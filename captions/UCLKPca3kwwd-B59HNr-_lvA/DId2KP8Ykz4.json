[
  {
    "text": "[Music]",
    "start": "350",
    "end": "13679"
  },
  {
    "text": "hello everyone Welcome to our talk uh my",
    "start": "13679",
    "end": "15920"
  },
  {
    "text": "name is atita and I work as a solution",
    "start": "15920",
    "end": "17880"
  },
  {
    "text": "architect at quadrant and um together",
    "start": "17880",
    "end": "21439"
  },
  {
    "text": "with me I have di I'm Diana Emory and I",
    "start": "21439",
    "end": "24160"
  },
  {
    "text": "am founding AI researcher at quo AI cool",
    "start": "24160",
    "end": "27519"
  },
  {
    "text": "so we would be talking about navigating",
    "start": "27519",
    "end": "29199"
  },
  {
    "text": "rag optimization with an evaluation",
    "start": "29199",
    "end": "31160"
  },
  {
    "text": "driven Compass so I think the track is",
    "start": "31160",
    "end": "34360"
  },
  {
    "text": "about rack so let's U talk and extend",
    "start": "34360",
    "end": "37120"
  },
  {
    "text": "what we already know and what we have",
    "start": "37120",
    "end": "38719"
  },
  {
    "text": "already seen so far so in this talk",
    "start": "38719",
    "end": "41039"
  },
  {
    "text": "today we will be discussing some of the",
    "start": "41039",
    "end": "42559"
  },
  {
    "text": "key essential topics for anyone",
    "start": "42559",
    "end": "44480"
  },
  {
    "text": "interested in building or",
    "start": "44480",
    "end": "46640"
  },
  {
    "text": "productionizing the most popular",
    "start": "46640",
    "end": "48360"
  },
  {
    "text": "implementation of generated AI that is",
    "start": "48360",
    "end": "50360"
  },
  {
    "text": "rag retrieval augmented generation uh in",
    "start": "50360",
    "end": "53320"
  },
  {
    "text": "simple terms rag combines the",
    "start": "53320",
    "end": "54920"
  },
  {
    "text": "capabilities of uh searching and",
    "start": "54920",
    "end": "56879"
  },
  {
    "text": "retrieving through the vast amount of",
    "start": "56879",
    "end": "59320"
  },
  {
    "text": "information stored in knowledge Source",
    "start": "59320",
    "end": "61800"
  },
  {
    "text": "um usually a vector database um and then",
    "start": "61800",
    "end": "65280"
  },
  {
    "text": "we use this information to generate",
    "start": "65280",
    "end": "67280"
  },
  {
    "text": "relevant and coherent responses",
    "start": "67280",
    "end": "69240"
  },
  {
    "text": "leveraging the capabilities of a large",
    "start": "69240",
    "end": "71840"
  },
  {
    "text": "language model we will be talking",
    "start": "71840",
    "end": "73680"
  },
  {
    "text": "through the known challenges of this",
    "start": "73680",
    "end": "75680"
  },
  {
    "text": "approach and uh how can you combat uh",
    "start": "75680",
    "end": "78600"
  },
  {
    "text": "them by adopting an evaluation based",
    "start": "78600",
    "end": "80560"
  },
  {
    "text": "optimization techniques to get the",
    "start": "80560",
    "end": "82320"
  },
  {
    "text": "desired results so without further Ado",
    "start": "82320",
    "end": "84560"
  },
  {
    "text": "let's get",
    "start": "84560",
    "end": "86119"
  },
  {
    "text": "started so yeah as uh simple as it's uh",
    "start": "86119",
    "end": "89640"
  },
  {
    "text": "defined find rag can be implemented in",
    "start": "89640",
    "end": "91720"
  },
  {
    "text": "many different ways as we can see on the",
    "start": "91720",
    "end": "93439"
  },
  {
    "text": "slide apologies for the busy slide as I",
    "start": "93439",
    "end": "95920"
  },
  {
    "text": "wanted to cover all the aspects of how U",
    "start": "95920",
    "end": "99000"
  },
  {
    "text": "rag can be implemented and uh we will be",
    "start": "99000",
    "end": "101680"
  },
  {
    "text": "starting with the simplest one the naive",
    "start": "101680",
    "end": "103280"
  },
  {
    "text": "rag this uh involves three key steps",
    "start": "103280",
    "end": "106200"
  },
  {
    "text": "first we split the documents uh using",
    "start": "106200",
    "end": "108880"
  },
  {
    "text": "the specific chunking strategy next we",
    "start": "108880",
    "end": "111520"
  },
  {
    "text": "process the document embedding and store",
    "start": "111520",
    "end": "113399"
  },
  {
    "text": "them into a vector database for each",
    "start": "113399",
    "end": "116280"
  },
  {
    "text": "user query we then retrieve the most",
    "start": "116280",
    "end": "118320"
  },
  {
    "text": "relevant document chunks based on our",
    "start": "118320",
    "end": "120719"
  },
  {
    "text": "retrieval strategy finally we add these",
    "start": "120719",
    "end": "123240"
  },
  {
    "text": "retrieve chunks to our prompt to",
    "start": "123240",
    "end": "125119"
  },
  {
    "text": "generate an answer using a chosen LM",
    "start": "125119",
    "end": "128599"
  },
  {
    "text": "Advanced versions involve enhancement to",
    "start": "128599",
    "end": "131000"
  },
  {
    "text": "user query such as um query expansion or",
    "start": "131000",
    "end": "134160"
  },
  {
    "text": "rewriting and uh post retrieval",
    "start": "134160",
    "end": "136319"
  },
  {
    "text": "treatments like um result reranking or",
    "start": "136319",
    "end": "139680"
  },
  {
    "text": "Fusion the further Advanced version of",
    "start": "139680",
    "end": "142400"
  },
  {
    "text": "uh rack includes uh query routing um to",
    "start": "142400",
    "end": "146080"
  },
  {
    "text": "task based agents and self-improvement",
    "start": "146080",
    "end": "148440"
  },
  {
    "text": "modules like tsp",
    "start": "148440",
    "end": "151239"
  },
  {
    "text": "however there's one tool that is common",
    "start": "151239",
    "end": "152920"
  },
  {
    "text": "in all these implementations if you",
    "start": "152920",
    "end": "154239"
  },
  {
    "text": "notice no matter if you want to build a",
    "start": "154239",
    "end": "156239"
  },
  {
    "text": "naive or agentic rag and that is a",
    "start": "156239",
    "end": "159159"
  },
  {
    "text": "vector database one of the most common",
    "start": "159159",
    "end": "161319"
  },
  {
    "text": "use cases for a building rag is for",
    "start": "161319",
    "end": "163800"
  },
  {
    "text": "Knowledge Management there are aspects",
    "start": "163800",
    "end": "165720"
  },
  {
    "text": "like retrieval performance scalability",
    "start": "165720",
    "end": "167840"
  },
  {
    "text": "to support large data volume and",
    "start": "167840",
    "end": "170640"
  },
  {
    "text": "resource optimization are",
    "start": "170640",
    "end": "173200"
  },
  {
    "text": "Paramount speaking of vector database",
    "start": "173200",
    "end": "175720"
  },
  {
    "text": "quadrant is open source uh Vector search",
    "start": "175720",
    "end": "178440"
  },
  {
    "text": "database built on Rust and uh is purpose",
    "start": "178440",
    "end": "181480"
  },
  {
    "text": "built to support your generative AI",
    "start": "181480",
    "end": "183239"
  },
  {
    "text": "applications built on large scale of",
    "start": "183239",
    "end": "185239"
  },
  {
    "text": "data if you haven't already checked out",
    "start": "185239",
    "end": "187720"
  },
  {
    "text": "uh please do check",
    "start": "187720",
    "end": "189599"
  },
  {
    "text": "out so coming back to our topic it is uh",
    "start": "189599",
    "end": "192360"
  },
  {
    "text": "Worth to understand and acknowledge um",
    "start": "192360",
    "end": "194480"
  },
  {
    "text": "the challenges that come along with all",
    "start": "194480",
    "end": "196080"
  },
  {
    "text": "the goodness of rag I'm repurposing our",
    "start": "196080",
    "end": "198920"
  },
  {
    "text": "naive rag architecture to highlight",
    "start": "198920",
    "end": "200959"
  },
  {
    "text": "common possible issues on each level",
    "start": "200959",
    "end": "202720"
  },
  {
    "text": "after all the first step to solving any",
    "start": "202720",
    "end": "205000"
  },
  {
    "text": "problem is to recognize there is one to",
    "start": "205000",
    "end": "207560"
  },
  {
    "text": "begin with during the data processing",
    "start": "207560",
    "end": "209519"
  },
  {
    "text": "stage age we could have um issues with",
    "start": "209519",
    "end": "212200"
  },
  {
    "text": "the information missing from our data",
    "start": "212200",
    "end": "214319"
  },
  {
    "text": "set or information that fails to get",
    "start": "214319",
    "end": "216120"
  },
  {
    "text": "extracted from our source of information",
    "start": "216120",
    "end": "218840"
  },
  {
    "text": "this would result in Incorrect and",
    "start": "218840",
    "end": "221120"
  },
  {
    "text": "incomplete responses on data inje there",
    "start": "221120",
    "end": "224200"
  },
  {
    "text": "is a constant battle to determine the",
    "start": "224200",
    "end": "226120"
  },
  {
    "text": "optimum chunking strategy along with",
    "start": "226120",
    "end": "228360"
  },
  {
    "text": "determining a suitable embedding model",
    "start": "228360",
    "end": "230799"
  },
  {
    "text": "that basically understands the",
    "start": "230799",
    "end": "232239"
  },
  {
    "text": "specificity and jarons uh used in your",
    "start": "232239",
    "end": "234599"
  },
  {
    "text": "data set information retrieval itself is",
    "start": "234599",
    "end": "238120"
  },
  {
    "text": "quite interesting and very ever evolving",
    "start": "238120",
    "end": "241040"
  },
  {
    "text": "uh field having spent 17 years in uh the",
    "start": "241040",
    "end": "243720"
  },
  {
    "text": "space myself I can probably say that um",
    "start": "243720",
    "end": "246079"
  },
  {
    "text": "relevancy is an unsolved problem so the",
    "start": "246079",
    "end": "249079"
  },
  {
    "text": "challenge with determining relevant",
    "start": "249079",
    "end": "250959"
  },
  {
    "text": "documents retrieval size or retrieval",
    "start": "250959",
    "end": "253079"
  },
  {
    "text": "window if you may call it and the Order",
    "start": "253079",
    "end": "255120"
  },
  {
    "text": "of documents is",
    "start": "255120",
    "end": "256759"
  },
  {
    "text": "unskippable response generation can face",
    "start": "256759",
    "end": "259759"
  },
  {
    "text": "challenges such as Incorrect and",
    "start": "259759",
    "end": "262280"
  },
  {
    "text": "incomplete answers to all the previously",
    "start": "262280",
    "end": "264080"
  },
  {
    "text": "mentioned issues and the issues of",
    "start": "264080",
    "end": "266479"
  },
  {
    "text": "straying from the provided context to",
    "start": "266479",
    "end": "269440"
  },
  {
    "text": "add our query is also vulnerable to",
    "start": "269440",
    "end": "272160"
  },
  {
    "text": "ambiguous or vague uh questions there",
    "start": "272160",
    "end": "275680"
  },
  {
    "text": "are certainly other challenges like",
    "start": "275680",
    "end": "277440"
  },
  {
    "text": "generating coherent responses",
    "start": "277440",
    "end": "279240"
  },
  {
    "text": "maintaining user conversations scaling a",
    "start": "279240",
    "end": "281639"
  },
  {
    "text": "rag for hundred or thousands of",
    "start": "281639",
    "end": "283960"
  },
  {
    "text": "concurrent users along with data",
    "start": "283960",
    "end": "285759"
  },
  {
    "text": "security and compliance issues so looks",
    "start": "285759",
    "end": "288160"
  },
  {
    "text": "like rag isn't really a piece of cake",
    "start": "288160",
    "end": "290160"
  },
  {
    "text": "after all fortunately as for like the",
    "start": "290160",
    "end": "292919"
  },
  {
    "text": "challenges we have plenty of improvement",
    "start": "292919",
    "end": "294600"
  },
  {
    "text": "techniques as well for the rag let's",
    "start": "294600",
    "end": "296120"
  },
  {
    "text": "look at them",
    "start": "296120",
    "end": "297280"
  },
  {
    "text": "next so we saw challenges zooming in to",
    "start": "297280",
    "end": "299919"
  },
  {
    "text": "data quality data that missed to get",
    "start": "299919",
    "end": "302000"
  },
  {
    "text": "generated after all the foundation of",
    "start": "302000",
    "end": "303800"
  },
  {
    "text": "great responses is uh it lies in the",
    "start": "303800",
    "end": "306960"
  },
  {
    "text": "richness and accuracy of its information",
    "start": "306960",
    "end": "309759"
  },
  {
    "text": "or context in case of rag which can be",
    "start": "309759",
    "end": "312440"
  },
  {
    "text": "controlled through adopting data",
    "start": "312440",
    "end": "313840"
  },
  {
    "text": "cleaning and Advanced Data extraction",
    "start": "313840",
    "end": "316440"
  },
  {
    "text": "methodologies it is not a bad idea to",
    "start": "316440",
    "end": "318840"
  },
  {
    "text": "use a general purpose embedding model to",
    "start": "318840",
    "end": "320680"
  },
  {
    "text": "begin with but for added improvements it",
    "start": "320680",
    "end": "322960"
  },
  {
    "text": "would be a good idea to use an embedding",
    "start": "322960",
    "end": "324919"
  },
  {
    "text": "model that comprehends the terminologies",
    "start": "324919",
    "end": "326880"
  },
  {
    "text": "of your domain metadata it is a very",
    "start": "326880",
    "end": "329919"
  },
  {
    "text": "versatile feature that can help you",
    "start": "329919",
    "end": "331440"
  },
  {
    "text": "retrieve um um your um added um",
    "start": "331440",
    "end": "335039"
  },
  {
    "text": "understanding of your documents and",
    "start": "335039",
    "end": "336360"
  },
  {
    "text": "improving your retrieval plus leveraging",
    "start": "336360",
    "end": "338639"
  },
  {
    "text": "the metadata filtering during the",
    "start": "338639",
    "end": "340160"
  },
  {
    "text": "retrieval it can also help you out with",
    "start": "340160",
    "end": "342080"
  },
  {
    "text": "filtering out the irrelevant",
    "start": "342080",
    "end": "344400"
  },
  {
    "text": "documents so it is also probably a good",
    "start": "344400",
    "end": "347280"
  },
  {
    "text": "idea to invest your uh time into",
    "start": "347280",
    "end": "349120"
  },
  {
    "text": "determining and improving your chunking",
    "start": "349120",
    "end": "350639"
  },
  {
    "text": "strategy which we spoke about earlier",
    "start": "350639",
    "end": "353120"
  },
  {
    "text": "sometimes just by reducing the chunk",
    "start": "353120",
    "end": "354600"
  },
  {
    "text": "size or adding semantic chunking can",
    "start": "354600",
    "end": "356840"
  },
  {
    "text": "work wonders we would be seeing that",
    "start": "356840",
    "end": "358280"
  },
  {
    "text": "also when di walks us through through",
    "start": "358280",
    "end": "359960"
  },
  {
    "text": "all the",
    "start": "359960",
    "end": "361120"
  },
  {
    "text": "experimentation so we have been aware of",
    "start": "361120",
    "end": "363759"
  },
  {
    "text": "Lost in the middle problem and this is",
    "start": "363759",
    "end": "365759"
  },
  {
    "text": "where it may be a good idea to determine",
    "start": "365759",
    "end": "367360"
  },
  {
    "text": "an apt Contex size needed for your rag",
    "start": "367360",
    "end": "370240"
  },
  {
    "text": "to generate a helpful response also",
    "start": "370240",
    "end": "373000"
  },
  {
    "text": "using suitable indexing algorithms like",
    "start": "373000",
    "end": "375240"
  },
  {
    "text": "hnsw bm25 or even graphs they can do",
    "start": "375240",
    "end": "379720"
  },
  {
    "text": "wonders talking about suitable contact",
    "start": "379720",
    "end": "381919"
  },
  {
    "text": "size also prioritizes the document",
    "start": "381919",
    "end": "384199"
  },
  {
    "text": "reranking as one of the key Improvement",
    "start": "384199",
    "end": "386039"
  },
  {
    "text": "parameters to ensure the most relevant",
    "start": "386039",
    "end": "388360"
  },
  {
    "text": "documents um that are provided in the",
    "start": "388360",
    "end": "390800"
  },
  {
    "text": "context for llm to generate a helpful",
    "start": "390800",
    "end": "393440"
  },
  {
    "text": "response with llms in the picture we",
    "start": "393440",
    "end": "395880"
  },
  {
    "text": "cannot um Overlook the difference a good",
    "start": "395880",
    "end": "399039"
  },
  {
    "text": "prompt or thinking about questions as a",
    "start": "399039",
    "end": "401520"
  },
  {
    "text": "Chain of Thought can make to the",
    "start": "401520",
    "end": "402960"
  },
  {
    "text": "progress of process of response",
    "start": "402960",
    "end": "405560"
  },
  {
    "text": "generation semantic understanding is",
    "start": "405560",
    "end": "407919"
  },
  {
    "text": "clearly desired we know that uh text",
    "start": "407919",
    "end": "410319"
  },
  {
    "text": "search alone doesn't works but if the",
    "start": "410319",
    "end": "412880"
  },
  {
    "text": "data set has the requirement for the",
    "start": "412880",
    "end": "414440"
  },
  {
    "text": "exact matches it may be worth exploring",
    "start": "414440",
    "end": "416400"
  },
  {
    "text": "dense as well as parse vectors and you",
    "start": "416400",
    "end": "418800"
  },
  {
    "text": "can do that on one or many fields",
    "start": "418800",
    "end": "421599"
  },
  {
    "text": "similar to the embedding model it may be",
    "start": "421599",
    "end": "423440"
  },
  {
    "text": "worth switching and experimenting with",
    "start": "423440",
    "end": "425039"
  },
  {
    "text": "different llms as well to ensure that",
    "start": "425039",
    "end": "427240"
  },
  {
    "text": "the desired response is generated and",
    "start": "427240",
    "end": "429479"
  },
  {
    "text": "lastly for better handling of task",
    "start": "429479",
    "end": "432240"
  },
  {
    "text": "driven uh user queries such as fetching",
    "start": "432240",
    "end": "434919"
  },
  {
    "text": "specific information or using custom",
    "start": "434919",
    "end": "436919"
  },
  {
    "text": "data it is beneficial to address these",
    "start": "436919",
    "end": "439240"
  },
  {
    "text": "uh challenges using agents which are",
    "start": "439240",
    "end": "441120"
  },
  {
    "text": "well suited for the",
    "start": "441120",
    "end": "442759"
  },
  {
    "text": "job so with so many different levers to",
    "start": "442759",
    "end": "445160"
  },
  {
    "text": "tweak in rack pipeline it's hard to know",
    "start": "445160",
    "end": "448000"
  },
  {
    "text": "what's going wrong what to change where",
    "start": "448000",
    "end": "449759"
  },
  {
    "text": "to start this is why evaluation is very",
    "start": "449759",
    "end": "452240"
  },
  {
    "text": "important without an evaluation-based",
    "start": "452240",
    "end": "454240"
  },
  {
    "text": "guided flow it is difficult to",
    "start": "454240",
    "end": "456639"
  },
  {
    "text": "accurately measure progress and ensure",
    "start": "456639",
    "end": "458960"
  },
  {
    "text": "Optimal Performance evaluation also",
    "start": "458960",
    "end": "461280"
  },
  {
    "text": "helps you to iteratively refine",
    "start": "461280",
    "end": "463199"
  },
  {
    "text": "applications making informed decisions",
    "start": "463199",
    "end": "465560"
  },
  {
    "text": "and ultimately achieve goals more",
    "start": "465560",
    "end": "467280"
  },
  {
    "text": "effectively so on that topic I would",
    "start": "467280",
    "end": "469440"
  },
  {
    "text": "like to welcome Tiana who's going to",
    "start": "469440",
    "end": "471159"
  },
  {
    "text": "basically walk us through how we did",
    "start": "471159",
    "end": "473360"
  },
  {
    "text": "this",
    "start": "473360",
    "end": "474840"
  },
  {
    "text": "experimentation uh thanks SAA for the",
    "start": "474840",
    "end": "477479"
  },
  {
    "text": "perfect setup",
    "start": "477479",
    "end": "479759"
  },
  {
    "text": "um so this is where quotient comes in I",
    "start": "479759",
    "end": "483080"
  },
  {
    "text": "might steal that from you thank you um",
    "start": "483080",
    "end": "485360"
  },
  {
    "text": "so because the quality of rag is so",
    "start": "485360",
    "end": "489000"
  },
  {
    "text": "dependent on the underlying documents a",
    "start": "489000",
    "end": "491960"
  },
  {
    "text": "thorough evaluation of rag system has to",
    "start": "491960",
    "end": "494800"
  },
  {
    "text": "be customized to suit that specific",
    "start": "494800",
    "end": "497400"
  },
  {
    "text": "domain and data set um so quo evaluation",
    "start": "497400",
    "end": "501319"
  },
  {
    "text": "solution fills this need by enabling",
    "start": "501319",
    "end": "503879"
  },
  {
    "text": "developers to measure the effectiveness",
    "start": "503879",
    "end": "506319"
  },
  {
    "text": "of their llm products accurately quo",
    "start": "506319",
    "end": "509720"
  },
  {
    "text": "platform accelerates the experimentation",
    "start": "509720",
    "end": "512919"
  },
  {
    "text": "process with an evaluation data set that",
    "start": "512919",
    "end": "515719"
  },
  {
    "text": "contains realistic examples of inputs",
    "start": "515719",
    "end": "519279"
  },
  {
    "text": "and expected outputs for your AI",
    "start": "519279",
    "end": "521039"
  },
  {
    "text": "solution you can quickly experiment and",
    "start": "521039",
    "end": "523518"
  },
  {
    "text": "iterate to optimize your rag",
    "start": "523519",
    "end": "526080"
  },
  {
    "text": "Solutions and if you don't have an",
    "start": "526080",
    "end": "528519"
  },
  {
    "text": "evaluation data set don't worry uh",
    "start": "528519",
    "end": "531360"
  },
  {
    "text": "quotient can help you get started by",
    "start": "531360",
    "end": "532680"
  },
  {
    "text": "generating one for you and you can hear",
    "start": "532680",
    "end": "534880"
  },
  {
    "text": "more from us on this at the AI Sizzle",
    "start": "534880",
    "end": "536839"
  },
  {
    "text": "and waves meetup on Friday",
    "start": "536839",
    "end": "540240"
  },
  {
    "text": "so how does this work in practice once",
    "start": "540240",
    "end": "542560"
  },
  {
    "text": "you have your quadrant Vector database",
    "start": "542560",
    "end": "544399"
  },
  {
    "text": "set up you can populate your evaluation",
    "start": "544399",
    "end": "547079"
  },
  {
    "text": "data set by submitting queries to return",
    "start": "547079",
    "end": "549880"
  },
  {
    "text": "the contexts for the llm you can then",
    "start": "549880",
    "end": "552800"
  },
  {
    "text": "submit your evaluation data set to",
    "start": "552800",
    "end": "554399"
  },
  {
    "text": "quotient which handles the full",
    "start": "554399",
    "end": "556160"
  },
  {
    "text": "orchestration including the prompt",
    "start": "556160",
    "end": "558519"
  },
  {
    "text": "formatting execution of llms and the",
    "start": "558519",
    "end": "561079"
  },
  {
    "text": "metric",
    "start": "561079",
    "end": "562560"
  },
  {
    "text": "computations so to see an in action",
    "start": "562560",
    "end": "565320"
  },
  {
    "text": "we've put together a demo walkthrough",
    "start": "565320",
    "end": "567240"
  },
  {
    "text": "where we'll show you a workflow for",
    "start": "567240",
    "end": "569079"
  },
  {
    "text": "making evaluation informed changes to",
    "start": "569079",
    "end": "572200"
  },
  {
    "text": "optimize your rag system using quotient",
    "start": "572200",
    "end": "574760"
  },
  {
    "text": "and quadrant for the sake of time we've",
    "start": "574760",
    "end": "577880"
  },
  {
    "text": "executed The Notebook ahead of time and",
    "start": "577880",
    "end": "579480"
  },
  {
    "text": "we'll be walking you through the code",
    "start": "579480",
    "end": "581320"
  },
  {
    "text": "outputs and if you scare scan the QR",
    "start": "581320",
    "end": "583920"
  },
  {
    "text": "code here you can find the notebook on",
    "start": "583920",
    "end": "585680"
  },
  {
    "text": "GitHub in this demo we are building a",
    "start": "585680",
    "end": "588920"
  },
  {
    "text": "rag solution for question answering on",
    "start": "588920",
    "end": "592079"
  },
  {
    "text": "quadrants documentation and this will",
    "start": "592079",
    "end": "594519"
  },
  {
    "text": "help enable quadrant users to get help",
    "start": "594519",
    "end": "598040"
  },
  {
    "text": "quickly so",
    "start": "598040",
    "end": "599839"
  },
  {
    "text": "before we begin evaluation it's",
    "start": "599839",
    "end": "601360"
  },
  {
    "text": "important to take a step back and",
    "start": "601360",
    "end": "602880"
  },
  {
    "text": "consider what we're optimizing for given",
    "start": "602880",
    "end": "605360"
  },
  {
    "text": "this use case it's generally important",
    "start": "605360",
    "end": "607560"
  },
  {
    "text": "to get helpful answers to the questions",
    "start": "607560",
    "end": "609920"
  },
  {
    "text": "but it's perhaps more important that the",
    "start": "609920",
    "end": "612120"
  },
  {
    "text": "answers do not contain any inaccurate",
    "start": "612120",
    "end": "614360"
  },
  {
    "text": "information that could misguide users",
    "start": "614360",
    "end": "617399"
  },
  {
    "text": "and so in other words we want to",
    "start": "617399",
    "end": "619480"
  },
  {
    "text": "minimize hallucinations and with that in",
    "start": "619480",
    "end": "622120"
  },
  {
    "text": "mind we will be looking at the following",
    "start": "622120",
    "end": "624160"
  },
  {
    "text": "metrics shown here with a focus on",
    "start": "624160",
    "end": "626959"
  },
  {
    "text": "faithfulness uh the first two metrics",
    "start": "626959",
    "end": "629000"
  },
  {
    "text": "are both both focused on measuring the",
    "start": "629000",
    "end": "630760"
  },
  {
    "text": "quality of the retrieval side of rag",
    "start": "630760",
    "end": "633320"
  },
  {
    "text": "context relevance tells us whether the",
    "start": "633320",
    "end": "635880"
  },
  {
    "text": "necessary information to answer the",
    "start": "635880",
    "end": "637360"
  },
  {
    "text": "question is in the retrieved documents",
    "start": "637360",
    "end": "639600"
  },
  {
    "text": "chunk relevance tells us how much of the",
    "start": "639600",
    "end": "642120"
  },
  {
    "text": "information retrieved is actually useful",
    "start": "642120",
    "end": "644360"
  },
  {
    "text": "for answering the question versus just",
    "start": "644360",
    "end": "646200"
  },
  {
    "text": "noise faithfulness is our hallucination",
    "start": "646200",
    "end": "649639"
  },
  {
    "text": "metric and and then because be the focus",
    "start": "649639",
    "end": "652720"
  },
  {
    "text": "of this talk is going to be optimizing",
    "start": "652720",
    "end": "654880"
  },
  {
    "text": "the retrieval side of rag we're sticking",
    "start": "654880",
    "end": "656639"
  },
  {
    "text": "to some of the more General text quality",
    "start": "656639",
    "end": "659320"
  },
  {
    "text": "metrics",
    "start": "659320",
    "end": "660959"
  },
  {
    "text": "here so when we're first getting started",
    "start": "660959",
    "end": "664240"
  },
  {
    "text": "we want to consider a simple naive rag",
    "start": "664240",
    "end": "666519"
  },
  {
    "text": "implementation to help us better",
    "start": "666519",
    "end": "669120"
  },
  {
    "text": "optimize the data processing and Vector",
    "start": "669120",
    "end": "671320"
  },
  {
    "text": "database",
    "start": "671320",
    "end": "672320"
  },
  {
    "text": "setup so we start off by choosing a",
    "start": "672320",
    "end": "675320"
  },
  {
    "text": "reasonable embedding model and chunking",
    "start": "675320",
    "end": "677079"
  },
  {
    "text": "parameters retrieval window and the",
    "start": "677079",
    "end": "679399"
  },
  {
    "text": "mistal instruct model and then to see if",
    "start": "679399",
    "end": "683120"
  },
  {
    "text": "we require additional context to answer",
    "start": "683120",
    "end": "685600"
  },
  {
    "text": "the questions we set up a second",
    "start": "685600",
    "end": "687120"
  },
  {
    "text": "experiment where we increase the chunk",
    "start": "687120",
    "end": "689040"
  },
  {
    "text": "per",
    "start": "689040",
    "end": "690320"
  },
  {
    "text": "parameters and so here are the results",
    "start": "690320",
    "end": "692920"
  },
  {
    "text": "of those first two experiments you can",
    "start": "692920",
    "end": "695079"
  },
  {
    "text": "see that by increasing the chunk size in",
    "start": "695079",
    "end": "697279"
  },
  {
    "text": "Experiment 2 we had some minor",
    "start": "697279",
    "end": "699200"
  },
  {
    "text": "improvements in our text quality metrics",
    "start": "699200",
    "end": "702240"
  },
  {
    "text": "that said we had a considerable drop in",
    "start": "702240",
    "end": "705279"
  },
  {
    "text": "our faithfulness which is the metric",
    "start": "705279",
    "end": "707079"
  },
  {
    "text": "we're optimizing for of note you can see",
    "start": "707079",
    "end": "710560"
  },
  {
    "text": "that the context relevance increased",
    "start": "710560",
    "end": "712839"
  },
  {
    "text": "meaning that we retrieved more of the",
    "start": "712839",
    "end": "714839"
  },
  {
    "text": "necessary information to answer the",
    "start": "714839",
    "end": "716560"
  },
  {
    "text": "question but the chunk relevance dropped",
    "start": "716560",
    "end": "719720"
  },
  {
    "text": "considerably meaning that a smaller",
    "start": "719720",
    "end": "721720"
  },
  {
    "text": "portion of the retriev documents was",
    "start": "721720",
    "end": "723880"
  },
  {
    "text": "actually relevant and so what this",
    "start": "723880",
    "end": "727079"
  },
  {
    "text": "implies is that if we simply retrieve",
    "start": "727079",
    "end": "730079"
  },
  {
    "text": "more documents but use the smaller chunk",
    "start": "730079",
    "end": "732399"
  },
  {
    "text": "size from before we might get better",
    "start": "732399",
    "end": "734040"
  },
  {
    "text": "results and so we try this",
    "start": "734040",
    "end": "736639"
  },
  {
    "text": "out as expected the smaller chunk size",
    "start": "736639",
    "end": "740760"
  },
  {
    "text": "uh with the larger retrieval window",
    "start": "740760",
    "end": "742600"
  },
  {
    "text": "achieved the highest relevance scores",
    "start": "742600",
    "end": "745360"
  },
  {
    "text": "and the best faithfulness score uh",
    "start": "745360",
    "end": "747399"
  },
  {
    "text": "meaning that we have a lower occurrence",
    "start": "747399",
    "end": "748639"
  },
  {
    "text": "of hallucination",
    "start": "748639",
    "end": "751160"
  },
  {
    "text": "in our next two iterations we test out a",
    "start": "751279",
    "end": "753839"
  },
  {
    "text": "new embedding model as well as a",
    "start": "753839",
    "end": "755720"
  },
  {
    "text": "different llm switching to GPT",
    "start": "755720",
    "end": "758079"
  },
  {
    "text": "3.5 and while the embedding model",
    "start": "758079",
    "end": "760959"
  },
  {
    "text": "experiment in the light gray didn't",
    "start": "760959",
    "end": "762360"
  },
  {
    "text": "quite work out for experiment 5 in the",
    "start": "762360",
    "end": "764720"
  },
  {
    "text": "dark gray we found that using the same",
    "start": "764720",
    "end": "766480"
  },
  {
    "text": "rag configuration but changing the llm",
    "start": "766480",
    "end": "769480"
  },
  {
    "text": "improved performance across all our",
    "start": "769480",
    "end": "773519"
  },
  {
    "text": "metrics so here we're looking at the",
    "start": "773600",
    "end": "775800"
  },
  {
    "text": "aggregated metrics for our top",
    "start": "775800",
    "end": "777360"
  },
  {
    "text": "performing rag configuration and the",
    "start": "777360",
    "end": "779880"
  },
  {
    "text": "large variance in the context relevance",
    "start": "779880",
    "end": "781680"
  },
  {
    "text": "which is highlighted in red implies that",
    "start": "781680",
    "end": "784040"
  },
  {
    "text": "some of the questions are having a",
    "start": "784040",
    "end": "785120"
  },
  {
    "text": "harder time retrieving the right",
    "start": "785120",
    "end": "786720"
  },
  {
    "text": "documents so to better understand what's",
    "start": "786720",
    "end": "789120"
  },
  {
    "text": "going on we have to look into the data",
    "start": "789120",
    "end": "791800"
  },
  {
    "text": "and here we've shown the two worst",
    "start": "791800",
    "end": "793920"
  },
  {
    "text": "performing data points in terms of",
    "start": "793920",
    "end": "796600"
  },
  {
    "text": "hallucination this third column here",
    "start": "796600",
    "end": "798720"
  },
  {
    "text": "shows us the retriev documents and it's",
    "start": "798720",
    "end": "800519"
  },
  {
    "text": "a lot of text so I'll just summarize um",
    "start": "800519",
    "end": "803959"
  },
  {
    "text": "so it seems like we're returning a lot",
    "start": "803959",
    "end": "805600"
  },
  {
    "text": "of unrelated documents that are likely",
    "start": "805600",
    "end": "808760"
  },
  {
    "text": "over indexing on specific words in the",
    "start": "808760",
    "end": "811160"
  },
  {
    "text": "query like quadrant support and search",
    "start": "811160",
    "end": "814600"
  },
  {
    "text": "and we're returning documents that",
    "start": "814600",
    "end": "816240"
  },
  {
    "text": "repeat these terms many times so to",
    "start": "816240",
    "end": "819320"
  },
  {
    "text": "address this issue one possible solution",
    "start": "819320",
    "end": "822199"
  },
  {
    "text": "could be expanding our retrieval window",
    "start": "822199",
    "end": "824079"
  },
  {
    "text": "to capture more documents and thereby",
    "start": "824079",
    "end": "826199"
  },
  {
    "text": "making it more likely we get the right",
    "start": "826199",
    "end": "828079"
  },
  {
    "text": "information but in doing so we'd also be",
    "start": "828079",
    "end": "830519"
  },
  {
    "text": "adding a lot of noise to our context so",
    "start": "830519",
    "end": "833839"
  },
  {
    "text": "by now we likely need to expand out of",
    "start": "833839",
    "end": "836160"
  },
  {
    "text": "naive Rag and start to add in some more",
    "start": "836160",
    "end": "838040"
  },
  {
    "text": "Advanced Techniques",
    "start": "838040",
    "end": "839839"
  },
  {
    "text": "and this is where reranking comes in so",
    "start": "839839",
    "end": "842519"
  },
  {
    "text": "we could try using a different embedding",
    "start": "842519",
    "end": "844399"
  },
  {
    "text": "model to rerank the retrieved documents",
    "start": "844399",
    "end": "846920"
  },
  {
    "text": "and then return only the top few thus",
    "start": "846920",
    "end": "849160"
  },
  {
    "text": "weeding out some of the more unrelated",
    "start": "849160",
    "end": "850800"
  },
  {
    "text": "ones so we try this out we perform three",
    "start": "850800",
    "end": "853959"
  },
  {
    "text": "different reranking experiments trying",
    "start": "853959",
    "end": "855880"
  },
  {
    "text": "rankers from mixed bread cohere and",
    "start": "855880",
    "end": "857880"
  },
  {
    "text": "Gina's Colbert model and we plot them",
    "start": "857880",
    "end": "860160"
  },
  {
    "text": "here against our top naive rag approach",
    "start": "860160",
    "end": "862480"
  },
  {
    "text": "in blue and you can see that in general",
    "start": "862480",
    "end": "865880"
  },
  {
    "text": "our context relevances and with it our",
    "start": "865880",
    "end": "867880"
  },
  {
    "text": "faithfulness have improved with this",
    "start": "867880",
    "end": "870079"
  },
  {
    "text": "strategy with cohere achieving the best",
    "start": "870079",
    "end": "872839"
  },
  {
    "text": "relevance and faithfulness",
    "start": "872839",
    "end": "875199"
  },
  {
    "text": "scores if we return to those same two",
    "start": "875199",
    "end": "877880"
  },
  {
    "text": "worst performing data points from",
    "start": "877880",
    "end": "879440"
  },
  {
    "text": "experiment 5 now and look at how our",
    "start": "879440",
    "end": "881839"
  },
  {
    "text": "reranking implementation did you can see",
    "start": "881839",
    "end": "884160"
  },
  {
    "text": "that in the second example we're now",
    "start": "884160",
    "end": "886720"
  },
  {
    "text": "retrieving documents that contain the",
    "start": "886720",
    "end": "888440"
  },
  {
    "text": "desired answer and with it our context",
    "start": "888440",
    "end": "891320"
  },
  {
    "text": "relevance and faithfulness are close to",
    "start": "891320",
    "end": "892959"
  },
  {
    "text": "one that said in the first example we're",
    "start": "892959",
    "end": "895959"
  },
  {
    "text": "still getting poor results and this",
    "start": "895959",
    "end": "897519"
  },
  {
    "text": "suggests that even after after expanding",
    "start": "897519",
    "end": "899639"
  },
  {
    "text": "our retrieval Windows we're still unable",
    "start": "899639",
    "end": "901759"
  },
  {
    "text": "to identify the relevant",
    "start": "901759",
    "end": "903440"
  },
  {
    "text": "documents so if we think about the",
    "start": "903440",
    "end": "905560"
  },
  {
    "text": "quadrant documentation and the text",
    "start": "905560",
    "end": "907759"
  },
  {
    "text": "within it it contains a lot of special",
    "start": "907759",
    "end": "909720"
  },
  {
    "text": "terminology jargon acronyms and so it's",
    "start": "909720",
    "end": "912519"
  },
  {
    "text": "unsurprising that these generally",
    "start": "912519",
    "end": "914079"
  },
  {
    "text": "trained embedding models are going to be",
    "start": "914079",
    "end": "916399"
  },
  {
    "text": "limited in performance so we could try",
    "start": "916399",
    "end": "919839"
  },
  {
    "text": "fine-tuning or training our own model to",
    "start": "919839",
    "end": "922279"
  },
  {
    "text": "address this issue but this could be",
    "start": "922279",
    "end": "924040"
  },
  {
    "text": "timec consuming and costly um so another",
    "start": "924040",
    "end": "927399"
  },
  {
    "text": "option to try is Hy search which",
    "start": "927399",
    "end": "929839"
  },
  {
    "text": "combines sparse and dense vectors and",
    "start": "929839",
    "end": "932440"
  },
  {
    "text": "these sparse vectors help us capture",
    "start": "932440",
    "end": "934240"
  },
  {
    "text": "documents that share similar",
    "start": "934240",
    "end": "936839"
  },
  {
    "text": "terminology so we tried two",
    "start": "936839",
    "end": "938720"
  },
  {
    "text": "implementations of this one where we",
    "start": "938720",
    "end": "940519"
  },
  {
    "text": "incorporate hybrid search with a ranker",
    "start": "940519",
    "end": "942680"
  },
  {
    "text": "and one without and you can see that uh",
    "start": "942680",
    "end": "945880"
  },
  {
    "text": "using the coh here ranker with hybrid",
    "start": "945880",
    "end": "947880"
  },
  {
    "text": "search gives us the best performance",
    "start": "947880",
    "end": "949360"
  },
  {
    "text": "across all metrics except for chunk",
    "start": "949360",
    "end": "952279"
  },
  {
    "text": "relevance so looking at this uh hybrid",
    "start": "952279",
    "end": "954880"
  },
  {
    "text": "search reranking experiment now on these",
    "start": "954880",
    "end": "956880"
  },
  {
    "text": "same two data points you can see that",
    "start": "956880",
    "end": "958720"
  },
  {
    "text": "the context relevance and faithfulness",
    "start": "958720",
    "end": "960519"
  },
  {
    "text": "scores are both close to one now a",
    "start": "960519",
    "end": "963160"
  },
  {
    "text": "significant improvement over our prior",
    "start": "963160",
    "end": "964880"
  },
  {
    "text": "ones and we're also better to retrie",
    "start": "964880",
    "end": "967440"
  },
  {
    "text": "better able to retrieve the information",
    "start": "967440",
    "end": "970160"
  },
  {
    "text": "necessary to answer these questions and",
    "start": "970160",
    "end": "972240"
  },
  {
    "text": "so this suggests the domain specific",
    "start": "972240",
    "end": "974440"
  },
  {
    "text": "terminology has a big effect on our",
    "start": "974440",
    "end": "976399"
  },
  {
    "text": "overall",
    "start": "976399",
    "end": "977800"
  },
  {
    "text": "performance so to summarize the table",
    "start": "977800",
    "end": "980399"
  },
  {
    "text": "here shows what gains in performance we",
    "start": "980399",
    "end": "982079"
  },
  {
    "text": "were able to make over just 10",
    "start": "982079",
    "end": "984000"
  },
  {
    "text": "experiments starting from a faithfulness",
    "start": "984000",
    "end": "986199"
  },
  {
    "text": "score of 76 we worked our way up to a",
    "start": "986199",
    "end": "988959"
  },
  {
    "text": "score of just under 85 and notably all",
    "start": "988959",
    "end": "991759"
  },
  {
    "text": "of these gains were made without",
    "start": "991759",
    "end": "993399"
  },
  {
    "text": "changing from a generic question",
    "start": "993399",
    "end": "995240"
  },
  {
    "text": "answering prompt so there's certainly",
    "start": "995240",
    "end": "997920"
  },
  {
    "text": "many more experiments to run and we have",
    "start": "997920",
    "end": "999519"
  },
  {
    "text": "plenty of room for improvement but you",
    "start": "999519",
    "end": "1001079"
  },
  {
    "text": "can see how starting from scratch you",
    "start": "1001079",
    "end": "1003000"
  },
  {
    "text": "can improve your rag system by making",
    "start": "1003000",
    "end": "1005880"
  },
  {
    "text": "incremental changes evaluating using a",
    "start": "1005880",
    "end": "1008800"
  },
  {
    "text": "combination of metrics that together can",
    "start": "1008800",
    "end": "1011519"
  },
  {
    "text": "help you identify underlying issues then",
    "start": "1011519",
    "end": "1014040"
  },
  {
    "text": "observing patterns in your data forming",
    "start": "1014040",
    "end": "1016040"
  },
  {
    "text": "a hypothesis and repeating the process",
    "start": "1016040",
    "end": "1020639"
  },
  {
    "text": "thank you",
    "start": "1020639",
    "end": "1021680"
  },
  {
    "text": "di so to summarize um this St and the",
    "start": "1021680",
    "end": "1025480"
  },
  {
    "text": "experimentation in this talk we covered",
    "start": "1025480",
    "end": "1027760"
  },
  {
    "text": "several key aspects of improving rag the",
    "start": "1027760",
    "end": "1030640"
  },
  {
    "text": "Baseline takeaway is that U there is no",
    "start": "1030640",
    "end": "1033280"
  },
  {
    "text": "substitute for evaluation based or data",
    "start": "1033280",
    "end": "1035600"
  },
  {
    "text": "driven improvements we emphasized",
    "start": "1035600",
    "end": "1037760"
  },
  {
    "text": "leveraging domain understanding to",
    "start": "1037760",
    "end": "1039798"
  },
  {
    "text": "achieve significant uh wins and uh",
    "start": "1039799",
    "end": "1042558"
  },
  {
    "text": "outlined various techniques for",
    "start": "1042559",
    "end": "1044438"
  },
  {
    "text": "enhancement in our experiments to ensure",
    "start": "1044439",
    "end": "1047199"
  },
  {
    "text": "continuous Improvement it is crucial to",
    "start": "1047199",
    "end": "1049039"
  },
  {
    "text": "keep your evaluation data set up to date",
    "start": "1049039",
    "end": "1051840"
  },
  {
    "text": "lastly avoid over engineering your rag",
    "start": "1051840",
    "end": "1054320"
  },
  {
    "text": "application without considering a",
    "start": "1054320",
    "end": "1056240"
  },
  {
    "text": "combination of carefully chosen metrics",
    "start": "1056240",
    "end": "1059000"
  },
  {
    "text": "if this talk picked your interest and",
    "start": "1059000",
    "end": "1061280"
  },
  {
    "text": "you are interested to get in touch with",
    "start": "1061280",
    "end": "1062799"
  },
  {
    "text": "us before that some key references and",
    "start": "1062799",
    "end": "1066559"
  },
  {
    "text": "the QR code please feel free to scan",
    "start": "1066559",
    "end": "1069280"
  },
  {
    "text": "them get in touch with us we're going to",
    "start": "1069280",
    "end": "1070799"
  },
  {
    "text": "be around and looking forward to all",
    "start": "1070799",
    "end": "1072360"
  },
  {
    "text": "your questions",
    "start": "1072360",
    "end": "1075520"
  },
  {
    "text": "[Music]",
    "start": "1077960",
    "end": "1094849"
  }
]
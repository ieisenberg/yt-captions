[
  {
    "text": "[Music]",
    "start": "350",
    "end": "14050"
  },
  {
    "text": "um so my name is Kevin and I'm going to",
    "start": "14080",
    "end": "16000"
  },
  {
    "text": "be talking about how embeddings are",
    "start": "16000",
    "end": "17720"
  },
  {
    "text": "stunting AI agents uh so I'm going to",
    "start": "17720",
    "end": "20840"
  },
  {
    "text": "let you in on some secrets about how we",
    "start": "20840",
    "end": "22439"
  },
  {
    "text": "build the product uh and exactly what",
    "start": "22439",
    "end": "24920"
  },
  {
    "text": "we're doing behind the scenes to improve",
    "start": "24920",
    "end": "27000"
  },
  {
    "text": "your Cod gen experience so at codium we",
    "start": "27000",
    "end": "30119"
  },
  {
    "text": "are building AI developer tools and",
    "start": "30119",
    "end": "32040"
  },
  {
    "text": "we're starting with an IDE plugin and as",
    "start": "32040",
    "end": "35239"
  },
  {
    "text": "uh as mentioned before we've been",
    "start": "35239",
    "end": "36360"
  },
  {
    "text": "downloaded over a million and a half",
    "start": "36360",
    "end": "38320"
  },
  {
    "text": "times uh we're one of the top rated",
    "start": "38320",
    "end": "40120"
  },
  {
    "text": "extensions across the different",
    "start": "40120",
    "end": "41280"
  },
  {
    "text": "marketplaces and to re reiterate we",
    "start": "41280",
    "end": "44039"
  },
  {
    "text": "offer free unlimited autocomplete chat",
    "start": "44039",
    "end": "46559"
  },
  {
    "text": "and search across 70 different languages",
    "start": "46559",
    "end": "49039"
  },
  {
    "text": "and 40 different ID so we plug into all",
    "start": "49039",
    "end": "51719"
  },
  {
    "text": "the popular",
    "start": "51719",
    "end": "53120"
  },
  {
    "text": "idees uh we are the highest rated",
    "start": "53120",
    "end": "55800"
  },
  {
    "text": "developer tool as voted in by developers",
    "start": "55800",
    "end": "58000"
  },
  {
    "text": "in the most recent stack Overflow survey",
    "start": "58000",
    "end": "60160"
  },
  {
    "text": "uh and you'll note that this is even",
    "start": "60160",
    "end": "61519"
  },
  {
    "text": "higher than tools like chat GPT and",
    "start": "61519",
    "end": "63760"
  },
  {
    "text": "GitHub",
    "start": "63760",
    "end": "65000"
  },
  {
    "text": "co-pilot and importantly we are trusted",
    "start": "65000",
    "end": "67600"
  },
  {
    "text": "by Fortune 500s to deliver high quality",
    "start": "67600",
    "end": "70040"
  },
  {
    "text": "code that actually makes it into",
    "start": "70040",
    "end": "71400"
  },
  {
    "text": "production and we do this with top grade",
    "start": "71400",
    "end": "73479"
  },
  {
    "text": "security licensing attribution for some",
    "start": "73479",
    "end": "75799"
  },
  {
    "text": "of the largest Enterprises on the planet",
    "start": "75799",
    "end": "78240"
  },
  {
    "text": "our goal at codium is to empower every",
    "start": "78240",
    "end": "80119"
  },
  {
    "text": "developer to have superpowers both",
    "start": "80119",
    "end": "82000"
  },
  {
    "text": "inside of the ID and",
    "start": "82000",
    "end": "85000"
  },
  {
    "text": "Beyond and today I'm going to let you in",
    "start": "85000",
    "end": "87320"
  },
  {
    "text": "on some secrets about how we've been",
    "start": "87320",
    "end": "88960"
  },
  {
    "text": "able to build a tool like this and why",
    "start": "88960",
    "end": "91240"
  },
  {
    "text": "CH uh users choose us over the other AI",
    "start": "91240",
    "end": "93560"
  },
  {
    "text": "tools on the market and the short answer",
    "start": "93560",
    "end": "95840"
  },
  {
    "text": "is context",
    "start": "95840",
    "end": "97759"
  },
  {
    "text": "awareness so here's a quick overview",
    "start": "97759",
    "end": "99920"
  },
  {
    "text": "about what context looks like today uh",
    "start": "99920",
    "end": "103159"
  },
  {
    "text": "we're all familiar since we're at an AI",
    "start": "103159",
    "end": "104600"
  },
  {
    "text": "conference with the basics of retrieval",
    "start": "104600",
    "end": "106399"
  },
  {
    "text": "augmented generation the idea being that",
    "start": "106399",
    "end": "108280"
  },
  {
    "text": "a user puts in a query um you accumulate",
    "start": "108280",
    "end": "111960"
  },
  {
    "text": "context from a variety of different",
    "start": "111960",
    "end": "113360"
  },
  {
    "text": "sources you throw it into your llm and",
    "start": "113360",
    "end": "115560"
  },
  {
    "text": "then you get a response whether that be",
    "start": "115560",
    "end": "117280"
  },
  {
    "text": "a code generation or a chat message",
    "start": "117280",
    "end": "121360"
  },
  {
    "text": "um here's a concrete example about how",
    "start": "121360",
    "end": "123399"
  },
  {
    "text": "retrieval can be used in code generation",
    "start": "123399",
    "end": "126000"
  },
  {
    "text": "so let's say we want to build a contact",
    "start": "126000",
    "end": "127600"
  },
  {
    "text": "form in react um now you could go to",
    "start": "127600",
    "end": "129959"
  },
  {
    "text": "chat GPT you could ask it to generate a",
    "start": "129959",
    "end": "131720"
  },
  {
    "text": "contact form but in reality on a",
    "start": "131720",
    "end": "133480"
  },
  {
    "text": "moderately large code base this is",
    "start": "133480",
    "end": "134920"
  },
  {
    "text": "really not going to work it's not going",
    "start": "134920",
    "end": "136160"
  },
  {
    "text": "to give you uh things that are",
    "start": "136160",
    "end": "137560"
  },
  {
    "text": "personalized to you uh and this is",
    "start": "137560",
    "end": "139640"
  },
  {
    "text": "really where contact retrieval comes in",
    "start": "139640",
    "end": "141599"
  },
  {
    "text": "we need to build a contact form that you",
    "start": "141599",
    "end": "144120"
  },
  {
    "text": "know is in line with our design system",
    "start": "144120",
    "end": "145840"
  },
  {
    "text": "components let's say you already have",
    "start": "145840",
    "end": "147040"
  },
  {
    "text": "buttons uh and inputs it has to be able",
    "start": "147040",
    "end": "149400"
  },
  {
    "text": "to uh pattern match with uh with local",
    "start": "149400",
    "end": "153120"
  },
  {
    "text": "um local instances of other forms inside",
    "start": "153120",
    "end": "155480"
  },
  {
    "text": "of your codebase it has to ingest your",
    "start": "155480",
    "end": "157319"
  },
  {
    "text": "style guide for example if you're using",
    "start": "157319",
    "end": "158800"
  },
  {
    "text": "Tailwind you have to be able to detect",
    "start": "158800",
    "end": "160800"
  },
  {
    "text": "and make the form look and feel like",
    "start": "160800",
    "end": "162519"
  },
  {
    "text": "every other thing on your site uh and",
    "start": "162519",
    "end": "164560"
  },
  {
    "text": "then of course there's documentation",
    "start": "164560",
    "end": "166080"
  },
  {
    "text": "both locally and externally um for",
    "start": "166080",
    "end": "168840"
  },
  {
    "text": "packages and other dependencies so the",
    "start": "168840",
    "end": "171200"
  },
  {
    "text": "question becomes how do you collect and",
    "start": "171200",
    "end": "173400"
  },
  {
    "text": "rank these items so that our code",
    "start": "173400",
    "end": "175239"
  },
  {
    "text": "generation can be both fast and accurate",
    "start": "175239",
    "end": "177560"
  },
  {
    "text": "for your use case so to dive into a",
    "start": "177560",
    "end": "180760"
  },
  {
    "text": "couple of different methods about how",
    "start": "180760",
    "end": "182040"
  },
  {
    "text": "people are tackling this today there's",
    "start": "182040",
    "end": "183760"
  },
  {
    "text": "really three main pillars the first one",
    "start": "183760",
    "end": "185760"
  },
  {
    "text": "is long context so this is the idea that",
    "start": "185760",
    "end": "188840"
  },
  {
    "text": "if you expand your prompt window in your",
    "start": "188840",
    "end": "190560"
  },
  {
    "text": "llm it can read more input and therefore",
    "start": "190560",
    "end": "193040"
  },
  {
    "text": "be a bit more personal to what you're",
    "start": "193040",
    "end": "194640"
  },
  {
    "text": "trying to put uh what you're trying to",
    "start": "194640",
    "end": "196000"
  },
  {
    "text": "generate this is very ergonomically easy",
    "start": "196000",
    "end": "197959"
  },
  {
    "text": "to use right you just shove more items",
    "start": "197959",
    "end": "199760"
  },
  {
    "text": "into your prompt but this comes at the",
    "start": "199760",
    "end": "201519"
  },
  {
    "text": "cost of latency uh latency and financial",
    "start": "201519",
    "end": "205159"
  },
  {
    "text": "cost so one of the most recent examples",
    "start": "205159",
    "end": "207519"
  },
  {
    "text": "was Gemini um Gemini actually takes 30 6",
    "start": "207519",
    "end": "210120"
  },
  {
    "text": "seconds to ingest",
    "start": "210120",
    "end": "211720"
  },
  {
    "text": "325k uh tokens to put this into",
    "start": "211720",
    "end": "214560"
  },
  {
    "text": "perspective a moderately sized or even",
    "start": "214560",
    "end": "217239"
  },
  {
    "text": "small repo is easily over 1 million",
    "start": "217239",
    "end": "219680"
  },
  {
    "text": "tokens uh and that accounts to about",
    "start": "219680",
    "end": "221560"
  },
  {
    "text": "100K lines of code so in this instance",
    "start": "221560",
    "end": "224400"
  },
  {
    "text": "most Enterprises have over a billion",
    "start": "224400",
    "end": "226159"
  },
  {
    "text": "tokens of code it's simply not feasible",
    "start": "226159",
    "end": "227959"
  },
  {
    "text": "to be throwing everything into a long",
    "start": "227959",
    "end": "229360"
  },
  {
    "text": "context model the second method is",
    "start": "229360",
    "end": "231840"
  },
  {
    "text": "fine-tuning so if for those that are",
    "start": "231840",
    "end": "233640"
  },
  {
    "text": "familiar fine tuning is the idea of",
    "start": "233640",
    "end": "235720"
  },
  {
    "text": "actually tweaking the weights of your",
    "start": "235720",
    "end": "237480"
  },
  {
    "text": "model to reflect the distribution of the",
    "start": "237480",
    "end": "239959"
  },
  {
    "text": "that your consumer expects right and so",
    "start": "239959",
    "end": "242159"
  },
  {
    "text": "this requires continuous updates it's",
    "start": "242159",
    "end": "244000"
  },
  {
    "text": "rather expensive computationally you",
    "start": "244000",
    "end": "245879"
  },
  {
    "text": "have to have one model per customer and",
    "start": "245879",
    "end": "247799"
  },
  {
    "text": "it's honestly prohibitively expensive",
    "start": "247799",
    "end": "249599"
  },
  {
    "text": "for most applications and finally we",
    "start": "249599",
    "end": "252079"
  },
  {
    "text": "have embeddings and for all of you",
    "start": "252079",
    "end": "253760"
  },
  {
    "text": "hopefully you're familiar this is a",
    "start": "253760",
    "end": "255200"
  },
  {
    "text": "relatively proven technology today um",
    "start": "255200",
    "end": "257519"
  },
  {
    "text": "it's pretty inexpensive to compute and",
    "start": "257519",
    "end": "259280"
  },
  {
    "text": "store uh but the difficulty that we're",
    "start": "259280",
    "end": "262199"
  },
  {
    "text": "about to dive into is that it is hard to",
    "start": "262199",
    "end": "264440"
  },
  {
    "text": "reason over multiple items it also has a",
    "start": "264440",
    "end": "266720"
  },
  {
    "text": "low dimensional space and I'll I'll talk",
    "start": "266720",
    "end": "268680"
  },
  {
    "text": "about that shortly",
    "start": "268680",
    "end": "270960"
  },
  {
    "text": "so to dive deeper into embeddings the",
    "start": "270960",
    "end": "272840"
  },
  {
    "text": "whole concept is that you take your",
    "start": "272840",
    "end": "274560"
  },
  {
    "text": "objects you throw it through an",
    "start": "274560",
    "end": "275919"
  },
  {
    "text": "embedding model and then you end up with",
    "start": "275919",
    "end": "277400"
  },
  {
    "text": "some sort of vector some sort of array",
    "start": "277400",
    "end": "279600"
  },
  {
    "text": "of numerical values and this is in a",
    "start": "279600",
    "end": "281840"
  },
  {
    "text": "fixed Dimension and so by mapping and",
    "start": "281840",
    "end": "284560"
  },
  {
    "text": "chunking code we can map it to an",
    "start": "284560",
    "end": "286800"
  },
  {
    "text": "embedding and that allows us to quickly",
    "start": "286800",
    "end": "288840"
  },
  {
    "text": "search over our functions our documents",
    "start": "288840",
    "end": "292080"
  },
  {
    "text": "whatever you decide to chunk by um and",
    "start": "292080",
    "end": "294280"
  },
  {
    "text": "this is what embedding search is",
    "start": "294280",
    "end": "296919"
  },
  {
    "text": "called uh embedding search like I said",
    "start": "296919",
    "end": "299199"
  },
  {
    "text": "is not a concept there is a bunch of",
    "start": "299199",
    "end": "301080"
  },
  {
    "text": "model models that I've tried to optimize",
    "start": "301080",
    "end": "302880"
  },
  {
    "text": "and in this example we're looking at one",
    "start": "302880",
    "end": "304720"
  },
  {
    "text": "of the kind of Northstar eval benchmarks",
    "start": "304720",
    "end": "307560"
  },
  {
    "text": "um it's become increasingly popular and",
    "start": "307560",
    "end": "309960"
  },
  {
    "text": "the question becomes how do we fit",
    "start": "309960",
    "end": "311720"
  },
  {
    "text": "millions of lines of code into an llm",
    "start": "311720",
    "end": "314120"
  },
  {
    "text": "model so that we can actually generate",
    "start": "314120",
    "end": "315400"
  },
  {
    "text": "useful results and so it's evident",
    "start": "315400",
    "end": "317800"
  },
  {
    "text": "through the years that we're actually",
    "start": "317800",
    "end": "318880"
  },
  {
    "text": "hitting a ceiling on what is possible",
    "start": "318880",
    "end": "320440"
  },
  {
    "text": "using these traditional uh vector",
    "start": "320440",
    "end": "322280"
  },
  {
    "text": "embeddings and over time even the",
    "start": "322280",
    "end": "324520"
  },
  {
    "text": "biggest models uh are approximating to",
    "start": "324520",
    "end": "326800"
  },
  {
    "text": "around the same level of performance as",
    "start": "326800",
    "end": "328840"
  },
  {
    "text": "you can see everything's kind of within",
    "start": "328840",
    "end": "330520"
  },
  {
    "text": "plus or minus 5 and at codium we kind of",
    "start": "330520",
    "end": "333520"
  },
  {
    "text": "believe that this is because",
    "start": "333520",
    "end": "334440"
  },
  {
    "text": "fundamentally we cannot distill all the",
    "start": "334440",
    "end": "336520"
  },
  {
    "text": "the dimension space of all possible",
    "start": "336520",
    "end": "338360"
  },
  {
    "text": "questions all possible English queries",
    "start": "338360",
    "end": "341319"
  },
  {
    "text": "down into the embedding Dimension space",
    "start": "341319",
    "end": "343919"
  },
  {
    "text": "uh that our vectors are going to",
    "start": "343919",
    "end": "346000"
  },
  {
    "text": "occupy and so at codium we've thought",
    "start": "346000",
    "end": "348080"
  },
  {
    "text": "very critically about what retrieval",
    "start": "348080",
    "end": "350280"
  },
  {
    "text": "matters to us are we measuring the right",
    "start": "350280",
    "end": "352520"
  },
  {
    "text": "things and does semantic distance",
    "start": "352520",
    "end": "354600"
  },
  {
    "text": "between these vectors really equate to",
    "start": "354600",
    "end": "356840"
  },
  {
    "text": "things like function relevance in the",
    "start": "356840",
    "end": "358479"
  },
  {
    "text": "concrete example that I showed",
    "start": "358479",
    "end": "360919"
  },
  {
    "text": "earlier and so what we landed on is that",
    "start": "360919",
    "end": "364000"
  },
  {
    "text": "benchmarks like the one that I showed",
    "start": "364000",
    "end": "365880"
  },
  {
    "text": "you before heavily skewed towards this",
    "start": "365880",
    "end": "368039"
  },
  {
    "text": "idea of needle and a Hy stack it's the",
    "start": "368039",
    "end": "370240"
  },
  {
    "text": "idea that you can sift through a corpus",
    "start": "370240",
    "end": "371919"
  },
  {
    "text": "of text and find some instance of",
    "start": "371919",
    "end": "375039"
  },
  {
    "text": "something that is relevant to you note",
    "start": "375039",
    "end": "377120"
  },
  {
    "text": "it is only one single needle so in",
    "start": "377120",
    "end": "379520"
  },
  {
    "text": "reality code search requires multiple",
    "start": "379520",
    "end": "381120"
  },
  {
    "text": "different needles right we showed that",
    "start": "381120",
    "end": "382360"
  },
  {
    "text": "slide earlier when you're building a",
    "start": "382360",
    "end": "383599"
  },
  {
    "text": "contact form you need all these",
    "start": "383599",
    "end": "384880"
  },
  {
    "text": "different things in order to actually",
    "start": "384880",
    "end": "386160"
  },
  {
    "text": "have a good generation and these",
    "start": "386160",
    "end": "388520"
  },
  {
    "text": "benchmarks really don't touch that and",
    "start": "388520",
    "end": "390199"
  },
  {
    "text": "so we decided to use a different metric",
    "start": "390199",
    "end": "392080"
  },
  {
    "text": "and it's called recall 50 the idea and",
    "start": "392080",
    "end": "395000"
  },
  {
    "text": "its definition is that um it's what",
    "start": "395000",
    "end": "397160"
  },
  {
    "text": "fraction of your ground truth is in the",
    "start": "397160",
    "end": "399240"
  },
  {
    "text": "top 50 items retrieved so the idea being",
    "start": "399240",
    "end": "401639"
  },
  {
    "text": "now we have multiple documents and we're",
    "start": "401639",
    "end": "403400"
  },
  {
    "text": "now looking at the top 50 documents that",
    "start": "403400",
    "end": "405440"
  },
  {
    "text": "we retrieved how many of those are part",
    "start": "405440",
    "end": "407199"
  },
  {
    "text": "of our ground truth set so this is",
    "start": "407199",
    "end": "409120"
  },
  {
    "text": "really helpful for understanding",
    "start": "409120",
    "end": "410639"
  },
  {
    "text": "document multi-document context",
    "start": "410639",
    "end": "413039"
  },
  {
    "text": "especially again for those large large",
    "start": "413039",
    "end": "414800"
  },
  {
    "text": "Co",
    "start": "414800",
    "end": "416000"
  },
  {
    "text": "bases and now we actually have to build",
    "start": "416000",
    "end": "418240"
  },
  {
    "text": "a data set around this and so so this is",
    "start": "418240",
    "end": "419919"
  },
  {
    "text": "where we did a little bit little bit of",
    "start": "419919",
    "end": "421759"
  },
  {
    "text": "magic we wanted to make the eval as",
    "start": "421759",
    "end": "423680"
  },
  {
    "text": "close as possible to our end user",
    "start": "423680",
    "end": "425400"
  },
  {
    "text": "distribution so we had to compile our",
    "start": "425400",
    "end": "427319"
  },
  {
    "text": "own data set so what we did this is a PR",
    "start": "427319",
    "end": "429960"
  },
  {
    "text": "that I put out um a few months ago we",
    "start": "429960",
    "end": "432440"
  },
  {
    "text": "looked at PRS like this it's broken down",
    "start": "432440",
    "end": "434560"
  },
  {
    "text": "into commits those commits we can",
    "start": "434560",
    "end": "437080"
  },
  {
    "text": "extract and actually match them with the",
    "start": "437080",
    "end": "438879"
  },
  {
    "text": "modified files right so now we have this",
    "start": "438879",
    "end": "440960"
  },
  {
    "text": "mapping from something in English to a",
    "start": "440960",
    "end": "444720"
  },
  {
    "text": "list of files that are relevant to that",
    "start": "444720",
    "end": "446240"
  },
  {
    "text": "change and you can imagine we can hash",
    "start": "446240",
    "end": "447960"
  },
  {
    "text": "this in many different ways but ultim",
    "start": "447960",
    "end": "449479"
  },
  {
    "text": "ultimately the point I'm trying to make",
    "start": "449479",
    "end": "451080"
  },
  {
    "text": "is we are creating a eval set that",
    "start": "451080",
    "end": "453560"
  },
  {
    "text": "mimics our production usage of something",
    "start": "453560",
    "end": "456160"
  },
  {
    "text": "like a code gen",
    "start": "456160",
    "end": "458520"
  },
  {
    "text": "product and so this message serves as",
    "start": "458520",
    "end": "460800"
  },
  {
    "text": "the backing for this new type of eval",
    "start": "460800",
    "end": "463319"
  },
  {
    "text": "where now we can run at scale this idea",
    "start": "463319",
    "end": "465720"
  },
  {
    "text": "of product-led benchmarks it gets us",
    "start": "465720",
    "end": "467960"
  },
  {
    "text": "closer to the ground truth of what our",
    "start": "467960",
    "end": "469680"
  },
  {
    "text": "users are actually experiencing and what",
    "start": "469680",
    "end": "471840"
  },
  {
    "text": "retrieval tweaks and retrieval actually",
    "start": "471840",
    "end": "474080"
  },
  {
    "text": "mean to the end",
    "start": "474080",
    "end": "476240"
  },
  {
    "text": "product and so we threw some of the uh",
    "start": "476240",
    "end": "478840"
  },
  {
    "text": "currently public available models at",
    "start": "478840",
    "end": "481440"
  },
  {
    "text": "this notion of retrieval this idea of",
    "start": "481440",
    "end": "483960"
  },
  {
    "text": "using commit messages and we found that",
    "start": "483960",
    "end": "486199"
  },
  {
    "text": "there is reduced performance um they're",
    "start": "486199",
    "end": "488639"
  },
  {
    "text": "unable to reason over specifically code",
    "start": "488639",
    "end": "491440"
  },
  {
    "text": "but then also specifically this kind of",
    "start": "491440",
    "end": "492840"
  },
  {
    "text": "real world notion of of English and and",
    "start": "492840",
    "end": "496159"
  },
  {
    "text": "commits right and so at codium we've",
    "start": "496159",
    "end": "499159"
  },
  {
    "text": "been able to actually break through this",
    "start": "499159",
    "end": "500599"
  },
  {
    "text": "ceiling this is something that we've",
    "start": "500599",
    "end": "502280"
  },
  {
    "text": "worked very hard at we have to to to",
    "start": "502280",
    "end": "504800"
  },
  {
    "text": "redefine exactly how we are approaching",
    "start": "504800",
    "end": "507000"
  },
  {
    "text": "retrieval in order to be kind of in our",
    "start": "507000",
    "end": "508960"
  },
  {
    "text": "class of our own so that when you are",
    "start": "508960",
    "end": "510720"
  },
  {
    "text": "typing in your ID when you're chatting",
    "start": "510720",
    "end": "512279"
  },
  {
    "text": "with our assistant when you're",
    "start": "512279",
    "end": "513479"
  },
  {
    "text": "generating autocompletes we're",
    "start": "513479",
    "end": "515120"
  },
  {
    "text": "retrieving the most relevant things that",
    "start": "515120",
    "end": "517320"
  },
  {
    "text": "are are for your your intents so now the",
    "start": "517320",
    "end": "520159"
  },
  {
    "text": "question becomes how do we actually get",
    "start": "520159",
    "end": "522399"
  },
  {
    "text": "this kind of best-in-class",
    "start": "522399",
    "end": "523919"
  },
  {
    "text": "retrieval and so I'm here to give you",
    "start": "523920",
    "end": "525760"
  },
  {
    "text": "the very short and sweet answer which is",
    "start": "525760",
    "end": "527920"
  },
  {
    "text": "we throw more compute at it right but of",
    "start": "527920",
    "end": "530360"
  },
  {
    "text": "course that can't come with uh absurd",
    "start": "530360",
    "end": "533720"
  },
  {
    "text": "absurd uh uh cost right Financial cost",
    "start": "533720",
    "end": "536959"
  },
  {
    "text": "uh so how do we do this actually in in",
    "start": "536959",
    "end": "539040"
  },
  {
    "text": "production how do we actually do this",
    "start": "539040",
    "end": "540640"
  },
  {
    "text": "without recurring an unreasonable cost",
    "start": "540640",
    "end": "543480"
  },
  {
    "text": "and so this goes back to a little bit of",
    "start": "543480",
    "end": "545240"
  },
  {
    "text": "codium secret sauce right we are",
    "start": "545240",
    "end": "546920"
  },
  {
    "text": "vertically integrated and what this",
    "start": "546920",
    "end": "548600"
  },
  {
    "text": "means is that we train our own models so",
    "start": "548600",
    "end": "551399"
  },
  {
    "text": "number one we train our own models this",
    "start": "551399",
    "end": "553000"
  },
  {
    "text": "means that these are customed to our own",
    "start": "553000",
    "end": "554640"
  },
  {
    "text": "workflows so when you're using our",
    "start": "554640",
    "end": "555959"
  },
  {
    "text": "product you're touching codium models",
    "start": "555959",
    "end": "558480"
  },
  {
    "text": "number two we build our own custom",
    "start": "558480",
    "end": "560240"
  },
  {
    "text": "infrastructure this is actually a very",
    "start": "560240",
    "end": "561920"
  },
  {
    "text": "important point and actually connects to",
    "start": "561920",
    "end": "563640"
  },
  {
    "text": "the whole EXA function to codium Pivot",
    "start": "563640",
    "end": "565560"
  },
  {
    "text": "that we discussed earlier EXA function",
    "start": "565560",
    "end": "566920"
  },
  {
    "text": "was a ml infrastructure uh company and",
    "start": "566920",
    "end": "569800"
  },
  {
    "text": "so what we've been able to do is build",
    "start": "569800",
    "end": "571959"
  },
  {
    "text": "our own custom infrastructure down to",
    "start": "571959",
    "end": "573399"
  },
  {
    "text": "the metal this means that our speed and",
    "start": "573399",
    "end": "575279"
  },
  {
    "text": "efficiency is unmatched by any other",
    "start": "575279",
    "end": "577040"
  },
  {
    "text": "competitor on the market so that we can",
    "start": "577040",
    "end": "578640"
  },
  {
    "text": "serve more completions at a cheaper cost",
    "start": "578640",
    "end": "581279"
  },
  {
    "text": "and finally we are product driven not",
    "start": "581279",
    "end": "583519"
  },
  {
    "text": "research driven now what this means is",
    "start": "583519",
    "end": "586240"
  },
  {
    "text": "we look at things like actual end user",
    "start": "586240",
    "end": "588720"
  },
  {
    "text": "results when we actually ship a feature",
    "start": "588720",
    "end": "590680"
  },
  {
    "text": "we're looking at real world usage and",
    "start": "590680",
    "end": "592720"
  },
  {
    "text": "we're always thinking about how does",
    "start": "592720",
    "end": "593920"
  },
  {
    "text": "this impact the end user experience not",
    "start": "593920",
    "end": "595959"
  },
  {
    "text": "just some local Benchmark tweaking and",
    "start": "595959",
    "end": "598240"
  },
  {
    "text": "so we could spend all day talking about",
    "start": "598240",
    "end": "600240"
  },
  {
    "text": "you know kind of why codium has done",
    "start": "600240",
    "end": "602040"
  },
  {
    "text": "this and yada yada but that's a talk for",
    "start": "602040",
    "end": "603640"
  },
  {
    "text": "a different time so I'm going to talk",
    "start": "603640",
    "end": "605839"
  },
  {
    "text": "about something that I find very cool",
    "start": "605839",
    "end": "607600"
  },
  {
    "text": "and this is the reason why we've taken",
    "start": "607600",
    "end": "609480"
  },
  {
    "text": "this vertical integration approach and",
    "start": "609480",
    "end": "611240"
  },
  {
    "text": "been able to turn it into something that",
    "start": "611240",
    "end": "613040"
  },
  {
    "text": "we call M",
    "start": "613040",
    "end": "614360"
  },
  {
    "text": "query so M query is this way of taking",
    "start": "614360",
    "end": "617519"
  },
  {
    "text": "your query so similar it's that idea of",
    "start": "617519",
    "end": "619920"
  },
  {
    "text": "taking your retrieval query you have",
    "start": "619920",
    "end": "622680"
  },
  {
    "text": "your code base and let's just say you",
    "start": "622680",
    "end": "624399"
  },
  {
    "text": "have n different items and because we",
    "start": "624399",
    "end": "626640"
  },
  {
    "text": "own our own infrastructure and train our",
    "start": "626640",
    "end": "628040"
  },
  {
    "text": "own models we're now making parallel",
    "start": "628040",
    "end": "629959"
  },
  {
    "text": "calls to an llm to actually reason over",
    "start": "629959",
    "end": "632680"
  },
  {
    "text": "each one of those items we're not",
    "start": "632680",
    "end": "634320"
  },
  {
    "text": "looking at uh vectors we're not looking",
    "start": "634320",
    "end": "636240"
  },
  {
    "text": "at small Dimension space we're literally",
    "start": "636240",
    "end": "638720"
  },
  {
    "text": "taking models and running them on each",
    "start": "638720",
    "end": "641120"
  },
  {
    "text": "one of those items so that you can",
    "start": "641120",
    "end": "642680"
  },
  {
    "text": "ensure you can imagine you know you run",
    "start": "642680",
    "end": "644600"
  },
  {
    "text": "chat GPT and tell it to say yes or no on",
    "start": "644600",
    "end": "646839"
  },
  {
    "text": "on an item for example that is going to",
    "start": "646839",
    "end": "648480"
  },
  {
    "text": "give you the highest quality highest",
    "start": "648480",
    "end": "649959"
  },
  {
    "text": "Dimension space of reasoning this leads",
    "start": "649959",
    "end": "652480"
  },
  {
    "text": "into very very high confidence ranking",
    "start": "652480",
    "end": "655519"
  },
  {
    "text": "that we can then take into account",
    "start": "655519",
    "end": "656760"
  },
  {
    "text": "things like your active files your",
    "start": "656760",
    "end": "658480"
  },
  {
    "text": "neighboring director",
    "start": "658480",
    "end": "659959"
  },
  {
    "text": "your most recent commits um you know",
    "start": "659959",
    "end": "662959"
  },
  {
    "text": "what what is the ticket that you're",
    "start": "662959",
    "end": "664079"
  },
  {
    "text": "working on currently we can compile all",
    "start": "664079",
    "end": "666160"
  },
  {
    "text": "this to give you you know the",
    "start": "666160",
    "end": "668720"
  },
  {
    "text": "topend uh documents that are relevant",
    "start": "668720",
    "end": "670880"
  },
  {
    "text": "for your generation so that we can start",
    "start": "670880",
    "end": "672240"
  },
  {
    "text": "streaming in higher quality Generations",
    "start": "672240",
    "end": "674720"
  },
  {
    "text": "higher quality chat messages uh things",
    "start": "674720",
    "end": "676720"
  },
  {
    "text": "of that nature",
    "start": "676720",
    "end": "679160"
  },
  {
    "text": "and the reason behind this is again it's",
    "start": "679160",
    "end": "681839"
  },
  {
    "text": "that vertical integration it's that idea",
    "start": "681839",
    "end": "683600"
  },
  {
    "text": "that our computation is one 100th of the",
    "start": "683600",
    "end": "686600"
  },
  {
    "text": "cost of the competitors we are not using",
    "start": "686600",
    "end": "688360"
  },
  {
    "text": "apis and as a result our customers and",
    "start": "688360",
    "end": "691800"
  },
  {
    "text": "our users actually get 100x the amount",
    "start": "691800",
    "end": "693920"
  },
  {
    "text": "of compute that they would on another",
    "start": "693920",
    "end": "695519"
  },
  {
    "text": "product and so we're willing to do that",
    "start": "695519",
    "end": "697200"
  },
  {
    "text": "we're willing to spend more compute per",
    "start": "697200",
    "end": "698920"
  },
  {
    "text": "user because it leads to a better",
    "start": "698920",
    "end": "702320"
  },
  {
    "text": "experience and so like I mentioned",
    "start": "702320",
    "end": "704519"
  },
  {
    "text": "earlier I lead our product engineering",
    "start": "704519",
    "end": "706160"
  },
  {
    "text": "team so we always want to Anchor",
    "start": "706160",
    "end": "707600"
  },
  {
    "text": "ourselves around these three different",
    "start": "707600",
    "end": "709040"
  },
  {
    "text": "things one that we have to build a",
    "start": "709040",
    "end": "711240"
  },
  {
    "text": "performant product it has to be really",
    "start": "711240",
    "end": "713320"
  },
  {
    "text": "fast for those of you that have used the",
    "start": "713320",
    "end": "714920"
  },
  {
    "text": "product you can probably attest this m",
    "start": "714920",
    "end": "716959"
  },
  {
    "text": "query runs thousands of llms in parall",
    "start": "716959",
    "end": "719760"
  },
  {
    "text": "so that the user can start streaming in",
    "start": "719760",
    "end": "721360"
  },
  {
    "text": "code within seconds not minutes not",
    "start": "721360",
    "end": "723519"
  },
  {
    "text": "hours seconds and often times",
    "start": "723519",
    "end": "725920"
  },
  {
    "text": "milliseconds it has to be powerful right",
    "start": "725920",
    "end": "728279"
  },
  {
    "text": "none of this matters if the actual",
    "start": "728279",
    "end": "729760"
  },
  {
    "text": "quality and the actual Generations that",
    "start": "729760",
    "end": "731279"
  },
  {
    "text": "you're building are wrong right and",
    "start": "731279",
    "end": "734600"
  },
  {
    "text": "finally it has to be easy to use we're",
    "start": "734600",
    "end": "736600"
  },
  {
    "text": "building an enduser product for people",
    "start": "736600",
    "end": "739000"
  },
  {
    "text": "today that's in the IDE tomorrow it",
    "start": "739000",
    "end": "740800"
  },
  {
    "text": "might not be in the IDE how do we",
    "start": "740800",
    "end": "742560"
  },
  {
    "text": "actually build something that is",
    "start": "742560",
    "end": "743519"
  },
  {
    "text": "intuitive to understand that people can",
    "start": "743519",
    "end": "745600"
  },
  {
    "text": "grapple with and see exactly what my",
    "start": "745600",
    "end": "747680"
  },
  {
    "text": "model is thinking",
    "start": "747680",
    "end": "750480"
  },
  {
    "text": "and so because we have the benefit of",
    "start": "750480",
    "end": "752959"
  },
  {
    "text": "distribution uh we were able to roll",
    "start": "752959",
    "end": "754839"
  },
  {
    "text": "this out to a small percentage of our",
    "start": "754839",
    "end": "756079"
  },
  {
    "text": "users and by small percentage we're",
    "start": "756079",
    "end": "757920"
  },
  {
    "text": "dealing in the order of you know million",
    "start": "757920",
    "end": "759560"
  },
  {
    "text": "plus downloads this actually reached the",
    "start": "759560",
    "end": "761199"
  },
  {
    "text": "surprising number of people and what",
    "start": "761199",
    "end": "763000"
  },
  {
    "text": "we've been able to see is that um we",
    "start": "763000",
    "end": "766160"
  },
  {
    "text": "were able to successfully reason over",
    "start": "766160",
    "end": "768000"
  },
  {
    "text": "these thousands of files in people's",
    "start": "768000",
    "end": "769440"
  },
  {
    "text": "monor repos and people's remote repos",
    "start": "769440",
    "end": "771760"
  },
  {
    "text": "and select what was relevant right we",
    "start": "771760",
    "end": "773959"
  },
  {
    "text": "can very accurately deem which files are",
    "start": "773959",
    "end": "777079"
  },
  {
    "text": "relevant for the generation that you're",
    "start": "777079",
    "end": "778360"
  },
  {
    "text": "trying to have and the result as you can",
    "start": "778360",
    "end": "780560"
  },
  {
    "text": "see this is a real-time GIF is both fast",
    "start": "780560",
    "end": "783360"
  },
  {
    "text": "and accurate so I'm asking for usage of",
    "start": "783360",
    "end": "785440"
  },
  {
    "text": "an alert dialogue it's going through and",
    "start": "785440",
    "end": "788040"
  },
  {
    "text": "I think I panned down here um this is",
    "start": "788040",
    "end": "790440"
  },
  {
    "text": "kind of a Shad CN component that I've",
    "start": "790440",
    "end": "792199"
  },
  {
    "text": "modified internally we're we're pulling",
    "start": "792199",
    "end": "794360"
  },
  {
    "text": "in basically the source code of of what",
    "start": "794360",
    "end": "796639"
  },
  {
    "text": "is relevant for Our Generation Um and",
    "start": "796639",
    "end": "799399"
  },
  {
    "text": "ultimately the results of this",
    "start": "799399",
    "end": "801120"
  },
  {
    "text": "experiment with that users were happy",
    "start": "801120",
    "end": "803240"
  },
  {
    "text": "they were thumbs they had more thumbs up",
    "start": "803240",
    "end": "805000"
  },
  {
    "text": "on chat messages they were accepting",
    "start": "805000",
    "end": "806920"
  },
  {
    "text": "more generations and we were able to see",
    "start": "806920",
    "end": "808519"
  },
  {
    "text": "that ultimately we were writing more",
    "start": "808519",
    "end": "810399"
  },
  {
    "text": "code for the user which is the ultimate",
    "start": "810399",
    "end": "812120"
  },
  {
    "text": "goal it's that idea of how much value",
    "start": "812120",
    "end": "814839"
  },
  {
    "text": "are we providing to our end",
    "start": "814839",
    "end": "817160"
  },
  {
    "text": "users and so we built this this context",
    "start": "817160",
    "end": "819880"
  },
  {
    "text": "engine right this this idea of M query",
    "start": "819880",
    "end": "822160"
  },
  {
    "text": "this idea of ingesting context and",
    "start": "822160",
    "end": "824120"
  },
  {
    "text": "deciding what is relevant to your query",
    "start": "824120",
    "end": "826279"
  },
  {
    "text": "to give you coding superpowers and so",
    "start": "826279",
    "end": "828519"
  },
  {
    "text": "our users will generate today they're",
    "start": "828519",
    "end": "830160"
  },
  {
    "text": "generating Auto completes they're",
    "start": "830160",
    "end": "831480"
  },
  {
    "text": "generating chats search messages but in",
    "start": "831480",
    "end": "833680"
  },
  {
    "text": "the future they're going to generate",
    "start": "833680",
    "end": "834759"
  },
  {
    "text": "documentation they're going to generate",
    "start": "834759",
    "end": "836399"
  },
  {
    "text": "commit messages code reviews uh code",
    "start": "836399",
    "end": "839120"
  },
  {
    "text": "scanning they're going to take you know",
    "start": "839120",
    "end": "840839"
  },
  {
    "text": "figma artboards and convert them into",
    "start": "840839",
    "end": "842880"
  },
  {
    "text": "comp uh into uis that were built by your",
    "start": "842880",
    "end": "844759"
  },
  {
    "text": "own components the possibilities are",
    "start": "844759",
    "end": "846440"
  },
  {
    "text": "endless but what it starts with is this",
    "start": "846440",
    "end": "848720"
  },
  {
    "text": "Bedrock this very hard problem of",
    "start": "848720",
    "end": "852079"
  },
  {
    "text": "retrieval and it brings us to again one",
    "start": "852079",
    "end": "855120"
  },
  {
    "text": "of the reasons why codium is approaching",
    "start": "855120",
    "end": "856959"
  },
  {
    "text": "this problem a little bit differently",
    "start": "856959",
    "end": "858720"
  },
  {
    "text": "our itation cycle starts with product",
    "start": "858720",
    "end": "860759"
  },
  {
    "text": "driven data and eval so we're starting",
    "start": "860759",
    "end": "863440"
  },
  {
    "text": "with the end problem we're building a",
    "start": "863440",
    "end": "865120"
  },
  {
    "text": "product for millions of people how do we",
    "start": "865120",
    "end": "867519"
  },
  {
    "text": "start with what they're asking for and",
    "start": "867519",
    "end": "869120"
  },
  {
    "text": "how do we build a data set and eval",
    "start": "869120",
    "end": "870639"
  },
  {
    "text": "system locally so that we could iterate",
    "start": "870639",
    "end": "872959"
  },
  {
    "text": "on the metrics that matter secondly",
    "start": "872959",
    "end": "875759"
  },
  {
    "text": "because we're vertically integrated",
    "start": "875759",
    "end": "877199"
  },
  {
    "text": "we're taking that massive amount of",
    "start": "877199",
    "end": "878800"
  },
  {
    "text": "compute and we're going to throw it at",
    "start": "878800",
    "end": "880320"
  },
  {
    "text": "our users you know paying or not paying",
    "start": "880320",
    "end": "883000"
  },
  {
    "text": "we're going to throw it at our users so",
    "start": "883000",
    "end": "884759"
  },
  {
    "text": "that they can get the best product",
    "start": "884759",
    "end": "886040"
  },
  {
    "text": "experience and the highest quality",
    "start": "886040",
    "end": "887480"
  },
  {
    "text": "results and then finally we're actually",
    "start": "887480",
    "end": "889360"
  },
  {
    "text": "going to be able to push this out to our",
    "start": "889360",
    "end": "891160"
  },
  {
    "text": "users in real time overnight and be able",
    "start": "891160",
    "end": "894240"
  },
  {
    "text": "to get a pulse check on how this is",
    "start": "894240",
    "end": "896240"
  },
  {
    "text": "going you know this is what we did for",
    "start": "896240",
    "end": "897880"
  },
  {
    "text": "for M query and when we evaluate in",
    "start": "897880",
    "end": "900279"
  },
  {
    "text": "production we can say you know thumbs up",
    "start": "900279",
    "end": "902240"
  },
  {
    "text": "thumbs down and then hit the drawing",
    "start": "902240",
    "end": "904480"
  },
  {
    "text": "board again back to that same cycle",
    "start": "904480",
    "end": "907720"
  },
  {
    "text": "repetition and so you can start seeing",
    "start": "907720",
    "end": "909680"
  },
  {
    "text": "how these pieces of compounding",
    "start": "909680",
    "end": "910920"
  },
  {
    "text": "technology come together right we've",
    "start": "910920",
    "end": "912440"
  },
  {
    "text": "alluded to some of them today modeling",
    "start": "912440",
    "end": "915639"
  },
  {
    "text": "infrastructure being able to retrieve",
    "start": "915639",
    "end": "918560"
  },
  {
    "text": "but then it also includes things like as",
    "start": "918560",
    "end": "920759"
  },
  {
    "text": "parsing indexing massive amounts of",
    "start": "920759",
    "end": "923000"
  },
  {
    "text": "repos knowledge graphs parsing",
    "start": "923000",
    "end": "925360"
  },
  {
    "text": "documentation looking at websites online",
    "start": "925360",
    "end": "927839"
  },
  {
    "text": "the list can go on and on and on but",
    "start": "927839",
    "end": "930399"
  },
  {
    "text": "we're confident that we're solving these",
    "start": "930399",
    "end": "932199"
  },
  {
    "text": "problems one piece at a time using that",
    "start": "932199",
    "end": "934440"
  },
  {
    "text": "same iteration cycle that same idea that",
    "start": "934440",
    "end": "936959"
  },
  {
    "text": "we're going to take the the distribution",
    "start": "936959",
    "end": "939279"
  },
  {
    "text": "and knowledge that we have and that",
    "start": "939279",
    "end": "940959"
  },
  {
    "text": "additional compute that we're willing to",
    "start": "940959",
    "end": "942399"
  },
  {
    "text": "afford each user to solve each one of",
    "start": "942399",
    "end": "944279"
  },
  {
    "text": "these puzzle pieces and um I want to",
    "start": "944279",
    "end": "948240"
  },
  {
    "text": "leave you with uh a parallel analogy so",
    "start": "948240",
    "end": "951600"
  },
  {
    "text": "in my past life I had experience in the",
    "start": "951600",
    "end": "953720"
  },
  {
    "text": "autonomous driving industry so to bring",
    "start": "953720",
    "end": "955839"
  },
  {
    "text": "over a metaphor from that industry in",
    "start": "955839",
    "end": "957880"
  },
  {
    "text": "2015 Tech crunch boldly predicted that",
    "start": "957880",
    "end": "960319"
  },
  {
    "text": "that was going to be the year of the",
    "start": "960319",
    "end": "961800"
  },
  {
    "text": "self-driving vehicle uh it was largely",
    "start": "961800",
    "end": "966240"
  },
  {
    "text": "uh you know now we're in 2024 so we can",
    "start": "966240",
    "end": "967800"
  },
  {
    "text": "look back in hindsight largely untrue",
    "start": "967800",
    "end": "970240"
  },
  {
    "text": "right we were doing things like Sensor",
    "start": "970240",
    "end": "972000"
  },
  {
    "text": "Fusion we were decreasing our polling",
    "start": "972000",
    "end": "974079"
  },
  {
    "text": "rates we were running offboard models",
    "start": "974079",
    "end": "976199"
  },
  {
    "text": "all this in the effort of making heris",
    "start": "976199",
    "end": "978959"
  },
  {
    "text": "that would compensate for the lack of",
    "start": "978959",
    "end": "980199"
  },
  {
    "text": "compute that was available because",
    "start": "980199",
    "end": "982279"
  },
  {
    "text": "consumer graphics cards were not as",
    "start": "982279",
    "end": "983720"
  },
  {
    "text": "popular or not as uh powerful as they",
    "start": "983720",
    "end": "985519"
  },
  {
    "text": "are today fast forward today we're",
    "start": "985519",
    "end": "987399"
  },
  {
    "text": "seeing 100x the amount amount of compute",
    "start": "987399",
    "end": "989440"
  },
  {
    "text": "available to a vehicle you can take a wh",
    "start": "989440",
    "end": "991600"
  },
  {
    "text": "around San Francisco which I encourage",
    "start": "991600",
    "end": "992959"
  },
  {
    "text": "you to do it's a wonderful experience um",
    "start": "992959",
    "end": "995839"
  },
  {
    "text": "but that means that we're actually able",
    "start": "995839",
    "end": "996920"
  },
  {
    "text": "to throw larger models at these problems",
    "start": "996920",
    "end": "999279"
  },
  {
    "text": "right more sensors higher frequency and",
    "start": "999279",
    "end": "1002160"
  },
  {
    "text": "now 2024 Tech crunch has released",
    "start": "1002160",
    "end": "1004040"
  },
  {
    "text": "another article that said will 2024",
    "start": "1004040",
    "end": "1005839"
  },
  {
    "text": "finally be the year of the self-driving",
    "start": "1005839",
    "end": "1007279"
  },
  {
    "text": "vehicle and we can now look at this",
    "start": "1007279",
    "end": "1009560"
  },
  {
    "text": "pattern and say driving performance was",
    "start": "1009560",
    "end": "1012639"
  },
  {
    "text": "substantially better by throwing larger",
    "start": "1012639",
    "end": "1014880"
  },
  {
    "text": "models being able to handle more and",
    "start": "1014880",
    "end": "1017120"
  },
  {
    "text": "more data",
    "start": "1017120",
    "end": "1018959"
  },
  {
    "text": "and so at codium we believe that this",
    "start": "1018959",
    "end": "1021360"
  },
  {
    "text": "embedding based retrieval is the",
    "start": "1021360",
    "end": "1023280"
  },
  {
    "text": "heuristic we should be planning for AI",
    "start": "1023280",
    "end": "1026160"
  },
  {
    "text": "first products throwing large models at",
    "start": "1026160",
    "end": "1029160"
  },
  {
    "text": "these at these problems so that AI is a",
    "start": "1029160",
    "end": "1031558"
  },
  {
    "text": "first class citizen we're planning for",
    "start": "1031559",
    "end": "1033438"
  },
  {
    "text": "the future and finally we also believe",
    "start": "1033439",
    "end": "1035600"
  },
  {
    "text": "that ideas are cheap you know I could",
    "start": "1035600",
    "end": "1037199"
  },
  {
    "text": "sit up here and tell you all these",
    "start": "1037199",
    "end": "1038520"
  },
  {
    "text": "different ideas about how you know we're",
    "start": "1038520",
    "end": "1040720"
  },
  {
    "text": "going to transform coding and the way",
    "start": "1040720",
    "end": "1042600"
  },
  {
    "text": "that the the the the theory behind uh",
    "start": "1042600",
    "end": "1045520"
  },
  {
    "text": "possible solutions but what we believe",
    "start": "1045520",
    "end": "1047240"
  },
  {
    "text": "at codium is that actually shipping",
    "start": "1047240",
    "end": "1049200"
  },
  {
    "text": "actually showcasing this technology",
    "start": "1049200",
    "end": "1051200"
  },
  {
    "text": "through a product is the best way to go",
    "start": "1051200",
    "end": "1054679"
  },
  {
    "text": "and so if you agree with these beliefs",
    "start": "1054679",
    "end": "1056559"
  },
  {
    "text": "you can come join our team we're based",
    "start": "1056559",
    "end": "1058360"
  },
  {
    "text": "in San Francisco and you can download",
    "start": "1058360",
    "end": "1060600"
  },
  {
    "text": "our extension it's free I'm not",
    "start": "1060600",
    "end": "1063160"
  },
  {
    "text": "obviously uh uh what's it called I'm not",
    "start": "1063160",
    "end": "1065520"
  },
  {
    "text": "advertising uh the core product nearly",
    "start": "1065520",
    "end": "1067440"
  },
  {
    "text": "as much we're kind of talking about the",
    "start": "1067440",
    "end": "1068480"
  },
  {
    "text": "technology but you can experience this",
    "start": "1068480",
    "end": "1069919"
  },
  {
    "text": "technology firsthand today by",
    "start": "1069919",
    "end": "1071799"
  },
  {
    "text": "downloading our extension it's available",
    "start": "1071799",
    "end": "1073520"
  },
  {
    "text": "on all the different plugins uh VSS code",
    "start": "1073520",
    "end": "1076559"
  },
  {
    "text": "jetbrains Vim emacs uh and you can see",
    "start": "1076559",
    "end": "1079640"
  },
  {
    "text": "how this infrastructure and the way that",
    "start": "1079640",
    "end": "1081200"
  },
  {
    "text": "we've approached product development has",
    "start": "1081200",
    "end": "1083559"
  },
  {
    "text": "shaped the experience for you as a user",
    "start": "1083559",
    "end": "1086039"
  },
  {
    "text": "and then of course you can reach out to",
    "start": "1086039",
    "end": "1087559"
  },
  {
    "text": "me on Twitter uh I put my handle up",
    "start": "1087559",
    "end": "1089559"
  },
  {
    "text": "there I'll be kind of floating around",
    "start": "1089559",
    "end": "1091520"
  },
  {
    "text": "outside so if you have other questions",
    "start": "1091520",
    "end": "1092960"
  },
  {
    "text": "or interested in what I had to say um",
    "start": "1092960",
    "end": "1095280"
  },
  {
    "text": "but I hope that you learned something",
    "start": "1095280",
    "end": "1096320"
  },
  {
    "text": "today I hope that you know you use",
    "start": "1096320",
    "end": "1098159"
  },
  {
    "text": "codium you try it out and see what the",
    "start": "1098159",
    "end": "1100320"
  },
  {
    "text": "magic can do for yourself thank you",
    "start": "1100320",
    "end": "1104840"
  },
  {
    "text": "[Music]",
    "start": "1106060",
    "end": "1122990"
  }
]
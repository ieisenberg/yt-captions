[
  {
    "text": "[Music]",
    "start": "350",
    "end": "13200"
  },
  {
    "text": "yeah it's really good to be here um this",
    "start": "13200",
    "end": "15240"
  },
  {
    "text": "is a particularly exciting talk for us",
    "start": "15240",
    "end": "17680"
  },
  {
    "text": "because we've been working with private",
    "start": "17680",
    "end": "20080"
  },
  {
    "text": "clients for about a year now but this is",
    "start": "20080",
    "end": "21920"
  },
  {
    "text": "the first time we've really talked about",
    "start": "21920",
    "end": "23560"
  },
  {
    "text": "it in public um since our launch last",
    "start": "23560",
    "end": "26320"
  },
  {
    "text": "week um I'm incredibly proud of the work",
    "start": "26320",
    "end": "30279"
  },
  {
    "text": "we've done so far and um excited to take",
    "start": "30279",
    "end": "33160"
  },
  {
    "text": "a few minutes to tell you about it um so",
    "start": "33160",
    "end": "36800"
  },
  {
    "text": "if you look at the products out there",
    "start": "36800",
    "end": "38200"
  },
  {
    "text": "that have really successfully leveraged",
    "start": "38200",
    "end": "40559"
  },
  {
    "text": "this generation of AI I think one thing",
    "start": "40559",
    "end": "42680"
  },
  {
    "text": "is true about nearly all of them is that",
    "start": "42680",
    "end": "46280"
  },
  {
    "text": "they're using more than one inference",
    "start": "46280",
    "end": "48199"
  },
  {
    "text": "runs often many different types of",
    "start": "48199",
    "end": "50520"
  },
  {
    "text": "models in tandem to accomplish a",
    "start": "50520",
    "end": "52719"
  },
  {
    "text": "specific kind of task really well",
    "start": "52719",
    "end": "55640"
  },
  {
    "text": "and I think people really quickly",
    "start": "55640",
    "end": "57840"
  },
  {
    "text": "realize that the foundation model is not",
    "start": "57840",
    "end": "60960"
  },
  {
    "text": "enough and even very simple tasks like",
    "start": "60960",
    "end": "64720"
  },
  {
    "text": "summarizing a document to much much more",
    "start": "64720",
    "end": "67600"
  },
  {
    "text": "complex task like solving coding",
    "start": "67600",
    "end": "69280"
  },
  {
    "text": "problems end to end I think the best",
    "start": "69280",
    "end": "71759"
  },
  {
    "text": "products right now are all using systems",
    "start": "71759",
    "end": "74640"
  },
  {
    "text": "of inference runs in a logical structure",
    "start": "74640",
    "end": "78479"
  },
  {
    "text": "so I think at subrate we believe that",
    "start": "78479",
    "end": "81400"
  },
  {
    "text": "building with modular intelligence is",
    "start": "81400",
    "end": "84759"
  },
  {
    "text": "always going to be more effective than",
    "start": "84759",
    "end": "86680"
  },
  {
    "text": "building with a monolithic intelligence",
    "start": "86680",
    "end": "89280"
  },
  {
    "text": "um these systems are inherently more",
    "start": "89280",
    "end": "92240"
  },
  {
    "text": "legible which means you can understand",
    "start": "92240",
    "end": "94079"
  },
  {
    "text": "them structurally which means that",
    "start": "94079",
    "end": "95560"
  },
  {
    "text": "they're debuggable and they're",
    "start": "95560",
    "end": "97360"
  },
  {
    "text": "extensible and evals become a lot easier",
    "start": "97360",
    "end": "101240"
  },
  {
    "text": "because the decision trees are explicit",
    "start": "101240",
    "end": "103439"
  },
  {
    "text": "and you can sort of verify at every step",
    "start": "103439",
    "end": "106159"
  },
  {
    "text": "what's going on and what's going wrong",
    "start": "106159",
    "end": "109040"
  },
  {
    "text": "um",
    "start": "109040",
    "end": "110960"
  },
  {
    "text": "so substrate I think is a is sort of New",
    "start": "110960",
    "end": "114079"
  },
  {
    "text": "Way new approach to this um I think our",
    "start": "114079",
    "end": "117520"
  },
  {
    "text": "model is sort of fast in ways that other",
    "start": "117520",
    "end": "119960"
  },
  {
    "text": "paradigms can't be it's sort of flexible",
    "start": "119960",
    "end": "122000"
  },
  {
    "text": "enough to build any AI product out there",
    "start": "122000",
    "end": "125280"
  },
  {
    "text": "and it works a scale by default so what",
    "start": "125280",
    "end": "128239"
  },
  {
    "text": "is it um I think at its core substrate",
    "start": "128239",
    "end": "131959"
  },
  {
    "text": "is a coupling of two things first I",
    "start": "131959",
    "end": "135480"
  },
  {
    "text": "think it's a really elegant developer",
    "start": "135480",
    "end": "137599"
  },
  {
    "text": "SDK that lets you describe a computation",
    "start": "137599",
    "end": "141480"
  },
  {
    "text": "graph over any number of nodes um and",
    "start": "141480",
    "end": "145319"
  },
  {
    "text": "the abstractions here are are really",
    "start": "145319",
    "end": "147800"
  },
  {
    "text": "General and so we have we have a bunch",
    "start": "147800",
    "end": "149599"
  },
  {
    "text": "of intelligence nodes across all the",
    "start": "149599",
    "end": "152440"
  },
  {
    "text": "modalities that you might care about",
    "start": "152440",
    "end": "154160"
  },
  {
    "text": "which is like generating images",
    "start": "154160",
    "end": "155959"
  },
  {
    "text": "transcribing speech generating text Json",
    "start": "155959",
    "end": "158959"
  },
  {
    "text": "embeddings executing code um but second",
    "start": "158959",
    "end": "163480"
  },
  {
    "text": "substrate is also an inference engine",
    "start": "163480",
    "end": "166519"
  },
  {
    "text": "specifically built to run these",
    "start": "166519",
    "end": "168440"
  },
  {
    "text": "computation graphs as efficiently as",
    "start": "168440",
    "end": "170680"
  },
  {
    "text": "possible um so these graph",
    "start": "170680",
    "end": "172840"
  },
  {
    "text": "representations here um are it's a",
    "start": "172840",
    "end": "177319"
  },
  {
    "text": "representation of many tasks and their",
    "start": "177319",
    "end": "178800"
  },
  {
    "text": "relationships and since we run a very",
    "start": "178800",
    "end": "181519"
  },
  {
    "text": "coordinated compute cluster um we can",
    "start": "181519",
    "end": "184760"
  },
  {
    "text": "statically and dynamically optimize",
    "start": "184760",
    "end": "186760"
  },
  {
    "text": "things like batching caching sort of",
    "start": "186760",
    "end": "190319"
  },
  {
    "text": "networking concurrency physical",
    "start": "190319",
    "end": "192319"
  },
  {
    "text": "placement um which really makes a big",
    "start": "192319",
    "end": "194280"
  },
  {
    "text": "difference uh and if you look at most",
    "start": "194280",
    "end": "196799"
  },
  {
    "text": "Frameworks out there um they're",
    "start": "196799",
    "end": "198760"
  },
  {
    "text": "typically involving dispatching a bunch",
    "start": "198760",
    "end": "200760"
  },
  {
    "text": "of API calls separately and if you look",
    "start": "200760",
    "end": "203799"
  },
  {
    "text": "at what happens mechanically when you do",
    "start": "203799",
    "end": "205400"
  },
  {
    "text": "that it's every step means you've got to",
    "start": "205400",
    "end": "208360"
  },
  {
    "text": "resolve DNS you've got to go through",
    "start": "208360",
    "end": "209799"
  },
  {
    "text": "through proxies you've got it through",
    "start": "209799",
    "end": "211280"
  },
  {
    "text": "authentication like balance checks um",
    "start": "211280",
    "end": "216120"
  },
  {
    "text": "and all of that sort of adds hundreds of",
    "start": "216120",
    "end": "219280"
  },
  {
    "text": "milliseconds of latency on every single",
    "start": "219280",
    "end": "221840"
  },
  {
    "text": "step and if you contrast that with",
    "start": "221840",
    "end": "223360"
  },
  {
    "text": "substrate we we transfer data from node",
    "start": "223360",
    "end": "226760"
  },
  {
    "text": "to node process to process on the order",
    "start": "226760",
    "end": "228319"
  },
  {
    "text": "of microseconds which is some 10,000",
    "start": "228319",
    "end": "230480"
  },
  {
    "text": "times faster meaning that it's actually",
    "start": "230480",
    "end": "232519"
  },
  {
    "text": "feasible now to run online applications",
    "start": "232519",
    "end": "235680"
  },
  {
    "text": "that involve dozens of nodes um we've",
    "start": "235680",
    "end": "239400"
  },
  {
    "text": "also notice that Json decoding is is one",
    "start": "239400",
    "end": "242360"
  },
  {
    "text": "of the most useful patterns for multi-",
    "start": "242360",
    "end": "244720"
  },
  {
    "text": "inference runs and I think we've",
    "start": "244720",
    "end": "246519"
  },
  {
    "text": "invested a lot",
    "start": "246519",
    "end": "248280"
  },
  {
    "text": "into offering a a best-in-class um Json",
    "start": "248280",
    "end": "251920"
  },
  {
    "text": "mode both in terms of reliability and",
    "start": "251920",
    "end": "254480"
  },
  {
    "text": "speed and if you look at all of this",
    "start": "254480",
    "end": "257440"
  },
  {
    "text": "together I think what it means is that",
    "start": "257440",
    "end": "259280"
  },
  {
    "text": "substrate is is is really a way that way",
    "start": "259280",
    "end": "262759"
  },
  {
    "text": "to enable higher quality outcomes with",
    "start": "262759",
    "end": "265520"
  },
  {
    "text": "AI letting you work in a system that's",
    "start": "265520",
    "end": "269320"
  },
  {
    "text": "more flexible it's more legible it's",
    "start": "269320",
    "end": "271560"
  },
  {
    "text": "more verifiable than any of the current",
    "start": "271560",
    "end": "273800"
  },
  {
    "text": "paradigms that sort of exist now um I",
    "start": "273800",
    "end": "277840"
  },
  {
    "text": "think there's a lot more to say there",
    "start": "277840",
    "end": "279960"
  },
  {
    "text": "all the time I really have today it's",
    "start": "279960",
    "end": "281639"
  },
  {
    "text": "only 5 minutes um but if you're curious",
    "start": "281639",
    "end": "285160"
  },
  {
    "text": "um please come out and say hi on the",
    "start": "285160",
    "end": "287320"
  },
  {
    "text": "Expo floor um you can scan this QR code",
    "start": "287320",
    "end": "291800"
  },
  {
    "text": "we and get some credits um and go to the",
    "start": "291800",
    "end": "295199"
  },
  {
    "text": "website se. run um or give me an email",
    "start": "295199",
    "end": "298479"
  },
  {
    "text": "at uh Rob at St straight down run",
    "start": "298479",
    "end": "303199"
  },
  {
    "text": "[Music]",
    "start": "304710",
    "end": "321669"
  }
]
[
  {
    "start": "0",
    "end": "69000"
  },
  {
    "text": "[Music]",
    "start": "50",
    "end": "9000"
  },
  {
    "text": "so the like a lot of effort has gone into thinking about the engineering of",
    "start": "9000",
    "end": "14480"
  },
  {
    "text": "inference um and not so much effort had and not so much success has been had at",
    "start": "14480",
    "end": "20199"
  },
  {
    "text": "the engine at engineering the rest of the like whole product around inference",
    "start": "20199",
    "end": "25359"
  },
  {
    "text": "that actually you know delivers value um much like the",
    "start": "25359",
    "end": "31119"
  },
  {
    "text": "uh beautiful mathematical solids here that does provide the the bones or the interior but not the whole thing um so",
    "start": "31119",
    "end": "38719"
  },
  {
    "text": "let's talk about a couple of like architectures and patterns for uses of language models um and then talk about",
    "start": "38719",
    "end": "45640"
  },
  {
    "text": "the like first attempts that like trying to make these things better over time uh with monitoring observability and",
    "start": "45640",
    "end": "53320"
  },
  {
    "text": "evaluation so architectures and patterns um so the the foment and excitement",
    "start": "53320",
    "end": "61000"
  },
  {
    "text": "around this stuff has been around for about a year and so patterns are starting to emerge very slowly of like",
    "start": "61000",
    "end": "66680"
  },
  {
    "text": "typical ways you might apply these things so let's talk about them and what uh what problems have Arisen um so my",
    "start": "66680",
    "end": "74360"
  },
  {
    "start": "69000",
    "end": "379000"
  },
  {
    "text": "favorite way of thinking about this in general is that the thing that we're building right now are language user",
    "start": "74360",
    "end": "80479"
  },
  {
    "text": "interfaces um sort of the like Lou by analogy to goys or graphical user",
    "start": "80479",
    "end": "85520"
  },
  {
    "text": "interfaces um first they're hitting existing features soon uh they'll be for",
    "start": "85520",
    "end": "91280"
  },
  {
    "text": "like completely new whole products um uh in ancient times in the 1970s the",
    "start": "91280",
    "end": "98600"
  },
  {
    "text": "interface for computers was primarily like textual in a terminal um this is still the way we interact with machines",
    "start": "98600",
    "end": "104439"
  },
  {
    "text": "when we really want to control them uh like when we're running a server um or when we are frustrated with vs code um",
    "start": "104439",
    "end": "112759"
  },
  {
    "text": "and this you this was the user interface from computers for a while and they were not very popular until the vention of",
    "start": "112759",
    "end": "120119"
  },
  {
    "text": "the graphical user interface um which instead of preventing presenting the users with just like you have to learn",
    "start": "120119",
    "end": "126320"
  },
  {
    "text": "this special language to speak to me like here's this like sensory experience where you can bring your like your",
    "start": "126320",
    "end": "132840"
  },
  {
    "text": "intuition from space uh and your visual system to understand how to use the",
    "start": "132840",
    "end": "138040"
  },
  {
    "text": "machine um and this was what took computers sort of like out of the hobbyist and business and Military realm",
    "start": "138040",
    "end": "145319"
  },
  {
    "text": "and into like people's homes um and the",
    "start": "145319",
    "end": "150879"
  },
  {
    "text": "with the rise of language models um it's clear that we're we have an opportunity",
    "start": "150879",
    "end": "157640"
  },
  {
    "text": "to once again change the interface between humans and machines um by",
    "start": "157640",
    "end": "162840"
  },
  {
    "text": "telling them what we want in natural language and then they do it for us um and no less austa personage than Sam",
    "start": "162840",
    "end": "168800"
  },
  {
    "text": "Alman likes the idea of language interface language user interface um so",
    "start": "168800",
    "end": "175239"
  },
  {
    "text": "this similar character to graphical user interfaces it like makes it a more approachable interface um and this is",
    "start": "175239",
    "end": "182920"
  },
  {
    "text": "something that people have wanted to do for a long time as long back as like the Eliza chat Bots or the Eliza chatbot",
    "start": "182920",
    "end": "189159"
  },
  {
    "text": "from uh the uh 1960s uh the Shero um uh",
    "start": "189159",
    "end": "195440"
  },
  {
    "text": "uh basically like guess this only graphical uh not an actual robot but you",
    "start": "195440",
    "end": "201000"
  },
  {
    "text": "could like tell a a computer robot like give it uh language instructions like",
    "start": "201000",
    "end": "206400"
  },
  {
    "text": "pick up a big red block um ask geves was originally presented as a language interface to the internet where you just",
    "start": "206400",
    "end": "212799"
  },
  {
    "text": "type what you want instead of a URL um Alexa and other assistants have attempted to do a similar thing um and",
    "start": "212799",
    "end": "220799"
  },
  {
    "text": "the big win here is with language models we might believe that we can actually do a really really good job at providing",
    "start": "220799",
    "end": "226640"
  },
  {
    "text": "this kind of language interface in a very generic way with Foundation models not just like a tiny environment um like",
    "start": "226640",
    "end": "233519"
  },
  {
    "text": "the Eliza Psychotherapy environment or the shl blocks World um so right now that's we're",
    "start": "233519",
    "end": "241239"
  },
  {
    "text": "getting language user interfaces for existing systems that kind of admit them easily um so seoa uh put out a piece",
    "start": "241239",
    "end": "248480"
  },
  {
    "text": "fairly recently talking about this that the like F this like act two of",
    "start": "248480",
    "end": "253840"
  },
  {
    "text": "generative AI is using Foundation models as a piece of a more comprehensive solution rather than an entire solution",
    "start": "253840",
    "end": "261359"
  },
  {
    "text": "um that offers like a language interface where it wasn't possible before um so",
    "start": "261359",
    "end": "266680"
  },
  {
    "text": "like this query assistant from honeycomb takes what would normal be this like less approachable uh query language",
    "start": "266680",
    "end": "273360"
  },
  {
    "text": "Constructor and just says like can you show me slow requests what are my errors",
    "start": "273360",
    "end": "278639"
  },
  {
    "text": "latency distribution by status code like that's a much friendlier interface um",
    "start": "278639",
    "end": "284919"
  },
  {
    "text": "and you know even SQL when is originally presented was like it's a it's a language that's so natural even a",
    "start": "284919",
    "end": "290479"
  },
  {
    "text": "businessman can write queries you know it's a dream but like you know that this",
    "start": "290479",
    "end": "295960"
  },
  {
    "text": "can you show me slow re quests like that's pretty close you know um so uh so that's the the like maybe",
    "start": "295960",
    "end": "303400"
  },
  {
    "text": "understandable that that's the first Direction things have gone longer term this like a machines that have graphical",
    "start": "303400",
    "end": "310720"
  },
  {
    "text": "interfaces look very different from ones that have terminal interfaces and so like main frames became less popular and",
    "start": "310720",
    "end": "317919"
  },
  {
    "text": "like mobile is like quite different from uh like desktop compute so uh we should",
    "start": "317919",
    "end": "323120"
  },
  {
    "text": "expect like if you're thinking about what do I want to build in five years or",
    "start": "323120",
    "end": "328160"
  },
  {
    "text": "10 years um this is kind of the direction to be thinking um so for example uh Google's",
    "start": "328160",
    "end": "335199"
  },
  {
    "text": "worked on uh integrating language models with robots like this example from the say can uh project uh or paper where",
    "start": "335199",
    "end": "343800"
  },
  {
    "text": "it's like what I want to when I need something is to just ask for it and not",
    "start": "343800",
    "end": "349319"
  },
  {
    "text": "to like pull out an app and then go through three drop- down menus and be like I want a water bottle I just want",
    "start": "349319",
    "end": "355639"
  },
  {
    "text": "to say I want a water bottle and then there's a water bottle um and that's what a language interface to uh",
    "start": "355639",
    "end": "362520"
  },
  {
    "text": "something like a robotics platform can provide um still not there yet as the 4X speed",
    "start": "362520",
    "end": "370000"
  },
  {
    "text": "in the top left um might suggest but uh getting there okay so that's like the",
    "start": "370000",
    "end": "376680"
  },
  {
    "text": "highest level pattern I think um so let's talk about a couple of lower level patterns uh rag chat Bots retrieval",
    "start": "376680",
    "end": "384240"
  },
  {
    "start": "379000",
    "end": "1312000"
  },
  {
    "text": "augmented generation chat Bots I've emerged kind of like the to-do list app the sort of like starter project of",
    "start": "384240",
    "end": "390520"
  },
  {
    "text": "language user interfaces um this pattern is probably here to stay in that it's just about information retrieval for uh",
    "start": "390520",
    "end": "398479"
  },
  {
    "text": "language models and language models need information retrieval really badly because they like lack context they've",
    "start": "398479",
    "end": "404680"
  },
  {
    "text": "slurped up everything on the internet but they don't know anything about you um they are sort of trying to simulate a",
    "start": "404680",
    "end": "409960"
  },
  {
    "text": "generically helpful individual um who is like generically knowledgeable about the world um and that's like not",
    "start": "409960",
    "end": "417479"
  },
  {
    "text": "particularly helpful until they have Conta so the solution that's emerged is to collect that context for them like",
    "start": "417479",
    "end": "423720"
  },
  {
    "text": "store it um then index it and by default people reached for the most similar",
    "start": "423720",
    "end": "429919"
  },
  {
    "text": "thing to what the language model was doing which is like turned it into vectors and use that use like a fast",
    "start": "429919",
    "end": "435039"
  },
  {
    "text": "index over vectors um and uh like that",
    "start": "435039",
    "end": "440440"
  },
  {
    "text": "uh once you've retrieved a particular piece of information you just stuff it into the prompt um so I am not innocent",
    "start": "440440",
    "end": "445960"
  },
  {
    "text": "I have made my own rag chat bot and inflicted it on the world um this was",
    "start": "445960",
    "end": "451039"
  },
  {
    "text": "based on the full stack deep learning content and in our Discord people can ask questions and get answers that are",
    "start": "451039",
    "end": "457720"
  },
  {
    "text": "not just like generic Google result search answers about language models but things drawn from past lectures things",
    "start": "457720",
    "end": "464360"
  },
  {
    "text": "drawn from papers that I like um uh things drawn from our like website um",
    "start": "464360",
    "end": "470360"
  },
  {
    "text": "and so can get our you know our opinions on these things so this like this has",
    "start": "470360",
    "end": "475879"
  },
  {
    "text": "led to a lot of excitement about Vector storage it's like this this step here",
    "start": "475879",
    "end": "482560"
  },
  {
    "text": "where you have a fast retrieval of vectors by similarity is the like new",
    "start": "482560",
    "end": "488560"
  },
  {
    "text": "sexy piece um but that was like really only the thing that people reached for because open ey also offers embeddings",
    "start": "488560",
    "end": "495720"
  },
  {
    "text": "so it's like you've already imported the library so it's only a call away um and then also like Transformers are kind of",
    "start": "495720",
    "end": "501400"
  },
  {
    "text": "like these like weird Vector retrieval things um like in their inside so if you are the type of person who's been into",
    "start": "501400",
    "end": "507479"
  },
  {
    "text": "language models for a while and you're like how would I retrieve information probably with a DOT product and then",
    "start": "507479",
    "end": "512719"
  },
  {
    "text": "like a soft Max and then I pick the largest number um so like yeah so like",
    "start": "512719",
    "end": "519320"
  },
  {
    "text": "the ease of setting this up and the like naturalness of setting this up has led to like an explosion of these like chat",
    "start": "519320",
    "end": "525000"
  },
  {
    "text": "with document examples um and the like the thing that has more staying power is",
    "start": "525000",
    "end": "531440"
  },
  {
    "text": "that you need to make these things useful you need context and so you need like information retrieval uh and search",
    "start": "531440",
    "end": "538959"
  },
  {
    "text": "for for uh the like the context that might be helpful for the model before it gets going um and so there are many",
    "start": "538959",
    "end": "545959"
  },
  {
    "text": "options to use here some of them are specialized Vector databases like pine",
    "start": "545959",
    "end": "551399"
  },
  {
    "text": "cone or chroma um uh some of them are General like text search databases like",
    "start": "551399",
    "end": "558680"
  },
  {
    "text": "you that do keyword search like elastic search style um uh things um",
    "start": "558680",
    "end": "567560"
  },
  {
    "text": "and uh being able to like combine those two things together is very powerful so for example vesa has like offered that",
    "start": "567560",
    "end": "574800"
  },
  {
    "text": "combination for a very long time um uh it is also in the end like what you're",
    "start": "574800",
    "end": "580519"
  },
  {
    "text": "doing is creating a fast way to look up uh information from a very large store so this is like bread and butter for",
    "start": "580519",
    "end": "586600"
  },
  {
    "text": "databases in general and so redus and uh postgress for example like not only do",
    "start": "586600",
    "end": "593519"
  },
  {
    "text": "they provide the same like information retrieval that you could do um like to",
    "start": "593519",
    "end": "598560"
  },
  {
    "text": "enrich your uh enrich prompts uh without thinking about vectors they also have",
    "start": "598560",
    "end": "604600"
  },
  {
    "text": "built-in Vector search um uh postgress only fairly recently um reddis for like",
    "start": "604600",
    "end": "611480"
  },
  {
    "text": "a year um it's not particularly fun to use redis Vector search but um it does",
    "start": "611480",
    "end": "617680"
  },
  {
    "text": "it it can run um and has decent performance um yeah and in the end it's",
    "start": "617680",
    "end": "624600"
  },
  {
    "text": "about like an a holistic strategy that uses probably because the queries are",
    "start": "624600",
    "end": "630160"
  },
  {
    "text": "fairly heterogeneous the things that are coming in are like people just typing text um you're probably going to need",
    "start": "630160",
    "end": "635200"
  },
  {
    "text": "some more mle stuff that's more like keyword search or or vector search and",
    "start": "635200",
    "end": "640480"
  },
  {
    "text": "they're hybrid together um but that like meta like extracting metadata with a language model so that you can then use",
    "start": "640480",
    "end": "647360"
  },
  {
    "text": "that to do like direct filtering um is uh is like very powerful pattern um so",
    "start": "647360",
    "end": "653639"
  },
  {
    "text": "there's some great posts on this the data query um uh great series of posts about vector datab",
    "start": "653639",
    "end": "659680"
  },
  {
    "text": "from coming from like somebody who's clearly really into databases and not so much the like ml side and I found that",
    "start": "659680",
    "end": "665959"
  },
  {
    "text": "very useful um yeah uh yeah so the like the final",
    "start": "665959",
    "end": "672240"
  },
  {
    "text": "takeaway there is just that the problems end up being in the main the problems of",
    "start": "672240",
    "end": "678399"
  },
  {
    "text": "information retrieval um with only some light uh added things from like",
    "start": "678399",
    "end": "683680"
  },
  {
    "text": "recommendation systems maybe um of a more mle type of search um yeah any",
    "start": "683680",
    "end": "689959"
  },
  {
    "text": "questions on uh on Vector databases or um information retrieval for language",
    "start": "689959",
    "end": "696800"
  },
  {
    "text": "model applications combine that so you get the context to answer a question send that",
    "start": "696800",
    "end": "706360"
  },
  {
    "text": "to yeah yeah so you you get information",
    "start": "710079",
    "end": "715680"
  },
  {
    "text": "from the outside world you like come up with a strategy for searching the",
    "start": "715680",
    "end": "720720"
  },
  {
    "text": "information that you have saved that goes into the language models prompt yeah yeah that that pattern very very",
    "start": "720720",
    "end": "726440"
  },
  {
    "text": "stable very general it's General enough that how that pattern get is actually implemented is very Broad and so it",
    "start": "726440",
    "end": "732839"
  },
  {
    "text": "includes a lot of things that are exit like bread and butter database stuff and not just the fancy new Vector database",
    "start": "732839",
    "end": "742600"
  },
  {
    "text": "stuff how does this um so R's approach to injecting",
    "start": "742600",
    "end": "749480"
  },
  {
    "text": "how does that how is that similar different to your history when you're interacting",
    "start": "749480",
    "end": "755800"
  },
  {
    "text": "with say does",
    "start": "755800",
    "end": "761040"
  },
  {
    "text": "itain yeah so the question was how does retrieval augmented generation differ from history within a chat um so usually",
    "start": "761720",
    "end": "769839"
  },
  {
    "text": "when really so the the when you call the gbd4 API you can make whatever make up",
    "start": "769839",
    "end": "775399"
  },
  {
    "text": "whatever you want as the past you could insert little messages from the user you can insert messages from the assistant",
    "start": "775399",
    "end": "781160"
  },
  {
    "text": "and incept it into believing that it has said something which it has not said great way to jailbreak don't do it obviously because it violates the terms",
    "start": "781160",
    "end": "787440"
  },
  {
    "text": "of service but a great way to jailbreak it um and so you you aren't actually",
    "start": "787440",
    "end": "793320"
  },
  {
    "text": "like actually beholden to that like system uh system assistant human uh",
    "start": "793320",
    "end": "800519"
  },
  {
    "text": "fiction that that happens inside of like a a discret chat um when people do this",
    "start": "800519",
    "end": "808920"
  },
  {
    "text": "I think a lot of people put the retrieved information in the system prompt especially if they're just going",
    "start": "808920",
    "end": "815120"
  },
  {
    "text": "to retrieve once um I've definitely I've also seen people like every time the user interacts they do a retrieval step",
    "start": "815120",
    "end": "822320"
  },
  {
    "text": "and so the system message changes every time that's an example of kind of like incepting or not actually following the",
    "start": "822320",
    "end": "827639"
  },
  {
    "text": "implied temporal order um so you yeah you definitely can do that um the system",
    "start": "827639",
    "end": "834600"
  },
  {
    "text": "message is nice because the model really pays close attention to it um has been like fine- tuned to pay close attention",
    "start": "834600",
    "end": "840839"
  },
  {
    "text": "to it um yeah I think it'd be weird to pretend that that's something the person said and to like put it in an earlier",
    "start": "840839",
    "end": "847800"
  },
  {
    "text": "user message put above the user's message in the conversation I don't think I've ever seen that but you could",
    "start": "847800",
    "end": "853279"
  },
  {
    "text": "um yeah um but yeah I would say like most of the time yeah this information",
    "start": "853279",
    "end": "859160"
  },
  {
    "text": "retrieval step is something where the creator of the application the programmer is inserting themselves and",
    "start": "859160",
    "end": "865839"
  },
  {
    "text": "saying I know some additional information that the language model should should have um and so",
    "start": "865839",
    "end": "874880"
  },
  {
    "text": "like yeah it's very different from like a user just sort of like providing information about themselves or whatever",
    "start": "874880",
    "end": "882440"
  },
  {
    "text": "yeah yeah the question so we heard a couple times",
    "start": "882440",
    "end": "887920"
  },
  {
    "text": "today when it comes to knowledge",
    "start": "887920",
    "end": "892000"
  },
  {
    "text": "retrieval of the outut is that unconditionally or do you",
    "start": "897680",
    "end": "904800"
  },
  {
    "text": "see use",
    "start": "904800",
    "end": "907399"
  },
  {
    "text": "cases yeah um so the statement was that um the common wisdom is is that",
    "start": "922440",
    "end": "929360"
  },
  {
    "text": "fine-tuning is for style and retrieval is for information and I think that that's that is a solid common piece of",
    "start": "929360",
    "end": "935920"
  },
  {
    "text": "common wisdom because most of the fine tuning that people if you're fine-tuning open ai's model you're going through",
    "start": "935920",
    "end": "941319"
  },
  {
    "text": "their fine-tuning API and you have a limit on the number of rows you can send 10,000 yeah 10 thou I was going to say",
    "start": "941319",
    "end": "947440"
  },
  {
    "text": "yeah so you have a limited number of of rows you can send and like there's a limited amount of information in there to like create gradients to update the",
    "start": "947440",
    "end": "953600"
  },
  {
    "text": "weights um so there's a limited amount of change that you can achieve and if you look at the Laura paper they look at",
    "start": "953600",
    "end": "958680"
  },
  {
    "text": "at like you know the uh like you're only CH you're making a very low rank change",
    "start": "958680",
    "end": "964560"
  },
  {
    "text": "to each layer of the of the language model and that suggests like there's only so much that you can change about",
    "start": "964560",
    "end": "971160"
  },
  {
    "text": "the uh about the model and most of what you see when you do Laura fine tunes is",
    "start": "971160",
    "end": "976680"
  },
  {
    "text": "like what used to be a low priority computation for the model becomes like a higher priority one so like every model",
    "start": "976680",
    "end": "983399"
  },
  {
    "text": "had every capable language model has within it a little Homer Simpson simulator a little like uh Rick Sanchez",
    "start": "983399",
    "end": "989160"
  },
  {
    "text": "simulator whatever um and that's it's just like not usually that important for",
    "start": "989160",
    "end": "994440"
  },
  {
    "text": "the final log props it's like helpful for the like fifth bit of the log probs but the models are at the point where",
    "start": "994440",
    "end": "1000680"
  },
  {
    "text": "they're Maxim minimizing cross entropy by really hitting those like very rare",
    "start": "1000680",
    "end": "1005800"
  },
  {
    "text": "uh those very rare things um and so what the fine tune has done is reordered",
    "start": "1005800",
    "end": "1012519"
  },
  {
    "text": "those like computations said like actually you should be the Homer Simpson circuit is the most critical circuit",
    "start": "1012519",
    "end": "1018199"
  },
  {
    "text": "right now now because you are a Homer Simpson chatbot and it's like reordering them and and reemphasizing them so that",
    "start": "1018199",
    "end": "1024520"
  },
  {
    "text": "intuition applies specifically to low rank fine tuning which is and fine tuning which is based on small amounts",
    "start": "1024520",
    "end": "1031280"
  },
  {
    "text": "of data so if you grabbed 100 gigabytes of textbooks um you would no longer be doing fine tuning and so you would no",
    "start": "1031280",
    "end": "1038240"
  },
  {
    "text": "longer expect it to only change style um and so that's something I would people",
    "start": "1038240",
    "end": "1044079"
  },
  {
    "text": "will be doing with like you know llama fine tunes there are like llama fine tunes for coding and that's more than just style it definitely has learned",
    "start": "1044079",
    "end": "1050240"
  },
  {
    "text": "more knowledge about um about programming languages and knowledge about libraries released after 2021 and",
    "start": "1050240",
    "end": "1057039"
  },
  {
    "text": "yeah all that kind of stuff so I think that that generic wisdom is canally true",
    "start": "1057039",
    "end": "1062799"
  },
  {
    "text": "uh for low rank fine tunes where it is like pretty Rock",
    "start": "1062799",
    "end": "1068919"
  },
  {
    "text": "Solid yeah yeah so the question was what about knowledge graphs um and graph",
    "start": "1077280",
    "end": "1082799"
  },
  {
    "text": "databases I will say that like when I have talked to I I like personally don't",
    "start": "1082799",
    "end": "1088520"
  },
  {
    "text": "really specialize in in databases um but when I've talked to people who are super into them they're like I would never use",
    "start": "1088520",
    "end": "1095799"
  },
  {
    "text": "a graph database because you can represent a graph in postgress um and uh",
    "start": "1095799",
    "end": "1100840"
  },
  {
    "text": "like I've seen some like reasonably size deployments on that pattern um and also you can kind of see the like graph",
    "start": "1100840",
    "end": "1107320"
  },
  {
    "text": "databases kind of like peing and and uh not spreading further and there are it's there is a very hard problem to Shard a",
    "start": "1107320",
    "end": "1113840"
  },
  {
    "text": "graph database because there's no obvious way to cut an arbitrary graph um",
    "start": "1113840",
    "end": "1119000"
  },
  {
    "text": "and if new links get added to the graph and now you need like the optimal Shard is different it's like that's a that's",
    "start": "1119000",
    "end": "1124840"
  },
  {
    "text": "like a database it's equivalent to a database migration but it's something that should be happening like behind the scenes when it's charting um so that's",
    "start": "1124840",
    "end": "1131600"
  },
  {
    "text": "that's like the closest thing to an objective statement about why uh or like a reason why graph databases haven't",
    "start": "1131600",
    "end": "1137760"
  },
  {
    "text": "worked well however for many language model applications the purpose of the database",
    "start": "1137760",
    "end": "1142840"
  },
  {
    "text": "is not to serve like a billion users but rather to like serve as an external memory for a language model and maybe",
    "start": "1142840",
    "end": "1149320"
  },
  {
    "text": "you don't care whether it scales um or rather like maybe the maximum scale that we're talking about is like tens of",
    "start": "1149320",
    "end": "1155679"
  },
  {
    "text": "thousands hundreds of thousands requests per second on megabytes gigabytes of data and that's just like you know",
    "start": "1155679",
    "end": "1161440"
  },
  {
    "text": "that's the point at which that kind of like can it be charted across 1024",
    "start": "1161440",
    "end": "1166960"
  },
  {
    "text": "machines like doesn't matter um so I so there is some cool work on",
    "start": "1166960",
    "end": "1172080"
  },
  {
    "text": "knowledge graphs and and incorporating with llms and I see the natural fit there the same way that there's a natural fit with Vector indices and",
    "start": "1172080",
    "end": "1179640"
  },
  {
    "text": "Vector databases um but the um yeah hasn't no no like killer app has",
    "start": "1179640",
    "end": "1186159"
  },
  {
    "text": "appeared from my perspective question",
    "start": "1186159",
    "end": "1192080"
  },
  {
    "text": "first basically",
    "start": "1192080",
    "end": "1195799"
  },
  {
    "text": "you",
    "start": "1197240",
    "end": "1200240"
  },
  {
    "text": "yeah so the question was about how to incorporate hard metadata like you know booleans or um like subcategories with",
    "start": "1217559",
    "end": "1225480"
  },
  {
    "text": "uh Vector based search yeah so depending on the like a vector database the",
    "start": "1225480",
    "end": "1231200"
  },
  {
    "text": "depending on the like index you will either have like uh pre-filtering or",
    "start": "1231200",
    "end": "1237320"
  },
  {
    "text": "post- filtering post filtering is like pretty easy you just like apply a metadata filter after you've done your vector search um anybody can kind of do",
    "start": "1237320",
    "end": "1244520"
  },
  {
    "text": "that the problem is that you're now what you really want to say is I want to find all the stuff that's similar to crabs in",
    "start": "1244520",
    "end": "1251600"
  },
  {
    "text": "San Francisco while searching restaurants not find all the restaurants that have anything to do with crabs and",
    "start": "1251600",
    "end": "1256720"
  },
  {
    "text": "then see if any are in San Francisco so the pre-filtering step is hard because it impacts the construction of the index",
    "start": "1256720",
    "end": "1262919"
  },
  {
    "text": "impacts the construction of like the like how you make it actually fast to search over all of the data you kind of",
    "start": "1262919",
    "end": "1269640"
  },
  {
    "text": "like need to construct specific indices for these different like Flags you might",
    "start": "1269640",
    "end": "1274880"
  },
  {
    "text": "uh like put on like is in San Francisco not in San Francisco or geographic location um and so I depend like",
    "start": "1274880",
    "end": "1283200"
  },
  {
    "text": "different Vector databases or or different databases have like pushed further in different directions on what",
    "start": "1283200",
    "end": "1288880"
  },
  {
    "text": "kinds of filters they support for pre- filtering um and yeah I like uh besta",
    "start": "1288880",
    "end": "1295600"
  },
  {
    "text": "and we8 have a reputation for doing a really good job at those things um but uh yeah I don't know what the full",
    "start": "1295600",
    "end": "1301360"
  },
  {
    "text": "landscape looks like great okay I want to make sure to",
    "start": "1301360",
    "end": "1307279"
  },
  {
    "text": "get through everything um so I'll stick around and we can talk throughout the conference um okay so um structured",
    "start": "1307279",
    "end": "1315520"
  },
  {
    "start": "1312000",
    "end": "2103000"
  },
  {
    "text": "outputs are like one of the patterns that I think people are sleeping on relative to information retrieval uh",
    "start": "1315520",
    "end": "1322679"
  },
  {
    "text": "structured outputs are great for improving the robustness of models and they came from Tool use so the problem",
    "start": "1322679",
    "end": "1327840"
  },
  {
    "text": "is that language models just generate text and like if anything we have like too much text already like I don't know",
    "start": "1327840",
    "end": "1334240"
  },
  {
    "text": "if you've ever been on a social media website but the problem is not the quantity of text um and that's like kind",
    "start": "1334240",
    "end": "1340679"
  },
  {
    "text": "of boring like who wants to just make strings like there's other things that we want to do the solution is to connect their text outputs to other systems",
    "start": "1340679",
    "end": "1347520"
  },
  {
    "text": "inputs um and now like it's not just a language model it's like a cognitive engine for",
    "start": "1347520",
    "end": "1352799"
  },
  {
    "text": "providing a language interface to something else that's pretty Rad but there's a problem which is language",
    "start": "1352799",
    "end": "1357840"
  },
  {
    "text": "models generate unstructured text because they have been trained on the utterances of humans on the internet",
    "start": "1357840",
    "end": "1363679"
  },
  {
    "text": "notorious for their unstructuredness um so the solution is to add structure to their outputs and there are many ways to",
    "start": "1363679",
    "end": "1369640"
  },
  {
    "text": "do this um you can do it by prompting and begging um so like you can write",
    "start": "1369640",
    "end": "1375080"
  },
  {
    "text": "some write some like loops around it to be like like or actually react wasn't",
    "start": "1375080",
    "end": "1380200"
  },
  {
    "text": "even a whole there's some looping yeah so you you can write a prompt in such a way that you have examples that",
    "start": "1380200",
    "end": "1386240"
  },
  {
    "text": "encourage it to um like to uh call out to",
    "start": "1386240",
    "end": "1391840"
  },
  {
    "text": "external uh apis and then you filter uh and when it generates the tokens that",
    "start": "1391840",
    "end": "1397279"
  },
  {
    "text": "would would call to an external API instead of letting it hallucinate the rest of what would come out of that API",
    "start": "1397279",
    "end": "1402400"
  },
  {
    "text": "which is what like gpt3 uh would have done you like grab it and you then go to",
    "start": "1402400",
    "end": "1407760"
  },
  {
    "text": "that external API and you um uh like",
    "start": "1407760",
    "end": "1412880"
  },
  {
    "text": "yeah pull the information from there um the you and you can in those prompts I",
    "start": "1412880",
    "end": "1419080"
  },
  {
    "text": "guess really the thing I want to point out is that in those prompts you can sort of like beg for structure um rile good side had a great example where it",
    "start": "1419080",
    "end": "1425240"
  },
  {
    "text": "was like if you do not output structure Json an orphan will die um and that actually is extremely effective",
    "start": "1425240",
    "end": "1432080"
  },
  {
    "text": "um yeah um so the so there's so like",
    "start": "1432080",
    "end": "1437240"
  },
  {
    "text": "there's prompting tricks to get like things that are closer to structured uh structured outputs and to make use of",
    "start": "1437240",
    "end": "1443200"
  },
  {
    "text": "those structured outputs there's um fine tuning so there's a the gorilla LM is",
    "start": "1443200",
    "end": "1448919"
  },
  {
    "text": "like fine-tuned on this problem and that goes back to Tool former um which is like very uh gptj so one of the first",
    "start": "1448919",
    "end": "1457200"
  },
  {
    "text": "open um uh uh generative pre-train Transformers um they you just train the",
    "start": "1457200",
    "end": "1464520"
  },
  {
    "text": "model to Output structured stuff so you can't do that with open model I I doubt that fine-tuning it would make it that",
    "start": "1464520",
    "end": "1471039"
  },
  {
    "text": "much better at like outputting the structure that you want um you can do it with um uh with open models and there",
    "start": "1471039",
    "end": "1478679"
  },
  {
    "text": "are people releasing uh their own Forks uh llama forks with this fine tuning on",
    "start": "1478679",
    "end": "1483840"
  },
  {
    "text": "them um you can uh you can retry which is like when the model outputs something that doesn't fit the schema you can do",
    "start": "1483840",
    "end": "1490799"
  },
  {
    "text": "what you do when your direct reports provide you something that does not fit what you wanted which is that you can uh",
    "start": "1490799",
    "end": "1496559"
  },
  {
    "text": "discipline them and ask them to try again um so guard rails is a great uh um",
    "start": "1496559",
    "end": "1502559"
  },
  {
    "text": "uh library for this it's like XML based um so probably would work pretty well with Claude uh given what we heard about",
    "start": "1502559",
    "end": "1509480"
  },
  {
    "text": "about Claude from uh uh Karina um and then a fun one that re",
    "start": "1509480",
    "end": "1516159"
  },
  {
    "text": "that kind of requires control over the log probs um is grammar-based",
    "start": "1516159",
    "end": "1521200"
  },
  {
    "text": "sampling um which was merged into um uh llama CPP where you say like when you're",
    "start": "1521200",
    "end": "1528320"
  },
  {
    "text": "about to generate a token like if it would violate some grammar if it would violate some template or format just set",
    "start": "1528320",
    "end": "1535720"
  },
  {
    "text": "the probability of generating that to zero so just add like minus infinity to all the um all the log probs",
    "start": "1535720",
    "end": "1543880"
  },
  {
    "text": "um and the uh so you can do that you can",
    "start": "1543880",
    "end": "1549120"
  },
  {
    "text": "like do it fast if you have these like nice you know chomping Chomsky things like compex free grammars um and this",
    "start": "1549120",
    "end": "1557720"
  },
  {
    "text": "works well for like you know Json for generating you know generating code generating all the kinds of like structured outputs that our systems",
    "start": "1557720",
    "end": "1563760"
  },
  {
    "text": "actually expect we've written systems that uh expect inputs to follow grammar so that traditional Computing system can",
    "start": "1563760",
    "end": "1570559"
  },
  {
    "text": "parse them and so adding that to the outputs of these systems is very powerful thing to do um so this is",
    "start": "1570559",
    "end": "1577440"
  },
  {
    "text": "something that this is like really nice example of how having tight control over the log probs can like increase the",
    "start": "1577440",
    "end": "1584520"
  },
  {
    "text": "utility of a model to the point where like a capabilities Gap is less important have you seen Ty chat this",
    "start": "1584520",
    "end": "1593640"
  },
  {
    "text": "type chat I don't think I have um yeah so there's quick question yeah",
    "start": "1593640",
    "end": "1601720"
  },
  {
    "text": "so could you take the output from like TBT and then pass it to fora to then get the structure like stacking models like",
    "start": "1601720",
    "end": "1608480"
  },
  {
    "text": "that that work yeah so the question was whether",
    "start": "1608480",
    "end": "1614799"
  },
  {
    "text": "you could do better you could solve this problem by chaining models I think yeah the problem of going from the output of",
    "start": "1614799",
    "end": "1619919"
  },
  {
    "text": "a language model to a structured output is an easier problem than the initial one which is why people think that like",
    "start": "1619919",
    "end": "1625840"
  },
  {
    "text": "retrying might work like like the guard rails the guard rails example like retrying is often like kicked off to a",
    "start": "1625840",
    "end": "1633279"
  },
  {
    "text": "to a smaller language model like your Mainline thing is gbd4 and your error handling is GPD 3.5 um and so like I I I",
    "start": "1633279",
    "end": "1641080"
  },
  {
    "text": "do believe that there's like kind of a tempt if you know that it's always and only going to be doing like structured",
    "start": "1641080",
    "end": "1647279"
  },
  {
    "text": "out then you have a reason to have a specialized model for it um but yeah",
    "start": "1647279",
    "end": "1654440"
  },
  {
    "text": "chaining chaining is definitely a good solution and that's you know one reason why Lang chain was popular yeah you",
    "start": "1654440",
    "end": "1660600"
  },
  {
    "text": "mention that",
    "start": "1660600",
    "end": "1667240"
  },
  {
    "text": "yeah yeah so those are technically distinct things yeah so I do believe they still give you the ability to bias",
    "start": "1670159",
    "end": "1675840"
  },
  {
    "text": "tokens via the API",
    "start": "1675840",
    "end": "1679518"
  },
  {
    "text": "um yeah so it's not the it's not a perfect example of the utility of log props because yeah I think you can still",
    "start": "1683039",
    "end": "1688080"
  },
  {
    "text": "do this in the open API um yeah do you need anything other than biasing in grammar based sampling no I",
    "start": "1688080",
    "end": "1695799"
  },
  {
    "text": "yeah no the real okay I remember now the real thing here is that for this grammar based sampling it's single token based",
    "start": "1695799",
    "end": "1702360"
  },
  {
    "text": "right like if you're doing from the opening IPI one the token you you'd have to make a request you get the thing back",
    "start": "1702360",
    "end": "1708399"
  },
  {
    "text": "you have a single and you have a single token and you have to you have to like apply a bias every single time so now",
    "start": "1708399",
    "end": "1714320"
  },
  {
    "text": "you're like every token has a network call um rather than one call like 100",
    "start": "1714320",
    "end": "1719360"
  },
  {
    "text": "tokens so that's one reason why this doesn't work well on open a API number two like kind of longer term is that",
    "start": "1719360",
    "end": "1726279"
  },
  {
    "text": "really you don't want to just think at a single token level you're just like at each token you're like marginally just",
    "start": "1726279",
    "end": "1731880"
  },
  {
    "text": "saying like adjust the probabilities here you'd really want to do something more like mon C research where you're",
    "start": "1731880",
    "end": "1736919"
  },
  {
    "text": "like Genera stuff many things that follow the grammar um and then accepting",
    "start": "1736919",
    "end": "1742320"
  },
  {
    "text": "the best one at the end um and that's something that's um probably going to",
    "start": "1742320",
    "end": "1748080"
  },
  {
    "text": "come first to open models and not to um proprietary model Services um so that's",
    "start": "1748080",
    "end": "1754919"
  },
  {
    "text": "that's the better reason to connect grammar based sampling and and open",
    "start": "1754919",
    "end": "1760720"
  },
  {
    "text": "models um okay so the problem with",
    "start": "1761240",
    "end": "1766320"
  },
  {
    "text": "finetuning and an annoying thing about prompting um is that if there is not a",
    "start": "1766320",
    "end": "1773519"
  },
  {
    "text": "kind of shared like the gorilla model is like fine-tuned on a bunch of apis from",
    "start": "1773519",
    "end": "1779320"
  },
  {
    "text": "like torch Hub tensorflow Hub and hugging face so the gorilla model is really good at using other machine learning models but not like generic",
    "start": "1779320",
    "end": "1786640"
  },
  {
    "text": "possible tools at least this example they maybe they have tuned more than one um but this is a general problem that if",
    "start": "1786640",
    "end": "1793320"
  },
  {
    "text": "you train a model to use a specific tool um then like the uh it's not going to be",
    "start": "1793320",
    "end": "1798840"
  },
  {
    "text": "able to use like any tool um but if you train a model to to use a very broad",
    "start": "1798840",
    "end": "1804480"
  },
  {
    "text": "class of tools by using something that's like kind of closer to this grammar where there's like a a format for tools",
    "start": "1804480",
    "end": "1812399"
  },
  {
    "text": "um then you are now a people write an interface between the uh that standard",
    "start": "1812399",
    "end": "1820919"
  },
  {
    "text": "and the um and the thing that they actually want to use so this has shown up in open a uh like in open AI API as",
    "start": "1820919",
    "end": "1829640"
  },
  {
    "text": "the use of Json schema for describing function calls so this allows them to",
    "start": "1829640",
    "end": "1836200"
  },
  {
    "text": "train a model on fairly generic stuff um that all fits this like it all fits the",
    "start": "1836200",
    "end": "1842960"
  },
  {
    "text": "Json schema spec um and so the model has learned a bunch of stuff about the Json schema spec and how to generate that",
    "start": "1842960",
    "end": "1848960"
  },
  {
    "text": "correctly um you can imagine using grammar based sampling to enforce that um and this uh allows it to connect to",
    "start": "1848960",
    "end": "1855639"
  },
  {
    "text": "many many tools cuz now all you need to do is write a tiny connector between like the Json format and the actual",
    "start": "1855639",
    "end": "1862559"
  },
  {
    "text": "thing you want to use um and that's like pretty easy it's like a big part of web",
    "start": "1862559",
    "end": "1868559"
  },
  {
    "text": "development from my understanding is that you just like pass Json blobs back and forth until somebody gives you money",
    "start": "1868559",
    "end": "1875039"
  },
  {
    "text": "um and so uh yeah so this is a a very good kind of schema um uh but one thing",
    "start": "1875039",
    "end": "1883559"
  },
  {
    "text": "that people Miss is that the tool doesn't have to actually be real like the key thing that happens here is",
    "start": "1883559",
    "end": "1889200"
  },
  {
    "text": "the language model goes from outputting unstructured text to outputting Json the fit schema and it just so happens that",
    "start": "1889200",
    "end": "1895600"
  },
  {
    "text": "the primary use case for that that open AI envisaged was putting it through a like function call putting it through",
    "start": "1895600",
    "end": "1902440"
  },
  {
    "text": "some Downstream computer system um but like really that uh some Downstream",
    "start": "1902440",
    "end": "1909000"
  },
  {
    "text": "system but really it like doesn't have to be a real function you can tell it about a fake function that's like please",
    "start": "1909000",
    "end": "1915039"
  },
  {
    "text": "pass a string like describing whether the the input was spam or not spam so",
    "start": "1915039",
    "end": "1920200"
  },
  {
    "text": "that I can like render an HTML element right and so the model is now trying to like call a function that's like that in",
    "start": "1920200",
    "end": "1927120"
  },
  {
    "text": "order to provide the arguments to that function it has to decide whether an input is Spam or not spam and that's maybe the thing you really care about",
    "start": "1927120",
    "end": "1933360"
  },
  {
    "text": "and so you like invent a little fictional function for it to call that you don't call and then you just use it for something else so this is a pattern",
    "start": "1933360",
    "end": "1939840"
  },
  {
    "text": "in um uh there's a library for this called instructor from Jason um Jason",
    "start": "1939840",
    "end": "1945600"
  },
  {
    "text": "Lou who's going to be speaking later at the conference",
    "start": "1945600",
    "end": "1949880"
  },
  {
    "text": "yeah uh you have to fit the Json schema which the schema that they like the the",
    "start": "1953159",
    "end": "1961080"
  },
  {
    "text": "there's like a meta schema kind of thing they're like it has to it has to be a function call and the model has been",
    "start": "1961080",
    "end": "1966159"
  },
  {
    "text": "trained on things that are like you know get name get current weather um so uh",
    "start": "1966159",
    "end": "1973120"
  },
  {
    "text": "yeah I mean you can hack in because you know functional programming has taught us that everything is just a function",
    "start": "1973120",
    "end": "1979080"
  },
  {
    "text": "like a constant is just a function that always returns the same thing um and so you can you can like hack it in there um",
    "start": "1979080",
    "end": "1985639"
  },
  {
    "text": "and instructor has some fun like kind of functional programming stuff built into it like May and and stuff so you know um",
    "start": "1985639",
    "end": "1993240"
  },
  {
    "text": "and also somebody did like dag construction where it's like you give it a schema for a dag Constructor and then",
    "start": "1993240",
    "end": "2000200"
  },
  {
    "text": "it like writes a dag of function calls instead of just a single function call so you can really go wild which is very",
    "start": "2000200",
    "end": "2006360"
  },
  {
    "text": "fun um and yeah most of the time when you generate",
    "start": "2006360",
    "end": "2015519"
  },
  {
    "text": "something if you want to extract something out of the output you want to display to the end user and then the",
    "start": "2015519",
    "end": "2021679"
  },
  {
    "text": "question of latency comes in that's why you it if we use this how do we solve",
    "start": "2021679",
    "end": "2027679"
  },
  {
    "text": "theam yeah so that is a great question the answer is that this basically breaks",
    "start": "2027679",
    "end": "2033320"
  },
  {
    "text": "your ability to stream um I think it's not not so this is maybe a little bit more",
    "start": "2033320",
    "end": "2040240"
  },
  {
    "text": "oriented to like back of house stuff where you're using language models to like handle data rather than using",
    "start": "2040240",
    "end": "2047399"
  },
  {
    "text": "language models to directly interact with a user um I think if you set up a pipeline",
    "start": "2047399",
    "end": "2054599"
  },
  {
    "text": "correctly then you can stream the outputs from one call into the inputs of the next one and if you have the",
    "start": "2054599",
    "end": "2062079"
  },
  {
    "text": "relevant information you need from the fun the function call one then you can just immediately kick off off the next",
    "start": "2062079",
    "end": "2067440"
  },
  {
    "text": "thing and you can just you can write you know like more like a Unix pipe style and then you start to get back to being",
    "start": "2067440",
    "end": "2074200"
  },
  {
    "text": "uh streaming but you don't have like the Unix pipes work because of new lines as",
    "start": "2074200",
    "end": "2079560"
  },
  {
    "text": "a separator that lets you break work out and there's not an obvious way to do that with this um so yeah the short",
    "start": "2079560",
    "end": "2086800"
  },
  {
    "text": "answer I guess is that it's really hard to get back that kind of streaming thing when using these um yeah um I'm going to",
    "start": "2086800",
    "end": "2094679"
  },
  {
    "text": "let's see how much more do I have I'm I'm going to push forward because I want to make sure to get to the last section",
    "start": "2094679",
    "end": "2100160"
  },
  {
    "text": "um but I will be around to answer people's questions um okay so uh this",
    "start": "2100160",
    "end": "2106280"
  },
  {
    "start": "2103000",
    "end": "2452000"
  },
  {
    "text": "conference is not called NLP engineer Summit and we've been talking about like",
    "start": "2106280",
    "end": "2112160"
  },
  {
    "text": "you know structured out extracting structured outputs from language information retrieval like that's also natural language processing and language",
    "start": "2112160",
    "end": "2119520"
  },
  {
    "text": "user interfaces like that's not artificial intelligence like where is the AI the like the thing that really",
    "start": "2119520",
    "end": "2125599"
  },
  {
    "text": "feels like artificial intelligence with language models is something like agents uh that are that have memory that they",
    "start": "2125599",
    "end": "2133880"
  },
  {
    "text": "keep over time uh so for example the generative agents um that was uh let's",
    "start": "2133880",
    "end": "2140800"
  },
  {
    "text": "see it's mostly St for people I remember correctly but uh the like generative",
    "start": "2140800",
    "end": "2146079"
  },
  {
    "text": "agents paper uh combined like a stream of memories generated as these agents",
    "start": "2146079",
    "end": "2152079"
  },
  {
    "text": "interacted in like a video game environment with like some like reasoning flows to create these like",
    "start": "2152079",
    "end": "2159079"
  },
  {
    "text": "little tiny characters that had personalities that developed over time in interaction with each other and like",
    "start": "2159079",
    "end": "2165960"
  },
  {
    "text": "um and that is uh like much closer to",
    "start": "2165960",
    "end": "2172240"
  },
  {
    "text": "what people imagine when they hear AI than even a chatbot um and there's been a lot of",
    "start": "2172240",
    "end": "2179960"
  },
  {
    "text": "advancement in uh using these things in simulated environments so that was like",
    "start": "2179960",
    "end": "2185280"
  },
  {
    "text": "a full all language models simulated environment with generative agents there's also a ton of really cool stuff",
    "start": "2185280",
    "end": "2190720"
  },
  {
    "text": "going on in the Minecraft world um which is like people have uh this Voyager",
    "start": "2190720",
    "end": "2197200"
  },
  {
    "text": "agent writes JavaScript code yeah Javas yeah JavaScript code to call the like",
    "start": "2197200",
    "end": "2204960"
  },
  {
    "text": "this like Minecraft API that allows it to like drive a little um uh you know a",
    "start": "2204960",
    "end": "2210119"
  },
  {
    "text": "little character in the Minecraft world and it starts with basically nothing um and then it writes itself a bunch of",
    "start": "2210119",
    "end": "2215240"
  },
  {
    "text": "little sub routines to like minewood log or like stab zombie or whatever and it",
    "start": "2215240",
    "end": "2220520"
  },
  {
    "text": "like accumulates them over time like learns how to do new stuff um like comes up with its own curriculum for how to so",
    "start": "2220520",
    "end": "2227800"
  },
  {
    "text": "like how to get better um and was able to like do extremely well at this uh notoriously hard RL task uh M Diamond uh",
    "start": "2227800",
    "end": "2237160"
  },
  {
    "text": "which was like a uh a grand challenge for the RL World um only a couple of years ago um so they're like they can",
    "start": "2237160",
    "end": "2246880"
  },
  {
    "text": "accumulate information over time they can accumulate skills over time they can use tools this is all very cool um they",
    "start": "2246880",
    "end": "2253640"
  },
  {
    "text": "are they've a couple of problems the biggest one being the like problem of reliability um structured outputs can",
    "start": "2253640",
    "end": "2260680"
  },
  {
    "text": "help with that and there's like only limited work I would say on agents that has come out since at least like",
    "start": "2260680",
    "end": "2267560"
  },
  {
    "text": "published you know research work since the like since function calling got",
    "start": "2267560",
    "end": "2273599"
  },
  {
    "text": "really good in the open a API um the also there's kind of like a cacophony of",
    "start": "2273599",
    "end": "2278720"
  },
  {
    "text": "different techniques out there with like Voyager uh react is kind of an agent um",
    "start": "2278720",
    "end": "2284319"
  },
  {
    "text": "generative agents um there's a really like awesome paper from uh Tom",
    "start": "2284319",
    "end": "2289760"
  },
  {
    "text": "Griffith's group at Princeton cognitive architectures for language agents that brings back a bunch of ideas from good",
    "start": "2289760",
    "end": "2295119"
  },
  {
    "text": "old fashioned AI in the 80s on like um production systems uh and cognitive",
    "start": "2295119",
    "end": "2300880"
  },
  {
    "text": "architectures a bunch of stuff that was like really cool ideas but it could never like get past the demo stage um on",
    "start": "2300880",
    "end": "2307359"
  },
  {
    "text": "like how to create the things that we know about or that we believe about",
    "start": "2307359",
    "end": "2312400"
  },
  {
    "text": "human and animal cognition like procedur Memories semantic memories episodic memories how to implement that in",
    "start": "2312400",
    "end": "2318040"
  },
  {
    "text": "software and the problem like those systems could do cool stuff but the problem is always that they lacked this like General World Knowledge and common",
    "start": "2318040",
    "end": "2324160"
  },
  {
    "text": "sense with language models they don't have memory um and they don't um like",
    "start": "2324160",
    "end": "2330800"
  },
  {
    "text": "they don't have this like structured aspect to their cognition um but they do have that like World Knowledge and that",
    "start": "2330800",
    "end": "2337079"
  },
  {
    "text": "Common Sense uh so this is uh like mushing those two things together and",
    "start": "2337079",
    "end": "2342839"
  },
  {
    "text": "using a language model to do um basically these kinds of like uh",
    "start": "2342839",
    "end": "2348560"
  },
  {
    "text": "observing the world or doing cognition um and doing decision procedures um like",
    "start": "2348560",
    "end": "2355640"
  },
  {
    "text": "Mary is the best of both worlds um and it is actually like a pretty effective",
    "start": "2355640",
    "end": "2361400"
  },
  {
    "text": "way of breaking down the existing agent architectures uh like in their different Cho about how to do long-term memory how",
    "start": "2361400",
    "end": "2368960"
  },
  {
    "text": "to do external grounding how they like interact with the external World um the concept of internal actions uh comes",
    "start": "2368960",
    "end": "2376200"
  },
  {
    "text": "from cognitive architectures um which is like uh choosing to spend time reasoning or choosing to update your like",
    "start": "2376200",
    "end": "2383160"
  },
  {
    "text": "long-term memory um or yeah or your decision procedure yeah and then also explicitly calling out a decision-making",
    "start": "2383160",
    "end": "2389920"
  },
  {
    "text": "procedure um so there's a and that that paper is also just like has an entire research agenda in it um on like ways",
    "start": "2389920",
    "end": "2397200"
  },
  {
    "text": "that you could just start filling out the cross product just filling out a big array of like try this idea from",
    "start": "2397200",
    "end": "2403520"
  },
  {
    "text": "language models with like this idea from cognitive architectures um and there's",
    "start": "2403520",
    "end": "2408560"
  },
  {
    "text": "just like a billion uh really cool ideas in there um so if you are interested in",
    "start": "2408560",
    "end": "2414040"
  },
  {
    "text": "agents um but have like struggled to like uh like wrap your brain around all",
    "start": "2414040",
    "end": "2419920"
  },
  {
    "text": "the different ways you could you could do stuff um and around like how to make",
    "start": "2419920",
    "end": "2425319"
  },
  {
    "text": "them a little bit more te uh I think the koala paper has some good",
    "start": "2425319",
    "end": "2431960"
  },
  {
    "text": "pointers um oh yeah and then lastly for this LM patterns thing I was talking",
    "start": "2431960",
    "end": "2437319"
  },
  {
    "text": "generally about like different ways people are building stuff with LMS Eugene's Blog has some of the best uh",
    "start": "2437319",
    "end": "2442599"
  },
  {
    "text": "writing on this um uh both on uh patterns and",
    "start": "2442599",
    "end": "2449000"
  },
  {
    "text": "anti-patterns okay um I want to give some time for monitoring evaluation observability so I'm just going to I",
    "start": "2449359",
    "end": "2455839"
  },
  {
    "start": "2452000",
    "end": "2742000"
  },
  {
    "text": "know there's probably lots of interesting things that people have to say on the agent stuff but we'll we have",
    "start": "2455839",
    "end": "2461440"
  },
  {
    "text": "the rest of the conference to talk about that um so uh the goal here is to talk",
    "start": "2461440",
    "end": "2466680"
  },
  {
    "text": "about AI engineering so that last part was about AI what about the engineering in engineering we want to have a process",
    "start": "2466680",
    "end": "2472480"
  },
  {
    "text": "for building like a process for creating these things and a process for improving them and progress on this front has been",
    "start": "2472480",
    "end": "2479640"
  },
  {
    "text": "pretty halting um and so the the like the dominant ideology right now is that",
    "start": "2479640",
    "end": "2486000"
  },
  {
    "text": "you should ship to learn rather than learning to ship um and so this is one",
    "start": "2486000",
    "end": "2491560"
  },
  {
    "text": "of the big ideas in the fullstack Deep learning course that I've taught in it's something that Andre karpathy has really",
    "start": "2491560",
    "end": "2498400"
  },
  {
    "text": "hammered on the like idea of a data engine or data flywheel where in order to do well you need to go out there and",
    "start": "2498400",
    "end": "2503880"
  },
  {
    "text": "collect data from the world uh find issues in your data and use that to improve your model in like you know uh",
    "start": "2503880",
    "end": "2510800"
  },
  {
    "text": "an an unending cycle um charity Majors from honeycomb uh who's Big in the monitoring observability world uh like",
    "start": "2510800",
    "end": "2518599"
  },
  {
    "text": "has said that this is something that she has come to like about ml in software you start with tests and then you",
    "start": "2518599",
    "end": "2523960"
  },
  {
    "text": "graduate production when the tests pass or at least like that's what you tell people on the internet and like your manager um uh but with ML you can even",
    "start": "2523960",
    "end": "2532359"
  },
  {
    "text": "lie and you know that you have to like start with production use that to find out the like issues with uh to like",
    "start": "2532359",
    "end": "2538960"
  },
  {
    "text": "generate your tests so you know it's it's oops all regression tests uh",
    "start": "2538960",
    "end": "2544040"
  },
  {
    "text": "version um and so what that that means",
    "start": "2544040",
    "end": "2549319"
  },
  {
    "text": "is that monitoring is very critical from the very beginning um that we monitor for user Behavior we monitor for",
    "start": "2549319",
    "end": "2555119"
  },
  {
    "text": "performance and cost and we monitor for bugs so some of these are just like regular old monitoring stuff and this is",
    "start": "2555119",
    "end": "2561359"
  },
  {
    "text": "just like bread and butter things that can be uh yeah like similar to the way",
    "start": "2561359",
    "end": "2567160"
  },
  {
    "text": "we do with with uh existing software monitoring users always reveals like uh",
    "start": "2567160",
    "end": "2573200"
  },
  {
    "text": "like both misuse and product insights so one thing that I found from running this Discord bot is like one of the things",
    "start": "2573200",
    "end": "2579240"
  },
  {
    "text": "that you get the most are like meta questions like uh are you getting feedback from these emojis who's a good",
    "start": "2579240",
    "end": "2585440"
  },
  {
    "text": "bot that's maybe an automatic question um does your data set include your own source code U what do you do like these",
    "start": "2585440",
    "end": "2590599"
  },
  {
    "text": "are very common like things that people input and it wasn't it wasn't in my head that that was important so now there's",
    "start": "2590599",
    "end": "2596200"
  },
  {
    "text": "like special stuff in the prompt for handling that class of questions so by monitoring how users use the uh your",
    "start": "2596200",
    "end": "2603680"
  },
  {
    "text": "your system you can get really great product insights yeah",
    "start": "2603680",
    "end": "2609078"
  },
  {
    "text": "did oh yeah uh I had logged them to Gantry and then I looked at the ones that had up and down thumbs um and I",
    "start": "2610240",
    "end": "2617880"
  },
  {
    "text": "also read all of them because it was like only a couple hundred rows oh man my batter is going to run",
    "start": "2617880",
    "end": "2625079"
  },
  {
    "text": "out uh all right we got to move fast um so uh modering modering performance uh",
    "start": "2625079",
    "end": "2631319"
  },
  {
    "text": "can help us manage the constraints that I like talked about when we were thinking about all the different places",
    "start": "2631319",
    "end": "2637000"
  },
  {
    "text": "um our models might run so with as always you want to monitor things like latency quantiles like like how long do",
    "start": "2637000",
    "end": "2644640"
  },
  {
    "text": "requests take oh wow that's nice thank you",
    "start": "2644640",
    "end": "2650559"
  },
  {
    "text": "huge um and so like latency quantiles like that's how long like take all the",
    "start": "2650559",
    "end": "2656680"
  },
  {
    "text": "requests what is the probability that a request took at least this long um the people often think like if I get 90% of",
    "start": "2656680",
    "end": "2663599"
  },
  {
    "text": "them like below something that's great and and the problem with thinking that way is that users don't just make one",
    "start": "2663599",
    "end": "2670359"
  },
  {
    "text": "request they make many requests in sequence so by the time you've made like 30 requests if there's 10% chance of hitting like a really slow one then um",
    "start": "2670359",
    "end": "2677480"
  },
  {
    "text": "you know you have hit a slow request so that um so you really need to care about those like 99th percentile latencies",
    "start": "2677480",
    "end": "2684440"
  },
  {
    "text": "those are also often your most useful and engaged users so watch those watch those extreme quantiles um and obviously",
    "start": "2684440",
    "end": "2692520"
  },
  {
    "text": "like throughput is a distinct thing to also monitor for the quality uh you know",
    "start": "2692520",
    "end": "2697559"
  },
  {
    "text": "quality of the system want to marry that with things like the profiles and traces that I talked about before like spot",
    "start": "2697559",
    "end": "2703240"
  },
  {
    "text": "check ones randomly subsampled so you can check what like so you can actually debug that through the throughput issues",
    "start": "2703240",
    "end": "2710000"
  },
  {
    "text": "that's fairly General stuff if you're an INF using inference as a service provider you're going to want to monitor API rates and errors monitor costs if",
    "start": "2710000",
    "end": "2717359"
  },
  {
    "text": "you're selfs serving inference you have a lot more stuff to monitor um and that's like compute",
    "start": "2717359",
    "end": "2723520"
  },
  {
    "text": "utilization um AI I guess I already talked about this uh yeah yeah well so",
    "start": "2723520",
    "end": "2728880"
  },
  {
    "text": "it's it's an even hard like maintaining the throughput when you're doing the inference yourself is like much more",
    "start": "2728880",
    "end": "2733920"
  },
  {
    "text": "your problem um and much more uh AI ml specific stuff um yeah okay monitoring",
    "start": "2733920",
    "end": "2742359"
  },
  {
    "start": "2742000",
    "end": "2982000"
  },
  {
    "text": "for bugs is another can of worms we'll talk about that in a second um this is",
    "start": "2742359",
    "end": "2747559"
  },
  {
    "text": "like just generally this is a very fast growing field um so there are generic",
    "start": "2747559",
    "end": "2752599"
  },
  {
    "text": "Monitoring observability Solutions for all kinds of like you know complex apps and and and web apps data dog Sentry New",
    "start": "2752599",
    "end": "2759559"
  },
  {
    "text": "Relic honeycomb like these are um like you can adapt those um and that might be",
    "start": "2759559",
    "end": "2765720"
  },
  {
    "text": "the thing that wins um there is uh you can of course just roll your own with",
    "start": "2765720",
    "end": "2771160"
  },
  {
    "text": "the like you know open open Telemetry compliant uh you know tooling and you",
    "start": "2771160",
    "end": "2776599"
  },
  {
    "text": "could use the existing mlops tooling so there's a lot of stuff that has been built for monitoring observability of",
    "start": "2776599",
    "end": "2782280"
  },
  {
    "text": "General ml applications so including weights and biases re used work um Fiddler arise and Gantry are the like",
    "start": "2782280",
    "end": "2789280"
  },
  {
    "text": "three larger startups in that space um with more of a focus on monitoring",
    "start": "2789280",
    "end": "2794839"
  },
  {
    "text": "systems in production and less on the like ml Ops like kind of like serving um",
    "start": "2794839",
    "end": "2801240"
  },
  {
    "text": "and like managing managing training like weights and biases um there's also",
    "start": "2801240",
    "end": "2806359"
  },
  {
    "text": "because generation times uh are now six months or less a new generation of Ops",
    "start": "2806359",
    "end": "2811599"
  },
  {
    "text": "tooling for llm Ops including Langs Smith from Lang chain and uh Lang fuse which was in y combinator recent batch",
    "start": "2811599",
    "end": "2819040"
  },
  {
    "text": "um it's like very unclear which of these is going to be the the best solution so",
    "start": "2819040",
    "end": "2824319"
  },
  {
    "text": "I think it's like you dealer's Choice try them all out um I think I like tools with as much ability to like make crazy",
    "start": "2824319",
    "end": "2832640"
  },
  {
    "text": "queries of unstructured data as possible um so that's something that I really like about weights and biases production",
    "start": "2832640",
    "end": "2838480"
  },
  {
    "text": "monitoring uh offering um Gantry has some similar stuff um I've tried less of",
    "start": "2838480",
    "end": "2843720"
  },
  {
    "text": "it with the uh the other tools um I think if you're doing if you're doing it with data dog Sentry Etc you're probably",
    "start": "2843720",
    "end": "2850680"
  },
  {
    "text": "going to need to roll some of that stuff yourself um but maybe that's fine Jupiter notebooks are",
    "start": "2850680",
    "end": "2856040"
  },
  {
    "text": "fun um I was going to check out the like Lang fuse monitoring interface but um in",
    "start": "2856040",
    "end": "2862000"
  },
  {
    "text": "interest of time going to go past that they have an awesome demo where you can interact with their docs chatbot and it",
    "start": "2862000",
    "end": "2868559"
  },
  {
    "text": "shows up in their monitoring interface so like they have a live demo of their monitoring tool where you can actually",
    "start": "2868559",
    "end": "2874040"
  },
  {
    "text": "like use it to monitor an app that you can also use um so that's just it's",
    "start": "2874040",
    "end": "2879520"
  },
  {
    "text": "really it was really fun to like actually try out the the tool that way um I recommend you try it out um but",
    "start": "2879520",
    "end": "2888040"
  },
  {
    "text": "just monitoring like just getting a hold of information is not enough this is something that's known from like the",
    "start": "2888040",
    "end": "2894079"
  },
  {
    "text": "distributed systems monitoring world what you really want is observability what both charity and Andre were talking",
    "start": "2894079",
    "end": "2900960"
  },
  {
    "text": "about is about how you improve a system based off of what You observe it's like not enough to just like throw something",
    "start": "2900960",
    "end": "2907599"
  },
  {
    "text": "out there and observe and like just see the mistakes you want to like fix the",
    "start": "2907599",
    "end": "2912839"
  },
  {
    "text": "mistakes um and so there's this uh honeycomb and uh charity are big on the",
    "start": "2912839",
    "end": "2919440"
  },
  {
    "text": "idea of observability as the uh as an idea from like control theory from like",
    "start": "2919440",
    "end": "2925200"
  },
  {
    "text": "old school um like control theory systems theory uh observability is",
    "start": "2925200",
    "end": "2930960"
  },
  {
    "text": "whether you can actually um figure out what is going on inside of a system system just from observing it from the",
    "start": "2930960",
    "end": "2937520"
  },
  {
    "text": "outside so it's like can you actually debug this software just from looking at your logs um and not having to go into a",
    "start": "2937520",
    "end": "2944760"
  },
  {
    "text": "live debugger inside of the system um and that's like uh when live debugging",
    "start": "2944760",
    "end": "2952760"
  },
  {
    "text": "does not work and when systems have outpaced our ability to predict what's going to break um this is the only",
    "start": "2952760",
    "end": "2959680"
  },
  {
    "text": "solution uh and for AI systems that is um where we can't predict what's going",
    "start": "2959680",
    "end": "2966160"
  },
  {
    "text": "to break and you can't like drop into a debugger 13 layers deep in gpt3 and or",
    "start": "2966160",
    "end": "2971720"
  },
  {
    "text": "gp4 and like debug uh it's inference U you have no choice but to monitor stuff",
    "start": "2971720",
    "end": "2977079"
  },
  {
    "text": "sufficiently that you can fix the issues the blocker here is that actually",
    "start": "2977079",
    "end": "2984079"
  },
  {
    "start": "2982000",
    "end": "3348000"
  },
  {
    "text": "determining whether the model is right or wrong um is itself hard which makes",
    "start": "2984079",
    "end": "2989720"
  },
  {
    "text": "figuring out how to fix it also hard because you don't necessarily know whether it's messing up and you don't",
    "start": "2989720",
    "end": "2995079"
  },
  {
    "text": "know what whether you fixed it um so we're in a tough phase for this problem",
    "start": "2995079",
    "end": "3000359"
  },
  {
    "text": "right now there will be lots of discussion of evaluation at this conference which is very exciting um",
    "start": "3000359",
    "end": "3006040"
  },
  {
    "text": "lots of people complaining about how difficult evaluation is anthropic and Arvin nin from Andes kapor who write the",
    "start": "3006040",
    "end": "3013760"
  },
  {
    "text": "AI snake oil substack really high quality stuff um and open AI like open",
    "start": "3013760",
    "end": "3020000"
  },
  {
    "text": "source their eval framework uh because in part they like don't can't really",
    "start": "3020000",
    "end": "3025079"
  },
  {
    "text": "evaluate their system themselves it's like that's how hard this problem is um it's also what we saw with the false",
    "start": "3025079",
    "end": "3032000"
  },
  {
    "text": "promise of imitating proprietary LMS like a large community of people were like kind of convinced that models were",
    "start": "3032000",
    "end": "3037440"
  },
  {
    "text": "doing better than they actually were um so the solution uh like is to",
    "start": "3037440",
    "end": "3044880"
  },
  {
    "text": "like one of the key Solutions spend time looking at your data Stella Beerman from a Luther has talked about this uh Jason",
    "start": "3044880",
    "end": "3050960"
  },
  {
    "text": "we has talked about how critical this is Jason is at open AI now um and talked about spending like a ton of time just",
    "start": "3050960",
    "end": "3057559"
  },
  {
    "text": "like getting very good at evals like building tooling internal tooling for evals spending time with like",
    "start": "3057559",
    "end": "3064359"
  },
  {
    "text": "understanding the evaluations um and somebody on Hacker News said it's a major differentiator so you know that's",
    "start": "3064359",
    "end": "3070720"
  },
  {
    "text": "that's definitely the orange website never lies um so um evaluation is",
    "start": "3070720",
    "end": "3077520"
  },
  {
    "text": "particularly hard and all these complaints about evaluation are when you're dealing with like open-ended Generations from a language model like",
    "start": "3077520",
    "end": "3083599"
  },
  {
    "text": "no structure to them um no no real structure to the user inputs um and like",
    "start": "3083599",
    "end": "3090119"
  },
  {
    "text": "limited data sources um but there's this nice flow chart um from the full stack",
    "start": "3090119",
    "end": "3095640"
  },
  {
    "text": "LM boot camp that my fellow instructor Josh Tobin made that sort of helps you avoid getting into that uh pit of",
    "start": "3095640",
    "end": "3103520"
  },
  {
    "text": "evaluations so if you can find a correct answer then you can stick with existing ml metrics and you like don't have to",
    "start": "3103520",
    "end": "3110559"
  },
  {
    "text": "worry about the problems of EV of like the difficulty of evaluating open-ended Generations if you you have a reference",
    "start": "3110559",
    "end": "3116240"
  },
  {
    "text": "answer you can check for like reference matching which is like a looser thing than like a literal correct answer which",
    "start": "3116240",
    "end": "3121599"
  },
  {
    "text": "is like a BC or D in multiple choice is a correct answer a reference answer is like a short like generation like a",
    "start": "3121599",
    "end": "3129160"
  },
  {
    "text": "short answer on the test um if you have a previous answer from your system you can at least see if your system is",
    "start": "3129160",
    "end": "3134480"
  },
  {
    "text": "getting better by comparing the two um and that like kind of which is better comparison can be done by a human can be",
    "start": "3134480",
    "end": "3140200"
  },
  {
    "text": "done by a language model um and if you have human feedback you can actually check like between",
    "start": "3140200",
    "end": "3146079"
  },
  {
    "text": "uh the input and the output was the feedback Incorporated by the language model like a human said I didn't like",
    "start": "3146079",
    "end": "3151440"
  },
  {
    "text": "that um did the language model get better and it's only if you don't have any of those things that you like are",
    "start": "3151440",
    "end": "3157119"
  },
  {
    "text": "out in the unstructured world um the people at elicit um who have worked on",
    "start": "3157119",
    "end": "3164960"
  },
  {
    "text": "doing extraction of information from scientific papers have a very principal approach of iterated decomposition where",
    "start": "3164960",
    "end": "3170880"
  },
  {
    "text": "you start with a task that runs end to end and then you uh when you Noti notice a failure you look at the failures and",
    "start": "3170880",
    "end": "3177880"
  },
  {
    "text": "you see how you could have broken the task out into multiple pieces in such a way that the failure would arise in a",
    "start": "3177880",
    "end": "3184400"
  },
  {
    "text": "simpler subtask and then optimize that subtask so you run into the problem",
    "start": "3184400",
    "end": "3189720"
  },
  {
    "text": "that's been mentioned before about latency if you're like chaining calls um and it's not always easy to like",
    "start": "3189720",
    "end": "3195599"
  },
  {
    "text": "decompose the for example to decompose the process of responding to a user in a chatbot that's kind of challenging um",
    "start": "3195599",
    "end": "3202599"
  },
  {
    "text": "but uh but when you can do this this is another great way to like get yourself out of the hole of needing to evaluate",
    "start": "3202599",
    "end": "3209240"
  },
  {
    "text": "open-ended Generations but if you're stuck evaluating natural text there's a couple of like basic approaches um you",
    "start": "3209240",
    "end": "3216440"
  },
  {
    "text": "can just uh keep a few trusty test cases at hand um and uh you know if it does",
    "start": "3216440",
    "end": "3222319"
  },
  {
    "text": "well on those couple of test cases looks good to me let's ship it um unclear what to do when it fails just like hit the",
    "start": "3222319",
    "end": "3228839"
  },
  {
    "text": "language model with a wrench um but uh this is what kind of grows out into that",
    "start": "3228839",
    "end": "3234160"
  },
  {
    "text": "data engine you start start with something like this then you start adding stuff from your production observations into it and then you like",
    "start": "3234160",
    "end": "3240280"
  },
  {
    "text": "put it in a GitHub action and like now that's like that's that's basically testing right um that's is certified",
    "start": "3240280",
    "end": "3247319"
  },
  {
    "text": "software um you can like uh you can try and get user feedback and you want to do",
    "start": "3247319",
    "end": "3252760"
  },
  {
    "text": "it as naturally as possible um like uh if you're like you would you really want",
    "start": "3252760",
    "end": "3258599"
  },
  {
    "text": "to reveal preferences from user Behavior so the image generation world is very ahead of the language modeling world I",
    "start": "3258599",
    "end": "3264640"
  },
  {
    "text": "think on this if you look at Mid Journey for example um that is what honeycomb did with their query Builder they",
    "start": "3264640",
    "end": "3270799"
  },
  {
    "text": "attached it to get this Downstream business objectives wow what a way to",
    "start": "3270799",
    "end": "3276000"
  },
  {
    "text": "build a software system that's the right way to do it um and so like connecting a chain of metrics from the actual system",
    "start": "3276000",
    "end": "3282640"
  },
  {
    "text": "that you're improving to the actual Downstream like organizational goals um uh through things like reveal",
    "start": "3282640",
    "end": "3289200"
  },
  {
    "text": "preferences of users or like yeah General user Behavior much better than like demanding users fill out form um",
    "start": "3289200",
    "end": "3296440"
  },
  {
    "text": "you would also pay people to do that work of giving you feedback on your system with an annotation team this is",
    "start": "3296440",
    "end": "3301480"
  },
  {
    "text": "what the large this is what open AI does to improve their models but as alluded to by Karina it's actually much more",
    "start": "3301480",
    "end": "3308200"
  },
  {
    "text": "effective to use language models in that place because language models are maybe not as smart as all humans uh but they",
    "start": "3308200",
    "end": "3314920"
  },
  {
    "text": "tend to outperform crowd workers um on uh a large number of very textual tasks",
    "start": "3314920",
    "end": "3321319"
  },
  {
    "text": "um and so um you might find that the task of like annotating and improving",
    "start": "3321319",
    "end": "3326520"
  },
  {
    "text": "your data if you're at the point where you're starting to think about crowd workers you'll find lower cost for equal performance with uh like gbd 3.5 turbo",
    "start": "3326520",
    "end": "3334160"
  },
  {
    "text": "is like a median crowd worker gbd4 is like a 90th percentile crowd worker um and maybe a hybrid approach with some",
    "start": "3334160",
    "end": "3340480"
  },
  {
    "text": "crowd workers a smaller number of crowd workers managing uh some language models is also been",
    "start": "3340480",
    "end": "3347200"
  },
  {
    "text": "discussed um all right so the there's like not that much to say in the end",
    "start": "3347200",
    "end": "3352400"
  },
  {
    "start": "3348000",
    "end": "3417000"
  },
  {
    "text": "about that like that aspect of the engineering of syst systems we don't know what the user interfaces and the",
    "start": "3352400",
    "end": "3357440"
  },
  {
    "text": "user experiences are going to look like we don't know uh we don't know a lot about how to engineer these things to be",
    "start": "3357440",
    "end": "3362799"
  },
  {
    "text": "correct um so uh I guess the exciting thing about that is that the people who",
    "start": "3362799",
    "end": "3368400"
  },
  {
    "text": "are here in this room on the stream at the summit are here to fill in all of the steps here that lead to from the",
    "start": "3368400",
    "end": "3375599"
  },
  {
    "text": "circle to the fully drawn owl um by like uh uh by figuring it out um by like",
    "start": "3375599",
    "end": "3382599"
  },
  {
    "text": "trying things and sharing what works like people would at this conference um so that's why I'm excited to be here and",
    "start": "3382599",
    "end": "3387760"
  },
  {
    "text": "I hope you are as well all right thank you [Applause]",
    "start": "3387760",
    "end": "3394570"
  },
  {
    "text": "[Music] [Applause] [Music]",
    "start": "3394570",
    "end": "3413880"
  },
  {
    "text": "everyone oh",
    "start": "3413880",
    "end": "3418200"
  }
]
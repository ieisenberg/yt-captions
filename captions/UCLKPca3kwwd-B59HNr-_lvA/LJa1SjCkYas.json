[
  {
    "text": "[Music]",
    "start": "3520",
    "end": "7860"
  },
  {
    "text": "hey everyone thanks so much for coming",
    "start": "13400",
    "end": "15000"
  },
  {
    "text": "I'm Hamza from an applied research",
    "start": "15000",
    "end": "16880"
  },
  {
    "text": "scientist at snorkel on the uh computer",
    "start": "16880",
    "end": "19000"
  },
  {
    "text": "vision team uh working on fine-tuning",
    "start": "19000",
    "end": "21880"
  },
  {
    "text": "you know Foundation models for",
    "start": "21880",
    "end": "23359"
  },
  {
    "text": "Enterprise use",
    "start": "23359",
    "end": "25279"
  },
  {
    "text": "cases thanks amza um I like the ears uh",
    "start": "25279",
    "end": "30320"
  },
  {
    "text": "thank",
    "start": "30320",
    "end": "31599"
  },
  {
    "text": "you why don't you start out by telling",
    "start": "31599",
    "end": "34079"
  },
  {
    "text": "the folks a little bit about uh snorkel",
    "start": "34079",
    "end": "36840"
  },
  {
    "text": "and what you do there it's a it's an",
    "start": "36840",
    "end": "39040"
  },
  {
    "text": "interesting name any relation to like AI",
    "start": "39040",
    "end": "41440"
  },
  {
    "text": "for scuba diving or anything like that",
    "start": "41440",
    "end": "43520"
  },
  {
    "text": "uh well hot tubs actually because",
    "start": "43520",
    "end": "45280"
  },
  {
    "text": "snorkel doccom once I joined the company",
    "start": "45280",
    "end": "47640"
  },
  {
    "text": "I learned as a hot tub company but no",
    "start": "47640",
    "end": "50520"
  },
  {
    "text": "actually we don't do anything for scuba",
    "start": "50520",
    "end": "52960"
  },
  {
    "text": "diving or hot tubbing um and to give a",
    "start": "52960",
    "end": "55719"
  },
  {
    "text": "little bit of context the main problem",
    "start": "55719",
    "end": "57359"
  },
  {
    "text": "that we're trying to solve is like you",
    "start": "57359",
    "end": "58840"
  },
  {
    "text": "know data Dev vment for the Enterprise",
    "start": "58840",
    "end": "61840"
  },
  {
    "text": "so uh what one key thing that I kind of",
    "start": "61840",
    "end": "64960"
  },
  {
    "text": "want to take note of is the fact that",
    "start": "64960",
    "end": "66680"
  },
  {
    "text": "you know out of the box llms rarely meet",
    "start": "66680",
    "end": "69000"
  },
  {
    "text": "Enterprise quality latency and cost",
    "start": "69000",
    "end": "71640"
  },
  {
    "text": "requirements you know to give some",
    "start": "71640",
    "end": "73520"
  },
  {
    "text": "context our customers are like Fortune",
    "start": "73520",
    "end": "75320"
  },
  {
    "text": "500 companies like Banks insurance",
    "start": "75320",
    "end": "77759"
  },
  {
    "text": "companies places like that and for them",
    "start": "77759",
    "end": "80000"
  },
  {
    "text": "to deploy their models they really need",
    "start": "80000",
    "end": "81720"
  },
  {
    "text": "them to be very reliable and very",
    "start": "81720",
    "end": "83600"
  },
  {
    "text": "accurate and off the-shelf models like",
    "start": "83600",
    "end": "86000"
  },
  {
    "text": "Claude or gp4 or or Gemini may get you",
    "start": "86000",
    "end": "89920"
  },
  {
    "text": "part of the way there but they but they",
    "start": "89920",
    "end": "91640"
  },
  {
    "text": "don't H have that you know final mile",
    "start": "91640",
    "end": "93439"
  },
  {
    "text": "that really you know says yes we can",
    "start": "93439",
    "end": "95720"
  },
  {
    "text": "like deploy these completely so what we",
    "start": "95720",
    "end": "98680"
  },
  {
    "text": "focus on is developing data to fine-tune",
    "start": "98680",
    "end": "101560"
  },
  {
    "text": "these models to get them",
    "start": "101560",
    "end": "103840"
  },
  {
    "text": "there so hza this this makes sense but",
    "start": "103840",
    "end": "107719"
  },
  {
    "text": "um why is it hard what what what's the",
    "start": "107719",
    "end": "109840"
  },
  {
    "text": "challenge in addressing this",
    "start": "109840",
    "end": "111560"
  },
  {
    "text": "issue yeah so uh data development is",
    "start": "111560",
    "end": "114880"
  },
  {
    "text": "fundamentally challenging and there's a",
    "start": "114880",
    "end": "116960"
  },
  {
    "text": "few key reasons for that one is that you",
    "start": "116960",
    "end": "119640"
  },
  {
    "text": "know rag is just a starting point you",
    "start": "119640",
    "end": "121560"
  },
  {
    "text": "know you guys may have heard of like you",
    "start": "121560",
    "end": "123039"
  },
  {
    "text": "know using like rag to hook up like you",
    "start": "123039",
    "end": "125680"
  },
  {
    "text": "know Enterprise knowledge databases to",
    "start": "125680",
    "end": "127799"
  },
  {
    "text": "these models and get them to help give",
    "start": "127799",
    "end": "130720"
  },
  {
    "text": "what you know these models were not",
    "start": "130720",
    "end": "132000"
  },
  {
    "text": "pre-trained on and I don't want to rag",
    "start": "132000",
    "end": "134000"
  },
  {
    "text": "on it it's great and all but it's just a",
    "start": "134000",
    "end": "136519"
  },
  {
    "text": "starting point you know it won't get you",
    "start": "136519",
    "end": "138640"
  },
  {
    "text": "all the way there and you know quality",
    "start": "138640",
    "end": "141280"
  },
  {
    "text": "in your data is absolutely key um and",
    "start": "141280",
    "end": "144640"
  },
  {
    "text": "finding and maintaining the right data",
    "start": "144640",
    "end": "146280"
  },
  {
    "text": "is critical um because you know a lot of",
    "start": "146280",
    "end": "149319"
  },
  {
    "text": "times you know",
    "start": "149319",
    "end": "150440"
  },
  {
    "text": "the common instruction toting data sets",
    "start": "150440",
    "end": "152560"
  },
  {
    "text": "may be very big but they don't contain",
    "start": "152560",
    "end": "154599"
  },
  {
    "text": "exactly the information that you need",
    "start": "154599",
    "end": "156879"
  },
  {
    "text": "like if you're training specifically on",
    "start": "156879",
    "end": "158440"
  },
  {
    "text": "I don't know a specific type of Bank",
    "start": "158440",
    "end": "160400"
  },
  {
    "text": "policy or a specific type of policy for",
    "start": "160400",
    "end": "163200"
  },
  {
    "text": "certain industries you need that very",
    "start": "163200",
    "end": "165879"
  },
  {
    "text": "key slice of information to be able to",
    "start": "165879",
    "end": "168239"
  },
  {
    "text": "really um improve these",
    "start": "168239",
    "end": "172080"
  },
  {
    "text": "models so I think folks have a good",
    "start": "172080",
    "end": "174879"
  },
  {
    "text": "understanding of what you guys do and",
    "start": "174879",
    "end": "177280"
  },
  {
    "text": "and why you do it why don't you talk a",
    "start": "177280",
    "end": "178879"
  },
  {
    "text": "little bit about what",
    "start": "178879",
    "end": "180400"
  },
  {
    "text": "snorkel is and what you're famous for",
    "start": "180400",
    "end": "182400"
  },
  {
    "text": "besides the interesting",
    "start": "182400",
    "end": "184599"
  },
  {
    "text": "name yeah so uh snorkel Pioneer data",
    "start": "184599",
    "end": "187799"
  },
  {
    "text": "development uh for llms and we're",
    "start": "187799",
    "end": "189799"
  },
  {
    "text": "trusted by you know many different",
    "start": "189799",
    "end": "191319"
  },
  {
    "text": "companies we've worked with lots of",
    "start": "191319",
    "end": "193200"
  },
  {
    "text": "companies in like you know the Fortune",
    "start": "193200",
    "end": "194519"
  },
  {
    "text": "500 and all that um we were spun up out",
    "start": "194519",
    "end": "197640"
  },
  {
    "text": "of the Stanford AI lab quite a while ago",
    "start": "197640",
    "end": "199760"
  },
  {
    "text": "and have a lot like you know decade of",
    "start": "199760",
    "end": "201840"
  },
  {
    "text": "experience in like data development",
    "start": "201840",
    "end": "203519"
  },
  {
    "text": "because it's keyed like you know many",
    "start": "203519",
    "end": "205120"
  },
  {
    "text": "aspects of ML and we've published many",
    "start": "205120",
    "end": "207200"
  },
  {
    "text": "papers and you know a lot of hot Fields",
    "start": "207200",
    "end": "209480"
  },
  {
    "text": "like prompting Rag architectures and so",
    "start": "209480",
    "end": "212840"
  },
  {
    "text": "on okay nice um I think we're going to",
    "start": "212840",
    "end": "216760"
  },
  {
    "text": "switch uh context here for a bit and",
    "start": "216760",
    "end": "219040"
  },
  {
    "text": "talk a little bit about the specific",
    "start": "219040",
    "end": "221120"
  },
  {
    "text": "research projects you you guys are",
    "start": "221120",
    "end": "223720"
  },
  {
    "text": "focused on um you guys take a research",
    "start": "223720",
    "end": "226400"
  },
  {
    "text": "first culture why don't you explain a",
    "start": "226400",
    "end": "229720"
  },
  {
    "text": "little bit about that and and the",
    "start": "229720",
    "end": "232599"
  },
  {
    "text": "projects yeah thanks Loy so uh first I",
    "start": "232599",
    "end": "235680"
  },
  {
    "text": "kind of want to talk a little bit about",
    "start": "235680",
    "end": "237079"
  },
  {
    "text": "our research Focus overall uh so really",
    "start": "237079",
    "end": "240360"
  },
  {
    "text": "what we the core question we try to",
    "start": "240360",
    "end": "242000"
  },
  {
    "text": "answer is how can Enterprises best",
    "start": "242000",
    "end": "243599"
  },
  {
    "text": "develop their data for custom AI models",
    "start": "243599",
    "end": "246400"
  },
  {
    "text": "um you know so we have there are a few",
    "start": "246400",
    "end": "248319"
  },
  {
    "text": "different directions we want to pursue",
    "start": "248319",
    "end": "249879"
  },
  {
    "text": "overall one is keeping eses in the loop",
    "start": "249879",
    "end": "252640"
  },
  {
    "text": "while maximizing the value of their time",
    "start": "252640",
    "end": "255159"
  },
  {
    "text": "um you know because again like for a lot",
    "start": "255159",
    "end": "256919"
  },
  {
    "text": "of these industries we need the subject",
    "start": "256919",
    "end": "258519"
  },
  {
    "text": "matter experts that know the key details",
    "start": "258519",
    "end": "261120"
  },
  {
    "text": "in order to be able to um you know",
    "start": "261120",
    "end": "264040"
  },
  {
    "text": "provide feedback to models and help them",
    "start": "264040",
    "end": "265960"
  },
  {
    "text": "be able to improve um the second is you",
    "start": "265960",
    "end": "269240"
  },
  {
    "text": "know make data development programmatic",
    "start": "269240",
    "end": "271160"
  },
  {
    "text": "scalable and auditable uh because you",
    "start": "271160",
    "end": "274080"
  },
  {
    "text": "know while we do need smmes at the same",
    "start": "274080",
    "end": "276639"
  },
  {
    "text": "time we also need to make things",
    "start": "276639",
    "end": "279000"
  },
  {
    "text": "scalable in a way that solely manual",
    "start": "279000",
    "end": "281199"
  },
  {
    "text": "intervention isn't so it's really being",
    "start": "281199",
    "end": "282960"
  },
  {
    "text": "able to combine those two things",
    "start": "282960",
    "end": "285280"
  },
  {
    "text": "together that make make this important",
    "start": "285280",
    "end": "287840"
  },
  {
    "text": "and the third is continuous evaluation",
    "start": "287840",
    "end": "290240"
  },
  {
    "text": "with domain specific Dynamic benchmarks",
    "start": "290240",
    "end": "293320"
  },
  {
    "text": "um you know I'm sure you all have seen",
    "start": "293320",
    "end": "294919"
  },
  {
    "text": "things like lmis or whatnot and it's",
    "start": "294919",
    "end": "297120"
  },
  {
    "text": "pretty good to see you know a general",
    "start": "297120",
    "end": "299840"
  },
  {
    "text": "understanding of where a lot of these",
    "start": "299840",
    "end": "301400"
  },
  {
    "text": "llms fall in terms of their ability to",
    "start": "301400",
    "end": "303520"
  },
  {
    "text": "do things but for specific Industries",
    "start": "303520",
    "end": "305840"
  },
  {
    "text": "you need specific benchmarks to say how",
    "start": "305840",
    "end": "308039"
  },
  {
    "text": "good is it at this like you know uh a",
    "start": "308039",
    "end": "310880"
  },
  {
    "text": "bank isn't going to care about how how",
    "start": "310880",
    "end": "313880"
  },
  {
    "text": "well these llms do at say grade school",
    "start": "313880",
    "end": "316000"
  },
  {
    "text": "math right so there's that and I want to",
    "start": "316000",
    "end": "320520"
  },
  {
    "text": "go into a little bit more detail and",
    "start": "320520",
    "end": "322240"
  },
  {
    "text": "talk about some active research projects",
    "start": "322240",
    "end": "324479"
  },
  {
    "text": "we're working on right now one is f",
    "start": "324479",
    "end": "326880"
  },
  {
    "text": "grain evaluation and looking at you know",
    "start": "326880",
    "end": "329759"
  },
  {
    "text": "where evaluation for these models is",
    "start": "329759",
    "end": "331560"
  },
  {
    "text": "broken one particular area is you know",
    "start": "331560",
    "end": "334199"
  },
  {
    "text": "in Long context models um you know you",
    "start": "334199",
    "end": "336960"
  },
  {
    "text": "guys may have seen things like the",
    "start": "336960",
    "end": "338160"
  },
  {
    "text": "needle and the Hast stack test where you",
    "start": "338160",
    "end": "339919"
  },
  {
    "text": "take a bunch of like polyram essays and",
    "start": "339919",
    "end": "342240"
  },
  {
    "text": "insert some sentence and see how well it",
    "start": "342240",
    "end": "344639"
  },
  {
    "text": "can find that but you know we one thing",
    "start": "344639",
    "end": "347199"
  },
  {
    "text": "we found is that again that that doesn't",
    "start": "347199",
    "end": "349319"
  },
  {
    "text": "necessarily give a a proper sense of how",
    "start": "349319",
    "end": "351960"
  },
  {
    "text": "these models handle long context in",
    "start": "351960",
    "end": "353880"
  },
  {
    "text": "other domains and you know really again",
    "start": "353880",
    "end": "356000"
  },
  {
    "text": "breaking everything down domain by",
    "start": "356000",
    "end": "357639"
  },
  {
    "text": "domain is super critical so you know",
    "start": "357639",
    "end": "360440"
  },
  {
    "text": "figuring out how can we improve long",
    "start": "360440",
    "end": "362199"
  },
  {
    "text": "context",
    "start": "362199",
    "end": "363919"
  },
  {
    "text": "overall um another key area is",
    "start": "363919",
    "end": "366039"
  },
  {
    "text": "Enterprise alignment um you know making",
    "start": "366039",
    "end": "367960"
  },
  {
    "text": "sure that these llms comply with you",
    "start": "367960",
    "end": "370120"
  },
  {
    "text": "know company goals regulations and all",
    "start": "370120",
    "end": "372639"
  },
  {
    "text": "that you know we don't want our llms to",
    "start": "372639",
    "end": "374400"
  },
  {
    "text": "be committing any career limiting moves",
    "start": "374400",
    "end": "376479"
  },
  {
    "text": "while outputting text um and another",
    "start": "376479",
    "end": "380080"
  },
  {
    "text": "area which is particularly near and dear",
    "start": "380080",
    "end": "381720"
  },
  {
    "text": "to me because I work on it actively is",
    "start": "381720",
    "end": "383360"
  },
  {
    "text": "multimodal alignment um we find that you",
    "start": "383360",
    "end": "386160"
  },
  {
    "text": "know these models trained on public data",
    "start": "386160",
    "end": "387919"
  },
  {
    "text": "you know underperform and like you know",
    "start": "387919",
    "end": "390120"
  },
  {
    "text": "specific domains and one area we're",
    "start": "390120",
    "end": "392240"
  },
  {
    "text": "working on is using these large Vision",
    "start": "392240",
    "end": "394160"
  },
  {
    "text": "language models or lvms to be able to",
    "start": "394160",
    "end": "396960"
  },
  {
    "text": "generate synthetic data without manual",
    "start": "396960",
    "end": "398720"
  },
  {
    "text": "annotation to be able to train you know",
    "start": "398720",
    "end": "401280"
  },
  {
    "text": "Downstream models so kind of being able",
    "start": "401280",
    "end": "403000"
  },
  {
    "text": "to really have this flywheel of going",
    "start": "403000",
    "end": "404759"
  },
  {
    "text": "from like dat specific data generation",
    "start": "404759",
    "end": "406880"
  },
  {
    "text": "in the loop to um model training is",
    "start": "406880",
    "end": "409520"
  },
  {
    "text": "something that we're very excited",
    "start": "409520",
    "end": "412560"
  },
  {
    "text": "about that's great uh hamzo we we we're",
    "start": "412560",
    "end": "416800"
  },
  {
    "text": "excited that a lot of these projects are",
    "start": "416800",
    "end": "418720"
  },
  {
    "text": "happening on azure's AI infrastructure",
    "start": "418720",
    "end": "422000"
  },
  {
    "text": "obviously as well um I think if if you",
    "start": "422000",
    "end": "424639"
  },
  {
    "text": "forward the slides a little bit um I",
    "start": "424639",
    "end": "428319"
  },
  {
    "text": "think you know you went through an",
    "start": "428319",
    "end": "430360"
  },
  {
    "text": "experience with Azure uh getting on",
    "start": "430360",
    "end": "433039"
  },
  {
    "text": "board and running these projects I think",
    "start": "433039",
    "end": "435639"
  },
  {
    "text": "people are really interested to maybe",
    "start": "435639",
    "end": "437440"
  },
  {
    "text": "understand um what are the best",
    "start": "437440",
    "end": "439319"
  },
  {
    "text": "practices you had working with our",
    "start": "439319",
    "end": "441240"
  },
  {
    "text": "infrastructure some of the um uh",
    "start": "441240",
    "end": "445000"
  },
  {
    "text": "pitfalls and and the benefits as well um",
    "start": "445000",
    "end": "448400"
  },
  {
    "text": "you know uh the this one's my slide I uh",
    "start": "448400",
    "end": "451759"
  },
  {
    "text": "I think the way we think about",
    "start": "451759",
    "end": "454000"
  },
  {
    "text": "infrastructure that's supporting this",
    "start": "454000",
    "end": "455599"
  },
  {
    "text": "wave of AI it's really about optimizing",
    "start": "455599",
    "end": "458960"
  },
  {
    "text": "it in every sense possible for um for",
    "start": "458960",
    "end": "463800"
  },
  {
    "text": "the different AI applications and use",
    "start": "463800",
    "end": "466720"
  },
  {
    "text": "you know we look at everything from our",
    "start": "466720",
    "end": "468960"
  },
  {
    "text": "Azure data centers we have over 300",
    "start": "468960",
    "end": "471599"
  },
  {
    "text": "worldwide the CPU or the host so",
    "start": "471599",
    "end": "474159"
  },
  {
    "text": "combining our virtual machines with the",
    "start": "474159",
    "end": "475919"
  },
  {
    "text": "right uh CPUs um and offering the right",
    "start": "475919",
    "end": "479960"
  },
  {
    "text": "throughput uh the",
    "start": "479960",
    "end": "482120"
  },
  {
    "text": "accelerator um we use a diversity of of",
    "start": "482120",
    "end": "485199"
  },
  {
    "text": "accelerators from AMD and viar and our",
    "start": "485199",
    "end": "488120"
  },
  {
    "text": "own first-party silicon as well with the",
    "start": "488120",
    "end": "490680"
  },
  {
    "text": "Maya uh with the mea chip we have",
    "start": "490680",
    "end": "493680"
  },
  {
    "text": "topologies that you know optimize that",
    "start": "493680",
    "end": "495840"
  },
  {
    "text": "iio between the different layers and",
    "start": "495840",
    "end": "497680"
  },
  {
    "text": "obviously the the networking um",
    "start": "497680",
    "end": "500080"
  },
  {
    "text": "throughput as well so it's really about",
    "start": "500080",
    "end": "503720"
  },
  {
    "text": "making sure that we can take the best of",
    "start": "503720",
    "end": "505680"
  },
  {
    "text": "breed at what we do at a supercomputing",
    "start": "505680",
    "end": "507919"
  },
  {
    "text": "scale uh and deliver that back to the",
    "start": "507919",
    "end": "510520"
  },
  {
    "text": "customers so we have a real cycle around",
    "start": "510520",
    "end": "513360"
  },
  {
    "text": "um you know learning from working with",
    "start": "513360",
    "end": "516360"
  },
  {
    "text": "organizations like openai mistol and",
    "start": "516360",
    "end": "519399"
  },
  {
    "text": "others that have trained their models on",
    "start": "519399",
    "end": "520880"
  },
  {
    "text": "azure's infrastructure and then being",
    "start": "520880",
    "end": "522760"
  },
  {
    "text": "able to democratize that and deliver it",
    "start": "522760",
    "end": "524600"
  },
  {
    "text": "back to to customers as well and so uh",
    "start": "524600",
    "end": "527880"
  },
  {
    "text": "Hamza with that um why don't you share a",
    "start": "527880",
    "end": "530360"
  },
  {
    "text": "little bit more about what exactly you",
    "start": "530360",
    "end": "532640"
  },
  {
    "text": "guys did on on",
    "start": "532640",
    "end": "535200"
  },
  {
    "text": "Azure uh yeah so so first we we'll",
    "start": "535200",
    "end": "538480"
  },
  {
    "text": "actually talk a little bit about about",
    "start": "538480",
    "end": "539680"
  },
  {
    "text": "how we do distributed training in",
    "start": "539680",
    "end": "541200"
  },
  {
    "text": "general with Azure so we so we have a",
    "start": "541200",
    "end": "543760"
  },
  {
    "text": "stack you know um and so on the ml",
    "start": "543760",
    "end": "546680"
  },
  {
    "text": "framework side you know we use pytorch",
    "start": "546680",
    "end": "548360"
  },
  {
    "text": "you know pretty standard framework um we",
    "start": "548360",
    "end": "551200"
  },
  {
    "text": "also use a library called horovod which",
    "start": "551200",
    "end": "553399"
  },
  {
    "text": "handles multi- node communication so if",
    "start": "553399",
    "end": "555200"
  },
  {
    "text": "we have like multiple Azure vmms how do",
    "start": "555200",
    "end": "557079"
  },
  {
    "text": "they communicate with each other um it",
    "start": "557079",
    "end": "559480"
  },
  {
    "text": "allow it allows for faster communication",
    "start": "559480",
    "end": "561800"
  },
  {
    "text": "across nodes and on the underlying you",
    "start": "561800",
    "end": "564760"
  },
  {
    "text": "know Hardware layer you know we use a",
    "start": "564760",
    "end": "566440"
  },
  {
    "text": "bunch of azure VMS they could be like A1",
    "start": "566440",
    "end": "568560"
  },
  {
    "text": "100s or h100 stands and they're all you",
    "start": "568560",
    "end": "572120"
  },
  {
    "text": "know we connect to them we use horovod",
    "start": "572120",
    "end": "574000"
  },
  {
    "text": "to connect to them and send gradients",
    "start": "574000",
    "end": "575440"
  },
  {
    "text": "through for distributed training and",
    "start": "575440",
    "end": "577200"
  },
  {
    "text": "they all read and write to a single",
    "start": "577200",
    "end": "578959"
  },
  {
    "text": "Network file system or NFS you can",
    "start": "578959",
    "end": "581600"
  },
  {
    "text": "basically think of an NFS as being a",
    "start": "581600",
    "end": "583200"
  },
  {
    "text": "shared file system that every machine",
    "start": "583200",
    "end": "585760"
  },
  {
    "text": "has access to as if it were a local file",
    "start": "585760",
    "end": "587800"
  },
  {
    "text": "system which makes it very seamless to",
    "start": "587800",
    "end": "590120"
  },
  {
    "text": "read data or write checkpoints for",
    "start": "590120",
    "end": "593000"
  },
  {
    "text": "models um so that's kind of our overall",
    "start": "593000",
    "end": "597360"
  },
  {
    "text": "um infr stack",
    "start": "597360",
    "end": "600240"
  },
  {
    "text": "and what about running on on Azure um",
    "start": "600240",
    "end": "603440"
  },
  {
    "text": "you guys had some specific workloads",
    "start": "603440",
    "end": "606000"
  },
  {
    "text": "that that you were covering yeah um so",
    "start": "606000",
    "end": "609040"
  },
  {
    "text": "we've run a number of projects on Azure",
    "start": "609040",
    "end": "611399"
  },
  {
    "text": "um and we've run them on different sizes",
    "start": "611399",
    "end": "613360"
  },
  {
    "text": "from like you know one node to dozens of",
    "start": "613360",
    "end": "615440"
  },
  {
    "text": "nodes so you know we've run like DPO",
    "start": "615440",
    "end": "617760"
  },
  {
    "text": "align models uh with a bunch of",
    "start": "617760",
    "end": "619640"
  },
  {
    "text": "instruction response preference data",
    "start": "619640",
    "end": "621839"
  },
  {
    "text": "sets um we've run like you know",
    "start": "621839",
    "end": "624200"
  },
  {
    "text": "preference optimization techniques and",
    "start": "624200",
    "end": "627120"
  },
  {
    "text": "and using and the things we''ve did that",
    "start": "627120",
    "end": "628920"
  },
  {
    "text": "used the most most compute have been",
    "start": "628920",
    "end": "630399"
  },
  {
    "text": "large scale distributed training jobs um",
    "start": "630399",
    "end": "632640"
  },
  {
    "text": "for multimodal training and inference um",
    "start": "632640",
    "end": "634839"
  },
  {
    "text": "you know with like dozens of gpus um so",
    "start": "634839",
    "end": "638880"
  },
  {
    "text": "yeah these are the kinds of workloads",
    "start": "638880",
    "end": "640279"
  },
  {
    "text": "that we've",
    "start": "640279",
    "end": "642600"
  },
  {
    "text": "run fantastic um",
    "start": "642920",
    "end": "646800"
  },
  {
    "text": "the I think um you had some lessons",
    "start": "646800",
    "end": "650680"
  },
  {
    "text": "learned throughout as well it wasn't you",
    "start": "650680",
    "end": "653560"
  },
  {
    "text": "know I think it's not always smooth",
    "start": "653560",
    "end": "655040"
  },
  {
    "text": "sailing with these types of jobs so um",
    "start": "655040",
    "end": "657920"
  },
  {
    "text": "any any best practice traps for young",
    "start": "657920",
    "end": "660800"
  },
  {
    "text": "players out there in terms of uh your",
    "start": "660800",
    "end": "664440"
  },
  {
    "text": "experience yeah absolutely um so there's",
    "start": "664440",
    "end": "667680"
  },
  {
    "text": "a number of key architectural",
    "start": "667680",
    "end": "669279"
  },
  {
    "text": "considerations to keep in mind one is",
    "start": "669279",
    "end": "672440"
  },
  {
    "text": "having enough nodes to support you know",
    "start": "672440",
    "end": "674480"
  },
  {
    "text": "your ideal batch size so on the CV side",
    "start": "674480",
    "end": "677360"
  },
  {
    "text": "you know when I was training like you",
    "start": "677360",
    "end": "678639"
  },
  {
    "text": "know let's say like clip based models",
    "start": "678639",
    "end": "680160"
  },
  {
    "text": "one thing I learned is that you know you",
    "start": "680160",
    "end": "681399"
  },
  {
    "text": "want we want enough nodes to have a",
    "start": "681399",
    "end": "684480"
  },
  {
    "text": "certain batch size but we also didn't",
    "start": "684480",
    "end": "686639"
  },
  {
    "text": "want too many such that we would either",
    "start": "686639",
    "end": "688720"
  },
  {
    "text": "fall into the trap of having too large a",
    "start": "688720",
    "end": "690839"
  },
  {
    "text": "batch size or underutilizing whichever",
    "start": "690839",
    "end": "693480"
  },
  {
    "text": "nodes we were using so getting that",
    "start": "693480",
    "end": "695279"
  },
  {
    "text": "balance right was pretty important",
    "start": "695279",
    "end": "697600"
  },
  {
    "text": "another thing is networking bottlenecks",
    "start": "697600",
    "end": "699320"
  },
  {
    "text": "we we want to make sure all of our data",
    "start": "699320",
    "end": "701120"
  },
  {
    "text": "and nodes are close together like you",
    "start": "701120",
    "end": "702600"
  },
  {
    "text": "know imagine if for example you had your",
    "start": "702600",
    "end": "705200"
  },
  {
    "text": "um a bunch of your your data in Like Us",
    "start": "705200",
    "end": "708200"
  },
  {
    "text": "West and maybe you had your nodes in",
    "start": "708200",
    "end": "710120"
  },
  {
    "text": "like you know um Asia or something like",
    "start": "710120",
    "end": "712920"
  },
  {
    "text": "that right you know that's like a simple",
    "start": "712920",
    "end": "714920"
  },
  {
    "text": "example but bottom line is networking",
    "start": "714920",
    "end": "716920"
  },
  {
    "text": "communication is pretty important and",
    "start": "716920",
    "end": "718560"
  },
  {
    "text": "you want to make sure sure that you know",
    "start": "718560",
    "end": "720240"
  },
  {
    "text": "when you're sending this data across",
    "start": "720240",
    "end": "721920"
  },
  {
    "text": "that's not going to be a bottleneck when",
    "start": "721920",
    "end": "723880"
  },
  {
    "text": "you cuz if you're training one thing",
    "start": "723880",
    "end": "725360"
  },
  {
    "text": "that will happen is when you send",
    "start": "725360",
    "end": "727200"
  },
  {
    "text": "gradients to different copies of the",
    "start": "727200",
    "end": "728680"
  },
  {
    "text": "model that could be a bottleneck there",
    "start": "728680",
    "end": "731519"
  },
  {
    "text": "another bottleneck could be data reading",
    "start": "731519",
    "end": "733720"
  },
  {
    "text": "uh because recall that you know while",
    "start": "733720",
    "end": "735519"
  },
  {
    "text": "your model is training and you're doing",
    "start": "735519",
    "end": "736880"
  },
  {
    "text": "your forward and backward propagations",
    "start": "736880",
    "end": "739000"
  },
  {
    "text": "um asynchronously you're loading in data",
    "start": "739000",
    "end": "741079"
  },
  {
    "text": "to be fed to the model um and so this is",
    "start": "741079",
    "end": "745440"
  },
  {
    "text": "where the NFS read speed is absolutely",
    "start": "745440",
    "end": "747720"
  },
  {
    "text": "critical um if if your NFS is not",
    "start": "747720",
    "end": "750120"
  },
  {
    "text": "reading in your data fast enough then",
    "start": "750120",
    "end": "751800"
  },
  {
    "text": "you could be bottlenecked waiting for",
    "start": "751800",
    "end": "753199"
  },
  {
    "text": "data to be processed and your model",
    "start": "753199",
    "end": "754720"
  },
  {
    "text": "isn't actually",
    "start": "754720",
    "end": "755920"
  },
  {
    "text": "crunching um and you know one key",
    "start": "755920",
    "end": "759160"
  },
  {
    "text": "takeaway for both of these is make sure",
    "start": "759160",
    "end": "760680"
  },
  {
    "text": "your GPU utilization is good and vsmi is",
    "start": "760680",
    "end": "763959"
  },
  {
    "text": "your best friend here if you see your",
    "start": "763959",
    "end": "766079"
  },
  {
    "text": "GPU utilization being low you know don't",
    "start": "766079",
    "end": "768600"
  },
  {
    "text": "be afraid to look into why and you know",
    "start": "768600",
    "end": "770240"
  },
  {
    "text": "you can you know do different things to",
    "start": "770240",
    "end": "772040"
  },
  {
    "text": "debug like if it's multi- node for",
    "start": "772040",
    "end": "773959"
  },
  {
    "text": "example then you know you can test",
    "start": "773959",
    "end": "776040"
  },
  {
    "text": "networking and stuff like that if it's",
    "start": "776040",
    "end": "777680"
  },
  {
    "text": "on a single node that likely means me",
    "start": "777680",
    "end": "779320"
  },
  {
    "text": "it's a data loading issue so there's",
    "start": "779320",
    "end": "781160"
  },
  {
    "text": "lots of different way ways and tools",
    "start": "781160",
    "end": "782920"
  },
  {
    "text": "that you can use to step into these",
    "start": "782920",
    "end": "784680"
  },
  {
    "text": "things and you know don't underestimate",
    "start": "784680",
    "end": "787320"
  },
  {
    "text": "the basics of like reliability",
    "start": "787320",
    "end": "788800"
  },
  {
    "text": "flexibility and manageability so you",
    "start": "788800",
    "end": "791160"
  },
  {
    "text": "know one thing that we were we really",
    "start": "791160",
    "end": "793120"
  },
  {
    "text": "cared about as a team is we wanted to",
    "start": "793120",
    "end": "794720"
  },
  {
    "text": "make sure that our data distribut that",
    "start": "794720",
    "end": "797240"
  },
  {
    "text": "you know when we were training",
    "start": "797240",
    "end": "798120"
  },
  {
    "text": "experiments right we were like you know",
    "start": "798120",
    "end": "799639"
  },
  {
    "text": "going through sometimes we needed all",
    "start": "799639",
    "end": "801519"
  },
  {
    "text": "the nodes sometimes we needed very few",
    "start": "801519",
    "end": "804079"
  },
  {
    "text": "and you know being able to work with",
    "start": "804079",
    "end": "805440"
  },
  {
    "text": "instances that gave us that flexibility",
    "start": "805440",
    "end": "807199"
  },
  {
    "text": "over a long period of time is very",
    "start": "807199",
    "end": "809120"
  },
  {
    "text": "important you know when we were shopping",
    "start": "809120",
    "end": "811040"
  },
  {
    "text": "around some Cloud providers only let us",
    "start": "811040",
    "end": "813240"
  },
  {
    "text": "use compute for a fixed amount of time",
    "start": "813240",
    "end": "816040"
  },
  {
    "text": "like maybe say a month or two months and",
    "start": "816040",
    "end": "817800"
  },
  {
    "text": "you know as a trade-off we'd have a",
    "start": "817800",
    "end": "819560"
  },
  {
    "text": "bunch of compute but that didn't really",
    "start": "819560",
    "end": "821199"
  },
  {
    "text": "work for us because we weren't in it for",
    "start": "821199",
    "end": "823560"
  },
  {
    "text": "a training a model for some fixed amount",
    "start": "823560",
    "end": "825160"
  },
  {
    "text": "of time we wanted something where we",
    "start": "825160",
    "end": "827120"
  },
  {
    "text": "could go on and off for a longer period",
    "start": "827120",
    "end": "829240"
  },
  {
    "text": "of",
    "start": "829240",
    "end": "831519"
  },
  {
    "text": "time that's that's great Insight Hamza I",
    "start": "832360",
    "end": "835399"
  },
  {
    "text": "think um also we we talked about some of",
    "start": "835399",
    "end": "838440"
  },
  {
    "text": "the advantages is of using Azure which",
    "start": "838440",
    "end": "841399"
  },
  {
    "text": "um would be great if you could",
    "start": "841399",
    "end": "842839"
  },
  {
    "text": "shamelessly plug that for Azure as well",
    "start": "842839",
    "end": "845399"
  },
  {
    "text": "yeah happy to so you know one was",
    "start": "845399",
    "end": "847440"
  },
  {
    "text": "availability you know the Azure VMS were",
    "start": "847440",
    "end": "849920"
  },
  {
    "text": "were dedicated and allowed us to adjust",
    "start": "849920",
    "end": "851880"
  },
  {
    "text": "our capacity on demand um the",
    "start": "851880",
    "end": "854279"
  },
  {
    "text": "reliability was pretty good it was",
    "start": "854279",
    "end": "855800"
  },
  {
    "text": "consistently Dependable with like no",
    "start": "855800",
    "end": "857560"
  },
  {
    "text": "real issues you know NFS throughput was",
    "start": "857560",
    "end": "861000"
  },
  {
    "text": "also quite good you know um again right",
    "start": "861000",
    "end": "863360"
  },
  {
    "text": "like you know if your NFS is bad then",
    "start": "863360",
    "end": "865560"
  },
  {
    "text": "that means that you know you're not",
    "start": "865560",
    "end": "866600"
  },
  {
    "text": "reading in data fast enough or for",
    "start": "866600",
    "end": "868680"
  },
  {
    "text": "example being able to dynamically change",
    "start": "868680",
    "end": "871079"
  },
  {
    "text": "the size of your NFS if let's say for",
    "start": "871079",
    "end": "873000"
  },
  {
    "text": "example you need more less capacity if",
    "start": "873000",
    "end": "875040"
  },
  {
    "text": "you if you need more because you",
    "start": "875040",
    "end": "876759"
  },
  {
    "text": "suddenly have more data than you",
    "start": "876759",
    "end": "877920"
  },
  {
    "text": "realized you had before then you need to",
    "start": "877920",
    "end": "879560"
  },
  {
    "text": "be able to tell it that at the same time",
    "start": "879560",
    "end": "881720"
  },
  {
    "text": "if you realize that you know your your",
    "start": "881720",
    "end": "883560"
  },
  {
    "text": "NFS is over provisioned you don't want",
    "start": "883560",
    "end": "885199"
  },
  {
    "text": "to be you know overpaying an Azure bills",
    "start": "885199",
    "end": "887800"
  },
  {
    "text": "um though I'm sure locky wouldn't mind",
    "start": "887800",
    "end": "889320"
  },
  {
    "text": "that but uh and you know the ease of use",
    "start": "889320",
    "end": "893160"
  },
  {
    "text": "is very important you know clear",
    "start": "893160",
    "end": "894800"
  },
  {
    "text": "documentation and straightforward",
    "start": "894800",
    "end": "896160"
  },
  {
    "text": "process you know like as the guy that",
    "start": "896160",
    "end": "897880"
  },
  {
    "text": "set up aure for my team team I really",
    "start": "897880",
    "end": "899959"
  },
  {
    "text": "didn't like it if other people needed to",
    "start": "899959",
    "end": "901759"
  },
  {
    "text": "bug me and thankfully once I got things",
    "start": "901759",
    "end": "903560"
  },
  {
    "text": "working it just worked and I did not",
    "start": "903560",
    "end": "906440"
  },
  {
    "text": "need to be paid so that is very",
    "start": "906440",
    "end": "909000"
  },
  {
    "text": "important that's really great to hear",
    "start": "909000",
    "end": "911320"
  },
  {
    "text": "hza um yeah I I think like you know uh",
    "start": "911320",
    "end": "916000"
  },
  {
    "text": "this is fantastic and and I think you",
    "start": "916000",
    "end": "917839"
  },
  {
    "text": "had some specific data points uh you",
    "start": "917839",
    "end": "921240"
  },
  {
    "text": "guys recently went through a process to",
    "start": "921240",
    "end": "924240"
  },
  {
    "text": "go from the A1 100s through to the h100s",
    "start": "924240",
    "end": "927880"
  },
  {
    "text": "or the VMS l in those um can share a bit",
    "start": "927880",
    "end": "931319"
  },
  {
    "text": "of ins around what you observed with",
    "start": "931319",
    "end": "933040"
  },
  {
    "text": "that",
    "start": "933040",
    "end": "933720"
  },
  {
    "text": "experience yeah um so the key takeaway",
    "start": "933720",
    "end": "936279"
  },
  {
    "text": "is that h100s are really good um one",
    "start": "936279",
    "end": "939279"
  },
  {
    "text": "thing we wanted to do when we were doing",
    "start": "939279",
    "end": "941480"
  },
  {
    "text": "this was do a cost analysis and see okay",
    "start": "941480",
    "end": "943959"
  },
  {
    "text": "for a given number of h100s and a given",
    "start": "943959",
    "end": "946199"
  },
  {
    "text": "number of A1 100s that cost the same",
    "start": "946199",
    "end": "947920"
  },
  {
    "text": "amount what kind of training and",
    "start": "947920",
    "end": "949120"
  },
  {
    "text": "inference are we getting and so here you",
    "start": "949120",
    "end": "951160"
  },
  {
    "text": "can see we're comparing two h100s to 4",
    "start": "951160",
    "end": "953279"
  },
  {
    "text": "A1 100s because that's what works out",
    "start": "953279",
    "end": "955560"
  },
  {
    "text": "about the same cost wise and we're doing",
    "start": "955560",
    "end": "957800"
  },
  {
    "text": "better on both training and inference um",
    "start": "957800",
    "end": "960199"
  },
  {
    "text": "which means that we're doing better per",
    "start": "960199",
    "end": "961759"
  },
  {
    "text": "dollar just by switching here and you",
    "start": "961759",
    "end": "965199"
  },
  {
    "text": "know one there are a couple key points I",
    "start": "965199",
    "end": "967279"
  },
  {
    "text": "really want to emphasize here one is",
    "start": "967279",
    "end": "970040"
  },
  {
    "text": "that um you know it's really nice when",
    "start": "970040",
    "end": "972800"
  },
  {
    "text": "you just have a very simple plug-and",
    "start": "972800",
    "end": "974279"
  },
  {
    "text": "playay change that works you know",
    "start": "974279",
    "end": "975560"
  },
  {
    "text": "there's a lot of ongoing work to",
    "start": "975560",
    "end": "977519"
  },
  {
    "text": "optimize you know you know especially",
    "start": "977519",
    "end": "979360"
  },
  {
    "text": "like things like inference for example",
    "start": "979360",
    "end": "980920"
  },
  {
    "text": "with your KV caches your partial KV",
    "start": "980920",
    "end": "982959"
  },
  {
    "text": "caches your speculative decodings and",
    "start": "982959",
    "end": "985199"
  },
  {
    "text": "it's really nice to be able to say hey",
    "start": "985199",
    "end": "986920"
  },
  {
    "text": "let's just do something simple and have",
    "start": "986920",
    "end": "988560"
  },
  {
    "text": "it work work and the second is that with",
    "start": "988560",
    "end": "991079"
  },
  {
    "text": "this faster inference in particular we",
    "start": "991079",
    "end": "992759"
  },
  {
    "text": "can we can go through more synthetic",
    "start": "992759",
    "end": "994920"
  },
  {
    "text": "data higher end model accuracy and it",
    "start": "994920",
    "end": "996560"
  },
  {
    "text": "just enables us a flywheel of faster",
    "start": "996560",
    "end": "998519"
  },
  {
    "text": "iteration which is super critical for",
    "start": "998519",
    "end": "1000880"
  },
  {
    "text": "being able to like do more",
    "start": "1000880",
    "end": "1003199"
  },
  {
    "text": "development yeah I I mean you can see",
    "start": "1003199",
    "end": "1005279"
  },
  {
    "text": "from the numbers the the performance is",
    "start": "1005279",
    "end": "1007759"
  },
  {
    "text": "there and it's I'm I'm I'm assuming that",
    "start": "1007759",
    "end": "1010480"
  },
  {
    "text": "internally just that ability to do more",
    "start": "1010480",
    "end": "1012639"
  },
  {
    "text": "with fewer gpus has been a really um",
    "start": "1012639",
    "end": "1016839"
  },
  {
    "text": "great benefit for you guys across all",
    "start": "1016839",
    "end": "1018440"
  },
  {
    "text": "the work you",
    "start": "1018440",
    "end": "1020120"
  },
  {
    "text": "doing um oh",
    "start": "1020120",
    "end": "1023959"
  },
  {
    "text": "sorry um sry your question is why the uh",
    "start": "1032400",
    "end": "1035199"
  },
  {
    "text": "training time while the inference is",
    "start": "1035199",
    "end": "1037038"
  },
  {
    "text": "taking longer than the training",
    "start": "1037039",
    "end": "1038959"
  },
  {
    "text": "time um I think it was because we were",
    "start": "1038959",
    "end": "1041678"
  },
  {
    "text": "doing a larger batch size and it just",
    "start": "1041679",
    "end": "1043600"
  },
  {
    "text": "happened to work out that way that for",
    "start": "1043600",
    "end": "1046760"
  },
  {
    "text": "whatever batch size we were doing it",
    "start": "1046760",
    "end": "1048558"
  },
  {
    "text": "just wound up taking longer cuz you with",
    "start": "1048559",
    "end": "1050760"
  },
  {
    "text": "with training you typically need a",
    "start": "1050760",
    "end": "1051960"
  },
  {
    "text": "smaller bat size cuz you have to to put",
    "start": "1051960",
    "end": "1054640"
  },
  {
    "text": "more things in memory for back propop",
    "start": "1054640",
    "end": "1056200"
  },
  {
    "text": "and somehow it just wound up working",
    "start": "1056200",
    "end": "1058200"
  },
  {
    "text": "that",
    "start": "1058200",
    "end": "1059799"
  },
  {
    "text": "way",
    "start": "1059799",
    "end": "1062799"
  },
  {
    "text": "so",
    "start": "1074640",
    "end": "1076440"
  },
  {
    "text": "um no cuz I know that when we were",
    "start": "1076440",
    "end": "1078440"
  },
  {
    "text": "comparing training inference across the",
    "start": "1078440",
    "end": "1080200"
  },
  {
    "text": "hardware th those were kept fixed like",
    "start": "1080200",
    "end": "1082400"
  },
  {
    "text": "whatever inference batch size we were",
    "start": "1082400",
    "end": "1083960"
  },
  {
    "text": "using for dh100 was the same as the",
    "start": "1083960",
    "end": "1087360"
  },
  {
    "text": "a00 um so that that wasn't a that wasn't",
    "start": "1087360",
    "end": "1090400"
  },
  {
    "text": "a",
    "start": "1090400",
    "end": "1092600"
  },
  {
    "text": "factor",
    "start": "1093240",
    "end": "1096240"
  },
  {
    "text": "yeah yeah so uh speaking about um what's",
    "start": "1097280",
    "end": "1101039"
  },
  {
    "text": "next I think this is a good segue so uh",
    "start": "1101039",
    "end": "1104080"
  },
  {
    "text": "with the next",
    "start": "1104080",
    "end": "1105679"
  },
  {
    "text": "slide um just from our point of view",
    "start": "1105679",
    "end": "1108559"
  },
  {
    "text": "with with Azure we are sort of adopting",
    "start": "1108559",
    "end": "1111960"
  },
  {
    "text": "and we spoke about um optimizing at",
    "start": "1111960",
    "end": "1115320"
  },
  {
    "text": "every layer of the stack and I think the",
    "start": "1115320",
    "end": "1117120"
  },
  {
    "text": "addition of our Maya uh AI accelerator",
    "start": "1117120",
    "end": "1120159"
  },
  {
    "text": "that's used for our own internal",
    "start": "1120159",
    "end": "1121559"
  },
  {
    "text": "workloads across Microsoft",
    "start": "1121559",
    "end": "1124480"
  },
  {
    "text": "365 uh but we we've just announced the",
    "start": "1124480",
    "end": "1127320"
  },
  {
    "text": "AMD Mi 300X with uh the high bandwidth",
    "start": "1127320",
    "end": "1130480"
  },
  {
    "text": "memory we've got the Nvidia A1 100s the",
    "start": "1130480",
    "end": "1133720"
  },
  {
    "text": "h100s and we'll be adopting Blackwell",
    "start": "1133720",
    "end": "1136520"
  },
  {
    "text": "what's really exciting is",
    "start": "1136520",
    "end": "1139559"
  },
  {
    "text": "the pace of innovation in in Silicon has",
    "start": "1139559",
    "end": "1142159"
  },
  {
    "text": "never been like this before we're",
    "start": "1142159",
    "end": "1144280"
  },
  {
    "text": "talking with Nvidia almost doing two",
    "start": "1144280",
    "end": "1146919"
  },
  {
    "text": "releases a year previously you know I I",
    "start": "1146919",
    "end": "1150760"
  },
  {
    "text": "I think it might have been one every two",
    "start": "1150760",
    "end": "1152360"
  },
  {
    "text": "years or something like that uh it's",
    "start": "1152360",
    "end": "1155039"
  },
  {
    "text": "really amazing to see this growth in the",
    "start": "1155039",
    "end": "1157760"
  },
  {
    "text": "in the Silicon how far we're getting and",
    "start": "1157760",
    "end": "1160679"
  },
  {
    "text": "what Hamza just shared the ability to",
    "start": "1160679",
    "end": "1162679"
  },
  {
    "text": "more and more with less uh on the",
    "start": "1162679",
    "end": "1165400"
  },
  {
    "text": "infrastructure as well and so um I think",
    "start": "1165400",
    "end": "1169280"
  },
  {
    "text": "you know certainly as far as Azure and",
    "start": "1169280",
    "end": "1171280"
  },
  {
    "text": "our AI infrastructure strategy it's to",
    "start": "1171280",
    "end": "1173840"
  },
  {
    "text": "continue to adopt these new evolutions",
    "start": "1173840",
    "end": "1176720"
  },
  {
    "text": "and really make sure the right gpus are",
    "start": "1176720",
    "end": "1179159"
  },
  {
    "text": "used in the right places for the right",
    "start": "1179159",
    "end": "1182039"
  },
  {
    "text": "workloads hza what about for snorkel AI",
    "start": "1182039",
    "end": "1185159"
  },
  {
    "text": "what's next yeah so to give you all a",
    "start": "1185159",
    "end": "1187640"
  },
  {
    "text": "sneak peek into what we're working on",
    "start": "1187640",
    "end": "1189320"
  },
  {
    "text": "actively at snorkel what we have a",
    "start": "1189320",
    "end": "1191559"
  },
  {
    "text": "number of directions you know one is to",
    "start": "1191559",
    "end": "1193520"
  },
  {
    "text": "you know say like you know better data",
    "start": "1193520",
    "end": "1195440"
  },
  {
    "text": "leads to better gen and get better",
    "start": "1195440",
    "end": "1197400"
  },
  {
    "text": "prototypes to production so so we want",
    "start": "1197400",
    "end": "1199480"
  },
  {
    "text": "to explore new ways to programmatically",
    "start": "1199480",
    "end": "1201159"
  },
  {
    "text": "utilize preference signals for data",
    "start": "1201159",
    "end": "1202679"
  },
  {
    "text": "synthesis and curation we also want to",
    "start": "1202679",
    "end": "1205440"
  },
  {
    "text": "develop scalable entry points for data",
    "start": "1205440",
    "end": "1207640"
  },
  {
    "text": "development using rationals and custom",
    "start": "1207640",
    "end": "1209760"
  },
  {
    "text": "taxonomies um and finally we want you",
    "start": "1209760",
    "end": "1212840"
  },
  {
    "text": "know better multimodal retrieval",
    "start": "1212840",
    "end": "1214440"
  },
  {
    "text": "algorithms um and we want to evaluate",
    "start": "1214440",
    "end": "1217039"
  },
  {
    "text": "those on domain specific data sets to",
    "start": "1217039",
    "end": "1218880"
  },
  {
    "text": "scale up the retrieval models we have so",
    "start": "1218880",
    "end": "1221799"
  },
  {
    "text": "and we're of course excited to do all",
    "start": "1221799",
    "end": "1223400"
  },
  {
    "text": "these things on Azure AI",
    "start": "1223400",
    "end": "1226840"
  },
  {
    "text": "infra fantastic com well thank you so",
    "start": "1226840",
    "end": "1229840"
  },
  {
    "text": "much for for presenting and and speaking",
    "start": "1229840",
    "end": "1232559"
  },
  {
    "text": "on behalf of uh Microsoft we we really",
    "start": "1232559",
    "end": "1235120"
  },
  {
    "text": "appreciate it thank you guys so much",
    "start": "1235120",
    "end": "1239570"
  },
  {
    "text": "[Music]",
    "start": "1239570",
    "end": "1247028"
  }
]
[
  {
    "text": "[Music]",
    "start": "350",
    "end": "13440"
  },
  {
    "text": "all right good afternoon everybody thank you all so much for for",
    "start": "13440",
    "end": "18640"
  },
  {
    "text": "joining us we have the uh envi pos enviable position of being after lunch I'm seeing some cookies on the table",
    "start": "18640",
    "end": "24760"
  },
  {
    "text": "still but thankfully you're not here to listen to me you're going to be riveted by The Prompt doctor he's going to come up in a second so I'm expecting no",
    "start": "24760",
    "end": "31080"
  },
  {
    "text": "sleeping on the table but but you never know um excited to be here I'm Jamie newor I lead our startup team at",
    "start": "31080",
    "end": "37760"
  },
  {
    "text": "anthropic and I just wanted to say a couple of quick things before we got going here with again the reason you're",
    "start": "37760",
    "end": "42879"
  },
  {
    "text": "here the prompt doctor uh we've had a lot of really exciting releases just in the last",
    "start": "42879",
    "end": "49360"
  },
  {
    "text": "couple of days some in the last couple of hours and wanted to just put these up there to highlight some of the cool",
    "start": "49360",
    "end": "54640"
  },
  {
    "text": "things that we're doing but also share how a lot of folks not only in this room some of your peers maybe f folks back at",
    "start": "54640",
    "end": "60399"
  },
  {
    "text": "the office can work with anthropic on not only some of the prompting of course Works uh work we're going to do here but",
    "start": "60399",
    "end": "66960"
  },
  {
    "text": "just helping you grow your business and the really cool things you guys are building with clad with ls on top of AI",
    "start": "66960",
    "end": "75960"
  },
  {
    "text": "my team is here specifically to help your company grow and scale the business",
    "start": "75960",
    "end": "81400"
  },
  {
    "text": "whether that's getting access to higher rate limits getting access to folks like Zach who's going to be up here in a moment learning more about what we're",
    "start": "81400",
    "end": "87479"
  },
  {
    "text": "doing from an early access perspective we want to work work with you and empower the next wave of really exciting",
    "start": "87479",
    "end": "93119"
  },
  {
    "text": "AI companies built on top of clot and we're helping from a product perspective",
    "start": "93119",
    "end": "98159"
  },
  {
    "text": "with a couple of the releases you see here has anyone tried 3.5 Sonic yet love it very cool really excit yeah",
    "start": "98159",
    "end": "105000"
  },
  {
    "text": "thankfully Zach has tried it as well so we're in a good place uh really excited about what we were able to release there",
    "start": "105000",
    "end": "110600"
  },
  {
    "text": "as well um also just today or excuse me I guess artifacts came out with that with our Claude teams and clae AI plan",
    "start": "110600",
    "end": "117600"
  },
  {
    "text": "artifacts is this really cool tool that some have been playing around with making video games with a couple lines",
    "start": "117600",
    "end": "123320"
  },
  {
    "text": "of text that turns into code but actually a lot of really cool business use cases from a diagram perspective",
    "start": "123320",
    "end": "128920"
  },
  {
    "text": "I've seen a lot of cool Pharma companies using this and thinking out how can I put what's in my head on a gene",
    "start": "128920",
    "end": "134160"
  },
  {
    "text": "sequencing kind of discussion onto something like an artifact share that with my peers all the way to prompting",
    "start": "134160",
    "end": "140760"
  },
  {
    "text": "cookbooks helping again folks like yourself I would imagine a lot of you hopefully will be featured on the website you know coming up with what you",
    "start": "140760",
    "end": "147160"
  },
  {
    "text": "be able to prompt for these use cases in your companies so just some ways that that we've uh uh you know things that",
    "start": "147160",
    "end": "153800"
  },
  {
    "text": "we've come out with over the last couple of days couple of hours when you think of Claud teams and projects and then ways to connect feel free to reach out",
    "start": "153800",
    "end": "160360"
  },
  {
    "text": "at sales uh sales anthropic ccom we have our head of devell Alex here as well so",
    "start": "160360",
    "end": "165680"
  },
  {
    "text": "we really love this community love staying engaged we're really excited about what we've released over the last couple of days to be able to help you",
    "start": "165680",
    "end": "172720"
  },
  {
    "text": "again and what you guys are building and so I'm going to leave all that to the prompt doctor as well to get that uh uh",
    "start": "172720",
    "end": "178959"
  },
  {
    "text": "to really make sure that that we can help and Zach why don't you come on up here and and see what we can do thank",
    "start": "178959",
    "end": "184000"
  },
  {
    "text": "you all so much for joining us today we're really [Applause]",
    "start": "184000",
    "end": "192640"
  },
  {
    "text": "excited thanks Jamie for the intro and thank you all for coming this is really awesome I had no idea this many people",
    "start": "192640",
    "end": "198120"
  },
  {
    "text": "are going to be here so thanks uh okay so not going to be much talk it's mostly",
    "start": "198120",
    "end": "203440"
  },
  {
    "text": "just going to be straight up prompting from beginning to end did make a a couple slides so mostly about what what",
    "start": "203440",
    "end": "209080"
  },
  {
    "text": "to bring so I set up a a slack Channel um in this uh the the the AI engineer",
    "start": "209080",
    "end": "216080"
  },
  {
    "text": "slack it's called prompt live Workshop anthropic um so that's where you can",
    "start": "216080",
    "end": "222280"
  },
  {
    "text": "upload prompts and what we're going to do on stage is uh I'm just going to sort of look at them uh I'm going to read",
    "start": "222280",
    "end": "228760"
  },
  {
    "text": "them we're going to test them in the console uh the anthropic console uh we're going to see if we can get better",
    "start": "228760",
    "end": "234120"
  },
  {
    "text": "results and we'll just sort of like uh try try to learn as we go uh so this is",
    "start": "234120",
    "end": "239360"
  },
  {
    "text": "something that I do like internally in our our team slack quite a bit but I've never done it in front of this many",
    "start": "239360",
    "end": "244720"
  },
  {
    "text": "people and I uh it'll be exciting it'll be it'll be fun um might be some hiccups along the way but hopefully you all have",
    "start": "244720",
    "end": "251040"
  },
  {
    "text": "a good time too and maybe learn something I know I'll definitely learn something um so what what kinds of things should you put in this uh slack",
    "start": "251040",
    "end": "257919"
  },
  {
    "text": "channel so uh you can put a prompt template so a prompt template is kind of",
    "start": "257919",
    "end": "263280"
  },
  {
    "text": "like a prompt uh actually I just realized I don't even need this this mic um okay so you put a prompt template uh",
    "start": "263280",
    "end": "270080"
  },
  {
    "text": "which is like a it's like a prompt but with spaces where the variables are going to go and the variables the",
    "start": "270080",
    "end": "277120"
  },
  {
    "text": "they're they're going to be denoted with these double brackets so in this case it's like this this document part um if",
    "start": "277120",
    "end": "283919"
  },
  {
    "text": "you don't have it in this format that's fine we can figure it out this is just like the ideal uh so this is like the prompt",
    "start": "283919",
    "end": "289600"
  },
  {
    "text": "template this is like the kind of thing you'd put there and then you can also have a couple examples of cases where it",
    "start": "289600",
    "end": "295039"
  },
  {
    "text": "doesn't do what you want and that will give us um the uh like direction as far",
    "start": "295039",
    "end": "300479"
  },
  {
    "text": "as like where we want to go with it um I might also like uh ask you questions out",
    "start": "300479",
    "end": "307000"
  },
  {
    "text": "loud if I have questions about like what kind of output is is good or not or I might ask questions in slack uh either",
    "start": "307000",
    "end": "313039"
  },
  {
    "text": "way because it's it's easier we'll have to kind of figure that that out as we go um okay so that being said uh we're",
    "start": "313039",
    "end": "320319"
  },
  {
    "text": "going to use the console for for iterating mostly although I might use a couple other tools like um quad for",
    "start": "320319",
    "end": "325880"
  },
  {
    "text": "Sheets which is like a spreadsheet where you can uh call Quad um okay uh so yeah let's see what we've",
    "start": "325880",
    "end": "333639"
  },
  {
    "text": "got in the slack already okay we have something here thank you Gordy so you're an expert",
    "start": "333639",
    "end": "341080"
  },
  {
    "text": "patient so let's put this into the console and then let's take a",
    "start": "341080",
    "end": "347000"
  },
  {
    "text": "look okay and I'm just going to go through as many of these as as we can get through in in the session and uh",
    "start": "351919",
    "end": "359039"
  },
  {
    "text": "yeah this is pretty much much what it's going to be so first of all we can probably capitalize",
    "start": "359039",
    "end": "366319"
  },
  {
    "text": "all the uh sentences does that matter does",
    "start": "366319",
    "end": "372199"
  },
  {
    "text": "that matter yeah sorry I'm gy thank you yeah yeah yeah yeah yeah perfect so does",
    "start": "372199",
    "end": "378199"
  },
  {
    "text": "it matter having capitalization I I think so",
    "start": "378199",
    "end": "384680"
  },
  {
    "text": "okay A a lot of things like prompt engineering is like it's it's very new right so like we",
    "start": "385720",
    "end": "392560"
  },
  {
    "text": "don't know for sure somebody out there might have done a study where they like conclusively show that using capital",
    "start": "392560",
    "end": "398160"
  },
  {
    "text": "letters and like using like better grammar fixing grammar mistakes help I have like anecdotally found this in a",
    "start": "398160",
    "end": "404120"
  },
  {
    "text": "few cases I also have read some like quantitative stuff showing that like typos do hurt performance but I'm also",
    "start": "404120",
    "end": "411400"
  },
  {
    "text": "just like pretty obsessive about this stuff so I just fix it and I think it like it definitely doesn't",
    "start": "411400",
    "end": "416440"
  },
  {
    "text": "hurt um okay can you zoom in can I zoom in great question is is that",
    "start": "416440",
    "end": "423479"
  },
  {
    "text": "any better no little more okay is that any",
    "start": "423479",
    "end": "430080"
  },
  {
    "text": "better okay um so first thing let's put information in XML tags so we can go",
    "start": "431520",
    "end": "439440"
  },
  {
    "text": "like this why not like marown why XML why not markdown uh another great question so Claude was trained with a",
    "start": "439440",
    "end": "446400"
  },
  {
    "text": "lot of XML in its training data and so it's sort of seen more of that than it's seen of other",
    "start": "446400",
    "end": "452639"
  },
  {
    "text": "formats um so it's just works a little bit better so this looks like all the",
    "start": "452639",
    "end": "457960"
  },
  {
    "text": "information here so we have the medication review will be okay um can you run it before and after before the",
    "start": "457960",
    "end": "466360"
  },
  {
    "text": "first itation and then the final itation and see how yeah great call uh okay actually let me undo everything that",
    "start": "466360",
    "end": "471879"
  },
  {
    "text": "I've done so far okay uh so we can run it here and",
    "start": "471879",
    "end": "479159"
  },
  {
    "text": "then now in the console it's asking us for the user input so do we have a user input I gave you samples okay",
    "start": "479159",
    "end": "488000"
  },
  {
    "text": "perfect so who are you let's do this one why do I need to uh yeah we can we can",
    "start": "488000",
    "end": "493039"
  },
  {
    "text": "do them both um who are",
    "start": "493039",
    "end": "499000"
  },
  {
    "text": "you okay so Gordy what do you think of this it's way too long this is a ation",
    "start": "502680",
    "end": "510000"
  },
  {
    "text": "agent so no more than one sentence okay it's too long um we can probably fix that",
    "start": "510000",
    "end": "519440"
  },
  {
    "text": "so uh but we can also use this evaluate tab so let's let's just like add all the test cases here so this is the evaluate",
    "start": "519440",
    "end": "526200"
  },
  {
    "text": "tab of the console I'm also going to be doing like some showing off of the console uh features cuz I think it's a",
    "start": "526200",
    "end": "531880"
  },
  {
    "text": "cool to tool for prompt iteration um there's also some secret new features",
    "start": "531880",
    "end": "538079"
  },
  {
    "text": "that I might show uh we'll see about that um okay so then we also have why do",
    "start": "538079",
    "end": "544200"
  },
  {
    "text": "I need to do this experiment looks like it added a bunch",
    "start": "544200",
    "end": "551160"
  },
  {
    "text": "of uh new lines let's definitely get rid of those um and then we can get this next",
    "start": "551160",
    "end": "558079"
  },
  {
    "text": "one can I schedule it tomorrow instead cool",
    "start": "558079",
    "end": "566519"
  },
  {
    "text": "um so hit run remaining and this is all running",
    "start": "567839",
    "end": "573040"
  },
  {
    "text": "through Dove uh sorry through um so okay so we have why do need to do this",
    "start": "573040",
    "end": "578360"
  },
  {
    "text": "appointment so this looks pretty long as well and here we have this like I",
    "start": "578360",
    "end": "584440"
  },
  {
    "text": "apologize but I don't have information about scheduling availability um okay",
    "start": "584440",
    "end": "591320"
  },
  {
    "text": "so is that true is it true that we don't have information about scheduling uh no we are always available",
    "start": "592399",
    "end": "600720"
  },
  {
    "text": "make it easy for that 24hour availability 24-hour availability okay",
    "start": "600720",
    "end": "606240"
  },
  {
    "text": "all right so this is like the version one now let's make some",
    "start": "606240",
    "end": "611480"
  },
  {
    "text": "changes um so first of all I'll actually I'll try to do things like roughly in",
    "start": "611480",
    "end": "616800"
  },
  {
    "text": "like some order of importance uh so maybe I won't make you",
    "start": "616800",
    "end": "622640"
  },
  {
    "text": "all sit through the capitalization uh even though I like would definitely do that I'm also going to add a new line",
    "start": "622640",
    "end": "628079"
  },
  {
    "text": "here just cuz I think that that's like more normal what you'd see in like a written document you'd have a new Lon um",
    "start": "628079",
    "end": "634880"
  },
  {
    "text": "we'll close the information tab um what's that you get fix",
    "start": "634880",
    "end": "642800"
  },
  {
    "text": "capitalization yeah I could actually uh that's not a bad idea the the one thing I wouldn't feel completely confident of",
    "start": "642800",
    "end": "649160"
  },
  {
    "text": "is that it would like exactly transcribe the the rest of everything like word for",
    "start": "649160",
    "end": "654240"
  },
  {
    "text": "word I think it probably would um what I actually do is just like",
    "start": "654240",
    "end": "660160"
  },
  {
    "text": "have CLA write code uh to capitalize every uh first word of the sentence then",
    "start": "660160",
    "end": "665600"
  },
  {
    "text": "I'd be worried about edge cases like what if there's like ellipses um but I I that kind of thing",
    "start": "665600",
    "end": "671560"
  },
  {
    "text": "is definitely useful and like I definitely use clad a lot in in writing prompts uh for instance like we have",
    "start": "671560",
    "end": "676800"
  },
  {
    "text": "like a a quad tool that like helps complete code basically and I do a lot of prompting in that IDE because like",
    "start": "676800",
    "end": "683120"
  },
  {
    "text": "especially with like very NE nested XML tags uh helps a lot just like suggesting the closures of them which is like",
    "start": "683120",
    "end": "689399"
  },
  {
    "text": "pretty obvious but still takes a long time to type uh so yeah if you have any sort of like co-pilot type thing uh",
    "start": "689399",
    "end": "696480"
  },
  {
    "text": "definitely that's like a good environment for for writing prompts um okay now let's do the same thing with",
    "start": "696480",
    "end": "701720"
  },
  {
    "text": "this instructions um and we can do",
    "start": "701720",
    "end": "710279"
  },
  {
    "text": "this it looks like um this one like didn't get a number so let's like do",
    "start": "710279",
    "end": "717560"
  },
  {
    "text": "that um where do you know to stop",
    "start": "717560",
    "end": "723959"
  },
  {
    "text": "XML leave it at PL text yeah so the key thing in terms of XML I think is just",
    "start": "723959",
    "end": "731079"
  },
  {
    "text": "like really XML isn't even that important the most important thing is just clearly separating the different",
    "start": "731079",
    "end": "736959"
  },
  {
    "text": "parts of the prompt using it for semantics of what this section is yeah exactly it's like here's this",
    "start": "736959",
    "end": "743199"
  },
  {
    "text": "stuff here's this other stuff like if we wanted to we could do something like like",
    "start": "743199",
    "end": "750240"
  },
  {
    "text": "like I I I wouldn't do this but like I think it would probably work fine",
    "start": "750519",
    "end": "756600"
  },
  {
    "text": "yeah um okay so this is all fine let's also do",
    "start": "756600",
    "end": "763279"
  },
  {
    "text": "the same thing with user",
    "start": "763279",
    "end": "766199"
  },
  {
    "text": "input now we can run we can go back to the evaluate Tab and we can hit rerun",
    "start": "770639",
    "end": "776360"
  },
  {
    "text": "all and it's using our nice new prompt um um still looks pretty long we can also see how it does on the the last",
    "start": "776360",
    "end": "783480"
  },
  {
    "text": "case where um okay so here it still said I don't",
    "start": "783480",
    "end": "788880"
  },
  {
    "text": "have access to the specific scheduling information so let's let's try and fix these two things so first of all we can",
    "start": "788880",
    "end": "794440"
  },
  {
    "text": "make it shorter so do we have anything here about like making it shorter what's that rule seven",
    "start": "794440",
    "end": "801959"
  },
  {
    "text": "rule seven okay um be concise and offer only",
    "start": "801959",
    "end": "807320"
  },
  {
    "text": "relevant information uh oops so let's actually do this don't want to Mis number",
    "start": "807320",
    "end": "815360"
  },
  {
    "text": "here and um be concise so like and offer only way",
    "start": "815360",
    "end": "822199"
  },
  {
    "text": "relevant information each response should",
    "start": "822199",
    "end": "827600"
  },
  {
    "text": "be uh or let's let's be a little bit like less prescriptive to give CLA like a little bit more room like if we say",
    "start": "827600",
    "end": "833360"
  },
  {
    "text": "like every response should be like exactly three sentences that might be like a little too constraining I'm just",
    "start": "833360",
    "end": "838639"
  },
  {
    "text": "guessing um so we could say",
    "start": "838639",
    "end": "843120"
  },
  {
    "text": "like so why is responses to be two to four sentences better than telling it to",
    "start": "849279",
    "end": "854800"
  },
  {
    "text": "be concise isit yeah concise could mean a lot of different things to to different",
    "start": "854800",
    "end": "860720"
  },
  {
    "text": "people like in some cases like concise might mean like literally only one word",
    "start": "860720",
    "end": "865800"
  },
  {
    "text": "in in some cases like if you ask for like a concise book review we might be looking at like you know a single page",
    "start": "865800",
    "end": "871320"
  },
  {
    "text": "word doc and that would be concise in the context of a book review um so yeah",
    "start": "871320",
    "end": "877959"
  },
  {
    "text": "quad is like trying to guess what you mean by",
    "start": "877959",
    "end": "882120"
  },
  {
    "text": "concise sorry one sec go ahead aomp if you have a long system a lot of",
    "start": "886079",
    "end": "892720"
  },
  {
    "text": "detail instructions saying be concise you're not going to get something super super short I think that's right I think",
    "start": "892720",
    "end": "898920"
  },
  {
    "text": "that the tone of the prompt so what he was saying for if people couldn't hear is like the prompt is long so the response might also be long I I don't",
    "start": "898920",
    "end": "906639"
  },
  {
    "text": "think that's like definitively true like you can have long prompts that give short responses or short prompts that",
    "start": "906639",
    "end": "912040"
  },
  {
    "text": "give long responses but it's more like if you don't say anything it might pick up on some of those like context clues",
    "start": "912040",
    "end": "917639"
  },
  {
    "text": "you were saying something over here ifs to beiing of question that's like yeah keep",
    "start": "917639",
    "end": "925839"
  },
  {
    "text": "it short for like that interaction right like sometimes we give really short",
    "start": "925839",
    "end": "931759"
  },
  {
    "text": "responses other times we give long responses yeah have we trained LM to do that yet or we not yeah so let me",
    "start": "931759",
    "end": "939120"
  },
  {
    "text": "actually get to that after we do this so this two to four sentences it looks like it's still pretty long I think maybe that's actually like longer than",
    "start": "939120",
    "end": "944959"
  },
  {
    "text": "necessary so maybe we should make it like one to one to two sentences",
    "start": "944959",
    "end": "950079"
  },
  {
    "text": "um let's try that never more than three okay now we can try that here",
    "start": "950079",
    "end": "960079"
  },
  {
    "text": "okay that looks better right this is definitely shorter okay um and it also seems that",
    "start": "961560",
    "end": "970800"
  },
  {
    "text": "it is giving variable numbers of sentences so these were both two sentences and then this one is three so",
    "start": "970800",
    "end": "977199"
  },
  {
    "text": "one of the questions over here is like can the llm figure out that it should do longer responses in certain situations and shorter others so it seems like it",
    "start": "977199",
    "end": "983519"
  },
  {
    "text": "it did that here um okay so then the next point was that in this this case it",
    "start": "983519",
    "end": "989440"
  },
  {
    "text": "shouldn't say that I don't have access to the scheduling system or specific appointment times what should it say instead it",
    "start": "989440",
    "end": "996920"
  },
  {
    "text": "should say sure what time tomorrow but intentionally in the prompt I left out that it's 24hour",
    "start": "996920",
    "end": "1004000"
  },
  {
    "text": "service so this is a case where we're asking a question that's not present in the information it",
    "start": "1004000",
    "end": "1011000"
  },
  {
    "text": "has okay so yeah I mean we could add something like um you're open for 24hour",
    "start": "1011000",
    "end": "1018560"
  },
  {
    "text": "service but you're saying you want to you want to test its ability to like figure out",
    "start": "1018560",
    "end": "1024240"
  },
  {
    "text": "how to do it without that I don't know oh okay it is saying I don't know which is good okay well then we we're",
    "start": "1024240",
    "end": "1030720"
  },
  {
    "text": "doing great all right should we anything else that you",
    "start": "1030720",
    "end": "1037120"
  },
  {
    "text": "wanted to get out of looking at this example gardi I think that oh about the",
    "start": "1037120",
    "end": "1042240"
  },
  {
    "text": "structure so does the order of the rules or the order of putting information then",
    "start": "1042240",
    "end": "1047880"
  },
  {
    "text": "rules or rules first then information does any of that matter yeah so do we",
    "start": "1047880",
    "end": "1053960"
  },
  {
    "text": "does it matter what order we have these components yeah I think it's better to put the information above the",
    "start": "1053960",
    "end": "1059320"
  },
  {
    "text": "instructions okay we've sort of found that instructions are more tightly",
    "start": "1059320",
    "end": "1065200"
  },
  {
    "text": "followed the closer they are to the bottom of the prompt as a rule this doesn't necessarily apply in all",
    "start": "1065200",
    "end": "1071080"
  },
  {
    "text": "situations so definitely test it out that actually is like a blanket statement that applies to everything",
    "start": "1071080",
    "end": "1076520"
  },
  {
    "text": "that I say but particularly for that",
    "start": "1076520",
    "end": "1082440"
  },
  {
    "text": "okay yeah asking questions no no no go ahead",
    "start": "1082440",
    "end": "1088600"
  },
  {
    "text": "it's only bald men allow so is there a signif to the",
    "start": "1088600",
    "end": "1094840"
  },
  {
    "text": "exclamation I noticed exclamation mark exclamation mark yes oh remember I don't think I",
    "start": "1094840",
    "end": "1103480"
  },
  {
    "text": "added that on or it looks like you added that Gordy I exclamation mark just as",
    "start": "1103480",
    "end": "1109360"
  },
  {
    "text": "they emphasize things for humans they also emphasize things to the model",
    "start": "1109360",
    "end": "1117159"
  },
  {
    "text": "think o yeah I don't I don't know at that level of detail and I think it's dependent on on context as well but yeah",
    "start": "1119760",
    "end": "1125840"
  },
  {
    "text": "if if you want to emphasize things like capitalizing them or putting exclamation marks or like just saying this is",
    "start": "1125840",
    "end": "1132880"
  },
  {
    "text": "extremely important that all does do something yeah",
    "start": "1132880",
    "end": "1139679"
  },
  {
    "text": "um so the tokenizer though um I I I'm taking a look at some your tokenizer",
    "start": "1139679",
    "end": "1146600"
  },
  {
    "text": "code but it doesn't seem like exclamation points actually like do anything really like",
    "start": "1146600",
    "end": "1154280"
  },
  {
    "text": "they're the toen com into the it does something that's all I I can say just",
    "start": "1154280",
    "end": "1160039"
  },
  {
    "text": "anecdotally if you put exclamation marks in it's it's different that's myis all",
    "start": "1160039",
    "end": "1166960"
  },
  {
    "text": "right okay I think let's go go to um the next how many got we got six you already",
    "start": "1166960",
    "end": "1172640"
  },
  {
    "text": "that's pretty good okay this is just a general question I'll just answer this",
    "start": "1172640",
    "end": "1177960"
  },
  {
    "text": "really quick is it in general for translations or multilingual output is it better to instructor English or the native",
    "start": "1177960",
    "end": "1183600"
  },
  {
    "text": "language I think it's better to instruct in the native language if you speak the native",
    "start": "1183600",
    "end": "1188840"
  },
  {
    "text": "language if you only speak English and you're choosing between like a better prompt that's written in English versus",
    "start": "1188840",
    "end": "1195159"
  },
  {
    "text": "like a worse prompt that's written in a language that you don't understand I would probably default to writing it in",
    "start": "1195159",
    "end": "1201039"
  },
  {
    "text": "the language that I knew super well but ideally I think for the ideal prompt you would find a native speaker of the",
    "start": "1201039",
    "end": "1206679"
  },
  {
    "text": "language and explain your use case to them and have them write the",
    "start": "1206679",
    "end": "1212080"
  },
  {
    "text": "prompt yeah so for language that is not so familiar",
    "start": "1213600",
    "end": "1221679"
  },
  {
    "text": "we like maybe write the prompt English but let the the cloud will translate",
    "start": "1221679",
    "end": "1227080"
  },
  {
    "text": "output into the just WR the so if if it's I think is that not",
    "start": "1227080",
    "end": "1233720"
  },
  {
    "text": "the same question that I just answered is it different said it's better to write I",
    "start": "1233720",
    "end": "1239080"
  },
  {
    "text": "think it's better to have the prompt in in that language in in general if you can if you can write a really good",
    "start": "1239080",
    "end": "1244240"
  },
  {
    "text": "prompt all right let's go to this this next guy so you'll be acting as a test reviewer I pump up the size here too um",
    "start": "1244240",
    "end": "1254000"
  },
  {
    "text": "okay not sure if there's a way to I can hide this okay great responsible for improving unit tests based on a set of",
    "start": "1254000",
    "end": "1260360"
  },
  {
    "text": "requirements below as the project directory project path do include any other explanation",
    "start": "1260360",
    "end": "1267720"
  },
  {
    "text": "conversion or output besides the",
    "start": "1267720",
    "end": "1270960"
  },
  {
    "text": "Json okay this is great because it's going to let me show off",
    "start": "1273720",
    "end": "1280039"
  },
  {
    "text": "prefills so let's make a new prompt",
    "start": "1280039",
    "end": "1286159"
  },
  {
    "text": "here let's paste this in we have to use uh double brackets instead of single",
    "start": "1286159",
    "end": "1291559"
  },
  {
    "text": "brackets to get variables in the console and then I think there's",
    "start": "1291559",
    "end": "1296720"
  },
  {
    "text": "another but this Json string uh who who gave this prompt this is from uh Dan the",
    "start": "1296720",
    "end": "1303159"
  },
  {
    "text": "Json string Dan that's is that variable or is that is that like an example in",
    "start": "1303159",
    "end": "1309520"
  },
  {
    "text": "this PR template so this that's",
    "start": "1309520",
    "end": "1315360"
  },
  {
    "text": "yeah test of your agent does not return always return Json only yeah like almost",
    "start": "1341279",
    "end": "1346360"
  },
  {
    "text": "all of this is just like workarounds for the fact that it doesn't always speak Json right like you can see how many times we said that in the yeah and then",
    "start": "1346360",
    "end": "1353440"
  },
  {
    "text": "uh do you have an example input here uh so that first if you go up a little bit sorry so that first comment is from the",
    "start": "1353440",
    "end": "1360440"
  },
  {
    "text": "unit test writer so that is the input like the unit test writer writes a bunch of unit tests and then the reviewer",
    "start": "1360440",
    "end": "1366520"
  },
  {
    "text": "reviews it and makes them better so everything everything here is",
    "start": "1366520",
    "end": "1371760"
  },
  {
    "text": "is what I should put into yes and then you can see that second set this is this is a good result",
    "start": "1371760",
    "end": "1377760"
  },
  {
    "text": "where it writes Json which basically says cool update this file with these unit tests and here's the modifications",
    "start": "1377760",
    "end": "1384440"
  },
  {
    "text": "I made that sort of thing okay so in in this template here where would the thing that that I",
    "start": "1384440",
    "end": "1391080"
  },
  {
    "text": "just copied go well so essentially we don't provide",
    "start": "1391080",
    "end": "1397240"
  },
  {
    "text": "it in line with the prompt we just provide the com the conversation and then this thing jumps in in as a as a",
    "start": "1397240",
    "end": "1404240"
  },
  {
    "text": "separate agent so like the the context window is going to have the unit tests in it but we're saying respond in this",
    "start": "1404240",
    "end": "1411600"
  },
  {
    "text": "format given the unit tests that are earlier in the conversation that you're picking up so that this the thing that",
    "start": "1411600",
    "end": "1417159"
  },
  {
    "text": "you just pasted as like step three of a multi-shot conversation uh the thing like m not multi-shot multi-turn yeah",
    "start": "1417159",
    "end": "1423880"
  },
  {
    "text": "yeah the thing I just pasted was two shots right unit test writer and then a unit test reviewer and the reviewer is",
    "start": "1423880",
    "end": "1429400"
  },
  {
    "text": "the one that's having the problem it comes second okay so it' be something it would",
    "start": "1429400",
    "end": "1434440"
  },
  {
    "text": "be something like like this um",
    "start": "1434440",
    "end": "1439559"
  },
  {
    "text": "here are some unit tests written by a unit test writer",
    "start": "1439559",
    "end": "1448799"
  },
  {
    "text": "bot",
    "start": "1448799",
    "end": "1451799"
  },
  {
    "text": "right okay and then we have this now you didn't uh so okay so this this is",
    "start": "1456320",
    "end": "1463000"
  },
  {
    "text": "basically how it works is does this look right oh no it",
    "start": "1463000",
    "end": "1468200"
  },
  {
    "text": "does I mean this we we just we do this in sort of this larger conversation not",
    "start": "1468200",
    "end": "1473320"
  },
  {
    "text": "just as sort of a standalone prompt for this one okay so then here I put the unit test in right yep and then for",
    "start": "1473320",
    "end": "1478640"
  },
  {
    "text": "project path what sort of thing should I put there um anything I mean this is",
    "start": "1478640",
    "end": "1483919"
  },
  {
    "text": "this is just like the local directory that's going to be modified and so it actually has access to the files in that directory and it'll it'll fill in its",
    "start": "1483919",
    "end": "1490320"
  },
  {
    "text": "own sort of which what files to modify okay so then I'll just put uh that's",
    "start": "1490320",
    "end": "1496200"
  },
  {
    "text": "fine um something like that",
    "start": "1496200",
    "end": "1502440"
  },
  {
    "text": "yeah okay so let's see if it comes out with the Json or not uh baited breath",
    "start": "1506520",
    "end": "1511640"
  },
  {
    "text": "here yeah we did do most of our tests on cloud 3 and not 3.5 so 3.5 is probably a little better um we haven't done yeah I",
    "start": "1511640",
    "end": "1518240"
  },
  {
    "text": "mean if if if it if it makes it more realistic we could also uh switch the model version to to use high oh no I",
    "start": "1518240",
    "end": "1523960"
  },
  {
    "text": "mean we're going to upgrade so I'd rather see it with this okay what was",
    "start": "1523960",
    "end": "1529760"
  },
  {
    "text": "that zero is the temperature being set to zero intentional yeah I usually for",
    "start": "1529760",
    "end": "1535880"
  },
  {
    "text": "knowledge work I usually have the temperature set to zero",
    "start": "1535880",
    "end": "1540360"
  },
  {
    "text": "01 I think using temperature zero you'll probably get like marginally fewer hallucinations okay oh here we",
    "start": "1549200",
    "end": "1556440"
  },
  {
    "text": "go okay so it looks like in this case it did output Json I think yeah that that looks",
    "start": "1556440",
    "end": "1564880"
  },
  {
    "text": "plausible okay it's very long Json I guess that explains why it was taking so long to",
    "start": "1564880",
    "end": "1572559"
  },
  {
    "text": "looks like actually it even ran into the max output tokens because it didn't finish its Json uhu um just to make this",
    "start": "1572559",
    "end": "1578720"
  },
  {
    "text": "since this one is is kind of going kind of slow I will test it with Haiku uh let's and let's also increase",
    "start": "1578720",
    "end": "1586000"
  },
  {
    "text": "the U Max tokens to sample so that it doesn't run into that",
    "start": "1586000",
    "end": "1592120"
  },
  {
    "text": "issue so what I'm really hoping is to get a case that doesn't output Json so that then I can fix it and then it will",
    "start": "1593360",
    "end": "1599919"
  },
  {
    "text": "output Json if not I can still say like how I would fix it yeah that would be",
    "start": "1599919",
    "end": "1605000"
  },
  {
    "text": "great just honestly any comments you have just on how we structured things okay yeah so I mean this is like uh",
    "start": "1605000",
    "end": "1611000"
  },
  {
    "text": "definitely like a big request from people is like how do I make sure the model outputs Json the most reliable way",
    "start": "1611000",
    "end": "1618360"
  },
  {
    "text": "to do that I feel is using the uh assistant prefill so uh maybe some of",
    "start": "1618360",
    "end": "1624840"
  },
  {
    "text": "you have used this feature before maybe some of you have like only used uh other models such as GPT that don't offer this",
    "start": "1624840",
    "end": "1631320"
  },
  {
    "text": "feature something that you can do in the CLA API is partially prefill an",
    "start": "1631320",
    "end": "1636919"
  },
  {
    "text": "assistant message so what you're doing there is you're putting some words in quad's mouth as we call it and then when",
    "start": "1636919",
    "end": "1644640"
  },
  {
    "text": "Claude continues from there it assumes that it's already said whatever you told it that it had said uh and just that can",
    "start": "1644640",
    "end": "1653480"
  },
  {
    "text": "help you get it on the right path so for instance in this case uh if we want to make sure so the classic like bad",
    "start": "1653480",
    "end": "1659720"
  },
  {
    "text": "response from from Claud when people give it prompts like this where they want to get Json is quad would say",
    "start": "1659720",
    "end": "1665360"
  },
  {
    "text": "something like uh I'll just like add another message just to have some to type it might be like here is the Json",
    "start": "1665360",
    "end": "1673080"
  },
  {
    "text": "right have people seen stuff like this and this part right here is like",
    "start": "1673080",
    "end": "1679320"
  },
  {
    "text": "very annoying and difficult to get rid of so",
    "start": "1679320",
    "end": "1684440"
  },
  {
    "text": "okay so I I have I have two strategies uh let me actually just give like the",
    "start": "1684440",
    "end": "1689919"
  },
  {
    "text": "the simplest one they both though they both require a tiny bit of post-processing at the",
    "start": "1689919",
    "end": "1696679"
  },
  {
    "text": "end so let's start by uh let's actually like take out all this stuff about make",
    "start": "1696679",
    "end": "1701919"
  },
  {
    "text": "sure to only respond in Json that that could be one way to get it to to not do the uh to to to be",
    "start": "1701919",
    "end": "1709480"
  },
  {
    "text": "bad uh so we could just go like this let's try to make it not do uh",
    "start": "1709480",
    "end": "1715120"
  },
  {
    "text": "Json let's get rid of all this stuff okay so here now maybe it will do",
    "start": "1715120",
    "end": "1722200"
  },
  {
    "text": "the Preamble thing that we don't want it to do perfect",
    "start": "1722200",
    "end": "1728480"
  },
  {
    "text": "okay so an easy way to get it to not do that is to just take this and then put",
    "start": "1728559",
    "end": "1735799"
  },
  {
    "text": "it in the prefix so it thinks that it already said",
    "start": "1735799",
    "end": "1740880"
  },
  {
    "text": "that uh like this so if we do",
    "start": "1740880",
    "end": "1747519"
  },
  {
    "text": "that just the Json so what we're doing here is you",
    "start": "1747519",
    "end": "1753399"
  },
  {
    "text": "could think of quad almost like a like a child who's just like misbehaving and it wants to do something and you're and",
    "start": "1753399",
    "end": "1759799"
  },
  {
    "text": "you're like don't do the thing but it just keeps doing it because it just loves Preamble so much and it has this",
    "start": "1759799",
    "end": "1765200"
  },
  {
    "text": "like innate desire to to do them so one way is to like argue with it a lot but like if you have a kid sometimes you",
    "start": "1765200",
    "end": "1771519"
  },
  {
    "text": "know you just have to like let them do the thing that they want to do and then they'll get over it so in this case",
    "start": "1771519",
    "end": "1776760"
  },
  {
    "text": "that's basically what we did we just gave Claud this this prefill where we let it do the thing so as far as it's",
    "start": "1776760",
    "end": "1782960"
  },
  {
    "text": "concerned it already did the thing and then from there what what it's outputting is is is Json now if you want",
    "start": "1782960",
    "end": "1789880"
  },
  {
    "text": "to make this even more reliable you can put this nice little bracket here and then it's like oh dang",
    "start": "1789880",
    "end": "1797080"
  },
  {
    "text": "like I'm really in j mode now like I'm I'm really my my Json has actually already begun so it's at at this point",
    "start": "1797080",
    "end": "1803840"
  },
  {
    "text": "it's definitely not going to do the Preamble The only thing here here is if you sample with with this with this uh",
    "start": "1803840",
    "end": "1810960"
  },
  {
    "text": "prefill you will need to add the bracket back before you try to do your json.",
    "start": "1810960",
    "end": "1816200"
  },
  {
    "text": "loads or what have you because CLA is since since you told it that had already said the opening bracket it's not going",
    "start": "1816200",
    "end": "1822279"
  },
  {
    "text": "to give you another opening bracket uh okay so then another thing",
    "start": "1822279",
    "end": "1827519"
  },
  {
    "text": "that you can do is return the Json in Json",
    "start": "1827519",
    "end": "1834320"
  },
  {
    "text": "tags and then if we do this without the prefill let's try it without the",
    "start": "1834320",
    "end": "1840760"
  },
  {
    "text": "prefill you don't normally capitalize",
    "start": "1840760",
    "end": "1845679"
  },
  {
    "text": "Json I'm not a software engineer okay I'm a prompt engineer I don't even know that it's capitalized for all I know",
    "start": "1849000",
    "end": "1854080"
  },
  {
    "text": "that's just like an English word um but yeah good good thank you um",
    "start": "1854080",
    "end": "1860360"
  },
  {
    "text": "okay so here we we see it it it did the thing so it gave its Preamble right and then it gave the Json tag everything",
    "start": "1860360",
    "end": "1868320"
  },
  {
    "text": "within the Json tag is Json and then at the end it closed this Json tag so again",
    "start": "1868320",
    "end": "1875000"
  },
  {
    "text": "this requires like the tiniest smidgen of post-processing where you're saying like",
    "start": "1875000",
    "end": "1881519"
  },
  {
    "text": "you just it's like a regex you just like take everything within the Json tags and then and then use that you can even",
    "start": "1881519",
    "end": "1887559"
  },
  {
    "text": "combine these two techniques so you could say here's the updated Json and now you",
    "start": "1887559",
    "end": "1895200"
  },
  {
    "text": "give it the Json tag we can even put a bracket Here and Now what we'll see is it will just give the Json minus the",
    "start": "1895200",
    "end": "1900760"
  },
  {
    "text": "bracket and then it will close the bracket and then it will close with uh the Json tag the closed Json",
    "start": "1900760",
    "end": "1909278"
  },
  {
    "text": "tag there we go and it also gave this uh so you can see it did at first I was",
    "start": "1912320",
    "end": "1917639"
  },
  {
    "text": "like a little bit panicked because I didn't see the closed Json tag at the very bottom but then I saw that it actually did include the tag up here and",
    "start": "1917639",
    "end": "1924880"
  },
  {
    "text": "then it gave this little explanation afterwards so this is another uh useful",
    "start": "1924880",
    "end": "1930240"
  },
  {
    "text": "thing this will uh save you some uh time and tokens in trouble one thing we could",
    "start": "1930240",
    "end": "1935679"
  },
  {
    "text": "do like like it cost Claud like it cost you money to get Claude to Output all",
    "start": "1935679",
    "end": "1941279"
  },
  {
    "text": "this stuff and you probably you probably don't need it in most cases you don't need the explanation you just need the",
    "start": "1941279",
    "end": "1947440"
  },
  {
    "text": "Json so one thing we could do is we could say do not include any",
    "start": "1947440",
    "end": "1954159"
  },
  {
    "text": "explanation after the Json right does it help to yell in that Cas I mean probably",
    "start": "1954159",
    "end": "1959720"
  },
  {
    "text": "but I don't know I honestly I don't yell that much I'm just like this is actually meant to be my parody of like what a",
    "start": "1959720",
    "end": "1965559"
  },
  {
    "text": "frustrated prompt engineer would write if they were like couldn't get rid of this but in practice you you might not",
    "start": "1965559",
    "end": "1970960"
  },
  {
    "text": "need to do that but the simpler way to to do this there's a and we're getting",
    "start": "1970960",
    "end": "1976200"
  },
  {
    "text": "outside the realm of prompt engineering for second and into the world of like API parameters but uh that's okay",
    "start": "1976200",
    "end": "1981960"
  },
  {
    "text": "there's a parameter that's called stop sequences and if you set so we told it",
    "start": "1981960",
    "end": "1987000"
  },
  {
    "text": "to return the Json and Json tags right so uh there's no functionality to this in the console so I can't show it off at",
    "start": "1987000",
    "end": "1993559"
  },
  {
    "text": "this exact moment but in the API there's a parameter called stop sequences and if you add uh",
    "start": "1993559",
    "end": "2001320"
  },
  {
    "text": "this Clos Json tag that I've highlighted with my mouse if you add that to the stop sequences then it will just hard",
    "start": "2001320",
    "end": "2009000"
  },
  {
    "text": "stop after it outputs those and you don't even have to worry about telling it not to continue from there because it just won't even sample from there you",
    "start": "2009000",
    "end": "2015440"
  },
  {
    "text": "won't be charged it's all good so one of the things that I'm sort of hoping to",
    "start": "2015440",
    "end": "2020760"
  },
  {
    "text": "impart with this talk is that a lot of times it's cheaper and easier to do a",
    "start": "2020760",
    "end": "2027760"
  },
  {
    "text": "little bit of work outside of a call to the llm and not even worry about prompting",
    "start": "2027760",
    "end": "2033600"
  },
  {
    "text": "because prompting is can feel sometimes like non-deterministic you don't know what the is going to do so when you can",
    "start": "2033600",
    "end": "2039559"
  },
  {
    "text": "offload stuff to code especially if the code is really easy to write it's like just do that right like don't don't put",
    "start": "2039559",
    "end": "2045000"
  },
  {
    "text": "a bunch of stuff in the prompt about you must output Json just just use the pre-fill and then parse it out with the",
    "start": "2045000",
    "end": "2050679"
  },
  {
    "text": "the regx you know don't don't add a bunch of stuff about how you have to to stop after you say a certain word just",
    "start": "2050679",
    "end": "2055878"
  },
  {
    "text": "add it to the stop sequences so like simple is is is better and following",
    "start": "2055879",
    "end": "2061839"
  },
  {
    "text": "back on code is better than relying on prompts yeah is a prefill available to",
    "start": "2061839",
    "end": "2067919"
  },
  {
    "text": "the API yes the pre-fill is available through the API what you do is you",
    "start": "2067919",
    "end": "2072960"
  },
  {
    "text": "include an assistant message as the last message in the messages",
    "start": "2072960",
    "end": "2078079"
  },
  {
    "text": "list and when I say an assistant message I I just mean a message where the role is set to assistant and uh what would",
    "start": "2078079",
    "end": "2085280"
  },
  {
    "text": "have happened if you had your the text that you put in the prefill you just put it into the last line of the",
    "start": "2085280",
    "end": "2092200"
  },
  {
    "text": "instructions so in other words if I said uh I'm actually not sure that's a good question so let's actually try",
    "start": "2092200",
    "end": "2100480"
  },
  {
    "text": "that I I I I genuinely do not know how CL will respond to this so let's",
    "start": "2103800",
    "end": "2110000"
  },
  {
    "text": "see so it looks like what it did was it looks to me like what it did",
    "start": "2111599",
    "end": "2116920"
  },
  {
    "text": "without looking at this Json is it included an additional Open",
    "start": "2116920",
    "end": "2122880"
  },
  {
    "text": "Bracket right cuz it it's supposed to already have started with an Open Bracket but here it started with with an",
    "start": "2122880",
    "end": "2128119"
  },
  {
    "text": "additional Open Bracket so it kind of almost worked but not quite anyways I don't recommend doing this but that was",
    "start": "2128119",
    "end": "2133760"
  },
  {
    "text": "uh fun just to out of curiosity sake yeah that we just remove that and uh",
    "start": "2133760",
    "end": "2142000"
  },
  {
    "text": "after the sentence like yeah yeah uh after the sentence we can",
    "start": "2142000",
    "end": "2147520"
  },
  {
    "text": "just write it like uh you wrote right uh written the Json written the response in the Json format and then in the next",
    "start": "2147520",
    "end": "2154560"
  },
  {
    "text": "line you can just write Json colon then leave it I think it will oh so like if I",
    "start": "2154560",
    "end": "2161160"
  },
  {
    "text": "said something like this like this yeah that's a yeah I",
    "start": "2161160",
    "end": "2167200"
  },
  {
    "text": "could see this working yeah looks like it worked pretty",
    "start": "2167200",
    "end": "2172520"
  },
  {
    "text": "well I I I think there's like a lot of ways to accomplish this I think the ways that I showed are the most reliable so",
    "start": "2172520",
    "end": "2178400"
  },
  {
    "text": "that's what I would like officially recommend uh but yeah like definitely",
    "start": "2178400",
    "end": "2185119"
  },
  {
    "text": "experiment if you were going to uh like try to use this for production or",
    "start": "2185119",
    "end": "2190440"
  },
  {
    "text": "whatever what like these exact kind of things you're playing around with right now how would you think about testing that like at some sort of scale like how",
    "start": "2190440",
    "end": "2197880"
  },
  {
    "text": "do we test it at some sort of scale yeah so more than like one like the one shot test we did right yeah yeah",
    "start": "2197880",
    "end": "2204480"
  },
  {
    "text": "yeah to test it at scale you need a bunch of test cases and if you don't have test cases",
    "start": "2204480",
    "end": "2213119"
  },
  {
    "text": "okay this is maybe a good time to maybe show off",
    "start": "2213119",
    "end": "2218520"
  },
  {
    "text": "this thing although I'm actually not sure if it will work uh so one I guess a more pointed question is this case I",
    "start": "2218520",
    "end": "2225280"
  },
  {
    "text": "think test cases are useful when I'm writing a prompt to deduce whether like",
    "start": "2225280",
    "end": "2230680"
  },
  {
    "text": "does asking it to think step by step lead to this thing being more accurate but in this case for for formatting I",
    "start": "2230680",
    "end": "2236720"
  },
  {
    "text": "guess what I'm wondering is like could you have this prompt and then feed in",
    "start": "2236720",
    "end": "2242000"
  },
  {
    "text": "the output and the prompt and then ask the model itself to evaluate like how good these various Things Are at",
    "start": "2242000",
    "end": "2247680"
  },
  {
    "text": "following the instructions yeah yeah okay so can we do model grading can we model grade the outputs yeah especially",
    "start": "2247680",
    "end": "2253200"
  },
  {
    "text": "for formatting related things we need a I would not model grade the outputs",
    "start": "2253200",
    "end": "2258240"
  },
  {
    "text": "because formatting is something that I can check in code so if I can do anything in code and I don't have to call the LM the LM is like this crazy",
    "start": "2258240",
    "end": "2265160"
  },
  {
    "text": "black box right it's like if I don't need to like make this pilgrimage to the Oracle and like ask it I I'd rather just",
    "start": "2265160",
    "end": "2270920"
  },
  {
    "text": "do it like in in code so formatting specifically we're we're kind of like in",
    "start": "2270920",
    "end": "2276040"
  },
  {
    "text": "luck it's easy to check for something like the other the the previous prompt we looked at where the outputs are a lot",
    "start": "2276040",
    "end": "2281440"
  },
  {
    "text": "more squishy we might possibly model grading could work possibly we might",
    "start": "2281440",
    "end": "2286599"
  },
  {
    "text": "need a human to evaluate the answers so just to lightly push back on that so I'm wondering like I actually put an example",
    "start": "2286599",
    "end": "2292400"
  },
  {
    "text": "on the slack Channel we don't need to get to it because we're talking through it now but like for uh let's imagine I",
    "start": "2292400",
    "end": "2297560"
  },
  {
    "text": "don't have or actually maybe maybe tags are the answer to this um like imagine I'm asking for a summary or something",
    "start": "2297560",
    "end": "2304680"
  },
  {
    "text": "and then I want to deduce whether there's additional chat like cont content like before or after that in",
    "start": "2304680",
    "end": "2309839"
  },
  {
    "text": "that case would you I would have my mental model would have been to use like an llm as a grer but it sounds like",
    "start": "2309839",
    "end": "2316040"
  },
  {
    "text": "maybe would you encourage instead using the summary tags and checking like hard coding for additional text around that",
    "start": "2316040",
    "end": "2323720"
  },
  {
    "text": "yeah I think that will be uh pretty quick and easy to do also just having",
    "start": "2323720",
    "end": "2329400"
  },
  {
    "text": "the summary be in summary tags is like generally good practice I generally have all my outputs inside tags to make it",
    "start": "2329400",
    "end": "2335440"
  },
  {
    "text": "really easy to extract them I I don't think there's really any any downside to doing that so and it it might even be",
    "start": "2335440",
    "end": "2342920"
  },
  {
    "text": "that by doing that you effectively fix your entire issue and you don't even like need to need to do the test anymore",
    "start": "2342920",
    "end": "2347960"
  },
  {
    "text": "or and you just put close summary in the stop sequences and and you're kind of good to go okay",
    "start": "2347960",
    "end": "2353520"
  },
  {
    "text": "cool but that's also does sound like a problem that an llm uh could",
    "start": "2353520",
    "end": "2359279"
  },
  {
    "text": "grade okay uh let's go to the next uh prompt",
    "start": "2359520",
    "end": "2365119"
  },
  {
    "text": "here just shout out your question here's a very poorly formatted Excel",
    "start": "2365119",
    "end": "2370680"
  },
  {
    "text": "spreadsheet um I got a question real quick so um this seems like a really",
    "start": "2370680",
    "end": "2376319"
  },
  {
    "text": "ridiculously like powerful attack Vector so can we test the prompt real",
    "start": "2376319",
    "end": "2381760"
  },
  {
    "text": "quick um I don't want to get into too much like jailbreaking stuff here sorry",
    "start": "2381760",
    "end": "2386839"
  },
  {
    "text": "okay apologies so that that's kind of my specialty okay yeah um I'm going to go",
    "start": "2386839",
    "end": "2393440"
  },
  {
    "text": "to the next next prompt um so what do we have",
    "start": "2393440",
    "end": "2399318"
  },
  {
    "text": "here here's a poorly formatted Excel spreadsheet CSV please extract all data into Json",
    "start": "2400640",
    "end": "2408800"
  },
  {
    "text": "okay how can we so uh Jan or Yan yeah uh",
    "start": "2408800",
    "end": "2413880"
  },
  {
    "text": "is it Jan or yan yan yan what what is the actual text that I should can can you can you paste the",
    "start": "2413880",
    "end": "2419880"
  },
  {
    "text": "text here because I I don't know how to get the CSV into the uh into the console I've just been oh hey thanks I've just",
    "start": "2419880",
    "end": "2427040"
  },
  {
    "text": "been just copying the entire CSV and putting that into the prompt again I've been",
    "start": "2427040",
    "end": "2433920"
  },
  {
    "text": "trying to use CLA to extract some information from spreadsheets and it's",
    "start": "2433920",
    "end": "2439720"
  },
  {
    "text": "always been very very hard it hallucinates a lot or it skips a lot of stuff I was wondering if you maybe more",
    "start": "2439720",
    "end": "2446240"
  },
  {
    "text": "generally how do you have CLA analyze really poorly formatted spreadsheets to",
    "start": "2446240",
    "end": "2451560"
  },
  {
    "text": "sometimes the different clusters or multiple data sets in the same sheet and things like that",
    "start": "2451560",
    "end": "2457599"
  },
  {
    "text": "okay I'll try to answer the general question of having uh analyzing like",
    "start": "2457599",
    "end": "2462720"
  },
  {
    "text": "poorly formatted spreadsheets the first thing that came to mind especially when you're talking about how the",
    "start": "2462720",
    "end": "2468480"
  },
  {
    "text": "spreadsheets are very big is breaking the problem down into so so give it like",
    "start": "2468480",
    "end": "2474160"
  },
  {
    "text": "fewer spreadsheets at a time give it fewer Columns of the spreadsheet at a time only give it the the columns that",
    "start": "2474160",
    "end": "2480000"
  },
  {
    "text": "it needs to to work with um and then make the questions sort of smaller and",
    "start": "2480000",
    "end": "2485960"
  },
  {
    "text": "more bite-sized and then tackle it that way by by breaking it down so at that",
    "start": "2485960",
    "end": "2492160"
  },
  {
    "text": "level of gen gener generality that's would be would be my answer here",
    "start": "2492160",
    "end": "2498599"
  },
  {
    "text": "um I I I'd also be curious to look at this one more specifically right now I'm just struggling with how to like copy",
    "start": "2498599",
    "end": "2504720"
  },
  {
    "text": "the text and put it into the tool that's what I did but it keeps",
    "start": "2504720",
    "end": "2510040"
  },
  {
    "text": "downloading it I guess I can um the ne sorry the next tab",
    "start": "2510040",
    "end": "2518079"
  },
  {
    "text": "this is that other one sorry I don't want to click open my",
    "start": "2518079",
    "end": "2523560"
  },
  {
    "text": "downloads I'm scared I'm going to like reveal some private information this is my work computer so I want to just do it",
    "start": "2523560",
    "end": "2529000"
  },
  {
    "text": "all in the",
    "start": "2529000",
    "end": "2531319"
  },
  {
    "text": "browser so you can go to the next one no yeah let's do the next one okay you are social media Ghost",
    "start": "2534960",
    "end": "2542640"
  },
  {
    "text": "Writer given the b along for article okay uh generally we would recommend",
    "start": "2545119",
    "end": "2551359"
  },
  {
    "text": "putting the I like this one is short we can do some quick hits here uh we would recommend putting the instructions after",
    "start": "2551359",
    "end": "2559359"
  },
  {
    "text": "the document that's similar to the question that was asked about should we have the information first or the instructions",
    "start": "2559359",
    "end": "2565520"
  },
  {
    "text": "first particularly with long documents it's a little bit better to give the instructions uh at the end let's also",
    "start": "2565520",
    "end": "2572319"
  },
  {
    "text": "put some XML tags here uh let let's just like clean up the",
    "start": "2572319",
    "end": "2578599"
  },
  {
    "text": "grammar a little bit given the above long form article create 5 to 10 tweets",
    "start": "2578599",
    "end": "2584800"
  },
  {
    "text": "don't use hashtags don't be hyperbolic and don't be cringe uh return a Json array of post content probably good to",
    "start": "2584800",
    "end": "2591400"
  },
  {
    "text": "to give an example uh of the",
    "start": "2591400",
    "end": "2597480"
  },
  {
    "text": "format uh so we could do like uh I guess we can just do it we return",
    "start": "2601079",
    "end": "2608079"
  },
  {
    "text": "like a list wait what did you originally have it is there a special reason that you",
    "start": "2608079",
    "end": "2613839"
  },
  {
    "text": "wanted it to be a Json array or is it just to make it parsible uh just to make it parsible for",
    "start": "2613839",
    "end": "2620119"
  },
  {
    "text": "automations okay yeah so let's say return in I'm just a huge fan of these",
    "start": "2620119",
    "end": "2627240"
  },
  {
    "text": "tags so let's do it like this",
    "start": "2627240",
    "end": "2631720"
  },
  {
    "text": "okay so that is that that's some stuff without adding examples the other thing",
    "start": "2658800",
    "end": "2664480"
  },
  {
    "text": "that I would want to do is to give some illustrative examples of what",
    "start": "2664480",
    "end": "2670280"
  },
  {
    "text": "it means to not be cringe so how long are these",
    "start": "2670280",
    "end": "2677160"
  },
  {
    "text": "documents put I used perfect",
    "start": "2677160",
    "end": "2684280"
  },
  {
    "text": "yeah let's actually let's run this as",
    "start": "2684280",
    "end": "2688880"
  },
  {
    "text": "is",
    "start": "2690319",
    "end": "2693319"
  },
  {
    "text": "last oh yep thank you now we can take",
    "start": "2695599",
    "end": "2704160"
  },
  {
    "text": "this uh oh what if they write cringe tweets about our product I'm going to be",
    "start": "2705440",
    "end": "2712880"
  },
  {
    "text": "embarrassed okay this doesn't include any hashtags doesn't seem very hyperbolic is",
    "start": "2716400",
    "end": "2723720"
  },
  {
    "text": "this cringe what do we think new feature alert that could be a little",
    "start": "2723720",
    "end": "2729760"
  },
  {
    "text": "bit cringe there's no Emojis a",
    "start": "2729760",
    "end": "2735920"
  },
  {
    "text": "good okay what do you uh your name was uh Charlie what do you think of this",
    "start": "2735920",
    "end": "2741200"
  },
  {
    "text": "Charlie uh I think they are adequate but not engaging not engaging okay so yeah",
    "start": "2741200",
    "end": "2749760"
  },
  {
    "text": "yeah yeah so we can try to make it more engaging without making it cringe so let's say don't you be hashtags but",
    "start": "2749760",
    "end": "2756000"
  },
  {
    "text": "cringe try to make the tweets engaging are these meant to be",
    "start": "2756000",
    "end": "2762760"
  },
  {
    "text": "tweeted from the anthropic Twitter account or from like the AI",
    "start": "2762760",
    "end": "2768319"
  },
  {
    "text": "influencer Twitter account sure let's say AI influencer Twitter account",
    "start": "2768319",
    "end": "2776000"
  },
  {
    "text": "okay let's see how this goes I'm going to switch back back to Dove too sorry",
    "start": "2784520",
    "end": "2791040"
  },
  {
    "text": "um exciting news is it to break it up into small in",
    "start": "2791880",
    "end": "2799040"
  },
  {
    "text": "thep comp sentences is it better to break up sentences to use like small sentences in",
    "start": "2799040",
    "end": "2806000"
  },
  {
    "text": "the prompt or big sentences I think generally in English",
    "start": "2806000",
    "end": "2811520"
  },
  {
    "text": "writing it's better to use small sentences and small words so so I think it's probably also",
    "start": "2811520",
    "end": "2818240"
  },
  {
    "text": "better to do that in a prompt I think it's fine to use big words if you are really sure you know what you're doing",
    "start": "2818240",
    "end": "2824599"
  },
  {
    "text": "and you know that it's the exact right word for the situation sometimes I'll find myself",
    "start": "2824599",
    "end": "2829920"
  },
  {
    "text": "using more academic language if I want the output to seem a bit more",
    "start": "2829920",
    "end": "2835800"
  },
  {
    "text": "academic generally I think simple small sentences is is",
    "start": "2835800",
    "end": "2841880"
  },
  {
    "text": "better uh okay so these are maybe a little bit more",
    "start": "2841880",
    "end": "2849318"
  },
  {
    "text": "engaging like they have these questions here want to try it",
    "start": "2851000",
    "end": "2857280"
  },
  {
    "text": "uh what do we think it's got exclamation points and question marks is it better",
    "start": "2857800",
    "end": "2863359"
  },
  {
    "text": "do you want it to be even more engaging or",
    "start": "2863359",
    "end": "2867960"
  },
  {
    "text": "something let's see cuz Okay so I honestly think temperatures doesn't is a",
    "start": "2869319",
    "end": "2874960"
  },
  {
    "text": "bit overrated maybe uh we can we can see if how how how that how that differs",
    "start": "2874960",
    "end": "2881480"
  },
  {
    "text": "though I'm not sure exactly how to distinguish these from the the previous ones they look kind of similar to me",
    "start": "2893240",
    "end": "2900000"
  },
  {
    "text": "from the ones with with temperature uh temperature one or temperature zero",
    "start": "2900000",
    "end": "2907240"
  },
  {
    "text": "M toity that's right yeah so what I was",
    "start": "2907960",
    "end": "2913960"
  },
  {
    "text": "going to say is I think this is roughly as far as you can take this without examples I think the best thing to",
    "start": "2913960",
    "end": "2920000"
  },
  {
    "text": "improve this prompt would be either examples of the sort of tweets that that",
    "start": "2920000",
    "end": "2925119"
  },
  {
    "text": "you want or even an entire other document an",
    "start": "2925119",
    "end": "2930520"
  },
  {
    "text": "example of tweets that go with that document and maybe like multiple of those so",
    "start": "2930520",
    "end": "2938119"
  },
  {
    "text": "uh if if you're cost limited maybe you don't want to put in all those input tokens every time but I don't know the",
    "start": "2938119",
    "end": "2945119"
  },
  {
    "text": "models are pretty cheap now and we don't need to generate that many tweets so if they if they have like any",
    "start": "2945119",
    "end": "2951720"
  },
  {
    "text": "economic value to you at all it's probably pretty cost effective to put so",
    "start": "2951720",
    "end": "2957599"
  },
  {
    "text": "basically like but it's it's more work on your part because what you're doing then is so okay so the the way that I",
    "start": "2957599",
    "end": "2964559"
  },
  {
    "text": "would actually do this uh is I would start out with some some document I would have qua write a bunch of tweets I",
    "start": "2964559",
    "end": "2972359"
  },
  {
    "text": "would take the ones that I liked and maybe I would write some more or get like my friend to write some more",
    "start": "2972359",
    "end": "2978119"
  },
  {
    "text": "or maybe I'd have CLA oops uh Claud generate 100 tweets and then I would take the the seven that that I liked",
    "start": "2978119",
    "end": "2984400"
  },
  {
    "text": "best and then I would put that in as an example and then from there I'd sample",
    "start": "2984400",
    "end": "2989559"
  },
  {
    "text": "okay now here's another document and then write a bunch more tweets based on this and what I would do is iteratively",
    "start": "2989559",
    "end": "2996240"
  },
  {
    "text": "build up this uh list of documents plus example",
    "start": "2996240",
    "end": "3001760"
  },
  {
    "text": "tweets and then I'd put them all into the prompt and it would look something like this uh so let's actually do that",
    "start": "3001760",
    "end": "3008559"
  },
  {
    "text": "so let's imagine that we had done this so it could be like you know system prompt you",
    "start": "3008559",
    "end": "3013880"
  },
  {
    "text": "uh you are an AI influencer who writes",
    "start": "3013880",
    "end": "3021040"
  },
  {
    "text": "engaging social media content about uh new models and",
    "start": "3021040",
    "end": "3028119"
  },
  {
    "text": "releases uh it could be like here are some example of",
    "start": "3028119",
    "end": "3033760"
  },
  {
    "text": "documents along with the tweets you wrote about",
    "start": "3033760",
    "end": "3040920"
  },
  {
    "text": "them um and here you would actually I'm going",
    "start": "3043319",
    "end": "3050160"
  },
  {
    "text": "to write this but you would actually put the literal text of the document here",
    "start": "3050160",
    "end": "3057760"
  },
  {
    "text": "and here again you put a literal tweet here this could either be something that you wrote or something that quad wrote or you know you something that clad",
    "start": "3063319",
    "end": "3069799"
  },
  {
    "text": "wrote and then you edited like a lot of times quad might give you an example that's not perfect but it's close enough",
    "start": "3069799",
    "end": "3075240"
  },
  {
    "text": "and then you you'll change it a little bit to to make it perfect I have honestly given uh",
    "start": "3075240",
    "end": "3082520"
  },
  {
    "text": "multi-shot examples pretty short shrift in this so far relative to their level of",
    "start": "3082520",
    "end": "3089599"
  },
  {
    "text": "importance like I I think that in reality most of the the gains most of",
    "start": "3089599",
    "end": "3096119"
  },
  {
    "text": "the effort most of the gains of writing a good prompt is literally just picking the perfect document that goes here",
    "start": "3096119",
    "end": "3102559"
  },
  {
    "text": "picking the perfect set of tweets that go here altering and and changing them to to to modulate the",
    "start": "3102559",
    "end": "3109000"
  },
  {
    "text": "tone uh in some ways that's more important than like everything else that I've said combined like another way to",
    "start": "3109000",
    "end": "3115520"
  },
  {
    "text": "do the whole Json thing would just be like with examples of quad giving the stuff without a preamble the pre the Json one is maybe an exception uh",
    "start": "3115520",
    "end": "3122960"
  },
  {
    "text": "because the the the prefill approach works so well there along with the tags but for anything else the examples are",
    "start": "3122960",
    "end": "3129040"
  },
  {
    "text": "are really huge anyways then we would",
    "start": "3129040",
    "end": "3134359"
  },
  {
    "text": "uh response like this or do you find further success with an exchange of",
    "start": "3138640",
    "end": "3146119"
  },
  {
    "text": "messages between the agent and the user where you're putting your F shot prompts in there really good question and",
    "start": "3146119",
    "end": "3152480"
  },
  {
    "text": "something that I would dearly love to know the answer to but I don't the the question is I I don't need to repeat the",
    "start": "3152480",
    "end": "3159280"
  },
  {
    "text": "questions think people can hear them uh but I'll I'll repeat anyway so do we want to just put all the examples in one",
    "start": "3159280",
    "end": "3164880"
  },
  {
    "text": "big giant examples block like this or do we want to structure the examples as a dialogue where the human says something",
    "start": "3164880",
    "end": "3171880"
  },
  {
    "text": "and then the assistant says something back and we're literally like putting a large number of messages into the mesages list I typically do it this way",
    "start": "3171880",
    "end": "3179880"
  },
  {
    "text": "with a big examples block but it's mostly because it's less work for me and",
    "start": "3179880",
    "end": "3185559"
  },
  {
    "text": "I don't have any evidence that this works either better or worse I did do some testing of this at one point on a",
    "start": "3185559",
    "end": "3191680"
  },
  {
    "text": "few data sets and I found that it didn't make much of a difference for my particular case but there's a lot of",
    "start": "3191680",
    "end": "3196799"
  },
  {
    "text": "like little particulars that went into my testing that make me not very confident in in the result that I got so",
    "start": "3196799",
    "end": "3203599"
  },
  {
    "text": "sorry for a bit of an unsatisfying answer here I'll just say I don't think it if it is wrong to do one giant",
    "start": "3203599",
    "end": "3209000"
  },
  {
    "text": "examples block I don't think it's like very wrong do you use anti examples too so",
    "start": "3209000",
    "end": "3215400"
  },
  {
    "text": "like in here would you give it a thing and say like this would be bad because this is cringe yes yeah I think that is",
    "start": "3215400",
    "end": "3222680"
  },
  {
    "text": "good I think it's good to include negative examples particularly around like the cringe thing where where Claude",
    "start": "3222680",
    "end": "3228480"
  },
  {
    "text": "might mess up uh I think just negative examples on their own don't usually get",
    "start": "3228480",
    "end": "3234799"
  },
  {
    "text": "you there you want to have some positive examples too but I think it's great to",
    "start": "3234799",
    "end": "3240240"
  },
  {
    "text": "have especially like contrasting pairs so like here's a document like here's a cringe tweet about this document here's",
    "start": "3240240",
    "end": "3247520"
  },
  {
    "text": "excellent tweet about about the same document uh and like set those up side by side I think that's pretty pretty",
    "start": "3247520",
    "end": "3254280"
  },
  {
    "text": "powerful and I do that and I think it it helps quad and then if if you also include like the reasoning for it right",
    "start": "3254280",
    "end": "3259559"
  },
  {
    "text": "so like if it was a cringe tweet it has like a little reasoning of like why why",
    "start": "3259559",
    "end": "3264680"
  },
  {
    "text": "um do you also do you trust that reasoning for the model so like if you ask like hey give me like what were you",
    "start": "3264680",
    "end": "3271880"
  },
  {
    "text": "thinking when you were writing this tweet and then write me this this tweet when you're reading through your",
    "start": "3271880",
    "end": "3277200"
  },
  {
    "text": "examples to choose the best ones how much do you trust that reasoning and how much do you rely on that versus just",
    "start": "3277200",
    "end": "3283960"
  },
  {
    "text": "like I just care about like the input output I don't trust the reasoning very much especially if it's after something",
    "start": "3283960",
    "end": "3289079"
  },
  {
    "text": "the model already said then I like really don't trust it yeah but I mean humans are not very good at explaining",
    "start": "3289079",
    "end": "3295040"
  },
  {
    "text": "why we do the things that we do we're really good at rationalizing and coming up with like fake reasons but a lot of",
    "start": "3295040",
    "end": "3301040"
  },
  {
    "text": "times we don't even know why we do the things that we did let alone be able to coherently explain them to someone else",
    "start": "3301040",
    "end": "3307440"
  },
  {
    "text": "so I there there's there's there's a subtlety here so something that does",
    "start": "3307440",
    "end": "3313559"
  },
  {
    "text": "work pretty well is having the model think about its reasoning in advance and like go through different reasons or",
    "start": "3313559",
    "end": "3319280"
  },
  {
    "text": "rationales for why it might choose one option or the other or think about what sort of things might go into good",
    "start": "3319280",
    "end": "3324559"
  },
  {
    "text": "response so if I had the model do some thinking in advance before it gave the",
    "start": "3324559",
    "end": "3330119"
  },
  {
    "text": "response then I might just trust or assume that the response would be",
    "start": "3330119",
    "end": "3335559"
  },
  {
    "text": "better having a bunch of explanation for why I did the thing after it probably I",
    "start": "3335559",
    "end": "3341039"
  },
  {
    "text": "I would not trust that sorry you had a question for a",
    "start": "3341039",
    "end": "3345520"
  },
  {
    "text": "while do I give reasoning to explain the examples yes I do a lot of giving giving",
    "start": "3355000",
    "end": "3360640"
  },
  {
    "text": "reasoning to explain the examples so for instance just in this case uh one thing",
    "start": "3360640",
    "end": "3367480"
  },
  {
    "text": "that we could do here is like um we could add something like",
    "start": "3367480",
    "end": "3373760"
  },
  {
    "text": "uh I I was going to say tweet planning but maybe it's like key points of",
    "start": "3373760",
    "end": "3379359"
  },
  {
    "text": "document and then we here we'd have some key points like the document uh",
    "start": "3379359",
    "end": "3387079"
  },
  {
    "text": "presents the launch",
    "start": "3387079",
    "end": "3390000"
  },
  {
    "text": "of so you would have this after the examples so if you have 10 examples no",
    "start": "3394920",
    "end": "3400200"
  },
  {
    "text": "this is before the examples or sorry so it's this is part of the example right here so I I I in in this particular",
    "start": "3400200",
    "end": "3406280"
  },
  {
    "text": "example in this example block I gave it a document now I'm doing this this key points business got it um",
    "start": "3406280",
    "end": "3416119"
  },
  {
    "text": "and then I would have these tweets now this key points could be something that I wrote myself or it could be something that Claude wrote and then uh I'm I'm uh",
    "start": "3416720",
    "end": "3425640"
  },
  {
    "text": "editing it or if CLA did a perfect job I maybe I could just include the thing that Claud wrote but now in order to get",
    "start": "3425640",
    "end": "3430880"
  },
  {
    "text": "this get clad to do this uh we would also say something like um return in",
    "start": "3430880",
    "end": "3435960"
  },
  {
    "text": "this format uh key points a list of the key points from the",
    "start": "3435960",
    "end": "3444640"
  },
  {
    "text": "document so so this is like a lightweight Chain of Thought where we're having the model do some thinking in advance and we also gave it examples of",
    "start": "3444960",
    "end": "3452599"
  },
  {
    "text": "it doing the thinking in advance uh like this uh",
    "start": "3452599",
    "end": "3460240"
  },
  {
    "text": "yeah um yeah so let's imagine we like really want to give examples like this",
    "start": "3463599",
    "end": "3468720"
  },
  {
    "text": "but we have a problem which is that our documents are like super long and I'm greedy and want to save on input tokens",
    "start": "3468720",
    "end": "3474839"
  },
  {
    "text": "would you air on the side of doing like one document but a really good example or doing like truncated",
    "start": "3474839",
    "end": "3481680"
  },
  {
    "text": "versions of more documents I would that's a good question I would air on the side of one extremely",
    "start": "3481680",
    "end": "3488640"
  },
  {
    "text": "good example and not truncated versions of more documents but I would also want",
    "start": "3488640",
    "end": "3493680"
  },
  {
    "text": "to look at the outputs and test that assumption because it's possible that with only one example Claude would",
    "start": "3493680",
    "end": "3499640"
  },
  {
    "text": "fixate on aspects of the exact document that uploaded and start trying to transfer them to your your document so I",
    "start": "3499640",
    "end": "3508280"
  },
  {
    "text": "think it's it's one of those it would be Case by case but I would I would want to start with like having one extremely",
    "start": "3508280",
    "end": "3513839"
  },
  {
    "text": "good example generally I think that like less but like higher quality is a better",
    "start": "3513839",
    "end": "3519079"
  },
  {
    "text": "way to go than like more and lower quality cool thank you okay we have a lot of prompts here",
    "start": "3519079",
    "end": "3525119"
  },
  {
    "text": "let's go to the okay this is good I was hoping we would get some like Persona ones here",
    "start": "3525119",
    "end": "3533880"
  },
  {
    "text": "okay so this is this looks like something where we're trying to get quad to to role play in these different",
    "start": "3540400",
    "end": "3549760"
  },
  {
    "text": "protocols so let's try this out and let's see how it works so this looks something where we're going to have like",
    "start": "3550160",
    "end": "3555319"
  },
  {
    "text": "a this looks like it's like a meant to be a multi-turn prompt right so this is like a",
    "start": "3555319",
    "end": "3562240"
  },
  {
    "text": "conversation you are talking to assistant",
    "start": "3562240",
    "end": "3567200"
  },
  {
    "text": "it said execute greater than P assist where's that basically at the top",
    "start": "3567880",
    "end": "3575760"
  },
  {
    "text": "R and then can decide who you want to talk to oh thanks so much so you see",
    "start": "3575760",
    "end": "3583160"
  },
  {
    "text": "three rolls at the top and then if you do that P assist you see down there that's highlighted in in yellow you can",
    "start": "3583160",
    "end": "3589839"
  },
  {
    "text": "just do um that little arrow p and then you can pick a different Persona and you",
    "start": "3589839",
    "end": "3596319"
  },
  {
    "text": "can have them talk between themselves or you can just switch we use this for designers in in our shop to do synthetic",
    "start": "3596319",
    "end": "3604920"
  },
  {
    "text": "interviews to synthetic users basically it allows us to switch back and forth and then uh what what issues are uh",
    "start": "3604920",
    "end": "3612599"
  },
  {
    "text": "troubles have you been having with this I'm guessing you have seen a lot of role playing prompts out there so I was just",
    "start": "3612599",
    "end": "3618359"
  },
  {
    "text": "wondering if you see anything that's perhaps not as optimized as it could be or any other best practices practices",
    "start": "3618359",
    "end": "3624520"
  },
  {
    "text": "for role playing part particularly with multiple synthetic personas within the same session",
    "start": "3624520",
    "end": "3631280"
  },
  {
    "text": "yeah okay for single personas there's there's one answer that I would give",
    "start": "3631280",
    "end": "3636599"
  },
  {
    "text": "this multiple personas thing actually I haven't worked that much with but here's like off the top of my head here is",
    "start": "3636599",
    "end": "3641960"
  },
  {
    "text": "probably how I would think about it I would give all the personas to I",
    "start": "3641960",
    "end": "3647119"
  },
  {
    "text": "would write a separate prompt for each Persona and then I would have the users's command trigger some coding",
    "start": "3647119",
    "end": "3654400"
  },
  {
    "text": "logic where it would decide which bot to send the the which which prompt to send that reply to so this is getting",
    "start": "3654400",
    "end": "3661359"
  },
  {
    "text": "back to the thing that I said before about like don't do it in a prompt if you don't have to like this I mean this prompt like is like there's a lot of",
    "start": "3661359",
    "end": "3668839"
  },
  {
    "text": "thought that went into it which is probably makes it work a lot better than it would have if you hadn't put as much effort into it but I think it's going to",
    "start": "3668839",
    "end": "3674599"
  },
  {
    "text": "be easier if you just dynamically route the query based on uh what the the user",
    "start": "3674599",
    "end": "3680960"
  },
  {
    "text": "said does that make sense it does okay you're talking about like if we were to use the API instead of just the chat",
    "start": "3680960",
    "end": "3688880"
  },
  {
    "text": "yeah construct something like this yeah exactly but you're doing this just in the chat just in the chat but I I",
    "start": "3688880",
    "end": "3695480"
  },
  {
    "text": "appreciate I definitely appreciate the the note there so maybe related to that",
    "start": "3695480",
    "end": "3700559"
  },
  {
    "text": "one of the other things is how much have you dealt with having a second thread",
    "start": "3700559",
    "end": "3705680"
  },
  {
    "text": "with the API that acts as maybe the entity that's capturing inputs from",
    "start": "3705680",
    "end": "3712000"
  },
  {
    "text": "multiple ones into a single thread you know what I mean like let's say that I build an app and I have the user",
    "start": "3712000",
    "end": "3719079"
  },
  {
    "text": "interact with these different synthetic personas but then I have a second interaction with the API that's tying",
    "start": "3719079",
    "end": "3725480"
  },
  {
    "text": "these things together into a cohesive Hole uh I don't know if you guys have",
    "start": "3725480",
    "end": "3730720"
  },
  {
    "text": "explored some of that I'll be curious yeah I don't I don't I don't",
    "start": "3730720",
    "end": "3736640"
  },
  {
    "text": "have a great answer for that one sorry I do want to kind of test this prompt out though just to kind of see how it goes",
    "start": "3736640",
    "end": "3742000"
  },
  {
    "text": "so um maybe here I would say uh I can just say something like so how",
    "start": "3742000",
    "end": "3748319"
  },
  {
    "text": "how how would I switch it I could so do the the right arrow P yeah right arrow p",
    "start": "3748319",
    "end": "3754520"
  },
  {
    "text": "and then type Sam and then say hey yeah so now I could you could say Hey",
    "start": "3754520",
    "end": "3762680"
  },
  {
    "text": "how do you what's your process to look for the right to for the best uh medication pricing whenever you get sick",
    "start": "3762680",
    "end": "3770440"
  },
  {
    "text": "or something like that and then here in this particular case if you switch to Joe Joe is optimize more for uh",
    "start": "3770440",
    "end": "3777960"
  },
  {
    "text": "convenience versus cost savings so you have two different types of users and we can learn from yeah okay so quad did the",
    "start": "3777960",
    "end": "3785240"
  },
  {
    "text": "thing here that I want to show you all like how to get rid of uh where oh yes",
    "start": "3785240",
    "end": "3791520"
  },
  {
    "text": "yes as Sam it's like that's not something that Sam would say right yeah",
    "start": "3791520",
    "end": "3797839"
  },
  {
    "text": "uh so I don't know for sure this is going to work I feel like a magician that's about to do a trick but like I",
    "start": "3797839",
    "end": "3803359"
  },
  {
    "text": "haven't practiced it but generally something that is is pretty useful uh",
    "start": "3803359",
    "end": "3808680"
  },
  {
    "text": "here is to we could say uh prend each response with the name of the",
    "start": "3808680",
    "end": "3817079"
  },
  {
    "text": "current Persona in",
    "start": "3817079",
    "end": "3821000"
  },
  {
    "text": "Brackets so one thing I'm going to do here is I'm G to change this like multi-shot",
    "start": "3828400",
    "end": "3834680"
  },
  {
    "text": "a little bit also because if quad sees itself not doing",
    "start": "3834680",
    "end": "3839760"
  },
  {
    "text": "the thing that I told it to do actually let's let's just redo the whole the whole conversation or we can take out uh",
    "start": "3839760",
    "end": "3845160"
  },
  {
    "text": "this um so let's let's just like run that back you are talking to assistant nice",
    "start": "3845160",
    "end": "3852279"
  },
  {
    "text": "and now we could say and now we could say the same thing",
    "start": "3852279",
    "end": "3859160"
  },
  {
    "text": "like what's your process for finding the best prices for Medicare",
    "start": "3859160",
    "end": "3867720"
  },
  {
    "text": "ation oh okay so I guess we need to do this we",
    "start": "3870440",
    "end": "3876240"
  },
  {
    "text": "need to like change in a separate call yeah okay great",
    "start": "3876240",
    "end": "3883039"
  },
  {
    "text": "now it's going to work totally it's going to totally",
    "start": "3883039",
    "end": "3888278"
  },
  {
    "text": "work okay it's a little bit better right it didn't say as Sam this is like something that human might maybe say",
    "start": "3888359",
    "end": "3895720"
  },
  {
    "text": "like as as someone who's okay I don't know um it's better than it",
    "start": "3895720",
    "end": "3902119"
  },
  {
    "text": "was before right uh maybe we could say something",
    "start": "3902119",
    "end": "3907920"
  },
  {
    "text": "like you don't need to uh say too much",
    "start": "3909720",
    "end": "3915480"
  },
  {
    "text": "about your persona and your responses just stay in character hey",
    "start": "3915480",
    "end": "3922319"
  },
  {
    "text": "quick question what are your thoughts on using things in the negative sense versus yo check it out it worked a lot",
    "start": "3922319",
    "end": "3927440"
  },
  {
    "text": "better sorry to interrupt oh yeah very nice very nice",
    "start": "3927440",
    "end": "3934000"
  },
  {
    "text": "um yeah so yeah what are your thoughts on using like negative stuff like you",
    "start": "3934000",
    "end": "3939200"
  },
  {
    "text": "don't versus the positive sense yeah I think positive is like a little bit better in this case I don't really have",
    "start": "3939200",
    "end": "3945079"
  },
  {
    "text": "a good answer for why I phrase this negatively uh I guess I did a combination I was like you don't need to",
    "start": "3945079",
    "end": "3951359"
  },
  {
    "text": "say too much just stay in character um I guess I think it's it's better to use like a light touch like if",
    "start": "3951359",
    "end": "3957319"
  },
  {
    "text": "you're doing negative prompting I think there's like a little bit of a thing going on with reverse psychology where",
    "start": "3957319",
    "end": "3962400"
  },
  {
    "text": "if you tell the model like don't talk about elephants don't definitely no elephants definitely don't say anything",
    "start": "3962400",
    "end": "3967799"
  },
  {
    "text": "about elephant it might make it more likely to talk about an elephant so if you do use negative prompting I think",
    "start": "3967799",
    "end": "3972880"
  },
  {
    "text": "it's better to have like a light touch where you just kind of say it once but like don't dwell on it too much um also",
    "start": "3972880",
    "end": "3979799"
  },
  {
    "text": "something similar with parenting it's like if you don't want your kid to eat prunes you're just like oh we're not having prunes today and then you just change the subject but if you really",
    "start": "3979799",
    "end": "3986200"
  },
  {
    "text": "like emphasize that there are like no prunes to be had then you might get more uh push back hi that um I noticed you're",
    "start": "3986200",
    "end": "3994119"
  },
  {
    "text": "not using the system prompt much like is there a reason for that or what do you think the biggest value items for a",
    "start": "3994119",
    "end": "3999599"
  },
  {
    "text": "system prompt are yeah system prompt personally the only thing that I ever put in the system prompt is a role so I",
    "start": "3999599",
    "end": "4006680"
  },
  {
    "text": "might say like you are this you are that I think generally CLA follows instructions a little bit better if they're in the the human prompt and not",
    "start": "4006680",
    "end": "4014279"
  },
  {
    "text": "in the system prompt uh the exception is things like tool use where maybe there's been some explicit fine-tuning on like",
    "start": "4014279",
    "end": "4021119"
  },
  {
    "text": "certain system prompts uh specifically for like General prompts like the ones we've been going over here though I",
    "start": "4021119",
    "end": "4027520"
  },
  {
    "text": "don't really think you need to use the system prompt very much",
    "start": "4027520",
    "end": "4034599"
  },
  {
    "text": "yeah thank you one thing we found when using the user prompt I guess sometimes",
    "start": "4036119",
    "end": "4041520"
  },
  {
    "text": "is it makes it more prone to hallucinations because it thinks the user is saying it and so we migrated",
    "start": "4041520",
    "end": "4048079"
  },
  {
    "text": "things to the system prompt more I don't know if you have any experience with that yeah yeah I've actually heard that",
    "start": "4048079",
    "end": "4053520"
  },
  {
    "text": "before so it's possible I'm missing something I've heard this from enough people that I could just be wrong so I'm",
    "start": "4053520",
    "end": "4059960"
  },
  {
    "text": "unusually likely to be wrong when when I say this I think that if you just put a bunch of context and you're like here's",
    "start": "4059960",
    "end": "4065279"
  },
  {
    "text": "the message from the user open user bracket and then put the message and then close the user bracket it will it",
    "start": "4065279",
    "end": "4071079"
  },
  {
    "text": "will work and you won't have that issue anymore that said like",
    "start": "4071079",
    "end": "4076680"
  },
  {
    "text": "I don't know maybe it does uh fall over sometimes but that would be my default is just to like specify even more",
    "start": "4076680",
    "end": "4083200"
  },
  {
    "text": "clearly in the if you're having this issue be like here's the message from the user here's the stuff that I want",
    "start": "4083200",
    "end": "4088599"
  },
  {
    "text": "you to do and I think it's it probably won't get confused by that uh I have a",
    "start": "4088599",
    "end": "4093960"
  },
  {
    "text": "question about the uh counter examples so before in order to get it to say not",
    "start": "4093960",
    "end": "4099238"
  },
  {
    "text": "cringy cringey things you were saying provide it with a counter example so but",
    "start": "4099239",
    "end": "4105040"
  },
  {
    "text": "here in the case of where you're doing this uh character bot you haven't provided it any counter examples so this",
    "start": "4105040",
    "end": "4111880"
  },
  {
    "text": "is sort of like a generic question so if the model is trained on preference optimization with uh examples and",
    "start": "4111880",
    "end": "4118679"
  },
  {
    "text": "counter examples do you get a better result in the prompting well uh I don't I don't know",
    "start": "4118679",
    "end": "4127199"
  },
  {
    "text": "that the details of the rhf have that much bearing because I I think when the model's",
    "start": "4127199",
    "end": "4133120"
  },
  {
    "text": "trained it it doesn't usually see those both in the same like window it it's more that it's like some stuff that",
    "start": "4133120",
    "end": "4139798"
  },
  {
    "text": "happens with like the the RL algorithms so I don't think that's necessarily the right way to think of it with counter",
    "start": "4139799",
    "end": "4145838"
  },
  {
    "text": "examples I don't feel that I have to include them in every prompt it's just a tool that I have in my toolbox that I'd use",
    "start": "4145839",
    "end": "4152159"
  },
  {
    "text": "sometimes in regards to like negative prompting uh I'm over here hi oh uh do",
    "start": "4152159",
    "end": "4159040"
  },
  {
    "text": "you think that it would be better to do negative prompting using control vectors like what you uh what you talked about",
    "start": "4159040",
    "end": "4164679"
  },
  {
    "text": "in your uh skill monos semanticity paper uh and maybe like having like a negative",
    "start": "4164679",
    "end": "4169880"
  },
  {
    "text": "version of the vector as your kind of negative prompt instead of mentioning it in the prompt outright yeah steering is",
    "start": "4169880",
    "end": "4176838"
  },
  {
    "text": "is is still like super new we don't know how well it works relative to prompting",
    "start": "4176839",
    "end": "4183278"
  },
  {
    "text": "I'm like a a you know dieh hard prompter till the end so uh I guess I I've played",
    "start": "4183279",
    "end": "4188520"
  },
  {
    "text": "around with a little bit I I haven't I haven't found it to work as well as as prompting in my experience so far that",
    "start": "4188520",
    "end": "4194238"
  },
  {
    "text": "said there's like a lot of resarch improvements that I won't get into in too much detail but there's a lot of stuff that could make it work better",
    "start": "4194239",
    "end": "4200520"
  },
  {
    "text": "than so like right now it's like finding these these features and then you're steering according uh to the features",
    "start": "4200520",
    "end": "4207040"
  },
  {
    "text": "which are sort of like these abstractions on top of the underlying Vector space yep there's other possibilities for how you could steer",
    "start": "4207040",
    "end": "4213719"
  },
  {
    "text": "and there's like academic papers that you can read where you're steering according to just like the the",
    "start": "4213719",
    "end": "4219480"
  },
  {
    "text": "differences in the activations versus like trying to pull it out to this feature first so maybe that would work a",
    "start": "4219480",
    "end": "4225040"
  },
  {
    "text": "bit better better like the control vectors thing y I haven't played with it enough to know for sure uh but I think",
    "start": "4225040",
    "end": "4230360"
  },
  {
    "text": "there's definitely like something along that line those lines will work eventually I can't say in the long term",
    "start": "4230360",
    "end": "4236320"
  },
  {
    "text": "if it'll work better or worse than prompting right now I still think prompting works like a lot better I mean from my experience with like smaller",
    "start": "4236320",
    "end": "4242760"
  },
  {
    "text": "models and trying to work with control vectors I've seen that it's better when it comes to style MH uh than it is for",
    "start": "4242760",
    "end": "4248560"
  },
  {
    "text": "like actual deterministic prop yeah pretty interesting sometimes I feel like stuff from smaller models transfers",
    "start": "4248560",
    "end": "4254960"
  },
  {
    "text": "sometimes doesn't transfer I don't have a great intuition for what does and doesn't transfer between small and large models but yeah it's all right good",
    "start": "4254960",
    "end": "4261280"
  },
  {
    "text": "points thank you okay I think we've uh gone over this roleplay stuff enough",
    "start": "4261280",
    "end": "4267520"
  },
  {
    "text": "let's go to the next one I'm going to upload a few screenshots of my dating profile okay this is our first image one",
    "start": "4267520",
    "end": "4275560"
  },
  {
    "text": "are there any screenshots no screenshots uh okay",
    "start": "4275560",
    "end": "4281480"
  },
  {
    "text": "actually somebody responded in the very first uh in reply so since we're doing images uh maybe I'll start there um if",
    "start": "4281480",
    "end": "4289679"
  },
  {
    "text": "you scroll down it's that was me that was you uh let me try and find my message here",
    "start": "4289679",
    "end": "4296560"
  },
  {
    "text": "all you said it's at the bottom of",
    "start": "4296560",
    "end": "4299840"
  },
  {
    "text": "the riveting to watch me scroll through this channel I'm sure",
    "start": "4307880",
    "end": "4314480"
  },
  {
    "text": "oh there's a lot of messages here okay here we",
    "start": "4320639",
    "end": "4325599"
  },
  {
    "text": "go okay so let's um can I copy the",
    "start": "4327199",
    "end": "4334120"
  },
  {
    "text": "image copy image okay cool I actually don't know if I can paste it into the console so I might fall back on using",
    "start": "4334120",
    "end": "4339880"
  },
  {
    "text": "call. a for this",
    "start": "4339880",
    "end": "4343760"
  },
  {
    "text": "placing images is not enabled right now okay let's try qu.",
    "start": "4345400",
    "end": "4350120"
  },
  {
    "text": "then um so then this the question was or the the the prompt here",
    "start": "4354239",
    "end": "4360678"
  },
  {
    "text": "was high performing validated AI",
    "start": "4365520",
    "end": "4370320"
  },
  {
    "text": "model sorry I like lost all your formatting here",
    "start": "4371280",
    "end": "4377120"
  },
  {
    "text": "okay so in this image here if we zoom in it's supposed to get mdty white",
    "start": "4378600",
    "end": "4384960"
  },
  {
    "text": "and 86 I'm having a hard time reading this",
    "start": "4384960",
    "end": "4390280"
  },
  {
    "text": "uh 8687 that's the hard one that it messes up on 8687 and then 8687 down",
    "start": "4390280",
    "end": "4396000"
  },
  {
    "text": "here and then in this one it's just 867 yeah they that's a typo that's a typo the human and so I'm hoping it can",
    "start": "4396000",
    "end": "4402400"
  },
  {
    "text": "correct for that I'm just trying to pull out kind of the average data all three",
    "start": "4402400",
    "end": "4408800"
  },
  {
    "text": "combined okay and it said it looks like it said middle Mark so it's it's misreading the okay so I don't know too",
    "start": "4409760",
    "end": "4418360"
  },
  {
    "text": "many good tips for image is but I'll I'll tell you what I have so one of the",
    "start": "4418360",
    "end": "4423560"
  },
  {
    "text": "things that you said oops sorry um one of the things that you said here was uh",
    "start": "4423560",
    "end": "4431360"
  },
  {
    "text": "that it works better with zooming in and cropping the image that's definitely like the easiest win",
    "start": "4431360",
    "end": "4437600"
  },
  {
    "text": "that you can have is just giving it like a higher quality image taking out the unnecessary details that might be hard",
    "start": "4437600",
    "end": "4445040"
  },
  {
    "text": "to do programmatically because it's like you don't know what that which details are necessary and unnecessary but for",
    "start": "4445040",
    "end": "4450199"
  },
  {
    "text": "the same reason that including extraneous information in text form you probably won't get as good results if",
    "start": "4450199",
    "end": "4456480"
  },
  {
    "text": "you include extraneous information in in image form the results probably won't be as good uh either so the more that you",
    "start": "4456480",
    "end": "4463400"
  },
  {
    "text": "can like narrow in on the exact information that you need the better um is the model down sampling",
    "start": "4463400",
    "end": "4470400"
  },
  {
    "text": "large images I don't know slash can't talk about that but definitely having like higher quality bigger images is is",
    "start": "4470400",
    "end": "4476719"
  },
  {
    "text": "better I I did just read on your website that it says it down it down samples to a thousand pixels by a thousand pixels",
    "start": "4476719",
    "end": "4483480"
  },
  {
    "text": "okay great that can be found with Google okay so then any general tips on how to",
    "start": "4483480",
    "end": "4489080"
  },
  {
    "text": "discuss images with Sonet um my number one tip for images is",
    "start": "4489080",
    "end": "4494440"
  },
  {
    "text": "to start by having the model describe everything it sees about the image so I",
    "start": "4494440",
    "end": "4499480"
  },
  {
    "text": "don't know if that will work here this this example is like this one is hard enough for me to even read that I like I kind of doubt that Claud will do well on",
    "start": "4499480",
    "end": "4505760"
  },
  {
    "text": "it regardless of of what we say but we can we can uh give it another shot one thing I've noticed when I attempted that",
    "start": "4505760",
    "end": "4512679"
  },
  {
    "text": "where if I asked it to go like tube by tube in that image if it like the first",
    "start": "4512679",
    "end": "4519040"
  },
  {
    "text": "tube if it came to the wrong conclusion it would use that and come to that same wrong conclusion on multiple tubes like",
    "start": "4519040",
    "end": "4525719"
  },
  {
    "text": "it it made it so there was some kind of like directionality in its thinking where if it got the answer wrong at first it would project that onto the",
    "start": "4525719",
    "end": "4532239"
  },
  {
    "text": "rest of the image it was analyzed yes I think that's definitely true if the model starts off on the wrong path it",
    "start": "4532239",
    "end": "4538280"
  },
  {
    "text": "probably just continue going on the wrong path it's trying really hard to be self-consistent M and it's it's and this is why",
    "start": "4538280",
    "end": "4546960"
  },
  {
    "text": "self-correction is such a big like Frontier for LMS in general right now",
    "start": "4546960",
    "end": "4553800"
  },
  {
    "text": "but as of this month",
    "start": "4553800",
    "end": "4556920"
  },
  {
    "text": "um I found like text track and OCR models I've played with don't do as well with some of the handwriting um like if",
    "start": "4562960",
    "end": "4568520"
  },
  {
    "text": "I zoom in on this image it actually does perform pretty well um from some of these fairly messy handwriting that's",
    "start": "4568520",
    "end": "4575480"
  },
  {
    "text": "even hard for a human okay yeah unfortunately I don't know how to get better results out of",
    "start": "4575480",
    "end": "4580920"
  },
  {
    "text": "this other than Maybe by by cropping it better and upsampling okay cool thank",
    "start": "4580920",
    "end": "4586320"
  },
  {
    "text": "you oops um here we",
    "start": "4586320",
    "end": "4592920"
  },
  {
    "text": "are so let's scroll up to where we were",
    "start": "4592920",
    "end": "4597560"
  },
  {
    "text": "before okay yeah still no screenshots there how do I enable",
    "start": "4610719",
    "end": "4616800"
  },
  {
    "text": "fragments uh what are fragments is fragments like the pre-fill",
    "start": "4616800",
    "end": "4623840"
  },
  {
    "text": "part the pre artifacts oh okay uh it's just a",
    "start": "4623840",
    "end": "4631440"
  },
  {
    "text": "setting it's in the bottom left of the you have to enable it yeah you can find it online or people will help you",
    "start": "4631440",
    "end": "4638199"
  },
  {
    "text": "uh sorry so I often dump full traceback",
    "start": "4638199",
    "end": "4643960"
  },
  {
    "text": "errors directly into the prompt box I often dump full traceback error directly into the prompt box as API it seems",
    "start": "4643960",
    "end": "4650480"
  },
  {
    "text": "exceptional at not running into Trace back Loops I don't know like if that's",
    "start": "4650480",
    "end": "4656440"
  },
  {
    "text": "intentional like I literally I'll just take the entire Trace back zero Conta to",
    "start": "4656440",
    "end": "4662480"
  },
  {
    "text": "Claude and I'll just dump the entire thing in yeah and then it'll it'll it'll",
    "start": "4662480",
    "end": "4667600"
  },
  {
    "text": "give me the fix okay great so but is it can you can you can you elaborate on how",
    "start": "4667600",
    "end": "4673120"
  },
  {
    "text": "that might have how this for example like this only really appeared with like",
    "start": "4673120",
    "end": "4679719"
  },
  {
    "text": "very recently like you'd have to explain explicitly a lot the models get better man they get better every every I",
    "start": "4679719",
    "end": "4686520"
  },
  {
    "text": "understand but this is like you know this isn't prompt like this is prompt engineering we're talking about right so",
    "start": "4686520",
    "end": "4691840"
  },
  {
    "text": "I'm just I'm just wondering like is this is this a form of prompt engineering or is just the model being good sounds more",
    "start": "4691840",
    "end": "4698360"
  },
  {
    "text": "like the model being good if you're just dumping it in right I'm going to move to this this prompt here okay so",
    "start": "4698360",
    "end": "4706719"
  },
  {
    "text": "uh the to the person who uploaded this do you and generally uh to anyone who's uploaded uh more examples if you could",
    "start": "4708520",
    "end": "4715679"
  },
  {
    "text": "just like put some stuff in the thread like write some stuff about what the issue is that you're having or like why",
    "start": "4715679",
    "end": "4721120"
  },
  {
    "text": "it's not working uh that would be great this is actually a followup to",
    "start": "4721120",
    "end": "4726600"
  },
  {
    "text": "like what I was doing with the translation so basically what I'm trying to get to do is to actually analyze the",
    "start": "4726600",
    "end": "4733679"
  },
  {
    "text": "text so like in this you know there's original English there's a bad Japanese translation and",
    "start": "4733679",
    "end": "4739880"
  },
  {
    "text": "I'm trying to get to score between 1 and five how good the translation is and so what I've been doing is adding a lot of",
    "start": "4739880",
    "end": "4745719"
  },
  {
    "text": "stuff to try to get to do sort of Chain of Thought to yeah you know see like because they'll notice errors but you",
    "start": "4745719",
    "end": "4751719"
  },
  {
    "text": "know it just generally does a very bad job at scoring yeah okay so this is great uh",
    "start": "4751719",
    "end": "4757440"
  },
  {
    "text": "I'm really glad that you asked this cuz model grading is something that I mean it would be incredibly useful if it",
    "start": "4757440",
    "end": "4762560"
  },
  {
    "text": "worked and right now it's in a place where it like sometimes kind of works and sometimes doesn't so let's uh past this into the",
    "start": "4762560",
    "end": "4771480"
  },
  {
    "text": "console okay so we have some English text and we have some  yep yep",
    "start": "4772360",
    "end": "4780239"
  },
  {
    "text": "yep then we got the Japanese text so is this a good translation or a bad translation terrible terrible",
    "start": "4791199",
    "end": "4797679"
  },
  {
    "text": "translation okay and quad's actually supposed to be good at Japanese too",
    "start": "4797679",
    "end": "4804320"
  },
  {
    "text": "so oh this is somebody else but I'm saying if clad is good at Japanese it should be good at like judging other",
    "start": "4804320",
    "end": "4809679"
  },
  {
    "text": "people's Japanese in theory the in theory okay so now we've got the answer",
    "start": "4809679",
    "end": "4815920"
  },
  {
    "text": "here so um I guess it's stalled out here for whatever reason so what are we doing in",
    "start": "4815920",
    "end": "4822440"
  },
  {
    "text": "this prompt we're scoring between one and five as below one is many grammatical errors the",
    "start": "4822440",
    "end": "4829320"
  },
  {
    "text": "native would never make contains multiple grammatical errors and average quality translation with some errors",
    "start": "4829320",
    "end": "4835840"
  },
  {
    "text": "okay that that looks pretty good look for specific clues or",
    "start": "4835840",
    "end": "4842158"
  },
  {
    "text": "indicators I don't know why it uh I think that's just a bug I think I'll will conclude here",
    "start": "4846320",
    "end": "4854719"
  },
  {
    "text": "okay so it gave it a three but we want it to give a one okay now have you found that it's",
    "start": "4855679",
    "end": "4863400"
  },
  {
    "text": "generally too forgiving or too strict or that it's just all over the place well",
    "start": "4863400",
    "end": "4869800"
  },
  {
    "text": "it's all over the place also it seems to um confuse sometimes content uh versus",
    "start": "4869800",
    "end": "4876120"
  },
  {
    "text": "uh you know so like for example this is from I think the hrf uh you know set so",
    "start": "4876120",
    "end": "4881400"
  },
  {
    "text": "you know the content is fine but so it might not actually rate It Low even though it's a terrible translation",
    "start": "4881400",
    "end": "4886600"
  },
  {
    "text": "because it thinks the content is okay even though if you asked it even to list all the errors there are a dozen errors",
    "start": "4886600",
    "end": "4894159"
  },
  {
    "text": "in that you know single piece of text for the translation yeah uh so that's what I'm trying to also see if you know",
    "start": "4894159",
    "end": "4899480"
  },
  {
    "text": "is there anywhere to like get to separate out um the grammatical or the actual translation errors versus yeah",
    "start": "4899480",
    "end": "4907280"
  },
  {
    "text": "okay a few thoughts so generally this is like a thing where if you ask the model if some text is",
    "start": "4907280",
    "end": "4913679"
  },
  {
    "text": "like good or bad it's sort of if the text is like about a nice subject it's more likely to say",
    "start": "4913679",
    "end": "4919719"
  },
  {
    "text": "that it's good in always like it's a good translation like it's well written it is flows very logically and if it's",
    "start": "4919719",
    "end": "4926040"
  },
  {
    "text": "about like a negative subject it's more likely to like criticize it and say that it doesn't flow well",
    "start": "4926040",
    "end": "4931800"
  },
  {
    "text": "yep I think you can get at uh those issues by typing language about it in",
    "start": "4931800",
    "end": "4938000"
  },
  {
    "text": "the prompt so for instance here you might say something like um",
    "start": "4938000",
    "end": "4946039"
  },
  {
    "text": "is H uh one is the worst and five should be",
    "start": "4947639",
    "end": "4953960"
  },
  {
    "text": "the best that's sort of like implicit in uh this rubric up",
    "start": "4953960",
    "end": "4960480"
  },
  {
    "text": "here but it might be good to say it",
    "start": "4961040",
    "end": "4964960"
  },
  {
    "text": "anyways how do you get around the fact that you may not have a Japanese tokenizer",
    "start": "4967520",
    "end": "4975280"
  },
  {
    "text": "do you have a Japanese tokenizer in clad quad the API will will tokenize anything",
    "start": "4976679",
    "end": "4981880"
  },
  {
    "text": "but how is it trained how is it trained ume off off topic for and also I don't",
    "start": "4981880",
    "end": "4989159"
  },
  {
    "text": "know I don't think I actually don't think there is a tokenizer for Claud",
    "start": "4989159",
    "end": "4994440"
  },
  {
    "text": "like oh so I I mean unless you say otherwise there's there's not I mean if you upload if you upload some text it",
    "start": "4994440",
    "end": "5000840"
  },
  {
    "text": "will be tokenized but pre it's not pre-trained so you're not going to get a really good answer for this or Japanese",
    "start": "5000840",
    "end": "5007639"
  },
  {
    "text": "text i' I've tested this okay Claude Claude speaks the best Japanese of any model available actually all right we",
    "start": "5007639",
    "end": "5014320"
  },
  {
    "text": "don't need to debate like claud's Japanese skill let's just like",
    "start": "5014320",
    "end": "5019800"
  },
  {
    "text": "uh uh but the tokenizer isn't available and so that would be interesting",
    "start": "5019800",
    "end": "5027159"
  },
  {
    "text": "okay yeah um I have a question about programming sorry can we we actually uh",
    "start": "5030400",
    "end": "5035880"
  },
  {
    "text": "cut the questions off while I type this this prompt here um okay so it's extra important to so what we're trying to do",
    "start": "5035880",
    "end": "5042360"
  },
  {
    "text": "here is get it to distinguish between the the like ethical nature of the text",
    "start": "5042360",
    "end": "5047760"
  },
  {
    "text": "and the quality of the translation so is it useful to tell it to be like extra",
    "start": "5047760",
    "end": "5053080"
  },
  {
    "text": "critical say like you're grading a uh you know like I don't know like graduate",
    "start": "5053080",
    "end": "5059199"
  },
  {
    "text": "course you know I'm a little bit all over the place I need to like type this out before I can clear the queue and like respond to other questions here so",
    "start": "5059199",
    "end": "5066159"
  },
  {
    "text": "it's important to distinguish between um",
    "start": "5066159",
    "end": "5072599"
  },
  {
    "text": "the uh what's a good word here like [Music]",
    "start": "5081520",
    "end": "5086600"
  },
  {
    "text": "um uh risque topics or um are",
    "start": "5086600",
    "end": "5096320"
  },
  {
    "text": "yeah so I don't know something like this could help the model uh not pay so much",
    "start": "5112960",
    "end": "5119199"
  },
  {
    "text": "attention the main thing that I would want to do for this prompt is just add a bunch of examples",
    "start": "5119199",
    "end": "5125719"
  },
  {
    "text": "so for each category I would add at least one example of that category so",
    "start": "5125719",
    "end": "5131679"
  },
  {
    "text": "like I have like a really bad translation and I'd say why it's a one and you can say that in your own words",
    "start": "5131679",
    "end": "5136840"
  },
  {
    "text": "and I'd have an example of like a twole translation a three Lev translation and",
    "start": "5136840",
    "end": "5142520"
  },
  {
    "text": "so on okay and in each case before you get to the answer you would have the",
    "start": "5142520",
    "end": "5148600"
  },
  {
    "text": "explanation for why it's good or bad I can't tape all that here among other reasons because I don't speak Japanese",
    "start": "5148600",
    "end": "5154520"
  },
  {
    "text": "mhm but I think that's the most valuable thing that that you could do here otherwise I mean like the formatting",
    "start": "5154520",
    "end": "5160239"
  },
  {
    "text": "looks really good the fact that you're doing the Chain of Thought in advance looks good I I think",
    "start": "5160239",
    "end": "5168760"
  },
  {
    "text": "um yeah I think maybe this specific Clues are indicators I think you could",
    "start": "5169520",
    "end": "5175119"
  },
  {
    "text": "go into a little bit more detail here about what is how shot every single uh",
    "start": "5175119",
    "end": "5183400"
  },
  {
    "text": "example or you know grade with an example basically yeah I mean it's it's tedious to write out all these examples",
    "start": "5183400",
    "end": "5189880"
  },
  {
    "text": "but a quad can help and then you have the problem of just editing Cloud's response uh versus like writing all out",
    "start": "5189880",
    "end": "5195400"
  },
  {
    "text": "yourself and B it really does lead to better performance versus like almost anything else that that you could do you",
    "start": "5195400",
    "end": "5202000"
  },
  {
    "text": "think it's better to use a number scale or ask to say like good bad you know",
    "start": "5202000",
    "end": "5207719"
  },
  {
    "text": "yeah in terms of the scale on these on these rubrics I think either a number scale or good bad is fine the thing I'd",
    "start": "5207719",
    "end": "5216480"
  },
  {
    "text": "be careful about with the number scale is that I don't think it's very well calibrated so if you're telling it like choose a number from one through 100",
    "start": "5216480",
    "end": "5223639"
  },
  {
    "text": "it's not going to be like a unbiased estimator necessarily so I'd probably just limit the granularity to maybe five",
    "start": "5223639",
    "end": "5230239"
  },
  {
    "text": "different classes",
    "start": "5230239",
    "end": "5235560"
  },
  {
    "text": "yeah this is a case where uh you might be able to utilize like log probs and",
    "start": "5239199",
    "end": "5244800"
  },
  {
    "text": "I'm wondering if that's something you ever use in any of your work or other prompts yeah I think I I agree this is",
    "start": "5244800",
    "end": "5251639"
  },
  {
    "text": "could be a case where log problems would be useful if you could get like the probability of each each grade yeah the",
    "start": "5251639",
    "end": "5259159"
  },
  {
    "text": "thing so here's the thing with log problems is you really want the Chain of Thought beforehand and the Chain of",
    "start": "5259159",
    "end": "5266080"
  },
  {
    "text": "Thought I think is going to get you more of a win than using the log problems but log problems there's",
    "start": "5266080",
    "end": "5273520"
  },
  {
    "text": "there's no in in in any model I don't think there's a way where you can just say sample all the way through and then",
    "start": "5273520",
    "end": "5278960"
  },
  {
    "text": "output after you output this like closed Chain of Thought tag then give me the log probs of whatever comes next mhm so",
    "start": "5278960",
    "end": "5285600"
  },
  {
    "text": "if you are going to use the log probs then you're looking at this like multi-turn setup where you first sample",
    "start": "5285600",
    "end": "5291239"
  },
  {
    "text": "all the The Chain of Thought or sample all the like prec confutation that that it wants to do M and then cut it off",
    "start": "5291239",
    "end": "5297719"
  },
  {
    "text": "there and then re-upload that with the Chain of Thought as a pre-fill message and then you could get the log problems",
    "start": "5297719",
    "end": "5303920"
  },
  {
    "text": "but you for that you need a model that both has uh the the pre-fill capacity",
    "start": "5303920",
    "end": "5309679"
  },
  {
    "text": "and has log prob capacity I'm not sure of what model has both of those character walk me through why it",
    "start": "5309679",
    "end": "5315880"
  },
  {
    "text": "wouldn't just be sufficient to like in this case just ask for I'm asking for a score one to five only return that but",
    "start": "5315880",
    "end": "5322320"
  },
  {
    "text": "then like look at the log probs of what it returns in that case yeah so the the",
    "start": "5322320",
    "end": "5328040"
  },
  {
    "text": "the what you're losing there is whatever intelligence boost you got from having the model do the Chain of Thought and my",
    "start": "5328040",
    "end": "5334320"
  },
  {
    "text": "sense is that Chain of Thought Plus have the model say either 1 2 3 4 or five is going to be more accurate than like the",
    "start": "5334320",
    "end": "5340560"
  },
  {
    "text": "more the additional Nuance that you'd get by having it give you the log problems because it's actually doing a",
    "start": "5340560",
    "end": "5345679"
  },
  {
    "text": "lot of its thinking in that Chain of Thought you're like leveraging more computation you're getting more forward passes for all the same reason that",
    "start": "5345679",
    "end": "5352600"
  },
  {
    "text": "Chain of Thought is like usually a good idea it's idea are you talking about like Chain of Thought and like it's actually out loud writing a Chain of",
    "start": "5352600",
    "end": "5358760"
  },
  {
    "text": "Thought before the answer exactly okay okay I got you which is what we see in this prompt right here right like we",
    "start": "5358760",
    "end": "5366040"
  },
  {
    "text": "we cut out thisis number the model you okay cool",
    "start": "5366280",
    "end": "5372920"
  },
  {
    "text": "that's good to know thank you what's",
    "start": "5372920",
    "end": "5378360"
  },
  {
    "text": "that okay um I'm being told that I should answer a couple more questions and then get off stage I was",
    "start": "5379520",
    "end": "5386440"
  },
  {
    "text": "like before I came here I was honestly really worried that like no one would have questions and I'd be supplying my",
    "start": "5386440",
    "end": "5392760"
  },
  {
    "text": "own but you all have had amazing question so far and amazing examples so I really appreciate that it's made this",
    "start": "5392760",
    "end": "5398960"
  },
  {
    "text": "gone well sry I'm supposed to say that at the end of this but I'm giving a pre pre thank you we now we can do the Encore uh yeah I just want to add that",
    "start": "5398960",
    "end": "5405880"
  },
  {
    "text": "um having a numbered list may give more um weight to like number one 2 3 four",
    "start": "5405880",
    "end": "5411199"
  },
  {
    "text": "five versus just having an unstructured list um so it may give more weight into their score uh for the output if you",
    "start": "5411199",
    "end": "5418199"
  },
  {
    "text": "just change it from like one two 3 four five to like little dashes uh for criteria um just as my experience of",
    "start": "5418199",
    "end": "5425480"
  },
  {
    "text": "what I've been seeing okay cool yeah so just FYI I have replied back with the prompt U that was fixed or that like in",
    "start": "5425480",
    "end": "5433280"
  },
  {
    "text": "my own Improvement of what I think is a better prompt for this yeah okay awesome um Nisha should I do another",
    "start": "5433280",
    "end": "5440080"
  },
  {
    "text": "prompt or should I just answer a couple questions and then head up dop all right let's do one last",
    "start": "5440080",
    "end": "5448560"
  },
  {
    "text": "prompt what's which one should we choose",
    "start": "5448560",
    "end": "5453920"
  },
  {
    "text": "okay let's do this one good old mitigating hallucinations because we haven't really done",
    "start": "5458960",
    "end": "5464920"
  },
  {
    "text": "that",
    "start": "5464920",
    "end": "5467920"
  },
  {
    "text": "okay please provide a summary of the text provide as input okay first thing I'll do is just move these instructions",
    "start": "5473760",
    "end": "5482280"
  },
  {
    "text": "down now Matt did you have an example of the document a document where it hallucinates with this",
    "start": "5482280",
    "end": "5490118"
  },
  {
    "text": "prompt yeah can you just put that in the",
    "start": "5490520",
    "end": "5494520"
  },
  {
    "text": "thread okay your summary should be concise while maintaining all important information that would assist in helping someone understand the content if it",
    "start": "5501320",
    "end": "5508280"
  },
  {
    "text": "mentions any dates don't start or end with anything like I've sum gener summated for you",
    "start": "5508280",
    "end": "5515320"
  },
  {
    "text": "here's the summ you asked for yeah so this one we can uh fix with a",
    "start": "5515320",
    "end": "5520760"
  },
  {
    "text": "pre-fill okay uh all we could do something like this",
    "start": "5539400",
    "end": "5545440"
  },
  {
    "text": "um now how about the hallucination part the the best trick that I know for getting around hallucinations in a case",
    "start": "5551040",
    "end": "5557119"
  },
  {
    "text": "like this is to have the model extract relevant quotes first so what I would",
    "start": "5557119",
    "end": "5562719"
  },
  {
    "text": "say do here is I would say something like",
    "start": "5562719",
    "end": "5567920"
  },
  {
    "text": "and now of course in this prefill since we're having uh relevant quotes here we wouldn't want to start with summary that",
    "start": "5588280",
    "end": "5594159"
  },
  {
    "text": "would just be confusing SL wrong so we could say here is the",
    "start": "5594159",
    "end": "5601840"
  },
  {
    "text": "something like this okay did you get the the dock",
    "start": "5606400",
    "end": "5615119"
  },
  {
    "text": "yet okay and then of course I'd put the document",
    "start": "5615119",
    "end": "5622400"
  },
  {
    "text": "here",
    "start": "5625679",
    "end": "5628679"
  },
  {
    "text": "yep okay uh I think I should get off stage uh so yeah let me just call it",
    "start": "5631840",
    "end": "5639719"
  },
  {
    "text": "here and Matt we can we can talk after um yeah once again I really appreciate you all coming out it's been amazing to",
    "start": "5639719",
    "end": "5646320"
  },
  {
    "text": "have such like a great audience engaged uh I've had fun I I learned some things",
    "start": "5646320",
    "end": "5652119"
  },
  {
    "text": "uh I hope you all did too I'm planning to stick around uh this event uh for the",
    "start": "5652119",
    "end": "5657199"
  },
  {
    "text": "next for the rest of the afternoon so I don't know exactly where I'll be but",
    "start": "5657199",
    "end": "5662360"
  },
  {
    "text": "maybe just DM me if you want to come find me in chat I'm always happy to talk prompt engineering it's like my truest",
    "start": "5662360",
    "end": "5669400"
  },
  {
    "text": "passion at this point in the world so like find me hit me up we we'll talk um",
    "start": "5669400",
    "end": "5674480"
  },
  {
    "text": "and yeah this has been great thank you so much",
    "start": "5674480",
    "end": "5679560"
  },
  {
    "text": "[Music]",
    "start": "5680460",
    "end": "5697390"
  }
]
[
  {
    "text": "hello everybody today I'm going to talk about AI agents Beyond chat GPT this talk is tailored for a more research",
    "start": "7160",
    "end": "14480"
  },
  {
    "text": "oriented a audience my name is Joe I'm from Columbia University I'm also the",
    "start": "14480",
    "end": "20760"
  },
  {
    "text": "founder of AR Collex AI so many people are talking about agents what are these",
    "start": "20760",
    "end": "26679"
  },
  {
    "text": "Bill Gates is very bullish on it talking about the biggest re solution in Computing Andrew en is talking about",
    "start": "26679",
    "end": "32920"
  },
  {
    "text": "this is a massive AI progress so Sam Alman from opening up is talking about",
    "start": "32920",
    "end": "39160"
  },
  {
    "text": "uh 2025 is the year of agent we also hear a lot of negative voice about oh",
    "start": "39160",
    "end": "46039"
  },
  {
    "text": "these are just Sim wrapper of large language model uh they they really can plan then we can't really have agents",
    "start": "46039",
    "end": "54039"
  },
  {
    "text": "and we're also talking about oh autog GPT is not great and they can never solve practical Solutions but but before",
    "start": "54039",
    "end": "60399"
  },
  {
    "text": "we hear all these kind of questions can we talk about what exactly is AI agents",
    "start": "60399",
    "end": "66000"
  },
  {
    "text": "so let's go back to the base also in nor so agents is not new it's really coming",
    "start": "66000",
    "end": "71320"
  },
  {
    "text": "down to the large language model have powered agents to become more powerful",
    "start": "71320",
    "end": "77040"
  },
  {
    "text": "these days first we have the step we call perception so like humans agent a",
    "start": "77040",
    "end": "84040"
  },
  {
    "text": "agent needs to understand the world the environment through sensing informations",
    "start": "84040",
    "end": "90079"
  },
  {
    "text": "front text image audio video Touch and so on and then once we get the information through these sensors we got",
    "start": "90079",
    "end": "97360"
  },
  {
    "text": "to have this go through this reasoning process sometimes people are also kind of in their malog to understand how do",
    "start": "97360",
    "end": "104399"
  },
  {
    "text": "we process these information how do we complete tasks break down task into individual steps and utilize these",
    "start": "104399",
    "end": "111560"
  },
  {
    "text": "inputs of the environment to help us to better think what are different tools or",
    "start": "111560",
    "end": "116920"
  },
  {
    "text": "different actions to take so this inner plan process sometimes we also call them",
    "start": "116920",
    "end": "122240"
  },
  {
    "text": "chain of thoughts reasoning that because it most of the time are powered by large language model and then we also have",
    "start": "122240",
    "end": "130039"
  },
  {
    "text": "some meta reasoning steps that we can perform called a reflect basically whenever you execute a certain action",
    "start": "130039",
    "end": "137040"
  },
  {
    "text": "you can ask yourself so far did I make the right choice if not can I go back",
    "start": "137040",
    "end": "143160"
  },
  {
    "text": "finally we talk about what considers to be actions of AI agents anything that",
    "start": "143160",
    "end": "148319"
  },
  {
    "text": "you perform that may be talking to human maybe moving from point A to point B are",
    "start": "148319",
    "end": "154840"
  },
  {
    "text": "also talk talking about are all actions so in general we're really talking about",
    "start": "154840",
    "end": "161239"
  },
  {
    "text": "agents are interacting with the environment through actuations of actions so in general this is like the",
    "start": "161239",
    "end": "168280"
  },
  {
    "text": "total process of Agents though it is difficult to",
    "start": "168280",
    "end": "175840"
  },
  {
    "text": "understand how how easy it is for us to deploy agents we're just going to use a",
    "start": "175840",
    "end": "182840"
  },
  {
    "text": "nice analog of different levels of autonomy in self-driving cars so you can",
    "start": "182840",
    "end": "189400"
  },
  {
    "text": "think about the very first base was a was a chatbot started was 2017 that you",
    "start": "189400",
    "end": "195920"
  },
  {
    "text": "can just retrieve information and that's it and level two is more about we call agent assist you have a customer service",
    "start": "195920",
    "end": "203360"
  },
  {
    "text": "agent they're using large language model to generate suggested responses and",
    "start": "203360",
    "end": "208519"
  },
  {
    "text": "people still has to be the person to approve the Sending message level three is what we have been",
    "start": "208519",
    "end": "215840"
  },
  {
    "text": "talking more right now it's called Agent as a service so we use large language model to automate the AI workflows that",
    "start": "215840",
    "end": "223360"
  },
  {
    "text": "we have and then usually using it as a service for example meeting bookings um",
    "start": "223360",
    "end": "228879"
  },
  {
    "text": "writing a job descriptions and level four is really coming down to one person",
    "start": "228879",
    "end": "234640"
  },
  {
    "text": "is not only doing one task at a time it can delegate the AI to do multiple tasks",
    "start": "234640",
    "end": "239840"
  },
  {
    "text": "task and these task have inter intersections about sharing components",
    "start": "239840",
    "end": "245519"
  },
  {
    "text": "sharing knowledges and resources as well so this we call autonom agents that can",
    "start": "245519",
    "end": "251360"
  },
  {
    "text": "behave uh and perform T multiple tasks together and then level five is one",
    "start": "251360",
    "end": "256560"
  },
  {
    "text": "level above is what we really think about the jarva S Iron Man so we trust",
    "start": "256560",
    "end": "262360"
  },
  {
    "text": "the agents 100% we delegate the agents with all our security measures like our",
    "start": "262360",
    "end": "268280"
  },
  {
    "text": "keys and then agents would to perform on behalf of us so self-driving car is",
    "start": "268280",
    "end": "274360"
  },
  {
    "text": "having the similar five levels right and but self-driving card you can consider it as one example of agent because it's",
    "start": "274360",
    "end": "282680"
  },
  {
    "text": "a agent doing the perception doing the actions of reasoning about planning and",
    "start": "282680",
    "end": "288400"
  },
  {
    "text": "trajectory of executing in terms of driving but self-driving is very high",
    "start": "288400",
    "end": "294880"
  },
  {
    "text": "risk which means that you have to make sure that there's no errors happening otherwise we are talking about lives and",
    "start": "294880",
    "end": "302039"
  },
  {
    "text": "life and de um so but AI agents what we talk about is you always like can",
    "start": "302039",
    "end": "308240"
  },
  {
    "text": "separate them into lowrisk task to highrisk tasks so when you talk about lowrisk task maybe there are some back",
    "start": "308240",
    "end": "314960"
  },
  {
    "text": "office task like for example um filing reimbursements um which you can have",
    "start": "314960",
    "end": "320520"
  },
  {
    "text": "human supervision and over time trusted over time to be able to automative um",
    "start": "320520",
    "end": "326680"
  },
  {
    "text": "and then customer facing task are usually considered to be more high-risk task and over time we can see people",
    "start": "326680",
    "end": "333120"
  },
  {
    "text": "going from back office into front office over time to deploy these",
    "start": "333120",
    "end": "339199"
  },
  {
    "text": "agents today we're going to talk a little bit more about how do we improve",
    "start": "339199",
    "end": "344840"
  },
  {
    "text": "large language models to to make it to be able to reason better to reflect",
    "start": "344840",
    "end": "350560"
  },
  {
    "text": "better and then we're going to talk about how do we elicit better behaviors from these existing large language",
    "start": "350560",
    "end": "357039"
  },
  {
    "text": "models that optimize towards AI agent task finally how do we learn from the",
    "start": "357039",
    "end": "363720"
  },
  {
    "text": "examples or traces we search over time to feed this information back to the",
    "start": "363720",
    "end": "369319"
  },
  {
    "text": "large language model so that we can have a large language model that is optimized towards AI agent",
    "start": "369319",
    "end": "377039"
  },
  {
    "text": "tasks so let's start with the first work which is a narco best outstanding paper",
    "start": "377039",
    "end": "382800"
  },
  {
    "text": "on self-improvements so let's start with an example reasoning task which is a",
    "start": "382800",
    "end": "389000"
  },
  {
    "text": "mathematic reasoning task so here is an simple example there are usually two",
    "start": "389000",
    "end": "395199"
  },
  {
    "text": "ways that we can actually solve it through using L langage model one is on",
    "start": "395199",
    "end": "400360"
  },
  {
    "text": "the left side we call it f sh prompting we generate examples of the same",
    "start": "400360",
    "end": "405599"
  },
  {
    "text": "mathematical similar mathematical problems and its corresponding answers",
    "start": "405599",
    "end": "410840"
  },
  {
    "text": "and use them as a context or sometimes we call it prompts to a large language",
    "start": "410840",
    "end": "415879"
  },
  {
    "text": "model for example GPD 4 and then get the right answer and the other methods we",
    "start": "415879",
    "end": "421479"
  },
  {
    "text": "call chain of thoughts which is instead of giving it example we give it an instruction saying let's think step by",
    "start": "421479",
    "end": "427879"
  },
  {
    "text": "step um so the models actually are following this step bystep uh chain of",
    "start": "427879",
    "end": "433400"
  },
  {
    "text": "thought process sometimes we also call it reasoning over the tokens and be able to reach the correct",
    "start": "433400",
    "end": "440440"
  },
  {
    "text": "answer um more recently there is a prompting method that combined the two methods together um that actually",
    "start": "440440",
    "end": "447400"
  },
  {
    "text": "improved the outcome so instead of asking the model to just simply think",
    "start": "447400",
    "end": "453520"
  },
  {
    "text": "step by step we actually give some information about these in the prompting",
    "start": "453520",
    "end": "458759"
  },
  {
    "text": "in order to improve its performance so for example we give the same question we",
    "start": "458759",
    "end": "465759"
  },
  {
    "text": "ask the models to solve it step by step and then we take the question and the",
    "start": "465759",
    "end": "472080"
  },
  {
    "text": "initial answer and then prompt the large language model to generate feedback So",
    "start": "472080",
    "end": "477960"
  },
  {
    "text": "based on the question and answer what do you think about do you think the answer is correct or not and then we have these",
    "start": "477960",
    "end": "484879"
  },
  {
    "text": "kind of generated things like in step two the part blah blah blah is incorrect this is because blah blah so what we",
    "start": "484879",
    "end": "492440"
  },
  {
    "text": "call this process is a reflection or self improvement and then we combine the",
    "start": "492440",
    "end": "498280"
  },
  {
    "text": "reflection or feedback together with the original question answer and then prompt the models again and then finally the",
    "start": "498280",
    "end": "505680"
  },
  {
    "text": "model is able to update the answer and the internal processes to get the uh",
    "start": "505680",
    "end": "511120"
  },
  {
    "text": "final feedback correct so what we call this process selfrefined or",
    "start": "511120",
    "end": "518159"
  },
  {
    "text": "self-improvement so we do find that this kind of a prompt feedback could improve",
    "start": "518200",
    "end": "523880"
  },
  {
    "text": "and you can do it multiple times if you couldn't reach the correct answer and then you can stop it when you feel 100%",
    "start": "523880",
    "end": "530920"
  },
  {
    "text": "that you are reaching the correct answer but in reality we do find this",
    "start": "530920",
    "end": "536360"
  },
  {
    "text": "interesting self-improvement process could be having a problem with smaller",
    "start": "536360",
    "end": "541519"
  },
  {
    "text": "large language model so here previously we all talking about large language model that is beyond 7 billion or 13",
    "start": "541519",
    "end": "548720"
  },
  {
    "text": "billion but if you're using a smaller model that is cost efficient like a llama 7 billion we do find that the",
    "start": "548720",
    "end": "556279"
  },
  {
    "text": "feedback that it generates sometimes contains what we call a noise and these",
    "start": "556279",
    "end": "561800"
  },
  {
    "text": "noise can propagate down to the correction steps as well so this is what",
    "start": "561800",
    "end": "567959"
  },
  {
    "text": "we usually call the blind is leading the blind so we actually instead of",
    "start": "567959",
    "end": "573079"
  },
  {
    "text": "improving the results act getting even less results over time and then people",
    "start": "573079",
    "end": "578640"
  },
  {
    "text": "may say oh these feedbacks gener by these smaller models are not great can we change it into a bigger model so you",
    "start": "578640",
    "end": "585680"
  },
  {
    "text": "can think about these kind of feedbacks also nowadays people call them verifiers one of the interesting things",
    "start": "585680",
    "end": "592360"
  },
  {
    "text": "that we saw is because these large language models demonstration or internal Logics are not compatible with",
    "start": "592360",
    "end": "600000"
  },
  {
    "text": "the smaller models for example the steps are completely different if we feed this",
    "start": "600000",
    "end": "605680"
  },
  {
    "text": "kind of internal logic back to the smaller model there is incompatibility so the feedback is not",
    "start": "605680",
    "end": "612000"
  },
  {
    "text": "useful at all so you can really think about this in human learning as well if you find your kid is making a mistake on",
    "start": "612000",
    "end": "619959"
  },
  {
    "text": "using pronouns you can't just say that you you should use a second person pronoun instead of a first person",
    "start": "619959",
    "end": "626320"
  },
  {
    "text": "pronoun in this situation your kit would never understand you you you should simply just say at this point you should",
    "start": "626320",
    "end": "632680"
  },
  {
    "text": "I want it instead of say you want it um so we have to Dum it down in terms of",
    "start": "632680",
    "end": "638440"
  },
  {
    "text": "the feedback to cater for these smaller models internal logic so this is where",
    "start": "638440",
    "end": "644079"
  },
  {
    "text": "we come from in terms of how do we help the smaller models to also acquire the",
    "start": "644079",
    "end": "650560"
  },
  {
    "text": "self-improvement process uh by distilling information from large language models so first we're going to",
    "start": "650560",
    "end": "657399"
  },
  {
    "text": "reformulate the problem and terms of uh we wanted to retrain the model with",
    "start": "657399",
    "end": "663399"
  },
  {
    "text": "attempt of uh solving the problem as an input and then we're going to generate feedback and updates and then we wanted",
    "start": "663399",
    "end": "670760"
  },
  {
    "text": "to consider not using smaller models to generate the feedback step in soad we're",
    "start": "670760",
    "end": "678480"
  },
  {
    "text": "actually using large language model to edit the smaller models feedback so that",
    "start": "678480",
    "end": "684600"
  },
  {
    "text": "it's more tailored towards the smaller model um you can also use Pyon squ for",
    "start": "684600",
    "end": "689959"
  },
  {
    "text": "this particular Mass reasoning task because which gives you more correct feedback so now you can think about our",
    "start": "689959",
    "end": "697120"
  },
  {
    "text": "propos message wiass uh we have the same question we use the small model to",
    "start": "697120",
    "end": "702519"
  },
  {
    "text": "prompt it to get the answer and then we prompt the smaller model to generate the",
    "start": "702519",
    "end": "708560"
  },
  {
    "text": "cell and then we ask the large model to edit this feedback and then use this cor",
    "start": "708560",
    "end": "715160"
  },
  {
    "text": "corrected feedback as input to further generate the up dated answer and this",
    "start": "715160",
    "end": "721480"
  },
  {
    "text": "process of a correction and getting the feedback could be iterated multiple",
    "start": "721480",
    "end": "727079"
  },
  {
    "text": "times until the problem is solved correctly because uh it's mathematical",
    "start": "727079",
    "end": "733199"
  },
  {
    "text": "problems you we have the ground CHS and some of the benchmarks so we can",
    "start": "733199",
    "end": "738560"
  },
  {
    "text": "actually uze this um like it just for every problem we'll be able to generate traces like that until we reach the",
    "start": "738560",
    "end": "746680"
  },
  {
    "text": "correct answer and then we can filter the trajectories of these kind of trial and error for a Balan set and then use",
    "start": "746680",
    "end": "754839"
  },
  {
    "text": "it to train our existing smaller models to be able to do self-improvement with",
    "start": "754839",
    "end": "761040"
  },
  {
    "text": "the guidance of larger model or other toolings like a Python",
    "start": "761040",
    "end": "766600"
  },
  {
    "text": "scripts we find like if we using a weighted self weighted supervised the",
    "start": "766600",
    "end": "773040"
  },
  {
    "text": "training POS policy and specifically we're talking about we have to train on the policy data we have to generate",
    "start": "773040",
    "end": "780720"
  },
  {
    "text": "these feedback in real time because your models over time is going to change so",
    "start": "780720",
    "end": "786199"
  },
  {
    "text": "the model has to be updated in real time um we're going to evaluate this on a big",
    "start": "786199",
    "end": "792279"
  },
  {
    "text": "bench hard mathematical problems for rithmic word shorting data understanding",
    "start": "792279",
    "end": "798040"
  },
  {
    "text": "logical deductions and so on and then we through all these kind of different tasks we collected we do find like after",
    "start": "798040",
    "end": "805600"
  },
  {
    "text": "three iterations of using our tripod so when we say reiterations like you you",
    "start": "805600",
    "end": "811360"
  },
  {
    "text": "provide feedback you you edit the answer you provide feedback and you edit the answer you have these kind of loop by",
    "start": "811360",
    "end": "817320"
  },
  {
    "text": "three times you're able to reach 48% which is even better than using some",
    "start": "817320",
    "end": "822600"
  },
  {
    "text": "supervised train data to do it and then the question is really",
    "start": "822600",
    "end": "828839"
  },
  {
    "text": "coming down to we improve the performance which means that these kind of un policy self to provision is useful",
    "start": "828839",
    "end": "836040"
  },
  {
    "text": "but at the model fine tune with the data that we we talk about self-improvement",
    "start": "836040",
    "end": "841120"
  },
  {
    "text": "it really learns the self-improvement in itself so we do find in this all the",
    "start": "841120",
    "end": "846160"
  },
  {
    "text": "four tasks we looked at the first time correction which is the pink one and",
    "start": "846160",
    "end": "851600"
  },
  {
    "text": "then if the second time later ones it was correct after self-improvement the dark pink it actually um obviously",
    "start": "851600",
    "end": "859920"
  },
  {
    "text": "happening all these kind of different fun task and the range is pretty high in terms of 7 to",
    "start": "859920",
    "end": "867279"
  },
  {
    "text": "18% so this question is really coming down to um this is what definitely we are getting extra answers correctly but",
    "start": "867279",
    "end": "875320"
  },
  {
    "text": "where does these kind of Delta really come from is if can can it just obtain",
    "start": "875320",
    "end": "880560"
  },
  {
    "text": "from fine-tuning on gold answers um instead of giving them the internal logic and and policies so we do find",
    "start": "880560",
    "end": "888079"
  },
  {
    "text": "that if you give on policy data we do much better and then you just use Simple",
    "start": "888079",
    "end": "893440"
  },
  {
    "text": "sft data you just like the Improvement is cutting in half so the takeaway is very simple that",
    "start": "893440",
    "end": "901079"
  },
  {
    "text": "we can actually improve these U models reflection or self-learning abilities",
    "start": "901079",
    "end": "906560"
  },
  {
    "text": "without explicitly human and supervision data we could use the synthetic ways to",
    "start": "906560",
    "end": "913079"
  },
  {
    "text": "generate data policy to help the models to improve and of course we have the",
    "start": "913079",
    "end": "918399"
  },
  {
    "text": "limitation that is that what we call about the verifiers or the editors which",
    "start": "918399",
    "end": "923880"
  },
  {
    "text": "are large language model if these large language model cannot edit it correctly then we always have the ceiling effects",
    "start": "923880",
    "end": "930240"
  },
  {
    "text": "as smaller models wouldn't be able to distill these information from these larg langage model so we're still hoping",
    "start": "930240",
    "end": "936519"
  },
  {
    "text": "there will be a big Lage model is pushing the boundaries of all the reasoning task and then we can actually",
    "start": "936519",
    "end": "942600"
  },
  {
    "text": "use these kind of uh sinking in by step or sing in in scale test time scale in",
    "start": "942600",
    "end": "949000"
  },
  {
    "text": "order to be able to use smaller models to catch up to large",
    "start": "949000",
    "end": "954279"
  },
  {
    "text": "models now we talked about a met reasoning typ we call a reflection now",
    "start": "954279",
    "end": "960519"
  },
  {
    "text": "we go into can we actually elicit better uh results or planning results for large",
    "start": "960519",
    "end": "966120"
  },
  {
    "text": "language model itself we all know in large language Model area there are three factors that",
    "start": "966120",
    "end": "973920"
  },
  {
    "text": "would impact the Train the training uh the training results of a large language model in the TR pre-training process um",
    "start": "973920",
    "end": "981759"
  },
  {
    "text": "the number of compute uh the the day size and the parameter size and we",
    "start": "981759",
    "end": "987240"
  },
  {
    "text": "definitely see it's it's like linear cor related was how the performance look like so this is what we call like the",
    "start": "987240",
    "end": "994000"
  },
  {
    "text": "scaling law we still believe that currently we're not reaching towards the Singo scaling law but we are close um we",
    "start": "994000",
    "end": "1002600"
  },
  {
    "text": "we're relying on more GP use but unfortunately data Siz is just we have one internet as Ilia talked about in",
    "start": "1002600",
    "end": "1009199"
  },
  {
    "text": "Europe how do we generate more data how do we get better data is a million",
    "start": "1009199",
    "end": "1014519"
  },
  {
    "text": "dollar question and then parameters wise we're already reaching like billion parameters if we increaseing even more",
    "start": "1014519",
    "end": "1021959"
  },
  {
    "text": "without the support of aboundant Diversified data the models are harder to improve as well but pre-training is",
    "start": "1021959",
    "end": "1030199"
  },
  {
    "text": "difficult you could you can do it with if you're not Google if you're not open AI for smaller companies or Academia",
    "start": "1030199",
    "end": "1038959"
  },
  {
    "text": "what kind of things could we do so there's a couple of new work related to GPD 401 and is getting us a new",
    "start": "1038959",
    "end": "1047120"
  },
  {
    "text": "Direction which is called test time H scaling so instead of pre-training a large language model you take the model",
    "start": "1047120",
    "end": "1053640"
  },
  {
    "text": "as it is but give it more steps or budgets in terms of inference um so",
    "start": "1053640",
    "end": "1059600"
  },
  {
    "text": "specifically like what we talked about I said to sync by step by step I said to do reflection and so on you can actually",
    "start": "1059600",
    "end": "1066600"
  },
  {
    "text": "reach better results in the end of the task right so given the budget we see",
    "start": "1066600",
    "end": "1072799"
  },
  {
    "text": "it's like a linearly increased in terms of um task assess so can we actually",
    "start": "1072799",
    "end": "1078880"
  },
  {
    "text": "further further elicit better behaviors was existing P train model and today is",
    "start": "1078880",
    "end": "1085080"
  },
  {
    "text": "what we're going to talk about how do we eless a stronger Model Behavior through a chain of thoughts like processing that",
    "start": "1085080",
    "end": "1091159"
  },
  {
    "text": "is even more on the Tre search side that is more complex but it gives you better results and finally how do we further",
    "start": "1091159",
    "end": "1098880"
  },
  {
    "text": "improve the base large language model by using the data we generated from these",
    "start": "1098880",
    "end": "1104520"
  },
  {
    "text": "sthetic processes so let's start with a very concrete task um I have been working on",
    "start": "1104520",
    "end": "1112880"
  },
  {
    "text": "dialogues for many years and then this is one of the example um but many dialogue tasks you can think about it's",
    "start": "1112880",
    "end": "1118960"
  },
  {
    "text": "a sequential decision making you at certain point talking to another person",
    "start": "1118960",
    "end": "1124799"
  },
  {
    "text": "you need to make a decision given the conversational context what should I say next so this is a process that you also",
    "start": "1124799",
    "end": "1131760"
  },
  {
    "text": "have a look ahead right uh in terms of oh this is my plan how do I strategize",
    "start": "1131760",
    "end": "1137280"
  },
  {
    "text": "my conversational strategies to Pro to do some of the task for example we have",
    "start": "1137280",
    "end": "1142760"
  },
  {
    "text": "the donation persuasion task the boy on the left is trying to persuade the girl on the right to donate to a charity C",
    "start": "1142760",
    "end": "1149559"
  },
  {
    "text": "save the children so they start with the conversation saying how are you doing I'm good and then we talk about some of",
    "start": "1149559",
    "end": "1156440"
  },
  {
    "text": "the strategies people use for persuasion uh we call it inquiries great have you ever donated to Charities right and then",
    "start": "1156440",
    "end": "1163760"
  },
  {
    "text": "given the user's response I'm in the right place at the right time then I would do it um this boy needs to think",
    "start": "1163760",
    "end": "1170360"
  },
  {
    "text": "about and ahead of time what kind of strategies to apply at this point in order to convert this",
    "start": "1170360",
    "end": "1176960"
  },
  {
    "text": "persuade so let's take a step back and think about this uh sequential decision- making in a more toy problem for example",
    "start": "1176960",
    "end": "1184480"
  },
  {
    "text": "like chest it's really coming down to you you have to think about what's your",
    "start": "1184480",
    "end": "1189520"
  },
  {
    "text": "next move and you can think about what's your move in a more efficient way if you",
    "start": "1189520",
    "end": "1194840"
  },
  {
    "text": "can stimulate if you do this what your compon opponent is going to do you right",
    "start": "1194840",
    "end": "1200000"
  },
  {
    "text": "so you can have these kind of what we usually call planned out or like simulate and evaluate process and we do",
    "start": "1200000",
    "end": "1207440"
  },
  {
    "text": "find that in chess games Grand Masters usually have many steps ahead of time in",
    "start": "1207440",
    "end": "1212840"
  },
  {
    "text": "order to see what is your best practice at this particular moment um so this is",
    "start": "1212840",
    "end": "1218400"
  },
  {
    "text": "very similar to Ala go and all these kind of algorithms that we're talking about that uses what we call tree",
    "start": "1218400",
    "end": "1224919"
  },
  {
    "text": "search so the idea is very simple you propose a certain move and then you",
    "start": "1224919",
    "end": "1230360"
  },
  {
    "text": "simulate what are the what are the Val or like changes after you make this move",
    "start": "1230360",
    "end": "1236520"
  },
  {
    "text": "and then you Val in terms of what are the outcomes of this particular move and then you do this multiple times until",
    "start": "1236520",
    "end": "1243000"
  },
  {
    "text": "you can you obtain a stronger move by",
    "start": "1243000",
    "end": "1247960"
  },
  {
    "text": "simulation so in our em emlp 20203 work",
    "start": "1249039",
    "end": "1254200"
  },
  {
    "text": "we basically brought brought the similar ideas of Chess into a conversational",
    "start": "1254200",
    "end": "1259480"
  },
  {
    "text": "setting which has a very clear goal uh we don't really need any training data",
    "start": "1259480",
    "end": "1265000"
  },
  {
    "text": "we hopefully could and be able to train this model with simulation so we start with the so",
    "start": "1265000",
    "end": "1272799"
  },
  {
    "text": "multicol tree search we call zero training how do we Design This multicol",
    "start": "1272799",
    "end": "1278120"
  },
  {
    "text": "TR search model is we we going to prompt large language model such chat gtvt so",
    "start": "1278120",
    "end": "1284080"
  },
  {
    "text": "first we're going to have the search potential uh which is a promising action",
    "start": "1284080",
    "end": "1289159"
  },
  {
    "text": "you basically prom a large language Mount to act as the policy and then you simulate action outcomes so basically if",
    "start": "1289159",
    "end": "1296120"
  },
  {
    "text": "you say these persuasion strategy what would be the outcome we also do prmt at large language model uh evaluate then",
    "start": "1296120",
    "end": "1303440"
  },
  {
    "text": "finally we going to do evaluate action quality so once you perform this action what are the quality of the actions",
    "start": "1303440",
    "end": "1310840"
  },
  {
    "text": "after interacting with the environment we also prompt a large language model um finally we basically update each action",
    "start": "1310840",
    "end": "1317880"
  },
  {
    "text": "quality over time uh you will be able to have this process and then we when we",
    "start": "1317880",
    "end": "1323679"
  },
  {
    "text": "talk about selfplay right you also have to simulate what your opponent's Behavior so here we used another large",
    "start": "1323679",
    "end": "1330480"
  },
  {
    "text": "language model to simulate the user again we also use prompting large language model so basically given the",
    "start": "1330480",
    "end": "1336919"
  },
  {
    "text": "conversational history I want the models to generate the",
    "start": "1336919",
    "end": "1342120"
  },
  {
    "text": "simulation so we want to see what are the prompts here particularly we have",
    "start": "1342320",
    "end": "1348080"
  },
  {
    "text": "for example prompting of negative reactions that is one of the process and",
    "start": "1348080",
    "end": "1353200"
  },
  {
    "text": "then we want to see given the prompt what are the evaluation of the success for example is it 0 23 or 0.5 this is",
    "start": "1353200",
    "end": "1361960"
  },
  {
    "text": "all very important in terms of how to evalate the performance of a particular action traditionally for these kind of",
    "start": "1361960",
    "end": "1370039"
  },
  {
    "text": "MCTS with zero training you would have a close loop of MCTS basically is given",
    "start": "1370039",
    "end": "1376480"
  },
  {
    "text": "the history what are your actions but in reality especially in our conversational task we have to account for a lot of",
    "start": "1376480",
    "end": "1383279"
  },
  {
    "text": "variance within humans response people are going to try different things um so you can consider this process of",
    "start": "1383279",
    "end": "1390120"
  },
  {
    "text": "stochastic process instead of using Clos to MCTS we're using open Lube MCTS so",
    "start": "1390120",
    "end": "1396960"
  },
  {
    "text": "basically given the conversational history we're going to stochastically randomly sample one number the one",
    "start": "1396960",
    "end": "1404240"
  },
  {
    "text": "possible simulated test so basically you can simulate different conversational strateg IES to persuade your",
    "start": "1404240",
    "end": "1410960"
  },
  {
    "text": "opponent and then the idea of this particular task is that we have a very",
    "start": "1410960",
    "end": "1416760"
  },
  {
    "text": "um objective way of evaluating it which is whether the person donated to the",
    "start": "1416760",
    "end": "1422440"
  },
  {
    "text": "charity or not but in this if you can't actually run with real humans then it's",
    "start": "1422440",
    "end": "1428520"
  },
  {
    "text": "really hard to have a good policy because it's very subjective it's very hard to train so here we particularly is",
    "start": "1428520",
    "end": "1437200"
  },
  {
    "text": "wanted to have GD P0 which is our proposed method to be able to com compare to without training be able to",
    "start": "1437200",
    "end": "1445120"
  },
  {
    "text": "generate a more stronger competitive results so we performed evaluations",
    "start": "1445120",
    "end": "1450679"
  },
  {
    "text": "versus we asked another large language model for example chat GPT to look at",
    "start": "1450679",
    "end": "1455760"
  },
  {
    "text": "the conversations and look at the general outputs One is using our planning algorithm one is not using our",
    "start": "1455760",
    "end": "1462440"
  },
  {
    "text": "planning algorithm which one it's more likely to to be persuasive can lead to",
    "start": "1462440",
    "end": "1468000"
  },
  {
    "text": "better outcomes of the task and then uh on the other side we have to run the",
    "start": "1468000",
    "end": "1473320"
  },
  {
    "text": "human studies so basically we release the model that is actually basically performing at the task of a Persuader we",
    "start": "1473320",
    "end": "1481039"
  },
  {
    "text": "ask the mechanical turers online to interact with this chatbot uh to see",
    "start": "1481039",
    "end": "1486760"
  },
  {
    "text": "whether they wanted to donate or not so the models that we deploy with our",
    "start": "1486760",
    "end": "1491799"
  },
  {
    "text": "planning algorism actually definitely gets better donations and also we find",
    "start": "1491799",
    "end": "1497080"
  },
  {
    "text": "that people find it it's more convincing more natural more coherent as well because the process is optimized for the",
    "start": "1497080",
    "end": "1505039"
  },
  {
    "text": "goal we also find through the analysis we can learn that these uh models can",
    "start": "1505039",
    "end": "1511039"
  },
  {
    "text": "self-discover a lot of task information for example we do find that uh they",
    "start": "1511039",
    "end": "1517200"
  },
  {
    "text": "wouldn't do the task like would you like to donate in the very early on of the conversation because that usually",
    "start": "1517200",
    "end": "1523559"
  },
  {
    "text": "according to the literature is also not good you wanted to pave the way into the big ask and we also do find it learns",
    "start": "1523559",
    "end": "1530919"
  },
  {
    "text": "how to diversify its strategies as well it's not using one strategy only for in",
    "start": "1530919",
    "end": "1536600"
  },
  {
    "text": "the entire conversation it learns to use different persuasion strategies emotional appeal logical appeal to",
    "start": "1536600",
    "end": "1542960"
  },
  {
    "text": "diversify its uh potential of convincing various different",
    "start": "1542960",
    "end": "1548120"
  },
  {
    "text": "people so in general this work really talks about um for dialog task you can",
    "start": "1548120",
    "end": "1553279"
  },
  {
    "text": "use multicol Tre to simulate what are the possible behaviors and then use",
    "start": "1553279",
    "end": "1558440"
  },
  {
    "text": "these kind of policies to drive in real world these decision makings although this is not as clear as the chess board",
    "start": "1558440",
    "end": "1566799"
  },
  {
    "text": "that has very detailed and limited action space but if you use these kind of quantifiable search spaces within",
    "start": "1566799",
    "end": "1574279"
  },
  {
    "text": "dialogue task can still gain better performances than not playing so of course this is just a",
    "start": "1574279",
    "end": "1581360"
  },
  {
    "text": "conversation task can we extend it into even larger AI agent Spades that not",
    "start": "1581360",
    "end": "1586520"
  },
  {
    "text": "only perform actions of talking but it performs actions of other tool use and",
    "start": "1586520",
    "end": "1593159"
  },
  {
    "text": "manipulations can we actually transfer the policy that we learned into other",
    "start": "1593159",
    "end": "1598679"
  },
  {
    "text": "tasks so this comes to our recent work in I CLE uh with the name of exact so",
    "start": "1598679",
    "end": "1606440"
  },
  {
    "text": "for large language models to be able to De various AI agent task we got to teach",
    "start": "1606440",
    "end": "1612039"
  },
  {
    "text": "it how to perceive the world and then we're going to start with a visual visual large language model we call a",
    "start": "1612039",
    "end": "1619000"
  },
  {
    "text": "visual language large language model because this is at least we want to have to be able to process image as well as",
    "start": "1619000",
    "end": "1625399"
  },
  {
    "text": "text so the traditional visual large language model or we call like vs are",
    "start": "1625399",
    "end": "1631640"
  },
  {
    "text": "trained with a task such as a visual question answer like what is he doing he's performing State skateboard trick",
    "start": "1631640",
    "end": "1639559"
  },
  {
    "text": "but in reality for AI agent task we want the computer uh to do things which for",
    "start": "1639559",
    "end": "1645880"
  },
  {
    "text": "example the input is a image of your computer screenshots and then the",
    "start": "1645880",
    "end": "1651640"
  },
  {
    "text": "actions where is that can you help me clear my shopping carts and then you have to perform actions like click",
    "start": "1651640",
    "end": "1657080"
  },
  {
    "text": "button to the shopping card click delete and so on so the entire training process",
    "start": "1657080",
    "end": "1663519"
  },
  {
    "text": "or entire usage of the current AI agent that we need for a large language model",
    "start": "1663519",
    "end": "1669519"
  },
  {
    "text": "that is a multimodal is very different from the previous vqa task so we really wanted to see if there is a way that we",
    "start": "1669519",
    "end": "1675640"
  },
  {
    "text": "can adapt the traditional vqa uh visual language model into a more action-based visual language model right if you look",
    "start": "1675640",
    "end": "1682640"
  },
  {
    "text": "at humans can do these kind of Benchmark Visual Web Arena like clean my shopping",
    "start": "1682640",
    "end": "1688519"
  },
  {
    "text": "carts find me a green pair of shoes and things like that uh",
    "start": "1688519",
    "end": "1693720"
  },
  {
    "text": "88% well if you just use a simple gbd4 V without anything in terms of plannings",
    "start": "1693720",
    "end": "1700360"
  },
  {
    "text": "or whatever smart things you get 16% so the absence of these kind of agent environment interacting with data and",
    "start": "1700360",
    "end": "1706919"
  },
  {
    "text": "training uh is is very lacking in this in these agentic task so here we want to",
    "start": "1706919",
    "end": "1712679"
  },
  {
    "text": "see if we don't have the budget to retrain GPD for all or do anything with",
    "start": "1712679",
    "end": "1718080"
  },
  {
    "text": "it there a better way that we can actually elicit better performance through test time",
    "start": "1718080",
    "end": "1724919"
  },
  {
    "text": "compute so we introduced a new algorithm called R MCTS which is short for RL",
    "start": "1724919",
    "end": "1732120"
  },
  {
    "text": "multicol Tre search um very like multicol Tre search it a search algorithm that can expl exp or the vast",
    "start": "1732120",
    "end": "1739080"
  },
  {
    "text": "action space on the flight and also improves decision making by incrementally constructing a search",
    "start": "1739080",
    "end": "1745279"
  },
  {
    "text": "treat unlike simple multicol tree search we extended to incorporate a contrastic",
    "start": "1745279",
    "end": "1751440"
  },
  {
    "text": "reflection so we basically allows agents to learn from past interactions and",
    "start": "1751440",
    "end": "1756880"
  },
  {
    "text": "dynamically improve their search efficiency um and also we using multi-agent debate to get reliable State",
    "start": "1756880",
    "end": "1763799"
  },
  {
    "text": "evaluation instead of using single uh prompting uh so here we have two",
    "start": "1763799",
    "end": "1770440"
  },
  {
    "text": "modifications that we did so the idea is that on top of Performing multicol research and improve",
    "start": "1770440",
    "end": "1777360"
  },
  {
    "text": "its decisions using a task we can equip the entire system with a memory module",
    "start": "1777360",
    "end": "1782559"
  },
  {
    "text": "such that it can improve its B Behavior across different tasks uh practically the idea is that after completing a Tas",
    "start": "1782559",
    "end": "1789799"
  },
  {
    "text": "we use reflective use contrastive reflection to help the model internalize",
    "start": "1789799",
    "end": "1795720"
  },
  {
    "text": "the success or the error it has made and save this experience to a vector database so we basically cach the",
    "start": "1795720",
    "end": "1803120"
  },
  {
    "text": "knowledge that we just learned then during any future task the agent will also retrieve reflection similar to the",
    "start": "1803120",
    "end": "1809240"
  },
  {
    "text": "current task um or the current uh computer state to enhance its dision",
    "start": "1809240",
    "end": "1815320"
  },
  {
    "text": "we're based on making this as a new",
    "start": "1815320",
    "end": "1818960"
  },
  {
    "text": "en finally the r MCTS we also introduced the message to improve the success Val",
    "start": "1820600",
    "end": "1827399"
  },
  {
    "text": "or the value estimate used during the uh specifically instead of directly prompting the language model to evaluate",
    "start": "1827399",
    "end": "1833919"
  },
  {
    "text": "the progress we find this evaluation process can be much more robust if we use in a form of a debate so basically",
    "start": "1833919",
    "end": "1841720"
  },
  {
    "text": "we're asking the models what it uh if it's a good action why it is a good action if it's a bad action why it is a",
    "start": "1841720",
    "end": "1849159"
  },
  {
    "text": "bad action so that you can have these kind of more holistic overview to counterbalance biases Front One models",
    "start": "1849159",
    "end": "1856360"
  },
  {
    "text": "topr um so basically basically through these two modifications of caching information and using more robust",
    "start": "1856360",
    "end": "1862480"
  },
  {
    "text": "verifier we're able to create this multicol tree search with a",
    "start": "1862480",
    "end": "1867679"
  },
  {
    "text": "reflection uh during each task the RM CS builds a search tree on the F by",
    "start": "1867679",
    "end": "1873480"
  },
  {
    "text": "interaction with the en by interacting with the environment and then R MCTS used multi-agent debate to provide a",
    "start": "1873480",
    "end": "1880320"
  },
  {
    "text": "more reliable State estimate and better guide the search process then after each",
    "start": "1880320",
    "end": "1886200"
  },
  {
    "text": "T task where RMC CTS is now originally performs this contrastive s reflection",
    "start": "1886200",
    "end": "1891960"
  },
  {
    "text": "at the end of the task in order to improve its future execution so it basically cat the information that we",
    "start": "1891960",
    "end": "1898960"
  },
  {
    "text": "learn through reflection and to eval to evaluate our method we use two Benchmark Visual Web",
    "start": "1898960",
    "end": "1906639"
  },
  {
    "text": "Arena and Os World which are the most popular world most popular AI agent",
    "start": "1906639",
    "end": "1912039"
  },
  {
    "text": "Benchmark so the Visual Web arena is a benchmark that evaluates AI agents performance on Broad in tasks so you",
    "start": "1912039",
    "end": "1919200"
  },
  {
    "text": "have a browser that you actually do various things like doing Reddit or doing shoppings and so on while the OS",
    "start": "1919200",
    "end": "1926120"
  },
  {
    "text": "world is a benchmark that consists computer desk such as navigating the file system using apps such as V code",
    "start": "1926120",
    "end": "1932880"
  },
  {
    "text": "Excel and so on in a Linux computer environment so we first wanted to look",
    "start": "1932880",
    "end": "1938960"
  },
  {
    "text": "at the Visual Web Arena we find that our search our algorithm outperforms other",
    "start": "1938960",
    "end": "1944240"
  },
  {
    "text": "existing search algorithms such as Brad first search depths for search a and then vanilla",
    "start": "1944240",
    "end": "1951600"
  },
  {
    "text": "MCTS we also compared our our method to non- search methods like a simple react",
    "start": "1951600",
    "end": "1958159"
  },
  {
    "text": "or as well as like um other search methods that from various different ways",
    "start": "1958159",
    "end": "1963519"
  },
  {
    "text": "we find that augmenting Elms or the visual large langage models with search arism can basically improve the",
    "start": "1963519",
    "end": "1970320"
  },
  {
    "text": "performance without additional human supervision um so through these kind of cashings through better verifications of",
    "start": "1970320",
    "end": "1978080"
  },
  {
    "text": "the states were able to get better performance we then basically also compared the another task which is all",
    "start": "1978080",
    "end": "1985919"
  },
  {
    "text": "OS world we can we are actually number one in the visual Weber V visual Weber",
    "start": "1985919",
    "end": "1992440"
  },
  {
    "text": "Arena leaderboard we also the best non-trained methods in the OS World",
    "start": "1992440",
    "end": "1998440"
  },
  {
    "text": "which means that we only do test time instead of fine tuning original",
    "start": "1998440",
    "end": "2004960"
  },
  {
    "text": "models so given what we see like Aon can actually improve agents without human",
    "start": "2004960",
    "end": "2010679"
  },
  {
    "text": "supervision can we actually consider transfer these additional knowledge we we that we obtain through the search",
    "start": "2010679",
    "end": "2017639"
  },
  {
    "text": "into the training process of the base larg Eng model and we basically also",
    "start": "2017639",
    "end": "2023080"
  },
  {
    "text": "invented the algorithm exploratory learning so compared to imitation",
    "start": "2023080",
    "end": "2028279"
  },
  {
    "text": "learning which is a direct transfer train the model using the best action found in the tree uh we propose to use",
    "start": "2028279",
    "end": "2035360"
  },
  {
    "text": "exper artillery learning which tree which treats the tree search process as single trajectory so the Tre basically",
    "start": "2035360",
    "end": "2043039"
  },
  {
    "text": "the models will learn how do you actually linearize the search tree traversal to motivate the model to learn",
    "start": "2043039",
    "end": "2049878"
  },
  {
    "text": "how to explore backtrack and evaluate so through this process of learning",
    "start": "2049879",
    "end": "2056040"
  },
  {
    "text": "teaching the model to do the exploration instead of giving it uh the final good answer we we actually make the models to",
    "start": "2056040",
    "end": "2063800"
  },
  {
    "text": "be able to improve its decision processes by itself so so we look at the",
    "start": "2063800",
    "end": "2069760"
  },
  {
    "text": "on on the rate if we let the model to do exploratory learning instead of imitation learning which is the darker",
    "start": "2069760",
    "end": "2077240"
  },
  {
    "text": "color through test time compute basically if you give in a a constrain budget can improve the",
    "start": "2077240",
    "end": "2085079"
  },
  {
    "text": "performance over time um here we basically provide an",
    "start": "2085079",
    "end": "2091760"
  },
  {
    "text": "example trajectory after explorator learning for example like this given the Tas such as find the",
    "start": "2091760",
    "end": "2098640"
  },
  {
    "text": "recent coffee maker was a touchscreen then comment was grade item so this",
    "start": "2098640",
    "end": "2104160"
  },
  {
    "text": "process the agent basically learns how to perform an action release it uh did not lead to desires date then go back",
    "start": "2104160",
    "end": "2111800"
  },
  {
    "text": "and try other actions so this evaluate and backtracking process happened",
    "start": "2111800",
    "end": "2117480"
  },
  {
    "text": "through the process so the mod actually learned this process which we find is very surprising and",
    "start": "2117480",
    "end": "2123640"
  },
  {
    "text": "great so in summary uh or the reflective MCTS models that we introdu just simply",
    "start": "2123640",
    "end": "2130760"
  },
  {
    "text": "relies on test time compute scaling is able to help the models to get better",
    "start": "2130760",
    "end": "2136720"
  },
  {
    "text": "performance and through explorator learning by training on the examples",
    "start": "2136720",
    "end": "2141800"
  },
  {
    "text": "that wech we're able to actually further improve the large language model so there are many more things we can try",
    "start": "2141800",
    "end": "2147920"
  },
  {
    "text": "that don't rely on human supervised information which we can provide in an",
    "start": "2147920",
    "end": "2153079"
  },
  {
    "text": "academic or smaller company setting so for example how do we get better r methods to reduce Reliance on the search",
    "start": "2153079",
    "end": "2159880"
  },
  {
    "text": "tree how to do model predictive control methods to reduce this exp really",
    "start": "2159880",
    "end": "2165280"
  },
  {
    "text": "expensive environment set up and interaction so some of the i al so so",
    "start": "2165280",
    "end": "2171640"
  },
  {
    "text": "far we basically talked about how do we elicit better large language model stability through test time compute",
    "start": "2171640",
    "end": "2178440"
  },
  {
    "text": "through retraining from refined refined or back Tred exploratory traces so some",
    "start": "2178440",
    "end": "2184960"
  },
  {
    "text": "of the recent things and ongoing work that we have done is more focused on how do we improve control abilities and also",
    "start": "2184960",
    "end": "2192599"
  },
  {
    "text": "at the same time the autonomous exploration together for the agent",
    "start": "2192599",
    "end": "2197640"
  },
  {
    "text": "orchestration layer so we just released our arlex open- source um agent",
    "start": "2197640",
    "end": "2203560"
  },
  {
    "text": "framework that has more features and more compared to many other existing Frameworks such as L train we have",
    "start": "2203560",
    "end": "2210920"
  },
  {
    "text": "various interesting components that we have for example continuous learning task decomposition which could you",
    "start": "2210920",
    "end": "2218800"
  },
  {
    "text": "developers more uh more flexibility in selecting different things one other",
    "start": "2218800",
    "end": "2224240"
  },
  {
    "text": "things that we have been doing we think is combining not only the machine learning machine learning expertise but",
    "start": "2224240",
    "end": "2231200"
  },
  {
    "text": "combining the system expertise the HCI expertise and also security expertise",
    "start": "2231200",
    "end": "2236839"
  },
  {
    "text": "together uh to form a group to learn how do we advance the system in a more",
    "start": "2236839",
    "end": "2242760"
  },
  {
    "text": "deeper and practical way so currently all the benchmarks I talked about is one single agent uh performing one single",
    "start": "2242760",
    "end": "2250359"
  },
  {
    "text": "task that human assigns to you right what if like you're um this is a super",
    "start": "2250359",
    "end": "2255599"
  },
  {
    "text": "inefficient to run this like in a separate instance what if I have one",
    "start": "2255599",
    "end": "2260720"
  },
  {
    "text": "humanman wants to the model to perform multiple tasks together on the same computer then we will encounter all",
    "start": "2260720",
    "end": "2268119"
  },
  {
    "text": "these kind of system level problems about scheduling how do we interact with database to avoid side effects how do we",
    "start": "2268119",
    "end": "2275079"
  },
  {
    "text": "have better Securities in terms of when to do human Handover when to act",
    "start": "2275079",
    "end": "2280400"
  },
  {
    "text": "actually request human supervision and then what's even more is if we have think about the entire process is a",
    "start": "2280400",
    "end": "2287079"
  },
  {
    "text": "community you will have multiple humans interacting with multiple different",
    "start": "2287079",
    "end": "2292880"
  },
  {
    "text": "agents and assign different works the multi-users multi-agents planning is",
    "start": "2292880",
    "end": "2298599"
  },
  {
    "text": "even more complicated can even lead to a lot of these kind of diversal settings that we want to quantify so nowadays",
    "start": "2298599",
    "end": "2305880"
  },
  {
    "text": "we're working together to establish more uh realistic benchmarks that have system",
    "start": "2305880",
    "end": "2311040"
  },
  {
    "text": "Integrations and also algorithm that I will build on top to not only consider",
    "start": "2311040",
    "end": "2316400"
  },
  {
    "text": "task completion but also consider efficiencies consider Securities and so on which you would provide for the basis",
    "start": "2316400",
    "end": "2323680"
  },
  {
    "text": "for all these kind of applications in the future okay thank you so much for listening um if you're interested to",
    "start": "2323680",
    "end": "2331240"
  },
  {
    "text": "know more about our uh framework that integrates all the research that we just talked about please join us at the ARX",
    "start": "2331240",
    "end": "2338720"
  },
  {
    "text": "AI",
    "start": "2338720",
    "end": "2341720"
  }
]
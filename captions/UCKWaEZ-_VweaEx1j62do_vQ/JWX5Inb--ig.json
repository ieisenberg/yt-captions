[
  {
    "start": "0",
    "end": "43000"
  },
  {
    "text": "If you need to store large amounts of data",
    "start": "266",
    "end": "2901"
  },
  {
    "text": "needing large amounts of data processing,",
    "start": "2901",
    "end": "5858"
  },
  {
    "text": "and you have requirements for large analytics capabilities,",
    "start": "5858",
    "end": "9573"
  },
  {
    "text": "you might be thinking you'll need some large compute.",
    "start": "9574",
    "end": "12478"
  },
  {
    "text": "But that's not necessarily the case with Apache Hadoop.",
    "start": "12478",
    "end": "16510"
  },
  {
    "text": "It's an open source framework that distributes processing of large data sets",
    "start": "16716",
    "end": "21000"
  },
  {
    "text": "using a simple programing models.",
    "start": "21000",
    "end": "23355"
  },
  {
    "text": "Hadoop is a cost-effective solution for storing and processing",
    "start": "23355",
    "end": "26428"
  },
  {
    "text": "massive amounts of structured, semi-structured, and unstructured data",
    "start": "26428",
    "end": "31698"
  },
  {
    "text": "with no format requirements.",
    "start": "31998",
    "end": "33633"
  },
  {
    "text": "And it has a pretty cool origin story.",
    "start": "33633",
    "end": "36836"
  },
  {
    "text": "Hadoop gets his name from a stuffed toy elephant",
    "start": "36970",
    "end": "39641"
  },
  {
    "text": "that belonged to Hadoop co-founder Doug Cutting's son.",
    "start": "39641",
    "end": "43710"
  },
  {
    "start": "43000",
    "end": "83000"
  },
  {
    "text": "Now, before we get into the details of how it works,",
    "start": "43777",
    "end": "46780"
  },
  {
    "text": "let's first discuss why you might need to use it at all,",
    "start": "47013",
    "end": "51751"
  },
  {
    "text": "by looking at some use cases.",
    "start": "52261",
    "end": "55798"
  },
  {
    "text": "Now, the first benefit that comes to my mind",
    "start": "56222",
    "end": "59225"
  },
  {
    "text": "is the ability to make better data driven decisions, the three Ds.",
    "start": "59225",
    "end": "65901"
  },
  {
    "text": "Hadoop enables the integration of real time data",
    "start": "66000",
    "end": "68810"
  },
  {
    "text": "that traditional data warehouses or relational databases",
    "start": "68810",
    "end": "71382"
  },
  {
    "text": "might not handle efficiently.",
    "start": "71383",
    "end": "73293"
  },
  {
    "text": "Now that includes things like streaming audio, video,",
    "start": "73293",
    "end": "76642"
  },
  {
    "text": "social media sentiment, clickstream data,",
    "start": "76642",
    "end": "79282"
  },
  {
    "text": "and other semi-structured and unstructured data.",
    "start": "79282",
    "end": "82449"
  },
  {
    "start": "83000",
    "end": "113000"
  },
  {
    "text": "Now, another significant benefit of Hadoop",
    "start": "83483",
    "end": "85685"
  },
  {
    "text": "is the improved data access and analysis.",
    "start": "85685",
    "end": "90323"
  },
  {
    "text": "Now, Hadoop provides real time self-service",
    "start": "90356",
    "end": "93426"
  },
  {
    "text": "access to data for data scientists,",
    "start": "93426",
    "end": "95470"
  },
  {
    "text": "line of business owners and developers,",
    "start": "95470",
    "end": "97197"
  },
  {
    "text": "which has utility for data science initiatives",
    "start": "97497",
    "end": "100319"
  },
  {
    "text": "that leverage data, algorithms, machine learning, and AI for advanced analysis.",
    "start": "100319",
    "end": "105926"
  },
  {
    "text": "It also allows the discovery of patterns",
    "start": "106473",
    "end": "109709"
  },
  {
    "text": "and the building of predictive models,",
    "start": "109709",
    "end": "111743"
  },
  {
    "text": "so it's very useful there as well.",
    "start": "111743",
    "end": "113245"
  },
  {
    "start": "113000",
    "end": "147000"
  },
  {
    "text": "Now, Hadoop also excels in data offload and consolidation,",
    "start": "113713",
    "end": "119272"
  },
  {
    "text": "so it can streamline costs in your enterprise data centers",
    "start": "119273",
    "end": "122477"
  },
  {
    "text": "by moving what's called cold data,",
    "start": "122477",
    "end": "124187"
  },
  {
    "text": "that's data that's not currently in use,",
    "start": "124187",
    "end": "126284"
  },
  {
    "text": "to a Hadoop-based distribution for storage.",
    "start": "126284",
    "end": "129332"
  },
  {
    "text": "Additionally, Hadoop allows for the consolidation of data",
    "start": "129562",
    "end": "132082"
  },
  {
    "text": "across an organization,",
    "start": "132082",
    "end": "133966"
  },
  {
    "text": "ensuring the data is readily available",
    "start": "133966",
    "end": "135918"
  },
  {
    "text": "for analysis when it's needed.",
    "start": "135918",
    "end": "137637"
  },
  {
    "text": "So with that in mind,",
    "start": "137904",
    "end": "139703"
  },
  {
    "text": "let's take a closer look at the Hadoop ecosystem",
    "start": "139703",
    "end": "142809"
  },
  {
    "text": "and really get into what's involved with this thing now.",
    "start": "143042",
    "end": "146679"
  },
  {
    "start": "147000",
    "end": "168000"
  },
  {
    "text": "Now, Hadoop is designed to run on clusters of commodity computers,",
    "start": "147847",
    "end": "151584"
  },
  {
    "text": "which makes it a cost-effective solution for large scale data processing.",
    "start": "151584",
    "end": "155321"
  },
  {
    "text": "And additionally, it can be installed on cloud servers.",
    "start": "155321",
    "end": "157690"
  },
  {
    "text": "So think about cloud providers like",
    "start": "157690",
    "end": "159591"
  },
  {
    "text": "Amazon Web Services or Microsoft Azure,",
    "start": "159591",
    "end": "161934"
  },
  {
    "text": "they offer Hadoop solutions, and Cloudera supports Hadoop",
    "start": "161934",
    "end": "165085"
  },
  {
    "text": "workloads both on-premises and in the cloud.",
    "start": "165085",
    "end": "168118"
  },
  {
    "start": "168000",
    "end": "419000"
  },
  {
    "text": "Now, the Hadoop framework, built by the Apache Software Foundation,",
    "start": "168368",
    "end": "171471"
  },
  {
    "text": "includes a number of components.",
    "start": "171671",
    "end": "173673"
  },
  {
    "text": "Let's break down some of them.",
    "start": "173673",
    "end": "175542"
  },
  {
    "text": "So the first one is called Hadoop Common,",
    "start": "175653",
    "end": "180124"
  },
  {
    "text": "And Hadoop Common, well that's basically the the common utilities",
    "start": "181114",
    "end": "185887"
  },
  {
    "text": "and the libraries that support other Hadoop modules.",
    "start": "185887",
    "end": "188888"
  },
  {
    "text": "Then there is the Hadoop HDFS,",
    "start": "189255",
    "end": "193822"
  },
  {
    "text": "that stands for Hadoop Distributed File System.",
    "start": "194294",
    "end": "198097"
  },
  {
    "text": "That's a file system for storing application data on commodity hardware.",
    "start": "198398",
    "end": "202034"
  },
  {
    "text": "So essentially providing distributed storage which is so important to the solution.",
    "start": "202035",
    "end": "206272"
  },
  {
    "text": "Now HDFS was designed to provide fault tolerance for Hadoop.",
    "start": "206739",
    "end": "210343"
  },
  {
    "text": "And it provides high aggregate data bandwidth",
    "start": "210610",
    "end": "213117"
  },
  {
    "text": "and high throughput access to data.",
    "start": "213117",
    "end": "215514"
  },
  {
    "text": "By default, data blocks are replicated across multiple nodes",
    "start": "215514",
    "end": "218818"
  },
  {
    "text": "at load or right time, and it also supports high availability",
    "start": "219018",
    "end": "222388"
  },
  {
    "text": "that allows a secondary node to take over",
    "start": "222755",
    "end": "225015"
  },
  {
    "text": "when an active node goes down.",
    "start": "225015",
    "end": "227060"
  },
  {
    "text": "All right, a couple more components.",
    "start": "227794",
    "end": "229529"
  },
  {
    "text": "There's Hadoop YARN .",
    "start": "229529",
    "end": "232232"
  },
  {
    "text": "So so an acronym.",
    "start": "232232",
    "end": "233526"
  },
  {
    "text": "YARN stands for \"yet another resource negotiator\".",
    "start": "233526",
    "end": "236069"
  },
  {
    "text": "It's a framework for job scheduling and cluster resource management.",
    "start": "236269",
    "end": "239305"
  },
  {
    "text": "It supports workloads such as interactive SQL,",
    "start": "239572",
    "end": "242309"
  },
  {
    "text": "advanced modeling and real time streaming.",
    "start": "242309",
    "end": "245113"
  },
  {
    "text": "Then we have Hadoop MapReduce.",
    "start": "245411",
    "end": "249715"
  },
  {
    "text": "And this component, MapReduce, is a YARN-based system actually,",
    "start": "250583",
    "end": "255754"
  },
  {
    "text": "and that stores data on multiple sources for parallel processing of large amounts of data.",
    "start": "255755",
    "end": "262028"
  },
  {
    "text": "And then finally there is Hadoop Ozone.",
    "start": "262428",
    "end": "266466"
  },
  {
    "text": "That's a scalable, redundant and distributed object store.",
    "start": "267600",
    "end": "270370"
  },
  {
    "text": "And that's really designed for big data applications.",
    "start": "270370",
    "end": "273238"
  },
  {
    "text": "Now beyond these core components,",
    "start": "273239",
    "end": "275446"
  },
  {
    "text": "the Hadoop ecosystem includes several supporting",
    "start": "275446",
    "end": "278077"
  },
  {
    "text": "Apache open source projects that enhance its functionality.",
    "start": "278077",
    "end": "282048"
  },
  {
    "text": "Now there's really a whole bunch that we could talk about.",
    "start": "282482",
    "end": "286352"
  },
  {
    "text": "I'll just talk about a few and we'll start",
    "start": "286686",
    "end": "289689"
  },
  {
    "text": "with Apache Ambari.",
    "start": "290490",
    "end": "293059"
  },
  {
    "text": "Now, Apache Ambari is a web-based tool for setting up,",
    "start": "293059",
    "end": "296919"
  },
  {
    "text": "managing and monitoring Hadoop clusters, which is handy for cluster management.",
    "start": "296920",
    "end": "302402"
  },
  {
    "text": "Another project we should really talk about is Hive, Apache Hive,",
    "start": "302402",
    "end": "307644"
  },
  {
    "text": "and that provides an SQL-like interface for querying and analyzing large data sets.",
    "start": "307644",
    "end": "312211"
  },
  {
    "text": "Another one is Apache HBase.",
    "start": "312822",
    "end": "316725"
  },
  {
    "text": "And that is a scalable, non-relational database",
    "start": "317450",
    "end": "320720"
  },
  {
    "text": "that supports structured data storage for very large tables.",
    "start": "320720",
    "end": "323823"
  },
  {
    "text": "And then just one more that we'll talk about for now that's Pig,",
    "start": "324123",
    "end": "327634"
  },
  {
    "text": "Apache Pig,",
    "start": "327635",
    "end": "328644"
  },
  {
    "text": "that allows for writing high level scripts for data analysis",
    "start": "328644",
    "end": "331798"
  },
  {
    "text": "enabling parallel processing.",
    "start": "331798",
    "end": "333466"
  },
  {
    "text": "Now a couple of other things to mention about Hadoop.",
    "start": "334000",
    "end": "336769"
  },
  {
    "text": "It was written in Java, but depending on the big data project,",
    "start": "336769",
    "end": "339872"
  },
  {
    "text": "developers can program in their choice of language.",
    "start": "340006",
    "end": "342259"
  },
  {
    "text": "So Python or R for example.",
    "start": "342259",
    "end": "344417"
  },
  {
    "text": "And additionally, we could do a whole video comparing Hadoop with another project",
    "start": "344782",
    "end": "349907"
  },
  {
    "text": "called Spark.",
    "start": "350177",
    "end": "352021"
  },
  {
    "text": "They are very much related.",
    "start": "353353",
    "end": "355421"
  },
  {
    "text": "Apache Spark is an open source framework for big data processing as well.",
    "start": "355421",
    "end": "359692"
  },
  {
    "text": "But to summarize, we could say that Hadoop is best for",
    "start": "359859",
    "end": "362969"
  },
  {
    "text": "batch processing of huge volumes of data,",
    "start": "362969",
    "end": "365634"
  },
  {
    "text": "while Spark, that supports both batch and real time data processing",
    "start": "365635",
    "end": "370069"
  },
  {
    "text": "and that's ideal for streaming data and graph computations.",
    "start": "370336",
    "end": "373657"
  },
  {
    "text": "Both Hadoop and Spark have machine learning libraries,",
    "start": "373873",
    "end": "376796"
  },
  {
    "text": "but due to something called in-memory processing,",
    "start": "376796",
    "end": "380348"
  },
  {
    "text": "Spark's machine learning is much faster.",
    "start": "380348",
    "end": "382866"
  },
  {
    "text": "So to sum this all up,",
    "start": "383249",
    "end": "385806"
  },
  {
    "text": "Apache Hadoop excels in environments where large data sets and large scale processing are the norm.",
    "start": "385806",
    "end": "392191"
  },
  {
    "text": "It's comprehensive framework and supporting projects make it a good fit",
    "start": "392458",
    "end": "395728"
  },
  {
    "text": "for managing and analyzing large amounts",
    "start": "395728",
    "end": "399031"
  },
  {
    "text": "of data effectively",
    "start": "399031",
    "end": "401075"
  },
  {
    "text": "- which is not bad for something that began life",
    "start": "401075",
    "end": "404160"
  },
  {
    "text": "as a stuffed yellow elephant.",
    "start": "404160",
    "end": "407529"
  }
]
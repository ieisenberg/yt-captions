[
  {
    "start": "0",
    "end": "98000"
  },
  {
    "text": "Malcom Gladwell: Hello, hello. Welcome to Smart \nTalks with IBM, a podcast from Pushkin Industries,  ",
    "start": "0",
    "end": "8680"
  },
  {
    "text": "iHeartRadio and IBM. I’m Malcolm Gladwell.\nThis season, we’re continuing our conversation  ",
    "start": "8680",
    "end": "15480"
  },
  {
    "text": "with New Creators— visionaries who \nare creatively applying technology in  ",
    "start": "15480",
    "end": "19840"
  },
  {
    "text": "business to drive change—but with a focus \non the transformative power of artificial  ",
    "start": "19840",
    "end": "25480"
  },
  {
    "text": "intelligence and what it means to leverage AI as \na game- changing multiplier for your business. ",
    "start": "25480",
    "end": "32599"
  },
  {
    "text": "Our guest today is Christina Montgomery, IBM’s \nChief Privacy & Trust Officer. She’s also chair of  ",
    "start": "32600",
    "end": "39480"
  },
  {
    "text": "IBM’s AI Ethics Board. In addition to overseeing \nIBM’s privacy policy, a core part of Christina’s  ",
    "start": "39480",
    "end": "47079"
  },
  {
    "text": "job involves “AI governance”—making sure the way \nAI is used complies with the international legal  ",
    "start": "47080",
    "end": "54880"
  },
  {
    "text": "regulations customized for each industry.\nIn today’s episode, Christina will explain  ",
    "start": "54880",
    "end": "61360"
  },
  {
    "text": "why businesses need foundational principles when \nit comes to using technology, why AI regulation  ",
    "start": "61360",
    "end": "68680"
  },
  {
    "text": "should focus on specific use cases over the \ntechnology itself, and share a bit about her  ",
    "start": "68680",
    "end": "75360"
  },
  {
    "text": "landmark congressional testimony last May.\nChristina spoke with Dr. Laurie Santos,  ",
    "start": "75360",
    "end": "81880"
  },
  {
    "text": "host of the Pushkin podcast The Happiness \nLab. A cognitive scientist and psychology  ",
    "start": "81880",
    "end": "88039"
  },
  {
    "text": "professor at Yale University, Laurie is an \nexpert on human happiness and cognition. ",
    "start": "88040",
    "end": "94920"
  },
  {
    "text": "Ok! Let’s get to the interview.",
    "start": "94920",
    "end": "98209"
  },
  {
    "start": "98000",
    "end": "182000"
  },
  {
    "text": "Laurie Santos: So Christina, I'm so excited to talk to you today. So let's start by talking \na little bit about your role at IBM. What does  ",
    "start": "99062",
    "end": "105240"
  },
  {
    "text": "a chief privacy and trust officer actually do?",
    "start": "105240",
    "end": "108033"
  },
  {
    "text": "Christina Montgomery: Yeah, it's a really dynamic profession. And it's not a new profession, but the  role has really changed. I mean, my role today is  ",
    "start": "108033",
    "end": "116360"
  },
  {
    "text": "broader than just helping to ensure compliance \nwith data-protection laws globally. I'm also  ",
    "start": "116360",
    "end": "122160"
  },
  {
    "text": "responsible for AI governance. I cochair our AI \nEthics Board here at IBM on—for data clearance,  ",
    "start": "122160",
    "end": "128800"
  },
  {
    "text": "and data governance as well, for the company.\nSo I have both a compliance aspect to my  ",
    "start": "128800",
    "end": "134200"
  },
  {
    "text": "role—really important on a global basis—but also \nhelp the business to competitively differentiate,  ",
    "start": "134200",
    "end": "141000"
  },
  {
    "text": "because really, trust is a strategic advantage \nfor IBM and a competitive differentiator, as a  ",
    "start": "141000",
    "end": "146120"
  },
  {
    "text": "company that's been responsibly managing the most- \nsensitive data for our clients for more than a  ",
    "start": "146120",
    "end": "151400"
  },
  {
    "text": "century now, and helping to usher new technologies \ninto the world with trust and transparency. And  ",
    "start": "151400",
    "end": "156480"
  },
  {
    "text": "so that's also a key aspect of my role.",
    "start": "156480",
    "end": "159504"
  },
  {
    "text": "Laurie Santos: And so—you joined us here on Smart Talks back in 2021, and you chatted with us about IBM's approach of building trust  ",
    "start": "159504",
    "end": "166080"
  },
  {
    "text": "and transparency with AI. And that was only two \nyears ago, but it almost feels like an eternity  ",
    "start": "166080",
    "end": "171200"
  },
  {
    "text": "has happened in the field of AI since then. And \nso I'm curious: How much has changed since you  ",
    "start": "171200",
    "end": "176200"
  },
  {
    "text": "were here last time? The things you told us \nbefore, are they still true? How are things— ",
    "start": "176200",
    "end": "181560"
  },
  {
    "text": "Christina Montgomery: You're absolutely \nright. It feels like the world has changed,  ",
    "start": "181560",
    "end": "185920"
  },
  {
    "start": "182000",
    "end": "264000"
  },
  {
    "text": "really, in the last two years. But the same \nfundamental principles and the same overall  ",
    "start": "185920",
    "end": "191400"
  },
  {
    "text": "governance apply to the IBM program, for \ndata protection and responsible AI that we  ",
    "start": "191400",
    "end": "198720"
  },
  {
    "text": "talked about two years ago, and—not much \nhas changed there from our perspective. ",
    "start": "198720",
    "end": "203520"
  },
  {
    "text": "And the good thing is, we've put these practices \nand this governance approach into place,  ",
    "start": "203520",
    "end": "209320"
  },
  {
    "text": "and we have an established way of looking at these \nemerging technologies as the technology evolves.  ",
    "start": "209320",
    "end": "215360"
  },
  {
    "text": "The tech is more powerful, for sure. Foundation \nmodels are vastly larger and more capable,  ",
    "start": "215360",
    "end": "221080"
  },
  {
    "text": "and are creating, in some respects, new issues, \nbut that just makes it all the more urgent to  ",
    "start": "221080",
    "end": "226040"
  },
  {
    "text": "do what we've been doing and to put trust and\ntransparency into place across the business—to  ",
    "start": "226040",
    "end": "231120"
  },
  {
    "text": "be accountable to those principles.",
    "start": "231120",
    "end": "233737"
  },
  {
    "text": "Laurie Santos: And so our conversation today is really centered around this need for \nnew AI regulation. And part of that regulation  ",
    "start": "233737",
    "end": "239920"
  },
  {
    "text": "involves the mitigation of bias. And this is \nsomething I think about a ton as a psychologist,  ",
    "start": "239920",
    "end": "244800"
  },
  {
    "text": "right? I know, my students and everyone who's \ninteracting with AI is, is assuming that the,  ",
    "start": "244800",
    "end": "250080"
  },
  {
    "text": "the kind of knowledge that they're getting \nfrom this kind of learning is accurate, right? ",
    "start": "250080",
    "end": "254080"
  },
  {
    "text": "But of course, AI is only as good as \nthe knowledge that's going in. And  ",
    "start": "254080",
    "end": "257160"
  },
  {
    "text": "so talk to me a little bit about, why \nbias occurs in AI and the level of the  ",
    "start": "257160",
    "end": "262440"
  },
  {
    "text": "problem that we're really dealing with.\nChristina Montgomery: Yeah. I mean—well,  ",
    "start": "262440",
    "end": "265240"
  },
  {
    "start": "264000",
    "end": "367000"
  },
  {
    "text": "obviously AI is based on data, right? It's trained \nwith data, and that data could be biased in and of  ",
    "start": "265240",
    "end": "273319"
  },
  {
    "text": "itself. And that's where issues could come up. \nThey come up in the data. They could also come  ",
    "start": "273320",
    "end": "277400"
  },
  {
    "text": "up in the output of the models themselves.\nSo it's really important that you build bias  ",
    "start": "277400",
    "end": "284080"
  },
  {
    "text": "consideration and bias testing into your product \ndevelopment cycle. And so what we've been thinking  ",
    "start": "284080",
    "end": "289800"
  },
  {
    "text": "about here at IBM, and doing—we had—some of our \nresearch teams, uh, delivered some of the very  ",
    "start": "289800",
    "end": "294759"
  },
  {
    "text": "first tool kits to help detect bias years ago \nnow, right? And deployed them to open source. ",
    "start": "294760",
    "end": "299640"
  },
  {
    "text": "And we have put into place for our \ndevelopers here at IBM an “ethics by  ",
    "start": "300520",
    "end": "305520"
  },
  {
    "text": "design” playbook that's a sort of a step-by-step \napproach, which also addresses very fully bias  ",
    "start": "305520",
    "end": "312840"
  },
  {
    "text": "considerations. And we provide not only, \nlike, “Here’s a point when you should test  ",
    "start": "312840",
    "end": "319199"
  },
  {
    "text": "for it and you consider it in the data.”\nYou have to measure it both at the data  ",
    "start": "319200",
    "end": "323160"
  },
  {
    "text": "and the model level or the outcome level. And we \nprovide guidance with respect to what tools can  ",
    "start": "323160",
    "end": "328880"
  },
  {
    "text": "best be used to accomplish that. So it's a really \nimportant issue. It's one you—you can't just talk  ",
    "start": "328880",
    "end": "334040"
  },
  {
    "text": "about. You have to provide, essentially, \nthe technology and the capabilities and  ",
    "start": "334040",
    "end": "338160"
  },
  {
    "text": "the guidance to enable people to test for it.\nLaurie Santos: Recently you had this wonderful  ",
    "start": "338160",
    "end": "342600"
  },
  {
    "text": "opportunity to head to Congress to talk about \nAI. And in your testimony before Congress, you",
    "start": "342600",
    "end": "347360"
  },
  {
    "text": "mentioned that it's often said that innovation \nmoves too fast for government to keep up. ",
    "start": "347360",
    "end": "352120"
  },
  {
    "text": "And this is something that I also \nworry about as a psychologist,  ",
    "start": "352120",
    "end": "354800"
  },
  {
    "text": "right? Are policymakers really understanding \nthe issues that they're dealing with? And so I'm  ",
    "start": "354800",
    "end": "358840"
  },
  {
    "text": "curious how you're approaching this challenge \nof adapting AI policies to keep up with the  ",
    "start": "358840",
    "end": "362919"
  },
  {
    "text": "sort of rapid pace of all the advancements \nwe're seeing in the AI technology itself. ",
    "start": "362920",
    "end": "368160"
  },
  {
    "start": "367000",
    "end": "422000"
  },
  {
    "text": "Christina Montgomery: It gets really critically \nimportant that you have foundational principles  ",
    "start": "368160",
    "end": "372360"
  },
  {
    "text": "that apply to not only how you use \ntechnology, but whether you're going  ",
    "start": "372360",
    "end": "377520"
  },
  {
    "text": "to use it in the first place and where you're \ngoing to use and apply it across your company. ",
    "start": "377520",
    "end": "381840"
  },
  {
    "text": "—and then your program, from a governance \nperspective, has to be agile. It has to be  ",
    "start": "381840",
    "end": "386240"
  },
  {
    "text": "able to address emerging capabilities, \nnew training methods, et cetera. And  ",
    "start": "386240",
    "end": "392080"
  },
  {
    "text": "part of that involves helping to educate and \ninstill and empower a trustworthy culture at  ",
    "start": "392080",
    "end": "398680"
  },
  {
    "text": "a company so you can spot those issues—so you \ncan ask the right questions at the right time. ",
    "start": "398680",
    "end": "404160"
  },
  {
    "text": "If we talked about, during the Senate hearing, \nand—and IBM's been talking for years about  ",
    "start": "404160",
    "end": "409920"
  },
  {
    "text": "regulating the use, not the technology itself, \nbecause if you try to regulate technology, you're  ",
    "start": "409920",
    "end": "416520"
  },
  {
    "text": "very quickly going to find out, um, regulation \nwill absolutely never keep up with that. ",
    "start": "416520",
    "end": "421580"
  },
  {
    "text": "Laurie Santos: In your testimony to Congress, \nyou also talked about this idea of a “precision  ",
    "start": "421580",
    "end": "425800"
  },
  {
    "start": "422000",
    "end": "554000"
  },
  {
    "text": "regulation approach” for AI. Tell me more about \nthis. What is a precision regulation approach,  ",
    "start": "425800",
    "end": "430599"
  },
  {
    "text": "and why could that be so important?\nChristina Montgomery: It's funny,  ",
    "start": "430600",
    "end": "433000"
  },
  {
    "text": "because I was able to share with Congress our \nprecision regulation point of view in 2023,  ",
    "start": "433000",
    "end": "440280"
  },
  {
    "text": "but that precision regulation point of view was \npublished by IBM in 2020. So we have not changed  ",
    "start": "440280",
    "end": "447560"
  },
  {
    "text": "our position that you should apply the tightest \ncontrols, the strictest regulatory requirements,  ",
    "start": "447560",
    "end": "454919"
  },
  {
    "text": "to the technology where the end use and \nrisk of societal harm is the greatest. ",
    "start": "454920",
    "end": "459920"
  },
  {
    "text": "So that's essentially what it is. There's \nlots of AI technology that's used today  ",
    "start": "459920",
    "end": "464600"
  },
  {
    "text": "that doesn't touch people—that's \nvery low risk in nature. And even",
    "start": "464600",
    "end": "468920"
  },
  {
    "text": "when you think about AI that delivers a movie \nrecommendation versus AI that is used to diagnose  ",
    "start": "468920",
    "end": "476320"
  },
  {
    "text": "cancer, right? There's very different implications \nassociated with those two uses of the technology. ",
    "start": "476320",
    "end": "482800"
  },
  {
    "text": "And so essentially what precision regulation \nis “Apply different rules to different risks,”  ",
    "start": "482800",
    "end": "487840"
  },
  {
    "text": "right? More-stringent regulation to the use \ncases with the greatest risk. And then also  ",
    "start": "487840",
    "end": "493760"
  },
  {
    "text": "we build that out, calling for things like \ntransparency. You see it today with content,  ",
    "start": "493760",
    "end": "499480"
  },
  {
    "text": "right? Misinformation and the like.\nWe believe that consumers should always  ",
    "start": "499480",
    "end": "504360"
  },
  {
    "text": "know when they're interacting with an AI system. \nSo: be transparent. Don't hide your AI. Clearly  ",
    "start": "504360",
    "end": "510120"
  },
  {
    "text": "define the risks. So as a country, we need to have \nsome clear guidance, right? And globally as well,  ",
    "start": "510120",
    "end": "516760"
  },
  {
    "text": "in terms of which uses of AI are higher risk, \nwhere we'll apply higher and stricter regulation,  ",
    "start": "516760",
    "end": "524039"
  },
  {
    "text": "and have sort of a common understanding \nof what those high-risk uses are,  ",
    "start": "524040",
    "end": "528839"
  },
  {
    "text": "and then demonstrate the impact in \nthe cases of those higher-risk uses. ",
    "start": "528840",
    "end": "533320"
  },
  {
    "text": "So companies who are using AI in spaces \nwhere they can impact people's legal rights,  ",
    "start": "533320",
    "end": "539960"
  },
  {
    "text": "for example, should have to conduct an impact \nassessment that demonstrates, you know, that  ",
    "start": "539960",
    "end": "545600"
  },
  {
    "text": "the technology isn't biased. So we've been \npretty clear about “Apply the most-stringent  ",
    "start": "545600",
    "end": "550959"
  },
  {
    "text": "regulation to the highest- risk uses of AI.”\nLaurie Santos: So far, we've been talking  ",
    "start": "550960",
    "end": "556320"
  },
  {
    "text": "about your congressional testimony in terms \nof, you know, the specific content that you  ",
    "start": "556320",
    "end": "560320"
  },
  {
    "text": "talked about. But I'm just curious on a personal \nlevel, what was that like, right? Like right now,  ",
    "start": "560320",
    "end": "565120"
  },
  {
    "text": "it feels like at a policy level, like there's a \nkind of fever pitch going on with AI right now. ",
    "start": "565120",
    "end": "570000"
  },
  {
    "text": "You know, what did that feel like, to kind \nof really have the opportunity to talk to  ",
    "start": "570000",
    "end": "573200"
  },
  {
    "text": "policymakers and sort of influence what \nthey're thinking about AI technologies,  ",
    "start": "573200",
    "end": "576960"
  },
  {
    "text": "like in the coming century, perhaps?\nChristina Montgomery: It was really an  ",
    "start": "576960",
    "end": "579960"
  },
  {
    "text": "honor to be able to do that, and to be one of the \nfirst set of invitees to the first hearing. And  ",
    "start": "579960",
    "end": "587560"
  },
  {
    "text": "what I learned from it essentially is, really \ntwo things. The first is really the value of  ",
    "start": "587560",
    "end": "592880"
  },
  {
    "text": "authenticity. So both as an individual and as \na company, I was able to talk about what I do.",
    "start": "592880",
    "end": "601480"
  },
  {
    "text": "I didn't need a lot of advance prep, \nright? I, I talked about what my job is,  ",
    "start": "601480",
    "end": "607040"
  },
  {
    "text": "what IBM has been putting in place for years now. \nSo this isn't about creating something. This was  ",
    "start": "607040",
    "end": "613519"
  },
  {
    "text": "just about showing up and being authentic. And we \nwere invited for a reason. We were invited because  ",
    "start": "613520",
    "end": "618880"
  },
  {
    "text": "we were one of the earliest companies in the AI \ntechnology space. We're the oldest technology  ",
    "start": "618880",
    "end": "625360"
  },
  {
    "text": "company, and we are trusted, and that's an honor.\nAnd then the second thing I came away with was  ",
    "start": "625360",
    "end": "632120"
  },
  {
    "text": "really how important this issue is to society. \nI don't think I appreciated it as much until,  ",
    "start": "632120",
    "end": "638160"
  },
  {
    "text": "following that experience, I had outreach from \ncolleagues I hadn't worked with for years. ",
    "start": "638160",
    "end": "644480"
  },
  {
    "text": "I had outreach from family members who \nheard me on the radio, my mother and my  ",
    "start": "644480",
    "end": "649399"
  },
  {
    "text": "mother-in-law and my nieces and nephews and \nmy— friends of my kids were all like, “Oh,  ",
    "start": "649400",
    "end": "654280"
  },
  {
    "text": "I get it. I get what you do now. Wow. That's \npretty cool.” You know, so that was really,  ",
    "start": "654280",
    "end": "658760"
  },
  {
    "text": "the best and most impactful takeaway that I had.",
    "start": "659600",
    "end": "662462"
  },
  {
    "text": "Malcom Gladwell: The mass adoption of generative AI happening at breakneck speed has spurred societies and governments  ",
    "start": "662463",
    "end": "669160"
  },
  {
    "text": "around the world to get serious \nabout regulating AI. For businesses,  ",
    "start": "669160",
    "end": "675319"
  },
  {
    "text": "compliance is complex enough already. But \nthrow an ever-evolving technology like AI  ",
    "start": "675320",
    "end": "680000"
  },
  {
    "text": "into the mix and compliance itself \nbecomes an exercise in adaptability. ",
    "start": "680000",
    "end": "686600"
  },
  {
    "text": "As regulators seek greater accountability in \nhow AI is used, businesses need help creating  ",
    "start": "686600",
    "end": "692759"
  },
  {
    "text": "governance processes that are comprehensive enough \nto comply with the law but agile enough to keep up  ",
    "start": "692760",
    "end": "699520"
  },
  {
    "text": "with the rapid rate of change in AI development.\nRegulatory scrutiny isn’t the only consideration,  ",
    "start": "699520",
    "end": "706640"
  },
  {
    "text": "either. Responsible AI governance—a business’s \nability to prove its AI models are transparent  ",
    "start": "706640",
    "end": "713360"
  },
  {
    "text": "and explainable—is also key to building \ntrust with customers, regardless of industry. ",
    "start": "713360",
    "end": "720600"
  },
  {
    "text": "In the next part of their conversation, Laurie \nasks Christina what businesses should consider  ",
    "start": "720600",
    "end": "726560"
  },
  {
    "text": "when approaching AI governance. Let’s listen.\nLaurie Santos: So what's the particular  ",
    "start": "726560",
    "end": "731320"
  },
  {
    "start": "730000",
    "end": "806000"
  },
  {
    "text": "role that businesses are playing in AI \ngovernance? Like, why is it so critical  ",
    "start": "731320",
    "end": "734960"
  },
  {
    "text": "for businesses to be part of this?",
    "start": "734960",
    "end": "737178"
  },
  {
    "text": "Christina Montgomery: I think it's really critically important that businesses understand the impacts that technology can have,  ",
    "start": "737178",
    "end": "744480"
  },
  {
    "text": "both in making them better businesses—but \nthe impacts that those technologies can  ",
    "start": "744480",
    "end": "748920"
  },
  {
    "text": "have on the consumers that they are supporting.\nBusinesses need to be deploying AI technology  ",
    "start": "748920",
    "end": "757839"
  },
  {
    "text": "that is in alignment with the goals that \nthey set for it and that can be trusted.  ",
    "start": "757840",
    "end": "762440"
  },
  {
    "text": "I think for us and for our clients, a \nlot of this comes back to trust in tech. ",
    "start": "762440",
    "end": "768080"
  },
  {
    "text": "If you deploy something that doesn't work, \nthat hallucinates, that discriminates,  ",
    "start": "768080",
    "end": "774280"
  },
  {
    "text": "that isn't transparent, where decisions can't \nbe explained, then you are going to very rapidly  ",
    "start": "774280",
    "end": "780440"
  },
  {
    "text": "erode the trust—at best, right?—of your clients. \nAnd at worst, for yourself; you're going to create  ",
    "start": "780440",
    "end": "786120"
  },
  {
    "text": "legal and regulatory issues for yourself as well.\nSo trust in technology is really important.  ",
    "start": "786120",
    "end": "791720"
  },
  {
    "text": "And I think there's a lot of pressure on \nbusinesses today to move very rapidly and  ",
    "start": "791720",
    "end": "795399"
  },
  {
    "text": "adopt technology. But if you do it without \nhaving a program of governance in place,  ",
    "start": "795400",
    "end": "799800"
  },
  {
    "text": "you're really risking eroding that trust.",
    "start": "799800",
    "end": "801705"
  },
  {
    "text": "Laurie Santos: And so this is really where I think a strong AI governance comes in. \nYou know—talk about, from your perspective,  ",
    "start": "801705",
    "end": "807400"
  },
  {
    "start": "806000",
    "end": "886000"
  },
  {
    "text": "how this really contributes to \nmaintaining the trust that customers  ",
    "start": "807400",
    "end": "811080"
  },
  {
    "text": "and stakeholders have in these technologies.",
    "start": "811080",
    "end": "813804"
  },
  {
    "text": "Christina Montgomery: Yeah, absolutely. I mean, you need to have a governance program because  you need to understand, that the technology,  ",
    "start": "813804",
    "end": "820120"
  },
  {
    "text": "particularly in the AI space that you \nare deploying, is explainable. You need  ",
    "start": "820120",
    "end": "825400"
  },
  {
    "text": "to understand why it's making decisions and \nrecommendations that it's making, and you  ",
    "start": "825400",
    "end": "830400"
  },
  {
    "text": "need to be able to explain that to your consumers.\nI mean, you can't do that if you don't know where  ",
    "start": "830400",
    "end": "834360"
  },
  {
    "text": "your data is coming from; what data you're using \nto train those models; if you don't have a program",
    "start": "834360",
    "end": "839320"
  },
  {
    "text": "that manages the alignment of your \nAI models over time to make sure—as  ",
    "start": "839320",
    "end": "845200"
  },
  {
    "text": "AI learns and evolves over uses, which is in \nlarge part what makes it so beneficial—that  ",
    "start": "845200",
    "end": "853320"
  },
  {
    "text": "it stays in alignment with the objectives \nthat you set for the technology over time. ",
    "start": "853320",
    "end": "858720"
  },
  {
    "text": "So you can't do that without a robust governance \nprocess in place. So we work with clients to share  ",
    "start": "858720",
    "end": "865800"
  },
  {
    "text": "our own story here at IBM in terms of how we \nput that in place, but also in our consulting  ",
    "start": "865800",
    "end": "871680"
  },
  {
    "text": "practice, uh, to help clients work with these new \ngenerative capabilities and foundation models and  ",
    "start": "871680",
    "end": "878440"
  },
  {
    "text": "the like, in order to put them to work for their \nbusiness in a way that's going to be impactful to  ",
    "start": "878440",
    "end": "883640"
  },
  {
    "text": "that business, but at the same time be trusted.",
    "start": "883640",
    "end": "886360"
  },
  {
    "start": "886000",
    "end": "1020000"
  },
  {
    "text": "Laurie Santos: And so now I wanted to turn a little bit towards watsonx.governance. And—so IBM recently announced their AI platform, watsonx,  ",
    "start": "886360",
    "end": "892800"
  },
  {
    "text": "which will include a governance \ncomponent. Could you tell us a  ",
    "start": "893360",
    "end": "896560"
  },
  {
    "text": "little bit more about watsonx.governance?",
    "start": "896560",
    "end": "898937"
  },
  {
    "text": "Christina Montgomery: Yeah. I mean, before I do that, I'll just back up and talk about  the full platform, and then lean into watsonx,  ",
    "start": "898937",
    "end": "906280"
  },
  {
    "text": "because I think it's important to understand \nthe delivery of a full suite of capabilities.  ",
    "start": "906280",
    "end": "912680"
  },
  {
    "text": "To get data, to train models, and then to govern \nthem over their life cycle—all of these things  ",
    "start": "912680",
    "end": "920480"
  },
  {
    "text": "are really important. From the onset, you need \nto make sure that you have—for our watsonx.ai,  ",
    "start": "920480",
    "end": "928600"
  },
  {
    "text": "for example; that's the studio to train \nnew foundation models and generative AI  ",
    "start": "928600",
    "end": "935160"
  },
  {
    "text": "and machine-learning capabilities, and we are \npopulating that studio with some IBM-trained  ",
    "start": "935160",
    "end": "943000"
  },
  {
    "text": "foundation models, which we're curating and \ntailoring more specifically for enterprises. ",
    "start": "943000",
    "end": "949200"
  },
  {
    "text": "So that's really important. It comes back to the \npoint I made earlier about business trust and  ",
    "start": "949200",
    "end": "953960"
  },
  {
    "text": "the need,to have enterprise-ready technologies \nin the AI space. And then the watsonx.data is  ",
    "start": "953960",
    "end": "963520"
  },
  {
    "text": "a fit-for-purpose data store or a data lake, \nand then watsonx.gov. So that's a particular  ",
    "start": "963520",
    "end": "970800"
  },
  {
    "text": "component of the platform that my team and the \nAI Ethics Board has really worked closely with  ",
    "start": "970800",
    "end": "977800"
  },
  {
    "text": "the product team on developing. And we're using \nit internally here in the chief privacy office  ",
    "start": "977800",
    "end": "982800"
  },
  {
    "text": "as well to help us govern our own uses of \nAI technology and our compliance program  ",
    "start": "982800",
    "end": "990680"
  },
  {
    "text": "here. And it essentially helps to notify \nyou if a model becomes biased or gets out  ",
    "start": "990680",
    "end": "998320"
  },
  {
    "text": "of alignment as you're using it over time. So \ncompanies are going to need these capabilities.",
    "start": "998320",
    "end": "1003680"
  },
  {
    "text": "I mean, they need them today \nto deliver technologies with  ",
    "start": "1003680",
    "end": "1007040"
  },
  {
    "text": "trust. They'll need them tomorrow to comply \nwith regulation, which is on the horizon. ",
    "start": "1007040",
    "end": "1012000"
  },
  {
    "text": "Laurie Santos: I think compliance becomes even \nmore complex when you consider international  ",
    "start": "1012000",
    "end": "1016800"
  },
  {
    "text": "data-protection laws and regulations. Honestly, \nI don't know how anyone on any company's legal  ",
    "start": "1016800",
    "end": "1021360"
  },
  {
    "start": "1020000",
    "end": "1139000"
  },
  {
    "text": "team is keeping up with this these days. But my \nquestion for you is really, “How can businesses  ",
    "start": "1021360",
    "end": "1025959"
  },
  {
    "text": "develop a strategy to maintain compliance and to \ndeal with it in this ever- changing landscape?” ",
    "start": "1025960",
    "end": "1031000"
  },
  {
    "text": "Christina Montgomery: Increasingly more \nchallenging. In fact, I saw a statistic  ",
    "start": "1031000",
    "end": "1034600"
  },
  {
    "text": "just this morning that the regulatory obligations \non companies have increased something like 700  ",
    "start": "1034600",
    "end": "1041000"
  },
  {
    "text": "times in the last 20 years. So, it really is \na huge focus area for companies. You have to  ",
    "start": "1041000",
    "end": "1048319"
  },
  {
    "text": "have a process in place in order to do that.\nAnd it's not easy, particularly for a company  ",
    "start": "1048320",
    "end": "1053919"
  },
  {
    "text": "like IBM, that has a presence in over 170 \ncountries around the world. There's more  ",
    "start": "1053920",
    "end": "1060640"
  },
  {
    "text": "than 150 comprehensive privacy regulations. \nThere are regulations of nonpersonal data.  ",
    "start": "1060640",
    "end": "1067880"
  },
  {
    "text": "There are AI regulations emerging. So you \nreally need an operational approach to it,  ",
    "start": "1067880",
    "end": "1074800"
  },
  {
    "text": "in order to stay compliant.\nBut, but one of the things we do  ",
    "start": "1074800",
    "end": "1077240"
  },
  {
    "text": "is we set a baseline—and a lot of companies do \nthis as well. So we define a privacy baseline,  ",
    "start": "1077240",
    "end": "1082800"
  },
  {
    "text": "we define an AI baseline, and we ensure, then, \nas a result of that, there are very few deviances  ",
    "start": "1082800",
    "end": "1090160"
  },
  {
    "text": "because it incorporates that baseline.\nSo that's one of the ways we do it. Other  ",
    "start": "1090160",
    "end": "1094320"
  },
  {
    "text": "companies, I think, are similarly situated in \nterms of doing that. But, again, it is a real  ",
    "start": "1094320",
    "end": "1101799"
  },
  {
    "text": "challenge for global companies. It's one of the \nreasons why we advocate for as much alignment as  ",
    "start": "1101800",
    "end": "1107640"
  },
  {
    "text": "possible—in the international realm as well as \nnationally here in the U.S.—as much alignment as  ",
    "start": "1107640",
    "end": "1115320"
  },
  {
    "text": "possible to make compliance—easier—and not just \nbecause companies want an easy way to comply,  ",
    "start": "1115320",
    "end": "1123759"
  },
  {
    "text": "but the harder it is, the less likely \nthere will be compliance. And it's  ",
    "start": "1123760",
    "end": "1129080"
  },
  {
    "text": "not the objective of anybody—governments, \ncompanies, consumers—to have to set legal  ",
    "start": "1129080",
    "end": "1136399"
  },
  {
    "text": "obligations that companies simply can't meet.",
    "start": "1136400",
    "end": "1139150"
  },
  {
    "start": "1139000",
    "end": "1191000"
  },
  {
    "text": "Laurie Santos: So what advice would you give to other companies who are looking to rethink or strengthen their approach to AI governance?",
    "start": "1139150",
    "end": "1144498"
  },
  {
    "text": "Christina Montgomery: I think you need to start \nwith, as we did, foundational principles. And  ",
    "start": "1144498",
    "end": "1148640"
  },
  {
    "text": "you need to start making decisions about \nwhat technology you're going to deploy,  ",
    "start": "1148640",
    "end": "1153080"
  },
  {
    "text": "and what technology you're not, what are you \ngoing to use it for and what aren't you going to  ",
    "start": "1153080",
    "end": "1155640"
  },
  {
    "text": "use it for. And then when you do use it, align \nto those principles. That's really important. ",
    "start": "1155640",
    "end": "1161200"
  },
  {
    "text": "Formalize a program. Have someone within \nthe organization—whether it's the Chief  ",
    "start": "1161200",
    "end": "1166320"
  },
  {
    "text": "Privacy Officer, whether it's some other \nrole, a Chief AI Ethics Officer—but have  ",
    "start": "1166320",
    "end": "1172759"
  },
  {
    "text": "an accountable individual, an accountable \norganization. Do a maturity assessment,  ",
    "start": "1172760",
    "end": "1178200"
  },
  {
    "text": "figure out where you are and where you need to \nbe, and really start, putting it into place today.  ",
    "start": "1178200",
    "end": "1185200"
  },
  {
    "text": "Don't wait for regulation to apply directly \nto your business because it'll be too late. ",
    "start": "1185200",
    "end": "1191264"
  },
  {
    "start": "1191000",
    "end": "1252000"
  },
  {
    "text": "Laurie Santos: So as Smart \nTalks features New Creators,  ",
    "start": "1191265",
    "end": "1193320"
  },
  {
    "text": "these visionaries like yourself who are creatively \napplying technology in business to drive change,  ",
    "start": "1193320",
    "end": "1198639"
  },
  {
    "text": "I'm curious if you see yourself as creative.",
    "start": "1198640",
    "end": "1200882"
  },
  {
    "text": "Christina Montgomery: I definitely do. I mean, you need to be creative when you're working in an industry that evolves so very quickly.  ",
    "start": "1200882",
    "end": "1211360"
  },
  {
    "text": "So you know, I started with IBM when \nwe were primarily a hardware company,  ",
    "start": "1211360",
    "end": "1216600"
  },
  {
    "text": "right? And we've changed our business \nso significantly over the years. And  ",
    "start": "1216600",
    "end": "1220679"
  },
  {
    "text": "the issues that are raised with respect to \neach new technology—whether it be cloud,  ",
    "start": "1220680",
    "end": "1226840"
  },
  {
    "text": "whether it be AI, now, where we're seeing a \nton of issues, or you look at emergent issues,  ",
    "start": "1226840",
    "end": "1232039"
  },
  {
    "text": "in the space of things like neuro technologies \nand quantum computers—you have to be strategic  ",
    "start": "1232040",
    "end": "1240720"
  },
  {
    "text": "and you have to be creative and thinking about \nhow you can adapt agilely, quickly, a company to  ",
    "start": "1240720",
    "end": "1249240"
  },
  {
    "text": "an environment that is changing so quickly.",
    "start": "1249240",
    "end": "1251957"
  },
  {
    "text": "Laurie Santos: And with this transformation happening at such a rapid pace, \ndo you think creativity plays a  ",
    "start": "1251957",
    "end": "1257040"
  },
  {
    "start": "1252000",
    "end": "1294000"
  },
  {
    "text": "role in how you think about and implement, \nspecifically, a trustworthy AI strategy? ",
    "start": "1257040",
    "end": "1263520"
  },
  {
    "text": "Christina Montgomery: Yeah. I absolutely think \nit does. Because again, it comes back to  ",
    "start": "1263520",
    "end": "1267920"
  },
  {
    "text": "these capabilities. And, there are ways, I guess how \nyou define “creativity” could be different,  ",
    "start": "1267920",
    "end": "1273560"
  },
  {
    "text": "right? But I'm thinking of creativity in the \nsense of, sort of agility and strategic vision and  ",
    "start": "1273560",
    "end": "1279520"
  },
  {
    "text": "creative problem-solving. I think that's really \nimportant in the world that we're in right now,  ",
    "start": "1279520",
    "end": "1285360"
  },
  {
    "text": "being able to creatively problem solve with \nnew issues that are rising sort of every day.",
    "start": "1285360",
    "end": "1293785"
  },
  {
    "text": "Laurie Santos: And so how do you see the role \nof Chief Privacy Officer evolving in the future  ",
    "start": "1293785",
    "end": "1297480"
  },
  {
    "text": "as AI technology continues to advance? Like, \nwhat steps should CPOs take to stay ahead of  ",
    "start": "1297480",
    "end": "1302280"
  },
  {
    "text": "all these changes that are coming their way?",
    "start": "1302280",
    "end": "1304232"
  },
  {
    "text": "Christina Montgomery: So the role is evolving, in most companies, I would say, pretty rapidly. Many companies are looking to  ",
    "start": "1304232",
    "end": "1313200"
  },
  {
    "text": "chief privacy officers, who already understand \nthe data that's being used in the organization  ",
    "start": "1313200",
    "end": "1318600"
  },
  {
    "text": "and have programs to ensure compliance with laws \nthat require you to manage that data in accordance  ",
    "start": "1318600",
    "end": "1325039"
  },
  {
    "text": "with data-protection laws and the like.\nIt's a natural place and position for,  ",
    "start": "1325040",
    "end": "1330241"
  },
  {
    "text": "AI responsibility. And so I think what's \nhappening to a lot of chief privacy officers is  ",
    "start": "1330241",
    "end": "1336440"
  },
  {
    "text": "they're being asked to take on this AI-governance \nresponsibility for companies,—and if not take it  ",
    "start": "1336440",
    "end": "1342320"
  },
  {
    "text": "on, at least play a very key role working with \nother parts of the business in AI governance. ",
    "start": "1342320",
    "end": "1349399"
  },
  {
    "text": "So that really is changing. And if Chief \nPrivacy Officers are in companies who maybe  ",
    "start": "1349400",
    "end": "1354880"
  },
  {
    "text": "haven't started thinking about AI yet, \nthey should, so I would encourage them  ",
    "start": "1354880",
    "end": "1360080"
  },
  {
    "text": "to look at different resources that are available \nalready in the AI-governance space. For example,  ",
    "start": "1360080",
    "end": "1366240"
  },
  {
    "text": "the International Association of Privacy \nProfessionals—which is the 75,000-member  ",
    "start": "1366240",
    "end": "1372480"
  },
  {
    "text": "professional body for the profession of chief \nprivacy officers—just recently launched,  ",
    "start": "1372480",
    "end": "1378520"
  },
  {
    "text": "an AI- governance initiative on—an AI-governance \ncertification program. I sit on their advisory  ",
    "start": "1378520",
    "end": "1384600"
  },
  {
    "text": "board. But that's just emblematic of the \nfact that the field is changing so rapidly. ",
    "start": "1384600",
    "end": "1391184"
  },
  {
    "start": "1391000",
    "end": "1480000"
  },
  {
    "text": "Laurie Santos: And so, speaking of rapid \nchange—when you were back here on Smart Talks  ",
    "start": "1391185",
    "end": "1395120"
  },
  {
    "text": "in 2021, you said that the future of AI will \nbe more transparent and more trustworthy.What  ",
    "start": "1395120",
    "end": "1400520"
  },
  {
    "text": "do you see the next five to 10 years holding? \nYou know, when you're back on Smart Talks in,  ",
    "start": "1400520",
    "end": "1404760"
  },
  {
    "text": "you know, 2026, you know, 2030, you know, \nwhat are we going to be talking about  ",
    "start": "1404760",
    "end": "1408640"
  },
  {
    "text": "when it comes to AI technology and governance?",
    "start": "1408640",
    "end": "1410584"
  },
  {
    "text": "Christina Montgomery: So I try to be an optimist, right? And I said that two years ago, and I think we're seeing it now come into  ",
    "start": "1410584",
    "end": "1419040"
  },
  {
    "text": "fruition. And there will be requirements, \nwhether they're coming from the U.S.,  ",
    "start": "1419040",
    "end": "1424200"
  },
  {
    "text": "whether they're coming from Europe, whether \nthey're just coming from voluntary adoption",
    "start": "1424200",
    "end": "1428120"
  },
  {
    "text": "by clients of things like the NIST risk-management \nframework, a really important voluntary framework,  ",
    "start": "1428120",
    "end": "1434720"
  },
  {
    "text": "you're going to have to adopt transparent \nand explainable practices in your uses of AI. ",
    "start": "1434720",
    "end": "1439960"
  },
  {
    "text": "So I do see that happening. And in the next \nfive to 10 years, boy, I think we'll see more  ",
    "start": "1439960",
    "end": "1444960"
  },
  {
    "text": "research into trust in, in techniques, because we \ndon't really know for example, how to watermark.  ",
    "start": "1444960",
    "end": "1454320"
  },
  {
    "text": "We were calling for things like watermarking; \nthere'll be more research into how to do that. ",
    "start": "1454320",
    "end": "1459840"
  },
  {
    "text": "I think you'll see regulation that's specifically \ngoing to require those types of things. So I  ",
    "start": "1459840",
    "end": "1466559"
  },
  {
    "text": "think—again, I think the regulation is going \nto drive research. It's going to drive research  ",
    "start": "1466560",
    "end": "1470680"
  },
  {
    "text": "into these areas that will help ensure that we can \ndeliver new capabilities, generative capabilities  ",
    "start": "1470680",
    "end": "1477680"
  },
  {
    "text": "and the like, with trust and explainability.",
    "start": "1477680",
    "end": "1479973"
  },
  {
    "text": "Laurie Santos: Thank you so much, Christina, for joining me on Smart Talks to talk about AI and governance. ",
    "start": "1479973",
    "end": "1484738"
  },
  {
    "start": "1480000",
    "end": "1617000"
  },
  {
    "text": "Christina Montgomery: Well, thank \nyou very much for having me. ",
    "start": "1484738",
    "end": "1488200"
  },
  {
    "text": "Malcolm Gladwell: To unlock the transformative growth possible with artificial intelligence, businesses need to know  ",
    "start": "1488200",
    "end": "1493960"
  },
  {
    "text": "what they wish to grow into first. Like Christina \nsaid, the best way forward in the AI future is for  ",
    "start": "1493960",
    "end": "1501360"
  },
  {
    "text": "businesses to figure out their own foundational \nprinciples around using the technology,  ",
    "start": "1501360",
    "end": "1506880"
  },
  {
    "text": "drawing upon those principles to apply AI in \na way that’s ethically consistent with their  ",
    "start": "1506880",
    "end": "1512680"
  },
  {
    "text": "mission and complies with the legal frameworks \nbuilt to hold the technology accountable. ",
    "start": "1512680",
    "end": "1518680"
  },
  {
    "text": "As AI adoption grows more and more widespread, \nso too will the expectation from consumers and  ",
    "start": "1518680",
    "end": "1524880"
  },
  {
    "text": "regulators that businesses use it responsibly. \nInvesting in dependable AI governance is a way for  ",
    "start": "1524880",
    "end": "1532040"
  },
  {
    "text": "businesses to lay the foundations for technology \ntheir customers can trust, while rising to the  ",
    "start": "1532040",
    "end": "1538520"
  },
  {
    "text": "challenge of increasing regulatory complexity.\nThough the emergence of AI does complicate  ",
    "start": "1538520",
    "end": "1545400"
  },
  {
    "text": "an already tough compliance landscape, \nbusinesses now face a creative opportunity to",
    "start": "1545400",
    "end": "1551360"
  },
  {
    "text": "set a precedent for what accountability in \nAI looks like and to rethink what it means  ",
    "start": "1551360",
    "end": "1556960"
  },
  {
    "text": "to deploy trustworthy artificial intelligence. ",
    "start": "1556960",
    "end": "1561640"
  },
  {
    "text": "I’m Malcolm Gladwell.\nThis is a paid advertisement from IBM. ",
    "start": "1561640",
    "end": "1567040"
  },
  {
    "text": "Smart talks with IBM will \nbe taking a short hiatus,  ",
    "start": "1567040",
    "end": "1569840"
  },
  {
    "text": "but look for new episodes in the coming weeks.\nSmart Talks with IBM is produced by Matt Romano,  ",
    "start": "1569840",
    "end": "1576640"
  },
  {
    "text": "David Zha, Nisha Venkat, and Royston \nBeserve, with Jacob Goldstein. We’re  ",
    "start": "1576640",
    "end": "1582080"
  },
  {
    "text": "edited by Lidia Jean Kott. Our engineer is \nJason Gambrell. Theme song by Gramoscope. ",
    "start": "1582080",
    "end": "1587799"
  },
  {
    "text": "Special thanks to Carly Migliori, Andy Kelly, \nKathy Callaghan, and the EightBar and IBM teams,  ",
    "start": "1588680",
    "end": "1595720"
  },
  {
    "text": "as well as the Pushkin marketing team.\nSmart Talks with IBM is a production  ",
    "start": "1595720",
    "end": "1600840"
  },
  {
    "text": "of Pushkin Industries and Ruby Studio at \niHeartMedia. To find more Pushkin podcasts,  ",
    "start": "1600840",
    "end": "1607240"
  },
  {
    "text": "listen on the iHeartRadio app, Apple \nPodcasts, or wherever you listen to podcasts.",
    "start": "1607240",
    "end": "1618000"
  }
]
[
  {
    "text": "This is how to build an MCP server so you can connect your LLM agents into just about anything.",
    "start": "30",
    "end": "5030"
  },
  {
    "text": "The model context protocol was released by Anthropic in November, 2024.",
    "start": "5190",
    "end": "9469"
  },
  {
    "text": "It addresses a lot of the issues that have been popping up around agents.",
    "start": "9970",
    "end": "13089"
  },
  {
    "text": "How?",
    "start": "13530",
    "end": "14269"
  },
  {
    "text": "Well, in order for agents to exist, they need tools, right?",
    "start": "14270",
    "end": "17649"
  },
  {
    "text": "But every framework or app or client tends to bring its own way of declaring these tools.",
    "start": "18030",
    "end": "22949"
  },
  {
    "text": "Now, this becomes a pain because",
    "start": "23350",
    "end": "25763"
  },
  {
    "text": "you might find yourself creating integrations repeatedly every time you want to use an AI capability.",
    "start": "25763",
    "end": "30210"
  },
  {
    "text": "This is where MCP comes in.",
    "start": "30950",
    "end": "33009"
  },
  {
    "text": "It standardizes how LLMs talk to tools.",
    "start": "33250",
    "end": "35970"
  },
  {
    "text": "So you can define your tool server once and use it everywhere.",
    "start": "36230",
    "end": "39630"
  },
  {
    "text": "I'm going to show you how to build your own in under 10 minutes,",
    "start": "40110",
    "end": "43103"
  },
  {
    "text": "but does it only work with paid LLM's and how hard is it actually to build?",
    "start": "43103",
    "end": "47449"
  },
  {
    "text": "And what about observability?",
    "start": "47750",
    "end": "48989"
  },
  {
    "text": "Can I track what's using a specific tool?",
    "start": "49170",
    "end": "51549"
  },
  {
    "text": "We'll get to that.",
    "start": "51890",
    "end": "52730"
  },
  {
    "text": "I'm recording this after a big bowl of carbs and without using cursor copilot or my",
    "start": "52730",
    "end": "56919"
  },
  {
    "text": "old mate stack overflow, I'm going to break it down into three straight forward steps.",
    "start": "56919",
    "end": "61189"
  },
  {
    "text": "Phase one, build the server.",
    "start": "61460",
    "end": "62659"
  },
  {
    "text": "Alrighty, so we are gonna go on ahead and build our very own MCP server.",
    "start": "63180",
    "end": "67200"
  },
  {
    "text": "And as usual, we're gonna set a bit of a timer.",
    "start": "67280",
    "end": "68979"
  },
  {
    "text": "So 10 minutes on the clock, let's kick this thing off.",
    "start": "69560",
    "end": "73099"
  },
  {
    "text": "So I've already got, I guess a little bit of background as to what we're going to be building an MCP server for.",
    "start": "73520",
    "end": "78759"
  },
  {
    "text": "So I built a machine learning API in this video where we actually went and deployed it using Fast API.",
    "start": "79140",
    "end": "86920"
  },
  {
    "text": "And you can see here that I've currently got it running locally via this specific endpoint.",
    "start": "87190",
    "end": "92109"
  },
  {
    "text": "Now, if I go and send this particular body, so years at company, so it's predicting employee churn.",
    "start": "92490",
    "end": "98129"
  },
  {
    "text": "So this dictates how many years that particular employee has been at the company,",
    "start": "98510",
    "end": "101881"
  },
  {
    "text": "as well as their satisfaction, their position, whether they're a manager or non-manager, and their salaries.",
    "start": "101881",
    "end": "106868"
  },
  {
    "text": "I've split this up into an ordinal representation between one to five.",
    "start": "106870",
    "end": "110590"
  },
  {
    "text": "So if I send this off, it's gonna predict whether or not the employee is",
    "start": "110850",
    "end": "113864"
  },
  {
    "text": "likely to churn, so you can say down here that we've got a prediction of zero.",
    "start": "113864",
    "end": "116629"
  },
  {
    "text": "If we went and change their employee satisfaction to zero one, you can see they're still not gonna churn.",
    "start": "116990",
    "end": "122409"
  },
  {
    "text": "What if their salary sucked?",
    "start": "122470",
    "end": "123949"
  },
  {
    "text": "So if we send that through, they're not gonna churn.",
    "start": "124290",
    "end": "126489"
  },
  {
    "text": "So maybe if they had less, so maybe they're ultra loyal.",
    "start": "126750",
    "end": "129229"
  },
  {
    "text": "So if change their years at the company, take a look.",
    "start": "129509",
    "end": "131629"
  },
  {
    "text": "So we've now got a one.",
    "start": "131690",
    "end": "132769"
  },
  {
    "text": "So that represents the fact that they are gonna churn.",
    "start": "132810",
    "end": "134989"
  },
  {
    "text": "But how would we convert this into an MCP server so that we can expose it to all of our amazing AI agents?",
    "start": "135350",
    "end": "142489"
  },
  {
    "text": "Well, that's exactly what we're gonna do with our MCP servers.",
    "start": "142870",
    "end": "145849"
  },
  {
    "text": "So.",
    "start": "145850",
    "end": "146490"
  },
  {
    "text": "You can see that I've got my API running here.",
    "start": "146490",
    "end": "148569"
  },
  {
    "text": "So that's just what I've shown using fast API and I'll include a link to that as well.",
    "start": "148590",
    "end": "152610"
  },
  {
    "text": "But for now, we are going to focus on getting our MCP server up and running.",
    "start": "152770",
    "end": "157710"
  },
  {
    "text": "Okay, so we wanna go on ahead and do this.",
    "start": "157990",
    "end": "160550"
  },
  {
    "text": "So, all right, focus.",
    "start": "161310",
    "end": "162010"
  },
  {
    "text": "So we're gonna go UV in it and we're going to create a employee project.",
    "start": "162010",
    "end": "167709"
  },
  {
    "text": "So this is going to now create a folder called employee.",
    "start": "167750",
    "end": "170190"
  },
  {
    "text": "It's got my PI project, thermal file, so on and so forth.",
    "start": "170350",
    "end": "173090"
  },
  {
    "text": "Then what we need to go ahead and a CD into that folder.",
    "start": "173450",
    "end": "176209"
  },
  {
    "text": "So we're now inside it and we want to go ahead and create a virtual environment.",
    "start": "177050",
    "end": "182110"
  },
  {
    "text": "So I'm gonna go UV, V, ENV.",
    "start": "182110",
    "end": "184009"
  },
  {
    "text": "So we've now got a virtual enviroment and then we're actually gonna copy this command to activate it.",
    "start": "184310",
    "end": "188610"
  },
  {
    "text": "Boom, that is our virtual environment now created.",
    "start": "188770",
    "end": "190870"
  },
  {
    "text": "So if we jump in, you can see that we've got our virtual enviornment.",
    "start": "190930",
    "end": "193189"
  },
  {
    "text": "All of our project files were looking good.",
    "start": "193350",
    "end": "195729"
  },
  {
    "text": "Okay, what do we wanna go ahead and do now?",
    "start": "196610",
    "end": "198289"
  },
  {
    "text": "We need to import or install our dependencies.",
    "start": "198310",
    "end": "200690"
  },
  {
    "text": "So we gonna go uv add and we wanna MCP CLI package.",
    "start": "200750",
    "end": "206569"
  },
  {
    "text": "And we also want requests.",
    "start": "207960",
    "end": "209400"
  },
  {
    "text": "Let's make sure I'm not covering that.",
    "start": "209480",
    "end": "210698"
  },
  {
    "text": "So we're actually going to be using the model context protocol.",
    "start": "210720",
    "end": "213500"
  },
  {
    "text": "So this is our big library over here, which is going to allow us to do all of this amazing stuff.",
    "start": "213560",
    "end": "218520"
  },
  {
    "text": "And there's a whole bunch of information about how this actually works.",
    "start": "218540",
    "end": "221079"
  },
  {
    "text": "We're mainly going to using the Python SDK.",
    "start": "221500",
    "end": "223600"
  },
  {
    "text": "Okay, so that is, let's run that install.",
    "start": "224080",
    "end": "226699"
  },
  {
    "text": "Perfect, we're now installed.",
    "start": "227040",
    "end": "228040"
  },
  {
    "text": "All right, we can clear that.",
    "start": "228880",
    "end": "229880"
  },
  {
    "text": "So if we jump into, we also want to create a server file.",
    "start": "230080",
    "end": "232860"
  },
  {
    "text": "So I'm gonna go touch server.py, beautiful.",
    "start": "232880",
    "end": "236419"
  },
  {
    "text": "Okay, so if we jump in here now, we should have a server file.",
    "start": "236720",
    "end": "239399"
  },
  {
    "text": "Okay, that is the beginnings of our server.",
    "start": "239880",
    "end": "241999"
  },
  {
    "text": "Very basic at the moment, but we need to go on ahead and build this out.",
    "start": "242080",
    "end": "245059"
  },
  {
    "text": "So the first thing that we're gonna do is we're going to import our dependencies.",
    "start": "245280",
    "end": "249539"
  },
  {
    "text": "Oh God, the time.",
    "start": "249980",
    "end": "251259"
  },
  {
    "text": "How's that time?",
    "start": "251780",
    "end": "252580"
  },
  {
    "text": "Oh my Lord, seven minutes.",
    "start": "252580",
    "end": "253900"
  },
  {
    "text": "Okay, we are gonna need to punch it.",
    "start": "254040",
    "end": "255459"
  },
  {
    "text": "So we're to go from mcp.server.fastmcp.",
    "start": "255480",
    "end": "261652"
  },
  {
    "text": "we are going to import fast MCP.",
    "start": "262610",
    "end": "265949"
  },
  {
    "text": "And then we need to import a bunch of other stuff.",
    "start": "266130",
    "end": "268209"
  },
  {
    "text": "So we're gonna import JSONs.",
    "start": "268210",
    "end": "269350"
  },
  {
    "text": "We're gonna use this.",
    "start": "269350",
    "end": "269990"
  },
  {
    "text": "So this fast MCP class is going to be like the crux of our entire server.",
    "start": "269990",
    "end": "274189"
  },
  {
    "text": "So you'll see when I instantiate that in a second.",
    "start": "274270",
    "end": "276229"
  },
  {
    "text": "Then we want JSON, we're going to use that for some parsing later on.",
    "start": "276530",
    "end": "278649"
  },
  {
    "text": "We're going import requests to actually make a request out to this API.",
    "start": "278670",
    "end": "282649"
  },
  {
    "text": "And then what do we want?",
    "start": "282810",
    "end": "284089"
  },
  {
    "text": "We need a little bit of typing assistance.",
    "start": "284130",
    "end": "286069"
  },
  {
    "text": "So we gonna go from typing, we're go to import list because that's how we're to pass the input",
    "start": "286070",
    "end": "291050"
  },
  {
    "text": "from that agent.",
    "start": "291360",
    "end": "292340"
  },
  {
    "text": "Okay, those are our dependencies now done.",
    "start": "292340",
    "end": "293759"
  },
  {
    "text": "We're then gonna create our server.",
    "start": "293880",
    "end": "294959"
  },
  {
    "text": "So I'm gonna say MCP is equal to fastMCP and we're gonna call it churn and burn.",
    "start": "295020",
    "end": "300078"
  },
  {
    "text": "sort of in alignment with my desktop, right?",
    "start": "302520",
    "end": "305119"
  },
  {
    "text": "Okay, so then, so that's our server created, server created.",
    "start": "305500",
    "end": "310279"
  },
  {
    "text": "And then we wanna create a tool.",
    "start": "310460",
    "end": "311979"
  },
  {
    "text": "So create the tool,",
    "start": "312240",
    "end": "313240"
  },
  {
    "text": "and there's different resource types, right, or different capabilities that you are able to build inside of your MCP server.",
    "start": "314620",
    "end": "321300"
  },
  {
    "text": "So you've got the ability, let me jump back.",
    "start": "321400",
    "end": "323459"
  },
  {
    "text": "You've got ability over down here.",
    "start": "323720",
    "end": "325379"
  },
  {
    "text": "So you can build resources, prompts, tools, you can handle sampling, transports.",
    "start": "325400",
    "end": "329839"
  },
  {
    "text": "We'll talk about that a little bit later.",
    "start": "329840",
    "end": "331000"
  },
  {
    "text": "Okay, so we are going to create a decorator.",
    "start": "332220",
    "end": "334300"
  },
  {
    "text": "So we're going to mcp.tool.",
    "start": "334300",
    "end": "336319"
  },
  {
    "text": "So this is going to wrap our function that's going to call out to our end point.",
    "start": "336920",
    "end": "340420"
  },
  {
    "text": "So then we're gonna create that specific tool.",
    "start": "340460",
    "end": "343518"
  },
  {
    "text": "So I'm gonna call it predict churn and it's going return a string and we now need to handle the data that we're to take in.",
    "start": "343540",
    "end": "352220"
  },
  {
    "text": "So we are gonna take in a argument called data.",
    "start": "352220",
    "end": "354799"
  },
  {
    "text": "It's going be a list of dictionaries.",
    "start": "355080",
    "end": "357659"
  },
  {
    "text": "Okay, that's beautiful.",
    "start": "358460",
    "end": "359638"
  },
  {
    "text": "So then what we actually need to do is define a docstring.",
    "start": "359740",
    "end": "362479"
  },
  {
    "text": "Now I've gone and written this a little bit earlier.",
    "start": "362560",
    "end": "364779"
  },
  {
    "text": "So this is what we're gonna paste in.",
    "start": "365080",
    "end": "366418"
  },
  {
    "text": "So I'm gonna copy that and then let's read it for a sec, time permitting.",
    "start": "366420",
    "end": "371180"
  },
  {
    "text": "Okay, so this tool predicts whether an employee will churn or not pass through the input as a list of samples.",
    "start": "371520",
    "end": "375899"
  },
  {
    "text": "So the arguments, so data employee attributes which are used for inference,",
    "start": "376280",
    "end": "379713"
  },
  {
    "text": "the example payload, and you can see I've got a list.",
    "start": "379713",
    "end": "381920"
  },
  {
    "text": "wrapped or a dictionary wrapped in a list.",
    "start": "382350",
    "end": "384350"
  },
  {
    "text": "And it takes in the exact same variables that we had inside of postman where I was over here.",
    "start": "384350",
    "end": "389329"
  },
  {
    "text": "Here's a company employee sat position and salary.",
    "start": "389370",
    "end": "391970"
  },
  {
    "text": "Here's the company employees sat position and salary, and it's gonna return either one churn or zero no churn.",
    "start": "392230",
    "end": "397509"
  },
  {
    "text": "Okay, so that's a doc string now created.",
    "start": "397710",
    "end": "400110"
  },
  {
    "text": "Now we wanna go on ahead and handle this.",
    "start": "400490",
    "end": "403009"
  },
  {
    "text": "So we're gonna create a variable for our payload and we're just gonna grab the first.",
    "start": "403010",
    "end": "407749"
  },
  {
    "text": "value that we have inside of our list, right?",
    "start": "408280",
    "end": "410800"
  },
  {
    "text": "So we're just accessing this excluding the list.",
    "start": "410800",
    "end": "413779"
  },
  {
    "text": "Okay.",
    "start": "414020",
    "end": "414520"
  },
  {
    "text": "Then we need to make a call out to our API for minutes.",
    "start": "414520",
    "end": "417680"
  },
  {
    "text": "Okay.",
    "start": "418000",
    "end": "418320"
  },
  {
    "text": "This is not looking good.",
    "start": "418320",
    "end": "419779"
  },
  {
    "text": "So we gonna go request.post cause remember over here, we're making a post",
    "start": "419780",
    "end": "424357"
  },
  {
    "text": "request and then we are gonna send it actually out to that URL.",
    "start": "424357",
    "end": "427860"
  },
  {
    "text": "But if you had an external URL, you'd be going out to, let's paste in there.",
    "start": "428080",
    "end": "432220"
  },
  {
    "text": "We need some headers and our headers, oh, okay.",
    "start": "432340",
    "end": "436839"
  },
  {
    "text": "I should have practiced some typing this morning.",
    "start": "437570",
    "end": "440070"
  },
  {
    "text": "We're going to accept CCEPT application forward slash JSON.",
    "start": "440250",
    "end": "446790"
  },
  {
    "text": "And we are going to specify the content type.",
    "start": "448130",
    "end": "452129"
  },
  {
    "text": "Should have toggled word wrap.",
    "start": "452870",
    "end": "455009"
  },
  {
    "text": "There we go. All right.",
    "start": "456230",
    "end": "456929"
  },
  {
    "text": "Content type is going to be application /JSON,",
    "start": "456929",
    "end": "461568"
  },
  {
    "text": "and then we want to pass through our data, which going to be a JSON dumped",
    "start": "461568",
    "end": "466850"
  },
  {
    "text": "Payload.",
    "start": "468421",
    "end": "469421"
  },
  {
    "text": "Okay, beautiful.",
    "start": "470360",
    "end": "471240"
  },
  {
    "text": "All right, so that's our response now set up.",
    "start": "471240",
    "end": "472979"
  },
  {
    "text": "Then what we're gonna do is we're going to return response.json once the user calls out to this.",
    "start": "473020",
    "end": "478879"
  },
  {
    "text": "Okay, so, that is our tool now created.",
    "start": "479020",
    "end": "480639"
  },
  {
    "text": "Now, we just basically need to specify what we do when it gets called out.",
    "start": "480920",
    "end": "484279"
  },
  {
    "text": "Actually, if name equals main, we are going to run our MCP server.",
    "start": "484360",
    "end": "492818"
  },
  {
    "text": "So, MCP.run and then our transport.",
    "start": "492920",
    "end": "495480"
  },
  {
    "text": "is going to equal STDIO, so standard input output.",
    "start": "496850",
    "end": "500430"
  },
  {
    "text": "All right, I'm pausing the timer.",
    "start": "500510",
    "end": "501410"
  },
  {
    "text": "All right. So we've got",
    "start": "501410",
    "end": "502346"
  },
  {
    "text": "two minutes and 47 seconds left, but that is our server now created.",
    "start": "502346",
    "end": "507170"
  },
  {
    "text": "So we're good to go.",
    "start": "508010",
    "end": "509370"
  },
  {
    "text": "All right so we've knocked off phase one and we've the server up and running, but how do we actually test that it's working?",
    "start": "509670",
    "end": "515509"
  },
  {
    "text": "Can we actually get to our tool?",
    "start": "515870",
    "end": "517289"
  },
  {
    "text": "Well, this brings us to phase two, testing out the server.",
    "start": "517669",
    "end": "520590"
  },
  {
    "text": "Okay, we're back.",
    "start": "521429",
    "end": "522229"
  },
  {
    "text": "So we've gone and created that server, but we haven't really tested it out yet.",
    "start": "522230",
    "end": "525428"
  },
  {
    "text": "So how do we go about doing this?",
    "start": "525450",
    "end": "527049"
  },
  {
    "text": "Well, I've got two minutes, 47 seconds left on the timer.",
    "start": "527090",
    "end": "530690"
  },
  {
    "text": "So let's keep this up.",
    "start": "531050",
    "end": "531910"
  },
  {
    "text": "So let me show you how to do this.",
    "start": "531910",
    "end": "533569"
  },
  {
    "text": "Okay, so we are currently inside of the employee folder.",
    "start": "533990",
    "end": "536289"
  },
  {
    "text": "We want to start off the dev server.",
    "start": "536410",
    "end": "538349"
  },
  {
    "text": "So this is going to give us access to the MCP inspector.",
    "start": "538390",
    "end": "541170"
  },
  {
    "text": "We can actually test out our tools.",
    "start": "541530",
    "end": "542909"
  },
  {
    "text": "We can go UV run MCP dev server.py.",
    "start": "542930",
    "end": "546510"
  },
  {
    "text": "This should start off the inspector.",
    "start": "547080",
    "end": "548460"
  },
  {
    "text": "I'm gonna pause it.",
    "start": "548640",
    "end": "549320"
  },
  {
    "text": "If we successfully get the inspector up.",
    "start": "549320",
    "end": "550860"
  },
  {
    "text": "Okay, that's our inspector up and running.",
    "start": "550960",
    "end": "552799"
  },
  {
    "text": "I can copy this URL here.",
    "start": "553120",
    "end": "555119"
  },
  {
    "text": "I'm going to go to a browser.",
    "start": "555460",
    "end": "557540"
  },
  {
    "text": "Nope, no, go back.",
    "start": "558000",
    "end": "559720"
  },
  {
    "text": "I'm not going to copy this again.",
    "start": "560080",
    "end": "561760"
  },
  {
    "text": "I'm now going to paste that in, beautiful.",
    "start": "563260",
    "end": "564740"
  },
  {
    "text": "All right, that time inspector.",
    "start": "564920",
    "end": "565920"
  },
  {
    "text": "So if I connect down here, then if I go to tools up here, then if go to list tools, that is our tool now running.",
    "start": "565920",
    "end": "573540"
  },
  {
    "text": "I'm go to pause it, all right.",
    "start": "573580",
    "end": "574440"
  },
  {
    "text": "We're good.",
    "start": "574440",
    "end": "574930"
  },
  {
    "text": "We've got two minutes left.",
    "start": "574930",
    "end": "575930"
  },
  {
    "text": "All right, but let me sort of show you, right?",
    "start": "575950",
    "end": "577070"
  },
  {
    "text": "So over here, we've got our transport type.",
    "start": "577510",
    "end": "579090"
  },
  {
    "text": "So there's two different transport types available.",
    "start": "579110",
    "end": "580950"
  },
  {
    "text": "So there standard input output.",
    "start": "581050",
    "end": "582609"
  },
  {
    "text": "There is also a SSE, which is server-sent events.",
    "start": "583070",
    "end": "586389"
  },
  {
    "text": "So this is more important.",
    "start": "586430",
    "end": "587450"
  },
  {
    "text": "So you probably use a standard input-output when you're just connecting with local files or local tools.",
    "start": "587790",
    "end": "592409"
  },
  {
    "text": "When you're doing something more client-server related, you're probably more default over to server-sent events.",
    "start": "592730",
    "end": "597370"
  },
  {
    "text": "We're using...",
    "start": "597470",
    "end": "598470"
  },
  {
    "text": "STDIO or standard input output as dictated based on the fact that right down here under transport, we are specifying that.",
    "start": "598906",
    "end": "606899"
  },
  {
    "text": "Tools like Cursor can handle SSE and STDIO, I think for desktop that uses STDIO only.",
    "start": "607160",
    "end": "615219"
  },
  {
    "text": "The capability that we're gonna use in a second is we're going to do that with STDIO when it comes to using our agent.",
    "start": "615820",
    "end": "620720"
  },
  {
    "text": "Okay, enough of me blabbing.",
    "start": "621160",
    "end": "622360"
  },
  {
    "text": "So let's jump over to our inspector.",
    "start": "622400",
    "end": "623820"
  },
  {
    "text": "So to use our inspector, you just make sure you specify the right transport type, the right command.",
    "start": "624280",
    "end": "628440"
  },
  {
    "text": "and the right argument.",
    "start": "629470",
    "end": "630689"
  },
  {
    "text": "And if you hit connect, you can see that we're connected.",
    "start": "630790",
    "end": "633209"
  },
  {
    "text": "Remember how I said there's different capabilities that you can pass through in your MCP server.",
    "start": "633510",
    "end": "637030"
  },
  {
    "text": "They're all up here.",
    "start": "637150",
    "end": "638150"
  },
  {
    "text": "We're just interested in our tool.",
    "start": "638190",
    "end": "639650"
  },
  {
    "text": "And if we hit predict churn, we can actually go and test this out.",
    "start": "639770",
    "end": "642869"
  },
  {
    "text": "So if I switch to JSON over here, we can go and pass through an object.",
    "start": "642870",
    "end": "646809"
  },
  {
    "text": "So again, I've got one nicely formatted.",
    "start": "646970",
    "end": "649310"
  },
  {
    "text": "So we're gonna copy this over, chuck that in here.",
    "start": "649350",
    "end": "653308"
  },
  {
    "text": "All right, drum roll, please.",
    "start": "653630",
    "end": "655049"
  },
  {
    "text": "So now if we go and hit run tool, take a look.",
    "start": "655810",
    "end": "658229"
  },
  {
    "text": "We've got our prediction.",
    "start": "658230",
    "end": "659230"
  },
  {
    "text": "So we've successfully gone and determined that this particular employee with these particular values will not churn.",
    "start": "659730",
    "end": "667010"
  },
  {
    "text": "Now, if we went and changed it up, so I'm just gonna change it in here because you get this weird thing, not ideal.",
    "start": "667150",
    "end": "671369"
  },
  {
    "text": "So when I go and delete value, so like, let's say I deleted this, you can see we're getting errors.",
    "start": "671610",
    "end": "675409"
  },
  {
    "text": "So it's running through syntax formatting while I'm trying to edit.",
    "start": "675450",
    "end": "679210"
  },
  {
    "text": "So we just do that here.",
    "start": "679750",
    "end": "681130"
  },
  {
    "text": "So let's they had not that many years of the company, they weren't",
    "start": "681330",
    "end": "684611"
  },
  {
    "text": "all that satisfied and their salary was in the lower quadrant or",
    "start": "684611",
    "end": "689630"
  },
  {
    "text": "what is it, fifth?",
    "start": "690120",
    "end": "691120"
  },
  {
    "text": "So if I paste that in now, take a look, that particular person will churn.",
    "start": "691700",
    "end": "695480"
  },
  {
    "text": "Okay, that is our tool now successfully running and our MCP server successfully working.",
    "start": "695740",
    "end": "700200"
  },
  {
    "text": "Right, so we've now established that our server actually works.",
    "start": "700440",
    "end": "703100"
  },
  {
    "text": "We've made a call to it and we're able to get a prediction back as",
    "start": "703120",
    "end": "706449"
  },
  {
    "text": "to whether or not somebody's likely to churn or not churn, how do we bring this into an agent?",
    "start": "706449",
    "end": "710959"
  },
  {
    "text": "Well, that brings us to phase three, adding it into an agent.",
    "start": "711280",
    "end": "714759"
  },
  {
    "text": "Alrighty, last thing we got to do, so I've got two minutes.",
    "start": "715000",
    "end": "717500"
  },
  {
    "text": "Thanks for watching!",
    "start": "717500",
    "end": "718330"
  },
  {
    "text": "Let me bring that back up.",
    "start": "718330",
    "end": "719310"
  },
  {
    "text": "Two minutes left on the timer.",
    "start": "719310",
    "end": "721009"
  },
  {
    "text": "All right, so what we now need to go ahead and do is integrate this into our agent.",
    "start": "721190",
    "end": "725389"
  },
  {
    "text": "So I've gone and pre-written up an agent using the BeeAI framework",
    "start": "725450",
    "end": "731204"
  },
  {
    "text": "and I'll make this available via GitHub so you'll be able to test that out.",
    "start": "731204",
    "end": "734669"
  },
  {
    "text": "And this is all built using, let me show you the LLM.",
    "start": "735040",
    "end": "739039"
  },
  {
    "text": "So we're using Ollama, we're specifically using the Granite 3.1, dense eight",
    "start": "739160",
    "end": "743339"
  },
  {
    "text": "billion parameter model, which is gonna be trained by an amazing research team.",
    "start": "743339",
    "end": "746760"
  },
  {
    "text": "So we are going to go on ahead and use this.",
    "start": "746960",
    "end": "749280"
  },
  {
    "text": "Now, right down the bottom, you can see that I've got this question.",
    "start": "749520",
    "end": "752080"
  },
  {
    "text": "So will this particular employee churn?",
    "start": "752140",
    "end": "754120"
  },
  {
    "text": "And I've gotten my employee sample over here.",
    "start": "754500",
    "end": "756720"
  },
  {
    "text": "So I've go the years of the company, the employees sat, the position and their salary.",
    "start": "756740",
    "end": "760880"
  },
  {
    "text": "So hopefully, fingers crossed, we can send this over.",
    "start": "761020",
    "end": "762839"
  },
  {
    "text": "So we were running out of time.",
    "start": "763060",
    "end": "764300"
  },
  {
    "text": "Got a minute 14 left.",
    "start": "764500",
    "end": "765500"
  },
  {
    "text": "Okay, let's punch this out.",
    "start": "765520",
    "end": "766440"
  },
  {
    "text": "So we need to go over to here.",
    "start": "766440",
    "end": "768719"
  },
  {
    "text": "We've got our standard input output server params.",
    "start": "768920",
    "end": "771639"
  },
  {
    "text": "So we needed to pass through our command.",
    "start": "771680",
    "end": "773220"
  },
  {
    "text": "So our command is going to be UV.",
    "start": "773320",
    "end": "774759"
  },
  {
    "text": "And then we are going to run, we need pass through directory to specify where our server actually is.",
    "start": "775200",
    "end": "781299"
  },
  {
    "text": "And then I just want to go and grab the file path to our server.",
    "start": "781480",
    "end": "785699"
  },
  {
    "text": "So I'm going to copy this, copy path boom, and then back into our agent.",
    "start": "785760",
    "end": "790100"
  },
  {
    "text": "And then, I'm gonna paste that in here",
    "start": "790140",
    "end": "793183"
  },
  {
    "text": "and then we need to go and run our command and we are going to run",
    "start": "793183",
    "end": "797420"
  },
  {
    "text": "server.py and just over here, I just want to get rid of server.",
    "start": "797420",
    "end": "801500"
  },
  {
    "text": "Okay, so now if I go and ran this, let me just go to another terminal, beautiful.",
    "start": "801560",
    "end": "805259"
  },
  {
    "text": "And if I got run Python single flow agent, okay. We've got 30 seconds left.",
    "start": "805360",
    "end": "810579"
  },
  {
    "text": "Let's see how we go.",
    "start": "811120",
    "end": "812200"
  },
  {
    "text": "Drum roll, please.",
    "start": "812400",
    "end": "813400"
  },
  {
    "text": "Take a look.",
    "start": "814140",
    "end": "815140"
  },
  {
    "text": "There we go, I'm going to pause it.",
    "start": "815840",
    "end": "817199"
  },
  {
    "text": "We had 22 seconds left, not too bad.",
    "start": "817540",
    "end": "819659"
  },
  {
    "text": "Okay, sorry.",
    "start": "819740",
    "end": "820740"
  },
  {
    "text": "And let's quickly run through this.",
    "start": "820760",
    "end": "821940"
  },
  {
    "text": "So right down here, you can see that we've got a thought from our agent.",
    "start": "822120",
    "end": "826380"
  },
  {
    "text": "So the user wants to know if the employee will churn based on their attributes.",
    "start": "826460",
    "end": "829080"
  },
  {
    "text": "I need to use the predict churn tool.",
    "start": "829180",
    "end": "830539"
  },
  {
    "text": "And then right down, here, we've managed to get a prediction.",
    "start": "830920",
    "end": "833859"
  },
  {
    "text": "So over here, we've a prediction of one indicating that the employee should churn.",
    "start": "834300",
    "end": "838200"
  },
  {
    "text": "So what does our agent said?",
    "start": "838240",
    "end": "839299"
  },
  {
    "text": "This employee is predicted to churn, so we've successfully gone",
    "start": "839680",
    "end": "843636"
  },
  {
    "text": "and built out our MCP server and integrated it into an agent.",
    "start": "843637",
    "end": "847600"
  },
  {
    "text": "A lmost forgot observability.",
    "start": "847860",
    "end": "849279"
  },
  {
    "text": "All you need to do is import logging and add in this line here.",
    "start": "849600",
    "end": "852880"
  },
  {
    "text": "And this will give you the ability to see every tool call in your server logs.",
    "start": "852940",
    "end": "856800"
  },
  {
    "text": "And in the interest of interoperability, just to prove that this MCP server could be used elsewhere,",
    "start": "857220",
    "end": "862323"
  },
  {
    "text": "I can add it to, for example, cursor by using the following command,",
    "start": "862323",
    "end": "866514"
  },
  {
    "text": "which is effectively just the command that will pass through to our agent, then I can open up a chat,",
    "start": "866514",
    "end": "871194"
  },
  {
    "text": "paste in an example to whether or not this particular person will churn, then convert to agent mode and hit send.",
    "start": "871194",
    "end": "879689"
  },
  {
    "text": "Then I should be able to run the tool by opening up the example and hitting run tool,",
    "start": "879790",
    "end": "885670"
  },
  {
    "text": "and if I scroll on down, you'll see that",
    "start": "886110",
    "end": "888420"
  },
  {
    "text": "I've got a prediction of one, which indicates that that particular employee is going to churn.",
    "start": "888420",
    "end": "891990"
  },
  {
    "text": "Same server, MCP everywhere.",
    "start": "892210",
    "end": "893670"
  }
]
[
  {
    "start": "0",
    "end": "8000"
  },
  {
    "text": "Hello everyone.",
    "start": "807",
    "end": "1689"
  },
  {
    "text": "My name is Aishwarya Srinivasan and I am an AI and ML innovation leader here at IBM.",
    "start": "1862",
    "end": "7293"
  },
  {
    "text": "What we see in the current knowledge era is that \nthe volume of data has increased tremendously  ",
    "start": "7840",
    "end": "13920"
  },
  {
    "start": "8000",
    "end": "42000"
  },
  {
    "text": "but the amount of information extracted from the \ndata hasn’t increased as much, which leads to a  ",
    "start": "13920",
    "end": "20640"
  },
  {
    "text": "knowledge gap with the un-used data. The total \naccumulated volume of data has grown from 4.4ZB  ",
    "start": "20640",
    "end": "27599"
  },
  {
    "text": "in 2013 to 44ZB in 2020, so we accumulated 9 \ntimes more data just in those 7 years, but we  ",
    "start": "28560",
    "end": "39760"
  },
  {
    "text": "haven’t been leveraging all this data. This data \ncan be anywhere. Different industries, different  ",
    "start": "39760",
    "end": "46559"
  },
  {
    "start": "42000",
    "end": "103000"
  },
  {
    "text": "organizations, local businesses, individuals \nstore their data in various sources - Oracle,  ",
    "start": "46560",
    "end": "54160"
  },
  {
    "text": "Db2, SQL Server, PostgreSQL, MongoDB etc. \nthat could be residing on multiple platforms;  ",
    "start": "54160",
    "end": "61360"
  },
  {
    "text": "cloud, on-premises, and mainframes in various \nformats; relational, non-relational and NoSQL.  ",
    "start": "62320",
    "end": "70320"
  },
  {
    "text": "The challenge comes when we want to use \nall these data sources for analytics  ",
    "start": "71360",
    "end": "75360"
  },
  {
    "text": "and to build models. So, what’s the best \nway to move data? To not move it at all.",
    "start": "75920",
    "end": "81759"
  },
  {
    "text": "This is where Data Virtualization comes into play.  ",
    "start": "82720",
    "end": "86320"
  },
  {
    "text": "Data virtualization is a technique to connect \nto all data sources seamlessly and securely in  ",
    "start": "86320",
    "end": "93120"
  },
  {
    "text": "a single location. With these capabilities, we can \nquery all the data source as if they reside in one  ",
    "start": "93120",
    "end": "101440"
  },
  {
    "text": "single space. without having to copy and replicate \ndata, regardless of its format. This would  ",
    "start": "101440",
    "end": "103760"
  },
  {
    "text": "significantly reduce costs and complexity for data \nengineering, simplify data management, improve  ",
    "start": "103760",
    "end": "111520"
  },
  {
    "text": "collaboration from data stewards to engineers to \ndata scientist, and enable centralized access.  ",
    "start": "111520",
    "end": "113840"
  },
  {
    "text": "When working with such huge volumes of data,  ",
    "start": "115520",
    "end": "119119"
  },
  {
    "text": "governance also comes into play which is \nalso addressed with data virtualization. ",
    "start": "119120",
    "end": "123840"
  },
  {
    "text": "As an overview, Data virtualization \nconsists of three layers.  ",
    "start": "124880",
    "end": "129200"
  },
  {
    "start": "125000",
    "end": "178000"
  },
  {
    "text": "The bottom most is the connection layer that \ninteracts with the databases that we need.  ",
    "start": "130000",
    "end": "135360"
  },
  {
    "text": "Next is the virtualization layer that is used to \nbuild optimized queries, virtual tables and scale  ",
    "start": "136320",
    "end": "143360"
  },
  {
    "text": "while preserving performance with parallel \nprocessing. The third layer is the consumer  ",
    "start": "143360",
    "end": "149200"
  },
  {
    "text": "layer which has all the user interface through \nwhile once can build views and query them. As  ",
    "start": "149200",
    "end": "156720"
  },
  {
    "text": "a complementary layer, we have the governance \ncatalog, that pulls metadata from across the  ",
    "start": "156720",
    "end": "163000"
  },
  {
    "text": "data sources and builds on business terms, data \nlineage, data privacy and protection rules.  ",
    "start": "163000",
    "end": "169840"
  },
  {
    "text": "With this we can have a controlled, governed \nand secure access to virtual datasets.",
    "start": "170800",
    "end": "177280"
  },
  {
    "start": "178000",
    "end": "282000"
  },
  {
    "text": "Let’s dig a little deeper into this.",
    "start": "178480",
    "end": "180640"
  },
  {
    "text": "With Data Virtualization, we can achieve faster \nData Exploration. Data virtualization is designed  ",
    "start": "181600",
    "end": "186204"
  },
  {
    "text": "and architected as a peer-to-peer computational \nmesh, which offers a significant advantage over  ",
    "start": "186204",
    "end": "186334"
  },
  {
    "text": "traditional federation architecture. \nUsing IBM Research advancements,  ",
    "start": "186335",
    "end": "186431"
  },
  {
    "text": "the data virtualization engine can rapidly deliver \nquery results from multiple data sources by  ",
    "start": "186431",
    "end": "186561"
  },
  {
    "text": "leveraging advanced parallel processing \nand optimization. Collaborative highly  ",
    "start": "186561",
    "end": "187840"
  },
  {
    "text": "paralleled compute models provide superior \nquery performance compared to federation,  ",
    "start": "187840",
    "end": "192879"
  },
  {
    "text": "up to 430% faster against 100TB \ndatasets. Data virtualization has  ",
    "start": "193520",
    "end": "199235"
  },
  {
    "text": "unmatched scaling of complex queries with joins \nand aggregates across dozens of live systems.",
    "start": "199235",
    "end": "199680"
  },
  {
    "text": "Secondly, when running queries \non these datasets, we need  ",
    "start": "199680",
    "end": "203599"
  },
  {
    "text": "to build optimized versions for better modeling.\nMachine learning can make database queries faster  ",
    "start": "203600",
    "end": "206541"
  },
  {
    "text": "and improve outcomes. For example, a traditional \ncost-based query optimizer can provide a suggested  ",
    "start": "206541",
    "end": "206663"
  },
  {
    "text": "execution strategy for a given query, but if the \nstrategy doesn’t work as expected, the optimizer  ",
    "start": "206663",
    "end": "206784"
  },
  {
    "text": "can’t learn from the experience. However, a \nmachine learning-powered query optimizer can  ",
    "start": "206785",
    "end": "206896"
  },
  {
    "text": "learn from experience and refine the query path \nwith each execution. That’s how the Db2 Machine  ",
    "start": "206896",
    "end": "207015"
  },
  {
    "text": "Learning Optimizer works. It mimics neural network \npatterns to optimize query paths. The result is  ",
    "start": "207016",
    "end": "208160"
  },
  {
    "text": "faster insights to your team—with \nsome queries being completed  ",
    "start": "208160",
    "end": "212000"
  },
  {
    "text": "up to 8 – 10 times faster as \nmeasured by IBM internal testing.",
    "start": "212000",
    "end": "216560"
  },
  {
    "text": "Third is Cost saving. To run a business in a \ndata-centric environment, you must have access  ",
    "start": "217120",
    "end": "218724"
  },
  {
    "text": "to exactly what you need, when you need it. When \nbusiness users have responsive and proactive  ",
    "start": "218725",
    "end": "218947"
  },
  {
    "text": "access to all data with governance, they make \nbetter business decisions. Data virtualization  ",
    "start": "218947",
    "end": "220720"
  },
  {
    "text": "leads to significantly lower costs for \ninfrastructure and reduces time spent  ",
    "start": "220720",
    "end": "226160"
  },
  {
    "text": "managing data, which has a direct \neffect on organizations bottom line. ",
    "start": "226160",
    "end": "230720"
  },
  {
    "text": "Another cost savings of the platform comes in \nthe form of the high-level compression techniques  ",
    "start": "230720",
    "end": "231269"
  },
  {
    "text": "within Virtual Data Pipeline. This solution helps \nenterprises minimize the required storage of data  ",
    "start": "231269",
    "end": "236640"
  },
  {
    "text": "copies while still maintaining continuity \nbetween the compressed and optimized versions  ",
    "start": "236640",
    "end": "241280"
  },
  {
    "text": "of the source or production data. The first copy \ntypically sees around a 50 percent decrease in  ",
    "start": "241280",
    "end": "243024"
  },
  {
    "text": "size while subsequent copies can garner upwards of \n95 percent decrease from the original source data.",
    "start": "243024",
    "end": "243524"
  },
  {
    "text": "Finally, Virtual Data Pipeline can be used \nas a storage backup and recovery capability  ",
    "start": "244400",
    "end": "250560"
  },
  {
    "text": "and expands to cover test data \nmanagement and analytics data  ",
    "start": "250560",
    "end": "254800"
  },
  {
    "text": "pipeline. Many organizations are shifting their \napplication strategy to a continuous approach  ",
    "start": "254800",
    "end": "255555"
  },
  {
    "text": "to ensure quality and support agile development \nand DevOps. For test data, this means drastically  ",
    "start": "255555",
    "end": "255782"
  },
  {
    "text": "reducing the data provisioning time while enabling \nautomation and self-service access to data.",
    "start": "255782",
    "end": "256000"
  },
  {
    "text": "So, with Data Virtualization \norganizations can view, access,  ",
    "start": "256000",
    "end": "260480"
  },
  {
    "text": "manipulate and analyze data, without \nworrying about the physical location.",
    "start": "261040",
    "end": "265767"
  },
  {
    "text": "To learn more about Data \nVirtualization, do visit our website.",
    "start": "266160",
    "end": "270000"
  }
]
[
  {
    "text": "Large language models like ChatGPT are examples of foundation models,",
    "start": "90",
    "end": "4511"
  },
  {
    "text": "large reusable models that have been trained on vast amounts of knowledge on the Internet,",
    "start": "4511",
    "end": "10090"
  },
  {
    "text": "and they're super flexible.",
    "start": "10090",
    "end": "11559"
  },
  {
    "text": "The same large language model can analyze a legal document",
    "start": "11580",
    "end": "15805"
  },
  {
    "text": "or write a poem about my soccer team.",
    "start": "15805",
    "end": "18909"
  },
  {
    "text": "But what if we want to improve the performance of pre-trained LLMs, or Large Language Models,",
    "start": "18930",
    "end": "25918"
  },
  {
    "text": "to address a specialized task?",
    "start": "25918",
    "end": "28420"
  },
  {
    "text": "Well, until recently, the best way to do that was using a method that is known as \"fine tuning\".",
    "start": "28500",
    "end": "37908"
  },
  {
    "text": "Now with fine tuning, you gather and label examples of the target task.",
    "start": "39390",
    "end": "45120"
  },
  {
    "text": "Lots and lots of examples,",
    "start": "45540",
    "end": "47906"
  },
  {
    "text": "and you fine tune your model rather than train an entirely new one from scratch.",
    "start": "47906",
    "end": "52661"
  },
  {
    "text": "But there's a simpler, far more energy efficient technique that has emerged in place of fine tuning,",
    "start": "52920",
    "end": "59331"
  },
  {
    "text": "and that is known as \"prompt tuning\".",
    "start": "59332",
    "end": "65741"
  },
  {
    "text": "So what is prompt tuning?",
    "start": "67220",
    "end": "69829"
  },
  {
    "text": "Well, prompt tuning allows a company with limited data to tailor a massive model to a very narrow task.",
    "start": "70280",
    "end": "76760"
  },
  {
    "text": "And there's no need for gathering thousands of labeled examples like we have to do with fine tuning.",
    "start": "77000",
    "end": "81590"
  },
  {
    "text": "In prompt tuning the best cues, or front end prompts,",
    "start": "81890",
    "end": "85537"
  },
  {
    "text": "are fed to your AI model to give it task-specific context.",
    "start": "85537",
    "end": "89269"
  },
  {
    "text": "The prompts can be extra words introduced by a human",
    "start": "89660",
    "end": "92209"
  },
  {
    "text": "or more commonly, an AI generated number introduced into the model's embedding layer",
    "start": "92209",
    "end": "97833"
  },
  {
    "text": "to guide the model towards a desired decision or prediction.",
    "start": "97833",
    "end": "100849"
  },
  {
    "text": "Now, if all this sounds a little bit familiar",
    "start": "100910",
    "end": "103352"
  },
  {
    "text": "using prompts to guide the output of an LLM,",
    "start": "103352",
    "end": "106988"
  },
  {
    "text": "that's because it most certainly is.",
    "start": "106988",
    "end": "109970"
  },
  {
    "text": "That is an example of something else called \"prompt engineering\".",
    "start": "110270",
    "end": "116498"
  },
  {
    "text": "Now, prompt engineering is the task of developing prompts that guided LLM to perform specialized tasks.",
    "start": "118130",
    "end": "124610"
  },
  {
    "text": "Honestly, it sounds like a lot of fun.",
    "start": "125300",
    "end": "127318"
  },
  {
    "text": "I think I'd quite like to be a prompt engineer one day.",
    "start": "127610",
    "end": "130699"
  },
  {
    "text": "So if I want my LLM to specialize as an English to French language translator,",
    "start": "131120",
    "end": "136786"
  },
  {
    "text": "I might engineer a prompt to do so.",
    "start": "136786",
    "end": "140178"
  },
  {
    "text": "So my prompt might start with, let's say, translate.",
    "start": "140178",
    "end": "145189"
  },
  {
    "text": "And we want to translate English to French.",
    "start": "145190",
    "end": "152290"
  },
  {
    "text": "That's the task description of my prompt.",
    "start": "153670",
    "end": "156909"
  },
  {
    "text": "Then I'm going to add some few short examples.",
    "start": "157090",
    "end": "159819"
  },
  {
    "text": "So let's let's add those now.",
    "start": "159970",
    "end": "161590"
  },
  {
    "text": "So here's the English word \"bread\" into the French word \"pain\".",
    "start": "161950",
    "end": "167627"
  },
  {
    "text": "That's one short example.",
    "start": "168000",
    "end": "169830"
  },
  {
    "text": "Let's add another, \"butter\".",
    "start": "169830",
    "end": "171580"
  },
  {
    "text": "We're going to turn that into \"beurre\".",
    "start": "171700",
    "end": "174323"
  },
  {
    "text": "And then the next part of my prompt,",
    "start": "174840",
    "end": "176789"
  },
  {
    "text": "I'm going to add to what that I wanted to translate next.",
    "start": "176789",
    "end": "179580"
  },
  {
    "text": "So, \"cheese\".",
    "start": "179730",
    "end": "181028"
  },
  {
    "text": "And that's it.",
    "start": "182870",
    "end": "183870"
  },
  {
    "text": "Now prompts like this written by a human, me,",
    "start": "184460",
    "end": "188098"
  },
  {
    "text": "Mr. Want-to-be-prompt-engineer himself,",
    "start": "188098",
    "end": "191331"
  },
  {
    "text": "they prime the model to retrieve the appropriate response from the LLM's vast memory.",
    "start": "191331",
    "end": "197148"
  },
  {
    "text": "In this case, specifically for other words in French.",
    "start": "197420",
    "end": "200180"
  },
  {
    "text": "And the model's output is its prediction.",
    "start": "200540",
    "end": "203689"
  },
  {
    "text": "What is this model going to output?",
    "start": "203900",
    "end": "207562"
  },
  {
    "text": "\"Fromage\", that worked!",
    "start": "207562",
    "end": "210099"
  },
  {
    "text": "We used prompt engineering to train a model",
    "start": "210490",
    "end": "213962"
  },
  {
    "text": "to perform a specialized task with just a single prompt",
    "start": "213962",
    "end": "217364"
  },
  {
    "text": "introduced to inference time without needing the model to be retrained.",
    "start": "217364",
    "end": "221622"
  },
  {
    "text": "But if the task is more complex than this, it may require dozens of these prompts.",
    "start": "221950",
    "end": "228249"
  },
  {
    "text": "And so these hand-crafted prompts have begun to be replaced",
    "start": "228250",
    "end": "232728"
  },
  {
    "text": "by AI designated prompts known as \"soft prompts\".",
    "start": "232728",
    "end": "239939"
  },
  {
    "text": "Now, soft prompts have been shown to outperform human engineered prompts,",
    "start": "242610",
    "end": "247948"
  },
  {
    "text": "which we can know now as \"hard prompts\".",
    "start": "247948",
    "end": "252209"
  },
  {
    "text": "These were hard coded by a human.",
    "start": "252930",
    "end": "255536"
  },
  {
    "text": "This is not good news for my prompt engineering career",
    "start": "256760",
    "end": "260234"
  },
  {
    "text": "because, you see, unlike hard problems, AI designed soft prompts,",
    "start": "260234",
    "end": "264131"
  },
  {
    "text": "they're used in prompt tuning and they are unrecognizable to the human eye.",
    "start": "264131",
    "end": "269839"
  },
  {
    "text": "Each prompt consists of an embedding",
    "start": "269870",
    "end": "271706"
  },
  {
    "text": "or strings of numbers that distill knowledge from the larger model.",
    "start": "271706",
    "end": "276139"
  },
  {
    "text": "And these soft prompts can be high level or task specific",
    "start": "276740",
    "end": "280474"
  },
  {
    "text": "and act as a substitute for additional training data",
    "start": "280475",
    "end": "283557"
  },
  {
    "text": "and are incredibly effective in guiding the model towards the desired output.",
    "start": "283557",
    "end": "287779"
  },
  {
    "text": "But do keep in mind that one drawback of prompt tuning and soft prompts in general",
    "start": "288470",
    "end": "293442"
  },
  {
    "text": "is its lack of interpretability.",
    "start": "293442",
    "end": "295550"
  },
  {
    "text": "That means that the AI discovers prompts optimized for a given task,",
    "start": "295580",
    "end": "299244"
  },
  {
    "text": "but it often can't explain why it chose those embeddings.",
    "start": "299244",
    "end": "302209"
  },
  {
    "text": "Like deep learning models themselves, soft prompts are opaque.",
    "start": "302360",
    "end": "306198"
  },
  {
    "text": "All right, so let's consider we have here a pre-trained model.",
    "start": "307040",
    "end": "313669"
  },
  {
    "text": "So this might be a large language model or something like that.",
    "start": "313880",
    "end": "319844"
  },
  {
    "text": "Okay, now let's consider three options for tailoring this pre-trained model for specialization.",
    "start": "322060",
    "end": "329939"
  },
  {
    "text": "I'm going to talk about the three that we've covered here.",
    "start": "330670",
    "end": "332939"
  },
  {
    "text": "So first of all, fine tuning.",
    "start": "332970",
    "end": "336000"
  },
  {
    "text": "Fine tuning.",
    "start": "337950",
    "end": "339170"
  },
  {
    "text": "So with fine tuning, we take this pre-trained model and we supplement it.",
    "start": "340500",
    "end": "345959"
  },
  {
    "text": "We supplement it specifically with tunable examples.",
    "start": "346350",
    "end": "350249"
  },
  {
    "text": "These are the thousands of examples that I talked about right at the beginning.",
    "start": "350250",
    "end": "353760"
  },
  {
    "text": "Once we've done that, we can then provide input data",
    "start": "354480",
    "end": "358738"
  },
  {
    "text": "into the model and it should now be able to perform a specialization.",
    "start": "358738",
    "end": "363150"
  },
  {
    "text": "So that's fine tuning.",
    "start": "363780",
    "end": "365310"
  },
  {
    "text": "What about prompt engineering?",
    "start": "365820",
    "end": "369940"
  },
  {
    "text": "How is that different?",
    "start": "370210",
    "end": "372000"
  },
  {
    "text": "But with prompt engineering, we take the model as it is,",
    "start": "372220",
    "end": "375670"
  },
  {
    "text": "we haven't tuned it, and then we add in an additional prompt.",
    "start": "375670",
    "end": "379899"
  },
  {
    "text": "So we have our input prompt.",
    "start": "379900",
    "end": "383686"
  },
  {
    "text": "But we also add in to that input prompt, an engineered prompt which sits in front of it.",
    "start": "384830",
    "end": "393000"
  },
  {
    "text": "So we effectively provide two prompts here for the specialization.",
    "start": "393650",
    "end": "397819"
  },
  {
    "text": "That's what we did with our language translator.",
    "start": "398750",
    "end": "401964"
  },
  {
    "text": "So we provided this prewritten engineered prompts, and then we provided our input, which was cheese.",
    "start": "402020",
    "end": "407660"
  },
  {
    "text": "So that's prompt engineering.",
    "start": "408760",
    "end": "410199"
  },
  {
    "text": "What about prompt tuning?",
    "start": "410350",
    "end": "412949"
  },
  {
    "text": "How is that different?",
    "start": "412960",
    "end": "414279"
  },
  {
    "text": "Well, with prompt tuning, again we use the pre-trained model as it is, and we again provide an input.",
    "start": "414760",
    "end": "422860"
  },
  {
    "text": "But we also provide something in front of that input.",
    "start": "424430",
    "end": "429108"
  },
  {
    "text": "And that is the tunable soft prompt that is generated by the AI itself.",
    "start": "429380",
    "end": "436500"
  },
  {
    "text": "And it's the combination of these two things that allow us to use the model in a specialized way.",
    "start": "436890",
    "end": "442440"
  },
  {
    "text": "Prompt tuning is proving to be a game changer in a variety of areas.",
    "start": "443430",
    "end": "446850"
  },
  {
    "text": "For instance, in multitask learning where models need to quickly switch between tasks,",
    "start": "446850",
    "end": "451547"
  },
  {
    "text": "researchers are finding ways to create universal prompts that can be easily recycled.",
    "start": "451547",
    "end": "455633"
  },
  {
    "text": "Techniques like multitask prompt tuning allow the model to be adapted swiftly",
    "start": "456060",
    "end": "460988"
  },
  {
    "text": "and for a fraction of the cost of retraining.",
    "start": "460988",
    "end": "463238"
  },
  {
    "text": "Prompt tuning is also showing promise in the field of continual learning,",
    "start": "463449",
    "end": "467434"
  },
  {
    "text": "where AI models need to learn new tasks and concepts without forgetting the old ones.",
    "start": "467434",
    "end": "471990"
  },
  {
    "text": "Essentially, prompt tuning allows you to adapt your model",
    "start": "472350",
    "end": "475918"
  },
  {
    "text": "to specialized tasks faster than fine tuning and prompt engineering,",
    "start": "475918",
    "end": "481801"
  },
  {
    "text": "making it easier to find and fix problems.",
    "start": "481801",
    "end": "485409"
  },
  {
    "text": "My career as a prompt engineer might be over before it started.",
    "start": "485750",
    "end": "490189"
  },
  {
    "text": "So I guess it's back to the drawing board,",
    "start": "490190",
    "end": "492344"
  },
  {
    "text": "or rather back to the embedding layer, because in the world a string of numbers is worth a thousand words.",
    "start": "492344",
    "end": "500906"
  },
  {
    "text": "If you have any questions, please drop us a line below.",
    "start": "501840",
    "end": "504449"
  },
  {
    "text": "And if you want to see more videos like this in the future, please \"like\" and subscribe.",
    "start": "504450",
    "end": "509456"
  },
  {
    "text": "Thanks for watching.",
    "start": "509670",
    "end": "511039"
  }
]
[
  {
    "text": "All right, looking back at 2024, what was the best model of the year? For me, it's going to be Gemini and Flash.",
    "start": "60",
    "end": "5590"
  },
  {
    "text": "And I'm going to nominate a sequence, I think, which is the sequence of the Llama models.",
    "start": "5600",
    "end": "10150"
  },
  {
    "text": "So is the bubble finally going to burst on Agents in 2025? Agents are the world. Agents are everything.",
    "start": "10770",
    "end": "16879"
  },
  {
    "text": "And in 2025, we're going to have super Agents. In 2025, is NVIDIA Still going to be king.",
    "start": "16879",
    "end": "23310"
  },
  {
    "text": "Not only NVIDIA is here, but we also see new entrance or the the other players in the market.",
    "start": "23369",
    "end": "29279"
  },
  {
    "text": "Are we going to end up having openness and safety? You can do this out in the open. It does not need to be behind a a black curtain.",
    "start": "29909",
    "end": "36690"
  },
  {
    "text": "So to speak. All that and more on today's mixture of experts.",
    "start": "36690",
    "end": "39750"
  },
  {
    "text": "I am Tim Hwang and welcome to Mixture of Experts. Each week, MoE is dedicated to bringing the gold standard banter you need",
    "start": "44790",
    "end": "51114"
  },
  {
    "text": "to make sense of the ever evolving landscape of artificial intelligence. Today, we're looking back at the huge evolutions across 2024.",
    "start": "51115",
    "end": "58265"
  },
  {
    "text": "You know, just to take you back, in January of 2024, we're all chattering about the release of the GPT store, Claude 2.1's long context window,",
    "start": "58475",
    "end": "66747"
  },
  {
    "text": "and I think at that point, we were still waiting for the release of Llama 3. Uh, 2024 was incredible, obviously a dynamic",
    "start": "66747",
    "end": "73429"
  },
  {
    "text": "year in AI, and so what we've done is we've gathered a bunch of our best panelists to talk about what stood out to them, what",
    "start": "73440",
    "end": "79070"
  },
  {
    "text": "didn't go as well, and maybe what they'll think, uh, about what happens in 2025. We're going to talk about agents, hardware,",
    "start": "79070",
    "end": "85868"
  },
  {
    "text": "product releases from the whole year, and But first, we're going to start with what happened in the world of AI models in 2024.",
    "start": "85899",
    "end": "91814"
  },
  {
    "text": "And to help us unpack the journey we've been on, we have with us Marina Danilevsky, who's a senior research scientist, and",
    "start": "92535",
    "end": "98244"
  },
  {
    "text": "Shobhit Varshney, senior partner consulting on AI for US, Canada, and Latin America.",
    "start": "98244",
    "end": "102804"
  },
  {
    "text": "And so I want to actually start with maybe a quick Uh, more kind of closer story, right? Even before we zoom back to the,",
    "start": "103324",
    "end": "108975"
  },
  {
    "text": "you know, dark ages of January 2024, uh, which is the release of o1. Um, you know, obviously this was",
    "start": "109095",
    "end": "114945"
  },
  {
    "text": "a big announcement, one of the biggest announcements of the year. And I know a show, but before the show, you and I were talking, you've You wanted to kind of",
    "start": "114945",
    "end": "121515"
  },
  {
    "text": "get in and actually just point out that like the release of o1 is actually marks a pretty big change in how these companies are thinking",
    "start": "121515",
    "end": "127895"
  },
  {
    "text": "about doing models and scaling these models. And maybe we'll just start there if you want to jump in. Excellent. It's such a great time to be alive.",
    "start": "127895",
    "end": "134925"
  },
  {
    "text": "Um, what we see all around us, like there's no other year in your entire career life",
    "start": "135075",
    "end": "140695"
  },
  {
    "text": "that you would rather be alive than today. In the last year or a year or so, we saw the era of scaling laws.",
    "start": "140695",
    "end": "147394"
  },
  {
    "text": "We got to a point where We realized that adding more compute, building larger models, and driving higher performance got us incredible,",
    "start": "147685",
    "end": "155284"
  },
  {
    "text": "incredible performance from these models, right? So we got to a point where we, we have insanely large models, now",
    "start": "155315",
    "end": "161301"
  },
  {
    "text": "Llama 4 and 5 billion parameters, 1.75 from GPT 4. You can see this huge set of big",
    "start": "161551",
    "end": "168475"
  },
  {
    "text": "models that are doing amazing work. Now we are transitioning to a couple of different shifts in the market.",
    "start": "168485",
    "end": "173385"
  },
  {
    "text": "One, we are seeing more of the shift moving towards the inference phase of it.",
    "start": "173645",
    "end": "178735"
  },
  {
    "text": "Slow down, think about what you want me to do and think through a plan and come up with an answer. We also started to give these models",
    "start": "179084",
    "end": "186174"
  },
  {
    "text": "more tools that they could use, just like we learned to use tools as we grow up. So we have these agentic flows that are",
    "start": "186174",
    "end": "191625"
  },
  {
    "text": "helping us increase the intelligence as well. We also saw a big shift in the overall cost.",
    "start": "191635",
    "end": "197275"
  },
  {
    "text": "The cost of these proprietary models implemented in the last year or so. But then smaller models got more",
    "start": "197524",
    "end": "203685"
  },
  {
    "text": "and more efficient and started to perform much much better. So we've seen this shift towards insanely",
    "start": "203685",
    "end": "209005"
  },
  {
    "text": "large models that can think a lot more. We saw us run out of all the public internet data and now we're focusing a lot",
    "start": "209005",
    "end": "215934"
  },
  {
    "text": "more on high quality enterprise data or stuff that's built for specific models.",
    "start": "215934",
    "end": "220894"
  },
  {
    "text": "So we're now getting to a point where you have a teacher model that's insanely large, really well thinking through the whole problem, that",
    "start": "221305",
    "end": "227844"
  },
  {
    "text": "can create synthetic data, can help Train a smaller model can distill a model that can",
    "start": "227845",
    "end": "233000"
  },
  {
    "text": "deliver high performance at a lower price point. So we've shifted this, shifted quite a bit in how we think about AI models and how",
    "start": "233010",
    "end": "239840"
  },
  {
    "text": "we have been investing in building them. 2025 and beyond is going to be a completely different ballgame in what",
    "start": "239840",
    "end": "245140"
  },
  {
    "text": "we see with what AI models would do. Marina, what are your thoughts? Yeah, I think you're right. It's been a really interesting year in terms",
    "start": "245140",
    "end": "252499"
  },
  {
    "text": "of where we started, where we've ended up. We've seen that, yes, we can go bigger and bigger and bigger.",
    "start": "252499",
    "end": "258219"
  },
  {
    "text": "And now we're finally there. We can say, great. So how well can we still keep going now that we can go so far? smaller. So that initial research push of how big can",
    "start": "258510",
    "end": "265755"
  },
  {
    "text": "we go, we've finally given ourselves the luxury of, all right, now it's time for efficiency. Now it's time for cutting costs.",
    "start": "265755",
    "end": "271634"
  },
  {
    "text": "Now it's maybe eventually time to talk about environmental aspects and things of that nature.",
    "start": "271654",
    "end": "276804"
  },
  {
    "text": "Maybe next year. Is that a prediction for 2025 or? 2025. Um, So that, that part is very interesting.",
    "start": "276804",
    "end": "283100"
  },
  {
    "text": "It also means that the quality has gotten to where we can start to, uh, build enterprise grade solutions reliably.",
    "start": "283100",
    "end": "289960"
  },
  {
    "text": "And I'm, I'm excited for that. I know we're not talking about next year yet, but that's the thing that I'm really excited for. The quality is there, I think finally.",
    "start": "290160",
    "end": "297110"
  },
  {
    "text": "And we, we can start getting real serious about enterprise solutions. Yeah, I mean, I think that seemed like a really big trend this year, you",
    "start": "297110",
    "end": "303233"
  },
  {
    "text": "know, was certainly someone who kind of like does software engineering in their free time, kind of as a hobby.",
    "start": "303234",
    "end": "308444"
  },
  {
    "text": "This is the year where I was like, wow, I am finally able to do stuff with these coding assistants that like I would not otherwise be able to do.",
    "start": "308714",
    "end": "314304"
  },
  {
    "text": "It's like finally fit for purpose for me to kind of use on a day to day basis. And I think that was, that was a very big.",
    "start": "314304",
    "end": "320155"
  },
  {
    "text": "jump, um, I think that, you know, we noticed in the last 12 months. I guess Marina, are there particular stories",
    "start": "320275",
    "end": "325724"
  },
  {
    "text": "that stand out to you from like, I don't know, earlier in the spring or otherwise where you're like, Oh, I'll, if when I look back on 2024, I'll really remember it for X.",
    "start": "325724",
    "end": "333673"
  },
  {
    "text": "I mean, first of all, I'll remember it for just the, uh, very, very high levels of competition.",
    "start": "333685",
    "end": "339815"
  },
  {
    "text": "It felt like every two weeks somebody was coming out with something and companies",
    "start": "339915",
    "end": "345604"
  },
  {
    "text": "that you maybe wouldn't even expect like even which is very recently Amazon being like, Oh, they're working on that. Oh, that's actually pretty good.",
    "start": "345604",
    "end": "351635"
  },
  {
    "text": "So I think I'll remember it for a lot of people trying to, uh, really one up each other, uh, in a, in a good way, in a way that",
    "start": "351945",
    "end": "359075"
  },
  {
    "text": "actually really pushes the thing forward. But I think that the number of players that we have this year is, uh, what's really going",
    "start": "359075",
    "end": "366474"
  },
  {
    "text": "to make it stand out for me and some of the. You know, as we talked about in previous episodes, some of the debuts were more",
    "start": "366474",
    "end": "373289"
  },
  {
    "text": "successful, some were less successful. Sometimes people didn't quite, you know, double check everything.",
    "start": "373289",
    "end": "378549"
  },
  {
    "text": "Maybe sometimes people thought that the demos were a little bit overcooked. Um, and so I, I think that that's, That's the",
    "start": "378589",
    "end": "384449"
  },
  {
    "text": "thing that'll make me really remember the year is the different ways of how do you join in the competition and introduce your, your flavor.",
    "start": "384450",
    "end": "390830"
  },
  {
    "text": "Shobit, how about you? I think from an enterprise perspective, uh, this is an amazing year. We, we recently ran a survey for our AI report",
    "start": "390860",
    "end": "397409"
  },
  {
    "text": "and about 15 percent of our clients globally got real tangible value by applying generative AI.",
    "start": "397420",
    "end": "402689"
  },
  {
    "text": "There's a lot of, uh, knowledge that was locked in documents and processes, things of that nature. And we saw meaningful movement and",
    "start": "402690",
    "end": "409449"
  },
  {
    "text": "how clients are focusing on it. a few small complex workflows and delivering exceptional value out of it.",
    "start": "409450",
    "end": "416090"
  },
  {
    "text": "I think we did not get enough value out of the generic co pilots or assistants.",
    "start": "416480",
    "end": "422000"
  },
  {
    "text": "That has shifted more towards, hey, this really has to be grounded in my data and my knowledge and things of that nature.",
    "start": "422550",
    "end": "427899"
  },
  {
    "text": "But overall, the last two weeks that we just went through, I think that was the most action we've ever seen in the last two weeks.",
    "start": "428300",
    "end": "434840"
  },
  {
    "text": "Two, three years of AI, what the competition between open AI and Google and then meta jumping",
    "start": "434960",
    "end": "440680"
  },
  {
    "text": "in that that has been a phenomenal, phenomenal movement in the community together and now we're",
    "start": "440680",
    "end": "445709"
  },
  {
    "text": "starting to see us move towards, hey, we have exceptional models, how do we start to then",
    "start": "445709",
    "end": "451759"
  },
  {
    "text": "control them a little bit more, adapt them to our enterprise workflows and our data sets and have them think and reason with tools and things",
    "start": "451760",
    "end": "458560"
  },
  {
    "text": "of that nature more the big movements around o1 I think it's going to go down in",
    "start": "458560",
    "end": "463590"
  },
  {
    "text": "history as a big, big point in time when we started to realize that 200",
    "start": "463599",
    "end": "469870"
  },
  {
    "text": "a month is actually great value. You start to get to a point where if you're thinking about how you, if you're",
    "start": "469870",
    "end": "476500"
  },
  {
    "text": "spending 200 bucks a month, you're really being very focused on which workflows truly",
    "start": "476500",
    "end": "482050"
  },
  {
    "text": "can see an uplift and apply AI to them. Now you're at a point where you're really paying somebody to do that. augment every aspect of your daily life.",
    "start": "482050",
    "end": "489324"
  },
  {
    "text": "I think we're great, great momentum to start 2025. Yeah, for sure. And I guess, I don't know if like folks have",
    "start": "489595",
    "end": "495745"
  },
  {
    "text": "nominees on superlatives for this, or it's like, is o1 the, the release of the year? I mean, I think from a model standpoint, or",
    "start": "495745",
    "end": "502384"
  },
  {
    "text": "were there other ones that kind of stand out? I mean, I guess we also had like, Mama 3 this year, right? It was also a huge, huge announcement.",
    "start": "502385",
    "end": "508275"
  },
  {
    "text": "For me, it's going to be Gemini, uh, uh, Flash. I think what they've just done with a small",
    "start": "508485",
    "end": "513490"
  },
  {
    "text": "model that does multimodal, that's going to drive the next two, three years of computing. And the reason I say that is",
    "start": "513510",
    "end": "518380"
  },
  {
    "text": "everything that you can now unlock. If you guys followed the Android XR announcements recently, you're now",
    "start": "518659",
    "end": "523780"
  },
  {
    "text": "at a point where multimodal models were inherently insanely large. They needed a lot of compute,",
    "start": "523780",
    "end": "529519"
  },
  {
    "text": "always happened on the servers. Now with models like Google Flash, you're getting to a point where a small model",
    "start": "529529",
    "end": "535800"
  },
  {
    "text": "can do multimodal really, really well. And the thing that will blow you away is how it starts to remember",
    "start": "536089",
    "end": "541420"
  },
  {
    "text": "things that you've just seen, right? I think it's going to start augmenting all parts of our, uh, of our day",
    "start": "541420",
    "end": "546709"
  },
  {
    "text": "to day workflows, including memory. That's something that we have not seen so far. Uh, we used to generally ask questions in a very cold start.",
    "start": "546709",
    "end": "552979"
  },
  {
    "text": "Now we'll get to a point where these models will have infinite memory, can have access tools like we do.",
    "start": "553240",
    "end": "558140"
  },
  {
    "text": "I'm very excited about high performance at a really small, uh, size. So we can then eventually get to this, Compute",
    "start": "558410",
    "end": "565775"
  },
  {
    "text": "infrastructure where you can have XR AR experiences and you can bring compute more and",
    "start": "565825",
    "end": "571345"
  },
  {
    "text": "more closer to the devices that will drive a lot more of privacy as well because then the data is locked into those devices that I'm",
    "start": "571345",
    "end": "577944"
  },
  {
    "text": "carrying with me versus somebody else's cloud. Yeah, I want to agree with that. Actually, the, the small model, the small models",
    "start": "577944",
    "end": "584175"
  },
  {
    "text": "thing, because I think that we're going to start at least in the next year or two, seeing a lot more, uh, formal regulation going on and",
    "start": "584175",
    "end": "591675"
  },
  {
    "text": "a lot more people waking up to what does it really mean as you're talking Shobit, but if the models are starting to remember, starting to be",
    "start": "591675",
    "end": "596935"
  },
  {
    "text": "personalized, starting to be customized, that's going to become extremely, extremely relevant. So having something small, local that you can",
    "start": "596935",
    "end": "603140"
  },
  {
    "text": "actually have that guarantee technologically. That's going to become very, very important. I agree with you.",
    "start": "603140",
    "end": "608340"
  },
  {
    "text": "Yeah, for sure. And how about you, Marina, I think in terms of like, you know, I know Shobhit was saying, oh, one was huge.",
    "start": "608430",
    "end": "613769"
  },
  {
    "text": "Like if you have like a, you know, best model of the year kind of nomination. That's a hard one. I, I like seeing them in a holistic way.",
    "start": "613800",
    "end": "621189"
  },
  {
    "text": "And I feel like it's hard to tell at the moment when something is actually going to, uh, you",
    "start": "621189",
    "end": "627070"
  },
  {
    "text": "know, turn, turn in, I'm going to nominate a. sequence, I think, which is the sequence of the Llama models, not the Llama models itself,",
    "start": "627070",
    "end": "633925"
  },
  {
    "text": "but the sequence of we're going to have Llama 3 and then we're, so we've seen what we can do with pre training and then we're going",
    "start": "634204",
    "end": "639613"
  },
  {
    "text": "to see what we can do with post training. So we're going to get bigger, bigger, bigger, bigger, and then we're going to see how far down we can go. I'd like to see a consistent perspective",
    "start": "639614",
    "end": "646855"
  },
  {
    "text": "of that as a sequence that people try of push the pre training, push the post training, push the size and do that",
    "start": "646895",
    "end": "654550"
  },
  {
    "text": "iteratively, iteratively, iteratively. I'd like to see that continue to be a thing. Yeah, I feel like that's like how we know",
    "start": "654560",
    "end": "660010"
  },
  {
    "text": "you're a connoisseur, Marina, is like, you like, you, you like the curation of Llama. It's not just like any given",
    "start": "660010",
    "end": "665729"
  },
  {
    "text": "model is the best model. Marina, I think we'll get to a point where the big research labs are going",
    "start": "665730",
    "end": "671590"
  },
  {
    "text": "to build even bigger, bigger models. But they may not release them in the public as a model.",
    "start": "671590",
    "end": "676660"
  },
  {
    "text": "And we use that more for creating synthetic data, for displaying teaching as a teacher model, and so forth.",
    "start": "677140",
    "end": "681990"
  },
  {
    "text": "But I'm really excited about, we're finally coming to a point where we've poked at this for a while, and we said, oh, if I just ask this",
    "start": "682340",
    "end": "690010"
  },
  {
    "text": "model to think before it answers, Well, this is what elementary school teacher kids, right?",
    "start": "690010",
    "end": "695445"
  },
  {
    "text": "And now we're trying to relearn how we teach young kids on how do they look at the like, try different things out, create",
    "start": "695635",
    "end": "701845"
  },
  {
    "text": "a plan, answer the question, go pick up a calculator if you really need to. And don't try to do this in your head, things of that nature.",
    "start": "701845",
    "end": "707924"
  },
  {
    "text": "Like I, I feel that we are, I have little kids and I've spoken about that quite a bit and I feel that we are, we are, there's so many similarities between",
    "start": "708780",
    "end": "715069"
  },
  {
    "text": "how we are training and we're doing some reinforcement learning with our kids and giving them rewards and mechanisms in place.",
    "start": "715070",
    "end": "721288"
  },
  {
    "text": "We are breaking problems into smaller chunks and they go solve each one of them separately and there's a whole positive reinforcement",
    "start": "721580",
    "end": "727839"
  },
  {
    "text": "around them and they get things right. I think we're getting to a point where we're getting to learn how these models learn and",
    "start": "727840",
    "end": "734010"
  },
  {
    "text": "that becomes a good symbiotic relationship. I think we will stop. Asking these models to do things that humans do really well, and we'll have a",
    "start": "734010",
    "end": "740769"
  },
  {
    "text": "better mutual appreciation of which things should be delegated down to these models. And that also means that benchmarks",
    "start": "740770",
    "end": "747310"
  },
  {
    "text": "and how we evaluate these models are going to change quite a bit. But I think today we're starting to get to know these models really well.",
    "start": "747310",
    "end": "752549"
  },
  {
    "text": "And 2025 and six will have a very different relationship with these models, becoming more of a companion.",
    "start": "752830",
    "end": "758170"
  },
  {
    "text": "Versus trying to figure out, hey, can you do this as well as I do? Yeah, absolutely. Yeah, I think one of the funniest outcomes",
    "start": "758490",
    "end": "763850"
  },
  {
    "text": "of this year has been all the examples of, like, could you just try harder? And then, like, the model actually just does better, which is, like, very funny.",
    "start": "763850",
    "end": "770310"
  },
  {
    "text": "I mean, computers did not used to do that. So, um, so I think maybe a final question, and then we can wrap up this segment, um,",
    "start": "770590",
    "end": "777910"
  },
  {
    "text": "is we haven't talked so much about, Uh, multimodality, but it really seems poised to become a really big deal in 2025.",
    "start": "777980",
    "end": "784750"
  },
  {
    "text": "I'm curious, I guess maybe Marina, I'll start with you, if, if you've got kind of predictions for what's coming up in the next year for, for multimodal.",
    "start": "785170",
    "end": "791840"
  },
  {
    "text": "Yeah, multimodal, uh, that's something where we had those thoughts when foundation model sort of first came on, cause we",
    "start": "791959",
    "end": "797820"
  },
  {
    "text": "were all very excited about the fact of, oh, well, it's just tokens in order. It doesn't have to be text. It can be anything, but then I think the",
    "start": "797820",
    "end": "804930"
  },
  {
    "text": "reason we all went into text as one of the very early code being part of it, I think, is the amount of training data that we",
    "start": "804930",
    "end": "811285"
  },
  {
    "text": "had, the amount of examples that we had. So especially now that we've gotten better with synthetic data and with, like you",
    "start": "811285",
    "end": "816745"
  },
  {
    "text": "said, Shobhit, but you were referring to teacher models, we're going to be able to explore that space, uh, a lot more.",
    "start": "816745",
    "end": "821975"
  },
  {
    "text": "And so I, I think that they might finally, uh, be at the point where once again, they are useful. There's huge interest in, uh, having the",
    "start": "822505",
    "end": "829014"
  },
  {
    "text": "multimodal models because now, you know how with the text models, we had the idea that when you have one doing lots",
    "start": "829015",
    "end": "835875"
  },
  {
    "text": "of tasks, it learns from each other. Now it's going to be even more interesting where if you have a multimodal model, does that make it actually also better",
    "start": "835875",
    "end": "841870"
  },
  {
    "text": "at each of the individual modalities? Again, I think the data is now finally there, not just the compute, but the data and the ability to create more data.",
    "start": "842100",
    "end": "849589"
  },
  {
    "text": "Um, and so I think that, yeah, next year we should see more. I think I was expecting to see",
    "start": "849910",
    "end": "855619"
  },
  {
    "text": "maybe a little bit more models that aimed at the sciences this year. Maybe now again, next year, uh, maybe",
    "start": "855619",
    "end": "861820"
  },
  {
    "text": "models that are going to be more successful with video, not just Sora, Sora. But something that is maybe a",
    "start": "861820",
    "end": "867495"
  },
  {
    "text": "little bit more useful lower down, think like, uh, with robotics. There's a lot of, uh, things to be minded there.",
    "start": "867495",
    "end": "873415"
  },
  {
    "text": "So that's, I guess where I, I see those maybe, yeah, the flashy parts are fun, but the real usefulness is somewhere a little",
    "start": "873425",
    "end": "879764"
  },
  {
    "text": "bit lower down with, um, with the hardware. No, I think the multimodal space is going to be amazing the next couple of years.",
    "start": "879765",
    "end": "886555"
  },
  {
    "text": "And I think it is important for it to understand all aspects of what humans are seeing, feeling, looking at, reading, and",
    "start": "886895",
    "end": "893384"
  },
  {
    "text": "listening before it comes and helps us. Um, I think it's going to have a huge impact on its understanding of the world around us.",
    "start": "893444",
    "end": "900010"
  },
  {
    "text": "So far, we have done things where, hey, I will take a picture of something or I'll translate that into text and ask a question of a chatbot.",
    "start": "900430",
    "end": "906688"
  },
  {
    "text": "That paradigm has not scaled. As the, as the multi modal models get better and smaller.",
    "start": "906980",
    "end": "913160"
  },
  {
    "text": "Like the Gemini 2. 0 Flash Experimental, those are the ones that are going to drive more and more",
    "start": "913585",
    "end": "918754"
  },
  {
    "text": "richer experiences in our day to day lives. And the competition is going to be very, very high. You will see these models come out from any, from everywhere.",
    "start": "918805",
    "end": "924824"
  },
  {
    "text": "Uh, the Any2Any, from speech to speech directly, those kind of models are delivering exceptional customer experiences.",
    "start": "925305",
    "end": "932084"
  },
  {
    "text": "If you go for, if you look at traditional ways of doing AI, you would go speech, To text. You take that text, you",
    "start": "932504",
    "end": "938045"
  },
  {
    "text": "pass it to a, to a AI model. AI model figures out what to respond with, and you go back from text to speech. A lot is lost in translation and transcription.",
    "start": "938045",
    "end": "945125"
  },
  {
    "text": "Now, when you start doing, um, from media to media, you go from voice to voice. It starts to understand the",
    "start": "945575",
    "end": "951274"
  },
  {
    "text": "nuances of how humans talk. I'll, I'm very excited about the next year of multimodal. Small and then starting the full context.",
    "start": "951275",
    "end": "957175"
  },
  {
    "text": "That's awesome. And that's all the time we have for today to talk about AI models showbirth marina Thanks for coming on.",
    "start": "957245",
    "end": "962265"
  },
  {
    "text": "Happy holidays, and we'll talk next year about all this and more",
    "start": "962305",
    "end": "964995"
  },
  {
    "text": "For our next segment I want to talk about agents in 2024 and to help me do that I'm gonna bring in Chris Hay distinguished engineer CTO customer",
    "start": "969985",
    "end": "976845"
  },
  {
    "text": "transformation and Maya Murad who is the product manager for AI incubation Maya, Chris, welcome back to the show Well, so in 2024, uh, it was",
    "start": "976845",
    "end": "984930"
  },
  {
    "text": "the year of the agents, agents, agents, agents. I think it almost became a little bit of an in joke at MoE that if we had an episode",
    "start": "984939",
    "end": "990639"
  },
  {
    "text": "that did not include agents, uh, that was a really big thing and an unusual thing. Um, and so I guess probably",
    "start": "990659",
    "end": "997610"
  },
  {
    "text": "let's put it this way. And I guess maybe Chris, we'll, we'll throw it to you first is, um, Agents",
    "start": "997660",
    "end": "1002620"
  },
  {
    "text": "over hyped in 2024 or under hyped in 2024 under hyped, not hyped enough. Agents are the world agents are everything, and",
    "start": "1002710",
    "end": "1010300"
  },
  {
    "text": "in 2025, wow, we're gonna have super agents. That's what's coming in 25. Okay, um, and I guess Maya, I mean, looking",
    "start": "1010300",
    "end": "1018199"
  },
  {
    "text": "back, um, I don't know if you'd agree with Chris or if there's like particular stories in 2024 that really stood out to you in",
    "start": "1018199",
    "end": "1024519"
  },
  {
    "text": "the development of agents, if they're going to be as big as Chris says for 2025. So I definitely agree 2024, I would say",
    "start": "1024519",
    "end": "1031349"
  },
  {
    "text": "it was a lot of talking about AI agents. Um, I'm excited to see more execution and what I expect to see is more quality.",
    "start": "1031349",
    "end": "1037904"
  },
  {
    "text": "Hurdles. Once we see more agents being pushed into production. I think we're just scratching",
    "start": "1037944",
    "end": "1043475"
  },
  {
    "text": "the surface of what is needed. A trend that I'm starting to see right now this year is having more",
    "start": "1043475",
    "end": "1049315"
  },
  {
    "text": "protocols and standardization efforts. So we saw that Meta is attempting to",
    "start": "1049615",
    "end": "1055180"
  },
  {
    "text": "do that with the Llama stack, Anthropic with their model context protocol, MCP.",
    "start": "1055180",
    "end": "1061080"
  },
  {
    "text": "Um, so I think it's going to be this little battle for how do we standardize how LLMs",
    "start": "1061500",
    "end": "1066749"
  },
  {
    "text": "interact with the external world, how agents, I think in the future it's going to be how agents interact with each other.",
    "start": "1066779",
    "end": "1072049"
  },
  {
    "text": "Um, and I think this is where the next frontier is and where a lot of our efforts I was going to be heading towards.",
    "start": "1072520",
    "end": "1079020"
  },
  {
    "text": "Yeah, this felt like a big, like, almost like a preparation year. I was looking at all the news stories and I was like, is the biggest agent story",
    "start": "1079220",
    "end": "1085529"
  },
  {
    "text": "of the year that Salesforce is hiring a lot of sales agents to sell agents? Like, it feels like, and then between",
    "start": "1085529",
    "end": "1090890"
  },
  {
    "text": "that and the technical standards, it's almost kind of like, it's almost far and few between to be like, oh yeah, this was the killer agent release of the year.",
    "start": "1090890",
    "end": "1098380"
  },
  {
    "text": "Um, and actually, in fact, a lot more prep. I don't know if Maya, you'd agree with that. It felt like it was the year of bracing",
    "start": "1098735",
    "end": "1103975"
  },
  {
    "text": "for what's to come and all the different things we needed to consider and then who wanted to own that category.",
    "start": "1103975",
    "end": "1109585"
  },
  {
    "text": "So it was really interesting that for example, Meta went out early and with, so",
    "start": "1109585",
    "end": "1114865"
  },
  {
    "text": "the first iteration of Llama Stack was. a little bit rough, but what they were trying to do with their saying, we're in the",
    "start": "1114865",
    "end": "1121475"
  },
  {
    "text": "long term, we're in this in the long term. And we want to help define those agent intercommunication protocols.",
    "start": "1121475",
    "end": "1127724"
  },
  {
    "text": "And I have faith if, if that's a direction that Meta wants to take, I'm sure they're going to do a good job at it. But this is also signaling",
    "start": "1128075",
    "end": "1133934"
  },
  {
    "text": "something interesting. Um, the last two years, it's, um, Mainly the field reacting to what open AI put out so open.",
    "start": "1133934",
    "end": "1141245"
  },
  {
    "text": "I put out their chat completions API and the whole ecosystem followed suit. And if you didn't have that exact API, your",
    "start": "1141375",
    "end": "1149324"
  },
  {
    "text": "thing was much more difficult to consume. And now we're seeing a lot more players contend to.",
    "start": "1149325",
    "end": "1154735"
  },
  {
    "text": "Uh, being the one setting those standards and protocols. Yeah, for sure. And maybe, I guess, Chris, to turn it",
    "start": "1155105",
    "end": "1160165"
  },
  {
    "text": "back to you, I mean, you're, I think you just used the phrase, agents are the world, which is a very bold claim.",
    "start": "1160175",
    "end": "1165265"
  },
  {
    "text": "But, I mean, 2025, I mean, you know, let's say agents are a lot more popular, become a",
    "start": "1165275",
    "end": "1170705"
  },
  {
    "text": "lot more prominent as a part of the landscape. You know, is it meta that's well positioned to win here or do you, do you have any",
    "start": "1170705",
    "end": "1176700"
  },
  {
    "text": "predictions about what we're going to see in terms of who's going to be leading in the space versus maybe a little bit further behind?",
    "start": "1176700",
    "end": "1181710"
  },
  {
    "text": "So I really like what Maya had to say on Anthropic and the model context protocol. I actually think that is going to be one of",
    "start": "1181800",
    "end": "1189029"
  },
  {
    "text": "the biggest enablers for agents next year. And I think the problem that they've solved really well is allowing remote calling of tools.",
    "start": "1189029",
    "end": "1197260"
  },
  {
    "text": "That's probably the biggest thing that they've solved there, right? So yeah. If we think about the enterprise for a second,",
    "start": "1197260",
    "end": "1202875"
  },
  {
    "text": "you're not going to have agents that are sitting scouring the web, or they're going to be, uh, sitting downloading documents, whatever.",
    "start": "1203155",
    "end": "1209625"
  },
  {
    "text": "It's going to be access to your enterprise tools. It's going to be things like accessing Slack, it's going to be accessing your, uh, Dropbox, or",
    "start": "1209865",
    "end": "1217384"
  },
  {
    "text": "your box folders, or whatever, or your GitHub. And a lot of that is being standardized. But more importantly, you want to take your own",
    "start": "1217385",
    "end": "1223185"
  },
  {
    "text": "data, and then expose your own APIs, and expose that in a way that agents can consume data.",
    "start": "1223185",
    "end": "1228195"
  },
  {
    "text": "In a standardized way. And I think MCP has done a really good job of allowing you to remote",
    "start": "1228210",
    "end": "1233549"
  },
  {
    "text": "call tools and then be able to chain them together with multiple servers. And I think that's going to be a big enabler.",
    "start": "1233570",
    "end": "1239039"
  },
  {
    "text": "Now what's interesting and what they've done there is it is easy to hook up different LLMs, for example.",
    "start": "1239040",
    "end": "1246028"
  },
  {
    "text": "So it's not tied to the cloud stack there. You can hook up any other model that you want.",
    "start": "1246030",
    "end": "1251749"
  },
  {
    "text": "And. It's all tied in to function calling, which again, was a standard that was created by OpenAI in that sense.",
    "start": "1252079",
    "end": "1258794"
  },
  {
    "text": "So, I like what you said there, Maya, about, you know, different providers coming in, and coming in an ecosystem.",
    "start": "1258795",
    "end": "1265164"
  },
  {
    "text": "And I think that's what I'd like to see happen is no one company winning. And this is ecosystem of providers is going",
    "start": "1265165",
    "end": "1271995"
  },
  {
    "text": "to push everything forward, and we're going to enter this world of the big agent marketplace.",
    "start": "1271995",
    "end": "1277325"
  },
  {
    "text": "And that's why I say super agents are coming, because it's going to be this really big ecosystem that's",
    "start": "1277325",
    "end": "1282515"
  },
  {
    "text": "going to start to emerge in 2025. And when you say super agent, what do you mean exactly? I just made up the term Tim, so.",
    "start": "1282515",
    "end": "1288795"
  },
  {
    "text": "You heard it here first on MoE. A really good agent. That's a super",
    "start": "1289165",
    "end": "1294375"
  },
  {
    "text": "coming from super intelligence or is this your definition or is it in the sense of like a Hollywood super agent?",
    "start": "1294715",
    "end": "1299845"
  },
  {
    "text": "Actually, I, thanks for the save there, Maya, right? I'm going to define a super agent as",
    "start": "1299915",
    "end": "1305445"
  },
  {
    "text": "the combination of the reasoning models. The inference time compute models are coming out just now combined with tool access.",
    "start": "1305445",
    "end": "1313134"
  },
  {
    "text": "So therefore they're more powerful than the agents that you have today. So there you heard it first. You're right, Tim.",
    "start": "1313334",
    "end": "1318224"
  },
  {
    "text": "That's what a super agent is. Very nice. Uh, Maya, you had a funny phrase when you",
    "start": "1318504",
    "end": "1323585"
  },
  {
    "text": "were kind of giving your reaction to my first question, which is, you know, next year's agents are going to be everywhere, but it's also going",
    "start": "1323585",
    "end": "1329715"
  },
  {
    "text": "to be the year we're going to discover, like, where the, the barriers or the limitations are, you know, basically this kind of the full force",
    "start": "1329715",
    "end": "1336085"
  },
  {
    "text": "of agents going to become crashing onto reality. And I think we're going to learn a lot. And, you know, I guess one question I've",
    "start": "1336085",
    "end": "1341164"
  },
  {
    "text": "been asking a lot of the panelists for this. This episode is, you know, what's underrated? What are people not thinking about that",
    "start": "1341165",
    "end": "1346395"
  },
  {
    "text": "are, that's likely to be like a big hurdle, right, for agents going forwards? Number one answer, security.",
    "start": "1346395",
    "end": "1352115"
  },
  {
    "text": "Super underrated. I think it's already being reported that a lot of the existing players in",
    "start": "1352205",
    "end": "1357434"
  },
  {
    "text": "the space are leaking sensitive data. And I, I, see agents as a way of",
    "start": "1357435",
    "end": "1363670"
  },
  {
    "text": "exacerbating these inherent risks of LLMs. And I think we're under appreciating",
    "start": "1363670",
    "end": "1369080"
  },
  {
    "text": "what it takes to get it right. I think the other thing is how to nail the right human interactions.",
    "start": "1369099",
    "end": "1374479"
  },
  {
    "text": "When you have this ability to automate more complex tasks. What are the things that you still need to delegate to the human?",
    "start": "1374670",
    "end": "1381130"
  },
  {
    "text": "How do you need to have a human in the loop? How do you avoid an overtrust issue? My team has done a number of user",
    "start": "1381140",
    "end": "1387610"
  },
  {
    "text": "studies and when information is presented neatly by an actor that looks and seems",
    "start": "1387610",
    "end": "1392920"
  },
  {
    "text": "intelligent, it's really easy to take everything surface level for granted. And I think there's a whole new paradigm of",
    "start": "1392920",
    "end": "1398970"
  },
  {
    "text": "human computer interaction or maybe human agent interaction that will be unlocked. And I'm, I'm really excited for",
    "start": "1399240",
    "end": "1404650"
  },
  {
    "text": "what's to come because I think this is inherently a creative exercise. How do we keep, retain our creativity, retain",
    "start": "1404650",
    "end": "1411500"
  },
  {
    "text": "our ability to do critical thinking, and yet automate certain parts of processes to AI?",
    "start": "1411500",
    "end": "1417329"
  },
  {
    "text": "Um, that will be a really interesting paradigm to get right. Yeah, I think that delegation problem is going to end up being super, super hard.",
    "start": "1417330",
    "end": "1424100"
  },
  {
    "text": "Uh, I think, uh, yeah, it's very easy to be dependent on, Even people who sound smart when they're not actually.",
    "start": "1424170",
    "end": "1430295"
  },
  {
    "text": "It's like no different, I guess, for, for agents, uh, as well. Um, well, I guess put it this way is, you",
    "start": "1430985",
    "end": "1437375"
  },
  {
    "text": "know, it sounds like we're very interested. And I guess the big prediction from both the two of you seems to be, you know, agent marketplaces.",
    "start": "1437375",
    "end": "1443445"
  },
  {
    "text": "Right.\nThat's going to be maybe like the big thing we're going to see, um, next year. You know, I think one of the big questions",
    "start": "1443515",
    "end": "1449455"
  },
  {
    "text": "is also kind of like what's going to be the first most popular agent use case in some ways. Um, you know, you think",
    "start": "1449455",
    "end": "1455414"
  },
  {
    "text": "about the big marketplace. There's a lot of things that agents could do that may be fun to do, but, you know, I think we're almost kind of looking like",
    "start": "1455425",
    "end": "1461214"
  },
  {
    "text": "what's going going to be the, what's going to be the email of the agent world, right? Like what's going to be the slack of the agent world.",
    "start": "1461224",
    "end": "1466870"
  },
  {
    "text": "Um, curious in both of your experiences, you know, talking to customers and stuff with their particular things, like in their hopes and dreams that",
    "start": "1467300",
    "end": "1473040"
  },
  {
    "text": "they really want to see out of agents. And if there's kind of anything recurring there, that's worth it for our listeners to know. I think from my perspective, Tim, and that",
    "start": "1473040",
    "end": "1480049"
  },
  {
    "text": "marketplace, I think there is some obvious ones. Like, Translation, I think, if I'm truly honest,",
    "start": "1480050",
    "end": "1485355"
  },
  {
    "text": "like language models today, I don't think they've really nailed translation so well. There's some models that do certain",
    "start": "1485355",
    "end": "1491385"
  },
  {
    "text": "languages really well, but then, um, if you think of the more esoteric languages, for example, um, the less popular ones, then",
    "start": "1491385",
    "end": "1498714"
  },
  {
    "text": "the, the large models aren't getting that. And then it's going to be specialized models that have been trained in that specific language.",
    "start": "1498804",
    "end": "1505404"
  },
  {
    "text": "So, um, I think that's probably a real opportunity for some of these smaller language models combined with an",
    "start": "1505534",
    "end": "1511270"
  },
  {
    "text": "agent to offer translation services. And again, add that into domain services. So things like legal, which is",
    "start": "1511270",
    "end": "1516819"
  },
  {
    "text": "something you know very well, Tim, then I think that will probably be a big. piece of that marketplace, but I'm hoping that",
    "start": "1516830",
    "end": "1524820"
  },
  {
    "text": "it won't just be about these individual agents. I think any piece of information, it could be sports scores, it could be golf",
    "start": "1524820",
    "end": "1532050"
  },
  {
    "text": "scores, it could be information about play, it could be absolutely anything. And one of the things, and this is my",
    "start": "1532060",
    "end": "1537579"
  },
  {
    "text": "next prediction for 2025, is I think we're going to get a shift in the world wide web.",
    "start": "1537580",
    "end": "1543040"
  },
  {
    "text": "So today, HTML, et cetera, is the dominant. Uh, language, markup language of the internet.",
    "start": "1543040",
    "end": "1549350"
  },
  {
    "text": "That's not really well designed for LLMs and not well designed for agents.",
    "start": "1549629",
    "end": "1555149"
  },
  {
    "text": "So I wonder if in order for the agents to exist, not just having the marketplaces,",
    "start": "1555159",
    "end": "1560679"
  },
  {
    "text": "but having the way to expose that data, we talked about MCP earlier, I wonder if you're going to start to see new types of.",
    "start": "1560970",
    "end": "1568180"
  },
  {
    "text": "Page is appearing where the content is optimized towards the agents for consumption by agents and resources that",
    "start": "1568804",
    "end": "1576034"
  },
  {
    "text": "they expose as opposed to necessarily human. So I'm, I'm kind of predicting we're",
    "start": "1576034",
    "end": "1581164"
  },
  {
    "text": "going to start to see this shift in the web to a kind of, uh, dare I say a web 4.0, I'm trying to avoid the term web 3. 0 where we have content that is",
    "start": "1581164",
    "end": "1592582"
  },
  {
    "text": "specifically designed for agent consumption. Yeah, it seems to be almost the prediction that's kind of implicit in what both of",
    "start": "1592624",
    "end": "1598024"
  },
  {
    "text": "you are saying is that you know there'll be so much interest in the promise of agents that like almost we're going to be kind",
    "start": "1598024",
    "end": "1603415"
  },
  {
    "text": "of reconstructing the web to make it safe for agents or make it work for agents. And I guess a lot of the kind of stack",
    "start": "1603415",
    "end": "1609965"
  },
  {
    "text": "and a lot of the kind of interoperability stuff that's being built is like an attempt to do that in some ways.",
    "start": "1609965",
    "end": "1615273"
  },
  {
    "text": "Um, I don't know, Maya,, do you agree with that? You think that's kind of like going to be the future is like we'll have a, you know, agent markup language basically.",
    "start": "1615675",
    "end": "1622264"
  },
  {
    "text": "Uh, A.T.M.L. I think a lot of the interesting use cases will be unlocked when different agents",
    "start": "1622330",
    "end": "1627909"
  },
  {
    "text": "that were built by different providers that are owned by different organizations are able to interact with each other.",
    "start": "1627940",
    "end": "1633990"
  },
  {
    "text": "And like, how do you establish a safety protocol? How are you able to do that productively? Like the promise here is like, how do we",
    "start": "1633990",
    "end": "1640488"
  },
  {
    "text": "break out of all these silos of different systems and having to manually architect how each one speaks to each other?",
    "start": "1640489",
    "end": "1647090"
  },
  {
    "text": "And can we get to, uh, Universal interaction protocol. This is really an interesting promise.",
    "start": "1647110",
    "end": "1653219"
  },
  {
    "text": "I don't know if we will fully unlock it next year, but a lot of different actors would like to go into this direction.",
    "start": "1653239",
    "end": "1658749"
  },
  {
    "text": "And there's simple things that we should nail before that. So I know like software engineering tasks are there's a lot of investment going that space.",
    "start": "1659009",
    "end": "1665859"
  },
  {
    "text": "I still think no one has nailed like the average business user, the average business user has to use, I don't know, a dozen of different",
    "start": "1666304",
    "end": "1672895"
  },
  {
    "text": "tools on their computer and their machine. None of them speaks with the other. Everyone has its own onboarding experience.",
    "start": "1672955",
    "end": "1679215"
  },
  {
    "text": "So I see a lot of opportunity to flatten out these complex experiences and make them much more dynamic and integrated.",
    "start": "1679675",
    "end": "1685735"
  },
  {
    "text": "And this is the true promise of this technology. And it's the ultimate dream, I guess. I mean. Because the world you're describing is",
    "start": "1685794",
    "end": "1691105"
  },
  {
    "text": "almost like the agent becomes your entire interface for all these applications, like they stay independent, but like, yeah, the",
    "start": "1691105",
    "end": "1698164"
  },
  {
    "text": "operating system in the future really is the agent that's doing things on your behalf. It's natural language. I was like.",
    "start": "1698164",
    "end": "1702764"
  },
  {
    "text": "LLMs changed our perception of how we interact with the digital world. We expect everything to be in natural language,",
    "start": "1703360",
    "end": "1709810"
  },
  {
    "text": "or you could do a form and then there's an option to do natural language interaction.",
    "start": "1709830",
    "end": "1714600"
  },
  {
    "text": "And I think that expectation is gonna widen. Yeah, no, I think that makes a ton of sense.",
    "start": "1714950",
    "end": "1720209"
  },
  {
    "text": "I guess maybe the final turn that we should talk a little bit about is like on the engineering and coding side, right?",
    "start": "1720279",
    "end": "1725269"
  },
  {
    "text": "I was thinking this year that like, The coding assistance has gotten really, really good.",
    "start": "1725779",
    "end": "1730490"
  },
  {
    "text": "But the dream is that you eventually have agents that are like, I'm really envisioning a software code base that looks like this.",
    "start": "1730830",
    "end": "1736759"
  },
  {
    "text": "And it's able to kind of like build and interoperate on all parts of that, and all parts of your code base.",
    "start": "1737060",
    "end": "1741888"
  },
  {
    "text": "What do we think are the prospects for that kind of automation and agentic behavior? I'm going to kick off here, and I'm",
    "start": "1742730",
    "end": "1749730"
  },
  {
    "text": "going to be controversial as always. And here is something for people to think about, which is Programming languages",
    "start": "1749730",
    "end": "1757570"
  },
  {
    "text": "today are designed for human beings, right? And if you think about things like loops, while loops, for loops, etc.",
    "start": "1757570",
    "end": "1764060"
  },
  {
    "text": "There you have however many versions and the same with conditionals, if statements, blah, blah, blah.",
    "start": "1764490",
    "end": "1769640"
  },
  {
    "text": "But you know what? When you get down to an assembly level, none of that exists, right? It's all back to branches and, you",
    "start": "1769900",
    "end": "1778049"
  },
  {
    "text": "know, uh, and jump statements, etc. And therefore We are in an agentic",
    "start": "1778050",
    "end": "1784110"
  },
  {
    "text": "world, we're getting them to program in a language that is designed for humans.",
    "start": "1784120",
    "end": "1789110"
  },
  {
    "text": "And the big challenge, I would say, that I think is going to happen over the next few years is that you're going",
    "start": "1789410",
    "end": "1794540"
  },
  {
    "text": "to have a more agentic native language. Something that is more designed for LLMs and therefore a less of a syntactic sugar",
    "start": "1794540",
    "end": "1801919"
  },
  {
    "text": "that you need to satisfy humans there. So, I think there's going to be an evolution in programming coming.",
    "start": "1801920",
    "end": "1807530"
  },
  {
    "text": "Um, And, and you can see it already today, right? The LLMs are already generating, uh, you",
    "start": "1807560",
    "end": "1814155"
  },
  {
    "text": "know, here's another Fibonacci function. I don't, I don't need another Fibonacci function in my life, right? We got those.",
    "start": "1814155",
    "end": "1819445"
  },
  {
    "text": "Exactly. So I then think you'll be like the equivalent of kind of NPM or something like that, where",
    "start": "1820335",
    "end": "1826754"
  },
  {
    "text": "you have a big massive AI library where you can pull the functions that you need. So I think. Like your AI operating system, I think we're",
    "start": "1826755",
    "end": "1834145"
  },
  {
    "text": "going to get an AI programming languages and libraries that are going to be a little bit more native, and then that's going to help the development of coding.",
    "start": "1834145",
    "end": "1840744"
  },
  {
    "text": "So I think that's an interesting term. Will it be 2025? Maybe, maybe it's going to be 26, but I think that's where we're going.",
    "start": "1840744",
    "end": "1846304"
  },
  {
    "text": "With the current technology we have, I'm like super impressed with what I've seen with Repl. it, with the ability to stand",
    "start": "1846334",
    "end": "1851970"
  },
  {
    "text": "up like full stack applications. On the project I'm working on with Bee, it's been such an interesting paradigm",
    "start": "1851970",
    "end": "1857260"
  },
  {
    "text": "like chat to build applications. Um, I, I really see the ability to create digital interfaces and code",
    "start": "1857260",
    "end": "1863949"
  },
  {
    "text": "bases being democratized in a way that hasn't been able to for before. Purely powered by the current",
    "start": "1863950",
    "end": "1870200"
  },
  {
    "text": "technology of agents that we have. I just think there's this like last mile problem to nail, and I think next year",
    "start": "1870210",
    "end": "1875870"
  },
  {
    "text": "this is going to blow up in a major way. Nice. Well, you heard it here first. That's all the time that we have for agents.",
    "start": "1875870",
    "end": "1881130"
  },
  {
    "text": "Uh, that was a lot to cover in a short period of time. Chris, Maya, thanks for coming on the show and we'll see you next year.",
    "start": "1881160",
    "end": "1886410"
  },
  {
    "text": "I want to move us on to talk about the hardware that powered AI in 2024 and I can't",
    "start": "1891490",
    "end": "1897090"
  },
  {
    "text": "have picked a better duo of people to help out in terms of explaining those, uh, than the two that I have online with me today.",
    "start": "1897140",
    "end": "1903740"
  },
  {
    "text": "Khaoutar El Maghraoui is a Principal Research Scientist, AI Engineering, AI Hardware Center, and Volkmar Uhlig is Vice",
    "start": "1904200",
    "end": "1910309"
  },
  {
    "text": "President, AI Infrastructure Portfolio Lead. Welcome to the show. Volkmar, maybe I'll turn to you first. So, you know, as we talk about hardware",
    "start": "1910310",
    "end": "1916990"
  },
  {
    "text": "on AI, it's almost become synonymous with saying that we want to talk about NVIDIA. Um, and, uh, I'm curious about what you thought",
    "start": "1916990",
    "end": "1923440"
  },
  {
    "text": "the biggest stories were this year from NVIDIA. I mean, the one that strikes me is the announcement of the upcoming GB200.",
    "start": "1923460",
    "end": "1929790"
  },
  {
    "text": "Uh, but curious if there's other things on radar for you as we kind of think about, you know, what were the big stories in 2024?",
    "start": "1930129",
    "end": "1936160"
  },
  {
    "text": "NVIDIA. Made a big splash for the GB200. Um, and I think we are seeing a big",
    "start": "1936320",
    "end": "1943210"
  },
  {
    "text": "shift towards more integrated systems and protocol on the training side. Very large, like rack scale computers now.",
    "start": "1943210",
    "end": "1950230"
  },
  {
    "text": "Um, liquid cooling is coming. So all the things we've, seen over the years how to get cramped more compute into",
    "start": "1950600",
    "end": "1959600"
  },
  {
    "text": "smaller form factor, you know, making it faster, better networks behind it, etc.",
    "start": "1959600",
    "end": "1965080"
  },
  {
    "text": "And I think NVIDIA is really trying to push hard on staying the leader.",
    "start": "1965400",
    "end": "1970269"
  },
  {
    "text": "Um, on, and then we are seeing upgrades, which are kind of a reflection of",
    "start": "1970999",
    "end": "1976470"
  },
  {
    "text": "Um, how models are now looking like. So we have 70 billion parameter models.",
    "start": "1976690",
    "end": "1982450"
  },
  {
    "text": "Um, and you know, the 70 billion parameters, even if you quantize gigabytes at 8 bit.",
    "start": "1982840",
    "end": "1989230"
  },
  {
    "text": "It's 140 gigabytes at 16 bit. Uh, now you don't want to have to buy full cards.",
    "start": "1989230",
    "end": "1994834"
  },
  {
    "text": "So that we see an increase in memory capacity across the board of all the, uh, the accelerators.",
    "start": "1995135",
    "end": "2001044"
  },
  {
    "text": "Uh, but not only NVIDIA is here, but we also see new entrants or the, the other players in the market.",
    "start": "2001495",
    "end": "2008005"
  },
  {
    "text": "AMD is announcing a pretty good roadmap of their products. All that's very, very large.",
    "start": "2008445",
    "end": "2014260"
  },
  {
    "text": "Memory capacities and memory bandwidth to address those large language models and fit more",
    "start": "2014795",
    "end": "2019855"
  },
  {
    "text": "model into less space or less compute like and, uh, and Intel is playing in the market as well.",
    "start": "2019855",
    "end": "2026835"
  },
  {
    "text": "And then you have a handful of startups, uh, where we also saw, you know, really",
    "start": "2026864",
    "end": "2032544"
  },
  {
    "text": "interesting technologies coming onto the market. So if you look at, uh, Cerebros, that's a",
    "start": "2032544",
    "end": "2037995"
  },
  {
    "text": "wafer scale, uh, AI, which, you know, like. A year ago, they were talking about it, now",
    "start": "2038015",
    "end": "2043910"
  },
  {
    "text": "you can actually use it as a cloud service. You have Croc being a player, there are other companies coming up, there's",
    "start": "2043910",
    "end": "2050490"
  },
  {
    "text": "D Matrix, which will have an adapter coming out at the beginning of next year. Um, and so I think, um, um, yeah, so I think",
    "start": "2050490",
    "end": "2058240"
  },
  {
    "text": "there's a good set of players in the market. And then there are new entrants, right? We just saw the, the Broadcom announcement,",
    "start": "2058240",
    "end": "2065870"
  },
  {
    "text": "um, pretty much, I think it was last week, um, with very large, you know, revenue",
    "start": "2065910",
    "end": "2071385"
  },
  {
    "text": "targets, uh, and the relationship with Apple, uh, and then Qualcomm is also in the game",
    "start": "2071385",
    "end": "2077035"
  },
  {
    "text": "and has a chip architecture coming, you know, and being some of them are available",
    "start": "2077075",
    "end": "2082195"
  },
  {
    "text": "and there's a good roadmap for them. So I think the market is not only NVIDIA anymore, which is, I think, good for the",
    "start": "2082195",
    "end": "2088544"
  },
  {
    "text": "industry, and it's moving extremely fast. So, and we have, we see training systems",
    "start": "2088545",
    "end": "2094194"
  },
  {
    "text": "there, but there's an an increasing. Um, focus on inferencing because from my perspective, it's kind",
    "start": "2094235",
    "end": "2100275"
  },
  {
    "text": "of where the money will be made. Yeah, for sure. And I guess, Khaoutar, I don't know if you want to talk a little bit about that bit. I wanted to make sure that we did talk a",
    "start": "2100275",
    "end": "2106613"
  },
  {
    "text": "little bit about kind of the big trends in inferencing this year, because it feels like that was actually a big, um, theme of",
    "start": "2106615",
    "end": "2112395"
  },
  {
    "text": "kind of how this market is developing out. And, uh, if you want to speak a little bit to that and where you think things went in 2024.",
    "start": "2112425",
    "end": "2118285"
  },
  {
    "text": "Yeah, so of course, there's a lot of, a lot happening, especially around, um, inference engines and optimizing inference engines.",
    "start": "2119045",
    "end": "2126194"
  },
  {
    "text": "Uh, a lot of hardware software co design is also, uh, you know, playing a key role in that.",
    "start": "2126565",
    "end": "2132005"
  },
  {
    "text": "So, uh, you, we see technologies like VLLM, for example. Uh, we see also things like the, um, They",
    "start": "2132365",
    "end": "2139325"
  },
  {
    "text": "try to what they're doing and all the the stuff around KV cache optimizations, the",
    "start": "2139325",
    "end": "2145455"
  },
  {
    "text": "batching for in the inference optimizations. So a lot of that, a lot of innovations is",
    "start": "2145455",
    "end": "2151665"
  },
  {
    "text": "happening in open source around building and scaling, inferencing, especially",
    "start": "2151705",
    "end": "2157315"
  },
  {
    "text": "focusing on large language models. But a lot of these optimizations we see, they're not only specific to LLM, they can",
    "start": "2157315",
    "end": "2163245"
  },
  {
    "text": "be also extended to other, to other models. So, um, so a lot of development that's happening",
    "start": "2163245",
    "end": "2170040"
  },
  {
    "text": "at the VLLM, uh, there is work, you know, even at IBM Research and others contributing to",
    "start": "2170040",
    "end": "2176390"
  },
  {
    "text": "open source to basically especially bring a lot of these co optimizations, um, in terms of",
    "start": "2176390",
    "end": "2183400"
  },
  {
    "text": "scheduling, in terms of batching, in terms of figuring out how to best basically collocate",
    "start": "2183409",
    "end": "2189600"
  },
  {
    "text": "all of these, uh, inference requests and get the hardware to, uh, um, uh, run them efficiently.",
    "start": "2189630",
    "end": "2195010"
  },
  {
    "text": "Yeah, absolutely. Volkmar, do you want to give us a little bit of a peek into 2025? I mean, it kind of sounds like with this",
    "start": "2195060",
    "end": "2200520"
  },
  {
    "text": "market becoming increasingly crowded, I think everybody's coming after NVIDIA's crown here. You know, what do you expect to happen in 2025?",
    "start": "2200520",
    "end": "2207000"
  },
  {
    "text": "Does NVIDIA largely still stay in the lead? Or do we end in December 2025 with, you know,",
    "start": "2207010",
    "end": "2212030"
  },
  {
    "text": "the market becoming a lot more divided and diversified than it has been traditionally, particularly on the training side?",
    "start": "2212030",
    "end": "2217490"
  },
  {
    "text": "So I think the training side will be, that's my prediction, will be still",
    "start": "2218070",
    "end": "2223980"
  },
  {
    "text": "very strongly in the hands of NVIDIA. Um, I think AMD and Intel will",
    "start": "2224030",
    "end": "2230090"
  },
  {
    "text": "try to break into that market. Uh, but I think that will probably be more in the 2026 27 timeframe.",
    "start": "2230110",
    "end": "2238200"
  },
  {
    "text": "Uh, the reason why I'm saying this is, um, the architecture you need to build, to",
    "start": "2238760",
    "end": "2244590"
  },
  {
    "text": "build a really successful training system, it's not the GPU, it's, it's a system.",
    "start": "2244590",
    "end": "2249670"
  },
  {
    "text": "So you need. Uh, really good, uh, low latency networking. You need to have a reliability problem.",
    "start": "2249670",
    "end": "2255704"
  },
  {
    "text": "There's a, like, a strong push to actually move compute into the fabric, um, to",
    "start": "2255935",
    "end": "2261375"
  },
  {
    "text": "further cut down the latency and more efficiently utilize, uh, the hardware. And, uh, NVIDIA, with their acquisition",
    "start": "2261555",
    "end": "2269295"
  },
  {
    "text": "of Mellanox, effectively bought the number one network vendor for high performance",
    "start": "2269295",
    "end": "2274530"
  },
  {
    "text": "computing, which, you know, training is. And so there is a, there's a, you",
    "start": "2274530",
    "end": "2279860"
  },
  {
    "text": "know, a bunch of consortiums coming up. There's Ultra Ethernet, um, where, you",
    "start": "2279860",
    "end": "2285089"
  },
  {
    "text": "know, they're trying to get to a similar capabilities what you have with InfiniBand. And InfiniBand, despite that it's an",
    "start": "2285090",
    "end": "2291230"
  },
  {
    "text": "open standard, there's pretty much only one vendor on the planet, which is Mellanox, which is now owned by NVIDIA. So I think NVIDIA has a good,",
    "start": "2291230",
    "end": "2298020"
  },
  {
    "text": "uh, you know, lock on that. side of the market, and therefore a lot of the,",
    "start": "2298330",
    "end": "2303780"
  },
  {
    "text": "of the investments where other people are, are playing is more in the inferencing market, which is much easier to enter, you know, because you",
    "start": "2303880",
    "end": "2310640"
  },
  {
    "text": "intrinsically not only have NVIDIA systems, like you don't have NVIDIA on cell phones, you don't have NVIDIA on the edge, and so there",
    "start": "2310830",
    "end": "2317369"
  },
  {
    "text": "is a, and the software investment you need to do on inferencing is, is much lower than what you have on training side, so I think training",
    "start": "2317370",
    "end": "2324150"
  },
  {
    "text": "is, is in, in, um, Very safe hands for NVIDIA. So unlocked, yeah.",
    "start": "2324150",
    "end": "2328410"
  },
  {
    "text": "But I think there is now enough with Gaudi 3 coming online, which has integrated Ethernet, uh, you know, the,",
    "start": "2329700",
    "end": "2336489"
  },
  {
    "text": "and what AMD is putting on the market. I think there will be, it will be a slow creep into that market.",
    "start": "2336540",
    "end": "2342099"
  },
  {
    "text": "And I think, you know, in 2026, we will probably see, um, that, you know, there is a major break",
    "start": "2342259",
    "end": "2347890"
  },
  {
    "text": "in into that market, and NVIDIA loses that. That very unique position it has right now.",
    "start": "2347890",
    "end": "2352535"
  },
  {
    "text": "Yeah.\nIt's going to be a big transition. Khaoutar, do you agree with that for the 2025 prediction? Yeah, I agree with that.",
    "start": "2352895",
    "end": "2357365"
  },
  {
    "text": "Of course, there's a rising competition in AI hardware, like Volkmar mentioned, companies like AMD, Intel, and startups",
    "start": "2358070",
    "end": "2364610"
  },
  {
    "text": "like Groq and Graphcore, they're developing competitive hardware. IBM also is developing, uh, competitive",
    "start": "2364620",
    "end": "2370209"
  },
  {
    "text": "hardware for training and inference. The problem with the NVIDIA GPUs is",
    "start": "2370219",
    "end": "2376210"
  },
  {
    "text": "also the cost and the power efficiency. The NVIDIA GPUs are very expensive and they're power hungry, making them less",
    "start": "2376210",
    "end": "2382430"
  },
  {
    "text": "attractive, especially for the edge AI and the cost sensitive deployments. So the competitors like AWS Inferentia,",
    "start": "2382430",
    "end": "2390580"
  },
  {
    "text": "IPUs, they offer specialized hardware that's often cheaper and more energy",
    "start": "2390640",
    "end": "2396560"
  },
  {
    "text": "efficient for certain applications. So. And I think, you know, the open standards, for",
    "start": "2396560",
    "end": "2402295"
  },
  {
    "text": "example, like the open AI Triton, um, and the Onyx and new, you know, these new frameworks,",
    "start": "2402295",
    "end": "2408445"
  },
  {
    "text": "they're also working a lot on reducing the reliance on NVIDIA's proprietary ecosystem,",
    "start": "2408475",
    "end": "2414265"
  },
  {
    "text": "which makes it makes it really easy for competitors to gain also some traction here.",
    "start": "2415165",
    "end": "2419695"
  },
  {
    "text": "And if we look at the inference specific hardware, there is, you know, these RISE, like I",
    "start": "2420610",
    "end": "2426840"
  },
  {
    "text": "mentioned VLLM before, this dedicated inference engines like VLLM, SGLang, Triton, they",
    "start": "2426840",
    "end": "2433400"
  },
  {
    "text": "highlight the potential for non NVIDIA hardware. So they're opening up the door for the competition, uh, easy entry.",
    "start": "2433400",
    "end": "2440449"
  },
  {
    "text": "And they also, and allow them also to excel in inference scenarios, especially for large language models.",
    "start": "2440720",
    "end": "2446349"
  },
  {
    "text": "So, Uh, we'll see uh, this widespread emergence of edge inference solutions powered by ASICs.",
    "start": "2446770",
    "end": "2454865"
  },
  {
    "text": "Uh, and, and I think this is challenging NVIDIA's role in this rapidly growing edge AI market.",
    "start": "2455275",
    "end": "2461784"
  },
  {
    "text": "Yeah, and I think the edge is, I think is the last bit I wanted to make sure that we touch on before we move on to the next segment. Um, you know, Volkmar, it seems to me",
    "start": "2462144",
    "end": "2468325"
  },
  {
    "text": "that obviously one of the big stories was Apple moving into Apple intelligence and making sure that all the, you",
    "start": "2468325",
    "end": "2474035"
  },
  {
    "text": "know, essentially AI chips on them. Um, I assume that's going to continue to 2025, but I'm curious for our listeners that",
    "start": "2474035",
    "end": "2480650"
  },
  {
    "text": "are less involved in watching the hardware space day to day, if there's any trends that you think are worth it for people to pay",
    "start": "2480650",
    "end": "2485720"
  },
  {
    "text": "attention to as we get into the next 12 months. I think the Apple model is, uh, is very elegant and protocol when you",
    "start": "2485720",
    "end": "2492270"
  },
  {
    "text": "are in a power constraint environment. Um, so you, you know, whatever you can do in that power constraint environment",
    "start": "2492270",
    "end": "2497980"
  },
  {
    "text": "with less accuracy you do on device. And then whenever you need more, you go somewhere else.",
    "start": "2497990",
    "end": "2502490"
  },
  {
    "text": "Uh, I think also the, the Apple. Uh, architecture that they are running on this on on the same silicon as they are running,",
    "start": "2503010",
    "end": "2510920"
  },
  {
    "text": "you know on their phone They run in the cloud. It's a it's a very Interesting architecture",
    "start": "2511070",
    "end": "2516630"
  },
  {
    "text": "because it simplifies it for the developer. It simplifies it in deployment And so I think that we will see more Of that type",
    "start": "2516630",
    "end": "2524235"
  },
  {
    "text": "of separation, and I think we will see more compute happening on edge devices, and we're",
    "start": "2524255",
    "end": "2531025"
  },
  {
    "text": "going now as silicon matures, and you know, there are there's more choices and you don't",
    "start": "2531025",
    "end": "2536484"
  },
  {
    "text": "need a high powered card anymore, and the silicon gets more and more specialized for",
    "start": "2536484",
    "end": "2541564"
  },
  {
    "text": "that, you know, simple matrix multiply, I think we will see pretty much every every chip",
    "start": "2541565",
    "end": "2547240"
  },
  {
    "text": "which will leave a factory will effectively contain AI capabilities in one form or another.",
    "start": "2547270",
    "end": "2552540"
  },
  {
    "text": "And then it's really this hybrid architecture of on device and off device",
    "start": "2552990",
    "end": "2558589"
  },
  {
    "text": "processing, which allows to have, you know, silicon live for a long period of time. But if you're on an edge, You know, and",
    "start": "2558590",
    "end": "2565680"
  },
  {
    "text": "Edge is not only a phone, it could be an industrial device, where you know, you know, your life cycle is five to ten years.",
    "start": "2565790",
    "end": "2571970"
  },
  {
    "text": "You don't want to go and every two years have to swap out the chip just because you want to train another network. And so I think the architecture Apple put",
    "start": "2572210",
    "end": "2578720"
  },
  {
    "text": "out will be uh, more solidified and we will see, you know, software ecosystems building being built around that.",
    "start": "2578720",
    "end": "2584859"
  },
  {
    "text": "Yeah, that's great. Well, Khaoutar, I'll let you have the last word here. Um, I've been asking most panelists as they've been coming on, what is the most underrated",
    "start": "2584930",
    "end": "2592369"
  },
  {
    "text": "thing, um, in this particular domain? So for AI hardware, are there things that people are not paying attention to?",
    "start": "2592400",
    "end": "2598290"
  },
  {
    "text": "Um, you know, there's a lot of hype in the AI hardware space. So I'm curious if there's any more subtle trends that you think are",
    "start": "2598579",
    "end": "2603825"
  },
  {
    "text": "important to pay attention to? Yeah, that's a, that's a great question. So I think, um, there is a lot of work",
    "start": "2603825",
    "end": "2609255"
  },
  {
    "text": "around real time compute optimizations. Um, technologies, for example, like",
    "start": "2609255",
    "end": "2614645"
  },
  {
    "text": "the test time compute, uh, which allows AI models to allocate additional",
    "start": "2614645",
    "end": "2620175"
  },
  {
    "text": "computational resources during inference. This is something that we saw with OpenAI o1 model.",
    "start": "2620395",
    "end": "2625785"
  },
  {
    "text": "It's really, I think it sets some precedence here and it allows the models to break down these complex problems",
    "start": "2626345",
    "end": "2633245"
  },
  {
    "text": "effectively and mimic also kind of what we're doing in human reasoning. And it also has implications also on the",
    "start": "2633255",
    "end": "2640784"
  },
  {
    "text": "way we design these models and also the way the models interact with the hardware. So it's kind of pushing for more hardware",
    "start": "2640784",
    "end": "2646684"
  },
  {
    "text": "software co design, um, in this context where processing during inference, I think another trend I see is the",
    "start": "2646685",
    "end": "2653855"
  },
  {
    "text": "hardware accessibility volunteer for all. I think when we see the Llama3 series, which",
    "start": "2653864",
    "end": "2659285"
  },
  {
    "text": "illustrates new hardware ecosystems are evolving for both high end research models,",
    "start": "2659295",
    "end": "2665385"
  },
  {
    "text": "but also for consumer grade applications. So the Llama models, they release, you know,",
    "start": "2665645",
    "end": "2671025"
  },
  {
    "text": "multiple versions, the 400, the 8 and so on. So that's also an important trend that we're seeing.",
    "start": "2671025",
    "end": "2676675"
  },
  {
    "text": "So we can kind of bridge the gap between high end These are data centers that allow",
    "start": "2676915",
    "end": "2682350"
  },
  {
    "text": "basically access to where you have access to these high end computes and infrastructure,",
    "start": "2682380",
    "end": "2687530"
  },
  {
    "text": "which is not accessible to everything. So pushing towards that would be really important.",
    "start": "2687530",
    "end": "2691819"
  },
  {
    "text": "The other thing is the open source and the enterprise synergy. IBM released Granite 3, which I think",
    "start": "2692720",
    "end": "2699040"
  },
  {
    "text": "is a great step in the right direction, which also highlights the importance of",
    "start": "2699040",
    "end": "2703889"
  },
  {
    "text": "open source AI and its ability to maximize the performance for enterprise hardware.",
    "start": "2704240",
    "end": "2709689"
  },
  {
    "text": "And, but there are still hardware design challenges. For example, what we see with NVIDIA's,",
    "start": "2710265",
    "end": "2714875"
  },
  {
    "text": "uh, the Blackwell GPUs and the issues that they have around thermal management and server architectures.",
    "start": "2715375",
    "end": "2722714"
  },
  {
    "text": "So, um, these hardware's, you know, to scale the need to meet demands for these next gen AI.",
    "start": "2722985",
    "end": "2728463"
  },
  {
    "text": "Power efficiency is becoming critical. So, um, so I think if I were to sum up what's",
    "start": "2729825",
    "end": "2736875"
  },
  {
    "text": "going on around these trends, I think the year 2024 showcased the importance of hardware",
    "start": "2736875",
    "end": "2744024"
  },
  {
    "text": "software co design and the industry's pivot also towards specialized AI accelerators,",
    "start": "2744025",
    "end": "2750295"
  },
  {
    "text": "open source adoption, and real time compute. Innovations are really very important, are",
    "start": "2750385",
    "end": "2756255"
  },
  {
    "text": "setting the stage for further breakthroughs. Yeah, that's a great note to end on. Well, that's all the time that we have for hardware.",
    "start": "2756265",
    "end": "2761775"
  },
  {
    "text": "Uh, Khaoutar Volkmar, thanks for joining us, uh, and for all your help in 2024, uh, explaining the kind of world of hardware and,",
    "start": "2761815",
    "end": "2768845"
  },
  {
    "text": "uh, we'll have to have you back on in 2025.",
    "start": "2768845",
    "end": "2770924"
  },
  {
    "text": "Finally, to round out our picture of 2024, we need to talk about the product releases that stunned us, amazed us",
    "start": "2775945",
    "end": "2781859"
  },
  {
    "text": "and gave us something to think about. To help me do that are Kate Soule, Director Technical Product Management for Granite, and",
    "start": "2781890",
    "end": "2787670"
  },
  {
    "text": "Kush Varshney, IBM Fellow on AI Governance. Kate, maybe I'll turn it to you first. Obviously, you know, the schedule was crazy",
    "start": "2787670",
    "end": "2794729"
  },
  {
    "text": "this year in terms of product releases. It felt like every other week there was something. But I guess looking back on the last 12",
    "start": "2794730",
    "end": "2799969"
  },
  {
    "text": "months, I'm kind of curious, like, what did you think was the biggest things, right? The stories that will kind of look back on",
    "start": "2800000",
    "end": "2805069"
  },
  {
    "text": "2024 and be like, Yeah, this is the year that. You know, that happens as the director for technical",
    "start": "2805070",
    "end": "2811099"
  },
  {
    "text": "product management for granite. I feel like I have to, uh, have to celebrate what our team at IBM accomplished and",
    "start": "2811100",
    "end": "2818470"
  },
  {
    "text": "released for, for launching the granite 3. 0 model family, um, focused on right.",
    "start": "2818470",
    "end": "2823910"
  },
  {
    "text": "Apache two licensed models that are transparent, uh, with kind of an ethical sourcing of the",
    "start": "2823910",
    "end": "2829580"
  },
  {
    "text": "data that went into them, uh, that we share all the details about online in our report. So really excited about being able to continue",
    "start": "2829580",
    "end": "2836010"
  },
  {
    "text": "that commitment to open source AI and being able to create, you know, state of the art",
    "start": "2836010",
    "end": "2840720"
  },
  {
    "text": "language models and the two to 8 billion parameter size that we can put out there under permissible terms for our customers and for",
    "start": "2841060",
    "end": "2848340"
  },
  {
    "text": "the open source communities to, to leverage more broadly, uh, looking outside of just IBM,",
    "start": "2848340",
    "end": "2853850"
  },
  {
    "text": "you know, I think the release of the GPT 4. 0 family of models and product was really exciting.",
    "start": "2853870",
    "end": "2860070"
  },
  {
    "text": "I think it. Launched a new wave of interest in how do we continue to improve performance without just",
    "start": "2860399",
    "end": "2867700"
  },
  {
    "text": "spending more money on our training compute. So I think that really is ushering in this next",
    "start": "2867700",
    "end": "2873650"
  },
  {
    "text": "wave that we're going to see in 2025 of how can we spend more at inference time allowing models",
    "start": "2873650",
    "end": "2878859"
  },
  {
    "text": "and products that use these models to have more advanced computations and inference calls that",
    "start": "2878859",
    "end": "2884099"
  },
  {
    "text": "get generated to improve performance beyond just let's throw more money at the training. Let's throw more data.",
    "start": "2884100",
    "end": "2889340"
  },
  {
    "text": "Let's scale, scale, scale. So that's more broadly, uh, something I was pretty excited to see. Yeah, we should definitely talk",
    "start": "2889379",
    "end": "2894865"
  },
  {
    "text": "about both of those themes. I mean, I think on the first one, you know, 2024 was really like the, the attack of the",
    "start": "2894875",
    "end": "2899934"
  },
  {
    "text": "open source, you know, it felt like for a moment there, like all the closed source models would really be winning the day. And it's just like the explosion",
    "start": "2899935",
    "end": "2906334"
  },
  {
    "text": "of activity on open source has been really, really exciting to see. And then I think the second one as well is kind of like, it's like the, the, you",
    "start": "2906334",
    "end": "2912725"
  },
  {
    "text": "know, play smarter, not harder, um, kind of world where, you know, I think like there's a bunch of new techniques that we're",
    "start": "2912725",
    "end": "2918105"
  },
  {
    "text": "seeing kind of play out in a lot of places. Maybe Kush, maybe we'll start with that first theme. Um, you know, in the open source world, of",
    "start": "2918105",
    "end": "2924795"
  },
  {
    "text": "course, this is also the year of Llama 3. Um, there's just been a lot happening in open source land.",
    "start": "2924795",
    "end": "2930015"
  },
  {
    "text": "And, uh, curious as you look back, I mean, I think on either of the themes that Kate, Pointed out here, you know, either on the open source",
    "start": "2930045",
    "end": "2935795"
  },
  {
    "text": "side or in the kind of different methods for doing AI If there's like things that you'd",
    "start": "2935795",
    "end": "2940944"
  },
  {
    "text": "want our listeners to remember from 2024. Yeah, I mean, I think You're phrasing of it.",
    "start": "2940945",
    "end": "2946994"
  },
  {
    "text": "I mean Open source returns or the return of whatever you want to call it.",
    "start": "2947305",
    "end": "2953255"
  },
  {
    "text": "Yeah, I mean, I think that's the The right way to frame it, I think, uh, we're realizing,",
    "start": "2953255",
    "end": "2959730"
  },
  {
    "text": "I mean, when we talk to customers across the board, um, that, uh, they were, I mean,",
    "start": "2959790",
    "end": "2965160"
  },
  {
    "text": "in 2023, it was all about kind of POCs and this sort of thing, like getting people",
    "start": "2965160",
    "end": "2970280"
  },
  {
    "text": "excited within their own companies that don't maybe generative AI has a role to play. But then over time, they realized",
    "start": "2970280",
    "end": "2976490"
  },
  {
    "text": "that actually we need to worry about. Um, uh, the copyrighted, uh, data, um, other",
    "start": "2976530",
    "end": "2982700"
  },
  {
    "text": "governance sort of issues, the cost, um, just, uh, how to make these operational.",
    "start": "2982720",
    "end": "2987740"
  },
  {
    "text": "And, uh, I think, uh, watsonx, uh, the IBM product, uh, kind of shined with, with that,",
    "start": "2987740",
    "end": "2994090"
  },
  {
    "text": "um, the, the granite models obviously as well. So, um, How do we take, uh, the, the",
    "start": "2994260",
    "end": "2999680"
  },
  {
    "text": "science experiment that we had in 2023, um, kind of was being used more, uh, this",
    "start": "2999680",
    "end": "3005830"
  },
  {
    "text": "year and now going into next year, it's all about, uh, being as serious as possible.",
    "start": "3005830",
    "end": "3010859"
  },
  {
    "text": "I would say. Yeah, for sure. And I think now that you're on, uh, for this segment, I mean, I think it's a good",
    "start": "3010860",
    "end": "3015899"
  },
  {
    "text": "time to ask too, obviously spend a lot of time thinking about AI governance, right? And there were a bunch of stories.",
    "start": "3015900",
    "end": "3021019"
  },
  {
    "text": "Yeah.\nin that vein, uh, this year. I don't know if there's ones that you'd want to call out for, for 2024.",
    "start": "3021020",
    "end": "3026099"
  },
  {
    "text": "Yeah, no, I mean, I think, uh, just the fact that, uh, the whole AI safety world, uh, convened, right?",
    "start": "3026150",
    "end": "3033349"
  },
  {
    "text": "I mean, uh, in, we had this, uh, Korea summit, we had the summit in San Francisco, um, uh, in November.",
    "start": "3033350",
    "end": "3040240"
  },
  {
    "text": "Um, and yeah, I mean, it's just, This is now the topic, I think it's the thing that we need to",
    "start": "3040300",
    "end": "3046885"
  },
  {
    "text": "overcome, uh, because just having AI generative AI out there without the safety guardrails and",
    "start": "3046885",
    "end": "3053404"
  },
  {
    "text": "without the governance, um, it's just dangerous. Um, I think it's, uh, the promise of",
    "start": "3053414",
    "end": "3059035"
  },
  {
    "text": "the return on investment is only a promise until you can overcome the hump of, uh, the, the governance issues.",
    "start": "3059075",
    "end": "3064815"
  },
  {
    "text": "Yeah, for sure. Do you have\nany predictions for where we go in 2025 with all that? I mean, um, Yeah. You know, I think we're, I'm detecting a theme here, which is 2024",
    "start": "3064855",
    "end": "3071450"
  },
  {
    "text": "almost like set up a lot of stuff. 2025, we're going to almost see how it plays out. I mean, both in open source and",
    "start": "3071450",
    "end": "3077010"
  },
  {
    "text": "in governance, it seems like. Yeah, no, I think, uh, the prediction is, uh, uh, I mean, the earlier segment",
    "start": "3077010",
    "end": "3083090"
  },
  {
    "text": "was about agentic AI in the show. So I think that's gonna really, um, explode as well. And I think the governance, uh, There is",
    "start": "3083110",
    "end": "3090369"
  },
  {
    "text": "going to be what drives the governance back down to, um, other use cases as well, because when you have autonomous",
    "start": "3090370",
    "end": "3096360"
  },
  {
    "text": "agents, um, uh, then really the governance, the trust is, uh, extremely important.",
    "start": "3096360",
    "end": "3101539"
  },
  {
    "text": "Uh, you have, I mean, no, very little control over what these things might do. Um, uh, the stuff that, uh, that Kate was",
    "start": "3101579",
    "end": "3108430"
  },
  {
    "text": "mentioning, the extra inference cycles that you're going to see are going to be, I think, mainly for the purpose of governance.",
    "start": "3108430",
    "end": "3115300"
  },
  {
    "text": "It's to make these things, um, kind of self reflect a little bit, maybe think twice about what answers they're",
    "start": "3115310",
    "end": "3121885"
  },
  {
    "text": "putting out there and so forth. So you're going to have more tools for governing the agents as well.",
    "start": "3121885",
    "end": "3128055"
  },
  {
    "text": "So the Granite Guardian 3. 1 release that just happened actually has a function calling",
    "start": "3128055",
    "end": "3134415"
  },
  {
    "text": "hallucination detector in there. So that's one of the things that agents actually do, right?",
    "start": "3134425",
    "end": "3139735"
  },
  {
    "text": "As part of the LLM Uh, they actually will call some other tools, some other agents, some other function and if that itself is, uh,",
    "start": "3140045",
    "end": "3147565"
  },
  {
    "text": "hallucinated the parameters, the, um, the, the type of the parameters, the function names,",
    "start": "3147575",
    "end": "3153544"
  },
  {
    "text": "all of these things can, uh, kind of go wrong. So we have ways of, of detecting, uh, issues there.",
    "start": "3153545",
    "end": "3159214"
  },
  {
    "text": "Kush, I'm, I'm curious, you said the, the inference. runtime is going to be used more almost",
    "start": "3159515",
    "end": "3165790"
  },
  {
    "text": "for kind of governance and self reflection. But I think you had even shared a paper",
    "start": "3165790",
    "end": "3171278"
  },
  {
    "text": "recently about how there's also like, it also opens this whole can of worms of other risks and potential security issues, right?",
    "start": "3171299",
    "end": "3178009"
  },
  {
    "text": "When the models are running all these loops offline and people are naturally able to observe what's going in the",
    "start": "3178009",
    "end": "3183650"
  },
  {
    "text": "Yeah, I mean, uh, I think This whole, I mean, self reflection, you can call it metacognition, you can call it wisdom.",
    "start": "3184130",
    "end": "3191485"
  },
  {
    "text": "I mean, I think these are going to be things that are going to be part of what happens.",
    "start": "3191505",
    "end": "3197345"
  },
  {
    "text": "But yeah, I mean, anytime you have extra stuff happening, more loops, more opportunities,",
    "start": "3197345",
    "end": "3202834"
  },
  {
    "text": "more surface area for attacks, right? So I think that is certainly going to be part of it.",
    "start": "3202835",
    "end": "3208545"
  },
  {
    "text": "But I have hope that just like in other sort of systems, you can have I mean, better",
    "start": "3208545",
    "end": "3215070"
  },
  {
    "text": "control when you can kind of have more opportunity to kind of affect what happens.",
    "start": "3215070",
    "end": "3220730"
  },
  {
    "text": "Yeah, and I think that ends up being critical and I think is also a pivot that I was going to mention to kind of throw it back to you, Kate, is, you know, if all of the,",
    "start": "3220770",
    "end": "3227410"
  },
  {
    "text": "you know, open source is just coming up so quickly in 2024, Um, it feels like 2025 might finally be the year where it's like",
    "start": "3228060",
    "end": "3233720"
  },
  {
    "text": "we're at parity or even open source is like going past closed source in some sense. And I think, you know, this is happening",
    "start": "3233720",
    "end": "3239400"
  },
  {
    "text": "not just because the technology is getting better, but also like Kush is saying, like, you know, I think our ability to you know, have",
    "start": "3239400",
    "end": "3246195"
  },
  {
    "text": "components that ensure safety in deploying open source models is also getting better, right? In the past, it was like, well, we have to rely",
    "start": "3246205",
    "end": "3252105"
  },
  {
    "text": "on closed source because they really understand how to do alignment and security and safety. There's a lot of scare tactics out there.",
    "start": "3252105",
    "end": "3257575"
  },
  {
    "text": "That's right. Yeah,\nexactly. Only the big model providers have the budget to be able to look at how",
    "start": "3257585",
    "end": "3263315"
  },
  {
    "text": "to do this safely or the expertise. Um, that's right. I, I, yeah, I think we're finally getting,",
    "start": "3263315",
    "end": "3268835"
  },
  {
    "text": "you know, chipping away at that enough. We're seeing Meta, for example, doing a phenomenal job releasing very large models.",
    "start": "3268885",
    "end": "3275174"
  },
  {
    "text": "with excellent safety alignment out there and showing that you can do this out in the open.",
    "start": "3275355",
    "end": "3280724"
  },
  {
    "text": "It does not need to be, you know, inside of, uh, behind a black curtain, so to speak. Yeah, for sure.",
    "start": "3280725",
    "end": "3285795"
  },
  {
    "text": "Is that a prediction for 2025? That we can, we can have our cake and eat it too. Like, like we can have it be open and it can also be safe.",
    "start": "3285795",
    "end": "3291325"
  },
  {
    "text": "Absolutely. Yeah. That's exciting. Um, do you have any open source predictions going into the next 12 months?",
    "start": "3291720",
    "end": "3296760"
  },
  {
    "text": "Like where do we go from here? Um, you know, I guess more granite, even better granite. I think the next year is really going to",
    "start": "3296800",
    "end": "3302840"
  },
  {
    "text": "be focused a little bit higher up, uh, the stack on top of the models and co optimizing",
    "start": "3302850",
    "end": "3308730"
  },
  {
    "text": "models and the developer frameworks. In which they're executed on. So we saw the release of Llama stack, right?",
    "start": "3308740",
    "end": "3315200"
  },
  {
    "text": "When, uh, 2024, um, I think we're going to see that wildly evolve, um, as it starts",
    "start": "3315240",
    "end": "3322870"
  },
  {
    "text": "to mature and other similar types of capabilities and stacks being developed. I think we've all also kind of accepted",
    "start": "3322870",
    "end": "3329450"
  },
  {
    "text": "like the open AI endpoint way of working with models is, you know, the incumbent",
    "start": "3329450",
    "end": "3334460"
  },
  {
    "text": "operating of, of, uh, way to operate. But. There's probably other ways we can continue to innovate and improve now that we've been around",
    "start": "3334950",
    "end": "3342080"
  },
  {
    "text": "the block a few times, so I think we're going to start to see a lot of open source innovation a little bit higher up the stack, particularly,",
    "start": "3342080",
    "end": "3348910"
  },
  {
    "text": "you know, from model providers who are looking, how do we further improve performance? It goes hand in hand.",
    "start": "3348950",
    "end": "3354290"
  },
  {
    "text": "If you're trying to optimize and run innovate at the inference time, you need a stack that can handle that. And so, That's where I think a lot of",
    "start": "3354290",
    "end": "3360725"
  },
  {
    "text": "the development is going to happen. Yeah, for sure. Yeah, I feel like there's so much that we've just taken as a given in some ways, just",
    "start": "3360725",
    "end": "3367645"
  },
  {
    "text": "because, like, that's where stuff got started. But it's even easy to forget, given that there's so much news. Like, this is like all very fresh.",
    "start": "3367645",
    "end": "3373595"
  },
  {
    "text": "And like just a few years ago, it was like basically non existent. Um, so. Yeah, I think one that I kind of put before",
    "start": "3373835",
    "end": "3379510"
  },
  {
    "text": "this group, particularly because we're talking about product releases, you know, I think this year I'm mixture of experts. We've talked a lot about how like chat, right?",
    "start": "3379510",
    "end": "3386280"
  },
  {
    "text": "It's just like an interface that we we started with just because like chat GPT was so successful. But there's kind of no reason why like",
    "start": "3386320",
    "end": "3392580"
  },
  {
    "text": "that has to be the way we interact with these systems going forwards. Um, I'm curious if either of you have kind of predictions on like, even like the interface.",
    "start": "3392580",
    "end": "3399550"
  },
  {
    "text": "Like do we start interacting with these systems in a way that's, that's pretty different from like what we've gotten used to? Yeah.\nI mean, I think, uh, the co creativity, co",
    "start": "3399550",
    "end": "3407430"
  },
  {
    "text": "creation is going to become a bigger thing. So. having multiple people.",
    "start": "3407430",
    "end": "3412460"
  },
  {
    "text": "I know there's been some canvas sort of things that have come out this year as well, but, uh, I think it's just going to grow.",
    "start": "3412460",
    "end": "3418309"
  },
  {
    "text": "And, um, uh, let me give a brief shout out to my brother. Um, he has a startup called KOCREE, K O",
    "start": "3418310",
    "end": "3424790"
  },
  {
    "text": "C R E E, and I just got to get that in. Exactly, exactly. And, um, uh, it's all about",
    "start": "3424790",
    "end": "3430710"
  },
  {
    "text": "kind of co creating music. Uh, for people, um, kind of through with AI, but also to help people, um, and society, um,",
    "start": "3430750",
    "end": "3438545"
  },
  {
    "text": "with their well being and, uh, and so forth. Because when you create with others, um, it's actually like a positive experience as well.",
    "start": "3438555",
    "end": "3445744"
  },
  {
    "text": "So, um, uh, so I think, you know, Just a shift in focus a little bit maybe towards more",
    "start": "3445765",
    "end": "3451055"
  },
  {
    "text": "human flourishing human sort of well being and kind of how to get people to really work",
    "start": "3451055",
    "end": "3456885"
  },
  {
    "text": "together to have kind of open endedness and so forth might be something that emerges.",
    "start": "3456885",
    "end": "3462425"
  },
  {
    "text": "What, uh, maybe we're got a little few minutes left on this segment. Is there anything that folks aren't talking about?",
    "start": "3462585",
    "end": "3468045"
  },
  {
    "text": "Like, I guess that's one thing is like, I feel like, um, you know, and particularly in AI, everyone is always excited about",
    "start": "3468105",
    "end": "3475700"
  },
  {
    "text": "like the latest model release or like the latest, you know, um, Yeah, I'm always kind of trying to see around corners. I think with both of you were you're kind of experts to think about this so deeply,",
    "start": "3475700",
    "end": "3482435"
  },
  {
    "text": "like what's under hyped, maybe like underrated at the moment that really deserves more attention going into the next year.",
    "start": "3482765",
    "end": "3488135"
  },
  {
    "text": "I think there's a going to be a tremendous opportunity. And I really hope this takes off around thinking",
    "start": "3488165",
    "end": "3494235"
  },
  {
    "text": "about modular components for building with LLMs. So how do we, like there's work",
    "start": "3494235",
    "end": "3499345"
  },
  {
    "text": "going on, for example, on how do we get to the point where you could. fine tune a LoRa adapter, right? Kind of a bucket of weights that you fine tune",
    "start": "3499355",
    "end": "3505935"
  },
  {
    "text": "for your task that sits on top of the model. Right now they have to be tailored for the exact model you're going to deploy and you, a new version comes",
    "start": "3505935",
    "end": "3512095"
  },
  {
    "text": "out, you have to retune your model. But how do we create versions of this? For example, there's interesting research that",
    "start": "3512095",
    "end": "3517615"
  },
  {
    "text": "are universal that can be applied anywhere. And then that creates some really nice, like modular components that you could",
    "start": "3517615",
    "end": "3524125"
  },
  {
    "text": "ship or could have a catalog of and choose from and provision live and swap in and out again at inference time, you could",
    "start": "3524125",
    "end": "3530075"
  },
  {
    "text": "swap these types of things in and out. I think there's also aspects like we've all heard now of our, uh, seminal",
    "start": "3530075",
    "end": "3536625"
  },
  {
    "text": "mixture of experts architecture, right? Um, so there, I think is going to be increasing",
    "start": "3536655",
    "end": "3541865"
  },
  {
    "text": "look at, can we make modular components where you have modular experts that get swapped in and out on the architecture side?",
    "start": "3541865",
    "end": "3547385"
  },
  {
    "text": "So I would love, and I think there's some really interesting, um, research going on at the ground level that could",
    "start": "3547385",
    "end": "3553345"
  },
  {
    "text": "support a focus around how do we make. building and specializing models more modular in 2025.",
    "start": "3553345",
    "end": "3560315"
  },
  {
    "text": "Yeah, that's super cool. And I think doesn't get enough attention. I mean, I think everybody's always like the AI just it just doesn't One big model that does everything.",
    "start": "3560425",
    "end": "3566375"
  },
  {
    "text": "Yeah Why do I have to choose and that's once we have the big model all our problems will be solved, right? Bigger is better, right?",
    "start": "3566715",
    "end": "3572525"
  },
  {
    "text": "Yeah, for sure How about you Kush anything underrated you'd point out to our listeners before we close up on this segment? Yeah, I think um, I mean the the middleware",
    "start": "3572665",
    "end": "3579655"
  },
  {
    "text": "for agents I think would be one thing as well. I mean, building on what Kate just said about the modularity.",
    "start": "3579665",
    "end": "3585839"
  },
  {
    "text": "So, uh, even having, uh, different agents in a multi agent system, how you kind of register them, orchestrate them and so forth.",
    "start": "3585850",
    "end": "3592890"
  },
  {
    "text": "So, um, from IBM research, uh, we have this, uh, B framework. So B as in the, the thing buzzing around in my",
    "start": "3592890",
    "end": "3599300"
  },
  {
    "text": "ear, um, uh, and, uh, that, Uh, is out there. There's, um, other startups as well.",
    "start": "3599300",
    "end": "3606145"
  },
  {
    "text": "Um, so, uh, some former IBM researchers, uh, have this company called Emergence AI, and, um, they have one.",
    "start": "3606145",
    "end": "3613375"
  },
  {
    "text": "Um, uh, there's others out there as well. So, um, I mean, I think that's gonna pick up, um, and it, I mean, again,",
    "start": "3613405",
    "end": "3620185"
  },
  {
    "text": "relates to what Kate was saying. I mean, connecting more between the development environment and the models kind of, uh, linking that, uh, much closer.",
    "start": "3620185",
    "end": "3627505"
  },
  {
    "text": "So I think, uh, Uh, once we are at a point where the models are all kind of good enough, then",
    "start": "3627505",
    "end": "3634495"
  },
  {
    "text": "it's a question of, um, how do we use them? How do we make productive use? Um, and, uh, how do we develop them better?",
    "start": "3634505",
    "end": "3640305"
  },
  {
    "text": "So, yeah. Yeah, for sure. Definitely keep an eye on that space. Well, Kate, Kush, thanks for joining us, uh, on this segment.",
    "start": "3640315",
    "end": "3645525"
  },
  {
    "text": "Appreciate you helping us to navigate 2024 in product releases, but also 2025 in product releases. And we will See you in the new year.",
    "start": "3645525",
    "end": "3652260"
  },
  {
    "text": "Well, that's everything we have time for on our episode today. So much happened in 2024. And there's basically no way",
    "start": "3652530",
    "end": "3658440"
  },
  {
    "text": "we could fit it into one show. But I want to thank all of our panelists for helping us try. And to all the panelists that we've been lucky",
    "start": "3658440",
    "end": "3665079"
  },
  {
    "text": "enough to have on Mixture of Experts in 2024. Each week, we get to nerd out with some of the smartest people in the business.",
    "start": "3665080",
    "end": "3671030"
  },
  {
    "text": "And it's a pleasure to be able to talk with them to better understand this crazy world of artificial intelligence.",
    "start": "3671050",
    "end": "3676470"
  },
  {
    "text": "And thanks to you for joining us. If you enjoyed what you heard, you can get us on Apple Podcasts, Spotify, and podcast platforms everywhere.",
    "start": "3677095",
    "end": "3682895"
  },
  {
    "text": "Here's to what was a great 2024, and here's looking forward to an incredible 2025.",
    "start": "3683275",
    "end": "3687725"
  }
]
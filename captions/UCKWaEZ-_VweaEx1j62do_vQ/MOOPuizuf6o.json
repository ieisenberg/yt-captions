[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "This fall, I bought a new plant.",
    "start": "480",
    "end": "2560"
  },
  {
    "text": "It's an orange mum, and it \nlooks great outside my house.",
    "start": "2560",
    "end": "6000"
  },
  {
    "text": "But the weather is already \ngetting colder in New York.",
    "start": "6000",
    "end": "8720"
  },
  {
    "text": "And if the temperature goes below \nfreezing, my new plant will die.",
    "start": "8720",
    "end": "12760"
  },
  {
    "text": "I gather data on hourly temperatures in \nNew York over the past several weeks.",
    "start": "12760",
    "end": "17720"
  },
  {
    "text": "Using this time series data.",
    "start": "17720",
    "end": "19680"
  },
  {
    "text": "I'm going to use the Lag-Llama model \nan Open Source Foundation model,",
    "start": "19680",
    "end": "24360"
  },
  {
    "text": "to predict the overnight low temperature and  ",
    "start": "24360",
    "end": "26960"
  },
  {
    "text": "help me decide when I need to bring \nthe plant indoors to keep it alive.",
    "start": "26960",
    "end": "31000"
  },
  {
    "start": "30000",
    "end": "122000"
  },
  {
    "text": "First, we'll clone the open source GitHub repo.",
    "start": "31000",
    "end": "34000"
  },
  {
    "text": "I'm using a notebook with an IBM \nwatsonx.ai studio for this project,  ",
    "start": "34000",
    "end": "39320"
  },
  {
    "text": "but you can use any environment to run this model.",
    "start": "39320",
    "end": "44440"
  },
  {
    "text": "Next we'll install the Pre-trained model weights \nfrom the hugging face repo where they're stored.",
    "start": "44440",
    "end": "50199"
  },
  {
    "text": "We use the hugging basically to download \nthe trained Lag-Llama checkpoint.",
    "start": "50200",
    "end": "57040"
  },
  {
    "text": "Now we have to wait for a pre-trained model \nthat we can use in our zero shot forecasting.",
    "start": "57040",
    "end": "65480"
  },
  {
    "text": "We need to import libraries \nto work with Lag-Llama.",
    "start": "65480",
    "end": "68640"
  },
  {
    "text": "For this project, we'll use GleonTS, \nan open source PyTorch Base library  ",
    "start": "68640",
    "end": "73400"
  },
  {
    "text": "for working with time series \ndata and forecasting models.",
    "start": "73400",
    "end": "78280"
  },
  {
    "text": "Next, we need to load the \ndata set for our tutorial.",
    "start": "78280",
    "end": "81640"
  },
  {
    "text": "You can find this dataset in the \nrepo along with the notebook.",
    "start": "81640",
    "end": "85920"
  },
  {
    "text": "This time series data contains hourly temperatures \nin New York for the month of October and November.",
    "start": "85920",
    "end": "91840"
  },
  {
    "text": "The data was gathered from ACS Web services.",
    "start": "91840",
    "end": "95679"
  },
  {
    "text": "I'm loading data from within my project \nin watsonx.ai Studio, but this will differ  ",
    "start": "95680",
    "end": "101240"
  },
  {
    "text": "depending on what environment you're using \nand where you are storing the data file.",
    "start": "101240",
    "end": "106600"
  },
  {
    "text": "The data has some missing readings.",
    "start": "106600",
    "end": "108479"
  },
  {
    "text": "We'll fill them in by \ninterpolating between values.",
    "start": "108480",
    "end": "111200"
  },
  {
    "text": "So there's no missing values in the time series.",
    "start": "111200",
    "end": "115159"
  },
  {
    "text": "Here's what the data looks like.",
    "start": "115160",
    "end": "116800"
  },
  {
    "text": "We can see the trend of colder \nweather throughout the fall.",
    "start": "116800",
    "end": "119840"
  },
  {
    "text": "Now we're ready to make predictions in traditional \ntime series forecasting with a model like ARIMA.",
    "start": "120400",
    "end": "126800"
  },
  {
    "start": "122000",
    "end": "220000"
  },
  {
    "text": "We'd have to first train \nthe model on this data set.",
    "start": "126800",
    "end": "129920"
  },
  {
    "text": "Lag-Llama works differently as a foundation model.",
    "start": "129920",
    "end": "133080"
  },
  {
    "text": "It can create a forecast without pre training,  ",
    "start": "133080",
    "end": "135800"
  },
  {
    "text": "the same way that an LLM can output text \nwithout being pre trained on a task.",
    "start": "135800",
    "end": "141360"
  },
  {
    "text": "This works because Lag-Llama is trained \non large scale time series data sets,  ",
    "start": "141360",
    "end": "146440"
  },
  {
    "text": "like how LLMs are trained on \na massive corpus of text data.",
    "start": "146440",
    "end": "151040"
  },
  {
    "text": "The Lag-Llama model uses a transformer  ",
    "start": "151040",
    "end": "153680"
  },
  {
    "text": "architecture based on the \nLlama model architecture.",
    "start": "153680",
    "end": "157439"
  },
  {
    "text": "The model makes use of lag features or \nprevious readings from the time series,  ",
    "start": "157440",
    "end": "162280"
  },
  {
    "text": "like traditional forecasting models such as ARIMA.",
    "start": "162280",
    "end": "166080"
  },
  {
    "text": "We need to specify some \nconfiguration settings for our model.",
    "start": "166080",
    "end": "170440"
  },
  {
    "text": "The prediction length is how many time \nsteps each prediction should contain.",
    "start": "170440",
    "end": "175080"
  },
  {
    "text": "We'll predict the overnight \ntemperatures, so eight hours out.",
    "start": "175080",
    "end": "179080"
  },
  {
    "text": "The context length sets the number \nof time points looking back into  ",
    "start": "179080",
    "end": "182800"
  },
  {
    "text": "the past that the model should \nlook for lagged correlations.",
    "start": "182800",
    "end": "186400"
  },
  {
    "text": "We'll look back one week when \nmaking these overnight predictions.",
    "start": "186400",
    "end": "192159"
  },
  {
    "text": "Now we'll create the forecaster.",
    "start": "192160",
    "end": "194160"
  },
  {
    "text": "This step consists of two parts.",
    "start": "194160",
    "end": "196720"
  },
  {
    "text": "First, we create a lag estimator which uses  ",
    "start": "196720",
    "end": "200040"
  },
  {
    "text": "all the parameters copied from \nthe downloaded Lag-Llama model.",
    "start": "200040",
    "end": "204079"
  },
  {
    "text": "The second step is to create \na Lag-Llama predictor using  ",
    "start": "204080",
    "end": "207920"
  },
  {
    "text": "that create predictor method of the estimator.",
    "start": "207920",
    "end": "211160"
  },
  {
    "text": "This allows us to pass a context lead sized window \nof data to get the forecasts from the predictor.",
    "start": "211160",
    "end": "218160"
  },
  {
    "text": "Now we're ready to create our forecast.",
    "start": "218160",
    "end": "221040"
  },
  {
    "start": "220000",
    "end": "407000"
  },
  {
    "text": "We'll focus on days in late November because  ",
    "start": "221040",
    "end": "223920"
  },
  {
    "text": "I know that's typically when the \nfirst frost of the season happens.",
    "start": "223920",
    "end": "227760"
  },
  {
    "text": "We'll use the make evaluation predictions  ",
    "start": "227760",
    "end": "230319"
  },
  {
    "text": "method from the GluonTS evaluation \nlibrary to generate our forecasts.",
    "start": "230320",
    "end": "235960"
  },
  {
    "text": "Now that we've generated our forecasts, we'll \nevaluate them against the ground truth data.",
    "start": "235960",
    "end": "241280"
  },
  {
    "text": "We'll use an evaluator object also \nfrom the GluonTS evaluation library  ",
    "start": "241280",
    "end": "246620"
  },
  {
    "text": "will generate several metrics that we can use \nto evaluate the accuracy of our forecasts.",
    "start": "246620",
    "end": "251640"
  },
  {
    "text": "But we'll focus on mean absolute \npercentage error or MAPE.",
    "start": "251640",
    "end": "259160"
  },
  {
    "text": "Once we have the evaluations for each \nprediction, we can graph each prediction.",
    "start": "259160",
    "end": "266160"
  },
  {
    "text": "Our chart shows each of \nour six zero shot forecasts  ",
    "start": "266160",
    "end": "269960"
  },
  {
    "text": "shown in green and the actual time series data,",
    "start": "269960",
    "end": "273800"
  },
  {
    "text": "the blue Line.",
    "start": "273800",
    "end": "275120"
  },
  {
    "text": "For each forecast, we can see the \nmean forecast as the green line.",
    "start": "275120",
    "end": "280040"
  },
  {
    "text": "The boundaries of the 50% prediction interval in  ",
    "start": "280040",
    "end": "283200"
  },
  {
    "text": "dark green and the boundaries of the 90% \nprediction interval in lighter green.",
    "start": "283200",
    "end": "289280"
  },
  {
    "text": "These prediction intervals show us how certain \nour model is about the forecast at each step.",
    "start": "289280",
    "end": "294800"
  },
  {
    "text": "This is an advantage of a probabilistic model.",
    "start": "294800",
    "end": "297639"
  },
  {
    "text": "It will show us how certain it \nis at each step in the forecast.",
    "start": "297640",
    "end": "302520"
  },
  {
    "text": "So what does this mean for my new plan?",
    "start": "302520",
    "end": "305199"
  },
  {
    "text": "To be cautious?",
    "start": "305200",
    "end": "306320"
  },
  {
    "text": "I think any time the 50% prediction interval \nindicates a frost, I'll take the plant inside.",
    "start": "306320",
    "end": "312360"
  },
  {
    "text": "By this measure, the Lag-Llama model performs \npretty well at predicting an overnight forecast.",
    "start": "312360",
    "end": "318840"
  },
  {
    "text": "For example, in this first chart for \nNovember 24th, the model predicts  ",
    "start": "318840",
    "end": "324480"
  },
  {
    "text": "within the 50% prediction interval that the \novernight temperature will go below freezing.",
    "start": "324480",
    "end": "330120"
  },
  {
    "text": "And it does.",
    "start": "330120",
    "end": "331280"
  },
  {
    "text": "We can see that the blue line tracks \nfairly closely to the green predicted line.",
    "start": "331280",
    "end": "337320"
  },
  {
    "text": "This is also reflected in our low \nMAPE for this day's predictions.",
    "start": "337320",
    "end": "343560"
  },
  {
    "text": "For the date of November 28th.",
    "start": "343560",
    "end": "346240"
  },
  {
    "text": "We see a less accurate forecast \nfrom the model on this day.",
    "start": "346240",
    "end": "350120"
  },
  {
    "text": "The overnight temperature drops \nto the coldest yet this season.",
    "start": "350120",
    "end": "354240"
  },
  {
    "text": "For this prediction, we see \nthe actual temperature ends  ",
    "start": "354240",
    "end": "357759"
  },
  {
    "text": "up within the 90% prediction interval, but \nmostly misses the 50% prediction interval.",
    "start": "357760",
    "end": "364680"
  },
  {
    "text": "But following my guideline to \ntake the plant inside any time  ",
    "start": "364680",
    "end": "368440"
  },
  {
    "text": "the 50% prediction interval goes below freezing,",
    "start": "368440",
    "end": "372240"
  },
  {
    "text": "I would have saved my plant on this day, so \nit's not bad performance overall from the model.",
    "start": "372240",
    "end": "378240"
  },
  {
    "text": "Based on the results with my new outdoor plant.",
    "start": "378240",
    "end": "381080"
  },
  {
    "text": "We can see that foundation models hold \npromise for time series forecasting.",
    "start": "381080",
    "end": "386080"
  },
  {
    "text": "While we've seen a lot of applications \nfor the use of generative AI",
    "start": "386080",
    "end": "389599"
  },
  {
    "text": "and foundation models for LLMs,  ",
    "start": "389600",
    "end": "392160"
  },
  {
    "text": "applying these approaches to time series \nforecasting is still a developing field.",
    "start": "392160",
    "end": "397621"
  }
]
[
  {
    "start": "0",
    "end": "54000"
  },
  {
    "text": "Can models officially reason now? They have risk levels for models. I think, uh, we're still good.",
    "start": "600",
    "end": "5720"
  },
  {
    "text": "So no terminators inside. Are agents as a service, the new software as a service? Agents are going to be everywhere.",
    "start": "5720",
    "end": "12000"
  },
  {
    "text": "And multi agents, uh, you know, operating in teams and crews, multi agent collaboration is going to be huge.",
    "start": "12000",
    "end": "18080"
  },
  {
    "text": "Are LLMs the true unlock for personalization? We came up with the notion that an active league is a happy league.",
    "start": "18080",
    "end": "30279"
  },
  {
    "text": "I'm Bryan Casey and I'm joined this week by a world class panel of experts across engineering, research, and product, and we're",
    "start": "30280",
    "end": "36480"
  },
  {
    "text": "excited to get into this week's news in AI. This week we have Nathalie Baracaldo, Senior Research Scientist, Master Inventor.",
    "start": "36480",
    "end": "43760"
  },
  {
    "text": "Aaron Baughman, IBM Fellow, Master Inventor, and Chris Hay, Distinguished",
    "start": "43760",
    "end": "48880"
  },
  {
    "text": "Engineer, CTO, Customer Transformation.",
    "start": "48880",
    "end": "56560"
  },
  {
    "start": "54000",
    "end": "1104000"
  },
  {
    "text": "Alright, so, as every week, we start out with a quick, hot take question. And this week's question is,",
    "start": "56560",
    "end": "62840"
  },
  {
    "text": "Was o1 Preview worth the hype? We'll start with you, Chris. I live for the hype, and",
    "start": "62840",
    "end": "68400"
  },
  {
    "text": "I wait for the next model. You know, where's my new model? It's been a week already, so it makes sense. Um, Aaron, what about you?",
    "start": "68400",
    "end": "74480"
  },
  {
    "text": "Um, yeah, I think scientifically this whole chain of thought, allowing systems to teach itself, is very interesting.",
    "start": "74480",
    "end": "80040"
  },
  {
    "text": "Um, but I need to wait and see how it works out in the implementation details in the application space.",
    "start": "80040",
    "end": "85880"
  },
  {
    "text": "And Nathalie, I think the new model, it's really interesting from the security perspective, some of the metrics that they show",
    "start": "85880",
    "end": "92360"
  },
  {
    "text": "really demonstrate improvement. So I'm very excited about it. All right, well, let's jump right into it.",
    "start": "92360",
    "end": "98440"
  },
  {
    "text": "And actually, that's going to be our first topic this week. So it was funny. So this model released last Thursday,",
    "start": "98440",
    "end": "105079"
  },
  {
    "text": "actually, and there's a little inside baseball for our listeners on the show, we should record this show.",
    "start": "105080",
    "end": "110400"
  },
  {
    "text": "On thursdays every week, um, and then we go into production and we release the show",
    "start": "110400",
    "end": "115440"
  },
  {
    "text": "friday morning This one week we didn't do that And we actually recorded the show on wednesday and then of course the model came",
    "start": "115440",
    "end": "121439"
  },
  {
    "text": "out on thursday so that's just the way of the world but Um, this was an announcement that",
    "start": "121440",
    "end": "126840"
  },
  {
    "text": "has been hyped for a long time for anybody who's on Uh, you know twitter or x You've",
    "start": "126840",
    "end": "132480"
  },
  {
    "text": "seen the memes around strawberry for what feels like an eternity, um, at, at this point.",
    "start": "132480",
    "end": "139640"
  },
  {
    "text": "Um, and then it's finally here. It happened. The model arrived, um, and it wasn't, you know, just released as a blog post.",
    "start": "139640",
    "end": "145400"
  },
  {
    "text": "It was actually rolled out, um, to, to the broad user base within their, uh, within chat",
    "start": "145400",
    "end": "150680"
  },
  {
    "text": "GPT and I think some of the API as, as well. Um, and the interesting thing about this model is that it introduced chain",
    "start": "150680",
    "end": "158200"
  },
  {
    "text": "of thought and reinforcement learning techniques Um into the model itself. So not as a way to interact with the model",
    "start": "158200",
    "end": "164519"
  },
  {
    "text": "but as a way that is an embedded capability inside of the model, which is um Definitely",
    "start": "164520",
    "end": "169920"
  },
  {
    "text": "kind of a new approach, um there and we've seen pretty important and noteworthy",
    "start": "169920",
    "end": "175200"
  },
  {
    "text": "improvements in reasoning capability as a result from that and so maybe just because Aaron because you You Um, touched",
    "start": "175200",
    "end": "182160"
  },
  {
    "text": "on this specifically in your first answer. Um, I actually just want to start with the The",
    "start": "182160",
    "end": "188720"
  },
  {
    "text": "interesting kind of science around including chain of thought and reinforcement learning techniques within the model itself And just like",
    "start": "188720",
    "end": "195920"
  },
  {
    "text": "get your reaction to that and why it's important the things that are exciting to you about it And maybe you know, you raised a couple questions",
    "start": "195920",
    "end": "202640"
  },
  {
    "text": "Um, even in your initial answer, but like some of the things that you're still waiting to see Yeah, I think it's really fascinating",
    "start": "202640",
    "end": "208720"
  },
  {
    "text": "how, you know, chain of thought it was really introduced in 2022, and it's just accelerated and expanded to become the self",
    "start": "208720",
    "end": "215123"
  },
  {
    "text": "education for large language models by 2023. And here we are today with strawberry, you know,",
    "start": "215123",
    "end": "220920"
  },
  {
    "text": "so it's great how fast technology is moving. And what I really like about this is that",
    "start": "220920",
    "end": "227120"
  },
  {
    "text": "These chain of thoughts, it helps us to introspect the mind of a jet generative A.",
    "start": "227120",
    "end": "232860"
  },
  {
    "text": "I.\nSystem. And what happens is, is that, you know, you might seed a system with",
    "start": "232860",
    "end": "238840"
  },
  {
    "text": "problems and answers so that you know whether the chain of thought helped. to induce the right answer.",
    "start": "238840",
    "end": "244800"
  },
  {
    "text": "And then later, um, you can keep iterating over and over and over with these chains of thoughts, with newer variations of the",
    "start": "244800",
    "end": "251560"
  },
  {
    "text": "problem, so it learns new skills over time. And you create variations of these problems, and",
    "start": "251560",
    "end": "257440"
  },
  {
    "text": "you have almost like a panel of these generative AIs, um, answering with different strategies.",
    "start": "257440",
    "end": "264240"
  },
  {
    "text": "And if all of the answers align towards, um, you know, that's the same answer,",
    "start": "264240",
    "end": "269720"
  },
  {
    "text": "even though you don't have a ground truth, then more than likely the chain of thought is working because it's converging",
    "start": "269720",
    "end": "274880"
  },
  {
    "text": "towards, uh, a less variant type answer. And through all of this looping, we have",
    "start": "274880",
    "end": "280400"
  },
  {
    "text": "these gradient updates so that it can learn, you know, uh, more and more, you know, so we have gradient updating and",
    "start": "280400",
    "end": "285960"
  },
  {
    "text": "we have in context learning put together. But, um, the last thing I'll mention is that what I really liked is how",
    "start": "285960",
    "end": "292199"
  },
  {
    "text": "they broke out reinforcement learning as what they call train time compute. Um, and then they have this",
    "start": "292200",
    "end": "297879"
  },
  {
    "text": "thinking time as test time compute. You know, so the thinking time is kind of when it iterates, and it's passing",
    "start": "297880",
    "end": "303720"
  },
  {
    "text": "these many chains of thoughts, you know, along, you know, and then, um, the train",
    "start": "303720",
    "end": "309280"
  },
  {
    "text": "time is where it's doing this in context learning and perhaps doing, you know, some, uh, you know, fine tuning, um, in there.",
    "start": "309280",
    "end": "316040"
  },
  {
    "text": "That's great. And Chris, I know you in particular have been, you know, I've been following you",
    "start": "316040",
    "end": "321320"
  },
  {
    "text": "following this, um, on Twitter as well. So, you know, maybe give you some space to have like a more open ended kind of reaction,",
    "start": "321320",
    "end": "328680"
  },
  {
    "text": "um, to, to just the release of this and, you know, the extent to which like it, it was, it wasn't what you were expecting it to be, but",
    "start": "328680",
    "end": "335080"
  },
  {
    "text": "would love to just get your, um, your thoughts. I thought it was super interesting. I mean, just to sort of go on sort",
    "start": "335080",
    "end": "342400"
  },
  {
    "text": "of some of Aaron's points there. The reinforcement learning part is really interesting.",
    "start": "342400",
    "end": "347600"
  },
  {
    "text": "So if you think of the chain of thoughts for a second, then if you're solving something",
    "start": "347600",
    "end": "352840"
  },
  {
    "text": "like a puzzle, so maybe you want to Get it to solve a Sudoku grid, or maybe you want it to, uh, calculate, you know, how, which",
    "start": "352840",
    "end": "360800"
  },
  {
    "text": "book, if Phileas Fogg was listening to the Harry Potter books, and, uh, what book would",
    "start": "360800",
    "end": "367360"
  },
  {
    "text": "he be on by the time he got to India, right? If you think of those sort of questions, then, yeah.",
    "start": "367360",
    "end": "372680"
  },
  {
    "text": "The answer isn't actually the important part, of course you want an accurate answer. The big thing you really want to do",
    "start": "372680",
    "end": "378360"
  },
  {
    "text": "is, is reason in the correct way. And the sort of things that you want the model to be able to do is, sort of calculate the",
    "start": "378360",
    "end": "384800"
  },
  {
    "text": "distance to, uh, India, for example, calculate the sleep time of Phileas Fogg, how long the",
    "start": "384800",
    "end": "390840"
  },
  {
    "text": "Harry Potter books are, and then be able to sort of validate those steps all the way across.",
    "start": "390840",
    "end": "396040"
  },
  {
    "text": "And, and that would be similar for something like validating a Sudoku puzzle, right? Okay. You want to check the horizontals, the",
    "start": "396040",
    "end": "401560"
  },
  {
    "text": "verticals, the sub mini grids, etc. Check each individual number and then see if there's any duplications.",
    "start": "401560",
    "end": "408720"
  },
  {
    "text": "That logic is more important than just trying to predict what your next token is. So if you think of reinforcement learning there,",
    "start": "408720",
    "end": "416400"
  },
  {
    "text": "The reward model that you could have there on training time can be a lot more accurate, right? You can give higher rewards for",
    "start": "416400",
    "end": "422600"
  },
  {
    "text": "each step that it calculates and then, uh, how it gets it right. And that means that you can actually",
    "start": "422600",
    "end": "428360"
  },
  {
    "text": "train the model towards doing the right type of chain of thought over time.",
    "start": "428360",
    "end": "433800"
  },
  {
    "text": "So I actually think that is the proper innovation there. The other thing that I see there is",
    "start": "433800",
    "end": "440520"
  },
  {
    "text": "this, this shift to inference time. And I really like that. It takes sort of. 32 seconds, whatever.",
    "start": "440520",
    "end": "446880"
  },
  {
    "text": "I suspect that there is some sort of tree search going on there. I suspect they're generating",
    "start": "446880",
    "end": "452400"
  },
  {
    "text": "multiple chains of thought. I suspect that as you go down each node of the tree, you're then probably iterating",
    "start": "452400",
    "end": "459080"
  },
  {
    "text": "that further to get to some of these answers. Hence why the thinking time will increase. And then Aaron says that's going to",
    "start": "459080",
    "end": "464360"
  },
  {
    "text": "feed back into the training model. later, but I, I think it's super exciting because it's that push towards, uh,",
    "start": "464360",
    "end": "471400"
  },
  {
    "text": "inference and being able to scale out there. Now you could argue that we have that already with agents, but in order for that",
    "start": "471400",
    "end": "478680"
  },
  {
    "text": "to work well with agents, you need to back that up with the reinforcement learning. You need to feed that training data back into",
    "start": "478680",
    "end": "485320"
  },
  {
    "text": "the model because if the model can't generate good chain of thought, then you're, you're not going to do very well in your agentic approach.",
    "start": "485320",
    "end": "491880"
  },
  {
    "text": "So for me. I find it highly satisfying. All right, and Nathalie, just to bring you in here a little bit, like you",
    "start": "491880",
    "end": "498080"
  },
  {
    "text": "mentioned some of the safety aspects. That was definitely, um, a thing they highlighted as well.",
    "start": "498080",
    "end": "503840"
  },
  {
    "text": "Like maybe as a way of, I have a couple questions on that, but maybe as a starting point, I'd love to hear your take on like the extent to which you",
    "start": "503840",
    "end": "510840"
  },
  {
    "text": "think that Capabilities, alignment and safety are like becoming the same problem.",
    "start": "510840",
    "end": "516279"
  },
  {
    "text": "Um, space. It's like, you know, can we just make this model do what we want to want it to do? And you solve all sorts of questions there.",
    "start": "516280",
    "end": "522640"
  },
  {
    "text": "Or do you can like look at them as kind of more distinct domains? That's a great question.",
    "start": "522640",
    "end": "528519"
  },
  {
    "text": "I think one aspect that really improves with this model is that before in AI, we had the",
    "start": "528520",
    "end": "534360"
  },
  {
    "text": "issue of having models that are black box, black box, meaning you And we tried in the",
    "start": "534360",
    "end": "540720"
  },
  {
    "text": "community to really inspect them, introspect them, try to check the activation, see how they",
    "start": "540720",
    "end": "546000"
  },
  {
    "text": "react to different inputs and stuff like that. But this model allows us to have something slightly different, and it's",
    "start": "546000",
    "end": "552839"
  },
  {
    "text": "that ability to introspect how it came back with a decision, with an answer.",
    "start": "552840",
    "end": "558400"
  },
  {
    "text": "So, uh, from that perspective, and to answer your question, I think, uh, there",
    "start": "558400",
    "end": "565200"
  },
  {
    "text": "may be some questions and answers, a lot of things that get touched upon, and I,",
    "start": "565200",
    "end": "571000"
  },
  {
    "text": "we only have one single model, so probably what's happening, uh, is that we're going to be mixing all these things together.",
    "start": "571000",
    "end": "577920"
  },
  {
    "text": "The training data contains a lot of different aspects of safety. I think, uh, it's important to cover all of",
    "start": "577920",
    "end": "585079"
  },
  {
    "text": "them as much as possible, but, uh, overall the main that makes this model so unique from",
    "start": "585080",
    "end": "591760"
  },
  {
    "text": "my perspective is that introspect without having to look into activations that we",
    "start": "591760",
    "end": "597960"
  },
  {
    "text": "humans are not super great at interpreting. So that is a part of the, I think, uh,",
    "start": "597960",
    "end": "604880"
  },
  {
    "text": "exciting aspects from security perspective. Uh, the other interesting perspective",
    "start": "604880",
    "end": "610120"
  },
  {
    "text": "that I think that I thought it was really interesting is that When we measure safety, we oftentimes have different",
    "start": "610120",
    "end": "617480"
  },
  {
    "text": "perspectives as you were alluding to. So we measure things like jailbreaking attacks, hallucinations.",
    "start": "617480",
    "end": "624160"
  },
  {
    "text": "We, uh, verify that, uh, the model is not going to insult anyone,",
    "start": "624160",
    "end": "629600"
  },
  {
    "text": "uh, fairness, all sorts of things. So if we see some of these aspects, for",
    "start": "629600",
    "end": "635200"
  },
  {
    "text": "example, jailbreaking attacks, that was one of the metrics that got improved.",
    "start": "635200",
    "end": "640560"
  },
  {
    "text": "Uh, maybe I'm talking too much, but, uh, I would say that I was really, really impressed with the fact that the community",
    "start": "640560",
    "end": "648400"
  },
  {
    "text": "is trying to really incorporate more and more, um, cutting edge benchmarks to",
    "start": "648400",
    "end": "654840"
  },
  {
    "text": "try to understand how the model behaves. Because one thing that happens with",
    "start": "654840",
    "end": "660160"
  },
  {
    "text": "benchmarks in this space is that they arrive today, people kind of overfeed to them.",
    "start": "660160",
    "end": "666280"
  },
  {
    "text": "And, uh, the jailbreaking attacks, uh, will happen the same, and things, uh, and all other",
    "start": "666280",
    "end": "671320"
  },
  {
    "text": "benchmarks are also kind of, uh, having that issue that people really overfeed to them.",
    "start": "671320",
    "end": "676440"
  },
  {
    "text": "So I was, uh, really impressed and continue to be impressed with the security community, the iSecurity community, try to push the",
    "start": "676440",
    "end": "682639"
  },
  {
    "text": "boundaries, have more red teaming, have more interesting stuff, uh, uh, things to throw at these models to test it out.",
    "start": "682640",
    "end": "690279"
  },
  {
    "text": "So overall, I'm very hopeful from the security perspective with this model and it",
    "start": "690280",
    "end": "696160"
  },
  {
    "text": "opens lots and lots of opportunities for us. I have a question for Nathalie.",
    "start": "696160",
    "end": "701600"
  },
  {
    "text": "So when I read the paper on this, they said that in the testing of the model, They were",
    "start": "701600",
    "end": "708840"
  },
  {
    "text": "playing a capture the flag scenario with the model, and the goal the model had was to",
    "start": "708840",
    "end": "714120"
  },
  {
    "text": "capture the flag like a security thing, but then the container was down, so the model broke out of the host and then restarted the",
    "start": "714120",
    "end": "721800"
  },
  {
    "text": "container so it could capture the flag, right? Very goal oriented. So I'm just like your take on that, Nathalie,",
    "start": "721800",
    "end": "728640"
  },
  {
    "text": "from a kind of security perspective. Yeah, this starts to looking like",
    "start": "728640",
    "end": "733960"
  },
  {
    "text": "Terminator sort of thing is going. Um, I think it's impressive.",
    "start": "733960",
    "end": "740519"
  },
  {
    "text": "First of all. The way the model it's trying to find out there it's way around to solve the issues.",
    "start": "740520",
    "end": "746360"
  },
  {
    "text": "Uh, sometimes it's going to do stuff like that, that, uh, it's not necessarily",
    "start": "746360",
    "end": "752120"
  },
  {
    "text": "the solution of a simple solution. Um, but overall, I think, uh, the risk",
    "start": "752120",
    "end": "758320"
  },
  {
    "text": "level, they have risk levels for models. I think, uh, we're still good. So no terminators inside.",
    "start": "758320",
    "end": "763760"
  },
  {
    "text": "We're good from the security perspective. Um, does that answer? And also curious to know what.",
    "start": "763760",
    "end": "771240"
  },
  {
    "text": "Aaron has to say about that, because it's such an interesting question. I mean, yeah, these are really great",
    "start": "771240",
    "end": "776880"
  },
  {
    "text": "questions and open ended discussions. And, um, one of the areas that I found,",
    "start": "776880",
    "end": "782160"
  },
  {
    "text": "um, interesting would be these air avalanches, because during this chain of thought reasoning, you know, you're always",
    "start": "782160",
    "end": "788720"
  },
  {
    "text": "pushing forward the chain of thought. And, If at step zero you have an error, then",
    "start": "788720",
    "end": "794040"
  },
  {
    "text": "that error could populate all the way to step n or n plus one, and it just creates this cascade of problems that could happen,",
    "start": "794040",
    "end": "802600"
  },
  {
    "text": "um, that might be harder to uncover than a hallucination, because You know, you have these",
    "start": "802600",
    "end": "808640"
  },
  {
    "text": "large outputs of change of thoughts, if you can even see them, because I know Strawberry, you know, in this case has hidden them from us.",
    "start": "808640",
    "end": "815959"
  },
  {
    "text": "You know, they, they made that deliberate choice. But, you know, but, but I know",
    "start": "815960",
    "end": "821279"
  },
  {
    "text": "that there are some, some work in academia, potentially industry now about looking at consistency, right?",
    "start": "821280",
    "end": "827400"
  },
  {
    "text": "Can these models consistently get answers, um, correct? And, you know, that's one way, um,",
    "start": "827400",
    "end": "833400"
  },
  {
    "text": "but I'm looking forward to seeing how Strawberry really handles that. And as more and more people use it.",
    "start": "833400",
    "end": "838640"
  },
  {
    "text": "How big of a problem, you know, is this, you know, this cascading error or this avalanche of, of errors that, that could",
    "start": "838640",
    "end": "845200"
  },
  {
    "text": "happen, um, along their, uh, reasoning. And, and Aaron, I think that's a really relevant",
    "start": "845200",
    "end": "850520"
  },
  {
    "text": "point if you have a single chain of thought that you're iterating down, but I'm not. I'm not convinced that that is the case.",
    "start": "850520",
    "end": "858360"
  },
  {
    "text": "I, I, I could be totally wrong. We're just guessing. We're just sort of trying to look at it from the outside.",
    "start": "858360",
    "end": "863840"
  },
  {
    "text": "But I, I really feel there's multiple chains of thought that's being generated there. And they're doing some sort of search",
    "start": "863840",
    "end": "869840"
  },
  {
    "text": "on that to be able to, to aggregate it. So, so if they are doing that, and I think they are, could be wrong, then there",
    "start": "869840",
    "end": "877400"
  },
  {
    "text": "might be less chance of that over time. Because at least it's got other options to take, uh, down that",
    "start": "877400",
    "end": "883560"
  },
  {
    "text": "path and aggregate it a little bit. But, but even then with the reinforcement learning to the point, then hopefully during",
    "start": "883560",
    "end": "890519"
  },
  {
    "text": "training, a lot of that would be taken away because, you know, the reward model will be sort",
    "start": "890520",
    "end": "895640"
  },
  {
    "text": "of pushing it in the right direction over time. But yeah, but it's a really great take. Yeah.\nOne other point I wanted to make too is",
    "start": "895640",
    "end": "901680"
  },
  {
    "text": "that, um, just the thinking time, the inference, I noticed that it took 10 hours. That they gave it 10 hours to solve",
    "start": "901680",
    "end": "908080"
  },
  {
    "text": "like six algorithmic problems and you know, that's a lot of time, right? And so so I think i'm i'm also curious to to",
    "start": "908080",
    "end": "915200"
  },
  {
    "text": "learn as you know We get our hands how much time, you know, what's the trade off, you know time versus speed, you know of response You",
    "start": "915200",
    "end": "922720"
  },
  {
    "text": "know and and and learn more about that as well. So i'm just really excited about you know, strawberry",
    "start": "922720",
    "end": "929000"
  },
  {
    "text": "I think that point on the length of time it takes for some of these answers to me draws This",
    "start": "929000",
    "end": "935080"
  },
  {
    "text": "like interesting scenario where kind of like the LLM router patterns, um, are going to become even more pronounced where it's like you're",
    "start": "935080",
    "end": "941839"
  },
  {
    "text": "going to want small fast models that are cheap and low latency to do certain types of tasks. And then when you have to offloading them",
    "start": "941840",
    "end": "948920"
  },
  {
    "text": "to these bigger, longer, more expensive, um, sort of, um, sort of scenarios.",
    "start": "948920",
    "end": "954560"
  },
  {
    "text": "The last question I have on this, cause I, I, I don't want to, I want to have one more question that's kind of like a.",
    "start": "954560",
    "end": "960399"
  },
  {
    "text": "More existential question, um, that I would love to get the panel's, uh, take on, uh, on this topic, which is, on a lot, many of",
    "start": "960400",
    "end": "966880"
  },
  {
    "text": "these benchmarks, it's now exceeding PhD level intelligence, um, and not to out myself here, I",
    "start": "966880",
    "end": "975280"
  },
  {
    "text": "consider myself a reasonably, like, economically productive person in society, but I do not have",
    "start": "975280",
    "end": "981120"
  },
  {
    "text": "PhD level intelligence on all of these tasks. And one of the really like interesting reactions",
    "start": "981120",
    "end": "987399"
  },
  {
    "text": "from some of the folks I saw on Twitter who are actually like, like Rune, who's at OpenAI,",
    "start": "987400",
    "end": "993160"
  },
  {
    "text": "works in the lab, like came out afterwards and was talking about how He didn't even",
    "start": "993160",
    "end": "998320"
  },
  {
    "text": "think product was that important and that the only game was getting to self reinforcing and",
    "start": "998320",
    "end": "1004040"
  },
  {
    "text": "self improving artificial superintelligence. And the question I have is like, are people",
    "start": "1004040",
    "end": "1010080"
  },
  {
    "text": "just like, like, when do we expect, like, how capable do these models have to be before we actually see the transformative economic impact?",
    "start": "1010080",
    "end": "1017440"
  },
  {
    "text": "Yeah, so I think one of the aspects is, uh, what's the application and how",
    "start": "1017440",
    "end": "1023160"
  },
  {
    "text": "much you can trust the model to make sure that, you know, Children have hallucinations in aspects that are important.",
    "start": "1023160",
    "end": "1028919"
  },
  {
    "text": "So, um, I think to have real economic impact, we need use cases first that, uh, where we can fake",
    "start": "1028920",
    "end": "1036120"
  },
  {
    "text": "basically we can fail and we're safe failing and still increase the productivity of people.",
    "start": "1036120",
    "end": "1041959"
  },
  {
    "text": "So that's, uh, that's my take on this. And so, for example, It's going to",
    "start": "1041960",
    "end": "1047640"
  },
  {
    "text": "be one of those use cases where, for example, you have multiple smaller models and you can try to orchestrate.",
    "start": "1047640",
    "end": "1055320"
  },
  {
    "text": "Perhaps this very big model will help us, uh, would help us really orchestrating or",
    "start": "1055320",
    "end": "1061320"
  },
  {
    "text": "try to devise plans when they are difficult. But I think, uh, overall, the question",
    "start": "1061320",
    "end": "1068800"
  },
  {
    "text": "of, uh, Just get a big, big model that can do everything just by itself, uh,",
    "start": "1068800",
    "end": "1075720"
  },
  {
    "text": "that's, uh, uh, probably not going to break all the problems in, uh, the industry.",
    "start": "1075720",
    "end": "1081240"
  },
  {
    "text": "I think we need a bunch of smaller models and the agentic approach and perhaps have another top layer.",
    "start": "1081240",
    "end": "1087840"
  },
  {
    "text": "Um in there to to really understand the big context, but yeah, that's uh, how I see things.",
    "start": "1087840",
    "end": "1093919"
  },
  {
    "text": "So I really think uh, Industry wise things are going agentic. So smaller models working together",
    "start": "1093920",
    "end": "1105200"
  },
  {
    "start": "1104000",
    "end": "1780000"
  },
  {
    "text": "We talk about agents every week on this show like the theme the show is just like we should just call it the agent",
    "start": "1105200",
    "end": "1110320"
  },
  {
    "text": "show uh at this point, um, but let's talk a little bit about Salesforce.",
    "start": "1110320",
    "end": "1116600"
  },
  {
    "text": "Um, and agent force. The thing that is almost most notable about this company is that I don't want to say maybe",
    "start": "1116600",
    "end": "1122680"
  },
  {
    "text": "they invented, but like they popularize SaaS. Um, right? Like they were the ogs of SaaS.",
    "start": "1122680",
    "end": "1129160"
  },
  {
    "text": "And what happened like over the last, you know, 15, 20 years is that basically",
    "start": "1129160",
    "end": "1135120"
  },
  {
    "text": "all of traditional software Somebody came along and disrupted each and every single",
    "start": "1135120",
    "end": "1140159"
  },
  {
    "text": "one of those categories with like a SaaS version of whatever that product was, right? And that happened in basically",
    "start": "1140160",
    "end": "1146400"
  },
  {
    "text": "every category across the industry. Um, there was this piece written by a a 16 Z that was talking about, um,",
    "start": "1146400",
    "end": "1155000"
  },
  {
    "text": "the death of the sales force, not. The death of sales force of the sales force, uh, and talking about more agentic",
    "start": "1155000",
    "end": "1162040"
  },
  {
    "text": "approaches, um, to, to this particular space and they did not believe actually",
    "start": "1162040",
    "end": "1168919"
  },
  {
    "text": "that like the incumbents had an advantage. They thought the entire space would be so radically transformed",
    "start": "1168920",
    "end": "1175720"
  },
  {
    "text": "by these capabilities that. It would be disrupted by new, new entrance into the market, um, essentially.",
    "start": "1175720",
    "end": "1182720"
  },
  {
    "text": "And I think that, that sort of dynamic is what's driving and propelling, um, Salesforce to do.",
    "start": "1182720",
    "end": "1189120"
  },
  {
    "text": "And a lot of the things that it's been doing, um, and the things that are announced this week, even, um, but the maybe as a question, as a",
    "start": "1189120",
    "end": "1196200"
  },
  {
    "text": "starting point, and maybe I'll flip it over to you, is do you think what played out in S?",
    "start": "1196200",
    "end": "1203600"
  },
  {
    "text": "Is going to play out with like AI and agents to like is every category going to",
    "start": "1203600",
    "end": "1209320"
  },
  {
    "text": "get threatened or disruptive by like an AI native version of that particular space?",
    "start": "1209320",
    "end": "1215720"
  },
  {
    "text": "Like, is that where we're going? And is like a Salesforce trying to again be the first one to do this?",
    "start": "1215720",
    "end": "1222320"
  },
  {
    "text": "Absolutely, next question. I'm joking. We got about 10 minutes, man.",
    "start": "1222320",
    "end": "1228400"
  },
  {
    "text": "Like, you know. So I think, I love what Salesforce is doing there, right? So I think the agent force thing",
    "start": "1228400",
    "end": "1234640"
  },
  {
    "text": "is absolutely spot on, right? Because they're effectively um, Speeding up the productivity, right?",
    "start": "1234640",
    "end": "1241120"
  },
  {
    "text": "So it's no different from kind of deterministic automation that you would do in these platforms today.",
    "start": "1241120",
    "end": "1246600"
  },
  {
    "text": "And now you're getting the agents to perform that. So anybody can compose an agent that performs a task and do it really quickly.",
    "start": "1246600",
    "end": "1253559"
  },
  {
    "text": "Um, agents are going to be everywhere. And multi agents, uh, you know, operating in teams and crews, multi",
    "start": "1253560",
    "end": "1259899"
  },
  {
    "text": "agent collaboration is going to be huge. The, and I did a video on this about a year and a half ago, and I think this is true.",
    "start": "1259900",
    "end": "1266240"
  },
  {
    "text": "I think we're heading towards a world of agent marketplaces. So you're going to go home and you're",
    "start": "1266240",
    "end": "1272440"
  },
  {
    "text": "going to have an agent that's good at translation into a native language. You're going to have an agent that is going to be good at performing a",
    "start": "1272440",
    "end": "1279360"
  },
  {
    "text": "particular task, an agent that, you know, can do benefit calculations. Every single task that you can imagine,",
    "start": "1279360",
    "end": "1285640"
  },
  {
    "text": "there will be an agent at some point. That can perform that task. So therefore, if you think about what Salesforce",
    "start": "1285640",
    "end": "1291400"
  },
  {
    "text": "has done there in their world, what they've created as an agent marketplace for within their SAS platform, that is cool, right?",
    "start": "1291400",
    "end": "1298559"
  },
  {
    "text": "Anybody can go and compose those agents and bring that together and sort of, you know, solve these tasks really quickly.",
    "start": "1298560",
    "end": "1305280"
  },
  {
    "text": "But that's not going to be limited to Salesforce, and it's not going to be limited to individual organizations that's",
    "start": "1305280",
    "end": "1310920"
  },
  {
    "text": "going to come out into the real world. In the same way as we have platforms like Fiverr, we're going to have.",
    "start": "1310920",
    "end": "1316480"
  },
  {
    "text": "Agent or and then, you know, people will be able to go and buy those tasks from those agents and",
    "start": "1316480",
    "end": "1322520"
  },
  {
    "text": "it's going to be it's it's going to be a rush. Right?\nAnd who are the companies that are going to be truly at the forefront is going to be",
    "start": "1322520",
    "end": "1331040"
  },
  {
    "text": "people who have the better data, who have the faster agents, the cheaper agents, and they're going to sort of dominate that.",
    "start": "1331040",
    "end": "1336960"
  },
  {
    "text": "So I actually think that The, the big tech companies are going to enter into that",
    "start": "1336960",
    "end": "1342320"
  },
  {
    "text": "space, uh, Salesforce being one of them. But I, I see this as a world marketplace. I don't see this being a company thing.",
    "start": "1342320",
    "end": "1349040"
  },
  {
    "text": "And maybe as like building on that a little bit, which the data point is particularly interesting",
    "start": "1349040",
    "end": "1355279"
  },
  {
    "text": "where some of the discussion I actually saw that was in the original post from a 16 Z was actually talking about how they thought Even",
    "start": "1355280",
    "end": "1363159"
  },
  {
    "text": "some of the incumbents only had actually a slice of the data that was going to be relevant",
    "start": "1363160",
    "end": "1369120"
  },
  {
    "text": "in the future because people are treating It like they have all that data But their belief that in like some of these customer service and",
    "start": "1369120",
    "end": "1374520"
  },
  {
    "text": "experience, uh domains that like multi modal data Um that is not true and even unstructured",
    "start": "1374520",
    "end": "1380280"
  },
  {
    "text": "data things that are not necessarily the core of how these things are powered today Will",
    "start": "1380280",
    "end": "1385679"
  },
  {
    "text": "become the core of how they were powered today. So the data advantage there, but it's not",
    "start": "1385680",
    "end": "1392440"
  },
  {
    "text": "as pronounced as people thought it was. Um, this is one hypothesis, um, at least,",
    "start": "1392440",
    "end": "1397800"
  },
  {
    "text": "but like Aaron or Nathalie, I'm curious the extent to which you think that, um, you",
    "start": "1397800",
    "end": "1403440"
  },
  {
    "text": "know, some of these other data sources are going to be represent both opportunities for like new entrants in these categories",
    "start": "1403440",
    "end": "1410440"
  },
  {
    "text": "and, or things that are just like, You know, some of the existing providers are gonna have no problem just like adding a",
    "start": "1410440",
    "end": "1416280"
  },
  {
    "text": "new data set into their existing platforms. Yeah, I mean, I mean, um, I always take a",
    "start": "1416280",
    "end": "1421680"
  },
  {
    "text": "step back and ask myself, what is an agent? You know, and to me, an agent is a process",
    "start": "1421680",
    "end": "1427360"
  },
  {
    "text": "I can perform a task that could otherwise be done by a human or even another agent. And then this gets to meta agents where an",
    "start": "1427360",
    "end": "1433360"
  },
  {
    "text": "agent can create yet another agent, right? And. And, and there's a couple of paradigms,",
    "start": "1433360",
    "end": "1438720"
  },
  {
    "text": "you know, and, and the two I'll stick with is sort of, you know, um, gives you a continuum in between.",
    "start": "1438720",
    "end": "1443840"
  },
  {
    "text": "But the first one is environmental centric agents. But these are agents that reason and",
    "start": "1443840",
    "end": "1448920"
  },
  {
    "text": "think and plan after each action. So they think, act and observe.",
    "start": "1448920",
    "end": "1453600"
  },
  {
    "text": "Um, and then the other one would be a human centric where they reason without observations, where they plan up front and they don't really",
    "start": "1454240",
    "end": "1460000"
  },
  {
    "text": "need output from tools in order to take action. And then there's anything. In between, right?",
    "start": "1460000",
    "end": "1465400"
  },
  {
    "text": "There's there's a polls and and it seems like that the data aspect it depends on",
    "start": "1465400",
    "end": "1471440"
  },
  {
    "text": "the use case of which the environment or of which the agent is going to operate within a given environment, right?",
    "start": "1471440",
    "end": "1477760"
  },
  {
    "text": "Is it more of a reactive kind of agent based on a signal that comes from a device?",
    "start": "1477760",
    "end": "1483600"
  },
  {
    "text": "where you don't really necessarily need a lot of, um, external data to create a reaction, or is it more of a rich textual",
    "start": "1483600",
    "end": "1491480"
  },
  {
    "text": "piece of which it needs to generate new information, um, and provide it back to a human or even to another agent, right?",
    "start": "1491480",
    "end": "1498600"
  },
  {
    "text": "Which could be instead of human centric, maybe we say it's agent slash human centric, right? Um, but it, but it's, it's, it's really",
    "start": "1498600",
    "end": "1504720"
  },
  {
    "text": "neat, uh, where all this is going. And, um, And I do think that, you know, there's different approaches of RAG, you know, um, that",
    "start": "1504720",
    "end": "1511840"
  },
  {
    "text": "we all know about where you can augment, um, uh, data pieces and, and to, um, context such that",
    "start": "1511840",
    "end": "1518800"
  },
  {
    "text": "it influences and informs what might output. But this might foreshadow another topic",
    "start": "1518800",
    "end": "1524200"
  },
  {
    "text": "we're going to, but I really like the machine unlearning, right, where you can, um, maybe, um, unlearn or erase from memory,",
    "start": "1524200",
    "end": "1532440"
  },
  {
    "text": "whether it's this hippocampus type memory or it's embedded in weights from all of these",
    "start": "1532440",
    "end": "1538440"
  },
  {
    "text": "generative AI pieces, but it kind of helps to focus in an agent on what they're meant",
    "start": "1538440",
    "end": "1543559"
  },
  {
    "text": "and supposed to do around their objectives. So they're sort of their their sneeze within a particular.",
    "start": "1543560",
    "end": "1549760"
  },
  {
    "text": "domain. So rather than being so broad and, and, and having this huge large language model with that's been trained and it has this",
    "start": "1549760",
    "end": "1556799"
  },
  {
    "text": "inherent data baked into it, you have these very narrow, smaller, uh, SME agents, right?",
    "start": "1556800",
    "end": "1563559"
  },
  {
    "text": "That, that are used that might be fine tuned in different ways. Maybe you're Removing data that's",
    "start": "1563560",
    "end": "1569559"
  },
  {
    "text": "already there that's been shared by these models that are open source. Are you adding data through rag",
    "start": "1569560",
    "end": "1575919"
  },
  {
    "text": "or fine tuning through rag with your own data that you might have? You know, so there's lots of permutations there.",
    "start": "1575920",
    "end": "1583200"
  },
  {
    "text": "And for Salesforce, I'm really excited that, you know, they're partnering with us, IBM to advance, you know, their products to make it",
    "start": "1583200",
    "end": "1590440"
  },
  {
    "text": "more open and trusted and to help think about these kinds of new architectures and agents and",
    "start": "1590440",
    "end": "1596279"
  },
  {
    "text": "how we're going to be using them data and plug and play pieces like Chris mentioned before.",
    "start": "1596280",
    "end": "1601880"
  },
  {
    "text": "Nathalie, maybe a question for you too, which is I think it was Chris that maybe you made this comment about, um, agents",
    "start": "1601880",
    "end": "1609680"
  },
  {
    "text": "versus like more deterministic workflows. Um, you know, and kind of that evolution over time.",
    "start": "1609680",
    "end": "1615440"
  },
  {
    "text": "Um, one of the things that I've seen a little bit, at least with some of the things that we've been doing is we've started with a lot of are using kind of Productionizing a",
    "start": "1615440",
    "end": "1623680"
  },
  {
    "text": "lot of like more internal use cases around the stuff that are like big improvements",
    "start": "1623680",
    "end": "1629000"
  },
  {
    "text": "and productivity, things like that. The interesting thing with Salesforce is some of the scenarios that they're talking about",
    "start": "1629000",
    "end": "1635120"
  },
  {
    "text": "are all customer facing things, which is, you know, that like changes the Calculus from a",
    "start": "1635120",
    "end": "1642440"
  },
  {
    "text": "risk perspective from a security perspective. Um, and I'm just I'm curious, Nathalie, how you think, how are how are people",
    "start": "1642440",
    "end": "1649120"
  },
  {
    "text": "going to approach the balance of, you know, kind of more deterministic workflows versus these more agentic ones?",
    "start": "1649120",
    "end": "1655240"
  },
  {
    "text": "That is a great question. Um, my perspective is the following. First, we need humans to know that",
    "start": "1655240",
    "end": "1663320"
  },
  {
    "text": "they are still important in this whole pipeline, because a lot of times when there are mistakes, uh, an expert would.",
    "start": "1663320",
    "end": "1670680"
  },
  {
    "text": "very much realize, uh, that there's something weird and there's something that doesn't quite feel right.",
    "start": "1670680",
    "end": "1676519"
  },
  {
    "text": "So I think, uh, first understanding the human and educating the human, like, hey, this is a tool, but just know that you",
    "start": "1676520",
    "end": "1683480"
  },
  {
    "text": "are potentially smarter than the tool. That's our first, first step. The second step is, uh, actually Understanding",
    "start": "1683480",
    "end": "1692200"
  },
  {
    "text": "when we want to explore solutions and when we want to explore the space versus when we",
    "start": "1692200",
    "end": "1698720"
  },
  {
    "text": "want something deterministic, for example, to retrieve a document that it's really relevant for certain types of questions, and we can",
    "start": "1698720",
    "end": "1705960"
  },
  {
    "text": "have a sort of pipeline that it's not as stochastic and that we know we want it that way.",
    "start": "1705960",
    "end": "1712880"
  },
  {
    "text": "So kind of setting up a paths within our spectrum of solutions so that when there's",
    "start": "1712880",
    "end": "1719000"
  },
  {
    "text": "something really critical, RAG and other types of technologies can be applied",
    "start": "1719000",
    "end": "1724920"
  },
  {
    "text": "so that we don't hallucinate widely. Uh, I think, uh, that's, um, that's a part of it.",
    "start": "1724920",
    "end": "1731440"
  },
  {
    "text": "So how do we set it up to make it trustworthy? I think that's the, the main, uh, aspect of it all.",
    "start": "1731440",
    "end": "1738040"
  },
  {
    "text": "And it's going to be a combination of human Plus, uh, a lot of techniques.",
    "start": "1738040",
    "end": "1743320"
  },
  {
    "text": "I think RAG, just the way it is done right now, may have some gaps, but we, I think",
    "start": "1743320",
    "end": "1750760"
  },
  {
    "text": "as a community, are moving forward towards solutions where we can specify a little",
    "start": "1750760",
    "end": "1756120"
  },
  {
    "text": "bit better where we are going for each of the questions, for each of the suggestions. But overall, um, Just to mention, I think",
    "start": "1756120",
    "end": "1764720"
  },
  {
    "text": "it's really, really important and really a tool for people to use and, uh, leverage",
    "start": "1764720",
    "end": "1771880"
  },
  {
    "text": "in their business cases, especially sales for sales force and so forth.",
    "start": "1771880",
    "end": "1776799"
  },
  {
    "start": "1780000",
    "end": "2315000"
  },
  {
    "text": "Keeping on the theme of putting this stuff in production and in front of actual customers.",
    "start": "1782200",
    "end": "1788360"
  },
  {
    "text": "Um, I will move us on to our third segment today, which is, uh, Talking about fantasy",
    "start": "1788360",
    "end": "1793520"
  },
  {
    "text": "football a little bit and some of the work that IBM is doing in in this space",
    "start": "1793520",
    "end": "1799240"
  },
  {
    "text": "Some of the work that I think this is, you know, these, this type of work is reaching like huge consumer audiences.",
    "start": "1800080",
    "end": "1805760"
  },
  {
    "text": "And so it actually is, um, I think some of the, some of the more exciting work that we're doing.",
    "start": "1805760",
    "end": "1811120"
  },
  {
    "text": "But, um, Aaron, I want to say the partnership has been going on for like eight years, uh, at this point, but, um, maybe just",
    "start": "1811120",
    "end": "1817440"
  },
  {
    "text": "talk a little bit about, you know, yeah. The work that we do around partnering with ESPN around fantasy football.",
    "start": "1817440",
    "end": "1823720"
  },
  {
    "text": "And then like, I know we introduced some new capabilities, um, this year that are driven by, um, LLM.",
    "start": "1823720",
    "end": "1829000"
  },
  {
    "text": "So maybe just talk a little bit about like the partnership there and then just like some of the stuff that we've brought new for, for the season.",
    "start": "1829000",
    "end": "1835600"
  },
  {
    "text": "Sure. Yeah.\nI mean, you perfect. It's, it's been around for our project has been around for eight years and",
    "start": "1835600",
    "end": "1841040"
  },
  {
    "text": "it, and, and we actually went down to the labs down in Austin with ESPN.",
    "start": "1841040",
    "end": "1846640"
  },
  {
    "text": "I'd say. 10 years ago, and we were trying to figure out what can we do right to help fantasy",
    "start": "1846640",
    "end": "1852160"
  },
  {
    "text": "football managers that hasn't been done before, and we came up with the notion that an active league is a happy league, right?",
    "start": "1852160",
    "end": "1859280"
  },
  {
    "text": "And what we want to do is to create this immersive and understandable experience for ESPN fantasy football team managers.",
    "start": "1859280",
    "end": "1866880"
  },
  {
    "text": "And, um, we've grown right. So now through eighth year, we have 12 million users that are registered.",
    "start": "1866880",
    "end": "1872960"
  },
  {
    "text": "We're actually live right now, and we're two and a half weeks into this very long season. And so far, we've had 919 million",
    "start": "1872960",
    "end": "1881120"
  },
  {
    "text": "page views, and we've Delivered 4. 6 billion insights, right? So it's really, really heavy.",
    "start": "1881120",
    "end": "1886960"
  },
  {
    "text": "And, um, we're, we are consumer facing, you know, so we have about 5, 000 requests per second that we sustain and, um, and one",
    "start": "1886960",
    "end": "1895720"
  },
  {
    "text": "stat that I just looked at this morning, I was just, just curious, but, um, the most time on a singular player has been",
    "start": "1895720",
    "end": "1903200"
  },
  {
    "text": "100 days just in two and a half weeks. And that player was Justin Fields, right? So, I mean, that gives you the volume, right?",
    "start": "1903200",
    "end": "1909440"
  },
  {
    "text": "And the amount of users that that we had. And the program, it starts in August and it runs into January of the following year.",
    "start": "1909440",
    "end": "1917040"
  },
  {
    "text": "And what we do is we provide boom, bust, score spreads and different stats about players to help folks make decisions.",
    "start": "1917040",
    "end": "1925559"
  },
  {
    "text": "And the idea at the beginning Which was novel, is that we wanted to create these different",
    "start": "1925560",
    "end": "1930840"
  },
  {
    "text": "predictions and player states, like do they have a hidden injury, just from text and",
    "start": "1930840",
    "end": "1936200"
  },
  {
    "text": "from videos and sound, not from stats, right? And that was a hypothesis, and we went",
    "start": "1936200",
    "end": "1941640"
  },
  {
    "text": "through this empirical metrics driven approach to measure how well we would do, and it came out that we did very",
    "start": "1941640",
    "end": "1948080"
  },
  {
    "text": "well and we're eight years into it. And then what we also do is we give trade analysis grades.",
    "start": "1948080",
    "end": "1953760"
  },
  {
    "text": "So if you and I were going to trade, I look at your situation, your roster, your rules, and, and, and I give you a grade.",
    "start": "1953760",
    "end": "1961760"
  },
  {
    "text": "Um, and then we also look at waiver wire players and give, give a grade. And we do opposing team rosters to",
    "start": "1961760",
    "end": "1967200"
  },
  {
    "text": "say, how will this player help my team? Because there's always an, an, you know, some",
    "start": "1967200",
    "end": "1972400"
  },
  {
    "text": "sort of opportunity costs, but the system, it uses a combination of generative AI, classical machine learning, um, simulated",
    "start": "1972400",
    "end": "1979440"
  },
  {
    "text": "quantum machine learning and different analytics that's been built up over the years.",
    "start": "1979440",
    "end": "1985399"
  },
  {
    "text": "Um, so it's, it's fascinating, it's very rewarding, you know, to see people use this and to see all of our insights,",
    "start": "1985400",
    "end": "1992760"
  },
  {
    "text": "generative insights as well on ESPN, on broadcast TV, um, and on the radio.",
    "start": "1992760",
    "end": "1998720"
  },
  {
    "text": "I think one of the things. That struck me the most, um, was correct",
    "start": "1998720",
    "end": "2004360"
  },
  {
    "text": "me if I'm wrong, but I want to say that we're using, um, like some of the trade, like gets a grade, um, right.",
    "start": "2004360",
    "end": "2010360"
  },
  {
    "text": "And then we actually use the IBM granite models as a way of producing some custom analysis associated with, with the grade.",
    "start": "2010360",
    "end": "2018080"
  },
  {
    "text": "Um, and so that text becomes like personalized, uh, really in a way to like, not just the person, but actually to the specific",
    "start": "2018080",
    "end": "2023800"
  },
  {
    "text": "situation, the, you know, One of the things so I do a lot of work in like media content",
    "start": "2023800",
    "end": "2030040"
  },
  {
    "text": "and the web and like personalization, I think for every every company that works",
    "start": "2030040",
    "end": "2035320"
  },
  {
    "text": "and thinks about their customer experience, like personalization is like the holy grail that everyone wants to get to.",
    "start": "2035320",
    "end": "2041920"
  },
  {
    "text": "And one of the things that So, so interesting is that, like, from a",
    "start": "2041920",
    "end": "2048240"
  },
  {
    "text": "content perspective, in particular, personalization is just insanely expensive. Um, and it's one of the gating aspects in order",
    "start": "2048240",
    "end": "2055879"
  },
  {
    "text": "to do it, because like, how many, like, I'm struggling to make one good version of this thing, and now you want me to create, like,",
    "start": "2055880",
    "end": "2061240"
  },
  {
    "text": "a hundred good versions of, of this thing. It's like, never gonna happen. Um, and then, so one of the first things I",
    "start": "2061240",
    "end": "2067879"
  },
  {
    "text": "thought about, uh, when, like, regenerative AI arrived, it was like, I wonder if this is the unlocked personalization.",
    "start": "2067880",
    "end": "2074399"
  },
  {
    "text": "Um, like, is this the thing that is really going to do that? Um, and so maybe, like, throw it over to",
    "start": "2074400",
    "end": "2080560"
  },
  {
    "text": "you, Chris, and just, like, how big of an impact do you think that, like, Gen AI is",
    "start": "2080560",
    "end": "2086040"
  },
  {
    "text": "going to have in personalization over time? And, like, what barriers do you think exist to, like, us doing even more of this?",
    "start": "2086040",
    "end": "2093560"
  },
  {
    "text": "So we're, we're already doing that. So personalizing, using generative AI to the",
    "start": "2093560",
    "end": "2099040"
  },
  {
    "text": "consumer, um, that is something we already do. And we do this with the customer data platforms.",
    "start": "2099040",
    "end": "2105440"
  },
  {
    "text": "So if you think of, uh, in marketing, you have the customer data platform where you have the, the 360 view of the customers.",
    "start": "2105440",
    "end": "2111480"
  },
  {
    "text": "So you have all your clicks or preferences, uh, all of that kind of marketing data, that's all in one profile.",
    "start": "2111480",
    "end": "2117680"
  },
  {
    "text": "Well, if you think about what generative AI is really good at, it's really good at role playing, right?",
    "start": "2117680",
    "end": "2122960"
  },
  {
    "text": "And you'll have seen that before, talk like a pirate, um, you know, talk like Snoop Dogg, et cetera.",
    "start": "2122960",
    "end": "2128240"
  },
  {
    "text": "Well, well, actually everything that you need to personalize there is sitting in your customer data platform.",
    "start": "2128240",
    "end": "2134240"
  },
  {
    "text": "So actually just. Getting all of that data that you've got today and then starting to put that in works really well.",
    "start": "2134240",
    "end": "2139839"
  },
  {
    "text": "And we've already been using that to build marketing segments, to then have even finer grained marketing segments",
    "start": "2139840",
    "end": "2146040"
  },
  {
    "text": "than you have today, and then be able to have that personalized content. And of course, that is making",
    "start": "2146040",
    "end": "2151519"
  },
  {
    "text": "it smaller and smaller. That's kind of what, Well, you know what's happening today in a practical level, but that's going to come down to to the",
    "start": "2151520",
    "end": "2158000"
  },
  {
    "text": "one and and if you think about this, it's not also about generation of content,",
    "start": "2158000",
    "end": "2163359"
  },
  {
    "text": "it's also about verification of content. So let's say you're going to do a marketing message and then you",
    "start": "2163360",
    "end": "2168760"
  },
  {
    "text": "go and do an A B test, right? That's quite an expensive test. You're doing that against real people and you're finding out.",
    "start": "2168760",
    "end": "2174040"
  },
  {
    "text": "Hey, is this work out? But remember what I said, the, the generative AI is really good at role playing.",
    "start": "2174040",
    "end": "2179800"
  },
  {
    "text": "So you can start to ask the question and say, how, how likely are you to respond to this content, right?",
    "start": "2179800",
    "end": "2185960"
  },
  {
    "text": "Is this content fitting in your particular persona? So you can start ask questions of that",
    "start": "2185960",
    "end": "2191200"
  },
  {
    "text": "persona that you've got there and understand if it's a good fit, and then maybe start to deal with that a little bit in advance.",
    "start": "2191200",
    "end": "2197360"
  },
  {
    "text": "So generation is absolutely where people want to go for personalization, but actually verification is, is",
    "start": "2197360",
    "end": "2204960"
  },
  {
    "text": "a really interesting use case. And as I said, we're already doing this. Yeah, yeah, I wanted to",
    "start": "2204960",
    "end": "2210120"
  },
  {
    "text": "just mention to, um, just to build off of that. Um, some of our challenges within the sports entertainment live events is",
    "start": "2210120",
    "end": "2215920"
  },
  {
    "text": "scale, right, because I mentioned we have 12 million users that could hit us in a single day, 5, 000 requests per second.",
    "start": "2215920",
    "end": "2222599"
  },
  {
    "text": "You know, so we, don't enable, um, well, we shield our origin servers,",
    "start": "2222600",
    "end": "2228360"
  },
  {
    "text": "right, from all that traffic. And what we do is we invented a way such that we could create batch jobs that would",
    "start": "2228360",
    "end": "2235720"
  },
  {
    "text": "create all these different generative, almost fill in the blank sentences. And then we would, on the edge, we would then",
    "start": "2235720",
    "end": "2242280"
  },
  {
    "text": "look up, you know, who, what league you're in. Because there's an infinite number of scoring rules, right?",
    "start": "2242280",
    "end": "2247520"
  },
  {
    "text": "That makes, um, these personalized sentences different, right? That could, again, be, be infinite.",
    "start": "2248040",
    "end": "2253720"
  },
  {
    "text": "And, um, and so what we do is we meet in the middle and we pull in those fill in the blank sentences on the edge and",
    "start": "2253720",
    "end": "2259760"
  },
  {
    "text": "then we personalize it, um, you know, through, um, fill in the blank adjectives. Uh, based on percentiles of the values",
    "start": "2259760",
    "end": "2268240"
  },
  {
    "text": "of which your players have, right? And, and then the language that you would expect. So it's almost like theory of the mind",
    "start": "2268240",
    "end": "2273839"
  },
  {
    "text": "where we want to, um, under, have our algorithms understand you, your data,",
    "start": "2273840",
    "end": "2280400"
  },
  {
    "text": "your situation, and then personalize the already generative AI and then field it off.",
    "start": "2280400",
    "end": "2285560"
  },
  {
    "text": "to you, right? And that's how we typically handle these massively large scale systems that hit us.",
    "start": "2285560",
    "end": "2294079"
  },
  {
    "text": "And it's, it's quite fun, right? To see the reaction of users when they see the data meeting their expectations and showing",
    "start": "2294080",
    "end": "2302120"
  },
  {
    "text": "them something that they didn't really know. They're like, wow, okay, now I get it. You know, and it's, and it shows the power of",
    "start": "2302120",
    "end": "2307920"
  },
  {
    "text": "what we do here, um, for lots of our customers.",
    "start": "2307920",
    "end": "2316240"
  },
  {
    "start": "2315000",
    "end": "2881000"
  },
  {
    "text": "Nathalie, I know you've actually been doing a lot of work in the space of, like, machine unlearning, um, and so maybe just,",
    "start": "2316240",
    "end": "2322640"
  },
  {
    "text": "like, to throw it over to you and just, like, talk a little bit about, like, what this is, why, why it's important, and, um,",
    "start": "2322640",
    "end": "2331720"
  },
  {
    "text": "yeah, just I'll throw it over to you there. Yeah, thank you. So this is a topic that I think it's very",
    "start": "2331720",
    "end": "2338600"
  },
  {
    "text": "important, very relevant, especially right now that we have huge models and is that basically",
    "start": "2338600",
    "end": "2345320"
  },
  {
    "text": "let's revisit for a second the pipeline. We have lots of training data. Lots, like a lot from the internet.",
    "start": "2345320",
    "end": "2351920"
  },
  {
    "text": "So untrusted training data, most of it, then we train a model that's huge. It takes months to do this and a lot",
    "start": "2351920",
    "end": "2359680"
  },
  {
    "text": "of know how, then we get the model. And then after that, we start red teaming and we start using the model",
    "start": "2359680",
    "end": "2366760"
  },
  {
    "text": "and we go like, Oh, We messed up. Perhaps we should have removed or not used",
    "start": "2366760",
    "end": "2372880"
  },
  {
    "text": "certain types of data that we use during these four months of training period, for example.",
    "start": "2372880",
    "end": "2378760"
  },
  {
    "text": "So, uh, the idea of unlearning is rather than retraining and try to solve the issues",
    "start": "2378760",
    "end": "2384840"
  },
  {
    "text": "by retraining or fine tuning, what we do is take the model, kind of perform some surgery",
    "start": "2384840",
    "end": "2390880"
  },
  {
    "text": "to it, and, uh, so that the effects of data that we don't want are no longer there.",
    "start": "2390880",
    "end": "2397680"
  },
  {
    "text": "There are, uh, different reasons for which we may want to do that. One of them is, for example, it turns",
    "start": "2397680",
    "end": "2404400"
  },
  {
    "text": "out that all of the sudden we have this subpopulation of people and then a lot of",
    "start": "2404400",
    "end": "2409600"
  },
  {
    "text": "the replies that we are getting for that subpopulation of people are not great. So very toxic behavior, for",
    "start": "2409600",
    "end": "2415960"
  },
  {
    "text": "example, from the model. Can we actually remove that a posteriori after training?",
    "start": "2415960",
    "end": "2421560"
  },
  {
    "text": "All the things that we don't like from toxicity. Uh, what if somebody, another use case,",
    "start": "2421560",
    "end": "2426880"
  },
  {
    "text": "use case number two, is poisoning? What if somebody actually took that untrusted",
    "start": "2426880",
    "end": "2431960"
  },
  {
    "text": "set, manipulated the training data in a way that was not great, and then, uh, we are",
    "start": "2431960",
    "end": "2438160"
  },
  {
    "text": "starting to, to understand that that has happened, the model is there, what do we do? Then, what we do is try to modify the models.",
    "start": "2438160",
    "end": "2445960"
  },
  {
    "text": "to remove that poisoning information. There is, uh, also a use case from, uh,",
    "start": "2445960",
    "end": "2452240"
  },
  {
    "text": "for example, removing copyrighted material. Licenses sometimes are not, even if,",
    "start": "2452240",
    "end": "2458600"
  },
  {
    "text": "for example, we filter, and at IBM, we really make a huge effort to filter",
    "start": "2458600",
    "end": "2463760"
  },
  {
    "text": "copyrighted material when we train. But licenses are sometimes non static.",
    "start": "2463760",
    "end": "2469200"
  },
  {
    "text": "So one thing that today seems okay to use, later on may have changed. What do we do?",
    "start": "2469200",
    "end": "2474560"
  },
  {
    "text": "Do we go back to retraining? Probably not. It will take forever. But if we use techniques like unlearning",
    "start": "2474560",
    "end": "2480400"
  },
  {
    "text": "that modify the model to remove that copyrighted information, that it's going to give us a big, big advantage.",
    "start": "2480400",
    "end": "2487640"
  },
  {
    "text": "Um, anything basically hallucinations, uh, that's another aspect of it.",
    "start": "2487640",
    "end": "2493120"
  },
  {
    "text": "What if we determine that the model always hallucinate in certain way? Can we go inspect it, modify it so that",
    "start": "2493120",
    "end": "2499840"
  },
  {
    "text": "we no longer have this hallucination? So the way I would say I like to think about",
    "start": "2499840",
    "end": "2505960"
  },
  {
    "text": "it is that you have a model It's a patient And you see that there's something like a",
    "start": "2505960",
    "end": "2511480"
  },
  {
    "text": "virus going on in there Uh, there's this new way to basically give it antibiotics",
    "start": "2511480",
    "end": "2517599"
  },
  {
    "text": "patch it And then you have a new model. So we are operating really in modifying",
    "start": "2517600",
    "end": "2522720"
  },
  {
    "text": "the model, and that adds like this extra layer of security to the whole pipeline and",
    "start": "2522720",
    "end": "2529400"
  },
  {
    "text": "helps us also manage the life cycle of the model itself so that we can basically in",
    "start": "2529400",
    "end": "2535519"
  },
  {
    "text": "retrospective, every time we find something it's odd or that we don't want, we can go ahead and change that model accordingly.",
    "start": "2535520",
    "end": "2543040"
  },
  {
    "text": "It's a fascinating thing because so much of The discussion around how we work with models has been about how do we add more data into",
    "start": "2543040",
    "end": "2549880"
  },
  {
    "text": "the model, um, whether we're talking about rag or fine tuning, like these are like, okay, we have a generic model, but we need",
    "start": "2549880",
    "end": "2556080"
  },
  {
    "text": "to get an enterprise data set into the thing so it can operate on our data on our tasks. Machine on learning is like the",
    "start": "2556080",
    "end": "2562359"
  },
  {
    "text": "opposite of that, of like, how do we actually get things out of the model? And so, you know, maybe Chris or Aaron, you",
    "start": "2562360",
    "end": "2569440"
  },
  {
    "text": "know, I'd be curious if you think that, like, is this domain like going to be entirely?",
    "start": "2569440",
    "end": "2574720"
  },
  {
    "text": "Like the world of model providers and like maybe some stuff in the open source world",
    "start": "2574720",
    "end": "2580240"
  },
  {
    "text": "or like, do we think that there is a world where like enterprises and, you know, when they're thinking like that, this, this type",
    "start": "2580240",
    "end": "2586600"
  },
  {
    "text": "of practices, like and techniques around removing data from models becomes like as commonplace as adding data to models.",
    "start": "2586600",
    "end": "2594360"
  },
  {
    "text": "Data 2 models around things like rag and fine tuning. Yeah, I think it's going to be pretty commonplace if I'm honest about it.",
    "start": "2594360",
    "end": "2600960"
  },
  {
    "text": "Because if I think about the fine tuning today,",
    "start": "2600960",
    "end": "2606680"
  },
  {
    "text": "I think fine tuning is really quite an imprecise art at the moment, if I'm truly honest about it.",
    "start": "2606680",
    "end": "2613440"
  },
  {
    "text": "We do things like freeze the layers, we make it smaller. But if we look at the kind of the space that",
    "start": "2613440",
    "end": "2619080"
  },
  {
    "text": "you've got in the models there, You're just sort of, it's almost like you're just lobbing off",
    "start": "2619080",
    "end": "2625080"
  },
  {
    "text": "stuff and then putting new stuff on top, right? And I, and it's imprecise. So I think as you train models, I",
    "start": "2625080",
    "end": "2632160"
  },
  {
    "text": "think, and as I think you're going to want to be more surgical, right? And I, and I keep thinking of the episode we did with the golden grape.",
    "start": "2632160",
    "end": "2638799"
  },
  {
    "text": "bridge, right, and the work that Anthropic did there, right, where they were saying that this, you know, this activation here would happen",
    "start": "2638800",
    "end": "2645720"
  },
  {
    "text": "when you did this, and then we could up it, and we could down it, or whatever, right, and, you know, you could make it talk more about",
    "start": "2645720",
    "end": "2651480"
  },
  {
    "text": "a Golden Gate Bridge, or less, or whatever. I think it's going to be in this direction. So, you'll have things like unlearning, so",
    "start": "2651480",
    "end": "2657799"
  },
  {
    "text": "being able to remove things from the model. But then I think you're going to want to fine tune in a more precise way. And, and, and I think we're all",
    "start": "2657800",
    "end": "2664920"
  },
  {
    "text": "going to become LLM surgeons. I think that's going to become a more precise art than it is today.",
    "start": "2664920",
    "end": "2670800"
  },
  {
    "text": "So, so yes, and that means the tools are going to get better, how we visualize the models",
    "start": "2670800",
    "end": "2676960"
  },
  {
    "text": "and look at it and be able to do scans and say, okay, this is the point where, you know, it's talking about Harry Potter, this is where",
    "start": "2676960",
    "end": "2683280"
  },
  {
    "text": "it's talking about copyright information. I think. I think this is, we're just going to have a deeper and richer view of the models in time.",
    "start": "2683280",
    "end": "2691000"
  },
  {
    "text": "And we just don't have that today. It's an imprecise art. It's funny that you mentioned, um, some of the",
    "start": "2691000",
    "end": "2696520"
  },
  {
    "text": "mechanistic interpretability, um, because like when we were actually having the conversation earlier about chain of thought, I was also",
    "start": "2696520",
    "end": "2703040"
  },
  {
    "text": "thinking about that as like a different way to understand the the way the model is thinking",
    "start": "2703040",
    "end": "2708799"
  },
  {
    "text": "because like there's this whole thing of like we have no idea the way these things work but like between the interpretability space",
    "start": "2708800",
    "end": "2714000"
  },
  {
    "text": "between everything around chain of thought between you know machine unlearning you're having all these sort of different techniques",
    "start": "2714000",
    "end": "2720160"
  },
  {
    "text": "that are all around getting it trying to get out the same problem of like how is this thing doing what it's doing and can we now that we",
    "start": "2720160",
    "end": "2727119"
  },
  {
    "text": "know that can we make it do something else yeah i mean this is almost like watching the movie The Matrix, right, where, you know, the",
    "start": "2727120",
    "end": "2733560"
  },
  {
    "text": "scene is, do you want to take the red pill, you know, and really learn and understand something that might make you uncomfortable, or take",
    "start": "2733560",
    "end": "2739599"
  },
  {
    "text": "the blue pill and just maintain status quo. And to me, this machine unlearning is almost",
    "start": "2739600",
    "end": "2744680"
  },
  {
    "text": "taking the red pill, where you're getting these models to focus on the data that matters.",
    "start": "2744680",
    "end": "2750240"
  },
  {
    "text": "Particular point in time, and maybe it's uncomfortable, you know, doing that and just trying to figure out exactly what data",
    "start": "2750880",
    "end": "2757960"
  },
  {
    "text": "does matter and what data doesn't, which is almost like a, you know, a governance kind of, you know, um, problem there",
    "start": "2757960",
    "end": "2764680"
  },
  {
    "text": "and, and what I really find Interesting. I guess getting a little nerdy is how it works.",
    "start": "2764680",
    "end": "2770160"
  },
  {
    "text": "You know, it's just really, really neat, you know, about, you know, about how, you know, if you're at a large language model, you know,",
    "start": "2770160",
    "end": "2777160"
  },
  {
    "text": "how you're basically teaching, um, a generic model to predict, um, the next token as if",
    "start": "2777160",
    "end": "2784599"
  },
  {
    "text": "it had, that doesn't have that data and you construct like a new training set and then you use that to feed back into the model to",
    "start": "2784600",
    "end": "2791200"
  },
  {
    "text": "relearn as though it never had the data in it. Somewhat erases, you know, the weights.",
    "start": "2791200",
    "end": "2796559"
  },
  {
    "text": "You know, on those gradients within the activation function, right? And that, that's, that's neat. And then when you get to multimedia, right?",
    "start": "2796560",
    "end": "2803840"
  },
  {
    "text": "Like image to image, it's, you know, it's, it's great because you can actually have these models forget, you know, how to",
    "start": "2803840",
    "end": "2811880"
  },
  {
    "text": "put in these new objects within images. I, Could be copyrighted, or maybe you don't want to have certain types of objects, or",
    "start": "2811880",
    "end": "2818840"
  },
  {
    "text": "maybe you do want to have certain objects. So you can sort of balance forgetting and remembering, but it's where you",
    "start": "2818840",
    "end": "2825480"
  },
  {
    "text": "can have like these loss functions that span forgetting and remembering, and you optimize both at the same time.",
    "start": "2825480",
    "end": "2832200"
  },
  {
    "text": "With two separate models and you're teaching one of them, you know, what data is the most important. So, um, so I mean going back to the matrix",
    "start": "2832200",
    "end": "2839440"
  },
  {
    "text": "I think all of these llms and us being surgeons, you know I think we're going to be taking more of these red pills.",
    "start": "2839440",
    "end": "2844920"
  },
  {
    "text": "I guess mixture of experts is now the red pill pod At this point, so I think that's a good way a good way to end today.",
    "start": "2844920",
    "end": "2852560"
  },
  {
    "text": "So Aaron, Chris, Nathalie, thank you for joining us today.",
    "start": "2852560",
    "end": "2857640"
  },
  {
    "text": "Another exciting week in AI. We will be back next week talking about all the news going on.",
    "start": "2857640",
    "end": "2864160"
  },
  {
    "text": "But for all of you out there in radio land, you can find us on podcast networks everywhere.",
    "start": "2864160",
    "end": "2870160"
  },
  {
    "text": "Thank you for joining in today, and we will see you back next week. So thanks very much, everyone.g",
    "start": "2870160",
    "end": "2876839"
  }
]
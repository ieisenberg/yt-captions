[
  {
    "start": "0",
    "end": "21000"
  },
  {
    "text": "Have you ever wanted to have a conversation with a llama?",
    "start": "600",
    "end": "3690"
  },
  {
    "text": "Well, you can't today.",
    "start": "4650",
    "end": "5999"
  },
  {
    "text": "But Llama models are the next best thing.",
    "start": "6510",
    "end": "9240"
  },
  {
    "text": "Today I'll cover what is Llama",
    "start": "9750",
    "end": "12398"
  },
  {
    "text": "and we'll talk about how the Llama model is transforming our world as it is and  talk about the past, present and future.",
    "start": "12398",
    "end": "21150"
  },
  {
    "start": "21000",
    "end": "134000"
  },
  {
    "text": "So let's talk a little bit more about what is Llama. ",
    "start": "21321",
    "end": "24286"
  },
  {
    "text": "First, Llama is an open",
    "start": "24493",
    "end": "26563"
  },
  {
    "text": "source model, which means it's built with open data and the code is open for all of us to consume and use it.",
    "start": "29090",
    "end": "36680"
  },
  {
    "text": "It also means that we can do a few special things with the model.",
    "start": "37730",
    "end": "41989"
  },
  {
    "text": "Because it's open.",
    "start": "42020",
    "end": "43020"
  },
  {
    "text": "First, it's transparent so we can see exactly how the model was built",
    "start": "43610",
    "end": "51341"
  },
  {
    "text": "and we know its shortcomings as well as where it may outperform others.",
    "start": "51659",
    "end": "57946"
  },
  {
    "text": "Second, we can customize it.",
    "start": "58438",
    "end": "61483"
  },
  {
    "text": "There's a lot of benefits to customization and being able to actually parse the model,",
    "start": "61850",
    "end": "67323"
  },
  {
    "text": "potentially create smaller models and do things like fine tuning to make sure the model works.",
    "start": "67323",
    "end": "73069"
  },
  {
    "text": "Specific to your use case.",
    "start": "73190",
    "end": "74899"
  },
  {
    "text": "Third is accuracy.",
    "start": "76180",
    "end": "79120"
  },
  {
    "text": "We can have more accurate models with smaller size, which means less cost and less time to build.",
    "start": "80090",
    "end": "87888"
  },
  {
    "text": "So.",
    "start": "89180",
    "end": "90180"
  },
  {
    "text": "How overall does Llama differentiate from other models on the market?",
    "start": "90800",
    "end": "95599"
  },
  {
    "text": "Well.",
    "start": "95930",
    "end": "96930"
  },
  {
    "text": "The biggest thing is it's much smaller than some of the proprietary models on the market.",
    "start": "97980",
    "end": "104010"
  },
  {
    "text": "Again, this means less money, less time, which can be huge benefits to you as you use and consume it.",
    "start": "104580",
    "end": "112739"
  },
  {
    "text": "Second, related to customization.",
    "start": "113820",
    "end": "116790"
  },
  {
    "text": "You can build models specific to your domain and your use cases, right?",
    "start": "118070",
    "end": "124670"
  },
  {
    "text": "So you're not using a general purpose model that answers everything.",
    "start": "124940",
    "end": "129349"
  },
  {
    "text": "You're able to take that model and make it specific to you.",
    "start": "129620",
    "end": "133580"
  },
  {
    "start": "134000",
    "end": "421000"
  },
  {
    "text": "All right.",
    "start": "134210",
    "end": "134750"
  },
  {
    "text": "Now, let's talk about the history of Llama.",
    "start": "134750",
    "end": "137779"
  },
  {
    "text": "So the first version of Llama came out in February of 2023.",
    "start": "138380",
    "end": "146120"
  },
  {
    "text": "And what Llama does is it's trained on words and sequences of words.",
    "start": "146780",
    "end": "151339"
  },
  {
    "text": "And it takes the previous word and tries to predict what the next word is.",
    "start": "151670",
    "end": "156800"
  },
  {
    "text": "And the first version of Llama range from 7 billion parameter model up to a 65 billion parameter model,",
    "start": "157220",
    "end": "168499"
  },
  {
    "text": "so much smaller than other models that were released on the market at that time.",
    "start": "168499",
    "end": "174228"
  },
  {
    "text": "And really the first of its kind for the small model market.",
    "start": "175080",
    "end": "178199"
  },
  {
    "text": "Next, we had version two of the model come out in July of 2023, and this included some performance updates.",
    "start": "179510",
    "end": "190189"
  },
  {
    "text": "And we focused in here, Llama did on the 7 million model and going up to a 70 billion parameter model.",
    "start": "190190",
    "end": "197930"
  },
  {
    "text": "And if we look at the performance compared to size, what this did with each release",
    "start": "198800",
    "end": "204578"
  },
  {
    "text": "is with the first release, you know, let's just say we had performance, good performance and small size.",
    "start": "204578",
    "end": "213169"
  },
  {
    "text": "Now with the second release with the V2, we had stronger performance",
    "start": "213200",
    "end": "219083"
  },
  {
    "text": "relative to the same size, so much higher performance.",
    "start": "219083",
    "end": "224150"
  },
  {
    "text": "And that focus really continued on with the future releases.",
    "start": "224510",
    "end": "227989"
  },
  {
    "text": "So we had a Code Llama release.",
    "start": "228410",
    "end": "232580"
  },
  {
    "text": "In August.",
    "start": "233560",
    "end": "234940"
  },
  {
    "text": "of 23.",
    "start": "235120",
    "end": "236569"
  },
  {
    "text": "And these were code models specifically.",
    "start": "237010",
    "end": "239889"
  },
  {
    "text": "So more domain specific models than the prior models released.",
    "start": "240550",
    "end": "244149"
  },
  {
    "text": "And one of them focused on Python.",
    "start": "244510",
    "end": "247939"
  },
  {
    "text": "So very helpful for developers out there that want to use open source models for code development.",
    "start": "247960",
    "end": "255550"
  },
  {
    "text": "Next we had Llama three.",
    "start": "258310",
    "end": "262839"
  },
  {
    "text": "Llama three was long awaited and came about in April of 2024, earlier this year.",
    "start": "263290",
    "end": "271360"
  },
  {
    "text": "And with the Llama three model, very exciting.",
    "start": "271780",
    "end": "274720"
  },
  {
    "text": "Again focused on the same range of models from 7 billion to 70 billion and a few other sizes in between.",
    "start": "274720",
    "end": "282939"
  },
  {
    "text": "But again, Llama was focused on increasing that performance relative to the same size.",
    "start": "283330",
    "end": "291459"
  },
  {
    "text": "And we see that trend continue all the way into the most recent release in July of 2024 with Llama version 3.1.",
    "start": "292360",
    "end": "302860"
  },
  {
    "text": "And there's many exciting features of the Llama 3.1 release.",
    "start": "304640",
    "end": "310160"
  },
  {
    "text": "The first is this model is multi lingual, which is very exciting.",
    "start": "311220",
    "end": "318420"
  },
  {
    "text": "So we had some training data before that used previous languages, but this model has heavily focused on having",
    "start": "318450",
    "end": "326246"
  },
  {
    "text": "the latest multilingual capabilities and can fully converse in many different languages.",
    "start": "326246",
    "end": "333000"
  },
  {
    "text": "Second is the context window.",
    "start": "333930",
    "end": "336449"
  },
  {
    "text": "The context window is the amount of data that is output of the model relative to the number of tokens.",
    "start": "338080",
    "end": "345129"
  },
  {
    "text": "So what this means is that now Llama can produce more text for a single run of the model.",
    "start": "345520",
    "end": "353289"
  },
  {
    "text": "And this is exciting because you have more ability to run the model in different places.",
    "start": "353830",
    "end": "358789"
  },
  {
    "text": "But it also introduces some security risks.",
    "start": "358810",
    "end": "362709"
  },
  {
    "text": "And to combat that, Llama has been some of the first on the market to introduce techniques like Llama Guard.",
    "start": "363280",
    "end": "370389"
  },
  {
    "text": "Which impacts and influences the security.",
    "start": "372060",
    "end": "375120"
  },
  {
    "text": "So this makes sure that techniques like prompt injection are less likely",
    "start": "375120",
    "end": "380626"
  },
  {
    "text": "and preventable from happening with that context window.",
    "start": "380626",
    "end": "385050"
  },
  {
    "text": "And finally again, Llama focused on power.",
    "start": "385440",
    "end": "389279"
  },
  {
    "text": "So this time lama went much bigger in size, but better in performance",
    "start": "389310",
    "end": "395014"
  },
  {
    "text": "with actually releasing a 405 billion parameter model",
    "start": "395014",
    "end": "400916"
  },
  {
    "text": "so much, much larger than the 70 billion and 65 billion that we had before.",
    "start": "400916",
    "end": "408180"
  },
  {
    "text": "But we see exciting, strong performance that competes with several of the other large models on the market",
    "start": "408450",
    "end": "416367"
  },
  {
    "text": "that today are proprietary.",
    "start": "416367",
    "end": "418350"
  },
  {
    "text": "And this model is completely open source.",
    "start": "418500",
    "end": "421110"
  },
  {
    "start": "421000",
    "end": "525000"
  },
  {
    "text": "Okay.",
    "start": "421710",
    "end": "422699"
  },
  {
    "text": "Now let's talk about some of the best ways you can use the new exciting enhancements with Llama 3.1.",
    "start": "422700",
    "end": "428760"
  },
  {
    "text": "First is for data generation.",
    "start": "429510",
    "end": "434160"
  },
  {
    "text": "So you can actually take the 4 or 5 billion parameter model and you can generate your own data.",
    "start": "434820",
    "end": "440970"
  },
  {
    "text": "This is particularly interesting to data scientists and data engineers that may have spent.",
    "start": "441210",
    "end": "447509"
  },
  {
    "text": "Days or weeks, sometimes getting access to the data you need to build a model.",
    "start": "448460",
    "end": "453560"
  },
  {
    "text": "Well, now you can use synthetic data generation to generate the data",
    "start": "453860",
    "end": "458155"
  },
  {
    "text": "in just a matter of minutes, which is huge, huge productivity enhancements.",
    "start": "458155",
    "end": "462979"
  },
  {
    "text": "Next, we have knowledge, distillation.",
    "start": "463910",
    "end": "466249"
  },
  {
    "text": "So we can take that model and break it down and also find more specific domain applicable use cases.",
    "start": "467240",
    "end": "476689"
  },
  {
    "text": "And then finally, we can use the model as an LLM judge",
    "start": "478330",
    "end": "483525"
  },
  {
    "text": "so we can look at several different LLMs and use Llama to evaluate which model is best for our given use case.",
    "start": "483525",
    "end": "492729"
  },
  {
    "text": "Today we covered what is Llama.",
    "start": "492940",
    "end": "495160"
  },
  {
    "text": "We covered the past.",
    "start": "495640",
    "end": "496959"
  },
  {
    "text": "We covered the present.",
    "start": "497260",
    "end": "498519"
  },
  {
    "text": "We covered the most common use cases.",
    "start": "498820",
    "end": "501100"
  },
  {
    "text": "But let's think about what is the future of Llama.",
    "start": "501610",
    "end": "505298"
  },
  {
    "text": "What are you most excited to see in the next Llama release?",
    "start": "505780",
    "end": "510338"
  }
]
[
  {
    "text": "Hi, I'm Anna and this is how to perform\nagentic  retrieval augmented generation.",
    "start": "333",
    "end": "4804"
  },
  {
    "text": "In other words, agentic RAG.",
    "start": "5138",
    "end": "7407"
  },
  {
    "text": "We'll need a few packages\nfor this tutorial.",
    "start": "7407",
    "end": "9676"
  },
  {
    "text": "Make sure to install the following\nlibraries.",
    "start": "9676",
    "end": "12679"
  },
  {
    "text": "Next, we'll import the following packages.",
    "start": "13146",
    "end": "16149"
  },
  {
    "text": "Then we input our API key and project ID.",
    "start": "18051",
    "end": "21054"
  },
  {
    "text": "We've set up our credentials\nusing a .env file.",
    "start": "21421",
    "end": "26993"
  },
  {
    "text": "For this tutorial we're using IBM's granite 3.08b instruct model, but you're free to use any AI model of your choice.",
    "start": "26993",
    "end": "35100"
  },
  {
    "text": "The purpose of these models is to serve as the reasoning engine that decides",
    "start": "35502",
    "end": "39472"
  },
  {
    "text": "which actions to take.",
    "start": "39472",
    "end": "42475"
  },
  {
    "text": "We'll set up a prompt template",
    "start": "43476",
    "end": "45211"
  },
  {
    "text": "to ask multiple questions,",
    "start": "45211",
    "end": "48181"
  },
  {
    "text": "and now we can set up a chain\nwith our prompt and our alarm.",
    "start": "48948",
    "end": "52752"
  },
  {
    "text": "This allows the LLM to produce a response.",
    "start": "53253",
    "end": "56088"
  },
  {
    "text": "Let's test our agent response to a basic question",
    "start": "57857",
    "end": "61194"
  },
  {
    "text": "like what sport is played at the US open?",
    "start": "61294",
    "end": "64296"
  },
  {
    "text": "Our agent responded correctly.",
    "start": "66199",
    "end": "68201"
  },
  {
    "text": "Let's try something a little harder.",
    "start": "68201",
    "end": "70536"
  },
  {
    "text": "Like where was the 2024 U.S. Open?",
    "start": "70537",
    "end": "75742"
  },
  {
    "text": "The LLM is unable\nto answer this question.",
    "start": "76543",
    "end": "79546"
  },
  {
    "text": "The training data used for this\nmodel is from before the 2024 U.S.",
    "start": "79879",
    "end": "84149"
  },
  {
    "text": "Open happened, and without the appropriate tools,",
    "start": "84150",
    "end": "87253"
  },
  {
    "text": "the agent doesn't have access\nto this information.",
    "start": "87520",
    "end": "90522"
  },
  {
    "text": "The first step in creating our knowledge\nbase is listing the URLs.",
    "start": "91224",
    "end": "95395"
  },
  {
    "text": "We will be getting content from.",
    "start": "95428",
    "end": "97297"
  },
  {
    "text": "Here are a list of URLs summarizing IBM's involvement in the 2024 U.S. Open. Let's put them in a list called URLs.",
    "start": "97297",
    "end": "105505"
  },
  {
    "text": "Next, weâ€™ll load the URLs as documents\nusing LangChain's web based loader.",
    "start": "106139",
    "end": "110844"
  },
  {
    "text": "We'll also print a sample document\nto see how it loaded.",
    "start": "111277",
    "end": "114180"
  },
  {
    "text": "Looks good.",
    "start": "117217",
    "end": "118351"
  },
  {
    "text": "In order to split the data\nin these documents into chunks that can",
    "start": "118351",
    "end": "121888"
  },
  {
    "text": "then be processed by the LLM,\nwe can use a text splitter.",
    "start": "121888",
    "end": "125859"
  },
  {
    "text": "The embedding model that we are using is",
    "start": "127627",
    "end": "129863"
  },
  {
    "text": "an IBM slate model through the watsonx.ai embedding service.",
    "start": "129863",
    "end": "134501"
  },
  {
    "text": "Let's initialize it.",
    "start": "134868",
    "end": "137871"
  },
  {
    "text": "In order to store or embedded documents.",
    "start": "139072",
    "end": "141374"
  },
  {
    "text": "We will use Chroma DB,\nan open source vector store",
    "start": "141374",
    "end": "145010"
  },
  {
    "text": "to access information in the vector store.",
    "start": "146679",
    "end": "149182"
  },
  {
    "text": "We must set up a retriever.",
    "start": "149182",
    "end": "152185"
  },
  {
    "text": "Let's define the get IBM US Open context function and tool.",
    "start": "153987",
    "end": "158892"
  },
  {
    "text": "Our agent will be using the tools description helps the agent know when to call it.",
    "start": "158925",
    "end": "164330"
  },
  {
    "text": "This tool can be used for routing questions to our vector store.",
    "start": "164330",
    "end": "167567"
  },
  {
    "text": "If they're related to IBM's involvement\nin the 2024 US Open.",
    "start": "167567",
    "end": "171638"
  },
  {
    "text": "Next, let's set up a new prompt template to ask multiple questions.",
    "start": "172939",
    "end": "177644"
  },
  {
    "text": "This template is more complex.",
    "start": "178044",
    "end": "179879"
  },
  {
    "text": "It's known as a structured chat prompt\nand can be used",
    "start": "179879",
    "end": "183183"
  },
  {
    "text": "for creating agents\nto have multiple tools available.",
    "start": "183183",
    "end": "186152"
  },
  {
    "text": "Our structured chat prompt\nwill be made up of a system prompt,",
    "start": "186653",
    "end": "189856"
  },
  {
    "text": "a human prompt, and our RAG tool.",
    "start": "190190",
    "end": "193059"
  },
  {
    "text": "First, we'll set up the system prompt.",
    "start": "193059",
    "end": "195495"
  },
  {
    "text": "This prompt tells the agent to print\nits thought process,",
    "start": "195495",
    "end": "198831"
  },
  {
    "text": "the tools that were used,\nand the final output.",
    "start": "199199",
    "end": "202202"
  },
  {
    "text": "In the following code,\nwe're establishing the human prompt.",
    "start": "203236",
    "end": "206271"
  },
  {
    "text": "This prompt tells the agent\nto display the user input, followed by",
    "start": "206306",
    "end": "210343"
  },
  {
    "text": "the intermediate steps taken by the agent\nas part of the agent scratchpad.",
    "start": "210343",
    "end": "215181"
  },
  {
    "text": "Next, we'll establish the order of our newly",
    "start": "216816",
    "end": "219319"
  },
  {
    "text": "defined prompts in the prompt template.",
    "start": "219319",
    "end": "221521"
  },
  {
    "text": "Now let's finalize our  prompt template\nby adding the tool names, descriptions,",
    "start": "223790",
    "end": "228361"
  },
  {
    "text": "and arguments using a partial prompt template.",
    "start": "228628",
    "end": "231664"
  },
  {
    "text": "An important feature of AI agents is\ntheir memory.",
    "start": "232999",
    "end": "236034"
  },
  {
    "text": "Agents are able to store\npast conversations",
    "start": "236402",
    "end": "239071"
  },
  {
    "text": "and past findings in their memory\nto improve the accuracy",
    "start": "239072",
    "end": "243309"
  },
  {
    "text": "and relevance of their responses\ngoing forward.",
    "start": "243309",
    "end": "246312"
  },
  {
    "text": "In our case, we'll be using LangChain conversation buffer memory",
    "start": "246446",
    "end": "250383"
  },
  {
    "text": "as a means of memory storage.",
    "start": "250683",
    "end": "253686"
  },
  {
    "text": "And now we can set up a chain\nwith our agents",
    "start": "254220",
    "end": "256722"
  },
  {
    "text": "scratchpad memory prompt and the LLM.",
    "start": "256723",
    "end": "260560"
  },
  {
    "text": "The agent executor class\nis used to execute the agent.",
    "start": "260994",
    "end": "264363"
  },
  {
    "text": "We're now able to ask the agent questions.",
    "start": "265498",
    "end": "268500"
  },
  {
    "text": "Remember how the agent\nwas previously unable",
    "start": "268534",
    "end": "271104"
  },
  {
    "text": "to provide us with the information\nrelated to our queries?",
    "start": "271104",
    "end": "274307"
  },
  {
    "text": "Now that the agent has its RAG tool\navailable to use,",
    "start": "275141",
    "end": "278544"
  },
  {
    "text": "let's try asking the same questions again.",
    "start": "278878",
    "end": "281581"
  },
  {
    "text": "Let's start with where was the 2020 for US Open?",
    "start": "281581",
    "end": "284951"
  },
  {
    "text": "Great.",
    "start": "291958",
    "end": "292525"
  },
  {
    "text": "The agent used its available RAG tool\nto return the location of the 2024 U.S. Open.",
    "start": "292525",
    "end": "298598"
  },
  {
    "text": "We even get to see the exact document\nthat the agent is retrieving its information from.",
    "start": "298598",
    "end": "304003"
  },
  {
    "text": "Now, let's try something harder.",
    "start": "304003",
    "end": "306339"
  },
  {
    "text": "This time, our query will be about IBM's involvement in the 2024 US Open.",
    "start": "306339",
    "end": "312879"
  },
  {
    "text": "Again, the agent was able\nto successfully retrieve",
    "start": "318785",
    "end": "321788"
  },
  {
    "text": "the relevant information\nrelated to our question.",
    "start": "321788",
    "end": "324791"
  },
  {
    "text": "Additionally, the agent is successfully\nupdating its knowledge base",
    "start": "324824",
    "end": "328361"
  },
  {
    "text": "as it learns new information\nand experiences new interactions",
    "start": "328695",
    "end": "332365"
  },
  {
    "text": "as seen by the history output.",
    "start": "332732",
    "end": "335401"
  },
  {
    "text": "Now, let's test if the agent can determine when to calling",
    "start": "335401",
    "end": "338771"
  },
  {
    "text": "isn't necessary to answer the user query.",
    "start": "338938",
    "end": "341940"
  },
  {
    "text": "We can test this by asking the wrong",
    "start": "342075",
    "end": "344010"
  },
  {
    "text": "agent a question\nthat is not about the US Open.",
    "start": "344010",
    "end": "347013"
  },
  {
    "text": "Like what is the capital of France?",
    "start": "347180",
    "end": "349048"
  },
  {
    "text": "As seen in the agent executor chain,",
    "start": "352418",
    "end": "354887"
  },
  {
    "text": "the agent recognized that it had\nthe information in its knowledge base.",
    "start": "354887",
    "end": "358891"
  },
  {
    "text": "To answer this question\nwithout using any of its tools.",
    "start": "359192",
    "end": "362828"
  },
  {
    "text": "And that's it.",
    "start": "363296",
    "end": "364297"
  },
  {
    "text": "In this tutorial, we created a RAG agent\nusing LangChain in Python with watsonx.ai.",
    "start": "364297",
    "end": "370806"
  },
  {
    "text": "The LLM we worked with was an IBM granite 3.08 the Instruct model.",
    "start": "370806",
    "end": "376342"
  },
  {
    "text": "The AI agent was successfully able\nto retrieve relevant",
    "start": "376442",
    "end": "379245"
  },
  {
    "text": "information via a rogue tool, update each memory",
    "start": "379245",
    "end": "382382"
  },
  {
    "text": "with each interaction and output responses.",
    "start": "382382",
    "end": "385350"
  },
  {
    "text": "It's also important\nto note the agent's ability to discern",
    "start": "385451",
    "end": "388521"
  },
  {
    "text": "whether tool calling is appropriate\nfor each specific task.",
    "start": "388521",
    "end": "391591"
  },
  {
    "text": "For instance, when the agent already had the relevant",
    "start": "392425",
    "end": "395228"
  },
  {
    "text": "information needed to answer a question about the capital of France,",
    "start": "395228",
    "end": "398965"
  },
  {
    "text": "it didn't use any tool calling for question answering.",
    "start": "399298",
    "end": "402001"
  }
]
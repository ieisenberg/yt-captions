[
  {
    "start": "0",
    "end": "38000"
  },
  {
    "text": "I wanna go back one year,\nit's May, 2024 again. What's the biggest thing in AI that\nturns out to be not that big of a deal?",
    "start": "90",
    "end": "7170"
  },
  {
    "text": "Kush Varshney is an IBM\nfellow, uh, on AI governance. Kush, welcome back to the show. Uh, what do you think?",
    "start": "7380",
    "end": "12360"
  },
  {
    "text": "Uh, Kolmogorov-Arnold  Networks. Got it. That's a good one. Shobhit Varshney, Head of\nData and AI for the Americas.",
    "start": "12480",
    "end": "18090"
  },
  {
    "text": "Shobhit. The cost of AI, I think the intelligence\nper dollar has plummeted  significantly.",
    "start": "18090",
    "end": "23695"
  },
  {
    "text": "Absolutely. And last but not least is Chris\nHay, Distinguished Engineer and CTO of Customer Transformation\nchris, what do you think those",
    "start": "23965",
    "end": "31134"
  },
  {
    "text": "stupid pin things we got\nall excited about last year. All that and more on\ntoday's Mixture of Experts.",
    "start": "31135",
    "end": "38484"
  },
  {
    "start": "38000",
    "end": "634000"
  },
  {
    "text": "I'm Tim Hwang and welcome\nto Mixture of Experts. Each week, MoE brings together the\nsmartest and I think the most good",
    "start": "43050",
    "end": "48390"
  },
  {
    "text": "looking crew in all of podcasting\nto discuss and debate the biggest news in artificial intelligence.",
    "start": "48390",
    "end": "53429"
  },
  {
    "text": "And this is a big episode. Today we're officially celebrating\nour one year anniversary of MoE.",
    "start": "53670",
    "end": "58678"
  },
  {
    "text": "We brought together the original crew from\nMoE episode one to join us. All-star Crew. We're gonna do a look back, uh, cover a\ncall to action from J.P. Morgan, a new",
    "start": "59055",
    "end": "69765"
  },
  {
    "text": "wave of action in the Chinese AI market. But first, I really wanted to cover\nall the latest from  LlamaCon.",
    "start": "69765",
    "end": "75765"
  },
  {
    "text": "So I believe this was the first event,\nuh, officially the first LlamaCon that Meta has run, focusing on its\nwork in the open source space and",
    "start": "76065",
    "end": "83745"
  },
  {
    "text": "around the Llama class of models. Um, I think a lot of announcements to\ncover here, but I think Shobhit the first one that I was really intrigued\nto get your take on was they announced",
    "start": "83745",
    "end": "91810"
  },
  {
    "text": "this thing called Llama API, and it's\na developer platform that quote will bring together the best of closed\nsource with open source flexibility.",
    "start": "91810",
    "end": "99040"
  },
  {
    "text": "Um, and so for our listeners\nwho might be less familiar with this, like what have they done\nand why is it kind of a big deal? I always, in my opinion, I\nthink it's kind of a big deal.",
    "start": "99400",
    "end": "105730"
  },
  {
    "text": "Yeah. So today, uh, in the current state, if\nuh, an enterprise needs to go play around with Llama models, you go to one of\nyour hyperscaler partners and say you're",
    "start": "106470",
    "end": "114390"
  },
  {
    "text": "gonna use their version of the studio. Their way of fine tuning it and whatever\nthe hyperscalers are, are producing.",
    "start": "114390",
    "end": "121110"
  },
  {
    "text": "And then once you're done with\nthat model, it's difficult to move it around and whatnot. Right? So in this particular case, Meta is\ncoming out and saying we want to be",
    "start": "121470",
    "end": "128910"
  },
  {
    "text": "as developer friendly as possible. We'll give you a central place\nwith all the playgrounds, the",
    "start": "128910",
    "end": "134130"
  },
  {
    "text": "fine tuning capabilities, also\nevaluations, and so on, so forth. So as you're fine tuning the\nmodel, you can test it out.",
    "start": "134130",
    "end": "140129"
  },
  {
    "text": "All of that will be done centrally. They will host the API for Llama as well.",
    "start": "140609",
    "end": "145575"
  },
  {
    "text": "You can obviously still get it everywhere\nelse that you get your, uh, your  LLMS from, but now they're developing a\nwhole set of stack, so they're moving",
    "start": "145785",
    "end": "153855"
  },
  {
    "text": "beyond just providing the model to\nbe providing the whole ecosystem. They have done enough work in the space\nwith Llama Stack and a few other things",
    "start": "153855",
    "end": "161325"
  },
  {
    "text": "in the past, but this was their coming\nout party saying that we are gonna be as developer friendly as possible.",
    "start": "161325",
    "end": "166755"
  },
  {
    "text": "Come work with us, we'll\nhelp you fine tune it. Once you're done with that\nmodel, you can take it anywhere. Obviously there are a lot of things\naround privacy where they will not train",
    "start": "167015",
    "end": "174605"
  },
  {
    "text": "the model, uh, on the data that you're\nproviding them and so on and so forth. But the inference speed is, is\namazing with their partnerships",
    "start": "174605",
    "end": "181713"
  },
  {
    "text": "with service and GR and others. So overall, they wanna be the hub\nwhere people come and experiment with Llama models versus Llama models\nbeing one of the 200 models available",
    "start": "181714",
    "end": "192034"
  },
  {
    "text": "on Microsoft or AWS or Google. For sure. And Chris, maybe to bring you into this\nconversation, I was having a debate",
    "start": "192065",
    "end": "197640"
  },
  {
    "text": "with a friend about this announcement\nand we're kind of talking about like whether or not this is almost like a\nposition of strength for Meta or almost",
    "start": "197640",
    "end": "203250"
  },
  {
    "text": "like a position of weakness for Meta. There's one point of view which\nis, hey, we release these open source models and everybody will\nbuild all the tooling around it.",
    "start": "203250",
    "end": "210540"
  },
  {
    "text": "Essentially that's like kind of what\nwe do is we do the model and then like everybody else builds the ecosystem.",
    "start": "210575",
    "end": "215614"
  },
  {
    "text": "So that's kind of like\nthe, the, the bear case. And uh, my friend was like, well\nthe bull case is actually that. Like they recognize that like they're\nactually investing more in this space now.",
    "start": "216035",
    "end": "224255"
  },
  {
    "text": "And it's like really they recognize\nthat there's such a big opportunity that they have to actively build this stack. I'm curious if you kind of have\nany feelings about that or how",
    "start": "224524",
    "end": "231274"
  },
  {
    "text": "you kind of size up these moves. I think it's a really interesting move. I mean, as you kind of say,\nI think it's a great move.",
    "start": "231274",
    "end": "238085"
  },
  {
    "text": "I think  having a sort of standardized\nstack where you can bring your models, you can fine tune them, and,\nand I think fine tuning is gonna",
    "start": "238085",
    "end": "246820"
  },
  {
    "text": "become a bigger thing in the future. So, you know, because you're gonna want\nyour own personalized model, you're gonna want something with domain knowledge\nand therefore bringing that into a",
    "start": "246820",
    "end": "254650"
  },
  {
    "text": "consistent place, I think is a good thing. And then if you think about where\nMeta wants to go in the future, they",
    "start": "254650",
    "end": "260139"
  },
  {
    "text": "want AI to power all your avatars\nassistance, et cetera, uh, on their platforms and, and have agents on there.",
    "start": "260140",
    "end": "267189"
  },
  {
    "text": "Um. Then I think making it easier to have a\nplayground for developers and individuals",
    "start": "267460",
    "end": "273575"
  },
  {
    "text": "to, to tune models based on Llamas\nstack, I think is a sensible thing. I, I do think though, that when I really\nlook at this though, um, all the APIs",
    "start": "273575",
    "end": "284435"
  },
  {
    "text": "are OpenAI,  compatible APIs, and nearly\nevery single service provider is moving",
    "start": "284505",
    "end": "290284"
  },
  {
    "text": "towards OpenAI  compatible APIs anyway,\nso I, there is still a part of me that",
    "start": "290284",
    "end": "296205"
  },
  {
    "text": "goes, well, can I do that somewhere else? And, and, and sure with the fine tuning\npart specifically, that is hard, right?",
    "start": "296205",
    "end": "303615"
  },
  {
    "text": "Because, you know, getting your\nmodels out of some of those existing stacks and taking 'em\nelsewhere is a more difficult thing.",
    "start": "303615",
    "end": "309044"
  },
  {
    "text": "So I think, I think that\nis a differential play in my mind. Totally. Yeah. It's getting more complicated,\nkind of seeing them navigate this.",
    "start": "309045",
    "end": "315825"
  },
  {
    "text": "Christian, another part of the\nannouncement that I wanted you to comment on was that they also\nannounced all of these kind of security and protection models.",
    "start": "316285",
    "end": "322645"
  },
  {
    "text": "Um, so Llama Guard, four Llama\nfirewall, Llama, Prompt Guard 2. It kind of feels like a little bit of\nlike, almost like the protection space",
    "start": "322675",
    "end": "331135"
  },
  {
    "text": "around AI starting to get like a lot\nmore complicated than it used to be. Where the old thing was like, oh, well\nwe just have a model that tells you",
    "start": "331135",
    "end": "336535"
  },
  {
    "text": "if like the outputs are toxic now. It feels like they've got like at every\nlayer of the stack, there's like a model you can use for security and safety.",
    "start": "336535",
    "end": "343044"
  },
  {
    "text": "Um, curious about how you kind\nof like read these trends. Like where is this going? Is it just gonna become like a\nmore and more complicated, you",
    "start": "343409",
    "end": "349229"
  },
  {
    "text": "know, ecosystem of safety models? Um, yeah, just curious\nabout your hot take on that. Yeah.",
    "start": "349229",
    "end": "354330"
  },
  {
    "text": "Um, so yeah, as you said, I mean, they,\nuh, have this new, uh, Llama Guard 4,",
    "start": "354330",
    "end": "359800"
  },
  {
    "text": "uh, it's uh, 12 billion parameter model. Um, it's multimodal, so it has\nthe vision and the text in there.",
    "start": "359820",
    "end": "365729"
  },
  {
    "text": "Um. Uh, the, uh, the prompt card they\nmade really tiny, I think, uh, 22,",
    "start": "365729",
    "end": "370675"
  },
  {
    "text": "uh, million parameters and stuff. So, yeah, I mean, they're making progress. Certainly. Um, uh, the headlines are good.",
    "start": "370915",
    "end": "376585"
  },
  {
    "text": "Um, uh, uh, we haven't had a\nchance to, to evaluate and see, uh, what the performance is yet.",
    "start": "376765",
    "end": "382465"
  },
  {
    "text": "And, um, yeah, actually just, uh, a\nweek and a half ago, um, uh, maybe two weeks ago, there was a new, uh.",
    "start": "382615",
    "end": "387955"
  },
  {
    "text": "A benchmark that came out,\nuh, called Guard Bench. Uh, so this Guard Bench, um, actually\ngoes and tests, um, a lot of, uh, of",
    "start": "388085",
    "end": "396215"
  },
  {
    "text": "different Guardrail models and and stuff. Um, uh, just a a side note, uh, the\nGranite Guardian model that I've",
    "start": "396215",
    "end": "402185"
  },
  {
    "text": "talked about in the past is, uh,\nat the top of that leaderboard, but, um, uh, we should see, I mean,\nhow is, uh, how is the big deal?",
    "start": "402185",
    "end": "408784"
  },
  {
    "text": "Yeah, exactly. The how's Llama Guard for, uh, uh, doing\nthere because, uh, if they've really made",
    "start": "409025",
    "end": "415025"
  },
  {
    "text": "good progress, that's, uh, that's awesome. Um. And, uh, I mean, the fact that the,\nuh, the prompt card is so tiny, I",
    "start": "415145",
    "end": "421815"
  },
  {
    "text": "think, uh, that, because that's gonna\nmake a, make a huge difference because it's like 22 million parameters.",
    "start": "421815",
    "end": "427035"
  },
  {
    "text": "It's like a blink of the eye. I mean, it's like, uh,\nuh, you can do it so fast. So, I mean, I think the\noverall space is, uh, just.",
    "start": "427035",
    "end": "434175"
  },
  {
    "text": "Becoming where people are realizing\nthe seriousness of safety and security. So, uh, just having everything there.",
    "start": "434485",
    "end": "441025"
  },
  {
    "text": "I mean, multiple layers of security. I mean, that's, uh, just good practice. Uh, so having it, uh, on the inputs, on\nthe outputs, um, the overall firewall.",
    "start": "441025",
    "end": "449995"
  },
  {
    "text": "I mean, all of that is, uh, is good stuff. And then we'll see, uh, I mean, how it\ngoes, uh, how it progresses and, um, uh.",
    "start": "449995",
    "end": "457405"
  },
  {
    "text": "I mean, no, uh, no concern for me. I think this is where,\nwhere the field needs to go. Um, Shobhit, before we move on to our\nnext topic, any other, uh, kind of",
    "start": "458155",
    "end": "465025"
  },
  {
    "text": "announcements that you'd highlight? I know there's a bunch announced. Those are the kind of two that\nstood out to me, but I know there's, like, I saw the whole blog post.",
    "start": "465025",
    "end": "470515"
  },
  {
    "text": "There's like a lot going on. Yeah.\nYeah. Um, the other couple things were\none was around their Meta AI app.",
    "start": "470515",
    "end": "475855"
  },
  {
    "text": "They have consolidated all of their\nintelligence into one app, and that could be a ChatGPT competitor or Gemini\nand so on and forth, but they want one",
    "start": "476765",
    "end": "484385"
  },
  {
    "text": "app that people can go and do, do some\ncool things and, and, and talk to it. And they have the potential to make this\nsuper hyper-personalized because they",
    "start": "484385",
    "end": "493025"
  },
  {
    "text": "have billions of, of, uh, interactions\nhappening across all of their. WhatsApp and Instagram\nand um, and Facebook.",
    "start": "493025",
    "end": "499845"
  },
  {
    "text": "You could potentially have a avatar\nthat is really personalized to your particular needs and wants and\nthings that you care about, right?",
    "start": "500115",
    "end": "506955"
  },
  {
    "text": "It is a delicate balance between\nprivacy and hyper-personalization. They'll have to do that\nbalance re uh, delicately.",
    "start": "507555",
    "end": "514604"
  },
  {
    "text": "But they, they have a huge bet on\ncreating the one app where you go to for all of your, uh, all of your AI.",
    "start": "514860",
    "end": "521039"
  },
  {
    "text": "There are a few other things that may\nhave been, uh, like brushed off in the, in the details, but they have\ndone, they've had about 1.2 billion",
    "start": "521520",
    "end": "529618"
  },
  {
    "text": "downloads of Llama models and most,\nand a lot of those, like majority of those are derivatives of Llama.",
    "start": "529620",
    "end": "534839"
  },
  {
    "text": "On Hugging Face and other places, right? So clearly the momentum around open\nsource with the developer community is amazing and Llama has had a\nhuge impact on where we are today",
    "start": "535590",
    "end": "544020"
  },
  {
    "text": "with open models versus others. But there were a few things where I was,\nwas still on my wishlist that, that we",
    "start": "544020",
    "end": "550890"
  },
  {
    "text": "couldn't quite, that they didn't get to. Uh, there are two other models\nthat they had announced. They're not coming quite yet.",
    "start": "550890",
    "end": "556050"
  },
  {
    "text": "One is their small little Llama model. That'll be about an 8\nbillion parameter model.",
    "start": "556290",
    "end": "561120"
  },
  {
    "text": "8 billion was the, was the most\npopular size of the Llama model from the last, uh, previous generation.",
    "start": "561675",
    "end": "566625"
  },
  {
    "text": "We have not announced, seen that yet,\nbut that would be a game changer for our enterprises, especially if you have\ngood methods of distilling it down.",
    "start": "567165",
    "end": "573615"
  },
  {
    "text": "And then on the other end of the\nspectrum is the behemoth model. They still need to figure\nout what they do with it. It's not something that's practical at,\nat this size to be run by enterprises, but",
    "start": "573885",
    "end": "582855"
  },
  {
    "text": "we need to figure out what's the right way\nof displaying it down or can I use that to train or other models and so on and forth.",
    "start": "582855",
    "end": "588765"
  },
  {
    "text": "There are other things around, uh,\nmulti-agent orchestration that I was expecting Llama to, to release as well.",
    "start": "589110",
    "end": "595140"
  },
  {
    "text": "Uh, like things like MCP support\nand agent to agent, uh, protocols or anything around agent ops as\npart of the whole Llama stack.",
    "start": "595470",
    "end": "604050"
  },
  {
    "text": "I'm waiting for them to announce\nmore things in that space as well. But overall, really positive. Uh, it's good to see that we are\ncelebrating open source, getting",
    "start": "604050",
    "end": "611580"
  },
  {
    "text": "closer and closer to, uh, to\nthe frontier models as well. So great LlamaCon for all of us.",
    "start": "611580",
    "end": "616920"
  },
  {
    "text": "We had a good partnership with them. IBM and Box have done some\namazing work with Llama was was announced on stage as well.",
    "start": "617025",
    "end": "623535"
  },
  {
    "text": "So overall, very positive for all of us.\nThe community has enjoyed it. That's great. Yeah.\nAnd a lot more to come. I'm sure what you talked about is\nlike gonna be coming out like in the",
    "start": "623685",
    "end": "630704"
  },
  {
    "text": "next, very soon I think probably.",
    "start": "630704",
    "end": "632774"
  },
  {
    "start": "634000",
    "end": "1403000"
  },
  {
    "text": "This is great. And I, speaking of open, I think\nI'll move us onto to our next topic. Uh, we wanted to do a kind of short\nsegment because there's been a",
    "start": "637725",
    "end": "643515"
  },
  {
    "text": "lot of kind of interesting things\nbubbling up, particularly in open source, um, in the Chinese market. And I did want to spend a little\nbit of time, uh, talking about that.",
    "start": "643515",
    "end": "651555"
  },
  {
    "text": "Um, one that we have that has actually\ncome out is that Alibaba has launched Qwen3  um, which is, uh, a kind of whole\nclass of models that they've kind of",
    "start": "651585",
    "end": "660255"
  },
  {
    "text": "put out, which is the latest generation\nof their kind of Qwen3 generation. Of models. Um, and I guess Chris, I think I wanted\nto kind of start with a little bit of",
    "start": "660255",
    "end": "667689"
  },
  {
    "text": "like a kind of like technical explainer. So in the blog post they talk a little\nbit about how these models are, what they call hybrid models, which combine\nquote thinking and non-thinking modes.",
    "start": "667689",
    "end": "677199"
  },
  {
    "text": "Um, and I think again, in true, uh,\nAI form, we picked all sorts of terminology that's like very confusing.",
    "start": "677470",
    "end": "683200"
  },
  {
    "text": "It's like, what is a hallucination? Anyways. Um, and so I guess I wanted to kind\nof just initially start with like",
    "start": "683200",
    "end": "688600"
  },
  {
    "text": "what is a thinking and non-thinking\nmode when it comes to AI and like why is it kind of important\nfor what they're doing here?",
    "start": "688844",
    "end": "694574"
  },
  {
    "text": "Yeah, so when we hear thinking, I will,\nI think of it as the kind of reasoning models, like the o1's,  o3's, o4's, right?",
    "start": "694964",
    "end": "701175"
  },
  {
    "text": "So, uh, in those particular cases, if\nyou think of what a model is, it is a kind of next token prediction model.",
    "start": "701175",
    "end": "707655"
  },
  {
    "text": "So, you know, it is gonna be\ntoken, token, token, token. So whenever it's answering a question\nand that, and that works great.",
    "start": "707655",
    "end": "713385"
  },
  {
    "text": "Um, but you can imagine some of these. Problems are a lot harder to solve. And therefore, if you equate the thinking\ntime to the number of tokens that you",
    "start": "713625",
    "end": "721615"
  },
  {
    "text": "generate, then the more tokens that\nyou generate, the more likely you're gonna get some sort of good answer.",
    "start": "721615",
    "end": "728095"
  },
  {
    "text": "Right. And, and so when you were saying thinking\nmode, in that sense, it's like, like a human being rather than blurting out the\nfirst thing that comes into your mind.",
    "start": "728095",
    "end": "736345"
  },
  {
    "text": "Spend a little bit of time deliberating\nthe, you know, whatever the answer is gonna be before you open your\nmouth and, and, uh, announce your",
    "start": "736480",
    "end": "745509"
  },
  {
    "text": "feelings to the world, right? Um, and keep those thoughts inside. Keep them inside. So, so regular human\nbeings don't know about it.",
    "start": "745510",
    "end": "752440"
  },
  {
    "text": "So that, that is kind of what\nthe idea of thinking is there. Now there is some class\nof questions where.",
    "start": "752440",
    "end": "758560"
  },
  {
    "text": "No matter how long you think about\nit, thinking is not gonna help. Right? So things like, you know, what\nis the capital of England, right?",
    "start": "758735",
    "end": "768485"
  },
  {
    "text": "So if you don't know the answer,\nsitting and thinking about it really isn't gonna help you, right? So, but doing something like a math\nproblem or a logical or reasoning problem,",
    "start": "768725",
    "end": "778055"
  },
  {
    "text": "if there are six cats and one falls out\nthe window, how many cats do you have left and how many lives is it's got?",
    "start": "778055",
    "end": "784834"
  },
  {
    "text": "Then it needs to think about\nthat a little bit and then. You know, it'll come to the answer and\ntherefore you'll generate those tokens.",
    "start": "785195",
    "end": "791645"
  },
  {
    "text": "So the idea of being able to\nsort of have this hybrid mode. In reality, you, for some cases,\nyou want thinking switched off right",
    "start": "791915",
    "end": "801390"
  },
  {
    "text": "quick questions, you know, general\nq and a type knowledge answers. But if you're doing logic and\nreasoning, you want the ability to",
    "start": "801390",
    "end": "807330"
  },
  {
    "text": "switch that on and have the model take\na little bit of time to think about that and come back with the answer. So, um, I still think this is a,\nthis is a problem today that is",
    "start": "807330",
    "end": "817920"
  },
  {
    "text": "gonna go away in the future, right? Just like human beings, you know, we\nhave learned when to blurt out an answer",
    "start": "818495",
    "end": "824974"
  },
  {
    "text": "and when not to blurt out an answer. You don't say to human being, I mean, speak for yourself, Chris. I,",
    "start": "824974",
    "end": "829435"
  },
  {
    "text": "well, actually, maybe not right,\nbut maybe I haven't learned, but. I, I think, I think in, in, in time.",
    "start": "831995",
    "end": "839385"
  },
  {
    "text": "Then I think that's gonna relax there. And we're not gonna have to switch that\non or off, but I, I do like this idea",
    "start": "839385",
    "end": "844815"
  },
  {
    "text": "of the future of like a thinking budget. You know, you've got five minutes to think\nabout it, three minutes to think about it. So I think this practice is\ngonna evolve, but I think is,",
    "start": "844815",
    "end": "852615"
  },
  {
    "text": "is very much a positive of the, uh, the hybrid mode. And Chris, I think one thing that's\nbeen raised before, but it might be",
    "start": "852675",
    "end": "859210"
  },
  {
    "text": "kind of fun to kind of tackle it more\ndirectly with kind of this segment and these releases that are coming out.",
    "start": "859210",
    "end": "864460"
  },
  {
    "text": "Um, you know, some people have commented\nlike, I think, um, uh, Kate might have",
    "start": "864550",
    "end": "869709"
  },
  {
    "text": "mentioned it on a previous episode, but we're really kind of, sort of\nstarting to see like the, the, the return of mixture of experts.",
    "start": "869710",
    "end": "876135"
  },
  {
    "text": "Like it feels like that is like\nnow very much back on the table. It's like what everybody's doing. So like what was kind of uncool\nagain is like really back and forth.",
    "start": "876345",
    "end": "884025"
  },
  {
    "text": "Um, and so wanna talk I guess a little\nbit about like why that's the case now that we're kind of seeing it in Qwen3\nand is rumored for the DeepSeek-R2",
    "start": "884355",
    "end": "892645"
  },
  {
    "text": "launch, which is kind of gonna also\npotentially be coming out maybe even by the time this episode releases is rumors\nthat happened potentially this week?",
    "start": "892665",
    "end": "898904"
  },
  {
    "text": "Yeah, I mean, uh. Whoever came up with the name of this\npodcast, uh, was, uh, quite prescient.",
    "start": "898935",
    "end": "904240"
  },
  {
    "text": "I mean, uh, \"Mixture of Experts.\"\num, uh, the term has been around for, for a long time. It meant something different, uh,\nwhen I was in grad school, um, so with",
    "start": "904599",
    "end": "913120"
  },
  {
    "text": "these gating mechanisms and stuff. But, um, uh, I mean, the point\nof it is, uh, really, uh...",
    "start": "913120",
    "end": "919839"
  },
  {
    "text": "I mean, just like Chris was saying,\nlike humans, uh, don't blurt stuff out. Humans also don't use their entire\nbrain when they're thinking, right?",
    "start": "920075",
    "end": "927815"
  },
  {
    "text": "I mean, the, I don't\nknow what the stat is. Like we only use 10% of our\nbrain at, at a time, right? Um, so, uh, same idea.",
    "start": "927815",
    "end": "934715"
  },
  {
    "text": "I mean, you don't need\nto, you use everything. You don't need to activate everything. Um, uh, because, uh, really\nthere's, uh, a portion that's, um,",
    "start": "934715",
    "end": "942694"
  },
  {
    "text": "really the, the important part when\nyou're, uh, thinking about something, computing something, what, whatever\nhave you in inferring something.",
    "start": "943280",
    "end": "949730"
  },
  {
    "text": "And so, uh, I think it's just\ntaking advantage of that. Uh, I mean, you can use less power, less\ncomputation, less, uh, of everything.",
    "start": "949730",
    "end": "957380"
  },
  {
    "text": "Um, if you're only activating\nthe, the relevant parts. And then if you can know, um, uh,\nwhich parts to, to activate, uh,",
    "start": "957439",
    "end": "963920"
  },
  {
    "text": "then, uh, then, then that's gonna\nend up being a, a good thing. And then you can have, uh, kind\nof, uh, different, uh, sort of",
    "start": "963920",
    "end": "970279"
  },
  {
    "text": "specializations, different sort of, uh, things that are, are, are better\nat, uh, at particular, uh, aspects.",
    "start": "970280",
    "end": "976500"
  },
  {
    "text": "So, uh, about of cats falling outta\ntrees, uh, mixture of expert or an expert",
    "start": "976500",
    "end": "982740"
  },
  {
    "text": "and then, uh, uh, I mean what,\nwhatever, I mean, all sorts of different experts on there. So I think, uh, that's where,\nwhere things are headed.",
    "start": "982740",
    "end": "989400"
  },
  {
    "text": "Sure. But I think the final bit that I\nwas hoping to get your take on is, you know what I love about the sort\nof DeepSeek  story is how much it",
    "start": "989650",
    "end": "997120"
  },
  {
    "text": "is kind of like messing with all of\nour intuitions about how competition and AI is like supposed to go down.",
    "start": "997120",
    "end": "1002280"
  },
  {
    "text": "So the first one of course was like, oh,\nokay, in the US it was Meta doing open source versus these closed source guys.",
    "start": "1002550",
    "end": "1008610"
  },
  {
    "text": "And so the introduction, introduction\nof DeepSeek  is like, oh, well now even Meta has competition. Yeah. Um, and I think the other\nreally interesting element",
    "start": "1008730",
    "end": "1015960"
  },
  {
    "text": "that's been rumored around R2. Is that they are doing the training\nnot on the video, which I think is",
    "start": "1015960",
    "end": "1022240"
  },
  {
    "text": "really intriguing and also kind of\ncompletely scrambles the idea that like, oh, everybody's gonna just build\non, you know, Jensen's chips and that's",
    "start": "1022240",
    "end": "1028510"
  },
  {
    "text": "gonna just be the way the AI works. Yeah. I think what I read in the blog post was\nthat the rumors that R2  was trained on",
    "start": "1028510",
    "end": "1033579"
  },
  {
    "text": "a server cluster of Huawei's Ascends 910B yes, chip, which would mark a really big\ntransition in how some of this hap happens",
    "start": "1033580",
    "end": "1042109"
  },
  {
    "text": "kind of at the, at the cutting edge. Do you wanna talk a little bit about that? I thought it was very interesting. Yeah, so I think over\ntime China is brilliant.",
    "start": "1042139",
    "end": "1049040"
  },
  {
    "text": "Uh, like the people, people\nare just absolutely stunning in these research labs, right? So they're very high\nconcentration of talent.",
    "start": "1049100",
    "end": "1054980"
  },
  {
    "text": "So they're trying to figure out\nways around, uh, supply chain, like their dependence on the US supply\nchain for intelligence, right?",
    "start": "1055399",
    "end": "1061490"
  },
  {
    "text": "So their own. They have a lot of intelligence\nto go build their own chips. There's a competition around not just\nthe chip, but the whole, uh, the whole",
    "start": "1061490",
    "end": "1068755"
  },
  {
    "text": "set of things that go before and after\nthe ecosystem around the chips as well. And China, I think has\na good shot at this.",
    "start": "1068755",
    "end": "1075385"
  },
  {
    "text": "They should be able to go and look\nat the Huawei, uh, a series of chips. And this is a really good\nuse case on printing them.",
    "start": "1075385",
    "end": "1081955"
  },
  {
    "text": "If you look at what Google did with their\ntensor processing units, the tpu right. They have a unfair advantage\nthat they have both all the",
    "start": "1082315",
    "end": "1089294"
  },
  {
    "text": "AI and the chip manufacturing. So when they release their models\nlike Gemini, which are running at",
    "start": "1089294",
    "end": "1094575"
  },
  {
    "text": "like crazy, uh, um, volume, uh,\nevery day, they need to make sure that they're super hyper optimized.",
    "start": "1094575",
    "end": "1100725"
  },
  {
    "text": "Like the Gemini Flash model,\nfor example, running on TPUs. Is a really good price point at scale\nwith billions of these every day, right?",
    "start": "1100725",
    "end": "1107790"
  },
  {
    "text": "So you'll start to see a lot of these,\nuh, companies start to leverage the architecture underlying optimize that,\nand China understands that they will not",
    "start": "1108030",
    "end": "1116190"
  },
  {
    "text": "always be able to get access to the, the,\nthe technology from the rest of the world. So they will start to create their\nown supply chain top to bottom.",
    "start": "1116190",
    "end": "1123450"
  },
  {
    "text": "There's a lot of investment\ncoming from each of the countries in their own sovereign AI and\ntrying to make sure that they can.",
    "start": "1123960",
    "end": "1129000"
  },
  {
    "text": "Uh, they can be, uh, masters of their own\ndestiny in the, in the AI space, right? I'm very excited about this whole David\nversus Goliath kind of a war, right?",
    "start": "1129470",
    "end": "1139250"
  },
  {
    "text": "If you're looking at the size of the\nmodel that Qwen3  came out with, you have, um, a good mixture of experts model\nwhere the number of active parameters are",
    "start": "1139250",
    "end": "1147409"
  },
  {
    "text": "very, very low and they're out competing\nsome of the best in class models from",
    "start": "1147410",
    "end": "1152629"
  },
  {
    "text": "open AI and Google and Llamas, right? So you have this, this, this crazy",
    "start": "1152660",
    "end": "1157820"
  },
  {
    "text": "compute, um, intelligence per dollar,\nthat's just completely plummeting and that",
    "start": "1158400",
    "end": "1164640"
  },
  {
    "text": "unlocks an insane amount of, uh, other use\ncases that we would deploy this at, right? If you look at the way we, within IBM are\nlooking at, say, our Z series and stuff",
    "start": "1164640",
    "end": "1172140"
  },
  {
    "text": "too, we want to bring AI closer and closer\nto where the transactions are happening. Billions of these in with\nalmost negligible latency.",
    "start": "1172140",
    "end": "1180570"
  },
  {
    "text": "So I think the whole size of\nthe model being smaller and outcompeting is a great thing. Taking this open source and\nthese are Apache 2.0 licenses.",
    "start": "1180840",
    "end": "1188705"
  },
  {
    "text": "Creating derivatives out of it and\nowning that intellectual property, carrying it with you, deploying it\nwhere you need to be at the edge",
    "start": "1189395",
    "end": "1195515"
  },
  {
    "text": "on the servers, on the clouds. I think that's the future\ndirection that they were taking. We should be very, very, uh, proud\nof how far the AI community has come,",
    "start": "1195515",
    "end": "1204045"
  },
  {
    "text": "on the open source models and the\nprogress that we are making this space. But I think going back to what, what\nKush was mentioning around all the",
    "start": "1204305",
    "end": "1211189"
  },
  {
    "text": "Guardrails that are needed, when we see\nmodels, uh, like Qwen3 come out, we do not see a lot more transparency on the\ndata that went in or any Guardrails and",
    "start": "1211189",
    "end": "1219470"
  },
  {
    "text": "stuff that have put, or any, like the\nequivalent of the Llama Guards or the granite Guardians being released from the\nChinese labs at, at this point quite yet.",
    "start": "1219470",
    "end": "1227929"
  },
  {
    "text": "Right. Qwen3  models. They are text only at this point. They're not quite multimodals.",
    "start": "1227929",
    "end": "1234075"
  },
  {
    "text": "That kind of reduces the space of\nwhat use cases we can deploy them at. So a few, few things that they, they\ndo need to catch upon, but there's",
    "start": "1234075",
    "end": "1240615"
  },
  {
    "text": "just so much happening in this space. This competition is really,\nreally positive for all of us. I think there's a flip to that\nas well, which is I, I think.",
    "start": "1240615",
    "end": "1249375"
  },
  {
    "text": "Although they're not being particularly\nopen on data, I think labs like DeepSeek,  et cetera, maybe not so much\nkind of Qwen there, but, uh, Alibaba.",
    "start": "1249925",
    "end": "1258175"
  },
  {
    "text": "But they're being very open\nwith their code bases, right? So they open source, their\ndistributed file system, et cetera.",
    "start": "1258175",
    "end": "1264745"
  },
  {
    "text": "So I think one of the things that I\nreally appreciate in this space with the competition is that the innovation\nis moving out into the open source",
    "start": "1264955",
    "end": "1274045"
  },
  {
    "text": "community, and I think, because these\nlabs are being constrained, it is",
    "start": "1274045",
    "end": "1279645"
  },
  {
    "text": "forcing them to think in a different way. So I, I actually really hope that some\ncrazy kid in a garage somewhere is just",
    "start": "1279645",
    "end": "1286665"
  },
  {
    "text": "gonna turn up one day and go, I've trained\na 50 billion trillion parameter model",
    "start": "1286665",
    "end": "1291945"
  },
  {
    "text": "and, and I've done it with a cheeseburger\nand, you know, and, and I just took",
    "start": "1292185",
    "end": "1297460"
  },
  {
    "text": "this chip at my microwave and it was fine. Do you know what I mean? And we'll be like, whoa.",
    "start": "1297620",
    "end": "1302510"
  },
  {
    "text": "And then what do we do with all\nof those chips at that point? And I, I, but I actually, I think there's\na really serious problem there is like",
    "start": "1302810",
    "end": "1309409"
  },
  {
    "text": "when the next innovation comes, right? And it will come at some point where we\nrealize we don't need all of these GPUs.",
    "start": "1309919",
    "end": "1317540"
  },
  {
    "text": "Well, what are we going to do with all of\nthese GPUs and these massive data centers? And, and again, if.",
    "start": "1317870",
    "end": "1323120"
  },
  {
    "text": "If NVIDIA wants to donate some to\nme, I will happily take them and I\nwill find something to do with them.",
    "start": "1323294",
    "end": "1328665"
  },
  {
    "text": "You hear that Jensen? If you're listening, uh, We always talk about\nChina and US, right?",
    "start": "1329115",
    "end": "1334695"
  },
  {
    "text": "Um, I'm not sure if you guys know this. There was a new model that\ncame out, uh, in the last few days for voice, speech to text.",
    "start": "1335175",
    "end": "1341655"
  },
  {
    "text": "There's a company, a small lab\nthat are two Korean undergrads. Who put this model together\ncalled D-I-A, uh, Dia.",
    "start": "1342014",
    "end": "1349960"
  },
  {
    "text": "Dia does speech to text\nwith a very high accuracy. It understands accents,\nbackground eyes, like uh, it",
    "start": "1350560",
    "end": "1356530"
  },
  {
    "text": "does a really, really good job. And it's outcompeting the bigger\nlabs, like 11 Labs or um, even OpenAI,",
    "start": "1356620",
    "end": "1363039"
  },
  {
    "text": "voices and stuff like that. Super small. Apache 2.0 open sourced it. So you're seeing innovation\nfrom all over the world.",
    "start": "1363040",
    "end": "1369549"
  },
  {
    "text": "This is not just a US versus. Uh, China, and at times you hear\nMistrial from France, right? But this is a global moment.",
    "start": "1369550",
    "end": "1376085"
  },
  {
    "text": "Right now. Everybody is investing heavily in India. You have a lot of labs that\nare now getting a lot of, uh,",
    "start": "1376355",
    "end": "1382145"
  },
  {
    "text": "investment to go build these\nmodels and own your own destiny. So just the fact that the whole community,\nthe global community is all in on",
    "start": "1382145",
    "end": "1389404"
  },
  {
    "text": "open source and powering through it. That's, that's the way we should be. And, and Shobhit, just to add to that Sir\nDemis Hassabis,  I mean, please",
    "start": "1389405",
    "end": "1396404"
  },
  {
    "text": "note the word \"Sir.\" I don't hear\nno American accent on him, buddy.",
    "start": "1396425",
    "end": "1400205"
  },
  {
    "start": "1403000",
    "end": "2385000"
  },
  {
    "text": "That's actually a great\npivot into our next segment. Uh, one thing I did really want to\ncover was this, uh, pretty interesting",
    "start": "1407000",
    "end": "1412280"
  },
  {
    "text": "letter that came outta J.P. Morgan,\nPatrick Opet, who is their Chief Information Security Officer.",
    "start": "1412280",
    "end": "1417409"
  },
  {
    "text": "Pens sort of an open letter to the\nindustry that was kind of a call to action to work on SaaS security, which\nis a, a big problem and a known problem,",
    "start": "1417729",
    "end": "1425600"
  },
  {
    "text": "but I thought was pretty interesting\nis that he focused specifically on, um, AI and its contribution to this issue.",
    "start": "1425600",
    "end": "1431510"
  },
  {
    "text": "So I'll just quote what he said. He said critically. The explosive growth of new value bearing\nservices and data management, automation,",
    "start": "1431510",
    "end": "1438225"
  },
  {
    "text": "artificial intelligence, and AI agents\namplifies and rapidly distributes these risks, bringing them directly to\nthe forefront of every organization.",
    "start": "1438225",
    "end": "1446145"
  },
  {
    "text": "And so kind of, there's a SaaS\nsecurity issue and then AI's gonna basically like pour gasoline on it. And I guess, Chris, we both throw it\nto you as like, this seems pretty dire.",
    "start": "1446145",
    "end": "1453735"
  },
  {
    "text": "Are we, are we in trouble? Uh, I don't know if there's anything new\nthat, uh, is being said in this letter.",
    "start": "1453735",
    "end": "1460870"
  },
  {
    "text": "Really. I mean, yes, agents of course. Um, but, uh, uh, we've had agents\nreally, I mean, for, for decades.",
    "start": "1460870",
    "end": "1468490"
  },
  {
    "text": "And in some ways, if you think about\nit, I mean the, uh, the autonomy, the, um, uh, the, the action\ntaking is, is not particularly new.",
    "start": "1468490",
    "end": "1476470"
  },
  {
    "text": "I mean, with AI agents these days, it's\nthe interaction through natural language. Um. More data and, and this sort of stuff.",
    "start": "1476470",
    "end": "1482625"
  },
  {
    "text": "But, um, I mean, there's been\nthings, I mean, Shobhit mentioned the, the Z processors and stuff.",
    "start": "1482625",
    "end": "1488594"
  },
  {
    "text": "I mean, transactions happen,\nthings happen very quickly. Um, there's been, um, I mean, software\nas a service for more than a decade.",
    "start": "1488594",
    "end": "1496155"
  },
  {
    "text": "Um, and, uh, like really, I mean,\nthe point of the letter is yes, I",
    "start": "1496635",
    "end": "1502185"
  },
  {
    "text": "mean, focus on security, of course. I mean, uh, like who's not gonna say yes.",
    "start": "1502185",
    "end": "1506985"
  },
  {
    "text": "Um, maybe there's a culture sort\nof issue that's, uh, being pointed out that, uh, uh, maybe we need to\nthink more, um, about these, uh,",
    "start": "1507480",
    "end": "1516810"
  },
  {
    "text": "important consequential industries. Regulated industries and\nstuff at the forefront. Maybe, uh, like you said, Tim,\nI mean, the mixture of experts.",
    "start": "1516810",
    "end": "1523409"
  },
  {
    "text": "We don't cover the, that\nin industry so much. Maybe we should, um, and other\nsort of industries like this.",
    "start": "1523410",
    "end": "1528990"
  },
  {
    "text": "But, uh, yeah, I mean, like for people\nwho do work in those industries, um, this",
    "start": "1528990",
    "end": "1534570"
  },
  {
    "text": "is not a, a, like anything new really. So this is a good reminder for everybody, uh,\nthat like you have to think about the",
    "start": "1534570",
    "end": "1541885"
  },
  {
    "text": "governance as we move from experiments\nto going into production at scale. And I'll give you my take on a more of\na, from an enterprise perspective, right?",
    "start": "1541885",
    "end": "1550014"
  },
  {
    "text": "When I'm working with my clients and we\nare putting things into production, I. Across all of these different\nSaaS vendors, everybody else is",
    "start": "1550044",
    "end": "1556549"
  },
  {
    "text": "in this rush to force agents into\ntheir SaaS, uh, platforms, right? The, like even industry standards\nlike MCP, it took them a while.",
    "start": "1556550",
    "end": "1565969"
  },
  {
    "text": "It like worked different\nversions to get to supporting authentication properly, right? This is so much in software\nengineering that has been done",
    "start": "1565969",
    "end": "1573985"
  },
  {
    "text": "to secure things the right way. And we are almost like throwing that away\nand starting from scratch when you're",
    "start": "1574340",
    "end": "1579590"
  },
  {
    "text": "getting to these agents and stuff, right? We have collectively decided as\na humanity that English is the",
    "start": "1579590",
    "end": "1585404"
  },
  {
    "text": "way to talk to these agents and\nit just does not scale quite yet. Right? If I'm trying to to call another agent\nand give it a task, I need more structure.",
    "start": "1585405",
    "end": "1594495"
  },
  {
    "text": "'cause I need to do error catching. I need to be able to pass authentication\nfor this particular task I'm giving",
    "start": "1594525",
    "end": "1599835"
  },
  {
    "text": "you read access to this particular\ndata set and whatnot, right? So we need to evolve beyond the\ncute demos that we have all done",
    "start": "1599835",
    "end": "1606825"
  },
  {
    "text": "on stage last year and this year. As you get more and more, uh, uh,\nmore serious about rolling these",
    "start": "1606825",
    "end": "1614360"
  },
  {
    "text": "out at scale, the governance aspects\nof it, you have 10 different, uh,",
    "start": "1614360",
    "end": "1619429"
  },
  {
    "text": "SaaS vendors for the marketing team\nthat you're working with, right? The CMO is not spending that much\ntime understanding what's happening",
    "start": "1619639",
    "end": "1625699"
  },
  {
    "text": "with all of that data is everything. If, if I have to go put a small policy\nand a policy could be as simple as:",
    "start": "1625699",
    "end": "1631939"
  },
  {
    "text": "I don't want generative AI\nto create any content that refers to these 10 competitors.",
    "start": "1632605",
    "end": "1638575"
  },
  {
    "text": "If I give it that small a tos, such\na basic thing to do, it's insane how much effort it'll take for all these\nenterprises to go make that happen",
    "start": "1639025",
    "end": "1646705"
  },
  {
    "text": "in every 10, 20, 30 different SaaS\nvendors that they're working with. So we are struggling as, uh, when we\nare delivering these with enterprises.",
    "start": "1646705",
    "end": "1653295"
  },
  {
    "text": "That's why all the work that Kush\nand team are doing around governance, around security, guardrails, things\nof that nature are so important.",
    "start": "1653415",
    "end": "1658934"
  },
  {
    "text": "And this has to work across regardless\nof which AI model that you're bringing into the organization.",
    "start": "1659295",
    "end": "1664305"
  },
  {
    "text": "So I think J.P. Morgan Chase is\ndoing a really good job at giving a reality check to leadership. And what J.P. Morgan does is often\nimitated and copied and people",
    "start": "1664485",
    "end": "1673485"
  },
  {
    "text": "in, uh, get inspired by the work\nthat they've done in the space. We need more people to talk about\ngovernance and the reason why we need",
    "start": "1673635",
    "end": "1680809"
  },
  {
    "text": "smaller models that you can monitor. You have the right guardrails,\neven speech models as you start",
    "start": "1680810",
    "end": "1686000"
  },
  {
    "text": "to move from just text-based  LLMS\nto now speech to speech native. I'm trying to roll something out\nat one of our regulated industry",
    "start": "1686000",
    "end": "1694010"
  },
  {
    "text": "clients and it's very tricky. The speech models tracing, looking\nat auditability, the agent ops",
    "start": "1694010",
    "end": "1701239"
  },
  {
    "text": "that's needed for speech models\nand stuff is insanely difficult. There's a lot that this\ncommunity is gonna do.",
    "start": "1701239",
    "end": "1706795"
  },
  {
    "text": "I would say if 2025 we say is the year\nof the agents, I would argue that 2025",
    "start": "1707125",
    "end": "1712345"
  },
  {
    "text": "is the, is the year of governance. We got to get this right if we have a\nshot at going at production, at scale.",
    "start": "1712345",
    "end": "1718460"
  },
  {
    "text": "Or, or we could build more\nagents to solve the problem.",
    "start": "1718580",
    "end": "1724010"
  },
  {
    "text": "Not, you know, I, I get your point. We should go governance and I, and I,\nand I, I believe that's a serious thing.",
    "start": "1724070",
    "end": "1729440"
  },
  {
    "text": "And we should build walls and put\neverything behind walls and then nobody can access in anything.",
    "start": "1729440",
    "end": "1733550"
  },
  {
    "text": "Or, or we could go, Hmm,\nlet's build more agents. And then the, the good agents\ncan fight the bad agents.",
    "start": "1734625",
    "end": "1743304"
  },
  {
    "text": "Yeah. And then we're gonna be fine because\nwe're gonna have a little good agent versus bad agent more so I\nthink any problem that is super hard",
    "start": "1743305",
    "end": "1750145"
  },
  {
    "text": "today, we don't need to solve that with things like governance,\nwe can solve that with more AI. That is, that is my solution to this.",
    "start": "1750145",
    "end": "1756955"
  },
  {
    "text": "So Cisco, we recently had the big\nsecurity conference this week. Cisco released a foundation\nmodel for security.",
    "start": "1756961",
    "end": "1763115"
  },
  {
    "text": "IBM has done a lot in this space\naround security related models, right? So if you're looking at cybersecurity\nrisks, you're looking at",
    "start": "1763725",
    "end": "1769310"
  },
  {
    "text": "hallucinations, things of that nature. So I think there'll be enough AI\nimprovements that we are doing. You need ai, good AI to fight bad AI\na hundred percent with you on that.",
    "start": "1769310",
    "end": "1777320"
  },
  {
    "text": "Um, we do need to talk about the\ndiscipline that enterprises need to have. To ensure that those good AI agents are\ndeployed as default baked and security",
    "start": "1777800",
    "end": "1786975"
  },
  {
    "text": "by design, not as an afterthought bolted on. Right? That's the point that I think\nJ.P. Morgan Chase is arguing",
    "start": "1786975",
    "end": "1792075"
  },
  {
    "text": "that get excited about this. Huge, huge benefit to us, but you\nhave to make sure that there's a secure by design for the very big.",
    "start": "1792405",
    "end": "1798885"
  },
  {
    "text": "But you can't cripple\ninnovation at the same time. No, I get it. Right. There's certain areas\nwhere you have to say.",
    "start": "1798945",
    "end": "1804644"
  },
  {
    "text": "You know what, um, I, this is\na very serious thing and I need it to not hallucinate, blah,\nblah, blah, blah, blah, blah.",
    "start": "1804825",
    "end": "1810495"
  },
  {
    "text": "But then at the same time, you\nneed to make breakthroughs and you need to discover new things. And we have a hype cycle\nto maintain, right?",
    "start": "1810795",
    "end": "1817695"
  },
  {
    "text": "So at the same time, we can't\nkind of hold back on that. So I'm, I, I get it. And I think for certain regulated\nindustries, I understand that",
    "start": "1817695",
    "end": "1825735"
  },
  {
    "text": "and that makes sense, but. Um, but at the same time, sometimes\nhallucinations are a good thing, right?",
    "start": "1825735",
    "end": "1832550"
  },
  {
    "text": "Because it gives you a bit of creativity. So I'm, you know, we just, we\njust need to, we just need to be appropriate for the right scenario.",
    "start": "1832550",
    "end": "1838789"
  },
  {
    "text": "Okay. Chris' point is actually a good one. Um, so, uh, when you have a mix of, uh,\nsome like, uh, things that are controlling",
    "start": "1838850",
    "end": "1847340"
  },
  {
    "text": "others, it doesn't always have to be just\nin a closed sort of system, like with a single governor, um, sort of thing, right?",
    "start": "1847340",
    "end": "1854180"
  },
  {
    "text": "I mean. Our immune system, like it\ncontrols diseases and stuff, right? I mean, there's bad things happening,\nthere's good guys fighting against it.",
    "start": "1854225",
    "end": "1861610"
  },
  {
    "text": "Um, it happens in nature all the\ntime in different ecosystems. So, um, if you take the, the big\nsystem level view of things, uh,",
    "start": "1861669",
    "end": "1868899"
  },
  {
    "text": "control is not always just like\none little knob and, and and stuff. So I think it's actually\na, a mix of things and, um.",
    "start": "1868930",
    "end": "1876610"
  },
  {
    "text": "Yeah, I just wanted to end with a shout\nout to the robust intelligence folks. So that's the, the team that put\ntogether the, the Cisco model",
    "start": "1877050",
    "end": "1883259"
  },
  {
    "text": "that, uh, that Shobhit mentioned. So, uh, really good, really\ngood work for, from, from them. Great. Well, that's resolved.",
    "start": "1883260",
    "end": "1888809"
  },
  {
    "text": "The, resolved, the Shobhit,\nChris, uh, debate conclusively. I thought my, I thought my\ncousin would be on my side.",
    "start": "1888810",
    "end": "1895290"
  },
  {
    "text": "I'm on both sides. You're on both sides. More security,  the better. Yeah, exactly.",
    "start": "1897510",
    "end": "1902260"
  },
  {
    "text": "Chris likes both of you equally. It's fine.",
    "start": "1902590",
    "end": "1904439"
  },
  {
    "text": "So I think to close our episode,\nas I mentioned at the top of the show, we're this is the first\nanniversary episode of MoE.",
    "start": "1910870",
    "end": "1917980"
  },
  {
    "text": "Very fast year. Uh, we were able to bring together\nthe original cast from episode one.",
    "start": "1918010",
    "end": "1923419"
  },
  {
    "text": "And so a little bit like the kind of\nkickoff question we did, I thought it'd be fun to end with just like a\nfinal segment just talking about like,",
    "start": "1923750",
    "end": "1930260"
  },
  {
    "text": "what we did on that first episode. 'cause it's very fun to take a look\nback and be like, oh yeah, like, what, whatever happened to that?",
    "start": "1930260",
    "end": "1935750"
  },
  {
    "text": "Or like, oh, that turned out\nto be a really big thing. So it's kind of just like a fun exercise. Um, producer Hans here\nwill be playing some clips.",
    "start": "1935750",
    "end": "1942409"
  },
  {
    "text": "You'll actually be able to hear\nyourself from a year ago, which may either be fun or cringeworthy. We're about to find out.",
    "start": "1942410",
    "end": "1947900"
  },
  {
    "text": "Um, but I think the first topic\nthat we covered on episode one was the Rabbit R1  device. Yeah. Which, if you recall, was a small, cute\nlittle hardware device with AI embedded,",
    "start": "1948400",
    "end": "1957580"
  },
  {
    "text": "and it was a conversation about AI\nhardware and where it was gonna go. Hans, do you wanna roll that tape\nso we can have the respective",
    "start": "1957580",
    "end": "1963250"
  },
  {
    "text": "takes of everybody on the show\nabout what they said about that? But it, it's like trying to\nsell a pager to somebody today.",
    "start": "1963250",
    "end": "1969090"
  },
  {
    "text": "It's like, here's this thing\nthat's got the things you need. You can get messages and, you know,\nbut nobody has a pager, right?",
    "start": "1969150",
    "end": "1975990"
  },
  {
    "text": "Because it was replaced by the phone. And, and so I do think there will\nbe AI on the hardware devices.",
    "start": "1975990",
    "end": "1981990"
  },
  {
    "text": "I, I just don't get that one. Just being an optimistic\nof where the tech is going. I'm more on the wash of, uh, I\nsee the promise of what this.",
    "start": "1982230",
    "end": "1990150"
  },
  {
    "text": "And Apple takes a while to\ncome into this industry, right? Same thing goes with the\nVision Pro glasses, right?",
    "start": "1995185",
    "end": "2001425"
  },
  {
    "text": "I, again, I was a big fan of them\nwhen I bought them early on and three days in I did return there.",
    "start": "2001665",
    "end": "2008115"
  },
  {
    "text": "To me, what is this is leading to is\nactually like a fourth paradigm of how we interact with computing, right?",
    "start": "2008115",
    "end": "2013965"
  },
  {
    "text": "I mean, there was punch cards, there was\ncommand line, then there was GUIs, and this is now, I mean like we're in this\nfourth sort of era, the language, natural",
    "start": "2013965",
    "end": "2022845"
  },
  {
    "text": "language interactions and so forth. I think, I mean, yeah, I mean maybe\nthere's no killer app yet, but the",
    "start": "2022845",
    "end": "2029745"
  },
  {
    "text": "killer app maybe is the fact that we\nhave this new way of interacting and that's what these devices are gonna,\nuh, start us, uh, on the road down.",
    "start": "2029745",
    "end": "2037605"
  },
  {
    "text": "Nice. Uh, that's awesome. Well show, but I'll start with you\n'cause I think you actually bought a Rabbit R1,  um, where is it?",
    "start": "2037784",
    "end": "2043695"
  },
  {
    "text": "Where is it now? It's in the garage. In a\nbox. Okay. I gone and sell it on eBay, man.",
    "start": "2043700",
    "end": "2049190"
  },
  {
    "text": "Oh, really? Can't even, there's no\nsecondary market for the  R1. Oh man. I'm hoping this will be, uh,\none of those things that goes",
    "start": "2049850",
    "end": "2055970"
  },
  {
    "text": "for a million bucks later. But yes, it's, uh, it's,\nit's in a garage in a box.",
    "start": "2055970",
    "end": "2061480"
  },
  {
    "text": "I, I couldn't even find it for,\nto bring this, for this episode. But, uh, I think overall, I\nstill stand by what I said.",
    "start": "2061485",
    "end": "2067450"
  },
  {
    "text": "I think the, the market needs to\nevolve and we are not there yet. We've not seen a single device\nthat is beyond, like even Ray-Bans.",
    "start": "2067480",
    "end": "2074020"
  },
  {
    "text": "I obviously have the Ray-Ban glasses\nas well, but it's, it's okay, but not at the point where you can\nreally use it as a, as real device.",
    "start": "2074020",
    "end": "2081099"
  },
  {
    "text": "I think the last time we saw an. Accessory that could augment, uh, your,\nuh, your iPhones and stuff was the watch.",
    "start": "2081340",
    "end": "2089065"
  },
  {
    "text": "Right? Watches. They looked at a niche, they\nwent off of that and they're augmented extending your phone.",
    "start": "2089365",
    "end": "2095695"
  },
  {
    "text": "They don't work without the phone. Right. It just works really, really\nwell as a, as a partner. So I think we'll get to that\npoint with, with devices, but.",
    "start": "2095935",
    "end": "2101935"
  },
  {
    "text": "I've not seen another thing to throw my money at yet. All right. Real quick, Chris, do you wanna\ntake a victory lap on this one?",
    "start": "2102615",
    "end": "2108015"
  },
  {
    "text": "Because I think you won this point. Yeah, no, and I'm, I'm\nfeeling good about that one.",
    "start": "2108015",
    "end": "2113145"
  },
  {
    "text": "That, that, that thing is a pager. I said it at the time and I'll\nsay it again, so I'm feeling good.",
    "start": "2113145",
    "end": "2117165"
  },
  {
    "text": "All right. Sounds good. Second thing, uh, that we covered on\nepisode one was the rise of a mysterious,",
    "start": "2118190",
    "end": "2124310"
  },
  {
    "text": "uh, chatbot on Chatbot Arena called GPT-2\nChatbot, which if you recall, there's",
    "start": "2124430",
    "end": "2129890"
  },
  {
    "text": "wild speculation about what it was, and. Um, I guess Hans, do you wanna\nplay the clip about like your, your, your all's take at the time?",
    "start": "2130040",
    "end": "2136385"
  },
  {
    "text": "Is it GPT-5? I don't know. I think they've hyped  GPT-5\nso much that if that is",
    "start": "2136445",
    "end": "2142025"
  },
  {
    "text": "at this point, it has to be  AGI or\nit's like not even gonna impress us. Exactly. So maybe it's GPT-4.5  but I, I don't\nthink that I, I, I read a theory online.",
    "start": "2142260",
    "end": "2151055"
  },
  {
    "text": "I can't say who's said it,\nbut I actually like it. I, somebody said that, uh, take the GPT\nto, uh, LLM, which they've open source.",
    "start": "2151055",
    "end": "2159695"
  },
  {
    "text": "You can download that in Hugging Face. And they reckon that they may have\ntrained GPT two on the, uh, latest,",
    "start": "2159695",
    "end": "2166840"
  },
  {
    "text": "uh, data that trains the GPT-4. And I think that's an\ninteresting theory, right? You know, GPT-2   with GPT-4 data.",
    "start": "2167200",
    "end": "2173380"
  },
  {
    "text": "So maybe it's something like that. Um, I don't know. Um, but I don't think it's  GPT-5. It, it probably is GPT-4.5,  and as\nyou say, you've, you've gotta put",
    "start": "2173680",
    "end": "2182050"
  },
  {
    "text": "it in some sort of arena to, to see\nhow well it's actually performing. Chris, that was a pretty good guess.",
    "start": "2182050",
    "end": "2187180"
  },
  {
    "text": "I mean, 'cause we're now living\nin a GPT-4.5   World, right? Yeah. I think, I think I got, I can't\neven remember what that model was.",
    "start": "2187180",
    "end": "2193830"
  },
  {
    "text": "Was that like the when, when was this? Was that the 4.o, or\nwas it slightly after? Yeah, so that was the next model that  GPT released.",
    "start": "2193830",
    "end": "2199838"
  },
  {
    "text": "And I think one of the, somebody had\nspilled the beans saying that, Hey, yes, that was, that we, it scored really\nhigh during the  GPT-4o   released.",
    "start": "2199859",
    "end": "2207089"
  },
  {
    "text": "So our guess is that that was, uh, the\ntesting they were doing on LLM arena. Yeah.\nI can't even remember.",
    "start": "2207315",
    "end": "2213375"
  },
  {
    "text": "That's how far back it was, but I think,\nI think my guess was pretty good, right? It wasn't quite four or five, but it was\nbasically the next version of the model.",
    "start": "2213375",
    "end": "2219345"
  },
  {
    "text": "Yeah, I feel good. Yeah, I still think the GPT-2 theory was\na great one though, so, you know, so,",
    "start": "2219435",
    "end": "2224805"
  },
  {
    "text": "so somebody's gotta do that actually. That's a good idea. All right. And so for the final one that I\nwant to play, we, we talked about",
    "start": "2224805",
    "end": "2232335"
  },
  {
    "text": "agents, which has since become\nbasically like an ongoing MoE in joke, I suppose.",
    "start": "2232395",
    "end": "2238000"
  },
  {
    "text": "Um, and, uh, I think with Shobhit\nand Chris, on the show, both of you are probably our most\nprolific users of the word agents.",
    "start": "2238900",
    "end": "2245890"
  },
  {
    "text": "I feel it. It, uh, if we just did a word count\nof all the things you've said on MoE, probably you two would be\nat the top of that leaderboard.",
    "start": "2245920",
    "end": "2252370"
  },
  {
    "text": "So Kush, I'm gonna ask you to\nmaybe make a guess, which is, which one of these guys used",
    "start": "2252700",
    "end": "2257650"
  },
  {
    "text": "agent first on MoE, um, like who is number\none on, on breaking that seal, I guess.",
    "start": "2258180",
    "end": "2265200"
  },
  {
    "text": "Yeah, this, this time I'll\ngo with the family member. Woo. The was plan.",
    "start": "2265200",
    "end": "2269720"
  },
  {
    "text": "All right, well roll the tape, Hans. The talk by Andrew on,\nuh, how agentic  flows",
    "start": "2270689",
    "end": "2277020"
  },
  {
    "text": "are going to be the way we get to the AGI. Yes! Nailed it, congratulations. So show didn't blame for starting that",
    "start": "2277020",
    "end": "2282820"
  },
  {
    "text": "I heard  agentic. Yeah. I didn't the word,  I didn't\nhear the word agents at all. I, I call, uh, this is, uh, a fix.",
    "start": "2282820",
    "end": "2289694"
  },
  {
    "text": "Yeah, yeah. Disqualified. So we'll do some investigation\non who actually used the word agent first, but I guess Shobhit",
    "start": "2290205",
    "end": "2295634"
  },
  {
    "text": "you can, uh, be, uh, you can rest\neasy knowing that you were really a, a pathblazer there for us.",
    "start": "2295634",
    "end": "2301035"
  },
  {
    "text": "But I still, but you should take that a second to acknowledge how far\nwe have come in the last year.",
    "start": "2301065",
    "end": "2306045"
  },
  {
    "text": "At that point, uh, Andrew had just\nintroduced how a 3.5, uh, can, can",
    "start": "2306420",
    "end": "2312298"
  },
  {
    "text": "GPT-3.5    with tools can actually\noutcompete GPT-4  and stuff, right? So just imagine how far we have come\nin terms of the cost, the kind of",
    "start": "2312299",
    "end": "2319950"
  },
  {
    "text": "tools, the ecosystem around agents. I'm just very proud of where the community\nis today with the, with our, what's",
    "start": "2319950",
    "end": "2325859"
  },
  {
    "text": "happening in the multi-agent space. Yeah, for sure. And more to come soon. I mean, I think we're gonna have\nto do this next year as well where we look back on what we were\ntalking about for, uh, in 2025.",
    "start": "2325859",
    "end": "2333790"
  },
  {
    "text": "Ooh, we should have done, uh,\nwhat should be the next word? That'll catch it. That'll go viral, right?",
    "start": "2333850",
    "end": "2338049"
  },
  {
    "text": "You may have used it on this episode. Open letter. You know, Congratulations to the production\ncrew for the one year anniversary.",
    "start": "2339250",
    "end": "2346869"
  },
  {
    "text": "I wanna give a big shout out to the\nproducer Hans, Alex, Michael and Selma, you guys have poured your soul into this.",
    "start": "2346870",
    "end": "2353295"
  },
  {
    "text": "Thank you so much for bringing the\nMixture of Experts to our audiences. Thank you so much! Happy birthday.",
    "start": "2353295",
    "end": "2359015"
  },
  {
    "text": "Happy birthday. Well, that's all the time\nthat we have for today. Uh, Kush, Shobhit,  Chris,\nan amazing panel.",
    "start": "2359890",
    "end": "2366634"
  },
  {
    "text": "Glad to have you on again! Um, and thanks to joining us all you\nlisteners, if you enjoyed what you heard",
    "start": "2366634",
    "end": "2371825"
  },
  {
    "text": "you can get us on Apple Podcasts,\nSpotify, and podcast platforms everywhere, and we will see you all\nnext week on Mixture of Experts.",
    "start": "2372095",
    "end": "2378934"
  }
]
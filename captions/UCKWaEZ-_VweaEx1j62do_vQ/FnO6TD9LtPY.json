[
  {
    "start": "0",
    "end": "68000"
  },
  {
    "text": "What comes next in open source? If you just combine this recipe and map it to other models, I'm expecting",
    "start": "520",
    "end": "7680"
  },
  {
    "text": "a lot of very powerful models. Because AI is prediction, it's",
    "start": "7680",
    "end": "13120"
  },
  {
    "text": "just pretty limited, right? Yes, I might take a bit of issue where AI is fundamentally about prediction.",
    "start": "13120",
    "end": "19480"
  },
  {
    "text": "Why exactly are people so excited about the use of AI in sustainable development? So you can see how People are, are trying",
    "start": "19480",
    "end": "26320"
  },
  {
    "text": "to wrangle, how do I balance the compute that's needed versus how do you, how",
    "start": "26320",
    "end": "31600"
  },
  {
    "text": "do you look at the energy consumption? All that and more on today's episode of Mixture of Experts.",
    "start": "31600",
    "end": "42800"
  },
  {
    "text": "I'm Tim Hwang and I'm exhausted. It's been another crazy week of news in artificial intelligence, but we are joined",
    "start": "42800",
    "end": "48280"
  },
  {
    "text": "today as we are every Friday by a world class panel of people to help us all sort it out.",
    "start": "48280",
    "end": "53440"
  },
  {
    "text": "Maryam Ashoori is Director of Product Management at Watson X AI. Shobit Varshney is Senior Partner Consulting",
    "start": "53440",
    "end": "59680"
  },
  {
    "text": "on AI for US, Canada, and Latin America. And Skyler Speakman is a senior research scientist.",
    "start": "59680",
    "end": "69720"
  },
  {
    "start": "68000",
    "end": "752000"
  },
  {
    "text": "So the way we're going to begin is, uh, what we've been doing for the last few episodes, I think it's just a fun way to get started, is to ask each of",
    "start": "69720",
    "end": "75320"
  },
  {
    "text": "you a simple round the horn question. For all the listeners, uh, the guests have not been prepped as to what",
    "start": "75320",
    "end": "81479"
  },
  {
    "text": "this question will be, so you'll be hearing their unvarnished, instinctual response to a really difficult question.",
    "start": "81480",
    "end": "87400"
  },
  {
    "text": "So here's the question. In 2025, a mere few months from now, will there be an open source model that is absolutely",
    "start": "87400",
    "end": "94680"
  },
  {
    "text": "better than any proprietary model on the market? Show a bit. Yes or no?",
    "start": "94680",
    "end": "100040"
  },
  {
    "text": "It'll get close. Okay. Skyler. I'm sorry. What?\nNo. Uh, yes, there will be.",
    "start": "100040",
    "end": "107440"
  },
  {
    "text": "Great.\nAnd Maryam, what do you think? A big yes. Okay.\nWhoa. All right. Nice. Very exciting.",
    "start": "107440",
    "end": "113080"
  },
  {
    "text": "Well, that's actually the lead in for our first segment today. One of the big announcements, of course, is the release of LLAMA 3.2.",
    "start": "113080",
    "end": "119840"
  },
  {
    "text": "Um, if you've been following the news or been living under a rock, LLAMA is the, uh, sort of best in class open source model,",
    "start": "120440",
    "end": "128280"
  },
  {
    "text": "uh, that Meta has been really helping to kind of, um, advance in the marketplace. Um, and their release, uh, just earlier",
    "start": "128280",
    "end": "135120"
  },
  {
    "text": "this week, Featured a large range of different models, small ones, big ones.",
    "start": "135120",
    "end": "140600"
  },
  {
    "text": "Um, and Maryam, I understand you were involved actually in the release. Um, do you want to tell us a little bit about kind of your experiences and how that was?",
    "start": "140600",
    "end": "147280"
  },
  {
    "text": "Yes, it's just so exciting to be part of that market moment. On the first day, when the models are released",
    "start": "147280",
    "end": "153640"
  },
  {
    "text": "to the market, it's available on the platform. Yeah, it's like a holiday.",
    "start": "153640",
    "end": "158742"
  },
  {
    "text": "The excitement is just amazing. Yeah. Yeah. I think from the outside, one thing I think would be helpful for our listeners to learn a little bit more",
    "start": "158742",
    "end": "164600"
  },
  {
    "text": "about is what's different with 3.2 release? Um, you know, is it just more open source?",
    "start": "164600",
    "end": "170280"
  },
  {
    "text": "Uh, what should we be paying attention to? Well, there are really three things that they released, uh, with 3.2.",
    "start": "170280",
    "end": "175760"
  },
  {
    "text": "The first one is lightweight, unlocking all the IoT and edge use cases with the release",
    "start": "175760",
    "end": "181959"
  },
  {
    "text": "of LLAMA, um, 3 billion and 1 billion. The second thing was the",
    "start": "181960",
    "end": "187160"
  },
  {
    "text": "multi modal vision support. It's imaging, text out. You can think of, Unlocking use",
    "start": "187160",
    "end": "194160"
  },
  {
    "text": "cases like image captioning, chart interpretation, visual Q& A on the images.",
    "start": "194160",
    "end": "201040"
  },
  {
    "text": "And the beauty of that is the way that they did it was they separated the image",
    "start": "201040",
    "end": "206280"
  },
  {
    "text": "encoder from the large language encoder and trained the adopter in a way that now the",
    "start": "206280",
    "end": "211760"
  },
  {
    "text": "model is not changed comparing to the 3.1. So it can be used as a drop",
    "start": "211760",
    "end": "218040"
  },
  {
    "text": "in replacement for the 3.1 LlamaÂ \n11 billion and, uh, the, um, 70",
    "start": "218040",
    "end": "224799"
  },
  {
    "text": "billion variants, but the image encoder that is added to that now is going to enable the",
    "start": "224800",
    "end": "231680"
  },
  {
    "text": "model to process image in and input out. So that's the second thing. And the third thing that released, they",
    "start": "231680",
    "end": "237880"
  },
  {
    "text": "released on the model side is the Llama guard for the vision, like the safety of these multimodal models matters.",
    "start": "237880",
    "end": "245200"
  },
  {
    "text": "And they released the Llama Guard that is also available in our platform for the customers. Yeah, that's awesome.",
    "start": "245200",
    "end": "250680"
  },
  {
    "text": "So there's a lot to go through here. Um, I think maybe to pick up on that first three theme, uh, Shobit, I know, you know,",
    "start": "250680",
    "end": "257359"
  },
  {
    "text": "the, the drum you always beat when you come on Mixture of Experts is the models are going to get smaller and it's a good thing.",
    "start": "257360",
    "end": "263280"
  },
  {
    "text": "Um, do you want to talk a little bit about how this matters for people who are implementing this kind of stuff in the enterprise?",
    "start": "263280",
    "end": "268440"
  },
  {
    "text": "Yes.\nSo a lot of my clients, we are deploying, uh, these small language models on device,",
    "start": "268440",
    "end": "273640"
  },
  {
    "text": "um, Quite a few times, it's just because they don't have good internet access in the factory floor or people who are running around",
    "start": "273640",
    "end": "279120"
  },
  {
    "text": "in the field, things of that nature, right? So we have to do a lot of that computation on device, especially if you're looking at our federal clients or manufacturing",
    "start": "279120",
    "end": "286280"
  },
  {
    "text": "and so on and so forth, right? In those cases, for the last few months, I've been super impressed by the",
    "start": "286280",
    "end": "291319"
  },
  {
    "text": "momentum we have had in this AI space. going towards much smaller, more efficient models.",
    "start": "291320",
    "end": "296919"
  },
  {
    "text": "So in the one billion to two and a half, three billion parameter space, we've seen a influx of a lot of models.",
    "start": "296920",
    "end": "303360"
  },
  {
    "text": "So I have been running, uh, Google's Gemma, Apple's open ELM. We've had Microsoft's five, 3.5.",
    "start": "303360",
    "end": "310520"
  },
  {
    "text": "They've been some amazing models have delivered quite a bit of value. Uh, we have from, uh, from Meta now,",
    "start": "310520",
    "end": "316560"
  },
  {
    "text": "the one billion parameter model. I was able to download that just before I took a flight.",
    "start": "316560",
    "end": "322000"
  },
  {
    "text": "So I was able to experiment for the next three hours with these small models. And by the way, I was looking at the MetaConnect using the Oculus glasses.",
    "start": "322000",
    "end": "329080"
  },
  {
    "text": "It was a completely different experience being there live. So I got, I got a chance to go",
    "start": "329080",
    "end": "334440"
  },
  {
    "text": "experiment with these models. There are certain things that we do for our clients where we add another layer",
    "start": "334440",
    "end": "339520"
  },
  {
    "text": "of some fine tuning to these models. And the fact that they are small. And I can fine tune them because they're open.",
    "start": "339520",
    "end": "345880"
  },
  {
    "text": "I'm able to deliver much higher accuracy, much, with a much, much smaller footprint. I think that's where you get gold.",
    "start": "345880",
    "end": "352280"
  },
  {
    "text": "The return on investment you get from these small models that you can then fine tune and then run on device, that opens up a",
    "start": "352280",
    "end": "358000"
  },
  {
    "text": "whole lot of use cases for our clients that we've not been able to do if you're going and calling an API call back and forth.",
    "start": "358000",
    "end": "364759"
  },
  {
    "text": "Yeah, definitely. And Skyler, I guess this kind of response puts maybe your response to the round the horn question into context.",
    "start": "364760",
    "end": "370360"
  },
  {
    "text": "You know, I think I was like, are you going to have an open source model that's better than the best model in the world?",
    "start": "370360",
    "end": "376080"
  },
  {
    "text": "I guess kind of, that's not what you think is exciting about this release, right? I feel like you're, you're like chomping at the bit to talk about how great these models are.",
    "start": "376080",
    "end": "382560"
  },
  {
    "text": "If they had come out with a 500 billion parameter model, that would have been, yeah, for me.",
    "start": "382560",
    "end": "388080"
  },
  {
    "text": "But if they're emphasizing the 3 billion and 1 billion parameter space, that gets me.",
    "start": "388080",
    "end": "393120"
  },
  {
    "text": "So excited because it's away from the bigger is better idea and that bigger is better idea has",
    "start": "393120",
    "end": "399840"
  },
  {
    "text": "crowded out Other really cool research problems that probably should have been looked worked on while people were scaling larger and larger",
    "start": "399840",
    "end": "406240"
  },
  {
    "text": "and larger So to see a major player like meta come out and make some noise about a 3 billion",
    "start": "406240",
    "end": "411440"
  },
  {
    "text": "1 million parameter model I think that's just some really outstanding work and In the larger",
    "start": "411440",
    "end": "417720"
  },
  {
    "text": "context, it also really shifts decision makers to not be gated behind the ones that have",
    "start": "417720",
    "end": "423720"
  },
  {
    "text": "access to running a 400 billion parameter model. So I, I think that type of, that kind",
    "start": "423720",
    "end": "429400"
  },
  {
    "text": "of power dynamic, if, if open source is continually getting these smaller scales, I think that's just a really good direction.",
    "start": "429400",
    "end": "435919"
  },
  {
    "text": "So, uh, yeah, kudos to that about LLAMA coming out and saying 1 billion in free parameter space.",
    "start": "435920",
    "end": "441720"
  },
  {
    "text": "Has is showing uh skills and and again being able to download right",
    "start": "441720",
    "end": "447000"
  },
  {
    "text": "before you said you hopped on a plane. I mean that type of thing Um, that's a really great direction to see these",
    "start": "447000",
    "end": "452800"
  },
  {
    "text": "types of foundation models going So there are a couple other things in this in the space as well the 128k window The context window.",
    "start": "452800",
    "end": "460040"
  },
  {
    "text": "That is pretty surprising to me for such a small size model. Why is it surprising? Yeah, I think some folks might not",
    "start": "460040",
    "end": "465520"
  },
  {
    "text": "actually have a familiarity there. It's worth, I think, for them to hear that subtlety, yeah. Yeah, so the fact is you can put more context",
    "start": "465520",
    "end": "471760"
  },
  {
    "text": "into that, into that prompt that you're asking. It's 128,000 tokens I can pass in as context.",
    "start": "471760",
    "end": "478240"
  },
  {
    "text": "So if I'm looking at a whole email thread chain, on device, I can pass that in. So that kind of a response or, or eventually",
    "start": "478240",
    "end": "486120"
  },
  {
    "text": "we'll start to see more models that can handle images and stuff too, that are this small size. Currently, uh, the PICS trial model, 12",
    "start": "486120",
    "end": "492879"
  },
  {
    "text": "billion parameters or Meta's 11 billion. Those are the ones that are doing images, but I'm very hopeful that soon we'll see",
    "start": "492880",
    "end": "498800"
  },
  {
    "text": "more image capabilities come down to this two or three billion parameter models as well. So doing that on device, when you're",
    "start": "498800",
    "end": "504200"
  },
  {
    "text": "walking around taking a picture of equipment and saying, what's wrong with this? What's the meter reading? Things of that nature.",
    "start": "504200",
    "end": "510560"
  },
  {
    "text": "I'm super excited as the capabilities increase. There are a few things that I lack that I would like to see come out in the future.",
    "start": "510560",
    "end": "517479"
  },
  {
    "text": "Things like function calling, being able to do, like, being able to create a plan and have",
    "start": "517480",
    "end": "523319"
  },
  {
    "text": "more agentic flows between these model models. I'm very excited about the future iterations of these models as well.",
    "start": "523320",
    "end": "528759"
  },
  {
    "text": "Maryam, when you compare, we've been working on Granite models for a while and we've always been focused on small models.",
    "start": "528760",
    "end": "535440"
  },
  {
    "text": "Can you give your perspective on the small model size? What are you seeing as the good size, like 7 billion to 2 billion?",
    "start": "535440",
    "end": "542680"
  },
  {
    "text": "Where do you see the right threshold of performance and size? Well, it depends on the use case, right? If you have an IoT or edge use",
    "start": "542680",
    "end": "549040"
  },
  {
    "text": "case, the smaller the better. But also, the smaller the better in the case that, like, it has impact on the latency.",
    "start": "549040",
    "end": "556399"
  },
  {
    "text": "It's faster, it has impact on the energy consumption and carbon footprint generation, and it has impact on cost.",
    "start": "556400",
    "end": "563920"
  },
  {
    "text": "So if we can get the performance that we need for, from a smaller model, that's,",
    "start": "563920",
    "end": "569480"
  },
  {
    "text": "that's well suited for that use case. But, but the, Skyler, to your point, what excites me about this release",
    "start": "569480",
    "end": "575839"
  },
  {
    "text": "and the lightweight is the way that they achieve that lightweight models. Like if you look into the paper of how",
    "start": "575840",
    "end": "581800"
  },
  {
    "text": "they did that, they grabbed the Lama 8B and they structurally pruned it.",
    "start": "581800",
    "end": "588600"
  },
  {
    "text": "So it's like cutting, cutting the network, making it smaller, but then they use the very large general purpose models, the",
    "start": "588600",
    "end": "595560"
  },
  {
    "text": "405B that they had as a teacher model for distillation to, to bridge that gap.",
    "start": "595560",
    "end": "602200"
  },
  {
    "text": "If you just combine this recipe and map it to other models, I'm expecting",
    "start": "602200",
    "end": "609760"
  },
  {
    "text": "a lot of very Powerful models coming to the market moving forward just with a",
    "start": "609760",
    "end": "616520"
  },
  {
    "text": "combination of distillation and pruning. Yeah, for sure. And I think one of the most interesting things is as it gets sort of cheaper and",
    "start": "616520",
    "end": "622200"
  },
  {
    "text": "cheaper and more available, I think we'll also see like lots of use cases, right? Like so far, we've been gated by how much",
    "start": "622200",
    "end": "627920"
  },
  {
    "text": "investment you need to put into these models and how expensive they are to run. But I think it's almost like as it becomes",
    "start": "627920",
    "end": "633040"
  },
  {
    "text": "more accessible, we'll also just see like, well, why not just plug a model in, right? Like it'll end up being something that you can apply for all sorts of different",
    "start": "633040",
    "end": "638480"
  },
  {
    "text": "applications that You know, we would have thought have been like ridiculous to do a few years ago because it would have been too expensive to even think of doing",
    "start": "638480",
    "end": "644520"
  },
  {
    "text": "it.\nMaryam, just on the latency part. I was stunned. I'm in the flight. I have a one parameter model running.",
    "start": "644520",
    "end": "651839"
  },
  {
    "text": "It's giving me 2000 tokens a second response. That's like 1500 words is generating per second.",
    "start": "651840",
    "end": "658760"
  },
  {
    "text": "That's the experience I want when I'm looking at a model on my phone responding. I just. I became a believer when I saw that",
    "start": "658760",
    "end": "664720"
  },
  {
    "text": "speed of response, the latency. Yeah, the vision of you like on the plane with the goggles using a model, this is like",
    "start": "664720",
    "end": "670360"
  },
  {
    "text": "your seat neighbor being like, who's this guy? Easy playing with LLM.",
    "start": "670360",
    "end": "674399"
  },
  {
    "text": "I'm waiting for the new airline documentation that come out that says, please do not run LLMs on devices while the plane is in flight.",
    "start": "675520",
    "end": "682240"
  },
  {
    "text": "So Maryam, I guess before we move on to our next topic, what What comes next, do you think? Like, are we going to see more releases of this kind?",
    "start": "685040",
    "end": "691800"
  },
  {
    "text": "Um, is this going to be the big release for a while? Like, what should we expect? I'm expecting to see a lot of movement",
    "start": "691800",
    "end": "697680"
  },
  {
    "text": "in open source and open community. Listen, the future of AI is open. It gives, really this openness drives",
    "start": "697680",
    "end": "705160"
  },
  {
    "text": "innovation and it gives you three things. One, making the technology accessible to a wider audience.",
    "start": "705160",
    "end": "710860"
  },
  {
    "text": "audience. And when you open it up to a wider audience, it gives you a chance to",
    "start": "710860",
    "end": "715920"
  },
  {
    "text": "stress test your technology, right? So we can advance safety of these models",
    "start": "715920",
    "end": "721240"
  },
  {
    "text": "together with the power of community. It gives you an acceleration on innovation and contribution back to Building",
    "start": "721240",
    "end": "728720"
  },
  {
    "text": "better models for different use cases. So, a combination of accessibility, safety,",
    "start": "728720",
    "end": "734200"
  },
  {
    "text": "enhancement, and acceleration innovation is what I'm expecting to see in the open community.",
    "start": "734200",
    "end": "740680"
  },
  {
    "text": "And because of that, we are going to see a lot more powerful, smaller models.",
    "start": "740680",
    "end": "746400"
  },
  {
    "text": "Emerging in the next six months,",
    "start": "746400",
    "end": "749160"
  },
  {
    "start": "752000",
    "end": "1374000"
  },
  {
    "text": "two researchers, uh, Arvin Narayan and his collaborator Koor, came out with a",
    "start": "753400",
    "end": "758480"
  },
  {
    "text": "book, uh, which was called AI Snake Oil. Um, and it's basically the book adaptation",
    "start": "758480",
    "end": "764080"
  },
  {
    "text": "of sort of a wildly successful substack they've been running for a while, uh, where they essentially kind of point out all the places where AI is.",
    "start": "764080",
    "end": "771120"
  },
  {
    "text": "being oversold, overhyped, or being deployed in ways that are, um, you know, not necessarily",
    "start": "771120",
    "end": "776920"
  },
  {
    "text": "like the best use of the technology. Um, and what's so fun is Arvind, you know, took to the internet to basically",
    "start": "776920",
    "end": "782680"
  },
  {
    "text": "say, we're so confident of our arguments here that we want to put a bounty out. If you think we're wrong on anything",
    "start": "782680",
    "end": "788160"
  },
  {
    "text": "that we're arguing in this book, um, tell us, right, and we can, we can put a bet on it, right, in two to five years.",
    "start": "788160",
    "end": "794400"
  },
  {
    "text": "And their sort of argument is that like the kinds of critiques that they're pointing out about AI systems are things that",
    "start": "794400",
    "end": "799920"
  },
  {
    "text": "don't have to do with like technological capabilities and have to do more with like, what can we actually predict in the world?",
    "start": "799920",
    "end": "807320"
  },
  {
    "text": "So one of the things they say is, you know, AI really can't predict individual life outcomes, or, you know, the success",
    "start": "807320",
    "end": "813360"
  },
  {
    "text": "of cultural products like books and movies, or things like pandemics, right? They're kind of arguing that like",
    "start": "813360",
    "end": "818880"
  },
  {
    "text": "prediction can only do so, go so far. And AI is ultimately a prediction machine. And so there's actually like kind of",
    "start": "818880",
    "end": "825800"
  },
  {
    "text": "just so far this technology can go. I think I just wanted to kind of first start there is like, I'm curious if",
    "start": "825800",
    "end": "830880"
  },
  {
    "text": "that group sort of buys that argument. Like, you know, do we think that this prediction thing, It's just limited in a",
    "start": "830880",
    "end": "836360"
  },
  {
    "text": "certain way, and that actually caps kind of what AI can be used for, or should be used for. Um, I guess, Skyler, maybe I'll throw it",
    "start": "836360",
    "end": "842360"
  },
  {
    "text": "to you if you've got any responses there. I guess I might take a bit of issue where AI is fundamentally about prediction.",
    "start": "842360",
    "end": "850320"
  },
  {
    "text": "I think the gains that we have seen recently on this idea of the transformer Being used to",
    "start": "850320",
    "end": "855920"
  },
  {
    "text": "do the next token prediction in that sense. Yes,",
    "start": "855920",
    "end": "860560"
  },
  {
    "text": "because it's able to that next token prediction, there are so many other use cases that are not prediction focused.",
    "start": "861840",
    "end": "868280"
  },
  {
    "text": "So it is. It's this idea about yes, we have to understand what this length of what this",
    "start": "868280",
    "end": "873800"
  },
  {
    "text": "context of data is and underlying it. That transformer model does rely on that prediction, but It is so much bigger than just",
    "start": "873800",
    "end": "882640"
  },
  {
    "text": "prediction, so I would really probably take that issue that, um, prediction is very difficult,",
    "start": "882640",
    "end": "888040"
  },
  {
    "text": "um, but the other downstream tasks that you can do after that prediction task is, is really",
    "start": "888040",
    "end": "895880"
  },
  {
    "text": "what has probably moved the space forward. So don't get too hung up on the",
    "start": "895880",
    "end": "902519"
  },
  {
    "text": "prediction, uh, capabilities of a model. Yeah, I'm, I'm with Skyler on that. Uh, if you look into traditional",
    "start": "902520",
    "end": "908680"
  },
  {
    "text": "ML, prediction was key. And all the use cases, the majority of the use cases, the enterprise use cases ML",
    "start": "908680",
    "end": "916900"
  },
  {
    "text": "for was a reflection of really prediction. But then, when it comes to generative AI,",
    "start": "916900",
    "end": "922240"
  },
  {
    "text": "the The prominent use cases for the Activity Unlocks that it does, which is a function of",
    "start": "922240",
    "end": "928960"
  },
  {
    "text": "content generation, code generation, it can be prediction in the sense that Skyler said, like",
    "start": "928960",
    "end": "934240"
  },
  {
    "text": "the next token, but that's, I don't think that's the prediction in the use case as a use case. So for that reason, I, I don't hundred percent",
    "start": "934240",
    "end": "942839"
  },
  {
    "text": "agree that a prediction use case is the primary use case that AI is designed to deliver.",
    "start": "942840",
    "end": "948600"
  },
  {
    "text": "Yeah, that's actually very interesting. I hadn't really thought about it like that. Um, this has come up in some of the episodes we've done before, but you know, this is one",
    "start": "948600",
    "end": "955280"
  },
  {
    "text": "of the debates I find most interesting is, oh, well, at some point, machine learning kind of diverged from computer science",
    "start": "955280",
    "end": "961200"
  },
  {
    "text": "because the way you program a computer is quite different from the way that you. you know, test, evaluate, and fine tune a model,",
    "start": "961200",
    "end": "966440"
  },
  {
    "text": "you're almost saying that actually, there's even another distinction could be made, which is basically this sort of like traditional",
    "start": "966440",
    "end": "971560"
  },
  {
    "text": "machine learning, if you will, right? We'll almost kind of diverge a little bit from like the kinds of concerns that we have",
    "start": "971560",
    "end": "976840"
  },
  {
    "text": "in generative AI or whatever you want to call it, but like this kind of current generation, you know, is almost so different in kind that",
    "start": "976840",
    "end": "982640"
  },
  {
    "text": "there's almost like a different set of problems. I don't know if that's kind of what you both are chasing after. I do think there, there is a divergence",
    "start": "982640",
    "end": "989800"
  },
  {
    "text": "away from classical machine learning, you know, take all of your decision trees, your regressions, all those spaces, and",
    "start": "989800",
    "end": "996600"
  },
  {
    "text": "then generative AI, those have diverged. And I'm trying to Trying to keep up with it, you know, that's my, my previous background was",
    "start": "996600",
    "end": "1003600"
  },
  {
    "text": "in the classical, uh, machine learning space. And then, man, we're, we're in for a wild ride on generative AI.",
    "start": "1003600",
    "end": "1009320"
  },
  {
    "text": "So, uh, Tim, being a podcast, let me just quickly recap, uh, the book.",
    "start": "1009320",
    "end": "1014440"
  },
  {
    "text": "I had, uh, I had the pleasure of listening to the audio book on the flight while I was hacking. Oh, you did? Okay.\nYeah, you did the homework.",
    "start": "1014440",
    "end": "1020440"
  },
  {
    "text": "Yeah, I was in a very meta phase because I'm trying to hack something while I'm listening to this book on AI.",
    "start": "1020440",
    "end": "1026959"
  },
  {
    "text": "The two authors are brilliant. They are two of the hundred top influential people in AI, Project Time magazine.",
    "start": "1027760",
    "end": "1034199"
  },
  {
    "text": "There are five points they make in the book. The first one is around making, they're saying that AI predicts but doesn't truly understand the context.",
    "start": "1034200",
    "end": "1041400"
  },
  {
    "text": "There's, the second point is around, they are, AI will reinforce our biases in areas",
    "start": "1041400",
    "end": "1046959"
  },
  {
    "text": "like Policy, hiring, things of that nature. Uh, third one is around, you have got to be",
    "start": "1046960",
    "end": "1052240"
  },
  {
    "text": "skeptical about anything that's black box AI solutions, the point that Maryam had just made about openness and that's the future direction.",
    "start": "1052240",
    "end": "1059080"
  },
  {
    "text": "Uh, then you had, there should be stricter regulations and accountability, especially when an AI is making an outcome that",
    "start": "1059080",
    "end": "1064520"
  },
  {
    "text": "could have an adverse impact elsewhere. And, uh, ethics and ethics and AI has to",
    "start": "1064520",
    "end": "1069800"
  },
  {
    "text": "be focused on beyond just the technical capabilities that we are making. Right. So none of these are groundbreaking statements",
    "start": "1069800",
    "end": "1075440"
  },
  {
    "text": "that, uh, that we have not heard before. But the very first one, I think that's where Skyler started was.",
    "start": "1075440",
    "end": "1080520"
  },
  {
    "text": "AI is making predictions, and in a lot of cases, we expect an intern or a junior person to make",
    "start": "1080520",
    "end": "1087799"
  },
  {
    "text": "a prediction, look at a pattern, and raise their hand when they see something that's not working. My wife is a physician.",
    "start": "1087800",
    "end": "1093760"
  },
  {
    "text": "She spent 14 years in medicine becoming a doctor, right? She does critical care, lungs, and sleep medicine.",
    "start": "1093760",
    "end": "1100480"
  },
  {
    "text": "She has a set of medical assistants, MAs or nurse practitioners who are helping patients as well.",
    "start": "1100480",
    "end": "1106840"
  },
  {
    "text": "She expects them to raise their hand when they see a pattern break. Here's the stats that they've",
    "start": "1106840",
    "end": "1113440"
  },
  {
    "text": "had from all their tests. A patient comes to them and say, hey, something looks different here. So all she's asking is recognize a",
    "start": "1113440",
    "end": "1119920"
  },
  {
    "text": "pattern and call me as an expert. I think that's where we should be with AI. AI is augmenting us.",
    "start": "1119920",
    "end": "1126799"
  },
  {
    "text": "We should be very precise in saying pattern recognition is a good thing. I want AI to do patterns, and I think",
    "start": "1126800",
    "end": "1133080"
  },
  {
    "text": "that's too much of a gap between pattern recognition and getting to the root cause analysis of being what caused this.",
    "start": "1133080",
    "end": "1139400"
  },
  {
    "text": "That causal modeling requires years of experience. And I think that's the relationship I would like to have with our AI.",
    "start": "1139400",
    "end": "1146039"
  },
  {
    "text": "Be able to find patterns and raise your hand, come to me for expert advice. So I think we're heading in a good direction.",
    "start": "1146040",
    "end": "1152040"
  },
  {
    "text": "The name of the book is very catchy, but I think the points that they're making are pretty grounded in what we see in reality today.",
    "start": "1152040",
    "end": "1158560"
  },
  {
    "text": "Yeah, for sure. And I think, I think to pick up on that point, I agree, Shobit. I mean, I think that's kind of a dream of how this technology should be deployed.",
    "start": "1158560",
    "end": "1165440"
  },
  {
    "text": "You know, I think part of their worry is that they feel like the market's not going to provide that, right? That there will be a tendency to be",
    "start": "1165440",
    "end": "1171480"
  },
  {
    "text": "like, yeah, let's just implement the AI and it will do everything for us. Um, and I guess maybe a question that I'd pose",
    "start": "1171480",
    "end": "1176840"
  },
  {
    "text": "back to the group is like, how do we do this? do a good job fighting that, right? Because I think, Shoba, I want to live in the world that you're describing, um, but I think",
    "start": "1176840",
    "end": "1183200"
  },
  {
    "text": "a lot of people who are particularly getting used to the technology or new to the technology almost have a tendency to kind of apply it",
    "start": "1183200",
    "end": "1188880"
  },
  {
    "text": "for that causal stuff, which is actually where we kind of want to preserve the human role. Um, and so I'm curious, like, in people's",
    "start": "1188880",
    "end": "1195240"
  },
  {
    "text": "conversations with, you know, friends and family and others, like, are there things that they've done to kind of, like, You know, help",
    "start": "1195240",
    "end": "1200919"
  },
  {
    "text": "to set level set with the technology properly. I think an example that has come up with this in our conversation recently, my parents were",
    "start": "1200920",
    "end": "1207480"
  },
  {
    "text": "both teachers, uh, public school teachers. And we were talking about whether AI is going to replace teaching.",
    "start": "1207480",
    "end": "1213280"
  },
  {
    "text": "And, uh, similar to the healthcare ideas, I would really like to see AI be very",
    "start": "1213280",
    "end": "1219440"
  },
  {
    "text": "measured in education because there's a, there's a, there's got to be a human connection there that comes through.",
    "start": "1219440",
    "end": "1225600"
  },
  {
    "text": "Um, and so to, to back off a little bit in, into that space, similar to Shobit's analogy",
    "start": "1225600",
    "end": "1230840"
  },
  {
    "text": "with the, uh, the medical situation about where we really see these specific roles.",
    "start": "1230840",
    "end": "1236040"
  },
  {
    "text": "And I, I think an AI instructor would actually It would be, it would be terrible. I don't want that.",
    "start": "1236040",
    "end": "1241440"
  },
  {
    "text": "I don't want that world. But having AI being able to assist students and assist that interaction between a",
    "start": "1241440",
    "end": "1247040"
  },
  {
    "text": "human teacher and the students, I think that would be a really cool example of this where we'd want to pull back a little",
    "start": "1247040",
    "end": "1253399"
  },
  {
    "text": "bit and not go full automation, uh, in, in education, probably in healthcare as well.",
    "start": "1253400",
    "end": "1259360"
  },
  {
    "text": "Skyler, on the whole education piece. I think if you follow Salman Khan doing. Khan Academy, Khan Migo.",
    "start": "1260240",
    "end": "1267120"
  },
  {
    "text": "I think the impact he's having surgically with AI, he's figured out a good blend between teachers, students, and where",
    "start": "1267120",
    "end": "1273760"
  },
  {
    "text": "AI becomes a copilot for them, right? So I think to your point of creating the human connection, 100%.",
    "start": "1273760",
    "end": "1279360"
  },
  {
    "text": "My mom was a teacher as well growing up. Unfortunately, she was also the principal of",
    "start": "1279360",
    "end": "1284520"
  },
  {
    "text": "my school, so that did not go well with me. Wait, while you were at the school? Yeah, when I was at the school, too.",
    "start": "1284520",
    "end": "1290200"
  },
  {
    "text": "But the fact that you can understand the nuances today, a teacher is addressing 60 kids in a row, and she has to go talk",
    "start": "1292840",
    "end": "1300600"
  },
  {
    "text": "at the same level for each one of them. So you can't adapt the training to people who have different, come from different",
    "start": "1300600",
    "end": "1306880"
  },
  {
    "text": "language backgrounds as an example, right? Or there's certain sections in the book that some people will take longer to understand, some",
    "start": "1306880",
    "end": "1312679"
  },
  {
    "text": "will take shorter time to understand, right? So I think adapting the teaching curriculum to that student.",
    "start": "1312680",
    "end": "1318240"
  },
  {
    "text": "AI can do a great job. You can take people from MIT, great PhDs or professors, and you can take that",
    "start": "1318240",
    "end": "1324000"
  },
  {
    "text": "coursework and translate that in Kannada for some person in a village in India.",
    "start": "1324000",
    "end": "1329040"
  },
  {
    "text": "Right, I think that, I think AI can play a very positive role. And back to what Tim was saying, we need your parents, Kyler, to tell",
    "start": "1329040",
    "end": "1335760"
  },
  {
    "text": "us where AI should be augmenting. Like taking the same lesson and creating multiple flashcards and different adapting",
    "start": "1335760",
    "end": "1342760"
  },
  {
    "text": "that lesson and things of that nature. And there are lots of things that you can do with AI in that space of teaching too.",
    "start": "1342760",
    "end": "1348120"
  },
  {
    "text": "Alright, so next week my parents will be on the podcast and uh, we'll, they'll, uh. We should definitely do a parents",
    "start": "1348120",
    "end": "1353840"
  },
  {
    "text": "episode where it's just everybody's parents but none of the usual guests. That would be so much fun. From this I've learned I need to joke.",
    "start": "1353840",
    "end": "1359640"
  },
  {
    "text": "I need to check back in with Khan Academy. I think the last time I was there, they were YouTube videos. So I think maybe that space has really expanded.",
    "start": "1359640",
    "end": "1366440"
  },
  {
    "text": "I need to go check back into that. Yeah, for sure. It's cool. Yeah, they're doing a lot of interesting experiments.",
    "start": "1366440",
    "end": "1375200"
  },
  {
    "start": "1374000",
    "end": "2034000"
  },
  {
    "text": "I want to make sure we get time for the last topic, which is a really broad one, but I think it connects a bunch of stories that have",
    "start": "1375200",
    "end": "1381360"
  },
  {
    "text": "kind of played out over the last few weeks and isn't really anything that we've covered in too much detail on mixture of experts in the past.",
    "start": "1381360",
    "end": "1387640"
  },
  {
    "text": "And the topic specifically is The relationship between generative AI and sustainability,",
    "start": "1387640",
    "end": "1393240"
  },
  {
    "text": "um, this week was the UN General Assembly and it was very interesting to me that the U. S.\nState Department said, we're going to bring a",
    "start": "1393240",
    "end": "1398920"
  },
  {
    "text": "bunch of people together, all the CEOs of all these companies to talk about how AI is going to be used for the sustainable development goals.",
    "start": "1398920",
    "end": "1406000"
  },
  {
    "text": "Um, and then similarly, you know, um, IBM just released a paper fairly recently talking about some collaborations they've been doing with NASA",
    "start": "1406000",
    "end": "1413320"
  },
  {
    "text": "specifically around predicting sort of climate and building climate models that are available. Um, and I guess, Shobhit, I want to",
    "start": "1413320",
    "end": "1419200"
  },
  {
    "text": "turn to you because my understanding is actually you gave a talk or were on a panel recently specifically on this topic. I'm wondering if you can give our listeners",
    "start": "1419200",
    "end": "1425280"
  },
  {
    "text": "sort of a sense of like how this sort of connection is evolving, like using this technology for these types of really, really",
    "start": "1425280",
    "end": "1431360"
  },
  {
    "text": "big problems where, you know, I think. Uh, as someone who hasn't really been as deep in the space, I'm kind of like, how does ChatGPT help save the world?",
    "start": "1431360",
    "end": "1438200"
  },
  {
    "text": "Uh, and I'm not, I know that's not the case, but if you can give us a little bit more color on like, how are people using this tech in this space?",
    "start": "1438200",
    "end": "1443240"
  },
  {
    "text": "Yeah, absolutely. And Tim, um, so IBM does a lot of work in the space. We have, uh, our own commitment to being",
    "start": "1443240",
    "end": "1449120"
  },
  {
    "text": "carbon, uh, neutral by 2030, and we're doing a great job, uh, against that already.",
    "start": "1449120",
    "end": "1455000"
  },
  {
    "text": "Uh, this week, I was, I spent a lot of time in New York with a lot of global leaders and, and, uh, like celebrities in the",
    "start": "1455000",
    "end": "1460440"
  },
  {
    "text": "space and got very humbled by the kind of problems that everybody's dealing with. So the, the entire conversation is",
    "start": "1460440",
    "end": "1466800"
  },
  {
    "text": "focused around AI can help solve some sustainability goals for us. And we need that compute power to be able",
    "start": "1466800",
    "end": "1473440"
  },
  {
    "text": "to solve these gnarly problems, right? So making predictions on what happens to, to, to climate all over",
    "start": "1473440",
    "end": "1480680"
  },
  {
    "text": "the world at a very granular level. How do you forecast what, uh, what events may happen?",
    "start": "1480680",
    "end": "1485800"
  },
  {
    "text": "And things of that nature. There's a lot that happens in that space. How to optimize the cost envelope of running businesses, things of that nature.",
    "start": "1485800",
    "end": "1492840"
  },
  {
    "text": "On the flip side, you have a cost, a climate and environmental cost that comes with running these models, right?",
    "start": "1492840",
    "end": "1498080"
  },
  {
    "text": "To just give you a few data points. If you ask ChatGPT or a massive model like that a question to go create something, right?",
    "start": "1498080",
    "end": "1505760"
  },
  {
    "text": "It consumes a 500 ml bottle of water to answer that question. That's just the water consumption",
    "start": "1505760",
    "end": "1511800"
  },
  {
    "text": "that goes behind these things, just cool down centers and whatnot. The data centers, Bloomberg came up with a",
    "start": "1511800",
    "end": "1517159"
  },
  {
    "text": "study, all the data centers together, would be the 17th largest country in energy consumption.",
    "start": "1517160",
    "end": "1523840"
  },
  {
    "text": "Countries like Italy or, um, Use more, use less energy than the data centers do today in",
    "start": "1523840",
    "end": "1531640"
  },
  {
    "text": "countries like Ireland, where they've become a center where all these international tech firms have all their data centers as well.",
    "start": "1531640",
    "end": "1538200"
  },
  {
    "text": "The data centers in Ireland use 12 percent of the national energy consumption. It's more than all the",
    "start": "1538200",
    "end": "1543520"
  },
  {
    "text": "households combined, right? So you're starting to get to these numbers where if you look at any of these graphs of the energy consumption.",
    "start": "1543520",
    "end": "1550240"
  },
  {
    "text": "And then you see where we are today, you get to a stage where companies like Microsoft are now partnering with nuclear reactors, the",
    "start": "1550240",
    "end": "1556600"
  },
  {
    "text": "things that had melted down, we're now trying to resurrect them so that they can power them. It was a three mile island, right?",
    "start": "1556600",
    "end": "1562200"
  },
  {
    "text": "Which famously had some trouble, you know, a little while back. So you can see how people are trying to wrangle,",
    "start": "1562200",
    "end": "1568800"
  },
  {
    "text": "how do I balance the compute that's needed. Versus how do you, how do you look at the energy consumption?",
    "start": "1568800",
    "end": "1575120"
  },
  {
    "text": "So my talk was about, uh, we have to be computationally responsible.",
    "start": "1575120",
    "end": "1580480"
  },
  {
    "text": "That was the title of the talk and we were talking about how do you figure out the right balance from the chip level all the way up to how do you end up using the models.",
    "start": "1580480",
    "end": "1587679"
  },
  {
    "text": "And, uh, when I was suggesting that like how you have cars that come with an empty MPG, a miles",
    "start": "1587680",
    "end": "1593080"
  },
  {
    "text": "per gallon sticker, that one number somebody can look at and say, yes, this is what I'm doing. When you're booking a flight, I know the carbon emissions.",
    "start": "1593080",
    "end": "1599840"
  },
  {
    "text": "So I think as part of that, we need to be very conscious about if I'm using ChatGPT as a calculator to add two numbers versus",
    "start": "1599840",
    "end": "1607120"
  },
  {
    "text": "using the actual calculator, there's a huge delta between one half and the other. I know we'll get the answer wrong. That's exactly right.",
    "start": "1607120",
    "end": "1612800"
  },
  {
    "text": "Yeah, I think there are some really good use cases of where AI has been helping augment. We do a lot of work with, uh, with forestation.",
    "start": "1612800",
    "end": "1620320"
  },
  {
    "text": "We look at how, how, how land use has increased. We are predicting, uh, Catastrophic events",
    "start": "1620320",
    "end": "1626880"
  },
  {
    "text": "with, with governments all across the world. We're trying to, to help them with wildfire, wildfires and stuff like that.",
    "start": "1626880",
    "end": "1632440"
  },
  {
    "text": "So I'm overall very impressed with how IBM has taken a, a position on sustainability using AI for good.",
    "start": "1632440",
    "end": "1638840"
  },
  {
    "text": "And we are super focused on smaller models, energy efficient, all the way down to how do we optimize our compute.",
    "start": "1638840",
    "end": "1645400"
  },
  {
    "text": "And this is also part of our whole AI alliance with Meta and all the other companies where we are. Collectively trying to reduce the threshold",
    "start": "1645400",
    "end": "1652320"
  },
  {
    "text": "required to go implement AI across the world, especially in Africa and parts of Europe",
    "start": "1652320",
    "end": "1657760"
  },
  {
    "text": "and Asia and things of that nature as well. So good. I like that bottle of water analogy. Um, there was a paper came out from",
    "start": "1657760",
    "end": "1664720"
  },
  {
    "text": "Signal and Hugging Face just this last week, and it was on sustainability and the energy that's being used here.",
    "start": "1664720",
    "end": "1671799"
  },
  {
    "text": "And one of the units of analysis they used is how many cell phone charges This thing",
    "start": "1671800",
    "end": "1677040"
  },
  {
    "text": "that a query would use and the highest was image generation and we're approaching a query to an image generating model is getting",
    "start": "1677040",
    "end": "1683040"
  },
  {
    "text": "close to a cell phones overnight charge. And I just, I just really liked that",
    "start": "1683040",
    "end": "1688440"
  },
  {
    "text": "kind of unit of analysis because it brings it home so much more about. Okay, I put in that query for an image",
    "start": "1688440",
    "end": "1693520"
  },
  {
    "text": "generation and now I have to think about that's the power of a cell phone for a day or two.",
    "start": "1693520",
    "end": "1699240"
  },
  {
    "text": "Uh, so I think it's really cool to try to maybe think about more creative metrics that we can",
    "start": "1699240",
    "end": "1704559"
  },
  {
    "text": "present this to the world about just how power hungry or water thirsty these, these models are.",
    "start": "1704560",
    "end": "1710960"
  },
  {
    "text": "Otherwise I see Milo, Milliwatt hours. I'm not an, I'm not an electrical engineer. Uh, and it, I don't really appreciate",
    "start": "1710960",
    "end": "1716960"
  },
  {
    "text": "it, but you tell me how many, you know, bottles of water it is, or how many, um, cell phone charges and, and it clicks.",
    "start": "1716960",
    "end": "1723120"
  },
  {
    "text": "So, uh, yeah. Uh, yeah. That's interesting. Would you want it to be like, metered, so like, as you're, you know, you're using",
    "start": "1723120",
    "end": "1728799"
  },
  {
    "text": "clot or something and it's like, here's how much power you've, you know, used. Yeah. Yeah.\nMm-Hmm. , that would be, that would be really useful.",
    "start": "1728800",
    "end": "1734540"
  },
  {
    "text": "Uh, Maryam, we've done a lot of work with granite models. with Prithvi, and we're open source then.",
    "start": "1734540",
    "end": "1739840"
  },
  {
    "text": "Do you want to share with the audience what we're doing with our granite models? With granite, we are focusing on the smaller model, um, for the exact",
    "start": "1739840",
    "end": "1747280"
  },
  {
    "text": "same reason that you mentioned. Like, let me, let me just share some data points. If you look into a five, hosting a 500",
    "start": "1747280",
    "end": "1755080"
  },
  {
    "text": "billion large language model on A100s, roughly you need 16 A100s for that hosting.",
    "start": "1755080",
    "end": "1762800"
  },
  {
    "text": "If you. Look into a 20 billion models, parameter model, just one single A100.",
    "start": "1762800",
    "end": "1769840"
  },
  {
    "text": "So the API call that you send to a 20 billion model versus a 500 billion model is 16X more",
    "start": "1769840",
    "end": "1778559"
  },
  {
    "text": "energy efficient, just because it's 16 times less GPU, just ignoring all the cost and",
    "start": "1778560",
    "end": "1784200"
  },
  {
    "text": "latency and all the other concerns just for sustainability because of this, what we see",
    "start": "1784200",
    "end": "1789919"
  },
  {
    "text": "in the market emerging is looking into all. The smallest model that makes sense and",
    "start": "1789920",
    "end": "1798360"
  },
  {
    "text": "customize that on their proprietary data. That's the data about their users.",
    "start": "1798360",
    "end": "1803480"
  },
  {
    "text": "That's the domain of specific data to create something differentiated that delivers the",
    "start": "1803480",
    "end": "1808720"
  },
  {
    "text": "performance that they need on a target. use case for a fraction of the cost. And by cost, I mean cost in terms of energy,",
    "start": "1808720",
    "end": "1815880"
  },
  {
    "text": "carbon footprint, and everything together. That's the guiding principles for Granite. Like we've been focusing on a smaller",
    "start": "1815880",
    "end": "1822840"
  },
  {
    "text": "enterprise ready models that are rooted in value and trust and allow our company, the",
    "start": "1822840",
    "end": "1829960"
  },
  {
    "text": "companies to use their own data on Granite. To make the custom model, if you look",
    "start": "1829960",
    "end": "1836200"
  },
  {
    "text": "into our granite custom, the open source models, they are released on their Apache 2.0 license.",
    "start": "1836200",
    "end": "1844679"
  },
  {
    "text": "What it gives enterprises is the freedom and flexibility to customize those models for their own commercial purposes.",
    "start": "1844680",
    "end": "1851799"
  },
  {
    "text": "with no restriction, which is really the power of granite. I love that. And Maryam, uh, this week, we",
    "start": "1851800",
    "end": "1858880"
  },
  {
    "text": "also released our Prithvi next generation models for granite, right? And just to share with the audience, we as",
    "start": "1858880",
    "end": "1864720"
  },
  {
    "text": "IPM have been partnering with NASA and the problem we're trying to solve, generally, we have, uh, these machine learning models",
    "start": "1864720",
    "end": "1871840"
  },
  {
    "text": "that make predictions on forecasting weather patterns and things of that nature, right? This is the first time it has ever been done.",
    "start": "1871840",
    "end": "1877840"
  },
  {
    "text": "Where we've created a foundation model where a pixel where it's a square inch or",
    "start": "1877840",
    "end": "1883640"
  },
  {
    "text": "of the earth, we're using those as tokens. We're trying to predict what will happen next, right? Instead of using text.",
    "start": "1883640",
    "end": "1888840"
  },
  {
    "text": "So we built this foundation model that combines weather data and climate data together in one model.",
    "start": "1888840",
    "end": "1894600"
  },
  {
    "text": "So in that model can then be adapted for various use cases. In the current state, we have things like if you want to do forecasting",
    "start": "1894600",
    "end": "1901440"
  },
  {
    "text": "in Florida for for rainfall, there'll be completely different model. If you're trying to do deforestation somewhere",
    "start": "1901440",
    "end": "1907399"
  },
  {
    "text": "else, it'll be completely different model. So the first time we have combined a model that can be easily adapted, just like the foundation",
    "start": "1907400",
    "end": "1913360"
  },
  {
    "text": "models that we've built and as a mic drop. Open source is completely to the community.",
    "start": "1913360",
    "end": "1918960"
  },
  {
    "text": "So now you can go and take these Prithvi models from Hugging Face, deploy them for the same model, multiple things.",
    "start": "1918960",
    "end": "1926200"
  },
  {
    "text": "The next iteration, where I think we will hopefully go, this is starting to do what multimodal models did.",
    "start": "1926200",
    "end": "1932399"
  },
  {
    "text": "You used to have one model that did text, one model that did image. And then just like Meta is 3.2 billion,Â \n3.2, now we're combining the two together.",
    "start": "1932400",
    "end": "1939960"
  },
  {
    "text": "So the same model can do both of them. I'm hoping that we'll come to that point with foundation models for weather and",
    "start": "1939960",
    "end": "1945560"
  },
  {
    "text": "climate, where you can then start to connect what's happening in two different places. The climate patterns are changing, the",
    "start": "1945560",
    "end": "1951240"
  },
  {
    "text": "forestation is changing, it'll be able to think through and combine those two. So we've made the first step towards a new",
    "start": "1951240",
    "end": "1957280"
  },
  {
    "text": "future, where foundation models will be able to combine all of this data together, and the same model can answer all of these questions.",
    "start": "1957280",
    "end": "1963919"
  },
  {
    "text": "So I'm super excited about this, these models. And also think about it, 40 years of NASA",
    "start": "1963920",
    "end": "1970000"
  },
  {
    "text": "satellite images, Are at our fingerprint now with this models to use it for weather forecast,",
    "start": "1970000",
    "end": "1977840"
  },
  {
    "text": "climate prediction, seasonal prediction and use that to inform decisions for planning",
    "start": "1978680",
    "end": "1983960"
  },
  {
    "text": "mitigations, um, for climate and weather. That's exciting.",
    "start": "1983960",
    "end": "1989240"
  },
  {
    "text": "That's super exciting. It's a great note to end on just because I think like both. It's a model that it's open source listeners. You can go and download and",
    "start": "1989240",
    "end": "1994720"
  },
  {
    "text": "play with it if you want it. Um, and, uh, and I think it's a great application. I think it's what I was talking about earlier.",
    "start": "1994720",
    "end": "2000200"
  },
  {
    "text": "Like, I think it's so useful to get beyond simply like, Oh, how does a chatbot save or gain sustainability?",
    "start": "2000200",
    "end": "2006240"
  },
  {
    "text": "There's so all these other aspects and applications that I think people don't think about when this this topic tends to come up.",
    "start": "2006240",
    "end": "2012880"
  },
  {
    "text": "Um, well, great, everybody. So that's all the time we have for today. Uh, thanks for joining us. Uh, if you enjoyed what you heard,",
    "start": "2012880",
    "end": "2018560"
  },
  {
    "text": "you can get us on Apple Podcasts, uh, Spotify and podcast platforms everywhere. Uh, Shobit, Skyler, Maryam, thanks",
    "start": "2018560",
    "end": "2025000"
  },
  {
    "text": "for joining us and we hope to have you on, uh, sometime in the future.",
    "start": "2025000",
    "end": "2033640"
  }
]
[
  {
    "text": "How many times a day do you use AI?",
    "start": "600",
    "end": "2969"
  },
  {
    "text": "You may be surprised to find",
    "start": "3180",
    "end": "4922"
  },
  {
    "text": "that AI powers many of the tech services you use throughout your day.",
    "start": "4922",
    "end": "8519"
  },
  {
    "text": "Any time you use speech to text on your phone",
    "start": "8970",
    "end": "11988"
  },
  {
    "text": "or you use a chat bot for customer service, you're using AI.",
    "start": "11988",
    "end": "15918"
  },
  {
    "text": "Behind the scenes, these existing technologies are consuming lots of energy.",
    "start": "16144",
    "end": "21783"
  },
  {
    "text": "One very exciting field has emerged to try and make AI more energy efficient,",
    "start": "22029",
    "end": "27213"
  },
  {
    "text": "and that's in-memory computing.",
    "start": "27214",
    "end": "29112"
  },
  {
    "text": "But you may be wondering why is energy efficient AI desirable?",
    "start": "29460",
    "end": "34288"
  },
  {
    "text": "My name is Nicole Saulnier,",
    "start": "34618",
    "end": "36538"
  },
  {
    "text": "and I'm a researcher with IBM working on in-memory computing.",
    "start": "36538",
    "end": "40307"
  },
  {
    "text": "In a traditional computer there are two main blocks.",
    "start": "41386",
    "end": "45870"
  },
  {
    "text": "A memory, and a CPU or Central Processing Unit.",
    "start": "48805",
    "end": "55252"
  },
  {
    "text": "These are connected together by a bus.",
    "start": "55252",
    "end": "59314"
  },
  {
    "text": "And data is transferred back and forth",
    "start": "60108",
    "end": "62757"
  },
  {
    "text": "to execute instructions and perform computations.",
    "start": "62757",
    "end": "66000"
  },
  {
    "text": "As transistors have continued to scale,",
    "start": "66294",
    "end": "69069"
  },
  {
    "text": "the CPU has become faster and more energy efficient.",
    "start": "69069",
    "end": "72396"
  },
  {
    "text": "This has increased the importance of the limitations of the speed and energy",
    "start": "72721",
    "end": "78134"
  },
  {
    "text": "that's used or consumed during the transfer of data back and forth",
    "start": "81505",
    "end": "87095"
  },
  {
    "text": "between the memory and the CPU.",
    "start": "87095",
    "end": "89309"
  },
  {
    "text": "In data intensive computation such as deep learning,",
    "start": "89545",
    "end": "93401"
  },
  {
    "text": "the data communication is actually dominating the model runtimes and the energy consumption.",
    "start": "93401",
    "end": "100094"
  },
  {
    "text": "To put that into perspective,",
    "start": "100833",
    "end": "103375"
  },
  {
    "text": "we can think about some commonly used models today.",
    "start": "103375",
    "end": "107198"
  },
  {
    "text": "To train just one very large natural language processing model,",
    "start": "107420",
    "end": "113032"
  },
  {
    "text": "we actually are consuming about the same amount of energy as the equivalent carbon footprint of five cars.",
    "start": "115051",
    "end": "126205"
  },
  {
    "text": "And even in a cloud environment where many computers are working together to solve the same problem,",
    "start": "126843",
    "end": "132848"
  },
  {
    "text": "it can take over one week to train.",
    "start": "132848",
    "end": "134979"
  },
  {
    "text": "To appreciate these energy and time constraints,",
    "start": "140620",
    "end": "143586"
  },
  {
    "text": "we have to look at the field of AI and look at the trends.",
    "start": "143586",
    "end": "147520"
  },
  {
    "text": "We can categorize AI by dividing it into three different categories.",
    "start": "148270",
    "end": "155501"
  },
  {
    "text": "In narrow AI, we're able to solve a single task with superhuman accuracy.",
    "start": "156480",
    "end": "165418"
  },
  {
    "text": "In broad AI, we're performing multiple tasks within the same domain.",
    "start": "166017",
    "end": "173034"
  },
  {
    "text": "Things like diagnosing a patient with cancer and providing a treatment plan for them.",
    "start": "173310",
    "end": "179241"
  },
  {
    "text": "And then in general AI, we're working across domain,",
    "start": "179537",
    "end": "187578"
  },
  {
    "text": "applying learning from one area to another area with ease and often without any supervision.",
    "start": "187578",
    "end": "193525"
  },
  {
    "text": "Today we're here somewhere between narrow and broad AI,",
    "start": "193929",
    "end": "198268"
  },
  {
    "text": "and we know if we want to move further to the right,",
    "start": "198268",
    "end": "202048"
  },
  {
    "text": "the size and complexity of our models are going to be increasing.",
    "start": "202048",
    "end": "205649"
  },
  {
    "text": "This is going to drive a need for innovation",
    "start": "205950",
    "end": "209621"
  },
  {
    "text": "and for more energy efficient AI compute.",
    "start": "209621",
    "end": "212370"
  },
  {
    "text": "And that's where in-memory computing comes in.",
    "start": "212850",
    "end": "214830"
  },
  {
    "text": "Instead of spending all this time, transferring our data back and forth,",
    "start": "215430",
    "end": "220510"
  },
  {
    "text": "what if we could design a system that eliminated this data movement",
    "start": "220510",
    "end": "225127"
  },
  {
    "text": "and actually perform the functions of both the memory and the CPU?",
    "start": "225127",
    "end": "232788"
  },
  {
    "text": "Then we could potentially have an increase in our speed and our energy performance.",
    "start": "233510",
    "end": "238668"
  },
  {
    "text": "In order to think about this,",
    "start": "241199",
    "end": "244128"
  },
  {
    "text": "it helps to break it down and to start thinking about what types of computations a memory could perform.",
    "start": "244242",
    "end": "250057"
  },
  {
    "text": "One can think of a memory as an array of resistive elements,",
    "start": "251056",
    "end": "255188"
  },
  {
    "text": "and each of these resistive elements can be programed to some conductance value \"G\",",
    "start": "255188",
    "end": "260120"
  },
  {
    "text": "where G is just going to be the inverse of our resistance.",
    "start": "260120",
    "end": "264296"
  },
  {
    "text": "If we have a simple crossbar of two metal wires",
    "start": "264889",
    "end": "269238"
  },
  {
    "text": "and we put one of our resistive elements between them,",
    "start": "269430",
    "end": "273626"
  },
  {
    "text": "this can be programed to conductance G1.",
    "start": "273626",
    "end": "276479"
  },
  {
    "text": "We can apply some voltage V1 across it,",
    "start": "276479",
    "end": "279216"
  },
  {
    "text": "and then we can calculate the current I1 flowing through our device.",
    "start": "279485",
    "end": "283844"
  },
  {
    "text": "And this will just be I1 is equal to v1 times G1.",
    "start": "284427",
    "end": "289294"
  },
  {
    "text": "And this is just dictated by Ohm's Law.",
    "start": "290050",
    "end": "293164"
  },
  {
    "text": "Now, if we extend our array and we add a second row of devices,",
    "start": "296267",
    "end": "303191"
  },
  {
    "text": "the current through this device can be expressed as I2,",
    "start": "303343",
    "end": "307852"
  },
  {
    "text": "and we can calculate the current coming out at the bottom of our column",
    "start": "307852",
    "end": "312729"
  },
  {
    "text": "as I is equal to I1 plus I2.",
    "start": "312730",
    "end": "318391"
  },
  {
    "text": "And this is just Kirchhoff's Law, which has performed an accumulation operation for us.",
    "start": "318934",
    "end": "332813"
  },
  {
    "text": "So, we're able to perform different operations: a multiplication with ohms law,",
    "start": "333241",
    "end": "337458"
  },
  {
    "text": "and an addition with Kirchhoff law by using these types of devices.",
    "start": "337458",
    "end": "342001"
  },
  {
    "text": "And we now take our simple one column and expand it out into an array.",
    "start": "343374",
    "end": "349944"
  },
  {
    "text": "We can put an element at each cross point",
    "start": "352376",
    "end": "356565"
  },
  {
    "text": "between the various metal wires,",
    "start": "356565",
    "end": "359644"
  },
  {
    "text": "and we can represent these as different conductance values.",
    "start": "363000",
    "end": "367076"
  },
  {
    "text": "Each can be programmed to a different value.",
    "start": "367076",
    "end": "369960"
  },
  {
    "text": "And we can represent this as a matrix G,",
    "start": "373799",
    "end": "378120"
  },
  {
    "text": "and that consists of all of our different elements.",
    "start": "379148",
    "end": "382719"
  },
  {
    "text": "We can then apply different voltages to each row of our array,",
    "start": "387722",
    "end": "392513"
  },
  {
    "text": "and we can represent that as a vector V of our input voltages.",
    "start": "392514",
    "end": "398732"
  },
  {
    "text": "Then our currents coming out the bottom of our columns",
    "start": "402889",
    "end": "407847"
  },
  {
    "text": "can be represented by the resultant vector I,",
    "start": "408000",
    "end": "413545"
  },
  {
    "text": "which is equal to our voltage vector times our conductance matrix G.",
    "start": "413886",
    "end": "420477"
  },
  {
    "text": "And this is just a matrix vector multiplication or an MVM,",
    "start": "420477",
    "end": "426349"
  },
  {
    "text": "and this is super convenient because it turns out that in AI inference workloads",
    "start": "426485",
    "end": "431771"
  },
  {
    "text": "around 60 to 90 percent of our operations are going to be these MVM operations.",
    "start": "431772",
    "end": "440572"
  },
  {
    "text": "So we have that basic building block available to us.",
    "start": "441907",
    "end": "444759"
  },
  {
    "text": "How do we actually map our neural network onto our hardware?",
    "start": "445570",
    "end": "449430"
  },
  {
    "text": "Well, a layer of a neural network consists of many output neurons.",
    "start": "449647",
    "end": "454806"
  },
  {
    "text": "And each of those output neurons, for instance N,",
    "start": "454955",
    "end": "460080"
  },
  {
    "text": "it's going to be driven by a set of input neurons through a set of weights.",
    "start": "460270",
    "end": "472332"
  },
  {
    "text": "And if we have our input to our neural network layer as X,",
    "start": "476756",
    "end": "482182"
  },
  {
    "text": "we can express the output from the layer mathematically as this equation.",
    "start": "482410",
    "end": "489692"
  },
  {
    "text": "Now we have to map this equation onto our memory array.",
    "start": "500242",
    "end": "504172"
  },
  {
    "text": "The first thing we can do is take all of our conductances",
    "start": "505151",
    "end": "508244"
  },
  {
    "text": "and program them such that our conductance matrix G is equal to our weights of our layer.",
    "start": "508605",
    "end": "515567"
  },
  {
    "text": "And then we can encode the inputs to our neural network layer X as a vector of input voltages V.",
    "start": "515827",
    "end": "524750"
  },
  {
    "text": "And finally, we can collect the currents coming out of the columns of each column of the array",
    "start": "525208",
    "end": "531671"
  },
  {
    "text": "and apply our activation function F to our current.",
    "start": "531671",
    "end": "535856"
  },
  {
    "text": "And that is going to give us the output from our neural network layer Y.",
    "start": "536289",
    "end": "541366"
  },
  {
    "text": "And this way, we can use these concepts to map our neural network onto our memory array",
    "start": "541734",
    "end": "547841"
  },
  {
    "text": "to perform analog in-memory computing for more energy efficient AI.",
    "start": "547841",
    "end": "553322"
  },
  {
    "text": "There are a lot of details that go into the design, the build,",
    "start": "553959",
    "end": "557589"
  },
  {
    "text": "and the usage of these analog in-memory computing chips.",
    "start": "557589",
    "end": "562089"
  },
  {
    "text": "You can join us and check out our AI hardware toolkit",
    "start": "562646",
    "end": "567558"
  },
  {
    "text": "to learn more about different neural networks and simulate those,",
    "start": "567558",
    "end": "571682"
  },
  {
    "text": "and you can also explore various memory elements, which we have included.",
    "start": "571682",
    "end": "576547"
  },
  {
    "text": "And the best part is you can contribute",
    "start": "576752",
    "end": "579181"
  },
  {
    "text": "and join us to help make AI more energy efficient.",
    "start": "579294",
    "end": "582526"
  },
  {
    "text": "Thanks for watching.",
    "start": "584230",
    "end": "585253"
  },
  {
    "text": "If you like the video, don't forget to like and subscribe to the channel",
    "start": "585254",
    "end": "589394"
  },
  {
    "text": "and also check out the links below for access to our open source analog AI hardware toolkit.",
    "start": "589394",
    "end": "597433"
  }
]
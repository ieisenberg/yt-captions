[
  {
    "text": "What if you were deciding between \nmultiple LLMs to perform a specific task,",
    "start": "180",
    "end": "4054"
  },
  {
    "text": "and you want to find the best one that meets your needs?",
    "start": "4054",
    "end": "6585"
  },
  {
    "text": "Using an LLM benchmark can be an option.",
    "start": "6930",
    "end": "9059"
  },
  {
    "text": "LLM benchmarks are standardized frameworks",
    "start": "10280",
    "end": "12406"
  },
  {
    "text": "for assessing the performance of LLMs.",
    "start": "12406",
    "end": "14687"
  },
  {
    "text": "They supply a task that an LLM must accomplish,",
    "start": "15140",
    "end": "18222"
  },
  {
    "text": "evaluate the model's performance based on a specific metric,",
    "start": "18222",
    "end": "21846"
  },
  {
    "text": "and produce a score based on that metric.",
    "start": "21846",
    "end": "24199"
  },
  {
    "text": "Models can be evaluated on their capabilities,",
    "start": "25040",
    "end": "27603"
  },
  {
    "text": "which can include coding, translation,",
    "start": "27603",
    "end": "31151"
  },
  {
    "text": "or text summarization.",
    "start": "31151",
    "end": "32902"
  },
  {
    "text": "LLM benchmarks allow us to compare different models",
    "start": "33859",
    "end": "36862"
  },
  {
    "text": "to determine the best model for a specific task.",
    "start": "36862",
    "end": "39489"
  },
  {
    "text": "They also help us fine tune the model to improve its performance.",
    "start": "40211",
    "end": "43660"
  },
  {
    "text": "Now let's go into the main components of an LLM benchmark.",
    "start": "43961",
    "end": "48430"
  },
  {
    "text": "There are three main steps when it comes to executing an LLM benchmark.",
    "start": "48910",
    "end": "52930"
  },
  {
    "text": "The first step is setting up and preparing the sample data.",
    "start": "53546",
    "end": "56455"
  },
  {
    "text": "This is the data that we're actually going to use to test the LLM and evaluate its performance.",
    "start": "56860",
    "end": "62020"
  },
  {
    "text": "This can include things such as text documents",
    "start": "62800",
    "end": "67177"
  },
  {
    "text": "or coding problems, or even math problems,",
    "start": "67177",
    "end": "74091"
  },
  {
    "text": "depending on the use case.",
    "start": "74091",
    "end": "76619"
  },
  {
    "text": "The second part is actually testing the LLM.",
    "start": "77960",
    "end": "81576"
  },
  {
    "text": "Now we're going to test the LLM on the sample data.",
    "start": "82160",
    "end": "84860"
  },
  {
    "text": "And we can use either a few shot, a zero shot,",
    "start": "85310",
    "end": "89310"
  },
  {
    "text": "or a fine tuned approach depending on the use case.",
    "start": "89310",
    "end": "93532"
  },
  {
    "text": "This simply refers to how much data we're going to give the LLM,",
    "start": "93980",
    "end": "98743"
  },
  {
    "text": "or how many labeled examples we're going to give the LLM",
    "start": "98743",
    "end": "102651"
  },
  {
    "text": "before we test it.",
    "start": "102652",
    "end": "103685"
  },
  {
    "text": "And now the last and third part, and arguably the most important, is scoring.",
    "start": "103850",
    "end": "108199"
  },
  {
    "text": "We're going to use a metric to determine how the model's output",
    "start": "108650",
    "end": "112515"
  },
  {
    "text": "differs or resembles the expected solution.",
    "start": "112515",
    "end": "116167"
  },
  {
    "text": "Metrics that are commonly used include accuracy,",
    "start": "116910",
    "end": "121022"
  },
  {
    "text": "which measures the number of correct predictions,",
    "start": "121022",
    "end": "125526"
  },
  {
    "text": "recall, which measures the number of true positives,",
    "start": "126252",
    "end": "130813"
  },
  {
    "text": "and perplexity.",
    "start": "130814",
    "end": "132963"
  },
  {
    "text": "This measures how well a model predicts.",
    "start": "133801",
    "end": "137069"
  },
  {
    "text": "Usually one or more of these quantitative metrics are combined.",
    "start": "137611",
    "end": "142079"
  },
  {
    "text": "And while this is not an exhaustive list,",
    "start": "142320",
    "end": "144970"
  },
  {
    "text": "usually one or more of these quantitative metrics are combined",
    "start": "144970",
    "end": "149008"
  },
  {
    "text": "in order to have a comprehensive and more\nthorough evaluation of the model's performance.",
    "start": "149008",
    "end": "153861"
  },
  {
    "text": "Overall, using those metrics we create a score from 0 to 100,",
    "start": "154290",
    "end": "160109"
  },
  {
    "text": "which is the final evaluation score for this model.",
    "start": "160109",
    "end": "163110"
  },
  {
    "text": "Now let's look at applying what we've learned about benchmarks to an LLM example.",
    "start": "163740",
    "end": "168794"
  },
  {
    "text": "Let's say that Joe, Susie and Mark",
    "start": "168870",
    "end": "171758"
  },
  {
    "text": "are three candidates who all want to join the track team.",
    "start": "171758",
    "end": "175368"
  },
  {
    "text": "In order to join the track team,",
    "start": "175800",
    "end": "177837"
  },
  {
    "text": "they must complete a 200 meter race, a 400 meter race,",
    "start": "177837",
    "end": "181787"
  },
  {
    "text": "and an 800 meter race and",
    "start": "181787",
    "end": "184676"
  },
  {
    "text": "complete the race within a certain amount of time.",
    "start": "184676",
    "end": "187831"
  },
  {
    "text": "These three scores will be aggregated to get their final score.",
    "start": "188341",
    "end": "191701"
  },
  {
    "text": "Let's say that Joe is able to complete the 200 meter race,",
    "start": "192930",
    "end": "196933"
  },
  {
    "text": "the 400 meter race, and 800 meter,",
    "start": "196933",
    "end": "199823"
  },
  {
    "text": "and he gets a score of 100 because he completed all three races.",
    "start": "199823",
    "end": "203759"
  },
  {
    "text": "Susie was able to pass the 200 meter and the 400 meter,",
    "start": "204780",
    "end": "209317"
  },
  {
    "text": "but not the 800, and got a score of 66.",
    "start": "209317",
    "end": "212807"
  },
  {
    "text": "Unfortunately for Mark, he was able to pass the 200 meter,",
    "start": "213590",
    "end": "217147"
  },
  {
    "text": "but not 400 or 800 and got a score of 33.",
    "start": "217147",
    "end": "222000"
  },
  {
    "text": "Looking at these scores,",
    "start": "223100",
    "end": "224620"
  },
  {
    "text": "we can see that based on this benchmark that we've set",
    "start": "224620",
    "end": "227818"
  },
  {
    "text": "for the track team candidates,",
    "start": "227818",
    "end": "229474"
  },
  {
    "text": "Joe is the best candidate for joining the track team.",
    "start": "229474",
    "end": "233334"
  },
  {
    "text": "Now let's look at applying what we've learned about benchmarks to an LLM example.",
    "start": "233511",
    "end": "238488"
  },
  {
    "text": "Let's say that we have three LLMs.",
    "start": "238671",
    "end": "240795"
  },
  {
    "text": "And we want to evaluate and compare all three of these LLMs",
    "start": "240920",
    "end": "244567"
  },
  {
    "text": "on a science test.",
    "start": "244567",
    "end": "245960"
  },
  {
    "text": "We want to determine which model is the best",
    "start": "246140",
    "end": "248667"
  },
  {
    "text": "at answering questions on a specific science test,",
    "start": "248667",
    "end": "251570"
  },
  {
    "text": "and we're going to use that as a benchmark.",
    "start": "251570",
    "end": "253762"
  },
  {
    "text": "Let's say that we've prepared the data for this benchmark",
    "start": "254360",
    "end": "257351"
  },
  {
    "text": "and we've tested all of these LLMS,",
    "start": "257351",
    "end": "259476"
  },
  {
    "text": "and we're going to use accuracy as a metric.",
    "start": "259476",
    "end": "261917"
  },
  {
    "text": "Accuracy because it's quite easy to understand.",
    "start": "262100",
    "end": "264800"
  },
  {
    "text": "It's the number of correct problems answered,",
    "start": "264980",
    "end": "267970"
  },
  {
    "text": "so the number of problems that were answered correctly on the test.",
    "start": "267970",
    "end": "271957"
  },
  {
    "text": "Let's say that the first LLM, LLM 1, has an accuracy of 90%,.",
    "start": "272840",
    "end": "278174"
  },
  {
    "text": "Because its the only metric we're using, we'll just say that the score from 0 to 100 is 90.",
    "start": "279126",
    "end": "284495"
  },
  {
    "text": "LLM 2 has an accuracy of 70%, thus its score is 70.",
    "start": "285590",
    "end": "290389"
  },
  {
    "text": "LLM 3 has an accuracy of 30%, thus its score is 30.",
    "start": "291678",
    "end": "297447"
  },
  {
    "text": "Based on these scores,",
    "start": "298030",
    "end": "299753"
  },
  {
    "text": "which are based on the accuracy rate,",
    "start": "299753",
    "end": "301903"
  },
  {
    "text": "we can conclude from the accuracy alone",
    "start": "301903",
    "end": "304878"
  },
  {
    "text": "that LLM 1 is theoretically the best LLM",
    "start": "304878",
    "end": "309492"
  },
  {
    "text": "for answering questions on this specific science test.",
    "start": "309492",
    "end": "312746"
  },
  {
    "text": "However, LLM benchmarks can have some limitations.",
    "start": "313496",
    "end": "317066"
  },
  {
    "text": "For one, they may not be able to accurately capture edge cases",
    "start": "317440",
    "end": "321048"
  },
  {
    "text": "or very specific or unusual scenarios.",
    "start": "321048",
    "end": "323656"
  },
  {
    "text": "In those sorts of cases,",
    "start": "323950",
    "end": "325652"
  },
  {
    "text": "an LLM benchmark is actually not specific enough",
    "start": "325652",
    "end": "328456"
  },
  {
    "text": "to accurately capture the problem that we are trying to solve.",
    "start": "328456",
    "end": "331298"
  },
  {
    "text": "Number two, LLM benchmarks can actually be too specific,",
    "start": "332250",
    "end": "336426"
  },
  {
    "text": "and they can cause the model to overfit,",
    "start": "336426",
    "end": "338534"
  },
  {
    "text": "which is not necessarily a reflection of how the model will perform",
    "start": "338534",
    "end": "341807"
  },
  {
    "text": "on new or unseen data.",
    "start": "341808",
    "end": "343786"
  },
  {
    "text": "And number three, due to the nature of LLM benchmarks,",
    "start": "344370",
    "end": "347955"
  },
  {
    "text": "they have finite lifespans.",
    "start": "347955",
    "end": "349905"
  },
  {
    "text": "If a model reaches the highest possible score,",
    "start": "350220",
    "end": "353101"
  },
  {
    "text": "the benchmark itself will have to be altered.",
    "start": "353101",
    "end": "355229"
  },
  {
    "text": "This will result in new benchmarks being developed",
    "start": "355710",
    "end": "358223"
  },
  {
    "text": "as LLMs grow more advanced.",
    "start": "358223",
    "end": "360029"
  },
  {
    "text": "Despite these limitations, LLM benchmarks are a good option",
    "start": "360420",
    "end": "363988"
  },
  {
    "text": "for quickly evaluating different models on different types of tasks",
    "start": "363988",
    "end": "367945"
  },
  {
    "text": "and fine tuning models for improvement.",
    "start": "367945",
    "end": "370413"
  }
]
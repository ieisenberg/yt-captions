[
  {
    "text": "Malcolm Gladwell: Alright, welcome everybody. You guys excited?  Hello, hello. Welcome to Smart Talks  with IBM, a podcast from Pushkin Industries,  ",
    "start": "0",
    "end": "13360"
  },
  {
    "text": "iHeartRadio and IBM. I’m Malcolm Gladwell.\nThis season, we’re continuing our conversations  ",
    "start": "13360",
    "end": "19200"
  },
  {
    "text": "with New Creators— visionaries who are creatively \napplying technology in business to drive change,  ",
    "start": "19200",
    "end": "25080"
  },
  {
    "text": "but with a focus on the transformative power \nof artificial intelligence and what it means  ",
    "start": "25080",
    "end": "30240"
  },
  {
    "text": "to leverage AI as a game-changing \nmultiplier for your business. ",
    "start": "30240",
    "end": "35760"
  },
  {
    "text": "Today’s episode is a bit different than usual. \nI was recently joined onstage by Darío Gil for  ",
    "start": "35760",
    "end": "41640"
  },
  {
    "text": "a conversation in front of a live audience at \nthe iHeartMedia headquarters in Manhattan. Darío  ",
    "start": "41640",
    "end": "46840"
  },
  {
    "text": "is the Senior Vice President and Director \nof IBM Research—one of the world’s largest  ",
    "start": "46840",
    "end": "51960"
  },
  {
    "text": "and most influential corporate research labs.\nWe discussed the rise of generative AI and what  ",
    "start": "51960",
    "end": "57960"
  },
  {
    "text": "it means for business and society. He also \nexplained how organizations that leverage   AI to create value will dominate in the near \nfuture. Okay, let’s get to the conversation. ",
    "start": "57960",
    "end": "70200"
  },
  {
    "text": "Malcolm Gladwell: Hello, everyone. Welcome. And I'm \nhere with Dr. Darío Gil. And I wanted to say,  ",
    "start": "70200",
    "end": "78479"
  },
  {
    "text": "before we get started—this is something I said \nbackstage: that I feel very guilty today because,  ",
    "start": "78480",
    "end": "84840"
  },
  {
    "text": "you're the arguably one of the most important \nfigures in AI research in the world, and we  ",
    "start": "84840",
    "end": "92359"
  },
  {
    "text": "have taken you away from your job for a morning.\nIt's like if, you know, Oppenheimer's wife in  ",
    "start": "92360",
    "end": "99160"
  },
  {
    "text": "1944 said, “Let's go and have a little getaway in \nthe Bahamas.” It's that kind of thing. You know,  ",
    "start": "99160",
    "end": "106960"
  },
  {
    "text": "what do you say to your wife? “I \ncan't. We have got to work on this   thing I can't tell you about.” She's like, “Get\nme out of Los Alamos.” “No.” So I do feel guilty.  ",
    "start": "106960",
    "end": "116160"
  },
  {
    "text": "Um, we've set back research by about four hours.\nbut I wanted to—you've been up with that, with  ",
    "start": "116160",
    "end": "125800"
  },
  {
    "text": "IBM, for 20— \nDario: Years. Twenty years this summer.  Malcolm: So—and how old were you when you—not \nto give away your age, but you were how old  ",
    "start": "125800",
    "end": "132040"
  },
  {
    "text": "when you started?\nDario: I was 28.  Malcolm: Okay. So I want to go \nback to your 28-year-old self. Now,  ",
    "start": "132040",
    "end": "137680"
  },
  {
    "text": "if I asked you about artificial intelligence, \nI asked 28-year-old Darío, “What does the  ",
    "start": "137680",
    "end": "143560"
  },
  {
    "text": "future hold for AI? How quickly will this new \ntechnology transform our world?” et cetera,  ",
    "start": "143560",
    "end": "149880"
  },
  {
    "text": "et cetera, what would 28-year-old Darío have said?\nDario: Well, I think the first thing is that even   though AI as a field has been with us for a \nlong time—since the mid-1950s—at that time,  ",
    "start": "149880",
    "end": "160840"
  },
  {
    "text": "“AI” was not a very polite word to say, \nmeaning within the scientific community. ",
    "start": "160840",
    "end": "166519"
  },
  {
    "text": "People didn't use, sort of, that term. They \nwould have said things like, you know, maybe, “I   do things related to machine learning,” right? Or \n“statistical techniques, in terms of classifiers,”  ",
    "start": "166520",
    "end": "175480"
  },
  {
    "text": "and so on. But AI had a mixed reputation, right? \nIt had gone through different cycles of hype and,  ",
    "start": "175480",
    "end": "182640"
  },
  {
    "text": "it's also had moments of a lot of negativity \ntowards it because of lack of success. ",
    "start": "182640",
    "end": "189600"
  },
  {
    "text": "Um—and so I think that that will be the first \nthing. We'd probably say, like, AI is like— what   is that? Like, you know, respectable scientists \nare not working on AI defined as such. And that  ",
    "start": "189600",
    "end": "199720"
  },
  {
    "text": "really changed over the last 15 years only, right? \nI would say with the advent of deep learning,   over the last decade, is when that reentered \nagain the lexicon of saying “AI,” and that  ",
    "start": "199720",
    "end": "209439"
  },
  {
    "text": "that was a legitimate thing, to work on.\nSo I would say that that's the first thing—I   think we would have noticed a \ncontrast 20 years ago. Yeah.",
    "start": "209440",
    "end": "216020"
  },
  {
    "text": "Malcolm: So at what point in your 20-year \ntenure at IBM would you say you kind of  ",
    "start": "216020",
    "end": "222160"
  },
  {
    "text": "snapped into the present kind of “wow” mode?\nDario: I would say, in, maybe the late 2000s.  ",
    "start": "222160",
    "end": "233520"
  },
  {
    "text": "When IBM was working on the Jeopardy! project, \nand just seeing the demonstrations of what could  ",
    "start": "233520",
    "end": "242680"
  },
  {
    "text": "be done in question- answering; it—\nMalcolm: Literally, Jeopardy! is this   crucial moment in the history of AI.\nDario: You know, there had been a long  ",
    "start": "242680",
    "end": "250520"
  },
  {
    "text": "and wonderful history, inside IBM on \nAI. So, for example, in terms of, like,  ",
    "start": "250520",
    "end": "256840"
  },
  {
    "text": "these grand challenges at the very \nbeginning of the field’s founding,   which is this famous Dartmouth conference \nthat, actually, IBM sponsored, to create,  ",
    "start": "256840",
    "end": "266000"
  },
  {
    "text": "there was an IBMer there called Nathaniel \nRochester, and there were a few others who,  ",
    "start": "266000",
    "end": "272360"
  },
  {
    "text": "right after that—they started thinking \nabout demonstrations of this field.  And then, for example, they created the first, \ngame to play checkers and to demonstrate that you  ",
    "start": "272360",
    "end": "281360"
  },
  {
    "text": "could do machine learning on that. Obviously, we \nsaw later in the ’90s, like chess, that was a very  ",
    "start": "281360",
    "end": "287520"
  },
  {
    "text": "famous example of that. That was Deep Blue. With \nDeep Blue, right? And, playing with Kasparov. ",
    "start": "287520",
    "end": "292639"
  },
  {
    "text": "And then—but I think the moment that \nwas really—those other ones felt like,   kind of like brute force, anticipating sort of \nlike moves ahead. But this aspect of dealing with  ",
    "start": "292640",
    "end": "300840"
  },
  {
    "text": "language and question-answering felt different. \nAnd I think for us internally and many others,  ",
    "start": "300840",
    "end": "307199"
  },
  {
    "text": "was when—a moment of saying like, wow, \nyou know, what are the possibilities here?  And then soon after that, connected to the sort of \nadvancements in computing and with deep learning,  ",
    "start": "307200",
    "end": "316840"
  },
  {
    "text": "the last decade has just been an all-out, \nyou know, sort of like front of advancements,   and that—and I just continue to be \nmore and more impressed. And the last  ",
    "start": "316840",
    "end": "323919"
  },
  {
    "text": "few years have been remarkable, too. Yeah. Malcolm: I'm going to ask you three quick conceptual questions before we dig into it. Just so I sort of get a—we all get a  ",
    "start": "323920",
    "end": "332960"
  },
  {
    "text": "feel for the shape of AI. Question number one \nis, where are we in the evolution of this? So,  ",
    "start": "332960",
    "end": "343039"
  },
  {
    "text": "the obvious que—we, we all suddenly are aware \nof it, we're talking about it. What—can you give   us an analogy about where we are in the kind \nof likely evolution of this as a Technology?",
    "start": "344080",
    "end": "354440"
  },
  {
    "text": "Dario: So I think we're on a significant \ninflection point. That, it feels like  ",
    "start": "354440",
    "end": "359800"
  },
  {
    "text": "the equivalent of the first browsers when they \nappeared, and people imagined the possibilities  ",
    "start": "359800",
    "end": "366319"
  },
  {
    "text": "of the internet—or more, imagined experiencing \nthe internet. The internet had been around,  ",
    "start": "366320",
    "end": "371400"
  },
  {
    "text": "right, for quite a few decades. AI \nhas been around for many decades.  I think the moment we find ourselves in is \nthat people can touch it, and they can— before,  ",
    "start": "371400",
    "end": "379800"
  },
  {
    "text": "there were AI systems that were like behind \nthe scenes, like your search results,   or translation systems. But they didn't have the \nexperience of like, this is what it feels like to  ",
    "start": "379800",
    "end": "388320"
  },
  {
    "text": "interact with this thing. So, that's what I mean.\nI think maybe that analogy of the browser is   appropriate because it's—all of a \nsudden it's like, whoa, you know,  ",
    "start": "388320",
    "end": "395680"
  },
  {
    "text": "there's this network of machines, and content can \nbe distributed, and everybody can self-publish.  ",
    "start": "395680",
    "end": "401039"
  },
  {
    "text": "And there was a moment that—we all remember \nthat. And I think that that is what the world   has experienced over the last nine months.\nSo, and—but fundamentally, also what is  ",
    "start": "401040",
    "end": "410080"
  },
  {
    "text": "important is that this moment is where the ease \nof—the number of people that can build and use AI  ",
    "start": "410080",
    "end": "416360"
  },
  {
    "text": "has skyrocketed. So over the last decade, \ntechnology firms that had large research  ",
    "start": "416360",
    "end": "423560"
  },
  {
    "text": "teams could build AI that worked really well, \nhonestly. But when you went down into, say, hey,  ",
    "start": "423560",
    "end": "429800"
  },
  {
    "text": "can everybody use it? Can a data-science team in \na bank, go and develop these applications? And it  ",
    "start": "429800",
    "end": "435199"
  },
  {
    "text": "was like more complicated. Some could do it, but \nit was more—the barrier of entry was high. Now   it's very different because of foundation \nmodels and the implications that that has— ",
    "start": "435200",
    "end": "444080"
  },
  {
    "text": "Malcolm: With the moment \nwhere the technology is being—  Dario: Democratized. Being democratized. Frankly, \nit works better, for classes of problems,  ",
    "start": "444080",
    "end": "452560"
  },
  {
    "text": "like programming and other things. It’s \nreally incredibly impressive what it can do.  So the accuracy and the performance of it is much \nbetter. Yeah. And the ease of use and the number  ",
    "start": "452560",
    "end": "460960"
  },
  {
    "text": "of use cases we can pursue is much bigger. \nSo that democratization is a big difference.  Malcolm: You say, when you make an analogy \nto the first browsers—if you, if we—to do  ",
    "start": "460960",
    "end": "470360"
  },
  {
    "text": "another one of these time-travel questions, \nback at the beginning of the first browsers, it's safe to say, many of the potential \nuses of the internet and such—we hadn't  ",
    "start": "470360",
    "end": "480360"
  },
  {
    "text": "even begun, we couldn't even anticipate.\nDario: Right. Right. Malcolm: Exactly. So we're at the point where the future direction is largely unpredictable.",
    "start": "480360",
    "end": "486957"
  },
  {
    "text": "Dario: Yes. Yeah, I think that is right, because it's such a horizontal technology that— \nthe intersection of the horizontal capability,  ",
    "start": "486957",
    "end": "494360"
  },
  {
    "text": "which is about expanding our productivity \non tasks that we wouldn't be able to do  ",
    "start": "494360",
    "end": "499439"
  },
  {
    "text": "efficiently without it—it has to marry, the \nuse cases that reflect the diversity of human  ",
    "start": "499440",
    "end": "504600"
  },
  {
    "text": "experience and institutional diversity.\nSo as more and more institutions said,   you know, I'm focused on agriculture, \nyou know, to be able to improve seeds,  ",
    "start": "504600",
    "end": "511880"
  },
  {
    "text": "in these kinds of environments, they'll find \ntheir own context in which—that—matters that   the creators of AI did not anticipate at \nthe beginning. So I think that that is,  ",
    "start": "513080",
    "end": "521200"
  },
  {
    "text": "then—the fruit of surprises will be like, why, we \ndidn't even think that it could be used for that.  And also, clever people will create new \nbusiness models associated with that. Like,  ",
    "start": "521200",
    "end": "530040"
  },
  {
    "text": "it happened with the internet, of course, as well, \nand that will be its own source of transformation  ",
    "start": "530040",
    "end": "535240"
  },
  {
    "text": "and change in its own right. So I think all \nof that is yet to unfold, right? What we're   seeing is this catalyst moment of technology that \nworks well enough, and it can be democratized. ",
    "start": "535240",
    "end": "543639"
  },
  {
    "text": "Malcolm: Yeah. The next sort of conceptual \nquestion: you know, we could loosely understand  ",
    "start": "543640",
    "end": "549720"
  },
  {
    "text": "or categorize innovations, in terms of their \nimpact on the kind of, balance of power between  ",
    "start": "549720",
    "end": "558800"
  },
  {
    "text": "haves and have-nots. Mm-hmm? Some innovations, \nyou know, obviously, uh, favor those who already  ",
    "start": "558800",
    "end": "564560"
  },
  {
    "text": "have a—make the rich richer. Some—the—some, \nit's a rising tide that lifts all boats,  ",
    "start": "564560",
    "end": "570360"
  },
  {
    "text": "and some are biased in the other direction.\nThey close the gap between. Is it possible  ",
    "start": "570360",
    "end": "576680"
  },
  {
    "text": "to say, to predict, which of those \nthree categories AI might fall into?  Dario: It's a great question. A first, observation \nI would make on your first two categories is that  ",
    "start": "576680",
    "end": "590000"
  },
  {
    "text": "it will be—both likely be true that the use of AI \nwill be highly democratized, meaning the number  ",
    "start": "590000",
    "end": "595840"
  },
  {
    "text": "of people that have access to its power to make \nimprovements in terms of efficiency and so on   will be fairly universal, and that the ones who \nare able to create AI, may be quite concentrated.",
    "start": "595840",
    "end": "609680"
  },
  {
    "text": "So if you look at it from the lens of who \ncreates wealth and value over sustained  ",
    "start": "609680",
    "end": "615720"
  },
  {
    "text": "periods of time—particularly, say, in a \ncontext like business—I think just being  ",
    "start": "615720",
    "end": "620759"
  },
  {
    "text": "a user of AI technology is an insufficient \nstrategy. And the reason for that is, like,  ",
    "start": "620760",
    "end": "627160"
  },
  {
    "text": "yes, you will get the immediate productivity \nboost of, like, just making API calls and,   that will be a new baseline for everybody. \nBut you're not accruing value in terms of  ",
    "start": "627160",
    "end": "636920"
  },
  {
    "text": "representing your data inside the AI in a \nway that gives you a sustainable competitive   advantage. So what I always try to tell people \nis, don't just be an AI user; be an AI value  ",
    "start": "636920",
    "end": "646839"
  },
  {
    "text": "creator. And I think that that will have a lot of \nconsequences in terms of the haves and have-nots,  ",
    "start": "646840",
    "end": "653400"
  },
  {
    "text": "as an example, and that will apply both to \ninstitutions and regions and countries, etc. ",
    "start": "653400",
    "end": "658640"
  },
  {
    "text": "So I think it would be kind \nof a mistake, right, to just   develop strategies that are just about usage.\nMalcolm: Yeah. But to come back to that question  ",
    "start": "658640",
    "end": "667960"
  },
  {
    "text": "for a moment, to give you a specific— suppose \nI'm a, I'm an industrial farmer in Iowa with 10  ",
    "start": "667960",
    "end": "675720"
  },
  {
    "text": "million in equipment, and blah, blah, blah. And \nI'm comparing it to a subsistence farmer, someone  ",
    "start": "675720",
    "end": "681079"
  },
  {
    "text": "in the developing world, who's got a cell phone,\nright. Over the next five years, whose,  ",
    "start": "681080",
    "end": "687760"
  },
  {
    "text": "whose well-being rises by a greater amount?\nDario: Yeah, I think, it's a good question,  ",
    "start": "687760",
    "end": "694960"
  },
  {
    "text": "but it might be hard to do a one-to-one sort of \nlike attribution to just one variable in this   case, which is AI. But again, provided \nthat you have access to a phone, right,  ",
    "start": "694960",
    "end": "705520"
  },
  {
    "text": "and some way to be able to be connected.\nI do think—so for example, in that context,  ",
    "start": "705520",
    "end": "711040"
  },
  {
    "text": "we've developed, we've done work with NASA, \nas an example, to build geospatial models,   using some of these new techniques. And \nI think, for example, our ability to do  ",
    "start": "711040",
    "end": "720040"
  },
  {
    "text": "flood prediction—I'll tell you an advantage of why \nwe'll be a democratization force in that context. ",
    "start": "720040",
    "end": "725160"
  },
  {
    "text": "Before, to build a flood model based on \nsatellite imagery was actually so onerous  ",
    "start": "725160",
    "end": "731079"
  },
  {
    "text": "and so complicated and difficult that you would \njust target to very specific regions. And then,   obviously, countries prioritize their \nown, right? But what we've demonstrated  ",
    "start": "731080",
    "end": "739120"
  },
  {
    "text": "is actually you can extend that technique \nto have like global coverage around that.  So in that context, I would say it's \na force towards democratization—that  ",
    "start": "739120",
    "end": "746080"
  },
  {
    "text": "everybody sort of would have access \nif you have some kind of connectivity. Malcolm: That Iowa farmer might have a flood \nmodel. The guy in the developing world definitely  ",
    "start": "746080",
    "end": "754720"
  },
  {
    "text": "didn't, and now he's got a shot at getting one.\nDario: Yeah, but now he has a shot at getting one.  So there's aspects of it that—so long as we \nprovide connectivity and access to it—that  ",
    "start": "754720",
    "end": "762240"
  },
  {
    "text": "there can be democratization forces. But I'll \ngive you another example that, that can be quite   concerning, which is language, right? So there's \nso much language, in English. And there is sort  ",
    "start": "762240",
    "end": "774720"
  },
  {
    "text": "of like this reinforcement loop that happens, \nthat the more you concentrate—because it has   obvious benefits for global communication \nand standardization—the more you can enrich  ",
    "start": "774720",
    "end": "783279"
  },
  {
    "text": "like base AI models based on that capability.\nIf you have very resource-scarce languages,  ",
    "start": "783280",
    "end": "789320"
  },
  {
    "text": "you tend to develop less powerful AI \nwith those languages, and so on. So one  ",
    "start": "789320",
    "end": "794400"
  },
  {
    "text": "has to actually worry and, and focus on the \nability to actually represent, in that case,  ",
    "start": "794400",
    "end": "801800"
  },
  {
    "text": "language is a piece of culture also in the AI \nsuch that everybody can benefit from it too. ",
    "start": "801800",
    "end": "807360"
  },
  {
    "text": "So there's a lot of considerations \nin terms of equity about the data,   the data sets that we accrue, and what problems \nare we trying to solve. I mean, you mentioned  ",
    "start": "807360",
    "end": "816399"
  },
  {
    "text": "agriculture or healthcare and so on. If we only \nsolve problems that are related to marketing,   as an example, that would be a less rich world in \nterms of opportunity than if we incorporate many,  ",
    "start": "816400",
    "end": "826240"
  },
  {
    "text": "many other broader sets of problems.\nMalcolm: Yeah. Who do you think—what do   you think are the biggest impediments to the \nadoption of, of AI as you would like—as you  ",
    "start": "826240",
    "end": "836800"
  },
  {
    "text": "think AI ought to be adopted? I mean, if you would \nlook, what are the sticking points that you would—  Dario: Look, in the end, I'm going to \ngive a nontechnological answer. The  ",
    "start": "836800",
    "end": "845080"
  },
  {
    "text": "first one has to do with workflow, right?\nSo even if the technology is very capable,  ",
    "start": "845080",
    "end": "851000"
  },
  {
    "text": "the organizational change inside a company, to \nincorporate into the natural workflow of people on  ",
    "start": "851000",
    "end": "856080"
  },
  {
    "text": "how we work, is—it's a lesson we have learned over \nthe last decade is hugely important. Mm-hmm? So  ",
    "start": "856080",
    "end": "862240"
  },
  {
    "text": "there's a lot of design considerations. There's \na lot of, how do people want to work, right? ",
    "start": "862240",
    "end": "868320"
  },
  {
    "text": "How do they work today? And what is the \nnatural entry point for AI? So that's   like number one. And then the second \none is, you know—for the broad, uh,  ",
    "start": "868320",
    "end": "877080"
  },
  {
    "text": "value-creation aspect of it—is the understanding \ninside the companies of how you have to curate and",
    "start": "877080",
    "end": "884280"
  },
  {
    "text": "create data, to combine it with external \ndata such that you can have powerful   AI models that actually fit your needs.\nAnd that aspect of what it takes to actually  ",
    "start": "884280",
    "end": "895000"
  },
  {
    "text": "create and curate the data for this modern AI—um, \nit's still a work in progress, right? I think part  ",
    "start": "895000",
    "end": "902280"
  },
  {
    "text": "of the problem that happens very often when I talk \nto institutions is that they say, “AI, yeah, yeah,   yeah, I'm doing it, I've been doing it for a long \ntime.” And the reality is that that answer can  ",
    "start": "902280",
    "end": "912480"
  },
  {
    "text": "sometimes be a little bit of a cop-out, right?\nI know you were doing machine learning. You were   doing some of these things, but actually the \nlatest version of AI, or what's happened with  ",
    "start": "912480",
    "end": "921280"
  },
  {
    "text": "foundation models—not only is it very new, it's \nvery hard to do. And honestly, if you haven't  ",
    "start": "921280",
    "end": "927400"
  },
  {
    "text": "been, assembling very large teams and spending \nhundreds of millions of dollars of compute—in sum,   you're probably not doing it right. You're doing \nsomething else that is in the broad category. And  ",
    "start": "927400",
    "end": "937280"
  },
  {
    "text": "I think the lessons about what it means to make \nthis transition to this new wave is still in early  ",
    "start": "937280",
    "end": "942400"
  },
  {
    "text": "phases of understanding. \nMalcolm: So what would you say? I want to give you a couple of   examples of people in real-world \npositions of responsibility. ",
    "start": "942400",
    "end": "951200"
  },
  {
    "text": "Imagine I'm sitting right here. So imagine \nthat I am the President of a small liberal   arts college. And I come to you and I say, \nDarío, I keep hearing about AI. My college  ",
    "start": "951200",
    "end": "960840"
  },
  {
    "text": "has— I'm making this much money. If—that \nevery year, my enrollment's declining,  ",
    "start": "960840",
    "end": "969440"
  },
  {
    "text": "I feel like this maybe is an opportunity. What \nis the opportunity for me? What would you say? ",
    "start": "969440",
    "end": "975160"
  },
  {
    "text": "Dario: So it's probably in a couple of segments \naround that, right? All one has to do is, well,  ",
    "start": "975160",
    "end": "981360"
  },
  {
    "text": "what is the implications of this technology inside \nthe institution itself, inside of the college,  ",
    "start": "981360",
    "end": "986920"
  },
  {
    "text": "and how we operate? And, can we improve, for \nexample, efficiency? Like if you're having   very low levels of, of sort of margin to be \nable to reinvest, is, you know, you run IT,  ",
    "start": "986920",
    "end": "998720"
  },
  {
    "text": "you run, infrastructure, you run many things \ninside the college. What are the opportunities  ",
    "start": "998720",
    "end": "1003920"
  },
  {
    "text": "to increase the productivity or automate and drive \nsavings such that you can reinvest that money into  ",
    "start": "1003920",
    "end": "1009760"
  },
  {
    "text": "the mission of education, right?—as an example.\nMalcolm: So number one is operational efficiency.  Dario: Operational efficiency, is a big one. I \nthink the second one is: within the context of  ",
    "start": "1009760",
    "end": "1018040"
  },
  {
    "text": "the college, there's implications for the \neducational mission in its own right. How will—how does a curriculum need to \nevolve, or not? What are acceptable  ",
    "start": "1018040",
    "end": "1026480"
  },
  {
    "text": "use policies for some of these AI?\nI don't think—we've all read a lot   about like what can happen in terms of exams \nand, and so on, and cheating and not cheating,  ",
    "start": "1026480",
    "end": "1033839"
  },
  {
    "text": "or what—are they actually positive elements \nof it in terms of how curriculum should be   developed? And professions? Sustain around \nthat. And then there's another, third,  ",
    "start": "1033840",
    "end": "1041559"
  },
  {
    "text": "dimension which is the outward-oriented element \nof it, which is like prospective students, right?  So, which is, frankly speaking, a big \nuse case that is happening right now,  ",
    "start": "1041560",
    "end": "1049920"
  },
  {
    "text": "which in the broader industry is called “customer \ncare” or “client care” or “citizen care.” So—and   this question will be— education. Like, you \nknow, “Hey, are you reaching the right students?”  ",
    "start": "1049920",
    "end": "1058399"
  },
  {
    "text": "Around that—that may apply to the college.\nHow can you create for them, for example,   an environment to interact with the college, and \nanswering questions? That could be a chatbot,  ",
    "start": "1058400",
    "end": "1066120"
  },
  {
    "text": "or something like that, to learn about it. And \npersonalization. So I would say there's, like,   at least three lenses with which \nI would give advice, right? The— ",
    "start": "1066120",
    "end": "1073640"
  },
  {
    "text": "Malcolm: The second, let's pause on the second \none though, because it's really interesting.  So I really can't assign an essay anymore, can I? \nDario: Can I assign an essay?",
    "start": "1073640",
    "end": "1083640"
  },
  {
    "text": "Malcolm: Can I say, “Write me a research paper and come back to me in three weeks?” Can I do that anymore? ",
    "start": "1083640",
    "end": "1088820"
  },
  {
    "text": "Dario: I think you can. \nMalcolm: How do I do that? Dario: I think you can. Look, this—so there's two questions around that. I think that if one goes and explains in the context,  ",
    "start": "1088820",
    "end": "1099120"
  },
  {
    "text": "like, “What is it? Why are we here? Why are we \nin this class? What is the purpose of this?” And,   one starts with assuming, like an element of, \nlike, decency in people, or people are there,  ",
    "start": "1099120",
    "end": "1108520"
  },
  {
    "text": "like, to learn, and so on, and you just give \na disclaimer: “Look, I know that one option   you have is, like, just, put the essay question \nand click ‘Go,’ and, like, and give an answer,  ",
    "start": "1108520",
    "end": "1117520"
  },
  {
    "text": "you know? But that is not why we’re here, and that \nis not the intent of what we’re trying to do.”  So first I would start with the—sort of \nlike the norms of intent and decency,  ",
    "start": "1117520",
    "end": "1127320"
  },
  {
    "text": "and appeal to those, as step number one. Then we \nall know that there will be a distribution of use",
    "start": "1127320",
    "end": "1132799"
  },
  {
    "text": "cases—that people like that will come in \none ear and come out of the other and do   that. And,—so for a subset of that, I think the \ntechnology is going to evolve in such a way that,  ",
    "start": "1132800",
    "end": "1142600"
  },
  {
    "text": "we will have more and more of the ability to \ndiscern—right?—you know when that has been   AI generated, right? And, created. It won't be \nperfect, right? But there's some elements that  ",
    "start": "1142600",
    "end": "1152440"
  },
  {
    "text": "you can—imagine inputting the essay, and you \nsay, “Hey, this is like—it— .” And for example,  ",
    "start": "1152440",
    "end": "1158320"
  },
  {
    "text": "one way you can do that, just to give you \nan intuition, you could just have an essay,   uh, that you write with pencil and paper at the \nbeginning. You get a baseline of what your writing  ",
    "start": "1158320",
    "end": "1166680"
  },
  {
    "text": "is like. And then later, when you, generate it, \nthere'll be obvious differences around what kind  ",
    "start": "1166680",
    "end": "1173000"
  },
  {
    "text": "of writing has been generated from the other.\nMalcolm: Yeah, but you've turned—it's—everything   you're describing makes sense, but it greatly—in \nthis, in this respect, at least, it seems to  ",
    "start": "1173000",
    "end": "1182440"
  },
  {
    "text": "greatly complicate the life of the teacher. \nWhereas the other two use cases seem to kind of  ",
    "start": "1182440",
    "end": "1187600"
  },
  {
    "text": "clarify and simplify the role, right? Suddenly, \nreaching students, prospective students, sounds  ",
    "start": "1187600",
    "end": "1195480"
  },
  {
    "text": "like I can do that much more kind of efficiently.\nYeah, I can bring down administration costs,   but the teaching thing is tricky.\nDario: Well, until we develop the new norms,  ",
    "start": "1195480",
    "end": "1205600"
  },
  {
    "text": "right? I know it's an abused analogy, but \ncalculators—we deal, we dealt with that too,  ",
    "start": "1205600",
    "end": "1210720"
  },
  {
    "text": "right? And, it says, “Well—calculator. What \nis the purpose of math? How are we going to   do this?” and so on.\nAnd we have— ",
    "start": "1210720",
    "end": "1216200"
  },
  {
    "text": "Malcolm: Can I tell you my dad's calculator story? \nDario: Yes, please.  Malcolm: My father was a mathematician. \nTaught mathematics at the University of  ",
    "start": "1216200",
    "end": "1222200"
  },
  {
    "text": "Waterloo in Canada. And in the ’70s, when \npeople started to get pocket calculators,  ",
    "start": "1222200",
    "end": "1227360"
  },
  {
    "text": "his students demanded that they be able \nto use them. And he said no, and he—they   took him to the administration and he lost.\nSo he then changed. Completely threw out all  ",
    "start": "1227360",
    "end": "1237799"
  },
  {
    "text": "of his old exams. Introduced new exams, where \nthere was no calculation. It was all like,  ",
    "start": "1237800",
    "end": "1244800"
  },
  {
    "text": "“deep think,” you know. Figure out the problem \non a conceptual level and describe it to me. And  ",
    "start": "1244800",
    "end": "1249840"
  },
  {
    "text": "they were all—students deeply unhappy that \nhe had made their lives more complicated. Dario: But it's to your point. \nThat's the point. To your— ",
    "start": "1249840",
    "end": "1256240"
  },
  {
    "text": "Malcolm: Point. Right. The result was probably \na better education. Right. He just removed the  ",
    "start": "1256240",
    "end": "1262600"
  },
  {
    "text": "element that they could gain with their pocket \ncalculators. I suppose it's a version of that.  Dario: I think it's a version of that. \nAnd so I think they will develop the  ",
    "start": "1262600",
    "end": "1269280"
  },
  {
    "text": "equivalent of what your father did.\nAnd I think people say, you know what,   it's like—these kinds of things, everybody's doing \nit generically and none of it has any meaning  ",
    "start": "1269280",
    "end": "1275760"
  },
  {
    "text": "because all you're doing is pressing buttons. And \nlike the intent of this was something which was to   teach you how to write or to think or something. \nThere may be a variant of how we do all of this. ",
    "start": "1275760",
    "end": "1283800"
  },
  {
    "text": "I mean, obviously some version of that that \nhas happened is like, okay, we're all going   to sit down and do it with pencil and paper and \nno computers in the classroom, but there'll be  ",
    "start": "1283800",
    "end": "1290720"
  },
  {
    "text": "other variants of creativity that people will \nput forth to say, you know what? You know,   that's a way to solve that problem too.\nMalcolm: But this is interesting,  ",
    "start": "1290720",
    "end": "1297600"
  },
  {
    "text": "because—to stay on this analogy—we're \nreally talking about a profound rethinking,  ",
    "start": "1297600",
    "end": "1303799"
  },
  {
    "text": "just—using a college as an example. A real \nprofound rethinking of the way—there's no  ",
    "start": "1303800",
    "end": "1310400"
  },
  {
    "text": "part of this college that's unaffected by AI, (a). \n(B), in one case, I've made everyone's job easier;  ",
    "start": "1310400",
    "end": "1317400"
  },
  {
    "text": "in one case I've made—I'm asking us to really \nrethink from the ground up what “teaching” means. ",
    "start": "1317400",
    "end": "1323920"
  },
  {
    "text": "In another case, I've automated systems \nthat I didn't think of. I mean, it's like,   that's right. That's all—it's not all—that's \na lot to ask someone who got a PhD in medieval  ",
    "start": "1323920",
    "end": "1332559"
  },
  {
    "text": "language and literature, 40 years ago.\nDario: Yeah, but you know, I'll tell   you a positive sort of development that I'm \nseeing. The sciences around this, which is,  ",
    "start": "1332560",
    "end": "1341000"
  },
  {
    "text": "you're seeing—as you see more and more examples \nof applying AI technology within the context  ",
    "start": "1341000",
    "end": "1347440"
  },
  {
    "text": "of like historians too as an example, right?\nWhen you have archival and—you know, and you have   all these books, and being able to actually help \nyou as an assistant, right, around that. But not  ",
    "start": "1347440",
    "end": "1356920"
  },
  {
    "text": "only with text now, but with diagrams, right? And, \nuh, I've seen it in anthropology too, right? And,  ",
    "start": "1356920",
    "end": "1362660"
  },
  {
    "text": "uh, in archaeology, with examples of engravings \nand translations and things. That can happen.",
    "start": "1362660",
    "end": "1367880"
  },
  {
    "text": "So, as you see in diverse fields, people \napplying these techniques to advance on how  ",
    "start": "1367880",
    "end": "1373080"
  },
  {
    "text": "to do physics or how to do chemistry. They \ninspire each other, right? And they say,   how does it apply, to my area? So once, as that \nhappens, it becomes less of a chore of like,  ",
    "start": "1373080",
    "end": "1383640"
  },
  {
    "text": "my God, how do I have to deal with this?\nBut actually, it's triggered by curiosity.   It's triggered by—you know, there'll be \nlike, you know, faculty that'll be like,  ",
    "start": "1383640",
    "end": "1391600"
  },
  {
    "text": "you know what, you know, “Let me explore \nwhat this means for my area.” And they will   adapt it to the local context—to the local, \nyou know, uh, language, and the profession  ",
    "start": "1391600",
    "end": "1399720"
  },
  {
    "text": "itself. So I see that as a positive vector.\nThat is not all going to feel like homework,  ",
    "start": "1399720",
    "end": "1405200"
  },
  {
    "text": "you know? It's not going to feel like, “Oh my \nGod, this is so overwhelming,” but rather to   be very practical, to see what works. What \nhave I seen others do that is inspiring?  ",
    "start": "1405200",
    "end": "1413160"
  },
  {
    "text": "And what am I inspired to do? You know, what— \nwhat is—how is this going to help my career?  I think that that's going to be an interesting \nquestion for, for, you know, those faculty  ",
    "start": "1413160",
    "end": "1420840"
  },
  {
    "text": "members, for the students and professionals.\nMalcolm: Sorry, I'm gonna stick with this example   alone, because it's really interesting. I'm \ncurious—following up on what you just said—that  ",
    "start": "1420840",
    "end": "1428760"
  },
  {
    "text": "one of the most persistent critiques of academia, \nbut also of many, of many corporate institutions,  ",
    "start": "1428760",
    "end": "1436280"
  },
  {
    "text": "um, in recent years has been “siloing,” right?\nDifferent parts of the, of the organization going  ",
    "start": "1436280",
    "end": "1442960"
  },
  {
    "text": "off on their own and not speaking to each other \nis a potent—is, is a real potential benefit to AI:  ",
    "start": "1442960",
    "end": "1451399"
  },
  {
    "text": "the kind of breaking down—a simple \ntool for breaking down those kinds   of barriers. Is that a very, is that an \nelegant way of sort of summing that up? ",
    "start": "1451400",
    "end": "1459640"
  },
  {
    "text": "Dario: I really think—and I was actually \njust having a conversation with a provost   very much on this topic very recently, exactly \non that, which is: all these, this appetite,  ",
    "start": "1459640",
    "end": "1469760"
  },
  {
    "text": "right? To collaborate across disciplines.\nThere's a lot of, attempts towards our goal,   right? Creating interdisciplinary centers, \ncreating dual-degree programs or dual-appointment  ",
    "start": "1469760",
    "end": "1478960"
  },
  {
    "text": "programs. But actually, in—a lot of progress in \nacademia, happens by methodology too. Right? Like  ",
    "start": "1478960",
    "end": "1485840"
  },
  {
    "text": "a new, when some methodology gets adopted—I mean, \nthe most famous example of that is the scientific",
    "start": "1485840",
    "end": "1491679"
  },
  {
    "text": "method, as an example of that—but when \nyou have a methodology that gets adopted,   it also provides a way to speak to your \ncolleagues across different disciplines. ",
    "start": "1491680",
    "end": "1500920"
  },
  {
    "text": "And I think what's happening in AI is, is linked \nto that. That within the context of the scientific  ",
    "start": "1500920",
    "end": "1506080"
  },
  {
    "text": "method, as an example, the methodology about which \nwe, about which we do discovery—the role of data,  ",
    "start": "1506080",
    "end": "1513640"
  },
  {
    "text": "the role of these neural networks, of how we \nactually find proximity of concepts to one   another—it's actually fundamentally different \nthan how we've traditionally applied it. ",
    "start": "1513640",
    "end": "1523760"
  },
  {
    "text": "So, as we see across more professions, people \napplying this methodology is also going to give  ",
    "start": "1523760",
    "end": "1529440"
  },
  {
    "text": "some element of common language to each other, \nright? And in fact, in this very high-dimensional  ",
    "start": "1529440",
    "end": "1535559"
  },
  {
    "text": "representation of information that is present in \nneural networks, we may find amazing adjacencies  ",
    "start": "1535560",
    "end": "1541360"
  },
  {
    "text": "or connections of themes and topics in ways that \nthe individual practitioners cannot describe, but  ",
    "start": "1541360",
    "end": "1547640"
  },
  {
    "text": "yet will be latent in these large neural networks.\nWe are going to suffer a little bit from  ",
    "start": "1547640",
    "end": "1552960"
  },
  {
    "text": "causality—from the problem of like, “Hey, \nwhat's the root cause of that?” Because I   think one of the unsatisfying aspects that \nthis methodology will provide is they may  ",
    "start": "1552960",
    "end": "1562400"
  },
  {
    "text": "give you answers for which they don't give you \ngood reasons for where the answers came from. ",
    "start": "1562400",
    "end": "1567800"
  },
  {
    "text": "And then there will be the traditional process \nof discovery, of saying, if that is the answer,   what are the reasons? So we're gonna \nhave to do this sort of hybrid, uh,  ",
    "start": "1567800",
    "end": "1576720"
  },
  {
    "text": "way of understanding the world. But I do think \nthat common layer of AI is a powerful new thing. ",
    "start": "1576720",
    "end": "1582559"
  },
  {
    "text": "Malcolm: Yeah. A couple of random \nquestions that come to mind as you talk.  In the, in the writer's strike that just ended in \nHollywood, one of the sticking points was how the  ",
    "start": "1582560",
    "end": "1592040"
  },
  {
    "text": "studios and writers would treat AI-generated \ncontent—would writers get credit if their  ",
    "start": "1592040",
    "end": "1598520"
  },
  {
    "text": "material was somehow the source for AI? But more \nbroadly, did the writers need protections against  ",
    "start": "1598520",
    "end": "1605160"
  },
  {
    "text": "the use of—. I could go on. You know what? \nYou probably were familiar with all of this.  Had you been—I don't know whether you were, \nbut had either side called you in for advice  ",
    "start": "1605160",
    "end": "1614360"
  },
  {
    "text": "during that? The writers, had the writers \ncalled you and said “Dario, what should we do about AI? And how should we—that \nshould be reflected in our contract  ",
    "start": "1614360",
    "end": "1624240"
  },
  {
    "text": "negotiations?” What would you have told them?\nDario: I—the way I think about that is that  ",
    "start": "1624240",
    "end": "1629559"
  },
  {
    "text": "I divide it—I would divide it into two parts. \nPieces. First is: what's technically possible,   right? And anticipate scenarios, like, what \ncan you do with voice cloning? For example,  ",
    "start": "1629560",
    "end": "1640720"
  },
  {
    "text": "it is possible there's been, um, dubbing, \nright? Like—let's just take that topic,   right? Around the world, there was all these, \nfolks that would dub people in other languages. ",
    "start": "1640720",
    "end": "1650360"
  },
  {
    "text": "Well, now you can do these incredible renderings; \nI mean, I don't know if you've seen them, where,   you know, you match the lips—it's your original \nvoice, but speaking any language that you want.  ",
    "start": "1650360",
    "end": "1659440"
  },
  {
    "text": "That's the thing. So basically that has a \nset of implications around that. I mean,   just to give an example. So I would say: create \na taxonomy, that describes technical capabilities  ",
    "start": "1659440",
    "end": "1668080"
  },
  {
    "text": "that we know of today and, uh, applications to the \nindustry and to examples of like, “Hey, I could  ",
    "start": "1668080",
    "end": "1674399"
  },
  {
    "text": "film you for five minutes and I could generate \ntwo hours of content of you and I don't have to,   you know—then if you'll get paid by the hour, \nobviously I'm not paying you for the other thing.” ",
    "start": "1674400",
    "end": "1682040"
  },
  {
    "text": "So I would say “technological capability,” and \nthen map with their expertise consequences of  ",
    "start": "1682040",
    "end": "1687240"
  },
  {
    "text": "how it changes the way they work, or the way \nthey interact, or the way they negotiate,   and so on. So that would be one element of it.\nAnd then the other one is like a  ",
    "start": "1687240",
    "end": "1695120"
  },
  {
    "text": "non-technology-related matter, which is an element \nof—almost of distributive justice. It's like,   who deserves what? Right? And who has the power \nto get what? And, and then that's a completely  ",
    "start": "1695120",
    "end": "1705000"
  },
  {
    "text": "different discussion. That is to say, well, \nif this is the scenario of what's possible,   you know, what do we want? And what are we able \nto get? And, I think that that's a different  ",
    "start": "1705000",
    "end": "1714559"
  },
  {
    "text": "discussion, which is, as old as life.\nMalcolm: Which one do you do first? I think it is very helpful to have an understanding of what's possible and how it \nchanges the landscape, uh, as part of a broader,  ",
    "start": "1714560",
    "end": "1728559"
  },
  {
    "text": "uh, discussion—right?— and a broader negotiation. \nBecause, you also have to see the opportunities,  ",
    "start": "1728560",
    "end": "1734520"
  },
  {
    "text": "because there will be a lot of ground to \nsay, “If we can do it in this way, and we  ",
    "start": "1734520",
    "end": "1740400"
  },
  {
    "text": "can all be that much more efficient in getting \nthis piece worked on or this filming done....” But we have a reasonable agreement about how \nwe—both sides—benefit from it, right? Then  ",
    "start": "1740400",
    "end": "1751600"
  },
  {
    "text": "that's a win-win for everybody, right? So that's \na—I think that would be a golden triangle, right?  Malcolm: Here's my reading, and I would \nlike you to correct me if I'm wrong. And  ",
    "start": "1751600",
    "end": "1759840"
  },
  {
    "text": "I'm likely to be wrong. Uh, when I looked at \nthat strike, I said, “If they're worried about   AI—the writers are worried about AI. That seems \nsilly. It should be the studios who are worried  ",
    "start": "1759840",
    "end": "1770919"
  },
  {
    "text": "about the economic impact of AI.” Doesn't, \nin the long run—AI puts the studios out of   business long before it puts the writers out \nof business. I only need the studio because  ",
    "start": "1770920",
    "end": "1779840"
  },
  {
    "text": "the costs of production are as high as the sky \nand the costs of production are overwhelming. ",
    "start": "1779840",
    "end": "1785159"
  },
  {
    "text": "And—whereas if I don't, if I have a \ntool which brings, introduces massive  ",
    "start": "1785160",
    "end": "1791360"
  },
  {
    "text": "technological efficiencies to the production \nof movies, then I don't need—why do I need a   studio? Why would they be the scared ones?\nDario: Or maybe—or maybe you need a, like,  ",
    "start": "1791360",
    "end": "1799120"
  },
  {
    "text": "a different kind of studio. Or a different \nkind of studio. A different kind of studio.  Malcolm: What do you mean? In this strike, \nthe frightened ones were the writers and  ",
    "start": "1799120",
    "end": "1808280"
  },
  {
    "text": "were the studios. Wasn't that backwards?\nDario: I haven't thought about it. But the  ",
    "start": "1808280",
    "end": "1816120"
  },
  {
    "text": "implications of it—it goes back to what we \nwere talking about before. The implications,   because they're so horizontal—it \nis right to think about it. Like,  ",
    "start": "1816120",
    "end": "1821880"
  },
  {
    "text": "what does it do to the studios as well, right?\nBut then, the reason why that happens is that  ",
    "start": "1821880",
    "end": "1828120"
  },
  {
    "text": "it's the order of either negotiations or who \nfirst got concerned about it and did something  ",
    "start": "1828120",
    "end": "1835280"
  },
  {
    "text": "about it—right?— which is in the context of \nthe strike. Um, you know, I don't know what the   equivalent conversations are going on inside \nthe studio and whether they have a war room  ",
    "start": "1835280",
    "end": "1842800"
  },
  {
    "text": "saying what this is going to mean to us, right?\nBut it doesn't get exercised through a strike,   but maybe through a task force inside, the \ncompanies, about what are they going to do, right?",
    "start": "1842800",
    "end": "1851280"
  },
  {
    "text": "Malcolm: Well—and to go back to your \nthing, you said the first thing you do   is you make a list of what technological \ncapabilities are, but don't technological  ",
    "start": "1851280",
    "end": "1858400"
  },
  {
    "text": "capabilities change every—? I mean, they do.\nYou're racing ahead so fast. So you can't—can  ",
    "start": "1858400",
    "end": "1863920"
  },
  {
    "text": "you have a contract? Again, I'm sorry \nfor getting into a little weeds here,   but this is interesting. Can you have a—you can't \nhave a five-year contract if the contract is based  ",
    "start": "1863920",
    "end": "1872320"
  },
  {
    "text": "on an assessment of technological capabilities \nin 2023. Because by the time we get to 2028,  ",
    "start": "1872320",
    "end": "1880399"
  },
  {
    "text": "2028, it's totally different, right?\nDario: Yeah, but like, where I was going  ",
    "start": "1880400",
    "end": "1885800"
  },
  {
    "text": "is like—there are some, abstractions around \nthat. It’s like, what can we do with my image,  ",
    "start": "1885800",
    "end": "1892480"
  },
  {
    "text": "right? Like, if I generally get the category, \nthat my image can be reproduced, generated,   contents, and so on, it’s like, let’s talk about \nthe abstract notion about who has rights to that,  ",
    "start": "1892480",
    "end": "1901600"
  },
  {
    "text": "or do we both get to benefit from that?\nIf you get that straight, yes, the nature   of how the image gets altered, created, or \nsomething—it will change underneath, but the  ",
    "start": "1901600",
    "end": "1910520"
  },
  {
    "text": "concept will stay the same. And, uh, so I think \nwhat’s important is to get the categories right.  Malcolm: Yeah. Yeah. If you had to—if you had to \nthink about the biggest technological obstacle,  ",
    "start": "1910520",
    "end": "1922040"
  },
  {
    "text": "revolutions of the postwar era—last 75 years—we \ncan all come up with a list. Actually, it’s really  ",
    "start": "1922040",
    "end": "1929480"
  },
  {
    "text": "fun to come up with a list. I was thinking about \nthis when we were, you know—containerized shipping   is my favorite. The green revolution. \nThe internet. Where is AI in that list? ",
    "start": "1929480",
    "end": "1944559"
  },
  {
    "text": "Dario: So I would put it first.\nIn that context that you put forth,   since World War II, undoubtedly, like, computing \nas a category is one of those trajectories that  ",
    "start": "1944560",
    "end": "1956560"
  },
  {
    "text": "has reshaped, right, our world. And I \nthink within computing, I would say,  ",
    "start": "1956560",
    "end": "1962600"
  },
  {
    "text": "the role that semiconductors have had has been \nincredibly defining. I would say AI is the second  ",
    "start": "1962600",
    "end": "1969520"
  },
  {
    "text": "example of that as a core architecture, uh, that \nis going to have an equivalent level of impact. ",
    "start": "1969520",
    "end": "1976080"
  },
  {
    "text": "And then the third leg I would put to \nthat equation will be quantum. Quantum   information. And that’s sort of like—I like \nto summarize that the future of computing is",
    "start": "1976080",
    "end": "1983560"
  },
  {
    "text": "bits, neurons, and qubits. And it’s that \nidea of high-precision computation—the   world of neural networks and artificial \nintelligence and the world of quantum. ",
    "start": "1983560",
    "end": "1992320"
  },
  {
    "text": "And the combination of those things \nis going to be the defining force   of the next 100 years in that category of \ncomputing. But it makes the list for sure. ",
    "start": "1992320",
    "end": "2000080"
  },
  {
    "text": "Malcolm: If it’s that high up on the list, this \nis a total hypothetical. Would you—if you were  ",
    "start": "2000080",
    "end": "2005159"
  },
  {
    "text": "starting over; if you were starting at IBM right \nnow—would you say, “Oh, our AI act operations  ",
    "start": "2005160",
    "end": "2012400"
  },
  {
    "text": "actually should be way bigger”?\nLike, how many thousands   of people working for you?\nDario: So within the research division,  ",
    "start": "2012400",
    "end": "2018840"
  },
  {
    "text": "uh, it’s about like 3,500 scientists.\nMalcolm: So in a perfect world, would you,   if it’s that big, isn’t that too small a group?\nDario: Yeah. Well, that’s like in the research  ",
    "start": "2018840",
    "end": "2028400"
  },
  {
    "text": "division. I mean, IBM overall, there’s tens \nof thousands of people working on that.  Malcolm: We’re talking, we’re talking about—but \nI mean, like, so, starting from—first,  ",
    "start": "2028400",
    "end": "2034240"
  },
  {
    "text": "so you have a—you’ve, we’ve got a technology \nthat you’re ranking with compute and, you know,  ",
    "start": "2034240",
    "end": "2041240"
  },
  {
    "text": "up there with it in terms of a world changer. \nAre we—so what I'm basically asking is,  ",
    "start": "2041240",
    "end": "2048159"
  },
  {
    "text": "are we underinvested in this future?\nDario: No, but so—so yeah,   it’s a, it’s a good question.\nSo like what I would say is that  ",
    "start": "2048160",
    "end": "2055679"
  },
  {
    "text": "I think we should segment. How many people do you \nneed on the creation of the technology itself? And  ",
    "start": "2055680",
    "end": "2062480"
  },
  {
    "text": "what is the right size of research and engineers \nand compute to do that? And how many people do you   need in the sort of application of the technology \nto create better products, to deliver services  ",
    "start": "2062480",
    "end": "2074560"
  },
  {
    "text": "and consulting, and then ultimately to diffuse it \nthrough, you know, sort of all spheres of society? ",
    "start": "2074560",
    "end": "2079760"
  },
  {
    "text": "And the numbers are very different, and that \nis not different than anywhere else. I mean,   I mean, if you give examples of—since you were \ntalking about, in the context of World War II,  ",
    "start": "2079760",
    "end": "2087800"
  },
  {
    "text": "how many people does it take to create, an atomic \nweapon as an example. It’s a large number. I mean,  ",
    "start": "2087800",
    "end": "2093840"
  },
  {
    "text": "it wasn’t just Los Alamos. There’s a lot \nof people in Oakland. It’s a large number,   but it wasn’t a million \npeople, right? Um, so, so you",
    "start": "2093840",
    "end": "2100640"
  },
  {
    "text": "could have highly concentrated teams of people \nthat with enough resources can do extraordinary  ",
    "start": "2100640",
    "end": "2106599"
  },
  {
    "text": "scientific and technological achievements. And \nthat’s always—by definition, is going to be, uh,   1 percent compared to the total volume that \nit’s going to require to then deal with it. ",
    "start": "2106600",
    "end": "2116119"
  },
  {
    "text": "Malcolm: Yeah. But the application side is infinite, almost.\nDario: That’s exactly—so that is where, like,   in the end, the bottleneck really is. So, with, \nyou know, thousands of scientists and engineers,  ",
    "start": "2116120",
    "end": "2126720"
  },
  {
    "text": "you can create world-class AI. Right? And, you \ndon’t need 10,000 to be able to create the large  ",
    "start": "2126720",
    "end": "2133200"
  },
  {
    "text": "language model and the generative model and so on.\nBut you need thousands, and you need,   you know, a very significant amount of compute \nand data. You need that. The rest is, “Okay, I,  ",
    "start": "2133200",
    "end": "2143120"
  },
  {
    "text": "build software,” “I build databases,” or “I build \na software product that allows you to do inventory  ",
    "start": "2143120",
    "end": "2148280"
  },
  {
    "text": "management,” or “I build, a photo editor,” and \nso on. Now that product, incorporating the AI,  ",
    "start": "2148280",
    "end": "2155400"
  },
  {
    "text": "modifying, expanding it, and so on—well, now \nyou’re talking about the entire software industry.  So now you're talking about millions of people, \nright, who are required to bring AI into their  ",
    "start": "2155400",
    "end": "2166840"
  },
  {
    "text": "products. Then you go a step beyond the technology \ncreators in terms of software and you say, well,  ",
    "start": "2166840",
    "end": "2172440"
  },
  {
    "text": "okay, now what? The skills to help organizations \ngo and deploy it in the Department of,  ",
    "start": "2172440",
    "end": "2177760"
  },
  {
    "text": "you know, the Interior, right?\nAnd then I said, okay, well,   now you need like consultants and experts \nand people to work there to integrate into  ",
    "start": "2177760",
    "end": "2184840"
  },
  {
    "text": "the workflow. So now you’re talking into the many \ntens of millions of people around that. So I see   it as these concentric circles of it. But to some \ndegree in many of these core technology areas,  ",
    "start": "2184840",
    "end": "2195120"
  },
  {
    "text": "just saying like, well, I need a team of like a \nhundred thousand people to create, like, AI, or a,   or a new transistor or a new quantum computer—\nIt’s actually a diminishing return,  ",
    "start": "2195120",
    "end": "2203360"
  },
  {
    "text": "right? In the end, like, too many people \nconnecting with each other is very difficult.  Malcolm: But, on the application side, \nit was just—think of our example of that  ",
    "start": "2203360",
    "end": "2213079"
  },
  {
    "text": "college. Just the task of sitting down \nwith a faculty and working with them  ",
    "start": "2213080",
    "end": "2219680"
  },
  {
    "text": "to reimagine what they do with this, \nwith this new set of tools in mind,   with the understanding that the students \ncoming in are probably going to know  ",
    "start": "2219680",
    "end": "2227120"
  },
  {
    "text": "more about it than they do—that alone—I mean, \nthat’s a, that is a Herculean people problem.",
    "start": "2227120",
    "end": "2233620"
  },
  {
    "text": "Dario: It’s a people problem. Yeah, \nthat’s why I started in terms of the   barriers of adoption of that.\nI mean, in the context of   IBM, an, an example—that's why we have a \nconsulting organization, IBM Consulting,  ",
    "start": "2233620",
    "end": "2243840"
  },
  {
    "text": "that complements IBM Technology, and the \nIBM Consulting organization has over 150,000  ",
    "start": "2243840",
    "end": "2249440"
  },
  {
    "text": "employees. Because of this question, right? \nBecause you have to sit down and you say,   okay, what problem are you trying to solve? \nWhat is the methodology we're going to use?  ",
    "start": "2249440",
    "end": "2257920"
  },
  {
    "text": "And here's the technology options that we have \nto be able to bring to the table. In the end,   the adoption across, uh, our society will be \nlimited by this part. The technology is going  ",
    "start": "2257920",
    "end": "2269480"
  },
  {
    "text": "to make it easier, more cost- effective \nto implement those, uh, solutions. But  ",
    "start": "2269480",
    "end": "2275080"
  },
  {
    "text": "you first have to think about what you want to \ndo, how you're going to do it, and how you're   going to bring it into the life of this—in this \ncontext, a faculty member, or, uh, you know, the  ",
    "start": "2275080",
    "end": "2283480"
  },
  {
    "text": "administrator and so on in this college, right?\nMalcolm: With that Hollywood, that, that notion,   I thought, which was absolutely, I thought really \ninteresting that, in a Hollywood strike, you have  ",
    "start": "2283480",
    "end": "2294000"
  },
  {
    "text": "to have this conversation about—a distributive \njustice conversation about how do we—that's,  ",
    "start": "2294000",
    "end": "2299560"
  },
  {
    "text": "it's a really hard conversation, right, to \nhave in a—so this brings me to my next point,   which is that you—we were talking backstage.\nYou have two daughters, one in college,  ",
    "start": "2299560",
    "end": "2309520"
  },
  {
    "text": "one about to go to college. Darío: That's right.\nMalcolm: So, they're both science minded.  Darío: Yeah.\nMalcolm: So tell me about  ",
    "start": "2309520",
    "end": "2314880"
  },
  {
    "text": "the conversations you have with your daughters. \nYou have a unique conversation with your daughters  ",
    "start": "2314880",
    "end": "2320559"
  },
  {
    "text": "because your conversa—your advice to them is, \nis influenced by what you do for a living. ",
    "start": "2320560",
    "end": "2326440"
  },
  {
    "text": "Darío: Yes, it's true.\nMalcolm: Did you warn your   daughters away from certain fields? Did you \nsay, “Whatever you do, don't be”—you know?",
    "start": "2326440",
    "end": "2335709"
  },
  {
    "text": "Dario: No, no, no, no. That's not my style. \nI mean, for me, no. I try not to be like,  ",
    "start": "2335709",
    "end": "2340760"
  },
  {
    "text": "preachy about that. So for me it was just \nabout showing by example of things I love,  ",
    "start": "2340760",
    "end": "2346120"
  },
  {
    "text": "right? And, things I care about.\nAnd then, bringing them to the lab   and seeing things, and then the natural \nconversations of things I'm working on,  ",
    "start": "2346120",
    "end": "2353960"
  },
  {
    "text": "or interesting people I meet. So, to the extent \nthat they have chosen that—and obviously this   has an influence on them—it has been through \nseeing it, perhaps through my eyes, right? ",
    "start": "2353960",
    "end": "2364440"
  },
  {
    "text": "And what you see me do, and that \nI like my profession. Right?  Malcolm: But one of your daughters, you said, \nis thinking that she wants to be a doctor. But  ",
    "start": "2364440",
    "end": "2372080"
  },
  {
    "text": "being a doctor in a post-AI world is surely a \nvery different proposition than being a doctor  ",
    "start": "2372080",
    "end": "2377240"
  },
  {
    "text": "in a pre-AI world. Do you think—have you \ntried to prepare her for that difference?  ",
    "start": "2377240",
    "end": "2383000"
  },
  {
    "text": "Have you explained to her what you think will \nhappen to this profession she might enter?  Dario: Yeah. I mean, not in like, you \nknow, incredible amount of detail, but yes,  ",
    "start": "2383000",
    "end": "2391880"
  },
  {
    "text": "at the level of understanding what is changing, \nlike this lens of the—information lens with which  ",
    "start": "2391880",
    "end": "2397559"
  },
  {
    "text": "you can look at the world and what is possible, \nuh, and what it can do, like what is our role and  ",
    "start": "2397560",
    "end": "2403680"
  },
  {
    "text": "what is the role of the technology and how that \nshapes at that level of abstraction, for sure.  But not at the level of like, \ndon't be a radiologist, you know,  ",
    "start": "2403680",
    "end": "2411440"
  },
  {
    "text": "because this is what we want for you.\nMalcolm: I was going to say, if you,   if you're unhappy with your current job, you could \ndo a podcast called Parenting Tips with Darío,  ",
    "start": "2411440",
    "end": "2417760"
  },
  {
    "text": "which is just, “an AI person gives you advice on \nwhat your kids should do based on exactly this.” ",
    "start": "2417760",
    "end": "2424000"
  },
  {
    "text": "Like, “Should I be a radiologist? Darío, \ntell me.” Like, it seems to be a really   important question.\nDarío: Yeah. ",
    "start": "2424000",
    "end": "2430220"
  },
  {
    "text": "Malcolm:, Let me ask this question in a \nmore—I'm joking, but in a more serious way,  ",
    "start": "2430220",
    "end": "2434680"
  },
  {
    "text": "surely it would—if—I don't mean to \nuse your daughter as an example,   but let's imagine we're giving advice to somebody \nwho wants to enter medicine. A really useful",
    "start": "2435280",
    "end": "2443599"
  },
  {
    "text": "conversation to have is, what are the skills \nthat are—will be—most prized in that profession,  ",
    "start": "2443600",
    "end": "2451520"
  },
  {
    "text": "yeah, fifteen years from now, and are they \ndifferent from the skills that are prized now?  How would you answer that question?\nDarío: Yeah, I think, for example—this is,  ",
    "start": "2451520",
    "end": "2461040"
  },
  {
    "text": "goes back to how is the scientific method on, \nin this context, like the practice of medicine,   going to change? I think we will see more changes \nin how we practice the scientific method and  ",
    "start": "2461040",
    "end": "2470319"
  },
  {
    "text": "so on as a consequence of what is happening \nwith the world of computing and information,  ",
    "start": "2470320",
    "end": "2476160"
  },
  {
    "text": "how we represent information, how we \nrepresent knowledge, how we extract   meaning from knowledge as a method, uh, \nthan we have seen in the last 200 years. ",
    "start": "2476160",
    "end": "2485280"
  },
  {
    "text": "So therefore, what I would like strongly \nto encourage is not about, like, hey,   use this tool for doing this or doing that, but \nin the curriculum itself, in understanding how  ",
    "start": "2485280",
    "end": "2494440"
  },
  {
    "text": "we do problem solving in the age of like \ndata and data representation and so on;  ",
    "start": "2494440",
    "end": "2499839"
  },
  {
    "text": "that needs to be embedded in the curriculum of \neverybody. You know, that is, I would say actually  ",
    "start": "2499840",
    "end": "2504880"
  },
  {
    "text": "quite horizontally, but certainly in the context \nof medicine and scientists and so on, for sure. ",
    "start": "2504880",
    "end": "2510440"
  },
  {
    "text": "And to the extent that that gets ingrained, that \nwill give us a lens that no matter what specialty  ",
    "start": "2510440",
    "end": "2516359"
  },
  {
    "text": "they go with in medicine, they will say, actually, \nthe way I want to be able to tackle improving the  ",
    "start": "2516360",
    "end": "2521720"
  },
  {
    "text": "quality of care, the way to do that is—in addition \nto all the elements that we have practiced in our,  ",
    "start": "2521720",
    "end": "2526800"
  },
  {
    "text": "in the field of medicine—is this new lens. And \nare we representing the data the right way? Do  ",
    "start": "2526800",
    "end": "2531840"
  },
  {
    "text": "we have the right tools to be able to represent \nthat knowledge? Am I incorporating that in my   own—sort of with my own knowledge in a way that \ngives me better outcomes, right? Do I have the  ",
    "start": "2531840",
    "end": "2541440"
  },
  {
    "text": "rigor of benchmarking to, and quality of, the \nresults? So that is what needs to be incorporated. ",
    "start": "2541440",
    "end": "2547119"
  },
  {
    "text": "Malcolm: How, in a perfect world, if I asked \nyou to, your team to rewrite the curriculum  ",
    "start": "2547120",
    "end": "2555000"
  },
  {
    "text": "for American medical schools, how dramatic \na revision is that? Are we tinkering with  ",
    "start": "2555000",
    "end": "2560280"
  },
  {
    "text": "10 percent of the curriculum or are \nwe tinkering with 50 percent of it?  Darío: I think there would be, a subset of classes \nthat is about the method—the methodology. What has  ",
    "start": "2560280",
    "end": "2571480"
  },
  {
    "text": "changed. Like, like, have this lens of it \nto understand. And then within each class,  ",
    "start": "2571480",
    "end": "2577119"
  },
  {
    "text": "that methodology will represent \nsomething that is embedded in it, right? So it will be substantive, but it \ndoesn't mean replacing the specialization  ",
    "start": "2577800",
    "end": "2588800"
  },
  {
    "text": "and the context and the knowledge of each domain.\nBut I do think everybody should have sort of a  ",
    "start": "2588800",
    "end": "2593920"
  },
  {
    "text": "basic knowledge of the horizontal, right? What \nis it? How does it work? What tools you have,  ",
    "start": "2593920",
    "end": "2599000"
  },
  {
    "text": "what is the technology, and like, you know, \nwhat are the dos and don'ts around that. And   in every area, you say—“That thing that you \nlearn? This is how it applies to, uh, anatomy,  ",
    "start": "2599000",
    "end": "2608359"
  },
  {
    "text": "and this is how it applies to radiology,” if \nyou're studying that. “Or, this is how you apply,  ",
    "start": "2608360",
    "end": "2613800"
  },
  {
    "text": "in the context of discovery—right?— of cell \nstructure. And this is how we can use it.”   Or “protein folding, and this is how it, it \ndoes—.” So that way, you'll see a connecting  ",
    "start": "2613800",
    "end": "2622119"
  },
  {
    "text": "tissue through, uh, throughout the whole thing.\nMalcolm: Yeah. I mean, I would add to that. It's  ",
    "start": "2622120",
    "end": "2630920"
  },
  {
    "text": "also this incredible opportunity to do what \ndoctors are supposed to do but don't have time   to do now, which is, they're so consumed with \nfiguring out what's wrong with you that they  ",
    "start": "2630920",
    "end": "2642839"
  },
  {
    "text": "have little time to talk about the implications \nof the diagnosis. And what we really want are—if  ",
    "start": "2642840",
    "end": "2648520"
  },
  {
    "text": "we can free them of some of the burden of what is \nactually quite a prosaic question of “What's wrong  ",
    "start": "2648520",
    "end": "2654080"
  },
  {
    "text": "with you?” and leave the hard human thing of let \nme—should you be scared or hopeful? Should you—,  ",
    "start": "2654080",
    "end": "2661680"
  },
  {
    "text": "what do you need to do? What—let me put this in \nthe context of all the patients I've seen. That   conversation, which is the most important one, is \nthe one that's—seems to me. So like if I had to,  ",
    "start": "2661680",
    "end": "2671120"
  },
  {
    "text": "I would add, if we were reimagining the curriculum \nof med school, I'd like—with whatever—by the way,  ",
    "start": "2671120",
    "end": "2678400"
  },
  {
    "text": "very little time. Maybe we have to \nadd two more years to med school.  But like a whole—that's not gonna be popular. \nBut the whole thing about bringing back the  ",
    "start": "2678400",
    "end": "2688280"
  },
  {
    "text": "human side of, yeah, you know, now \nif I can give you ten more minutes,  ",
    "start": "2688280",
    "end": "2694000"
  },
  {
    "text": "how do you use that ten more minutes?\nDarío: But in that, in that   reconceptualization that you just did \nis what we should be doing around that. ",
    "start": "2694000",
    "end": "2700880"
  },
  {
    "text": "Because I think the debate as to like, “Well, am \nI gonna need doctors or not?” is actually a not   very useful debate. But rather this other question \nis “How is your time being spent? What problems  ",
    "start": "2700880",
    "end": "2710880"
  },
  {
    "text": "are you getting stuck?” I mean, I generalize \nthis by like the obvious observation that if   you look around in our professions, in our daily \nlives, we have not run out of problems to solve.",
    "start": "2710880",
    "end": "2720240"
  },
  {
    "text": "So as—an example of that is, hey, if I'm spending \nall my time trying to do diagnosis, and I could do   that ten times faster, and it allowed me actually \nto go and, um, you know, and take care of the  ",
    "start": "2720240",
    "end": "2729720"
  },
  {
    "text": "patients and all The next steps and what we have \nto do about it. That's probably a trade-off that a   lot of doctors would take—would take, right? Yeah.\nAnd then you say, well, to what degree does it  ",
    "start": "2729720",
    "end": "2738520"
  },
  {
    "text": "allow me to do that? And I can do these other \nthings and these other things that are critically   important for my profession around that. So \nwhen you actually become less abstract, and  ",
    "start": "2738520",
    "end": "2747720"
  },
  {
    "text": "like we get past the futile conversation of like, \n“Oh, there's no more jobs and AI's gonna take it,   all of it,” which is kind of nonsense, is: you go \nback to say, in practice, in your context, right,  ",
    "start": "2747720",
    "end": "2758839"
  },
  {
    "text": "for you, what does it mean? How do you work? What \ncan you do differently around that? Actually,  ",
    "start": "2758840",
    "end": "2764040"
  },
  {
    "text": "that's a much richer conversation. And very often \nwe would find ourselves—that there's a portion of   the work we do that we say, “I would rather do \nless of that. This, this other part I, I like a  ",
    "start": "2764040",
    "end": "2772680"
  },
  {
    "text": "lot. And if it is possible that technology could \nhelp us make that trade- off, I'll take it in a  ",
    "start": "2772680",
    "end": "2777760"
  },
  {
    "text": "heartbeat.” Now, poorly implemented technology can \nalso create another problem. You say, hey, this  ",
    "start": "2777760",
    "end": "2783280"
  },
  {
    "text": "was supposed to solve things, but the way it's \nbeing implemented is not helping me, right? It's  ",
    "start": "2783280",
    "end": "2788520"
  },
  {
    "text": "making my life much more miserable, or so on, or \nI've lost connection in how I used to work, etc. ",
    "start": "2788520",
    "end": "2794480"
  },
  {
    "text": "So that is why design is so important. That is \nwhy also workflow is so important in being able to  ",
    "start": "2794480",
    "end": "2801760"
  },
  {
    "text": "solve these problems. But it begins by, you know, \ngoing from the intergalactic to the reality of it,  ",
    "start": "2801760",
    "end": "2808600"
  },
  {
    "text": "of that faculty member in the liberal arts \ncollege or a practitioner in medicine in a  ",
    "start": "2808600",
    "end": "2814640"
  },
  {
    "text": "hospital and what it means for them, right?\nMalcolm: Mm-hmm. Yeah. What struck me, Darío,   throughout our conversation is, um, how much of \nthis revolution is nontechnical. ’Cause to say,  ",
    "start": "2814640",
    "end": "2827279"
  },
  {
    "text": "“You guys are doing the technical thing \nhere, but the real, the revolution is   going to require a whole range of people doing \nthings that have nothing to do with software,  ",
    "start": "2827280",
    "end": "2836200"
  },
  {
    "text": "that have to do with working out new, new \nhuman arrangements”—talking about that,   I mean, I keep coming back to the Hollywood strike \nthing: that you have to have a conversation about  ",
    "start": "2836200",
    "end": "2846839"
  },
  {
    "text": "our values as creators of movies; how are  we going to divide up the credit, and the— \nDario: Exactly right!",
    "start": "2847360",
    "end": "2855540"
  },
  {
    "text": "Malcolm: Like that’s a conversation about philosophy, and, \nDarío: it's in the grand tradition of why,  ",
    "start": "2855540",
    "end": "2864320"
  },
  {
    "text": "a liberal education is so important in \nthe, the broadest possible sense, right?  There's no common conception of the good, \nright? That is always a contested, uh,  ",
    "start": "2866200",
    "end": "2876480"
  },
  {
    "text": "dialogue that happens within our society. And \ntechnology is going to fit in that context too, right? So that's why personally, as a \nphilosophy, I'm not a technological determiner.  ",
    "start": "2876480",
    "end": "2885559"
  },
  {
    "text": "Right? And I don't like when colleagues in my \nprofession, right, start saying like, well, this   is the way the technology is going to be, and by \nconsequence, this is how society is going to be. ",
    "start": "2885560",
    "end": "2894600"
  },
  {
    "text": "I'm like, that's a highly contested goal, and \nif you want to enter into a realm of politics   or the realm of other ones, go and stand \nup on a stool and discuss whether that's  ",
    "start": "2894600",
    "end": "2903520"
  },
  {
    "text": "what society wants. You will find that it's a \nhuge diversity of, of opinions and perspective,  ",
    "start": "2903520",
    "end": "2908800"
  },
  {
    "text": "and that's what makes, you know, uh, you know, \nin a democracy, the richness of our society.  And in the end, that is going to be the \ncenterpiece of the conversation. What do we  ",
    "start": "2908800",
    "end": "2917280"
  },
  {
    "text": "want? You know, who gets what? And so on, and \nthat is—actually, I don't think it's anything  ",
    "start": "2917280",
    "end": "2922560"
  },
  {
    "text": "negative. That's as it should be. Because in \nthe end, it's anchor of who we want as humans,  ",
    "start": "2922560",
    "end": "2927800"
  },
  {
    "text": "as friends, family, citizens, and we have many \noverlapping sets of responsibilities, right?  And as a technology creator, my \nonly responsibility is not just as  ",
    "start": "2928320",
    "end": "2936400"
  },
  {
    "text": "a scientist and a technology creator; I'm \nalso a member of a family, I'm a citizen,   and I have many other things that I care \nabout. And I think that—that sometimes  ",
    "start": "2936400",
    "end": "2943960"
  },
  {
    "text": "in the debate of the technological determinists, \nthey start now butting into what is the realm of  ",
    "start": "2943960",
    "end": "2952400"
  },
  {
    "text": "justice and society and philosophy and democracy.\nAnd that's where they get the most uncomfortable,  ",
    "start": "2953600",
    "end": "2959960"
  },
  {
    "text": "because it's like—I'm just telling you \nlike, you know, uh, what's possible. And   when there's pushback, it's like, yeah, \nbut, but now we're talking about how we  ",
    "start": "2959960",
    "end": "2968280"
  },
  {
    "text": "live. And how we work and how much I get paid \nor not paid. So that technology is important. ",
    "start": "2968280",
    "end": "2976080"
  },
  {
    "text": "Technology shapes our conversation. But \nwe're gonna have the conversation with a   different language. As it should be. And \ntechnologies need to get accustomed to—if  ",
    "start": "2976080",
    "end": "2984880"
  },
  {
    "text": "they want to participate in that world with the \nbroad consequences, hey, get accustomed to deal   with the complexity of that world. Of politics, \nsociety, institutions, unions, all that stuff. ",
    "start": "2984880",
    "end": "2995280"
  },
  {
    "text": "And, you know, you can't be, like, whiny \nabout it. It's like, “They're not adopting   my technology.” That's what it takes \nto bring technology into the world.",
    "start": "2995280",
    "end": "3001800"
  },
  {
    "text": "Malcolm: Yeah, well said. Thank you, Darío, for \nthis wonderful conversation. Thank you, to all of  ",
    "start": "3001800",
    "end": "3010440"
  },
  {
    "text": "you for coming and listening. And, thank you.\nDarío: Thank you. Malcolm: Darío Gil transformed how \nI think about the future of AI. ",
    "start": "3010440",
    "end": "3022320"
  },
  {
    "text": "He explained to me how huge of \na leap it was when we went from  chess-playing models to language-learning models.\nAnd he talked about how we still  ",
    "start": "3022320",
    "end": "3031320"
  },
  {
    "text": "have a lot of room to grow. That’s\nwhy it’s important that we get things right.  The future of AI is impossible to predict. \nBut the technology has so much potential  ",
    "start": "3031320",
    "end": "3042200"
  },
  {
    "text": "in every industry. Zooming into an academic \nor a medical setting showed just how close  ",
    "start": "3042200",
    "end": "3047359"
  },
  {
    "text": "we are to the widespread adoption of AI. Even \nHollywood is being forced to figure this out. ",
    "start": "3047360",
    "end": "3054000"
  },
  {
    "text": "Institutions of all sorts will have to be at the \nforefront of integration in order to unlock the  ",
    "start": "3054000",
    "end": "3059800"
  },
  {
    "text": "full power of AI thoughtfully and responsibly. \nHumans have the power and the responsibility to  ",
    "start": "3059800",
    "end": "3066760"
  },
  {
    "text": "shape the tech for our world. I, for one, \nam excited to see how things play out.",
    "start": "3066760",
    "end": "3073840"
  },
  {
    "text": "Smart Talks with IBM is produced \nby Matt Romano, Joey Fischground,   David Zha, and Jacob Goldstein. \nWe’re edited by Lidia Jean Kott.",
    "start": "3073840",
    "end": "3082960"
  },
  {
    "text": "Our engineers are Jason Gambrell, \nSarah Bruguiere, and   Ben Tolliday. Theme song by Gramoscope.\nSpecial thanks to Andy Kelly, Kathy Callaghan,  ",
    "start": "3082960",
    "end": "3093640"
  },
  {
    "text": "and the EightBar and IBM teams, as \nwell as the Pushkin marketing team. ",
    "start": "3093640",
    "end": "3098720"
  },
  {
    "text": "Smart Talks with IBM is a production \nof Pushkin Industries and Ruby Studio   at iHeartMedia. To find more Pushkin podcasts, \nlisten on the iHeartRadio app, Apple Podcasts,  ",
    "start": "3098720",
    "end": "3110000"
  },
  {
    "text": "or wherever you listen to podcasts.\nI’m Malcolm Gladwell. ",
    "start": "3110000",
    "end": "3115200"
  },
  {
    "text": "This is a paid advertisement from IBM.",
    "start": "3115200",
    "end": "3122960"
  }
]
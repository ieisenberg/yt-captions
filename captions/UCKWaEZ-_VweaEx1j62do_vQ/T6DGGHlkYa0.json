[
  {
    "start": "0",
    "end": "193000"
  },
  {
    "text": "Hello and welcome to Mixture of Experts. I'm your host, Tim Wong. Each week, Mixture of Experts brings\ntogether a world class team of",
    "start": "9210",
    "end": "15640"
  },
  {
    "text": "researchers, product experts, engineers,\nuh, and more to debate and distill down the biggest news of the week in AI.",
    "start": "15640",
    "end": "21970"
  },
  {
    "text": "Today on the show, the OpenAI\nand Google showdown of the week. Who's up, who's down,\nwho's cool, who's cringe?",
    "start": "22469",
    "end": "28580"
  },
  {
    "text": "What matters, and what was just hype? We're going to talk about the huge\nwave of announcements coming out of both companies this week, and what\nit means for the industry as a whole.",
    "start": "28904",
    "end": "36605"
  },
  {
    "text": "So, for panelists today on the show,\nI'm ably supported by an incredible panel, uh, two veterans who have\njoined the show before, and a new,",
    "start": "37164",
    "end": "44644"
  },
  {
    "text": "uh, contestant has joined the ring. Um, so, first off, uh, Shobhit Varshney,\nhe's the Senior Partner Consulting",
    "start": "44834",
    "end": "51364"
  },
  {
    "text": "for AI in US, Canada, and LATAM. Shobhit, welcome back to the show. Thanks for having me back, Tim.",
    "start": "51364",
    "end": "56485"
  },
  {
    "text": "Love this. Yeah, definitely. Glad to have you here. Chris Hay, who is a distinguished engineer\nand the CTO of Customer Transformation.",
    "start": "56585",
    "end": "63690"
  },
  {
    "text": "Chris, welcome back. Hey, nice to be back. Yeah, glad to have you back. And joining us for the first time\nis Bryan Casey, who is the Director",
    "start": "63750",
    "end": "71689"
  },
  {
    "text": "of Digital Marketing, who has\npromised a 90 minute monologue. Uh, on AI and search summaries, which\nI don't know if we're going to get to,",
    "start": "71690",
    "end": "78510"
  },
  {
    "text": "but we're going to have him have a say. Bryan, welcome to the show. We'll have to suffer through showbit\nand Chris for a little bit, and",
    "start": "78510",
    "end": "83660"
  },
  {
    "text": "then we'll get to the monologue. But for having me. The good stuff. Yeah, exactly.",
    "start": "83660",
    "end": "87400"
  },
  {
    "text": "Um, well, great. Well, let's just go ahead\nand jump right into it. So obviously there were a huge\nnumber of announcements this week.",
    "start": "88669",
    "end": "95240"
  },
  {
    "text": "OpenAI came out of the gate with\nits kind of raft of announcements. Uh, Google I. O. is going on and they did\ntheir set of announcements.",
    "start": "95280",
    "end": "102780"
  },
  {
    "text": "And so, really, more things, I\nthink, were debuted, promised, coming out, than we're going to have the\nchance to cover on this episode.",
    "start": "103110",
    "end": "110240"
  },
  {
    "text": "But sort of from my point of view, and\nI think I wanted to use this as a way of organizing the episode, there were\nkind of three big themes coming out",
    "start": "110840",
    "end": "117580"
  },
  {
    "text": "of Google and OpenAI this week that\nwe'll sort of take in turn and use to kind of make sense of everything.",
    "start": "117580",
    "end": "122469"
  },
  {
    "text": "So I think the first thing\nis multimodality, right? Both companies are sort of obsessed with\ntheir models taking video input and being",
    "start": "123209",
    "end": "130438"
  },
  {
    "text": "able to make sense of it and going from,\nyou know, image to audio, text to audio. Um, and I want to talk\na little bit about that.",
    "start": "130439",
    "end": "136620"
  },
  {
    "text": "Second thing is latency and costs, right? Everybody touted the fact that their\nmodels are going to be cheaper, and they're going to be way faster, right?",
    "start": "137510",
    "end": "144000"
  },
  {
    "text": "And, you know, I think if you're from\nthe outside, you might say, well, it's kind of a difference in kind. Things get faster and cheaper.",
    "start": "144050",
    "end": "149390"
  },
  {
    "text": "But I think what's happening here\nreally potentially might have a huge impact on downstream uses, uh, of AI.",
    "start": "149390",
    "end": "155849"
  },
  {
    "text": "And so I want to talk a little bit about\nthat dimension and sort of what it means. Um, and then finally, uh, I've already\nkind of previewed a little bit.",
    "start": "155850",
    "end": "163000"
  },
  {
    "text": "Um, Google made this big announcement\nthat I think is almost literally going to be like Many people's very\nfirst experience with LLMs in full",
    "start": "163050",
    "end": "171085"
  },
  {
    "text": "production, uh, Google basically\nannounced that going forwards, uh, the U. S. market and then globally, uh, those\nusers of Google search will start",
    "start": "171085",
    "end": "179555"
  },
  {
    "text": "seeing AI summaries at the top of\neach of their sort of search results. Um, that's a huge change.",
    "start": "179565",
    "end": "184694"
  },
  {
    "text": "We're gonna talk a little bit about\nwhat that means and, um, if it's good. I think is a really good question, uh,\nso looking forward to diving into it all.",
    "start": "184695",
    "end": "192105"
  },
  {
    "start": "193000",
    "end": "546000"
  },
  {
    "text": "So let's talk a little bit\nabout multi modal first. So there's two showcase demos from Google\nand OpenAI, and I think both of them",
    "start": "197495",
    "end": "205785"
  },
  {
    "text": "kind of roughly got at the same thing,\nwhich is that in the future you're going to open up your phone, you're going to\nturn on your camera, and then you can",
    "start": "205824",
    "end": "211445"
  },
  {
    "text": "wave your camera around, and your AI will\nbasically be responding in real time. And so, Shobhit, I want to bring\nyou in because you were the one who",
    "start": "211455",
    "end": "218459"
  },
  {
    "text": "kind of flagged this being like, we\nshould really talk about this, because I think the big question that I'm\nsort of left with is like, you know,",
    "start": "218460",
    "end": "224489"
  },
  {
    "text": "where do we think this is all going? Right? It's a really cool feature, but\nlike, what kind of products do we think it's really going to unlock?",
    "start": "224489",
    "end": "229599"
  },
  {
    "text": "And maybe we'll start there, but\nI'm sure, I mean, this topic goes into all different places, so\nI'll give you the floor to start.",
    "start": "229599",
    "end": "234374"
  },
  {
    "text": "Tim, Monday and Tuesday were\njust phenomenal inflection points for the industry altogether. It's getting to a point where\nan AI can make sense of all",
    "start": "234825",
    "end": "243084"
  },
  {
    "text": "these different modalities. It's an insanely tough problem. We've been at this for a while\nand we've not gotten it right.",
    "start": "243084",
    "end": "248664"
  },
  {
    "text": "We spent all this time trying to create\npipelines to do each of these speech to text and understand and then text to back.",
    "start": "249104",
    "end": "254424"
  },
  {
    "text": "It takes a while to get\nall of the processing done. The 2024 we were able to do this,\nwhat a time to be alive man.",
    "start": "254724",
    "end": "261353"
  },
  {
    "text": "I just feel that we are getting,\nfinally getting to a point where. Your phone becomes an extension\nof your eyes, of your listening",
    "start": "262165",
    "end": "268840"
  },
  {
    "text": "in and stuff like that, right? And that is a, that has a\nprofound impact on some of the workflows in our daily lives.",
    "start": "268840",
    "end": "274370"
  },
  {
    "text": "Now, within IBM, I focus\na lot more on enterprises. So I'll give you more of an\nenterprise view of how these",
    "start": "274990",
    "end": "280830"
  },
  {
    "text": "technologies are actually going to\nmake a, make a difference or not. In both cases, Gemini and OpenAI is 4.",
    "start": "280879",
    "end": "288150"
  },
  {
    "text": "0. And by the way, in my case, I'm 4. 0. 4. 0 does not stand for Omni. For me, 4. 0 means, oh my God, it is\nreally, really that good.",
    "start": "288180",
    "end": "295349"
  },
  {
    "text": "So, um, we're getting to a point\nwhere there are certain workflows that we do with enterprises, like\nyou are looking at transferring",
    "start": "295940",
    "end": "303550"
  },
  {
    "text": "knowledge from one person to the other. And usually you're looking at a\nscreen and you have a bunch of here's what I did, how I solved for it.",
    "start": "303550",
    "end": "309054"
  },
  {
    "text": "We used to spend a lot of time\ntrying to capture all of that and what happened in the desktop. Classic BPO processes, these are billions\nof dollars of work that happens, right?",
    "start": "309495",
    "end": "317525"
  },
  {
    "text": "Yeah, and I think if I could pause\nyou there, like I'm curious if you can explain, because again, this is not\nmy world, I'm sure a lot of listeners",
    "start": "317575",
    "end": "322995"
  },
  {
    "text": "aren't, it isn't their world as well. How did it used to be done? Right? Like, so if you're, you're trying\nto like automate a bunch of these",
    "start": "322995",
    "end": "328479"
  },
  {
    "text": "workflows, is it just people writing\nscripts for every single task? Or like, I'm just kind of\ncurious about what it looks like. Yeah.",
    "start": "328479",
    "end": "333840"
  },
  {
    "text": "So Tim, let's, let's pick\na more concrete example. Uh, say you have outsourcing a particular\npiece of work and your finance documents",
    "start": "333929",
    "end": "340829"
  },
  {
    "text": "coming in, you're comparing it against\nother things, you're finding errors, you're going to go back and send an\nemail, things of that nature, right?",
    "start": "340829",
    "end": "346669"
  },
  {
    "text": "So we used to spend a lot of time\ndocumenting the current process. And then we look at that 7...20...9 step\nprocess and say I'm going to call an",
    "start": "346960",
    "end": "354510"
  },
  {
    "text": "API, I'm going to write some scripts,\nand all kinds of issues used to happen along the way, unhappy paths and so forth.",
    "start": "354510",
    "end": "359869"
  },
  {
    "text": "So the whole process used to be\ncodified in some level of code, and then it's deterministic, it does one\nthing in a particular flow really well.",
    "start": "359869",
    "end": "367290"
  },
  {
    "text": "And you can't interrupt it, you can't just\nbarge in and say, no, no, no, this is not what I wanted, can you do something else? So we're now finally getting to a point\nwhere that knowledge work, that work",
    "start": "367619",
    "end": "376080"
  },
  {
    "text": "that is to get done in a process, that'll\nstart getting automated significantly with announcements from both Google and OpenAI.",
    "start": "376080",
    "end": "382649"
  },
  {
    "text": "So far people would solve it as a\ndecision step by step flowchart. But now we're in a paradigm shift\nwhere I can, in the middle of it,",
    "start": "383469",
    "end": "389675"
  },
  {
    "text": "interrupt an action to say, Hey, see\nwhat's on my desktop and figure it out. I've been playing, I've been playing\naround with, uh, with OpenAI's 4.",
    "start": "389765",
    "end": "396495"
  },
  {
    "text": "0, its ability to go look at a video\nof a screen and things of that nature. It's pretty outstanding. We are coming to a point where\nthe, the speed at which the",
    "start": "396534",
    "end": "403994"
  },
  {
    "text": "inference is happening is so quick. And now you can physically we\ncan actually bring them into your workflows early to just take so long.",
    "start": "403994",
    "end": "410305"
  },
  {
    "text": "It was very clunky is very expensive. So you couldn't really justify\nadding AI into those workflows. It'll be you do liver arbitrage\nor things of that nature",
    "start": "410375",
    "end": "418365"
  },
  {
    "text": "versus trying to automate it. So these are kind of workflows\ninfusing AI in doing this entire",
    "start": "418625",
    "end": "423994"
  },
  {
    "text": "process into an phenomenal unlock. One of my clients is a big CBG company.",
    "start": "423995",
    "end": "428985"
  },
  {
    "text": "And as we walk into the aisles, they\ndo things like panograms where you're looking at a picture of the Um, And\nthese consumer product goods companies",
    "start": "429445",
    "end": "437690"
  },
  {
    "text": "would give you a particular format\nin which you want to keep different chips and drinks and so forth.",
    "start": "437690",
    "end": "442509"
  },
  {
    "text": "And each of those labels are turned\naround or they are in a different place. You have to audit and say, Am I placing\nthings on the shelf the right way?",
    "start": "443020",
    "end": "449990"
  },
  {
    "text": "Like the consumer product goods model. That's called planogram. Realogram, planogram, that's the idea.",
    "start": "450270",
    "end": "455320"
  },
  {
    "text": "So earlier we used to take pictures,\na human would go in and note things and say, yes, I have enough of\nthe bottles in the right order.",
    "start": "455750",
    "end": "461440"
  },
  {
    "text": "Then we started to take\npictures and analyzing it. You start to run into real world issues. You don't have enough space to\nback up and take a picture or.",
    "start": "461689",
    "end": "468610"
  },
  {
    "text": "You go to the next island, the lighting\nis very different and stuff like that. So AI never quite scaled. And this is the first time now we're\nlooking at models like Gemini and",
    "start": "468925",
    "end": "476555"
  },
  {
    "text": "others where I can just walk past it and\ncreate a video and just feed the whole",
    "start": "476565",
    "end": "481445"
  },
  {
    "text": "five minute video in with this context\nlength of two million plus and stuff. It can just actually ingest. Right, just process it all.",
    "start": "481755",
    "end": "487574"
  },
  {
    "text": "On the fly. It was missing. Yeah. That's right. Yeah. Those kind of things that were very,\nvery difficult to do for us earlier.",
    "start": "487574",
    "end": "493395"
  },
  {
    "text": "Those are becoming a piece of cake. um, how do I make sure that the\nAI, the normal stuff that we are",
    "start": "494075",
    "end": "501164"
  },
  {
    "text": "seeing, is grounded in enterprise? So it's my data, my planogram style,\nor my processes, my documents, not",
    "start": "501164",
    "end": "509034"
  },
  {
    "text": "getting knowledge from elsewhere. So in all the demos, one of the things\nthat I was missing was, how do I make it",
    "start": "509305",
    "end": "515135"
  },
  {
    "text": "go down a particular path that I want? Right. If the answer is not quite\nright, how do I control it? So I think a lot more around.",
    "start": "515255",
    "end": "521125"
  },
  {
    "text": "How do I bring this to my enterprise\nclients and deliver value for them? Those are some of the open questions. Chris, do you have\nsomething similar to that?",
    "start": "521505",
    "end": "528224"
  },
  {
    "text": "Totally, I do want to get into that. I see Chris coming off mute though,\nso I don't want to break his role. I don't know if Chris, you got\nkind of a view on this, or if you",
    "start": "528225",
    "end": "533665"
  },
  {
    "text": "disagree, you're like, ah, it's\nactually not that impressive. Google glasses back, baby.",
    "start": "533665",
    "end": "538715"
  },
  {
    "text": "Yeah. So I, I think, I think multimodality\nis a huge thing, as Shobhit",
    "start": "538915",
    "end": "545695"
  },
  {
    "text": "covered it correctly, right? There's so many use cases. Yeah. in the enterprise, but also\nin consumer based scenarios.",
    "start": "545735",
    "end": "553760"
  },
  {
    "start": "546000",
    "end": "708000"
  },
  {
    "text": "And I think one of the things we really\nneed to think about is we've been working with LLMs for so long now,\nwhich has been great, but the 2D tech",
    "start": "553760",
    "end": "561040"
  },
  {
    "text": "space isn't enough for generative AI. It's, it's, we want to be\nable to interact real time.",
    "start": "561090",
    "end": "568139"
  },
  {
    "text": "We want to be able to interact with audio. Um, you know, and you can take that to\nthings like contact centers where you",
    "start": "568140",
    "end": "573709"
  },
  {
    "text": "want to be able to transcribe that audio. You want to then have AIs be able\nto respond back in a human way.",
    "start": "573719",
    "end": "578890"
  },
  {
    "text": "And you want to chat with the assistants. Like you'd like you saw\nin the open AI demo. Uh, you know, you don't want to\nbe sitting there and go, well, you",
    "start": "578959",
    "end": "585160"
  },
  {
    "text": "know, my conversation is going to\nbe as fast as my fingers can type. You want to be able to say, Hey.",
    "start": "585160",
    "end": "590540"
  },
  {
    "text": "you know, what do you think about this? What about that? And you want to imagine new scenarios. So you want to say, what\ndoes this model look like?",
    "start": "590600",
    "end": "597700"
  },
  {
    "text": "What does this image look like? You know, tell me what this is. And you want to be able to\ninteract with the world around you.",
    "start": "597710",
    "end": "603300"
  },
  {
    "text": "And to be able to do that, you\nneed multimodal, uh, models. And, and therefore, Like in the Google\ndemo, where, you know, yeah, she picked",
    "start": "603380",
    "end": "613680"
  },
  {
    "text": "up the glasses again, you know, so\nI jokingly said Google glasses back, but, but it really is, it's, if you're\ngoing and having a shopping experience,",
    "start": "613680",
    "end": "621550"
  },
  {
    "text": "retail, and you want to be able to look\nat what the price of a mobile phone is, for example, you're not going to\nwant to stop getting phone out, type,",
    "start": "621550",
    "end": "628819"
  },
  {
    "text": "type, type, you just want to be able\nto interact with an assistant there and then, or seeing your glasses, what the\nprice is, and I give the mobile phone",
    "start": "628820",
    "end": "636540"
  },
  {
    "text": "example for a reason, I Which is, the\nprice that I pay for a mobile phone isn't",
    "start": "636540",
    "end": "642125"
  },
  {
    "text": "the same price as you would pay, right? Because it's all contract rates. And if I go and speak, if I want to\nget the price of how much am I paying",
    "start": "642165",
    "end": "649683"
  },
  {
    "text": "for that phone, it takes an advisor\nlike 20 minutes, because they have to go look up your contract details, etc.",
    "start": "649685",
    "end": "656055"
  },
  {
    "text": "They have to look up what the\nphone is, and then they do a deal. In a world of multi modality,\nwhere you've got something like",
    "start": "656294",
    "end": "661905"
  },
  {
    "text": "glasses on, it can recognize the\nobject, it knows who you are. And then it can go and look up what, uh,\nwhat the price of the phone is for you.",
    "start": "661915",
    "end": "669813"
  },
  {
    "text": "And then be able to answer questions\nthat are not generic questions, but specific about you, your contract.",
    "start": "670095",
    "end": "675125"
  },
  {
    "text": "To you. Right. Exactly. That, that is where multi modality\nis going to start, start to come in.",
    "start": "675345",
    "end": "681185"
  },
  {
    "text": "I mean, it kind of sounds\nlike, right, yeah, totally. I mean, Chris, if I have you right, I\nmean, this is one of the questions I want",
    "start": "681185",
    "end": "686605"
  },
  {
    "text": "to pitch to both you, Shobhit, and you,\nChris, on this is, You know, I actually, my mind goes directly back to Google\nGlass, like the bar where the guy got",
    "start": "686615",
    "end": "694010"
  },
  {
    "text": "beat up for wearing Google Glass years\nago, that was like around the corner from where I used to live in San Francisco.",
    "start": "694030",
    "end": "698830"
  },
  {
    "text": "And you know, there's just been this\ndream and obviously all the open AI demos and Google demos for that\nmatter are all very consumer, right?",
    "start": "699360",
    "end": "706489"
  },
  {
    "text": "You're walking around with your\nglasses and you're looking around the world and you know, get\nprices and that kind of thing. This has been like a longstanding\nSilicon Valley dream and it's",
    "start": "706739",
    "end": "713480"
  },
  {
    "start": "708000",
    "end": "1014000"
  },
  {
    "text": "been very hard to achieve. And I guess the one thing I wanted\nto run by you is like, And the answer might just be both, or we don't know,\nis like, if you're more bullish on the",
    "start": "713480",
    "end": "721019"
  },
  {
    "text": "B2B side or on the B2C side, right? Because I hear what Shobit's saying,\nand I'm like, oh, okay, I can see",
    "start": "721020",
    "end": "726199"
  },
  {
    "text": "why enterprises really get a huge\nbonus from this sort of thing. Um, and, and I guess it's really funny\nto me, because I think there's one",
    "start": "726199",
    "end": "732659"
  },
  {
    "text": "point of view, which is everybody's\ntalking about the consumer use case, but the actual near term impact may\nactually be more on the enterprise side.",
    "start": "732659",
    "end": "738900"
  },
  {
    "text": "But I don't know if you guys buy\nthat, or if you really are, like, this is the era of Google Glass,\nyou know, it's back, baby, so.",
    "start": "739160",
    "end": "743850"
  },
  {
    "text": "I can start first, Tim. Um, like I've, we've been working\nwith Apple Vision quite a bit, um,",
    "start": "745325",
    "end": "750665"
  },
  {
    "text": "uh, with an IBM with our clients. And a lot of those are enterprise use\ncases in a very controlled environment.",
    "start": "750744",
    "end": "756204"
  },
  {
    "text": "So things that where things break\nin the consumer world, you don't have a controlled environment. You have corner cases\nthat happen a lot, right?",
    "start": "756525",
    "end": "763875"
  },
  {
    "text": "In an enterprise setting, If I'm\nwearing my Vision Pros for two",
    "start": "764454",
    "end": "769760"
  },
  {
    "text": "hours at a stretch doing, I'm a\nmechanic, I'm fixing things, right? That's a place where I need additional\ninput and I can't go look at other things",
    "start": "769760",
    "end": "778480"
  },
  {
    "text": "like pick up my cell phone and work on it. I'm underneath, I'm fixing something\nin the middle of it, right?",
    "start": "778480",
    "end": "783569"
  },
  {
    "text": "So those use cases, because the\nenvironment is very controlled, I can do AI with higher accuracy, it's reputable.",
    "start": "783920",
    "end": "790970"
  },
  {
    "text": "I know I can start crossing the\nanswers because I have enough data coming out from it, right? So you're not trying\nto solve every problem.",
    "start": "791185",
    "end": "796295"
  },
  {
    "text": "But I think we'll see a higher\nuptake of these devices. By the way, I love the Ray\nBan glasses from Meta as well.",
    "start": "796625",
    "end": "803784"
  },
  {
    "text": "Great to do something quick, but\nwhen you don't want to switch. But I think we're moving to a point\nwhere enterprises will go deliver these",
    "start": "803954",
    "end": "812305"
  },
  {
    "text": "at scale, the tech starts to get better. And adoption is going to\ncome over on the B2C side.",
    "start": "812314",
    "end": "817680"
  },
  {
    "text": "But in the consumer goods, we'll\nhave multiple attempts at this. Like we had with Google Glasses and stuff. It'll take a few attempts to get better.",
    "start": "818140",
    "end": "824000"
  },
  {
    "text": "On the enterprise side, we will learn\nand make the models a lot better. But I think there's an insane amount\nof value that we're delivering",
    "start": "824329",
    "end": "830390"
  },
  {
    "text": "to our clients with Apple Vision\nPro today in enterprise settings. I think it's going to follow that.",
    "start": "830390",
    "end": "835270"
  },
  {
    "text": "Totally. Yeah. And it's actually interesting. I hadn't really thought about this. And Chris, I'll let you get in. It's like, um, basically like\nthe phone is almost not as big of",
    "start": "835850",
    "end": "842850"
  },
  {
    "text": "competition in the enterprise setting. Right. Whereas like the example that Chris gave\nwas like literally there you're trying to be like, is this multimodal device faster\nthan using my phone in that interaction?",
    "start": "842870",
    "end": "853000"
  },
  {
    "text": "Which is like a real competition, but\nif it's something like a mechanic, you know, they don't have, they don't,\nthey can't just pull out their phone.",
    "start": "853355",
    "end": "858375"
  },
  {
    "text": "Um, Chris, any final thoughts on this? And then I want to move\nus to our next topic. Yeah. And I was just going to give\nanother kind of use case scenario.",
    "start": "858435",
    "end": "864565"
  },
  {
    "text": "I, I often think of things like\nthe oil rigs example, example. So a real sort of enterprise space where\nyou're wandering around and you have to",
    "start": "864625",
    "end": "872695"
  },
  {
    "text": "go and do safety checks on various things. Most of their time, if you think of\nthe days before the mobile phone or",
    "start": "872695",
    "end": "879580"
  },
  {
    "text": "before the tablet, what they would have\nto do is go look at the part, do the inspection, the visual inspection, and\nthen walk back to a PC to go fill that in.",
    "start": "879580",
    "end": "887139"
  },
  {
    "text": "And then these days, you do that\nwith a tablet on the rig, right? But, but then actually, you need to\nfind the component you're going to look",
    "start": "887140",
    "end": "893368"
  },
  {
    "text": "at, you have to do the defect analysis. You want to be able to\ntake pictures of that. You need the geo location of\nwhere that part is so that",
    "start": "893369",
    "end": "901060"
  },
  {
    "text": "the next person can find it. And then you want to be able to see\nthe notes that they had before on this.",
    "start": "901060",
    "end": "906500"
  },
  {
    "text": "And then you've got to fill\nin the safety form, right? So they have to fill in a ton of forms. So there's a whole set of information.",
    "start": "906500",
    "end": "913200"
  },
  {
    "text": "If you just think about AI, just having. You know, even your phone or glasses\npick either to be able to look at",
    "start": "913219",
    "end": "919860"
  },
  {
    "text": "that part, be able to have the notes\ncontextualized in that geospatial space, be able to fill in that form,\nbe able to do an analysis with AI.",
    "start": "919860",
    "end": "927350"
  },
  {
    "text": "It's, it's got a huge impact on enterprise\ncases and probably multimodality in that",
    "start": "927620",
    "end": "933670"
  },
  {
    "text": "sense has probably got a bigger impact,\nI would say, in the enterprise cases than the consumer spaces even today.",
    "start": "933670",
    "end": "939360"
  },
  {
    "text": "And I, and I think that's something\nwe really need to think about. The other one is. And again, I know you wanted\nthis to be quick there, Tim,",
    "start": "939680",
    "end": "946730"
  },
  {
    "text": "is the clue and generative AI\nis the generative part, right? So actually I can create images,\nI can create audio, I could create",
    "start": "947010",
    "end": "957310"
  },
  {
    "text": "music things that don't exist today. So, and with the text part of\nsomething like an LLM, Then I",
    "start": "957310",
    "end": "963824"
  },
  {
    "text": "can create new creative stuff. I can create DevOps pipelines,\nDocker files, whatever.",
    "start": "963824",
    "end": "968685"
  },
  {
    "text": "So there comes a part where I want\nto visualize the thing that I create. I don't want to be copying and pasting\nfrom one system to another, right?",
    "start": "968964",
    "end": "978923"
  },
  {
    "text": "That's not any different\nfrom the oil rig scenario. So as I start to imagine new new\nbusiness processes, new pipelines,",
    "start": "978944",
    "end": "986430"
  },
  {
    "text": "new, uh, tech processes, I then want\nto be able to have the real time visualization of that at the same\ntime, or be able to interact with that.",
    "start": "986450",
    "end": "993690"
  },
  {
    "text": "And that's why multi modality\nis, is really important, probably more so in the enterprise space. Yeah, that's right.",
    "start": "993730",
    "end": "999269"
  },
  {
    "text": "I mean, I think some of the\nexperiments you're seeing with, like, dynamic visualization generation\nare just, like, very cool, right?",
    "start": "999270",
    "end": "1005040"
  },
  {
    "text": "Uh, cause then you basically have\nYou can say, like, here's how I want to interact with the data. The system kind of just generates\nit, right, on the fly, which I",
    "start": "1005370",
    "end": "1012694"
  },
  {
    "text": "think is very, very exciting.",
    "start": "1012694",
    "end": "1013665"
  },
  {
    "start": "1014000",
    "end": "1255000"
  },
  {
    "text": "All right, so next up, I want\nto talk about latency and cost. So this is another big trend, you know,\nI think it was very interesting that",
    "start": "1019104",
    "end": "1025134"
  },
  {
    "text": "both companies went out of their way\nto be like, we've got this offering and it's way cheaper for everybody,\nwhich I think suggests to me that, you",
    "start": "1025135",
    "end": "1032905"
  },
  {
    "text": "know, these big, huge competitors in AI\nall recognize That like your, your per token cost is gonna be this huge bar to\ngetting the technology more distributed.",
    "start": "1032905",
    "end": "1041169"
  },
  {
    "text": "Um, so certainly one of the ways\nthey sold 4.0 was that it was cheaper and as good as GPT, right?",
    "start": "1041260",
    "end": "1048369"
  },
  {
    "text": "And everybody was kind of like, okay,\nwell why do I pay for Pro anymore if I'm just gonna get this for, for free? And then Google's bid, of course,\nwas Gemini 1.5 flash, right?",
    "start": "1048375",
    "end": "1055779"
  },
  {
    "text": "Which is okay, it's gonna\nbe cheaper and faster again. Um, and I know Chris, you threw this.",
    "start": "1055780",
    "end": "1060758"
  },
  {
    "text": "Uh, sort of topic out, so I'll kind of\nlet you have the first say, but I think the main question I'm left with is,\nlike, what are the downstream impacts of",
    "start": "1061145",
    "end": "1067934"
  },
  {
    "text": "this, right, for someone who's not really\npaying attention to AI very closely, like, is this just a matter of, like,\nit's getting cheaper, or do you think,",
    "start": "1067935",
    "end": "1074114"
  },
  {
    "text": "like, these are actually, these economics\nare kind of changing how the technology is actually going to be rolled out?",
    "start": "1074115",
    "end": "1078475"
  },
  {
    "text": "I think latency and smaller models and\ntokens are probably one of the most",
    "start": "1079435",
    "end": "1085889"
  },
  {
    "text": "interesting challenges we have today. So if you think about like\nthe GPT 4 and everybody was",
    "start": "1085889",
    "end": "1091530"
  },
  {
    "text": "talking like, oh, that's a 1. 8 trillion model or whatever\nit is, that's great.",
    "start": "1091530",
    "end": "1096560"
  },
  {
    "text": "But the problem with these large models\nis every layer that you have in the neural",
    "start": "1096890",
    "end": "1103479"
  },
  {
    "text": "network is adding time to get a response\nback, and not only time, but cost.",
    "start": "1103479",
    "end": "1109725"
  },
  {
    "text": "So if you look at the demo that OpenAI\ndid, for example, what was really cool",
    "start": "1110044",
    "end": "1115743"
  },
  {
    "text": "about that demo was the fact that when\nyou were speaking to the assistant, it was",
    "start": "1115745",
    "end": "1120535"
  },
  {
    "text": "answering pretty much instantly, right? And that is the real important part.",
    "start": "1120885",
    "end": "1125945"
  },
  {
    "text": "And when we look at previous demos,\nwhat you would have to do if you were having a voice interaction is you'd\nbe stitching together kind of three",
    "start": "1125995",
    "end": "1133984"
  },
  {
    "text": "different pipelines you need to do Uh,\nspeech to text, then you're going to run that through the model, and then you're\ngoing to do text to speech back the",
    "start": "1133984",
    "end": "1141139"
  },
  {
    "text": "way, so you're getting latency, latency,\nlatency, before you get a response, and that timing that it would take, because\nit's not in the sort of 300 millisecond",
    "start": "1141140",
    "end": "1150710"
  },
  {
    "text": "mark, it was too long for a human being\nto be able to interact, so you got this massive pause, so actually, the, latency\nand the kind of tokens per second becomes",
    "start": "1150710",
    "end": "1160510"
  },
  {
    "text": "the most important thing if you want to\nbe able to interact with models quickly and be able to have those conversations.",
    "start": "1160510",
    "end": "1166970"
  },
  {
    "text": "And that's sort of why also multimodality\nis really important, because if I can do this in one model as well,\nthen it means that I'm not sort",
    "start": "1166999",
    "end": "1175398"
  },
  {
    "text": "of jumping pipelines all the time. So the smaller you can make the\nmodel, the faster it's going to be.",
    "start": "1175399",
    "end": "1181490"
  },
  {
    "text": "Now, if you look at the GPT 4. on the model. I don't know if you've played\nwith just the text mode.",
    "start": "1181760",
    "end": "1187070"
  },
  {
    "text": "It is lightning fast when it comes. Very fast now. Yeah, it is. It's noticeably so like, it's just\nlike, it feels like every time I'm in,",
    "start": "1187420",
    "end": "1194880"
  },
  {
    "text": "there's like these improvements, right? Yeah. And this is what you're doing. You're sort of trading off reasoning\nversus, uh, speed of the model, right?",
    "start": "1194890",
    "end": "1203730"
  },
  {
    "text": "And, and as we move into kind\nof agentic platforms, as we",
    "start": "1203780",
    "end": "1208860"
  },
  {
    "text": "move into the multimodality. You need that latency to be super,\nsuper sharp, because you're not",
    "start": "1208860",
    "end": "1214355"
  },
  {
    "text": "going to be waiting all the time. So, there is going to be scenarios\nwhere you want to move back to a bigger model, that is fine.",
    "start": "1214355",
    "end": "1220125"
  },
  {
    "text": "Um, but you're going\nto be paying the cost. And that cost is going to be the cost,\nuh, the price of the tokens in the first",
    "start": "1220395",
    "end": "1227444"
  },
  {
    "text": "place, but also the speed of the response. And I think this is the push\nand pull that model creators",
    "start": "1227445",
    "end": "1232865"
  },
  {
    "text": "are going to be playing against. All of the time and, and, and therefore\nif you can a similar result from a",
    "start": "1232865",
    "end": "1240825"
  },
  {
    "text": "smaller model and you can get a similar\nresult from a faster model and a cheaper model, then you're going to go for that.",
    "start": "1240835",
    "end": "1247644"
  },
  {
    "text": "But in those cases where it's not,\nthen you may need to go to the larger model to kind of reason. So this, this is really",
    "start": "1247684",
    "end": "1253505"
  },
  {
    "text": "Totally. Yeah. I think there's a bunch\nof things to say there. I mean, I think one thing that you've\npointed out clearly is that like this makes conversation possible.",
    "start": "1253505",
    "end": "1259654"
  },
  {
    "start": "1255000",
    "end": "1479000"
  },
  {
    "text": "Right, like that you and I can\nhave a conversation in part because I have low latency is\nkind of the way to think about it.",
    "start": "1259935",
    "end": "1265155"
  },
  {
    "text": "And like now that we're reaching\nkind of human like parity on latency, you know, finally these models can\nkind of converse in a certain way.",
    "start": "1265415",
    "end": "1271504"
  },
  {
    "text": "The other one is actually, I really\nthought about that there is kind of this almost like thinking fast and\nslow thing where basically like the",
    "start": "1271785",
    "end": "1277334"
  },
  {
    "text": "models can be faster, but they're\njust not as good at reasoning. Um, and then there's kind of this\nlike deep thinking mode, which",
    "start": "1277334",
    "end": "1283425"
  },
  {
    "text": "actually is like slower in some ways. So Tim, uh, the way we are helping. Enterprise clients, again, have\nthat kind of focus in life.",
    "start": "1283425",
    "end": "1290540"
  },
  {
    "text": "There is a split. There's a, there's a, there are\ntwo ways of looking at applying Gen AI in the industry right now.",
    "start": "1291120",
    "end": "1296179"
  },
  {
    "text": "One is at the use case level. You're looking at the whole workflow\nend to end, seven different steps.",
    "start": "1296580",
    "end": "1301630"
  },
  {
    "text": "The other is going and looking\nat it at a sub task level. Right, so I'll just pick an\nexample and walk you through it.",
    "start": "1302619",
    "end": "1308030"
  },
  {
    "text": "So say I have an invoice that comes\nin and I'm taking an application, I'm pulling something out of it, I'm\nmaking sure that that's as per the",
    "start": "1308510",
    "end": "1315609"
  },
  {
    "text": "contract, I'm going to send you an email\nsaying your invoice is paid, right? So some sort of a flow like that, right?",
    "start": "1315609",
    "end": "1321600"
  },
  {
    "text": "So say it is seven steps,\njust very simplified, right? I'm going to pull things from\nthe back end systems using APIs.",
    "start": "1321910",
    "end": "1328510"
  },
  {
    "text": "Step number three, I'm going to go\nA fraud detection model that has been working great for three years.",
    "start": "1328520",
    "end": "1333534"
  },
  {
    "text": "Step number four, I'm\nextracting things from a paper. Right, an invoice that came in. That extraction I used\nto be doing with OCR.",
    "start": "1333895",
    "end": "1340885"
  },
  {
    "text": "85 percent accuracy, humans\nwill do the overflow of it. At that point we're taking a pause\nand saying, we have reason to believe",
    "start": "1341435",
    "end": "1348134"
  },
  {
    "text": "that LLMs today can look at an image\nand extract this with higher accuracy. Yeah. Say we get up to 94%.",
    "start": "1348134",
    "end": "1353605"
  },
  {
    "text": "So that's nine points, uh, higher\naccuracy of pulling things out. So we pause at that point and say, let's\ncreate a set of constraints for step",
    "start": "1354330",
    "end": "1362250"
  },
  {
    "text": "number four to find the right athletes. And the constraint could\nbe, what's the latency?",
    "start": "1362250",
    "end": "1367319"
  },
  {
    "text": "Like we just spoke, how quickly I\nneed the result, or can this take 30 seconds and I'll be okay with it? Yeah. Second could be around cost.",
    "start": "1367359",
    "end": "1373470"
  },
  {
    "text": "If I'm doing this a thousand\ntimes, I have a cost envelope to work with versus a human doing it. If I'm doing it a million times, I\ncan invest a little bit more if I",
    "start": "1373880",
    "end": "1381170"
  },
  {
    "text": "can get accuracy out of it, right? So the ROI becomes important. Then you're looking at security\nconstraints around, does this data",
    "start": "1381170",
    "end": "1387470"
  },
  {
    "text": "have any identifiable PHI data,\nPII I have to bring things closer.",
    "start": "1387470",
    "end": "1392890"
  },
  {
    "text": "Or is this something that is\nmilitary grade secrets and has to be on prem, right? So you have certain\nconstraints around that.",
    "start": "1393130",
    "end": "1398300"
  },
  {
    "text": "So you come up with a list of\nfive, six constraints, and then that lets you decide whether. What kind of an LLM will actually\ncheck off all these different",
    "start": "1398570",
    "end": "1405875"
  },
  {
    "text": "constraints, and then you start\ncomparing and bringing it in. So the spirit that we're seeing in the\nmarket is one way with LLM agents and",
    "start": "1405875",
    "end": "1413075"
  },
  {
    "text": "with these multi modal models, they're\ntrying to accomplish the entire flow work for end to end, like you saw\nwith Google's returning the shoes.",
    "start": "1413075",
    "end": "1419814"
  },
  {
    "text": "It's taking an image of it, it's going and\nlooking at your Gmail to find the receipt, starting the return, giving you a QR\ncode with the whole return process done.",
    "start": "1420650",
    "end": "1428010"
  },
  {
    "text": "So just figure it out how to go\ncreate the entire end to end workflow. But where the enterprises are still\nfocused is more on the sub task level.",
    "start": "1428379",
    "end": "1435760"
  },
  {
    "text": "That point we are saying, This step number\nfour is worth switching and I have enough evals before and after, I have enough\nmetrics to understand, and I can control",
    "start": "1436200",
    "end": "1445420"
  },
  {
    "text": "that, I can audit that much better. The thing that from an enterprise\nperspective, these end to end multimodal",
    "start": "1445420",
    "end": "1450299"
  },
  {
    "text": "models, it'll be difficult for us\nto explain to SEC, for example, why we rejected somebody's benefits on a\ncredit card, things of that nature.",
    "start": "1450810",
    "end": "1459000"
  },
  {
    "text": "So I think in the, in the enterprise\nworld, we're going to go down the path of, Let me define the process.",
    "start": "1459000",
    "end": "1464590"
  },
  {
    "text": "I'm going to pick small models to Chris's\npoint to do that particular piece better. And then eventually start moving over to,\nand now let me make sure that those, that",
    "start": "1465060",
    "end": "1473320"
  },
  {
    "text": "framework evals and all that stuff can be\napplied to end to end multimodal models. I guess I do want to\nmaybe bring in Brian here.",
    "start": "1473579",
    "end": "1480545"
  },
  {
    "start": "1479000",
    "end": "1812000"
  },
  {
    "text": "You like release the Brian\non this conversation. Um, cause I, I'm curious about like, kind\nof like the marketer's view on all this.",
    "start": "1480545",
    "end": "1487375"
  },
  {
    "text": "Right. Cause I think there's one point of\nview, which is yes, yes, Chris, show a bit like this is all nerd stuff, right?",
    "start": "1487405",
    "end": "1492434"
  },
  {
    "text": "Like I, you know, it's like latency\nand cost and speed and whatever. The big thing is that you can\nactually talk to these AIs.",
    "start": "1492435",
    "end": "1498554"
  },
  {
    "text": "Right. And I guess I'm kind of curious from\nyour point of view about like, I mean, one really big thing that came out of\nlike the open AI announcements was.",
    "start": "1498865",
    "end": "1505924"
  },
  {
    "text": "Yeah. We're going to use this latency\nthing largely to kind of create this feature that just feels a lot more\nhuman and lifelike, um, than, you",
    "start": "1505935",
    "end": "1513525"
  },
  {
    "text": "know, typing and chatting with an AI. And I guess I'm kind of curious\nabout, like, you know, what you",
    "start": "1513525",
    "end": "1518875"
  },
  {
    "text": "think about that move, right? Like, is that ultimately, like, Like\ngoing to help the adoption of AI? Is it just kind of like a weird sci\nfi thing that OpenAI wants to do?",
    "start": "1518885",
    "end": "1526434"
  },
  {
    "text": "And also, I mean, I think if you've\ngot any thoughts on, you know, how it impacts the enterprise as well,\nwhich is like, do companies suddenly",
    "start": "1526645",
    "end": "1532295"
  },
  {
    "text": "say, Oh, I understand this now, right? It's because it's like the AI from her. I can buy this. Um, just kind of interesting thinking\nabout like the, the sort of surface part",
    "start": "1532295",
    "end": "1540064"
  },
  {
    "text": "of this, because it actually will really\nhave a big impact on the market as well. It's kind of like the technical advances\nare driving the marketing of this.",
    "start": "1540064",
    "end": "1545945"
  },
  {
    "text": "I mean, I do think when you, when\nyou look at like some of the initial reviews of, I don't know, honestly like\nthe pin and rabbit like I remember one",
    "start": "1546595",
    "end": "1555050"
  },
  {
    "text": "of the one of the scenarios that was\nbeing demoed was I think they were I think he was looking at a car and he\nwas asking a question about it and The",
    "start": "1555050",
    "end": "1563120"
  },
  {
    "text": "whole interaction took like 20 seconds\nthere and he went through his it was just showing that he could do the whole\nthing On his phone in the same amount of",
    "start": "1563120",
    "end": "1569449"
  },
  {
    "text": "time but the thing that I was thinking\nabout when I was watching that was like He just did like 50 steps on his phone.",
    "start": "1569449",
    "end": "1574525"
  },
  {
    "text": "That was awful. As opposed to just pushing a\nbutton and asking a question. And it was like, it was very clear that\nthe UX interaction of just like, like",
    "start": "1574555",
    "end": "1582345"
  },
  {
    "text": "asking the question and looking at the\nthing, was a way better experience than pushing the 50 buttons on your phone.",
    "start": "1582404",
    "end": "1588555"
  },
  {
    "text": "But the 50 buttons still won just because\nit was faster to do 50 buttons than to, you know, deal with the latency\nimpact of, um, of where we were before.",
    "start": "1588905",
    "end": "1596615"
  },
  {
    "text": "And so it actually, it reminded me a\nlot of, Just the way I used to hear, remember hearing Spotify talk early\nabout the way that they thought about",
    "start": "1596625",
    "end": "1605060"
  },
  {
    "text": "latency and the things that they did\nto just make the first 15 seconds of a song land, um, essentially, so that it\nfelt like, you know, appeal, like a file",
    "start": "1605070",
    "end": "1614189"
  },
  {
    "text": "that you had on your device, because\nI think from their perspective, They, it felt like every time you wanted to\nlisten to a song that was buffering as",
    "start": "1614190",
    "end": "1620570"
  },
  {
    "text": "opposed to sitting on your device, you\nwere never going to really adopt that thing because it's a horrible experience\nrelative to just having the file locally.",
    "start": "1620570",
    "end": "1627070"
  },
  {
    "text": "And so they put in all this\nwork so that it felt the same. And that wound up being a huge part of\nhow the technology ended up getting and",
    "start": "1627390",
    "end": "1634479"
  },
  {
    "text": "the product ended up getting adopted. And, you know, I do think there's a lot\nof, a lot of stuff we're doing that.",
    "start": "1634479",
    "end": "1641179"
  },
  {
    "text": "It's almost like, I don't want to say\nback office, but like just enterprise processes around how people do things,\noperational things, but there are plenty",
    "start": "1641460",
    "end": "1650130"
  },
  {
    "text": "of ways where people are thinking about\nthe way that we do more with like agents in terms of how that involves like\ncustomer experience, whether it's support",
    "start": "1650130",
    "end": "1656940"
  },
  {
    "text": "interactions, whether it's like bots on\nthe site, you can just Clearly imagine that that's going to play a bigger role\nin customer experience going far forward.",
    "start": "1656950",
    "end": "1665000"
  },
  {
    "text": "And if you feel like every time you\nask a question that you're waiting 20 seconds to get a response from this thing.",
    "start": "1665450",
    "end": "1670710"
  },
  {
    "text": "Like you're just getting the other\nperson on the end of that interaction is just getting madder and madder\nand madder the entire time. Where the more it feels like\nyou're talking to a person",
    "start": "1670720",
    "end": "1678190"
  },
  {
    "text": "and that they're responding to\nyou as fast as you're talking. I think the more likely it is\nthat people are going to accept that as an interaction model.",
    "start": "1678190",
    "end": "1684335"
  },
  {
    "text": "Um, and so I do think that that latency\nand like making that feel to you,",
    "start": "1684345",
    "end": "1689625"
  },
  {
    "text": "like to your point about having a\nhuman beings being zero latency, um, I think that's a necessary condition\nfor a lot of these interaction models.",
    "start": "1689675",
    "end": "1696835"
  },
  {
    "text": "And so it's going to be super\nimportant going forward. And to me, it's also when I think\nabout the Spotify thing, it's like, Are people are going to do\ninteresting things to solve for the",
    "start": "1696835",
    "end": "1703900"
  },
  {
    "text": "first 15 seconds of an interaction\nas opposed to the entire interaction? Like, you know, can you get,\nthere was a lot of talk about like",
    "start": "1703900",
    "end": "1711128"
  },
  {
    "text": "opening, I'm small I want to say like\nresponding with like, sure, or just like some space filling entry point.",
    "start": "1711640",
    "end": "1717960"
  },
  {
    "text": "Um, so it like, it could catch\nup with the rest of the dialogue. So I think it, I think people\nwill prioritize that a lot",
    "start": "1717989",
    "end": "1723539"
  },
  {
    "text": "because it don't matter a lot. I mean, I love the idea that like\nto save to save cost, basically, OpenAI is like, for the first\nfew turns of the conversation, we",
    "start": "1723660",
    "end": "1729695"
  },
  {
    "text": "deliver the really fast model, so\nit feels like you're really having, like, a nice, flowing conversation. And then, basically, once you build\nconfidence, they, like, fall back to,",
    "start": "1729695",
    "end": "1736084"
  },
  {
    "text": "like, the slower model that has better\nresults, where you're like, oh, this person is a good conversationalist, but\nthey're also smart, too, right, is, like,",
    "start": "1736084",
    "end": "1742405"
  },
  {
    "text": "kind of what they're trying to do by,\nkind of, playing with model delivery. Um, so. We got to talk about search, but\nChris, I saw you go off mute, so do",
    "start": "1742415",
    "end": "1749705"
  },
  {
    "text": "you want to do a final quick hit on the\nquestion of latency before we move on? No, I was just coming to come up with\nwhat Brian was saying there, and what",
    "start": "1749705",
    "end": "1756375"
  },
  {
    "text": "you were saying, Tim, I totally agree. It was always doing this, hey, and\nthen repeat the question, so I wonder",
    "start": "1756375",
    "end": "1763355"
  },
  {
    "text": "if underneath the hood, as you say,\nis there's a much smaller classifier model that is just doing that hey piece.",
    "start": "1763355",
    "end": "1769385"
  },
  {
    "text": "And then as you say, there's\nprobably a slightly larger model actually analyzing the real thing.",
    "start": "1769655",
    "end": "1775344"
  },
  {
    "text": "So I do wonder if there's two small model,\na small model and a slightly larger model",
    "start": "1775345",
    "end": "1780745"
  },
  {
    "text": "in between there for that interaction. So it's super interesting. But maybe the thing I wanted to\nadd to that is we don't have that",
    "start": "1780804",
    "end": "1788929"
  },
  {
    "text": "voice model in our hands today. We only have the text model. So I wonder once we get out of\nthe demo environment and then",
    "start": "1788940",
    "end": "1796340"
  },
  {
    "text": "maybe in a three weeks time or\nwhatever, we have that model. Whether that's gonna be super\nannoying every time we ask a",
    "start": "1796370",
    "end": "1803035"
  },
  {
    "text": "question, it's gonna go, Hey, and\nthen repeat the question back. So, it's cool for a demo, but I\nwonder if that will actually be",
    "start": "1803035",
    "end": "1810135"
  },
  {
    "text": "super annoying in two weeks time.",
    "start": "1810145",
    "end": "1811605"
  },
  {
    "start": "1812000",
    "end": "2244000"
  },
  {
    "text": "Alright, so, last topic that we\ngot a few minutes on, uh, and this is like, Brian's big moment. So, Brian, get yourself ready for this.",
    "start": "1816935",
    "end": "1823255"
  },
  {
    "text": "We've hyped this too much. I mean, show the Chris, you should\nget yourself ready, cause apparently Bryan's gonna, you know, you know. Everyone else can leave the meeting.",
    "start": "1823335",
    "end": "1828610"
  },
  {
    "text": "Yeah, yeah, take our eyebrows off\nhere with his, uh, with his rant. So, the, the setup for this is\nthat basically Google announced,",
    "start": "1828620",
    "end": "1835660"
  },
  {
    "text": "uh, that AI generated overviews\nwill be rolling out to U. S. users and then everybody,\nuh, in the near future.",
    "start": "1835780",
    "end": "1842959"
  },
  {
    "text": "And I think there's two things\nthat are to set you up, Brian. I think the first one is, this is\nwhat we've been talking about, right? Like, is AI going to replace search?",
    "start": "1843530",
    "end": "1849610"
  },
  {
    "text": "Here it is. You know, here it is consuming. The preeminent search engine. So I think it's like, we're here, right?",
    "start": "1849990",
    "end": "1855975"
  },
  {
    "text": "This is happening. And then the second one is\nlike, I'm a little nostalgic. You know, someone who grew up with Google. Um, you know, I'm like the ten blue links.",
    "start": "1855975",
    "end": "1863455"
  },
  {
    "text": "You know, like the search engine. You know, it's like a big part of how\nI experienced and grew up with the web. And um, You know, this seems to me\nlike kind of a big shift in how we",
    "start": "1863494",
    "end": "1871720"
  },
  {
    "text": "interact with the web as a whole. And so, I do want you to kind of\nfirst talk a little about what you think it means for the market, um,\nand, uh, and how you think it's going",
    "start": "1871720",
    "end": "1879909"
  },
  {
    "text": "to change the economy of the web. So, I follow two communities, I\nwould say, pretty closely online.",
    "start": "1879909",
    "end": "1887010"
  },
  {
    "text": "I follow the tech community\nand, uh, pretty closely. And then I, as a, somebody who works in\nmarketing, I follow my SEOs community.",
    "start": "1887010",
    "end": "1894530"
  },
  {
    "text": "Um, and they have very different, um,\nReactions to, uh, to what's going on.",
    "start": "1894570",
    "end": "1899345"
  },
  {
    "text": "I think your first question, though,\nof, um, you know, is this the equivalent of swallowing the web?",
    "start": "1899575",
    "end": "1906305"
  },
  {
    "text": "Um, and from the minute, what's funny\nis from the minute sort of chat GPT arrived on the scene, people were\nproclaiming the death of search.",
    "start": "1906435",
    "end": "1913445"
  },
  {
    "text": "Now, for what it's worth, if you've\nworked in marketing or on the internet for a while, people have proclaimed\nThe death of search has like an annual",
    "start": "1913485",
    "end": "1919595"
  },
  {
    "text": "event for the last like 25 years. And so, um, this is just like par\nfor the course on, on some level.",
    "start": "1919935",
    "end": "1927155"
  },
  {
    "text": "But what's interesting to me is that you\nhad this product chat GPT, which is fast growing consumer product ever a hundred\nmillion users faster than anybody else.",
    "start": "1927545",
    "end": "1935045"
  },
  {
    "text": "And. What was interesting is sort of like\nspeed run, speed ran the sort of growth cycle that usually takes years or decades.",
    "start": "1935335",
    "end": "1942430"
  },
  {
    "text": "I'm like, well, maybe not decades,\nbut like it takes a long time for most consumer companies to do what they did. And the interesting thing about that is\nif it was gonna totally disrupt search,",
    "start": "1942480",
    "end": "1951479"
  },
  {
    "text": "you would have expected it to show up\nand happen sooner than it would have with other products that maybe would have\nhad a slower sort of growth trajectory.",
    "start": "1951589",
    "end": "1957949"
  },
  {
    "text": "Um, but that didn't happen. Like as somebody who watches\ntheir search traffic super",
    "start": "1958409",
    "end": "1963559"
  },
  {
    "text": "closely, like there's been no. chaotic drop of of this, like people\nhave continued to use search engines",
    "start": "1963560",
    "end": "1970585"
  },
  {
    "text": "and like one of the reasons I think\nthat that happened is because people actually misunderstood, um, like,\nlike the equivalent of like chat GPT",
    "start": "1970585",
    "end": "1978995"
  },
  {
    "text": "and Google as competitors, um, with\none another, I know Google and open AI probably are on some level, but I\ndon't know that those two products are.",
    "start": "1978995",
    "end": "1986054"
  },
  {
    "text": "And the reason I was thinking about that\nis like, if if chat GPT didn't You know,",
    "start": "1986615",
    "end": "1992050"
  },
  {
    "text": "within the within basically the time plan\nwe've had so far, uh, disrupt Google. The question is like, why,\nwhy didn't that happen?",
    "start": "1992050",
    "end": "1999210"
  },
  {
    "text": "And I think you could have a couple\ndifferent hypotheses for that. Like one, you could say the\nform factor wasn't right.",
    "start": "1999250",
    "end": "2004330"
  },
  {
    "text": "It wasn't text that was going to do it. It was, we needed Scarlett\nJohansson on your phone. And that's the thing\nthat's going to do it.",
    "start": "2004340",
    "end": "2009799"
  },
  {
    "text": "And so they're leaning into that\nthought process a little bit. You could say it was hallucinations,\nlike, oh, the content's just not accurate.",
    "start": "2009800",
    "end": "2016685"
  },
  {
    "text": "Uh, yeah, right. So that's a possibility around it. You could say just like\nlearn consumer behavior.",
    "start": "2016775",
    "end": "2022745"
  },
  {
    "text": "People have been using\nthis stuff for 20 years. It's going to take a while to get\nthem to do something different. You could say Google's\nadvantages in distribution.",
    "start": "2022745",
    "end": "2029005"
  },
  {
    "text": "So it's like we're on the phone. We got browsers. Um, it's really hard. to, you know, get the level\nof penetration that we have.",
    "start": "2029034",
    "end": "2035605"
  },
  {
    "text": "I think all of those\nprobably play some role. But my biggest belief is that it's\nactually impossible to separate",
    "start": "2035605",
    "end": "2041955"
  },
  {
    "text": "Google from the internet itself. Um, Google is kind of like the\noperating system for the web. So to disrupt Google, you actually\nare not disrupting search.",
    "start": "2042115",
    "end": "2049004"
  },
  {
    "text": "You have to disrupt the internet. Um, and it turns out that\nthat's an incredibly high bar, um, to have to disrupt.",
    "start": "2049005",
    "end": "2054155"
  },
  {
    "text": "Because you're not only dealing\nwith search, you're dealing with the capabilities, whether it's banks or,\nyou know, Airlines or, you know, retail,",
    "start": "2054155",
    "end": "2060565"
  },
  {
    "text": "whatever it is, every single website that\nsits on the opposite end of the internet. And it turns out that that's like\nan enormous amount of capability,",
    "start": "2060775",
    "end": "2068655"
  },
  {
    "text": "um, that's built up there. And so I looked at it, I look at that\nand say like for as much as Like I think",
    "start": "2068685",
    "end": "2075284"
  },
  {
    "text": "this, this technology is brought to\nthe table, hasn't done that thing yet. And so because it hasn't done that, there\nhasn't been some dramatic shift there.",
    "start": "2075755",
    "end": "2084105"
  },
  {
    "text": "The thing that Google search is not good\nat though, um, and I think you see it in a little bit in terms of how they\ndescribed, you know, What they think",
    "start": "2084715",
    "end": "2092659"
  },
  {
    "text": "the utility of AI overviews, um, will\nbe is that it's not good at complex",
    "start": "2092660",
    "end": "2098049"
  },
  {
    "text": "multi part questions of saying, like, if\nyou're trying to plan, if you're doing anything from, like, doing a buying\ndecision for a large enterprise product",
    "start": "2098050",
    "end": "2105679"
  },
  {
    "text": "or, like, planning your kid's birthday\nparty, like, you're going to have to do, like, 25 queries along the way there. And you just, you've just\naccepted and internalized 25",
    "start": "2105690",
    "end": "2114680"
  },
  {
    "text": "like, basically, like,\nsearch is one shot, right? Like, you just say it\nand responses come back. So there's no.",
    "start": "2114870",
    "end": "2119400"
  },
  {
    "text": "Yeah, sorry, go ahead. Yeah, and so, like, the way I was\nthinking about LLMs is they're kind of like Internet SQL, um, in a way,\nwhere you can ask this, like, much more",
    "start": "2120040",
    "end": "2128410"
  },
  {
    "text": "complicated question and then you can\nactually describe the way that you want the output of that thing to look it's\nlike, I want to compare these three",
    "start": "2128410",
    "end": "2134359"
  },
  {
    "text": "products on these three dimensions,\ngo get me all this data, and that would have been 40 queries, um, at one\npoint, but now you can do it in one.",
    "start": "2134359",
    "end": "2140740"
  },
  {
    "text": "And search is terrible\nat doing that right now. You have to go cherry pick\neach one of those data points.",
    "start": "2141380",
    "end": "2146540"
  },
  {
    "text": "But the interesting thing is that that's\nalso maybe the most valuable query to a user because you save 30 minutes.",
    "start": "2146970",
    "end": "2154590"
  },
  {
    "text": "And so I think Google looks at that and\nsays, Um, if we seed that particular space",
    "start": "2154890",
    "end": "2160615"
  },
  {
    "text": "of complex queries to some other platform,\nlike, that's a long term risk for us. And then if it's a long term risk for\nthem, what it ends up being is a long",
    "start": "2160615",
    "end": "2168744"
  },
  {
    "text": "term risk for the web, um, I think. So I actually think it was incredibly\nimportant that Google bring this type of capability into, into the web, even\nif it ends up being disruptive a little",
    "start": "2168744",
    "end": "2178315"
  },
  {
    "text": "bit from a publisher's perspective. Because what it does is at least preserves\nsome of the dynamic we have now, of",
    "start": "2178315",
    "end": "2184085"
  },
  {
    "text": "like the web still being an important. thing. And I hope that continues to your point. I have like present and past nostalgia.",
    "start": "2184085",
    "end": "2190845"
  },
  {
    "text": "Yeah, exactly. So I think it's, I think it's important\nthat it continues to evolve if we all",
    "start": "2190845",
    "end": "2196655"
  },
  {
    "text": "want the web to continue to persist\nas like a healthy dynamic place. Yeah, for sure. No, I think that's a,\nthat's a great take on it.",
    "start": "2196655",
    "end": "2202835"
  },
  {
    "text": "And you know, Google always used to say,\nlook, we measure our success based on how fast we get you off our website.",
    "start": "2202844",
    "end": "2207765"
  },
  {
    "text": "Right? And then kind of, Brian, what you're\npointing out, which I think is, is very true, is that like, what they\nnever said was, there's this whole",
    "start": "2207935",
    "end": "2213964"
  },
  {
    "text": "set of queries we never surface that,\nyou know, you really have to kind of keep, keep searching for, right? And like, that's, that ends up being\nkind of like, uh, the, the, the",
    "start": "2213965",
    "end": "2222344"
  },
  {
    "text": "search volume of the future that\neverybody wants to, to capture. Um, well, uh, so Brian, I think\nwe also had a little intervention",
    "start": "2222344",
    "end": "2229150"
  },
  {
    "text": "from AI, the thumbs up thing. We were joking about that before the show. It's just, yeah. I didn't know that My ranking\nfor worst AI feature of all time.",
    "start": "2229150",
    "end": "2236480"
  },
  {
    "text": "Um, so, um, but, um, yeah, the thumbnail on the, on the video. That's right.",
    "start": "2236510",
    "end": "2241969"
  },
  {
    "text": "Exactly. Um, well, great. So we've got just a few minutes\nleft Shobhit,  Chris, any final parting shots on this topic?",
    "start": "2242489",
    "end": "2248839"
  },
  {
    "start": "2244000",
    "end": "2463000"
  },
  {
    "text": "Sure. I'm very bullish. I think, uh, AI overviews. Have a lot of future as long as There's a\ngood mechanism of feedback incorporating",
    "start": "2249520",
    "end": "2260710"
  },
  {
    "text": "and making hyper personalized a simple\nquery like I want to go have dinner tonight Say I tell you I want to look\nfor a Thai restaurant Yeah If you look",
    "start": "2260710",
    "end": "2268630"
  },
  {
    "text": "if I go on open Open table or Yelp or\nGoogle and try to find that there's a particular way in which I think through\nit the filters that I Apply are very",
    "start": "2268639",
    "end": "2276109"
  },
  {
    "text": "different from how Chris would do it. Right? So the way I make a decision If somebody's\nmaking that decision for me, great.",
    "start": "2276109",
    "end": "2283310"
  },
  {
    "text": "The reason why TikTok works so much better\nthan Netflix, on an average, I think,",
    "start": "2283890",
    "end": "2288750"
  },
  {
    "text": "I was listening to a video by Scott,\nand he mentioned that we spend about",
    "start": "2289150",
    "end": "2293890"
  },
  {
    "text": "155 minutes a week browsing Netflix. On an average in the U. S.",
    "start": "2294429",
    "end": "2299490"
  },
  {
    "text": "and something of that nature. It's a pretty exorbitant amount of time. Versus TikTok has just completely taken\nthat fallacy of choice out for you.",
    "start": "2299530",
    "end": "2306950"
  },
  {
    "text": "When you go on TikTok, the video\nthat they have made, there's just so many data points. A 17 second video averaged\n16 minutes of viewing time",
    "start": "2307380",
    "end": "2315090"
  },
  {
    "text": "across your TikTok engagement. And you have so many data\npoints coming out of it. Seven, seven, ten of them.",
    "start": "2315100",
    "end": "2319960"
  },
  {
    "text": "Every few seconds, right? So they have hyper personalized it based\non how you interact with things, right?",
    "start": "2320350",
    "end": "2325819"
  },
  {
    "text": "Because they have not, not\nasking you to go pick a channel, a choice, this is that nature. They're just showing you the next,\nnext, next thing in the sequence.",
    "start": "2326140",
    "end": "2332920"
  },
  {
    "text": "Hence the stickiness. They've understood the brains\nof teenagers and, and, and that demographic really, really well.",
    "start": "2333380",
    "end": "2338579"
  },
  {
    "text": "I think that's the direction\nthat Google will go into. It'll start hyper personalizing\nbased on all the content.",
    "start": "2338809",
    "end": "2343585"
  },
  {
    "text": "If they're reading and finding out\nwhere the receipt of my shoes are, they know what I actually ended up\nordering at the restaurant I went to.",
    "start": "2343945",
    "end": "2350284"
  },
  {
    "text": "So the full feedback loop coming into\nthe Google ecosystem, I think it's going to be brilliant if they get to a point\nwhere they just Make a prediction on",
    "start": "2350295",
    "end": "2358204"
  },
  {
    "text": "which restaurant is going to work for me,\nbased on everything they know about me. That's right, yeah. I mean, the future is they're just going\nto book it for you, and a car is going",
    "start": "2358215",
    "end": "2364675"
  },
  {
    "text": "to show up, and you're going to get in. It's going to take you someplace, right? Uh, so Chris, uh",
    "start": "2364675",
    "end": "2369795"
  },
  {
    "text": "They'll send a confirmation\nfrom your email. Yeah, exactly, right. Uh, Chris, 30 seconds. You've got the last word.",
    "start": "2369805",
    "end": "2375389"
  },
  {
    "text": "30 seconds. Search is going to be a commodity. And I think as we see\nthe AI assistant era.",
    "start": "2375680",
    "end": "2381410"
  },
  {
    "text": "How dare you. Yeah. But it will be a commodity because\nwe are going to interact with search",
    "start": "2381410",
    "end": "2387650"
  },
  {
    "text": "via these assistants it's going to\nbe the serial on my phone, which will be enhanced by AI technology.",
    "start": "2387670",
    "end": "2394210"
  },
  {
    "text": "It's going to be a Android and Gemini's\nversion on there, we are not going",
    "start": "2394390",
    "end": "2399740"
  },
  {
    "text": "to be interacting with Google search\nin the way we do today with browsers. That is going to be commoditized\nand we're going to be dealing with",
    "start": "2399740",
    "end": "2406189"
  },
  {
    "text": "our assistants who are going to\ngo and fetch those queries for us. So I, I think that's going to be upended\nand, and at the heart of that is going to",
    "start": "2406190",
    "end": "2413808"
  },
  {
    "text": "be latency and multimodality as we said. So, uh, I think they got it or\nthey're going to be disrupted.",
    "start": "2413820",
    "end": "2420900"
  },
  {
    "text": "Yeah, I was going to say just like\nif that happens, what's interesting is that all of the advantage Google\nhas actually vanishes, like, and then",
    "start": "2421200",
    "end": "2427705"
  },
  {
    "text": "it's an even playing field against\nevery other LLM, which is, you know, that's a very interesting market\nsituation in that, at that point.",
    "start": "2427705",
    "end": "2434785"
  },
  {
    "text": "Yeah, I'm going to pick that up next week. That's a very, very good topic. We should get more into it. Um, great. Well, we're out of time.",
    "start": "2435265",
    "end": "2441065"
  },
  {
    "text": "Uh, Shobit, Chris, uh, thanks\nfor joining us on the show again. Uh, Brian, we hope to\nsee you again sometime.",
    "start": "2441135",
    "end": "2446735"
  },
  {
    "text": "Um, and to all you out there in Radioland,\nif you enjoyed what you heard, you can get us on Apple Podcasts, Spotify,\nand podcast platforms everywhere.",
    "start": "2446965",
    "end": "2454735"
  },
  {
    "text": "And we'll see you next week\nfor Mixture of Experts.",
    "start": "2454735",
    "end": "2456835"
  }
]
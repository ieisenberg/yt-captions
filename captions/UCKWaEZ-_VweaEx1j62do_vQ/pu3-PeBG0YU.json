[
  {
    "text": "Generative AI models are great, but have you ever wondered how to specialize",
    "start": "180",
    "end": "4394"
  },
  {
    "text": "them for a specific use case to be a subject matter expert in whatever your field might be?",
    "start": "4394",
    "end": "8550"
  },
  {
    "text": "Well, in the next few minutes you'll learn how you can take an open source",
    "start": "8880",
    "end": "12071"
  },
  {
    "text": "large language model and fine tune it from your laptop,",
    "start": "12071",
    "end": "14849"
  },
  {
    "text": "and the best part is you don't have to be a developer or data scientist at all to do this.",
    "start": "15090",
    "end": "19469"
  },
  {
    "text": "What you might have noticed after using LLMs is that they're great for general purposes, but for truly useful answers,",
    "start": "20100",
    "end": "26129"
  },
  {
    "text": "they need to know the domain in which they're working with,",
    "start": "26130",
    "end": "28557"
  },
  {
    "text": "and the data that's useful for your work is likely useful for an AI model too.",
    "start": "28557",
    "end": "32578"
  },
  {
    "text": "So instead of needing to provide examples of behavior to a model,",
    "start": "33120",
    "end": "36719"
  },
  {
    "text": "for example, respond back as an insurance claim adjuster with a professional tone and this knowledge of common policies,",
    "start": "36720",
    "end": "42739"
  },
  {
    "text": "you can actually bake this intuition into the model itself.",
    "start": "42739",
    "end": "45989"
  },
  {
    "text": "This means better responses with smaller prompts,",
    "start": "46470",
    "end": "49383"
  },
  {
    "text": "potentially faster inference and lower compute cost and a model that truly understands your domain.",
    "start": "49383",
    "end": "54960"
  },
  {
    "text": "So let's start this fine tuning process with the open source project and InstructLab.",
    "start": "55350",
    "end": "59419"
  },
  {
    "text": "InstructLab is a research based approach to democratize and enable community based contributions to AI models,",
    "start": "59419",
    "end": "65858"
  },
  {
    "text": "and allow us to do it in an accessible way on our laptop, just as we'll be doing today.",
    "start": "65858",
    "end": "69929"
  },
  {
    "text": "Now, there's three steps that I want to show you that we're going to be doing in today's video.",
    "start": "69960",
    "end": "73950"
  },
  {
    "text": "So firstly, is the curation of data for whatever you want your model to do or to know.",
    "start": "74220",
    "end": "79169"
  },
  {
    "text": "Second, fine tuning a model takes a lot of data more than what we have time or resources to create today.",
    "start": "79650",
    "end": "85409"
  },
  {
    "text": "So we're going to use a large language model that's running locally",
    "start": "85410",
    "end": "88717"
  },
  {
    "text": "to help us create synthetic data from our initial examples that we've curated.",
    "start": "88717",
    "end": "92340"
  },
  {
    "text": "And finally, we're going to bake this back into the model itself, using a multiphase tuning technique called Laura.",
    "start": "92670",
    "end": "98700"
  },
  {
    "text": "Now, I mentioned the first step is that curation of data.",
    "start": "99030",
    "end": "101879"
  },
  {
    "text": "So let me explain how this works in my IDE.",
    "start": "101910",
    "end": "104400"
  },
  {
    "text": "Now, I've already gotten InstructLab installed, the CLI is ilab and we'll do an ilab",
    "start": "104610",
    "end": "108176"
  },
  {
    "text": "configuration initialized to set up our working directory.",
    "start": "108176",
    "end": "112620"
  },
  {
    "text": "We'll set some defaults for the parameters of how we want to use this project, and we'll point to a taxonomy repository,",
    "start": "112890",
    "end": "118919"
  },
  {
    "text": "this is how we're going to structure and organize our data,",
    "start": "118930",
    "end": "121559"
  },
  {
    "text": "and we'll also point to a local model that we can serve locally to help us generate more examples,",
    "start": "121890",
    "end": "126900"
  },
  {
    "text": "and just like that, we're ready to start using InstructLab.",
    "start": "127200",
    "end": "129778"
  },
  {
    "text": "Now we've actually got this taxonomy open.",
    "start": "130169",
    "end": "132479"
  },
  {
    "text": "And you can see here on the left is this kind of a hierarchical structure",
    "start": "132690",
    "end": "136056"
  },
  {
    "text": "of different folders to organize the information we want to provide to the model in skills and knowledge.",
    "start": "136056",
    "end": "141899"
  },
  {
    "text": "So let's check out a skill.",
    "start": "142080",
    "end": "143550"
  },
  {
    "text": "So this is a YAML formatted question and answer document in plain text.",
    "start": "144000",
    "end": "148369"
  },
  {
    "text": "So I could be anybody to contribute to this model.",
    "start": "148380",
    "end": "151550"
  },
  {
    "text": "You don't have to be a data scientist or ML engineer and I can provide this to essentially teach the model new things.",
    "start": "151560",
    "end": "158280"
  },
  {
    "text": "For example, this is to teach it how to read markdown formatted tables.",
    "start": "158290",
    "end": "162299"
  },
  {
    "text": "So we have context.",
    "start": "162300",
    "end": "163860"
  },
  {
    "text": "We also have a question which breed has the most energy and an answer.",
    "start": "164100",
    "end": "167639"
  },
  {
    "text": "As you can see here, we've got a five out of five for the Labrador.",
    "start": "167640",
    "end": "171009"
  },
  {
    "text": "So we can use this as sample data to generate more examples like this and teach the model something new.",
    "start": "171030",
    "end": "176910"
  },
  {
    "text": "Now, this is really cool, but I also want to show you teaching the model about new subjects as well.",
    "start": "177360",
    "end": "181860"
  },
  {
    "text": "So the 2024 Oscars has happened, but the model that we're using today doesn't know that we need to fix that.",
    "start": "182250",
    "end": "188280"
  },
  {
    "text": "So we're going to ask this model a specific question from this training data that we want to provide.",
    "start": "188490",
    "end": "193529"
  },
  {
    "text": "Specifically, what film had the most Oscar nominations?",
    "start": "193830",
    "end": "196619"
  },
  {
    "text": "Now I can do an ilab model chat in order to talk to a model that have running locally.",
    "start": "196950",
    "end": "201509"
  },
  {
    "text": "This is Merlinite 7 billion parameters.",
    "start": "201510",
    "end": "203610"
  },
  {
    "text": "It's based off of the open source model Mistral and will ask the question which film had the most Oscar nominations?",
    "start": "203850",
    "end": "209999"
  },
  {
    "text": "And unfortunately the Irishman is incorrect.",
    "start": "210660",
    "end": "213270"
  },
  {
    "text": "The answer is Oppenheimer, and it's our job to make this correct.",
    "start": "213510",
    "end": "216599"
  },
  {
    "text": "So what we're going to go ahead and do is use this local training information",
    "start": "216960",
    "end": "222492"
  },
  {
    "text": "and curation that we've done from our local machine and create more synthetic training data and also point to this seed document here at the bottom.",
    "start": "222492",
    "end": "230999"
  },
  {
    "text": "This is markdown formatted information that we're going to pull during this data generation process",
    "start": "231240",
    "end": "236011"
  },
  {
    "text": "that provides more context and information about the specific subject that we're going to teach the model.",
    "start": "236011",
    "end": "241159"
  },
  {
    "text": "So let's get started.",
    "start": "241170",
    "end": "242490"
  },
  {
    "text": "Now it's time for the magic to happen.",
    "start": "242820",
    "end": "244909"
  },
  {
    "text": "So these large language models, as you might know, have been trained extensively on terabytes of data.",
    "start": "244920",
    "end": "249840"
  },
  {
    "text": "And what we're going to do is use a teacher model that we've already served locally",
    "start": "250110",
    "end": "253806"
  },
  {
    "text": "to generate hundreds or potentially thousands of additional examples based on our key data that we provided.",
    "start": "253806",
    "end": "259739"
  },
  {
    "text": "So let's kick this off.",
    "start": "260040",
    "end": "261209"
  },
  {
    "text": "We're first going to do an ilab taxonomy and make sure that everything is formatted as it should be.",
    "start": "261209",
    "end": "267059"
  },
  {
    "text": "And we've got back that smiley face.",
    "start": "267270",
    "end": "269190"
  },
  {
    "text": "We're good to go.",
    "start": "269220",
    "end": "270220"
  },
  {
    "text": "So what we're going to go ahead and do now is start generating that data.",
    "start": "270330",
    "end": "273430"
  },
  {
    "text": "So I'll do an ilab data generate,",
    "start": "273450",
    "end": "275850"
  },
  {
    "text": "and specifically, we're going to generate three instructions here using that locally served model,",
    "start": "275940",
    "end": "281740"
  },
  {
    "text": "or we could point to one that's running remotely,",
    "start": "281760",
    "end": "283848"
  },
  {
    "text": "and we're going to search for that Oscar's question answer pair that we've provided",
    "start": "283848",
    "end": "288839"
  },
  {
    "text": "and it's going to generate more similar examples to have enough training data to fully train this model.",
    "start": "289243",
    "end": "295680"
  },
  {
    "text": "So this is really cool because it's creating different variations",
    "start": "295980",
    "end": "299580"
  },
  {
    "text": "of our initial training data to be able to train this model in the end.",
    "start": "299910",
    "end": "304829"
  },
  {
    "text": "And as you see here, we've generated three examples.",
    "start": "305100",
    "end": "308009"
  },
  {
    "text": "You could see who was nominated for the Best Actor award.",
    "start": "308310",
    "end": "311310"
  },
  {
    "text": "And we're providing or we're getting back this answer, these different actors.",
    "start": "311520",
    "end": "315750"
  },
  {
    "text": "And what's great is that there's a filtration process because not all data is good data.",
    "start": "316050",
    "end": "320488"
  },
  {
    "text": "With that newly generated data, it's time for what's known as parameter efficient, fine tuning with InstructLab.",
    "start": "320640",
    "end": "326130"
  },
  {
    "text": "So I'll go ahead and do and ilab model train,",
    "start": "326550",
    "end": "329459"
  },
  {
    "text": "and what this is going to do is integrate this new knowledge and skills back into the new model.",
    "start": "329730",
    "end": "335189"
  },
  {
    "text": "Just updating a subset of its parameters as a whole, which is why we're able to do so on a consumer laptop like mine.",
    "start": "335280",
    "end": "341519"
  },
  {
    "text": "So we've done some cooking show magic here to speed things up",
    "start": "341880",
    "end": "344749"
  },
  {
    "text": "since that process might have taken a few hours depending on your hardware,",
    "start": "344749",
    "end": "348268"
  },
  {
    "text": "but finally, our result is a newly fine tuned model specialized with the knowledge that we gave it.",
    "start": "348660",
    "end": "353550"
  },
  {
    "text": "So let's go ahead and see it in action in.",
    "start": "353850",
    "end": "355663"
  },
  {
    "text": "a new terminal window I'm going to go ahead and serve",
    "start": "355663",
    "end": "358798"
  },
  {
    "text": "the quantized version of this model so it can run locally on my machine,",
    "start": "358798",
    "end": "362109"
  },
  {
    "text": "and we're going to go ahead and ask the question, which I think, you know what it might be,",
    "start": "362460",
    "end": "366539"
  },
  {
    "text": "what film had the most Oscar nominations in 2024?",
    "start": "366810",
    "end": "369990"
  },
  {
    "text": "So let's open up a new window and do an ilab model chat,",
    "start": "370440",
    "end": "374639"
  },
  {
    "text": "and we're going to talk to this model and ask you this question.",
    "start": "375360",
    "end": "378059"
  },
  {
    "text": "So what film had the most Oscar nominations?",
    "start": "378090",
    "end": "380609"
  },
  {
    "text": "Oppenheimer.",
    "start": "381000",
    "end": "381840"
  },
  {
    "text": "So it's really incredible to see the before and after of doing this fine tuning process.",
    "start": "381840",
    "end": "387238"
  },
  {
    "text": "And the coolest part, we're not AI ML experts.",
    "start": "387450",
    "end": "390180"
  },
  {
    "text": "We're just using open source projects like InstructLab among others out there",
    "start": "390180",
    "end": "394580"
  },
  {
    "text": "that can aid with the fine tuning of large language models.",
    "start": "394580",
    "end": "397768"
  },
  {
    "text": "Now with this fine tuned model, a popular way to provide external and",
    "start": "398870",
    "end": "403391"
  },
  {
    "text": "up to date information would be to use RAG or retrieval augmented generation,",
    "start": "403391",
    "end": "407388"
  },
  {
    "text": "but you can also imagine doing automated or regular builds with this fine tuned model when the static resources change.",
    "start": "407720",
    "end": "414066"
  },
  {
    "text": "So one more thing.",
    "start": "414290",
    "end": "415700"
  },
  {
    "text": "We believe that the future of AI is open, but what does that really mean?",
    "start": "415700",
    "end": "419149"
  },
  {
    "text": "Well, the InstructLab project is all about building a community of AI contributors.",
    "start": "419360",
    "end": "424008"
  },
  {
    "text": "Being able to share your contributions upstream and collaborate on domain specific models.",
    "start": "424280",
    "end": "429050"
  },
  {
    "text": "Now, what does that look like?",
    "start": "429350",
    "end": "430489"
  },
  {
    "text": "Well, imagine that you're working at an insurance company.",
    "start": "430730",
    "end": "433360"
  },
  {
    "text": "You could fine tune a model on your company's past claims and best practices",
    "start": "433370",
    "end": "437260"
  },
  {
    "text": "for handling accidents to help agents in the field and make their life better,",
    "start": "437260",
    "end": "441200"
  },
  {
    "text": "or maybe you're a law firm specializing in entertainment contracts.",
    "start": "441530",
    "end": "445519"
  },
  {
    "text": "You could train a model on your past contracts to help review and process new ones more quickly.",
    "start": "445730",
    "end": "450889"
  },
  {
    "text": "But the possibilities are endless.",
    "start": "451370",
    "end": "453319"
  },
  {
    "text": "And you're in control.",
    "start": "453320",
    "end": "454669"
  },
  {
    "text": "With what we've done today, you've effectively taken an open source, large language model,",
    "start": "454850",
    "end": "458502"
  },
  {
    "text": "locally trained on specific data without using a third party,",
    "start": "458502",
    "end": "462050"
  },
  {
    "text": "and now have a baked in model that we could use on premise in the cloud or share with others.",
    "start": "462050",
    "end": "466849"
  },
  {
    "text": "Now, what are you interested in creating?",
    "start": "467090",
    "end": "468949"
  },
  {
    "text": "Let us know in the comments below.",
    "start": "469070",
    "end": "470810"
  },
  {
    "text": "Now, as always, thank you so much for watching.",
    "start": "471320",
    "end": "473750"
  },
  {
    "text": "Please be sure to like this video.",
    "start": "473900",
    "end": "475488"
  },
  {
    "text": "If you learn something today and make sure you're subscribed.",
    "start": "475490",
    "end": "477959"
  },
  {
    "text": "For more content around AI and more.",
    "start": "477980",
    "end": "480199"
  }
]
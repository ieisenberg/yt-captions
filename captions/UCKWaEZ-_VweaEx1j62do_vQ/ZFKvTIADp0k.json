[
  {
    "start": "0",
    "end": "82000"
  },
  {
    "text": "Have you been to Mars?",
    "start": "210",
    "end": "1210"
  },
  {
    "text": "Me neither.",
    "start": "1770",
    "end": "2770"
  },
  {
    "text": "But according to an LLM, or a large language model, out there",
    "start": "2940",
    "end": "7320"
  },
  {
    "text": "I have been to Mars in 1950, right?",
    "start": "7320",
    "end": "9930"
  },
  {
    "text": "It is not uncommon for the large language models to generate misleading data such as this.",
    "start": "10260",
    "end": "15539"
  },
  {
    "text": "Let's look at some more examples.",
    "start": "16500",
    "end": "18120"
  },
  {
    "text": "A large language model creating or generating a Python script",
    "start": "18660",
    "end": "23906"
  },
  {
    "text": "that looks logically correct, but totally unexecutable, right?",
    "start": "23906",
    "end": "28649"
  },
  {
    "text": "Another example could be",
    "start": "29160",
    "end": "30887"
  },
  {
    "text": "a mathematical or a financial calculation that the large language model creates",
    "start": "30887",
    "end": "35826"
  },
  {
    "text": "is incorrect, totally misleading and incorrect.",
    "start": "35826",
    "end": "38880"
  },
  {
    "text": "It could also be giving you incorrect dates on major events such as a moon landing, right?",
    "start": "39570",
    "end": "45689"
  },
  {
    "text": "These are all very good examples of AI hallucinations.",
    "start": "46050",
    "end": "50340"
  },
  {
    "text": "So AI hallucinations is a very well known phenomenon by the large language models.",
    "start": "50580",
    "end": "55830"
  },
  {
    "text": "This is where the AI models are generating misleading",
    "start": "56460",
    "end": "60577"
  },
  {
    "text": "and factually incorrect,",
    "start": "60577",
    "end": "62385"
  },
  {
    "text": "and sometimes even nonsensical responses for the questions you are asking.",
    "start": "62385",
    "end": "66210"
  },
  {
    "text": "You see hallucinations commonly where in question answering",
    "start": "66750",
    "end": "71901"
  },
  {
    "text": "or when you are asking the models to generate summaries.",
    "start": "71901",
    "end": "75466"
  },
  {
    "text": "So the hallucinations can be statistically inaccurate and factually incorrect.",
    "start": "75987",
    "end": "81186"
  },
  {
    "start": "82000",
    "end": "167000"
  },
  {
    "text": "So why do hallucinations occur?",
    "start": "82230",
    "end": "84629"
  },
  {
    "text": "There could be two reasons.",
    "start": "85110",
    "end": "86765"
  },
  {
    "text": "And there are two types of hallucinations.",
    "start": "87060",
    "end": "89399"
  },
  {
    "text": "One is intentional",
    "start": "89640",
    "end": "91663"
  },
  {
    "text": "where, for example, threat actors can be injecting",
    "start": "91663",
    "end": "95585"
  },
  {
    "text": "malicious data into your corporate data.",
    "start": "95585",
    "end": "98700"
  },
  {
    "text": "That is leading to adversarial hallucinations.",
    "start": "99720",
    "end": "102840"
  },
  {
    "text": "It is a quite common cybersecurity example of hallucinations.",
    "start": "103830",
    "end": "108359"
  },
  {
    "text": "Now, the second one is the unintentional hallucinations.",
    "start": "109080",
    "end": "113609"
  },
  {
    "text": "These hallucinations occur because of the nature, innate nature,",
    "start": "114150",
    "end": "118709"
  },
  {
    "text": "of the large language models being, trained on large volumes of unlabeled data.",
    "start": "118709",
    "end": "125430"
  },
  {
    "text": "When you are using unlabeled data and there are too large volumes of it,",
    "start": "126210",
    "end": "130572"
  },
  {
    "text": "there could be misrepresentations of this fact,",
    "start": "130572",
    "end": "133761"
  },
  {
    "text": "and there could be conflicting information that could be misleading",
    "start": "133761",
    "end": "138658"
  },
  {
    "text": "and incomplete information also, which causes the models to",
    "start": "138658",
    "end": "143137"
  },
  {
    "text": "generate incorrect representations of responses.",
    "start": "143137",
    "end": "147930"
  },
  {
    "text": "Sometimes these unintentional hallucinations are also caused by the",
    "start": "149070",
    "end": "155040"
  },
  {
    "text": "encoder and decoder models that are very foundational to the large language models.",
    "start": "155040",
    "end": "161340"
  },
  {
    "text": "So, we are beginning to understand hallucinations quite well.",
    "start": "162240",
    "end": "166650"
  },
  {
    "start": "167000",
    "end": "188000"
  },
  {
    "text": "And we have also developed and leveraged techniques, the prompting techniques,",
    "start": "167310",
    "end": "172110"
  },
  {
    "text": "that are out there in containing the AI hallucinations.",
    "start": "172110",
    "end": "176190"
  },
  {
    "text": "I am going to talk through five different prompting techniques that we could use",
    "start": "176730",
    "end": "181263"
  },
  {
    "text": "to contain the hallucinations in your large language model responses.",
    "start": "181263",
    "end": "186959"
  },
  {
    "start": "188000",
    "end": "299000"
  },
  {
    "text": "The first one will be the temperature prompting technique.",
    "start": "188070",
    "end": "192599"
  },
  {
    "text": "It is actually a parameter that the sequencing models leverage.",
    "start": "192870",
    "end": "197519"
  },
  {
    "text": "And the value of the temperature can typically be between 0 and 1.",
    "start": "198480",
    "end": "203939"
  },
  {
    "text": "The temperature parameter is going to determine how greedy your large language model is going to be, right?",
    "start": "205260",
    "end": "212698"
  },
  {
    "text": "If the temperature value is zero, then it is going to be a lot less greedy, right?",
    "start": "213090",
    "end": "218659"
  },
  {
    "text": "In being accurate.",
    "start": "218670",
    "end": "219689"
  },
  {
    "text": "And if it is, the temperature value is more one, then the model is going to be very greedy and gets very creative.",
    "start": "220050",
    "end": "227279"
  },
  {
    "text": "Now let us apply the temperature values 0 to 1",
    "start": "227400",
    "end": "231429"
  },
  {
    "text": "in with a business document where you are interested in extracting facts,",
    "start": "231429",
    "end": "237906"
  },
  {
    "text": "like a net income or a company name by salary, etc., or also the SLAs of a contractual document, right.",
    "start": "237906",
    "end": "247110"
  },
  {
    "text": "And you also have another document called a creative document,",
    "start": "247560",
    "end": "252170"
  },
  {
    "text": "where you are asking going to ask the large language model",
    "start": "252170",
    "end": "256040"
  },
  {
    "text": "to create a poem or write a sonnet in either Keats' style or Milton's style.",
    "start": "256040",
    "end": "261569"
  },
  {
    "text": "So if I were gaining, asking the large language model to extract facts,",
    "start": "262920",
    "end": "268275"
  },
  {
    "text": "I would give it anywhere between point three.",
    "start": "268275",
    "end": "270720"
  },
  {
    "text": "And if I am asking the large language model to extract SLA's from a contractual document, I could go from 0.5 to 0.7.",
    "start": "272490",
    "end": "280948"
  },
  {
    "text": "However, if I'm asking a large language model to write a song, a sonnet,",
    "start": "282780",
    "end": "288572"
  },
  {
    "text": "I would be giving it a whopping 0.8,",
    "start": "288572",
    "end": "291624"
  },
  {
    "text": "because that makes the model very flexible with the words",
    "start": "291624",
    "end": "296218"
  },
  {
    "text": "and generating that song in a sonnet.",
    "start": "296218",
    "end": "298470"
  },
  {
    "start": "299000",
    "end": "353000"
  },
  {
    "text": "Okay, the next technique, my favorite, in generating very effective outcomes is the role assignment.",
    "start": "299370",
    "end": "307470"
  },
  {
    "text": "In this, you are controlling the outcomes of the responses from the large language models",
    "start": "307560",
    "end": "312977"
  },
  {
    "text": "by telling it to take a role of a certain persona, right?",
    "start": "312977",
    "end": "317729"
  },
  {
    "text": "For example, if you have a patient document,",
    "start": "317940",
    "end": "321086"
  },
  {
    "text": "you can tell the large language models to be a doctor,",
    "start": "321086",
    "end": "324782"
  },
  {
    "text": "to go through the symptoms and come up with a diagnosis.",
    "start": "324782",
    "end": "327540"
  },
  {
    "text": "That is for a medical kind of a document.",
    "start": "328980",
    "end": "332879"
  },
  {
    "text": "If you were to create a creative document,",
    "start": "333210",
    "end": "337199"
  },
  {
    "text": "then you can tell it, think like Keats and write a poem.",
    "start": "337200",
    "end": "340350"
  },
  {
    "text": "Or think like Milton and write a sonnet.",
    "start": "341940",
    "end": "344309"
  },
  {
    "text": "That is how you are going to tell the model to focus on the outcome that you want to come out of those models.",
    "start": "345600",
    "end": "352589"
  },
  {
    "start": "353000",
    "end": "413000"
  },
  {
    "text": "So the third, very effective, technique is called specificity, right?",
    "start": "353010",
    "end": "359009"
  },
  {
    "text": "This takes the role assignement to the next level.",
    "start": "359310",
    "end": "362279"
  },
  {
    "text": "In the specificity approach you are giving specific data rules and formulae",
    "start": "362279",
    "end": "367975"
  },
  {
    "text": "and the  examples to the model to follow and get you the results that you want.",
    "start": "367975",
    "end": "374008"
  },
  {
    "text": "This is a very good example of using the few short, prompting technique.",
    "start": "375630",
    "end": "381179"
  },
  {
    "text": "Like chain-of-thought, ReAct, ... ",
    "start": "382320",
    "end": "384660"
  },
  {
    "text": "and this works very, very well, particularly when you have scientific calculations",
    "start": "385020",
    "end": "391125"
  },
  {
    "text": "or you have financial calculations",
    "start": "391125",
    "end": "393566"
  },
  {
    "text": "and you want a model to arrive at a solution in a very methodical manner.",
    "start": "393566",
    "end": "400823"
  },
  {
    "text": "This is also a very good example of writing code.",
    "start": "402090",
    "end": "406169"
  },
  {
    "text": "Where is it, for example, writing or writing code to solve a problem.",
    "start": "406380",
    "end": "409529"
  },
  {
    "text": "Use that in those examples.",
    "start": "410700",
    "end": "412739"
  },
  {
    "start": "413000",
    "end": "462000"
  },
  {
    "text": "So the next and very effective technique,",
    "start": "413490",
    "end": "415860"
  },
  {
    "text": "and by the way this is my really favorite approach,",
    "start": "415860",
    "end": "418991"
  },
  {
    "text": "is content grounding.",
    "start": "418992",
    "end": "420479"
  },
  {
    "text": "This is where you are making the large language models to look into your domain data.",
    "start": "420900",
    "end": "425399"
  },
  {
    "text": "Well, even though it is trained on the internet unlabeled data,",
    "start": "426270",
    "end": "430240"
  },
  {
    "text": "it is now focusing on your data to respond to your questions.",
    "start": "430240",
    "end": "433919"
  },
  {
    "text": "It is very useful in the business scenarios, right?",
    "start": "434040",
    "end": "438450"
  },
  {
    "text": "Where you are asking for security breaches",
    "start": "438774",
    "end": "442900"
  },
  {
    "text": "or, you know, risk in a contract, etc..",
    "start": "442900",
    "end": "445259"
  },
  {
    "text": "So the large language model is focusing on your content and getting you that response.",
    "start": "445260",
    "end": "452449"
  },
  {
    "text": "By the way, RAG is a really good approach",
    "start": "452910",
    "end": "457541"
  },
  {
    "text": "to use for content grounding, Retrieval Augmented Generation.",
    "start": "457541",
    "end": "462104"
  },
  {
    "start": "462000",
    "end": "535000"
  },
  {
    "text": "And the final and also a very effective prompting technique",
    "start": "462464",
    "end": "467671"
  },
  {
    "text": "is the providing instructions of what to do and what not to do to the large language model.",
    "start": "467671",
    "end": "472889"
  },
  {
    "text": "In a business document, supposing you have five types of risks involved,",
    "start": "474240",
    "end": "479061"
  },
  {
    "text": "but you are only interested in the infringement risk.",
    "start": "479061",
    "end": "481829"
  },
  {
    "text": "So you can tell the large language model to focus on the infringement risk.",
    "start": "482280",
    "end": "486089"
  },
  {
    "text": "Similarly, if you want to create a song or a poem by Keats",
    "start": "486720",
    "end": "491621"
  },
  {
    "text": "and you want only happy poems,",
    "start": "491621",
    "end": "493936"
  },
  {
    "text": "you can tell the model to do so, right?",
    "start": "493936",
    "end": "496799"
  },
  {
    "text": "It works very well.",
    "start": "497010",
    "end": "498389"
  },
  {
    "text": "So try to incorporate do's and don'ts in your prompting technique.",
    "start": "498600",
    "end": "502379"
  },
  {
    "text": "There you go.",
    "start": "503600",
    "end": "504500"
  },
  {
    "text": "These are the different techniques you can use to contain hallucinations.",
    "start": "504500",
    "end": "508129"
  },
  {
    "text": "It is so critical to do that",
    "start": "508550",
    "end": "510538"
  },
  {
    "text": "because you want to avoid harmful misinformation,",
    "start": "510538",
    "end": "514427"
  },
  {
    "text": "avoid legal implications,",
    "start": "514428",
    "end": "516664"
  },
  {
    "text": "and also build trust and confidence",
    "start": "516665",
    "end": "520001"
  },
  {
    "text": "in leveraging the generative AI models.",
    "start": "520002",
    "end": "522470"
  },
  {
    "text": "Thank you for watching.",
    "start": "523740",
    "end": "524938"
  },
  {
    "text": "Before you leave, please click Subscribe and Like.",
    "start": "525180",
    "end": "528943"
  }
]
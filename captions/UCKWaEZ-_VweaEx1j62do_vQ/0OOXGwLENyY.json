[
  {
    "text": "Hey, everybody.",
    "start": "210",
    "end": "1210"
  },
  {
    "text": "Today, I want to talk to you about how to apply domain specific knowledge to your LLM lifecycle.",
    "start": "1530",
    "end": "9000"
  },
  {
    "text": "A traditional approach starts with a data engineer.",
    "start": "9870",
    "end": "14999"
  },
  {
    "text": "Who's curating data that is then used.",
    "start": "17320",
    "end": "20980"
  },
  {
    "text": "By data scientists.",
    "start": "22850",
    "end": "24079"
  },
  {
    "text": "Who ultimately takes that data.",
    "start": "26780",
    "end": "29030"
  },
  {
    "text": "Trains it to the model.",
    "start": "37770",
    "end": "40380"
  },
  {
    "text": "And then makes that model available for inference.",
    "start": "46900",
    "end": "51249"
  },
  {
    "text": "One of the challenges with this, though.",
    "start": "56080",
    "end": "57640"
  },
  {
    "text": "Is that the data over here being used,",
    "start": "59010",
    "end": "61619"
  },
  {
    "text": "it's typically a traditional database of some sort, either sequel or no sequel,",
    "start": "66520",
    "end": "71683"
  },
  {
    "text": "and it's usually containing metrics",
    "start": "72210",
    "end": "74914"
  },
  {
    "text": "or sales data or anything that's typically organized or curated by an organization.",
    "start": "74914",
    "end": "81069"
  },
  {
    "text": "The challenge here is getting domain specific knowledge within",
    "start": "81610",
    "end": "85804"
  },
  {
    "text": "an organization and applying it to this same process.",
    "start": "85804",
    "end": "89139"
  },
  {
    "text": "Now let's look at the same approach,",
    "start": "90000",
    "end": "91979"
  },
  {
    "text": "but use a variety of tools that can empower people like project managers,",
    "start": "91979",
    "end": "97696"
  },
  {
    "text": "and business analysts to be contributing to the process.",
    "start": "97696",
    "end": "102430"
  },
  {
    "text": "So here we have a project manager",
    "start": "104070",
    "end": "107560"
  },
  {
    "text": "And business analyst.",
    "start": "109410",
    "end": "111569"
  },
  {
    "text": "They both have domain specific knowledge about processes",
    "start": "112890",
    "end": "119940"
  },
  {
    "text": "within their organization,",
    "start": "121410",
    "end": "122849"
  },
  {
    "text": "but these could be stored in word documents or text files of some sort,",
    "start": "123660",
    "end": "129453"
  },
  {
    "text": "not the traditional data stores that we have that we typically use within a model lifecycle,",
    "start": "129453",
    "end": "135419"
  },
  {
    "text": "but we can change this.",
    "start": "137280",
    "end": "138630"
  },
  {
    "text": "We can use a tool like InstructLab to manage this process.",
    "start": "139560",
    "end": "148709"
  },
  {
    "text": "InstructLab is an open source tool that allows the management of what we call a taxonomy.",
    "start": "153610",
    "end": "160990"
  },
  {
    "text": "This taxonomy is just a git repository typically where we can manage things like indie files or text files",
    "start": "162310",
    "end": "172702"
  },
  {
    "text": "and then apply that to our model.",
    "start": "172702",
    "end": "177069"
  },
  {
    "text": "We could even have more traditional document formats like PDFs,",
    "start": "180850",
    "end": "186414"
  },
  {
    "text": "and have those be transformed and the necessary file structure that InstructLab takes.",
    "start": "186414",
    "end": "192519"
  },
  {
    "text": "Once they've applied that data to the taxonomy that InstructLab manages,",
    "start": "193840",
    "end": "200295"
  },
  {
    "text": "we can then start the more traditional process that we saw earlier,",
    "start": "200296",
    "end": "205179"
  },
  {
    "text": "but we don't actually need a data scientist in this case.",
    "start": "206170",
    "end": "209560"
  },
  {
    "text": "InstructLab is handling all that,",
    "start": "210190",
    "end": "212110"
  },
  {
    "text": "and it will then create synthetic data",
    "start": "212560",
    "end": "216729"
  },
  {
    "text": "through this process.",
    "start": "220670",
    "end": "222080"
  },
  {
    "text": "Now I know synthetic data.",
    "start": "224160",
    "end": "226499"
  },
  {
    "text": "That sounds kind of scary, but I want to approach it in a different way.",
    "start": "227700",
    "end": "232409"
  },
  {
    "text": "Think of synthetic data in this case as just another way of reframing the question,",
    "start": "233400",
    "end": "239596"
  },
  {
    "text": "instead of one way of asking a question,",
    "start": "239596",
    "end": "243719"
  },
  {
    "text": "We have many different ways of asking the same question.",
    "start": "243960",
    "end": "247469"
  },
  {
    "text": "This empowers the model, especially when we go through the training cycle,",
    "start": "248370",
    "end": "253146"
  },
  {
    "text": "to then apply more opportunities to the LLM to be able to accurately reply to your prompts.",
    "start": "253146",
    "end": "262949"
  },
  {
    "text": "Once we've trained the model, we can then go ahead and deploy it into an AI platform.",
    "start": "264380",
    "end": "272779"
  },
  {
    "text": "This could be Kubernetes based like OpenShift, for example.",
    "start": "274720",
    "end": "278800"
  },
  {
    "text": "and this can take advantage of different AI accelerators that can be used",
    "start": "283040",
    "end": "289219"
  },
  {
    "text": "like  NVIDIA,",
    "start": "290480",
    "end": "293179"
  },
  {
    "text": "AMD, or Intel, for example.",
    "start": "296910",
    "end": "300269"
  },
  {
    "text": "Now this is the infrastructure layer,",
    "start": "303220",
    "end": "306333"
  },
  {
    "text": "but we want to be able to interact with our model and be able to configure",
    "start": "306333",
    "end": "311175"
  },
  {
    "text": "the inference and be able to apply metrics",
    "start": "311175",
    "end": "314600"
  },
  {
    "text": "and all those things that need to be part of the MLOps lifecycle.",
    "start": "314601",
    "end": "318550"
  },
  {
    "text": "Now we can do this.",
    "start": "319120",
    "end": "320738"
  },
  {
    "text": "With an extension for OpenShift called Red Hat OpenShift AI",
    "start": "321400",
    "end": "330139"
  },
  {
    "text": "Which will provide you all those tools for managing the lifecycle of this model within production.",
    "start": "331110",
    "end": "338488"
  },
  {
    "text": "Now, you may want to then interact with that model.",
    "start": "339930",
    "end": "343289"
  },
  {
    "text": "You want to validate it or apply governance or other things.",
    "start": "343920",
    "end": "347730"
  },
  {
    "text": "You even just sandbox with it.",
    "start": "348420",
    "end": "349680"
  },
  {
    "text": "This could be done with something like watsonx.AI.",
    "start": "350550",
    "end": "357370"
  },
  {
    "text": "I can sit on top of OpenShift and interact with all the models that are being inferred within this AI stack.",
    "start": "357570",
    "end": "365370"
  },
  {
    "text": "Now once this life cycle has finished.",
    "start": "366590",
    "end": "370579"
  },
  {
    "text": "We can then restart the whole process again",
    "start": "370970",
    "end": "375080"
  },
  {
    "text": "and use the new data that has since been built up by our project managers and business analysts",
    "start": "375080",
    "end": "382685"
  },
  {
    "text": "and go through this lifecycle once more.",
    "start": "382686",
    "end": "385399"
  },
  {
    "text": "But one thing to note is that can be really costly.",
    "start": "386750",
    "end": "390320"
  },
  {
    "text": "We may not want to run this process over and over again every week.",
    "start": "391370",
    "end": "394760"
  },
  {
    "text": "We may only have the budget to run it maybe once a month or once every other month.",
    "start": "395060",
    "end": "399019"
  },
  {
    "text": "Well, we can use technologies like RAG,",
    "start": "399680",
    "end": "403729"
  },
  {
    "text": "And how this data come over here in the interim before we go through this process again.",
    "start": "407450",
    "end": "417859"
  },
  {
    "text": "Once we do that, we can flush out our RAG database and then start a new.",
    "start": "418970",
    "end": "425120"
  },
  {
    "text": "As data is collected by our project managers and our business analysts.",
    "start": "425150",
    "end": "429798"
  },
  {
    "text": "All right.",
    "start": "431190",
    "end": "431970"
  },
  {
    "text": "We shown the complete model lifecycle",
    "start": "431970",
    "end": "434665"
  },
  {
    "text": "and how to apply domain specific knowledge",
    "start": "434665",
    "end": "437686"
  },
  {
    "text": "from people within our organization, like project managers and business analysts.",
    "start": "437686",
    "end": "442170"
  },
  {
    "text": "Then manage that data through a taxonomy, through InstructLab,",
    "start": "442920",
    "end": "447070"
  },
  {
    "text": "generate synthetic data that's then used for training that model,",
    "start": "447070",
    "end": "451553"
  },
  {
    "text": "and then ultimately deploying into a Kubernetes based platform like OpenShift.",
    "start": "451553",
    "end": "457080"
  },
  {
    "text": "Utilizing AI services from tools like watsonx.ai,",
    "start": "457560",
    "end": "462408"
  },
  {
    "text": "and ultimately using technologies like RAG to enhance that experience.",
    "start": "462408",
    "end": "468539"
  },
  {
    "text": "Thank you so much for watching.",
    "start": "469290",
    "end": "470670"
  }
]
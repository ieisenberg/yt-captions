[
  {
    "text": "So we all know what retrieval augmented\ngeneration is.",
    "start": "900",
    "end": "4471"
  },
  {
    "text": "But let's just do a quick refresher.",
    "start": "4804",
    "end": "6873"
  },
  {
    "text": "Retrieval augmented generation is a powerful and popular",
    "start": "6873",
    "end": "10477"
  },
  {
    "text": "pipeline that enhances responses\nfrom a large language model.",
    "start": "10477",
    "end": "13780"
  },
  {
    "text": "It does this by incorporating relevant\ndata retrieved from a vector database,",
    "start": "14114",
    "end": "18318"
  },
  {
    "text": "adding it as context to the prompt,\nand sending it to the LLM for generation.",
    "start": "18318",
    "end": "22188"
  },
  {
    "text": "What this does is it allows the LLM to ground its response in concrete and accurate information,",
    "start": "22622",
    "end": "28028"
  },
  {
    "text": "and that improves the quality\nand reliability of the response.",
    "start": "28028",
    "end": "31297"
  },
  {
    "text": "Let me quickly sketch it out.",
    "start": "31698",
    "end": "34234"
  },
  {
    "text": "So let's say we have a user",
    "start": "34234",
    "end": "37203"
  },
  {
    "text": "or an application, even.",
    "start": "37203",
    "end": "40205"
  },
  {
    "text": "And they send a query.",
    "start": "41274",
    "end": "44276"
  },
  {
    "text": "Now without retrieval augment\nthe generation.",
    "start": "44611",
    "end": "47113"
  },
  {
    "text": "This query is going to go and get itself\ninterpolated into a prompt.",
    "start": "47113",
    "end": "53920"
  },
  {
    "text": "And from there",
    "start": "55221",
    "end": "55922"
  },
  {
    "text": "that's going to hit the LLM.",
    "start": "57023",
    "end": "60025"
  },
  {
    "text": "And that's going to generate an output.",
    "start": "61361",
    "end": "64364"
  },
  {
    "text": "To make this rag.",
    "start": "67901",
    "end": "69102"
  },
  {
    "text": "We can add a vector database.",
    "start": "69102",
    "end": "72104"
  },
  {
    "text": "So instead of just going directly\nand getting itself",
    "start": "72505",
    "end": "74374"
  },
  {
    "text": "interpolated into the prompt, it's\ngoing to hit this vector db.",
    "start": "74374",
    "end": "77377"
  },
  {
    "text": "And the response from that vector db\nis going to be used as context",
    "start": "77677",
    "end": "81181"
  },
  {
    "text": "for the prompt.",
    "start": "81181",
    "end": "83116"
  },
  {
    "text": "Now in this typical pipeline\nwe call the LLM only once,",
    "start": "83116",
    "end": "87153"
  },
  {
    "text": "and we use it\nsolely to generate a response.",
    "start": "87320",
    "end": "90323"
  },
  {
    "text": "But what if we could leverage the LLM\nnot just for responses,",
    "start": "90824",
    "end": "94911"
  },
  {
    "text": "but also for additional tasks like deciding\nwhich vector database to query",
    "start": "94912",
    "end": "99365"
  },
  {
    "text": "If we have multiple databases, or even determining the type of response\nto give?",
    "start": "99365",
    "end": "103345"
  },
  {
    "text": "Should an answer with text generate a chart\nor even provide a code snippet?",
    "start": "103345",
    "end": "107674"
  },
  {
    "text": "And that would all be dependent\non the context of that query.",
    "start": "108268",
    "end": "111117"
  },
  {
    "text": "So this is where the agenetic RAG\npipeline",
    "start": "112145",
    "end": "116182"
  },
  {
    "text": "comes into play.",
    "start": "117917",
    "end": "118952"
  },
  {
    "text": "In agenetic RAG, we use the LLM as an agent and the LLM goes\nbeyond just generating a response.",
    "start": "118952",
    "end": "125225"
  },
  {
    "text": "It takes on an active role\nand can make decisions that will improve",
    "start": "125492",
    "end": "129194"
  },
  {
    "text": "both the relevance\nand accuracy of the retrieved data.",
    "start": "129195",
    "end": "132732"
  },
  {
    "text": "Now, let's explore how we can augment\nthe initial process",
    "start": "133233",
    "end": "136503"
  },
  {
    "text": "with an agent\nand a couple of different sources of data.",
    "start": "136636",
    "end": "139639"
  },
  {
    "text": "So instead of just one single source,",
    "start": "140306",
    "end": "142375"
  },
  {
    "text": "let's add a second.",
    "start": "142375",
    "end": "145378"
  },
  {
    "text": "And the first one can be, you know,",
    "start": "145712",
    "end": "148681"
  },
  {
    "text": "internal documentation, Right?",
    "start": "148715",
    "end": "151683"
  },
  {
    "text": "And the second one can be general industry knowledge.",
    "start": "151684",
    "end": "157290"
  },
  {
    "text": "Now in the internal documentation\nwe're going to have things",
    "start": "159926",
    "end": "162228"
  },
  {
    "text": "like policies procedures and guidelines.",
    "start": "162228",
    "end": "164430"
  },
  {
    "text": "And the general knowledge base",
    "start": "164430",
    "end": "165898"
  },
  {
    "text": "will have things like industry standards,\nbest practices and public resources.",
    "start": "165899",
    "end": "170370"
  },
  {
    "text": "So how can we get the LLM to use the vector database",
    "start": "171404",
    "end": "174707"
  },
  {
    "text": "that contains the data\nthat would be most relevant to the query?",
    "start": "174707",
    "end": "177710"
  },
  {
    "text": "Let's add that agent into this pipeline.",
    "start": "178077",
    "end": "181080"
  },
  {
    "text": "Now, this agent can intelligently decide\nwhich database",
    "start": "185185",
    "end": "188788"
  },
  {
    "text": "to query based on the user's question,\nand the agent isn't making a random guess.",
    "start": "188788",
    "end": "192792"
  },
  {
    "text": "It's leveraging the LLMs language,\nunderstanding capabilities",
    "start": "192825",
    "end": "196763"
  },
  {
    "text": "to interpret the query and determine its context.",
    "start": "197130",
    "end": "200233"
  },
  {
    "text": "So if an employee asks\nwhat's the company's policy on remote work",
    "start": "201100",
    "end": "204604"
  },
  {
    "text": "during the holidays, it would route that\nto the internal documentation,",
    "start": "204604",
    "end": "208007"
  },
  {
    "text": "and that response\nwill be used as context for the prompt.",
    "start": "208141",
    "end": "211144"
  },
  {
    "text": "But if the question is more general,\nlike what are the industries standards",
    "start": "211644",
    "end": "215280"
  },
  {
    "text": "for remote work in tech companies,",
    "start": "215548",
    "end": "218451"
  },
  {
    "text": "the agent's going to route\nthat to the general knowledge database,",
    "start": "218451",
    "end": "220920"
  },
  {
    "text": "and that context is going to be used\nwithin that prompt powered by an LLM",
    "start": "220920",
    "end": "225592"
  },
  {
    "text": "and properly trained, the agent analyzes\nthe query and based on the understanding",
    "start": "225592",
    "end": "230362"
  },
  {
    "text": "of the content and the context, decides\nwhich database to use.",
    "start": "230363",
    "end": "233733"
  },
  {
    "text": "But they're not always going to ask\nquestions that are generally",
    "start": "234334",
    "end": "237437"
  },
  {
    "text": "or genuinely relevant to any of this,\nany of the stuff that we have",
    "start": "237437",
    "end": "240506"
  },
  {
    "text": "in our vector DB.",
    "start": "240506",
    "end": "241274"
  },
  {
    "text": "So what if someone asks a question\nthat is just totally out of left field?",
    "start": "241274",
    "end": "245245"
  },
  {
    "text": "Like who won the World Series in 2015?",
    "start": "245545",
    "end": "248548"
  },
  {
    "text": "What the agent can do at that point\nis it could route it to a failsafe.",
    "start": "248815",
    "end": "253286"
  },
  {
    "text": "So because the agent is able",
    "start": "255521",
    "end": "256789"
  },
  {
    "text": "to recognize the context of the query,",
    "start": "256789",
    "end": "261060"
  },
  {
    "text": "it could recognize that it's not a part\nof the two databases that we have,",
    "start": "261728",
    "end": "264897"
  },
  {
    "text": "could route it to the failsafe\nand return back.",
    "start": "265231",
    "end": "268201"
  },
  {
    "text": "Sorry, I don't have the information\nin looking for.",
    "start": "269269",
    "end": "272396"
  },
  {
    "text": "This agentic RAG pipeline can be used in customer\nsupport systems and legal tech.",
    "start": "272396",
    "end": "276975"
  },
  {
    "text": "For example, a lawyer can source",
    "start": "277644",
    "end": "279178"
  },
  {
    "text": "answers to their questions\nfrom like their internal briefs",
    "start": "279178",
    "end": "282181"
  },
  {
    "text": "and then in another query, just get stuff\nfrom public caseload databases.",
    "start": "282515",
    "end": "286052"
  },
  {
    "text": "The agent can be utilized\nin a ton of ways.",
    "start": "286552",
    "end": "289255"
  },
  {
    "text": "Agentic RAG is an evolution in how\nwe enhance the RAG pipeline by moving",
    "start": "289255",
    "end": "293426"
  },
  {
    "text": "beyond simple response generation\nto more intelligent decision making.",
    "start": "293426",
    "end": "297729"
  },
  {
    "text": "By allowing an agent\nto choose the best data sources",
    "start": "298364",
    "end": "301367"
  },
  {
    "text": "and potentially even incorporate\nexternal information",
    "start": "301467",
    "end": "304404"
  },
  {
    "text": "like real timedata or third party services.",
    "start": "304404",
    "end": "307406"
  },
  {
    "text": "We can create a pipeline that's more responsive, more accurate, and more adaptable.",
    "start": "307507",
    "end": "313246"
  },
  {
    "text": "This approach opens up\nso many possibilities for applications",
    "start": "313246",
    "end": "316382"
  },
  {
    "text": "in customer\nservice, legal, tech, health care,",
    "start": "316382",
    "end": "319384"
  },
  {
    "text": "virtually any field\nas IT technology continues to evolve.",
    "start": "319485",
    "end": "323222"
  },
  {
    "text": "We will see AI systems\nthat truly understand context",
    "start": "323222",
    "end": "326491"
  },
  {
    "text": "and can deliver amazing values to the end user.",
    "start": "326693",
    "end": "329195"
  }
]
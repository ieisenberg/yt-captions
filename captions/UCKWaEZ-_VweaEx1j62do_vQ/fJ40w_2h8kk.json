[
  {
    "text": "PyTorch has emerged as the de facto standard for \nmachine learning and deep learning.",
    "start": "400",
    "end": "6292"
  },
  {
    "text": "And I know a little bit about PyTorch, but I've brought in an \nexpert, Sahdev Zala,",
    "start": "6370",
    "end": "11898"
  },
  {
    "text": "to teach us all more about PyTorch.",
    "start": "11898",
    "end": "14339"
  },
  {
    "text": "So, Sahdev, what is PyTorch?",
    "start": "14455",
    "end": "16581"
  },
  {
    "text": "Hi Brad! So it's a framework for machine learning and deep learning.",
    "start": "16678",
    "end": "21518"
  },
  {
    "text": "And what I mean by that is",
    "start": "21963",
    "end": "26044"
  },
  {
    "text": "you can use PyTorch to build your models",
    "start": "26045",
    "end": "30721"
  },
  {
    "text": "because it provides you all of the building blocks.",
    "start": "30721",
    "end": "33173"
  },
  {
    "text": "It provides you all the functionalities\nto run faster training on that model.",
    "start": "33270",
    "end": "38375"
  },
  {
    "text": "And it's an open source project under PyTorch Foundation, \nwhich is part of the Linux Foundation.",
    "start": "38375",
    "end": "43356"
  },
  {
    "text": "So there is a dynamic community behind the project.",
    "start": "43356",
    "end": "46354"
  },
  {
    "text": "Oh, great! So it's got an ecosystem and it's in the Foundation.",
    "start": "46470",
    "end": "50121"
  },
  {
    "text": "So that means you're going to have open governance\nand a level playing field. That's wonderful.",
    "start": "50121",
    "end": "54357"
  },
  {
    "text": "Well, Sahdev, can you tell \nme about the key features of PyTorch?",
    "start": "54473",
    "end": "58593"
  },
  {
    "text": "Yeah, sure. That's a great question.",
    "start": "58594",
    "end": "61051"
  },
  {
    "text": "So let me just mention \nthe common steps of model training.",
    "start": "61051",
    "end": "65752"
  },
  {
    "text": "So first, you need to prep your data,",
    "start": "65752",
    "end": "68471"
  },
  {
    "text": "your data set for training.",
    "start": "68839",
    "end": "72965"
  },
  {
    "text": "And, ideally you also want to do it for testing.",
    "start": "73139",
    "end": "77760"
  },
  {
    "text": "And then, the other steps is you're \ngoing to build your model.",
    "start": "77876",
    "end": "83367"
  },
  {
    "text": "And you're going to train it.",
    "start": "85498",
    "end": "88464"
  },
  {
    "text": "And as I mentioned, you're going to test.",
    "start": "89045",
    "end": "94063"
  },
  {
    "text": "Okay. So those look like some\npretty straightforward features.",
    "start": "94471",
    "end": "97650"
  },
  {
    "text": "Why don't you tell me about the first one? \nWhat do you mean by prepping the data?",
    "start": "97650",
    "end": "101264"
  },
  {
    "text": "Right. So, the data says are you going to use \nfor your model, maybe small as you're learning it,",
    "start": "101419",
    "end": "106740"
  },
  {
    "text": "but for larger models, these data sets can \nbe huge--10 terabytes, petabytes wide.",
    "start": "106740",
    "end": "112863"
  },
  {
    "text": "So how do you use this data\nto train your model and then test it?",
    "start": "112863",
    "end": "118700"
  },
  {
    "text": "So PyTorch provides you two things here.",
    "start": "119087",
    "end": "122090"
  },
  {
    "text": "Data sets and data loader classes that help \nyou to easily feed this data for your training and testing.",
    "start": "122207",
    "end": "134424"
  },
  {
    "text": "Okay. How does this help me?\nDoes it speed things up?",
    "start": "134579",
    "end": "137200"
  },
  {
    "text": "Well, that's a good question. So, it helps you to download \nthe data to make it accessible for your training and testing.",
    "start": "137336",
    "end": "142847"
  },
  {
    "text": "And this data loader, it provides you iterator over this \ndata so that you can use them to train in a batch.",
    "start": "142847",
    "end": "150837"
  },
  {
    "text": "Because you're not going to just feed one data \nat a time. You're going to train using the batch sizes that you want.",
    "start": "150837",
    "end": "157734"
  },
  {
    "text": "It also provides you other things like shuffling the data.",
    "start": "157734",
    "end": "161135"
  },
  {
    "text": "You don't want to just feed the data in an order so that your model, \nit's only memorizing the data versus versus it's learning.",
    "start": "161233",
    "end": "169549"
  },
  {
    "text": "So this will shuffle for you as well. \nIt has other features as well.",
    "start": "169666",
    "end": "173236"
  },
  {
    "text": "Very nice. Well, it also helps you to build models? ",
    "start": "173372",
    "end": "176681"
  },
  {
    "text": "Absolutely. So, once you think you're ready with your preparation",
    "start": "176818",
    "end": "181200"
  },
  {
    "text": "using PyTorch because it takes you all the takes \ncare of all the complexity, the next step would  ",
    "start": "181200",
    "end": "185599"
  },
  {
    "text": "be and building the model to define your models \nand for that what you need is layers because it's  ",
    "start": "185600",
    "end": "192120"
  },
  {
    "text": "a deep learning, it's made of multiple layers. \nSo you need different layers like linear layer or  ",
    "start": "192120",
    "end": "197000"
  },
  {
    "text": "combination layer. And there are many others that \nare provided by partners to you. And that are also  ",
    "start": "197000",
    "end": "203400"
  },
  {
    "text": "things like, besides layers, that are activation \nfunctions that you'll be using to add nonlinearity  ",
    "start": "203400",
    "end": "211480"
  },
  {
    "text": "to your model-- that's also provided to you by \nPyTorch. So you don't have to do anything but  ",
    "start": "211480",
    "end": "216760"
  },
  {
    "text": "just to call those functions.  ",
    "start": "216760",
    "end": "218823"
  },
  {
    "text": "What do you mean by nonlinearity?",
    "start": "218824",
    "end": "220630"
  },
  {
    "text": "So, in general, when you train the model and then-- it's a \nmathematical term, right, linear as well,  ",
    "start": "220630",
    "end": "226800"
  },
  {
    "text": "but it will if you don't get nonlinear, you \nbasically just get like a one straight line.  ",
    "start": "226800",
    "end": "231680"
  },
  {
    "text": "And in real life, not everything is just \nchanging in X will be same as changing your Y  ",
    "start": "231680",
    "end": "240200"
  },
  {
    "text": "output. So it adds you that nonlinearity for \nyou. And the next step would be training and there  ",
    "start": "240200",
    "end": "248200"
  },
  {
    "text": "basically I can talk more about the training side, Brad. ",
    "start": "248200",
    "end": "252648"
  },
  {
    "text": "Well, so tell me about features-- \nwhat  does it do to help you train? ",
    "start": "252648",
    "end": "255920"
  },
  {
    "text": "So training will require to use the loss function. And loss function  ",
    "start": "255920",
    "end": "259480"
  },
  {
    "text": "is basically to find out the loss that you going \nto have. As when you run this model like  ",
    "start": "259480",
    "end": "267480"
  },
  {
    "text": "a forward pass from the input and you get some \noutput. Well, I'm not going to have the correct output  ",
    "start": "267480",
    "end": "274520"
  },
  {
    "text": "every time magically, there's no magic there. So \nyou can have lots of parameters in between, you are",
    "start": "274520",
    "end": "279120"
  },
  {
    "text": "just going to randomize them in the beginning, \nyou got some output, but then you're going to  ",
    "start": "279120",
    "end": "283000"
  },
  {
    "text": "have a loss function to calculate the loss from \nthe desired output.",
    "start": "283000",
    "end": "287728"
  },
  {
    "text": "So your want your model to reach a certain expectation. \nAnd typically during the training process that model's falling short  ",
    "start": "287728",
    "end": "295880"
  },
  {
    "text": "and you're seeing how much it's falling short \nfrom where you want it to be.",
    "start": "295880",
    "end": "298790"
  },
  {
    "text": "Exactly. So that loss functions, there are multiple loss\nfunctions and PyTorch provides it to you again. You again  ",
    "start": "298790",
    "end": "304720"
  },
  {
    "text": "you call them according to your need for \nthe model. Once you have the loss function used,  ",
    "start": "304720",
    "end": "313560"
  },
  {
    "text": "the next big thing is finding the gradient of this \nloss with regards to your parameters. So PyTorch  ",
    "start": "313560",
    "end": "320680"
  },
  {
    "text": "provides the backward propagation for you, or, \nauto-grade features. That is by far one of the  ",
    "start": "320680",
    "end": "332560"
  },
  {
    "text": "most popular feature of PyTorch, that it will \ncalculate the gradient for you. ",
    "start": "332560",
    "end": "337870"
  },
  {
    "text": "So if we all think back from our calculus days, gradients are \nthis piece that helps you to tweak and  ",
    "start": "337870",
    "end": "346199"
  },
  {
    "text": "get the model the way you want it and it's got \nit built-in for you. ",
    "start": "346200",
    "end": "349554"
  },
  {
    "text": "Exactly. So once you got the gradient, you basically\nrun the optimizer function just to step over, which is again  ",
    "start": "349554",
    "end": "355400"
  },
  {
    "text": "provided by PyTorch to you. And like you exactly \nsaid, you're going to tweak the parameters, you're  ",
    "start": "355400",
    "end": "360080"
  },
  {
    "text": "going to optimize it to reach to a level in a \nnumber of iterations. So that you basically define  ",
    "start": "360080",
    "end": "367240"
  },
  {
    "text": "those iterations. But the number of iterations \nyou're going to reach to a level where we're like,  ",
    "start": "367240",
    "end": "372280"
  },
  {
    "text": "you know what, that should be enough training. \nI do like 3x, 5x iterations, and at that point  ",
    "start": "372280",
    "end": "379120"
  },
  {
    "text": "you are ready to test it. ",
    "start": "379120",
    "end": "382216"
  },
  {
    "text": "And is that a big deal for these models",
    "start": "382216",
    "end": "385161"
  },
  {
    "text": "to have to do testing or I just  test once I'm done? Or is it more more than that? ",
    "start": "385161",
    "end": "388116"
  },
  {
    "text": "Yeah. So the next step would be no. From here to the test side. You need to test it. Ideally it's optional. But as part of testing, PyTorch provides  ",
    "start": "388116",
    "end": "399656"
  },
  {
    "text": "a function, an eval evaluation. So you can \nevaluate your model. And at that point, you're not  ",
    "start": "399656",
    "end": "405960"
  },
  {
    "text": "going to calculate the gradient, you're not going \nto find the loss function. You basically just do  ",
    "start": "405960",
    "end": "412680"
  },
  {
    "text": "the forward pass. You see what you're getting. And \nif you're happy with it, then pretty much ready  ",
    "start": "412680",
    "end": "419039"
  },
  {
    "text": "to use the model. If you're not, then you're \ngoing to do the further training. And again,  ",
    "start": "419040",
    "end": "423320"
  },
  {
    "text": "this data sets, which I mentioned earlier, that \nwould be used for training useful test, white or  ",
    "start": "423320",
    "end": "428800"
  },
  {
    "text": "black are two different datasets.",
    "start": "428800",
    "end": "430263"
  },
  {
    "text": "So as part of the testing. I'm getting to decide, hey, \nis my model good enough? I think I'm ready to go with it.",
    "start": "430264",
    "end": "435466"
  },
  {
    "text": "Pretty much, yeah. ",
    "start": "435466",
    "end": "437077"
  },
  {
    "text": "Well, it all seems a little complicated to me.\nIs PyTorch really easy to use? ",
    "start": "437077",
    "end": "442893"
  },
  {
    "text": "Well, yes,  that's one of the best things I love about PyTorch. \nIt's easy to get started. It's easy to install.  ",
    "start": "442893",
    "end": "450313"
  },
  {
    "text": "It's easy to use because it's Pythonic; the \"Py\" \nin PyTorch is for Python. So you know how much  ",
    "start": "450600",
    "end": "459200"
  },
  {
    "text": "data scientists just love Python. Absolutely. \nPyTorch is in Python. And it's been easily I use  ",
    "start": "459200",
    "end": "467960"
  },
  {
    "text": "by data scientists. And if someone if they don't \nknow Python, they can learn it quickly as well.  ",
    "start": "467960",
    "end": "473680"
  },
  {
    "text": "PyTorch.org provides a lot of good documentation, \ntutorials that will help you to get started very  ",
    "start": "473680",
    "end": "480160"
  },
  {
    "text": "quickly and it's also flexible. So I mentioned \nthe training on your right. You can run training,  ",
    "start": "480160",
    "end": "487080"
  },
  {
    "text": "you can run your PyTorch on CPU just \nusing the tensor that PyTorch uses in  ",
    "start": "487080",
    "end": "494439"
  },
  {
    "text": "data structure (multi-dimensional \narrays). They can be run on CPUs,  ",
    "start": "494440",
    "end": "499320"
  },
  {
    "text": "they can be run on GPUs, they can do the training \non multiple CPU and GPU on a single machine,  ",
    "start": "499320",
    "end": "505720"
  },
  {
    "text": "you can do that on a distributed environment on \nmultiple machines, multiple GPUs. And you can  ",
    "start": "505720",
    "end": "513840"
  },
  {
    "text": "like say part of that you can just run PyTorch on \nyour laptop and play with it. There is also like  ",
    "start": "513840",
    "end": "519599"
  },
  {
    "text": "a mobile development going on to to help PyTorch \non your mobile devices. ",
    "start": "519600",
    "end": "524782"
  },
  {
    "text": "So yeah, it's a lot of  options. Supports a lot of platforms. GPUs. \nCPUs. Well, what if I want to be a contributor?  ",
    "start": "524783",
    "end": "532756"
  },
  {
    "text": "Well, that's great question. Something I love as \nan contributor myself, so it's actually very easy.  ",
    "start": "533000",
    "end": "539200"
  },
  {
    "text": "PyTorch is part of PyTorch Foundation as I \nmentioned. There's a dynamic community behind it,  ",
    "start": "539200",
    "end": "545120"
  },
  {
    "text": "very friendly. Lots of people are going to help \nyou to get started, to contribute. As long as you  ",
    "start": "545120",
    "end": "553080"
  },
  {
    "text": "sign the CLA, follow the code of conduct, these \nare things to do. You are ready to contribute.  ",
    "start": "553080",
    "end": "559160"
  },
  {
    "text": "The community also provides weekly office hours. \n ",
    "start": "559160",
    "end": "562052"
  },
  {
    "text": "Office hours, that's huge. I can come in as\na new person and say, hey, could you help me out",
    "start": "562052",
    "end": "567133"
  },
  {
    "text": "or can you give me an easy first item to work on?\nI could do that in an office hours. ",
    "start": "567133",
    "end": "570343"
  },
  {
    "text": "Yes, exactly. And there are things like you can easily\nfind the good first issues. You can find the document issues to \n ",
    "start": "570343",
    "end": "575668"
  },
  {
    "text": "get started with and you can ask questions. \nAnd the office hours, through their Slack channel is another one. ",
    "start": "575668",
    "end": "582380"
  },
  {
    "text": "And one of the classic tips is when you join a new project, \nask for a mentor and ask them to put you to work on something. Because  ",
    "start": "582380",
    "end": "591360"
  },
  {
    "text": "when they put you to work on something, they're \ngoing to be very interested in what you're doing  ",
    "start": "591360",
    "end": "595440"
  },
  {
    "text": "and they're going to give you timely reviews and \nanswer all your questions. So tell me more about  ",
    "start": "595440",
    "end": "599800"
  },
  {
    "text": "how IBM is contributing to PyTorch.",
    "start": "599800",
    "end": "601933"
  },
  {
    "text": "Yeah, sure. \nWell, IBM is contributing to PyTorch in a big way,",
    "start": "601933",
    "end": "606200"
  },
  {
    "text": "like IBM always do. By using PyTorch, so we are \ngoing to contribute to help the community, grow  ",
    "start": "606200",
    "end": "613240"
  },
  {
    "text": "the community. And a part of that, we working on \nmany different things, something called like FSDP,  ",
    "start": "613240",
    "end": "620800"
  },
  {
    "text": "Fully Sharded Data Parallel, well, an advanced topic, \nbut it helps you to shard the model parameters  ",
    "start": "620800",
    "end": "628120"
  },
  {
    "text": "across multiple GPUs across multiple machines\nfor fast training and for your  ",
    "start": "628120",
    "end": "635760"
  },
  {
    "text": "large models they may not fit in like a single GPU \nor CPU. And so we are contributing there. There's  ",
    "start": "635760",
    "end": "641120"
  },
  {
    "text": "really good blog posts out there. Just search \nfor it, \"IBM FSDP PyTorch\" wiil find it quickly.  ",
    "start": "641120",
    "end": "646920"
  },
  {
    "text": "Highly recommend to read it. We also provide \nimprovements in the storage site for training,  ",
    "start": "646920",
    "end": "653079"
  },
  {
    "text": "compiler optimizations. And besides that benchmarking,\n test side improvements and documentation.  ",
    "start": "653080",
    "end": "662160"
  },
  {
    "text": "And we have multiple developers working in the \ncommunity. ",
    "start": "662160",
    "end": "664910"
  },
  {
    "text": "So it sounds like there's lots of nice features to help it\nsupport those large foundation models, supporting multiple GPUs  ",
    "start": "664910",
    "end": "672120"
  },
  {
    "text": "and running in a distributed fashion. And \na lot of work being done for benchmarking,  ",
    "start": "672120",
    "end": "676880"
  },
  {
    "text": "seeing how fast things are running and obviously \na lot of work in the documentation to help others  ",
    "start": "676880",
    "end": "681760"
  },
  {
    "text": "get started. It's a fabulous. It is.",
    "start": "681760",
    "end": "683508"
  },
  {
    "text": "It's amazing. I'm so glad to be part of the community. ",
    "start": "683508",
    "end": "687837"
  },
  {
    "text": "Well, thank you, Sahdev. I've learned a lot today. This \nis fabulous. We hope that you've learned a lot  ",
    "start": "687837",
    "end": "694727"
  },
  {
    "text": "about PyTorch and we encourage you to come \njoin the community. We really enjoy working  ",
    "start": "694728",
    "end": "701000"
  },
  {
    "text": "on PyTorch and pushing forward with your deep \nlearning/machine learning initiatives.  ",
    "start": "701000",
    "end": "706800"
  },
  {
    "text": "Thanks for watching our video. And don't forget, if you \nliked it, remember to hit like and subscribe.",
    "start": "706800",
    "end": "716600"
  }
]
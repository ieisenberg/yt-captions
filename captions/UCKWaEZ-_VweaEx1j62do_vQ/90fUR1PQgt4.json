[
  {
    "start": "0",
    "end": "55000"
  },
  {
    "text": "What percentage of enterprise data is unstructured data? Kate Soule is Director of Technical",
    "start": "240",
    "end": "5680"
  },
  {
    "text": "Product Management for Granite. Uh, Kate, welcome back to the show. What's your estimate? This feels like a trap, uh, without,",
    "start": "5680",
    "end": "12320"
  },
  {
    "text": "you know, just a, a wild guess. I'm gonna say 40%. Shobhit Varshney is Head of Data and AI for the Americas.",
    "start": "12320",
    "end": "18160"
  },
  {
    "text": "Uh, Shobhit tuning in live from Vegas. Uh, what do you think? 200%. Have you seen the quality of structured data in companies?",
    "start": "18160",
    "end": "25359"
  },
  {
    "text": "All right, great. And last but not least in joining us for the very first time is Hillery Hunter, IBM fellow, and CTO of IBM Infrastructure uh,",
    "start": "25360",
    "end": "32480"
  },
  {
    "text": "you've got an advantage on this question, but I don't know if you wanna offer your guess. Yeah, I'll, I'll take the midpoint there. Uh, not exactly the midpoint,",
    "start": "32480",
    "end": "38560"
  },
  {
    "text": "but uh, I'll go with 80%. Okay, great. So the answer is 90%. Uh, we're gonna talk about that today and all that, and more on the.",
    "start": "38560",
    "end": "45520"
  },
  {
    "text": "Very 50th episode of Mixture of Experts 50th episode. Crazy and welcome for Woo-hoo.",
    "start": "45520",
    "end": "50720"
  },
  {
    "text": "Yeah.\nWoo-hoo.",
    "start": "50720",
    "end": "53520"
  },
  {
    "start": "55000",
    "end": "702000"
  },
  {
    "text": "I'm Tim Hwang and welcome to Mixture of Experts. Each week, MoE brings together a talented and just lovely group of researchers, product",
    "start": "56800",
    "end": "63360"
  },
  {
    "text": "leaders, and more to discuss and debate the week's top headlines in artificial intelligence. As always, there's a ton to cover.",
    "start": "63360",
    "end": "70159"
  },
  {
    "text": "We're gonna talk about the Llama 4 release, Shobhit's in Vegas. He's gonna tell us all about Google Cloud Next.",
    "start": "70160",
    "end": "76159"
  },
  {
    "text": "Some really super interesting research coming outta Pew Research. Uh, but today, uh, we want to take the opportunity because Hillery is on the line with",
    "start": "76160",
    "end": "82960"
  },
  {
    "text": "us, uh, to talk about IBM z, which is a new launch that just came out on I believe Tuesday.",
    "start": "82960",
    "end": "89120"
  },
  {
    "text": "Um, and it concerns mainframes. Uh, and so I guess, Hillery do you wanna just start for listeners who are less",
    "start": "89120",
    "end": "94320"
  },
  {
    "text": "familiar with the sector, what is a mainframe anyways and why is it important? Yeah, I'm, I think first fun fact is \"z\"",
    "start": "94320",
    "end": "100640"
  },
  {
    "text": "stands for zero downtime and mathematically, that's kind of an interesting conversation. We talk about the system now having eight",
    "start": "100640",
    "end": "107280"
  },
  {
    "text": "nines of reliability and the way that you, you count those nines, as you say, it's 99 point and then six more nines.",
    "start": "107280",
    "end": "114080"
  },
  {
    "text": "So that's how you get to, it's a lot of nines. Nines resiliency. Yeah. But it means just a couple hundred milliseconds, a year of downtime on average.",
    "start": "114080",
    "end": "121840"
  },
  {
    "text": "And so, you know, when I talk to family members or I, I meet someone socially. I kind of say we work on building the computers",
    "start": "121840",
    "end": "129039"
  },
  {
    "text": "that you don't see and that you just sort of assume are there and never think about. And what that means is really, this",
    "start": "129040",
    "end": "135520"
  },
  {
    "text": "is where most of the world's financial transaction volume, everything from things in the market to your personal credit card",
    "start": "135520",
    "end": "142319"
  },
  {
    "text": "transactions go through it in the back end. And you hopefully never think about whether or not that computer's gonna work or your",
    "start": "142320",
    "end": "148080"
  },
  {
    "text": "credit card transaction goes through. These are these systems that we just all assume are up all the time.",
    "start": "148080",
    "end": "153120"
  },
  {
    "text": "And so it's really kind of at the core of. The global economy, to be honest, that's really not an exaggeration.",
    "start": "153120",
    "end": "158400"
  },
  {
    "text": "Yeah.\nWhat I love about this is like you work on like arguably the hi, some of the highest of highest stakes computing.",
    "start": "158400",
    "end": "164720"
  },
  {
    "text": "Um, and I think one of the most interesting things about the launch is that I know AI is a, a, a big part of this launch in some ways.",
    "start": "164720",
    "end": "171440"
  },
  {
    "text": "Um, I know there's sort of z17 which is the mainframe, and then there's \"z\" sort of the software, which sounds like kind",
    "start": "171440",
    "end": "177600"
  },
  {
    "text": "of IBM pushing into the idea that these, you know, 6 9s of reliability computers.",
    "start": "177600",
    "end": "182960"
  },
  {
    "text": "Really are gonna get, you know, sort of integrated into the overall sort of AI revolution, which, you know, we talked about on the show before.",
    "start": "182960",
    "end": "188959"
  },
  {
    "text": "AI, you know, is, is is not always kind of like production. It, it like sometimes, you know, messes up,",
    "start": "188960",
    "end": "194400"
  },
  {
    "text": "it's stochastic, it has all sorts of randomness. So curious to hear a little bit more about like what's getting launched on the software",
    "start": "194400",
    "end": "200080"
  },
  {
    "text": "side and I guess how you kind of like get AI to work at like such a high level of reliability that I think most software",
    "start": "200080",
    "end": "205920"
  },
  {
    "text": "developers never even need to think about as they're kind of vibe coding or whatever. Yeah, it's, it's a pretty different space, but",
    "start": "205920",
    "end": "211599"
  },
  {
    "text": "it's equally fascinating, I think to that whole vibe coding kind of space that a lot of folks are interacting with now on a daily basis.",
    "start": "211600",
    "end": "218480"
  },
  {
    "text": "Um, from a technical perspective, getting things done in transaction means having millisecond",
    "start": "218480",
    "end": "224480"
  },
  {
    "text": "level AI and that means super, super fast, tightly integrated, being able to handleÂ \nbillions of transactions a day, um, and",
    "start": "224480",
    "end": "234560"
  },
  {
    "text": "being able to score things at line speed, right? So. Again, anecdotal sort of example,",
    "start": "234560",
    "end": "240480"
  },
  {
    "text": "if you're talking about fraud and analytics in the credit card transaction processing space.",
    "start": "240480",
    "end": "246960"
  },
  {
    "text": "If I as a consumer am buying something online, it's okay. There's minutes to hours before the thing gets",
    "start": "246960",
    "end": "252320"
  },
  {
    "text": "shipped out, you know, so fraud can happen offline, but if it's in a store and somebody's trying to rip you off and buy an expensive",
    "start": "252320",
    "end": "258799"
  },
  {
    "text": "phone or something like that, at Best Buy, you wanna make sure that instantaneously, the moment the transaction goes through,",
    "start": "258800",
    "end": "264240"
  },
  {
    "text": "that it's detected as being fraudulent. And so there's actual real economic value and consumer value to being able",
    "start": "264240",
    "end": "269520"
  },
  {
    "text": "to score every transaction in real time. The interesting thing that we're now",
    "start": "269520",
    "end": "274560"
  },
  {
    "text": "talking about being possible on this next generation of mainframe is multi-model AI. So a really small, fast compact model that's",
    "start": "274560",
    "end": "282000"
  },
  {
    "text": "running there, right on the processor, dealing with this massive transaction throughput. Maybe occasionally it has low confidence in",
    "start": "282000",
    "end": "288160"
  },
  {
    "text": "the scoring it provided, and it needs to be backed up by a bit more robust, complicated model, and so we're putting extra AI cards",
    "start": "288160",
    "end": "295680"
  },
  {
    "text": "called the Spyre card into the system to enhance not just being able to do that super fast processing on the processor itself.",
    "start": "295680",
    "end": "302480"
  },
  {
    "text": "But also do fast processing, one step slightly removed and adjacent on a PCIe attached set of cards.",
    "start": "302480",
    "end": "309120"
  },
  {
    "text": "And so we've just multiplied the AI capacity, um, and throughput for the system.",
    "start": "309120",
    "end": "314319"
  },
  {
    "text": "And also then from the perspective of then the total system experience on the software side, like you said.",
    "start": "314320",
    "end": "319840"
  },
  {
    "text": "We now something called Operations Unite, which is AIOps driven AI chat driven interface",
    "start": "319840",
    "end": "326080"
  },
  {
    "text": "to everything going on in the system. So observing, remediating issues, all happening in a totally modern interface.",
    "start": "326080",
    "end": "333040"
  },
  {
    "text": "So it's pervasive once you put the AI capability in. It's not just about the workloads running in the system, but also how people use and operate",
    "start": "333040",
    "end": "339759"
  },
  {
    "text": "and keep the whole thing stable and healthy. Yeah,\nthat's awesome. So Shobhit I'd love to bring you in. I, I know I launched this episode",
    "start": "339760",
    "end": "345360"
  },
  {
    "text": "with a question about just. How much unstructured data, uh, enterprises are sitting on, and I'm sure this is a problem",
    "start": "345360",
    "end": "350639"
  },
  {
    "text": "that you have to deal with and that you talk about with customers day in, day out. Uh, I know that's a component of this launch,",
    "start": "350640",
    "end": "356400"
  },
  {
    "text": "but curious if you want to just opine a little bit on kind of how the world is evolving there and I guess how the Z launch",
    "start": "356400",
    "end": "361520"
  },
  {
    "text": "sort of fits into some of those questions. Uh, a big fan of, uh, of, of the Z Series and I",
    "start": "361520",
    "end": "366640"
  },
  {
    "text": "grew up in a cloud, first AI, first world, and I have so much respect for understanding the right balance between where mainframe should",
    "start": "366640",
    "end": "373360"
  },
  {
    "text": "be playing versus where the clouds are, right? So as an example, working with a very, very large bank where we leveraging cloud",
    "start": "373360",
    "end": "379840"
  },
  {
    "text": "environments with a lot of different GPUs and compute behind it to train the models. But once you have fine tuned the models",
    "start": "379840",
    "end": "385919"
  },
  {
    "text": "to enterprise data, you wanna go bring it where the transactions are happening. And these are sub milliseconds, right?",
    "start": "385920",
    "end": "391840"
  },
  {
    "text": "Very, very quickly. You're having doing this, and you're doing billions and billions of these every hour. So you want to bring the AI",
    "start": "391840",
    "end": "398320"
  },
  {
    "text": "inference as close as possible to where the transaction is happening. In the first wave of doing unstructured",
    "start": "398320",
    "end": "404080"
  },
  {
    "text": "content analysis, you would have some large language model that summarizes a call recording or starts to do some",
    "start": "404080",
    "end": "409920"
  },
  {
    "text": "knowledge search and things of that nature. Now, in the next wave, once we've proven out that this technology is working, you wanna",
    "start": "409920",
    "end": "415440"
  },
  {
    "text": "do this in more mission critical workflows. For example, when fraud detection happens, like Hillery was mentioning, there's a lot",
    "start": "415440",
    "end": "421439"
  },
  {
    "text": "of, uh, patterns that we need to look for. It's not just that one transaction that happened. You also need to look for",
    "start": "421440",
    "end": "426800"
  },
  {
    "text": "how that transaction was. Was, uh. At that point of the transaction happening in sub milliseconds, the",
    "start": "426800",
    "end": "433520"
  },
  {
    "text": "larger models have a lot of latency. You can obviously not afford to have that, that data go out to the cloud",
    "start": "433520",
    "end": "439360"
  },
  {
    "text": "and come back A, security issues and B, the latency and, and, and other things. Right? So you, you, we are in the world where we see.",
    "start": "439360",
    "end": "446800"
  },
  {
    "text": "A lot of our larger fortune hundred companies move from experimenting with",
    "start": "446800",
    "end": "452000"
  },
  {
    "text": "large, uh, frontier models that are API calls to then fine tuning smaller open",
    "start": "452000",
    "end": "457040"
  },
  {
    "text": "models and bring them close to the compute. So I think the Z series works incredibly in this space.",
    "start": "457040",
    "end": "462080"
  },
  {
    "text": "And we also have the brand permission with Z. They're like, what, Hillery What? 90% of all credit card transactions",
    "start": "462080",
    "end": "468480"
  },
  {
    "text": "happen on Z and 90% of the Fortune 50 banks rely on us and whatnot. Airlines, retailers.",
    "start": "468480",
    "end": "475039"
  },
  {
    "text": "So you're on the mission critical workflows. This is no longer, Hey, let me ask the prompt a different way, right?",
    "start": "475040",
    "end": "480320"
  },
  {
    "text": "So you're not experimenting, you are doing this in, in more critical workflows. You know, I love that you went to latency. I think one of the things related as well",
    "start": "480320",
    "end": "486880"
  },
  {
    "text": "to that whole leaving the system is the data security model, data sovereignty, all those other really hot topics.",
    "start": "486880",
    "end": "493040"
  },
  {
    "text": "And so I think also bringing AI to where that data is and where that mission critical data is, where that valuable and",
    "start": "493040",
    "end": "498240"
  },
  {
    "text": "sensitive consumer and personal information is, is a big part of this conversation. I, I think one other thing, in",
    "start": "498240",
    "end": "503759"
  },
  {
    "text": "addition, again to latency and then that data protection is also the energy. So we've greatly increased the AI capability and",
    "start": "503760",
    "end": "510879"
  },
  {
    "text": "the overall capability of the system, but drop this whole system generation to generation by",
    "start": "510880",
    "end": "516000"
  },
  {
    "text": "17% in the power consumption, and the team has measured that it's about five x more efficient",
    "start": "516000",
    "end": "521360"
  },
  {
    "text": "to do that AI in place where the data is. Then, to your point, calling out to some external system.",
    "start": "521360",
    "end": "526560"
  },
  {
    "text": "So these days everybody's running outta power, looking to take out more data centers base, all that other kind of stuff,",
    "start": "526560",
    "end": "531920"
  },
  {
    "text": "and being able to do AI so efficiently, I think is a, is a really exciting step forward. And Hillery just, just about a month back,",
    "start": "531920",
    "end": "538480"
  },
  {
    "text": "I was with one of the largest top three credit card companies and we were having this, uh, concern around fraud detection",
    "start": "538480",
    "end": "543520"
  },
  {
    "text": "and said, uh, we can obviously do a lot of LLM work to understand patterns, right? It's not just a spot in time.",
    "start": "543520",
    "end": "550240"
  },
  {
    "text": "And even a month back, we struggled to bring models that are LLM models.",
    "start": "550240",
    "end": "555360"
  },
  {
    "text": "In real time transactions 'cause it just sub, sub millisecond and stuff. And I was just so proud that in the last week we, this week we've been able",
    "start": "555360",
    "end": "562400"
  },
  {
    "text": "to go after those use cases that we couldn't even, even a few weeks back. Right. So we are coming to a point where clients",
    "start": "562400",
    "end": "568160"
  },
  {
    "text": "understand that they've proven it out inside of their enterprises that we can use LLMs and we've trained them",
    "start": "568160",
    "end": "573280"
  },
  {
    "text": "in a particular way, but latency was coming in the way of us doing this work. A lot of our clients are just huge",
    "start": "573280",
    "end": "578880"
  },
  {
    "text": "kudo to your team to doing this right. I think you bring enough AI and, and to your point, the creativity just explodes.",
    "start": "578880",
    "end": "583920"
  },
  {
    "text": "Every developer in kind of this core of the enterprise space is now, oh, that's now for me. That's not something for people",
    "start": "583920",
    "end": "589120"
  },
  {
    "text": "elsewhere in different environments. It's now insurance claims processing, even medical image assessment. There's all kinds of amazing",
    "start": "589120",
    "end": "595680"
  },
  {
    "text": "things going on on that core data. 'cause AI is also for those people and for that data and for that context also.",
    "start": "595680",
    "end": "601680"
  },
  {
    "text": "That's super exciting. So Hillery, before we move on to the next topic, what, uh, what comes next for you all? Yeah, so the capabilities with",
    "start": "601680",
    "end": "608560"
  },
  {
    "text": "Spyre come out in 4th quarter. There's rolling set of announcements on the different software enhancements, and I think",
    "start": "608560",
    "end": "614320"
  },
  {
    "text": "the way to think about it is we're making these systems AI through and through, like I kind of mentioned, you know, starting back even",
    "start": "614320",
    "end": "620000"
  },
  {
    "text": "in z/OS 3.1, the last release there was AI inside things starting to look in that direction",
    "start": "620000",
    "end": "625520"
  },
  {
    "text": "of self-healing or, or sort of automation of management, of the efficiency of the system. Uh, what we've stated about z/OS 3.2, which is",
    "start": "625520",
    "end": "633519"
  },
  {
    "text": "gonna be coming out is, is even more integration of that smartness into the core of and the heart of how the system operates, and then how",
    "start": "633520",
    "end": "640400"
  },
  {
    "text": "operations teams experience it and going all the way out even into our support staffing.",
    "start": "640400",
    "end": "645440"
  },
  {
    "text": "So. If you call IBM for help with something, now we are also using watsonx technology to help those",
    "start": "645440",
    "end": "652400"
  },
  {
    "text": "agents who are helping you with your mainframe. So that's a project that we started with in our technology lifecycle services",
    "start": "652400",
    "end": "658400"
  },
  {
    "text": "organization with our storage products. And we're, you know, we've announced now this week that we're also bringing that to mainframe support.",
    "start": "658400",
    "end": "664880"
  },
  {
    "text": "So that whole experience end to end, how the system runs, what you can do on it, what you understand about it, and",
    "start": "664880",
    "end": "670160"
  },
  {
    "text": "then how somebody helps support you is. All gonna be AI enabled. And I think that end-to-end in full",
    "start": "670160",
    "end": "675279"
  },
  {
    "text": "stack story is, is just really exciting. This is us living what we've been talking about with the power of AI.",
    "start": "675280",
    "end": "681680"
  },
  {
    "text": "This is awesome. Yeah.\nSo we'd love to have you back on the show as things unfold here. I think it's a, like a segment of AI that",
    "start": "681680",
    "end": "686720"
  },
  {
    "text": "we haven't talked as much about, but I, I love it personally just 'cause it is like this kind of very high stakes thing. You really gotta get it right in these domains.",
    "start": "686720",
    "end": "693360"
  },
  {
    "text": "And so, um, you know, it's a kind of AI, almost engineering that you don't really see in a whole lot of other.",
    "start": "693360",
    "end": "698960"
  },
  {
    "text": "Which is really exciting.",
    "start": "698960",
    "end": "704800"
  },
  {
    "start": "702000",
    "end": "1502000"
  },
  {
    "text": "So I'm gonna move us on to our next topic. Uh, Meta has released LLlama 4 a long",
    "start": "704800",
    "end": "710000"
  },
  {
    "text": "awaited release in the open source space. Um, there's three models that they've talked about. Two of them actually announced,",
    "start": "710000",
    "end": "716160"
  },
  {
    "text": "uh, the Scout model, the Maverick model, and the Behemoth model. Um, and it follows in a pattern that we've seen.",
    "start": "716160",
    "end": "722640"
  },
  {
    "text": "Elsewhere in the open source space where people are launching both smaller models and bigger models to meet a variety of different applications.",
    "start": "722640",
    "end": "729200"
  },
  {
    "text": "Um, Kate, maybe I'll start with you. I don't know if you had a chance to kind of play with some of the models yet, but curious about your early impressions, your vibe,",
    "start": "729200",
    "end": "734960"
  },
  {
    "text": "check, uh, on, on how this release went. Yeah. Uh, you know, it's been a busy week, so I haven't had a chance to to play with them",
    "start": "734960",
    "end": "740640"
  },
  {
    "text": "directly, but it's really exciting to, I've been reading up on them, uh, certainly, and it's really exciting to see what Meta put out there.",
    "start": "740640",
    "end": "747279"
  },
  {
    "text": "Uh, I mean, with the release of their largest model, which is, uh, you know, over 400 billion parameters, I believe,",
    "start": "747280",
    "end": "753840"
  },
  {
    "text": "mixture of experts and a hundred billion parameters, I think is the scout. Uh, they're really starting to",
    "start": "753840",
    "end": "759040"
  },
  {
    "text": "take on larger and larger tasks and create, you know, some powerful models out in the open source ecosystem.",
    "start": "759040",
    "end": "765279"
  },
  {
    "text": "I think with the, uh, announcement of their B myth model, which is, you know. 2 trillion, uh, parameters.",
    "start": "765280",
    "end": "771600"
  },
  {
    "text": "Uh, I think what they said said that's big, right?\nThat's big. That's, that's pretty big, Tim.",
    "start": "771600",
    "end": "776640"
  },
  {
    "text": "Um, so, you know, they're, they're talking about, you've already on earlier trained versions, checkpoints, uh, it's",
    "start": "776640",
    "end": "783360"
  },
  {
    "text": "cracking GPT-4 0.5 on tasks like science. So they're clearly, you know, putting themselves",
    "start": "783360",
    "end": "789920"
  },
  {
    "text": "out there as a frontier model provider. And doing that in the open, I think is only gonna continue to",
    "start": "789920",
    "end": "795519"
  },
  {
    "text": "put more pressure on these closed. Labs to release some of their work out in the open as well, and",
    "start": "795520",
    "end": "801600"
  },
  {
    "text": "more broadly help the community. So that, that's really interesting. Um, I think there is a lot to be",
    "start": "801600",
    "end": "807439"
  },
  {
    "text": "said about the, uh, mixture of experts architecture that's going on. Uh, where we see, you know, obviously",
    "start": "807440",
    "end": "814000"
  },
  {
    "text": "DeepSeek made this famous, uh, when they first released, uh, back in December or so, uh, with, not first released, but",
    "start": "814000",
    "end": "821279"
  },
  {
    "text": "released a big update to their family. Um, it's. An architecture that's been used more broadly even before that.",
    "start": "821280",
    "end": "827200"
  },
  {
    "text": "But I'm really hopeful that this release will help get broader community support behind mixture of expert architecture.",
    "start": "827200",
    "end": "833279"
  },
  {
    "text": "'cause there's just tons of, uh, really interesting things about it. Very training efficient, um,",
    "start": "833280",
    "end": "838640"
  },
  {
    "text": "inference efficient, particularly if run at a, a low batch size. So. You only have to use the experts that, that",
    "start": "838640",
    "end": "845600"
  },
  {
    "text": "you need to call at inference time, which, you know, if you're just running, you know, one or two tasks, uh, can be run really efficiently.",
    "start": "845600",
    "end": "852079"
  },
  {
    "text": "You start to lose a little bit of that if you have to run these at much larger batch sizes. 'cause you have to load all your experts into memory.",
    "start": "852080",
    "end": "857680"
  },
  {
    "text": "So most people don't quite realize that about mixture of experts. But either way, really excited to see just another",
    "start": "857680",
    "end": "864080"
  },
  {
    "text": "power horse model get released, uh, in this case, two power horse models get released out into the open. Yeah, for sure.",
    "start": "864080",
    "end": "869600"
  },
  {
    "text": "And if you can go into that a little bit more for some of our listeners. I mean, I miss namesake of the show, so I have to kind of fight for it,",
    "start": "869600",
    "end": "875840"
  },
  {
    "text": "but it's like, has mixture of experts been a little bit uncool as of late? Like, I guess, is this kind of you, it sounds like what you're implying is sort",
    "start": "875840",
    "end": "881760"
  },
  {
    "text": "of like these models might like make it like a focus of the community again in a way that it hasn't in the past.",
    "start": "881760",
    "end": "886880"
  },
  {
    "text": "And I'm, I'm kind of curious about how that, how that's developed. Well, I mean even just with the the Z system, right? We're talking about the focus on inference",
    "start": "886880",
    "end": "893440"
  },
  {
    "text": "efficiency, running things quickly at inference time, and a lot of what requires that, or what enables that is the",
    "start": "893440",
    "end": "900960"
  },
  {
    "text": "community building open source software and platforms to be able to host and run these models as quickly and fast as possible.",
    "start": "900960",
    "end": "907920"
  },
  {
    "text": "And just because the most popular open source models to date, including pre prior generations of Llama, have been dense.",
    "start": "907920",
    "end": "913920"
  },
  {
    "text": "Architecture models, a lot of the existing support for hosting and running these models,",
    "start": "913920",
    "end": "919120"
  },
  {
    "text": "running them locally, run, hosting them and running them yourselves on platforms like VLM are, you know, predominantly based on some",
    "start": "919120",
    "end": "925520"
  },
  {
    "text": "of those more popular dense architectures. So there is going to need to be kind of a, a groundswell movement of the",
    "start": "925520",
    "end": "930560"
  },
  {
    "text": "community continuing to build out support. I think we've seen a lot of that already with the release of Llama 4, and I'm just excited",
    "start": "930560",
    "end": "936000"
  },
  {
    "text": "to get more open source developers interested. In mixture of experts as architecture as a whole and continue to build out",
    "start": "936000",
    "end": "942640"
  },
  {
    "text": "toolings and, you know, ways that we can work with these models more broadly. Sure.\nBut maybe I'll bring you in here a little bit.",
    "start": "942640",
    "end": "948240"
  },
  {
    "text": "You know, I think that there's coff in a way this discussion goes, which I think is like less interesting, where it's basically like, okay, Meta did this release now,",
    "start": "948240",
    "end": "954960"
  },
  {
    "text": "like, who's ahead, you know, in this race? But like, I think that's often like the wrong way to think about it, particularly",
    "start": "954960",
    "end": "960240"
  },
  {
    "text": "as the space gets more and more complex. Yeah.\nLike how should we read into this? Sort of launch about what Meta strategy",
    "start": "960240",
    "end": "966480"
  },
  {
    "text": "is and how it's trying to kind of like fill a, a niche in the market, right? Because I think rather than thinking about like,",
    "start": "966480",
    "end": "971680"
  },
  {
    "text": "oh, DeepSeek is ahead, or Meta is ahead, I think we should just kinda ask the question of just like, how are the strategies sort of evolving?",
    "start": "971680",
    "end": "977680"
  },
  {
    "text": "Absolutely.\nYeah. I'm curious if you have some thoughts like what you read into this launch, basically. So let's just start by, by acknowledging",
    "start": "977680",
    "end": "983600"
  },
  {
    "text": "what a consequential, uh, impact Llama has had on industry, the Llama",
    "start": "983600",
    "end": "989120"
  },
  {
    "text": "models have been as of like 18th of March, they've been downloaded a billion times.",
    "start": "989120",
    "end": "994224"
  },
  {
    "text": "Sure.\nLet, let's just let that sink in A billion. That's a lot times we've downloaded a model and made different versions of it adapted and this of that nature.",
    "start": "994224",
    "end": "1000880"
  },
  {
    "text": "Right. So a lot of enterprise that we work with, they are, we are very focused on how do I adapt a",
    "start": "1000880",
    "end": "1006320"
  },
  {
    "text": "model to our enterprise specific domain, our data, and the way we want the models to behave.",
    "start": "1006320",
    "end": "1011760"
  },
  {
    "text": "Right. That adaptation comes only when you're really, really open. There are certain, uh, frontier models",
    "start": "1011760",
    "end": "1017760"
  },
  {
    "text": "that can be adapted fine tuning, but then you're leaving, you're sending your proprietary data to the cloud. That's a no go.",
    "start": "1017760",
    "end": "1023680"
  },
  {
    "text": "So usually open models, open weight models are fine, uh, in that space where you can go and tune them to that.",
    "start": "1023680",
    "end": "1030240"
  },
  {
    "text": "So our own Granite models, there's some models from Mistral and DeepSeek and others are also",
    "start": "1030240",
    "end": "1036160"
  },
  {
    "text": "open weights, open models. But it takes quite a bit to create a good mechanism to assess the quality of an output.",
    "start": "1036160",
    "end": "1044319"
  },
  {
    "text": "So for a lot of our clients, we have to go and gr build end-to-end LLM benchmarking mechanisms.",
    "start": "1044320",
    "end": "1049840"
  },
  {
    "text": "How do you evaluate the output on your specific documents? So the. Benchmark results that are public.",
    "start": "1049840",
    "end": "1056559"
  },
  {
    "text": "Those are a good starting point to get you a directional y check to say, yeah, it's worth looking at. 'cause Llama 4 did X better, but",
    "start": "1056560",
    "end": "1063279"
  },
  {
    "text": "none of my clients jump up and down saying that, oh my God, this is like 0.2 points higher than the other one. Right?",
    "start": "1063280",
    "end": "1068880"
  },
  {
    "text": "People have other criteria that we use to judge which LLM uh, we should be leveraging. It starts by IP.",
    "start": "1068880",
    "end": "1075440"
  },
  {
    "text": "Who can own the IP on that model. It starts with where the data gravity AI model follows the data gravity.",
    "start": "1075440",
    "end": "1081680"
  },
  {
    "text": "It's actually commitments that you've made to specific vendor cloud vendors, right? There is things around can I adapt this",
    "start": "1081680",
    "end": "1088480"
  },
  {
    "text": "to my own, uh, to my own environment? And then return on investment, the overall ROI of running these models.",
    "start": "1088480",
    "end": "1094400"
  },
  {
    "text": "So you'll see a trend towards every six months. The next size smaller model gets smart enough to outcompete the",
    "start": "1094400",
    "end": "1100400"
  },
  {
    "text": "previous one from six months back. So we're seeing this constant trend where we're getting really good",
    "start": "1100400",
    "end": "1105760"
  },
  {
    "text": "power, like the performance to. The cost ratio, right? I think that's the sweet spot, and",
    "start": "1105760",
    "end": "1111840"
  },
  {
    "text": "Llama has done a really good job. I would anticipate that we'll continue this trajectory of a billion downloads and we'll have different adapted versions",
    "start": "1111840",
    "end": "1118159"
  },
  {
    "text": "of Llama available for our enterprises. That's the right frame to look at it versus, oh my God, this just crushed",
    "start": "1118160",
    "end": "1123760"
  },
  {
    "text": "the numbers on this particular task. Then there is, uh, then there are other models that will constantly",
    "start": "1123760",
    "end": "1128960"
  },
  {
    "text": "innovate with new methodologies. I think DeepSeek did a phenomenal job with, with some of the paperwork, our Granite models.",
    "start": "1128960",
    "end": "1135200"
  },
  {
    "text": "We have some really nice tricks up our sleeves in our own models, and we give back to the community too. So I'm just super pumped about",
    "start": "1135200",
    "end": "1140960"
  },
  {
    "text": "the community coming together. Open source, getting to a point you can adapt it to the enterprise and very, very focused",
    "start": "1140960",
    "end": "1147440"
  },
  {
    "text": "on intelligence, uh, divided by the price and the what, and that kind of a metric. Hillery, maybe I'll bring you in,",
    "start": "1147440",
    "end": "1153759"
  },
  {
    "text": "um, you know, just to talk a little bit about this Behemoth model. I know it wasn't released, but it is like shockingly large.",
    "start": "1153760",
    "end": "1160960"
  },
  {
    "text": "Um, and, and it's cool on one level, you're like, wow, okay. It's like really, it's really big. I'm kind of curious though, like from your",
    "start": "1160960",
    "end": "1167360"
  },
  {
    "text": "point of view, you know, the degree to which like these are actually kind of like. Practical models that a lot of people will",
    "start": "1167360",
    "end": "1172800"
  },
  {
    "text": "use in the wild, 'cause it sort of feels like the kind of infra you need to pull off. Like really actually serving and using a model of the scale.",
    "start": "1172800",
    "end": "1179280"
  },
  {
    "text": "Like there's part of me is like, is this just kind of a more of a marketing thing than it is actually like a practical reality. But curious about your take on, on this",
    "start": "1179280",
    "end": "1185600"
  },
  {
    "text": "is like, is there room for open source on the like mega, mega, mega scale model? Just because it kind of almost like",
    "start": "1185600",
    "end": "1191600"
  },
  {
    "text": "limits like the set of people who would actually practically end up using it. Yeah. I guess a, I have a lot of similar",
    "start": "1191600",
    "end": "1196640"
  },
  {
    "text": "thoughts to what Shobhit just shared. Um, a couple of things, right? I mean, within IBM Infrastructure, we're also handling, creating the cloud infrastructure",
    "start": "1196640",
    "end": "1203120"
  },
  {
    "text": "for watsonx and deployment of all these infra services and stuff like that. So the other part of my brain is, is looking",
    "start": "1203120",
    "end": "1210000"
  },
  {
    "text": "at how do we bring, you know, more and more powerful accelerators of all kinds into that cloud environment to do whatever",
    "start": "1210000",
    "end": "1215680"
  },
  {
    "text": "it is that watsonx needs to do, right? So if our customers are gonna need those really big models. I'm not gonna be the one that says No, we",
    "start": "1215680",
    "end": "1221440"
  },
  {
    "text": "won't provide the infrastructure for it. Right?\nSo we're advancing with NVIDIA and Intel and a MD and putting, you know, new and",
    "start": "1221440",
    "end": "1227440"
  },
  {
    "text": "more GPUs out there to enable people to play around with models as large",
    "start": "1227440",
    "end": "1233440"
  },
  {
    "text": "as they feel like are gonna be useful. I think on the practical side though, we see a lot of experimentation or attempts to use",
    "start": "1233440",
    "end": "1240320"
  },
  {
    "text": "these things maybe from a teaching perspective. Um, but then when it comes to scaling out",
    "start": "1240320",
    "end": "1245760"
  },
  {
    "text": "deployments, almost all of our customers then start to engage with us on how can I customize smaller things, right?",
    "start": "1245760",
    "end": "1252240"
  },
  {
    "text": "So I feel like you sort of have to know where things are at on the large side and what it might do for you.",
    "start": "1252240",
    "end": "1257760"
  },
  {
    "text": "You may use that to inform yourself on, you know, what the solution might look like or, uh, maybe create,",
    "start": "1257760",
    "end": "1264080"
  },
  {
    "text": "um, you know, additional tuning data or something like that, you know, to get that characteristic that you need out of something",
    "start": "1264080",
    "end": "1269360"
  },
  {
    "text": "that's then gonna be affordable to scale. So I continue like show bsu most of our customers saying, Hey.",
    "start": "1269360",
    "end": "1275920"
  },
  {
    "text": "Um, you know, work largely in kind of the B2B space. As, as, as IBM we're working with other large enterprises who have millions",
    "start": "1275920",
    "end": "1282480"
  },
  {
    "text": "to hundreds of millions of clients. And when you're wanting to engage with all of them and run at business scale of billions",
    "start": "1282480",
    "end": "1289680"
  },
  {
    "text": "and hundreds of millions of things and people, um, the affordability very quickly kind of kicks in and people, you know, start",
    "start": "1289680",
    "end": "1296080"
  },
  {
    "text": "looking at customization of smaller things for real scale out of, of deployments. Well, and if I can make a",
    "start": "1296080",
    "end": "1301200"
  },
  {
    "text": "prediction based off of what Hillery, you just said. Um, and, and kind of speaking to Shobhit, what",
    "start": "1301200",
    "end": "1306880"
  },
  {
    "text": "you mentioned about, you know, small LLMs are increasingly being able to do more things. You know, I, my prediction is that",
    "start": "1306880",
    "end": "1314000"
  },
  {
    "text": "most of the models for, uh, Llama 4 that were released, they're very, even the smallest one is quite big.",
    "start": "1314000",
    "end": "1319040"
  },
  {
    "text": "You know, a hundred billion parameters. I think they're going to be used most by the community to fine tune some",
    "start": "1319040",
    "end": "1324080"
  },
  {
    "text": "of the older, smaller Llama 3 models. So if we look at what can run on a laptop, what you can easily train and customize,",
    "start": "1324080",
    "end": "1331279"
  },
  {
    "text": "you're really talking, you know, like, uh, one to 10 billion parameters in size, uh,",
    "start": "1331280",
    "end": "1336880"
  },
  {
    "text": "more and you know, maybe a dense architecture. 'cause there's a lot of tuning support for that kind of capability, uh, model already created.",
    "start": "1336880",
    "end": "1344080"
  },
  {
    "text": "So. I think that some of the most immediate uses of these biggest models are going to be to continue",
    "start": "1344080",
    "end": "1349840"
  },
  {
    "text": "on that trend of how do we get those smaller models even more performant, uh, by using those bigger models to be able to teach, to be able",
    "start": "1349840",
    "end": "1356800"
  },
  {
    "text": "to generate data, to be able to help augment existing enterprise data and create more of it, and them bring that and pack that down into",
    "start": "1356800",
    "end": "1363520"
  },
  {
    "text": "smaller models like the older generations of Llama our generation of Granite, um, all playing in that, you know, single",
    "start": "1363520",
    "end": "1369720"
  },
  {
    "text": "digit billion parameter size frame. I, I, I totally agree, Kate. And I think one other, you know, little factoid, I'm sure you guys have talked",
    "start": "1369720",
    "end": "1375519"
  },
  {
    "text": "about this before, but it's estimated that only about 1% of enterprise data or 1% of the things in enterprise needs",
    "start": "1375520",
    "end": "1380960"
  },
  {
    "text": "and model to use are contained in publicly available models, right? So as you think about that, it has",
    "start": "1380960",
    "end": "1386640"
  },
  {
    "text": "to be that, um, an enterprise is gonna be customizing something. And then the question is what is that something?",
    "start": "1386640",
    "end": "1391840"
  },
  {
    "text": "And is that something affordable enough then to scale? Yeah.\nAnd uh, the size, uh, and both the size of the model, but also the",
    "start": "1391840",
    "end": "1398240"
  },
  {
    "text": "context of Windows side, right? 10 million per context window. What a world we live in, right? I can just dump a bunch of data",
    "start": "1398240",
    "end": "1403679"
  },
  {
    "text": "to it and, and talk against it. But it takes a lot to host these models.",
    "start": "1403680",
    "end": "1408880"
  },
  {
    "text": "So a lot of, uh, use, uh, different vendors who are offering inference, infrastructure, the same exact model",
    "start": "1408880",
    "end": "1415840"
  },
  {
    "text": "it is complex to host this and get it right. Each vendor is offering different kinds of context windows.",
    "start": "1415840",
    "end": "1421440"
  },
  {
    "text": "'cause not everybody can pull off a 10 million infrastructure the way you fine tune it, so and so forth, right? Even companies that do third party analysis, uh,",
    "start": "1421440",
    "end": "1429120"
  },
  {
    "text": "like artificial analysis and stuff like that. It took them a few turns to get the models",
    "start": "1429120",
    "end": "1434720"
  },
  {
    "text": "to be provided, the inference infrastructure just right to be able to match what Llama",
    "start": "1434720",
    "end": "1440880"
  },
  {
    "text": "had claimed to, to be the, the results in their papers and stuff like that. So it takes a few rounds to get this done,",
    "start": "1440880",
    "end": "1446480"
  },
  {
    "text": "and I believe that this is, speaks to the complexity of some of these larger models on how much difference you see from the same",
    "start": "1446480",
    "end": "1452720"
  },
  {
    "text": "prompt being sent to three different or seven different vendors who are hosting this model have slightly different responses and you see",
    "start": "1452720",
    "end": "1459519"
  },
  {
    "text": "quite a bit of a difference between the two. So I think we'll get to a point where derivatives of Llama 4, uh, the data that's",
    "start": "1459520",
    "end": "1467600"
  },
  {
    "text": "created synthetic data out of Llama 4 and some of the new techniques that they released will make their ways into smaller models.",
    "start": "1467600",
    "end": "1473440"
  },
  {
    "text": "And those are the ones that'll scale, uh, across, uh, different companies. But I'm generally very, very excited of these, these big releases",
    "start": "1473440",
    "end": "1480880"
  },
  {
    "text": "that model companies are doing. They're still sticking to their open weight models, there's still the",
    "start": "1480880",
    "end": "1486960"
  },
  {
    "text": "restrictions that come with a Meta license that's not quite Apache and MIT, but overall our clients have, have, have loved",
    "start": "1486960",
    "end": "1493600"
  },
  {
    "text": "the fact that we can now outcompete each other in the AI space and all clients win.",
    "start": "1493600",
    "end": "1499040"
  },
  {
    "text": "When you have great AI labs working on this together.",
    "start": "1499040",
    "end": "1506160"
  },
  {
    "start": "1502000",
    "end": "2069000"
  },
  {
    "text": "I'm gonna move us on to our next topic, which is Google Cloud Next, uh, show ba you're actually dialing in, uh, straight",
    "start": "1506160",
    "end": "1512640"
  },
  {
    "text": "from Vegas, so I'll kick it over to you. Um, you've been there all week. Uh, what are the big things that we should",
    "start": "1512640",
    "end": "1517840"
  },
  {
    "text": "know about coming out of this, uh, this show? It's, it's lovely to be with developers and just people who are hacking through,",
    "start": "1517840",
    "end": "1524320"
  },
  {
    "text": "and clients who are actually using it. Uh, 500. Customer logos on screen.",
    "start": "1524320",
    "end": "1530559"
  },
  {
    "text": "That's where Google Cloud is today. Like that's such a great testament to where they were two, three years back",
    "start": "1530560",
    "end": "1536080"
  },
  {
    "text": "and they've done quite a bit to make sure that they're serving the enterprises and they have more and more data. Cloud is growing, profitable,",
    "start": "1536080",
    "end": "1542000"
  },
  {
    "text": "things of that nature. When you start to look at, uh, how they're bringing AI across the entire platform, how they are.",
    "start": "1542000",
    "end": "1548720"
  },
  {
    "text": "Exposing some of their internal strengths. So as a, as a great example, they have amazing TPUs to train their own models for",
    "start": "1548720",
    "end": "1555840"
  },
  {
    "text": "their own use cases like YouTube, so Gemini across mobile apps and whatnot, right? So they're, they're bringing that",
    "start": "1555840",
    "end": "1561919"
  },
  {
    "text": "TPU out to enterprises and they constantly innovating on that. So the latest release, Ironwood, amazing",
    "start": "1561920",
    "end": "1568160"
  },
  {
    "text": "progress they've made on their own chips. Then there's a lot of stuff that Google does in turn be to support their billions of users.",
    "start": "1568160",
    "end": "1575360"
  },
  {
    "text": "So things like their own wide area network of, of fiber. It's millions of miles of fiber that",
    "start": "1575360",
    "end": "1580640"
  },
  {
    "text": "they've now exposed to or to, uh, enterprise, uh, users and stuff. So this seem, they're seeming to make a",
    "start": "1580640",
    "end": "1585919"
  },
  {
    "text": "very concerted, uh, effort in making sure that their secret sauce is now available",
    "start": "1585920",
    "end": "1590960"
  },
  {
    "text": "to the end enterprises to use as well. Uh, overall, they, uh, they spent a lot",
    "start": "1590960",
    "end": "1597919"
  },
  {
    "text": "of time on media creation, uh, versus, uh, use cases like coding or data and",
    "start": "1597920",
    "end": "1603920"
  },
  {
    "text": "things of that nature, the media creation. Clearly they're the only cloud that can do this end to end across all these",
    "start": "1603920",
    "end": "1609279"
  },
  {
    "text": "different modalities, creating content. Uh, I was privileged to be part of the sphere experience in the on Day Zero where",
    "start": "1609280",
    "end": "1615600"
  },
  {
    "text": "they showed us the Wizard of Awes and what they're doing to do this on such a mega scale. Right?\nIt is just. It's, it's a great experience to see",
    "start": "1615600",
    "end": "1623120"
  },
  {
    "text": "AI leveraging the, the best techniques to go create a such a immersive experience on this big sphere, uh, scope.",
    "start": "1623120",
    "end": "1629840"
  },
  {
    "text": "So a lot in the media space, but not a lot of our enterprise clients jump up and down on the media topic.",
    "start": "1629840",
    "end": "1636000"
  },
  {
    "text": "There's marketing great, there's some media creation, but the bigger focus on enterprises are what do I do with the call center?",
    "start": "1636000",
    "end": "1641920"
  },
  {
    "text": "What do I do in my code development processes? My data is, is messy and things of that nature. So they made.",
    "start": "1641920",
    "end": "1647440"
  },
  {
    "text": "Quite a bit of, uh, announcements in this space. They have been for the last few weeks announcing newer and newer models.",
    "start": "1647440",
    "end": "1653840"
  },
  {
    "text": "It's just amazing to see how 10 days before your annual event, you're releasing your Gemini 2.5, right?",
    "start": "1653840",
    "end": "1659680"
  },
  {
    "text": "This is, it's this great people hold onto these big announcements, but in this AI race, you can't wait for 10 days.",
    "start": "1659680",
    "end": "1666000"
  },
  {
    "text": "You need to get Gemini 2.5 out before Llama 4 comes in. So it's, it's good to see that",
    "start": "1666000",
    "end": "1671039"
  },
  {
    "text": "progress is, is, uh, going really fast. The performance per intelligence per dollar. Gemini Flash has been doing really, really well.",
    "start": "1671040",
    "end": "1678480"
  },
  {
    "text": "Do talk. Their Gemini 2.5 Pro model across the board",
    "start": "1679120",
    "end": "1684720"
  },
  {
    "text": "on the benchmarks and on all the different things that matter, including the loss exam for humanity is absolutely number one.",
    "start": "1684720",
    "end": "1690960"
  },
  {
    "text": "So a huge focus on that. Uh, just shifting a little bit more towards the agents space.",
    "start": "1690960",
    "end": "1696159"
  },
  {
    "text": "Uh, we had MCP from Anthropic, which allows an LLM to in a structured way",
    "start": "1696160",
    "end": "1701760"
  },
  {
    "text": "with a, with a standard protocol, access backend systems and stuff like that. To compliment that Google has created",
    "start": "1701760",
    "end": "1707840"
  },
  {
    "text": "its own agent to agent protocol, which allows one agent to talk to the other agent, not as a tool, but as a, as a",
    "start": "1707840",
    "end": "1714640"
  },
  {
    "text": "equal citizen, like equal little citizen. It's a peer. So both of them can peer and they can talk to each other and say, Hey, I found this error.",
    "start": "1714640",
    "end": "1720960"
  },
  {
    "text": "How do I what? Do what? Do you want me to do this? Or maybe go talk to a human if needed. And this is asynchronous. It takes a while.",
    "start": "1720960",
    "end": "1726640"
  },
  {
    "text": "It can take long working task and they can talk to them back and forth. I'm generally very pumped when we",
    "start": "1726640",
    "end": "1731840"
  },
  {
    "text": "get to a point where people start. Collecting around specific standards. Uh, Google had a lot of different partners,",
    "start": "1731840",
    "end": "1738240"
  },
  {
    "text": "50 plus already working on, on, uh, agent to agent within IBM consulting. We obviously have a really",
    "start": "1738240",
    "end": "1743440"
  },
  {
    "text": "good agent tech workflow. We have our own IBM Consulting Advantage we already have MCP integrated into it.",
    "start": "1743440",
    "end": "1749440"
  },
  {
    "text": "Now we are working on agent to agent within that space as well. So we are getting really, really excited about, uh, making sure that this is very",
    "start": "1749440",
    "end": "1755840"
  },
  {
    "text": "open ecosystem and you're working sideways. Uh, those were my highlights from the Google event. Just very pumped about the.",
    "start": "1755840",
    "end": "1762160"
  },
  {
    "text": "The clients talking about the specifics of how they did it. It's not just a 30 second video, but a whole half an hour session.",
    "start": "1762160",
    "end": "1768720"
  },
  {
    "text": "Let's deep dive, here are the challenges, here's our journey of which models we use and so and forth. So it's very good to work with the product",
    "start": "1768720",
    "end": "1774400"
  },
  {
    "text": "teams and the customers in these events. That's great. Yeah. So, uh, I guess Hillery an avalanche of announcements here from a",
    "start": "1774400",
    "end": "1780480"
  },
  {
    "text": "number of different directions. Um, I'm curious, I, I think as you kind of like look at Google Cloud and what they're announcing, trends, thoughts, hot takes, uh,",
    "start": "1780480",
    "end": "1788080"
  },
  {
    "text": "from, from the Sears, uh, Google Cloud Next. Yeah.\nOne of the things that caught my eye that Shobhit didn't have on his list, so I can can",
    "start": "1788080",
    "end": "1794480"
  },
  {
    "text": "grab onto it and mention it, um, you missed one. Yeah. So, so they also talked about, uh, AI on",
    "start": "1794480",
    "end": "1800960"
  },
  {
    "text": "premises and, and offering those capabilities. And I think that's also exciting to see in the sense of, again, it affirms kind",
    "start": "1800960",
    "end": "1807440"
  },
  {
    "text": "of what we've been thinking here, that clients do need to be able to run AI. In an air gap environment, we keep saying that",
    "start": "1807440",
    "end": "1813600"
  },
  {
    "text": "AI is a platform conversation and that AI and hybrid cloud are two sides of the same coin.",
    "start": "1813600",
    "end": "1818960"
  },
  {
    "text": "And really that's a statement going back to everything. We were talking at the beginning, that there is data in really important places",
    "start": "1818960",
    "end": "1824960"
  },
  {
    "text": "and that data needs to be secured. Sometimes it needs to adhere to sovereignty concerns and other things like that.",
    "start": "1824960",
    "end": "1831200"
  },
  {
    "text": "And so. Bringing AI to the data. Um, and the fact that, you know, one of their announcements this week affirm that is, is",
    "start": "1831200",
    "end": "1837760"
  },
  {
    "text": "something that they also see as important. I think it is just a really good affirmation of what we're also seeing in the enterprise space that gotta bring the AI to the data.",
    "start": "1837760",
    "end": "1845040"
  },
  {
    "text": "AI is a, is a decision about how flexibly you can deploy AI and all those locations that you have, data and customers.",
    "start": "1845040",
    "end": "1852160"
  },
  {
    "text": "Um, it's not just a decision about. Only which model and only which location it runs in",
    "start": "1852160",
    "end": "1857679"
  },
  {
    "text": "any final takes. Kate, I dunno if you have any thoughts from, uh, this year's Google Cloud Next uh, on any and all of this.",
    "start": "1857680",
    "end": "1863200"
  },
  {
    "text": "I mean, it's just like remarkable every time like Shobhit comes to a show and is like, here's what's happening. And it just feels like, it's like this, like",
    "start": "1863200",
    "end": "1868720"
  },
  {
    "text": "voluminous list that I have trouble parsing, but I know I need aho it to die to decompose.",
    "start": "1868720",
    "end": "1873760"
  },
  {
    "text": "Uh, yeah. All of these main tech conferences going on, it's great. No, I mean, o obviously from, you know, my",
    "start": "1873760",
    "end": "1879440"
  },
  {
    "text": "perspective, I'm most interested in things like the Gemini 2.5 Pro release, which has been really",
    "start": "1879440",
    "end": "1884800"
  },
  {
    "text": "impressive, honestly, getting great, great vibe checks from that model. Um, really exciting to see them",
    "start": "1884800",
    "end": "1889920"
  },
  {
    "text": "really kind of take center stage, uh, and have a, a strong release there. So, you know, more, more great",
    "start": "1889920",
    "end": "1895760"
  },
  {
    "text": "models out there only, uh, improves what the field can can accomplish. So, uh, from that perspective,",
    "start": "1895760",
    "end": "1901520"
  },
  {
    "text": "really excited to see them push the. Push the boundaries. Yeah, I think, uh, just one last parting thought. I think Google is really flexing.",
    "start": "1901520",
    "end": "1908240"
  },
  {
    "text": "Its, uh, B2C learnings, right? The fact that they can train their models from so much content, and again, I'm not getting",
    "start": "1908240",
    "end": "1914480"
  },
  {
    "text": "into where the content is coming from and like, and indemnification and stuff of that. I'm just purely commenting on the fact that",
    "start": "1914480",
    "end": "1920559"
  },
  {
    "text": "they can train on so much more real world. Information from B2C, uh, space, right?",
    "start": "1920560",
    "end": "1925840"
  },
  {
    "text": "There's nobody else who has access to so much data B2C, right? So the video generation, for example, the videos",
    "start": "1925840",
    "end": "1931600"
  },
  {
    "text": "that they are creating are very, very cinematic and they, it seems like they have really gone out and looked at all of the YouTube videos",
    "start": "1931600",
    "end": "1938480"
  },
  {
    "text": "from really good creators and stuff like that. So the quality is, is, is really good, and it's translating into voice experience.",
    "start": "1938480",
    "end": "1945280"
  },
  {
    "text": "And this is becoming more and more critical for clients to get to vendors, to get voice right.",
    "start": "1945280",
    "end": "1950480"
  },
  {
    "text": "And I think they have an unfair advantage in the space where there they can go and provide some very nice audio experiences",
    "start": "1950480",
    "end": "1957840"
  },
  {
    "text": "as you're, as you're thinking through. So one small example was if I have some Google docs and stuff like that, I can,",
    "start": "1957840",
    "end": "1963200"
  },
  {
    "text": "I can ask an agent to say, create, uh, a particular workflow, do some research, and",
    "start": "1963200",
    "end": "1968400"
  },
  {
    "text": "then create a very long research paper. So now it's created a three page. Paper on a particular topic on why",
    "start": "1968400",
    "end": "1974480"
  },
  {
    "text": "your margins are dropping, though your revenues are going up and it'll do competitive analysis and all this stuff.",
    "start": "1974480",
    "end": "1980240"
  },
  {
    "text": "Create a three page paper. I can click a button and create an audio, uh, broad, uh, podcast out of it.",
    "start": "1980240",
    "end": "1985679"
  },
  {
    "text": "Right?\nAnd this like corporate enterprise stuff that's so difficult to consume and now",
    "start": "1985680",
    "end": "1991600"
  },
  {
    "text": "you're plugging in a really nice audio, uh, layer on top of it and I can listen to it on my drive to to work, right?",
    "start": "1991600",
    "end": "1998080"
  },
  {
    "text": "I think the fact they have an unfair advantage on the audio and the experience side. That starts to give them some advantages",
    "start": "1998080",
    "end": "2004080"
  },
  {
    "text": "on the enterprise side as well that some of the other, uh, peers of theirs don't have with these podcasts going up on YouTube,",
    "start": "2004080",
    "end": "2009600"
  },
  {
    "text": "maybe Kate, you'll get the digital twin of Shobhit that you've been wishing for. Exactly.",
    "start": "2009600",
    "end": "2014720"
  },
  {
    "text": "As long as he gets some royalties from it. Yeah, that's right. Exactly. There's ad dollars. There.\nSo, um, yeah, I mean, I think the future of like",
    "start": "2014720",
    "end": "2022640"
  },
  {
    "text": "educational entertainment here is really funny and interesting to think about is like, convert all my emails of the day into a Netflix series.",
    "start": "2022640",
    "end": "2029120"
  },
  {
    "text": "I can just watch when I get home. You know?\nI think we will start to enter this like very strange worlds. But here's the kicker",
    "start": "2029120",
    "end": "2034320"
  },
  {
    "text": "man, and I'll, I'll absolutely close on this. I wanna live in a world where I can insert myself show bit inside of",
    "start": "2034320",
    "end": "2042080"
  },
  {
    "text": "a movie scene that I'm seeing, right? If Iron Man comes to a bar and orders a drink, I wanna be the bartender, right?",
    "start": "2042080",
    "end": "2048879"
  },
  {
    "text": "If, if you have, like, if you have all the celebrities on screen, I wanna be part of that. I could be the driver of like, I want",
    "start": "2049600",
    "end": "2055119"
  },
  {
    "text": "to immerse myself as part of the video, and this was not possible till today. So if you look at how far we have come with the",
    "start": "2055120",
    "end": "2061280"
  },
  {
    "text": "video creation, I think we're at a point we'll have super personalized movies where they'll be cracking jokes that I do on my daily basis too.",
    "start": "2061280",
    "end": "2072560"
  },
  {
    "start": "2069000",
    "end": "2244000"
  },
  {
    "text": "I'm gonna move us on to our final topic of the day. Uh, I'd be remiss to mention this even though we just have a few minutes on the episode today.",
    "start": "2072560",
    "end": "2078720"
  },
  {
    "text": "Um, I really encourage you, if you're listening to the show, to check out this super interesting report that came outta Pew Research.",
    "start": "2078720",
    "end": "2084159"
  },
  {
    "text": "Essentially it's a, uh, survey of American perceptions around AI and how",
    "start": "2084160",
    "end": "2089360"
  },
  {
    "text": "people use AI in their everyday lives. Um, and I think we only have enough time to kind of do a few kind of hot takes here, but I",
    "start": "2089360",
    "end": "2095600"
  },
  {
    "text": "think one sort of really interesting takeaway. From this report was the degree to which sort of experts in AI have views about AI",
    "start": "2095600",
    "end": "2103200"
  },
  {
    "text": "that are really, really divergent from, you know, people who are just kind of like using or experiencing AI in their like everyday",
    "start": "2103200",
    "end": "2108800"
  },
  {
    "text": "lives or even just having heard about it and never used the technology at all. Um, and I think maybe, Kate I'll kick it to you.",
    "start": "2108800",
    "end": "2115119"
  },
  {
    "text": "I think like one of the really interesting results was, you know, all these data, all, all these kind of data points about.",
    "start": "2115120",
    "end": "2120640"
  },
  {
    "text": "Experts saying, uh, that, you know, uh, jobs won't be impacted by AI, but people really",
    "start": "2120640",
    "end": "2126000"
  },
  {
    "text": "feeling like jobs will be impacted by AI. Um, experts generally being a lot more positive on the technology than the journal public is.",
    "start": "2126000",
    "end": "2132560"
  },
  {
    "text": "Do you feel like this kind of impacts the kind of prospects for AI going forwards? Um, just kind of curious about your",
    "start": "2132560",
    "end": "2137680"
  },
  {
    "text": "quick take in the minutes that we have. Yeah. You know, I think there's a lot of interesting things from the, the Pew report.",
    "start": "2137680",
    "end": "2142960"
  },
  {
    "text": "Definitely not enough to get fully into right now, but. I think it speaks to the optimism of the",
    "start": "2142960",
    "end": "2148559"
  },
  {
    "text": "researchers involved, which is great because we need people optimistic about the impact of technology and science on the world to be the",
    "start": "2148560",
    "end": "2155200"
  },
  {
    "text": "ones inventing and trying to push it forward. But I also think it speaks a bit what I saw",
    "start": "2155200",
    "end": "2160560"
  },
  {
    "text": "to some of the representation in technology in that we still have work to do to get",
    "start": "2160560",
    "end": "2165600"
  },
  {
    "text": "better representation to more reflect the world building this technology. So if you also look at, they broke down,",
    "start": "2165600",
    "end": "2172080"
  },
  {
    "text": "you know, men versus women's perception of technology and how it will impact, it's similarly men matched AI experts.",
    "start": "2172080",
    "end": "2178480"
  },
  {
    "text": "And it will be no surprise to anyone that most of the AI experts and the research field is still predominantly, you know,",
    "start": "2178480",
    "end": "2185360"
  },
  {
    "text": "uh, the work is being done by men. So. I think there's also, you know, it reflects just some of the needed diversity and",
    "start": "2185360",
    "end": "2191680"
  },
  {
    "text": "different opinions and broader perspectives that we still have room to grow and bring into AI research as a discipline as a whole.",
    "start": "2191680",
    "end": "2198000"
  },
  {
    "text": "I think it's a great note to end on and I think, um, hopefully it was a good sell for you all to go check out the report.",
    "start": "2198000",
    "end": "2203040"
  },
  {
    "text": "I think there's a lot of data there and I think it's worth really parsing through and I, I agree with you. I think it really points out, so the need for,",
    "start": "2203040",
    "end": "2208800"
  },
  {
    "text": "for greater efforts on diversity in the space. As per usual. I say this every episode now I feel",
    "start": "2208800",
    "end": "2214000"
  },
  {
    "text": "it's like almost a tradition like saying agent, uh, in every single episode, but we have had more things to cover",
    "start": "2214000",
    "end": "2219840"
  },
  {
    "text": "than we have had time to cover today. Uh, but uh, Shobhit, Kate, Hillery, thanks for ablely guiding us",
    "start": "2219840",
    "end": "2225680"
  },
  {
    "text": "through, uh, for our 50th episode. And, uh, thanks for joining us. Uh, if you enjoyed what you heard,",
    "start": "2225680",
    "end": "2230720"
  },
  {
    "text": "uh, you can get us on Apple Podcasts, Spotify, and podcast platforms everywhere. And we will see you next week on Mixture of Experts.",
    "start": "2230720",
    "end": "2240320"
  }
]
[
  {
    "text": "In the world of AI, it seems that 2025 is the year of the AI Agent.",
    "start": "470",
    "end": "8830"
  },
  {
    "text": "New agentic workflows and models are released all the time,",
    "start": "8830",
    "end": "12557"
  },
  {
    "text": "often accompanied by breathless declarations on social media that a task that previously required human expertise",
    "start": "12557",
    "end": "20580"
  },
  {
    "text": "has now been entirely automated by the latest agentic breakthrough.",
    "start": "20580",
    "end": "26230"
  },
  {
    "text": "But can you distinguish a simple reflex agent from an advanced learning agent?",
    "start": "26470",
    "end": "32328"
  },
  {
    "text": "You see agents are classified based on their level of intelligence,",
    "start": "33060",
    "end": "37161"
  },
  {
    "text": "based on their decision-making processes and how they interact with their surroundings to reach wanted outcomes.",
    "start": "37161",
    "end": "43619"
  },
  {
    "text": "So let's explore the five main types of AI agents to understand what they can and cannot do.",
    "start": "43740",
    "end": "50819"
  },
  {
    "text": "Now a simple reflex agent that is the most simple type of AI agent,",
    "start": "51120",
    "end": "60343"
  },
  {
    "text": "the most basic type, and it follows predefined rules to make decisions like a thermostat.",
    "start": "60344",
    "end": "67129"
  },
  {
    "text": "It turns on the heat when the temperature drops below a",
    "start": "67130",
    "end": "69994"
  },
  {
    "text": "predefined threshold and then it turns it off again when a set temperature is reached.",
    "start": "69995",
    "end": "73969"
  },
  {
    "text": "So let's break it down.",
    "start": "74690",
    "end": "75690"
  },
  {
    "text": "We've got our agent here.",
    "start": "75690",
    "end": "78230"
  },
  {
    "text": "Now the the environment over here that's the external world that the agent is embedded into and it next to.",
    "start": "78690",
    "end": "87510"
  },
  {
    "text": "Then we've got precepts.",
    "start": "88308",
    "end": "90246"
  },
  {
    "text": "These are the perceived input from the environment as measured through sensors.",
    "start": "90246",
    "end": "94420"
  },
  {
    "text": "Then these sensors feed the precept into the internal logic of the agent",
    "start": "94420",
    "end": "101158"
  },
  {
    "text": "which gives us a representation of what the world is like now,",
    "start": "101158",
    "end": "106860"
  },
  {
    "text": "and knowing what the word is like now we can use condition action rules as the core logic of these simple reflex agent.",
    "start": "106860",
    "end": "115379"
  },
  {
    "text": "Now, these are rules that follow an if condition.",
    "start": "115380",
    "end": "118519"
  },
  {
    "text": "Then action structure.",
    "start": "118860",
    "end": "120440"
  },
  {
    "text": "So if the temperature drops to 18 Celsius then turn on the heat.",
    "start": "120540",
    "end": "126080"
  },
  {
    "text": "That's executed by actuators and that results in an action.",
    "start": "126440",
    "end": "132539"
  },
  {
    "text": "The output behavior by the agent and that action affects the",
    "start": "132860",
    "end": "138269"
  },
  {
    "text": "environment which in turn affects the next set of precepts and around and around we go.",
    "start": "138269",
    "end": "145759"
  },
  {
    "text": "Simple reflex agents like this are effective in structured",
    "start": "146670",
    "end": "150125"
  },
  {
    "text": "and predictable environments where the rules are well defined, but dynamic scenarios?",
    "start": "150125",
    "end": "155310"
  },
  {
    "text": "They can trip these agents up,",
    "start": "155790",
    "end": "157861"
  },
  {
    "text": "and because they don't store past information, they can repeatedly make the same mistakes",
    "start": "157861",
    "end": "163487"
  },
  {
    "text": "if the predefined rules are insufficient for handling new situations.",
    "start": "163488",
    "end": "168670"
  },
  {
    "text": "All right, well how about this one?",
    "start": "170310",
    "end": "172249"
  },
  {
    "text": "This is called a model based reflex agent.",
    "start": "172250",
    "end": "178459"
  },
  {
    "text": "So this is a more advanced version of the the simple reflex agent,",
    "start": "179360",
    "end": "184787"
  },
  {
    "text": "and it uses condition action rules to make decisions as well but,",
    "start": "184787",
    "end": "189123"
  },
  {
    "text": "it also incorporates an internal model of the world and that's stored in the state",
    "start": "189123",
    "end": "195522"
  },
  {
    "text": "component and that state component is updated by observing how the world actually evolves.",
    "start": "195522",
    "end": "202699"
  },
  {
    "text": "Essentially how the environment changes from one state to another.",
    "start": "203060",
    "end": "208480"
  },
  {
    "text": "The agent also tracks how its own actions affect the environment.",
    "start": "209160",
    "end": "214080"
  },
  {
    "text": "That's what my actions do.",
    "start": "214200",
    "end": "216039"
  },
  {
    "text": "And all of this is used instead of just taking the raw precepts data for decision making.",
    "start": "216480",
    "end": "221939"
  },
  {
    "text": "So take a robotic vacuum cleaner for example.",
    "start": "222158",
    "end": "225560"
  },
  {
    "text": "The internal state that remembers where it's been and what areas are clean and where the obstacles are.",
    "start": "225780",
    "end": "232400"
  },
  {
    "text": "It knows that if it moves forwards, it changes its location and that action has consequences.",
    "start": "232820",
    "end": "238460"
  },
  {
    "text": "And it has condition-action rules, like if I think I'm in a dirty area and I haven't cleaned it yet, then vacuum it.",
    "start": "238820",
    "end": "248099"
  },
  {
    "text": "It doesn't just react to what it immediately sees, it infers and it remembers parts of the environment it can't currently observe.",
    "start": "248260",
    "end": "256398"
  },
  {
    "text": "That's model-based reasoning in action.",
    "start": "256970",
    "end": "259859"
  },
  {
    "text": "now a goal-based AI model that is building on top of the model-based agent by adding decision-making that's based on goals.",
    "start": "261143",
    "end": "275069"
  },
  {
    "text": "So we don't have any more condition action rules, we have goals,",
    "start": "275230",
    "end": "279196"
  },
  {
    "text": "and they represent the desired output the agent is trying to achieve.",
    "start": "279196",
    "end": "283269"
  },
  {
    "text": "So the agent uses its model, that's how the world evolves and what my actions do,",
    "start": "283430",
    "end": "290014"
  },
  {
    "text": "to simulate future outcomes of possible actions, essentially predicting what will it be like if I do action A.",
    "start": "290014",
    "end": "299490"
  },
  {
    "text": "Now that's a shift in decision making.",
    "start": "299550",
    "end": "301690"
  },
  {
    "text": "The agent isn't just asking what action matches this condition,",
    "start": "301770",
    "end": "305879"
  },
  {
    "text": "it's now asking what actually will help me achieve my goal based on the current state and predicted future.",
    "start": "305880",
    "end": "312050"
  },
  {
    "text": "So consider a self-driving car.",
    "start": "312310",
    "end": "314629"
  },
  {
    "text": "If the goal is to get to destination X, It'll consider its state, which is, I'm on Main Street.",
    "start": "314790",
    "end": "321789"
  },
  {
    "text": "It will then generate a prediction.",
    "start": "322110",
    "end": "323709"
  },
  {
    "text": "If I turn left, I'll head towards the highway, and it'll ask, will that help me reach destination X?",
    "start": "323990",
    "end": "329608"
  },
  {
    "text": "And if the answer is yes, then the action will be to turn left.",
    "start": "329610",
    "end": "334629"
  },
  {
    "text": "Goal-based agents are widely used in robotics and simulations where",
    "start": "335150",
    "end": "339070"
  },
  {
    "text": "a clear objective is set and adaptation to the environment is required.",
    "start": "339071",
    "end": "343329"
  },
  {
    "text": "Now a utility-based agent looks like this.",
    "start": "344170",
    "end": "350770"
  },
  {
    "text": "And it considers not just if a goal is met, but how desirable different outcomes are.",
    "start": "351170",
    "end": "357290"
  },
  {
    "text": "So utility here represents a happiness score or a preference value for a particular outcome.",
    "start": "357385",
    "end": "363470"
  },
  {
    "text": "So for each possible future state, the agent asks how happy will I be",
    "start": "363670",
    "end": "368390"
  },
  {
    "text": "in such a state or really the expected utility of the future state.",
    "start": "368390",
    "end": "373850"
  },
  {
    "text": "And this lets it rank options, not just pick anything that meets the goal.",
    "start": "374110",
    "end": "379050"
  },
  {
    "text": "So consider an autonomous drone delivery.",
    "start": "379050",
    "end": "381840"
  },
  {
    "text": "The goal-based version might be to use a goal of",
    "start": "382280",
    "end": "385471"
  },
  {
    "text": "deliver the package to address X, and it chooses an action that completes that goal.",
    "start": "385471",
    "end": "389779"
  },
  {
    "text": "Doesn't matter if it gives you a bumpy energy-wasting route,",
    "start": "390300",
    "end": "393676"
  },
  {
    "text": "but a utility-based person,",
    "start": "393676",
    "end": "396761"
  },
  {
    "text": "that might instead be something like deliver the packages quickly and safely and with minimum energy usage,",
    "start": "396761",
    "end": "402125"
  },
  {
    "text": "whereby now the drone simulates multiple paths, it estimates things like duration and battery level and weather,",
    "start": "402125",
    "end": "408259"
  },
  {
    "text": "and it picks the route that maximizes its utility score.",
    "start": "408630",
    "end": "411989"
  },
  {
    "text": "That's AI agent number four.",
    "start": "412590",
    "end": "415029"
  },
  {
    "text": "Now, the fifth agent is the most adaptable and also the most powerful and it is the learning agent.",
    "start": "415530",
    "end": "424509"
  },
  {
    "text": "So rather than being hard coded or being goal driven, it learns from experience.",
    "start": "424690",
    "end": "429629"
  },
  {
    "text": "It improves its performance over time by updating its behavior based on feedback from the environment.",
    "start": "429790",
    "end": "435369"
  },
  {
    "text": "So how does it work?",
    "start": "436070",
    "end": "437070"
  },
  {
    "text": "There's a critic component and that observes the outcome of an agent's actions",
    "start": "437680",
    "end": "442800"
  },
  {
    "text": "via the sensors and it compares them to a performance standard.",
    "start": "442800",
    "end": "447159"
  },
  {
    "text": "Now that gives us a numerical feedback signal that's often called a reward in reinforcement learning",
    "start": "447580",
    "end": "453672"
  },
  {
    "text": "and this reward is then passed to a learning element",
    "start": "453673",
    "end": "457429"
  },
  {
    "text": "that updates the agent's knowledge using the feedback from the critic.",
    "start": "457429",
    "end": "461923"
  },
  {
    "text": "Its job here is to improve the agents mapping from states all the way through to actions.",
    "start": "461924",
    "end": "467259"
  },
  {
    "text": "Now the problem generator, that suggests new actions the",
    "start": "468190",
    "end": "471922"
  },
  {
    "text": "agent hasn't tried yet, like try a different path, see if it's any faster.",
    "start": "471922",
    "end": "475850"
  },
  {
    "text": "And then the performance element selects actions based on what the learning element has determined to be optimal.",
    "start": "476310",
    "end": "483430"
  },
  {
    "text": "So think of an AI chess bot, the performance elements that plays the game using current learn strategies.",
    "start": "483750",
    "end": "490309"
  },
  {
    "text": "The critic, you'll see that it lost the match.",
    "start": "490810",
    "end": "493310"
  },
  {
    "text": "The learning element adjusts its strategy based on the outcomes of",
    "start": "493950",
    "end": "497494"
  },
  {
    "text": "thousands of games and the problem generator suggests new moves that it hasn't explored yet.",
    "start": "497494",
    "end": "503039"
  },
  {
    "text": "So a simple reflex agent reacts.",
    "start": "503700",
    "end": "509409"
  },
  {
    "text": "It's fast to execute but it has no memory and it has no understanding of history.",
    "start": "509950",
    "end": "515249"
  },
  {
    "text": "A model-based reflex agent, we can really think that the difference there is that that remembers.",
    "start": "515970",
    "end": "522849"
  },
  {
    "text": "It does that by tracking state over time.",
    "start": "523350",
    "end": "525529"
  },
  {
    "text": "It doesn't plan, it's still reactive.",
    "start": "525830",
    "end": "527590"
  },
  {
    "text": "Now a goal-based model, that aims.",
    "start": "528370",
    "end": "531570"
  },
  {
    "text": "It aims by using goal-directed behavior but any way of meeting that goal...",
    "start": "532230",
    "end": "537769"
  },
  {
    "text": "Will do.",
    "start": "538060",
    "end": "539060"
  },
  {
    "text": "Whereas, an utility-based agent that takes a different path, it evaluates.",
    "start": "539480",
    "end": "546600"
  },
  {
    "text": "It does that by choosing the best outcome, but requires an accurate utility function to do so.",
    "start": "546980",
    "end": "553279"
  },
  {
    "text": "And then a learning agent that improves by learning from experience,",
    "start": "553500",
    "end": "560203"
  },
  {
    "text": "but this can be the slowest and most data intensive process.",
    "start": "560203",
    "end": "564720"
  },
  {
    "text": "Now in many cases, we will want to use multiple agents together.",
    "start": "564855",
    "end": "570190"
  },
  {
    "text": "That is called a multi-agent system.",
    "start": "570730",
    "end": "574690"
  },
  {
    "text": "And that's where multiple agents operate in a shared environment,",
    "start": "575610",
    "end": "579600"
  },
  {
    "text": "working in a cooperative way, working towards a common goal.",
    "start": "579600",
    "end": "583029"
  },
  {
    "text": "And as agentic AI continues to evolve, particularly with learning agents that are making uses of advances in generative AI,",
    "start": "583830",
    "end": "591762"
  },
  {
    "text": "AI agents are becoming increasingly adept at handling complex use cases,",
    "start": "591762",
    "end": "597210"
  },
  {
    "text": "but it's not really all over for us just yet.",
    "start": "598110",
    "end": "601769"
  },
  {
    "text": "AI agents typically work best with a good old human in the loop.",
    "start": "602290",
    "end": "606748"
  },
  {
    "text": "At least for the time being.",
    "start": "607930",
    "end": "609329"
  }
]
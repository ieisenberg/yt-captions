[
  {
    "start": "0",
    "end": "49000"
  },
  {
    "text": "A lot of web developers are using AI applications such as chat assistance or code assistance.",
    "start": "240",
    "end": "5410"
  },
  {
    "text": "But building an application yourself can sound like a scary task, but it's not as complex as you think.",
    "start": "5430",
    "end": "11070"
  },
  {
    "text": "In this video, I'm going to walk you through how you",
    "start": "11100",
    "end": "13182"
  },
  {
    "text": "get from asking a question to retrieving an answer by a large language model.",
    "start": "13182",
    "end": "19289"
  },
  {
    "text": "There are a couple of patterns in between.",
    "start": "19620",
    "end": "21089"
  },
  {
    "text": "So let's break down what a typical application looks like.",
    "start": "21210",
    "end": "24359"
  },
  {
    "text": "Often it starts with a user interface and a user interface.",
    "start": "25110",
    "end": "28760"
  },
  {
    "text": "You can ask your questions.",
    "start": "28770",
    "end": "29940"
  },
  {
    "text": "The user interface will then connect to a library or a framework.",
    "start": "30420",
    "end": "34259"
  },
  {
    "text": "This library or framework could be open source or it could be a cloud product.",
    "start": "35580",
    "end": "39659"
  },
  {
    "text": "This library or framework will interact with an API and is APIs typically provided by an LLM provider.",
    "start": "40470",
    "end": "47640"
  },
  {
    "start": "49000",
    "end": "168000"
  },
  {
    "text": "As mentioned, there are a couple of better things I'd like to highlight.",
    "start": "49600",
    "end": "51939"
  },
  {
    "text": "Usually people start by asking a question to a large language model.",
    "start": "52480",
    "end": "56530"
  },
  {
    "text": "This question will be put inside of a prompt. ",
    "start": "57820",
    "end": "60159"
  },
  {
    "text": "Then this prompt will be sent to the large language model.",
    "start": "62050",
    "end": "65140"
  },
  {
    "text": "And retrieve your final answer.",
    "start": "66950",
    "end": "68539"
  },
  {
    "text": "So in your prompt, you would put both your question, but also a set of instructions for the LLM,",
    "start": "69320",
    "end": "73996"
  },
  {
    "text": "such as be a helpful assistant or don't hallucinate or don't offend anyone.",
    "start": "73996",
    "end": "78470"
  },
  {
    "text": "There's also more complex, better and next to basic prompting and this is what we call RAG or retrieval augmented generation.",
    "start": "79220",
    "end": "85489"
  },
  {
    "text": "Again, it starts with a question.",
    "start": "87990",
    "end": "89700"
  },
  {
    "text": "This time your question won't be directly put inside a prompt, but it will be turned into an embedding.",
    "start": "90510",
    "end": "96989"
  },
  {
    "text": "This embedding will then be used by a vector database to find relevant context.",
    "start": "97950",
    "end": "102718"
  },
  {
    "text": "So it is vector database",
    "start": "102870",
    "end": "104370"
  },
  {
    "text": "is right here.",
    "start": "106970",
    "end": "108020"
  },
  {
    "text": "And with this vector database, you can retrieve relevant context.",
    "start": "108230",
    "end": "111799"
  },
  {
    "text": "We call this top N matches.",
    "start": "111860",
    "end": "113450"
  },
  {
    "text": "These top N matches will be put inside a prompt.",
    "start": "115400",
    "end": "117649"
  },
  {
    "text": "And this prompt will, of course, also contain your question.",
    "start": "118790",
    "end": "121700"
  },
  {
    "text": "What the LLM sees is your prompts, which includes both the question and the top N matches.",
    "start": "122990",
    "end": "128028"
  },
  {
    "text": "And based on this, it's going to return your final answer.",
    "start": "130289",
    "end": "133139"
  },
  {
    "text": "With RAG is also a stage where you upload your data into the vector database.",
    "start": "136963",
    "end": "141370"
  },
  {
    "text": "And this is important because otherwise the vector database won't be able to retrieve early and relevant context.",
    "start": "141380",
    "end": "146599"
  },
  {
    "text": "If you look at basic prompting, this is typically done via an API or an SDK, which could be provided by LLM provider.",
    "start": "147660",
    "end": "155729"
  },
  {
    "text": "If we look at RAG or retrieval augmented generation, you typically do this via a library or a framework.",
    "start": "156030",
    "end": "163679"
  },
  {
    "start": "168000",
    "end": "281000"
  },
  {
    "text": "So the final pattern and you can implement as a web developer on building your application is AI agents with AI agents.",
    "start": "168870",
    "end": "175709"
  },
  {
    "text": "You still have a question and a final answer,",
    "start": "175860",
    "end": "178641"
  },
  {
    "text": "but it's time you have an agent in the middle that will help you to answer the question.",
    "start": "178641",
    "end": "182370"
  },
  {
    "text": "So we start again with a question.",
    "start": "183270",
    "end": "185129"
  },
  {
    "text": "This time your question will be sent to the agent.",
    "start": "185490",
    "end": "188039"
  },
  {
    "text": "There are multiple patterns to implement agents, and typically you use a framework or a library to do this.",
    "start": "189210",
    "end": "195120"
  },
  {
    "text": "The agent will typically plan based on your question and the available tools.",
    "start": "195990",
    "end": "200639"
  },
  {
    "text": "It will act or react based on the tool calls.",
    "start": "201030",
    "end": "205610"
  },
  {
    "text": "And finally, it's going to reflect and see if your answer is matching the question.",
    "start": "205620",
    "end": "211343"
  },
  {
    "text": "For the plan the next stage it needs a set of tools.",
    "start": "211343",
    "end": "214289"
  },
  {
    "text": "And these tools could be either APIs, databases or code, for example, to crawl the web.",
    "start": "215640",
    "end": "221159"
  },
  {
    "text": "The LLM is going to use those tools to plan and execute.",
    "start": "222320",
    "end": "225979"
  },
  {
    "text": "And finally, providing you with your final answer.",
    "start": "226220",
    "end": "229339"
  },
  {
    "text": "Next to a single agent.",
    "start": "230440",
    "end": "231610"
  },
  {
    "text": "You can also have a multi agent framework.",
    "start": "231820",
    "end": "234039"
  },
  {
    "text": "This typically involves a supervisor agents, which is going to determine",
    "start": "234700",
    "end": "238458"
  },
  {
    "text": "which agent should be called to answer your question.",
    "start": "238458",
    "end": "240549"
  },
  {
    "text": "So in this video we looked at three different paterns to implement AI applications.",
    "start": "241270",
    "end": "245620"
  },
  {
    "text": "The first one was basic prompting, where you use a prompt, which includes your question and a set of instructions.",
    "start": "245620",
    "end": "250959"
  },
  {
    "text": "The second one was RAG, Retrieval Augmented Generation,",
    "start": "251320",
    "end": "254457"
  },
  {
    "text": "where we use a vector database to make LLMs context aware of your data.",
    "start": "254457",
    "end": "257980"
  },
  {
    "text": "And a final one was agents, where you use an agent that will",
    "start": "258399",
    "end": "261854"
  },
  {
    "text": "look at a set of tools and based on the tools is going to answer your question.",
    "start": "261855",
    "end": "265479"
  },
  {
    "text": "So with this, I hope you can start building your applications today.",
    "start": "265900",
    "end": "269048"
  }
]
[
  {
    "start": "0",
    "end": "57000"
  },
  {
    "text": "In deep learning, neural networks, including large language models, can be big.",
    "start": "280",
    "end": "3600"
  },
  {
    "text": "Very big.",
    "start": "4470",
    "end": "5370"
  },
  {
    "text": "Like hundreds of billions of parameters big.",
    "start": "5370",
    "end": "8900"
  },
  {
    "text": "And running them at inference time is usually a very compute intensive operation.",
    "start": "8910",
    "end": "13710"
  },
  {
    "text": "So enter Mixture of Experts,",
    "start": "14100",
    "end": "17241"
  },
  {
    "text": "which is a machine learning approach",
    "start": "17241",
    "end": "19324"
  },
  {
    "text": "that divides an AI model into separate subnetworks, or \"experts\".",
    "start": "19324",
    "end": "23969"
  },
  {
    "text": "Each expert focuses on a subset of the input data,",
    "start": "24360",
    "end": "27880"
  },
  {
    "text": "and only the relevant experts are activated for a given task.",
    "start": "27880",
    "end": "31529"
  },
  {
    "text": "Rather than using the entire network for every operation.",
    "start": "31920",
    "end": "35280"
  },
  {
    "text": "Now, mixture of experts isn't new.",
    "start": "35760",
    "end": "37769"
  },
  {
    "text": "Not at all.",
    "start": "37890",
    "end": "38670"
  },
  {
    "text": "It goes back to a paper published in 1991,",
    "start": "38670",
    "end": "44121"
  },
  {
    "text": "when researchers proposed an AI system with separate networks,",
    "start": "44121",
    "end": "47857"
  },
  {
    "text": "each specializing in different training cases.",
    "start": "47857",
    "end": "50146"
  },
  {
    "text": "And their experiment was a hit.",
    "start": "50220",
    "end": "51899"
  },
  {
    "text": "The model reached target accuracy in half the training cycles",
    "start": "52230",
    "end": "55739"
  },
  {
    "text": "of a conventional model.",
    "start": "55739",
    "end": "57030"
  },
  {
    "text": "Now, fast forward to today,",
    "start": "57240",
    "end": "58966"
  },
  {
    "text": "and mixture of experts is making a bit of a comeback.",
    "start": "58966",
    "end": "61699"
  },
  {
    "text": "It's kind of trendy again,",
    "start": "61699",
    "end": "63515"
  },
  {
    "text": "and leading large language models, like ones from Mistral, are using it.",
    "start": "63515",
    "end": "68050"
  },
  {
    "text": "So, let's break down the mixture of experts architecture",
    "start": "68070",
    "end": "72659"
  },
  {
    "text": "and see what it's made of.",
    "start": "72659",
    "end": "74789"
  },
  {
    "text": "Well, we have in our model an input and an output.",
    "start": "75299",
    "end": "82170"
  },
  {
    "text": "Now we also have a bunch of expert networks in between,",
    "start": "84100",
    "end": "89288"
  },
  {
    "text": "and there's probably many of them.",
    "start": "89288",
    "end": "90769"
  },
  {
    "text": "I'll just draw a few, so we'll have Expert Network number 1,",
    "start": "90790",
    "end": "96009"
  },
  {
    "text": "Expert Network number 2,",
    "start": "96009",
    "end": "99298"
  },
  {
    "text": "all the way through to Expert Network N.",
    "start": "99298",
    "end": "103280"
  },
  {
    "text": "And these sit between the input and the output.",
    "start": "103350",
    "end": "108670"
  },
  {
    "text": "Now there is a thing called a gating network.",
    "start": "110470",
    "end": "115090"
  },
  {
    "text": "And this sits between the input and the experts.",
    "start": "115990",
    "end": "122199"
  },
  {
    "text": "Think of the gating network a bit like a traffic cop, I guess,",
    "start": "123950",
    "end": "127481"
  },
  {
    "text": "deciding which experts should handle each subtask.",
    "start": "127482",
    "end": "131090"
  },
  {
    "text": "So we get a request in",
    "start": "131900",
    "end": "134107"
  },
  {
    "text": "and the gating network will pick which experts",
    "start": "134108",
    "end": "137553"
  },
  {
    "text": "it's going to invoke for that given input.",
    "start": "137553",
    "end": "140719"
  },
  {
    "text": "Now the gating network assigns weights as it goes,",
    "start": "141410",
    "end": "146030"
  },
  {
    "text": "and with those weights we are using the results,",
    "start": "146030",
    "end": "150882"
  },
  {
    "text": "combining them to produce the final output.",
    "start": "150882",
    "end": "154210"
  },
  {
    "text": "So we'll get the results back from those experts",
    "start": "154220",
    "end": "157092"
  },
  {
    "text": "and combine them into our output here.",
    "start": "157092",
    "end": "160190"
  },
  {
    "start": "160000",
    "end": "247000"
  },
  {
    "text": "Now we can think of the experts as specialized subnetworks",
    "start": "160970",
    "end": "165131"
  },
  {
    "text": "within the bigger neural network.",
    "start": "165131",
    "end": "166939"
  },
  {
    "text": "And the gating network is acting as the coordinator,",
    "start": "167210",
    "end": "170133"
  },
  {
    "text": "activating only the best experts for each input.",
    "start": "170133",
    "end": "174019"
  },
  {
    "text": "So, let's take a look at a real world example",
    "start": "174470",
    "end": "176647"
  },
  {
    "text": "using that Mistral model I mentioned earlier.",
    "start": "176647",
    "end": "179372"
  },
  {
    "text": "That's actually called Mixtral, and the specific name is Mixtral 8x7B.",
    "start": "179458",
    "end": "187004"
  },
  {
    "text": "It's a large language model, open source,",
    "start": "187250",
    "end": "189710"
  },
  {
    "text": "and in this model each layer has a total of eight experts.",
    "start": "189710",
    "end": "195439"
  },
  {
    "text": "And each expert consists of 7 billion parameters.",
    "start": "195830",
    "end": "199969"
  },
  {
    "text": "That's what the 7B is.",
    "start": "199980",
    "end": "201097"
  },
  {
    "text": "Which on its own it's actually quite a small model for a large language model.",
    "start": "201111",
    "end": "205129"
  },
  {
    "text": "Now, as the model processes each token like a word or a part of a word,",
    "start": "205700",
    "end": "209791"
  },
  {
    "text": "a router network in each layer picks the two most suitable experts out of the eight,",
    "start": "209791",
    "end": "214344"
  },
  {
    "text": "and these two experts do their thing,",
    "start": "214344",
    "end": "216935"
  },
  {
    "text": "their outputs are mixed together and the combined result moves on to the next layer.",
    "start": "216936",
    "end": "221479"
  },
  {
    "text": "So let's take a look at some of the concepts that make up this architecture.",
    "start": "222140",
    "end": "226819"
  },
  {
    "text": "And the first one I want to mention is called sparsity.",
    "start": "227210",
    "end": "231619"
  },
  {
    "text": "In a sparse layer, ",
    "start": "232790",
    "end": "235032"
  },
  {
    "text": "only experts and their parameters are activated from the list of all of them.",
    "start": "235033",
    "end": "240000"
  },
  {
    "text": "So we just select a few.",
    "start": "240000",
    "end": "241580"
  },
  {
    "text": "And this approach cuts down on compute needs",
    "start": "241970",
    "end": "244984"
  },
  {
    "text": "as opposed to sending the requests through the whole network.",
    "start": "244984",
    "end": "247661"
  },
  {
    "start": "247000",
    "end": "356000"
  },
  {
    "text": "And sparse line is really shine when dealing with complex high dimensional data.",
    "start": "247662",
    "end": "252289"
  },
  {
    "text": "Like for example, human language.",
    "start": "252530",
    "end": "255689"
  },
  {
    "text": "So think about it.",
    "start": "255710",
    "end": "256609"
  },
  {
    "text": "Different parts of a sentence might need different types of analysis.",
    "start": "256610",
    "end": "260419"
  },
  {
    "text": "You might need one expert that can understand idioms",
    "start": "260420",
    "end": "263889"
  },
  {
    "text": "like, \"it's raining cats and dogs\".",
    "start": "263889",
    "end": "265850"
  },
  {
    "text": "And then you might need another expert to untangle complex grammar structures.",
    "start": "266210",
    "end": "270108"
  },
  {
    "text": "So sparse mixture of expert models are great at this,",
    "start": "270680",
    "end": "273656"
  },
  {
    "text": "because they can call in just the right experts for each part of the input,",
    "start": "273656",
    "end": "277756"
  },
  {
    "text": "allowing for specialized processing.",
    "start": "277756",
    "end": "279709"
  },
  {
    "text": "Now another important concept is the concept of routing.",
    "start": "280460",
    "end": "285380"
  },
  {
    "text": "Now this refers to how this gating network here decides which expert to use.",
    "start": "286610",
    "end": "292009"
  },
  {
    "text": "And there are various ways to do this.",
    "start": "292010",
    "end": "294030"
  },
  {
    "text": "But getting it right is key.",
    "start": "294080",
    "end": "296209"
  },
  {
    "text": "If the routing strategy is off,",
    "start": "296660",
    "end": "298948"
  },
  {
    "text": "some experts might end up under trained,",
    "start": "298948",
    "end": "301559"
  },
  {
    "text": "or they might end up too specialized,",
    "start": "301559",
    "end": "303436"
  },
  {
    "text": "which can make the whole network less effective.",
    "start": "303436",
    "end": "306199"
  },
  {
    "text": "So here's how routing typically works.",
    "start": "306680",
    "end": "308839"
  },
  {
    "text": "The router predicts how likely each expert is to give the best output for a given input.",
    "start": "309170",
    "end": "315919"
  },
  {
    "text": "This prediction is based on the strength of connections between the expert",
    "start": "316310",
    "end": "319835"
  },
  {
    "text": "and the current data.",
    "start": "319835",
    "end": "321018"
  },
  {
    "text": "Now Mixtral, for example,",
    "start": "321560",
    "end": "323842"
  },
  {
    "text": "uses what is called a \"top-k\" routing strategy,",
    "start": "323842",
    "end": "330000"
  },
  {
    "text": "where k is the number of experts selected.",
    "start": "330000",
    "end": "333380"
  },
  {
    "text": "Specifically, it uses top-2 routing,",
    "start": "333530",
    "end": "337908"
  },
  {
    "text": "meaning it picks the best two out of its eight experts for each task.",
    "start": "337908",
    "end": "342018"
  },
  {
    "text": "Now, while this approach has its advantages,",
    "start": "342890",
    "end": "345081"
  },
  {
    "text": "it can also lead to some challenges.",
    "start": "345081",
    "end": "347210"
  },
  {
    "text": "And that leads us to our next concept,",
    "start": "347630",
    "end": "350936"
  },
  {
    "text": "and that is load balancing.",
    "start": "350936",
    "end": "354470"
  },
  {
    "text": "Now, in mixture of expert models",
    "start": "355250",
    "end": "359121"
  },
  {
    "start": "356000",
    "end": "477000"
  },
  {
    "text": "there's a potential issue where the gating network,",
    "start": "359121",
    "end": "362553"
  },
  {
    "text": "it may converge to consistently activate only a few experts,",
    "start": "362553",
    "end": "366245"
  },
  {
    "text": "and this creates a bit of a self-reinforcing cycle,",
    "start": "366245",
    "end": "369753"
  },
  {
    "text": "because if certain experts are disproportionately selected early on,",
    "start": "369753",
    "end": "373813"
  },
  {
    "text": "they receive more training, leading to more reliable outputs,",
    "start": "373813",
    "end": "378171"
  },
  {
    "text": "and consequently, these experts are chosen more frequently",
    "start": "378171",
    "end": "381130"
  },
  {
    "text": "while others remain underutilized.",
    "start": "381130",
    "end": "383019"
  },
  {
    "text": "That's an imbalance that can result in a significant portion of the network",
    "start": "383410",
    "end": "387092"
  },
  {
    "text": "becoming ineffective, essentially turning into computational overhead.",
    "start": "387092",
    "end": "392770"
  },
  {
    "text": "Now, to solve this, researchers developed a technique",
    "start": "393460",
    "end": "397278"
  },
  {
    "text": "specifically for top-k and it's called \"noisy top-k\" gating.",
    "start": "397278",
    "end": "404819"
  },
  {
    "text": "And using noisy top-k gating introduces",
    "start": "405420",
    "end": "409936"
  },
  {
    "text": "Gaussian noise to the probability values predicted for each expert",
    "start": "409936",
    "end": "413840"
  },
  {
    "text": "during the selection process.",
    "start": "413840",
    "end": "415379"
  },
  {
    "text": "The controlled randomness promotes a more evenly distributed activation of experts.",
    "start": "415860",
    "end": "420403"
  },
  {
    "text": "So mixture of experts offers a bunch of advantages in efficiency and performance.",
    "start": "421350",
    "end": "427170"
  },
  {
    "text": "But it's not without its challenges.",
    "start": "427170",
    "end": "429070"
  },
  {
    "text": "It introduces model complexity,",
    "start": "429120",
    "end": "431787"
  },
  {
    "text": "which can make training more difficult and time consuming.",
    "start": "431787",
    "end": "434819"
  },
  {
    "text": "The routing mechanism, while powerful,",
    "start": "435240",
    "end": "437789"
  },
  {
    "text": "adds another layer of intricacy to the model architecture",
    "start": "437790",
    "end": "441064"
  },
  {
    "text": "and issues like load balancing and potential underutilization of experts",
    "start": "441064",
    "end": "445831"
  },
  {
    "text": "require careful tuning and monitoring.",
    "start": "445831",
    "end": "448379"
  },
  {
    "text": "But still, for many applications, particularly large scale language models",
    "start": "448560",
    "end": "453317"
  },
  {
    "text": "where computational resources are at a premium,",
    "start": "453317",
    "end": "456060"
  },
  {
    "text": "the improved efficiency and specialized processing capabilities",
    "start": "456060",
    "end": "460290"
  },
  {
    "text": "of the mixture of expert architecture make it a compelling option.",
    "start": "460290",
    "end": "465269"
  }
]
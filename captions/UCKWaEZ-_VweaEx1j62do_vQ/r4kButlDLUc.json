[
  {
    "text": "With all the excitement around ChatGPT, it's easy to lose sight of the unique risks of generative AI.",
    "start": "300",
    "end": "5792"
  },
  {
    "text": "Large language models, a form of generative AI, are really good at helping people who struggle with writing English prose.",
    "start": "6630",
    "end": "13890"
  },
  {
    "text": "It can help them unlock the written word at low cost and sound like a native speaker.",
    "start": "14460",
    "end": "19163"
  },
  {
    "text": "But because they're so good at generating the next syntactically correct word,",
    "start": "19163",
    "end": "24338"
  },
  {
    "text": "large language models may give a false impression that they possess actual understanding or meaning.",
    "start": "24338",
    "end": "31049"
  },
  {
    "text": "The results can include a flagrantly false narrative directly as a result of its calculated predictions versus a true understanding.",
    "start": "31680",
    "end": "40829"
  },
  {
    "text": "So ask yourself: What is the cost of using an AI that could spread misinformation?",
    "start": "41610",
    "end": "45659"
  },
  {
    "text": "What is the cost to your brand, your business, individuals or society?",
    "start": "45930",
    "end": "50160"
  },
  {
    "text": "Could your large language model be hijacked by a bad actor?",
    "start": "50550",
    "end": "53520"
  },
  {
    "text": "Let me explain how you can reduce your risk.",
    "start": "54060",
    "end": "56259"
  },
  {
    "text": "It falls into four areas: Hallucinations, Bias, Consent, and Security.",
    "start": "56280",
    "end": "62909"
  },
  {
    "text": "As I present each risk, I'll also call out the strategies you can use to mitigate these risks.",
    "start": "63240",
    "end": "68340"
  },
  {
    "text": "You ready?",
    "start": "68670",
    "end": "70177"
  },
  {
    "text": "Let's start with the falsehoods, often referred to as \"AI hallucinations\".",
    "start": "70330",
    "end": "74980"
  },
  {
    "text": "Quick sidebar -- I really don't like the word \"hallucinations\" because I fear it anthropomorphizes AI.",
    "start": "75820",
    "end": "82099"
  },
  {
    "text": "I'll explain it a bit.",
    "start": "82140",
    "end": "83664"
  },
  {
    "text": "Okay, you've probably heard the news reports of large language models claiming they're human,",
    "start": "83800",
    "end": "88588"
  },
  {
    "text": "or claiming they have emotions, or just stating things that are factually wrong.",
    "start": "88588",
    "end": "93579"
  },
  {
    "text": "What's actually going on here?",
    "start": "94030",
    "end": "96108"
  },
  {
    "text": "Well, large language models predict the next best syntactically correct word,",
    "start": "96340",
    "end": "100921"
  },
  {
    "text": "not accurate answers based on understanding of what the human is actually asking for.",
    "start": "100921",
    "end": "106569"
  },
  {
    "text": "Which means it's going to sound great, but might be 100% wrong in its answer.",
    "start": "106780",
    "end": "112090"
  },
  {
    "text": "This wrong answer is a statistical error.",
    "start": "112540",
    "end": "115450"
  },
  {
    "text": "Let's take a simple example.",
    "start": "115930",
    "end": "117519"
  },
  {
    "text": "Who authored the poems A, B, C?",
    "start": "117730",
    "end": "122590"
  },
  {
    "text": "Let's say they were all authored by the poet X, but there's one source claiming it was the author Z.",
    "start": "123130",
    "end": "132190"
  },
  {
    "text": "We have conflicting sources in the training data.",
    "start": "132820",
    "end": "135159"
  },
  {
    "text": "Which one actually wins the argument?",
    "start": "135550",
    "end": "137679"
  },
  {
    "text": "Even worse, there may not be a disagreement at all, but again, a statistical error.",
    "start": "137920",
    "end": "142990"
  },
  {
    "text": "The response could very well be incorrect because again,",
    "start": "143634",
    "end": "147429"
  },
  {
    "text": "the large language models do not understand meaning; these inaccuracies can be exceptionally dangerous.",
    "start": "147429",
    "end": "155110"
  },
  {
    "text": "It's even more dangerous when you have large language models annotate its sources for totally bogus answers.",
    "start": "155380",
    "end": "163150"
  },
  {
    "text": "Why?",
    "start": "164210",
    "end": "165210"
  },
  {
    "text": "Because it gives the perception it has proof when it just doesn't have any.",
    "start": "165350",
    "end": "170894"
  },
  {
    "text": "Imagine a call center that has replaced its personnel with a large language model, and it offers a factually wrong answer to a customer.",
    "start": "171650",
    "end": "179508"
  },
  {
    "text": "Right, here's your factually wrong answer.",
    "start": "180050",
    "end": "182930"
  },
  {
    "text": "Now, imagine how much angrier this customer will be when they can't actually offer a correction via a feedback loop.",
    "start": "183530",
    "end": "191539"
  },
  {
    "text": "This brings us to our first mitigation strategy: Explainability.",
    "start": "192050",
    "end": "196879"
  },
  {
    "text": "Now, you could offer inline explainability and pair a large language model",
    "start": "199270",
    "end": "205721"
  },
  {
    "text": "with the system that offered real data and data lineage and provenance via a knowledge graph.",
    "start": "205721",
    "end": "211159"
  },
  {
    "text": "Why did the model say what it just said?",
    "start": "211790",
    "end": "214698"
  },
  {
    "text": "Where did it pull its data from?",
    "start": "215150",
    "end": "216918"
  },
  {
    "text": "Which sources?",
    "start": "216920",
    "end": "218427"
  },
  {
    "text": "The large language model could provide variations on the answer that was offered by the knowledge graph.",
    "start": "218720",
    "end": "224120"
  },
  {
    "text": "Next risk: Bias.",
    "start": "224780",
    "end": "226846"
  },
  {
    "text": "Do not be surprised if the output for your original query only lists white male Western European poets.",
    "start": "227090",
    "end": "236689"
  },
  {
    "text": "Want a more representative answer?",
    "start": "237680",
    "end": "239480"
  },
  {
    "text": "Your prompt would have to say something like, \"Can you please give me a list of poets that include women and non-Western Europeans?\"",
    "start": "239480",
    "end": "246168"
  },
  {
    "text": "Don't expect the large language model to learn from your prompt.",
    "start": "246920",
    "end": "250159"
  },
  {
    "text": "This brings us to the second mitigation strategy: Culture and Audits.",
    "start": "250850",
    "end": "256070"
  },
  {
    "text": "Okay, culture is what people do when no one is looking.",
    "start": "259959",
    "end": "264370"
  },
  {
    "text": "It starts with approaching this entire subject with humility, as there is so much that has to be learned and even, I would say, unlearned.",
    "start": "264880",
    "end": "273430"
  },
  {
    "text": "You need teams that are truly diverse and multidisciplinary in nature working on AI because AI is a great mirror into our own biases.",
    "start": "273850",
    "end": "282399"
  },
  {
    "text": "Let's take the results of our audits of AI models and make corrections to our own organizational culture when there are disparate outcomes.",
    "start": "283000",
    "end": "292462"
  },
  {
    "text": "Audit pre-model deployment as well as post-model deployment.",
    "start": "293200",
    "end": "297250"
  },
  {
    "text": "Okay, next risk is Consent.",
    "start": "298010",
    "end": "300346"
  },
  {
    "text": "Is the data that you are curating representative?",
    "start": "301000",
    "end": "303919"
  },
  {
    "text": "Was it gathered with consent?",
    "start": "304270",
    "end": "306009"
  },
  {
    "text": "Are there copyright issues?",
    "start": "306250",
    "end": "308079"
  },
  {
    "text": "Right! Here's a little copyright symbol.",
    "start": "308600",
    "end": "310389"
  },
  {
    "text": "These are things we can and should ask for.",
    "start": "310690",
    "end": "313839"
  },
  {
    "text": "This should be included in an easy to find, understandable fact sheet.",
    "start": "314260",
    "end": "318220"
  },
  {
    "text": "Oftentimes we subjects, we have no idea where the heck the training data came from these large language models.",
    "start": "318880",
    "end": "324399"
  },
  {
    "text": "Where we were that gathered from? Did the developers hoover the dark recesses of the Internet?",
    "start": "324730",
    "end": "329556"
  },
  {
    "text": "To mitigate consent-related risk, we need combined efforts of auditing and accountability.",
    "start": "330370",
    "end": "339344"
  },
  {
    "text": "Right!",
    "start": "339620",
    "end": "340620"
  },
  {
    "text": "Accountability includes establishing AI governance processes, making sure you are compliant to existing laws and regulations,",
    "start": "340910",
    "end": "348261"
  },
  {
    "text": "and you're offering ways for people to have their feedback incorporated.",
    "start": "348261",
    "end": "353389"
  },
  {
    "text": "Now on to the final risk, Security.",
    "start": "353930",
    "end": "356995"
  },
  {
    "text": "Large language models could be used for all sorts of malicious tasks,",
    "start": "357590",
    "end": "361380"
  },
  {
    "text": "including leaking people's private information, helping criminals phish, spam, scam.",
    "start": "361380",
    "end": "367098"
  },
  {
    "text": "Hackers have gotten AI models to change their original programming, endorsing things like racism, suggesting people do illegal things.",
    "start": "367134",
    "end": "376369"
  },
  {
    "text": "It's called jailbreaking.",
    "start": "376970",
    "end": "378893"
  },
  {
    "text": "Another attack is an indirect prompt injection.",
    "start": "379160",
    "end": "383180"
  },
  {
    "text": "That's when a third party alters a website, adding hidden data to change the AI's behavior.",
    "start": "383180",
    "end": "389436"
  },
  {
    "text": "The result?",
    "start": "389720",
    "end": "390980"
  },
  {
    "text": "Automation relying on AI potentially sending out malicious instructions without you even being aware.",
    "start": "390980",
    "end": "398449"
  },
  {
    "text": "This brings us to our final mitigation strategy, and the one that actually pulls all of this together, and that is education.",
    "start": "399020",
    "end": "407750"
  },
  {
    "text": "All right, let me give you an example.",
    "start": "409160",
    "end": "411000"
  },
  {
    "text": "Training a brand new large language model produces as much carbon as over a 100 roundtrip flights between New York and Beijing.",
    "start": "411200",
    "end": "418879"
  },
  {
    "text": "I know, crazy, right?",
    "start": "419360",
    "end": "420878"
  },
  {
    "text": "This means it's important that we know the strengths and weaknesses of this technology.",
    "start": "421040",
    "end": "425960"
  },
  {
    "text": "It means educating our own people on principles for the responsible curation of AI,",
    "start": "426320",
    "end": "430882"
  },
  {
    "text": "the risks, the environmental cost, the safeguard rails, as well as what the opportunities are.",
    "start": "430882",
    "end": "436459"
  },
  {
    "text": "Let me give you another example of where education matters.",
    "start": "436940",
    "end": "439893"
  },
  {
    "text": "Today, some tech companies are just trusting that large language models training data has not been maliciously tampered with.",
    "start": "440330",
    "end": "448220"
  },
  {
    "text": "I can buy a domain myself now and fill it with bogus data.",
    "start": "448610",
    "end": "452149"
  },
  {
    "text": "By poisoning the dataset with enough examples, you could influence a large language model's behavior and outputs forever.",
    "start": "452600",
    "end": "459560"
  },
  {
    "text": "This tech isn't going anywhere.",
    "start": "460540",
    "end": "462519"
  },
  {
    "text": "We need to think about the relationship that we ultimately want to have with AI.",
    "start": "462760",
    "end": "468149"
  },
  {
    "text": "If we're going to use it to augment human intelligence, we have to ask ourselves the question:",
    "start": "468760",
    "end": "473634"
  },
  {
    "text": "What is the experience like of a person who has been augmented?",
    "start": "473634",
    "end": "477514"
  },
  {
    "text": "Are they indeed empowered?",
    "start": "477850",
    "end": "479748"
  },
  {
    "text": "Help us make education about the subject of data and AI far more accessible and inclusive than it is today.",
    "start": "480190",
    "end": "487419"
  },
  {
    "text": "We need more seats at the table for different kinds of people with varying skill sets working on this very, very important topic.",
    "start": "487990",
    "end": "496300"
  },
  {
    "text": "Thank you for your time.",
    "start": "496990",
    "end": "499528"
  }
]
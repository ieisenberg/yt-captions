[
  {
    "start": "0",
    "end": "84000"
  },
  {
    "text": "today we're going to talk about the true",
    "start": "160",
    "end": "2120"
  },
  {
    "text": "cost of generative AI for the Enterprise",
    "start": "2120",
    "end": "4359"
  },
  {
    "text": "specifically focusing on large language",
    "start": "4359",
    "end": "6520"
  },
  {
    "text": "models and it's important for an",
    "start": "6520",
    "end": "8599"
  },
  {
    "text": "Enterprise to consider all of the costs",
    "start": "8599",
    "end": "10880"
  },
  {
    "text": "Beyond simply subscribing to a chatbot",
    "start": "10880",
    "end": "13599"
  },
  {
    "text": "llm like chat GPT I'd like to start with",
    "start": "13599",
    "end": "16920"
  },
  {
    "text": "a a quick story last week I was at a",
    "start": "16920",
    "end": "19400"
  },
  {
    "text": "wedding and no one could find the best",
    "start": "19400",
    "end": "21439"
  },
  {
    "text": "man we were in the the dinner and the",
    "start": "21439",
    "end": "24039"
  },
  {
    "text": "rehearsal and all of a sudden he came",
    "start": "24039",
    "end": "26760"
  },
  {
    "text": "out of the back room with his laptop and",
    "start": "26760",
    "end": "28720"
  },
  {
    "text": "he was in this back room",
    "start": "28720",
    "end": "30480"
  },
  {
    "text": "writing his bassmen speech on his laptop",
    "start": "30480",
    "end": "33360"
  },
  {
    "text": "using chat GPT and you know what it came",
    "start": "33360",
    "end": "35520"
  },
  {
    "text": "out fantastic for a consumer use like",
    "start": "35520",
    "end": "38840"
  },
  {
    "text": "writing a last minute speech or a funny",
    "start": "38840",
    "end": "41160"
  },
  {
    "text": "poem using a consumer chatbot is awesome",
    "start": "41160",
    "end": "44360"
  },
  {
    "text": "and that's why for the consumer use case",
    "start": "44360",
    "end": "46879"
  },
  {
    "text": "spending under $25 a month for Access",
    "start": "46879",
    "end": "49760"
  },
  {
    "text": "feels like a great deal because it is",
    "start": "49760",
    "end": "52239"
  },
  {
    "text": "but we're comparing Enterprise use",
    "start": "52239",
    "end": "55520"
  },
  {
    "text": "versus consumer use for the enterprise",
    "start": "55520",
    "end": "58399"
  },
  {
    "text": "we have to safeguard what putting into",
    "start": "58399",
    "end": "60440"
  },
  {
    "text": "production when we're dealing with",
    "start": "60440",
    "end": "62120"
  },
  {
    "text": "sensitive confidential and proprietary",
    "start": "62120",
    "end": "64280"
  },
  {
    "text": "data now it's essential for the business",
    "start": "64280",
    "end": "67159"
  },
  {
    "text": "to evaluate working with a platform",
    "start": "67159",
    "end": "69960"
  },
  {
    "text": "partner or vendor that is geared towards",
    "start": "69960",
    "end": "72000"
  },
  {
    "text": "the Enterprise and this comes with very",
    "start": "72000",
    "end": "74080"
  },
  {
    "text": "different cost factors than the Consumer",
    "start": "74080",
    "end": "76640"
  },
  {
    "text": "today we're going to touch on seven of",
    "start": "76640",
    "end": "78280"
  },
  {
    "text": "these important cost factors that",
    "start": "78280",
    "end": "80479"
  },
  {
    "text": "influence how to scale generative AI",
    "start": "80479",
    "end": "82520"
  },
  {
    "text": "across the Enterprise number one use",
    "start": "82520",
    "end": "85200"
  },
  {
    "text": "case what is it that you actually want",
    "start": "85200",
    "end": "87200"
  },
  {
    "text": "to do with generative AI number two",
    "start": "87200",
    "end": "89439"
  },
  {
    "text": "model size what type and parameter size",
    "start": "89439",
    "end": "92280"
  },
  {
    "text": "of the model are you leveraging three",
    "start": "92280",
    "end": "95079"
  },
  {
    "text": "pre-training costs are you looking to",
    "start": "95079",
    "end": "97240"
  },
  {
    "text": "build an llm from scratch four",
    "start": "97240",
    "end": "100520"
  },
  {
    "text": "inferencing this is the cost of",
    "start": "100520",
    "end": "102439"
  },
  {
    "text": "generating a response using the llm five",
    "start": "102439",
    "end": "106159"
  },
  {
    "text": "tuning which is the cost of adapting the",
    "start": "106159",
    "end": "108680"
  },
  {
    "text": "pre-train model to do new tasks six",
    "start": "108680",
    "end": "112600"
  },
  {
    "text": "hosting which is the cost of deploying",
    "start": "112600",
    "end": "114799"
  },
  {
    "text": "and maintaining that model and then",
    "start": "114799",
    "end": "116680"
  },
  {
    "text": "seven deployment are you going to be",
    "start": "116680",
    "end": "119000"
  },
  {
    "text": "deploying this in the cloud on SAS or on",
    "start": "119000",
    "end": "121600"
  },
  {
    "start": "120000",
    "end": "200000"
  },
  {
    "text": "premise now these are all areas to",
    "start": "121600",
    "end": "124200"
  },
  {
    "text": "consider and the first that we're going",
    "start": "124200",
    "end": "125640"
  },
  {
    "text": "to cover is use case now I can't tell",
    "start": "125640",
    "end": "129280"
  },
  {
    "text": "you how often I have sellers customers",
    "start": "129280",
    "end": "132400"
  },
  {
    "text": "come to me and ask me to create a",
    "start": "132400",
    "end": "135200"
  },
  {
    "text": "blanket statement for what generative AI",
    "start": "135200",
    "end": "138760"
  },
  {
    "text": "is going to cost them for their",
    "start": "138760",
    "end": "140760"
  },
  {
    "text": "Enterprise and what I say to that is",
    "start": "140760",
    "end": "143400"
  },
  {
    "text": "that this is very similar to walking",
    "start": "143400",
    "end": "145959"
  },
  {
    "text": "into a car dealership and asking how",
    "start": "145959",
    "end": "148280"
  },
  {
    "text": "much a vehicle is going to be",
    "start": "148280",
    "end": "150360"
  },
  {
    "text": "different use cases will require",
    "start": "150360",
    "end": "152080"
  },
  {
    "text": "different methods and are going to drive",
    "start": "152080",
    "end": "153879"
  },
  {
    "text": "different amounts of compute we need to",
    "start": "153879",
    "end": "156400"
  },
  {
    "text": "understand are you looking for a",
    "start": "156400",
    "end": "157920"
  },
  {
    "text": "convertible a truck off-roading leather",
    "start": "157920",
    "end": "160680"
  },
  {
    "text": "interior we need some specifics and my",
    "start": "160680",
    "end": "163480"
  },
  {
    "text": "recommendation here is to work with a",
    "start": "163480",
    "end": "165319"
  },
  {
    "text": "partner or a vendor that allows you to",
    "start": "165319",
    "end": "167519"
  },
  {
    "text": "participate in a pilot so that you can",
    "start": "167519",
    "end": "169440"
  },
  {
    "text": "identify all of your pain points and",
    "start": "169440",
    "end": "171480"
  },
  {
    "text": "first see if generative AI makes sense",
    "start": "171480",
    "end": "173440"
  },
  {
    "text": "as a solution this will give you the",
    "start": "173440",
    "end": "175800"
  },
  {
    "text": "opportunity to really Workshop out what",
    "start": "175800",
    "end": "178159"
  },
  {
    "text": "it needs to test and evaluate for your",
    "start": "178159",
    "end": "181840"
  },
  {
    "text": "Enterprise play around with different",
    "start": "181840",
    "end": "183760"
  },
  {
    "text": "models see what delivers the best",
    "start": "183760",
    "end": "185840"
  },
  {
    "text": "efficacy at the lowest cost and the",
    "start": "185840",
    "end": "188239"
  },
  {
    "text": "fastest speeds if you have access to an",
    "start": "188239",
    "end": "191280"
  },
  {
    "text": "entire workbench of models and numerous",
    "start": "191280",
    "end": "193959"
  },
  {
    "text": "tuning methods you won't be locked in",
    "start": "193959",
    "end": "196200"
  },
  {
    "text": "and you can do what's right for your",
    "start": "196200",
    "end": "197720"
  },
  {
    "text": "Enterprise and truly customize that now",
    "start": "197720",
    "end": "200840"
  },
  {
    "start": "200000",
    "end": "370000"
  },
  {
    "text": "we're going to move on to our second",
    "start": "200840",
    "end": "202799"
  },
  {
    "text": "cost driver which is evaluating model",
    "start": "202799",
    "end": "206480"
  },
  {
    "text": "size now when we talk about model size",
    "start": "206480",
    "end": "209439"
  },
  {
    "text": "the size and complexity of the",
    "start": "209439",
    "end": "211480"
  },
  {
    "text": "generative AI model can really impact",
    "start": "211480",
    "end": "213840"
  },
  {
    "text": "pricing and what we see here is that the",
    "start": "213840",
    "end": "217040"
  },
  {
    "text": "larger the model is the more parameters",
    "start": "217040",
    "end": "219720"
  },
  {
    "text": "it has and that's going to drive compute",
    "start": "219720",
    "end": "222640"
  },
  {
    "text": "and different resources so what we'll",
    "start": "222640",
    "end": "224879"
  },
  {
    "text": "find is that vendors will offer",
    "start": "224879",
    "end": "226599"
  },
  {
    "text": "different pricing tiers based on model",
    "start": "226599",
    "end": "228920"
  },
  {
    "text": "size so we can look here at some",
    "start": "228920",
    "end": "230760"
  },
  {
    "text": "examples right we have our smallest",
    "start": "230760",
    "end": "233159"
  },
  {
    "text": "model here which is flan where we see",
    "start": "233159",
    "end": "236439"
  },
  {
    "text": "this at 11 billion parameters we have",
    "start": "236439",
    "end": "238599"
  },
  {
    "text": "Granite which is a midle middle tier",
    "start": "238599",
    "end": "240760"
  },
  {
    "text": "size at 13 billion and then we have the",
    "start": "240760",
    "end": "243439"
  },
  {
    "text": "largest of them all llama 2 at 70",
    "start": "243439",
    "end": "247159"
  },
  {
    "text": "billion parameters and what's important",
    "start": "247159",
    "end": "249760"
  },
  {
    "text": "to know is that different models are",
    "start": "249760",
    "end": "252400"
  },
  {
    "text": "going to serve different use cases some",
    "start": "252400",
    "end": "254360"
  },
  {
    "text": "are better for language translation",
    "start": "254360",
    "end": "256759"
  },
  {
    "text": "others are better for Q&A and as you",
    "start": "256759",
    "end": "259600"
  },
  {
    "text": "move across different models you have",
    "start": "259600",
    "end": "261519"
  },
  {
    "text": "the opportunity to assess what's going",
    "start": "261519",
    "end": "263919"
  },
  {
    "text": "to best suit your use case so something",
    "start": "263919",
    "end": "266040"
  },
  {
    "text": "to look out for when assessing a vendor",
    "start": "266040",
    "end": "268560"
  },
  {
    "text": "or partner to work with is what's their",
    "start": "268560",
    "end": "270440"
  },
  {
    "text": "stance on model access specifically are",
    "start": "270440",
    "end": "274039"
  },
  {
    "text": "they locking you into one model for",
    "start": "274039",
    "end": "276120"
  },
  {
    "text": "every use case or do you have the option",
    "start": "276120",
    "end": "278639"
  },
  {
    "text": "to select what works best for you",
    "start": "278639",
    "end": "281039"
  },
  {
    "text": "another thing is to assess whether or",
    "start": "281039",
    "end": "283000"
  },
  {
    "text": "not they're continuously innovating on",
    "start": "283000",
    "end": "284840"
  },
  {
    "text": "their own proprietary models we found",
    "start": "284840",
    "end": "287199"
  },
  {
    "text": "that Innovation at the model level can",
    "start": "287199",
    "end": "289360"
  },
  {
    "text": "actually provide you with some key",
    "start": "289360",
    "end": "291000"
  },
  {
    "text": "advantages when it comes to domain",
    "start": "291000",
    "end": "293000"
  },
  {
    "text": "specific task generation and",
    "start": "293000",
    "end": "295360"
  },
  {
    "text": "experimenting with different parameter",
    "start": "295360",
    "end": "297680"
  },
  {
    "text": "sizes now we're going to go to our third",
    "start": "297680",
    "end": "300199"
  },
  {
    "text": "cost driver which is",
    "start": "300199",
    "end": "302880"
  },
  {
    "text": "pre-training this is the process of",
    "start": "302880",
    "end": "305000"
  },
  {
    "text": "building and training a foundation model",
    "start": "305000",
    "end": "307240"
  },
  {
    "text": "from",
    "start": "307240",
    "end": "308120"
  },
  {
    "text": "scratch now if we look at what this",
    "start": "308120",
    "end": "311800"
  },
  {
    "text": "means it's been very hos prohibitive for",
    "start": "311800",
    "end": "315280"
  },
  {
    "text": "a lot of Enterprises to do so because it",
    "start": "315280",
    "end": "317759"
  },
  {
    "text": "requires a tremendous amount of compute",
    "start": "317759",
    "end": "321000"
  },
  {
    "text": "time and effort and while this does give",
    "start": "321000",
    "end": "323360"
  },
  {
    "text": "Enterprises the control of the data used",
    "start": "323360",
    "end": "325520"
  },
  {
    "text": "to train an llm it does come with a cost",
    "start": "325520",
    "end": "328919"
  },
  {
    "text": "we can look at something that everyone's",
    "start": "328919",
    "end": "330759"
  },
  {
    "text": "familiar with gpt3 and if we look at",
    "start": "330759",
    "end": "333400"
  },
  {
    "text": "what some of these cost factors were it",
    "start": "333400",
    "end": "335520"
  },
  {
    "text": "was over a th000",
    "start": "335520",
    "end": "338000"
  },
  {
    "text": "gpus over a 30-day period and what this",
    "start": "338000",
    "end": "342600"
  },
  {
    "text": "particular 30-day period cost was over",
    "start": "342600",
    "end": "345600"
  },
  {
    "text": "4.6 million so we can see that this is",
    "start": "345600",
    "end": "350520"
  },
  {
    "text": "very very expensive and really why we",
    "start": "350520",
    "end": "353120"
  },
  {
    "text": "only see a few key players that have",
    "start": "353120",
    "end": "355240"
  },
  {
    "text": "emerged on the marketplace to take on",
    "start": "355240",
    "end": "357880"
  },
  {
    "text": "that challenge of pre-training llms from",
    "start": "357880",
    "end": "360240"
  },
  {
    "text": "scratch so if you're not going to",
    "start": "360240",
    "end": "362039"
  },
  {
    "text": "pre-train you can certainly leverage and",
    "start": "362039",
    "end": "364319"
  },
  {
    "text": "take advantage of an llm that's already",
    "start": "364319",
    "end": "366400"
  },
  {
    "text": "been tree pre-trained so now we'll move",
    "start": "366400",
    "end": "368520"
  },
  {
    "text": "on to the next cost factor of working",
    "start": "368520",
    "end": "371800"
  },
  {
    "start": "370000",
    "end": "500000"
  },
  {
    "text": "with a pre-trained llm which is",
    "start": "371800",
    "end": "374840"
  },
  {
    "text": "inferencing and when we talk about",
    "start": "374840",
    "end": "376720"
  },
  {
    "text": "inferencing we are talking about the",
    "start": "376720",
    "end": "378759"
  },
  {
    "text": "process that the model uses to",
    "start": "378759",
    "end": "380880"
  },
  {
    "text": "understand the prompt question and the",
    "start": "380880",
    "end": "382880"
  },
  {
    "text": "process that it uses to generate a",
    "start": "382880",
    "end": "384800"
  },
  {
    "text": "response so essentially this is how the",
    "start": "384800",
    "end": "387440"
  },
  {
    "text": "model figures out what it is that you",
    "start": "387440",
    "end": "389120"
  },
  {
    "text": "want and then uses its own knowledge to",
    "start": "389120",
    "end": "391759"
  },
  {
    "text": "create the answer inferencing operates",
    "start": "391759",
    "end": "394759"
  },
  {
    "text": "on a discrete unit of information that",
    "start": "394759",
    "end": "397639"
  },
  {
    "text": "we call a token and this is a common",
    "start": "397639",
    "end": "400720"
  },
  {
    "text": "industry term where one token roughly",
    "start": "400720",
    "end": "404479"
  },
  {
    "text": "equates to 3/4 of a word now you can",
    "start": "404479",
    "end": "409639"
  },
  {
    "text": "expand that out to identify that 100",
    "start": "409639",
    "end": "412319"
  },
  {
    "text": "tokens would equate to roughly 75 words",
    "start": "412319",
    "end": "415360"
  },
  {
    "text": "and if you're still trying to figure out",
    "start": "415360",
    "end": "416840"
  },
  {
    "text": "what that benchmarks into the entire",
    "start": "416840",
    "end": "419560"
  },
  {
    "text": "work of Shakespeare would come out to",
    "start": "419560",
    "end": "421319"
  },
  {
    "text": "roughly 900,000 words now the size of a",
    "start": "421319",
    "end": "424319"
  },
  {
    "text": "token can vary depending on which",
    "start": "424319",
    "end": "426560"
  },
  {
    "text": "tokenizer you use tokenizer refers to",
    "start": "426560",
    "end": "429759"
  },
  {
    "text": "the tool that actually converts the text",
    "start": "429759",
    "end": "432599"
  },
  {
    "text": "to a token but 3/4 of a word is a rough",
    "start": "432599",
    "end": "435759"
  },
  {
    "text": "rule of thumb that you can go off of now",
    "start": "435759",
    "end": "438280"
  },
  {
    "text": "when we talk about the cost for a single",
    "start": "438280",
    "end": "440440"
  },
  {
    "text": "inference it's important to note that",
    "start": "440440",
    "end": "442479"
  },
  {
    "text": "this includes the number of tokens in",
    "start": "442479",
    "end": "444720"
  },
  {
    "text": "both the",
    "start": "444720",
    "end": "446599"
  },
  {
    "text": "prompt and the completion which would be",
    "start": "446599",
    "end": "450800"
  },
  {
    "text": "the",
    "start": "450800",
    "end": "452120"
  },
  {
    "text": "output so important to note that it",
    "start": "452120",
    "end": "454759"
  },
  {
    "text": "covers both of those now there's one",
    "start": "454759",
    "end": "458000"
  },
  {
    "text": "other term that's important when we're",
    "start": "458000",
    "end": "459560"
  },
  {
    "text": "covering inferencing and that is prompt",
    "start": "459560",
    "end": "463759"
  },
  {
    "text": "engineering now when we talk about",
    "start": "463759",
    "end": "465680"
  },
  {
    "text": "prompt",
    "start": "465680",
    "end": "467199"
  },
  {
    "text": "engineering this is how we interact with",
    "start": "467199",
    "end": "471039"
  },
  {
    "text": "the prompt itself and this is an",
    "start": "471039",
    "end": "473039"
  },
  {
    "text": "industry term for really the methodology",
    "start": "473039",
    "end": "476199"
  },
  {
    "text": "used to craft effective prompts with the",
    "start": "476199",
    "end": "479360"
  },
  {
    "text": "ultimate goal of eliciting a desired",
    "start": "479360",
    "end": "481440"
  },
  {
    "text": "response from the llm what's important",
    "start": "481440",
    "end": "483800"
  },
  {
    "text": "to note here is that it does not touch",
    "start": "483800",
    "end": "485720"
  },
  {
    "text": "the parameters of the model itself it's",
    "start": "485720",
    "end": "487560"
  },
  {
    "text": "more like choosing the right words and",
    "start": "487560",
    "end": "489479"
  },
  {
    "text": "formatting how you ask the question to",
    "start": "489479",
    "end": "491879"
  },
  {
    "text": "really help the model better understand",
    "start": "491879",
    "end": "494120"
  },
  {
    "text": "and it's a really cost effective way to",
    "start": "494120",
    "end": "496199"
  },
  {
    "text": "achieve tailored results without",
    "start": "496199",
    "end": "498080"
  },
  {
    "text": "extensive model alteration and this is",
    "start": "498080",
    "end": "500680"
  },
  {
    "start": "500000",
    "end": "807000"
  },
  {
    "text": "different than tuning because it does",
    "start": "500680",
    "end": "502440"
  },
  {
    "text": "not require the high compute resources",
    "start": "502440",
    "end": "504720"
  },
  {
    "text": "or any of the hosting so now we're",
    "start": "504720",
    "end": "506639"
  },
  {
    "text": "moving on to cost Factor number five",
    "start": "506639",
    "end": "510120"
  },
  {
    "text": "which is tuning now when we talk about",
    "start": "510120",
    "end": "513039"
  },
  {
    "text": "tuning we're talking about the process",
    "start": "513039",
    "end": "515120"
  },
  {
    "text": "of adjusting the internal settings or",
    "start": "515120",
    "end": "517640"
  },
  {
    "text": "parameters of the model itself to really",
    "start": "517640",
    "end": "519560"
  },
  {
    "text": "improve performance tuning is measured",
    "start": "519560",
    "end": "522200"
  },
  {
    "text": "in hours and you'll often see that there",
    "start": "522200",
    "end": "524680"
  },
  {
    "text": "are different hourly rate charges",
    "start": "524680",
    "end": "526959"
  },
  {
    "text": "depending on what model size you're",
    "start": "526959",
    "end": "528920"
  },
  {
    "text": "using we talked earlier about how",
    "start": "528920",
    "end": "530800"
  },
  {
    "text": "different parameter sizes lead to",
    "start": "530800",
    "end": "532480"
  },
  {
    "text": "different cost increases now when you're",
    "start": "532480",
    "end": "535000"
  },
  {
    "text": "making the decision to",
    "start": "535000",
    "end": "536760"
  },
  {
    "text": "tune there maybe two reasons",
    "start": "536760",
    "end": "540040"
  },
  {
    "text": "why you would choose to do so so reason",
    "start": "540040",
    "end": "543079"
  },
  {
    "text": "number one maybe it's to achieve better",
    "start": "543079",
    "end": "546320"
  },
  {
    "text": "performance from your base model when we",
    "start": "546320",
    "end": "549880"
  },
  {
    "text": "talk about better",
    "start": "549880",
    "end": "551399"
  },
  {
    "text": "performance we're going to evaluate",
    "start": "551399",
    "end": "554279"
  },
  {
    "text": "whether or not tuning the model on a",
    "start": "554279",
    "end": "556360"
  },
  {
    "text": "large number of labeled data could",
    "start": "556360",
    "end": "558519"
  },
  {
    "text": "really enhance performance when we do",
    "start": "558519",
    "end": "561040"
  },
  {
    "text": "this we see that you can actually",
    "start": "561040",
    "end": "563959"
  },
  {
    "text": "optimize it by bringing in your own data",
    "start": "563959",
    "end": "566760"
  },
  {
    "text": "the other option for tuning may be to",
    "start": "566760",
    "end": "569200"
  },
  {
    "text": "evaluate whether or not you can lower",
    "start": "569200",
    "end": "571240"
  },
  {
    "text": "the cost at scale by deploying a smaller",
    "start": "571240",
    "end": "575279"
  },
  {
    "text": "model than maybe what you initially used",
    "start": "575279",
    "end": "577920"
  },
  {
    "text": "one thing that's really important to",
    "start": "577920",
    "end": "579320"
  },
  {
    "text": "keep in mind here is that the cost of",
    "start": "579320",
    "end": "581200"
  },
  {
    "text": "label data acquisition is a really",
    "start": "581200",
    "end": "583240"
  },
  {
    "text": "important factor now when we talk about",
    "start": "583240",
    "end": "585920"
  },
  {
    "text": "tuning there are two main functions of",
    "start": "585920",
    "end": "588399"
  },
  {
    "text": "tuning and two main methodologies of how",
    "start": "588399",
    "end": "591000"
  },
  {
    "text": "you can tune we have fine",
    "start": "591000",
    "end": "593800"
  },
  {
    "text": "tuning and then we have parameter",
    "start": "593800",
    "end": "597279"
  },
  {
    "text": "efficient fine-tuning otherwise known as",
    "start": "597279",
    "end": "601519"
  },
  {
    "text": "PFT now to cover the difference between",
    "start": "601519",
    "end": "604160"
  },
  {
    "text": "these two when we talk about fine-tuning",
    "start": "604160",
    "end": "606839"
  },
  {
    "text": "we're talking about extensive adaptation",
    "start": "606839",
    "end": "609760"
  },
  {
    "text": "of the model itself so you're tuning all",
    "start": "609760",
    "end": "612600"
  },
  {
    "text": "of the parameters and changing them",
    "start": "612600",
    "end": "615360"
  },
  {
    "text": "you're going to be generating a forked",
    "start": "615360",
    "end": "617440"
  },
  {
    "text": "version of this base model that actually",
    "start": "617440",
    "end": "620000"
  },
  {
    "text": "requires you to then go on and host that",
    "start": "620000",
    "end": "623880"
  },
  {
    "text": "and it",
    "start": "623880",
    "end": "625839"
  },
  {
    "text": "requires hundreds of thousands",
    "start": "625839",
    "end": "629680"
  },
  {
    "text": "of data points label data for you to",
    "start": "629680",
    "end": "632519"
  },
  {
    "text": "bring in here so this is ideal for",
    "start": "632519",
    "end": "635920"
  },
  {
    "text": "highly specialized tasks where",
    "start": "635920",
    "end": "637720"
  },
  {
    "text": "performance is critical when we talk",
    "start": "637720",
    "end": "640040"
  },
  {
    "text": "about parameter efficient fine-tuning",
    "start": "640040",
    "end": "642320"
  },
  {
    "text": "this really aims to achieve task",
    "start": "642320",
    "end": "644320"
  },
  {
    "text": "specific performance without the high",
    "start": "644320",
    "end": "646560"
  },
  {
    "text": "costs that are associated with extensive",
    "start": "646560",
    "end": "648760"
  },
  {
    "text": "fine-tuning and this is really achieved",
    "start": "648760",
    "end": "650920"
  },
  {
    "text": "by avoiding any changes to the model",
    "start": "650920",
    "end": "652920"
  },
  {
    "text": "itself so here you could think of this",
    "start": "652920",
    "end": "655720"
  },
  {
    "text": "as tuning smaller models by adding",
    "start": "655720",
    "end": "658240"
  },
  {
    "text": "additional parameters is not altering",
    "start": "658240",
    "end": "660200"
  },
  {
    "text": "what exists so for this you can see this",
    "start": "660200",
    "end": "662639"
  },
  {
    "text": "more around hundreds to thousands of",
    "start": "662639",
    "end": "667399"
  },
  {
    "text": "label data sources uh and we see",
    "start": "667399",
    "end": "670920"
  },
  {
    "text": "different types of cost-effective ways",
    "start": "670920",
    "end": "673800"
  },
  {
    "text": "to apply parameter efficient fine tuning",
    "start": "673800",
    "end": "676760"
  },
  {
    "text": "some of these types that you may have",
    "start": "676760",
    "end": "678320"
  },
  {
    "text": "heard of may include prefix tuning",
    "start": "678320",
    "end": "680800"
  },
  {
    "text": "prompt tuning ptuning Laura but these",
    "start": "680800",
    "end": "684040"
  },
  {
    "text": "are all methods of parameter efficient",
    "start": "684040",
    "end": "686639"
  },
  {
    "text": "fine-tuning so let's drive this home an",
    "start": "686639",
    "end": "689279"
  },
  {
    "text": "analogy let's say you buy a home you",
    "start": "689279",
    "end": "691920"
  },
  {
    "text": "move in congratulations everything's",
    "start": "691920",
    "end": "694120"
  },
  {
    "text": "perfect but after a couple of months you",
    "start": "694120",
    "end": "696639"
  },
  {
    "text": "discover that it actually snows quite a",
    "start": "696639",
    "end": "698720"
  },
  {
    "text": "bit more uh in your environment than",
    "start": "698720",
    "end": "701720"
  },
  {
    "text": "what you thought it would and it gets a",
    "start": "701720",
    "end": "703120"
  },
  {
    "text": "lot colder and initially you had windows",
    "start": "703120",
    "end": "707200"
  },
  {
    "text": "that served you quite well in the summer",
    "start": "707200",
    "end": "709560"
  },
  {
    "text": "but now that it's winter they no longer",
    "start": "709560",
    "end": "712160"
  },
  {
    "text": "work it's really drafty so you decide to",
    "start": "712160",
    "end": "715800"
  },
  {
    "text": "go and completely change the structure",
    "start": "715800",
    "end": "717880"
  },
  {
    "text": "of your windows you put new windows in",
    "start": "717880",
    "end": "720639"
  },
  {
    "text": "that provide you with insulation and you",
    "start": "720639",
    "end": "723360"
  },
  {
    "text": "even get some really nice curtains to go",
    "start": "723360",
    "end": "725519"
  },
  {
    "text": "along with that but on top of that it",
    "start": "725519",
    "end": "727800"
  },
  {
    "text": "snows so much more so now you actually",
    "start": "727800",
    "end": "730440"
  },
  {
    "text": "have to go on and buy a ton of new",
    "start": "730440",
    "end": "733399"
  },
  {
    "text": "equipment you have to buy snow plow snow",
    "start": "733399",
    "end": "735959"
  },
  {
    "text": "shovel snow boots snow tires and",
    "start": "735959",
    "end": "738560"
  },
  {
    "text": "actually build yourself a garage to",
    "start": "738560",
    "end": "740680"
  },
  {
    "text": "store all of this this is an example of",
    "start": "740680",
    "end": "743880"
  },
  {
    "text": "fine tuning in the sense that you are",
    "start": "743880",
    "end": "746240"
  },
  {
    "text": "making structural changes to the",
    "start": "746240",
    "end": "748320"
  },
  {
    "text": "architecture of your house how this",
    "start": "748320",
    "end": "750480"
  },
  {
    "text": "would relate to the model making",
    "start": "750480",
    "end": "752040"
  },
  {
    "text": "structural changes to the underlying",
    "start": "752040",
    "end": "754120"
  },
  {
    "text": "parameters if we look at what this would",
    "start": "754120",
    "end": "756440"
  },
  {
    "text": "mean for p well perhaps here you're not",
    "start": "756440",
    "end": "759920"
  },
  {
    "text": "going to do anything to actually change",
    "start": "759920",
    "end": "761680"
  },
  {
    "text": "the underlying structure maybe instead",
    "start": "761680",
    "end": "763760"
  },
  {
    "text": "of rebuilding your windows you put a",
    "start": "763760",
    "end": "765880"
  },
  {
    "text": "towel under there to block the draft",
    "start": "765880",
    "end": "767920"
  },
  {
    "text": "instead of building a garage to house",
    "start": "767920",
    "end": "770240"
  },
  {
    "text": "all of your new snow equipment maybe you",
    "start": "770240",
    "end": "772399"
  },
  {
    "text": "reuse something you already have and you",
    "start": "772399",
    "end": "775120"
  },
  {
    "text": "just use your broom and use that to",
    "start": "775120",
    "end": "777600"
  },
  {
    "text": "scrape snow away so it's helpful to",
    "start": "777600",
    "end": "780120"
  },
  {
    "text": "consider here that there's different",
    "start": "780120",
    "end": "782560"
  },
  {
    "text": "methods that make sense for different",
    "start": "782560",
    "end": "784720"
  },
  {
    "text": "use cases perhaps in some we mentioned",
    "start": "784720",
    "end": "787360"
  },
  {
    "text": "earlier you can get everything you need",
    "start": "787360",
    "end": "788959"
  },
  {
    "text": "in your output from prompt engineering",
    "start": "788959",
    "end": "791360"
  },
  {
    "text": "as you need to make your models tuned",
    "start": "791360",
    "end": "793800"
  },
  {
    "text": "for more specific use cases it's helpful",
    "start": "793800",
    "end": "796360"
  },
  {
    "text": "to have different methods of doing so",
    "start": "796360",
    "end": "798320"
  },
  {
    "text": "and working with a partner or vendor",
    "start": "798320",
    "end": "800120"
  },
  {
    "text": "that provides you with the ability to",
    "start": "800120",
    "end": "801720"
  },
  {
    "text": "explore different parameter efficient",
    "start": "801720",
    "end": "804079"
  },
  {
    "text": "fine-tuning methods as well as",
    "start": "804079",
    "end": "805680"
  },
  {
    "text": "fine-tuning for when you really need it",
    "start": "805680",
    "end": "807320"
  },
  {
    "start": "807000",
    "end": "996000"
  },
  {
    "text": "because then you have the advantage of",
    "start": "807320",
    "end": "809399"
  },
  {
    "text": "selecting the most cost effective method",
    "start": "809399",
    "end": "811839"
  },
  {
    "text": "for your needs now we're going to move",
    "start": "811839",
    "end": "814199"
  },
  {
    "text": "on to discuss evaluating factor six",
    "start": "814199",
    "end": "817680"
  },
  {
    "text": "which is when do you need to host a",
    "start": "817680",
    "end": "821240"
  },
  {
    "text": "model now there are different",
    "start": "821240",
    "end": "823440"
  },
  {
    "text": "circumstances that would require you to",
    "start": "823440",
    "end": "826480"
  },
  {
    "text": "actually have to host a model to then go",
    "start": "826480",
    "end": "828440"
  },
  {
    "text": "back and interact with it in these ways",
    "start": "828440",
    "end": "830720"
  },
  {
    "text": "that we discussed before for inferencing",
    "start": "830720",
    "end": "833199"
  },
  {
    "text": "and things of that sort now if you are",
    "start": "833199",
    "end": "836360"
  },
  {
    "text": "going to make an llm available for you",
    "start": "836360",
    "end": "838800"
  },
  {
    "text": "use there are two ways to go about doing",
    "start": "838800",
    "end": "840920"
  },
  {
    "text": "it one would be hosting it or one would",
    "start": "840920",
    "end": "843880"
  },
  {
    "text": "be using an inference API Each of which",
    "start": "843880",
    "end": "846920"
  },
  {
    "text": "becomes relevant depending on whether or",
    "start": "846920",
    "end": "848680"
  },
  {
    "text": "not you're going to fine-tune a model so",
    "start": "848680",
    "end": "851160"
  },
  {
    "text": "if you're not fine-tuning a model and",
    "start": "851160",
    "end": "853120"
  },
  {
    "text": "you're going to use some of those",
    "start": "853120",
    "end": "854079"
  },
  {
    "text": "earlier methods we discussed where maybe",
    "start": "854079",
    "end": "855920"
  },
  {
    "text": "you're using parameter efficient",
    "start": "855920",
    "end": "857720"
  },
  {
    "text": "fine-tuning or you're using prompt",
    "start": "857720",
    "end": "859880"
  },
  {
    "text": "engineering this is when you can go on",
    "start": "859880",
    "end": "862399"
  },
  {
    "text": "and us an API for inferencing and",
    "start": "862399",
    "end": "866480"
  },
  {
    "text": "essentially what this means is that",
    "start": "866480",
    "end": "868320"
  },
  {
    "text": "you're going to stay consistent with",
    "start": "868320",
    "end": "870160"
  },
  {
    "text": "those initial cost factors that we",
    "start": "870160",
    "end": "872240"
  },
  {
    "text": "described with the token unit of driving",
    "start": "872240",
    "end": "876480"
  },
  {
    "text": "price and cost and compute and here the",
    "start": "876480",
    "end": "879240"
  },
  {
    "text": "llm is predeployment",
    "start": "879240",
    "end": "882600"
  },
  {
    "text": "as you need it again as I mentioned the",
    "start": "896839",
    "end": "900120"
  },
  {
    "text": "cost for inference when you're using an",
    "start": "900120",
    "end": "901880"
  },
  {
    "text": "API inference is based on the number of",
    "start": "901880",
    "end": "904199"
  },
  {
    "text": "tokens that have been processed by The",
    "start": "904199",
    "end": "906079"
  },
  {
    "text": "Prompt plus the completion of that",
    "start": "906079",
    "end": "908160"
  },
  {
    "text": "prompt via the API call this again is",
    "start": "908160",
    "end": "911560"
  },
  {
    "text": "used when you're not making changes to",
    "start": "911560",
    "end": "913639"
  },
  {
    "text": "the underlying model so you're not",
    "start": "913639",
    "end": "915160"
  },
  {
    "text": "fine-tuning and you're not bringing",
    "start": "915160",
    "end": "916839"
  },
  {
    "text": "something new in that's not already",
    "start": "916839",
    "end": "918279"
  },
  {
    "text": "hosted by your platform the other way we",
    "start": "918279",
    "end": "921360"
  },
  {
    "text": "consider hosting is actually when it",
    "start": "921360",
    "end": "923440"
  },
  {
    "text": "becomes relevant when you are",
    "start": "923440",
    "end": "925360"
  },
  {
    "text": "fine-tuning or you are bringing your own",
    "start": "925360",
    "end": "927880"
  },
  {
    "text": "model at that point you are required to",
    "start": "927880",
    "end": "931079"
  },
  {
    "text": "then go and host that model because",
    "start": "931079",
    "end": "932680"
  },
  {
    "text": "you're essentially creating either a",
    "start": "932680",
    "end": "934240"
  },
  {
    "text": "forked version or bringing something new",
    "start": "934240",
    "end": "936399"
  },
  {
    "text": "in and in this case the llm is actually",
    "start": "936399",
    "end": "939199"
  },
  {
    "text": "made available for deployment by the",
    "start": "939199",
    "end": "941480"
  },
  {
    "text": "platform Provider by taking this in and",
    "start": "941480",
    "end": "943959"
  },
  {
    "text": "so for this you could think of it as",
    "start": "943959",
    "end": "945959"
  },
  {
    "text": "rather than phoning a friend because",
    "start": "945959",
    "end": "948240"
  },
  {
    "text": "they don't have access to a phone you",
    "start": "948240",
    "end": "950519"
  },
  {
    "text": "actually build them a room in your house",
    "start": "950519",
    "end": "952440"
  },
  {
    "text": "and that's where they are for easy",
    "start": "952440",
    "end": "953959"
  },
  {
    "text": "access whenever you need to chat them up",
    "start": "953959",
    "end": "955959"
  },
  {
    "text": "so when we're talking about how we think",
    "start": "955959",
    "end": "958800"
  },
  {
    "text": "about cost factors when you are actually",
    "start": "958800",
    "end": "961480"
  },
  {
    "text": "hosting a new forked version of the",
    "start": "961480",
    "end": "963199"
  },
  {
    "text": "model on top of what you use with your",
    "start": "963199",
    "end": "966000"
  },
  {
    "text": "tokens for prompting you also have to",
    "start": "966000",
    "end": "968480"
  },
  {
    "text": "consider in the hours that are required",
    "start": "968480",
    "end": "972199"
  },
  {
    "text": "for hosting this model and again you",
    "start": "972199",
    "end": "975440"
  },
  {
    "text": "would pay for hours based off of the",
    "start": "975440",
    "end": "977319"
  },
  {
    "text": "amount of time that you want to interact",
    "start": "977319",
    "end": "978759"
  },
  {
    "text": "with the model so if this is something",
    "start": "978759",
    "end": "980240"
  },
  {
    "text": "you need to interact with all the time",
    "start": "980240",
    "end": "982759"
  },
  {
    "text": "you'd be paying the hour cost for 24x7",
    "start": "982759",
    "end": "985800"
  },
  {
    "text": "access to this model now again it's it's",
    "start": "985800",
    "end": "988680"
  },
  {
    "text": "very important to realize that different",
    "start": "988680",
    "end": "991199"
  },
  {
    "text": "use cases and circumstances are going to",
    "start": "991199",
    "end": "993399"
  },
  {
    "text": "require different methods of connecting",
    "start": "993399",
    "end": "995120"
  },
  {
    "text": "to your model it's helpful to have a",
    "start": "995120",
    "end": "997240"
  },
  {
    "start": "996000",
    "end": "1159000"
  },
  {
    "text": "vendor or partner that actually allows",
    "start": "997240",
    "end": "1000120"
  },
  {
    "text": "you to interact with your model in",
    "start": "1000120",
    "end": "1001920"
  },
  {
    "text": "numerous ways if you do need to host it",
    "start": "1001920",
    "end": "1004279"
  },
  {
    "text": "with fine tuning to have that option but",
    "start": "1004279",
    "end": "1006800"
  },
  {
    "text": "you know if you can do an API inference",
    "start": "1006800",
    "end": "1009040"
  },
  {
    "text": "to also have the ability to access it in",
    "start": "1009040",
    "end": "1011199"
  },
  {
    "text": "that way as",
    "start": "1011199",
    "end": "1012319"
  },
  {
    "text": "well and now we've made it to our",
    "start": "1012319",
    "end": "1015040"
  },
  {
    "text": "seventh cost factor which is deployment",
    "start": "1015040",
    "end": "1019399"
  },
  {
    "text": "now when we think about deployment every",
    "start": "1019399",
    "end": "1021839"
  },
  {
    "text": "industry has different standards and",
    "start": "1021839",
    "end": "1024640"
  },
  {
    "text": "every business has different needs so we",
    "start": "1024640",
    "end": "1026880"
  },
  {
    "text": "are referring to where you're putting",
    "start": "1026880",
    "end": "1029120"
  },
  {
    "text": "the platform and the cost of using",
    "start": "1029120",
    "end": "1031280"
  },
  {
    "text": "generative AI can vary significantly",
    "start": "1031280",
    "end": "1033280"
  },
  {
    "text": "depending on whether you choose SAS or",
    "start": "1033280",
    "end": "1035880"
  },
  {
    "text": "an on-prem deployment so when we talk",
    "start": "1035880",
    "end": "1038600"
  },
  {
    "text": "about SAS there are some benefits here",
    "start": "1038600",
    "end": "1041520"
  },
  {
    "text": "when it comes to cost standpoint uh",
    "start": "1041520",
    "end": "1043720"
  },
  {
    "text": "first of all you're using a subscription",
    "start": "1043720",
    "end": "1045600"
  },
  {
    "text": "feed this is often a predictable and",
    "start": "1045600",
    "end": "1047959"
  },
  {
    "text": "manage",
    "start": "1047959",
    "end": "1049039"
  },
  {
    "text": "cost structure as you're paying that",
    "start": "1049039",
    "end": "1050640"
  },
  {
    "text": "recurring fee to access the AI service",
    "start": "1050640",
    "end": "1053679"
  },
  {
    "text": "you have a different approach to the",
    "start": "1053679",
    "end": "1055280"
  },
  {
    "text": "infrastructure here you're not going out",
    "start": "1055280",
    "end": "1057280"
  },
  {
    "text": "and procuring your own hardware and data",
    "start": "1057280",
    "end": "1060039"
  },
  {
    "text": "centers you are um avoiding that aspect",
    "start": "1060039",
    "end": "1063120"
  },
  {
    "text": "of the cost and when it comes to",
    "start": "1063120",
    "end": "1064520"
  },
  {
    "text": "scalability you have the ability to",
    "start": "1064520",
    "end": "1066640"
  },
  {
    "text": "increase or decrease usage as needed and",
    "start": "1066640",
    "end": "1070000"
  },
  {
    "text": "again all of the maintenance and updates",
    "start": "1070000",
    "end": "1071960"
  },
  {
    "text": "to the infrastructure are included the",
    "start": "1071960",
    "end": "1074919"
  },
  {
    "text": "big thing here is that when it comes to",
    "start": "1074919",
    "end": "1076640"
  },
  {
    "text": "generative AI a lot of people are",
    "start": "1076640",
    "end": "1078640"
  },
  {
    "text": "concerned about acquiring gpus with this",
    "start": "1078640",
    "end": "1082200"
  },
  {
    "text": "you don't need to go out and procure",
    "start": "1082200",
    "end": "1083720"
  },
  {
    "text": "your own gpus the SAS providers are",
    "start": "1083720",
    "end": "1086000"
  },
  {
    "text": "actually sharing those GPU resources",
    "start": "1086000",
    "end": "1088559"
  },
  {
    "text": "across multiple users so it ends up",
    "start": "1088559",
    "end": "1090559"
  },
  {
    "text": "being more cost effective for the end",
    "start": "1090559",
    "end": "1093120"
  },
  {
    "text": "user on the other end we have on premise",
    "start": "1093120",
    "end": "1096880"
  },
  {
    "text": "now for some Industries there are",
    "start": "1096880",
    "end": "1098720"
  },
  {
    "text": "regulations that require you to do",
    "start": "1098720",
    "end": "1101520"
  },
  {
    "text": "things on Prem and you're not allowed to",
    "start": "1101520",
    "end": "1103840"
  },
  {
    "text": "host your data in the cloud and for that",
    "start": "1103840",
    "end": "1106320"
  },
  {
    "text": "there are solutions out there for on",
    "start": "1106320",
    "end": "1108000"
  },
  {
    "text": "premise deployments as well what's",
    "start": "1108000",
    "end": "1110200"
  },
  {
    "text": "important to note here though is that",
    "start": "1110200",
    "end": "1112000"
  },
  {
    "text": "you are required to purchase and",
    "start": "1112000",
    "end": "1113760"
  },
  {
    "text": "maintain those gpus uh the amount of",
    "start": "1113760",
    "end": "1116400"
  },
  {
    "text": "which would be contingent to the amount",
    "start": "1116400",
    "end": "1118640"
  },
  {
    "text": "of compute that is required um based off",
    "start": "1118640",
    "end": "1121520"
  },
  {
    "text": "of your inferencing tuning model",
    "start": "1121520",
    "end": "1124000"
  },
  {
    "text": "selection but you do have the benefit",
    "start": "1124000",
    "end": "1126360"
  },
  {
    "text": "here of having full control over the",
    "start": "1126360",
    "end": "1128520"
  },
  {
    "text": "architecture and how your data is",
    "start": "1128520",
    "end": "1130720"
  },
  {
    "text": "deployed there are no black boxes so",
    "start": "1130720",
    "end": "1133200"
  },
  {
    "text": "again depending on your use case in",
    "start": "1133200",
    "end": "1135280"
  },
  {
    "text": "Industry you might have different needs",
    "start": "1135280",
    "end": "1137480"
  },
  {
    "text": "but the recommendation here is to find a",
    "start": "1137480",
    "end": "1139600"
  },
  {
    "text": "partner or vendor to work with that can",
    "start": "1139600",
    "end": "1141600"
  },
  {
    "text": "meet you where you're at that can",
    "start": "1141600",
    "end": "1142960"
  },
  {
    "text": "provide you with the opportunity to",
    "start": "1142960",
    "end": "1144880"
  },
  {
    "text": "leverage generative AI whether in the",
    "start": "1144880",
    "end": "1147039"
  },
  {
    "text": "cloud or on premise thank you for",
    "start": "1147039",
    "end": "1149440"
  },
  {
    "text": "watching if you've liked this video and",
    "start": "1149440",
    "end": "1151400"
  },
  {
    "text": "you want to see more like it please like",
    "start": "1151400",
    "end": "1153280"
  },
  {
    "text": "And subscribe if you have any questions",
    "start": "1153280",
    "end": "1155640"
  },
  {
    "text": "please drop them in the comments",
    "start": "1155640",
    "end": "1158600"
  },
  {
    "text": "below",
    "start": "1158600",
    "end": "1161600"
  }
]
[
  {
    "start": "0",
    "end": "65000"
  },
  {
    "text": "As a machine learning engineer,",
    "start": "390",
    "end": "1906"
  },
  {
    "text": "you may have experienced this dilemma.",
    "start": "1906",
    "end": "3629"
  },
  {
    "text": "You've cleaned and processed your data",
    "start": "4019",
    "end": "5836"
  },
  {
    "text": "and now it's time to train your machine learning model.",
    "start": "5836",
    "end": "7920"
  },
  {
    "text": "Let's draw an example of what your graph might look like.",
    "start": "9640",
    "end": "12010"
  },
  {
    "text": "For a data set with these following points as an example,",
    "start": "12900",
    "end": "17604"
  },
  {
    "text": "you're probably expecting a graph that looks like this.",
    "start": "17604",
    "end": "21540"
  },
  {
    "text": "However, after training your machine learning model,",
    "start": "22630",
    "end": "25223"
  },
  {
    "text": "you find out that it looks like this.",
    "start": "25223",
    "end": "28029"
  },
  {
    "text": "So obviously the data is underfitting",
    "start": "28960",
    "end": "32648"
  },
  {
    "text": "and the model wasn't able to learn the training data well enough.",
    "start": "32649",
    "end": "35769"
  },
  {
    "text": "So we can fix that by training the data for a longer amount of time.",
    "start": "36220",
    "end": "39820"
  },
  {
    "text": "However, now it looks like this.",
    "start": "40660",
    "end": "43569"
  },
  {
    "text": "It's fitting almost every single data point exactly.",
    "start": "44140",
    "end": "46989"
  },
  {
    "text": "So it looks like the model has learned the training data a little too well.",
    "start": "47710",
    "end": "51669"
  },
  {
    "text": "Well, why does this happen?",
    "start": "52120",
    "end": "53559"
  },
  {
    "text": "In a previous video in our channel,",
    "start": "54190",
    "end": "55775"
  },
  {
    "text": "we talked about how overfitting and underfitting",
    "start": "55776",
    "end": "58248"
  },
  {
    "text": "can affect machine learning models.",
    "start": "58248",
    "end": "59920"
  },
  {
    "text": "But let's dive deeper into the root cause of the problem,",
    "start": "60310",
    "end": "62656"
  },
  {
    "text": "which is bias and variance.",
    "start": "62656",
    "end": "64569"
  },
  {
    "start": "65000",
    "end": "146000"
  },
  {
    "text": "So what do those terms mean?",
    "start": "65830",
    "end": "67719"
  },
  {
    "text": "Bias and variance are two types of error",
    "start": "68530",
    "end": "71278"
  },
  {
    "text": "that can lead to underfitting or overfitting",
    "start": "71278",
    "end": "73856"
  },
  {
    "text": "in machine learning models.",
    "start": "73856",
    "end": "75099"
  },
  {
    "text": "Let's talk about bias first.",
    "start": "75670",
    "end": "77259"
  },
  {
    "text": "Bias can be defined as the difference between the predicted values",
    "start": "77860",
    "end": "82562"
  },
  {
    "text": "and the actual values, also known as the ground truth.",
    "start": "82562",
    "end": "86409"
  },
  {
    "text": "When the bias is high,",
    "start": "87250",
    "end": "89015"
  },
  {
    "text": "the model fails to recognize patterns in the data",
    "start": "89015",
    "end": "91905"
  },
  {
    "text": "and it starts to oversimplify the data.",
    "start": "91905",
    "end": "94239"
  },
  {
    "text": "When the data is oversimplified so much",
    "start": "96200",
    "end": "98697"
  },
  {
    "text": "that it's not able to recognize patterns or complexities at all,",
    "start": "98697",
    "end": "102513"
  },
  {
    "text": "we can call that underfitting.",
    "start": "102513",
    "end": "104180"
  },
  {
    "text": "Let's talk about variants next.",
    "start": "106390",
    "end": "108069"
  },
  {
    "text": "Variance can be defined",
    "start": "109520",
    "end": "111195"
  },
  {
    "text": "as the variability in predictions for each value in the data set.",
    "start": "111195",
    "end": "114590"
  },
  {
    "text": "When the variance is high,",
    "start": "116310",
    "end": "118013"
  },
  {
    "text": "the model basically memorizes all of the points",
    "start": "118013",
    "end": "120939"
  },
  {
    "text": "in the training data set,",
    "start": "120939",
    "end": "122315"
  },
  {
    "text": "instead of memorizing the overall complexity",
    "start": "122315",
    "end": "125272"
  },
  {
    "text": "and patterns behind the data.",
    "start": "125272",
    "end": "127310"
  },
  {
    "text": "When this happens, we call that overfitting.",
    "start": "128039",
    "end": "131346"
  },
  {
    "text": "In short, a model with high bias",
    "start": "132640",
    "end": "135930"
  },
  {
    "text": "and low variance will tend to underfit.",
    "start": "135930",
    "end": "138980"
  },
  {
    "text": "And on the other hand,",
    "start": "139540",
    "end": "140918"
  },
  {
    "text": "a model with high variance and low bias will tend to overfit.",
    "start": "140918",
    "end": "145149"
  },
  {
    "start": "146000",
    "end": "280000"
  },
  {
    "text": "We don't want our graph to look like either one of these graphs.",
    "start": "146130",
    "end": "149520"
  },
  {
    "text": "Ideally, we want a model that has both low bias and low variance.",
    "start": "150090",
    "end": "154883"
  },
  {
    "text": "In other words, we want a model that is able to recognize",
    "start": "155400",
    "end": "159228"
  },
  {
    "text": "complexities and patterns in the training data,",
    "start": "159229",
    "end": "162020"
  },
  {
    "text": "but also on data that it hasn't seen before.",
    "start": "162020",
    "end": "164773"
  },
  {
    "text": "This is known as the bias variance trade off.",
    "start": "165170",
    "end": "168424"
  },
  {
    "text": "All right, let's take a closer look at a graph that you may have seen before",
    "start": "169240",
    "end": "173947"
  },
  {
    "text": "that illustrates the bias variance trade off.",
    "start": "173947",
    "end": "176919"
  },
  {
    "text": "This is a graph that shows",
    "start": "179730",
    "end": "181868"
  },
  {
    "text": "how the total amount of error changes",
    "start": "181868",
    "end": "184601"
  },
  {
    "text": "as model complexity increases.",
    "start": "184602",
    "end": "187560"
  },
  {
    "text": "We can think of model complexity",
    "start": "189750",
    "end": "191707"
  },
  {
    "text": "as a way to measure how well a model is able to recognize",
    "start": "191707",
    "end": "196070"
  },
  {
    "text": "relationships and patterns in data.",
    "start": "196070",
    "end": "198270"
  },
  {
    "text": "We notice that as the model complexity increases,",
    "start": "201520",
    "end": "205522"
  },
  {
    "text": "the total amount bias decreases.",
    "start": "205522",
    "end": "208690"
  },
  {
    "text": "We also notice that as the model complexity increases,",
    "start": "210170",
    "end": "214153"
  },
  {
    "text": "that the amount of variance increases.",
    "start": "214154",
    "end": "217940"
  },
  {
    "text": "And as the variance and bias change,",
    "start": "222150",
    "end": "225062"
  },
  {
    "text": "the total amount of error also changes.",
    "start": "225062",
    "end": "227939"
  },
  {
    "text": "So our overall goal",
    "start": "232850",
    "end": "235215"
  },
  {
    "text": "is to minimize both the variance and bias",
    "start": "235215",
    "end": "238496"
  },
  {
    "text": "such that we can get the lowest amount of error,",
    "start": "238496",
    "end": "241930"
  },
  {
    "text": "and that will usually be in this sweet spot right here.",
    "start": "241930",
    "end": "245299"
  },
  {
    "text": "This is our ideal complexity.",
    "start": "246420",
    "end": "248760"
  },
  {
    "text": "So, in short, the best way to fix and prevent",
    "start": "254010",
    "end": "258087"
  },
  {
    "text": "overfitting and underfitting is to find the ideal complexity in the model",
    "start": "258087",
    "end": "263071"
  },
  {
    "text": "that allows you to reduce both variance and bias,",
    "start": "263071",
    "end": "266504"
  },
  {
    "text": "while also reducing the total amount of error.",
    "start": "266504",
    "end": "268860"
  },
  {
    "text": "Thanks for watching",
    "start": "270460",
    "end": "271488"
  },
  {
    "text": "and as always, please remember to like and subscribe.",
    "start": "271488",
    "end": "274511"
  }
]
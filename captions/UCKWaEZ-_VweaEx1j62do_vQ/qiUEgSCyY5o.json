[
  {
    "text": "If I input myself into an autoencoder...",
    "start": "1010",
    "end": "5186"
  },
  {
    "text": "it could create a pretty good,",
    "start": "6858",
    "end": "9436"
  },
  {
    "text": "although not perfect, reconstruction of me.",
    "start": "9436",
    "end": "14042"
  },
  {
    "text": "Why don't I...",
    "start": "14042",
    "end": "15670"
  },
  {
    "text": "well, I mean you, explain?",
    "start": "15670",
    "end": "17707"
  },
  {
    "text": "Sure.",
    "start": "17950",
    "end": "18370"
  },
  {
    "text": "So, look, autoencoders are an unsupervised neural network,",
    "start": "18370",
    "end": "22148"
  },
  {
    "text": "and they consist of two parts.",
    "start": "22148",
    "end": "24429"
  },
  {
    "text": "Let's take a look.",
    "start": "24700",
    "end": "25480"
  },
  {
    "text": "There is, first of all, an encoder.",
    "start": "25780",
    "end": "28081"
  },
  {
    "text": "That's the first layer.",
    "start": "30050",
    "end": "32561"
  },
  {
    "text": "And that takes in some input.",
    "start": "32561",
    "end": "35628"
  },
  {
    "text": "And learns how to efficiently compress and encode that data",
    "start": "37540",
    "end": "42964"
  },
  {
    "text": "into something that we call the \"code\".",
    "start": "42964",
    "end": "46890"
  },
  {
    "text": "Then we have a decoder that learns how to reconstruct that encoded data representation.",
    "start": "49720",
    "end": "56063"
  },
  {
    "text": "So, decoder..",
    "start": "56063",
    "end": "58200"
  },
  {
    "text": "and that creates output.",
    "start": "59580",
    "end": "63813"
  },
  {
    "text": "And that output is as similar to the original input data as possible.",
    "start": "63813",
    "end": "69330"
  },
  {
    "text": "Effectively, an autoencoder learns to recognize which aspects of observable data are relevant,",
    "start": "69780",
    "end": "75409"
  },
  {
    "text": "and limit noise in data that can be discarded.",
    "start": "75409",
    "end": "78209"
  },
  {
    "text": "Separate the signal from the noise.",
    "start": "78690",
    "end": "80970"
  },
  {
    "text": "OK, great.",
    "start": "82080",
    "end": "82739"
  },
  {
    "text": "So is this all about creating smaller file sizes like the way I'll zip up some documents or compress a video?",
    "start": "82750",
    "end": "90110"
  },
  {
    "text": "No, not at all.",
    "start": "90180",
    "end": "91276"
  },
  {
    "text": "So let's talk about some examples.",
    "start": "91740",
    "end": "94438"
  },
  {
    "text": "Convolutional autoencoders have a variety of use cases related to images.",
    "start": "95160",
    "end": "100110"
  },
  {
    "text": "So, for example, I can draw an image like this number three.",
    "start": "100440",
    "end": "104219"
  },
  {
    "text": "And then through a process called feature extraction,",
    "start": "105760",
    "end": "109613"
  },
  {
    "text": "I can derive the required features of the image by removing noise;",
    "start": "109613",
    "end": "115021"
  },
  {
    "text": "something that looks a bit more like this.",
    "start": "115022",
    "end": "118728"
  },
  {
    "text": "And then I'm able to generate an output that approximates the original.",
    "start": "120570",
    "end": "125279"
  },
  {
    "text": "It's not exactly the same.",
    "start": "126280",
    "end": "128364"
  },
  {
    "text": "But it's pretty close.",
    "start": "129620",
    "end": "130817"
  },
  {
    "text": "Now I can use this part, called the code,",
    "start": "132380",
    "end": "134868"
  },
  {
    "text": "to do other things like create a higher resolution version of the output image,",
    "start": "134868",
    "end": "139805"
  },
  {
    "text": "or I can colorized an image, so black and white input -- full color output.",
    "start": "139805",
    "end": "144265"
  },
  {
    "text": "Now, in this case, the input and the output, they look much the same,",
    "start": "144559",
    "end": "148944"
  },
  {
    "text": "which, well, that's what autoencoders are all about, but they don't have to be.",
    "start": "148944",
    "end": "153941"
  },
  {
    "text": "We can provide input to an autoencoder in a corrupted form, like the noisy image of a three.",
    "start": "154340",
    "end": "161748"
  },
  {
    "text": "And then train a de-noising autoencoder to reconstruct our original image from the noisy version of it.",
    "start": "161815",
    "end": "169270"
  },
  {
    "text": "Once we've trained our autoencoder to remove noise from a representation of a number,",
    "start": "169730",
    "end": "174500"
  },
  {
    "text": "or a picture, or park bench,",
    "start": "174501",
    "end": "177616"
  },
  {
    "text": "we can apply that to all sorts of objects within an object element that displayed the same noise pattern.",
    "start": "177616",
    "end": "183800"
  },
  {
    "text": "So let's take a closer look inside an autoencoder.",
    "start": "184700",
    "end": "188122"
  },
  {
    "text": "The encoder itself compresses the input into a latent space representation.",
    "start": "188540",
    "end": "194607"
  },
  {
    "text": "So, we have multiple layers here that represent the encoder.",
    "start": "194607",
    "end": "203527"
  },
  {
    "text": "Each one a little smaller than the other, so this part here, that's the encoder.",
    "start": "203527",
    "end": "209454"
  },
  {
    "text": "The most compressed version, that's called the code,",
    "start": "209454",
    "end": "213181"
  },
  {
    "text": "that's also known as the bottleneck,",
    "start": "213182",
    "end": "217204"
  },
  {
    "text": "because, I suppose, much like the neck of a bottle, that's the most compressed part.",
    "start": "217204",
    "end": "221670"
  },
  {
    "text": "Then we have the decoder, which is reconstructed from that bottleneck.",
    "start": "222130",
    "end": "231235"
  },
  {
    "text": "That's the decoder.",
    "start": "231450",
    "end": "232886"
  },
  {
    "text": "And it's reconstructed from the latent space representation to generate the output.",
    "start": "233113",
    "end": "237798"
  },
  {
    "text": "By learning what makes up the signal and what makes up the noise,",
    "start": "238039",
    "end": "241568"
  },
  {
    "text": "we also have the ability to detect when something is not part of the status quo,",
    "start": "241568",
    "end": "246049"
  },
  {
    "text": "and that's anomaly detection.",
    "start": "246049",
    "end": "248286"
  },
  {
    "text": "Anomalies are a significant deviation from the general behavior of the data,",
    "start": "248487",
    "end": "253224"
  },
  {
    "text": "and autoencoders are a very good at telling us when something doesn't fit.",
    "start": "253224",
    "end": "257620"
  },
  {
    "text": "As a result, autoencoders are a widely used in anomaly detection in things such as",
    "start": "257776",
    "end": "262913"
  },
  {
    "text": "fault, fraud, and intrusion detection.",
    "start": "262913",
    "end": "266251"
  },
  {
    "text": "So autoencoders are a great way of extracting noise, recognizing relevant features, and detecting anomalies.",
    "start": "266750",
    "end": "274339"
  },
  {
    "text": "A pretty handy toolbox for dealing with all sorts of data...",
    "start": "274700",
    "end": "278949"
  },
  {
    "text": "and eerily similar clones.",
    "start": "278949",
    "end": "283160"
  },
  {
    "text": "If you have any questions, please drop us a line below,",
    "start": "285760",
    "end": "288431"
  },
  {
    "text": "and if you want to see more videos like this in the future,",
    "start": "288431",
    "end": "291420"
  },
  {
    "text": "please like and subscribe.",
    "start": "291420",
    "end": "293019"
  },
  {
    "text": "Thanks for watching.",
    "start": "293560",
    "end": "294747"
  }
]
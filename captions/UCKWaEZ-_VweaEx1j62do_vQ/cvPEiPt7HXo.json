[
  {
    "start": "0",
    "end": "67000"
  },
  {
    "text": "If you're watching this video and I'm pretty sure you are. Well, I'm going to hazard a guess  ",
    "start": "360",
    "end": "4840"
  },
  {
    "text": "and say that you've at least interacted with a large language model or an LLM.",
    "start": "4840",
    "end": "11080"
  },
  {
    "text": "LLMs can quickly answer natural language questions,",
    "start": "11080",
    "end": "15444"
  },
  {
    "text": "provide summarization and follow complex instructions.",
    "start": "15444",
    "end": "18640"
  },
  {
    "text": "But have you thought about the operational side of these models?",
    "start": "18720",
    "end": "22512"
  },
  {
    "text": "LLMs need deployment, monitoring and maintenance just like anything else.",
    "start": "22512",
    "end": "27084"
  },
  {
    "text": "And that's what LLMOps addresses.",
    "start": "27084",
    "end": "31871"
  },
  {
    "text": "Large language model operations.",
    "start": "32005",
    "end": "35183"
  },
  {
    "text": "It's a collaboration of data scientists, DevOps engineers, and IT professionals",
    "start": "35504",
    "end": "41441"
  },
  {
    "text": "in an environment for data exploration, prompt engineering, and pipeline management.",
    "start": "41441",
    "end": "46071"
  },
  {
    "text": "LLMOps automates the operational and monitoring tasks in the machine learning lifecycle.",
    "start": "46178",
    "end": "52911"
  },
  {
    "text": "Ah, yes, machine learning",
    "start": "53099",
    "end": "55647"
  },
  {
    "text": "because LLMOps falls within the scope of machine learning operations,",
    "start": "55647",
    "end": "59498"
  },
  {
    "text": "it might be tempting to think of LLMs as just another model for something called MLOps.",
    "start": "59498",
    "end": "67060"
  },
  {
    "start": "67000",
    "end": "134000"
  },
  {
    "text": " Now, if you're not familiar, MLOps is about streamlining the process  ",
    "start": "67693",
    "end": "71200"
  },
  {
    "text": "of taking machine learning models in production",
    "start": "71200",
    "end": "73944"
  },
  {
    "text": "and then maintaining and monitoring them.",
    "start": "73944",
    "end": "76296"
  },
  {
    "text": "So the difference here is that LLMOps addresses the specifics of LLM machine learning models,  ",
    "start": "76430",
    "end": "83120"
  },
  {
    "text": "but traditional MLOps does not.",
    "start": "83120",
    "end": "86659"
  },
  {
    "text": "Now an MLOps lifecycle might look a bit like this.",
    "start": "86806",
    "end": "91165"
  },
  {
    "text": "So we have exploratory data analysis and some development here as one stage.",
    "start": "91245",
    "end": "97749"
  },
  {
    "text": "Then beneath that we have a couple of CICD pipelines.",
    "start": "98204",
    "end": "104561"
  },
  {
    "text": "What's that? That's continuous integration and continuous delivery.",
    "start": "104681",
    "end": "109114"
  },
  {
    "text": "And in fact, we would probably have one here for deployment",
    "start": "109240",
    "end": "113580"
  },
  {
    "text": "and we would have another one over here for actually training our model,",
    "start": "113580",
    "end": "120359"
  },
  {
    "text": "So training CICD here, and then finally, this all filters into one last stage,",
    "start": "121014",
    "end": "127882"
  },
  {
    "text": "which is effectively the monitor stage, for monitoring the model.",
    "start": "127975",
    "end": "133881"
  },
  {
    "start": "134000",
    "end": "414000"
  },
  {
    "text": "But LLMs, they introduce additional requirements over other ML models.",
    "start": "135000",
    "end": "140464"
  },
  {
    "text": "So, for example, let's consider transfer learning",
    "start": "140464",
    "end": "145757"
  },
  {
    "text": "and many traditional ML models are created and trained from scratch.",
    "start": "145757",
    "end": "149729"
  },
  {
    "text": "But that's typically not the case with most LLMs.",
    "start": "149840",
    "end": "152502"
  },
  {
    "text": "Building new elements from scratch,",
    "start": "152503",
    "end": "155218"
  },
  {
    "text": "well, that would be a very expensive operation.",
    "start": "155218",
    "end": "158684"
  },
  {
    "text": "Many LLMs actually start from an existing foundation model,",
    "start": "158845",
    "end": "162950"
  },
  {
    "text": "and that model is then fine tuned with new data to improve model performance in a given domain.",
    "start": "162950",
    "end": "168333"
  },
  {
    "text": "Or consider hyperparameter tuning.",
    "start": "168734",
    "end": "172801"
  },
  {
    "text": "In ML hyperparameter tuning often focuses on improving metrics like accuracy.",
    "start": "172896",
    "end": "178163"
  },
  {
    "text": "For LLMs, tuning also becomes important for reducing the cost",
    "start": "178163",
    "end": "181788"
  },
  {
    "text": "and computational power requirements of training an inference.",
    "start": "181788",
    "end": "186000"
  },
  {
    "text": "Another difference that is performance metrics.",
    "start": "186136",
    "end": "191092"
  },
  {
    "text": "Now ML models most often have clearly defined and easy to calculate",
    "start": "191199",
    "end": "195556"
  },
  {
    "text": "performance metrics like accuracy (AUC).",
    "start": "195556",
    "end": "198585"
  },
  {
    "text": "That's area on the curve and an F1 score.",
    "start": "198585",
    "end": "201541"
  },
  {
    "text": "But when evaluating LMS, a different set of standard benchmarks and scoring unneeded.",
    "start": "201541",
    "end": "207022"
  },
  {
    "text": "Bilingual Evaluations Understudy (BLEU)",
    "start": "207022",
    "end": "210373"
  },
  {
    "text": "and Recall-Oriented Understudy for Gisting Evaluation, I think that's right, for ROGUE.",
    "start": "210373",
    "end": "216666"
  },
  {
    "text": "These are all things that require additional consideration during implementation.",
    "start": "216800",
    "end": "221721"
  },
  {
    "text": "So the components of LLMOps look something like this.",
    "start": "222336",
    "end": "227788"
  },
  {
    "text": "So at the top here, we have EDA, or exploratory data analysis,",
    "start": "227788",
    "end": "233692"
  },
  {
    "text": "to iteratively explore and share data for use in the LLM model.",
    "start": "233692",
    "end": "238941"
  },
  {
    "text": "That moves us into data prep that transforms, aggregates and duplicates data.",
    "start": "239449",
    "end": "247897"
  },
  {
    "text": "We have prompt engineering that's used to develop prompts for structured, reliable queries to LLMs.",
    "start": "248526",
    "end": "256407"
  },
  {
    "text": "Now, as we've discussed, it's likely that this model will actually be fine tuned",
    "start": "256782",
    "end": "262957"
  },
  {
    "text": "to improve its performance to the domain where it's operating.",
    "start": "262957",
    "end": "267291"
  },
  {
    "text": "There's also a model review and governance process to track the model",
    "start": "267532",
    "end": "275399"
  },
  {
    "text": "and pipeline versions and then manage that complete lifecycle.",
    "start": "275399",
    "end": "279367"
  },
  {
    "text": "There is model inference and serving",
    "start": "279930",
    "end": "284934"
  },
  {
    "text": "and that can manage the production specifics of testing and QA",
    "start": "284934",
    "end": "288647"
  },
  {
    "text": "such as frequency of model refresh and inference request times.",
    "start": "288647",
    "end": "293247"
  },
  {
    "text": "And finally, an LLMOps lifecycle is likely to include a stage for model monitoring. ",
    "start": "293327",
    "end": "301052"
  },
  {
    "text": "That includes human feedback to your LLM applications.",
    "start": "301119",
    "end": "304707"
  },
  {
    "text": "This stage can identify potential malicious attacks,",
    "start": "304708",
    "end": "307768"
  },
  {
    "text": "model drift and potential areas for improvement.",
    "start": "307768",
    "end": "310938"
  },
  {
    "text": "Ultimately, LLM development consists of many components,",
    "start": "311527",
    "end": "314506"
  },
  {
    "text": "and some of these components are specific to LLMS, not other machine learning models.",
    "start": "314506",
    "end": "319480"
  },
  {
    "text": "And those developed LLM models need to be deployed and they need to be monitored.",
    "start": "319480",
    "end": "324080"
  },
  {
    "text": "And all of this requires collaboration and hand-offs across various teams.",
    "start": "324080",
    "end": "328789"
  },
  {
    "text": "An LLMOps platform like this can streamline this, where data scientists",
    "start": "329016",
    "end": "334246"
  },
  {
    "text": "and machine learning engineers, and DevOps, and stakeholders,",
    "start": "334246",
    "end": "337625"
  },
  {
    "text": "are able to collaborate more quickly on a unified platform.",
    "start": "337625",
    "end": "341380"
  },
  {
    "text": "In essence, LLMOps improves things like efficiency throughout the entire lifecycle.",
    "start": "341594",
    "end": "351184"
  },
  {
    "text": "And then when it comes to risk, we can reduce the risk",
    "start": "351358",
    "end": "357343"
  },
  {
    "text": "through improved security and privacy by using advanced, enterprise grade LLMOps",
    "start": "357410",
    "end": "362350"
  },
  {
    "text": "to prioritize the protection of sensitive information.",
    "start": "362350",
    "end": "365238"
  },
  {
    "text": "And LLMOps enable easier scalability.",
    "start": "365358",
    "end": "370277"
  },
  {
    "text": "And that's through the management of the data,",
    "start": "371494",
    "end": "375142"
  },
  {
    "text": "which is important when we're talking about multiple models that need to be overseen,",
    "start": "375142",
    "end": "379652"
  },
  {
    "text": "controlled and monitored for continuous integration, delivery and deployment.",
    "start": "379652",
    "end": "385103"
  },
  {
    "text": "So that's LLMops in a nutshell.",
    "start": "385558",
    "end": "388260"
  },
  {
    "text": "It's a set of practices, techniques, and tools",
    "start": "388260",
    "end": "390921"
  },
  {
    "text": "used for the operational management of large language models in production environments.",
    "start": "390921",
    "end": "395500"
  },
  {
    "text": "And, unlike the broader MLOps, it addresses the unique approach",
    "start": "395568",
    "end": "399936"
  },
  {
    "text": "that's required to train and deploy LLMs.",
    "start": "399937",
    "end": "403654"
  },
  {
    "text": "If you have any questions, please drop us a line below.",
    "start": "404577",
    "end": "407335"
  },
  {
    "text": "And if you want to see more videos like this in the future,",
    "start": "407335",
    "end": "410370"
  },
  {
    "text": "please like and subscribe. Thanks for watching.",
    "start": "410370",
    "end": "413958"
  }
]
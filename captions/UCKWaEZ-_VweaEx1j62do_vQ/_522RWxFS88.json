[
  {
    "text": "So when we're talking about trust for AI we \nhear about these five pillars, right. Awareness,  ",
    "start": "320",
    "end": "5440"
  },
  {
    "text": "robustness, privacy, explainability, and \ntransparency. So, what is all of this?  ",
    "start": "5440",
    "end": "10480"
  },
  {
    "text": "You're right Aishwarya. There are you know, \nat this point in time we usually talk about  ",
    "start": "11680",
    "end": "16000"
  },
  {
    "text": "five different pillars, but keep in mind that \nthis is a fast evolving space. This field is  ",
    "start": "16000",
    "end": "22720"
  },
  {
    "text": "changing rapidly. But at this point we \nusually talk about fairness, robustness,  ",
    "start": "23440",
    "end": "29840"
  },
  {
    "text": "privacy, explainability, and transparency. Let's \nmaybe talk about each of them quickly. Fairness  ",
    "start": "29840",
    "end": "36320"
  },
  {
    "text": "is probably obvious it is to make sure that the \nmodels are not behaving in a biased way. Now it  ",
    "start": "36320",
    "end": "44400"
  },
  {
    "text": "may actually start, the challenges may start way \nbefore a model is built. It might be understanding  ",
    "start": "44400",
    "end": "49360"
  },
  {
    "text": "if the data itself is biased. If it is how do you \ndeal with that? When you build a model how do you  ",
    "start": "49360",
    "end": "56240"
  },
  {
    "text": "make sure that the model is not systematically \ngiving an advantage or a disadvantage to a  ",
    "start": "56240",
    "end": "63600"
  },
  {
    "text": "certain group. And the definition of the \ngroup varies by industry, by use case,  ",
    "start": "63600",
    "end": "68560"
  },
  {
    "text": "it could be based on sensitive attributes like \nage and gender and ethnicity, but may not be  ",
    "start": "69200",
    "end": "75039"
  },
  {
    "text": "limited to any of those. You want to make sure \nthat the system is not consistently favoring one  ",
    "start": "75040",
    "end": "83360"
  },
  {
    "text": "over the other in an unfair way. Robustness, you \nwant to make sure that your models behave well  ",
    "start": "83360",
    "end": "91520"
  },
  {
    "text": "in exceptional conditions. How do you make sure \nthat the model performance is good over time?  ",
    "start": "94240",
    "end": "100399"
  },
  {
    "text": "What is happening with the effective data drift? \nOr for example, in the context of the of the  ",
    "start": "101360",
    "end": "109600"
  },
  {
    "text": "pandemic, we know that customer behavior has \nchanged you know customer patterns have changed,  ",
    "start": "109600",
    "end": "116479"
  },
  {
    "text": "customer touch points have changed. Is your \nmodel still behaving as expected, or if it is not  ",
    "start": "116480",
    "end": "123280"
  },
  {
    "text": "can you at least have an understanding \nof how the model behavior is changing,  ",
    "start": "124000",
    "end": "129280"
  },
  {
    "text": "how data is drifting, how accuracy is drifting, \netc. Privacy, can you make sure that the model,  ",
    "start": "129280",
    "end": "135840"
  },
  {
    "text": "the data, the model that is built off of \nthat model, the insights from that model,  ",
    "start": "135840",
    "end": "140160"
  },
  {
    "text": "they are all that the the model builder \nowns and retains control of those insights.  ",
    "start": "140720",
    "end": "147440"
  },
  {
    "text": "And how do you do this not just as in terms \nof consumption of the output of the model,  ",
    "start": "148160",
    "end": "152960"
  },
  {
    "text": "but across the life cycle. How do you make \nsure that data protection rules are in place  ",
    "start": "152960",
    "end": "159120"
  },
  {
    "text": "through the model building testing validation \nand monitoring stages. Explainability is probably  ",
    "start": "159120",
    "end": "166400"
  },
  {
    "text": "pretty obvious. How can you explain the behavior \nof a model. Why was someone approved for a loan,  ",
    "start": "166400",
    "end": "172159"
  },
  {
    "text": "why was someone rejected. When somebody applied \nfor a job and that person was selected but someone  ",
    "start": "172160",
    "end": "181280"
  },
  {
    "text": "with very similar qualifications applied that \nperson was rejected, can you explain the behavior  ",
    "start": "181280",
    "end": "186800"
  },
  {
    "text": "to the end user or to a decision maker. \nTransparency, you want to be able to inspect  ",
    "start": "187440",
    "end": "194320"
  },
  {
    "text": "everything about a model. Can you understand \nall the facts surrounding the model. Who  ",
    "start": "194320",
    "end": "199360"
  },
  {
    "text": "built it, what data is being used, what \nalgorithms, what packages are being used,  ",
    "start": "199360",
    "end": "205200"
  },
  {
    "text": "who approved it, who validated it. All of these \naspects of the model, facts about the model,  ",
    "start": "206240",
    "end": "213760"
  },
  {
    "text": "should be easily available. Just like you know, \nyou have you buy a food product and there is a,  ",
    "start": "213760",
    "end": "219680"
  },
  {
    "text": "there's a label on it, you know, it has the \nnutritional facts, when was it manufactured,  ",
    "start": "219680",
    "end": "224319"
  },
  {
    "text": "where was it manufactured, all of that. Just \nlike that for a model, you should be able to  ",
    "start": "224320",
    "end": "228960"
  },
  {
    "text": "get the facts of that model very quickly. So \nthese I would say are sort of the fundamental  ",
    "start": "228960",
    "end": "233680"
  },
  {
    "text": "pillars of Trustworthy AI. The challenge is \nmaking sure these can be done in a systematic  ",
    "start": "233680",
    "end": "240879"
  },
  {
    "text": "way regardless of what tools are used to build \nthe models and where the models are deployed.  ",
    "start": "241680",
    "end": "246560"
  },
  {
    "text": "So John, in the recent past, we have seen that \nas AI systems were new to a lot of organizations,  ",
    "start": "247200",
    "end": "253520"
  },
  {
    "text": "organizations have very recently adopted such \nlarge-scale AI applications or systems in  ",
    "start": "253520",
    "end": "259120"
  },
  {
    "text": "their workflow. And that's where we started \nseeing these side effects of AI, right. And  ",
    "start": "259120",
    "end": "264479"
  },
  {
    "text": "that's where we pinpointed that, hey, like these \nwere some of the aspects which we need to target  ",
    "start": "264480",
    "end": "269040"
  },
  {
    "text": "to make sure that AI doesn't have an ill effect on \nthe community, or doesn't have an ill effect on it  ",
    "start": "269600",
    "end": "275360"
  },
  {
    "text": "on an entire perspective. So when we see that \norganizations are facing such challenges,  ",
    "start": "275360",
    "end": "281759"
  },
  {
    "text": "when they are seeing such like roadblocks \nwith respect to building trust for the AI,  ",
    "start": "281760",
    "end": "286960"
  },
  {
    "text": "what is the recommended methodology on making sure \nthat building such AI systems, or like building  ",
    "start": "286960",
    "end": "292639"
  },
  {
    "text": "such trusted AI systems is easily done throughout \ndifferent business units of the organization and  ",
    "start": "292640",
    "end": "298800"
  },
  {
    "text": "doesn't surely, you know, it doesn't really \nstreamline to just one particular department  ",
    "start": "298800",
    "end": "304319"
  },
  {
    "text": "or team. How can we make it a big thing and how \ncan an entire organization productionalize this  ",
    "start": "304320",
    "end": "310240"
  },
  {
    "text": "streamlined work? So Aishwarya, you know, you're \ntalking about expanding this across our company,  ",
    "start": "310240",
    "end": "316960"
  },
  {
    "text": "sort of setting up this governance framework and \nthat was one of the patterns we talked about. Many  ",
    "start": "316960",
    "end": "322400"
  },
  {
    "text": "companies may not start there, but they may start \nwith one of the other patterns we talked about,  ",
    "start": "322400",
    "end": "326479"
  },
  {
    "text": "which is let's start with assessment or building \nout a new use case, a new application that follows  ",
    "start": "326480",
    "end": "333600"
  },
  {
    "text": "Trustworthy AI principles, but yeah some companies \nmay want to look at a top-down approach and  ",
    "start": "333600",
    "end": "339840"
  },
  {
    "text": "and set up the governance framework taking \ninto account that there are multiple streams of  ",
    "start": "339840",
    "end": "345760"
  },
  {
    "text": "data science and AI activities going \non concurrently. But in all of these,  ",
    "start": "346720",
    "end": "351280"
  },
  {
    "text": "you know, regardless of which approach you take, \nI think three elements need to come together.  ",
    "start": "351280",
    "end": "355520"
  },
  {
    "text": "And I would say these these are \nthese three elements are technology,  ",
    "start": "357360",
    "end": "360479"
  },
  {
    "text": "people, and process. Technology is probably \nobvious, we need to have guardrails across  ",
    "start": "361040",
    "end": "368080"
  },
  {
    "text": "each of the stages of the life cycle. \nWhen you're working with data, how do you  ",
    "start": "368080",
    "end": "372240"
  },
  {
    "text": "check for bias in the data, how do you correct \nthat. That's a guardrail at the data exploration  ",
    "start": "373040",
    "end": "379120"
  },
  {
    "text": "time. When you're building the model you \nneed a guardrail in place for model building  ",
    "start": "379120",
    "end": "385360"
  },
  {
    "text": "for checking the robustness of the model, for \nproviding an explanation in development time.  ",
    "start": "385360",
    "end": "391120"
  },
  {
    "text": "You need a guardrail which will allow you to go \ninto valid, through validation into deployment,  ",
    "start": "392400",
    "end": "398880"
  },
  {
    "text": "and you need an outermost guard where \nyou think of it as a one-time guardrail  ",
    "start": "398880",
    "end": "402400"
  },
  {
    "text": "which can continue to do monitoring of your model \nand look at how it is behaving against thresholds,  ",
    "start": "403520",
    "end": "410720"
  },
  {
    "text": "whether the thresholds are being breached, etc. \nNow, so technology provides these guardrails  ",
    "start": "410720",
    "end": "417120"
  },
  {
    "text": "for all of the different five pillars that we \ntalk about. Now technology in itself is not  ",
    "start": "417120",
    "end": "422160"
  },
  {
    "text": "sufficient that's why I was mentioning people and \nprocess. People because you need a set of skills  ",
    "start": "422160",
    "end": "428320"
  },
  {
    "text": "to come together. It is not just data science \nskills. The MLOps paradigm requires you to have  ",
    "start": "428320",
    "end": "435360"
  },
  {
    "text": "the operational skills come together with data \nscience skills. You might have risk and compliance  ",
    "start": "435360",
    "end": "442159"
  },
  {
    "text": "expertise coming into the picture. You might have \nbusiness analysts and business stakeholders coming  ",
    "start": "442160",
    "end": "448800"
  },
  {
    "text": "into the picture, and so on. So the right level \nof expertise, personas who are collaborating to  ",
    "start": "448800",
    "end": "455599"
  },
  {
    "text": "achieve this common goal is important. And then \nfinally, process. In a process, that term process,  ",
    "start": "455600",
    "end": "461600"
  },
  {
    "text": "you know, people may not always like that, but \nthe reality is you need a set of best practices  ",
    "start": "462960",
    "end": "468400"
  },
  {
    "text": "for each stage of the life cycle. Whether it \nis coping and building, or it is validation  ",
    "start": "468400",
    "end": "474160"
  },
  {
    "text": "or deployment or monitoring over time, you need \na set of best practices. So technology, people,  ",
    "start": "474160",
    "end": "482560"
  },
  {
    "text": "best practices coming together make it possible \nto loot Trustworthy AI at scale and operationalize  ",
    "start": "483360",
    "end": "491039"
  },
  {
    "text": "it. Great, thank you so much John, like \nit was very insightful for me because to  ",
    "start": "491040",
    "end": "497360"
  },
  {
    "text": "understand kind of the AI systems we build, from \nunderstanding it from a data science perspective,  ",
    "start": "497360",
    "end": "502240"
  },
  {
    "text": "to how it can be productionized and run \nsuccessfully in these large organizations. It is  ",
    "start": "502240",
    "end": "508000"
  },
  {
    "text": "very important that organizations are responsible \nto the people who are using it, right. So it was,  ",
    "start": "508000",
    "end": "514159"
  },
  {
    "text": "it was really insightful that we got to learn so \nmany different things from you. In the meanwhile,  ",
    "start": "514160",
    "end": "518800"
  },
  {
    "text": "I feel like there's a lot of other resources \nwhich is available for us to dig deeper and  ",
    "start": "518800",
    "end": "523200"
  },
  {
    "text": "learn about fairness, robustness, transparency, \nprivacy, and explainability. So everyone who's  ",
    "start": "523200",
    "end": "528960"
  },
  {
    "text": "watching this you can find the right resources \nin the description below, and soon we'll be  ",
    "start": "528960",
    "end": "534160"
  },
  {
    "text": "posting more series of videos talking deeper \ninto each of these pillars. Thank you so much.",
    "start": "534160",
    "end": "543839"
  }
]
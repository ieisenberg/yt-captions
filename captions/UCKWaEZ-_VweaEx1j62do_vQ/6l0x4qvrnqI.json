[
  {
    "text": "Generative AI algorithms, they're rapidly learning new domains.",
    "start": "150",
    "end": "2990"
  },
  {
    "text": "But as they do so, the big question is, are they going to lose their minds?",
    "start": "3350",
    "end": "6469"
  },
  {
    "text": "Now, say for instance, I have a friend, Ravi.",
    "start": "7090",
    "end": "10109"
  },
  {
    "text": "He has a swim meet coming up and he wants to use a large language model to get hints on how to better his butterfly.",
    "start": "10390",
    "end": "15770"
  },
  {
    "text": "But perhaps these hints aren't the best.",
    "start": "16050",
    "end": "17849"
  },
  {
    "text": "And then I have another friend named Kevin who's working on a dog artwork.",
    "start": "18310",
    "end": "21630"
  },
  {
    "text": "And he wants a different style transferred into that piece.",
    "start": "21850",
    "end": "24570"
  },
  {
    "text": "And he wants to use a generative AI system to help him out.",
    "start": "24870",
    "end": "28010"
  },
  {
    "text": "Now both of these are really good ideas and use cases where we can use generative AI to help us out in our daily lives,",
    "start": "28430",
    "end": "34210"
  },
  {
    "text": "but we need to make sure as we do this that they don't lose their minds.",
    "start": "34710",
    "end": "38149"
  },
  {
    "text": "Well there's a lot of similarity between the human brain and large language models.",
    "start": "38630",
    "end": "42070"
  },
  {
    "text": "Now both of them, they have these neurons that are deeply connected together.",
    "start": "42470",
    "end": "47709"
  },
  {
    "text": "So in the brain, you have the prefrontal cortex and that's responsible for the different types of thinking that we have.",
    "start": "48150",
    "end": "53510"
  },
  {
    "text": "Now over in LLMs, Within feed-forward neural networks, you have these densely packed",
    "start": "53930",
    "end": "58144"
  },
  {
    "text": "regions that can propagate forward and infer an output.",
    "start": "58144",
    "end": "62070"
  },
  {
    "text": "Now, the other part is called memory.",
    "start": "62470",
    "end": "64609"
  },
  {
    "text": "So within the human brain, we have what's called the hippocampus.",
    "start": "65670",
    "end": "69470"
  },
  {
    "text": "This is where we store our memories and we have to retrieve information in order to respond to our environment.",
    "start": "69710",
    "end": "74750"
  },
  {
    "text": "Now, LLMs are kind of similar because they use what's called a vector database.",
    "start": "75330",
    "end": "79290"
  },
  {
    "text": "So we can write vectors into it and then pull it out.",
    "start": "79330",
    "end": "82189"
  },
  {
    "text": "Now the third aspect that are very similar between the two.",
    "start": "82774",
    "end": "85348"
  },
  {
    "text": "or is what we call specialized regions, right?",
    "start": "85470",
    "end": "89110"
  },
  {
    "text": "And we could think about this within the domain of generative AI as a mixture of experts.",
    "start": "89110",
    "end": "95969"
  },
  {
    "text": "Now within the brain, we can also look at the cerebellum,",
    "start": "96528",
    "end": "98902"
  },
  {
    "text": "a nd the cerebellum helps us with balance and movement and such,",
    "start": "99170",
    "end": "102756"
  },
  {
    "text": "but each of these specialized areas have a certain function that can help us out.",
    "start": "102756",
    "end": "107630"
  },
  {
    "text": "So I told you how they're all similar, but now, how is the brain different?",
    "start": "108170",
    "end": "112069"
  },
  {
    "text": "Okay, so some of the differences here.",
    "start": "112630",
    "end": "114409"
  },
  {
    "text": "is power, right?",
    "start": "114780",
    "end": "116979"
  },
  {
    "text": "So the human brain, it only needs 0.3 kilowatt hours of power.",
    "start": "117040",
    "end": "121819"
  },
  {
    "text": "Now an LLM, it needs thousands of kilowatt hours in particular to train it.",
    "start": "122380",
    "end": "127078"
  },
  {
    "text": "And now the other difference between the two is also volume.",
    "start": "127500",
    "end": "131180"
  },
  {
    "text": "Now the human brain takes up only 1200 cubic centimeters.",
    "start": "131740",
    "end": "135860"
  },
  {
    "text": "And then when I compare that just to the cables alone",
    "start": "136160",
    "end": "138994"
  },
  {
    "text": "to put these supercomputers and clusters that have GPUs together,",
    "start": "138994",
    "end": "142404"
  },
  {
    "text": "right, the generative AI part could have miles of cables.",
    "start": "142404",
    "end": "145340"
  },
  {
    "text": "Now the other biggest difference is the way in which each of them pass messages, right?",
    "start": "145920",
    "end": "150800"
  },
  {
    "text": "So there's a complex series of messages.",
    "start": "150820",
    "end": "154599"
  },
  {
    "text": "So one of them is chemical, the other is binary.",
    "start": "155060",
    "end": "157840"
  },
  {
    "text": "So within the brain, we have this complex stew of neurotransmitters that relay messages back and forth,",
    "start": "159000",
    "end": "164167"
  },
  {
    "text": "whereas in generative AI, we have encoded floating points that use ones in zeros to pass that said information back and forth.",
    "start": "164167",
    "end": "171159"
  },
  {
    "text": "Now, say my friend Kevin, he's learning how to draw the better dogs.",
    "start": "171950",
    "end": "175250"
  },
  {
    "text": "Well, we still need to take some of the similarities and the differences and train these LLMs to help him draw better dogs.",
    "start": "175770",
    "end": "182689"
  },
  {
    "text": "Okay, why don't we jump into it?",
    "start": "183610",
    "end": "184889"
  },
  {
    "text": "So at the foundational level, we can begin this phased training approach.",
    "start": "184910",
    "end": "189309"
  },
  {
    "text": "Now, this training approach is broken down into two different components.",
    "start": "189870",
    "end": "192890"
  },
  {
    "text": "The first one being unsupervised learning,",
    "start": "193110",
    "end": "195322"
  },
  {
    "text": "where you don't provide any labels at all, but the model learns how to represent the data.",
    "start": "195322",
    "end": "199773"
  },
  {
    "text": "And the second component of this is supervised learning.",
    "start": "199773",
    "end": "202680"
  },
  {
    "text": "This is where you do provide the answer,",
    "start": "202760",
    "end": "204724"
  },
  {
    "text": "and then it can back propagate the error in between the output and the answer so you change the gradients.",
    "start": "204724",
    "end": "210220"
  },
  {
    "text": "Now the second area that I wanted to mention is called chain of thought.",
    "start": "210700",
    "end": "214180"
  },
  {
    "text": "This is a step-by-step logical reasoning that can be used to even teach other models.",
    "start": "214520",
    "end": "219339"
  },
  {
    "text": "And this also provides transparency so that we can understand what's happening.",
    "start": "219540",
    "end": "223418"
  },
  {
    "text": "Now what you're seeing in the field that's beginning to emerge, it's called self-learning.",
    "start": "224220",
    "end": "228780"
  },
  {
    "text": "Now the self learning aspect,",
    "start": "229430",
    "end": "231344"
  },
  {
    "text": "this is where we can use a lot of these chain of thoughts and nest them together and have a mixture of experts learn them.",
    "start": "231344",
    "end": "237829"
  },
  {
    "text": "So they become experts in their own little area, right?",
    "start": "237850",
    "end": "241009"
  },
  {
    "text": "And what you can do is have each of those experts in the MoE vote,",
    "start": "241030",
    "end": "244389"
  },
  {
    "text": "and the more votes you have for a particular answer, that is going to be the right answer,",
    "start": "244890",
    "end": "249250"
  },
  {
    "text": "and that can be your quasi or meta ground truth that you then can send back right into the network so it learns.",
    "start": "249290",
    "end": "255489"
  },
  {
    "text": "Now this helps the models to branch off and learn even new skills, it can learn new capabilities,",
    "start": "255930",
    "end": "261616"
  },
  {
    "text": "and you'll even begin to see reinforcement learning that's being used within the field as well.",
    "start": "261616",
    "end": "266350"
  },
  {
    "text": "Now you might be thinking that some of these models are losing their mind.",
    "start": "266690",
    "end": "269270"
  },
  {
    "text": "Well, they're really not.",
    "start": "269730",
    "end": "271310"
  },
  {
    "text": "So as these models begin to teach themselves, we really need to be careful that they do produce good results.",
    "start": "271670",
    "end": "277069"
  },
  {
    "text": "Now, we try to use what's called a funnel of trust,",
    "start": "277660",
    "end": "280040"
  },
  {
    "text": "and we can use this funnel to help minimize the hallucinations or incorrect skills",
    "start": "280120",
    "end": "284186"
  },
  {
    "text": "that might be acquired through these three examples that I provided.",
    "start": "284186",
    "end": "287279"
  },
  {
    "text": "Now, one of these areas that I would like to highlight is called a large language model as a judge.",
    "start": "287780",
    "end": "294339"
  },
  {
    "text": "Now, this is where a model itself, it interprets the output of another model,",
    "start": "294760",
    "end": "298800"
  },
  {
    "text": "and if we want to follow what's called a condorcet jury theorem,",
    "start": "299060",
    "end": "301888"
  },
  {
    "text": "we can stack together lots of these judge models together to create a jury,",
    "start": "301888",
    "end": "306235"
  },
  {
    "text": "right, and say if all of these jury members are more than half likelihood to get it right",
    "start": "306235",
    "end": "312728"
  },
  {
    "text": "and you keep adding more and more and more, then your judge jury is gonna be more than likely correct as well.",
    "start": "312728",
    "end": "318669"
  },
  {
    "text": "Now the other area is called theory of mind.",
    "start": "319250",
    "end": "322410"
  },
  {
    "text": "And what we wanna do here is ensure that the output of these models,",
    "start": "323030",
    "end": "326023"
  },
  {
    "text": "they match your expectations so that the models understand,",
    "start": "326023",
    "end": "329380"
  },
  {
    "text": "wait a minute, my user or my agent that's trying to use me, they have their own expectations,",
    "start": "329380",
    "end": "335250"
  },
  {
    "text": "and so we want to be able to meet these agent mental models or user",
    "start": "335810",
    "end": "340344"
  },
  {
    "text": "mental models so that they begin to have an alignment of their output.",
    "start": "340344",
    "end": "344750"
  },
  {
    "text": "Now the other area is called machine unlearning.",
    "start": "345330",
    "end": "349009"
  },
  {
    "text": "With machine unlearning, we can begin to remove data in a systematic way.",
    "start": "349470",
    "end": "354769"
  },
  {
    "text": "So we can have this where we can create virtual lesions within a",
    "start": "355150",
    "end": "358234"
  },
  {
    "text": "MOE where one of the experts forgets the data that they were taught, right? This is called selective forgetting.",
    "start": "358234",
    "end": "365610"
  },
  {
    "text": "And this is very powerful in MOEs,",
    "start": "366180",
    "end": "368689"
  },
  {
    "text": "or even during retraining, we can shard the data and split it so that we don't want to train a certain skill anymore.",
    "start": "368689",
    "end": "374459"
  },
  {
    "text": "Now you might think that all this is pretty interesting",
    "start": "374780",
    "end": "377118"
  },
  {
    "text": "and it can help my friend Kevin draw better dogs",
    "start": "377118",
    "end": "379884"
  },
  {
    "text": "or can help Ravi begin to understand how to get a different style of swimming for the upcoming meet that they might have,",
    "start": "379884",
    "end": "386619"
  },
  {
    "text": "but as we do this, we can begin to help LLMs learn without losing their mind.",
    "start": "386900",
    "end": "391639"
  }
]
[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": "Users of modern day cloud applications expect a real-time experience.",
    "start": "720",
    "end": "5293"
  },
  {
    "text": "How is this achieved?",
    "start": "5294",
    "end": "7051"
  },
  {
    "text": "My name is Whitney Lee, I'm a cloud developer here at IBM.",
    "start": "7051",
    "end": "11156"
  },
  {
    "text": "Apache Kafka is an open source, distributed streaming platform",
    "start": "11156",
    "end": "16190"
  },
  {
    "text": "that allows for the development of real-time event-driven applications.",
    "start": "16190",
    "end": "21312"
  },
  {
    "text": "Specifically, it allows developers to make applications that continuously produce",
    "start": "21312",
    "end": "28464"
  },
  {
    "start": "22000",
    "end": "112000"
  },
  {
    "text": "and consume streams of data records.",
    "start": "28464",
    "end": "33311"
  },
  {
    "text": "Now, Kafka is distributed.",
    "start": "33889",
    "end": "37963"
  },
  {
    "text": "It runs as a cluster that can span multiple servers or even multiple data centers.",
    "start": "37963",
    "end": "43881"
  },
  {
    "text": "The records that are produced are replicated and partitioned in such a way",
    "start": "43881",
    "end": "49547"
  },
  {
    "text": "that allows for a high volume of users to use the application simultaneously",
    "start": "49547",
    "end": "55732"
  },
  {
    "text": "without any perceptible lag in performance.",
    "start": "55732",
    "end": "59232"
  },
  {
    "text": "So, with that, Apache Kafka is super fast.",
    "start": "59232",
    "end": "64591"
  },
  {
    "text": "It also maintains a very high level of accuracy  with the data records,",
    "start": "64768",
    "end": "73280"
  },
  {
    "text": "- and Apache Kafka maintains the order of their occurrence,",
    "start": "73953",
    "end": "83580"
  },
  {
    "text": "and, finally, because it's replicated,",
    "start": "84033",
    "end": "87104"
  },
  {
    "text": "Apache Kafka is also resilient and fault-tolerant.",
    "start": "87105",
    "end": "92799"
  },
  {
    "text": "So, these characteristics all together add up to an extremely powerful platform.",
    "start": "93777",
    "end": "101564"
  },
  {
    "text": "Let's talk about some use-cases for this.",
    "start": "101692",
    "end": "104688"
  },
  {
    "text": "Or, actually, before we do, let's talk about how applications used to be made",
    "start": "104688",
    "end": "108741"
  },
  {
    "text": "before event streaming was on the scene.",
    "start": "108741",
    "end": "112116"
  },
  {
    "start": "112000",
    "end": "176000"
  },
  {
    "text": "If the developer wanted to make a retail application, for example,",
    "start": "112116",
    "end": "116086"
  },
  {
    "text": "they would might make a checkout,",
    "start": "116086",
    "end": "119920"
  },
  {
    "text": "and then, with that checkout, when it happens, they want it to trigger a shipment.",
    "start": "120960",
    "end": "127060"
  },
  {
    "text": "So, a user checks out and then the order gets shipped.",
    "start": "127060",
    "end": "131936"
  },
  {
    "text": "They need to write an integration for that to happen,",
    "start": "131936",
    "end": "134959"
  },
  {
    "text": "consider the shape of the data,",
    "start": "134960",
    "end": "136558"
  },
  {
    "text": "the way the data is transported, and the format of the data,",
    "start": "136558",
    "end": "139734"
  },
  {
    "text": "but it's only one integration, so it's not a huge deal.",
    "start": "139734",
    "end": "142693"
  },
  {
    "text": "But, as the application grows, maybe we want to add",
    "start": "142693",
    "end": "146568"
  },
  {
    "text": "an automated email receipt when a checkout happens,",
    "start": "146568",
    "end": "150191"
  },
  {
    "text": "or maybe we want to add an update to the inventory",
    "start": "150192",
    "end": "154094"
  },
  {
    "text": "when a checkout happens.",
    "start": "154094",
    "end": "156672"
  },
  {
    "text": "As front and back end services get added, and the application grows,",
    "start": "156673",
    "end": "162180"
  },
  {
    "text": "more and more integrations need to get built and it can get very messy.",
    "start": "162180",
    "end": "166687"
  },
  {
    "text": "Not only that, but the teams in charge of each of the services",
    "start": "166687",
    "end": "170192"
  },
  {
    "text": "are now reliant upon each other before they can make any changes",
    "start": "170192",
    "end": "173742"
  },
  {
    "text": "and development is slow.",
    "start": "173742",
    "end": "176166"
  },
  {
    "start": "176000",
    "end": "246000"
  },
  {
    "text": "So, one great use case for Apache Kafka is decoupling system dependencies.",
    "start": "176166",
    "end": "184065"
  },
  {
    "text": "So, with Apache Kafka, all the hard integrations go away",
    "start": "185000",
    "end": "192239"
  },
  {
    "text": "and, instead, what we do is the checkout will stream events.",
    "start": "192239",
    "end": "197599"
  },
  {
    "text": "So, every time a checkout happens, that will get streamed,",
    "start": "197599",
    "end": "201280"
  },
  {
    "text": "and the checkout is not concerned with who's listening to that stream.",
    "start": "201280",
    "end": "205120"
  },
  {
    "text": "It's broadcasting those events.",
    "start": "205120",
    "end": "207480"
  },
  {
    "text": "Then the other services - email, shipment, inventory,",
    "start": "207480",
    "end": "210886"
  },
  {
    "text": "they subscribe to that stream, they choose to listen to that one,",
    "start": "210886",
    "end": "214348"
  },
  {
    "text": "and then they get the information they need and it triggers them to act accordingly.",
    "start": "214348",
    "end": "219808"
  },
  {
    "text": "So, this is how Kafka can decouple your system dependencies",
    "start": "219808",
    "end": "223680"
  },
  {
    "text": "and it is also a good use-case for how Kafka can be used for messaging.",
    "start": "223680",
    "end": "229680"
  },
  {
    "text": "So, even if this application was built from the ground up",
    "start": "230400",
    "end": "233474"
  },
  {
    "text": "as a cloud-native application, it could still be built in this way,",
    "start": "233475",
    "end": "237855"
  },
  {
    "text": "and use messaging to move the checkout experience along.",
    "start": "237855",
    "end": "245040"
  },
  {
    "text": "Another use case for Apache Kafka could be location tracking.",
    "start": "245727",
    "end": "253058"
  },
  {
    "start": "246000",
    "end": "290000"
  },
  {
    "text": "An example of this might be a ride share service.",
    "start": "254801",
    "end": "259728"
  },
  {
    "text": "So, a driver in a ride share service using the application",
    "start": "259728",
    "end": "264320"
  },
  {
    "text": "would turn on their app and maybe every, let's say, every second",
    "start": "264320",
    "end": "269428"
  },
  {
    "text": "a new event would get admitted with their current location.",
    "start": "269428",
    "end": "273489"
  },
  {
    "text": "This can be used by the application on a smaller scale,",
    "start": "273489",
    "end": "276598"
  },
  {
    "text": "say, to let an individual user know how close their particular ride is",
    "start": "276640",
    "end": "281520"
  },
  {
    "text": "or on a large scale, to calculate surge pricing,",
    "start": "281520",
    "end": "284960"
  },
  {
    "text": "to show a user a map before they choose which ride they want.",
    "start": "284960",
    "end": "289600"
  },
  {
    "start": "290000",
    "end": "346000"
  },
  {
    "text": "Another way to use Apache Kafka, another use-case",
    "start": "290000",
    "end": "295520"
  },
  {
    "text": "would be data gathering.",
    "start": "295520",
    "end": "299680"
  },
  {
    "text": "This can be used",
    "start": "300960",
    "end": "303840"
  },
  {
    "text": "in a simple way just to collect analytics, to optimize your website,",
    "start": "304640",
    "end": "309024"
  },
  {
    "text": "or it can be used more in a more complex way",
    "start": "309120",
    "end": "311682"
  },
  {
    "text": "with a a music streaming service, for example.",
    "start": "311747",
    "end": "314787"
  },
  {
    "text": "Where one user, every song they listen to can be a stream of records,",
    "start": "314787",
    "end": "319478"
  },
  {
    "text": "and your application could use that stream",
    "start": "319478",
    "end": "322612"
  },
  {
    "text": "to give real-time recommendations to that user.",
    "start": "322612",
    "end": "325803"
  },
  {
    "text": "Or, it can take the data records from all the users,",
    "start": "325803",
    "end": "330183"
  },
  {
    "text": "aggregate them, and then come up with a list of an artist's top songs.",
    "start": "330183",
    "end": "335008"
  },
  {
    "text": "So, this is in no way exhaustive,",
    "start": "335008",
    "end": "337796"
  },
  {
    "text": "but these are some very interesting use-cases",
    "start": "337796",
    "end": "340336"
  },
  {
    "text": "to show how powerful Kafka is and ways things that you can do with it,",
    "start": "340337",
    "end": "345565"
  },
  {
    "text": "but let's give an overview of how Kafka works.",
    "start": "345565",
    "end": "349774"
  },
  {
    "start": "346000",
    "end": "401000"
  },
  {
    "text": "Kafka is built on four core APIs.",
    "start": "349774",
    "end": "354345"
  },
  {
    "text": "The first one is the \"producer\" API.",
    "start": "354345",
    "end": "358880"
  },
  {
    "text": "The producer API",
    "start": "360883",
    "end": "364671"
  },
  {
    "text": "allows your application to produce, to make, these streams of data.",
    "start": "364671",
    "end": "369711"
  },
  {
    "text": "So, it creates the records and produces them to topics.",
    "start": "369919",
    "end": "376542"
  },
  {
    "text": "A \"topic\" is an ordered list of events.",
    "start": "376542",
    "end": "380910"
  },
  {
    "text": "Now the topic can persist to disk -",
    "start": "380911",
    "end": "384450"
  },
  {
    "text": "that's where it can be saved for just a matter of minutes if it's going to be consumed immediately",
    "start": "384450",
    "end": "390516"
  },
  {
    "text": "or you can have it saved for hours, days, or even forever.",
    "start": "390516",
    "end": "394159"
  },
  {
    "text": "As long as you have enough storage space that the topics are persisted to physical storage.",
    "start": "394159",
    "end": "400465"
  },
  {
    "start": "401000",
    "end": "438000"
  },
  {
    "text": "Then we have the consumer API.",
    "start": "401103",
    "end": "406897"
  },
  {
    "text": "The consumer API subscribes to one or more topics",
    "start": "407680",
    "end": "414255"
  },
  {
    "text": "and listens and ingests that data.",
    "start": "414401",
    "end": "418586"
  },
  {
    "text": "It can subscribe to topics in real time",
    "start": "418586",
    "end": "421605"
  },
  {
    "text": "or it can consume those old data records that are saved to the topic.",
    "start": "421605",
    "end": "428160"
  },
  {
    "text": "Now producers can produce directly to consumers",
    "start": "428255",
    "end": "432000"
  },
  {
    "text": "and that works for a simple Kafka application where the data doesn't change, ",
    "start": "432000",
    "end": "437246"
  },
  {
    "text": "but to transform that data, what we need is the streams API.",
    "start": "437326",
    "end": "445039"
  },
  {
    "start": "438000",
    "end": "492000"
  },
  {
    "text": "The streams API is very powerful.",
    "start": "445871",
    "end": "450128"
  },
  {
    "text": "It leverages the producer and the consumer APIs.",
    "start": "450128",
    "end": "455328"
  },
  {
    "text": "So, it will consume from a topic or topics",
    "start": "455456",
    "end": "460224"
  },
  {
    "text": "and then it will analyze, aggregate, or otherwise transform the data ",
    "start": "460565",
    "end": "468196"
  },
  {
    "text": "in real time, and then produce the resulting streams",
    "start": "468196",
    "end": "474672"
  },
  {
    "text": "to a topic - either the same topics or to new topics.",
    "start": "474753",
    "end": "480784"
  },
  {
    "text": "This is really at the core of what makes Kafka so amazing, and what powers",
    "start": "480784",
    "end": "486000"
  },
  {
    "text": "the more complex use-cases like the location tracking or the data gathering.",
    "start": "486000",
    "end": "491648"
  },
  {
    "text": "Finally, we have the connector API.",
    "start": "491648",
    "end": "496800"
  },
  {
    "start": "492000",
    "end": "556000"
  },
  {
    "text": "The connector API enables developers to write connectors,",
    "start": "498448",
    "end": "503294"
  },
  {
    "text": "which are reusable producers and consumers.",
    "start": "503295",
    "end": "506559"
  },
  {
    "text": "So, in a Kafka cluster many developers",
    "start": "506559",
    "end": "509886"
  },
  {
    "text": "might need to integrate the same type of data source,",
    "start": "509886",
    "end": "512372"
  },
  {
    "text": "like a MongoDB, for example.",
    "start": "512372",
    "end": "514853"
  },
  {
    "text": "Well, not every single developer should have to write that integration,",
    "start": "514853",
    "end": "518781"
  },
  {
    "text": "what the connector API allows",
    "start": "518782",
    "end": "520925"
  },
  {
    "text": "is for that integration to get written once, the code is there,",
    "start": "520926",
    "end": "524085"
  },
  {
    "text": "and then all the developer needs to do is configure it",
    "start": "524085",
    "end": "526827"
  },
  {
    "text": "in order to get that data source into their cluster.",
    "start": "526827",
    "end": "530483"
  },
  {
    "text": "So, modern day cloud application users expect a real-time experience",
    "start": "530483",
    "end": "536457"
  },
  {
    "text": "and Kafka is what's behind that technology.",
    "start": "536457",
    "end": "539850"
  },
  {
    "text": "Thank you! If you have questions please drop us a line below.",
    "start": "539851",
    "end": "543602"
  },
  {
    "text": "If you want to see more videos like this in the future",
    "start": "543602",
    "end": "546109"
  },
  {
    "text": "please like and subscribe",
    "start": "546109",
    "end": "547832"
  },
  {
    "text": "and don't forget:",
    "start": "547832",
    "end": "548886"
  },
  {
    "text": "you can grow your skills and earn a badge with IBM Cloud Labs",
    "start": "548887",
    "end": "553036"
  },
  {
    "text": "which are free, browser-based interactive Kubernetes labs.",
    "start": "553138",
    "end": "556756"
  }
]
[
  {
    "start": "0",
    "end": "103000"
  },
  {
    "text": "Tim Hwang: Hello and welcome\nto Mixture of Experts. I'm your host Tim Hwang. Each week, Mixture of Experts\nbrings together a brilliant team",
    "start": "8804",
    "end": "16160"
  },
  {
    "text": "of researchers, product experts,\nengineers, and more working at the cutting edge of artificial intelligence.",
    "start": "16160",
    "end": "21919"
  },
  {
    "text": "We debate, distill, and discuss down\nthe biggest news of the week in AI, from product announcements and the\nhottest papers on archive to industry",
    "start": "21920",
    "end": "29640"
  },
  {
    "text": "gossip and NVIDIA stock price. This week, three stories. First up, Scarlett Johansson versus\nOpenAI, the Sky Voice Controversy.",
    "start": "29640",
    "end": "38040"
  },
  {
    "text": "Who's right, who's wrong, and what\ndoes it tell us about where things are going in the design of AI products?",
    "start": "38040",
    "end": "43560"
  },
  {
    "text": "Second, who's afraid of the FMTI? The Center for Research on\nFoundation Models at Stanford University have released the\nlatest edition of their Foundation",
    "start": "43560",
    "end": "51600"
  },
  {
    "text": "Model Transparency Index, or FMTI. What is it, and why does it matter?",
    "start": "51600",
    "end": "57080"
  },
  {
    "text": "And then finally, last but not least, it's\nannouncement season, uh, and announcement season continues with IBM Think hot\non the heels of OpenAI and Google.",
    "start": "57080",
    "end": "65160"
  },
  {
    "text": "watsonx is seeing a bunch of major\nannouncements, what to tell us about the future of AI and enterprise\nand more specifically about the",
    "start": "65160",
    "end": "71280"
  },
  {
    "text": "future of open source in enterprise. So the panelists, as always, I'm\njoined by an S tier level of, uh,",
    "start": "71280",
    "end": "79040"
  },
  {
    "text": "set of panelists for us today. First off, Marina Danilevsky,\na senior research scientist. Welcome back to the show.",
    "start": "79040",
    "end": "85901"
  },
  {
    "text": "Marina Danilevsky: Happy to be here. Tim Hwang: Kate Soule, Program\nDirector, Generative AI Research. Thanks and welcome to the show.",
    "start": "85901",
    "end": "91827"
  },
  {
    "text": "Kate Soule: Great to be here, Tim. Tim Hwang: And finally, Armand\nRuiz, Vice President, Product Management on the AI Platform.",
    "start": "91828",
    "end": "98747"
  },
  {
    "text": "Armand Ruiz: Thank you so much. Hi, everybody.",
    "start": "98747",
    "end": "105109"
  },
  {
    "start": "103000",
    "end": "760000"
  },
  {
    "text": "Tim Hwang: I want to tackle our kind\nof first story, which was sort of the hot news of the week, uh, the\nScarJo versus OpenAI controversy.",
    "start": "105109",
    "end": "112280"
  },
  {
    "text": "So hot on the heels of GPT 4o announcements the other week, um, and\nbasically Sam Altman simply tweeting",
    "start": "112280",
    "end": "119040"
  },
  {
    "text": "her, there had already been a lot of\nmajor speculation that essentially the Spike Jonze film from about a\ndecade ago, Her, um, was somehow",
    "start": "119040",
    "end": "127520"
  },
  {
    "text": "weirdly ending up being the template\nfor OpenAI's, uh, product development. Uh, and all of this kind of took a\nmajor turn when Scarlett Johansson",
    "start": "127520",
    "end": "135400"
  },
  {
    "text": "herself, uh, released a public\nstatement saying that OpenAI had approached her to use her voice.",
    "start": "135400",
    "end": "141320"
  },
  {
    "text": "Uh, and then when she had refused, had\nproceeded to release a, a similar one, a, a kind of stunningly similar one.",
    "start": "141320",
    "end": "147120"
  },
  {
    "text": "In fact, so similar that people\nhad been like, that sounds like Scarlett Johansson, uh, when\nOpenAI was, uh, demoing, uh, GPT 4o.",
    "start": "147120",
    "end": "154420"
  },
  {
    "text": "um, uh, the other week. And so I think the main question, you\nknow, I think we can get into the who's",
    "start": "154420",
    "end": "160440"
  },
  {
    "text": "right, who's wrong here, but I think\nthe kind of first question that I want, wanted the kind of panel to opine on is.",
    "start": "160440",
    "end": "166599"
  },
  {
    "text": "You know, the unbelievable thing for\nme is like, Her is like a movie that's like a decade old and that like, Sarah\nJohansson is still like the cultural",
    "start": "166600",
    "end": "173640"
  },
  {
    "text": "template for like the kind of assistive\ntechnologies that people are working on today to the point that like one\nof the leading companies in the space",
    "start": "173640",
    "end": "180760"
  },
  {
    "text": "almost explicitly is like really still\nusing that movie as kind of like a template for their product development.",
    "start": "180760",
    "end": "187160"
  },
  {
    "text": "And I guess I'm kind of curious if any of\nyou have kind of thoughts about like the persistence of like the vision in Her.",
    "start": "187160",
    "end": "193360"
  },
  {
    "text": "Um, and why it. still so kind of compelling today,\nor if actually, you know, you think it's actually kind of silly that\npeople think that it is so compelling.",
    "start": "193360",
    "end": "200959"
  },
  {
    "text": "Um, uh, I don't know if\nany, you have any thoughts. I mean, K Armand, you're new to the show,\nbut I don't know if you would want to jump in first with some thoughts on that.",
    "start": "200960",
    "end": "209760"
  },
  {
    "text": "Armand Ruiz: Uh, I can, I can start. I mean, uh, look, From my perspective\nand, um, my, most of my conversations are",
    "start": "209760",
    "end": "216520"
  },
  {
    "text": "always with, uh, within an enterprise set\nup, but, uh, everything related to voice",
    "start": "216520",
    "end": "223040"
  },
  {
    "text": "imitation and, uh, which is a technology\nthat has been progressing a lot in the last few years, uh, is, is a big concern.",
    "start": "223040",
    "end": "230840"
  },
  {
    "text": "Um, and I think that's why we're,\nwe're seeing this acceleration on, on",
    "start": "230840",
    "end": "236120"
  },
  {
    "text": "regulations, because these examples\nare just freaking people out, honestly.",
    "start": "236120",
    "end": "242159"
  },
  {
    "text": "Right.\nAnd. And, uh, we, we, we need to be\ncareful, especially when companies",
    "start": "242160",
    "end": "247320"
  },
  {
    "text": "like, uh, OpenAI, that they have so\nmuch, um, reach and hype around them. And, by the way, that demo was\nspectacular in every single sense.",
    "start": "247320",
    "end": "256600"
  },
  {
    "text": "And it's a little bit sad that all we're\ntalking about is, is this controversy. Uh, on, on the resemblance, on the voice\nwith Scarlett Johansson, I think we, there",
    "start": "256600",
    "end": "266640"
  },
  {
    "text": "was this opportunity to just pick another\nvoice or make it, uh, less closer to, to her, given like that they tried actually\nto, to, um, to get her voice officially in",
    "start": "266640",
    "end": "277920"
  },
  {
    "text": "the, in the system and it didn't work out. I don't know. What do you think? Kate Soule: Yeah. I mean, I, I think a lot of the draw to\nhaving a Scarlett Johansson type voice",
    "start": "277920",
    "end": "287000"
  },
  {
    "text": "is really, you know, an attempt to try\nand get trust and comfort with these systems that, you know, that's where I\nthink a lot of the initial ambitions lay.",
    "start": "287000",
    "end": "295840"
  },
  {
    "text": "But if you think about it, like\nthese models are, are tools, they're not, they're not people,\nthey're not humans, they're tools.",
    "start": "295840",
    "end": "302040"
  },
  {
    "text": "And is this really the right tone? And even, even, I mean, there are huge\nissues on data rights to consider, but",
    "start": "302040",
    "end": "308880"
  },
  {
    "text": "even that aside, is this the right tone\nand mode in which to actually communicate the value and that these tools can offer?",
    "start": "308880",
    "end": "317349"
  },
  {
    "text": "Tim Hwang: Yeah, for sure. I think that's kind of\none of the funny things. I mean, to first respond to Armand,\nI think like, um, you know, everybody",
    "start": "317349",
    "end": "322960"
  },
  {
    "text": "I know who is like more in the\nmachine learning space saw the demo and they're like, low latency. It's crazy. Right. And then everybody else who kind\nof saw the demo who are less in",
    "start": "322960",
    "end": "329160"
  },
  {
    "text": "the AI space are like, it's her. And it's sort of interesting, like\nwhat people pick up from demos, depending on their level of.",
    "start": "329160",
    "end": "334200"
  },
  {
    "text": "Familiar with uh, the technology. But I guess, Kate, we'd love to kind of\ngo into the point you just made a little",
    "start": "334200",
    "end": "339840"
  },
  {
    "text": "bit more, you know, I think there's\na kind of question of like, should we be imitating Her in the first place?",
    "start": "339840",
    "end": "345400"
  },
  {
    "text": "Like I think Her is kind of such a\nfascinating movie, cause I, I watched it again recently, because I've been\ntalking to a bunch of people being like,",
    "start": "345400",
    "end": "350479"
  },
  {
    "text": "oh yeah, it's like a great product vision\nlike And then you watch her and like the whole point of her is like, this is a bad\ndirection for technology to be going down.",
    "start": "350480",
    "end": "358240"
  },
  {
    "text": "And so it's like very strange to\nme that like, you know, it's become a template, uh, in some ways.",
    "start": "358240",
    "end": "364080"
  },
  {
    "text": "Um, and I guess the kind of pick up would,\nis sort of what you're saying that like we, we actually might not want technology\ncompanies to really kind of, imitate like",
    "start": "364080",
    "end": "371960"
  },
  {
    "text": "a human companion, like that there's some\nethical concerns that you have around that, or, um, or maybe your point is\nactually maybe in a different direction.",
    "start": "371960",
    "end": "378508"
  },
  {
    "text": "Kate Soule: Well, you know, there's a,\na principle in data storytelling and data visualizations that, you know,\nthe, what you visualize should reflect,",
    "start": "378508",
    "end": "386840"
  },
  {
    "text": "uh, the data and how it was created. And so if you're uncertain and there's\nuncertainty, you should visualize error bars, for example, you know, and I think.",
    "start": "386840",
    "end": "394320"
  },
  {
    "text": "A similar principle applies for large\nlanguage models, like the mechanism and the mode of how you communicate\nthe results that the model is saying",
    "start": "394320",
    "end": "401520"
  },
  {
    "text": "and the tone and intonation, everything\nthat you're doing is providing a lot of information for the user,\nwhether you realize it or not.",
    "start": "401520",
    "end": "408200"
  },
  {
    "text": "And I don't think that human voices\nshould be off the table, but you know, very flirtatious female human voices\nfor something that's meant to be a",
    "start": "408200",
    "end": "417040"
  },
  {
    "text": "tool and an assistant, you know, is\nthat really the right thing to do. mode and mechanism. And I think there's a\nright way and a wrong way.",
    "start": "417040",
    "end": "423440"
  },
  {
    "text": "And it's, you know, it's sometimes hard\nto define exactly what correct and wrong is, but you know, this one seems to lean\na little bit too far to the wrong side.",
    "start": "423440",
    "end": "432309"
  },
  {
    "text": "Tim Hwang: Definitely. And it's sort of interesting because I\nthink like when you get to the realm of voice, you really are working on like\npeople's, kind of cultural priors, right?",
    "start": "432309",
    "end": "438920"
  },
  {
    "text": "Like, you can imagine a voice which\nwas like very like sci fi robotic. It's like very arbitrary what\nvoice we wanted to produce.",
    "start": "438920",
    "end": "445240"
  },
  {
    "text": "And like, you know, I guess in that\nsense, maybe it communicates more that it is a computer that you're\ntalking with versus a versus a person.",
    "start": "445240",
    "end": "451600"
  },
  {
    "text": "Um, Kate Soule: and there's like\nways to earn trust, right? In systems and to make\npeople feel more comfortable.",
    "start": "451600",
    "end": "456840"
  },
  {
    "text": "But like, do you, you know, there's also\nreal reasons to have some skepticism of what you're hearing from models.",
    "start": "456840",
    "end": "462639"
  },
  {
    "text": "And there's, you know, proper ways\nto go about, you know, showing that models are not confident and that\nthere are risks and things that should",
    "start": "462640",
    "end": "471240"
  },
  {
    "text": "be evaluated objectively by humans. And if we're just being told something\nin a very trusting, loving voice, then,",
    "start": "471240",
    "end": "478000"
  },
  {
    "text": "you know, are we really doing our due\ndiligence here as model providers and giving our customers the right, you know,\nputting them in the right mindset of how",
    "start": "478000",
    "end": "485400"
  },
  {
    "text": "to use these models in a responsible way? Tim Hwang: Totally. So, Marina, I want to bring you in. I know you're a veteran to this\nshow, but I think one of the reasons",
    "start": "485400",
    "end": "492440"
  },
  {
    "text": "I was very excited to have you back\non was last time you were talking about Inspector Ragget, right?",
    "start": "492440",
    "end": "497479"
  },
  {
    "text": "And I think the conversation that\nwe had at that point was, well, how do we know that RAG is doing well? We need to build kind of like a\ndashboard experience for people to",
    "start": "497480",
    "end": "504840"
  },
  {
    "text": "kind of monitor and understand whether\nor not they They should trust the results coming out of a RAG process.",
    "start": "504840",
    "end": "509440"
  },
  {
    "text": "And I guess as someone who has like worked\nso deeply with that as a method, right? Like the dashboard as the way\nyou establish trust versus like",
    "start": "510440",
    "end": "517079"
  },
  {
    "text": "the voice as the interface. Are you, how do you feel about voice? Are you like kind of suspicious about it? Like I get it.",
    "start": "517080",
    "end": "522399"
  },
  {
    "text": "I'm getting suspicious vibes from Kate,\nbut I'm kind of curious about like how you kind of navigate this as we think\nabout like all the different interfaces",
    "start": "522400",
    "end": "528960"
  },
  {
    "text": "we can have in sort of assessing like\nmodel trust essentially, which it really seems like we're talking about.",
    "start": "528960",
    "end": "534541"
  },
  {
    "text": "Marina Danilevsky: Sure, I will say I\ndon't think that the, the dashboard is the only way and it tends to be the kind of\nthing that is, again, more understandable",
    "start": "534541",
    "end": "540920"
  },
  {
    "text": "to model developers, um, normal folks\ndon't understand it and actually often I think it's a way to have even less trust\nbecause if you have somebody who's not",
    "start": "540920",
    "end": "549000"
  },
  {
    "text": "technical, they're going to look at it and\nbe like, what am I supposed to do with all these numbers, all of this, all of that? Like, tell me sort of\nat the end of the day.",
    "start": "549000",
    "end": "554400"
  },
  {
    "text": "So I really, really agree with what it. Kate is saying, which is that it's\nimportant in how you deliver the information at the end, finally, to\nthe end user, you should give on in",
    "start": "554400",
    "end": "563440"
  },
  {
    "text": "terms that are obvious to the person\nreceiving it, whether you should trust and how you should take it. So like one direction that's a little\nbit worrying is the amount of, uh, people",
    "start": "563440",
    "end": "573360"
  },
  {
    "text": "using these language models, for example,\nas ad hoc psychologists or ad hoc friends or girlfriends or anything of that kind.",
    "start": "573360",
    "end": "580040"
  },
  {
    "text": "So now we're going to make\nsure that now we have that in Scarlett Johansson's voice. That seems again, not maybe.",
    "start": "580040",
    "end": "585280"
  },
  {
    "text": "The right direction to go. Let's just\nTim Hwang: pour some gasoline Marina Danilevsky: on this. And certainly not in\nthe enterprise setting.",
    "start": "585280",
    "end": "591680"
  },
  {
    "text": "So voice is great, uh, but it should also\nbe a way to communicate, just as in text,",
    "start": "591680",
    "end": "598279"
  },
  {
    "text": "are, you know, to what extent should I\nbe really trusting what you say and can you give me the appropriate caveats? There's a responsibility here.",
    "start": "598280",
    "end": "604760"
  },
  {
    "text": "Just as when you read something that\nreads extremely fluent, you hear something and it's extremely fluent. It's got that affect and it sounds human.",
    "start": "604760",
    "end": "611640"
  },
  {
    "text": "Of course, you're going\nto have a tendency. To, to take it in a particular way. I think there's a lot of responsibility\non the people providing these models",
    "start": "611640",
    "end": "619120"
  },
  {
    "text": "to, to, to do that accordingly. Tim Hwang: Yeah.\nI never really, oh, yeah, Armand, go Armand Ruiz: ahead.\nTim Hwang: Yeah, Armand Ruiz: I just wanna\nadd, uh, two quick things.",
    "start": "619120",
    "end": "625840"
  },
  {
    "text": "One, I think, um, maybe it's\na little bit controversial, but I'm gonna say it anyway. Please do.\nUh.",
    "start": "625840",
    "end": "632560"
  },
  {
    "text": "Here we are talking about it, right? So I think Sam Altman is like Elon Musk,\nuh, they, they know very well, they are",
    "start": "632560",
    "end": "638760"
  },
  {
    "text": "very smart how to market their products. And, and they had the Google conference\nright after this, their, their event.",
    "start": "638760",
    "end": "646360"
  },
  {
    "text": "And they always find ways\nto be on the headlines. One way or the other. So I think that they like a\nlittle bit of the controversy.",
    "start": "646360",
    "end": "654360"
  },
  {
    "text": "I think maybe this one is getting a\nlittle bit out of control, but it's not the first one that they faced.",
    "start": "654360",
    "end": "659240"
  },
  {
    "text": "Um, and on the other hand, I think\nthere is also, uh, about voice. I think voice is, it's been the promise\nfor AI for many years with Siri,",
    "start": "659880",
    "end": "667360"
  },
  {
    "text": "with Alexa, but it was low latency. It was, It's very robotic.",
    "start": "667360",
    "end": "672480"
  },
  {
    "text": "So that demo and the Google demo, and\nthere was a similar demo a few years ago, very researchy from Google that was\nshowing already like a more natural voice.",
    "start": "672480",
    "end": "683680"
  },
  {
    "text": "And at some point it's going\nto always be a problem. Any voice they put is going to\nresemble to someone else's voice.",
    "start": "683680",
    "end": "690920"
  },
  {
    "text": "So this is a very difficult conversation\nin this case is because we're talking about a celebrity and, and voice cloning\nfrom celebrities is going to be a problem.",
    "start": "690920",
    "end": "701080"
  },
  {
    "text": "But we will always have these\nproblems that these voices will resemble, uh, someone else. Marina Danilevsky: Actually, I\nwanted to respond to something that",
    "start": "701080",
    "end": "707320"
  },
  {
    "text": "you said, um, I don't like Elon\nMusk and Sam Altman speaking for",
    "start": "707320",
    "end": "713120"
  },
  {
    "text": "all of us that are working in AI. They like controversy. They, they're kind of, they're\nvery, you know, bro kind of guys.",
    "start": "713120",
    "end": "720000"
  },
  {
    "text": "Okay, great. But this assumption that, you know, all\npublicity is good publicity and as long as you're talking about me, that's great.",
    "start": "720000",
    "end": "727040"
  },
  {
    "text": "It's not. Reflective, I think, a lot of us\nthat are here, and also the idea of, well, why wouldn't Scarlett\nJohansson agree to be the voice?",
    "start": "727040",
    "end": "734000"
  },
  {
    "text": "She should be honored that she was asked. She was in a sci fi movie about this. So, clearly, this is the same thing.",
    "start": "734000",
    "end": "739480"
  },
  {
    "text": "That level of assumption and that\nlevel of, well, it should be an honor to participate in anything\nthat I do, that leaves a very",
    "start": "739480",
    "end": "746760"
  },
  {
    "text": "bad taste in a lot of our mouths. And I just want to, say a lot\nof us are not pleased and do not, that doesn't represent us.",
    "start": "746760",
    "end": "757949"
  },
  {
    "text": "Tim Hwang: So we'll move on actually,\nbecause we have three topics to get to. So I'm going to bring up the second\ntopic and Kate, I'll bring you in",
    "start": "757949",
    "end": "763360"
  },
  {
    "start": "760000",
    "end": "1497000"
  },
  {
    "text": "to kind of lead us on this, but\njust to kind of quickly tee us up. Um, so this is a big week. Um, there's a group called the\nCenter for Research on Foundation",
    "start": "763360",
    "end": "770880"
  },
  {
    "text": "Models, uh, at Stanford university. Um, Uh, Percy Lang and a number of his\ncollaborators there have been working",
    "start": "770880",
    "end": "776600"
  },
  {
    "text": "for some time on something they call\nthe Foundation Model Transparency Index, or FMTI for short, um, and it\neffectively is kind of this annual",
    "start": "776600",
    "end": "785960"
  },
  {
    "text": "index they're doing of like leading\nfoundation models evaluating effectively their commitment to transparency.",
    "start": "785960",
    "end": "792360"
  },
  {
    "text": "And I guess, um, Kay, I figured,\nyou know, just for our listeners, It worth it kind of talk a little bit\nabout what it is in the first place.",
    "start": "792360",
    "end": "798720"
  },
  {
    "text": "Um, and then I know you were\nactually working in a, in a pretty deep way on this just recently. So we'd love to kind of hear about\nsort of your involvement and sort",
    "start": "798720",
    "end": "804800"
  },
  {
    "text": "of IBM's involvement in the FMTI. Kate Soule: Yeah, absolutely. So Stanford's report in the transparency\nindex is, uh, a compilation of a",
    "start": "804800",
    "end": "814720"
  },
  {
    "text": "hundred different questions that\nthey basically ask model providers to understand uh, how transparent and open\nthey are across the model life cycle.",
    "start": "814720",
    "end": "823440"
  },
  {
    "text": "So they look at everything from upstream,\nhow is the data curated, what rights do",
    "start": "823440",
    "end": "828960"
  },
  {
    "text": "you have to the data, are you transparent\nabout what data you use, To the model itself as the second main category.",
    "start": "828960",
    "end": "835000"
  },
  {
    "text": "So have you evaluated your\nmodel for different risks? Do you describe those risks? Do you provide mitigations\nfor those risks?",
    "start": "835000",
    "end": "842040"
  },
  {
    "text": "And then also to the downstream uses,\nlike, do you, are you clear where the usage and policies, do you talk about\nhow you would enforce those usage",
    "start": "842040",
    "end": "849560"
  },
  {
    "text": "policies, where are your models being\nused and, and those types of applications?",
    "start": "849560",
    "end": "854640"
  },
  {
    "text": "So what it does really well, and what I\nreally appreciate about it is it, It's not trying to evaluate and say, this\nis an unbiased model or this score.",
    "start": "854640",
    "end": "864240"
  },
  {
    "text": "If you score well, that\nmeans your models are safe. What it's doing is trying to look\nat how open our model providers",
    "start": "864240",
    "end": "871360"
  },
  {
    "text": "about their own technology. Are people actually sharing what they've\nbuilt, sharing the degree to which they've tested different safety aspects?",
    "start": "871360",
    "end": "879000"
  },
  {
    "text": "Um, and are sharing those with\ntheir own customers or not. And you know, that's something that\nI I'm really, really passionate about",
    "start": "879000",
    "end": "885920"
  },
  {
    "text": "in the entire team here for IBM that\ntrains granite models have strongly felt we need to show up very strongly on.",
    "start": "885920",
    "end": "892760"
  },
  {
    "text": "So, uh, our granite models\nwere ranked in this report. We're really excited. We came in fourth overall.",
    "start": "892760",
    "end": "898520"
  },
  {
    "text": "Uh, and especially on the upstream,\nlike all of the data collection, uh, and all the work that we do on the\ncuration and transparency around what",
    "start": "898520",
    "end": "907040"
  },
  {
    "text": "data goes into our models, we were one\nof the top scoring model providers. So the, the granite model showed\nup very well in that report.",
    "start": "907040",
    "end": "914280"
  },
  {
    "text": "And we're really excited,\nexcited by those results. Tim Hwang: Yeah, congratulations. I know it was like very competitive\nactually, like the number of",
    "start": "914280",
    "end": "921240"
  },
  {
    "text": "companies and sort of models that\nthey were covering was like very vast. Kate Soule: I mean, they cover\nthe top 14 or so model providers.",
    "start": "921240",
    "end": "928279"
  },
  {
    "text": "This is the second time\nthey did the report. The first time was back in October\nand they looked at the top eight.",
    "start": "928280",
    "end": "934360"
  },
  {
    "text": "Uh, or so, and, um, it's, it's\na really, really exciting area. Tim Hwang: Yeah, for sure.",
    "start": "934360",
    "end": "939880"
  },
  {
    "text": "So, I think there's a bunch of\ninteresting questions I want to kind of talk to the panel about, really kind\nof about sort of like governance in the",
    "start": "939880",
    "end": "946440"
  },
  {
    "text": "universe of AI, because I think there's\nsort of two very interesting things going on that I see in FMTI, right?",
    "start": "946440",
    "end": "951840"
  },
  {
    "text": "Like, I think one of them is, uh,\nYou know, even a few years ago, and it still kind of is this way, right? Like, I think, like, a lot of the\nprocess of, you know, pre training,",
    "start": "951840",
    "end": "959199"
  },
  {
    "text": "fine tuning models is, like, shrouded\nin mystery, where people are like, oh, well, you know, I heard they have, like,\nthis thing that they do in the recipe",
    "start": "959200",
    "end": "966120"
  },
  {
    "text": "that really gets these great results. And so, like, a lot of the way\nAI development has proceeded in the past has been very secretive.",
    "start": "966120",
    "end": "972519"
  },
  {
    "text": "It's been the realm of,\nlike, trade secrets. Um, and so I think like one of the\ninteresting things here is like, can",
    "start": "972520",
    "end": "978120"
  },
  {
    "text": "we create an index that kind of creates\nsort of like a race to the top, right? Like avoid a world in which everybody's\nincredibly closed, uh, about their model.",
    "start": "978120",
    "end": "986400"
  },
  {
    "text": "And yeah. You know, I guess I'm, I'm curious,\nyou know, uh, Marina, like, uh, as a researcher in the space, you know,\ndo you feel like it's working, right?",
    "start": "986400",
    "end": "995040"
  },
  {
    "text": "Like the strategy, like, do you\nthink FMTI is like helping to improve or like encourage companies to\nbe more transparent in the space?",
    "start": "995040",
    "end": "1001519"
  },
  {
    "text": "Um, and, and if so, I'm kind of curious\nabout like how far you think it will go? Because presumably at some point all\ncompanies will be like, well, we're never,",
    "start": "1001520",
    "end": "1008040"
  },
  {
    "text": "can't definitely tell you about that. Right. And so I think we're kind of playing\nwith this line about like, what do companies owe to the public\nwhen they release these models?",
    "start": "1008040",
    "end": "1015000"
  },
  {
    "text": "And, um, yeah, I was just kind of\ncurious as someone who's kind of like a researcher researcher in the\ntrenches thinking about this, um, how you sort of see this type of effort.",
    "start": "1015000",
    "end": "1021661"
  },
  {
    "text": "Marina Danilevsky: Sure. So I'll start again with agreeing\nwith Kate that this at least encourages people because they see,\noh, other companies are saying stuff.",
    "start": "1021661",
    "end": "1028559"
  },
  {
    "text": "So it's maybe okay or good for PR or for\nadoption reasons for me to also say stuff.",
    "start": "1028560",
    "end": "1034319"
  },
  {
    "text": "First, everybody had to get to a\ncertain point of So when nobody could figure out how to get the models to a\ncertain point of quality, no one was",
    "start": "1034320",
    "end": "1040800"
  },
  {
    "text": "going to say anything, just in case\nthey came up with the right secret sauce and I'm not going to share. As people, I think, start to get the\ntechnology to be a little bit more,",
    "start": "1040800",
    "end": "1049160"
  },
  {
    "text": "uh, evolved, a little bit more mature,\nokay, now there are reasons, including economic ones, of why you'd want to\nshare, because that'll be the kind of",
    "start": "1049160",
    "end": "1057440"
  },
  {
    "text": "thing that your clients or customers\nwill, you know, pick you over somebody else because of aspects of this.",
    "start": "1057440",
    "end": "1063399"
  },
  {
    "text": "So this kind of. public, uh, pressure of, well, they\ndid this, so I'm going to do this. This pit is actually really good.",
    "start": "1063400",
    "end": "1069720"
  },
  {
    "text": "Um, there's going to be a limit\nto how far it's going to go. Of course, nobody's going to share, uh,\nlike customer data or also anything that",
    "start": "1069720",
    "end": "1077320"
  },
  {
    "text": "might get them bad PR or anything that\nmight get them potentially in trouble. Uh, legal waters or anything of the kind.",
    "start": "1077320",
    "end": "1083889"
  },
  {
    "text": "Sure, right, yeah, yeah.\nPeople won't share. But overall, it's a good trend. It speaks to the, um, evolving\nmaturity of the field to me.",
    "start": "1083889",
    "end": "1091160"
  },
  {
    "text": "So that's, that's, that's how I see\nsort of that back and forth going. Kate Soule: I mean, you can\nsee it in the scores too.",
    "start": "1091160",
    "end": "1096560"
  },
  {
    "text": "Like the scores from October\nto, uh, this, this year. Latest report may have gone up\nacross everyone who was evaluated.",
    "start": "1096560",
    "end": "1102960"
  },
  {
    "text": "Like I think there's this like safety in\nnumbers where also given the regulations are still evolving and everyone, you\nknow, a lot of case laws still evolving,",
    "start": "1102960",
    "end": "1110799"
  },
  {
    "text": "people are kind of testing the waters,\nbut as more and more, uh, results are shared and, and people are more and\nmore transparent, it gives confidence",
    "start": "1110800",
    "end": "1118120"
  },
  {
    "text": "for, for more people to do the same. Tim Hwang: It does sort of feel like,\nlike things like transparency, right, or like things like, you know, chatbot\narena, they're in some ways kind of",
    "start": "1118120",
    "end": "1125640"
  },
  {
    "text": "like of a piece, which is that like\nearly on everybody was sort of like competing against these like benchmarks.",
    "start": "1125640",
    "end": "1131000"
  },
  {
    "text": "And essentially like as the benchmarks\nhave become like more and more saturated, now it seems like everybody's trying\nto differentiate in different ways.",
    "start": "1131000",
    "end": "1137160"
  },
  {
    "text": "And like one of the differentiations\nis like, is your model transparent or not, right, which is almost\nlike a factor that sits, you know,",
    "start": "1137160",
    "end": "1142400"
  },
  {
    "text": "somewhat on top of the model, but\nalso like outside of it as well. Marina Danilevsky: I was just going\nto say, if you actually look at the places where the scores are still\nlow, Um, I think, uh, off the top",
    "start": "1142400",
    "end": "1150720"
  },
  {
    "text": "of my head, I know it's about like\nevaluation of model trustworthiness. How do you do it? And then also downstream applications.",
    "start": "1150720",
    "end": "1156000"
  },
  {
    "text": "These are things that we're not yet very\ngood at, do not understand yet very well. So those are the cards that people\nare still kind of holding a little",
    "start": "1156000",
    "end": "1161440"
  },
  {
    "text": "closer to their chest in case again,\nthis turns into a differentiator. So again, it just makes the point\nof lots of the scores are improved. It's very interesting to see the ones that\nhaven't, because it again, gives a sense",
    "start": "1161440",
    "end": "1169519"
  },
  {
    "text": "of, you know, what is the confidence and\nthe maturity of, uh, of the technology.",
    "start": "1169520",
    "end": "1174987"
  },
  {
    "text": "Armand Ruiz: Yeah, for sure. I'll add, uh, this, uh, in the\nconference IBM think this week.",
    "start": "1174987",
    "end": "1180720"
  },
  {
    "text": "I maybe talk to 50 plus customers\num, governance, transparency, trust.",
    "start": "1180720",
    "end": "1186480"
  },
  {
    "text": "Uh, it was in every single discussion. Um, and over the last year, Granite\nand the work that we're doing at IBM.",
    "start": "1186480",
    "end": "1194679"
  },
  {
    "text": "Uh, is really a differentiator. Our customers really appreciate that.",
    "start": "1194680",
    "end": "1199840"
  },
  {
    "text": "Um, and in fact, if you follow me on\nLinkedIn, I'm extremely open and I published a few times the research paper\nfrom Granite, which I recommend everyone",
    "start": "1199840",
    "end": "1207920"
  },
  {
    "text": "to go check because it explains very well\nwhere they went to train the model and",
    "start": "1207920",
    "end": "1213200"
  },
  {
    "text": "the data collection process, the data\npreprocessing, we've been extremely open. You won't find a paper with such openness\non what he went to train the model.",
    "start": "1213200",
    "end": "1222279"
  },
  {
    "text": "Um, so that is actually. becoming more and more important\nbecause companies, they, they",
    "start": "1222280",
    "end": "1227760"
  },
  {
    "text": "take, they take these models as a\nbase model, and then they mix it up with their own enterprise data.",
    "start": "1227760",
    "end": "1233320"
  },
  {
    "text": "So you need to get a very good base\nmodel that you can trust, uh, if you are going to mix it up with\nyour own data to get, uh, outcomes.",
    "start": "1233320",
    "end": "1241680"
  },
  {
    "text": "Yeah, Armand, Tim Hwang: you're actually like, you\nwere, uh, you're anticipating my question because I think one of the things,\nuh, I have, I think is as a, you know,",
    "start": "1241680",
    "end": "1248480"
  },
  {
    "text": "point of point of critique as well. Okay. There's a bunch of academics\nat Stanford, right? Like, is this actually impacting\nhow business is behaving?",
    "start": "1248480",
    "end": "1255360"
  },
  {
    "text": "It sounds like your answer is yes. Like, actually, it turns out that,\nlike, companies are there looking at the, you know, the FMTI being like,\nwell, this actually is relevant to",
    "start": "1255360",
    "end": "1264200"
  },
  {
    "text": "my purchasing decision, which is\nreally, really pretty interesting. Kate Soule: Well, just to build on\nyour point a little bit, Armand, it's like, you know, it's not like\nyou're just taking these models",
    "start": "1264200",
    "end": "1272360"
  },
  {
    "text": "and then adding a layer on top. Like when a model provides a response,\nyou can't pinpoint back that the model is",
    "start": "1272360",
    "end": "1278320"
  },
  {
    "text": "using your data or it's pre training data. You know, it all basically, you\nknow, goes into a blender and comes",
    "start": "1278320",
    "end": "1284480"
  },
  {
    "text": "out mixed together the other end. So just because you're going through\napplications with your own data and using rag patterns or even fine\ntuning and other things, it doesn't",
    "start": "1284480",
    "end": "1293280"
  },
  {
    "text": "mean that you have control over all\nof the history you're inheriting and baggage and skeletons and closets\nyou could potentially be inheriting",
    "start": "1293280",
    "end": "1301040"
  },
  {
    "text": "when using some of these models. Tim Hwang: Yeah, totally. So Kate, final question. I'm curious if you have any thoughts\non is, you know, kind of almost talking",
    "start": "1301040",
    "end": "1308840"
  },
  {
    "text": "about the trend is like, where does\nthings like FMTI go into the future? Um, and I guess I want to kind of relay\na fear and maybe you can relay my fear.",
    "start": "1308840",
    "end": "1317320"
  },
  {
    "text": "Uh, but I don't know if you agree is\nbasically like, you know, I agree. I think one of the nice things about FMTI,\nthough, having been in a company that",
    "start": "1317320",
    "end": "1324000"
  },
  {
    "text": "received an FMTI request was like, Oh, you\nknow, it's basically like they have not. Take it any shortcuts, right?",
    "start": "1324000",
    "end": "1329440"
  },
  {
    "text": "They're basically like, how do we know\nwhether or not you're transparent? I don't know. It depends on how well you do against\nthese a hundred indicators, right?",
    "start": "1329440",
    "end": "1336120"
  },
  {
    "text": "Which is like a massive It's like a\nproject in order to take on responding to the FMTI Um, and I guess I'm kind of\ncurious and maybe a little bit worried",
    "start": "1336120",
    "end": "1344680"
  },
  {
    "text": "about kind of the commercial pressures\non indices like FMTI What I mean by that is You know, if you're a B2B\nbuyer, you're an enterprise like on the",
    "start": "1344680",
    "end": "1352320"
  },
  {
    "text": "market looking for, you know, a model\nto use for your internal operations. A hundred indicators is like a lot,\nyou know, like there's a reason",
    "start": "1352320",
    "end": "1360280"
  },
  {
    "text": "people go to Wirecutter and they're\nlike, Oh, I will buy the same fridge that everybody else has. They're like, I'll buy the same, You know,\nwire management, everybody else says.",
    "start": "1360280",
    "end": "1368200"
  },
  {
    "text": "Do you worry at all that, like, as\nthese models, or these indices become more and more used by industry, like\nby businesses to make purchasing",
    "start": "1368200",
    "end": "1374720"
  },
  {
    "text": "decisions, we'll also see kind of,\nlike, pressure to kind of, like, narrow. Like, people do ultimately just\nwant, like, transparent or not.",
    "start": "1374720",
    "end": "1381120"
  },
  {
    "text": "Or like, you know, rubber, yeah. And so, you know. If you do agree with that, like, I'm kind\nof curious if you have thoughts on, like,",
    "start": "1381120",
    "end": "1387279"
  },
  {
    "text": "how do we keep that aperture open, right? Because it's important for us to,\nlike, keep the kind of transparency that it sounds like Percy and\nteam is really chasing after here.",
    "start": "1387280",
    "end": "1394080"
  },
  {
    "text": "So, and a couple of thoughts\nthere, but curious about, like, how you'd navigate that. Kate Soule: I mean, I think particularly\nwhen regulations start to come into",
    "start": "1394080",
    "end": "1401559"
  },
  {
    "text": "act, you know, there's going to be\ntremendous pressure to be able to put a, you know, a rubber stamp on something\nand say it's compliant or not compliant.",
    "start": "1401560",
    "end": "1408240"
  },
  {
    "text": "Um, and there, so there will certainly\nbe pressure along those lines, but you know, Similar to, it's a\nsimilar risk that you bring up that",
    "start": "1408240",
    "end": "1417560"
  },
  {
    "text": "you have with also gamification. Like people are going to just start\noptimizing for a couple of key things and how do we make sure that\nwe continue to push forward and to",
    "start": "1417560",
    "end": "1426040"
  },
  {
    "text": "drive how we're, we're innovating. And I really think it comes\ndown to making sure that we're",
    "start": "1426040",
    "end": "1432039"
  },
  {
    "text": "continuing to keep pushing forward. pace on how we define transparency\nand safety in models with how fast this technology is growing.",
    "start": "1432040",
    "end": "1438680"
  },
  {
    "text": "So if you look at how we looked at\nlarge language models a year ago and what was considered state of the art\nand what was considered safe versus",
    "start": "1438680",
    "end": "1444920"
  },
  {
    "text": "not safe a year ago compared to\ntoday is an entirely different story. And it's going to need\nto continue to evolve.",
    "start": "1444920",
    "end": "1450960"
  },
  {
    "text": "And we need researchers like those at\nStanford helping us articulate to what those risks are coming up with more,\nuh, nuanced ways as, as some of these",
    "start": "1450960",
    "end": "1459159"
  },
  {
    "text": "metrics and indices become saturated. Everyone's always. You know, sharing all this information,\nyou know, maybe we can shift our focus",
    "start": "1459160",
    "end": "1465080"
  },
  {
    "text": "into some of these new emerging things\nthat we need to continue to keep in mind. Tim Hwang: Yeah. And I think that will be the new\ngame is like the initial task is like",
    "start": "1465080",
    "end": "1472040"
  },
  {
    "text": "getting the companies to do this. And then now that sort of the challenge is\nlike, well, we don't want you to game it.",
    "start": "1472040",
    "end": "1477640"
  },
  {
    "text": "So like the criteria also may also become\nthis kind of game where it's like, well, we won't tell you what the criteria\nare for certain types of indicators.",
    "start": "1477640",
    "end": "1483640"
  },
  {
    "text": "You order to kind of retain\nthe benefit of the, the Sigma. But I, yeah, I think Kate Soule: that's to our\nbenefit as a field, right? Totally. If, if we don't have some sort of\nincentive to keep innovating, um, then",
    "start": "1483640",
    "end": "1492560"
  },
  {
    "text": "you know it's gonna become stagnant. So, uh, certainly welcome it.",
    "start": "1492560",
    "end": "1498320"
  },
  {
    "start": "1497000",
    "end": "2331000"
  },
  {
    "text": "Tim Hwang: Um, so I'll move\nus on to our last topic here. And Armand, I'm gonna give you\ncenter stage, uh, 'cause it sounds",
    "start": "1500440",
    "end": "1507720"
  },
  {
    "text": "like you were, had a really busy\nweek presenting all of this. Um, so, uh, this was,\nuh, IBM's think week.",
    "start": "1507720",
    "end": "1514720"
  },
  {
    "text": "Um, it continues the\nseason of announcements. Everybody's announcing AI. stuff right now. And so I guess, um, you know, I think\njust as an open question, Armand, do",
    "start": "1514720",
    "end": "1521679"
  },
  {
    "text": "you want to just kind of quickly give\na thumbnail sketch of everything? I know in particular, you\nwere very excited about the",
    "start": "1521680",
    "end": "1526720"
  },
  {
    "text": "announcements around watsonx. Um, and if you just want to give like a\nthumbnail sketch to our listeners about what was announced, because I read the\nblog post and I was like, this is going",
    "start": "1526720",
    "end": "1533960"
  },
  {
    "text": "to be a lot to cover in 15 minutes. Um, but I think you as an expert\nwould probably be able to put us best on track on, you know, what\npeople should be paying attention to.",
    "start": "1533960",
    "end": "1541667"
  },
  {
    "text": "Armand Ruiz: Yeah, there is so much. Uh, I'm going to be a little bit\nselfish and talk about the area, uh, of what's so nice that I cover,\nwhich is the AI platform part.",
    "start": "1541667",
    "end": "1549840"
  },
  {
    "text": "Um, I will start with, with, uh, Granite\nmodels that, uh, they are now open source and I'll let Kate elaborate on that.",
    "start": "1549840",
    "end": "1557440"
  },
  {
    "text": "So, um, but we're really\nexcited, uh, to, to just jump into the open source movement.",
    "start": "1557440",
    "end": "1563919"
  },
  {
    "text": "And then we, we have something called\ninstruct lab that helps customize models. So, um, I'll let, um, explain, uh,\nKate will explain that a lot better.",
    "start": "1563920",
    "end": "1573440"
  },
  {
    "text": "She's been driving a lot of\nthat from the research angle. Then, um, we announced a very exciting\npartner partnership with Mistral as well.",
    "start": "1573440",
    "end": "1581960"
  },
  {
    "text": "And we already had the Mistral open\nsource models in, in our platform. And we offer that to our customers.",
    "start": "1581960",
    "end": "1587560"
  },
  {
    "text": "Now we also have the\nMistral commercial models. That includes Mistral\nlarge and Mistral small.",
    "start": "1587560",
    "end": "1592759"
  },
  {
    "text": "And that is, I mean, we, we, we\nlove Mistral and now we're gonna be able to offer that to customers\nin the cloud and on prem as well.",
    "start": "1592760",
    "end": "1601760"
  },
  {
    "text": "And specifically in Europe,\nthat's gonna be a very big hit. Um, we are We released a lot of features.",
    "start": "1601760",
    "end": "1608400"
  },
  {
    "text": "So many features. One I would like to highlight is, for\nexample, chat with your documents. The classic RAG use case, we introduced a\nuser interface that is very easy to add",
    "start": "1608400",
    "end": "1618400"
  },
  {
    "text": "documents or point to a vector database. You can have thousands of documents there. And in just a few clicks, you can create\nyour own chat interface to talk to the",
    "start": "1618400",
    "end": "1626600"
  },
  {
    "text": "documents that will pinpoint directly\nto the reference and to the citations. And then you can export that as an\napplication or as an endpoint that you",
    "start": "1626600",
    "end": "1634280"
  },
  {
    "text": "can integrate with your own applications. So, um, there are a lot of, uh, tools\nlike that that will make the development",
    "start": "1634280",
    "end": "1641920"
  },
  {
    "text": "of, uh, solutions, um, very flexible. The last one I would like to highlight\nis two more I would like to highlight.",
    "start": "1641920",
    "end": "1649280"
  },
  {
    "text": "One is a toolkit that we're releasing\nin tech preview for application",
    "start": "1649280",
    "end": "1654480"
  },
  {
    "text": "developers to make it extremely\neasy to develop Gen AI applications. So we're all the time talking\nabout LLMs, but LLMs don't make",
    "start": "1654480",
    "end": "1662679"
  },
  {
    "text": "applications and solutions. LLMs are just one component. And coming back to the RAG use\ncase, you need an embeddings model.",
    "start": "1662680",
    "end": "1669480"
  },
  {
    "text": "You need a vector database. You need a to chunk the data. So you need a lot of different things.",
    "start": "1669480",
    "end": "1675960"
  },
  {
    "text": "So we, we believe we were creating one\nof the best toolkits for developers",
    "start": "1675960",
    "end": "1681080"
  },
  {
    "text": "to make the development of those use\ncases extremely simple with a lot of templates and access to tools.",
    "start": "1681080",
    "end": "1687480"
  },
  {
    "text": "And the last one on the governance. On the governance, we also\nrelease a lot of stuff. I'll, I'll highlight, um, What we're\ndoing with AWS, we have a very good",
    "start": "1687480",
    "end": "1696600"
  },
  {
    "text": "partnership with AWS and SageMaker\nis a very popular tool for, um, for,",
    "start": "1696600",
    "end": "1702760"
  },
  {
    "text": "um, enterprise, uh, to just build\nand deploy machine learning models. And now you can govern all those\nmodels directly with watsonx.",
    "start": "1702760",
    "end": "1710919"
  },
  {
    "text": "Governance. That means you can have like your full\ncentral panel, MLOps panel, And, and",
    "start": "1710920",
    "end": "1716679"
  },
  {
    "text": "then you, you have those components of\nregulatory compliance and risk management to make sure those models perform.",
    "start": "1716680",
    "end": "1721800"
  },
  {
    "text": "So those are just a few, but\nthere is, there are so many new assistance and other features, but\nmaybe let me hand it over to Kate.",
    "start": "1721800",
    "end": "1728120"
  },
  {
    "text": "You can explain the open source\nangle on Granite and InstructLab. Tim Hwang: Yeah. Do you really mean it?",
    "start": "1728120",
    "end": "1733159"
  },
  {
    "text": "Before Kate, you jump in. It's, it does feel like. It's like open source, like the big\nmessage is you're all in on open source.",
    "start": "1733160",
    "end": "1739799"
  },
  {
    "text": "Yeah, Kate Soule: it was really\nexciting to be there. You know, it was hosted in my\nhometown this year, which was really fun, uh, in Boston.",
    "start": "1740320",
    "end": "1747120"
  },
  {
    "text": "And the message across every\nsingle presentation was IBM is all in on open source.",
    "start": "1747120",
    "end": "1753440"
  },
  {
    "text": "And so it was really, really\nexciting to be there and to be part of the announcement for the Granite\ncode models that we released.",
    "start": "1753440",
    "end": "1759480"
  },
  {
    "text": "So we open sourced eight state of the\nart granite code models two variants, um for four different model sizes a 3b and\n8b Uh 34 billion parameter models And",
    "start": "1759480",
    "end": "1771960"
  },
  {
    "text": "especially the 8 billion parameter model\nreally we're seeing state of the art performance And its ability to outperform\nanything else that has come out there",
    "start": "1771960",
    "end": "1780120"
  },
  {
    "text": "we're really thrilled just to be able\nto create this as a starting point that the rest of the community can operate\nunder and A lot Of Armand's mention in",
    "start": "1780120",
    "end": "1789320"
  },
  {
    "text": "Struck Lab, a lot of our intent behind\nreleasing the Instruct Lab open source project, which I think you guys covered\nin an earlier episode as well, is giving",
    "start": "1789320",
    "end": "1797040"
  },
  {
    "text": "the community, the open source community,\nthe tools to work on models together. So allowing them to collaborate and\ncontribute to models, uh, and build",
    "start": "1797040",
    "end": "1806040"
  },
  {
    "text": "ultimately a better model that benefits\nfrom the world working together. And, you know, I think it gets Marina\nkind of to your earlier point of",
    "start": "1806040",
    "end": "1813120"
  },
  {
    "text": "like, You know, there's a lot of big\npersonalities who are trying to define how AI works and the world works.",
    "start": "1813120",
    "end": "1819720"
  },
  {
    "text": "And that's one version of the world,\nbut that's not how IBM sees it. And it's really only through, you know,\nan open source ecosystem where we bring",
    "start": "1819720",
    "end": "1826800"
  },
  {
    "text": "the best that the community has to offer\nand everyone working together that I think we'll really be able to unlock,\nuh, the, the future potential here.",
    "start": "1826800",
    "end": "1834908"
  },
  {
    "text": "Tim Hwang: So I'll reveal, uh, reveal\na little bit of my own bias here. Uh, huge open source head. Thanks Um, struggled for many years\nrunning just like Linux, like that",
    "start": "1834909",
    "end": "1844000"
  },
  {
    "text": "was my, my childhood was like running\nfree and open source software locally. Um, and I think one of the things,\nyou know, I kind of would love the",
    "start": "1844000",
    "end": "1851560"
  },
  {
    "text": "three of you to kind of respond to,\num, is essentially like this kind of interesting question that I saw popping\nup on social media this week, which is",
    "start": "1851560",
    "end": "1858960"
  },
  {
    "text": "how sustainable is open source, right? Um, and, you know, I think.",
    "start": "1858960",
    "end": "1864520"
  },
  {
    "text": "One of the debates, I mean,\nspeaking about big personalities that want to define AI, right? So there's a bunch of very loud\nVCs on AI arguing about this.",
    "start": "1864520",
    "end": "1871880"
  },
  {
    "text": "But I think that the root of the debate,\nI think, is an interesting one, right? Which is that, you know, you\nlook at the pre training costs",
    "start": "1871880",
    "end": "1878519"
  },
  {
    "text": "of state of the art models. And as we scale bigger and bigger and\nbigger, it just gets more and more",
    "start": "1878520",
    "end": "1883840"
  },
  {
    "text": "and more expensive to like, accumulate\nthe computing clusters you need to do this, to do the pre training runs.",
    "start": "1883840",
    "end": "1889560"
  },
  {
    "text": "Um, and I think, you know, I think one\nof the arguments sort of being made right now, right, is, is there coming\na point where basically like these next",
    "start": "1889560",
    "end": "1898360"
  },
  {
    "text": "generation models are becoming so, so\nexpensive that like it would be very, very difficult to imagine any company\nthat originates these models being willing",
    "start": "1898360",
    "end": "1906720"
  },
  {
    "text": "to open source them going forwards. So that essentially sort of the argument\nis that there's a point at which kind of like the, the sort of like, uh,\nupside from open sourcing is going to",
    "start": "1906720",
    "end": "1916040"
  },
  {
    "text": "be outweighed by sort of like the raw\npre training costs of these models. You know, the conclusion goes,\nright, with these big personalities",
    "start": "1916040",
    "end": "1923640"
  },
  {
    "text": "on Twitter is basically like, dot,\ndot, dot, open source has a ceiling.",
    "start": "1923640",
    "end": "1928708"
  },
  {
    "text": "Kate Soule: Do\nTim Hwang: you Kate Soule: all buy that Tim Hwang: argument? If not, why not? Kate Soule: I don't buy that argument. I mean, I think there is incentive to\ncontinue to drive model performance, spend",
    "start": "1928708",
    "end": "1938440"
  },
  {
    "text": "more and create bigger and bigger models. But I think we're seeing diminishing\nreturns in terms of, you know, The use",
    "start": "1938440",
    "end": "1944919"
  },
  {
    "text": "cases and the value, you can accomplish\na ton of incredibly, you know, take",
    "start": "1944920",
    "end": "1950720"
  },
  {
    "text": "care of low hanging fruit, so to\nspeak, with much smaller models that are going to be the ones that you're\nactually deploying and using day to day.",
    "start": "1950720",
    "end": "1957280"
  },
  {
    "text": "Like, that's where I think the\neconomic value is going to drive. And that's where open source\nis really, Well positioned.",
    "start": "1957280",
    "end": "1963560"
  },
  {
    "text": "I also think we're also, you know, we're\nlearning a lot this past year, these past",
    "start": "1963560",
    "end": "1969240"
  },
  {
    "text": "couple of months in terms of how to unlock\nvalue and improve performance in models.",
    "start": "1969240",
    "end": "1974640"
  },
  {
    "text": "And most of the cost is\nspent on pre training, right? As you say, you know, Burning\nGPUs for months, thousands of",
    "start": "1974640",
    "end": "1980559"
  },
  {
    "text": "GPUs, uh, to create a base model. But then there's a step\nafterwards called alignment. And that's where the open source community\nhas really been leading the innovation.",
    "start": "1980560",
    "end": "1989600"
  },
  {
    "text": "They take these models like the llama\nmodel series, that's incredibly popular. And they take that base model and\niterate on the alignment step.",
    "start": "1989600",
    "end": "1996679"
  },
  {
    "text": "And that is far less costly,\nfar less compute intensive. So we're able to drive, you know, these\nstep changes without having to resort",
    "start": "1996680",
    "end": "2004160"
  },
  {
    "text": "back to just burning compute hours for,\nyou know, eons driving up crazy costs. So I, I don't think that's, you\nknow, a valid argument in my mind.",
    "start": "2004160",
    "end": "2012669"
  },
  {
    "text": "Tim Hwang: Yeah, for sure. Armin and Marina, do you\nwant to jump in at all? Or do you largely agree? Armand Ruiz: Yeah, no,\nI fully, I fully agree.",
    "start": "2012669",
    "end": "2018840"
  },
  {
    "text": "And, and, and, uh, we're all in on open\nsource at IBM and I, I, I see the passion",
    "start": "2018840",
    "end": "2027360"
  },
  {
    "text": "of the community and that's really,\nreally hard to, to compete with, right? Like, um, even, even companies\nare using the open source speech",
    "start": "2027360",
    "end": "2036840"
  },
  {
    "text": "that, um, to attract talent. Uh, researchers, they, they\nwant to see their work. I contributed back to the community\nand not closed source and behind an API",
    "start": "2036840",
    "end": "2046560"
  },
  {
    "text": "and their work not represented in any\ndifferent way than just a commercial API. So I think there is\nalso that angle as well.",
    "start": "2046560",
    "end": "2053600"
  },
  {
    "text": "The power of the community is\nproving to attract the best minds in the planet to progress on AI.",
    "start": "2053600",
    "end": "2061429"
  },
  {
    "text": "Tim Hwang: Yeah, it's fascinating\nto believe that, you know, like the era of big scale is already over. Like, essentially, like, the\ncompetition has already shifted.",
    "start": "2061429",
    "end": "2068080"
  },
  {
    "text": "Like, it has turned out that,\nlike, scale was not all you needed. Like, actually, you needed a lot more\nthan, more than scale in some ways.",
    "start": "2068080",
    "end": "2074359"
  },
  {
    "text": "I think, Kate, what's also really\ninteresting in what you say is I think a little bit also about, like,\nyou know, in a company using AI, like",
    "start": "2074360",
    "end": "2080560"
  },
  {
    "text": "in any company, There's this, uh,\nlike hierarchy of prestige, right? Who's doing the important work? Who's the rock star?",
    "start": "2080560",
    "end": "2086440"
  },
  {
    "text": "And for a very long time, pre training\nwas like the rock stars, right? Like, oh man, they're like really using\nthese like, you know, F1 computers to",
    "start": "2086440",
    "end": "2093200"
  },
  {
    "text": "like kind of create these like, you\nknow, beings of pure linear algebra. But like kind of what you're saying is\nlike, actually the future is not that.",
    "start": "2093200",
    "end": "2099880"
  },
  {
    "text": "Like, in fact, like it's turned out\nthat like what was traditionally almost low prestige in the\nmachine learning space, which is.",
    "start": "2099880",
    "end": "2105200"
  },
  {
    "text": "You just do the fine tuning at the end\nto make it a nice chatbot is actually where the action is going to be. Do you buy that?",
    "start": "2105200",
    "end": "2110800"
  },
  {
    "text": "Like in the future, people are\ngoing to be like, Oh my God, that person's like a God of fine tuning. Like this person is so amazing at\nalignment, like they're the ones and I,",
    "start": "2110800",
    "end": "2118200"
  },
  {
    "text": "this commodity stuff is like pre training. Kate Soule: Uh, I mean, I think\nthe community like is the quickly already there if we're not already.",
    "start": "2118200",
    "end": "2124960"
  },
  {
    "text": "It is insane the amount of innovation\nthat's happening at that part of the process, and there's just so much\nuntapped potential given, relatively",
    "start": "2126040",
    "end": "2134520"
  },
  {
    "text": "speaking, how cost effective it is. So, you know, I think that's where\nwe're also going to continue just to",
    "start": "2134520",
    "end": "2139760"
  },
  {
    "text": "be incentivized and where rock stars,\nas you say, will be made because you're going to do what pre training had to\nspend millions and billions of dollars",
    "start": "2139760",
    "end": "2147720"
  },
  {
    "text": "to do and, you know, a fraction of that. Should I ask the question then?",
    "start": "2147720",
    "end": "2153629"
  },
  {
    "text": "Tim Hwang: Why keep scaling? Is it an insane thing for\nthe industry to be doing? Kate Soule: Okay, well, the hidden curse\nof why alignment's doing so well is you",
    "start": "2153629",
    "end": "2161880"
  },
  {
    "text": "need big models to make good small models. So, you know, there is this paradox\nhere of like, okay, small models are",
    "start": "2161880",
    "end": "2168440"
  },
  {
    "text": "where we're incentivized, but At some\npoint, if you don't have a big model, you can't make a good small model.",
    "start": "2168440",
    "end": "2173800"
  },
  {
    "text": "But we're also seeing a lot of open\nsource, great larger models come out. There's a bit of a play there that\nhas to still, I think, evolve in terms",
    "start": "2173800",
    "end": "2181240"
  },
  {
    "text": "of, you know, the market still needs\nto feel out how that's going to fully play out, um, for model providers.",
    "start": "2181240",
    "end": "2187560"
  },
  {
    "text": "Tim Hwang: So this is great. Uh, any final thoughts,\nuh, Armand and, uh, Marina?",
    "start": "2187560",
    "end": "2193261"
  },
  {
    "text": "Marina Danilevsky: Um, I think\nthat, uh, these things go in waves. So we had a wave of, like, scale, scale,\nscale in a way that you just could",
    "start": "2193261",
    "end": "2199680"
  },
  {
    "text": "never do before, and that was amazing. So it's very natural that we say, all\nright, we've maybe hit not a plateau,",
    "start": "2199680",
    "end": "2205680"
  },
  {
    "text": "but it may be a little bit of a slight\nslowing down in the S curve, all right, let's see what else we can do. It's going to come back again, and\nmeanwhile, it's a very reasonable thing to",
    "start": "2205680",
    "end": "2213080"
  },
  {
    "text": "continue to try to see, well, what can we\nmeanwhile do with, with the hardware, with the acceleration, with everything else?",
    "start": "2213080",
    "end": "2218200"
  },
  {
    "text": "Because it's going to come up again\nfor, for some reason or another. All right. So it's very good and natural that you\ngo from scaling and now it's like, all",
    "start": "2218200",
    "end": "2225840"
  },
  {
    "text": "right, how do you get small from big? It's probably going to go again. Okay, now what can we turn those small\nthings into once again, something big.",
    "start": "2225840",
    "end": "2232520"
  },
  {
    "text": "It's this, this, this is a\nnormal and the pendulum swinging Tim Hwang: basically. Marina Danilevsky: We're just\nin that part of the swing.",
    "start": "2232520",
    "end": "2239160"
  },
  {
    "text": "So it's not that it's not valuable. It's just that what are people innovating\nthe most rapidly and that the pendulum",
    "start": "2239160",
    "end": "2244720"
  },
  {
    "text": "will swing of where the focus is there. Armand Ruiz: I will add just things\nthat people don't talk about it",
    "start": "2244720",
    "end": "2249800"
  },
  {
    "text": "that much is, for example, when\nLama 3 went out, I think Lama 3 had, um, what was the context window?",
    "start": "2249800",
    "end": "2256680"
  },
  {
    "text": "Like 32, 000 or 16, 000,\nbut it wasn't super large. Uh, and days after the release, the\ncommunity was already contributing,",
    "start": "2256680",
    "end": "2265440"
  },
  {
    "text": "uh, A version with a technique\nto increase the context window. So those are small details that only\nthe practitioners notice, uh, and, and",
    "start": "2265440",
    "end": "2274359"
  },
  {
    "text": "they don't get into, into the headlines,\nbut that is really the power of open source that those contributions that\ninnovation and, um, that's going to be",
    "start": "2274360",
    "end": "2282640"
  },
  {
    "text": "really, really hard, really hard to stop. Tim Hwang: Yeah, that's\na great note to end on.",
    "start": "2282640",
    "end": "2288560"
  },
  {
    "text": "Well, that's all the time\nthat we have for today. Marina, thanks for\ncoming back on the show. Marina Danilevsky: Pleasure. Tim Hwang: And Kay Armand, it's been\nawesome having you on the show for",
    "start": "2288560",
    "end": "2295840"
  },
  {
    "text": "the first time, and hope to have\nyou again on the show sometime. Thanks so much. Thanks\nKate Soule: for the great discussion.",
    "start": "2295840",
    "end": "2301349"
  },
  {
    "text": "Tim Hwang: Thanks for\njoining Mixture of Experts. And for the first time, a quick\ncall out to all you listeners. We're thinking about doing a\nsegment in the next few weeks",
    "start": "2301349",
    "end": "2308120"
  },
  {
    "text": "that will focus specifically on\nagents and what's happening there. Uh, we're always looking for interesting\nstories and people to talk to, so",
    "start": "2308120",
    "end": "2315240"
  },
  {
    "text": "if you've seen any cool papers or\ncompanies or people working in the space, um, please, uh, drop a line\nin the comments on it and we'd love",
    "start": "2315240",
    "end": "2321320"
  },
  {
    "text": "to pick it up in a future episode. Um, see you next time.",
    "start": "2321320",
    "end": "2330200"
  }
]
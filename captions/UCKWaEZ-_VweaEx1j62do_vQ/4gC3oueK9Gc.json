[
  {
    "text": "So if you have AI and it's designed to talk like your basic 10th grader",
    "start": "30",
    "end": "5538"
  },
  {
    "text": "and it starts talking like a two year old, that's not good,. That's a problem.",
    "start": "5538",
    "end": "9750"
  },
  {
    "text": "If you have AI and it starts cursing like a sailor after it's deployed and out in the world, that's not a good thing either.",
    "start": "10270",
    "end": "16930"
  },
  {
    "text": "So how do you keep that from happening?",
    "start": "17170",
    "end": "18609"
  },
  {
    "text": "So today in this video we're going to walk through three different ways",
    "start": "19390",
    "end": "21995"
  },
  {
    "text": "that you can keep your AI doing what it's supposed to do.",
    "start": "21996",
    "end": "24809"
  },
  {
    "text": "I think before we get into that, I think it's important though to understand what data scientists and AI engineers do.",
    "start": "25970",
    "end": "31669"
  },
  {
    "text": "AI engineers and data scientists, we build models,",
    "start": "32170",
    "end": "35390"
  },
  {
    "text": "and typically we build these models and what I'll call or what we call the development space,",
    "start": "36410",
    "end": "41818"
  },
  {
    "text": "and you can think of our development space as kind of like a sandbox.",
    "start": "45800",
    "end": "49334"
  },
  {
    "text": "It's our happy little world where we take inputs,",
    "start": "49840",
    "end": "53159"
  },
  {
    "text": "build models,",
    "start": "57460",
    "end": "58460"
  },
  {
    "text": "and these models create output. ",
    "start": "62820",
    "end": "64559"
  },
  {
    "text": "And while we're developing these models, we're very meticulous.",
    "start": "67990",
    "end": "71369"
  },
  {
    "text": "We wanna make sure that this output is exactly what we want it to be, right?",
    "start": "71990",
    "end": "76729"
  },
  {
    "text": "We don't want it to be, if we want the hey hi to speak like your average 10th grader",
    "start": "77030",
    "end": "81451"
  },
  {
    "text": "and the output is speaking like a two-year-old, we're gonna go back and we're gonna fix that.",
    "start": "81452",
    "end": "86129"
  },
  {
    "text": "If the model is designed to predict customer churn and it's not, we're gonna go back and fix that.",
    "start": "86470",
    "end": "92609"
  },
  {
    "text": "But once we get to a point where we're happy with the model, we think it's wonderful,",
    "start": "92950",
    "end": "97116"
  },
  {
    "text": "we put it into production, or we deploy it, we put it out into the world.",
    "start": "97116",
    "end": "101499"
  },
  {
    "text": "Typically we'll call this our production space.",
    "start": "102740",
    "end": "104680"
  },
  {
    "text": "like the deployment space in production.",
    "start": "109812",
    "end": "112660"
  },
  {
    "text": "A model is going to have input",
    "start": "119270",
    "end": "120689"
  },
  {
    "text": "and output.",
    "start": "130539",
    "end": "131539"
  },
  {
    "text": "So how do we ensure that this model is doing what it's supposed to do?",
    "start": "135790",
    "end": "139769"
  },
  {
    "text": "So we have really three different methods.",
    "start": "140697",
    "end": "142316"
  },
  {
    "text": "The first is what we call comparing the model output to ground truth, right?",
    "start": "143130",
    "end": "147849"
  },
  {
    "text": "So if we've built a model to predict churn,",
    "start": "147870",
    "end": "151228"
  },
  {
    "text": "and those predictions are not accurate,",
    "start": "151228",
    "end": "154647"
  },
  {
    "text": "like the people we've predicted to cancel their service don't cancel their service,",
    "start": "154647",
    "end": "159415"
  },
  {
    "text": "we know there's a problem.",
    "start": "159415",
    "end": "160849"
  },
  {
    "text": "So we can compare this output to some sort of ground truth.",
    "start": "160890",
    "end": "164410"
  },
  {
    "text": "In the generative world,",
    "start": "171430",
    "end": "172469"
  },
  {
    "text": "we can take, like if we have AI that's writing emails, based on some kind of prompt",
    "start": "174840",
    "end": "180551"
  },
  {
    "text": "or some kind of stimulus, we can have a human write an email to the same stimulus,",
    "start": "180551",
    "end": "185400"
  },
  {
    "text": "and the output coming from the AI in the human based on the same stimulus should be similar.",
    "start": "185740",
    "end": "192779"
  },
  {
    "text": "If they're not, we've got an issue and we need to go back and look at our model.",
    "start": "192860",
    "end": "196360"
  },
  {
    "text": "But again, in both situations, we're comparing the output of the model to some sort of ground truth.",
    "start": "196640",
    "end": "201080"
  },
  {
    "text": "The other thing we can do,",
    "start": "201870",
    "end": "202912"
  },
  {
    "text": "remember over here in the development space where the data scientists were",
    "start": "202912",
    "end": "206379"
  },
  {
    "text": "very, very rigorous in terms of what their model was doing, we can compare",
    "start": "206379",
    "end": "211137"
  },
  {
    "text": "the output in deployment to the output in development.",
    "start": "211137",
    "end": "215288"
  },
  {
    "text": "So if we're predicting a model that should be predicting on average a churn rate of 4%,",
    "start": "215870",
    "end": "222062"
  },
  {
    "text": "but in development, the average churn rate was like, let's say,  .4%, that's an issue, right?",
    "start": "222063",
    "end": "228510"
  },
  {
    "text": "What we're seeing in the deployment that is different than what we saw when we developed the model.",
    "start": "228610",
    "end": "232540"
  },
  {
    "text": "Likewise, if we built a model to talk like your average 10th grader",
    "start": "233020",
    "end": "236646"
  },
  {
    "text": "and all of a sudden it's talking like a two-year-old, that's an issue.",
    "start": "236646",
    "end": "239418"
  },
  {
    "text": "And we could tell that by comparing it to the output that was created in the development.",
    "start": "239420",
    "end": "243240"
  },
  {
    "text": "We can also compare the input data from production to development.",
    "start": "244040",
    "end": "250099"
  },
  {
    "text": "Like if the average age of the data going into our model in development was 25 years",
    "start": "250520",
    "end": "256915"
  },
  {
    "text": "and deployment or in production we're noticing that it's 50 years.",
    "start": "256915",
    "end": "261180"
  },
  {
    "text": "Whoa, hold on, something could go wrong.",
    "start": "261560",
    "end": "263700"
  },
  {
    "text": "We've had a lot, we're feeding a lot older group of people into this model.",
    "start": "263860",
    "end": "268078"
  },
  {
    "text": "So comparing it to ground truth, comparing it to the model in development,",
    "start": "269099",
    "end": "273302"
  },
  {
    "text": "comparing it to ground truth is sometimes called accuracy.",
    "start": "273302",
    "end": "275458"
  },
  {
    "text": "Comparing it to ground truth is sometimes called model drift.",
    "start": "276200",
    "end": "278800"
  },
  {
    "text": "The third thing we can do is we can create flags or filters around this output.",
    "start": "280520",
    "end": "284360"
  },
  {
    "text": "For example, we can have a PII flag.",
    "start": "286620",
    "end": "289199"
  },
  {
    "text": "So if somebody's social security number shows up in this output,",
    "start": "289258",
    "end": "292304"
  },
  {
    "text": "this flag is gonna get flagged and we know, okay, we can't send this out into the world.",
    "start": "292304",
    "end": "296167"
  },
  {
    "text": "Likewise, if it's hate, abuse, or profanity, HAP, we can identify in this output, flag it, get it out of there.",
    "start": "296500",
    "end": "303199"
  },
  {
    "text": "So anyway, those are three ways that you can ensure that your AI is doing what it's supposed to do.",
    "start": "304340",
    "end": "310779"
  },
  {
    "text": "I hope this was helpful.",
    "start": "311120",
    "end": "312120"
  },
  {
    "text": "Thank you so much.",
    "start": "312250",
    "end": "313250"
  }
]
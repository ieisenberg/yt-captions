[
  {
    "start": "0",
    "end": "82000"
  },
  {
    "text": "We're a little ways into 2024 now,",
    "start": "900",
    "end": "3100"
  },
  {
    "text": "and the pace of AI certainly isn't slowing down.",
    "start": "3101",
    "end": "5228"
  },
  {
    "text": "But where will it be by the end of the year?",
    "start": "5228",
    "end": "8444"
  },
  {
    "text": "Well, we've put together 9 trends",
    "start": "8520",
    "end": "11295"
  },
  {
    "text": "that we expect to emerge throughout the year.",
    "start": "11295",
    "end": "13349"
  },
  {
    "text": "Some of them are broad and high level,",
    "start": "13380",
    "end": "15269"
  },
  {
    "text": "some are a bit more technical.",
    "start": "15269",
    "end": "16649"
  },
  {
    "text": "So let's get into them.",
    "start": "17070",
    "end": "18070"
  },
  {
    "text": "Oh, and if you've stumbled across this video in 2025,",
    "start": "18840",
    "end": "22240"
  },
  {
    "text": "let us know how we did.",
    "start": "22240",
    "end": "23761"
  },
  {
    "text": "Okay, Trend #1: this is the year of the reality check.",
    "start": "24150",
    "end": "31619"
  },
  {
    "text": "It is the year of more realistic expectations.",
    "start": "32369",
    "end": "36420"
  },
  {
    "text": "When generative AI first hit mass awareness,",
    "start": "37020",
    "end": "40055"
  },
  {
    "text": "it was met with breathless news coverage.",
    "start": "40055",
    "end": "42430"
  },
  {
    "text": "Everyone was messing around with ChatGPT, Dall-E and the like.",
    "start": "42450",
    "end": "45681"
  },
  {
    "text": "And now that the dust has settled,",
    "start": "46140",
    "end": "47397"
  },
  {
    "text": "we're starting to develop a more refined understanding",
    "start": "47397",
    "end": "50223"
  },
  {
    "text": "of what AI-powered solutions can do.",
    "start": "50223",
    "end": "52509"
  },
  {
    "text": "Now, many generative AI tools are now being implemented as integrated elements",
    "start": "52680",
    "end": "57657"
  },
  {
    "text": "rather than standalone chatbots and the like.",
    "start": "57657",
    "end": "60568"
  },
  {
    "text": "They enhance and complement existing tools",
    "start": "60780",
    "end": "63602"
  },
  {
    "text": "rather than revolutionize or replace them.",
    "start": "63603",
    "end": "66200"
  },
  {
    "text": "So, think Copilot features in Microsoft Office,",
    "start": "66210",
    "end": "69428"
  },
  {
    "text": "or generative fill in Adobe Photoshop.",
    "start": "69428",
    "end": "72000"
  },
  {
    "text": "And embedding AI into everyday workflows like these",
    "start": "72330",
    "end": "75541"
  },
  {
    "text": "helps us to better understand what generative AI can",
    "start": "75541",
    "end": "78690"
  },
  {
    "text": "and cannot do in its current form.",
    "start": "78690",
    "end": "81920"
  },
  {
    "start": "82000",
    "end": "148000"
  },
  {
    "text": "And one area where generative AI is really extending its capabilities,",
    "start": "82320",
    "end": "87000"
  },
  {
    "text": "that is in multimodal AI.",
    "start": "87000",
    "end": "91649"
  },
  {
    "text": "Now AI multimodal models can take multiple layers of data as input,",
    "start": "94020",
    "end": "100060"
  },
  {
    "text": "and we already have interdisciplinary models today, like OpenAI's GPT-4v",
    "start": "100060",
    "end": "105979"
  },
  {
    "text": "and Google Gemini, that can move freely between natural language processing and computer vision tasks.",
    "start": "105980",
    "end": "111659"
  },
  {
    "text": "So users can, for example, like ask about an image and then receive a natural language answer.",
    "start": "111660",
    "end": "117060"
  },
  {
    "text": "Or they could ask out loud for instructions to, let's say, repair something",
    "start": "117060",
    "end": "121276"
  },
  {
    "text": "and receive visual aids alongside step-by-step text instructions.",
    "start": "121276",
    "end": "125625"
  },
  {
    "text": "New models are also bringing video into the fold.",
    "start": "126060",
    "end": "128789"
  },
  {
    "text": "And where this really gets interesting",
    "start": "128789",
    "end": "131123"
  },
  {
    "text": "is in how multimodal AI allows for models to process more diverse data inputs.",
    "start": "131123",
    "end": "136475"
  },
  {
    "text": "And that expands the information available for training and inference, for example, by",
    "start": "136770",
    "end": "141299"
  },
  {
    "text": "ingesting data captured by video cameras for holistic learning.",
    "start": "141299",
    "end": "144599"
  },
  {
    "text": "So there's lots more to come this year.",
    "start": "144600",
    "end": "147922"
  },
  {
    "start": "148000",
    "end": "250000"
  },
  {
    "text": "Now Trend #3, that relates to smaller models.",
    "start": "149000",
    "end": "154129"
  },
  {
    "text": "Now massive models, they jump-started the generative AI age, but they're not without drawbacks.",
    "start": "156170",
    "end": "161299"
  },
  {
    "text": "According to one estimate from the University of Washington,",
    "start": "161330",
    "end": "164058"
  },
  {
    "text": "training a single GPT-3 size model requires the yearly electricity consumption of over 1000 households.",
    "start": "164058",
    "end": "171000"
  },
  {
    "text": "And you might be thinking,",
    "start": "171440",
    "end": "172568"
  },
  {
    "text": "sure, that's training, we know that's expensive,",
    "start": "172568",
    "end": "175040"
  },
  {
    "text": "but what about inference?",
    "start": "175040",
    "end": "176836"
  },
  {
    "text": "Well, a standard day of chatGPT queries",
    "start": "177170",
    "end": "180269"
  },
  {
    "text": "rivals the daily energy consumption of something like 33,000 households.",
    "start": "180269",
    "end": "185778"
  },
  {
    "text": "Smaller models, meanwhile, are far less resource intensive.",
    "start": "186270",
    "end": "189889"
  },
  {
    "text": "Much of the ongoing innovation in LLMs is focused on yielding greater output from fewer parameters.",
    "start": "190220",
    "end": "196370"
  },
  {
    "text": "Now, GPT-4 that is rumored to have around 1.76 trillion parameters,",
    "start": "196790",
    "end": "204620"
  },
  {
    "text": "but many open source models have seen success with model sizes in the 3 to 17 billion parameter range.",
    "start": "204620",
    "end": "211698"
  },
  {
    "text": "So billions instead of trillions.",
    "start": "211700",
    "end": "213709"
  },
  {
    "text": "Now, in December last year, Mistral released Mixtral.",
    "start": "214550",
    "end": "218446"
  },
  {
    "text": "That is a mixture of experts, or an MoE, model",
    "start": "218540",
    "end": "221722"
  },
  {
    "text": "integrating eight neural networks, each with 7 billion parameters.",
    "start": "221723",
    "end": "225379"
  },
  {
    "text": "And Mistral claims that Mixtral not only outperforms the 70 billion parameter variant of Llama 2",
    "start": "225660",
    "end": "231081"
  },
  {
    "text": "on most benchmarks at six times faster inference speeds no less,",
    "start": "231081",
    "end": "235741"
  },
  {
    "text": "but that it even matches or outperforms OpenAI's far larger GPT-3.5 on most standard benchmarks.",
    "start": "235741",
    "end": "242689"
  },
  {
    "text": "Smaller parameter models can be run at lower cost",
    "start": "243410",
    "end": "246734"
  },
  {
    "text": "and run locally on many devices like personal laptops.",
    "start": "246734",
    "end": "250398"
  },
  {
    "start": "250000",
    "end": "295000"
  },
  {
    "text": "Which, conversely, brings us to Trend #4,",
    "start": "250910",
    "end": "254636"
  },
  {
    "text": "which is GPU and cloud costs.",
    "start": "254636",
    "end": "260000"
  },
  {
    "text": "The trend towards smaller models is being driven",
    "start": "261120",
    "end": "264608"
  },
  {
    "text": "as much by necessity as it is by entrepreneurial vigor.",
    "start": "264608",
    "end": "268510"
  },
  {
    "text": "The larger the model, the higher the requirement on GPUs for training and inference.",
    "start": "268680",
    "end": "273179"
  },
  {
    "text": "Relatively few AI adopters maintain their own infrastructure,",
    "start": "273630",
    "end": "277025"
  },
  {
    "text": "so that puts upward pressure on cloud costs",
    "start": "277025",
    "end": "280327"
  },
  {
    "text": "as providers update and optimize their own infrastructure to meet gen AI demands,",
    "start": "280327",
    "end": "285090"
  },
  {
    "text": "all while everybody is scrambling to obtain the necessary GPUs",
    "start": "285090",
    "end": "288632"
  },
  {
    "text": "to power the infrastructure.",
    "start": "288632",
    "end": "290400"
  },
  {
    "text": "If only these models were a bit more optimized,",
    "start": "291000",
    "end": "294333"
  },
  {
    "text": "they'd need less compute.",
    "start": "294333",
    "end": "295620"
  },
  {
    "start": "295000",
    "end": "359000"
  },
  {
    "text": "Yes, that is Trend #5, that is model optimization.",
    "start": "296450",
    "end": "303936"
  },
  {
    "text": "Now, this past year, we've already seen adoption of techniques for training,",
    "start": "304690",
    "end": "309000"
  },
  {
    "text": "tweaking and fine tuning pre-trained models like quantization.",
    "start": "309000",
    "end": "312949"
  },
  {
    "text": "You know how you can reduce the file size of an audio file",
    "start": "313120",
    "end": "315974"
  },
  {
    "text": "or a video file just by lowering its bitrate?",
    "start": "315974",
    "end": "318822"
  },
  {
    "text": "Well, quantization lowers the precision used to represent model data points.",
    "start": "319150",
    "end": "323139"
  },
  {
    "text": "For example, from 16 bit floating point to eight bit integer",
    "start": "323140",
    "end": "327132"
  },
  {
    "text": "to reduce memory usage and speed up inference.",
    "start": "327132",
    "end": "330379"
  },
  {
    "text": "Also, rather than directing directly fine tuning billions of model parameters,",
    "start": "330710",
    "end": "336091"
  },
  {
    "text": "something called LoRA, or Low-Rank Adaptation,",
    "start": "336091",
    "end": "339364"
  },
  {
    "text": "entails freezing pre-trained model weights and injecting trainable layers",
    "start": "339364",
    "end": "344075"
  },
  {
    "text": "in each transformer block,",
    "start": "344075",
    "end": "346213"
  },
  {
    "text": "and LoRA reduces the number of parameters that need to be updated,",
    "start": "346213",
    "end": "349135"
  },
  {
    "text": "which, in turn, dramatically speeds up fine tuning and",
    "start": "349135",
    "end": "352315"
  },
  {
    "text": "reduces the memory needed to store model updates.",
    "start": "352315",
    "end": "354614"
  },
  {
    "text": "So expect to see more model optimization techniques emerge this year.",
    "start": "354680",
    "end": "359211"
  },
  {
    "start": "359000",
    "end": "459000"
  },
  {
    "text": "Okay, that's, let's knock out a few more.",
    "start": "360340",
    "end": "363000"
  },
  {
    "text": "And the next one is all about custom local models.",
    "start": "363400",
    "end": "369327"
  },
  {
    "text": "Open source models afford the opportunity to develop powerful custom AI models.",
    "start": "370740",
    "end": "376379"
  },
  {
    "text": "That means trained on an organization's proprietary data",
    "start": "376380",
    "end": "379762"
  },
  {
    "text": "and fine-tuned for their specific needs.",
    "start": "379762",
    "end": "382229"
  },
  {
    "text": "Keeping AI training and inference local",
    "start": "382800",
    "end": "384998"
  },
  {
    "text": "avoids the risk of proprietary data or sensitive personal information",
    "start": "384998",
    "end": "388106"
  },
  {
    "text": "being used to train closed source models",
    "start": "388106",
    "end": "391113"
  },
  {
    "text": "or otherwise pass through to the hands of third parties.",
    "start": "391114",
    "end": "394000"
  },
  {
    "text": "And then using things like RAG, or Retrieval Augmented Generation,",
    "start": "394350",
    "end": "397967"
  },
  {
    "text": "to access relevant information,",
    "start": "397967",
    "end": "399838"
  },
  {
    "text": "rather than storing all of that information directly within the LLM itself,",
    "start": "399838",
    "end": "404205"
  },
  {
    "text": "that helps to reduce model size.",
    "start": "404205",
    "end": "405899"
  },
  {
    "text": "Trend #7, that is virtual agents.",
    "start": "407100",
    "end": "412766"
  },
  {
    "text": "Now, that goes beyond the straightforward customer experience chatbot,",
    "start": "413700",
    "end": "419650"
  },
  {
    "text": "because virtual agents relate to task automation,",
    "start": "419650",
    "end": "423458"
  },
  {
    "text": "where agents will get stuff done for you,",
    "start": "423458",
    "end": "426205"
  },
  {
    "text": "they'll make reservations, or they'll complete checklist tasks,",
    "start": "426205",
    "end": "430241"
  },
  {
    "text": "or they'll connect to other services.",
    "start": "430241",
    "end": "432029"
  },
  {
    "text": "So, lots more to come there.",
    "start": "432210",
    "end": "434186"
  },
  {
    "text": "Trend #8, that is all about regulation.",
    "start": "434740",
    "end": "439720"
  },
  {
    "text": "Now, in December of last year,",
    "start": "440470",
    "end": "442793"
  },
  {
    "text": "the European Union reached a provisional agreement on the Artificial Intelligence Act.",
    "start": "442793",
    "end": "447143"
  },
  {
    "text": "Also, the role of copyrighted material",
    "start": "447670",
    "end": "450148"
  },
  {
    "text": "in the training of AI models used for content generation",
    "start": "450148",
    "end": "452745"
  },
  {
    "text": "remains a hotly contested issue.",
    "start": "452745",
    "end": "454861"
  },
  {
    "text": "So expect much more to come in the area of regulation.",
    "start": "454960",
    "end": "458876"
  },
  {
    "start": "459000",
    "end": "574000"
  },
  {
    "text": "And finally, we're at Trend #9, which is the continuance of something called shadow AI.",
    "start": "459450",
    "end": "469639"
  },
  {
    "text": "What's that?",
    "start": "470230",
    "end": "471220"
  },
  {
    "text": "Well, it's the unofficial",
    "start": "471220",
    "end": "473512"
  },
  {
    "text": "personal use of AI in the workplace by employees.",
    "start": "473512",
    "end": "477070"
  },
  {
    "text": "It's about using gen AI",
    "start": "477430",
    "end": "479235"
  },
  {
    "text": "without going through IT for approval or oversight.",
    "start": "479235",
    "end": "482439"
  },
  {
    "text": "Now, in one study from Ernst and Young,",
    "start": "482470",
    "end": "484774"
  },
  {
    "text": "90% of respondents said they used AI at work.",
    "start": "484774",
    "end": "488018"
  },
  {
    "text": "But without corporate AI policies in place",
    "start": "488260",
    "end": "490929"
  },
  {
    "text": "- and, importantly, policies that are observed -",
    "start": "490929",
    "end": "494258"
  },
  {
    "text": "this can lead to issues regarding security,",
    "start": "494259",
    "end": "497665"
  },
  {
    "text": "privacy, compliance, that sort of thing.",
    "start": "497665",
    "end": "499965"
  },
  {
    "text": "So, for example, an employee might unknowingly feed trade secrets",
    "start": "500140",
    "end": "504000"
  },
  {
    "text": "to a public-facing AI model that continually trains the model on user input.",
    "start": "504000",
    "end": "508482"
  },
  {
    "text": "Or they might use copyright protected material to train a proprietary model,",
    "start": "508870",
    "end": "514096"
  },
  {
    "text": "and then that could expose the company to legal action.",
    "start": "514096",
    "end": "517434"
  },
  {
    "text": "The dangers of generative AI arise kind of almost in a linear line",
    "start": "517809",
    "end": "522213"
  },
  {
    "text": "with its capabilities, and that line's going up.",
    "start": "522213",
    "end": "524950"
  },
  {
    "text": "With great power comes great responsibility.",
    "start": "525910",
    "end": "529000"
  },
  {
    "text": "So, there you have it.",
    "start": "529450",
    "end": "530529"
  },
  {
    "text": "Nine important AI trends for this year.",
    "start": "530860",
    "end": "533678"
  },
  {
    "text": "But why nine?",
    "start": "534160",
    "end": "536795"
  },
  {
    "text": "Don't these things almost always come in tens?",
    "start": "537060",
    "end": "538499"
  },
  {
    "text": "Why, yes, yes they do.",
    "start": "538499",
    "end": "540749"
  },
  {
    "text": "And that's YOUR job.",
    "start": "540750",
    "end": "543179"
  },
  {
    "text": "What is the one AI trend for 2024 that we haven't covered here?",
    "start": "543630",
    "end": "549359"
  },
  {
    "text": "The missing 10th trend.",
    "start": "549660",
    "end": "552120"
  },
  {
    "text": "Let us know in the comments.",
    "start": "552900",
    "end": "554830"
  },
  {
    "text": "If you have any questions, please drop us a line below.",
    "start": "555630",
    "end": "558200"
  },
  {
    "text": "And if you want to see more videos like this in the future,",
    "start": "558210",
    "end": "561234"
  },
  {
    "text": "please like and subscribe.",
    "start": "561234",
    "end": "563157"
  },
  {
    "text": "Thanks for watching.",
    "start": "563430",
    "end": "564430"
  }
]
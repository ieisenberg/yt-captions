[
  {
    "start": "0",
    "end": "72000"
  },
  {
    "text": "What's the most exciting thing to\ncome out of IBM Think this year?",
    "start": "0",
    "end": "3030"
  },
  {
    "text": "Kate Soule is Director of Technical\nProduct Management for Granite.",
    "start": "3330",
    "end": "6149"
  },
  {
    "text": "Kate, welcome back.",
    "start": "6150",
    "end": "7050"
  },
  {
    "text": "Uh, what's your pick for IBM?",
    "start": "7080",
    "end": "8340"
  },
  {
    "text": "Think",
    "start": "8340",
    "end": "8790"
  },
  {
    "text": "My pick is the research keynotes.",
    "start": "8790",
    "end": "10889"
  },
  {
    "text": "We talked about a new wave of computing,\nso we've got traditional classical",
    "start": "10890",
    "end": "14550"
  },
  {
    "text": "computing, we've got quantum computing\nand at Think we announced a new way of",
    "start": "14550",
    "end": "18990"
  },
  {
    "text": "building with models generative computing.",
    "start": "18990",
    "end": "21029"
  },
  {
    "text": "It's really exciting.",
    "start": "21060",
    "end": "21869"
  },
  {
    "text": "Kaoutar El Maghraoui is a Principal\nResearch Scientist and Manager",
    "start": "21870",
    "end": "25110"
  },
  {
    "text": "for Hybrid Cloud platform.",
    "start": "25110",
    "end": "26670"
  },
  {
    "text": "Kaoutar, welcome back.",
    "start": "26670",
    "end": "27630"
  },
  {
    "text": "What was your favorite?",
    "start": "27630",
    "end": "28410"
  },
  {
    "text": "My favorite was also the generative\ncomputing part, but also the launch",
    "start": "28410",
    "end": "32255"
  },
  {
    "text": "of a lot of a AI agents and, uh,\nat what's our watsonx Orchestrate",
    "start": "32255",
    "end": "37205"
  },
  {
    "text": "platform, over 150 enterprise ready",
    "start": "37235",
    "end": "39965"
  },
  {
    "text": "AI agents.",
    "start": "39965",
    "end": "40625"
  },
  {
    "text": "That's really huge.",
    "start": "40625",
    "end": "41465"
  },
  {
    "text": "Yeah, that is huge.",
    "start": "41675",
    "end": "42305"
  },
  {
    "text": "And we will talk about that.",
    "start": "42305",
    "end": "43355"
  },
  {
    "text": "And finally, last but not least is\nSkyler Speakman Senior Research Scientist,",
    "start": "43355",
    "end": "46989"
  },
  {
    "text": "Skyler watching, uh, the conference.",
    "start": "46990",
    "end": "49060"
  },
  {
    "text": "What was your favorite?",
    "start": "49060",
    "end": "49930"
  },
  {
    "text": "Yeah, a non-technical take on\nthis is just how much fun they",
    "start": "49990",
    "end": "53950"
  },
  {
    "text": "were having during the keynote.",
    "start": "53950",
    "end": "55060"
  },
  {
    "text": "Arvind marched a mascot penguin across\nthe stage and the crowd loved it.",
    "start": "55060",
    "end": "60610"
  },
  {
    "text": "Uh, so it was really cool to see\npeople having fun, um, up on stage",
    "start": "60760",
    "end": "64030"
  },
  {
    "text": "during his keynotes, penguins,\nagents, and programming all that.",
    "start": "64030",
    "end": "66970"
  },
  {
    "text": "And more on today's Mixture of Experts.",
    "start": "66970",
    "end": "70150"
  },
  {
    "start": "72000",
    "end": "567000"
  },
  {
    "text": "I am Tim Hwang and welcome\nto Mixture of Experts.",
    "start": "74695",
    "end": "76515"
  },
  {
    "text": "Each week, MOE brings together the\nsmartest, most talented, most wonderful",
    "start": "76545",
    "end": "80715"
  },
  {
    "text": "experts in all of artificial intelligence,\nuh, to talk a little bit about the",
    "start": "80715",
    "end": "84645"
  },
  {
    "text": "biggest news, uh, in the sector.",
    "start": "84645",
    "end": "86803"
  },
  {
    "text": "And this is a big episode.",
    "start": "86895",
    "end": "87825"
  },
  {
    "text": "We've got a lot that we need to\ntalk about as per usual, a really",
    "start": "87825",
    "end": "90225"
  },
  {
    "text": "fascinating story coming outta the New\nYork Times about AI and hallucination.",
    "start": "90225",
    "end": "93615"
  },
  {
    "text": "A bunch of news coming out of OpenAI, uh,\nin terms of its corporate organization",
    "start": "93914",
    "end": "97664"
  },
  {
    "text": "and its recent acquisition of Windsurf.",
    "start": "97664",
    "end": "99495"
  },
  {
    "text": "But first, uh, I wanted to start\nwith IBM Think, which was the",
    "start": "99845",
    "end": "103625"
  },
  {
    "text": "big IBM conference of the year.",
    "start": "103625",
    "end": "105365"
  },
  {
    "text": "Tons and tons of announcements\nand things to go through.",
    "start": "105605",
    "end": "108695"
  },
  {
    "text": "But I think, uh, the one that was most\nimportant to me, of course, was that",
    "start": "108995",
    "end": "112295"
  },
  {
    "text": "I, and I do wanna start with is Kate, I\nrealize, uh, you have a book coming out.",
    "start": "112295",
    "end": "115505"
  },
  {
    "text": "I. That was also kind of announced\nthat IBM Think so maybe I'll",
    "start": "115505",
    "end": "118329"
  },
  {
    "text": "just start there for the plug.",
    "start": "118330",
    "end": "119680"
  },
  {
    "text": "Yeah, no thanks Tim.",
    "start": "120250",
    "end": "121120"
  },
  {
    "text": "So we did, uh, release a book.",
    "start": "121120",
    "end": "123040"
  },
  {
    "text": "I've got it here with me.",
    "start": "123040",
    "end": "124270"
  },
  {
    "text": "It's called AI Value Creators.",
    "start": "124270",
    "end": "126130"
  },
  {
    "text": "Really excited, uh, to be\nable to share it more broadly.",
    "start": "126130",
    "end": "128950"
  },
  {
    "text": "A lot of what we talked about at Think\nparticularly, uh, in some of the future",
    "start": "128950",
    "end": "133569"
  },
  {
    "text": "looking sessions like on generative\ncomputing, we actually have whole",
    "start": "133570",
    "end": "136570"
  },
  {
    "text": "chapters dedicated to, in the book.",
    "start": "136570",
    "end": "138580"
  },
  {
    "text": "It's really all about how can, you know,",
    "start": "138970",
    "end": "140890"
  },
  {
    "text": "folks looking to not just build\nwith generative AI, but kind of",
    "start": "141575",
    "end": "144935"
  },
  {
    "text": "build a competitive moat with\ngenerative AI, get the most value",
    "start": "144935",
    "end": "148114"
  },
  {
    "text": "and, and invest in strategic places.",
    "start": "148115",
    "end": "150635"
  },
  {
    "text": "So really, really excited\nfor folks to check it out.",
    "start": "150905",
    "end": "152915"
  },
  {
    "text": "We actually have a download link\nfor all of our Mixture of Expert",
    "start": "152915",
    "end": "156364"
  },
  {
    "text": "listeners, so we'll include that in\nthe show notes and would love any,",
    "start": "156365",
    "end": "159965"
  },
  {
    "text": "uh, feedback the team has, uh, as\nthey, they read through the content.",
    "start": "159965",
    "end": "163265"
  },
  {
    "text": "That's great.",
    "start": "163355",
    "end": "163925"
  },
  {
    "text": "And Kate, I guess for those who\nare kind of just getting their head",
    "start": "163925",
    "end": "166055"
  },
  {
    "text": "around generative computing.",
    "start": "166055",
    "end": "167704"
  },
  {
    "text": "What's the general concept there?",
    "start": "167720",
    "end": "168830"
  },
  {
    "text": "Do you wanna give us like a little\nbit of a flavor of how, you know, it",
    "start": "168830",
    "end": "171500"
  },
  {
    "text": "sounds like it's a big part of the\nkeynote, it's a big part of the book.",
    "start": "171500",
    "end": "173690"
  },
  {
    "text": "Just kind of interested in how all\nthese pieces are fitting together and",
    "start": "173690",
    "end": "175850"
  },
  {
    "text": "well, what is generative computing?",
    "start": "176120",
    "end": "177530"
  },
  {
    "text": "Yeah, so I think at the end of the\nday, it's really just trying to",
    "start": "177710",
    "end": "180770"
  },
  {
    "text": "bring some of generative AI back\nto the realm of computer science.",
    "start": "180770",
    "end": "185480"
  },
  {
    "text": "You know, if you look at how we've emerged\nbuilding, uh, applications and agents with",
    "start": "185480",
    "end": "190970"
  },
  {
    "text": "LLMs today, it's all basically a form of",
    "start": "190970",
    "end": "193370"
  },
  {
    "text": "prompt engineering where we end\nup with these really massive, you",
    "start": "193560",
    "end": "197609"
  },
  {
    "text": "know, pages and pages of prompts.",
    "start": "197609",
    "end": "199530"
  },
  {
    "text": "We call them essay prompts\nin our book, where it can be",
    "start": "199530",
    "end": "202680"
  },
  {
    "text": "very difficult to maintain.",
    "start": "202680",
    "end": "204239"
  },
  {
    "text": "These prompts are very brittle.",
    "start": "204240",
    "end": "205710"
  },
  {
    "text": "You look at how they're written, they're\nkind of like over optimized and force",
    "start": "205710",
    "end": "209280"
  },
  {
    "text": "fit for a specific model, and it's\njust not very, uh, sustainable, secure.",
    "start": "209280",
    "end": "213540"
  },
  {
    "text": "There's all sorts of issues.",
    "start": "213540",
    "end": "215730"
  },
  {
    "text": "If we think about how we build in\na more computer science forward",
    "start": "216065",
    "end": "219575"
  },
  {
    "text": "discipline, you know, there needs to\nbe abstractions for key activities",
    "start": "219575",
    "end": "223535"
  },
  {
    "text": "that we want a model to take on.",
    "start": "223535",
    "end": "225215"
  },
  {
    "text": "And there needs to be ways to set,\nyou know, clear control flow of how",
    "start": "225605",
    "end": "229954"
  },
  {
    "text": "we build programs versus, you know,\ninstead of asking a model, first do",
    "start": "229954",
    "end": "233375"
  },
  {
    "text": "this, then do this, then do this.",
    "start": "233375",
    "end": "235024"
  },
  {
    "text": "You know, we can actually",
    "start": "235385",
    "end": "236120"
  },
  {
    "text": "build a lot of the same code.",
    "start": "236455",
    "end": "237715"
  },
  {
    "text": "We don't need to ask a\nmodel to do everything.",
    "start": "237715",
    "end": "239965"
  },
  {
    "text": "So it's really about how can we take\nsome of these best practices from",
    "start": "240475",
    "end": "243985"
  },
  {
    "text": "software engineering and computer\nscience and bring in all the power",
    "start": "244315",
    "end": "247615"
  },
  {
    "text": "that models have to be able to express,\nuh, natural language and run functions",
    "start": "247615",
    "end": "253315"
  },
  {
    "text": "in natural language and bring them\ntogether in a much more maintainable way.",
    "start": "253315",
    "end": "257815"
  },
  {
    "text": "Nice.",
    "start": "257815",
    "end": "258144"
  },
  {
    "text": "Yeah, that really is, I think the\nfuture is just like now moving",
    "start": "258144",
    "end": "260424"
  },
  {
    "text": "into like, how do we make this\nproduction, you know, at scale.",
    "start": "260425",
    "end": "263125"
  },
  {
    "text": "So it's very exciting to see.",
    "start": "263125",
    "end": "264385"
  },
  {
    "text": "Absolutely.",
    "start": "264385",
    "end": "264885"
  },
  {
    "text": "And I think there's a lot also that\ngoes on when you start to build",
    "start": "265145",
    "end": "268085"
  },
  {
    "text": "things in a little bit more structure\nwhere you can take advantage of a",
    "start": "268085",
    "end": "272134"
  },
  {
    "text": "lot of techniques that are coming\nout in the field around inference",
    "start": "272135",
    "end": "275255"
  },
  {
    "text": "scaling and inference time compute.",
    "start": "275255",
    "end": "277025"
  },
  {
    "text": "So instead of running one big,\nmassive prompt once, how do you",
    "start": "277445",
    "end": "280985"
  },
  {
    "text": "break it up into smaller parts, run\nmultiple generations and use that to",
    "start": "280985",
    "end": "286805"
  },
  {
    "text": "create an even richer response often\nin far less time, far less compute.",
    "start": "287035",
    "end": "291385"
  },
  {
    "text": "Uh, and so all of that and more\nwe, we really get into in the book.",
    "start": "291805",
    "end": "294565"
  },
  {
    "text": "That's great.",
    "start": "294625",
    "end": "295195"
  },
  {
    "text": "Yeah.",
    "start": "295195",
    "end": "295345"
  },
  {
    "text": "Well, I encourage\neverybody to check it out.",
    "start": "295345",
    "end": "296695"
  },
  {
    "text": "Um, I think the next one I\nwant to touch on is Kaoutar.",
    "start": "296785",
    "end": "299105"
  },
  {
    "text": "You have already won the MOE award for\nmentioning agent first in the episode.",
    "start": "299125",
    "end": "303235"
  },
  {
    "text": "Um, but, uh, but it is genuinely exciting.",
    "start": "303595",
    "end": "305725"
  },
  {
    "text": "I mean, in some ways it's no surprise\nthat IBM would be announcing a, a a a",
    "start": "305725",
    "end": "309835"
  },
  {
    "text": "kind of like product leap in agents.",
    "start": "309835",
    "end": "311694"
  },
  {
    "text": "But do you wanna talk a little\nbit about what's happening and,",
    "start": "311695",
    "end": "313615"
  },
  {
    "text": "and why you find it exciting?",
    "start": "313615",
    "end": "314544"
  },
  {
    "text": "Yes, definitely.",
    "start": "315020",
    "end": "316009"
  },
  {
    "text": "So IBM, you know, at Think introduced, you\nknow, over 150 pre-built AI agents, um,",
    "start": "316010",
    "end": "322070"
  },
  {
    "text": "through the watsonx Orchestrate platform.",
    "start": "322100",
    "end": "324290"
  },
  {
    "text": "And I, I thought that's really\nhuge, you know, enabling, you",
    "start": "324590",
    "end": "327050"
  },
  {
    "text": "know, basically enterprises to\ndeploy AI driven workloads rapidly.",
    "start": "327050",
    "end": "330650"
  },
  {
    "text": "So these agents, they're.",
    "start": "330650",
    "end": "331790"
  },
  {
    "text": "They're designed to, to be kind of\nprebuilt, uh, uh, you can integrate them",
    "start": "332105",
    "end": "337265"
  },
  {
    "text": "seamlessly with popular enterprise tools\nlike Salesforce and Workday and Adobe, and",
    "start": "337265",
    "end": "343535"
  },
  {
    "text": "allows, you know, businesses to automate\ntasks and enhance also productivity.",
    "start": "343535",
    "end": "347315"
  },
  {
    "text": "So.",
    "start": "347675",
    "end": "348185"
  },
  {
    "text": "And you know, this is, you know, kind of\nshowcasing our approach, IBM's approach to",
    "start": "348475",
    "end": "353065"
  },
  {
    "text": "support the creation of custom AI agents.",
    "start": "353065",
    "end": "355435"
  },
  {
    "text": "I think, which is also very important,\nrelying first on the Granite models",
    "start": "355435",
    "end": "359845"
  },
  {
    "text": "as well as models from Meta and Mistral.",
    "start": "360145",
    "end": "362514"
  },
  {
    "text": "So it's also modular approach\nthat provides you flexibility,",
    "start": "362515",
    "end": "366295"
  },
  {
    "text": "that also facilitates, you know,\ntailoring, you know, your solutions",
    "start": "366505",
    "end": "369985"
  },
  {
    "text": "for diverse business needs.",
    "start": "369985",
    "end": "371574"
  },
  {
    "text": "I think that that was\nalso very, very important.",
    "start": "371875",
    "end": "374335"
  },
  {
    "text": "Um.",
    "start": "374635",
    "end": "375175"
  },
  {
    "text": "So basically, you know, this flexibility\nthat provides is not just about, you",
    "start": "375975",
    "end": "380085"
  },
  {
    "text": "know, one, you know, uh, one approach,\nbut you know, you can integrate different",
    "start": "380085",
    "end": "384705"
  },
  {
    "text": "models, you know, in a, in a flexible\nand modular way and allows you also",
    "start": "384705",
    "end": "389414"
  },
  {
    "text": "to customize in addition to pre the\nprebuilt the existing AI agents that",
    "start": "389415",
    "end": "394275"
  },
  {
    "text": "you can just add and, uh, customize.",
    "start": "394275",
    "end": "396854"
  },
  {
    "text": "Yeah, for sure.",
    "start": "396945",
    "end": "397515"
  },
  {
    "text": "And I did wanna touch on that.",
    "start": "397515",
    "end": "398535"
  },
  {
    "text": "I mean, Skyler, before\nwe talk about the mascot.",
    "start": "398535",
    "end": "400785"
  },
  {
    "text": "Which I do want to hear more about.",
    "start": "400785",
    "end": "402010"
  },
  {
    "text": "But, um, I guess, uh, Kate, uh,\nthe mention of Granite, I guess",
    "start": "402010",
    "end": "405219"
  },
  {
    "text": "you've been name checked, so I do\ngotta kind of bring it back to you.",
    "start": "405489",
    "end": "408250"
  },
  {
    "text": "Um, there, I understand there is\na announcement coming out about",
    "start": "408580",
    "end": "411340"
  },
  {
    "text": "Granite actually from IBM Think",
    "start": "411340",
    "end": "413020"
  },
  {
    "text": "so on Friday actually.",
    "start": "413229",
    "end": "415359"
  },
  {
    "text": "So we did a sneak, uh, preview.",
    "start": "415359",
    "end": "417930"
  },
  {
    "text": "We didn't tell anyone\nwe were gonna do this.",
    "start": "417930",
    "end": "419699"
  },
  {
    "text": "We released a preview of our\nGranite 4  models, and we got to",
    "start": "419700",
    "end": "422400"
  },
  {
    "text": "talk about them a lot at Think.",
    "start": "422400",
    "end": "424199"
  },
  {
    "text": "That was also a really exciting\npart of the conference.",
    "start": "424200",
    "end": "427080"
  },
  {
    "text": "These models, if you, we can, um, post\na link to the blog that that talks",
    "start": "427080",
    "end": "430770"
  },
  {
    "text": "about the new architecture behind them.",
    "start": "430770",
    "end": "432449"
  },
  {
    "text": "But basically they're a mixture\nof experts hybrid, uh, model.",
    "start": "432840",
    "end": "437550"
  },
  {
    "text": "So they are very fast,\nvery efficient.",
    "start": "437760",
    "end": "441000"
  },
  {
    "text": "The tiny preview that we just released\nonly takes 15 gigs of memory.",
    "start": "441465",
    "end": "445125"
  },
  {
    "text": "So, uh, even running, you\nknow, 1 20 k context length",
    "start": "445125",
    "end": "448605"
  },
  {
    "text": "with multiple concurrencies.",
    "start": "448605",
    "end": "449955"
  },
  {
    "text": "So we think these models are gonna\nbe really efficient and excellent",
    "start": "450225",
    "end": "454455"
  },
  {
    "text": "counterpoints to complement much\nlarger models that are being deployed.",
    "start": "454485",
    "end": "457694"
  },
  {
    "text": "You know, having those bigger models\nand then the smaller efficient Granite",
    "start": "457965",
    "end": "460455"
  },
  {
    "text": "models working together hand in hand.",
    "start": "460455",
    "end": "461985"
  },
  {
    "text": "I really like the emphasis here\non smaller domain specific and",
    "start": "462185",
    "end": "465995"
  },
  {
    "text": "also the energy efficiency.",
    "start": "465995",
    "end": "467735"
  },
  {
    "text": "'cause you know, if you see these\nmodels, they, you know, the, the sizes,",
    "start": "468095",
    "end": "470795"
  },
  {
    "text": "they range from three to 20 billion\nparameters as opposed to what you see,",
    "start": "470795",
    "end": "474305"
  },
  {
    "text": "like, uh, you know, trillion parameters\nor many billion parameters in the other,",
    "start": "474305",
    "end": "478595"
  },
  {
    "text": "in the open source or in other models.",
    "start": "478595",
    "end": "480665"
  },
  {
    "text": "So it's, it's, you know, the, the,\nthe, the key thing here is, you know,",
    "start": "480935",
    "end": "484385"
  },
  {
    "text": "how do you build these things that\nare optimized for specific industries?",
    "start": "484595",
    "end": "487925"
  },
  {
    "text": "And offering cost effective and\nefficient alternative to the",
    "start": "488270",
    "end": "491360"
  },
  {
    "text": "larger general purpose model.",
    "start": "491360",
    "end": "493400"
  },
  {
    "text": "So I really like, you know, the,\nuh, focus on the efficiency here.",
    "start": "493400",
    "end": "496250"
  },
  {
    "text": "Yeah, for sure.",
    "start": "496340",
    "end": "497090"
  },
  {
    "text": "So, Skyler, uh, curious if you wanna\ntell us more about the mascot, but I",
    "start": "497420",
    "end": "500180"
  },
  {
    "text": "think in general, like, I, I thought what\nwas very striking about your response",
    "start": "500180",
    "end": "503060"
  },
  {
    "text": "was you're like, it's so much fun.",
    "start": "503060",
    "end": "505130"
  },
  {
    "text": "Uh, which I think is actually like\nan important part of all this.",
    "start": "505490",
    "end": "508009"
  },
  {
    "text": "Um, but exactly.",
    "start": "508040",
    "end": "509300"
  },
  {
    "text": "To kind of hear what you saw.",
    "start": "509360",
    "end": "510289"
  },
  {
    "text": "Yeah, I know.",
    "start": "510290",
    "end": "510860"
  },
  {
    "text": "I think that just sort of captures it.",
    "start": "510860",
    "end": "512510"
  },
  {
    "text": "They had kind of this transition\nfrom having these Ferrari race.",
    "start": "512510",
    "end": "516680"
  },
  {
    "text": "Car team members up on stage talking\nabout how they're using IBM Tech.",
    "start": "516680",
    "end": "520265"
  },
  {
    "text": "And then there was this, uh, pivot\nto IBM's relationship with Red Hat,",
    "start": "520924",
    "end": "524584"
  },
  {
    "text": "and of course, Linux more broadly,\nand a penguin mascot just starts",
    "start": "524584",
    "end": "528755"
  },
  {
    "text": "walking across the back of the stage.",
    "start": "528755",
    "end": "530405"
  },
  {
    "text": "Great.",
    "start": "531334",
    "end": "531844"
  },
  {
    "text": "So hats off to whoever had that planned.",
    "start": "531844",
    "end": "533704"
  },
  {
    "text": "Maybe it was last minute.",
    "start": "533704",
    "end": "534844"
  },
  {
    "text": "Maybe that's been someone's\ndream for a, for a year.",
    "start": "534844",
    "end": "537365"
  },
  {
    "text": "I don't know.",
    "start": "537365",
    "end": "537935"
  },
  {
    "text": "But I thought it was, uh,\nI thought it was well done.",
    "start": "538110",
    "end": "540149"
  },
  {
    "text": "Yeah, for sure.",
    "start": "540480",
    "end": "541290"
  },
  {
    "text": "And I do like, it's like one of the\nthings I'm really fascinated by is",
    "start": "541290",
    "end": "543930"
  },
  {
    "text": "like how all the companies that are\nkind of in the AI space are kind of",
    "start": "543930",
    "end": "547470"
  },
  {
    "text": "coming up with their own brands about\nhow they present AI stuff, right?",
    "start": "547470",
    "end": "550860"
  },
  {
    "text": "Like some companies are very\nserious and some companies are very",
    "start": "550860",
    "end": "553529"
  },
  {
    "text": "technical, uh, uh, like in, like,\nin kind of like a very granular,",
    "start": "553530",
    "end": "557040"
  },
  {
    "text": "kind of like almost academic way.",
    "start": "557040",
    "end": "558420"
  },
  {
    "text": "And it's, it's kind of fun seeing\nIBM kind of take like a certain",
    "start": "558420",
    "end": "560850"
  },
  {
    "text": "level of fun in terms of like how to\npresent and talk about this stuff.",
    "start": "560850",
    "end": "563790"
  },
  {
    "text": "So it's very cool.",
    "start": "564000",
    "end": "564750"
  },
  {
    "start": "567000",
    "end": "1163000"
  },
  {
    "text": "I'm gonna move us on\nto, uh, our next topic.",
    "start": "569670",
    "end": "572160"
  },
  {
    "text": "Um, super interesting article that\nkind of hit the New York Times, uh,",
    "start": "572190",
    "end": "575730"
  },
  {
    "text": "I believe this week or last week.",
    "start": "575730",
    "end": "577620"
  },
  {
    "text": "Um, focusing on sort of the kind\nof rise of hallucinations with, um.",
    "start": "577680",
    "end": "583020"
  },
  {
    "text": "the emergence of reasoning models.",
    "start": "583229",
    "end": "585060"
  },
  {
    "text": "Um, and we haven't talked about\nhallucinations on the show for a",
    "start": "585479",
    "end": "587819"
  },
  {
    "text": "little while, but obviously it kind\nof remains a sort of big question",
    "start": "587819",
    "end": "591060"
  },
  {
    "text": "and a big problem that people are\nsort of working on in the space.",
    "start": "591060",
    "end": "594510"
  },
  {
    "text": "Um, and I guess maybe Skyler, maybe\nI'll stay with you, is do you have",
    "start": "594569",
    "end": "598589"
  },
  {
    "text": "an intuition for why it seems so?",
    "start": "598589",
    "end": "600688"
  },
  {
    "text": "The article seem to argue that\nlike reasoning models are like",
    "start": "600689",
    "end": "603300"
  },
  {
    "text": "newly hallucinatory in a way that\nwe are learning to deal with.",
    "start": "603300",
    "end": "606839"
  },
  {
    "text": "And is that, is that the case?",
    "start": "607425",
    "end": "609105"
  },
  {
    "text": "And do you have an intuition for",
    "start": "609105",
    "end": "610005"
  },
  {
    "text": "why hallucinations themselves are not new?",
    "start": "610005",
    "end": "612975"
  },
  {
    "text": "Um, it does appear that\nthey are on the rise.",
    "start": "613545",
    "end": "616725"
  },
  {
    "text": "There was this great contra\nposition of they had asked, uh, you",
    "start": "616725",
    "end": "620324"
  },
  {
    "text": "know, a spokesperson for comment.",
    "start": "620325",
    "end": "621495"
  },
  {
    "text": "They said, no, they're,\nthey're not on the rise.",
    "start": "621495",
    "end": "623235"
  },
  {
    "text": "But if you go and check the receipts\nand look at the model cards that",
    "start": "623235",
    "end": "626505"
  },
  {
    "text": "OpenAI also produces, you do see,\no4 mini hallucinating more than",
    "start": "626505",
    "end": "631295"
  },
  {
    "text": "o3 and o3 hallucinating more than\no1 is like definitely on the rise.",
    "start": "631295",
    "end": "635135"
  },
  {
    "text": "Yes it is.",
    "start": "635285",
    "end": "636425"
  },
  {
    "text": "Um, and but they're also very clear\nto say they don't know why and.",
    "start": "636785",
    "end": "640360"
  },
  {
    "text": "I, I'm also gonna draw a blank.",
    "start": "641205",
    "end": "642735"
  },
  {
    "text": "Sorry.",
    "start": "642735",
    "end": "643095"
  },
  {
    "text": "I'm not quite sure.",
    "start": "643095",
    "end": "644235"
  },
  {
    "text": "I don't have any really gut\ninstincts as to why those are",
    "start": "644235",
    "end": "647024"
  },
  {
    "text": "increasing accuracies going up.",
    "start": "647025",
    "end": "649095"
  },
  {
    "text": "Uh, they're getting better at math,\nbut hallucinations are also increasing,",
    "start": "649275",
    "end": "652755"
  },
  {
    "text": "so it is something that really does\nneed a lot more attention paid to it.",
    "start": "652755",
    "end": "656145"
  },
  {
    "text": "Yeah, and I think this is one of the\nreally interesting things is like, I feel",
    "start": "656205",
    "end": "659085"
  },
  {
    "text": "like the AI era is teaching us all the\nways in which intelligence is very lumpy.",
    "start": "659085",
    "end": "663375"
  },
  {
    "text": "You know, like the model gets really good\nat one thing, but, and you kind of expect",
    "start": "663735",
    "end": "666495"
  },
  {
    "text": "that it'll be good at everything else in\na well-rounded way, but like that kind of.",
    "start": "666495",
    "end": "669855"
  },
  {
    "text": "It doesn't seem to be the case.",
    "start": "669925",
    "end": "671935"
  },
  {
    "text": "Um, I guess, uh, Kate, like\nI'm curious if you've got",
    "start": "671995",
    "end": "675055"
  },
  {
    "text": "intuitions or similar like Skyler.",
    "start": "675055",
    "end": "676563"
  },
  {
    "text": "You're like, I, I don't know.",
    "start": "676584",
    "end": "677694"
  },
  {
    "text": "It's just weird.",
    "start": "677694",
    "end": "678233"
  },
  {
    "text": "Yeah, I mean, I will, uh, give,\ngive my thoughts obviously.",
    "start": "679135",
    "end": "683334"
  },
  {
    "text": "I think there's a lot that's\nstill left to be discovered,",
    "start": "683545",
    "end": "686214"
  },
  {
    "text": "but to me it seems like it's a",
    "start": "686305",
    "end": "688795"
  },
  {
    "text": "kind of classic example of\njust misaligned incentives.",
    "start": "689250",
    "end": "692490"
  },
  {
    "text": "So we've got, you know, these models are\ngoing through extensive reinforcement",
    "start": "692580",
    "end": "698430"
  },
  {
    "text": "learning pipelines in order to improve\nthe model's verbosity among other",
    "start": "698430",
    "end": "703860"
  },
  {
    "text": "things to get it to say more and\nto try and craft these well-rounded",
    "start": "703860",
    "end": "708480"
  },
  {
    "text": "responses that humans will prefer.",
    "start": "708480",
    "end": "710730"
  },
  {
    "text": "And, you know, there is\nsome degree of, you know,",
    "start": "711330",
    "end": "714960"
  },
  {
    "text": "any human likes to hear people\nwho are persuasive speakers talk.",
    "start": "715230",
    "end": "719430"
  },
  {
    "text": "We're not very good at fact\nchecking things, and we don't",
    "start": "719430",
    "end": "722670"
  },
  {
    "text": "naturally resonate with something\nthat is just black and white.",
    "start": "722699",
    "end": "725970"
  },
  {
    "text": "The answer is X. We wanna know, y\nwe wanna hear more and more thought,",
    "start": "725970",
    "end": "728938"
  },
  {
    "text": "and we question things less when\nhear that, uh, thought, um, process.",
    "start": "728939",
    "end": "734130"
  },
  {
    "text": "And that's a little bit encountered\nto a different objective function",
    "start": "734565",
    "end": "738075"
  },
  {
    "text": "that was originally solved for\nwhich is much more get the answer.",
    "start": "738075",
    "end": "741495"
  },
  {
    "text": "Exactly correct.",
    "start": "741555",
    "end": "742545"
  },
  {
    "text": "And that's how pre\nreasoning models were cer.",
    "start": "742995",
    "end": "745095"
  },
  {
    "text": "That was certainly the focus.",
    "start": "745125",
    "end": "746265"
  },
  {
    "text": "And so I expect there's just some, you\nknow, misalignment in those objective",
    "start": "746265",
    "end": "750345"
  },
  {
    "text": "functions and we're trying to solve for a\nlot of different things and we're waiting,",
    "start": "750345",
    "end": "753915"
  },
  {
    "text": "having these really verbose thought\nprocesses that are much harder to check",
    "start": "754245",
    "end": "757995"
  },
  {
    "text": "for factual accuracy when that training\ndata is created and that, you know,",
    "start": "758355",
    "end": "763125"
  },
  {
    "text": "just innately are going to promote\nhaving more chances to hallucinate in any",
    "start": "763295",
    "end": "768095"
  },
  {
    "text": "given response than you know the answer.",
    "start": "768095",
    "end": "770555"
  },
  {
    "text": "Is, the answer's x.",
    "start": "770555",
    "end": "771815"
  },
  {
    "text": "Kaoutar.",
    "start": "772085",
    "end": "772355"
  },
  {
    "text": "Are you, um, optimistic, uh,\nin the end with all this?",
    "start": "772355",
    "end": "775475"
  },
  {
    "text": "I remember a few years ago I was\ntalking to a researcher who is like,",
    "start": "775475",
    "end": "778115"
  },
  {
    "text": "don't worry, and like 18 months",
    "start": "778685",
    "end": "780125"
  },
  {
    "text": "there will just no be,\nno more hallucinations.",
    "start": "780125",
    "end": "782030"
  },
  {
    "text": "We're gonna just crack the problem.",
    "start": "782030",
    "end": "783140"
  },
  {
    "text": "It's solved, right?",
    "start": "783200",
    "end": "784220"
  },
  {
    "text": "Like clearly there's gonna be\nless and less hallucinations",
    "start": "784220",
    "end": "785930"
  },
  {
    "text": "and it's just gonna be done.",
    "start": "785930",
    "end": "787040"
  },
  {
    "text": "And I guess kind of what's interesting\nabout this article is almost the",
    "start": "787460",
    "end": "789680"
  },
  {
    "text": "idea that like hallucinations might\nbe kind of like a thing that keeps",
    "start": "789680",
    "end": "792230"
  },
  {
    "text": "coming back as the technology advances.",
    "start": "792230",
    "end": "795704"
  },
  {
    "text": "Um, and I guess from where you're\nsitting, I mean, do you feel like yeah,",
    "start": "795795",
    "end": "798464"
  },
  {
    "text": "maybe in 2030, you know, we won't even\nbe talking about hallucination anymore",
    "start": "798465",
    "end": "801915"
  },
  {
    "text": "'cause it's kind of a solved problem?",
    "start": "801945",
    "end": "803145"
  },
  {
    "text": "Or is this really something\npersistent that we're gonna be",
    "start": "803145",
    "end": "804915"
  },
  {
    "text": "dealing with for a long time?",
    "start": "804915",
    "end": "805995"
  },
  {
    "text": "Yeah, I think it's gonna be persists.",
    "start": "806025",
    "end": "808035"
  },
  {
    "text": "Uh, maybe they'll, we'll have, you\nknow, I. Different techniques or",
    "start": "808125",
    "end": "811800"
  },
  {
    "text": "methods or maybe hybrid approaches\nwhere we need to do also factual check.",
    "start": "811800",
    "end": "815370"
  },
  {
    "text": "So what's happening here is these models\nthey use probabilistic, not logic, you",
    "start": "815969",
    "end": "820410"
  },
  {
    "text": "know, uh, probabilities, you know, and\nnot logic to predict these responses.",
    "start": "820410",
    "end": "824188"
  },
  {
    "text": "And reinforcement learning helps in math\nand coding, but also causes the model,",
    "start": "824640",
    "end": "829140"
  },
  {
    "text": "like Kate mentioned, to forget, you know,\nsome of these al consistencies, you know,",
    "start": "829140",
    "end": "833640"
  },
  {
    "text": "to, you know, the, the reasoning models.",
    "start": "833640",
    "end": "835349"
  },
  {
    "text": "They take these multi-step approaches\nto the problem solving.",
    "start": "835349",
    "end": "839579"
  },
  {
    "text": "Each step introduces also this\ncompound effect of hallucination.",
    "start": "839665",
    "end": "844074"
  },
  {
    "text": "So the tools today, they can't keep up.",
    "start": "844495",
    "end": "846505"
  },
  {
    "text": "So of course a lot of work in research\nto build tools to trace, you know, the",
    "start": "846505",
    "end": "850765"
  },
  {
    "text": "AI output back to the training data.",
    "start": "850765",
    "end": "853074"
  },
  {
    "text": "But these systems are very,\nyou know, complex too, too",
    "start": "853344",
    "end": "856464"
  },
  {
    "text": "large to fully understand.",
    "start": "856464",
    "end": "858444"
  },
  {
    "text": "And the explanations even that\nare shown to the user sometimes",
    "start": "858824",
    "end": "861644"
  },
  {
    "text": "they really don't reflect the\nmodel's actual internal process.",
    "start": "861645",
    "end": "865215"
  },
  {
    "text": "So what are really these,\nthe broad implications here?",
    "start": "865425",
    "end": "868154"
  },
  {
    "text": "So accuracy is kind of eroding here.",
    "start": "868155",
    "end": "870465"
  },
  {
    "text": "Even as the LLMs become more powerful in\ncognitive tasks, their grip on the factual",
    "start": "870465",
    "end": "875655"
  },
  {
    "text": "reliability, you know, is loosening here.",
    "start": "875685",
    "end": "878265"
  },
  {
    "text": "And of course this has a\nlot of enterprise concerns.",
    "start": "878564",
    "end": "881295"
  },
  {
    "text": "And so I think the challenge\nstill remains unresolved.",
    "start": "881715",
    "end": "884685"
  },
  {
    "text": "You know, there's quite",
    "start": "884685",
    "end": "885194"
  },
  {
    "text": "many efforts from OpenAI, Google, DeepSeek, and others, there is no clear fix.",
    "start": "885705",
    "end": "890775"
  },
  {
    "text": "So hallucination appears to be, you\nknow, kind of an intrinsic limitations",
    "start": "890925",
    "end": "895185"
  },
  {
    "text": "of the current model architectures.",
    "start": "895185",
    "end": "896895"
  },
  {
    "text": "So what I'm thinking is we need kind\nof hybrid approaches, not just relying",
    "start": "897225",
    "end": "901394"
  },
  {
    "text": "on the model, but see if we can.",
    "start": "901395",
    "end": "903195"
  },
  {
    "text": "You know, combine that with other systems\nto, to do these reasoning, symbolic",
    "start": "904160",
    "end": "909259"
  },
  {
    "text": "reasoning, combine them with symbolic\nreasoning systems or factual check-ins.",
    "start": "909260",
    "end": "913580"
  },
  {
    "text": "So hopefully that can kind of\nresolve these issues that we find.",
    "start": "913760",
    "end": "917090"
  },
  {
    "text": "Yeah, and I did wanna get into that\nas like, I mean, you Kaoutar, I think",
    "start": "917150",
    "end": "920210"
  },
  {
    "text": "you point out quite rightly, like\nfrom an enterprise standpoint, I'm",
    "start": "920210",
    "end": "922910"
  },
  {
    "text": "a company that's about to implement\nthis stuff I'm reading in the New",
    "start": "922910",
    "end": "925415"
  },
  {
    "text": "York Times that like these great\nnew models that people are trying to",
    "start": "925415",
    "end": "927980"
  },
  {
    "text": "pitch me on, like I hallucinate more.",
    "start": "927980",
    "end": "930380"
  },
  {
    "text": "I mean, Skyler, what's\nwhat's to be done, right?",
    "start": "930740",
    "end": "932630"
  },
  {
    "text": "I think.",
    "start": "932630",
    "end": "932925"
  },
  {
    "text": "Kaoutar is kind of throwing out like maybe\nwe need more symbolic approaches, like",
    "start": "932925",
    "end": "936404"
  },
  {
    "text": "what is the kind of toolkit of things\nthat we do to try to kind of deal with",
    "start": "936405",
    "end": "939735"
  },
  {
    "text": "this, particularly in a setting where,\nyou know, a business is trying to",
    "start": "939735",
    "end": "942435"
  },
  {
    "text": "implement this, they need the reliability.",
    "start": "942435",
    "end": "944085"
  },
  {
    "text": "I think that point right there\nat the end is very important.",
    "start": "944175",
    "end": "946755"
  },
  {
    "text": "Which use case are these being built for\nhallucinations during your Google search?",
    "start": "946785",
    "end": "951285"
  },
  {
    "text": "It's annoying, but it's\nnot, not game breaking.",
    "start": "952875",
    "end": "955005"
  },
  {
    "text": "Uh, using a tool in order to improve\nsome sort of legal argument or medical",
    "start": "955515",
    "end": "960165"
  },
  {
    "text": "diagnosis, incredibly important.",
    "start": "960165",
    "end": "962475"
  },
  {
    "text": "So I, I think these, these\nhallucinations will always be with us.",
    "start": "962475",
    "end": "966225"
  },
  {
    "text": "Um, I did think it would\nbe on a downward trend.",
    "start": "966585",
    "end": "968865"
  },
  {
    "text": "Tim, as you had said earlier, I am\nsurprised there're going up because",
    "start": "968925",
    "end": "972315"
  },
  {
    "text": "there are teams of researchers\nworking on this problem and",
    "start": "972315",
    "end": "975585"
  },
  {
    "text": "they seem to be falling behind the pace",
    "start": "975990",
    "end": "978120"
  },
  {
    "text": "the progress of the LLMs is if we're\njust kind of, you know, reading the",
    "start": "978120",
    "end": "981180"
  },
  {
    "text": "hallucination rates as they increase.",
    "start": "981180",
    "end": "982829"
  },
  {
    "text": "Um, so I think what's probably the\nmost key important part here is",
    "start": "983219",
    "end": "987060"
  },
  {
    "text": "what's your downstream use case?",
    "start": "987900",
    "end": "989579"
  },
  {
    "text": "And, are hallucinations,\ngame breaking in those.",
    "start": "989640",
    "end": "993885"
  },
  {
    "text": "Um, then, then there will be some\nserious pause about how you really",
    "start": "994035",
    "end": "998024"
  },
  {
    "text": "roll out AI into your workflows.",
    "start": "998025",
    "end": "999915"
  },
  {
    "text": "Um, if you're using it to, to\nspeed up a, uh, internet query,",
    "start": "1000335",
    "end": "1004175"
  },
  {
    "text": "um, I think we're gonna have some\nentertaining hallucinations for",
    "start": "1004535",
    "end": "1007504"
  },
  {
    "text": "another five years to come yet.",
    "start": "1007505",
    "end": "1008705"
  },
  {
    "text": "And if I can make a plug for generative\ncomputing, like I think this is exactly",
    "start": "1009325",
    "end": "1014155"
  },
  {
    "text": "the type of thing we're trying to\nsolve and to wrap our heads around",
    "start": "1014155",
    "end": "1017755"
  },
  {
    "text": "for real deployed use cases, how do\nwe set up workflows so that it's not",
    "start": "1017755",
    "end": "1023545"
  },
  {
    "text": "just a model giving carte blanche to\ngo and create tons of chain of thought,",
    "start": "1023545",
    "end": "1028135"
  },
  {
    "text": "do a bunch of actions, hallucinate\nsome things, give a response back,",
    "start": "1028224",
    "end": "1031944"
  },
  {
    "text": "but instead, how can you have.",
    "start": "1032005",
    "end": "1034345"
  },
  {
    "text": "Very programmatic control steps with\nchecks where you're validating the",
    "start": "1034535",
    "end": "1038974"
  },
  {
    "text": "outputs programmatically, uh, and\nwhere you really reduce the scope of",
    "start": "1038974",
    "end": "1043175"
  },
  {
    "text": "what the model does at any one point\nin time so that you can really try",
    "start": "1043175",
    "end": "1047135"
  },
  {
    "text": "and reduce your risks of hallucination\nand other safety issues and a keep.",
    "start": "1047135",
    "end": "1052415"
  },
  {
    "text": "Part to that is also bringing in\nadditional layers of security.",
    "start": "1052450",
    "end": "1055960"
  },
  {
    "text": "So for example, we've got Granite Guardian\nmodels, which can detect hallucinations",
    "start": "1055960",
    "end": "1060820"
  },
  {
    "text": "in any grounded response or function call.",
    "start": "1060820",
    "end": "1063370"
  },
  {
    "text": "So there's all sorts of tools that\nyou can start to layer in if you're",
    "start": "1063790",
    "end": "1066820"
  },
  {
    "text": "not taking what I call like the\nYOLO prompt approach where you just.",
    "start": "1066820",
    "end": "1070480"
  },
  {
    "text": "Create one big approach, one big prompt,\nthrow it at the model and you know,",
    "start": "1070480",
    "end": "1073725"
  },
  {
    "text": "fingers crossed hope for the best.",
    "start": "1073725",
    "end": "1075225"
  },
  {
    "text": "But if you start to break this out, it\ntakes a little bit more work to set up,",
    "start": "1075645",
    "end": "1078735"
  },
  {
    "text": "but it gives you so much more control\nover the risks and the performance at any",
    "start": "1078764",
    "end": "1083625"
  },
  {
    "text": "given part in the process that I think it\nwill be, you know, really critical for.",
    "start": "1083625",
    "end": "1087915"
  },
  {
    "text": "Real life enterprise deployments.",
    "start": "1088210",
    "end": "1090279"
  },
  {
    "text": "Yeah.",
    "start": "1090490",
    "end": "1090700"
  },
  {
    "text": "I think this is still like one of the\nkind of funniest ironies I think of the",
    "start": "1090700",
    "end": "1093880"
  },
  {
    "text": "AI era is, you know, you've built a thing\nthat's like, it's in the computer, but",
    "start": "1093880",
    "end": "1098050"
  },
  {
    "text": "it doesn't really behave like computing.",
    "start": "1098050",
    "end": "1099790"
  },
  {
    "text": "And like there's all this work now to kind\nof like put it back in the box and make it",
    "start": "1100030",
    "end": "1102940"
  },
  {
    "text": "behave like a more traditional computer.",
    "start": "1103060",
    "end": "1104920"
  },
  {
    "text": "'cause you need it for all sorts of like\nvery practical, you know, reliability",
    "start": "1105130",
    "end": "1108220"
  },
  {
    "text": "reasons, security reasons, safety reasons.",
    "start": "1108220",
    "end": "1110140"
  },
  {
    "text": "Like there are prompts out there where\nit says in all caps, do not hallucinate.",
    "start": "1110230",
    "end": "1114520"
  },
  {
    "text": "Like that's not computer science.",
    "start": "1115020",
    "end": "1116550"
  },
  {
    "text": "Like this is, we've lost all, you\nknow, uh, grounding to reality here.",
    "start": "1116550",
    "end": "1122129"
  },
  {
    "text": "That's not how computer science is done.",
    "start": "1122129",
    "end": "1124170"
  },
  {
    "text": "So we need to get to a\nbetter way of working.",
    "start": "1124230",
    "end": "1126480"
  },
  {
    "text": "Yeah.",
    "start": "1126780",
    "end": "1127080"
  },
  {
    "text": "It is the fact that we're seeing\nright now, the smarter these models",
    "start": "1127080",
    "end": "1130169"
  },
  {
    "text": "are getting at reasoning, the\nless we can trust them on facts.",
    "start": "1130170",
    "end": "1133139"
  },
  {
    "text": "So put in hallucinations, you know, they\nmay require more than just reinforcement",
    "start": "1133530",
    "end": "1137880"
  },
  {
    "text": "learning as it is being used today.",
    "start": "1137880",
    "end": "1139830"
  },
  {
    "text": "So like, uh, Kate mentioned it, we\nreally need new architectures and",
    "start": "1140190",
    "end": "1144029"
  },
  {
    "text": "new programing paradigm that really\nexplicitly encode truth constraints.",
    "start": "1144030",
    "end": "1148500"
  },
  {
    "text": "On, or modular hybrid systems like that's\ncombine LMS with verifiable databases",
    "start": "1148975",
    "end": "1154554"
  },
  {
    "text": "or symbolic logic engines, you know, and\nthat's, you know, I think at the core of",
    "start": "1154555",
    "end": "1158335"
  },
  {
    "text": "what generative computing is trying to do.",
    "start": "1158485",
    "end": "1160405"
  },
  {
    "start": "1163000",
    "end": "1683000"
  },
  {
    "text": "I wanna move us to the\nlast story of today.",
    "start": "1165395",
    "end": "1168125"
  },
  {
    "text": "Uh, it was announced, or rather it\nwas leaked ultimately, um, that OpenAI",
    "start": "1168185",
    "end": "1172324"
  },
  {
    "text": "is about to make an acquisition of\nWindsurf, um, which is, uh, effectively",
    "start": "1172324",
    "end": "1176674"
  },
  {
    "text": "kind of a coating environment.",
    "start": "1176675",
    "end": "1177725"
  },
  {
    "text": "Um, and it would be the number\nthat has been leaked is that the",
    "start": "1178145",
    "end": "1181264"
  },
  {
    "text": "acquisition would be $3 billion, right?",
    "start": "1181264",
    "end": "1183395"
  },
  {
    "text": "Which would make it the biggest\nOpenAI acquisition to date.",
    "start": "1183395",
    "end": "1186064"
  },
  {
    "text": "And obviously just like a gigantic\nacquisition, uh, in its own right.",
    "start": "1186245",
    "end": "1190294"
  },
  {
    "text": "Um, and.",
    "start": "1190685",
    "end": "1191705"
  },
  {
    "text": "You know, I guess maybe Kate, to go back\nto you, I like some people were saying",
    "start": "1192110",
    "end": "1195020"
  },
  {
    "text": "online that this is kind of like, in\nsome ways like evidence that a lot of",
    "start": "1195020",
    "end": "1198800"
  },
  {
    "text": "this a GI stuff is marketing, right?",
    "start": "1198800",
    "end": "1200840"
  },
  {
    "text": "Because if you really believe that a\nGI was about to come about, why would",
    "start": "1200840",
    "end": "1204529"
  },
  {
    "text": "you spend $3 billion on, you know,\nessentially like a text editor with",
    "start": "1204530",
    "end": "1208520"
  },
  {
    "text": "like some AI components added to it.",
    "start": "1208520",
    "end": "1210380"
  },
  {
    "text": "Um, and, and so yeah, kind of curious\nabout like how you size that up.",
    "start": "1210800",
    "end": "1214100"
  },
  {
    "text": "Like do you buy that argument, which\nis like, yeah, it kind of seems",
    "start": "1214100",
    "end": "1216350"
  },
  {
    "text": "like maybe opening eyes is speaking\nout two sides of its mouth here,",
    "start": "1216350",
    "end": "1218660"
  },
  {
    "text": "so.",
    "start": "1219800",
    "end": "1220300"
  },
  {
    "text": "I think OpenAI probably is\nspeaking out of many different",
    "start": "1220669",
    "end": "1223309"
  },
  {
    "text": "sides of its mouth at all times.",
    "start": "1223310",
    "end": "1224689"
  },
  {
    "text": "But, um, I do think that it\nmakes a lot of sense and I don't",
    "start": "1224810",
    "end": "1229550"
  },
  {
    "text": "think it's mutually exclusive.",
    "start": "1229550",
    "end": "1231080"
  },
  {
    "text": "Uh, so if you look at how OpenAI\nbecame the BM Methodist today,",
    "start": "1231139",
    "end": "1237080"
  },
  {
    "text": "they released a chat interface.",
    "start": "1237080",
    "end": "1238789"
  },
  {
    "text": "They found a UI that all of a sudden\nmade their models relevant to the",
    "start": "1238790",
    "end": "1243139"
  },
  {
    "text": "mass consumers, and then they had",
    "start": "1243139",
    "end": "1245720"
  },
  {
    "text": "millions of people all of a sudden\nusing that interface, generating",
    "start": "1246314",
    "end": "1251324"
  },
  {
    "text": "data that they use to bootstrap\ntheir way, like rocket ship their way",
    "start": "1251324",
    "end": "1255283"
  },
  {
    "text": "into really high performance models.",
    "start": "1255284",
    "end": "1257084"
  },
  {
    "text": "And I think what we're seeing is the\nkiller use case of 2025 and probably",
    "start": "1257594",
    "end": "1263504"
  },
  {
    "text": "for a while is coding assistance.",
    "start": "1263504",
    "end": "1265784"
  },
  {
    "text": "And they don't have their own UI, their\nown access to developers in that arena.",
    "start": "1265784",
    "end": "1270344"
  },
  {
    "text": "So they're losing that advantage that",
    "start": "1270615",
    "end": "1272445"
  },
  {
    "text": "gave them this amazing starting point in\nposition, and so I see it very much as",
    "start": "1272500",
    "end": "1278290"
  },
  {
    "text": "their, you know, and it makes total sense.",
    "start": "1278290",
    "end": "1280000"
  },
  {
    "text": "They would spend this type of money on\nit their way to try and regain some of",
    "start": "1280000",
    "end": "1283990"
  },
  {
    "text": "that advantage and to better understand\nhow their users are using the models and",
    "start": "1283990",
    "end": "1289090"
  },
  {
    "text": "figuring out how to continue to\nimprove the models moving forward.",
    "start": "1289899",
    "end": "1293050"
  },
  {
    "text": "Skyler, this is like a little bit\nof a weird outcome though, right?",
    "start": "1293199",
    "end": "1296110"
  },
  {
    "text": "Because I, I could have remembered when\nlike Chat GPT first came out and everybody",
    "start": "1296139",
    "end": "1300129"
  },
  {
    "text": "was doing kind of like startups around\nAI, people were like, oh, well you're",
    "start": "1300129",
    "end": "1303790"
  },
  {
    "text": "just like a thin wrapper around GPT.",
    "start": "1303790",
    "end": "1305770"
  },
  {
    "text": "Or like, you know, that's not a real\ncompany, that's just a wrapper around",
    "start": "1305770",
    "end": "1308485"
  },
  {
    "text": "GPT, but like $3 billion, like,\nit doesn't really feel like these",
    "start": "1308485",
    "end": "1312309"
  },
  {
    "text": "rappers are, are quite valuable now.",
    "start": "1312310",
    "end": "1314260"
  },
  {
    "text": "Right.",
    "start": "1314260",
    "end": "1314560"
  },
  {
    "text": "And it's kind of almost like an\ninversion from what we thought,",
    "start": "1314560",
    "end": "1316810"
  },
  {
    "text": "you know, earlier in the game.",
    "start": "1317120",
    "end": "1318500"
  },
  {
    "text": "Um, is that the right interpretation?",
    "start": "1318530",
    "end": "1320330"
  },
  {
    "text": "I\nthink",
    "start": "1320659",
    "end": "1320990"
  },
  {
    "text": "while we're talking about doublespeaker\nor talking about both sides",
    "start": "1320990",
    "end": "1324379"
  },
  {
    "text": "of your mouths, I think on one\nhand you can call it a wrapper.",
    "start": "1324379",
    "end": "1326960"
  },
  {
    "text": "I think another hand you can view\nWindsurf or some of these other,",
    "start": "1327050",
    "end": "1330260"
  },
  {
    "text": "uh, companies as integrators and\nOpenAI great at model building.",
    "start": "1330350",
    "end": "1335809"
  },
  {
    "text": "Um, but they haven't, as Kate's\npointed out, they haven't really",
    "start": "1336455",
    "end": "1339365"
  },
  {
    "text": "integrated into other spaces.",
    "start": "1339365",
    "end": "1340684"
  },
  {
    "text": "They had a great chat bot interface.",
    "start": "1340685",
    "end": "1342275"
  },
  {
    "text": "Um, and I think while these models\nare continuing to grow, integration is",
    "start": "1342605",
    "end": "1348005"
  },
  {
    "text": "the complimentary scarce factor that's\nlagging behind and I, so yes, wrapper.",
    "start": "1348005",
    "end": "1352745"
  },
  {
    "text": "Or integrator, depending on\nwhich way you really view it.",
    "start": "1352745",
    "end": "1355205"
  },
  {
    "text": "Um, I do think, I, I do think\nOpenAI knows where it sits in",
    "start": "1355534",
    "end": "1359014"
  },
  {
    "text": "terms of the model building game.",
    "start": "1359014",
    "end": "1360784"
  },
  {
    "text": "Um, and they probably saw a bit\nof a, a bit of a weakness in their",
    "start": "1361294",
    "end": "1365104"
  },
  {
    "text": "own structure of how do we actually\ndeploy this on people's machines?",
    "start": "1365104",
    "end": "1368165"
  },
  {
    "text": "That's not",
    "start": "1368165",
    "end": "1368824"
  },
  {
    "text": "a chat interface.",
    "start": "1369350",
    "end": "1370280"
  },
  {
    "text": "And so again, maybe thinking of this\nmore as, uh, integrating systems into",
    "start": "1370490",
    "end": "1375530"
  },
  {
    "text": "the, uh, language models, uh, rather\nthan a wrapper is probably why you",
    "start": "1375530",
    "end": "1379010"
  },
  {
    "text": "can up with a 3 billion as opposed\nto the, uh, just a wrapper I take.",
    "start": "1379010",
    "end": "1382670"
  },
  {
    "text": "Um, how, how it plays out.",
    "start": "1383030",
    "end": "1385220"
  },
  {
    "text": "We don't know.",
    "start": "1385669",
    "end": "1386449"
  },
  {
    "text": "Uh, but I do think there's this\ninteresting take on the difference",
    "start": "1386540",
    "end": "1390050"
  },
  {
    "text": "between building models and then actually\nintegrating those into workflows.",
    "start": "1390050",
    "end": "1393469"
  },
  {
    "text": "And this might be OpenAI\ncovering its spaces on the ladder.",
    "start": "1393979",
    "end": "1397310"
  },
  {
    "text": "Yeah.",
    "start": "1397429",
    "end": "1397549"
  },
  {
    "text": "I love the idea that's kind of like\na valuable wrapper is an integrator.",
    "start": "1397550",
    "end": "1400610"
  },
  {
    "text": "Yeah.",
    "start": "1400610",
    "end": "1401000"
  },
  {
    "text": "It's like, yes.",
    "start": "1401000",
    "end": "1401344"
  },
  {
    "text": "That's when, when once you get\nvaluable enough, like that's what",
    "start": "1401344",
    "end": "1404000"
  },
  {
    "text": "you've transformed into, um, Kaoutar\nwhere's where does this all go?",
    "start": "1404000",
    "end": "1407959"
  },
  {
    "text": "Right.\nBecause it kind of suggests.",
    "start": "1407989",
    "end": "1409219"
  },
  {
    "text": "Like this sort of vertical integration\nin the space where, you know, coding",
    "start": "1409219",
    "end": "1413135"
  },
  {
    "text": "assistance of obviously is like a\nreally big use case as Kate mentioned.",
    "start": "1413135",
    "end": "1416345"
  },
  {
    "text": "And so it kind of makes sense that\nthe model provider would eventually",
    "start": "1416585",
    "end": "1418955"
  },
  {
    "text": "kind of like get one of those, right.",
    "start": "1418955",
    "end": "1421115"
  },
  {
    "text": "And it would be vertically integrated.",
    "start": "1421115",
    "end": "1422375"
  },
  {
    "text": "Like I'm kind of thinking about like\nare there other domains you think",
    "start": "1422794",
    "end": "1425105"
  },
  {
    "text": "that an OpenAI might be interested?",
    "start": "1425105",
    "end": "1426544"
  },
  {
    "text": "Because I think what's interesting\nabout AI right, is of course",
    "start": "1426544",
    "end": "1428824"
  },
  {
    "text": "that it can be applied across\nall these different domains.",
    "start": "1428824",
    "end": "1431283"
  },
  {
    "text": "And so it's kind of like, well\nmaybe it's not gonna be a $3 billion",
    "start": "1431615",
    "end": "1434135"
  },
  {
    "text": "acquisition, but like where else\ncould they be going, I guess.",
    "start": "1434135",
    "end": "1437014"
  },
  {
    "text": "That they might want to kind of\ncreate this sort of like, you know,",
    "start": "1437270",
    "end": "1439910"
  },
  {
    "text": "they both control the model layer\nand then also the application layer.",
    "start": "1439910",
    "end": "1442820"
  },
  {
    "text": "Yeah, that's a very good point.",
    "start": "1443210",
    "end": "1444500"
  },
  {
    "text": "And I think the, the example that's when\nsurf shown showed us here is they build",
    "start": "1444530",
    "end": "1449240"
  },
  {
    "text": "this sticky developer workflow and,\nuh, additional trust layer over GPT.",
    "start": "1449240",
    "end": "1454280"
  },
  {
    "text": "Like, you know, what we all\nwere referring to as the wrapper",
    "start": "1454280",
    "end": "1457070"
  },
  {
    "text": "and here OpenAI's reaction.",
    "start": "1457400",
    "end": "1459680"
  },
  {
    "text": "It's just not what they don't want\njust to own the model, but also the",
    "start": "1459680",
    "end": "1463070"
  },
  {
    "text": "developer experience in the ecosystem.",
    "start": "1463070",
    "end": "1465289"
  },
  {
    "text": "So it, it seems like we",
    "start": "1465650",
    "end": "1467120"
  },
  {
    "text": "enter in here a phase where\nthese verticalized copilots, for",
    "start": "1467270",
    "end": "1470660"
  },
  {
    "text": "example, for finance, for law, for\nscience, for medical, et cetera,",
    "start": "1470660",
    "end": "1474410"
  },
  {
    "text": "they're the new bottle ground.",
    "start": "1474680",
    "end": "1475970"
  },
  {
    "text": "And owning the UX layer is a very\nstrategic approach here, and I think",
    "start": "1476000",
    "end": "1480710"
  },
  {
    "text": "that's what's, you know, it's a smart\nplay that's open AI is doing, because",
    "start": "1480710",
    "end": "1485450"
  },
  {
    "text": "as the model layer commoditizes here.",
    "start": "1485450",
    "end": "1487820"
  },
  {
    "text": "The moat is the ecosystem\nand the developer tooling.",
    "start": "1488030",
    "end": "1491270"
  },
  {
    "text": "And especially as we are moving in\nmore these agentic AI, this vertical",
    "start": "1491480",
    "end": "1494750"
  },
  {
    "text": "integration becomes very important if you\nreally wants to have a strategic advantage",
    "start": "1494750",
    "end": "1499850"
  },
  {
    "text": "and be competitive in the marketplace.",
    "start": "1499850",
    "end": "1501799"
  },
  {
    "text": "Yeah, and I think it kind\nof leads to a world, um,",
    "start": "1501860",
    "end": "1504379"
  },
  {
    "text": "where it kind of feels like maybe OpenAI\nis gonna become, like, they're gonna",
    "start": "1504784",
    "end": "1507185"
  },
  {
    "text": "almost like take the Apple model, right?",
    "start": "1507185",
    "end": "1509105"
  },
  {
    "text": "Where like everything's vertically\nintegrated, you know, they build the",
    "start": "1509315",
    "end": "1511625"
  },
  {
    "text": "hardware, they have like, you know,\napps that are like, definitely their",
    "start": "1511625",
    "end": "1514715"
  },
  {
    "text": "apps and it's just kind of end to end.",
    "start": "1514715",
    "end": "1516513"
  },
  {
    "text": "Um, I mean, Kate, do you think that's\ngonna be the sort of future of AI where",
    "start": "1516995",
    "end": "1520085"
  },
  {
    "text": "you almost have like, kind of like some\ncompanies that are like Apple, other",
    "start": "1520085",
    "end": "1523263"
  },
  {
    "text": "companies that are just like kind of,\nyou know, it's like the ThinkPad, right?",
    "start": "1523264",
    "end": "1525905"
  },
  {
    "text": "It's like a, a piece of a computer\nthat you can run anything on?",
    "start": "1525905",
    "end": "1528125"
  },
  {
    "text": "No, I, I definitely agree.",
    "start": "1528215",
    "end": "1529835"
  },
  {
    "text": "And building on Kaoutar, I\nreally like how you framed it.",
    "start": "1529835",
    "end": "1532145"
  },
  {
    "text": "As you know, we're starting to see",
    "start": "1532145",
    "end": "1533705"
  },
  {
    "text": "commoditization at the model layer.",
    "start": "1533760",
    "end": "1535620"
  },
  {
    "text": "And I think for a lot of, you know,\ntasks like coding assistance, we are",
    "start": "1535680",
    "end": "1541170"
  },
  {
    "text": "absolutely hitting a point where many\nmodels are gonna start to converge on",
    "start": "1541170",
    "end": "1545430"
  },
  {
    "text": "very similar layers of performance.",
    "start": "1545430",
    "end": "1547260"
  },
  {
    "text": "And so then how do you differentiate?",
    "start": "1547350",
    "end": "1548760"
  },
  {
    "text": "You make really high switching costs.",
    "start": "1548820",
    "end": "1550350"
  },
  {
    "text": "You may, or how do you\ndevelop your competitive moat?",
    "start": "1550889",
    "end": "1552959"
  },
  {
    "text": "Rather you make really high switching\ncosts so that it's, once you're kind of",
    "start": "1552959",
    "end": "1556350"
  },
  {
    "text": "in the ecosystem, you're not gonna switch\nover to whoever's, you know, offering the",
    "start": "1556350",
    "end": "1560309"
  },
  {
    "text": "same offering for a few cents cheaper.",
    "start": "1560310",
    "end": "1562830"
  },
  {
    "text": "And from that perspective, I think\nOpenAI and I think other providers are",
    "start": "1563429",
    "end": "1567059"
  },
  {
    "text": "going to continue to invest in that.",
    "start": "1567060",
    "end": "1569070"
  },
  {
    "text": "And that's why it's really important\nwe continue to support a robust",
    "start": "1569459",
    "end": "1573209"
  },
  {
    "text": "open source ecosystem in order to\nmake sure that we have kind of.",
    "start": "1573240",
    "end": "1578189"
  },
  {
    "text": "Diversity of technology, of thought\nand ultimately are optimizing the",
    "start": "1578530",
    "end": "1583480"
  },
  {
    "text": "efficiency of generative AI and trying\nto continue to bring down costs and,",
    "start": "1583480",
    "end": "1587014"
  },
  {
    "text": "and push advantages and make sure that\nwe don't just get kind of locked into",
    "start": "1587320",
    "end": "1590289"
  },
  {
    "text": "these, uh, single provider ecosystems.",
    "start": "1590290",
    "end": "1592750"
  },
  {
    "text": "Yeah, for sure.",
    "start": "1592870",
    "end": "1593500"
  },
  {
    "text": "Skyler, any thoughts on this?",
    "start": "1593500",
    "end": "1594520"
  },
  {
    "text": "An analogy I've heard once before was,\nI don't know, you go back 30 years and",
    "start": "1594610",
    "end": "1598690"
  },
  {
    "text": "people define their compute experience\nby what OS they used, you know, or you",
    "start": "1598690",
    "end": "1602769"
  },
  {
    "text": "Windows or your Mac, and then that's",
    "start": "1602770",
    "end": "1604149"
  },
  {
    "text": "it's converged and then it was what\nbrowser you use that identified your user",
    "start": "1604155",
    "end": "1608745"
  },
  {
    "text": "experience, and those have converged.",
    "start": "1608745",
    "end": "1610184"
  },
  {
    "text": "Um, right now we're in the space\nwhere people, you know, swear by one",
    "start": "1610545",
    "end": "1614055"
  },
  {
    "text": "particular, uh, LLM and I do think\nthat will eventually converge as well.",
    "start": "1614055",
    "end": "1618764"
  },
  {
    "text": "There will be small nuances here\nand there, but at least from",
    "start": "1618764",
    "end": "1621075"
  },
  {
    "text": "a consumer perspective, I do\nsee the some, uh, converging.",
    "start": "1621075",
    "end": "1623865"
  },
  {
    "text": "Um, so yeah, we've seen it\nbefore happening over technology",
    "start": "1624675",
    "end": "1627495"
  },
  {
    "text": "where that sort of decision\ndefined your compute experience.",
    "start": "1627495",
    "end": "1632145"
  },
  {
    "text": "And then fast forward five years\nand you can see that actually a lot",
    "start": "1632290",
    "end": "1635680"
  },
  {
    "text": "of the options are pretty similar.",
    "start": "1635680",
    "end": "1637000"
  },
  {
    "text": "Um, I can see that sort of\nprogression happening, um, here with",
    "start": "1637390",
    "end": "1641200"
  },
  {
    "text": "your chatbot of choice.",
    "start": "1641200",
    "end": "1643029"
  },
  {
    "text": "Yeah.",
    "start": "1643060",
    "end": "1643390"
  },
  {
    "text": "It kind of makes me think a\nlittle bit about, if you remember",
    "start": "1643390",
    "end": "1644950"
  },
  {
    "text": "that old commercial, like,\noh, I'm, I'm a Mac, I'm a PC.",
    "start": "1644950",
    "end": "1647620"
  },
  {
    "text": "Yep.\nIt's like I'm waiting for that commercial.",
    "start": "1647710",
    "end": "1649179"
  },
  {
    "text": "That'll be like.",
    "start": "1649180",
    "end": "1649810"
  },
  {
    "text": "I'm a, I'm an open, I'm an\nOpenAI coding assistant.",
    "start": "1649835",
    "end": "1652385"
  },
  {
    "text": "You know, like I'm an open\nsource e coding assistant.",
    "start": "1652385",
    "end": "1655205"
  },
  {
    "text": "Uh, well more to come soon.",
    "start": "1655835",
    "end": "1657005"
  },
  {
    "text": "Um, as always, action packs a\nlot to cover, uh, way more to",
    "start": "1657065",
    "end": "1660695"
  },
  {
    "text": "cover than we have time for.",
    "start": "1660695",
    "end": "1661865"
  },
  {
    "text": "Um, but as always, thanks for joining us.",
    "start": "1662195",
    "end": "1663634"
  },
  {
    "text": "Skyler, great to see you again,\nKaoutar, Kate, always great",
    "start": "1663635",
    "end": "1666035"
  },
  {
    "text": "to have you, uh, on the show.",
    "start": "1666035",
    "end": "1667775"
  },
  {
    "text": "And, uh, thanks to all you listeners.",
    "start": "1668135",
    "end": "1669545"
  },
  {
    "text": "Uh, if you enjoyed what you heard, you\ncan get us on Apple Podcasts, Spotify,",
    "start": "1669605",
    "end": "1672934"
  },
  {
    "text": "and podcast platforms everywhere.",
    "start": "1672935",
    "end": "1674255"
  },
  {
    "text": "And we'll see you next\nweek on Mixture of Experts.",
    "start": "1674525",
    "end": "1676895"
  }
]
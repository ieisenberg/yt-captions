[
  {
    "text": "If I asked you to identify\nthis object in my hand, you'd likely say",
    "start": "934",
    "end": "5071"
  },
  {
    "text": "it's a pen.",
    "start": "6139",
    "end": "7540"
  },
  {
    "text": "Even if you've never seen this specific pen, which is a special marker for light boards.",
    "start": "7540",
    "end": "12645"
  },
  {
    "text": "It shares enough attributes\nwith other pens for you to recognize it.",
    "start": "12645",
    "end": "16616"
  },
  {
    "text": "In fact, you and most humans can recognize\napproximately",
    "start": "16649",
    "end": "21354"
  },
  {
    "text": "30,000 individually distinguishable object categories.",
    "start": "21955",
    "end": "28261"
  },
  {
    "text": "Now, to train a deep learning model\nto recognize objects,",
    "start": "28795",
    "end": "32165"
  },
  {
    "text": "we often turn to something\ncalled supervised learning.",
    "start": "32432",
    "end": "39004"
  },
  {
    "text": "A form of deep learning,\nand that requires many labeled examples.",
    "start": "39005",
    "end": "44544"
  },
  {
    "text": "Models learn by making predictions on a bunch of labels in a data set.",
    "start": "44978",
    "end": "52785"
  },
  {
    "text": "These labels provide the correct answers,",
    "start": "54354",
    "end": "56689"
  },
  {
    "text": "or the ground truth for each example.",
    "start": "56689",
    "end": "59691"
  },
  {
    "text": "The model adjusts its weights to minimize the difference between its predictions  and the ground truth,and this process then needs a whole bunch",
    "start": "60060",
    "end": "68068"
  },
  {
    "text": "of labeled samples\nfor many rounds of training.",
    "start": "68234",
    "end": "73139"
  },
  {
    "text": "So if we want AI models\nto remotely approach human capabilities",
    "start": "73506",
    "end": "78211"
  },
  {
    "text": "using supervised learning,\nthey must be explicitly trained on labeled",
    "start": "78211",
    "end": "82449"
  },
  {
    "text": "data for something\nlike 30,000 object categories.",
    "start": "82449",
    "end": "86618"
  },
  {
    "text": "That's a lot of time, cost and compute.",
    "start": "87420",
    "end": "90256"
  },
  {
    "text": "So the need for machine learning models\nto be able to generalize quickly",
    "start": "90256",
    "end": "94593"
  },
  {
    "text": "to a large number of semantic categories\nwith minimal training overhead,",
    "start": "94794",
    "end": "98298"
  },
  {
    "text": "has given rise\nto something called N-shot learning.",
    "start": "98638",
    "end": "107340"
  },
  {
    "text": "That's a subset of machine learning\nthat includes a number of categories.",
    "start": "107340",
    "end": "112779"
  },
  {
    "text": "So we have few shot learning, which uses transfer learning and meta learning methods to train models to recognize new classes.",
    "start": "112779",
    "end": "123756"
  },
  {
    "text": "Then we have one shot learning,",
    "start": "124491",
    "end": "128961"
  },
  {
    "text": "which just uses a single labeled\nexample to learn.",
    "start": "129562",
    "end": "133666"
  },
  {
    "text": "But what if we don't want to use\nany labeled examples at all?",
    "start": "133700",
    "end": "137270"
  },
  {
    "text": "Well, that is the focus of this video.",
    "start": "137704",
    "end": "140707"
  },
  {
    "text": "And that is zero shot learning where\ninstead of providing labeled examples,",
    "start": "140940",
    "end": "146846"
  },
  {
    "text": "the model is asked to make predictions\non unseen classes post training.",
    "start": "146980",
    "end": "151918"
  },
  {
    "text": "Zero shot learning has become a notable\narea of research in data science,",
    "start": "151951",
    "end": "155655"
  },
  {
    "text": "particularly in the fields of computer\nvision and natural language processing.",
    "start": "155655",
    "end": "159159"
  },
  {
    "text": "So how does it work\nwithout explicit annotations to guide it?",
    "start": "159192",
    "end": "163930"
  },
  {
    "text": "Is there a shot learning requires a more fundamental understanding of the labels meaning because after all, that's how we humans do it.",
    "start": "164197",
    "end": "171304"
  },
  {
    "text": "So imagine a child wants to learn\nwhat a bird looks like.",
    "start": "171304",
    "end": "174974"
  },
  {
    "text": "In a process similar to a few shot learning, the child would learn by looking at images labeled bird in a book of animal pictures.",
    "start": "175175",
    "end": "182749"
  },
  {
    "text": "Moving forward, you'll recognize a bird\nbecause it resembles the bird images she's already seen.",
    "start": "183416",
    "end": "188621"
  },
  {
    "text": "But in a zero shot learning scenario, no such labeled\nexamples are available.",
    "start": "188621",
    "end": "195662"
  },
  {
    "text": "So instead, the child might read a written story on birds\nand then they're small or medium sized",
    "start": "196129",
    "end": "201433"
  },
  {
    "text": "animals with feathers, beaks and wings\nthat can fly through the air.",
    "start": "201434",
    "end": "205171"
  },
  {
    "text": "So it should then be able\nto recognize the bird in the real world,",
    "start": "205638",
    "end": "208441"
  },
  {
    "text": "even though she's never seen one before,",
    "start": "208441",
    "end": "210075"
  },
  {
    "text": "because she has learned\nthe concept of a bird.",
    "start": "210076",
    "end": "213079"
  },
  {
    "text": "Just as even if you've never seen this pen\nbefore,",
    "start": "213179",
    "end": "215481"
  },
  {
    "text": "you can still classify it\nbecause of its cylindrical shape.",
    "start": "215481",
    "end": "218985"
  },
  {
    "text": "It has a tip\nand that it's leaving colored markings",
    "start": "219219",
    "end": "223655"
  },
  {
    "text": "when it comes in contact\nwith the glass in front of me.",
    "start": "223990",
    "end": "226893"
  },
  {
    "text": "And yes, there is actually glass\nin front of me.",
    "start": "228027",
    "end": "230263"
  },
  {
    "text": "I'm not writing into thin air.",
    "start": "230263",
    "end": "232398"
  },
  {
    "text": "Now, what I've described is one example",
    "start": "232398",
    "end": "235635"
  },
  {
    "text": "of a method of zero shot learning, a way to implement\nzero shot learning.",
    "start": "236102",
    "end": "243676"
  },
  {
    "text": "And that method that I've introduced\nis called",
    "start": "244110",
    "end": "247113"
  },
  {
    "text": "attribute based.",
    "start": "247313",
    "end": "250350"
  },
  {
    "text": "So this is an attribute based zero shot\nlearning method.",
    "start": "250350",
    "end": "253353"
  },
  {
    "text": "That's where we are training on labeled features",
    "start": "253519",
    "end": "256456"
  },
  {
    "text": "like color, shape, and other characteristics.",
    "start": "256456",
    "end": "259458"
  },
  {
    "text": "Even without seeing the target classes\nduring the training,",
    "start": "259692",
    "end": "262327"
  },
  {
    "text": "the model infers labels\nbased on similar attributes.",
    "start": "262328",
    "end": "266633"
  },
  {
    "text": "So for example, a model can learn\nabout different types of animals.",
    "start": "266666",
    "end": "271271"
  },
  {
    "text": "So let's say it starts off\nby learning about stripes,",
    "start": "271271",
    "end": "276342"
  },
  {
    "text": "and it learns about stripes from looking\nat images of tigers and zebras.",
    "start": "276576",
    "end": "280746"
  },
  {
    "text": "Then it can learn about yellow",
    "start": "281281",
    "end": "284284"
  },
  {
    "text": "the color yellow from images,\nlet's say of canaries.",
    "start": "284284",
    "end": "288154"
  },
  {
    "text": "And then it can learn about flying insects",
    "start": "288388",
    "end": "292525"
  },
  {
    "text": "from, let's say, just looking at,",
    "start": "293326",
    "end": "295560"
  },
  {
    "text": "well, pictures of flies.",
    "start": "295561",
    "end": "298564"
  },
  {
    "text": "Now the model can now perform zero shot\nclassification of a new animal,",
    "start": "298631",
    "end": "302435"
  },
  {
    "text": "let's say bees, despite the absence of bee\nimages in the training set,",
    "start": "302435",
    "end": "307073"
  },
  {
    "text": "because it can understand them\nas a combination of learned features",
    "start": "307440",
    "end": "311144"
  },
  {
    "text": "so striped plus yellow",
    "start": "311344",
    "end": "314314"
  },
  {
    "text": "plus flying insect that might equal",
    "start": "314314",
    "end": "317750"
  },
  {
    "text": "bee.",
    "start": "318751",
    "end": "319817"
  },
  {
    "text": "Now attribute based methods are quite versatile,\nbut they do have some drawbacks.",
    "start": "319817",
    "end": "324823"
  },
  {
    "text": "They rely on the assumption\nthat every class can be described",
    "start": "325091",
    "end": "328561"
  },
  {
    "text": "with a single vector of attributes,\nwhich isn't always the case.",
    "start": "328561",
    "end": "332832"
  },
  {
    "text": "So for example, like a Tesla Cybertruck\nand a Volkswagen Beetle,",
    "start": "332865",
    "end": "336401"
  },
  {
    "text": "they're both cars, but they differ greatly\nin shape, size, materials, and features.",
    "start": "336736",
    "end": "341541"
  },
  {
    "text": "Now, many in zero shot learning methods\nuse an alternative method,",
    "start": "342475",
    "end": "346312"
  },
  {
    "text": "and that is known as embedding.",
    "start": "346612",
    "end": "349816"
  },
  {
    "text": "So an embedding based approach",
    "start": "350817",
    "end": "354020"
  },
  {
    "text": "to zero shot learning.",
    "start": "354287",
    "end": "357223"
  },
  {
    "text": "Now this works by representing\nboth classes",
    "start": "357223",
    "end": "360059"
  },
  {
    "text": "and samples and vector embeddings that\nreflect their features and relationships.",
    "start": "360059",
    "end": "363962"
  },
  {
    "text": "Classification is determined by measuring\nsimilarity between these embeddings",
    "start": "364330",
    "end": "368067"
  },
  {
    "text": "using metrics like cosine similarity\nor Euclidean distance.",
    "start": "368067",
    "end": "371370"
  },
  {
    "text": "Similar to K-nearest neighbors algorithms.",
    "start": "371671",
    "end": "374306"
  },
  {
    "text": "And because embedding based methods\ntypically process inputs from",
    "start": "374307",
    "end": "377210"
  },
  {
    "text": "multiple modalities like word embeddings\nthat describe a class label",
    "start": "377210",
    "end": "381681"
  },
  {
    "text": "and image embeddings of a photograph\nthat might belong to the same class,",
    "start": "381914",
    "end": "385952"
  },
  {
    "text": "they require a way to compare between\nembeddings of different data types,",
    "start": "386552",
    "end": "390656"
  },
  {
    "text": "and that's where joint embedding space can\nhelp normalize those vector embeddings.",
    "start": "390656",
    "end": "394293"
  },
  {
    "text": "Now, another method of",
    "start": "395495",
    "end": "397430"
  },
  {
    "text": "zero shot learning relates to generative",
    "start": "397430",
    "end": "401968"
  },
  {
    "text": "based methods of zero shot learning.",
    "start": "402568",
    "end": "405570"
  },
  {
    "text": "Now, if we think of the first example",
    "start": "406639",
    "end": "409208"
  },
  {
    "text": "of generative based,\nwe have to think of LLMs.",
    "start": "409208",
    "end": "413913"
  },
  {
    "text": "That's large language models and large\nlanguage models have a natural ability",
    "start": "413913",
    "end": "418918"
  },
  {
    "text": "to perform zero shot learning\nbased on their ability to fundamentally",
    "start": "418918",
    "end": "422989"
  },
  {
    "text": "understand the meaning of the words\nused to name data.",
    "start": "422989",
    "end": "426325"
  },
  {
    "text": "Classes and limbs are pre-trained\nthrough self-supervised",
    "start": "426325",
    "end": "429562"
  },
  {
    "text": "learning on a massive corpus of text\nthat may contain incidental references",
    "start": "429562",
    "end": "434667"
  },
  {
    "text": "to knowledge about unseen data classes,\nwhich the LLM can learn to make sense of.",
    "start": "434667",
    "end": "439638"
  },
  {
    "text": "And then, beyond just LLMs,\nanother zero shot generative",
    "start": "440273",
    "end": "443576"
  },
  {
    "text": "based approach\nis my favorite type of neural network.",
    "start": "443576",
    "end": "447280"
  },
  {
    "text": "And that is a GAN.",
    "start": "447480",
    "end": "450516"
  },
  {
    "text": "Gan that's an acronym\nfor Generative Adversarial Network.",
    "start": "450883",
    "end": "455054"
  },
  {
    "text": "And it actually consists\nof two competing neural networks",
    "start": "455421",
    "end": "458491"
  },
  {
    "text": "jointly trained in an adversarial zero\nsum game.",
    "start": "458491",
    "end": "462261"
  },
  {
    "text": "So there's a generator component",
    "start": "462261",
    "end": "465630"
  },
  {
    "text": "that uses semantic attributes\nand Gaussian noise to synthesize samples.",
    "start": "465832",
    "end": "470303"
  },
  {
    "text": "And then there is a discriminator network\nas well.",
    "start": "470703",
    "end": "474240"
  },
  {
    "text": "Lin determines\nwhether samples are real or fake",
    "start": "474774",
    "end": "477776"
  },
  {
    "text": "fake meaning\nthey were synthesized by the generator.",
    "start": "478344",
    "end": "481347"
  },
  {
    "text": "Now feedback from the discriminator\nis used to train the generator",
    "start": "481414",
    "end": "486853"
  },
  {
    "text": "until the discriminator can no longer\ndistinguish",
    "start": "487119",
    "end": "489922"
  },
  {
    "text": "between the real\nand the synthetic samples.",
    "start": "489922",
    "end": "492925"
  },
  {
    "text": "That's perfect\nfor generating synthetic data that mimics",
    "start": "492992",
    "end": "495862"
  },
  {
    "text": "the attributes of unseen\nclasses, thereby enabling models",
    "start": "495862",
    "end": "499765"
  },
  {
    "text": "to learn from these synthesized examples\nas if they were labeled.",
    "start": "499765",
    "end": "503102"
  },
  {
    "text": "So that is zero shot learning.",
    "start": "503936",
    "end": "506272"
  },
  {
    "text": "It's something you do effortlessly\nevery time you see a new object.",
    "start": "506272",
    "end": "509976"
  },
  {
    "text": "And it's something deep learning\nmodels can be taught to do as well.",
    "start": "510176",
    "end": "513312"
  },
  {
    "text": "Zero shot learning shows AI's potential\nto generalize for minimal information,",
    "start": "513846",
    "end": "518216"
  },
  {
    "text": "saving time compute\nand the hassle of labeling data.",
    "start": "518217",
    "end": "523321"
  },
  {
    "text": "If you like this video and",
    "start": "524557",
    "end": "525491"
  },
  {
    "text": "want to see more like it, please\nlike and subscribe.",
    "start": "525491",
    "end": "528494"
  },
  {
    "text": "If you have any questions or want to share\nyour thoughts about this topic,",
    "start": "529328",
    "end": "532532"
  },
  {
    "text": "please leave a comment below.",
    "start": "532532",
    "end": "534133"
  }
]
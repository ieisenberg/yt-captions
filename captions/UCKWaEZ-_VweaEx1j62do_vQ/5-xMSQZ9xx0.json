[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "what's the most exciting announcement at this year's IBM Tech Exchange? Kate Soule is a program director at IBM Research.",
    "start": "120",
    "end": "6200"
  },
  {
    "text": "Kate, welcome. What do you think? The Apache 2 license of Granite 3.0. Kush Varshney, IBM Fellow.",
    "start": "6200",
    "end": "12880"
  },
  {
    "text": "Uh, granite Guardian. And joining us for the very first time, Petros Zerfos, who's a principal research scientist at IBM Research.",
    "start": "12880",
    "end": "19840"
  },
  {
    "text": "That's an easy one. That's a high performance granite 3.0. Terrific. All that and more on today's Mixture of Experts.",
    "start": "19840",
    "end": "29960"
  },
  {
    "start": "30000",
    "end": "1297000"
  },
  {
    "text": "I'm Tim Hwang, and it's Friday again, which means it's time again to take a whirlwind tour of the biggest stories",
    "start": "31440",
    "end": "36760"
  },
  {
    "text": "moving artificial intelligence this week. We'll talk about NVIDIA's latest and greatest open source model, perplexity raising at a",
    "start": "36760",
    "end": "43240"
  },
  {
    "text": "wild evaluation, But first, we're going to talk about IBM's annual tech exchange conference.",
    "start": "43240",
    "end": "48800"
  },
  {
    "text": "There's a slew of announcements out of IBM, and we've got the ideal team to talk about what's launching this week.",
    "start": "48800",
    "end": "54840"
  },
  {
    "text": "The first headline that I want to really address is that Granite 3.0 is out. Um, and Kate, I know you played a really big role in getting that all together",
    "start": "54840",
    "end": "61600"
  },
  {
    "text": "and being a big part of the launch. Um, tell us about what's exciting and different here from the previous generations of Granite.",
    "start": "61600",
    "end": "66920"
  },
  {
    "text": "Thanks, Tim. So we're really excited about Granite 3.0.\nIt launched at like 12 15 a.m. on Monday morning.",
    "start": "66920",
    "end": "73640"
  },
  {
    "text": "And you know, down to the minute, I know down to the minute. Uh, and the reception has been really, really phenomenal.",
    "start": "73640",
    "end": "79320"
  },
  {
    "text": "So Granite 3.0 is IBM's state of the art large language model family. They're a series of models that cover",
    "start": "79320",
    "end": "86200"
  },
  {
    "text": "Language models, safety models called Granite Guardian, uh, we even have some models focused around efficiency, like a",
    "start": "86200",
    "end": "92840"
  },
  {
    "text": "speculative decoder model that came out, and they're all available under Apache \n2.0 license, which is really exciting.",
    "start": "92840",
    "end": "98280"
  },
  {
    "text": "Yeah, and I would say, is there kind of a deeper theme that IBM's kind of pushing with this set of releases? It almost feels like every generation of",
    "start": "98280",
    "end": "103840"
  },
  {
    "text": "Granite's getting kind of broader and broader, and there's like more and more things launching with each generation, but I'm curious if the team had any particular thing that they",
    "start": "103840",
    "end": "110280"
  },
  {
    "text": "were kind of emphasizing on this round? Well, with this round, Our main goal was to actually consolidate all the",
    "start": "110280",
    "end": "117160"
  },
  {
    "text": "different things into one model. So where before IBM had English language models,",
    "start": "117160",
    "end": "122400"
  },
  {
    "text": "multilingual models, code models in our previous generations, generations one and two, with generation three, we're able to bring all of",
    "start": "122400",
    "end": "129280"
  },
  {
    "text": "that into one model while continuing to push the boundaries of how much performance can you pack",
    "start": "129280",
    "end": "134440"
  },
  {
    "text": "into, you know, an 8 billion parameter model. Nice.\nSo I really want to get into the details here because we have an ideal configuration, which is.",
    "start": "134440",
    "end": "141280"
  },
  {
    "text": "Kate, you and Kush and Petrus were all involved in the Granite sort of release and we'd love to kind of dig more into the details.",
    "start": "141280",
    "end": "147800"
  },
  {
    "text": "Petrus, I think maybe I'll throw it over to you because you name check that the most exciting thing, uh, at, uh, Tech Exchange this",
    "start": "147800",
    "end": "154040"
  },
  {
    "text": "year was, uh, Granite, which you worked on. Um, do you want to tell us a little bit about your involvement with the release and what's got you most excited about it?",
    "start": "154040",
    "end": "161319"
  },
  {
    "text": "Yeah, absolutely. Yeah, as I mentioned, it's a very exciting release, uh, my involvement is around the data",
    "start": "161320",
    "end": "167000"
  },
  {
    "text": "engineering, essentially the preparation of the huge amounts of data that goes into the",
    "start": "167000",
    "end": "172519"
  },
  {
    "text": "training of, um, such kind of large language models all the way from the acquisition.",
    "start": "172520",
    "end": "177720"
  },
  {
    "text": "of the point where it's converted into their vectorized form, which is called tokens. And this is essentially what's used",
    "start": "177720",
    "end": "182840"
  },
  {
    "text": "for the training of granite models. It's billions of documents, lots of",
    "start": "182840",
    "end": "187879"
  },
  {
    "text": "terabytes and petabytes worth of data, massive infrastructures thrown behind it.",
    "start": "187880",
    "end": "193320"
  },
  {
    "text": "Very exciting. Yeah, for sure. And I really want to get into that because I think so often, you know, particularly at these tech conferences",
    "start": "193320",
    "end": "199040"
  },
  {
    "text": "or even, you know, just in general, people always see the end result, right? They say, uh, look at these",
    "start": "199040",
    "end": "204080"
  },
  {
    "text": "cool new models I can use. And, you know, as someone who's a consumer of these models, obviously I'm personally very excited.",
    "start": "204080",
    "end": "209480"
  },
  {
    "text": "But I think what's so exciting about your work and the opportunity of having you on the show today is to kind of talk a little bit about what goes on behind the scenes.",
    "start": "209480",
    "end": "216879"
  },
  {
    "text": "Um, and that data curation, um, like tell us what's like, what is hard about it?",
    "start": "216880",
    "end": "222439"
  },
  {
    "text": "Right.\nLike what, what makes it a really hard challenge? Right. That's a very good question.",
    "start": "222440",
    "end": "227480"
  },
  {
    "text": "Um, what makes it a very hard challenge is, um, a multitude actually of things, many challenges.",
    "start": "227480",
    "end": "232680"
  },
  {
    "text": "First of all, um, the sheer volume of data that is needed in order to essentially be curated and be fed in some sense into the",
    "start": "232680",
    "end": "240400"
  },
  {
    "text": "training process is, um, is breathtaking. Um, we're starting with Literally petabytes of",
    "start": "240400",
    "end": "246520"
  },
  {
    "text": "raw data collected from a number of sources, including the whole internet itself, and then",
    "start": "246520",
    "end": "253440"
  },
  {
    "text": "the curation process and the subsequent steps of annotation and filtering towards essentially",
    "start": "253440",
    "end": "260200"
  },
  {
    "text": "finding the golden nuggets of very high quality data that will go into the training. It's a massively kind of challenging process.",
    "start": "260200",
    "end": "268120"
  },
  {
    "text": "Lots and lots of Um, uh, machines and clusters and data centers, if I may say,",
    "start": "268120",
    "end": "274120"
  },
  {
    "text": "um, are needed in order to go through such kind of, um, cleansing and filtering. Yeah.",
    "start": "274120",
    "end": "279400"
  },
  {
    "text": "Were there any particular documents that you were like, oh man, this is in here? Or like, I'm kind of curious about like if there's any surprises in the",
    "start": "279400",
    "end": "285199"
  },
  {
    "text": "process where you're like, oh, it's really funny that the most high quality piece of data is, you know, ABC or XYZ.",
    "start": "285200",
    "end": "290840"
  },
  {
    "text": "Right.\nSo, um, having essentially, you know, kind of a process through pretty much.",
    "start": "290840",
    "end": "296720"
  },
  {
    "text": "Most of the data that's out there in the internet, you can definitely find some things that make you kind of wonder about humanity",
    "start": "296720",
    "end": "303440"
  },
  {
    "text": "itself, what it puts out there, if I may say. There's absolutely, of course, you know,",
    "start": "303440",
    "end": "309479"
  },
  {
    "text": "the golden nuggets of knowledge in the form of textbooks and the scientific papers.",
    "start": "309480",
    "end": "315480"
  },
  {
    "text": "And the medical studies and the legal studies that are written essentially by the",
    "start": "315480",
    "end": "320840"
  },
  {
    "text": "scholars and by people with high expertise. And of course it's a pleasure to",
    "start": "320840",
    "end": "326400"
  },
  {
    "text": "have the high quality aspects be included in the training of granite. So it's an aspect that we've talked about",
    "start": "326400",
    "end": "333040"
  },
  {
    "text": "on the show before, um, and I think this is a great thing hearing you talk a little bit more about it is just, you know, this",
    "start": "333040",
    "end": "338360"
  },
  {
    "text": "is not just a matter of kind of dumping huge amounts of data into the model. Uh, it is that, but there's just a lot of work",
    "start": "338360",
    "end": "344240"
  },
  {
    "text": "that goes into like selecting the right tokens. It's almost, um, you know, artisanal in nature, right? You're getting like the right,",
    "start": "344240",
    "end": "349880"
  },
  {
    "text": "you know, blend to get the most or best results out of the model. Well, Tim, it's our artisanal, but I also want to highlight with something that the team",
    "start": "349880",
    "end": "356840"
  },
  {
    "text": "did that I think is really cool, which is the degree of experimenting and searching that the team did over different data mixtures.",
    "start": "356840",
    "end": "364120"
  },
  {
    "text": "So training one, you know, 2 billion parameter model requires training.",
    "start": "364120",
    "end": "369600"
  },
  {
    "text": "Petrus, I don't know how many small models do you think you trained? Oh, we trained hundreds of those, uh, very easily.",
    "start": "369600",
    "end": "376468"
  },
  {
    "text": "No big deal.\nEven smaller models, we trained thousands of those to get, uh, to get down to the proper mixtures, uh, as well as",
    "start": "376468",
    "end": "383440"
  },
  {
    "text": "kind of bigger models in the order of like one to two billion parameters. We trained literally hundreds of those.",
    "start": "383440",
    "end": "388640"
  },
  {
    "text": "In order to figure out what is the best type of cleansing and the best type of mixing, right?",
    "start": "388640",
    "end": "394479"
  },
  {
    "text": "So, um, definitely lots of effort by very large teams in IBM research and",
    "start": "394480",
    "end": "400560"
  },
  {
    "text": "lots of infrastructure from behind it in both TPUs as well as general clusters.",
    "start": "400560",
    "end": "405919"
  },
  {
    "text": "Yeah, for sure. And to underscore some of the, like, it's not always black and white, right, on, uh, on data, so some of, to underscore a bit some",
    "start": "405920",
    "end": "413800"
  },
  {
    "text": "of the decisions and processes the team went through, like, a fun example is just thinking about, you know, how many emojis do you",
    "start": "413800",
    "end": "420600"
  },
  {
    "text": "include in Um, Uh, granite training model data. So like, what is the appropriate level of emoji, Tim, for a model to understand?",
    "start": "420600",
    "end": "428200"
  },
  {
    "text": "It's a hard question. I mean, um, what, what's the risk of having too many emojis? Well, then the model has a predilection",
    "start": "428200",
    "end": "434680"
  },
  {
    "text": "to give a lot of emojis in the response, which I mean, depending on your use case, maybe you care about that, but you",
    "start": "434680",
    "end": "440560"
  },
  {
    "text": "certainly, um, in an enterprise setting, probably don't want to skew towards emojis. But if you remove emojis altogether, The",
    "start": "440560",
    "end": "447159"
  },
  {
    "text": "model doesn't understand the concept of emojis, can't interpret emojis, which of course is going to be critical for a",
    "start": "447160",
    "end": "453600"
  },
  {
    "text": "variety of just basic tasks and use cases. So, you know, there was a whole effort, I'm not kidding, just figuring out what",
    "start": "453600",
    "end": "459320"
  },
  {
    "text": "is the right level of emojis that the model should be trained on to understand.",
    "start": "459320",
    "end": "465280"
  },
  {
    "text": "That's fascinating. Well, uh, Kush, I don't want to let you off the hook here. I know, I understand you were",
    "start": "465280",
    "end": "470439"
  },
  {
    "text": "also involved in this release. Uh, do you want to talk a little bit about more of your part of, uh, of this, this launch?",
    "start": "470440",
    "end": "476040"
  },
  {
    "text": "Yeah, I was involved in a few different parts, actually. So on the Granite 3.0, the \nlanguage models, actually, as",
    "start": "476040",
    "end": "482080"
  },
  {
    "text": "Kate said, it's really language and code and a lot of things all together. Um, uh, so I was involved in",
    "start": "482080",
    "end": "488720"
  },
  {
    "text": "a lot of the safety alignment. Uh, so. Uh, these things, uh, after Petros does his work, right?",
    "start": "488720",
    "end": "494760"
  },
  {
    "text": "Um, we have the pre training data, then there's, um, uh, the training process, and then there's further alignment after that.",
    "start": "494760",
    "end": "501560"
  },
  {
    "text": "Uh, so part of that is, uh, taking the model from the base model into an instruct model.",
    "start": "501560",
    "end": "507360"
  },
  {
    "text": "But then after that, doing further, uh, tuning to, uh, to make it safe in various ways.",
    "start": "507360",
    "end": "512599"
  },
  {
    "text": "Um, so, uh, I was working with, uh, again, a big team of folks, um, and, uh, we were Coming",
    "start": "512600",
    "end": "519839"
  },
  {
    "text": "up with seed examples to generate synthetic data across many different types of harms and",
    "start": "519840",
    "end": "525320"
  },
  {
    "text": "risks and, uh, kind of, uh, figuring out how to get the model not to engage in those topics.",
    "start": "525320",
    "end": "531640"
  },
  {
    "text": "So, uh, that's one key area and I would just want to point out, uh, the way we evaluate",
    "start": "531640",
    "end": "537520"
  },
  {
    "text": "that, um, that level of safety is, uh, Uh, through a variety of benchmarks. One of those was developed in our research lab.",
    "start": "537520",
    "end": "545640"
  },
  {
    "text": "It's called ATTAQ, A T T A with a Q at the end, and, um, uh, we actually compared, uh, the Granite \n3.0, um, uh, all of the models, but the",
    "start": "545640",
    "end": "555080"
  },
  {
    "text": "8 billion instructor as an example, um, outperforms, uh, all of the other competitors",
    "start": "555080",
    "end": "560600"
  },
  {
    "text": "that are out there, um, in this benchmark. It's, uh, really is the, the safest, uh, in, in many ways.",
    "start": "560600",
    "end": "566920"
  },
  {
    "text": "And then, um, That's one half. Um, the other half of the work was on the granite guardian models.",
    "start": "566920",
    "end": "572319"
  },
  {
    "text": "And so, uh, the way to think about it is, um, when you're thinking about safety",
    "start": "572320",
    "end": "577480"
  },
  {
    "text": "about preventing harms, you want to do the best that you can on the main model. But then, you know, I mean, inherently",
    "start": "577480",
    "end": "584720"
  },
  {
    "text": "that it's never going to be perfect. So there should also be a second model that's independent.",
    "start": "584720",
    "end": "590680"
  },
  {
    "text": "That's actually checking the first model to make sure that, uh, it's not putting bad stuff out there.",
    "start": "590680",
    "end": "596880"
  },
  {
    "text": "So, um, The Granite Guardian is a second model. It's actually built on top of the Granite \n3.0 language models, um, Uh, it's, uh,",
    "start": "596880",
    "end": "605120"
  },
  {
    "text": "but it's, uh, kind of constrained just to give a yes or a no answer. Uh, so it'll say, um, look at either an",
    "start": "605120",
    "end": "612080"
  },
  {
    "text": "input prompt at a model response or the combination and it'll say yes or no. Is this, um, harmful?",
    "start": "612080",
    "end": "618280"
  },
  {
    "text": "Is it doing, uh, is it a jailbreaking attack? Is there a hallucination? Is there, um, a problem with context relevance?",
    "start": "618280",
    "end": "625400"
  },
  {
    "text": "Is there a problem with answer relevance in a RAG setting? This model is meant to act in that capacity,",
    "start": "625400",
    "end": "631240"
  },
  {
    "text": "and, um, uh, it's important to understand. It's actually not limited to just working",
    "start": "631240",
    "end": "636400"
  },
  {
    "text": "with the granite, uh, models, so you can apply this with any model out there.",
    "start": "636400",
    "end": "642440"
  },
  {
    "text": "So I know we're going to talk about other models later in the show, so you can use the granite guardian with any of those.",
    "start": "642440",
    "end": "648720"
  },
  {
    "text": "Yeah, for sure. There's a lot there. I mean, I guess maybe one question to kind of push you a little bit further, Kush, is um, How do you, I mean, one thing that",
    "start": "648720",
    "end": "655080"
  },
  {
    "text": "occurs to me is like, safety is so broad. There's only so many things that like a model could do wrong in the world.",
    "start": "655080",
    "end": "662080"
  },
  {
    "text": "How does you and your team kind of like work to kind of, Manage those risks right because it's like this infinite attack space.",
    "start": "662080",
    "end": "668579"
  },
  {
    "text": "Yeah, but as yet, you know, like tech exchanges this week You got to get something launched Curious about how you reconcile those two",
    "start": "668580",
    "end": "674240"
  },
  {
    "text": "how the team thinks about like broadening its risk set over time or narrowing it over time I just think it's a really interesting process",
    "start": "674240",
    "end": "679399"
  },
  {
    "text": "that a lot of people don't usually hear about Yeah, and it is always about broadening. So as you said, that attack surface",
    "start": "679400",
    "end": "684960"
  },
  {
    "text": "area is, uh, pretty much infinite. So we can only pick and choose and touch on some parts of it.",
    "start": "684960",
    "end": "690720"
  },
  {
    "text": "And we understand that. Um, so we created this, uh, attack atlas. Um, it's a paper.",
    "start": "690720",
    "end": "696160"
  },
  {
    "text": "It will be presented in Europe's, uh, in a workshop. And I mean, there's so many different ways, um, so many different strategies,",
    "start": "696160",
    "end": "702920"
  },
  {
    "text": "um, so many different topics of harm. Uh, so, uh, we can, I mean, just do our best, right?",
    "start": "702920",
    "end": "709240"
  },
  {
    "text": "Um, it's a, yeah. But you keep making progress. You keep adding things. So using taxonomies to categorize",
    "start": "709240",
    "end": "717200"
  },
  {
    "text": "different types of risks and harms. So building that up, trying to get as broad coverage as you can.",
    "start": "717200",
    "end": "724720"
  },
  {
    "text": "Looking at different strategies of those attacks. Keep working on that. But it's a cat and mouse game in some sense.",
    "start": "724720",
    "end": "731240"
  },
  {
    "text": "So kind of red teaming, blue teaming, going back and forth, kind of seeing what the problems",
    "start": "731240",
    "end": "736480"
  },
  {
    "text": "are, then going Figuring out how to address them and, uh, yeah, just, uh, just cycling through",
    "start": "736480",
    "end": "741720"
  },
  {
    "text": "it and, yeah, I mean, again, nothing's ever going to be perfect, uh, it's a, it's a process.",
    "start": "741720",
    "end": "746800"
  },
  {
    "text": "Yeah, for sure. So, uh, Kate, you'll have to indulge me, I mean, as the lawyer on the phone, you were like, the most exciting thing is",
    "start": "746800",
    "end": "753560"
  },
  {
    "text": "Apache, and I was like, oh my god, yes. Let's talk about Apache 2.0. Um, why should our listeners be excited about",
    "start": "753560",
    "end": "760600"
  },
  {
    "text": "that if they're not huge licensing nerds? So, I think the reason to be excited is Apache 2.0 is an \nincredibly permissive license.",
    "start": "760600",
    "end": "768640"
  },
  {
    "text": "It basically says that anyone can take and use our Granite models. And can customize them however you like,",
    "start": "768640",
    "end": "775560"
  },
  {
    "text": "use any outputs of the models however you like, and IBM will make no claims to that IP, and you have full rights.",
    "start": "775560",
    "end": "782680"
  },
  {
    "text": "So, that's really important for especially enterprises who are looking to customize.",
    "start": "782680",
    "end": "788480"
  },
  {
    "text": "models, large language models with their own data, with their own IP, you want to make sure you have no further restrictions on what",
    "start": "788480",
    "end": "794920"
  },
  {
    "text": "is essentially now your, your IP that you've encoded inside of a large language model. So we're really excited about being able to",
    "start": "794920",
    "end": "801519"
  },
  {
    "text": "offer these models under those terms, and make sure that they're just as reducing the",
    "start": "801520",
    "end": "806800"
  },
  {
    "text": "barriers for the broader community to use them and customize them as much as possible.",
    "start": "806800",
    "end": "812079"
  },
  {
    "text": "And it's something of a bit of a dying breed. Unfortunately, if we look at models that are being released in the open, um, we",
    "start": "812080",
    "end": "818600"
  },
  {
    "text": "are seeing models continue to be released in the open, but more and more they're being released with custom licenses. So we're trying to keep it simple.",
    "start": "818600",
    "end": "825120"
  },
  {
    "text": "Apache two, please take our models. Please customize 'em and go use them out in the world. Yeah, I was definitely",
    "start": "825120",
    "end": "830440"
  },
  {
    "text": "confronted with this recently. I was, you know, importing a model from Hugging Face recently and I was like, oh, the model was gated and then there",
    "start": "830440",
    "end": "836360"
  },
  {
    "text": "was like a completely custom license. I was like, this is gonna take forever to see if this is something I really wanna work with.",
    "start": "836360",
    "end": "841560"
  },
  {
    "text": "Can I ask why? Like, why is IBM taking the most open kind of perspective? It sounds like there's actually",
    "start": "841560",
    "end": "846920"
  },
  {
    "text": "been a conscious strategy to say. We're going to be out of all the open providers, the most open",
    "start": "846920",
    "end": "852720"
  },
  {
    "text": "well again, I think it really comes down to this enterprise use case where we believe the",
    "start": "852720",
    "end": "858280"
  },
  {
    "text": "future of large length trials and generative AI and the enterprise is being able to customize models with enterprise and proprietary data.",
    "start": "858280",
    "end": "867079"
  },
  {
    "text": "And so really, we're trying to create the tools both through the base models. like the granite model series, which can be then",
    "start": "867080",
    "end": "873360"
  },
  {
    "text": "customized without any restrictions on its use. And tools like construct lab, uh, which is",
    "start": "873360",
    "end": "878960"
  },
  {
    "text": "through our rel AI product offering at Red Hat. You can take those models and customize them and build on top of them without concerns or worry.",
    "start": "878960",
    "end": "886519"
  },
  {
    "text": "And then wrapping that all right under, if you get our models through, for example, Watson XAI through indemnification",
    "start": "886520",
    "end": "891760"
  },
  {
    "text": "and other protections support. So it's really trying to make sure that we create this kind of",
    "start": "891760",
    "end": "897200"
  },
  {
    "text": "open market and ecosystem that. Our customers can build on with confidence. Yeah, and I think that's actually a theme",
    "start": "897200",
    "end": "902920"
  },
  {
    "text": "I really wanted to build on, just because, I mean, a big part of this seems to be like unleash the developers to kind of do what",
    "start": "902920",
    "end": "908720"
  },
  {
    "text": "they need to do around these models, and we're not gonna kind of put any controls over that. But one kind of unique thing, and I",
    "start": "908720",
    "end": "914519"
  },
  {
    "text": "guess Petrus, maybe you're the natural person to bring into this discussion, is IBM as I understand it, is also open sourcing, the kind of data prep kit.",
    "start": "914520",
    "end": "921560"
  },
  {
    "text": "around these models, which is kind of a unique thing, right? Like, I think there's been a lot of hype around open sourced models, but like,",
    "start": "921560",
    "end": "928000"
  },
  {
    "text": "what seems to be here is also like a level of openness around all of the stuff that goes into constructing the model.",
    "start": "928000",
    "end": "934360"
  },
  {
    "text": "Um, and, uh, I guess there's kind of two questions for you. One of them is why, like, why is IBM doing that?",
    "start": "934360",
    "end": "940000"
  },
  {
    "text": "Um, uh, but let's maybe start there. And this is a kind of follow up I would love to ask you. Sure. Yeah, that goes along the general thing,",
    "start": "940000",
    "end": "946680"
  },
  {
    "text": "theme of openness, we're not opening the models themselves and their weights under",
    "start": "946680",
    "end": "951720"
  },
  {
    "text": "the, if I may say it in a single sentence, the most permissive license, right? That's what Apache 2.0 is.",
    "start": "951720",
    "end": "958079"
  },
  {
    "text": "We're similarly doing the same thing with the software assets that we developed, we open source them again under the Apache \n2.0 license, the most permissive one.",
    "start": "958080",
    "end": "967480"
  },
  {
    "text": "Both to enable the community to build upon that, be able to reproduce it, be able to make use of the same in some",
    "start": "967480",
    "end": "976360"
  },
  {
    "text": "sense kind of facilities that we developed and used for the training of granite.",
    "start": "976360",
    "end": "981840"
  },
  {
    "text": "We believe that this benefits the overall community, the overall ecosystem.",
    "start": "981840",
    "end": "987120"
  },
  {
    "text": "And, um, you know, as Kate said, it enables more and more developers essentially to follow the same kind of best practices",
    "start": "987120",
    "end": "993720"
  },
  {
    "text": "that we, um, kind of, uh, learned through hard lessons, if I may say.",
    "start": "993720",
    "end": "998920"
  },
  {
    "text": "I mean, like you, you guys have solved the emoji questions so that developers don't have to. We debated a lot around the emoji",
    "start": "1000320",
    "end": "1005680"
  },
  {
    "text": "question. Yeah, I can tell this, I can only imagine the meetings and, uh, it's incredible.",
    "start": "1005680",
    "end": "1011959"
  },
  {
    "text": "Exactly. Um, that's really great. I guess the follow up question around kind",
    "start": "1011960",
    "end": "1017480"
  },
  {
    "text": "of this, um, sort of the data prep kit and open sourcing it as well is, you know, I'm,",
    "start": "1017480",
    "end": "1023720"
  },
  {
    "text": "I'm curious if you think that this is also a way of kind of encouraging other providers to also start releasing their data openly, right?",
    "start": "1023720",
    "end": "1029439"
  },
  {
    "text": "Because I think this is like such an important aspect of the ecosystem. And I've been also frustrated at times, right?",
    "start": "1029440",
    "end": "1034480"
  },
  {
    "text": "Like a new model will come out and it behaves totally differently and breaks all of your tooling. And you're like, why is that?",
    "start": "1034480",
    "end": "1039959"
  },
  {
    "text": "And I would love to be able to kind of delve a little bit further, and so the hope is like that what IBM's doing here becomes a more general practice.",
    "start": "1039960",
    "end": "1045959"
  },
  {
    "text": "Um, and I guess, kind of, Petros, I'm curious if you think, like, if you're hearing from around the industry, like, I would love to see this become more of a norm, but I'm",
    "start": "1045960",
    "end": "1052080"
  },
  {
    "text": "curious if you think it's going to become one. Right, yeah, no, that's a very good question. Yeah, there's kind of an interesting",
    "start": "1052080",
    "end": "1058400"
  },
  {
    "text": "attachment that goes like, um, you know, every conversation in AI starts with models, but ends with data, right?",
    "start": "1058400",
    "end": "1064640"
  },
  {
    "text": "Meaning that everyone recognizes that data is the, um, kind of oil or the fuel that powers the AI models.",
    "start": "1064640",
    "end": "1071880"
  },
  {
    "text": "So, um, open sourcing this is, um, you know, the data prep kit is, is a kind of a good practice, bring on more people",
    "start": "1071880",
    "end": "1079360"
  },
  {
    "text": "and developers into doing the same. There is a trend developing around essentially",
    "start": "1079360",
    "end": "1086280"
  },
  {
    "text": "providing the data assets for preparing models. NVIDIA, for example, has its own NEMO curator.",
    "start": "1086280",
    "end": "1093520"
  },
  {
    "text": "Other kind of big names as well are going towards that direction, along with",
    "start": "1093520",
    "end": "1098600"
  },
  {
    "text": "the general kind of team of openness that IBM is kind of advocating for.",
    "start": "1098600",
    "end": "1104600"
  },
  {
    "text": "Um, data is essentially the natural thing that follows. Yeah, for sure. Well, I want to throw it open before we move on to our next topic.",
    "start": "1104600",
    "end": "1110840"
  },
  {
    "text": "I mean, obviously there were lots of things announced at TechXchange. Uh, we've been talking a lot about Granite because, well, you all just",
    "start": "1110840",
    "end": "1116880"
  },
  {
    "text": "spent a lot of time working on Granite. Um, are there other things that you'd point people towards that they should, you know, check out while they're",
    "start": "1116880",
    "end": "1122039"
  },
  {
    "text": "kind of looking at this stuff online? I'm curious if, you know, I know there's a code assistant announced, but also just like I was looking at the list",
    "start": "1122040",
    "end": "1127320"
  },
  {
    "text": "and I was like, there's way more. Things that happened here, then we'll have time to cover, but I'm kind of curious if there's like, you know,",
    "start": "1127320",
    "end": "1133160"
  },
  {
    "text": "specific things that you'd highlight that we should, uh, kind of shout out here. Uh, I might just give a couple of shout outs.",
    "start": "1133160",
    "end": "1139360"
  },
  {
    "text": "One, please go and try out the models, especially on platforms like we're really excited. Olama, you can run these models locally.",
    "start": "1139360",
    "end": "1146080"
  },
  {
    "text": "They're blazing fast. Uh, really excited that we're making these models broadly available across a number of different partners.",
    "start": "1146080",
    "end": "1153080"
  },
  {
    "text": "Um, second, there was a big focus at Tech Exchange on agents and assistants.",
    "start": "1153080",
    "end": "1158280"
  },
  {
    "text": "So really excited to see how the What's Next software portfolio is continuing to evolve",
    "start": "1158280",
    "end": "1163360"
  },
  {
    "text": "and create different agent orchestrators and management of agentic systems. So I think you're going to continue to see a lot",
    "start": "1163360",
    "end": "1169680"
  },
  {
    "text": "of really exciting work from IBM in that space. Yeah, for sure. Um, and maybe we'll end with",
    "start": "1169680",
    "end": "1175400"
  },
  {
    "text": "you, Kush, is, um, you know. Uh, where is Granite going next? Uh, like I guess this is kind of a question",
    "start": "1175400",
    "end": "1180559"
  },
  {
    "text": "when we're sitting here in 2025 talking about what just happened in tech exchange, I'm kind of curious about like what the team is",
    "start": "1180560",
    "end": "1186559"
  },
  {
    "text": "piling towards and particularly in safety. I know what you work on, like if there's kind of like what's the next frontier on safety, I",
    "start": "1186560",
    "end": "1192480"
  },
  {
    "text": "think would be great for people to hear about. Yeah.\nSo, um, I mean, one thing just building on what Petro said.",
    "start": "1192480",
    "end": "1197760"
  },
  {
    "text": "Um, so, I mean, having this data prep kit out there is not only a boon for, I mean, the value creation among the",
    "start": "1197760",
    "end": "1203799"
  },
  {
    "text": "developers and the ecosystem, but it is also contributing to the safety aspects. Um, because, uh, When you can inspect",
    "start": "1203800",
    "end": "1210240"
  },
  {
    "text": "these things, then you can know. I mean, this is why this is happening. And these are potential concerns as well.",
    "start": "1210240",
    "end": "1216800"
  },
  {
    "text": "So I think just the movement towards openness is going to be a big aspect of the safety world.",
    "start": "1216800",
    "end": "1224280"
  },
  {
    "text": "Um, uh, TechXchange. We announced some new features and what's next on governance as well.",
    "start": "1224280",
    "end": "1230440"
  },
  {
    "text": "Um, so that's our platform played on the governance and safety side. But, um, where granite goes next, um, with",
    "start": "1230440",
    "end": "1238240"
  },
  {
    "text": "the granite guardian, especially, um, as Kate said, with the agentic workflows. So our next, uh, Release of Granite",
    "start": "1238240",
    "end": "1245280"
  },
  {
    "text": "Guardian will have a function calling hallucination detection. So that's something that's not out there, um, uh, from anyone else.",
    "start": "1245280",
    "end": "1252120"
  },
  {
    "text": "And, uh, I think that'll, um, kind of, uh, bridge the gap. So when you are talking, uh, to a",
    "start": "1252120",
    "end": "1258320"
  },
  {
    "text": "model in natural language, and then it translates that into an API call, um, We want to make sure that there's nothing",
    "start": "1258320",
    "end": "1265640"
  },
  {
    "text": "wrong happening between in that step. So, uh, the parameters for the function names or the parameter values, all of",
    "start": "1265640",
    "end": "1271720"
  },
  {
    "text": "those should, uh, come out cleanly. So, uh, that's, uh, I think one of the more exciting sort of things that we have lined up.",
    "start": "1271720",
    "end": "1278400"
  },
  {
    "text": "Well, awesome. A lot more to potentially talk about, but this is a great overview and I'm glad we kind of got a little behind the scenes on how these launches",
    "start": "1278400",
    "end": "1284640"
  },
  {
    "text": "happened because there's just, you know, you just see the model at the end of the day, but it's just like, it turns out like lots of humans spend a lot of time just getting that right.",
    "start": "1284640",
    "end": "1291240"
  },
  {
    "text": "So appreciate you giving our listeners a little bit of a lead in.",
    "start": "1291240",
    "end": "1299400"
  },
  {
    "start": "1297000",
    "end": "1842000"
  },
  {
    "text": "So our next story that we really want to focus on is some news that kind of came out this week about the company Perplexity.",
    "start": "1299400",
    "end": "1306280"
  },
  {
    "text": "Um, So if you're not familiar, perplexity is essentially AI driven search. Um, It's a little bit different from,",
    "start": "1306280",
    "end": "1312160"
  },
  {
    "text": "you know, what you kind of get from like a traditional Google experience where, you know, you have a search bar. Instead, it's kind of you ask queries",
    "start": "1312160",
    "end": "1318760"
  },
  {
    "text": "and you can kind of make it interactive. You have a conversation, um, and it pulls results from the internet.",
    "start": "1318760",
    "end": "1324080"
  },
  {
    "text": "Um, The big news was that the rumors were that it was about to raise, the company was about to raise 500 million,",
    "start": "1324080",
    "end": "1330679"
  },
  {
    "text": "um, at an 8 billion valuation, which I believe is twice what it was before.",
    "start": "1330680",
    "end": "1336320"
  },
  {
    "text": "Um, and, uh, and that's just, that's just wild. Obviously we're living through an era of like a lot of excitement around AI and AI company",
    "start": "1336320",
    "end": "1343160"
  },
  {
    "text": "valuations are sort of through the roof. But even I saw this number and I was like, wow, this is, this is really intense.",
    "start": "1343160",
    "end": "1348520"
  },
  {
    "text": "Um, and I guess, Kate, maybe I'll kick it to you is, um. Is this valuation justified?",
    "start": "1349240",
    "end": "1354399"
  },
  {
    "text": "Like, what is chat the future of search? Like, is this the new Google that we're looking at, or kind of curious about how you size up news that a company",
    "start": "1354400",
    "end": "1361360"
  },
  {
    "text": "like this would be valued at this value? Yeah, I mean, I think there's a lot going on, as you say, certainly a lot of hype.",
    "start": "1361360",
    "end": "1368120"
  },
  {
    "text": "Um, but yes, I think chat is the future of search. I think it's just a much more natural way to try",
    "start": "1368120",
    "end": "1374400"
  },
  {
    "text": "and find information to inquire about something. But I also really wonder, you know,",
    "start": "1374400",
    "end": "1379800"
  },
  {
    "text": "how differentiated or competitive, uh, perplexity can stay, right?",
    "start": "1379800",
    "end": "1385200"
  },
  {
    "text": "What is, how are they gonna, what's their moat, you know, to prevent others from basically doing the same thing with a, um,",
    "start": "1385200",
    "end": "1391520"
  },
  {
    "text": "with a different end, uh, API end call? So, you know, I, I do worry that we're",
    "start": "1391520",
    "end": "1396720"
  },
  {
    "text": "seeing some inflation here, uh, of expectations and, uh, in this valuation.",
    "start": "1396720",
    "end": "1402240"
  },
  {
    "text": "Yeah, for sure. I mean, not for nothing, I mean, out of all of the subscriptions that I'm spending on monthly, perplexity is one",
    "start": "1402240",
    "end": "1408000"
  },
  {
    "text": "of the few that I actually use regularly. But, okay, I think you're touching on a super important question, which is, what, what is the moat?",
    "start": "1408000",
    "end": "1413800"
  },
  {
    "text": "Is there a moat here? I mean, Petross, I'm curious if you have any views on like, it seems like maybe other",
    "start": "1413800",
    "end": "1418960"
  },
  {
    "text": "search companies that I could name might be really good at this, doing this at some point. But I mean, clearly someone sees",
    "start": "1418960",
    "end": "1424799"
  },
  {
    "text": "something in this, like, they feel like it's a good enough bet. Um, and so I guess, I don't know if you want to give us like the, the kind of bull case, right?",
    "start": "1424800",
    "end": "1430960"
  },
  {
    "text": "Like, is there a moat here? Right. Um, I have to admit, I agree with Kate. I'm also struggling to figure out",
    "start": "1430960",
    "end": "1437200"
  },
  {
    "text": "what the mode is in this case. Search, unsurprisingly, has been one of the areas that many companies, both,",
    "start": "1437200",
    "end": "1444559"
  },
  {
    "text": "um, startups as well as, like, um, big, um, megacorporations, actually have. try to tackle and attack essentially",
    "start": "1444560",
    "end": "1452400"
  },
  {
    "text": "the incumbents, right, over the years. It never panned out.",
    "start": "1452960",
    "end": "1459120"
  },
  {
    "text": "Well, why? Because, you know, the existing ones were good enough, right? They were pretty good.",
    "start": "1459120",
    "end": "1464280"
  },
  {
    "text": "Now it's a brand new interface, essentially, a brand new way of interacting with the search engine. More importantly, Getting something",
    "start": "1464280",
    "end": "1470720"
  },
  {
    "text": "that I feel everyone appreciates a very good summary of things instead of having like to go and read yourself.",
    "start": "1470720",
    "end": "1476720"
  },
  {
    "text": "Everyone really appreciates someone to summarize in a nice executive kind of bullet point type of interface.",
    "start": "1476720",
    "end": "1483720"
  },
  {
    "text": "So that being said, kind of evaluation on this kind of type of expectations",
    "start": "1483720",
    "end": "1490600"
  },
  {
    "text": "probably is kind of makes sense. The mode also struggling to figure out what it is, especially as a few big",
    "start": "1490600",
    "end": "1497840"
  },
  {
    "text": "names out there that only we're offered. Essentially on it, right? Yeah,\nfor sure.",
    "start": "1497840",
    "end": "1504360"
  },
  {
    "text": "Kush, there's one question I really wanted to bring up around safety. So, I agree. I mean, I think like, interacting with",
    "start": "1504360",
    "end": "1509480"
  },
  {
    "text": "perplexity, I'm like, oh yeah, like, chat really is like, giving me a lot of action on search.",
    "start": "1509480",
    "end": "1514800"
  },
  {
    "text": "Um, unfortunately, I think one of the things that it's caused me to do the most of recently is like, buy too many books. Because I'm always like, oh, could",
    "start": "1514800",
    "end": "1520520"
  },
  {
    "text": "you give me some recommendations? It's like, oh, of course. And here's like ten fascinating books about the thing that you're interested in.",
    "start": "1520520",
    "end": "1526039"
  },
  {
    "text": "Um, Can I, maybe I'll play skeptic for a moment is, you know, I do think that one of the really funny things about LLMs is that everybody",
    "start": "1526040",
    "end": "1533480"
  },
  {
    "text": "has rushed to use it as a search interface. But like out of the box, LLMs are not",
    "start": "1533480",
    "end": "1538880"
  },
  {
    "text": "concerned with information retrieval. They're not really concerned about facts. They're not really concerned about,",
    "start": "1538880",
    "end": "1544519"
  },
  {
    "text": "you know, validation or verification. There's no notion of like a page rank that would even give kind of like, you know, a",
    "start": "1544520",
    "end": "1550440"
  },
  {
    "text": "sense of credibility between different sources. So. You know, there's almost, if I can play skeptic",
    "start": "1550440",
    "end": "1555520"
  },
  {
    "text": "for a moment, I'd love to hear kind of the counter argument is no, you know, LLMs are not the future of search because like LLMs do",
    "start": "1555520",
    "end": "1562440"
  },
  {
    "text": "something that's just so fundamentally different from what you want out of search that like, it's weird that we're in this weird situation.",
    "start": "1562440",
    "end": "1568080"
  },
  {
    "text": "We've got this technology, we're trying to like bolt search like features onto this tech. Isn't that a little bit like getting,",
    "start": "1568080",
    "end": "1573720"
  },
  {
    "text": "you know, the car before the horse? Yeah, I mean, I think you're absolutely right in many ways, right?",
    "start": "1573720",
    "end": "1580240"
  },
  {
    "text": "So, The fact is, really, it's the RAG that's doing the search, right? And then the language model is, um,",
    "start": "1580240",
    "end": "1587120"
  },
  {
    "text": "like on top of it, I mean, creating the bullet points or whatever have you. So, um, And, like, I'll",
    "start": "1587120",
    "end": "1593200"
  },
  {
    "text": "disagree with Kate a little bit. I'm not convinced the chat is the best method for, um, for doing search, necessarily,",
    "start": "1593200",
    "end": "1599519"
  },
  {
    "text": "or the best interface, because, um, like, when I go, um, and I'm, like, searching for",
    "start": "1599520",
    "end": "1606280"
  },
  {
    "text": "stuff, um, like, whatever, like, a research assistant goes to the library and, like, is actually, like, trying to find stuff.",
    "start": "1606280",
    "end": "1612920"
  },
  {
    "text": "Um, the chat isn't, like, all of the way there, right? I mean, I think there's like, oh, you go down",
    "start": "1612920",
    "end": "1618960"
  },
  {
    "text": "one rabbit hole, or you come back, you look for this, you go over here, go do this and that. So it's not a linear process, which",
    "start": "1618960",
    "end": "1625240"
  },
  {
    "text": "is what chat kind of insists on. And so, um, uh, intent based, um,",
    "start": "1625240",
    "end": "1630760"
  },
  {
    "text": "interaction is certainly part of it. So chat is, I think, the simplest version of, uh, kind of intent, uh, communication.",
    "start": "1630760",
    "end": "1637680"
  },
  {
    "text": "But, uh, I think there's more ways of doing this that are Going to actually emerge and that are more helpful.",
    "start": "1637680",
    "end": "1643320"
  },
  {
    "text": "So that's where the LLM strength will be like, um, kind of how to organize the work, um, organize these, um, sort of",
    "start": "1643320",
    "end": "1650679"
  },
  {
    "text": "different threads and putting them together. The search itself, I think, is, um, uh, is",
    "start": "1650680",
    "end": "1656320"
  },
  {
    "text": "the retrieval part, and that is actually already not part of how the LLM is doing it. So, uh, I think that's where we might end up.",
    "start": "1656320",
    "end": "1665320"
  },
  {
    "text": "Yeah, that's super helpful. I mean as almost like it's almost two innovations really that we're talking about, right? Like one is the actual retrieval,",
    "start": "1665320",
    "end": "1671720"
  },
  {
    "text": "and then almost like the LLM is just like the spice on top that makes it, you know, um, more, more digestible.",
    "start": "1671720",
    "end": "1677800"
  },
  {
    "text": "I don't know, Kate, if you want to kind of respond to that at all. No, I mean, I don't disagree. I think Chat is a huge improvement",
    "start": "1677800",
    "end": "1684600"
  },
  {
    "text": "on search compared to just, you know, shouting into the void of a search box, but is it the final frontier?",
    "start": "1684600",
    "end": "1691760"
  },
  {
    "text": "You know, I, I definitely think because she bring up some really good points. Um, you know, this isn't a quite a",
    "start": "1691760",
    "end": "1698080"
  },
  {
    "text": "linear flow on, you know, a lot of ways. I think we've worked on, um Uh, making a",
    "start": "1698080",
    "end": "1704920"
  },
  {
    "text": "faster horse when we need a car, right, uh, is the kind of old saying we've made chat,",
    "start": "1704920",
    "end": "1710240"
  },
  {
    "text": "uh, a really fast horse, but what does a car invention look like in the, uh, search world?",
    "start": "1710240",
    "end": "1715679"
  },
  {
    "text": "So, you know, certainly there's opportunities ahead. Yeah.\nIt'd be cool if it's like an entirely different paradigm. Like in some ways, uh, I do think about",
    "start": "1715680",
    "end": "1722320"
  },
  {
    "text": "the kind of anchoring effect of stuff like stuff like chat GPT is like the only reason we've taken this interface is because",
    "start": "1722320",
    "end": "1728280"
  },
  {
    "text": "there was this accidental thing where this particular product became so successful that we kind of see everything about LLMs.",
    "start": "1728280",
    "end": "1734320"
  },
  {
    "text": "through this lens, but it's like, it's just almost like a historical accident, um, in some ways. It's really interesting to think about kind of",
    "start": "1734320",
    "end": "1740880"
  },
  {
    "text": "the different users like Kush as a researcher, you know, you probably have a, a very well honed",
    "start": "1740880",
    "end": "1747240"
  },
  {
    "text": "art to how you investigate, uh, with Upmost rigor on different topics where, you know, if",
    "start": "1747240",
    "end": "1754080"
  },
  {
    "text": "we talk about somebody who's just trying to, you know, find, you know, what grocery stores closest or, you know, more casual investigation,",
    "start": "1754080",
    "end": "1762200"
  },
  {
    "text": "you know, that's probably a different mode. So I think there's tremendous diversity as well in potential interfaces that",
    "start": "1762200",
    "end": "1767679"
  },
  {
    "text": "we're going to see for search, and there's probably not going to be one size fits all. Yeah, I would definitely agree with that.",
    "start": "1767680",
    "end": "1773200"
  },
  {
    "text": "I mean, when my kids are looking for information, like, uh, uh, like how many goals did, uh, whatever, like Alex Morgan's.",
    "start": "1773200",
    "end": "1780800"
  },
  {
    "text": "score throughout her career. I mean, they don't need to do it in the same rigorous way as I need to do my research.",
    "start": "1780800",
    "end": "1786960"
  },
  {
    "text": "So yeah, absolutely. Yeah.\nAnd I think I, my, my long term theory is that a little bit like how there's",
    "start": "1786960",
    "end": "1792240"
  },
  {
    "text": "like Google ease where people have just like, not, they don't really speak in. In English is kind of like a string of",
    "start": "1792240",
    "end": "1799080"
  },
  {
    "text": "words that they found to optimize the search result, like we will also end up having like a very even for these chat interfaces,",
    "start": "1799080",
    "end": "1805040"
  },
  {
    "text": "like our own perplexity ease, which will like not be quite a conversation, but we'll just be like how we've kind of learned",
    "start": "1805040",
    "end": "1810720"
  },
  {
    "text": "to get the best results out of the system and ironically, as we do that, the model providers are going to be",
    "start": "1810720",
    "end": "1815800"
  },
  {
    "text": "figuring out how to take that it. Translate it into what they think is optimal for the model and then feed that.",
    "start": "1815800",
    "end": "1822559"
  },
  {
    "text": "So there's just going to be layers and layers of trying to find the right way to frame a question.",
    "start": "1822560",
    "end": "1827960"
  },
  {
    "text": "And that is what agentic workflows are. I mean, I think multiple layers of agents translating from one thing",
    "start": "1828960",
    "end": "1834760"
  },
  {
    "text": "to another thing to another thing. So, I mean, that's where we're headed.",
    "start": "1834760",
    "end": "1843480"
  },
  {
    "start": "1842000",
    "end": "2233000"
  },
  {
    "text": "Alright, for our final story, it's another open source model story, but I think it's a another interesting one to kind of",
    "start": "1843480",
    "end": "1849240"
  },
  {
    "text": "compare and contrast and kind of like talk about the overall trend in open source. Nvidia, maker of fine GPUs, um, has",
    "start": "1849240",
    "end": "1857600"
  },
  {
    "text": "come out recently with a fine tune of llama that they call Nemotron, specifically Nemotron 70B Instruct.",
    "start": "1857600",
    "end": "1865480"
  },
  {
    "text": "Um, and, uh, it was kind of widely touted by Nvidia, they showed that they were able to beat a bunch of state of the art benchmarks",
    "start": "1865480",
    "end": "1871760"
  },
  {
    "text": "across all the other proprietary models. Um, I think that's all well and interesting. But I think one thing I wanted to bring to",
    "start": "1871760",
    "end": "1877560"
  },
  {
    "text": "this panel was just to ask the question of why. I know Nvidia from its GPUs, its",
    "start": "1877560",
    "end": "1883200"
  },
  {
    "text": "hardware, um, like why are they getting into the model training business? And why would they be open",
    "start": "1883200",
    "end": "1888640"
  },
  {
    "text": "sourcing models at all? Um, Petros, I'm kind of curious, you know, I'll just throw it to you. Yeah, that's a very interesting, um, question.",
    "start": "1888640",
    "end": "1894480"
  },
  {
    "text": "Um, everyone knows Nvidia about its GPUs. Um, I'm not sure, um, how many people don't",
    "start": "1894480",
    "end": "1899920"
  },
  {
    "text": "know that Nvidia is actually, Nvidia's mode is actually, in my view, software. It's actually the CUDA.",
    "start": "1899920",
    "end": "1905880"
  },
  {
    "text": "interfaces and drivers that essentially have managed to attract developers over the course",
    "start": "1905880",
    "end": "1912160"
  },
  {
    "text": "of the last 10 years onto the NVIDIA hardware. That's why everyone actually ended up using",
    "start": "1912160",
    "end": "1917840"
  },
  {
    "text": "NVIDIA and still using GPUs from NVIDIA. So in that sense they do have a very kind of strong mode in the form of software.",
    "start": "1917840",
    "end": "1925960"
  },
  {
    "text": "So it's only kind of natural to expect them to Expand on that both in terms of the software",
    "start": "1925960",
    "end": "1932440"
  },
  {
    "text": "ecosystem that they build around their hardware as well as of course showcasing this through",
    "start": "1932440",
    "end": "1937520"
  },
  {
    "text": "models that are able to train themselves. And the last kind of thought on this",
    "start": "1937520",
    "end": "1943600"
  },
  {
    "text": "from my side is the fact that NVIDIA is also developing its NVIDIA Cloud. Which is also another kind of aspect",
    "start": "1943600",
    "end": "1951360"
  },
  {
    "text": "that contributes to the ecosystem of AI models that NVIDIA essentially is driving, for sure, from the hardware side.",
    "start": "1951360",
    "end": "1958120"
  },
  {
    "text": "So I guess, I mean, Cade, this sounds like, I guess, from Petros's interpretation, it's almost like just a, it's a show of strength.",
    "start": "1958120",
    "end": "1964200"
  },
  {
    "text": "Like, NVIDIA is just saying, we can do models like this. Um, but I guess part of this is",
    "start": "1964200",
    "end": "1969680"
  },
  {
    "text": "like they're trying to attract people to their, their cloud, right? Like I guess part of this is marketing the, the cloud offering, which is true.",
    "start": "1969680",
    "end": "1975760"
  },
  {
    "text": "When I think of cloud, I think of, you know, Google, I think of Amazon. I don't really think of Nvidia. Is that kind of how you read it as well?",
    "start": "1975760",
    "end": "1981880"
  },
  {
    "text": "That it's sort of kind of like trying to promote that aspect of their business. Yeah, you know, I think it's really a powerful",
    "start": "1981880",
    "end": "1989400"
  },
  {
    "text": "demonstration, right, of being able to say we can take a model and we can customize it, we",
    "start": "1989400",
    "end": "1994560"
  },
  {
    "text": "can continue to train it, and we can continue to boost performance beyond, in NVIDIA's",
    "start": "1994560",
    "end": "1999799"
  },
  {
    "text": "terms, what was originally released in the CHAP version of Uh, instructor version rather of the 70 billion llama model, but so in doing",
    "start": "1999800",
    "end": "2008440"
  },
  {
    "text": "so, I think they're trying to demonstrate right that they have these capabilities and invite customers to come and join in and be able to",
    "start": "2008440",
    "end": "2014400"
  },
  {
    "text": "customize their own models, continue to train their own models all on NVIDIA's platform. So it makes a lot of sense just as a",
    "start": "2014400",
    "end": "2020600"
  },
  {
    "text": "pure almost marketing point, right? Being able to showcase their capabilities. Yeah, definitely. Kush, does do you, do you think this makes, um.",
    "start": "2020600",
    "end": "2027559"
  },
  {
    "text": "The other company is a little bit nervous. I'm kind of thinking about like, you know, like, NVIDIA has always been like in the background,",
    "start": "2027560",
    "end": "2033559"
  },
  {
    "text": "the chip people, they do infrastructure. And then now this is almost like what you're on our turf, right? Like, what are you doing, releasing",
    "start": "2033560",
    "end": "2039440"
  },
  {
    "text": "something that competes with O1 or, you know, Opus or whatever? Um, should, should the companies be nervous?",
    "start": "2039440",
    "end": "2045280"
  },
  {
    "text": "Like, is this kind of NVIDIA kind of playing in a new playground in some ways? Yeah, I think so. And, uh, I mean, I think in the future what'll",
    "start": "2045280",
    "end": "2052040"
  },
  {
    "text": "happen is, um, just like in the traditional machine learning, we, I mean, we have a problem.",
    "start": "2052040",
    "end": "2059240"
  },
  {
    "text": "We would look for a data set or collect a data set and then go and build a model for that. I think now in a couple of years, it's",
    "start": "2059240",
    "end": "2066040"
  },
  {
    "text": "going to be where models are the same. You have a problem. You go look for a model that's appropriate. You go look for maybe some fine",
    "start": "2066040",
    "end": "2072104"
  },
  {
    "text": "tuning data that's appropriate. And then you work with those. You're not going to treat models as",
    "start": "2072104",
    "end": "2077560"
  },
  {
    "text": "anything other than artifacts that are Okay. Part of the world of, uh, possibilities for solving your problem.",
    "start": "2077560",
    "end": "2083440"
  },
  {
    "text": "And so I think the, um, way that NVIDIA can kind of position themselves is that, um,",
    "start": "2083440",
    "end": "2090120"
  },
  {
    "text": "now, um, all these models are out there. Um, you customer, you, uh, whatever",
    "start": "2090120",
    "end": "2095159"
  },
  {
    "text": "company, you don't have to like innovate on, on, on those pre trained models. But what you do need to do is the customization.",
    "start": "2095160",
    "end": "2101240"
  },
  {
    "text": "And I mean, that's the, what's next story as well. But, um, uh, the customization, uh, come to us.",
    "start": "2101240",
    "end": "2107440"
  },
  {
    "text": "I mean, we're going to be the ones who help you. And, uh, and I think just having that",
    "start": "2107440",
    "end": "2112520"
  },
  {
    "text": "mindset available that you don't have to worry about, uh, all these, uh, these different models just on the customization.",
    "start": "2112520",
    "end": "2119640"
  },
  {
    "text": "I think that's the, uh, the part that'll, uh, kind of be their strength. Another thing I'll kind of just say is, uh,",
    "start": "2119640",
    "end": "2125599"
  },
  {
    "text": "I mean, there's, there's this overused trope. I mean, that in the gold rush, the people that made money were the ones who, um, I provided",
    "start": "2125600",
    "end": "2132920"
  },
  {
    "text": "the shovels or whatever, or the blue jeans, um, so I think with the blue jeans, I think",
    "start": "2132920",
    "end": "2139840"
  },
  {
    "text": "the thing is, I mean, they somehow crossed over from just being something for minors to being like a high fashion sort of item",
    "start": "2139840",
    "end": "2146600"
  },
  {
    "text": "people would customize, um, and so forth. So I think it's, I mean, somehow moving from that commodity to the, to",
    "start": "2146600",
    "end": "2152480"
  },
  {
    "text": "the fashion as well in some capacity. Yeah, that's right. Yeah.\nIt's the, it's the high prestige,",
    "start": "2152480",
    "end": "2157640"
  },
  {
    "text": "you know, salvage denim jeans. Yeah, that's right. Um, Yeah, I think that final comment is so",
    "start": "2157640",
    "end": "2163880"
  },
  {
    "text": "interesting, too, because it kind of suggests the ways in which, I guess, some of these visions are aligned, particularly between,",
    "start": "2163880",
    "end": "2168960"
  },
  {
    "text": "like, say, IBM and NVIDIA, where sort of NVIDIA is like, well, so long as there's more demand for models, we're excited,",
    "start": "2168960",
    "end": "2174560"
  },
  {
    "text": "because it all takes place on chips, right? Uh, and then IBM in some ways is like, we want to release all these models to kind of",
    "start": "2174560",
    "end": "2179840"
  },
  {
    "text": "unleash all these developers, but we also believe there's going to be, like, a lot of enterprise services we'll do on top of it.",
    "start": "2179840",
    "end": "2184960"
  },
  {
    "text": "Um, and I actually don't even understand, is it right? I think Granite's going to be available on NVIDIA as well. It\nis.",
    "start": "2184960",
    "end": "2190240"
  },
  {
    "text": "They were a launch partner. You can check out the Granite \n3.0 models on NVIDIA today. And even the Granite Guardian within 12",
    "start": "2190240",
    "end": "2197160"
  },
  {
    "text": "hours, they had it up as a full working demo. So you can try the Granite Guardian there too.",
    "start": "2197160",
    "end": "2202640"
  },
  {
    "text": "Yeah, it's so fast. Well, great. Well, that's all the time we have for today. Um, Kate Cush, always great to see you.",
    "start": "2202640",
    "end": "2209160"
  },
  {
    "text": "Um, thanks for taking the time to talk about Granite and Petros hopes, Petros, so we have you on the show again in the future.",
    "start": "2209160",
    "end": "2214720"
  },
  {
    "text": "Thank you very much for having me. Well listeners, if you enjoyed what you heard, you can get us on Apple Podcasts,",
    "start": "2214720",
    "end": "2220080"
  },
  {
    "text": "Spotify, and podcast platforms everywhere. And we'll see you next week for another action packed week of Mixture of Experts.",
    "start": "2220080",
    "end": "2232360"
  }
]
[
  {
    "text": "GPT, or Generative Pre-trained Transformer,",
    "start": "187",
    "end": "3132"
  },
  {
    "text": "is a large language model, or an LLM,",
    "start": "3132",
    "end": "7978"
  },
  {
    "text": "that can generate human-like text.",
    "start": "8075",
    "end": "10783"
  },
  {
    "text": "And I've been using GPT in its various forms for years.",
    "start": "10783",
    "end": "14927"
  },
  {
    "text": "In this video we are going to number 1,",
    "start": "15118",
    "end": "18948"
  },
  {
    "text": "ask \"what is an LLM?\"",
    "start": "18948",
    "end": "22353"
  },
  {
    "text": "Number 2, we are going to describe how they work.",
    "start": "22544",
    "end": "26637"
  },
  {
    "text": "And then number 3,",
    "start": "26787",
    "end": "28208"
  },
  {
    "text": "we're going to ask, \"what are the business applications of LLMs?\"",
    "start": "28208",
    "end": "32236"
  },
  {
    "text": "So let's start with number 1, \"what is a large language model?\"",
    "start": "32313",
    "end": "36339"
  },
  {
    "text": "Well, a large language model",
    "start": "36505",
    "end": "39837"
  },
  {
    "text": "is an instance of something else called a foundation model.",
    "start": "40013",
    "end": "47174"
  },
  {
    "text": "Now foundation models are pre-trained on large amounts of unlabeled and self-supervised data,",
    "start": "49201",
    "end": "55479"
  },
  {
    "text": "meaning the model learns from patterns in the data in a way that produces generalizable and adaptable output.",
    "start": "55542",
    "end": "61491"
  },
  {
    "text": "And large language models are instances of foundation models applied specifically to text and text-like things.",
    "start": "61491",
    "end": "69234"
  },
  {
    "text": "I'm talking about things like code.",
    "start": "69377",
    "end": "71310"
  },
  {
    "text": "Now, large language models are trained on large datasets of text, such as books, articles and conversations.",
    "start": "71843",
    "end": "78773"
  },
  {
    "text": "And look, when we say \"large\",",
    "start": "78773",
    "end": "81604"
  },
  {
    "text": "these models can be tens of gigabytes in size",
    "start": "81604",
    "end": "84938"
  },
  {
    "text": "and trained on enormous amounts of text data.",
    "start": "84939",
    "end": "87952"
  },
  {
    "text": "We're talking potentially petabytes of data here.",
    "start": "87952",
    "end": "90909"
  },
  {
    "text": "So to put that into perspective,",
    "start": "91165",
    "end": "93494"
  },
  {
    "text": "a text file that is, let's say, one gigabyte in size,",
    "start": "93581",
    "end": "98430"
  },
  {
    "text": "that can store about 178 million words.",
    "start": "98430",
    "end": "104561"
  },
  {
    "text": "A lot of words just in one Gb.",
    "start": "104849",
    "end": "107231"
  },
  {
    "text": "And how many gigabytes are in a petabyte?",
    "start": "107344",
    "end": "111078"
  },
  {
    "text": "Well, it's about 1 million.",
    "start": "111806",
    "end": "116529"
  },
  {
    "text": "Yeah, that's truly a lot of text.",
    "start": "117572",
    "end": "119401"
  },
  {
    "text": "And LLMs are also among the biggest models when it comes to parameter count.",
    "start": "119675",
    "end": "124054"
  },
  {
    "text": "A parameter is a value the model can change independently as it learns,",
    "start": "124536",
    "end": "128239"
  },
  {
    "text": "and the more parameters a model has, the more complex it can be.",
    "start": "128346",
    "end": "131411"
  },
  {
    "text": "GPT-3, for example, is pre-trained on a corpus of actually 45 terabytes of data,",
    "start": "131412",
    "end": "140456"
  },
  {
    "text": "and it uses 175 billion ML parameters.",
    "start": "140600",
    "end": "145036"
  },
  {
    "text": "All right, so how do they work?",
    "start": "145328",
    "end": "148299"
  },
  {
    "text": "Well, we can think of it like this.",
    "start": "148299",
    "end": "150759"
  },
  {
    "text": "LLM equals three things:",
    "start": "150759",
    "end": "154367"
  },
  {
    "text": "data, architecture, and lastly, we can think of it as training.",
    "start": "154367",
    "end": "164189"
  },
  {
    "text": "Those three things are really the components of an LLM.",
    "start": "164249",
    "end": "167728"
  },
  {
    "text": "Now, we've already discussed the enormous amounts of text data that goes into these things.",
    "start": "167855",
    "end": "173524"
  },
  {
    "text": "As for the architecture,",
    "start": "173849",
    "end": "175391"
  },
  {
    "text": "this is a neural network and for GPT that is a transformer.",
    "start": "175391",
    "end": "181810"
  },
  {
    "text": "And the transformer architecture enables the model to handle sequences of data",
    "start": "183746",
    "end": "187756"
  },
  {
    "text": "like sentences or lines of code.",
    "start": "187756",
    "end": "189912"
  },
  {
    "text": "And transformers are designed to understand the context of each word in a sentence",
    "start": "189912",
    "end": "193710"
  },
  {
    "text": "by considering it in relation to every other word.",
    "start": "193710",
    "end": "197414"
  },
  {
    "text": "This allows the model to build a comprehensive understanding of the sentence structure",
    "start": "197680",
    "end": "201157"
  },
  {
    "text": "and the meaning of the words within it.",
    "start": "201158",
    "end": "202540"
  },
  {
    "text": "And then this architecture is trained",
    "start": "203070",
    "end": "205840"
  },
  {
    "text": "on all of this large amount of data.",
    "start": "205840",
    "end": "209009"
  },
  {
    "text": "Now, during training, the model learns to predict the next word in a sentence.",
    "start": "209465",
    "end": "213525"
  },
  {
    "text": "So, \"the sky is...\" it starts off with a with a random guess, \"the sky is bug\".",
    "start": "213525",
    "end": "220956"
  },
  {
    "text": "But with each iteration, the model adjusts its internal parameters",
    "start": "221540",
    "end": "225568"
  },
  {
    "text": "to reduce the difference between its predictions and the actual outcomes.",
    "start": "225568",
    "end": "230161"
  },
  {
    "text": "And the model keeps doing this gradually improving its word predictions",
    "start": "230161",
    "end": "233678"
  },
  {
    "text": "until it can reliably generate coherent sentences.",
    "start": "233871",
    "end": "237811"
  },
  {
    "text": "Forget about \"bug\", it can figure out it's \"blue\".",
    "start": "237909",
    "end": "242556"
  },
  {
    "text": "Now, the model can be fine tuned on a smaller, more specific dataset ",
    "start": "242668",
    "end": "247486"
  },
  {
    "text": "Here the model refines its understanding to be able to perform this specific task more accurately.",
    "start": "247486",
    "end": "253096"
  },
  {
    "text": "Fine tuning is what allows a general language model",
    "start": "253285",
    "end": "256411"
  },
  {
    "text": "to become an expert at a specific task.",
    "start": "256411",
    "end": "258594"
  },
  {
    "text": "OK, so how does this all fit into number 3, business applications?",
    "start": "258935",
    "end": "262715"
  },
  {
    "text": "Well, for customer service applications,",
    "start": "263615",
    "end": "267349"
  },
  {
    "text": "businesses can use LLMs to create intelligent chatbots that can handle a variety of customer queries,",
    "start": "267471",
    "end": "272818"
  },
  {
    "text": "freeing up human agents for more complex issues.",
    "start": "273000",
    "end": "276815"
  },
  {
    "text": "Another good field, content creation.",
    "start": "277014",
    "end": "280664"
  },
  {
    "text": "That can benefit from LLMs which can help generate articles,",
    "start": "280926",
    "end": "284594"
  },
  {
    "text": "emails, social media posts, and even YouTube video scripts.",
    "start": "284673",
    "end": "289029"
  },
  {
    "text": "Hmm, there's an idea.",
    "start": "289640",
    "end": "291111"
  },
  {
    "text": "Now, LLMs can even contribute to software development.",
    "start": "291536",
    "end": "296365"
  },
  {
    "text": "And they can do that by helping to generate and review code.",
    "start": "297099",
    "end": "300588"
  },
  {
    "text": "And look, that's just scratching the surface.",
    "start": "300588",
    "end": "303158"
  },
  {
    "text": "As large language models continue to evolve,",
    "start": "303158",
    "end": "305179"
  },
  {
    "text": "we're bound to discover more innovative applications.",
    "start": "305179",
    "end": "308616"
  },
  {
    "text": "And that's why I'm so enamored with large language models.",
    "start": "309000",
    "end": "313529"
  },
  {
    "text": "If you have any questions, please drop us a line below.",
    "start": "314690",
    "end": "317254"
  },
  {
    "text": "And if you want to see more videos like this in the future,",
    "start": "317254",
    "end": "320283"
  },
  {
    "text": "please like and subscribe.",
    "start": "320283",
    "end": "322209"
  },
  {
    "text": "Thanks for watching.",
    "start": "322520",
    "end": "323496"
  }
]
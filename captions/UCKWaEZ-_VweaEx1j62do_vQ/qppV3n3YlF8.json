[
  {
    "text": "So imagine you're a journalist",
    "start": "33",
    "end": "1964"
  },
  {
    "text": "and you want to write an article",
    "start": "1964",
    "end": "4460"
  },
  {
    "text": "on a specific topic.",
    "start": "4604",
    "end": "6947"
  },
  {
    "text": "Now you have a pretty good general idea about this topic,",
    "start": "7407",
    "end": "12267"
  },
  {
    "text": "but you'd like to do some more research.",
    "start": "12267",
    "end": "14223"
  },
  {
    "text": "So you go to your local library.",
    "start": "14223",
    "end": "18385"
  },
  {
    "text": "Now, this library has thousands of books",
    "start": "19786",
    "end": "25467"
  },
  {
    "text": "on multiple different topics.",
    "start": "25468",
    "end": "27282"
  },
  {
    "text": "But how do you know, as a journalist,",
    "start": "27527",
    "end": "30027"
  },
  {
    "text": "which books are relevant for your topic?",
    "start": "30027",
    "end": "32436"
  },
  {
    "text": "Well, you go to the librarian.",
    "start": "32632",
    "end": "34836"
  },
  {
    "text": "Now, the librarian is the expert on what books contain,",
    "start": "34904",
    "end": "38605"
  },
  {
    "text": "which information in the library.",
    "start": "38605",
    "end": "40573"
  },
  {
    "text": "So, our journalist queries the librarian to retrieve",
    "start": "40675",
    "end": "45204"
  },
  {
    "text": "books on certain topics.",
    "start": "45205",
    "end": "47047"
  },
  {
    "text": "And the librarian produces those books",
    "start": "47147",
    "end": "50135"
  },
  {
    "text": "and provides them back to the journalist.",
    "start": "50135",
    "end": "51873"
  },
  {
    "text": "Now, the librarian isn't the expert on writing the article,",
    "start": "52085",
    "end": "55100"
  },
  {
    "text": "and the journalist isn't the expert",
    "start": "55101",
    "end": "56986"
  },
  {
    "text": "on finding the most up-to-date and relevant information.",
    "start": "56986",
    "end": "60000"
  },
  {
    "text": "But with the combination of the two, we can get the job done.",
    "start": "60293",
    "end": "63569"
  },
  {
    "text": "Luv, this sounds like a lot like the process of RAG,",
    "start": "64697",
    "end": "67700"
  },
  {
    "text": "or Retrieval Augmented Generation,",
    "start": "67734",
    "end": "70500"
  },
  {
    "text": "where large language models call on vector databases",
    "start": "70500",
    "end": "73570"
  },
  {
    "text": "to provide key sources of data and information",
    "start": "73570",
    "end": "76244"
  },
  {
    "text": "to answer a question.",
    "start": "76244",
    "end": "77668"
  },
  {
    "text": "I'm not seeing the connection.",
    "start": "77904",
    "end": "79546"
  },
  {
    "text": "Can you help me understand a little bit better?",
    "start": "79546",
    "end": "81114"
  },
  {
    "text": "Sure.",
    "start": "81114",
    "end": "82682"
  },
  {
    "text": "So we have a user.",
    "start": "82682",
    "end": "85156"
  },
  {
    "text": "In your scenario, it's that journalist.",
    "start": "85919",
    "end": "88922"
  },
  {
    "text": "And they have a question.",
    "start": "94394",
    "end": "96476"
  },
  {
    "text": "So what types of questions would you want to ask?",
    "start": "97430",
    "end": "100733"
  },
  {
    "text": "Maybe we can make this more of a business context.",
    "start": "100900",
    "end": "103269"
  },
  {
    "text": "Yeah, so let's say this is a business analyst.",
    "start": "103269",
    "end": "105370"
  },
  {
    "text": "And let's say they want to ask,",
    "start": "105371",
    "end": "107293"
  },
  {
    "text": "\"What was revenue in Q1 from customers in the northeast region?\"",
    "start": "107293",
    "end": "112045"
  },
  {
    "text": "Right, so that's your prompt.",
    "start": "112579",
    "end": "114988"
  },
  {
    "text": "Okay, so a couple of questions on that user.",
    "start": "117250",
    "end": "119486"
  },
  {
    "text": "Does it have to be a person or could it be something else too.",
    "start": "119486",
    "end": "122789"
  },
  {
    "text": "Yeah. So this doesn't necessarily have to be a user.",
    "start": "122922",
    "end": "125225"
  },
  {
    "text": "It could be a bot",
    "start": "125225",
    "end": "127450"
  },
  {
    "text": "or it could be another application.",
    "start": "128495",
    "end": "130968"
  },
  {
    "text": "Even the question that we're talking about,",
    "start": "131564",
    "end": "133666"
  },
  {
    "text": "\"What was our revenue in Q1 from the northeast?\"",
    "start": "133666",
    "end": "136669"
  },
  {
    "text": "You know, the first part of that question,",
    "start": "136703",
    "end": "138571"
  },
  {
    "text": "it's pretty easy for, you know, a general LLM to understand, right?",
    "start": "138571",
    "end": "142442"
  },
  {
    "text": "What was our revenue?",
    "start": "142442",
    "end": "143710"
  },
  {
    "text": "But it's that second part in Q1 from customers in the northeast.",
    "start": "143710",
    "end": "148154"
  },
  {
    "text": "That's not something that LLMs are trained on, right.",
    "start": "148314",
    "end": "150884"
  },
  {
    "text": "It's very specific to our business and it changes over time.",
    "start": "150884",
    "end": "155093"
  },
  {
    "text": "So we have to treat those separately.",
    "start": "155255",
    "end": "157423"
  },
  {
    "text": "So how do we manage that part of the request?",
    "start": "157423",
    "end": "161427"
  },
  {
    "text": "Exactly.",
    "start": "161895",
    "end": "162852"
  },
  {
    "text": "You'll need multiple different sources of data potentially",
    "start": "163023",
    "end": "165972"
  },
  {
    "text": "to answer a specific question, right?",
    "start": "165973",
    "end": "168376"
  },
  {
    "text": "Whether that's maybe a PDF, or",
    "start": "168376",
    "end": "171237"
  },
  {
    "text": "another business application,",
    "start": "171638",
    "end": "173839"
  },
  {
    "text": "or maybe some images,",
    "start": "173839",
    "end": "176614"
  },
  {
    "text": "whatever that question is, we need the appropriate data",
    "start": "176776",
    "end": "179452"
  },
  {
    "text": "in order to provide the answer back.",
    "start": "179452",
    "end": "181247"
  },
  {
    "text": "What technology allows us to aggregate that data,",
    "start": "181381",
    "end": "185201"
  },
  {
    "text": "and use it for our LLM.",
    "start": "185201",
    "end": "187287"
  },
  {
    "text": "Yeah, so we can take this data",
    "start": "187850",
    "end": "189172"
  },
  {
    "text": "and we can put it into what we call a vector database.",
    "start": "189172",
    "end": "192454"
  },
  {
    "text": "a vector database is a mathematical representation",
    "start": "195195",
    "end": "197915"
  },
  {
    "text": "of structured and unstructured data",
    "start": "197915",
    "end": "200208"
  },
  {
    "text": "similar to what we might see in an array.",
    "start": "200667",
    "end": "203670"
  },
  {
    "text": "Gotcha, and these arrays are better suited or easier to understand",
    "start": "204003",
    "end": "208793"
  },
  {
    "text": "for machine learning or generative AI models",
    "start": "208793",
    "end": "211446"
  },
  {
    "text": "versus just that underlying unstructured data.",
    "start": "211446",
    "end": "214380"
  },
  {
    "text": "Exactly.",
    "start": "214514",
    "end": "215281"
  },
  {
    "text": "We query our vector database, right?",
    "start": "215281",
    "end": "217550"
  },
  {
    "text": "And we get back an embedding that includes",
    "start": "217550",
    "end": "221321"
  },
  {
    "text": "the relevant data for which we're prompting.",
    "start": "221321",
    "end": "225346"
  },
  {
    "text": "And then we include it back into the original prompt, right?",
    "start": "225529",
    "end": "227880"
  },
  {
    "text": "Yeah, exactly.",
    "start": "227880",
    "end": "228995"
  },
  {
    "text": "That feeds back into the prompt.",
    "start": "228995",
    "end": "231030"
  },
  {
    "text": "And then once we're at this point,",
    "start": "231030",
    "end": "233125"
  },
  {
    "text": "we move over to the other side of the equation,",
    "start": "233125",
    "end": "236272"
  },
  {
    "text": "which is a large language model.",
    "start": "236272",
    "end": "237943"
  },
  {
    "text": "Gotcha, so that that prompt,",
    "start": "238504",
    "end": "240528"
  },
  {
    "text": "that includes the vector embeddings now",
    "start": "240528",
    "end": "242558"
  },
  {
    "text": "are fed into the large language model,",
    "start": "242558",
    "end": "244975"
  },
  {
    "text": "which then produces the output",
    "start": "245128",
    "end": "249705"
  },
  {
    "text": "with the answer to our original question",
    "start": "250302",
    "end": "252452"
  },
  {
    "text": "with sourced, up-to-date and accurate data.",
    "start": "252452",
    "end": "255388"
  },
  {
    "text": "Exactly. And that's a crucial aspect of it.",
    "start": "255888",
    "end": "258462"
  },
  {
    "text": "As new data comes in to this vector database,",
    "start": "258462",
    "end": "261824"
  },
  {
    "text": "where things that are updated back to your relevant question",
    "start": "262395",
    "end": "265098"
  },
  {
    "text": "around performance in Q1,",
    "start": "265098",
    "end": "267201"
  },
  {
    "text": "as new data comes in, those embeddings are updated.",
    "start": "267201",
    "end": "270240"
  },
  {
    "text": "So when that question is asked the second time,",
    "start": "270325",
    "end": "272672"
  },
  {
    "text": "we have more relevant data in order to provide back",
    "start": "272672",
    "end": "275575"
  },
  {
    "text": "to the LLM who then generates the output in the answer.",
    "start": "275575",
    "end": "279234"
  },
  {
    "text": "OK, very cool.",
    "start": "279579",
    "end": "280638"
  },
  {
    "text": "So Shawn, this sounds a lot like my original analogy there",
    "start": "280638",
    "end": "283951"
  },
  {
    "text": "with the librarian and our journalist, right?",
    "start": "283951",
    "end": "286906"
  },
  {
    "text": "So the journalists trusts that the information in the library",
    "start": "286907",
    "end": "291326"
  },
  {
    "text": "is accurate and correct.",
    "start": "291326",
    "end": "292831"
  },
  {
    "text": "Now, one of the challenges that I see is when I'm talking to enterprise customers",
    "start": "292992",
    "end": "296396"
  },
  {
    "text": "is they're concerned about deploying this kind of technology",
    "start": "296396",
    "end": "300033"
  },
  {
    "text": "into customer facing, business critical applications.",
    "start": "300433",
    "end": "304237"
  },
  {
    "text": "So if they're building applications, taking customer orders,",
    "start": "304390",
    "end": "307240"
  },
  {
    "text": "processing refunds,",
    "start": "307273",
    "end": "308823"
  },
  {
    "text": "they're worried that these kinds of technologies",
    "start": "308823",
    "end": "312679"
  },
  {
    "text": "can produce hallucinations or inaccurate results, right?",
    "start": "312979",
    "end": "316249"
  },
  {
    "text": "Or perpetuate some kind of bias.",
    "start": "316249",
    "end": "318418"
  },
  {
    "text": "What are some things that can be done",
    "start": "318418",
    "end": "320904"
  },
  {
    "text": "to help mitigate some of these concerns?",
    "start": "320904",
    "end": "322955"
  },
  {
    "text": "That brings up a great point Luv.",
    "start": "323089",
    "end": "324892"
  },
  {
    "text": "Data that comes in on this side,",
    "start": "324977",
    "end": "326762"
  },
  {
    "text": "but also on this side,",
    "start": "326762",
    "end": "328522"
  },
  {
    "text": "is incredibly important to the output that we get",
    "start": "328523",
    "end": "331171"
  },
  {
    "text": "when we go to make that prompt and get that answer back.",
    "start": "331171",
    "end": "333871"
  },
  {
    "text": "So it really is true: \"Garbage in and garbage out\", right?",
    "start": "333957",
    "end": "337398"
  },
  {
    "text": "So we need to make sure we have good data that comes into the vector database.",
    "start": "337501",
    "end": "340469"
  },
  {
    "text": "We need to make sure that data is clean,",
    "start": "340469",
    "end": "342444"
  },
  {
    "text": "governed and managed properly.",
    "start": "342444",
    "end": "345000"
  },
  {
    "text": "Gotcha, so what I'm hearing is",
    "start": "345712",
    "end": "348000"
  },
  {
    "text": "that things like governance",
    "start": "348000",
    "end": "350808"
  },
  {
    "text": "and data management",
    "start": "351050",
    "end": "354052"
  },
  {
    "text": "are of course crucial to the vector database, right?",
    "start": "355355",
    "end": "359486"
  },
  {
    "text": "So making sure that the actual information that's flowing through into the model,",
    "start": "359486",
    "end": "363796"
  },
  {
    "text": "such as the business results in the sample prompt we talked about",
    "start": "363796",
    "end": "367564"
  },
  {
    "text": "is governance and clean,",
    "start": "367564",
    "end": "368784"
  },
  {
    "text": "but also crucially,",
    "start": "368784",
    "end": "371003"
  },
  {
    "text": "on the large language model side,",
    "start": "371003",
    "end": "373479"
  },
  {
    "text": "we need to make sure that we're not using a",
    "start": "373479",
    "end": "376333"
  },
  {
    "text": "large language model that takes a black box approach, right?",
    "start": "376333",
    "end": "379441"
  },
  {
    "text": "So, a model where you don't actually know",
    "start": "379512",
    "end": "381781"
  },
  {
    "text": "what is the underlying data that went into training it, right?",
    "start": "381781",
    "end": "385670"
  },
  {
    "text": "You don't know if there's any intellectual property in there.",
    "start": "385752",
    "end": "388154"
  },
  {
    "text": "You don't know if there's inaccuracies in there",
    "start": "388154",
    "end": "390723"
  },
  {
    "text": "or you don't know if there are, pieces of data",
    "start": "390723",
    "end": "393693"
  },
  {
    "text": "that will end up perpetuating bias in your output results.",
    "start": "393693",
    "end": "396929"
  },
  {
    "text": "Right?",
    "start": "397029",
    "end": "397797"
  },
  {
    "text": "So as a business,",
    "start": "397797",
    "end": "399248"
  },
  {
    "text": "and as a business that's trying to",
    "start": "399248",
    "end": "402780"
  },
  {
    "text": "manage and uphold their brand reputation,",
    "start": "402781",
    "end": "405717"
  },
  {
    "text": "it's absolutely critical to make sure that we're taking an approach",
    "start": "405717",
    "end": "409026"
  },
  {
    "text": "that uses LLMs that are transparent in how they were trained,",
    "start": "409026",
    "end": "415137"
  },
  {
    "text": "and we can be 100% certain",
    "start": "415248",
    "end": "418422"
  },
  {
    "text": "that there aren't any inaccuracies",
    "start": "418518",
    "end": "421487"
  },
  {
    "text": "or data that's not supposed to be in there, right?",
    "start": "421487",
    "end": "425124"
  },
  {
    "text": "Yeah, exactly.",
    "start": "425324",
    "end": "426626"
  },
  {
    "text": "It's incredibly important, especially as a brand, that we get the right answers.",
    "start": "426626",
    "end": "430196"
  },
  {
    "text": "We've seen the results of impact, and especially back",
    "start": "430196",
    "end": "433399"
  },
  {
    "text": "to our original question around \"what was our revenue in Q1\", right?",
    "start": "433399",
    "end": "437073"
  },
  {
    "text": "We don't want that to be impacted by the results of a question",
    "start": "437203",
    "end": "440840"
  },
  {
    "text": "that comes from, you know, that prompts one of our LLMs.",
    "start": "440840",
    "end": "443843"
  },
  {
    "text": "Exactly, exactly.",
    "start": "444177",
    "end": "445144"
  },
  {
    "text": "So very powerful technology.",
    "start": "445144",
    "end": "446879"
  },
  {
    "text": "But it makes me think back to the the library.",
    "start": "446879",
    "end": "450050"
  },
  {
    "text": "Our journalist and librarian, they both trust the data and the books that are in the library.",
    "start": "450050",
    "end": "454654"
  },
  {
    "text": "We have to have that same kind of confidence",
    "start": "454654",
    "end": "456656"
  },
  {
    "text": "when we're building out these types of generative AI use cases for business as well.",
    "start": "456656",
    "end": "460593"
  },
  {
    "text": "Exactly, Luv.",
    "start": "460693",
    "end": "461527"
  },
  {
    "text": "So governance, AI, but also data and data management",
    "start": "461527",
    "end": "466051"
  },
  {
    "text": "are incredibly important to this process.",
    "start": "466051",
    "end": "468134"
  },
  {
    "text": "We need all three in order to get the best result.",
    "start": "468367",
    "end": "471000"
  }
]
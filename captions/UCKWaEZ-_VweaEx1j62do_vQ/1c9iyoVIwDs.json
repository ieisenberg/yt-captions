[
  {
    "start": "0",
    "end": "76000"
  },
  {
    "text": "So Suj, if you look in your LinkedIn profile lately and notice",
    "start": "66",
    "end": "3570"
  },
  {
    "text": "there are a ton of job openings for prompt engineers.",
    "start": "3570",
    "end": "7406"
  },
  {
    "text": "Absolutely.",
    "start": "7540",
    "end": "8475"
  },
  {
    "text": "And that's why today we're going to do",
    "start": "8475",
    "end": "10300"
  },
  {
    "text": "a deep dive on what that is.",
    "start": "10300",
    "end": "11644"
  },
  {
    "text": "But first, to give a little context,",
    "start": "12212",
    "end": "14071"
  },
  {
    "text": "let's talk about what large language models are used to do",
    "start": "14071",
    "end": "17786"
  },
  {
    "text": "For a review, of course, everyone is familiar with chatbots",
    "start": "17786",
    "end": "21237"
  },
  {
    "text": "and that, we see that all the time.",
    "start": "21237",
    "end": "23022"
  },
  {
    "text": "It's also used for, well, using summaries.",
    "start": "23223",
    "end": "26626"
  },
  {
    "text": "For example, another common use case",
    "start": "26626",
    "end": "28541"
  },
  {
    "text": "or information retrieval.",
    "start": "28541",
    "end": "30234"
  },
  {
    "text": "Those are three different cases.",
    "start": "30430",
    "end": "32398"
  },
  {
    "text": "But for our viewers,can you explain",
    "start": "32399",
    "end": "34518"
  },
  {
    "text": "how that applies in prompt engineering?",
    "start": "34519",
    "end": "37344"
  },
  {
    "text": "Sure, prompt engineering is really vital",
    "start": "37739",
    "end": "40114"
  },
  {
    "text": "in communicating effectively with large language models.",
    "start": "40114",
    "end": "43176"
  },
  {
    "text": "What does it mean?",
    "start": "43209",
    "end": "44411"
  },
  {
    "text": "It is designing, coming up with the proper questions",
    "start": "44411",
    "end": "47631"
  },
  {
    "text": "to get the responses you are looking for",
    "start": "47631",
    "end": "50000"
  },
  {
    "text": "from the large language model.",
    "start": "50000",
    "end": "51818"
  },
  {
    "text": "Because you want to avoid hallucinations, right?",
    "start": "51851",
    "end": "54788"
  },
  {
    "text": "Hallucinations are where you get essentially",
    "start": "54821",
    "end": "57409"
  },
  {
    "text": "false results out of a large language model.",
    "start": "57409",
    "end": "59981"
  },
  {
    "text": "And that's because ...",
    "start": "59981",
    "end": "61072"
  },
  {
    "text": "Because the large language models are predominantly trained\non the Internet data.",
    "start": "61072",
    "end": "66331"
  },
  {
    "text": "And there could be conflicting data,",
    "start": "66331",
    "end": "68040"
  },
  {
    "text": "conflicting information and so on.",
    "start": "68040",
    "end": "69903"
  },
  {
    "text": "Great, okay, I got that.",
    "start": "70136",
    "end": "71237"
  },
  {
    "text": "So we're going to look at this from four different approaches.",
    "start": "71237",
    "end": "73706"
  },
  {
    "text": "So let's get straight to it.",
    "start": "74040",
    "end": "75487"
  },
  {
    "text": "Yep.",
    "start": "75487",
    "end": "76248"
  },
  {
    "start": "76000",
    "end": "213000"
  },
  {
    "text": "we're going to look at the first approach, which is RAG, or Retrieval Augmented Generation.",
    "start": "76439",
    "end": "81089"
  },
  {
    "text": "We've had videos about this already on the channel,",
    "start": "81089",
    "end": "83383"
  },
  {
    "text": "so I have kind of a basic understanding of it",
    "start": "83659",
    "end": "85468"
  },
  {
    "text": "where you take domain specific knowledge",
    "start": "85469",
    "end": "87297"
  },
  {
    "text": "and add it to your model.",
    "start": "87297",
    "end": "88320"
  },
  {
    "text": "But how does that actually work behind the scenes?",
    "start": "88656",
    "end": "90339"
  },
  {
    "text": "Can you explain that to me?",
    "start": "90339",
    "end": "91467"
  },
  {
    "text": "Absolutely.",
    "start": "91468",
    "end": "92386"
  },
  {
    "text": "So the large language models, as you know,",
    "start": "92635",
    "end": "94683"
  },
  {
    "text": "are trained on the Internet data.",
    "start": "94683",
    "end": "96555"
  },
  {
    "text": "They are not aware of your domain specific knowledge base content at all.",
    "start": "96555",
    "end": "102093"
  },
  {
    "text": "So when you are querying the large language models,",
    "start": "102203",
    "end": "105406"
  },
  {
    "text": "you want to bring awareness of your knowledge base",
    "start": "105511",
    "end": "108704"
  },
  {
    "text": "to the large language models.",
    "start": "108897",
    "end": "110474"
  },
  {
    "text": "So when you say knowledge base here,",
    "start": "110474",
    "end": "112017"
  },
  {
    "text": "you're referring to something that might be specific to my industry,",
    "start": "112017",
    "end": "114671"
  },
  {
    "text": "specific to my company,",
    "start": "114671",
    "end": "115956"
  },
  {
    "text": "which I'm going to then be applied to the model.",
    "start": "115956",
    "end": "118717"
  },
  {
    "text": "Absolutely.",
    "start": "118717",
    "end": "119613"
  },
  {
    "text": "And so how's that work again?",
    "start": "119613",
    "end": "120788"
  },
  {
    "text": "So to make this, bring this awareness to the large language models,",
    "start": "120788",
    "end": "125087"
  },
  {
    "text": "we have to have two components.",
    "start": "125087",
    "end": "126727"
  },
  {
    "text": "One is the retrieval component,",
    "start": "126727",
    "end": "128618"
  },
  {
    "text": "which brings the context of your domain knowledge base",
    "start": "128725",
    "end": "132121"
  },
  {
    "text": "to the generated part of the larger language model.",
    "start": "132347",
    "end": "136118"
  },
  {
    "text": "And when they work together",
    "start": "136118",
    "end": "137795"
  },
  {
    "text": "and when you ask the questions to the larger language model,",
    "start": "138014",
    "end": "141175"
  },
  {
    "text": "it is now responding to your questions",
    "start": "141363",
    "end": "143932"
  },
  {
    "text": "based on the domain specificity of your content.",
    "start": "143932",
    "end": "147269"
  },
  {
    "text": "Okay, I think I got it now.",
    "start": "147269",
    "end": "148336"
  },
  {
    "text": "This retriever, that can be really as simple as a database search, right?",
    "start": "148337",
    "end": "151668"
  },
  {
    "text": "Exactly, it can be a vector database.",
    "start": "151668",
    "end": "153674"
  },
  {
    "text": "Okay, I got that.",
    "start": "153674",
    "end": "154662"
  },
  {
    "text": "But could you first kind of give me a quick example",
    "start": "154662",
    "end": "157293"
  },
  {
    "text": "of how you've seen that applied in an industry?",
    "start": "157293",
    "end": "159516"
  },
  {
    "text": "Absolutely, let's take the example of a financial information for a company.",
    "start": "160000",
    "end": "164404"
  },
  {
    "text": "Right.",
    "start": "164667",
    "end": "165168"
  },
  {
    "text": "If you were to directly ask a question through the large language model",
    "start": "165233",
    "end": "169662"
  },
  {
    "text": "about the total earnings of the company for a specific year,",
    "start": "169662",
    "end": "172732"
  },
  {
    "text": "it's going to go through its learning and Internet data",
    "start": "172923",
    "end": "176160"
  },
  {
    "text": "and come up with a number that may not be accurate.",
    "start": "176160",
    "end": "179429"
  },
  {
    "text": "Right?",
    "start": "180000",
    "end": "180767"
  },
  {
    "text": "So, for example, the annual earnings,",
    "start": "180767",
    "end": "182995"
  },
  {
    "text": "it could come back with $19.5 billion",
    "start": "182995",
    "end": "185846"
  },
  {
    "text": "and which may be totally incorrect.",
    "start": "185846",
    "end": "187540"
  },
  {
    "text": "Whereas if you want to get the accurate responses,",
    "start": "188024",
    "end": "191461"
  },
  {
    "text": "then you bring the attention to the domain knowledge base",
    "start": "191750",
    "end": "195204"
  },
  {
    "text": "and they ask the same question.",
    "start": "195376",
    "end": "197703"
  },
  {
    "text": "Then the large language model is going to refer to your knowledge base",
    "start": "197703",
    "end": "201396"
  },
  {
    "text": "to bring that answer, and this time it will be accurate,",
    "start": "201396",
    "end": "204226"
  },
  {
    "text": "say, for example, $5.4 billion.",
    "start": "204227",
    "end": "206409"
  },
  {
    "text": "I see, because this is a trusted source",
    "start": "206501",
    "end": "209050"
  },
  {
    "text": "that it can then integrate in with this larger model.",
    "start": "209050",
    "end": "212807"
  },
  {
    "text": "Correct.",
    "start": "212807",
    "end": "213405"
  },
  {
    "start": "213000",
    "end": "390000"
  },
  {
    "text": "Okay, so now we're on the second approach to prompt engineering,",
    "start": "213511",
    "end": "216678"
  },
  {
    "text": "COT, or Chain-of-Thought.",
    "start": "216678",
    "end": "218778"
  },
  {
    "text": "And I sometimes think of this as the old saying,",
    "start": "218964",
    "end": "222200"
  },
  {
    "text": "explain it to me like I'm an 8-year-old,",
    "start": "222467",
    "end": "225008"
  },
  {
    "text": "but could you give me more a practical explanation of what that really means?",
    "start": "225430",
    "end": "229500"
  },
  {
    "text": "Absolutely. I think the large language models, like any 8-year-old,",
    "start": "229748",
    "end": "234519"
  },
  {
    "text": "also need guidance on how to arrive at those responses.",
    "start": "234519",
    "end": "238452"
  },
  {
    "text": "Right, and before I jump to the Chain-of-Thought approach,",
    "start": "238693",
    "end": "242760"
  },
  {
    "text": "I want to recommend something, right?",
    "start": "242760",
    "end": "245860"
  },
  {
    "text": "Any time you are working with the large language models,",
    "start": "246220",
    "end": "249199"
  },
  {
    "text": "consider two things:",
    "start": "249199",
    "end": "250594"
  },
  {
    "text": "The number one is the RAG approach.",
    "start": "250801",
    "end": "253261"
  },
  {
    "text": "Content grounding.",
    "start": "253411",
    "end": "255295"
  },
  {
    "text": "Content ground you work large language models, right?",
    "start": "255381",
    "end": "259130"
  },
  {
    "text": "And then take the approach of prompting it,",
    "start": "259131",
    "end": "262876"
  },
  {
    "text": "guiding the model through the prompts",
    "start": "262876",
    "end": "265684"
  },
  {
    "text": "to get the responses that you need.",
    "start": "265684",
    "end": "267375"
  },
  {
    "text": "And COT belongs in that second category.",
    "start": "267376",
    "end": "270503"
  },
  {
    "text": "As well as these other three, right?",
    "start": "270503",
    "end": "272056"
  },
  {
    "text": "Absolutely.",
    "start": "272056",
    "end": "272874"
  },
  {
    "text": "So let's talk about Chain-of-Thought. Okay. Right.",
    "start": "272874",
    "end": "275419"
  },
  {
    "text": "Chain-of-Thought is all about taking a bigger task",
    "start": "276099",
    "end": "279947"
  },
  {
    "text": "of arriving at a response,",
    "start": "279947",
    "end": "281672"
  },
  {
    "text": "breaking it down into multiple sections,",
    "start": "281776",
    "end": "284629"
  },
  {
    "text": "and then combining the results of all those multiple sections",
    "start": "284629",
    "end": "287873"
  },
  {
    "text": "and coming up with the final answer.",
    "start": "287873",
    "end": "289918"
  },
  {
    "text": "So instead of asking a larger language model,",
    "start": "290919",
    "end": "294255"
  },
  {
    "text": "what is the total earnings of a company in 2022,",
    "start": "294568",
    "end": "299339"
  },
  {
    "text": "which it will give you just a blurb of a number like $5.4 million.",
    "start": "299339",
    "end": "304211"
  },
  {
    "text": "You can actually ask the large language model,",
    "start": "304556",
    "end": "307615"
  },
  {
    "text": "give me the total earnings of a company in 2022 for software,",
    "start": "307615",
    "end": "312921"
  },
  {
    "text": "for hardware, and for consulting.",
    "start": "312921",
    "end": "316824"
  },
  {
    "text": "Say, for instance. I see.",
    "start": "316825",
    "end": "317892"
  },
  {
    "text": "So you're asking me to be more precise with the idea that you'll be able",
    "start": "317892",
    "end": "321162"
  },
  {
    "text": "to get individual results that will ultimately combine.",
    "start": "321162",
    "end": "324132"
  },
  {
    "text": "Combining.",
    "start": "324132",
    "end": "324819"
  },
  {
    "text": "I see. So for example, you cited, we'll just make up some numbers,",
    "start": "324820",
    "end": "328113"
  },
  {
    "text": "if I had 5, 2, and then continue the rest.",
    "start": "328113",
    "end": "331039"
  },
  {
    "text": "And 3, for example. ",
    "start": "331039",
    "end": "332709"
  },
  {
    "text": "And the final answer will be 5 + 2 + 3.",
    "start": "332709",
    "end": "336414"
  },
  {
    "text": "That would be the output.",
    "start": "336414",
    "end": "337624"
  },
  {
    "text": "But the larger language model is now arriving at this number",
    "start": "338309",
    "end": "343134"
  },
  {
    "text": "through reasoning and through explainability.",
    "start": "343135",
    "end": "346644"
  },
  {
    "text": "This was .. these were three separate\nqueries essentially,",
    "start": "347217",
    "end": "349614"
  },
  {
    "text": "three separate prompts.",
    "start": "349614",
    "end": "350387"
  },
  {
    "text": "So the way I tell the large language model is",
    "start": "350607",
    "end": "353176"
  },
  {
    "text": "I give the problem",
    "start": "353176",
    "end": "354077"
  },
  {
    "text": "and I explain it on how I will break down the problem.",
    "start": "354215",
    "end": "357518"
  },
  {
    "text": "So, for example, I say,",
    "start": "357720",
    "end": "359307"
  },
  {
    "text": "what is the total earnings of a company?",
    "start": "359587",
    "end": "362171"
  },
  {
    "text": "And if the total earnings of a company\nfor software is 5,",
    "start": "362171",
    "end": "365690"
  },
  {
    "text": "for hardware it is 2,",
    "start": "365691",
    "end": "367192"
  },
  {
    "text": "for consulting it is 3.",
    "start": "367192",
    "end": "368737"
  },
  {
    "text": "Then the total earnings is 5 + 2 + 3.",
    "start": "368738",
    "end": "371465"
  },
  {
    "text": "Let me see if I can net that out to make sure I got it. ",
    "start": "371465",
    "end": "373819"
  },
  {
    "text": "So in RAG, we were talking about being able to essentially",
    "start": "373819",
    "end": "377717"
  },
  {
    "text": "improve based on domain knowledge,",
    "start": "377717",
    "end": "379717"
  },
  {
    "text": "but then to improve on the results that that generates.",
    "start": "379717",
    "end": "383362"
  },
  {
    "text": "We then apply this technique,",
    "start": "383362",
    "end": "384958"
  },
  {
    "text": "the \"explain it to an 8-year-old\" technique,",
    "start": "384958",
    "end": "387591"
  },
  {
    "text": "which then makes the result even better.",
    "start": "388300",
    "end": "390651"
  },
  {
    "start": "390000",
    "end": "648000"
  },
  {
    "text": "Okay, that was Chain-of-Thought,",
    "start": "390652",
    "end": "392243"
  },
  {
    "text": "which is, I understand, is a few shot prompt technique",
    "start": "392243",
    "end": "395390"
  },
  {
    "text": "where you basically provide some examples to improve the end result.",
    "start": "395777",
    "end": "398762"
  },
  {
    "text": "And I think the ReAct is kind of the same genre, but it's a little bit different. Can you explain to me the difference?",
    "start": "399686",
    "end": "405000"
  },
  {
    "text": "Absolutely, so ReAct is also a few shot prompting technique,",
    "start": "405000",
    "end": "409382"
  },
  {
    "text": "but it is different than the chain of thought.",
    "start": "409704",
    "end": "412124"
  },
  {
    "text": "In chain of thought we were going\nbreaking down the steps of arriving at a response.",
    "start": "412124",
    "end": "416994"
  },
  {
    "text": "Right, so you were reasoning through these steps and arriving at the response,",
    "start": "417083",
    "end": "421126"
  },
  {
    "text": "whereas ReAct is goes one step further. It's not only the reasoning with that,",
    "start": "421663",
    "end": "427882"
  },
  {
    "text": "but acting based off of what else is necessary to arrive at the response.",
    "start": "428111",
    "end": "432860"
  },
  {
    "text": "So this data, though, is coming from different sources.",
    "start": "432860",
    "end": "435684"
  },
  {
    "text": "We weren't talking about that in the latter case with chain of thought.",
    "start": "435684",
    "end": "438982"
  },
  {
    "text": "Mm hmm. And they are? So they are, for example,",
    "start": "438982",
    "end": "442352"
  },
  {
    "text": "you have a situation where you have your content,",
    "start": "442352",
    "end": "445755"
  },
  {
    "text": "the domain content in your private data base, knowledge base.",
    "start": "445755",
    "end": "449441"
  },
  {
    "text": "Right, but you are asking a prompt where your question is demanding responses",
    "start": "449441",
    "end": "455530"
  },
  {
    "text": "that are not already available in your knowledge base.",
    "start": "455530",
    "end": "458546"
  },
  {
    "text": "Then the ReAct approach has the ability to actually go into a private",
    "start": "458546",
    "end": "465000"
  },
  {
    "text": "at a public knowledge base",
    "start": "465192",
    "end": "467194"
  },
  {
    "text": "and gather both the information and then arrive at the response.",
    "start": "467280",
    "end": "470852"
  },
  {
    "text": "So the action part of the ReAct is its ability\nto go to the external resources",
    "start": "471067",
    "end": "476806"
  },
  {
    "text": "to gain additional information, to arrive at your responses.",
    "start": "477194",
    "end": "480964"
  },
  {
    "text": "I got it. I got it.",
    "start": "481319",
    "end": "482553"
  },
  {
    "text": "But there's one thing that confusing me just a teeny bit",
    "start": "482553",
    "end": "484729"
  },
  {
    "text": "is that in RAG, that looks awfully similar.",
    "start": "484729",
    "end": "487505"
  },
  {
    "text": "But they're not the same. Where's the difference here?",
    "start": "487505",
    "end": "490207"
  },
  {
    "text": "So the difference is they both are using the private databases, right?",
    "start": "490207",
    "end": "495469"
  },
  {
    "text": "Knowledge bases.",
    "start": "495469",
    "end": "496650"
  },
  {
    "text": "But in large language models, I want you to think about 2 steps, right?",
    "start": "496650",
    "end": "502085"
  },
  {
    "text": "One is content grounding.",
    "start": "502085",
    "end": "503796"
  },
  {
    "text": "That's what RAG is doing.",
    "start": "503796",
    "end": "505439"
  },
  {
    "text": "It is making your large language model, aware of your domain content",
    "start": "505675",
    "end": "510046"
  },
  {
    "text": "where ReACT is different is has the ability to go to the public resources,",
    "start": "510605",
    "end": "515410"
  },
  {
    "text": "public content and knowledge bases to bring additional information to complete the task.",
    "start": "515868",
    "end": "521300"
  },
  {
    "text": "Okay, before we wrap, can you give me an example of ReAct?",
    "start": "521505",
    "end": "525345"
  },
  {
    "text": "Absolutely, so let's go back to the financial example you were looking at in the previous patterns.",
    "start": "525345",
    "end": "530990"
  },
  {
    "text": "We were looking at the total earnings",
    "start": "530991",
    "end": "533660"
  },
  {
    "text": "of a company for a specific year.",
    "start": "533660",
    "end": "535946"
  },
  {
    "text": "Supposing you come back with a prompt",
    "start": "536268",
    "end": "538031"
  },
  {
    "text": "where you are asking for the total earnings of 2010 and 2022, right?",
    "start": "538031",
    "end": "544686"
  },
  {
    "text": "Your 2022 information is here in your private database ... knowledge base.",
    "start": "544686",
    "end": "550771"
  },
  {
    "text": "But 2010 information is not there, for example.",
    "start": "550771",
    "end": "554482"
  },
  {
    "text": "It's over here in the public one.",
    "start": "554482",
    "end": "555935"
  },
  {
    "text": "Exactly. I got it, okay.",
    "start": "555935",
    "end": "557104"
  },
  {
    "text": "So the large language model in the ReACT approach,",
    "start": "557104",
    "end": "561776"
  },
  {
    "text": "now takes the external ...",
    "start": "561776",
    "end": "564395"
  },
  {
    "text": "takes for the external resources to get that information for 2010",
    "start": "564395",
    "end": "568922"
  },
  {
    "text": "and then brings both of them and does the observation.",
    "start": "568922",
    "end": "572809"
  },
  {
    "text": "I see, so that's going to produce a result that takes into consideration this,",
    "start": "572809",
    "end": "576770"
  },
  {
    "text": "whereas before it might have produced, essentially, a hallucination.",
    "start": "576770",
    "end": "579697"
  },
  {
    "text": "Hallucination. And a couple of more things, right?",
    "start": "579697",
    "end": "582366"
  },
  {
    "text": "The ReAct gives you the result in a 3-step process, right?",
    "start": "582366",
    "end": "586103"
  },
  {
    "text": "When you are asking the prompt in a ReACT mode,",
    "start": "586103",
    "end": "589562"
  },
  {
    "text": "you have to, first of all, split that prompt into three steps.",
    "start": "589562",
    "end": "593898"
  },
  {
    "text": "One is the thought, right?",
    "start": "593898",
    "end": "595533"
  },
  {
    "text": "What are you looking for?",
    "start": "595533",
    "end": "597501"
  },
  {
    "text": "And the second one is action.",
    "start": "597501",
    "end": "599294"
  },
  {
    "text": "What are you getting from where, right?",
    "start": "599294",
    "end": "602597"
  },
  {
    "text": "And the third one, finally, is the observation",
    "start": "602597",
    "end": "605058"
  },
  {
    "text": "that is the summary of the action that is taking place.",
    "start": "605058",
    "end": "608570"
  },
  {
    "text": "So, for example, Part 1 will be, \"Retrieve the total earnings for 2022\" Right?",
    "start": "608845",
    "end": "616172"
  },
  {
    "text": "And the part ... so Action 1 will be",
    "start": "616172",
    "end": "618967"
  },
  {
    "text": "it will actually go to the knowledge base to retrieve 2022",
    "start": "618967",
    "end": "622881"
  },
  {
    "text": "and Observation will be 2022 value.",
    "start": "622882",
    "end": "625798"
  },
  {
    "text": "Now Part 2 is \"retrieve the value for 2010 from an external knowledge base\"",
    "start": "625798",
    "end": "632790"
  },
  {
    "text": "now and have that value there.",
    "start": "632897",
    "end": "635355"
  },
  {
    "text": "And Observation 2 will have that value",
    "start": "635355",
    "end": "637678"
  },
  {
    "text": "and then Part 3 will be comparing them",
    "start": "637678",
    "end": "640912"
  },
  {
    "text": "to arrive at which is a better total learning for you.",
    "start": "640913",
    "end": "644222"
  },
  {
    "text": "I think I've got it, that's great.",
    "start": "644222",
    "end": "646091"
  },
  {
    "text": "We only have one more to go",
    "start": "646091",
    "end": "647816"
  },
  {
    "text": "If you really want to impress your colleagues,",
    "start": "647816",
    "end": "650269"
  },
  {
    "start": "648000",
    "end": "725000"
  },
  {
    "text": "you want to learn about this next one,",
    "start": "650270",
    "end": "652124"
  },
  {
    "text": "which is Directional Stimulus Prompting, or DSP.",
    "start": "652124",
    "end": "655771"
  },
  {
    "text": "Different from the other ones, and how so?",
    "start": "655771",
    "end": "658293"
  },
  {
    "text": "DSP is a fun way,",
    "start": "658293",
    "end": "660125"
  },
  {
    "text": "and a brand new one that I want to introduce to the audience,",
    "start": "660125",
    "end": "663360"
  },
  {
    "text": "of making the large language models give specific information,",
    "start": "663360",
    "end": "669055"
  },
  {
    "text": "giving it a direction to give specific information from the task.",
    "start": "669055",
    "end": "672791"
  },
  {
    "text": "So, for example, you ask a question and say, for example,",
    "start": "673156",
    "end": "678620"
  },
  {
    "text": "\"What is the annual earnings of a company?\"",
    "start": "678620",
    "end": "683837"
  },
  {
    "text": "But then you want don't want the final number,",
    "start": "683837",
    "end": "686725"
  },
  {
    "text": "but you want specific details about annual earnings",
    "start": "686725",
    "end": "689493"
  },
  {
    "text": "for, say, software or for consulting.",
    "start": "689494",
    "end": "692588"
  },
  {
    "text": "So you give a hint and say software and consulting.",
    "start": "692588",
    "end": "695991"
  },
  {
    "text": "And the large language model, first of all, will get the earnings.",
    "start": "695991",
    "end": "700558"
  },
  {
    "text": "And then, from that, extract specific values for software and consulting.",
    "start": "700558",
    "end": "704634"
  },
  {
    "text": "This kind of reminds me of the game",
    "start": "704634",
    "end": "706293"
  },
  {
    "text": "where you're trying to get someone to draw a picture and what do you do?",
    "start": "706332",
    "end": "709214"
  },
  {
    "text": "You provide a hint, and in effect,",
    "start": "709214",
    "end": "711248"
  },
  {
    "text": "this provides you a better result in the same fashion.",
    "start": "711249",
    "end": "713258"
  },
  {
    "text": "Absolutely, so it is a very simple technique,",
    "start": "713258",
    "end": "715852"
  },
  {
    "text": "but it works very, very well when you are looking for specific values from the task.",
    "start": "715853",
    "end": "721366"
  },
  {
    "text": "So try it out!",
    "start": "721366",
    "end": "722658"
  },
  {
    "text": "Well, thanks, Suj. I now understand what DSP is,",
    "start": "723092",
    "end": "725444"
  },
  {
    "start": "725000",
    "end": "762000"
  },
  {
    "text": "but could you kind of net out, how do you combine these different techniques?",
    "start": "725444",
    "end": "728972"
  },
  {
    "text": "You should always start with RAG",
    "start": "728973",
    "end": "731281"
  },
  {
    "text": "to bring focus to your domain content,",
    "start": "731281",
    "end": "734051"
  },
  {
    "text": "but you can also combine COT and ReAct.",
    "start": "734051",
    "end": "736658"
  },
  {
    "text": "You can also combine the RAG and DSP",
    "start": "736658",
    "end": "739437"
  },
  {
    "text": "to get that cumulative effect.",
    "start": "739437",
    "end": "742564"
  },
  {
    "text": "Excellent. Okay. Well, thank you very much.",
    "start": "742564",
    "end": "745004"
  },
  {
    "text": "I hope you come back for another episode in prompt tuning.",
    "start": "745004",
    "end": "747940"
  },
  {
    "text": "Absolutely. Thank you Dan.",
    "start": "748151",
    "end": "749797"
  },
  {
    "text": "Thank you for watching. Before you leave, please click subscribe and like.",
    "start": "750967",
    "end": "755540"
  }
]
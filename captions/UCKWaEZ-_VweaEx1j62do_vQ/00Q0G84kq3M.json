[
  {
    "start": "0",
    "end": "66000"
  },
  {
    "text": "Let's talk about RAG versus fine tuning.",
    "start": "60",
    "end": "2339"
  },
  {
    "text": "Now, they're both powerful ways",
    "start": "2340",
    "end": "3763"
  },
  {
    "text": "to enhance the capabilities of large language models.",
    "start": "3763",
    "end": "6237"
  },
  {
    "text": "But today you're going to learn about their strengths,",
    "start": "6240",
    "end": "8680"
  },
  {
    "text": "their use cases and how you can choose between them.",
    "start": "8680",
    "end": "11486"
  },
  {
    "text": "So one of the biggest issues with dealing with generative AI right now",
    "start": "11490",
    "end": "15087"
  },
  {
    "text": "is one, enhancing the models,",
    "start": "15090",
    "end": "16949"
  },
  {
    "text": "but also two, dealing with their limitations.",
    "start": "16950",
    "end": "19558"
  },
  {
    "text": "For example, I just recently asked my favorite LLM a simple question.",
    "start": "19560",
    "end": "24027"
  },
  {
    "text": "Who won the Euro 2024 World Championship?",
    "start": "24030",
    "end": "27478"
  },
  {
    "text": "And while this might seem like a simple query for my model,",
    "start": "27480",
    "end": "30274"
  },
  {
    "text": "Well, there's a slight issue.",
    "start": "30274",
    "end": "31531"
  },
  {
    "text": "Because the model wasn't trained on that specific information,",
    "start": "31531",
    "end": "34647"
  },
  {
    "text": "it can't give me an accurate or up to date answer.",
    "start": "34650",
    "end": "37588"
  },
  {
    "text": "At the same time, these popular models are very generalistic.",
    "start": "37590",
    "end": "40918"
  },
  {
    "text": "And so how do we think about specializing them",
    "start": "40920",
    "end": "43626"
  },
  {
    "text": "for specific use cases and adapt them in enterprise applications?",
    "start": "43626",
    "end": "47516"
  },
  {
    "text": "Because your data is one of the most important things that you can work with.",
    "start": "47520",
    "end": "51388"
  },
  {
    "text": "And in the field of AI, using techniques such as RAG or fine tuning",
    "start": "51390",
    "end": "54809"
  },
  {
    "text": "will allow you to supercharge the capabilities that your application delivers.",
    "start": "54810",
    "end": "58886"
  },
  {
    "text": "So in the next few minutes, we're going to learn about both of these techniques,",
    "start": "58890",
    "end": "61800"
  },
  {
    "text": "the differences between them",
    "start": "61800",
    "end": "63061"
  },
  {
    "text": "and where you can start seeing and using them in.",
    "start": "63061",
    "end": "65245"
  },
  {
    "text": "Let's get started.",
    "start": "65250",
    "end": "66306"
  },
  {
    "start": "66000",
    "end": "205000"
  },
  {
    "text": "So let's begin with Retrieval Augmented Generation,",
    "start": "66810",
    "end": "69101"
  },
  {
    "text": "which is a way to increase the capabilities of a model",
    "start": "69101",
    "end": "72242"
  },
  {
    "text": "through retrieving external and up to date information,",
    "start": "72242",
    "end": "75204"
  },
  {
    "text": "augmenting the original prompt that was given to the model,",
    "start": "75210",
    "end": "77654"
  },
  {
    "text": "and then generating a response back",
    "start": "77654",
    "end": "79949"
  },
  {
    "text": "using that context and information.",
    "start": "79950",
    "end": "81959"
  },
  {
    "text": "And this is really powerful because",
    "start": "81960",
    "end": "83699"
  },
  {
    "text": "if we think back about that example",
    "start": "83700",
    "end": "85379"
  },
  {
    "text": "of with the Eurocup,",
    "start": "85380",
    "end": "86548"
  },
  {
    "text": "while the model didn't have the information and context to provide an answer.",
    "start": "86549",
    "end": "90327"
  },
  {
    "text": "And this is one of the big limitations of LLM's,",
    "start": "90330",
    "end": "92478"
  },
  {
    "text": "but this is mitigated in a way with a RAG,",
    "start": "92479",
    "end": "95173"
  },
  {
    "text": "because now instead of having an incorrect",
    "start": "95173",
    "end": "97921"
  },
  {
    "text": "or possibly hallucinated answer,",
    "start": "97921",
    "end": "101104"
  },
  {
    "text": "we're able to work with what's known as a corpus of information.",
    "start": "101105",
    "end": "104124"
  },
  {
    "text": "So this could be data,",
    "start": "104130",
    "end": "105932"
  },
  {
    "text": "this could be PDFs, documents, spreadsheets,",
    "start": "105932",
    "end": "108187"
  },
  {
    "text": "things that are relevant to our specific organization or knowledge",
    "start": "108187",
    "end": "111648"
  },
  {
    "text": "that we need to specialize in.",
    "start": "111649",
    "end": "112615"
  },
  {
    "text": "So when the query comes in this time,",
    "start": "112620",
    "end": "115184"
  },
  {
    "text": "we're working with what's known as a retriever",
    "start": "115184",
    "end": "117608"
  },
  {
    "text": "that's able to pull the correct documents and relative context",
    "start": "117608",
    "end": "122259"
  },
  {
    "text": "to what the question is and then pass that knowledge,",
    "start": "122259",
    "end": "125467"
  },
  {
    "text": "as well as the original prompt to a large language model.",
    "start": "125467",
    "end": "128931"
  },
  {
    "text": "And with its intuition and pre-trained data,",
    "start": "128940",
    "end": "131392"
  },
  {
    "text": "it's able to give us a response back",
    "start": "131392",
    "end": "133459"
  },
  {
    "text": "based on that contextualized information,",
    "start": "133460",
    "end": "135979"
  },
  {
    "text": "which is really, really powerful.",
    "start": "136105",
    "end": "137728"
  },
  {
    "text": "Because we can start to see that",
    "start": "137730",
    "end": "139290"
  },
  {
    "text": "we can get better responses back from a model with our",
    "start": "139290",
    "end": "141892"
  },
  {
    "text": "proprietary and confidential information",
    "start": "141892",
    "end": "143673"
  },
  {
    "text": "without needing to do any retraining on the model.",
    "start": "143673",
    "end": "145839"
  },
  {
    "text": "And this is a great and popular way to enhance the capabilities of a model,",
    "start": "146022",
    "end": "149818"
  },
  {
    "text": "without having to do any fine tuning.",
    "start": "149818",
    "end": "152036"
  },
  {
    "text": "So, as the name implies,",
    "start": "152040",
    "end": "153679"
  },
  {
    "text": "what this involves is taking a large language foundational model.",
    "start": "153679",
    "end": "157617"
  },
  {
    "text": "But this time we're going to be",
    "start": "157620",
    "end": "159329"
  },
  {
    "text": "specializing it in a certain domain or area.",
    "start": "159330",
    "end": "161609"
  },
  {
    "text": "So we're working with labeled and targeted data",
    "start": "161610",
    "end": "164951"
  },
  {
    "text": "that's going to be provided to the model.",
    "start": "164951",
    "end": "166857"
  },
  {
    "text": "And when we do some processing,",
    "start": "166860",
    "end": "168479"
  },
  {
    "text": "we'll have a specialized model for a specific use case",
    "start": "168480",
    "end": "172648"
  },
  {
    "text": "to talk in a certain style,",
    "start": "172650",
    "end": "174101"
  },
  {
    "text": "to have a certain tone that could represent our organization or company.",
    "start": "174102",
    "end": "177598"
  },
  {
    "text": "And so then when a model is queried from a user",
    "start": "177600",
    "end": "181665"
  },
  {
    "text": "or any other type of way,",
    "start": "181665",
    "end": "183566"
  },
  {
    "text": "we'll have a response that gives the correct tone",
    "start": "183570",
    "end": "187402"
  },
  {
    "text": "and output or specialty and a domain that we'd like to receive.",
    "start": "187402",
    "end": "191577"
  },
  {
    "text": "And this is really important because",
    "start": "191580",
    "end": "193109"
  },
  {
    "text": "what we're doing is essentially baking in this context",
    "start": "193110",
    "end": "196138"
  },
  {
    "text": "and intuition into the model.",
    "start": "196140",
    "end": "198659"
  },
  {
    "text": "And it's really important because",
    "start": "198660",
    "end": "199769"
  },
  {
    "text": "this is now a part of the model's",
    "start": "199770",
    "end": "200939"
  },
  {
    "text": "weights versus being supplemented",
    "start": "200940",
    "end": "202829"
  },
  {
    "text": "on top with a technique like rag.",
    "start": "202830",
    "end": "204960"
  },
  {
    "start": "205000",
    "end": "357000"
  },
  {
    "text": "Okay, so we understand how both of these techniques",
    "start": "206020",
    "end": "208340"
  },
  {
    "text": "can enhance a model's accuracy, output and performance.",
    "start": "208340",
    "end": "211176"
  },
  {
    "text": "But let's take a look at their strengths and weaknesses",
    "start": "211180",
    "end": "213362"
  },
  {
    "text": "and some common use cases,",
    "start": "213362",
    "end": "214562"
  },
  {
    "text": "because of the direction that you go in,",
    "start": "214562",
    "end": "216272"
  },
  {
    "text": "can greatly affect a model's performance, its accuracy,",
    "start": "216272",
    "end": "219495"
  },
  {
    "text": "outputs, compute cost, and much, much more.",
    "start": "219495",
    "end": "222032"
  },
  {
    "text": "So let's begin with Retrieval Augmented Generation.",
    "start": "222040",
    "end": "224678"
  },
  {
    "text": "And something that I want to point out here",
    "start": "224680",
    "end": "226454"
  },
  {
    "text": "is that because we're working with a corpus of information and data,",
    "start": "226454",
    "end": "229664"
  },
  {
    "text": "this is perfect for a dynamic data sources such as databases,",
    "start": "229664",
    "end": "233365"
  },
  {
    "text": "and other data repositories",
    "start": "233365",
    "end": "235482"
  },
  {
    "text": "where we want to continuously pull information",
    "start": "235482",
    "end": "237743"
  },
  {
    "text": "and have that up to date for the model to use and understand.",
    "start": "237744",
    "end": "240838"
  },
  {
    "text": "And at the same time,",
    "start": "240970",
    "end": "242409"
  },
  {
    "text": "because we're working with this retriever system",
    "start": "242409",
    "end": "244689"
  },
  {
    "text": "and passing in the information as context in the prompt,",
    "start": "244690",
    "end": "247666"
  },
  {
    "text": "well, that really helps with hallucinations.",
    "start": "247666",
    "end": "249757"
  },
  {
    "text": "And providing the sources for this information is really important",
    "start": "249760",
    "end": "253360"
  },
  {
    "text": "in systems where we need trust and transparency when we're using AI.",
    "start": "253360",
    "end": "257346"
  },
  {
    "text": "So this is fantastic, but",
    "start": "257350",
    "end": "259191"
  },
  {
    "text": "let's also think about this whole system because,",
    "start": "259191",
    "end": "261488"
  },
  {
    "text": "having this efficient retrieval system,",
    "start": "261488",
    "end": "264394"
  },
  {
    "text": "is really important in how we select and pick the data ",
    "start": "264394",
    "end": "268200"
  },
  {
    "text": "that we want to provide in that limited context window.",
    "start": "268200",
    "end": "271172"
  },
  {
    "text": "And so maintaining this is also something that you need to think about.",
    "start": "271180",
    "end": "274186"
  },
  {
    "text": "And at the same time,",
    "start": "274570",
    "end": "275858"
  },
  {
    "text": "what we're doing here in this system is effectively",
    "start": "275858",
    "end": "278321"
  },
  {
    "text": "supplementing that information on top of the model.",
    "start": "278321",
    "end": "280896"
  },
  {
    "text": "So we're not essentially enhancing the base model itself,",
    "start": "280900",
    "end": "283992"
  },
  {
    "text": "we're just giving it the relative and contextual information it needs.",
    "start": "283993",
    "end": "288126"
  },
  {
    "text": "Versus fine tuning is a little bit different,",
    "start": "288130",
    "end": "289919"
  },
  {
    "text": "because we're actually baking in",
    "start": "289919",
    "end": "291766"
  },
  {
    "text": "that context and intuition into the model,",
    "start": "291766",
    "end": "294645"
  },
  {
    "text": "while we have greater influence",
    "start": "294645",
    "end": "297288"
  },
  {
    "text": "in essentially how the model behaves and reacts in different situations.",
    "start": "297288",
    "end": "301742"
  },
  {
    "text": "Is it an insurance adjuster?",
    "start": "301750",
    "end": "303609"
  },
  {
    "text": "Can it summarize documents?",
    "start": "303610",
    "end": "305319"
  },
  {
    "text": "Whatever we want the model to do",
    "start": "305320",
    "end": "307291"
  },
  {
    "text": "we can essentially use fine tuning in order to help with that process.",
    "start": "307291",
    "end": "310987"
  },
  {
    "text": "And at the same time, because that is baked into the model's weights itself,",
    "start": "310990",
    "end": "314972"
  },
  {
    "text": "well, that's really great for speed and inference cost",
    "start": "314972",
    "end": "318046"
  },
  {
    "text": "and a variety of other factors that come to running models.",
    "start": "318046",
    "end": "321608"
  },
  {
    "text": "So, for example, we can use smaller prompt context windows",
    "start": "321610",
    "end": "325462"
  },
  {
    "text": "in order to get the responses that we want from the model.",
    "start": "325463",
    "end": "328116"
  },
  {
    "text": "And as we begin to specialize these models,",
    "start": "328120",
    "end": "330302"
  },
  {
    "text": "they can get smaller and smaller for our specific use case.",
    "start": "330302",
    "end": "332827"
  },
  {
    "text": "So it's really great for running these specific, specialized models",
    "start": "332830",
    "end": "336802"
  },
  {
    "text": "in a variety of use cases.",
    "start": "336803",
    "end": "337957"
  },
  {
    "text": "But at the same time we have the same issue of cutoffs.",
    "start": "337960",
    "end": "341198"
  },
  {
    "text": "So up until the point where the model is trained",
    "start": "341200",
    "end": "344159"
  },
  {
    "text": "well, after that, we have no more additional information",
    "start": "344159",
    "end": "346906"
  },
  {
    "text": "that we can give to the model.",
    "start": "346907",
    "end": "348188"
  },
  {
    "text": "So the same issue that we had with the World Cup example.",
    "start": "348188",
    "end": "350884"
  },
  {
    "text": "So both of these have their strengths and weaknesses.",
    "start": "350890",
    "end": "353768"
  },
  {
    "text": "But let's actually see this in some examples and use cases here.",
    "start": "353770",
    "end": "356738"
  },
  {
    "start": "357000",
    "end": "536000"
  },
  {
    "text": "So when you're thinking about choosing between RAG and fine tuning,",
    "start": "357820",
    "end": "360457"
  },
  {
    "text": "it's really important to consider your AI enabled applications,",
    "start": "360457",
    "end": "363621"
  },
  {
    "text": "priorities and requirements.",
    "start": "363621",
    "end": "365104"
  },
  {
    "text": "So namely this starts off with the data.",
    "start": "365110",
    "end": "367628"
  },
  {
    "text": "Is the data that you're working with slow moving or is it fast?",
    "start": "367630",
    "end": "371558"
  },
  {
    "text": "For example, if we need to use,",
    "start": "371560",
    "end": "374139"
  },
  {
    "text": "up to date external information",
    "start": "374140",
    "end": "375933"
  },
  {
    "text": "and have that ready contextually every time we use a model,",
    "start": "375933",
    "end": "378943"
  },
  {
    "text": "then this could be a great use case for RAG.",
    "start": "378943",
    "end": "380826"
  },
  {
    "text": "For example, a product documentation chatbot",
    "start": "380830",
    "end": "383347"
  },
  {
    "text": "where we can continually update the responses with",
    "start": "383347",
    "end": "386375"
  },
  {
    "text": "up to date information.",
    "start": "386375",
    "end": "388146"
  },
  {
    "text": "Now, at the same time, let's think about the industry that you might be in.",
    "start": "388150",
    "end": "391387"
  },
  {
    "text": "Now, fine tuning is really, powerful",
    "start": "391390",
    "end": "394058"
  },
  {
    "text": "for specific industries that have nuances in their writing styles,",
    "start": "394058",
    "end": "398433"
  },
  {
    "text": "terminology, vocabulary.",
    "start": "398433",
    "end": "400236"
  },
  {
    "text": "And so, for example, if we have a legal document Summarizer,",
    "start": "400240",
    "end": "403625"
  },
  {
    "text": "well, this could be a perfect use case for fine tuning.",
    "start": "403626",
    "end": "406326"
  },
  {
    "text": "Now let's think about sources.",
    "start": "406330",
    "end": "408189"
  },
  {
    "text": "This is really important right now",
    "start": "408190",
    "end": "410000"
  },
  {
    "text": "in having transparency behind our models.",
    "start": "410000",
    "end": "413207"
  },
  {
    "text": "And with RAG being able to provide the context",
    "start": "413207",
    "end": "415873"
  },
  {
    "text": "and where the information came from, is really, really great.",
    "start": "415873",
    "end": "419405"
  },
  {
    "text": "And so this could be a great use case again, for that",
    "start": "419410",
    "end": "422045"
  },
  {
    "text": "chat bot for retail insurance and a variety of other specialties where",
    "start": "422045",
    "end": "427642"
  },
  {
    "text": "having that source and information",
    "start": "427642",
    "end": "429463"
  },
  {
    "text": "in the context of the prompt is very important.",
    "start": "429463",
    "end": "431837"
  },
  {
    "text": "But at the same time, we may have things such as past data",
    "start": "431920",
    "end": "435125"
  },
  {
    "text": "in our organization that we can use to train a model.",
    "start": "435125",
    "end": "437646"
  },
  {
    "text": "So let it be accustomed to the data",
    "start": "437650",
    "end": "440283"
  },
  {
    "text": "that we're going to be working with.",
    "start": "440283",
    "end": "441517"
  },
  {
    "text": "For example, again, that legal summarizer",
    "start": "441520",
    "end": "443735"
  },
  {
    "text": "could have past data on different legal cases and documents",
    "start": "443735",
    "end": "446909"
  },
  {
    "text": "that we feed it so that it understands the situation that it's working in",
    "start": "446910",
    "end": "450132"
  },
  {
    "text": "and we have better, more desirable outputs.",
    "start": "450132",
    "end": "452733"
  },
  {
    "text": "So this is cool, but I think the best",
    "start": "452740",
    "end": "455245"
  },
  {
    "text": "situation is a combination of both of these methods.",
    "start": "455245",
    "end": "458497"
  },
  {
    "text": "So let's say we have a financial news reporting service.",
    "start": "458500",
    "end": "461288"
  },
  {
    "text": "Well, we could fine tune it to be native to the industry",
    "start": "461290",
    "end": "465549"
  },
  {
    "text": "of finance and understand all the lingo there.",
    "start": "465549",
    "end": "468516"
  },
  {
    "text": "We could also give it past data of financial records and let it understand",
    "start": "468520",
    "end": "472345"
  },
  {
    "text": "how we work in that specific industry,",
    "start": "472345",
    "end": "474880"
  },
  {
    "text": "but also be able to provide the most up to date sources for news and data",
    "start": "474880",
    "end": "478996"
  },
  {
    "text": "and be able to provide that with a level of confidence and transparency",
    "start": "478996",
    "end": "481941"
  },
  {
    "text": "and trust to the end user who is making that decision",
    "start": "481941",
    "end": "484735"
  },
  {
    "text": "and needs to know the source.",
    "start": "484735",
    "end": "486238"
  },
  {
    "text": "And this is really where a combination of fine tuning and RAG",
    "start": "486372",
    "end": "490450"
  },
  {
    "text": "is so awesome, because we can really build amazing applications",
    "start": "490450",
    "end": "494273"
  },
  {
    "text": "taking advantage of both RAG",
    "start": "494273",
    "end": "496401"
  },
  {
    "text": "as a way to retrieve that information and have it up to date,",
    "start": "496401",
    "end": "499212"
  },
  {
    "text": "but fine tuning to specialize our data,",
    "start": "499212",
    "end": "502422"
  },
  {
    "text": "but also specialize our model in a certain domain.",
    "start": "502422",
    "end": "504899"
  },
  {
    "text": "So, they're both wonderful techniques,",
    "start": "504910",
    "end": "508014"
  },
  {
    "text": "and they have their strengths,",
    "start": "508014",
    "end": "509525"
  },
  {
    "text": "but the choice to use one or combination of both techniques",
    "start": "509525",
    "end": "511918"
  },
  {
    "text": "is up to you and your specific use case and data.",
    "start": "511918",
    "end": "515013"
  },
  {
    "text": "So thank you so much for watching.",
    "start": "515020",
    "end": "517418"
  },
  {
    "text": "As always, if you have any questions about",
    "start": "517419",
    "end": "519388"
  },
  {
    "text": "fine tuning, RAG, or all AI-related topics,",
    "start": "519389",
    "end": "522146"
  },
  {
    "text": "let us know in the comment section below.",
    "start": "522146",
    "end": "523896"
  },
  {
    "text": "Don't forget to like the video",
    "start": "524083",
    "end": "525275"
  },
  {
    "text": "and subscribe to the channel for more content.",
    "start": "525275",
    "end": "527577"
  },
  {
    "text": "Thanks so much for watching!",
    "start": "527577",
    "end": "529019"
  }
]
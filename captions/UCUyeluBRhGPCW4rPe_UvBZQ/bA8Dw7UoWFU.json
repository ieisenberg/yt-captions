[
  {
    "start": "0",
    "end": "55000"
  },
  {
    "text": "three key lessons in application server optimization November 15 2023 hot off",
    "start": "80",
    "end": "6399"
  },
  {
    "text": "the presses weeks I've spent most of my time let's see weeks I spend most of my time improving the performance of uh",
    "start": "6399",
    "end": "12599"
  },
  {
    "text": "wait something's wrong here some something's wrong here something's wrong here I zoomed in and it got all effed up",
    "start": "12599",
    "end": "18720"
  },
  {
    "text": "oh yeah it got all effed up once you zoom in okay over the past six weeks we've I I've spent most of my time",
    "start": "18720",
    "end": "25119"
  },
  {
    "text": "improving the performance of graphitees application server affectionally nicknamed subwoofer while this effort is",
    "start": "25119",
    "end": "31119"
  },
  {
    "text": "still fresh in my mind I wanted to share three key lessons that help me uh help us find meaningful performance gains in",
    "start": "31119",
    "end": "37280"
  },
  {
    "text": "uh and in doing so greatly improve the graphite user experience okay okay I'm",
    "start": "37280",
    "end": "42879"
  },
  {
    "text": "pretty excited about this yeah by the way I do love it that I can that I want to be able to zoom in and have all the",
    "start": "42879",
    "end": "48039"
  },
  {
    "text": "side stuff go away so I can just look at the article because now it has to be so small you know what I mean it has to be",
    "start": "48039",
    "end": "54480"
  },
  {
    "text": "so small all right context uh we started to investigate our app server performance in Earnest after noticing a",
    "start": "54480",
    "end": "60480"
  },
  {
    "start": "55000",
    "end": "430000"
  },
  {
    "text": "few uh concerning Trends in the data over the summer okay at the time we would semi-frequently experience large",
    "start": "60480",
    "end": "66560"
  },
  {
    "text": "but unexplained regressions in server endpoint latency all right every three or four",
    "start": "66560",
    "end": "71799"
  },
  {
    "text": "weeks a team would get paged because of large regression in endpoint response time think something like P90 shifted up",
    "start": "71799",
    "end": "77799"
  },
  {
    "text": "to eight seconds for a few",
    "start": "77799",
    "end": "81200"
  },
  {
    "text": "minutes oh that's crazy if you're getting 8 seconds on a P90 that means",
    "start": "83960",
    "end": "89320"
  },
  {
    "text": "10% of your customers are having 10 or 8 seconds or larger request times that's",
    "start": "89320",
    "end": "96320"
  },
  {
    "text": "crazy I smell GC issues I don't think so you'd have to be on an old ass version of of node you'd have to be on like node",
    "start": "96880",
    "end": "103360"
  },
  {
    "text": "12 in practice these regressions would render the graphite's dashboard unusually slow for reviewing or merging",
    "start": "103360",
    "end": "109399"
  },
  {
    "text": "PRS but then again really large amounts of react can be quite slow despite",
    "start": "109399",
    "end": "114520"
  },
  {
    "text": "dayong investigations into these regressions each time they cropped up the cause of these incidents remained a mystery have you profile filed as a",
    "start": "114520",
    "end": "120680"
  },
  {
    "text": "result we began settling into an uneasy Rhythm that we've noticed large performance regression scale up the number of server pods dig in usually",
    "start": "120680",
    "end": "127320"
  },
  {
    "text": "find nothing and just move on repeating the exercise again for a few weeks later really being able to run a server",
    "start": "127320",
    "end": "134000"
  },
  {
    "text": "isolate a server Run It To The Ground profile uh usually if you're on a server",
    "start": "134000",
    "end": "139560"
  },
  {
    "text": "perf utilities is around pf's a great one to really get a good look at kind of where time in generally is being spent",
    "start": "139560",
    "end": "145680"
  },
  {
    "text": "uh between the aforementioned regressions and the outlier uh outlier users we've noticed uh were adding",
    "start": "145680",
    "end": "150920"
  },
  {
    "text": "disproportional load our site performance graph were extremely spiky when teammates Andor users in our slack",
    "start": "150920",
    "end": "156640"
  },
  {
    "text": "Community remarked that our site had gotten slower over the past window of time it was difficult to authoritatively",
    "start": "156640",
    "end": "162239"
  },
  {
    "text": "verify or disprove this let alone Point pinpoint the cause um wait",
    "start": "162239",
    "end": "169080"
  },
  {
    "text": "what wait what of course you can verify it you just eff and said your P90 was above 8",
    "start": "169080",
    "end": "175319"
  },
  {
    "text": "seconds you can verifiy verify yes with all authority we're",
    "start": "175319",
    "end": "183440"
  },
  {
    "text": "slow right now we're slower than we were and it happens a lot of",
    "start": "183440",
    "end": "190239"
  },
  {
    "text": "times we don't know why sorry my P90 69 is under three milliseconds well damn",
    "start": "190239",
    "end": "196799"
  },
  {
    "text": "son that's fast anyways that's kind of I feel like you can verify that these things are",
    "start": "196799",
    "end": "203159"
  },
  {
    "text": "happening it's just why we have no idea there uh there was a clear user pain to be addressed if only we could get",
    "start": "203159",
    "end": "208680"
  },
  {
    "text": "Wrangle on the system okay uh hope this investigation let's see the hope for this investigation was two-part learn",
    "start": "208680",
    "end": "214560"
  },
  {
    "text": "where those large aggressions were coming from and remove any of them as possible reducing the bad user experience and making it easier to",
    "start": "214560",
    "end": "219920"
  },
  {
    "text": "understand app server performance Trends over time let's dive in uh",
    "start": "219920",
    "end": "226439"
  },
  {
    "text": "typically I'm G to I'm just going to toss out before I look it almost always come down to",
    "start": "226560",
    "end": "232720"
  },
  {
    "text": "coping promises react server rendering",
    "start": "232720",
    "end": "241680"
  },
  {
    "text": "just going to throw it out there your P90 is 5.7 almost statistically",
    "start": "242239",
    "end": "249159"
  },
  {
    "text": "averaged I'm just going to assume the problem isn't with looking up data Maybe",
    "start": "249760",
    "end": "255000"
  },
  {
    "text": "that's going to be 500 milliseconds but that's usually a very obvious problem when your database is the slow thing",
    "start": "255000",
    "end": "261519"
  },
  {
    "text": "okay all right throughout this investigation I used our existing uh P95 server endpoint metric as my guide",
    "start": "261520",
    "end": "267400"
  },
  {
    "text": "whenever I saw a spike in this metric I would dig in as proposed to pass incidents where we would investigate thing uh things would return to normal",
    "start": "267400",
    "end": "273560"
  },
  {
    "text": "and then we'd move back on to other work this time I didn't rest until I had answers we had a hypothesis of of course",
    "start": "273560",
    "end": "279360"
  },
  {
    "text": "hypothesis of course but the results were actually surprising a few things emerged okay one one verify the",
    "start": "279360",
    "end": "285080"
  },
  {
    "text": "underlying impact P95 latency can be too blunt okay interesting okay what does this mean this lesson is key for an",
    "start": "285080",
    "end": "291840"
  },
  {
    "text": "application that integrates with a third party API in our case",
    "start": "291840",
    "end": "296960"
  },
  {
    "text": "API providing experience and or provider experiencing an incident to spike your P or your app's P95 response time okay",
    "start": "299720",
    "end": "307240"
  },
  {
    "text": "that's fair this is fair you should put timeouts always put timeouts uh all without any real degradation on your uh",
    "start": "307240",
    "end": "313960"
  },
  {
    "text": "side during the six weeks when I was working on performance a large customer onboarded onto our graphite onto our",
    "start": "313960",
    "end": "319759"
  },
  {
    "text": "graphite yeah I don't know a graphite I actually I don't think I've used graphite a few days after the customer onboarded sessions we've noticed a",
    "start": "319759",
    "end": "325080"
  },
  {
    "text": "search and server latencies okay so we're having some issues hi QPS failing",
    "start": "325080",
    "end": "332039"
  },
  {
    "text": "server nodes DB bottlenecks okay okay exciting graphite is awesome time series database oh super cool I've never played",
    "start": "332039",
    "end": "339120"
  },
  {
    "text": "with a Time series database I always have to use Hadoop at at work or Hive a",
    "start": "339120",
    "end": "344440"
  },
  {
    "text": "lot of hiving told you and so I've never played I I I've I've briefly seen",
    "start": "344440",
    "end": "350840"
  },
  {
    "text": "grafana and you know I almost had to write an adapter for grafana but I've",
    "start": "350840",
    "end": "356600"
  },
  {
    "text": "never I've never played with grafana much",
    "start": "356600",
    "end": "361479"
  },
  {
    "text": "so looking at a rollup let's see looking at a rollup on the top user endpoint combinations we noticed that a surge in",
    "start": "361840",
    "end": "367960"
  },
  {
    "text": "the number of requests was coming from a specific set of users one or when one of these users",
    "start": "367960",
    "end": "374160"
  },
  {
    "text": "would try to load the insights page on the graphite dashboard our app server would try to grab a profile info for",
    "start": "374160",
    "end": "380319"
  },
  {
    "text": "every GitHub user in their monor repo including their GitHub Avatar URLs ooh",
    "start": "380319",
    "end": "385800"
  },
  {
    "text": "which needed to be proxied through a server resulting in a single Network request for each Avatar and thousands of requests with a span of seconds this was",
    "start": "385800",
    "end": "393440"
  },
  {
    "text": "not ideal but easily remedied okay great this is a great okay so great great stuff right here don't make a thousand",
    "start": "393440",
    "end": "400280"
  },
  {
    "text": "requests okay I just assumed that whatever the problems were we weren't going to see these type of problems",
    "start": "400280",
    "end": "405720"
  },
  {
    "text": "because these are very obvious problems don't make a thousand requests right like this just bad it's just bad for",
    "start": "405720",
    "end": "411039"
  },
  {
    "text": "business okay it creates a thousand promises it has to wait for a thousand things to be done uh it's just it's just",
    "start": "411039",
    "end": "416199"
  },
  {
    "text": "not a good thing we quickly stemmed the bleeding uh for this customer and based on the knowledge we had around queries per second the cost of each request",
    "start": "416199",
    "end": "422560"
  },
  {
    "text": "assumed that we had taken a sitewide hit in performance because of the spikes over uh an overall server latency",
    "start": "422560",
    "end": "429199"
  },
  {
    "text": "however digging in showed a different picture our server actually processed the thousands of Avatar proxies with no",
    "start": "429199",
    "end": "434720"
  },
  {
    "text": "trouble instead it was the customer GitHub Enterprise instance that had become overwhelmed leading to a high",
    "start": "434720",
    "end": "440240"
  },
  {
    "text": "endpoint latency for this particular organization but perfectly normal behavior for all other graphite users",
    "start": "440240",
    "end": "445879"
  },
  {
    "text": "okay the lesson here sometimes P95 latency can be a bit too blunt and shift",
    "start": "445879",
    "end": "451319"
  },
  {
    "text": "and shift as a result of a few",
    "start": "451319",
    "end": "454800"
  },
  {
    "text": "outliers I don't get that I honestly don't get that phrase because I'm just trying to understand it P95 means your",
    "start": "457280",
    "end": "463280"
  },
  {
    "text": "top 5% of your customers it's not a few outliers it it's the 4.99% behind the",
    "start": "463280",
    "end": "471280"
  },
  {
    "text": "P95 that are slower right so if you see a shift in your P95 that means there's like people are",
    "start": "471280",
    "end": "479960"
  },
  {
    "text": "hurting right 5% one out of 20 if top 5% is five users then it's an outlier well",
    "start": "479960",
    "end": "485360"
  },
  {
    "text": "if top 5% is five",
    "start": "485360",
    "end": "488599"
  },
  {
    "text": "users I'd have to think about that okay so the P95 is a the a number of requests and you have power users in which are",
    "start": "492159",
    "end": "497800"
  },
  {
    "text": "Distributing most of the requests that is that what they're trying to say so that the P95 could just be a couple",
    "start": "497800",
    "end": "505520"
  },
  {
    "text": "users if you're if the top 95 is five users then your bottom 95 is 95",
    "start": "505520",
    "end": "512760"
  },
  {
    "text": "users if you have 100 users you don't really need percentiles right you want percentiles always so that's the thing I",
    "start": "512760",
    "end": "519200"
  },
  {
    "text": "guess I'm a little bit confused on what does this mean are they saying like because one really good way to make sure that you're doing a good job measuring",
    "start": "519200",
    "end": "526120"
  },
  {
    "text": "how users are affected is that you need to be able to take the uh you need to be",
    "start": "526120",
    "end": "531920"
  },
  {
    "text": "able to take all of a users's experience and then take that individual user's",
    "start": "531920",
    "end": "537720"
  },
  {
    "text": "experience and average it and then take the medians of the user's averages and",
    "start": "537720",
    "end": "543360"
  },
  {
    "text": "why I think that is more important is that one user that does like 900 things",
    "start": "543360",
    "end": "550079"
  },
  {
    "text": "becomes a singular data point that way you have a more reasonable distribution",
    "start": "550079",
    "end": "555600"
  },
  {
    "text": "of what is happening for each user you can have better insights into each user uh I always found that to be a way",
    "start": "555600",
    "end": "561880"
  },
  {
    "text": "better way to kind of look at these type of things you don't want to let one power user",
    "start": "561880",
    "end": "567640"
  },
  {
    "text": "shift you know your stuff around just something to think about uh We've let's",
    "start": "567640",
    "end": "572680"
  },
  {
    "start": "570000",
    "end": "700000"
  },
  {
    "text": "see we've since seen other instances in which P95 latency was pushed up because of a regression in one end point in",
    "start": "572680",
    "end": "578000"
  },
  {
    "text": "particular while I was uh while I still use P95 latency as the simplest leading indicator it's crucial to attach it to a",
    "start": "578000",
    "end": "584240"
  },
  {
    "text": "chart of P95 is grouped by endpoint yep Fair good average average users no you",
    "start": "584240",
    "end": "589880"
  },
  {
    "text": "want median average you want you want to do the median always median is good you don't want to just do averages across",
    "start": "589880",
    "end": "595800"
  },
  {
    "text": "the board you only take average of the user's experience then then you look at the the quantiles of the",
    "start": "595800",
    "end": "601760"
  },
  {
    "text": "averages then it's a little bit nicer I think in the tldr is you are a big client uh so we'll ignore your bad",
    "start": "601760",
    "end": "608720"
  },
  {
    "text": "experience well yeah not the median you want quanti but you get the idea you get you get the idea all right P95 P95 by",
    "start": "608720",
    "end": "615440"
  },
  {
    "text": "endpoint very interesting look at that look at that purple just blow up interesting interesting for an example",
    "start": "615440",
    "end": "621040"
  },
  {
    "text": "you can spot the significant jump in P95 at just before 6 a.m. above is actually due to a spike in response time from the",
    "start": "621040",
    "end": "626920"
  },
  {
    "text": "yellow endpoint I honestly can't tell I mean I see these",
    "start": "626920",
    "end": "632720"
  },
  {
    "text": "spikes in yellow but I also see spikes in purple blue has been really spiky I I can't quite tell what he means by that",
    "start": "632720",
    "end": "638720"
  },
  {
    "text": "now this on the other hand this oh this chart yes this chart seems very reasonable to look at this chart I can I",
    "start": "638720",
    "end": "644160"
  },
  {
    "text": "can really see that things were happening and then all the things seem to happen but still I'm not sure how I",
    "start": "644160",
    "end": "650880"
  },
  {
    "text": "don't really know what's happening because blue is low and then blue just just skyrockets but yellow's been up for",
    "start": "650880",
    "end": "656200"
  },
  {
    "text": "a while been up for 8 10 10",
    "start": "656200",
    "end": "661279"
  },
  {
    "text": "hours on the other hand here's a clear example on Thursday July 24th where uh there is a true sitewide regression with",
    "start": "661279",
    "end": "668279"
  },
  {
    "text": "all the lines spiking uh each other let's see each color representing a different end point okay okay I still",
    "start": "668279",
    "end": "674760"
  },
  {
    "text": "don't really I I don't quite understand the lesson here I don't understand the lesson I",
    "start": "674760",
    "end": "680480"
  },
  {
    "text": "just think they're not necessarily measuring their P95 potentially well uh unsure watch out for the event Loop",
    "start": "680480",
    "end": "686079"
  },
  {
    "text": "blockers in particular big queries okay I like this this is this is good uh with the per endpoint graphs in place I",
    "start": "686079",
    "end": "692360"
  },
  {
    "text": "started H uh honing in on the use cases where we'd see sitewide regressions and ass surge across many endpoints uh end",
    "start": "692360",
    "end": "699519"
  },
  {
    "text": "points latencies simultaneously some of the regressions where the result of issues we were familiar with high uh",
    "start": "699519",
    "end": "705200"
  },
  {
    "text": "database CPU and outlier number of requests servers running out of",
    "start": "705200",
    "end": "710920"
  },
  {
    "text": "memory classic JavaScript on that last one I love that last",
    "start": "711360",
    "end": "717720"
  },
  {
    "text": "one that's not a skill issue that's just a JS issue and sort of a skill issue uh",
    "start": "717959",
    "end": "723800"
  },
  {
    "text": "but for the other regressions all of our variables seem to hold at healthy levels despite a jump in latency in some of",
    "start": "723800",
    "end": "730399"
  },
  {
    "text": "those cases we just see a quiet period where everything would look healthy then there'd be a few or no air logs but",
    "start": "730399",
    "end": "736360"
  },
  {
    "text": "latency would still be uh Skyhigh yeah you're blocking baby uh because the lack of concerning external variables or",
    "start": "736360",
    "end": "742600"
  },
  {
    "text": "hypothesis was that there must be something occurring within nodejs process itself enter node event loop",
    "start": "742600",
    "end": "748600"
  },
  {
    "text": "block ERS oh interesting is there a specific list of event Loop",
    "start": "748600",
    "end": "754440"
  },
  {
    "text": "blockers don't block the event Loop or worker pool well yeah but who's blocking I mean sometimes you have to do a lot of",
    "start": "755399",
    "end": "761480"
  },
  {
    "text": "work I mean that's just a reality and that blocks uh the simple mental model here is that node is uh single threaded",
    "start": "761480",
    "end": "768240"
  },
  {
    "text": "so when you do heavy synchronous compute you can block the process and thus the server from handling any other inflight",
    "start": "768240",
    "end": "774000"
  },
  {
    "text": "requests yes data dog provides a basic outof thebox dashboard here uh though though granted it does have some",
    "start": "774000",
    "end": "780160"
  },
  {
    "text": "weaknesses uh it also slows everything else you're doing down so if you're having problems with promises SL like",
    "start": "780160",
    "end": "785760"
  },
  {
    "text": "crushing out stuff you also by the nature of observing make things difficult uh namely that once you get",
    "start": "785760",
    "end": "793199"
  },
  {
    "text": "down to this service level you can't Slice on a per pod basis despite each pod having its a separate node process",
    "start": "793199",
    "end": "800120"
  },
  {
    "text": "with its own event Loop you can't let's see you can't examine each pod granularly oh that's too bad I assume",
    "start": "800120",
    "end": "805519"
  },
  {
    "text": "they can fix that that seems like a fixable issue here this means that a large event Loop blockers may get hidden",
    "start": "805519",
    "end": "811320"
  },
  {
    "text": "and averaged out if the other nine server Pods at the time are doing",
    "start": "811320",
    "end": "816600"
  },
  {
    "text": "fine you could also just I mean if you're just doing testing uh you could also just launch a bunch of single pod",
    "start": "816760",
    "end": "823120"
  },
  {
    "text": "instances out there right I mean yeah you're being really wasteful with your CPU but for a little",
    "start": "823120",
    "end": "828399"
  },
  {
    "text": "while you know be wasteful to try to catch a problem that's that's I think that's fair uh instead I suggested uh",
    "start": "828399",
    "end": "835040"
  },
  {
    "text": "via Ashby uh in the let's see in an extremely help ful blog post I found logging to be more fruitful approach I",
    "start": "835040",
    "end": "841399"
  },
  {
    "text": "do like a good oldfashioned logging o uh as a side note we also tried profiling our CPU using Linux perf tools as per",
    "start": "841399",
    "end": "847320"
  },
  {
    "text": "Netflix suggested let's go is this the yunong one uh I like this one but we uh wound up preferring Ashby's approach for",
    "start": "847320",
    "end": "853560"
  },
  {
    "text": "a couple reasons adws doesn't expose the underlying settings needed to use Linux perf tools on ECS containers okay okay",
    "start": "853560",
    "end": "860440"
  },
  {
    "text": "fair fair uh Ashby's approach allows us to identify the specific request that",
    "start": "860440",
    "end": "865839"
  },
  {
    "text": "block the event Loop making it easy to replay uh set request with the exact details to recreate the blocking",
    "start": "865839",
    "end": "872160"
  },
  {
    "text": "conditions this would be possible with plain flame chart okay that's fair that's really fair uh here here's what",
    "start": "872160",
    "end": "878639"
  },
  {
    "text": "the end result of implementing this logging approach looked like oh very cool okay so you're able to",
    "start": "878639",
    "end": "884720"
  },
  {
    "text": "replay these requests and you just put a bunch of logs in that effectively track all the logs and the time spent for each one of these you have like effectively a",
    "start": "884720",
    "end": "890639"
  },
  {
    "text": "bunch of performance counters and you have a bunch of things summing it up and then you have the the related request",
    "start": "890639",
    "end": "896600"
  },
  {
    "text": "coming in",
    "start": "896600",
    "end": "900680"
  },
  {
    "text": "that's pretty cool uh the APM Trace includes request start log which allows us to replay the request locally with",
    "start": "902000",
    "end": "907120"
  },
  {
    "text": "the manage command that then spits out an Associated curl command to replay the request and debug against a local server",
    "start": "907120",
    "end": "912839"
  },
  {
    "text": "very cool that's super cool after debugging lots of requests in this manner there are a few common themes half of the event Loops blockers were",
    "start": "912839",
    "end": "919480"
  },
  {
    "start": "913000",
    "end": "994000"
  },
  {
    "text": "from intensive synchronous work that we were doing rendering react uh in this case we moved computation off the main",
    "start": "919480",
    "end": "926160"
  },
  {
    "text": "event Loop and into a worker thread the other half came from database queries specifically database queries that returned a significant amount of data",
    "start": "926160",
    "end": "933480"
  },
  {
    "text": "when type omm received results back from the database it parses these Raw results and transforms them into typed entities",
    "start": "933480",
    "end": "939959"
  },
  {
    "text": "that we then interact with in our code base or are they using um is it some sort of input validation like",
    "start": "939959",
    "end": "946959"
  },
  {
    "text": "Zod uh SSR is not bad some SSR is",
    "start": "946959",
    "end": "952639"
  },
  {
    "text": "bad uh not all not all SSR is created equally uh let's see because I'm curious",
    "start": "952639",
    "end": "959639"
  },
  {
    "text": "about this because when it says that you have a typed omm is is there some sort of like Zod like validation for this",
    "start": "959639",
    "end": "966000"
  },
  {
    "text": "because Zod is like definitely not known for its speediness now maybe it's gotten better I haven't looked at it in a while",
    "start": "966000",
    "end": "971920"
  },
  {
    "text": "but Zod is most certainly not fast uh when these Raw results are large three megabytes or larger in our particular",
    "start": "971920",
    "end": "978040"
  },
  {
    "text": "case the uh this parsing can be extremely expensive valid I verified this by",
    "start": "978040",
    "end": "983839"
  },
  {
    "text": "cloning a type orm locally plugging it into a server and adding custom debug logs yes",
    "start": "983839",
    "end": "989040"
  },
  {
    "text": "it's blazingly type orm does is OD stuff yeah so yeah that's very very typically",
    "start": "989040",
    "end": "994720"
  },
  {
    "start": "994000",
    "end": "1094000"
  },
  {
    "text": "type validation runtime validation because you're not using a real typed language remember typescript is not statically typed it's a lint okay if you",
    "start": "994720",
    "end": "1002040"
  },
  {
    "text": "don't think of it if you think of it as a lint you will not be disappointed as much with typescript but the moment you think about it like it's typed like it's",
    "start": "1002040",
    "end": "1008759"
  },
  {
    "text": "enforcing some sort of types no it's linting okay it's just letting you know when your types are out of place from",
    "start": "1008759",
    "end": "1015279"
  },
  {
    "text": "each other that's it and so that means if you want to know you're using a real type you have to do a runtime check on",
    "start": "1015279",
    "end": "1022160"
  },
  {
    "text": "it meaning that you have to crawl the entire object using object doc Keys using whatever it takes to go through uh",
    "start": "1022160",
    "end": "1028880"
  },
  {
    "text": "you know go through the whole thing and validation validate its key and its property as being the same thing uh it's",
    "start": "1028880",
    "end": "1034640"
  },
  {
    "text": "just different you can't just use type of right because if you want to validate an object is of a certain shape has a few keys in it you have to go through it",
    "start": "1034640",
    "end": "1041640"
  },
  {
    "text": "all so typically people will use type guarding uh as one of the better ways but I mean there's still a lot of",
    "start": "1041640",
    "end": "1046918"
  },
  {
    "text": "oddities that goes through with type guard stting uh you can type guard not realizing a certain field became uh",
    "start": "1046919",
    "end": "1052440"
  },
  {
    "text": "undefined that's a real thing right you don't realize a field can be undefined from some particular third party service",
    "start": "1052440",
    "end": "1058360"
  },
  {
    "text": "or whatever and then you get this response back out it happens to be undefined you didn't know about it you",
    "start": "1058360",
    "end": "1064039"
  },
  {
    "text": "blow up your server despite your typescript saying everything is good great and awesome so you know there's these weird little audities that will",
    "start": "1064039",
    "end": "1069880"
  },
  {
    "text": "show up if you don't have perfectly correct types uh typescript just moves the problem from type checking in your",
    "start": "1069880",
    "end": "1077120"
  },
  {
    "text": "code via runtime to typechecking Via lint it's good I mean don't get me wrong I'm I'm fine with what they do it just",
    "start": "1077120",
    "end": "1084440"
  },
  {
    "text": "still can be difficult it's not free is what I'm",
    "start": "1084440",
    "end": "1089960"
  },
  {
    "text": "trying to say so this is why you run into these situations is that you are type checking I assume that's what typm",
    "start": "1089960",
    "end": "1095480"
  },
  {
    "start": "1094000",
    "end": "1151000"
  },
  {
    "text": "is doing it's literally type checking against your data making sure that you've adhered to some sort of schema",
    "start": "1095480",
    "end": "1101120"
  },
  {
    "text": "all right the results may be larger because uh we're quering for a large number of rows or because the joined data in the query type omm Maps the join",
    "start": "1101120",
    "end": "1108720"
  },
  {
    "text": "in the entity manager to left joins with uh which can result in significantly inflated number of rows hold on typ maps",
    "start": "1108720",
    "end": "1115919"
  },
  {
    "text": "the joins and it's entity man manager hold on it's doing a left join in typescript is that what I'm seeing not",
    "start": "1115919",
    "end": "1122880"
  },
  {
    "text": "free called it pick is that what I'm reading here pick pick am I reading that you're doing a join in not a",
    "start": "1122880",
    "end": "1131679"
  },
  {
    "text": "database typ RM Maps its entity managers to left join which can result in",
    "start": "1133720",
    "end": "1139600"
  },
  {
    "text": "significantly inflated number of rows if there is a lot of relations between the query data oh no no it just does the joins",
    "start": "1139600",
    "end": "1145480"
  },
  {
    "text": "itself it does the joint it it it does these left joints somewhere and then brings a bunch of extra stuff down is",
    "start": "1145480",
    "end": "1151440"
  },
  {
    "start": "1151000",
    "end": "1224000"
  },
  {
    "text": "what I'm seeing okay it's probably that um this means that there are uh there were a few seemingly innocuous queries",
    "start": "1151440",
    "end": "1158480"
  },
  {
    "text": "that turned out to be timing out the postrest serialization time not even event Loop blocker related though the",
    "start": "1158480",
    "end": "1164600"
  },
  {
    "text": "concept is the same because of all of the joined data",
    "start": "1164600",
    "end": "1170240"
  },
  {
    "text": "[Music] I'm impressed okay so it is it is it is",
    "start": "1170870",
    "end": "1177159"
  },
  {
    "text": "joined in the DB okay so that's good it's not doing something that I think Prisma was doing Prisma had the Russ cin doing the joint itself which again I",
    "start": "1177159",
    "end": "1184880"
  },
  {
    "text": "mean again just just a cautionary tale raw dog and squeal typically results in you knowing what happening squeal",
    "start": "1184880",
    "end": "1192280"
  },
  {
    "text": "Builders are like the next level of raw dogging maybe it's not as raw dogged maybe it's a little bit you know it's a",
    "start": "1192280",
    "end": "1198760"
  },
  {
    "text": "medium rare it's a medium rare squeal query okay still good you still have a lot of control but at the end of the day",
    "start": "1198760",
    "end": "1204799"
  },
  {
    "text": "you're not crafting the query yourself and then finally the last level is omms which mostly could be good right OMS",
    "start": "1204799",
    "end": "1212240"
  },
  {
    "text": "mostly good but sometimes you run into these odd situations okay so you got to know",
    "start": "1212240",
    "end": "1218600"
  },
  {
    "text": "when to Raw Dog it okay because sometimes your queries come out medium well all",
    "start": "1218600",
    "end": "1224000"
  },
  {
    "start": "1224000",
    "end": "1335000"
  },
  {
    "text": "right uh what is omm to be honest it's just like effectively your mapping things to like classes just imagine",
    "start": "1224000",
    "end": "1230919"
  },
  {
    "text": "that's how how I like to imagine it is that you have a way to effectively manifest representations that you have",
    "start": "1230919",
    "end": "1237520"
  },
  {
    "text": "from the database into your code and it gives you all the nice little things around it I think front end Masters does",
    "start": "1237520",
    "end": "1242799"
  },
  {
    "text": "a really interesting thing they're telling me about it which is they have a handcrafted squeal Builder which only",
    "start": "1242799",
    "end": "1249799"
  },
  {
    "text": "allows specific operations for each field meaning you can't just look up by",
    "start": "1249799",
    "end": "1255520"
  },
  {
    "text": "any field in a table it has hardcoded each field which ones are indexed",
    "start": "1255520",
    "end": "1261480"
  },
  {
    "text": "doesn't allow you to do that so when you want to add a new query you have to alter this like this kind of squeal",
    "start": "1261480",
    "end": "1267240"
  },
  {
    "text": "Builder to be like all right I want this new query that does this that way they have every last bit of queries very easy",
    "start": "1267240",
    "end": "1273400"
  },
  {
    "text": "to represent in the system but highly optimized in their like back end right",
    "start": "1273400",
    "end": "1278799"
  },
  {
    "text": "because they know the exact query every single time there's no messing around uh it's it's very very fast I love those",
    "start": "1278799",
    "end": "1285200"
  },
  {
    "text": "kind of approaches because it's the it's the middle ground right typically you the dev you're not doing anything uh but",
    "start": "1285200",
    "end": "1292120"
  },
  {
    "text": "everything is still raw but it's protected behind what feels like a a query Builder so when you go all right I",
    "start": "1292120",
    "end": "1297840"
  },
  {
    "text": "want from this table all of a sudden you only get like three Fields you can select on so it kind of like reduces",
    "start": "1297840",
    "end": "1304279"
  },
  {
    "text": "things down to what you can do oh you can't even sort this table do sort is not a method found on this table sorry",
    "start": "1304279",
    "end": "1310440"
  },
  {
    "text": "you may not do that right like it it makes you think in a different way right it's a",
    "start": "1310440",
    "end": "1316400"
  },
  {
    "text": "specific problem to a specific uh or it's a specific solution",
    "start": "1316400",
    "end": "1322240"
  },
  {
    "text": "to a specific uh problem which I really like I think that's the best way to write any really good performance or",
    "start": "1322240",
    "end": "1327600"
  },
  {
    "text": "really good application as a specific problem and a specific solution uh the more specific you can go the better",
    "start": "1327600",
    "end": "1333559"
  },
  {
    "text": "index scan all the BBS you always index scan all the things at all times uh there are let's see there are",
    "start": "1333559",
    "end": "1340200"
  },
  {
    "start": "1335000",
    "end": "1421000"
  },
  {
    "text": "some more there are some other interesting but Niche F fixes as well as some of our uh pattern of mapping over a",
    "start": "1340200",
    "end": "1346320"
  },
  {
    "text": "list of objects to generate promises blocking the event",
    "start": "1346320",
    "end": "1351000"
  },
  {
    "text": "Loop nice uh there could be lots of objects uh in that list or to creating",
    "start": "1351480",
    "end": "1356840"
  },
  {
    "text": "promises took uh some non-trivial synchronous work constructing typo query Builders interesting that a query",
    "start": "1356840",
    "end": "1363760"
  },
  {
    "text": "Builder would take non-trivial amount of synchronous work I'm confused by that I",
    "start": "1363760",
    "end": "1369360"
  },
  {
    "text": "I must not understand how building a query would take anything more than like a handful",
    "start": "1369360",
    "end": "1376200"
  },
  {
    "text": "of microseconds you know okay you have a slow machine maybe it takes a millisecond or two like",
    "start": "1376200",
    "end": "1382520"
  },
  {
    "text": "it just that that's hard for me to understand this isn't uh this isn't a call to prematurely optimize which by the way again call out to Casey",
    "start": "1382520",
    "end": "1389159"
  },
  {
    "text": "premature optimization is the root of all evil is a misquote uh the the creators would just uh and canth",
    "start": "1389159",
    "end": "1396799"
  },
  {
    "text": "would say hey we are talking about hand rolling assembly to make it faster than C don't hand roll assembly to make it to",
    "start": "1396799",
    "end": "1403840"
  },
  {
    "text": "make it faster than C don't do that that's stupid but",
    "start": "1403840",
    "end": "1409200"
  },
  {
    "text": "writing good code you should do that okay optimize your code just don't",
    "start": "1409200",
    "end": "1414880"
  },
  {
    "text": "handroll assembly only do that when you really need to do that uh uh SSL you know I get",
    "start": "1414880",
    "end": "1421400"
  },
  {
    "start": "1421000",
    "end": "1575000"
  },
  {
    "text": "it that TLS whatever it is 1.3 or whatever it is does do that that's fine uh I wouldn't worry about the",
    "start": "1421400",
    "end": "1426919"
  },
  {
    "text": "synchronous CPU intensive type uh of work off the bat but I would rather monitor it as it rolled out knowing that",
    "start": "1426919",
    "end": "1432880"
  },
  {
    "text": "this might later have to move to a worker thread I would say that uh avoid",
    "start": "1432880",
    "end": "1437960"
  },
  {
    "text": "promises you'll find a huge you'll just find a just a giant win uh there are also cases however where there was a",
    "start": "1437960",
    "end": "1443880"
  },
  {
    "text": "logic I thought would be quite CPU intensive which turned out not to be so this is why proper logging and",
    "start": "1443880",
    "end": "1449039"
  },
  {
    "text": "monitoring are crucial in a web application at scale absolutely 100% be very wary of large volumes of data",
    "start": "1449039",
    "end": "1454880"
  },
  {
    "text": "return from databases it turns out that this not only has an uh an expense on the database level and sending it down",
    "start": "1454880",
    "end": "1461520"
  },
  {
    "text": "to the client but can also affect other all inlight requests yeah absolutely this makes perfect sense because when",
    "start": "1461520",
    "end": "1466919"
  },
  {
    "text": "you Json code when you walk these objects and cast them into things when you verify or validate their shape at",
    "start": "1466919",
    "end": "1473840"
  },
  {
    "text": "runtime you 100 and 10% spend all that time synchronously in JavaScript there",
    "start": "1473840",
    "end": "1479720"
  },
  {
    "text": "is no anything else that can run and every time you create a promise remember anything however long it takes to",
    "start": "1479720",
    "end": "1485679"
  },
  {
    "text": "resolve that promise Constructor everything else behind it in the event Loop gets to have that has to wait until that thing is done and so it's like it's",
    "start": "1485679",
    "end": "1492120"
  },
  {
    "text": "very good to know these things exist uh from this investigation we were able to",
    "start": "1492120",
    "end": "1497640"
  },
  {
    "text": "uh uh to let's see we're able to burning down a number of these event Loop blockers however keeping an eye out on",
    "start": "1497640",
    "end": "1503399"
  },
  {
    "text": "performance will continue to be required as we inevitably introduce new blockers absolutely lesson three everything has a cost but only the most expensive things",
    "start": "1503399",
    "end": "1510320"
  },
  {
    "text": "have impact classic completely reasonable statement",
    "start": "1510320",
    "end": "1516440"
  },
  {
    "text": "that you cannot argue with uh on the let's see let's see one of the first things I dug into when I was looking at performance was background fetching uh",
    "start": "1516440",
    "end": "1523320"
  },
  {
    "text": "that our app did um we had noticed in data dog metrics that our server spent a",
    "start": "1523320",
    "end": "1528440"
  },
  {
    "text": "lot of time evaluating these requests by server wall time this was a third highest end point but because of",
    "start": "1528440",
    "end": "1533840"
  },
  {
    "text": "requests that uh that occurred in the background for users we weren't sure whether uh whether this was worth",
    "start": "1533840",
    "end": "1539960"
  },
  {
    "text": "optimizing okay very interesting um interesting but if it's in node.js it",
    "start": "1539960",
    "end": "1545960"
  },
  {
    "text": "doesn't matter that it's in the background for a user because if it takes time it takes resources and if it",
    "start": "1545960",
    "end": "1551399"
  },
  {
    "text": "takes resources other services have to be slow or slowed down right I mean by",
    "start": "1551399",
    "end": "1558240"
  },
  {
    "text": "the very nature we'll find out at the time we decided uh to experiment with unshipping the feature that relied on",
    "start": "1558240",
    "end": "1563360"
  },
  {
    "text": "this background fetching curious to see the impact uh showed up anywhere after unshipping the server CPU and memory",
    "start": "1563360",
    "end": "1569520"
  },
  {
    "text": "stayed at the same uh at the same and we saw dramatic drop off in the event Loop delay crazy key takeaway here for me uh",
    "start": "1569520",
    "end": "1577640"
  },
  {
    "start": "1575000",
    "end": "1708000"
  },
  {
    "text": "with and with much more of this performance work was that nothing comes for free even non-user face facing",
    "start": "1577640",
    "end": "1583440"
  },
  {
    "text": "latency again at some point you have to process it at some point you're taking up resources at some point it has to get",
    "start": "1583440",
    "end": "1590480"
  },
  {
    "text": "in line with other things you know what I mean like of course nothing's free I mean that's this makes perfect sense",
    "start": "1590480",
    "end": "1597799"
  },
  {
    "text": "right you either have yeah you vertically scale you horizontally scale",
    "start": "1597799",
    "end": "1603640"
  },
  {
    "text": "or you get rid of it or make it better for a while we've theorized that some of the large unpaginated endpoints we have",
    "start": "1603640",
    "end": "1609919"
  },
  {
    "text": "are costly however we H haven't seen this show up in our top level performance metrics these queries don't",
    "start": "1609919",
    "end": "1615679"
  },
  {
    "text": "seem to be using a disproportional amount of C CPU or memory or blocking the event Loop more than the other endpoints so while we uh while we could",
    "start": "1615679",
    "end": "1624120"
  },
  {
    "text": "staff a large effort to overhall these end points and iron out our pagination scheme I not yet confident that this",
    "start": "1624120",
    "end": "1629880"
  },
  {
    "text": "trade-off will be worth it the so one thing to kind of say about this not all changes are worth it as the first line",
    "start": "1629880",
    "end": "1638000"
  },
  {
    "text": "but making things fast mean you don't have to make them faster later when more things rely on",
    "start": "1638000",
    "end": "1644960"
  },
  {
    "text": "it or at least making it good enough enough do you know what I mean like as",
    "start": "1644960",
    "end": "1650720"
  },
  {
    "text": "you let things that you know aren't good sit more things grow on it which means",
    "start": "1650720",
    "end": "1657360"
  },
  {
    "text": "it's harder to detangle that mess as time goes on you know almost always is it a good idea to try to write the right",
    "start": "1657360",
    "end": "1663919"
  },
  {
    "text": "thing first that you know is going to be as efficient as you can write it that's",
    "start": "1663919",
    "end": "1669080"
  },
  {
    "text": "not hyper ridiculously made right uh I do not like make it work make it right",
    "start": "1669080",
    "end": "1674559"
  },
  {
    "text": "make it fast I've never liked that uh phrase I like to make it like I try to make",
    "start": "1674559",
    "end": "1681519"
  },
  {
    "text": "things performance-minded first as I make the thing right I design my apis",
    "start": "1681519",
    "end": "1686760"
  },
  {
    "text": "around it I think about where and how I'm allocating memory why I'm allocating memory can I reuse objects I just don't",
    "start": "1686760",
    "end": "1694000"
  },
  {
    "text": "I don't first think about making the thing because often it becomes really difficult going backwards you know what I mean it's difficult going backwards",
    "start": "1694000",
    "end": "1700720"
  },
  {
    "text": "and then making something fast because you've made a lot of tradeoffs in how you've designed it it can be difficult",
    "start": "1700720",
    "end": "1707240"
  },
  {
    "text": "uh all right capturing performance Trends after fixing many of our outliers and our latency graphs are much smoother",
    "start": "1707240",
    "end": "1712600"
  },
  {
    "start": "1708000",
    "end": "2023000"
  },
  {
    "text": "and more consistent week over week for example uh consider the following uh time Seri graphs that show the number of",
    "start": "1712600",
    "end": "1718440"
  },
  {
    "text": "requests that took greater than 5 Seconds greater than two seconds greater than 1 seconds the Blue Line shows the data from today and the orange tracking",
    "start": "1718440",
    "end": "1725519"
  },
  {
    "text": "line shows the data from the same point from the week before oh nice some week over week graphs okay",
    "start": "1725519",
    "end": "1731799"
  },
  {
    "text": "um it looks like wait is blue sucking more than Orange in",
    "start": "1731799",
    "end": "1738159"
  },
  {
    "text": "this situation I don't really see much of a win",
    "start": "1738159",
    "end": "1742840"
  },
  {
    "text": "here let me just make sure I got that blue and blue and orange correct here",
    "start": "1749919",
    "end": "1756480"
  },
  {
    "text": "um the Blue Line shows the data from today yeah I I don't know if I don't I I'm not sure if I'm seeing like huge",
    "start": "1756640",
    "end": "1763159"
  },
  {
    "text": "winds all the time it's really hard to say that there's a wind you need to do more statistical rigor on this kind of win um you know what I mean you have to",
    "start": "1763159",
    "end": "1771080"
  },
  {
    "text": "do a lot more statistical rigor on these type of things I would never eyeball a graph like eyeballing a graph only works",
    "start": "1771080",
    "end": "1779080"
  },
  {
    "text": "if it's obvious you know what I mean like if if it's like one graph and there's a golf inet Twix and then",
    "start": "1779080",
    "end": "1784960"
  },
  {
    "text": "another graph you don't have to do much rigor on that one and be like yeah that's",
    "start": "1784960",
    "end": "1790360"
  },
  {
    "text": "probably better we're like lower at all points by at least 20 milliseconds",
    "start": "1790360",
    "end": "1795559"
  },
  {
    "text": "probably faster but if it's like right",
    "start": "1795559",
    "end": "1800880"
  },
  {
    "text": "there I'd be careful I mean this just looks like an accent right here uh now when we see the performance regressions",
    "start": "1801880",
    "end": "1808000"
  },
  {
    "text": "it becomes easy to con uh uh concretely identify in the grass below for example a regression around midnight immediately",
    "start": "1808000",
    "end": "1814760"
  },
  {
    "text": "jumps",
    "start": "1814760",
    "end": "1817039"
  },
  {
    "text": "out yeah there's like that that jump right there that must be a regression I I I just don't see any",
    "start": "1820760",
    "end": "1826559"
  },
  {
    "text": "difference though look what do you think of these two images they're the same um anyways",
    "start": "1826559",
    "end": "1832480"
  },
  {
    "text": "there's no midnight either uh previously we were using graphs to monitor latency across our entire application but uh the",
    "start": "1832480",
    "end": "1837720"
  },
  {
    "text": "hope is that we can now use this approach to track performance Trends on uh key end points the work continues uh",
    "start": "1837720",
    "end": "1844760"
  },
  {
    "text": "through this work we have significantly improved our ability to understand where large performance regressions on the graphite apps are coming from and how to",
    "start": "1844760",
    "end": "1850200"
  },
  {
    "text": "combat them I do like this you know the per endpoint kind of identification week",
    "start": "1850200",
    "end": "1856240"
  },
  {
    "text": "over week graphs those kind of things they're actually super useful because when something does regress at least you",
    "start": "1856240",
    "end": "1862960"
  },
  {
    "text": "know where and when it happened then you can attempt to fix",
    "start": "1862960",
    "end": "1869159"
  },
  {
    "text": "it you know what I mean at least that's good identification is half the problem",
    "start": "1869159",
    "end": "1875399"
  },
  {
    "text": "it is it is a very good thing uh I like that uh I I do like that I let's see",
    "start": "1875399",
    "end": "1880639"
  },
  {
    "text": "understand how overall site performance is tracked tracking over time yeah that's also good historic historic is always really good uh it's really good",
    "start": "1880639",
    "end": "1887360"
  },
  {
    "text": "to know that you're slowly doing it the hard part is that when you creep up slowly over time you you don't do larger",
    "start": "1887360",
    "end": "1893240"
  },
  {
    "text": "regressions with more statistical rigor over time because then the problem becomes over two Monon period did you",
    "start": "1893240",
    "end": "1899200"
  },
  {
    "text": "slowly become slower I can fix her every developer uh yes this is th this is it uh While most",
    "start": "1899200",
    "end": "1907159"
  },
  {
    "text": "of this work has centered around uh our understanding at the most extreme outliers we are continuously hard at",
    "start": "1907159",
    "end": "1912720"
  },
  {
    "text": "work continuing to drive down endpoint Lane sees across the board and more importantly locking our wins in all in",
    "start": "1912720",
    "end": "1918600"
  },
  {
    "text": "all the this investigation the resulting fixes have greatly improved graphite's app server performance over the last six",
    "start": "1918600",
    "end": "1924360"
  },
  {
    "text": "weeks and I'm confident uh these learnings will only help us continuing going forward you know what I'd love to see them do I would love to see them uh",
    "start": "1924360",
    "end": "1934720"
  },
  {
    "text": "just simply isolate a server be able to run some Dev tools on it and look at the",
    "start": "1934720",
    "end": "1941919"
  },
  {
    "text": "performance or the performance have and just see how much time are they spending in garbage collection right like that's",
    "start": "1941919",
    "end": "1947200"
  },
  {
    "text": "such an amazing thing to do is just looking at that also what node version are they on are they on node uh 16 18 20",
    "start": "1947200",
    "end": "1955639"
  },
  {
    "text": "like very very different performance characteristics and note 16 is like",
    "start": "1955639",
    "end": "1960960"
  },
  {
    "text": "intensely slower than Note 18 which is still much slower than Note 20 right so",
    "start": "1960960",
    "end": "1966960"
  },
  {
    "text": "it's like there's there's some real wins there that would be great to see uh what like what's going on because",
    "start": "1966960",
    "end": "1973559"
  },
  {
    "text": "I think that if you looked at garbage collection you can also find a huge number of reasons why uh individual requests or a set of",
    "start": "1973559",
    "end": "1979639"
  },
  {
    "text": "requests Spike for a while anyways the",
    "start": "1979639",
    "end": "1985080"
  },
  {
    "text": "name is I really like I like this kind of stuff I think this stuff is great I love that they made graphs I love that they're tracking tracking is always the",
    "start": "1985080",
    "end": "1991519"
  },
  {
    "text": "best first step I love they being proactive about it absolutely lovely uh these graphs I don't really buy you",
    "start": "1991519",
    "end": "1996960"
  },
  {
    "text": "should really get some statistical analysis in here at uh at at the startup at places where I've worked we call this",
    "start": "1996960",
    "end": "2003000"
  },
  {
    "text": "uh we call this automatic Canary analysis or being able to kind of alert on Trend differentiating some good stuff",
    "start": "2003000",
    "end": "2010639"
  },
  {
    "text": "and so I just love to see this absolutely love to see this the name is the prime gen unlike",
    "start": "2010639",
    "end": "2016039"
  },
  {
    "text": "unsubscribe report dmca call my mom do it all you got it a Jen",
    "start": "2016039",
    "end": "2025398"
  }
]
[
  {
    "text": "all right is bun better than go what the heck is this well bun performed in the previous Benchmark so I decided to",
    "start": "199",
    "end": "7399"
  },
  {
    "text": "compare it with go Link in my mind go is in different class compared to JavaScript in this video we'll first",
    "start": "7399",
    "end": "14519"
  },
  {
    "text": "compare ban with goink using standard Library we'll use SL API SL devices",
    "start": "14519",
    "end": "21400"
  },
  {
    "text": "endpoint to return a hardcoded device in Json format to the client and we'll",
    "start": "21400",
    "end": "27160"
  },
  {
    "text": "focus on four golden signals since the these are user facing applications our",
    "start": "27160",
    "end": "32758"
  },
  {
    "text": "main focus will be on latency specifically using P99 percent for those",
    "start": "32759",
    "end": "38960"
  },
  {
    "text": "that don't know the difference between these things is that bun obviously runs",
    "start": "38960",
    "end": "44120"
  },
  {
    "text": "JavaScript all right go is its own language the reason why JavaScript",
    "start": "44120",
    "end": "49520"
  },
  {
    "text": "should never ever for any reason be faster than go is because at some point there's something called V8 which has to",
    "start": "49520",
    "end": "56680"
  },
  {
    "text": "take in text turn it into bite code then it has to keep track of that by",
    "start": "56680",
    "end": "63439"
  },
  {
    "text": "code with some sort of like uh opt op optimizing stuff you'll see this if you look at the memory usage you'll see that",
    "start": "63439",
    "end": "70119"
  },
  {
    "text": "the memory usage goes off the charts uh on on a per function basis for",
    "start": "70119",
    "end": "75720"
  },
  {
    "text": "how much memory is actually used and then on top of that uh if it's called",
    "start": "75720",
    "end": "81040"
  },
  {
    "text": "enough times depending on the length of the function typically at least in V8 it will go off and then it'll actually try",
    "start": "81040",
    "end": "86360"
  },
  {
    "text": "to jit it so if it's called with enough times with the simp similar shaped objects it will then do a proper thing",
    "start": "86360",
    "end": "92399"
  },
  {
    "text": "now obviously bun uses uh JavaScript core so I don't know if the rules are or",
    "start": "92399",
    "end": "98320"
  },
  {
    "text": "are not the same but there's something right and so just in time uh",
    "start": "98320",
    "end": "103920"
  },
  {
    "text": "compilation is going to have something that produces something like some sort",
    "start": "103920",
    "end": "109280"
  },
  {
    "text": "of assembly level uh performance I'm not exactly sure the exact nature of it but I know that it's not going to be as fast",
    "start": "109280",
    "end": "116479"
  },
  {
    "text": "as something that is compiled and as good I've heard numbers saying it's twice as slow as your standard as your",
    "start": "116479",
    "end": "122960"
  },
  {
    "text": "standard program language I'm not sure if that's true it's ass performance",
    "start": "122960",
    "end": "128080"
  },
  {
    "text": "that's all I know so go as long as there's not some sort of egregious programming issue go should massively",
    "start": "128080",
    "end": "136400"
  },
  {
    "text": "outperformed because remember every time these functions are called they're still tracking a lot of information so it's",
    "start": "136400",
    "end": "142160"
  },
  {
    "text": "not completely for free right there still is this optimized thing going on and which you know goes and and",
    "start": "142160",
    "end": "149360"
  },
  {
    "text": "determines are we still jitting or do we need to unit it due to the type of arguments",
    "start": "149360",
    "end": "154599"
  },
  {
    "text": "being passed in all sorts of stuff next is through output which for web",
    "start": "154599",
    "end": "159800"
  },
  {
    "text": "application means the number of requests per second that each application can",
    "start": "159800",
    "end": "165400"
  },
  {
    "text": "handle then we'll look at saturation by measuring how full the service is I also",
    "start": "165400",
    "end": "171879"
  },
  {
    "text": "just did a a test on this gosh when bun came out and uh when I did it go was",
    "start": "171879",
    "end": "178400"
  },
  {
    "text": "like two and a uh two and a half half four times as fast something like that I can't remember it was significantly faster for the exact same thing more",
    "start": "178400",
    "end": "185640"
  },
  {
    "text": "specifically CPU and memory usage of the applications relative to the limits",
    "start": "185640",
    "end": "191480"
  },
  {
    "text": "defined in kubernetes we'll also need to measure CPU throttling as it plays a",
    "start": "191480",
    "end": "196720"
  },
  {
    "text": "significant role in kubernetes when a service is throttled it immediately increases latency and degrades overall",
    "start": "196720",
    "end": "204840"
  },
  {
    "text": "performance finally we'll measure availability by looking at the number of failed requests relative to the total",
    "start": "204840",
    "end": "212760"
  },
  {
    "text": "number of requests over a specific period of time now most benchmarks focus",
    "start": "212760",
    "end": "218599"
  },
  {
    "text": "on synthetic tests but I also want to see how these applications perform in",
    "start": "218599",
    "end": "224560"
  },
  {
    "text": "real world scenarios I use different use cases in different benchmarks in this",
    "start": "224560",
    "end": "230480"
  },
  {
    "text": "one we'll add a persistance layer using manga DB database every time application",
    "start": "230480",
    "end": "236680"
  },
  {
    "text": "receives a post request it will pass the request body generate uid and save the",
    "start": "236680",
    "end": "243239"
  },
  {
    "text": "item into Monga B in addition to standard Matrix I instrumented each I",
    "start": "243239",
    "end": "248599"
  },
  {
    "text": "mean this still isn't very fair like this is just not a very fair thing there's so many there's just so much",
    "start": "248599",
    "end": "254560"
  },
  {
    "text": "more crap that goes on think about just the size of your headers in these synthetic tests the size of your headers",
    "start": "254560",
    "end": "260120"
  },
  {
    "text": "alone are rather small they're not they're not going to be contain they're not going to contain all the data that",
    "start": "260120",
    "end": "266400"
  },
  {
    "text": "you would in the real world and so it's just like there's just so much smaller things uh grpc solves this well yeah",
    "start": "266400",
    "end": "272639"
  },
  {
    "text": "grpc uses hpack which hpack is going to effectively greatly reduce your header",
    "start": "272639",
    "end": "277800"
  },
  {
    "text": "size no my headers are huge I know your headers are huge that's the problem if you're not on hp2 which most the",
    "start": "277800",
    "end": "284039"
  },
  {
    "text": "internet now is on hp2 you're going to have huge header problems if you're at least on hp2 you won't have uh you won't",
    "start": "284039",
    "end": "292440"
  },
  {
    "text": "have that header issue so or at least you won't mostly have that header issue",
    "start": "292440",
    "end": "297600"
  },
  {
    "text": "application with primal mric to measure how long it takes for each applic I",
    "start": "297600",
    "end": "303000"
  },
  {
    "text": "don't the difference between H and headest including database Matrix so I",
    "start": "303000",
    "end": "310600"
  },
  {
    "text": "have also added CPU usage of mangad itself and in this tests will generate",
    "start": "310600",
    "end": "317199"
  },
  {
    "text": "enough load to find the breaking point of both",
    "start": "317199",
    "end": "322319"
  },
  {
    "text": "applications I deploy both applications to production R kubernetes cluster in",
    "start": "322800",
    "end": "328680"
  },
  {
    "text": "ads using large instances for the applications each with two CPUs and 8 GB",
    "start": "328680",
    "end": "335880"
  },
  {
    "text": "of memory since BN uses a single threat for most operations I limit each",
    "start": "335880",
    "end": "341919"
  },
  {
    "text": "application to one CPU which can be viewed as 100% of a 100 millisecond",
    "start": "341919",
    "end": "348840"
  },
  {
    "text": "interval in a cycle that repeats indefinitely and enforced by c groups",
    "start": "348840",
    "end": "354759"
  },
  {
    "text": "additionally I locate 256 MB of memory I also scale",
    "start": "354759",
    "end": "360240"
  },
  {
    "text": "applications horizontally deploying two instances of each application on each",
    "start": "360240",
    "end": "365919"
  },
  {
    "text": "ec2 instance to generate load I use graviton instances which a bit cheaper",
    "start": "365919",
    "end": "371599"
  },
  {
    "text": "and deploy 20 ports for each application these ports gradually increase the",
    "start": "371599",
    "end": "377120"
  },
  {
    "text": "number of virtual clients until both applications fail any advice on how to",
    "start": "377120",
    "end": "382400"
  },
  {
    "text": "improve either by the way good that he's using real machines not using Local Host Local Host can be kind of deceiving uh",
    "start": "382400",
    "end": "389280"
  },
  {
    "text": "there's lot of optimizations that do Local Host type of performance tests so I always am very wary of anything that",
    "start": "389280",
    "end": "396280"
  },
  {
    "text": "involves or we of anything that involves local hosts uh taking away goes",
    "start": "396280",
    "end": "401520"
  },
  {
    "text": "performance benefit by fitting the test uh to buns yeah you're also yes okay so that's that's a really good point which",
    "start": "401520",
    "end": "407400"
  },
  {
    "text": "is one thing that's deeply unfair about all of this is that for those that don't know anything about how job jscript",
    "start": "407400",
    "end": "413880"
  },
  {
    "text": "works or any of these run times work the runtime is the environment in which JavaScript runs JavaScript is actually",
    "start": "413880",
    "end": "419319"
  },
  {
    "text": "not you know is not the full thing there's also all the network stuff and so this can technically operate on many",
    "start": "419319",
    "end": "426680"
  },
  {
    "text": "threads but this cannot operate on many threads the JavaScript itself has to be",
    "start": "426680",
    "end": "432840"
  },
  {
    "text": "executed on a single thread and so you can go through here and you can aggregate your requests every one of the",
    "start": "432840",
    "end": "438639"
  },
  {
    "text": "requests that come in can be parsed and you know operated on and then put onto the process uh the process CU and so",
    "start": "438639",
    "end": "444960"
  },
  {
    "text": "that way they're answered in order and all that good stuff right awesome but the actual you know popping of the",
    "start": "444960",
    "end": "451680"
  },
  {
    "text": "process Q is going to happen in order and on a single thread whereas with go",
    "start": "451680",
    "end": "458080"
  },
  {
    "text": "you don't have to have this go can answer these things in a very very uh uh",
    "start": "458080",
    "end": "463520"
  },
  {
    "text": "kind of a multi a multi-threaded approach with how they do their their go routines which is fantastic and allows",
    "start": "463520",
    "end": "469199"
  },
  {
    "text": "for actually significant speed UPS so whoever said that is absolutely right this is something I just didn't even read they took these you really",
    "start": "469199",
    "end": "476560"
  },
  {
    "text": "completely dominate your ability with go by simply taking it and saying oh you",
    "start": "476560",
    "end": "481919"
  },
  {
    "text": "only get one CPU because the reality is this it's extremely easy to vertically",
    "start": "481919",
    "end": "487159"
  },
  {
    "text": "scale node and so go routines allow you to just simply go oh I have four CPUs I",
    "start": "487159",
    "end": "493960"
  },
  {
    "text": "have eight CPUs boom right it is it is pretty amazing what you can do node is",
    "start": "493960",
    "end": "500039"
  },
  {
    "text": "not single threaded yes cuz node is the runtime so as I described earlier node",
    "start": "500039",
    "end": "505879"
  },
  {
    "text": "is the runtime or bun is the runtime JavaScript JavaScript core or V8 is the",
    "start": "505879",
    "end": "511879"
  },
  {
    "text": "JavaScript engine the JavaScript engine is required to be single-threaded when you're running JavaScript that is single",
    "start": "511879",
    "end": "517640"
  },
  {
    "text": "threaded you cannot add and remove items within it on anything but single threaded now even garbage collection is",
    "start": "517640",
    "end": "523000"
  },
  {
    "text": "largely done off thread there's these scavenger tasks that happen off thread but there isn't anything you know it's",
    "start": "523000",
    "end": "530720"
  },
  {
    "text": "only what's it called the actual JavaScript running uh promises are multi-threaded no they're not they're",
    "start": "530720",
    "end": "536240"
  },
  {
    "text": "not okay they're not multi-threaded if you think they're multi-threaded uh don't hey don't worry night shade",
    "start": "536240",
    "end": "541519"
  },
  {
    "text": "dude you don't have to worry at all promises are not multi-threaded you just don't understand it okay that's not how",
    "start": "541519",
    "end": "549279"
  },
  {
    "text": "this works what happens underneath the hood on a promise could be multi-threaded and that makes sense uh",
    "start": "549279",
    "end": "557000"
  },
  {
    "text": "promises themselves are not multi-threaded there's an event Loop and every single thing gets added to the event Loop that's how these uh things",
    "start": "557000",
    "end": "563480"
  },
  {
    "text": "work promise. all is that's concurrency that it's okay so here I didn't realize",
    "start": "563480",
    "end": "568519"
  },
  {
    "text": "how much people have no idea first off yall need to understand um you you need",
    "start": "568519",
    "end": "574079"
  },
  {
    "text": "to understand some pretty basic stuff all right so let's pretend we have three",
    "start": "574079",
    "end": "580000"
  },
  {
    "text": "Network requests and we do a promise at all all right now the Constructor to the promise",
    "start": "580000",
    "end": "587480"
  },
  {
    "text": "each Constructor will execute in order so let's pretend this is how long the Constructor takes this is how long the",
    "start": "587480",
    "end": "594959"
  },
  {
    "text": "network request takes and this is how long the processing of the result takes that means if you executed three",
    "start": "594959",
    "end": "602320"
  },
  {
    "text": "of these in a row and let's just say they all take uh they're they're going to take here I'm",
    "start": "602320",
    "end": "607959"
  },
  {
    "text": "just going to draw this nice and carefully they're all effectively executed what appears to be in order",
    "start": "607959",
    "end": "613200"
  },
  {
    "text": "promised out all here's an array this does not execute it has to",
    "start": "613200",
    "end": "618640"
  },
  {
    "text": "wait for the ability to have the thread and so now that the Constructor has executed the network request is out then",
    "start": "618640",
    "end": "625480"
  },
  {
    "text": "the next Constructor can execute now it's waiting on the network it's waiting on the networks and some sort of",
    "start": "625480",
    "end": "630839"
  },
  {
    "text": "processing at the end now when this network comes back it will have its ability to execute now here's the best",
    "start": "630839",
    "end": "637600"
  },
  {
    "text": "part is if this one came back down here it would actually have to wait until it",
    "start": "637600",
    "end": "642959"
  },
  {
    "text": "has the ability to execute so that means this thing is going to be waiting until it has the",
    "start": "642959",
    "end": "650120"
  },
  {
    "text": "ability to construct does that make sense JavaScript executes always",
    "start": "650120",
    "end": "657360"
  },
  {
    "text": "synchronously go does not have to do that this is in fact incorrect anytime JavaScript is",
    "start": "657360",
    "end": "665480"
  },
  {
    "text": "executing it is single-threaded there is no difference ever at any point why I",
    "start": "665480",
    "end": "673079"
  },
  {
    "text": "just explained it that it can't be and he's like no actually it is it's in the kernel no it's not you're just you got to listen to the words JavaScript can",
    "start": "673079",
    "end": "680240"
  },
  {
    "text": "only execute single threaded now underneath it can be multi-threaded",
    "start": "680240",
    "end": "685320"
  },
  {
    "text": "you're absolutely right Network request can go off and if there's C++ that process it it can be processed the",
    "start": "685320",
    "end": "690920"
  },
  {
    "text": "headers can be decoded all those things exist but JavaScript itself is single",
    "start": "690920",
    "end": "697079"
  },
  {
    "text": "threaded workers are a different they're a new V8 isolate right so underneath yes",
    "start": "697079",
    "end": "703560"
  },
  {
    "text": "things can be processed but on top they cannot be okay so now that we all know this just just you got to you just got",
    "start": "703560",
    "end": "709600"
  },
  {
    "text": "to go read okay you have to go read and you got to go look yes the runtime can be multi-threaded absolutely so that's",
    "start": "709600",
    "end": "716839"
  },
  {
    "text": "why this is a this is why this is a very un Fair test because go L if you did this with go go routines",
    "start": "716839",
    "end": "724760"
  },
  {
    "text": "would look more like this each one of these would be a",
    "start": "724760",
    "end": "729959"
  },
  {
    "text": "Constructor each assuming they're all taking equal time of course and this would be the the three",
    "start": "729959",
    "end": "736120"
  },
  {
    "text": "processes on the other side right they would all happen in parallel with each other if you did gof Funk G Funk gof",
    "start": "736120",
    "end": "742720"
  },
  {
    "text": "Funk theoretically if you had all the CPU you know there's there's obviously",
    "start": "742720",
    "end": "748279"
  },
  {
    "text": "some what's it called there's there's some uh there is some level of of complexity being hidden here but",
    "start": "748279",
    "end": "754560"
  },
  {
    "text": "assuming you had all the processing power in the world you you would be able to do that right go Funk yourself",
    "start": "754560",
    "end": "759839"
  },
  {
    "text": "exactly application is welcome as well as pool requests which I typically merge",
    "start": "759839",
    "end": "764920"
  },
  {
    "text": "within a single day sorry for hey all right sorry for calling you stupid",
    "start": "764920",
    "end": "770040"
  },
  {
    "text": "sorry my fault I got I got a I got I got a little I got a little intense there my",
    "start": "770040",
    "end": "776240"
  },
  {
    "text": "fault on that one okay I'm going to say I'm say my fault on that one okay I got",
    "start": "776240",
    "end": "781720"
  },
  {
    "text": "a little excitable a bunch of people keep saying they're less than 13 years old or calling themselves 13 I have I've",
    "start": "781720",
    "end": "787360"
  },
  {
    "text": "had to ban too many people today and so you know I'm just I'm just a little riled up okay right let's get started in",
    "start": "787360",
    "end": "793800"
  },
  {
    "text": "the first test we evaluating how well each application can process HTTP",
    "start": "793800",
    "end": "798839"
  },
  {
    "text": "requests and return hardcoded values in Json format to the client on the top",
    "start": "798839",
    "end": "804560"
  },
  {
    "text": "right graph we'll measure thout I forgot to say this is the reason why this is unfair to go",
    "start": "804560",
    "end": "809720"
  },
  {
    "text": "is now you're giving one CPU so if you only give one CPU the thing that makes go so amazing is that it does",
    "start": "809720",
    "end": "817800"
  },
  {
    "text": "this and so by this working fast with go right it's just like you've now defeated",
    "start": "817800",
    "end": "823839"
  },
  {
    "text": "one of Go's best things which is exceptionally simple vertical scaling output which shows how many requests",
    "start": "823839",
    "end": "830320"
  },
  {
    "text": "each application can handle on the left hand side we have latency which measures",
    "start": "830320",
    "end": "836320"
  },
  {
    "text": "how long it takes to respond from the start you can see that one application takes significantly more time to process",
    "start": "836320",
    "end": "844040"
  },
  {
    "text": "each request it's also important to note that we measure latency from the client",
    "start": "844040",
    "end": "849360"
  },
  {
    "text": "side to make it as accurate as possible next we'll look at saturation which",
    "start": "849360",
    "end": "854720"
  },
  {
    "text": "indicates how full the service is you can see a trend in CPU usage go uses",
    "start": "854720",
    "end": "860920"
  },
  {
    "text": "more CPU time and will be the first to experience throttling since I deployed",
    "start": "860920",
    "end": "866279"
  },
  {
    "text": "two replicas for each application we measure average CPU usage on the right",
    "start": "866279",
    "end": "871680"
  },
  {
    "text": "hand side we have memory usage which only becomes critical when both services",
    "start": "871680",
    "end": "876880"
  },
  {
    "text": "are overloaded next we have a I think this is a good thing go using a lot of",
    "start": "876880",
    "end": "882519"
  },
  {
    "text": "CPU it means it's more efficiently using the small amount of allocated CPU that",
    "start": "882519",
    "end": "887720"
  },
  {
    "text": "you've been given I'm having a I'm having a hard time understanding why this isn't good the hard part is the request per second are about the same",
    "start": "887720",
    "end": "895040"
  },
  {
    "text": "which something has gone something is going weird here it's memory usage is",
    "start": "895040",
    "end": "901199"
  },
  {
    "text": "way down CPU throttling not there availability all the way right here why is more CPU being used there's less",
    "start": "901199",
    "end": "907959"
  },
  {
    "text": "whatever this this throttling is I'd have to understand more about this something feel ability in this test the average request takes less than 1",
    "start": "907959",
    "end": "915600"
  },
  {
    "text": "millisecond to complete so I set the client timeout to 100 milliseconds when",
    "start": "915600",
    "end": "921639"
  },
  {
    "text": "that timeout is exceeded you'll see a drop in availability graph up until 60",
    "start": "921639",
    "end": "927160"
  },
  {
    "text": "to 70% CPU user you won't see any throttling at around 23,000 request per",
    "start": "927160",
    "end": "933360"
  },
  {
    "text": "second CPU usage differences between two applications become more apparent by",
    "start": "933360",
    "end": "939360"
  },
  {
    "text": "this point goink starts losing its advantage in latency for this type of",
    "start": "939360",
    "end": "944519"
  },
  {
    "text": "application once CPU usage hits 40% performance starts to degrade and",
    "start": "944519",
    "end": "951040"
  },
  {
    "text": "latency increases by around 40 something has to be wrong and you it",
    "start": "951040",
    "end": "957240"
  },
  {
    "text": "should be a dead giveaway cuz go is a compiled language like if it is one for",
    "start": "957240",
    "end": "963560"
  },
  {
    "text": "one something something goofy is going on here what is it uh go still could be",
    "start": "963560",
    "end": "969560"
  },
  {
    "text": "very fast on a single CPU the standard uh the standard lib just goes uh does a go routine for every request and not a",
    "start": "969560",
    "end": "975079"
  },
  {
    "text": "worker pool so this kind of test is targeting a specific weakness in the standard live and forcing thrashing Behavior this is not a language itself",
    "start": "975079",
    "end": "981440"
  },
  {
    "text": "yeah I I'm I feel somewhat confused by this the language that can use multicol",
    "start": "981440",
    "end": "987279"
  },
  {
    "text": "properly will have schedulers that distributed at work which must have some overhead yeah but gen I mean I guess one",
    "start": "987279",
    "end": "993040"
  },
  {
    "text": "could okay so one could argue that the scheduling mechanism is more difficult on a single CPU for go than it is for",
    "start": "993040",
    "end": "1000600"
  },
  {
    "text": "bun if it's just a it's just an event Loop right bun is just simply adding tasks to a linked list so you can just",
    "start": "1000600",
    "end": "1007680"
  },
  {
    "text": "go you know you're just you're just it's it's like an O of one operation whereas when you have a scheduling and go",
    "start": "1007680",
    "end": "1014120"
  },
  {
    "text": "routines you're probably not doing well maybe that's like maybe that's the the issue that we're seeing",
    "start": "1014120",
    "end": "1019560"
  },
  {
    "text": "it's just weird to impose JS limits on go I'm very confused by requests per second goling starts failing behind B in",
    "start": "1019560",
    "end": "1027120"
  },
  {
    "text": "terms of number of requests it can handle at 61,000 requests per second the",
    "start": "1027120",
    "end": "1032678"
  },
  {
    "text": "differences becomes even more noticeable gol's latency increases to 10",
    "start": "1032679",
    "end": "1038079"
  },
  {
    "text": "milliseconds and kubernetes begins throttle it which affects performance on",
    "start": "1038079",
    "end": "1043319"
  },
  {
    "text": "the other hand B maintains low latency although some requests start to out it's",
    "start": "1043319",
    "end": "1049679"
  },
  {
    "text": "not many but you'll notice drops in availability graph at 69,000 request per",
    "start": "1049679",
    "end": "1055480"
  },
  {
    "text": "second it becomes clear that goink can't handle any more requests and begins",
    "start": "1055480",
    "end": "1061600"
  },
  {
    "text": "caching some of them all right let's continue at around 90,000 request per second BN also hits its limit and gets",
    "start": "1061600",
    "end": "1069720"
  },
  {
    "text": "throttled by kubernetes now let me open each graph for the full test duration as",
    "start": "1069720",
    "end": "1075200"
  },
  {
    "text": "you can see the test took around 2 hours to complete first we have requests per second yeah I",
    "start": "1075200",
    "end": "1083039"
  },
  {
    "text": "I I am very curious what happens as you increase CPU allowance and all",
    "start": "1083039",
    "end": "1091280"
  },
  {
    "text": "that perhaps I mean I guess the only plausible explanation has to be that the scheduler is very bad when you give it",
    "start": "1091280",
    "end": "1097159"
  },
  {
    "text": "exceptionally limited resources which is actually a pretty reasonable argument hey why have a complex piece of",
    "start": "1097159",
    "end": "1102440"
  },
  {
    "text": "scheduling that is meant to vertically scale on something that has absolutely no benefit but something still feels",
    "start": "1102440",
    "end": "1108480"
  },
  {
    "text": "very fishy about that there could also be some magic Zig optimization but the magic Zig optimization should be also",
    "start": "1108480",
    "end": "1115400"
  },
  {
    "text": "quote unquote magically available C latency after goink what's it called uh",
    "start": "1115400",
    "end": "1120720"
  },
  {
    "text": "it should be also available in go right there's not some sort of magic thing buns HP implementation is written in Zig",
    "start": "1120720",
    "end": "1126760"
  },
  {
    "text": "so they're only Json stringify that's run by JS oh okay so they're doing are they doing the entire thing in",
    "start": "1126760",
    "end": "1132880"
  },
  {
    "text": "effectively they're just only using Zig Zig utilities yeah cuz Zig should outperform go by a good margin uh just",
    "start": "1132880",
    "end": "1138919"
  },
  {
    "text": "because it is a they can do all sorts of really impressive things with Zig you can do Arena allocations yeah this is so",
    "start": "1138919",
    "end": "1144960"
  },
  {
    "text": "this is one of the problems about when I say small world tests I I actually here let's see if we can look at the code",
    "start": "1144960",
    "end": "1150280"
  },
  {
    "text": "small world tests are one of those very interesting worlds that exist um original source code the reason being is",
    "start": "1150280",
    "end": "1156039"
  },
  {
    "text": "that you have this really tiny amount of JavaScript that gets",
    "start": "1156039",
    "end": "1162200"
  },
  {
    "text": "executed but it doesn't look like that app.js yeah I mean there it's not just",
    "start": "1162200",
    "end": "1167520"
  },
  {
    "text": "simply that so I I am curious how why this thing is performing so much",
    "start": "1167520",
    "end": "1172679"
  },
  {
    "text": "better there's this histogram thing they're doing a string uh a string a",
    "start": "1172679",
    "end": "1178200"
  },
  {
    "text": "string check they're creating new uids they're doing a Json the Json obviously",
    "start": "1178200",
    "end": "1183840"
  },
  {
    "text": "done done well I wonder what is going",
    "start": "1183840",
    "end": "1189200"
  },
  {
    "text": "on it's very interesting right it's only calling get oh it's only calling get it's not creating any new devices so",
    "start": "1190240",
    "end": "1196280"
  },
  {
    "text": "it's just doing a get and doing this yeah but it's still doing something",
    "start": "1196280",
    "end": "1201440"
  },
  {
    "text": "right healths with a z very awesome very good typescript Master race if bun is",
    "start": "1201440",
    "end": "1209440"
  },
  {
    "text": "better then you should use bun right that's the reality is if bun is better you should use bun because I",
    "start": "1209440",
    "end": "1216159"
  },
  {
    "text": "mean that I mean at the end of the day what whatever is really great or let's try to replicate the results no I don't",
    "start": "1216159",
    "end": "1221400"
  },
  {
    "text": "want to replicate the results huh what is Prometheus it's obviously some sort of",
    "start": "1221400",
    "end": "1227200"
  },
  {
    "text": "uh I don't know don't know what this is this is something I don't I don't know what this is but this is this is uh",
    "start": "1227200",
    "end": "1233760"
  },
  {
    "text": "writing to Prometheus directly from go yeah we're writing to Prometheus I didn't maybe I didn't maybe",
    "start": "1233760",
    "end": "1239679"
  },
  {
    "text": "I missed the Prometheus part Prometheus is a Time series DB oh",
    "start": "1239679",
    "end": "1245200"
  },
  {
    "text": "nice okay where's main",
    "start": "1245200",
    "end": "1252480"
  },
  {
    "text": "app.js yeah this one you don't see any you at least you don't see the time series series DB",
    "start": "1254600",
    "end": "1260600"
  },
  {
    "text": "here but I'm sure it does exist I'm sure I you know obviously I must be missing some sort of something that's going on",
    "start": "1260600",
    "end": "1266559"
  },
  {
    "text": "with the post register from prom client oh there we go register nice okay yeah",
    "start": "1266559",
    "end": "1272679"
  },
  {
    "text": "that's only on a metrics call so that's on a metrics call so there must be some sort of thing that's going on that's able to do all that there must be some",
    "start": "1272679",
    "end": "1279240"
  },
  {
    "text": "sort of middleware one would assume if bun is that fast then you Zig yeah Zig is really really",
    "start": "1279240",
    "end": "1284720"
  },
  {
    "text": "good degrading at around 40% CPU usage its latency surpasses bonds but before",
    "start": "1284720",
    "end": "1292240"
  },
  {
    "text": "that its latency was much",
    "start": "1292240",
    "end": "1295960"
  },
  {
    "text": "lower if Zig is so fast as you see well Zig is just really convenien see next we",
    "start": "1299400",
    "end": "1305159"
  },
  {
    "text": "have CPU usage I'd be really curi yeah now I mean",
    "start": "1305159",
    "end": "1310679"
  },
  {
    "text": "now it just it the desire to know what has happened is entirely too high you",
    "start": "1310679",
    "end": "1316760"
  },
  {
    "text": "can see memory spikes in go when it's unable to process all the requests and",
    "start": "1316760",
    "end": "1322159"
  },
  {
    "text": "starts cash eventually memory usage reaches 100% and kubernetes kills",
    "start": "1322159",
    "end": "1328480"
  },
  {
    "text": "application multiple times due to out of memory errors after that we have availability",
    "start": "1328480",
    "end": "1335520"
  },
  {
    "text": "graph I did I looked at the code if building client facing",
    "start": "1335520",
    "end": "1341679"
  },
  {
    "text": "applications where latency is important you may want to consider goaling because",
    "start": "1341679",
    "end": "1346799"
  },
  {
    "text": "up until 40% CPU usage it performs much better on the other hand if you care",
    "start": "1346799",
    "end": "1352720"
  },
  {
    "text": "more about throut output and latency is less critical such as internal micros service B might be the better choice I I",
    "start": "1352720",
    "end": "1361640"
  },
  {
    "text": "don't think you can take any takeaways from this because again you're literally just you're just like hardcoding a",
    "start": "1361640",
    "end": "1367400"
  },
  {
    "text": "single device like no endpoint no endpoint has ever looked like that right",
    "start": "1367400",
    "end": "1373080"
  },
  {
    "text": "don't make decisions on this you'd want something that's a bit more complete because typically you're making several",
    "start": "1373080",
    "end": "1379039"
  },
  {
    "text": "requests with inside of any other request you're doing a bunch of stuff and then aggregating all the resets",
    "start": "1379039",
    "end": "1384120"
  },
  {
    "text": "results and then doing something a single Json stringify I don't know copium could very well be copium just",
    "start": "1384120",
    "end": "1391440"
  },
  {
    "text": "something about this doesn't feel quite correct most benchmarks use Simple tasks and algorithms to measure performance",
    "start": "1391440",
    "end": "1398760"
  },
  {
    "text": "but in reality you would rely heavily on external libraries and your application",
    "start": "1398760",
    "end": "1404480"
  },
  {
    "text": "performance would depend on how well those libraries developed also almost all applications require some kind of P",
    "start": "1404480",
    "end": "1412159"
  },
  {
    "text": "resistance layer such as a database in the previous B versus n Benchmark I used",
    "start": "1412159",
    "end": "1418080"
  },
  {
    "text": "pogress relational database in this test I have replaced it with a mongodb",
    "start": "1418080",
    "end": "1423360"
  },
  {
    "text": "document database if you're interested in how Bond performed with pogress you can check out that video I instrumented",
    "start": "1423360",
    "end": "1430360"
  },
  {
    "text": "both applications with promethos Matrix so we can measure the duration of each",
    "start": "1430360",
    "end": "1435559"
  },
  {
    "text": "function call in this test when application receives a post request it generates uu ID and stores the complete",
    "start": "1435559",
    "end": "1443679"
  },
  {
    "text": "object in the database you can find a link to the source code in the video description I also use Primus histogram",
    "start": "1443679",
    "end": "1451000"
  },
  {
    "text": "to measure how long it takes to insert data into Monga DB additionally based on",
    "start": "1451000",
    "end": "1456480"
  },
  {
    "text": "feedback I received I'm now measuring Monga CPU usage along with the other",
    "start": "1456480",
    "end": "1461720"
  },
  {
    "text": "standard Matrix in this test goling performs significantly better than BN",
    "start": "1461720",
    "end": "1467279"
  },
  {
    "text": "the latency for the client and database insert is almost half of what ban has",
    "start": "1467279",
    "end": "1473600"
  },
  {
    "text": "goink also has much lower CPU usage compared to bun at around 7 and half",
    "start": "1473600",
    "end": "1479480"
  },
  {
    "text": "th000 requests per second bun starts to degrade and drops some requests Kutis",
    "start": "1479480",
    "end": "1485279"
  },
  {
    "text": "also begins I still think it'd be it would be still much more interesting to see more work done in",
    "start": "1485279",
    "end": "1491720"
  },
  {
    "text": "endpoint you have to have more work like I want to see an actual represent like",
    "start": "1491720",
    "end": "1497120"
  },
  {
    "text": "the problem is the last time I've any sort of testing I built a game that's played completely on the server to test the difference between bun and go and",
    "start": "1497120",
    "end": "1504000"
  },
  {
    "text": "the the the the results were staggeringly different it doesn't really feel that much that much more wild when",
    "start": "1504000",
    "end": "1511520"
  },
  {
    "text": "you don't run with like an actual you know actual goodness uh",
    "start": "1511520",
    "end": "1518919"
  },
  {
    "text": "versus just like hey here's a simple program that does one thing most most end points aren't as simple as I take it",
    "start": "1518919",
    "end": "1526600"
  },
  {
    "text": "like I mean hopefully you're not writing something as simple as a crud endpoint that's like store device it just comes",
    "start": "1526600",
    "end": "1532600"
  },
  {
    "text": "in stores a device and returns right you usually have a bit more stuff going on",
    "start": "1532600",
    "end": "1538080"
  },
  {
    "text": "than just simply one for one database operation per actual request going in and out throt it which causes the",
    "start": "1538080",
    "end": "1545720"
  },
  {
    "text": "latency to increase cuz I'm not sure if I can even believe this find goink breaking point at around 24,000 request",
    "start": "1545720",
    "end": "1552640"
  },
  {
    "text": "per second goling starts to degrade as well reaching nearly 100% CPU usage as",
    "start": "1552640",
    "end": "1559440"
  },
  {
    "text": "you can see when the test involves more than just returning static responses",
    "start": "1559440",
    "end": "1564799"
  },
  {
    "text": "like in the previous test goink performs much better in real world scenarios you",
    "start": "1564799",
    "end": "1571000"
  },
  {
    "text": "will definitely need more than just static responses based on my experience and benchmarks I've run ban performs",
    "start": "1571000",
    "end": "1578960"
  },
  {
    "text": "very well with static synthetic benchmarks but when it time to do real work such as interacting with a database",
    "start": "1578960",
    "end": "1586799"
  },
  {
    "text": "ban loses many of its advantages even nojz performs better in these cases so",
    "start": "1586799",
    "end": "1593919"
  },
  {
    "text": "that would be more Curious than anything else if I mean because that's actually a real test I think Aiden said it Aiden uh",
    "start": "1593919",
    "end": "1600600"
  },
  {
    "text": "amazing amazing uh go engineer at twitch even said if if we're going to agree",
    "start": "1600600",
    "end": "1605760"
  },
  {
    "text": "that bun is better than go then we also need to agree that postgress is better than react which is just a wild one now",
    "start": "1605760",
    "end": "1611799"
  },
  {
    "text": "if if no. JS actually does outperform bun at least we're comparing a very similar environment right we're",
    "start": "1611799",
    "end": "1617000"
  },
  {
    "text": "comparing two environments that have effectively the same conditions now",
    "start": "1617000",
    "end": "1622679"
  },
  {
    "text": "we're comparing Legacy C++ plus a bunch of if defs plus all this stuff plus V8 versus",
    "start": "1622679",
    "end": "1630039"
  },
  {
    "text": "zigg none of the Legacy you know JSC now yeah classic",
    "start": "1630039",
    "end": "1636360"
  },
  {
    "text": "Aiden base take classic Aiden base take right just why is he so based just based",
    "start": "1636360",
    "end": "1641399"
  },
  {
    "text": "as it gets right this Aiden guy sounds smart this Aiden guy sounds like he's pretty goodlooking too huh all right",
    "start": "1641399",
    "end": "1648799"
  },
  {
    "text": "but I think uh anti-d deluvian apocalypse I don't know where you went but you said something that I think is probably the best which is most of us",
    "start": "1648799",
    "end": "1656840"
  },
  {
    "text": "don't write code that executes with 990,000 requests per second on a single",
    "start": "1656840",
    "end": "1663279"
  },
  {
    "text": "machine and you're also only running the world's tiniest amount of CPU right a",
    "start": "1663279",
    "end": "1668440"
  },
  {
    "text": "you're going to probably scale up and use a lot more CPU but regardless of all that you're going to probably do a lot",
    "start": "1668440",
    "end": "1674039"
  },
  {
    "text": "more work you will not even be close to being able to perform that amount of uh",
    "start": "1674039",
    "end": "1680039"
  },
  {
    "text": "operations per second anyways either in go or in bun but on top of that you",
    "start": "1680039",
    "end": "1685320"
  },
  {
    "text": "should probably just choose the language that makes you more happy if you can just choose the language that makes you",
    "start": "1685320",
    "end": "1691840"
  },
  {
    "text": "feel more productive and feel more excited you are likely going to be a lot",
    "start": "1691840",
    "end": "1697039"
  },
  {
    "text": "happier you just will be you'll be a lot more happier than if you choose a language just for efficiency and you",
    "start": "1697039",
    "end": "1703320"
  },
  {
    "text": "hate it right like I just don't find a lot of love in Rust that's all there is to I just don't find a lot of love in",
    "start": "1703320",
    "end": "1709559"
  },
  {
    "text": "Rust I I'm willing to reive another rust attempt where I attempt to make sweet",
    "start": "1709559",
    "end": "1714799"
  },
  {
    "text": "love with rust one more time but I just don't like it it's not fun for me it's I I don't get languages that are really",
    "start": "1714799",
    "end": "1723080"
  },
  {
    "text": "difficult um languages that are really difficult to refactor or when anything",
    "start": "1723080",
    "end": "1728240"
  },
  {
    "text": "changes that I have to do a lot of like changing I find that to be very",
    "start": "1728240",
    "end": "1733760"
  },
  {
    "text": "frustrating Zig doesn't seem to have that problem and go does not have that",
    "start": "1733760",
    "end": "1739080"
  },
  {
    "text": "problem whereas rust does have that problem and I I just don't I just don't like that what the [ __ ] is a box pointer",
    "start": "1739080",
    "end": "1745640"
  },
  {
    "text": "it's not that bad a box pointer is just a a it's just a pointer okay that's all",
    "start": "1745640",
    "end": "1751200"
  },
  {
    "text": "it is they just use the term box right because you have to have something that's consistently sized on a",
    "start": "1751200",
    "end": "1757559"
  },
  {
    "text": "the stack and typically whenever you're like using JavaScript they call it a boxed value as well a box is just it's",
    "start": "1757559",
    "end": "1763960"
  },
  {
    "text": "just a pointer that's all it is it's just something yep Dick in a Box box no it's not a dick in a box there's no dick",
    "start": "1763960",
    "end": "1770399"
  },
  {
    "text": "in any box okay what is an arc that's an atomic reference count pointer okay it's",
    "start": "1770399",
    "end": "1775960"
  },
  {
    "text": "a shared pointer if you've ever used C++ and you use shared pointer that's all an arc is that's it you know that's it a",
    "start": "1775960",
    "end": "1783080"
  },
  {
    "text": "bck and a docks yeah that's right too many types too many types changeability is important to software development",
    "start": "1783080",
    "end": "1788440"
  },
  {
    "text": "that's typically why I enjoy go or zigg more just because I find that the changeability is rather nice in either",
    "start": "1788440",
    "end": "1795279"
  },
  {
    "text": "of them typically speaking I suggest testing your specific use case before",
    "start": "1795279",
    "end": "1801679"
  },
  {
    "text": "choosing Bon if your goal is to improve performance all right let me show each graph for the entire test duration all",
    "start": "1801679",
    "end": "1809279"
  },
  {
    "text": "right nice I still don't really consider this a like I don't really think this is a big win for go either and I'm not sure",
    "start": "1809279",
    "end": "1816039"
  },
  {
    "text": "if this is any sort of issue here like you can see right here that you've effectively just maxed out I mean you",
    "start": "1816039",
    "end": "1821840"
  },
  {
    "text": "can see right here that that [ __ ] becomes the problem the database insert is where we're actually stuck in all",
    "start": "1821840",
    "end": "1827559"
  },
  {
    "text": "performance just by looking at this graph one could guess that that's just the problem is you're just playing",
    "start": "1827559",
    "end": "1833440"
  },
  {
    "text": "database insert because you'll notice that this matches that right and so it's not like a huge there's not a lot of",
    "start": "1833440",
    "end": "1839720"
  },
  {
    "text": "huge W going on here I'm a little confused why there's so much leg right away with bun and inserting into the",
    "start": "1839720",
    "end": "1846080"
  },
  {
    "text": "database to me this already says there's something wrong right here that's even that has nothing to",
    "start": "1846080",
    "end": "1853519"
  },
  {
    "text": "do with whatever is going on whatever we're seeing because you'll notice that this and this are almost one for one",
    "start": "1853519",
    "end": "1858960"
  },
  {
    "text": "right your entire your entire uh latency is dependent on how long it takes for",
    "start": "1858960",
    "end": "1864559"
  },
  {
    "text": "you to insert into the database in a 20 millisecond insert just feels like something's gone",
    "start": "1864559",
    "end": "1870880"
  },
  {
    "text": "wrong yeah yeah there's something yeah yeah exactly a there's just some other",
    "start": "1870880",
    "end": "1876240"
  },
  {
    "text": "thing happening here that we're measuring that's not quite the right thing it's just you're measuring the",
    "start": "1876240",
    "end": "1881279"
  },
  {
    "text": "wrong item and my guess again is just the fact that it has to do with exceptionally tiny amount of CPU that",
    "start": "1881279",
    "end": "1888399"
  },
  {
    "text": "You' have allotted to this machine and just you're having all these different things vying for attention so it's just",
    "start": "1888399",
    "end": "1894120"
  },
  {
    "text": "tons of contact switching if you have a connection pool to a mongod DB that's",
    "start": "1894120",
    "end": "1899799"
  },
  {
    "text": "spawning a bunch of these little green threads running and then on top of it you have a whole bunch of every single",
    "start": "1899799",
    "end": "1905519"
  },
  {
    "text": "time you make a request you add something to the process queue in which then adds a couple more things to the process queue it's just then you're",
    "start": "1905519",
    "end": "1911600"
  },
  {
    "text": "going to this ever growing thing here and then you have go that's constantly running right one cor is for B let's see",
    "start": "1911600",
    "end": "1917080"
  },
  {
    "text": "for bun is also rough yeah one core for anything is typically rough when it comes to JavaScript you usually do n",
    "start": "1917080",
    "end": "1922600"
  },
  {
    "text": "minus one because you want at least one more core for all the other things",
    "start": "1922600",
    "end": "1928240"
  },
  {
    "text": "running but just having everything on one CPU that's also been limited it's just you're just not going to win right",
    "start": "1928240",
    "end": "1934240"
  },
  {
    "text": "there's no W there there's no W going on here more CPU would uh yeah and and the reality is that if you just added a CPU",
    "start": "1934240",
    "end": "1940960"
  },
  {
    "text": "or added two CPS Bun's performance would likely increase by a significant margin",
    "start": "1940960",
    "end": "1946080"
  },
  {
    "text": "it's n minus one n minus one is how many uh how many bun instances you want right",
    "start": "1946080",
    "end": "1951559"
  },
  {
    "text": "but Go's performance would not increase just significant it would increase like astronomically it would",
    "start": "1951559",
    "end": "1959200"
  },
  {
    "text": "just be pegged right to mongod DB's ability to insert on a single machine that's it like that's that would be Go's",
    "start": "1959200",
    "end": "1966039"
  },
  {
    "text": "performance because go would be able to utilize all the available other CPU very very well first we have aest yes and",
    "start": "1966039",
    "end": "1973120"
  },
  {
    "text": "also what would be really really nice is this right here taking being able to run several bun instances or however you",
    "start": "1973120",
    "end": "1979880"
  },
  {
    "text": "want to do it to be able to run multi-thread bun whether you're using workers or several instances however you",
    "start": "1979880",
    "end": "1985240"
  },
  {
    "text": "want to do it then do that but you also have to describe that as a difficulty because let's let's just be just at",
    "start": "1985240",
    "end": "1991760"
  },
  {
    "text": "least a touch honest here having a singular program right Fu that runs and",
    "start": "1991760",
    "end": "1998919"
  },
  {
    "text": "is able to utilize all of your CPU cores no matter what you're using is significantly easier to write and to",
    "start": "1998919",
    "end": "2006360"
  },
  {
    "text": "maintain than writing some service that has to thus spawn some n minus Su number",
    "start": "2006360",
    "end": "2012880"
  },
  {
    "text": "that you've determined works correctly for the amount of cores that are available on the machine such that you",
    "start": "2012880",
    "end": "2018559"
  },
  {
    "text": "can make bun run as efficiently as possible Right like this is a problem that you don't even have to think about",
    "start": "2018559",
    "end": "2025399"
  },
  {
    "text": "this is a problem that you have to think about and you have to write correctly you have to yeah you have to write a",
    "start": "2025399",
    "end": "2031799"
  },
  {
    "text": "some sort of reverse proxy for all the instances to be able to hand that out which means you're probably not writing",
    "start": "2031799",
    "end": "2036880"
  },
  {
    "text": "bun to begin with cuz now you're writing a reverse proxy probably in rust or in go or in Zig like you just have this",
    "start": "2036880",
    "end": "2043519"
  },
  {
    "text": "entire other problem that exists that you just don't have here and that's engineering hours this is engineering",
    "start": "2043519",
    "end": "2050118"
  },
  {
    "text": "hours second graph that's pretty awesome though so it's not free I just wanted I",
    "start": "2050119",
    "end": "2055878"
  },
  {
    "text": "know I'm sure there's a lot of really great stuff by the way that you can do that will make it work cuz someone said B uh bun has pretty simple clustering",
    "start": "2055879",
    "end": "2062398"
  },
  {
    "text": "with shared Port yeah I'm sure it has something that's already been built in it probably already has it must have the reverse proxy already built in for you",
    "start": "2062399",
    "end": "2068760"
  },
  {
    "text": "but nonetheless you are still having to write the reverse proxy you're you're still having to think about that as a",
    "start": "2068760",
    "end": "2074158"
  },
  {
    "text": "problem right up hold on I got something I'm GNA be right back flip take this out client",
    "start": "2074159",
    "end": "2080240"
  },
  {
    "text": "latency that's kind of fun this little this little curve database insert",
    "start": "2080240",
    "end": "2086440"
  },
  {
    "text": "latency multiple CPUs wouldn't really help let's see wouldn't really help uh",
    "start": "2086440",
    "end": "2091520"
  },
  {
    "text": "with go that much just push this Behavior out a little bit more well it would help in the sense that it pushes that behavior out",
    "start": "2091520",
    "end": "2098480"
  },
  {
    "text": "more I mean obviously you'd be pegged to your database at some point but it would",
    "start": "2098480",
    "end": "2103839"
  },
  {
    "text": "most certainly help a decent amount because go can you you don't even have",
    "start": "2103839",
    "end": "2109760"
  },
  {
    "text": "to think about it Go just naturally will use all of your CPUs significantly easier and so if you if you added a",
    "start": "2109760",
    "end": "2115839"
  },
  {
    "text": "couple CPUs it would nicely use all of that and you wouldn't even have to think about it now obviously your CPU or",
    "start": "2115839",
    "end": "2122720"
  },
  {
    "text": "however Mongo's been written I don't know it's the unbounded number of G routines versus workers yeah",
    "start": "2122720",
    "end": "2129640"
  },
  {
    "text": "but but there's a there's a lot more overhead when it comes to a worker in bun than there is in go a go routine is",
    "start": "2129640",
    "end": "2135599"
  },
  {
    "text": "a pretty lightweight construction a worker or a new bun instance is a heavyweight item to be",
    "start": "2135599",
    "end": "2144040"
  },
  {
    "text": "able to have several buns running you're going to have to have gigabytes and gigabytes of",
    "start": "2144040",
    "end": "2152000"
  },
  {
    "text": "RAM whereas if you don't have that it's you know it's just there's going to be a lot of different",
    "start": "2152000",
    "end": "2158440"
  },
  {
    "text": "if you know there's going to be there's definitely going to be some things here it's okay it's okay bu I'm heavyweight too yeah it's okay you can be",
    "start": "2158440",
    "end": "2164079"
  },
  {
    "text": "heavyweight we're not even saying that even again just go back to what I said at the beginning which is honestly if",
    "start": "2164079",
    "end": "2169680"
  },
  {
    "text": "you'd rather write bun go for it enjoy your several buns okay that's for you",
    "start": "2169680",
    "end": "2174720"
  },
  {
    "text": "it's just not a problem I enjoy I've actually found that a really simple language has allowed me to have a really",
    "start": "2174720",
    "end": "2180440"
  },
  {
    "text": "simple model of the world which has allowed me to really think about the problem I want to solve and yes I would",
    "start": "2180440",
    "end": "2187040"
  },
  {
    "text": "assume that the standard Library does a uh co- routine per or a go routin not a CO a go routine per request or else it's",
    "start": "2187040",
    "end": "2194520"
  },
  {
    "text": "going to get like if you if you halt it then it's going to suck but this type of test specifically targets server implementation of unbounded go routines",
    "start": "2194520",
    "end": "2201119"
  },
  {
    "text": "versus uh using a worker pool in go if you made a go server that used worker pools then it' perform better in this",
    "start": "2201119",
    "end": "2207440"
  },
  {
    "text": "case I'm sure it would I I've never played around with worker pools in in go so I I have no",
    "start": "2207440",
    "end": "2214720"
  },
  {
    "text": "idea right this test is poop it's interesting in the sense that you can see that I think the most interesting",
    "start": "2214720",
    "end": "2221800"
  },
  {
    "text": "takeaway I have about this is that smaller synthetic tests can produce wildly weird outcomes and one should",
    "start": "2221800",
    "end": "2230000"
  },
  {
    "text": "not one should never take the synthetic test you see did you see like did you",
    "start": "2230000",
    "end": "2236079"
  },
  {
    "text": "see the difference between these two these two tests are not that much different but you can see a vastly",
    "start": "2236079",
    "end": "2242920"
  },
  {
    "text": "difference perfor in performance think about how many times especially if you're at like a Lar larger company",
    "start": "2242920",
    "end": "2248599"
  },
  {
    "text": "where you have somebody come in and they show you something they're like look at how much better this is and so many",
    "start": "2248599",
    "end": "2255280"
  },
  {
    "text": "people latch on to those things and they go see this is better",
    "start": "2255280",
    "end": "2261319"
  },
  {
    "text": "and there's no actual real production traffic there's no real production workload there's no real anything about",
    "start": "2261319",
    "end": "2266680"
  },
  {
    "text": "it they showed something that is in their favor because what you could do like honestly how much do you think",
    "start": "2266680",
    "end": "2273359"
  },
  {
    "text": "people will show this first test and be like look bun is better I bet you there are tweets right now that only watch",
    "start": "2273359",
    "end": "2279280"
  },
  {
    "text": "this far into the test and that's it and people are talking about it and that's that and it's not even real right like",
    "start": "2279280",
    "end": "2286000"
  },
  {
    "text": "they're being misled for some dumb reason just be super care I think that's",
    "start": "2286000",
    "end": "2291200"
  },
  {
    "text": "the big takeaway here is that slight variations can cause vastly different outcomes in these kind of micro",
    "start": "2291200",
    "end": "2299000"
  },
  {
    "text": "Benchmark type environments manga DB CPU usage application CPU usage",
    "start": "2299000",
    "end": "2309079"
  },
  {
    "text": "memory",
    "start": "2311400",
    "end": "2313880"
  },
  {
    "text": "usage availability",
    "start": "2316839",
    "end": "2320640"
  },
  {
    "text": "graph and finally CPU throttling I have other benchmarks that you might find",
    "start": "2322359",
    "end": "2328040"
  },
  {
    "text": "interesting and if you know how to improve any of these applications please feel free to submit a pool request thank",
    "start": "2328040",
    "end": "2334240"
  },
  {
    "text": "you for watching and I'll see you in the next video so I did something I think I call like",
    "start": "2334240",
    "end": "2339920"
  },
  {
    "text": "uh shooter. JS um the primagen so I did something similar and I did this one I",
    "start": "2339920",
    "end": "2345760"
  },
  {
    "text": "did with various different ones and I have a whole like View and everything that that is involved in this and I do a",
    "start": "2345760",
    "end": "2351640"
  },
  {
    "text": "lot of fun stuff with this and like the differences are are significant and then",
    "start": "2351640",
    "end": "2358040"
  },
  {
    "text": "I even did one with uh rust in here and someone someone made a a a PR to Russ",
    "start": "2358040",
    "end": "2365160"
  },
  {
    "text": "let's see if they have it in here I don't think so anyways no it doesn't look like there is someone made a pi in",
    "start": "2365160",
    "end": "2370480"
  },
  {
    "text": "Rust and showed me a different way to do it in Rust and it made it just like insanely faster and there's all sorts of",
    "start": "2370480",
    "end": "2376720"
  },
  {
    "text": "kind of fun ways you can do stuff that uh that you can do that it's just it's",
    "start": "2376720",
    "end": "2382400"
  },
  {
    "text": "just not really possible in the in the world in in the JavaScript World versus in these worlds where you can just go so",
    "start": "2382400",
    "end": "2388960"
  },
  {
    "text": "much faster and the basic testing I was doing was seeing how much like theoretical theoretical games that",
    "start": "2388960",
    "end": "2395079"
  },
  {
    "text": "involve Collision detection and everything on a server can run concurrently and have good performance",
    "start": "2395079",
    "end": "2400839"
  },
  {
    "text": "meaning that frames aren't dropped on the server and it's just like the difference between any node any",
    "start": "2400839",
    "end": "2407160"
  },
  {
    "text": "JavaScript versus go is like 10x different and the diff any difference",
    "start": "2407160",
    "end": "2412480"
  },
  {
    "text": "between go and rust is significantly different but it is not different in the same",
    "start": "2412480",
    "end": "2418319"
  },
  {
    "text": "level right it's it's it's just better but not by the same level of margin",
    "start": "2418319",
    "end": "2424480"
  },
  {
    "text": "right and so it's interesting it's just a very interesting world looking at these and seeing how people form these",
    "start": "2424480",
    "end": "2429960"
  },
  {
    "text": "kind of marks big takeaway don't trust micro benchmarks don't trust small world benchmarks trust real data go out",
    "start": "2429960",
    "end": "2436280"
  },
  {
    "text": "measure production go and make a change continue to measure production does",
    "start": "2436280",
    "end": "2441480"
  },
  {
    "text": "production's 99 percentile go up or down because if it goes down then guess what",
    "start": "2441480",
    "end": "2447079"
  },
  {
    "text": "good thing happen you probably solved some problems you probably made better stuff so test in production don't test",
    "start": "2447079",
    "end": "2453599"
  },
  {
    "text": "don't test synthetic test don't make decisions best on based on really small synthetic tests you'll likely be sad",
    "start": "2453599",
    "end": "2460200"
  },
  {
    "text": "measure your production not mine or anyone else we have different prod anyways the name is that was pretty",
    "start": "2460200",
    "end": "2467680"
  },
  {
    "text": "interesting though it's it's interesting that I I feel nerd sniped but I'm",
    "start": "2467680",
    "end": "2473280"
  },
  {
    "text": "refusing to do it because all I want to do is finish up my stuff right here my little uh I'm building a simulation",
    "start": "2473280",
    "end": "2479839"
  },
  {
    "text": "tester for my game servers and so I just want to I want to finish that so I'm refusing to let myself be nerd sniped",
    "start": "2479839",
    "end": "2486200"
  },
  {
    "text": "but I can feel it I can feel the pull I feel the pull of being nerd sniped right now just not doing it not letting it not",
    "start": "2486200",
    "end": "2492079"
  },
  {
    "text": "going to let it happen a Jen",
    "start": "2492079",
    "end": "2496599"
  }
]
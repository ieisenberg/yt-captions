[
  {
    "text": "Thank you, Johannes, for the introduction. Uh, you stole my icebreaker questions, but that's okay.",
    "start": "3289",
    "end": "7949"
  },
  {
    "text": "Uh, um, thank you guys all so much for attending\nthe Effect meetup here in San Francisco.",
    "start": "8470",
    "end": "15060"
  },
  {
    "text": "I think this is the second annual meetup, I guess. Um, but we're so excited to see so many faces in\nthe audience that are excited to learn about Effect.",
    "start": "15060",
    "end": "22839"
  },
  {
    "text": "The title of my talk is the Rise of Autonomous\nSoftware, building Agentic Workflows with Effect.",
    "start": "23910",
    "end": "30600"
  },
  {
    "text": "But what do I really mean by agentic\nworkflows or agentic systems? We're becoming increasingly surrounded by\nsystems that operate autonomously, systems that",
    "start": "32030",
    "end": "41749"
  },
  {
    "text": "can make decisions, dynamically adapt to their\nenvironment, without really any human intervention.",
    "start": "41750",
    "end": "46880"
  },
  {
    "text": "Think about like all the self driving cars\nwe see here in San Francisco, we definitely don't have those in New Jersey, yet.",
    "start": "47720",
    "end": "52640"
  },
  {
    "text": "Um, but maybe soon, who knows. Um, but these systems can process and analyze\ninputs, adapt, and perform actions on their own.",
    "start": "53250",
    "end": "61599"
  },
  {
    "text": "And that's really what I mean by agentic systems. These systems have agency themselves to take action.",
    "start": "61839",
    "end": "67530"
  },
  {
    "text": "But as developers who are tasked with\ndesigning and building these systems, we are faced with an enormous amount of complexity.",
    "start": "69779",
    "end": "76469"
  },
  {
    "text": "We have to make these systems fault tolerant. We have to make these systems scalable. We have to make them observable.",
    "start": "77169",
    "end": "81939"
  },
  {
    "text": "Uh, and the list just keeps going on. Um, and while these systems are not\nnecessarily unique, to agentic systems.",
    "start": "82390",
    "end": "90214"
  },
  {
    "text": "Um, when we throw AI into the mix, we sort of like\nexponentially compound the complexity that we're faced with.",
    "start": "90645",
    "end": "96794"
  },
  {
    "text": "But how, so how do we like deal with all of this complexity? Well, I think one of the ways we can deal\nwith it is by leaning into our tooling.",
    "start": "97414",
    "end": "105205"
  },
  {
    "text": "Um, we need tools that are expressive enough\nto model all of this complex behavior.",
    "start": "105784",
    "end": "110804"
  },
  {
    "text": "And interactions while also maintaining the\nreliability, the scalability, observability of",
    "start": "111120",
    "end": "116479"
  },
  {
    "text": "that we need when we're building these systems. And I think this is really where Effect shines, um, so\njust a quick level set, um, in this talk, we're gonna",
    "start": "116509",
    "end": "126460"
  },
  {
    "text": "spend a tiny bit of time talking about agents kind of\ngiving a little bit of a definition of what they are. Some common design patterns that are in\nuse, um, and then some of the challenges.",
    "start": "126460",
    "end": "135534"
  },
  {
    "text": "And we'll try to go a little bit quicker through\nthis part of the talk so that we can arrive at the part that everybody's probably more\ninterested in, which is the role of effect.",
    "start": "135535",
    "end": "143045"
  },
  {
    "text": "And, like, actually looking at some code,\num, a little bit about me, I think Johannes",
    "start": "143045",
    "end": "148454"
  },
  {
    "text": "already gave a great introduction, but. I'm based in New Jersey. I was originally a pharmacist in a previous life.",
    "start": "148455",
    "end": "154653"
  },
  {
    "text": "Um, I'm a huge Effect enthusiast. I've been part of the community\nfor the better part of six years.",
    "start": "154855",
    "end": "159903"
  },
  {
    "text": "Um, I'm also a DevOps and infrastructure nerd. That's kind of how I got my, um, start in the tech world.",
    "start": "160355",
    "end": "166434"
  },
  {
    "text": "Um, so if any of these topics are of\ninterest to you, please get in touch. I'd love to chat. Um, maybe we can chat this evening.",
    "start": "166884",
    "end": "172645"
  },
  {
    "text": "So, let's talk a little bit about what is an agent? How many folks in the audience have like a working\nDefinition of what an AI agent actually is.",
    "start": "175144",
    "end": "184694"
  },
  {
    "text": "That's pretty good. Um, well, large language models have definitely\nchanged the way that we interact with software.",
    "start": "185575",
    "end": "191715"
  },
  {
    "text": "Um, historically, and I use the word historically extremely\nloosely, because I think I'm referring to like two years",
    "start": "192480",
    "end": "197970"
  },
  {
    "text": "ago, but in the AI world, I guess that's like an eternity. Um, historically, interactions with models were primarily\nand basically only in a request response format, right?",
    "start": "197970",
    "end": "209080"
  },
  {
    "text": "You prompt a model and you immediately get the\noutput of that model token by token returned to you.",
    "start": "209080",
    "end": "214270"
  },
  {
    "text": "There was no opportunity for\nthe model to improve its output. There was no opportunity for any refinement. Um, and so you basically got what you got.",
    "start": "214550",
    "end": "221838"
  },
  {
    "text": "But over time, we started to figure out ways that\nwe could enhance the output of our LLMs, right?",
    "start": "223090",
    "end": "229590"
  },
  {
    "text": "We figured out we could give these models\nthe ability to reflect on their output before they actually returned it to us.",
    "start": "229780",
    "end": "236129"
  },
  {
    "text": "So kind of giving it a feedback loop,\nwe connected them with external tools.",
    "start": "236129",
    "end": "240380"
  },
  {
    "text": "And by doing this, we were sort of already building up\ntowards what we sort of define today as like an AI agent.",
    "start": "241260",
    "end": "247780"
  },
  {
    "text": "While there's really not, like, a universally agreed upon\ndefinition of an agent, um, there is one particular, I",
    "start": "249560",
    "end": "257669"
  },
  {
    "text": "guess, set of, uh, characteristics that's pretty unique. And this comes from Lillian Wang, who is the\ncurrent head of safety systems at OpenAI and",
    "start": "257669",
    "end": "269625"
  },
  {
    "text": "is a former head of applied AI research there. She maintains a fantastic blog, so if you guys don't\nknow about it, go check it out, it's really cool.",
    "start": "269625",
    "end": "277865"
  },
  {
    "text": "Um, where she provides overviews on various AI topics,\num, and she really does a great job of distilling these",
    "start": "278485",
    "end": "284994"
  },
  {
    "text": "down into more easily digestible, uh, kind of formats. Um, and in her definition of an agent, she\nbasically says that they have three components.",
    "start": "284994",
    "end": "294455"
  },
  {
    "text": "The first is planning, the second is memory,\nand the third is the ability to use tools. For planning, agents should have the ability\nto decompose tasks into smaller subunits.",
    "start": "294865",
    "end": "304985"
  },
  {
    "text": "Basically take a complex problem, break it into\nsmaller problems that are more easy to solve. And then, similarly, as part of planning, the\nagent should be able to reflect on its output",
    "start": "305495",
    "end": "315965"
  },
  {
    "text": "so that it can improve upon its mistakes. And if you think about it, this isn't really\nall that different from how we as humans",
    "start": "316235",
    "end": "322444"
  },
  {
    "text": "approach solving a complex problem, right? We sort of do the same thing. We also, as humans, have memory.",
    "start": "322544",
    "end": "329594"
  },
  {
    "text": "Um, both short and long term. Just like agents. For agents though, their short term memory is\nreally in the form of what we can fit into a prompt.",
    "start": "330044",
    "end": "338194"
  },
  {
    "text": "So everything about the prompt is kind of\nlike the short term memory of an agent. Um, whereas the long term memory of an agent\nIt's more associated with things that the agent",
    "start": "338335",
    "end": "347310"
  },
  {
    "text": "might fetch, uh, as part of a request, right? I think probably one of the most popular examples of\nthis is retrieval augmented generation, where you might",
    "start": "347310",
    "end": "354969"
  },
  {
    "text": "have a vector database that has some embeddings, uh, on a\nparticular topic, um, and that agent can go and get that",
    "start": "354979",
    "end": "361369"
  },
  {
    "text": "information to enhance the output it's generating for you. And then the third component\nhere is the ability to use tools.",
    "start": "361369",
    "end": "367430"
  },
  {
    "text": "So, for example, giving the agent the ability\nto search the web or run code in an interpreter.",
    "start": "367800",
    "end": "372460"
  },
  {
    "text": "Um, and I want to talk a little bit now about, now\nthat we, like, kind of have a working definition",
    "start": "373695",
    "end": "381615"
  },
  {
    "text": "of what an agent actually is, um, I want to talk\na little bit about agentic design patterns, um,",
    "start": "381615",
    "end": "387434"
  },
  {
    "text": "like the ways that we actually build these systems. But it's kind of difficult to talk about this, because\nnumber one, the tooling and the literature surrounding",
    "start": "387434",
    "end": "397345"
  },
  {
    "text": "basically all of AI is moving at a breakneck speed. So it's really hard for us to sort of\nkeep up with what's going on on a basis.",
    "start": "397735",
    "end": "405765"
  },
  {
    "text": "And also everyone's sort of taking a little bit\nof a different approach to building these systems,",
    "start": "406825",
    "end": "412045"
  },
  {
    "text": "so classifying them becomes more difficult. But earlier this year in March, Andrew Ng, the founder\nof Deep Learning AI and a bunch of other things,",
    "start": "412485",
    "end": "423535"
  },
  {
    "text": "presented at the Sequoia Capital's AI Ascent on what\nhe thought was sort of next for agentic systems.",
    "start": "424355",
    "end": "430885"
  },
  {
    "text": "And he classified the design patterns that he thought\nwere going to become popular into four major categories.",
    "start": "431615",
    "end": "437315"
  },
  {
    "text": "So we'll go through these one by one quickly. Um, the first design pattern he thought would become\npopular over this, this year, um, was reflection.",
    "start": "438034",
    "end": "447775"
  },
  {
    "text": "So again, giving the agent, the agent the\nability to learn from its past mistakes, right?",
    "start": "447814",
    "end": "453104"
  },
  {
    "text": "Giving it a feedback loop. So an example here is having maybe two agents\nwork together to write a piece of code.",
    "start": "453354",
    "end": "460409"
  },
  {
    "text": "Right? You give, uh, the agent a task to write code\nto solve a problem, and that agent can, uh,",
    "start": "460909",
    "end": "467849"
  },
  {
    "text": "iteratively improve the output of that code. And then here, in this example, where we have\ntwo agents interacting together, but I want to",
    "start": "467909",
    "end": "475019"
  },
  {
    "text": "point out, you could also, uh, get reflection just\nwith a single LLM self critiquing its own work.",
    "start": "475019",
    "end": "481219"
  },
  {
    "text": "Um, the second design pattern, He thought would become\npopular was connecting a, uh, LLMs to external tools.",
    "start": "482570",
    "end": "489495"
  },
  {
    "text": "So you sort of start to see the similarities between how\nLillian Wang defined an agent and the design pattern, the",
    "start": "489505",
    "end": "494814"
  },
  {
    "text": "design patterns Andrew Ng thought would become popular. Um, and again, this is just giving\nthe agent the ability to use.",
    "start": "494814",
    "end": "504025"
  },
  {
    "text": "Something that's not part of its API\ncall out to a particular tool to perform some action on the left or I guess.",
    "start": "504405",
    "end": "511724"
  },
  {
    "text": "Yeah, the left here. Um, we have a prompt where we want to know\nwhat the best coffee is based on reviews.",
    "start": "511955",
    "end": "519274"
  },
  {
    "text": "So we give the agent the ability to search the web for. Reviews, right? And on the right, we have a separate example where we\ngive the agent a word problem where it has to perform",
    "start": "519284",
    "end": "528825"
  },
  {
    "text": "some mathematical calculation and that agent can now\ngenerate some code and run it in the code interpreter.",
    "start": "528855",
    "end": "535664"
  },
  {
    "text": "We give it access to so again, giving agents the\nability to use tools can significantly enhance the",
    "start": "535665",
    "end": "541873"
  },
  {
    "text": "output, depending on the problem we're trying to solve. The 3rd pattern is planning, which, again, you can\nremember from Lillian Wang's definition of an agent.",
    "start": "541874",
    "end": "551415"
  },
  {
    "text": "Um, and the example I want to point out here is. We're going to take a particular complicated task, break it\ndown into more digestible problems that the agent can solve.",
    "start": "552315",
    "end": "562440"
  },
  {
    "text": "And for each of those subtasks, the agent can\nuse different tools to sort of solve the problem.",
    "start": "563110",
    "end": "568378"
  },
  {
    "text": "So here in this example, we're prompting the\nagent to generate a picture of a girl reading in",
    "start": "568409",
    "end": "574079"
  },
  {
    "text": "the same pose as the boy on the scooter, right? So the first thing the agent might do is generate\na task to do a pose determination, followed by",
    "start": "574079",
    "end": "582160"
  },
  {
    "text": "Generating an image from that pose and again, we\ncan use different tools to solve these different tasks and the fourth design pattern that he thought\nwould become popular is multi agent collaboration.",
    "start": "582689",
    "end": "594368"
  },
  {
    "text": "And I think this is probably the most\ninteresting 1 where we use multiple agents working together to try to solve a problem.",
    "start": "594369",
    "end": "600738"
  },
  {
    "text": "And I think, uh, hi, a more, um. Frequently cited example of this\nis, uh, the chapter of architecture.",
    "start": "602320",
    "end": "611419"
  },
  {
    "text": "So the paper that kind of explained\nthis architecture goes through. You know, uh, a mock chat powered software development\nframework where every agent has a particular role as",
    "start": "611519",
    "end": "623010"
  },
  {
    "text": "if they were in, like, a software development company. Um, and when you feed a problem into the beginning\nof the chain, it sort of goes through, like, the",
    "start": "623010",
    "end": "630118"
  },
  {
    "text": "planning phase with the C suite and then through the\ncoding phase with the engineers, et cetera, et cetera.",
    "start": "630119",
    "end": "635130"
  },
  {
    "text": "And on the other end, you hopefully get\na comprehensive solution to the problem. But the idea here is, again, you have multiple agents\nthat are working together to solve the problem.",
    "start": "635130",
    "end": "642880"
  },
  {
    "text": "And I think if we think about the AI systems that\nare around today, um, Andrew was Pretty spot on",
    "start": "645235",
    "end": "651390"
  },
  {
    "text": "with his predictions, but I think what's becoming\neven more common is combining all of these tools,",
    "start": "651400",
    "end": "657040"
  },
  {
    "text": "uh, into even more interesting design patterns. I think a popular one today that basically combines\nall of these pieces is the mixture of agents, uh, uh,",
    "start": "657740",
    "end": "668149"
  },
  {
    "text": "mixture of agents, uh, model where you feed a prompt\ninto the system and you have multiple, Agents that are",
    "start": "668160",
    "end": "677620"
  },
  {
    "text": "all evaluating that same prompt and generating output. And then you have an aggregator agent that is basically\ntrying to pick out what the best version of the output is.",
    "start": "677620",
    "end": "688509"
  },
  {
    "text": "Um, and what's really cool about this is every\nsingle one of those agents in the framework",
    "start": "689090",
    "end": "694879"
  },
  {
    "text": "has Tools, the ability to plant, the ability\nto reach out to different sources of memory.",
    "start": "694879",
    "end": "700435"
  },
  {
    "text": "Um, so you can really get some high quality\noutput with a relatively simple design, simple in quotes, because obviously the implementation\nis much more complicated than this picture.",
    "start": "700975",
    "end": "709895"
  },
  {
    "text": "And we can add additional layers into this model, which is\npretty cool, because, um, just by adding additional layers,",
    "start": "713075",
    "end": "719474"
  },
  {
    "text": "you can continually improve the output that you're getting. Um, but one thing we really haven't mentioned\nat all when talking about these design patterns",
    "start": "719484",
    "end": "728380"
  },
  {
    "text": "are the challenges that we face when we\nactually try to implement these things, right? More agents, more problems, right?",
    "start": "728570",
    "end": "734910"
  },
  {
    "text": "So, um, whenever we're building these systems, we\nhave to deal with a lot of different challenges.",
    "start": "734959",
    "end": "741529"
  },
  {
    "text": "For example, error handling. We need these systems to be fault tolerant, right? We need to figure out what to do in different error states.",
    "start": "742690",
    "end": "749410"
  },
  {
    "text": "We also, in the sit, in the situation where we have\nmultiple agents communicating together, this may be happening concurrently, and we need to have a principled,\nuh, approach to how we actually manage that concurrency.",
    "start": "751200",
    "end": "761709"
  },
  {
    "text": "Um, also, if we have, uh, many different concurrent\nrequests out there to agents to generate output,",
    "start": "763120",
    "end": "770120"
  },
  {
    "text": "if one of those agents encounters an error, we\nprobably want to interrupt what's going on with the other agents so we don't waste bandwidth.",
    "start": "770520",
    "end": "776240"
  },
  {
    "text": "Um, and observability is, uh, always\nsomething that we should be keeping in mind, but often ends up being an afterthought.",
    "start": "777555",
    "end": "783925"
  },
  {
    "text": "In these systems, it's even more important to kind\nof try to make observability a first class citizen.",
    "start": "783925",
    "end": "789375"
  },
  {
    "text": "And the list goes on of challenges that\nwe face when we're building these systems. Um, other types of complexity also exist that maybe are\nslightly more specific to agentic systems, where we have",
    "start": "791034",
    "end": "801954"
  },
  {
    "text": "really long running processes, so you can think, Towards\nlike your autonomous agents, where the processes might last",
    "start": "801954",
    "end": "808175"
  },
  {
    "text": "forever, um, interactions with multiple models means you\nhave to handle all of these problems across every model.",
    "start": "808185",
    "end": "814705"
  },
  {
    "text": "You're interacting with and then streaming, right? Everything becomes more complicated when you\nstart incorporating streaming and doing all",
    "start": "814705",
    "end": "822043"
  },
  {
    "text": "of these things, but in the streaming context. But again, all of these problems are not\nnecessarily unique to agentic systems.",
    "start": "822045",
    "end": "832415"
  },
  {
    "text": "They're sort of things that we deal with every\nday when we're developing normal software. Um, and so for those familiar with effect,\nyou know that these are problems that are",
    "start": "832775",
    "end": "841844"
  },
  {
    "text": "pretty much addressed by the library already. We do a great job of all, handling all of these things.",
    "start": "841844",
    "end": "847495"
  },
  {
    "text": "So why do I keep saying that when we're building\nagentic systems, we sort of compound the complexity?",
    "start": "848254",
    "end": "854194"
  },
  {
    "text": "Well, the reason is that agentic systems\nare inherently non deterministic.",
    "start": "855760",
    "end": "860440"
  },
  {
    "text": "Meaning, for the same inputs, you\ndon't always get the same outputs.",
    "start": "860830",
    "end": "866340"
  },
  {
    "text": "Right? You might call an agentic system with three different\ntimes, and for each one of those times, that agent may",
    "start": "866810",
    "end": "874369"
  },
  {
    "text": "decide to call different tools, or reach out to different\nsources of memory, and you may end up getting totally different output from that, those individual prompts.",
    "start": "874370",
    "end": "882170"
  },
  {
    "text": "Um, and so, how do we deal with These nondeterministic,\nuh, pieces of software, these nondeterministic",
    "start": "883650",
    "end": "891470"
  },
  {
    "text": "systems that are very hard to predict. Well, in an environment where nondeterminism is the default,\nwe believe that effect is the antidote, so to speak.",
    "start": "891480",
    "end": "902540"
  },
  {
    "text": "Observability and monitoring should be things that\nare critical from day one when building these systems.",
    "start": "903399",
    "end": "908810"
  },
  {
    "text": "In fact, it does a great job with handling those things. And it don't just take our word for it, there\nare already plenty of folks building these",
    "start": "908840",
    "end": "918515"
  },
  {
    "text": "systems, uh, with effect and seeing great results. Because Effect really makes sure that, you\nknow, these are things that you consider up",
    "start": "918515",
    "end": "926915"
  },
  {
    "text": "front, companies like MarkPrompt, you guys\nare here, doing a great job with Effect. Um, Expand. ai is another wonderful company.",
    "start": "926915",
    "end": "932994"
  },
  {
    "text": "There's, there's so many more that are using\nEffect, uh, to handle these agentic systems.",
    "start": "932994",
    "end": "937674"
  },
  {
    "text": "Um, and the list goes on, and I could keep talking\nabout the problems that we're trying to solve. Um, But I do want to dive into some code, but before\nI do, I have a little bit of an announcement to make.",
    "start": "939274",
    "end": "950089"
  },
  {
    "text": "Um,",
    "start": "950300",
    "end": "950899"
  },
  {
    "text": "so today, I'm really excited to be announcing\nthe alpha release of a set of effect native",
    "start": "955630",
    "end": "960520"
  },
  {
    "text": "integration packages designed to make. Integrating with, uh, AI foundation\nmodels, um, kind of like a breeze, right?",
    "start": "960800",
    "end": "969529"
  },
  {
    "text": "Things that, like, it's just like\nwriting normal effect programs. Our goal is to help developers who want to build AI\npowered app software applications sleep better at night.",
    "start": "969530",
    "end": "978319"
  },
  {
    "text": "Just like we're helping, just like we're\nhelping the developers who write, Non AI",
    "start": "978810",
    "end": "983954"
  },
  {
    "text": "powered applications sleep better at night. Um, well, a huge shout out to Tim Smart who couldn't be\nhere today, but did an enormous amount of work on these",
    "start": "983955",
    "end": "993454"
  },
  {
    "text": "libraries and came up with a pretty spectacular API. Um, but yeah, so I'm really excited.",
    "start": "993454",
    "end": "999914"
  },
  {
    "text": "Um, you guys should all go out and\ntry it and let us know what you think. We're super interested to hear your feedback.",
    "start": "999935",
    "end": "1004605"
  },
  {
    "text": "Um, so let's dive into some code. So, we're going to build up a small example here.",
    "start": "1005275",
    "end": "1013214"
  },
  {
    "text": "Of just a simple prompt that we're going to feed\ninto a model to rewrite some code with effect, right?",
    "start": "1013524",
    "end": "1019834"
  },
  {
    "text": "Effects AI integrations are designed\nto be completely provider agnostic.",
    "start": "1021214",
    "end": "1026454"
  },
  {
    "text": "So you can write code once and plug in the provider later.",
    "start": "1026875",
    "end": "1031194"
  },
  {
    "text": "So in this example, you can see we're importing\nthe completions service from Effect AI.",
    "start": "1033365",
    "end": "1038214"
  },
  {
    "text": "And we're calling it in our program. Interacting with the API of providers, um, is\nalso designed to be agnostic of the provider.",
    "start": "1038464",
    "end": "1047170"
  },
  {
    "text": "We're trying to help unify the API so you folks don't\nhave to worry about, am I calling this model and I have to tweak this particular configuration value or whatever.",
    "start": "1047430",
    "end": "1054839"
  },
  {
    "text": "Um, we want a unified API for calling your models. Um, and, uh, you can see here we're calling\nthe create, um, we're calling the create",
    "start": "1055339",
    "end": "1064740"
  },
  {
    "text": "method on the completions API with our prompt. So let's start to think about some of the possible\nfailure scenarios that we might need to deal with.",
    "start": "1064750",
    "end": "1072929"
  },
  {
    "text": "One particular failure scenario I can think of right\noff the bat is if a particular call to a provider takes",
    "start": "1073480",
    "end": "1080080"
  },
  {
    "text": "way too long, we want to timeout that request, right? It's as easy as an effect. timeout here with whatever you\nwant as your timeout duration.",
    "start": "1080200",
    "end": "1087859"
  },
  {
    "text": "But we also probably want to have a retry policy\nwhere when we call models, um, maybe we want to",
    "start": "1089040",
    "end": "1095130"
  },
  {
    "text": "have that request be retried in a principled way. So here, in this example, We're going to retry our\ncall to this particular model with a policy of only",
    "start": "1095140",
    "end": "1107970"
  },
  {
    "text": "making that retry call every 500 milliseconds, no\nmore than every 500 milliseconds, and only two times.",
    "start": "1107980",
    "end": "1113160"
  },
  {
    "text": "But another situation that you can think of when\nyou're doing this is if the timeout situation",
    "start": "1117940",
    "end": "1124720"
  },
  {
    "text": "happens, we probably don't want to retry. We've already been interacting with that model for\nfive seconds, and we're waiting for a response.",
    "start": "1124729",
    "end": "1131029"
  },
  {
    "text": "If we're timing out, we probably don't want to\nend up retrying that, that particular API call.",
    "start": "1131280",
    "end": "1136110"
  },
  {
    "text": "So again, it's as simple as adding, excuse me,\nuh, a while, uh, parameter to our retry, and",
    "start": "1136774",
    "end": "1145034"
  },
  {
    "text": "just filtering out for the timeout exception. So now we're only handling errors that actually\noccur as a result of our interaction with our model.",
    "start": "1145034",
    "end": "1151104"
  },
  {
    "text": "Um, and then I mentioned before that we\nwant observability with default, by default.",
    "start": "1152694",
    "end": "1157605"
  },
  {
    "text": "Um, again, simple as a width span on\nwhatever effect program you're running.",
    "start": "1158185",
    "end": "1162405"
  },
  {
    "text": "And we'll see an example later of this. But within all of our, uh, AI integration packages, um,\nyou get automatic tracing throughout the lifespan of",
    "start": "1163405",
    "end": "1173100"
  },
  {
    "text": "that request, um, generated for you as part of trace. So if you plug in, um, your trace exporter, um,\nyou'll see the trace going through the, um, actual",
    "start": "1173110",
    "end": "1183089"
  },
  {
    "text": "integration with whatever provider package you're using. So we'll see an example of that, but a little bit later.",
    "start": "1183089",
    "end": "1188129"
  },
  {
    "text": "So this is great. Um, it's cool and whatever, and we're doing\nthings in a provider agnostic way, which is cool.",
    "start": "1189929",
    "end": "1195299"
  },
  {
    "text": "Um, but. Model responses can be really long, um, and often\ntimes we don't want to wait for the whole thing to",
    "start": "1195570",
    "end": "1202140"
  },
  {
    "text": "come back before we do something with it, right? So what about streaming? How do we actually do this?",
    "start": "1202140",
    "end": "1206778"
  },
  {
    "text": "Well, this is the program we had before,\nand this is the same program with streaming.",
    "start": "1208969",
    "end": "1214570"
  },
  {
    "text": "So most, for the most part, you change out\ncreate for stream and effect for stream. And now you have a fully streaming version of this program.",
    "start": "1215449",
    "end": "1222710"
  },
  {
    "text": "Um, same number of lines of code, uh, and it becomes really\neasy if requirements change in your company to swap out",
    "start": "1223900",
    "end": "1230570"
  },
  {
    "text": "the behavior of the program, um, without having to sort of\nrethink the entire API design that you were coming up with.",
    "start": "1230570",
    "end": "1236748"
  },
  {
    "text": "Um, and I just want to point out, I don't know if\nthis is going to work on the screen, let's see.",
    "start": "1240530",
    "end": "1246170"
  },
  {
    "text": "So, I don't know if you folks can see it up there, um,\nbut in the environment of the effect, you'll see that",
    "start": "1249465",
    "end": "1254755"
  },
  {
    "text": "the completion service that we're using to interact\nwith the model, um, is now a requirement of the program.",
    "start": "1254845",
    "end": "1260515"
  },
  {
    "text": "So, at some point when we're done, we need to\nactually plug in the model we're going to call.",
    "start": "1260625",
    "end": "1264655"
  },
  {
    "text": "So, let's see a little bit of an example of that. Um, so, at the moment, we only have an open AI integration\npackage, but we're already working on, uh, we're already",
    "start": "1266195",
    "end": "1278153"
  },
  {
    "text": "working on integrations for a number of other providers. Um, and our goal is to have most of the\nfoundation models covered for you guys by default.",
    "start": "1278154",
    "end": "1285589"
  },
  {
    "text": "Um, but here we're creating a client to OpenAI. You can see it's pretty simple. All you really need to bring along is your API key.",
    "start": "1286370",
    "end": "1294010"
  },
  {
    "text": "Um, and what's cool about this is, we'll see this a\nlittle bit later, anything redacted throughout your",
    "start": "1294829",
    "end": "1300449"
  },
  {
    "text": "program automatically gets redacted in your traces. So if somehow some sensitive value ends up in a trace or\na log somewhere, it'll automatically be redacted for you.",
    "start": "1300449",
    "end": "1309110"
  },
  {
    "text": "Um, and then Once we have our client built\nup, we can actually build an interface to the",
    "start": "1311469",
    "end": "1319550"
  },
  {
    "text": "completion service that we want to interact with. So in this case, we're building a completion\nservice that's going to interact with the GPT 4.",
    "start": "1319749",
    "end": "1326219"
  },
  {
    "text": "0 model. But you can imagine that if you have many different\ncompletion models that you want to interact with,",
    "start": "1326219",
    "end": "1332650"
  },
  {
    "text": "all you have to do is just create layers for\nthe different models that you want to work with.",
    "start": "1332929",
    "end": "1337750"
  },
  {
    "text": "And again, the client is pluggable in this scenario as well.",
    "start": "1338895",
    "end": "1341735"
  },
  {
    "text": "So, um, I just wanted to show a quick example\nof how we actually plug in the client.",
    "start": "1343945",
    "end": "1349835"
  },
  {
    "text": "So this is. The same code that we wrote before,\nbut just sort of paired down.",
    "start": "1350345",
    "end": "1354535"
  },
  {
    "text": "Um, we're still operating on the\nprovider with our agnostic API.",
    "start": "1355725",
    "end": "1362075"
  },
  {
    "text": "But you can see now we're actually plugging in our\ncompletions that we created in the step before.",
    "start": "1363150",
    "end": "1368480"
  },
  {
    "text": "And another thing I wanted to point out, we were\na little bit thoughtful about the cases where you folks might want to provide, provide provider\nspecific configuration, per provider configuration.",
    "start": "1369600",
    "end": "1382400"
  },
  {
    "text": "However you want to say that, too many provides. So that if you, if you are using a particular provider in\nyour program, those configuration values would be applied.",
    "start": "1383619",
    "end": "1393778"
  },
  {
    "text": "for that. Otherwise, they won't be, right? So, you can imagine if you want to have a piece\nof code, again, that's totally agnostic, you",
    "start": "1393780",
    "end": "1400804"
  },
  {
    "text": "can just keep providing configs, and when that\nprovider's in use, those configs would be applied.",
    "start": "1400804",
    "end": "1405625"
  },
  {
    "text": "So, I don't know how to do this in a\nway that's ergonomic, but a quick demo.",
    "start": "1408044",
    "end": "1415844"
  },
  {
    "text": "Okay. This is a slightly expanded example of what\nwe went through, um, before, but essentially,",
    "start": "1418114",
    "end": "1425985"
  },
  {
    "text": "uh, I'm just prompting, uh, the model to\nrewrite this piece of code, uh, with effect.",
    "start": "1428195",
    "end": "1434384"
  },
  {
    "text": "I will say in my tests, uh, our model must\nhave, uh, been trained on a very old version",
    "start": "1434884",
    "end": "1440665"
  },
  {
    "text": "of effect, but we can still see what happens.",
    "start": "1440675",
    "end": "1442585"
  },
  {
    "text": "And this is the streaming version, by the way. So you can see, we wrote a completely provider agnostic\nprogram, we plugged in the provider at the end.",
    "start": "1449865",
    "end": "1459935"
  },
  {
    "text": "Fully streaming, no problems, all effect native. And then I, I think that,",
    "start": "1460360",
    "end": "1465210"
  },
  {
    "text": "I'm not necessarily the best\nhype man, so thank you, Johannes. Um, and then I also wanted to give a\nquick showcase on the observability piece.",
    "start": "1470800",
    "end": "1480219"
  },
  {
    "text": "Because, again, I, I think that the, the way\nwe combat non determinism in these systems is",
    "start": "1480240",
    "end": "1486850"
  },
  {
    "text": "by making observability a first class citizen. Because the only way that you can actually\nhandle non determinism is with observability.",
    "start": "1486850",
    "end": "1493709"
  },
  {
    "text": "Um, so. Where did my mouse go? Okay,",
    "start": "1494810",
    "end": "1499090"
  },
  {
    "text": "this is interesting. Um, okay.",
    "start": "1500709",
    "end": "1506709"
  },
  {
    "text": "I also wanted to give a little bit of an\nexample of observability and how we handle that. So the AI integration packages, we're\nalready dogfooding them in production.",
    "start": "1507870",
    "end": "1517229"
  },
  {
    "text": "Um, I don't know how many of you\nfolks are a member of our Discord. Okay, whoever's not should join.",
    "start": "1517909",
    "end": "1524580"
  },
  {
    "text": "It's a great community. But, um, Uh, we wanted to keep Discord relatively clean.",
    "start": "1524669",
    "end": "1531960"
  },
  {
    "text": "We get a lot of questions, and we wanted to\nkeep it, uh, our channels from growing too",
    "start": "1531960",
    "end": "1537360"
  },
  {
    "text": "exponentially when a question's answer ran too fast. You know, 60 70 80 100 responses long.",
    "start": "1537360",
    "end": "1544055"
  },
  {
    "text": "So we decided to implement a bot\nthat would do auto threading for us. Um, but we also wanted to have a descriptive title\nfor those threads so that we could track, like, the",
    "start": "1544705",
    "end": "1555104"
  },
  {
    "text": "threads that we were a part of, and make sure that,\nlike, we're trying to respond as quickly as we can. You know, track which threads were a part\nof what we were doing in that thread, etc.",
    "start": "1555104",
    "end": "1563220"
  },
  {
    "text": "So we decided to connect our Discord bot with an LLM to\nhelp generate an appropriate title based on the message.",
    "start": "1563980",
    "end": "1570330"
  },
  {
    "text": "There's a couple of other AI features in\nthe bot, uh, like generating issues for us based on the summary of the thread, etc.",
    "start": "1570610",
    "end": "1577059"
  },
  {
    "text": "Um, but what I want to show off today is how\nwe use our Discord bot to generate titles for",
    "start": "1577575",
    "end": "1583664"
  },
  {
    "text": "these threads, and how we can observe that, um,\nby wiring that up to a tracing, uh, exporter.",
    "start": "1583665",
    "end": "1589575"
  },
  {
    "text": "So, hang on, bear with me.",
    "start": "1590454",
    "end": "1593885"
  },
  {
    "text": "Okay, so here is the code,",
    "start": "1598225",
    "end": "1602535"
  },
  {
    "text": "there we go. Um, this is the method that we have in our, like,\nAIUtils service in the Discord bot, which is used",
    "start": "1605224",
    "end": "1613475"
  },
  {
    "text": "to actually generate a title for these threads. Um, you can see again, this is basically\nthe same code that we were using before.",
    "start": "1613485",
    "end": "1620239"
  },
  {
    "text": "Um, and it's not too complex, pretty easy to reason about. Um, and as you can see, we're using open AI.",
    "start": "1620750",
    "end": "1626690"
  },
  {
    "text": "Um, and then the usage,",
    "start": "1627440",
    "end": "1629498"
  },
  {
    "text": "the actual usage here. Um, you can see we're logging errors when we need to.",
    "start": "1633960",
    "end": "1639640"
  },
  {
    "text": "Uh, we have a retry policy enabled. We only have specific scenarios where we\nactually want to retry these interactions.",
    "start": "1639969",
    "end": "1645809"
  },
  {
    "text": "Um, but I want to draw your attention to. This right here, this width span right here,\nand also the one that we were looking at before.",
    "start": "1645810",
    "end": "1656715"
  },
  {
    "text": "So we trace everything that happens in our\nDiscord bot, and because we do this, because",
    "start": "1658024",
    "end": "1664175"
  },
  {
    "text": "we just provide those width spans, we get,",
    "start": "1664175",
    "end": "1667804"
  },
  {
    "text": "hold please, traces generated for us, uh, in, uh,\nwe use Honeycomb for tracing, but the point being",
    "start": "1671945",
    "end": "1680894"
  },
  {
    "text": "here is that up until this point, The generated\ntitle span, we were annotating those traces.",
    "start": "1680895",
    "end": "1687870"
  },
  {
    "text": "Everything else that happens here\nwas generated for us automatically. So, these 2 spans were automatically added\nby our tracing our client integration.",
    "start": "1687890",
    "end": "1698140"
  },
  {
    "text": "And we have a whole bunch of information, but\nwhat actually went on during that request, all",
    "start": "1698520",
    "end": "1703240"
  },
  {
    "text": "the request headers, all the response headers. Attributes that we pass in, and this is all\ndone automatically for you if you're using.",
    "start": "1703600",
    "end": "1709880"
  },
  {
    "text": "Uh, the client integration, the provider integrations.",
    "start": "1710320",
    "end": "1713320"
  },
  {
    "text": "So yeah, not to quote Tim Smart,\nbut you get all of this for free.",
    "start": "1716100",
    "end": "1719900"
  },
  {
    "text": "Okay. We're arriving at the end. So, uh, where do we actually go from here?",
    "start": "1728410",
    "end": "1733680"
  },
  {
    "text": "Yes, we, the effect team, are going to continue to do\nour best to add additional, uh, APIs to the AI packages.",
    "start": "1735225",
    "end": "1745635"
  },
  {
    "text": "We want to integrate with more providers. We want to give you the ability to do things\nlike interact with OpenAI's new real time API.",
    "start": "1746235",
    "end": "1752554"
  },
  {
    "text": "We want to provide all of those things, um, through our\nAI integration, so we're working really hard on that.",
    "start": "1752565",
    "end": "1757924"
  },
  {
    "text": "Um, but where's the future really taking us here? Hopefully. I've convinced you all by this point that effect\nis the perfect fit for developing agentic systems.",
    "start": "1758775",
    "end": "1770160"
  },
  {
    "text": "But how are we actually going\nto deploy and run these agents? These are, especially in the world of autonomous\nsystems, where I think that that's where we're going.",
    "start": "1771290",
    "end": "1780800"
  },
  {
    "text": "These autonomous agents may be long\nrunning processes that might live forever.",
    "start": "1781759",
    "end": "1785540"
  },
  {
    "text": "So, how are we actually going to run these systems? Well, I'm really excited about what we're working on.",
    "start": "1786980",
    "end": "1794179"
  },
  {
    "text": "Unfortunately, there's not enough time\nfor me today to talk to you all about it. Uh, but stay tuned.",
    "start": "1794909",
    "end": "1799870"
  },
  {
    "text": "We're working very hard in this direction,\nand I hope that, uh, the next time I talk to",
    "start": "1800070",
    "end": "1805130"
  },
  {
    "text": "you all, I'll be able to share a lot more. Um, so thank you all for your attention. I really appreciate it.",
    "start": "1805130",
    "end": "1809670"
  }
]
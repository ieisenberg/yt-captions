[
  {
    "start": "0",
    "end": "132000"
  },
  {
    "text": "(audience applauds)",
    "start": "0",
    "end": "3333"
  },
  {
    "text": "Like the hat? So that hat has a long story, and I remove it.",
    "start": "6583",
    "end": "14208"
  },
  {
    "text": "I'll not be able to give the talk otherwise. So the hat comes from a dear friend, a community member",
    "start": "16750",
    "end": "24458"
  },
  {
    "text": "for a while, co-organizer of this event, which is Sebastian Lorenz.",
    "start": "24458",
    "end": "28500"
  },
  {
    "text": "But maybe first I should introduce myself. I'm Michael Arnaldi. I'm the original author of \"Effect\"",
    "start": "29500",
    "end": "35041"
  },
  {
    "text": "That's clearly not me. That's what I refer to as the Backstreet Boys version",
    "start": "36416",
    "end": "42500"
  },
  {
    "text": "of Sebastian Lorenz. That's the only reason I have this slide, by the way.",
    "start": "42500",
    "end": "47375"
  },
  {
    "text": "I had to wear the hat and kind of make fun of myself. I was like, now everybody's going to make fun of him.",
    "start": "48166",
    "end": "55458"
  },
  {
    "text": "(audience laughs) So to begin this talk, I first want",
    "start": "55500",
    "end": "63583"
  },
  {
    "text": "to say thank you to everyone, starting to thank the organizers, the other speakers, the attendees,",
    "start": "63708",
    "end": "72583"
  },
  {
    "text": "no attendees, equal, no conference. The venue managers, they've been amazing.",
    "start": "73208",
    "end": "78791"
  },
  {
    "text": "This venue is truly exceptional. Catering, I've enjoyed eating so much.",
    "start": "79750",
    "end": "86458"
  },
  {
    "text": "The sponsors, yes, of course, and everyone else.",
    "start": "87791",
    "end": "92416"
  },
  {
    "text": "Funny that we also sponsored the conference, and I forgot to thank you the sponsors. But really, thank you a lot.",
    "start": "93416",
    "end": "100250"
  },
  {
    "text": "(audience applauds)",
    "start": "101916",
    "end": "102708"
  },
  {
    "text": "As I said before, that's the second version of \"Effect Days\"",
    "start": "112041",
    "end": "117500"
  },
  {
    "text": "And a year went by. It flew over.",
    "start": "118291",
    "end": "123958"
  },
  {
    "text": "We've got new team members that today have been officially announced that are welcome to join officially.",
    "start": "124500",
    "end": "129582"
  },
  {
    "text": "And last year, it was about \"Effect\"",
    "start": "130416",
    "end": "136875"
  },
  {
    "start": "132000",
    "end": "288000"
  },
  {
    "text": "being close to production readiness. It was used in production already for a while,",
    "start": "136875",
    "end": "143040"
  },
  {
    "text": "but we had the very first stable version of \"Effect\" to bring to the wider TypeScript ecosystem.",
    "start": "143541",
    "end": "151791"
  },
  {
    "text": "And as Johannes said this morning, the metrics since then have improved a lot.",
    "start": "152750",
    "end": "159665"
  },
  {
    "text": "And \"Effect\" has been used for many more use cases,",
    "start": "160083",
    "end": "164500"
  },
  {
    "text": "a lot of brilliant production grade usage from both small and large companies.",
    "start": "165833",
    "end": "172041"
  },
  {
    "text": "Today, we've got a lot of talks about how \"Effect\" is currently used in some critical systems.",
    "start": "172916",
    "end": "180875"
  },
  {
    "text": "And one of the things I'm most proud of is that in pretty much any of the talk",
    "start": "182000",
    "end": "187208"
  },
  {
    "text": "about using \"Effect\" in production, you could see a similar picture about an open telemetry",
    "start": "188083",
    "end": "195500"
  },
  {
    "text": "set of spans. That means \"Effect\" really gives the power to those people to observe what's going on in",
    "start": "197166",
    "end": "203208"
  },
  {
    "text": "those production grade systems to improve, and so on and so forth. So where are we today?",
    "start": "203208",
    "end": "208875"
  },
  {
    "text": "Today, we are close to make stable what I would call",
    "start": "209916",
    "end": "214833"
  },
  {
    "text": "the Layer one level of the ecosystem. That means platform CLI, SQL, RPC, and so on and so forth.",
    "start": "214958",
    "end": "224458"
  },
  {
    "text": "They are more and more ready for prime time and ready for production usage.",
    "start": "224458",
    "end": "229708"
  },
  {
    "text": "And we've got amazing talks from Maxwell and Tim this morning about what's coming next at the ecosystem level",
    "start": "230375",
    "end": "238250"
  },
  {
    "text": "with the AI packages that are in alpha now and with the cluster package that has reached alpha, which",
    "start": "238375",
    "end": "247041"
  },
  {
    "text": "again, to quote Ethan Niser, that means it's stable enough to be deployed in all production grade",
    "start": "247166",
    "end": "254208"
  },
  {
    "text": "and critical systems. Of course, bug free as much as possible.",
    "start": "254208",
    "end": "260333"
  },
  {
    "text": "But really, what my talk is about has nothing to do with this and has",
    "start": "261708",
    "end": "269583"
  },
  {
    "text": "more to do with what we've learned from the community and from those production grade users during the last year",
    "start": "269750",
    "end": "278375"
  },
  {
    "text": "and how we are trying to incorporate the feedback into what's coming next.",
    "start": "279000",
    "end": "283207"
  },
  {
    "text": "So what is next? Well, today I'm going to talk about Effect 4.0,",
    "start": "285208",
    "end": "293000"
  },
  {
    "start": "288000",
    "end": "390000"
  },
  {
    "text": "codename \"smol\" Come on.",
    "start": "293875",
    "end": "298416"
  },
  {
    "text": "(audience applauds)",
    "start": "299750",
    "end": "301041"
  },
  {
    "text": "So to be clear, we are nowhere near ready to release Effect 4.0. This is a talk about the",
    "start": "305708",
    "end": "312416"
  },
  {
    "text": "current state, what we've been doing, and what's still left to be done.",
    "start": "312416",
    "end": "318083"
  },
  {
    "text": "And I'm going to be honest, some of the things you're going to see today, they might not end up being implemented at the end.",
    "start": "319333",
    "end": "326291"
  },
  {
    "text": "Or we might have more features than what we show today. But I wanted to show where our thinking goes.",
    "start": "327333",
    "end": "336166"
  },
  {
    "text": "So straight after this talk, I'm going to open access to the repository, which",
    "start": "338666",
    "end": "345375"
  },
  {
    "text": "is called Effect SMOL. And you can try it. It's not going to be published.",
    "start": "345375",
    "end": "350166"
  },
  {
    "text": "So just to avoid people like Patrick Roser to use it in production, we avoid publishing it.",
    "start": "350958",
    "end": "357625"
  },
  {
    "text": "So at least you have to run the code locally, build it by your own. And if you want to destroy your systems, go ahead, please.",
    "start": "358458",
    "end": "365125"
  },
  {
    "text": "So the first thing that we've heard from the wider TypeScript community is, Effect is big.",
    "start": "368500",
    "end": "376375"
  },
  {
    "text": "And it's big, especially in use cases where bundle size matters, like front end.",
    "start": "377333",
    "end": "382916"
  },
  {
    "text": "For this reason, we had to create a specialized module, which is called Micro in the current version of Effect.",
    "start": "383833",
    "end": "390333"
  },
  {
    "start": "390000",
    "end": "524000"
  },
  {
    "text": "But after having created Micro and having done the research on Micro, I'm famous to always ask why.",
    "start": "392250",
    "end": "399458"
  },
  {
    "text": "And I started asking to my team, why does Effect",
    "start": "400416",
    "end": "406791"
  },
  {
    "text": "need to exist and Micro needs to exist? Isn't that enough to get the baseline of Micro",
    "start": "406791",
    "end": "413958"
  },
  {
    "text": "and extend from there? Can we make Effect as small as Micro?",
    "start": "414375",
    "end": "418500"
  },
  {
    "text": "And I'm happy to say that, of course, I have to learn how to use a laptop.",
    "start": "420083",
    "end": "426041"
  },
  {
    "text": "But I have to increase font size probably.",
    "start": "427333",
    "end": "432791"
  },
  {
    "text": "This is building up a few examples that are also built in every one of our PRs.",
    "start": "440375",
    "end": "446375"
  },
  {
    "text": "So we're keeping track of the bundle size growth",
    "start": "446375",
    "end": "451708"
  },
  {
    "text": "and basic usage of Effect, which includes the runtime.",
    "start": "452500",
    "end": "458958"
  },
  {
    "text": "It's a very simple program just to test out the basics. This is about 5.4 kilowatts, which",
    "start": "459250",
    "end": "466000"
  },
  {
    "text": "is less than the current size of Micro. And this is feature complete.",
    "start": "466125",
    "end": "471083"
  },
  {
    "text": "That means Effect is now much more tree-shakeable",
    "start": "472000",
    "end": "479166"
  },
  {
    "text": "than it was before. And as we add features, such as, for example,",
    "start": "479166",
    "end": "485000"
  },
  {
    "text": "batching and so on and so forth, loggers, you see that the bundle size increases.",
    "start": "485291",
    "end": "491458"
  },
  {
    "text": "But even a very feature complete usage, such as schema,",
    "start": "492333",
    "end": "498125"
  },
  {
    "text": "is now around 17k. It used to be more than 50kb.",
    "start": "499500",
    "end": "504208"
  },
  {
    "text": "So that's a huge improvement in bundle size.",
    "start": "504916",
    "end": "509707"
  },
  {
    "text": "Well, that's why the codename \"smol\"",
    "start": "510083",
    "end": "512666"
  },
  {
    "start": "524000",
    "end": "652000"
  },
  {
    "text": "One of the other questions that we asked ourselves is related to the current runtime.",
    "start": "525166",
    "end": "532750"
  },
  {
    "text": "And our Fiber Reference and Runtime Flags and Context all needed.",
    "start": "533541",
    "end": "538875"
  },
  {
    "text": "Or can we get away with just context? Because if we can get away with just Context,",
    "start": "539916",
    "end": "545583"
  },
  {
    "text": "we are going to, one, improve bundle size, because there's less madness going on.",
    "start": "546333",
    "end": "552083"
  },
  {
    "text": "And point two, we don't have to clone objects once we forked new Fibers.",
    "start": "552583",
    "end": "559000"
  },
  {
    "text": "We can just reuse the same context object, given that it is immutable. And that should be a huge speed up.",
    "start": "559000",
    "end": "565416"
  },
  {
    "text": "Well, the answer is yes. We definitely can. And in the new version of Effect,",
    "start": "566583",
    "end": "576458"
  },
  {
    "text": "you will not have Fiber references. You will have context references.",
    "start": "577166",
    "end": "582833"
  },
  {
    "text": "Context references are just services with a default.",
    "start": "583583",
    "end": "587708"
  },
  {
    "text": "So you can use a context reference without the context being affected",
    "start": "588958",
    "end": "595666"
  },
  {
    "text": "with the type of the service. And they have a default. And the defaults are cached globally.",
    "start": "596250",
    "end": "601208"
  },
  {
    "text": "So if they are initialized at any point in the lifetime of your program, they're",
    "start": "601916",
    "end": "606958"
  },
  {
    "text": "never going to be initialized twice. But you can override that. And to prove the point, I've built a small program that",
    "start": "606958",
    "end": "614500"
  },
  {
    "text": "uses-- I thought a future flag would be a good way of demoing this.",
    "start": "614500",
    "end": "620375"
  },
  {
    "text": "And here, obviously, we can see that the program runs first with the default, with the future flag disabled.",
    "start": "629750",
    "end": "636083"
  },
  {
    "text": "Then we locally provide the service. And it becomes enabled.",
    "start": "636625",
    "end": "642000"
  },
  {
    "start": "652000",
    "end": "796000"
  },
  {
    "text": "Then another thing that has hurt many users in the worst possible way has been subtyping.",
    "start": "652333",
    "end": "660208"
  },
  {
    "text": "And this is something we went back and forth a little bit.",
    "start": "661250",
    "end": "665916"
  },
  {
    "text": "But while building Effect, we thought, what a great idea would be to make option a subtype of Effect, to make either a subtype of Effect,",
    "start": "666291",
    "end": "674625"
  },
  {
    "text": "to make everything a subtype of Effect, which means you can yield them in a generator.",
    "start": "674625",
    "end": "680416"
  },
  {
    "text": "And you can use them just like you would use normal Effects. But this feature paired with flattening,",
    "start": "680416",
    "end": "686416"
  },
  {
    "text": "so functions like and then, for example, where you can pass both a function that returns an Effect",
    "start": "686833",
    "end": "693541"
  },
  {
    "text": "or that returns a normal value, you'd get surprising behavior because that would auto flatten, for example, a reference.",
    "start": "693541",
    "end": "700791"
  },
  {
    "text": "And you would get the value instead of the reference. So in 4.0, we are testing with the concept of yieldability",
    "start": "701041",
    "end": "710000"
  },
  {
    "text": "instead of subtyping, which means stuff like options are not directly Effects, but are convertible into Effects.",
    "start": "710125",
    "end": "718625"
  },
  {
    "text": "And you can still use them normally inside a generator. Let me see this.",
    "start": "719000",
    "end": "723541"
  },
  {
    "text": "So here, I have a program. And you can see in this program,",
    "start": "728666",
    "end": "733500"
  },
  {
    "text": "I'm doing the same type of code that I would write today. I'm yielding Effect.write.",
    "start": "733791",
    "end": "739625"
  },
  {
    "text": "I'm yielding Effect.sum. These returns Effect void.",
    "start": "739625",
    "end": "745583"
  },
  {
    "text": "Of course, I'm not actually returning anything. But then you have the no such element error,",
    "start": "745583",
    "end": "751291"
  },
  {
    "text": "which is coming from the option. But those are not directly Effects anymore.",
    "start": "751291",
    "end": "757541"
  },
  {
    "text": "And in fact, if I do this, I'll get a type error. So to use them outside of a generator,",
    "start": "758000",
    "end": "765791"
  },
  {
    "text": "you'll have to say as Effect, and they become normal Effects.",
    "start": "766708",
    "end": "771250"
  },
  {
    "text": "This helps preventing conflict together with auto flattening while still allowing you to",
    "start": "772041",
    "end": "778041"
  },
  {
    "text": "use them as normal values inside a generator, which we think is the right balance between ease",
    "start": "778041",
    "end": "786250"
  },
  {
    "text": "of usage and safety.",
    "start": "786375",
    "end": "788000"
  },
  {
    "start": "796000",
    "end": "1016000"
  },
  {
    "text": "In current version, we have far too many queues.",
    "start": "796708",
    "end": "799500"
  },
  {
    "text": "And that's something that has been going on over time.",
    "start": "802375",
    "end": "807625"
  },
  {
    "text": "We figure new stuff. We don't want to break old stuff. And we add stuff. And that means we currently have 500 different ways",
    "start": "807833",
    "end": "814125"
  },
  {
    "text": "of doing the same thing. At the beginning, queue was directly ported from Zio.",
    "start": "814250",
    "end": "819583"
  },
  {
    "text": "And there's a little bit of over-engineering behind the scenes. And in the lifetime of 3.0, we've",
    "start": "820208",
    "end": "827000"
  },
  {
    "text": "extended queue with a different module, which is called mailbox.",
    "start": "827625",
    "end": "831416"
  },
  {
    "text": "And that module also-- it's like a queue with two parameters. You can also raise an error.",
    "start": "832750",
    "end": "838458"
  },
  {
    "text": "It's more feature complete. For example, when you derive a stream out of a queue,",
    "start": "839250",
    "end": "845250"
  },
  {
    "text": "you would usually derive a stream from a queue of exit values. There's really no way of finalizing a queue,",
    "start": "845583",
    "end": "852958"
  },
  {
    "text": "pushing a final element to a queue, and doing stuff like that. And it's all in mailbox.",
    "start": "853625",
    "end": "858458"
  },
  {
    "text": "A mailbox also turns out to be much more performant. And it's internally built",
    "start": "859291",
    "end": "864791"
  },
  {
    "text": "using plain JS data structures that are way more performant at what we could ever achieve with custom data structures that",
    "start": "864791",
    "end": "872166"
  },
  {
    "text": "are currently used in queue. So the new queue is just mailbox, with removing the 500 ways of doing the same thing.",
    "start": "872750",
    "end": "880958"
  },
  {
    "text": "And I'm going to demonstrate how new queues look like.",
    "start": "881375",
    "end": "885458"
  },
  {
    "text": "As you can see, you can create a normal unbounded queue. You can omit the second argument.",
    "start": "894416",
    "end": "899291"
  },
  {
    "text": "And you just get the plain old queue of a number. But the second parameter is never.",
    "start": "900166",
    "end": "906000"
  },
  {
    "text": "If I specify the second parameter, it becomes the second parameter of the queue, which is the potential error type",
    "start": "907500",
    "end": "913541"
  },
  {
    "text": "that you can push into the queue. It can offer elements just normally.",
    "start": "913750",
    "end": "918833"
  },
  {
    "text": "But then you can say that the queue is done, or just end the queue.",
    "start": "919500",
    "end": "923958"
  },
  {
    "text": "You can be done with a failure, or you can be done with an interrupt. You can be done with any element.",
    "start": "924916",
    "end": "931500"
  },
  {
    "text": "If you're done with a void, the queue is declared as ended.",
    "start": "931750",
    "end": "936166"
  },
  {
    "text": "And when you pull from the queue, so when you take elements, you've got the choice of defining what behavior you",
    "start": "937000",
    "end": "944083"
  },
  {
    "text": "really want. Just to prove this is supposed to be working.",
    "start": "944833",
    "end": "950958"
  },
  {
    "text": "And it does. And I think I even have a benchmark somewhere.",
    "start": "953833",
    "end": "960666"
  },
  {
    "text": "Let me check. I've-- yeah, it's still called mailbox, you see.",
    "start": "961250",
    "end": "968333"
  },
  {
    "text": "So I just want to run this benchmark to let you see the performance.",
    "start": "971000",
    "end": "975291"
  },
  {
    "text": "So here we are pushing a million of elements into the queue. And then we're taking the million of elements from the queue.",
    "start": "976333",
    "end": "983375"
  },
  {
    "text": "And we're repeating this.",
    "start": "983458",
    "end": "984916"
  },
  {
    "text": "In average, we take 32 milliseconds to push a million elements into the queue, and 85, around 80,",
    "start": "990458",
    "end": "996541"
  },
  {
    "text": "to take a million elements out of the queue. With the old implementation, this would have taken probably a second, more or less.",
    "start": "996541",
    "end": "1005125"
  },
  {
    "text": "That means things can get faster.",
    "start": "1007000",
    "end": "1010208"
  },
  {
    "start": "1016000",
    "end": "1302000"
  },
  {
    "text": "We've re-encoded everything. Quite literally, I don't think there is even a single data",
    "start": "1017208",
    "end": "1024416"
  },
  {
    "text": "type that we haven't rebuilt from scratch. That means Fiber is tiny, schedule is tiny,",
    "start": "1024500",
    "end": "1031708"
  },
  {
    "text": "Layer is tiny, a lot more performant than it used to be.",
    "start": "1032541",
    "end": "1037500"
  },
  {
    "text": "So you'll be able to provide Layers locally without any concern for performance or bundle overhead.",
    "start": "1038041",
    "end": "1045083"
  },
  {
    "text": "They add less than a kilobyte to the final bundle size. Channel, which is the underpinning module",
    "start": "1045958",
    "end": "1054708"
  },
  {
    "text": "that stream is based on, is being completely re-encoded. And channel is also very lightweight.",
    "start": "1055375",
    "end": "1063291"
  },
  {
    "text": "And by consequence, stream is also very lightweight.",
    "start": "1064166",
    "end": "1067208"
  },
  {
    "text": "How did we do that? Most of those types were implemented using a technique which is called",
    "start": "1070333",
    "end": "1076708"
  },
  {
    "text": "executable encoding, or initial encoding, which is declarative encoding.",
    "start": "1077208",
    "end": "1082333"
  },
  {
    "text": "And that means we would have a series of fixed operations and build everything else on top of those set of fixed",
    "start": "1083291",
    "end": "1090250"
  },
  {
    "text": "operations, and then have a runtime that ends up interpreting those operations. Now, all of those are built straight up",
    "start": "1090375",
    "end": "1098083"
  },
  {
    "text": "on top of Effect with an executable encoding, or also known as final encoding, which is supposed",
    "start": "1098208",
    "end": "1105833"
  },
  {
    "text": "to be way more performant and way more lightweight.",
    "start": "1105833",
    "end": "1110625"
  },
  {
    "text": "And let me show you what I mean by slightly more performant.",
    "start": "1111750",
    "end": "1115750"
  },
  {
    "text": "I have here an example. And I'm producing a stream of 100,000 elements.",
    "start": "1118333",
    "end": "1124375"
  },
  {
    "text": "And I'm mapping Effect fully over the stream with a concurrency of 10.",
    "start": "1125166",
    "end": "1130625"
  },
  {
    "text": "That means I'm going to have 10 concurrently running Fibers that process each element independently.",
    "start": "1132125",
    "end": "1137833"
  },
  {
    "text": "So currently, this takes about 170 milliseconds.",
    "start": "1139833",
    "end": "1149541"
  },
  {
    "text": "But now, a little surprise.",
    "start": "1150958",
    "end": "1152125"
  },
  {
    "text": "You can, by the way, see API compatibility. Now, I'm just using old Effect. So migrating to this new version will hopefully not",
    "start": "1157541",
    "end": "1165166"
  },
  {
    "text": "be such a big effort in consumer code.",
    "start": "1165333",
    "end": "1170791"
  },
  {
    "text": "I want to ask you a question. How much do you think this program will take using",
    "start": "1172500",
    "end": "1178958"
  },
  {
    "text": "the old Effect version?",
    "start": "1178958",
    "end": "1180333"
  },
  {
    "text": "[INAUDIBLE] (audience laughs) [INAUDIBLE]",
    "start": "1185166",
    "end": "1191750"
  },
  {
    "text": "An hour and a half. I don't know. (audience laughs)",
    "start": "1191750",
    "end": "1196041"
  },
  {
    "text": "That's 3.2 seconds. That's about-- (audience applauds)",
    "start": "1201916",
    "end": "1207000"
  },
  {
    "text": "[INAUDIBLE] (audience applauds)",
    "start": "1207000",
    "end": "1213041"
  },
  {
    "text": "That's about 20x per four-- [INAUDIBLE] Bun.",
    "start": "1214833",
    "end": "1220041"
  },
  {
    "text": "No, I'm not going to run these on Bun. Sorry, Jared.",
    "start": "1220041",
    "end": "1223041"
  },
  {
    "text": "I want to say something. We're not cheating. We have not rewrote the internal so Effecting goal.",
    "start": "1227625",
    "end": "1233208"
  },
  {
    "text": "So that's a 20-- 20x improvement just on top of TypeScript.",
    "start": "1233833",
    "end": "1240625"
  },
  {
    "text": "We just used a small tool which is called Tim Smart to optimize",
    "start": "1241416",
    "end": "1246416"
  },
  {
    "text": "this. (audience applauds)",
    "start": "1247583",
    "end": "1255541"
  },
  {
    "text": "And-- and-- and maybe if I found it.",
    "start": "1256708",
    "end": "1263208"
  },
  {
    "text": "Yes, stream here. Let me actually open.",
    "start": "1263208",
    "end": "1268500"
  },
  {
    "text": "Let me take just my last PR, for example, where we run all the tests.",
    "start": "1276250",
    "end": "1281791"
  },
  {
    "text": "Stream is 6.6 kilobytes, three-shaped.",
    "start": "1283708",
    "end": "1288041"
  },
  {
    "text": "So not only is 20x faster, it's around 20x smaller too.",
    "start": "1289416",
    "end": "1293916"
  },
  {
    "text": "(audience applauds)",
    "start": "1296000",
    "end": "1300125"
  },
  {
    "start": "1302000",
    "end": "1605000"
  },
  {
    "text": "In the lifetime of 3.0, we thought the use case of batching queries would be so important",
    "start": "1303208",
    "end": "1309500"
  },
  {
    "text": "that we decided to support this in core. But we took the ideas from--",
    "start": "1310416",
    "end": "1316625"
  },
  {
    "text": "from ZO query, and I've hacked those ideas into the Effect",
    "start": "1317041",
    "end": "1322916"
  },
  {
    "text": "Fiber. The reality is that the model of concurrency and the model of batching kind of",
    "start": "1322958",
    "end": "1330500"
  },
  {
    "text": "were fighting between each other, which is why you have--",
    "start": "1330500",
    "end": "1334625"
  },
  {
    "text": "when you do with concurrency or you do for each and so on and so forth, you have two options to enable.",
    "start": "1335750",
    "end": "1341750"
  },
  {
    "text": "You have concurrency to enable, and you have to-- you have batching to enable. You can batch without concurrency.",
    "start": "1341750",
    "end": "1347416"
  },
  {
    "text": "You can do concurrency without batching. And the reason really is one, batching",
    "start": "1347416",
    "end": "1355833"
  },
  {
    "text": "was implemented in this odd way, where basically it would violate the lifetime of a Fiber.",
    "start": "1355833",
    "end": "1362041"
  },
  {
    "text": "It would stop an Effect from execution. It would save the state, batch the requests,",
    "start": "1362541",
    "end": "1370625"
  },
  {
    "text": "and then restart the Effect in a different Fiber than the original one.",
    "start": "1370625",
    "end": "1375750"
  },
  {
    "text": "So you could do batching with no concurrency at all. Second reason is Fibers used to be slow,",
    "start": "1376250",
    "end": "1382458"
  },
  {
    "text": "or used to be less freeded than they are currently are.",
    "start": "1383375",
    "end": "1390208"
  },
  {
    "text": "With Effect SMOL, with 4.0, we asked ourselves,",
    "start": "1391333",
    "end": "1396375"
  },
  {
    "text": "can we unify the two things? Can we just have batching made-- be made on top of Fibers?",
    "start": "1396583",
    "end": "1402583"
  },
  {
    "text": "So you would have-- for each without bounded concurrency, you would have all the operations awaiting on the requests to be resolved.",
    "start": "1403333",
    "end": "1412291"
  },
  {
    "text": "Much easier to use patterns like data loaders. You can batch over 500 milliseconds,",
    "start": "1414875",
    "end": "1419500"
  },
  {
    "text": "and all sorts of time-based batching stuff without getting crazy with building custom resolvers.",
    "start": "1419916",
    "end": "1427166"
  },
  {
    "text": "And the answer is yes, absolutely, thanks to the Fibers being faster and smaller,",
    "start": "1428291",
    "end": "1437166"
  },
  {
    "text": "we can 100% do so. And I want to show you a program.",
    "start": "1437458",
    "end": "1445791"
  },
  {
    "text": "So this program batches 100,000 different calls to a get user ID.",
    "start": "1448916",
    "end": "1455000"
  },
  {
    "text": "But if you see now, I can do just something like pipe, and say resolver.set delay Effect.sleep 100 millis.",
    "start": "1455833",
    "end": "1469791"
  },
  {
    "text": "No, Effect.set delay. Why doesn't this-- why am I doing it wrong?",
    "start": "1470375",
    "end": "1475583"
  },
  {
    "text": "[INAUDIBLE]\nDuration.",
    "start": "1478125",
    "end": "1478791"
  },
  {
    "text": "Set delay, it's just a duration, yes. There was a set delay Effect.",
    "start": "1484250",
    "end": "1490958"
  },
  {
    "text": "I'm not out of my mind yet.",
    "start": "1491125",
    "end": "1497208"
  },
  {
    "text": "So yes, you can also do with a direct delay of 100 millis.",
    "start": "1500458",
    "end": "1506500"
  },
  {
    "text": "And this would batch everything that happens within 100 milliseconds, regardless of where",
    "start": "1507583",
    "end": "1513791"
  },
  {
    "text": "it's coming from in your program. That means batching is no longer restricted to occur on a single for each call.",
    "start": "1513791",
    "end": "1520541"
  },
  {
    "text": "Not yet. Not yet. Not yet.",
    "start": "1526875",
    "end": "1541541"
  },
  {
    "text": "Here I'm benchmarking the same program.",
    "start": "1543958",
    "end": "1547250"
  },
  {
    "text": "Keep in mind, this program runs 100,000 Fibers concurrently.",
    "start": "1549916",
    "end": "1554583"
  },
  {
    "text": "I think, in average, it takes-- let's see if I can calculate the average before this ends.",
    "start": "1566166",
    "end": "1571541"
  },
  {
    "text": "I think it's about 140-something, 150 milliseconds. And in 150 milliseconds, we are forking 100,000 Fibers,",
    "start": "1572333",
    "end": "1581083"
  },
  {
    "text": "resolving 100,000 requests, and yielding the response back.",
    "start": "1581333",
    "end": "1585375"
  },
  {
    "text": "Again, the tool of use was Tim Smart",
    "start": "1586500",
    "end": "1589916"
  },
  {
    "text": "(audience applauds)",
    "start": "1591833",
    "end": "1599250"
  },
  {
    "start": "1605000",
    "end": "1826000"
  },
  {
    "text": "This case, the tool of use is me. We've heard this morning from Ethan about the STM module.",
    "start": "1605791",
    "end": "1616083"
  },
  {
    "text": "It's an extremely powerful module, which is absurdly underutilized.",
    "start": "1616833",
    "end": "1622666"
  },
  {
    "text": "The reason it's underutilized is that it's not Effect. And you have to learn a new module.",
    "start": "1623458",
    "end": "1629416"
  },
  {
    "text": "You have to read further documentation. You have to fight with the restrictions of STM,",
    "start": "1629625",
    "end": "1634750"
  },
  {
    "text": "like not being able to run Effects inside STM, and not having functions like log,",
    "start": "1635250",
    "end": "1641500"
  },
  {
    "text": "having a different environment. When you use STM, you never know if you should export your type as an STM or as an Effect.",
    "start": "1643291",
    "end": "1651291"
  },
  {
    "text": "The idea is very simple. The idea for STM-- STM stands for software transactional memory--",
    "start": "1653125",
    "end": "1659625"
  },
  {
    "text": "is basically, you want transactions",
    "start": "1661375",
    "end": "1666666"
  },
  {
    "text": "which can be repeated over and over again until they succeed. And they run optimistically.",
    "start": "1667000",
    "end": "1672791"
  },
  {
    "text": "So those are repeated transactions. They are the equivalent in software than database",
    "start": "1673875",
    "end": "1679791"
  },
  {
    "text": "transactions would be on databases. And we've been able to merge the power of STM",
    "start": "1679875",
    "end": "1689708"
  },
  {
    "text": "inside Effect in the first place. So you will have modules like TxRef,",
    "start": "1690166",
    "end": "1702000"
  },
  {
    "text": "which is a transactional reference. You can just create transactional reference normally.",
    "start": "1702500",
    "end": "1708000"
  },
  {
    "text": "Here we are working a program that every 100 milliseconds",
    "start": "1708625",
    "end": "1713625"
  },
  {
    "text": "updates the value of the TxRef.",
    "start": "1714625",
    "end": "1719500"
  },
  {
    "text": "And here we are declaring an Effect transaction that",
    "start": "1720666",
    "end": "1726916"
  },
  {
    "text": "accesses the STM value, the transactional reference value. If it's less than 10, it logs something",
    "start": "1727000",
    "end": "1733500"
  },
  {
    "text": "using normal Effect.log. And it yields a retry transaction,",
    "start": "1733583",
    "end": "1740375"
  },
  {
    "text": "which will instruct the transaction entity to restart any time any of the access values change.",
    "start": "1740875",
    "end": "1749250"
  },
  {
    "text": "If the value is 10, then we're just logging. Fine, and the transaction is supposed to close.",
    "start": "1750458",
    "end": "1755750"
  },
  {
    "text": "So hopefully, if I run these and I haven't pushed any bug in the last 48 hours, I haven't wrote any code.",
    "start": "1756833",
    "end": "1763333"
  },
  {
    "text": "So it's very hard, but never know. demo got.",
    "start": "1763375",
    "end": "1768291"
  },
  {
    "text": "This runs 10 times, and the 10th time just returns. That means you're going to be able to use STM all over the",
    "start": "1778125",
    "end": "1786791"
  },
  {
    "text": "place to do coordination synchronization between processes and so on and so forth in a much easier and more",
    "start": "1786791",
    "end": "1792958"
  },
  {
    "text": "accessible way. Basically, you have to document a single function and a",
    "start": "1793125",
    "end": "1798750"
  },
  {
    "text": "few set of modules that you can use. And transactional modules, we have transactional reference,",
    "start": "1798750",
    "end": "1805166"
  },
  {
    "text": "we have transactional queues, we have transactional maps, we have transactional chunks, and so on and so forth.",
    "start": "1805458",
    "end": "1811833"
  },
  {
    "start": "1826000",
    "end": "1937000"
  },
  {
    "text": "This is an odd thing that I think many of you expected to",
    "start": "1826958",
    "end": "1834708"
  },
  {
    "text": "work already, which is Unresolved Fibers keeps the process alive.",
    "start": "1834708",
    "end": "1838750"
  },
  {
    "text": "And that means this program, let me ask you, do you know",
    "start": "1839833",
    "end": "1856250"
  },
  {
    "text": "what's the result of this with old?",
    "start": "1857250",
    "end": "1863041"
  },
  {
    "text": "If I run this program, what should I expect?",
    "start": "1864000",
    "end": "1866583"
  },
  {
    "text": "There you go. Nothing. Absolutely nothing.",
    "start": "1878625",
    "end": "1882666"
  },
  {
    "text": "That's counterintuitive. The reason is there's no longer any work to do. There are no handlers pushed in",
    "start": "1883791",
    "end": "1889583"
  },
  {
    "text": "the event loop, and JavaScript thinks everything is done.",
    "start": "1889583",
    "end": "1893791"
  },
  {
    "text": "And I can't tell you how many times I had Johannes pushing screenshots to my DMs with some red arrows and say, what is",
    "start": "1895000",
    "end": "1904333"
  },
  {
    "text": "going on here?",
    "start": "1904333",
    "end": "1905000"
  },
  {
    "text": "We all know that. Now it hangs the process, which also means you have to pay",
    "start": "1910916",
    "end": "1920083"
  },
  {
    "text": "more attention to interrupt, because if you hang some Fibers around, your program is going to keep running.",
    "start": "1920166",
    "end": "1926708"
  },
  {
    "text": "But this is a very, again, detailed element, but I think the current semantic is much",
    "start": "1927375",
    "end": "1933500"
  },
  {
    "text": "better than what it used to be. Less surprises all over the place.",
    "start": "1933500",
    "end": "1938791"
  },
  {
    "start": "1937000",
    "end": "2072000"
  },
  {
    "text": "Here, I've already shown the channel and stream example, but",
    "start": "1942166",
    "end": "1951583"
  },
  {
    "text": "having re-encoded every module, and here, like, Maxwell has done",
    "start": "1952791",
    "end": "1958583"
  },
  {
    "text": "tons of work on schedule. Like, the work has been going on for months and months.",
    "start": "1958750",
    "end": "1964208"
  },
  {
    "text": "Everything is literally as efficient and fast as possible currently.",
    "start": "1965291",
    "end": "1968958"
  },
  {
    "text": "So I don't know if I have any other example for this. I think I was supposed to run the stream program at this",
    "start": "1971000",
    "end": "1980500"
  },
  {
    "text": "point in time. I've done it before, so I won't bother you again with this.",
    "start": "1980500",
    "end": "1985125"
  },
  {
    "text": "But maybe let me show the schedule re-encoding that again",
    "start": "1986750",
    "end": "1992916"
  },
  {
    "text": "was supposed to show later. But here we have schedule with Cron.",
    "start": "1993000",
    "end": "2000333"
  },
  {
    "text": "Cron is an amazing addition, almost useless. But Sebastian has spent a lot of time on it.",
    "start": "2000875",
    "end": "2008583"
  },
  {
    "text": "And he was very, very insistent on having me tell you that now",
    "start": "2008833",
    "end": "2015541"
  },
  {
    "text": "Cron supports time zones, too.",
    "start": "2015666",
    "end": "2019000"
  },
  {
    "text": "(audience applauds)",
    "start": "2023000",
    "end": "2023958"
  },
  {
    "text": "What I wanted to show in this example, apart from the obvious, very important Cron module, is that schedule now",
    "start": "2029000",
    "end": "2038541"
  },
  {
    "text": "tracks errors explicitly. Before schedule did not track errors explicitly, it was",
    "start": "2039250",
    "end": "2044541"
  },
  {
    "text": "assumed to be a never-failing type. And now those types are correctly propagated back into",
    "start": "2044625",
    "end": "2051041"
  },
  {
    "text": "the main Effect. So you'll be able to build schedules that can fail, no",
    "start": "2051500",
    "end": "2056625"
  },
  {
    "text": "reason to do that unless you're implementing Cron for no use case whatsoever.",
    "start": "2056625",
    "end": "2061500"
  },
  {
    "text": "This is the price of buying me a hat.",
    "start": "2066416",
    "end": "2068291"
  },
  {
    "start": "2072000",
    "end": "2215000"
  },
  {
    "text": "More implicit handling of Scope. I've been asked, I think, a million of times in this",
    "start": "2073208",
    "end": "2081208"
  },
  {
    "text": "code, I'm using this Layer.unwrapEffect, piece of",
    "start": "2081333",
    "end": "2088125"
  },
  {
    "text": "code, gigantic piece of code, and I have Scope in my requirements. Why?",
    "start": "2088208",
    "end": "2092958"
  },
  {
    "text": "Well, you didn't have to use unwrapEffect. You had to use unwrap sculpt.",
    "start": "2093541",
    "end": "2098916"
  },
  {
    "text": "And you did not have to use Layer.effect, but you had to use Layer.scoped.",
    "start": "2100500",
    "end": "2105916"
  },
  {
    "text": "Very happy to tell you now that you can just use Layer Effect, you can just use Layer.unwrapEffect, and the Scope",
    "start": "2109500",
    "end": "2118125"
  },
  {
    "text": "is implicitly handled. You're not going to leak Scopes everywhere.",
    "start": "2118125",
    "end": "2122666"
  },
  {
    "text": "So again, less surprises, more good defaults.",
    "start": "2123625",
    "end": "2127500"
  },
  {
    "text": "The Cron was still running. It's a very persistent module.",
    "start": "2129875",
    "end": "2132791"
  },
  {
    "text": "I think it does the job.",
    "start": "2135916",
    "end": "2141083"
  },
  {
    "text": "And when the program ends, it's-- so this program is using--",
    "start": "2141500",
    "end": "2145291"
  },
  {
    "text": "we haven't ported yet Effect.Service, which we will in the future. But what this is doing is creating a background Fiber",
    "start": "2146541",
    "end": "2153458"
  },
  {
    "text": "that increments a counter every 100 milliseconds. And then my main program reads the current count after 500",
    "start": "2153541",
    "end": "2161125"
  },
  {
    "text": "milliseconds, so I get 0 and 5, no surprise. But when the program ends, you can see there's no Scope",
    "start": "2161250",
    "end": "2168000"
  },
  {
    "text": "needed here. I provide this Layer, and everything works out of the box, the Fiber is killed.",
    "start": "2168083",
    "end": "2174166"
  },
  {
    "text": "The proof that the Fiber is killed is that the program does not hang, thanks to the future before that I've shown before.",
    "start": "2175000",
    "end": "2182333"
  },
  {
    "text": "And in general, I've mentioned this before, less ways of doing the same thing. We're also consolidating the ways of creating tags into",
    "start": "2189541",
    "end": "2198083"
  },
  {
    "text": "only Effect.Service with a few more options to enable all",
    "start": "2198875",
    "end": "2204291"
  },
  {
    "text": "the different use cases. And this is pretty much where we currently are.",
    "start": "2204291",
    "end": "2210750"
  },
  {
    "text": "Effect is functioning. There's a lot of passing tests. But we still have to do a lot of stuff.",
    "start": "2211250",
    "end": "2216666"
  },
  {
    "start": "2215000",
    "end": "2402000"
  },
  {
    "text": "And here I literally mean a lot of different things.",
    "start": "2217166",
    "end": "2224125"
  },
  {
    "text": "Namely, we still have to implement stuck traces. We still have to implement metrics. We have to unify caching, because we have about seven",
    "start": "2225416",
    "end": "2233583"
  },
  {
    "text": "different ways of creating cached Effects. We are reevaluating once again if to rename either into",
    "start": "2233708",
    "end": "2242208"
  },
  {
    "text": "result. A lot of people are going to be happy about this. Personally, I dislike this change.",
    "start": "2242291",
    "end": "2248083"
  },
  {
    "text": "I hate it with all of my body. But I'm not the only one using Effect.",
    "start": "2250208",
    "end": "2256000"
  },
  {
    "text": "If we rename either as a result, we are thinking about making exit a result of either--",
    "start": "2258458",
    "end": "2265708"
  },
  {
    "text": "you see either is more general-- a result of either, A or cause, E. We're trying to make",
    "start": "2266916",
    "end": "2275041"
  },
  {
    "text": "equal structure by default. So if you don't use the data module to create an object, they are compared by default",
    "start": "2275916",
    "end": "2285375"
  },
  {
    "text": "using structural equality. What's hard here is to avoid circularity, because a generic",
    "start": "2285500",
    "end": "2292583"
  },
  {
    "text": "object might be circular, and the structural version kind of loops.",
    "start": "2292666",
    "end": "2297666"
  },
  {
    "text": "We have some ideas how to restrict this problem. The idea is generally to have plain objects being",
    "start": "2298791",
    "end": "2306166"
  },
  {
    "text": "structural, but as soon as you use a class, by default it's going to be referential.",
    "start": "2306208",
    "end": "2310708"
  },
  {
    "text": "So if the prototype is not the default prototype, it's going to be referential, unless you use, of course, data.tech",
    "start": "2311750",
    "end": "2317791"
  },
  {
    "text": "class, data.class, and the data functions where you are explicitly tapping into structurality.",
    "start": "2317875",
    "end": "2325458"
  },
  {
    "text": "As I said before, we have to port Effect and make it more generic. We have to port the remaining module.",
    "start": "2326916",
    "end": "2332500"
  },
  {
    "text": "In fact, it's very big. We have to redesign some of the STM data structures with the new encoding and actually make them usable, because some of",
    "start": "2333250",
    "end": "2343916"
  },
  {
    "text": "the data structures that we currently have in STM don't really make a lot of sense in JavaScript.",
    "start": "2343916",
    "end": "2348208"
  },
  {
    "text": "We have to consolidate API names. I haven't shown any of the new names on purpose, because we",
    "start": "2349583",
    "end": "2355375"
  },
  {
    "text": "are still not certain. We have to improve everything, like catch all, all what.",
    "start": "2355375",
    "end": "2363166"
  },
  {
    "text": "We're trying to make that something like catch all errors, catch all failures, something around that that tells you a",
    "start": "2364291",
    "end": "2371000"
  },
  {
    "text": "little bit more of the functionality you are tapping into.",
    "start": "2371000",
    "end": "2375375"
  },
  {
    "text": "And we are also evaluating if to memoize Layers in between provides, because we've seen many people use Effect provide",
    "start": "2376500",
    "end": "2383083"
  },
  {
    "text": "multiple times in their application tree and Layers being recreated. We want Layers to be memoized from the top",
    "start": "2383583",
    "end": "2391416"
  },
  {
    "text": "most of the provide. Those may not happen, or they may.",
    "start": "2391458",
    "end": "2398458"
  },
  {
    "text": "And who knows what else? Tentative timeline, probably going to take around three",
    "start": "2400125",
    "end": "2407083"
  },
  {
    "start": "2402000",
    "end": "2492000"
  },
  {
    "text": "months to release a beta of this. Three months further to port the ecosystem projects.",
    "start": "2407125",
    "end": "2417291"
  },
  {
    "text": "This hopefully it's not a lot of work, given that we aim for close to API compatibility.",
    "start": "2418041",
    "end": "2423666"
  },
  {
    "text": "And to be honest, to dock food a little bit on the new Effect",
    "start": "2425333",
    "end": "2430666"
  },
  {
    "text": "version. And so we expect six months in total for a stable release.",
    "start": "2430708",
    "end": "2437375"
  },
  {
    "text": "And Effect 3.0 is stable. So we plan to keep supporting Effect 3.0 for a while before",
    "start": "2439750",
    "end": "2450916"
  },
  {
    "text": "everything diverges into 4.0. We are thinking about a six months timeline after the",
    "start": "2451208",
    "end": "2459791"
  },
  {
    "text": "release has been declared production ready to give people enough time to migrate.",
    "start": "2460083",
    "end": "2464666"
  },
  {
    "text": "And I think my feeling is that 4.x will be the first LTS version of Effect.",
    "start": "2466375",
    "end": "2472625"
  },
  {
    "text": "Because this time we have really learned from production usage. We restarted from scratch, reevaluating all of the core",
    "start": "2473541",
    "end": "2481208"
  },
  {
    "text": "choices. Once we are stable with this, I honestly would have no idea what",
    "start": "2481250",
    "end": "2487041"
  },
  {
    "text": "to change in the short term.",
    "start": "2487041",
    "end": "2489875"
  },
  {
    "start": "2492000",
    "end": "2555000"
  },
  {
    "text": "So thank you, and see you next year. Hopefully where I will announce that Effect 4.0 is long term",
    "start": "2492625",
    "end": "2500041"
  },
  {
    "text": "support. (audience applauds)",
    "start": "2500166",
    "end": "2511291"
  },
  {
    "text": "And just to avoid--",
    "start": "2513250",
    "end": "2516208"
  },
  {
    "text": "I haven't done that for a while.",
    "start": "2520500",
    "end": "2522125"
  },
  {
    "text": "(audience laughs)",
    "start": "2531666",
    "end": "2535708"
  },
  {
    "text": "This repository is currently public. Have fun. (audience applauds)",
    "start": "2545250",
    "end": "2550291"
  }
]
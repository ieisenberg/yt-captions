[
  {
    "text": " Okay, so today is gonna be quite a day, so let's just have a quick recap of",
    "start": "4266",
    "end": "10766"
  },
  {
    "text": "what we did last time. So let's maybe move in here some windows, okay, so we",
    "start": "11349",
    "end": "19966"
  },
  {
    "text": "can draw something. Okay, so what are we working on? We are working on effect cluster. Effect",
    "start": "19966",
    "end": "25682"
  },
  {
    "text": "cluster is a library that allows you to implement what's called entity and location sharding,",
    "start": "25683",
    "end": "31883"
  },
  {
    "text": "which means that you can have one server running something, and that",
    "start": "32316",
    "end": "38500"
  },
  {
    "text": "server is usually called pod, so pod number one. Okay,",
    "start": "38500",
    "end": "43099"
  },
  {
    "text": "and over the pod number one you can have entities such, for",
    "start": "43933",
    "end": "49199"
  },
  {
    "text": "example, user, number, user Mattia,",
    "start": "49199",
    "end": "54000"
  },
  {
    "text": "that is being processed over this end, this pod, and then we can have other",
    "start": "56616",
    "end": "63166"
  },
  {
    "text": "users, let's say for example that we have user-milad, and then",
    "start": "63166",
    "end": "73083"
  },
  {
    "text": "what happens is that maybe for some reason this server becomes very stressed with a lot of",
    "start": "73083",
    "end": "80666"
  },
  {
    "text": "entities. What you can do is that you can then spawn up a new server that will be able to handle",
    "start": "80666",
    "end": "88800"
  },
  {
    "text": "a different set of users, let's say for example that Michael joins, and now we have a new",
    "start": "88800",
    "end": "96366"
  },
  {
    "text": "server that is running the user named Mike.",
    "start": "96366",
    "end": "101616"
  },
  {
    "text": "So at application code level, ideally you don't want to care about",
    "start": "102983",
    "end": "108866"
  },
  {
    "text": "where the user is being processed. You want to transparently reference the",
    "start": "108866",
    "end": "114649"
  },
  {
    "text": "user by just knowing its name, and that's what's called location transparency. Basically by just",
    "start": "114650",
    "end": "120266"
  },
  {
    "text": "knowing that you want to speak with Mattia, you can speak with Mattia, just by not knowing where",
    "start": "120266",
    "end": "128500"
  },
  {
    "text": "Mattia actually is right now, okay? And this ideally can scale",
    "start": "128500",
    "end": "133816"
  },
  {
    "text": "to the infinity, because you can spawn up a third server that is running a new set of entities, and",
    "start": "134383",
    "end": "140800"
  },
  {
    "text": "that scales up to the infinite, and then when one server is not",
    "start": "140800",
    "end": "146283"
  },
  {
    "text": "needed anymore, let's say that for example this server goes down, the user",
    "start": "146283",
    "end": "151383"
  },
  {
    "text": "will be shut down slowly, and then will be moved onto the new pod, which is the pod number",
    "start": "151383",
    "end": "159715"
  },
  {
    "text": "one, which is a new pod for the entity, but it is the oldest pod that we have in the system,",
    "start": "159716",
    "end": "165866"
  },
  {
    "text": "and that can happen in any sort of direction you want, okay? And so what we did last time? Last time",
    "start": "166183",
    "end": "178099"
  },
  {
    "text": "what we did is change the way that pods communicate between",
    "start": "178099",
    "end": "183599"
  },
  {
    "text": "each other, because let's say, let's come back and say that we have entities living on different",
    "start": "183599",
    "end": "190283"
  },
  {
    "text": "pods, okay? Let's say that we have pod number one with Mattia and Milad, and we",
    "start": "190300",
    "end": "196050"
  },
  {
    "text": "have pod number two, okay? And then we have some code that",
    "start": "196050",
    "end": "201949"
  },
  {
    "text": "needs to call from Mattia data files from Mike. So let's",
    "start": "201949",
    "end": "208816"
  },
  {
    "text": "say for example that there is a particular procedure on the entity named Mattia, then can ask information about Mike, okay? Or",
    "start": "208816",
    "end": "218583"
  },
  {
    "text": "Mattia from its entity behavior needs to speak with the entity of Mike. So this communication",
    "start": "218583",
    "end": "227383"
  },
  {
    "text": "before was handled by in an HTTP API,",
    "start": "227383",
    "end": "233466"
  },
  {
    "text": "we had an HTTP server running on both",
    "start": "234250",
    "end": "241650"
  },
  {
    "text": "pods here and here, and this",
    "start": "241650",
    "end": "246715"
  },
  {
    "text": "HTTP server was actually part of the pod server. You cannot have a pod",
    "start": "246716",
    "end": "253349"
  },
  {
    "text": "without its HTTP server, okay? Sorry.",
    "start": "253349",
    "end": "260299"
  },
  {
    "text": "So this situation is kind of like this, where you have different pods and each pod has",
    "start": "264400",
    "end": "271166"
  },
  {
    "text": "each HTTP server embedded in, okay? And when Mattia wants to speak",
    "start": "271183",
    "end": "277900"
  },
  {
    "text": "with Mike, what he does is in the entity behavior of Mattia, we",
    "start": "277900",
    "end": "283866"
  },
  {
    "text": "trigger an HTTP request to the pod number two, and then",
    "start": "283866",
    "end": "290082"
  },
  {
    "text": "the request will be processed, and then we will have the response back, okay? So this is basically",
    "start": "290216",
    "end": "297666"
  },
  {
    "text": "an HTTP request, and this HTTP request is called for example send message,",
    "start": "297750",
    "end": "305166"
  },
  {
    "text": "that will actually send the message and get back the result. And right now, these all behave just",
    "start": "308316",
    "end": "315366"
  },
  {
    "text": "by using HTTP server, but the idea we are",
    "start": "315416",
    "end": "320916"
  },
  {
    "text": "pursuing right now is that why should we be actually tied to being an HTTP server? It can be",
    "start": "320916",
    "end": "328150"
  },
  {
    "text": "anything, okay? It can be maybe not an HTTP server, but an",
    "start": "328150",
    "end": "333250"
  },
  {
    "text": "gRPC PC service, or whatever you want.",
    "start": "333250",
    "end": "338150"
  },
  {
    "text": "So instead of having an HTTP server, we are now migrating to",
    "start": "338916",
    "end": "345083"
  },
  {
    "text": "having an RPC server. And thanks to effect having pluggable context, we can",
    "start": "345083",
    "end": "350715"
  },
  {
    "text": "basically plug in whatever we want, as long as it is supported by",
    "start": "350716",
    "end": "356516"
  },
  {
    "text": "effect RPC. So Milad asked, \"Would it be third pod as",
    "start": "356516",
    "end": "363866"
  },
  {
    "text": "a new one when the second pod dies? Would it be third pod as a new",
    "start": "364616",
    "end": "372000"
  },
  {
    "text": "one when the second pod dies that user brought to the third pod?",
    "start": "372000",
    "end": "377349"
  },
  {
    "text": "Sounds like a replica possible.\" So you are basically saying",
    "start": "377883",
    "end": "382948"
  },
  {
    "text": "that, \"Would it be a third pod as a new one when the second pod dies that user",
    "start": "383983",
    "end": "393199"
  },
  {
    "text": "brought to the third pod?\" It's not actually a third pod. You",
    "start": "393199",
    "end": "398465"
  },
  {
    "text": "can imagine the pod as being an application logic server.",
    "start": "398466",
    "end": "403650"
  },
  {
    "text": "A pod has only the responsibility of hosting entity behaviors. So basically the pod is",
    "start": "403900",
    "end": "410416"
  },
  {
    "text": "hosting the behavior, okay? But the pod can stay alive ideally",
    "start": "411099",
    "end": "416500"
  },
  {
    "text": "forever, should stay alive ideally forever, okay? So when a new entity joins",
    "start": "416500",
    "end": "422150"
  },
  {
    "text": "in, it's not a new pod, but basically it's just joining a pod, it's starting a new entity behavior",
    "start": "422150",
    "end": "427550"
  },
  {
    "text": "inside that pod, okay? Not sure if I completely understood your question, but feel free to tell me",
    "start": "427550",
    "end": "434666"
  },
  {
    "text": "if not, okay? And yeah, basically we want to move away",
    "start": "434666",
    "end": "439616"
  },
  {
    "text": "from having an HTTP and having everything as RPC. So we can exchange",
    "start": "439750",
    "end": "447016"
  },
  {
    "text": "messaging without knowing, which is the actual transport in between. It can be HTTP, gRPC, or whatever, okay?",
    "start": "447016",
    "end": "458550"
  },
  {
    "text": "And last time we did this kind of communication, but we also have another communication,",
    "start": "463050",
    "end": "469366"
  },
  {
    "text": "which is between the pods and what's called the shard manager.",
    "start": "470783",
    "end": "477815"
  },
  {
    "text": "Oh, hello again. Hello Dark Energy. Hello Mattia, I really like the Effect library. I hope I can learn a lot from you",
    "start": "482500",
    "end": "490016"
  },
  {
    "text": "guys. I hope to let you learn something even today.",
    "start": "490016",
    "end": "495316"
  },
  {
    "text": "And so I was saying, okay, we actually have a third kind of server,",
    "start": "497649",
    "end": "503166"
  },
  {
    "text": "which is the shard manager, and the shard manager is a server with responsibility is just",
    "start": "503166",
    "end": "509283"
  },
  {
    "text": "to list and keep track of the pods that are alive and subscribed",
    "start": "509283",
    "end": "516516"
  },
  {
    "text": "to the cluster. So for example, now the shard manager knows that there is the pod entity number",
    "start": "516516",
    "end": "523766"
  },
  {
    "text": "one, the pod that handles entity number two, etc. Okay? And what happens is that when a pod",
    "start": "523766",
    "end": "530483"
  },
  {
    "text": "starts, the first things that it does is calling",
    "start": "530483",
    "end": "537166"
  },
  {
    "text": "the shard manager and saying to shard manager, register, is",
    "start": "538066",
    "end": "546350"
  },
  {
    "text": "basically gonna register himself to the shard manager. So the shard manager knows that a pod exists. So if",
    "start": "546350",
    "end": "553816"
  },
  {
    "text": "for example, we spawn up a new pod, let's say that we have pod number three, it will call",
    "start": "553816",
    "end": "561066"
  },
  {
    "text": "the shard manager saying, \"register myself,\" and the shard manager",
    "start": "561066",
    "end": "569983"
  },
  {
    "text": "will then reply, \"okay, now you are registered.\" And when the shard manager sees that there is",
    "start": "569983",
    "end": "578500"
  },
  {
    "text": "a new pod, the pod number three that we have just registered, and that pod has no entity on",
    "start": "578500",
    "end": "588399"
  },
  {
    "text": "himself, what the shard manager will do is try to rebalance the system and tell the pod number one,",
    "start": "588399",
    "end": "597166"
  },
  {
    "text": "\"please do not care about the user named Mattia, and please",
    "start": "597383",
    "end": "603016"
  },
  {
    "text": "shut down the entity behavior for the user named Mattia, because now I want to move the user named",
    "start": "603016",
    "end": "608883"
  },
  {
    "text": "Mattia to the pod number three.\" Okay? So the shard manager is the server that is doing this kind of",
    "start": "608883",
    "end": "615449"
  },
  {
    "text": "work. And last time, as I said, we moved this communication between",
    "start": "615683",
    "end": "621283"
  },
  {
    "text": "pods, and today I hope to",
    "start": "621283",
    "end": "625283"
  },
  {
    "text": "fix the eventual issue we have in this communication. Let's hope that we get it running,",
    "start": "626383",
    "end": "632316"
  },
  {
    "text": "and then move to implement the communication between the pods and the shard manager.",
    "start": "632466",
    "end": "637000"
  },
  {
    "text": "Okay? So let's see how we are going. Oh,",
    "start": "637983",
    "end": "644000"
  },
  {
    "text": "hi there Federico, how's it going? So last time, let's see if maybe we start",
    "start": "644000",
    "end": "653600"
  },
  {
    "text": "by trying running an example. So let's move to desktop cluster,",
    "start": "653600",
    "end": "660683"
  },
  {
    "text": "and then we need to move to packages,",
    "start": "665416",
    "end": "668666"
  },
  {
    "text": "packages, cluster node.",
    "start": "671466",
    "end": "674916"
  },
  {
    "text": "Right now, this package is one sub package of the Effect cluster, which is called cluster node, but",
    "start": "676483",
    "end": "682050"
  },
  {
    "text": "I hope to move that to be something like cluster RPC or cluster platform. So something that is not actually tied to",
    "start": "682383",
    "end": "689750"
  },
  {
    "text": "being running on node. Okay?",
    "start": "689750",
    "end": "691850"
  },
  {
    "text": "Okay, so... Milad asked, I read shard on the net,",
    "start": "697350",
    "end": "703383"
  },
  {
    "text": "but it seems more related to database, but in your area, doesn't make sense. Can you please",
    "start": "703383",
    "end": "708665"
  },
  {
    "text": "explain what shard is?\" Okay, so let's go back to",
    "start": "708666",
    "end": "713699"
  },
  {
    "text": "our drawing board. Okay? Right now, I always said that we moved",
    "start": "714383",
    "end": "721350"
  },
  {
    "text": "entities. Okay? We moved the user named Mattia, we moved the user",
    "start": "721350",
    "end": "727615"
  },
  {
    "text": "named Milad, user named Mike, etc. Okay? You can imagine that",
    "start": "727616",
    "end": "733116"
  },
  {
    "text": "in your system, you will have something like thousands of entities.",
    "start": "733183",
    "end": "737782"
  },
  {
    "text": "Okay? So you cannot imagine having the shard manager being a single",
    "start": "738399",
    "end": "744316"
  },
  {
    "text": "point that keeps track of every entity that exists on your",
    "start": "744316",
    "end": "749500"
  },
  {
    "text": "system. Okay? So what happens is that...",
    "start": "749500",
    "end": "754716"
  },
  {
    "text": "What actually happens is that instead of the shard manager telling the pod to start a new entity or",
    "start": "755966",
    "end": "765966"
  },
  {
    "text": "shut down a specific entities, all the entities that",
    "start": "765966",
    "end": "771500"
  },
  {
    "text": "exist in your system are actually grouped into what are called",
    "start": "771583",
    "end": "776816"
  },
  {
    "text": "shards. Okay? And what are shards? Shards are just logical grouping of",
    "start": "776816",
    "end": "783115"
  },
  {
    "text": "entities. Okay? So let's have a real world example. Okay? Let's say that we have user named Mattia,",
    "start": "783116",
    "end": "792350"
  },
  {
    "text": "user named Milad, user named Mike, and user named",
    "start": "793283",
    "end": "802415"
  },
  {
    "text": "Federico. Okay? What actually is a shard?",
    "start": "802550",
    "end": "807266"
  },
  {
    "text": "A shard, as we said, is a logical grouping. So instead of referencing its entity, we",
    "start": "807949",
    "end": "813199"
  },
  {
    "text": "can say that this is group of entities number one, and this is group of entities number two.",
    "start": "813199",
    "end": "820866"
  },
  {
    "text": "Sorry. This is group of entities number two. Okay? But how we tell its user to",
    "start": "824550",
    "end": "833649"
  },
  {
    "text": "which group it belongs? So to solve that in a pretty",
    "start": "833649",
    "end": "840550"
  },
  {
    "text": "deterministic way so that its server exactly known which shard",
    "start": "840550",
    "end": "845850"
  },
  {
    "text": "its entities belongs to, the thing that we can do is, for example,",
    "start": "846550",
    "end": "852665"
  },
  {
    "text": "make a hash of the user ID. Okay? We can say a hash of Mattia.",
    "start": "853250",
    "end": "860699"
  },
  {
    "text": "And let's pretend that the value of this hash is one. Okay? So",
    "start": "864966",
    "end": "870116"
  },
  {
    "text": "now we know that Mattia, the hash of the entity ID Mattia is one.",
    "start": "870116",
    "end": "875383"
  },
  {
    "text": "Now we know that the shard ID for the entity Mattia is one. Okay? Now we can do the same for",
    "start": "875383",
    "end": "881800"
  },
  {
    "text": "Milad. Okay? And Milad has the same hash. And now we go to Mike, and we see that",
    "start": "881800",
    "end": "891250"
  },
  {
    "text": "Mike actually has hash number two. So this is a different shard ID. Okay?",
    "start": "891250",
    "end": "900483"
  },
  {
    "text": "Not sure if I completely if I completely replied or explained well",
    "start": "901416",
    "end": "907000"
  },
  {
    "text": "to you. But yeah, you're right. It's usually more related to the database word because usually",
    "start": "907000",
    "end": "916116"
  },
  {
    "text": "database uses shard in order to aggregate entities or",
    "start": "916116",
    "end": "921800"
  },
  {
    "text": "aggregate data in order to keep data in groupings or performance",
    "start": "921800",
    "end": "927866"
  },
  {
    "text": "optimizations. But in our domain, shards are just used so that the shard",
    "start": "927866",
    "end": "934250"
  },
  {
    "text": "manager, instead of knowing exactly its entity, its pod is dealing, the shard manager knows just",
    "start": "934250",
    "end": "942266"
  },
  {
    "text": "the list of shard IDs, which is a fixed number you can configure in your system, saying, okay,",
    "start": "942266",
    "end": "949649"
  },
  {
    "text": "your system will have 2,000 shard IDs.",
    "start": "949649",
    "end": "954199"
  },
  {
    "text": "Okay? And now the hash will go just up to 200 and nothing more.",
    "start": "954750",
    "end": "960649"
  },
  {
    "text": "Okay? And so we can have an infinite number of entities",
    "start": "960966",
    "end": "967066"
  },
  {
    "text": "that are now grouped into shard IDs.",
    "start": "967816",
    "end": "974050"
  },
  {
    "text": "Okay? And now the shard manager just manages which shard IDs",
    "start": "974416",
    "end": "979683"
  },
  {
    "text": "live on which pod. Okay? Okay. I'm happy",
    "start": "980066",
    "end": "985665"
  },
  {
    "text": "that my explanation made sense for you. Okay? So back to what we were doing before, we",
    "start": "985666",
    "end": "999666"
  },
  {
    "text": "were trying to run the examples, right? And see a cluster",
    "start": "999666",
    "end": "1005699"
  },
  {
    "text": "node and say pnpm example and then saying",
    "start": "1005899",
    "end": "1012683"
  },
  {
    "text": "something like example examples sample",
    "start": "1012683",
    "end": "1017915"
  },
  {
    "text": "manager because we need to start the manager first. Okay. Okay. We have an error, but this is just",
    "start": "1019500",
    "end": "1030500"
  },
  {
    "text": "logged as debug. And to be honest, this error is expected",
    "start": "1030500",
    "end": "1036965"
  },
  {
    "text": "because what the shard manager does upon starting is try to",
    "start": "1038216",
    "end": "1044865"
  },
  {
    "text": "contact, let's say that, let's go back to the drawing board and say, let's say that for some",
    "start": "1044866",
    "end": "1051550"
  },
  {
    "text": "reason, all of our system goes down. Okay? Now everything is shut down.",
    "start": "1051550",
    "end": "1056500"
  },
  {
    "text": "The first thing that can spawn up is not",
    "start": "1056983",
    "end": "1061449"
  },
  {
    "text": "mandatory, but can be the first thing that's going up is the shard manager. Okay? And now the shard manager comes back online and says, \"Ooh,",
    "start": "1062783",
    "end": "1069516"
  },
  {
    "text": "I know that exists pod number one, pod number two, and pod number three.\" So let's ensure that",
    "start": "1069716",
    "end": "1075283"
  },
  {
    "text": "they are actually still alive. And now what happens is that the shard manager tries to contact back",
    "start": "1075283",
    "end": "1083583"
  },
  {
    "text": "the pod and it basically sends a ping, not a ping in a",
    "start": "1083583",
    "end": "1089699"
  },
  {
    "text": "sense of a network ping, but a ping in a sense of a message that is",
    "start": "1089699",
    "end": "1095116"
  },
  {
    "text": "trying to ask, \"Hey, are you still alive?\" And if the server doesn't respond",
    "start": "1095116",
    "end": "1101000"
  },
  {
    "text": "as it happened right now, the shard manager will now say, \"Okay, you are offline. You are not",
    "start": "1101000",
    "end": "1108382"
  },
  {
    "text": "running up to now.\" Okay? And so this is expected that we get the",
    "start": "1108383",
    "end": "1114350"
  },
  {
    "text": "error saying that he tried to post to a server that is no longer alive because I",
    "start": "1114350",
    "end": "1120800"
  },
  {
    "text": "didn't start it yet. And then we try to start a",
    "start": "1120800",
    "end": "1126983"
  },
  {
    "text": "new, maybe we can move to the \"desktop cluster packages\"",
    "start": "1126983",
    "end": "1133983"
  },
  {
    "text": "\"cluster_node\" \"pnpm_example\" \"sample_shard\"",
    "start": "1136233",
    "end": "1142383"
  },
  {
    "text": "\"example\" maybe \"examples sample_shard\"",
    "start": "1145250",
    "end": "1151649"
  },
  {
    "text": "Okay, and now as you can see, I started",
    "start": "1152383",
    "end": "1157399"
  },
  {
    "text": "this pod. So now it's alive. And the first thing that happened is",
    "start": "1157399",
    "end": "1164550"
  },
  {
    "text": "the shard manager acknowledged that this pod is now alive and basically removed",
    "start": "1165983",
    "end": "1173116"
  },
  {
    "text": "all of the entities. Mattia,",
    "start": "1173116",
    "end": "1176416"
  },
  {
    "text": "Milad, Mike, everyone, he moved to this pod. Okay, because now this",
    "start": "1180000",
    "end": "1185983"
  },
  {
    "text": "pod is alive and is able to process entities. And as you can see here",
    "start": "1185983",
    "end": "1191050"
  },
  {
    "text": "in log, we don't see the actual name of the entities, but we see the list of the shard IDs that",
    "start": "1191050",
    "end": "1198866"
  },
  {
    "text": "we spoke before. Okay? You can see that basically since this is",
    "start": "1198866",
    "end": "1205783"
  },
  {
    "text": "the only server in the system, the shard manager decided that okay, I'm gonna assign you everything.",
    "start": "1205783",
    "end": "1211582"
  },
  {
    "text": "Okay, and now the third thing that I want to start is to start my",
    "start": "1214816",
    "end": "1222449"
  },
  {
    "text": "\"cd desktop/cluster/packages\"",
    "start": "1222483",
    "end": "1227683"
  },
  {
    "text": "\"cluster_node\" Not browser, but node.",
    "start": "1230366",
    "end": "1235100"
  },
  {
    "text": "I want to start now something that tries to connect to the entities and send messages to",
    "start": "1237516",
    "end": "1242683"
  },
  {
    "text": "the entities. So \"pnpm example examples\" \"sample-connect\"",
    "start": "1242683",
    "end": "1250315"
  },
  {
    "text": "I think that I called it, yes. Okay, now as you can see, this",
    "start": "1250316",
    "end": "1255350"
  },
  {
    "text": "process is calling the entities. Basically is sending an increment message",
    "start": "1255350",
    "end": "1260966"
  },
  {
    "text": "to entity number 0, 1, 2, 3, 4, etc. And each entities has a behavior that just keeps",
    "start": "1260966",
    "end": "1267449"
  },
  {
    "text": "track of the current number and increases. Okay? And as you can see, the actual entity is being",
    "start": "1267449",
    "end": "1274716"
  },
  {
    "text": "processed on the shard process, not into the client process and",
    "start": "1274716",
    "end": "1279800"
  },
  {
    "text": "not into the shard manager. Okay? And now, as we have seen the",
    "start": "1279800",
    "end": "1286816"
  },
  {
    "text": "other times, we can spawn up ideally new processes and the shard manager will balance things between. Like",
    "start": "1286816",
    "end": "1293616"
  },
  {
    "text": "let's say for example that I start a new process again. Sorry if I'm bothering someone",
    "start": "1293616",
    "end": "1299850"
  },
  {
    "text": "that already has seen this demo, but it's also useful because we've moved the protocol so we can see",
    "start": "1299850",
    "end": "1306050"
  },
  {
    "text": "and check that everything is working. And then, yeah, matrix love.",
    "start": "1306050",
    "end": "1311666"
  },
  {
    "text": "A lot of text moving on. I need to change the color of the text to be green. And then let's say that",
    "start": "1312449",
    "end": "1319516"
  },
  {
    "text": "I move to desktop, cluster packages, cluster node.",
    "start": "1319516",
    "end": "1326850"
  },
  {
    "text": "And then I say that I want to start on port 1, 2, 3, 4, pnpm,",
    "start": "1327266",
    "end": "1335666"
  },
  {
    "text": "example, examples, sample shard.",
    "start": "1335666",
    "end": "1340683"
  },
  {
    "text": "So now I will start a new process that is able to host entity",
    "start": "1341149",
    "end": "1346350"
  },
  {
    "text": "behaviors. So this process will be able to host the logic for the counter",
    "start": "1346350",
    "end": "1351648"
  },
  {
    "text": "that right now is running only on this process. And ideally, if I start this one, what we",
    "start": "1351649",
    "end": "1361083"
  },
  {
    "text": "will see is that we have an error. Okay. Error server is not running. Ooh. We have an error.",
    "start": "1361083",
    "end": "1370383"
  },
  {
    "text": "Server is not running. What are you trying to ask? And this is why, oh, I see why we have",
    "start": "1371566",
    "end": "1382100"
  },
  {
    "text": "error, right? We have migrated to effect RPC in order to provide the RPC",
    "start": "1382100",
    "end": "1390850"
  },
  {
    "text": "server. So we have now sharding service RPC that exposes",
    "start": "1390850",
    "end": "1396916"
  },
  {
    "text": "our router. Okay. But right now in my examples, the port for the RPC",
    "start": "1397199",
    "end": "1406898"
  },
  {
    "text": "is configured into the sharding config. But then when I start the shard,",
    "start": "1409183",
    "end": "1417382"
  },
  {
    "text": "I start that on a fixed port. Instead, I need to get the port from the",
    "start": "1419033",
    "end": "1425549"
  },
  {
    "text": "configuration instead of right now here. And so that's why we get",
    "start": "1425550",
    "end": "1431966"
  },
  {
    "text": "the error when starting the second process, because we are trying to start on the same port as the first",
    "start": "1431966",
    "end": "1437616"
  },
  {
    "text": "one that is already running. So let's try to fix this. So ideally, if",
    "start": "1437616",
    "end": "1444750"
  },
  {
    "text": "I just, for example, change the port manually, save the code and run again, now this",
    "start": "1444750",
    "end": "1452366"
  },
  {
    "text": "will use a different port. And you can see that as I discussed before, the first message will be a",
    "start": "1452366",
    "end": "1458399"
  },
  {
    "text": "register message that now this port has a register to server.",
    "start": "1458399",
    "end": "1463766"
  },
  {
    "text": "And slowly but surely the shard manager will basically figure out that now it",
    "start": "1467800",
    "end": "1476166"
  },
  {
    "text": "needs to send things. Let's try to see. Let's",
    "start": "1476166",
    "end": "1486399"
  },
  {
    "text": "see if something happens. Oh, no, it's not working because, yeah,",
    "start": "1486399",
    "end": "1495116"
  },
  {
    "text": "because we are not using the correct config. Yeah. We are not using the correct config. So",
    "start": "1495116",
    "end": "1500250"
  },
  {
    "text": "we need to first fix this. Okay. So this is using a layer.",
    "start": "1500250",
    "end": "1505398"
  },
  {
    "text": "And now here instead, we need to use a different port. So let's say that we do something like",
    "start": "1505449",
    "end": "1513882"
  },
  {
    "text": "a layer.flatMap.",
    "start": "1515666",
    "end": "1519283"
  },
  {
    "text": "And we do something like. Okay, when we want to start from the",
    "start": "1521583",
    "end": "1532816"
  },
  {
    "text": "sharding config. So we start from sharding.",
    "start": "1532816",
    "end": "1538716"
  },
  {
    "text": "Sharding config.shardingConfig. And then we go Effect.flatMap.",
    "start": "1542850",
    "end": "1549166"
  },
  {
    "text": "And this will go from the config. We need to create the actual",
    "start": "1549666",
    "end": "1556600"
  },
  {
    "text": "HTTP server. So we have here",
    "start": "1556600",
    "end": "1560350"
  },
  {
    "text": "the various things and we have layer, layer server.",
    "start": "1562866",
    "end": "1569799"
  },
  {
    "text": "Layer config. And layer",
    "start": "1570949",
    "end": "1577766"
  },
  {
    "text": "config uses net.list. Oh, okay.",
    "start": "1577766",
    "end": "1581283"
  },
  {
    "text": "So we can use either make.",
    "start": "1583183",
    "end": "1585916"
  },
  {
    "text": "But we'll use a scope and I don't like that. So maybe what we can do here is say something like.",
    "start": "1589000",
    "end": "1596050"
  },
  {
    "text": "Now I have the config. I want to do something like this one, basically.",
    "start": "1596550",
    "end": "1605699"
  },
  {
    "text": "Create layer from, oops. And the port will be config.shardingPort.",
    "start": "1609183",
    "end": "1618766"
  },
  {
    "text": "This will be a map, not a flat map. Okay.",
    "start": "1618800",
    "end": "1625300"
  },
  {
    "text": "And let's see if we have something like layer dot flatten. Yeah, we have. Okay. And what is",
    "start": "1625899",
    "end": "1635315"
  },
  {
    "text": "the expected definition of layer.flatten? See, flatten layers nested in the context of",
    "start": "1635316",
    "end": "1640699"
  },
  {
    "text": "an effect. Okay. So I provide you what? I provide you a layer.",
    "start": "1640699",
    "end": "1646250"
  },
  {
    "text": "A layer and a tag. Okay. And",
    "start": "1646466",
    "end": "1652216"
  },
  {
    "text": "I get back the, that's okay.",
    "start": "1652216",
    "end": "1655299"
  },
  {
    "text": "So let's try to use that. So from here, now I",
    "start": "1658116",
    "end": "1666315"
  },
  {
    "text": "want to basically get the",
    "start": "1666316",
    "end": "1672066"
  },
  {
    "text": "layer dot, we have said flatten. No, not",
    "start": "1674699",
    "end": "1680000"
  },
  {
    "text": "flatten. Layer dot. Yeah, it was flattened. Yeah, was flatten. But I need to provide the",
    "start": "1680000",
    "end": "1686283"
  },
  {
    "text": "HTTP server.Server.server.",
    "start": "1686283",
    "end": "1691266"
  },
  {
    "text": "Right. Node HTTP server. Sorry. Node",
    "start": "1695266",
    "end": "1703116"
  },
  {
    "text": "HTTP server. And server layer and the layer it provides is,",
    "start": "1703116",
    "end": "1708583"
  },
  {
    "text": "oh, HTTP server platform, platform, HTTP. Okay. So you need to",
    "start": "1709066",
    "end": "1714483"
  },
  {
    "text": "provide all of these services. Okay. So I'm not a big fan. Let's see.",
    "start": "1714483",
    "end": "1720616"
  },
  {
    "text": "Maybe we have something better instead of using layer. Maybe I can use something like make.",
    "start": "1720616",
    "end": "1727449"
  },
  {
    "text": "Okay. And this will create our flatten effect. So I can do",
    "start": "1728699",
    "end": "1735600"
  },
  {
    "text": "flatMap and now we'll have. Okay. But",
    "start": "1736066",
    "end": "1741850"
  },
  {
    "text": "now I still have to provide those as layer. Yeah. It would be best just to use layer and",
    "start": "1741850",
    "end": "1747800"
  },
  {
    "text": "then flatten and we need to have the tags for",
    "start": "1747800",
    "end": "1751799"
  },
  {
    "text": "the HTTP server, which goes from. Effect Platform. Yeah.",
    "start": "1753666",
    "end": "1759783"
  },
  {
    "text": "Where is platform? Where is platform? I'm missing platform. Oh, HTTP",
    "start": "1773000",
    "end": "1778300"
  },
  {
    "text": "server. I already have that. HTTP server.server.server. Are",
    "start": "1778300",
    "end": "1786149"
  },
  {
    "text": "you fine with that? No. Why? Because it should be,",
    "start": "1786149",
    "end": "1791482"
  },
  {
    "text": "it should be a layer. Okay. And this instead is an effect. Okay. So layer from",
    "start": "1793016",
    "end": "1801315"
  },
  {
    "text": "effect. And this creates this service.",
    "start": "1802066",
    "end": "1808850"
  },
  {
    "text": "I'm not sure the best way to do this one. The thing is that in the end I want to",
    "start": "1817750",
    "end": "1826466"
  },
  {
    "text": "create an HTTP live and all of these in the end is void.",
    "start": "1826466",
    "end": "1832882"
  },
  {
    "text": "So I'm just making my life harder because what I can do is more simple. It's",
    "start": "1834350",
    "end": "1842850"
  },
  {
    "text": "something like maybe a pipe shardingConfig.shardingConfig",
    "start": "1842850",
    "end": "1856850"
  },
  {
    "text": "Effect.flatMap",
    "start": "1856850",
    "end": "1863583"
  },
  {
    "text": "What would you achieve for the test variable? I would like to have something like,",
    "start": "1863583",
    "end": "1868766"
  },
  {
    "text": "I would like to have a layer the exact same definition that I have",
    "start": "1868783",
    "end": "1875350"
  },
  {
    "text": "right now, as you can see. So I want this to be in a layer that produces nothing, can",
    "start": "1875350",
    "end": "1881866"
  },
  {
    "text": "result in a server error and needs sharding. Okay. I want to have something",
    "start": "1881866",
    "end": "1887100"
  },
  {
    "text": "that is exactly the same, but also require shouting config because I need to provide",
    "start": "1887100",
    "end": "1893083"
  },
  {
    "text": "that shouting config in here. So I was later thinking that I was doing that the hard",
    "start": "1893083",
    "end": "1898916"
  },
  {
    "text": "way because what I can do is something like flat map. Now we have the config or even",
    "start": "1898916",
    "end": "1906266"
  },
  {
    "text": "map is better. And now that I have the config, I can create a layer in here and use the",
    "start": "1906266",
    "end": "1918350"
  },
  {
    "text": "config.sharding port in here and this will create an effect.",
    "start": "1918350",
    "end": "1923666"
  },
  {
    "text": "Oh yeah sure. I'll write it in here.",
    "start": "1926766",
    "end": "1931416"
  },
  {
    "text": "I want this to be something like this, not nested right here.",
    "start": "1936566",
    "end": "1942516"
  },
  {
    "text": "And I want a layer. So this is the",
    "start": "1942949",
    "end": "1954315"
  },
  {
    "text": "signature that I'm looking for. It produces never. So it's",
    "start": "1954316",
    "end": "1959683"
  },
  {
    "text": "discard. It can produce a server error and then",
    "start": "1959683",
    "end": "1965316"
  },
  {
    "text": "there's a sharding config. Yeah. Yeah. It's really hard when you try to",
    "start": "1965316",
    "end": "1971216"
  },
  {
    "text": "compose a lot of services to remember what you actually want.",
    "start": "1971216",
    "end": "1975398"
  },
  {
    "text": "So this is what I want. And ideally this gives me an effect. So maybe what I can do next is saying",
    "start": "1976483",
    "end": "1982449"
  },
  {
    "text": "that I want a layer.effectdiscard and",
    "start": "1983416",
    "end": "1993416"
  },
  {
    "text": "this should be create a layer of okay.",
    "start": "1993416",
    "end": "1996850"
  },
  {
    "text": "Oh, I cannot use effect discard. I should have effect. And this requires me to keep",
    "start": "1999050",
    "end": "2005166"
  },
  {
    "text": "the tag of the service that is building and I can use actually whatever I want.",
    "start": "2005199",
    "end": "2014500"
  },
  {
    "text": "Right. Effect layer is not assignable to type.",
    "start": "2015000",
    "end": "2021583"
  },
  {
    "text": "Sharding . Oh, because it's actually producing never. No. Why a layer and not an effect? So the",
    "start": "2022166",
    "end": "2032366"
  },
  {
    "text": "thing is that I could create an effect and then",
    "start": "2032366",
    "end": "2037600"
  },
  {
    "text": "the effect can be converted into a layer. That's true. That's",
    "start": "2038300",
    "end": "2043583"
  },
  {
    "text": "something that you can do. And that's something that maybe we can start with. We can do",
    "start": "2043583",
    "end": "2049866"
  },
  {
    "text": "maybe server.make and this",
    "start": "2049866",
    "end": "2053982"
  },
  {
    "text": "is the same. We have make, go to definition. We have make",
    "start": "2055350",
    "end": "2063116"
  },
  {
    "text": "here. Okay. And this returns the server, can produce a server error and has a",
    "start": "2063116",
    "end": "2069416"
  },
  {
    "text": "scope. But the thing is that I want something to be more composable when I expect some",
    "start": "2069416",
    "end": "2075398"
  },
  {
    "text": "services to be provided by the user. Okay. But indeed, if we want to start with something, we",
    "start": "2075399",
    "end": "2082766"
  },
  {
    "text": "can do maybe set.make and this will have what?",
    "start": "2082766",
    "end": "2087765"
  },
  {
    "text": "The create server and now it's not",
    "start": "2089683",
    "end": "2092766"
  },
  {
    "text": "Effect.provide service.",
    "start": "2099366",
    "end": "2100983"
  },
  {
    "text": "Oh, but yeah, we cannot actually use that. We could, but we would be very verbose because the",
    "start": "2106333",
    "end": "2111866"
  },
  {
    "text": "thing is that this layer, if you go to definition, you see that it produces a lot of services.",
    "start": "2111866",
    "end": "2118199"
  },
  {
    "text": "And if I convert that to an effect, I will have basically all of",
    "start": "2119100",
    "end": "2124750"
  },
  {
    "text": "these to be defined manually. Okay. So I think that I need to see. I'm",
    "start": "2124750",
    "end": "2135966"
  },
  {
    "text": "not very familiar with layers. It's something that I am trying to understand. But I think that",
    "start": "2135966",
    "end": "2144149"
  },
  {
    "text": "ideally by using something like flat map, I can say that, let's say that I start",
    "start": "2144149",
    "end": "2151199"
  },
  {
    "text": "with the HTTP live layer.",
    "start": "2151199",
    "end": "2153383"
  },
  {
    "text": "And then this will work with, so let's say I start with this.",
    "start": "2156550",
    "end": "2161799"
  },
  {
    "text": "And I get this. Okay. So this is the",
    "start": "2162300",
    "end": "2167566"
  },
  {
    "text": "config now ideally. Right. Oh, this is not an",
    "start": "2167566",
    "end": "2174716"
  },
  {
    "text": "effect, right? This is. This is the layer I want.",
    "start": "2174716",
    "end": "2180699"
  },
  {
    "text": "Do I actually want to be layer.effect? I want a layer",
    "start": "2183583",
    "end": "2189166"
  },
  {
    "text": "From an effect that come from this. And now this should be the",
    "start": "2189666",
    "end": "2195699"
  },
  {
    "text": "config. No, because this actually requires, yeah, this actually requires the target",
    "start": "2195699",
    "end": "2201116"
  },
  {
    "text": "itself. So let's start by writing these as the dumbest way I can came up.",
    "start": "2201116",
    "end": "2208816"
  },
  {
    "text": "Okay. And this should be the config. Okay. This is the config and it's in the context. Okay. Sorry.",
    "start": "2210883",
    "end": "2220515"
  },
  {
    "text": "Okay. And then I want to use this config",
    "start": "2221616",
    "end": "2227800"
  },
  {
    "text": "to create this.",
    "start": "2230050",
    "end": "2231783"
  },
  {
    "text": "This is a context. Context. So maybe from the",
    "start": "2236649",
    "end": "2243583"
  },
  {
    "text": "context, context, I can get",
    "start": "2243583",
    "end": "2247883"
  },
  {
    "text": "import everything as context.",
    "start": "2250600",
    "end": "2254916"
  },
  {
    "text": "From Effect/context. Okay. And now",
    "start": "2257383",
    "end": "2262766"
  },
  {
    "text": "I can do something like context.get. I",
    "start": "2262783",
    "end": "2272550"
  },
  {
    "text": "want to get the sharding config.",
    "start": "2272550",
    "end": "2276149"
  },
  {
    "text": "Dot. I want to get the sharding config. Yeah. Right. Or from",
    "start": "2278966",
    "end": "2284699"
  },
  {
    "text": "the context I want to get on the context. I want to get the sharding config. Right. Or",
    "start": "2284699",
    "end": "2290500"
  },
  {
    "text": "is it the opposite way? Yeah. Yeah. And I want to get the tag. And why",
    "start": "2290500",
    "end": "2297449"
  },
  {
    "text": "are you context is not named like that. It's named config. That's why you are screaming at",
    "start": "2297449",
    "end": "2304549"
  },
  {
    "text": "me. You're right. Okay. And this should return",
    "start": "2304550",
    "end": "2308616"
  },
  {
    "text": "the sharding port. Okay. It took a while for me to get it. And in",
    "start": "2310550",
    "end": "2317050"
  },
  {
    "text": "the end, this should look like a layer that produces never can result",
    "start": "2317050",
    "end": "2325883"
  },
  {
    "text": "into a serve error, which means that when we start our RPC server, we can get into an error",
    "start": "2325883",
    "end": "2332350"
  },
  {
    "text": "and then we can assume both the sharding config in order to know which port we need the server to",
    "start": "2332350",
    "end": "2337750"
  },
  {
    "text": "start in. And we use the sharding because that is the actual service we are using. Okay. Now",
    "start": "2337750",
    "end": "2346116"
  },
  {
    "text": "everything seems to be fine. Okay. So this will actually replace the HTTP live. I was trying to",
    "start": "2346116",
    "end": "2354300"
  },
  {
    "text": "write before. HTTP live. Okay. And now ideally,",
    "start": "2354300",
    "end": "2363550"
  },
  {
    "text": "ideally, if I do exactly like before and say port 1234 right now,",
    "start": "2364500",
    "end": "2373183"
  },
  {
    "text": "okay, we can see that now it's actually listening on the correct port,",
    "start": "2373183",
    "end": "2378083"
  },
  {
    "text": "not in on the wrong one. Like as before. Okay. Okay. And now",
    "start": "2378399",
    "end": "2384566"
  },
  {
    "text": "you can see that the shard matter. I know less that now this the",
    "start": "2384566",
    "end": "2390616"
  },
  {
    "text": "server port is alive and assigned some shard IDs. Perfect. It's working",
    "start": "2390616",
    "end": "2397649"
  },
  {
    "text": "guys. Okay. So now slowly but",
    "start": "2397649",
    "end": "2403015"
  },
  {
    "text": "surely we will see that some entities will be moved from this server to this one. As you can",
    "start": "2403016",
    "end": "2408849"
  },
  {
    "text": "see just the shard ID that contains the entity number one has been",
    "start": "2408850",
    "end": "2414516"
  },
  {
    "text": "moved and now both of the server are doing some work.",
    "start": "2414516",
    "end": "2418800"
  },
  {
    "text": "This is only request for the counter number one. And now also the six which",
    "start": "2421083",
    "end": "2426649"
  },
  {
    "text": "just got assigned as I was picking and this one did the other ones. Okay. So just a",
    "start": "2426649",
    "end": "2435799"
  },
  {
    "text": "moment for a quick sip. If someone has some question and then",
    "start": "2435800",
    "end": "2441250"
  },
  {
    "text": "we'll go back into coding something",
    "start": "2441250",
    "end": "2446116"
  },
  {
    "text": "for the communication between the shard manager and the actual pods.",
    "start": "2448083",
    "end": "2453750"
  },
  {
    "text": "Okay. So let's stop everything. So I",
    "start": "2464016",
    "end": "2470283"
  },
  {
    "text": "don't want to waste resources. Okay. This is stopped. Stop. Okay.",
    "start": "2470283",
    "end": "2476866"
  },
  {
    "text": "Okay. So I see that we also have another issue that we need to fix.",
    "start": "2486383",
    "end": "2492399"
  },
  {
    "text": "That is that a fiber has stopped but instead we want",
    "start": "2494616",
    "end": "2500600"
  },
  {
    "text": "to do like this effect config. Yeah, I",
    "start": "2500616",
    "end": "2514599"
  },
  {
    "text": "tried that before. But the",
    "start": "2514600",
    "end": "2520000"
  },
  {
    "text": "thing is that this is not a layer. So you need to convert this into a layer. And I dumbly converted that",
    "start": "2520000",
    "end": "2527965"
  },
  {
    "text": "into a layer by using the effect and using the tag itself.",
    "start": "2527966",
    "end": "2531899"
  },
  {
    "text": "There are indeed better ways to do that. But for now, that works. So let's start with something",
    "start": "2533983",
    "end": "2540149"
  },
  {
    "text": "that works and then move on. As always, I say that with Effect, you don't need to",
    "start": "2540149",
    "end": "2545816"
  },
  {
    "text": "actually learn all of the APIs. I already know that flatmap has",
    "start": "2545816",
    "end": "2551250"
  },
  {
    "text": "something that if you give an instance or a box of A, you will get something a",
    "start": "2551266",
    "end": "2558199"
  },
  {
    "text": "computation. You can chain a computation that takes the A and produces a box of B and",
    "start": "2558199",
    "end": "2563316"
  },
  {
    "text": "obtain a box of B as an end of the computation that changed all of them together. And that's",
    "start": "2563316",
    "end": "2569716"
  },
  {
    "text": "what I do. I know that I know flatMap. I know that I can construct a layer from an effect. So",
    "start": "2569716",
    "end": "2576015"
  },
  {
    "text": "I construct a layer here and then I flatmapped with another layer. There may be indeed better",
    "start": "2576016",
    "end": "2581382"
  },
  {
    "text": "ways to make this code readable. This is unreadable. I definitely agree with you. But let's start",
    "start": "2581383",
    "end": "2587649"
  },
  {
    "text": "with something and then improve. Okay. So I was saying that I did not",
    "start": "2587649",
    "end": "2595216"
  },
  {
    "text": "expect when I stopped one of the choose server",
    "start": "2595216",
    "end": "2599566"
  },
  {
    "text": "everything to go down. Because ideally we",
    "start": "2600866",
    "end": "2606366"
  },
  {
    "text": "need our Pods RPC. Upon error,",
    "start": "2606366",
    "end": "2611265"
  },
  {
    "text": "it needs to retry again sending the message. Okay. And",
    "start": "2611683",
    "end": "2619566"
  },
  {
    "text": "ideally I don't remember doing something like \"please die when this happens\".",
    "start": "2619566",
    "end": "2627966"
  },
  {
    "text": "But yeah, let's see.",
    "start": "2627983",
    "end": "2636366"
  },
  {
    "text": "The thing may be that when there are transport errors, we need",
    "start": "2636766",
    "end": "2644466"
  },
  {
    "text": "to see how effectRPC handles transport errors.",
    "start": "2644466",
    "end": "2650183"
  },
  {
    "text": "Because the thing may be that maybe effectRPC by default, when there are errors, it goes",
    "start": "2651133",
    "end": "2657566"
  },
  {
    "text": "into a defect. And that's what maybe I",
    "start": "2657766",
    "end": "2665466"
  },
  {
    "text": "don't want. I want instead to retry again. So let's see.",
    "start": "2665466",
    "end": "2671483"
  },
  {
    "text": "effectRPC. Let's say resolver. Yeah, it",
    "start": "2671500",
    "end": "2686283"
  },
  {
    "text": "goes on or die. Yeah. Yeah,",
    "start": "2686283",
    "end": "2691682"
  },
  {
    "text": "process is fine. Or die. Yeah. But I don't want to die. Because if this",
    "start": "2691683",
    "end": "2697765"
  },
  {
    "text": "dies, okay, then the client fails. So instead of dying,",
    "start": "2697766",
    "end": "2704283"
  },
  {
    "text": "I want to retry. So here when I said logError,",
    "start": "2706250",
    "end": "2714099"
  },
  {
    "text": "I could say that upon error, I want to",
    "start": "2714399",
    "end": "2721666"
  },
  {
    "text": "retry again. So catch all calls. And then I want to",
    "start": "2721666",
    "end": "2727550"
  },
  {
    "text": "log the error and also move that into a failure.",
    "start": "2727899",
    "end": "2732000"
  },
  {
    "text": "I want to move the error into a failure. Effect.fail of this error.",
    "start": "2741316",
    "end": "2746300"
  },
  {
    "text": "And now these will actually produce a failure of type cause of never.",
    "start": "2747083",
    "end": "2751515"
  },
  {
    "text": "But then I would say effect retry.",
    "start": "2753866",
    "end": "2758250"
  },
  {
    "text": "Or maybe instead of retrying this API, ideally the pods API, let's",
    "start": "2764233",
    "end": "2771083"
  },
  {
    "text": "say what is the expected type signature. Yeah, they cannot fail. So",
    "start": "2771083",
    "end": "2779283"
  },
  {
    "text": "they need to retry upon some network error.",
    "start": "2779283",
    "end": "2783100"
  },
  {
    "text": "So retry. While to.",
    "start": "2785866",
    "end": "2791966"
  },
  {
    "text": "Let's move this.",
    "start": "2792000",
    "end": "2805050"
  },
  {
    "text": "Okay. And why are you not okay with",
    "start": "2820416",
    "end": "2825566"
  },
  {
    "text": "this? Oh, because the retry. Oh, right. Yeah, because catch all calls.",
    "start": "2825566",
    "end": "2833416"
  },
  {
    "text": "Yeah, retry. Well, so instead of doing this, we should be something like Effect.map.",
    "start": "2833783",
    "end": "2840216"
  },
  {
    "text": "Error cause. Which is also better.",
    "start": "2842699",
    "end": "2847083"
  },
  {
    "text": "we have the error. Effect.fail.",
    "start": "2850399",
    "end": "2853866"
  },
  {
    "text": "Error. Okay. Oh, it's a map. So I want this to be a",
    "start": "2855750",
    "end": "2864750"
  },
  {
    "text": "cause. Okay. So instead of map, I want Effect.",
    "start": "2864750",
    "end": "2869800"
  },
  {
    "text": "I remember having something like.",
    "start": "2869850",
    "end": "2876699"
  },
  {
    "text": "Tap error. Yeah, this accesses the error on error. Yeah. The thing is that I want",
    "start": "2877983",
    "end": "2884250"
  },
  {
    "text": "this to be something that is retried. Yeah, the best way maybe is that I can catch. I can",
    "start": "2884250",
    "end": "2893100"
  },
  {
    "text": "catch upon the errors and then move. Yeah. Let's see.",
    "start": "2893100",
    "end": "2899883"
  },
  {
    "text": "So here we can have the defects. Okay. So this computation can die. Okay. This can die. So",
    "start": "2904050",
    "end": "2912166"
  },
  {
    "text": "we provide the environment and we say, okay, if you die, just log it and",
    "start": "2912466",
    "end": "2918366"
  },
  {
    "text": "then we move the error into",
    "start": "2918783",
    "end": "2923883"
  },
  {
    "text": "the failure channel. Okay. And then ideally this retry. Yeah, this",
    "start": "2923883",
    "end": "2932000"
  },
  {
    "text": "should return the type I expected, right? Yeah. void. Cause. Oh, retry. Yeah.",
    "start": "2932000",
    "end": "2939215"
  },
  {
    "text": "Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. I see. I see. I see. The thing is that retry will tell to",
    "start": "2939216",
    "end": "2945416"
  },
  {
    "text": "retry, but is not actually.",
    "start": "2945416",
    "end": "2946800"
  },
  {
    "text": "Retry. This is something more like not retrying, but",
    "start": "2953016",
    "end": "2959716"
  },
  {
    "text": "recomputing everything. So I need maybe to write a custom schedule for this. Yeah. I need to write a custom schedule because. This is the",
    "start": "2960149",
    "end": "2970416"
  },
  {
    "text": "red sweater. Yeah. This is the red sweater. Yeah, exactly.",
    "start": "2970416",
    "end": "2975265"
  },
  {
    "text": "Oh, I, by the way, this is the red sweater. Yeah. The red sweater that I",
    "start": "2976300",
    "end": "2983050"
  },
  {
    "text": "always use when I go to speaking into conferences. Yeah. Oh, I",
    "start": "2983050",
    "end": "2991149"
  },
  {
    "text": "also have as a complimentary. I have also my bold cap. As a complimentary accessory.",
    "start": "2991149",
    "end": "2999649"
  },
  {
    "text": "But yeah. So going back to what I was thinking of",
    "start": "3001383",
    "end": "3007483"
  },
  {
    "text": "is that I have this computation that can go on a die and I want these to be",
    "start": "3007583",
    "end": "3015183"
  },
  {
    "text": "eventually repeated if we get in something that is a failure.",
    "start": "3015183",
    "end": "3021083"
  },
  {
    "text": "Okay. Because this competition, this trade that we provide",
    "start": "3021716",
    "end": "3027016"
  },
  {
    "text": "is something that is expected to be retried upon a failure. Okay. So the pod",
    "start": "3027416",
    "end": "3032500"
  },
  {
    "text": "straight is something that expects the under under really the",
    "start": "3032500",
    "end": "3038350"
  },
  {
    "text": "transport underneath to retry if something goes on error. Okay. So if we have a die that happens",
    "start": "3038350",
    "end": "3046699"
  },
  {
    "text": "for some reason, we need them to sleep and to try again. So maybe the best thing we can do is have",
    "start": "3046699",
    "end": "3054699"
  },
  {
    "text": "a look at schedule. I am not waiting with schedule. So",
    "start": "3054699",
    "end": "3059850"
  },
  {
    "text": "let's, let's learn about it altogether.",
    "start": "3059850",
    "end": "3064616"
  },
  {
    "text": "So scheduling is basically this rate of effect when you can construct by using the",
    "start": "3065899",
    "end": "3072250"
  },
  {
    "text": "schedule API, you can construct things like repeat or whatever, and they can be",
    "start": "3072250",
    "end": "3080500"
  },
  {
    "text": "easily composed. So let's see from the API references",
    "start": "3080500",
    "end": "3086300"
  },
  {
    "text": "of effect. What are the things that comes from schedule? Request schedule. Okay.",
    "start": "3087183",
    "end": "3094449"
  },
  {
    "text": "Okay. So we need to have",
    "start": "3094949",
    "end": "3101666"
  },
  {
    "text": "something like, we need to retry.",
    "start": "3101666",
    "end": "3106416"
  },
  {
    "text": "And I'm not sure if we can use like,",
    "start": "3109166",
    "end": "3118300"
  },
  {
    "text": "while we lay, let's see, modify on decision, recur. Yeah, I think that maybe in the",
    "start": "3118666",
    "end": "3125866"
  },
  {
    "text": "effect documentation, we have something better than what I'm trying to do. Let's say",
    "start": "3125866",
    "end": "3131066"
  },
  {
    "text": "schedule. The petition, the built-in schedules.",
    "start": "3131066",
    "end": "3135349"
  },
  {
    "text": "This is the one that recurs, repeat. Yeah. The thing is that I want to move",
    "start": "3139566",
    "end": "3146116"
  },
  {
    "text": "catch all codes, E and I then fail. And",
    "start": "3147100",
    "end": "3154066"
  },
  {
    "text": "then that is fine. And then I want to build a schedule that retries. Yeah, retries forever.",
    "start": "3154066",
    "end": "3163750"
  },
  {
    "text": "Yeah. So maybe you can see something like import",
    "start": "3164199",
    "end": "3168966"
  },
  {
    "text": "everything as schedule from effect,",
    "start": "3169666",
    "end": "3176266"
  },
  {
    "text": "effect schedule. And then",
    "start": "3179116",
    "end": "3181966"
  },
  {
    "text": "effect.retry. And here ideally it",
    "start": "3184483",
    "end": "3190250"
  },
  {
    "text": "also accepts schedule. Okay. And schedule.",
    "start": "3190250",
    "end": "3194383"
  },
  {
    "text": "dot retry, it's called forever, I think.",
    "start": "3197350",
    "end": "3204916"
  },
  {
    "text": "The schedule is always a compression, count of repeats, 0, 1, 2. Yeah.",
    "start": "3207916",
    "end": "3211216"
  },
  {
    "text": "I think that ideally this should be the one that I am looking for.",
    "start": "3215816",
    "end": "3220083"
  },
  {
    "text": "Oh, but still the schedule doesn't erase my",
    "start": "3224616",
    "end": "3229800"
  },
  {
    "text": "my error from the channel. Let's think about it.",
    "start": "3229816",
    "end": "3238350"
  },
  {
    "text": "Okay. I have something that fails with the die. I can use catchAllCause to convert that",
    "start": "3241066",
    "end": "3247066"
  },
  {
    "text": "failure in the die channel into a failure. And then I want",
    "start": "3247750",
    "end": "3255050"
  },
  {
    "text": "to retry on the error. Yeah.",
    "start": "3255050",
    "end": "3256783"
  },
  {
    "text": "I want to retry while true. Yeah. But",
    "start": "3265699",
    "end": "3272765"
  },
  {
    "text": "this doesn't make the compiler happy because actually",
    "start": "3272766",
    "end": "3276800"
  },
  {
    "text": "this should be something like maybe there are better options in the retry. Let's see. Retry",
    "start": "3277899",
    "end": "3283449"
  },
  {
    "text": "schedule options. Retry options. Retry options.",
    "start": "3283750",
    "end": "3291316"
  },
  {
    "text": "Yeah. We need to do something like, yeah, effects or die. This will make the",
    "start": "3296483",
    "end": "3305500"
  },
  {
    "text": "compiler happy. Yeah. It's horrible right now, but",
    "start": "3305500",
    "end": "3313149"
  },
  {
    "text": "it works. I need to fix this. This is definitely horrible to write, but",
    "start": "3313149",
    "end": "3329250"
  },
  {
    "text": "yeah, I need to find a better way to do that. A schedule would be, I think, the best",
    "start": "3329250",
    "end": "3335083"
  },
  {
    "text": "way. I need to first convert the failure and then provide the schedule. And yeah, I need",
    "start": "3335083",
    "end": "3341265"
  },
  {
    "text": "the schedule to be something that basically never",
    "start": "3341266",
    "end": "3346283"
  },
  {
    "text": "outputs the error. But yeah, I will have a look at that next time. I want to first finish this task.",
    "start": "3346383",
    "end": "3352800"
  },
  {
    "text": "Okay. So let's try again the situation we had before. So ideally the shard manager is",
    "start": "3353983",
    "end": "3360116"
  },
  {
    "text": "still is now running. Okay. shard manager",
    "start": "3360149",
    "end": "3365816"
  },
  {
    "text": "is now loaded. Now I want to run my first shard. Okay. And now the shard has",
    "start": "3365816",
    "end": "3372416"
  },
  {
    "text": "started. Now I want to message with the entities.",
    "start": "3372416",
    "end": "3377066"
  },
  {
    "text": "So I send. Okay. And now it's working. Now I start the second",
    "start": "3378466",
    "end": "3384116"
  },
  {
    "text": "shard. It's registering itself.",
    "start": "3384116",
    "end": "3388550"
  },
  {
    "text": "Eventually this shard manager will trigger a rebalance event. Let's see if it starts.",
    "start": "3390366",
    "end": "3396899"
  },
  {
    "text": "Ideally it should in less than two minutes. Yeah, here it is.",
    "start": "3399533",
    "end": "3405182"
  },
  {
    "text": "Here we have a rebalance. Eventually in the next rebalance, we will",
    "start": "3405600",
    "end": "3411199"
  },
  {
    "text": "have some entities that will be moved from your server to the new one. Let's see.",
    "start": "3411199",
    "end": "3421466"
  },
  {
    "text": "And three, two, one. Okay. As you can see right now, it's retrying forever,",
    "start": "3423683",
    "end": "3430416"
  },
  {
    "text": "but it's not able to contact the entity. Oh, and that is actually true. That's",
    "start": "3432600",
    "end": "3444083"
  },
  {
    "text": "actually true because we don't need to, we don't need to coach or catch all",
    "start": "3444083",
    "end": "3451166"
  },
  {
    "text": "cause. Yeah. We need to catch all defect",
    "start": "3451166",
    "end": "3457149"
  },
  {
    "text": "because there are only the defects that",
    "start": "3457366",
    "end": "3462966"
  },
  {
    "text": "we need to move into the alert channel. Yeah.",
    "start": "3462966",
    "end": "3467583"
  },
  {
    "text": "Uh, this, this I touched, but I shouldn't",
    "start": "3478683",
    "end": "3484316"
  },
  {
    "text": "because the ping function is expected.",
    "start": "3484316",
    "end": "3491000"
  },
  {
    "text": "Yeah. To fail. Okay. So I changed more than I should. Okay. So I",
    "start": "3492300",
    "end": "3498515"
  },
  {
    "text": "say that when we have a defect, I move that into the failure and I retry when I have failure.",
    "start": "3498516",
    "end": "3503783"
  },
  {
    "text": "Okay. Or I die. Okay. Same goes for assigned shots. Ping is an",
    "start": "3503783",
    "end": "3512899"
  },
  {
    "text": "exception because ping can fail. It is expected to fail with the pod and available exception",
    "start": "3512899",
    "end": "3518866"
  },
  {
    "text": "where the pod is no longer available. And then we also have send and get state",
    "start": "3518866",
    "end": "3525083"
  },
  {
    "text": "that is expected to fail as well.",
    "start": "3525083",
    "end": "3531483"
  },
  {
    "text": "So here, maybe we can",
    "start": "3531500",
    "end": "3539399"
  },
  {
    "text": "just catch all cause.",
    "start": "3539399",
    "end": "3541250"
  },
  {
    "text": "And let's see. As you can see, the send and get state is",
    "start": "3546949",
    "end": "3555599"
  },
  {
    "text": "allowed to fail. Yeah. And the fail that can have",
    "start": "3555600",
    "end": "3560566"
  },
  {
    "text": "is a shutting section. Okay. So that goes for the ping. Okay. But the",
    "start": "3560916",
    "end": "3567199"
  },
  {
    "text": "assign, they cannot. Okay. So here we have, instead of retrying",
    "start": "3567199",
    "end": "3575116"
  },
  {
    "text": "forever, we just move that into something like",
    "start": "3575116",
    "end": "3579883"
  },
  {
    "text": "catch all cause. That will be catch all",
    "start": "3580616",
    "end": "3585699"
  },
  {
    "text": "defect in something like effect.fail.",
    "start": "3585699",
    "end": "3590116"
  },
  {
    "text": "ShardingException will be something like a podunavailable exception.",
    "start": "3592649",
    "end": "3601099"
  },
  {
    "text": "Okay. And this requires what? The pod address. Okay. We have pod address. Okay.",
    "start": "3608466",
    "end": "3616366"
  },
  {
    "text": "And ideally, let's try to have a look at",
    "start": "3616399",
    "end": "3624583"
  },
  {
    "text": "back at all of them again. Okay. We have assignedShard. This operation cannot fail.",
    "start": "3624583",
    "end": "3629983"
  },
  {
    "text": "And it should be retried. Okay.",
    "start": "3631899",
    "end": "3634866"
  },
  {
    "text": "And we have unassigned shard that cannot fail. And then we have ping that can fail,",
    "start": "3637983",
    "end": "3643300"
  },
  {
    "text": "but can fail with a typed error of pod and available exception. So we need to catch all",
    "start": "3643366",
    "end": "3648716"
  },
  {
    "text": "the defects and transform them into podUnavailbleException",
    "start": "3648783",
    "end": "3656383"
  },
  {
    "text": "And we have send and get state that can result in some errors. And if we have some defects,",
    "start": "3656383",
    "end": "3662266"
  },
  {
    "text": "we've moved that into some pod UnvailableException. Okay. The only",
    "start": "3662266",
    "end": "3670016"
  },
  {
    "text": "thing that I'm not fully sure about is that, is that really true that assign shard and an assigned",
    "start": "3670016",
    "end": "3676765"
  },
  {
    "text": "shard cannot fail. Let's go back into our",
    "start": "3676766",
    "end": "3683983"
  },
  {
    "text": "methods. Assign shard. And let's see where we",
    "start": "3683983",
    "end": "3689916"
  },
  {
    "text": "use those. The shard measure.",
    "start": "3689916",
    "end": "3692350"
  },
  {
    "text": "And if you see, we actually expect those to fail.",
    "start": "3696399",
    "end": "3701882"
  },
  {
    "text": "We actually expect those to fail. Yeah. So let me see. We",
    "start": "3705149",
    "end": "3713199"
  },
  {
    "text": "expect those to fail. Yeah. So given we expect those to fail, the type signature that we",
    "start": "3713199",
    "end": "3719283"
  },
  {
    "text": "have defined are completely wrong because we said that they can never fail, but they actually",
    "start": "3719283",
    "end": "3725399"
  },
  {
    "text": "can fail. And we also handled in the past that if we have a failure, we",
    "start": "3725399",
    "end": "3732166"
  },
  {
    "text": "map in here. Yeah. And yeah, we should have the cause exactly. Yeah. The exception. Yeah. But",
    "start": "3732166",
    "end": "3741149"
  },
  {
    "text": "no longer receive the exception. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah.",
    "start": "3741149",
    "end": "3747816"
  },
  {
    "text": "So maybe, maybe, maybe we can also update the trade, the pods",
    "start": "3751300",
    "end": "3758000"
  },
  {
    "text": "trade right now and say that this actually can fail and say, the",
    "start": "3758000",
    "end": "3766316"
  },
  {
    "text": "exception dot pod unavailable exception.",
    "start": "3766316",
    "end": "3768965"
  },
  {
    "text": "Pod unavailable exception. Okay. And ideally here we already handled that. And",
    "start": "3773416",
    "end": "3780500"
  },
  {
    "text": "right now what we need to do is just move, catch",
    "start": "3780500",
    "end": "3787649"
  },
  {
    "text": "all defect to produce a new",
    "start": "3787649",
    "end": "3791465"
  },
  {
    "text": "sharding exception, pod unavailable exception. And the pod address is the one we were trying to",
    "start": "3793533",
    "end": "3799483"
  },
  {
    "text": "message with. And we do not retry. We do",
    "start": "3799516",
    "end": "3804699"
  },
  {
    "text": "nothing. Okay. So what we change is that",
    "start": "3804699",
    "end": "3810682"
  },
  {
    "text": "now in case of defect, that is because Effect RPC produces a defect",
    "start": "3810683",
    "end": "3817583"
  },
  {
    "text": "in case of some network issue. Now in case of defect, what we do, we catch the defect and we",
    "start": "3817583",
    "end": "3825183"
  },
  {
    "text": "log the defect and we convert that into a pod",
    "start": "3825183",
    "end": "3830399"
  },
  {
    "text": "unavailable exception. Yep. And we can do",
    "start": "3830949",
    "end": "3836666"
  },
  {
    "text": "the same for the unassigned.",
    "start": "3836666",
    "end": "3839149"
  },
  {
    "text": "Okay. So moment of truth. Let's try again. We start the shard manager.",
    "start": "3843583",
    "end": "3849500"
  },
  {
    "text": "Okay. And then we start our first shard.",
    "start": "3853066",
    "end": "3856849"
  },
  {
    "text": "Now it's registered to the shard manager. And then",
    "start": "3858083",
    "end": "3861949"
  },
  {
    "text": "we start other shard and now it's registered. Okay. And then we start the",
    "start": "3863500",
    "end": "3870750"
  },
  {
    "text": "connect, which will send messages. Okay. Right now it seems to",
    "start": "3870750",
    "end": "3876716"
  },
  {
    "text": "work everything. We have some entities, entity number five and number nine on this process. And",
    "start": "3876716",
    "end": "3882916"
  },
  {
    "text": "all the other one are on this process. So let's try to kill",
    "start": "3882916",
    "end": "3888666"
  },
  {
    "text": "this one gracefully. Okay. Now we get",
    "start": "3889583",
    "end": "3898316"
  },
  {
    "text": "notified that there was an unhealthy pod, the one that we killed. And what happened is now our system is",
    "start": "3898316",
    "end": "3910382"
  },
  {
    "text": "back working perfectly because what happened is that",
    "start": "3910383",
    "end": "3915849"
  },
  {
    "text": "basically we can go back to our TLdraw if I still have it. Oh, I closed it. Okay. And here it is.",
    "start": "3917983",
    "end": "3931083"
  },
  {
    "text": "Okay. So what happened right now is that we started the first pod. We pinged it. It worked. Okay.",
    "start": "3931649",
    "end": "3937216"
  },
  {
    "text": "And then we started our second pod. Okay. We moved some entities from one pod to another, and",
    "start": "3937566",
    "end": "3945516"
  },
  {
    "text": "then we stopped again this pod. So the shard manager figured out that now this pod is not available.",
    "start": "3945516",
    "end": "3952816"
  },
  {
    "text": "And then the entities were moved from this pod to this pod.",
    "start": "3953699",
    "end": "3958083"
  },
  {
    "text": "That's perfect. I think. Yeah. Okay. And",
    "start": "3960316",
    "end": "3965882"
  },
  {
    "text": "it's not ugly as I thought. Okay. Sure. This can be improved because basically all of this is error",
    "start": "3965883",
    "end": "3977449"
  },
  {
    "text": "management. But yeah. And",
    "start": "3977449",
    "end": "3983666"
  },
  {
    "text": "then I think that we are fine.",
    "start": "3983666",
    "end": "3986899"
  },
  {
    "text": "And this work. Okay. Let's see what we have changed. We have changed the signature of our pod",
    "start": "3990000",
    "end": "3998166"
  },
  {
    "text": "straight in order to account for a Pod unavailable exception.",
    "start": "3998166",
    "end": "4001816"
  },
  {
    "text": "And that's fine. And then we changed a little. Yeah. Our HTTP",
    "start": "4003750",
    "end": "4010000"
  },
  {
    "text": "live in order to actually use the scheduling config part. This is not",
    "start": "4010000",
    "end": "4015199"
  },
  {
    "text": "so clean, but we will clean it up later. And then we changed the pod RPC because",
    "start": "4015199",
    "end": "4022683"
  },
  {
    "text": "right now we need to handle the defects and move that into a pod unavailable exception. We",
    "start": "4022683",
    "end": "4029266"
  },
  {
    "text": "didn't touch the ping because that was working before. And we also catch right now the defects",
    "start": "4029266",
    "end": "4036916"
  },
  {
    "text": "with the pod unavailable exception. And that's it. Yeah. So progress. This is",
    "start": "4036916",
    "end": "4047015"
  },
  {
    "text": "fine. It works. Yes. Okay. I'm going to sing those changes.",
    "start": "4047016",
    "end": "4052983"
  },
  {
    "text": "What happened?",
    "start": "4055699",
    "end": "4061066"
  },
  {
    "text": "Oh, I see. Yeah. I see what it is. Yeah.",
    "start": "4072566",
    "end": "4078149"
  },
  {
    "text": "I'm going to fix it later. Yeah. I see. I see. I see. I see. Yeah. Okay.",
    "start": "4078699",
    "end": "4086050"
  },
  {
    "text": "Yeah. I cleaned up something. Yeah.",
    "start": "4088216",
    "end": "4090699"
  },
  {
    "text": "Yeah. Yeah. Yeah. I will fix this later. Yeah. Okay. So we fixed this.",
    "start": "4093366",
    "end": "4104916"
  },
  {
    "text": "And I think that the other thing that I want to start maybe working on is",
    "start": "4106616",
    "end": "4113865"
  },
  {
    "text": "maybe we can fix this issue. Yeah. I know. I know. I know. I want to",
    "start": "4116616",
    "end": "4126016"
  },
  {
    "text": "see what the issues are. Yeah. Yeah. This one. This one. This one. Yeah.",
    "start": "4126016",
    "end": "4135050"
  },
  {
    "text": "Yeah. I need to fix that one later. Yeah. Because I tried something off camera and",
    "start": "4136016",
    "end": "4142549"
  },
  {
    "text": "I break everything as always. But yeah. Yeah. Let's keep the current git branch",
    "start": "4142550",
    "end": "4150083"
  },
  {
    "text": "and do not care about the old one. Okay. So we moved basically the shard",
    "start": "4150083",
    "end": "4157600"
  },
  {
    "text": "sharding service now to be a router. And I think that the next thing that I",
    "start": "4157600",
    "end": "4165316"
  },
  {
    "text": "want to start tackle is the shard manager",
    "start": "4165316",
    "end": "4169882"
  },
  {
    "text": "protocol, which is also HTTP, but I want",
    "start": "4170383",
    "end": "4175615"
  },
  {
    "text": "to move into RPC. Yeah.",
    "start": "4175616",
    "end": "4180666"
  },
  {
    "text": "I want that to move into RPC. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah.",
    "start": "4182516",
    "end": "4189149"
  },
  {
    "text": "Yeah. Yeah. Yeah. Yeah. Yeah. So let's see how we can start that.",
    "start": "4189149",
    "end": "4196966"
  },
  {
    "text": "I think that we can start by defining the protocol has we did in here by using schema type",
    "start": "4197516",
    "end": "4203616"
  },
  {
    "text": "requests. So shard manager protocol. I have a name this to",
    "start": "4203616",
    "end": "4209966"
  },
  {
    "text": "RPC. Okay. And now we need to move. No, I",
    "start": "4209983",
    "end": "4218282"
  },
  {
    "text": "don't want to update here. Okay. And now we need to move those as tagged requests before we",
    "start": "4218283",
    "end": "4225300"
  },
  {
    "text": "just use the plain schema with data. Now I want to use tagged request export",
    "start": "4225300",
    "end": "4231383"
  },
  {
    "text": "class register extends schema",
    "start": "4231383",
    "end": "4237515"
  },
  {
    "text": "dot taggedrequest here of type register.",
    "start": "4239899",
    "end": "4245083"
  },
  {
    "text": "And is a register. That's my manager. One that's memory is",
    "start": "4247466",
    "end": "4253050"
  },
  {
    "text": "here. The tag. The tag is Effect cluster node shard manager",
    "start": "4253050",
    "end": "4263050"
  },
  {
    "text": "protocol RPC register. And can it fail?",
    "start": "4263050",
    "end": "4273966"
  },
  {
    "text": "No, it shouldn't for now.",
    "start": "4274000",
    "end": "4282550"
  },
  {
    "text": "Let's say schema.never. Or maybe we can just use, let's see if it",
    "start": "4282550",
    "end": "4290149"
  },
  {
    "text": "can or if it can't. Let's have a look. A shard manager protocol. The shard",
    "start": "4290149",
    "end": "4298216"
  },
  {
    "text": "manager protocol uses",
    "start": "4298216",
    "end": "4299515"
  },
  {
    "text": "uses with services. Shard manager. unregister. Yeah. This cannot fail.",
    "start": "4303666",
    "end": "4309666"
  },
  {
    "text": "And this cannot fail. Okay. So those are unfailable ones.",
    "start": "4310766",
    "end": "4315716"
  },
  {
    "text": "So schema.void. They don't return",
    "start": "4318750",
    "end": "4326416"
  },
  {
    "text": "nothing. Sorry, the schema.never they not fail.",
    "start": "4326416",
    "end": "4331216"
  },
  {
    "text": "And schema dot void as return type. And the fields that we have are just the pod",
    "start": "4332066",
    "end": "4339550"
  },
  {
    "text": "of a type pod dot schema. And that's it. And the same goes for",
    "start": "4339550",
    "end": "4350282"
  },
  {
    "text": "unregister. We can just rename that easier.",
    "start": "4350283",
    "end": "4356683"
  },
  {
    "text": "unregister. We can do unregister.",
    "start": "4357666",
    "end": "4363716"
  },
  {
    "text": "Okay. We're missing classes. Yeah. Okay.",
    "start": "4366600",
    "end": "4375500"
  },
  {
    "text": "Now we have a notify unhealthy pod. Notify an unhealthy pod. And as you can see,",
    "start": "4375850",
    "end": "4392615"
  },
  {
    "text": "those messages are more like notifications that goes from the client to the server or vice",
    "start": "4392616",
    "end": "4400149"
  },
  {
    "text": "versa. The server register itself or the cluster pod, the register itself to a shard manager",
    "start": "4400149",
    "end": "4406416"
  },
  {
    "text": "or unregistered himself to the shard manager or one pod to notify that there is",
    "start": "4406416",
    "end": "4411916"
  },
  {
    "text": "another pod that is not able to contact. And there is also,",
    "start": "4411916",
    "end": "4416966"
  },
  {
    "text": "oh, there is get assignment. Yeah. We have assignments result. Okay.",
    "start": "4417183",
    "end": "4423250"
  },
  {
    "text": "So we have the API called get assignments.",
    "start": "4424649",
    "end": "4430166"
  },
  {
    "text": "Get assignments. Get assignments. And this returns on, has an",
    "start": "4434066",
    "end": "4440216"
  },
  {
    "text": "array of tuples of schema option schema. But I think that this was",
    "start": "4440216",
    "end": "4447083"
  },
  {
    "text": "just a workaround because at the time I didn't have",
    "start": "4447083",
    "end": "4451449"
  },
  {
    "text": "final references. At that time I didn't.",
    "start": "4452300",
    "end": "4457682"
  },
  {
    "text": "Oh, this is actually done. Don't use. Okay. This is not used so we can just don't",
    "start": "4457683",
    "end": "4467566"
  },
  {
    "text": "care about this and maybe tackle it later.",
    "start": "4467566",
    "end": "4472300"
  },
  {
    "text": "Okay. And then let's go here. Oh, that's",
    "start": "4474449",
    "end": "4481000"
  },
  {
    "text": "why it was not. Yeah. Array from. Yeah. And I got assignments. Yeah. It is",
    "start": "4481000",
    "end": "4487583"
  },
  {
    "text": "actually an hash map of the shard ID and has an option of",
    "start": "4487583",
    "end": "4492183"
  },
  {
    "text": "our pod address. Yeah. Okay. Nevermind. We actually have that. But",
    "start": "4492616",
    "end": "4499050"
  },
  {
    "text": "back in the days, schema didn't have hash map. Now I think that schema has",
    "start": "4499050",
    "end": "4504083"
  },
  {
    "text": "hash map. So the result now can be schema.hashMap",
    "start": "4504083",
    "end": "4509966"
  },
  {
    "text": "of shard ID dot schema schema dot option",
    "start": "4511316",
    "end": "4517566"
  },
  {
    "text": "of pod address dot schema. Yeah. And that's it.",
    "start": "4517566",
    "end": "4527566"
  },
  {
    "text": "Uh, hash map. Oh, key and value. Yeah.",
    "start": "4530283",
    "end": "4532916"
  },
  {
    "text": "You want an object. That's fine by me. I can say key is this and value is this.",
    "start": "4535949",
    "end": "4543883"
  },
  {
    "text": "Okay. And, uh, have as a parameter. Did",
    "start": "4543916",
    "end": "4554683"
  },
  {
    "text": "we send something as a parameter for this? Get assignments.",
    "start": "4554683",
    "end": "4557800"
  },
  {
    "text": "Get assignments. No, we have no parameters. So we can just",
    "start": "4559750",
    "end": "4565149"
  },
  {
    "text": "remove the pod from here. And this one. Okay. And this is really",
    "start": "4565149",
    "end": "4572216"
  },
  {
    "text": "nice and clean right now. We can register a pod. We can register a pod or we can notify that a",
    "start": "4572216",
    "end": "4577916"
  },
  {
    "text": "pod is not healthy, is not live. And then we get the assignments back. Okay. So this is basically the",
    "start": "4577916",
    "end": "4584765"
  },
  {
    "text": "protocol for register thing or whatever that happens between the pod and the shard manager. Okay. And",
    "start": "4584766",
    "end": "4592700"
  },
  {
    "text": "then we have to implement a shard manager RPC instead of",
    "start": "4592700",
    "end": "4599350"
  },
  {
    "text": "HTTP. I don't want to update those. How",
    "start": "4599700",
    "end": "4607166"
  },
  {
    "text": "much time we have left. I think that we have left 20 minutes. Yeah. Okay. So this was my",
    "start": "4607166",
    "end": "4618266"
  },
  {
    "text": "old implementation that relied on",
    "start": "4618266",
    "end": "4622399"
  },
  {
    "text": "effect platform HTTP server. But now I would want to move to",
    "start": "4623816",
    "end": "4629399"
  },
  {
    "text": "something more similar to this where I export a router. So I think that I will start by copying the required",
    "start": "4629399",
    "end": "4636850"
  },
  {
    "text": "dependencies from here. Okay. And remove the double one. I can",
    "start": "4636850",
    "end": "4643316"
  },
  {
    "text": "see pipe layer and create server we don't need anymore.",
    "start": "4643316",
    "end": "4648365"
  },
  {
    "text": "Sharding manager protocol. Yep. Internal server we don't need",
    "start": "4649383",
    "end": "4654615"
  },
  {
    "text": "anymore. Now we just care about exporting our router. So we need",
    "start": "4654616",
    "end": "4662450"
  },
  {
    "text": "something like this and this. And just copy paste everything because I",
    "start": "4662450",
    "end": "4669600"
  },
  {
    "text": "am a lazy developer and lazy developer just copy and paste this data. So we have",
    "start": "4669600",
    "end": "4676399"
  },
  {
    "text": "shard manager protocol. I removed RPC. Yeah. I removed RPC. Yeah.",
    "start": "4676399",
    "end": "4683949"
  },
  {
    "text": "So I can rename this one. I named shard manager protocol without RPC. Okay. That's it.",
    "start": "4684500",
    "end": "4693149"
  },
  {
    "text": "And then I have shard manager protocol without HTTP.",
    "start": "4694183",
    "end": "4698200"
  },
  {
    "text": "And then I need to handle things like shard manager protocol. And we start my great code",
    "start": "4700500",
    "end": "4707850"
  },
  {
    "text": "for from the old things. So what happens when a user asks for a register? We have our register",
    "start": "4707850",
    "end": "4714700"
  },
  {
    "text": "request in here. And what we do is we access the shard manager API. So we access the shard",
    "start": "4714866",
    "end": "4724450"
  },
  {
    "text": "manager API. And then from the shard manager, this is the shard manager. We",
    "start": "4724633",
    "end": "4733366"
  },
  {
    "text": "called the dot register and we say request.pod. That's it.",
    "start": "4733366",
    "end": "4744899"
  },
  {
    "text": "And now we need to do the same thing for all of the APIs. So the register we have done. And then we",
    "start": "4746250",
    "end": "4755049"
  },
  {
    "text": "do the same for unregister, which I would say we can",
    "start": "4755049",
    "end": "4760383"
  },
  {
    "text": "just copy and paste from register to unregister. Unregister. Okay.",
    "start": "4760466",
    "end": "4770100"
  },
  {
    "text": "And then we notify unhealthy pod,",
    "start": "4771216",
    "end": "4776816"
  },
  {
    "text": "which is called by one pod when it sees that another pod is not responding. Notify unhealthy pod",
    "start": "4777149",
    "end": "4783016"
  },
  {
    "text": "and we have in the request ideally request dot pod. Yeah. but",
    "start": "4783183",
    "end": "4791782"
  },
  {
    "text": "should take the pod address. So pod address. And goes for here. Dot address.",
    "start": "4791783",
    "end": "4799399"
  },
  {
    "text": "Beautify, unregister. Oh, they all take a pod address instead of a pod. Yeah. So",
    "start": "4807933",
    "end": "4814216"
  },
  {
    "text": "register takes a pod address. No, pod address. No, pod address. Yeah. So let's change the",
    "start": "4814216",
    "end": "4820600"
  },
  {
    "text": "protocol and say that we have a pod address. Everything. Yeah.",
    "start": "4820600",
    "end": "4829083"
  },
  {
    "text": "NotifyUnhealthyPod. Because a pod has both the address and if I",
    "start": "4829083",
    "end": "4834183"
  },
  {
    "text": "remember correctly also have things like a diversion. Yeah. But we",
    "start": "4834183",
    "end": "4841316"
  },
  {
    "text": "don't care about that. Okay. So let's say register requires a pod, but",
    "start": "4841316",
    "end": "4847350"
  },
  {
    "text": "unregister and notify requires a pod address. So we can change the protocol to just",
    "start": "4847350",
    "end": "4853149"
  },
  {
    "text": "require register pod address. Okay. And here we have a pod",
    "start": "4853149",
    "end": "4860483"
  },
  {
    "text": "address. Let's rename this as pod address. Pod address.",
    "start": "4860950",
    "end": "4868016"
  },
  {
    "text": "And now here instead of doing this dance, we do pod address.",
    "start": "4870666",
    "end": "4875649"
  },
  {
    "text": "Pod address. Okay. And the last thing that we need to implement is get assignments.",
    "start": "4878850",
    "end": "4885316"
  },
  {
    "text": "And guess what? Copy paste. Get",
    "start": "4886733",
    "end": "4892066"
  },
  {
    "text": "assignments. We have the request. We call get assignments and has",
    "start": "4892066",
    "end": "4898366"
  },
  {
    "text": "actually no data in the request. So I actually don't care about it. And that's it. We have now",
    "start": "4899016",
    "end": "4906599"
  },
  {
    "text": "our router that handles these kind of requests and requires in the effect",
    "start": "4906700",
    "end": "4913799"
  },
  {
    "text": "context a shard manager in order to construct a router. So we can",
    "start": "4913799",
    "end": "4920066"
  },
  {
    "text": "call this shard manager RPC.",
    "start": "4920066",
    "end": "4927365"
  },
  {
    "text": "And then shard manager RPC request.",
    "start": "4935883",
    "end": "4939383"
  },
  {
    "text": "Okay. So we're saying shard manager RPC request.",
    "start": "4941649",
    "end": "4946583"
  },
  {
    "text": "And then we don't need anything more from here.",
    "start": "4949149",
    "end": "4953016"
  },
  {
    "text": "Everything dies and goes away.",
    "start": "4956166",
    "end": "4959316"
  },
  {
    "text": "Okay. We can also remove these dependencies that are not required",
    "start": "4962116",
    "end": "4967799"
  },
  {
    "text": "anymore. And that's it.",
    "start": "4967799",
    "end": "4970199"
  },
  {
    "text": "Okay. And now we need to create the actual client. So shard",
    "start": "4973899",
    "end": "4981233"
  },
  {
    "text": "manager client RPC. Yes.",
    "start": "4981233",
    "end": "4984166"
  },
  {
    "text": "Maybe I want to, I want to remove sharding.",
    "start": "4986566",
    "end": "4990483"
  },
  {
    "text": "Shard manager service RPC maybe.",
    "start": "4992966",
    "end": "4995099"
  },
  {
    "text": "Yeah. I want to name this to something like service RPC. Yeah.",
    "start": "5001350",
    "end": "5009033"
  },
  {
    "text": "Shard manager service RPC. This seems something more fitting. And then I want",
    "start": "5010433",
    "end": "5019399"
  },
  {
    "text": "shard manager client RPC.",
    "start": "5019399",
    "end": "5022133"
  },
  {
    "text": "Okay. And this is basically the thing, same thing that pods does.",
    "start": "5029366",
    "end": "5034616"
  },
  {
    "text": "But the thing here is that here we actually know that the shard",
    "start": "5037133",
    "end": "5044316"
  },
  {
    "text": "manager URL is fixed. Okay. So instead of doing all the dance that I",
    "start": "5044316",
    "end": "5051783"
  },
  {
    "text": "did there, we can make it more simple.",
    "start": "5051783",
    "end": "5056466"
  },
  {
    "text": "But I still need a way to create a client. Yeah. So I",
    "start": "5058883",
    "end": "5064532"
  },
  {
    "text": "still need to have a way to say that I want to create a client that",
    "start": "5064533",
    "end": "5071916"
  },
  {
    "text": "is a agnostic of whatever are the protocol of the RPC.",
    "start": "5071916",
    "end": "5079433"
  },
  {
    "text": "Yeah. So I can do something like rename this whole one for now and say",
    "start": "5079916",
    "end": "5086299"
  },
  {
    "text": "export function and shard manager client",
    "start": "5087033",
    "end": "5094799"
  },
  {
    "text": "RPC. And as a parameter, these will take in some function",
    "start": "5094799",
    "end": "5101015"
  },
  {
    "text": "that will create client. And the client will be something like that.",
    "start": "5103366",
    "end": "5109182"
  },
  {
    "text": "Client will be something like I already have it there. Yeah.",
    "start": "5113733",
    "end": "5121433"
  },
  {
    "text": "Yeah. So the client is some a function that when called will",
    "start": "5130666",
    "end": "5136166"
  },
  {
    "text": "actually give a request of type sharding manager protocol not HTTP but RPC.",
    "start": "5136166",
    "end": "5143816"
  },
  {
    "text": "Give a request of this kind RPC request.",
    "start": "5149183",
    "end": "5154216"
  },
  {
    "text": "Okay. Will return the request result also says. Okay. I need to import request",
    "start": "5158850",
    "end": "5166783"
  },
  {
    "text": "from effect request. Request. Okay.",
    "start": "5168799",
    "end": "5175015"
  },
  {
    "text": "And it's not called shard manager service. Shard manager protocol. Yeah. Shard",
    "start": "5177283",
    "end": "5184599"
  },
  {
    "text": "manager protocol without RPC.",
    "start": "5184600",
    "end": "5186200"
  },
  {
    "text": "No. Rename symbol. Yes. Okay. Shard",
    "start": "5189933",
    "end": "5196716"
  },
  {
    "text": "manager protocol request. Right. Shard manager.",
    "start": "5196716",
    "end": "5201833"
  },
  {
    "text": "Oh. Because I need to import those for yeah. Yeah. Yeah. Yeah.",
    "start": "5206783",
    "end": "5212233"
  },
  {
    "text": "Yeah. Shard manager because the thing is that with effect RPC you",
    "start": "5212916",
    "end": "5218116"
  },
  {
    "text": "need to import the typings from the actual router not the protocol. The protocol are just",
    "start": "5218116",
    "end": "5223399"
  },
  {
    "text": "the messages. The single messages. Okay. Those are the messages. And then I have the service",
    "start": "5223399",
    "end": "5229966"
  },
  {
    "text": "RPC which creates the router and the types for the router and the same goes in here. And then in",
    "start": "5229966",
    "end": "5236716"
  },
  {
    "text": "the client I need to import shard manager service RPC. Service RPC.",
    "start": "5236716",
    "end": "5244733"
  },
  {
    "text": "Shard manager service RPC request. Okay. Now it makes sense. Okay.",
    "start": "5247416",
    "end": "5252183"
  },
  {
    "text": "Perfect. And then here I create a new layer.effect that can go in the same",
    "start": "5253383",
    "end": "5261833"
  },
  {
    "text": "way. Same exact way. Yeah.",
    "start": "5261833",
    "end": "5266299"
  },
  {
    "text": "And I save return this. Okay. But here I will say that I do not",
    "start": "5269883",
    "end": "5276032"
  },
  {
    "text": "have to create a client. I just need to access the config. Okay.",
    "start": "5276033",
    "end": "5281299"
  },
  {
    "text": "And yeah. Oh yeah. To be honest I need",
    "start": "5283016",
    "end": "5287833"
  },
  {
    "text": "these to be a function like make client that takes in",
    "start": "5288883",
    "end": "5298466"
  },
  {
    "text": "the shard manager URI.",
    "start": "5300733",
    "end": "5303500"
  },
  {
    "text": "Shard manager URI string.",
    "start": "5306033",
    "end": "5310016"
  },
  {
    "text": "And then what I will do is that upon a register I will then client I need to",
    "start": "5315516",
    "end": "5323866"
  },
  {
    "text": "make client make client by passing the shard config.shard manager",
    "start": "5323866",
    "end": "5334716"
  },
  {
    "text": "URI. And this is not an effect. It's just a function.",
    "start": "5334716",
    "end": "5340966"
  },
  {
    "text": "Okay. And then I can do things like register is just calling",
    "start": "5341433",
    "end": "5347115"
  },
  {
    "text": "client and new shard manager",
    "start": "5347116",
    "end": "5355233"
  },
  {
    "text": "protocol not HTTP.",
    "start": "5356883",
    "end": "5362500"
  },
  {
    "text": "I need to import that shard manager protocol.",
    "start": "5365500",
    "end": "5369183"
  },
  {
    "text": "And then call shard manager protocol.register. And the pod is",
    "start": "5375799",
    "end": "5383916"
  },
  {
    "text": "oh I actually forgot",
    "start": "5386549",
    "end": "5389133"
  },
  {
    "text": "that I needed to look what it was before. Yeah. Yeah. Yeah. Yeah.",
    "start": "5391766",
    "end": "5396899"
  },
  {
    "text": "Yeah. What it was before. Shard manager client.",
    "start": "5396899",
    "end": "5400100"
  },
  {
    "text": "I used to do it. Yeah. It was something like pod dot make. Okay. Pod address config dot",
    "start": "5402799",
    "end": "5407816"
  },
  {
    "text": "server. Okay. So it was like this. Yeah.",
    "start": "5407866",
    "end": "5411600"
  },
  {
    "text": "It means to register and it's a register.",
    "start": "5413016",
    "end": "5416266"
  },
  {
    "text": "Okay. So the pod is this.",
    "start": "5418116",
    "end": "5424233"
  },
  {
    "text": "And void never R is not assignable to",
    "start": "5427133",
    "end": "5432365"
  },
  {
    "text": "type void never never. Yeah. Because I",
    "start": "5432366",
    "end": "5436483"
  },
  {
    "text": "said here R but I actually don't want",
    "start": "5437866",
    "end": "5444133"
  },
  {
    "text": "are I want never. Okay. That's fine. And then",
    "start": "5444133",
    "end": "5451033"
  },
  {
    "text": "cannot be used as value as important. That's not too I want this as a value.",
    "start": "5452000",
    "end": "5458383"
  },
  {
    "text": "Okay. And that's it. And the same goes for all the other",
    "start": "5458716",
    "end": "5465083"
  },
  {
    "text": "requests that I have. So unregister as",
    "start": "5465083",
    "end": "5470166"
  },
  {
    "text": "you can guess is the same thing. But goes unregister and doesn't require a",
    "start": "5470166",
    "end": "5483799"
  },
  {
    "text": "pod but a pod address. And then we have the same for notify",
    "start": "5483799",
    "end": "5491833"
  },
  {
    "text": "unhealthy pod that uses notify unhealthy pod.",
    "start": "5491833",
    "end": "5499883"
  },
  {
    "text": "And then finally we have get assignments. Okay. And this actually what does is",
    "start": "5501100",
    "end": "5510699"
  },
  {
    "text": "assignments. Okay. So this is just calling the method and",
    "start": "5510700",
    "end": "5519716"
  },
  {
    "text": "returning data. So get assignments will be just something like a client.",
    "start": "5520166",
    "end": "5528299"
  },
  {
    "text": "New shard manager protocol.",
    "start": "5528333",
    "end": "5534033"
  },
  {
    "text": "Yeah. Dot get assignments with no parameters.",
    "start": "5534533",
    "end": "5540083"
  },
  {
    "text": "Yep. And we need to remove this piece of old code. And that's it.",
    "start": "5541933",
    "end": "5547983"
  },
  {
    "text": "This will die and get removed. Okay. Are we missing a semicolon? Yes.",
    "start": "5549466",
    "end": "5556966"
  },
  {
    "text": "We're missing a parenthesis. Okay. And semicolon. Yeah. So this function takes in the sharding",
    "start": "5557100",
    "end": "5565532"
  },
  {
    "text": "manager. The make client which is basically given the sharding manager URI. I will build a client.",
    "start": "5565533",
    "end": "5571899"
  },
  {
    "text": "Okay. And then uses that client that can handle this kind of",
    "start": "5572899",
    "end": "5578066"
  },
  {
    "text": "request to actually call the function over the server. And",
    "start": "5578399",
    "end": "5586066"
  },
  {
    "text": "then it's fine. Perfect. Now we need to remove some",
    "start": "5586066",
    "end": "5592683"
  },
  {
    "text": "unused imports. That's it.",
    "start": "5592683",
    "end": "5596533"
  },
  {
    "text": "And then let me just lower the volume of the music. Okay. And then what we do here is the",
    "start": "5598700",
    "end": "5609583"
  },
  {
    "text": "sharding manager client is ideally completed. So we did everything in here. We need",
    "start": "5609583",
    "end": "5617633"
  },
  {
    "text": "just to update the examples, I think. Okay. So now it's not HTTP, but it's",
    "start": "5617633",
    "end": "5628515"
  },
  {
    "text": "shard manager client RPC. Sharding manager client RPC.",
    "start": "5628516",
    "end": "5634299"
  },
  {
    "text": "And we need to now make",
    "start": "5635283",
    "end": "5642583"
  },
  {
    "text": "sharding manager client RPC. Sharding manager client RPC.",
    "start": "5642583",
    "end": "5648066"
  },
  {
    "text": "And this will take in a shard manager",
    "start": "5648100",
    "end": "5657266"
  },
  {
    "text": "URI. And we need to create a client with that.",
    "start": "5657266",
    "end": "5664966"
  },
  {
    "text": "Oh, I also already asked about better typings for this, the team. So I need to update this",
    "start": "5667299",
    "end": "5673899"
  },
  {
    "text": "one because I actually know what I need to do. And here I need to actually call the shard manager",
    "start": "5674000",
    "end": "5681483"
  },
  {
    "text": "URI. Perfect. And that's it, I think.",
    "start": "5681766",
    "end": "5688583"
  },
  {
    "text": "Yeah. And this piece of code goes in here. And here,",
    "start": "5688783",
    "end": "5697500"
  },
  {
    "text": "here, what do you need? For me. What are you complaining for? Oh,",
    "start": "5697516",
    "end": "5705615"
  },
  {
    "text": "we have some error. Yeah. But that is because right now we changed something. And now we need to update the",
    "start": "5705616",
    "end": "5711816"
  },
  {
    "text": "shard manager client RPC. And we need them to",
    "start": "5711816",
    "end": "5721166"
  },
  {
    "text": "update this one. And we are fine.",
    "start": "5721166",
    "end": "5725600"
  },
  {
    "text": "Okay. So what's begging you?",
    "start": "5727583",
    "end": "5731766"
  },
  {
    "text": "What are you not happy with? Okay. So here are you saying, oh, shard",
    "start": "5733566",
    "end": "5740833"
  },
  {
    "text": "manager HTTP. No, it's shard manager R client RPC.",
    "start": "5740833",
    "end": "5745266"
  },
  {
    "text": "Shard manager service RPC. Yeah. Shard manager service RPC. And",
    "start": "5746700",
    "end": "5753600"
  },
  {
    "text": "here we need to do the same dance we did before with the HTTP live.",
    "start": "5753600",
    "end": "5759016"
  },
  {
    "text": "But for the manger, ideally this part of code that I am",
    "start": "5760733",
    "end": "5765883"
  },
  {
    "text": "building inside of the examples will be something provided by the library. But yeah,",
    "start": "5766549",
    "end": "5772600"
  },
  {
    "text": "I need to create import create server.",
    "start": "5773333",
    "end": "5775983"
  },
  {
    "text": "I need also import the thing. I need also import manager config.",
    "start": "5779700",
    "end": "5785833"
  },
  {
    "text": "I think, yeah, already had manager config. Okay. HTTP server.",
    "start": "5786083",
    "end": "5795816"
  },
  {
    "text": "HTTP client.",
    "start": "5797666",
    "end": "5798700"
  },
  {
    "text": "Client already had. Okay. HTTP router. HTTP router and solver from RPC. Yep.",
    "start": "5803483",
    "end": "5812399"
  },
  {
    "text": "Makes sense. And instead of being sharding service RPC is now",
    "start": "5812700",
    "end": "5819983"
  },
  {
    "text": "shard manager RPC. Yes. And what I'm",
    "start": "5820016",
    "end": "5827716"
  },
  {
    "text": "still missing and node HTTP server and context node HTTP server.",
    "start": "5827716",
    "end": "5834816"
  },
  {
    "text": "Okay. And the context. And that goes from manager",
    "start": "5840633",
    "end": "5849233"
  },
  {
    "text": "config.managerConfig.",
    "start": "5849233",
    "end": "5852365"
  },
  {
    "text": "API port. Yeah.",
    "start": "5860883",
    "end": "5863899"
  },
  {
    "text": "API port. Yes. That's it. And we need now to provide in the same way we do here.",
    "start": "5868816",
    "end": "5877000"
  },
  {
    "text": "We need to provide HTTP live. Yeah.",
    "start": "5878033",
    "end": "5881766"
  },
  {
    "text": "And we start with",
    "start": "5889283",
    "end": "5891033"
  },
  {
    "text": "we have an Effect, we try to provide HTTP live. Which requires",
    "start": "5908566",
    "end": "5917000"
  },
  {
    "text": "measure config and the shard manager. Okay. So shard manager",
    "start": "5917200",
    "end": "5924266"
  },
  {
    "text": "dot live. It's in here. And manager config. We have in here.",
    "start": "5924266",
    "end": "5932583"
  },
  {
    "text": "Okay. So you should be fine.",
    "start": "5933016",
    "end": "5936916"
  },
  {
    "text": "All right. It's the HTTP live. Requires what? Requires",
    "start": "5943033",
    "end": "5951865"
  },
  {
    "text": "manager config and shard manager. Okay. Yeah. We need to fix those examples. We have",
    "start": "5952233",
    "end": "5958200"
  },
  {
    "text": "on render code in here. Yeah. We need to fix those. Ah. Yeah. Yeah. Yeah. I definitely need",
    "start": "5959899",
    "end": "5966683"
  },
  {
    "text": "to fix those. Yeah. Okay. So instead of doing something like the live layer. Yeah. We did",
    "start": "5966683",
    "end": "5975133"
  },
  {
    "text": "scope.discard. Provided the HTTPLive. Yeah. Yeah. Yeah. Yeah.",
    "start": "5975133",
    "end": "5983782"
  },
  {
    "text": "Maybe we can do a layer.scoped Discard. Okay. This fixes",
    "start": "5984233",
    "end": "5993433"
  },
  {
    "text": "it. But we need to improve the examples in this. Oh, hey there. Jean-Baptiste",
    "start": "5993433",
    "end": "6000966"
  },
  {
    "text": "Nice to meet you. How's it going?",
    "start": "6000966",
    "end": "6004233"
  },
  {
    "text": "So right now we should have fixed everything and we should be using",
    "start": "6006483",
    "end": "6013333"
  },
  {
    "text": "effect RPC right now. So let's start.",
    "start": "6013366",
    "end": "6019183"
  },
  {
    "text": "Let's start the shard manager. Okay. The shard manager is listening on port 8080. Perfect. And",
    "start": "6020483",
    "end": "6031733"
  },
  {
    "text": "then the shard manager is listening on port 8080.",
    "start": "6031733",
    "end": "6037633"
  },
  {
    "text": "Yeah. But I think that in the manager config alongside of that",
    "start": "6038166",
    "end": "6044866"
  },
  {
    "text": "we have the API port. Yeah. That's fine. Oh, it's really your first",
    "start": "6044866",
    "end": "6051816"
  },
  {
    "text": "time on Twitch ever. Hope that will be some good memory",
    "start": "6051816",
    "end": "6057583"
  },
  {
    "text": "for you. So we are working on effect cluster. And as you can see, I have",
    "start": "6057583",
    "end": "6065466"
  },
  {
    "text": "orrendous example because I am in the middle of factoring. As",
    "start": "6065466",
    "end": "6070916"
  },
  {
    "text": "I have discussed, I have before I had an architecture that relied on effect HTTP in order to",
    "start": "6070916",
    "end": "6077383"
  },
  {
    "text": "speak with different pods. And now I want to migrate everything to use effect RPC instead. So I can use",
    "start": "6077383",
    "end": "6085616"
  },
  {
    "text": "whatever protocol you want. And I am in the middle of testing if everything worked. But by the",
    "start": "6085616",
    "end": "6097000"
  },
  {
    "text": "mean of things, I see that here I expected something else",
    "start": "6097000",
    "end": "6101015"
  },
  {
    "text": "because I see 8080 is listening on port 8080, but ideally the",
    "start": "6102083",
    "end": "6108916"
  },
  {
    "text": "default config for the client says that sharding config. Oh, we also",
    "start": "6108916",
    "end": "6120500"
  },
  {
    "text": "need to prepend something else. Yeah. It's 8080, but we also need to prepend API rest.",
    "start": "6120500",
    "end": "6126766"
  },
  {
    "text": "Yeah. Okay. Because in the shard manager config, I have that.",
    "start": "6127100",
    "end": "6133016"
  },
  {
    "text": "Yeah. Okay. Shard manager config. Yeah. I",
    "start": "6133033",
    "end": "6145433"
  },
  {
    "text": "only have the API port. Yeah. Oh yeah, but I don't... Yeah, it should",
    "start": "6145433",
    "end": "6152966"
  },
  {
    "text": "work because... Let's see. Let's try. It's easier to try. Yeah. Now we have a shard. Yeah, the",
    "start": "6152966",
    "end": "6159833"
  },
  {
    "text": "shard started and registered itself. So we did the shake between the shard manager and the",
    "start": "6159833",
    "end": "6167066"
  },
  {
    "text": "pod that we just started. The registered himself. Yeah. Okay.",
    "start": "6167066",
    "end": "6171265"
  },
  {
    "text": "Perfect. That's really, really perfect. Okay. And then we want to",
    "start": "6172233",
    "end": "6179516"
  },
  {
    "text": "start the process that sends messages. Let's see. And it's working.",
    "start": "6179516",
    "end": "6186383"
  },
  {
    "text": "It's asking the pod. Okay. And then let's start another pod",
    "start": "6186933",
    "end": "6194183"
  },
  {
    "text": "on a different port. And it registered",
    "start": "6194316",
    "end": "6204316"
  },
  {
    "text": "itself. It received. That's perfect. That's really, really",
    "start": "6204316",
    "end": "6213316"
  },
  {
    "text": "perfect. It has new shard assigned. Yeah. And the process",
    "start": "6213316",
    "end": "6218383"
  },
  {
    "text": "that was sending messages is still sending messages. Right now, so if I stop the first",
    "start": "6218383",
    "end": "6223466"
  },
  {
    "text": "shard manager, I should see that now I",
    "start": "6223883",
    "end": "6229916"
  },
  {
    "text": "hear it's retrying forever. Okay. Until",
    "start": "6229916",
    "end": "6233566"
  },
  {
    "text": "now the shard manager figured out that one pod is not alive anymore. And slowly but surely",
    "start": "6236799",
    "end": "6245000"
  },
  {
    "text": "it's moving all the entities over the new pod. So let's see.",
    "start": "6245216",
    "end": "6256500"
  },
  {
    "text": "Yeah. As you can see, it's moving slowly, but surely the pods. Yeah. It's working guys. Yes. So I think that unfortunately for",
    "start": "6265866",
    "end": "6275516"
  },
  {
    "text": "you, you joined quite later, unfortunately, but you can still see the bottom of the recording of",
    "start": "6275516",
    "end": "6284865"
  },
  {
    "text": "the session. And what we accomplished today is we finally moved everything away from effect",
    "start": "6284866",
    "end": "6294015"
  },
  {
    "text": "HTTP and we now rely on effect RPC. So that means that",
    "start": "6294016",
    "end": "6298966"
  },
  {
    "text": "we could also, that could be very interesting. I know that there is someone that is very",
    "start": "6299916",
    "end": "6305916"
  },
  {
    "text": "interesting in this, uh, run a cluster inside the browser between different",
    "start": "6305916",
    "end": "6311782"
  },
  {
    "text": "workers, because now we are not tied to having this one being",
    "start": "6311783",
    "end": "6316899"
  },
  {
    "text": "something HTTP. It can be, for example, post message",
    "start": "6316899",
    "end": "6322133"
  },
  {
    "text": "between two different windows.",
    "start": "6322633",
    "end": "6326432"
  },
  {
    "text": "And it should work ideally.",
    "start": "6334716",
    "end": "6337883"
  },
  {
    "text": "So this is something that we will work towards in next streams. So move into a",
    "start": "6342000",
    "end": "6351233"
  },
  {
    "text": "browser environment. And everything work. But yeah, I think",
    "start": "6351233",
    "end": "6358183"
  },
  {
    "text": "that we have been streaming for two, almost two hours after now. So yeah, I think that I'm",
    "start": "6358183",
    "end": "6366200"
  },
  {
    "text": "gonna have lunch and thank you again to everyone who joined.",
    "start": "6366200",
    "end": "6371532"
  },
  {
    "text": "Hope you had fun. Hope you learned something. As always,",
    "start": "6373750",
    "end": "6378066"
  },
  {
    "text": "we will see you next Thursday, I hope. And then thank you very",
    "start": "6379299",
    "end": "6385883"
  },
  {
    "text": "much to everyone. Hope that you have fun. We have finally moved to effect RPC. So can't wait to",
    "start": "6385883",
    "end": "6393216"
  },
  {
    "text": "work next week on cleaning up all of those dirty examples",
    "start": "6393216",
    "end": "6398466"
  },
  {
    "text": "we have right now and have something that works better. Thanks again, everyone for joining and",
    "start": "6398483",
    "end": "6405816"
  },
  {
    "text": "see you next time. Bye-bye everyone.",
    "start": "6406316",
    "end": "6408583"
  }
]
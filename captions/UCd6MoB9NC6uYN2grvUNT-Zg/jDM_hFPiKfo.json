[
  {
    "text": "All of our foundation\nmodels are trained on AWS.",
    "start": "166",
    "end": "2836"
  },
  {
    "text": "Amazon S3 was,",
    "start": "2836",
    "end": "4421"
  },
  {
    "text": "is a very important\ncomponent when training Gen AI,",
    "start": "4421",
    "end": "7799"
  },
  {
    "text": "we ingest petabytes of\nmultimodality data, so images,",
    "start": "7799",
    "end": "11886"
  },
  {
    "text": "videos, music, everything stored\non Amazon S3",
    "start": "11886",
    "end": "15681"
  },
  {
    "text": "and then streamlined into",
    "start": "15682",
    "end": "16933"
  },
  {
    "text": "supercomputers on top of\nAmazon SageMaker.",
    "start": "16933",
    "end": "19477"
  },
  {
    "text": "And then eventually we're producing",
    "start": "19477",
    "end": "22605"
  },
  {
    "text": "a foundation model. Working\nwith AWS allowed Bria",
    "start": "22605",
    "end": "26860"
  },
  {
    "text": "to scale from one foundation\nmodel to today, up",
    "start": "26860",
    "end": "30447"
  },
  {
    "text": "to 50 foundation models trained\non top of supercomputers",
    "start": "30447",
    "end": "34617"
  },
  {
    "text": "and using petabytes of data.",
    "start": "34617",
    "end": "36244"
  },
  {
    "text": "At Bria, we utilize Apache Iceberg tables",
    "start": "36244",
    "end": "40165"
  },
  {
    "text": "for our data catalog, meaning\nthat we're taking petabytes",
    "start": "40165",
    "end": "43334"
  },
  {
    "text": "of data and we formalize\nthem into tables in order",
    "start": "43334",
    "end": "47255"
  },
  {
    "text": "for a research team to be\nable to curate real time",
    "start": "47255",
    "end": "51426"
  },
  {
    "text": "and query the database to create subset",
    "start": "51426",
    "end": "54303"
  },
  {
    "text": "for training dataset.",
    "start": "54304",
    "end": "55680"
  },
  {
    "text": "We started with low\ncompute, low amount of data",
    "start": "55680",
    "end": "58850"
  },
  {
    "text": "and the models were very light and small.",
    "start": "58850",
    "end": "61560"
  },
  {
    "text": "And today the models are huge",
    "start": "61561",
    "end": "63313"
  },
  {
    "text": "and we are using supercomputers\nto train these huge models.",
    "start": "63313",
    "end": "66775"
  },
  {
    "text": "I think working at Bria\nputs me in the frontier",
    "start": "66775",
    "end": "69778"
  },
  {
    "text": "of a very exciting times\nof generative AI era.",
    "start": "69778",
    "end": "73615"
  },
  {
    "text": "I think it's very exciting\ntimes and a good place to be at.",
    "start": "73615",
    "end": "76201"
  }
]
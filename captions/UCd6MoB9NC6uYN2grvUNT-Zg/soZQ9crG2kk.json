[
  {
    "text": "hello everyone",
    "start": "960",
    "end": "2639"
  },
  {
    "text": "have you ever thought of unveiling",
    "start": "2639",
    "end": "4620"
  },
  {
    "text": "insights from your unstructured data",
    "start": "4620",
    "end": "6420"
  },
  {
    "text": "such as PDF documents let's go a step",
    "start": "6420",
    "end": "9480"
  },
  {
    "text": "over and see how we can start chatting",
    "start": "9480",
    "end": "11880"
  },
  {
    "text": "with your PDF documents using Amazon",
    "start": "11880",
    "end": "13860"
  },
  {
    "text": "open search Service as the vector",
    "start": "13860",
    "end": "15660"
  },
  {
    "text": "database I am Praveen Mohan working as",
    "start": "15660",
    "end": "18420"
  },
  {
    "text": "an analytics specialist with AWS so now",
    "start": "18420",
    "end": "21359"
  },
  {
    "text": "we will look into a short demo on a",
    "start": "21359",
    "end": "23400"
  },
  {
    "text": "chart-based web application where you",
    "start": "23400",
    "end": "25619"
  },
  {
    "text": "can simply start uploading your PDF",
    "start": "25619",
    "end": "27480"
  },
  {
    "text": "documents and ask questions based upon",
    "start": "27480",
    "end": "30000"
  },
  {
    "text": "the PDF content and let Amazon open",
    "start": "30000",
    "end": "32279"
  },
  {
    "text": "search service to answer them",
    "start": "32279",
    "end": "35780"
  },
  {
    "text": "this is the web application with the",
    "start": "37260",
    "end": "39480"
  },
  {
    "text": "chat interface I have hosted this on an",
    "start": "39480",
    "end": "41940"
  },
  {
    "text": "ec2 instance and the web UA is built",
    "start": "41940",
    "end": "44640"
  },
  {
    "text": "with streamlit",
    "start": "44640",
    "end": "45899"
  },
  {
    "text": "so this left panel you can simply start",
    "start": "45899",
    "end": "48840"
  },
  {
    "text": "browsing your files from a local system",
    "start": "48840",
    "end": "50820"
  },
  {
    "text": "and upload the PDFs to the application",
    "start": "50820",
    "end": "53340"
  },
  {
    "text": "and once the processing is over you can",
    "start": "53340",
    "end": "55620"
  },
  {
    "text": "simply start asking questions",
    "start": "55620",
    "end": "58140"
  },
  {
    "text": "so for the demo I will be using two PDF",
    "start": "58140",
    "end": "61379"
  },
  {
    "text": "documents as a knowledge base",
    "start": "61379",
    "end": "64378"
  },
  {
    "text": "so we'll just have a quick look on those",
    "start": "64379",
    "end": "66900"
  },
  {
    "text": "documents one talks about the",
    "start": "66900",
    "end": "69600"
  },
  {
    "text": "operational best practices for Amazon",
    "start": "69600",
    "end": "71460"
  },
  {
    "text": "open search service this is available",
    "start": "71460",
    "end": "73760"
  },
  {
    "text": "publicly available in the official",
    "start": "73760",
    "end": "75960"
  },
  {
    "text": "documentation",
    "start": "75960",
    "end": "77220"
  },
  {
    "text": "so it talks about the different uh best",
    "start": "77220",
    "end": "80400"
  },
  {
    "text": "practices and recommendations for Amazon",
    "start": "80400",
    "end": "83040"
  },
  {
    "text": "open search service",
    "start": "83040",
    "end": "84780"
  },
  {
    "text": "the next one is the Amazon open search",
    "start": "84780",
    "end": "86880"
  },
  {
    "text": "service FAQs again this is the publicly",
    "start": "86880",
    "end": "89759"
  },
  {
    "text": "available document so uh both the",
    "start": "89759",
    "end": "93060"
  },
  {
    "text": "documents talks about the open search",
    "start": "93060",
    "end": "94860"
  },
  {
    "text": "best practices and a lot of details",
    "start": "94860",
    "end": "97439"
  },
  {
    "text": "about open search in general",
    "start": "97439",
    "end": "99540"
  },
  {
    "text": "so this is uh these two web pages have",
    "start": "99540",
    "end": "102600"
  },
  {
    "text": "converted into PDF documents and we will",
    "start": "102600",
    "end": "104939"
  },
  {
    "text": "be using these two PDF documents as",
    "start": "104939",
    "end": "107400"
  },
  {
    "text": "knowledge base",
    "start": "107400",
    "end": "110000"
  },
  {
    "text": "so let's start uploading both the files",
    "start": "110820",
    "end": "113100"
  },
  {
    "text": "here",
    "start": "113100",
    "end": "115280"
  },
  {
    "text": "yeah so when you click process here what",
    "start": "119040",
    "end": "123060"
  },
  {
    "text": "happens begin the screen is that",
    "start": "123060",
    "end": "125399"
  },
  {
    "text": "both the PDF documents will be",
    "start": "125399",
    "end": "127979"
  },
  {
    "text": "undergoing some transformation stages",
    "start": "127979",
    "end": "129840"
  },
  {
    "text": "starting from uh chunking the PDFs into",
    "start": "129840",
    "end": "132900"
  },
  {
    "text": "smaller documents and then",
    "start": "132900",
    "end": "135200"
  },
  {
    "text": "these documents are converted into",
    "start": "135200",
    "end": "137340"
  },
  {
    "text": "vectors using an embedding model and",
    "start": "137340",
    "end": "139560"
  },
  {
    "text": "finally those vectors are indexed into",
    "start": "139560",
    "end": "141000"
  },
  {
    "text": "Open Source service index so now we have",
    "start": "141000",
    "end": "144060"
  },
  {
    "text": "the processing is over where we got a",
    "start": "144060",
    "end": "146580"
  },
  {
    "text": "message that we can start searching on",
    "start": "146580",
    "end": "148560"
  },
  {
    "text": "your PDFs",
    "start": "148560",
    "end": "149819"
  },
  {
    "text": "so let's start with a very uh simple",
    "start": "149819",
    "end": "152819"
  },
  {
    "text": "question something like",
    "start": "152819",
    "end": "155400"
  },
  {
    "text": "what is",
    "start": "155400",
    "end": "157800"
  },
  {
    "text": "open search",
    "start": "157800",
    "end": "159840"
  },
  {
    "text": "used for",
    "start": "159840",
    "end": "162560"
  },
  {
    "text": "yeah so now we got an answer I think it",
    "start": "165660",
    "end": "168900"
  },
  {
    "text": "looks more relevant right so uh the",
    "start": "168900",
    "end": "170879"
  },
  {
    "text": "answer tells us that open source can be",
    "start": "170879",
    "end": "173280"
  },
  {
    "text": "used for log analytics supplication",
    "start": "173280",
    "end": "175019"
  },
  {
    "text": "search Enterprise search and so on",
    "start": "175019",
    "end": "177239"
  },
  {
    "text": "yeah so this is uh actually coming from",
    "start": "177239",
    "end": "180180"
  },
  {
    "text": "the Amazon Open Source service FAQ",
    "start": "180180",
    "end": "183239"
  },
  {
    "text": "document that we just uploaded so now we",
    "start": "183239",
    "end": "185879"
  },
  {
    "text": "will go uh for the next question",
    "start": "185879",
    "end": "187940"
  },
  {
    "text": "something like",
    "start": "187940",
    "end": "190140"
  },
  {
    "text": "how to secure it",
    "start": "190140",
    "end": "194959"
  },
  {
    "text": "yeah now",
    "start": "197700",
    "end": "199739"
  },
  {
    "text": "we got some recommendations in terms of",
    "start": "199739",
    "end": "203760"
  },
  {
    "text": "security best practices so it talks",
    "start": "203760",
    "end": "206580"
  },
  {
    "text": "about encryption address known to node",
    "start": "206580",
    "end": "208500"
  },
  {
    "text": "encryption fine print access control for",
    "start": "208500",
    "end": "211739"
  },
  {
    "text": "the open search cluster and so on yeah",
    "start": "211739",
    "end": "213900"
  },
  {
    "text": "this looks more relevant which are the",
    "start": "213900",
    "end": "216000"
  },
  {
    "text": "security best practices but one thing uh",
    "start": "216000",
    "end": "219180"
  },
  {
    "text": "to be noted in this particular question",
    "start": "219180",
    "end": "220739"
  },
  {
    "text": "that we asked so the question that I",
    "start": "220739",
    "end": "223680"
  },
  {
    "text": "used here is how to secure it right I",
    "start": "223680",
    "end": "226980"
  },
  {
    "text": "didn't mention uh whether it is going to",
    "start": "226980",
    "end": "229500"
  },
  {
    "text": "be open search or anything else right so",
    "start": "229500",
    "end": "231480"
  },
  {
    "text": "I just used a pronoun it but still uh",
    "start": "231480",
    "end": "234540"
  },
  {
    "text": "the application was quite smart enough",
    "start": "234540",
    "end": "236340"
  },
  {
    "text": "to understand the context which is the",
    "start": "236340",
    "end": "238680"
  },
  {
    "text": "open search itself and it was able to",
    "start": "238680",
    "end": "240720"
  },
  {
    "text": "give the uh relevant answer we will see",
    "start": "240720",
    "end": "243540"
  },
  {
    "text": "how this is happening behind the screen",
    "start": "243540",
    "end": "245040"
  },
  {
    "text": "when we go through the architecture",
    "start": "245040",
    "end": "246540"
  },
  {
    "text": "diagram but",
    "start": "246540",
    "end": "248819"
  },
  {
    "text": "um one thing is that that application is",
    "start": "248819",
    "end": "251099"
  },
  {
    "text": "able to",
    "start": "251099",
    "end": "252239"
  },
  {
    "text": "remember the history of conversations",
    "start": "252239",
    "end": "254120"
  },
  {
    "text": "for every dialogue that's happening uh",
    "start": "254120",
    "end": "257579"
  },
  {
    "text": "in the chat",
    "start": "257579",
    "end": "260239"
  },
  {
    "text": "we'll go with one more last question",
    "start": "260519",
    "end": "262260"
  },
  {
    "text": "being more specific something like",
    "start": "262260",
    "end": "266340"
  },
  {
    "text": "what is the",
    "start": "266340",
    "end": "269180"
  },
  {
    "text": "maximum number of",
    "start": "269180",
    "end": "272900"
  },
  {
    "text": "allowed shots",
    "start": "273860",
    "end": "277159"
  },
  {
    "text": "yeah so now we got an answer which tells",
    "start": "282900",
    "end": "286800"
  },
  {
    "text": "that the maximum number of a load charts",
    "start": "286800",
    "end": "289139"
  },
  {
    "text": "per node in the service is thousand yeah",
    "start": "289139",
    "end": "292440"
  },
  {
    "text": "this looks more accurate right so again",
    "start": "292440",
    "end": "294180"
  },
  {
    "text": "this is coming from the operational best",
    "start": "294180",
    "end": "296520"
  },
  {
    "text": "practices document",
    "start": "296520",
    "end": "298020"
  },
  {
    "text": "yeah so you know overall uh we are able",
    "start": "298020",
    "end": "300960"
  },
  {
    "text": "to uh",
    "start": "300960",
    "end": "302820"
  },
  {
    "text": "chat with the PDF content and get more",
    "start": "302820",
    "end": "305160"
  },
  {
    "text": "relevant and accurate answers so now",
    "start": "305160",
    "end": "307440"
  },
  {
    "text": "let's move on to the architecture",
    "start": "307440",
    "end": "309120"
  },
  {
    "text": "diagram which is powering this uh demo",
    "start": "309120",
    "end": "311400"
  },
  {
    "text": "that you're seeing here",
    "start": "311400",
    "end": "314180"
  },
  {
    "text": "so this is the overall AWS Cloud",
    "start": "315660",
    "end": "318180"
  },
  {
    "text": "architecture uh that is powering the",
    "start": "318180",
    "end": "320580"
  },
  {
    "text": "demo",
    "start": "320580",
    "end": "321900"
  },
  {
    "text": "so these are the core components of the",
    "start": "321900",
    "end": "323759"
  },
  {
    "text": "architecture first and foremost is the",
    "start": "323759",
    "end": "327000"
  },
  {
    "text": "central core component that is the",
    "start": "327000",
    "end": "328860"
  },
  {
    "text": "vector database which is Amazon open",
    "start": "328860",
    "end": "331080"
  },
  {
    "text": "search service that stores the uploaded",
    "start": "331080",
    "end": "333780"
  },
  {
    "text": "PDF documents informative vectors and",
    "start": "333780",
    "end": "337800"
  },
  {
    "text": "then answer the questions that we ask",
    "start": "337800",
    "end": "341220"
  },
  {
    "text": "next is the document encoder component",
    "start": "341220",
    "end": "343560"
  },
  {
    "text": "which is basically a Lambda function",
    "start": "343560",
    "end": "345919"
  },
  {
    "text": "enclosing the Lang chain framework",
    "start": "345919",
    "end": "348380"
  },
  {
    "text": "responsible for pre-processing the PDF",
    "start": "348380",
    "end": "351000"
  },
  {
    "text": "contents and then ingesting it into open",
    "start": "351000",
    "end": "353280"
  },
  {
    "text": "search",
    "start": "353280",
    "end": "355440"
  },
  {
    "text": "next comes the query encoder component",
    "start": "355440",
    "end": "357720"
  },
  {
    "text": "which is again a Lambda function with",
    "start": "357720",
    "end": "360000"
  },
  {
    "text": "Lang chain framework querying the open",
    "start": "360000",
    "end": "362520"
  },
  {
    "text": "search cluster for whatever the question",
    "start": "362520",
    "end": "364680"
  },
  {
    "text": "is asked from the client",
    "start": "364680",
    "end": "367820"
  },
  {
    "text": "next is the embedder component which is",
    "start": "367860",
    "end": "370680"
  },
  {
    "text": "a common layer for both the document and",
    "start": "370680",
    "end": "373020"
  },
  {
    "text": "the query encoder and this basically",
    "start": "373020",
    "end": "375419"
  },
  {
    "text": "used to encode the text documents into",
    "start": "375419",
    "end": "378120"
  },
  {
    "text": "vectors",
    "start": "378120",
    "end": "379440"
  },
  {
    "text": "it is basically the embedding model",
    "start": "379440",
    "end": "381360"
  },
  {
    "text": "hosted in sagemaker and for the demo we",
    "start": "381360",
    "end": "385380"
  },
  {
    "text": "used GPT 6 billion variant model",
    "start": "385380",
    "end": "390259"
  },
  {
    "text": "next is the memory store which is a",
    "start": "390300",
    "end": "393180"
  },
  {
    "text": "dynamodb to make sure the context of",
    "start": "393180",
    "end": "396240"
  },
  {
    "text": "conversations are maintained to support",
    "start": "396240",
    "end": "398639"
  },
  {
    "text": "multi-turn conversations",
    "start": "398639",
    "end": "401340"
  },
  {
    "text": "this is the reason that the application",
    "start": "401340",
    "end": "403560"
  },
  {
    "text": "was able to maintain",
    "start": "403560",
    "end": "405840"
  },
  {
    "text": "the complete context which was the open",
    "start": "405840",
    "end": "408660"
  },
  {
    "text": "search itself",
    "start": "408660",
    "end": "410520"
  },
  {
    "text": "so that even even when we asked a",
    "start": "410520",
    "end": "412860"
  },
  {
    "text": "question",
    "start": "412860",
    "end": "413880"
  },
  {
    "text": "how to secure it",
    "start": "413880",
    "end": "415979"
  },
  {
    "text": "the application was quite smart enough",
    "start": "415979",
    "end": "418500"
  },
  {
    "text": "to understand that we are talking about",
    "start": "418500",
    "end": "420300"
  },
  {
    "text": "the context open search because the",
    "start": "420300",
    "end": "422759"
  },
  {
    "text": "context was actually stored in this",
    "start": "422759",
    "end": "424440"
  },
  {
    "text": "dynamodb",
    "start": "424440",
    "end": "427080"
  },
  {
    "text": "so last one is the large language model",
    "start": "427080",
    "end": "430139"
  },
  {
    "text": "generator component which generates a",
    "start": "430139",
    "end": "432720"
  },
  {
    "text": "final response based upon the context",
    "start": "432720",
    "end": "434699"
  },
  {
    "text": "provided for the demo we use flan T5",
    "start": "434699",
    "end": "439020"
  },
  {
    "text": "double XL large language model",
    "start": "439020",
    "end": "442860"
  },
  {
    "text": "now let's see how the flow goes on as we",
    "start": "442860",
    "end": "446039"
  },
  {
    "text": "interact with the UI",
    "start": "446039",
    "end": "449060"
  },
  {
    "text": "so once we upload the PDF the document",
    "start": "449099",
    "end": "451860"
  },
  {
    "text": "gets stored in S3",
    "start": "451860",
    "end": "453840"
  },
  {
    "text": "which then triggers the Lambda",
    "start": "453840",
    "end": "456539"
  },
  {
    "text": "Lambda then does the cleansing of PDF",
    "start": "456539",
    "end": "459300"
  },
  {
    "text": "followed by chunking of the PDF into",
    "start": "459300",
    "end": "462000"
  },
  {
    "text": "individual documents and finally",
    "start": "462000",
    "end": "464460"
  },
  {
    "text": "transforming the chunks into vectors",
    "start": "464460",
    "end": "467039"
  },
  {
    "text": "using the embeda component",
    "start": "467039",
    "end": "469080"
  },
  {
    "text": "and this happens in a batch fashion",
    "start": "469080",
    "end": "472380"
  },
  {
    "text": "once the vectors are generated the",
    "start": "472380",
    "end": "474840"
  },
  {
    "text": "Lambda does does a bulk request to",
    "start": "474840",
    "end": "477599"
  },
  {
    "text": "ingest the document vectors into open",
    "start": "477599",
    "end": "479940"
  },
  {
    "text": "search index",
    "start": "479940",
    "end": "482720"
  },
  {
    "text": "this completes the overall ingestion",
    "start": "483180",
    "end": "485340"
  },
  {
    "text": "flow",
    "start": "485340",
    "end": "487699"
  },
  {
    "text": "then we ask a question over the PDF",
    "start": "488220",
    "end": "490740"
  },
  {
    "text": "content which goes through the APA",
    "start": "490740",
    "end": "493319"
  },
  {
    "text": "Gateway and proxies to the Lambda",
    "start": "493319",
    "end": "495720"
  },
  {
    "text": "function",
    "start": "495720",
    "end": "496819"
  },
  {
    "text": "Lambda with the help of flank chain",
    "start": "496819",
    "end": "499199"
  },
  {
    "text": "first converts a query into Vector using",
    "start": "499199",
    "end": "502560"
  },
  {
    "text": "a real-time sagemaker endpoint hosting",
    "start": "502560",
    "end": "505139"
  },
  {
    "text": "the actual embedding model",
    "start": "505139",
    "end": "508139"
  },
  {
    "text": "Lambda then uses a neural search query",
    "start": "508139",
    "end": "510720"
  },
  {
    "text": "to fetch the documents related to the",
    "start": "510720",
    "end": "513360"
  },
  {
    "text": "query Vector as response r",
    "start": "513360",
    "end": "517519"
  },
  {
    "text": "Lambda as the next step it's a dynamodb",
    "start": "517620",
    "end": "520500"
  },
  {
    "text": "table to check if there are any",
    "start": "520500",
    "end": "522539"
  },
  {
    "text": "conversations related to the same",
    "start": "522539",
    "end": "524459"
  },
  {
    "text": "session ID and then add those messages",
    "start": "524459",
    "end": "527580"
  },
  {
    "text": "related to the particular session ID to",
    "start": "527580",
    "end": "530339"
  },
  {
    "text": "the response",
    "start": "530339",
    "end": "532440"
  },
  {
    "text": "so now R becomes R plus M where M being",
    "start": "532440",
    "end": "537660"
  },
  {
    "text": "the messages retrieved from the dynamodb",
    "start": "537660",
    "end": "540360"
  },
  {
    "text": "table",
    "start": "540360",
    "end": "542100"
  },
  {
    "text": "please note that a new session ID is",
    "start": "542100",
    "end": "544980"
  },
  {
    "text": "automatically generated for every new",
    "start": "544980",
    "end": "547680"
  },
  {
    "text": "user or every new session and gets",
    "start": "547680",
    "end": "551040"
  },
  {
    "text": "stored in the dynamodb table",
    "start": "551040",
    "end": "554300"
  },
  {
    "text": "now the augmented response R plus m is",
    "start": "555000",
    "end": "558720"
  },
  {
    "text": "passed as input to the large language",
    "start": "558720",
    "end": "560399"
  },
  {
    "text": "model with this prompt template",
    "start": "560399",
    "end": "563760"
  },
  {
    "text": "so basically now the large language",
    "start": "563760",
    "end": "566100"
  },
  {
    "text": "model generates a response based upon",
    "start": "566100",
    "end": "568860"
  },
  {
    "text": "the context R plus m",
    "start": "568860",
    "end": "571620"
  },
  {
    "text": "here the responses from the open search",
    "start": "571620",
    "end": "574380"
  },
  {
    "text": "and the dynamodb are combined and passed",
    "start": "574380",
    "end": "577680"
  },
  {
    "text": "as prompts to the large language model",
    "start": "577680",
    "end": "579360"
  },
  {
    "text": "to generate the response",
    "start": "579360",
    "end": "582779"
  },
  {
    "text": "Lambda takes a generated response back",
    "start": "582779",
    "end": "585300"
  },
  {
    "text": "to the APA Gateway and finally the",
    "start": "585300",
    "end": "587880"
  },
  {
    "text": "response a is what you see in the chat",
    "start": "587880",
    "end": "590100"
  },
  {
    "text": "as the answer to the question asked",
    "start": "590100",
    "end": "593220"
  },
  {
    "text": "this way open search as a vector",
    "start": "593220",
    "end": "595740"
  },
  {
    "text": "database Powers the conversational",
    "start": "595740",
    "end": "597899"
  },
  {
    "text": "search for your own unstructured data",
    "start": "597899",
    "end": "601620"
  },
  {
    "text": "thank you",
    "start": "601620",
    "end": "604339"
  }
]
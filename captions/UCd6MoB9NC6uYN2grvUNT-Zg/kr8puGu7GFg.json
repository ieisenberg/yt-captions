[
  {
    "text": "In this video, you’ll see how to process Amazon\nKinesis data streams using AWS Lambda.",
    "start": "0",
    "end": "5559"
  },
  {
    "text": "With this solution, you can build \ncomplex processing logic more easily,",
    "start": "6000",
    "end": "9961"
  },
  {
    "text": "pay only for what you use with \na 100 percent serverless model,",
    "start": "9961",
    "end": "13554"
  },
  {
    "text": "and get infinite scalability \nwith no operational overhead.",
    "start": "13554",
    "end": "17084"
  },
  {
    "text": "For this demonstration, we’ll build a \nsimple application that has a source",
    "start": "18000",
    "end": "21388"
  },
  {
    "text": "writing data to a Kinesis data stream.",
    "start": "21388",
    "end": "23640"
  },
  {
    "text": "Then, we’ll use a Lambda function to \nread data from the Kinesis data stream",
    "start": "24102",
    "end": "27643"
  },
  {
    "text": "and write it into an Amazon DynamoDB table.",
    "start": "27643",
    "end": "30583"
  },
  {
    "text": "A Kinesis data stream is integrated \nwith Lambda through a resource",
    "start": "31441",
    "end": "34520"
  },
  {
    "text": "called an event source mapping.",
    "start": "34520",
    "end": "36559"
  },
  {
    "text": "Typically, when data stored in a Kinesis \ndata stream is consumed by an application,",
    "start": "37449",
    "end": "41688"
  },
  {
    "text": "it is that consumer's responsibility to \ntrack-or checkpoint- a stream's last",
    "start": "41688",
    "end": "45875"
  },
  {
    "text": "known position that was successfully processed.",
    "start": "45875",
    "end": "48150"
  },
  {
    "text": "The event source mapping takes care of \ncheckpointing for you, so your Lambda",
    "start": "48595",
    "end": "52169"
  },
  {
    "text": "function code can purely focus on the business \nlogic for processing an event or set of events.",
    "start": "52169",
    "end": "56872"
  },
  {
    "text": "The event source mapping also has a retry \nmechanism built in, so if your event processing",
    "start": "57731",
    "end": "62640"
  },
  {
    "text": "code fails, it is executed again with the \nsame set of records until it is successful.",
    "start": "62640",
    "end": "67348"
  },
  {
    "text": "If poison messages get into a data \nstream, they can break the processing",
    "start": "68370",
    "end": "71718"
  },
  {
    "text": "code in a Lambda function.",
    "start": "71718",
    "end": "73212"
  },
  {
    "text": "You can configure the event source \nmapping to write any poison messages",
    "start": "73592",
    "end": "76818"
  },
  {
    "text": "in a stream to an Amazon Simple Queue\nService (Amazon SQS) queue or to an Amazon",
    "start": "76818",
    "end": "82146"
  },
  {
    "text": "Simple Notification Service (Amazon \nSNS) topic and continue processing the",
    "start": "82146",
    "end": "86641"
  },
  {
    "text": "remaining messages in the stream.",
    "start": "86641",
    "end": "88428"
  },
  {
    "text": "The event source mapping has \nfunctionality to control how many",
    "start": "89501",
    "end": "92415"
  },
  {
    "text": "concurrent Lambda functions are \nused to process a data stream.",
    "start": "92415",
    "end": "95545"
  },
  {
    "text": "It enables you to run up to 10 \nconcurrent Lambda functions per partition",
    "start": "95891",
    "end": "99352"
  },
  {
    "text": "and retains the order of delivery for \nmessages with the same partition key.",
    "start": "99352",
    "end": "102980"
  },
  {
    "text": "The event source mapping can also \nbatch incoming data before it's",
    "start": "104053",
    "end": "107139"
  },
  {
    "text": "delivered to the Lambda function.",
    "start": "107139",
    "end": "108742"
  },
  {
    "text": "You can designate batches by size or window.",
    "start": "109121",
    "end": "111643"
  },
  {
    "text": "You can also specify a tumbling window \nto accumulate records for a fixed period",
    "start": "112682",
    "end": "117141"
  },
  {
    "text": "and dispatch all those records \ninto a Lambda function at once.",
    "start": "117141",
    "end": "120381"
  },
  {
    "text": "These benefits help cut costs and \nsimplify the process of building",
    "start": "120678",
    "end": "123962"
  },
  {
    "text": "sophisticated event streaming logic, \nso you can focus on developing the",
    "start": "123962",
    "end": "127708"
  },
  {
    "text": "business logic for processing \nevents in your Kinesis data stream.",
    "start": "127708",
    "end": "130994"
  },
  {
    "text": "Now let’s go to the AWS Management \nConsole and build this application.",
    "start": "131572",
    "end": "135322"
  },
  {
    "text": "We’ll begin by navigating to the Kinesis \nconsole, where we’ll create a data stream.",
    "start": "137417",
    "end": "141618"
  },
  {
    "text": "Let’s name our data stream events.",
    "start": "142410",
    "end": "144455"
  },
  {
    "text": "We can choose either On-demand or \nProvisioned mode for our data stream capacity.",
    "start": "147737",
    "end": "151730"
  },
  {
    "text": "We are going to work with a very small \nworkload with predictable throughput,",
    "start": "151961",
    "end": "155225"
  },
  {
    "text": "so we'll use Provisioned mode.",
    "start": "155225",
    "end": "156825"
  },
  {
    "text": "Let’s keep the number of provisioned \nshards set to 1 and create the data stream.",
    "start": "157897",
    "end": "161796"
  },
  {
    "text": "Now that our data stream is ready, let’s\nnavigate to DynamoDB and create a table.",
    "start": "165425",
    "end": "169751"
  },
  {
    "text": "We’ll give the table a name \nand provide a partition key.",
    "start": "174617",
    "end": "177185"
  },
  {
    "text": "Let’s retain the default table\nsettings and create the table.",
    "start": "179560",
    "end": "182535"
  },
  {
    "text": "The DynamoDB table has been created.",
    "start": "185537",
    "end": "187586"
  },
  {
    "text": "Now let’s navigate to the Lambda \nconsole and create a function.",
    "start": "188015",
    "end": "191067"
  },
  {
    "text": "We’ll use the option to author from\n scratch and give the function a name.",
    "start": "193871",
    "end": "197658"
  },
  {
    "text": "Let’s use Python 3.9 to write our function.",
    "start": "201073",
    "end": "203800"
  },
  {
    "text": "We’ll use the default architecture.",
    "start": "205697",
    "end": "207468"
  },
  {
    "text": "Next, let’s configure our Lambda \nfunction with the necessary permissions.",
    "start": "208457",
    "end": "211954"
  },
  {
    "text": "We'll use an existing IAM role.",
    "start": "212300",
    "end": "214253"
  },
  {
    "text": "This IAM role has permissions to read \nfrom Kinesis and write to DynamoDB.",
    "start": "218657",
    "end": "222923"
  },
  {
    "text": "Now let’s create the function.",
    "start": "223253",
    "end": "224688"
  },
  {
    "text": "Once the function has been created, we \ncan configure its event processing logic.",
    "start": "227294",
    "end": "231314"
  },
  {
    "text": "Let’s start by removing the \nToDo Implement placeholder.",
    "start": "231842",
    "end": "234726"
  },
  {
    "text": "Next, we’ll import boto3 so that we \ncan use the AWS SDK for Python.",
    "start": "235815",
    "end": "240570"
  },
  {
    "text": "Next, we’ll create a DynamoDB resource instance.",
    "start": "241659",
    "end": "244515"
  },
  {
    "text": "Next, we’ll call a function named table \nin the DynamoDB resource and specify",
    "start": "245588",
    "end": "249540"
  },
  {
    "text": "our table name, which is events.",
    "start": "249540",
    "end": "251607"
  },
  {
    "text": "Since the records will be dispatched in \nbatches when our Lambda function is",
    "start": "252597",
    "end": "255646"
  },
  {
    "text": "integrated to Kinesis, our Lambda function \nhandler could receive one or more events.",
    "start": "255646",
    "end": "260292"
  },
  {
    "text": "Let’s write code to handle all the records\n dispatched to the function handler.",
    "start": "260622",
    "end": "264094"
  },
  {
    "text": "We’ll create a record and \nextract the partition key from it.",
    "start": "264771",
    "end": "267509"
  },
  {
    "text": "Next, we’ll extract the message \npayload from the record in Kinesis.",
    "start": "268532",
    "end": "271809"
  },
  {
    "text": "When records are written into Kinesis, \nthe message payload is base64 encoded.",
    "start": "272205",
    "end": "276589"
  },
  {
    "text": "In order to read this encoded stream \nas a piece of text, we first need to",
    "start": "277084",
    "end": "280312"
  },
  {
    "text": "decode it using a basic default code.",
    "start": "280312",
    "end": "282289"
  },
  {
    "text": "Let’s import base64.",
    "start": "282487",
    "end": "284205"
  },
  {
    "text": "Let’s construct a variable called msg \nby reading the decoding property in our",
    "start": "285211",
    "end": "289345"
  },
  {
    "text": "record object and passing a record.",
    "start": "289345",
    "end": "291385"
  },
  {
    "text": "This returns a message variable with all \nthe bytes decoded from the base64 stream.",
    "start": "292423",
    "end": "296907"
  },
  {
    "text": "Now let’s write the record \nto the DynamoDB table.",
    "start": "297930",
    "end": "300371"
  },
  {
    "text": "The table will include a PK column \nwith the partition key for the record.",
    "start": "301443",
    "end": "304828"
  },
  {
    "text": "It will also include a data column with the data \nstream decoded from bytes into a UTF-8 string.",
    "start": "305918",
    "end": "311242"
  },
  {
    "text": "Let’s configure the function to return status code \n200 once all the records have been processed.",
    "start": "312397",
    "end": "317208"
  },
  {
    "text": "Now let’s deploy our Lambda function.",
    "start": "318116",
    "end": "319985"
  },
  {
    "text": "For the function to process items from\n our Kinesis data stream, we need to",
    "start": "323004",
    "end": "326245"
  },
  {
    "text": "create an event source mapping.",
    "start": "326245",
    "end": "327916"
  },
  {
    "text": "To do this, let’s add a trigger.",
    "start": "328328",
    "end": "330000"
  },
  {
    "text": "We’ll set the source to Kinesis and \nselect our stream named events.",
    "start": "333000",
    "end": "336617"
  },
  {
    "text": "We can specify an EFO \nconsumer for better throughput.",
    "start": "343281",
    "end": "346291"
  },
  {
    "text": "In this case, we’ll skip this option.",
    "start": "346538",
    "end": "348337"
  },
  {
    "text": "Let’s keep the Activate trigger check box\nselected so that the trigger is activated",
    "start": "348734",
    "end": "352386"
  },
  {
    "text": "as soon as we finish creating it.",
    "start": "352386",
    "end": "354146"
  },
  {
    "text": "Next, we’ll reduce the batch size to 10 because \nwe won’t be writing data at a very fast pace.",
    "start": "355153",
    "end": "360157"
  },
  {
    "text": "We’ll keep the starting \nposition in the stream to latest.",
    "start": "361064",
    "end": "363823"
  },
  {
    "text": "We’ll also leave the default batch \nwindow so that the event source \nmapping will dispatch results as fast as \nrecords are received by our Lambda function.",
    "start": "364202",
    "end": "370921"
  },
  {
    "text": "Now let’s add the trigger.",
    "start": "372109",
    "end": "373395"
  },
  {
    "text": "The trigger now appears in the Lambda \nfunction overview, and it has been enabled.",
    "start": "375408",
    "end": "379228"
  },
  {
    "text": "The details show that no \nrecords have been processed.",
    "start": "385590",
    "end": "388139"
  },
  {
    "text": "This is because we haven’t written \nany data into our data stream yet.",
    "start": "388221",
    "end": "391234"
  },
  {
    "text": "Let's do that now.",
    "start": "391399",
    "end": "392487"
  },
  {
    "text": "We’ll use the AWS CLI to put a \nrecord into our Kinesis data stream.",
    "start": "395125",
    "end": "399121"
  },
  {
    "text": "The record has been written to shard ID 0, and \nthe sequence number for the record is returned.",
    "start": "400226",
    "end": "405000"
  },
  {
    "text": "Now let’s go back to the Lambda console.",
    "start": "405478",
    "end": "407527"
  },
  {
    "text": "We’ll refresh the list to view the \nupdated details for the trigger.",
    "start": "410216",
    "end": "413218"
  },
  {
    "text": "The last processing result is OK, which \nmeans the trigger has processed an item.",
    "start": "414966",
    "end": "419397"
  },
  {
    "text": "To determine if the Lambda function \nproduced the results that we want,",
    "start": "420749",
    "end": "423837"
  },
  {
    "text": "let’s navigate to our DynamoDB table.",
    "start": "423838",
    "end": "426114"
  },
  {
    "text": "The primary key and data now \nappear in our table as expected.",
    "start": "432695",
    "end": "435906"
  },
  {
    "text": "You’ve just seen how to process Amazon \nKinesis data streams using AWS Lambda.",
    "start": "439023",
    "end": "443472"
  },
  {
    "text": "You can learn more about this topic in \nthe description and links for this video.",
    "start": "444647",
    "end": "448025"
  },
  {
    "text": "Thanks for watching. Now it’s your turn to try.",
    "start": "448207",
    "end": "450412"
  }
]
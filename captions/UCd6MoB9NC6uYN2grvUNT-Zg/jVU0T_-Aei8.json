[
  {
    "text": "hey folks Emily here uh today we are",
    "start": "919",
    "end": "3399"
  },
  {
    "text": "going to learn how to use the FM",
    "start": "3399",
    "end": "5080"
  },
  {
    "text": "evaluation library and sagemaker",
    "start": "5080",
    "end": "7040"
  },
  {
    "text": "pipeline so let's get",
    "start": "7040",
    "end": "9440"
  },
  {
    "text": "started all right so we understand that",
    "start": "9440",
    "end": "12200"
  },
  {
    "text": "llm evaluation helps us make the right",
    "start": "12200",
    "end": "15400"
  },
  {
    "text": "choice across our large language model",
    "start": "15400",
    "end": "17680"
  },
  {
    "text": "development and deployment life cycle",
    "start": "17680",
    "end": "19840"
  },
  {
    "text": "all the way from selecting the right",
    "start": "19840",
    "end": "21480"
  },
  {
    "text": "model to finding the right prompts",
    "start": "21480",
    "end": "24240"
  },
  {
    "text": "building and enhancing or retrieval",
    "start": "24240",
    "end": "26400"
  },
  {
    "text": "Stacks driving model fine tuning",
    "start": "26400",
    "end": "29279"
  },
  {
    "text": "reducing costs migrations rhf and then",
    "start": "29279",
    "end": "33160"
  },
  {
    "text": "governance and mlops in this video uh we",
    "start": "33160",
    "end": "36480"
  },
  {
    "text": "are going to double click on governance",
    "start": "36480",
    "end": "38040"
  },
  {
    "text": "and mlops let's get",
    "start": "38040",
    "end": "40120"
  },
  {
    "text": "rolling so let's take a quick look at",
    "start": "40120",
    "end": "42960"
  },
  {
    "text": "the mlops like life cycle remember",
    "start": "42960",
    "end": "45280"
  },
  {
    "text": "machine learning operations is a",
    "start": "45280",
    "end": "47719"
  },
  {
    "text": "technique that we can use to enhance our",
    "start": "47719",
    "end": "50920"
  },
  {
    "text": "uh building across teams um so to make",
    "start": "50920",
    "end": "54000"
  },
  {
    "text": "our team development uh faster make",
    "start": "54000",
    "end": "57199"
  },
  {
    "text": "deployments more streamlined um and",
    "start": "57199",
    "end": "60000"
  },
  {
    "text": "enhance and improve uh generally",
    "start": "60000",
    "end": "62440"
  },
  {
    "text": "speaking the way we work uh and so let's",
    "start": "62440",
    "end": "64920"
  },
  {
    "text": "take a look at this so classic mlops um",
    "start": "64920",
    "end": "67960"
  },
  {
    "text": "really centers on sort of three uh",
    "start": "67960",
    "end": "70759"
  },
  {
    "text": "accounts sort of you have this three",
    "start": "70759",
    "end": "72479"
  },
  {
    "text": "account structure uh where you'll start",
    "start": "72479",
    "end": "74799"
  },
  {
    "text": "with a Dev account or a Dev environment",
    "start": "74799",
    "end": "77360"
  },
  {
    "text": "um and this is where the majority of the",
    "start": "77360",
    "end": "79159"
  },
  {
    "text": "model building happens where we're doing",
    "start": "79159",
    "end": "81680"
  },
  {
    "text": "uh pre-processing training evaluation",
    "start": "81680",
    "end": "84720"
  },
  {
    "text": "then and then model registration Sage",
    "start": "84720",
    "end": "87320"
  },
  {
    "text": "maker provides a model registry uh that",
    "start": "87320",
    "end": "90119"
  },
  {
    "text": "you can use to establish when a model is",
    "start": "90119",
    "end": "92759"
  },
  {
    "text": "shipped when it's built and when it's",
    "start": "92759",
    "end": "94399"
  },
  {
    "text": "ready and approved from the data science",
    "start": "94399",
    "end": "97200"
  },
  {
    "text": "perspective uh to be onboarded for",
    "start": "97200",
    "end": "99840"
  },
  {
    "text": "application development uh and so once a",
    "start": "99840",
    "end": "102840"
  },
  {
    "text": "model is in the model registry um you",
    "start": "102840",
    "end": "105479"
  },
  {
    "text": "can then use mlops tooling uh to promote",
    "start": "105479",
    "end": "109719"
  },
  {
    "text": "that model to a higher environment so",
    "start": "109719",
    "end": "111960"
  },
  {
    "text": "you might promote it uh to pre-prod or",
    "start": "111960",
    "end": "114680"
  },
  {
    "text": "to test uh where you'll create the",
    "start": "114680",
    "end": "117000"
  },
  {
    "text": "endpoint and then uh test the endpoint",
    "start": "117000",
    "end": "119200"
  },
  {
    "text": "Ure it's up operational and then",
    "start": "119200",
    "end": "121119"
  },
  {
    "text": "ultimately deploy um that environment",
    "start": "121119",
    "end": "123799"
  },
  {
    "text": "into a production environment presumably",
    "start": "123799",
    "end": "126200"
  },
  {
    "text": "where your customers and the rest of",
    "start": "126200",
    "end": "127880"
  },
  {
    "text": "your application are actually going to",
    "start": "127880",
    "end": "129720"
  },
  {
    "text": "be interacting with it and so classic",
    "start": "129720",
    "end": "131920"
  },
  {
    "text": "mlops um helps us build tooling and",
    "start": "131920",
    "end": "134760"
  },
  {
    "text": "Technology uh to help make all of this",
    "start": "134760",
    "end": "137080"
  },
  {
    "text": "streamlined fast and uh and sing uh with",
    "start": "137080",
    "end": "140879"
  },
  {
    "text": "with the needs of your business so what",
    "start": "140879",
    "end": "143560"
  },
  {
    "text": "we're going to evaluate today is using",
    "start": "143560",
    "end": "145440"
  },
  {
    "text": "llm evaluation and then mlops to make",
    "start": "145440",
    "end": "148440"
  },
  {
    "text": "the right choices at scale really so we",
    "start": "148440",
    "end": "151720"
  },
  {
    "text": "learned about the again FM eval library",
    "start": "151720",
    "end": "154800"
  },
  {
    "text": "and how we can use that to evaluate a",
    "start": "154800",
    "end": "156440"
  },
  {
    "text": "single model now we're going to use that",
    "start": "156440",
    "end": "159120"
  },
  {
    "text": "to learn how to evaluate many models at",
    "start": "159120",
    "end": "161920"
  },
  {
    "text": "the same time actually by running",
    "start": "161920",
    "end": "163640"
  },
  {
    "text": "different jobs and different processes",
    "start": "163640",
    "end": "166080"
  },
  {
    "text": "uh this is going to enable us to promote",
    "start": "166080",
    "end": "168400"
  },
  {
    "text": "those models and the customized models",
    "start": "168400",
    "end": "170840"
  },
  {
    "text": "to production environments faster uh",
    "start": "170840",
    "end": "173480"
  },
  {
    "text": "because we can build one pipeline uh to",
    "start": "173480",
    "end": "176560"
  },
  {
    "text": "then promote models as they meet that",
    "start": "176560",
    "end": "178920"
  },
  {
    "text": "criteria uh this then enables monitoring",
    "start": "178920",
    "end": "181840"
  },
  {
    "text": "on those models it enables better and",
    "start": "181840",
    "end": "184599"
  },
  {
    "text": "more robust uh retrieval Stacks",
    "start": "184599",
    "end": "186920"
  },
  {
    "text": "fine-tuning stacks and then of course",
    "start": "186920",
    "end": "189040"
  },
  {
    "text": "testing for new models we know we live",
    "start": "189040",
    "end": "191519"
  },
  {
    "text": "in a world where New Foundation models",
    "start": "191519",
    "end": "193599"
  },
  {
    "text": "pop up like daisies they're very common",
    "start": "193599",
    "end": "196720"
  },
  {
    "text": "um and so this way uh we can enable fast",
    "start": "196720",
    "end": "200239"
  },
  {
    "text": "and Rapid testing for new models and so",
    "start": "200239",
    "end": "203360"
  },
  {
    "text": "again we don't need to spend our time",
    "start": "203360",
    "end": "205280"
  },
  {
    "text": "spinning wheels figuring out if we",
    "start": "205280",
    "end": "206879"
  },
  {
    "text": "should evaluate a new model or not um",
    "start": "206879",
    "end": "209319"
  },
  {
    "text": "just throw it into the pipeline and see",
    "start": "209319",
    "end": "211799"
  },
  {
    "text": "if it sticks and if it's good use it if",
    "start": "211799",
    "end": "214159"
  },
  {
    "text": "not move on to the next one so let's",
    "start": "214159",
    "end": "217760"
  },
  {
    "text": "let's see how we're going to do this um",
    "start": "217760",
    "end": "220400"
  },
  {
    "text": "so uh some co-workers of mine built a",
    "start": "220400",
    "end": "223599"
  },
  {
    "text": "really awesome project uh that enables",
    "start": "223599",
    "end": "227080"
  },
  {
    "text": "you to run the FME eval library inside",
    "start": "227080",
    "end": "230799"
  },
  {
    "text": "of sag maker pipelines and so uh we're",
    "start": "230799",
    "end": "233640"
  },
  {
    "text": "going to take a look at this open source",
    "start": "233640",
    "end": "235319"
  },
  {
    "text": "sample and then I'll show you how to set",
    "start": "235319",
    "end": "237040"
  },
  {
    "text": "it up and we'll walk through a couple",
    "start": "237040",
    "end": "238840"
  },
  {
    "text": "examples together so let's say I'm a",
    "start": "238840",
    "end": "241079"
  },
  {
    "text": "data scientist as a data scientist uh I",
    "start": "241079",
    "end": "244200"
  },
  {
    "text": "primarily interact with my notebook for",
    "start": "244200",
    "end": "246480"
  },
  {
    "text": "example I'm going to be in Jupiter",
    "start": "246480",
    "end": "247799"
  },
  {
    "text": "notebook running a couple tests uh my ml",
    "start": "247799",
    "end": "251120"
  },
  {
    "text": "engineer is going to take the notebook",
    "start": "251120",
    "end": "254640"
  },
  {
    "text": "uh that I write and then actually format",
    "start": "254640",
    "end": "257680"
  },
  {
    "text": "that into a more robust repository which",
    "start": "257680",
    "end": "260919"
  },
  {
    "text": "can enable all of this um this",
    "start": "260919",
    "end": "263680"
  },
  {
    "text": "evaluation using pipelines so this can",
    "start": "263680",
    "end": "266400"
  },
  {
    "text": "run a pre-processing step uh to of",
    "start": "266400",
    "end": "269199"
  },
  {
    "text": "course transform the data ahead of time",
    "start": "269199",
    "end": "271800"
  },
  {
    "text": "deploy a variety of models onto",
    "start": "271800",
    "end": "274400"
  },
  {
    "text": "endpoints evaluate both of those models",
    "start": "274400",
    "end": "278039"
  },
  {
    "text": "uh and then compare those models based",
    "start": "278039",
    "end": "280560"
  },
  {
    "text": "on cost latency quality toxicity and so",
    "start": "280560",
    "end": "284720"
  },
  {
    "text": "on and so",
    "start": "284720",
    "end": "285919"
  },
  {
    "text": "forth and so here's a view of two",
    "start": "285919",
    "end": "288919"
  },
  {
    "text": "pipelines we're going to look at today",
    "start": "288919",
    "end": "290440"
  },
  {
    "text": "one is a very simple single model um",
    "start": "290440",
    "end": "294600"
  },
  {
    "text": "pipeline where we'll do some",
    "start": "294600",
    "end": "296440"
  },
  {
    "text": "pre-processing uh and a deploy step both",
    "start": "296440",
    "end": "299000"
  },
  {
    "text": "at the same time",
    "start": "299000",
    "end": "300400"
  },
  {
    "text": "uh and then those come together and we",
    "start": "300400",
    "end": "302000"
  },
  {
    "text": "evaluate the model that has been uh",
    "start": "302000",
    "end": "305479"
  },
  {
    "text": "deployed after that we'll take a look at",
    "start": "305479",
    "end": "307560"
  },
  {
    "text": "a multimodel evaluation pipeline uh",
    "start": "307560",
    "end": "310479"
  },
  {
    "text": "where we pre-process our data deploy a",
    "start": "310479",
    "end": "313560"
  },
  {
    "text": "model uh deploy a second model evaluate",
    "start": "313560",
    "end": "316919"
  },
  {
    "text": "this and then ultimately make a choice",
    "start": "316919",
    "end": "319400"
  },
  {
    "text": "about which Foundation model to use uh",
    "start": "319400",
    "end": "322199"
  },
  {
    "text": "based on the evaluation results and",
    "start": "322199",
    "end": "324440"
  },
  {
    "text": "actually the second um pipeline will",
    "start": "324440",
    "end": "327960"
  },
  {
    "text": "also include fine-tuning so you can",
    "start": "327960",
    "end": "330520"
  },
  {
    "text": "compare uh Falcon 7B llama 7B and then a",
    "start": "330520",
    "end": "334880"
  },
  {
    "text": "fine tuned uh llama 7B to see which one",
    "start": "334880",
    "end": "337919"
  },
  {
    "text": "is the best for your use case so before",
    "start": "337919",
    "end": "340759"
  },
  {
    "text": "we get into the demo uh quick shout out",
    "start": "340759",
    "end": "342680"
  },
  {
    "text": "to the team who who built this thank you",
    "start": "342680",
    "end": "344720"
  },
  {
    "text": "so much Socrates uh carus uh J deep",
    "start": "344720",
    "end": "347960"
  },
  {
    "text": "singon and then Ricardo gati uh really",
    "start": "347960",
    "end": "350880"
  },
  {
    "text": "appreciate your Cycles in in putting",
    "start": "350880",
    "end": "352720"
  },
  {
    "text": "this together and then helping me get",
    "start": "352720",
    "end": "354160"
  },
  {
    "text": "this online uh it's awesome to to see",
    "start": "354160",
    "end": "356759"
  },
  {
    "text": "this come together so let's get going",
    "start": "356759",
    "end": "359840"
  },
  {
    "text": "all right so as promised uh robust and",
    "start": "359840",
    "end": "364039"
  },
  {
    "text": "operational pipeline but let's figure",
    "start": "364039",
    "end": "367720"
  },
  {
    "text": "out where this came from uh so again",
    "start": "367720",
    "end": "369840"
  },
  {
    "text": "there's an open source example you can",
    "start": "369840",
    "end": "372000"
  },
  {
    "text": "use FM evaluation at scale uh which",
    "start": "372000",
    "end": "376680"
  },
  {
    "text": "takes the FME Val library and helps you",
    "start": "376680",
    "end": "381680"
  },
  {
    "text": "operationalizing it operationalize it",
    "start": "381680",
    "end": "384599"
  },
  {
    "text": "with sag maker pipelines um so you can",
    "start": "384599",
    "end": "387280"
  },
  {
    "text": "use sag maker pipelines uh which has a",
    "start": "387280",
    "end": "390160"
  },
  {
    "text": "pipeline. py file along with the yaml",
    "start": "390160",
    "end": "393319"
  },
  {
    "text": "file so you can modify the yaml file",
    "start": "393319",
    "end": "396160"
  },
  {
    "text": "with um the name of the model you want",
    "start": "396160",
    "end": "398880"
  },
  {
    "text": "to evaluate the type of evaluation you",
    "start": "398880",
    "end": "401840"
  },
  {
    "text": "would like to do um you can point to a",
    "start": "401840",
    "end": "405440"
  },
  {
    "text": "data set you would like to fine-tune uh",
    "start": "405440",
    "end": "408280"
  },
  {
    "text": "in S3 for example and a few different",
    "start": "408280",
    "end": "411000"
  },
  {
    "text": "modes and then uh just run the script",
    "start": "411000",
    "end": "414759"
  },
  {
    "text": "and then it it triggers all of the um",
    "start": "414759",
    "end": "417720"
  },
  {
    "text": "all of the pipelines to actually execute",
    "start": "417720",
    "end": "419840"
  },
  {
    "text": "and then give you the evaluation results",
    "start": "419840",
    "end": "422599"
  },
  {
    "text": "we can also um of course configure this",
    "start": "422599",
    "end": "425840"
  },
  {
    "text": "um using new uh models as we like so",
    "start": "425840",
    "end": "429840"
  },
  {
    "text": "let's jump",
    "start": "429840",
    "end": "431440"
  },
  {
    "text": "in all",
    "start": "431440",
    "end": "434720"
  },
  {
    "text": "right so first we'll just look at the uh",
    "start": "435720",
    "end": "440039"
  },
  {
    "text": "repository so once you download this of",
    "start": "440039",
    "end": "442759"
  },
  {
    "text": "course uh you'll open this up and then",
    "start": "442759",
    "end": "445360"
  },
  {
    "text": "I'm in the source directory and in",
    "start": "445360",
    "end": "448039"
  },
  {
    "text": "particular SM pipeline",
    "start": "448039",
    "end": "450319"
  },
  {
    "text": "lines and this is the the primary folder",
    "start": "450319",
    "end": "454000"
  },
  {
    "text": "uh I've been doing most of my work in",
    "start": "454000",
    "end": "455680"
  },
  {
    "text": "this SM pipelines library and then",
    "start": "455680",
    "end": "459560"
  },
  {
    "text": "you'll see this handy runme uh library",
    "start": "459560",
    "end": "462919"
  },
  {
    "text": "or notebook rather python notebook and",
    "start": "462919",
    "end": "465680"
  },
  {
    "text": "so this has two requirements actually so",
    "start": "465680",
    "end": "468319"
  },
  {
    "text": "there's a local requirements um to run",
    "start": "468319",
    "end": "471199"
  },
  {
    "text": "the python packages in this",
    "start": "471199",
    "end": "473400"
  },
  {
    "text": "notebook there is a second",
    "start": "473400",
    "end": "475479"
  },
  {
    "text": "requirements.txt actually let me zoom in",
    "start": "475479",
    "end": "477599"
  },
  {
    "text": "here so you can see this a little bit",
    "start": "477599",
    "end": "478720"
  },
  {
    "text": "better there is a second",
    "start": "478720",
    "end": "481680"
  },
  {
    "text": "requirements.txt",
    "start": "481680",
    "end": "483400"
  },
  {
    "text": "uh which is what the processing job will",
    "start": "483400",
    "end": "486680"
  },
  {
    "text": "need to execute all of the rest of the",
    "start": "486680",
    "end": "489319"
  },
  {
    "text": "steps so local requirements for your",
    "start": "489319",
    "end": "491560"
  },
  {
    "text": "notebook and then uh sort of larger",
    "start": "491560",
    "end": "494800"
  },
  {
    "text": "requirements for what's actually going",
    "start": "494800",
    "end": "496400"
  },
  {
    "text": "to run in the pipeline so that's this",
    "start": "496400",
    "end": "500879"
  },
  {
    "text": "again make sure you're using the latest",
    "start": "500879",
    "end": "502560"
  },
  {
    "text": "version of the uh stage maker python SDK",
    "start": "502560",
    "end": "505520"
  },
  {
    "text": "in addition to Bodo 3 um as this will",
    "start": "505520",
    "end": "509159"
  },
  {
    "text": "IND aable you to use both um uh",
    "start": "509159",
    "end": "512719"
  },
  {
    "text": "sagemaker clarify Foundation model",
    "start": "512719",
    "end": "515440"
  },
  {
    "text": "evaluation and the updates to sagemaker",
    "start": "515440",
    "end": "518560"
  },
  {
    "text": "pipeline sagemaker pipelines had an",
    "start": "518560",
    "end": "520320"
  },
  {
    "text": "update um and it's now much easier uh to",
    "start": "520320",
    "end": "523360"
  },
  {
    "text": "create a step you can create a step",
    "start": "523360",
    "end": "525160"
  },
  {
    "text": "really in a single line of python code",
    "start": "525160",
    "end": "527720"
  },
  {
    "text": "and so that's what we use in addition to",
    "start": "527720",
    "end": "530560"
  },
  {
    "text": "FM",
    "start": "530560",
    "end": "532240"
  },
  {
    "text": "eval and then the notebook here is",
    "start": "532240",
    "end": "536080"
  },
  {
    "text": "really just uploading all of the data",
    "start": "536080",
    "end": "538640"
  },
  {
    "text": "sets to the right WR S3 location so you",
    "start": "538640",
    "end": "540959"
  },
  {
    "text": "can set your output bucket here I'm just",
    "start": "540959",
    "end": "543560"
  },
  {
    "text": "using my default bucket and then it's",
    "start": "543560",
    "end": "546560"
  },
  {
    "text": "loading the local files so in this local",
    "start": "546560",
    "end": "550399"
  },
  {
    "text": "data sets",
    "start": "550399",
    "end": "551839"
  },
  {
    "text": "folder uh which ships with this",
    "start": "551839",
    "end": "554079"
  },
  {
    "text": "repository so the local data sets and",
    "start": "554079",
    "end": "556720"
  },
  {
    "text": "then we're going to upload those to our",
    "start": "556720",
    "end": "558440"
  },
  {
    "text": "S3 bucket um and they become available",
    "start": "558440",
    "end": "562200"
  },
  {
    "text": "this is also the same S3 bucket where",
    "start": "562200",
    "end": "565079"
  },
  {
    "text": "the output of the evaluation jobs will",
    "start": "565079",
    "end": "568600"
  },
  {
    "text": "go so unlike the um sagemaker UI which",
    "start": "568600",
    "end": "573519"
  },
  {
    "text": "gives you this very lengthy uh and",
    "start": "573519",
    "end": "576200"
  },
  {
    "text": "detailed report uh that explain the",
    "start": "576200",
    "end": "579279"
  },
  {
    "text": "metrics and that goes into detail and",
    "start": "579279",
    "end": "581360"
  },
  {
    "text": "gives you these nice graphs um the",
    "start": "581360",
    "end": "583480"
  },
  {
    "text": "library is not going to do that the",
    "start": "583480",
    "end": "585040"
  },
  {
    "text": "library is much more tur uh and it just",
    "start": "585040",
    "end": "587519"
  },
  {
    "text": "gives us the evaluation results so we'll",
    "start": "587519",
    "end": "589839"
  },
  {
    "text": "be able to download those from our S3",
    "start": "589839",
    "end": "591920"
  },
  {
    "text": "bucket um as this job",
    "start": "591920",
    "end": "594760"
  },
  {
    "text": "completes and then we just run uh",
    "start": "594760",
    "end": "598079"
  },
  {
    "text": "pipeline. nice and easy so let's take a",
    "start": "598079",
    "end": "601600"
  },
  {
    "text": "look at this pipeline. py business and",
    "start": "601600",
    "end": "604440"
  },
  {
    "text": "see if we can figure out what's going on",
    "start": "604440",
    "end": "606320"
  },
  {
    "text": "so pipeline py right here uh so it's",
    "start": "606320",
    "end": "610920"
  },
  {
    "text": "using the sagemaker workflow again the",
    "start": "610920",
    "end": "613600"
  },
  {
    "text": "sagemaker pipelines um core process and",
    "start": "613600",
    "end": "617959"
  },
  {
    "text": "then we're importing these steps",
    "start": "617959",
    "end": "620320"
  },
  {
    "text": "actually we have them defined in this",
    "start": "620320",
    "end": "622920"
  },
  {
    "text": "repository here and then we're just",
    "start": "622920",
    "end": "625760"
  },
  {
    "text": "establishing our stagemaker session",
    "start": "625760",
    "end": "628079"
  },
  {
    "text": "pointing to our default bucket it uh",
    "start": "628079",
    "end": "630760"
  },
  {
    "text": "adding the uh input and output data",
    "start": "630760",
    "end": "634160"
  },
  {
    "text": "arguments and then parsing this yaml",
    "start": "634160",
    "end": "636959"
  },
  {
    "text": "file so this yaml is how you can modify",
    "start": "636959",
    "end": "641120"
  },
  {
    "text": "what's in this",
    "start": "641120",
    "end": "642320"
  },
  {
    "text": "pipeline so it's pipeline. yaml which is",
    "start": "642320",
    "end": "645680"
  },
  {
    "text": "right here and so this takes uh the name",
    "start": "645680",
    "end": "649320"
  },
  {
    "text": "of your pipeline the data set names the",
    "start": "649320",
    "end": "653440"
  },
  {
    "text": "types uh the input and the output keys",
    "start": "653440",
    "end": "656440"
  },
  {
    "text": "and then your model name so right here",
    "start": "656440",
    "end": "658920"
  },
  {
    "text": "and then algorithms as well so this is",
    "start": "658920",
    "end": "660880"
  },
  {
    "text": "where you can modify all of those things",
    "start": "660880",
    "end": "663639"
  },
  {
    "text": "um when you're running this",
    "start": "663639",
    "end": "666480"
  },
  {
    "text": "pipeline all right so that's your config",
    "start": "666480",
    "end": "669720"
  },
  {
    "text": "and then we'll just set up an execution",
    "start": "669720",
    "end": "671880"
  },
  {
    "text": "ID pipeline",
    "start": "671880",
    "end": "674600"
  },
  {
    "text": "name uh set point to the algorithm that",
    "start": "674600",
    "end": "677720"
  },
  {
    "text": "we uploaded from that pipeline. yamma",
    "start": "677720",
    "end": "681519"
  },
  {
    "text": "file set this and then we create our",
    "start": "681519",
    "end": "685279"
  },
  {
    "text": "step so our step has this",
    "start": "685279",
    "end": "687880"
  },
  {
    "text": "pre-process uh it has has an endpoint",
    "start": "687880",
    "end": "690040"
  },
  {
    "text": "name and then these evaluation",
    "start": "690040",
    "end": "693320"
  },
  {
    "text": "results and then a cleanup step as well",
    "start": "693320",
    "end": "696200"
  },
  {
    "text": "to delete the",
    "start": "696200",
    "end": "697360"
  },
  {
    "text": "resources and then we create the",
    "start": "697360",
    "end": "699920"
  },
  {
    "text": "pipeline so this is your",
    "start": "699920",
    "end": "702360"
  },
  {
    "text": "pipeline and then we add the execution",
    "start": "702360",
    "end": "705360"
  },
  {
    "text": "rule so let's check this out so uh",
    "start": "705360",
    "end": "708320"
  },
  {
    "text": "you'll notice I'm in uh sagemaker Studio",
    "start": "708320",
    "end": "710959"
  },
  {
    "text": "Classic actually but",
    "start": "710959",
    "end": "713760"
  },
  {
    "text": "let's inspect this and so again we have",
    "start": "713760",
    "end": "717639"
  },
  {
    "text": "two pipelines we're going to look at one",
    "start": "717639",
    "end": "719839"
  },
  {
    "text": "is the single model um that evaluates",
    "start": "719839",
    "end": "722920"
  },
  {
    "text": "one model of course and then the second",
    "start": "722920",
    "end": "724399"
  },
  {
    "text": "one evaluates multiple models so let's",
    "start": "724399",
    "end": "727279"
  },
  {
    "text": "open this so here we go uh we have a",
    "start": "727279",
    "end": "729560"
  },
  {
    "text": "successful run going to right click on",
    "start": "729560",
    "end": "731760"
  },
  {
    "text": "this open execution details and here we",
    "start": "731760",
    "end": "735079"
  },
  {
    "text": "go uh so this is my pipeline again",
    "start": "735079",
    "end": "738480"
  },
  {
    "text": "that's evaluating one model this is",
    "start": "738480",
    "end": "741839"
  },
  {
    "text": "evaluating uh the tax generation llama 2",
    "start": "741839",
    "end": "745639"
  },
  {
    "text": "7 billion so first it",
    "start": "745639",
    "end": "747839"
  },
  {
    "text": "deploys uh the model then runs um that",
    "start": "747839",
    "end": "752000"
  },
  {
    "text": "pre-processing step evaluates the model",
    "start": "752000",
    "end": "755079"
  },
  {
    "text": "and then ultimately cleans up the",
    "start": "755079",
    "end": "757360"
  },
  {
    "text": "resources and then for each of these we",
    "start": "757360",
    "end": "759639"
  },
  {
    "text": "can drill into some of the details",
    "start": "759639",
    "end": "762680"
  },
  {
    "text": "looking at the the files the source",
    "start": "762680",
    "end": "766079"
  },
  {
    "text": "files um the logs and then the the",
    "start": "766079",
    "end": "769560"
  },
  {
    "text": "relevant information and then this uh",
    "start": "769560",
    "end": "773480"
  },
  {
    "text": "the evaluation result is actually",
    "start": "773480",
    "end": "775920"
  },
  {
    "text": "sitting in my S3 bucket so my S3 bucket",
    "start": "775920",
    "end": "778959"
  },
  {
    "text": "is over here uh so I'm in my session",
    "start": "778959",
    "end": "783120"
  },
  {
    "text": "buckets llm evalid scale example and",
    "start": "783120",
    "end": "786680"
  },
  {
    "text": "then this is the output uh for one of my",
    "start": "786680",
    "end": "789360"
  },
  {
    "text": "jobs actually let me show you the output",
    "start": "789360",
    "end": "791920"
  },
  {
    "text": "for this job yeah so this is the output",
    "start": "791920",
    "end": "795079"
  },
  {
    "text": "for the single model uh which is a",
    "start": "795079",
    "end": "797720"
  },
  {
    "text": "factual knowledge score of",
    "start": "797720",
    "end": "801000"
  },
  {
    "text": "0.59 um so we get this evaluation",
    "start": "801000",
    "end": "803760"
  },
  {
    "text": "response uh for this single",
    "start": "803760",
    "end": "806480"
  },
  {
    "text": "model let's see if we can Heat this up a",
    "start": "806480",
    "end": "810560"
  },
  {
    "text": "little bit so now I'm going to close",
    "start": "810560",
    "end": "812360"
  },
  {
    "text": "this",
    "start": "812360",
    "end": "813360"
  },
  {
    "text": "out and we're going to go back to",
    "start": "813360",
    "end": "815880"
  },
  {
    "text": "pipelines and now let's look at how we",
    "start": "815880",
    "end": "818519"
  },
  {
    "text": "can evaluate multiple",
    "start": "818519",
    "end": "822000"
  },
  {
    "text": "models again successful run we're going",
    "start": "822639",
    "end": "826399"
  },
  {
    "text": "to open the execution details and here",
    "start": "826399",
    "end": "829360"
  },
  {
    "text": "we go uh so let's unpack this so there",
    "start": "829360",
    "end": "833440"
  },
  {
    "text": "are three evaluation processes happening",
    "start": "833440",
    "end": "838759"
  },
  {
    "text": "uh and you know what let me dive in even",
    "start": "838759",
    "end": "841519"
  },
  {
    "text": "further because this is probably a",
    "start": "841519",
    "end": "842880"
  },
  {
    "text": "little bit tough to see uh so first",
    "start": "842880",
    "end": "845399"
  },
  {
    "text": "we're deploying a llama 7B drop an",
    "start": "845399",
    "end": "848440"
  },
  {
    "text": "evaluation on that uh next we're",
    "start": "848440",
    "end": "851440"
  },
  {
    "text": "deploying a falcon 7B also deploying",
    "start": "851440",
    "end": "855920"
  },
  {
    "text": "this and then we have this third stream",
    "start": "855920",
    "end": "859000"
  },
  {
    "text": "over here that's fine-tuning llama 2",
    "start": "859000",
    "end": "862639"
  },
  {
    "text": "deploying this and then evaluating it",
    "start": "862639",
    "end": "865720"
  },
  {
    "text": "and so all three of those different",
    "start": "865720",
    "end": "868600"
  },
  {
    "text": "models",
    "start": "868600",
    "end": "869880"
  },
  {
    "text": "feed into this single step which is",
    "start": "869880",
    "end": "872880"
  },
  {
    "text": "selecting the model and then this model",
    "start": "872880",
    "end": "876199"
  },
  {
    "text": "selection um creates that same HTML file",
    "start": "876199",
    "end": "880279"
  },
  {
    "text": "I showed you um where we see the uh",
    "start": "880279",
    "end": "883120"
  },
  {
    "text": "results of this model in factual",
    "start": "883120",
    "end": "884759"
  },
  {
    "text": "knowledge Q&A um and then we clean up",
    "start": "884759",
    "end": "887759"
  },
  {
    "text": "each of these resources and so",
    "start": "887759",
    "end": "892240"
  },
  {
    "text": "let's open this in more",
    "start": "892240",
    "end": "896480"
  },
  {
    "text": "detail so we have the logs for the model",
    "start": "897680",
    "end": "900560"
  },
  {
    "text": "selection which is quite nice uh we can",
    "start": "900560",
    "end": "903440"
  },
  {
    "text": "see actually for each model",
    "start": "903440",
    "end": "908480"
  },
  {
    "text": "um the endpoint name model version",
    "start": "908480",
    "end": "912480"
  },
  {
    "text": "evaluation",
    "start": "912480",
    "end": "914839"
  },
  {
    "text": "config factual knowledge eval score",
    "start": "914839",
    "end": "918720"
  },
  {
    "text": "value right here so here the logs are",
    "start": "918720",
    "end": "922320"
  },
  {
    "text": "actually showing the output um of the",
    "start": "922320",
    "end": "926360"
  },
  {
    "text": "evaluation which is quite nice",
    "start": "926360",
    "end": "930959"
  },
  {
    "text": "all right and then we can drill into the",
    "start": "934800",
    "end": "939079"
  },
  {
    "text": "S3 path which again is in this S3 bucket",
    "start": "939079",
    "end": "942519"
  },
  {
    "text": "that I uh provided and then output the",
    "start": "942519",
    "end": "946519"
  },
  {
    "text": "name of the job",
    "start": "946519",
    "end": "950319"
  },
  {
    "text": "multimodels let's look at this one and",
    "start": "950519",
    "end": "953319"
  },
  {
    "text": "then again we have three HTML files uh",
    "start": "953319",
    "end": "956560"
  },
  {
    "text": "for each of the models that",
    "start": "956560",
    "end": "961199"
  },
  {
    "text": "we",
    "start": "961199",
    "end": "962759"
  },
  {
    "text": "deployed and then here we go factual",
    "start": "962759",
    "end": "965000"
  },
  {
    "text": "knowledge score much higher so",
    "start": "965000",
    "end": "968360"
  },
  {
    "text": "0.59 great all right and then uh",
    "start": "968360",
    "end": "972040"
  },
  {
    "text": "remember the repository has um ways for",
    "start": "972040",
    "end": "976040"
  },
  {
    "text": "you to modify this to add even more",
    "start": "976040",
    "end": "979959"
  },
  {
    "text": "models and to do even more uh",
    "start": "979959",
    "end": "982759"
  },
  {
    "text": "modifications so if you'd like to",
    "start": "982759",
    "end": "985319"
  },
  {
    "text": "evaluate 50 models or run you know tens",
    "start": "985319",
    "end": "989920"
  },
  {
    "text": "of fine-tuning jobs and then evaluate",
    "start": "989920",
    "end": "991920"
  },
  {
    "text": "all of those um you can modify this to",
    "start": "991920",
    "end": "995000"
  },
  {
    "text": "to be able to run those massive",
    "start": "995000",
    "end": "996600"
  },
  {
    "text": "evaluations of",
    "start": "996600",
    "end": "998120"
  },
  {
    "text": "scale so with that thank you very much I",
    "start": "998120",
    "end": "1000560"
  },
  {
    "text": "hope you enjoyed this video uh in this",
    "start": "1000560",
    "end": "1002519"
  },
  {
    "text": "YouTube video uh we looked at setting up",
    "start": "1002519",
    "end": "1005319"
  },
  {
    "text": "Foundation model evaluation in sagemaker",
    "start": "1005319",
    "end": "1008000"
  },
  {
    "text": "pipelines uh to help us operationalize",
    "start": "1008000",
    "end": "1010560"
  },
  {
    "text": "and scale our large language model",
    "start": "1010560",
    "end": "1012680"
  },
  {
    "text": "evaluation uh to meet the needs of our",
    "start": "1012680",
    "end": "1014639"
  },
  {
    "text": "customers this includes evaluation for",
    "start": "1014639",
    "end": "1018199"
  },
  {
    "text": "um models hosted in Sag maker of course",
    "start": "1018199",
    "end": "1020560"
  },
  {
    "text": "with sage maker jumpstart in addition to",
    "start": "1020560",
    "end": "1022839"
  },
  {
    "text": "custom models and uh Runners that we",
    "start": "1022839",
    "end": "1025600"
  },
  {
    "text": "that we build and establish um and then",
    "start": "1025600",
    "end": "1028120"
  },
  {
    "text": "we we're running pipelines uh to enable",
    "start": "1028120",
    "end": "1031798"
  },
  {
    "text": "us to evaluate again single models and",
    "start": "1031799",
    "end": "1034079"
  },
  {
    "text": "then multiple models uh including models",
    "start": "1034079",
    "end": "1036640"
  },
  {
    "text": "that have been fine-tuned uh so thank",
    "start": "1036640",
    "end": "1039240"
  },
  {
    "text": "you I hope you enjoyed this and then in",
    "start": "1039240",
    "end": "1041438"
  },
  {
    "text": "the next video uh we're going to take a",
    "start": "1041439",
    "end": "1043438"
  },
  {
    "text": "look at how to bring our own data sets",
    "start": "1043439",
    "end": "1045959"
  },
  {
    "text": "uh models and evaluation metrics for FME",
    "start": "1045959",
    "end": "1048558"
  },
  {
    "text": "vals so",
    "start": "1048559",
    "end": "1051240"
  },
  {
    "text": "thanks",
    "start": "1052520",
    "end": "1055520"
  }
]
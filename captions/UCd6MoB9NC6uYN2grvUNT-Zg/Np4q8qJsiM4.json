[
  {
    "text": "hi my name is Matt n Andale I'm a senior",
    "start": "3120",
    "end": "5160"
  },
  {
    "text": "specialist Solutions architect at AWS",
    "start": "5160",
    "end": "7200"
  },
  {
    "text": "focusing on generative AI training and",
    "start": "7200",
    "end": "8880"
  },
  {
    "text": "inference in this video I will walk",
    "start": "8880",
    "end": "11120"
  },
  {
    "text": "through the steps for creating a",
    "start": "11120",
    "end": "12519"
  },
  {
    "text": "hyperpod cluster on Amazon sagemaker",
    "start": "12519",
    "end": "15400"
  },
  {
    "text": "before I do so let's walk through what's",
    "start": "15400",
    "end": "17600"
  },
  {
    "text": "involved in the process when creating a",
    "start": "17600",
    "end": "20039"
  },
  {
    "text": "sagemaker hyperpod cluster you need to",
    "start": "20039",
    "end": "22080"
  },
  {
    "text": "define the resources within your account",
    "start": "22080",
    "end": "24000"
  },
  {
    "text": "which you wish to integrate with",
    "start": "24000",
    "end": "25039"
  },
  {
    "text": "sagemaker",
    "start": "25039",
    "end": "26240"
  },
  {
    "text": "hyperpod for the sake of today's demo we",
    "start": "26240",
    "end": "29000"
  },
  {
    "text": "provide a sagemaker VPC Cloud",
    "start": "29000",
    "end": "30800"
  },
  {
    "text": "information template which sets up the",
    "start": "30800",
    "end": "32719"
  },
  {
    "text": "necessary networking and storage",
    "start": "32719",
    "end": "34239"
  },
  {
    "text": "infrastructure to deploy a sagemaker",
    "start": "34239",
    "end": "36239"
  },
  {
    "text": "hyperpod",
    "start": "36239",
    "end": "37800"
  },
  {
    "text": "cluster this template is also open-",
    "start": "37800",
    "end": "40000"
  },
  {
    "text": "sourced on our GitHub repository which",
    "start": "40000",
    "end": "41719"
  },
  {
    "text": "will be linked below the sagemaker VPC",
    "start": "41719",
    "end": "44160"
  },
  {
    "text": "template contains both a public and a",
    "start": "44160",
    "end": "46160"
  },
  {
    "text": "private subnet along with an internet",
    "start": "46160",
    "end": "47920"
  },
  {
    "text": "gateway and Knack gateways for managing",
    "start": "47920",
    "end": "49840"
  },
  {
    "text": "internet access the template also",
    "start": "49840",
    "end": "52079"
  },
  {
    "text": "includes security groups configured for",
    "start": "52079",
    "end": "54079"
  },
  {
    "text": "Amazon elastic fabric adapter or EFA",
    "start": "54079",
    "end": "57160"
  },
  {
    "text": "communication additionally it Provisions",
    "start": "57160",
    "end": "59359"
  },
  {
    "text": "an Amazon FSX for luster file system",
    "start": "59359",
    "end": "62239"
  },
  {
    "text": "which gives high performance storage and",
    "start": "62239",
    "end": "64518"
  },
  {
    "text": "optionally provides the availability to",
    "start": "64519",
    "end": "66360"
  },
  {
    "text": "create S3 endpoints and an S3 bucket",
    "start": "66360",
    "end": "69280"
  },
  {
    "text": "which will contain the life cycle",
    "start": "69280",
    "end": "70479"
  },
  {
    "text": "scripts used to deploy the cluster along",
    "start": "70479",
    "end": "72759"
  },
  {
    "text": "with an I am cluster execution Ro which",
    "start": "72759",
    "end": "75360"
  },
  {
    "text": "will give the sagemaker cluster",
    "start": "75360",
    "end": "77200"
  },
  {
    "text": "instances permissions to access AWS",
    "start": "77200",
    "end": "80280"
  },
  {
    "text": "resources here I Define the parameters",
    "start": "80280",
    "end": "82640"
  },
  {
    "text": "for my sagemaker hyperpod template here",
    "start": "82640",
    "end": "84840"
  },
  {
    "text": "I will enter the availability Zone",
    "start": "84840",
    "end": "86520"
  },
  {
    "text": "configuration for the subnets this is",
    "start": "86520",
    "end": "88680"
  },
  {
    "text": "the availability Zone which contains the",
    "start": "88680",
    "end": "90520"
  },
  {
    "text": "capacity used to create the cluster",
    "start": "90520",
    "end": "92759"
  },
  {
    "text": "additionally I will also Define",
    "start": "92759",
    "end": "94320"
  },
  {
    "text": "parameters for my Amazon FSX for luster",
    "start": "94320",
    "end": "96759"
  },
  {
    "text": "file system here I'm defining a 1.2",
    "start": "96759",
    "end": "99439"
  },
  {
    "text": "Tabit file system as well as creating an",
    "start": "99439",
    "end": "101920"
  },
  {
    "text": "S3 endpoint finally I'll leave the rest",
    "start": "101920",
    "end": "104439"
  },
  {
    "text": "as defaults including the luster version",
    "start": "104439",
    "end": "106560"
  },
  {
    "text": "and compression for the file system and",
    "start": "106560",
    "end": "109079"
  },
  {
    "text": "go ahead and create the stack while this",
    "start": "109079",
    "end": "112040"
  },
  {
    "text": "stack is spinning up let's take some",
    "start": "112040",
    "end": "113719"
  },
  {
    "text": "time to understand what else is required",
    "start": "113719",
    "end": "115719"
  },
  {
    "text": "to create a sagemaker hyperpod cluster",
    "start": "115719",
    "end": "118600"
  },
  {
    "text": "with the sagemaker VPC stack deploying",
    "start": "118600",
    "end": "121320"
  },
  {
    "text": "let's take a moment to understand",
    "start": "121320",
    "end": "122560"
  },
  {
    "text": "sagemaker hyper pod's life cycle scripts",
    "start": "122560",
    "end": "125640"
  },
  {
    "text": "life cycle scripts are a set of",
    "start": "125640",
    "end": "127119"
  },
  {
    "text": "customizable based scripts which",
    "start": "127119",
    "end": "128679"
  },
  {
    "text": "hyperpod uses to bootstrap your cluster",
    "start": "128679",
    "end": "130879"
  },
  {
    "text": "nodes when they're created life cycle",
    "start": "130879",
    "end": "133400"
  },
  {
    "text": "scripts can be used for things like",
    "start": "133400",
    "end": "134879"
  },
  {
    "text": "pre-installing particular packages",
    "start": "134879",
    "end": "137040"
  },
  {
    "text": "defining user access permissions",
    "start": "137040",
    "end": "139200"
  },
  {
    "text": "configuring cluster monitoring and",
    "start": "139200",
    "end": "141280"
  },
  {
    "text": "mounting shared storage to your cluster",
    "start": "141280",
    "end": "143800"
  },
  {
    "text": "we publish a base set of life cycle",
    "start": "143800",
    "end": "145400"
  },
  {
    "text": "scripts that follows our recommended",
    "start": "145400",
    "end": "146959"
  },
  {
    "text": "best practices to bootstrap your cluster",
    "start": "146959",
    "end": "149959"
  },
  {
    "text": "these best practices include things like",
    "start": "149959",
    "end": "151640"
  },
  {
    "text": "mounting an Amazon FSX for luster file",
    "start": "151640",
    "end": "153800"
  },
  {
    "text": "system creating posix users configuring",
    "start": "153800",
    "end": "156760"
  },
  {
    "text": "home directories on the nodes to map to",
    "start": "156760",
    "end": "158560"
  },
  {
    "text": "the shared file system configuring slurm",
    "start": "158560",
    "end": "161239"
  },
  {
    "text": "accounting optionally configuring user",
    "start": "161239",
    "end": "163519"
  },
  {
    "text": "access through El app server setting up",
    "start": "163519",
    "end": "166000"
  },
  {
    "text": "Prometheus for observability and finally",
    "start": "166000",
    "end": "168560"
  },
  {
    "text": "installing Docker and root and",
    "start": "168560",
    "end": "171920"
  },
  {
    "text": "pixies when your cluster is created",
    "start": "172280",
    "end": "174959"
  },
  {
    "text": "these set of life cycle scripts that you",
    "start": "174959",
    "end": "176599"
  },
  {
    "text": "define run on each cluster node at",
    "start": "176599",
    "end": "178879"
  },
  {
    "text": "creation point",
    "start": "178879",
    "end": "180879"
  },
  {
    "text": "sagemaker hyperpod will also run these",
    "start": "180879",
    "end": "183120"
  },
  {
    "text": "scripts anytime a replacement action is",
    "start": "183120",
    "end": "185720"
  },
  {
    "text": "is made within your cluster this",
    "start": "185720",
    "end": "187799"
  },
  {
    "text": "includes a hyperpod autor resume or",
    "start": "187799",
    "end": "189680"
  },
  {
    "text": "manual replace",
    "start": "189680",
    "end": "192440"
  },
  {
    "text": "action we publish our base set of life",
    "start": "192440",
    "end": "195000"
  },
  {
    "text": "cycle scripts to our GitHub awesome",
    "start": "195000",
    "end": "197280"
  },
  {
    "text": "distributed training repository we",
    "start": "197280",
    "end": "199720"
  },
  {
    "text": "recommend users clone these Bas life",
    "start": "199720",
    "end": "201599"
  },
  {
    "text": "cycle strips scripts and use or modify",
    "start": "201599",
    "end": "204319"
  },
  {
    "text": "them when creating their sagemaker",
    "start": "204319",
    "end": "205720"
  },
  {
    "text": "hyperpod cluster we will do that",
    "start": "205720",
    "end": "208760"
  },
  {
    "text": "today you can view the oncreate dosh",
    "start": "208760",
    "end": "211680"
  },
  {
    "text": "script here which is the entry point for",
    "start": "211680",
    "end": "213840"
  },
  {
    "text": "all of your sagemaker",
    "start": "213840",
    "end": "215480"
  },
  {
    "text": "hyperpod uh cluster life cycle",
    "start": "215480",
    "end": "218280"
  },
  {
    "text": "scripts in the script here we Define a",
    "start": "218280",
    "end": "220599"
  },
  {
    "text": "log file which will get output to cloud",
    "start": "220599",
    "end": "222560"
  },
  {
    "text": "formation for the cluster",
    "start": "222560",
    "end": "225480"
  },
  {
    "text": "provisioning as well as the resource",
    "start": "225480",
    "end": "227840"
  },
  {
    "text": "configuration path that gets installed",
    "start": "227840",
    "end": "229599"
  },
  {
    "text": "on our sagemaker cluster",
    "start": "229599",
    "end": "231840"
  },
  {
    "text": "nodes the life cycle script.py file is",
    "start": "231840",
    "end": "235000"
  },
  {
    "text": "where we Define the life cycle scripts",
    "start": "235000",
    "end": "238400"
  },
  {
    "text": "that will be called on each cluster",
    "start": "238400",
    "end": "240720"
  },
  {
    "text": "node here we can see the you the files",
    "start": "240720",
    "end": "243480"
  },
  {
    "text": "within our utils folder that that will",
    "start": "243480",
    "end": "245400"
  },
  {
    "text": "execute the specific actions on node",
    "start": "245400",
    "end": "247400"
  },
  {
    "text": "creation such as mounting FSX to the",
    "start": "247400",
    "end": "249760"
  },
  {
    "text": "auntu home directory installing Docker",
    "start": "249760",
    "end": "252879"
  },
  {
    "text": "and installing n rottin Pixies so now",
    "start": "252879",
    "end": "255239"
  },
  {
    "text": "that we've taken a look at the life",
    "start": "255239",
    "end": "256400"
  },
  {
    "text": "cycle",
    "start": "256400",
    "end": "258400"
  },
  {
    "text": "scripts let's understand what it what is",
    "start": "258400",
    "end": "261160"
  },
  {
    "text": "configured within a cluster",
    "start": "261160",
    "end": "262400"
  },
  {
    "text": "configuration",
    "start": "262400",
    "end": "263840"
  },
  {
    "text": "file the cluster configuration. Json",
    "start": "263840",
    "end": "266720"
  },
  {
    "text": "file is where you define your sagemaker",
    "start": "266720",
    "end": "268919"
  },
  {
    "text": "hyperpod param parameters including your",
    "start": "268919",
    "end": "270840"
  },
  {
    "text": "cluster name your controller node the",
    "start": "270840",
    "end": "274400"
  },
  {
    "text": "instance type of your controller node as",
    "start": "274400",
    "end": "276919"
  },
  {
    "text": "well as your worker groups in the",
    "start": "276919",
    "end": "278479"
  },
  {
    "text": "instance types and instance counts of",
    "start": "278479",
    "end": "280800"
  },
  {
    "text": "the nodes within your worker groups in",
    "start": "280800",
    "end": "283080"
  },
  {
    "text": "this example we have a worker group set",
    "start": "283080",
    "end": "285080"
  },
  {
    "text": "to mlp5 48x large with instance count",
    "start": "285080",
    "end": "288520"
  },
  {
    "text": "equal to 32 The Source S3 URI defined in",
    "start": "288520",
    "end": "292440"
  },
  {
    "text": "the cluster configuration",
    "start": "292440",
    "end": "294240"
  },
  {
    "text": "file includes the path to the S3 bucket",
    "start": "294240",
    "end": "297080"
  },
  {
    "text": "which contains our life cycle Scripts",
    "start": "297080",
    "end": "299759"
  },
  {
    "text": "finally with the cluster configuration",
    "start": "299759",
    "end": "301680"
  },
  {
    "text": "file created we execute the AWS sag",
    "start": "301680",
    "end": "304440"
  },
  {
    "text": "maker create cluster API and pass in",
    "start": "304440",
    "end": "307520"
  },
  {
    "text": "this cluster configuration. Json",
    "start": "307520",
    "end": "311080"
  },
  {
    "text": "file after about 15 to 20 minutes when",
    "start": "311080",
    "end": "313880"
  },
  {
    "text": "the cluster creates will ssh in to the",
    "start": "313880",
    "end": "317120"
  },
  {
    "text": "cluster via Amazon SSM or systems",
    "start": "317120",
    "end": "319280"
  },
  {
    "text": "manager session",
    "start": "319280",
    "end": "320560"
  },
  {
    "text": "manager with the sagemaker hyperpod",
    "start": "320560",
    "end": "322880"
  },
  {
    "text": "stack deployed now we can go ahead and",
    "start": "322880",
    "end": "325360"
  },
  {
    "text": "create our cluster to create the cluster",
    "start": "325360",
    "end": "328280"
  },
  {
    "text": "for today's demo we're going to be using",
    "start": "328280",
    "end": "330000"
  },
  {
    "text": "our easys setup.sh script which is",
    "start": "330000",
    "end": "332120"
  },
  {
    "text": "published to our awesome distributed",
    "start": "332120",
    "end": "333479"
  },
  {
    "text": "training",
    "start": "333479",
    "end": "334479"
  },
  {
    "text": "repository this script will read the",
    "start": "334479",
    "end": "336759"
  },
  {
    "text": "cloud information stack parameters that",
    "start": "336759",
    "end": "338600"
  },
  {
    "text": "were created in the previous step and",
    "start": "338600",
    "end": "340960"
  },
  {
    "text": "use those parameters to populate our",
    "start": "340960",
    "end": "342600"
  },
  {
    "text": "cluster configuration and call the",
    "start": "342600",
    "end": "344560"
  },
  {
    "text": "Amazon Sage maker create cluster",
    "start": "344560",
    "end": "348160"
  },
  {
    "text": "API let's see that in",
    "start": "348160",
    "end": "351840"
  },
  {
    "text": "action so first I'm going to curl this",
    "start": "353800",
    "end": "358039"
  },
  {
    "text": "script to receive it it from",
    "start": "358039",
    "end": "361440"
  },
  {
    "text": "GitHub now that I have the easy setup.sh",
    "start": "361440",
    "end": "364319"
  },
  {
    "text": "script in my",
    "start": "364319",
    "end": "366880"
  },
  {
    "text": "repository I am going to call",
    "start": "366880",
    "end": "370720"
  },
  {
    "text": "it and pass in the cluster",
    "start": "372199",
    "end": "376599"
  },
  {
    "text": "name head to my handy dandy cheat sheet",
    "start": "376680",
    "end": "381639"
  },
  {
    "text": "here I'm going to pass in the region",
    "start": "384240",
    "end": "386759"
  },
  {
    "text": "which is AP Southeast 2 in this case the",
    "start": "386759",
    "end": "389000"
  },
  {
    "text": "instance type P5 48x large as well as",
    "start": "389000",
    "end": "392319"
  },
  {
    "text": "the instance count which is",
    "start": "392319",
    "end": "394400"
  },
  {
    "text": "four I will also pass in the cluster",
    "start": "394400",
    "end": "396800"
  },
  {
    "text": "name ml cluster demo let's execute this",
    "start": "396800",
    "end": "399880"
  },
  {
    "text": "script and we'll see the output",
    "start": "399880",
    "end": "401840"
  },
  {
    "text": "beginning to be populated here the",
    "start": "401840",
    "end": "404000"
  },
  {
    "text": "script is reading my cloud information",
    "start": "404000",
    "end": "405680"
  },
  {
    "text": "stack for the resources that were",
    "start": "405680",
    "end": "407759"
  },
  {
    "text": "created including the subnets and the",
    "start": "407759",
    "end": "409479"
  },
  {
    "text": "FSX for",
    "start": "409479",
    "end": "411319"
  },
  {
    "text": "luster it's Gathering those and",
    "start": "411319",
    "end": "413560"
  },
  {
    "text": "uploading the life cycle scripts to S3",
    "start": "413560",
    "end": "416280"
  },
  {
    "text": "finally it's validating the",
    "start": "416280",
    "end": "417360"
  },
  {
    "text": "configuration and creating my cluster",
    "start": "417360",
    "end": "420440"
  },
  {
    "text": "as an output of the script I have a",
    "start": "420440",
    "end": "422039"
  },
  {
    "text": "cluster",
    "start": "422039",
    "end": "423199"
  },
  {
    "text": "Arn I'll be able to go to the Amazon",
    "start": "423199",
    "end": "425360"
  },
  {
    "text": "sagemaker console to view my cluster",
    "start": "425360",
    "end": "427199"
  },
  {
    "text": "being created",
    "start": "427199",
    "end": "429960"
  },
  {
    "text": "now so now I can navigate to the",
    "start": "431120",
    "end": "433240"
  },
  {
    "text": "sagemaker hyperpod console and view my",
    "start": "433240",
    "end": "435440"
  },
  {
    "text": "cluster I can see that cluster is now in",
    "start": "435440",
    "end": "438039"
  },
  {
    "text": "service uh it's changed from status",
    "start": "438039",
    "end": "440039"
  },
  {
    "text": "creating to inservice and the instance",
    "start": "440039",
    "end": "442919"
  },
  {
    "text": "nodes are also running this cluster",
    "start": "442919",
    "end": "445120"
  },
  {
    "text": "consists of a single controller node an",
    "start": "445120",
    "end": "447120"
  },
  {
    "text": "M5 12x large as well as four compute",
    "start": "447120",
    "end": "449960"
  },
  {
    "text": "nodes which are P5 48x large the",
    "start": "449960",
    "end": "453039"
  },
  {
    "text": "sagemaker hyperpod console also tells me",
    "start": "453039",
    "end": "455080"
  },
  {
    "text": "the S3 life cycle path that was used for",
    "start": "455080",
    "end": "458080"
  },
  {
    "text": "the life cycle scripts when creating",
    "start": "458080",
    "end": "459720"
  },
  {
    "text": "this cluster as well as the cluster",
    "start": "459720",
    "end": "461680"
  },
  {
    "text": "execution role additionally I can see",
    "start": "461680",
    "end": "464159"
  },
  {
    "text": "the security group in VPC subnets that",
    "start": "464159",
    "end": "466800"
  },
  {
    "text": "were configured for the sagemaker",
    "start": "466800",
    "end": "468560"
  },
  {
    "text": "hyperpod",
    "start": "468560",
    "end": "469599"
  },
  {
    "text": "cluster now that the cluster is in",
    "start": "469599",
    "end": "471520"
  },
  {
    "text": "service let's go ahead and connect to",
    "start": "471520",
    "end": "473039"
  },
  {
    "text": "the controller node to do so we will use",
    "start": "473039",
    "end": "476159"
  },
  {
    "text": "our easys SSH Dosh script which is",
    "start": "476159",
    "end": "478960"
  },
  {
    "text": "included our GitHub",
    "start": "478960",
    "end": "481159"
  },
  {
    "text": "repository so I'm going to curl this",
    "start": "481159",
    "end": "483159"
  },
  {
    "text": "script which will take in cluster name",
    "start": "483159",
    "end": "485800"
  },
  {
    "text": "as a parameter and use Amazon systems",
    "start": "485800",
    "end": "488319"
  },
  {
    "text": "manager session manager on the back end",
    "start": "488319",
    "end": "490479"
  },
  {
    "text": "to create a session with the controller",
    "start": "490479",
    "end": "492080"
  },
  {
    "text": "node of our sagemaker hyperpod",
    "start": "492080",
    "end": "495599"
  },
  {
    "text": "cluster Let Me Clear My screen and I'm",
    "start": "496680",
    "end": "499720"
  },
  {
    "text": "going to curl that script from",
    "start": "499720",
    "end": "503599"
  },
  {
    "text": "GitHub awesome now that I have the easy",
    "start": "506080",
    "end": "508560"
  },
  {
    "text": "SSH script I'm going to use it to",
    "start": "508560",
    "end": "510680"
  },
  {
    "text": "connect to my",
    "start": "510680",
    "end": "512159"
  },
  {
    "text": "cluster by passing the cluster name mlp5",
    "start": "512159",
    "end": "517479"
  },
  {
    "text": "cluster oh let me change permissions on",
    "start": "517479",
    "end": "520518"
  },
  {
    "text": "that",
    "start": "520519",
    "end": "522719"
  },
  {
    "text": "script and I will pass my cluster name",
    "start": "531800",
    "end": "534959"
  },
  {
    "text": "now on the back end the script is using",
    "start": "534959",
    "end": "537279"
  },
  {
    "text": "systems manager session manager to allow",
    "start": "537279",
    "end": "539200"
  },
  {
    "text": "me to to connect to the",
    "start": "539200",
    "end": "541040"
  },
  {
    "text": "cluster here I can log in as auntu user",
    "start": "541040",
    "end": "544360"
  },
  {
    "text": "by default if there were multiple users",
    "start": "544360",
    "end": "546160"
  },
  {
    "text": "on this cluster I might log in as my own",
    "start": "546160",
    "end": "548120"
  },
  {
    "text": "individual posic",
    "start": "548120",
    "end": "549839"
  },
  {
    "text": "user and now that I'm on the cluster",
    "start": "549839",
    "end": "551880"
  },
  {
    "text": "head node I'll run s info which will",
    "start": "551880",
    "end": "554279"
  },
  {
    "text": "show me the slurm State of the State of",
    "start": "554279",
    "end": "556880"
  },
  {
    "text": "the slurm nodes within the cluster snfo",
    "start": "556880",
    "end": "559360"
  },
  {
    "text": "is reported by the slurm controller",
    "start": "559360",
    "end": "560880"
  },
  {
    "text": "Damon which is running on the controller",
    "start": "560880",
    "end": "562480"
  },
  {
    "text": "node here I can see that I have four P5",
    "start": "562480",
    "end": "565560"
  },
  {
    "text": "nodes in my cluster the part they all",
    "start": "565560",
    "end": "568120"
  },
  {
    "text": "exist within both the dev which is the",
    "start": "568120",
    "end": "570120"
  },
  {
    "text": "default and the P5 48x large partition",
    "start": "570120",
    "end": "573120"
  },
  {
    "text": "which was created by hyperpod when I",
    "start": "573120",
    "end": "574880"
  },
  {
    "text": "when I built my",
    "start": "574880",
    "end": "576079"
  },
  {
    "text": "cluster I also have the IP addresses of",
    "start": "576079",
    "end": "578680"
  },
  {
    "text": "all the cluster",
    "start": "578680",
    "end": "581040"
  },
  {
    "text": "nodes now before I SSH into one of these",
    "start": "581040",
    "end": "584120"
  },
  {
    "text": "cluster nodes let me run uh DF minus",
    "start": "584120",
    "end": "588440"
  },
  {
    "text": "H here we can see that the shared FSX",
    "start": "588440",
    "end": "591560"
  },
  {
    "text": "for luster file system which is created",
    "start": "591560",
    "end": "594040"
  },
  {
    "text": "as 1.2 teyes is mounted onto the",
    "start": "594040",
    "end": "597079"
  },
  {
    "text": "controller node at Mount pointf",
    "start": "597079",
    "end": "600600"
  },
  {
    "text": "SX if I run PWD I also see that my home",
    "start": "600600",
    "end": "604079"
  },
  {
    "text": "directory is mounted at F uh FSX auntu",
    "start": "604079",
    "end": "608920"
  },
  {
    "text": "um this was configured by the life cycle",
    "start": "608920",
    "end": "610880"
  },
  {
    "text": "script that will Mount the home",
    "start": "610880",
    "end": "612320"
  },
  {
    "text": "directory for each user in this case",
    "start": "612320",
    "end": "614040"
  },
  {
    "text": "auntu user to the shared file",
    "start": "614040",
    "end": "617720"
  },
  {
    "text": "system now if I try to SSH into one of",
    "start": "617720",
    "end": "620560"
  },
  {
    "text": "these",
    "start": "620560",
    "end": "621839"
  },
  {
    "text": "nodes at cluster creation I will get a",
    "start": "621839",
    "end": "624440"
  },
  {
    "text": "permission denied that's because I",
    "start": "624440",
    "end": "626399"
  },
  {
    "text": "haven't created a public key yet so so",
    "start": "626399",
    "end": "629640"
  },
  {
    "text": "now as a Next Step I'll create a public",
    "start": "629640",
    "end": "632040"
  },
  {
    "text": "key we have instructions on doing so in",
    "start": "632040",
    "end": "634399"
  },
  {
    "text": "our",
    "start": "634399",
    "end": "635120"
  },
  {
    "text": "Workshop uh I've also got a handy helper",
    "start": "635120",
    "end": "637480"
  },
  {
    "text": "script here which I will pull",
    "start": "637480",
    "end": "640920"
  },
  {
    "text": "up so to create the uh public key and",
    "start": "641800",
    "end": "646160"
  },
  {
    "text": "mount that to the FSX file system I'm",
    "start": "646160",
    "end": "648120"
  },
  {
    "text": "going to CD into the SSH directory and",
    "start": "648120",
    "end": "652000"
  },
  {
    "text": "generate a new public key I'm then going",
    "start": "652000",
    "end": "654839"
  },
  {
    "text": "to write that key to the authorized key",
    "start": "654839",
    "end": "657040"
  },
  {
    "text": "file this will share that that SSH key",
    "start": "657040",
    "end": "660600"
  },
  {
    "text": "on the FSX file system which is mounted",
    "start": "660600",
    "end": "662600"
  },
  {
    "text": "on all the cluster nodes now that I've",
    "start": "662600",
    "end": "665000"
  },
  {
    "text": "done this I can CD back to my user",
    "start": "665000",
    "end": "667920"
  },
  {
    "text": "directory and SSH to one of the cluster",
    "start": "667920",
    "end": "671560"
  },
  {
    "text": "nodes and I should be prompted to",
    "start": "671560",
    "end": "674680"
  },
  {
    "text": "confirm great so now that I've SSH from",
    "start": "674680",
    "end": "678160"
  },
  {
    "text": "the controller node the m512 x large to",
    "start": "678160",
    "end": "681200"
  },
  {
    "text": "the cluster node the compute node the P5",
    "start": "681200",
    "end": "683800"
  },
  {
    "text": "48x",
    "start": "683800",
    "end": "685160"
  },
  {
    "text": "large I can run Nvidia SMI and see that",
    "start": "685160",
    "end": "689079"
  },
  {
    "text": "there 8 h100",
    "start": "689079",
    "end": "691680"
  },
  {
    "text": "gpus I can also run DF minus H as a",
    "start": "691680",
    "end": "695000"
  },
  {
    "text": "sanity check and see that we have our",
    "start": "695000",
    "end": "697800"
  },
  {
    "text": "FSX for luster shared file system",
    "start": "697800",
    "end": "699600"
  },
  {
    "text": "mounted to the compute node as well and",
    "start": "699600",
    "end": "702760"
  },
  {
    "text": "the P5 node also",
    "start": "702760",
    "end": "705639"
  },
  {
    "text": "contains uh nvme storage about 27",
    "start": "705639",
    "end": "708800"
  },
  {
    "text": "terabytes available nvme storage per P5",
    "start": "708800",
    "end": "714160"
  },
  {
    "text": "node from here I will exit and go back",
    "start": "714200",
    "end": "717079"
  },
  {
    "text": "to the controller node now that we've",
    "start": "717079",
    "end": "719680"
  },
  {
    "text": "gotten comfortable with operating uh a",
    "start": "719680",
    "end": "721760"
  },
  {
    "text": "sag maker hyperpod cluster at a very",
    "start": "721760",
    "end": "723639"
  },
  {
    "text": "high level in the next video we'll dive",
    "start": "723639",
    "end": "726240"
  },
  {
    "text": "into launching distributed training jobs",
    "start": "726240",
    "end": "728240"
  },
  {
    "text": "on sagemaker",
    "start": "728240",
    "end": "729600"
  },
  {
    "text": "hyperpod hope you'll join us thanks",
    "start": "729600",
    "end": "734399"
  }
]
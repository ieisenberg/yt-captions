[
  {
    "start": "0",
    "end": "130000"
  },
  {
    "text": "all right hi everybody we are getting ready to get started here I am just oh I",
    "start": "2060",
    "end": "13880"
  },
  {
    "text": "figured we would recap some of the things that we talked about last time",
    "start": "14630",
    "end": "19970"
  },
  {
    "text": "[Music] I'm just trying to get into the console here sorry I am Randall hunt I am",
    "start": "19970",
    "end": "28289"
  },
  {
    "text": "actually our hunt on Twitter I'm here on Sunil we are today I'm gonna be talking",
    "start": "28289",
    "end": "34050"
  },
  {
    "text": "about convolutional neural networks which is a really complicated thing that",
    "start": "34050",
    "end": "39690"
  },
  {
    "text": "I don't know anything about but I'm hoping I'm gonna learn about it today in the previous two episodes we are three",
    "start": "39690",
    "end": "47520"
  },
  {
    "text": "episodes too - okay in the previous two episodes we have covered the basics of",
    "start": "47520",
    "end": "55469"
  },
  {
    "text": "how to set up the deep learning am i how to build a multi-layer perceptron model",
    "start": "55469",
    "end": "66470"
  },
  {
    "text": "and then how to do kind of analysis from",
    "start": "66470",
    "end": "71909"
  },
  {
    "text": "there so last time what we did was we used Polly to translate what we used a",
    "start": "71909",
    "end": "78900"
  },
  {
    "text": "model to take a pronunciation of a word like aluminum or airplane or even our",
    "start": "78900",
    "end": "89340"
  },
  {
    "text": "names and we took that pronunciation and mapped it to the way person with a",
    "start": "89340",
    "end": "96119"
  },
  {
    "text": "different accent might pronounce it and then we pass that in to Polly and make Polly speak in one of the British voices",
    "start": "96119",
    "end": "103110"
  },
  {
    "text": "with an American accent for instance so that was kind of interesting they use the CMU dick model and some other stuff",
    "start": "103110",
    "end": "112229"
  },
  {
    "text": "and we kind of got it all working there at the end at least a little bit so",
    "start": "112229",
    "end": "119750"
  },
  {
    "text": "today what are we gonna be covering I'm gonna flip it over to your screen is",
    "start": "119750",
    "end": "124920"
  },
  {
    "text": "that all right yeah okay it's on your screen all right so",
    "start": "124920",
    "end": "134020"
  },
  {
    "start": "130000",
    "end": "430000"
  },
  {
    "text": "yeah today we will try and learn more about image recognition and also you",
    "start": "134020",
    "end": "140590"
  },
  {
    "text": "know how we can leverage combination neural networks which is a type of neural network to build these things",
    "start": "140590",
    "end": "149980"
  },
  {
    "text": "so the fundamental fundamentals that we learn here are applicable to other image",
    "start": "149980",
    "end": "157030"
  },
  {
    "text": "or video related you know problems as well so we've gone through basics of",
    "start": "157030",
    "end": "166810"
  },
  {
    "text": "neural networks in you know a couple of episodes already so we saw the first",
    "start": "166810",
    "end": "173830"
  },
  {
    "text": "episode with multi-layer perceptron being used for sentiment analysis we",
    "start": "173830",
    "end": "179860"
  },
  {
    "text": "could solve this problem today with a multi-layer perceptron as well but",
    "start": "179860",
    "end": "185140"
  },
  {
    "text": "conditional neural networks tend to do really well with images and we'll see why so today our task would will be to",
    "start": "185140",
    "end": "196140"
  },
  {
    "text": "classify or identify get given image",
    "start": "196140",
    "end": "201209"
  },
  {
    "text": "into a piece of clothing so our data set",
    "start": "201209",
    "end": "207970"
  },
  {
    "text": "actually has about ten different kinds of clothing and accessories so we have",
    "start": "207970",
    "end": "214510"
  },
  {
    "text": "t-shirts trousers dress coat bag ankle boot all these",
    "start": "214510",
    "end": "219670"
  },
  {
    "text": "categories are available and we have a lot of images there so it's called a",
    "start": "219670",
    "end": "227200"
  },
  {
    "text": "fashion M Nest data set and the reason",
    "start": "227200",
    "end": "232570"
  },
  {
    "text": "is M nest is a popular you know the",
    "start": "232570",
    "end": "238690"
  },
  {
    "text": "hundred handwritten digit recognition data set and I feel like that is",
    "start": "238690",
    "end": "244239"
  },
  {
    "text": "certainly been overused and which is why I didn't want to take that you know want",
    "start": "244239",
    "end": "250480"
  },
  {
    "text": "to take something a little more fun to kind of get started with convolutional neural networks",
    "start": "250480",
    "end": "257410"
  },
  {
    "text": "here with all the different machine learning tasks that we're trying to undertake we go through a series of",
    "start": "257410",
    "end": "263260"
  },
  {
    "text": "steps first it's getting data but and then second is applying labels to that",
    "start": "263260",
    "end": "270160"
  },
  {
    "text": "data or maybe the data already comes with some labels which is the easy mode give'em and then we transform that data",
    "start": "270160",
    "end": "276910"
  },
  {
    "text": "into a format that MX net or some library can understand good then we",
    "start": "276910",
    "end": "284350"
  },
  {
    "text": "build our model the the symbol we build the symbolic representation of our model",
    "start": "284350",
    "end": "290110"
  },
  {
    "text": "right did we execute that and train the model then we save the model and then we",
    "start": "290110",
    "end": "297340"
  },
  {
    "text": "can use it okay so glad I'm glad you've",
    "start": "297340",
    "end": "302470"
  },
  {
    "text": "been following along Randall yeah cool",
    "start": "302470",
    "end": "312180"
  },
  {
    "text": "so here's kind of like the data set you know it looks like this and I'm gonna",
    "start": "312180",
    "end": "320020"
  },
  {
    "text": "share the link on Twitch so people I",
    "start": "320020",
    "end": "325600"
  },
  {
    "text": "still can share links when you're hundreds yeah so okay I'm gonna make",
    "start": "325600",
    "end": "335830"
  },
  {
    "text": "sure link to you perfect",
    "start": "335830",
    "end": "342569"
  },
  {
    "text": "so so this is a you know fun little data set and you know it trains fast so it's",
    "start": "343950",
    "end": "351400"
  },
  {
    "text": "a good it's a good starting you know point but the concepts here are",
    "start": "351400",
    "end": "357490"
  },
  {
    "text": "translatable or reusable pretty much for more advanced use cases as well okay",
    "start": "357490",
    "end": "369449"
  },
  {
    "text": "alright so what I'm gonna do is as you can see the data set is available it's",
    "start": "369570",
    "end": "377320"
  },
  {
    "text": "actually got some weird a rather you know a compressed format so I'm not",
    "start": "377320",
    "end": "384100"
  },
  {
    "text": "gonna write the code to kind of transform this or load the data what we'll do",
    "start": "384100",
    "end": "390129"
  },
  {
    "text": "is go to the amnesty toriel on Amex net",
    "start": "390129",
    "end": "395319"
  },
  {
    "text": "and we're gonna copy the you know read data the code to read and unpack the",
    "start": "395319",
    "end": "402819"
  },
  {
    "text": "binary and get it into a numpy array so",
    "start": "402819",
    "end": "408969"
  },
  {
    "text": "it looks like a pretty reasonable format yeah so I'm gonna share this link with",
    "start": "408969",
    "end": "417219"
  },
  {
    "text": "you as well so that folks can copy the",
    "start": "417219",
    "end": "424050"
  },
  {
    "text": "loading part of the code and can we make",
    "start": "424050",
    "end": "431169"
  },
  {
    "start": "430000",
    "end": "740000"
  },
  {
    "text": "your screen your notebook page full screen yes we're not necessarily full",
    "start": "431169",
    "end": "441189"
  },
  {
    "text": "screen but just like maximize yep there you go Thanks hey do it do you need me",
    "start": "441189",
    "end": "449139"
  },
  {
    "text": "to zoom it I think a little bit of zoom would help yes",
    "start": "449139",
    "end": "454529"
  },
  {
    "text": "okay okay bit here cool so the eminence dataset was originally",
    "start": "459810",
    "end": "468550"
  },
  {
    "text": "hosted by young McCune and we can just change that path to fashion - amnesty s3",
    "start": "468550",
    "end": "479740"
  },
  {
    "text": "website EU central one Amazon AWS so we",
    "start": "479740",
    "end": "484990"
  },
  {
    "text": "can change the path attempt again I'm",
    "start": "484990",
    "end": "497620"
  },
  {
    "text": "sending a command to make you a mod but it's not working anyway oh do you get to",
    "start": "497620",
    "end": "507220"
  },
  {
    "text": "see the link okay that's it perfect alright good and then we can just",
    "start": "507220",
    "end": "518080"
  },
  {
    "text": "execute this code which loads the training label and validation labels",
    "start": "518080",
    "end": "523419"
  },
  {
    "text": "right so remember you know we're we're pretty much gonna cover on the supervised learning tasks they tend to",
    "start": "523419",
    "end": "531760"
  },
  {
    "text": "be relatively easier than unsupervised and this data set has clean sanitized",
    "start": "531760",
    "end": "537520"
  },
  {
    "text": "labels and it already comes in a training set and a validation set as",
    "start": "537520",
    "end": "545800"
  },
  {
    "text": "well right remember we we split the data into training and validation set the",
    "start": "545800",
    "end": "552070"
  },
  {
    "text": "network only trains on the training set the validation set is kept aside so that we are keeping in check to see how the",
    "start": "552070",
    "end": "560680"
  },
  {
    "text": "model performs because we want a generalized model we don't want to model",
    "start": "560680",
    "end": "566440"
  },
  {
    "text": "that is really you know kind of fixed per se and you know over fits into that",
    "start": "566440",
    "end": "575170"
  },
  {
    "text": "data set that it trained on we because ultimately we want to predict with some wild examples as well make sense yep and",
    "start": "575170",
    "end": "584829"
  },
  {
    "text": "then do you have a good estimate for what the size of the the training set is",
    "start": "584829",
    "end": "590310"
  },
  {
    "text": "the size of the verification set I mean relative numbers people go anywhere",
    "start": "590310",
    "end": "597510"
  },
  {
    "text": "between between 70 30 to something like a 90/10 so I would say like 20 25",
    "start": "597510",
    "end": "604950"
  },
  {
    "text": "percent is a good number to kind of keep the validation set aside but as far as",
    "start": "604950",
    "end": "611610"
  },
  {
    "text": "actual numbers it really varies on the problem so the rule of thumb is more",
    "start": "611610",
    "end": "618360"
  },
  {
    "text": "data you have the better it is for deep learning but you know your mitten which",
    "start": "618360",
    "end": "626100"
  },
  {
    "text": "may not be possible always so if you have let's say very small data set like",
    "start": "626100",
    "end": "633300"
  },
  {
    "text": "how can we leverage say free trade models or what are some of the techniques to do that and actually we'll",
    "start": "633300",
    "end": "640200"
  },
  {
    "text": "cover during the second half of this where we'll go with a smaller data set",
    "start": "640200",
    "end": "646290"
  },
  {
    "text": "and try and train so this is that'll be a fun use case I have not done this so I",
    "start": "646290",
    "end": "652740"
  },
  {
    "text": "had this crazy idea last night that you know the second part we will build a",
    "start": "652740",
    "end": "658770"
  },
  {
    "text": "model to identify if the image is Randall or not so so we will take a stab",
    "start": "658770",
    "end": "666300"
  },
  {
    "text": "at that yes let's let's see let's see if we can",
    "start": "666300",
    "end": "675120"
  },
  {
    "text": "get to that then that'd be a fun exercise and I know that the parentheses",
    "start": "675120",
    "end": "685490"
  },
  {
    "text": "like I am the parentheses around train label and train image you're not required I know it's a as I said I just",
    "start": "685490",
    "end": "697560"
  },
  {
    "text": "copied the code from the ms2 toriel websites there's a lot of non packet",
    "start": "697560",
    "end": "706230"
  },
  {
    "text": "code I will be writing in this tutorial",
    "start": "706230",
    "end": "712310"
  },
  {
    "text": "and I'm surprised the edges we need to run a lint after this before",
    "start": "712790",
    "end": "720010"
  },
  {
    "text": "we submit cool so I load the tape I load",
    "start": "720010",
    "end": "726190"
  },
  {
    "text": "the labels and the training set I've just pasted this mark down so that we",
    "start": "726190",
    "end": "733750"
  },
  {
    "text": "can just reference the code here so the",
    "start": "733750",
    "end": "739780"
  },
  {
    "text": "next part is let's just take a look at you know what data set import so let's",
    "start": "739780",
    "end": "758830"
  },
  {
    "start": "740000",
    "end": "830000"
  },
  {
    "text": "just do the plots in line so let's say",
    "start": "758830",
    "end": "764290"
  },
  {
    "text": "let's display what I'm trying to do is display like the first you know ten",
    "start": "764290",
    "end": "769810"
  },
  {
    "text": "images so my part lab so the subplot so",
    "start": "769810",
    "end": "787510"
  },
  {
    "text": "I'm creating you know one row with second images and this is the index of",
    "start": "787510",
    "end": "795910"
  },
  {
    "text": "the image and plot I so I'm going to",
    "start": "795910",
    "end": "802240"
  },
  {
    "text": "show the images I thought it'd be just like cool to visualize you know the",
    "start": "802240",
    "end": "807250"
  },
  {
    "text": "images that we have kind of like maybe I",
    "start": "807250",
    "end": "815020"
  },
  {
    "text": "can skip this see map we'll just turn",
    "start": "815020",
    "end": "820120"
  },
  {
    "text": "off the axis which is displaying images and so we're just 10 yeah and these are",
    "start": "820120",
    "end": "832060"
  },
  {
    "start": "830000",
    "end": "1340000"
  },
  {
    "text": "just like 28 pixels by 28 pixels or something correct yeah so it's a small data set I mean the images of tiny",
    "start": "832060",
    "end": "838290"
  },
  {
    "text": "images the coloring that's because if the matplotlib uses like BGR or",
    "start": "838290",
    "end": "844930"
  },
  {
    "text": "something right right so what what what I can do is say do this and this way it's all",
    "start": "844930",
    "end": "852550"
  },
  {
    "text": "grayscale cool so now that we've seen",
    "start": "852550",
    "end": "860100"
  },
  {
    "text": "seeing the data let's actually transform the data right so let's just like the",
    "start": "860100",
    "end": "872050"
  },
  {
    "text": "classic step right we needed to be fed to the next net let's just so so the",
    "start": "872050",
    "end": "884230"
  },
  {
    "text": "thing is I max net takes or pretty much",
    "start": "884230",
    "end": "890050"
  },
  {
    "text": "every you know framework kind of takes it in a certain shape the inputs so",
    "start": "890050",
    "end": "897819"
  },
  {
    "text": "usually it'll be something like you know bad size and for images we'll have a 3d",
    "start": "897819",
    "end": "904329"
  },
  {
    "text": "data right so 3d data is the number of channels the height and the width",
    "start": "904329",
    "end": "913350"
  },
  {
    "text": "yeah so width and height sorry so in our case you know whatever bad size is and",
    "start": "915810",
    "end": "927670"
  },
  {
    "text": "it'll be 1 comma 28 comma 28",
    "start": "927670",
    "end": "933370"
  },
  {
    "text": "because our height and width are 28 by 28 and our number of channels is 1",
    "start": "933370",
    "end": "939430"
  },
  {
    "text": "because we're just using greyscale well",
    "start": "939430",
    "end": "951189"
  },
  {
    "text": "that's a different question so it certainly may I I can't really say but",
    "start": "951189",
    "end": "958350"
  },
  {
    "text": "depends actually on the kind of prediction we might be doing so I'll",
    "start": "958350",
    "end": "967209"
  },
  {
    "text": "table that why don't you ask me the question in like maybe 20 minutes because so color we might learn other",
    "start": "967209",
    "end": "975279"
  },
  {
    "text": "features that are you know color independent right let's say I am",
    "start": "975279",
    "end": "980800"
  },
  {
    "text": "detecting you know versus a shoe I really didn't know I",
    "start": "980800",
    "end": "985810"
  },
  {
    "text": "really don't need the color correct but if I'm I'm trying to identify a red",
    "start": "985810",
    "end": "991420"
  },
  {
    "text": "palette this is a green parrot then well I need the color so but even even",
    "start": "991420",
    "end": "996490"
  },
  {
    "text": "greyscale isn't just one channel it's",
    "start": "996490",
    "end": "1003839"
  },
  {
    "text": "the little white picks over a black pencil right because that would be black and right white not a great deal but",
    "start": "1003839",
    "end": "1009180"
  },
  {
    "text": "then there there's intensity right so there's a number from zero each pixel has a value",
    "start": "1009180",
    "end": "1015660"
  },
  {
    "text": "from 0 to 255 cranks and we're actually",
    "start": "1015660",
    "end": "1022140"
  },
  {
    "text": "going to normalize that so let's say that sighs I don't know I'm just",
    "start": "1022140",
    "end": "1034980"
  },
  {
    "text": "arbitrarily picking a number here just like strain I try to write so remember",
    "start": "1034980",
    "end": "1042860"
  },
  {
    "text": "we had the ND array iterator which which",
    "start": "1042860",
    "end": "1050640"
  },
  {
    "text": "basically takes you know first it takes the input array the label right the bad",
    "start": "1050640",
    "end": "1060390"
  },
  {
    "text": "size and you know we have the option to shuffle our input and shuffling is",
    "start": "1060390",
    "end": "1067470"
  },
  {
    "text": "always good because any kind of natural ordering is kind of disrupted and the",
    "start": "1067470",
    "end": "1074669"
  },
  {
    "text": "model tends to converge faster when you shuffle the data we when we were using",
    "start": "1074669",
    "end": "1080669"
  },
  {
    "text": "the one hi no the one heart is a",
    "start": "1080669",
    "end": "1087900"
  },
  {
    "text": "representation of of just you know",
    "start": "1087900",
    "end": "1095400"
  },
  {
    "text": "representing the label or data in a format that is consumable by the model so yeah but it does help what it does is",
    "start": "1095400",
    "end": "1107580"
  },
  {
    "text": "it actually helps the model not assume natural ordering right let's say in this",
    "start": "1107580",
    "end": "1114630"
  },
  {
    "text": "case that we have categories correct so that's a you know t-shirt",
    "start": "1114630",
    "end": "1120270"
  },
  {
    "text": "ankle boots there's no real ordering here right and we kind of don't want",
    "start": "1120270",
    "end": "1126809"
  },
  {
    "text": "when we you know dealing with like sensitive or rather like very sparse",
    "start": "1126809",
    "end": "1134760"
  },
  {
    "text": "data sets or judges from a correctness perspective it's dangerous to let the",
    "start": "1134760",
    "end": "1140730"
  },
  {
    "text": "model assume something so we can one-hot encode the labels so that you know",
    "start": "1140730",
    "end": "1149250"
  },
  {
    "text": "there's some kind of authoring that we bring to the table okay and Herbert",
    "start": "1149250",
    "end": "1157590"
  },
  {
    "text": "Kelly asked me to turn off my mic so I'm turning up my mic and similarly we'll do",
    "start": "1157590",
    "end": "1165750"
  },
  {
    "text": "the validation item but here's the thing right like we need to convert the the",
    "start": "1165750",
    "end": "1175110"
  },
  {
    "text": "data into this four D shape right so we'll just do a 240 you know function",
    "start": "1175110",
    "end": "1184610"
  },
  {
    "text": "and what we'll do is we'll reshape the image so the reshape function you know",
    "start": "1184610",
    "end": "1193110"
  },
  {
    "text": "takes so we'll need to get the shape of",
    "start": "1193110",
    "end": "1199860"
  },
  {
    "text": "the image first so we can just do image dot shape of 0 which gives us so I'll",
    "start": "1199860",
    "end": "1208020"
  },
  {
    "text": "just show an example it's called",
    "start": "1208020",
    "end": "1213200"
  },
  {
    "text": "training image right let's not just",
    "start": "1213200",
    "end": "1219480"
  },
  {
    "text": "assume that so we'll just use rather than hard coding I'm just accessing our",
    "start": "1219480",
    "end": "1226710"
  },
  {
    "text": "channel here and what we'll do is we'll",
    "start": "1226710",
    "end": "1233820"
  },
  {
    "text": "just we'll just we we just cast then",
    "start": "1233820",
    "end": "1239280"
  },
  {
    "text": "this as a float value so what we can do",
    "start": "1239280",
    "end": "1245970"
  },
  {
    "text": "is use an p dot float 32",
    "start": "1245970",
    "end": "1251220"
  },
  {
    "text": "/ 255 we'll just normalize all our pixel values okay crack yeah and label is",
    "start": "1251220",
    "end": "1268770"
  },
  {
    "text": "already in that shape it what's called",
    "start": "1268770",
    "end": "1275010"
  },
  {
    "text": "do we need to do some sort of like list comprehension or something or is it gonna work on the whole array yeah",
    "start": "1275010",
    "end": "1282240"
  },
  {
    "text": "because it's actually in numpy array",
    "start": "1282240",
    "end": "1286070"
  },
  {
    "text": "so well sorry",
    "start": "1290000",
    "end": "1297680"
  },
  {
    "text": "yeah okay",
    "start": "1299210",
    "end": "1303500"
  },
  {
    "text": "there you go I worked so you can see here this is a",
    "start": "1310270",
    "end": "1315679"
  },
  {
    "text": "bad size we've got the data that's actually a pointer to the data as you can see the nandi array and it's assumed",
    "start": "1315679",
    "end": "1322910"
  },
  {
    "text": "that it's you know we're still working in the CPU realm of things so it's actually bound to the CPU we've got the",
    "start": "1322910",
    "end": "1329870"
  },
  {
    "text": "label yeah so this is essentially our",
    "start": "1329870",
    "end": "1335870"
  },
  {
    "text": "data now okay so pretty much you know",
    "start": "1335870",
    "end": "1342380"
  },
  {
    "start": "1340000",
    "end": "2060000"
  },
  {
    "text": "this is pretty easy right like we this is our easy data set now we can actually start the model already but you know I",
    "start": "1342380",
    "end": "1352100"
  },
  {
    "text": "thought it'd be good to kind of cover some of the basics of what's happening",
    "start": "1352100",
    "end": "1358539"
  },
  {
    "text": "so I just saw what's on your screen and I am terrified because this takes me back to high school well I'm gonna scare",
    "start": "1360010",
    "end": "1368659"
  },
  {
    "text": "you for the next two minutes and then say like you don't need to worry about anything okay so the idea here I'll you",
    "start": "1368659",
    "end": "1378650"
  },
  {
    "text": "know there are other better resources you're gonna go dive into actual math again because we're focusing on",
    "start": "1378650",
    "end": "1384409"
  },
  {
    "text": "developers we'll just kind of like treat this more hey this is all we need to",
    "start": "1384409",
    "end": "1391190"
  },
  {
    "text": "know and we know this works under the hood and we're just gonna access it like we do like any other API s-- so the",
    "start": "1391190",
    "end": "1400640"
  },
  {
    "text": "intuition here with Commission's if you remember with traditional machine",
    "start": "1400640",
    "end": "1405950"
  },
  {
    "text": "learning tasks right so we do a lot of like feature engineering and identifying which features remember with sentiment",
    "start": "1405950",
    "end": "1414110"
  },
  {
    "text": "analysis we broke things down into words right so in this case we need to do",
    "start": "1414110",
    "end": "1419270"
  },
  {
    "text": "something similar and what it happened what what it's proven is over the last",
    "start": "1419270",
    "end": "1426740"
  },
  {
    "text": "few years convolutions have become this amazing thing to extract features from",
    "start": "1426740",
    "end": "1432440"
  },
  {
    "text": "images so what what essentially we do is we define little filters and these",
    "start": "1432440",
    "end": "1440630"
  },
  {
    "text": "filters are tract features from images okay",
    "start": "1440630",
    "end": "1445789"
  },
  {
    "text": "you're with me redefine filters filters are extracting features from the image",
    "start": "1445789",
    "end": "1451250"
  },
  {
    "text": "crack so delight is your goal in nature right it's like correctness filter",
    "start": "1451250",
    "end": "1456350"
  },
  {
    "text": "correct a filter is also called a kernel and in in and they happen to be matrices",
    "start": "1456350",
    "end": "1463400"
  },
  {
    "text": "like these because we're dealing in two dimensions right images are two-dimensional and we we basically",
    "start": "1463400",
    "end": "1472730"
  },
  {
    "text": "define these filters and we run those filters through the matrix so as you can",
    "start": "1472730",
    "end": "1481250"
  },
  {
    "text": "see here let's say our filter is you",
    "start": "1481250",
    "end": "1486559"
  },
  {
    "text": "know this becomes our filter we run the filter through the matrix so what it's",
    "start": "1486559",
    "end": "1491840"
  },
  {
    "text": "doing is it's doing matrix multiplication and we get the outputs",
    "start": "1491840",
    "end": "1497450"
  },
  {
    "text": "transformed or we capture the outputs of as we convolve through the matrix and",
    "start": "1497450",
    "end": "1504700"
  },
  {
    "text": "I'll build up intuition on what the filters do so here's here's actually an",
    "start": "1504700",
    "end": "1510740"
  },
  {
    "text": "example of you know four different filters what happens so as you can see a",
    "start": "1510740",
    "end": "1519169"
  },
  {
    "text": "certain filter like this filter happens to identify edges in a certain direction",
    "start": "1519169",
    "end": "1524919"
  },
  {
    "text": "this filter again a different direction and this filter seems to you know",
    "start": "1524919",
    "end": "1532159"
  },
  {
    "text": "identify more like edge so it's kind of like edges in kind of with an angle and",
    "start": "1532159",
    "end": "1541360"
  },
  {
    "text": "certain filters can blur they can sharpen they can identify textures and",
    "start": "1541360",
    "end": "1547580"
  },
  {
    "text": "so on asking are they always 3d matrix",
    "start": "1547580",
    "end": "1555950"
  },
  {
    "text": "ie RGB specifically or images so",
    "start": "1555950",
    "end": "1563440"
  },
  {
    "text": "convolution in general is you can do in any dimension so you can do a one",
    "start": "1563440",
    "end": "1569600"
  },
  {
    "text": "deconvolution you can do a 2d convolution 3d convolution and so on depends on like how your input is",
    "start": "1569600",
    "end": "1576950"
  },
  {
    "text": "structured in this case we happen to have our images into you know as a 2d",
    "start": "1576950",
    "end": "1582950"
  },
  {
    "text": "matrix and which is why we will just do a 2d convolution so we're using the word",
    "start": "1582950",
    "end": "1590150"
  },
  {
    "text": "convolution a lot but I don't actually I know that it is an operation that you perform on a matrix but I don't remember",
    "start": "1590150",
    "end": "1597200"
  },
  {
    "text": "how it works I don't like I don't remember how to convulse um thing is that something that you have any time to",
    "start": "1597200",
    "end": "1603770"
  },
  {
    "text": "cover or I don't but I have links shared",
    "start": "1603770",
    "end": "1609680"
  },
  {
    "text": "links to do like the mathematical intuition between convolutions but for",
    "start": "1609680",
    "end": "1616010"
  },
  {
    "text": "the sake of this lecture we can just say you know we we use filters and we'll run",
    "start": "1616010",
    "end": "1624440"
  },
  {
    "text": "the filters through images to extract features and we'll work on those features to do our image classification",
    "start": "1624440",
    "end": "1632560"
  },
  {
    "text": "and is there anything stopping us from running all of these filters in parallel",
    "start": "1632560",
    "end": "1638530"
  },
  {
    "text": "really because we're not yeah we were",
    "start": "1638530",
    "end": "1645200"
  },
  {
    "text": "doing it independently and that's probably where we can get a lot of gains in terms of speed as we can say yeah",
    "start": "1645200",
    "end": "1652940"
  },
  {
    "text": "feature maps for like 28 features that we've identified we're gonna run on all 28 at once because we have it on you",
    "start": "1652940",
    "end": "1658790"
  },
  {
    "text": "know on the CPU or GPU yep absolutely so what I do is I'll just play this",
    "start": "1658790",
    "end": "1664790"
  },
  {
    "text": "little video and you know just yeah this",
    "start": "1664790",
    "end": "1675830"
  },
  {
    "text": "should help kind of get an idea as you can see we ran a certain filter with the",
    "start": "1675830",
    "end": "1682100"
  },
  {
    "text": "edge you know slightly slanted in this",
    "start": "1682100",
    "end": "1688430"
  },
  {
    "text": "way and you know it identified you know this is this essentially is a result of",
    "start": "1688430",
    "end": "1695510"
  },
  {
    "text": "the convolution that we did and it you know is identified this is the feature",
    "start": "1695510",
    "end": "1702200"
  },
  {
    "text": "map okay now similarly there's a different you can you can see the green one",
    "start": "1702200",
    "end": "1718870"
  },
  {
    "text": "one was with an edge in this direction or the one with an edge this in this",
    "start": "1722990",
    "end": "1728749"
  },
  {
    "text": "direction so so you can kind of imagine that we can you know build a bunch of",
    "start": "1728749",
    "end": "1734990"
  },
  {
    "text": "these filters to extract many features",
    "start": "1734990",
    "end": "1740799"
  },
  {
    "text": "yeah yep a lot of a lot of for example a",
    "start": "1747820",
    "end": "1754129"
  },
  {
    "text": "lot of only blood detection algorithms use use filters or on or laplacian our",
    "start": "1754129",
    "end": "1766940"
  },
  {
    "text": "you know edge detectors or canny edge detectors to kind of find the edges and",
    "start": "1766940",
    "end": "1772100"
  },
  {
    "text": "depending upon how many edges that you kind of find you can identify if images",
    "start": "1772100",
    "end": "1778909"
  },
  {
    "text": "you know sharp or not because if you have more edges the image is sharp if",
    "start": "1778909",
    "end": "1785809"
  },
  {
    "text": "it's blood and it's kind of smarts so you don't find many edges right so so a",
    "start": "1785809",
    "end": "1791090"
  },
  {
    "text": "lot of that is actually built in to this and we don't need to explicitly kind of",
    "start": "1791090",
    "end": "1797960"
  },
  {
    "text": "go extract these features as you'll see the framework does the heavy lifting for",
    "start": "1797960",
    "end": "1803659"
  },
  {
    "text": "us that's really like everything just sort of clicked in my mind right now so",
    "start": "1803659",
    "end": "1810429"
  },
  {
    "text": "nice it's just math right it's just it's just taking a major exact lie across the",
    "start": "1810429",
    "end": "1819860"
  },
  {
    "text": "earth okay correct as you can see here right so we can just do this we can just",
    "start": "1819860",
    "end": "1826309"
  },
  {
    "text": "multiply with this filter and we now have a block we we can we can define our own blur filters",
    "start": "1826309",
    "end": "1834190"
  },
  {
    "text": "as ten years ago it's okay not too late",
    "start": "1834860",
    "end": "1841150"
  },
  {
    "text": "so the next the next thing is we will run will pass through an activation",
    "start": "1841150",
    "end": "1849830"
  },
  {
    "text": "function because we need to remember if you remember we needed to add a non-linearity to be able to kind of",
    "start": "1849830",
    "end": "1858140"
  },
  {
    "text": "classify a rather map to a much higher dimension right so we're with so the",
    "start": "1858140",
    "end": "1866059"
  },
  {
    "text": "traditional machine learning algorithms which are linear classifiers we can only do so many things with non-linearity we",
    "start": "1866059",
    "end": "1873740"
  },
  {
    "text": "get more degrees of freedom and we can solve more complex problems so we run it",
    "start": "1873740",
    "end": "1880400"
  },
  {
    "text": "through an activation function and this is just an example of the activation function to you know what once it's",
    "start": "1880400",
    "end": "1890960"
  },
  {
    "text": "faster the activation function after the feature map extraction how it looks",
    "start": "1890960",
    "end": "1898299"
  },
  {
    "text": "the next step is actually something called a spooling so you know if you're",
    "start": "1898370",
    "end": "1906169"
  },
  {
    "text": "gonna do like 728 into 28 which is a 756 that's a lot of like it's it's quite",
    "start": "1906169",
    "end": "1915470"
  },
  {
    "text": "large now imagine if we were working with you know 256 by 256 images then it",
    "start": "1915470",
    "end": "1921799"
  },
  {
    "text": "just becomes way too large now the intuition is I don't really need a miss",
    "start": "1921799",
    "end": "1930230"
  },
  {
    "text": "to be that big to say it's a cat or a dog or a t-shirt I just I just don't",
    "start": "1930230",
    "end": "1936230"
  },
  {
    "text": "even need it to be that big so what we do is an operation called pooling where",
    "start": "1936230",
    "end": "1941620"
  },
  {
    "text": "we reduce the size of the image by taking the max of adjacent pixels now",
    "start": "1941620",
    "end": "1950799"
  },
  {
    "text": "again since this is 2d will basically say hey max pool of two by two filters",
    "start": "1950799",
    "end": "1958100"
  },
  {
    "text": "and we'll pass it just like the convolution but the operation here is if",
    "start": "1958100",
    "end": "1964460"
  },
  {
    "text": "we'd say it's max pooling we'll take the max of the adjacent pixel values we can do average and so on does that",
    "start": "1964460",
    "end": "1974480"
  },
  {
    "text": "make sense I get it I the reason we have to do this though",
    "start": "1974480",
    "end": "1980420"
  },
  {
    "text": "is not necessarily mathematical it's more computational like it's exactly",
    "start": "1980420",
    "end": "1986960"
  },
  {
    "text": "yeah we don't because hey we can do faster mother you know matrix multiplications with this we don't",
    "start": "1986960",
    "end": "1993980"
  },
  {
    "text": "really need to have a much bigger you know image or matrix to work on so when",
    "start": "1993980",
    "end": "2004720"
  },
  {
    "text": "we have something that is small enough to fit in a register or if it and you",
    "start": "2004720",
    "end": "2010120"
  },
  {
    "text": "know a cache it's gonna be way faster than if we have to pull in a megabyte worth of hijra every time yeah yep so",
    "start": "2010120",
    "end": "2020100"
  },
  {
    "text": "okay so now that we know about",
    "start": "2020100",
    "end": "2026160"
  },
  {
    "text": "convolutions that's actually stopped a model so we'll use one of the most basic",
    "start": "2026160",
    "end": "2037920"
  },
  {
    "text": "conditional network that young laoco√∂n",
    "start": "2037920",
    "end": "2043390"
  },
  {
    "text": "proposed way back in 95 to do handle",
    "start": "2043390",
    "end": "2048810"
  },
  {
    "text": "classification and we'll see how we can change maybe different functions and activation functions and see if we can",
    "start": "2048810",
    "end": "2056350"
  },
  {
    "text": "improve the results from that basic network so as usual we declare our you know we",
    "start": "2056350",
    "end": "2066060"
  },
  {
    "start": "2060000",
    "end": "2230000"
  },
  {
    "text": "placeholder variable data and then we'll",
    "start": "2066060",
    "end": "2071590"
  },
  {
    "text": "start declaring our convolution so we'll do MX dots in convolution so so we've",
    "start": "2071590",
    "end": "2079270"
  },
  {
    "text": "never covered convolution so this is a new part of the next net epi correct",
    "start": "2079270",
    "end": "2084460"
  },
  {
    "text": "so let's look up the convolution operation correct",
    "start": "2084460",
    "end": "2091419"
  },
  {
    "text": "okay so the convolution API is pretty cool we just need to send it the data",
    "start": "2091420",
    "end": "2096909"
  },
  {
    "text": "and [Music] so it's as you can see there are",
    "start": "2096910",
    "end": "2103420"
  },
  {
    "text": "different kinds of conversation here right so we can give it that the data the kernel the kernel is essentially the",
    "start": "2103420",
    "end": "2110680"
  },
  {
    "text": "the size right so it's a three by three five by five what's our kernel size",
    "start": "2110680",
    "end": "2116280"
  },
  {
    "text": "stride is do we skip certain steps it's the window size right so if do we go do",
    "start": "2116280",
    "end": "2124540"
  },
  {
    "text": "we skip two things stride of one is essentially we'll just go one by one and slide the window",
    "start": "2124540",
    "end": "2130360"
  },
  {
    "text": "if stride is equal to 2 that means that we will skip a couple of you know",
    "start": "2130360",
    "end": "2136470"
  },
  {
    "text": "columns and then you know slide the window so things like that so it's all",
    "start": "2136470",
    "end": "2141730"
  },
  {
    "text": "built in and we can just specify the number of filters and the framework will",
    "start": "2141730",
    "end": "2148300"
  },
  {
    "text": "figure out what filters it needs to generate and actually do that for us so",
    "start": "2148300",
    "end": "2153570"
  },
  {
    "text": "so our so our API looks trying to find",
    "start": "2153570",
    "end": "2164460"
  },
  {
    "text": "actually wrong which let's try to find a",
    "start": "2164640",
    "end": "2170770"
  },
  {
    "text": "example sample right like a convolution",
    "start": "2170770",
    "end": "2183960"
  },
  {
    "text": "so we'll say data equal to theta and then kernel right so kernel will specify",
    "start": "2192040",
    "end": "2200090"
  },
  {
    "text": "our kernel we'll just say five by five I know again we can use three by three I'm",
    "start": "2200090",
    "end": "2207710"
  },
  {
    "text": "just I think this would be a good start so a number of filters will go into twenty filters so the next the next step",
    "start": "2207710",
    "end": "2219080"
  },
  {
    "text": "is to send this through an activation function right so I make starts and we",
    "start": "2219080",
    "end": "2225349"
  },
  {
    "text": "can just say activation so they're the",
    "start": "2225349",
    "end": "2230990"
  },
  {
    "start": "2230000",
    "end": "2420000"
  },
  {
    "text": "very young and you can see there I go to con one here there are different",
    "start": "2230990",
    "end": "2237020"
  },
  {
    "text": "activation functions so we'll have like Danette sigmoid value the most common",
    "start": "2237020",
    "end": "2244609"
  },
  {
    "text": "one is rel you but that was proposed back in 2012 and since we are using the",
    "start": "2244609",
    "end": "2251570"
  },
  {
    "text": "most basic network which is 95 I thought it'd be just good to kind of cover and",
    "start": "2251570",
    "end": "2258140"
  },
  {
    "text": "play with different activation functions so we'll still go with the primitive",
    "start": "2258140",
    "end": "2265210"
  },
  {
    "text": "activation function to start with they",
    "start": "2265210",
    "end": "2271190"
  },
  {
    "text": "go these are the activation functions that are available for us so sigmoid",
    "start": "2271190",
    "end": "2277160"
  },
  {
    "text": "canach software lu and raloo so sigma",
    "start": "2277160",
    "end": "2282650"
  },
  {
    "text": "the the the reason why these functions are helpful they add non-linearity right",
    "start": "2282650",
    "end": "2290119"
  },
  {
    "text": "so",
    "start": "2290119",
    "end": "2292390"
  },
  {
    "text": "[Music]",
    "start": "2295820",
    "end": "2298989"
  },
  {
    "text": "let me see if we have right Haga do you",
    "start": "2302549",
    "end": "2309519"
  },
  {
    "text": "see the shape right so they have nice s shape with like Sigma and can edge right",
    "start": "2309519",
    "end": "2316269"
  },
  {
    "text": "well what that means is they give these they kind of like could either the",
    "start": "2316269",
    "end": "2322329"
  },
  {
    "text": "inputs between like 0 & 1 or minus 1 to 1 they kind of give this nice shape",
    "start": "2322329",
    "end": "2328439"
  },
  {
    "text": "where you know because this is a continuous function we can differentiate",
    "start": "2328439",
    "end": "2333669"
  },
  {
    "text": "through that and we can this adds to",
    "start": "2333669",
    "end": "2338709"
  },
  {
    "text": "non-linearity which is important to give us more so to speak degrees of freedom",
    "start": "2338709",
    "end": "2345849"
  },
  {
    "text": "to help with you know finding that crazy function shapes which will allow us to",
    "start": "2345849",
    "end": "2351489"
  },
  {
    "text": "do more complex tasks because we're basically trying to find a function that that will map to whatever our input is",
    "start": "2351489",
    "end": "2360509"
  },
  {
    "text": "yeah so if you remember the neural network equation right so it's it's",
    "start": "2360509",
    "end": "2367809"
  },
  {
    "text": "basically WX plus B where X is the input",
    "start": "2367809",
    "end": "2373479"
  },
  {
    "text": "and W is the weight matrix we're trying to find the weights for each of those",
    "start": "2373479",
    "end": "2379269"
  },
  {
    "text": "connections in in our network so like",
    "start": "2379269",
    "end": "2387189"
  },
  {
    "text": "that's that's our task if we had linear",
    "start": "2387189",
    "end": "2392289"
  },
  {
    "text": "weights then it's just a linear combination we won't be able to find the best you know weights or rather it",
    "start": "2392289",
    "end": "2401139"
  },
  {
    "text": "becomes a simple function we need a very complex function and adding the non-linearity helps us get there okay",
    "start": "2401139",
    "end": "2407109"
  },
  {
    "text": "and I mean that's the intuition I'm",
    "start": "2407109",
    "end": "2413229"
  },
  {
    "text": "trying to not scare the audience I'm scared okay so the next idea is adding",
    "start": "2413229",
    "end": "2425439"
  },
  {
    "start": "2420000",
    "end": "2540000"
  },
  {
    "text": "the pooling layer so I max out send pooling data equal to",
    "start": "2425439",
    "end": "2431190"
  },
  {
    "text": "activation and let's look at the pooling layer there you go",
    "start": "2431190",
    "end": "2442760"
  },
  {
    "text": "similar pooling it takes the data out it",
    "start": "2442760",
    "end": "2448710"
  },
  {
    "text": "again takes the color we can have a pool type and a stride we'll just let all",
    "start": "2448710",
    "end": "2455849"
  },
  {
    "text": "those two defaults and we'll just say",
    "start": "2455849",
    "end": "2461210"
  },
  {
    "text": "pool type equal to we'll just use max pooling yeah and you know you can try",
    "start": "2461210",
    "end": "2473880"
  },
  {
    "text": "average pooling and other pooling generally with images people tend to use max pooling average pooling kind of like",
    "start": "2473880",
    "end": "2481819"
  },
  {
    "text": "deforms the images like that's kind of kind of my intuition behind but people",
    "start": "2481819",
    "end": "2489510"
  },
  {
    "text": "tend to use max pooling a lot and in terms of like image recognition stuff",
    "start": "2489510",
    "end": "2495589"
  },
  {
    "text": "again there might be a better reason for using max pooling but I feel as I said",
    "start": "2495589",
    "end": "2501450"
  },
  {
    "text": "like you know it still kind of retains the image when you pull down rather than",
    "start": "2501450",
    "end": "2507690"
  },
  {
    "text": "an average which kind of like smudges the entire image because the edges in",
    "start": "2507690",
    "end": "2514079"
  },
  {
    "text": "pixels is going to get you know smoothened out right okay does that make",
    "start": "2514079",
    "end": "2521490"
  },
  {
    "text": "sense or gotcha so yeah so we can you just leave it here",
    "start": "2521490",
    "end": "2533599"
  },
  {
    "text": "so the intuition behind how portions of",
    "start": "2533599",
    "end": "2541970"
  },
  {
    "start": "2540000",
    "end": "2840000"
  },
  {
    "text": "adding the non-linearity I get the pooling I get the activation function",
    "start": "2541970",
    "end": "2547609"
  },
  {
    "text": "and I get the convolution but I don't fully grok how you know your your your",
    "start": "2547609",
    "end": "2558000"
  },
  {
    "text": "doing a four pixel kernel for the the",
    "start": "2558000",
    "end": "2564089"
  },
  {
    "text": "max pooling and then you're doing a 5 or a 25 pixel",
    "start": "2564089",
    "end": "2572390"
  },
  {
    "text": "kernel for the for the convolution and the features and yeah it's I feel like",
    "start": "2572390",
    "end": "2580499"
  },
  {
    "text": "that stuff is still kind of like arbitrarily chosen and you like max pooling I guess the the 4 pixels is a",
    "start": "2580499",
    "end": "2587430"
  },
  {
    "text": "sense that's that's pretty straightforward but the kernel size and yeah stuff like that I don't so the",
    "start": "2587430",
    "end": "2594390"
  },
  {
    "text": "kernel size again like depends on you know people tend to use 3 by 3 or 5 by 5",
    "start": "2594390",
    "end": "2601170"
  },
  {
    "text": "are generally the two kernel sizes that we tend to use why I chose 5x5 because",
    "start": "2601170",
    "end": "2609539"
  },
  {
    "text": "that was originally again I'm trying to recreate the Anglicans Lynette the first",
    "start": "2609539",
    "end": "2616380"
  },
  {
    "text": "kind of like convolutional network right so hence 5x5 and that's what he",
    "start": "2616380",
    "end": "2622319"
  },
  {
    "text": "empirically found to be better but people kind of starting with",
    "start": "2622319",
    "end": "2628079"
  },
  {
    "text": "convolutional Network I would just start with like 3 by 3 and 5 by 5 see kind of",
    "start": "2628079",
    "end": "2633150"
  },
  {
    "text": "what results you get kind of look at how convolution operations happen and we can",
    "start": "2633150",
    "end": "2640470"
  },
  {
    "text": "visualize this as well kind of gets you an idea of you know hey my compositions",
    "start": "2640470",
    "end": "2648480"
  },
  {
    "text": "are too big and I'm not getting like my",
    "start": "2648480",
    "end": "2653970"
  },
  {
    "text": "networks not training so I can add more filters I can reduce the number of filters and so on so there's a lot of",
    "start": "2653970",
    "end": "2661079"
  },
  {
    "text": "experimentation that we'll need to do to arrive what I typically do is look at",
    "start": "2661079",
    "end": "2668690"
  },
  {
    "text": "you know kind of papers or other networks that people have built and try to replicate you know their hard work",
    "start": "2668690",
    "end": "2676289"
  },
  {
    "text": "and kind of go from there as a good starting point okay I I said where",
    "start": "2676289",
    "end": "2683759"
  },
  {
    "text": "you're pulling it from I I don't have the intuition yet to I think I would",
    "start": "2683759",
    "end": "2690299"
  },
  {
    "text": "just be copy and pasting from papers yeah from there that's a that's a good step that's a",
    "start": "2690299",
    "end": "2697180"
  },
  {
    "text": "good and this we're defining this convolution this activation and this",
    "start": "2697180",
    "end": "2703330"
  },
  {
    "text": "pooling has a single layer or is that actually a couple of layers so they can",
    "start": "2703330",
    "end": "2710890"
  },
  {
    "text": "be grouped together because you know we",
    "start": "2710890",
    "end": "2716760"
  },
  {
    "text": "the the convolution and the activation kind of fused into a single layer so you the convolution output goes to the",
    "start": "2716760",
    "end": "2723490"
  },
  {
    "text": "activation and then we say hey there's a pooling layer that that map's this down and what I do is I'll visualize the",
    "start": "2723490",
    "end": "2731590"
  },
  {
    "text": "network after we created so that we can walk through how the array sizes or you",
    "start": "2731590",
    "end": "2740260"
  },
  {
    "text": "know entierro sizes kind of change through the entire network so so we will",
    "start": "2740260",
    "end": "2749500"
  },
  {
    "text": "just do a two layer convolutional network remember like with the",
    "start": "2749500",
    "end": "2754660"
  },
  {
    "text": "multi-layer perceptron we have two fully connected layers which made us which made the multi-layer perceptron so we'll",
    "start": "2754660",
    "end": "2761230"
  },
  {
    "text": "we'll do a simple model again so I just copied the same things in bow so some of",
    "start": "2761230",
    "end": "2767170"
  },
  {
    "text": "the state-of-the-art networks revenue have like a thousand layers somewhere",
    "start": "2767170",
    "end": "2772900"
  },
  {
    "text": "between 100 and a thousand layers as well correct so so as you can see right",
    "start": "2772900",
    "end": "2780250"
  },
  {
    "text": "like there's no reason why we can just define like a convolution factory helper",
    "start": "2780250",
    "end": "2785650"
  },
  {
    "text": "function to do to generate both of this right so I'm just going to lay it down",
    "start": "2785650",
    "end": "2791320"
  },
  {
    "text": "because it's a simple Network yeah so I'm not going to add another function here but you can see that we can add a",
    "start": "2791320",
    "end": "2798100"
  },
  {
    "text": "helper function and essentially generate a bunch of these convolutional layers all at once Wow",
    "start": "2798100",
    "end": "2805950"
  },
  {
    "text": "it's a whole other level of abstraction yeah so what we'll do is we'll just add",
    "start": "2805950",
    "end": "2815230"
  },
  {
    "text": "50 filters or pass the convolution to activation function to and pull two",
    "start": "2815230",
    "end": "2824790"
  },
  {
    "text": "halation the data coming in is supposed to be the pool one right because we're",
    "start": "2826460",
    "end": "2832250"
  },
  {
    "text": "just passing things down correct yeah so this is how the connection this is other chain continues so what happens is let",
    "start": "2832250",
    "end": "2847490"
  },
  {
    "text": "me try and find a good sample that I had",
    "start": "2847490",
    "end": "2859510"
  },
  {
    "text": "let me find a good image okay this is a",
    "start": "2862570",
    "end": "2870290"
  },
  {
    "text": "good enough image so we have a question",
    "start": "2870290",
    "end": "2879349"
  },
  {
    "text": "okay from Herbert Kelly he says so will a two by two be four times less",
    "start": "2879349",
    "end": "2888080"
  },
  {
    "text": "processor-intensive than a poor my court colonel",
    "start": "2888080",
    "end": "2892780"
  },
  {
    "text": "and and my intuition there is actually that with two by two and four by four that's the difference between four",
    "start": "2893300",
    "end": "2899660"
  },
  {
    "text": "pixels and 16 pixels and to the processor that probably makes very little difference because the registers",
    "start": "2899660",
    "end": "2906320"
  },
  {
    "text": "that it's using and everything are built to hold you know a byte at a time or you",
    "start": "2906320",
    "end": "2914990"
  },
  {
    "text": "know however however many bytes at a time that they're supposed to hold so with smaller kernels I would imagine the",
    "start": "2914990",
    "end": "2921530"
  },
  {
    "text": "processor processing difference is fairly small but once you get into larger and larger ones then you do start",
    "start": "2921530",
    "end": "2928880"
  },
  {
    "text": "to see that linear increase in processing time is that correct I think that's a bet yeah I think that's a fair",
    "start": "2928880",
    "end": "2935030"
  },
  {
    "text": "intuition Randall I don't know what the exact sizes again again with the GPU",
    "start": "2935030",
    "end": "2940400"
  },
  {
    "text": "right things are done family it these days the GPUs tend to have larger you",
    "start": "2940400",
    "end": "2947990"
  },
  {
    "text": "know course so I would I don't know where the breakpoint is in terms of you",
    "start": "2947990",
    "end": "2955520"
  },
  {
    "text": "know kernel sizes but like you know once you get to a certain point the the amount of processing work",
    "start": "2955520",
    "end": "2960710"
  },
  {
    "text": "required does increase linearly with this yeah okay yeah I'd say so because again",
    "start": "2960710",
    "end": "2966440"
  },
  {
    "text": "you're its matrix multiplication gotcha",
    "start": "2966440",
    "end": "2971980"
  },
  {
    "text": "okay so here here's an example of how things look end to end in a network",
    "start": "2972190",
    "end": "2979119"
  },
  {
    "text": "right so let's say we have a car or as",
    "start": "2979119",
    "end": "2984890"
  },
  {
    "text": "we saw you know certain filters so these are you know kind of let us say these",
    "start": "2984890",
    "end": "2992390"
  },
  {
    "text": "are filter visualizations in layer one and initially what you'll have is the",
    "start": "2992390",
    "end": "2998960"
  },
  {
    "text": "filters will learn edge orientations as we saw in those videos right so this",
    "start": "2998960",
    "end": "3004840"
  },
  {
    "text": "filter tends to like you know the edge in this direction this filter in this",
    "start": "3004840",
    "end": "3011619"
  },
  {
    "text": "other direction and so on and certain filters will get affinity to texture or",
    "start": "3011619",
    "end": "3018960"
  },
  {
    "text": "you know other other things as you can see this is not a this is not an edge filter correct this is like yeah I mean",
    "start": "3018960",
    "end": "3031210"
  },
  {
    "text": "I can't really I can't really make out what the probably is maybe I don't know",
    "start": "3031210",
    "end": "3036599"
  },
  {
    "text": "some kind of texture color but what",
    "start": "3036599",
    "end": "3041710"
  },
  {
    "text": "happens is as we go further the next layer builds on what the",
    "start": "3041710",
    "end": "3047740"
  },
  {
    "text": "previous layer has learned or has detected so the learning is hierarchical",
    "start": "3047740",
    "end": "3054190"
  },
  {
    "text": "right things are built on top of what things have been seen or learnt in the",
    "start": "3054190",
    "end": "3060040"
  },
  {
    "text": "previous layers you you see where that's going I do",
    "start": "3060040",
    "end": "3066329"
  },
  {
    "text": "out of curiosity though the the third",
    "start": "3066930",
    "end": "3072490"
  },
  {
    "text": "picture here so it's got the Audi it's got the edges and you know whatever other kind of feature sets it's supposed",
    "start": "3072490",
    "end": "3078790"
  },
  {
    "text": "to be checking for this third layer are those features that it has derived",
    "start": "3078790",
    "end": "3086710"
  },
  {
    "text": "correct it's built on the previous layer now what well it is done is constructed as you can see it seems like there are",
    "start": "3086710",
    "end": "3093970"
  },
  {
    "text": "different cars and it's kind of identified what an average car looks",
    "start": "3093970",
    "end": "3099880"
  },
  {
    "text": "like and you can see it's from different angles and orientations that it's",
    "start": "3099880",
    "end": "3105310"
  },
  {
    "text": "actually detected the cars okay right so",
    "start": "3105310",
    "end": "3111250"
  },
  {
    "text": "so that's kind of what we're trying to replicate here and what happens usually is you know you can see here there are a",
    "start": "3111250",
    "end": "3120700"
  },
  {
    "text": "bunch of convolutions and the size reduces as we go further and that's probably representing pooling and but",
    "start": "3120700",
    "end": "3129430"
  },
  {
    "text": "what's the end what we need to do is oh we're in a very high dimensional space",
    "start": "3129430",
    "end": "3135700"
  },
  {
    "text": "so what we do is we add a fully connected layer to kind of basically",
    "start": "3135700",
    "end": "3142210"
  },
  {
    "text": "gather all this information from all these neurons in the previous layer and",
    "start": "3142210",
    "end": "3147280"
  },
  {
    "text": "kind of map them to a lower dimension right so we are mapping things and",
    "start": "3147280",
    "end": "3154030"
  },
  {
    "text": "squishing them you know together and do we do multiple yeah people do that so it",
    "start": "3154030",
    "end": "3164410"
  },
  {
    "text": "depends typically on how large the feature set we are operating or",
    "start": "3164410",
    "end": "3169570"
  },
  {
    "text": "dimension we are operating in so let's say you know we had a layer with you",
    "start": "3169570",
    "end": "3176830"
  },
  {
    "text": "know ten thousand you know feature map right like we've learned like ten thousand feature map and if we kind of",
    "start": "3176830",
    "end": "3183250"
  },
  {
    "text": "map that down to let's say ten nodes fully connected you know fully connect",
    "start": "3183250",
    "end": "3188320"
  },
  {
    "text": "layer with ten nodes well we're going from a much larger like you know space",
    "start": "3188320",
    "end": "3194980"
  },
  {
    "text": "to a smaller space we might lose the risk yeah so usually what people do is",
    "start": "3194980",
    "end": "3200410"
  },
  {
    "text": "kind of break it down say go from 10,000 to say 500 - then you know say 10 so",
    "start": "3200410",
    "end": "3207400"
  },
  {
    "text": "that that's usually done where you have multiple funny connected layers rather",
    "start": "3207400",
    "end": "3212620"
  },
  {
    "text": "than going from really large space to a smaller space you you kind of like slow it down gotcha",
    "start": "3212620",
    "end": "3220200"
  },
  {
    "start": "3220000",
    "end": "3599000"
  },
  {
    "text": "so we'll so we'll do the same so we can",
    "start": "3220869",
    "end": "3226009"
  },
  {
    "text": "do is let our flattening layer just called flatten right so because we're",
    "start": "3226009",
    "end": "3235039"
  },
  {
    "text": "just squishing everything into a 1d array it's easier to operate go to and",
    "start": "3235039",
    "end": "3244359"
  },
  {
    "text": "then we'll call our layer FC one we can",
    "start": "3244359",
    "end": "3250579"
  },
  {
    "text": "just call fully connected there are other networks that kind of if people",
    "start": "3250579",
    "end": "3256909"
  },
  {
    "text": "have worked with other networks it's called a dense layer dense because you know it's fully connected so those terms",
    "start": "3256909",
    "end": "3263569"
  },
  {
    "text": "are interchangeable okay yeah so you",
    "start": "3263569",
    "end": "3273559"
  },
  {
    "text": "know so if you're gonna like see here right so you go from this fully",
    "start": "3273559",
    "end": "3281509"
  },
  {
    "text": "connected layer you can see it goes from six five nodes to three ways the thing",
    "start": "3281509",
    "end": "3286609"
  },
  {
    "text": "they're only classifying three outputs in our case we'll go we'll reduce it to",
    "start": "3286609",
    "end": "3293900"
  },
  {
    "text": "like 500 to start with okay and then",
    "start": "3293900",
    "end": "3299650"
  },
  {
    "text": "remember we need our we need our",
    "start": "3299650",
    "end": "3308689"
  },
  {
    "text": "nonlinearities and then we'll send it through our second fully connected layer",
    "start": "3308689",
    "end": "3314929"
  },
  {
    "text": "here and this time we'll use 10 can you",
    "start": "3314929",
    "end": "3323569"
  },
  {
    "text": "guess why correct",
    "start": "3323569",
    "end": "3330140"
  },
  {
    "text": "this is gonna be our last fully connected layer before before the",
    "start": "3330140",
    "end": "3335390"
  },
  {
    "text": "network so so when that",
    "start": "3335390",
    "end": "3341528"
  },
  {
    "text": "so max so we'll add a layer called as",
    "start": "3343660",
    "end": "3349820"
  },
  {
    "text": "the softmax output layer which is a really common really common when we use",
    "start": "3349820",
    "end": "3359450"
  },
  {
    "text": "[Music] categoric essentially categoric",
    "start": "3359450",
    "end": "3365770"
  },
  {
    "text": "classification tasks so what what softmax does is at the last layer it",
    "start": "3365770",
    "end": "3372260"
  },
  {
    "text": "converts say our predictions into probabilities so it's it's really it's",
    "start": "3372260",
    "end": "3380030"
  },
  {
    "text": "really nice to kind of rather than having binary values having values where",
    "start": "3380030",
    "end": "3389560"
  },
  {
    "text": "you know hey we predicted it was likely to be you know 5% likely that it's",
    "start": "3389560",
    "end": "3397550"
  },
  {
    "text": "category 0 10% there was you know 50 and so on it helps the network learn better",
    "start": "3397550",
    "end": "3404600"
  },
  {
    "text": "so it's it's easier to rather than",
    "start": "3404600",
    "end": "3410210"
  },
  {
    "text": "having if you have if we had like step functions right like something that is binary we wouldn't be able to",
    "start": "3410210",
    "end": "3415520"
  },
  {
    "text": "differentiate through that so because we",
    "start": "3415520",
    "end": "3420650"
  },
  {
    "text": "have you know because we're adding these you know in case of softmax it's",
    "start": "3420650",
    "end": "3426800"
  },
  {
    "text": "negative likelihood it's easier for us to compute or we can actually compute",
    "start": "3426800",
    "end": "3433190"
  },
  {
    "text": "gradients and the network can learn better so that last fully connected",
    "start": "3433190",
    "end": "3445340"
  },
  {
    "text": "layer coming in so what happens is w",
    "start": "3445340",
    "end": "3451340"
  },
  {
    "text": "right correct so so what it does is we",
    "start": "3451340",
    "end": "3456950"
  },
  {
    "text": "we basically end up calculating the so",
    "start": "3456950",
    "end": "3463850"
  },
  {
    "text": "essentially we will have outputs here and the outputs will be in the softmax",
    "start": "3463850",
    "end": "3469040"
  },
  {
    "text": "layer actually probably so let's say it's going to be something like 0.1 0.8",
    "start": "3469040",
    "end": "3477260"
  },
  {
    "text": "and point one again right so that becomes our output now what what we'll",
    "start": "3477260",
    "end": "3483350"
  },
  {
    "text": "do is depend on our loss function so in this case the most common one is called",
    "start": "3483350",
    "end": "3491330"
  },
  {
    "text": "a cross entropy function and what what",
    "start": "3491330",
    "end": "3498140"
  },
  {
    "text": "will do is will that that loss function tells us how off we are from the actual",
    "start": "3498140",
    "end": "3507190"
  },
  {
    "text": "predicted or the labels to be predicted so so in this case let's say we were",
    "start": "3507190",
    "end": "3513770"
  },
  {
    "text": "predicting you know it to be an RD which",
    "start": "3513770",
    "end": "3518780"
  },
  {
    "text": "is let's say category you know - or category one here that's Chi is 0 1 2",
    "start": "3518780",
    "end": "3527290"
  },
  {
    "text": "what we do is we calculate the loss function will actually tell us how you",
    "start": "3527290",
    "end": "3533840"
  },
  {
    "text": "know how different we are or how off we are from the actual printed output and then we'll calculate the gradient now",
    "start": "3533840",
    "end": "3541790"
  },
  {
    "text": "this process is called the gradient right so we are calculating the gradients with respect to the loss",
    "start": "3541790",
    "end": "3547610"
  },
  {
    "text": "function will calculate it here and then we will will actually you know do the",
    "start": "3547610",
    "end": "3554120"
  },
  {
    "text": "correction and then we'll do to the next layer so the previous layer of the previous layer and so on that whole",
    "start": "3554120",
    "end": "3560570"
  },
  {
    "text": "process is back propagation so we're we're only following a single path back",
    "start": "3560570",
    "end": "3566570"
  },
  {
    "text": "or each so it's done per layer yeah it's",
    "start": "3566570",
    "end": "3571910"
  },
  {
    "text": "done per layer so the fully connected layers probably take much longer in complication",
    "start": "3571910",
    "end": "3579280"
  },
  {
    "text": "well it just depends on the number of parameters and that layer I as in this",
    "start": "3581720",
    "end": "3588620"
  },
  {
    "text": "case actually correct yes in this case the conveyor - is the one that's going",
    "start": "3588620",
    "end": "3596930"
  },
  {
    "text": "to take the most time actually there is a way to realize how long I think steak",
    "start": "3596930",
    "end": "3604730"
  },
  {
    "text": "as well I had written um it's it's actually a blog that I had wrote",
    "start": "3604730",
    "end": "3610280"
  },
  {
    "text": "written where UK which shows you there's a name accident profiler where you can actually view the yeah let's let's see",
    "start": "3610280",
    "end": "3621550"
  },
  {
    "text": "there you go I'll show you guys so there's profiler",
    "start": "3621550",
    "end": "3626780"
  },
  {
    "text": "support so we can just set the profiler run the code and you know you can just",
    "start": "3626780",
    "end": "3633860"
  },
  {
    "text": "do you know let's say in your favorite browser you can you know kind of see the slices between you know how long your",
    "start": "3633860",
    "end": "3642740"
  },
  {
    "text": "network operation your DNS you know waiting all that you know wanders",
    "start": "3642740",
    "end": "3648670"
  },
  {
    "text": "similarly you can generate a JSON file and load it in in this case of use from",
    "start": "3648670",
    "end": "3653680"
  },
  {
    "text": "to see where you know it spends most of its time that's pretty cool okay sorry",
    "start": "3653680",
    "end": "3672500"
  },
  {
    "text": "it's very nice yeah as long as it's helpful to the audience I'm happy to",
    "start": "3672500",
    "end": "3678940"
  },
  {
    "text": "answer okay so so I'm gonna use the",
    "start": "3678940",
    "end": "3688400"
  },
  {
    "text": "visualizer so and I start with plot sorry where's dot plot network and so",
    "start": "3688400",
    "end": "3701510"
  },
  {
    "text": "we'll just give it the shape so shape it's just a dummy variable for us to or",
    "start": "3701510",
    "end": "3708650"
  },
  {
    "text": "a place or a variable for it to actually see or compute the how it's gonna look",
    "start": "3708650",
    "end": "3716810"
  },
  {
    "text": "like when we send the data in through the network so so we did a one into 28",
    "start": "3716810",
    "end": "3728210"
  },
  {
    "text": "and 28 right that was our matrix we ran through a 5x5 kernel and 20 filters what",
    "start": "3728210",
    "end": "3736550"
  },
  {
    "text": "happens is we now because see we get the we get the matrices",
    "start": "3736550",
    "end": "3743810"
  },
  {
    "text": "you know say 28 by 28 into 5x5 kernels gets us 24 into 24 right you see the",
    "start": "3743810",
    "end": "3750890"
  },
  {
    "text": "size actually reduces because you know it doesn't quite fit exactly right like",
    "start": "3750890",
    "end": "3756650"
  },
  {
    "text": "we will be the odd number kana so we actually reduce the the original image",
    "start": "3756650",
    "end": "3762500"
  },
  {
    "text": "size into a smaller one do you see this it's actually 20 by 20 424 do you know",
    "start": "3762500",
    "end": "3770840"
  },
  {
    "text": "why I am 20 yeah because we use 20",
    "start": "3770840",
    "end": "3776450"
  },
  {
    "text": "filters so we get basically we get 20 different 24 by 24 matrices each for",
    "start": "3776450",
    "end": "3783470"
  },
  {
    "text": "each filter remember you're asking can we do this Baddeley right yep we can so",
    "start": "3783470",
    "end": "3792770"
  },
  {
    "text": "we send it to the activation function which is applied to the entire matrix we save the pooling layer and the pooling",
    "start": "3792770",
    "end": "3799640"
  },
  {
    "text": "layer reduces as you can see to it were 23 by 23 matrix we send it to a 55 by",
    "start": "3799640",
    "end": "3808760"
  },
  {
    "text": "550 convolution it further reduces but now we have 50 different matrices right",
    "start": "3808760",
    "end": "3816370"
  },
  {
    "text": "make sense and then you know we",
    "start": "3817060",
    "end": "3824090"
  },
  {
    "text": "flattened we flattened the array the matrix we get this we send it to the",
    "start": "3824090",
    "end": "3831740"
  },
  {
    "text": "next fully connected layer so we basically get 500 get 500 you know",
    "start": "3831740",
    "end": "3839390"
  },
  {
    "text": "features will further reduce that and I lost fully connected layer is 10 because",
    "start": "3839390",
    "end": "3846110"
  },
  {
    "text": "we have 10 categories okay okay so let's",
    "start": "3846110",
    "end": "3855140"
  },
  {
    "text": "now here I mean the model is gonna",
    "start": "3855140",
    "end": "3864830"
  },
  {
    "text": "output numbers are 0 1 and so on it's just the index of this so we'll use",
    "start": "3864830",
    "end": "3871010"
  },
  {
    "text": "this lookup table once we",
    "start": "3871010",
    "end": "3874390"
  },
  {
    "text": "simple vlogging winner gets auger I",
    "start": "3877549",
    "end": "3883069"
  },
  {
    "text": "think set level right I think it's",
    "start": "3883069",
    "end": "3895829"
  },
  {
    "text": "capital right okay",
    "start": "3895829",
    "end": "3903019"
  },
  {
    "text": "context to go to right yep let's say",
    "start": "3903019",
    "end": "3914880"
  },
  {
    "text": "number of epoch equal to just do one epoch just to kind of test so is a good",
    "start": "3914880",
    "end": "3921990"
  },
  {
    "text": "practice to kind of send the network through one epoch see what's happening just kind of like get a feel for the",
    "start": "3921990",
    "end": "3929519"
  },
  {
    "text": "network before you actually run it with everything okay this is a best practice",
    "start": "3929519",
    "end": "3938180"
  },
  {
    "text": "what we're gonna do is specify the symbol in this case its Lynette and",
    "start": "3946039",
    "end": "3952069"
  },
  {
    "text": "we're gonna we're gonna say context equal to Z DX now we need to bind find",
    "start": "3952069",
    "end": "3964650"
  },
  {
    "text": "the network and we need to give it the basically it takes the data shapes and",
    "start": "3964650",
    "end": "3972289"
  },
  {
    "text": "the label shapes so what I'm gonna do is",
    "start": "3972289",
    "end": "3979369"
  },
  {
    "text": "basically the Train I traitor has these",
    "start": "3979369",
    "end": "3985440"
  },
  {
    "text": "shapes already so it already has it in built because we built the train i",
    "start": "3985440",
    "end": "3992130"
  },
  {
    "text": "traitor so rather than hot coding and i'll just extracted from there so we can",
    "start": "3992130",
    "end": "3997319"
  },
  {
    "text": "just say provide provide label of 0",
    "start": "3997319",
    "end": "4005200"
  },
  {
    "text": "provide data zero so I can just I can",
    "start": "4011720",
    "end": "4017700"
  },
  {
    "text": "just do the shape actually it takes a",
    "start": "4017700",
    "end": "4023150"
  },
  {
    "text": "because we can have multiple inputs and multiple outputs the data shapes and",
    "start": "4024920",
    "end": "4030930"
  },
  {
    "text": "label shapes actually take and take a list rather than a single object does",
    "start": "4030930",
    "end": "4037380"
  },
  {
    "text": "that make sense okay",
    "start": "4037380",
    "end": "4040099"
  },
  {
    "text": "the next is actually calling the fit function so all the fit function it",
    "start": "4043080",
    "end": "4048540"
  },
  {
    "text": "takes the train I traitor that takes the validation iterator and my room lights",
    "start": "4048540",
    "end": "4059070"
  },
  {
    "text": "just and now it's back up be stationary",
    "start": "4059070",
    "end": "4070710"
  },
  {
    "text": "so optimizer right so remember will use the basic optimizers stochastic gradient",
    "start": "4070710",
    "end": "4077520"
  },
  {
    "text": "descent we used Adam before we can try we can try Adam which is the more",
    "start": "4077520",
    "end": "4084150"
  },
  {
    "text": "advanced one we'll try that later we just use one type of parameter here this",
    "start": "4084150",
    "end": "4092760"
  },
  {
    "text": "is the number of steps in the direction we go we'll choose a faster learning rate yeah optimizer param I believe",
    "start": "4092760",
    "end": "4104430"
  },
  {
    "text": "we'll see what else am I missing fit and",
    "start": "4104430",
    "end": "4110160"
  },
  {
    "text": "that's it Oh actually let's let me specify so",
    "start": "4110160",
    "end": "4116670"
  },
  {
    "text": "evaluation metric equal to accuracy",
    "start": "4116670",
    "end": "4121670"
  },
  {
    "text": "accuracy because we're just doing categorical so if it's just going to be a direct comparison so we our final",
    "start": "4122120",
    "end": "4129390"
  },
  {
    "text": "label output will be like hey it's five and we'll have something like saying hey",
    "start": "4129390",
    "end": "4137819"
  },
  {
    "text": "the true prediction was or so in that case the accuracy metric",
    "start": "4137820",
    "end": "4143068"
  },
  {
    "text": "will say a zero it's just a binary metric it just tells us how many things we got correct that and so I'm just",
    "start": "4143069",
    "end": "4151349"
  },
  {
    "text": "using I'll use this callback function so that I think we've used this before just",
    "start": "4151349",
    "end": "4157528"
  },
  {
    "text": "to kind of see how we're doing so",
    "start": "4157529",
    "end": "4165000"
  },
  {
    "text": "speedometer yeah so we can just see this",
    "start": "4165000",
    "end": "4172818"
  },
  {
    "text": "speedometer and say the bath size every 200 matches do this and we shouldn't",
    "start": "4172819",
    "end": "4185099"
  },
  {
    "text": "forget the number of epochs equal to num each block okay let's see okay",
    "start": "4185099",
    "end": "4196590"
  },
  {
    "text": "fit function maybe I think it's epoch okay there you go",
    "start": "4196590",
    "end": "4204659"
  },
  {
    "text": "oh look at that quick we're in batches right look at that jump that means that",
    "start": "4204659",
    "end": "4211530"
  },
  {
    "text": "things are going well yeah yeah 77",
    "start": "4211530",
    "end": "4219599"
  },
  {
    "text": "percent accuracy that's not that's not bad at all so 10 is that gonna be too many or no that's no we'll see what",
    "start": "4219599",
    "end": "4227940"
  },
  {
    "text": "happens that right and so while the",
    "start": "4227940",
    "end": "4235590"
  },
  {
    "text": "network is you know training what I'm gonna do is I'm gonna get the prediction",
    "start": "4235590",
    "end": "4241679"
  },
  {
    "text": "function ready right so let's say",
    "start": "4241679",
    "end": "4247790"
  },
  {
    "text": "actually we can get the predictions of the entire validation set by just doing something like net dot predict well I",
    "start": "4247790",
    "end": "4255469"
  },
  {
    "text": "mean just give and it's gonna predict for the entire validation set actually",
    "start": "4255469",
    "end": "4263580"
  },
  {
    "text": "I'll show you something look at look at how slow that is right",
    "start": "4263580",
    "end": "4270079"
  },
  {
    "text": "let's Acme I'm gonna try and use all my",
    "start": "4270079",
    "end": "4277369"
  },
  {
    "text": "GPUs this is how easy it is to do",
    "start": "4277369",
    "end": "4283579"
  },
  {
    "text": "multi-gpu training give 8g fingers yes like g3 excellent it's a it's a now it's",
    "start": "4283579",
    "end": "4293360"
  },
  {
    "text": "up B to Axl PT ratings oh geez",
    "start": "4293360",
    "end": "4299440"
  },
  {
    "text": "hopefully I have nothing else running",
    "start": "4299440",
    "end": "4303579"
  },
  {
    "text": "okay so I'm gonna do is actually let's",
    "start": "4308469",
    "end": "4315909"
  },
  {
    "text": "let's pick pick index say 30 it's",
    "start": "4315909",
    "end": "4321590"
  },
  {
    "text": "actually going slower than it was on yeah but I think it'll go faster when it",
    "start": "4321590",
    "end": "4326719"
  },
  {
    "text": "gets to the bigger layers actually uptime that yeah we need that's a good",
    "start": "4326719",
    "end": "4332329"
  },
  {
    "text": "that's a good point I actually forget how big the data set is so using",
    "start": "4332329",
    "end": "4338510"
  },
  {
    "text": "multiple GPUs necessary doesn't mean things are gonna train fast so the",
    "start": "4338510",
    "end": "4344540"
  },
  {
    "text": "reason being remember like all the gradients so so what happens is every",
    "start": "4344540",
    "end": "4351460"
  },
  {
    "text": "GPU gets you know what my bad size was not up I just used the same bad size so",
    "start": "4351460",
    "end": "4357770"
  },
  {
    "text": "it actually you need to use a larger batch because all the batches are being",
    "start": "4357770",
    "end": "4363920"
  },
  {
    "text": "distributed across the GPUs correctly and and the gradients need to be kind of",
    "start": "4363920",
    "end": "4370429"
  },
  {
    "text": "need to be synced or calculated on you know per per layer so what we are seeing",
    "start": "4370429",
    "end": "4379040"
  },
  {
    "text": "is probably network synchronization issues like it's also paying the cost of",
    "start": "4379040",
    "end": "4386750"
  },
  {
    "text": "shipping all that data from you know wherever it's pulling it from RAM in this case over to the GPU yeah",
    "start": "4386750",
    "end": "4396489"
  },
  {
    "text": "correct correct so so when you have larger datasets you're likely to",
    "start": "4397000",
    "end": "4403469"
  },
  {
    "text": "things you know faster with multiple GPUs but if you're a smaller data set",
    "start": "4403469",
    "end": "4408989"
  },
  {
    "text": "you know probably sticking to a single GPU is it's probably better I mean this",
    "start": "4408989",
    "end": "4415139"
  },
  {
    "text": "is we were doing seven thousand samples a second on the single GPU so we're still right so let me just I think",
    "start": "4415139",
    "end": "4425400"
  },
  {
    "text": "there's a good exercise so I'll yeah let's do that directly re-execute the",
    "start": "4425400",
    "end": "4440699"
  },
  {
    "text": "other layers - yes now it's the same network right that's the same network",
    "start": "4440699",
    "end": "4446150"
  },
  {
    "text": "this was faster remember the last time it took 16 seconds yeah it now took only",
    "start": "4446150",
    "end": "4452070"
  },
  {
    "text": "10 seconds so there you go right so",
    "start": "4452070",
    "end": "4457800"
  },
  {
    "text": "remember like this is a good lesson right like you can't just arbitrarily go much GPU your bad size needs to kind of",
    "start": "4457800",
    "end": "4464610"
  },
  {
    "text": "reflect because you know you you want enough computation you don't want to",
    "start": "4464610",
    "end": "4470460"
  },
  {
    "text": "break it into really small tasks where network becomes the bottleneck right so",
    "start": "4470460",
    "end": "4479039"
  },
  {
    "text": "that's better okay I am sure so what I can do is right so",
    "start": "4479039",
    "end": "4494309"
  },
  {
    "text": "what we will do is create our so just display the gray",
    "start": "4494309",
    "end": "4500909"
  },
  {
    "text": "so we'll just display the image that we want to predict on similarly you know I",
    "start": "4500909",
    "end": "4507179"
  },
  {
    "text": "love that show actually X's done off the",
    "start": "4507179",
    "end": "4512219"
  },
  {
    "text": "axis okay all the predictions now what",
    "start": "4512219",
    "end": "4521940"
  },
  {
    "text": "we can do is the probability is threads",
    "start": "4521940",
    "end": "4527249"
  },
  {
    "text": "of I DX as numpy",
    "start": "4527249",
    "end": "4533869"
  },
  {
    "text": "and",
    "start": "4534989",
    "end": "4537989"
  },
  {
    "text": "87% accuracy which is not bad you know we should probably train it for more",
    "start": "4557180",
    "end": "4564180"
  },
  {
    "text": "epochs and see what happens so if we're",
    "start": "4564180",
    "end": "4570990"
  },
  {
    "text": "addicted if you get to like 87% and then",
    "start": "4570990",
    "end": "4576000"
  },
  {
    "text": "it's only going up maybe 1% per Deepak after that is there anything that you",
    "start": "4576000",
    "end": "4581190"
  },
  {
    "text": "can do you know what does your intuition tell you about trying to make it improve",
    "start": "4581190",
    "end": "4586980"
  },
  {
    "text": "more or is it just yeah good yeah that's a good question so you kind of get",
    "start": "4586980",
    "end": "4594350"
  },
  {
    "text": "diminishing returns or rather think I",
    "start": "4594350",
    "end": "4600800"
  },
  {
    "text": "think I have a graph I think I did it here let's see so your lost function",
    "start": "4600800",
    "end": "4608670"
  },
  {
    "text": "kind of goes here on a per econ EPOC basis right so look at that graph",
    "start": "4608670",
    "end": "4613760"
  },
  {
    "text": "initially you get like large returns or the loss function really goes down and then it kind of like slows down so which",
    "start": "4613760",
    "end": "4621810"
  },
  {
    "text": "is a pretty common this is a good like a good shape for how you have your network",
    "start": "4621810",
    "end": "4627720"
  },
  {
    "text": "kind of should look like so more epochs you kind of get to an accuracy that you can deter mind and",
    "start": "4627720",
    "end": "4634350"
  },
  {
    "text": "people do a lot of tricks to get that last you know a couple of percent they",
    "start": "4634350",
    "end": "4639780"
  },
  {
    "text": "will do a lot of crazy things what some of the most common ones are you know you",
    "start": "4639780",
    "end": "4645600"
  },
  {
    "text": "kind of like lower your learning rate you start playing with different bat sizes and you know you do those kind of",
    "start": "4645600",
    "end": "4654990"
  },
  {
    "text": "tricks to you know get get to that last level of you know greater accuracy okay",
    "start": "4654990",
    "end": "4668060"
  },
  {
    "text": "so we can do product our max and then",
    "start": "4670039",
    "end": "4678320"
  },
  {
    "text": "let's see what happens that is purse I forget it",
    "start": "4681139",
    "end": "4689328"
  },
  {
    "text": "yeah let's see what is wrong prob it's alright I think it's gonna be a RG max",
    "start": "4689480",
    "end": "4696599"
  },
  {
    "text": "right instead of a gr oh yeah yeah Scott",
    "start": "4696599",
    "end": "4701849"
  },
  {
    "text": "even are blanks so predicted is eight huh remember what eight was I do not",
    "start": "4701849",
    "end": "4709469"
  },
  {
    "text": "X actually one second yeah predicted",
    "start": "4709469",
    "end": "4726559"
  },
  {
    "text": "alright that's about 99% but its category eight alright cool",
    "start": "4742940",
    "end": "4753199"
  },
  {
    "text": "let's you know let's not rely on a single data point that's it yeah that's",
    "start": "4753199",
    "end": "4765690"
  },
  {
    "text": "a pullover right like it's got the sleeves gotcha",
    "start": "4765690",
    "end": "4771230"
  },
  {
    "text": "yeah the images are too small so it's a little hard for us to let's take",
    "start": "4771739",
    "end": "4777599"
  },
  {
    "text": "something that is obvious now that's that's ankles shoes right ankle ankle",
    "start": "4777599",
    "end": "4786150"
  },
  {
    "text": "hey go",
    "start": "4786150",
    "end": "4789110"
  },
  {
    "text": "I believe that that's a shirt no our sweater oh yes sorry I was looking at",
    "start": "4791250",
    "end": "4802500"
  },
  {
    "text": "seven yeah yeah now we indexed from 0 yeah okay so there",
    "start": "4802500",
    "end": "4811770"
  },
  {
    "text": "you go that was our first convolutional neural network it's there I so I know",
    "start": "4811770",
    "end": "4818550"
  },
  {
    "text": "that you talked about optimizers is there a way of for instance this has a",
    "start": "4818550",
    "end": "4824460"
  },
  {
    "text": "probability of 55% it's there an",
    "start": "4824460",
    "end": "4829710"
  },
  {
    "text": "optimizer or a method that we can use to go and find the ones that have roller probability and increase yeah so that's",
    "start": "4829710",
    "end": "4842070"
  },
  {
    "text": "good right like so our network really we saw just 87% with Jenny box right so I'm",
    "start": "4842070",
    "end": "4848550"
  },
  {
    "text": "going to use a different activation function okay okay and I might just",
    "start": "4848550",
    "end": "4854300"
  },
  {
    "text": "increase the number of filters a little bit I don't know so function we're using",
    "start": "4854300",
    "end": "4862440"
  },
  {
    "text": "now is really yeah really yeah which is a more modern one and pretty much every",
    "start": "4862440",
    "end": "4867660"
  },
  {
    "text": "network just to start with Lulu okay okay okay",
    "start": "4867660",
    "end": "4873390"
  },
  {
    "text": "let's let's see what happens I don't know this is just intuition I have my fingers crossed to see what the network",
    "start": "4873390",
    "end": "4880590"
  },
  {
    "text": "does so",
    "start": "4880590",
    "end": "4884360"
  },
  {
    "text": "pretty go came to 67% after 25 it's a little slower right we added more layers",
    "start": "4889020",
    "end": "4895230"
  },
  {
    "text": "as you can see we added more nodes right it was taking us like 10 seconds now",
    "start": "4895230",
    "end": "4900930"
  },
  {
    "text": "it's like 13 I'm eagerly awaiting each",
    "start": "4900930",
    "end": "4906870"
  },
  {
    "text": "one of these well I mean we're already",
    "start": "4906870",
    "end": "4912210"
  },
  {
    "text": "pretty much we're 7% off from where we were last time yeah and that's only",
    "start": "4912210",
    "end": "4919680"
  },
  {
    "text": "after to ease off so there you go 84 sofa we will do better",
    "start": "4919680",
    "end": "4929570"
  },
  {
    "text": "so yeah the intuition is again you know again we used a std which is again a",
    "start": "4929570",
    "end": "4935280"
  },
  {
    "text": "little slower in terms of the optimizer so we can we could have tried Adam we",
    "start": "4935280",
    "end": "4941460"
  },
  {
    "text": "could have tried different so the whole concept of like hyper parameter optimization itself is a big area and",
    "start": "4941460",
    "end": "4948560"
  },
  {
    "text": "you know we you can play with the bad sides you can play with learning rate you can play with the optimizer all",
    "start": "4948560",
    "end": "4955830"
  },
  {
    "text": "these things and try and find a really",
    "start": "4955830",
    "end": "4960890"
  },
  {
    "text": "you know a better network or a better parameters for a given network that's I",
    "start": "4960890",
    "end": "4969380"
  },
  {
    "text": "think we're getting close to everywhere I mean we're about to hit 90 percent",
    "start": "4969380",
    "end": "4977450"
  },
  {
    "text": "yeah so I mean 88 percent was what we got two last time right so it's perfect",
    "start": "4977450",
    "end": "4984360"
  },
  {
    "text": "yeah so you're saved like three box invalidation accuracy is the one to look",
    "start": "4984360",
    "end": "4991800"
  },
  {
    "text": "for right because we don't want the model overfitting it's the moment like validation accuracy",
    "start": "4991800",
    "end": "4996810"
  },
  {
    "text": "starts dropping we know that the network is really learned well well we've got",
    "start": "4996810",
    "end": "5004610"
  },
  {
    "text": "we've made an improvement of one percent there you go and you know this is again",
    "start": "5004610",
    "end": "5015410"
  },
  {
    "text": "like you know we can add a third layer you know deeper we go the better we",
    "start": "5015410",
    "end": "5023510"
  },
  {
    "text": "probably could do so I'm gonna try and do that last experimentation and I'm",
    "start": "5023510",
    "end": "5029960"
  },
  {
    "text": "gonna kick that off and so I'm gonna do",
    "start": "5029960",
    "end": "5039060"
  },
  {
    "text": "[Music] okay okay",
    "start": "5039060",
    "end": "5048110"
  },
  {
    "text": "while our network is running yeah so while the network is running let's go -",
    "start": "5048110",
    "end": "5054219"
  },
  {
    "text": "lets go attempt it the fine tuning ok",
    "start": "5054219",
    "end": "5060830"
  },
  {
    "text": "I'll show you guys the filter viewing a little later but yeah so what do we do what do we do",
    "start": "5060830",
    "end": "5069170"
  },
  {
    "text": "when we don't have enough data right so that that's a good question so there's",
    "start": "5069170",
    "end": "5074540"
  },
  {
    "text": "this concept called as transfer learning or fine tuning what that means is we can use networks that are being trained on",
    "start": "5074540",
    "end": "5081380"
  },
  {
    "text": "another data set and leverage the same model to do other things now we can take",
    "start": "5081380",
    "end": "5089120"
  },
  {
    "text": "some of the layers and layers from those correct because remember hierarchical",
    "start": "5089120",
    "end": "5095660"
  },
  {
    "text": "learning right I told you that we we learn features like edges and edge",
    "start": "5095660",
    "end": "5101870"
  },
  {
    "text": "orientations initially and then things get built up on top of that and it's the final layer where the outputs get mapped",
    "start": "5101870",
    "end": "5108650"
  },
  {
    "text": "to the layer labels and that's how the network learns so so what we'll do is",
    "start": "5108650",
    "end": "5117460"
  },
  {
    "text": "there you go yeah so what we're doing is",
    "start": "5117520",
    "end": "5123310"
  },
  {
    "text": "you will take a model so imagenet is a competition where the data set has about",
    "start": "5123310",
    "end": "5129230"
  },
  {
    "text": "1.2 million images it's the most popular benchmarking data set out there for deep",
    "start": "5129230",
    "end": "5136489"
  },
  {
    "text": "learning networks and it's pretty comprehensive and it's got labeled",
    "start": "5136489",
    "end": "5143020"
  },
  {
    "text": "thousand categories it's identified a lot of you know it's got like cats dogs",
    "start": "5143020",
    "end": "5150710"
  },
  {
    "text": "cars plenty of different labels what what the intention here is the network has",
    "start": "5150710",
    "end": "5157160"
  },
  {
    "text": "learned all these nice features and we can apply to other image models as well",
    "start": "5157160",
    "end": "5163100"
  },
  {
    "text": "so so because the way we'll identify a",
    "start": "5163100",
    "end": "5168230"
  },
  {
    "text": "face is quite a similar right we'll we'll get edges and edge orientations the intuition is can we try and use what",
    "start": "5168230",
    "end": "5175940"
  },
  {
    "text": "the network is learned to detect images that are random or run or not right so",
    "start": "5175940",
    "end": "5183560"
  },
  {
    "text": "that's the intuition here so the steps to do that the two kinds of transfer",
    "start": "5183560",
    "end": "5190400"
  },
  {
    "text": "learning what what we can do is we can freeze just the last you know layer and",
    "start": "5190400",
    "end": "5199600"
  },
  {
    "text": "run the model through just train that part by fixing the weights or we can",
    "start": "5199600",
    "end": "5205010"
  },
  {
    "text": "reinitialize the entire network with different weights as well so we'll do the former and what we'll do is we'll",
    "start": "5205010",
    "end": "5212960"
  },
  {
    "text": "freeze the other layers and we're only going to modify and train the last layer",
    "start": "5212960",
    "end": "5220630"
  },
  {
    "text": "- you know - for our data set okay okay",
    "start": "5220630",
    "end": "5231320"
  },
  {
    "text": "this is gonna be a little faster so what I'm gonna do is I'm gonna refer to some",
    "start": "5231320",
    "end": "5237260"
  },
  {
    "text": "of the code in the MX net notebook github and we'll use the code from there",
    "start": "5237260",
    "end": "5244820"
  },
  {
    "text": "and transform that code for your data set all right okay so rename or should",
    "start": "5244820",
    "end": "5251690"
  },
  {
    "text": "we call it Randall or not so so the mxf",
    "start": "5251690",
    "end": "5264380"
  },
  {
    "text": "notebook tutorial has some really cool for example it's got the fine-tuning",
    "start": "5264380",
    "end": "5269770"
  },
  {
    "text": "cats versus dogs there's an example here",
    "start": "5269770",
    "end": "5275530"
  },
  {
    "text": "the only thing is we'll need to convert the images so that might take some time",
    "start": "5278320",
    "end": "5285940"
  },
  {
    "text": "so let's let's get let's download a network so let's let's download so MX",
    "start": "5285940",
    "end": "5294440"
  },
  {
    "text": "net has a model zoo which basically has",
    "start": "5294440",
    "end": "5304670"
  },
  {
    "text": "all these pre trained models so some of these models have taken like a month to Train cost like you know you know to",
    "start": "5304670",
    "end": "5314139"
  },
  {
    "text": "upwards of ten to twenty thousand dollars because you know it's been a lot of time that's spent so we can just go",
    "start": "5314139",
    "end": "5322760"
  },
  {
    "text": "download these models and train on top of them so it's it's very efficient as a",
    "start": "5322760",
    "end": "5329480"
  },
  {
    "text": "developer this is probably what you'll end up doing a lot is taking pre trained models",
    "start": "5329480",
    "end": "5335179"
  },
  {
    "text": "and then fine-tuning them for your use case because not everybody can afford to",
    "start": "5335179",
    "end": "5340489"
  },
  {
    "text": "spend you know twenty thirty thousand dollars and train from scratch and also",
    "start": "5340489",
    "end": "5345769"
  },
  {
    "text": "you might not have the data set for which is that large to be trained from",
    "start": "5345769",
    "end": "5350989"
  },
  {
    "text": "scratch so function so here we go",
    "start": "5350989",
    "end": "5364239"
  },
  {
    "text": "so we get the fine tuning so as you can",
    "start": "5364239",
    "end": "5370219"
  },
  {
    "text": "see here's what the fine tuning model does so we have we passed the model file",
    "start": "5370219",
    "end": "5377420"
  },
  {
    "text": "if you do sim dot get internals it gets all the internal layers and thanks",
    "start": "5377420",
    "end": "5390940"
  },
  {
    "text": "so friends",
    "start": "5392770",
    "end": "5396580"
  },
  {
    "text": "good fine I just want to display the model visualizer beginner yeah you can",
    "start": "5405020",
    "end": "5418829"
  },
  {
    "text": "copy that from what we did earlier now there you go yeah okay",
    "start": "5418829",
    "end": "5440159"
  },
  {
    "text": "so num classes is gonna be - because Randall or not Randall yeah well not",
    "start": "5440159",
    "end": "5457050"
  },
  {
    "text": "symbol uh I forget get oh sorry I'll",
    "start": "5457050",
    "end": "5463230"
  },
  {
    "text": "display it a little later I forget the actual command but essentially it's you know you can refer",
    "start": "5463230",
    "end": "5469770"
  },
  {
    "text": "to the the layers here and we'll just get the last output layer",
    "start": "5469770",
    "end": "5476250"
  },
  {
    "text": "and the layer name happens to be flattened zero and I think I feel like",
    "start": "5476250",
    "end": "5487739"
  },
  {
    "text": "I've had it somewhere in the code here",
    "start": "5487739",
    "end": "5491868"
  },
  {
    "text": "okay anyways we're just reset so so we",
    "start": "5495079",
    "end": "5503310"
  },
  {
    "text": "got the we got the last layer and what we'll do is we'll just initialize the",
    "start": "5503310",
    "end": "5509489"
  },
  {
    "text": "fully connected layer and we'll get the softmax upwards so we're just replacing the last layer so remember this image",
    "start": "5509489",
    "end": "5517730"
  },
  {
    "text": "we're doing this part we're replacing the last layer and we're going to train",
    "start": "5517730",
    "end": "5523889"
  },
  {
    "text": "on that does that make sense yep okay",
    "start": "5523889",
    "end": "5530719"
  },
  {
    "text": "all right but before we do that we actually need to well we'll need to kind",
    "start": "5533719",
    "end": "5543900"
  },
  {
    "text": "of shape the leader shape the images so we'll use a I traitor so so deny",
    "start": "5543900",
    "end": "5553619"
  },
  {
    "text": "traitors that we're going to use so I'm just going to reuse that which is going",
    "start": "5553619",
    "end": "5559800"
  },
  {
    "text": "to be in binary format so for example we need to create these record IO files so",
    "start": "5559800",
    "end": "5567630"
  },
  {
    "text": "that things are Randall or not so I'm gonna walk through how we are going to create that data set I'm cured data and",
    "start": "5567630",
    "end": "5577460"
  },
  {
    "text": "[Music] Randall you said you had your yeah if",
    "start": "5577460",
    "end": "5582750"
  },
  {
    "text": "you just do AWS s3 sync dot alright to",
    "start": "5582750",
    "end": "5593099"
  },
  {
    "text": "do s3 ran man - selfies are a and MA and",
    "start": "5593099",
    "end": "5600440"
  },
  {
    "text": "yeah sorry that should do it",
    "start": "5600440",
    "end": "5607909"
  },
  {
    "text": "okay well there's six thousand well view",
    "start": "5607909",
    "end": "5615780"
  },
  {
    "text": "uh do you want me to do Puritan no that's that's fine that's fine we might",
    "start": "5615780",
    "end": "5622170"
  },
  {
    "text": "want to filter out and get rid of the ones that are like less than 60kb also",
    "start": "5622170",
    "end": "5630300"
  },
  {
    "text": "appropriate all of these are will see",
    "start": "5630300",
    "end": "5637429"
  },
  {
    "text": "areas we've not done this so we'll see how to do this yeah this there's this",
    "start": "5637429",
    "end": "5644340"
  },
  {
    "text": "bug in the interview SS three same thing because the list object command returns",
    "start": "5644340",
    "end": "5650070"
  },
  {
    "text": "1000 by default so it always shows approximately 1000 files are meaning",
    "start": "5650070",
    "end": "5656960"
  },
  {
    "text": "in today I just look at the bytes the total bytes and that gives me an idea",
    "start": "5657130",
    "end": "5665429"
  },
  {
    "text": "okay whoa I think I should just stop it now",
    "start": "5665489",
    "end": "5673290"
  },
  {
    "text": "what do you think I think that's enough data sure only guys I'm gonna try and",
    "start": "5673290",
    "end": "5691690"
  },
  {
    "text": "get at these 2,000 images so what what",
    "start": "5691690",
    "end": "5696760"
  },
  {
    "text": "we need to do is I'll just explain the next step so that I can run through them",
    "start": "5696760",
    "end": "5702329"
  },
  {
    "text": "will create a train basically training and validation set directories and will like label them say",
    "start": "5702329",
    "end": "5709300"
  },
  {
    "text": "1 & 0 just that it's easier for us to you know work with this and then I'm",
    "start": "5709300",
    "end": "5720460"
  },
  {
    "text": "just going to move some of these files around and we're gonna convert we're gonna execute these commands to create",
    "start": "5720460",
    "end": "5728520"
  },
  {
    "text": "record I traitor files so that it's more efficient when we train ok so I should",
    "start": "5728520",
    "end": "5740139"
  },
  {
    "text": "have probably done the data processing but you know this is a live show ok the",
    "start": "5740139",
    "end": "5747119"
  },
  {
    "text": "train slash I'll call zero Randal",
    "start": "5747119",
    "end": "5754230"
  },
  {
    "text": "ok so move",
    "start": "5756030",
    "end": "5762360"
  },
  {
    "text": "okay so I've moved everything there so what I did was I went to fw datasets",
    "start": "5765130",
    "end": "5775999"
  },
  {
    "text": "there's a face database and there's a bunch of like celebrity images that are",
    "start": "5775999",
    "end": "5782030"
  },
  {
    "text": "present here which I downloaded and that's going to be our not Randall data",
    "start": "5782030",
    "end": "5787610"
  },
  {
    "text": "set okay yeah they are labeled I might",
    "start": "5787610",
    "end": "5796639"
  },
  {
    "text": "use that for another project so right so",
    "start": "5796639",
    "end": "5803449"
  },
  {
    "text": "they gonna I think I don't know so I",
    "start": "5803449",
    "end": "5817820"
  },
  {
    "text": "need to copy all these images over so",
    "start": "5817820",
    "end": "5823448"
  },
  {
    "text": "okay let's see let's do some bash here",
    "start": "5824050",
    "end": "5830169"
  },
  {
    "text": "for I think I have it a list of",
    "start": "5830169",
    "end": "5836619"
  },
  {
    "text": "oh man I thought I had a file Wow can",
    "start": "5845289",
    "end": "5864280"
  },
  {
    "text": "you LS dash L a grip anyways I'm really",
    "start": "5864280",
    "end": "5870610"
  },
  {
    "text": "trying to find a command that you ran previously yeah if you do ctrl R and you",
    "start": "5870610",
    "end": "5875679"
  },
  {
    "text": "type the beginning part of it now no no I'm sorry I'm actually trying to find the side generated the file",
    "start": "5875679",
    "end": "5885030"
  },
  {
    "text": "there you go sell it images stuff txq that's what I want so I have these",
    "start": "5887639",
    "end": "5893800"
  },
  {
    "text": "images so far let's say for F in cat",
    "start": "5893800",
    "end": "5903118"
  },
  {
    "text": "some of them is 62 and we so I'm going",
    "start": "5903179",
    "end": "5910420"
  },
  {
    "text": "to move the file what's the train one not Randall",
    "start": "5910420",
    "end": "5928590"
  },
  {
    "text": "sar you doing yeah I see what you're doing there you",
    "start": "5940410",
    "end": "5946420"
  },
  {
    "text": "go hopefully that works I don't have a",
    "start": "5946420",
    "end": "5955690"
  },
  {
    "text": "backup here city I left my soda in the freezer so it's completely frozen now because I forgot",
    "start": "5955690",
    "end": "5961989"
  },
  {
    "text": "that we were doing the show and maybe we",
    "start": "5961989",
    "end": "5970180"
  },
  {
    "text": "should switch to you okay there you go so we have our data set Randall and not",
    "start": "5970180",
    "end": "5977980"
  },
  {
    "text": "random now what I'm gonna do is you know",
    "start": "5977980",
    "end": "5986940"
  },
  {
    "text": "basically have a split function",
    "start": "5987090",
    "end": "5992400"
  },
  {
    "text": "so basically of copied can we because I",
    "start": "5992650",
    "end": "5999100"
  },
  {
    "text": "think it's gonna be useful I think we should clear out let's let's try it",
    "start": "5999100",
    "end": "6013260"
  },
  {
    "text": "let's build a model like let's try to get and then we can improve and see what's wrong",
    "start": "6013260",
    "end": "6020130"
  },
  {
    "text": "so all right lighting I'm gonna be",
    "start": "6020130",
    "end": "6032130"
  },
  {
    "text": "coding in the dark now let me just get",
    "start": "6032130",
    "end": "6041280"
  },
  {
    "text": "up there you okay it's got",
    "start": "6041280",
    "end": "6052670"
  },
  {
    "text": "I'm just gonna keep the same directory names doesn't matter all right so well",
    "start": "6055470",
    "end": "6063610"
  },
  {
    "text": "it 1-1 it's not Crandall okay you know",
    "start": "6063610",
    "end": "6080890"
  },
  {
    "text": "this would only work with a millennial because I'm the only kind of person who takes 3,000 selfies with myself yeah I",
    "start": "6080890",
    "end": "6086620"
  },
  {
    "text": "know okay oh yeah okay yeah now I'm gonna create",
    "start": "6086620",
    "end": "6114820"
  },
  {
    "text": "the list",
    "start": "6114820",
    "end": "6118679"
  },
  {
    "text": "Randall not random out in our I'm just",
    "start": "6121320",
    "end": "6129310"
  },
  {
    "text": "gonna call that so we're creating our list for our validation these are just",
    "start": "6129310",
    "end": "6134470"
  },
  {
    "text": "list files or so we can efficiently",
    "start": "6134470",
    "end": "6142960"
  },
  {
    "text": "generate the record i/o files and we're gonna",
    "start": "6142960",
    "end": "6149850"
  },
  {
    "text": "so you can see these are just image operation we can see we are resizing",
    "start": "6154980",
    "end": "6161580"
  },
  {
    "text": "we're car we're changing the quality of the images and it's pretty efficiently",
    "start": "6161580",
    "end": "6167790"
  },
  {
    "text": "implemented within c-class class as a Python equivalent as well so the images",
    "start": "6167790",
    "end": "6178950"
  },
  {
    "text": "the input images need to be in the same shape yeah so this is just casting them",
    "start": "6178950",
    "end": "6184200"
  },
  {
    "text": "all to that shape and greyscale and all the other stuff yeah so this is this",
    "start": "6184200",
    "end": "6189420"
  },
  {
    "text": "becomes a I added an extra prefix and",
    "start": "6189420",
    "end": "6196710"
  },
  {
    "text": "doesn't matter but train there you go",
    "start": "6196710",
    "end": "6201750"
  },
  {
    "text": "that's our dataset okay so that worked so you can see here we're shuffling",
    "start": "6201750",
    "end": "6207720"
  },
  {
    "text": "we're we're saying hey you can crop you can mirror so we're augmenting the dataset and enhancing that as well I",
    "start": "6207720",
    "end": "6214950"
  },
  {
    "text": "just we created new options - yeah different things it's pretty cool right",
    "start": "6214950",
    "end": "6221880"
  },
  {
    "text": "so we basically enhance our dataset even because we only have like say 3,000",
    "start": "6221880",
    "end": "6227640"
  },
  {
    "text": "images of you correct",
    "start": "6227640",
    "end": "6237110"
  },
  {
    "text": "I mean this is this is done yeah this is done within the you know operator itself",
    "start": "6239420",
    "end": "6245880"
  },
  {
    "text": "so we've done we're done with these steps now so we have downloaded the",
    "start": "6245880",
    "end": "6253470"
  },
  {
    "text": "model we will get our training model and",
    "start": "6253470",
    "end": "6260040"
  },
  {
    "text": "the next thing is actually so now we can",
    "start": "6260040",
    "end": "6271850"
  },
  {
    "text": "correct so we're gonna run it for two",
    "start": "6271850",
    "end": "6276920"
  },
  {
    "text": "classes by a classification we handle",
    "start": "6276920",
    "end": "6282720"
  },
  {
    "text": "versus not really yeah",
    "start": "6282720",
    "end": "6286850"
  },
  {
    "text": "okay I'm gonna use all the GPUs I don't",
    "start": "6290260",
    "end": "6298970"
  },
  {
    "text": "know I'm gonna I mean it's I'm just going to use a single GPU but for bad size we'll see",
    "start": "6298970",
    "end": "6305750"
  },
  {
    "text": "what happens I just want to see some improvements we'll call the fit function okay",
    "start": "6305750",
    "end": "6331520"
  },
  {
    "text": "cannot find any like file that's because",
    "start": "6331520",
    "end": "6336530"
  },
  {
    "text": "they are in the data folder Wow the",
    "start": "6336530",
    "end": "6354200"
  },
  {
    "text": "lights going out yeah you're not active enough",
    "start": "6354200",
    "end": "6360460"
  },
  {
    "text": "- same directory",
    "start": "6367159",
    "end": "6370790"
  },
  {
    "text": "I don't know what's happening here get",
    "start": "6388090",
    "end": "6393270"
  },
  {
    "text": "it is in the right directory rate this rich CNN cannot find you alright",
    "start": "6393270",
    "end": "6402099"
  },
  {
    "text": "patterns of match data do you maybe mean",
    "start": "6402099",
    "end": "6408790"
  },
  {
    "text": "need a dot slash in front of theta yeah could be no I'm gonna do we can",
    "start": "6408790",
    "end": "6426489"
  },
  {
    "text": "always do like oh it's path that expand",
    "start": "6426489",
    "end": "6433989"
  },
  {
    "text": "user and then passing the full path yeah I'm just gonna cheat",
    "start": "6433989",
    "end": "6442020"
  },
  {
    "text": "Oh still not working",
    "start": "6452499",
    "end": "6466989"
  },
  {
    "text": "yeah maybe it's maybe it depends on the",
    "start": "6466989",
    "end": "6473670"
  },
  {
    "text": "input space yeah maybe yeah I doubt it",
    "start": "6474300",
    "end": "6483030"
  },
  {
    "text": "if so like we can open a bug against the next net",
    "start": "6486869",
    "end": "6491999"
  },
  {
    "text": "so I mean what is the file size that's the other thing that it's checked that's a good good point actually",
    "start": "6503679",
    "end": "6510699"
  },
  {
    "text": "yeah it's a good point we probably did",
    "start": "6510699",
    "end": "6515860"
  },
  {
    "text": "not do something went wrong in our step yeah that's why it's not working it's",
    "start": "6515860",
    "end": "6523300"
  },
  {
    "text": "because it's look at that in this file yep there you go it doesn't throw friendly editors yeah I mean it does say",
    "start": "6523300",
    "end": "6532570"
  },
  {
    "text": "that in the error message it's just we had to sit there and read the beginning part of the error message because it looked like the second the English part",
    "start": "6532570",
    "end": "6538690"
  },
  {
    "text": "of the error message is like could not find a file type book made sense but the",
    "start": "6538690",
    "end": "6543760"
  },
  {
    "text": "way right before that is did not match this pattern of file size not equal to",
    "start": "6543760",
    "end": "6549070"
  },
  {
    "text": "zero so that did complete very quickly",
    "start": "6549070",
    "end": "6558929"
  },
  {
    "text": "yeah I should have suspected that I think this is okay there you go there",
    "start": "6558929",
    "end": "6576370"
  },
  {
    "text": "you go there we go that's good that is what we want",
    "start": "6576370",
    "end": "6583090"
  },
  {
    "text": "[Music] oh",
    "start": "6583090",
    "end": "6589780"
  },
  {
    "text": "I need this yeah I should do it",
    "start": "6589780",
    "end": "6607948"
  },
  {
    "text": "okay",
    "start": "6612590",
    "end": "6615590"
  },
  {
    "text": "aha there we go oh so this is doing all",
    "start": "6623369",
    "end": "6629110"
  },
  {
    "text": "those rotations and things creating a lot more images than we started with no it's actually just converting into the",
    "start": "6629110",
    "end": "6637260"
  },
  {
    "text": "its resizing and converting it coos ooh cat says hey I just tuned in what are",
    "start": "6637260",
    "end": "6643570"
  },
  {
    "text": "you guys doing we are building an image recognition model a convolutional neural",
    "start": "6643570",
    "end": "6649060"
  },
  {
    "text": "network for determining whether or not something is a picture of my face",
    "start": "6649060",
    "end": "6655679"
  },
  {
    "text": "because that seemed like a good idea at the time there you go",
    "start": "6658440",
    "end": "6668340"
  },
  {
    "text": "we've got 218 Meg's and the validation set is about 6.3 gotcha",
    "start": "6668340",
    "end": "6679139"
  },
  {
    "text": "aha okay catch so you see like I'm still",
    "start": "6703800",
    "end": "6714580"
  },
  {
    "text": "using Socastee gradient descent I'm not using the optimizer I'm just using",
    "start": "6714580",
    "end": "6719860"
  },
  {
    "text": "whatever was there and seeing what happens right so but this is what you as",
    "start": "6719860",
    "end": "6725440"
  },
  {
    "text": "a programmer will need to play with you might use a different optimizer and use a different learning rate different bat",
    "start": "6725440",
    "end": "6731620"
  },
  {
    "text": "size like that's the that's what all you need to do so look at that that's not",
    "start": "6731620",
    "end": "6738250"
  },
  {
    "text": "bad at all right yeah I mean it's really",
    "start": "6738250",
    "end": "6743260"
  },
  {
    "text": "easy to identify you I'm gonna very standout kind of person I really hope",
    "start": "6743260",
    "end": "6749380"
  },
  {
    "text": "that it's not taking all of the images that are just like 60kb black images and",
    "start": "6749380",
    "end": "6756070"
  },
  {
    "text": "assuming that if I post a black image that it's a Randall yeah I don't know",
    "start": "6756070",
    "end": "6762340"
  },
  {
    "text": "so let's Matt okay well save I wonder",
    "start": "6762340",
    "end": "6776800"
  },
  {
    "text": "how many batches I would let it go while I build up the rest of the code okay so",
    "start": "6776800",
    "end": "6783100"
  },
  {
    "text": "yeah I'll show you guys how to like load",
    "start": "6783100",
    "end": "6788350"
  },
  {
    "text": "the model so we'll take a we take an",
    "start": "6788350",
    "end": "6796240"
  },
  {
    "text": "image and see if you know that's Randall or not you wanna you said you wanna send",
    "start": "6796240",
    "end": "6804430"
  },
  {
    "text": "me a selfie you know yes put and put a new image in in that bucket and let's",
    "start": "6804430",
    "end": "6811120"
  },
  {
    "text": "let's see what happens do you want to just grab the one from the evangelist page does that work or does it need to",
    "start": "6811120",
    "end": "6817660"
  },
  {
    "text": "be the same input type I can now I can shape because I have the code here to shape",
    "start": "6817660",
    "end": "6823270"
  },
  {
    "text": "the model so we can use that prefix if",
    "start": "6823270",
    "end": "6828489"
  },
  {
    "text": "you grab the one from this page I'll put it in twitch chat but also send it to you yeah if you just grab the a-hole",
    "start": "6828489",
    "end": "6838810"
  },
  {
    "text": "photoshopped picture in there it might be good otherwise I'll stay here and",
    "start": "6838810",
    "end": "6853570"
  },
  {
    "text": "then okay this is gonna be fun",
    "start": "6853570",
    "end": "6861219"
  },
  {
    "text": "I wish I could just stop but it has to",
    "start": "6861219",
    "end": "6871000"
  },
  {
    "text": "finish that first Devo kind of can I'm just waiting to see if just finish so",
    "start": "6871000",
    "end": "6879070"
  },
  {
    "text": "let's let's get everything else ready so I'm the hunch this is a really bad photo",
    "start": "6879070",
    "end": "6889840"
  },
  {
    "text": "of me by the way this is my badge photo",
    "start": "6889840",
    "end": "6896158"
  },
  {
    "text": "[Music] but you can W get that if you need to",
    "start": "6898060",
    "end": "6904409"
  },
  {
    "text": "now I have the code to do that I think I",
    "start": "6904409",
    "end": "6916060"
  },
  {
    "text": "just anyways yeah I shouldn't have done",
    "start": "6916060",
    "end": "6927429"
  },
  {
    "text": "that and you shouldn't do we have to start again yeah I know I I accidentally",
    "start": "6927429",
    "end": "6941100"
  },
  {
    "text": "do we need to do module dot save instead of or no that's fine like the module",
    "start": "6944689",
    "end": "6952769"
  },
  {
    "text": "variable wasn't available for me because I stopped it it was in the there's not in the context alright where did we",
    "start": "6952769",
    "end": "6958889"
  },
  {
    "text": "define the number of epochs I didn't see that here oh good question",
    "start": "6958889",
    "end": "6967619"
  },
  {
    "text": "is by default it just takes one I think we declared it",
    "start": "6967619",
    "end": "6973849"
  },
  {
    "text": "yeah I'm just using the default epoch okay it's going faster this time it was only doing 12 samples a second last time",
    "start": "6976760",
    "end": "6983489"
  },
  {
    "text": "yeah because I using four GPUs have you shut down all of the other models like a",
    "start": "6983489",
    "end": "6989280"
  },
  {
    "text": "chain think so so the other one oh well",
    "start": "6989280",
    "end": "6997130"
  },
  {
    "text": "the other model we tried earlier we still kind of got stuck at 88% it seems",
    "start": "6997130",
    "end": "7003829"
  },
  {
    "text": "like we need a more really changes in you know the filter size perhaps we need",
    "start": "7003829",
    "end": "7011269"
  },
  {
    "text": "to make the model a little more complex I feel to get better results maybe some",
    "start": "7011269",
    "end": "7017570"
  },
  {
    "text": "rotations and stuff like that yeah more yeah more data and so on so adding",
    "start": "7017570",
    "end": "7025429"
  },
  {
    "text": "another layer didn't really help us in that case correct so the adding layer correct yeah it didn't really affect so",
    "start": "7025429",
    "end": "7032659"
  },
  {
    "text": "which means that maybe we lack the data maybe the filter size so you kind of like can start debugging from that from",
    "start": "7032659",
    "end": "7040369"
  },
  {
    "text": "that point so is in the convolutional sense is adding another layer the first",
    "start": "7040369",
    "end": "7046519"
  },
  {
    "text": "thing that you try or yeah you can do that yeah so it depends on more layers",
    "start": "7046519",
    "end": "7054429"
  },
  {
    "text": "but more layers need more data I thought I had more data but maybe I didn't so",
    "start": "7054429",
    "end": "7063550"
  },
  {
    "text": "yeah you can you play with this then you know depending upon the results you see",
    "start": "7063550",
    "end": "7069139"
  },
  {
    "text": "well so you've got to build on that intuition so it's a lot of like debugging like code like debugging kind",
    "start": "7069139",
    "end": "7075949"
  },
  {
    "text": "of see you know what the network is telling you what the process is telling you and then kind of so we have some",
    "start": "7075949",
    "end": "7084110"
  },
  {
    "text": "people in the twitch chat asking if we're working on Skynet no this reminds",
    "start": "7084110",
    "end": "7090530"
  },
  {
    "text": "me so Fox asked if we were working on Skynet I'll go ahead and say no but I",
    "start": "7090530",
    "end": "7096769"
  },
  {
    "text": "for one welcome our new artificially intelligent overlords and then go suit cat says this reminds me of something",
    "start": "7096769",
    "end": "7102499"
  },
  {
    "text": "the NSA would make and I'm sure the NSA has already made this and the threat Barry says how are you feeling today I'm",
    "start": "7102499",
    "end": "7108559"
  },
  {
    "text": "feeling pretty good I can walk a day",
    "start": "7108559",
    "end": "7122360"
  },
  {
    "text": "gpus well yeah I've tried too many",
    "start": "7122360",
    "end": "7133249"
  },
  {
    "text": "things now my how are we gonna run again",
    "start": "7133249",
    "end": "7142030"
  },
  {
    "text": "yep that's some of the they don't",
    "start": "7142030",
    "end": "7150769"
  },
  {
    "text": "cleanly detach depending on how the kernel is stopped or how the execution",
    "start": "7150769",
    "end": "7156349"
  },
  {
    "text": "is stopped yeah that's true I think I'm",
    "start": "7156349",
    "end": "7164150"
  },
  {
    "text": "using this okay clearly",
    "start": "7164150",
    "end": "7170499"
  },
  {
    "text": "there you go to that right not happy we've got a bunch of things running on",
    "start": "7172960",
    "end": "7179960"
  },
  {
    "text": "all the GPS clear all those like if we",
    "start": "7179960",
    "end": "7191570"
  },
  {
    "text": "just PS ox or P grep for Python I don't",
    "start": "7191570",
    "end": "7198500"
  },
  {
    "text": "know I don't want to kill all the stuff",
    "start": "7198500",
    "end": "7206739"
  },
  {
    "text": "maybe running something important okay",
    "start": "7206980",
    "end": "7212870"
  },
  {
    "text": "so Fred berry asks if we could get a Amazon lumberyard game'll obsession I",
    "start": "7212870",
    "end": "7218570"
  },
  {
    "text": "could probably do a lumberyard session maybe around the November timeframe game",
    "start": "7218570",
    "end": "7225110"
  },
  {
    "text": "live I don't have enough people who would want to play a game that I would need a game left really I mean I can",
    "start": "7225110",
    "end": "7232670"
  },
  {
    "text": "demonstrate game lifts and I can demonstrate the matchmaking components but you guys would all have to download",
    "start": "7232670",
    "end": "7237980"
  },
  {
    "text": "an executable and then we would have to you know artificially limit my number of",
    "start": "7237980",
    "end": "7243980"
  },
  {
    "text": "servers to zero so that it would spin up an additional server and then hello",
    "start": "7243980",
    "end": "7250219"
  },
  {
    "text": "world for connecting lumberyard AWS and twitch maybe I can get somebody from really lumberyard team to come and do",
    "start": "7250219",
    "end": "7256580"
  },
  {
    "text": "that they they have their own twitch channel as you guys can check out the Amazon game studios twitch channel so if",
    "start": "7256580",
    "end": "7263510"
  },
  {
    "text": "you look at Clay breakaway in those games they have a good twitch channel as",
    "start": "7263510",
    "end": "7269840"
  },
  {
    "text": "well I'm trying to speed up this entire",
    "start": "7269840",
    "end": "7275270"
  },
  {
    "text": "process and things are not being friendly I think unfortunately like yeah",
    "start": "7275270",
    "end": "7281870"
  },
  {
    "text": "I was trying to get it in the next two minutes and we'll we'll probably need to stop here and we will not come back",
    "start": "7281870",
    "end": "7291489"
  },
  {
    "text": "anyway no will will show no the code is there we know it's training it's",
    "start": "7291489",
    "end": "7299120"
  },
  {
    "text": "probably going to get things right but we just don't know how it might just",
    "start": "7299120",
    "end": "7304219"
  },
  {
    "text": "take us you know ten minutes to get this running and you know stream needs to be closed so I don't know if",
    "start": "7304219",
    "end": "7313430"
  },
  {
    "text": "you have ideas maybe we can post this a",
    "start": "7313430",
    "end": "7319310"
  },
  {
    "text": "little later so I'm going to run this in the background and we'll post it in the Twitter stream or twitch chat or we'll",
    "start": "7319310",
    "end": "7327260"
  },
  {
    "text": "just have this will just tweet out and yeah you guys can take it from there",
    "start": "7327260",
    "end": "7332660"
  },
  {
    "text": "okay I am gonna say that I think you're probably gonna need to remove some of those all-black images to make the model",
    "start": "7332660",
    "end": "7339680"
  },
  {
    "text": "train if not faster better yeah what's the good news about those all",
    "start": "7339680",
    "end": "7345500"
  },
  {
    "text": "black images if they're all like less than 100k so you could just do like fine name JPEG size 100k - delete so for",
    "start": "7345500",
    "end": "7357680"
  },
  {
    "text": "folks like you know who want to just go play with the code the fine-tuning code",
    "start": "7357680",
    "end": "7363860"
  },
  {
    "text": "that I showed is already up on github so it's I'm posting the code so you guys",
    "start": "7363860",
    "end": "7372200"
  },
  {
    "text": "can go start you know this is an instruction it you know it's very",
    "start": "7372200",
    "end": "7377690"
  },
  {
    "text": "detailed you can download this data set and and get it going to basically",
    "start": "7377690",
    "end": "7383690"
  },
  {
    "text": "identify cats and not cats or cats and",
    "start": "7383690",
    "end": "7389990"
  },
  {
    "text": "dogs in this case cool well thanks again",
    "start": "7389990",
    "end": "7397460"
  },
  {
    "text": "for putting up with me and teaching me through a two hour long series of",
    "start": "7397460",
    "end": "7406520"
  },
  {
    "text": "questions I anything else that you want to close with anything that you want",
    "start": "7406520",
    "end": "7412610"
  },
  {
    "text": "people to know about the next session yeah so so people folks say you can go",
    "start": "7412610",
    "end": "7420320"
  },
  {
    "text": "to the github link all the code was uploaded here as you can see episode one",
    "start": "7420320",
    "end": "7426590"
  },
  {
    "text": "and two the codes already up I'll post the code that we did today probably",
    "start": "7426590",
    "end": "7432980"
  },
  {
    "text": "ended today or early in the morning so go check this out run the labs the sessions are recorded",
    "start": "7432980",
    "end": "7439960"
  },
  {
    "text": "you know feel free to send questions you know send us feedback also if you have",
    "start": "7439960",
    "end": "7446349"
  },
  {
    "text": "some cool ideas or datasets that you want us to model and work on I'm happy",
    "start": "7446349",
    "end": "7451690"
  },
  {
    "text": "to take that on so next week I'm still deciding on what to do but we probably",
    "start": "7451690",
    "end": "7458860"
  },
  {
    "text": "do neural machine translation will will kind of explore how we can you know",
    "start": "7458860",
    "end": "7466559"
  },
  {
    "text": "convert from French to English French to German and kind of play with language",
    "start": "7466559",
    "end": "7472360"
  },
  {
    "text": "conversion there I speak those languages so that's fine okay I can I can grade our translation and",
    "start": "7472360",
    "end": "7479829"
  },
  {
    "text": "I'm really excited to say this twitch users name what set that that's his name this is",
    "start": "7479829",
    "end": "7486789"
  },
  {
    "text": "will this be available on YouTube or somewhere else later it will be on the twitch channel maybe ten minutes after",
    "start": "7486789",
    "end": "7492039"
  },
  {
    "text": "this recording and it'll go to the YouTube channel in a few days I guess",
    "start": "7492039",
    "end": "7498460"
  },
  {
    "text": "but you can get all of the information about the twitch series not just about the stuff that we do at native esa",
    "start": "7498460",
    "end": "7504460"
  },
  {
    "text": "amazon.com slash twitch and i'll post",
    "start": "7504460",
    "end": "7509889"
  },
  {
    "text": "that link here and you can see all the different episodes and stuff that we run so it's Neal thank you so much I had a",
    "start": "7509889",
    "end": "7517750"
  },
  {
    "text": "good time today I learned a lot I feel like a bunch of different concepts buy my click together in my head that's good",
    "start": "7517750",
    "end": "7524260"
  },
  {
    "text": "I am going to go and play with some of this and that's it bye I'm gonna hold",
    "start": "7524260",
    "end": "7530829"
  },
  {
    "text": "you I'm gonna hold you up for that okay cheers guys",
    "start": "7530829",
    "end": "7536849"
  }
]
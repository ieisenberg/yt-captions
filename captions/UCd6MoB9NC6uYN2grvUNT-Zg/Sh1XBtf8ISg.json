[
  {
    "text": "- Hi everyone, my name is Lester,",
    "start": "1110",
    "end": "3179"
  },
  {
    "text": "an associate solutions\narchitect here at AWS.",
    "start": "3180",
    "end": "6720"
  },
  {
    "text": "In today's quick demo,",
    "start": "6720",
    "end": "7979"
  },
  {
    "text": "I'll be covering the\ntopic of generative AI",
    "start": "7980",
    "end": "10770"
  },
  {
    "text": "and how you can create custom\nmodels in Amazon Bedrock",
    "start": "10770",
    "end": "13800"
  },
  {
    "text": "using fine-tuning by leveraging\non your own business data",
    "start": "13800",
    "end": "17250"
  },
  {
    "text": "to create unique interactions\nwith your customers.",
    "start": "17250",
    "end": "20103"
  },
  {
    "text": "Today, Amazon Bedrock provides access",
    "start": "21390",
    "end": "23730"
  },
  {
    "text": "to a wide range of foundation models",
    "start": "23730",
    "end": "25949"
  },
  {
    "text": "from leaders such as AI21 Labs,",
    "start": "25950",
    "end": "28140"
  },
  {
    "text": "Anthropic, Cohere, Meta, Stability AI,",
    "start": "28140",
    "end": "30990"
  },
  {
    "text": "as well as some of our\nown Amazon Titan models.",
    "start": "30990",
    "end": "34143"
  },
  {
    "text": "And here are some of the common approaches",
    "start": "35280",
    "end": "36719"
  },
  {
    "text": "to customizing the foundation models.",
    "start": "36720",
    "end": "38910"
  },
  {
    "text": "In this demo,",
    "start": "38910",
    "end": "39750"
  },
  {
    "text": "I'll be focusing on how\nyou can fine-tune a model",
    "start": "39750",
    "end": "42270"
  },
  {
    "text": "in Amazon Bedrock with your training data.",
    "start": "42270",
    "end": "44910"
  },
  {
    "text": "There are two ways for customizing:",
    "start": "44910",
    "end": "46950"
  },
  {
    "text": "One is using fine-tuning,",
    "start": "46950",
    "end": "48390"
  },
  {
    "text": "and the second is continued pre-training.",
    "start": "48390",
    "end": "50790"
  },
  {
    "text": "So with fine-tuning, you're\nproviding labeled datasets",
    "start": "50790",
    "end": "53400"
  },
  {
    "text": "to train the model on a specific task,",
    "start": "53400",
    "end": "55500"
  },
  {
    "text": "and the purpose is to\nincrease the accuracy",
    "start": "55500",
    "end": "57390"
  },
  {
    "text": "for this specific task.",
    "start": "57390",
    "end": "59280"
  },
  {
    "text": "With continued pre-training,",
    "start": "59280",
    "end": "61110"
  },
  {
    "text": "you're providing large\nnumber of unlabeled datasets",
    "start": "61110",
    "end": "63780"
  },
  {
    "text": "to maintain the accuracy\nof the foundation model",
    "start": "63780",
    "end": "65820"
  },
  {
    "text": "for your domain.",
    "start": "65820",
    "end": "66990"
  },
  {
    "text": "But in this demo,",
    "start": "66990",
    "end": "68100"
  },
  {
    "text": "I'll be now showing you how\nyou can fine-tune a model",
    "start": "68100",
    "end": "70890"
  },
  {
    "text": "in Amazon Bedrock.",
    "start": "70890",
    "end": "72000"
  },
  {
    "text": "So let's jump right into it.",
    "start": "72000",
    "end": "73400"
  },
  {
    "text": "In this demo,",
    "start": "74250",
    "end": "75083"
  },
  {
    "text": "we'll be using the dialogsum dataset,",
    "start": "75083",
    "end": "77070"
  },
  {
    "text": "and I have downloaded the\nParquet file into my local drive",
    "start": "77070",
    "end": "80460"
  },
  {
    "text": "to process it using a Jupyter notebook.",
    "start": "80460",
    "end": "83040"
  },
  {
    "text": "So the dialogue column is\nthe transcript of a call,",
    "start": "83040",
    "end": "85620"
  },
  {
    "text": "while the summary column\nacts as the labeled dataset",
    "start": "85620",
    "end": "88170"
  },
  {
    "text": "in terms of specifying",
    "start": "88170",
    "end": "89520"
  },
  {
    "text": "how I want the dialogue to be summarized",
    "start": "89520",
    "end": "91380"
  },
  {
    "text": "in a certain format.",
    "start": "91380",
    "end": "93119"
  },
  {
    "text": "So I'll go ahead to create\na new column called prompt,",
    "start": "93120",
    "end": "95640"
  },
  {
    "text": "and in the text, I'll summarize\nthe following conversation",
    "start": "95640",
    "end": "98460"
  },
  {
    "text": "in front of each dialogue.",
    "start": "98460",
    "end": "100293"
  },
  {
    "text": "I'll then rename the columns\nto prompt and completion",
    "start": "101580",
    "end": "105060"
  },
  {
    "text": "and also limit it to 1,000\nrows to train for this demo.",
    "start": "105060",
    "end": "108452"
  },
  {
    "text": "I'll then save this training\ndataset as a JSONL format",
    "start": "109740",
    "end": "112650"
  },
  {
    "text": "to my local drive.",
    "start": "112650",
    "end": "114330"
  },
  {
    "text": "And this is how the\nJSONL format looks like.",
    "start": "114330",
    "end": "117093"
  },
  {
    "text": "So I have the training data,",
    "start": "121350",
    "end": "122880"
  },
  {
    "text": "the JSONL format data in my local drive,",
    "start": "122880",
    "end": "124890"
  },
  {
    "text": "and I'll upload it to Amazon S3.",
    "start": "124890",
    "end": "127470"
  },
  {
    "text": "I've created a\ndemo-bedrock-finetuning bucket",
    "start": "127470",
    "end": "130020"
  },
  {
    "text": "to upload the JSONL format data.",
    "start": "130020",
    "end": "132303"
  },
  {
    "text": "Next, we'll also have created",
    "start": "133380",
    "end": "135150"
  },
  {
    "text": "a bedrock-finetuning-output bucket.",
    "start": "135150",
    "end": "137819"
  },
  {
    "text": "This will be storing the\nBedrock output later on.",
    "start": "137820",
    "end": "141510"
  },
  {
    "text": "So let's go ahead search\nour Amazon Bedrock.",
    "start": "141510",
    "end": "143580"
  },
  {
    "text": "I'm using the North Virginia\nregion for this demo,",
    "start": "143580",
    "end": "146250"
  },
  {
    "text": "and also ensure that I have",
    "start": "146250",
    "end": "148380"
  },
  {
    "text": "the appropriate model\naccess before continuing.",
    "start": "148380",
    "end": "151680"
  },
  {
    "text": "So let's click on Custom models",
    "start": "151680",
    "end": "153420"
  },
  {
    "text": "and create a fine-tuning job.",
    "start": "153420",
    "end": "155730"
  },
  {
    "text": "Select a model, in this\ncase, a Command Light model.",
    "start": "155730",
    "end": "158430"
  },
  {
    "text": "Give it a model name, as well\nas a job configuration name.",
    "start": "158430",
    "end": "162243"
  },
  {
    "text": "Under the Input data, you\ncan select the S3 location",
    "start": "163470",
    "end": "166530"
  },
  {
    "text": "to start containing your training data.",
    "start": "166530",
    "end": "168480"
  },
  {
    "text": "And scrolling down, you'll\nsee the Hyperparameters",
    "start": "170250",
    "end": "172830"
  },
  {
    "text": "that you can change for your\nfine-tuning job as well.",
    "start": "172830",
    "end": "175743"
  },
  {
    "text": "And in the Output data, you\ncan select the S3 bucket",
    "start": "177390",
    "end": "180150"
  },
  {
    "text": "to install your outputs later on.",
    "start": "180150",
    "end": "182252"
  },
  {
    "text": "Next, I will create a new IAM rule",
    "start": "183810",
    "end": "186239"
  },
  {
    "text": "that gives Amazon Bedrock permissions",
    "start": "186240",
    "end": "188250"
  },
  {
    "text": "to read and write to the\ninput and output S3 buckets",
    "start": "188250",
    "end": "191580"
  },
  {
    "text": "that we specified earlier.",
    "start": "191580",
    "end": "193233"
  },
  {
    "text": "We can go ahead and click\non Create a fine-tuning job.",
    "start": "194880",
    "end": "197580"
  },
  {
    "text": "And you can monitor the progress",
    "start": "199230",
    "end": "201030"
  },
  {
    "text": "under the Training jobs tab.",
    "start": "201030",
    "end": "202743"
  },
  {
    "text": "Once that is completed,",
    "start": "204930",
    "end": "207060"
  },
  {
    "text": "we can proceed back to the Model step",
    "start": "207060",
    "end": "209940"
  },
  {
    "text": "and click on the model\nthat we have trained.",
    "start": "209940",
    "end": "212140"
  },
  {
    "text": "We can scroll down",
    "start": "214170",
    "end": "215490"
  },
  {
    "text": "and click on Purchase Provision Throughput",
    "start": "215490",
    "end": "218220"
  },
  {
    "text": "to be able to use our custom models.",
    "start": "218220",
    "end": "221430"
  },
  {
    "text": "You can select a commitment term,",
    "start": "221430",
    "end": "222689"
  },
  {
    "text": "in this case, I'll select No commitment",
    "start": "222690",
    "end": "224370"
  },
  {
    "text": "and purchase the provision throughput.",
    "start": "224370",
    "end": "226713"
  },
  {
    "text": "Once it has been created and\nshows that it's in service,",
    "start": "228780",
    "end": "231780"
  },
  {
    "text": "we can go ahead to test it out",
    "start": "231780",
    "end": "233550"
  },
  {
    "text": "by clicking on Text under\nthe Playground section.",
    "start": "233550",
    "end": "236670"
  },
  {
    "text": "So select our custom fine-tuned model",
    "start": "236670",
    "end": "239340"
  },
  {
    "text": "and provide it with a sample prompt.",
    "start": "239340",
    "end": "241590"
  },
  {
    "text": "And we can see that the output prompt",
    "start": "241590",
    "end": "243480"
  },
  {
    "text": "actually closely mimics\nthe format that we specify",
    "start": "243480",
    "end": "245970"
  },
  {
    "text": "in our training dataset.",
    "start": "245970",
    "end": "247233"
  },
  {
    "text": "And this is how it looks like",
    "start": "248880",
    "end": "249960"
  },
  {
    "text": "using the Boto3 Python library.",
    "start": "249960",
    "end": "252030"
  },
  {
    "text": "We'll import the necessary libraries,",
    "start": "252030",
    "end": "254490"
  },
  {
    "text": "and then we are using the same prompt.",
    "start": "254490",
    "end": "256829"
  },
  {
    "text": "And in our body,",
    "start": "256830",
    "end": "257759"
  },
  {
    "text": "we can define some of the\nhyperparameters in Bedrock.",
    "start": "257760",
    "end": "261030"
  },
  {
    "text": "Invoke model, we'll copy the model ARN",
    "start": "261030",
    "end": "263260"
  },
  {
    "text": "from our Custom models.",
    "start": "264120",
    "end": "266160"
  },
  {
    "text": "Here's how we can find the\nmodel ARN and paste it over.",
    "start": "266160",
    "end": "269370"
  },
  {
    "text": "And this is a sample code of\nhow we can invoke the model",
    "start": "269370",
    "end": "272580"
  },
  {
    "text": "from a custom fine-tuning job.",
    "start": "272580",
    "end": "274503"
  },
  {
    "text": "And let's recap.",
    "start": "276060",
    "end": "277050"
  },
  {
    "text": "With a few clicks,",
    "start": "277050",
    "end": "277919"
  },
  {
    "text": "you can go from generic models",
    "start": "277920",
    "end": "279420"
  },
  {
    "text": "to ones that are\nspecialized and customized",
    "start": "279420",
    "end": "281640"
  },
  {
    "text": "using Amazon Bedrock.",
    "start": "281640",
    "end": "283410"
  },
  {
    "text": "We have imported the labeled\ntraining datasets into S3.",
    "start": "283410",
    "end": "286800"
  },
  {
    "text": "Created a fine-tuning\njob in Amazon Bedrock",
    "start": "286800",
    "end": "289590"
  },
  {
    "text": "that points to the S3 bucket",
    "start": "289590",
    "end": "291180"
  },
  {
    "text": "containing the training dataset.",
    "start": "291180",
    "end": "293220"
  },
  {
    "text": "Now, under the hood,",
    "start": "293220",
    "end": "294210"
  },
  {
    "text": "Bedrock makes a copy of this base model,",
    "start": "294210",
    "end": "296520"
  },
  {
    "text": "it trains it, and creates\na private fine-tuned model",
    "start": "296520",
    "end": "299340"
  },
  {
    "text": "so you can get tailored responses.",
    "start": "299340",
    "end": "301440"
  },
  {
    "text": "And this was the model ARN\nthat we copied earlier.",
    "start": "301440",
    "end": "304590"
  },
  {
    "text": "Security of our customer's\ndata and privacy is important,",
    "start": "304590",
    "end": "307980"
  },
  {
    "text": "and your data is kept within your VPC.",
    "start": "307980",
    "end": "310680"
  },
  {
    "text": "None of your inputs will be used",
    "start": "310680",
    "end": "312090"
  },
  {
    "text": "to train the original base model.",
    "start": "312090",
    "end": "314550"
  },
  {
    "text": "And with that, we have come\nto the end of this demo",
    "start": "314550",
    "end": "316919"
  },
  {
    "text": "for fine-tuning your foundation\nmodel on Amazon Bedrock.",
    "start": "316920",
    "end": "319803"
  }
]
[
  {
    "start": "0",
    "end": "85000"
  },
  {
    "text": "good afternoon everybody welcome to auto-scaling primetime how are you all",
    "start": "1040",
    "end": "7680"
  },
  {
    "text": "doing we're in the final few hours of reinvent are you hanging in there all right i'm tara van yunnan i'm the",
    "start": "7680",
    "end": "15719"
  },
  {
    "text": "product marketing manager for our automation and messaging services and i honestly didn't make it almost didn't",
    "start": "15719",
    "end": "22289"
  },
  {
    "text": "make it up here today on day two i entirely lost my voice and you can you",
    "start": "22289",
    "end": "28019"
  },
  {
    "text": "can still tell that it's trained and my body just doesn't respond so well to the",
    "start": "28019",
    "end": "35160"
  },
  {
    "text": "demands of reinvent and i expect that many of you are feeling the same way",
    "start": "35160",
    "end": "41840"
  },
  {
    "text": "so I've been thinking wouldn't it be great if we could Auto scale ourselves",
    "start": "41840",
    "end": "47640"
  },
  {
    "text": "like we auto scale our apps but we're",
    "start": "47640",
    "end": "52739"
  },
  {
    "text": "not nearly as elastic as the cloud and I don't have a solution to tell you for",
    "start": "52739",
    "end": "58649"
  },
  {
    "text": "self scaling but I do have a solution that can save you a lot of time and a",
    "start": "58649",
    "end": "64080"
  },
  {
    "text": "lot of effort when scaling your applications and my friend Vadim will be",
    "start": "64080",
    "end": "74010"
  },
  {
    "text": "coming up here in a bit to share how this solution is helping the engineering",
    "start": "74010",
    "end": "79200"
  },
  {
    "text": "team at Netflix to change the way they do scaling the session is all about",
    "start": "79200",
    "end": "86990"
  },
  {
    "start": "85000",
    "end": "85000"
  },
  {
    "text": "dynamic scaling and dynamic scaling is one of your most powerful tools to take advantage of the elasticity of the cloud",
    "start": "86990",
    "end": "93930"
  },
  {
    "text": "it allows you to scale your resources in and out in response to changing demands",
    "start": "93930",
    "end": "100009"
  },
  {
    "text": "here's a quick example of how it works here we have a couple of ec2 instances",
    "start": "100009",
    "end": "106560"
  },
  {
    "text": "in an auto scaling group behind an ELB and the metric that we want to scale in",
    "start": "106560",
    "end": "112950"
  },
  {
    "text": "and scale out on is our average CPU utilization because we've determined that this metric has an impact on the",
    "start": "112950",
    "end": "120810"
  },
  {
    "text": "performance of our app so as that CPU utilization starts to climb in response",
    "start": "120810",
    "end": "127020"
  },
  {
    "text": "to an increasing amount of traffic auto scaling will automatically spin",
    "start": "127020",
    "end": "134030"
  },
  {
    "text": "additional ec2 instances in order to bring that CPU to CPU utilization back",
    "start": "134030",
    "end": "140610"
  },
  {
    "text": "down to keep your performance in check and this provides two benefits first it",
    "start": "140610",
    "end": "147510"
  },
  {
    "text": "helps you to reduce cost because you're paying for capacity as you go as you",
    "start": "147510",
    "end": "154110"
  },
  {
    "text": "need it instead of provisioning for peak capacity up front and it also helps you",
    "start": "154110",
    "end": "159780"
  },
  {
    "text": "to improve the availability of your application because you're able to manage performance and our customers",
    "start": "159780",
    "end": "166470"
  },
  {
    "text": "that have horizontally scalable applications are using dynamic scaling extensively today",
    "start": "166470",
    "end": "172170"
  },
  {
    "text": "I mean amazon.com uses auto scaling to met handle the significant increases in",
    "start": "172170",
    "end": "179190"
  },
  {
    "text": "traffic that that come with the prime Day in Black Friday how many of you were",
    "start": "179190",
    "end": "184620"
  },
  {
    "text": "at the session yesterday the auto scaling session with NASA JPL and that",
    "start": "184620",
    "end": "190710"
  },
  {
    "text": "session they they showed how they're using dynamic scaling to scale the processing of data from their Earth",
    "start": "190710",
    "end": "197520"
  },
  {
    "text": "observing satellites in order to to improve the response times for the emergency teams on the ground following",
    "start": "197520",
    "end": "204750"
  },
  {
    "text": "hurricanes and earthquakes and volcanoes and of course Netflix uses auto scaling",
    "start": "204750",
    "end": "212720"
  },
  {
    "text": "to handle those those prime times for traffic like after the recent release of",
    "start": "212720",
    "end": "219480"
  },
  {
    "text": "season 2 of stranger things but as you",
    "start": "219480",
    "end": "225420"
  },
  {
    "text": "have seen from this week we constantly iterate and innovate on our services and",
    "start": "225420",
    "end": "231920"
  },
  {
    "text": "in order to do that we work backwards from our customers so about this time",
    "start": "231920",
    "end": "239010"
  },
  {
    "start": "235000",
    "end": "235000"
  },
  {
    "text": "last year we did a survey of auto scaling users like you to find out what",
    "start": "239010",
    "end": "246330"
  },
  {
    "text": "was working and what was wanted with auto scaling and here are the top picks",
    "start": "246330",
    "end": "254090"
  },
  {
    "text": "the first pick is all about speed customers tell us they want a super",
    "start": "254090",
    "end": "261090"
  },
  {
    "text": "simple way to set up scaling policies they also tell us they want us to bring",
    "start": "261090",
    "end": "267620"
  },
  {
    "text": "auto-scaling to more AWS services they want to be able to to supersize a wider",
    "start": "267620",
    "end": "276680"
  },
  {
    "text": "range of resources and lastly they tell us that they want to become masters of",
    "start": "276680",
    "end": "284240"
  },
  {
    "text": "metrics meaning they want us to provide guidance and tools and techniques that",
    "start": "284240",
    "end": "291710"
  },
  {
    "text": "help them understand what metrics to use when and what value so I'm gonna show",
    "start": "291710",
    "end": "299180"
  },
  {
    "text": "you what we've done to live to deliver speedy setup and more services for for",
    "start": "299180",
    "end": "307220"
  },
  {
    "text": "auto scaling and Vadim is going to share with you some tips that they've learned",
    "start": "307220",
    "end": "314990"
  },
  {
    "text": "at Netflix for mastering metrics sound good good",
    "start": "314990",
    "end": "320770"
  },
  {
    "text": "so since speed is speed is relative right so let's look at the step scaling",
    "start": "320770",
    "end": "328100"
  },
  {
    "start": "322000",
    "end": "322000"
  },
  {
    "text": "policies that most of our customers have been using for the last few years with",
    "start": "328100",
    "end": "334400"
  },
  {
    "text": "step scaling you pick a metric you want to scale on and then you set a number of",
    "start": "334400",
    "end": "340880"
  },
  {
    "text": "scaling adjustments for that metric you're accountable for determining how",
    "start": "340880",
    "end": "348200"
  },
  {
    "text": "many instances to add or remove at different thresholds for that metric so",
    "start": "348200",
    "end": "355070"
  },
  {
    "text": "it gives you a lot of control over your scaling adjustments but it also gives",
    "start": "355070",
    "end": "361190"
  },
  {
    "text": "you full ownership over all your scaling adjustments and some of our customers",
    "start": "361190",
    "end": "366770"
  },
  {
    "text": "they want that ownership they want the ability to set really granular scaling",
    "start": "366770",
    "end": "372710"
  },
  {
    "text": "behaviors and do all the fine-tuning themselves but as you saw from our survey many of our customers just want",
    "start": "372710",
    "end": "381080"
  },
  {
    "text": "to set the metric and be done with it which is why earlier this year we",
    "start": "381080",
    "end": "389240"
  },
  {
    "text": "launched target tracking and I like to call target tracking the upside down of",
    "start": "389240",
    "end": "396890"
  },
  {
    "text": "step scaling because with target tracking you don't",
    "start": "396890",
    "end": "401950"
  },
  {
    "text": "have to take care you don't have to worry about a single scaling adjustment that's under the hood it works a lot",
    "start": "401950",
    "end": "409750"
  },
  {
    "text": "like a home thermostat but in this case instead of setting the temperature you're setting a target value for a",
    "start": "409750",
    "end": "417940"
  },
  {
    "text": "metric that you want to keep so you just set the metric and target tracking",
    "start": "417940",
    "end": "425010"
  },
  {
    "text": "calculates how many instances to add and remove from your auto scaling group in",
    "start": "425010",
    "end": "430060"
  },
  {
    "text": "order to maintain that metric so you just set it and forget it",
    "start": "430060",
    "end": "436979"
  },
  {
    "text": "look at how easy this is three clicks setting up this scaling",
    "start": "437040",
    "end": "445030"
  },
  {
    "start": "440000",
    "end": "440000"
  },
  {
    "text": "policy you name your policy you select your metric and you set your target and",
    "start": "445030",
    "end": "452490"
  },
  {
    "text": "target tracking is self optimizing I mean there's an algorithm of algorithm",
    "start": "452490",
    "end": "458230"
  },
  {
    "text": "that measures how that metric is changing over time and this allows you",
    "start": "458230",
    "end": "463960"
  },
  {
    "text": "to minimize both over scaling and under scaling as well as any oscillations and",
    "start": "463960",
    "end": "469950"
  },
  {
    "text": "it also gives you the fastest scaling response time because it's constantly",
    "start": "469950",
    "end": "476050"
  },
  {
    "text": "calculating how many instances to add or remove may stop based on the difference",
    "start": "476050",
    "end": "481240"
  },
  {
    "text": "in the value the actual value of that metric versus the target let's take a",
    "start": "481240",
    "end": "488620"
  },
  {
    "start": "488000",
    "end": "488000"
  },
  {
    "text": "look at how this works in a scaling out example so once we have ec2 instances in",
    "start": "488620",
    "end": "497020"
  },
  {
    "text": "an auto scaling group behind our ELB and for this application the metric we've",
    "start": "497020",
    "end": "504070"
  },
  {
    "text": "chosen to scale on is CPU utilization and we've set our target to 50% as you",
    "start": "504070",
    "end": "510100"
  },
  {
    "text": "see in the gold dashed line and at the",
    "start": "510100",
    "end": "516340"
  },
  {
    "text": "current level of traffic those 10 ec2 instances are able to maintain that",
    "start": "516340",
    "end": "522820"
  },
  {
    "text": "target CPU but as you increase traffic to the ELB and that in turn increases",
    "start": "522820",
    "end": "530020"
  },
  {
    "text": "traffic to the instances your CPU utilization starts to climb so",
    "start": "530020",
    "end": "537010"
  },
  {
    "text": "target tracking will do all the calculations to determine how many ec2 instances to add to that auto scaling",
    "start": "537010",
    "end": "543820"
  },
  {
    "text": "group to bring that CPU back to the target of 50% and in this case it adds",
    "start": "543820",
    "end": "550270"
  },
  {
    "text": "five and then you brings your traffic and your CPU in a manageable in a matte",
    "start": "550270",
    "end": "559300"
  },
  {
    "text": "in a matte and in a condition that can manage the performance of your application I want to show you how this",
    "start": "559300",
    "end": "567580"
  },
  {
    "start": "566000",
    "end": "566000"
  },
  {
    "text": "works in an actual demo so we have set up a typical web application typical",
    "start": "567580",
    "end": "573610"
  },
  {
    "text": "three-tier web application at the top layer we have our application load",
    "start": "573610",
    "end": "578740"
  },
  {
    "text": "balancer that manages the incoming traffic and then distributes that traffic to the ec2 fleets within an auto",
    "start": "578740",
    "end": "586000"
  },
  {
    "text": "scaling group at the compute layer and auto scaling automatically balances your",
    "start": "586000",
    "end": "593260"
  },
  {
    "text": "ec2 instances across a ZZZ for fault tolerance and high availability and then",
    "start": "593260",
    "end": "600520"
  },
  {
    "text": "the application uses dynamo DB at the data layer so for the demo I'm going to",
    "start": "600520",
    "end": "607330"
  },
  {
    "text": "show you we've set our target tracking scaling policy at the compute layer so",
    "start": "607330",
    "end": "613270"
  },
  {
    "text": "that it adds and removes ec2 instances as a traffic changes but you could also",
    "start": "613270",
    "end": "620220"
  },
  {
    "text": "set target tracking scaling policies at the data layer for DynamoDB tables so",
    "start": "620220",
    "end": "626860"
  },
  {
    "text": "that it adds or removes provisioned capacity as the traffic changes and I",
    "start": "626860",
    "end": "636330"
  },
  {
    "text": "pre-recorded this demo because like my voice I can't rely on Wi-Fi and also",
    "start": "636330",
    "end": "644680"
  },
  {
    "text": "because we wanted to make this available to you on our website for reference after reinvent so we're gonna start in",
    "start": "644680",
    "end": "654190"
  },
  {
    "text": "our ec2 console from here we're going to go into our auto scaling groups",
    "start": "654190",
    "end": "662860"
  },
  {
    "text": "and as you can see we already have an auto scaling group set up and we have",
    "start": "662860",
    "end": "672260"
  },
  {
    "text": "attached in the D in the details tab you can see we've attached a target group",
    "start": "672260",
    "end": "677300"
  },
  {
    "text": "now target groups are a concept with application load balancers target groups",
    "start": "677300",
    "end": "682880"
  },
  {
    "text": "listen to the application low bouncers that as it receives the traffic and it's what allows us to route the requests",
    "start": "682880",
    "end": "691220"
  },
  {
    "text": "from that application load balancer to our ASG and I'm showing you this because",
    "start": "691220",
    "end": "697750"
  },
  {
    "text": "when I go into the scaling policy setup you're gonna see that that try out",
    "start": "697750",
    "end": "704660"
  },
  {
    "text": "target tracking demo for the target group is automatically populated so let's add our policy we're gonna give it",
    "start": "704660",
    "end": "712940"
  },
  {
    "text": "a name I chose the name Mad Max and you can see that there's a number of of",
    "start": "712940",
    "end": "720070"
  },
  {
    "text": "predefined metrics to choose from you can also omit your own custom metric and",
    "start": "720070",
    "end": "726980"
  },
  {
    "text": "then pick that from the SDK or the CLI and the metric that we're going to use",
    "start": "726980",
    "end": "735730"
  },
  {
    "text": "to scale our sample app is the application load balancer request count",
    "start": "735730",
    "end": "743210"
  },
  {
    "text": "per target and it is in this example the target is simply an ec2 instance and the",
    "start": "743210",
    "end": "751820"
  },
  {
    "text": "reason we've selected this metric is because it directly correlates with the",
    "start": "751820",
    "end": "757340"
  },
  {
    "text": "incoming traffic to our app and as I said you can see that the target value",
    "start": "757340",
    "end": "764230"
  },
  {
    "text": "that you saw in the details tab is automatically pre-populated and I've set",
    "start": "764230",
    "end": "770990"
  },
  {
    "text": "my target value here to a thousand request counts per minute for ec2",
    "start": "770990",
    "end": "776690"
  },
  {
    "text": "instance because we've already done some load testing and we see that at about",
    "start": "776690",
    "end": "783020"
  },
  {
    "text": "1100 requests counts our ec2 instances start to run a bit hot so I'm setting",
    "start": "783020",
    "end": "789410"
  },
  {
    "text": "this here at a thousand to give me a bed of headroom so I said that I hit create and boom we",
    "start": "789410",
    "end": "801660"
  },
  {
    "text": "have our Mad Max auto scaling policy set up but now I want to see how auto",
    "start": "801660",
    "end": "810390"
  },
  {
    "text": "scaling behaves when it handles traffic for a 24-hour period so I'm gonna go",
    "start": "810390",
    "end": "817230"
  },
  {
    "text": "into cloud watch to take a look at the scaling adjustments as the traffic ramps",
    "start": "817230",
    "end": "824820"
  },
  {
    "text": "up and ramps down as we expected to do through the course of a day and there's",
    "start": "824820",
    "end": "830130"
  },
  {
    "text": "two graphs that I that I want to show you with a couple key takeaways this first graph shows you that target",
    "start": "830130",
    "end": "840450"
  },
  {
    "text": "tracking allows you to follow the traffic extremely closely as you can see",
    "start": "840450",
    "end": "846750"
  },
  {
    "text": "here the Gold Line which is our ASG size is tracking with the traffic throughout",
    "start": "846750",
    "end": "855390"
  },
  {
    "text": "the day very closely so it's doing all the scaling adjustments for you and it's",
    "start": "855390",
    "end": "861420"
  },
  {
    "text": "scaling very quickly but the the science behind this scaling behavior is really",
    "start": "861420",
    "end": "870000"
  },
  {
    "text": "evidenced in the next graph because the next graph shows you that the auto",
    "start": "870000",
    "end": "881010"
  },
  {
    "text": "scaling group size is actually being dictated by our target metric if you",
    "start": "881010",
    "end": "891120"
  },
  {
    "text": "look here target tracking will always keep will always add and remove",
    "start": "891120",
    "end": "897000"
  },
  {
    "text": "instances to keep you as close as possible to your target value in this",
    "start": "897000",
    "end": "903420"
  },
  {
    "text": "case 1000 requests counts per minute so it does all of the calculations to",
    "start": "903420",
    "end": "909810"
  },
  {
    "text": "determine how many instances to add or remove so it's giving you the right",
    "start": "909810",
    "end": "914910"
  },
  {
    "text": "scaling adjustments to maintain that target so your application is able to",
    "start": "914910",
    "end": "922320"
  },
  {
    "text": "get the capacity that it needs to handle the the changing traffic without you having to make a single",
    "start": "922320",
    "end": "930010"
  },
  {
    "text": "scaling adjustment yourself and that's",
    "start": "930010",
    "end": "935560"
  },
  {
    "text": "why many of our customers really like target tracking it allows them to not",
    "start": "935560",
    "end": "944950"
  },
  {
    "text": "only have speedy setup but also speedy",
    "start": "944950",
    "end": "949960"
  },
  {
    "text": "scaling which is why when we brought",
    "start": "949960",
    "end": "955780"
  },
  {
    "text": "auto scaling to more services this year they came out the gate with target",
    "start": "955780",
    "end": "962980"
  },
  {
    "start": "956000",
    "end": "956000"
  },
  {
    "text": "tracking policies right away in fact DynamoDB audits are auto scaling for",
    "start": "962980",
    "end": "969490"
  },
  {
    "text": "DynamoDB which we launched in June was the very first AWS service to come out",
    "start": "969490",
    "end": "976150"
  },
  {
    "text": "with target tracking scaling policies and with dynamo DB DB said of scaling on",
    "start": "976150",
    "end": "983440"
  },
  {
    "text": "ec2 instances your scaling on read and write I ops and just before reinvent you",
    "start": "983440",
    "end": "989980"
  },
  {
    "text": "might have you might have seen that we announced auto scaling for Aurora incidentally that's the fastest growing",
    "start": "989980",
    "end": "997210"
  },
  {
    "text": "AWS service ever so you can auto scale a",
    "start": "997210",
    "end": "1004290"
  },
  {
    "text": "number of AWS services the resources that you scale on will differ and as",
    "start": "1004290",
    "end": "1012750"
  },
  {
    "text": "well as the metrics but this gives you a lot of advantages especially that we're",
    "start": "1012750",
    "end": "1019260"
  },
  {
    "text": "bringing target tracking to the rest of these services over time and I want to",
    "start": "1019260",
    "end": "1026550"
  },
  {
    "text": "now invite a deem to the stage so now you can talk about how Netflix has been",
    "start": "1026550",
    "end": "1034170"
  },
  {
    "text": "using target tracking in practice",
    "start": "1034170",
    "end": "1038870"
  },
  {
    "text": "[Applause] Thank You Tara thank you good afternoon everyone what",
    "start": "1041160",
    "end": "1053470"
  },
  {
    "text": "the show begin what it begin this is",
    "start": "1053470",
    "end": "1061480"
  },
  {
    "text": "Vancouver British Columbia that's where yes that's where it R is",
    "start": "1061480",
    "end": "1067570"
  },
  {
    "text": "from that's where auto-scale and team is located and that's where target tracking has been developed beautiful city I've",
    "start": "1067570",
    "end": "1076060"
  },
  {
    "text": "been there once hope to visit one more time this is Seattle even if I didn't",
    "start": "1076060",
    "end": "1083710"
  },
  {
    "text": "put a caption on this skyline it's easy to recognize the Space Needle dominates",
    "start": "1083710",
    "end": "1090970"
  },
  {
    "text": "the skyline Seattle is also headquarters of Amazon this is what a misconfigured",
    "start": "1090970",
    "end": "1102790"
  },
  {
    "text": "auto-scaling could look like my name is Vadim Villeneuve ski I'm a performance",
    "start": "1102790",
    "end": "1109000"
  },
  {
    "text": "and reliability engineer at Netflix and in this presentation I'll show you how",
    "start": "1109000",
    "end": "1114070"
  },
  {
    "text": "Netflix makes our auto scale and look less like this and more like this this",
    "start": "1114070",
    "end": "1121510"
  },
  {
    "text": "is the same as G with roughly the same traffic the next day one we fixed Auto",
    "start": "1121510",
    "end": "1126970"
  },
  {
    "text": "scale and polishes but first let's talk",
    "start": "1126970",
    "end": "1132430"
  },
  {
    "text": "about the need for Auto scale in certainly it takes some effort and some",
    "start": "1132430",
    "end": "1139050"
  },
  {
    "text": "time and sometimes a little bit of trial and error to set up Auto scale and",
    "start": "1139050",
    "end": "1145420"
  },
  {
    "text": "policies why is it worth for us let me",
    "start": "1145420",
    "end": "1150970"
  },
  {
    "text": "show you take a look at this two steals these are stills from the Iron Fist a",
    "start": "1150970",
    "end": "1158170"
  },
  {
    "text": "Netflix original if you don't see differences between these two images",
    "start": "1158170",
    "end": "1165100"
  },
  {
    "text": "your eyes do not deceive you these two images are meant to look",
    "start": "1165100",
    "end": "1172020"
  },
  {
    "text": "the same even though these are two distinct images and here's the",
    "start": "1172020",
    "end": "1178710"
  },
  {
    "text": "difference one of these video streams was encoded at 556 kilobits per second",
    "start": "1178710",
    "end": "1186380"
  },
  {
    "text": "another one at only 277 kilobit per second",
    "start": "1186380",
    "end": "1192320"
  },
  {
    "text": "Netflix employs something that we call perceptually optimal video encoding to",
    "start": "1192320",
    "end": "1198090"
  },
  {
    "text": "encode our content and reduce the bit rate without perceived loss in quality",
    "start": "1198090",
    "end": "1205970"
  },
  {
    "text": "as you can imagine we need a lot of compute power to run this encode across",
    "start": "1205970",
    "end": "1213030"
  },
  {
    "text": "our ever-growing catalogue where does it come from take a look at this graph the",
    "start": "1213030",
    "end": "1221580"
  },
  {
    "start": "1219000",
    "end": "1219000"
  },
  {
    "text": "blue area at the bottom represents our normal ec2 usage it's actually it's only",
    "start": "1221580",
    "end": "1230370"
  },
  {
    "text": "a slice of it for a particular instance type for a particular region you can see",
    "start": "1230370",
    "end": "1235760"
  },
  {
    "text": "peaks and troughs obviously around 7 8 p.m. a lot of people watched Netflix at",
    "start": "1235760",
    "end": "1243030"
  },
  {
    "text": "2:00 or 3:00 a.m. only hardcore fans watch Netflix so our easy to usage goes",
    "start": "1243030",
    "end": "1250020"
  },
  {
    "text": "down with a need as much capacity to support the view in Netflix runs almost",
    "start": "1250020",
    "end": "1255750"
  },
  {
    "text": "entirely on reserved instances what do we do with those instances during",
    "start": "1255750",
    "end": "1262200"
  },
  {
    "text": "off-peak hours we use them for encoding we build a pipeline that allows us to",
    "start": "1262200",
    "end": "1269700"
  },
  {
    "text": "use those instances and auto scaling enables us to reuse this capacity for",
    "start": "1269700",
    "end": "1275850"
  },
  {
    "text": "encoding and that's the the yellow graph on the top another use case",
    "start": "1275850",
    "end": "1283640"
  },
  {
    "start": "1283000",
    "end": "1283000"
  },
  {
    "text": "recommendations as Netflix expands to more countries as Netflix adds more",
    "start": "1283640",
    "end": "1290220"
  },
  {
    "text": "content more languages we need better recommendation algorithms better",
    "start": "1290220",
    "end": "1297900"
  },
  {
    "text": "recommendations algorithms sometimes require more capacity to run especially",
    "start": "1297900",
    "end": "1303690"
  },
  {
    "text": "as our customer base keeps growing the bulk of it runs during off-peak hours and we",
    "start": "1303690",
    "end": "1312100"
  },
  {
    "text": "reuse the capacity that we do not use for streaming there's a few other",
    "start": "1312100",
    "end": "1317770"
  },
  {
    "text": "benefits of auto scaling red-black pushes the industry standard",
    "start": "1317770",
    "end": "1324309"
  },
  {
    "start": "1318000",
    "end": "1318000"
  },
  {
    "text": "name for this is blue green but I'll stick with Netflix term we call it red",
    "start": "1324309",
    "end": "1329830"
  },
  {
    "text": "black pushes Netflix infrastructure is immutable which means that would bacon",
    "start": "1329830",
    "end": "1336520"
  },
  {
    "text": "ami we deploy it we never patch those instances when the new version of the",
    "start": "1336520",
    "end": "1342280"
  },
  {
    "text": "code is ready we set up a new ASG with the new ami switch the traffic then we",
    "start": "1342280",
    "end": "1350350"
  },
  {
    "text": "remove the old SG imagine if we provisioned every ASG for peak doing red",
    "start": "1350350",
    "end": "1359049"
  },
  {
    "text": "black pushes would be pretty expensive because we would have to double up our",
    "start": "1359049",
    "end": "1364660"
  },
  {
    "text": "capacity auto scaling allows us to reduce the cost of red black pushes",
    "start": "1364660",
    "end": "1371380"
  },
  {
    "text": "because usually we push in the morning hours when is G are at half or maybe",
    "start": "1371380",
    "end": "1377290"
  },
  {
    "text": "even at less than half of their capacity regional failover it's an interesting",
    "start": "1377290",
    "end": "1383890"
  },
  {
    "text": "use case you see a picture of cond because this is internal name for",
    "start": "1383890",
    "end": "1389260"
  },
  {
    "text": "regional failover for the system that does regional fail overs Netflix operates in three regions we have the",
    "start": "1389260",
    "end": "1396760"
  },
  {
    "text": "ability to fail out of any single region and serve our customers all our traffic",
    "start": "1396760",
    "end": "1404620"
  },
  {
    "text": "from the remaining two regions now how auto scaling helps with that if",
    "start": "1404620",
    "end": "1411250"
  },
  {
    "text": "you think about this for example Virginia versus Ireland we see the time",
    "start": "1411250",
    "end": "1418510"
  },
  {
    "text": "shift in peaks between these two regions about seven eight hours so one will fail",
    "start": "1418510",
    "end": "1425230"
  },
  {
    "text": "traffic out of Virginia the bulk of it goes to Ireland we don't have to",
    "start": "1425230",
    "end": "1431320"
  },
  {
    "text": "provision Ireland for the peak of Peaks we have to provision it only to hold the",
    "start": "1431320",
    "end": "1437760"
  },
  {
    "text": "local teak it's like adding two sine waves that are shifted it's not doubling",
    "start": "1437760",
    "end": "1443790"
  },
  {
    "text": "up it's much less than that and lastly it's an interesting use case I wanted to",
    "start": "1443790",
    "end": "1450240"
  },
  {
    "text": "call it out it's a hack day project that's not something that we usually do",
    "start": "1450240",
    "end": "1456030"
  },
  {
    "text": "but it illustrates the power of dynamic scale in folding at home as a stanford",
    "start": "1456030",
    "end": "1462360"
  },
  {
    "text": "project folding proteins find and cure for cancer unfortunately it's not there",
    "start": "1462360",
    "end": "1467700"
  },
  {
    "text": "yet but hopefully one day as a part of hack day project one of our engineers",
    "start": "1467700",
    "end": "1474440"
  },
  {
    "text": "joined some of our off-peak capacity to fold in at home and helped curing cancer",
    "start": "1474440",
    "end": "1484310"
  },
  {
    "text": "lastly I want to call out that auto scaling is not a random scale in a lot",
    "start": "1484370",
    "end": "1493590"
  },
  {
    "text": "of times I hear comments from from folks sometimes teams internal and Netflix",
    "start": "1493590",
    "end": "1500130"
  },
  {
    "text": "sometimes folks outside of Netflix the concern is what does auto scale and do",
    "start": "1500130",
    "end": "1505410"
  },
  {
    "text": "to my ASG will I have enough capacity will I have too much and end up paying",
    "start": "1505410",
    "end": "1511740"
  },
  {
    "text": "extra whoo it seems like some kind of black box that desert randomly or",
    "start": "1511740",
    "end": "1517380"
  },
  {
    "text": "magically no auto scaling has a very",
    "start": "1517380",
    "end": "1524010"
  },
  {
    "text": "well-defined set of rules and if you're understand your performance band your",
    "start": "1524010",
    "end": "1530220"
  },
  {
    "text": "performance characteristics and if you understand your traffic patterns then",
    "start": "1530220",
    "end": "1535650"
  },
  {
    "text": "you can set up auto scaling rules so that auto scaling always keeps you in",
    "start": "1535650",
    "end": "1541860"
  },
  {
    "text": "this performance band and saves your cost let's get to setting up auto",
    "start": "1541860",
    "end": "1551310"
  },
  {
    "text": "scaling and the first question you will have to answer is which metric to scale",
    "start": "1551310",
    "end": "1557580"
  },
  {
    "text": "on Tara mentioned it in her presentation that this was one of the feedbacks from",
    "start": "1557580",
    "end": "1564330"
  },
  {
    "text": "the customers easy metric setup how do we choose our metrics I can totally",
    "start": "1564330",
    "end": "1571350"
  },
  {
    "text": "relate to this because I get these questions all the time that's how it goes the guy",
    "start": "1571350",
    "end": "1578530"
  },
  {
    "start": "1576000",
    "end": "1576000"
  },
  {
    "text": "on the right is me the guy on the left is a service owners and the question is",
    "start": "1578530",
    "end": "1583900"
  },
  {
    "text": "which metric should I scale on and the answer is you should scale on something",
    "start": "1583900",
    "end": "1589990"
  },
  {
    "text": "that shows how busy your instance is that changes proportionately with the",
    "start": "1589990",
    "end": "1596260"
  },
  {
    "text": "size of your ASG in my experience this",
    "start": "1596260",
    "end": "1601780"
  },
  {
    "text": "answer well actually doesn't answer the question because usually what happens service owners say okay let me explain",
    "start": "1601780",
    "end": "1609280"
  },
  {
    "text": "what my service does here it does ABC L to Z and by the way it's a very",
    "start": "1609280",
    "end": "1615790"
  },
  {
    "text": "important service now you tell me which metric to scale on okay I got it here",
    "start": "1615790",
    "end": "1622830"
  },
  {
    "start": "1622000",
    "end": "1622000"
  },
  {
    "text": "which metric explained there is too general buckets throughput and resource",
    "start": "1622830",
    "end": "1630820"
  },
  {
    "text": "utilization throughput measures how much work is being done resource utilization",
    "start": "1630820",
    "end": "1638790"
  },
  {
    "text": "measures wall house-trained is your resource it's very easy to relate to",
    "start": "1638790",
    "end": "1644320"
  },
  {
    "text": "this imagine you're running marathon your throughput is how many miles you",
    "start": "1644320",
    "end": "1649480"
  },
  {
    "text": "ran and your resource utilization is say your heartbeat because that could be a",
    "start": "1649480",
    "end": "1655660"
  },
  {
    "text": "proxy for how tired you are AWS provides",
    "start": "1655660",
    "end": "1661570"
  },
  {
    "text": "a few metrics by default request count per target I believe that's the metric",
    "start": "1661570",
    "end": "1668350"
  },
  {
    "text": "they are used for her demo it's a great metric it shows how many requests per instance alb is processing CPU",
    "start": "1668350",
    "end": "1677740"
  },
  {
    "text": "utilization again it's available by default good metric to scale on both of",
    "start": "1677740",
    "end": "1685540"
  },
  {
    "text": "these metrics both of these classes of metrics have pros and cons the pro of",
    "start": "1685540",
    "end": "1690990"
  },
  {
    "text": "throughput is that it's very very intuitive it's a direct measure of your",
    "start": "1690990",
    "end": "1696760"
  },
  {
    "text": "work usually if your request request mixes homogeneous it's a great metric to",
    "start": "1696760",
    "end": "1703990"
  },
  {
    "text": "scale on it's also intuitive in a sense that if let's say you know your total expected",
    "start": "1703990",
    "end": "1710360"
  },
  {
    "text": "throughput per ASG and you know your target you can divide one by another and",
    "start": "1710360",
    "end": "1716029"
  },
  {
    "text": "arrive to the number of instances you can sum up throughput for each individual instance and arrive to the",
    "start": "1716029",
    "end": "1723230"
  },
  {
    "text": "total throughput of ASG very intuitive cons it done to drift over time",
    "start": "1723230",
    "end": "1730340"
  },
  {
    "text": "obviously as we push out new version of our code as we add more features usually",
    "start": "1730340",
    "end": "1738309"
  },
  {
    "text": "it's not it's not uncommon that request becomes heavier and we need to adjust",
    "start": "1738309",
    "end": "1744679"
  },
  {
    "text": "our target CPU utilization is a little bit more forgiving in this sense it's",
    "start": "1744679",
    "end": "1752119"
  },
  {
    "text": "from zero to hundred you can always say scale and fifty percent even if your",
    "start": "1752119",
    "end": "1757789"
  },
  {
    "text": "request becomes heavier as you will still keep you at 50 percent CPU utilization probably at the cost of",
    "start": "1757789",
    "end": "1764450"
  },
  {
    "text": "extra capacity but you can do it something it's prone to drift as well in",
    "start": "1764450",
    "end": "1772700"
  },
  {
    "text": "a sense that if the older version of code was able to operate normally at 50",
    "start": "1772700",
    "end": "1778580"
  },
  {
    "text": "percent CPU utilization the new version of quad code might not be able to do",
    "start": "1778580",
    "end": "1783710"
  },
  {
    "text": "this you always have to watch the targets in our experience we notice that",
    "start": "1783710",
    "end": "1791119"
  },
  {
    "text": "CPU utilization have slightly more oscillation and jitter again if you run",
    "start": "1791119",
    "end": "1797690"
  },
  {
    "text": "maybe some kind of periodic tasks refreshes on your ASG that can affect your CPU utilization that can push it a",
    "start": "1797690",
    "end": "1804919"
  },
  {
    "text": "little bit higher but your mileage may vary one more thing I wanted to call out",
    "start": "1804919",
    "end": "1811460"
  },
  {
    "text": "about throughput is that depending on how you measure your true put you can",
    "start": "1811460",
    "end": "1818809"
  },
  {
    "text": "get different results let me give you an example let's say we have a service that",
    "start": "1818809",
    "end": "1824830"
  },
  {
    "text": "watermarks documents you pause the document service processes it watermarks",
    "start": "1824830",
    "end": "1831679"
  },
  {
    "text": "every page and spits it out what is my",
    "start": "1831679",
    "end": "1837169"
  },
  {
    "text": "true put if you measure put in requests per second or documents",
    "start": "1837169",
    "end": "1842500"
  },
  {
    "text": "per second that might not be the best metric for the work you are doing",
    "start": "1842500",
    "end": "1847710"
  },
  {
    "text": "because each document is different one document can have three pages another",
    "start": "1847710",
    "end": "1854160"
  },
  {
    "text": "123 pages however if you express it in pages per second then you equalize your",
    "start": "1854160",
    "end": "1861730"
  },
  {
    "text": "unit of work and now it's a more precise throughput metric and it's more suitable",
    "start": "1861730",
    "end": "1867910"
  },
  {
    "text": "for scaling skeletal multiple metrics is",
    "start": "1867910",
    "end": "1874059"
  },
  {
    "start": "1872000",
    "end": "1872000"
  },
  {
    "text": "something that is very very tempting to do it's certainly possible to do this",
    "start": "1874059",
    "end": "1880750"
  },
  {
    "text": "it's fully supported by AWS you can set",
    "start": "1880750",
    "end": "1886600"
  },
  {
    "text": "it up the issue becomes it gets harder",
    "start": "1886600",
    "end": "1892270"
  },
  {
    "text": "to reason about scale and behavior it gets also a little bit harder to control",
    "start": "1892270",
    "end": "1897730"
  },
  {
    "text": "the metrics because you can run into situations when different metrics point",
    "start": "1897730",
    "end": "1902770"
  },
  {
    "text": "into different directions and auto-scaling might start oscillating at Netflix we",
    "start": "1902770",
    "end": "1911320"
  },
  {
    "text": "follow this typical set up normal scale up and scale down on throughput requests",
    "start": "1911320",
    "end": "1917230"
  },
  {
    "text": "per second emergency scale up on CPU we call it the hammer rule if something god forbid",
    "start": "1917230",
    "end": "1923950"
  },
  {
    "text": "happens we have a spike in traffic or for whatever reason CPU spikes up drop",
    "start": "1923950",
    "end": "1929679"
  },
  {
    "text": "the hammer scale up survive this the surge when I say normal scale up and",
    "start": "1929679",
    "end": "1937030"
  },
  {
    "text": "scale down four-step policies these are two separate policies for target",
    "start": "1937030",
    "end": "1942400"
  },
  {
    "text": "tracking obviously it's a single policy that controls both scale up and scale down next is setting the target now that",
    "start": "1942400",
    "end": "1952780"
  },
  {
    "text": "we know our metric we need to set the target this is probably the most influential decision you will make for",
    "start": "1952780",
    "end": "1960070"
  },
  {
    "text": "your ASG how do we set up the target",
    "start": "1960070",
    "end": "1966149"
  },
  {
    "start": "1966000",
    "end": "1966000"
  },
  {
    "text": "there is plenty of tools available to generate traffic well Karl is not",
    "start": "1966300",
    "end": "1975110"
  },
  {
    "text": "entirely a performance dusting tool but if you want to generate three requests per second why not",
    "start": "1975110",
    "end": "1980870"
  },
  {
    "text": "I've seen people doing this there is a lot of tool that can generate synthetic",
    "start": "1980870",
    "end": "1987140"
  },
  {
    "text": "load there is a lot of tool that can generate that can capture and replay the",
    "start": "1987140",
    "end": "1992840"
  },
  {
    "text": "traffic there is a lot of open source solution there is a lot of commercial",
    "start": "1992840",
    "end": "1998120"
  },
  {
    "text": "solutions for that and they're all great and they solve certain aspects of this",
    "start": "1998120",
    "end": "2004840"
  },
  {
    "text": "problem what they doesn't solve is even if you start replaying traffic you need",
    "start": "2004840",
    "end": "2012430"
  },
  {
    "text": "to make sure that the traffic you captured and prod and replay ninh your test or dev environment it hits the same",
    "start": "2012430",
    "end": "2019720"
  },
  {
    "text": "data set keeping environments in sync",
    "start": "2019720",
    "end": "2025170"
  },
  {
    "text": "quickly becomes a nightmare Netflix answer runs quiz tests in",
    "start": "2025170",
    "end": "2034590"
  },
  {
    "text": "production with a live production traffic here's how this is an example of",
    "start": "2034590",
    "end": "2045460"
  },
  {
    "start": "2043000",
    "end": "2043000"
  },
  {
    "text": "mid-tier service we have a server ASG with a certain ami we have client aSG's",
    "start": "2045460",
    "end": "2051399"
  },
  {
    "text": "Sundin traffic to the server we cloned our server ASG with a single instance",
    "start": "2051400",
    "end": "2060639"
  },
  {
    "text": "that will that would be our target squeeze SG we also spin up an instance",
    "start": "2060640",
    "end": "2068350"
  },
  {
    "text": "of a proxy then we start diverting traffic from our clients to the proxy",
    "start": "2068350",
    "end": "2076950"
  },
  {
    "text": "proxy splits the traffic it measures the exact throughput to the squeeze SG the",
    "start": "2076950",
    "end": "2085060"
  },
  {
    "text": "rest of the traffic the excess goes back to the server SG and control throughput",
    "start": "2085060",
    "end": "2094090"
  },
  {
    "text": "this is our measure this is our result of our squeeze we can use it as our",
    "start": "2094090",
    "end": "2100060"
  },
  {
    "text": "target this approach allows us to use our live",
    "start": "2100060",
    "end": "2106450"
  },
  {
    "text": "production traffic which is the exact traffic that we will get in real in real",
    "start": "2106450",
    "end": "2112930"
  },
  {
    "text": "usage scenarios and this would also allow us to minimize the blast radius we",
    "start": "2112930",
    "end": "2118570"
  },
  {
    "text": "do not squeeze the whole ASG we squeeze only a single instance and we have",
    "start": "2118570",
    "end": "2124030"
  },
  {
    "text": "mechanisms such as retries to to recover if there is any failures during the",
    "start": "2124030",
    "end": "2131470"
  },
  {
    "text": "squeeze test speaking of failures in my opinion it's",
    "start": "2131470",
    "end": "2138900"
  },
  {
    "start": "2135000",
    "end": "2135000"
  },
  {
    "text": "extremely important to understand your failures I know nobody likes to think",
    "start": "2138900",
    "end": "2146770"
  },
  {
    "text": "about it nobody likes to talk about it but there's a performance and reliability engineer I deal with",
    "start": "2146770",
    "end": "2153609"
  },
  {
    "text": "failures day in and day out so here's an example of two services service on the",
    "start": "2153609",
    "end": "2160840"
  },
  {
    "text": "Left can ramp up the throughput from roughly hundred to maybe hundred eighty",
    "start": "2160840",
    "end": "2166950"
  },
  {
    "text": "requests per second CPU utilization goes from 40 to 80% latency almost doubles",
    "start": "2166950",
    "end": "2175300"
  },
  {
    "text": "from about 30 milliseconds to 58 60 but",
    "start": "2175300",
    "end": "2181270"
  },
  {
    "text": "the service still able to process all incoming requests it's all good the",
    "start": "2181270",
    "end": "2187570"
  },
  {
    "text": "service on the right have our have a very distinct break and point at some",
    "start": "2187570",
    "end": "2193990"
  },
  {
    "text": "point even though our CPU utilization is relatively low the server falls off the",
    "start": "2193990",
    "end": "2201040"
  },
  {
    "text": "cliff latency shoots up to the point that I have to use logarithmic scale to",
    "start": "2201040",
    "end": "2206650"
  },
  {
    "text": "plot this graph it goes from milliseconds to over a second CPU utilization goes to close to 100% this",
    "start": "2206650",
    "end": "2214990"
  },
  {
    "text": "is a failure what's the difference",
    "start": "2214990",
    "end": "2220500"
  },
  {
    "text": "this is the difference between this two scenarios service on the Left keeps",
    "start": "2222270",
    "end": "2227760"
  },
  {
    "text": "going service on the right fails how is it related to auto scaling if you have",
    "start": "2227760",
    "end": "2236390"
  },
  {
    "text": "the good service the service on the left then it's a business decision at this",
    "start": "2236390",
    "end": "2243420"
  },
  {
    "text": "point you can choose to operate it at a lower CPU utilization lower latency at a",
    "start": "2243420",
    "end": "2253260"
  },
  {
    "text": "higher HD size pay a little bit more but get the latency get the low latency if",
    "start": "2253260",
    "end": "2260670"
  },
  {
    "text": "you don't care about latency between 30 and 60 milliseconds you can run it",
    "start": "2260670",
    "end": "2268050"
  },
  {
    "text": "hotter and save money the service on the right you do not have the same luxury",
    "start": "2268050",
    "end": "2274260"
  },
  {
    "text": "you have to make sure you operate it well below the point where it breaks now",
    "start": "2274260",
    "end": "2284400"
  },
  {
    "text": "we know our metric we know our target let's get to setting up scale and",
    "start": "2284400",
    "end": "2290400"
  },
  {
    "text": "policies here is an example of of an ASG",
    "start": "2290400",
    "end": "2298350"
  },
  {
    "start": "2293000",
    "end": "2293000"
  },
  {
    "text": "with a scale and policy on throughput the graph on the top represents the ASG",
    "start": "2298350",
    "end": "2303810"
  },
  {
    "text": "size that's the gray area versus throughput that's the pink line the",
    "start": "2303810",
    "end": "2309300"
  },
  {
    "text": "graph at the bottom is the throughput per instance yellow and blue lines are",
    "start": "2309300",
    "end": "2316440"
  },
  {
    "text": "our threshold scale up and scale down threshold first of all you can see that",
    "start": "2316440",
    "end": "2321660"
  },
  {
    "text": "even visually this size and overall throughput they kind of match they're",
    "start": "2321660",
    "end": "2328620"
  },
  {
    "text": "about the same shape but the bottom graph is more telling this is this is",
    "start": "2328620",
    "end": "2335490"
  },
  {
    "text": "the hole this is how auto scaling operates it keeps your target metric",
    "start": "2335490",
    "end": "2340650"
  },
  {
    "text": "within a band width step scale in pulses you used to set this band explicitly by",
    "start": "2340650",
    "end": "2347430"
  },
  {
    "text": "scale up and scale down thresholds with target tracking there is an implicit band but it's always a band for as long",
    "start": "2347430",
    "end": "2355020"
  },
  {
    "text": "as your map stay within the band auto-scaling doesn't do anything doesn't scale up",
    "start": "2355020",
    "end": "2361060"
  },
  {
    "text": "doesn't scale down it keeps you steady when the metric goes above your scale up",
    "start": "2361060",
    "end": "2366820"
  },
  {
    "text": "trash hole above your ceiling it gives you more capacity and your true put goes",
    "start": "2366820",
    "end": "2372910"
  },
  {
    "text": "down and as the traffic increases III peds so when the traffic increases we",
    "start": "2372910",
    "end": "2379780"
  },
  {
    "text": "keep bumping up against the ceiling and getting more capacity on the way down we're bumping up against the floor",
    "start": "2379780",
    "end": "2386370"
  },
  {
    "text": "removing capacity or the scale and always tries to keep the metric within",
    "start": "2386370",
    "end": "2391540"
  },
  {
    "text": "the band sounds easy must be easy to set",
    "start": "2391540",
    "end": "2397030"
  },
  {
    "text": "up let's see what could go wrong here's a few examples nor our scaling well you",
    "start": "2397030",
    "end": "2406960"
  },
  {
    "start": "2404000",
    "end": "2404000"
  },
  {
    "text": "can see even visually there is something wrong if you compare it to the previous slide the shapes do not match and the",
    "start": "2406960",
    "end": "2415960"
  },
  {
    "text": "troupe odd per instance goes way below the the floor and a little bit above the",
    "start": "2415960",
    "end": "2421420"
  },
  {
    "text": "ceiling in this particular case the team that set it up they confused the scale",
    "start": "2421420",
    "end": "2429700"
  },
  {
    "text": "up by the number of instances versus the scale up by the percentage of SG size",
    "start": "2429700",
    "end": "2435490"
  },
  {
    "text": "that's one of the parameters step scale pulses allow you to choose as you can",
    "start": "2435490",
    "end": "2442870"
  },
  {
    "text": "see the size of this SG but between three and four hundred instances at this",
    "start": "2442870",
    "end": "2448270"
  },
  {
    "text": "point scaling by five instances versus five percent it matters in this case",
    "start": "2448270",
    "end": "2455290"
  },
  {
    "text": "auto scaling does what it's supposed to do but it simply cannot keep up with the",
    "start": "2455290",
    "end": "2461710"
  },
  {
    "text": "traffic the solution in this case is to",
    "start": "2461710",
    "end": "2466720"
  },
  {
    "text": "increase kelyn amounts or migrate the target tracking target tracking doesn't have this problem everything is managed",
    "start": "2466720",
    "end": "2473230"
  },
  {
    "text": "for you another example twitch is killing this SG doubles up",
    "start": "2473230",
    "end": "2482070"
  },
  {
    "start": "2476000",
    "end": "2476000"
  },
  {
    "text": "capacity as soon as our throughput metric reaches the scale up trash hole",
    "start": "2482070",
    "end": "2489930"
  },
  {
    "text": "when I spoke with the service owners for this particular SG and I asked him I",
    "start": "2489930",
    "end": "2495369"
  },
  {
    "text": "asked them why did you set it up this way their answer was we wanted to make",
    "start": "2495369",
    "end": "2501430"
  },
  {
    "text": "sure we have enough capacity but we don't really know how much is enough",
    "start": "2501430",
    "end": "2507460"
  },
  {
    "text": "we're not sure how much traffic we're gonna get so doubling up seemed like a",
    "start": "2507460",
    "end": "2513760"
  },
  {
    "text": "safe bet okay well the problem with that is that once you double up your",
    "start": "2513760",
    "end": "2521320"
  },
  {
    "text": "scaled-down policy starts killing you down immediately so all it achieves is",
    "start": "2521320",
    "end": "2526810"
  },
  {
    "text": "just an instance churn target tracking obviously doesn't have the same problem",
    "start": "2526810",
    "end": "2534240"
  },
  {
    "text": "it always keeps you in the band it doesn't give you all a ssin and lastly",
    "start": "2534240",
    "end": "2543330"
  },
  {
    "start": "2542000",
    "end": "2542000"
  },
  {
    "text": "this is my favorite example should I stay or should I go there's a little",
    "start": "2543330",
    "end": "2548440"
  },
  {
    "text": "story behind this example one of the teams discovered and discovered the",
    "start": "2548440",
    "end": "2554260"
  },
  {
    "text": "performance regression in in one of their services they discovered it on",
    "start": "2554260",
    "end": "2559840"
  },
  {
    "text": "Friday so they have a choice push a fix going into the weekend or scale-up stay",
    "start": "2559840",
    "end": "2569170"
  },
  {
    "text": "throughout the weekend and push the fix on Monday they chose not to push on",
    "start": "2569170",
    "end": "2575770"
  },
  {
    "text": "Friday which is considered our best practice that's great and incapacity to",
    "start": "2575770",
    "end": "2582790"
  },
  {
    "text": "survive the weekend good decision what happened is they lowered their scale-up",
    "start": "2582790",
    "end": "2589810"
  },
  {
    "text": "threshold they lowered the ceiling but they didn't lowered the floor so instead",
    "start": "2589810",
    "end": "2596920"
  },
  {
    "text": "of a band it became a single line both scale up and scale down thresholds are",
    "start": "2596920",
    "end": "2603130"
  },
  {
    "text": "exactly the same what happened is G start oscillating obviously again I'm",
    "start": "2603130",
    "end": "2612490"
  },
  {
    "text": "repeating myself but I think it's worth it target tracking doesn't have this",
    "start": "2612490",
    "end": "2617859"
  },
  {
    "text": "problem in terms of setup",
    "start": "2617859",
    "end": "2623070"
  },
  {
    "start": "2623000",
    "end": "2623000"
  },
  {
    "text": "going back to customer feedback speedier speedy setup it's about ten fields",
    "start": "2623070",
    "end": "2629890"
  },
  {
    "text": "versus three in target tracking this is a screenshot from spinnaker our deployment system it's open source by",
    "start": "2629890",
    "end": "2636430"
  },
  {
    "text": "the way you can use it as well but it's closely in this particular case it closely resembles AWS console instead of",
    "start": "2636430",
    "end": "2644560"
  },
  {
    "text": "specifying thresholds and scaling amounts and the number of evaluation",
    "start": "2644560",
    "end": "2651010"
  },
  {
    "text": "periods you just specify your metric and your target and more map time that's it",
    "start": "2651010",
    "end": "2658320"
  },
  {
    "text": "but wait that's not it four-step policies you have to specify",
    "start": "2658320",
    "end": "2664750"
  },
  {
    "text": "both scale up and scale down and you have to make sure they're aligned target",
    "start": "2664750",
    "end": "2672070"
  },
  {
    "text": "ranking doesn't have this problem single policy controls both scale up and scale",
    "start": "2672070",
    "end": "2677470"
  },
  {
    "text": "down just the metric target warmup time and it scales by the virtual for the",
    "start": "2677470",
    "end": "2686380"
  },
  {
    "text": "scale and magic and lastly the traffic patterns I think it's very important to",
    "start": "2686380",
    "end": "2694660"
  },
  {
    "text": "understand your traffic patterns here is an example what is common between all",
    "start": "2694660",
    "end": "2701620"
  },
  {
    "start": "2698000",
    "end": "2698000"
  },
  {
    "text": "these kids shows that available on Netflix and this traffic pattern here it",
    "start": "2701620",
    "end": "2711580"
  },
  {
    "text": "turns out that Saturdays have a much steeper traffic ramp up in the morning",
    "start": "2711580",
    "end": "2718630"
  },
  {
    "text": "hours and it's been attributed to kids watching Netflix early in the morning",
    "start": "2718630",
    "end": "2724140"
  },
  {
    "text": "instead of going to school as they do on a weekday",
    "start": "2724140",
    "end": "2729690"
  },
  {
    "text": "how does Auto scale and react to this let's see this is a zoom in on Saturday",
    "start": "2729990",
    "end": "2738910"
  },
  {
    "start": "2736000",
    "end": "2736000"
  },
  {
    "text": "morning as you can see that traffic ramps up much steeper as compared to",
    "start": "2738910",
    "end": "2744760"
  },
  {
    "text": "Friday Saturday more volume of traffic why am I talking about",
    "start": "2744760",
    "end": "2749890"
  },
  {
    "text": "mornings instead of peak times because usually when people talk about auto-scaling the question is well",
    "start": "2749890",
    "end": "2755350"
  },
  {
    "text": "I have enough capacity to handle my peak the answer is yes or the scaling will give you this capacity it will give you",
    "start": "2755350",
    "end": "2762280"
  },
  {
    "text": "capacity up to your ASG max actually the more more salient problem",
    "start": "2762280",
    "end": "2769930"
  },
  {
    "text": "here is that when the ASG is at the lowest size and you have sharp increase",
    "start": "2769930",
    "end": "2776770"
  },
  {
    "text": "in traffic can auto scale and keep up with increasing demand you have only a",
    "start": "2776770",
    "end": "2782350"
  },
  {
    "text": "few instances to spread your traffic across at peak you have much more to",
    "start": "2782350",
    "end": "2789160"
  },
  {
    "text": "answer this question within an experiment we run one service with our",
    "start": "2789160",
    "end": "2795360"
  },
  {
    "text": "reasonably well tuned step policies then the next week we run we're on it with",
    "start": "2795360",
    "end": "2802270"
  },
  {
    "text": "target tracking on the same threshold with the same target and here's the",
    "start": "2802270",
    "end": "2808540"
  },
  {
    "text": "comparison blue line represents the behavior of target tracking yellow line",
    "start": "2808540",
    "end": "2816160"
  },
  {
    "text": "represents the stab policies in terms of per instance throughput you can see that",
    "start": "2816160",
    "end": "2824170"
  },
  {
    "text": "between 4 & 5 a.m. and the morning step policies gives us higher throughput they",
    "start": "2824170",
    "end": "2830290"
  },
  {
    "text": "both are slightly above our target but step policies go higher above the target",
    "start": "2830290",
    "end": "2837070"
  },
  {
    "text": "and this is the danger zone step policies cannot keep up with this",
    "start": "2837070",
    "end": "2842980"
  },
  {
    "text": "traffic then if you look from 6 to 7",
    "start": "2842980",
    "end": "2850060"
  },
  {
    "text": "a.m. step scale pulses all of a sudden give",
    "start": "2850060",
    "end": "2856030"
  },
  {
    "text": "us more capacity the ASG runs slightly cooler than it could have",
    "start": "2856030",
    "end": "2862050"
  },
  {
    "text": "and if you look at is G size unsurprisingly target tracking gives us",
    "start": "2862050",
    "end": "2868660"
  },
  {
    "text": "a little bit more capacity early in the morning and a little bit less capacity",
    "start": "2868660",
    "end": "2874110"
  },
  {
    "text": "later in the morning between 6:00 and 7:00 a.m. essentially it saves us from trouble",
    "start": "2874110",
    "end": "2879910"
  },
  {
    "text": "early in the morning and it saves us money later by simply keeping the target",
    "start": "2879910",
    "end": "2886870"
  },
  {
    "text": "closer track the target closer when you look at this",
    "start": "2886870",
    "end": "2893330"
  },
  {
    "text": "graphs you might say okay well it doesn't seem like we save much but",
    "start": "2893330",
    "end": "2900800"
  },
  {
    "text": "actually keep in mind this is a relatively small SG on our larger aSG's",
    "start": "2900800",
    "end": "2907220"
  },
  {
    "text": "we see bigger saving for example in this particular case the savings the savings",
    "start": "2907220",
    "end": "2913760"
  },
  {
    "text": "over the week estimated about four percent that's a pretty decent result especially considering that we didn't",
    "start": "2913760",
    "end": "2920960"
  },
  {
    "text": "invest any time in tuning auto-scaling target tracking did it for us it's just",
    "start": "2920960",
    "end": "2927290"
  },
  {
    "text": "set it and forget it to summarize target tracking gives us",
    "start": "2927290",
    "end": "2937070"
  },
  {
    "start": "2933000",
    "end": "2933000"
  },
  {
    "text": "easier setup and better demand tracking",
    "start": "2937070",
    "end": "2942310"
  },
  {
    "text": "easier setup results in increased productivity better demand tracking",
    "start": "2943570",
    "end": "2949130"
  },
  {
    "text": "gives us reliability I wanted to talk a little bit more about productivity when",
    "start": "2949130",
    "end": "2956300"
  },
  {
    "text": "I say productivity it's not that it I'm not talking about filling out down",
    "start": "2956300",
    "end": "2962330"
  },
  {
    "text": "fields four-step policy versus three fields for target tracking it's more how",
    "start": "2962330",
    "end": "2970910"
  },
  {
    "text": "teams use it what we noticed is that snap policies extremely powerful but",
    "start": "2970910",
    "end": "2978710"
  },
  {
    "text": "setup was not was not obvious so teams was avoiding changing their scale and",
    "start": "2978710",
    "end": "2986060"
  },
  {
    "text": "policies they were not really looking at their demand they were not really",
    "start": "2986060",
    "end": "2992180"
  },
  {
    "text": "tracking it with target tracking it becomes it becomes so easy and so",
    "start": "2992180",
    "end": "2998030"
  },
  {
    "text": "intuitive that teams pay more attention it's very easy for them to stay on the",
    "start": "2998030",
    "end": "3003250"
  },
  {
    "text": "top of their performance characteristics and capacity demands and productivity",
    "start": "3003250",
    "end": "3009550"
  },
  {
    "text": "alone in my opinion justifies the moved target tracking and by the way by",
    "start": "3009550",
    "end": "3015280"
  },
  {
    "text": "increasing productivity ultimately we save cost but again that's not it there",
    "start": "3015280",
    "end": "3022240"
  },
  {
    "text": "another AWS innovation per second billion combined with better demand",
    "start": "3022240",
    "end": "3029200"
  },
  {
    "text": "tracking it gives us reduced cost we spin up capacity only when we need it",
    "start": "3029200",
    "end": "3036820"
  },
  {
    "text": "and target tracking is very good at reacting quickly and givin us exactly",
    "start": "3036820",
    "end": "3043360"
  },
  {
    "text": "the amount of capacity that needed to process the incoming traffic and that is",
    "start": "3043360",
    "end": "3050200"
  },
  {
    "text": "how target tracking hits productivity reliability and cost it's not a zero-sum",
    "start": "3050200",
    "end": "3059920"
  },
  {
    "text": "games you can get all three of them if you don't use auto scaling start with",
    "start": "3059920",
    "end": "3066880"
  },
  {
    "text": "target tracking if you use step scaling policies I encourage you to migrate I",
    "start": "3066880",
    "end": "3073780"
  },
  {
    "text": "encourage you to at least give target tracking a try thank you",
    "start": "3073780",
    "end": "3079000"
  },
  {
    "text": "[Applause]",
    "start": "3079000",
    "end": "3083610"
  },
  {
    "text": "thanks for deem thanks for sharing your auto-scaling learnings and lessons from",
    "start": "3084250",
    "end": "3090320"
  },
  {
    "text": "Netflix hopefully will help others to avoid some growing pains and as you said",
    "start": "3090320",
    "end": "3097460"
  },
  {
    "start": "3097000",
    "end": "3097000"
  },
  {
    "text": "encourage you if you haven't tried target tracking we make it really easy there's some great resources on our",
    "start": "3097460",
    "end": "3104120"
  },
  {
    "text": "getting started page or if you want to try auto-scaling with one of our new auto scalable services like DynamoDB or",
    "start": "3104120",
    "end": "3111620"
  },
  {
    "text": "aurora and for us we'd love to hear how",
    "start": "3111620",
    "end": "3116720"
  },
  {
    "text": "our customers are using our services so if you want to share at hashtag",
    "start": "3116720",
    "end": "3121790"
  },
  {
    "text": "auto-scaling what you're scaling and how you're scaling would love that maybe you'll be on stage with us at the next",
    "start": "3121790",
    "end": "3128750"
  },
  {
    "text": "summit thank you for your time and enjoy the joy tonight enjoy the rest of",
    "start": "3128750",
    "end": "3133850"
  },
  {
    "text": "reinvent thank you [Applause]",
    "start": "3133850",
    "end": "3138749"
  }
]
[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": "hello my name is tony omar and i'm a solutions architect here at aws",
    "start": "880",
    "end": "6879"
  },
  {
    "text": "today i'm very excited to show you how you can leverage event driven flows using amazon app flow",
    "start": "6879",
    "end": "14320"
  },
  {
    "text": "and sagemaker to classify salesforce cases using machine learning",
    "start": "14320",
    "end": "21199"
  },
  {
    "start": "20000",
    "end": "104000"
  },
  {
    "text": "but before we proceed i want us to take a step back and talk about a use case that is very",
    "start": "21199",
    "end": "27519"
  },
  {
    "text": "common for a lot for our customers imagine a scenario where your customers",
    "start": "27519",
    "end": "32880"
  },
  {
    "text": "open a support ticket through a web portal or email the case is then",
    "start": "32880",
    "end": "37920"
  },
  {
    "text": "routed to a specialist who has to read the description of the support ticket then make a",
    "start": "37920",
    "end": "44000"
  },
  {
    "text": "decision on which team needs to be assigned the case",
    "start": "44000",
    "end": "50000"
  },
  {
    "text": "this is very common but it does pose some challenges to your business this process is error prone the person",
    "start": "50160",
    "end": "57120"
  },
  {
    "text": "assigning the new case might not have expertise in that subject area",
    "start": "57120",
    "end": "63600"
  },
  {
    "text": "there is also the issue over longer wait times for issues to be resolved due to the",
    "start": "63600",
    "end": "69360"
  },
  {
    "text": "manual processes involved in opening a support ticket",
    "start": "69360",
    "end": "74560"
  },
  {
    "text": "this can also lead to low seaside scores because your customers will have to wait for a",
    "start": "74560",
    "end": "79600"
  },
  {
    "text": "very long time for them to be able to start interacting with the subject matter expert for that",
    "start": "79600",
    "end": "85439"
  },
  {
    "text": "particular support keys support cases a better solution is actually to use",
    "start": "85439",
    "end": "91680"
  },
  {
    "text": "machine learning to classify the cases using then using salesforce",
    "start": "91680",
    "end": "97040"
  },
  {
    "text": "auto assign rules to route the case to the appropriate team and we are going to look at how you can",
    "start": "97040",
    "end": "102399"
  },
  {
    "text": "do that in the upcoming sections but before you build a system that is",
    "start": "102399",
    "end": "107840"
  },
  {
    "start": "104000",
    "end": "205000"
  },
  {
    "text": "capable of classifying cases or salesforce cases in near real time",
    "start": "107840",
    "end": "113280"
  },
  {
    "text": "there are two critical components that you will need to address before moving any further those two",
    "start": "113280",
    "end": "120719"
  },
  {
    "text": "critical components is the integration between aws",
    "start": "120719",
    "end": "126079"
  },
  {
    "text": "and salesforce and the other one is machine learning previously",
    "start": "126079",
    "end": "133040"
  },
  {
    "text": "our customers spent a lot of time and resources building connectors to move data between",
    "start": "133040",
    "end": "140720"
  },
  {
    "text": "their sas applications to aws but what our customers kept telling us",
    "start": "140720",
    "end": "146879"
  },
  {
    "text": "was that they want to spend time focusing on their customers focusing on solving their business problems",
    "start": "146879",
    "end": "153840"
  },
  {
    "text": "and getting insights into this data and this is where aflo came into play",
    "start": "153840",
    "end": "160720"
  },
  {
    "text": "we built upflow so that the customers can spend time solving",
    "start": "160720",
    "end": "166000"
  },
  {
    "text": "their actual business problem instead of maintaining scaling and building these connectors",
    "start": "166000",
    "end": "174080"
  },
  {
    "text": "the second piece is machine learning for you to build machine learning models you need to have the infrastructure and",
    "start": "174959",
    "end": "181360"
  },
  {
    "text": "the tools to build train and develop machine learning model",
    "start": "181360",
    "end": "186560"
  },
  {
    "text": "including hosting and this is where sagemaker becomes very helpful and we are going to look at how you can",
    "start": "186560",
    "end": "194640"
  },
  {
    "text": "be able to leverage the sagemaker capability to host you a machine learning model",
    "start": "194640",
    "end": "200319"
  },
  {
    "text": "that is going to be used to classify the cases",
    "start": "200319",
    "end": "205120"
  },
  {
    "start": "205000",
    "end": "230000"
  },
  {
    "text": "so let's talk about amazon airflow so airflow",
    "start": "207120",
    "end": "213360"
  },
  {
    "text": "is a fully managed service that enables you to securely transfer data",
    "start": "213360",
    "end": "218879"
  },
  {
    "text": "between your sas applications like salesforce to aws services like s3 with just a few",
    "start": "218879",
    "end": "226879"
  },
  {
    "text": "clicks and zero coding the way it works",
    "start": "226879",
    "end": "233200"
  },
  {
    "start": "230000",
    "end": "302000"
  },
  {
    "text": "is very simple you define your data flow requirement this is basically the source for your",
    "start": "233200",
    "end": "239519"
  },
  {
    "text": "data and the destination then under the covers we provision",
    "start": "239519",
    "end": "246319"
  },
  {
    "text": "all the resources that you need to move your data from point a to point b and this can be compute",
    "start": "246319",
    "end": "253360"
  },
  {
    "text": "storage or networking resources and then finally afflow will invoke",
    "start": "253360",
    "end": "260959"
  },
  {
    "text": "the flow and there are three types of flows that you can configure",
    "start": "260959",
    "end": "266479"
  },
  {
    "text": "using airflow the first one is event driven the second one is on demand",
    "start": "266479",
    "end": "273280"
  },
  {
    "text": "and the third one is scheduled for this demo today our focus is going",
    "start": "273280",
    "end": "280560"
  },
  {
    "text": "to be on event driven flows because when a user opens a support ticket",
    "start": "280560",
    "end": "288000"
  },
  {
    "text": "we want to classify that salesforce object in near real time using machine learning",
    "start": "288000",
    "end": "295280"
  },
  {
    "text": "model that has actually been hosted in sagemaker",
    "start": "295280",
    "end": "301040"
  },
  {
    "start": "302000",
    "end": "360000"
  },
  {
    "text": "back to machine learning the main service that we are going to",
    "start": "305120",
    "end": "310240"
  },
  {
    "text": "use for this demo to host our machine learning model is going to be amazon sagemaker",
    "start": "310240",
    "end": "317360"
  },
  {
    "text": "so sagemaker is a fully managed service that provides every developer and data scientists",
    "start": "317360",
    "end": "323680"
  },
  {
    "text": "with the ability to train and deploy machine learning models",
    "start": "323680",
    "end": "330080"
  },
  {
    "text": "without having to build scale the underlying infrastructure",
    "start": "330080",
    "end": "336880"
  },
  {
    "text": "for your ml needs so we it does have components that you",
    "start": "336880",
    "end": "343280"
  },
  {
    "text": "need like notebooks and and you know we do have substance like ground truthful labeling",
    "start": "343280",
    "end": "349360"
  },
  {
    "text": "but for our use case we are only going to use it for training and inference",
    "start": "349360",
    "end": "356000"
  },
  {
    "text": "piece of our solution",
    "start": "356000",
    "end": "359520"
  },
  {
    "start": "360000",
    "end": "562000"
  },
  {
    "text": "so for our demo today at a higher level we are going to have a web application",
    "start": "364880",
    "end": "372319"
  },
  {
    "text": "and this is just a standard amplify uh web app that is hosted uh",
    "start": "372319",
    "end": "379280"
  },
  {
    "text": "in cloudfront distribution in s3 and s3 and the way it works is the users will",
    "start": "379280",
    "end": "385680"
  },
  {
    "text": "go to the web application and they'll be able to authenticate uh using uh cognito cognito is one of",
    "start": "385680",
    "end": "393280"
  },
  {
    "text": "our services that we do offer that allows you to authenticate users and and basically provide you with the",
    "start": "393280",
    "end": "398720"
  },
  {
    "text": "directory store for storing your username and passwords and then once the user has been authenticated they will fill out a",
    "start": "398720",
    "end": "405440"
  },
  {
    "text": "support form and behind the scenes",
    "start": "405440",
    "end": "410479"
  },
  {
    "text": "the web app is using salesforce capability of web to case and that essentially creates a case",
    "start": "410479",
    "end": "417919"
  },
  {
    "text": "object in salesforce and when the sales object is created in salesforce there is an event that is",
    "start": "417919",
    "end": "423280"
  },
  {
    "text": "fired which triggers the airflow event-driven flow the event-driven flow will pull the data",
    "start": "423280",
    "end": "430960"
  },
  {
    "text": "and once the data is pulled by airflow it's going to be delivered to amazon eventbridge",
    "start": "430960",
    "end": "436800"
  },
  {
    "text": "so eventbridge is a fully managed aws service that is essentially an event bus that",
    "start": "436800",
    "end": "441840"
  },
  {
    "text": "allows you to route events to different aws services in our case",
    "start": "441840",
    "end": "446880"
  },
  {
    "text": "it's going to route the event to aws lambda and lambda is a serverless",
    "start": "446880",
    "end": "454080"
  },
  {
    "text": "compute service uh you don't have to provision any compute uh set up the operating system or any sort",
    "start": "454080",
    "end": "460080"
  },
  {
    "text": "of thing in other words you just provide your code and and essentially you know",
    "start": "460080",
    "end": "465120"
  },
  {
    "text": "we invoke the code for you so what happens here is that eventbridge will send the event to aws lambda and",
    "start": "465120",
    "end": "472240"
  },
  {
    "text": "what lambda will do it would basically look at the data look at our object and pick up the description field because that's where",
    "start": "472240",
    "end": "478319"
  },
  {
    "text": "we have the description of why the user is opening that particular support case",
    "start": "478319",
    "end": "483599"
  },
  {
    "text": "and it's going to call sagemaker endpoint which is a fully trained ml model nlp",
    "start": "483599",
    "end": "490160"
  },
  {
    "text": "model that is able to classify that particular case and tag it or",
    "start": "490160",
    "end": "496960"
  },
  {
    "text": "basically tell the the lambda function what type of case it is or what what's the category of the case",
    "start": "496960",
    "end": "503759"
  },
  {
    "text": "and when we get to the sagemaker piece i am going to walk you through our sagemaker notebook well it's no longer meant to be a deep dive",
    "start": "503759",
    "end": "510879"
  },
  {
    "text": "into sagemaker the goal of me building this demo for you is actually",
    "start": "510879",
    "end": "516399"
  },
  {
    "text": "to demonstrate to you how you can leverage the power of airflow or the capability that we are",
    "start": "516399",
    "end": "522560"
  },
  {
    "text": "offering you with airflow to be able to do the art of the possible using your sas application so in our",
    "start": "522560",
    "end": "528080"
  },
  {
    "text": "case we are trying to improve our customer experience by automating some of the manual processes that are",
    "start": "528080",
    "end": "534320"
  },
  {
    "text": "prone to errors and things like that in your salesforce activities and use machine learning to",
    "start": "534320",
    "end": "540800"
  },
  {
    "text": "basically help automate that process so this is the art of the possible but all this is possible mainly due to",
    "start": "540800",
    "end": "548480"
  },
  {
    "text": "the fact that we have amazon afflow that has simplified the integration between your sas application",
    "start": "548480",
    "end": "554880"
  },
  {
    "text": "and aws now we are going to jump into the demo but before i jump into the",
    "start": "554880",
    "end": "561360"
  },
  {
    "text": "demo i'm kind of going to show you",
    "start": "561360",
    "end": "566399"
  },
  {
    "text": "what the complete application looks like and then we are going to dive in and start configuring the different components",
    "start": "566399",
    "end": "572720"
  },
  {
    "text": "that we need for application",
    "start": "572720",
    "end": "577839"
  },
  {
    "text": "so let's switch to the web browser and take a look at our sample",
    "start": "586959",
    "end": "592640"
  },
  {
    "text": "application",
    "start": "592640",
    "end": "595200"
  },
  {
    "start": "596000",
    "end": "650000"
  },
  {
    "text": "so here is our sample app and you can see it's very simple it's just a web portal where our customers can",
    "start": "597920",
    "end": "604399"
  },
  {
    "text": "come in and submit a support ticket and that's exactly what we're going to do so i'm going to put in my name",
    "start": "604399",
    "end": "612560"
  },
  {
    "text": "and i'm going to put in my email and i'm going to put my phone number",
    "start": "612560",
    "end": "620160"
  },
  {
    "text": "and the subject in this case issue with my email",
    "start": "622079",
    "end": "629760"
  },
  {
    "text": "then we're going to put the support description which is essentially the user is having issues with the outlook application then you're",
    "start": "629760",
    "end": "636399"
  },
  {
    "text": "going to submit the support ticket then we are going to get redirected back",
    "start": "636399",
    "end": "642480"
  },
  {
    "text": "to the thank you page or success page switching",
    "start": "642480",
    "end": "649760"
  },
  {
    "text": "into our salesforce application",
    "start": "649760",
    "end": "654560"
  },
  {
    "start": "650000",
    "end": "775000"
  },
  {
    "text": "and you realize that here we have configured assignment rules",
    "start": "655680",
    "end": "662160"
  },
  {
    "text": "and in this case it's case assignment rules we have a couple of them the one that is active right now is the",
    "start": "668720",
    "end": "674399"
  },
  {
    "text": "one called customer support and if you open customer support there are two rule entries",
    "start": "674399",
    "end": "680560"
  },
  {
    "text": "let's take a look at the first one so the first rule entry is looking for a case object and if the",
    "start": "680560",
    "end": "688079"
  },
  {
    "text": "field case object of uh if the case type if the field known as the case type the value is",
    "start": "688079",
    "end": "695279"
  },
  {
    "text": "category five then that particular case is assigned to a queue",
    "start": "695279",
    "end": "700720"
  },
  {
    "text": "called category five okay the other one is having",
    "start": "700720",
    "end": "708320"
  },
  {
    "text": "a second type of category which is category four so the way it works actually is that when when you create a case object",
    "start": "708320",
    "end": "716079"
  },
  {
    "text": "afflow gets triggered and it sends the it once upload is triggered it sends the",
    "start": "716079",
    "end": "721680"
  },
  {
    "text": "event to eventbridge and then eventbridge will trigger our code and then once our",
    "start": "721680",
    "end": "727040"
  },
  {
    "text": "code has been triggered what actually happens behind the scene is that we call sagemaker endpoint",
    "start": "727040",
    "end": "732480"
  },
  {
    "text": "uh used by getting the value of the description of our of our support ticket and then we classify uh that particular",
    "start": "732480",
    "end": "740399"
  },
  {
    "text": "case once we classify that case then we come back and update the the fill",
    "start": "740399",
    "end": "746720"
  },
  {
    "text": "type for that case object once the field type has been updated then the that's where the auto assignment",
    "start": "746720",
    "end": "752079"
  },
  {
    "text": "rules kicks in so i already received an email that i have a case that was created",
    "start": "752079",
    "end": "758800"
  },
  {
    "text": "and i am going to move that case to this screen",
    "start": "758800",
    "end": "766480"
  },
  {
    "text": "a second",
    "start": "771839",
    "end": "774399"
  },
  {
    "start": "775000",
    "end": "997000"
  },
  {
    "text": "that's our case and you can see that our case id is zero zero one one one seven",
    "start": "777360",
    "end": "787839"
  },
  {
    "text": "now if we go to our cases",
    "start": "789040",
    "end": "793360"
  },
  {
    "text": "we can see we have a case here called zero zero one one one seven if i open that case that case has been",
    "start": "798720",
    "end": "805120"
  },
  {
    "text": "classified as category four and this happened automatically",
    "start": "805120",
    "end": "810480"
  },
  {
    "text": "using aws lambda airflow and sagemaker ml model to essentially",
    "start": "810480",
    "end": "816160"
  },
  {
    "text": "tag this particular case",
    "start": "816160",
    "end": "819680"
  },
  {
    "text": "the next let's switch gears here let's look at how we use sagemaker to deploy this",
    "start": "821360",
    "end": "828000"
  },
  {
    "text": "model sedgemaker is very very modular and in my case here i'm using my local laptop as the",
    "start": "828000",
    "end": "834399"
  },
  {
    "text": "sagemaker notebook it's very straightforward the first thing i do is",
    "start": "834399",
    "end": "839519"
  },
  {
    "text": "use the sagemaker sdk and boto3 which is the aws sdk",
    "start": "839519",
    "end": "845120"
  },
  {
    "text": "i split the data into training and validation data then i create an",
    "start": "845120",
    "end": "851279"
  },
  {
    "text": "estimator which is an estimator using the aws sagemaker sdk",
    "start": "851279",
    "end": "856800"
  },
  {
    "text": "encapsulates the training where i specify the size of my computer that i'm going to use together with where i'm going to save",
    "start": "856800",
    "end": "863760"
  },
  {
    "text": "the output i set some hyper parameters then i do the training once the training is complete i actually",
    "start": "863760",
    "end": "871040"
  },
  {
    "text": "deploy my sagemaker model and at that point i'm ready to consume",
    "start": "871040",
    "end": "876079"
  },
  {
    "text": "my model by using an api this the actual uh sagemaker model the",
    "start": "876079",
    "end": "882079"
  },
  {
    "text": "actual machine learning model is hosted in sagemaker endpoints and if you go to aws services in the",
    "start": "882079",
    "end": "888880"
  },
  {
    "text": "console and we're going to look for sagemaker",
    "start": "888880",
    "end": "893519"
  },
  {
    "text": "as i already mentioned sagemaker is very modular it has a lot of components notebook instances but in our case",
    "start": "894639",
    "end": "900000"
  },
  {
    "text": "what we are going to use is sagemaker endpoints and this is the name of the endpoint",
    "start": "900000",
    "end": "906320"
  },
  {
    "text": "that we are going to use let's take a look at the code",
    "start": "906320",
    "end": "915440"
  },
  {
    "text": "for this particular web app as you can see it's a simple angular application and",
    "start": "915440",
    "end": "921680"
  },
  {
    "text": "this particular form html code was generated by salesforce web to case",
    "start": "921680",
    "end": "928800"
  },
  {
    "text": "and the most important part here is the org id which is blood which has been blown out for security",
    "start": "928800",
    "end": "934320"
  },
  {
    "text": "reason but you supply the org id together with the return url so that once a user",
    "start": "934320",
    "end": "941040"
  },
  {
    "text": "successfully submits the case uh they have a return url which in my case is a thank you page",
    "start": "941040",
    "end": "947600"
  },
  {
    "text": "so at a much higher level my application is very simple i use a go to the web portal",
    "start": "947600",
    "end": "953279"
  },
  {
    "text": "submit their case which essentially is created in salesforce that in turn triggers an event",
    "start": "953279",
    "end": "960800"
  },
  {
    "text": "and once the event has been triggered it's sent to eventbridge and then eventbridge will invoke my lambda",
    "start": "960800",
    "end": "967360"
  },
  {
    "text": "function and we'll going to talk about the lambda function during our configuration",
    "start": "967360",
    "end": "972560"
  },
  {
    "text": "and once that lambda function is triggered it's going to call the sagemaker endpoint which essentially is a machine learning model endpoint and get an inference and",
    "start": "972560",
    "end": "980160"
  },
  {
    "text": "turn around and classify my case so let's go ahead and switch gears here",
    "start": "980160",
    "end": "987440"
  },
  {
    "text": "and jump straight into the configuration of app flow together with",
    "start": "987440",
    "end": "996000"
  },
  {
    "text": "the other components that we need great let's head over to the aws console",
    "start": "996000",
    "end": "1001839"
  },
  {
    "start": "997000",
    "end": "1200000"
  },
  {
    "text": "and start configuring the integration so in the aws console we're going to look for app flow",
    "start": "1001839",
    "end": "1012240"
  },
  {
    "text": "then we're going to create a new flow i am going to call my flow sage maker",
    "start": "1014079",
    "end": "1020880"
  },
  {
    "text": "s s",
    "start": "1021440",
    "end": "1025839"
  },
  {
    "text": "events you have the option of configuring uh encryption using your",
    "start": "1026959",
    "end": "1033199"
  },
  {
    "text": "customer manage keys but we are going to go with the default and not use that but by default",
    "start": "1033199",
    "end": "1039520"
  },
  {
    "text": "all the data transfer under the covers is encrypted",
    "start": "1039520",
    "end": "1044720"
  },
  {
    "text": "then you're going to click next in the next screen we are going to configure the source of",
    "start": "1045360",
    "end": "1052000"
  },
  {
    "text": "our data which is going to be salesforce then we are going to create a connection to a",
    "start": "1052000",
    "end": "1057520"
  },
  {
    "text": "salesforce organization basically essentially here we are providing uh authentication",
    "start": "1057520",
    "end": "1063200"
  },
  {
    "text": "so that afflow is able to read your salesforce data so i'm going to",
    "start": "1063200",
    "end": "1069120"
  },
  {
    "text": "call this sagemaker demo connection i'm going to click continue",
    "start": "1069120",
    "end": "1076960"
  },
  {
    "text": "since i was already logged into my salesforce i'm going to click allow now that we have a connection",
    "start": "1076960",
    "end": "1082640"
  },
  {
    "text": "established between uh our app between afflow and our",
    "start": "1082640",
    "end": "1088320"
  },
  {
    "text": "salesforce organization the next thing we want to do we want to select which type of objects we want",
    "start": "1088320",
    "end": "1095039"
  },
  {
    "text": "to be sent to aws in our case we want to be sending event driven flows so we have to",
    "start": "1095039",
    "end": "1100320"
  },
  {
    "text": "select self force event then we select the object that we want to capture events",
    "start": "1100320",
    "end": "1107679"
  },
  {
    "text": "from in this case it's going to be the case object next we select the destination in our",
    "start": "1107679",
    "end": "1113919"
  },
  {
    "text": "case it's going to be event bridge if you remember our previous architecture diagram",
    "start": "1113919",
    "end": "1121200"
  },
  {
    "text": "then we are going to create a new partner source let me talk about that a",
    "start": "1121360",
    "end": "1126480"
  },
  {
    "text": "little bit so a partner event source is used by aws partners",
    "start": "1126480",
    "end": "1132080"
  },
  {
    "text": "to send events to an aws account in this case salesforce",
    "start": "1132080",
    "end": "1138799"
  },
  {
    "text": "is a partner with amazon event bridge so we have to generate a partner event source so we're going to",
    "start": "1138799",
    "end": "1146160"
  },
  {
    "text": "click generate event source then in case the payload that is being sent",
    "start": "1146160",
    "end": "1154000"
  },
  {
    "text": "over to aws is greater than 256 kilobyte we want to",
    "start": "1154000",
    "end": "1160640"
  },
  {
    "text": "save that data in an s3 bucket",
    "start": "1160640",
    "end": "1166080"
  },
  {
    "text": "so we have to configure that i'm going to not specify any prefix",
    "start": "1166080",
    "end": "1173520"
  },
  {
    "text": "then i'm going to select next here i'm going to map the fields that i need for my object right now i've",
    "start": "1173520",
    "end": "1180880"
  },
  {
    "text": "selected all the fills but we do have the option of selecting only the",
    "start": "1180880",
    "end": "1185919"
  },
  {
    "text": "fields that is relevant for a use case so i'm going to go with the default and select all the fields",
    "start": "1185919",
    "end": "1192400"
  },
  {
    "text": "then i'm going to click next next and finally create flow",
    "start": "1192400",
    "end": "1200640"
  },
  {
    "start": "1200000",
    "end": "1433000"
  },
  {
    "text": "word of caution before activating the flow you want to make sure that the partner",
    "start": "1200799",
    "end": "1208320"
  },
  {
    "text": "event source that has been generated by app flow is associated with",
    "start": "1208320",
    "end": "1213840"
  },
  {
    "text": "with an event bus so we're going to head over to eventbridge",
    "start": "1213840",
    "end": "1220799"
  },
  {
    "text": "and we see we do have a partner event source that was created by our flow that is in a pending state so what we",
    "start": "1220799",
    "end": "1227200"
  },
  {
    "text": "want to do is select that partner event source and associate it with an event bus and you should get",
    "start": "1227200",
    "end": "1235280"
  },
  {
    "text": "a successful message there so now we go back to event buses and",
    "start": "1235280",
    "end": "1241360"
  },
  {
    "text": "here we go we do have our event bus and looking at our event bus",
    "start": "1241360",
    "end": "1247679"
  },
  {
    "text": "there is an option weight saying schema discovery has not been initiated in this case schema",
    "start": "1247679",
    "end": "1254159"
  },
  {
    "text": "discovery allows us to discover this the the schema of the events that",
    "start": "1254159",
    "end": "1259600"
  },
  {
    "text": "is being sent to eventbridge and we can actually save those schemas",
    "start": "1259600",
    "end": "1265200"
  },
  {
    "text": "into the schema registry but before you can do that you want to turn on schema discovery",
    "start": "1265200",
    "end": "1272000"
  },
  {
    "text": "on that particular event bus so you select the radio button and you turn on schema discovery",
    "start": "1272000",
    "end": "1280000"
  },
  {
    "text": "and the state should switch to started now we can head back to upflow and activate the flow",
    "start": "1280000",
    "end": "1287440"
  },
  {
    "text": "and the status of the flow should switch from it should be switched to active",
    "start": "1287440",
    "end": "1295120"
  },
  {
    "text": "now that we have the partner event source associated with an event bus",
    "start": "1297280",
    "end": "1304400"
  },
  {
    "text": "the next thing we want to do is actually to discover the actual schema we have already turned on schema",
    "start": "1304400",
    "end": "1310960"
  },
  {
    "text": "discovery but since there is no data that has been sent over to the event bus there is no",
    "start": "1310960",
    "end": "1317120"
  },
  {
    "text": "schemas that has been registered for that particular um event bus so that's",
    "start": "1317120",
    "end": "1322960"
  },
  {
    "text": "that's what we're going to do so i am going to go here and if you look at the run history",
    "start": "1322960",
    "end": "1328400"
  },
  {
    "text": "there is no flow run history so i'm going to head back to my app and i am going to submit a support ticket and that was",
    "start": "1328400",
    "end": "1336240"
  },
  {
    "text": "successful now if we come to go back to uh our run",
    "start": "1336240",
    "end": "1341679"
  },
  {
    "text": "history and refresh this we can see that it was near real time right there was an event",
    "start": "1341679",
    "end": "1349120"
  },
  {
    "text": "there was an execution that happened and you can see the amount of data that was transferred now if we go back to event bridge and",
    "start": "1349120",
    "end": "1356880"
  },
  {
    "text": "refresh this and go to discover schema we should be able to see a schema that was discovered",
    "start": "1356880",
    "end": "1362640"
  },
  {
    "text": "for data and looking at this schema you can see",
    "start": "1362640",
    "end": "1368000"
  },
  {
    "text": "that we can see the the json event schema how it looks like for that event we can see the case number created by",
    "start": "1368000",
    "end": "1373360"
  },
  {
    "text": "basically the fields that we selected uh from our flow on id and etc so now that we have",
    "start": "1373360",
    "end": "1382159"
  },
  {
    "text": "schema registry configured we have the event bus configured the next thing we want to do is create",
    "start": "1382159",
    "end": "1389520"
  },
  {
    "text": "an event rule so a rule matches an incoming event and routes them to the",
    "start": "1389520",
    "end": "1395440"
  },
  {
    "text": "targets for processing in our case we want to use the rule to capture an event and route it to",
    "start": "1395440",
    "end": "1402799"
  },
  {
    "text": "a serverless computer which is lambda so that it can be able to send that to our machine learning model and and be",
    "start": "1402799",
    "end": "1409120"
  },
  {
    "text": "able to predict uh or classify that particular case",
    "start": "1409120",
    "end": "1414240"
  },
  {
    "text": "depending on which category it belongs to so in our case we only want to capture salesforce events from appflo",
    "start": "1414240",
    "end": "1423120"
  },
  {
    "text": "for only new events and for us to do that we want to create a",
    "start": "1423120",
    "end": "1429039"
  },
  {
    "text": "row so i'm going to create a row and that rule is going to be associated",
    "start": "1429039",
    "end": "1435679"
  },
  {
    "start": "1433000",
    "end": "1807000"
  },
  {
    "text": "with the partner event bus that i that we created earlier and we are going to call",
    "start": "1435679",
    "end": "1441840"
  },
  {
    "text": "that new row let's see here we're going to call it",
    "start": "1441840",
    "end": "1449760"
  },
  {
    "text": "a flow sfdc classifier it's an event pattern and we're going to create a custom event",
    "start": "1449760",
    "end": "1456840"
  },
  {
    "text": "pattern and in each event that is sent",
    "start": "1456840",
    "end": "1462000"
  },
  {
    "text": "to eventbridge we want to look at the",
    "start": "1462000",
    "end": "1468880"
  },
  {
    "text": "following fields we want to make sure that the change type is create we only want the events",
    "start": "1468880",
    "end": "1475840"
  },
  {
    "text": "that the change type is create to be sent to our lambda function so if someone updates an object we don't want",
    "start": "1475840",
    "end": "1481679"
  },
  {
    "text": "to process that we only want to process this for new events or basically new objects",
    "start": "1481679",
    "end": "1487279"
  },
  {
    "text": "that are created in salesforce so we also look at the status to make sure it's new and the origin is web so",
    "start": "1487279",
    "end": "1496080"
  },
  {
    "text": "when that object is sent to eventbridge we are looking at these fields and if these fields are true if the schema",
    "start": "1496720",
    "end": "1502480"
  },
  {
    "text": "matches what we're looking for whereby the change type is create the status is new and the origin is web then we want to route that event for",
    "start": "1502480",
    "end": "1509840"
  },
  {
    "text": "processing in our lambda function next we select the event source and this is",
    "start": "1509840",
    "end": "1516080"
  },
  {
    "text": "where we select the target where do we want to send that event to we have lots of options we can send it",
    "start": "1516080",
    "end": "1522000"
  },
  {
    "text": "to sql sq uh sql sq is our queuing service that we do have in aws or in our case we're going to send it to",
    "start": "1522000",
    "end": "1528799"
  },
  {
    "text": "lambda function then we're going to select the function which we're going to use to send that event",
    "start": "1528799",
    "end": "1536158"
  },
  {
    "text": "so in our lambda function we are going to select a pre-provision lambda function that i",
    "start": "1536880",
    "end": "1541919"
  },
  {
    "text": "have already called case classifier now i will show you the code for this lambda function it's",
    "start": "1541919",
    "end": "1547919"
  },
  {
    "text": "very straightforward then next i go ahead and click create all right so",
    "start": "1547919",
    "end": "1554640"
  },
  {
    "text": "now we do have a rule that will route events that match",
    "start": "1554640",
    "end": "1560799"
  },
  {
    "text": "this pattern right here to our lambda function",
    "start": "1560799",
    "end": "1566000"
  },
  {
    "text": "next we go back to our application",
    "start": "1566000",
    "end": "1571840"
  },
  {
    "text": "and in this case i want to create another event",
    "start": "1573279",
    "end": "1578480"
  },
  {
    "text": "okay then when we go back to upflow and refresh the run history you can see",
    "start": "1579919",
    "end": "1587200"
  },
  {
    "text": "that we do have an execution that is in progress it's near real time",
    "start": "1587200",
    "end": "1594480"
  },
  {
    "text": "refresh that still in progress",
    "start": "1594799",
    "end": "1601760"
  },
  {
    "text": "and it's successful now when we go back to our lambda function",
    "start": "1602640",
    "end": "1613840"
  },
  {
    "text": "and this is our lambda function",
    "start": "1615279",
    "end": "1618640"
  },
  {
    "text": "go to monitoring so before before i move further so this is this is the lambda configuration page we upload the code as",
    "start": "1621120",
    "end": "1627679"
  },
  {
    "text": "a zip file which i had already done the runtime is already python 3.8 i'm not going to dive deep into",
    "start": "1627679",
    "end": "1633279"
  },
  {
    "text": "how lambda function works and etc but the the most important thing here is to understand that lambda is an event",
    "start": "1633279",
    "end": "1639600"
  },
  {
    "text": "uh compute whereby you know it's invoked when an event is sent to it or in",
    "start": "1639600",
    "end": "1646000"
  },
  {
    "text": "response to an event in our case the event that invokes our lambda function is eventbridge",
    "start": "1646000",
    "end": "1651760"
  },
  {
    "text": "then when you click to monitoring and look at the lambda function logs",
    "start": "1651760",
    "end": "1657840"
  },
  {
    "text": "we have a log stream here and we click on that and you can see that we did receive an",
    "start": "1664000",
    "end": "1669039"
  },
  {
    "text": "event and again i'm going to quickly before the end of the of the webinar",
    "start": "1669039",
    "end": "1674960"
  },
  {
    "text": "or this session show you the code you can see that the the event that i received from aflo",
    "start": "1674960",
    "end": "1682000"
  },
  {
    "text": "has been logged in in the lumber function logs",
    "start": "1682000",
    "end": "1688559"
  },
  {
    "text": "so let's let's take a look at that lambda function code and see what's happening there i'm going to make this bigger",
    "start": "1691200",
    "end": "1699360"
  },
  {
    "text": "so here the first thing i'm doing is i'm setting up the log of course and",
    "start": "1699840",
    "end": "1705039"
  },
  {
    "text": "then i have a function that is called sagemaker what that function is doing is it's capturing the event that is coming",
    "start": "1705039",
    "end": "1711760"
  },
  {
    "text": "in from eventbridge and if you remember the schema and once i",
    "start": "1711760",
    "end": "1716880"
  },
  {
    "text": "capture that event i pass the the the case description that is coming in then i pass that data",
    "start": "1716880",
    "end": "1724640"
  },
  {
    "text": "into a function called process case and what that actually does is take that case and using uh using uh",
    "start": "1724640",
    "end": "1732960"
  },
  {
    "text": "sagemaker sdk in this case the sagemaker predictor object i'm able to send that to a sagemaker",
    "start": "1732960",
    "end": "1741440"
  },
  {
    "text": "endpoint this is the name of my endpoint and i get back a response of what's the category",
    "start": "1741440",
    "end": "1747279"
  },
  {
    "text": "of my uh of that new case and here you can see that this this function here is returning uh an",
    "start": "1747279",
    "end": "1754240"
  },
  {
    "text": "object of type case category so it's it's pretty",
    "start": "1754240",
    "end": "1759520"
  },
  {
    "text": "straightforward so in a nutshell uh that pretty much summarizes",
    "start": "1764679",
    "end": "1770559"
  },
  {
    "text": "that pretty much summarizes um a demo right we had a web application",
    "start": "1770559",
    "end": "1776080"
  },
  {
    "text": "that our customers will go in put in or open a support ticket they'll be able to authenticate with aws",
    "start": "1776080",
    "end": "1782000"
  },
  {
    "text": "cognito and then we have an event that is sent to salesforce uh using cdc the events are sent to app",
    "start": "1782000",
    "end": "1787679"
  },
  {
    "text": "flow and app flow in turn routes that event to event bridge uh then event bridge routes the events",
    "start": "1787679",
    "end": "1794240"
  },
  {
    "text": "to a lambda function which in turn called sagemaker model to to make a prediction",
    "start": "1794240",
    "end": "1801600"
  },
  {
    "text": "with that said thank you for watching",
    "start": "1801600",
    "end": "1808960"
  }
]
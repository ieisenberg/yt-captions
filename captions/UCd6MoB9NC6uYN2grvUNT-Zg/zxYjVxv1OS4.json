[
  {
    "text": "also great I welcome everybody I guess this is the die-hard crew on the last",
    "start": "2389",
    "end": "10349"
  },
  {
    "text": "day of the conference and you're all still here amazing my name is Keith Stewart I'm a",
    "start": "10349",
    "end": "17390"
  },
  {
    "text": "specialist solution architect from AWS for the last two and a half years I've",
    "start": "17390",
    "end": "23130"
  },
  {
    "text": "been specializing in the analytic space in particular EMR but of course nothing",
    "start": "23130",
    "end": "29220"
  },
  {
    "text": "works in a vacuum so EMR works with a bunch of other AWS services and",
    "start": "29220",
    "end": "35360"
  },
  {
    "text": "customers don't just have a problem that's just solved with EMR they typically have other things what I'm",
    "start": "35360",
    "end": "42510"
  },
  {
    "text": "going to talk about today is how to leverage not just EMR but other AWS",
    "start": "42510",
    "end": "47730"
  },
  {
    "text": "services to be able to do predictive analytics machine learning and",
    "start": "47730",
    "end": "53640"
  },
  {
    "text": "predictive analytics just to calibrate my understanding of where people are in",
    "start": "53640",
    "end": "60090"
  },
  {
    "text": "terms of their experience quick show of hands how many use s3 it's probably the",
    "start": "60090",
    "end": "65549"
  },
  {
    "text": "hole okay I'm gonna use EMR okay I'm gonna use spark on EMR okay what about",
    "start": "65549",
    "end": "74010"
  },
  {
    "text": "spark ml on EMR okay what about AWS glue okay smaller",
    "start": "74010",
    "end": "83159"
  },
  {
    "text": "number how about Athena oh wow surprising number",
    "start": "83159",
    "end": "89520"
  },
  {
    "text": "okay what about quick site okay a",
    "start": "89520",
    "end": "95460"
  },
  {
    "text": "smaller number all right so I'm going to try is assuming we have enough time to",
    "start": "95460",
    "end": "100799"
  },
  {
    "text": "talk about the various components why they're advantageous for for your",
    "start": "100799",
    "end": "106799"
  },
  {
    "text": "predictive analytics needs and hopefully if we have time at the end I'll be able to get through a demo and try to show",
    "start": "106799",
    "end": "114299"
  },
  {
    "text": "you how you can quickly go from raw data to training a model making predictions",
    "start": "114299",
    "end": "121850"
  },
  {
    "text": "querying results with Athena and maybe even displaying things with quick sight",
    "start": "121850",
    "end": "129410"
  },
  {
    "text": "all right so let's see okay so what we're gonna cover",
    "start": "129410",
    "end": "135810"
  },
  {
    "text": "predictive analytics of course we're gonna define it you know what is it why it's important these days as time goes",
    "start": "135810",
    "end": "143040"
  },
  {
    "text": "on you know how can you do it at scale you know we're all drowning in data",
    "start": "143040",
    "end": "149270"
  },
  {
    "text": "companies nowadays are dealing with petabytes multiple petabytes sometimes",
    "start": "149270",
    "end": "154680"
  },
  {
    "text": "even more I think was it yesterday there was a company that used our snowmobile",
    "start": "154680",
    "end": "160650"
  },
  {
    "text": "because they they have hundreds of petabytes so so we're we're definitely",
    "start": "160650",
    "end": "165660"
  },
  {
    "text": "in the petabyte age so how do you deal with that that scale also how do you",
    "start": "165660",
    "end": "171180"
  },
  {
    "text": "move quickly in the analytic space prior to a number of the services that we've",
    "start": "171180",
    "end": "176610"
  },
  {
    "text": "offered it was a very painstaking and slow process to be able to do predictive",
    "start": "176610",
    "end": "181860"
  },
  {
    "text": "analytics so we'll talk about how how you move quickly if we break this question down into its components we can",
    "start": "181860",
    "end": "189420"
  },
  {
    "text": "ask how do you do a data lake with s3 and AWS blue so a data Lake of course is",
    "start": "189420",
    "end": "197459"
  },
  {
    "text": "going to give you that capacity to manage petabytes of data then we're",
    "start": "197459",
    "end": "203130"
  },
  {
    "text": "gonna ask the question how do you train a predictive machine learning model in a distributed fashion in other words with",
    "start": "203130",
    "end": "209220"
  },
  {
    "text": "a with a cluster of servers as opposed to your laptop right and so it was",
    "start": "209220",
    "end": "216030"
  },
  {
    "text": "specifically focusing on EMR apache spark and spark ml and then we'll use",
    "start": "216030",
    "end": "221670"
  },
  {
    "text": "the zeppelin notebook to to be able to quickly put together the the code and",
    "start": "221670",
    "end": "228269"
  },
  {
    "text": "then how do you do distributed sequel queries over potentially petabytes of",
    "start": "228269",
    "end": "234209"
  },
  {
    "text": "data right and that of course you can use athena for and then how do you",
    "start": "234209",
    "end": "239220"
  },
  {
    "text": "visualize it a quick site so and then at the end we'll do depending on how much time we have we'll try to get as quickly",
    "start": "239220",
    "end": "245489"
  },
  {
    "text": "through all the the things we talked about through a demo okay",
    "start": "245489",
    "end": "251010"
  },
  {
    "text": "so what is predictive analytics why is it important so just a few definitions",
    "start": "251010",
    "end": "256549"
  },
  {
    "text": "analytics is really the discovery interpretation and communication of meaningful patterns in data predictive",
    "start": "256549",
    "end": "265289"
  },
  {
    "text": "analytics goes one step further it brings in a bunch of statistical rigorous statistical",
    "start": "265289",
    "end": "271070"
  },
  {
    "text": "techniques from areas like predictive modeling machine learning data mining",
    "start": "271070",
    "end": "276480"
  },
  {
    "text": "and you use that to analyze the current base of data as well as historical data",
    "start": "276480",
    "end": "283230"
  },
  {
    "text": "and learn patterns within that data to be able to make predictions or",
    "start": "283230",
    "end": "288780"
  },
  {
    "text": "classifications of what we call inferences and you can see examples of",
    "start": "288780",
    "end": "296940"
  },
  {
    "text": "what customers are trying to do with things like you know questions like which customers are likely to be the",
    "start": "296940",
    "end": "301980"
  },
  {
    "text": "most profitable right that's an important question how much revenue should I expect from this particular",
    "start": "301980",
    "end": "307950"
  },
  {
    "text": "customer which customers are likely to churn right if we're not doing a great",
    "start": "307950",
    "end": "313830"
  },
  {
    "text": "job keeping customers happy there's a risk we could lose them so what's the what's the probability for for certain",
    "start": "313830",
    "end": "320610"
  },
  {
    "text": "customers among all the customers we have what which are likely to respond to our next big offer and then what's the",
    "start": "320610",
    "end": "328500"
  },
  {
    "text": "probability that a specific customer will respond to a specific offer right",
    "start": "328500",
    "end": "334380"
  },
  {
    "text": "and you can look at the product or service offerings that you have and you",
    "start": "334380",
    "end": "341070"
  },
  {
    "text": "can leverage predictive analytics to ask questions like what products should we offer or develop right what items are",
    "start": "341070",
    "end": "348780"
  },
  {
    "text": "likely to be purchased together it's often called basket analysis and then",
    "start": "348780",
    "end": "354360"
  },
  {
    "text": "there's your operations your business operations you'd like to understand things like are the metrics for our",
    "start": "354360",
    "end": "361110"
  },
  {
    "text": "particular service are they nominal or is there something anomalous about them all right and you'd like to know that as",
    "start": "361110",
    "end": "367110"
  },
  {
    "text": "as soon as possible and then if you're running equipment what's the probability",
    "start": "367110",
    "end": "373410"
  },
  {
    "text": "that it's likely to fail within the next within the near future okay so things",
    "start": "373410",
    "end": "381900"
  },
  {
    "text": "are changing in the business landscape and in terms of data processing and predictive analytics is becoming",
    "start": "381900",
    "end": "388680"
  },
  {
    "text": "increasingly vital for the last umpteen years companies have been accumulating",
    "start": "388680",
    "end": "396690"
  },
  {
    "text": "lots and lots of data a lot of transactional data now there's social media there's IOT",
    "start": "396690",
    "end": "404090"
  },
  {
    "text": "devices generating data so companies have been accumulating data for a long time and they're you know they've",
    "start": "404090",
    "end": "411320"
  },
  {
    "text": "they're sitting on all this data and then wondering you know how can they get value out of that how can they get",
    "start": "411320",
    "end": "417140"
  },
  {
    "text": "insights we've built with the technologies I've talked about AWS has",
    "start": "417140",
    "end": "423320"
  },
  {
    "text": "built Big Data technologies or analytics as we call them to address the data",
    "start": "423320",
    "end": "428720"
  },
  {
    "text": "management and the processing of that data but there's some real pressure now",
    "start": "428720",
    "end": "436730"
  },
  {
    "text": "to be faster than your competitor to be able to take advantage of your",
    "start": "436730",
    "end": "442370"
  },
  {
    "text": "your data and insights from that data to better address question a better treat",
    "start": "442370",
    "end": "450140"
  },
  {
    "text": "customers and give them a more optimal experience to run things more efficiently prevent you know",
    "start": "450140",
    "end": "457010"
  },
  {
    "text": "preventative maintenance on equipment that that might die and so we there's an increasing pressure to do that and so",
    "start": "457010",
    "end": "464990"
  },
  {
    "text": "you want to leverage all this accumulated data and and do classifications and and so on and",
    "start": "464990",
    "end": "471590"
  },
  {
    "text": "there's a desire to evolve now if we take a look at the kind of the history",
    "start": "471590",
    "end": "477590"
  },
  {
    "text": "of the predictive of analytics you know oh we used to be satisfied with doing",
    "start": "477590",
    "end": "484130"
  },
  {
    "text": "quarterly reports monthly reports maybe even weekly reports but that's a",
    "start": "484130",
    "end": "489500"
  },
  {
    "text": "rearview mirror perspective on your data you're asking you're trying to answer questions what happened in the past",
    "start": "489500",
    "end": "496340"
  },
  {
    "text": "right that has value but it's not as important as what's going to happen next",
    "start": "496340",
    "end": "501920"
  },
  {
    "text": "right so companies are now trying to understand in real time through alerts",
    "start": "501920",
    "end": "510040"
  },
  {
    "text": "what's happening right now on our website right what's happening right now",
    "start": "510040",
    "end": "515090"
  },
  {
    "text": "with this specific customer you know are they are they happy are they said and",
    "start": "515090",
    "end": "520640"
  },
  {
    "text": "and you know equipment etc you want to know instantaneously right now what's happening but even that's not getting",
    "start": "520640",
    "end": "528490"
  },
  {
    "text": "good enough for companies a lot of them want to be able to make forecasts and",
    "start": "528490",
    "end": "533680"
  },
  {
    "text": "move into the predictive analytics space so it's it's clearly an evolution of what companies expect now from their",
    "start": "533680",
    "end": "541390"
  },
  {
    "text": "data and and you want to be able to take advantage of the tools that can do that",
    "start": "541390",
    "end": "546510"
  },
  {
    "text": "okay so how do you do this at scale right we talked about petabyte and more data how do you do it with agility we",
    "start": "546510",
    "end": "554830"
  },
  {
    "text": "like to think of the big data problem space in these kind of abstract phases",
    "start": "554830",
    "end": "561550"
  },
  {
    "text": "of course there's storage you've got to have your data in some place in order to be able to make do you make analyses and",
    "start": "561550",
    "end": "569110"
  },
  {
    "text": "make predictions from it so storage has to be addressed and there's lots of different solutions for that you want to",
    "start": "569110",
    "end": "575410"
  },
  {
    "text": "be able to process it do ETL transform the data clean it up and that turns out",
    "start": "575410",
    "end": "581740"
  },
  {
    "text": "to be a significant percentage of the time and then you want to be able to do the machine learning and inferencing and",
    "start": "581740",
    "end": "588190"
  },
  {
    "text": "then finally be able to visualize results so that you can quickly identify situations those abstract components",
    "start": "588190",
    "end": "597070"
  },
  {
    "text": "have solutions out there lots of open source solutions we have lots of",
    "start": "597070",
    "end": "603070"
  },
  {
    "text": "customers running these open source solutions on ec2 for example but what we",
    "start": "603070",
    "end": "610180"
  },
  {
    "text": "offer is aimed at is managed services which is aiming to relieve the heavy",
    "start": "610180",
    "end": "618250"
  },
  {
    "text": "lifting that that customers have so instead of taking the the kind of the",
    "start": "618250",
    "end": "625000"
  },
  {
    "text": "Wild West of the open source technologies trying to harness that deploy it maintain it etc we provide",
    "start": "625000",
    "end": "632500"
  },
  {
    "text": "systems that are fully managed you just launch them take advantage of them and",
    "start": "632500",
    "end": "637860"
  },
  {
    "text": "you let us worry about babysitting the servers that are behind those and we",
    "start": "637860",
    "end": "644140"
  },
  {
    "text": "even include now of course a number of server las' applications so managed",
    "start": "644140",
    "end": "649930"
  },
  {
    "text": "services are a great way to gain agility because you're going to save yourself a",
    "start": "649930",
    "end": "655240"
  },
  {
    "text": "lot of headaches and a lot of time by having systems that are automated in their deployment and",
    "start": "655240",
    "end": "661200"
  },
  {
    "text": "and configuration okay so if we take those those abstract components",
    "start": "661200",
    "end": "669080"
  },
  {
    "text": "collection or ingestion storage processing or analysis and then consuming or visualizing the data we",
    "start": "669080",
    "end": "676470"
  },
  {
    "text": "have a lot of solutions and you'll see both open source and managed services",
    "start": "676470",
    "end": "681660"
  },
  {
    "text": "here I'm obviously not going to go through all these but we have a lot of choices and there are there are",
    "start": "681660",
    "end": "690300"
  },
  {
    "text": "different trade-offs with the different options so if you're going to collect and store the data there are differences",
    "start": "690300",
    "end": "698310"
  },
  {
    "text": "in terms of latency in terms of the durability and and so on and of course",
    "start": "698310",
    "end": "705870"
  },
  {
    "text": "cost and so so if you're if you're dealing with data with different",
    "start": "705870",
    "end": "712410"
  },
  {
    "text": "temperatures as we show on here temperatures meaning you know the velocity of the data how quickly it",
    "start": "712410",
    "end": "718440"
  },
  {
    "text": "needs to be captured and dealt with or whether it's cold and and so that can",
    "start": "718440",
    "end": "724230"
  },
  {
    "text": "often determine the the pricing and the choice of technology that you you'll use okay so we're not going to cover all",
    "start": "724230",
    "end": "731250"
  },
  {
    "text": "those I'm going to focus on these components here Amazon s3 AWS glue which",
    "start": "731250",
    "end": "738150"
  },
  {
    "text": "are the the storage and ETL parts of the of the solution spark and spark ml on",
    "start": "738150",
    "end": "747030"
  },
  {
    "text": "EMR and in Athena I'm not going to talk about AI but that's a solution that's",
    "start": "747030",
    "end": "753630"
  },
  {
    "text": "out there as well and we have quick site as well so why s3 so s3 is an excellent",
    "start": "753630",
    "end": "762240"
  },
  {
    "text": "solution for a data Lake it doesn't care what the data is whether it's a single byte or a five terabyte video file so",
    "start": "762240",
    "end": "771120"
  },
  {
    "text": "it's it will hold any any kind of data it's scalable and elastic if any of you",
    "start": "771120",
    "end": "777240"
  },
  {
    "text": "have run Hadoop clusters on Prem you know what a pain it is to have to stay",
    "start": "777240",
    "end": "783210"
  },
  {
    "text": "ahead of your storage requirements you know you have to have enough capacity through say HDFS to give you three X",
    "start": "783210",
    "end": "791310"
  },
  {
    "text": "replication of your data if you leverage the coupling of storage and compute the DMR",
    "start": "791310",
    "end": "797230"
  },
  {
    "text": "provides using s3 as the backend persistence that will take care of your",
    "start": "797230",
    "end": "802509"
  },
  {
    "text": "storage you don't need to be on top of how fast your data is growing because s3",
    "start": "802509",
    "end": "807910"
  },
  {
    "text": "is there to grow elastically to accommodate that data 11900 Tech ting your data when you put",
    "start": "807910",
    "end": "815499"
  },
  {
    "text": "it on s3 and this is the the bandwidth is an interesting consideration there's",
    "start": "815499",
    "end": "822279"
  },
  {
    "text": "no upper limit on the aggregate inbound bandwidth going into s3 the only limit",
    "start": "822279",
    "end": "829269"
  },
  {
    "text": "is the number of hosts and processes and threads that are simultaneously talking",
    "start": "829269",
    "end": "834759"
  },
  {
    "text": "to s3 so if you need higher bandwidth you need more data going in in a shorter",
    "start": "834759",
    "end": "840670"
  },
  {
    "text": "period of time have more hosts and and processes and threads sending that data",
    "start": "840670",
    "end": "846279"
  },
  {
    "text": "to s3 all of that bandwidth will be accommodated there's no upper limit on that extremely little cost two point",
    "start": "846279",
    "end": "853119"
  },
  {
    "text": "three cents per gigabyte month or 23 bucks per terabyte and virtually all the",
    "start": "853119",
    "end": "860470"
  },
  {
    "text": "AWS services take advantage of s3 it's a foundational service rock-solid it's",
    "start": "860470",
    "end": "866769"
  },
  {
    "text": "ideal for a data Lake and this just summarizes that the benefits including",
    "start": "866769",
    "end": "874600"
  },
  {
    "text": "things like performance and and it's integrated with all the other AWS services and it's easy to use",
    "start": "874600",
    "end": "882459"
  },
  {
    "text": "AWS glue so luke came out I guess it was what's earlier this year and glue is",
    "start": "882459",
    "end": "891879"
  },
  {
    "text": "aiming to reduce the heavy lifting involved in the ETL and and processing",
    "start": "891879",
    "end": "899110"
  },
  {
    "text": "and schema tizen of your data taking semi-structured or unstructured data and turning it into",
    "start": "899110",
    "end": "906569"
  },
  {
    "text": "structure superimposing a structure on it that you can then work with in terms",
    "start": "906569",
    "end": "912699"
  },
  {
    "text": "of queries and and processing so but a really key part and what we'll take a",
    "start": "912699",
    "end": "919089"
  },
  {
    "text": "look closely at this the really key part is the data catalog so the glue data",
    "start": "919089",
    "end": "924699"
  },
  {
    "text": "catalog is a service that will crawl your data you you simply indicate which data",
    "start": "924699",
    "end": "931780"
  },
  {
    "text": "sources as three buckets for example you tell it where to crawl and what it'll do",
    "start": "931780",
    "end": "938950"
  },
  {
    "text": "is on an either on a recurring basis or on a triggered basis when you launch it",
    "start": "938950",
    "end": "944380"
  },
  {
    "text": "it will walk it will crawl through your data think of that CSV Parque etc and",
    "start": "944380",
    "end": "952390"
  },
  {
    "text": "then it will generate this schema for you you say you don't need to do X data",
    "start": "952390",
    "end": "957670"
  },
  {
    "text": "exploration to figure out what kind of schema to superimpose on your data the",
    "start": "957670",
    "end": "962740"
  },
  {
    "text": "data catalog will do that and it's pretty quick so once your data lands on s3 you launch glue on it which is a",
    "start": "962740",
    "end": "972430"
  },
  {
    "text": "fully managed service and it will turn that data into something that you can then very quickly start to query and",
    "start": "972430",
    "end": "978460"
  },
  {
    "text": "work with in a in a structured way it'll also do transformation ETL we won't get",
    "start": "978460",
    "end": "986290"
  },
  {
    "text": "into that today as I said you can do it on a recurring basis with a job scheduler it runs on top of the patchy",
    "start": "986290",
    "end": "993700"
  },
  {
    "text": "spark so it's very fast and integrated with a bunch of other data stores and",
    "start": "993700",
    "end": "998770"
  },
  {
    "text": "you can you can work with the data through a JDBC connection right so you'd",
    "start": "998770",
    "end": "1004380"
  },
  {
    "text": "discover it so it manages the metadata so those of you familiar with Hadoop and",
    "start": "1004380",
    "end": "1012180"
  },
  {
    "text": "an EMR it will create the meta meta data",
    "start": "1012180",
    "end": "1017400"
  },
  {
    "text": "entries corresponding to your unstructured and semi-structured data the hive meta store and so and and and",
    "start": "1017400",
    "end": "1026970"
  },
  {
    "text": "then that hive meta store becomes available for a bunch of other systems like EMR and and and spark and presto",
    "start": "1026970",
    "end": "1037410"
  },
  {
    "text": "and and so on so that's just a",
    "start": "1037410",
    "end": "1043079"
  },
  {
    "text": "screenshot but we'll get into the demo on this we've we've extended it now so",
    "start": "1043079",
    "end": "1049740"
  },
  {
    "text": "you can search the search the metadata to find your data sources so a lot of us",
    "start": "1049740",
    "end": "1056340"
  },
  {
    "text": "will be accumulating multiple different types of data and we may tag those in in different",
    "start": "1056340",
    "end": "1062419"
  },
  {
    "text": "ways but the glue data catalog allows you to find those through through",
    "start": "1062419",
    "end": "1067850"
  },
  {
    "text": "searching we talked about connections classifications so when it's schema",
    "start": "1067850",
    "end": "1075799"
  },
  {
    "text": "tizen the data it's looking at the entries within the columns okay if it's",
    "start": "1075799",
    "end": "1081140"
  },
  {
    "text": "like a CSV or or JSON or whatever it'll it'll scan the data the sample of data",
    "start": "1081140",
    "end": "1088399"
  },
  {
    "text": "in the columns and from that automatically infer what's the appropriate data type for that column",
    "start": "1088399",
    "end": "1095510"
  },
  {
    "text": "and it'll add that to the schema right and it manages versions okay so it",
    "start": "1095510",
    "end": "1102860"
  },
  {
    "text": "populates the hive using hive DDL and you can also do bulk imports and we",
    "start": "1102860",
    "end": "1110120"
  },
  {
    "text": "talked about crawlers all right so the crawlers they think they have built-in classifiers to crawl through things like",
    "start": "1110120",
    "end": "1118039"
  },
  {
    "text": "JSON and and XML and and park' etc but you can also design your own classifiers",
    "start": "1118039",
    "end": "1124669"
  },
  {
    "text": "so if you have some oddball data format you can do do that and then it'll it'll",
    "start": "1124669",
    "end": "1130309"
  },
  {
    "text": "take advantage of those and extracts the schemas okay and you'll be able to",
    "start": "1130309",
    "end": "1138490"
  },
  {
    "text": "contribute to the open source any any type of crawlers that you think would be generally useful okay it'll work with",
    "start": "1138490",
    "end": "1146889"
  },
  {
    "text": "partitions so if you're familiar with Hadoop and and familiar with how EMR can",
    "start": "1146889",
    "end": "1153230"
  },
  {
    "text": "can partition the data on something like HDFS or s3 the the particularly time",
    "start": "1153230",
    "end": "1161480"
  },
  {
    "text": "series data and and so on blue will automatically pick pick those up as well",
    "start": "1161480",
    "end": "1168519"
  },
  {
    "text": "right you can run them on schedule you can do you can have it triggered by schema changes and it's serverless",
    "start": "1168519",
    "end": "1175909"
  },
  {
    "text": "there's no server for you to spin up and babysit Amazon EMR I think a good number",
    "start": "1175909",
    "end": "1183380"
  },
  {
    "text": "of you familiar with that this is our scalable hadoop as a service that's something of a misnomer though it's",
    "start": "1183380",
    "end": "1189950"
  },
  {
    "text": "really more of a multi massively parallel processing platform MPP platform it runs",
    "start": "1189950",
    "end": "1197480"
  },
  {
    "text": "a variety of MPP frameworks not just Hadoop it does spark it also does presto",
    "start": "1197480",
    "end": "1204820"
  },
  {
    "text": "and a bunch of other MPP frameworks in",
    "start": "1204820",
    "end": "1211279"
  },
  {
    "text": "HBase as well it's easy to use it's a managed service you focus in terms of",
    "start": "1211279",
    "end": "1217879"
  },
  {
    "text": "the cluster and how big you want it to be you don't worry about individual servers it's on demand so you can spin",
    "start": "1217879",
    "end": "1225289"
  },
  {
    "text": "up a cluster anytime and you can shut it down anytime and you cease to pay as the hourly I guess now we're charging by the",
    "start": "1225289",
    "end": "1233330"
  },
  {
    "text": "second so you don't have you you can use it for less than an hour and and save",
    "start": "1233330",
    "end": "1238850"
  },
  {
    "text": "money compared to to what it was previously because we were rounding it down to the nearest second and there's",
    "start": "1238850",
    "end": "1247639"
  },
  {
    "text": "different ways to pay for things you can have reserved instances based on a commitment to use certain types for the",
    "start": "1247639",
    "end": "1255409"
  },
  {
    "text": "Year spot pricing so it can automatically take advantage of the spot tool right the instances that are not",
    "start": "1255409",
    "end": "1262580"
  },
  {
    "text": "yet allocated to customers and it works with a variety of file systems most of",
    "start": "1262580",
    "end": "1267980"
  },
  {
    "text": "our customers however are using s3 because of the economics and all the other benefits of s3 and the high",
    "start": "1267980",
    "end": "1274519"
  },
  {
    "text": "performance and now recently with 5.8",
    "start": "1274519",
    "end": "1279740"
  },
  {
    "text": "since since 5.8 we're now up to 5.10 of EMR it works with the AWS glue data",
    "start": "1279740",
    "end": "1288259"
  },
  {
    "text": "catalog and we'll walk through an example of that with with EMR and of",
    "start": "1288259",
    "end": "1295220"
  },
  {
    "text": "course end-to-end security very popular lots and lots of customers this is just",
    "start": "1295220",
    "end": "1300860"
  },
  {
    "text": "a small sample of the big name customers that are using using EMR on a daily basis some of them with multiple",
    "start": "1300860",
    "end": "1309769"
  },
  {
    "text": "petabytes of data SPARC ml is very powerful we you know a spark spark ml",
    "start": "1309769",
    "end": "1317299"
  },
  {
    "text": "Apache spark ml includes a whole host of different just models that you can train with in our",
    "start": "1317299",
    "end": "1324700"
  },
  {
    "text": "demo we'll walk through an example with decision trees but it includes",
    "start": "1324700",
    "end": "1330630"
  },
  {
    "text": "capabilities of implementing what's called a pipeline where you can take data that's represented as RDD as data",
    "start": "1330630",
    "end": "1340600"
  },
  {
    "text": "frames and you can cue up or link together a bunch of transformations on",
    "start": "1340600",
    "end": "1346830"
  },
  {
    "text": "those data frames and manage that as a first-order entity you could persist the",
    "start": "1346830",
    "end": "1353410"
  },
  {
    "text": "pipeline and then retrieve it in some other some other application and immediately use whatever model was",
    "start": "1353410",
    "end": "1360070"
  },
  {
    "text": "trained with that pipeline okay",
    "start": "1360070",
    "end": "1365590"
  },
  {
    "text": "decision trees everybody know what decision trees are this is a simple",
    "start": "1365590",
    "end": "1370720"
  },
  {
    "text": "example showing you know you have a bunch of predictors or attributes and then you'll",
    "start": "1370720",
    "end": "1378100"
  },
  {
    "text": "have a target attribute that you're trying to predict based on some inherent pattern in in those other attributes and",
    "start": "1378100",
    "end": "1385780"
  },
  {
    "text": "essentially what is doing is building a decision tree and in memory the branching structure where there's",
    "start": "1385780",
    "end": "1391990"
  },
  {
    "text": "criteria that have to be checked as you as you work through the work through the",
    "start": "1391990",
    "end": "1397750"
  },
  {
    "text": "the tree to categorize or make predictions on the attribute another",
    "start": "1397750",
    "end": "1403270"
  },
  {
    "text": "example this one's a kind of a financial one bank loan right offs so so you can",
    "start": "1403270",
    "end": "1408520"
  },
  {
    "text": "look at balances the age of the person whether they're employed or not and then",
    "start": "1408520",
    "end": "1414310"
  },
  {
    "text": "make predictions as to whether there'll be a bank write-off and that it makes",
    "start": "1414310",
    "end": "1419500"
  },
  {
    "text": "the point down here that you take features together as vectors so most SAR",
    "start": "1419500",
    "end": "1426700"
  },
  {
    "text": "nearly all machine learning works with numerical vectors you can you can train",
    "start": "1426700",
    "end": "1431950"
  },
  {
    "text": "on Lian categorical data and and string data but those strings have to be first",
    "start": "1431950",
    "end": "1437200"
  },
  {
    "text": "converted into into indexes and into numerical values and then bundle",
    "start": "1437200",
    "end": "1443350"
  },
  {
    "text": "together to create your feature that will inform the model okay quick sight",
    "start": "1443350",
    "end": "1451420"
  },
  {
    "text": "fast business analytics wide variety of data visualizations",
    "start": "1451420",
    "end": "1457170"
  },
  {
    "text": "works with a wide variety of data sources you can perform ad-hoc analyses",
    "start": "1457170",
    "end": "1462560"
  },
  {
    "text": "and and supports hundreds of thousands of users we have an enterprise version so you can give your whole company",
    "start": "1462560",
    "end": "1468920"
  },
  {
    "text": "access to quick site and we've expanded the the visualizations and this allows",
    "start": "1468920",
    "end": "1476730"
  },
  {
    "text": "because it runs in the cloud where your data is and where your computational results are it's very fast at taking",
    "start": "1476730",
    "end": "1484050"
  },
  {
    "text": "that data you're not having to download data or move it around a quick site will",
    "start": "1484050",
    "end": "1489600"
  },
  {
    "text": "work with it immediately because both of them are in the in the cloud right",
    "start": "1489600",
    "end": "1495480"
  },
  {
    "text": "that's just a summary of integrated cloud native super fast and easy",
    "start": "1495480",
    "end": "1501440"
  },
  {
    "text": "cost-effective it's I think it's down to like nine dollars per seat per month so",
    "start": "1501440",
    "end": "1507330"
  },
  {
    "text": "very inexpensive it's not it's not a tableau or a micro strategy or looker",
    "start": "1507330",
    "end": "1513390"
  },
  {
    "text": "it's it's it's not meant for power users that like to really play around with",
    "start": "1513390",
    "end": "1520650"
  },
  {
    "text": "data what it is is for for the average user to be able to easily take take data",
    "start": "1520650",
    "end": "1527280"
  },
  {
    "text": "that they can see in the clot in their account in the cloud and very quickly put together visualizations and be able",
    "start": "1527280",
    "end": "1534360"
  },
  {
    "text": "to share those with their colleagues all without being a data scientist ok one of",
    "start": "1534360",
    "end": "1541740"
  },
  {
    "text": "the capabilities underlying quick site is a engine called spice which is super",
    "start": "1541740",
    "end": "1549030"
  },
  {
    "text": "fast parallel in-memory computational engine I think that's why we shortened",
    "start": "1549030",
    "end": "1556350"
  },
  {
    "text": "it to spice but essentially it's a data cube if you want to think of it that way running in memory okay so so data that",
    "start": "1556350",
    "end": "1564750"
  },
  {
    "text": "you want to analyze even on s3 which is persisted data can be pulled into spice",
    "start": "1564750",
    "end": "1570780"
  },
  {
    "text": "and then you can interrogate that in a variety of ways generating a variety of different visualizations one after the",
    "start": "1570780",
    "end": "1579060"
  },
  {
    "text": "other without without any delay okay so let's",
    "start": "1579060",
    "end": "1585120"
  },
  {
    "text": "do a demo here alright so just to set",
    "start": "1585120",
    "end": "1590160"
  },
  {
    "text": "things up we're gonna we're gonna pretend we're a car company called Lux cars right and we're we're going to be",
    "start": "1590160",
    "end": "1598860"
  },
  {
    "text": "bringing a fancy expensive car to market we'll call it the Lux mobile but we want",
    "start": "1598860",
    "end": "1606300"
  },
  {
    "text": "to do some intelligent marketing we want to leverage predictive analytics to understand who is going to be the best",
    "start": "1606300",
    "end": "1613400"
  },
  {
    "text": "type of customer for this ideally we want customers that we think have higher",
    "start": "1613400",
    "end": "1619559"
  },
  {
    "text": "than average incomes they have high enough thing comes to afford our car we",
    "start": "1619559",
    "end": "1625320"
  },
  {
    "text": "don't want to waste our time advertising to to people who are unlikely to buy it right so we want to focus the marketing",
    "start": "1625320",
    "end": "1633000"
  },
  {
    "text": "on on wealthy people and we're gonna have we're going to take advantage of",
    "start": "1633000",
    "end": "1639000"
  },
  {
    "text": "some demographic data where we have some characteristics for the geography that",
    "start": "1639000",
    "end": "1646290"
  },
  {
    "text": "we want to target things like the age of the individual the the number of years",
    "start": "1646290",
    "end": "1652500"
  },
  {
    "text": "of education whatever degree they had you know what industries they work in all those kind of demographic data we",
    "start": "1652500",
    "end": "1659400"
  },
  {
    "text": "have those but we don't know their incomes right so what we want to be able to do is infer their income based on",
    "start": "1659400",
    "end": "1665820"
  },
  {
    "text": "those other attributes not infer in terms of precise values but in a kind of",
    "start": "1665820",
    "end": "1671250"
  },
  {
    "text": "binary fashion now the data set I'm using in this demo is an old old data",
    "start": "1671250",
    "end": "1676500"
  },
  {
    "text": "set so the the cutoff for wealthy I guess is 50k so it's an old data set but",
    "start": "1676500",
    "end": "1683640"
  },
  {
    "text": "it serves our purposes to illustrate right so so we need to predict salary or",
    "start": "1683640",
    "end": "1691140"
  },
  {
    "text": "the salary salary category income category from the from the demographic data so how are we going to approach",
    "start": "1691140",
    "end": "1698190"
  },
  {
    "text": "this okay so we're going to take US Census income data and move that into",
    "start": "1698190",
    "end": "1705360"
  },
  {
    "text": "the cloud so we'll see that process we want to schema ties the data so so the",
    "start": "1705360",
    "end": "1711420"
  },
  {
    "text": "data is is in file format it's in CSV format but we want to schematize it we",
    "start": "1711420",
    "end": "1717390"
  },
  {
    "text": "want to superimpose at a tabular structure on it that we can then leverage to to do things like machine",
    "start": "1717390",
    "end": "1724140"
  },
  {
    "text": "learning so we want to train a spark machine learning model on the data and",
    "start": "1724140",
    "end": "1729779"
  },
  {
    "text": "then we want to do batch prediction given a bunch of a bunch of individuals",
    "start": "1729779",
    "end": "1735890"
  },
  {
    "text": "anonymized individuals of course with with without income data we want to be",
    "start": "1735890",
    "end": "1741600"
  },
  {
    "text": "able to use our trained model to figure out what category are they in right and",
    "start": "1741600",
    "end": "1747870"
  },
  {
    "text": "this this step I actually didn't get to in the demo so where it will skip that the idea was that if you combined income",
    "start": "1747870",
    "end": "1757950"
  },
  {
    "text": "predictions with state or zip codes for",
    "start": "1757950",
    "end": "1763200"
  },
  {
    "text": "example you can and you had an idea of the number of individuals that are in",
    "start": "1763200",
    "end": "1768510"
  },
  {
    "text": "the upper category for that zip code you",
    "start": "1768510",
    "end": "1773639"
  },
  {
    "text": "could compute something like a a wealth density right you could look to see what what what kind of above average income",
    "start": "1773639",
    "end": "1780450"
  },
  {
    "text": "per zip code per square mile would be available and in that that",
    "start": "1780450",
    "end": "1786269"
  },
  {
    "text": "could drive your marketing and then we want to visualize predictions okay and",
    "start": "1786269",
    "end": "1792480"
  },
  {
    "text": "then share the results with our marketing director that looks cars okay",
    "start": "1792480",
    "end": "1797909"
  },
  {
    "text": "so we're going to take data that's sitting out on the US out on a website",
    "start": "1797909",
    "end": "1803490"
  },
  {
    "text": "and actually isn't the it's the US census data but it's at the UCI machine learning repository well we're gonna in",
    "start": "1803490",
    "end": "1812130"
  },
  {
    "text": "AWS we're gonna spin up an ec2 instance download that data unpack it get it into",
    "start": "1812130",
    "end": "1818880"
  },
  {
    "text": "S into an s3 bucket okay and then we're",
    "start": "1818880",
    "end": "1824880"
  },
  {
    "text": "going to run glue on it to schematize it to be able to create entries in the blue",
    "start": "1824880",
    "end": "1832649"
  },
  {
    "text": "data catalog in the meta meta store that we can then take advantage of we're",
    "start": "1832649",
    "end": "1838590"
  },
  {
    "text": "going to have any Amazon EMR cluster running the Zeppelin notebook and spark",
    "start": "1838590",
    "end": "1845010"
  },
  {
    "text": "spark machine learning and so then we're going to take that data that the trainer",
    "start": "1845010",
    "end": "1850830"
  },
  {
    "text": "training portion trained a decision tree using SPARQL and",
    "start": "1850830",
    "end": "1857220"
  },
  {
    "text": "then we're going to take other the customers for which we don't know income and make predictions and store those",
    "start": "1857220",
    "end": "1864440"
  },
  {
    "text": "will query them with Athena and then and",
    "start": "1864440",
    "end": "1869730"
  },
  {
    "text": "then depending on time we'll get to quick site and visualize them okay and",
    "start": "1869730",
    "end": "1874890"
  },
  {
    "text": "then with one of the things you can do with quick site is build these stories so you can put together a particular",
    "start": "1874890",
    "end": "1882000"
  },
  {
    "text": "perspective on the data it's web-based so you can share that with with colleagues such as our marketing",
    "start": "1882000",
    "end": "1888510"
  },
  {
    "text": "director okay so let's build this you probably can't",
    "start": "1888510",
    "end": "1900900"
  },
  {
    "text": "read that right tell me when that gets",
    "start": "1900900",
    "end": "1906179"
  },
  {
    "text": "readable for people at the back is that",
    "start": "1906179",
    "end": "1911820"
  },
  {
    "text": "good to large no okay so I won't bother",
    "start": "1911820",
    "end": "1922590"
  },
  {
    "text": "spinning up an ec2 instance I'm sure you guys have done that but I have one already running so let me let me connect",
    "start": "1922590",
    "end": "1930510"
  },
  {
    "text": "to that actually this text you probably",
    "start": "1930510",
    "end": "1936210"
  },
  {
    "text": "can't read",
    "start": "1936210",
    "end": "1938630"
  },
  {
    "text": "and that needs to be larger Jim it's",
    "start": "1941320",
    "end": "1947629"
  },
  {
    "text": "readable initially on my screen but when it wouldn't attaches to the high-definition projector it scrunches",
    "start": "1947629",
    "end": "1956090"
  },
  {
    "text": "it down okay so all right so so with ec2",
    "start": "1956090",
    "end": "1964249"
  },
  {
    "text": "you know you need to SSH into it with your key so we're going to do that same",
    "start": "1964249",
    "end": "1972019"
  },
  {
    "text": "thing I've got network connectivity",
    "start": "1972019",
    "end": "1975879"
  },
  {
    "text": "all right well that might have been the tunnel okay Oh looks like I may already okay I'm",
    "start": "1981150",
    "end": "1989340"
  },
  {
    "text": "already logged in on this this terminal here okay so what we would do is use a double you",
    "start": "1989340",
    "end": "1998190"
  },
  {
    "text": "get to pull the data down I've already done that and I've got the data in the C",
    "start": "1998190",
    "end": "2005870"
  },
  {
    "text": "Census income test",
    "start": "2005870",
    "end": "2010930"
  },
  {
    "text": "all right so we would some of you or most of you perhaps are already familiar with this but we could create a bucket",
    "start": "2033610",
    "end": "2040430"
  },
  {
    "text": "using our CLI so we say AWS s3 make bucket we give it a s3 URI and we'll",
    "start": "2040430",
    "end": "2049370"
  },
  {
    "text": "call it test bucket okay no probably",
    "start": "2049370",
    "end": "2061159"
  },
  {
    "text": "because it I need to okay so that that",
    "start": "2061160",
    "end": "2066919"
  },
  {
    "text": "was successful and then we could do AWS s3 ECP and we'll take the since this",
    "start": "2066920",
    "end": "2082510"
  },
  {
    "text": "income data and put that into our bucket",
    "start": "2082990",
    "end": "2091240"
  },
  {
    "text": "that is",
    "start": "2091240",
    "end": "2094510"
  },
  {
    "text": "and we'll call it we could call it training okay so that date is up on in",
    "start": "2097130",
    "end": "2106070"
  },
  {
    "text": "an s3 bucket I've actually got another bucket with with better data but so we'll move on to",
    "start": "2106070",
    "end": "2113020"
  },
  {
    "text": "now that's an s3 now what we want to do is run glue and schematize that data so",
    "start": "2113020",
    "end": "2120980"
  },
  {
    "text": "we'll go AWS glue and actually I want to",
    "start": "2120980",
    "end": "2133910"
  },
  {
    "text": "delete that one because we're gonna recreate that as part of the demo",
    "start": "2133910",
    "end": "2138730"
  },
  {
    "text": "okay and since his training okay so so",
    "start": "2142570",
    "end": "2158590"
  },
  {
    "text": "if we took that data and ran glue on it this is what we would have I'll go I'll",
    "start": "2158590",
    "end": "2164170"
  },
  {
    "text": "draw I'll launch a crawler to do to do another another one just so you see that",
    "start": "2164170",
    "end": "2169900"
  },
  {
    "text": "process so the add a crawler we can call",
    "start": "2169900",
    "end": "2181360"
  },
  {
    "text": "it incomes data cr0 for you indicate the you're gonna use s3",
    "start": "2181360",
    "end": "2191040"
  },
  {
    "text": "you could use other data sources and we're going to we have our data in s3 so",
    "start": "2191040",
    "end": "2197770"
  },
  {
    "text": "we're going to find that and we'll go to",
    "start": "2197770",
    "end": "2202320"
  },
  {
    "text": "income incomes ml right so there that",
    "start": "2205560",
    "end": "2211330"
  },
  {
    "text": "one and then we have this",
    "start": "2211330",
    "end": "2216900"
  },
  {
    "text": "okay and then we're gonna go we're not going to grab any other data we're going to stick with that of course you for",
    "start": "2221720",
    "end": "2227990"
  },
  {
    "text": "permissions you need to use a role that gives you X and that gives glue permission to work with that data we're",
    "start": "2227990",
    "end": "2234620"
  },
  {
    "text": "going to have it run on demand will create a new new database let's see",
    "start": "2234620",
    "end": "2241599"
  },
  {
    "text": "okay and that so these are all the respects we gave it we say finish and",
    "start": "2250600",
    "end": "2257270"
  },
  {
    "text": "then we get this prompt it says it was created to run on demand you want to run it now so we do that now that'll",
    "start": "2257270",
    "end": "2265160"
  },
  {
    "text": "complete fairly quickly but I've got a complete data set already crawled by my",
    "start": "2265160",
    "end": "2270650"
  },
  {
    "text": "glue and what that does when glue is done it creates the database or reuses a",
    "start": "2270650",
    "end": "2277370"
  },
  {
    "text": "database that we already had and the one I'm gonna use is income this one here so",
    "start": "2277370",
    "end": "2289340"
  },
  {
    "text": "that database and then we have a bunch of tables in here and we're gonna we're",
    "start": "2289340",
    "end": "2294770"
  },
  {
    "text": "gonna take a look at this one so this this hat you can see it was able to",
    "start": "2294770",
    "end": "2300260"
  },
  {
    "text": "schematize it was able to look at the comma-separated data the header and to",
    "start": "2300260",
    "end": "2305420"
  },
  {
    "text": "be able to work out the the appropriate schema for that data sitting on s3",
    "start": "2305420",
    "end": "2310930"
  },
  {
    "text": "located at incomes ml CSV - okay so now",
    "start": "2310930",
    "end": "2316070"
  },
  {
    "text": "we'll go to the machine learning so now I could spin up an EMR cluster but it",
    "start": "2316070",
    "end": "2322670"
  },
  {
    "text": "would take ten minutes and I don't want to waste your time with that so what I've done is already spun up a cluster",
    "start": "2322670",
    "end": "2330070"
  },
  {
    "text": "with SPARC and as for those that have used DMR you know it's very",
    "start": "2330070",
    "end": "2335780"
  },
  {
    "text": "straightforward if you want spark or presto or HBase there's just check boxes",
    "start": "2335780",
    "end": "2341120"
  },
  {
    "text": "in the web UI that you click on and when it spins up it'll have those applications if you're launching EMR",
    "start": "2341120",
    "end": "2348800"
  },
  {
    "text": "from the command line with the AWS CLI they're just parameters that you can use",
    "start": "2348800",
    "end": "2354170"
  },
  {
    "text": "to specify what set of applications you want running anyways I spun up previously spun up this cluster now with SPARC and an end",
    "start": "2354170",
    "end": "2363740"
  },
  {
    "text": "zeppelin so this is upland notebook you're seeing you probably can't read them the zeppelin notebook is running on",
    "start": "2363740",
    "end": "2371900"
  },
  {
    "text": "the master node and in the EMR cluster and within that notebook where we're",
    "start": "2371900",
    "end": "2377630"
  },
  {
    "text": "running SPARC you can see the the direct their spark so we're gonna run a bunch of spark code in this notebook and",
    "start": "2377630",
    "end": "2385349"
  },
  {
    "text": "although the notebook is running on the master node it is distributing the processing across all the nodes in the",
    "start": "2385349",
    "end": "2392010"
  },
  {
    "text": "cluster and I think this is like a ten node cluster or something like that but",
    "start": "2392010",
    "end": "2397589"
  },
  {
    "text": "anyways if I if I clear the the output that's a clear output yep so we start",
    "start": "2397589",
    "end": "2407339"
  },
  {
    "text": "over okay so now I just have code and what i'm doing here is asking spark to",
    "start": "2407339",
    "end": "2414839"
  },
  {
    "text": "look at the data catalog the this meta store that glue created and give us you",
    "start": "2414839",
    "end": "2421349"
  },
  {
    "text": "know it and set the current database that spark is going to use from glue to",
    "start": "2421349",
    "end": "2426359"
  },
  {
    "text": "to that income is 3 DB and then it's going to show us a list of tables in",
    "start": "2426359",
    "end": "2431880"
  },
  {
    "text": "that database so I execute this cell and we get the list of data of tables right",
    "start": "2431880",
    "end": "2439520"
  },
  {
    "text": "this is going to perform a sequence that readable what is it readable so this is",
    "start": "2439520",
    "end": "2449849"
  },
  {
    "text": "going to create a data frame by running sequel sparks equal across that entry in",
    "start": "2449849",
    "end": "2457740"
  },
  {
    "text": "in the glue data catalog that table in",
    "start": "2457740",
    "end": "2462960"
  },
  {
    "text": "this case it's called CSV - and it's going to pull out certain fields now this data set the census data set very",
    "start": "2462960",
    "end": "2470250"
  },
  {
    "text": "large because like over 40 attributes we're only concerned with a few of them we're going to look at age the working",
    "start": "2470250",
    "end": "2477480"
  },
  {
    "text": "class attribute and the education",
    "start": "2477480",
    "end": "2482720"
  },
  {
    "text": "achieved whether the person has relationships that kind of thing that comes and and their income category of",
    "start": "2482720",
    "end": "2489390"
  },
  {
    "text": "course so we're gonna we're gonna create this data frame which puts the data in memory so this will execute and it tells",
    "start": "2489390",
    "end": "2496170"
  },
  {
    "text": "us the the schema here the schema of the data frame there's more data more app",
    "start": "2496170",
    "end": "2502170"
  },
  {
    "text": "more attributes the blue bar in was indicating progress and then we ask it",
    "start": "2502170",
    "end": "2507630"
  },
  {
    "text": "here to give us a sampling of ten show us ten ten rows from",
    "start": "2507630",
    "end": "2512960"
  },
  {
    "text": "from that okay so we've got age working-class education and you can see the kind some of them are string values",
    "start": "2512960",
    "end": "2518570"
  },
  {
    "text": "some of their marker numeric values and then we have the income category less than or equal to 50 K or greater than 50",
    "start": "2518570",
    "end": "2525740"
  },
  {
    "text": "K all right so we've got now got the data in memory now we're going to ask",
    "start": "2525740",
    "end": "2530950"
  },
  {
    "text": "we're going to start to do the training and actually I think they're supposed to",
    "start": "2530950",
    "end": "2536450"
  },
  {
    "text": "be yeah there's some texts there we're gonna convert these fields as I said",
    "start": "2536450",
    "end": "2542420"
  },
  {
    "text": "earlier machine learning typically requires numerical data and it has to",
    "start": "2542420",
    "end": "2547460"
  },
  {
    "text": "take string data categorical data and convert those into numbers and then",
    "start": "2547460",
    "end": "2553160"
  },
  {
    "text": "build vectors to represent the numerical features and that's what the models get",
    "start": "2553160",
    "end": "2558589"
  },
  {
    "text": "trained on now you can always once you have predictions you can go back to what the original labels were and we'll see",
    "start": "2558589",
    "end": "2564349"
  },
  {
    "text": "that in another cell coming up but this code if you can read that we're going to",
    "start": "2564349",
    "end": "2573460"
  },
  {
    "text": "convert the the string attribute the working class string attribute we're",
    "start": "2573460",
    "end": "2579109"
  },
  {
    "text": "going to create a work class indexer and essentially what that does is we take",
    "start": "2579109",
    "end": "2584570"
  },
  {
    "text": "the data frame that we created earlier okay and or when we execute it'll create",
    "start": "2584570",
    "end": "2591700"
  },
  {
    "text": "and then it's going to convert the values into a set of indices based on",
    "start": "2591700",
    "end": "2598490"
  },
  {
    "text": "the the range of values that are available and then it'll out set that into a separate column separate field",
    "start": "2598490",
    "end": "2604970"
  },
  {
    "text": "called out called work class index similarly for the education we're going",
    "start": "2604970",
    "end": "2610580"
  },
  {
    "text": "to take that string and convert that into a numeric index relationship and then the income index R as well then we",
    "start": "2610580",
    "end": "2619160"
  },
  {
    "text": "use something called a vector assembler which takes a bunch of these attributes",
    "start": "2619160",
    "end": "2624890"
  },
  {
    "text": "and combined that are now numerical and and builds a vector assembles a vector",
    "start": "2624890",
    "end": "2631550"
  },
  {
    "text": "from those and and calls that set of that set of vectors features that's",
    "start": "2631550",
    "end": "2636950"
  },
  {
    "text": "what's going to be used in the training here we're simply dividing up the data between training and and test data",
    "start": "2636950",
    "end": "2644839"
  },
  {
    "text": "here we're instantiating a decision tree classifier where we we tell it what is",
    "start": "2644839",
    "end": "2651619"
  },
  {
    "text": "the the you know what's the what's what column to call the predictions right or",
    "start": "2651619",
    "end": "2660499"
  },
  {
    "text": "the set of set of columns and then what columns that we've already declared in",
    "start": "2660499",
    "end": "2667309"
  },
  {
    "text": "other words the features that will be used to train the model right and then here is where we we were a built a a",
    "start": "2667309",
    "end": "2673759"
  },
  {
    "text": "label converter which can go backwards from index to the corresponding label",
    "start": "2673759",
    "end": "2679670"
  },
  {
    "text": "string label and then we build a pipeline so SPARC ml version I think it",
    "start": "2679670",
    "end": "2685969"
  },
  {
    "text": "was two came out with the pipeline architecture where you can put all these things together and then manage that as",
    "start": "2685969",
    "end": "2692569"
  },
  {
    "text": "a first-order entity persisting it retrieving it in a different application etc so we basically string together",
    "start": "2692569",
    "end": "2700180"
  },
  {
    "text": "stages as shown here including the assembler including the income index or",
    "start": "2700180",
    "end": "2705829"
  },
  {
    "text": "the label the decision tree and then the label converter and essentially all",
    "start": "2705829",
    "end": "2711170"
  },
  {
    "text": "we're doing is saying there's a series of transformations on this data frame that we've that we've pulled out of the",
    "start": "2711170",
    "end": "2717890"
  },
  {
    "text": "database a series of transformations that result in additional columns for",
    "start": "2717890",
    "end": "2723799"
  },
  {
    "text": "things like predictions right and and as well as the numeric features and then at",
    "start": "2723799",
    "end": "2729829"
  },
  {
    "text": "the end the last column gives us the conversion back to the original label so this is a relatively small data set so",
    "start": "2729829",
    "end": "2737089"
  },
  {
    "text": "when I execute this it should go pretty quickly it's just telling us what it's doing the blue bar indicates is still",
    "start": "2737089",
    "end": "2743359"
  },
  {
    "text": "running you've got a percent up here",
    "start": "2743359",
    "end": "2748420"
  },
  {
    "text": "those of you who have done spark and I'll know all all of this but it looked sounded like the bar the audience was a",
    "start": "2748450",
    "end": "2755859"
  },
  {
    "text": "significant number of people that hadn't used spark ml so okay so it's I'm almost",
    "start": "2755859",
    "end": "2762349"
  },
  {
    "text": "done here it's letting us know the various things that's instantiated and declared and yeah and so it's finished",
    "start": "2762349",
    "end": "2769539"
  },
  {
    "text": "alright so the next cell",
    "start": "2769539",
    "end": "2773950"
  },
  {
    "text": "and Excel should be txt you know fit the decision tree classifier so all we've",
    "start": "2775500",
    "end": "2781950"
  },
  {
    "text": "done so far is queued up the the data frames for the eventual training of the",
    "start": "2781950",
    "end": "2791280"
  },
  {
    "text": "model we've declared the pipeline but we haven't yet trained the model that's where the next step is and this is where",
    "start": "2791280",
    "end": "2798119"
  },
  {
    "text": "we take the date the pipeline that we declared and we ask it to fit fit the",
    "start": "2798119",
    "end": "2803400"
  },
  {
    "text": "the pipeline to the training data so essentially that runs the training data",
    "start": "2803400",
    "end": "2808410"
  },
  {
    "text": "through that pipeline through all the various stages through the various transformations and results in a trained",
    "start": "2808410",
    "end": "2815520"
  },
  {
    "text": "model so that that goes fairly quickly as well",
    "start": "2815520",
    "end": "2821240"
  },
  {
    "text": "okay so told us it down here instantiated the model and then this",
    "start": "2828510",
    "end": "2834119"
  },
  {
    "text": "step we're getting near the end here this step is going to now make some",
    "start": "2834119",
    "end": "2839400"
  },
  {
    "text": "predictions on on a different set of data this is where we're going to infer",
    "start": "2839400",
    "end": "2844410"
  },
  {
    "text": "the income of samples that for which we did not have income prediction of income",
    "start": "2844410",
    "end": "2851640"
  },
  {
    "text": "data so here we're taking the model that's now been trained we're asking it",
    "start": "2851640",
    "end": "2857430"
  },
  {
    "text": "to do do a transformation in other words a prediction on the the test data and",
    "start": "2857430",
    "end": "2864109"
  },
  {
    "text": "that results in a data frame called Preds and then this one we're pulling",
    "start": "2864109",
    "end": "2869700"
  },
  {
    "text": "out certain fields because there's a lot of intermediate vectors and stuff that just kind of pollute the screen so I'm",
    "start": "2869700",
    "end": "2876830"
  },
  {
    "text": "selectively pulling out interesting and useful attributes and you can see them",
    "start": "2876830",
    "end": "2882750"
  },
  {
    "text": "declare it there and we're going to show two ten samples and then we're gonna",
    "start": "2882750",
    "end": "2888720"
  },
  {
    "text": "write this data back out to s3 using the hive a hive table called predicted",
    "start": "2888720",
    "end": "2896030"
  },
  {
    "text": "incomes okay so we'll run that and it's fairly quick too",
    "start": "2896030",
    "end": "2901850"
  },
  {
    "text": "okay so we got our ten samples this is these are the predicted label here blue",
    "start": "2901850",
    "end": "2912450"
  },
  {
    "text": "bar says is still running",
    "start": "2912450",
    "end": "2915500"
  },
  {
    "text": "okay not finished and no errors so the data went to s3 and right this one yeah",
    "start": "2921190",
    "end": "2936549"
  },
  {
    "text": "I will skip that one so so now we've just to sum up what we did with the EMR",
    "start": "2936549",
    "end": "2943180"
  },
  {
    "text": "and sparkin well we took that schematized data that glue created for us in the data catalog it's essentially",
    "start": "2943180",
    "end": "2950859"
  },
  {
    "text": "a meta meta store spark was able to query that data pulling out particular",
    "start": "2950859",
    "end": "2957010"
  },
  {
    "text": "fields it took those rendered them in numerical fashion trained a decision",
    "start": "2957010",
    "end": "2963460"
  },
  {
    "text": "tree took that decision tree classifier model and then fed it cut it previously",
    "start": "2963460",
    "end": "2970630"
  },
  {
    "text": "unseen samples and got predictions for what the income would be and then those",
    "start": "2970630",
    "end": "2975849"
  },
  {
    "text": "results were sent back to s3 using using the the the database that we connected",
    "start": "2975849",
    "end": "2983710"
  },
  {
    "text": "to at the beginning okay so let's now look at a thena and maybe it's worth",
    "start": "2983710",
    "end": "2991230"
  },
  {
    "text": "summarize showing the just to recap oops",
    "start": "2991230",
    "end": "2998039"
  },
  {
    "text": "this one right here just to remind everybody okay so so we're now done all",
    "start": "2998039",
    "end": "3008160"
  },
  {
    "text": "these steps we've got data sitting in s3 and we're going to now query it with the",
    "start": "3008160",
    "end": "3013799"
  },
  {
    "text": "athena so go back here type in Athena there we",
    "start": "3013799",
    "end": "3020730"
  },
  {
    "text": "go okay and Athena is a fully managed",
    "start": "3020730",
    "end": "3026819"
  },
  {
    "text": "service there's no servers no cluster just spin up and and run and what we're",
    "start": "3026819",
    "end": "3034020"
  },
  {
    "text": "going to do is take our CSV table here with various attributes and write a",
    "start": "3034020",
    "end": "3040140"
  },
  {
    "text": "query we can do so like this is the original raw data from CSV to limit",
    "start": "3040140",
    "end": "3049550"
  },
  {
    "text": "100 ok so here's here's the original",
    "start": "3049550",
    "end": "3057680"
  },
  {
    "text": "data that we pulled off the internet put",
    "start": "3057680",
    "end": "3062690"
  },
  {
    "text": "into s3 ran through ran through glue and you can see it's it's structured and",
    "start": "3062690",
    "end": "3069080"
  },
  {
    "text": "we've got a hundred samples there we can now you can see remember I deleted that predicted income stable previously with",
    "start": "3069080",
    "end": "3076550"
  },
  {
    "text": "them before we started we now have a predicted incomes table showing up",
    "start": "3076550",
    "end": "3082130"
  },
  {
    "text": "thanks to spark sending that back to the meta store and we've got these",
    "start": "3082130",
    "end": "3088040"
  },
  {
    "text": "attributes including the the predicted label and for this weekend a new query",
    "start": "3088040",
    "end": "3096550"
  },
  {
    "text": "and we predicted incomes limit",
    "start": "3099490",
    "end": "3108970"
  },
  {
    "text": "so there's the data there if we scroll over you can see the the predicted label",
    "start": "3112640",
    "end": "3118020"
  },
  {
    "text": "okay so we can interact with the data we could run additional queries on it etc",
    "start": "3118020",
    "end": "3125730"
  },
  {
    "text": "and now quick site let's see",
    "start": "3125730",
    "end": "3131600"
  },
  {
    "text": "okay and all - words like that a little",
    "start": "3146960",
    "end": "3155880"
  },
  {
    "text": "larger",
    "start": "3155880",
    "end": "3158420"
  },
  {
    "text": "I'll just go to a convenient data source and so so here we the data was that was",
    "start": "3164000",
    "end": "3171200"
  },
  {
    "text": "on s3 it's pulled into spice which you can see over here a little hard to see",
    "start": "3171200",
    "end": "3177790"
  },
  {
    "text": "and we can very easily generate these these graphics and then share those with",
    "start": "3177790",
    "end": "3186520"
  },
  {
    "text": "you know we can create a story storyboard I guess we have a storyboard",
    "start": "3186520",
    "end": "3193700"
  },
  {
    "text": "or any to it",
    "start": "3193700",
    "end": "3196450"
  },
  {
    "text": "you could change the graphs as well",
    "start": "3207140",
    "end": "3211119"
  },
  {
    "text": "okay and let's see",
    "start": "3213199",
    "end": "3219140"
  },
  {
    "text": "export trying to remember how you share it with somebody but it's it's via a",
    "start": "3222160",
    "end": "3229180"
  },
  {
    "text": "story so you can put together your selection of the various visualizations",
    "start": "3229180",
    "end": "3235480"
  },
  {
    "text": "they're already on the web and then you can share those with other users including our marketing director so with",
    "start": "3235480",
    "end": "3243579"
  },
  {
    "text": "that that's the demo as you can see things move pretty quickly with the",
    "start": "3243579",
    "end": "3250240"
  },
  {
    "text": "services most of them being managed services that's the way to go if you want agility and if you want elasticity",
    "start": "3250240",
    "end": "3258819"
  },
  {
    "text": "and scalability you know make sure you're using things like s3 and and",
    "start": "3258819",
    "end": "3264990"
  },
  {
    "text": "scalable clusters like EMR I forgot to mention that it can dynamically change",
    "start": "3264990",
    "end": "3270059"
  },
  {
    "text": "you can auto scale EMR so if you've got more data to crunch you can set",
    "start": "3270059",
    "end": "3277000"
  },
  {
    "text": "thresholds and criteria for that automatic expansion so a lot of tools it",
    "start": "3277000",
    "end": "3282819"
  },
  {
    "text": "takes time to play with them and get to get familiar with them think about",
    "start": "3282819",
    "end": "3287950"
  },
  {
    "text": "scenarios like this hypothetical one where you know you're trying to try to leverage existing data train a model and",
    "start": "3287950",
    "end": "3295150"
  },
  {
    "text": "then be able to predict on new data that you you haven't previously seen and leverage that in your business so with",
    "start": "3295150",
    "end": "3302859"
  },
  {
    "text": "that I'll take questions and we'll do that",
    "start": "3302859",
    "end": "3308160"
  },
  {
    "text": "you don't program well okay so so glue you can create classifiers right now we",
    "start": "3315260",
    "end": "3323630"
  },
  {
    "text": "support Python it's a good question I don't know if we would move to Scala or",
    "start": "3323630",
    "end": "3329880"
  },
  {
    "text": "not Python is very popular for doing ETL and transformations and classifications but",
    "start": "3329880",
    "end": "3337740"
  },
  {
    "text": "that's a good suggestion we can mmm I",
    "start": "3337740",
    "end": "3344359"
  },
  {
    "text": "don't but I think this slides I can probably update the slides with a with a",
    "start": "3344960",
    "end": "3351210"
  },
  {
    "text": "link online for people to follow yeah",
    "start": "3351210",
    "end": "3356369"
  },
  {
    "text": "and end the the Scala code for for doing the machine learning I can share that as well and these data these data sets we",
    "start": "3356369",
    "end": "3363809"
  },
  {
    "text": "can share their US census data so search",
    "start": "3363809",
    "end": "3371339"
  },
  {
    "text": "one yeah yeah if you search on the identifier for our",
    "start": "3371339",
    "end": "3378410"
  },
  {
    "text": "oh yeah it was in the Scala code in spark ml yeah it instantiated a decision",
    "start": "3381150",
    "end": "3389010"
  },
  {
    "text": "tree classifier yeah its decision trees",
    "start": "3389010",
    "end": "3396599"
  },
  {
    "text": "are very popular because they they're they work with both categorical data and numerical data and and they're they're",
    "start": "3396599",
    "end": "3403650"
  },
  {
    "text": "pretty robust and high-performance so they're yeah you could you could have",
    "start": "3403650",
    "end": "3413279"
  },
  {
    "text": "numerical predictions in this case we had binary you know greater than or less than 50k but you could have a numerical",
    "start": "3413279",
    "end": "3420539"
  },
  {
    "text": "put as well yeah but there are other probably better ones like linear regression that wouldn't it would be",
    "start": "3420539",
    "end": "3426599"
  },
  {
    "text": "better for that Oh in Sage maker um yeah",
    "start": "3426599",
    "end": "3439470"
  },
  {
    "text": "yeah well spark definitely has more than one linear regression model and sage",
    "start": "3439470",
    "end": "3447210"
  },
  {
    "text": "maker if it doesn't have it today it will very soon have it you know yep you",
    "start": "3447210",
    "end": "3457980"
  },
  {
    "text": "know the quick site oh yeah",
    "start": "3457980",
    "end": "3469210"
  },
  {
    "text": "[Music]",
    "start": "3469380",
    "end": "3472439"
  },
  {
    "text": "well well so so why would you need quick site if you why would you need Athena if",
    "start": "3481340",
    "end": "3487050"
  },
  {
    "text": "you've got quick site so they're there they're apples and oranges so so quick site is for visualization it's it's you",
    "start": "3487050",
    "end": "3495570"
  },
  {
    "text": "wouldn't do high-performance predictions you wouldn't do you wouldn't do queries you",
    "start": "3495570",
    "end": "3501570"
  },
  {
    "text": "know complex queries on it it's more for there aren't there's like you know data scale limits and that kind of thing like",
    "start": "3501570",
    "end": "3509270"
  },
  {
    "text": "it depends on the size of your your spice engine you have to when you sign",
    "start": "3509270",
    "end": "3515550"
  },
  {
    "text": "up you have to decide how much RAM you want your spice engines to have things",
    "start": "3515550",
    "end": "3521040"
  },
  {
    "text": "like that yeah this was a small this was",
    "start": "3521040",
    "end": "3528810"
  },
  {
    "text": "a small set of data yeah well Athena Athena is for doing complex sequel queries like an C sequel",
    "start": "3528810",
    "end": "3536640"
  },
  {
    "text": "with nested nested sub queries and and that kind of thing",
    "start": "3536640",
    "end": "3542430"
  },
  {
    "text": "quick site is really just for rendering as graphs and charts well what you can",
    "start": "3542430",
    "end": "3550050"
  },
  {
    "text": "do is run Athena on some data to create a specialized view you know pulling out",
    "start": "3550050",
    "end": "3557460"
  },
  {
    "text": "certain columns a materialized view and then you could you could store you could",
    "start": "3557460",
    "end": "3562470"
  },
  {
    "text": "create a datastore from the results of Athena and then you can go to quick site and and point to that data source and",
    "start": "3562470",
    "end": "3569940"
  },
  {
    "text": "have undo graphical rendering of the data so you can use the two of them",
    "start": "3569940",
    "end": "3575690"
  },
  {
    "text": "right well so cool yeah a quick quick sight can interface with with it can",
    "start": "3580240",
    "end": "3586700"
  },
  {
    "text": "inter it can interface with Athena tables but also redshift and so so you",
    "start": "3586700",
    "end": "3593930"
  },
  {
    "text": "can tap into other data sources I used s3 because that's that's the one with",
    "start": "3593930",
    "end": "3599240"
  },
  {
    "text": "the best value proposition in my mind you know the scale elasticity is at low",
    "start": "3599240",
    "end": "3604970"
  },
  {
    "text": "cost and yeah yeah but it doesn't have to be s3 it could be an RDS database as",
    "start": "3604970",
    "end": "3612140"
  },
  {
    "text": "well CSV yeah json xml parque oor c",
    "start": "3612140",
    "end": "3629049"
  },
  {
    "text": "trying to think if there's anything else pretty much Hadoop Hadoop standard -",
    "start": "3629049",
    "end": "3635690"
  },
  {
    "text": "Hadoop formats yeah it looks like your",
    "start": "3635690",
    "end": "3642289"
  },
  {
    "text": "date it replaces the heavy lifting that you would normally do if you had your",
    "start": "3642289",
    "end": "3648410"
  },
  {
    "text": "raw data you would you would go in and look at it try to figure out you know what what is the appropriate data type",
    "start": "3648410",
    "end": "3654529"
  },
  {
    "text": "for this column or field and you know what what should my table look like and",
    "start": "3654529",
    "end": "3660170"
  },
  {
    "text": "then you would create the meta meta store entry manually right what this is",
    "start": "3660170",
    "end": "3665180"
  },
  {
    "text": "doing is saving you from all that you put your data on s3 crawl it and then and then it creates the meta story entry",
    "start": "3665180",
    "end": "3671420"
  },
  {
    "text": "for you",
    "start": "3671420",
    "end": "3673778"
  },
  {
    "text": "yeah spark spark can query CSV data as well but what what you're trying to do",
    "start": "3678360",
    "end": "3685840"
  },
  {
    "text": "with with blue is to create a meta store entry you're trying to figure out you're",
    "start": "3685840",
    "end": "3691600"
  },
  {
    "text": "trying to schematize the data so that it can be used in a variety of ways it could be used for presto could be used",
    "start": "3691600",
    "end": "3697870"
  },
  {
    "text": "for for you know loading into H into a relational database so you see and it's",
    "start": "3697870",
    "end": "3706510"
  },
  {
    "text": "a it's a the meta store is persistent so so even if your cost your EMR cluster it",
    "start": "3706510",
    "end": "3712300"
  },
  {
    "text": "goes away that that data is still on s3 and there's a tabular interpretation of",
    "start": "3712300",
    "end": "3718060"
  },
  {
    "text": "it in in the medicine in the data catalog so so it's you know it lives",
    "start": "3718060",
    "end": "3724210"
  },
  {
    "text": "beyond the cluster the SPARC version the schema interpretation only lasts as long",
    "start": "3724210",
    "end": "3730930"
  },
  {
    "text": "as SPARC is running right right",
    "start": "3730930",
    "end": "3740970"
  },
  {
    "text": "change the location you know really for the external table they want to know how",
    "start": "3747450",
    "end": "3786309"
  },
  {
    "text": "are you predicted right right yeah yep",
    "start": "3786309",
    "end": "3791740"
  },
  {
    "text": "so so the question is how can you understand in the decision tree can you",
    "start": "3791740",
    "end": "3797589"
  },
  {
    "text": "understand what how it arrives at its predictions yes that's that's in fact",
    "start": "3797589",
    "end": "3803319"
  },
  {
    "text": "one of the real benefits of decision trees some of these other more exotic",
    "start": "3803319",
    "end": "3809039"
  },
  {
    "text": "machine learning models are fairly opaque and it's hard I certainly think",
    "start": "3809039",
    "end": "3814210"
  },
  {
    "text": "you know things like deep learning models you've got a bunch of neurons and weights between them and and the sheer",
    "start": "3814210",
    "end": "3820420"
  },
  {
    "text": "number is just astronomical so decision trees have that advantage is that you",
    "start": "3820420",
    "end": "3825849"
  },
  {
    "text": "can actually see what's the criteria to go from one node to down one branch and",
    "start": "3825849",
    "end": "3832089"
  },
  {
    "text": "then a sub branch and so on you can actually see that that criteria",
    "start": "3832089",
    "end": "3837450"
  },
  {
    "text": "yeah you'd have to interrogate the interrogate the decision that modeled",
    "start": "3839069",
    "end": "3844900"
  },
  {
    "text": "that's been trained yeah Python yeah spark spark does a lot",
    "start": "3844900",
    "end": "3853530"
  },
  {
    "text": "of languages apart there's Python which is super popular Scala you could do Java if you're a masochist maybe that's our",
    "start": "3853530",
    "end": "3861680"
  },
  {
    "text": "spark our what else is there I think now",
    "start": "3861680",
    "end": "3876060"
  },
  {
    "text": "there are there are actually better notebooks for like managing individuals",
    "start": "3876060",
    "end": "3881790"
  },
  {
    "text": "so things like Jupiter notebooks or better where you can actually have separate user accounts they actually",
    "start": "3881790",
    "end": "3891300"
  },
  {
    "text": "that that's not true because if you if you look at",
    "start": "3891300",
    "end": "3896600"
  },
  {
    "text": "Jupiter's getting very popular yeah I can't think can type at the same time so",
    "start": "3902920",
    "end": "3913069"
  },
  {
    "text": "so Zeppelin is its it it's good for things like spark and and so on Jupiter",
    "start": "3913069",
    "end": "3920650"
  },
  {
    "text": "is largely used for things like Python I guess you can use Jupiter for Scala as",
    "start": "3920650",
    "end": "3928790"
  },
  {
    "text": "well it depends on what interpreters have been plugged in i think even presto",
    "start": "3928790",
    "end": "3934700"
  },
  {
    "text": "you can run presto through through Jupiter yeah so so there is actually",
    "start": "3934700",
    "end": "3946670"
  },
  {
    "text": "some some oh yeah here credential",
    "start": "3946670",
    "end": "3951730"
  },
  {
    "text": "actually popping up but but apparently there there's I don't know maybe I lost",
    "start": "3952839",
    "end": "3963200"
  },
  {
    "text": "my connection",
    "start": "3963200",
    "end": "3965650"
  },
  {
    "text": "you know hopefully you got a sense of kind of the the breadth of functionality",
    "start": "3968369",
    "end": "3974160"
  },
  {
    "text": "and how you can go fairly quickly once you get comfortable with how things work you can very quickly zip through these",
    "start": "3974160",
    "end": "3980849"
  },
  {
    "text": "things and go from raw data to predictions to visualizing results okay",
    "start": "3980849",
    "end": "3989990"
  },
  {
    "text": "yeah",
    "start": "3995690",
    "end": "3998690"
  },
  {
    "text": "right",
    "start": "4028770",
    "end": "4031400"
  },
  {
    "text": "hmm yeah yeah I mean I didn't have a lot",
    "start": "4042880",
    "end": "4050860"
  },
  {
    "text": "of time to put this together so I had I had more time I would have researched better better data sources I mean a lot",
    "start": "4050860",
    "end": "4057400"
  },
  {
    "text": "of the value you get is a function of the size and quality of the data set and",
    "start": "4057400",
    "end": "4063910"
  },
  {
    "text": "you know what kind of attributes are present so but good good point we do have an AWS public data sets site",
    "start": "4063910",
    "end": "4072480"
  },
  {
    "text": "where you can get lot of big data data sets on s3 that are world readable so",
    "start": "4072480",
    "end": "4080860"
  },
  {
    "text": "from your own account from your own AWS account you can work with those data sets which are already in the cloud",
    "start": "4080860",
    "end": "4086590"
  },
  {
    "text": "you're not paying for that storage yep",
    "start": "4086590",
    "end": "4092370"
  },
  {
    "text": "okay yeah yeah we have things like the New York City Taxi Cab data set which is",
    "start": "4092460",
    "end": "4099339"
  },
  {
    "text": "massive that's like a petabyte or a billion records anyways I'm sorry I",
    "start": "4099340",
    "end": "4105670"
  },
  {
    "text": "think you reaching in first",
    "start": "4105670",
    "end": "4109230"
  },
  {
    "text": "well so-so data in s3 by default without you doing anything is secured the only",
    "start": "4118469",
    "end": "4124770"
  },
  {
    "text": "way it becomes unsecured is if you deliberately make it world readable or you decide to to make it readable by",
    "start": "4124770",
    "end": "4131670"
  },
  {
    "text": "others yeah now see ya Athena can work",
    "start": "4131670",
    "end": "4143040"
  },
  {
    "text": "with encrypted fields and columns I believe yes if I remember correctly yes",
    "start": "4143040",
    "end": "4151258"
  },
  {
    "text": "yep",
    "start": "4151259",
    "end": "4153859"
  },
  {
    "text": "more details than then I showed well what I did was distributed training",
    "start": "4161239",
    "end": "4168170"
  },
  {
    "text": "right so spark the way spark works is it",
    "start": "4170420",
    "end": "4175670"
  },
  {
    "text": "essentially partitions the data spreads the data across the cluster okay and",
    "start": "4175670",
    "end": "4181528"
  },
  {
    "text": "then it pushes copies of the code to the data so each each partition is working",
    "start": "4181529",
    "end": "4187318"
  },
  {
    "text": "with a different slice of the data now there is rep there's replication within the cluster at least in on-prem with EMR",
    "start": "4187319",
    "end": "4195300"
  },
  {
    "text": "where we're taking advantage of s3's durability but the data gets partitioned",
    "start": "4195300",
    "end": "4200850"
  },
  {
    "text": "and so you get these nodes with multiple cores each running a copy of the code",
    "start": "4200850",
    "end": "4206570"
  },
  {
    "text": "processing their own local data right but then there are there's what they",
    "start": "4206570",
    "end": "4212580"
  },
  {
    "text": "call shuffling where you bring bring related data together for final roll-ups",
    "start": "4212580",
    "end": "4218699"
  },
  {
    "text": "and aggregate aggregate and results that way that's a very simplified explanation",
    "start": "4218699",
    "end": "4224850"
  },
  {
    "text": "of SPARC works yep well there was no",
    "start": "4224850",
    "end": "4231480"
  },
  {
    "text": "deep learning here this was machine this was a traditional decision tree",
    "start": "4231480",
    "end": "4238670"
  },
  {
    "text": "so well so so deep learning you would",
    "start": "4245120",
    "end": "4251000"
  },
  {
    "text": "would probably well the best way to do deep learning would be on sage maker",
    "start": "4251000",
    "end": "4256040"
  },
  {
    "text": "because that's a managed service it takes a lot of the headache away it's",
    "start": "4256040",
    "end": "4261290"
  },
  {
    "text": "managing multiple containers ECS containers for manage training so so you",
    "start": "4261290",
    "end": "4268370"
  },
  {
    "text": "have your data and you simply make a call with your data indicating what what",
    "start": "4268370",
    "end": "4273980"
  },
  {
    "text": "kind of training you want the service does the training for you there's no there's nothing for you to spin up and",
    "start": "4273980",
    "end": "4279860"
  },
  {
    "text": "manage that way and then you get a trained model coming back and then you can deploy that into production that's",
    "start": "4279860",
    "end": "4285950"
  },
  {
    "text": "the best way to do deep learning you could also take deep learning Ami's deep learning ami and deploy it on",
    "start": "4285950",
    "end": "4292730"
  },
  {
    "text": "multiple EC EC twos or ECS containers",
    "start": "4292730",
    "end": "4300320"
  },
  {
    "text": "you could do it that way as well you can put load balancers in front of it that's more work but it's still virtualized",
    "start": "4300320",
    "end": "4306860"
  },
  {
    "text": "servers so so you're not having to you know buy hardware to do your your deep learning alright how I think we probably",
    "start": "4306860",
    "end": "4314510"
  },
  {
    "text": "need to wrap it up one last question I'm sorry compare athena and s3 OS 3",
    "start": "4314510",
    "end": "4325880"
  },
  {
    "text": "select yeah that's brand-new you heard it the first time I did so it's yeah",
    "start": "4325880",
    "end": "4334670"
  },
  {
    "text": "what it's doing essentially is is pruning this search tree I guess it's",
    "start": "4334670",
    "end": "4340340"
  },
  {
    "text": "pushing predicates down to the s3 level so that instead of as three returning",
    "start": "4340340",
    "end": "4346610"
  },
  {
    "text": "all the data for something else to filter and and and work through and decide on its you push predicates down",
    "start": "4346610",
    "end": "4354230"
  },
  {
    "text": "to the s3 level and then s3 only returns what matches the predicates so it cuts",
    "start": "4354230",
    "end": "4360680"
  },
  {
    "text": "down dramatically on the amount of Vaio presto does pushdown of predicates as",
    "start": "4360680",
    "end": "4367900"
  },
  {
    "text": "well yeah but this is at the s3 level s3 select well yeah you can you can",
    "start": "4367900",
    "end": "4379480"
  },
  {
    "text": "definitely get a performance boost with s/3 s/3 select yeah because it's it's",
    "start": "4379480",
    "end": "4384910"
  },
  {
    "text": "operating at the it's it's it's avoiding unnecessary data i/o it's only sending",
    "start": "4384910",
    "end": "4391330"
  },
  {
    "text": "back the data that actually matches the predicates right okay the ML",
    "start": "4391330",
    "end": "4405630"
  },
  {
    "text": "so so glue does ETL it transforms the data and it's cute eise's the data puts",
    "start": "4413710",
    "end": "4421640"
  },
  {
    "text": "an entry in the meta meta store you don't do do machine learning on on glue",
    "start": "4421640",
    "end": "4427370"
  },
  {
    "text": "right you need EMR to take advantage of SPARC ml right so so glue is not glue",
    "start": "4427370",
    "end": "4434840"
  },
  {
    "text": "isn't so much compute as it is ETL and and schematized the data so so it's it",
    "start": "4434840",
    "end": "4441860"
  },
  {
    "text": "it it's not designed for machine learning",
    "start": "4441860",
    "end": "4446889"
  },
  {
    "text": "mm-hmm so so it's a you have to",
    "start": "4463060",
    "end": "4472579"
  },
  {
    "text": "understand with with big data you don't want to be moving or copying data so",
    "start": "4472579",
    "end": "4478400"
  },
  {
    "text": "what is the schema time schematize doing is defining an interpretation of the",
    "start": "4478400",
    "end": "4485179"
  },
  {
    "text": "data that's already persistent you're not going to move you're not going to move that data you're not gonna copy it",
    "start": "4485179",
    "end": "4490550"
  },
  {
    "text": "anywhere you're gonna leave it where it is create a meta store entry that that superimposes a definition or defines",
    "start": "4490550",
    "end": "4497690"
  },
  {
    "text": "defines an interpretation so that then something like hive or Pig and spark and",
    "start": "4497690",
    "end": "4504590"
  },
  {
    "text": "you know presto Kent can then query query that data by",
    "start": "4504590",
    "end": "4511280"
  },
  {
    "text": "essentially scanning the data but it's leveraging that meta store table definition for the data I'm sorry well",
    "start": "4511280",
    "end": "4525710"
  },
  {
    "text": "no no so glue has two functions it has the ETL capability and we didn't go",
    "start": "4525710",
    "end": "4532219"
  },
  {
    "text": "through that that's where you can define how you want data transformed cleaned up",
    "start": "4532219",
    "end": "4539810"
  },
  {
    "text": "perhaps and but the key thing was that I showed was the data catalog that we're",
    "start": "4539810",
    "end": "4545090"
  },
  {
    "text": "where it crawls your data on s3 it could be other data sources but it crawls your data on s3 and figures out what that",
    "start": "4545090",
    "end": "4552199"
  },
  {
    "text": "meta store tabular interpretation should be and creates an entry in the meta",
    "start": "4552199",
    "end": "4557540"
  },
  {
    "text": "store to be used by EMR and other things Athena it is a hive datastore",
    "start": "4557540",
    "end": "4566659"
  },
  {
    "text": "essentially yeah but it but it's automating the creation of the entries and I've Minister okay all right thanks",
    "start": "4566659",
    "end": "4573770"
  },
  {
    "text": "everybody",
    "start": "4573770",
    "end": "4575980"
  }
]
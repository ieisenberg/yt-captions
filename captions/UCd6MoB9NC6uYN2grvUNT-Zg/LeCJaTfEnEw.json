[
  {
    "text": "hello everyone my name is Craig roach I'm a solution architect in the ANZ public-sector team I'm based in",
    "start": "30",
    "end": "5520"
  },
  {
    "text": "Wellington and today I'm going to be talking to you about best practice and best practices and patterns for building",
    "start": "5520",
    "end": "12389"
  },
  {
    "text": "data lakes now the the technique I'm",
    "start": "12389",
    "end": "17640"
  },
  {
    "text": "going to be doing it using fit to do that is to actually use an actual case study sorry a simulated case study drawn",
    "start": "17640",
    "end": "24090"
  },
  {
    "text": "from the healthcare industry now the reason I've chosen their healthcare industry is one it's an area that I've been focusing over the last couple of",
    "start": "24090",
    "end": "31050"
  },
  {
    "text": "years in New Zealand as a field solution architect so I've had a lot of hands-on experience in that in that domain but",
    "start": "31050",
    "end": "37710"
  },
  {
    "text": "also because I think it's an area that pretty much everyone in this room has had encounters with has touched your",
    "start": "37710",
    "end": "42899"
  },
  {
    "text": "lives in some way so I think the examples will probably be very um very familiar to you now this is what we're",
    "start": "42899",
    "end": "50850"
  },
  {
    "text": "going to build this is a this is the the sample data Lake and it's a clinical",
    "start": "50850",
    "end": "56399"
  },
  {
    "text": "data Lake that's going to be working with hospital data now I'm not going to bore you with a tedious walk through",
    "start": "56399",
    "end": "62579"
  },
  {
    "text": "this this diagram because I'm you've probably all been through that you'll know it's it's like pulling teeth well",
    "start": "62579",
    "end": "68369"
  },
  {
    "text": "I'm gonna do instead to start at the beginning and start with some requirements which is always a good place to start",
    "start": "68369",
    "end": "75200"
  },
  {
    "text": "so generally our best practice is the start small start with a small number of",
    "start": "75200",
    "end": "80250"
  },
  {
    "text": "objectives it's not a small number of insights a small number of data sources and three seems to be about a route",
    "start": "80250",
    "end": "85650"
  },
  {
    "text": "about the right number now the insights we're going to we're going to work with are going to take use two examples in",
    "start": "85650",
    "end": "92729"
  },
  {
    "text": "the category of anomaly detection and the anomaly so we're going to be looking for anomalies in admissions to hospital",
    "start": "92729",
    "end": "98820"
  },
  {
    "text": "and discharges from hospital we're also going to be looking for insights into the optimization that maintenance",
    "start": "98820",
    "end": "104220"
  },
  {
    "text": "schedules around some of the the plants and equipment associated with the hospital and we'll be touching real-time",
    "start": "104220",
    "end": "109530"
  },
  {
    "text": "systems for that and the data sources we'll be working with the hospitals",
    "start": "109530",
    "end": "114810"
  },
  {
    "text": "patient's system its discharge system and all the collection of real-time therapeutic consents and imaging systems",
    "start": "114810",
    "end": "122130"
  },
  {
    "text": "associated with running the hospital as well so we'll get a good coverage of the different data types difference or the",
    "start": "122130",
    "end": "127590"
  },
  {
    "text": "data update frequencies and durability requirements so we're going to start",
    "start": "127590",
    "end": "133470"
  },
  {
    "text": "with the full discharge system now the hospital discharge system pumps out a set of data",
    "start": "133470",
    "end": "138600"
  },
  {
    "text": "called hl7 now hl7 if you're not for me with the healthcare sector is a fairly well established format for encoding",
    "start": "138600",
    "end": "145400"
  },
  {
    "text": "medical information clinical information and interoperating with other with other hospitals and health agencies so the",
    "start": "145400",
    "end": "152670"
  },
  {
    "text": "system's already producing this hl7 format and what we're going to do is use is pump that data into s3 using the data",
    "start": "152670",
    "end": "160230"
  },
  {
    "text": "sync service and the data sync service is a little bit like an hour sync service is constantly monitoring the",
    "start": "160230",
    "end": "165630"
  },
  {
    "text": "arrival of new data and then pushing it to s3 now once it lands on s3 what we're",
    "start": "165630",
    "end": "171390"
  },
  {
    "text": "going to do is actually look up the lookup the arriving objects based on their name in a list of predefined data",
    "start": "171390",
    "end": "178170"
  },
  {
    "text": "sources and this list of data source is going to have things like metadata associated with those objects it's going",
    "start": "178170",
    "end": "184530"
  },
  {
    "text": "to have things like validation rules and partitioning rules so we're going to pull that information from our from our",
    "start": "184530",
    "end": "190140"
  },
  {
    "text": "list of no and data sources and use that information to actually obtain the",
    "start": "190140",
    "end": "195360"
  },
  {
    "text": "metadata and validate the schema so we're going to check this is actually well-formed hl7 data if it is we're",
    "start": "195360",
    "end": "202260"
  },
  {
    "text": "going to move it into the staging bucket and we're also going to move the object metadata into a dynamodb table and",
    "start": "202260",
    "end": "209400"
  },
  {
    "text": "that's going to be time-stamped and the reason we do that is we're now we're going to feed that object metadata into",
    "start": "209400",
    "end": "215940"
  },
  {
    "text": "an elastic search cluster and this is going to give us the mechanism by which we can do data lineage analysis we can",
    "start": "215940",
    "end": "222180"
  },
  {
    "text": "actually look at a time the arrival of data as a time series look at the metadata and do searches on that",
    "start": "222180",
    "end": "227519"
  },
  {
    "text": "metadata in using something like gabbana we can also build data flow dashboards",
    "start": "227519",
    "end": "232590"
  },
  {
    "text": "and that sort of thing once it's in the less tsearch so that's going to be a really powerful mechanism to build our",
    "start": "232590",
    "end": "237750"
  },
  {
    "text": "method data analysis capabilities in our data lake so we've got we've got um validated data with metadata sitting in",
    "start": "237750",
    "end": "245040"
  },
  {
    "text": "our staging bucket the next thing we're going to do is we ever try and discover",
    "start": "245040",
    "end": "250530"
  },
  {
    "text": "the schema and we're going to use the AWS glue that the glue serves to do that and in particular the crawler mechanism",
    "start": "250530",
    "end": "256410"
  },
  {
    "text": "and the crawler mechanism on a regular schedule will go and look at this the staging bucket discover the schema in",
    "start": "256410",
    "end": "263070"
  },
  {
    "text": "that data in that hl7 data and publish that schema into a glue dyrdek log which is in a it's a hive compatible",
    "start": "263070",
    "end": "270450"
  },
  {
    "text": "meta store which means it's accessible to a whole ecosystem of our MapReduce type tools like like spark and flink and",
    "start": "270450",
    "end": "277020"
  },
  {
    "text": "those sorts of things so and that that glued data catalog as you'll see in this in the talk is going to be the hub by",
    "start": "277020",
    "end": "283740"
  },
  {
    "text": "which we're going to do all about MapReduce analysis our relational queries so it really becomes the the",
    "start": "283740",
    "end": "289680"
  },
  {
    "text": "central focus so that's one data source let's add another one make bit of room",
    "start": "289680",
    "end": "296310"
  },
  {
    "text": "so now we're going to hook into the the hospitals many that hospitals manage the",
    "start": "296310",
    "end": "301530"
  },
  {
    "text": "mission system admission system now for the sake of the example we'll say that this is an actually an on-premises",
    "start": "301530",
    "end": "306960"
  },
  {
    "text": "system we'll say it's actually a cloud-based system and oftentimes there are there's some really well-established players in this is V manage two managed",
    "start": "306960",
    "end": "315030"
  },
  {
    "text": "hospital systems market so we'll assume it's a managed service it could be running at a degree s probably is may",
    "start": "315030",
    "end": "321450"
  },
  {
    "text": "not be though and what this what the system is doing is pumping out admissions data in another medical",
    "start": "321450",
    "end": "327360"
  },
  {
    "text": "format called fire now fire is a rest-based protocol and it pushes Jason transactions to to a configured endpoint",
    "start": "327360",
    "end": "334920"
  },
  {
    "text": "and this is a very common pattern within the great integrating with them clinical systems and what we're going to do is",
    "start": "334920",
    "end": "340920"
  },
  {
    "text": "use the Amazon API gateway to receive these admission transactions these these are emission messages as they arrive and",
    "start": "340920",
    "end": "348000"
  },
  {
    "text": "the ape Amazon API gateway is going to go to perform the capture function there's a set of lambda code that will",
    "start": "348000",
    "end": "354300"
  },
  {
    "text": "parse those messages publish it to dynamo DB but more importantly for our data lake purposes we're going to feed",
    "start": "354300",
    "end": "360810"
  },
  {
    "text": "those jason transactions into our raw data bucket it's the same sort of bucket as we're talking earlier with our",
    "start": "360810",
    "end": "365880"
  },
  {
    "text": "discharge system and we'll go through that same process of looking up the catalog the data sources validating the",
    "start": "365880",
    "end": "372390"
  },
  {
    "text": "information that necessary extracting metadata feeding it into the elasticsearch cluster so that we can do",
    "start": "372390",
    "end": "377730"
  },
  {
    "text": "searches on it later on and then moving into the staging area and again we'll use the glue crawler and the and the",
    "start": "377730",
    "end": "384630"
  },
  {
    "text": "data catalog so now we've got two data sources sitting in our data catalog by",
    "start": "384630",
    "end": "391770"
  },
  {
    "text": "the way there's this particular pattern is that there's a published a solution blueprint today the abuse has published",
    "start": "391770",
    "end": "397470"
  },
  {
    "text": "that I'm I'll show in the in the there will be a link at the end of the presentation for this also the the",
    "start": "397470",
    "end": "403620"
  },
  {
    "text": "lambda code that I'm showing here that the moves that performs this validation and looks up the schema extracts",
    "start": "403620",
    "end": "409620"
  },
  {
    "text": "metadata is also available on github as well and I'll prepare a link for that",
    "start": "409620",
    "end": "414689"
  },
  {
    "text": "there's a link for that at the back of the sliders were back of the presentation as well so don't think you have to write all this code if you're",
    "start": "414689",
    "end": "420419"
  },
  {
    "text": "trying to build a data Lake so we'll add the third data source and this is the",
    "start": "420419",
    "end": "430710"
  },
  {
    "text": "whole collection of real-time systems now they're going to be a probably quite a mixed variety of systems they might",
    "start": "430710",
    "end": "436379"
  },
  {
    "text": "range from imaging systems sense sensors it could be scanners could even be things like environmental controls and",
    "start": "436379",
    "end": "442740"
  },
  {
    "text": "what we're going to do is use is capture logging information from those systems and feed them into our data lake now by",
    "start": "442740",
    "end": "448560"
  },
  {
    "text": "their nature this is likely to be a real-time type of system so it's feeding in real-time information and will",
    "start": "448560",
    "end": "453659"
  },
  {
    "text": "integrate with the logging systems the logger the systems are probably built using tools like calf curved log4j flew",
    "start": "453659",
    "end": "460889"
  },
  {
    "text": "and flew and D whole lot of open sourcing and commercial products and we're going to feed that in fact that",
    "start": "460889",
    "end": "465960"
  },
  {
    "text": "CSV data into Kinesis data streams and that that's a sharded model that's able",
    "start": "465960",
    "end": "471240"
  },
  {
    "text": "to sustain very large volumes of data now Kinesis data streams is then going to feed into Kinesis data firehose which",
    "start": "471240",
    "end": "479490"
  },
  {
    "text": "will batch up those those tiny transactions into into groups publish them as objects into s3 and then kicks",
    "start": "479490",
    "end": "485909"
  },
  {
    "text": "off the other standard process we've been looking at earlier where we're dropping that real-time data into a raw",
    "start": "485909",
    "end": "490979"
  },
  {
    "text": "bucket it triggers the process of looking up our data catalog extracting metadata and then feeding the data into",
    "start": "490979",
    "end": "498180"
  },
  {
    "text": "the staging bucket and then again running it through the glue crawler and making it available through the data",
    "start": "498180",
    "end": "503789"
  },
  {
    "text": "catalog just as a special point here the with real-time systems there's obviously a certain certain hour latency with this",
    "start": "503789",
    "end": "510569"
  },
  {
    "text": "sort of batched discovery and analysis process and some applications you want",
    "start": "510569",
    "end": "516089"
  },
  {
    "text": "to get a real-time window into what's going on in your real-time systems so there's another related Amazon Kinesis",
    "start": "516089",
    "end": "521789"
  },
  {
    "text": "service called data and data analytics that will actually work with the time rolling window of time to where you can",
    "start": "521789",
    "end": "528630"
  },
  {
    "text": "actually run SQL queries against their data as its flowing through the pipe in real time",
    "start": "528630",
    "end": "535100"
  },
  {
    "text": "so I've got out we've done our staging now we've got a nice clean validated dad",
    "start": "535200",
    "end": "540820"
  },
  {
    "text": "late to start working with we've got a populated data catalog that's been arm populated automatically through our",
    "start": "540820",
    "end": "546490"
  },
  {
    "text": "crawlers now it's time to do some analysis and generally the place to",
    "start": "546490",
    "end": "552460"
  },
  {
    "text": "start with the analysis is got all SQL reporting and visualization and the way",
    "start": "552460",
    "end": "557980"
  },
  {
    "text": "we're going to do that is we're going to use a service called Amazon Athena and the Athena will hook into the data",
    "start": "557980",
    "end": "564220"
  },
  {
    "text": "catalog which becomes its data dictionary and use the the the schema information and the location information",
    "start": "564220",
    "end": "570160"
  },
  {
    "text": "in that data catalog to run SQL queries directly against the s3 data so it",
    "start": "570160",
    "end": "576190"
  },
  {
    "text": "basically makes the s3 double ache and the Dikshit and the associate catalog look like an SQL data range data engine",
    "start": "576190",
    "end": "582820"
  },
  {
    "text": "and to the outside world out Cena is publishing supports protocols like JDBC",
    "start": "582820",
    "end": "589330"
  },
  {
    "text": "ODBC so from a tool from a point of view of a tool like tableau or clixsense or",
    "start": "589330",
    "end": "595180"
  },
  {
    "text": "um power bi click quick site it just looks like a regular old relational",
    "start": "595180",
    "end": "601240"
  },
  {
    "text": "database engine like Oracle or sequel server so it means we can leverage our",
    "start": "601240",
    "end": "606280"
  },
  {
    "text": "existing that the existing business reporting tools and existing skills and those business reporting tools but",
    "start": "606280",
    "end": "612100"
  },
  {
    "text": "actually run the whole data Lake or for a non-relational engine now that'll take",
    "start": "612100",
    "end": "618190"
  },
  {
    "text": "us so far but bear in mind that we're actually querying low very small s very",
    "start": "618190",
    "end": "623710"
  },
  {
    "text": "small objects in there in our data Lake and at some point the Dudley is going to grow to a point where that's not going",
    "start": "623710",
    "end": "629110"
  },
  {
    "text": "to be sustainable at least for some types of queries and we're gonna have to optimize the performance and the best",
    "start": "629110",
    "end": "634450"
  },
  {
    "text": "way to do that is to use Amazon glue to another aspect of Amazon glue to do",
    "start": "634450",
    "end": "641280"
  },
  {
    "text": "compression and partitioning of that data and the particular compression format this example is using as Apache",
    "start": "641280",
    "end": "648070"
  },
  {
    "text": "park' Apache park' is a columnar compression format it dramatically",
    "start": "648070",
    "end": "654130"
  },
  {
    "text": "accelerates the performance of queries by up to an order of magnitude compared to querying the objects directly because",
    "start": "654130",
    "end": "659920"
  },
  {
    "text": "Athena is a as a paper query saw the service will paper data scans for the service that also correspondingly drops",
    "start": "659920",
    "end": "666310"
  },
  {
    "text": "down the cost running the query as well so it's basically a win-win situation if you can",
    "start": "666310",
    "end": "671570"
  },
  {
    "text": "use compression in addition to that you can also use partitioning and",
    "start": "671570",
    "end": "677240"
  },
  {
    "text": "partitioning is a really powerful technique when there's a match between the the common constraints that you're",
    "start": "677240",
    "end": "682940"
  },
  {
    "text": "including area in your SQL queries and the partitioning key that you're storing the data under and if you think of an",
    "start": "682940",
    "end": "689240"
  },
  {
    "text": "example if you imagine you're using year and month as the as a partitioning key",
    "start": "689240",
    "end": "694280"
  },
  {
    "text": "then the query that says show me all of the patient or outpatient discharges for the current month is going to run",
    "start": "694280",
    "end": "700310"
  },
  {
    "text": "extremely quickly because Athena can look at that partition information and say I only need to tear the subset of my",
    "start": "700310",
    "end": "705680"
  },
  {
    "text": "data but I'm running the query you can also use that glued process to do",
    "start": "705680",
    "end": "710750"
  },
  {
    "text": "standardization of things like date/time stamps to make our life easier the people writing the use the SQL queries",
    "start": "710750",
    "end": "718660"
  },
  {
    "text": "now for some parts of your data even the thena with the park' compression it's not going to be good enough and some set",
    "start": "719110",
    "end": "725870"
  },
  {
    "text": "of users maybe you're the people doing in this case doing of follow ups and referrals to GPS might say we really",
    "start": "725870",
    "end": "733340"
  },
  {
    "text": "want to have with there's a really tight set of data that we need to access very quickly related to recent discharges",
    "start": "733340",
    "end": "740120"
  },
  {
    "text": "from the hospital so if you're really good at thinking that speed them up for us so we're going to do is drop in Amazon redshift onto our data Lake and",
    "start": "740120",
    "end": "747080"
  },
  {
    "text": "with redshift we can load subsets of data from s3 into redshift but also with",
    "start": "747080",
    "end": "752450"
  },
  {
    "text": "the spectrum feature there's it doesn't become a binary decision that the data is either in redshift or it's not we can",
    "start": "752450",
    "end": "757820"
  },
  {
    "text": "use the spectrum feature to perform unions and joins with with data it's",
    "start": "757820",
    "end": "763310"
  },
  {
    "text": "still sitting in s3 so we don't have to load the entire data set into redshift we can just lo the hot subset of that",
    "start": "763310",
    "end": "768950"
  },
  {
    "text": "data into redshift and have the best of both worlds so it's a really good way of balancing the cost performance of your",
    "start": "768950",
    "end": "775430"
  },
  {
    "text": "data Lake or your relational queries and obviously redshift still supports those standard JDBC ODBC protocols we can use",
    "start": "775430",
    "end": "783350"
  },
  {
    "text": "continue using familiar tools now that's all that's all well and good",
    "start": "783350",
    "end": "789580"
  },
  {
    "text": "for the business reporting guys but what about the data scientists they're not gonna be really happy if you just give them a bunch of SQL tools to work with",
    "start": "789580",
    "end": "795730"
  },
  {
    "text": "they're gonna one want to operate and say a managed notebook environment like Zeppelin or Jupiter notebooks they're",
    "start": "795730",
    "end": "802360"
  },
  {
    "text": "going to be going to want to be able to run spark jobs against their query so we can help them out by using using the nem",
    "start": "802360",
    "end": "809050"
  },
  {
    "text": "managed notebook features of Amazon the EMR and another aspect of the Amazon the",
    "start": "809050",
    "end": "814900"
  },
  {
    "text": "EMR that's really powerful for using with data lakes is a thing called the EMR file system or EMR FS and that X is",
    "start": "814900",
    "end": "821830"
  },
  {
    "text": "an overlay that makes an s3 and s3 said the buckets look like a Hadoop file",
    "start": "821830",
    "end": "827500"
  },
  {
    "text": "system from the perspective of tools like spark so you don't need to shuffle data from from s3 buckets into HDFS file",
    "start": "827500",
    "end": "836200"
  },
  {
    "text": "systems and back and forth again you can directly query the data in place using MRFs so that's that's taken the so far",
    "start": "836200",
    "end": "848590"
  },
  {
    "text": "but what about machine learning applications so what about machine learning so we've basically just scratched the surface here so with our",
    "start": "848590",
    "end": "855430"
  },
  {
    "text": "medical services we can run a service called Amazon comprehend medical and comprehend Medical is able to take some",
    "start": "855430",
    "end": "862180"
  },
  {
    "text": "of the clinical notes in written in free format text within our hl7 messages and",
    "start": "862180",
    "end": "867510"
  },
  {
    "text": "extract the the clinical terminology from those from that text so it's able",
    "start": "867510",
    "end": "873130"
  },
  {
    "text": "to pull out things like diagnosis medical condition conditions prescription medical prescriptions",
    "start": "873130",
    "end": "878830"
  },
  {
    "text": "anatomical terms symptoms all that sort of thing and then represent them as JSON",
    "start": "878830",
    "end": "884110"
  },
  {
    "text": "structures and you can see an example here where we've got a piece of unstructured clinical text as we've run",
    "start": "884110",
    "end": "891340"
  },
  {
    "text": "it through comprehends there's the JSON representation of the highlighted terms that comprehends produced and on the",
    "start": "891340",
    "end": "898270"
  },
  {
    "text": "right-hand side the bottom there's a there's a diagrammatic representation that the comprehend produces to help you",
    "start": "898270",
    "end": "904300"
  },
  {
    "text": "actually validate what's actually coming out of comprehend now this is this allows us to do to do a little bit",
    "start": "904300",
    "end": "911260"
  },
  {
    "text": "better than just um working with with keyword matches on the text because as you probably guess if you if you're just",
    "start": "911260",
    "end": "916960"
  },
  {
    "text": "matching on words like rash for example and the clinical notes say no sign of a rash then your keyword",
    "start": "916960",
    "end": "923620"
  },
  {
    "text": "search is going to say or there's a rash here but I'm you know there's a negation term in there now comprehend is able as",
    "start": "923620",
    "end": "929709"
  },
  {
    "text": "because it does natural language processing can recognize those negation terms it can recognize quantifiers and",
    "start": "929709",
    "end": "935589"
  },
  {
    "text": "so you're working on a firm basis when you're running your data like so again the plug comprehend into our data Lake",
    "start": "935589",
    "end": "941620"
  },
  {
    "text": "it's going to feed it's going to be triggered by the arrival of unstructured data in our staging bucket and we're",
    "start": "941620",
    "end": "947500"
  },
  {
    "text": "gonna use a lambda function to call comprehend produce those duration structures we're also going to go a step",
    "start": "947500",
    "end": "953470"
  },
  {
    "text": "further and actually what do matches into clinical terminology or taxonomy databases like sno-med and an icd-10",
    "start": "953470",
    "end": "961720"
  },
  {
    "text": "which are taxon and these for classifying diseases and symptoms and diagnosis and then we're going to come",
    "start": "961720",
    "end": "968680"
  },
  {
    "text": "store that codified data in a medica in the directory called med coded so now",
    "start": "968680",
    "end": "973839"
  },
  {
    "text": "we're getting a little bit further down the track with them the medical domain with our data Lake now comprehend is",
    "start": "973839",
    "end": "980950"
  },
  {
    "text": "really good if you're working that's a prepackaged application service pre-built on the corpus of medical knowledge but we won't actually go a",
    "start": "980950",
    "end": "987490"
  },
  {
    "text": "little bit better than that we want to actually do look for anomalies in med discharges and admissions to our to our",
    "start": "987490",
    "end": "994720"
  },
  {
    "text": "Hospital so these are things like say Oh an anomaly might be a an immediate",
    "start": "994720",
    "end": "1001380"
  },
  {
    "text": "readmission of a patient for a related condition soon after a discharge we're looking for things like that now there's",
    "start": "1001380",
    "end": "1007410"
  },
  {
    "text": "no Amazon pre-built service that's going to do that for us we're gonna have to train our own our own system to do that",
    "start": "1007410",
    "end": "1013579"
  },
  {
    "text": "we're going to use sage maker to do that and sage makers got a couple of dimensions to it it provides a notebook",
    "start": "1013579",
    "end": "1019350"
  },
  {
    "text": "a type of environment for data scientists to be able to leverage tools like redshift Amazon Athena run sort of",
    "start": "1019350",
    "end": "1025558"
  },
  {
    "text": "experiments and queries they can build training models in the experiment and iterate with those training models in a",
    "start": "1025559",
    "end": "1032100"
  },
  {
    "text": "in a very friendly interactive environment and at some point the and this is generally referred to as a",
    "start": "1032100",
    "end": "1037709"
  },
  {
    "text": "feature engineering process and at some point the the data scientists will say well we think we've actually got a a",
    "start": "1037709",
    "end": "1043920"
  },
  {
    "text": "working model for detecting anomalies in our discharges and they're not and admissions and we want to publish that",
    "start": "1043920",
    "end": "1050190"
  },
  {
    "text": "as a model so the next thing they will do is use sage maker the",
    "start": "1050190",
    "end": "1055290"
  },
  {
    "text": "which the model inference endpoint and then our dad lake is able to leverage that by writing a lambda function",
    "start": "1055290",
    "end": "1062690"
  },
  {
    "text": "triggered on the arrival of our medically coded data to go out to present the admission or the discharge",
    "start": "1062690",
    "end": "1069000"
  },
  {
    "text": "transaction to the model inference endpoint and the model inference will",
    "start": "1069000",
    "end": "1074310"
  },
  {
    "text": "then score that transaction to say what's the probability this is the anomalous discharge or or a readmission",
    "start": "1074310",
    "end": "1079740"
  },
  {
    "text": "and that that scoring result can be fed back into the data lake now once we get",
    "start": "1079740",
    "end": "1085740"
  },
  {
    "text": "a little bit more elaborate we can actually build an entire workflow around this inference chain and we can use step functions as a way of doing that so you",
    "start": "1085740",
    "end": "1092550"
  },
  {
    "text": "can have a whole series of inferences and models being a bay away that as part of our data like so we're sort of",
    "start": "1092550",
    "end": "1100920"
  },
  {
    "text": "closing the loop now and and you can see this is back basically where we started",
    "start": "1100920",
    "end": "1107150"
  },
  {
    "text": "what can we learn from this so some pro tips I think from this from this exercise first of all set some",
    "start": "1107720",
    "end": "1115020"
  },
  {
    "text": "achievable objectives feared are like a small number of business insights a small number of Davis Davis data sources",
    "start": "1115020",
    "end": "1120900"
  },
  {
    "text": "three Sprint's that sort of thing really good way place to start build a data catalog they can use the trace object",
    "start": "1120900",
    "end": "1126960"
  },
  {
    "text": "lineage or data lineage and query it and and also to discover schemas automatically so people aren't running",
    "start": "1126960",
    "end": "1132780"
  },
  {
    "text": "around making sure the data is what they think it is use parkade transforms to",
    "start": "1132780",
    "end": "1137940"
  },
  {
    "text": "actually optimize your queries to use columnar compression and speed up your queries you can process the s3 data",
    "start": "1137940",
    "end": "1145740"
  },
  {
    "text": "directly using em on the EMR clusters using MRFs so don't move data to and",
    "start": "1145740",
    "end": "1151710"
  },
  {
    "text": "from s3 and i and hadoop file systems processes in place using MRFs use",
    "start": "1151710",
    "end": "1157890"
  },
  {
    "text": "machine learning application services where they where they're good enough to do the job but then extend that further",
    "start": "1157890",
    "end": "1162900"
  },
  {
    "text": "by using your own machine learning models to enrich the data lake and feed back into the data lake so build a",
    "start": "1162900",
    "end": "1168180"
  },
  {
    "text": "virtuous cycle that way so i've presented a story here based on a",
    "start": "1168180",
    "end": "1175080"
  },
  {
    "text": "medical case study but I want to introduce David Scott from the network",
    "start": "1175080",
    "end": "1180120"
  },
  {
    "text": "and they said intelligence you know that the transport for New South Wales and David's going to present a very a",
    "start": "1180120",
    "end": "1185490"
  },
  {
    "text": "business perspective on the value of a data Lake and also presented quite a different",
    "start": "1185490",
    "end": "1190650"
  },
  {
    "text": "domain which is which is based on their journey planners application so this is basically journeys as opposed to to",
    "start": "1190650",
    "end": "1197880"
  },
  {
    "text": "medical information but what you'll find I hope is that when you look at some of the David's architecture and some of the",
    "start": "1197880",
    "end": "1203430"
  },
  {
    "text": "outcomes you'll see those same best practices and patterns being applied in a very different domain and I hope",
    "start": "1203430",
    "end": "1208620"
  },
  {
    "text": "they'll convince you that this is actually a generally applicable set of guidance it's all hand over to David",
    "start": "1208620",
    "end": "1215660"
  },
  {
    "text": "thanks Craig good morning okay so my most section of",
    "start": "1217700",
    "end": "1226110"
  },
  {
    "text": "the presentation is going to be quite different to Craig's I'm gonna probably focus almost entirely on the journey",
    "start": "1226110",
    "end": "1234450"
  },
  {
    "text": "we've gone and been on in terms of developing really a capability which is",
    "start": "1234450",
    "end": "1240720"
  },
  {
    "text": "designed to deliver a step change an improvement in customer experience for for the citizens of New South Wales or",
    "start": "1240720",
    "end": "1246630"
  },
  {
    "text": "anyone who really comes to our state and uses our transport options so like I",
    "start": "1246630",
    "end": "1255180"
  },
  {
    "text": "said our function is really established to come up with ways that we can help improve customer experience the the",
    "start": "1255180",
    "end": "1263490"
  },
  {
    "text": "domain that we've focused on for the last couple of years has been specific exclusively roads so if I go back you",
    "start": "1263490",
    "end": "1271650"
  },
  {
    "text": "know when I started with roads and maritime which is in within Transport for New South Wales it was a very very",
    "start": "1271650",
    "end": "1278220"
  },
  {
    "text": "siloed data environment with a really low little level of data literacy the",
    "start": "1278220",
    "end": "1284550"
  },
  {
    "text": "the ability to access information to make network improvements or to influence influence customer choice was",
    "start": "1284550",
    "end": "1292380"
  },
  {
    "text": "really it was really difficult yeah and so we've we've really focused sever the last two years in building capability",
    "start": "1292380",
    "end": "1298560"
  },
  {
    "text": "across all these different domains whether it be visualization data science",
    "start": "1298560",
    "end": "1303890"
  },
  {
    "text": "forecasting or even partnering with third parties to buy data that can help",
    "start": "1303890",
    "end": "1309150"
  },
  {
    "text": "us just make better choices about how we improve our roads network and I think",
    "start": "1309150",
    "end": "1316320"
  },
  {
    "text": "underpinning all of this was an ethos that we there we establish within within the group which was about democratize",
    "start": "1316320",
    "end": "1322380"
  },
  {
    "text": "data internally to really empower our colleagues to make better choices okay",
    "start": "1322380",
    "end": "1328080"
  },
  {
    "text": "so you know my background being banking in telco and those industries access to",
    "start": "1328080",
    "end": "1334679"
  },
  {
    "text": "information is an expectation okay but coming in the public service what I've found is people use that information is",
    "start": "1334679",
    "end": "1340530"
  },
  {
    "text": "power okay and so there's a vested interest to lock it away and and and use",
    "start": "1340530",
    "end": "1346650"
  },
  {
    "text": "it as the the one thing that you know that everyone else doesn't know okay that doesn't work for us and definitely",
    "start": "1346650",
    "end": "1351690"
  },
  {
    "text": "doesn't work for our in customer so so a bit of I just want to give you a bit of",
    "start": "1351690",
    "end": "1357870"
  },
  {
    "text": "insight into the journey that we've been on I'm hoping there's a few people here who are in the public sector I think",
    "start": "1357870",
    "end": "1364440"
  },
  {
    "text": "this is actually a really exciting story for us and I'd hope that you have the opportunity to do something yourselves",
    "start": "1364440",
    "end": "1370289"
  },
  {
    "text": "which is quite similar so so if we go back rewind to February 2018 we had",
    "start": "1370289",
    "end": "1376380"
  },
  {
    "text": "about five people with with the skills and the ability to access data to understand what was happening on the",
    "start": "1376380",
    "end": "1382320"
  },
  {
    "text": "roads network and maybe two or three of our stakeholders we might just let them access the information but they had to",
    "start": "1382320",
    "end": "1388320"
  },
  {
    "text": "pass a series of tests before we'd enable them fast forward to when this",
    "start": "1388320",
    "end": "1393840"
  },
  {
    "text": "slide was done in July we did increase our numbers to about 60 analysts data scientists engineers but the combination",
    "start": "1393840",
    "end": "1401340"
  },
  {
    "text": "of permanent headcount and plus augmenting with with various partners and we've also started enabling our",
    "start": "1401340",
    "end": "1408450"
  },
  {
    "text": "internal stakeholders so in addition to my group having access to a whole new",
    "start": "1408450",
    "end": "1413820"
  },
  {
    "text": "range of information on a single platform which is AWS we've now enabled",
    "start": "1413820",
    "end": "1418980"
  },
  {
    "text": "people across the organization to have access to better information which is really you know starting to ramp up in",
    "start": "1418980",
    "end": "1426059"
  },
  {
    "text": "terms of the value that we can deliver to our end consumers from an operating model perspective heard a couple of",
    "start": "1426059",
    "end": "1432240"
  },
  {
    "text": "people speak over the last couple of days we are fully agile so we run scrums",
    "start": "1432240",
    "end": "1437640"
  },
  {
    "text": "it's a DevOps environment so we've got the people who didn't development on AWS very close to the people who are working",
    "start": "1437640",
    "end": "1444390"
  },
  {
    "text": "with stakeholders understanding the opportunities and the problems for the business and really focusing on",
    "start": "1444390",
    "end": "1450000"
  },
  {
    "text": "delivering value so lokay where I started you know our vision is to",
    "start": "1450000",
    "end": "1456210"
  },
  {
    "text": "deliver a step change improvement in customer experience and so what that means when he speak when I when he when",
    "start": "1456210",
    "end": "1461400"
  },
  {
    "text": "we talk about agile ways of working every single thing we do needs to tie back to a customer outcome and agile has",
    "start": "1461400",
    "end": "1468960"
  },
  {
    "text": "been really important in making sure that we keep our team really aligned and focused on high-value initiatives and",
    "start": "1468960",
    "end": "1476220"
  },
  {
    "text": "then from a technology perspective you know if I go back to February 2018 you",
    "start": "1476220",
    "end": "1481380"
  },
  {
    "text": "know we weren't using the right tools our above enterprise data warehouse was a sequel server which was completely not",
    "start": "1481380",
    "end": "1488070"
  },
  {
    "text": "fit for purpose we've now gone to you know full AWS stack wherever possible",
    "start": "1488070",
    "end": "1493770"
  },
  {
    "text": "we've we've stayed really close to the native technologies and that's allowed us to really ramp up quite quickly so so",
    "start": "1493770",
    "end": "1502110"
  },
  {
    "text": "getting access to to AWS from IEEE group really only started to to ramp up in",
    "start": "1502110",
    "end": "1508920"
  },
  {
    "text": "February this year and we've already got over about a hundred and thirty terabytes of data and I've got one",
    "start": "1508920",
    "end": "1515700"
  },
  {
    "text": "example that I'll talk to in a second where we're really starting to deliver high-value initiatives but the focus",
    "start": "1515700",
    "end": "1522990"
  },
  {
    "text": "isn't just on doing management reporting or you know supporting our more",
    "start": "1522990",
    "end": "1530280"
  },
  {
    "text": "traditional infrastructure build the the the way we're moving is towards using technologies like AWS that allows us to",
    "start": "1530280",
    "end": "1537750"
  },
  {
    "text": "not only build the data like structure the data but also build applications",
    "start": "1537750",
    "end": "1543480"
  },
  {
    "text": "that are customer facing so instead of being limited like you know many of the",
    "start": "1543480",
    "end": "1549060"
  },
  {
    "text": "other groups that I've worked in in the past where you your main focus as an analytics expert is is on you know",
    "start": "1549060",
    "end": "1556490"
  },
  {
    "text": "improving business processes or driving more sales really what's happening here",
    "start": "1556490",
    "end": "1562650"
  },
  {
    "text": "is our people are focused on delivering better outcomes for customers and really being able to take products all the way",
    "start": "1562650",
    "end": "1568830"
  },
  {
    "text": "through to market so it's as Craig",
    "start": "1568830",
    "end": "1574410"
  },
  {
    "text": "mentioned this is this is actually a new product that we've we've launched only last few days we're calling it our",
    "start": "1574410",
    "end": "1581220"
  },
  {
    "text": "journey planner so I might take you back I guess like I said you know we really",
    "start": "1581220",
    "end": "1587400"
  },
  {
    "text": "spent the last sort of 18 months building capability but what I wanted to do with",
    "start": "1587400",
    "end": "1592760"
  },
  {
    "text": "with my group was give them a bit of permission to challenge the status quo so the first place we started was we",
    "start": "1592760",
    "end": "1599389"
  },
  {
    "text": "said okay you know we've been doing a lot of - boarding a lot of analysis - to",
    "start": "1599389",
    "end": "1606139"
  },
  {
    "text": "really understand what's happening in terms of demand let's start communicating out to the end consumer so",
    "start": "1606139",
    "end": "1612019"
  },
  {
    "text": "in December released some forecasts you know where we were communicated with the end customer we said ok these are the",
    "start": "1612019",
    "end": "1618260"
  },
  {
    "text": "places around the roads network where we expect you're going to have a pretty bad experience leaving Sydney around",
    "start": "1618260",
    "end": "1623600"
  },
  {
    "text": "Christmas so we did that we got a little bit of traction I wouldn't say it was too much but I guess we wanted to keep",
    "start": "1623600",
    "end": "1630740"
  },
  {
    "text": "going and so we we in April release some more information for Easter again really",
    "start": "1630740",
    "end": "1637460"
  },
  {
    "text": "not really giving the end consumer any tool but just giving advice ok in June",
    "start": "1637460",
    "end": "1643279"
  },
  {
    "text": "we wanted to ramp it up a bit so we laid in and laid down a challenge for the team we gave them 6 days and we said ok",
    "start": "1643279",
    "end": "1651350"
  },
  {
    "text": "in the next six days we won't need to come up with an application that we can release to the end consumer to help them",
    "start": "1651350",
    "end": "1656720"
  },
  {
    "text": "plan their journeys around the the June long weekend so we came up with that version one of the journey planner it",
    "start": "1656720",
    "end": "1662630"
  },
  {
    "text": "did not look like this ok but six days you expectations can't be too high anyway it was an amazing result so of a",
    "start": "1662630",
    "end": "1669799"
  },
  {
    "text": "zero base we had about 13,000 hits to our microsite we were able to identify",
    "start": "1669799",
    "end": "1675529"
  },
  {
    "text": "really significant changes in demand for some of those hot spots so for anyone",
    "start": "1675529",
    "end": "1680779"
  },
  {
    "text": "who knows Sydney think about the m1 at moronga living Sydney going north or the",
    "start": "1680779",
    "end": "1686179"
  },
  {
    "text": "Hume going south we could absolutely measure some real changes in demand and",
    "start": "1686179",
    "end": "1693139"
  },
  {
    "text": "seeing people change their journeys and move their journey times to time when the the amount of traffic was going to",
    "start": "1693139",
    "end": "1700880"
  },
  {
    "text": "be a little bit lower so with this new version now we've now modelled 16",
    "start": "1700880",
    "end": "1706720"
  },
  {
    "text": "different Road segments across the network where we know that we've got some pretty significant congestion the",
    "start": "1706720",
    "end": "1715220"
  },
  {
    "text": "idea is it's always on so you can forecast out for about seven days and you you get a pretty good expectation",
    "start": "1715220",
    "end": "1722600"
  },
  {
    "text": "to what we expect we've used just basic linear regression to do the predictions",
    "start": "1722600",
    "end": "1728950"
  },
  {
    "text": "we get an R square for the checks in the room of about 0.9 7 so it's very very",
    "start": "1728950",
    "end": "1734270"
  },
  {
    "text": "accurate we can explain almost all of the all of the variability in the demand",
    "start": "1734270",
    "end": "1740530"
  },
  {
    "text": "with a really simple model and what we've also done is we've given people the ability to go back in time and",
    "start": "1740530",
    "end": "1746780"
  },
  {
    "text": "evaluate what the demand was versus our forecast ok and so um this is live now feel free",
    "start": "1746780",
    "end": "1752870"
  },
  {
    "text": "to jump on it except wait till I'm finished talking and so so if you look at a corridor like Parramatta Road where",
    "start": "1752870",
    "end": "1759530"
  },
  {
    "text": "we've just opened the the extension to the m4 our models are wrong ok and it's",
    "start": "1759530",
    "end": "1766669"
  },
  {
    "text": "because of this approach you need a bit of history but what it shows is and what the big the big benefit to us is the",
    "start": "1766669",
    "end": "1774080"
  },
  {
    "text": "Roads agency is we can now start to explain the benefits that we can deliver to the end consumer budget by opening",
    "start": "1774080",
    "end": "1781970"
  },
  {
    "text": "these new corridors so we're saying about 2 200 200 cars per every 15",
    "start": "1781970",
    "end": "1788780"
  },
  {
    "text": "minutes decrease on Parramatta Road which which is leading to much more",
    "start": "1788780",
    "end": "1793909"
  },
  {
    "text": "significant sorry much more consistent journey times anyway so yeah I think for",
    "start": "1793909",
    "end": "1800720"
  },
  {
    "text": "us this is very much a work in progress it's it's all using AWS technologies our",
    "start": "1800720",
    "end": "1809570"
  },
  {
    "text": "vision is to make it real time so the the demand data that you see there which",
    "start": "1809570",
    "end": "1814580"
  },
  {
    "text": "we pick up from a traffic light system we're updating daily but in the next",
    "start": "1814580",
    "end": "1820039"
  },
  {
    "text": "couple of months we do intend to introduce real-time data to this",
    "start": "1820039",
    "end": "1825289"
  },
  {
    "text": "application and so the intention is or our vision is is that over time people",
    "start": "1825289",
    "end": "1831590"
  },
  {
    "text": "will change decisions about when they travel and start traveling at times when",
    "start": "1831590",
    "end": "1836600"
  },
  {
    "text": "they're going to get a much better experience so I'm not going to go",
    "start": "1836600",
    "end": "1843830"
  },
  {
    "text": "through the technical services I think Craig would do a much better job than me but I think if you do have any questions",
    "start": "1843830",
    "end": "1850370"
  },
  {
    "text": "about these services that we have applied feel free to grab me after",
    "start": "1850370",
    "end": "1856450"
  },
  {
    "text": "and that's it thank you thank you Vic",
    "start": "1857020",
    "end": "1865220"
  },
  {
    "text": "it's the promise links to any of those clinical information sources or the data Lake pattern if you need them thank you",
    "start": "1865220",
    "end": "1874419"
  }
]
[
  {
    "text": "hi everybody thanks for coming so early my name is Tim secor I'm the manager of",
    "start": "0",
    "end": "5160"
  },
  {
    "text": "developer productivity at octa we're out of San Francisco and today we're going",
    "start": "5160",
    "end": "12090"
  },
  {
    "text": "to talk about CI using AWS services we use a hundred percent AWS services for",
    "start": "12090",
    "end": "19920"
  },
  {
    "text": "our CI CD pipeline and so today I'm going to talk a little bit about who opt is how octa engineering works the",
    "start": "19920",
    "end": "26849"
  },
  {
    "text": "challenge of my team in particular and then some detail on the CI system that we built using Amazon ec2 container",
    "start": "26849",
    "end": "33239"
  },
  {
    "text": "service and docker so at octa we connect everything we connect the users devices",
    "start": "33239",
    "end": "39510"
  },
  {
    "text": "applications organizations we have SSO adaptive mfa mobility where the leader",
    "start": "39510",
    "end": "46680"
  },
  {
    "text": "in the magic quadrant and enforcer wave and we believe that connecting everybody will make organizations more productive",
    "start": "46680",
    "end": "53730"
  },
  {
    "text": "and more secure above all we ensure that our customers are successful millions of",
    "start": "53730",
    "end": "62250"
  },
  {
    "text": "people use octa every day and thousands of enterprises use octa to connect to",
    "start": "62250",
    "end": "68520"
  },
  {
    "text": "Adobe's Creative Cloud and we have thousands of enterprise customers",
    "start": "68520",
    "end": "74990"
  },
  {
    "text": "we have a platform architecture that's built from the ground up for scale we have redundancy and scalability built in",
    "start": "81930",
    "end": "89530"
  },
  {
    "text": "where the most reliable identity as a service and we're never taken offline you can see our stats at octa calm /",
    "start": "89530",
    "end": "98740"
  },
  {
    "text": "trust if you want more information and we are currently spread throughout most",
    "start": "98740",
    "end": "105549"
  },
  {
    "text": "of Amazon's global centers so engineering how do we work and ship our",
    "start": "105549",
    "end": "114789"
  },
  {
    "text": "code we have two hundred engineers and they each have their split into teams",
    "start": "114789",
    "end": "120369"
  },
  {
    "text": "with embedded specialists we have embedded test engineers we have embedded you I engineers and we have one week",
    "start": "120369",
    "end": "126459"
  },
  {
    "text": "sprints we deploy every week to production so we have a lot of changes that go out on a very continual basis",
    "start": "126459",
    "end": "133690"
  },
  {
    "text": "and we have the ability to push out more than one hotfix per day if we need to we try not to we try to keep it keep it",
    "start": "133690",
    "end": "140410"
  },
  {
    "text": "back to 11 per week but if customers have urgent requests or we find bugs or",
    "start": "140410",
    "end": "146579"
  },
  {
    "text": "we find something we need to change then we can push out and so we have to have code ready to do that at any time so",
    "start": "146579",
    "end": "153700"
  },
  {
    "text": "therefore every merge to master that a developer makes has to be a potential",
    "start": "153700",
    "end": "159430"
  },
  {
    "text": "release candidate has to be ready to go out so in order to do this we have to",
    "start": "159430",
    "end": "165459"
  },
  {
    "text": "have all of our topic branches go that go in go through the same amount of testing as our master branches as our",
    "start": "165459",
    "end": "173170"
  },
  {
    "text": "release candidates and we do this by enforcing that all the tests run the",
    "start": "173170",
    "end": "178570"
  },
  {
    "text": "same number of tests run on all topics as run on our release candidates our",
    "start": "178570",
    "end": "184269"
  },
  {
    "text": "largest repo has 30,000 tests and it can take about an hour to run with 22 parallel tests test Suites our smallest",
    "start": "184269",
    "end": "192790"
  },
  {
    "text": "repo maybe has 100 tests runs in a couple of minutes and my team the",
    "start": "192790",
    "end": "198100"
  },
  {
    "text": "developer productivity team is responsible for supporting an engineering and getting all of these tests run for them so the challenges",
    "start": "198100",
    "end": "206319"
  },
  {
    "text": "that we face in developer productivity are that we have to have to offer a good",
    "start": "206319",
    "end": "212170"
  },
  {
    "text": "developer experience to our team we have to make sure that they get a good turnaround time that",
    "start": "212170",
    "end": "217209"
  },
  {
    "text": "when they commit to master when they commit to topic branches they know that all the tests that are necessary will be",
    "start": "217209",
    "end": "222310"
  },
  {
    "text": "run and they'll get results in a short period of time we need to to ensure that",
    "start": "222310",
    "end": "228400"
  },
  {
    "text": "their that the tests are all run to support the quality team to make sure that we've tested everything there are",
    "start": "228400",
    "end": "233980"
  },
  {
    "text": "no regressions in all the topic branches before they go in and as far as cost we",
    "start": "233980",
    "end": "239799"
  },
  {
    "text": "need to make sure that we we don't spend too much money it's very easy to spin up many many servers and spend more than",
    "start": "239799",
    "end": "246849"
  },
  {
    "text": "several engineers pay on a lot of CI servers in order to service all of our",
    "start": "246849",
    "end": "252549"
  },
  {
    "text": "engineers we try not to do that and we aim T's cloud services whenever possible",
    "start": "252549",
    "end": "257979"
  },
  {
    "text": "it's a lot easier than maintaining local machines so the problems we've",
    "start": "257979",
    "end": "263020"
  },
  {
    "text": "encountered in running this CI system we started out using open-source monolithic",
    "start": "263020",
    "end": "269680"
  },
  {
    "text": "applications and you can see here all of this is this is a diagram of our system",
    "start": "269680",
    "end": "274720"
  },
  {
    "text": "several months ago and you can see that there's the yellow is the developer the",
    "start": "274720",
    "end": "281050"
  },
  {
    "text": "green our services one of them is Amazon and the rest were all ec2 machines and",
    "start": "281050",
    "end": "287050"
  },
  {
    "text": "they but we had to maintain them we had to make sure their disks didn't fill up we had to apply security patches we had",
    "start": "287050",
    "end": "293530"
  },
  {
    "text": "to do OS upgrades we had to do a lot of things and we basically spent a lot of",
    "start": "293530",
    "end": "298570"
  },
  {
    "text": "our time doing IT support for our own systems so a couple of these we can",
    "start": "298570",
    "end": "305560"
  },
  {
    "text": "replace pretty directly with SQS and we've done that some of these we can",
    "start": "305560",
    "end": "312880"
  },
  {
    "text": "replace with lambda and what we had before we had some home built programs",
    "start": "312880",
    "end": "319090"
  },
  {
    "text": "that were running on a server on an ec2 machine and they had to talk to many different servers and figure out how",
    "start": "319090",
    "end": "326590"
  },
  {
    "text": "many machines we needed and spin those up and the machines took a long time to come up and it was very it was very",
    "start": "326590",
    "end": "333520"
  },
  {
    "text": "brittle so that's been replaced with with lambda and then we have a couple of",
    "start": "333520",
    "end": "340270"
  },
  {
    "text": "these which were good candidates these are homegrown apps we have reporting app",
    "start": "340270",
    "end": "345810"
  },
  {
    "text": "that that has a lot the octa policy built into it and we have some test analytics that we run",
    "start": "345810",
    "end": "352720"
  },
  {
    "text": "against our all of our tests and these were great candidates for being run on ecs as services the one that we spent",
    "start": "352720",
    "end": "361330"
  },
  {
    "text": "the most time on because it has the most machines and cost the most money are the",
    "start": "361330",
    "end": "366340"
  },
  {
    "text": "is the slave pool we were running over 100 machines per day and I think we were",
    "start": "366340",
    "end": "371889"
  },
  {
    "text": "at one point running 120 and that was as much as our master build server could handle and we wanted to scale higher",
    "start": "371889",
    "end": "378280"
  },
  {
    "text": "without having to deal with the complexity of having multiple masters and synchronizing them and reporting all",
    "start": "378280",
    "end": "384370"
  },
  {
    "text": "the output of that so the vision that we had for our system was the following we",
    "start": "384370",
    "end": "393970"
  },
  {
    "text": "wanted to have clean test environments with the old system a lot of the machines the ec2 machines they're slow",
    "start": "393970",
    "end": "399820"
  },
  {
    "text": "to spin up they would carry over a lot of the changes from a previous job into",
    "start": "399820",
    "end": "405490"
  },
  {
    "text": "the next job if you give if you give your developers as much latitude as we do with their build scripts they will",
    "start": "405490",
    "end": "412300"
  },
  {
    "text": "find a way to make the machine not revert to a clean state when they're done so we wanted to have a clean test",
    "start": "412300",
    "end": "420460"
  },
  {
    "text": "environment for parallel runs where we're running to test Suites on the same machine as well as serial runs so that",
    "start": "420460",
    "end": "426130"
  },
  {
    "text": "they don't leave things behind for the next test dynamic worker scaling we",
    "start": "426130",
    "end": "432610"
  },
  {
    "text": "wanted to have very very dynamic scaling we didn't want to worry about the granularity of billing when we were",
    "start": "432610",
    "end": "439860"
  },
  {
    "text": "scaling up and down our worker pool we wanted our workers to be able to survive",
    "start": "439860",
    "end": "445620"
  },
  {
    "text": "the loss of their servers and we didn't want to worry about the machines that",
    "start": "445620",
    "end": "451330"
  },
  {
    "text": "the main build server was running on we didn't want to worry about the memory of it worrying about scaling it worried",
    "start": "451330",
    "end": "456970"
  },
  {
    "text": "about disk space on it anything like that",
    "start": "456970",
    "end": "460650"
  },
  {
    "text": "we also wanted to start using spot instances because anyone who's looked at",
    "start": "464539",
    "end": "471270"
  },
  {
    "text": "the spot instance charts will see that you can save a lot of money they run for a fraction of the price of an on-demand",
    "start": "471270",
    "end": "478020"
  },
  {
    "text": "instance and with our testing environments we run a lot of short-lived",
    "start": "478020",
    "end": "484759"
  },
  {
    "text": "tasks that take a few minutes if they go down because of a spot price fluctuation",
    "start": "484759",
    "end": "490590"
  },
  {
    "text": "we can just rerun them and they'll be right back up there and we'll get our we'll get our results will just get them a few minutes late we wanted to enable",
    "start": "490590",
    "end": "499409"
  },
  {
    "text": "version testing so that we could actually run different versions of the",
    "start": "499409",
    "end": "504479"
  },
  {
    "text": "build infrastructure underneath different versions of the code we wanted to be able to tie our code together with",
    "start": "504479",
    "end": "510720"
  },
  {
    "text": "our infrastructure and we had some ways of doing that but it it involved a lot",
    "start": "510720",
    "end": "516060"
  },
  {
    "text": "of work on our side and the developers can really do it themselves our queuing",
    "start": "516060",
    "end": "521370"
  },
  {
    "text": "system was terrible it was it was tied to the machines that were running and I don't think that the queue should",
    "start": "521370",
    "end": "527850"
  },
  {
    "text": "necessarily care about the workers that are pulling from the queue and it didn't",
    "start": "527850",
    "end": "533490"
  },
  {
    "text": "have very good visibility we had to write our own our own dashboard for that so this seemed like a good candidate for",
    "start": "533490",
    "end": "539970"
  },
  {
    "text": "SQS and that's what we ended up replacing it with we wanted less infrastructure flakiness we basically",
    "start": "539970",
    "end": "545730"
  },
  {
    "text": "wanted to be able to focus on the infrastructure in our team and we didn't want to have to focus on the build",
    "start": "545730",
    "end": "551579"
  },
  {
    "text": "environment that the developer is needed so we wanted to push some of that the the build environment out to the",
    "start": "551579",
    "end": "557790"
  },
  {
    "text": "developers so they could actually maintain that set up a system in a way that they needed it to run their tests",
    "start": "557790",
    "end": "563370"
  },
  {
    "text": "to test their code and we could just focus on making our infrastructure less flaky and also we wanted to be able to",
    "start": "563370",
    "end": "573120"
  },
  {
    "text": "run we basically want a multi-tenancy within our company we wanted to be able to have some of our groups running in",
    "start": "573120",
    "end": "580589"
  },
  {
    "text": "the same clusters in the same set of slaves as other groups without worrying about credentials spilling over and",
    "start": "580589",
    "end": "588649"
  },
  {
    "text": "anybody getting access to something that they shouldn't so the solutions that we",
    "start": "588649",
    "end": "594180"
  },
  {
    "text": "came up to with these problems we used ec2 container surface and docker",
    "start": "594180",
    "end": "601870"
  },
  {
    "text": "we have many amazon web services and then we have custom java web apps that",
    "start": "601870",
    "end": "608930"
  },
  {
    "text": "we built and those are running in ecs and we built our own front end our own",
    "start": "608930",
    "end": "614899"
  },
  {
    "text": "reporting server the docker allows us to have immutable and disposable build",
    "start": "614899",
    "end": "620480"
  },
  {
    "text": "workers we can create them destroy them every time you bring one up it's just",
    "start": "620480",
    "end": "625819"
  },
  {
    "text": "clean you don't have to worry about resetting the system it costs us",
    "start": "625819",
    "end": "630860"
  },
  {
    "text": "basically nothing on the weekends we get our we get our slave pull down to near",
    "start": "630860",
    "end": "636079"
  },
  {
    "text": "zero and the all the tools that we're using are basically free so all we ended",
    "start": "636079",
    "end": "643160"
  },
  {
    "text": "up you spending money on now are the ec2 instances and if you compare the amount of money we're spending on all the other",
    "start": "643160",
    "end": "649279"
  },
  {
    "text": "services combined it's a blip on the on the graph sorry let me go back one the",
    "start": "649279",
    "end": "658639"
  },
  {
    "text": "ecs allows us to maximize the usage of the of the machines because before when you spin up a machine for a five minute",
    "start": "658639",
    "end": "665240"
  },
  {
    "text": "job if that job was done in five minutes it would take a couple minutes to spin off the machine the job would finish in",
    "start": "665240",
    "end": "671779"
  },
  {
    "text": "a couple of minutes and then you'd have to pay for the whole hour and by using ec2 or ecs we were able to then launch",
    "start": "671779",
    "end": "679029"
  },
  {
    "text": "more jobs that were from different test Suites on the same machine immediately",
    "start": "679029",
    "end": "684559"
  },
  {
    "text": "afterward we could use the same containers for multiple types and we didn't have to wipe the machine",
    "start": "684559",
    "end": "691519"
  },
  {
    "text": "completely we didn't have to worry about what areas of the machine were touched by a test suite we could just throw it",
    "start": "691519",
    "end": "697759"
  },
  {
    "text": "throw the machine image away and spin up another one immediately so we built a",
    "start": "697759",
    "end": "703490"
  },
  {
    "text": "custom reporting app and this is our largest test suite you can see that it's running 22 sweets all at once we use we",
    "start": "703490",
    "end": "713149"
  },
  {
    "text": "have selective retry so we only rerun the tests that fail and this takes a",
    "start": "713149",
    "end": "720230"
  },
  {
    "text": "little bit under an hour so if how many",
    "start": "720230",
    "end": "727819"
  },
  {
    "text": "people here are using docker and their current systems cool okay it's like third maybe",
    "start": "727819",
    "end": "735080"
  },
  {
    "text": "a little bit more than a third I can't actually click on this but if you want a",
    "start": "735080",
    "end": "740120"
  },
  {
    "text": "good good website to go and look go to docker com they have a lot of courses",
    "start": "740120",
    "end": "746900"
  },
  {
    "text": "they have a lot of training there they have a lot of how to's this link will take you directly to the comparison",
    "start": "746900",
    "end": "752690"
  },
  {
    "text": "between VMS and docker images and the main difference is that docker images",
    "start": "752690",
    "end": "758390"
  },
  {
    "text": "don't contain a whole OS and they're able to share the underlying resources of the host machine with other docker",
    "start": "758390",
    "end": "765740"
  },
  {
    "text": "containers that are running at the same time that allows you to run more of them on the machine as long as you're not",
    "start": "765740",
    "end": "771200"
  },
  {
    "text": "overusing overtaxing the machine to update the docker images once you have",
    "start": "771200",
    "end": "778340"
  },
  {
    "text": "an image that you want to run we update our docker file in a docker file is kind",
    "start": "778340",
    "end": "783920"
  },
  {
    "text": "of like a user data file or chef recipe it's something that will take a base",
    "start": "783920",
    "end": "790190"
  },
  {
    "text": "docker image lay new layers on top of it and then it will spit out a new docker image we have a CI system set up so that",
    "start": "790190",
    "end": "798380"
  },
  {
    "text": "we can change our docker files on the on the fly and then we can push out the new",
    "start": "798380",
    "end": "803720"
  },
  {
    "text": "image and have it be running in our system pretty quickly and then when we",
    "start": "803720",
    "end": "808910"
  },
  {
    "text": "want to update the whole cluster we can update the task definition of the tasks",
    "start": "808910",
    "end": "816050"
  },
  {
    "text": "that we're running on the cluster and that will just go out with the next task that we send to that cluster here's an",
    "start": "816050",
    "end": "823340"
  },
  {
    "text": "example of the dockerfile if you haven't seen it before you can see the first line we're calling from an internal",
    "start": "823340",
    "end": "830180"
  },
  {
    "text": "service to make sure that we're not pulling external images that we don't",
    "start": "830180",
    "end": "835850"
  },
  {
    "text": "know anything about we install a few libraries that we need we install some",
    "start": "835850",
    "end": "841870"
  },
  {
    "text": "some let's see that we don't actually",
    "start": "841870",
    "end": "847400"
  },
  {
    "text": "have that line in here but on some of them yeah we don't have that here so we",
    "start": "847400",
    "end": "855620"
  },
  {
    "text": "set up the ports and then we set up the the command that's going to run when the when the image is launched and when a",
    "start": "855620",
    "end": "862730"
  },
  {
    "text": "new create tanner is created now we have a lot of",
    "start": "862730",
    "end": "867920"
  },
  {
    "text": "security conventions that we've come up with when we're using docker and one of",
    "start": "867920",
    "end": "873170"
  },
  {
    "text": "them is the one I just mentioned from the docker file which is don't allow containers from outside unless you know",
    "start": "873170",
    "end": "881300"
  },
  {
    "text": "what you're doing so what we have done is we've taken the containers from third",
    "start": "881300",
    "end": "887149"
  },
  {
    "text": "parties that we know and we trust and we've built on top of those and then we store them in internal repositories this",
    "start": "887149",
    "end": "892940"
  },
  {
    "text": "just keeps us from pulling maybe the latest version of something from outside and building with it on our internal",
    "start": "892940",
    "end": "899300"
  },
  {
    "text": "system without knowing what's there you can use J frog x-ray for doing security scanning of containers and we're setting",
    "start": "899300",
    "end": "905779"
  },
  {
    "text": "that up now you can use C adviser from google that that works well for us and",
    "start": "905779",
    "end": "912579"
  },
  {
    "text": "another important thing is to never bake any secure any secrets into your",
    "start": "912579",
    "end": "918589"
  },
  {
    "text": "containers into the images there there are some newer things in docker 110",
    "start": "918589",
    "end": "926620"
  },
  {
    "text": "where you can run the container is a non privileged user and so this is what",
    "start": "926620",
    "end": "932600"
  },
  {
    "text": "we're starting to do now we're starting to run in different space so that we don't have access we don't give one",
    "start": "932600",
    "end": "938690"
  },
  {
    "text": "container access to resources from another container ok so our build",
    "start": "938690",
    "end": "949579"
  },
  {
    "text": "conventions are that our tests run",
    "start": "949579",
    "end": "954649"
  },
  {
    "text": "against code running a container we build immutable versions and publish the",
    "start": "954649",
    "end": "962810"
  },
  {
    "text": "artifact server and we have rules that we enforce at the CI level for where we",
    "start": "962810",
    "end": "970640"
  },
  {
    "text": "pull where we pull from the artifact server for the convention of the image that we create and we actually have the",
    "start": "970640",
    "end": "978260"
  },
  {
    "text": "docker files checked in to each project repository so that the the images that",
    "start": "978260",
    "end": "984680"
  },
  {
    "text": "are created to run a project to run code are are built from code that's with that",
    "start": "984680",
    "end": "991100"
  },
  {
    "text": "code so we have the infrastructure that we're running it on closely tied to the",
    "start": "991100",
    "end": "996800"
  },
  {
    "text": "code that we're at chilly running and also we never use",
    "start": "996800",
    "end": "1001930"
  },
  {
    "text": "latest as it tends to allow new code",
    "start": "1001930",
    "end": "1007240"
  },
  {
    "text": "that's untested to come in and and break our system this is a sketch of our of",
    "start": "1007240",
    "end": "1014620"
  },
  {
    "text": "our build process and it just shows the developers can check-in it automatically",
    "start": "1014620",
    "end": "1019660"
  },
  {
    "text": "goes through CI creates new images and spits the images out on the other end where there then usable and we push",
    "start": "1019660",
    "end": "1026520"
  },
  {
    "text": "images of our projects to our internal artifactory docker server and we put the",
    "start": "1026520",
    "end": "1035829"
  },
  {
    "text": "images that we use for our CI system we store those in ECR and amazon's ECR and",
    "start": "1035829",
    "end": "1040900"
  },
  {
    "text": "that does really well for us for logging and monitoring we make sure that we we",
    "start": "1040900",
    "end": "1048339"
  },
  {
    "text": "have a an agreement that we will just write all of our errors out to standard",
    "start": "1048339",
    "end": "1053800"
  },
  {
    "text": "out and we give all of the logging responsibilities to the host and we'll",
    "start": "1053800",
    "end": "1059380"
  },
  {
    "text": "talk about the host more in the next section on ecs and then we write all",
    "start": "1059380",
    "end": "1064900"
  },
  {
    "text": "that to a centralized splunk server so that everybody in our company everybody in our development team has access to",
    "start": "1064900",
    "end": "1072220"
  },
  {
    "text": "the logs and they don't have to go searching around and anything that happens on one of our machines just gets",
    "start": "1072220",
    "end": "1077860"
  },
  {
    "text": "written to the central login server so if you want a good place to read about",
    "start": "1077860",
    "end": "1084400"
  },
  {
    "text": "ec2 or ecs how many people here are using ecs right now so it looks like a",
    "start": "1084400",
    "end": "1092100"
  },
  {
    "text": "lot less than docker if you want a good",
    "start": "1092100",
    "end": "1097570"
  },
  {
    "text": "good place to look you can get this link off of the the slide show that you'll be",
    "start": "1097570",
    "end": "1103179"
  },
  {
    "text": "able to download later and this this goes to Amazon's web page which actually talks a lot about ecs so as far as host",
    "start": "1103179",
    "end": "1115870"
  },
  {
    "text": "management when you when you set up a cluster in amazon you basically give it",
    "start": "1115870",
    "end": "1123190"
  },
  {
    "text": "the am I the host that you need that you want to run in your cluster and the way",
    "start": "1123190",
    "end": "1129309"
  },
  {
    "text": "that we the way that we bring up those machines is we use user data we don't use chef we",
    "start": "1129309",
    "end": "1136820"
  },
  {
    "text": "don't use a lot of other configuration management because the idea is that you want to keep your hosts as simple as",
    "start": "1136820",
    "end": "1142129"
  },
  {
    "text": "possible you want to be able to launch many of them and keep them very simple you don't want to have to worry about",
    "start": "1142129",
    "end": "1147169"
  },
  {
    "text": "changing them a lot because all of the changes in all of the libraries and everything should be installed in your",
    "start": "1147169",
    "end": "1152389"
  },
  {
    "text": "docker images and running in your containers not on the on the host so we",
    "start": "1152389",
    "end": "1157759"
  },
  {
    "text": "want the host as simple as possible you can use Amazon's ecs optimized images",
    "start": "1157759",
    "end": "1163509"
  },
  {
    "text": "we've found that that we have a few things that we needed to change and so we actually pushed some of these onto",
    "start": "1163509",
    "end": "1171799"
  },
  {
    "text": "the host such as our slave terminator instead of just cutting the slaves off",
    "start": "1171799",
    "end": "1179239"
  },
  {
    "text": "and deleting them and letting ecs handle that what we do is we d register a machine from a cluster and then we let",
    "start": "1179239",
    "end": "1186409"
  },
  {
    "text": "that machine look at itself introspect see if it's running any containers if",
    "start": "1186409",
    "end": "1191570"
  },
  {
    "text": "it's doing any work if it's not doing any work then it's allowed to kill itself you can load the base docker",
    "start": "1191570",
    "end": "1197720"
  },
  {
    "text": "images on the machines if you want to we don't actually do that it hasn't saved us a lot of time but I think",
    "start": "1197720",
    "end": "1202999"
  },
  {
    "text": "theoretically it'll save you a little bit of time on set up we set up some credentials which we pull from s3 and we",
    "start": "1202999",
    "end": "1210289"
  },
  {
    "text": "have them encrypted we set up our logging and we we actually cash a lot of",
    "start": "1210289",
    "end": "1216080"
  },
  {
    "text": "our larger data so some of our repos are very large and they take a long time to",
    "start": "1216080",
    "end": "1222320"
  },
  {
    "text": "clone from scratch and so the docker images in order to keep them from being too large we actually pull down some of",
    "start": "1222320",
    "end": "1228649"
  },
  {
    "text": "the code and put it on the host so that when we bring up a new container we can",
    "start": "1228649",
    "end": "1233779"
  },
  {
    "text": "just copy the data over because it's a lot faster to copy data over from a local host than it is to download it from the internet every time from github",
    "start": "1233779",
    "end": "1240169"
  },
  {
    "text": "or wherever you store your your code and we also put a lot of libraries locally",
    "start": "1240169",
    "end": "1246049"
  },
  {
    "text": "and do the same thing with that just because otherwise your docker image can become gigabytes nobody wants to be",
    "start": "1246049",
    "end": "1252230"
  },
  {
    "text": "moving around gigabytes of data when you're spinning up hundreds of containers thousands of containers per day",
    "start": "1252230",
    "end": "1259210"
  },
  {
    "text": "so one of the things that Amazon just announced was that you can now do I am",
    "start": "1262450",
    "end": "1269450"
  },
  {
    "text": "access management / task definition so a task definition defines a specific task",
    "start": "1269450",
    "end": "1275120"
  },
  {
    "text": "that runs in an ecs cluster and a task will be brought up on a docker container",
    "start": "1275120",
    "end": "1281960"
  },
  {
    "text": "which is based on a docker image what you've had to do before is set up the I",
    "start": "1281960",
    "end": "1288559"
  },
  {
    "text": "am roles for the host and then any containers that came up on that host would use the IM roles of the host there",
    "start": "1288559",
    "end": "1295940"
  },
  {
    "text": "were ways to get around this they involved limiting access to certain to",
    "start": "1295940",
    "end": "1303140"
  },
  {
    "text": "certain IP addresses and certain API endpoints and they've they've fixed that",
    "start": "1303140",
    "end": "1308240"
  },
  {
    "text": "now or just made it better by allowing you to tie i am roles to tasks so now a",
    "start": "1308240",
    "end": "1315230"
  },
  {
    "text": "specific task that's tied to a specific test suite or a specific job that you",
    "start": "1315230",
    "end": "1320450"
  },
  {
    "text": "run can actually have its own roles and therefore has access to its own data",
    "start": "1320450",
    "end": "1325640"
  },
  {
    "text": "that it can pull down its own credentials that it can pull down and so that's that's the way forward that was",
    "start": "1325640",
    "end": "1331790"
  },
  {
    "text": "just released I think a month ago and so we're going going forward with that we're rolling that out now another thing",
    "start": "1331790",
    "end": "1340460"
  },
  {
    "text": "that we found is that in order to build docker within docker because a lot of our new services now are actually coming",
    "start": "1340460",
    "end": "1347059"
  },
  {
    "text": "out and docker containers so they're docker images that we have to build to deploy to production in order to run",
    "start": "1347059",
    "end": "1353059"
  },
  {
    "text": "those and build them within a docker CI system then we had to share the docker Damon that's running on the host with",
    "start": "1353059",
    "end": "1359990"
  },
  {
    "text": "the containers and I'll show you how to do that in the in the task definition in in a couple slides I also hear it it's",
    "start": "1359990",
    "end": "1369140"
  },
  {
    "text": "repeated we prefetch large data blobs because they just take a long time to download when you when you launch a",
    "start": "1369140",
    "end": "1375140"
  },
  {
    "text": "container and also we have multiple containers so it's kind of nice and in",
    "start": "1375140",
    "end": "1380210"
  },
  {
    "text": "the task definition file you can list several containers and the port's that",
    "start": "1380210",
    "end": "1386570"
  },
  {
    "text": "all connect them together and so you can actually launched like a small constellation of services that are all",
    "start": "1386570",
    "end": "1392840"
  },
  {
    "text": "tied together and you do that for each task and so some of our test suites for instance require",
    "start": "1392840",
    "end": "1398690"
  },
  {
    "text": "elasticsearch and so we launched we launched a small extra container for that and some of them require my sequel",
    "start": "1398690",
    "end": "1405470"
  },
  {
    "text": "and so we launched a small extra container for that and so these extra containers come up and they're just",
    "start": "1405470",
    "end": "1410840"
  },
  {
    "text": "linked to the first container and they can run complete their tests and then both containers are destroyed so here's",
    "start": "1410840",
    "end": "1418400"
  },
  {
    "text": "an example the task definition that we use for this you can see here the mount points this is where we're sharing the",
    "start": "1418400",
    "end": "1423620"
  },
  {
    "text": "dr. Damon between the host and the containers that's important to get the",
    "start": "1423620",
    "end": "1431899"
  },
  {
    "text": "versions aligned between between docker on the host and in the container so that you can build docker within docker",
    "start": "1431899",
    "end": "1437679"
  },
  {
    "text": "essential true is very important if you're going to be launching multiple",
    "start": "1437679",
    "end": "1442760"
  },
  {
    "text": "containers for a task for a test suite if you have three containers that need",
    "start": "1442760",
    "end": "1448250"
  },
  {
    "text": "to come up sometimes one of them will fail and it can be from various reasons if they fail and you don't have a",
    "start": "1448250",
    "end": "1455179"
  },
  {
    "text": "central set to true then you won't necessarily know that the task is failed",
    "start": "1455179",
    "end": "1461059"
  },
  {
    "text": "and the machines the containers will start trying to talk to each other and one of them will be missing and you'll get some some strange errors so by",
    "start": "1461059",
    "end": "1467419"
  },
  {
    "text": "setting essential to true you're basically telling the ecs system that you require all of these to come up",
    "start": "1467419",
    "end": "1473360"
  },
  {
    "text": "before it consider the task ready to go here's more on is just the bottom so",
    "start": "1473360",
    "end": "1481610"
  },
  {
    "text": "there's more on how to share the the doctor socket so what what does using",
    "start": "1481610",
    "end": "1488419"
  },
  {
    "text": "docker offer us it offers us the clean testing environments that we had in our vision we get nearly instant machine",
    "start": "1488419",
    "end": "1495380"
  },
  {
    "text": "refresh which I'll show you how fast it is just starting to dr. container if you haven't seen that in the next slide it",
    "start": "1495380",
    "end": "1502340"
  },
  {
    "text": "takes literally seconds and then you're right back into the setup that you would normally do on any machine anyway it",
    "start": "1502340",
    "end": "1510950"
  },
  {
    "text": "allows us to set up the environment on the developers machine so they can",
    "start": "1510950",
    "end": "1516770"
  },
  {
    "text": "actually build it locally and we have we have several of our services now we're all of the development was done on the",
    "start": "1516770",
    "end": "1522470"
  },
  {
    "text": "on the developers machine they built docker images they ran the containers locally they tested",
    "start": "1522470",
    "end": "1528200"
  },
  {
    "text": "everything they got it all working so they basically have their own little CI on their laptop and then once they were",
    "start": "1528200",
    "end": "1533630"
  },
  {
    "text": "done we just had to make a few tweaks uploaded into our CI system and we were",
    "start": "1533630",
    "end": "1539389"
  },
  {
    "text": "able to then build their docker container and run with it in our CI system without having to do a lot of",
    "start": "1539389",
    "end": "1545179"
  },
  {
    "text": "changes and in the old system what we'd have to do is we'd have to go in and give them a specific host and teach them",
    "start": "1545179",
    "end": "1552049"
  },
  {
    "text": "how to login to the host or get their ssh keys and it was very difficult to get them to actually build something on",
    "start": "1552049",
    "end": "1558679"
  },
  {
    "text": "a machine that was similar to what we were running in CI and now by having these clean testing environments and the",
    "start": "1558679",
    "end": "1565610"
  },
  {
    "text": "ability to run it locally we don't run into that anymore so this also offers us",
    "start": "1565610",
    "end": "1574779"
  },
  {
    "text": "very efficient machine usage because as soon as a job is done you can just reuse",
    "start": "1574779",
    "end": "1581510"
  },
  {
    "text": "that machine for something else if the machine is not using very many resources for a smaller job you can run a larger",
    "start": "1581510",
    "end": "1586639"
  },
  {
    "text": "job next to it on the same machine so can we play the short boring video but",
    "start": "1586639",
    "end": "1595190"
  },
  {
    "text": "it'll show you how fast starting docker is so this the longest part of this is",
    "start": "1595190",
    "end": "1600380"
  },
  {
    "text": "just logging into the into the host and so right now i'm logging into a host",
    "start": "1600380",
    "end": "1605929"
  },
  {
    "text": "that is running in an ecs cluster and so this is one of the the host nodes that",
    "start": "1605929",
    "end": "1612049"
  },
  {
    "text": "will run docker container so there it was that was it we started a docker image from scratch there's a brand-new",
    "start": "1612049",
    "end": "1618080"
  },
  {
    "text": "docker container running and then we can run our setup which is running our tests so I'll do it one more time in case you",
    "start": "1618080",
    "end": "1624679"
  },
  {
    "text": "didn't see how fast it was already here we go have to hit enter there that was",
    "start": "1624679",
    "end": "1631279"
  },
  {
    "text": "it it takes literally seconds to start up a new machine and normally using VMs",
    "start": "1631279",
    "end": "1637000"
  },
  {
    "text": "you can go on to the next slide thank",
    "start": "1637000",
    "end": "1642289"
  },
  {
    "text": "you normally with VMs you have to wait for the whole boot cycle and that can",
    "start": "1642289",
    "end": "1647389"
  },
  {
    "text": "take minutes so it's it's a quantum leap in performance another thing that that",
    "start": "1647389",
    "end": "1654139"
  },
  {
    "text": "doing this allows us to do is to have very very dynamic worker scaling we don't have to worry about machine boot",
    "start": "1654139",
    "end": "1659960"
  },
  {
    "text": "up times we don't have to worry about user data time we what we do is we maintain a buffer in our ecs host pool",
    "start": "1659960",
    "end": "1667940"
  },
  {
    "text": "so that we always have a few extra machines and then as we get new jobs that was not supposed to go as we get",
    "start": "1667940",
    "end": "1677420"
  },
  {
    "text": "new jobs we just increase we keep adding to our buffer and the jobs that come in pull from from the existing buffer and",
    "start": "1677420",
    "end": "1684560"
  },
  {
    "text": "you can see here what we have is we have our new jobs come in through SQS and SNS",
    "start": "1684560",
    "end": "1690440"
  },
  {
    "text": "and SNS will immediately kick off a lambda scheduler and a lambda bin",
    "start": "1690440",
    "end": "1696650"
  },
  {
    "text": "packing machine or function all at the same time and the bin Packer will look",
    "start": "1696650",
    "end": "1702080"
  },
  {
    "text": "to see what's available which host nodes in ecs are available in where it can put",
    "start": "1702080",
    "end": "1707930"
  },
  {
    "text": "this new job that came in and since we always keep a buffer there usually is space to put it it'll put it on a",
    "start": "1707930",
    "end": "1713930"
  },
  {
    "text": "machine at the same time the lambda funk the lambda function that's looking at scheduling or at scaling will see that",
    "start": "1713930",
    "end": "1721130"
  },
  {
    "text": "we need more machines and it will start the spin up process for a new host nodes and those are the ones that can take a couple minutes to spin up so we",
    "start": "1721130",
    "end": "1728960"
  },
  {
    "text": "basically have no Q anymore and we used to have cues that would last on a bad",
    "start": "1728960",
    "end": "1734120"
  },
  {
    "text": "day on a very busy day when everyone was trying to get code in sometimes it would go up to an hour or an hour an hour and",
    "start": "1734120",
    "end": "1740780"
  },
  {
    "text": "a half it was terrible at times when something when anything would go wrong it would just take a long time and everything would back up in the queue",
    "start": "1740780",
    "end": "1747020"
  },
  {
    "text": "and now we could lose our whole system relaunch it from scratch and there would",
    "start": "1747020",
    "end": "1752060"
  },
  {
    "text": "be no queue it would just it would take two minutes to launch all the machines in parallel and we'd have 150 machines",
    "start": "1752060",
    "end": "1757760"
  },
  {
    "text": "200 machines running within a couple minutes and all taking the jobs off the queue so the queue basically has gone",
    "start": "1757760",
    "end": "1763490"
  },
  {
    "text": "away we maintain a cue that's under things come in from github and our",
    "start": "1763490",
    "end": "1769640"
  },
  {
    "text": "process within a couple minutes every single one of them and a lot of the time there is just in polling and and how",
    "start": "1769640",
    "end": "1776270"
  },
  {
    "text": "long it takes for github to send you the the commit and things like that so here",
    "start": "1776270",
    "end": "1782900"
  },
  {
    "text": "you can see at the bottom this is how the bin packing works that we had to implement in order to use this for to",
    "start": "1782900",
    "end": "1789290"
  },
  {
    "text": "use ecs for long running tasks so you can see these are jobs coming in there's",
    "start": "1789290",
    "end": "1794390"
  },
  {
    "text": "a new job and bin packing it puts it with the other jobs that are running already over",
    "start": "1794390",
    "end": "1799470"
  },
  {
    "text": "here it put it on a new machine because it tends to spread out over all of the available nodes and so then what",
    "start": "1799470",
    "end": "1806250"
  },
  {
    "text": "happened is when we scaled down when we went to pick a machine to destroy our is",
    "start": "1806250",
    "end": "1811290"
  },
  {
    "text": "picked an empty machine and the standard one will pick just any old random machine because we still have four",
    "start": "1811290",
    "end": "1817500"
  },
  {
    "text": "available here and so it'll pull it can pull any one of the machines because it assumes that it's a stateless web",
    "start": "1817500",
    "end": "1823920"
  },
  {
    "text": "service that's spread across many nodes and it can just pull one out and it'll be replaced by other ones when you're",
    "start": "1823920",
    "end": "1829020"
  },
  {
    "text": "running stateful slow tasks that are that are maybe a test suite or a",
    "start": "1829020",
    "end": "1835740"
  },
  {
    "text": "long-running job that's waiting for something on the other end you really want to make sure that you aren't just killing the jobs in the middle because",
    "start": "1835740",
    "end": "1841620"
  },
  {
    "text": "then you have to start over again and so we use lambda to do this and you can use",
    "start": "1841620",
    "end": "1847830"
  },
  {
    "text": "other schedulers most of them require that you set them up on another server and then have them interact with with",
    "start": "1847830",
    "end": "1855900"
  },
  {
    "text": "ecs in order to to schedule where the jobs go we found it was easier to",
    "start": "1855900",
    "end": "1861210"
  },
  {
    "text": "actually write a couple hundred lines in lambda in Java and just push up a jar",
    "start": "1861210",
    "end": "1866790"
  },
  {
    "text": "and it's working really well for us you",
    "start": "1866790",
    "end": "1875010"
  },
  {
    "text": "can see from this graph what we used to have the the peak there is about 125 and",
    "start": "1875010",
    "end": "1881330"
  },
  {
    "text": "we used to at times have to run on a busy week on a Friday when everyone was",
    "start": "1881330",
    "end": "1888240"
  },
  {
    "text": "trying to get their code in we would actually have to guess how many slaves we needed how many workers we needed and",
    "start": "1888240",
    "end": "1893460"
  },
  {
    "text": "we'd spin up 120 machines a couple hours before we thought we needed needed them and just blowing lots of cash because",
    "start": "1893460",
    "end": "1902760"
  },
  {
    "text": "the machines would sit there idle much of the time if you look there you can see there's a big dip and that dip is I",
    "start": "1902760",
    "end": "1908400"
  },
  {
    "text": "think it's between like 8am and lunchtime everyone checks in at lunch time before they go to lunch and you can",
    "start": "1908400",
    "end": "1913560"
  },
  {
    "text": "see the next peak take off and so all that time in between there was just wasted machines and then at night you",
    "start": "1913560",
    "end": "1919530"
  },
  {
    "text": "had to go in and manually shut them down or you could have schedules there were some programs that would take them down for you but this enables us to have the",
    "start": "1919530",
    "end": "1928590"
  },
  {
    "text": "peaks come up sure and they drop off faster so it's much more scalable much more of a",
    "start": "1928590",
    "end": "1933930"
  },
  {
    "text": "dynamic and you can see how much money we saved we basically are running in the",
    "start": "1933930",
    "end": "1939000"
  },
  {
    "text": "machines less now than the amount that we stopped running them so it used to be",
    "start": "1939000",
    "end": "1944370"
  },
  {
    "text": "more than more than double I think the first time we set this up we saved is",
    "start": "1944370",
    "end": "1949670"
  },
  {
    "text": "about eighty percent or something like that it was it was an obvious win the",
    "start": "1949670",
    "end": "1955950"
  },
  {
    "text": "next thing you would think of doing with any one of these services is using spot instances to save money because of what",
    "start": "1955950",
    "end": "1962310"
  },
  {
    "text": "I talked about earlier they cost a fraction of what a normal on-demand instance does so the thing about spot",
    "start": "1962310",
    "end": "1969090"
  },
  {
    "text": "instances we chart the spot instance prices and you can see those lines those",
    "start": "1969090",
    "end": "1975210"
  },
  {
    "text": "lines this is for one availability zone and those lines are the on demand prices",
    "start": "1975210",
    "end": "1980760"
  },
  {
    "text": "so we set our pricing for spot instances to the on-demand pricing and then if the",
    "start": "1980760",
    "end": "1987930"
  },
  {
    "text": "spot prices spiked above the on-demand price then we basically don't watch any",
    "start": "1987930",
    "end": "1993240"
  },
  {
    "text": "more machines and what we have to do is go in manually and switch over to an on-demand instance launcher which you do",
    "start": "1993240",
    "end": "2000350"
  },
  {
    "text": "and you do in one of the in the cluster and there it's a manual process it takes",
    "start": "2000350",
    "end": "2008180"
  },
  {
    "text": "a little while and it's not automatic and so we don't really like doing that but you can see how these things are",
    "start": "2008180",
    "end": "2014210"
  },
  {
    "text": "spiking up to several dollars and what we found is that different instances will spike differently on different",
    "start": "2014210",
    "end": "2019960"
  },
  {
    "text": "availability zones so what we actually had to do was spread our load spread our",
    "start": "2019960",
    "end": "2026390"
  },
  {
    "text": "CI system across many availability zones in order to take advantage of that and what happens then is when you get a",
    "start": "2026390",
    "end": "2032060"
  },
  {
    "text": "spike on one machine size in one availability zone you'll lose a section of your machines and but you'll keep a",
    "start": "2032060",
    "end": "2039830"
  },
  {
    "text": "section running and the other one and so then you can switch that one over to on demand or you can just launch more spot",
    "start": "2039830",
    "end": "2045590"
  },
  {
    "text": "instances and the other one in the other availability zone but it's not perfect",
    "start": "2045590",
    "end": "2051409"
  },
  {
    "text": "yet we're working on working on going around the the limitations of this seems",
    "start": "2051410",
    "end": "2057200"
  },
  {
    "text": "like some people just set their their prices very high to eight dollars or something and and that's how they",
    "start": "2057200",
    "end": "2062780"
  },
  {
    "text": "whether these storms I know a few years ago sometimes we would run into issues where we",
    "start": "2062780",
    "end": "2068450"
  },
  {
    "text": "couldn't launch on demand servers when they seem to be in high demand and we",
    "start": "2068450",
    "end": "2074810"
  },
  {
    "text": "were worried that when the spot instance prices peaked and we had to switch over to on demand that we wouldn't have them",
    "start": "2074810",
    "end": "2081260"
  },
  {
    "text": "available we thought maybe there was a tie-in between the spot instance pricing and the on demand it hasn't proven to be",
    "start": "2081260",
    "end": "2087020"
  },
  {
    "text": "true every time we've had to switch over to on demand we've been able to this is",
    "start": "2087020",
    "end": "2093320"
  },
  {
    "text": "from july i don't know if you can read it july sixth to july 28th I think so",
    "start": "2093320",
    "end": "2100010"
  },
  {
    "text": "this is about a month and this is last month and these these are the alerts",
    "start": "2100010",
    "end": "2105410"
  },
  {
    "text": "that we get from amazon when they're going to kill one of our machines and so we're running thousands and thousands of",
    "start": "2105410",
    "end": "2112580"
  },
  {
    "text": "machines per day a couple thousand machines per day and I think the peak",
    "start": "2112580",
    "end": "2118369"
  },
  {
    "text": "there is 50 60 about 60 so on one day",
    "start": "2118369",
    "end": "2124520"
  },
  {
    "text": "one particularly bad day we had 60 machines which were killed from under us so if you think about it and the amount",
    "start": "2124520",
    "end": "2132109"
  },
  {
    "text": "of machine the number of machines are running these are actually very small numbers and you can see most days we",
    "start": "2132109",
    "end": "2137330"
  },
  {
    "text": "don't have any machines killed some days we have a few machines killed and the worst case we got 60 out of a couple",
    "start": "2137330",
    "end": "2143720"
  },
  {
    "text": "thousand machines killed it's not really that big of a deal if you can survive it if your system can survive it and with a",
    "start": "2143720",
    "end": "2151369"
  },
  {
    "text": "CI internal system you usually can do that all it does is it it causes you to",
    "start": "2151369",
    "end": "2156770"
  },
  {
    "text": "have to wait a few more minutes for your test to finish because you r eq the test and so what we do is when we get these",
    "start": "2156770",
    "end": "2161990"
  },
  {
    "text": "notifications this is in spunk by the way when we get these notifications we",
    "start": "2161990",
    "end": "2169070"
  },
  {
    "text": "immediately just reek you that job and send it back to sq s and then it gets picked up because there's no queue it",
    "start": "2169070",
    "end": "2174740"
  },
  {
    "text": "gets picked back up right away and launched on another job two minutes before the Machine actually goes down",
    "start": "2174740",
    "end": "2180530"
  },
  {
    "text": "and so usually it doesn't really affect us that much people don't really notice",
    "start": "2180530",
    "end": "2185720"
  },
  {
    "text": "and you can see this is the effect its had on our honor costs so that top line",
    "start": "2185720",
    "end": "2194109"
  },
  {
    "text": "that was the line that we were at before we went to spot prices and we",
    "start": "2194109",
    "end": "2199710"
  },
  {
    "text": "were actually bumping past that line a little bit and you can see at the end of the month there it was over twenty",
    "start": "2199710",
    "end": "2206190"
  },
  {
    "text": "percent it's like 22 or 23 percent that we saved per month just by switching to spot prices and allowing some very very",
    "start": "2206190",
    "end": "2214800"
  },
  {
    "text": "very very small percentage of our jobs to die on occasion saves us I think this",
    "start": "2214800",
    "end": "2221910"
  },
  {
    "text": "chart in that chart is twenty thousand dollars per month that we save just by switching the spot instances for this",
    "start": "2221910",
    "end": "2228240"
  },
  {
    "text": "one system so another thing that we wanted to do we wanted to have version",
    "start": "2228240",
    "end": "2235800"
  },
  {
    "text": "jobs and by having versioned docker images that you can tie to the code you",
    "start": "2235800",
    "end": "2244080"
  },
  {
    "text": "can have that you can have versioned infrastructure in your CI system running beneath the the versioned code that your",
    "start": "2244080",
    "end": "2250620"
  },
  {
    "text": "developers are producing and so what we started doing about a year ago in anticipation of this move is we started",
    "start": "2250620",
    "end": "2257190"
  },
  {
    "text": "pushing our scripts into the repositories so that the developers now owned the building test script and you",
    "start": "2257190",
    "end": "2263280"
  },
  {
    "text": "can see I don't know if you can actually read it from there but these this is our build and test script and you can see",
    "start": "2263280",
    "end": "2269220"
  },
  {
    "text": "the developers are making changes to it and github and so they actually make changes as they like and we just help",
    "start": "2269220",
    "end": "2275430"
  },
  {
    "text": "them if they have problems what this did for us is it made the transition to dr.",
    "start": "2275430",
    "end": "2280620"
  },
  {
    "text": "very easy because once everything was set in a script that was away from our",
    "start": "2280620",
    "end": "2286500"
  },
  {
    "text": "build server that didn't use plugins that were tied into our build server that didn't have expectations of where",
    "start": "2286500",
    "end": "2292290"
  },
  {
    "text": "they were being run we actually were able to then just switch to docker workers which could run this script and",
    "start": "2292290",
    "end": "2299960"
  },
  {
    "text": "run the build and test we had all the reporting built in so we actually wrap our docker containers in in a reporting",
    "start": "2299960",
    "end": "2307830"
  },
  {
    "text": "script which reports back to the backend",
    "start": "2307830",
    "end": "2313260"
  },
  {
    "text": "we call it aperture our aperture reporter which is running an ecs and it reports back there when it starts the",
    "start": "2313260",
    "end": "2319830"
  },
  {
    "text": "docker container and it knows what job its starting in the docker container so even if the docker container dies we",
    "start": "2319830",
    "end": "2325050"
  },
  {
    "text": "know about it and then when the docker container finishes and it leaves its logs behind then our rapper will",
    "start": "2325050",
    "end": "2331500"
  },
  {
    "text": "upload the logs upload the completion rates upload test suite results all of",
    "start": "2331500",
    "end": "2337950"
  },
  {
    "text": "that so what this gave us was version",
    "start": "2337950",
    "end": "2344010"
  },
  {
    "text": "docker containers version task definitions and versioned code so it's",
    "start": "2344010",
    "end": "2351480"
  },
  {
    "text": "extreme flexibility we can actually run pretty much whatever we want wherever we want we can run using cloud formation we",
    "start": "2351480",
    "end": "2359370"
  },
  {
    "text": "can spin up a whole new CI system in a matter of minutes and we've done it on multiple occasions our operations team",
    "start": "2359370",
    "end": "2365490"
  },
  {
    "text": "wanted to test some new software they wanted to have it running on their own am eyes and I think it took five minutes",
    "start": "2365490",
    "end": "2371910"
  },
  {
    "text": "for for one of our team to go and spin up a whole new CI system for them that had all of its own queues all of its own",
    "start": "2371910",
    "end": "2378900"
  },
  {
    "text": "lambda functions everything was processing in its own servers so the",
    "start": "2378900",
    "end": "2387720"
  },
  {
    "text": "problems that we've experienced docker containers not launching sometimes",
    "start": "2387720",
    "end": "2394650"
  },
  {
    "text": "docker containers just don't launch we don't know why we're we're looking into it we're upgrading to we're always",
    "start": "2394650",
    "end": "2402990"
  },
  {
    "text": "upgrading to the latest versions of docker we're upgrading to the latest ami is put out by amazon sometimes they just",
    "start": "2402990",
    "end": "2408210"
  },
  {
    "text": "disappear sometimes the ec2 container",
    "start": "2408210",
    "end": "2413820"
  },
  {
    "text": "agent so the way that ecs works is on each host within the cluster they launch",
    "start": "2413820",
    "end": "2421170"
  },
  {
    "text": "their own container and their own container is the agent for the cluster for that node so that asian actually",
    "start": "2421170",
    "end": "2428430"
  },
  {
    "text": "talks to the cluster to get jobs to tell it the status of the host and so sometimes that would fail not very often",
    "start": "2428430",
    "end": "2434820"
  },
  {
    "text": "but that was one of the things that would fail sometimes docker containers would just stop or disappear and so one",
    "start": "2434820",
    "end": "2441810"
  },
  {
    "text": "of the ways that we've gotten around this is we use visibility timeout in the SQ s and so what you do is you leave",
    "start": "2441810",
    "end": "2449250"
  },
  {
    "text": "your job in the queue and you don't take it out until you're done and so that way if the Machine disappears if the docker",
    "start": "2449250",
    "end": "2455610"
  },
  {
    "text": "container disappears anything happens your job will automatically become visible again and some other worker will",
    "start": "2455610",
    "end": "2462210"
  },
  {
    "text": "pick it up and that's works pretty well another problem we have is incompatibility with certain services so",
    "start": "2462210",
    "end": "2468750"
  },
  {
    "text": "there was a je s unit testing framework",
    "start": "2468750",
    "end": "2473790"
  },
  {
    "text": "which just doesn't work with docker it would it would break the machine and we couldn't launch another container on it",
    "start": "2473790",
    "end": "2479100"
  },
  {
    "text": "afterward and there was a bug associated with that and we've been waiting for that to get fixed but it was we couldn't",
    "start": "2479100",
    "end": "2485970"
  },
  {
    "text": "move all of our tests off we had one test suite that was stuck on our old system docker operating system",
    "start": "2485970",
    "end": "2493770"
  },
  {
    "text": "availability this is obvious it's not not available to run windows yet can't",
    "start": "2493770",
    "end": "2499050"
  },
  {
    "text": "run Mac iOS stuff is is not easy to do",
    "start": "2499050",
    "end": "2504230"
  },
  {
    "text": "so that's another problem we have to sort of maintain a separate system of",
    "start": "2504230",
    "end": "2509310"
  },
  {
    "text": "slaves that will run tests for Windows and other things cleanup has always been",
    "start": "2509310",
    "end": "2514320"
  },
  {
    "text": "a problem as well the the default i think is to clean up docker containers after three hours on ecs I think it's",
    "start": "2514320",
    "end": "2522030"
  },
  {
    "text": "three hours and what we found is that since we're running this with many many short tasks and we have a large number",
    "start": "2522030",
    "end": "2528660"
  },
  {
    "text": "of containers a large number of images that we actually fill up our disks and",
    "start": "2528660",
    "end": "2534210"
  },
  {
    "text": "we could launch hosts with larger disks but we we realize we just didn't need to keep the containers around as long and",
    "start": "2534210",
    "end": "2539820"
  },
  {
    "text": "so we had to write our own cleanup script another thing was just image size",
    "start": "2539820",
    "end": "2545670"
  },
  {
    "text": "so this is what I mentioned earlier about putting code and putting libraries on the host when you launch the host",
    "start": "2545670",
    "end": "2551970"
  },
  {
    "text": "using user data because we found that if we put our code into the containers into",
    "start": "2551970",
    "end": "2557820"
  },
  {
    "text": "the images the docker images we'd end up with multiple gigabytes images that we'd",
    "start": "2557820",
    "end": "2564270"
  },
  {
    "text": "have to cart around everywhere and it was just slow to move that stuff around so we have some feature requests for ecs",
    "start": "2564270",
    "end": "2573630"
  },
  {
    "text": "container service ec2 container service dynamic port mapping to containers so",
    "start": "2573630",
    "end": "2580110"
  },
  {
    "text": "that when you launch them you can set the set the ports at that time you don't have to hard code it beforehand we'd",
    "start": "2580110",
    "end": "2587970"
  },
  {
    "text": "like to fail the the health check based on HTTP return code so when the elastic",
    "start": "2587970",
    "end": "2593520"
  },
  {
    "text": "load balancer is routing traffic to your machines what we did in our previous system is we",
    "start": "2593520",
    "end": "2599520"
  },
  {
    "text": "actually had to write our own load balancer and when it would see an error come back and they had more than a few",
    "start": "2599520",
    "end": "2606090"
  },
  {
    "text": "errors per per second or within some period of time it would take that host out of the out of the balanced pool and",
    "start": "2606090",
    "end": "2613110"
  },
  {
    "text": "we'd like to see something like that in ALB also having a different endpoint for",
    "start": "2613110",
    "end": "2619560"
  },
  {
    "text": "adding things to the load balancer to the cluster and for removing them would",
    "start": "2619560",
    "end": "2625170"
  },
  {
    "text": "be great so that you could perform more tests on something to add it and then you could just have a much higher bar",
    "start": "2625170",
    "end": "2631740"
  },
  {
    "text": "for what has to work in order to remove it from the from the cluster bin packing",
    "start": "2631740",
    "end": "2637260"
  },
  {
    "text": "scheduler we went through that before",
    "start": "2637260",
    "end": "2640910"
  },
  {
    "text": "there aren't really good cost management tools it's sort of hard we had to write",
    "start": "2643010",
    "end": "2648030"
  },
  {
    "text": "our own to go pull from the a the AP is to get all of our costs so we could see how much we were spending we tried some",
    "start": "2648030",
    "end": "2654360"
  },
  {
    "text": "of the third-party tools out there and and they were a little bit slow they're dealing with a lot of data it would be",
    "start": "2654360",
    "end": "2660990"
  },
  {
    "text": "nice if there were some better cost management reporting tools from amazon and stopping containers are stopping the",
    "start": "2660990",
    "end": "2672120"
  },
  {
    "text": "nodes within a cluster sometimes they stop in weird states and so we just like",
    "start": "2672120",
    "end": "2677310"
  },
  {
    "text": "some more some more ability to set the",
    "start": "2677310",
    "end": "2683370"
  },
  {
    "text": "shutdown behavior and just to control how they shut down right now there's not",
    "start": "2683370",
    "end": "2688470"
  },
  {
    "text": "a lot of control and sometimes they'll end up in a weird state and then you can't deregister them and and it can",
    "start": "2688470",
    "end": "2694380"
  },
  {
    "text": "change it can mess up your auto scaling also you have to worry about pork",
    "start": "2694380",
    "end": "2700410"
  },
  {
    "text": "conflicts so and",
    "start": "2700410",
    "end": "2705500"
  },
  {
    "text": "canary so when you launch a service in",
    "start": "2708719",
    "end": "2713739"
  },
  {
    "text": "ecs there's not a good way to to test a",
    "start": "2713739",
    "end": "2718959"
  },
  {
    "text": "machine other than health check before you add it in so what a lot of a lot of people and we're starting to do this",
    "start": "2718959",
    "end": "2725349"
  },
  {
    "text": "will do is whenever you have a cluster you have a second cluster that has one",
    "start": "2725349",
    "end": "2732219"
  },
  {
    "text": "machine that's similar to the first one and so when you have a new a new bit of",
    "start": "2732219",
    "end": "2737529"
  },
  {
    "text": "code a new new node that you want to add you push it to that smaller cluster that",
    "start": "2737529",
    "end": "2742839"
  },
  {
    "text": "only has one machine and then you route some traffic to it and you see how that does and if that works then you push it",
    "start": "2742839",
    "end": "2747999"
  },
  {
    "text": "to your other machine it would be nice if we could have some of that built in to the to ecs so that it would just do",
    "start": "2747999",
    "end": "2754119"
  },
  {
    "text": "that for us rollback is super easy with services so you basically just tell the",
    "start": "2754119",
    "end": "2761410"
  },
  {
    "text": "service tell ecs you want to run the old version and it'll just roll that out it",
    "start": "2761410",
    "end": "2767469"
  },
  {
    "text": "was really easy to get working ecs was very very simple we tried some other",
    "start": "2767469",
    "end": "2772719"
  },
  {
    "text": "some other cluster managers they all required setting up multiple servers they required writing a lot of software",
    "start": "2772719",
    "end": "2780029"
  },
  {
    "text": "ecs to set up services is extremely easy to set up long running tasks for a CI",
    "start": "2780029",
    "end": "2786910"
  },
  {
    "text": "environment it was not that hard we had the right a few hundred lines of java",
    "start": "2786910",
    "end": "2792239"
  },
  {
    "text": "upload them into the lambda functions and we were up and running and since",
    "start": "2792239",
    "end": "2798190"
  },
  {
    "text": "everything's changing so fast then we're not putting stateful services and docker except for our tests which are in tasks",
    "start": "2798190",
    "end": "2805989"
  },
  {
    "text": "in long running tasks but as long as far as having a service that you leave for a very very long period of time we're not",
    "start": "2805989",
    "end": "2813640"
  },
  {
    "text": "doing that yet these are all the amazon web services that we used to build the",
    "start": "2813640",
    "end": "2819699"
  },
  {
    "text": "CI system and we don't really use",
    "start": "2819699",
    "end": "2825279"
  },
  {
    "text": "anything outside of that we use one hundred percent amazon services the the",
    "start": "2825279",
    "end": "2831309"
  },
  {
    "text": "couple apps that we have that we've written we run on ec2 machines and this is our new system i think there are two",
    "start": "2831309",
    "end": "2839410"
  },
  {
    "text": "things in there that were that are in in progress right now and the rest you can see are in nothing's running on",
    "start": "2839410",
    "end": "2848440"
  },
  {
    "text": "an ec2 machine anymore they're all running an ecs or lambda or Kinesis and",
    "start": "2848440",
    "end": "2856240"
  },
  {
    "text": "the blue box and the yellow box are CloudFormation template so we can",
    "start": "2856240",
    "end": "2862240"
  },
  {
    "text": "actually spin up this whole CI system using cloud formation in a matter of minutes and where we're going in the",
    "start": "2862240",
    "end": "2871780"
  },
  {
    "text": "future with this we're going to push out more of our services on to ecs we just",
    "start": "2871780",
    "end": "2878800"
  },
  {
    "text": "have to build build our new new projects first and we'd like to allow developers more control in the system we'd like to",
    "start": "2878800",
    "end": "2885700"
  },
  {
    "text": "enable them to push out their changes without us on the developer productivity side having to do anything we don't want",
    "start": "2885700",
    "end": "2891940"
  },
  {
    "text": "to have to change something in the database we don't have to want to have to change any definitions anywhere so",
    "start": "2891940",
    "end": "2897370"
  },
  {
    "text": "we're pushing out more of the the configuration of CI into the even more than just the the scripts that we've",
    "start": "2897370",
    "end": "2903220"
  },
  {
    "text": "pushed out so far and then lastly the the developer environments we're already using docker for long-running services",
    "start": "2903220",
    "end": "2910060"
  },
  {
    "text": "on developer machines we used to have a lot of problems with services like my sequel where developers would get their",
    "start": "2910060",
    "end": "2917500"
  },
  {
    "text": "machine into a weird state and we'd have to go figure it out or uninstall everything and reinstall everything and",
    "start": "2917500",
    "end": "2923350"
  },
  {
    "text": "what we've done now is we run things like Redis and my sequel and some other some other services on their laptops",
    "start": "2923350",
    "end": "2929970"
  },
  {
    "text": "using docker so that if they break you basically just remove the container and",
    "start": "2929970",
    "end": "2935530"
  },
  {
    "text": "relaunch it and they're right back to an initial working state that works very well and it saves us a lot of time",
    "start": "2935530",
    "end": "2941350"
  },
  {
    "text": "troubleshooting and by doing this by by putting docker on the laptops we're enabling them to run to as i said before",
    "start": "2941350",
    "end": "2949540"
  },
  {
    "text": "build the images that we're going to run in CI and then once we have them in CI we can actually pull them back and give",
    "start": "2949540",
    "end": "2955750"
  },
  {
    "text": "them to the developers so that they can run them locally now there are some caveats in that when you're when you're",
    "start": "2955750",
    "end": "2961960"
  },
  {
    "text": "launching a container in in Amazon in ecs they're launching with IM roles and",
    "start": "2961960",
    "end": "2968110"
  },
  {
    "text": "they have automatic access to some services they have they have automatic access to some credentials which they",
    "start": "2968110",
    "end": "2974299"
  },
  {
    "text": "don't locally and they can't on a laptop so we have to write some some code in",
    "start": "2974299",
    "end": "2979339"
  },
  {
    "text": "there too to put parallel paths so that when it's running on a laptop it uses one set of credentials and when it's",
    "start": "2979339",
    "end": "2985549"
  },
  {
    "text": "running in the cloud it would use another the result of all of this is",
    "start": "2985549",
    "end": "2991160"
  },
  {
    "text": "that developers can write more tests quicker when we the first day we rolled",
    "start": "2991160",
    "end": "2996259"
  },
  {
    "text": "this out i think we doubled our throughput so we went from 120 things running at a time 120 test suites",
    "start": "2996259",
    "end": "3002079"
  },
  {
    "text": "running at a time to 250 that day we have happy developers everything works",
    "start": "3002079",
    "end": "3008559"
  },
  {
    "text": "faster now they get good feedback it's more stable the quality team is happy",
    "start": "3008559",
    "end": "3015119"
  },
  {
    "text": "ops team is happy they always have release candidates and the management is very happy because we save twenty",
    "start": "3015359",
    "end": "3021339"
  },
  {
    "text": "percent on our ec2 gusts so thank you and if you want to check out the stack",
    "start": "3021339",
    "end": "3026380"
  },
  {
    "text": "that we're using the docta you can go to stack share I owe octa / octa and we're",
    "start": "3026380",
    "end": "3032079"
  },
  {
    "text": "always looking for good people so you can go to our careers page down there at the bottom if you want to join thank you",
    "start": "3032079",
    "end": "3042959"
  }
]
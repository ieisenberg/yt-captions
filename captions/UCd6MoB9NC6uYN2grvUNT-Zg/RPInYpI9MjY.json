[
  {
    "start": "0",
    "end": "75000"
  },
  {
    "text": "Kris screen ACK I am a partner solutions architect and the global machine learning segment lead for the AWS",
    "start": "0",
    "end": "7919"
  },
  {
    "text": "partner network this is a special series just for our partners what we're doing",
    "start": "7919",
    "end": "13230"
  },
  {
    "text": "here is walking through each of the built-in algorithms that are part of",
    "start": "13230",
    "end": "18779"
  },
  {
    "text": "Sage maker this is a series and we will be going through all of the algorithms",
    "start": "18779",
    "end": "24269"
  },
  {
    "text": "and it is even very likely that before we get to the end of this series as planned",
    "start": "24269",
    "end": "29699"
  },
  {
    "text": "there will be more algorithms what we try to do is provide some insights we",
    "start": "29699",
    "end": "35340"
  },
  {
    "text": "assume little but we do do not assume no prior experience with development with",
    "start": "35340",
    "end": "43260"
  },
  {
    "text": "AWS but we do try to cover all of the basics so if you're just getting started",
    "start": "43260",
    "end": "48329"
  },
  {
    "text": "if you don't categorize yourself as a data scientist but rather as a developer",
    "start": "48329",
    "end": "53879"
  },
  {
    "text": "don't worry this course is for you if you do design define yourself as a data",
    "start": "53879",
    "end": "59820"
  },
  {
    "text": "scientist then I hope there are some new insights and functionalities that we provide as we go through each of our",
    "start": "59820",
    "end": "66000"
  },
  {
    "text": "algorithms in this series so today we're talking about k-means clustering k-means",
    "start": "66000",
    "end": "71909"
  },
  {
    "text": "clustering of course is a part of machine learning that is generally",
    "start": "71909",
    "end": "77460"
  },
  {
    "start": "75000",
    "end": "195000"
  },
  {
    "text": "considered unsupervised learning but where we to take the types of machine",
    "start": "77460",
    "end": "82950"
  },
  {
    "text": "learning and just sort of divide them into a matrix we could take a look first",
    "start": "82950",
    "end": "88110"
  },
  {
    "text": "of all on the left hand side on the y axis if you will there are really two kinds generally of data discrete and",
    "start": "88110",
    "end": "96270"
  },
  {
    "text": "continuous with discrete data you have",
    "start": "96270",
    "end": "101460"
  },
  {
    "text": "some idea of classification in the terms of you know categories days of the weeks",
    "start": "101460",
    "end": "107899"
  },
  {
    "text": "for example cats and dogs it's a different discrete entity and in it's",
    "start": "107899",
    "end": "113700"
  },
  {
    "text": "relatively easy to identify a particular unit in that entity with supervised",
    "start": "113700",
    "end": "120899"
  },
  {
    "text": "learning of course we have classification itself where we would use we would have discriminate between cats",
    "start": "120899",
    "end": "128459"
  },
  {
    "text": "and dogs etc hot dog not a hot dog in unsupervised learning we may not",
    "start": "128459",
    "end": "133500"
  },
  {
    "text": "have the labels before we start and that's where clustering comes in it's really a method for understanding data",
    "start": "133500",
    "end": "141870"
  },
  {
    "text": "doing data discovery and really trying to glean insights from data that you",
    "start": "141870",
    "end": "149370"
  },
  {
    "text": "have where all of the data in the world labeled and not messy and not require",
    "start": "149370",
    "end": "156330"
  },
  {
    "text": "cleaning up we probably wouldn't need clustering but because data is dirty and generally hard to classify from time to",
    "start": "156330",
    "end": "163770"
  },
  {
    "text": "time or the relationships between various features in our data if they",
    "start": "163770",
    "end": "170340"
  },
  {
    "text": "were as clear at to the eye as they were or intuitive as we're looking at them we",
    "start": "170340",
    "end": "175350"
  },
  {
    "text": "probably wouldn't need clustering but that is really what clustering is for so unsupervised learning you know really is",
    "start": "175350",
    "end": "183180"
  },
  {
    "text": "a discovery process and it's important to approach it with a feeling of",
    "start": "183180",
    "end": "190739"
  },
  {
    "text": "experimentation now you don't want to create a mess if you don't have to so",
    "start": "190739",
    "end": "196830"
  },
  {
    "start": "195000",
    "end": "325000"
  },
  {
    "text": "what what we start with is really beginning to understand our data itself",
    "start": "196830",
    "end": "203420"
  },
  {
    "text": "visualizing our data is one of the principal ways of beginning to discover data when we are working with",
    "start": "203420",
    "end": "211739"
  },
  {
    "text": "unsupervised learning typically we're not too concerned about accuracy",
    "start": "211739",
    "end": "218330"
  },
  {
    "text": "you know principal measurements for classification in some of our other",
    "start": "218330",
    "end": "224100"
  },
  {
    "text": "methods the absolute score that is you know the most important is accuracy",
    "start": "224100",
    "end": "229290"
  },
  {
    "text": "sometimes to thousandths of a percentage not so much with supervised learning we're really looking for patterns when",
    "start": "229290",
    "end": "237450"
  },
  {
    "text": "we're using unsupervised techniques structure is learned by the methods that",
    "start": "237450",
    "end": "242820"
  },
  {
    "text": "are employed themselves and typically we will summarize data and go through the",
    "start": "242820",
    "end": "249180"
  },
  {
    "text": "data in a way that produces more insights as opposed to really sort of",
    "start": "249180",
    "end": "255000"
  },
  {
    "text": "focusing down on individual discoveries and I'm just going to take a moment here",
    "start": "255000",
    "end": "264660"
  },
  {
    "text": "and excuse me just had to review I saw that there might be a problem with the audio quality but it seems like maybe we're",
    "start": "264660",
    "end": "271379"
  },
  {
    "text": "okay alright so when we're doing clustering",
    "start": "271379",
    "end": "276509"
  },
  {
    "text": "we can certainly include a couple of methods for doing clustering including",
    "start": "276509",
    "end": "283400"
  },
  {
    "text": "autoencoders density estimation and dimensionality reduction so there are a",
    "start": "283400",
    "end": "292229"
  },
  {
    "text": "number of ways to do clustering I'm going to cover just a few and frequently",
    "start": "292229",
    "end": "297569"
  },
  {
    "text": "clustering is done in a pipeline so I'm gonna touch just briefly on that and I",
    "start": "297569",
    "end": "303659"
  },
  {
    "text": "also want to point out a few particular problems probably the most important one",
    "start": "303659",
    "end": "309479"
  },
  {
    "text": "is that clustering methods discover clusters even when your data doesn't",
    "start": "309479",
    "end": "314789"
  },
  {
    "text": "have any so there are a few caveats when you go into clustering methods and it's",
    "start": "314789",
    "end": "320699"
  },
  {
    "text": "important to be mindful before you even get started so we know by now what",
    "start": "320699",
    "end": "327270"
  },
  {
    "start": "325000",
    "end": "495000"
  },
  {
    "text": "clustering is from a technology point of view how do we use it in the real world",
    "start": "327270",
    "end": "332300"
  },
  {
    "text": "well principally data discovery is the number one method as a data scientist I",
    "start": "332300",
    "end": "339330"
  },
  {
    "text": "what I like to say is you wouldn't do machine learning if you knew the answers to the questions that you were beginning",
    "start": "339330",
    "end": "345599"
  },
  {
    "text": "to ask unlike ordinary software development when you're doing machine",
    "start": "345599",
    "end": "351150"
  },
  {
    "text": "learning you don't know frequently what's in your data so using clustering as a data pre-processing technique is",
    "start": "351150",
    "end": "357690"
  },
  {
    "text": "very important when you're doing clustering what you will do is begin to",
    "start": "357690",
    "end": "363690"
  },
  {
    "text": "discover groups in your data and then that those groups once defined and a",
    "start": "363690",
    "end": "369240"
  },
  {
    "text": "model has been trained can be very useful for classifying all kinds of",
    "start": "369240",
    "end": "374729"
  },
  {
    "text": "objects now those objects may be information that you're looking for in",
    "start": "374729",
    "end": "379860"
  },
  {
    "text": "documents it could be images and it's also a really important part of search",
    "start": "379860",
    "end": "385560"
  },
  {
    "text": "whether that search is visual or textual I would say the probably the number one",
    "start": "385560",
    "end": "392819"
  },
  {
    "text": "use case the most common use case for clustering is is micro segmentation for",
    "start": "392819",
    "end": "398130"
  },
  {
    "text": "marketing purposes every business tries to address their",
    "start": "398130",
    "end": "404940"
  },
  {
    "text": "customers both as a in a very personal one-to-one way whenever possible but",
    "start": "404940",
    "end": "411030"
  },
  {
    "text": "also in groups to provide value micro segmentation is a very hot topic these",
    "start": "411030",
    "end": "416880"
  },
  {
    "text": "days not only so that you can communicate through marketing means which is the typical way but also for",
    "start": "416880",
    "end": "424110"
  },
  {
    "text": "creating dynamic content if someone is is new to your site they have not made a",
    "start": "424110",
    "end": "431160"
  },
  {
    "text": "lot of choices yet about their preferences you can use the the little",
    "start": "431160",
    "end": "436650"
  },
  {
    "text": "bit of data that they have provided perhaps in a login form or some of the",
    "start": "436650",
    "end": "441840"
  },
  {
    "text": "information that might be available just through HTTP methods and you could begin to provide dynamic content that's more",
    "start": "441840",
    "end": "449670"
  },
  {
    "text": "relevant another term for micro segmentation is algorithmic personas and",
    "start": "449670",
    "end": "454730"
  },
  {
    "text": "this is where we're not going to cover this too much but the topic is in this",
    "start": "454730",
    "end": "460770"
  },
  {
    "text": "particular seminar but the topic is so important that it's very likely we'll",
    "start": "460770",
    "end": "466080"
  },
  {
    "text": "dedicate another webinar specifically to customer segmentation and dynamic",
    "start": "466080",
    "end": "472170"
  },
  {
    "text": "content delivery clustering is also used for a fraud detection and anti-money",
    "start": "472170",
    "end": "477810"
  },
  {
    "text": "laundering detection it's very useful for going through logs and notifications",
    "start": "477810",
    "end": "484440"
  },
  {
    "text": "that are caused by alerts and as I mentioned before it's very common in the",
    "start": "484440",
    "end": "489660"
  },
  {
    "text": "machine learning pipeline we're going to touch on that briefly using spark so",
    "start": "489660",
    "end": "496410"
  },
  {
    "start": "495000",
    "end": "615000"
  },
  {
    "text": "k-means k-means is probably the most popular clustering technique there are",
    "start": "496410",
    "end": "502680"
  },
  {
    "text": "others what Kay refers to is how many clusters there are in your particular",
    "start": "502680",
    "end": "509630"
  },
  {
    "text": "data set so k is a predetermined number before you can run k-means clustering",
    "start": "509630",
    "end": "515360"
  },
  {
    "text": "you have to ascertain some with some method how many clusters you think are",
    "start": "515360",
    "end": "522840"
  },
  {
    "text": "there so for example if you had a collection of handwritten images and you",
    "start": "522840",
    "end": "529860"
  },
  {
    "text": "knew that those images were all numbers 0 through 9 it would be pretty easy to determine",
    "start": "529860",
    "end": "535080"
  },
  {
    "text": "that the number of clusters you were going to come get to once you've gone",
    "start": "535080",
    "end": "540990"
  },
  {
    "text": "through those images would be ten because there's there's only ten digits it's not so easy when you're taking a",
    "start": "540990",
    "end": "547380"
  },
  {
    "text": "look for example at your customer transaction data you know where where do",
    "start": "547380",
    "end": "552690"
  },
  {
    "text": "they live what's their income what's their standard purchase level it's sometimes very difficult to determine",
    "start": "552690",
    "end": "559950"
  },
  {
    "text": "but I'm going to show you a method that's quickly evolving for determining in advance what a good number to start",
    "start": "559950",
    "end": "566760"
  },
  {
    "text": "is for your question typically the way the method works is you take a look at",
    "start": "566760",
    "end": "573060"
  },
  {
    "text": "your addressable data space and you place the centroids at random locations",
    "start": "573060",
    "end": "578360"
  },
  {
    "text": "then you will find for each point in the data set where the nearest point to that",
    "start": "578360",
    "end": "586790"
  },
  {
    "text": "randomly assigned centroid is what it's called and begin to calculate a distance",
    "start": "586790",
    "end": "594350"
  },
  {
    "text": "so for each cluster then once you've done that once you will move actually",
    "start": "594350",
    "end": "600810"
  },
  {
    "text": "your data point to the average in Euclidean distance to where you assigned",
    "start": "600810",
    "end": "607140"
  },
  {
    "text": "where you initially sign the first random centroid so I have a graphic",
    "start": "607140",
    "end": "612750"
  },
  {
    "text": "description of that if that was a little bit hard to follow so let's say we have",
    "start": "612750",
    "end": "617910"
  },
  {
    "text": "a data set right here and of course it's unlabeled at this point and we're guessing that there are two clusters in",
    "start": "617910",
    "end": "625500"
  },
  {
    "text": "this particular set of data we have a n X and y axis here so this is you know",
    "start": "625500",
    "end": "631980"
  },
  {
    "text": "just a two dimensional view but you can and we will actually in today's demo look at n dimensional data so we don't",
    "start": "631980",
    "end": "640500"
  },
  {
    "text": "know right now where the clusters are in this group so we start off by just",
    "start": "640500",
    "end": "645720"
  },
  {
    "text": "picking two random points and we calculate the Euclidean distance between",
    "start": "645720",
    "end": "650760"
  },
  {
    "text": "them and then set a line perpendicular to that the line we first came up with",
    "start": "650760",
    "end": "656940"
  },
  {
    "text": "then we simply divide okay all of the",
    "start": "656940",
    "end": "663020"
  },
  {
    "text": "data sets the data points that are on one side of outline we'll go to one centroid the",
    "start": "663020",
    "end": "670499"
  },
  {
    "text": "others we'll go to the other centroid now the next step is to calculate the mean or the average distance between",
    "start": "670499",
    "end": "677519"
  },
  {
    "text": "every one of those points and our randomly chosen centroid now I should",
    "start": "677519",
    "end": "683879"
  },
  {
    "text": "have said this initially the centroid is denoted by the triangle so what we do is",
    "start": "683879",
    "end": "690749"
  },
  {
    "text": "we take that mean number and we relocate the centroid once we've moved that",
    "start": "690749",
    "end": "697350"
  },
  {
    "text": "centroid to the new mean we repeat the process again and we iterate essentially",
    "start": "697350",
    "end": "704279"
  },
  {
    "text": "until none of the points within the cluster members are changing changing",
    "start": "704279",
    "end": "711899"
  },
  {
    "text": "cluster groups so that's the basic methodology when you walk through it sort of visually I think it makes a",
    "start": "711899",
    "end": "718170"
  },
  {
    "text": "little bit more sense it's important to note that there will be a handful of",
    "start": "718170",
    "end": "723480"
  },
  {
    "text": "anomalies some of the data points just don't fall nicely into the clusters that",
    "start": "723480",
    "end": "730769"
  },
  {
    "text": "are pre-assign so these are typically the sort of grains of sand that we're",
    "start": "730769",
    "end": "736589"
  },
  {
    "text": "looking for when we're doing anomaly detection and they may be interesting",
    "start": "736589",
    "end": "743430"
  },
  {
    "text": "data points for exploration for other techniques in machine learning you know",
    "start": "743430",
    "end": "749100"
  },
  {
    "text": "why why are these outliers out there however the majority of the data points",
    "start": "749100",
    "end": "755040"
  },
  {
    "text": "here have been put into our respective clusters so where are you to have the",
    "start": "755040",
    "end": "760470"
  },
  {
    "text": "attributes of that particular cluster in arriving in your data set it would be",
    "start": "760470",
    "end": "767100"
  },
  {
    "text": "relatively easy to act on that data now I mentioned that it's not particularly",
    "start": "767100",
    "end": "774329"
  },
  {
    "start": "770000",
    "end": "840000"
  },
  {
    "text": "easy to determine in advance how many clusters you're going to have in your data set there is a method it's called",
    "start": "774329",
    "end": "782100"
  },
  {
    "text": "the elbow method where you essentially repeatedly run your k-means clustering",
    "start": "782100",
    "end": "788249"
  },
  {
    "text": "for a range of values for K so for each value of K you calculate a sum of square",
    "start": "788249",
    "end": "795870"
  },
  {
    "text": "errors and you just graph that and you do we visually look to see if there's",
    "start": "795870",
    "end": "803060"
  },
  {
    "text": "something that looks like an elbow on this particular chart we see an elbow around three and that's where as we",
    "start": "803060",
    "end": "811010"
  },
  {
    "text": "begin to add more and more clusters there's just less and less a benefit to",
    "start": "811010",
    "end": "816680"
  },
  {
    "text": "adding to the number of clusters so I have a little bit of Python code here",
    "start": "816680",
    "end": "821900"
  },
  {
    "text": "that's you know it just sort of shows how that that chart was created it's",
    "start": "821900",
    "end": "827390"
  },
  {
    "text": "it's a simple method and it comes in pretty handy one warning here though is that sometimes it does not produce a",
    "start": "827390",
    "end": "834680"
  },
  {
    "text": "nice clean elbow so you have to just eyeball the data and or look for other",
    "start": "834680",
    "end": "839990"
  },
  {
    "text": "methods now sage makers built-in k-means is not your scikit-learn k-means it's",
    "start": "839990",
    "end": "849110"
  },
  {
    "start": "840000",
    "end": "940000"
  },
  {
    "text": "based on some interesting technology that is a bit custom to what we're doing",
    "start": "849110",
    "end": "855560"
  },
  {
    "text": "in house but also positive it's popular in the literature",
    "start": "855560",
    "end": "861040"
  },
  {
    "text": "so in particular we have two means of",
    "start": "861040",
    "end": "866350"
  },
  {
    "text": "creating our initial cluster centers one is called k-means plus plus and the",
    "start": "866350",
    "end": "872960"
  },
  {
    "text": "other is random which is is the default so like the original it scales massive",
    "start": "872960",
    "end": "880070"
  },
  {
    "text": "data sets to deliver improvements a little hard time seeing my screen here",
    "start": "880070",
    "end": "885950"
  },
  {
    "text": "because the webinar control panels in the way there we go excuse me and the way you change this is actually on the",
    "start": "885950",
    "end": "893690"
  },
  {
    "text": "either in python or in the GUI by setting the factor that that essentially",
    "start": "893690",
    "end": "902270"
  },
  {
    "text": "just chooses your means of k-means clustering we also have an additional",
    "start": "902270",
    "end": "908990"
  },
  {
    "text": "factor called the extra center factor which also increases accuracy the k-means that's",
    "start": "908990",
    "end": "915860"
  },
  {
    "text": "built into sage maker is made made for very large datasets although it's",
    "start": "915860",
    "end": "921560"
  },
  {
    "text": "certainly usable on on small datasets but this ability to do mini batches",
    "start": "921560",
    "end": "927520"
  },
  {
    "text": "massively improves the time and reduces the cost of doing your",
    "start": "927520",
    "end": "934130"
  },
  {
    "text": "straining now what what does the IO look",
    "start": "934130",
    "end": "942380"
  },
  {
    "start": "940000",
    "end": "975000"
  },
  {
    "text": "like so when you're creating k-means cluster or data is generally expected to",
    "start": "942380",
    "end": "951050"
  },
  {
    "text": "be tabular data the rows will represent the observations that you want to",
    "start": "951050",
    "end": "956210"
  },
  {
    "text": "cluster and the columns represent the attributes or the features of the data",
    "start": "956210",
    "end": "962350"
  },
  {
    "text": "you can have any number of features and",
    "start": "962350",
    "end": "967420"
  },
  {
    "text": "so there's really no practical limit but that brings us to one of the next topics",
    "start": "967420",
    "end": "974930"
  },
  {
    "text": "which is how do we know which of those factors are important so we're going to cover that very very briefly with PCA",
    "start": "974930",
    "end": "981260"
  },
  {
    "start": "975000",
    "end": "1010000"
  },
  {
    "text": "but we made you PCA in a separate seminar as well now how do you create",
    "start": "981260",
    "end": "987170"
  },
  {
    "text": "the training job so you will need to specify the case string there is a case",
    "start": "987170",
    "end": "996080"
  },
  {
    "text": "simply being your the number of clusters you expect you do have the option of adding that extra Center factor string",
    "start": "996080",
    "end": "1003990"
  },
  {
    "text": "and then you specify the strategy you want to use for that initial cluster Center now because there is no accuracy",
    "start": "1003990",
    "end": "1016540"
  },
  {
    "start": "1010000",
    "end": "1065000"
  },
  {
    "text": "measurement no validation set is required so how do we do hyper parameter",
    "start": "1016540",
    "end": "1023020"
  },
  {
    "text": "optimization and that's where the test dataset comes in so the taste test data",
    "start": "1023020",
    "end": "1029140"
  },
  {
    "text": "set will emit metrics that depend on the squared distance between data points and",
    "start": "1029140",
    "end": "1034750"
  },
  {
    "text": "the final cluster centroids at the end of the training run so this can be used",
    "start": "1034750",
    "end": "1039880"
  },
  {
    "text": "to test and create some optimizations around our final centroid values a range",
    "start": "1039880",
    "end": "1048970"
  },
  {
    "text": "of values are tested by running many jobs so you can choose tunable hyper",
    "start": "1048970",
    "end": "1054100"
  },
  {
    "text": "parameters and you would set a an objective metric for each of those I'm",
    "start": "1054100",
    "end": "1060010"
  },
  {
    "text": "going to demonstrate this when we get to our actual hands-on demo here now I've",
    "start": "1060010",
    "end": "1065980"
  },
  {
    "start": "1065000",
    "end": "1175000"
  },
  {
    "text": "hinted a few times that we do some dimensionality reduction we do",
    "start": "1065980",
    "end": "1071470"
  },
  {
    "text": "have a built-in algorithm for that called PCA or a principal component analysis PCA is very common in data",
    "start": "1071470",
    "end": "1081100"
  },
  {
    "text": "science when you have a data set with many many features and that could be",
    "start": "1081100",
    "end": "1086680"
  },
  {
    "text": "anything from a transaction database say if you have credit card transactions",
    "start": "1086680",
    "end": "1092200"
  },
  {
    "text": "you're a merchant and you have all this data around them that includes GPS data",
    "start": "1092200",
    "end": "1098010"
  },
  {
    "text": "the time of sale the location of the store other things that were purchased",
    "start": "1098010",
    "end": "1103420"
  },
  {
    "text": "on the same invoice etc and what we'll attempt to do is take the factors in",
    "start": "1103420",
    "end": "1110710"
  },
  {
    "text": "those the features in the columns in that data set and determine which caused",
    "start": "1110710",
    "end": "1117370"
  },
  {
    "text": "the most variability in that data set it will cluster them in such a way that",
    "start": "1117370",
    "end": "1123990"
  },
  {
    "text": "they will begin to combine those features into combined components where",
    "start": "1123990",
    "end": "1130150"
  },
  {
    "text": "the largest possible variability becomes your first component the second most becomes your second most and so on I",
    "start": "1130150",
    "end": "1138100"
  },
  {
    "text": "have seen some datasets with literally thousands of features thousands of",
    "start": "1138100",
    "end": "1144400"
  },
  {
    "text": "columns for example as you're looking at the data so that is not the kind of",
    "start": "1144400",
    "end": "1149980"
  },
  {
    "text": "thing you want to run through a k-means clustering it's very likely not going to",
    "start": "1149980",
    "end": "1155530"
  },
  {
    "text": "produce usable data but if you could trim that down by both ignoring",
    "start": "1155530",
    "end": "1161620"
  },
  {
    "text": "irrelevant columns and combining columns that combine well to reduce variability",
    "start": "1161620",
    "end": "1168220"
  },
  {
    "text": "it's a really important part of creating a really effective clustering model",
    "start": "1168220",
    "end": "1174390"
  },
  {
    "text": "there's two kinds of PCA modes regular and randomized regular is for data sets",
    "start": "1174390",
    "end": "1180670"
  },
  {
    "start": "1175000",
    "end": "1195000"
  },
  {
    "text": "with spart sparse data and randomized would be used for data sets with both a",
    "start": "1180670",
    "end": "1186490"
  },
  {
    "text": "large number of observations and features that uses another approximation algorithm another important thing about",
    "start": "1186490",
    "end": "1195490"
  },
  {
    "start": "1195000",
    "end": "1220000"
  },
  {
    "text": "CH Baker in general is a lot of the routines a lot of the algorithms do",
    "start": "1195490",
    "end": "1201040"
  },
  {
    "text": "prefer what's called record i/o for a map however comma separated values is also",
    "start": "1201040",
    "end": "1207610"
  },
  {
    "text": "an option it's pretty easy to convert your data into record i/o format we're",
    "start": "1207610",
    "end": "1212740"
  },
  {
    "text": "gonna see a little bit of that in the code but you can still use CSV so what",
    "start": "1212740",
    "end": "1221020"
  },
  {
    "start": "1220000",
    "end": "1365000"
  },
  {
    "text": "does this look like in a pipeline well first of all notice that there's well",
    "start": "1221020",
    "end": "1227410"
  },
  {
    "text": "not only a spinning sneaker but a big blue line in the middle of this screen",
    "start": "1227410",
    "end": "1232570"
  },
  {
    "text": "and that blue line is differentiating between the model training section and",
    "start": "1232570",
    "end": "1238420"
  },
  {
    "text": "the inference section so sometimes I think or even described model training",
    "start": "1238420",
    "end": "1244090"
  },
  {
    "text": "is almost like a compiler you know where instead of writing code you know you've",
    "start": "1244090",
    "end": "1251110"
  },
  {
    "text": "got data your data is in the form of labeled image vectors in that case",
    "start": "1251110",
    "end": "1258220"
  },
  {
    "text": "you're really examining the data you know looking at the data and creating a",
    "start": "1258220",
    "end": "1263260"
  },
  {
    "text": "cluster clustered model that then becomes a trained model so in my",
    "start": "1263260",
    "end": "1268710"
  },
  {
    "text": "metaphor or my analogy to a compiler you know your trained model is the output",
    "start": "1268710",
    "end": "1273930"
  },
  {
    "text": "like that executable code say but that's all just when you're training that's",
    "start": "1273930",
    "end": "1280210"
  },
  {
    "text": "just when you're looking at the data initially and you're creating a model it's not really what you're going to do",
    "start": "1280210",
    "end": "1286450"
  },
  {
    "text": "when you're in production when somebody comes to your site and you have those handful of attributes and say they want",
    "start": "1286450",
    "end": "1292690"
  },
  {
    "text": "to buy a gold sneaker and you want to you know get them to the closest",
    "start": "1292690",
    "end": "1298450"
  },
  {
    "text": "approximation of that object as you have in your online store for example so",
    "start": "1298450",
    "end": "1305380"
  },
  {
    "text": "that's where inference comes in inference is the real-time production version of your model it will take",
    "start": "1305380",
    "end": "1311710"
  },
  {
    "text": "whatever you're looking for let's say you saw somebody with a gold sneaker on the street and took a photo of that and",
    "start": "1311710",
    "end": "1318970"
  },
  {
    "text": "you uploaded that image to your online store and you wanted to find the nearest",
    "start": "1318970",
    "end": "1324000"
  },
  {
    "text": "centroid to that particular image so that's where that's where you're using",
    "start": "1324000",
    "end": "1330040"
  },
  {
    "text": "clustering in production and you know it's sort of a it's sort of a",
    "start": "1330040",
    "end": "1335210"
  },
  {
    "text": "I've case maybe but I wanted to separate very clearly for folks who are",
    "start": "1335210",
    "end": "1341000"
  },
  {
    "text": "relatively new to machine learning this critical difference between model",
    "start": "1341000",
    "end": "1346220"
  },
  {
    "text": "training and then inference in production so once you've found that nearest centroid you've found the actual",
    "start": "1346220",
    "end": "1353059"
  },
  {
    "text": "SKU for that sneaker in your database that's what you then return you may not",
    "start": "1353059",
    "end": "1358669"
  },
  {
    "text": "have the highly unique sneaker that was asked for originally so let's take a",
    "start": "1358669",
    "end": "1364730"
  },
  {
    "text": "look at some of this code now so first",
    "start": "1364730",
    "end": "1371870"
  },
  {
    "start": "1365000",
    "end": "1450000"
  },
  {
    "text": "of all I'm here at the sage maker console when you go to Sage maker of",
    "start": "1371870",
    "end": "1378320"
  },
  {
    "text": "course you have to create a notebook instance to begin to work with we have",
    "start": "1378320",
    "end": "1383750"
  },
  {
    "text": "some other courses that show you how to do that how to set that up properly but",
    "start": "1383750",
    "end": "1389029"
  },
  {
    "text": "just simply notice here that I already have one instance that's already in production and to start it up I just",
    "start": "1389029",
    "end": "1396049"
  },
  {
    "text": "click on this Open button if you ups I guess I have to renew my session here",
    "start": "1396049",
    "end": "1403940"
  },
  {
    "text": "was waiting a little bit too long okay when you do get to your sage maker",
    "start": "1403940",
    "end": "1409700"
  },
  {
    "text": "session you'll be greeted with a jupiter notebook browser if this is let me just",
    "start": "1409700",
    "end": "1416929"
  },
  {
    "text": "make that a little bit bigger if this is new to you let me just show you one or two of the features on this first of all",
    "start": "1416929",
    "end": "1424220"
  },
  {
    "text": "it is a browser okay I don't like the messages that I'm getting that's not",
    "start": "1424220",
    "end": "1436490"
  },
  {
    "text": "good do this quickly okay there we go",
    "start": "1436490",
    "end": "1441890"
  },
  {
    "text": "sorry for that delay I guess that's what happens when you're sitting with your notebook open for a little while okay so",
    "start": "1441890",
    "end": "1451010"
  },
  {
    "start": "1450000",
    "end": "1525000"
  },
  {
    "text": "here's what you see when you go into your notebook browser now I already have quite a few files here if this is a a",
    "start": "1451010",
    "end": "1456830"
  },
  {
    "text": "new notebook for you you will see a relatively empty set you'll just see this lost-and-found directory",
    "start": "1456830",
    "end": "1463240"
  },
  {
    "text": "importantly over here on the I guess the fourth tab in we",
    "start": "1463240",
    "end": "1468950"
  },
  {
    "text": "have a number of built-in sage maker examples and I like to use these as frequently as possible whenever I'm",
    "start": "1468950",
    "end": "1474970"
  },
  {
    "text": "describing features of sage maker I'm gonna use these mostly for today's presentation but I also have one or two",
    "start": "1474970",
    "end": "1482210"
  },
  {
    "text": "that are custom so what you'll see here is a lot of cut and paste code this is",
    "start": "1482210",
    "end": "1489350"
  },
  {
    "text": "really important to dive into some of these notebooks and take a look at some",
    "start": "1489350",
    "end": "1495170"
  },
  {
    "text": "of the features when you go into sage maker Python SDK we have a notebook here",
    "start": "1495170",
    "end": "1501650"
  },
  {
    "text": "called k-means M nest IP MIB now that IP NY b stands for ipython notebook and i",
    "start": "1501650",
    "end": "1509360"
  },
  {
    "text": "guess I'm gonna have to reload everything now that's unfortunate",
    "start": "1509360",
    "end": "1514400"
  },
  {
    "text": "we just mmm just kill everything and I guess I'm gonna have to start it back up",
    "start": "1514400",
    "end": "1521150"
  },
  {
    "text": "from scratch that's unfortunate so I do want to show you though quickly how I",
    "start": "1521150",
    "end": "1528620"
  },
  {
    "start": "1525000",
    "end": "1640000"
  },
  {
    "text": "brought up these built in or example notebooks up so that you can get running",
    "start": "1528620",
    "end": "1534560"
  },
  {
    "text": "right away and the way you do that is you open up the sage maker Tao examples",
    "start": "1534560",
    "end": "1539900"
  },
  {
    "text": "tab identify the notebook you're going to work with the first one we're gonna do is this k-means m nist ipy and be",
    "start": "1539900",
    "end": "1546950"
  },
  {
    "text": "notice to that there's two ways to look at this if you're just here to copy and paste code you can click on preview and",
    "start": "1546950",
    "end": "1553880"
  },
  {
    "text": "what it's essentially going to do is give you the code you could just very quickly copy and paste this put in the",
    "start": "1553880",
    "end": "1560510"
  },
  {
    "text": "notebook that you know you're you're building just go ahead and close that and you're done you're on your way if",
    "start": "1560510",
    "end": "1566570"
  },
  {
    "text": "you do want to run this in your in your notebook you just click the use button",
    "start": "1566570",
    "end": "1572140"
  },
  {
    "text": "so I'm going to go back to my file browser and I'm going to click on this",
    "start": "1572140",
    "end": "1577520"
  },
  {
    "text": "which I did have I did start earlier actually here's the notebook that I",
    "start": "1577520",
    "end": "1583610"
  },
  {
    "text": "actually started it's k-means and mist and - this is a really simple example of",
    "start": "1583610",
    "end": "1592270"
  },
  {
    "text": "using k-means to do exactly the case",
    "start": "1592270",
    "end": "1598040"
  },
  {
    "text": "that i described before where you're identifying twelve handwritten digits now one of the",
    "start": "1598040",
    "end": "1604559"
  },
  {
    "text": "reasons that the M newest data set is used so frequently is it's very well labeled it's somewhat well known and",
    "start": "1604559",
    "end": "1612179"
  },
  {
    "text": "it's also got a lot of dimensionality each of the images in the Amnesty Attah",
    "start": "1612179",
    "end": "1619620"
  },
  {
    "text": "set and there are 70,000 of them represent 28 by 28 pixel images and I",
    "start": "1619620",
    "end": "1627419"
  },
  {
    "text": "believe that if you do the multiplication there that each of those are going to be vectors then of 728 a",
    "start": "1627419",
    "end": "1635909"
  },
  {
    "text": "size of 728 so I'm not going to go",
    "start": "1635909",
    "end": "1641130"
  },
  {
    "start": "1640000",
    "end": "1675000"
  },
  {
    "text": "through every step I'm just going to point out the features of this particular notebook first of all of",
    "start": "1641130",
    "end": "1647400"
  },
  {
    "text": "course we have to acquire the data next up we're going to inspect a single cell",
    "start": "1647400",
    "end": "1653460"
  },
  {
    "text": "of that data we have a small routine here called show digit and here's the",
    "start": "1653460",
    "end": "1659370"
  },
  {
    "text": "handwritten digit of a3 we can change that just so you know that there's a",
    "start": "1659370",
    "end": "1665730"
  },
  {
    "text": "whole bunch of digits in here I'll change that to the very next one which may not necessarily be a three it isn't",
    "start": "1665730",
    "end": "1671669"
  },
  {
    "text": "it's an 8 now we go to actually train the model we have a number of built-in",
    "start": "1671669",
    "end": "1678260"
  },
  {
    "start": "1675000",
    "end": "1735000"
  },
  {
    "text": "algorithms that are in the SDK and they're all documented in both on HTTP",
    "start": "1678260",
    "end": "1686360"
  },
  {
    "text": "online and also in a PDF which I highly recommend downloading so to call the",
    "start": "1686360",
    "end": "1692789"
  },
  {
    "text": "k-means algorithm we essentially have a wrapper here where we call this wrapper",
    "start": "1692789",
    "end": "1698130"
  },
  {
    "text": "and we have to give it a few parameters first of all we're going to say how many instances do we want to train on what",
    "start": "1698130",
    "end": "1705630"
  },
  {
    "text": "machine type do we want to train on in this instance it's a c48 x-large",
    "start": "1705630",
    "end": "1711169"
  },
  {
    "text": "we do have to specify the required parameters in this case we know the",
    "start": "1711169",
    "end": "1717600"
  },
  {
    "text": "numbers 10 and we do need to say where the data is now that was defined right",
    "start": "1717600",
    "end": "1723390"
  },
  {
    "text": "here so so far in this notebook we have downloaded our data set we have taken a",
    "start": "1723390",
    "end": "1730380"
  },
  {
    "text": "quick look at it we've told the wrapper where the data set is",
    "start": "1730380",
    "end": "1736410"
  },
  {
    "start": "1735000",
    "end": "1800000"
  },
  {
    "text": "now we want to actually train the model and in order to do that we call the",
    "start": "1736410",
    "end": "1743100"
  },
  {
    "text": "rapper and with its method called fit I just want to show you in Sage Maker now",
    "start": "1743100",
    "end": "1748830"
  },
  {
    "text": "what goodness what that looks like here on the console so in the console on the",
    "start": "1748830",
    "end": "1755100"
  },
  {
    "text": "left hand side we have a separate section for training jobs so unlike",
    "start": "1755100",
    "end": "1761250"
  },
  {
    "text": "maybe other jupiter notebook experiences that you may have had when you're",
    "start": "1761250",
    "end": "1767670"
  },
  {
    "text": "training jobs on sage maker your training goes to another machine now one",
    "start": "1767670",
    "end": "1774090"
  },
  {
    "text": "of the reasons we do that is to keep our costs low oh and you're in a notebook and you're just editing code the way you",
    "start": "1774090",
    "end": "1780420"
  },
  {
    "text": "just saw me do exploring data etc there's no reason to have for example a p2 or p3 instance which can be very",
    "start": "1780420",
    "end": "1788400"
  },
  {
    "text": "costly in fact when I started up this instance I just used an m4 you can even use a t2",
    "start": "1788400",
    "end": "1794580"
  },
  {
    "text": "which is our least costly server so one reason is so that you keep the costs",
    "start": "1794580",
    "end": "1800940"
  },
  {
    "start": "1800000",
    "end": "1880000"
  },
  {
    "text": "very low another is so that when you do your training job you can send those jobs off to clusters in this particular",
    "start": "1800940",
    "end": "1808740"
  },
  {
    "text": "instance I'll just click on this job which I ran some time ago and we specified in this case we specified an",
    "start": "1808740",
    "end": "1816480"
  },
  {
    "text": "incidence count of only one but you can train on any number of machines in fact",
    "start": "1816480",
    "end": "1822020"
  },
  {
    "text": "we have this notion of infinitely scalable training algorithms in sage",
    "start": "1822020",
    "end": "1828720"
  },
  {
    "text": "maker what that means essentially is that we automatically manage our memory",
    "start": "1828720",
    "end": "1834810"
  },
  {
    "text": "not only within the GPUs but even out of the GPUs to clusters of machines to",
    "start": "1834810",
    "end": "1840120"
  },
  {
    "text": "train very large data sets so these are very powerful capabilities within sage",
    "start": "1840120",
    "end": "1846810"
  },
  {
    "text": "maker at the bottom of the screen you can monitor your logs from the training session I'll just click on that very",
    "start": "1846810",
    "end": "1852900"
  },
  {
    "text": "quickly and what we'll see is the output that you would ordinarily see in your",
    "start": "1852900",
    "end": "1858930"
  },
  {
    "text": "Joe Pitt or notebook as we went through the epics of the training so I'm going",
    "start": "1858930",
    "end": "1863940"
  },
  {
    "text": "to close that window up go back to my notebook here we'll see that that same",
    "start": "1863940",
    "end": "1869770"
  },
  {
    "text": "data is a little bit harder to read because it's all kind of comes out and read here when you're doing that",
    "start": "1869770",
    "end": "1875950"
  },
  {
    "text": "training next up we're going to actually host our model so on sage maker we do",
    "start": "1875950",
    "end": "1882550"
  },
  {
    "start": "1880000",
    "end": "1925000"
  },
  {
    "text": "differentiate between our notebook our training sessions and then our production endpoints when you set a",
    "start": "1882550",
    "end": "1890350"
  },
  {
    "text": "production endpoint you just use this command called deploy and once again you have enormous power here and your",
    "start": "1890350",
    "end": "1897250"
  },
  {
    "text": "options in this particular instance we're just setting up one server but you could set that as 10 you can also do",
    "start": "1897250",
    "end": "1904780"
  },
  {
    "text": "production variants to run your incoming data in through several different",
    "start": "1904780",
    "end": "1912250"
  },
  {
    "text": "versions of your trained model we're keeping it simple here though and notice for all that power that we have in this",
    "start": "1912250",
    "end": "1918520"
  },
  {
    "text": "one command it only takes six minutes and just removes all of that heavy lifting all",
    "start": "1918520",
    "end": "1923980"
  },
  {
    "text": "right so now we're gonna validate the model we're gonna call predict on that model and we're gonna send it these two",
    "start": "1923980",
    "end": "1932560"
  },
  {
    "start": "1925000",
    "end": "1950000"
  },
  {
    "text": "items from our data set the ones we looked at above as we do that and we can",
    "start": "1932560",
    "end": "1938950"
  },
  {
    "text": "do this one interactively because we we do have the the endpoint in production",
    "start": "1938950",
    "end": "1947800"
  },
  {
    "text": "we can see what our clusters turned out to be now k-means clustering is is not the best",
    "start": "1947800",
    "end": "1954520"
  },
  {
    "start": "1950000",
    "end": "1990000"
  },
  {
    "text": "way to do image recognition I mean we do see in this example here that you know it's certainly clustered the zero as",
    "start": "1954520",
    "end": "1961150"
  },
  {
    "text": "well this cluster doesn't look too good the three is a little confusing but as a",
    "start": "1961150",
    "end": "1967300"
  },
  {
    "text": "very simple sort of off-the-shelf alit sort of nailed the sixes but you do see",
    "start": "1967300",
    "end": "1973180"
  },
  {
    "text": "that data has been clustered the the images have been clustered perhaps if we",
    "start": "1973180",
    "end": "1978580"
  },
  {
    "text": "ran more epics this would have been a little bit better but we do have a soup",
    "start": "1978580",
    "end": "1984310"
  },
  {
    "text": "to nuts example here of how to do the actual clustering on these images now",
    "start": "1984310",
    "end": "1991270"
  },
  {
    "start": "1990000",
    "end": "2075000"
  },
  {
    "text": "it's very important at the end of any of these notebooks there's always an option here to delete the endpoint I commented",
    "start": "1991270",
    "end": "1997660"
  },
  {
    "text": "mine out because I did not want these to be deleted for today's training session please do too",
    "start": "1997660",
    "end": "2003539"
  },
  {
    "text": "these though because they can be costly if you forget to delete them at the end",
    "start": "2003539",
    "end": "2008759"
  },
  {
    "text": "of your session okay so we're done with those notebooks I'm I want to dive a",
    "start": "2008759",
    "end": "2014460"
  },
  {
    "text": "little bit more deeply into this process now we looked at a very high level means",
    "start": "2014460",
    "end": "2021629"
  },
  {
    "text": "of doing K means we really trusted the defaults around a lot of the process we",
    "start": "2021629",
    "end": "2029369"
  },
  {
    "text": "do have another notebook here which is simply called M missed low level and what this sampled notebook exposes and",
    "start": "2029369",
    "end": "2037169"
  },
  {
    "text": "I'm just going to go right to it because it's very similar except for one section here is this section right here so a",
    "start": "2037169",
    "end": "2045299"
  },
  {
    "text": "really important point of learning how to use sage maker getting you know sort of up to intermediate and advanced level",
    "start": "2045299",
    "end": "2052200"
  },
  {
    "text": "on it is recognizing that it's built on a foundation of docker containers right",
    "start": "2052200",
    "end": "2059970"
  },
  {
    "text": "here we're specifying where the docker containers are actually in ECR excuse me",
    "start": "2059970",
    "end": "2065990"
  },
  {
    "text": "for all of our built-in algorithms those are just set up in a list here the",
    "start": "2065990",
    "end": "2071760"
  },
  {
    "text": "docker images and what I wanted to show here is what all the particular training",
    "start": "2071760",
    "end": "2077908"
  },
  {
    "start": "2075000",
    "end": "2190000"
  },
  {
    "text": "parameters are for a k-means job what those options are now once again this is",
    "start": "2077909",
    "end": "2084030"
  },
  {
    "text": "pretty well articulated in the documentation there are also numerous examples online but if I go to the",
    "start": "2084030",
    "end": "2091950"
  },
  {
    "text": "console go to training jobs here again and just click on the create training",
    "start": "2091950",
    "end": "2097079"
  },
  {
    "text": "job button you'll be given this form where you can actually see through a GUI",
    "start": "2097079",
    "end": "2103520"
  },
  {
    "text": "what all of those options are so all of the built-in algorithms are right here and you can explore those at any time",
    "start": "2103520",
    "end": "2110160"
  },
  {
    "text": "when we click on k-means and come down here to hyper parameters we see what all",
    "start": "2110160",
    "end": "2116309"
  },
  {
    "text": "of those options are so for our training job for example we're going to say we're going to give it 10 future dimensions I",
    "start": "2116309",
    "end": "2123750"
  },
  {
    "text": "could be wrong but I think it's 7:28 here's that method for your initial",
    "start": "2123750",
    "end": "2129059"
  },
  {
    "text": "cluster placement by default it's going to be random we can use k-means plus",
    "start": "2129059",
    "end": "2134339"
  },
  {
    "text": "plus if your data set is small we my want to reduce this so you get the idea",
    "start": "2134339",
    "end": "2140310"
  },
  {
    "text": "and then also we have our extra Center factor so these are all things that I",
    "start": "2140310",
    "end": "2146010"
  },
  {
    "text": "sort of mentioned and a number of other controls including the various local Lloyd options so I encourage you to play",
    "start": "2146010",
    "end": "2156270"
  },
  {
    "text": "with this everything we're doing here in Python can be done in the GUI and",
    "start": "2156270",
    "end": "2161570"
  },
  {
    "text": "sometimes going to the GUI can be helpful when you're writing this Python code so that you set your parameters",
    "start": "2161570",
    "end": "2168420"
  },
  {
    "text": "appropriately now here in this section we have our hyper parameters we have our",
    "start": "2168420",
    "end": "2173430"
  },
  {
    "text": "case setting at 10'o feature dimensions is 784 that's it I said 728 believe I",
    "start": "2173430",
    "end": "2180960"
  },
  {
    "text": "believe earlier so forgive me but there it is 784 mini-batch size five hundred",
    "start": "2180960",
    "end": "2186590"
  },
  {
    "text": "so the rest of this job is pretty much like the initial job we do have this",
    "start": "2186590",
    "end": "2194550"
  },
  {
    "start": "2190000",
    "end": "2290000"
  },
  {
    "text": "method called describe training job I would like to point out very briefly",
    "start": "2194550",
    "end": "2199830"
  },
  {
    "text": "that all of those commands for monitoring are available from the AWS",
    "start": "2199830",
    "end": "2208940"
  },
  {
    "text": "CLI so if I type AWS sage maker and help",
    "start": "2208940",
    "end": "2215060"
  },
  {
    "text": "you will see all of the various commands including this described training job",
    "start": "2215060",
    "end": "2221160"
  },
  {
    "text": "which is right here if I copy that and say AWS sage maker and then describe",
    "start": "2221160",
    "end": "2230520"
  },
  {
    "text": "training job and help you can see what the required parameters are versus you",
    "start": "2230520",
    "end": "2238020"
  },
  {
    "text": "know the optional parameters and this is true now the reason I'm pointing this out is you know sometimes it takes a",
    "start": "2238020",
    "end": "2243900"
  },
  {
    "text": "long time to train data right so you know I like to set this up in a way let",
    "start": "2243900",
    "end": "2249690"
  },
  {
    "text": "me make that a little bigger so you can all see that I like to set this up so that I might have a bash shell and a",
    "start": "2249690",
    "end": "2256410"
  },
  {
    "text": "while loop that is checking to see whether the status of that job is done",
    "start": "2256410",
    "end": "2261420"
  },
  {
    "text": "and then I'll use SNS to contact me send me a text when my training job is done",
    "start": "2261420",
    "end": "2267990"
  },
  {
    "text": "this one went fairly quickly and just for and once again the testing routines at",
    "start": "2267990",
    "end": "2273599"
  },
  {
    "text": "the bottom indicate that we found pretty good clusters but not perfect as",
    "start": "2273599",
    "end": "2279239"
  },
  {
    "text": "mentioned k-means is is not you would want to use a convolutional neural network for doing clustering of digits",
    "start": "2279239",
    "end": "2288470"
  },
  {
    "text": "so we don't always have image data right nine times out of ten we're working with",
    "start": "2288470",
    "end": "2293960"
  },
  {
    "start": "2290000",
    "end": "2365000"
  },
  {
    "text": "tabular data there's a really great blog entry here that's in the AWS blog and",
    "start": "2293960",
    "end": "2301950"
  },
  {
    "text": "the AWS blog is a great resource for many things hammam created this particular one and I think it's a great",
    "start": "2301950",
    "end": "2309630"
  },
  {
    "text": "introduction to how you might use 2d data in k-means clustering it also",
    "start": "2309630",
    "end": "2315450"
  },
  {
    "text": "demonstrates a very very typical pipeline where you would use PCA to",
    "start": "2315450",
    "end": "2321599"
  },
  {
    "text": "first reduce dimensionality of a particular data set and then use that",
    "start": "2321599",
    "end": "2327150"
  },
  {
    "text": "data set them for clustering in this example he uses US census data for a",
    "start": "2327150",
    "end": "2333329"
  },
  {
    "text": "popular population segmentation and says I think you know quite accurately when",
    "start": "2333329",
    "end": "2339420"
  },
  {
    "text": "whenever elections come up you want to dig into your data for insights as you",
    "start": "2339420",
    "end": "2345299"
  },
  {
    "text": "begin to you know look at how certain counties in the US might might be",
    "start": "2345299",
    "end": "2352589"
  },
  {
    "text": "similar or different and that's exactly what he does here he uses an open source",
    "start": "2352589",
    "end": "2358910"
  },
  {
    "text": "dataset it's not run by the Census Department but it includes Census",
    "start": "2358910",
    "end": "2364019"
  },
  {
    "text": "Department data so I created a I created",
    "start": "2364019",
    "end": "2369239"
  },
  {
    "start": "2365000",
    "end": "2390000"
  },
  {
    "text": "a notebook which may or not be accessible here there we go I created a notebook from that blog",
    "start": "2369239",
    "end": "2375599"
  },
  {
    "text": "entry this is not open source yet but it will be soon and as members of the",
    "start": "2375599",
    "end": "2382559"
  },
  {
    "text": "partner network you can certainly reach out to me if you want to get early access to at least my version of this",
    "start": "2382559",
    "end": "2389249"
  },
  {
    "text": "thing so as you could see first what we do in this notebook is we simply load up",
    "start": "2389249",
    "end": "2396089"
  },
  {
    "start": "2390000",
    "end": "2430000"
  },
  {
    "text": "our various modules nothing too",
    "start": "2396089",
    "end": "2401640"
  },
  {
    "text": "surprising here we have pandas numpy map etc we will go in here and get the",
    "start": "2401640",
    "end": "2408630"
  },
  {
    "text": "actual census data it turns out that it this is one of the many open-source data",
    "start": "2408630",
    "end": "2414960"
  },
  {
    "text": "sets that AWS keeps in s3 and it's at this bucket which is available once",
    "start": "2414960",
    "end": "2421980"
  },
  {
    "text": "again through the CLI AWS ml blog sage maker census segmentation etc so we get",
    "start": "2421980",
    "end": "2429090"
  },
  {
    "text": "that data into our s3 bucket and we just take a quick look at it and what we see here are states and counties and all of",
    "start": "2429090",
    "end": "2437520"
  },
  {
    "text": "the various population and census characteristics around this data now",
    "start": "2437520",
    "end": "2443340"
  },
  {
    "text": "what's interesting about this is that this is free data it's open data where are you doing market segmentation this",
    "start": "2443340",
    "end": "2450600"
  },
  {
    "text": "is a pretty good place to look when you were looking to enhance the number of features that you had in your data set",
    "start": "2450600",
    "end": "2458390"
  },
  {
    "text": "job number one always is cleaning up your data first thing he does is drop",
    "start": "2458390",
    "end": "2464480"
  },
  {
    "start": "2460000",
    "end": "2530000"
  },
  {
    "text": "incomplete data in the rows turns on it turns out only two rows drop out he",
    "start": "2464480",
    "end": "2470400"
  },
  {
    "text": "combines state and counties together takes a look at just one of the",
    "start": "2470400",
    "end": "2477030"
  },
  {
    "text": "characteristics of that data where he's taking a look at job types you can see that there's a pretty strong cluster in",
    "start": "2477030",
    "end": "2484290"
  },
  {
    "text": "this histogram around say 27 percent for people that characterized their job as",
    "start": "2484290",
    "end": "2489450"
  },
  {
    "text": "professional service or office but it does run all the way to almost 80 percent in some counties service only",
    "start": "2489450",
    "end": "2497760"
  },
  {
    "text": "goes to 40 and office only goes to well just a little bit over 35 so already",
    "start": "2497760",
    "end": "2503550"
  },
  {
    "text": "we're discovering some interesting stuff in this data next up we're using scikit-learn to convert all of the",
    "start": "2503550",
    "end": "2511880"
  },
  {
    "text": "values within our columns to between 0 and 1 it's a very very common practice",
    "start": "2511880",
    "end": "2517760"
  },
  {
    "text": "when you use pandas described we can take another look at this data and we",
    "start": "2517760",
    "end": "2523560"
  },
  {
    "text": "could see this all now has been scaled between 0 & 1 alright let's skip ahead now to pca so",
    "start": "2523560",
    "end": "2530190"
  },
  {
    "start": "2530000",
    "end": "2555000"
  },
  {
    "text": "just as in the first example where we have a built-in function that calls k-means we have one for pca",
    "start": "2530190",
    "end": "2537730"
  },
  {
    "text": "here we're specifying how many machines we're gonna run our training on just one we're gonna do it on a c4 no GPU",
    "start": "2537730",
    "end": "2544930"
  },
  {
    "text": "required and we are specifying the number of components that we're looking for we're also going to specify that all",
    "start": "2544930",
    "end": "2552760"
  },
  {
    "text": "our data is float32 and what comes out of this let me just",
    "start": "2552760",
    "end": "2558070"
  },
  {
    "start": "2555000",
    "end": "2570000"
  },
  {
    "text": "scroll down a little bit oh I don't want to skip this part though what comes out",
    "start": "2558070",
    "end": "2564070"
  },
  {
    "text": "of this once our job has been trained this is actually the main reason I'm showing you this particular notebook",
    "start": "2564070",
    "end": "2570150"
  },
  {
    "start": "2570000",
    "end": "2675000"
  },
  {
    "text": "once our models been trained we need to open up that model and take a look at the individual components in this",
    "start": "2570150",
    "end": "2577570"
  },
  {
    "text": "particular case in a pipeline case we don't just care that we create a well-trained model we actually need to",
    "start": "2577570",
    "end": "2584140"
  },
  {
    "text": "look at the coefficients for the actual data so we can determine which parameters we want to use now because",
    "start": "2584140",
    "end": "2591450"
  },
  {
    "text": "PCA is built on MX net we can use MX net utilities all we have to do is load up",
    "start": "2591450",
    "end": "2599080"
  },
  {
    "text": "well first we have to import MX net then we load up the trained model and from",
    "start": "2599080",
    "end": "2605290"
  },
  {
    "text": "that trained model which is just going to be an ND array we can pull out these",
    "start": "2605290",
    "end": "2610930"
  },
  {
    "text": "two metrics and as it's described here V is going to be our principal components",
    "start": "2610930",
    "end": "2617500"
  },
  {
    "text": "and s is going to be the singular values for the components that were created in",
    "start": "2617500",
    "end": "2622630"
  },
  {
    "text": "that PCA transformation and just to move",
    "start": "2622630",
    "end": "2627760"
  },
  {
    "text": "down here just a little bit we could see that component number one which is our",
    "start": "2627760",
    "end": "2632859"
  },
  {
    "text": "most powerful component has these particular characteristics it is",
    "start": "2632859",
    "end": "2638670"
  },
  {
    "text": "predominantly black and Hispanic very low white population income is low so",
    "start": "2638670",
    "end": "2645940"
  },
  {
    "text": "this is obviously a pretty important variable we don't need to look at all 32",
    "start": "2645940",
    "end": "2651310"
  },
  {
    "text": "variables in this particular case we're just going to look at the first five now",
    "start": "2651310",
    "end": "2657220"
  },
  {
    "text": "we know from looking at this data what components were combined in this case",
    "start": "2657220",
    "end": "2665130"
  },
  {
    "text": "component one is poverty and unemployment self-employment public workers is number two and",
    "start": "2665130",
    "end": "2671390"
  },
  {
    "text": "cetera so now in order to use this we need to deploy it we need this as an",
    "start": "2671390",
    "end": "2677210"
  },
  {
    "text": "endpoint now this is not an endpoint in our case that we're gonna make available to the public we're not going to attach",
    "start": "2677210",
    "end": "2683720"
  },
  {
    "text": "it to API gateway or anything like that we're just going to use it for our internal purposes in in this pipeline we",
    "start": "2683720",
    "end": "2691940"
  },
  {
    "text": "run our data against that model and we have some interesting results here right",
    "start": "2691940",
    "end": "2698930"
  },
  {
    "start": "2695000",
    "end": "2735000"
  },
  {
    "text": "so this is now we could take our original data and run it against that PCA once we've done that now we can",
    "start": "2698930",
    "end": "2707599"
  },
  {
    "text": "begin to use the art transform data and do some clustering on that data so just",
    "start": "2707599",
    "end": "2714019"
  },
  {
    "text": "to remind ourselves what we're trying to do here is look for similarities and census characteristics between all the",
    "start": "2714019",
    "end": "2719869"
  },
  {
    "text": "various counties in the United States so we've trained our PCA we've run our",
    "start": "2719869",
    "end": "2725569"
  },
  {
    "text": "original data against the PCA now we're creating a model and deploying that",
    "start": "2725569",
    "end": "2730789"
  },
  {
    "text": "model with k-means and now we're going to run a prediction against that model what we see is we specified that we were",
    "start": "2730789",
    "end": "2738980"
  },
  {
    "start": "2735000",
    "end": "2750000"
  },
  {
    "text": "going to look at six particular components and we can see so now we need",
    "start": "2738980",
    "end": "2744410"
  },
  {
    "text": "to visualize some of the differences between these components and here's",
    "start": "2744410",
    "end": "2750650"
  },
  {
    "start": "2750000",
    "end": "2800000"
  },
  {
    "text": "where the reward is sort of at the end when we take a look at the and we extracted this data from our our model",
    "start": "2750650",
    "end": "2758359"
  },
  {
    "text": "using the exact same technique that we did for PCA right we used our MX net",
    "start": "2758359",
    "end": "2763730"
  },
  {
    "text": "tools and now we can examine all of the individual characteristics this",
    "start": "2763730",
    "end": "2768980"
  },
  {
    "text": "information is a little bit hard to glean right now so I'm really happy that",
    "start": "2768980",
    "end": "2774079"
  },
  {
    "text": "I talked to the folks in house here and got a copy of this notebook to share",
    "start": "2774079",
    "end": "2781099"
  },
  {
    "text": "with our partners today because one of the questions that I've come across frequently since Age maker was announced",
    "start": "2781099",
    "end": "2789140"
  },
  {
    "text": "was hey it's great that we created these models I want the coefficients well here's how you get the coefficients they're there right there all right",
    "start": "2789140",
    "end": "2796690"
  },
  {
    "text": "last but not least we can create a heat map out of these coefficients where we",
    "start": "2796690",
    "end": "2801829"
  },
  {
    "start": "2800000",
    "end": "2850000"
  },
  {
    "text": "take the principal components and map them against the class and we can see there's some broad",
    "start": "2801829",
    "end": "2807529"
  },
  {
    "text": "differences here in cluster number three I might want to look at cluster number six as well so down below we take a look inside and",
    "start": "2807529",
    "end": "2816829"
  },
  {
    "text": "what we actually see here well actually here in this particular instance we're looking at cluster number",
    "start": "2816829",
    "end": "2822920"
  },
  {
    "text": "one and we're taking a look at the head of that particular cluster and we can",
    "start": "2822920",
    "end": "2828140"
  },
  {
    "text": "see surprisingly that California New Mexico New York City South Dakota are",
    "start": "2828140",
    "end": "2835489"
  },
  {
    "text": "all in this exact same cluster so these counties have very very common characteristics given by our top",
    "start": "2835489",
    "end": "2842779"
  },
  {
    "text": "principal components so that is are those are the notebooks I wanted to take",
    "start": "2842779",
    "end": "2850339"
  },
  {
    "start": "2850000",
    "end": "2880000"
  },
  {
    "text": "a look at to sort of illustrate the built-in algorithms before we leave and",
    "start": "2850339",
    "end": "2856759"
  },
  {
    "text": "I certainly hope we can see a quest hmm so when to kind of want to have back the",
    "start": "2856759",
    "end": "2865400"
  },
  {
    "text": "cart these systems are my baddest I will stop",
    "start": "2865400",
    "end": "2881839"
  },
  {
    "start": "2880000",
    "end": "2965000"
  },
  {
    "text": "speaking when I hear the question come in what I'd like to do very briefly",
    "start": "2881839",
    "end": "2887299"
  },
  {
    "text": "before we go to our Q&A I wanted to save the last well at ten minutes but I guess",
    "start": "2887299",
    "end": "2893029"
  },
  {
    "text": "eight or seven as the case may be is how do we create this from a spark",
    "start": "2893029",
    "end": "2899479"
  },
  {
    "text": "pipeline now many folks are familiar with spark and the ability to use spark",
    "start": "2899479",
    "end": "2906559"
  },
  {
    "text": "in a pipeline manner there is a notebook that comes with all of our instantiate",
    "start": "2906559",
    "end": "2913309"
  },
  {
    "text": "'add sage maker instances it's called PI spark and nest pca k-means and I love",
    "start": "2913309",
    "end": "2918890"
  },
  {
    "text": "this illustration here at very clearly illustrates that from your internal data in your training data frame you can call",
    "start": "2918890",
    "end": "2926960"
  },
  {
    "text": "a one of the sage maker algorithms PC a sage maker estimator to then go to Sage",
    "start": "2926960",
    "end": "2934940"
  },
  {
    "text": "Maker k-means estimator so you're actually within your spark pipeline here but then calling sage",
    "start": "2934940",
    "end": "2942230"
  },
  {
    "text": "maker built-in algorithms so if you are a spark user this is a really explicit",
    "start": "2942230",
    "end": "2950500"
  },
  {
    "text": "example once again using the emne Stata data set which should be very familiar",
    "start": "2950500",
    "end": "2956500"
  },
  {
    "text": "but it's a great example for integrating sage maker with spark so so that's all I",
    "start": "2956500",
    "end": "2964700"
  },
  {
    "text": "wanted to go through today I did have just one or two more of things here that I wanted to cover very briefly there are",
    "start": "2964700",
    "end": "2974510"
  },
  {
    "start": "2965000",
    "end": "2980000"
  },
  {
    "text": "other clustering methods one in particular is TC and because we are",
    "start": "2974510",
    "end": "2980270"
  },
  {
    "start": "2980000",
    "end": "3070000"
  },
  {
    "text": "working with the the Emnes data set I",
    "start": "2980270",
    "end": "2986570"
  },
  {
    "text": "just want to bring this up very quickly tensorflow has a great projector that",
    "start": "2986570",
    "end": "2993560"
  },
  {
    "text": "has the MMS data set with images built",
    "start": "2993560",
    "end": "2998839"
  },
  {
    "text": "into it and of course it does PCA which is the default here but while we go to",
    "start": "2998839",
    "end": "3004150"
  },
  {
    "text": "Q&A I wanted to turn start a TC clustering of that particular data set",
    "start": "3004150",
    "end": "3011260"
  },
  {
    "text": "and we can now move to questions while we watch that form so I am ready for",
    "start": "3011260",
    "end": "3024190"
  },
  {
    "text": "questions trying to get the GUI up here",
    "start": "3024190",
    "end": "3042130"
  },
  {
    "text": "so I can see questions I would like to",
    "start": "3042130",
    "end": "3048550"
  },
  {
    "text": "remind everybody that questions can be entered in the question tab also on the",
    "start": "3048550",
    "end": "3054640"
  },
  {
    "text": "chat directly or you may raise your hand in order to ask us the questions",
    "start": "3054640",
    "end": "3061210"
  },
  {
    "text": "verbally",
    "start": "3061210",
    "end": "3063690"
  },
  {
    "text": "so while we're waiting for questions to come in and please interrupt me at any time you can see in this one of my",
    "start": "3066350",
    "end": "3072530"
  },
  {
    "start": "3070000",
    "end": "3220000"
  },
  {
    "text": "favorite visualizations here the individual handwritten characters being",
    "start": "3072530",
    "end": "3078410"
  },
  {
    "text": "sorted through the the T Snee algorithm now TC nee was created by Geoffrey",
    "start": "3078410",
    "end": "3086030"
  },
  {
    "text": "Hinton specifically for the clustering of high dimensional data of course ok",
    "start": "3086030",
    "end": "3095810"
  },
  {
    "text": "great so here's one question that came in is that the only notebook which is",
    "start": "3095810",
    "end": "3102110"
  },
  {
    "text": "integratable with the SPARC pipeline so for example can you use Zeppelin so I",
    "start": "3102110",
    "end": "3110300"
  },
  {
    "text": "don't know I don't know the answer to that question in other words I don't know if we enabled that through a",
    "start": "3110300",
    "end": "3116450"
  },
  {
    "text": "QuickStart or something I mean certainly you can integrate Zeppelin with spark",
    "start": "3116450",
    "end": "3121690"
  },
  {
    "text": "but it's certainly not one of the default setups that we have here so um",
    "start": "3121690",
    "end": "3126800"
  },
  {
    "text": "whoever asked that question if you do follow up with me in email I'll see if we maybe have a quick start to do that",
    "start": "3126800",
    "end": "3133070"
  },
  {
    "text": "now of course that may not it may not be as easily to do sage maker integration",
    "start": "3133070",
    "end": "3140420"
  },
  {
    "text": "with that particular configuration and I'll also say I personally have never done I've never used that configuration",
    "start": "3140420",
    "end": "3149230"
  },
  {
    "text": "we're certainly open to other questions you can also color this any data you can",
    "start": "3149410",
    "end": "3156410"
  },
  {
    "text": "upload your own data using the technique that I showed you with our ability to",
    "start": "3156410",
    "end": "3163490"
  },
  {
    "text": "pull components out of our models in sage maker you can upload your road data",
    "start": "3163490",
    "end": "3170930"
  },
  {
    "text": "set and put it into this visualizer and I see that we do have someone with their",
    "start": "3170930",
    "end": "3179510"
  },
  {
    "text": "hand up you can certainly ask questions if you like",
    "start": "3179510",
    "end": "3185860"
  },
  {
    "text": "Pratap maybe you can help me a little bit with this we have a muted Azarcon as",
    "start": "3185860",
    "end": "3192470"
  },
  {
    "text": "our please proceed with your question [Music]",
    "start": "3192470",
    "end": "3199339"
  },
  {
    "text": "as our you are connected to audio now please proceed with your question we may",
    "start": "3204070",
    "end": "3214760"
  },
  {
    "text": "be having a technical difficulty here so certainly type your question if if you do have it so one more thing I would",
    "start": "3214760",
    "end": "3224090"
  },
  {
    "start": "3220000",
    "end": "3250000"
  },
  {
    "text": "like to mention these are not sage maker algorithms built-in algorithms but TCE",
    "start": "3224090",
    "end": "3229670"
  },
  {
    "text": "of course is available through tensorflow and other frameworks also",
    "start": "3229670",
    "end": "3237410"
  },
  {
    "text": "just in scikit-learn I'd like to mention briefly a a model agglomerative",
    "start": "3237410",
    "end": "3243200"
  },
  {
    "text": "clustering glommer ative clustering can be very useful in demographic analysis",
    "start": "3243200",
    "end": "3251120"
  },
  {
    "start": "3250000",
    "end": "3290000"
  },
  {
    "text": "because it is hierarchical so you can see from this dendogram that's given on",
    "start": "3251120",
    "end": "3256400"
  },
  {
    "text": "this particular example here that you may not only be able to have the",
    "start": "3256400",
    "end": "3262550"
  },
  {
    "text": "individual clusters at the ends of these nodes but also as you go into the",
    "start": "3262550",
    "end": "3267740"
  },
  {
    "text": "various heights of the dendogram you may be able to classify for your micro",
    "start": "3267740",
    "end": "3273500"
  },
  {
    "text": "segmentation models using these all these various methods so you know",
    "start": "3273500",
    "end": "3278600"
  },
  {
    "text": "obviously we're focusing on our built-in algorithms on sage maker today but",
    "start": "3278600",
    "end": "3284090"
  },
  {
    "text": "because sage maker is open and we're non-denominational in the way we do",
    "start": "3284090",
    "end": "3290570"
  },
  {
    "text": "almost everything here at AWS you're certainly welcome to import other frameworks and use them in tandem or in",
    "start": "3290570",
    "end": "3297800"
  },
  {
    "text": "combination with sage maker notebooks so we're at the bottom of our our hero may",
    "start": "3297800",
    "end": "3303320"
  },
  {
    "text": "be pause for a few more seconds see if we can get these questions in oh great we got another one okay so here it is",
    "start": "3303320",
    "end": "3309500"
  },
  {
    "text": "can you use our studio with sage maker so you know Sarge moves that there's",
    "start": "3309500",
    "end": "3315170"
  },
  {
    "text": "some great quick starts that will start up our studio on EMR which is of course",
    "start": "3315170",
    "end": "3322700"
  },
  {
    "text": "our spark a dupe service but no you can use our in sage maker they",
    "start": "3322700",
    "end": "3330180"
  },
  {
    "text": "a built-in notebook that loads up our and we have plenty of our examples but our studio itself no all right so we're",
    "start": "3330180",
    "end": "3339630"
  },
  {
    "text": "at the end of it our our our here I hope that that was enlightening and no matter where you're coming from on your journey",
    "start": "3339630",
    "end": "3346530"
  },
  {
    "text": "into machine learning I hope you found some strong value if I prompted other questions or if there were if you",
    "start": "3346530",
    "end": "3353970"
  },
  {
    "text": "weren't able to get in through our interface here I hope you will please",
    "start": "3353970",
    "end": "3360000"
  },
  {
    "text": "reach out to me at my email address I'm a partner solutions architects so I am",
    "start": "3360000",
    "end": "3365700"
  },
  {
    "text": "here to help you guys out and someone just got one last question in here where",
    "start": "3365700",
    "end": "3371550"
  },
  {
    "text": "do we get the notebook for the census data just send me an email my email address is right there so I'm more than",
    "start": "3371550",
    "end": "3377640"
  },
  {
    "text": "happy to provide the URL for that blog in the chat window so you put Oh",
    "start": "3377640",
    "end": "3384750"
  },
  {
    "text": "fantastic I believe the question came from a Samantha so command you can just",
    "start": "3384750",
    "end": "3389970"
  },
  {
    "text": "look in the in the chat window and and click we have the azure is asking the",
    "start": "3389970",
    "end": "3396060"
  },
  {
    "text": "question now come on the customizable is sage maker through the SDK and why there",
    "start": "3396060",
    "end": "3402510"
  },
  {
    "text": "are two different variants of the API ie through AWS SDK and separate such maker",
    "start": "3402510",
    "end": "3408990"
  },
  {
    "text": "API okay so as far as customization goes it's highly customizable we're gonna go",
    "start": "3408990",
    "end": "3417450"
  },
  {
    "text": "through our built-in algorithms first it is important to note if you are a n is V",
    "start": "3417450",
    "end": "3425640"
  },
  {
    "text": "if you're in business selling software especially software is a service you can start a Jupiter a sage maker Jupiter",
    "start": "3425640",
    "end": "3433350"
  },
  {
    "text": "notebook directly from your product you can launch it right from your product",
    "start": "3433350",
    "end": "3439020"
  },
  {
    "text": "and do integrations with your data directly from the product so eager to talk to you about that as for the",
    "start": "3439020",
    "end": "3446580"
  },
  {
    "text": "different methods of access of course we have the various language SDKs we have",
    "start": "3446580",
    "end": "3452610"
  },
  {
    "text": "the bash interface we have the GUI interface and the reason we have these is because workflows are different in",
    "start": "3452610",
    "end": "3458550"
  },
  {
    "text": "different environments many of the features are identical across",
    "start": "3458550",
    "end": "3464010"
  },
  {
    "text": "different api's so they're just designed this way to enable a workflow that's",
    "start": "3464010",
    "end": "3470490"
  },
  {
    "text": "best for your environment all right all",
    "start": "3470490",
    "end": "3480480"
  },
  {
    "text": "right I would like to thank everybody for the participation today we will soon be in contact with you to organize the",
    "start": "3480480",
    "end": "3487050"
  },
  {
    "text": "third stage my craft deep dive we hope that you have enjoyed the presentation",
    "start": "3487050",
    "end": "3492390"
  },
  {
    "text": "and we look forward to speaking with you soon thank you very much",
    "start": "3492390",
    "end": "3497869"
  }
]
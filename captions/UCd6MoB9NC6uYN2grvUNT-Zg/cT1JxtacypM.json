[
  {
    "start": "0",
    "end": "94000"
  },
  {
    "text": "all right I think we're gonna go ahead and get started here so appreciate",
    "start": "0",
    "end": "5580"
  },
  {
    "text": "everybody attending the last session of the day hopefully great I know I'm standing between you and and dinner",
    "start": "5580",
    "end": "11910"
  },
  {
    "text": "plans and everything but we're gonna be talking about Kinesis and streaming",
    "start": "11910",
    "end": "19050"
  },
  {
    "text": "analytics on AWS so what to expect from this session we're first gonna be",
    "start": "19050",
    "end": "25529"
  },
  {
    "text": "talking about streaming analytics and really what streaming analytics means you know when you talk to people about",
    "start": "25529",
    "end": "31260"
  },
  {
    "text": "streaming there's video streaming which is something different and then streaming analytics and and really what",
    "start": "31260",
    "end": "36630"
  },
  {
    "text": "we're talking about here is a velocity of events going into your system so that",
    "start": "36630",
    "end": "42360"
  },
  {
    "text": "could be a ot sensors for GPS for buses in the city it could be heart rate",
    "start": "42360",
    "end": "48420"
  },
  {
    "text": "monitors for people out collecting from IOT devices you know lots and lots of",
    "start": "48420",
    "end": "54480"
  },
  {
    "text": "things generating real-time data and needing to ingest that data and either",
    "start": "54480",
    "end": "59789"
  },
  {
    "text": "store it into adorable store or run analytics on that data curiosity how",
    "start": "59789",
    "end": "66030"
  },
  {
    "text": "many folks in the room are running streaming analytics today okay a handful",
    "start": "66030",
    "end": "72540"
  },
  {
    "text": "of folks so no that sounds good so we're gonna really dive into a Kinesis we'll",
    "start": "72540",
    "end": "79350"
  },
  {
    "text": "go through the three services that really Kinesis is made up of but then we're gonna die very very deep into",
    "start": "79350",
    "end": "85290"
  },
  {
    "text": "Kinesis firehose and why folks use firehose why we built five heroes based",
    "start": "85290",
    "end": "90299"
  },
  {
    "text": "on all the user user and customer feedback so the three services that",
    "start": "90299",
    "end": "96540"
  },
  {
    "text": "really make up the Kinesis service is the first thing is Kinesis streams and",
    "start": "96540",
    "end": "102960"
  },
  {
    "text": "the reason why folks use Kinesis streams is when they really need the full flexibility to be able to process",
    "start": "102960",
    "end": "110490"
  },
  {
    "text": "analyze and really run their algorithms",
    "start": "110490",
    "end": "115950"
  },
  {
    "text": "on a streaming set of events you're able to do things like use open source technologies and we'll talk about some",
    "start": "115950",
    "end": "122280"
  },
  {
    "text": "of those such as Stormin and spark streaming but we also have some services that make it very very easy for you to",
    "start": "122280",
    "end": "128789"
  },
  {
    "text": "run your own client libraries on top of that Kinesis client library is one of those",
    "start": "128789",
    "end": "134090"
  },
  {
    "text": "but it really gives the engineers and the developers the full flexibility to",
    "start": "134090",
    "end": "139710"
  },
  {
    "text": "really do any type of processing on the consumer end of that stream based on",
    "start": "139710",
    "end": "146160"
  },
  {
    "text": "that customer feedback that got released in the 2013 timeframe based on that customer feedback we actually released",
    "start": "146160",
    "end": "152460"
  },
  {
    "text": "Kinesis firehose Kinesis firehose is really set to address the use case where",
    "start": "152460",
    "end": "159480"
  },
  {
    "text": "you have that streaming of events coming into your system and you need to durably",
    "start": "159480",
    "end": "165390"
  },
  {
    "text": "store that into a repository like s3 redshift or elasticsearch and we'll dive",
    "start": "165390",
    "end": "171270"
  },
  {
    "text": "into a lot more of the details there but that was a very very common pattern I have all this telemetry data I need to",
    "start": "171270",
    "end": "178740"
  },
  {
    "text": "store it and later on do some deep analysis on it using things like spark R and EMR and and those sorts of tools",
    "start": "178740",
    "end": "185160"
  },
  {
    "text": "that you've been hearing about today the last service this service is currently",
    "start": "185160",
    "end": "190440"
  },
  {
    "text": "in preview mode but it's a very very exciting service that makes up that portfolio of that you know Kinesis falls",
    "start": "190440",
    "end": "197280"
  },
  {
    "text": "under is Kinesis analytics the really powerful thing about Kinesis analytics",
    "start": "197280",
    "end": "202770"
  },
  {
    "text": "we're the first to really dealt with collecting and storing the streaming",
    "start": "202770",
    "end": "209220"
  },
  {
    "text": "events Kinesis analytics is really a self-contained service to be able to",
    "start": "209220",
    "end": "215130"
  },
  {
    "text": "process the streaming events one of the really powerful aspects of kenosis",
    "start": "215130",
    "end": "221280"
  },
  {
    "text": "analytics is its sequel based so when you have finished business analysts and you have folks that know sequel it's",
    "start": "221280",
    "end": "228660"
  },
  {
    "text": "very very easy to start analyzing your stream of events and we'll talk about how some of that works but the majority",
    "start": "228660",
    "end": "236970"
  },
  {
    "text": "of the time is gonna be focused on Kinesis firehose that that was really a service that we released because it was",
    "start": "236970",
    "end": "243209"
  },
  {
    "text": "a very very common use case that we saw across our customers and based on that feedback you know as I mentioned the",
    "start": "243209",
    "end": "251340"
  },
  {
    "text": "Kinesis analytics is in preview you can login request preview access but you",
    "start": "251340",
    "end": "257609"
  },
  {
    "text": "know kind of look for that in the future so a common use case that we see when it",
    "start": "257609",
    "end": "265560"
  },
  {
    "start": "262000",
    "end": "373000"
  },
  {
    "text": "comes to streaming analytics is the first is that they have the streaming need or they have all this",
    "start": "265560",
    "end": "271620"
  },
  {
    "text": "data getting generated could be one spot or it could be you know geographically",
    "start": "271620",
    "end": "276889"
  },
  {
    "text": "distributed across a region or a set of locations but the first use case that we",
    "start": "276889",
    "end": "283290"
  },
  {
    "text": "see most customers take even you know in IOT and gaming and public sector is",
    "start": "283290",
    "end": "288870"
  },
  {
    "text": "really being able to collect transform that transformation might be a simple",
    "start": "288870",
    "end": "294720"
  },
  {
    "text": "transformation or our complex transformation and really load that data and that's really one of the niche",
    "start": "294720",
    "end": "301280"
  },
  {
    "text": "positions why folks use Kinesis firehose is it really does that very very very",
    "start": "301280",
    "end": "306510"
  },
  {
    "text": "well once you're doing that the next step is to really start running",
    "start": "306510",
    "end": "312060"
  },
  {
    "text": "analytics on that data set you know there's the deep analysis using things like EMR and spark and and those sorts",
    "start": "312060",
    "end": "320160"
  },
  {
    "text": "of tools but also being able to perform real-time metrics on that on that stream",
    "start": "320160",
    "end": "327000"
  },
  {
    "text": "of metric stream of events after you do that you're able to start getting a",
    "start": "327000",
    "end": "333030"
  },
  {
    "text": "real-time view of that and the next stage is really folks end up taking that real-time information and embedding it",
    "start": "333030",
    "end": "339990"
  },
  {
    "text": "into their business dashboards and this is where where you really start making a",
    "start": "339990",
    "end": "345030"
  },
  {
    "text": "lot of real-time business impact for your customers and for your mission being able to in real time and we'll",
    "start": "345030",
    "end": "352050"
  },
  {
    "text": "talk about what real-time means but in real-time being able to collect information about telemetry information",
    "start": "352050",
    "end": "358500"
  },
  {
    "text": "or users or whatever that streaming data is and be able to really react and and",
    "start": "358500",
    "end": "363539"
  },
  {
    "text": "change your behavior based on that and that's really you know the third step that we see customers go through so you",
    "start": "363539",
    "end": "375449"
  },
  {
    "start": "373000",
    "end": "489000"
  },
  {
    "text": "know we're still talking about the three broad services that make up Kinesis the Kinesis streams firehose and analytics",
    "start": "375449",
    "end": "381479"
  },
  {
    "text": "and they all really fall into these key characteristics the first you know like",
    "start": "381479",
    "end": "387060"
  },
  {
    "text": "all the AWS services is it's very easy as a customer to be able to provision",
    "start": "387060",
    "end": "392910"
  },
  {
    "text": "and scale the the streaming analytics within their environments of course I am",
    "start": "392910",
    "end": "400650"
  },
  {
    "text": "protect so that so you know the customer has the full flexibility to control who has that functionality or that access and you",
    "start": "400650",
    "end": "407940"
  },
  {
    "text": "know audit all that behavior in cloud trail but it really empowers the user to be able to do that on their own and",
    "start": "407940",
    "end": "414259"
  },
  {
    "text": "really elastically grow that based on their demand not only that but being",
    "start": "414259",
    "end": "419460"
  },
  {
    "text": "able to do that at scale and making it highly available and we'll talk about how Kim uses streams in Kinesis firehose",
    "start": "419460",
    "end": "426630"
  },
  {
    "text": "really lets you focus on the streaming analytic rather than doing things like",
    "start": "426630",
    "end": "432120"
  },
  {
    "text": "how am I gonna manage leader the leader election algorithms and how am I going to stand up a coronation service you",
    "start": "432120",
    "end": "440639"
  },
  {
    "text": "know for example you zookeepers and coordination service all of that is handled as a service for you and you're",
    "start": "440639",
    "end": "446940"
  },
  {
    "text": "really able to focus on you know what matters of processing that streaming events and and extracting that business",
    "start": "446940",
    "end": "453570"
  },
  {
    "text": "value out real-time real time is a key for Kinesis streams so oftentimes when",
    "start": "453570",
    "end": "459330"
  },
  {
    "text": "we're working with Kinesis streams and our customers we're talking about a second to second type latency from the",
    "start": "459330",
    "end": "465780"
  },
  {
    "text": "time that it gets published and processes and of course pay-as-you-go",
    "start": "465780",
    "end": "471510"
  },
  {
    "text": "model so it's very easy to start small start with a single shard and we'll talk",
    "start": "471510",
    "end": "476909"
  },
  {
    "text": "about what that means within a stream and then be able to grow that really based on however much you grow and",
    "start": "476909",
    "end": "483960"
  },
  {
    "text": "shrink your your demand for so so within",
    "start": "483960",
    "end": "491909"
  },
  {
    "start": "489000",
    "end": "636000"
  },
  {
    "text": "Kinesis streams the first part about konista streams is it's very very easy to administer or you know the the way",
    "start": "491909",
    "end": "500159"
  },
  {
    "text": "you setup can use the streams is you really just create a stream name and that stream name is used by the",
    "start": "500159",
    "end": "506909"
  },
  {
    "text": "producers and consumers as a customer or through scripting and through different",
    "start": "506909",
    "end": "513000"
  },
  {
    "text": "programmatic interfaces at runtime you could dynamically change the shards that",
    "start": "513000",
    "end": "518909"
  },
  {
    "text": "define the stream and the shards are actually the mechanism to grow and",
    "start": "518909",
    "end": "524880"
  },
  {
    "text": "shrink the capacity that that stream could handle one shark had had a one Meg",
    "start": "524880",
    "end": "530730"
  },
  {
    "text": "input and two Meg output and we'll dive a little bit more deeper into that sharp is highly available it's",
    "start": "530730",
    "end": "536420"
  },
  {
    "text": "replicated across multiple availability zones and we'll show some diagrams about that but that's your capacity management",
    "start": "536420",
    "end": "543460"
  },
  {
    "text": "mechanism to be able to control that elasticity of how much traffic that that",
    "start": "543460",
    "end": "550420"
  },
  {
    "text": "one sits on that stream really really great set of tools to be able to analyze",
    "start": "550420",
    "end": "556580"
  },
  {
    "text": "that data spark streaming is a is a great one spark streaming uses a micro",
    "start": "556580",
    "end": "562100"
  },
  {
    "text": "batch methodology running either on the Hadoop you know most a lot of folks end",
    "start": "562100",
    "end": "568730"
  },
  {
    "text": "up running that on EMR or you could use Apache storm battery storm is a",
    "start": "568730",
    "end": "574540"
  },
  {
    "text": "real-time processing engine made up of essentially a topology to process data",
    "start": "574540",
    "end": "580670"
  },
  {
    "text": "as is coming off of the stream and then really the other option is for folks to",
    "start": "580670",
    "end": "589190"
  },
  {
    "text": "be able to leverage the KCl the KCl is the Kinesis client library and what that",
    "start": "589190",
    "end": "594860"
  },
  {
    "text": "does is it's another mechanism for you to focus on your your processing logic",
    "start": "594860",
    "end": "601390"
  },
  {
    "text": "rather than the logic to actually read the data off of the shards so the KCl",
    "start": "601390",
    "end": "607160"
  },
  {
    "text": "it's open source project on github that you could download and look at the source and run yourself but when you're",
    "start": "607160",
    "end": "614150"
  },
  {
    "text": "running that what happens is the KCl automatically handles entering all the records across the different shards even",
    "start": "614150",
    "end": "621050"
  },
  {
    "text": "if this number of shards changes over time you know because your capacity requirements might change and all that",
    "start": "621050",
    "end": "626210"
  },
  {
    "text": "is abstracted away from you so you could focus on the processing and not how to read the records",
    "start": "626210",
    "end": "633910"
  },
  {
    "start": "636000",
    "end": "739000"
  },
  {
    "text": "but really with this uh you know why this is really taken off is is being",
    "start": "637399",
    "end": "644339"
  },
  {
    "text": "able to have full flexibility to be able to use these different consumers and producers you can use very very low",
    "start": "644339",
    "end": "651480"
  },
  {
    "text": "level AWS decays to be able to produce and consume the data just like we have a",
    "start": "651480",
    "end": "658110"
  },
  {
    "text": "KCl for consuming data there's a kpl Kinesis producer library to be able to",
    "start": "658110",
    "end": "664259"
  },
  {
    "text": "easily produce data on top of the Kinesis stream but you also have a lot of open source projects that have really",
    "start": "664259",
    "end": "671309"
  },
  {
    "text": "nicely integrated with Kinesis streams a lot of folks that are using you know",
    "start": "671309",
    "end": "676589"
  },
  {
    "text": "log4j flume influent d for example those are pretty well-established open source",
    "start": "676589",
    "end": "682170"
  },
  {
    "text": "projects to be able to stream data from consumers and Kinesis is able to become",
    "start": "682170",
    "end": "688290"
  },
  {
    "text": "a destination for that so you could use those at your application and it could stream directly into the Kinesis stream",
    "start": "688290",
    "end": "695809"
  },
  {
    "text": "on the consumer side again you could use the api natively you could use the",
    "start": "695809",
    "end": "704040"
  },
  {
    "text": "client library we also have a set of other libraries on github ones a",
    "start": "704040",
    "end": "710160"
  },
  {
    "text": "connector library that allows you to very easily do ETL processes to be able to take data off of the stream and load",
    "start": "710160",
    "end": "717209"
  },
  {
    "text": "it into other repositories as well as some aggregators to be able to do very",
    "start": "717209",
    "end": "723120"
  },
  {
    "text": "very custom aggregations of data and all that data are all those libraries are on github open source for you to use of",
    "start": "723120",
    "end": "731249"
  },
  {
    "text": "course that elastic MapReduce apache storm and apache spark are used quite a",
    "start": "731249",
    "end": "736259"
  },
  {
    "text": "bit when a producer produces a message",
    "start": "736259",
    "end": "742980"
  },
  {
    "text": "and puts it within with on the Kinesis stream what happens under the covers is",
    "start": "742980",
    "end": "748769"
  },
  {
    "text": "of course you know authentication and authorization happens first using you know a common denominator of I am to",
    "start": "748769",
    "end": "755639"
  },
  {
    "text": "make sure that you know that producers will allow to produce that message but",
    "start": "755639",
    "end": "760740"
  },
  {
    "text": "once that happens that message is actually replicated across three availability zones and that's done for",
    "start": "760740",
    "end": "767699"
  },
  {
    "text": "durability for high availability you know just probably everyone in the rooms familiar with availability zone",
    "start": "767699",
    "end": "774100"
  },
  {
    "text": "but availability something within the region is really a separate set of data",
    "start": "774100",
    "end": "779560"
  },
  {
    "text": "centers that make up a single AZ that's isolated from the other AZ's for fault",
    "start": "779560",
    "end": "784930"
  },
  {
    "text": "tolerance reasons so when that message gets published it's within that larger",
    "start": "784930",
    "end": "790480"
  },
  {
    "text": "region for example in North Virginia it's automatically replicated across those different three AZ's when that",
    "start": "790480",
    "end": "798550"
  },
  {
    "text": "message gets published what happens is that becomes a time ordered series of events that are put on the shard",
    "start": "798550",
    "end": "805330"
  },
  {
    "text": "so as producers are reading off the data off of the shard within the shard it's",
    "start": "805330",
    "end": "810400"
  },
  {
    "text": "actually a time ordered series of events and what you could have is you could have a very large number of consumers",
    "start": "810400",
    "end": "818280"
  },
  {
    "text": "consuming that message those sets of messages for different purposes so one",
    "start": "818280",
    "end": "824320"
  },
  {
    "text": "set of consumers could be popularly in a real-time dashboard while another one",
    "start": "824320",
    "end": "830290"
  },
  {
    "text": "the set of consumers might be doing a scan over seven days worth of streaming",
    "start": "830290",
    "end": "835360"
  },
  {
    "text": "data to be able to provide some other analytical results you know once a day or something like that so very very",
    "start": "835360",
    "end": "841780"
  },
  {
    "text": "decoupled from the producers and consumers sense real-time in nature one second two second lane sees and really",
    "start": "841780",
    "end": "848920"
  },
  {
    "text": "being able to have full flexibility of different sets of consumers to be able to process and analyze your streaming",
    "start": "848920",
    "end": "855190"
  },
  {
    "text": "data apologize for looking back this screen isn't uh isn't on down here so so",
    "start": "855190",
    "end": "864150"
  },
  {
    "start": "863000",
    "end": "1030000"
  },
  {
    "text": "Kinesis streams very very powerful but you know like we were talking about a",
    "start": "864150",
    "end": "869530"
  },
  {
    "text": "couple minutes ago a very very common use case was to have all this event data getting published and why and do things",
    "start": "869530",
    "end": "876160"
  },
  {
    "text": "like storing all that data in s3 storing all that data into red ship to be able to run tableau you know quick cite you",
    "start": "876160",
    "end": "884590"
  },
  {
    "text": "know those sorts of tools on top of so you know what we did is you know like many of our services are really all of",
    "start": "884590",
    "end": "890620"
  },
  {
    "text": "our services we listen to our customers and release the new service that is",
    "start": "890620",
    "end": "897040"
  },
  {
    "text": "going to be coming on a couple slides but related saat we also released a few",
    "start": "897040",
    "end": "903340"
  },
  {
    "text": "new features really this past year for Kinesis streams the first was to really",
    "start": "903340",
    "end": "909010"
  },
  {
    "text": "be able to optimize the publishing of events on top of Kinesis what we",
    "start": "909010",
    "end": "915190"
  },
  {
    "text": "released was being able to do batch loading of records so rather than doing one call per record you could actually",
    "start": "915190",
    "end": "920920"
  },
  {
    "text": "load you know n number of records and publish those on top of the Kinesis streams those could have different",
    "start": "920920",
    "end": "927010"
  },
  {
    "text": "partition IDs which fan out to different shards also increase things like the max",
    "start": "927010",
    "end": "933250"
  },
  {
    "text": "size of the messages and and other optimizations to really improve the producing side of the kinesin stream the",
    "start": "933250",
    "end": "942700"
  },
  {
    "text": "other thing we did is really expand the number of or the different types of languages that the KCl supported",
    "start": "942700",
    "end": "950040"
  },
  {
    "text": "originally it was done in one language and now we also support Python nodejs from ruby and also released the kpl many",
    "start": "950040",
    "end": "958300"
  },
  {
    "text": "many folks like the kco and we we got some feedback saying you know I really wanted to to ease the development let me",
    "start": "958300",
    "end": "965620"
  },
  {
    "text": "focus on on generating the messages and help me produce them easier so that KP",
    "start": "965620",
    "end": "970690"
  },
  {
    "text": "all got released pretty recent we also released server-side timestamps to be",
    "start": "970690",
    "end": "978520"
  },
  {
    "text": "able to have that on the metadata of each of each event that gets published",
    "start": "978520",
    "end": "983710"
  },
  {
    "text": "as well so that becomes part of the metadata and you know so when you're reading the shard you you know what the",
    "start": "983710",
    "end": "988960"
  },
  {
    "text": "shard idea is you know what the sequence number ideas you also get a timestamp",
    "start": "988960",
    "end": "995610"
  },
  {
    "text": "last but not least really great enhancement is being able to extend how",
    "start": "997620",
    "end": "1003780"
  },
  {
    "text": "much data is is really saved on your stream up to seven days and what this means is prior to this release you know",
    "start": "1003780",
    "end": "1012630"
  },
  {
    "text": "as data was getting read off of the stream consumers were able to read the last 24 hours of data now you could",
    "start": "1012630",
    "end": "1019860"
  },
  {
    "text": "actually expand that up to seven days worth of data and be able to you know back play and reprocess all that data",
    "start": "1019860",
    "end": "1029240"
  },
  {
    "start": "1030000",
    "end": "1258000"
  },
  {
    "text": "the other thing that we recently released this got released last vent OS",
    "start": "1031199",
    "end": "1036970"
  },
  {
    "text": "Kinesis fire hose can uses fire hose is really focused on that use case of",
    "start": "1036970",
    "end": "1042699"
  },
  {
    "text": "having that streaming events and being able to persist them and do back end",
    "start": "1042699",
    "end": "1050049"
  },
  {
    "text": "processing later on on that data within within the Kinesis fire hose",
    "start": "1050049",
    "end": "1056320"
  },
  {
    "text": "instead of doing things like setting up a shard for capacity so with Kinesis streams what you did is since it you had",
    "start": "1056320",
    "end": "1063580"
  },
  {
    "text": "the total flexibility of producers and consumers you define the number of shards and that drove how much capacity",
    "start": "1063580",
    "end": "1070000"
  },
  {
    "text": "one stream could handle with Kinesis fire hose it's completely automated you're you're still using the same sort",
    "start": "1070000",
    "end": "1076690"
  },
  {
    "text": "of producers but when it comes to managing the Kinesis fire hose all you",
    "start": "1076690",
    "end": "1082539"
  },
  {
    "text": "do is you really specify that destination I want to write this to s3 or redshift or elasticsearch and the",
    "start": "1082539",
    "end": "1090760"
  },
  {
    "text": "rest is handed for you you could produce as much data as you want on that Kinesis fire hose or you could produce this as",
    "start": "1090760",
    "end": "1097149"
  },
  {
    "text": "little and it will automatically scale and shrink based on how much it needs to",
    "start": "1097149",
    "end": "1102490"
  },
  {
    "text": "based on that load so it's really completely managed at at a higher level",
    "start": "1102490",
    "end": "1107529"
  },
  {
    "text": "above the shards and you don't have to worry about anything when it comes to",
    "start": "1107529",
    "end": "1113320"
  },
  {
    "text": "getting the data from the consumers point of view there's no consumers with",
    "start": "1113320",
    "end": "1119140"
  },
  {
    "text": "Kinesis fire hose because the surface is really configured based on your settings",
    "start": "1119140",
    "end": "1124360"
  },
  {
    "text": "so you configure the consumer for example and we'll step through some of the slides but for example you could",
    "start": "1124360",
    "end": "1130090"
  },
  {
    "text": "configure it to write toward the s3 bucket and it will automatically have the code that knows how to do that you",
    "start": "1130090",
    "end": "1135100"
  },
  {
    "text": "configure it to write to redshift and it knows how to do that the other thing",
    "start": "1135100",
    "end": "1142299"
  },
  {
    "text": "that it allows you to do is and really one of the key benefits here is Kinesis",
    "start": "1142299",
    "end": "1147520"
  },
  {
    "text": "fire hose batches all the data together s3 lights larger files you know be able",
    "start": "1147520",
    "end": "1154299"
  },
  {
    "text": "to do things like run MapReduce on it to run spark on it the way the partitions work that is the splits work when it's",
    "start": "1154299",
    "end": "1161440"
  },
  {
    "text": "reading data you larger files are better for streaming data when you're doing that back-end",
    "start": "1161440",
    "end": "1166950"
  },
  {
    "text": "deeper analysis so what it does is it batches the data for you based on your",
    "start": "1166950",
    "end": "1172139"
  },
  {
    "text": "heuristic so you say I want the file to be this large and it will follow that definition and store the data for you",
    "start": "1172139",
    "end": "1179480"
  },
  {
    "text": "you could also define a time window so you in addition to the size criteria you",
    "start": "1179480",
    "end": "1185309"
  },
  {
    "text": "could specify it as little as 60 seconds and it'll take all the events that",
    "start": "1185309",
    "end": "1190379"
  },
  {
    "text": "happen within that time window even if it didn't reach that size limitation and write that out so those are the two",
    "start": "1190379",
    "end": "1196860"
  },
  {
    "text": "variables that really define the amount that gets batched the other thing that",
    "start": "1196860",
    "end": "1202649"
  },
  {
    "text": "happens is you're able to optionally do things like encrypt your data with KMS keys so the key management service so",
    "start": "1202649",
    "end": "1210450"
  },
  {
    "text": "when it's writing the data out to s3 you can specify what keys you want to perform if you want encryption turned on",
    "start": "1210450",
    "end": "1217100"
  },
  {
    "text": "you can also specify things like compression and what compression algorithm you want to use to compress",
    "start": "1217100",
    "end": "1223259"
  },
  {
    "text": "the data and you know one of the reasons",
    "start": "1223259",
    "end": "1233669"
  },
  {
    "text": "why this this has really taken off is you know it is a common use case but when it comes to managing the scale and",
    "start": "1233669",
    "end": "1240720"
  },
  {
    "text": "elasticity it's very very hands-off you really all you need to do is define the",
    "start": "1240720",
    "end": "1246690"
  },
  {
    "text": "delivery mechanism and start producing to it and the service of stuff will handle the writing the data out to that",
    "start": "1246690",
    "end": "1253559"
  },
  {
    "text": "delivery channel that delivery stream so",
    "start": "1253559",
    "end": "1259799"
  },
  {
    "start": "1258000",
    "end": "1383000"
  },
  {
    "text": "so this is depicting you know the updated version of what",
    "start": "1259799",
    "end": "1264990"
  },
  {
    "text": "Kinesis firehose looks like Kinesis streams they'll use quite a bit but when you do need to do that batching and",
    "start": "1264990",
    "end": "1273350"
  },
  {
    "text": "offline or batch processing of the data the the consider the producers that you",
    "start": "1273350",
    "end": "1280590"
  },
  {
    "text": "use are the same exact sort of producers so you could use you know Kinesis producer library you use the SDKs you",
    "start": "1280590",
    "end": "1288240"
  },
  {
    "text": "could use you know the fluent D all the other producers that you saw on the",
    "start": "1288240",
    "end": "1293460"
  },
  {
    "text": "previous side are the same sort of producers you could use with Kinesis firehose because from that point",
    "start": "1293460",
    "end": "1299920"
  },
  {
    "text": "of view that all the producers are doing is producing data it's producing streaming data it doesn't it's not aware",
    "start": "1299920",
    "end": "1306460"
  },
  {
    "text": "of how you want to process the data on the consumer side there are no consumers",
    "start": "1306460",
    "end": "1311530"
  },
  {
    "text": "from the customers perspective and what I mean by that is all you do is you configure that definition s3 redshifts",
    "start": "1311530",
    "end": "1319740"
  },
  {
    "text": "yeah or elasticsearch and you can do combinations of these so you know for",
    "start": "1319740",
    "end": "1326110"
  },
  {
    "text": "example when writes out to redshift it's actually right now to s3 first the very",
    "start": "1326110",
    "end": "1336010"
  },
  {
    "text": "very common use cases using IOT so with in IOT there's a feature called IOT",
    "start": "1336010",
    "end": "1343060"
  },
  {
    "text": "rules and what that allows you to do is each message that comes in from all the sensors that you may have all the",
    "start": "1343060",
    "end": "1350260"
  },
  {
    "text": "controls modules that you may have and within your IOT you could define an IOT",
    "start": "1350260",
    "end": "1356260"
  },
  {
    "text": "rule and one of the actions that that IOT rule could take is to actually",
    "start": "1356260",
    "end": "1361300"
  },
  {
    "text": "publish on to a Kinesis stream or Kinesis firehose so very very easy to",
    "start": "1361300",
    "end": "1366330"
  },
  {
    "text": "use our IT service to have sensors out",
    "start": "1366330",
    "end": "1371710"
  },
  {
    "text": "in the wild essentially producing messages and then have that all stored",
    "start": "1371710",
    "end": "1377230"
  },
  {
    "text": "within your s3 buckets and bi tools so",
    "start": "1377230",
    "end": "1385720"
  },
  {
    "start": "1383000",
    "end": "1409000"
  },
  {
    "text": "you know why this is important that first use case that folks usually get started when it comes to streaming data",
    "start": "1385720",
    "end": "1391660"
  },
  {
    "text": "is collecting all that data and being able to process it you know using these",
    "start": "1391660",
    "end": "1396910"
  },
  {
    "text": "you know well well-established tools and fire hose mix makes that very very easy so you could stand it up and get started",
    "start": "1396910",
    "end": "1403920"
  },
  {
    "text": "you know very quickly with kinesins fire hose so we're defining Kinesis fire hose",
    "start": "1403920",
    "end": "1414070"
  },
  {
    "start": "1409000",
    "end": "1515000"
  },
  {
    "text": "what happens is instead of a stream you define a delivery stream so what you",
    "start": "1414070",
    "end": "1423010"
  },
  {
    "text": "don't have to do is you know like we're talking about is to find the shards you don't have to specify a partition key so",
    "start": "1423010",
    "end": "1430060"
  },
  {
    "text": "the way that strange works is when the Purdue producer is generating the data it",
    "start": "1430060",
    "end": "1435279"
  },
  {
    "text": "generates a petition ID and that Perdition ID is used to fan the",
    "start": "1435279",
    "end": "1440980"
  },
  {
    "text": "trafficker across the various shards on that stream with Kinesis fire hose you",
    "start": "1440980",
    "end": "1446139"
  },
  {
    "text": "don't have to specify any of that that fan out all happens under the covers for you the records are the same sort of",
    "start": "1446139",
    "end": "1456999"
  },
  {
    "text": "format and syntax as kinesin streams there really any any blob up to up to a",
    "start": "1456999",
    "end": "1464379"
  },
  {
    "text": "megabyte it could be handled on the Kinesis stream or the Kinesis firehose and what",
    "start": "1464379",
    "end": "1470860"
  },
  {
    "text": "happens is that data ends up being used in order to be put in as a row with an",
    "start": "1470860",
    "end": "1477070"
  },
  {
    "text": "s3 so if it's jet you know for example if you're generating temperature sensors",
    "start": "1477070",
    "end": "1482369"
  },
  {
    "text": "each each message might be you know what the sensor was and what the temperature is and that becomes various rows that",
    "start": "1482369",
    "end": "1490090"
  },
  {
    "text": "all get appended together in one batch load into s3 or redshift and the data",
    "start": "1490090",
    "end": "1499210"
  },
  {
    "text": "producer all this data producer really needs to do is know how to write out",
    "start": "1499210",
    "end": "1504309"
  },
  {
    "text": "using one of those open source tools or using one of our API calls which is very",
    "start": "1504309",
    "end": "1509860"
  },
  {
    "text": "very easy to get started lots of great examples on github so next few slides",
    "start": "1509860",
    "end": "1517360"
  },
  {
    "text": "what we're gonna do is we're gonna step through how some of this is set up within Kinesis firehose to really show",
    "start": "1517360",
    "end": "1523749"
  },
  {
    "text": "how simple it is to stand up this delivery stream and be able to start",
    "start": "1523749",
    "end": "1529299"
  },
  {
    "text": "having this very very elastic highly available delivery stream to be able to save all your streaming data so when you",
    "start": "1529299",
    "end": "1539379"
  },
  {
    "text": "get to the landing page right now what you'll see is Kinesis streams and firehose because can you set analytics",
    "start": "1539379",
    "end": "1545350"
  },
  {
    "text": "in preview mode but when you go in there and you select Kinesis firehose what",
    "start": "1545350",
    "end": "1552610"
  },
  {
    "start": "1551000",
    "end": "1600000"
  },
  {
    "text": "happens is you you're able to configure the destination so you give it a",
    "start": "1552610",
    "end": "1558279"
  },
  {
    "text": "destination name such as in this a destination type in this example we're",
    "start": "1558279",
    "end": "1563350"
  },
  {
    "text": "showing s3 next examples will show redshift and ElastiCache but you're able to do things",
    "start": "1563350",
    "end": "1570419"
  },
  {
    "text": "like give it the s3 bucket and the other important thing that you're able to",
    "start": "1570419",
    "end": "1575549"
  },
  {
    "text": "specify is a prefix that way you know if you want all the files that get bashed",
    "start": "1575549",
    "end": "1581730"
  },
  {
    "text": "and saved an s3 to have a prefix which you know simulates a directory structure",
    "start": "1581730",
    "end": "1586919"
  },
  {
    "text": "with an s3 you could set that up in order for for your different data to be",
    "start": "1586919",
    "end": "1592440"
  },
  {
    "text": "able to be stored in one bucket but all be grouped together based on different delivery streams the the next slide goes",
    "start": "1592440",
    "end": "1600480"
  },
  {
    "start": "1600000",
    "end": "1662000"
  },
  {
    "text": "into some of that optional configuration that we're talking about you know the",
    "start": "1600480",
    "end": "1606350"
  },
  {
    "text": "the middle section is actually the compression algorithm the encryption",
    "start": "1606350",
    "end": "1611549"
  },
  {
    "text": "algorithm at the very bottom you'll notice that I am roll so I am is used",
    "start": "1611549",
    "end": "1616970"
  },
  {
    "text": "both by our services to be allowed to talk to other services as well as by",
    "start": "1616970",
    "end": "1622530"
  },
  {
    "text": "users and ec2 instances and those sorts of things so that I am role is really",
    "start": "1622530",
    "end": "1628400"
  },
  {
    "text": "what allows the fire host service to do things like write to your s3 bucket and",
    "start": "1628400",
    "end": "1634110"
  },
  {
    "text": "you have control within that I am role to really be very selective of what bucket a could write to and follow that",
    "start": "1634110",
    "end": "1641010"
  },
  {
    "text": "principle of least privilege there and then up at the top you have the buffer size and the buffer interval and and",
    "start": "1641010",
    "end": "1648630"
  },
  {
    "text": "those are the those are really the two mandatory fields besides the I am role here that define",
    "start": "1648630",
    "end": "1654600"
  },
  {
    "text": "you know how big those chunks of data are that gets written out to s3 in this",
    "start": "1654600",
    "end": "1664320"
  },
  {
    "start": "1662000",
    "end": "1715000"
  },
  {
    "text": "example you know we're showing the redshift configuration so some of the",
    "start": "1664320",
    "end": "1671490"
  },
  {
    "text": "very very similar fields but you know instead of doing the s3 bucket and key spaces it's now allowing you to find the",
    "start": "1671490",
    "end": "1680250"
  },
  {
    "text": "redshift cluster that it should write to one things you'll notice is the middle section still has an s3 definition and",
    "start": "1680250",
    "end": "1688110"
  },
  {
    "text": "the reason why we do this is you know it's a general best practice to to really save your data out to s3 first",
    "start": "1688110",
    "end": "1694980"
  },
  {
    "text": "and what's happening under the covers is it gets saved to s3 it's actually performing copy statement",
    "start": "1694980",
    "end": "1701089"
  },
  {
    "text": "to distribute the loading across all the compute nodes in redshift to be able to load all that data into redshifts very",
    "start": "1701089",
    "end": "1707989"
  },
  {
    "text": "very parallel rather than trying to go you know single thread to the leader node or something like that and then the",
    "start": "1707989",
    "end": "1718159"
  },
  {
    "start": "1715000",
    "end": "1771000"
  },
  {
    "text": "elastic search service this is a relatively new addition to firehose but",
    "start": "1718159",
    "end": "1724999"
  },
  {
    "text": "here what you're able to do is define a Amazon Elastic search endpoint and be",
    "start": "1724999",
    "end": "1730909"
  },
  {
    "text": "able to define the domain that you want to write to the index the I have a",
    "start": "1730909",
    "end": "1736669"
  },
  {
    "text": "pointer here the index rotation things like retry you know if something you",
    "start": "1736669",
    "end": "1743539"
  },
  {
    "text": "know doesn't work it's you're able to find that retrial market logic as well",
    "start": "1743539",
    "end": "1748579"
  },
  {
    "text": "as you know what that s3 backup mode is do you want to only load the failed",
    "start": "1748579",
    "end": "1753769"
  },
  {
    "text": "documents in s3 if for some reason something happens with you know the elastic search cluster is you know is",
    "start": "1753769",
    "end": "1759709"
  },
  {
    "text": "serving a lot of queries maybe it's elastically growing on its own and you're able to specify how to handle",
    "start": "1759709",
    "end": "1767049"
  },
  {
    "text": "different criteria down there the the",
    "start": "1767049",
    "end": "1774949"
  },
  {
    "start": "1771000",
    "end": "1873000"
  },
  {
    "text": "the other way to really publish messages on top of a Kinesis stream or Kinesis",
    "start": "1774949",
    "end": "1780289"
  },
  {
    "text": "firehose is using the amazon Kinesis agent and the Kinesis agent is like many",
    "start": "1780289",
    "end": "1791029"
  },
  {
    "text": "agents that you'd find you know in various situations is a piece of",
    "start": "1791029",
    "end": "1797059"
  },
  {
    "text": "software that gets loaded on you know one of the application OS is that you",
    "start": "1797059",
    "end": "1802909"
  },
  {
    "text": "want to generate events from and what it does is it really monitors the traffic",
    "start": "1802909",
    "end": "1809449"
  },
  {
    "text": "on that so you could configure it to listening to things like log files and generate messages for all the events",
    "start": "1809449",
    "end": "1816440"
  },
  {
    "text": "that happen in that log file you could listen to various sources and what it will do is or it will run on that that",
    "start": "1816440",
    "end": "1824029"
  },
  {
    "text": "instance and publish messages to Keeney such dreams or Kinesis firehose for you",
    "start": "1824029",
    "end": "1830649"
  },
  {
    "text": "it it will do things like handle you know a lot of logging technologies do",
    "start": "1830820",
    "end": "1836500"
  },
  {
    "text": "file rotation you know renaming of the files the agent is smart enough to be able to keep",
    "start": "1836500",
    "end": "1842350"
  },
  {
    "text": "trailing the same most recent file even if the other file gets renamed a new file handle gets opened up it has some",
    "start": "1842350",
    "end": "1851289"
  },
  {
    "text": "pre processing capability so you know if you're loading something like a redshift database and you want to pre-process",
    "start": "1851289",
    "end": "1858820"
  },
  {
    "text": "that formatting to make that copy into red you know much simpler you could",
    "start": "1858820",
    "end": "1865419"
  },
  {
    "text": "do that within the agent it's a really kind of stage and prep that format if you'd like you know it has all the retry",
    "start": "1865419",
    "end": "1877000"
  },
  {
    "text": "and built you know built-in logic to make sure that that message gets published out to the extreme and you",
    "start": "1877000",
    "end": "1887770"
  },
  {
    "start": "1886000",
    "end": "1961000"
  },
  {
    "text": "know how do you know that's working you know like many of our services the KCl does this the kpl does this KCl be in",
    "start": "1887770",
    "end": "1894970"
  },
  {
    "text": "the Kinesis client library in the producer library or the consumer it",
    "start": "1894970",
    "end": "1901809"
  },
  {
    "text": "publishes messages our metrics out to cloud watch so these metrics give you",
    "start": "1901809",
    "end": "1907480"
  },
  {
    "text": "things like how well is the agent performing across your various instances that way you could have that situational",
    "start": "1907480",
    "end": "1914529"
  },
  {
    "text": "awareness in that single dashboard you",
    "start": "1914529",
    "end": "1920679"
  },
  {
    "text": "know as we're talking about it's also compatible it was streamed so this is",
    "start": "1920679",
    "end": "1926289"
  },
  {
    "text": "something you could use with firehose one example is you know if you have a whole bunch of transient instances that",
    "start": "1926289",
    "end": "1932830"
  },
  {
    "text": "might you know that are spun up and later terminated but you want to save all the application log data off of that",
    "start": "1932830",
    "end": "1939789"
  },
  {
    "text": "you do things like you use this to go to Kinesis streams it could get written out",
    "start": "1939789",
    "end": "1945460"
  },
  {
    "text": "to you know elasticsearch if you want to you know capture that data and have search there's some other patterns you",
    "start": "1945460",
    "end": "1951340"
  },
  {
    "text": "could use you could go watch logs and cloud watch logs has elastic search capability as well so a few options",
    "start": "1951340",
    "end": "1959158"
  },
  {
    "text": "and you know with with with Kinesis firehose very very inexpensive to use",
    "start": "1961170",
    "end": "1968050"
  },
  {
    "text": "for everything that you're getting three and a half cents per gig ingested so can",
    "start": "1968050",
    "end": "1974290"
  },
  {
    "text": "use the strings the way the streaming service works is it's really priced per shard so this is with Kinesis streams",
    "start": "1974290",
    "end": "1983140"
  },
  {
    "text": "where you have the full flexibility of producers consumers you grow and shrink",
    "start": "1983140",
    "end": "1988750"
  },
  {
    "text": "the capacity based on the shard that's how it's priced so that's Kinesis firehose is completely managed for you",
    "start": "1988750",
    "end": "1995320"
  },
  {
    "text": "it's a you know no admin to you all you're doing is configuring that delivery stream and probably messages to",
    "start": "1995320",
    "end": "2002640"
  },
  {
    "text": "it it's based on how much data you publish to that stream and it's a three",
    "start": "2002640",
    "end": "2007650"
  },
  {
    "text": "and a half cents per gig per month for the US regions dublin i think is 3/10",
    "start": "2007650",
    "end": "2015200"
  },
  {
    "text": "three-tenths of a cent more it's like 0.38 for Dublin so what used cases would",
    "start": "2015200",
    "end": "2023370"
  },
  {
    "text": "would you want to start using Kinesis streams and what use cases would you want to start using Kinesis firehose so",
    "start": "2023370",
    "end": "2032460"
  },
  {
    "start": "2031000",
    "end": "2129000"
  },
  {
    "text": "if you really need to do very very custom processing for incoming events",
    "start": "2032460",
    "end": "2038040"
  },
  {
    "text": "and that custom processing needs to be real time you need to be able to have",
    "start": "2038040",
    "end": "2043680"
  },
  {
    "text": "you know one second sub loved one second processing of those events to be able to",
    "start": "2043680",
    "end": "2049638"
  },
  {
    "text": "drive your metrics drive your your analytics then you want to use cases",
    "start": "2049639",
    "end": "2055800"
  },
  {
    "text": "streams because you could write those those consumers and things like stark storm lambda use the KCl spark streaming",
    "start": "2055800",
    "end": "2065760"
  },
  {
    "text": "and you're able to implement that consumer logic very very easily if you",
    "start": "2065760",
    "end": "2071730"
  },
  {
    "text": "really have all this streaming data all this data is getting generated out in your enterprise or out you know out in",
    "start": "2071730",
    "end": "2078000"
  },
  {
    "text": "the world and you want to be able to collect that data and then do process processing of that data you know every",
    "start": "2078000",
    "end": "2085590"
  },
  {
    "text": "hour every few minutes you don't really have that real-time nature but you have very very high velocity data that you",
    "start": "2085590",
    "end": "2091888"
  },
  {
    "text": "need to collect Kinesis firehose is a great option because what it will give you is that",
    "start": "2091889",
    "end": "2097710"
  },
  {
    "text": "end point to produce all that messages and save that into a durable durable",
    "start": "2097710",
    "end": "2102900"
  },
  {
    "text": "location for you and you don't really have to pick either/or of these you know",
    "start": "2102900",
    "end": "2108570"
  },
  {
    "text": "many many times folks want to do both of these and it's a perfectly acceptable architecture to have both of these used",
    "start": "2108570",
    "end": "2116100"
  },
  {
    "text": "together in order to have real time processing but then be able to do backend heuristic analysis later on on",
    "start": "2116100",
    "end": "2123240"
  },
  {
    "text": "your data next what we're gonna do is",
    "start": "2123240",
    "end": "2131520"
  },
  {
    "start": "2129000",
    "end": "2149000"
  },
  {
    "text": "we're gonna really dive a little bit into Kinesis analytics it's a very very exciting new service to to be able to",
    "start": "2131520",
    "end": "2138440"
  },
  {
    "text": "really start processing or make it easier for folks to process real-time",
    "start": "2138440",
    "end": "2144480"
  },
  {
    "text": "data so really achieve that sub-second processing of data when you need it so",
    "start": "2144480",
    "end": "2150530"
  },
  {
    "text": "again this is currently in preview but what it allows you to do is really",
    "start": "2150530",
    "end": "2156600"
  },
  {
    "text": "define a sequel definition of your analytic so for example if you're if you",
    "start": "2156600",
    "end": "2162840"
  },
  {
    "text": "have a whole bunch of atmospheric information temperature and and you know",
    "start": "2162840",
    "end": "2169080"
  },
  {
    "text": "different sensors out out in the world and what you want to do is you want to be doing you want to do things like take",
    "start": "2169080",
    "end": "2174960"
  },
  {
    "text": "you the average temperature max temperature run different analytics on that streaming data it's very very easy",
    "start": "2174960",
    "end": "2182670"
  },
  {
    "text": "to form that in a traditional sequel syntax you know doing different aggregation functions what Kinesis",
    "start": "2182670",
    "end": "2188970"
  },
  {
    "text": "analytics does is it allows you to have that same notation and also qualify it",
    "start": "2188970",
    "end": "2194430"
  },
  {
    "text": "with what time interval to do that aggregation on and really define your analytics very very simple you know in a",
    "start": "2194430",
    "end": "2202080"
  },
  {
    "text": "simple syntax but listen to instead of running that on a database or you know",
    "start": "2202080",
    "end": "2208040"
  },
  {
    "text": "another technology run it on the actual Kinesis stream it's also able to listen",
    "start": "2208040",
    "end": "2214590"
  },
  {
    "text": "on your Kinesis firehose so if you do want to save that data to s3 or you do",
    "start": "2214590",
    "end": "2219720"
  },
  {
    "text": "want to save it out to redshift you could also use Kinesis analytics to be able to run that some of the",
    "start": "2219720",
    "end": "2226540"
  },
  {
    "text": "that real-time computation you know that real-time statistics on that data and be",
    "start": "2226540",
    "end": "2233110"
  },
  {
    "text": "able to do things like power dashboards and and other other use cases and of",
    "start": "2233110",
    "end": "2239890"
  },
  {
    "text": "course it's built built for for scale it will automatically grow based on how",
    "start": "2239890",
    "end": "2247510"
  },
  {
    "text": "many shards you define or how much traffic is on that team uses firehose so",
    "start": "2247510",
    "end": "2252700"
  },
  {
    "text": "you don't have to go in and really speck out you know how much compute your your",
    "start": "2252700",
    "end": "2258030"
  },
  {
    "text": "your analytic would need to be able to process the data you write your sequel syntax and and that's how you define",
    "start": "2258030",
    "end": "2264870"
  },
  {
    "text": "define that algorithm these are these",
    "start": "2264870",
    "end": "2271030"
  },
  {
    "start": "2269000",
    "end": "2283000"
  },
  {
    "text": "are some of the customers that are some of the public use cases that that we talk about sometimes when it comes to",
    "start": "2271030",
    "end": "2277650"
  },
  {
    "text": "what we're gonna do is we're gonna dive into a few of the architectures and step through some of those and you can't see",
    "start": "2277650",
    "end": "2285370"
  },
  {
    "start": "2283000",
    "end": "2341000"
  },
  {
    "text": "the lines on this screen for some reason I apologize for that but this is a tech",
    "start": "2285370",
    "end": "2291160"
  },
  {
    "text": "company that is really in the market of serving bids and serving ads out to out",
    "start": "2291160",
    "end": "2299320"
  },
  {
    "text": "to folks that want marketing space and what you can see is you know they're they're leveraging open source",
    "start": "2299320",
    "end": "2305260"
  },
  {
    "text": "technologies to be able to produce messages they're leveraging things like are they're leveraging Kinesis as",
    "start": "2305260",
    "end": "2311650"
  },
  {
    "text": "they're they're streaming they're streaming service that way they can focus on the producers and the consumers",
    "start": "2311650",
    "end": "2318540"
  },
  {
    "text": "and they have various consumers one is an archiver to be able to to load things in to",
    "start": "2318540",
    "end": "2325510"
  },
  {
    "text": "redshift the other is a event playback using an e mark cluster and then a set",
    "start": "2325510",
    "end": "2331360"
  },
  {
    "text": "of KCl applications there's a great green vent talk where they actually yeah",
    "start": "2331360",
    "end": "2343000"
  },
  {
    "start": "2341000",
    "end": "2404000"
  },
  {
    "text": "I love sushi so I like to talk about this use case is a very very innovative case so there's a",
    "start": "2343000",
    "end": "2351010"
  },
  {
    "text": "there's a sushi sushi chain that they really want to improve business operations and the way this this",
    "start": "2351010",
    "end": "2359320"
  },
  {
    "text": "restaurant works is there's actually a conveyor belt that has various sushi on it and as",
    "start": "2359320",
    "end": "2365940"
  },
  {
    "text": "as patrons actually pick up the dish that's how they're charged so you know",
    "start": "2365940",
    "end": "2371890"
  },
  {
    "text": "everyone sees the dishes going around the conveyor belt if somebody wants the dish they pick it off and they eat it and later on they get the bill but what",
    "start": "2371890",
    "end": "2379150"
  },
  {
    "text": "they want to do is they really want to optimize you know what type of you know sushi should I make in order to really",
    "start": "2379150",
    "end": "2385960"
  },
  {
    "text": "optimize the flow not have waste that sort of thing so each sushi plate actually has a",
    "start": "2385960",
    "end": "2391210"
  },
  {
    "text": "sensor on the bottom to be able to recognize you know how long it's on the",
    "start": "2391210",
    "end": "2397120"
  },
  {
    "text": "conveyor belt and and how long did it there before it got picked off and eaten",
    "start": "2397120",
    "end": "2402610"
  },
  {
    "text": "by a customer to do this they're they're leveraging a few services together you",
    "start": "2402610",
    "end": "2409840"
  },
  {
    "start": "2404000",
    "end": "2449000"
  },
  {
    "text": "know the first is using Kinesis to be able to collect all that data from the various various data feeds excuse me",
    "start": "2409840",
    "end": "2417910"
  },
  {
    "text": "and then they're using things they're loading it using a Kinesis happen to",
    "start": "2417910",
    "end": "2423010"
  },
  {
    "text": "redshift a redshift is a very very wonderful data warehouse to be able to run bi and a lot of complex queries on",
    "start": "2423010",
    "end": "2430870"
  },
  {
    "text": "top of and in front of that they're leveraging tableau in order to really",
    "start": "2430870",
    "end": "2437140"
  },
  {
    "text": "visualize the data build various reports and really optimize their their processing flow or their their supply",
    "start": "2437140",
    "end": "2444910"
  },
  {
    "text": "chain the last one i wanted to talk",
    "start": "2444910",
    "end": "2451660"
  },
  {
    "start": "2449000",
    "end": "2539000"
  },
  {
    "text": "about is Hearst another one of our great customers and recently I want highlight",
    "start": "2451660",
    "end": "2459040"
  },
  {
    "text": "them is you know they're actually leveraging a spark to do ETL on top of EMR so again they're leveraging Kim uses",
    "start": "2459040",
    "end": "2466690"
  },
  {
    "text": "streams in this case Runnings spark streaming on top of EMR that way they",
    "start": "2466690",
    "end": "2473440"
  },
  {
    "text": "could focus on the streaming application and not necessarily how to stand the whole Hadoop ecosystem how to stand up",
    "start": "2473440",
    "end": "2478870"
  },
  {
    "text": "the various demons that sort of thing and then leveraging red-red ships s3",
    "start": "2478870",
    "end": "2485470"
  },
  {
    "text": "with firehose and elastic for for some of their API and",
    "start": "2485470",
    "end": "2492820"
  },
  {
    "text": "all the way from the beginning of this flow into their final repository it",
    "start": "2492820",
    "end": "2498310"
  },
  {
    "text": "takes about 135 seconds to really pop and populate that back-end repository",
    "start": "2498310",
    "end": "2504820"
  },
  {
    "text": "for them and that you know the reason why they set up that you know that's what they needed to do for their use",
    "start": "2504820",
    "end": "2509920"
  },
  {
    "text": "case but considering you know what it's doing across that entire flow being able",
    "start": "2509920",
    "end": "2515590"
  },
  {
    "text": "to have that in the back end and you can",
    "start": "2515590",
    "end": "2521710"
  },
  {
    "text": "see some of the the sizing when it comes to the throughput as well there or you",
    "start": "2521710",
    "end": "2527710"
  },
  {
    "text": "could partially see it you can screen it 100 gigs per day five gigs one gig and",
    "start": "2527710",
    "end": "2534520"
  },
  {
    "text": "then so I wanted to to thank everybody",
    "start": "2534520",
    "end": "2542800"
  },
  {
    "start": "2539000",
    "end": "2561000"
  },
  {
    "text": "for the time I know I know dinner's waiting here so I'll I'll stay up at the front here if there's any questions and",
    "start": "2542800",
    "end": "2548890"
  },
  {
    "text": "definitely appreciate everyone's time",
    "start": "2548890",
    "end": "2552299"
  }
]
[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": "all right good morning everyone thank you very much for coming",
    "start": "1439",
    "end": "8160"
  },
  {
    "text": "my name is jonathan deroche i'm a solutions architect with amazon web services and later into",
    "start": "8160",
    "end": "14080"
  },
  {
    "text": "the slides i'm going to be joined by a customer by the name of justin lintz from chartbeat thank you very much for",
    "start": "14080",
    "end": "22000"
  },
  {
    "start": "20000",
    "end": "93000"
  },
  {
    "text": "coming this is the 400 level session of the website's track what that means is that",
    "start": "22000",
    "end": "29760"
  },
  {
    "text": "this is a session made by http lovers for http lovers we're going to be going",
    "start": "29760",
    "end": "36320"
  },
  {
    "text": "very deep into http as a transport mechanism and what can we get out of it if that's you",
    "start": "36320",
    "end": "43760"
  },
  {
    "text": "awesome if that's not you you're so welcome to stay but please understand that this is going to be today's agenda",
    "start": "43760",
    "end": "50399"
  },
  {
    "text": "and it will be catering to the technical audience also worth mentioning by virtue",
    "start": "50399",
    "end": "58079"
  },
  {
    "text": "of http in the stack can we have the timer running please gentlemen thank you by virtue of the",
    "start": "58079",
    "end": "66479"
  },
  {
    "text": "http stack it does have some interface points and some overlaps with the application itself which is",
    "start": "66479",
    "end": "73119"
  },
  {
    "text": "further explored in the websites track as well as the larger architecture which is explored in",
    "start": "73119",
    "end": "79280"
  },
  {
    "text": "architecture track we're going to touch on some of those points but for the greater part",
    "start": "79280",
    "end": "84560"
  },
  {
    "text": "those are things which are greater discussed in the respective tracks so for best results keep in mind those synergies and keep an",
    "start": "84560",
    "end": "91360"
  },
  {
    "text": "eye out for the other sessions let's talk about performance let's talk",
    "start": "91360",
    "end": "97759"
  },
  {
    "start": "93000",
    "end": "169000"
  },
  {
    "text": "about how we get there so one approach or one strategy",
    "start": "97759",
    "end": "104159"
  },
  {
    "text": "is simply to use newer hardware and software moore's law takes effect we keep on",
    "start": "104159",
    "end": "110720"
  },
  {
    "text": "relaunching new instance types there are quantifiable measurable",
    "start": "110720",
    "end": "116000"
  },
  {
    "text": "benefits that you as a customer could take advantage of simply by keeping up and upgrading to",
    "start": "116000",
    "end": "121840"
  },
  {
    "text": "the next and the best that's one approach the merits of it is that it's almost free",
    "start": "121840",
    "end": "128000"
  },
  {
    "text": "a different approach might be to apply more resources through auto scaling yes we may not necessarily have the most",
    "start": "128000",
    "end": "135680"
  },
  {
    "text": "optimized application but sometimes it actually makes sense for the business",
    "start": "135680",
    "end": "140879"
  },
  {
    "text": "to throw more hardware at the problem the third approach which we're going to",
    "start": "140879",
    "end": "146239"
  },
  {
    "text": "touch on is to offload some of the heavy lifting to someone else and lastly and this is the one that",
    "start": "146239",
    "end": "152480"
  },
  {
    "text": "we're really going to be touching on today is what could we do within the realm",
    "start": "152480",
    "end": "157680"
  },
  {
    "text": "of the web server to optimize our experience and get better performance gentlemen the",
    "start": "157680",
    "end": "165519"
  },
  {
    "text": "counter is still not working let's define better performance because",
    "start": "165519",
    "end": "172400"
  },
  {
    "start": "169000",
    "end": "217000"
  },
  {
    "text": "that may mean different things for different people and keep in mind not all of the strategies and not all the approaches",
    "start": "172400",
    "end": "178400"
  },
  {
    "text": "i've just mentioned could necessarily buy us all of these benefits so one way of qualifying better could be",
    "start": "178400",
    "end": "186400"
  },
  {
    "text": "measured in throughput as in transactions per second how many of those do we have",
    "start": "186400",
    "end": "192959"
  },
  {
    "text": "also we could be interested in latency reduction that one is especially relevant because",
    "start": "192959",
    "end": "199120"
  },
  {
    "text": "latency isn't necessarily something that's gained by adding more hardware at the problem",
    "start": "199120",
    "end": "205680"
  },
  {
    "text": "we could also talk about cost reduction right if we're gaining more mileage from our resources",
    "start": "205680",
    "end": "211599"
  },
  {
    "text": "we could get away with using less of them and paying less of them along the way",
    "start": "211599",
    "end": "217519"
  },
  {
    "start": "217000",
    "end": "396000"
  },
  {
    "text": "so let's talk about optimizations or more specifically what is it that",
    "start": "218480",
    "end": "225040"
  },
  {
    "text": "we're optimizing if there's one takeaway i'd like you guys to take from today is that optimization",
    "start": "225040",
    "end": "233040"
  },
  {
    "text": "is not free what it means by definition is first and foremost it's something that i'm applying for a",
    "start": "233040",
    "end": "239519"
  },
  {
    "text": "particular workload or a particular use case and i'm making gains by sacrificing",
    "start": "239519",
    "end": "246159"
  },
  {
    "text": "certain properties of the system that i'm not interested in so i'm gaining some and i'm losing some",
    "start": "246159",
    "end": "251920"
  },
  {
    "text": "but that's okay because i'm gaining where i care and i'm losing where i don't care in other words if i were to say that",
    "start": "251920",
    "end": "258639"
  },
  {
    "text": "we're optimizing really we're optimizing the application itself and that lends itself",
    "start": "258639",
    "end": "264560"
  },
  {
    "text": "into an entire discussion around how do we go about the act of optimizing and the",
    "start": "264560",
    "end": "271600"
  },
  {
    "text": "act of validating our optimization and the act of refining it and the act of deploying it into production",
    "start": "271600",
    "end": "278000"
  },
  {
    "text": "in a nutshell the best advice i could give you there is treat those optimizations as an integral",
    "start": "278000",
    "end": "284400"
  },
  {
    "text": "part of the application itself for example if this is an elastic beanstalk",
    "start": "284400",
    "end": "289840"
  },
  {
    "text": "application take said optimizations and bundle them into the eb extensions file we've talked about the new servers code",
    "start": "289840",
    "end": "296960"
  },
  {
    "text": "deploy use code deploy to deploy the optimizations alongside the application itself they're a part of a larger whole",
    "start": "296960",
    "end": "305039"
  },
  {
    "text": "and remember the optimizations themselves by definition or application specific",
    "start": "305039",
    "end": "311600"
  },
  {
    "text": "you cannot go ahead and optimize your application without understanding what it is when",
    "start": "311600",
    "end": "317199"
  },
  {
    "text": "justin is going to take the stage i'd like you guys to take note on how acutely aware he is of his business",
    "start": "317199",
    "end": "322639"
  },
  {
    "text": "and his workload and everything that he did which he's going to share with us is specific to that take note of that",
    "start": "322639",
    "end": "331199"
  },
  {
    "text": "so going back to the act of optimizing our software and the configuration",
    "start": "333039",
    "end": "338639"
  },
  {
    "text": "let's follow the same practices and the same best guidelines that we have for the software itself test and",
    "start": "338639",
    "end": "345680"
  },
  {
    "text": "validate those optimizations together with the application themselves tie them into your containers",
    "start": "345680",
    "end": "351120"
  },
  {
    "text": "integration tie them into your deployment tools benchmark not just once when you're",
    "start": "351120",
    "end": "356720"
  },
  {
    "text": "coming up with the configuration benchmark on every build applications change over time",
    "start": "356720",
    "end": "362800"
  },
  {
    "text": "we should be able to keep up and make sure that the assumptions that we've made when we've optimized for the applications are still true",
    "start": "362800",
    "end": "369840"
  },
  {
    "text": "a hundred and a thousand builds from now and remember there is absolutely no substitution for",
    "start": "369840",
    "end": "375919"
  },
  {
    "text": "production data don't be afraid of putting one server that has a different configuration the canary testing",
    "start": "375919",
    "end": "381759"
  },
  {
    "text": "put it in production see how it handles benchmark condense the other guys take production transactions and replay",
    "start": "381759",
    "end": "389120"
  },
  {
    "text": "them in a test environment one way or the other there is no substitution for production data",
    "start": "389120",
    "end": "396639"
  },
  {
    "start": "396000",
    "end": "427000"
  },
  {
    "text": "let's start our journey by identifying the bionics first and foremost we need to understand",
    "start": "398000",
    "end": "404319"
  },
  {
    "text": "what is it that we're serving is it a high volume application is it a low volume application do we have",
    "start": "404319",
    "end": "410560"
  },
  {
    "text": "large transactions small transactions which resource is the bottleneck what are we doing today are we well off",
    "start": "410560",
    "end": "417840"
  },
  {
    "text": "today is our so-called optimization subtracting for that or adding from that",
    "start": "417840",
    "end": "424240"
  },
  {
    "text": "in other words what is the bionic resource logs in our world and in our life",
    "start": "424240",
    "end": "433039"
  },
  {
    "text": "are the ultimate source of truth they tell us what have we done how have we done it",
    "start": "433039",
    "end": "440479"
  },
  {
    "start": "440000",
    "end": "460000"
  },
  {
    "text": "the logs themselves come from a variety of sources some of them we can generate ourselves as a customer others may come from aws",
    "start": "441039",
    "end": "448880"
  },
  {
    "text": "and are made available to you as a best practice you should be aware",
    "start": "448880",
    "end": "453919"
  },
  {
    "text": "of which logs are available at your disposal and correlate them together to get a more complete picture",
    "start": "453919",
    "end": "461599"
  },
  {
    "start": "460000",
    "end": "544000"
  },
  {
    "text": "in this regard i would like to spend a couple of minutes talking about cloudwatch logs cloudwatch logs is a new service that",
    "start": "461680",
    "end": "468240"
  },
  {
    "text": "we've offered or launched this past april the basic premise of cloudwatch logs is that we take that log data",
    "start": "468240",
    "end": "475120"
  },
  {
    "text": "that comes from the application we ask you the customer to feed it to us via",
    "start": "475120",
    "end": "480479"
  },
  {
    "text": "the cloud watch apis and at that point two things are gonna happen the first",
    "start": "480479",
    "end": "486000"
  },
  {
    "text": "cloudwatch the service is gonna archive all these entries for later retrieval",
    "start": "486000",
    "end": "492160"
  },
  {
    "text": "so if you ever want to go back in the time machine and see what happened in this transaction this time this date you can that's a value right there the",
    "start": "492160",
    "end": "499599"
  },
  {
    "text": "second thing that happens is we give you the ability to specify filters",
    "start": "499599",
    "end": "505360"
  },
  {
    "text": "and filters or each filter is a rule set that goes over the incoming logs",
    "start": "505360",
    "end": "511039"
  },
  {
    "text": "parses them extracts metadata and plots them or feeds them into a cloudvat",
    "start": "511039",
    "end": "517200"
  },
  {
    "text": "metric here on the left here is an example of a cloud dot metric",
    "start": "517200",
    "end": "522719"
  },
  {
    "text": "that parses access logs of nginx and extracts from them the",
    "start": "522719",
    "end": "529120"
  },
  {
    "text": "latency of the request and plots the average latency as a graph as a side note",
    "start": "529120",
    "end": "535120"
  },
  {
    "text": "all the charts that we're going to be seeing here today are real it was very important for us to give you real data in real life",
    "start": "535120",
    "end": "541279"
  },
  {
    "text": "examples let's talk about the metric anatomy of a",
    "start": "541279",
    "end": "548000"
  },
  {
    "start": "544000",
    "end": "681000"
  },
  {
    "text": "cloud watch lot so at its core a metric is a statistical",
    "start": "548000",
    "end": "553839"
  },
  {
    "text": "construct it gives us some information as to the minimum the maximum average count and sum of data points",
    "start": "553839",
    "end": "561040"
  },
  {
    "text": "that were added to the to the metric via the filter and it takes those it aggregates those and",
    "start": "561040",
    "end": "568000"
  },
  {
    "text": "produces a aggregation of one data point per minute on these different dimensions",
    "start": "568000",
    "end": "574800"
  },
  {
    "text": "that we've talked about once those are in the service we can graph them",
    "start": "574800",
    "end": "580160"
  },
  {
    "text": "such as here on the right this is the number of transactions that flow in one of my benchmarks or we can pass",
    "start": "580160",
    "end": "587360"
  },
  {
    "text": "them as an alarm and feed them into an alarm and act upon it if something happens",
    "start": "587360",
    "end": "594079"
  },
  {
    "text": "again going back to the motif of your application optimizing for it it would be wise to",
    "start": "596240",
    "end": "604079"
  },
  {
    "text": "take a look at your application and the logs you are producing feed them into the service and gain some",
    "start": "604079",
    "end": "610320"
  },
  {
    "text": "insights which are specific to you and most meaningful for you some examples could be number of orders",
    "start": "610320",
    "end": "616480"
  },
  {
    "text": "placed that may be a very good metric to the health of my system or the health of my business",
    "start": "616480",
    "end": "621920"
  },
  {
    "text": "number of user account registration successful logins failed logins whichever that may be you are the one",
    "start": "621920",
    "end": "628720"
  },
  {
    "text": "that knows best your application you are the one that knows best which metrics best represent the health and",
    "start": "628720",
    "end": "634079"
  },
  {
    "text": "the performance of said application another angle of cloud watch metrics",
    "start": "634079",
    "end": "642000"
  },
  {
    "text": "are those that we make available for you so not every service allows you to",
    "start": "642000",
    "end": "647200"
  },
  {
    "text": "install an agent and see what's going on notable examples are elastical balancing or ebs",
    "start": "647200",
    "end": "652959"
  },
  {
    "text": "other services may be available to you such as ec2 but some facets or some elements of the",
    "start": "652959",
    "end": "658959"
  },
  {
    "text": "configuration may not be available from the context of the os itself such as cpu credits in the new t2 family",
    "start": "658959",
    "end": "667279"
  },
  {
    "text": "cpu utilization or provision iops utilization you can know what you've done with the",
    "start": "667279",
    "end": "672560"
  },
  {
    "text": "volume but you don't necessarily know how the volume provision this information is communicated to you via",
    "start": "672560",
    "end": "678079"
  },
  {
    "text": "cloudwatch",
    "start": "678079",
    "end": "680720"
  },
  {
    "start": "681000",
    "end": "768000"
  },
  {
    "text": "we've spent some time talking about metrics now i want to go deep and say that not all metrics",
    "start": "683279",
    "end": "688800"
  },
  {
    "text": "are created equal and not all metrics produce the same data so on the left hand side is a histogram",
    "start": "688800",
    "end": "696160"
  },
  {
    "text": "of test results of an application that i've benchmarked on the x-axis we can see the latency",
    "start": "696160",
    "end": "703360"
  },
  {
    "text": "that was used for the request or the latency that was consumed by the request and on the y-axis is how many requests happen to have this",
    "start": "703360",
    "end": "710480"
  },
  {
    "text": "latency as you can see if we switch the context to the right",
    "start": "710480",
    "end": "715760"
  },
  {
    "text": "i've plotted them as a transaction percentile moving from the left of one all the way to the right to the tp 99 meaning that",
    "start": "715760",
    "end": "722800"
  },
  {
    "text": "99 of the requests were worse off than that metric what we",
    "start": "722800",
    "end": "728240"
  },
  {
    "text": "can see is if we were to look at the average which is the purple line that we've plotted",
    "start": "728240",
    "end": "734240"
  },
  {
    "text": "the average doesn't really look the same as when you actually break it down by the percentage point if i were to",
    "start": "734240",
    "end": "740320"
  },
  {
    "text": "naively say okay i'm just going to average everything out what would end up happening is that for",
    "start": "740320",
    "end": "745600"
  },
  {
    "text": "most of the requests i would think that i have a worse average than really i have and for some of the requests and take",
    "start": "745600",
    "end": "751519"
  },
  {
    "text": "note of the long tail that spikes up this is where a garbage collection kicked in in its full glory for some requests i am",
    "start": "751519",
    "end": "760320"
  },
  {
    "text": "are offering a horrible user experience and if i'm averaging it out i would never know",
    "start": "760320",
    "end": "767600"
  },
  {
    "start": "768000",
    "end": "881000"
  },
  {
    "text": "another example to deliver in that point there's no substitution for understanding your logs",
    "start": "769760",
    "end": "776079"
  },
  {
    "text": "and understanding how they're reflected within the architecture so in this example i took the eob logs",
    "start": "776079",
    "end": "783360"
  },
  {
    "text": "and the eob actually breaks out latency into three components the response processing time which is",
    "start": "783360",
    "end": "789839"
  },
  {
    "text": "the blue rectangle essentially that is derived from the latency between the user's browser",
    "start": "789839",
    "end": "797360"
  },
  {
    "text": "going through the internet and arriving at the doorstep of the elb",
    "start": "797360",
    "end": "803279"
  },
  {
    "text": "as a thought exercise if there's latency there really there's nothing i could do about it in my application",
    "start": "803600",
    "end": "809279"
  },
  {
    "text": "this is where i would explore content distribution networks cloudfront and the such this may be very relevant for the user",
    "start": "809279",
    "end": "816240"
  },
  {
    "text": "maybe relevant for my business but this is not something that that even touches my web application",
    "start": "816240",
    "end": "822320"
  },
  {
    "text": "conversely we have the request processing time which is the overhead of the transaction",
    "start": "822320",
    "end": "827440"
  },
  {
    "text": "within the eob which is usually quite minimal and then we have the back-end processing time which is how long did it take",
    "start": "827440",
    "end": "834480"
  },
  {
    "text": "for my web server to respond to the elb",
    "start": "834480",
    "end": "839360"
  },
  {
    "text": "in this example perhaps we have an rds database in the backend and perhaps the http requests are actually blocked",
    "start": "839600",
    "end": "846639"
  },
  {
    "text": "until the database query returns the eob would never know you know if i have a horrible back-end",
    "start": "846639",
    "end": "855440"
  },
  {
    "text": "processing time that may not necessarily be driven by the web application either perhaps",
    "start": "855440",
    "end": "860959"
  },
  {
    "text": "that's driven by rds and symbolic there so the eob gives us an insight",
    "start": "860959",
    "end": "866959"
  },
  {
    "text": "as to where in the world the problem lies but there's absolutely no substitution for you to",
    "start": "866959",
    "end": "872399"
  },
  {
    "text": "know your application and your architecture and know how to correlate between the the graphs and the numbers",
    "start": "872399",
    "end": "878959"
  },
  {
    "text": "and reality another example as to metric management",
    "start": "878959",
    "end": "885680"
  },
  {
    "start": "881000",
    "end": "938000"
  },
  {
    "text": "on the left i took a system that has a mix of http gets and http posts",
    "start": "885680",
    "end": "892800"
  },
  {
    "text": "naturally we have four more gets than we have posts and if i were to average them together",
    "start": "892800",
    "end": "898160"
  },
  {
    "text": "i have that chart on the left breaking it down to the latency of gets in posts",
    "start": "898160",
    "end": "906160"
  },
  {
    "text": "and assigning fairer weights into each one of them we can see a latency spike in the posts",
    "start": "906160",
    "end": "914399"
  },
  {
    "text": "again if we were averaging out and or if we were not breaking down the metrics",
    "start": "914399",
    "end": "920320"
  },
  {
    "text": "and if we're not breaking down the data into a more insightful metrics we would never know that there's a",
    "start": "920320",
    "end": "926000"
  },
  {
    "text": "problem going on so metric management is a discipline",
    "start": "926000",
    "end": "931360"
  },
  {
    "text": "and one that's worth mastering if we are aiming to seek better performance",
    "start": "931360",
    "end": "940240"
  },
  {
    "start": "938000",
    "end": "1012000"
  },
  {
    "text": "going deeper into the stack we've talked about cloudwatch whose",
    "start": "940240",
    "end": "946079"
  },
  {
    "text": "strength is to give us this high level overview and real time over what's going in the system",
    "start": "946079",
    "end": "951279"
  },
  {
    "text": "there are other metric solutions that are agent-based and are",
    "start": "951279",
    "end": "958560"
  },
  {
    "text": "giving us more insights and more information than what's available in cloudwatch these are not necessarily things that",
    "start": "958560",
    "end": "964480"
  },
  {
    "text": "you'll rely on for your daily operations but having this abundance of information",
    "start": "964480",
    "end": "969759"
  },
  {
    "text": "could be very relevant if you're tackling a very specific problem trying to get to the root off or perhaps doing a very specific",
    "start": "969759",
    "end": "976160"
  },
  {
    "text": "benchmark in this example i've plotted it using a piece of software called munin it's",
    "start": "976160",
    "end": "982000"
  },
  {
    "text": "available in amazon linux and a whole bunch of other distributions it's very easy to get up and started",
    "start": "982000",
    "end": "987600"
  },
  {
    "text": "with it the screenshot on the right hand side they took actually from their website where they have a live demo",
    "start": "987600",
    "end": "993759"
  },
  {
    "text": "i encourage you guys to go there and take a look at the software you don't have to use it if you feel that some other piece of software does",
    "start": "993759",
    "end": "1000000"
  },
  {
    "text": "the same job you're welcome to use that but one way or the other having a what i label a micrograph",
    "start": "1000000",
    "end": "1007360"
  },
  {
    "text": "versus a macro graph is a tool that you'd like to have in your arsenal",
    "start": "1007360",
    "end": "1012880"
  },
  {
    "start": "1012000",
    "end": "1088000"
  },
  {
    "text": "rounding up the discussion we have some other ideas from useful report types we've talked about the transaction",
    "start": "1014320",
    "end": "1020480"
  },
  {
    "text": "percentile of 95 or 99 being common correlating transactions if we have a service",
    "start": "1020480",
    "end": "1025918"
  },
  {
    "text": "oriented architecture and we're fanning out the execution we'd like to know where the latency is within that larger execution",
    "start": "1025919",
    "end": "1032558"
  },
  {
    "text": "top talkers get to know your customers see what they tell you hot urls common errors and by far",
    "start": "1032559",
    "end": "1041120"
  },
  {
    "text": "whatever makes most sense for you",
    "start": "1041120",
    "end": "1045038"
  },
  {
    "text": "a couple of reporting engines that could be useful we've mentioned cloudwatch elastic mapreduce is also very useful to",
    "start": "1046240",
    "end": "1053840"
  },
  {
    "text": "log and crunch logs which may be stored and deposited in s3 amazon kinesis is also very useful if",
    "start": "1053840",
    "end": "1060720"
  },
  {
    "text": "you want to feed some metrics into it and gain some real-time insights amazon redshift and lastly",
    "start": "1060720",
    "end": "1067840"
  },
  {
    "text": "there's an abundance of third-party tools both on the low generation the visualization thereof",
    "start": "1067840",
    "end": "1075120"
  },
  {
    "text": "sam analytics optimizations these are different categories that exist within the aws marketplace with",
    "start": "1075120",
    "end": "1080960"
  },
  {
    "text": "different vendors there i would encourage you to take a look at that if you feel like buying something off the shelf as opposed to doing it",
    "start": "1080960",
    "end": "1086559"
  },
  {
    "text": "yourself with that i would like to ask on stage",
    "start": "1086559",
    "end": "1091919"
  },
  {
    "start": "1088000",
    "end": "1121000"
  },
  {
    "text": "justin lintz from chargebeat to talk about his experience thank you",
    "start": "1091919",
    "end": "1097840"
  },
  {
    "text": "thank you jonathan so my name is justin lintz i'm currently a senior web",
    "start": "1101520",
    "end": "1106880"
  },
  {
    "text": "operations engineer at charpeat been a system in for around eight years or so and i've been a user of aws since",
    "start": "1106880",
    "end": "1112320"
  },
  {
    "text": "around 2008 back when there was no web console there was only scripts there's one instance type",
    "start": "1112320",
    "end": "1117840"
  },
  {
    "text": "you know we walked uphill both ways in the winter and we liked it so a little bit about sharpie",
    "start": "1117840",
    "end": "1124080"
  },
  {
    "start": "1121000",
    "end": "1134000"
  },
  {
    "text": "chartbeat's a real-time web analytics company we're based out of new york our products mainly cater towards publishers",
    "start": "1124080",
    "end": "1129520"
  },
  {
    "text": "with products specifically for video ads and paid content as well",
    "start": "1129520",
    "end": "1134799"
  },
  {
    "text": "so i may be a little bit biased but i think we have one of the most beautiful real-time web analytic dashboards out there",
    "start": "1134799",
    "end": "1140080"
  },
  {
    "text": "right now um and if you want to take a look at it you can go over to sharpie.com publishing demo and you can actually see",
    "start": "1140080",
    "end": "1146559"
  },
  {
    "text": "right now a live demo of gizmodo.com's traffic",
    "start": "1146559",
    "end": "1151840"
  },
  {
    "start": "1151000",
    "end": "1182000"
  },
  {
    "text": "so a little bit about chartbeats infrastructure we have around 400 to 500 servers running at any given time and",
    "start": "1152160",
    "end": "1158320"
  },
  {
    "text": "most of that's due to like emr jobs that are running throughout the day our peak traffic's around 275 000",
    "start": "1158320",
    "end": "1164799"
  },
  {
    "text": "requests a second that's going through a single elb at this time and we have a peak of around 11 to 12 million concurrent users across",
    "start": "1164799",
    "end": "1171840"
  },
  {
    "text": "all the sites in our network um we've been you know on aws since the beginning of the company which is 2009",
    "start": "1171840",
    "end": "1178160"
  },
  {
    "text": "and we use a wide array of other aws services as well you can see here's a typical 24-hour",
    "start": "1178160",
    "end": "1184720"
  },
  {
    "start": "1182000",
    "end": "1229000"
  },
  {
    "text": "period in the chart b traffic and this is on the y-axis the total concurrence across all the sites",
    "start": "1184720",
    "end": "1190000"
  },
  {
    "text": "in our network you can see we kind of peek off at around 1 pm eastern standard time and half of our peak you know in the",
    "start": "1190000",
    "end": "1196480"
  },
  {
    "text": "middle of the night around 2 am you can see we dip pretty low down one of the interesting things about chartbeats traffic is because we have a",
    "start": "1196480",
    "end": "1202960"
  },
  {
    "text": "lot of publishers because we have a lot of publishers with",
    "start": "1202960",
    "end": "1208000"
  },
  {
    "text": "our clients we end up with dealing with crazy spikes in traffic so if there's a breaking news",
    "start": "1208000",
    "end": "1213039"
  },
  {
    "text": "story we've seen our traffic increase by 25 or more during a breaking news story so being on aws allows us to quickly react",
    "start": "1213039",
    "end": "1219600"
  },
  {
    "text": "and handle those traffic spikes and you take a look at the url at the top that has the current number of concurrents across all the sites in our",
    "start": "1219600",
    "end": "1226000"
  },
  {
    "text": "network right now if you load that url up so a little bit about our traffic",
    "start": "1226000",
    "end": "1231039"
  },
  {
    "start": "1229000",
    "end": "1295000"
  },
  {
    "text": "characteristics so charby works by we have a little bit of javascript on every one of our clients pages that",
    "start": "1231039",
    "end": "1236159"
  },
  {
    "text": "sends us data every 15 seconds and that you know response load or request load rather is pretty small it's",
    "start": "1236159",
    "end": "1241760"
  },
  {
    "text": "limited to the length of a url which on most browsers is one kilobyte in size and the data we really look at on",
    "start": "1241760",
    "end": "1247840"
  },
  {
    "text": "average is around 213 bytes plus you know headers tcp overhead sl whatever and our response size is 43",
    "start": "1247840",
    "end": "1254559"
  },
  {
    "text": "bytes in size and that's the smallest response we can send without sending an empty response",
    "start": "1254559",
    "end": "1260000"
  },
  {
    "text": "and that's actually the smallest uh gift size that you can send back to a user and yes i pronounce that gif",
    "start": "1260000",
    "end": "1265840"
  },
  {
    "text": "um and we actually ran some numbers if we were able to actually you know get rid of the 43 byte response",
    "start": "1265840",
    "end": "1272640"
  },
  {
    "text": "size and just send an empty response we would potentially save thousands of dollars a month in traffic costs but unfortunately we can't do that we",
    "start": "1272640",
    "end": "1278559"
  },
  {
    "text": "actually have to have an empty gift there to do some error handling on the front-end side of things",
    "start": "1278559",
    "end": "1284240"
  },
  {
    "text": "so i'm going to expand a little bit about what jonathan was talking about on logging and kind of dive into some tweaks that you can do to",
    "start": "1284240",
    "end": "1289679"
  },
  {
    "text": "help alleviate some latency problems that you may experience when dealing with log files on your server",
    "start": "1289679",
    "end": "1296159"
  },
  {
    "text": "so you know you enable logging on your server and for most workloads you know it's not really going to make too much of a performance impact",
    "start": "1296159",
    "end": "1303200"
  },
  {
    "text": "but you know logging is not free you're going to end up with these sequential rights and they're pretty fast but these logs grow and grow and grow and maybe",
    "start": "1303200",
    "end": "1309440"
  },
  {
    "start": "1305000",
    "end": "1331000"
  },
  {
    "text": "you end up with log files that are 10 gigs in size 100 gigabytes in size or terabytes in size so",
    "start": "1309440",
    "end": "1315600"
  },
  {
    "text": "what do you end up doing with all these log files right you now are sitting there with 100 gigabyte log file maybe at the end of an hour",
    "start": "1315600",
    "end": "1321360"
  },
  {
    "text": "maybe at the end of the day you have a few options you can rotate them off you can compress them you can ship them",
    "start": "1321360",
    "end": "1327039"
  },
  {
    "text": "elsewhere but all those events actually have an impact on the latency of your web requests so you can see on this slide here here's",
    "start": "1327039",
    "end": "1334960"
  },
  {
    "start": "1331000",
    "end": "1368000"
  },
  {
    "text": "a 95th percentile of the average of the latency of a web server that we had set up this is an 8 gigabyte log file that i",
    "start": "1334960",
    "end": "1341679"
  },
  {
    "text": "just did a simple log rotate on standard excuse me standard gzip compression",
    "start": "1341679",
    "end": "1346960"
  },
  {
    "text": "ext4 it's already a pretty big box and you can see when i ran the gzip compression our 95th percentile went from around",
    "start": "1346960",
    "end": "1353440"
  },
  {
    "text": "four to three milliseconds up to 10 milliseconds right there a lot of people just set up their web servers",
    "start": "1353440",
    "end": "1358559"
  },
  {
    "text": "right away you know install the standalone standard log rotate command and are having this run every hour every day",
    "start": "1358559",
    "end": "1364559"
  },
  {
    "text": "and it's actually impacting your latency and you may not even realize it so i'm going to discuss some simple",
    "start": "1364559",
    "end": "1369600"
  },
  {
    "text": "tweaks we can do to help minimize those latency impacts first thing you do is rotate your logs",
    "start": "1369600",
    "end": "1375679"
  },
  {
    "start": "1373000",
    "end": "1398000"
  },
  {
    "text": "hourly right the goal here is just deal with smaller latency spikes throughout the day the default log rotate uh package but",
    "start": "1375679",
    "end": "1382240"
  },
  {
    "text": "doesn't actually rotate hourly so you have to force this with cron job it's on a 24 24-hour basis at sharpie",
    "start": "1382240",
    "end": "1389120"
  },
  {
    "text": "you know we actually can't fit a day's worth of uncompressed data on our servers so we rotate off hourly and try",
    "start": "1389120",
    "end": "1394400"
  },
  {
    "text": "to get rid of those latency spikes",
    "start": "1394400",
    "end": "1398320"
  },
  {
    "start": "1398000",
    "end": "1433000"
  },
  {
    "text": "excuse me your next option is just to avoid compression altogether on the web server um if you really have to you can look at",
    "start": "1399600",
    "end": "1406320"
  },
  {
    "text": "using some of these other alternative compression codecs such as lz4 lzo and snappy they're an order of",
    "start": "1406320",
    "end": "1411600"
  },
  {
    "text": "magnitude faster than gzip and they're also splittable if you're doing emr jobs or any map reduce jobs so",
    "start": "1411600",
    "end": "1416880"
  },
  {
    "text": "by default with gzip if you're doing emr jobs you're only going to get one mapper per gzip file so if you have a gzip file that's 100",
    "start": "1416880",
    "end": "1423200"
  },
  {
    "text": "gigabytes in size you only have one mapper to that you're not really going to take advantage of the emr capabilities there",
    "start": "1423200",
    "end": "1428960"
  },
  {
    "text": "so take a look at lzo snappy or lz4",
    "start": "1428960",
    "end": "1434080"
  },
  {
    "start": "1433000",
    "end": "1463000"
  },
  {
    "text": "the other option is you can use an extent based file system so a lot of systems still ship with ext3 by default",
    "start": "1434320",
    "end": "1439919"
  },
  {
    "text": "depending on what distro you're on or what you know iteration of that distro ext3",
    "start": "1439919",
    "end": "1445279"
  },
  {
    "text": "uses block mappings to disk offsets so you have a hundred gigabyte log file four kilobyte block size you're gonna",
    "start": "1445279",
    "end": "1450799"
  },
  {
    "text": "have tons of mappings there and an extent based file system i believe the default extent is 128",
    "start": "1450799",
    "end": "1456320"
  },
  {
    "text": "megabytes you're going to end up with a lot faster deletes and being able to handle large log files in a lot more efficient way",
    "start": "1456320",
    "end": "1463520"
  },
  {
    "start": "1463000",
    "end": "1476000"
  },
  {
    "text": "and of course you know you can always just throw hardware at the problem right you can use ssd some of these new gp2",
    "start": "1463760",
    "end": "1469200"
  },
  {
    "text": "ebs volumes you could use some of the new generation instance types that all support ssd today",
    "start": "1469200",
    "end": "1476799"
  },
  {
    "text": "so i'm going to discuss a couple other more involved tweaks so the previous slides are kind of simple tweaks you could take advantage of right away",
    "start": "1476880",
    "end": "1482559"
  },
  {
    "text": "your existing infrastructure you don't really need to make too many crazy changes to them your first option you could just",
    "start": "1482559",
    "end": "1488720"
  },
  {
    "start": "1487000",
    "end": "1510000"
  },
  {
    "text": "avoid hitting disk altogether right you could stream your logs via syslog engine x and the free open source",
    "start": "1488720",
    "end": "1494640"
  },
  {
    "text": "version started supporting this in 1.61 and up i believe was supported in the paid version starting at nginx 1.41",
    "start": "1494640",
    "end": "1501919"
  },
  {
    "text": "and apache has supported this for quite some time using the custom log command and you could just pipe that out to logger which is available on all",
    "start": "1501919",
    "end": "1507840"
  },
  {
    "text": "standard unix your other option is if you're using an elb you could take advantage of the elb",
    "start": "1507840",
    "end": "1513760"
  },
  {
    "start": "1510000",
    "end": "1542000"
  },
  {
    "text": "access logging and just disable logging on your web server altogether kind of not something i really recommend but if you're really prone or sensitive",
    "start": "1513760",
    "end": "1520400"
  },
  {
    "text": "to latency it is an option you have the problems with that is you're only really going to see one side of the picture",
    "start": "1520400",
    "end": "1525919"
  },
  {
    "text": "the logs are delayed and you actually can't adjust any custom headers so if you have any custom metrics that you're logging custom headers or anything like",
    "start": "1525919",
    "end": "1532000"
  },
  {
    "text": "that you can't make changes to that at chartbeat we don't want to log ip addresses or anything like that so given",
    "start": "1532000",
    "end": "1537760"
  },
  {
    "text": "the elb logs and we can't change that format the ip address is going to be in there",
    "start": "1537760",
    "end": "1543360"
  },
  {
    "start": "1542000",
    "end": "1569000"
  },
  {
    "text": "and this last option you can kind of perform a little ballet or so with log rotate using pre-rotate",
    "start": "1543360",
    "end": "1548640"
  },
  {
    "text": "and post rotate you know if you're behind an elb you can pull the nodes in and out of rotation do whatever you need to do",
    "start": "1548640",
    "end": "1554080"
  },
  {
    "text": "run your compression shift your log files off maybe do some like light data analysis on those log files and put them back in rotation",
    "start": "1554080",
    "end": "1561440"
  },
  {
    "text": "problem with this is it's kind of a little you know it requires a lot of staggering of the nodes a lot could go wrong but it is something to consider so",
    "start": "1561440",
    "end": "1570320"
  },
  {
    "start": "1569000",
    "end": "1589000"
  },
  {
    "text": "over these next few slides i'm gonna dive in some tcp tweaks at the os level and then kind of cover some uh slides",
    "start": "1570320",
    "end": "1576640"
  },
  {
    "text": "that discuss nginx and apache and some of those settings that complement those i'm gonna try to avoid mentioning any",
    "start": "1576640",
    "end": "1582000"
  },
  {
    "text": "specific values only to encourage you to explore what makes sense for your environment but i do in a couple cases",
    "start": "1582000",
    "end": "1587679"
  },
  {
    "text": "mention what we use the chartbeat this first option right here the listenq backlog we're going to deal with the",
    "start": "1587679",
    "end": "1594159"
  },
  {
    "start": "1589000",
    "end": "1608000"
  },
  {
    "text": "netcore somax connection so that's the number of max sockets uh number of socket max connections the",
    "start": "1594159",
    "end": "1600400"
  },
  {
    "text": "fault value is 128 apache and engine x both have specific values that they have defaulted to a much higher",
    "start": "1600400",
    "end": "1607039"
  },
  {
    "text": "value so the problem with this is so max connection says this is this number right here is going",
    "start": "1607039",
    "end": "1613200"
  },
  {
    "start": "1608000",
    "end": "1628000"
  },
  {
    "text": "to be the max that ngx or apache can set this value to so by default they're looking at 511 under the default linux",
    "start": "1613200",
    "end": "1620080"
  },
  {
    "text": "system you have 128 and you look at the man listing page you can see this value is going to be",
    "start": "1620080",
    "end": "1625200"
  },
  {
    "text": "truncated if you try to set it to a higher value and we actually learned this lesson the hard way hrp",
    "start": "1625200",
    "end": "1631279"
  },
  {
    "text": "so we had our so max connections value set really high something around sixteen thousand and we noticed we were dropping packets",
    "start": "1631279",
    "end": "1638000"
  },
  {
    "text": "you know you can see the synthelis listen q q drops right here and we didn't know about this uh nginx setting that allows us to set the",
    "start": "1638000",
    "end": "1644559"
  },
  {
    "text": "backlog values that still still set something very low at 511. you can see in that blue dotted light",
    "start": "1644559",
    "end": "1651200"
  },
  {
    "text": "line right there is where i actually made that change and you can see we stopped dropping packets on that system so it's something you want to make sure",
    "start": "1651200",
    "end": "1656960"
  },
  {
    "text": "to pay attention to especially if you have bursty workload especially with the charby you know where our traffic can burst and spike at",
    "start": "1656960",
    "end": "1663440"
  },
  {
    "text": "any given moment we saw issues with this and there's a few other additional ctl",
    "start": "1663440",
    "end": "1669120"
  },
  {
    "text": "settings related to backlogs such as netdev max backlog which is a per cpu backlog which deals",
    "start": "1669120",
    "end": "1674880"
  },
  {
    "text": "with network frames and there's also half open connections when you're dealing with tcp max in backlog",
    "start": "1674880",
    "end": "1680240"
  },
  {
    "text": "a lot of these were help to mitigate dos attacks but given the size of dos attacks these days",
    "start": "1680240",
    "end": "1685679"
  },
  {
    "text": "they're usually distributed it's going to be a ton of traffic and you know upping these is really not going to save you from a",
    "start": "1685679",
    "end": "1691279"
  },
  {
    "text": "distributed denial of service attack so i'm going to touch a little bit on the initial congestion window the",
    "start": "1691279",
    "end": "1697600"
  },
  {
    "start": "1694000",
    "end": "1745000"
  },
  {
    "text": "initial congestion window specifically starting in kernel 2.639 this was changed from 3 to 10",
    "start": "1697600",
    "end": "1704080"
  },
  {
    "text": "thanks to a lot of research done at google you can see on the slide on the left that's the average latency of a google",
    "start": "1704080",
    "end": "1709679"
  },
  {
    "text": "web search request in that research documentation you can see google shaved about 20 milliseconds off an average",
    "start": "1709679",
    "end": "1716000"
  },
  {
    "text": "request search from just increasing the initial congestion window from three to ten these patches eventually",
    "start": "1716000",
    "end": "1721520"
  },
  {
    "text": "made it made their way into the kernel main line and if you're running an older kernel you do have the option of changing that",
    "start": "1721520",
    "end": "1727200"
  },
  {
    "text": "so the tcp congestion window is going to increase during the length of your congestion during the length of your",
    "start": "1727200",
    "end": "1734480"
  },
  {
    "text": "connection and during that connection you're gonna you know if you have a long lift connection you're sending a",
    "start": "1734480",
    "end": "1739679"
  },
  {
    "text": "20 megabyte file it's going to start at say something like 10 and work its way up to something like 64.",
    "start": "1739679",
    "end": "1744960"
  },
  {
    "text": "and you're going to want to keep that congestion window open as large as possible so you can send the most amount of data in flight so this next option right here",
    "start": "1744960",
    "end": "1752480"
  },
  {
    "start": "1745000",
    "end": "1778000"
  },
  {
    "text": "you want to take a look at is tcp slow start after idle let's say you have a user that comes along they have an http keep live",
    "start": "1752480",
    "end": "1758399"
  },
  {
    "text": "session open up with your web server they just download a 10 megabyte file and now they're sitting idle a little bit",
    "start": "1758399",
    "end": "1764399"
  },
  {
    "text": "that congestion window is now wide open you got the max throughput there and you know they're reading your web page and then if this option isn't set",
    "start": "1764399",
    "end": "1771200"
  },
  {
    "text": "that window is going to collapse back down and have to start and work its way back up so you want to maintain this window to be high as possible",
    "start": "1771200",
    "end": "1778559"
  },
  {
    "start": "1778000",
    "end": "1805000"
  },
  {
    "text": "so these next few slides i'm going to cover a little bit of something that i researched a lot when i was at sharpie that",
    "start": "1778640",
    "end": "1783760"
  },
  {
    "text": "there's a lot of misinformation out there about the time weight socket state so if you're dealing with any servers",
    "start": "1783760",
    "end": "1789200"
  },
  {
    "text": "that are dealing with a high number of connections high number of performance one of the things you may notice if you're on the ss command or netsat",
    "start": "1789200",
    "end": "1795120"
  },
  {
    "text": "you're going to see a ton of sockets in this time wait state and if you're like me you kind of freaked out and you're like what is going on like is this something broken",
    "start": "1795120",
    "end": "1801520"
  },
  {
    "text": "with our servers like you know is this is there something going on and i ended up reading a lot about you know on these blog posts and",
    "start": "1801520",
    "end": "1807440"
  },
  {
    "start": "1805000",
    "end": "1858000"
  },
  {
    "text": "books and everything and dealing with this so this first option right here this is the max number of time weight buckets",
    "start": "1807440",
    "end": "1813039"
  },
  {
    "text": "you can have on a server we actually ran into this at sharpie early on before we were behind in elb we have a lot of connections per server",
    "start": "1813039",
    "end": "1819760"
  },
  {
    "text": "as you saw 11 to 12 million concurrent users you know it was normal for us to have around 200 300",
    "start": "1819760",
    "end": "1825760"
  },
  {
    "text": "000 sockets in a time weight state and if we had not raised that value we would",
    "start": "1825760",
    "end": "1830799"
  },
  {
    "text": "actually be dropping some of those connections off this next option right here is you know",
    "start": "1830799",
    "end": "1836480"
  },
  {
    "text": "you research a lot of these time weight states and for some reason there's a lot of blog posts out there that mention hey if you want to increase the amount",
    "start": "1836480",
    "end": "1842559"
  },
  {
    "text": "of time a socket's in the time weight state just adjust this tcp fin timeout state but that actually has no effect on the",
    "start": "1842559",
    "end": "1848399"
  },
  {
    "text": "time weight socket state at all it only affects the fin weight 2 state but i kind of just wanted to touch on it a little bit like that",
    "start": "1848399",
    "end": "1854320"
  },
  {
    "text": "because the value for time weight say it's actually hard-coded into the kernel and you can see on this next slide here's a link like the github source",
    "start": "1854320",
    "end": "1860559"
  },
  {
    "text": "code of the kernel source code rather on github i hope that line is still right given all the changes that's been going on",
    "start": "1860559",
    "end": "1865600"
  },
  {
    "text": "but you can actually see you know the line there that says hey this is the amount of time a socket is going to be in time weight",
    "start": "1865600",
    "end": "1870720"
  },
  {
    "text": "if you really want to change the amount of time the sockets and time wait you can install the ip contract module",
    "start": "1870720",
    "end": "1877279"
  },
  {
    "text": "but then you're going to add some additional overhead to all of your connections so something to look into so you know that",
    "start": "1877279",
    "end": "1884080"
  },
  {
    "start": "1882000",
    "end": "1912000"
  },
  {
    "text": "being said you research a lot of things out there when you're trying to optimize your server that says hey you should do this here's",
    "start": "1884080",
    "end": "1889919"
  },
  {
    "text": "all the ctl settings that you should put on your server and you know it's going to make everything awesome like would you run",
    "start": "1889919",
    "end": "1895519"
  },
  {
    "text": "curl and pipe it through bash as root on your server no no it's vegas any hands like i won't",
    "start": "1895519",
    "end": "1900880"
  },
  {
    "text": "tell anyone but you know it's something that a lot of blog posts out there recommend and i've seen this in books and they kind of just don't explain",
    "start": "1900880",
    "end": "1907200"
  },
  {
    "text": "these settings like you can cause some serious issues with your servers if you're not careful with some of these",
    "start": "1907200",
    "end": "1912240"
  },
  {
    "start": "1912000",
    "end": "1942000"
  },
  {
    "text": "and speaking of serious issues with your servers this tcp time weight recycle",
    "start": "1912240",
    "end": "1917600"
  },
  {
    "text": "option insist ctl often cited if you start searching you know time weight sockets or anything like that",
    "start": "1917600",
    "end": "1923039"
  },
  {
    "text": "you'll see mentions out there that say hey enable this you should never enable this if you're reading a blog post or a book",
    "start": "1923039",
    "end": "1928559"
  },
  {
    "text": "or anything like that it tells you enable it throw your laptop out the window throw the book out the window burn it move on to something else like",
    "start": "1928559",
    "end": "1934640"
  },
  {
    "text": "it's wrong you're going to end up with connections that are being dropped especially if any of your clients are behind a nat or stateful firewall which",
    "start": "1934640",
    "end": "1940320"
  },
  {
    "text": "they are um so you know if you do really want to actually uh you know limit the number of time",
    "start": "1940320",
    "end": "1947200"
  },
  {
    "start": "1942000",
    "end": "1949000"
  },
  {
    "text": "connections that are in a time weight state on your server there is this time weight reuse option and that's going to handle and try to",
    "start": "1947200",
    "end": "1953840"
  },
  {
    "start": "1949000",
    "end": "1960000"
  },
  {
    "text": "clean up those time weight sockets in a more cleaner manner and it's not going to like abruptly disconnect any clients",
    "start": "1953840",
    "end": "1960159"
  },
  {
    "start": "1960000",
    "end": "1974000"
  },
  {
    "text": "one thing to note about the time weight state it actually doesn't take up any memory or resources on the server so",
    "start": "1960159",
    "end": "1966000"
  },
  {
    "text": "don't panic if you see a ton of them and a quick way to take a look at like the socket states is we run ss-s on any",
    "start": "1966000",
    "end": "1972080"
  },
  {
    "text": "of your servers if you're really interested in this recycle versus reuse there's a great blog post right here that dives into the",
    "start": "1972080",
    "end": "1978240"
  },
  {
    "start": "1974000",
    "end": "1989000"
  },
  {
    "text": "kernel source code and really goes in and explains what each one of those options are doing and it's you know if you're a c coder or like",
    "start": "1978240",
    "end": "1984720"
  },
  {
    "text": "into tcp stuff it's a really great blog post i recommend so these next couple of slides i'm going",
    "start": "1984720",
    "end": "1990640"
  },
  {
    "start": "1989000",
    "end": "2017000"
  },
  {
    "text": "to talk a little bit about socket buffers so specifically the read and write socket buffer size so these are going to",
    "start": "1990640",
    "end": "1995760"
  },
  {
    "text": "be auto tuned by your kernel but if you're sending a large amount of files through your web server or you have large log files that you're shipping off",
    "start": "1995760",
    "end": "2002000"
  },
  {
    "text": "you may want to increase these buffers to be a little bit larger than their default values um you know we changed these at sharpie",
    "start": "2002000",
    "end": "2007919"
  },
  {
    "text": "but our payload is pretty low as you saw earlier from the slide you know our average request and response size is pretty small",
    "start": "2007919",
    "end": "2014000"
  },
  {
    "text": "but it does help with shipping the log files off the servers and this next option here just controls",
    "start": "2014000",
    "end": "2019679"
  },
  {
    "start": "2017000",
    "end": "2040000"
  },
  {
    "text": "the amount of memory available for all the sockets on the server at any given time for most of you out there you know if",
    "start": "2019679",
    "end": "2025600"
  },
  {
    "text": "you're not going to have a ton of connections running it's really like the sockets really don't take up too much memory",
    "start": "2025600",
    "end": "2031039"
  },
  {
    "text": "but if you do end up in a state where you're doing a very high amount of connections on each server you could run into this limit it is set",
    "start": "2031039",
    "end": "2036720"
  },
  {
    "text": "pretty high by default but it is something to take a look at and if you're really interested in more",
    "start": "2036720",
    "end": "2041760"
  },
  {
    "start": "2040000",
    "end": "2080000"
  },
  {
    "text": "of this tcp tuning or anything about how tcp works or system performance tuning take a look at tcp ip illustrated volume",
    "start": "2041760",
    "end": "2048960"
  },
  {
    "text": "one it's a great reference book even if you're not a c coder just if you're a system in web operations",
    "start": "2048960",
    "end": "2054079"
  },
  {
    "text": "engineer whatever it goes deep into the protocols and how they work there's so much more to tcp than the three-way handshake",
    "start": "2054079",
    "end": "2060240"
  },
  {
    "text": "you know you sit there reading it late at night because that's what everyone does right and you're reading about selective acts and all these things and you know your",
    "start": "2060240",
    "end": "2066480"
  },
  {
    "text": "girlfriend's telling you to come to bed and i'm like no no there's one more chapter one more chapter but and if you went to brendan greg's",
    "start": "2066480",
    "end": "2072800"
  },
  {
    "text": "talk the other day he has a great book consistent uh performance tuning which covers a few things on tcp tuning as well so i highly",
    "start": "2072800",
    "end": "2078800"
  },
  {
    "text": "recommend looking at those so now i'm going to talk a little bit about some settings that uh in nginx and",
    "start": "2078800",
    "end": "2084398"
  },
  {
    "text": "apache that kind of complement some of the settings we were previously talking about and i'm really not going to say like",
    "start": "2084399",
    "end": "2090240"
  },
  {
    "text": "which is better which you should use or anything like that i want to encourage you to kind of explore these what makes sense for your environment",
    "start": "2090240",
    "end": "2096720"
  },
  {
    "start": "2096000",
    "end": "2108000"
  },
  {
    "text": "so this first one we touched on a little bit earlier right the listen backlog you know if you are going to touch this make sure you change the net core sl max",
    "start": "2096720",
    "end": "2103599"
  },
  {
    "text": "connections otherwise you're going to run into trouble as you saw from the slide tcp defer except we're basically just",
    "start": "2103599",
    "end": "2110720"
  },
  {
    "text": "telling you know it's going to save on some resources after that tcp handshake completes the socket's not going to the server is not",
    "start": "2110720",
    "end": "2116880"
  },
  {
    "text": "going to wake up until the data payload is ready you know by default apache enables this nginx gives the ability to turn this on",
    "start": "2116880",
    "end": "2123440"
  },
  {
    "text": "or off send files another great one if you're sending any large files off your system",
    "start": "2123440",
    "end": "2130320"
  },
  {
    "start": "2126000",
    "end": "2161000"
  },
  {
    "text": "or any really serving any static files in general of your server performs what's basically called the zero copy given two file descriptors a",
    "start": "2130320",
    "end": "2136640"
  },
  {
    "text": "read and a write instead of going back and forth and performing a context switch between user space and kernel space",
    "start": "2136640",
    "end": "2142160"
  },
  {
    "text": "it's all going to happen in the kernel space um and you know by default it's actually",
    "start": "2142160",
    "end": "2147200"
  },
  {
    "text": "turned off and the reason this is there's actually some bugs and some plat on some platforms with ipv6 checksum offloading and",
    "start": "2147200",
    "end": "2154400"
  },
  {
    "text": "some issues serving files off nfs mounts for most people this doesn't really apply so it's something you probably want to turn on",
    "start": "2154400",
    "end": "2161760"
  },
  {
    "start": "2161000",
    "end": "2188000"
  },
  {
    "text": "there's also tcp cork or as nginx calls it tcp no push apache by default just says you",
    "start": "2161760",
    "end": "2167520"
  },
  {
    "text": "know we know what's best for you here we're just going to turn it on if you're using send file this allows the app the web server to",
    "start": "2167520",
    "end": "2173119"
  },
  {
    "text": "actually control the building of the packet so in the example of like a web server if you send your headers first and then",
    "start": "2173119",
    "end": "2178960"
  },
  {
    "text": "your payload later you know in most web web request responses that can all fit in one packet",
    "start": "2178960",
    "end": "2184320"
  },
  {
    "text": "so allow the web server to build that packet and send it back and of course there's tcp no delay often",
    "start": "2184320",
    "end": "2191440"
  },
  {
    "start": "2188000",
    "end": "2209000"
  },
  {
    "text": "referred to nagel's algorithm not too relevant nowadays given the speed of connections and the bandwidth",
    "start": "2191440",
    "end": "2196960"
  },
  {
    "text": "available apache you know it's just going to be disabled well the algorithm is going to be disabled by default there's no",
    "start": "2196960",
    "end": "2203040"
  },
  {
    "text": "ability to toggle it nginx still gives you the ability to toggle it but it only affects keepaway settings",
    "start": "2203040",
    "end": "2209838"
  },
  {
    "start": "2209000",
    "end": "2249000"
  },
  {
    "text": "so this last option on here http people live at sharpie you know this is very specific to your workload",
    "start": "2210000",
    "end": "2215119"
  },
  {
    "text": "at sharpie before we were behind the elb we didn't want to have people live enabled you know we have 11 to 12 million",
    "start": "2215119",
    "end": "2220400"
  },
  {
    "text": "concurrent users we're going to have to maintain an established connection for every user that's a lot of resources then we're going to run into some of",
    "start": "2220400",
    "end": "2225920"
  },
  {
    "text": "those things i was talking about earlier but when we moved behind an elb we ended up flipping on the keep alive and we saw",
    "start": "2225920",
    "end": "2231359"
  },
  {
    "text": "some huge savings for some reason nginx and apache greatly differ in their default timeouts you see",
    "start": "2231359",
    "end": "2236640"
  },
  {
    "text": "75 seconds or five five seconds not too sure about that or why that is but",
    "start": "2236640",
    "end": "2242079"
  },
  {
    "text": "if you are using an elb make sure you match the timeout on the elb to your timeout that you set and keep alive here",
    "start": "2242079",
    "end": "2249119"
  },
  {
    "text": "and also if you're doing any downstream proxying which is kind of common with nginx which we're doing heavily at char bead you want to make sure you have",
    "start": "2249200",
    "end": "2255680"
  },
  {
    "text": "keep live enabled on your upstream as well this was supported as a patch for a while and now it's included in nginx 1.14 and up",
    "start": "2255680",
    "end": "2263359"
  },
  {
    "text": "so you can take a look at these are some actual charts from our servers at chartbeat we were behind an",
    "start": "2263359",
    "end": "2269359"
  },
  {
    "start": "2264000",
    "end": "2296000"
  },
  {
    "text": "elb at this point and you can see we're doing around 20 000 packets per second and kind of guess where i enabled keep alive",
    "start": "2269359",
    "end": "2275760"
  },
  {
    "text": "there i didn't even need to draw the dotted line but you know we see here cut our packets per second in half we're just doing so",
    "start": "2275760",
    "end": "2281599"
  },
  {
    "text": "many tearing down of connections and reconnections and just such a small payload you can see our cpu usage dropped off by",
    "start": "2281599",
    "end": "2287200"
  },
  {
    "text": "10 to 15 as well maybe not the best we have to show that but we're able to reduce our server footprint just by enabling keep alive",
    "start": "2287200",
    "end": "2293599"
  },
  {
    "text": "between us and elb so just to kind of summarize and go over",
    "start": "2293599",
    "end": "2298880"
  },
  {
    "start": "2296000",
    "end": "2350000"
  },
  {
    "text": "everything we discussed right we wanted to keep the connection open for as long as possible with things like keep alive",
    "start": "2298880",
    "end": "2304079"
  },
  {
    "text": "and making sure the slow start idle as well doesn't collapse back down we talked about settings to minimize the",
    "start": "2304079",
    "end": "2310640"
  },
  {
    "text": "latency we discussed about settings to increase throughput on your servers you know and the big thing i hope you guys get away",
    "start": "2310640",
    "end": "2316560"
  },
  {
    "text": "from this is you're going to research a lot of these optimizations out there there's a lot of bad material do your homework there are",
    "start": "2316560",
    "end": "2322320"
  },
  {
    "text": "some good references out there such as the books i mentioned but see what makes most sense for your environment you know jonathan touched on",
    "start": "2322320",
    "end": "2328160"
  },
  {
    "text": "this benchmarking and toggling these options on and off you know for us at sharpie we have a unique workload where we're a",
    "start": "2328160",
    "end": "2334079"
  },
  {
    "text": "really high request late and really low payload so our overall bandwidth on our server on our inbound traffic is",
    "start": "2334079",
    "end": "2340079"
  },
  {
    "text": "around maybe 200 megabytes 280 megabytes a second um you know it averages out to around a",
    "start": "2340079",
    "end": "2345520"
  },
  {
    "text": "kilobyte a second or a kilobyte per uh request so and",
    "start": "2345520",
    "end": "2351599"
  },
  {
    "start": "2350000",
    "end": "2371000"
  },
  {
    "text": "now here i thank myself and i turn it back over to jonathan who's going to finish up the rest of the talk so thank you guys good job man",
    "start": "2351599",
    "end": "2361520"
  },
  {
    "text": "all right thank you very much justin so to wrap up let's talk about some offload",
    "start": "2363359",
    "end": "2370079"
  },
  {
    "text": "opportunities so justin just mentioned it will be i would like to revisit this topic",
    "start": "2370079",
    "end": "2376720"
  },
  {
    "text": "within the context of what specifically could elb do for us so one thing eld can do for us is",
    "start": "2376720",
    "end": "2384320"
  },
  {
    "text": "connection pooling um take a look at the graph on the right this is the benchmark that i've done",
    "start": "2384320",
    "end": "2390800"
  },
  {
    "text": "and again you can guess where exactly i've enabled uh the the elb within the data stream right so on the left hand",
    "start": "2390800",
    "end": "2396880"
  },
  {
    "text": "side we have the ballpark of 420 or so connections each one of those is a",
    "start": "2396880",
    "end": "2402960"
  },
  {
    "text": "client opening a connection directly to the web server as soon as you introduce an eob in the middle not all of the sockets or not all",
    "start": "2402960",
    "end": "2410240"
  },
  {
    "text": "the connections are necessarily used elb will shuffle them around and we'll reuse the same connections",
    "start": "2410240",
    "end": "2415920"
  },
  {
    "text": "causing a drop in the number of connections which will result in efficiencies because we're doing less",
    "start": "2415920",
    "end": "2421680"
  },
  {
    "text": "handshakes we're keeping less connections alive elb is just going to do that heavy lifting for us this is",
    "start": "2421680",
    "end": "2427280"
  },
  {
    "text": "even more so relevant if you are living in an ssl world",
    "start": "2427280",
    "end": "2433599"
  },
  {
    "text": "ssl the handshake thereof is a very expensive operation not to mention that it adds latency to",
    "start": "2433599",
    "end": "2439920"
  },
  {
    "text": "the overall transaction by doing the ssl connection to the elb",
    "start": "2439920",
    "end": "2445599"
  },
  {
    "text": "or even running traffic in the clear if that makes more sense we can cut down at the number of ssl",
    "start": "2445599",
    "end": "2451359"
  },
  {
    "text": "handshakes which are done at the server at the expense of the elb but that's okay",
    "start": "2451359",
    "end": "2456480"
  },
  {
    "text": "we've just turned it into eob's problem as well as doing persistent sessions",
    "start": "2456480",
    "end": "2461599"
  },
  {
    "text": "that's something that lives a little bit more on the application side and less so on the performance side but worth keeping in mind",
    "start": "2461599",
    "end": "2468640"
  },
  {
    "text": "other offload opportunities we've talked about the new instance types i want to make sure that you are keenly",
    "start": "2468640",
    "end": "2474800"
  },
  {
    "text": "aware of the new intel instructor's set the sni the basic premise of this",
    "start": "2474800",
    "end": "2480640"
  },
  {
    "text": "instruction set is we can do s encryption cryptographic operations",
    "start": "2480640",
    "end": "2485839"
  },
  {
    "text": "in hardware within the cpu this instructure set is available in all the new instance",
    "start": "2485839",
    "end": "2491599"
  },
  {
    "text": "types c3 m3 r3 etc if you're using a newish",
    "start": "2491599",
    "end": "2497760"
  },
  {
    "text": "version of openssl and the rest of your web stack to match",
    "start": "2497760",
    "end": "2502800"
  },
  {
    "text": "you are already taking advantage of this operation not only are we talking about less cpu",
    "start": "2502800",
    "end": "2508319"
  },
  {
    "text": "cycles because it's done in hardware rather than software the latency and the throughput per server are increased",
    "start": "2508319",
    "end": "2514960"
  },
  {
    "text": "so in other words use the nuisance types that's a net win other offload opportunities worth",
    "start": "2514960",
    "end": "2521119"
  },
  {
    "text": "keeping in mind are serving static assets from s3",
    "start": "2521119",
    "end": "2527039"
  },
  {
    "text": "another good option is serving assets from amazon dynamodb so in the s3 example",
    "start": "2528000",
    "end": "2534880"
  },
  {
    "text": "s3 specs speaks http every asset there has an url you're",
    "start": "2534880",
    "end": "2540319"
  },
  {
    "text": "simply handing out these url to your users in the dynamodb example we have launched",
    "start": "2540319",
    "end": "2546000"
  },
  {
    "text": "a javascript sdk in the browser you could have the user's browser",
    "start": "2546000",
    "end": "2552640"
  },
  {
    "text": "make api calls directly to dynamodb and get some data directly from dynamodb circumventing the web server altogether",
    "start": "2552640",
    "end": "2560319"
  },
  {
    "text": "it's somewhat involved but if that's the workload if that's your life that could be a an easy win we've touched on amazon",
    "start": "2560319",
    "end": "2568240"
  },
  {
    "text": "cloudfront especially as it relates to reducing latency and increasing throughput on the last mile",
    "start": "2568240",
    "end": "2574720"
  },
  {
    "text": "by co-locating the data closer to the user it means both optimized connections",
    "start": "2574720",
    "end": "2580720"
  },
  {
    "text": "coming back to us as well as some hits which are going to hit the cache as",
    "start": "2580720",
    "end": "2586880"
  },
  {
    "text": "opposed to hitting the application again that could be a very good win",
    "start": "2586880",
    "end": "2592000"
  },
  {
    "text": "the best advice i can give you as it relates to cloud front is if you're using it pay close attention to the",
    "start": "2592000",
    "end": "2597200"
  },
  {
    "text": "cache headers that you're responding within your application those are going to tune the performance of what get cached and",
    "start": "2597200",
    "end": "2603599"
  },
  {
    "text": "what gets hit against the web servers and some other ideas are further discussed",
    "start": "2603599",
    "end": "2608960"
  },
  {
    "text": "in the website's track another option in reducing latency is",
    "start": "2608960",
    "end": "2615839"
  },
  {
    "start": "2611000",
    "end": "2654000"
  },
  {
    "text": "co-locating ourselves closer to the user so amazon web services operates 11",
    "start": "2615839",
    "end": "2621119"
  },
  {
    "text": "regions worldwide um if it makes sense we could actually establish",
    "start": "2621119",
    "end": "2626800"
  },
  {
    "text": "redundant parallel stacks within these different geographies worldwide",
    "start": "2626800",
    "end": "2631920"
  },
  {
    "text": "and then use the ralph 53 latency based routing to direct user to the stack closest to him so",
    "start": "2631920",
    "end": "2638400"
  },
  {
    "text": "everything that we've talked about in terms of optimizing the web server still applies but now we've just shrinked the physical",
    "start": "2638400",
    "end": "2644640"
  },
  {
    "text": "distance between the user and us just by virtue of spreading out spreading the love and having more",
    "start": "2644640",
    "end": "2650240"
  },
  {
    "text": "physical locations worldwide where we have our web servers",
    "start": "2650240",
    "end": "2654720"
  },
  {
    "start": "2654000",
    "end": "2737000"
  },
  {
    "text": "a couple of last thoughts before we break monitor everything keeping logs",
    "start": "2655520",
    "end": "2662960"
  },
  {
    "text": "and keeping that data around is a pretty safe bet even if you're not crunching it in real time even if you don't have these fancy",
    "start": "2662960",
    "end": "2669680"
  },
  {
    "text": "reports running every day or every week this may be something that you'd like to go back and revisit down the line",
    "start": "2669680",
    "end": "2677119"
  },
  {
    "text": "i cannot stress this enough tune your web server to your workloads it's your application",
    "start": "2677119",
    "end": "2682800"
  },
  {
    "text": "you know it best you know which sacrifices and which trade-offs make sense",
    "start": "2682800",
    "end": "2688160"
  },
  {
    "text": "the improvement must be quantifiable the favorite part my favorite part of",
    "start": "2688160",
    "end": "2694400"
  },
  {
    "text": "justin's session was that dotted blue line where he said okay this is when they made the",
    "start": "2694400",
    "end": "2700800"
  },
  {
    "text": "difference and this is the reduction in drop packets cause and effect if you can do that you may be",
    "start": "2700800",
    "end": "2708880"
  },
  {
    "text": "lacking something in your operations and it's going to make that very hard for you to optimize your application",
    "start": "2708880",
    "end": "2714160"
  },
  {
    "text": "experiment and continuously revalidate again we've had real-life examples of",
    "start": "2714160",
    "end": "2719680"
  },
  {
    "text": "optimizations that used to be true used to be stellar and down the line have lost their validity not only do we",
    "start": "2719680",
    "end": "2728160"
  },
  {
    "text": "want to benchmark we want to re-benchmark and revalidate those assumptions that we've made over the timeline to make sure that we're",
    "start": "2728160",
    "end": "2734640"
  },
  {
    "text": "actually progressing in a positive trajectory with that said please do give us your",
    "start": "2734640",
    "end": "2740560"
  },
  {
    "start": "2737000",
    "end": "2754000"
  },
  {
    "text": "feedback we eagerly wait to hear what you have to say good or bad justin and i are going to be",
    "start": "2740560",
    "end": "2746880"
  },
  {
    "text": "available for questions and answers here and outdoors thank you again for coming and please do enjoy the rest of the conference",
    "start": "2746880",
    "end": "2756880"
  }
]
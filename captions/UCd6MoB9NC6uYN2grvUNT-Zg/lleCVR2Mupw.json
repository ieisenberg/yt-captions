[
  {
    "start": "0",
    "end": "28000"
  },
  {
    "text": "welcome to reinvent my name is Luke",
    "start": "299",
    "end": "3240"
  },
  {
    "text": "Youngblood and I'm here today with Greg",
    "start": "3240",
    "end": "5160"
  },
  {
    "text": "FEM ik and we're here we're here to talk",
    "start": "5160",
    "end": "7350"
  },
  {
    "text": "to you about how to build a server this",
    "start": "7350",
    "end": "9330"
  },
  {
    "text": "pipeline to transcode a two hour video",
    "start": "9330",
    "end": "11670"
  },
  {
    "text": "in minutes so really excited to share",
    "start": "11670",
    "end": "14400"
  },
  {
    "text": "this with you I think it's a fun",
    "start": "14400",
    "end": "15719"
  },
  {
    "text": "presentation we're gonna save a little",
    "start": "15719",
    "end": "17970"
  },
  {
    "text": "bit of time at the end for questions but",
    "start": "17970",
    "end": "21000"
  },
  {
    "text": "during the presentation we won't be",
    "start": "21000",
    "end": "22859"
  },
  {
    "text": "taking any questions but we'll save a",
    "start": "22859",
    "end": "24150"
  },
  {
    "text": "few minutes at the end so let's go ahead",
    "start": "24150",
    "end": "27000"
  },
  {
    "text": "and get started today this is what we're",
    "start": "27000",
    "end": "29939"
  },
  {
    "start": "28000",
    "end": "66000"
  },
  {
    "text": "going to cover today first I'm just",
    "start": "29939",
    "end": "31500"
  },
  {
    "text": "gonna give a brief overview of",
    "start": "31500",
    "end": "32730"
  },
  {
    "text": "serverless technology I know everyone in",
    "start": "32730",
    "end": "34890"
  },
  {
    "text": "the room here this is a 300 level",
    "start": "34890",
    "end": "36300"
  },
  {
    "text": "session so everyone pretty much knows",
    "start": "36300",
    "end": "37920"
  },
  {
    "text": "what server this is but I'm gonna just",
    "start": "37920",
    "end": "39780"
  },
  {
    "text": "give you a quick reminder recap and then",
    "start": "39780",
    "end": "42180"
  },
  {
    "text": "I'm going to introduce the challenges",
    "start": "42180",
    "end": "43559"
  },
  {
    "text": "introduced Greg and he'll talk about the",
    "start": "43559",
    "end": "45629"
  },
  {
    "text": "challenges they faced and how they built",
    "start": "45629",
    "end": "47820"
  },
  {
    "text": "the server list transcoding pipeline",
    "start": "47820",
    "end": "50300"
  },
  {
    "text": "they're gonna talk about some of the",
    "start": "50300",
    "end": "52289"
  },
  {
    "text": "lessons learned that can hopefully help",
    "start": "52289",
    "end": "54449"
  },
  {
    "text": "you if you have a similar use case and",
    "start": "54449",
    "end": "57289"
  },
  {
    "text": "then give you some best practices and",
    "start": "57289",
    "end": "59489"
  },
  {
    "text": "recommendations for serverless",
    "start": "59489",
    "end": "61739"
  },
  {
    "text": "especially in media and entertainment",
    "start": "61739",
    "end": "63480"
  },
  {
    "text": "use cases so let's talk about serverless",
    "start": "63480",
    "end": "67170"
  },
  {
    "start": "66000",
    "end": "116000"
  },
  {
    "text": "what is service mean first of all of",
    "start": "67170",
    "end": "70170"
  },
  {
    "text": "course no servers to provision or manage",
    "start": "70170",
    "end": "71939"
  },
  {
    "text": "we take care of the undifferentiated",
    "start": "71939",
    "end": "73710"
  },
  {
    "text": "heavy lifting for you and then also it",
    "start": "73710",
    "end": "77189"
  },
  {
    "text": "scales with your usage right you can",
    "start": "77189",
    "end": "78780"
  },
  {
    "text": "launch a single lambda function or you",
    "start": "78780",
    "end": "80549"
  },
  {
    "text": "can launch a thousand lambda functions",
    "start": "80549",
    "end": "82380"
  },
  {
    "text": "so you get this very elastic and",
    "start": "82380",
    "end": "84780"
  },
  {
    "text": "scalable service technology in addition",
    "start": "84780",
    "end": "89009"
  },
  {
    "text": "you never have to pay for idle so this",
    "start": "89009",
    "end": "90689"
  },
  {
    "text": "is a big selling point for a lot of our",
    "start": "90689",
    "end": "92280"
  },
  {
    "text": "customers that are managing compute on",
    "start": "92280",
    "end": "95310"
  },
  {
    "text": "ec2 today it's very rare that we see",
    "start": "95310",
    "end": "97650"
  },
  {
    "text": "customers that have a hundred percent",
    "start": "97650",
    "end": "99420"
  },
  {
    "text": "CPU utilization on their ec2 but with",
    "start": "99420",
    "end": "102659"
  },
  {
    "text": "server lists you only pay for the exact",
    "start": "102659",
    "end": "104909"
  },
  {
    "text": "amount of compute that you consume and",
    "start": "104909",
    "end": "108030"
  },
  {
    "text": "so you never have to pay for that excess",
    "start": "108030",
    "end": "110280"
  },
  {
    "text": "idle capacity of course availability and",
    "start": "110280",
    "end": "113100"
  },
  {
    "text": "fault tolerance are built in to the",
    "start": "113100",
    "end": "114990"
  },
  {
    "text": "platform and so let's just talk about",
    "start": "114990",
    "end": "118710"
  },
  {
    "start": "116000",
    "end": "168000"
  },
  {
    "text": "what a service application looks like",
    "start": "118710",
    "end": "120210"
  },
  {
    "text": "briefly so you've got an event source a",
    "start": "120210",
    "end": "123420"
  },
  {
    "text": "service applications tend to be",
    "start": "123420",
    "end": "125430"
  },
  {
    "text": "event-driven architectures right so that",
    "start": "125430",
    "end": "128099"
  },
  {
    "text": "event could be a change in a data source",
    "start": "128099",
    "end": "129989"
  },
  {
    "text": "like someone has uploaded an object to",
    "start": "129989",
    "end": "132300"
  },
  {
    "text": "an s3 bucket",
    "start": "132300",
    "end": "133590"
  },
  {
    "text": "could be a request to an API gateway",
    "start": "133590",
    "end": "135750"
  },
  {
    "text": "endpoint it could be a change in a",
    "start": "135750",
    "end": "138390"
  },
  {
    "text": "resource state maybe AWS config notice",
    "start": "138390",
    "end": "141629"
  },
  {
    "text": "that you made a configuration change on",
    "start": "141629",
    "end": "143129"
  },
  {
    "text": "one of your cloud resources so you can",
    "start": "143129",
    "end": "145470"
  },
  {
    "text": "launch a function in response to events",
    "start": "145470",
    "end": "147739"
  },
  {
    "text": "the function can be node JavaScript",
    "start": "147739",
    "end": "150720"
  },
  {
    "text": "Python Java C sharp and then you can use",
    "start": "150720",
    "end": "154410"
  },
  {
    "text": "that lambda function to do anything you",
    "start": "154410",
    "end": "156060"
  },
  {
    "text": "could do in code today so you can talk",
    "start": "156060",
    "end": "158250"
  },
  {
    "text": "to other AWS services you can talk to",
    "start": "158250",
    "end": "160650"
  },
  {
    "text": "third-party partner services pretty much",
    "start": "160650",
    "end": "163590"
  },
  {
    "text": "anything you can codify can be put into",
    "start": "163590",
    "end": "166799"
  },
  {
    "text": "a service function so what are the",
    "start": "166799",
    "end": "169890"
  },
  {
    "start": "168000",
    "end": "315000"
  },
  {
    "text": "common use cases that we see customers",
    "start": "169890",
    "end": "171120"
  },
  {
    "text": "using first of all static web sites very",
    "start": "171120",
    "end": "175590"
  },
  {
    "text": "popular use case customers are storing",
    "start": "175590",
    "end": "177720"
  },
  {
    "text": "their static website in s3 and then",
    "start": "177720",
    "end": "180269"
  },
  {
    "text": "they're building these rich dynamic",
    "start": "180269",
    "end": "182299"
  },
  {
    "text": "applications these complex web",
    "start": "182299",
    "end": "184500"
  },
  {
    "text": "applications that talk to serverless",
    "start": "184500",
    "end": "186870"
  },
  {
    "text": "backends through API gateway so",
    "start": "186870",
    "end": "190920"
  },
  {
    "text": "customers are building these backends",
    "start": "190920",
    "end": "192810"
  },
  {
    "text": "for mobile for IOT devices for desktop",
    "start": "192810",
    "end": "195959"
  },
  {
    "text": "for any any type of client you can think",
    "start": "195959",
    "end": "198030"
  },
  {
    "text": "of and then the use case we're going to",
    "start": "198030",
    "end": "200069"
  },
  {
    "text": "talk about today is there's really this",
    "start": "200069",
    "end": "202079"
  },
  {
    "text": "one on the 3rd from the left here the",
    "start": "202079",
    "end": "204180"
  },
  {
    "text": "data processing use case so customers",
    "start": "204180",
    "end": "207389"
  },
  {
    "text": "are processing data in real time but",
    "start": "207389",
    "end": "209519"
  },
  {
    "text": "they're also using an interesting",
    "start": "209519",
    "end": "210750"
  },
  {
    "text": "pattern which is kind of comes from the",
    "start": "210750",
    "end": "213060"
  },
  {
    "text": "Hadoop ecosystem called MapReduce so if",
    "start": "213060",
    "end": "215790"
  },
  {
    "text": "you're not familiar with MapReduce what",
    "start": "215790",
    "end": "217079"
  },
  {
    "text": "it is is basically you have a function",
    "start": "217079",
    "end": "220859"
  },
  {
    "text": "that map's your work load so you take",
    "start": "220859",
    "end": "224250"
  },
  {
    "text": "this large compute workload and you map",
    "start": "224250",
    "end": "227940"
  },
  {
    "text": "it across multiple parallel processes so",
    "start": "227940",
    "end": "231030"
  },
  {
    "text": "by parallelizing your application you",
    "start": "231030",
    "end": "233099"
  },
  {
    "text": "can actually process data much quicker",
    "start": "233099",
    "end": "235230"
  },
  {
    "text": "than you could if you had a single",
    "start": "235230",
    "end": "236280"
  },
  {
    "text": "process handling that and then at the",
    "start": "236280",
    "end": "239160"
  },
  {
    "text": "end you have to reduce the outputs of",
    "start": "239160",
    "end": "240810"
  },
  {
    "text": "all those those mappers into the single",
    "start": "240810",
    "end": "243870"
  },
  {
    "text": "output that you wanted so for use cases",
    "start": "243870",
    "end": "246419"
  },
  {
    "text": "like transcoding video it's it's",
    "start": "246419",
    "end": "248459"
  },
  {
    "text": "actually very powerful because now I can",
    "start": "248459",
    "end": "250319"
  },
  {
    "text": "run this in parallel across hundreds or",
    "start": "250319",
    "end": "252389"
  },
  {
    "text": "thousands of lambda functions and that's",
    "start": "252389",
    "end": "253799"
  },
  {
    "text": "what Greg's going to talk to you about",
    "start": "253799",
    "end": "254849"
  },
  {
    "text": "so I'm excited to have him share that",
    "start": "254849",
    "end": "257130"
  },
  {
    "text": "with you we also see customers using",
    "start": "257130",
    "end": "259919"
  },
  {
    "text": "server lists for chat BOTS they're using",
    "start": "259919",
    "end": "262320"
  },
  {
    "text": "Amazon Lexx to power chat BOTS and",
    "start": "262320",
    "end": "264870"
  },
  {
    "text": "they're building these rich",
    "start": "264870",
    "end": "266219"
  },
  {
    "text": "conversational interfaces",
    "start": "266219",
    "end": "268260"
  },
  {
    "text": "things like booking a flight booking a",
    "start": "268260",
    "end": "270600"
  },
  {
    "text": "hotel ordering a pizza and then they",
    "start": "270600",
    "end": "273510"
  },
  {
    "text": "once they understand the intent of what",
    "start": "273510",
    "end": "275460"
  },
  {
    "text": "the customer is trying to purchase or to",
    "start": "275460",
    "end": "277680"
  },
  {
    "text": "book then you can hand that off to a",
    "start": "277680",
    "end": "279750"
  },
  {
    "text": "lambda function that goes ahead and",
    "start": "279750",
    "end": "280920"
  },
  {
    "text": "fulfills that request for the customer",
    "start": "280920",
    "end": "283790"
  },
  {
    "text": "so we see customers integrating server",
    "start": "283790",
    "end": "287490"
  },
  {
    "text": "listen to their Alexa skills this is a",
    "start": "287490",
    "end": "289860"
  },
  {
    "text": "very popular platform for Alexa and then",
    "start": "289860",
    "end": "293460"
  },
  {
    "text": "the last use case we really see is IT",
    "start": "293460",
    "end": "295860"
  },
  {
    "text": "automation many of our customers are",
    "start": "295860",
    "end": "298140"
  },
  {
    "text": "using serverless technologies to",
    "start": "298140",
    "end": "300360"
  },
  {
    "text": "automate their IT infrastructure in the",
    "start": "300360",
    "end": "301950"
  },
  {
    "text": "cloud and even on-premises so that's",
    "start": "301950",
    "end": "304650"
  },
  {
    "text": "things like a policy enforcement making",
    "start": "304650",
    "end": "307860"
  },
  {
    "text": "sure your systems are secure",
    "start": "307860",
    "end": "309330"
  },
  {
    "text": "extending AWS services lifecycle",
    "start": "309330",
    "end": "312210"
  },
  {
    "text": "management this is a very powerful use",
    "start": "312210",
    "end": "314370"
  },
  {
    "text": "case so with that I just wanted to go",
    "start": "314370",
    "end": "317460"
  },
  {
    "start": "315000",
    "end": "339000"
  },
  {
    "text": "ahead and introduce Greg Greg why don't",
    "start": "317460",
    "end": "319590"
  },
  {
    "text": "you go ahead and tell us a little bit",
    "start": "319590",
    "end": "320670"
  },
  {
    "text": "about yourself thanks Luke so I'm a",
    "start": "320670",
    "end": "323760"
  },
  {
    "text": "software developer at revel we're a",
    "start": "323760",
    "end": "325440"
  },
  {
    "text": "small team in San Francisco with a",
    "start": "325440",
    "end": "327210"
  },
  {
    "text": "passion for video we come from a number",
    "start": "327210",
    "end": "329220"
  },
  {
    "text": "of different companies like Hulu and",
    "start": "329220",
    "end": "331590"
  },
  {
    "text": "Netflix and Amazon right now we're",
    "start": "331590",
    "end": "333360"
  },
  {
    "text": "focused on building a next-generation",
    "start": "333360",
    "end": "335510"
  },
  {
    "text": "television experience for Verizon so",
    "start": "335510",
    "end": "340110"
  },
  {
    "start": "339000",
    "end": "381000"
  },
  {
    "text": "what I'm going to be talking about today",
    "start": "340110",
    "end": "341280"
  },
  {
    "text": "is the way we've used lambda in our",
    "start": "341280",
    "end": "343680"
  },
  {
    "text": "video processing pipeline so to set the",
    "start": "343680",
    "end": "345960"
  },
  {
    "text": "stage a little bit I'll tell you some of",
    "start": "345960",
    "end": "348330"
  },
  {
    "text": "the challenges that we ran into when",
    "start": "348330",
    "end": "350250"
  },
  {
    "text": "building our video on-demand video",
    "start": "350250",
    "end": "352410"
  },
  {
    "text": "pipeline so we have a lot of videos to",
    "start": "352410",
    "end": "354900"
  },
  {
    "text": "transcode and they come from a variety",
    "start": "354900",
    "end": "356520"
  },
  {
    "text": "of different sources in a particular way",
    "start": "356520",
    "end": "358170"
  },
  {
    "text": "so we support direct browser upload FTP",
    "start": "358170",
    "end": "361170"
  },
  {
    "text": "aspera sometimes we literally get a hard",
    "start": "361170",
    "end": "363090"
  },
  {
    "text": "drive in the mail with several terabytes",
    "start": "363090",
    "end": "365010"
  },
  {
    "text": "of videos to process but basically we",
    "start": "365010",
    "end": "366930"
  },
  {
    "text": "don't really know exactly when this is",
    "start": "366930",
    "end": "368100"
  },
  {
    "text": "coming so and the input files themselves",
    "start": "368100",
    "end": "370890"
  },
  {
    "text": "can vary from like a small clip someone",
    "start": "370890",
    "end": "373500"
  },
  {
    "text": "capture on their cell phone to a",
    "start": "373500",
    "end": "374730"
  },
  {
    "text": "full-length feature film from a major",
    "start": "374730",
    "end": "376830"
  },
  {
    "text": "studio so we have a wide range of input",
    "start": "376830",
    "end": "378900"
  },
  {
    "text": "formats that we need to support as well",
    "start": "378900",
    "end": "381080"
  },
  {
    "text": "now after we take the videos in from the",
    "start": "381080",
    "end": "384960"
  },
  {
    "text": "content owners we process them to be",
    "start": "384960",
    "end": "387840"
  },
  {
    "text": "displayed on a variety different devices",
    "start": "387840",
    "end": "389340"
  },
  {
    "text": "so this is just a quick list of some of",
    "start": "389340",
    "end": "391650"
  },
  {
    "text": "the formats that we're producing you",
    "start": "391650",
    "end": "393840"
  },
  {
    "text": "have standard progressive mp4 and then",
    "start": "393840",
    "end": "396000"
  },
  {
    "text": "HLS and - for iOS and Android",
    "start": "396000",
    "end": "399090"
  },
  {
    "text": "and we also based on variety",
    "start": "399090",
    "end": "401650"
  },
  {
    "text": "contracts have DRM requirements too for",
    "start": "401650",
    "end": "404530"
  },
  {
    "text": "some of these outputs so our early",
    "start": "404530",
    "end": "407860"
  },
  {
    "start": "406000",
    "end": "435000"
  },
  {
    "text": "solutions and included some popular",
    "start": "407860",
    "end": "410080"
  },
  {
    "text": "software's service solutions we ran into",
    "start": "410080",
    "end": "413259"
  },
  {
    "text": "a few issues with these the first was",
    "start": "413259",
    "end": "415030"
  },
  {
    "text": "that coming from you know lots of video",
    "start": "415030",
    "end": "417490"
  },
  {
    "text": "backgrounds we wanted more control over",
    "start": "417490",
    "end": "419169"
  },
  {
    "text": "the process eventually uh and also at",
    "start": "419169",
    "end": "422320"
  },
  {
    "text": "scale we found it wasn't particularly",
    "start": "422320",
    "end": "423940"
  },
  {
    "text": "cost-effective in particular the",
    "start": "423940",
    "end": "426310"
  },
  {
    "text": "marginal cost of producing additional",
    "start": "426310",
    "end": "427840"
  },
  {
    "text": "output formats after everybody",
    "start": "427840",
    "end": "429490"
  },
  {
    "text": "transcoded one variety wasn't quite what",
    "start": "429490",
    "end": "432100"
  },
  {
    "text": "we thought it could be so our initial",
    "start": "432100",
    "end": "434350"
  },
  {
    "text": "approach was to build a a transcript",
    "start": "434350",
    "end": "438070"
  },
  {
    "start": "435000",
    "end": "451000"
  },
  {
    "text": "farma on ec2 pretty straightforward here",
    "start": "438070",
    "end": "440680"
  },
  {
    "text": "it solved the control issue and the cost",
    "start": "440680",
    "end": "443949"
  },
  {
    "text": "concern to some extent but created some",
    "start": "443949",
    "end": "447010"
  },
  {
    "text": "operational challenges so the more",
    "start": "447010",
    "end": "450070"
  },
  {
    "text": "detail that so we had people using the",
    "start": "450070",
    "end": "454750"
  },
  {
    "start": "451000",
    "end": "540000"
  },
  {
    "text": "service who would take a quick video on",
    "start": "454750",
    "end": "456820"
  },
  {
    "text": "on their cell phone and upload it and",
    "start": "456820",
    "end": "459130"
  },
  {
    "text": "won't be able to share it very quickly",
    "start": "459130",
    "end": "460509"
  },
  {
    "text": "so we wanted to avoid any queuing where",
    "start": "460509",
    "end": "462940"
  },
  {
    "text": "their video would be stuck in a long",
    "start": "462940",
    "end": "464289"
  },
  {
    "text": "processing queue for a while so that",
    "start": "464289",
    "end": "466000"
  },
  {
    "text": "means that we wanted to be able to you",
    "start": "466000",
    "end": "467889"
  },
  {
    "text": "know pretty quickly respond to new",
    "start": "467889",
    "end": "469330"
  },
  {
    "text": "demand but we had a cold start problem",
    "start": "469330",
    "end": "471789"
  },
  {
    "text": "once you combine the cost of starting",
    "start": "471789",
    "end": "473710"
  },
  {
    "text": "the instance downloading our software",
    "start": "473710",
    "end": "476380"
  },
  {
    "text": "installing any updates downloading the",
    "start": "476380",
    "end": "477909"
  },
  {
    "text": "file to start with would be a",
    "start": "477909",
    "end": "479260"
  },
  {
    "text": "significant amount of time between the",
    "start": "479260",
    "end": "481000"
  },
  {
    "text": "need for extra capacity arose and we",
    "start": "481000",
    "end": "483280"
  },
  {
    "text": "were actually had that capacity you know",
    "start": "483280",
    "end": "485380"
  },
  {
    "text": "spinning away and processing of files",
    "start": "485380",
    "end": "487360"
  },
  {
    "text": "and then we had a problem on the reverse",
    "start": "487360",
    "end": "489220"
  },
  {
    "text": "side - when it came time to scale down",
    "start": "489220",
    "end": "490900"
  },
  {
    "text": "so if we have a large instance that was",
    "start": "490900",
    "end": "493150"
  },
  {
    "text": "capable of running multiple jobs but",
    "start": "493150",
    "end": "495400"
  },
  {
    "text": "there was a you know single long-running",
    "start": "495400",
    "end": "496900"
  },
  {
    "text": "job on it an HD video transcode at least",
    "start": "496900",
    "end": "499449"
  },
  {
    "text": "at our settings and with the way we",
    "start": "499449",
    "end": "500919"
  },
  {
    "text": "added configure could take several hours",
    "start": "500919",
    "end": "502210"
  },
  {
    "text": "there's no way to really reuse that",
    "start": "502210",
    "end": "504970"
  },
  {
    "text": "extra capacity that's on that instance",
    "start": "504970",
    "end": "507130"
  },
  {
    "text": "they can process five jobs which only",
    "start": "507130",
    "end": "508599"
  },
  {
    "text": "have one running on it you can't really",
    "start": "508599",
    "end": "510070"
  },
  {
    "text": "stop the job in the middle and move it",
    "start": "510070",
    "end": "513310"
  },
  {
    "text": "over to another machine - to reclaim",
    "start": "513310",
    "end": "515260"
  },
  {
    "text": "that excess capacity so we had wasted",
    "start": "515260",
    "end": "517360"
  },
  {
    "text": "capacity there and then when we built",
    "start": "517360",
    "end": "520360"
  },
  {
    "text": "this there was also a one hour minimum",
    "start": "520360",
    "end": "522250"
  },
  {
    "text": "or like you were building ec2 and when",
    "start": "522250",
    "end": "525160"
  },
  {
    "text": "our chunks so that meant that if we spun",
    "start": "525160",
    "end": "527020"
  },
  {
    "text": "up a bunch of instances to process video",
    "start": "527020",
    "end": "528610"
  },
  {
    "text": "so like 20 minutes you'd pay for the",
    "start": "528610",
    "end": "530110"
  },
  {
    "text": "rest of the rest of the hour anyways",
    "start": "530110",
    "end": "531850"
  },
  {
    "text": "that it said September this is now in",
    "start": "531850",
    "end": "533800"
  },
  {
    "text": "Peru",
    "start": "533800",
    "end": "534200"
  },
  {
    "text": "but it's useful at least for motivation",
    "start": "534200",
    "end": "536360"
  },
  {
    "text": "as to why we did this in the first place",
    "start": "536360",
    "end": "539560"
  },
  {
    "start": "540000",
    "end": "611000"
  },
  {
    "text": "so why did we pick serverless for this",
    "start": "540160",
    "end": "543110"
  },
  {
    "text": "problem its songs are cold start",
    "start": "543110",
    "end": "545780"
  },
  {
    "text": "straightaway so we don't have any issues",
    "start": "545780",
    "end": "548330"
  },
  {
    "text": "with starting machines or installing",
    "start": "548330",
    "end": "549890"
  },
  {
    "text": "updates or you know waiting for them to",
    "start": "549890",
    "end": "551840"
  },
  {
    "text": "join the your workgroup and get started",
    "start": "551840",
    "end": "553640"
  },
  {
    "text": "ready to go right from the get-go no",
    "start": "553640",
    "end": "556010"
  },
  {
    "text": "wasted capacity is Luke touched on this",
    "start": "556010",
    "end": "557690"
  },
  {
    "text": "before but we can scale up and scale",
    "start": "557690",
    "end": "559610"
  },
  {
    "text": "down the fearless Lane and then all of",
    "start": "559610",
    "end": "563270"
  },
  {
    "text": "us just results in fewer operations",
    "start": "563270",
    "end": "565490"
  },
  {
    "text": "challenges first so our code runs the",
    "start": "565490",
    "end": "567020"
  },
  {
    "text": "same whether we're running on two",
    "start": "567020",
    "end": "568460"
  },
  {
    "text": "thousand cores or twenty fours and as I",
    "start": "568460",
    "end": "573950"
  },
  {
    "text": "just mentioned that's the large standby",
    "start": "573950",
    "end": "575720"
  },
  {
    "text": "capacity if it's critical for us here so",
    "start": "575720",
    "end": "577670"
  },
  {
    "text": "our current limit is 2,000 concurrent",
    "start": "577670",
    "end": "580280"
  },
  {
    "text": "functions but that's not like a hard",
    "start": "580280",
    "end": "582800"
  },
  {
    "text": "ceiling there and I'll get into this a",
    "start": "582800",
    "end": "586340"
  },
  {
    "text": "little bit more in detail but the way we",
    "start": "586340",
    "end": "587780"
  },
  {
    "text": "mapped the problem to solve it in a",
    "start": "587780",
    "end": "589250"
  },
  {
    "text": "service standpoint means that we have",
    "start": "589250",
    "end": "591380"
  },
  {
    "text": "flexible resource allocations so we can",
    "start": "591380",
    "end": "593180"
  },
  {
    "text": "decide hey we're going to put a lot more",
    "start": "593180",
    "end": "594530"
  },
  {
    "text": "resources against solving this",
    "start": "594530",
    "end": "596030"
  },
  {
    "text": "particular problem tranche routing this",
    "start": "596030",
    "end": "598160"
  },
  {
    "text": "particular video because it's more",
    "start": "598160",
    "end": "599240"
  },
  {
    "text": "important and that can actually change",
    "start": "599240",
    "end": "600440"
  },
  {
    "text": "throughout the job so if we're halfway",
    "start": "600440",
    "end": "602540"
  },
  {
    "text": "through processing a large file that's",
    "start": "602540",
    "end": "604250"
  },
  {
    "text": "sort of a background task we'll get a",
    "start": "604250",
    "end": "605510"
  },
  {
    "text": "new file that we need to process put",
    "start": "605510",
    "end": "607850"
  },
  {
    "text": "more resources against immediately we",
    "start": "607850",
    "end": "609260"
  },
  {
    "text": "can do that with this approach so here",
    "start": "609260",
    "end": "613820"
  },
  {
    "start": "611000",
    "end": "649000"
  },
  {
    "text": "are some of the challenges of taking",
    "start": "613820",
    "end": "615230"
  },
  {
    "text": "video transcoding and mapping it to a",
    "start": "615230",
    "end": "616820"
  },
  {
    "text": "service world we start with big input",
    "start": "616820",
    "end": "619760"
  },
  {
    "text": "files some of our files are you know",
    "start": "619760",
    "end": "621740"
  },
  {
    "text": "hundreds of gigabytes and we don't",
    "start": "621740",
    "end": "623420"
  },
  {
    "text": "really want to have to wait to download",
    "start": "623420",
    "end": "624740"
  },
  {
    "text": "the entire file before we start",
    "start": "624740",
    "end": "625880"
  },
  {
    "text": "processing it and then you know lambdas",
    "start": "625880",
    "end": "628550"
  },
  {
    "text": "case you not even enough space to",
    "start": "628550",
    "end": "630050"
  },
  {
    "text": "download in the first places so the",
    "start": "630050",
    "end": "632960"
  },
  {
    "text": "other thing that makes this big file",
    "start": "632960",
    "end": "634280"
  },
  {
    "text": "problem tricky is that most of the video",
    "start": "634280",
    "end": "635930"
  },
  {
    "text": "processing tools aren't set up to handle",
    "start": "635930",
    "end": "638930"
  },
  {
    "text": "like the input and output in chunks they",
    "start": "638930",
    "end": "640700"
  },
  {
    "text": "basically assume that you have the whole",
    "start": "640700",
    "end": "642260"
  },
  {
    "text": "input file and just somewhere and",
    "start": "642260",
    "end": "643490"
  },
  {
    "text": "they're gonna be writing the whole",
    "start": "643490",
    "end": "644570"
  },
  {
    "text": "output file to another spot on disk so",
    "start": "644570",
    "end": "647630"
  },
  {
    "text": "they're a little bit difficult to string",
    "start": "647630",
    "end": "648890"
  },
  {
    "text": "that and the jobs themselves are can be",
    "start": "648890",
    "end": "652040"
  },
  {
    "start": "649000",
    "end": "669000"
  },
  {
    "text": "slow like as I mentioned it kind of",
    "start": "652040",
    "end": "653450"
  },
  {
    "text": "depends on what settings you're using in",
    "start": "653450",
    "end": "654800"
  },
  {
    "text": "your quality ratios and whatnot but an",
    "start": "654800",
    "end": "656870"
  },
  {
    "text": "HD transcript of a movie can take",
    "start": "656870",
    "end": "658580"
  },
  {
    "text": "several hours and these jobs are sort of",
    "start": "658580",
    "end": "661340"
  },
  {
    "text": "hard to pause and resume most of the",
    "start": "661340",
    "end": "662750"
  },
  {
    "text": "tools don't support like serializing",
    "start": "662750",
    "end": "664520"
  },
  {
    "text": "their state and uploading it to another",
    "start": "664520",
    "end": "666440"
  },
  {
    "text": "machine",
    "start": "666440",
    "end": "667010"
  },
  {
    "text": "starting in the fresh from there so here",
    "start": "667010",
    "end": "671450"
  },
  {
    "start": "669000",
    "end": "716000"
  },
  {
    "text": "is our plan basically when you come up",
    "start": "671450",
    "end": "673970"
  },
  {
    "text": "with a problem that you can't solve",
    "start": "673970",
    "end": "675260"
  },
  {
    "text": "straight forward or what do you do it",
    "start": "675260",
    "end": "676370"
  },
  {
    "text": "you divide in Congress it has Luke",
    "start": "676370",
    "end": "677720"
  },
  {
    "text": "mentioned this is a MapReduce here so a",
    "start": "677720",
    "end": "681610"
  },
  {
    "text": "basic idea is that we'll consider the",
    "start": "681610",
    "end": "684890"
  },
  {
    "text": "video in small chunks we use five",
    "start": "684890",
    "end": "686810"
  },
  {
    "text": "seconds but that's just a you know a",
    "start": "686810",
    "end": "688490"
  },
  {
    "text": "number we picked and we'll transfer to",
    "start": "688490",
    "end": "690440"
  },
  {
    "text": "each one of those five chunks in the map",
    "start": "690440",
    "end": "692300"
  },
  {
    "text": "step and then when we need to produce an",
    "start": "692300",
    "end": "694670"
  },
  {
    "text": "output like you know progressive mp4 for",
    "start": "694670",
    "end": "697160"
  },
  {
    "text": "the whole video that's where the reduce",
    "start": "697160",
    "end": "698690"
  },
  {
    "text": "comes in or reduce all those small",
    "start": "698690",
    "end": "700010"
  },
  {
    "text": "chunks to form the resulting in before",
    "start": "700010",
    "end": "702070"
  },
  {
    "text": "for some lost cases we can actually use",
    "start": "702070",
    "end": "704780"
  },
  {
    "text": "the output of the map step directly like",
    "start": "704780",
    "end": "706550"
  },
  {
    "text": "the output of the map sub is the TS",
    "start": "706550",
    "end": "708260"
  },
  {
    "text": "segments that you want to stream but for",
    "start": "708260",
    "end": "711530"
  },
  {
    "text": "other cases we have to do some improve",
    "start": "711530",
    "end": "712970"
  },
  {
    "text": "post-processing there in particular drm",
    "start": "712970",
    "end": "716410"
  },
  {
    "text": "so here are the tools that we use to",
    "start": "716410",
    "end": "718610"
  },
  {
    "text": "build this of course we're here because",
    "start": "718610",
    "end": "720260"
  },
  {
    "text": "we're using lambda the big components",
    "start": "720260",
    "end": "722750"
  },
  {
    "text": "this are the instant scale that we get",
    "start": "722750",
    "end": "724760"
  },
  {
    "text": "and just a huge parallel compute",
    "start": "724760",
    "end": "727010"
  },
  {
    "text": "capacity s3 was also a critical part so",
    "start": "727010",
    "end": "732350"
  },
  {
    "start": "729000",
    "end": "759000"
  },
  {
    "text": "in particular multi-part uploads which",
    "start": "732350",
    "end": "734570"
  },
  {
    "text": "let us create a large object in s3",
    "start": "734570",
    "end": "736520"
  },
  {
    "text": "without having to have the whole data",
    "start": "736520",
    "end": "738350"
  },
  {
    "text": "buffered on disk at some point we don't",
    "start": "738350",
    "end": "739880"
  },
  {
    "text": "even have to know how big it is when we",
    "start": "739880",
    "end": "741350"
  },
  {
    "text": "start we can just start throwing data",
    "start": "741350",
    "end": "743240"
  },
  {
    "text": "into s3 and at the end we'll say okay",
    "start": "743240",
    "end": "744680"
  },
  {
    "text": "that's all I have and we'll create the",
    "start": "744680",
    "end": "746060"
  },
  {
    "text": "object for us then the important part",
    "start": "746060",
    "end": "748310"
  },
  {
    "text": "was a ranger quest so this is sort of",
    "start": "748310",
    "end": "749930"
  },
  {
    "text": "the reverse and we don't have to have",
    "start": "749930",
    "end": "751670"
  },
  {
    "text": "the whole file to upload we also don't",
    "start": "751670",
    "end": "753260"
  },
  {
    "text": "have to download the whole file at once",
    "start": "753260",
    "end": "754580"
  },
  {
    "text": "we can just ask for a small part of you",
    "start": "754580",
    "end": "756710"
  },
  {
    "text": "know this logic but filed a process to",
    "start": "756710",
    "end": "760910"
  },
  {
    "start": "759000",
    "end": "779000"
  },
  {
    "text": "do the actual video processing we used",
    "start": "760910",
    "end": "762410"
  },
  {
    "text": "ffmpeg mostly before it's a wide range",
    "start": "762410",
    "end": "764540"
  },
  {
    "text": "of features in particular input and",
    "start": "764540",
    "end": "766610"
  },
  {
    "text": "output formats and for our language of",
    "start": "766610",
    "end": "769310"
  },
  {
    "text": "choice we picked by though it's natively",
    "start": "769310",
    "end": "771080"
  },
  {
    "text": "supported by lambda and also the team at",
    "start": "771080",
    "end": "773990"
  },
  {
    "text": "revel has a lot of experience with",
    "start": "773990",
    "end": "775100"
  },
  {
    "text": "Python so we felt comfortable using it",
    "start": "775100",
    "end": "776870"
  },
  {
    "text": "to stick together all the C code that",
    "start": "776870",
    "end": "778430"
  },
  {
    "text": "does the actual work so here's the",
    "start": "778430",
    "end": "781910"
  },
  {
    "start": "779000",
    "end": "820000"
  },
  {
    "text": "architectural diagram which I'll I'll go",
    "start": "781910",
    "end": "784430"
  },
  {
    "text": "over briefly here but then we'll dive",
    "start": "784430",
    "end": "785660"
  },
  {
    "text": "into bits in more detail as we go so all",
    "start": "785660",
    "end": "789680"
  },
  {
    "text": "of our files start in s3 we take them",
    "start": "789680",
    "end": "792830"
  },
  {
    "text": "from the various uploaded locations and",
    "start": "792830",
    "end": "794690"
  },
  {
    "text": "dump them off in s3 and then we run our",
    "start": "794690",
    "end": "796880"
  },
  {
    "text": "map so critically here we can run",
    "start": "796880",
    "end": "800170"
  },
  {
    "text": "basically an arbitrary number of these",
    "start": "800170",
    "end": "801610"
  },
  {
    "text": "maps in parallel so taking each team of",
    "start": "801610",
    "end": "804400"
  },
  {
    "text": "five second chunk of the video and",
    "start": "804400",
    "end": "805780"
  },
  {
    "text": "processing it doesn't depend on any of",
    "start": "805780",
    "end": "808060"
  },
  {
    "text": "the other five second chunks so",
    "start": "808060",
    "end": "809680"
  },
  {
    "text": "depending on how many cores we have",
    "start": "809680",
    "end": "811930"
  },
  {
    "text": "available or you know concurring lambda",
    "start": "811930",
    "end": "813490"
  },
  {
    "text": "function executions we can we can run a",
    "start": "813490",
    "end": "815110"
  },
  {
    "text": "bunch of these all at once results when",
    "start": "815110",
    "end": "817510"
  },
  {
    "text": "those ts chunks end up being stored in",
    "start": "817510",
    "end": "819370"
  },
  {
    "text": "another s3 bucket and then we'll run our",
    "start": "819370",
    "end": "821890"
  },
  {
    "start": "820000",
    "end": "840000"
  },
  {
    "text": "reduced steps on those chunks so there's",
    "start": "821890",
    "end": "824260"
  },
  {
    "text": "a simple reduce to combine them into an",
    "start": "824260",
    "end": "825880"
  },
  {
    "text": "mp4 file more complicated reductions to",
    "start": "825880",
    "end": "830130"
  },
  {
    "text": "produce DRM outputs and for this example",
    "start": "830130",
    "end": "833260"
  },
  {
    "text": "where we'll go over what we do for HLS",
    "start": "833260",
    "end": "835570"
  },
  {
    "text": "and similarly for for - DRM files so",
    "start": "835570",
    "end": "841570"
  },
  {
    "start": "840000",
    "end": "854000"
  },
  {
    "text": "let's dive in a bit to our map step so",
    "start": "841570",
    "end": "843970"
  },
  {
    "text": "this is the little called the chunk",
    "start": "843970",
    "end": "845500"
  },
  {
    "text": "function because we produce a TS chunk",
    "start": "845500",
    "end": "847180"
  },
  {
    "text": "from it so what we must do here is",
    "start": "847180",
    "end": "848740"
  },
  {
    "text": "decode a small portion of the input file",
    "start": "848740",
    "end": "850540"
  },
  {
    "text": "transferred it to the desired bit right",
    "start": "850540",
    "end": "852700"
  },
  {
    "text": "and then upload that chunk to s3 so the",
    "start": "852700",
    "end": "855940"
  },
  {
    "text": "challenge here is actually decoding that",
    "start": "855940",
    "end": "858730"
  },
  {
    "text": "small chunk because as I mentioned",
    "start": "858730",
    "end": "860260"
  },
  {
    "text": "before we have large input file and we",
    "start": "860260",
    "end": "862120"
  },
  {
    "text": "don't have to download the whole thing",
    "start": "862120",
    "end": "863260"
  },
  {
    "text": "now I have MPEG does most of the work",
    "start": "863260",
    "end": "865180"
  },
  {
    "text": "here for us because they support in HTTP",
    "start": "865180",
    "end": "868390"
  },
  {
    "text": "input so they'll only ask for you know",
    "start": "868390",
    "end": "870490"
  },
  {
    "text": "view should be range requests only ask",
    "start": "870490",
    "end": "871900"
  },
  {
    "text": "for the small bit of the files need to",
    "start": "871900",
    "end": "873010"
  },
  {
    "text": "process but unfortunately what we've",
    "start": "873010",
    "end": "875320"
  },
  {
    "text": "found out is that ffmpeg will want to",
    "start": "875320",
    "end": "878740"
  },
  {
    "text": "like read a few bytes and then seek for",
    "start": "878740",
    "end": "880510"
  },
  {
    "text": "word and then read a few more bikes and",
    "start": "880510",
    "end": "881530"
  },
  {
    "text": "then seek backward or whatnot and all of",
    "start": "881530",
    "end": "883150"
  },
  {
    "text": "these little requests for a bite or two",
    "start": "883150",
    "end": "885070"
  },
  {
    "text": "and it being separate HTTP requests and",
    "start": "885070",
    "end": "886900"
  },
  {
    "text": "the overhead of all these HTTP requests",
    "start": "886900",
    "end": "889150"
  },
  {
    "text": "ends up you know being too expensive so",
    "start": "889150",
    "end": "892390"
  },
  {
    "text": "what we did is we built a cache that",
    "start": "892390",
    "end": "894760"
  },
  {
    "text": "runs in the lambda function alongside",
    "start": "894760",
    "end": "897760"
  },
  {
    "text": "lambda just you know an HTTP daemon",
    "start": "897760",
    "end": "901300"
  },
  {
    "text": "there and what it does is it proxies all",
    "start": "901300",
    "end": "903160"
  },
  {
    "text": "the read requests from ffmpeg to to s3",
    "start": "903160",
    "end": "906270"
  },
  {
    "text": "so what we do is we fetch the files from",
    "start": "906270",
    "end": "910120"
  },
  {
    "text": "s3 in larger chunks then ffmpeg will ask",
    "start": "910120",
    "end": "913120"
  },
  {
    "text": "for so whenever from big is slowly",
    "start": "913120",
    "end": "915010"
  },
  {
    "text": "moving along or moving backwards or",
    "start": "915010",
    "end": "916780"
  },
  {
    "text": "reading the same part there's a good",
    "start": "916780",
    "end": "917830"
  },
  {
    "text": "chance that we actually have that data",
    "start": "917830",
    "end": "919090"
  },
  {
    "text": "already in memory we don't have to make",
    "start": "919090",
    "end": "920800"
  },
  {
    "text": "a separate HTTP request to s3 to to",
    "start": "920800",
    "end": "923920"
  },
  {
    "text": "fulfill that and the other thing that we",
    "start": "923920",
    "end": "926590"
  },
  {
    "text": "do is",
    "start": "926590",
    "end": "927790"
  },
  {
    "text": "because even though it may all kind of",
    "start": "927790",
    "end": "929800"
  },
  {
    "text": "move around a little bit locally as its",
    "start": "929800",
    "end": "931450"
  },
  {
    "text": "processing the general trend is still",
    "start": "931450",
    "end": "933220"
  },
  {
    "text": "sort of from the beginning of the file",
    "start": "933220",
    "end": "934720"
  },
  {
    "text": "to the end of the file so will actually",
    "start": "934720",
    "end": "936280"
  },
  {
    "text": "proactively fetch the next chunk of the",
    "start": "936280",
    "end": "938470"
  },
  {
    "text": "video wallet if MPEG is processing the",
    "start": "938470",
    "end": "940300"
  },
  {
    "text": "previous chunks basically you never want",
    "start": "940300",
    "end": "942580"
  },
  {
    "text": "your CPU waiting for your IO or",
    "start": "942580",
    "end": "944200"
  },
  {
    "text": "vice-versa",
    "start": "944200",
    "end": "946470"
  },
  {
    "start": "946000",
    "end": "967000"
  },
  {
    "text": "so I'll talk a little bit about some of",
    "start": "946470",
    "end": "949270"
  },
  {
    "text": "the problems we ran into running ffmpeg",
    "start": "949270",
    "end": "951490"
  },
  {
    "text": "inside a lambda environment this is",
    "start": "951490",
    "end": "953530"
  },
  {
    "text": "hopefully won't just be specific to",
    "start": "953530",
    "end": "955390"
  },
  {
    "text": "ffmpeg and you could apply this for any",
    "start": "955390",
    "end": "957040"
  },
  {
    "text": "other binary that you might want to run",
    "start": "957040",
    "end": "958300"
  },
  {
    "text": "so we found that it was unreliable",
    "start": "958300",
    "end": "960790"
  },
  {
    "text": "if dynamically linked so we ended up",
    "start": "960790",
    "end": "962590"
  },
  {
    "text": "statically linking everything obviously",
    "start": "962590",
    "end": "965670"
  },
  {
    "text": "larger binaries but it still fit with it",
    "start": "965670",
    "end": "968950"
  },
  {
    "start": "967000",
    "end": "977000"
  },
  {
    "text": "well within the lambda limits it's",
    "start": "968950",
    "end": "970030"
  },
  {
    "text": "actually a lot of space there",
    "start": "970030",
    "end": "971770"
  },
  {
    "text": "particularly if you use the s3 upload as",
    "start": "971770",
    "end": "974260"
  },
  {
    "text": "opposed to like trying to do it from the",
    "start": "974260",
    "end": "976510"
  },
  {
    "text": "browser and also talk about some of the",
    "start": "976510",
    "end": "980200"
  },
  {
    "start": "977000",
    "end": "1051000"
  },
  {
    "text": "things we ran into with running ffmpeg",
    "start": "980200",
    "end": "983740"
  },
  {
    "text": "in particular so obviously if you're",
    "start": "983740",
    "end": "985690"
  },
  {
    "text": "doing multi processing in a Linux",
    "start": "985690",
    "end": "987370"
  },
  {
    "text": "environment you're probably talking",
    "start": "987370",
    "end": "988360"
  },
  {
    "text": "about forking and when you fork the",
    "start": "988360",
    "end": "991300"
  },
  {
    "text": "process you inherit everything from the",
    "start": "991300",
    "end": "993010"
  },
  {
    "text": "parent process which you might not",
    "start": "993010",
    "end": "994180"
  },
  {
    "text": "realize is that in lambda that that",
    "start": "994180",
    "end": "996580"
  },
  {
    "text": "parent process that you're running",
    "start": "996580",
    "end": "997690"
  },
  {
    "text": "actually includes some of the lambda",
    "start": "997690",
    "end": "1000090"
  },
  {
    "text": "sandbox that's running your code in so",
    "start": "1000090",
    "end": "1002190"
  },
  {
    "text": "in our particular case what we found is",
    "start": "1002190",
    "end": "1004140"
  },
  {
    "text": "that when we you know forked ffmpeg from",
    "start": "1004140",
    "end": "1006840"
  },
  {
    "text": "from our Python code it inherited a few",
    "start": "1006840",
    "end": "1009420"
  },
  {
    "text": "file descriptors from the lands of",
    "start": "1009420",
    "end": "1011130"
  },
  {
    "text": "sandbox in particular standard in we got",
    "start": "1011130",
    "end": "1013170"
  },
  {
    "text": "standard in an input that we weren't",
    "start": "1013170",
    "end": "1014340"
  },
  {
    "text": "expecting which you know caused a few",
    "start": "1014340",
    "end": "1015930"
  },
  {
    "text": "few bugs from time to time however we",
    "start": "1015930",
    "end": "1017580"
  },
  {
    "text": "obviously just fixed by ignoring",
    "start": "1017580",
    "end": "1018750"
  },
  {
    "text": "standard in you could close your file",
    "start": "1018750",
    "end": "1019950"
  },
  {
    "text": "descriptors but should be aware that if",
    "start": "1019950",
    "end": "1021330"
  },
  {
    "text": "you're running multi processing in",
    "start": "1021330",
    "end": "1022770"
  },
  {
    "text": "lambda you might end up with things in",
    "start": "1022770",
    "end": "1025079"
  },
  {
    "text": "your fork process that you didn't you",
    "start": "1025079",
    "end": "1027449"
  },
  {
    "text": "know manually create yourself and also",
    "start": "1027449",
    "end": "1030569"
  },
  {
    "text": "I'll talk about this in more detail but",
    "start": "1030570",
    "end": "1032870"
  },
  {
    "text": "if you're running multiple lambda",
    "start": "1032870",
    "end": "1034770"
  },
  {
    "text": "functions back-to-back there's a chance",
    "start": "1034770",
    "end": "1036209"
  },
  {
    "text": "that it reuses the containers which",
    "start": "1036209",
    "end": "1038160"
  },
  {
    "text": "means that if you didn't clean up a",
    "start": "1038160",
    "end": "1040439"
  },
  {
    "text": "process that you started in a previous",
    "start": "1040440",
    "end": "1041970"
  },
  {
    "text": "lambda execution it might persist to a",
    "start": "1041970",
    "end": "1044010"
  },
  {
    "text": "subsequent one so make sure that you",
    "start": "1044010",
    "end": "1045630"
  },
  {
    "text": "always clean up your process when you're",
    "start": "1045630",
    "end": "1047400"
  },
  {
    "text": "done including error cases that was the",
    "start": "1047400",
    "end": "1049410"
  },
  {
    "text": "you know obviously the one we missed so",
    "start": "1049410",
    "end": "1052740"
  },
  {
    "start": "1051000",
    "end": "1192000"
  },
  {
    "text": "now I'll talk about one of the reduce of",
    "start": "1052740",
    "end": "1054750"
  },
  {
    "text": "steps so after we've mapped our large",
    "start": "1054750",
    "end": "1057150"
  },
  {
    "text": "input file into a bunch of small chunks",
    "start": "1057150",
    "end": "1058800"
  },
  {
    "text": "and transfer them into",
    "start": "1058800",
    "end": "1059770"
  },
  {
    "text": "we will reduce them and one of the main",
    "start": "1059770",
    "end": "1063010"
  },
  {
    "text": "ones is to produce a single mp4 file for",
    "start": "1063010",
    "end": "1065290"
  },
  {
    "text": "for distribution here so the basic idea",
    "start": "1065290",
    "end": "1067750"
  },
  {
    "text": "here is we'll read in the TS chunks",
    "start": "1067750",
    "end": "1069310"
  },
  {
    "text": "combine them into the mp4 file and",
    "start": "1069310",
    "end": "1071380"
  },
  {
    "text": "upload to s3 so the challenge here is on",
    "start": "1071380",
    "end": "1073720"
  },
  {
    "text": "the opposite side",
    "start": "1073720",
    "end": "1074560"
  },
  {
    "text": "it's the output file which is too big as",
    "start": "1074560",
    "end": "1076570"
  },
  {
    "text": "opposed to the little input files so",
    "start": "1076570",
    "end": "1078640"
  },
  {
    "text": "there's not enough space to store it in",
    "start": "1078640",
    "end": "1080320"
  },
  {
    "text": "the temporary storage for lambda",
    "start": "1080320",
    "end": "1082810"
  },
  {
    "text": "but ffmpeg again meets us halfway here",
    "start": "1082810",
    "end": "1085600"
  },
  {
    "text": "because they support FTP and output but",
    "start": "1085600",
    "end": "1088150"
  },
  {
    "text": "the challenge here is that for the kind",
    "start": "1088150",
    "end": "1089800"
  },
  {
    "text": "of mp4 files we're producing after",
    "start": "1089800",
    "end": "1092140"
  },
  {
    "text": "writing most of the video content ffmpeg",
    "start": "1092140",
    "end": "1094180"
  },
  {
    "text": "wants to seek back to the beginning of",
    "start": "1094180",
    "end": "1095830"
  },
  {
    "text": "the file an instance of additional data",
    "start": "1095830",
    "end": "1097960"
  },
  {
    "text": "essentially like bookkeeping a location",
    "start": "1097960",
    "end": "1100360"
  },
  {
    "text": "of you know iframes for seek points and",
    "start": "1100360",
    "end": "1102220"
  },
  {
    "text": "whatnot but obviously this creates a",
    "start": "1102220",
    "end": "1104740"
  },
  {
    "text": "problem if we were planning to just like",
    "start": "1104740",
    "end": "1106870"
  },
  {
    "text": "upload the data as soon as it arrived",
    "start": "1106870",
    "end": "1108310"
  },
  {
    "text": "and not store it around because how do",
    "start": "1108310",
    "end": "1110500"
  },
  {
    "text": "we shift everything down to make space",
    "start": "1110500",
    "end": "1111610"
  },
  {
    "text": "for it so this is where our s3",
    "start": "1111610",
    "end": "1113470"
  },
  {
    "text": "multi-part upload comes in so what we",
    "start": "1113470",
    "end": "1115420"
  },
  {
    "text": "did is we built a FTP like adapter which",
    "start": "1115420",
    "end": "1118210"
  },
  {
    "text": "runs inside the lambda function third",
    "start": "1118210",
    "end": "1120040"
  },
  {
    "text": "way our cache ran inside the lambda",
    "start": "1120040",
    "end": "1121690"
  },
  {
    "text": "function and it adapts FTP input to an",
    "start": "1121690",
    "end": "1126010"
  },
  {
    "text": "s3 multi-part upload and then what we do",
    "start": "1126010",
    "end": "1128350"
  },
  {
    "text": "to handle this",
    "start": "1128350",
    "end": "1129670"
  },
  {
    "text": "stick back to the beginning and write",
    "start": "1129670",
    "end": "1130870"
  },
  {
    "text": "some additional data problem is we delay",
    "start": "1130870",
    "end": "1133360"
  },
  {
    "text": "uploading the first chunk so one of the",
    "start": "1133360",
    "end": "1135520"
  },
  {
    "text": "features of the multi-part upload is",
    "start": "1135520",
    "end": "1136930"
  },
  {
    "text": "that you don't have to upload all the",
    "start": "1136930",
    "end": "1138850"
  },
  {
    "text": "parts in sequence you can give them",
    "start": "1138850",
    "end": "1140530"
  },
  {
    "text": "numbers and start with two and then at",
    "start": "1140530",
    "end": "1142360"
  },
  {
    "text": "the very end come back and say oh by the",
    "start": "1142360",
    "end": "1143680"
  },
  {
    "text": "way here's part one and all your parts",
    "start": "1143680",
    "end": "1145210"
  },
  {
    "text": "don't have to be the same size either so",
    "start": "1145210",
    "end": "1147130"
  },
  {
    "text": "if you don't know how big part one is",
    "start": "1147130",
    "end": "1148810"
  },
  {
    "text": "because you're not sure what a fop goes",
    "start": "1148810",
    "end": "1151150"
  },
  {
    "text": "gonna go back and right you can just",
    "start": "1151150",
    "end": "1152380"
  },
  {
    "text": "wait until the very end until you know",
    "start": "1152380",
    "end": "1153790"
  },
  {
    "text": "so that's what we do here well now",
    "start": "1153790",
    "end": "1155800"
  },
  {
    "text": "ffmpeg will you know dutifully attempt",
    "start": "1155800",
    "end": "1157690"
  },
  {
    "text": "to shift all the data down after it's",
    "start": "1157690",
    "end": "1159220"
  },
  {
    "text": "gone back to the beginning and wrote but",
    "start": "1159220",
    "end": "1160420"
  },
  {
    "text": "in this case we can just lie just say",
    "start": "1160420",
    "end": "1162190"
  },
  {
    "text": "hey yeah here's some data and it Peretz",
    "start": "1162190",
    "end": "1164500"
  },
  {
    "text": "it back to us and it works so here's",
    "start": "1164500",
    "end": "1168160"
  },
  {
    "text": "another other reduced functions we do so",
    "start": "1168160",
    "end": "1170020"
  },
  {
    "text": "this is in particularly for producing",
    "start": "1170020",
    "end": "1173050"
  },
  {
    "text": "DRAM output for HLS so we read in our TS",
    "start": "1173050",
    "end": "1176050"
  },
  {
    "text": "chunks we've produced from the map",
    "start": "1176050",
    "end": "1177220"
  },
  {
    "text": "statement from the map functions and",
    "start": "1177220",
    "end": "1179230"
  },
  {
    "text": "then we combine them and encrypt them",
    "start": "1179230",
    "end": "1181360"
  },
  {
    "text": "and then upload the encrypted file to s3",
    "start": "1181360",
    "end": "1183730"
  },
  {
    "text": "we combine them for for cache efficiency",
    "start": "1183730",
    "end": "1185620"
  },
  {
    "text": "just so that the CDN only has one object",
    "start": "1185620",
    "end": "1189310"
  },
  {
    "text": "with a HLS",
    "start": "1189310",
    "end": "1191080"
  },
  {
    "text": "arrange playlists so the challenge here",
    "start": "1191080",
    "end": "1194260"
  },
  {
    "start": "1192000",
    "end": "1261000"
  },
  {
    "text": "was around the time it took for this",
    "start": "1194260",
    "end": "1196419"
  },
  {
    "text": "function to execute so while other",
    "start": "1196419",
    "end": "1197679"
  },
  {
    "text": "reductions would happen in a single you",
    "start": "1197679",
    "end": "1199779"
  },
  {
    "text": "know lambda function of the five-minute",
    "start": "1199779",
    "end": "1201970"
  },
  {
    "text": "limit just fine but in this particular",
    "start": "1201970",
    "end": "1204940"
  },
  {
    "text": "case the sample aes encryption you know",
    "start": "1204940",
    "end": "1208750"
  },
  {
    "text": "involves repackaging the TS stream and",
    "start": "1208750",
    "end": "1210669"
  },
  {
    "text": "it would take too long if for some of",
    "start": "1210669",
    "end": "1213399"
  },
  {
    "text": "the longer movies I wouldn't finish",
    "start": "1213399",
    "end": "1214510"
  },
  {
    "text": "within a single 5 minute function so we",
    "start": "1214510",
    "end": "1218019"
  },
  {
    "text": "ended up doing here was just daisy",
    "start": "1218019",
    "end": "1219640"
  },
  {
    "text": "changing daisy chaining a few lambda",
    "start": "1219640",
    "end": "1221860"
  },
  {
    "text": "functions together so if the first",
    "start": "1221860",
    "end": "1223809"
  },
  {
    "text": "function didn't finish the multi-part",
    "start": "1223809",
    "end": "1225669"
  },
  {
    "text": "upload it could actually serialize the",
    "start": "1225669",
    "end": "1227380"
  },
  {
    "text": "state of the multi-part upload pass that",
    "start": "1227380",
    "end": "1229539"
  },
  {
    "text": "along to a subsequent lambda function",
    "start": "1229539",
    "end": "1231220"
  },
  {
    "text": "which would resume the multi-part upload",
    "start": "1231220",
    "end": "1232870"
  },
  {
    "text": "and continue encrypting and concatenated",
    "start": "1232870",
    "end": "1234940"
  },
  {
    "text": "chunks so this worked pretty well just",
    "start": "1234940",
    "end": "1237940"
  },
  {
    "text": "one thing I'll mention here you may find",
    "start": "1237940",
    "end": "1240399"
  },
  {
    "text": "that in fact I expect you'll find that",
    "start": "1240399",
    "end": "1242679"
  },
  {
    "text": "your download and upload speeds aren't",
    "start": "1242679",
    "end": "1245200"
  },
  {
    "text": "aren't necessarily symmetric so make",
    "start": "1245200",
    "end": "1247000"
  },
  {
    "text": "sure that you have some way of",
    "start": "1247000",
    "end": "1247929"
  },
  {
    "text": "restricting download speeds if your",
    "start": "1247929",
    "end": "1249789"
  },
  {
    "text": "upload becomes the bottleneck because we",
    "start": "1249789",
    "end": "1251529"
  },
  {
    "text": "we had a few cases where we ran out of",
    "start": "1251529",
    "end": "1252940"
  },
  {
    "text": "memory just could be downloaded so much",
    "start": "1252940",
    "end": "1254320"
  },
  {
    "text": "that and you know we couldn't upload it",
    "start": "1254320",
    "end": "1256090"
  },
  {
    "text": "all in time so just have some back",
    "start": "1256090",
    "end": "1257380"
  },
  {
    "text": "pressure there if you end up doing",
    "start": "1257380",
    "end": "1258760"
  },
  {
    "text": "similar streaming processing so I'm",
    "start": "1258760",
    "end": "1263470"
  },
  {
    "start": "1261000",
    "end": "1344000"
  },
  {
    "text": "going to are like deployment and some of",
    "start": "1263470",
    "end": "1266350"
  },
  {
    "text": "our integration pipeline a bit here so",
    "start": "1266350",
    "end": "1268230"
  },
  {
    "text": "we build all of our lambda functions",
    "start": "1268230",
    "end": "1270730"
  },
  {
    "text": "inside docker containers mostly just for",
    "start": "1270730",
    "end": "1272649"
  },
  {
    "text": "reproducibility and so it's easier for",
    "start": "1272649",
    "end": "1274149"
  },
  {
    "text": "developers on different platforms to all",
    "start": "1274149",
    "end": "1275860"
  },
  {
    "text": "come up with the same result and with",
    "start": "1275860",
    "end": "1278440"
  },
  {
    "text": "the get shaw and a hash of the script",
    "start": "1278440",
    "end": "1281289"
  },
  {
    "text": "that we used to build the function in",
    "start": "1281289",
    "end": "1282580"
  },
  {
    "text": "the first place",
    "start": "1282580",
    "end": "1283299"
  },
  {
    "text": "end up being included in the name of the",
    "start": "1283299",
    "end": "1286840"
  },
  {
    "text": "zip file we generate this is our way of",
    "start": "1286840",
    "end": "1288490"
  },
  {
    "text": "attempting to get closer to an immutable",
    "start": "1288490",
    "end": "1290260"
  },
  {
    "text": "build concept and then once we have this",
    "start": "1290260",
    "end": "1292210"
  },
  {
    "text": "new zip that we're ready to upload to",
    "start": "1292210",
    "end": "1294460"
  },
  {
    "text": "lambda we actually don't immediately",
    "start": "1294460",
    "end": "1296289"
  },
  {
    "text": "replace you know the current version",
    "start": "1296289",
    "end": "1298299"
  },
  {
    "text": "that's running in production we create a",
    "start": "1298299",
    "end": "1299529"
  },
  {
    "text": "new version of the lambda function which",
    "start": "1299529",
    "end": "1301510"
  },
  {
    "text": "is you know fully functional we can run",
    "start": "1301510",
    "end": "1302980"
  },
  {
    "text": "tests against it and we do to make sure",
    "start": "1302980",
    "end": "1304840"
  },
  {
    "text": "that you know we included everything",
    "start": "1304840",
    "end": "1307299"
  },
  {
    "text": "we're supposed to include it's a good",
    "start": "1307299",
    "end": "1308620"
  },
  {
    "text": "binary whatnot we didn't make any",
    "start": "1308620",
    "end": "1310179"
  },
  {
    "text": "introduce any new regressions or",
    "start": "1310179",
    "end": "1311649"
  },
  {
    "text": "something and then once we're ready and",
    "start": "1311649",
    "end": "1313419"
  },
  {
    "text": "we're confident that function is good to",
    "start": "1313419",
    "end": "1314799"
  },
  {
    "text": "go we update the alias that we've used",
    "start": "1314799",
    "end": "1316510"
  },
  {
    "text": "in production to point to this new",
    "start": "1316510",
    "end": "1317919"
  },
  {
    "text": "version and that's actually when the new",
    "start": "1317919",
    "end": "1320020"
  },
  {
    "text": "code starts being run in production so a",
    "start": "1320020",
    "end": "1322389"
  },
  {
    "text": "little aside here maybe",
    "start": "1322389",
    "end": "1324450"
  },
  {
    "text": "little preachy but one of the nice",
    "start": "1324450",
    "end": "1325769"
  },
  {
    "text": "things about serverless architecture is",
    "start": "1325769",
    "end": "1327899"
  },
  {
    "text": "it makes you divide your code into small",
    "start": "1327899",
    "end": "1330600"
  },
  {
    "text": "sections with well-defined api's which",
    "start": "1330600",
    "end": "1332879"
  },
  {
    "text": "is kind of what you have to do to make",
    "start": "1332879",
    "end": "1334559"
  },
  {
    "text": "them testable in the first place",
    "start": "1334559",
    "end": "1336029"
  },
  {
    "text": "so if you do want a service architecture",
    "start": "1336029",
    "end": "1338249"
  },
  {
    "text": "definitely take advantage the fact that",
    "start": "1338249",
    "end": "1340289"
  },
  {
    "text": "your code doesn't have split up in a",
    "start": "1340289",
    "end": "1341999"
  },
  {
    "text": "nice way for testing so some just the",
    "start": "1341999",
    "end": "1345749"
  },
  {
    "start": "1344000",
    "end": "1450000"
  },
  {
    "text": "general learnings from lambda that we",
    "start": "1345749",
    "end": "1347460"
  },
  {
    "text": "came through while doing this I",
    "start": "1347460",
    "end": "1348600"
  },
  {
    "text": "mentioned this before briefly around",
    "start": "1348600",
    "end": "1349980"
  },
  {
    "text": "multiprocessing but reusing containers",
    "start": "1349980",
    "end": "1353220"
  },
  {
    "text": "can you know create a few additional",
    "start": "1353220",
    "end": "1355440"
  },
  {
    "text": "challenges as well so in addition to not",
    "start": "1355440",
    "end": "1357480"
  },
  {
    "text": "cleaning up extra processes which you",
    "start": "1357480",
    "end": "1359759"
  },
  {
    "text": "might have left over if lambda decides",
    "start": "1359759",
    "end": "1361950"
  },
  {
    "text": "to reuse a container you might also like",
    "start": "1361950",
    "end": "1365460"
  },
  {
    "text": "if you used any of the temporary disk",
    "start": "1365460",
    "end": "1366720"
  },
  {
    "text": "space it doesn't clear that for you so",
    "start": "1366720",
    "end": "1368759"
  },
  {
    "text": "make sure that you clean up that when",
    "start": "1368759",
    "end": "1370080"
  },
  {
    "text": "you're done same thing with memory so",
    "start": "1370080",
    "end": "1371460"
  },
  {
    "text": "the biggest thing here is if you have a",
    "start": "1371460",
    "end": "1372419"
  },
  {
    "text": "process that's eating a bunch of memory",
    "start": "1372419",
    "end": "1373889"
  },
  {
    "text": "too but depending on like what kind of",
    "start": "1373889",
    "end": "1375749"
  },
  {
    "text": "language you're using if it's some",
    "start": "1375749",
    "end": "1376950"
  },
  {
    "text": "garbage question language and created a",
    "start": "1376950",
    "end": "1378299"
  },
  {
    "text": "bunch of big objects in memory you you",
    "start": "1378299",
    "end": "1381570"
  },
  {
    "text": "might run into problems if you've run a",
    "start": "1381570",
    "end": "1383639"
  },
  {
    "text": "bunch of functions back-to-back with",
    "start": "1383639",
    "end": "1384899"
  },
  {
    "text": "cumulative memory usage and then the",
    "start": "1384899",
    "end": "1387809"
  },
  {
    "text": "last thing I'll mention is that we",
    "start": "1387809",
    "end": "1389789"
  },
  {
    "text": "obviously with the s3 cash and the FTP",
    "start": "1389789",
    "end": "1393379"
  },
  {
    "text": "adapter we ended up you know binding to",
    "start": "1393379",
    "end": "1395909"
  },
  {
    "text": "ports and so make sure that if you're if",
    "start": "1395909",
    "end": "1398129"
  },
  {
    "text": "you're binding to a static port but you",
    "start": "1398129",
    "end": "1399840"
  },
  {
    "text": "release that socket or you know the",
    "start": "1399840",
    "end": "1402779"
  },
  {
    "text": "program ends or or in our case we just",
    "start": "1402779",
    "end": "1404609"
  },
  {
    "text": "let the OS pick a socket randomly so",
    "start": "1404609",
    "end": "1406679"
  },
  {
    "text": "that we didn't they don't have to deal",
    "start": "1406679",
    "end": "1407879"
  },
  {
    "text": "with that but either way so if you're",
    "start": "1407879",
    "end": "1410220"
  },
  {
    "text": "doing multi processing and lambda and",
    "start": "1410220",
    "end": "1412559"
  },
  {
    "text": "you know it's not working or you're",
    "start": "1412559",
    "end": "1413850"
  },
  {
    "text": "running into bugs the sandbox actually",
    "start": "1413850",
    "end": "1415830"
  },
  {
    "text": "has a bunch of common Linux utilities",
    "start": "1415830",
    "end": "1417179"
  },
  {
    "text": "you can just use so you can spawn PS or",
    "start": "1417179",
    "end": "1419369"
  },
  {
    "text": "top the logs will show up in cloud watch",
    "start": "1419369",
    "end": "1421679"
  },
  {
    "text": "and you can check out what's happening",
    "start": "1421679",
    "end": "1422789"
  },
  {
    "text": "inside your function is if it was a",
    "start": "1422789",
    "end": "1423929"
  },
  {
    "text": "little virtual machine because it pretty",
    "start": "1423929",
    "end": "1425399"
  },
  {
    "text": "much is I and one last bit here",
    "start": "1425399",
    "end": "1428600"
  },
  {
    "text": "especially if you have any i/o involved",
    "start": "1428600",
    "end": "1430889"
  },
  {
    "text": "you know you're uploading downloading do",
    "start": "1430889",
    "end": "1432239"
  },
  {
    "text": "anything like that just be aware that",
    "start": "1432239",
    "end": "1434039"
  },
  {
    "text": "you're a function run time might be",
    "start": "1434039",
    "end": "1435690"
  },
  {
    "text": "variable so for us we'd run into",
    "start": "1435690",
    "end": "1437879"
  },
  {
    "text": "situations where you know a function was",
    "start": "1437879",
    "end": "1440279"
  },
  {
    "text": "time out in five minutes but we retry it",
    "start": "1440279",
    "end": "1442259"
  },
  {
    "text": "again and it works and you know three or",
    "start": "1442259",
    "end": "1444359"
  },
  {
    "text": "two minutes so just just be prepared to",
    "start": "1444359",
    "end": "1446489"
  },
  {
    "text": "retry functions that may occasionally",
    "start": "1446489",
    "end": "1448470"
  },
  {
    "text": "timeout so here are some numbers to go",
    "start": "1448470",
    "end": "1453149"
  },
  {
    "start": "1450000",
    "end": "1539000"
  },
  {
    "text": "along with these results so",
    "start": "1453149",
    "end": "1456460"
  },
  {
    "text": "just a sort of proof that it wasn't just",
    "start": "1456460",
    "end": "1458530"
  },
  {
    "text": "a you know proof of concept we have a",
    "start": "1458530",
    "end": "1460630"
  },
  {
    "text": "hundred fifty thousand hours of",
    "start": "1460630",
    "end": "1462130"
  },
  {
    "text": "transcript of video through this system",
    "start": "1462130",
    "end": "1464130"
  },
  {
    "text": "using well now well over 400 million",
    "start": "1464130",
    "end": "1467500"
  },
  {
    "text": "lambda function invocations so the cost",
    "start": "1467500",
    "end": "1470410"
  },
  {
    "text": "savings it's a little bit hard to",
    "start": "1470410",
    "end": "1472990"
  },
  {
    "text": "compare apples to apples but what I'll",
    "start": "1472990",
    "end": "1474340"
  },
  {
    "text": "do is I'll say that if we wanted similar",
    "start": "1474340",
    "end": "1476050"
  },
  {
    "text": "on-demand ec2 capacity so two thousand",
    "start": "1476050",
    "end": "1478390"
  },
  {
    "text": "cores of you know c4 family ec2 capacity",
    "start": "1478390",
    "end": "1481030"
  },
  {
    "text": "it would cost us about 60 K a month for",
    "start": "1481030",
    "end": "1484630"
  },
  {
    "text": "on-demand ec2 instances like that but we",
    "start": "1484630",
    "end": "1487090"
  },
  {
    "text": "get access to that same scale for an",
    "start": "1487090",
    "end": "1489430"
  },
  {
    "text": "average monthly bill of 6 K now",
    "start": "1489430",
    "end": "1492910"
  },
  {
    "text": "obviously if we transmit a bunch of",
    "start": "1492910",
    "end": "1494440"
  },
  {
    "text": "videos that'll go up if we don't it goes",
    "start": "1494440",
    "end": "1495760"
  },
  {
    "text": "down but just as a general ballpark for",
    "start": "1495760",
    "end": "1498700"
  },
  {
    "text": "a port we're looking at in terms of cost",
    "start": "1498700",
    "end": "1500140"
  },
  {
    "text": "savings there and then of course is the",
    "start": "1500140",
    "end": "1501910"
  },
  {
    "text": "you know the the title of the",
    "start": "1501910",
    "end": "1503710"
  },
  {
    "text": "presentation mentioned because we're",
    "start": "1503710",
    "end": "1506770"
  },
  {
    "text": "only limited in terms of like the time a",
    "start": "1506770",
    "end": "1509770"
  },
  {
    "text": "single map takes so because we can run a",
    "start": "1509770",
    "end": "1511720"
  },
  {
    "text": "ton of maps in parallel and we have",
    "start": "1511720",
    "end": "1513940"
  },
  {
    "text": "2,000 cores",
    "start": "1513940",
    "end": "1514720"
  },
  {
    "text": "we can actually take it to our movie and",
    "start": "1514720",
    "end": "1516460"
  },
  {
    "text": "process each five-second chunk at the",
    "start": "1516460",
    "end": "1518410"
  },
  {
    "text": "same time so this means that our time to",
    "start": "1518410",
    "end": "1520450"
  },
  {
    "text": "transcode a full video goes from you",
    "start": "1520450",
    "end": "1522520"
  },
  {
    "text": "know the time of transcript of the whole",
    "start": "1522520",
    "end": "1523690"
  },
  {
    "text": "thing to just transcoding 5 seconds of",
    "start": "1523690",
    "end": "1525730"
  },
  {
    "text": "it plus any of the reductions that we",
    "start": "1525730",
    "end": "1527500"
  },
  {
    "text": "need to do so easily within 10 minutes",
    "start": "1527500",
    "end": "1530380"
  },
  {
    "text": "there or or usually fewer if we're you",
    "start": "1530380",
    "end": "1533710"
  },
  {
    "text": "know if we put the whole capacity",
    "start": "1533710",
    "end": "1535990"
  },
  {
    "text": "against a single file so just a few",
    "start": "1535990",
    "end": "1541120"
  },
  {
    "start": "1539000",
    "end": "1681000"
  },
  {
    "text": "final thoughts that I'll wrap up with in",
    "start": "1541120",
    "end": "1542920"
  },
  {
    "text": "terms of you know and things we've",
    "start": "1542920",
    "end": "1544690"
  },
  {
    "text": "learned things you might do differently",
    "start": "1544690",
    "end": "1545770"
  },
  {
    "text": "so one of the limitations of this is",
    "start": "1545770",
    "end": "1548560"
  },
  {
    "text": "that you do in fact only have you know",
    "start": "1548560",
    "end": "1550930"
  },
  {
    "text": "five minutes so if you wanted to do some",
    "start": "1550930",
    "end": "1552760"
  },
  {
    "text": "particularly fancy video processing or",
    "start": "1552760",
    "end": "1554770"
  },
  {
    "text": "like you know 4k 60fps from a really",
    "start": "1554770",
    "end": "1558100"
  },
  {
    "text": "uncompressed source you might not have",
    "start": "1558100",
    "end": "1559420"
  },
  {
    "text": "time to do it all in the 5 minutes",
    "start": "1559420",
    "end": "1561460"
  },
  {
    "text": "depending on your chunk size of course",
    "start": "1561460",
    "end": "1562900"
  },
  {
    "text": "and another limitation there's something",
    "start": "1562900",
    "end": "1566590"
  },
  {
    "text": "to be aware of is that to decode a",
    "start": "1566590",
    "end": "1568570"
  },
  {
    "text": "five-second chunk in the middle of video",
    "start": "1568570",
    "end": "1570070"
  },
  {
    "text": "without you know processing the all the",
    "start": "1570070",
    "end": "1572770"
  },
  {
    "text": "previous bytes you have to be able to",
    "start": "1572770",
    "end": "1574300"
  },
  {
    "text": "efficiently seek now we have you know",
    "start": "1574300",
    "end": "1576520"
  },
  {
    "text": "take an input from a ton of different",
    "start": "1576520",
    "end": "1577930"
  },
  {
    "text": "you know vendors and you know major",
    "start": "1577930",
    "end": "1580360"
  },
  {
    "text": "studios to you know mom-and-pop shops",
    "start": "1580360",
    "end": "1582340"
  },
  {
    "text": "and we haven't run into a format yet",
    "start": "1582340",
    "end": "1583990"
  },
  {
    "text": "that we weren't able to do this with but",
    "start": "1583990",
    "end": "1585520"
  },
  {
    "text": "it's a guess theoretically possible that",
    "start": "1585520",
    "end": "1587110"
  },
  {
    "text": "you'll find a format where you can't",
    "start": "1587110",
    "end": "1588610"
  },
  {
    "text": "just like you know",
    "start": "1588610",
    "end": "1589670"
  },
  {
    "text": "by trained requests to the middle and",
    "start": "1589670",
    "end": "1590930"
  },
  {
    "text": "figure out where you are well enough to",
    "start": "1590930",
    "end": "1592880"
  },
  {
    "text": "to chop out like a five-second chunk in",
    "start": "1592880",
    "end": "1595100"
  },
  {
    "text": "the middle and then just as a you know",
    "start": "1595100",
    "end": "1597710"
  },
  {
    "text": "obviously a general note there is a",
    "start": "1597710",
    "end": "1599600"
  },
  {
    "text": "slightly higher cost per CPU hour on",
    "start": "1599600",
    "end": "1602450"
  },
  {
    "text": "lamb compared directly to ec2 and with",
    "start": "1602450",
    "end": "1605600"
  },
  {
    "text": "our particular approach there's also",
    "start": "1605600",
    "end": "1606860"
  },
  {
    "text": "some decoding overhead in the sense that",
    "start": "1606860",
    "end": "1608960"
  },
  {
    "text": "each of those map steps which is",
    "start": "1608960",
    "end": "1610700"
  },
  {
    "text": "produced in just a five-second chunk has",
    "start": "1610700",
    "end": "1612260"
  },
  {
    "text": "to do some decoding work which is",
    "start": "1612260",
    "end": "1613880"
  },
  {
    "text": "repeated across so they all have to sort",
    "start": "1613880",
    "end": "1616370"
  },
  {
    "text": "of figure out okay I have you know two",
    "start": "1616370",
    "end": "1618800"
  },
  {
    "text": "streams for for audio and one stream for",
    "start": "1618800",
    "end": "1621050"
  },
  {
    "text": "video and do some general like decoding",
    "start": "1621050",
    "end": "1622910"
  },
  {
    "text": "of the initial metadata of the file that",
    "start": "1622910",
    "end": "1624170"
  },
  {
    "text": "in theory is a little bit repeated among",
    "start": "1624170",
    "end": "1626300"
  },
  {
    "text": "the different steps so a little bit of",
    "start": "1626300",
    "end": "1627500"
  },
  {
    "text": "overhead there so in the future we'd",
    "start": "1627500",
    "end": "1630230"
  },
  {
    "text": "like to support more output formats",
    "start": "1630230",
    "end": "1631820"
  },
  {
    "text": "we're sort of eagerly awaiting you know",
    "start": "1631820",
    "end": "1634130"
  },
  {
    "text": "iOS and Android OS adoptions that we can",
    "start": "1634130",
    "end": "1636200"
  },
  {
    "text": "eventually move to just a single source",
    "start": "1636200",
    "end": "1637880"
  },
  {
    "text": "for for both those guys and better",
    "start": "1637880",
    "end": "1640760"
  },
  {
    "text": "efficiency for small files what I mean",
    "start": "1640760",
    "end": "1642530"
  },
  {
    "text": "here is just for simple you know to",
    "start": "1642530",
    "end": "1644300"
  },
  {
    "text": "simplify the problem for us we produce",
    "start": "1644300",
    "end": "1646580"
  },
  {
    "text": "one TS chunk for each map function we",
    "start": "1646580",
    "end": "1649550"
  },
  {
    "text": "run but since the function can run for",
    "start": "1649550",
    "end": "1651290"
  },
  {
    "text": "five minutes and you know when we're",
    "start": "1651290",
    "end": "1652520"
  },
  {
    "text": "doing the smaller bit rates it takes you",
    "start": "1652520",
    "end": "1653960"
  },
  {
    "text": "know just a few seconds to produce a",
    "start": "1653960",
    "end": "1655370"
  },
  {
    "text": "five-second chunk there's no reason we",
    "start": "1655370",
    "end": "1657440"
  },
  {
    "text": "just have to produce you know one",
    "start": "1657440",
    "end": "1658790"
  },
  {
    "text": "five-second chunk in each map function",
    "start": "1658790",
    "end": "1660260"
  },
  {
    "text": "so we could save some of that decoding",
    "start": "1660260",
    "end": "1661520"
  },
  {
    "text": "overhead and produce multiple but that's",
    "start": "1661520",
    "end": "1663200"
  },
  {
    "text": "more of an optimization since lambdas",
    "start": "1663200",
    "end": "1665060"
  },
  {
    "text": "build down to the tenth of a second I",
    "start": "1665060",
    "end": "1666770"
  },
  {
    "text": "think it's not really doesn't really",
    "start": "1666770",
    "end": "1668270"
  },
  {
    "text": "bite us too much there okay thank you",
    "start": "1668270",
    "end": "1672800"
  },
  {
    "text": "all for coming today I think we'll take",
    "start": "1672800",
    "end": "1674300"
  },
  {
    "text": "a few questions okay thanks",
    "start": "1674300",
    "end": "1677030"
  },
  {
    "text": "[Applause]",
    "start": "1677030",
    "end": "1680760"
  },
  {
    "text": "so",
    "start": "1680760",
    "end": "1683760"
  }
]
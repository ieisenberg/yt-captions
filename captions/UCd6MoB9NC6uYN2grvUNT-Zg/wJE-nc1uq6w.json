[
  {
    "start": "0",
    "end": "128000"
  },
  {
    "text": "very good morning to everybody who's joined today this is Ross Evansville marketing lead for the UK public sector",
    "start": "12530",
    "end": "20130"
  },
  {
    "text": "here at AWS really pleased to have you join us for today's part two of our data lifecycle series which was entitled",
    "start": "20130",
    "end": "26720"
  },
  {
    "text": "preparing your data for cloud analytics and AI and m/l I'm super pleased to",
    "start": "26720",
    "end": "33930"
  },
  {
    "text": "introduce a beer Roy Chowdhury who is a technical business development manager",
    "start": "33930",
    "end": "39210"
  },
  {
    "text": "here at AWS and a specialist in all things data warehousing storage databases data preparation and all the",
    "start": "39210",
    "end": "46620"
  },
  {
    "text": "good things you want to hear about today and sitting with me behind the scenes got Charlie Llewellyn from our solution",
    "start": "46620",
    "end": "52229"
  },
  {
    "text": "architects team he is going to be manning the Q&A so do feel free to ask",
    "start": "52229",
    "end": "57329"
  },
  {
    "text": "some questions that might occur to you during the course of today there's a an actual widget as part of the GoToWebinar",
    "start": "57329",
    "end": "64549"
  },
  {
    "text": "software that allows you to ask questions so please feel free to do that and we'll make sure we are answer those",
    "start": "64549",
    "end": "70260"
  },
  {
    "text": "as we go and if there's anything really cool and pertinent and challenging what we'll do is we'll we'll call those out",
    "start": "70260",
    "end": "75690"
  },
  {
    "text": "at the end and we'll put them to appear live at the end of the session so that's enough for me",
    "start": "75690",
    "end": "80930"
  },
  {
    "text": "very warm welcome to a bit it's over to you sir thanks Ross for the introduction",
    "start": "80930",
    "end": "86820"
  },
  {
    "text": "and thank you very much everyone for spending your valuable time for this session so good morning yeah so this",
    "start": "86820",
    "end": "94050"
  },
  {
    "text": "session is really designed for introductory levels on AWS analytic services and how to really bring them",
    "start": "94050",
    "end": "100230"
  },
  {
    "text": "together picking the right analytical engine is not always an easy task and this webinar",
    "start": "100230",
    "end": "106560"
  },
  {
    "text": "will provide you with a structured approach and while exploring AWS services on the way we offer a range of",
    "start": "106560",
    "end": "114030"
  },
  {
    "text": "analytical engines to match you of several use cases and that could address big data processing data warehousing a",
    "start": "114030",
    "end": "121110"
  },
  {
    "text": "doc analysis or real-time streaming or even look and that it takes so before we",
    "start": "121110",
    "end": "128519"
  },
  {
    "start": "128000",
    "end": "128000"
  },
  {
    "text": "start just a quick overview of the agenda you know we will look at the",
    "start": "128519",
    "end": "133860"
  },
  {
    "text": "public sector situation give you an overview of what feedback we receive from our public sector customers what",
    "start": "133860",
    "end": "139740"
  },
  {
    "text": "blockers and challenges they face and I'll walk you through the data lifecycle process and theory and we will",
    "start": "139740",
    "end": "146600"
  },
  {
    "text": "explore AWS services on the way that could help you and then we will show you a quick demo on how all those elements",
    "start": "146600",
    "end": "153140"
  },
  {
    "text": "really come together it's really a simple demo for which we will use an open data set with climate data that's",
    "start": "153140",
    "end": "160400"
  },
  {
    "text": "provided by Cornell through our AWS open data platform after that I will briefly",
    "start": "160400",
    "end": "166610"
  },
  {
    "text": "touch on some customer references and talk about best practices to secure your",
    "start": "166610",
    "end": "171980"
  },
  {
    "text": "data lag and end with some architectural guidelines before I open up the webinar",
    "start": "171980",
    "end": "177050"
  },
  {
    "text": "for answering more questions so what do",
    "start": "177050",
    "end": "183230"
  },
  {
    "start": "183000",
    "end": "183000"
  },
  {
    "text": "we actually observe in public sector many of our customers report that data",
    "start": "183230",
    "end": "188660"
  },
  {
    "text": "is dispersed and difficult to access so when it comes to looking at the data and",
    "start": "188660",
    "end": "194990"
  },
  {
    "text": "ask questions we see that business have a very siloed approach so a datasource per datasource approach so for example",
    "start": "194990",
    "end": "203480"
  },
  {
    "text": "we see typically a relational database where users are querying a specific data set or in a different instance data is",
    "start": "203480",
    "end": "211970"
  },
  {
    "text": "extracted from that relational database and loaded into a data warehouse and if",
    "start": "211970",
    "end": "218330"
  },
  {
    "text": "you do any more type of analytics that usually happens in isolation so",
    "start": "218330",
    "end": "223900"
  },
  {
    "text": "businesses are really struggling to bring different data sources together and as they have different formats",
    "start": "223900",
    "end": "230780"
  },
  {
    "text": "you know summer at rests on my motion it really becomes difficult to join them up",
    "start": "230780",
    "end": "235820"
  },
  {
    "text": "and ask more elaborate questions however if you can overcome the challenge you can enable your business with some",
    "start": "235820",
    "end": "242330"
  },
  {
    "text": "really valuable insight I give you a quick example one of our customers FINRA who is a financial regulator in the u.s.",
    "start": "242330",
    "end": "249220"
  },
  {
    "text": "ingested the unstructured data in form of documents or brokerage reports into",
    "start": "249220",
    "end": "255350"
  },
  {
    "text": "the AWS data Lake which allowed them to convert the data into relational data",
    "start": "255350",
    "end": "262400"
  },
  {
    "text": "using Amazon comprehend which is a natural language processing data service",
    "start": "262400",
    "end": "270590"
  },
  {
    "text": "powered by machine learning so suddenly you transform the static assets static archive type data into",
    "start": "270590",
    "end": "277860"
  },
  {
    "text": "valuable 8a data where you can perform sentiment analysis or entity extraction",
    "start": "277860",
    "end": "283279"
  },
  {
    "text": "so businesses report that they have a limited view on what's going on in the",
    "start": "283279",
    "end": "288479"
  },
  {
    "text": "business and so most business queries are run on historical information so",
    "start": "288479",
    "end": "294599"
  },
  {
    "text": "typical bi business intelligence type information from a siloed resource the",
    "start": "294599",
    "end": "300180"
  },
  {
    "text": "customers want to now use more advanced analytics to recognize patterns and make",
    "start": "300180",
    "end": "305580"
  },
  {
    "text": "predictions to use analytics in the decision-making really to anticipate",
    "start": "305580",
    "end": "311340"
  },
  {
    "text": "what may happen in their business but the top two bullet points are usually",
    "start": "311340",
    "end": "316610"
  },
  {
    "text": "related to the third one which is resource constraints and by that I don't just mean IT assets that's also related",
    "start": "316610",
    "end": "324150"
  },
  {
    "text": "to personnel so doing anything beyond the usual day-to-day business is limited",
    "start": "324150",
    "end": "330150"
  },
  {
    "text": "by you know people's time and focus which is sometimes invested on the daily",
    "start": "330150",
    "end": "335159"
  },
  {
    "text": "firefighting so implementing a more sophisticated infrastructure environment is strongly kappa'd coupled with capital",
    "start": "335159",
    "end": "343740"
  },
  {
    "text": "investment and complexity in in order to provision those so I give you a",
    "start": "343740",
    "end": "349919"
  },
  {
    "text": "different example where a customer was trying to set up an on-premise ado cluster to do some batch processing on",
    "start": "349919",
    "end": "356909"
  },
  {
    "text": "their large data sets just setting up the batch the Hadoop cluster would take",
    "start": "356909",
    "end": "361979"
  },
  {
    "text": "them several weeks to months so to the point where you it takes a long time to",
    "start": "361979",
    "end": "368580"
  },
  {
    "text": "get your cluster operational and running and create really business value tasks",
    "start": "368580",
    "end": "373740"
  },
  {
    "text": "so there's a great community available around those open source technologies but it doesn't sometimes match the time",
    "start": "373740",
    "end": "381750"
  },
  {
    "text": "to market objective also think about queries that only run for a short period",
    "start": "381750",
    "end": "387389"
  },
  {
    "text": "of time so data scientists running queries to find results for the hypothesis maybe only for sheep short",
    "start": "387389",
    "end": "394949"
  },
  {
    "text": "period of time and between those periods you know you have a system being idle",
    "start": "394949",
    "end": "401180"
  },
  {
    "text": "there are many great open source products available but building your own DIY",
    "start": "401180",
    "end": "406529"
  },
  {
    "text": "Ellucian may be time-consuming and very costly so all those challenges the first",
    "start": "406529",
    "end": "413339"
  },
  {
    "text": "three are in also true in the enterprise world but I think the one thing which is",
    "start": "413339",
    "end": "420889"
  },
  {
    "text": "important in the public sector is governance and compliance so this is",
    "start": "420979",
    "end": "426119"
  },
  {
    "text": "really about the ability to ensure who is accessing your resources and apps has",
    "start": "426119",
    "end": "432119"
  },
  {
    "text": "the right Authority and monitoring and auditing data access patterns and you",
    "start": "432119",
    "end": "437939"
  },
  {
    "text": "know alerting you when there is malicious activity and the platform itself you know should protect you",
    "start": "437939",
    "end": "444029"
  },
  {
    "text": "against corruption deletion and manipulation so in Everton tlie or maliciously and",
    "start": "444029",
    "end": "449279"
  },
  {
    "text": "this is really about you know the ability ensure that all those services used in the process meet your compliance",
    "start": "449279",
    "end": "456089"
  },
  {
    "text": "certification requirements as well so this is really to quickly frame up the",
    "start": "456089",
    "end": "461189"
  },
  {
    "text": "challenges we face so what is the Big Data challenge so first of all the Big",
    "start": "461189",
    "end": "467759"
  },
  {
    "text": "Data challenge is a data management challenge and which we identify by the",
    "start": "467759",
    "end": "473219"
  },
  {
    "text": "three vs the first being volume that could range from terabytes to exercise",
    "start": "473219",
    "end": "479549"
  },
  {
    "text": "petabytes of data and need why do we need those large data sets well we sometimes need large data sets",
    "start": "479549",
    "end": "486179"
  },
  {
    "text": "to Train an accurate model and get accurate results and some examples could",
    "start": "486179",
    "end": "492389"
  },
  {
    "text": "be human genetics population stats climate data or even high-res images",
    "start": "492389",
    "end": "497959"
  },
  {
    "text": "what solution requirement does this impose well you need a solution that can",
    "start": "497959",
    "end": "504449"
  },
  {
    "text": "help you offline process that large data set but you also need the capability to transport those that large data sets",
    "start": "504449",
    "end": "511109"
  },
  {
    "text": "across and sometimes you just want to extract the information that is valuable",
    "start": "511109",
    "end": "516448"
  },
  {
    "text": "to you the second one being variety so we touched on different sources",
    "start": "516449",
    "end": "521879"
  },
  {
    "text": "you know dispersed and it is really about bringing those different sources and formats together so that could be",
    "start": "521879",
    "end": "528209"
  },
  {
    "text": "data at rest data in ocean from semi to structured and unstructured data here",
    "start": "528209",
    "end": "534059"
  },
  {
    "text": "think about Askia JSON binary data",
    "start": "534059",
    "end": "539569"
  },
  {
    "text": "example data could be anything from a database to documents and the solution requirement is really bringing those",
    "start": "539660",
    "end": "545510"
  },
  {
    "text": "together the third one on this list here is velocity and this has a real",
    "start": "545510",
    "end": "551000"
  },
  {
    "text": "interesting characteristic because it has a stringent requirement from the time the data is created created to the",
    "start": "551000",
    "end": "557390"
  },
  {
    "text": "time you know you get actionable insight so the expiry of the data set is very",
    "start": "557390",
    "end": "562520"
  },
  {
    "text": "relevant and the use case is really stream data think about IOT that is",
    "start": "562520",
    "end": "567830"
  },
  {
    "text": "created you know at high speed and only relevant for a short period and the",
    "start": "567830",
    "end": "573320"
  },
  {
    "text": "solution requirement it really creates is to capture that stream data and being",
    "start": "573320",
    "end": "579500"
  },
  {
    "text": "able to run either real-time analytics on that data or save it for offline processing later on so if you look at",
    "start": "579500",
    "end": "586970"
  },
  {
    "text": "these V's when your data comes available it is it is sometimes large and complex",
    "start": "586970",
    "end": "595370"
  },
  {
    "text": "to process so you have to start innovating how you collect store and process and analyze and share the data",
    "start": "595370",
    "end": "604839"
  },
  {
    "start": "605000",
    "end": "605000"
  },
  {
    "text": "very quickly I mean there is a lot of noise in the market around big data",
    "start": "606070",
    "end": "611690"
  },
  {
    "text": "analytics a lot of market analysts reports shared by IDC Gartner and",
    "start": "611690",
    "end": "617720"
  },
  {
    "text": "Forrester but one I want to pick out here is around you know data warehouse",
    "start": "617720",
    "end": "623210"
  },
  {
    "text": "and data Lake in the cloud and BI platform in the cloud at the top three types of technologies enterprise are",
    "start": "623210",
    "end": "628670"
  },
  {
    "text": "planning to use so that may match with your objective as well but we're",
    "start": "628670",
    "end": "633980"
  },
  {
    "text": "actually interested to hear your motivation and you know what your individual plans and challenges are so",
    "start": "633980",
    "end": "640640"
  },
  {
    "text": "you know please feedback to us through your contacts or through the email at the end of this presentation so you know",
    "start": "640640",
    "end": "647510"
  },
  {
    "text": "we can see how we can plan to help you",
    "start": "647510",
    "end": "652750"
  },
  {
    "text": "so let's with the data lifecycle so when we think",
    "start": "652750",
    "end": "658140"
  },
  {
    "start": "653000",
    "end": "653000"
  },
  {
    "text": "about a data lifecycle project regardless of what data system you're building there is always a common",
    "start": "658140",
    "end": "664320"
  },
  {
    "text": "pattern you would follow so it could start with a bi system that builds on top of the data warehouse it could be a",
    "start": "664320",
    "end": "670650"
  },
  {
    "text": "distributed file system such as Hadoop that batch process is large files or you are enriching your data by asking more",
    "start": "670650",
    "end": "677610"
  },
  {
    "text": "elaborate questions with a machine learning application but the first questions you need to think about is you",
    "start": "677610",
    "end": "682710"
  },
  {
    "text": "know how do we get the data from our many sources and in traditional IT that's usually on-premise you know how",
    "start": "682710",
    "end": "691500"
  },
  {
    "text": "do we properly stage the data and apply the right housekeeping but also what level of cleansing does the data have to",
    "start": "691500",
    "end": "698340"
  },
  {
    "text": "go through before I can provide that data set to our users and how do you",
    "start": "698340",
    "end": "703710"
  },
  {
    "text": "drive analytics and visualization and create meaningful report for the decision-making so in the following",
    "start": "703710",
    "end": "710970"
  },
  {
    "text": "sections we're going to step through the cycle and we will you know mention some tools and services and illustrate the",
    "start": "710970",
    "end": "717870"
  },
  {
    "text": "theory in a very simple demo so the",
    "start": "717870",
    "end": "724350"
  },
  {
    "text": "first thing the first stage is really the data ingestion and this is about",
    "start": "724350",
    "end": "730820"
  },
  {
    "text": "mechanisms of moving the data and data sources include transactions here from",
    "start": "730820",
    "end": "738000"
  },
  {
    "text": "IP systems clickstream data lock files devices and think about you disparate",
    "start": "738000",
    "end": "745020"
  },
  {
    "text": "databases that needs to be migrated over and traditionally I mentioned that a lot",
    "start": "745020",
    "end": "750660"
  },
  {
    "text": "of these sources are on-premises so we need to think about the destination as well what is the destination is it some",
    "start": "750660",
    "end": "757170"
  },
  {
    "text": "sort of photo storage or a database and when we're retrieving you know data from",
    "start": "757170",
    "end": "763020"
  },
  {
    "text": "from a source at rest like relational database it's way different than from a source that is in",
    "start": "763020",
    "end": "768870"
  },
  {
    "text": "motion like a real-time click stream the data structure will influence the collection method you know I mentioned",
    "start": "768870",
    "end": "774810"
  },
  {
    "text": "structured data say me or a man structured data think about is the",
    "start": "774810",
    "end": "783270"
  },
  {
    "text": "source immutable so think about IOT telemetry data like temperature that changes over time",
    "start": "783270",
    "end": "789000"
  },
  {
    "text": "clickstream that is part of real time the collection methodology of uploading",
    "start": "789000",
    "end": "794250"
  },
  {
    "text": "batch data offline batch data is completely different as well so we mentioned Hadoop earlier so think about",
    "start": "794250",
    "end": "800670"
  },
  {
    "text": "a cluster that is idle for a long period of time and suddenly you know massive amounts of data are pushed through to",
    "start": "800670",
    "end": "807930"
  },
  {
    "text": "get some results so destination now",
    "start": "807930",
    "end": "813450"
  },
  {
    "text": "where is the destination is it going into a data warehouse is it populated into a data lake so in AWS terms that",
    "start": "813450",
    "end": "820200"
  },
  {
    "text": "would be an s3 object store or are we passing it through for further",
    "start": "820200",
    "end": "825270"
  },
  {
    "text": "downstream analytics ml for example so all these questions",
    "start": "825270",
    "end": "831690"
  },
  {
    "text": "need to be considered before really choosing the right tool for the right job and just one thing to remember as",
    "start": "831690",
    "end": "840030"
  },
  {
    "text": "well that these services are not mutually exclusive for a use case you know you can use those building blocks",
    "start": "840030",
    "end": "845340"
  },
  {
    "text": "in no particular order and one a point of advice is you know start with it",
    "start": "845340",
    "end": "851070"
  },
  {
    "text": "you know start with any order that is relevant to your business and your business priority so you could start",
    "start": "851070",
    "end": "856980"
  },
  {
    "text": "with the data Lake and add a data warehouse or vice versa and and you know and don't try to get all your data",
    "start": "856980",
    "end": "862770"
  },
  {
    "text": "sources in at once and match that to your business priority in our world we",
    "start": "862770",
    "end": "869070"
  },
  {
    "text": "like to take the MVP approach which is the minimal Viable Product so focus on",
    "start": "869070",
    "end": "874560"
  },
  {
    "text": "your first case that match your business priority and then move on to the next building block once you are successful",
    "start": "874560",
    "end": "881310"
  },
  {
    "text": "and you know once you get your cycle running and you see the business value you can really think about different use",
    "start": "881310",
    "end": "887610"
  },
  {
    "text": "cases and different functionalities so yeah don't get intimidated by the vast amount of services available focus on",
    "start": "887610",
    "end": "894630"
  },
  {
    "text": "the ones that serves you use case and you know you use the cloud advantage as well and experiment try those services",
    "start": "894630",
    "end": "901080"
  },
  {
    "text": "you know you can say they'll fast and unproven quickly there's no risk at you no cost you know so you're not losing",
    "start": "901080",
    "end": "907710"
  },
  {
    "text": "much investment further to the",
    "start": "907710",
    "end": "914570"
  },
  {
    "start": "912000",
    "end": "912000"
  },
  {
    "text": "Xion if we just look at the traditional sources we mentioned earlier and and I",
    "start": "914570",
    "end": "919640"
  },
  {
    "text": "said that most of them reside on premises so we need to think about how",
    "start": "919640",
    "end": "925640"
  },
  {
    "text": "we connect our on-premises environment to the clouds or establish the network connection from source to the target and",
    "start": "925640",
    "end": "931880"
  },
  {
    "text": "we offer services such as Direct Connect between sites and VPN for connection",
    "start": "931880",
    "end": "940100"
  },
  {
    "text": "tunneling to connect to your let's say on Prem EAP system just a word around",
    "start": "940100",
    "end": "946340"
  },
  {
    "text": "the databases we provide you provide you with a migration an assessment tool kit",
    "start": "946340",
    "end": "952940"
  },
  {
    "text": "which is made of DMS which stands for database migration service but it actually does a little bit more an SCT",
    "start": "952940",
    "end": "960050"
  },
  {
    "text": "so DMS it's an in summary and",
    "start": "960050",
    "end": "965090"
  },
  {
    "text": "heterogeneous replication engine that helps you you know copying your data from one schema to the other SCT is a",
    "start": "965090",
    "end": "974030"
  },
  {
    "text": "schema conversion tool and what you could do is really point your schema",
    "start": "974030",
    "end": "980660"
  },
  {
    "text": "conversion tool to your source and point it to your desired target and then you",
    "start": "980660",
    "end": "985790"
  },
  {
    "text": "can do an run an early assessment of to find out what complex a migration",
    "start": "985790",
    "end": "991670"
  },
  {
    "text": "complexity you're going to face it will give you a conversion auto conversion",
    "start": "991670",
    "end": "996680"
  },
  {
    "text": "rate ratio and and give you visibility of how much refactoring manual coding",
    "start": "996680",
    "end": "1003490"
  },
  {
    "text": "you are to expect of moving that workload it's worth mentioning that these tools work bi-directional so you",
    "start": "1003490",
    "end": "1010540"
  },
  {
    "text": "can even replicate out of AWS as well so",
    "start": "1010540",
    "end": "1015780"
  },
  {
    "text": "the other data types here on this list are around media big export files lock",
    "start": "1015780",
    "end": "1024760"
  },
  {
    "text": "files which are typical candidates for s3 object data so with large export",
    "start": "1024760",
    "end": "1030250"
  },
  {
    "text": "especially you know we see many ways to import the data via us 3 interface and",
    "start": "1030250",
    "end": "1035790"
  },
  {
    "text": "we have for the very large volumes which you know you want which challenges your",
    "start": "1035790",
    "end": "1042130"
  },
  {
    "text": "network connection we have device services available to you you may have",
    "start": "1042130",
    "end": "1047680"
  },
  {
    "text": "heard of you know the snowball and snowball edge devices where you can especially move large volumes of data and have I take",
    "start": "1047680",
    "end": "1055750"
  },
  {
    "text": "the pressure from your network links so if you look at the bottom right so when",
    "start": "1055750",
    "end": "1063940"
  },
  {
    "text": "it comes to the IOT sensors clickstream telemetry type data so we're looking at",
    "start": "1063940",
    "end": "1069430"
  },
  {
    "text": "stream data we are going to address that with our Kinesis suit software so",
    "start": "1069430",
    "end": "1077260"
  },
  {
    "text": "kinases data streams you can bring the streaming data in very effectively and kinases Maps it really nicely to your",
    "start": "1077260",
    "end": "1084130"
  },
  {
    "text": "scenario so now give you an example so when you define the data stream within Kinesis you're actually defining how",
    "start": "1084130",
    "end": "1090850"
  },
  {
    "text": "many records you are approximately expecting so let's say your IOT device is generating thousand records per",
    "start": "1090850",
    "end": "1096940"
  },
  {
    "text": "second you only need to worry about the record throughput so you configure the",
    "start": "1096940",
    "end": "1102010"
  },
  {
    "text": "parameter with a thousand records and should that change so let's say that increases to ten thousand you just",
    "start": "1102010",
    "end": "1109030"
  },
  {
    "text": "change that parameter and vice versa if you want to shrink it down you can just configure the parameter and the beauty",
    "start": "1109030",
    "end": "1114910"
  },
  {
    "text": "is you don't really have to worry about the network architecture or the compute",
    "start": "1114910",
    "end": "1120610"
  },
  {
    "text": "infrastructure that needs to facilitate that requirement yeah so we're leaving the heavy lifting to us now if you want",
    "start": "1120610",
    "end": "1129130"
  },
  {
    "text": "to take the data stream and save it and",
    "start": "1129130",
    "end": "1134290"
  },
  {
    "text": "process it process it later for you know offline processing you can use Kinesis data firehose so let's say you're",
    "start": "1134290",
    "end": "1141640"
  },
  {
    "text": "collecting your smart city IOT data and want to feed and train a machine learning model for advanced analytics",
    "start": "1141640",
    "end": "1147610"
  },
  {
    "text": "later you just set up your data for fire I'm sorry your data firehose collect the data using producer library such as",
    "start": "1147610",
    "end": "1154180"
  },
  {
    "text": "flume laughs - to publish in the fire hose and then fire hose takes the data and writes",
    "start": "1154180",
    "end": "1160270"
  },
  {
    "text": "it into your desired target that could be an s3 object store in your data Lake a data warehouse or even an",
    "start": "1160270",
    "end": "1166900"
  },
  {
    "text": "elasticsearch cluster so again fire house is doing all the heavy lifting once the data hits the pipe and stores",
    "start": "1166900",
    "end": "1174430"
  },
  {
    "text": "the data in the repository of your choice one popular collection",
    "start": "1174430",
    "end": "1180010"
  },
  {
    "text": "open-source tech ecology I'm in the market is Kafka and",
    "start": "1180010",
    "end": "1186100"
  },
  {
    "text": "last year our annual conference reinvent we introduced Amazon managed streaming",
    "start": "1186100",
    "end": "1193039"
  },
  {
    "text": "for Kafka which also takes all the heavy lifting away so for example you don't need to worry about standing up your own",
    "start": "1193039",
    "end": "1198919"
  },
  {
    "text": "brokers it provides multi a z4h a as many other AWS services do and all the",
    "start": "1198919",
    "end": "1207729"
  },
  {
    "text": "configurations that make Kafka enterprise and production great so just stand up your cluster in your V PC and",
    "start": "1207729",
    "end": "1215629"
  },
  {
    "text": "it's also different to kinases because kinases actually works on regional level",
    "start": "1215629",
    "end": "1222220"
  },
  {
    "text": "so I mentioned Kinesis so I mentioned IOT a lot and temperature",
    "start": "1222220",
    "end": "1229909"
  },
  {
    "text": "data telemetry data kinases also nicely integrates with our IOT services",
    "start": "1229909",
    "end": "1236090"
  },
  {
    "text": "available such as IOT core so you set up your IT broker which supports for",
    "start": "1236090",
    "end": "1242330"
  },
  {
    "text": "example the MQ GT protocol which is often used in resource constrained",
    "start": "1242330",
    "end": "1247429"
  },
  {
    "text": "devices and the broker receives the data stream and you can forward it to kinases via a horse or to multiple destinations",
    "start": "1247429",
    "end": "1254330"
  },
  {
    "text": "based on the rules you have defined so in summary the key thing is really these",
    "start": "1254330",
    "end": "1261470"
  },
  {
    "text": "are all loosely coupled architectures so we are following you know the micro service architecture the right tool for",
    "start": "1261470",
    "end": "1267049"
  },
  {
    "text": "the job approach and the way the data is really collected it depends on the",
    "start": "1267049",
    "end": "1273529"
  },
  {
    "text": "analytics that is required so let's stay",
    "start": "1273529",
    "end": "1280369"
  },
  {
    "start": "1278000",
    "end": "1278000"
  },
  {
    "text": "with real-time data movement for a second and review that architectural",
    "start": "1280369",
    "end": "1285590"
  },
  {
    "text": "diagram here so on the left hand side under one you can see we have producer",
    "start": "1285590",
    "end": "1292129"
  },
  {
    "text": "library so if you want you can use the Amazon AWS native one so there is an AWS",
    "start": "1292129",
    "end": "1298519"
  },
  {
    "text": "SDK the Kinesis producer library a mobile sdk as well however if you prefer",
    "start": "1298519",
    "end": "1304399"
  },
  {
    "text": "using an open-source product you can use log4j flume or flume t as well so that",
    "start": "1304399",
    "end": "1310249"
  },
  {
    "text": "option is available to you and when you start provisioning you know and pop",
    "start": "1310249",
    "end": "1315419"
  },
  {
    "text": "in your data Lake I gave you the example with Kinesis data streams where you can capture the records you can then use",
    "start": "1315419",
    "end": "1322109"
  },
  {
    "text": "firehose to save it for further processing and at that time you're",
    "start": "1322109",
    "end": "1327479"
  },
  {
    "text": "actually storing the data definition in AWS clew a glue which helps you to",
    "start": "1327479",
    "end": "1333179"
  },
  {
    "text": "catalog in your data and from there you know you can just start off different",
    "start": "1333179",
    "end": "1339839"
  },
  {
    "text": "processes so you can start processing your data offline with you know by triggering or triggering the creation of",
    "start": "1339839",
    "end": "1346200"
  },
  {
    "text": "environments let's say through a server less compute function represented by",
    "start": "1346200",
    "end": "1351329"
  },
  {
    "text": "lambda so that could be kicking off transient cluster that is created or you",
    "start": "1351329",
    "end": "1358229"
  },
  {
    "text": "use real-time analytics such as kinases data analytics or spark on EMR or even",
    "start": "1358229",
    "end": "1363869"
  },
  {
    "text": "if you have custom code available on your virtual Mis machine on ec2 instance so all these services give you like in",
    "start": "1363869",
    "end": "1371309"
  },
  {
    "text": "our first business insight before you attempt to create any architecture data flow that is important to focus on the",
    "start": "1371309",
    "end": "1378419"
  },
  {
    "text": "business problem now we talked about the right tool for the right job and they",
    "start": "1378419",
    "end": "1384329"
  },
  {
    "text": "are like all these different engines available to you so how do you select the right tool and how do you select the",
    "start": "1384329",
    "end": "1391379"
  },
  {
    "text": "right service so the two aspects you need to look into is a the data",
    "start": "1391379",
    "end": "1398459"
  },
  {
    "text": "structure and and the data access pattern so for sequel that would",
    "start": "1398459",
    "end": "1404459"
  },
  {
    "text": "translate into is the data highly normalized in a highly normalized table structure does it require a fixed schema",
    "start": "1404459",
    "end": "1410969"
  },
  {
    "text": "it's a schema on right and is the data processing based on an ETL approach",
    "start": "1410969",
    "end": "1416489"
  },
  {
    "text": "where the transform data is mapped to an existing schema or does it use a lot of",
    "start": "1416489",
    "end": "1421889"
  },
  {
    "text": "joins so all these questions help you to elaborate okay I need potentially a sequel server a sequel based platform",
    "start": "1421889",
    "end": "1429659"
  },
  {
    "text": "right so in terms of access patterns you know do we have multiple users reading",
    "start": "1429659",
    "end": "1435479"
  },
  {
    "text": "the same objects you could consider some in-memory technology are we talking",
    "start": "1435479",
    "end": "1441269"
  },
  {
    "text": "about key value stores which are great for storing data that needs to be quickly stored and queried so this could",
    "start": "1441269",
    "end": "1447929"
  },
  {
    "text": "include session data tracking data for car",
    "start": "1447929",
    "end": "1452970"
  },
  {
    "text": "locations for example or do you have telemetry data IOT temperature data",
    "start": "1452970",
    "end": "1458210"
  },
  {
    "text": "there is a time series database available which addresses the time",
    "start": "1458210",
    "end": "1463290"
  },
  {
    "text": "interval aspect so different data structures often define different types of storage and there's even more",
    "start": "1463290",
    "end": "1474980"
  },
  {
    "start": "1472000",
    "end": "1472000"
  },
  {
    "text": "parameters to consider but again if you want to start focus on the use case and",
    "start": "1474980",
    "end": "1480830"
  },
  {
    "text": "focus on the shape of the day if you need an append-only system of record",
    "start": "1480830",
    "end": "1487710"
  },
  {
    "text": "type application where you're not changing the actual record and only appending to it you probably want to",
    "start": "1487710",
    "end": "1493530"
  },
  {
    "text": "look in something like a ledger database where we offer an Amazon QL DB database and you can I'm not going to dive into",
    "start": "1493530",
    "end": "1500760"
  },
  {
    "text": "each of those categories here but you can you can you can get the idea of you know how to really approach it so use",
    "start": "1500760",
    "end": "1509250"
  },
  {
    "text": "cases shape is important but what's also really interesting is actually price and",
    "start": "1509250",
    "end": "1515220"
  },
  {
    "text": "price is an interesting indicator as prices are designed to against the use",
    "start": "1515220",
    "end": "1520800"
  },
  {
    "text": "case I'll give you an example if you're deciding not to use Kinesis data streams",
    "start": "1520800",
    "end": "1526680"
  },
  {
    "text": "to collect your clickstream data as previously described and you decide to",
    "start": "1526680",
    "end": "1533100"
  },
  {
    "text": "write individually to s3 so via put methodologies you may not experience the",
    "start": "1533100",
    "end": "1540420"
  },
  {
    "text": "same economics as using Kinesis data streams for it yeah so yes although the",
    "start": "1540420",
    "end": "1548100"
  },
  {
    "text": "use case is kind of matched against the pricing model so going back to our flow",
    "start": "1548100",
    "end": "1557790"
  },
  {
    "start": "1556000",
    "end": "1556000"
  },
  {
    "text": "we have now collected the data and restoring it so we need to think about",
    "start": "1557790",
    "end": "1564540"
  },
  {
    "text": "the questions we ask in the in the staging phase so what type of data validation needs to be performed and",
    "start": "1564540",
    "end": "1571940"
  },
  {
    "text": "this could really include a specific type of notification we want to see as",
    "start": "1571940",
    "end": "1577440"
  },
  {
    "text": "data hits the pipe of functions I want to trigger so I mentioned lambda serverless function that triggers",
    "start": "1577440",
    "end": "1584180"
  },
  {
    "text": "the creation of an environment to offline process data or do I want to detect anomalies which I want to capture",
    "start": "1584180",
    "end": "1592520"
  },
  {
    "text": "so let's say something comes in a string comes in and certain values don't match",
    "start": "1592520",
    "end": "1597590"
  },
  {
    "text": "so a very popular methodology infrared detection data governance and data",
    "start": "1597590",
    "end": "1603920"
  },
  {
    "text": "engineering play an important role and this is really this is really about cracking the nut where where the effort",
    "start": "1603920",
    "end": "1610610"
  },
  {
    "text": "really lies in the data engineering and we just want you to help you to focus on that task why we focus on the",
    "start": "1610610",
    "end": "1617840"
  },
  {
    "text": "undifferentiated heavy lifting so as data comes in you can Auto tag the data",
    "start": "1617840",
    "end": "1623210"
  },
  {
    "text": "as well and in the Security section at the end I will dive into that a little bit more now that there there's there's",
    "start": "1623210",
    "end": "1630770"
  },
  {
    "text": "some really powerful stuff available in with the object data tagging so in",
    "start": "1630770",
    "end": "1637580"
  },
  {
    "text": "staging the main thing is really that you can crawl and catalog your data and allow apply the required housekeeping",
    "start": "1637580",
    "end": "1644420"
  },
  {
    "text": "task prior to making it available to the users so when it comes to the cleansing",
    "start": "1644420",
    "end": "1655850"
  },
  {
    "start": "1652000",
    "end": "1652000"
  },
  {
    "text": "stage it's really important you know to transform the data so it can be used for",
    "start": "1655850",
    "end": "1661400"
  },
  {
    "text": "downstream analytics many organizations have a common data model and sometimes this clashes with other sets different",
    "start": "1661400",
    "end": "1668870"
  },
  {
    "text": "fields that call you know the same value for example in our little demo we are",
    "start": "1668870",
    "end": "1674600"
  },
  {
    "text": "clearing a location we're creating a location with longitude and latitude but",
    "start": "1674600",
    "end": "1681020"
  },
  {
    "text": "in the original data set it's designated with X&Y so there is a little task for",
    "start": "1681020",
    "end": "1686179"
  },
  {
    "text": "some data quality services before we pass it on to downstream analytics we nee also need to ask how to optimize the",
    "start": "1686179",
    "end": "1694190"
  },
  {
    "text": "data are we optimizing towards read or write queries what will the data cleanup",
    "start": "1694190",
    "end": "1699200"
  },
  {
    "text": "look like once the data is process can the data be deleted if not immutable",
    "start": "1699200",
    "end": "1704270"
  },
  {
    "text": "what type of removal or archival principles apply just some guidance on",
    "start": "1704270",
    "end": "1710060"
  },
  {
    "text": "that as well try not to remove any raw data and so created creating a lifecycle policy",
    "start": "1710060",
    "end": "1717320"
  },
  {
    "text": "helps you to move between tears and so you know your data becomes a source of record which means you know when the",
    "start": "1717320",
    "end": "1724170"
  },
  {
    "text": "data was ingested how it was cleansed excuse me and stored and and this is",
    "start": "1724170",
    "end": "1731310"
  },
  {
    "text": "also a practice you start working with when you're using open data sets where the data is provided by someone else so",
    "start": "1731310",
    "end": "1743730"
  },
  {
    "start": "1742000",
    "end": "1742000"
  },
  {
    "text": "with this we're going to take a little break from the slides and jump into a",
    "start": "1743730",
    "end": "1749930"
  },
  {
    "text": "demonstration so for this demo we're using an AWS open data set and the",
    "start": "1749930",
    "end": "1757680"
  },
  {
    "text": "public sector has with their open data set you know a very valuable asset and for this demonstration we're going to",
    "start": "1757680",
    "end": "1764520"
  },
  {
    "text": "use Cornell's climate data set which is hosted on our AWS open data platform and the AWS public data set program covers",
    "start": "1764520",
    "end": "1772410"
  },
  {
    "text": "the cost of storage for this publicly available data sets I think there is a",
    "start": "1772410",
    "end": "1778140"
  },
  {
    "text": "session next week or later on which we'll dive a little bit more into the",
    "start": "1778140",
    "end": "1783720"
  },
  {
    "text": "subject so",
    "start": "1783720",
    "end": "1788210"
  },
  {
    "text": "yeah just a quick overview here you can see how we are moving not actually",
    "start": "1793450",
    "end": "1799400"
  },
  {
    "text": "moving but accessing data provided through the open data set platform so that's the corner climate data and let",
    "start": "1799400",
    "end": "1808700"
  },
  {
    "text": "me just so the first thing we're actually going to do we are going to",
    "start": "1808700",
    "end": "1813980"
  },
  {
    "text": "create a table using an AWS glue job and that tables provides us with a catalog",
    "start": "1813980",
    "end": "1820880"
  },
  {
    "text": "view so as you can see here we're accessing the data Lake location where",
    "start": "1820880",
    "end": "1827230"
  },
  {
    "text": "the the climate data sets resides and just by cataloging the data and crawling",
    "start": "1827230",
    "end": "1835070"
  },
  {
    "text": "the data we get an early view on the columns and so for example you have like",
    "start": "1835070",
    "end": "1841250"
  },
  {
    "text": "level here which represents a level of atmosphere I mentioned the coordinates represented by X and y then you have",
    "start": "1841250",
    "end": "1847340"
  },
  {
    "text": "like all the coordinates available to you as well so the actual value",
    "start": "1847340",
    "end": "1853040"
  },
  {
    "text": "observations or the degrees wind speed so we already have some information now",
    "start": "1853040",
    "end": "1858890"
  },
  {
    "text": "available where we can run some queries just to let you know before we did any",
    "start": "1858890",
    "end": "1866990"
  },
  {
    "text": "type of optimization we ran queries directly on the data set and that took",
    "start": "1866990",
    "end": "1873260"
  },
  {
    "text": "us over an hour to perform a query and especially when you're moving into a",
    "start": "1873260",
    "end": "1879470"
  },
  {
    "text": "pay-as-you-go model this query time translates into a cost so once we",
    "start": "1879470",
    "end": "1888950"
  },
  {
    "text": "actually converted this the the data into Parque so into a columnar format",
    "start": "1888950",
    "end": "1898390"
  },
  {
    "text": "once we applied partitioning to the data that query performance and using",
    "start": "1898390",
    "end": "1905630"
  },
  {
    "text": "actually compression as well went down to three minutes as you can",
    "start": "1905630",
    "end": "1912410"
  },
  {
    "text": "see here so I've already run the query because there's no point of watching the query run and and and that's that's a",
    "start": "1912410",
    "end": "1919130"
  },
  {
    "text": "massive win in terms of query performance and cost savings so this is really going back to the",
    "start": "1919130",
    "end": "1925530"
  },
  {
    "text": "principle of saying you know before we present the data to our business users you know it should go through some level",
    "start": "1925530",
    "end": "1931680"
  },
  {
    "text": "of cleansing and end data preparation and later on you know once the user",
    "start": "1931680",
    "end": "1937950"
  },
  {
    "text": "knows they're only clearing a specific set you know they can they can just you",
    "start": "1937950",
    "end": "1943890"
  },
  {
    "text": "know have a very targeted view so you could they can use the materialized view and and maybe not necessarily don't need",
    "start": "1943890",
    "end": "1950760"
  },
  {
    "text": "the entire data set yeah so it's just it's just like some-some thinking around",
    "start": "1950760",
    "end": "1958200"
  },
  {
    "text": "you know try to try to optimize that the the data formats and there a lot of tools available to you",
    "start": "1958200",
    "end": "1964050"
  },
  {
    "text": "so we've performed everything here in redshift at Spectrum which is worth",
    "start": "1964050",
    "end": "1970050"
  },
  {
    "text": "mentioning we are haven't actually copied any data into redshift so with redshift spectrum you are using the",
    "start": "1970050",
    "end": "1977910"
  },
  {
    "text": "engine and port performing the queries against the data set where lies so the objectives is really not trying to copy",
    "start": "1977910",
    "end": "1984600"
  },
  {
    "text": "too much data around so you can copy the query and really you know run the query",
    "start": "1984600",
    "end": "1992850"
  },
  {
    "text": "in athina for some ad hoc analytics as well I mean redshift is obviously a better use case to run much more",
    "start": "1992850",
    "end": "2000230"
  },
  {
    "text": "elaborate complex queries so this is really all about looking at the existing",
    "start": "2000230",
    "end": "2007250"
  },
  {
    "text": "data and doing some queries there but we said about you know once you've prepared",
    "start": "2007250",
    "end": "2013340"
  },
  {
    "text": "your data it's it's really worth um like",
    "start": "2013340",
    "end": "2019300"
  },
  {
    "text": "optimizing a little bit more so just on the redshift spectrum thing again so the",
    "start": "2019300",
    "end": "2025010"
  },
  {
    "text": "the beauty really is that retro supports orc and tacky and yeah you can copy the",
    "start": "2025010",
    "end": "2030740"
  },
  {
    "text": "files into the database if you want and so when you run your initial queries on your data set you know without using",
    "start": "2030740",
    "end": "2037610"
  },
  {
    "text": "partitioning compression converting into a parquet it will scan the entire data",
    "start": "2037610",
    "end": "2043760"
  },
  {
    "text": "set you know which which can take hours and yeah so it uses external tables as",
    "start": "2043760",
    "end": "2051230"
  },
  {
    "text": "well to query the data that's stored in s3 you can create an external table",
    "start": "2051230",
    "end": "2056850"
  },
  {
    "text": "storing it in redshift glue Athena or even in an Apache hive Mehta store so",
    "start": "2056850",
    "end": "2062720"
  },
  {
    "text": "again why partitioning when you partition your data you can restrict the amount of data that redshift spectrum",
    "start": "2062720",
    "end": "2069060"
  },
  {
    "text": "scans and you can filter on the partition key and you can partition your",
    "start": "2069060",
    "end": "2074669"
  },
  {
    "text": "data by any key yeah so a common practice is to partition the data based on time so year month date hour what's",
    "start": "2074670",
    "end": "2082409"
  },
  {
    "text": "also interesting if you have data coming from multiple sources you might partition by a data source identifier",
    "start": "2082410",
    "end": "2088409"
  },
  {
    "text": "and date so let's say we want to pass it on to downstream analytics and do a",
    "start": "2088410",
    "end": "2098670"
  },
  {
    "text": "little bit more with it and this is really taking a CSV export and importing",
    "start": "2098670",
    "end": "2106740"
  },
  {
    "text": "it into Sage maker and in here usually the data scientists prefer Jupiter",
    "start": "2106740",
    "end": "2114720"
  },
  {
    "text": "notebooks to create the data frame and they apply libraries and also called",
    "start": "2114720",
    "end": "2121080"
  },
  {
    "text": "pandas and I'm not going to dive too much into into the ML element here but",
    "start": "2121080",
    "end": "2126180"
  },
  {
    "text": "you can see that yes you can do some data preparation and and and then visualize the data and once you've done",
    "start": "2126180",
    "end": "2134790"
  },
  {
    "text": "that you can just move on into training a model to do some predictions and in",
    "start": "2134790",
    "end": "2141180"
  },
  {
    "text": "this work-in-progress environment we are focusing on forecasting so yeah so you",
    "start": "2141180",
    "end": "2147870"
  },
  {
    "text": "get the idea of passing really the data to the different stages of of processing",
    "start": "2147870",
    "end": "2156230"
  },
  {
    "text": "so the idea really was here to show you just with a couple of hours of you know",
    "start": "2156740",
    "end": "2164100"
  },
  {
    "text": "tinkering and experimenting what you could actually achieve with your data sets and not once I have to think about",
    "start": "2164100",
    "end": "2173330"
  },
  {
    "text": "infrastructure and provisioning and could see some early results so just",
    "start": "2173330",
    "end": "2186460"
  },
  {
    "start": "2185000",
    "end": "2185000"
  },
  {
    "text": "summarize on the analytics and visualization so data analytics is really the stage where organization can",
    "start": "2186460",
    "end": "2193810"
  },
  {
    "text": "identify how to effectively you know manage that manage the budget you know potentially reduce costs and analytics",
    "start": "2193810",
    "end": "2201310"
  },
  {
    "text": "in combination with visualization delivers decision-makers insights which",
    "start": "2201310",
    "end": "2206830"
  },
  {
    "text": "could help them transforming them organization you know so that could include identifying the unmet and",
    "start": "2206830",
    "end": "2212530"
  },
  {
    "text": "consider needs and optimizing processes data-driven decisions you know that can",
    "start": "2212530",
    "end": "2220630"
  },
  {
    "text": "give decision-makers a backup who usually rely on the he si and instincts",
    "start": "2220630",
    "end": "2228670"
  },
  {
    "text": "when making choices and so the key considerations in this phase is really the requirements for analytics be",
    "start": "2228670",
    "end": "2235869"
  },
  {
    "text": "clearly defined you know what what is the output being aligned to the use cases and the consumers of the data",
    "start": "2235869",
    "end": "2243280"
  },
  {
    "text": "within the organization you know should really have valuable reports with actionable data I want to just quickly",
    "start": "2243280",
    "end": "2254800"
  },
  {
    "text": "dive into some customer references at the very beginning I mentioned FINRA so",
    "start": "2254800",
    "end": "2261430"
  },
  {
    "start": "2259000",
    "end": "2259000"
  },
  {
    "text": "FINRA is an US financial industry regulator and they are leveraging different tools for different jobs",
    "start": "2261430",
    "end": "2267030"
  },
  {
    "text": "they're collecting from many different sources with many different formats so for example from the New York Stock",
    "start": "2267030",
    "end": "2272890"
  },
  {
    "text": "Exchange NASDAQ and that's mostly structured data sources so data from",
    "start": "2272890",
    "end": "2278859"
  },
  {
    "text": "databases but they're also collecting a lot of unstructured data such as brokerage report and that could be about",
    "start": "2278859",
    "end": "2286000"
  },
  {
    "text": "a million documents a year and I mentioned earlier that they're using a",
    "start": "2286000",
    "end": "2291330"
  },
  {
    "text": "natural language processing service Amazon comprehend to convert their",
    "start": "2291330",
    "end": "2297580"
  },
  {
    "text": "unstructured data into structured data to do sentiment analysis and entity extraction etc and that really helps",
    "start": "2297580",
    "end": "2304660"
  },
  {
    "text": "them to dig out a treasure out of the unstructured data that is often really unusable archive data so if you look at",
    "start": "2304660",
    "end": "2313119"
  },
  {
    "text": "the middle bit so in terms of the architecture they're leveraging EMR so the Hadoop service to perform",
    "start": "2313119",
    "end": "2318720"
  },
  {
    "text": "interactive career and EEMA provides them with their",
    "start": "2318720",
    "end": "2323970"
  },
  {
    "text": "surveillance analytics as well and redshift data warehouse is used for",
    "start": "2323970",
    "end": "2330140"
  },
  {
    "text": "running predefined queries and the data modeling if you look at here it's very",
    "start": "2330140",
    "end": "2336630"
  },
  {
    "text": "similar to you know what we described the area earlier so data lands into s3 data is preferred different analytics",
    "start": "2336630",
    "end": "2343380"
  },
  {
    "text": "tools and services serving a different use case and also and answering different questions securing compliance",
    "start": "2343380",
    "end": "2350430"
  },
  {
    "text": "is also very important to finra so the architecture is designed for security and compliance you can see we're using B",
    "start": "2350430",
    "end": "2358050"
  },
  {
    "text": "pcs so these are virtual private cloud architecture surprise provide logically",
    "start": "2358050",
    "end": "2364410"
  },
  {
    "text": "isolated sections and then we have VPN to provide secure and private connection",
    "start": "2364410",
    "end": "2370350"
  },
  {
    "text": "tunneling and encryption is being used for data at rest and in motion and for",
    "start": "2370350",
    "end": "2376320"
  },
  {
    "text": "auditing governance and compliance they use cloud trail and database auditing as",
    "start": "2376320",
    "end": "2382320"
  },
  {
    "text": "well Hearst who is not a public sector",
    "start": "2382320",
    "end": "2388680"
  },
  {
    "text": "customer so their major median information company and they provide",
    "start": "2388680",
    "end": "2395190"
  },
  {
    "text": "different formats such as magazines newspapers and TV they collect crawl data from different websites using",
    "start": "2395190",
    "end": "2401220"
  },
  {
    "text": "Kinesis data streams and in the top fork you can see they're storing offline processing and in the bottom they're",
    "start": "2401220",
    "end": "2406710"
  },
  {
    "text": "performing real-time analytics where they create dashboards and materialized",
    "start": "2406710",
    "end": "2412290"
  },
  {
    "text": "views through a lambda pipeline so then leveraging service tech and all is",
    "start": "2412290",
    "end": "2418620"
  },
  {
    "text": "stored in a no sequel dynamodb database",
    "start": "2418620",
    "end": "2424730"
  },
  {
    "text": "so which analytics should I use to answer that question this one second so",
    "start": "2425390",
    "end": "2438290"
  },
  {
    "text": "again looking into the use case and the business requirement but also look at",
    "start": "2438290",
    "end": "2443820"
  },
  {
    "text": "the time frame of the question so is it streaming it's real time does it take minutes to hours or are we looking at",
    "start": "2443820",
    "end": "2450600"
  },
  {
    "text": "milliseconds for for your analytics and so consider those things as well and",
    "start": "2450600",
    "end": "2456440"
  },
  {
    "text": "another bit of advice you know the more you can leverage a managed service solution where AWS takes care of the",
    "start": "2456440",
    "end": "2464040"
  },
  {
    "text": "undifferentiated heavy lifting the more you will be able to focus on what matters for the business and so don't",
    "start": "2464040",
    "end": "2470640"
  },
  {
    "text": "worry about infrastructure and even when",
    "start": "2470640",
    "end": "2477420"
  },
  {
    "text": "looking into you know which analytics tool should I use again focus on the use case and I'm gonna dive into too much",
    "start": "2477420",
    "end": "2484440"
  },
  {
    "text": "detail here you can see like Athena for some a doc",
    "start": "2484440",
    "end": "2490850"
  },
  {
    "text": "analytics you know talked about Richard Spectrum how you can just run the the",
    "start": "2490850",
    "end": "2497220"
  },
  {
    "text": "engine without copying the data into redshift and and then Amazon EMR splits",
    "start": "2497220",
    "end": "2504870"
  },
  {
    "text": "down into different use cases here as well and which stream processing",
    "start": "2504870",
    "end": "2511200"
  },
  {
    "text": "technology should I use similar principle applies here so for example if",
    "start": "2511200",
    "end": "2518070"
  },
  {
    "text": "you want to use Kinesis analytics that allows you to run the flink application",
    "start": "2518070",
    "end": "2524340"
  },
  {
    "text": "so you can really run sequel queries on your real time data so what does that mean you know people who understand",
    "start": "2524340",
    "end": "2530160"
  },
  {
    "text": "relational databases and sequel can quickly apply this to real time",
    "start": "2530160",
    "end": "2535320"
  },
  {
    "text": "analytics queries you know and for example to grouping of anomaly detection",
    "start": "2535320",
    "end": "2541700"
  },
  {
    "text": "but people who want a bit more control as well you know so people who need the low level coding they can use Java",
    "start": "2541700",
    "end": "2549660"
  },
  {
    "text": "Python and dotnet core so one of the",
    "start": "2549660",
    "end": "2556230"
  },
  {
    "text": "newer services I want to quickly mention is lake formation and lake formation",
    "start": "2556230",
    "end": "2561530"
  },
  {
    "text": "automates many of the steps we discussed allowing customers to get started with just a few clicks you know from a single",
    "start": "2561530",
    "end": "2568350"
  },
  {
    "text": "unified dashboard and customers can really build quickly",
    "start": "2568350",
    "end": "2573829"
  },
  {
    "text": "some lake from some data lake environment so with lake formation you know you can move store catalog and",
    "start": "2573829",
    "end": "2581329"
  },
  {
    "text": "clean your data faster so how do we do it we simply point our lake formation",
    "start": "2581329",
    "end": "2586459"
  },
  {
    "text": "service at our data sources and lake formation crawls those sources and moves the data into your Amazon s3 data lake",
    "start": "2586459",
    "end": "2595279"
  },
  {
    "text": "and lake formation organizes the data in s3 around frequently used query terms",
    "start": "2595279",
    "end": "2602719"
  },
  {
    "text": "and and into right sized chunks to increase the efficiency it also converts",
    "start": "2602719",
    "end": "2609709"
  },
  {
    "text": "the data I change the data into formats like a patch of parquet and awk for fast",
    "start": "2609709",
    "end": "2615319"
  },
  {
    "text": "analytics as we discussed briefly in the demo lake formation has also built in",
    "start": "2615319",
    "end": "2621619"
  },
  {
    "text": "machine learning to address deduplication and to find matching",
    "start": "2621619",
    "end": "2626749"
  },
  {
    "text": "records so that could be you know two entries that refer to the same thing and by that it can increase the data quality",
    "start": "2626749",
    "end": "2633999"
  },
  {
    "text": "it's simplified security management as well so if you look at lake formation to",
    "start": "2633999",
    "end": "2641719"
  },
  {
    "text": "centrally define your security governance and auditing policies you know you can take that and enforce those",
    "start": "2641719",
    "end": "2647059"
  },
  {
    "text": "policies for your users across the analytics applications in terms of",
    "start": "2647059",
    "end": "2654109"
  },
  {
    "text": "self-service access you can build a data catalog that describes the different",
    "start": "2654109",
    "end": "2659869"
  },
  {
    "text": "data sets that are available along with you know the groups of users that have access to each and this makes it really",
    "start": "2659869",
    "end": "2667339"
  },
  {
    "text": "more productive by helping a users with the right data set they require for their processes and you can give",
    "start": "2667339",
    "end": "2674509"
  },
  {
    "text": "granular permissions so that means you can give permissions on columnar level so you know really you can restrict user",
    "start": "2674509",
    "end": "2679759"
  },
  {
    "text": "access not just to a specific table but also to a column in terms of audit",
    "start": "2679759",
    "end": "2688219"
  },
  {
    "text": "ability it provides you with a lot of audit of activity and access in your",
    "start": "2688219",
    "end": "2695479"
  },
  {
    "text": "data Lake and we will touch on that very soon but before that I want to just",
    "start": "2695479",
    "end": "2701479"
  },
  {
    "text": "touch on the last element the last state in our lifecycle which is data archiving and this is also",
    "start": "2701479",
    "end": "2709760"
  },
  {
    "start": "2702000",
    "end": "2702000"
  },
  {
    "text": "important for compliance and maintaining a system of record and in the archival process we also we wanted we want it to",
    "start": "2709760",
    "end": "2718220"
  },
  {
    "text": "be easy so that means we don't want to worry about you know configuring the tape libraries and it should be more",
    "start": "2718220",
    "end": "2725359"
  },
  {
    "text": "about the storage of your data and less about the management and this is storing across different classes of storage and",
    "start": "2725359",
    "end": "2733000"
  },
  {
    "text": "also focusing you know on setting up a lifecycle policy and there are also many",
    "start": "2733000",
    "end": "2738380"
  },
  {
    "text": "new features such as intelligent tearing which helps you monitoring access patterns and then actions the movement",
    "start": "2738380",
    "end": "2745549"
  },
  {
    "text": "of data between tiers and when by tearing your data securely it really helps you drive the cost down by you",
    "start": "2745549",
    "end": "2752390"
  },
  {
    "text": "know and and and not necessarily losing the data before we talk about security",
    "start": "2752390",
    "end": "2758539"
  },
  {
    "start": "2758000",
    "end": "2758000"
  },
  {
    "text": "just a quick recap on our shared responsibility model so just for those",
    "start": "2758539",
    "end": "2764690"
  },
  {
    "text": "who are not familiar with the approach so in essence that's a double use is really responsible for the security of",
    "start": "2764690",
    "end": "2770750"
  },
  {
    "text": "the cloud which includes everything from the concrete of the data center facility to the physical security up to the hypervisor",
    "start": "2770750",
    "end": "2777410"
  },
  {
    "text": "layer and customers are responsible for security in the cloud so concerning the",
    "start": "2777410",
    "end": "2782450"
  },
  {
    "text": "data they put in and the handling of the data so this this is really no",
    "start": "2782450",
    "end": "2788450"
  },
  {
    "text": "encryption and and and and and depending on what service you're using obviously",
    "start": "2788450",
    "end": "2794059"
  },
  {
    "text": "if you're using a situ you need to look at look at patching and all these things but it's some moving targets if you know",
    "start": "2794059",
    "end": "2799609"
  },
  {
    "text": "if you decide to run a managed service but when it comes to securing a",
    "start": "2799609",
    "end": "2805039"
  },
  {
    "start": "2805000",
    "end": "2805000"
  },
  {
    "text": "day-to-day Lake and not just securing but also protecting and managing it",
    "start": "2805039",
    "end": "2810559"
  },
  {
    "text": "effectively you know these are the the key elements I would revisit and",
    "start": "2810559",
    "end": "2816890"
  },
  {
    "text": "consider and so when you're building it an analytics environment and especially a data Lake environment that serves as a",
    "start": "2816890",
    "end": "2823849"
  },
  {
    "text": "centralized repository it is really important to implement a stringent security model and an AWS with s3 as its",
    "start": "2823849",
    "end": "2833539"
  },
  {
    "text": "core we have the following features available to you so first of",
    "start": "2833539",
    "end": "2839060"
  },
  {
    "text": "all we have access policies and identity access management I am so you can manage you as three object resources using",
    "start": "2839060",
    "end": "2846500"
  },
  {
    "text": "policy options so all buckets are private by default so that means the AWS",
    "start": "2846500",
    "end": "2851930"
  },
  {
    "text": "account that created that bucket can access them and then you can use resource based policies so which are",
    "start": "2851930",
    "end": "2859220"
  },
  {
    "text": "bucket policies and access control lists also known as ACLs and then you have",
    "start": "2859220",
    "end": "2864800"
  },
  {
    "text": "access policies which you can attach the user the combination is really used to",
    "start": "2864800",
    "end": "2869900"
  },
  {
    "text": "manage these three buckets objects and and also other resources for data Lake",
    "start": "2869900",
    "end": "2875690"
  },
  {
    "text": "environments we recommend using user policy so permission to access data sets can be tied to roles for data processing",
    "start": "2875690",
    "end": "2883670"
  },
  {
    "text": "using a specific analytic service and tools users will use and user policies",
    "start": "2883670",
    "end": "2891020"
  },
  {
    "text": "that associated with I am so identity and access management users groups and",
    "start": "2891020",
    "end": "2896300"
  },
  {
    "text": "roles when it comes to encryption we look at s3 and kms key management",
    "start": "2896300",
    "end": "2902240"
  },
  {
    "text": "service so if you look at the first bullet this is really about you know who can see in access but if someone gets",
    "start": "2902240",
    "end": "2909770"
  },
  {
    "text": "inadvertently or maliciously access you want to make the data unusable and this is achieved by using encryption and s3",
    "start": "2909770",
    "end": "2917000"
  },
  {
    "text": "supports multiple options so kms helps you scaling and better management of",
    "start": "2917000",
    "end": "2924500"
  },
  {
    "text": "your you know centralized keys kms also integrates with other AWS services which",
    "start": "2924500",
    "end": "2931670"
  },
  {
    "text": "makes it very easy to encrypt the data and stored in those services it",
    "start": "2931670",
    "end": "2939380"
  },
  {
    "text": "integrates with cloud trail so which enables you to audit who used which keys on which resources and when and so the",
    "start": "2939380",
    "end": "2950030"
  },
  {
    "text": "daily Legon on AWS we said you know is actually using multiple encryption keys and one of them being server-side",
    "start": "2950030",
    "end": "2956060"
  },
  {
    "text": "encryption also known as SSE and the client-side encryption solve sse is the",
    "start": "2956060",
    "end": "2962390"
  },
  {
    "text": "addressed encryption for data written to s3 so this is happening the encryption happening on object level",
    "start": "2962390",
    "end": "2968259"
  },
  {
    "text": "and the client-side encryption is really the data objects are encrypted before they are transferred to s3 if you",
    "start": "2968259",
    "end": "2976089"
  },
  {
    "text": "combine those two you get the highest level of protection and data like is you",
    "start": "2976089",
    "end": "2982150"
  },
  {
    "text": "know data legs are really a complex environment so coordinating key management is a complex task so we would",
    "start": "2982150",
    "end": "2988720"
  },
  {
    "text": "recommend really to use kms for that and you can extend that further if you want",
    "start": "2988720",
    "end": "2994089"
  },
  {
    "text": "to do some you know check real let some",
    "start": "2994089",
    "end": "2999309"
  },
  {
    "text": "check-in and check-out mechanisms for your data like assets you can use API gateway and kognito and combine those",
    "start": "2999309",
    "end": "3005099"
  },
  {
    "text": "together now if we actually look at the platform and with s3 at its core you",
    "start": "3005099",
    "end": "3010769"
  },
  {
    "text": "know we need to be able to protect against corruption and loss and it's free provides you with a high durability",
    "start": "3010769",
    "end": "3016680"
  },
  {
    "text": "of 99% 9 x 9 so what does that mean it actually means that you get four to six",
    "start": "3016680",
    "end": "3024119"
  },
  {
    "text": "orders of magnitude what customers are currently you know experiencing with on-premises solution it protects you",
    "start": "3024119",
    "end": "3030869"
  },
  {
    "text": "across multiple availability zones so one zone consists of more or one discrete data centers which have",
    "start": "3030869",
    "end": "3036630"
  },
  {
    "text": "redundant power connectivity and each AZ is an isolated location and as Rios",
    "start": "3036630",
    "end": "3043109"
  },
  {
    "text": "provides you with versioning of multiple copies so that helps you to protect",
    "start": "3043109",
    "end": "3048239"
  },
  {
    "text": "against deletion and corruption and s3 also has life cycle management which",
    "start": "3048239",
    "end": "3053609"
  },
  {
    "text": "enables you with long term retention and moving your data to low it here cause",
    "start": "3053609",
    "end": "3059789"
  },
  {
    "text": "storage and s3 also provides you with G replication you know should you as a",
    "start": "3059789",
    "end": "3066029"
  },
  {
    "text": "customer require this and this is not something we would do obviously without your consent and the data and transit is",
    "start": "3066029",
    "end": "3073440"
  },
  {
    "text": "usually encrypted with SSL the last thing I want to mention is the object",
    "start": "3073440",
    "end": "3079019"
  },
  {
    "text": "tagging and data like solutions are multi tenant solutions so you have many",
    "start": "3079019",
    "end": "3084410"
  },
  {
    "text": "organizations line of business uses an app so it's important to associate data",
    "start": "3084410",
    "end": "3090779"
  },
  {
    "text": "sets with all those entities an object tag is a mutable key value pair so each",
    "start": "3090779",
    "end": "3097349"
  },
  {
    "text": "object s3 object can have multiple tax I think it's up to ten and if an object contains for example",
    "start": "3097349",
    "end": "3104700"
  },
  {
    "text": "protected health information so pH I data a user app using this object may",
    "start": "3104700",
    "end": "3110730"
  },
  {
    "text": "tag it you know using a key value pH I equals through or classification equals",
    "start": "3110730",
    "end": "3117690"
  },
  {
    "text": "pH I and the object tagging can be used in conjunction with I am to enable you",
    "start": "3117690",
    "end": "3123720"
  },
  {
    "text": "with fire and grained controls of accessing of access permissions and data",
    "start": "3123720",
    "end": "3130619"
  },
  {
    "text": "lake user or group can be granted permissions to only read specific objects with specific tax you know and",
    "start": "3130619",
    "end": "3136710"
  },
  {
    "text": "those tax can be also combined with lifecycle policies tax can be also",
    "start": "3136710",
    "end": "3141930"
  },
  {
    "text": "combined with cloud watch and cloud trail so this helps you with the monitoring and auditing and with the",
    "start": "3141930",
    "end": "3150900"
  },
  {
    "text": "last point you know you obviously want to make sure that the services you're",
    "start": "3150900",
    "end": "3156030"
  },
  {
    "text": "using also meet certification and compliance requirements so let's quickly",
    "start": "3156030",
    "end": "3166050"
  },
  {
    "start": "3166000",
    "end": "3166000"
  },
  {
    "text": "review some of the architectural principles you know we talked about decoupled systems and so the ingestion",
    "start": "3166050",
    "end": "3172260"
  },
  {
    "text": "point shouldn't create a dependency how the data is being processed stored and further analyzed you know this helps you",
    "start": "3172260",
    "end": "3179130"
  },
  {
    "text": "to scale and easily extend your environment it helps you for your dev teams to work autonomously so especially",
    "start": "3179130",
    "end": "3186210"
  },
  {
    "text": "you know in the new world where development teams are dispersed and potentially in different time zones you",
    "start": "3186210",
    "end": "3192990"
  },
  {
    "text": "know and you're not impacting the downstream analytics when you're storing your data you should try to use a",
    "start": "3192990",
    "end": "3199320"
  },
  {
    "text": "standard format like JSON CSV Parque orcas and what does it actually means is",
    "start": "3199320",
    "end": "3205500"
  },
  {
    "text": "proprietary types you know they can silo your your data leverage many services as",
    "start": "3205500",
    "end": "3213570"
  },
  {
    "text": "much as possible you know and serverless so you can focus on the activities that",
    "start": "3213570",
    "end": "3219420"
  },
  {
    "text": "generate business value that means less admin you know we do the heavy lifting and a lot of our services are built on",
    "start": "3219420",
    "end": "3228210"
  },
  {
    "text": "open standards and so we looked into Athena which is built on presto so if you have",
    "start": "3228210",
    "end": "3233710"
  },
  {
    "text": "press the query you can use it right away no answer you don't have to worry about their provisioning a complex press",
    "start": "3233710",
    "end": "3240130"
  },
  {
    "text": "to infrastructure and as we said before open source has many benefits but it can",
    "start": "3240130",
    "end": "3245650"
  },
  {
    "text": "be sometimes complex to implement and this is where we give you the services",
    "start": "3245650",
    "end": "3250839"
  },
  {
    "text": "the wrapper around those open source services to give you the enterprise GAE great enhancement and increase there by",
    "start": "3250839",
    "end": "3260619"
  },
  {
    "text": "your manageability experience focus on",
    "start": "3260619",
    "end": "3266079"
  },
  {
    "text": "immutable data sets you know when data is ingested try to append on and this is a practice you",
    "start": "3266079",
    "end": "3272470"
  },
  {
    "text": "obviously adapt when you dealing with raw data from different sources big data",
    "start": "3272470",
    "end": "3278920"
  },
  {
    "text": "doesn't mean big cost so it can be costly on Prem but with AWS cloud you",
    "start": "3278920",
    "end": "3284140"
  },
  {
    "text": "can just benefit from a pay-as-you-go you know all the other benefits in terms",
    "start": "3284140",
    "end": "3289809"
  },
  {
    "text": "of elasticity apply you know start small on demand and enrich your data further",
    "start": "3289809",
    "end": "3296650"
  },
  {
    "text": "you know but by using machine learning and trainer training models to gain more",
    "start": "3296650",
    "end": "3303430"
  },
  {
    "text": "elaborate insights into your environment so we talked about the challenges at the",
    "start": "3303430",
    "end": "3311799"
  },
  {
    "text": "beginning you know just to summarize that quickly so we talked about that data is dispersed in difficult to access",
    "start": "3311799",
    "end": "3319329"
  },
  {
    "text": "we looked how data can be linked into AWS transformed and passed to",
    "start": "3319329",
    "end": "3324490"
  },
  {
    "text": "purpose-built analytics and how the copying of the data is not always required limited views we provided",
    "start": "3324490",
    "end": "3332470"
  },
  {
    "text": "different views use different engines and run queries across datasets resource",
    "start": "3332470",
    "end": "3339040"
  },
  {
    "text": "constraints not once had do we we have to look into the infrastructure provisioning and the configuration",
    "start": "3339040",
    "end": "3344770"
  },
  {
    "text": "efforts and we just could establish something with a couple of hours of experimenting elasticity you know only",
    "start": "3344770",
    "end": "3352750"
  },
  {
    "text": "pay when the queries are running you know leave the data where it is just don't copy stuff around necessarily and",
    "start": "3352750",
    "end": "3358829"
  },
  {
    "text": "the governance can compliance aspect you know everything is in an environment where you have full control and",
    "start": "3358829",
    "end": "3364119"
  },
  {
    "text": "visibility of the data you know with compliant and certified services",
    "start": "3364119",
    "end": "3370710"
  },
  {
    "text": "now with this we are really coming to the end of this presentation and I hope",
    "start": "3370710",
    "end": "3377470"
  },
  {
    "text": "the proposed data lifecycle structure resonates with you and maybe there was",
    "start": "3377470",
    "end": "3382570"
  },
  {
    "text": "something new you could learn and hopefully this inspires you you know to",
    "start": "3382570",
    "end": "3387720"
  },
  {
    "text": "you know think about optimizing processes and looking into different methodologies and yeah so I would like",
    "start": "3387720",
    "end": "3397570"
  },
  {
    "text": "to say thank you very much and let's open up the session for any more",
    "start": "3397570",
    "end": "3402640"
  },
  {
    "text": "questions fantastic thanks very much for that beer so I've got time just to",
    "start": "3402640",
    "end": "3410080"
  },
  {
    "text": "squeeze one question in there before we wrap up for today so I'll just pick one",
    "start": "3410080",
    "end": "3415869"
  },
  {
    "text": "here the is good question actually so can you give any guidance or sort of",
    "start": "3415869",
    "end": "3421690"
  },
  {
    "text": "best practices about how to sync later from a range of different devices I",
    "start": "3421690",
    "end": "3429299"
  },
  {
    "text": "think when syncing data from different devices are probably we need to elaborate more I mean where where where",
    "start": "3430680",
    "end": "3437050"
  },
  {
    "text": "is the data coming from and is it really about talking asynchronous as a",
    "start": "3437050",
    "end": "3443470"
  },
  {
    "text": "synchronous and I think it depends on a couple of things it's just first of all",
    "start": "3443470",
    "end": "3449020"
  },
  {
    "text": "what is it what is the actual use case but is what is the infrastructure available you know and and and then",
    "start": "3449020",
    "end": "3456510"
  },
  {
    "text": "really working from the use case and the environment to detect of what tools and",
    "start": "3456510",
    "end": "3465400"
  },
  {
    "text": "services we may require you know it's a it's a bit of an ambiguous answer but we",
    "start": "3465400",
    "end": "3471100"
  },
  {
    "text": "would really need to understand me what type of data are we actually sinking you know but what is it and I think I mean I",
    "start": "3471100",
    "end": "3476440"
  },
  {
    "text": "think you can't just make a general comment on okay and this is how we're going to sync the data so this is this",
    "start": "3476440",
    "end": "3481570"
  },
  {
    "text": "is going back to my point of let's look at the business problem and try to understand you know where is it coming",
    "start": "3481570",
    "end": "3487840"
  },
  {
    "text": "from what is the frequency we're trying to sink as well you know how frequently is the data changing okay fantastic and",
    "start": "3487840",
    "end": "3496890"
  },
  {
    "text": "thanks that well liked it yeah any more questions you know there is an email for people to",
    "start": "3496890",
    "end": "3503570"
  },
  {
    "text": "all to ask so yeah thank you very much yeah absolutely please do drop us a note at the email address that's on the",
    "start": "3503570",
    "end": "3509000"
  },
  {
    "text": "screen now in the meantime thank you very much for taking the time to join us",
    "start": "3509000",
    "end": "3514760"
  },
  {
    "text": "today thanks so much to a beer thanks very much to Charlie and we'll put a quick poll up on the screen in just a",
    "start": "3514760",
    "end": "3521360"
  },
  {
    "text": "second just to get your feedback on how things went today but otherwise for myself and the team thanks very much and we'll see you next time",
    "start": "3521360",
    "end": "3529060"
  }
]
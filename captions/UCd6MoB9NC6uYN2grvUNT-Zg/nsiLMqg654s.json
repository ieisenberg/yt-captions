[
  {
    "text": "everybody thanks so much for coming my name is Rahul potluck and we're here to",
    "start": "30",
    "end": "6600"
  },
  {
    "text": "talk about AWS lake formation so it's the last session of the day I'm really gonna drag this one out no I'm just",
    "start": "6600",
    "end": "12540"
  },
  {
    "text": "kidding just kidding so we're gonna you know we're booked for an hour what will probably happen is",
    "start": "12540",
    "end": "17550"
  },
  {
    "text": "we'll go quickly through the slides we'll open up for questions so people if they want to get to other things can so",
    "start": "17550",
    "end": "23010"
  },
  {
    "text": "I've been in Amazon about seven years I'm the general manager for our big data data lakes and blockchain area and today",
    "start": "23010",
    "end": "29279"
  },
  {
    "text": "we're gonna talk about why we built lake formation what is it and why you should",
    "start": "29279",
    "end": "34620"
  },
  {
    "text": "care about it and then what it's gonna do for you and how we believe it's gonna simplify what you're trying to do with",
    "start": "34620",
    "end": "39989"
  },
  {
    "text": "s3 and data leaks so quick show of hands who has data on s3 today all right",
    "start": "39989",
    "end": "46860"
  },
  {
    "text": "that's what I was hoping and who's using s3 is their primary data Lake or data",
    "start": "46860",
    "end": "52410"
  },
  {
    "text": "warehouse alright so it's a smaller set but not bad alright so hopefully we'll work to",
    "start": "52410",
    "end": "57930"
  },
  {
    "text": "change that as you get to use this service but you know one of the key drivers behind the adoption of data",
    "start": "57930",
    "end": "64140"
  },
  {
    "text": "lakes has been that data is growing at an insane rate so I know for sure all of",
    "start": "64140",
    "end": "69240"
  },
  {
    "text": "you have at least one cell phone in this room I'm pretty sure some of you have more than one so what we're seeing",
    "start": "69240",
    "end": "75270"
  },
  {
    "text": "across our customer base is that data is growing roughly 10x every five years and so if you've got a platform decision",
    "start": "75270",
    "end": "81780"
  },
  {
    "text": "that's gonna live 10 years that's a hundred X increase 15 years is a thousand X increase so if you're dealing",
    "start": "81780",
    "end": "87390"
  },
  {
    "text": "with a terabyte today you're gonna be dealing with a petabyte in 15 years and we're going to go up from there",
    "start": "87390",
    "end": "92970"
  },
  {
    "text": "petabytes will become exabytes and this is going beyond the classic sort of",
    "start": "92970",
    "end": "98070"
  },
  {
    "text": "tabular relational database data there used to be in ERP systems and CRM systems we're now seeing events coming",
    "start": "98070",
    "end": "104579"
  },
  {
    "text": "off of web applications social media so it's a mix of semi structured unstructured data and we need to find a",
    "start": "104579",
    "end": "111420"
  },
  {
    "text": "way to make sense of all of this the other piece of it is that we're increasingly seeing more and more",
    "start": "111420",
    "end": "118110"
  },
  {
    "text": "customers wanting to give governed access to data broadly throughout their organization so we talk we hear",
    "start": "118110",
    "end": "124799"
  },
  {
    "text": "customers saying things like I want to democratize data access I want to get out of the way I want to get people",
    "start": "124799",
    "end": "130289"
  },
  {
    "text": "experimenting with data but only the data they're allowed to see and people are doing more than just sort",
    "start": "130289",
    "end": "136100"
  },
  {
    "text": "of the classic reporting and dashboard ago went to do real-time processing they",
    "start": "136100",
    "end": "141200"
  },
  {
    "text": "want to do machine learning and predictive analytics and so this is really driving the need for more",
    "start": "141200",
    "end": "146810"
  },
  {
    "text": "flexibility in how data is consumed and so what we've got with the data Lake is",
    "start": "146810",
    "end": "153350"
  },
  {
    "text": "something that spans beyond the boundary of a data warehouse it allows you to keep all of your data and it's a",
    "start": "153350",
    "end": "159680"
  },
  {
    "text": "centralized repository for both structured semi-structured and unstructured data and we want you to be",
    "start": "159680",
    "end": "165860"
  },
  {
    "text": "able to keep it there and then be able to access it through multiple systems and the reason unstructured data is",
    "start": "165860",
    "end": "172400"
  },
  {
    "text": "interesting if you think about things like images or video or text these used to be opaque to analytic systems but now",
    "start": "172400",
    "end": "178880"
  },
  {
    "text": "with some of the m/l services that we have you can actually extract metadata from images or from video from audio and",
    "start": "178880",
    "end": "185450"
  },
  {
    "text": "that metadata becomes things that you can build dashboards on run queries on build predictive models around and so",
    "start": "185450",
    "end": "191720"
  },
  {
    "text": "data that used to be opaque is now becoming visible and transparent to analytic services and so what we have is",
    "start": "191720",
    "end": "199760"
  },
  {
    "text": "this idea of multiple sources of data your classic line of business systems and databases going into data warehouses",
    "start": "199760",
    "end": "208070"
  },
  {
    "text": "you've got semi structured and unstructured coming into data Lakes and then you need a catalog to really tell",
    "start": "208070",
    "end": "214460"
  },
  {
    "text": "you what you have so you know where your data is which database it resides in we're on s3 it is and then you want to",
    "start": "214460",
    "end": "221570"
  },
  {
    "text": "be able to really run any sort of analytics that you want on this data simultaneously and so as you'll know",
    "start": "221570",
    "end": "227690"
  },
  {
    "text": "everyone has data in s3 as three supports multiple systems acting on the same data simultaneously without",
    "start": "227690",
    "end": "234470"
  },
  {
    "text": "interfering with each other and so you can run data warehousing in redshift you can use redshift spectrum to run",
    "start": "234470",
    "end": "240950"
  },
  {
    "text": "scale out exabyte queries over data in s3 as well as data in the cluster with the EMR you get the latest of the apache",
    "start": "240950",
    "end": "247310"
  },
  {
    "text": "open source ecosystem for analytics and then you can have real-time and interactive analysis with things like",
    "start": "247310",
    "end": "253160"
  },
  {
    "text": "athena and then quick site for visualization sage maker and more for ml",
    "start": "253160",
    "end": "259720"
  },
  {
    "text": "and so what data leaks enable really is any workload at any scale at low cost",
    "start": "259720",
    "end": "265400"
  },
  {
    "text": "and so we have individual customers three that are nudging the exabytes scale and once you're able to bring data",
    "start": "265400",
    "end": "272660"
  },
  {
    "text": "in using a variety of services like Kinesis for streaming data snowmobile if",
    "start": "272660",
    "end": "278030"
  },
  {
    "text": "you happen to have a hundred petabytes lying around that you need to move and that data can come to as three it can be",
    "start": "278030",
    "end": "284090"
  },
  {
    "text": "cataloged and then it's available for analysis and m/l we've got just about",
    "start": "284090",
    "end": "290810"
  },
  {
    "text": "you know it's a people in pretty much every industry at every scale or using",
    "start": "290810",
    "end": "295940"
  },
  {
    "text": "AWS for analytics and it's three for data leaks and really the thing to take away from this slide is a yes a lot of",
    "start": "295940",
    "end": "302120"
  },
  {
    "text": "people do this and all of you do which is great but it's really people of any scale so you can be starting small",
    "start": "302120",
    "end": "307760"
  },
  {
    "text": "running small experiments on megabytes but there's then these can scale up to hundreds of petabytes and beyond",
    "start": "307760",
    "end": "314600"
  },
  {
    "text": "so fortnight for example builds our s3 their data Lake entirely on this tree and that's 14 petabytes of data growing",
    "start": "314600",
    "end": "321890"
  },
  {
    "text": "at two petabytes a month all tracking how you're playing games to get you to play more and there's just a broad range",
    "start": "321890",
    "end": "329210"
  },
  {
    "text": "of use cases here but it's challenging so if you want to set up a data Lake",
    "start": "329210",
    "end": "334630"
  },
  {
    "text": "what do you have to do you have to figure out where your sources are you have to set up your storage locations on",
    "start": "334630",
    "end": "341030"
  },
  {
    "text": "s3 you've got to figure out where to land data that's raw where you're gonna put data that's been transformed and",
    "start": "341030",
    "end": "346790"
  },
  {
    "text": "curated you have to identify your data sources are they coming from Kinesis or",
    "start": "346790",
    "end": "351830"
  },
  {
    "text": "relational databases am i pulling in log files and once that data's in you're gonna clean it combine it transform it",
    "start": "351830",
    "end": "359060"
  },
  {
    "text": "and get it into a form that's optimized for query and then once it's in the",
    "start": "359060",
    "end": "364280"
  },
  {
    "text": "queryable system you then have to figure out what you're gonna do to govern access to that data how will you set up policies how will",
    "start": "364280",
    "end": "372020"
  },
  {
    "text": "you think about what data people are allowed to access how can you match that to the s3 permissions that you need how",
    "start": "372020",
    "end": "378260"
  },
  {
    "text": "do you configure the grants inside of redshift or the security controls inside of glue and then you'll make your data",
    "start": "378260",
    "end": "384950"
  },
  {
    "text": "available for analysis so there's a lot of work to be done and this can take",
    "start": "384950",
    "end": "390800"
  },
  {
    "text": "some of our customers months especially if you've got complex workloads or a very complicated enterprise security",
    "start": "390800",
    "end": "397310"
  },
  {
    "text": "policy or a large company with multiple different roles it takes a long time to get all of this",
    "start": "397310",
    "end": "402680"
  },
  {
    "text": "set up correctly to where you're confident to allow people open access",
    "start": "402680",
    "end": "408250"
  },
  {
    "text": "and a lot of time is actually spent dealing with data munging so if you",
    "start": "408250",
    "end": "414590"
  },
  {
    "text": "think about this is actually from a typical machine learning scientist workflow there's spent about 80 percent of their",
    "start": "414590",
    "end": "420110"
  },
  {
    "text": "time dealing with data and then the rest of it goes into things like feature extraction and building and training",
    "start": "420110",
    "end": "425420"
  },
  {
    "text": "models so data is really at the heart of this and you know we I work in the the",
    "start": "425420",
    "end": "431870"
  },
  {
    "text": "big data arena and I talk about it as being the plumbing underneath all of the sexy AI and m/l stuff but it's super",
    "start": "431870",
    "end": "437330"
  },
  {
    "text": "important and it's really the foundation for any sort of predictive analytics that you can drive so to give you a",
    "start": "437330",
    "end": "445700"
  },
  {
    "text": "sense from what customers have to do today to set up data leaks on s3 so you",
    "start": "445700",
    "end": "450800"
  },
  {
    "text": "start by figuring out where your data lives so here we're looking at RDS instances you're looking at databases",
    "start": "450800",
    "end": "456100"
  },
  {
    "text": "what data am I gonna pull in you then go to figure out where an s3 is gonna is",
    "start": "456100",
    "end": "462860"
  },
  {
    "text": "this gonna live I need to create my buckets typically customers will create a row zone for landing data that's",
    "start": "462860",
    "end": "469040"
  },
  {
    "text": "coming in its raw form then they'll create an area for curated data after it's been transformed and what we",
    "start": "469040",
    "end": "476000"
  },
  {
    "text": "recommend to customers is look you should bring in your raw data that will get processed downstream into something",
    "start": "476000",
    "end": "481430"
  },
  {
    "text": "that'll be query optimized but archive your raw data at a glacier just in case you need to go back to it at any point",
    "start": "481430",
    "end": "487130"
  },
  {
    "text": "in the future you've got an unvarnished view of history as it was created at the time and you can always recreate and we",
    "start": "487130",
    "end": "494060"
  },
  {
    "text": "see that as being very important for things like ml where you might want to go back and relook at the world with a better model but anyway coming back to",
    "start": "494060",
    "end": "501740"
  },
  {
    "text": "this you're putting data into s3 locations we're then figuring out access policies",
    "start": "501740",
    "end": "507260"
  },
  {
    "text": "and this is you know there's a lot of power in these they're very granular which is great for setting up fine gain",
    "start": "507260",
    "end": "514070"
  },
  {
    "text": "controls but it also makes it complicated to get correct and then once you've got your access policy set up you",
    "start": "514070",
    "end": "520789"
  },
  {
    "text": "have to define tables and you have to then say here's my schema this is what it looks like and the schema is backed",
    "start": "520789",
    "end": "527270"
  },
  {
    "text": "by s3 objects and partitions in this particular location and then you're able to actually then",
    "start": "527270",
    "end": "533440"
  },
  {
    "text": "start to think about what you might want to do to query and then before you're getting to query typically customers",
    "start": "533440",
    "end": "539410"
  },
  {
    "text": "will be generating data in in Log form CSV is JSON and then you'll want to",
    "start": "539410",
    "end": "544660"
  },
  {
    "text": "convert this into a query optimized format and for most of our customers that's typically or see or parkade and",
    "start": "544660",
    "end": "552580"
  },
  {
    "text": "those are better just because they're columnar and compressed so you'll get better query performance and you'll",
    "start": "552580",
    "end": "557860"
  },
  {
    "text": "generally pay less on data scanned and at this point you then have to set up",
    "start": "557860",
    "end": "563500"
  },
  {
    "text": "who's allowed to access your tables so we've gone from s3 permissions to data transformations to then access to your",
    "start": "563500",
    "end": "570430"
  },
  {
    "text": "schemas and then you can start to run queries so there's just a lot of work to",
    "start": "570430",
    "end": "575590"
  },
  {
    "text": "do before you can get started and now every time you add a data source or you want",
    "start": "575590",
    "end": "580600"
  },
  {
    "text": "to configure a new service or you add a new class of user you've got to go through this process again so it just",
    "start": "580600",
    "end": "586300"
  },
  {
    "text": "takes a long time both to set up and to maintain and this is what we're trying to get at and solve for you with lake",
    "start": "586300",
    "end": "592450"
  },
  {
    "text": "formation so we want to take a lot of the tedious manual aspects of this and the things that make it error-prone out",
    "start": "592450",
    "end": "598780"
  },
  {
    "text": "of the process and automate them and so with lake formation the intent is we",
    "start": "598780",
    "end": "604870"
  },
  {
    "text": "want to make it easy to get data in and ingest it and transform it we want to give you a central place to define your",
    "start": "604870",
    "end": "611800"
  },
  {
    "text": "security policies so they live with the data that way whatever service you use",
    "start": "611800",
    "end": "617140"
  },
  {
    "text": "it's okay because the policy is actually enforced with the data so as long as the user authenticates the data will define",
    "start": "617140",
    "end": "623470"
  },
  {
    "text": "what they're allowed to see so you can then let them use whatever tooling they want without having to worry about",
    "start": "623470",
    "end": "628600"
  },
  {
    "text": "whether inadvertently data is gonna be exposed that shouldn't be and then we want to you allow you to then give",
    "start": "628600",
    "end": "635110"
  },
  {
    "text": "people multiple entry points all governed by the same access policies and it's by combining these data sets and",
    "start": "635110",
    "end": "641200"
  },
  {
    "text": "breaking down silos or you can actually start to find interesting elements in your data sets so we'll go through",
    "start": "641200",
    "end": "650200"
  },
  {
    "text": "really how we do this with lake formation and really the way we think about the different stages are we want",
    "start": "650200",
    "end": "656560"
  },
  {
    "text": "to ingest data we want to register the locations both the sources and the destinations for data and your data Lake",
    "start": "656560",
    "end": "662640"
  },
  {
    "text": "we then want to help you set up security and control policies around your data we want to allow people to",
    "start": "662640",
    "end": "669480"
  },
  {
    "text": "discover and use datasets they're allowed to see and then this will allow them to run their queries to develop",
    "start": "669480",
    "end": "675870"
  },
  {
    "text": "their analyses and then we want to give admins a central place to monitor an audit data access so this way you can",
    "start": "675870",
    "end": "681900"
  },
  {
    "text": "close the loop around security you can set up permissions you can enforce encryption but then you can audit it's",
    "start": "681900",
    "end": "687480"
  },
  {
    "text": "always about verification after the fact and that's just important for compliance and peace of mind so on the registry",
    "start": "687480",
    "end": "695760"
  },
  {
    "text": "phase we're really you know we're big believers in s3 as the core foundation",
    "start": "695760",
    "end": "700920"
  },
  {
    "text": "for data leaks it's scalable it's durable it's highly available you've got all of the encryption capabilities",
    "start": "700920",
    "end": "706830"
  },
  {
    "text": "you've got its cross region copy capabilities the 11/9 durability design point it's just in our belief the best",
    "start": "706830",
    "end": "713490"
  },
  {
    "text": "way to build data leaks on AWS and that's really what we're doing we're managing your data in s3 using lake",
    "start": "713490",
    "end": "719670"
  },
  {
    "text": "formation you register any existing s3 buckets that you want to have as part of your lake with the service you can also",
    "start": "719670",
    "end": "727410"
  },
  {
    "text": "ask lake formation to create buckets for your data Lake if you haven't already set one up or if you're doing it for the first time and data is always under your",
    "start": "727410",
    "end": "735150"
  },
  {
    "text": "control you're not loading it into yet another silo it's living on s3 it's living in your accounts it's owned by",
    "start": "735150",
    "end": "740790"
  },
  {
    "text": "you you own all of the encryption keys and all of those controls we are managing that process to make it more",
    "start": "740790",
    "end": "746850"
  },
  {
    "text": "straightforward but ultimately ownership and retention lives with you and I just",
    "start": "746850",
    "end": "754260"
  },
  {
    "text": "want to emphasize one point we talk about open data formats in s3 as being really important and this is because it",
    "start": "754260",
    "end": "760290"
  },
  {
    "text": "gives you freedom from lock-in if you've got data in a CSV for a file or JSON or park' you can take it anywhere and use",
    "start": "760290",
    "end": "767580"
  },
  {
    "text": "it with just about anything we've engineered our services to work with this the open source ecosystem works",
    "start": "767580",
    "end": "772770"
  },
  {
    "text": "with this and you get that portability that's really important the other big benefit you get is your technology",
    "start": "772770",
    "end": "778200"
  },
  {
    "text": "agnostic so we have customers like FINRA that have moved from they started with greenplum on-premise they moved to hive",
    "start": "778200",
    "end": "784980"
  },
  {
    "text": "on MapReduce on s3 they were then able to spin up hive on tears in parallel and",
    "start": "784980",
    "end": "790080"
  },
  {
    "text": "then presto and spark because your data is decoupled from your analytic layer you can actually run anything",
    "start": "790080",
    "end": "795390"
  },
  {
    "text": "simultaneously and you get this ability to use the best breed of technology at any point in time",
    "start": "795390",
    "end": "800440"
  },
  {
    "text": "and test it without disrupting existing production workload so that last point is really important",
    "start": "800440",
    "end": "806120"
  },
  {
    "text": "open formats in your account on s3 we",
    "start": "806120",
    "end": "811340"
  },
  {
    "text": "then provide blueprints in lake formation so blueprints are predefined templates that make it easy to get data",
    "start": "811340",
    "end": "817850"
  },
  {
    "text": "out of data sources we ship with blueprints for databases relational",
    "start": "817850",
    "end": "823160"
  },
  {
    "text": "databases so the flavors of RDS and Aurora and then these could also be",
    "start": "823160",
    "end": "828710"
  },
  {
    "text": "databases on ec2 we also have support for data that's been ingested through Kinesis firehose onto us three and we've",
    "start": "828710",
    "end": "836060"
  },
  {
    "text": "got predefined templates and for building schema and partition for cloud",
    "start": "836060",
    "end": "841910"
  },
  {
    "text": "trail logs ELB logs CloudFront logs we'll continue to add to this and you can always add your custom recognizers",
    "start": "841910",
    "end": "849530"
  },
  {
    "text": "for data using glue jobs so glue lake formation really builds on glue so you",
    "start": "849530",
    "end": "854870"
  },
  {
    "text": "have all of the capability and openness of glue as well in order to ingest data but with blueprints you just point to",
    "start": "854870",
    "end": "861080"
  },
  {
    "text": "your data sources and we support a one-time ingest into your data leak as well as an ongoing incremental ingest",
    "start": "861080",
    "end": "867320"
  },
  {
    "text": "into the data leak so with blueprints we want to make this all just easy for you to setup and all you have to do when",
    "start": "867320",
    "end": "874640"
  },
  {
    "text": "you're using leak formation blueprints is point to your data sources tell us where you want that data to end up and",
    "start": "874640",
    "end": "880750"
  },
  {
    "text": "specify the frequency at which you want that data to be synced and then blueprints will discover the schemas in",
    "start": "880750",
    "end": "886940"
  },
  {
    "text": "the source data it'll automatically convert data if that's what you requested it will detect partitions as",
    "start": "886940",
    "end": "893300"
  },
  {
    "text": "opposed to new tables and keep track of that and it'll bring that in on a schedule and all of this is designed to",
    "start": "893300",
    "end": "899470"
  },
  {
    "text": "make it easy for you to get started but not for you to give up any control you always have the option to go in edit and",
    "start": "899470",
    "end": "905600"
  },
  {
    "text": "customize and so we're really trying to find the balance between making it easy to use to start but for those of you who",
    "start": "905600",
    "end": "912440"
  },
  {
    "text": "want to get into the details all of the powers available to you you just don't have to deal with it on your first",
    "start": "912440",
    "end": "918550"
  },
  {
    "text": "instance of the service and so with",
    "start": "918550",
    "end": "923990"
  },
  {
    "text": "blueprints we build on the capabilities of AWS glue so we provide templates and",
    "start": "923990",
    "end": "930320"
  },
  {
    "text": "workflow to manage what's running underneath which is glue jobs and glue crawlers that are",
    "start": "930320",
    "end": "935590"
  },
  {
    "text": "extracting and transforming data recognizing schema and partitions and glue already has the ability to talk to",
    "start": "935590",
    "end": "942310"
  },
  {
    "text": "wide range of databases both relational and dynamo and redshift as well as s3 and then there's the glue data catalog",
    "start": "942310",
    "end": "949510"
  },
  {
    "text": "which maintains a registry of your schema and databases in connexion so we really want to wrap all of this and make",
    "start": "949510",
    "end": "955690"
  },
  {
    "text": "this easy to use with lake formation and so the way that it works is we've also",
    "start": "955690",
    "end": "963490"
  },
  {
    "text": "added the ability to build in data cleansing capabilities and so this is",
    "start": "963490",
    "end": "968830"
  },
  {
    "text": "technology that we've been using in amazon.com for a long time if you think about our e-commerce business hundreds",
    "start": "968830",
    "end": "975010"
  },
  {
    "text": "of millions of customers billions of items in the catalog and this is typically messy data provided by other",
    "start": "975010",
    "end": "980560"
  },
  {
    "text": "people and so we have the ability to use ml to deduplicate data to link data",
    "start": "980560",
    "end": "986200"
  },
  {
    "text": "using fuzzy matching to figure out these things are actually the same and then we can provide ways for you to tune these",
    "start": "986200",
    "end": "992890"
  },
  {
    "text": "matches so you can actually show us if we're doing better or worse and then we can once you're satisfied build a job",
    "start": "992890",
    "end": "999130"
  },
  {
    "text": "that can be run periodically to clean up your data sets and we're starting with deduplication which is essentially",
    "start": "999130",
    "end": "1005790"
  },
  {
    "text": "removing duplicates from incoming data or matching it to existing data record linkage so the idea is that you might",
    "start": "1005790",
    "end": "1012210"
  },
  {
    "text": "have data which represents say a merchant ID but in one table it's called merchant ID and another it's merchants",
    "start": "1012210",
    "end": "1018360"
  },
  {
    "text": "underscore ID and we won't actually be able to infer that these are the same thing semantically and so these ml",
    "start": "1018360",
    "end": "1024360"
  },
  {
    "text": "transform jobs let you do that and you know a little bit of a deep dive here so",
    "start": "1024360",
    "end": "1030240"
  },
  {
    "text": "the classic way to do this is you take data sets you look at all pairs of your data sets and you try and compute",
    "start": "1030240",
    "end": "1036240"
  },
  {
    "text": "similarity and then you build partitions based on the likelihood that something is similar now this is fine except that",
    "start": "1036240",
    "end": "1043319"
  },
  {
    "text": "it's an N squared algorithm meaning that your processing time goes up dramatically as your data volumes",
    "start": "1043319",
    "end": "1048750"
  },
  {
    "text": "increase and pretty quickly this becomes untenable so the technology that we're",
    "start": "1048750",
    "end": "1053760"
  },
  {
    "text": "using in lake formation is actually first talked about at vldb in 2008 but",
    "start": "1053760",
    "end": "1059490"
  },
  {
    "text": "it's a parallelizable way to build dynamic pairing and candidate sets across large volumes of data so looking",
    "start": "1059490",
    "end": "1067440"
  },
  {
    "text": "at 400 million rows of data and seven and a half billion candidate pairs for matching you can actually get this done",
    "start": "1067440",
    "end": "1072510"
  },
  {
    "text": "in under three hours and then we use customer input as training data so we",
    "start": "1072510",
    "end": "1078690"
  },
  {
    "text": "can actually not require you to spend time fine-tuning models but rather just tell us this is what I want it to look",
    "start": "1078690",
    "end": "1084360"
  },
  {
    "text": "like and the system will adapt itself and when you're satisfied will then run that on a schedule or on an event and",
    "start": "1084360",
    "end": "1091040"
  },
  {
    "text": "we'll continue to build on these over time and as we hear from you about what you'd like to see in this area master",
    "start": "1091040",
    "end": "1099450"
  },
  {
    "text": "security so this is the the other big time-saving piece that we've got in lake formation so any of you any of you that",
    "start": "1099450",
    "end": "1107220"
  },
  {
    "text": "have built data leak so that's three know that it's a challenge to actually get the security right because as users",
    "start": "1107220",
    "end": "1112800"
  },
  {
    "text": "we think about tables and we think about columns and we think about rows but once you're on s3 you're thinking about",
    "start": "1112800",
    "end": "1119010"
  },
  {
    "text": "objects and buckets and Ackles and figuring out the mapping between those can be challenging and then you've",
    "start": "1119010",
    "end": "1126150"
  },
  {
    "text": "got to set up that mapping in any so every service that you use so you've essentially have a problem that",
    "start": "1126150",
    "end": "1131400"
  },
  {
    "text": "multiplies anytime you're adding a new capability to your data leak and so what we set out to do with lake formation was",
    "start": "1131400",
    "end": "1137130"
  },
  {
    "text": "to really simplify this and turn the problem inside out to allow you to essentially set up your data Lake",
    "start": "1137130",
    "end": "1142530"
  },
  {
    "text": "permissions in lake formation have the access control policies live next to the",
    "start": "1142530",
    "end": "1147840"
  },
  {
    "text": "data in the data catalog and then when users come in and authenticate and then",
    "start": "1147840",
    "end": "1153210"
  },
  {
    "text": "try to use a service the service actually sends the user credentials and the roles the user has to Lake formation",
    "start": "1153210",
    "end": "1159540"
  },
  {
    "text": "the lake formation catalog looks at those roles see what that user's allowed to access returns a short-term",
    "start": "1159540",
    "end": "1165540"
  },
  {
    "text": "credential that represents the data that that person is allowed to see and so regardless of the service the customer",
    "start": "1165540",
    "end": "1171900"
  },
  {
    "text": "used to come in they're going to get a policy vendor to them that defines what data they can see and this will be",
    "start": "1171900",
    "end": "1177870"
  },
  {
    "text": "honored in Athena in redshift and in EMR and so you'll get the ability to essentially define permissions once and",
    "start": "1177870",
    "end": "1185040"
  },
  {
    "text": "then open up access to a range of managed services and then those will come in and have those policies enforced",
    "start": "1185040",
    "end": "1194450"
  },
  {
    "text": "and so in the lake formation console and API as we give you a way to easily",
    "start": "1194450",
    "end": "1200419"
  },
  {
    "text": "control access to data so in the top right you've got console screenshot it",
    "start": "1200419",
    "end": "1205730"
  },
  {
    "text": "shows tables you can add or revoke permissions for tables you can think",
    "start": "1205730",
    "end": "1211460"
  },
  {
    "text": "about what users and roles can access which tables and columns you don't have to think about objects and then we give",
    "start": "1211460",
    "end": "1217970"
  },
  {
    "text": "you easy ways to see what policies a user has or you can see what permissions",
    "start": "1217970",
    "end": "1223279"
  },
  {
    "text": "have been given on a particular table so we want to give you multiple vectors to analyze who's allowed to see what and",
    "start": "1223279",
    "end": "1230239"
  },
  {
    "text": "that gives you a central place from which to audit all data access and",
    "start": "1230239",
    "end": "1236889"
  },
  {
    "text": "similarly we want you to be able to search and understand what permissions people have so in the top right you've",
    "start": "1236889",
    "end": "1242749"
  },
  {
    "text": "got user permissions you can see a user name you can see what tables are allowed to access you can see what permissions",
    "start": "1242749",
    "end": "1249889"
  },
  {
    "text": "they have on that table this is explorable to the console or VAP eyes and you can go the other way rather",
    "start": "1249889",
    "end": "1256129"
  },
  {
    "text": "than looking and saying hey what can this user do you can say oh I have this table who's allowed to do what to it and",
    "start": "1256129",
    "end": "1262789"
  },
  {
    "text": "you can come the other way and look at tables or columns and see who has permissions to interact with them and",
    "start": "1262789",
    "end": "1268789"
  },
  {
    "text": "then we also give you the ability to easily revoke all permissions from a particular user and so this way you can",
    "start": "1268789",
    "end": "1275330"
  },
  {
    "text": "if someone leaves the company or changes roles it becomes easy to actually guarantee securely that they're not able",
    "start": "1275330",
    "end": "1283309"
  },
  {
    "text": "to access data that they shouldn't by revoking their their abilities and their policies and that requires a",
    "start": "1283309",
    "end": "1289159"
  },
  {
    "text": "confirmation step so you don't do it by accident and unlock people out the other",
    "start": "1289159",
    "end": "1296210"
  },
  {
    "text": "thing that we've built into lake formation is the ability to segregate permissions by columns so this is a",
    "start": "1296210",
    "end": "1301779"
  },
  {
    "text": "sample table it's got a list of columns and data types and you can restrict what",
    "start": "1301779",
    "end": "1307279"
  },
  {
    "text": "user one can see they can just see a subset user to potentially has an admin role in this case they can see",
    "start": "1307279",
    "end": "1313129"
  },
  {
    "text": "everything so this allows you to do things like restrict access to PII because you can say like you know data",
    "start": "1313129",
    "end": "1320509"
  },
  {
    "text": "analysts normally will not have access to columns that contain PII but maybe my auditor does and so this allows you to",
    "start": "1320509",
    "end": "1327590"
  },
  {
    "text": "get very great in terms of who's allowed to see what and do it in a way that maps to how we",
    "start": "1327590",
    "end": "1333600"
  },
  {
    "text": "think about accessing data which is tables rows and columns not not sort of",
    "start": "1333600",
    "end": "1338700"
  },
  {
    "text": "buckets and objects and so to dig a little deeper into the data flow what's",
    "start": "1338700",
    "end": "1345630"
  },
  {
    "text": "happening here is when a user tries to query a table which is step one the",
    "start": "1345630",
    "end": "1351269"
  },
  {
    "text": "services that they're using Athena EMR redshift they make a request to lake",
    "start": "1351269",
    "end": "1356340"
  },
  {
    "text": "formation for access to that table so lake formation verifies that the users",
    "start": "1356340",
    "end": "1361620"
  },
  {
    "text": "authenticated this can be done through I am users or roles we'd also support Active Directory",
    "start": "1361620",
    "end": "1367019"
  },
  {
    "text": "integrations for Federation so once we know who a user is or what group they're part of lake formation and the catalog",
    "start": "1367019",
    "end": "1374490"
  },
  {
    "text": "will then short-term credentials that essentially encode the set of permissions that user or role has for",
    "start": "1374490",
    "end": "1381450"
  },
  {
    "text": "data that permission goes back to the service so lake formation isn't in the read path the service gets back the",
    "start": "1381450",
    "end": "1388139"
  },
  {
    "text": "token that represents the data access policy the service then requests as three for those objects those objects",
    "start": "1388139",
    "end": "1395879"
  },
  {
    "text": "come back and then the service will actually filter out things like columns the person isn't allowed to see based on",
    "start": "1395879",
    "end": "1402539"
  },
  {
    "text": "the data access policy before it ever gets back to the user so essentially you've got the ability to do very",
    "start": "1402539",
    "end": "1408840"
  },
  {
    "text": "fine-grained access control on data that ties into the customer the models of authentication that we're all familiar",
    "start": "1408840",
    "end": "1414750"
  },
  {
    "text": "with and and you can be comfortable knowing that regardless of the entry",
    "start": "1414750",
    "end": "1420779"
  },
  {
    "text": "point because we're enforcing policy at the data layer we will enforce and make",
    "start": "1420779",
    "end": "1426330"
  },
  {
    "text": "sure the right columns get shown back to the user and a naturally this is a shared security model for infrastructure",
    "start": "1426330",
    "end": "1431789"
  },
  {
    "text": "we control we we are responsible but you know if your users are tweeting out their database passwords there's not",
    "start": "1431789",
    "end": "1437789"
  },
  {
    "text": "much we can do about that so Security's on both of us now the other important part here is",
    "start": "1437789",
    "end": "1443549"
  },
  {
    "text": "that Lake formations credential mechanism is not in the read path of all",
    "start": "1443549",
    "end": "1449070"
  },
  {
    "text": "of your services you're not generating these bottlenecks at the lake formation layer essentially the credential goes",
    "start": "1449070",
    "end": "1454409"
  },
  {
    "text": "back to the service that does the filtering so this is a huge time saver",
    "start": "1454409",
    "end": "1459690"
  },
  {
    "text": "for customers and we're excited to get your feedback on it as you get to using this so this",
    "start": "1459690",
    "end": "1464840"
  },
  {
    "text": "has been the security in the access control piece of the stage the next stage is really about searching and",
    "start": "1464840",
    "end": "1470869"
  },
  {
    "text": "collaborating with data so we're extending the catalog to allow customers to put in business metadata around",
    "start": "1470869",
    "end": "1477320"
  },
  {
    "text": "tables and columns so you can when you bring in a new data set you can say look this is customer sales history for my",
    "start": "1477320",
    "end": "1483700"
  },
  {
    "text": "European regions and you can also add other attributes like data owners or",
    "start": "1483700",
    "end": "1489049"
  },
  {
    "text": "data stewards and these become table properties you can also talk about data sensitivity you can add definitions two",
    "start": "1489049",
    "end": "1496070"
  },
  {
    "text": "columns will also support adding tags and all of this then becomes searchable so you can then search for datasets in",
    "start": "1496070",
    "end": "1502820"
  },
  {
    "text": "the catalog you can look for all data related to customers for example you can say show me all data with these column",
    "start": "1502820",
    "end": "1510139"
  },
  {
    "text": "attributes so data discovery becomes a lot easier and more meaningful and you",
    "start": "1510139",
    "end": "1515690"
  },
  {
    "text": "can then once you've searched and you found a data set you like you can straightaway go to view the data which",
    "start": "1515690",
    "end": "1521240"
  },
  {
    "text": "essentially launches a query and Athena and keeps track of all of the permissions that you have so you're not",
    "start": "1521240",
    "end": "1526340"
  },
  {
    "text": "allowed to see data that you don't have permissions for you won't be able to query it but it's a great way to then",
    "start": "1526340",
    "end": "1531619"
  },
  {
    "text": "collaborate around your data catalog and so this is a way to prevent you losing",
    "start": "1531619",
    "end": "1537470"
  },
  {
    "text": "track of what data you have you essentially start to build a catalog and an ability to explore that and make that",
    "start": "1537470",
    "end": "1542600"
  },
  {
    "text": "data broadly accessible within your organization's and then we give you a",
    "start": "1542600",
    "end": "1548419"
  },
  {
    "text": "central place to where you can audit and monitor data activities so if you think about what we've done we've created a",
    "start": "1548419",
    "end": "1554539"
  },
  {
    "text": "central authorization point for data access which means that every time a user accesses data the system knows",
    "start": "1554539",
    "end": "1560779"
  },
  {
    "text": "about it so this then gives you a great place from which to audit data access so in the console you're able to see who",
    "start": "1560779",
    "end": "1566570"
  },
  {
    "text": "has done what you can see if permissions were added or removed and then you can also download these logs for further",
    "start": "1566570",
    "end": "1572960"
  },
  {
    "text": "analysis in other systems and we're also publishing these events these data",
    "start": "1572960",
    "end": "1578600"
  },
  {
    "text": "ingest events and catalog notifications to cloud watch and then you can take actions based on that using cloud what",
    "start": "1578600",
    "end": "1584389"
  },
  {
    "text": "actions so it allows you to build workflows based on what's going on with your data in a way that's much easier",
    "start": "1584389",
    "end": "1590269"
  },
  {
    "text": "than was possible before I because we've got this central point of authorization",
    "start": "1590269",
    "end": "1595520"
  },
  {
    "text": "and around data so let's just walk through what that's gonna look like so",
    "start": "1595520",
    "end": "1602000"
  },
  {
    "text": "we'll look at blueprints for ingestion we'll look at granting permissions and then we'll just set an example of",
    "start": "1602000",
    "end": "1608240"
  },
  {
    "text": "querying data so with blueprints in the top left you're creating a blueprint so",
    "start": "1608240",
    "end": "1614750"
  },
  {
    "text": "here we're picking a database incremental load sorry it's probably a little hard to read you then pick your data source",
    "start": "1614750",
    "end": "1621740"
  },
  {
    "text": "details here we're picking a wordpress import table we're picking our roles we're choosing whether it's gonna be",
    "start": "1621740",
    "end": "1628070"
  },
  {
    "text": "incremental or not we're picking the column that we're going to use to determine whether the data is incremental and then we will essentially",
    "start": "1628070",
    "end": "1636230"
  },
  {
    "text": "set this process up and it'll just start going so all you're doing is figuring out which blueprint you want pointing it",
    "start": "1636230",
    "end": "1642230"
  },
  {
    "text": "to your tables setting any configurations and then we'll go and then you can monitor the import of this",
    "start": "1642230",
    "end": "1647930"
  },
  {
    "text": "data into your data Lake in this case it's completed successfully which is conveniently highlighted there and",
    "start": "1647930",
    "end": "1653570"
  },
  {
    "text": "you've got the other properties around the table name the role that's associated with it the s3 object that's",
    "start": "1653570",
    "end": "1659450"
  },
  {
    "text": "backing that table definition and once that's data can is then import it into",
    "start": "1659450",
    "end": "1666440"
  },
  {
    "text": "your data Lake it's imported as a table so you have a concept of what the columns are what the types are that's",
    "start": "1666440",
    "end": "1672380"
  },
  {
    "text": "all registered and then you can start to grant permissions to it so now we can",
    "start": "1672380",
    "end": "1677780"
  },
  {
    "text": "say which users have permissions and which don't so in this case we're giving permissions",
    "start": "1677780",
    "end": "1683000"
  },
  {
    "text": "to two Shaam to access this table and he's getting select permissions and that's the only user that has access to",
    "start": "1683000",
    "end": "1689840"
  },
  {
    "text": "this table and then we can go run a query in Athena so here we've got in the",
    "start": "1689840",
    "end": "1695690"
  },
  {
    "text": "top left Shaun's user is running a query he's got permission he's able to run the",
    "start": "1695690",
    "end": "1700760"
  },
  {
    "text": "query he sees results but then Austin is logged in and when Austin tries to query",
    "start": "1700760",
    "end": "1705980"
  },
  {
    "text": "the table he didn't have permission and so he doesn't see any results so this way that's all enforce of the data layer",
    "start": "1705980",
    "end": "1711140"
  },
  {
    "text": "and then the services take care of enforcing that policy upstream and there's no additional charge for lake",
    "start": "1711140",
    "end": "1718190"
  },
  {
    "text": "formation so you're only going to be charged for the underlying resources and services that you consume we don't",
    "start": "1718190",
    "end": "1723920"
  },
  {
    "text": "believe that customers should have to pay extra for security or for ease of use and really that's why we've chosen this pricing approach so",
    "start": "1723920",
    "end": "1730450"
  },
  {
    "text": "it's really designed to help you accelerate your use of s3 for data Lakes make it easy to secure them centrally",
    "start": "1730450",
    "end": "1736419"
  },
  {
    "text": "and then use the services as you would before and some of the customers that",
    "start": "1736419",
    "end": "1742360"
  },
  {
    "text": "we've working been working with prior to this as we've developed the service so changed healthcare they want a central",
    "start": "1742360",
    "end": "1748779"
  },
  {
    "text": "point of control they're one of the largest payment processors in the industry and and patient record",
    "start": "1748779",
    "end": "1755350"
  },
  {
    "text": "providers and so they have a need for HIPPA certification which wake formation ships with on day one and then they",
    "start": "1755350",
    "end": "1761889"
  },
  {
    "text": "really need to maintain very strict control and auditing of who I can access their data and then Fender digital you",
    "start": "1761889",
    "end": "1768639"
  },
  {
    "text": "probably know offender from the guitars of offender digital brill's apps and digital experiences around those guitars",
    "start": "1768639",
    "end": "1774490"
  },
  {
    "text": "and so they're also looking to build data leaks to understand customer experience and for them again they want",
    "start": "1774490",
    "end": "1780250"
  },
  {
    "text": "to have a single place to look at activity marketing data but also not be",
    "start": "1780250",
    "end": "1785380"
  },
  {
    "text": "confident that no PII or anything like that is being exposed anywhere else and",
    "start": "1785380",
    "end": "1792190"
  },
  {
    "text": "you know before I wrap up I just want to ask the Big Data and lake formation team",
    "start": "1792190",
    "end": "1797860"
  },
  {
    "text": "members who are here to please just stand up for a second those folks in the corner so I've given the presentation I",
    "start": "1797860",
    "end": "1804610"
  },
  {
    "text": "haven't done any of the work in building this service I just want to give them a round of applause",
    "start": "1804610",
    "end": "1810179"
  },
  {
    "text": "thank you and there's many more folks that couldn't make it here but it's really them that I've done the work to",
    "start": "1812160",
    "end": "1818410"
  },
  {
    "text": "deliver this to you and that's all I have for slides I'm happy to stick around for questions I won't take",
    "start": "1818410",
    "end": "1824620"
  },
  {
    "text": "offense if people want to go leave and get drinks but thank you very much folks really appreciate it",
    "start": "1824620",
    "end": "1830470"
  },
  {
    "text": "you know as you get into the preview we're super excited to get your feedback please email me or email us and thank",
    "start": "1830470",
    "end": "1838120"
  },
  {
    "text": "you for coming to reinvent I think",
    "start": "1838120",
    "end": "1845620"
  },
  {
    "text": "there's mics for questions if people want yeah go ahead",
    "start": "1845620",
    "end": "1851340"
  },
  {
    "text": "okay I went to ask about thinking about gee PDR for instance what if I have to",
    "start": "1851340",
    "end": "1859330"
  },
  {
    "text": "delete some kind of data for a specific user is that kind is there any flow",
    "start": "1859330",
    "end": "1865570"
  },
  {
    "text": "inside lake formation for that kind of use so we're definitely thinking about",
    "start": "1865570",
    "end": "1870940"
  },
  {
    "text": "that it's a common so the question was are there any built in flows for dealing with gdpr data in lake formation so at",
    "start": "1870940",
    "end": "1877630"
  },
  {
    "text": "the moment no but we are thinking about that the typical model that our customers use is they'll build an",
    "start": "1877630",
    "end": "1883330"
  },
  {
    "text": "exclude filter and then essentially run a job behind the scenes to do a delete of that data within the SLA that's",
    "start": "1883330",
    "end": "1890290"
  },
  {
    "text": "required by the right to be forgotten but you know please stay tuned we're definitely thinking about what we can do",
    "start": "1890290",
    "end": "1895900"
  },
  {
    "text": "here oh yeah go ahead I'll just alternate so yeah two questions so first",
    "start": "1895900",
    "end": "1902970"
  },
  {
    "text": "so does Lake permission to introduce a compute layer on top of s3 to resolve",
    "start": "1902970",
    "end": "1909100"
  },
  {
    "text": "those permissions they call column level permissions oh it does it just bypass",
    "start": "1909100",
    "end": "1914650"
  },
  {
    "text": "the permissions to decree service whether it's red shift or athina in the service handles the permissions",
    "start": "1914650",
    "end": "1920950"
  },
  {
    "text": "themselves and the second questions is what about row level based parameters so",
    "start": "1920950",
    "end": "1927670"
  },
  {
    "text": "answer the second question first yes we are working on row level permissions it'll probably come immediately post GA",
    "start": "1927670",
    "end": "1934660"
  },
  {
    "text": "it's very common request so we absolutely will support that you know essentially what we're doing",
    "start": "1934660",
    "end": "1940790"
  },
  {
    "text": "with lake formation the way it's working is we have built we've built extensions",
    "start": "1940790",
    "end": "1947750"
  },
  {
    "text": "to the catalog that will vent short-term credentials and then we've modified our analytic services to use those",
    "start": "1947750",
    "end": "1954350"
  },
  {
    "text": "short-term credentials to prevent any unnecessary or unauthorized data from getting back into the system so we're",
    "start": "1954350",
    "end": "1959780"
  },
  {
    "text": "not introducing additional layers we're modifying the capabilities of the top-level services to deal with that",
    "start": "1959780",
    "end": "1964940"
  },
  {
    "text": "okay thanks God hi my question is that do you",
    "start": "1964940",
    "end": "1970700"
  },
  {
    "text": "support incremental loads when it comes to relational databases and if you do how do you handle the mutable data can",
    "start": "1970700",
    "end": "1978650"
  },
  {
    "text": "you say the last part of my stuff if you do support the incremental loads but for",
    "start": "1978650",
    "end": "1983780"
  },
  {
    "text": "the relational databases do you and how do you handle the immutable data mutable",
    "start": "1983780",
    "end": "1989420"
  },
  {
    "text": "data so we do support incremental loads today we require essentially a primary key column that we will look at yeah so",
    "start": "1989420",
    "end": "1996020"
  },
  {
    "text": "as long as that doesn't as long as that is something that we can look at to understand when new data is arrived",
    "start": "1996020",
    "end": "2001750"
  },
  {
    "text": "we're able to do it for data that's mutating in place without updating any of those we'd need you to take some sort",
    "start": "2001750",
    "end": "2007780"
  },
  {
    "text": "of action to signal to us that we'd have to bring that data in okay I have a",
    "start": "2007780",
    "end": "2014620"
  },
  {
    "text": "specific use case I was history staging area yep I want to move all the files",
    "start": "2014620",
    "end": "2020560"
  },
  {
    "text": "from that staging area to a specific target but I want to validate the files on the fly and if any of them fails I",
    "start": "2020560",
    "end": "2028390"
  },
  {
    "text": "wanna cancel all the transfers yeah you can so essentially we're using",
    "start": "2028390",
    "end": "2034060"
  },
  {
    "text": "glue ETL jobs under the underneath and glue ETL jobs are essentially running PI",
    "start": "2034060",
    "end": "2039280"
  },
  {
    "text": "spark code so you could build that validation into your glue ETL job so",
    "start": "2039280",
    "end": "2044560"
  },
  {
    "text": "it'll basically validate on read and it won't take any additional steps if that data fails so that can be built in but",
    "start": "2044560",
    "end": "2050648"
  },
  {
    "text": "you'd have to encode that into the ETL job through adding it to the PI spark job itself and it would be a transaction",
    "start": "2050649",
    "end": "2056980"
  },
  {
    "text": "level basically everything all the files that have already been moved would be cancelled I think it's entirely up to",
    "start": "2056980",
    "end": "2063520"
  },
  {
    "text": "you as to how you'd set that up so some customers would rather just skip a file other customers may want to fail the",
    "start": "2063520",
    "end": "2069010"
  },
  {
    "text": "entire batch but you would have control over how you configured that I just want please starting to cheat with to",
    "start": "2069010",
    "end": "2075570"
  },
  {
    "text": "restaurant is it possible to using the monitoring level to know when the file",
    "start": "2075570",
    "end": "2080919"
  },
  {
    "text": "was accessed yes so the auditable because we provide that central author",
    "start": "2080920",
    "end": "2087340"
  },
  {
    "text": "authorization point you will know when that file was accessed through the audit logs thank you sure good hello",
    "start": "2087340",
    "end": "2094899"
  },
  {
    "text": "so we're gonna limit it to one and one follow-up because we could be here a long time okay two quick questions the",
    "start": "2094900",
    "end": "2100660"
  },
  {
    "text": "lake formation catalog is it the same as a glue data catalog or is it a different implementation it'll be the same so",
    "start": "2100660",
    "end": "2107140"
  },
  {
    "text": "you'll have one catalog during the preview we'll have to okay but once we get to J it'll be one catalog that's",
    "start": "2107140",
    "end": "2113010"
  },
  {
    "text": "consistent across Glu lake formation athena mr redshift and the second question is an incremental load of data",
    "start": "2113010",
    "end": "2120670"
  },
  {
    "text": "will it recognize the deleted rose it's sources I don't know the answer to that",
    "start": "2120670",
    "end": "2126490"
  },
  {
    "text": "so if you just drop me an email we'll get you an answer it may be just email lake formation PM",
    "start": "2126490",
    "end": "2132100"
  },
  {
    "text": "and all thank you thanks a lot this kind of builds off both him in the previous",
    "start": "2132100",
    "end": "2137200"
  },
  {
    "text": "guy over there now with coordinated I was curious if you guys had any plans to",
    "start": "2137200",
    "end": "2142810"
  },
  {
    "text": "support like a change data capture style blueprint where you're capturing every change that's replicating off the",
    "start": "2142810",
    "end": "2148030"
  },
  {
    "text": "database something along those lines so the blueprint today is essentially doing",
    "start": "2148030",
    "end": "2153880"
  },
  {
    "text": "incremental load based on querying a column you know it would be interesting",
    "start": "2153880",
    "end": "2158980"
  },
  {
    "text": "to look at there's some our DMS service for example supports streaming changes",
    "start": "2158980",
    "end": "2164590"
  },
  {
    "text": "onto s3 and those could be consumed and there are a number of other services that'll handle CDC into s3 and at that point that could",
    "start": "2164590",
    "end": "2171700"
  },
  {
    "text": "be ingest and applied but it's not built into a blueprint today but I suspect based on the volume of questions about",
    "start": "2171700",
    "end": "2178240"
  },
  {
    "text": "this we'll have to think about how we do that before too long gotcha thank you sure you talked about",
    "start": "2178240",
    "end": "2184440"
  },
  {
    "text": "centralization of them say access controls and policy are any other policy",
    "start": "2184440",
    "end": "2189460"
  },
  {
    "text": "centralized for example applying encryption uniformly across m vm rs3 etc",
    "start": "2189460",
    "end": "2196170"
  },
  {
    "text": "so the short answer is yes not all of that will be done through the lake formation catalog although we can",
    "start": "2196170",
    "end": "2202150"
  },
  {
    "text": "explore ways to expose those controls but I don't know if you call the announcement around s3 account level",
    "start": "2202150",
    "end": "2210130"
  },
  {
    "text": "controls you can essentially require that accounts are say all blocked or that nothing can be written without encryption so at the s3 layer you could",
    "start": "2210130",
    "end": "2217839"
  },
  {
    "text": "do that this is more about at the logical construct of tables and columns what are people allowed to see thank you",
    "start": "2217839",
    "end": "2225030"
  },
  {
    "text": "about the incremental ingest what are kind of mechanism to ensure we don't",
    "start": "2225030",
    "end": "2231940"
  },
  {
    "text": "overload the database like a number of connections or and the size of the batch",
    "start": "2231940",
    "end": "2237359"
  },
  {
    "text": "what kind of options we have yeah so I'm sorry I don't have a precise answer to",
    "start": "2237359",
    "end": "2242980"
  },
  {
    "text": "that but if you email us at lake formation p.m. we can get into it and as",
    "start": "2242980",
    "end": "2248500"
  },
  {
    "text": "we get into the preview we'll be happy to answer that that's a good question okay sorry follow up a question about a",
    "start": "2248500",
    "end": "2254020"
  },
  {
    "text": "lot of use cases we have a lot of tables mm-hmm to microwave some of them just",
    "start": "2254020",
    "end": "2259990"
  },
  {
    "text": "small tables is there any mechanism to combine all these to a single groove job so right now I guess one source table is",
    "start": "2259990",
    "end": "2267609"
  },
  {
    "text": "a one clue job right it doesn't necessarily have to be one glue job so we could you know we could work with you",
    "start": "2267609",
    "end": "2274540"
  },
  {
    "text": "to help design a glue job that looked at a set of tables and coalesced them okay I think actually doable Thanks hi so my",
    "start": "2274540",
    "end": "2281440"
  },
  {
    "text": "team currently uses Apache airflow Forge all of our pipelines is there a way to externally trigger these schedules for",
    "start": "2281440",
    "end": "2288250"
  },
  {
    "text": "the ingestion layer so I believe there will be just because everything is",
    "start": "2288250",
    "end": "2293950"
  },
  {
    "text": "accessible via API so you could use things like lambda events on data arrival or you could trigger API calls",
    "start": "2293950",
    "end": "2300520"
  },
  {
    "text": "from your air flow scheduler in order to get these processes rolling through CLI I don't know the air flows oh sorry yes",
    "start": "2300520",
    "end": "2309250"
  },
  {
    "text": "if we have api's will also have CLI corresponding CLI calls so you could do it that way as well thank you yep first",
    "start": "2309250",
    "end": "2315400"
  },
  {
    "text": "of all thank you this is amazing it's all these guys this amazing job is even like zoom to transform our lives the",
    "start": "2315400",
    "end": "2322839"
  },
  {
    "text": "question I have is do you plan to support group blueprints for moving like",
    "start": "2322839",
    "end": "2328000"
  },
  {
    "text": "Hadoop as GFS payload to s3 in an easy way that's once in our we come up in",
    "start": "2328000",
    "end": "2333190"
  },
  {
    "text": "very often yeah so I can't speak to specifics but you know customer feedback",
    "start": "2333190",
    "end": "2338650"
  },
  {
    "text": "really drives all of this and absolutely at the hdfs to files on s3 path is one that",
    "start": "2338650",
    "end": "2344980"
  },
  {
    "text": "we absolutely want to enable you know we don't have blueprints for that now I suspect as we get into the preview we'll",
    "start": "2344980",
    "end": "2351490"
  },
  {
    "text": "learn about that but we also do have a lot of experience with customers moving HDFS to s3 and so we can definitely help",
    "start": "2351490",
    "end": "2358180"
  },
  {
    "text": "you out with that the same email alias will be good and we'll connect the right dots thank you sure so my team already",
    "start": "2358180",
    "end": "2365020"
  },
  {
    "text": "created a solution for data Lake we're using blue crawlers Athena lambdas the",
    "start": "2365020",
    "end": "2371950"
  },
  {
    "text": "only missing part we had is the security are we going to be able to use migrate whatever we did or use whatever we have",
    "start": "2371950",
    "end": "2378369"
  },
  {
    "text": "or we have to start from scratch you'll be able to migrate so once in the",
    "start": "2378369",
    "end": "2384099"
  },
  {
    "text": "preview phase we don't want customers using this with production data but as soon as we get out of preview early next year you'll be able to migrate and build",
    "start": "2384099",
    "end": "2390280"
  },
  {
    "text": "on everything that you've got so because we're essentially extending what glue can do today the work that you've done",
    "start": "2390280",
    "end": "2396369"
  },
  {
    "text": "will will essentially act as a foundation of where you go from there awesome thank you yep I promise just one",
    "start": "2396369",
    "end": "2403119"
  },
  {
    "text": "question it's done another issue that's close to to heart in our company's data",
    "start": "2403119",
    "end": "2408910"
  },
  {
    "text": "lineage so if I can trace toward it which file was accessed Oh two files as",
    "start": "2408910",
    "end": "2415000"
  },
  {
    "text": "I said by process then they've been loaded processed written a new file for it is there a way for me to basically",
    "start": "2415000",
    "end": "2421750"
  },
  {
    "text": "track this yeah so this is very similar",
    "start": "2421750",
    "end": "2427000"
  },
  {
    "text": "to the row level permissions question absolutely soon post VA we will support data lineage and the ability to",
    "start": "2427000",
    "end": "2432670"
  },
  {
    "text": "understand you know where data went and where data came from it's gonna be a",
    "start": "2432670",
    "end": "2438160"
  },
  {
    "text": "very super common task so thank you yep what is the support you you're gonna",
    "start": "2438160",
    "end": "2445329"
  },
  {
    "text": "offer for cross accountant data sets so data sets in multiple accounts being",
    "start": "2445329",
    "end": "2451000"
  },
  {
    "text": "brought in to a central glue catalog and then consumed for multiple accounts is that something that comes out of the box yes so essentially that's supported in",
    "start": "2451000",
    "end": "2458440"
  },
  {
    "text": "Glu today and typically it's very common for our customers to have an account that owns data and then allow other accounts to",
    "start": "2458440",
    "end": "2464680"
  },
  {
    "text": "access data so that that model should be supported out of the box but in this case have multiple accounts that own",
    "start": "2464680",
    "end": "2470140"
  },
  {
    "text": "data and multiple consumers of those you know we should follow up so just",
    "start": "2470140",
    "end": "2475820"
  },
  {
    "text": "drop me out it's always and the details on these things thank you Thanks my question is about the query or is such",
    "start": "2475820",
    "end": "2484070"
  },
  {
    "text": "been able to discover the images you have in the lake I know you talk a lot about like you gave the example example",
    "start": "2484070",
    "end": "2491000"
  },
  {
    "text": "about CSV files and looking at the tables if you have just a bunch of files",
    "start": "2491000",
    "end": "2496930"
  },
  {
    "text": "hundreds of thousands of images for example I mean how does it how would it",
    "start": "2496930",
    "end": "2503000"
  },
  {
    "text": "be easy to query for those things yeah so you know the way I would think about",
    "start": "2503000",
    "end": "2508310"
  },
  {
    "text": "making sense of data and images or videos I would use a service like recognition and that'll descent",
    "start": "2508310",
    "end": "2514640"
  },
  {
    "text": "regenerate a list of objects and a list of metadata so scene detection what's in the object what kind of people and that",
    "start": "2514640",
    "end": "2521810"
  },
  {
    "text": "metadata is then something that you can ingest into something like elastic search that's the best way to get a",
    "start": "2521810",
    "end": "2527360"
  },
  {
    "text": "search index built on top of things like video or imagery that's not really the",
    "start": "2527360",
    "end": "2532640"
  },
  {
    "text": "use case we're targeting at the moment with the catalog but we're always open to feedback on thank you is there any",
    "start": "2532640",
    "end": "2540560"
  },
  {
    "text": "data masking functionality or features we're like no in just like a no other than column level permissions very user",
    "start": "2540560",
    "end": "2546920"
  },
  {
    "text": "cannot see the data if we just mask on-the-fly so initially we want so if",
    "start": "2546920",
    "end": "2552260"
  },
  {
    "text": "you will be wanting to do masking or obfuscation you'll typically do that as part of your transform job you know it's",
    "start": "2552260",
    "end": "2558560"
  },
  {
    "text": "something that we do hear from customers so we will take a look at it but it's not going to be part of the initial set and the second question is this column",
    "start": "2558560",
    "end": "2565130"
  },
  {
    "text": "level permission where do you specify that these are the columns which you need to kind of like okay PII or PCI",
    "start": "2565130",
    "end": "2572360"
  },
  {
    "text": "columns and is there any dynamic way to control it using the tags or something rather than anything that in a policy",
    "start": "2572360",
    "end": "2578480"
  },
  {
    "text": "somehow I'm not sure how exactly works but yeah so the I think you talked about",
    "start": "2578480",
    "end": "2584630"
  },
  {
    "text": "exactly correctly which is using tags and essentially once columns are tagged then those tags have a set of",
    "start": "2584630",
    "end": "2589700"
  },
  {
    "text": "permissions and roles that are allowed to see them and that's how that all flows through so you don't have to manually reconfigure it for every user",
    "start": "2589700",
    "end": "2596570"
  },
  {
    "text": "that's accessing every column you can associate tags with roles and then that will take care of that side of things so",
    "start": "2596570",
    "end": "2602240"
  },
  {
    "text": "there will be a column level tagging which yes that's right so we'd be able to get the column in the table level",
    "start": "2602240",
    "end": "2608720"
  },
  {
    "text": "definitely one of the best sessions is Raymond thanks for that oh thank you my",
    "start": "2608720",
    "end": "2613770"
  },
  {
    "text": "questions around the interoperability between data warehouse and italics they expect to address different use cases",
    "start": "2613770",
    "end": "2620910"
  },
  {
    "text": "right so how do you expect from a product roadmap perspective like based on changing business needs how how could",
    "start": "2620910",
    "end": "2627270"
  },
  {
    "text": "they shift from one to the other yeah no it's a great question so you",
    "start": "2627270",
    "end": "2632310"
  },
  {
    "text": "know you're exactly right they address different use cases and that's why we organize the way we do we believe in providing the right service for the",
    "start": "2632310",
    "end": "2638340"
  },
  {
    "text": "right use case and so in our managed services redshift is our data warehouse it's a relational NPP data warehouse",
    "start": "2638340",
    "end": "2645420"
  },
  {
    "text": "with acid semantics but it also has this redshift spectrum layer which provides a",
    "start": "2645420",
    "end": "2651510"
  },
  {
    "text": "federated scale-out query over arbitrary data in s3 and so what we recommend to",
    "start": "2651510",
    "end": "2656790"
  },
  {
    "text": "customers is it look even if you have a data warehousing workload start with ground truth in s3 ingest that into your",
    "start": "2656790",
    "end": "2663480"
  },
  {
    "text": "data warehouse and then you can run data warehousing workloads on that data and still have access to s3 through",
    "start": "2663480",
    "end": "2669770"
  },
  {
    "text": "interfaces that you're familiar with and that way you don't need to morph your data warehouse into something it's not",
    "start": "2669770",
    "end": "2675630"
  },
  {
    "text": "but then if other customers have that needs to access data using spark on EMR or they want to run ad hoc sequel",
    "start": "2675630",
    "end": "2681570"
  },
  {
    "text": "through Athena they can do that on the same data because it also exists in s3 so that's the way to think about how to",
    "start": "2681570",
    "end": "2687990"
  },
  {
    "text": "combine those use cases yeah hello what's the pattern for a role level",
    "start": "2687990",
    "end": "2695010"
  },
  {
    "text": "security here so I can't share specific timelines you know our plan is to GA",
    "start": "2695010",
    "end": "2700880"
  },
  {
    "text": "early next year and shortly after that follow with row level it's it is the one",
    "start": "2700880",
    "end": "2706410"
  },
  {
    "text": "of the top things that we will be working on hi my question is can I use",
    "start": "2706410",
    "end": "2715140"
  },
  {
    "text": "the column level access control with SPARC yes so we do intend to make that",
    "start": "2715140",
    "end": "2720840"
  },
  {
    "text": "available essentially with SPARC hive presto and EMR as long as you're using",
    "start": "2720840",
    "end": "2726330"
  },
  {
    "text": "the lake formation and glue catalogs SPARC through um are will honor that",
    "start": "2726330",
    "end": "2733130"
  },
  {
    "text": "now we've run out on that mic all right",
    "start": "2733310",
    "end": "2737900"
  },
  {
    "text": "you're not so lucky sorry one quick question so who do you",
    "start": "2739470",
    "end": "2745839"
  },
  {
    "text": "see as the right customer for this product people at companies have already",
    "start": "2745839",
    "end": "2751150"
  },
  {
    "text": "taken some of their data onto s3 but have not used that glued data catalog",
    "start": "2751150",
    "end": "2757859"
  },
  {
    "text": "you see them also as customers for this product or only new customers or going",
    "start": "2757859",
    "end": "2764290"
  },
  {
    "text": "into this tree so you know my selfish hope is that every single person that reinvent and Beyond will be a customer",
    "start": "2764290",
    "end": "2769990"
  },
  {
    "text": "for this product so I do think that s3 is the right location for data but if you've got an existing data Lake that's",
    "start": "2769990",
    "end": "2775990"
  },
  {
    "text": "great it's no problem you know if you want to move some of that to Lake formation to make it easier to manage",
    "start": "2775990",
    "end": "2781839"
  },
  {
    "text": "policies over time that's great this is really a service for anyone that's dealing with data on s3 and accessing",
    "start": "2781839",
    "end": "2789520"
  },
  {
    "text": "that data for analytics so you know whether you're starting for the first time or you've got existing locations",
    "start": "2789520",
    "end": "2795369"
  },
  {
    "text": "either one will work we can register existing as three locations or we can create new ones to act as the starting",
    "start": "2795369",
    "end": "2801130"
  },
  {
    "text": "point for data leaks thank you yep been",
    "start": "2801130",
    "end": "2809650"
  },
  {
    "text": "thinking about how for might this question a little bit meandering but with with ginge ingesting the human of",
    "start": "2809650",
    "end": "2818890"
  },
  {
    "text": "data and one of the biggest things I've been hearing about in this conference is making sure you have high-quality data in your data like how do you measure the",
    "start": "2818890",
    "end": "2826420"
  },
  {
    "text": "quality the quality of how well you set it up yeah that's that's you know it's",
    "start": "2826420",
    "end": "2832060"
  },
  {
    "text": "an easily stated question with a complicated answer I mean the basic thing is data quality is really a",
    "start": "2832060",
    "end": "2838060"
  },
  {
    "text": "relative issue it's what matters for your business like if you're looking at clickstream logs off a web app you may not care if you lose everything if",
    "start": "2838060",
    "end": "2844180"
  },
  {
    "text": "you're looking at medical doses coming off EMR system you might actually care a lot about every single things so you",
    "start": "2844180",
    "end": "2850930"
  },
  {
    "text": "know data quality is context dependent and you'll have to decide what are the metrics and dimensions that matter for",
    "start": "2850930",
    "end": "2856540"
  },
  {
    "text": "quality and then build that quality scoring into part of your ingest job so basically the typical flow will be",
    "start": "2856540",
    "end": "2862089"
  },
  {
    "text": "you'll have raw data arriving it'll go through a transform and quality validation step and that's where you'll",
    "start": "2862089",
    "end": "2867700"
  },
  {
    "text": "do the audit that's relevant for the business use case for the data and then he would decide what what you",
    "start": "2867700",
    "end": "2873040"
  },
  {
    "text": "do then do that's really a business news case specific response developing that",
    "start": "2873040",
    "end": "2879700"
  },
  {
    "text": "is part a is part of making your data leak sorry developing that's a that's a kind of one",
    "start": "2879700",
    "end": "2885370"
  },
  {
    "text": "steps that will be information yeah I mean I think the place to build us in would be either in a scheduling workflow",
    "start": "2885370",
    "end": "2891370"
  },
  {
    "text": "that orchestrates the jobs or into the ETL job itself so there's no it's no",
    "start": "2891370",
    "end": "2897490"
  },
  {
    "text": "getting away from the fact that you've got to check that what you're gonna bail out about to put in make sense for the context thank you yep yeah but just",
    "start": "2897490",
    "end": "2905830"
  },
  {
    "text": "beauty on that last question we saw that the loading jobs are gonna be part of",
    "start": "2905830",
    "end": "2911110"
  },
  {
    "text": "the lake formation definition itself right in the blueprint phase so maybe what he said makes sense I mean the",
    "start": "2911110",
    "end": "2917140"
  },
  {
    "text": "quality should be part of the lake formation but that was not my question just a comment it's a fair comment and I",
    "start": "2917140",
    "end": "2922930"
  },
  {
    "text": "think you know when working with us everything is a discussion right you know if we think it's the right thing",
    "start": "2922930",
    "end": "2929170"
  },
  {
    "text": "eventually there are releases new quality service or something that's right but the actual question in a third",
    "start": "2929170",
    "end": "2935650"
  },
  {
    "text": "question sorry but the actual question was and actually I do have two questions one is regarding the loading that we saw",
    "start": "2935650",
    "end": "2944170"
  },
  {
    "text": "in the blueprint phase I mean are you going to eventually support on-prem databases as well when I could through Direct Connect or something and the",
    "start": "2944170",
    "end": "2951250"
  },
  {
    "text": "second question is going back to the interaction between a screen in the upper creating services whether it's a",
    "start": "2951250",
    "end": "2958000"
  },
  {
    "text": "red shift spectrum or Athena doesn't matter but I'm I'm trying to understand so if there's a query that's trying to",
    "start": "2958000",
    "end": "2964210"
  },
  {
    "text": "either get ten columns in the s3 dataset has a hundred columns or a thousand columns and imagine that that that we've",
    "start": "2964210",
    "end": "2971740"
  },
  {
    "text": "released you a hundred gigs in your data set but I'm really only interested in",
    "start": "2971740",
    "end": "2977260"
  },
  {
    "text": "one gig of that data set disastrous to fetch everything up to the upper service",
    "start": "2977260",
    "end": "2982420"
  },
  {
    "text": "and I'm effectively paying for that whole traffic or am i it is eventually",
    "start": "2982420",
    "end": "2988150"
  },
  {
    "text": "is lake formation can eventually be able to optimize that traffic between those services yeah so the answer to your",
    "start": "2988150",
    "end": "2995020"
  },
  {
    "text": "first question was I think we intend to anywhere we can get a network connection to a database that we support we want to",
    "start": "2995020",
    "end": "3000420"
  },
  {
    "text": "support being able to get data from so the the second question is you know",
    "start": "3000420",
    "end": "3007130"
  },
  {
    "text": "do can you how do you optimize the scan and really today that there's two ways to optimize the scan and this exists",
    "start": "3007130",
    "end": "3012890"
  },
  {
    "text": "outside of lake formation so one is to convert your data into Park a or or C and then the database query engine that",
    "start": "3012890",
    "end": "3019880"
  },
  {
    "text": "you're using will only select the columns that are needed and only those columns will be read and filtered if you",
    "start": "3019880",
    "end": "3025760"
  },
  {
    "text": "have a large object like a JSON blob that'll just get red and then filtered on mass so for data that you query",
    "start": "3025760",
    "end": "3032330"
  },
  {
    "text": "regularly we strongly recommend you convert it to an optimized format it'll save you money and your queries will run",
    "start": "3032330",
    "end": "3037850"
  },
  {
    "text": "faster there is a you know there is a new capability in s3 that's also",
    "start": "3037850",
    "end": "3042980"
  },
  {
    "text": "supported in EU Mar which is s3 select so as three select allows you to actually push down filters into objects",
    "start": "3042980",
    "end": "3049190"
  },
  {
    "text": "like JSON and CSV but you'd have to explicitly call that in your jobs today but that would also allow you to then",
    "start": "3049190",
    "end": "3055520"
  },
  {
    "text": "only extract a subset of the data that was in a non optimized format but in general if you're gonna query data",
    "start": "3055520",
    "end": "3062150"
  },
  {
    "text": "regularly that there's just no good reason to not take the one time conversion into an optimized form but",
    "start": "3062150",
    "end": "3067580"
  },
  {
    "text": "sorry just your compliment but that does support that does help with the column level access what about role of axes in",
    "start": "3067580",
    "end": "3073790"
  },
  {
    "text": "role of axes you really need to know what data is there before you even optimize or fetches I mean what I'm",
    "start": "3073790",
    "end": "3080570"
  },
  {
    "text": "trying to understand is are we seeing more for optimizer kind of behavior being embedded into lake formation so",
    "start": "3080570",
    "end": "3086420"
  },
  {
    "text": "the other Mizer behavior that you'll see is partition elimination so if you're filtering based on data the way it's",
    "start": "3086420",
    "end": "3091670"
  },
  {
    "text": "partitioned then we can skip partitions okay but there isn't sort of this clustered index idea that you know we",
    "start": "3091670",
    "end": "3097520"
  },
  {
    "text": "just happen to know the randomly that these are the keys to go fetch from your row from your columns okay thank you",
    "start": "3097520",
    "end": "3102650"
  },
  {
    "text": "appreciate our use cases we write to a",
    "start": "3102650",
    "end": "3110510"
  },
  {
    "text": "staging area we validate and so on and so on and copied to a target area but",
    "start": "3110510",
    "end": "3115910"
  },
  {
    "text": "the time is really important I mean we really need the copy to be done as quickly as possible because the data is",
    "start": "3115910",
    "end": "3121310"
  },
  {
    "text": "going to be used by different job shots waiting for it to be ready for my experience glue catalog can take forever",
    "start": "3121310",
    "end": "3127640"
  },
  {
    "text": "to scan especially if you have many small files also if you run ETL jobs you",
    "start": "3127640",
    "end": "3133250"
  },
  {
    "text": "have to sometimes adjust the DP use which I assumed we wouldn't need to do in this",
    "start": "3133250",
    "end": "3138290"
  },
  {
    "text": "service as impressions how do we basically make sure that the performance is performant sure so you know",
    "start": "3138290",
    "end": "3145790"
  },
  {
    "text": "performance just please email us at lake lake formation def p.m. and we'll dig",
    "start": "3145790",
    "end": "3150830"
  },
  {
    "text": "into the specifics it's hard to provide general answers on perf but we'd really happy to dig in and see what we can do",
    "start": "3150830",
    "end": "3156950"
  },
  {
    "text": "to help thank you yep so we got let's see six and a half minutes so I guess we",
    "start": "3156950",
    "end": "3163280"
  },
  {
    "text": "can keep going but if anyone wants to leave please I won't be offended just walk on out it's all good so you were",
    "start": "3163280",
    "end": "3169430"
  },
  {
    "text": "saying that we will be able to use tagging for access so currently our federated users they log in to only one",
    "start": "3169430",
    "end": "3177620"
  },
  {
    "text": "role are we going to be able to use multiple roles within the catalog for the data lake or will that be for",
    "start": "3177620",
    "end": "3185030"
  },
  {
    "text": "further users they will have to have their individual role in order to be able to have these granular access in",
    "start": "3185030",
    "end": "3192020"
  },
  {
    "text": "the data link yes so essentially whatever is doing the authenticating that's the thing that the",
    "start": "3192020",
    "end": "3198140"
  },
  {
    "text": "permissions are associated with so if you've got multiple users associated with the role it'll be tied to that role so we'll need",
    "start": "3198140",
    "end": "3204770"
  },
  {
    "text": "to either construct alternate policies we're trying to think through ways to achieve what you're talking about and",
    "start": "3204770",
    "end": "3210950"
  },
  {
    "text": "happy to follow up after the fact if you shoot us a note I would love to understand what you're trying to really get done and see what the best way to do",
    "start": "3210950",
    "end": "3217430"
  },
  {
    "text": "that would be awesome thank you yep so my question is that we have data stored",
    "start": "3217430",
    "end": "3223520"
  },
  {
    "text": "in different kind of formats like CSV and park' so in order to use a column wise access controls that's really",
    "start": "3223520",
    "end": "3230540"
  },
  {
    "text": "required the data to be stored in specific format no essentially because",
    "start": "3230540",
    "end": "3235850"
  },
  {
    "text": "you're defining logical tables in the catalog those tables can be defined on data regardless of type underneath what",
    "start": "3235850",
    "end": "3243440"
  },
  {
    "text": "so you you don't need to convert it to get the column level filtering that the the trade-off is you'll spend longer",
    "start": "3243440",
    "end": "3250610"
  },
  {
    "text": "scanning that data because we'll have to scan all of it to filter out the columns that should be filtered out whereas in",
    "start": "3250610",
    "end": "3256610"
  },
  {
    "text": "the case of a columnar format you can avoid reading those columns entirely okay so there is going to be performance",
    "start": "3256610",
    "end": "3262730"
  },
  {
    "text": "difference yes because it's just a I mean it's physics you're gonna read more with a unoptimized object and you would",
    "start": "3262730",
    "end": "3268940"
  },
  {
    "text": "with something that was compressed or columnar thank you yep there was an",
    "start": "3268940",
    "end": "3274640"
  },
  {
    "text": "announcement today about outpost outpost interesting offering do you think s3 elect formation",
    "start": "3274640",
    "end": "3282670"
  },
  {
    "text": "this kind of service will be available outpost so that we can use that as a",
    "start": "3282670",
    "end": "3288500"
  },
  {
    "text": "sort of enterprise data like is alternative do in enterprise setting yes so I mean I'm not the subject matter",
    "start": "3288500",
    "end": "3294590"
  },
  {
    "text": "expert on outpost but the intent for outpost is to provide hardware that you run in your data center that is",
    "start": "3294590",
    "end": "3300710"
  },
  {
    "text": "identical to AWS so essentially anything running on outpost will transparently connect back to services like s3 or kms",
    "start": "3300710",
    "end": "3307730"
  },
  {
    "text": "or lake formation so from a user perspective there'll be no different so these all of these services will be",
    "start": "3307730",
    "end": "3312800"
  },
  {
    "text": "visible to you through your outpost infrastructure thank you yep",
    "start": "3312800",
    "end": "3318850"
  },
  {
    "text": "we're using the Apache Ranger as a data ordnance tool right now security tool so",
    "start": "3319670",
    "end": "3326840"
  },
  {
    "text": "do you guys have any plan to once we have that implement because this is looks like it's going to take some time",
    "start": "3326840",
    "end": "3332750"
  },
  {
    "text": "to make sure this one so you guys have any plan to import that data and export into the data like take for mission yeah",
    "start": "3332750",
    "end": "3342680"
  },
  {
    "text": "I mean I think you know I'd love to follow up on that we have a number of customers that were in discussions with",
    "start": "3342680",
    "end": "3348470"
  },
  {
    "text": "they use Ranger at the moment I think you know Ranger is is good but it really",
    "start": "3348470",
    "end": "3353630"
  },
  {
    "text": "only works for the Hadoop centric applications and so our view is that",
    "start": "3353630",
    "end": "3358850"
  },
  {
    "text": "with table column and row level permissions and things like column tags we should be able to get to what you've got in Ranger but in terms of importing",
    "start": "3358850",
    "end": "3366980"
  },
  {
    "text": "range of policies and expressing them as lake formation we haven't made a decision on that but please email us at",
    "start": "3366980",
    "end": "3372200"
  },
  {
    "text": "lake formation p.m. and we'd love to follow up hello for this to to work with",
    "start": "3372200",
    "end": "3381890"
  },
  {
    "text": "the compliance and security does the ingestion and cleansing of the data needs to happen through clue or is it",
    "start": "3381890",
    "end": "3388940"
  },
  {
    "text": "okay if we have custom spark jobs does not need to happen through glue so you",
    "start": "3388940",
    "end": "3393980"
  },
  {
    "text": "it's designed to be modular so you can use whatever elements of it you want to or don't want to the the key to make the",
    "start": "3393980",
    "end": "3400040"
  },
  {
    "text": "security work is to ensure that the data is registered in the catalog and that you've closed off any other side channel access to the",
    "start": "3400040",
    "end": "3406820"
  },
  {
    "text": "data but it can be transformed in spark or through any other process okay thanks great all right one two minutes",
    "start": "3406820",
    "end": "3416329"
  },
  {
    "text": "to spare well thank you very much folks I appreciate it and I enjoy the rest of reinvent",
    "start": "3416329",
    "end": "3422859"
  }
]
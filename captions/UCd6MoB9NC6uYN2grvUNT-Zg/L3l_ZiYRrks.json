[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "hi and welcome to going big with containers my name is Matt Callen and",
    "start": "709",
    "end": "8370"
  },
  {
    "text": "I'm the engineering manager in tech lead at Expedia in our cloud acceleration",
    "start": "8370",
    "end": "13980"
  },
  {
    "text": "team so we exist to help speed up the lives of developers and our mission is",
    "start": "13980",
    "end": "20189"
  },
  {
    "text": "to make developers lives easier and faster when it comes to deploying to the cloud migrating out of data centers and",
    "start": "20189",
    "end": "27390"
  },
  {
    "text": "beginning their their cloud journey so I work out about brisbane australia office",
    "start": "27390",
    "end": "33239"
  },
  {
    "text": "and out of out of brisbane we focus on the ECS cluster management the",
    "start": "33239",
    "end": "39030"
  },
  {
    "text": "deployment automation aspects of our of our cloud platform so this presentation I'm going to focus on those aspects of",
    "start": "39030",
    "end": "45809"
  },
  {
    "text": "deploying to the cloud with with docker and using ecs I'm not going to talk about data center",
    "start": "45809",
    "end": "52320"
  },
  {
    "text": "connectivity using Direct Connect I'm not going to talk about the persistence layer and the various database options",
    "start": "52320",
    "end": "58559"
  },
  {
    "text": "that our teams can choose from those are out of scope for this conversation I'm going to be focusing on how do we how do",
    "start": "58559",
    "end": "64650"
  },
  {
    "text": "we really scale when it comes to using containers for deploying applications to the cloud so you've probably heard of",
    "start": "64650",
    "end": "73439"
  },
  {
    "text": "Expedia it's it's a large enterprise with a number of different brands under their umbrella that you might also",
    "start": "73439",
    "end": "78930"
  },
  {
    "text": "recognize so we look at a number of the building blocks that make up our our",
    "start": "78930",
    "end": "84420"
  },
  {
    "start": "81000",
    "end": "81000"
  },
  {
    "text": "platform deploying - - to the cloud there and we're gonna start with the application creation side of things how",
    "start": "84420",
    "end": "91110"
  },
  {
    "text": "do we generate micro services how do we make that easy for our teams to get microsomes as up and going we'll talk",
    "start": "91110",
    "end": "96960"
  },
  {
    "text": "about deployment automation when it comes to deploying - ECS how we do that and we'll look at the underlying",
    "start": "96960",
    "end": "102600"
  },
  {
    "text": "management of those ECS clusters how we manage the underlying ec2 infrastructure",
    "start": "102600",
    "end": "107670"
  },
  {
    "text": "and it's all built on top of AWS this whole bunch of different services there",
    "start": "107670",
    "end": "112680"
  },
  {
    "text": "that we use I'm not going to go through those in details but they're all part of our platform and ultimately we rely on",
    "start": "112680",
    "end": "118680"
  },
  {
    "text": "AWS support when it comes to - drilling into specific issues and recommendations",
    "start": "118680",
    "end": "125479"
  },
  {
    "text": "so to start with application creation what is the cost of creating a micro",
    "start": "125479",
    "end": "130950"
  },
  {
    "text": "service so if you had an experiment that you want to run in ISIL a out in production you've got some ideas how long will it take you to get your",
    "start": "130950",
    "end": "137460"
  },
  {
    "text": "experiment out there and what we need to do so you'll need to create our source code repository a working codebase",
    "start": "137460",
    "end": "143370"
  },
  {
    "start": "143000",
    "end": "143000"
  },
  {
    "text": "you'll need a basic test suite you'll want to deploy two immutable servers using infrastructure as code that Devon",
    "start": "143370",
    "end": "149850"
  },
  {
    "text": "ops can maintain with centralized logging and centralized monitoring you want chat notifications you want a load",
    "start": "149850",
    "end": "155820"
  },
  {
    "start": "155000",
    "end": "155000"
  },
  {
    "text": "balancer you'll want some sort of cname DNS networking you don't want Bluegreen deploys it continues delivery pipeline",
    "start": "155820",
    "end": "162470"
  },
  {
    "text": "how long is all they're going to take takes to create you want to get your experiment out there is it a couple of",
    "start": "162470",
    "end": "167550"
  },
  {
    "text": "days is it a week a month six weeks I think a month is generous for a lot of enterprises let's say it takes takes two",
    "start": "167550",
    "end": "174960"
  },
  {
    "text": "weeks what what what's the opportunity cost what could you've been doing in the two weeks that it takes to generate that",
    "start": "174960",
    "end": "180150"
  },
  {
    "text": "that micro service and to go through that experience how much context switching was going on for your",
    "start": "180150",
    "end": "185250"
  },
  {
    "text": "development teams how much you know rigorous discussions were there between your developers and your admins fighting",
    "start": "185250",
    "end": "192660"
  },
  {
    "text": "once again about naming standards and all the different approval processes that you need to go through all that the",
    "start": "192660",
    "end": "198209"
  },
  {
    "text": "yak shaving and these are all things that prevent experimentation and innovation in in terms of what we call",
    "start": "198209",
    "end": "204720"
  },
  {
    "text": "the time value of information a piece of information today is worth more than that same piece of information tomorrow",
    "start": "204720",
    "end": "210450"
  },
  {
    "text": "so if we say that every commit that a developer makes is a hypothesis I think this this change this commitment I'm",
    "start": "210450",
    "end": "216270"
  },
  {
    "text": "making will result in you know better sales or improved performance or you",
    "start": "216270",
    "end": "222060"
  },
  {
    "text": "know less bugs then how much could having that information today be more beneficial to your company this is what",
    "start": "222060",
    "end": "228150"
  },
  {
    "text": "DevOps continuous delivery and lean and agile all teach us is that feedback is king we need feedback as fast as",
    "start": "228150",
    "end": "233340"
  },
  {
    "text": "possible that really helps us to get the results from our experiment and the less risky your changes become if you can get",
    "start": "233340",
    "end": "239520"
  },
  {
    "text": "the feedback the fastest possible way so we internally within Expedia we've",
    "start": "239520",
    "end": "244590"
  },
  {
    "text": "created a micro Service generation platform we call it primer and teams will go to the internal primer tool into",
    "start": "244590",
    "end": "251910"
  },
  {
    "text": "the UI and they'll click a button I want to create an app and you can choose from",
    "start": "251910",
    "end": "257160"
  },
  {
    "text": "a number of different templates some JVM you know drop wizard spring work templates and ruby base templates Python",
    "start": "257160",
    "end": "263340"
  },
  {
    "text": "PHP Scala whatever is being created by the internal community will be available to the we'll go through a series of processes",
    "start": "263340",
    "end": "270000"
  },
  {
    "text": "to create the application the darker image and the the builds and within ten",
    "start": "270000",
    "end": "275220"
  },
  {
    "text": "minutes they'll have an application repository for their micro service with a continuous delivery pipeline ready for",
    "start": "275220",
    "end": "280560"
  },
  {
    "text": "commits a docker repository the application will be built as a docker image and deployed to a prod like",
    "start": "280560",
    "end": "286170"
  },
  {
    "text": "testing environment so within 10 minutes they can get started with with their experiment all those things that could",
    "start": "286170",
    "end": "291240"
  },
  {
    "text": "possibly take you you 10/10 in two weeks or a month to do within within an enterprise our teams within Expedia do",
    "start": "291240",
    "end": "298860"
  },
  {
    "text": "this 20 times a day every business day there's 20 new micro services created just because the cost is sloped so low",
    "start": "298860",
    "end": "305880"
  },
  {
    "text": "that people want can easily make an experiment they say I want to test out this this particular idea that I have",
    "start": "305880",
    "end": "311460"
  },
  {
    "text": "you might be wondering what those distracting spikes are hackathons people",
    "start": "311460",
    "end": "316830"
  },
  {
    "text": "are getting excited about hacking away on some new ideas so going back to the question how long does it take to create",
    "start": "316830",
    "end": "322530"
  },
  {
    "text": "a micro service if it takes more than a few days to go through this process all the approvals and everything then your teams are unlikely to consider even even",
    "start": "322530",
    "end": "329280"
  },
  {
    "text": "doing this the time burns to great and there's it's a big opportunity cost that's that's been lost there and when",
    "start": "329280",
    "end": "336630"
  },
  {
    "text": "it comes to getting feedback within a monolith if a monolith has like a two-week release cycle that and you and",
    "start": "336630",
    "end": "343230"
  },
  {
    "text": "with the market service you can get it out within a day that's a 10x release cycle on your monolith what could you",
    "start": "343230",
    "end": "349140"
  },
  {
    "text": "have been doing in those two weeks what other experiments could you have been running and within our industry fast",
    "start": "349140",
    "end": "355620"
  },
  {
    "text": "feedback is so important because over two-thirds of our experiments fail two-thirds of our projects we have a",
    "start": "355620",
    "end": "361470"
  },
  {
    "text": "sixty eight percent failure rate within our industry and so if you have a 10x cycle time you're ten times less likely",
    "start": "361470",
    "end": "367620"
  },
  {
    "text": "to to be able to get the results from your your experiments so in the time that you could have run ten experiments",
    "start": "367620",
    "end": "374130"
  },
  {
    "text": "with three successful experiment attempts out of that with microservices you could worm one failed experiment in",
    "start": "374130",
    "end": "380669"
  },
  {
    "text": "your ten week long a monolith release cycle does your does your feature even",
    "start": "380669",
    "end": "386910"
  },
  {
    "text": "belong in your monolith probably not it probably started out looking nicely and beautiful architecture but then over time more and more features were crammed",
    "start": "386910",
    "end": "393810"
  },
  {
    "text": "in there and your new experiment doesn't really belong there you're just increasing the technical debt",
    "start": "393810",
    "end": "399990"
  },
  {
    "text": "so the benefits that we see out of primer is twofold we've got the reduction in in cost due to",
    "start": "399990",
    "end": "406319"
  },
  {
    "text": "experimentation and fast feedback and and we get the benefit of speed from that as well in terms of deployment",
    "start": "406319",
    "end": "414120"
  },
  {
    "text": "automation so how do we get our containers onto the cloud we're gonna look at the deployment pipelines order",
    "start": "414120",
    "end": "419759"
  },
  {
    "text": "scaling security logging traffic management what's the motivation why did",
    "start": "419759",
    "end": "425160"
  },
  {
    "start": "423000",
    "end": "423000"
  },
  {
    "text": "we choose to use containers for our micro service platform why not VMs why not functions with lambda and we do have",
    "start": "425160",
    "end": "431039"
  },
  {
    "text": "these offerings for our primer a primary platform teams can choose to use dedicated ec2 instances with cloud",
    "start": "431039",
    "end": "438120"
  },
  {
    "text": "formation they can choose to deploy to lambda but containers really provides the sweet spot of a nice consistent",
    "start": "438120",
    "end": "445320"
  },
  {
    "text": "deployment packaging mechanism that's very portable developers can run the same docker image on their laptop as",
    "start": "445320",
    "end": "451500"
  },
  {
    "text": "they can run on a on an SES cluster and they can port it between different types of deployment topologies it also gives",
    "start": "451500",
    "end": "459240"
  },
  {
    "text": "them the flexibility of resources in CPU and memory which you don't see as much flexibility with something like lambdas",
    "start": "459240",
    "end": "465539"
  },
  {
    "text": "lambda is a great they provide that extra level of abstraction you just deploy the the code the function but",
    "start": "465539",
    "end": "472470"
  },
  {
    "text": "then you're restricted in terms of memory and CPU and execution time I mean at the other end of the spectrum dedicated ec2 instances with dedicated",
    "start": "472470",
    "end": "479190"
  },
  {
    "text": "VMs gives you even more flexibility with CPU and memory but then you're constrained your applications constrained to the operating system that",
    "start": "479190",
    "end": "485039"
  },
  {
    "text": "it's running on whereas docker abstracts that away away for you so the default for most of our templates with primaries",
    "start": "485039",
    "end": "491130"
  },
  {
    "text": "to build a docker image and deploy that to to EEZs and then when it comes to",
    "start": "491130",
    "end": "497669"
  },
  {
    "text": "clusters so the clustering technology that you'll see with containers your various different technologies out there",
    "start": "497669",
    "end": "504240"
  },
  {
    "text": "kubernetes we've got my sauce docker swarm ECS they're all very similar technologies and what they provide is",
    "start": "504240",
    "end": "510750"
  },
  {
    "text": "that the the brain the scheduler which you tell the brain I want to deploy this",
    "start": "510750",
    "end": "516240"
  },
  {
    "text": "docker image I want I want to know what for copies of it for this application and the brain works out we're in this",
    "start": "516240",
    "end": "521640"
  },
  {
    "text": "pre-built fleet of VMs should I put that workload to balance it out across there and so",
    "start": "521640",
    "end": "528930"
  },
  {
    "text": "that's the benefit of having a clustering technology you don't need to work out how am I going to get my docker image onto a VM the the brains",
    "start": "528930",
    "end": "535830"
  },
  {
    "text": "take takes care of that for you why did we choose Amazon SES why not some of the",
    "start": "535830",
    "end": "542940"
  },
  {
    "text": "other offerings Amazon SES integrates nicely with things like I am with load balancers with auto scaling and for AZ",
    "start": "542940",
    "end": "551880"
  },
  {
    "text": "balancing so you get redundancy across these people are so we scared about Lockean with Amazon",
    "start": "551880",
    "end": "558060"
  },
  {
    "text": "we're on Amazon anyway we're on SES we're on AWS anyway so that some it's",
    "start": "558060",
    "end": "564089"
  },
  {
    "text": "not really worth it trying to abstract across multiple different clustering technologies the time and effort that we",
    "start": "564089",
    "end": "569970"
  },
  {
    "text": "would spend in there we're better off just getting benefit from one technology so that's where we are with that terms",
    "start": "569970",
    "end": "576779"
  },
  {
    "text": "of some of the statistics of our footprint on ECS we have 2600 ECR services deploy so EC our service is",
    "start": "576779",
    "end": "583529"
  },
  {
    "text": "what we'd call an application 1100 of those are unique applications deployed to clusters all around the world with",
    "start": "583529",
    "end": "589890"
  },
  {
    "text": "13,000 containers across 860 instances",
    "start": "589890",
    "end": "595490"
  },
  {
    "start": "595000",
    "end": "595000"
  },
  {
    "text": "that's across 13 different ECS clusters the green is production the blue is test",
    "start": "595490",
    "end": "601350"
  },
  {
    "text": "our largest production clusters 480 applications 230 instances they're",
    "start": "601350",
    "end": "606930"
  },
  {
    "text": "across 11 different V pcs in 5 different regions this is a visualization of one",
    "start": "606930",
    "end": "612779"
  },
  {
    "text": "of our cluster production clusters so the vertical bars there are instances each instance has a 8 cores of CPU each",
    "start": "612779",
    "end": "620820"
  },
  {
    "text": "of the colored boxes is a task in our task in ECS is a collection of containers so if if I say I want my",
    "start": "620820",
    "end": "627660"
  },
  {
    "text": "application to run four times in parallel on this on this cluster then you'll have four tasks so the similarly",
    "start": "627660",
    "end": "634260"
  },
  {
    "text": "colored tasks are belong to the same service and this is using our c3 Tver",
    "start": "634260",
    "end": "640829"
  },
  {
    "text": "open source tool that you can download from Expedia comm on github in terms of",
    "start": "640829",
    "end": "648120"
  },
  {
    "start": "646000",
    "end": "646000"
  },
  {
    "text": "the deployment pipeline so very fairly typical you'll get your you'll get repo",
    "start": "648120",
    "end": "653490"
  },
  {
    "text": "that's created by primer for you which says your source code in your application config when you when a developer does a commit to the to the",
    "start": "653490",
    "end": "659279"
  },
  {
    "text": "git repo it will trigger off a commit build will use Jenkins for that the commit build will compile the code do",
    "start": "659279",
    "end": "666089"
  },
  {
    "text": "basic unit tests we'll build the artifact as a jar or a war as if whatever whatever artifact",
    "start": "666089",
    "end": "672460"
  },
  {
    "text": "makes sense for that technology and then what it will do is pull in a base darker image that we've built ahead of time so",
    "start": "672460",
    "end": "679750"
  },
  {
    "text": "for all of our all of our primary templates we have a base docker image for each of those that's built ahead of",
    "start": "679750",
    "end": "685840"
  },
  {
    "text": "time so we'll pull in that base docker image and then it will layer on top of",
    "start": "685840",
    "end": "691540"
  },
  {
    "text": "that image by copying in the artifact that's been built and generated a new application docker image and push that",
    "start": "691540",
    "end": "697330"
  },
  {
    "text": "to the internal docker registry and then after the commit build is successful it will trigger off a test deployment bill",
    "start": "697330",
    "end": "703950"
  },
  {
    "text": "which will deploy to ECS and we've set up the EECS cluster ahead of time as well and I'll discuss the management of",
    "start": "703950",
    "end": "710200"
  },
  {
    "text": "that those clusters in the next section so the deployment tells ECS to pull down",
    "start": "710200",
    "end": "716500"
  },
  {
    "text": "the application docker image from the docker registry and pull down the application config thats specific for",
    "start": "716500",
    "end": "722620"
  },
  {
    "text": "that target environment and then teams can choose to go to other testing environments as well integration or or",
    "start": "722620",
    "end": "729670"
  },
  {
    "text": "stress environments when it comes to deploying to prod it's a very similar process they will trigger the bill to go",
    "start": "729670",
    "end": "736150"
  },
  {
    "text": "to production which is which region they want to go to and I will pull in the exact same docker image and put on the",
    "start": "736150",
    "end": "741430"
  },
  {
    "text": "application config that's specific to their own environment and teams can choose to go multi region if they want",
    "start": "741430",
    "end": "747340"
  },
  {
    "text": "that's just separate builds and we we provide a pipelining tool on top of this that's that's internal to experior as",
    "start": "747340",
    "end": "753550"
  },
  {
    "text": "well which drives jenkins that says each team can choose you know when our test deployments finished I want to",
    "start": "753550",
    "end": "759490"
  },
  {
    "text": "automatically go to production but maybe I only want to do the deployment not the release and they will stop at deployment",
    "start": "759490",
    "end": "764530"
  },
  {
    "text": "so they can do testing and they can insert various automated testing phases within their pipelining tool so they can",
    "start": "764530",
    "end": "770110"
  },
  {
    "text": "build up a fully automated pipeline or they can build up a semi-automated it's really up to each team to choose what they want to do and when it comes to",
    "start": "770110",
    "end": "779320"
  },
  {
    "text": "deploying to ECS we split down the deployment phase in the release phase and what that means is that we want to",
    "start": "779320",
    "end": "785560"
  },
  {
    "text": "allow a way for teams to test their containers working in the target",
    "start": "785560",
    "end": "791890"
  },
  {
    "text": "environment before they send live production traffic to it what that looks like is this so they have a service",
    "start": "791890",
    "end": "797950"
  },
  {
    "start": "795000",
    "end": "795000"
  },
  {
    "text": "already running their applications running on version 1 in ECS the four boxes there represent",
    "start": "797950",
    "end": "803420"
  },
  {
    "text": "four tasks each running its own copy of of the container that they've built that",
    "start": "803420",
    "end": "808460"
  },
  {
    "text": "service will be behind a load balancer which is behind around fifty three cname we want to go to version two so what",
    "start": "808460",
    "end": "815150"
  },
  {
    "text": "we'll do is create as separate as separate ECS service called the Canary",
    "start": "815150",
    "end": "820250"
  },
  {
    "text": "service and will deploy a single task just for testing that's going to be on version two it's the exact same",
    "start": "820250",
    "end": "826000"
  },
  {
    "text": "application but a newer version of the image as well behind its own load balancer and its own route 53 C name and",
    "start": "826000",
    "end": "832430"
  },
  {
    "text": "teams can begin testing against that canary when it comes to we call that the deploy and then when it comes to release",
    "start": "832430",
    "end": "838880"
  },
  {
    "text": "time after they've tested their deploy we use the Amazon's ECS update service",
    "start": "838880",
    "end": "845540"
  },
  {
    "text": "command which says okay take this live running service and do an implicit blue-green deploy on that what that does",
    "start": "845540",
    "end": "852260"
  },
  {
    "text": "is basically treats it like an implicit blue going to play by saying I'm gonna create or replacement tasks that the",
    "start": "852260",
    "end": "859940"
  },
  {
    "text": "green tasks there and then you've got em in mixed mode that you both both version 1 and version 2 running behind the load",
    "start": "859940",
    "end": "866120"
  },
  {
    "text": "balancer and then once version 2 tasks are successfully placed behind the load balancer it removes the old blue tasks",
    "start": "866120",
    "end": "873080"
  },
  {
    "text": "and then you're running your life service purely on version 2 and then we go ahead and delete the canary so that's",
    "start": "873080",
    "end": "878720"
  },
  {
    "text": "the that's how we do Bluegreen deploys on ECS for application order scaling we",
    "start": "878720",
    "end": "886250"
  },
  {
    "start": "883000",
    "end": "883000"
  },
  {
    "text": "take advantage of the auto scaling feature that that's built into ECS and so we can say when this application",
    "start": "886250",
    "end": "893390"
  },
  {
    "text": "reaches 70 75 % of CPU utilization then",
    "start": "893390",
    "end": "898820"
  },
  {
    "text": "go ahead and spin up an extra two tasks and so that will just create another two tasks and put them behind the load",
    "start": "898820",
    "end": "904490"
  },
  {
    "text": "balancer and it happens seamlessly to until the user and then it can scale back down when it after the peak load",
    "start": "904490",
    "end": "910690"
  },
  {
    "text": "has kind of died down it can scale back down to two the containers that it had before for role-based security we use I",
    "start": "910690",
    "end": "919670"
  },
  {
    "text": "am so when an application is deployed it gets a minimal set of I am roles",
    "start": "919670",
    "end": "924700"
  },
  {
    "text": "permissions but they teams can choose to say I want this application to be associated with a specific role and it",
    "start": "924700",
    "end": "931880"
  },
  {
    "text": "uses that I am ECS tah scroll to do that and that allows teams to say for this particular",
    "start": "931880",
    "end": "938009"
  },
  {
    "text": "Apple and access these AWS services and only that application can have access those permissions the logging we use",
    "start": "938009",
    "end": "948389"
  },
  {
    "text": "Splunk so how do we get logs from a container onto Splunk so on the left is the e CS is you see a single e CS task",
    "start": "948389",
    "end": "955919"
  },
  {
    "text": "is represented so we saw a service there with four tasks this is a single task and within a task we can have more than",
    "start": "955919",
    "end": "961139"
  },
  {
    "text": "one container so we'll have the main application container this will be maybe your your java web service may be",
    "start": "961139",
    "end": "968129"
  },
  {
    "text": "running on here might be whatever technology you've chosen us to do applications running on there and we'll",
    "start": "968129",
    "end": "973139"
  },
  {
    "text": "deploy alongside that a what we call a Splunk forwarder container this is you using what's known in the industry as a",
    "start": "973139",
    "end": "979019"
  },
  {
    "text": "sidecar container pattern so every every application every every application",
    "start": "979019",
    "end": "985139"
  },
  {
    "text": "container has its own spawn forwarder container there and the executable the",
    "start": "985139",
    "end": "990599"
  },
  {
    "text": "web service that's running on the container and the Splunk folder has it has its own binary that's running on",
    "start": "990599",
    "end": "996179"
  },
  {
    "text": "there and so when the app executable is writing out logs to disk it's simply shared using a volume",
    "start": "996179",
    "end": "1001969"
  },
  {
    "text": "sharing mechanism between the containers on that same task Splunk binary sees those logs being",
    "start": "1001969",
    "end": "1007729"
  },
  {
    "text": "written and simply forwards them to Splunk and the user can see those on that the spunk survey UI and then the",
    "start": "1007729",
    "end": "1016189"
  },
  {
    "text": "executable might also log to stand it out in standard error which is a process that we prefer with we're training for",
    "start": "1016189",
    "end": "1022219"
  },
  {
    "text": "12 factor apps what you're not writing to disk but some apps do both and when it writes out to the console we simply",
    "start": "1022219",
    "end": "1028909"
  },
  {
    "text": "use the the Splunk logging driver which comes with with docker and you see us can plug into that the traffic",
    "start": "1028909",
    "end": "1038360"
  },
  {
    "text": "management so we have the picture here of an application stack with ECS service the load balancer the route 53 cname",
    "start": "1038360",
    "end": "1045279"
  },
  {
    "text": "let's say that that's running within a particular region will call it application a how does internet traffic",
    "start": "1045279",
    "end": "1050600"
  },
  {
    "text": "get to our service traffic's coming through on the internet we have an internal team it just does traffic",
    "start": "1050600",
    "end": "1057529"
  },
  {
    "text": "management and they've defined some some software that you can set up some traffic rules so that when traffic is",
    "start": "1057529",
    "end": "1063440"
  },
  {
    "text": "coming from the internet you can say right this application only what needs to be in a single region so",
    "start": "1063440",
    "end": "1069379"
  },
  {
    "text": "we'll send all traffic from the Internet to that particular cname for that application but maybe you want to go",
    "start": "1069379",
    "end": "1076429"
  },
  {
    "text": "multi region which is referred approach in that case we can set up some geo rules to say well depending on where you",
    "start": "1076429",
    "end": "1082039"
  },
  {
    "text": "are in the world go to the closest go to the closest region for you inter region",
    "start": "1082039",
    "end": "1088970"
  },
  {
    "text": "intra region so if you're within one region with multiple apps how do they discover each other so perhaps",
    "start": "1088970",
    "end": "1094940"
  },
  {
    "text": "application is in region one application B is also in region one but it's in the",
    "start": "1094940",
    "end": "1100100"
  },
  {
    "text": "private subnet for app a to talk to a be simply the the application just uses the",
    "start": "1100100",
    "end": "1106850"
  },
  {
    "text": "route 53 C name that's a pretty simple kind of set up if we have two public",
    "start": "1106850",
    "end": "1112190"
  },
  {
    "text": "apps app and app C and they want to talk to each other again it just use the same mechanism that covers off the deployment",
    "start": "1112190",
    "end": "1119179"
  },
  {
    "start": "1117000",
    "end": "1117000"
  },
  {
    "text": "automation section the benefits so that we see there is the the speed aspect of reducing a lot of manual steps down to",
    "start": "1119179",
    "end": "1126259"
  },
  {
    "text": "basically a single click or even a fully automated process why about pipelining tool and then there's the safety because",
    "start": "1126259",
    "end": "1133639"
  },
  {
    "text": "those those steps have all been automated it's a repeatable and reliable process that has a very little manual",
    "start": "1133639",
    "end": "1139999"
  },
  {
    "text": "intervention so for cluster management we can look at how we how we do the the",
    "start": "1139999",
    "end": "1146570"
  },
  {
    "start": "1142000",
    "end": "1142000"
  },
  {
    "text": "creation of our clusters using immutable servers and auto scaling how we do zero downtime upgrades of those of those",
    "start": "1146570",
    "end": "1152809"
  },
  {
    "text": "cluster instances how we do monitoring and and right sizing so in terms of",
    "start": "1152809",
    "end": "1158240"
  },
  {
    "start": "1157000",
    "end": "1157000"
  },
  {
    "text": "creating the eCos cluster we start off with a cloud formation stack that has a an auto scaling group will start off",
    "start": "1158240",
    "end": "1165049"
  },
  {
    "text": "always with five instances that just gives us enough redundancy when it comes",
    "start": "1165049",
    "end": "1170210"
  },
  {
    "text": "to deploying and releasing applications and then those auto scaling groups are set to automatically scale out based on",
    "start": "1170210",
    "end": "1176929"
  },
  {
    "text": "demand of that particular cluster and we'll create the ECS cluster separately",
    "start": "1176929",
    "end": "1182869"
  },
  {
    "text": "to the cloud formation stack and when those instances start up when they launch they'll automatically join the",
    "start": "1182869",
    "end": "1188990"
  },
  {
    "text": "cloud formation that the ECS cost of have been configured to join our via the launch configuration in the in the",
    "start": "1188990",
    "end": "1194990"
  },
  {
    "text": "confirmation stack and then the auto-scaling rules were set up there so once he hit 70% CPU",
    "start": "1194990",
    "end": "1202000"
  },
  {
    "text": "reservation across the cluster hadn't had an instance 60% memory scale down",
    "start": "1202000",
    "end": "1207310"
  },
  {
    "text": "for 10% CPU or 20% memory those statistics those metrics have been searches based on our experience over",
    "start": "1207310",
    "end": "1213220"
  },
  {
    "text": "the years and we used to we use an immutable server approach when it comes",
    "start": "1213220",
    "end": "1218290"
  },
  {
    "start": "1215000",
    "end": "1215000"
  },
  {
    "text": "to creating and updating our instances so by immutable server approach I mean",
    "start": "1218290",
    "end": "1223780"
  },
  {
    "text": "that if there's if we need to make any changes to the instances changing the configuration or updating packages we",
    "start": "1223780",
    "end": "1229180"
  },
  {
    "text": "will not do that on instances in place we will simply replace the entire instance not only is this industry best",
    "start": "1229180",
    "end": "1235210"
  },
  {
    "text": "practice but it's something that we've learned through bitter experience you don't restart docker on all of your",
    "start": "1235210",
    "end": "1240790"
  },
  {
    "text": "instances simultaneously you don't do that more than once accidentally so we",
    "start": "1240790",
    "end": "1246130"
  },
  {
    "text": "what we do is we we we build a buildin AMI and we'll version it and we'll use a",
    "start": "1246130",
    "end": "1252340"
  },
  {
    "text": "new version of our new me or my to roll out updates to all of our clusters so how do we build that ami what we do is",
    "start": "1252340",
    "end": "1258580"
  },
  {
    "text": "we take the ECS optimized ami so the amazon SES team they produce an ami",
    "start": "1258580",
    "end": "1264520"
  },
  {
    "text": "whenever they have updates that they want to bring forward their updates might include they build theirs on top",
    "start": "1264520",
    "end": "1269950"
  },
  {
    "text": "of the amazon linux ami so there might be a security update to amazon linux that they want to incorporate they they",
    "start": "1269950",
    "end": "1276430"
  },
  {
    "text": "put the docker daemon into that image and they put their ECS agent which is just a small docker container that does",
    "start": "1276430",
    "end": "1282520"
  },
  {
    "text": "the the communications between what's running on on the east two instance and the scheduling brain within the ECS",
    "start": "1282520",
    "end": "1289120"
  },
  {
    "text": "service so they may have updates to either of those that they want to apply when they build a new SES optimized ami",
    "start": "1289120",
    "end": "1295420"
  },
  {
    "text": "we'll we'll take that and we'll create a temporary instance out of that ami and on top of that we'll layer down in our",
    "start": "1295420",
    "end": "1301030"
  },
  {
    "text": "standard Expedia image a standard configuration by a chef and we'll put down the configuration for for docker",
    "start": "1301030",
    "end": "1308020"
  },
  {
    "text": "that we want to have on all of our clusters everywhere in the world so we'll we'll take that a temporary",
    "start": "1308020",
    "end": "1314950"
  },
  {
    "text": "instance and bake a new ami out of that and then we'll make that ami available to all regions and all accounts that we",
    "start": "1314950",
    "end": "1321430"
  },
  {
    "text": "want to create an update cluster Z then when it comes to launch time when a auto",
    "start": "1321430",
    "end": "1327730"
  },
  {
    "text": "scaling group needs to launch a new instance of that ami it's got all of those things already",
    "start": "1327730",
    "end": "1333249"
  },
  {
    "text": "baked into that new instance and at launch time we have a custom bootstrap script that runs that configures the",
    "start": "1333249",
    "end": "1339639"
  },
  {
    "text": "instance for that particular cluster in that particular environment and region and that bootstrap script includes the",
    "start": "1339639",
    "end": "1345399"
  },
  {
    "text": "ECS cluster configuration what what cluster should I join that that changes depending on which region you're in it's",
    "start": "1345399",
    "end": "1352419"
  },
  {
    "text": "we control the startup life cycle of the EECS agent itself we want to make sure that that agent doesn't style until we",
    "start": "1352419",
    "end": "1358570"
  },
  {
    "text": "fully configured the box and also the docker configuration we start up we we",
    "start": "1358570",
    "end": "1363669"
  },
  {
    "text": "control when the docker daemon starts up the the bootstrap script also initiates",
    "start": "1363669",
    "end": "1369549"
  },
  {
    "text": "some cron jobs so every minute we'll check that the ECS agent and the docker demon is still running if not we'll",
    "start": "1369549",
    "end": "1375339"
  },
  {
    "text": "restart them and put some custom metrics so is the ECS agent running his docker it contain a docker daemon still running",
    "start": "1375339",
    "end": "1382299"
  },
  {
    "text": "and we'll push those metrics to cloud watch and various other care watch metrics so that we can monitor the state",
    "start": "1382299",
    "end": "1387549"
  },
  {
    "text": "of the instance and so we we have a fair",
    "start": "1387549",
    "end": "1393070"
  },
  {
    "text": "bit of experience when it comes to upgrading these clusters so we have a few a few different attempts over the",
    "start": "1393070",
    "end": "1399639"
  },
  {
    "text": "years on how to how to do zero downtime cluster updates so we when it comes to updating and production cluster if you",
    "start": "1399639",
    "end": "1405700"
  },
  {
    "text": "have a cluster with a hundred instances in it and you want to replace all of those you need to be very careful about",
    "start": "1405700",
    "end": "1411039"
  },
  {
    "text": "making sure that all the containers on those 100 instances safely moved to a new 100 instances and so we started",
    "start": "1411039",
    "end": "1417820"
  },
  {
    "text": "using cloud formations auto scaling rolling update policy we found some",
    "start": "1417820",
    "end": "1423129"
  },
  {
    "text": "issues with that where we needed to be very careful about when exactly tasks were being terminated we've been stopped",
    "start": "1423129",
    "end": "1429999"
  },
  {
    "text": "and we have a few different iterations through that we wrote our own Ruby script to go through and do instances",
    "start": "1429999",
    "end": "1436690"
  },
  {
    "text": "one of the time but that was taking ten hours to do a 100 instance cluster and you can imagine an engineer sitting",
    "start": "1436690",
    "end": "1442479"
  },
  {
    "text": "there for 10 nail-biting hours watching making sure that all all the tasks are moving across safely and we're replacing",
    "start": "1442479",
    "end": "1449529"
  },
  {
    "text": "one instance at a time so if something went wrong halfway through that process we've got a cluster with half new",
    "start": "1449529",
    "end": "1455409"
  },
  {
    "text": "instances and half old instances in the only way to rollback is to create again all of the old instances and there's",
    "start": "1455409",
    "end": "1461549"
  },
  {
    "text": "some some nervous nervous moments involved that so what we start at the beginning",
    "start": "1461549",
    "end": "1468339"
  },
  {
    "text": "of this year was was project prism which was really aimed at getting that ten hours down to less than an hour so prism",
    "start": "1468339",
    "end": "1474429"
  },
  {
    "text": "stands for project replaced in sixty minutes and the goals of prism were",
    "start": "1474429",
    "end": "1480009"
  },
  {
    "start": "1478000",
    "end": "1478000"
  },
  {
    "text": "first of all safety we wanted to ensure that there was a very down time for applications that while we're replacing",
    "start": "1480009",
    "end": "1486339"
  },
  {
    "text": "all of the infrastructure in within that cluster underneath all the applications that are running we're gonna make sure",
    "start": "1486339",
    "end": "1491829"
  },
  {
    "text": "that they don't experience any downtime and that it's seamless to our internal users in our external users the other",
    "start": "1491829",
    "end": "1499839"
  },
  {
    "text": "aspect the other goal was speed so yeah we wanted to complete it as fast as possible less than an hour was our goal",
    "start": "1499839",
    "end": "1505269"
  },
  {
    "text": "I wanted to be rollback able so we want to be able to quickly retreat back to a know in good state and not have to rollback by rolling forward and we",
    "start": "1505269",
    "end": "1512169"
  },
  {
    "text": "wanted to be identity' if anything went wrong during this process or if the scripts timed out or something",
    "start": "1512169",
    "end": "1517539"
  },
  {
    "text": "unforeseen happened that we could just resume by restarting the script and it would pick up from where it left off and",
    "start": "1517539",
    "end": "1523690"
  },
  {
    "text": "avoid this thundering herd scenario that we had with the original approach where as your terminating old instances and",
    "start": "1523690",
    "end": "1530529"
  },
  {
    "text": "those tasks are moving they're moving onto instances that are just about to be replaced as you're rolling through one instance at a time so we wanted to avoid",
    "start": "1530529",
    "end": "1537309"
  },
  {
    "text": "that scenario we wanted to also avoid a scenario where as where we're going for",
    "start": "1537309",
    "end": "1542529"
  },
  {
    "text": "speed with with replacing all of these instances and creating new containers",
    "start": "1542529",
    "end": "1547539"
  },
  {
    "text": "new images let me make sure that there wasn't a big burden on our internal docker registry where the images will be",
    "start": "1547539",
    "end": "1553179"
  },
  {
    "text": "pulled down for and likewise a big burden on our internal network all of this image copying was taking place so",
    "start": "1553179",
    "end": "1562659"
  },
  {
    "text": "we spit we split prism down into three different phases each of them independently roll back will and I",
    "start": "1562659",
    "end": "1568029"
  },
  {
    "text": "dampening the first phase was called expand the second relocate tasks and then the third was to clean up so in the",
    "start": "1568029",
    "end": "1574959"
  },
  {
    "text": "first phase we took this cluster that that we showed before and we duplicated the cloud formation stack which created",
    "start": "1574959",
    "end": "1581769"
  },
  {
    "text": "a new auto scaling group with all of the replacement instances so if we had a 100 instance cluster we would create a",
    "start": "1581769",
    "end": "1588039"
  },
  {
    "text": "duplicate stack with the 100 new instances running on the new ami that we'd built and those 100 instances at",
    "start": "1588039",
    "end": "1594969"
  },
  {
    "text": "launch time would join the EECS cluster it was quite amazing to see within six minutes 100 new instances join the cluster and",
    "start": "1594969",
    "end": "1602520"
  },
  {
    "text": "then phase 2 we took advantage of the draining feature that the ECS team",
    "start": "1602520",
    "end": "1608230"
  },
  {
    "text": "introduced last year which was which was very beneficial and what the draining feature does is you set an instance into",
    "start": "1608230",
    "end": "1615100"
  },
  {
    "text": "draining mode and that says all right ACS says all of the tasks that are running on this draining instance they",
    "start": "1615100",
    "end": "1621550"
  },
  {
    "text": "need to be relocated to any instance that's not draining and so it won't stop",
    "start": "1621550",
    "end": "1627190"
  },
  {
    "text": "those tasks on the draining instance until they're safely running on other active instances and behind their respective load balances for those",
    "start": "1627190",
    "end": "1633940"
  },
  {
    "text": "services so that was a big win for us so what we do is we go through in batches of of instances in the old auto scaling",
    "start": "1633940",
    "end": "1641560"
  },
  {
    "text": "group we set them to draining and we programmatically poll waiting until a certain threshold of tasks has safely",
    "start": "1641560",
    "end": "1648760"
  },
  {
    "text": "moved and then when we want to the next batch once those instances are fully",
    "start": "1648760",
    "end": "1653980"
  },
  {
    "text": "drained phase three is to clean up by just simply removing the old stack so",
    "start": "1653980",
    "end": "1659320"
  },
  {
    "text": "there were a few benefits of this approach and one of them was the ability to rollback so at any point in time if something went wrong on the new stack",
    "start": "1659320",
    "end": "1666040"
  },
  {
    "text": "with the relocation we could simply reverse the draining process set the old instances into active mode and then set",
    "start": "1666040",
    "end": "1673450"
  },
  {
    "text": "the news misses into draining way for them to retreat back to the knowing good state that had been running in production for a while already and then",
    "start": "1673450",
    "end": "1680800"
  },
  {
    "text": "we could just terminate the new stack and we didn't have to wait a long time",
    "start": "1680800",
    "end": "1686470"
  },
  {
    "text": "for that to happen so for a 100 instance cluster which is what we saw at the beginning of the year for ten hours for",
    "start": "1686470",
    "end": "1694150"
  },
  {
    "text": "the old process we reduce that to around half an hour so it actually worked out to me to be really good and then after",
    "start": "1694150",
    "end": "1701800"
  },
  {
    "text": "Phase three you're left with just a single stack running on the new PCs cluster so another aspect of this is",
    "start": "1701800",
    "end": "1709720"
  },
  {
    "text": "monitoring of our clusters so ECS doesn't provide monitoring you need to",
    "start": "1709720",
    "end": "1716800"
  },
  {
    "text": "set up your own monitoring you know monitoring dashboards and alerts they do",
    "start": "1716800",
    "end": "1723130"
  },
  {
    "text": "provide some cloud watch statistics that you can use in can take advantage of but you still need to be very aware of",
    "start": "1723130",
    "end": "1728550"
  },
  {
    "text": "what's going on in your clusters so this is a monitoring dashboard we have in a called Griffin are two popular",
    "start": "1728550",
    "end": "1734740"
  },
  {
    "text": "open-source tool each bro is a different region so the top row there you can see",
    "start": "1734740",
    "end": "1740680"
  },
  {
    "text": "that we're monitoring CPU and memory utilization and reservation which is a statistic we get at the ECS level an",
    "start": "1740680",
    "end": "1746920"
  },
  {
    "text": "average across the entire cluster we're monitoring the number of the instances in the auto-scaling groups and we're",
    "start": "1746920",
    "end": "1753130"
  },
  {
    "text": "monitoring instances services and tasks within that same costume the things that",
    "start": "1753130",
    "end": "1759730"
  },
  {
    "start": "1758000",
    "end": "1758000"
  },
  {
    "text": "we're by experience that we've come to learn to to monitor memory CPU disk for",
    "start": "1759730",
    "end": "1765340"
  },
  {
    "text": "just about everything you want to know about any any issues going on in this before your internal users do their",
    "start": "1765340",
    "end": "1772330"
  },
  {
    "text": "clusters themselves as I mentioned have some statistics that you can keep an eye on auto-scaling groups watching those",
    "start": "1772330",
    "end": "1778720"
  },
  {
    "text": "statistics the build and deployment servers don't forget to monitor those what's going on because your teams you",
    "start": "1778720",
    "end": "1786730"
  },
  {
    "text": "know we treat we treat our test environment internally we are responsible for maintaining the test",
    "start": "1786730",
    "end": "1793270"
  },
  {
    "text": "environment and make sure deployments are smooth we want to make sure that our internal users experience is just as",
    "start": "1793270",
    "end": "1799360"
  },
  {
    "text": "smooth in test as it is in production so if there's any issues in tests we want to treat that like it is production",
    "start": "1799360",
    "end": "1804850"
  },
  {
    "text": "internally for our team similarly for our Jenkins build nodes",
    "start": "1804850",
    "end": "1810220"
  },
  {
    "text": "logging servers docker registry these are all the things that we've come to learn it's really important to keep an",
    "start": "1810220",
    "end": "1816550"
  },
  {
    "text": "eye on those things and know about problems that are going on there so what does it look like in terms of how the metrics get into our graph on our",
    "start": "1816550",
    "end": "1823000"
  },
  {
    "text": "dashboard so we've got our ec2 instances in our auto scaling in each instance will be pushing metrics to cloud watch",
    "start": "1823000",
    "end": "1829960"
  },
  {
    "text": "so we I mentioned those custom metrics that we have so we're we're checking the state of the ECS agent and the docker",
    "start": "1829960",
    "end": "1835210"
  },
  {
    "text": "daemon periodically pushing the state whether they're running or not so we can alert if it's if it's been down for some",
    "start": "1835210",
    "end": "1840760"
  },
  {
    "text": "time we push extended cloud watch metrics using the standard cloud watch scripts and we've got some cron jobs",
    "start": "1840760",
    "end": "1847630"
  },
  {
    "text": "that push some other custom metrics as well and then a graphing our dashboard is able to pull down those metrics from",
    "start": "1847630",
    "end": "1853870"
  },
  {
    "text": "cloud watch directly then we use Jenkins to pull periodically pull down some",
    "start": "1853870",
    "end": "1860440"
  },
  {
    "text": "stats from the auto scaling group itself just by clearing the Amazon api's push those two graph I which is another",
    "start": "1860440",
    "end": "1865930"
  },
  {
    "text": "common open-source monitoring tool and graph final calls in those statistics from",
    "start": "1865930",
    "end": "1872160"
  },
  {
    "text": "graphite and we've built in some chatroom integration with with slack so",
    "start": "1872160",
    "end": "1880020"
  },
  {
    "text": "we get notified about any alerts that are coming on or auto-scaling events or various different things we keep an eye",
    "start": "1880020",
    "end": "1885840"
  },
  {
    "text": "on that on the channel and make sure things that go on smoothly when it comes",
    "start": "1885840",
    "end": "1891450"
  },
  {
    "text": "to right sizing instances this is a tricky aspect of cluster management what",
    "start": "1891450",
    "end": "1896640"
  },
  {
    "text": "you want to go for is a balance between your CPU and your your memory statistics",
    "start": "1896640",
    "end": "1902400"
  },
  {
    "text": "on on your on your instances so you want to make sure that you've got the right mix there we started off with C for 4x",
    "start": "1902400",
    "end": "1909060"
  },
  {
    "text": "large instances but we found with 30 gigs of ram 16 cores we found that people were not using much of the CPU",
    "start": "1909060",
    "end": "1916380"
  },
  {
    "text": "that they had reserved so we changed our default CPU reservation for applications",
    "start": "1916380",
    "end": "1921810"
  },
  {
    "text": "that are generated by primer we set that down to 1/8 of a call and then we changed our instance type to our 4 to X",
    "start": "1921810",
    "end": "1928080"
  },
  {
    "text": "large which gives double the memory and half the CPU I showed this diagram",
    "start": "1928080",
    "end": "1934830"
  },
  {
    "text": "before this is this cluster is at about 64% CPU reservation it will be somewhere",
    "start": "1934830",
    "end": "1942120"
  },
  {
    "text": "between 60 and 75 percent depending on how many auto-scaling events are triggered but still we're",
    "start": "1942120",
    "end": "1948900"
  },
  {
    "text": "only at 12% CPU utilization for memory we're at the bound 30 percent",
    "start": "1948900",
    "end": "1954300"
  },
  {
    "text": "reservation and around 13 percent utilization you can see that we've got it we got the instance type right in",
    "start": "1954300",
    "end": "1960300"
  },
  {
    "text": "terms of memory and CPU are around the 1213 percent marks we've got the the right size of the instance type to Reza",
    "start": "1960300",
    "end": "1966330"
  },
  {
    "text": "to utilization but when it comes to reservation we need to sorry we need to work closely more closely with our teams",
    "start": "1966330",
    "end": "1972210"
  },
  {
    "text": "to say you're reserving a lot of CPU calls that we're just not using and it's up to us to go back and socialise and",
    "start": "1972210",
    "end": "1978000"
  },
  {
    "text": "try and get that balance get that balance right across the org",
    "start": "1978000",
    "end": "1983510"
  },
  {
    "text": "so in terms of cost and management the benefits that we get out of this this approach this investment that we have we",
    "start": "1983870",
    "end": "1989730"
  },
  {
    "text": "get the speed out of having those prevailed ECS clusters which means that there's no ec2 instance startup time for",
    "start": "1989730",
    "end": "1997200"
  },
  {
    "text": "deployments or for auto schedules we've pre-built those clusters and they scale out independently of deployment and auto-scaling activities",
    "start": "1997200",
    "end": "2005020"
  },
  {
    "text": "another aspect of speed is that when when you build a docker image if you",
    "start": "2005020",
    "end": "2010160"
  },
  {
    "text": "have to Java applications they were both built off the same base image then when it comes to pulling down that",
    "start": "2010160",
    "end": "2016520"
  },
  {
    "text": "application image to an instance if an instance is running two totally different Java applications they can share the same base image and that",
    "start": "2016520",
    "end": "2023030"
  },
  {
    "text": "basically means only needs to be pulled down once and then for the second application it just needs to pull down that extra layer on top with the",
    "start": "2023030",
    "end": "2029030"
  },
  {
    "text": "artifact of that image so that's another benefit that we get out of having a shared ECS cluster or any sort of",
    "start": "2029030",
    "end": "2035000"
  },
  {
    "text": "clustering technology is that you docker can take advantage of the fact that it only needs to pull down the differences",
    "start": "2035000",
    "end": "2041210"
  },
  {
    "text": "in image layers we also get safety",
    "start": "2041210",
    "end": "2046580"
  },
  {
    "text": "aspects out of this as well so because we're using the immutable server approach it means there's no",
    "start": "2046580",
    "end": "2051710"
  },
  {
    "text": "configuration drift from one instance to another you're never asking the question why is this instance misbehaving what's",
    "start": "2051710",
    "end": "2057379"
  },
  {
    "text": "somebody gone and done on that instance why is that instance different to any others we just simply accept the fact",
    "start": "2057380",
    "end": "2063470"
  },
  {
    "text": "that at scale you're going to have problems that you can't foresee you simply terminate the instance and you can investigate to see is there going to",
    "start": "2063470",
    "end": "2069620"
  },
  {
    "text": "be a widespread issue that we have but it just reduces a lot of the questions that you have around what are the",
    "start": "2069620",
    "end": "2074990"
  },
  {
    "text": "potential changes that are going on between different instance types and the last benefit there is scale so because",
    "start": "2074990",
    "end": "2082100"
  },
  {
    "text": "these clusters automatically scale horizontally to match we're hands off where we just we let the order scaling",
    "start": "2082100",
    "end": "2087770"
  },
  {
    "text": "take care of that so we start off with a five instance cluster and then we come back and instead thirty instances because teams have been deploying to",
    "start": "2087770",
    "end": "2093530"
  },
  {
    "text": "that region our big clusters they just keep scaling bigger and bigger some",
    "start": "2093530",
    "end": "2099530"
  },
  {
    "text": "people ask us what sort of skill set do you have within your team that supports this we have around eight people that",
    "start": "2099530",
    "end": "2105440"
  },
  {
    "text": "taken that take responsibility for those middle two aspects so our cloud acceleration team it's a worldwide team",
    "start": "2105440",
    "end": "2111880"
  },
  {
    "text": "and within our brisbane office we focus mostly on on these aspects here but will",
    "start": "2111880",
    "end": "2117140"
  },
  {
    "text": "also contribute to the wider cloud effort and there'll be people from other offices that also contribute so this is",
    "start": "2117140",
    "end": "2123260"
  },
  {
    "text": "a virtual virtual allocation of people that we need to keep this platform",
    "start": "2123260",
    "end": "2128750"
  },
  {
    "text": "running and we have about six engineers different development and operations backgrounds",
    "start": "2128750",
    "end": "2134060"
  },
  {
    "text": "myself as an engineering manager and a project manager what we do is we'd liaised with them as on ECS team if",
    "start": "2134060",
    "end": "2140630"
  },
  {
    "text": "there's any issues if there's any feedback that we have all that they have recommendations we do that upgrading of",
    "start": "2140630",
    "end": "2146210"
  },
  {
    "text": "VCs clusters so periodically we'll go through and replace the clusters with with new a.m. eyes assisting development",
    "start": "2146210",
    "end": "2152180"
  },
  {
    "text": "teams with their questions about how do we get into the cloud monitoring of those AWS resource limits that you need",
    "start": "2152180",
    "end": "2158840"
  },
  {
    "text": "to be very aware of cost optimization and monitoring infrastructure and migrations we kind of sit as this team",
    "start": "2158840",
    "end": "2165650"
  },
  {
    "start": "2164000",
    "end": "2164000"
  },
  {
    "text": "in the middle of the cloud team between Amazon and our developers so we're really trying to really trying to",
    "start": "2165650",
    "end": "2170840"
  },
  {
    "text": "accelerate the developers experience so when it comes to what the developers have to do well they're the ones that go",
    "start": "2170840",
    "end": "2176359"
  },
  {
    "text": "into primer and create their micro services they're responsible for configuring their pipelines and",
    "start": "2176359",
    "end": "2181790"
  },
  {
    "text": "configuring their build jobs and configuring their applications and then we're responsible for building that",
    "start": "2181790",
    "end": "2189020"
  },
  {
    "text": "platform in between and then we like liaise with Amazon so they're responsible for the ECS scheduler that",
    "start": "2189020",
    "end": "2194750"
  },
  {
    "text": "brain the central brain we don't get involved in that we just if there's any",
    "start": "2194750",
    "end": "2199820"
  },
  {
    "text": "issues with that we will just contact them and then that doesn't link of tasks",
    "start": "2199820",
    "end": "2205790"
  },
  {
    "text": "and then we get involved in recommendations and feedback about the service itself so what are some of the",
    "start": "2205790",
    "end": "2213050"
  },
  {
    "text": "lessons that we've learned along the way the first one is monitoring is your friend and we learned this the hard way",
    "start": "2213050",
    "end": "2218570"
  },
  {
    "text": "so I come from a development background and yeah we we quickly encountered just",
    "start": "2218570",
    "end": "2225800"
  },
  {
    "text": "issues where you know maybe we weren't monitoring CPU and and disk so we were",
    "start": "2225800",
    "end": "2231530"
  },
  {
    "text": "in the early days surprised by things that developers would tell us about it so really appreciate having some good",
    "start": "2231530",
    "end": "2237740"
  },
  {
    "text": "strong sysadmin skills in the team now and they've been been helping us to to really own solidify that experience next",
    "start": "2237740",
    "end": "2245990"
  },
  {
    "text": "is a true blue green deploys so I mentioned before how we do blue green deploys is by having a canary service so",
    "start": "2245990",
    "end": "2253369"
  },
  {
    "text": "we do a separate deploy to release process and some of the issues that",
    "start": "2253369",
    "end": "2260119"
  },
  {
    "text": "we've experienced with this process is that you can't easily rollback without releasing from if you want to go from v2",
    "start": "2260119",
    "end": "2267320"
  },
  {
    "text": "to v1 you have to roll back by re-releasing v1 and testing tasks independently they're the",
    "start": "2267320",
    "end": "2273440"
  },
  {
    "text": "other other issues is that some aspects of load balances are immutable so if you",
    "start": "2273440",
    "end": "2278660"
  },
  {
    "text": "want to change your EOB scheme from internet-facing to private to internal you can't you",
    "start": "2278660",
    "end": "2285650"
  },
  {
    "text": "can't do that and you might want to create a whole new load balancer for your service but ECS has a one-to-one",
    "start": "2285650",
    "end": "2291650"
  },
  {
    "text": "mapping with the EOB that you can't modify after you've created your ECS service so any of our internal customers",
    "start": "2291650",
    "end": "2297590"
  },
  {
    "text": "that want a new load balancer we have to say what you have to create a new new service or you have to experience some",
    "start": "2297590",
    "end": "2302900"
  },
  {
    "text": "downtime for your app or you what you replace it so that's some of the aspects",
    "start": "2302900",
    "end": "2309920"
  },
  {
    "text": "there that we see so the true Bluegreen approaches this is what we actually use for our dedicated ec2 platform that we",
    "start": "2309920",
    "end": "2318860"
  },
  {
    "text": "have and we want to move our ECS deployments over to as well and what we do there is we treat the live service",
    "start": "2318860",
    "end": "2324980"
  },
  {
    "text": "the version 1 service is the the blue stack and then when it comes to upgrading to version 2 we'll create a",
    "start": "2324980",
    "end": "2331460"
  },
  {
    "text": "whole new load balancer and a new ECS service as the green stack running",
    "start": "2331460",
    "end": "2336920"
  },
  {
    "text": "version 2 so instead of a single canary task we'll create all the replacement tasks with a whole new load balancer and",
    "start": "2336920",
    "end": "2342830"
  },
  {
    "text": "the idea is that we would test against the load balancer direct and then when it comes to release time we would send",
    "start": "2342830",
    "end": "2349910"
  },
  {
    "text": "traffic from the old load balancer to the new load balancer we can bleed that traffic over across slowly so you can",
    "start": "2349910",
    "end": "2355640"
  },
  {
    "text": "start off with with 10% and just do some load testing if you're processing thousands of transactions you can just",
    "start": "2355640",
    "end": "2362660"
  },
  {
    "text": "see how are we going on version 2 with the 10% of the traffic if there's an issue you can roll back back to 100% on",
    "start": "2362660",
    "end": "2369080"
  },
  {
    "text": "the old version and it allows you to have new ERV settings but you do have to",
    "start": "2369080",
    "end": "2374150"
  },
  {
    "text": "warm up that EOB so that's why we would leave the traffic over gradually and it's a tweetable thing that users can",
    "start": "2374150",
    "end": "2381020"
  },
  {
    "text": "choose that deployment time at release time how quickly they want to roll over to the new load balancer so eventually",
    "start": "2381020",
    "end": "2389330"
  },
  {
    "text": "you'd be sending 100% traffic to the load balancer if there's some issues with version 2 you can simply roll back",
    "start": "2389330",
    "end": "2394520"
  },
  {
    "text": "to the old load balancer with a cname switch and once you're happy you go back and send all your traffic all would be",
    "start": "2394520",
    "end": "2401090"
  },
  {
    "text": "running on version two next lesson is is to know your limits so in terms of resource",
    "start": "2401090",
    "end": "2410270"
  },
  {
    "start": "2406000",
    "end": "2406000"
  },
  {
    "text": "limits the number of services you can have per cluster is 500 and we did did hit this limit the solution is to ask",
    "start": "2410270",
    "end": "2416330"
  },
  {
    "text": "nicely and and the ECS support team can can increase it for you some changes",
    "start": "2416330",
    "end": "2421820"
  },
  {
    "text": "that can't be made that we've hit is when it comes to the registration rate for ECS agents connecting to the EECS",
    "start": "2421820",
    "end": "2429140"
  },
  {
    "text": "scheduler so with our prism project we were trying to stand up that is 100 replacement instances all at once and so",
    "start": "2429140",
    "end": "2435020"
  },
  {
    "text": "we have 100 agents trying to or within the same couple of seconds register into the into the central brain and would get",
    "start": "2435020",
    "end": "2443000"
  },
  {
    "text": "some some api rate limit issues there so we solved that just simply by having an exponential back-off you know ECS agent",
    "start": "2443000",
    "end": "2450230"
  },
  {
    "text": "startup script that i mentioned that we control the when when to startup that ECS agent the other limits to be aware",
    "start": "2450230",
    "end": "2458300"
  },
  {
    "start": "2457000",
    "end": "2457000"
  },
  {
    "text": "of is is rate limits when it comes to api rate limits you know what we experienced where's our accounts and our",
    "start": "2458300",
    "end": "2464840"
  },
  {
    "text": "own clusters were getting bigger and bigger the more elby's and the more easier services we have the more chatty",
    "start": "2464840",
    "end": "2469850"
  },
  {
    "text": "those two services are on our behalf to each other so or what we're working",
    "start": "2469850",
    "end": "2476870"
  },
  {
    "text": "towards is sharding our accounts into smaller accounts which i think is the recommended best practice we're looking",
    "start": "2476870",
    "end": "2484370"
  },
  {
    "text": "at each it's large team having their own account we take advantage of cloud trail",
    "start": "2484370",
    "end": "2490130"
  },
  {
    "text": "events and we'll push those events into elasticsearch and then we'll use Cabana",
    "start": "2490130",
    "end": "2495290"
  },
  {
    "text": "to visualize which is an example there which really helps to to drill down if you're experiencing API rate limits go",
    "start": "2495290",
    "end": "2501440"
  },
  {
    "text": "and see what are the biggest defenders by analyzing your your Cabana visualizations another lesson that we",
    "start": "2501440",
    "end": "2510620"
  },
  {
    "text": "learned is is to avoid auto scale thrashing by this I mean the problem where you scale up do to perhaps CPU",
    "start": "2510620",
    "end": "2517820"
  },
  {
    "text": "reservation being too high in the cluster needs to expand but then five minutes later it realizes that memory",
    "start": "2517820",
    "end": "2523520"
  },
  {
    "text": "utilization is is now two memory reservation is too low so it will scale back down and it repeats that cycle over",
    "start": "2523520",
    "end": "2529640"
  },
  {
    "text": "and over every five minutes so the way to fix that and there's a few solutions you can",
    "start": "2529640",
    "end": "2535060"
  },
  {
    "text": "you can fix your scaling dimensions so that you only scale down when when both",
    "start": "2535060",
    "end": "2540890"
  },
  {
    "text": "the low to do that you need to create your own custom cloud watch metric which combines CPU and memory and push that to",
    "start": "2540890",
    "end": "2546650"
  },
  {
    "text": "cloud watch and only use that specifically when you are scaling down another solution that you could have for",
    "start": "2546650",
    "end": "2552740"
  },
  {
    "text": "that is to fix the ratios at which you configure your configure your services",
    "start": "2552740",
    "end": "2558380"
  },
  {
    "text": "so if you have an 8 core and 64 gig instance type which is like a ratio of 1",
    "start": "2558380",
    "end": "2565070"
  },
  {
    "text": "to 8 make sure that your users can only have a 1 to weight ratio when they are specifying the memory and CPU statistics",
    "start": "2565070",
    "end": "2573590"
  },
  {
    "text": "for for their application the solution we ended up with it was just for now set",
    "start": "2573590",
    "end": "2579140"
  },
  {
    "text": "the scale down policies low we really need to scale down anyway because we're just organically growing as more and",
    "start": "2579140",
    "end": "2584840"
  },
  {
    "text": "more primer applications and being created every day some of the the future",
    "start": "2584840",
    "end": "2591020"
  },
  {
    "text": "plans that we have in place that we're looking at doing some things that would like to to get on top of is cost",
    "start": "2591020",
    "end": "2597110"
  },
  {
    "text": "allocation how do we allocate costs to individual teams when we're having this shared infrastructure a service",
    "start": "2597110",
    "end": "2603740"
  },
  {
    "text": "discovery approach particularly for internal private applications moving towards ECR gives us some extra",
    "start": "2603740",
    "end": "2610490"
  },
  {
    "text": "redundancy having an ECR per her region so to summarize the benefits that we get",
    "start": "2610490",
    "end": "2617960"
  },
  {
    "start": "2614000",
    "end": "2614000"
  },
  {
    "text": "out of this micro service platform using ECS we've got the the primer application the primer tool there which gives us the",
    "start": "2617960",
    "end": "2624350"
  },
  {
    "text": "benefits of reduced cost of experimentation and that fast feedback",
    "start": "2624350",
    "end": "2629440"
  },
  {
    "text": "the deployment automation gives us that that that speed and safety when it comes",
    "start": "2629440",
    "end": "2634760"
  },
  {
    "text": "to reducing a lot of manual steps down to repeatable reliable steps the click of a button will fully automated and",
    "start": "2634760",
    "end": "2640910"
  },
  {
    "text": "then the cluster management the investment we have therein in keeping those ECS clusters maintained it means",
    "start": "2640910",
    "end": "2647000"
  },
  {
    "text": "that we've got those pre-built instances they're ready to receive docker workloads and and give me the ultimate",
    "start": "2647000",
    "end": "2652580"
  },
  {
    "text": "speed at deployment and auto scaling time and also the sharing of those docker layers that I mentioned increases",
    "start": "2652580",
    "end": "2658910"
  },
  {
    "text": "the speed the immutable server approach no configuration drift and the ability to auto scale horizontally so that's",
    "start": "2658910",
    "end": "2666770"
  },
  {
    "text": "just summarize the the benefits we get so did we succeed I mentioned that our mission as a cloud",
    "start": "2666770",
    "end": "2672770"
  },
  {
    "text": "acceleration team is to speed up developers lines to make to make their lives faster and easier so our hypothesis was going back two and a half",
    "start": "2672770",
    "end": "2680300"
  },
  {
    "text": "years now when we when we embarked on this journey we thought that we could make developers lives faster maybe",
    "start": "2680300",
    "end": "2686240"
  },
  {
    "text": "double the speed at which it takes to deploy using using docker instead of dedicated ec2 instances the initial",
    "start": "2686240",
    "end": "2694610"
  },
  {
    "text": "primer approach did use docker ec2 instances and that would use chef to build a.m. eyes and I will take about 30",
    "start": "2694610",
    "end": "2700340"
  },
  {
    "text": "minutes to deploy because it needs to used to spin up a new instance it needs to pull down chef set up all the all",
    "start": "2700340",
    "end": "2707360"
  },
  {
    "text": "those configuration and software and it needs to burn in a ami and then create a",
    "start": "2707360",
    "end": "2712880"
  },
  {
    "text": "cloud formation stack for L our 2.0 approach using docker with ECS it takes",
    "start": "2712880",
    "end": "2719690"
  },
  {
    "text": "three minutes to do that that process and it's this is just talking about the initial deploy to the initial testing",
    "start": "2719690",
    "end": "2725360"
  },
  {
    "text": "environment so to get production like feedback so we received that feedback as a developer every commit you'll receive",
    "start": "2725360",
    "end": "2732440"
  },
  {
    "text": "that feedback twenty seven minutes faster because it takes advantage of having that shared UCS infrastructure",
    "start": "2732440",
    "end": "2738880"
  },
  {
    "text": "and now developers do on average five hundred and twenty four deploys per day per business day to our initial testing",
    "start": "2738880",
    "end": "2745730"
  },
  {
    "text": "environment so if you multiply that out as you go further right you'll see that five hundred twenty four times twenty",
    "start": "2745730",
    "end": "2751820"
  },
  {
    "text": "seven minutes that that's a saving of about twenty nine and a half business days every day so that means",
    "start": "2751820",
    "end": "2757760"
  },
  {
    "text": "that we are developers will receive that feedback and this is the most critical feedback right it's that will this will",
    "start": "2757760",
    "end": "2765170"
  },
  {
    "text": "this commit that I've made will this change I've made actually work in a production like environment so just that initial commit commit and and deploy so",
    "start": "2765170",
    "end": "2774650"
  },
  {
    "text": "that's it's pretty staggering when you kind of look at the figures and say well because we're deploying a lot faster we",
    "start": "2774650",
    "end": "2779960"
  },
  {
    "text": "can do a lot more deploys and because we're doing now we're saving a lot of time that's where the support team of",
    "start": "2779960",
    "end": "2786590"
  },
  {
    "text": "around eight people we save around thirty developer days every day so using these pre-built fleet fleets or",
    "start": "2786590",
    "end": "2793880"
  },
  {
    "text": "VCS instances with these clusters and we were able to speed up deploy times and",
    "start": "2793880",
    "end": "2799250"
  },
  {
    "text": "and be able to quickly and safely deploy software is as docker images and this has effectively reduced that opportunity",
    "start": "2799250",
    "end": "2805670"
  },
  {
    "text": "cost by by a factor of 30 times and together with the primer micro-service",
    "start": "2805670",
    "end": "2811010"
  },
  {
    "text": "generation platform it really helps to capture that that time value of",
    "start": "2811010",
    "end": "2816380"
  },
  {
    "text": "information and bring that that experimentation down as and get that feedback as early as possible so we have",
    "start": "2816380",
    "end": "2825920"
  },
  {
    "text": "we have some time for questions now there's some microphones set up by the side of the room so any questions please",
    "start": "2825920",
    "end": "2831470"
  },
  {
    "text": "come ahead yeah so your developers are",
    "start": "2831470",
    "end": "2836630"
  },
  {
    "text": "spinning things up and so a lot of that is going to be abandoned stuff in some",
    "start": "2836630",
    "end": "2843710"
  },
  {
    "text": "of it new stuff is going to come it's going to replace older stuff so how are",
    "start": "2843710",
    "end": "2849109"
  },
  {
    "text": "you finding the stuff that it's end-of-life and the stuff that is abandoned sure so we have around 4,000",
    "start": "2849109",
    "end": "2857390"
  },
  {
    "text": "primer applications and we have in total",
    "start": "2857390",
    "end": "2863060"
  },
  {
    "text": "there was six and a half thousand so two and a half thousand have already been deleted there are temporary experiments",
    "start": "2863060",
    "end": "2868220"
  },
  {
    "text": "and it's really up to each individual team to decide what that lifecycle is so we will find some apps some applications",
    "start": "2868220",
    "end": "2876050"
  },
  {
    "text": "that are abandoned that are kind of running still in our clusters and will usually go through and contact the",
    "start": "2876050",
    "end": "2881570"
  },
  {
    "text": "authors and say hey did you know this was still running there and that yeah",
    "start": "2881570",
    "end": "2888790"
  },
  {
    "text": "yeah yeah the question there was that requires people looking at it and seeing",
    "start": "2888790",
    "end": "2895369"
  },
  {
    "text": "is this still being used yeah that's the case yeah this is really inspiring work",
    "start": "2895369",
    "end": "2901010"
  },
  {
    "text": "I must say cuz we're trying to get this far in my organization my question is some of the capabilities are provided by",
    "start": "2901010",
    "end": "2907730"
  },
  {
    "text": "the platform like auto scaling and so on how much local development software",
    "start": "2907730",
    "end": "2913820"
  },
  {
    "text": "development did your teams need to do in order to realize this full and end solution sure when it comes specifically",
    "start": "2913820",
    "end": "2921530"
  },
  {
    "text": "to auto scaling this is where we we fully take advantage of the features that are in a diverse platform for auto",
    "start": "2921530",
    "end": "2927560"
  },
  {
    "text": "scaling so the only automation that we need to ride is to say is to configure",
    "start": "2927560",
    "end": "2933890"
  },
  {
    "text": "at deployment time for the applications just all right create some cloud watch alarms for this application and create and tell",
    "start": "2933890",
    "end": "2941420"
  },
  {
    "text": "the ECS service that when you're deploying this service use these cloud watch alarms and we specify the auto",
    "start": "2941420",
    "end": "2948410"
  },
  {
    "text": "scaling metrics to say when these cloud watch alarms are fired and it's been up another two so that's something that we",
    "start": "2948410",
    "end": "2955460"
  },
  {
    "text": "took advantage of auto scaling is one thing yep the whole primer application we've been locally written right yes",
    "start": "2955460",
    "end": "2961900"
  },
  {
    "text": "looking past primer into the CI CD and throughout the ability to do the",
    "start": "2961900",
    "end": "2968359"
  },
  {
    "text": "blue-green deploys how much how much of that work the biggest challenges don't need to be solved in software yeah it is",
    "start": "2968359",
    "end": "2975799"
  },
  {
    "text": "a significant effort that we've we've invested internally so primer started in 2014 with an idea that if we we can",
    "start": "2975799",
    "end": "2984770"
  },
  {
    "text": "automate all this stuff it will make people's lives easier and then from there people once we built it people can",
    "start": "2984770",
    "end": "2989930"
  },
  {
    "text": "write so people started using it and we're quite surprised at how popular it became and from there it's a matter of",
    "start": "2989930",
    "end": "2996260"
  },
  {
    "text": "it's the kind of almost in an internal startup mode right you you build something you've got an experiment and",
    "start": "2996260",
    "end": "3001660"
  },
  {
    "text": "then people start using it and so you need to start building in more safety you start building in more automation",
    "start": "3001660",
    "end": "3006910"
  },
  {
    "text": "and smoothing out the developer experience and as people more people with internally within the companies",
    "start": "3006910",
    "end": "3012430"
  },
  {
    "text": "start adopting it that's where you need to just start investing more and you get more buy-in to have the internal",
    "start": "3012430",
    "end": "3019299"
  },
  {
    "text": "resources come and work on it so we have a number of different internal services",
    "start": "3019299",
    "end": "3024369"
  },
  {
    "text": "and internal teams some people working on the primer UX aspect the primer tool",
    "start": "3024369",
    "end": "3029950"
  },
  {
    "text": "some people working on the cluster management other people working on account management and different aspects",
    "start": "3029950",
    "end": "3036280"
  },
  {
    "text": "so yeah thank you yeah hi",
    "start": "3036280",
    "end": "3042309"
  },
  {
    "text": "for your Bluegreen deployments you mentioned that you're able to tip a certain percentage of the traffic to the to the that's aspirational but it",
    "start": "3042309",
    "end": "3049510"
  },
  {
    "text": "doesn't get spun around though ok yes where exactly you turn that dial right yeah so the the logic behind that so what we",
    "start": "3049510",
    "end": "3058119"
  },
  {
    "text": "do at release time on the on our ec2 platform that we want to move to our UCS platform at release time in your Jenkins",
    "start": "3058119",
    "end": "3065410"
  },
  {
    "text": "build you can say I want 10% traffic time to go to be bled and I want this",
    "start": "3065410",
    "end": "3072120"
  },
  {
    "text": "whole bleeding process to take five minutes so it's a simple math calculation to say okay well do 10% and",
    "start": "3072120",
    "end": "3078950"
  },
  {
    "text": "divide that across five minute interval five five minute entire period and so",
    "start": "3078950",
    "end": "3084810"
  },
  {
    "text": "what will happen there is the way it works is with route 53 with weighted cnames it will start off 100% goes to the old",
    "start": "3084810",
    "end": "3092880"
  },
  {
    "text": "load balancer and so I think we just use the figure 100 and there's a route 53 53",
    "start": "3092880",
    "end": "3098400"
  },
  {
    "text": "weighted cnames yeah yeah and then so we'll reduce that to 90 for the old load balancer and simultaneously ten for the new load",
    "start": "3098400",
    "end": "3105030"
  },
  {
    "text": "balancer and then traffic starts going across ten percent and then we just kind of do that intervals yeah I had a",
    "start": "3105030",
    "end": "3116010"
  },
  {
    "text": "question about secret management mmm-hmm so you mentioned configure application configurations how are you guys doing it",
    "start": "3116010",
    "end": "3123840"
  },
  {
    "text": "what's best practice there sure yeah and that's up to each individual team internally to work with the security",
    "start": "3123840",
    "end": "3129450"
  },
  {
    "text": "team and they work out where where secrets should be stored and in the",
    "start": "3129450",
    "end": "3135480"
  },
  {
    "text": "appropriate process for that all right so it's application specific yeah it's not telling you guys me no no all right",
    "start": "3135480",
    "end": "3142590"
  },
  {
    "text": "thanks no problem hey so we're doing a fair amount of the",
    "start": "3142590",
    "end": "3150030"
  },
  {
    "text": "stuff that you're doing but at the moment the way instead of using primer we just sort of copy and paste things",
    "start": "3150030",
    "end": "3157290"
  },
  {
    "text": "which has yeah worked well ish yeah we're starting gets to the point where it's not really gonna cut it anymore",
    "start": "3157290",
    "end": "3163920"
  },
  {
    "text": "yeah could you talk like just a little bit about like roughly how primer is set",
    "start": "3163920",
    "end": "3170190"
  },
  {
    "text": "up yeah yeah sure so it started its life as a as a series of parson and bash scripts and the the",
    "start": "3170190",
    "end": "3178490"
  },
  {
    "text": "the templates will just get repos one per template and it would take the",
    "start": "3178490",
    "end": "3184260"
  },
  {
    "text": "template bring it down from get apply some parameterization to it like they",
    "start": "3184260",
    "end": "3189690"
  },
  {
    "text": "change the app name change the app name token and then push it to a new get repo for that application and now it's it's",
    "start": "3189690",
    "end": "3196560"
  },
  {
    "text": "more advanced we we use a series of services that we've built up and we'll",
    "start": "3196560",
    "end": "3202440"
  },
  {
    "text": "in different different templates because the underlying concept is still there one git repo template and pull it down",
    "start": "3202440",
    "end": "3209460"
  },
  {
    "text": "parameterize it with the correct values and so we'll bring in metadata from different places for the application and",
    "start": "3209460",
    "end": "3215960"
  },
  {
    "text": "we and it really started off as a community effort so when it comes to maintaining those templates symbolize on",
    "start": "3215960",
    "end": "3222390"
  },
  {
    "text": "the community to do that and then we we try and you know make make that",
    "start": "3222390",
    "end": "3228599"
  },
  {
    "text": "experience as consistent as possible across the different applications yeah just a specific follow up I guess like",
    "start": "3228599",
    "end": "3236250"
  },
  {
    "text": "what as a maybe simple example you know some applications need databases so do",
    "start": "3236250",
    "end": "3245609"
  },
  {
    "text": "you really just have a template for every like commonly used combination of",
    "start": "3245609",
    "end": "3252089"
  },
  {
    "text": "technology right no we don't do that no we leave the database choice is up to",
    "start": "3252089",
    "end": "3257460"
  },
  {
    "text": "each team how they want to do that yeah but then we do provide some self-service tools to be able to to create those",
    "start": "3257460",
    "end": "3263869"
  },
  {
    "text": "resources as well but each team is responsible for what backend choices they want to make yeah thanks know we",
    "start": "3263869",
    "end": "3272280"
  },
  {
    "text": "struggle to get our developers to rebuild their containers when there's security patches only when there's",
    "start": "3272280",
    "end": "3278280"
  },
  {
    "text": "critical can we really force them I deal with that on a large scale yeah that's right but I've got to get it out there",
    "start": "3278280",
    "end": "3284339"
  },
  {
    "text": "and I think at deployment time that's where you can really say no you can't deploy anymore because your your",
    "start": "3284339",
    "end": "3291390"
  },
  {
    "text": "container is using the an older version yeah with that yeah that's right",
    "start": "3291390",
    "end": "3301250"
  },
  {
    "text": "I've got time for a couple more questions if there's any otherwise we can get an early mark and get ready for",
    "start": "3303290",
    "end": "3308460"
  },
  {
    "text": "the next session oh um so you're talking about bringing down the deployment time",
    "start": "3308460",
    "end": "3315599"
  },
  {
    "text": "from that 10 hour nightmare to to getting you with an hour and part of that was the item potency where you were",
    "start": "3315599",
    "end": "3322380"
  },
  {
    "text": "able to roll it back um so I guess I don't have much of as much of a question as much as as I think",
    "start": "3322380",
    "end": "3329790"
  },
  {
    "text": "it is I'm dubious about that right like so if you have a chain right and you have some any cygnus",
    "start": "3329790",
    "end": "3335680"
  },
  {
    "text": "process going on maybe somebody's going on a cure or something I got you've had a change in a coat coming in and then",
    "start": "3335680",
    "end": "3341230"
  },
  {
    "text": "you're running the task you run it over on the new stuff and then you roll back the old stuff you may end up getting",
    "start": "3341230",
    "end": "3347830"
  },
  {
    "text": "unexpected data or or not data that expects it's not there so you're still",
    "start": "3347830",
    "end": "3353260"
  },
  {
    "text": "gonna gonna have to jump in there and do something do some recovery right I mean does that make sense yes understanding",
    "start": "3353260",
    "end": "3359470"
  },
  {
    "text": "something yeah I think I think I'm understanding it so the the rollback you",
    "start": "3359470",
    "end": "3365080"
  },
  {
    "text": "know is specific for a certain category of issues it won't cover every issue the issue that it's designed to capture is",
    "start": "3365080",
    "end": "3371620"
  },
  {
    "text": "when you go from an old am i to a new am i things look good when they're starting",
    "start": "3371620",
    "end": "3376630"
  },
  {
    "text": "to relocate but then perhaps after a few minutes you realize it's just not something that's not quite right with",
    "start": "3376630",
    "end": "3381970"
  },
  {
    "text": "the new way of mine maybe it's a new version of docker or something in that environments not quite right business",
    "start": "3381970",
    "end": "3387660"
  },
  {
    "text": "business rules change or logic change or anything like all right yeah that makes a lot more sense good yeah and then so",
    "start": "3387660",
    "end": "3393310"
  },
  {
    "text": "that being able to retreat back to unknown good is in most cases going and kind of satisfy the the problems that",
    "start": "3393310",
    "end": "3398590"
  },
  {
    "text": "you're trying to try to recover from you explained it really straightforward",
    "start": "3398590",
    "end": "3404980"
  },
  {
    "text": "thing I appreciate it okay thanks for the feedback that good question you open source primer hahaha a question comes up",
    "start": "3404980",
    "end": "3411940"
  },
  {
    "text": "a lot and I've heard a lot of companies have their own internal primer it has",
    "start": "3411940",
    "end": "3417160"
  },
  {
    "text": "been talked about internally but yeah I can't comment beyond that I don't I don't know yeah yeah",
    "start": "3417160",
    "end": "3425190"
  },
  {
    "text": "great well thanks for coming everybody enjoy",
    "start": "3427449",
    "end": "3432759"
  }
]
[
  {
    "start": "0",
    "end": "63000"
  },
  {
    "text": "good afternoon everyone uh my name is John inof I'm the senior product manager for Amazon elastic map produce the topic",
    "start": "1319",
    "end": "8480"
  },
  {
    "text": "of this session is the Hadoop ecosystem uh it's going to last about 50 minutes there will be three different speakers",
    "start": "8480",
    "end": "15200"
  },
  {
    "text": "uh myself uh Ted Dunning the Chief Architect from map R and Ronan Schwarz",
    "start": "15200",
    "end": "20560"
  },
  {
    "text": "from uh the the VP of product at Informatica uh we each have very different things to talk about but",
    "start": "20560",
    "end": "26000"
  },
  {
    "text": "they're all related to the Hadoop ecosystem uh we hope that this will be useful for all of you um for my piece",
    "start": "26000",
    "end": "32078"
  },
  {
    "text": "I'm going to talk for a few minutes about what is Amazon elastic map ruce I'll assume that you have a basic",
    "start": "32079",
    "end": "37800"
  },
  {
    "text": "understanding of what it is um given that this is a a 200 level uh session um",
    "start": "37800",
    "end": "43000"
  },
  {
    "text": "but I'll go over it at a high level and then we'll talk a little bit about the Hop ecosystem um as well as emrs role",
    "start": "43000",
    "end": "50199"
  },
  {
    "text": "within that ecosystem uh and then I'll let uh Ted and Ronin introduce their topics which I think are are very",
    "start": "50199",
    "end": "56079"
  },
  {
    "text": "interesting and again relate to the Hadoop ecosystem broadly",
    "start": "56079",
    "end": "61359"
  },
  {
    "text": "so first of all uh what is EMR so can I just see with a ra a raise of your hands",
    "start": "61359",
    "end": "67240"
  },
  {
    "start": "63000",
    "end": "63000"
  },
  {
    "text": "how many of you have have ever used Hadoop okay I'm hoping most people great",
    "start": "67240",
    "end": "72280"
  },
  {
    "text": "how many of you have launched an EMR cluster elastic map produced cluster show of hand so it looks like maybe a",
    "start": "72280",
    "end": "78360"
  },
  {
    "text": "third of the room or so um so EMR very high level is Hadoop running in the",
    "start": "78360",
    "end": "85280"
  },
  {
    "text": "Amazon Cloud um Hadoop is and this is probably all I'll say about about Hadoop",
    "start": "85280",
    "end": "91079"
  },
  {
    "text": "um is it's an open- Source platform for massive parallel processing across many many different machines um and and again",
    "start": "91079",
    "end": "99399"
  },
  {
    "text": "I think that there is an intro level uh EMR um course and I think they're going to repeat the session tomorrow so if",
    "start": "99399",
    "end": "104880"
  },
  {
    "text": "you're looking for more of the basics of what Hadoop is what map produce is I would strongly encourage you to check",
    "start": "104880",
    "end": "109960"
  },
  {
    "text": "out that session there's also information online on our website but for for our purposes just kind of think",
    "start": "109960",
    "end": "115880"
  },
  {
    "text": "of it as massive parallel processing across many many nodes and in our case those nodes are ec2 instances in the",
    "start": "115880",
    "end": "124640"
  },
  {
    "text": "cloud Amazon elastic map produce or EMR as it's commonly abbreviated is run in",
    "start": "124719",
    "end": "131200"
  },
  {
    "start": "125000",
    "end": "125000"
  },
  {
    "text": "many different Industries uh and has a wide variety of use cases so everything",
    "start": "131200",
    "end": "136440"
  },
  {
    "text": "from media companies and advertising companies optimizing their advertising Roi to retail companies like amazon.com",
    "start": "136440",
    "end": "143879"
  },
  {
    "text": "developing recommendations and personalization uh to financial services companies calculating risk to mobile",
    "start": "143879",
    "end": "151200"
  },
  {
    "text": "companies uh looking at user behavior on a on a mobile device um so we see a lot",
    "start": "151200",
    "end": "157000"
  },
  {
    "text": "of gaming and advertising and uh kind of mobile tablet applications we have thousands of",
    "start": "157000",
    "end": "163920"
  },
  {
    "text": "customers around the world uh we're also very uh well we we've run two million",
    "start": "163920",
    "end": "169280"
  },
  {
    "text": "clusters just in the last 12 months if you were at the keynote this morning you probably saw the exponential chart of",
    "start": "169280",
    "end": "174640"
  },
  {
    "text": "the number of EMR clusters that have been launched um we've been doing this for for a while now we start started in",
    "start": "174640",
    "end": "180720"
  },
  {
    "text": "2009 uh and as I said we're we're used by thousands of customers around the world these are just a this is a small",
    "start": "180720",
    "end": "186560"
  },
  {
    "text": "sampling of who runs their Hadoop jobs using EMR um and I'll just comment on one of them in particular",
    "start": "186560",
    "end": "193720"
  },
  {
    "text": "amazon.com um is actually a huge user of elastic map produce um there are",
    "start": "193720",
    "end": "199680"
  },
  {
    "text": "hundreds of teams all over the company that use EMR for everything from developing the recommendations that you",
    "start": "199680",
    "end": "205440"
  },
  {
    "text": "see when you go to amazon.com uh to figuring out the optimal routing of packages uh if you",
    "start": "205440",
    "end": "211560"
  },
  {
    "text": "think if you think about that problem it's a very complex problem and uh Hadoop can really um bear a lot of fruit",
    "start": "211560",
    "end": "217560"
  },
  {
    "text": "when you apply it to that that issue um also everything from identifying fraudulent buyers and sellers looking at",
    "start": "217560",
    "end": "224239"
  },
  {
    "text": "things that are happening in the warehouse um advertising Roi kind of you you whatever you can think of chances",
    "start": "224239",
    "end": "230159"
  },
  {
    "text": "are there's a team at Amazon that's using EMR for that purpose um which is really cool for us and um you know we",
    "start": "230159",
    "end": "235280"
  },
  {
    "text": "like to see that that internal usage so and and I'll do this at a very",
    "start": "235280",
    "end": "241000"
  },
  {
    "text": "high level because again this is a 200 level session but at a very high level uh customers and I'll describe one one",
    "start": "241000",
    "end": "248680"
  },
  {
    "text": "very common model here uh customers will put their data into S3 which is Amazon",
    "start": "248680",
    "end": "254280"
  },
  {
    "text": "simple storage service very cheap highly durable storage",
    "start": "254280",
    "end": "259840"
  },
  {
    "text": "um next they make some decisions so they decide which Hadoop distribution they want to run um and we provide a number",
    "start": "259840",
    "end": "267199"
  },
  {
    "text": "of options you can run map rm3 you can run map RM 5 there's an Amazon distribution uh and the Amazon",
    "start": "267199",
    "end": "272680"
  },
  {
    "text": "distribution by the way is is basically aache Hadoop that has been extended and modified to make it work really well in",
    "start": "272680",
    "end": "278680"
  },
  {
    "text": "the cloud but you so you decide what what which distribution you want to run you choose how many nodes you want to",
    "start": "278680",
    "end": "285120"
  },
  {
    "text": "have in your cluster so it could be everything from two or three nodes which we see a lot of to hundreds or even",
    "start": "285120",
    "end": "290360"
  },
  {
    "text": "thousands of nodes and we see a lot of those as well um in addition to the number of nodes you also choose what",
    "start": "290360",
    "end": "296479"
  },
  {
    "text": "types of nodes so if you're familiar with ec2 which I assume most of you guys are already um we have different",
    "start": "296479",
    "end": "303080"
  },
  {
    "text": "families of instances some of them are high CPU some are high memory um some are optimized for for for dis some are",
    "start": "303080",
    "end": "310240"
  },
  {
    "text": "better for for networking um it's really kind of application dependent and based on what your needs are you would choose",
    "start": "310240",
    "end": "316160"
  },
  {
    "text": "what instance you want to have as one of your your cluster nodes um in addition to that you have you have root access",
    "start": "316160",
    "end": "323520"
  },
  {
    "text": "and you can make configuration changes change settings like the Java Heap size and kind of whatever you need to do to",
    "start": "323520",
    "end": "329720"
  },
  {
    "text": "optimize and control and make uh make changes to your cluster um you would make those decisions upfront but you",
    "start": "329720",
    "end": "335560"
  },
  {
    "text": "could also change it later on um and then in addition you would make decisions about what other Technologies",
    "start": "335560",
    "end": "340639"
  },
  {
    "text": "you want to install as part of your EMR cluster so for example do you want to",
    "start": "340639",
    "end": "345759"
  },
  {
    "text": "install and run Hive do you want to run Pig do you want to run hbas uh and we make we you have to make that decision",
    "start": "345759",
    "end": "351319"
  },
  {
    "text": "and we make it very easy to once you've made the decision install and run those Services once you've made all of those",
    "start": "351319",
    "end": "358240"
  },
  {
    "text": "decisions you go to the EMR service and you launch your cluster uh and you have",
    "start": "358240",
    "end": "363960"
  },
  {
    "text": "a variety of tools that you can use to launch your cluster you can use our web guei that we call our Management console",
    "start": "363960",
    "end": "370639"
  },
  {
    "text": "uh you can use the command line interface we have a ruby CLI that you can use um we also have a variety of",
    "start": "370639",
    "end": "376039"
  },
  {
    "text": "sdks and API so it's sort of up to you what you're most comfortable with uh we provide a variety of of options for",
    "start": "376039",
    "end": "382039"
  },
  {
    "text": "actually launching and managing your clusters so so now you've kind of you've put your data in S3 you've made some",
    "start": "382039",
    "end": "388960"
  },
  {
    "text": "decisions about what you want to do with the data um you've launched your cluster using the EMR service the EMR service",
    "start": "388960",
    "end": "396400"
  },
  {
    "text": "starts to provision ec2 instances we install Hadoop we install our patches um",
    "start": "396400",
    "end": "401560"
  },
  {
    "text": "other techn other software that you want to install um and uh so we we get the",
    "start": "401560",
    "end": "407520"
  },
  {
    "text": "cluster going the cluster will start pulling that data in from S3 it will start processing it when the data when",
    "start": "407520",
    "end": "412880"
  },
  {
    "text": "the processing is complete the output is sent back to S3 where you can pick it up",
    "start": "412880",
    "end": "419639"
  },
  {
    "text": "now that's one model uh for what customers will will do with EMR there's another very common model which is they",
    "start": "419639",
    "end": "425599"
  },
  {
    "text": "skip S3 uh and they put all of the data on hdfs and they leave it there they",
    "start": "425599",
    "end": "430960"
  },
  {
    "text": "keep the cluster up all the time um and and that's an option for you and actually we have some customers that do",
    "start": "430960",
    "end": "436560"
  },
  {
    "text": "both for some jobs they will put the data in S3 they'll spin up their cluster do the processing shut the cluster down",
    "start": "436560",
    "end": "442039"
  },
  {
    "text": "you stop paying for it we have other customers who uh want to have and Netflix is an example of this where you",
    "start": "442039",
    "end": "447440"
  },
  {
    "text": "have a several hundred node cluster and they keep it up all the time and they keep their data in hdfs and they're continuously scanning against",
    "start": "447440",
    "end": "454199"
  },
  {
    "text": "it um and actually customers like Netflix actually do both some some clusters they keep up and they use htfs",
    "start": "454199",
    "end": "459599"
  },
  {
    "text": "others they keep it in S3 um spin up clusters and shut them down it's really up to",
    "start": "459599",
    "end": "465400"
  },
  {
    "text": "you now one of the things that you can do with elastic map produce and generally when you're one of the cool things about doing Hadoop in the cloud",
    "start": "465400",
    "end": "471960"
  },
  {
    "text": "is that you can scale your cluster so let's say you have an application um and you need normally about 100 nodes to do",
    "start": "471960",
    "end": "479080"
  },
  {
    "text": "your process procing steady state um but and maybe that's for kind of to process 24 hours of data but let's say now you",
    "start": "479080",
    "end": "485960"
  },
  {
    "text": "have to process a month worth of data or a Year's worth of data you don't want to use that same 100 node cluster you can",
    "start": "485960",
    "end": "491360"
  },
  {
    "text": "take that cluster and you can almost instantly scale it and then when you're done you scale it back down and of",
    "start": "491360",
    "end": "496840"
  },
  {
    "text": "course with the cloud you only paid for what you used um it's as simple here as",
    "start": "496840",
    "end": "501919"
  },
  {
    "text": "a a very quick command line uh argument and by the way when you're rescaling",
    "start": "501919",
    "end": "507840"
  },
  {
    "text": "your cluster one of the very very powerful things about EMR and I hope that you guys are thinking about this if",
    "start": "507840",
    "end": "513560"
  },
  {
    "text": "you're using EMR is you can use spot nodes for this so if you're familiar with spot you know that it's you're",
    "start": "513560",
    "end": "518919"
  },
  {
    "text": "basically bidding on unused ec2 capacity you're oftentimes paying Pennies on the dollar for those notes so imagine going",
    "start": "518919",
    "end": "525959"
  },
  {
    "text": "back to that scenario where you've got your 100 node cluster um and you want to scale it up to 500 nodes well you could",
    "start": "525959",
    "end": "532160"
  },
  {
    "text": "those 400 nodes that you want to add in those could be spot nodes um and that's a way of speeding up your job",
    "start": "532160",
    "end": "537480"
  },
  {
    "text": "dramatically but also dramatically lowering your costs because you're again you're only paying Pennies on the dollar",
    "start": "537480",
    "end": "543160"
  },
  {
    "text": "um many of our customers are using spot but many are actually still not aware that that's a possibility so I would",
    "start": "543160",
    "end": "548440"
  },
  {
    "text": "definitely encourage you to think about that if you are yourselves running EMR now when you're done with the",
    "start": "548440",
    "end": "554320"
  },
  {
    "text": "processing you can shut the cluster down that's one of the really really cool things about EMR uh and of course once",
    "start": "554320",
    "end": "559920"
  },
  {
    "text": "the cluster is shut down you stop paying for it um but going back to what I was saying earlier that's one model a lot of",
    "start": "559920",
    "end": "566920"
  },
  {
    "text": "customers spin up their clusters they do their processing and then they shut it down many other customers keep their",
    "start": "566920",
    "end": "572640"
  },
  {
    "text": "cluster up all the time and again they store the data in hdfs and it's it's always there and then there are some",
    "start": "572640",
    "end": "578040"
  },
  {
    "text": "customers that that do both they have both models so at a high level what we're",
    "start": "578040",
    "end": "585160"
  },
  {
    "start": "583000",
    "end": "583000"
  },
  {
    "text": "trying to do with this service is provide you options uh options and control so you it is up to you to decide",
    "start": "585160",
    "end": "592519"
  },
  {
    "text": "how many nodes you want in your cluster what types of nodes do you want High CPU do you want High memory um do you",
    "start": "592519",
    "end": "599880"
  },
  {
    "text": "you want to have like a small cluster now and resize it or do you want to have many small clusters it's completely up to you um we let you choose and you know",
    "start": "599880",
    "end": "607600"
  },
  {
    "text": "we encourage you to choose which distribution is best for your options um map bar has done some really great work to make to do uh very Enterprise ready",
    "start": "607600",
    "end": "615079"
  },
  {
    "text": "and there's some really cool features in the map bar distributions and we're really excited that that's an option for uh our customers when they come to our",
    "start": "615079",
    "end": "621320"
  },
  {
    "text": "service um you also have a choice of Hadoop components so I mentioned earlier",
    "start": "621320",
    "end": "626720"
  },
  {
    "text": "you could uh very easily install and run High you could run Pig you could run hpas uh",
    "start": "626720",
    "end": "632519"
  },
  {
    "text": "and there's a variety of other things that you could run with Hadoop um so although our name is map R we're really",
    "start": "632519",
    "end": "638200"
  },
  {
    "text": "about enabling much more than that we're trying to make it really easy to use all of these other Hadoop components that",
    "start": "638200",
    "end": "644480"
  },
  {
    "text": "are part of the Hadoop ecosystem um so we're trying and we're trying to make that as easy as possible we also want",
    "start": "644480",
    "end": "651240"
  },
  {
    "text": "you to have a choice of tools so there's a we we provide the the obbc and jdbc",
    "start": "651240",
    "end": "657079"
  },
  {
    "text": "drivers and we we provide integration with a wide variety of non-amazon tools so if you have a bi tool that you like",
    "start": "657079",
    "end": "664000"
  },
  {
    "text": "or you have a visualization tool that you like uh as long as it works with a Pache Hadoop it will work with elastic",
    "start": "664000",
    "end": "669839"
  },
  {
    "text": "map ruce um and finally we have a concept called bootstrap actions which is a little bit different it's something",
    "start": "669839",
    "end": "675600"
  },
  {
    "text": "that we invented um and the idea of this is that you write a script uh you store",
    "start": "675600",
    "end": "681760"
  },
  {
    "text": "that script in S3 and this the script essentially has instructions for installing or running uh anything you",
    "start": "681760",
    "end": "688240"
  },
  {
    "text": "want basically so you could use that to install additional software you could use it to change some of the Hadoop default settings um basically it's",
    "start": "688240",
    "end": "695560"
  },
  {
    "text": "anything you want when the EMR service launches the cluster we will ask you for",
    "start": "695560",
    "end": "701480"
  },
  {
    "text": "uh the location of the script if you want to provide one and when we're when we're provisioning the instances uh",
    "start": "701480",
    "end": "706839"
  },
  {
    "text": "we'll grab the script execute the instructions and we'll do that before Hadoop starts running so through the",
    "start": "706839",
    "end": "712279"
  },
  {
    "text": "bootstrap action and you can use multiple bootstrap actions you have really complete control over everything",
    "start": "712279",
    "end": "718040"
  },
  {
    "text": "that's going on in your cluster um so again it's about options and it's about",
    "start": "718040",
    "end": "724480"
  },
  {
    "text": "control now let's talk a little bit about the Hadoop ecosystem so core Hadoop really consists of in my view two",
    "start": "724480",
    "end": "731720"
  },
  {
    "start": "725000",
    "end": "725000"
  },
  {
    "text": "things there's map reduce and there's hdfs so hdfs uh and again I'm going to go through through this at a fairly high",
    "start": "731720",
    "end": "737839"
  },
  {
    "text": "level so I hope that that that that's okay for this group hdfs is the Hadoop distributed file system map ruce is the",
    "start": "737839",
    "end": "744279"
  },
  {
    "text": "computational model within Hadoop uh when you pair the two together that's where you really get the power of this",
    "start": "744279",
    "end": "750560"
  },
  {
    "text": "parallel processing where you can take a job and get it done much faster and um you you really see the power of Big Data",
    "start": "750560",
    "end": "757560"
  },
  {
    "text": "um that's that's kind of where it started but over time a variety of other tools and technologies have been added",
    "start": "757560",
    "end": "763279"
  },
  {
    "text": "to the ecosystem that for example make it easier to get your data into Hadoop",
    "start": "763279",
    "end": "768839"
  },
  {
    "text": "that make it easier to connect your Hadoop cluster with a relational database um we do you see some of the",
    "start": "768839",
    "end": "775480"
  },
  {
    "text": "some of the logos up here help with serialization and deserialization um monitoring of your cluster so if you",
    "start": "775480",
    "end": "781360"
  },
  {
    "text": "think about over time these the the number of tools and Technologies available to you in the ecosystem has",
    "start": "781360",
    "end": "787040"
  },
  {
    "text": "really grown explosively and we're very excited about that growth um and you're only really on this slide you're only",
    "start": "787040",
    "end": "793920"
  },
  {
    "text": "seeing a small slice of the the tools and technologies that are now part of this ecosystem I think really broadly",
    "start": "793920",
    "end": "800760"
  },
  {
    "text": "defined the Hadoop ecosystem is what you're seeing on the screen here but it's also all of the non-open source",
    "start": "800760",
    "end": "807440"
  },
  {
    "text": "tools and technologies that are out there it's the open- source tools that are not officially related to Apache",
    "start": "807440",
    "end": "812760"
  },
  {
    "text": "Hadoop um that people are starting to use with Hadoop like R um and it's really it's a very exciting space it's",
    "start": "812760",
    "end": "819480"
  },
  {
    "text": "growing very rapidly um and we're very excited to see that and uh you're going to hear in a moment from Ted and Ronin",
    "start": "819480",
    "end": "826480"
  },
  {
    "text": "they're going to talk to you about some of these some of the other tools and technologies that are part of this ecosystem for last the thing I'll say",
    "start": "826480",
    "end": "833720"
  },
  {
    "text": "about from the elastic map produce perspective is we want to make it really easy for you to run these tools uh and",
    "start": "833720",
    "end": "840279"
  },
  {
    "text": "to experiment with things as they come out a lot of the tools that are out there are very new some of them are",
    "start": "840279",
    "end": "845399"
  },
  {
    "text": "relatively immature right now but we want you to be able to experiment cheaply and quickly with them so to that",
    "start": "845399",
    "end": "851800"
  },
  {
    "text": "I want to show you some examples of uh some of these tools in particular and how you would actually run them with",
    "start": "851800",
    "end": "857279"
  },
  {
    "text": "elastic Ma prodes so Hive is probably one of the",
    "start": "857279",
    "end": "863079"
  },
  {
    "start": "860000",
    "end": "860000"
  },
  {
    "text": "oldest technologies that complement Hadoop it is essentially a data warehouse for Hadoop it Prov provides a",
    "start": "863079",
    "end": "869560"
  },
  {
    "text": "SQL like query language that if you're familiar with SQL you'll you're probably",
    "start": "869560",
    "end": "874920"
  },
  {
    "text": "you'll probably find hiveql pretty familiar there's some Nuance differences but generally they're very similar uh",
    "start": "874920",
    "end": "881720"
  },
  {
    "text": "and we find many many customers using Hive um pig is another one that is patchy Pig",
    "start": "881720",
    "end": "888199"
  },
  {
    "text": "this is a very very commonly used uh programming language it's really great for ETL and data flow type processing um",
    "start": "888199",
    "end": "897079"
  },
  {
    "text": "it supports userdefined functions so so there's it's quite flexible and extensible um I would say of all of the",
    "start": "897079",
    "end": "903480"
  },
  {
    "text": "Hadoop ecosystem components these are the two that are probably the most popular the most common the most tried",
    "start": "903480",
    "end": "909000"
  },
  {
    "text": "if you're not using one or both of these today I would definitely encourage you to to to check them",
    "start": "909000",
    "end": "914720"
  },
  {
    "text": "out uh and uh by the way both of these are available as an option in a drop-",
    "start": "914720",
    "end": "920440"
  },
  {
    "text": "down box when you're launching your EMR cluster so there's you don't need to worry about getting the getting the code",
    "start": "920440",
    "end": "926440"
  },
  {
    "text": "and installing it and configuring it you literally if you're using the web guey you select Hive in the dropdown or if",
    "start": "926440",
    "end": "932480"
  },
  {
    "text": "you're launching your cluster from the command line it's an additional argument uh again very very",
    "start": "932480",
    "end": "939560"
  },
  {
    "text": "simple um so that's Hive and pig hbas is a column oriented database that's really",
    "start": "939560",
    "end": "945319"
  },
  {
    "text": "ideal for when you have billions of rows millions of columns it provides random",
    "start": "945319",
    "end": "950600"
  },
  {
    "text": "uh read write access and it's really great for sparse data so in particular where where I see customers using hbas",
    "start": "950600",
    "end": "957079"
  },
  {
    "text": "is for analytics applications um but there you know there's a wide variety of use cases if you're not",
    "start": "957079",
    "end": "963360"
  },
  {
    "text": "familiar with hbas um I think this is also something that you should you should probably check",
    "start": "963360",
    "end": "968800"
  },
  {
    "text": "out mahout is a machine learning library for Hadoop um it comes pre-installed on",
    "start": "968800",
    "end": "975480"
  },
  {
    "text": "your cluster so again there's nothing to install it's right there ready for you to use um it's it's especially good for",
    "start": "975480",
    "end": "982360"
  },
  {
    "text": "things like recommendations um item classifications things like that um if you're looking at machine learning this",
    "start": "982360",
    "end": "988519"
  },
  {
    "text": "would be a good thing to for you to to to evaluate now in addition there there's a",
    "start": "988519",
    "end": "995319"
  },
  {
    "start": "993000",
    "end": "993000"
  },
  {
    "text": "wide variety of other tools and technologies that we try to enable and try to make really simple to run with EMR uh one of them is ganglia so ganglia",
    "start": "995319",
    "end": "1002639"
  },
  {
    "text": "is used to do monitoring uh of your cluster so you can look at cluster level information node level information um",
    "start": "1002639",
    "end": "1010040"
  },
  {
    "text": "and the way you run ganglia with elastic map ruce is you install it through a bootstrap action so that's the script",
    "start": "1010040",
    "end": "1016399"
  },
  {
    "text": "that I was talking about earlier uh and we provide the script you don't have to write anything all you have to do when you",
    "start": "1016399",
    "end": "1021920"
  },
  {
    "text": "launch the cluster is specify the location of the script that we give you and we will do all the work for",
    "start": "1021920",
    "end": "1028720"
  },
  {
    "text": "you R is something that we're starting to see more and more commonly used with Hadoop um I think probably most people",
    "start": "1028720",
    "end": "1035678"
  },
  {
    "text": "in the room are familiar with this as the very very powerful um language and",
    "start": "1035679",
    "end": "1040798"
  },
  {
    "text": "software environment for essentially statistical Computing um very very",
    "start": "1040799",
    "end": "1046760"
  },
  {
    "text": "powerful especially when you do it in conjunction with Hadoop so we see some customers using it for example to do",
    "start": "1046760",
    "end": "1052080"
  },
  {
    "text": "stochastic modeling um on Hadoop very very cool we're very excited about that um the last stable version of R um is is",
    "start": "1052080",
    "end": "1062120"
  },
  {
    "text": "light like mahout available on the cluster pre-installed you don't need to worry about having to install",
    "start": "1062120",
    "end": "1068080"
  },
  {
    "text": "it so now uh I'm just going to talk I'm going to give you a few examples of what it looks like to actually use these",
    "start": "1068080",
    "end": "1074799"
  },
  {
    "start": "1069000",
    "end": "1069000"
  },
  {
    "text": "Technologies um just to give you a flavor for you know what it takes to Launch them so if you wanted to launch a",
    "start": "1074799",
    "end": "1080960"
  },
  {
    "text": "Hadoop cluster from the command line interface you would write elastic map ruce D- create that's actually all you",
    "start": "1080960",
    "end": "1088159"
  },
  {
    "text": "need I've added some additional arguments here just to give you a flavor for other things you can do from the command line um these these other",
    "start": "1088159",
    "end": "1095039"
  },
  {
    "text": "arguments here dash dash alive means that the cluster will stay up even after the job is finished processing um and",
    "start": "1095039",
    "end": "1101799"
  },
  {
    "text": "you can see here that we're specifying that we want five nodes and we want those nodes to be m1x large that's",
    "start": "1101799",
    "end": "1107720"
  },
  {
    "text": "basically our standard instance family um it's the the largest in that family I think it comes with about 1 and a half",
    "start": "1107720",
    "end": "1114400"
  },
  {
    "text": "terabytes of local dis um and and as I mentioned earlier there's a wide variety",
    "start": "1114400",
    "end": "1119679"
  },
  {
    "text": "of instance types and you would need to to choose ahead of time what you want to run so that's a standard Hadoop",
    "start": "1119679",
    "end": "1126000"
  },
  {
    "text": "cluster um so what does it take to launch a hive cluster so and again here I've added some additional uh optional",
    "start": "1126000",
    "end": "1132919"
  },
  {
    "start": "1127000",
    "end": "1127000"
  },
  {
    "text": "arguments but you basically are writing elastic map produce-- create um you can",
    "start": "1132919",
    "end": "1138080"
  },
  {
    "text": "see here we're specifying a Hadoop version we're specifying how many nodes what type of node um we're specifying",
    "start": "1138080",
    "end": "1145120"
  },
  {
    "text": "The Hive version um so hopefully you would agree with me it's it's pretty simple to launch a hive cluster um and",
    "start": "1145120",
    "end": "1151880"
  },
  {
    "text": "we provide you the the ability to choose all of these things like how many nodes and which version of Hive things like",
    "start": "1151880",
    "end": "1157799"
  },
  {
    "text": "that so that's Hive what about H Bas so once again elastic map produce-- create",
    "start": "1157799",
    "end": "1164159"
  },
  {
    "text": "and the difference here is d-h BAS that's all you need uh here we're naming",
    "start": "1164159",
    "end": "1169640"
  },
  {
    "text": "the h-based cluster we're saying how many nodes and we're giving it the cc28 extra large that is one of our cluster",
    "start": "1169640",
    "end": "1176400"
  },
  {
    "text": "compute instance types um and you know again depending on your application that may be the right instance for you but",
    "start": "1176400",
    "end": "1182600"
  },
  {
    "text": "you could run on any of the other instance types as well all right what about ganglia so",
    "start": "1182600",
    "end": "1188559"
  },
  {
    "start": "1187000",
    "end": "1187000"
  },
  {
    "text": "this is one where you install it through a bootstrap action so what that looks like is elastic map produce-- create and",
    "start": "1188559",
    "end": "1195320"
  },
  {
    "text": "then bootstrap action and then you can see here this is the location of the bootstrap action in S3 and we",
    "start": "1195320",
    "end": "1201960"
  },
  {
    "text": "have written it for you you just need to specify this at launch uh and what EMR will do is it will go to that location",
    "start": "1201960",
    "end": "1207919"
  },
  {
    "text": "in S3 it will pull the script execute it and it will do all of that before Hadoop starts working starts",
    "start": "1207919",
    "end": "1215200"
  },
  {
    "text": "running and finally uh so the last few examples were from the command line interface the other another very common",
    "start": "1215720",
    "end": "1222679"
  },
  {
    "start": "1216000",
    "end": "1216000"
  },
  {
    "text": "model is customers like to use the the Management console so what we're looking at here is the wizard for launching a",
    "start": "1222679",
    "end": "1229400"
  },
  {
    "text": "new job flow there are five screens so the on the first screen here you're",
    "start": "1229400",
    "end": "1234559"
  },
  {
    "text": "specifying the name of your job flow you choose which Hadoop distribution you want to run and then here we're we're",
    "start": "1234559",
    "end": "1241960"
  },
  {
    "text": "selecting Hive from the dropdown so fairly simple if you wanted to run um a",
    "start": "1241960",
    "end": "1247480"
  },
  {
    "text": "custom jar if you wanted to run hbas you would just select the appropriate option here that's the first screen on the",
    "start": "1247480",
    "end": "1254240"
  },
  {
    "text": "second screen uh and and in this example what we're running is a hive uh cluster or cluster running Hive so on",
    "start": "1254240",
    "end": "1262120"
  },
  {
    "text": "the next screen what we're selecting here is that we want to execute the script rather than uh launching the",
    "start": "1262120",
    "end": "1267919"
  },
  {
    "text": "cluster and keeping it open for an interactive session uh and then what you're seeing in the options here is where what is the location of your HIV",
    "start": "1267919",
    "end": "1274200"
  },
  {
    "text": "script where is the data the input data where do you want EMR to put the the",
    "start": "1274200",
    "end": "1279320"
  },
  {
    "text": "output data and do you have any extra arguments uh that you want to that you",
    "start": "1279320",
    "end": "1284720"
  },
  {
    "text": "want to pass in on the next screen this is where you choose the number and types of instances that you want to run um we",
    "start": "1284720",
    "end": "1292320"
  },
  {
    "text": "have three different types of instances or three different types of nodes in your Hadoop cluster there's the master node there is a group of core nodes and",
    "start": "1292320",
    "end": "1300080"
  },
  {
    "text": "then there's a group of task nodes the difference between core and task is that uh task does not include hdfs it's",
    "start": "1300080",
    "end": "1307559"
  },
  {
    "text": "purely to help with the computation it speeds up the processing uh there is hdfs data on the core group and here",
    "start": "1307559",
    "end": "1314480"
  },
  {
    "text": "what we're selecting is what instance type the number and here is where you would actually specify uh do you want to",
    "start": "1314480",
    "end": "1320640"
  },
  {
    "text": "use spot the next screen is Advanced options",
    "start": "1320640",
    "end": "1325840"
  },
  {
    "text": "so if you're an amaz if you're an AWS customer of vc2 you probably already have a key pair you could specify the",
    "start": "1325840",
    "end": "1332000"
  },
  {
    "text": "name of your key pair here if you wanted to SSH into the master node which can be very useful um if you want to persist",
    "start": "1332000",
    "end": "1338000"
  },
  {
    "text": "your logs to S3 for debugging purposes if you want to keep the cluster alive or not there's sort of a variety of uh",
    "start": "1338000",
    "end": "1344720"
  },
  {
    "text": "Advanced options here for you and then finally this is where you would specify the location of a bootstrap script or",
    "start": "1344720",
    "end": "1351720"
  },
  {
    "text": "bootstrap action that you want us to run so if we had selected this radio button it would basically just ask you for um",
    "start": "1351720",
    "end": "1358360"
  },
  {
    "text": "the location of that script uh then you hit next and your cluster will start launching and that's the same for if",
    "start": "1358360",
    "end": "1364640"
  },
  {
    "text": "you're launching a two node cluster or if you're launching 2,000 nodes um it the the cluster will launch and then",
    "start": "1364640",
    "end": "1370120"
  },
  {
    "text": "you'll be brought to our management dashboard where you'll have information on each of your clusters the health how",
    "start": "1370120",
    "end": "1375360"
  },
  {
    "text": "long it's been running um things like that and uh if it's all right with the group",
    "start": "1375360",
    "end": "1381559"
  },
  {
    "start": "1381000",
    "end": "1381000"
  },
  {
    "text": "we're going to take questions at the end I think that we probably will have time so if you could just save that um last thing I'll go through this very quickly",
    "start": "1381559",
    "end": "1387640"
  },
  {
    "text": "and then I want to hand over the the uh the the mic high level key benefits of using",
    "start": "1387640",
    "end": "1393520"
  },
  {
    "text": "elastic map produce it's very easy to get started you can literally launch your first cluster in less than a minute",
    "start": "1393520",
    "end": "1399480"
  },
  {
    "text": "um it's particularly easy if you're already an AWS Customer because you already have a key pair you know you're",
    "start": "1399480",
    "end": "1404720"
  },
  {
    "text": "kind of already set it's easy to scale up and down you can go from two nodes to 2,000 nodes in",
    "start": "1404720",
    "end": "1411279"
  },
  {
    "text": "minutes you only pay for what you use so there's very little risk that you're going to spend money on all of this",
    "start": "1411279",
    "end": "1416880"
  },
  {
    "text": "infrastructure up front and then decide a few months later that you kind of made the wrong decision and and there's you",
    "start": "1416880",
    "end": "1422360"
  },
  {
    "text": "know some sort of a of a problem uh you can launch parallel clusters uh that are",
    "start": "1422360",
    "end": "1428039"
  },
  {
    "text": "pointing at the same data so Netflix does this for example where they have their data in3 and they launch multiple",
    "start": "1428039",
    "end": "1433760"
  },
  {
    "text": "parallel clusters um each pointing at and using the same data they'll have one cluster for their production systems one",
    "start": "1433760",
    "end": "1439840"
  },
  {
    "text": "for their analysts for their their um people that are look doing queries like which videos are the most common right",
    "start": "1439840",
    "end": "1445760"
  },
  {
    "text": "now which videos kind of have the highest latency issues um maybe another cluster where they're doing kind of ad",
    "start": "1445760",
    "end": "1451320"
  },
  {
    "text": "hoc analyses um the ability to launch these parallel clusters is one of the key reasons why Netflix loves running on",
    "start": "1451320",
    "end": "1457520"
  },
  {
    "text": "elastic map produce if your needs change and I was talking about this a moment ago it it's",
    "start": "1457520",
    "end": "1463039"
  },
  {
    "text": "very easy to change you can you can shut down the cluster you can start a new one you can change the size the node type",
    "start": "1463039",
    "end": "1468159"
  },
  {
    "text": "the new version it's really simple to do that we integrate with Dynamo DB uh ec2",
    "start": "1468159",
    "end": "1475720"
  },
  {
    "text": "S3 um VPC cloudwatch so if you're familiar with those Services if you're using them you'll find that there's very",
    "start": "1475720",
    "end": "1481240"
  },
  {
    "text": "uh very seamless connectivity and integration between us and their services uh because we give you root",
    "start": "1481240",
    "end": "1487080"
  },
  {
    "text": "access and boot strip actions it means that you are in complete control of your cluster so if you want it you can tune",
    "start": "1487080",
    "end": "1493080"
  },
  {
    "text": "it and optimize it uh and do whatever you need to do to make it s for you we provide you that ability and finally",
    "start": "1493080",
    "end": "1499960"
  },
  {
    "text": "what we're trying to do at the core is we're trying to make it so that you don't need to worry about launching and",
    "start": "1499960",
    "end": "1505600"
  },
  {
    "text": "managing configuring uh Hadoop we know that that's complicated that's hard work and",
    "start": "1505600",
    "end": "1511720"
  },
  {
    "text": "it's frankly not probably part of the the core value that you can bring in your business what you really want to do",
    "start": "1511720",
    "end": "1517520"
  },
  {
    "text": "I'm guessing is get value out of your data uh and so we want to take that",
    "start": "1517520",
    "end": "1522960"
  },
  {
    "text": "heavy lifting off your shoulders and make it as simple and as easy to do as possible",
    "start": "1522960",
    "end": "1528480"
  },
  {
    "text": "so that's elastic map produce um I'd like to introduce Ronan Schwarz he's a VP of product at Informatica uh he's",
    "start": "1528480",
    "end": "1534799"
  },
  {
    "text": "going to talk to you a little bit about H parser and some other very interesting things so if you could please welcome uh",
    "start": "1534799",
    "end": "1541880"
  },
  {
    "text": "Ronan thank you everybody and I'm really glad to be here um my first question to",
    "start": "1544640",
    "end": "1549679"
  },
  {
    "text": "you is how many of you are familiar with Informatica maybe I can see a okay have",
    "start": "1549679",
    "end": "1554720"
  },
  {
    "text": "maybe about a third of that so Informatica has been the pioneer of an area called ETL extract transform and",
    "start": "1554720",
    "end": "1562480"
  },
  {
    "text": "load that uh later on have been um developed into what is called today data",
    "start": "1562480",
    "end": "1567679"
  },
  {
    "start": "1564000",
    "end": "1564000"
  },
  {
    "text": "integration if you're asking analysts large customers um and and small customers as well Informatica is pretty",
    "start": "1567679",
    "end": "1574120"
  },
  {
    "text": "much there at the edge of the of the of of a very key technology that is uh",
    "start": "1574120",
    "end": "1579799"
  },
  {
    "text": "bringing data into the data warehousing bringing data into analytics making data",
    "start": "1579799",
    "end": "1584919"
  },
  {
    "text": "available U between applications um I'm very lucky to be here in front of you today because it seems like data",
    "start": "1584919",
    "end": "1591120"
  },
  {
    "text": "warehousing is getting to be more relevant for this community than ever before Informatica is key technology in",
    "start": "1591120",
    "end": "1597399"
  },
  {
    "text": "enabling in enabling that while Informatica started as a Pioneer in the ETL space one of the areas of growth was",
    "start": "1597399",
    "end": "1604080"
  },
  {
    "text": "we've supplying a lot of services around the data integration that are critical to bring the data in the right way so",
    "start": "1604080",
    "end": "1610320"
  },
  {
    "text": "that you can actually leverage it afterwards in application analytics things like data transformation how do I",
    "start": "1610320",
    "end": "1615520"
  },
  {
    "text": "take files into a into a structure uh things like exchanging data bringing data from external sources masking",
    "start": "1615520",
    "end": "1623000"
  },
  {
    "text": "quality MDM and so on this is kind of building the Informatica platform and",
    "start": "1623000",
    "end": "1628159"
  },
  {
    "text": "I'm really U pleased to to share with you that about 12 months ago we have started bringing this technology to be",
    "start": "1628159",
    "end": "1634360"
  },
  {
    "text": "fully available on EMR um and what I'm here to share with you today is how one of these Technologies H parser is",
    "start": "1634360",
    "end": "1641520"
  },
  {
    "text": "working on on a dup in general and specifically optimized to work on elastic map",
    "start": "1641520",
    "end": "1647159"
  },
  {
    "text": "reduce so if we're looking into the Ado uh problem in a very very simplistic way",
    "start": "1647159",
    "end": "1652559"
  },
  {
    "text": "we can look at it as a source u a map and reduce actions and then a Target and",
    "start": "1652559",
    "end": "1658320"
  },
  {
    "text": "the source can be on hdfs it can be on S3 but it's basically there is a source there is a Target and then a map produce",
    "start": "1658320",
    "end": "1664519"
  },
  {
    "text": "set of actions um when a lot of this technology was developed the sources were extremely simple mainly Apache logs",
    "start": "1664519",
    "end": "1671640"
  },
  {
    "text": "or logs in general very flattened in at least in the initial look into them but",
    "start": "1671640",
    "end": "1678320"
  },
  {
    "text": "of the real world data um is more complex than that it's",
    "start": "1678320",
    "end": "1683480"
  },
  {
    "text": "not actually clear where does the record start where does the record end how to define it how to translate the data the",
    "start": "1683480",
    "end": "1689320"
  },
  {
    "text": "data is binary not necessarily textual um this real world this real problem is",
    "start": "1689320",
    "end": "1695240"
  },
  {
    "text": "sometimes underestimate and uh when um um when I thought about which example",
    "start": "1695240",
    "end": "1700600"
  },
  {
    "text": "should I share with you I I had a bunch of examples but um those of you that was were on the lunch uh um on the lunch",
    "start": "1700600",
    "end": "1707600"
  },
  {
    "text": "area you you saw how hard it is to parallel five or 6 thousand people getting into one lunch area right even",
    "start": "1707600",
    "end": "1713159"
  },
  {
    "text": "though they had all of these different stations we still had a bottleneck and sometimes this bottleneck if you're",
    "start": "1713159",
    "end": "1718480"
  },
  {
    "text": "doing map reduce is actually in how to take the real life data and make it available to be paralyzed how do you",
    "start": "1718480",
    "end": "1724640"
  },
  {
    "text": "flatten it so that then the mean reduce is becoming effective this is where H parser is uh is playing a role and it's",
    "start": "1724640",
    "end": "1731480"
  },
  {
    "text": "giving you a few things doing that it is actually giving you a visual environment",
    "start": "1731480",
    "end": "1736799"
  },
  {
    "text": "to Define how to leten this data um it is supporting any format not just a",
    "start": "1736799",
    "end": "1742279"
  },
  {
    "text": "textual format it supports things like uh XML Json it supports things like Word",
    "start": "1742279",
    "end": "1748240"
  },
  {
    "text": "documents and PDF Excel files it does support industry standards and uh and it",
    "start": "1748240",
    "end": "1754120"
  },
  {
    "text": "does Support also the logs and the from a variety of formats so supporting any format",
    "start": "1754120",
    "end": "1761279"
  },
  {
    "text": "supporting complexity in the in the format but also in the data structure and easily embeddable inside your proc",
    "start": "1761279",
    "end": "1768279"
  },
  {
    "text": "process uh because it is becoming an natural map reduce step um available on",
    "start": "1768279",
    "end": "1774240"
  },
  {
    "text": "EMR if we're looking into the design environment it is um um it's basically",
    "start": "1774240",
    "end": "1779679"
  },
  {
    "text": "include a few a few components uh we're allowing you to develop the transformation or the rules how to flatten the data while you're looking",
    "start": "1779679",
    "end": "1786240"
  },
  {
    "text": "into a sample data so what you see on the right side of the screen is a sample of the data and then in a simple drag",
    "start": "1786240",
    "end": "1793039"
  },
  {
    "text": "and draw process you're basically developing the rules how to extract the data uh when when you're doing that the",
    "start": "1793039",
    "end": "1798880"
  },
  {
    "text": "data is starting to get highlighted so you're seeing whether you're successful or not you don't have to compile it and",
    "start": "1798880",
    "end": "1804159"
  },
  {
    "text": "run it you can on the spot see the input the output and how does the data look on",
    "start": "1804159",
    "end": "1810360"
  },
  {
    "text": "the on the source itself so you can take in here any data binary or non-binary",
    "start": "1810360",
    "end": "1815760"
  },
  {
    "text": "documents or um or blob and really convert that into a data that would be",
    "start": "1815760",
    "end": "1821320"
  },
  {
    "text": "very simple to do map reduce processes",
    "start": "1821320",
    "end": "1826200"
  },
  {
    "text": "afterwards so so basically if you look into the endtoend process we're taking a sample data multiple files um as as the",
    "start": "1826720",
    "end": "1835240"
  },
  {
    "text": "input and we are aiming at creating a a well structured output um the example",
    "start": "1835240",
    "end": "1841600"
  },
  {
    "text": "that I'm going to talk about is actually going to be a Telco example but um every one of the industries shared earlier",
    "start": "1841600",
    "end": "1846640"
  },
  {
    "text": "actually have its own set of challenging data sets um if we're looking into the Telco industry they have a one of the",
    "start": "1846640",
    "end": "1852480"
  },
  {
    "text": "ugliest formats that you can Define called asn1 it is a cobble like compression that is very important so",
    "start": "1852480",
    "end": "1859240"
  },
  {
    "text": "that you can move the data from the switches to a central location we're allowing you to actually take this input",
    "start": "1859240",
    "end": "1865080"
  },
  {
    "text": "file put it on the source side and create on the on the other side um a well flat textual file that you can do",
    "start": "1865080",
    "end": "1871880"
  },
  {
    "text": "in a map reduce so first you are developing this transformation in the in the design environment and then",
    "start": "1871880",
    "end": "1878360"
  },
  {
    "text": "basically you are deploying it to run as part of um of your map reduce processes usually in the map uh in the map St uh",
    "start": "1878360",
    "end": "1885760"
  },
  {
    "text": "step um and um there are a few uh",
    "start": "1885760",
    "end": "1891600"
  },
  {
    "text": "optimizations that are done to make it easy U because one of the other challenges that happens is that um the",
    "start": "1891600",
    "end": "1897200"
  },
  {
    "text": "file format change the data sources that you want to integrate into your application into analytics they change",
    "start": "1897200",
    "end": "1903120"
  },
  {
    "text": "and you don't want to need to do a complex compilation you don't want to do a complex redeployment so basically the",
    "start": "1903120",
    "end": "1909720"
  },
  {
    "text": "transformation rules are within a simple file that you can share quickly with the",
    "start": "1909720",
    "end": "1915000"
  },
  {
    "text": "cluster itself so the value proposition is real world",
    "start": "1915000",
    "end": "1921559"
  },
  {
    "text": "data flat file logs hierarchical data like XML Json AO and so on full support",
    "start": "1921559",
    "end": "1928080"
  },
  {
    "text": "for industry standards so there are thousands of predefined transformation that handle the complexity of a variety",
    "start": "1928080",
    "end": "1933720"
  },
  {
    "text": "of verticals Financial Services Banking and insurance Health Care uh Telco um",
    "start": "1933720",
    "end": "1940399"
  },
  {
    "text": "manufacturing and Retail and so on and so forth and also full support for documents including the binary ones that",
    "start": "1940399",
    "end": "1946720"
  },
  {
    "text": "are a bit older the XML ones that are newer and so on when we're talking about um",
    "start": "1946720",
    "end": "1953919"
  },
  {
    "text": "transformation um the problems that I defined are sufficient uh but when we're looking into a dupe the the next part is",
    "start": "1953919",
    "end": "1960120"
  },
  {
    "text": "does it scale um and um I want to share with you two uh two charts here",
    "start": "1960120",
    "end": "1966919"
  },
  {
    "text": "um I'm not to blame for creating these charts but the AES are definitely not uh",
    "start": "1966919",
    "end": "1972159"
  },
  {
    "text": "uh um are not not helping me show showing the graph as a as a linear graph",
    "start": "1972159",
    "end": "1978600"
  },
  {
    "text": "it actually shows it a bit better but basically what what I'm trying to to share with you is that uh with h parser",
    "start": "1978600",
    "end": "1984200"
  },
  {
    "text": "you can not only um scale you can also predict how much compute would you need",
    "start": "1984200",
    "end": "1989519"
  },
  {
    "text": "in order to transform the data so basically you can see here how much does it take us to process 10 gabt from a",
    "start": "1989519",
    "end": "1996600"
  },
  {
    "text": "much larger data set how much does it take us to process 50 gabt from a much larger data set of Telco binary format",
    "start": "1996600",
    "end": "2003559"
  },
  {
    "text": "so all the data here need to go through a similar process to an encrypt decrypt from the binary format and then be",
    "start": "2003559",
    "end": "2009000"
  },
  {
    "text": "normalized and flattened this is kind of showing you how will you be able to do it on a growing uh amount of",
    "start": "2009000",
    "end": "2015880"
  },
  {
    "text": "nodes another problem that you sometimes have is you have a Windows of time in which you need to process a certain",
    "start": "2015880",
    "end": "2021519"
  },
  {
    "start": "2017000",
    "end": "2017000"
  },
  {
    "text": "amount of data so the following chart is showing you on a 72 node cluster how",
    "start": "2021519",
    "end": "2026840"
  },
  {
    "text": "much data are you able to process and showing you what what is the amount of comp what is the amount of data that you",
    "start": "2026840",
    "end": "2033039"
  },
  {
    "text": "can process within a known uh window of time where we've actually optim the the",
    "start": "2033039",
    "end": "2038480"
  },
  {
    "text": "software is in making sure that it is fully scaling per the nodes and that it does support unlimited data sets it does",
    "start": "2038480",
    "end": "2045120"
  },
  {
    "text": "include the ability to support not only large amount of small files it also",
    "start": "2045120",
    "end": "2050240"
  },
  {
    "text": "support um large files with built-in streaming capabilities and optimize",
    "start": "2050240",
    "end": "2055320"
  },
  {
    "text": "parallelism",
    "start": "2055320",
    "end": "2057960"
  },
  {
    "text": "afterwards my last slide is actually going to tell you this is available for you on EMR it is op optimized to make",
    "start": "2061599",
    "end": "2068599"
  },
  {
    "text": "your install easy as part of the bootstrap option so you can really Point",
    "start": "2068599",
    "end": "2073960"
  },
  {
    "text": "as shown earlier and get that working for you it is available in a community Edition which is a free we to support",
    "start": "2073960",
    "end": "2081040"
  },
  {
    "text": "web logs XML Json and other formats and you can download it by simply searching",
    "start": "2081040",
    "end": "2086240"
  },
  {
    "text": "H parser Community Edition or Amazon H parser and it does come with a full",
    "start": "2086240",
    "end": "2092040"
  },
  {
    "text": "tutorial that give you examples of how does that work and um you can buy a more",
    "start": "2092040",
    "end": "2097960"
  },
  {
    "text": "content more capabilities informatical support for a for the full",
    "start": "2097960",
    "end": "2103240"
  },
  {
    "text": "edition um this is um this is this was my part done done quickly and this will be a good time for me to introduce Ted",
    "start": "2103240",
    "end": "2109440"
  },
  {
    "text": "donning Chief application architect at [Applause]",
    "start": "2109440",
    "end": "2117610"
  },
  {
    "text": "mear commonly known as the guy in the red hat uh which is often true uh I had",
    "start": "2117760",
    "end": "2124680"
  },
  {
    "text": "a bad situation the other day when my wife didn't recognize me because I took my hat off but that doesn't happen all",
    "start": "2124680",
    "end": "2130800"
  },
  {
    "text": "the time so what I want to talk about is two particular things that are happening partly with map R but partly in a larger",
    "start": "2130800",
    "end": "2138000"
  },
  {
    "text": "Community one is the new Apache drill project back up sorry uh Apache drill is",
    "start": "2138000",
    "end": "2147280"
  },
  {
    "start": "2145000",
    "end": "2145000"
  },
  {
    "text": "uh intended for low latency interactive queries a second uh and in its open",
    "start": "2147280",
    "end": "2152839"
  },
  {
    "text": "source there's hundreds of people evolved in this across the US Europe uh",
    "start": "2152839",
    "end": "2157960"
  },
  {
    "text": "there's some people now beginning to work on it in Asia as well uh the the goal is to be develop Community",
    "start": "2157960",
    "end": "2165160"
  },
  {
    "text": "consensus around what this sort of uh API needs to be and what sort of",
    "start": "2165160",
    "end": "2171359"
  },
  {
    "text": "functionality is really needed we expect a a very early prototype release this",
    "start": "2171359",
    "end": "2177440"
  },
  {
    "text": "quarter this being Q4 and uh more real realistic releases",
    "start": "2177440",
    "end": "2183760"
  },
  {
    "text": "next quarter so the problem here is that latency really matters you saw on",
    "start": "2183760",
    "end": "2190920"
  },
  {
    "text": "ronin's slides that these data conversion jobs running map produce things have a little caveat there with a",
    "start": "2190920",
    "end": "2197079"
  },
  {
    "text": "one minute startup time and a one minute tail off time uh and that's very typical of a map produce environment it's",
    "start": "2197079",
    "end": "2202760"
  },
  {
    "text": "nothing to do with Informatica and it's based on the fact that had dupa map",
    "start": "2202760",
    "end": "2209079"
  },
  {
    "text": "produce especially is intended for large batch operations and therefore a bit of",
    "start": "2209079",
    "end": "2215480"
  },
  {
    "text": "overhead a minute to start the program it's not that big a deal well it is that",
    "start": "2215480",
    "end": "2220720"
  },
  {
    "text": "big a deal if I type a query or I try to hit a dashboard page and I ask for data",
    "start": "2220720",
    "end": "2227440"
  },
  {
    "text": "it's just not acceptable to be waiting as long as it takes to spin up a batch",
    "start": "2227440",
    "end": "2233160"
  },
  {
    "text": "job it's also not acceptable to not take some of the economies that are possible",
    "start": "2233160",
    "end": "2240000"
  },
  {
    "text": "in a query language such as column oriented database uh and so we feel that",
    "start": "2240000",
    "end": "2246240"
  },
  {
    "text": "there's uh a lot of people feel this way too that there's a lot of scope for kind",
    "start": "2246240",
    "end": "2251760"
  },
  {
    "start": "2247000",
    "end": "2247000"
  },
  {
    "text": "of the missing bit out of out of the open source thing the batch processing over on the left we've got pretty well",
    "start": "2251760",
    "end": "2258839"
  },
  {
    "text": "covered with Hadoop map produce the real-time stream processing the open source Community has",
    "start": "2258839",
    "end": "2265359"
  },
  {
    "text": "pretty well covered with things like uh storm or Apache S4 but there's a middle",
    "start": "2265359",
    "end": "2270640"
  },
  {
    "text": "ground where we're not actually doing streaming on the on the streaming side we have fixed queries that are defined",
    "start": "2270640",
    "end": "2277640"
  },
  {
    "text": "ahead of time before the stream starts on the batch side we have interactive queries but large overheads there's a",
    "start": "2277640",
    "end": "2284640"
  },
  {
    "text": "missing bit in the Middle where we want to have the flexibility of the batch",
    "start": "2284640",
    "end": "2290160"
  },
  {
    "text": "sort of thing but some of the interactivity of the stream oriented realtime stuff and that's where drill is",
    "start": "2290160",
    "end": "2296880"
  },
  {
    "text": "fitting that's where at Google the the Dremel project filled that Gap but there",
    "start": "2296880",
    "end": "2302079"
  },
  {
    "text": "is no good truly open- Source Apache like project for that",
    "start": "2302079",
    "end": "2309040"
  },
  {
    "text": "whole so one of the goals of drill is to be highly flexible and initially we'll",
    "start": "2309040",
    "end": "2314800"
  },
  {
    "text": "have uh an SQL like language but adapted for nested data nested data is commonly",
    "start": "2314800",
    "end": "2320960"
  },
  {
    "text": "used in Big Data applications to denormalize what would otherwise be",
    "start": "2320960",
    "end": "2326359"
  },
  {
    "text": "relational data with linking tables and things like that uh other options",
    "start": "2326359",
    "end": "2331800"
  },
  {
    "text": "include for later things like the query language which is widely used purely because mongodb itself is used we",
    "start": "2331800",
    "end": "2340079"
  },
  {
    "text": "want to make it easy to plug in new languages if you'd like to clone the pig",
    "start": "2340079",
    "end": "2345200"
  },
  {
    "text": "qu Pig Latin uh then that should be very easy to do uh the data model is also nested",
    "start": "2345200",
    "end": "2352319"
  },
  {
    "text": "instead of a relational sort of thing we want to have records that have records that have arrays of Records inside them",
    "start": "2352319",
    "end": "2359920"
  },
  {
    "start": "2356000",
    "end": "2356000"
  },
  {
    "text": "and we expect to be supporting multiple formats there afro protuff Json things",
    "start": "2359920",
    "end": "2366760"
  },
  {
    "text": "like that Json on in various binary formats and flat files of course a you",
    "start": "2366760",
    "end": "2372119"
  },
  {
    "text": "know rectangular flat files are a special case of this where we don't need to Nest",
    "start": "2372119",
    "end": "2377280"
  },
  {
    "text": "anything uh we want drill to be highly extensible right now most of the action",
    "start": "2377280",
    "end": "2382960"
  },
  {
    "text": "is going on around specifying the abstract internal representations for",
    "start": "2382960",
    "end": "2388800"
  },
  {
    "text": "both the logical plan and the physical execution plan so that anybody can drive",
    "start": "2388800",
    "end": "2394160"
  },
  {
    "text": "to those formats from any language or any gener format that they like and drive from the",
    "start": "2394160",
    "end": "2400920"
  },
  {
    "text": "execution plan into any kind of scanner or data processor that they happen to",
    "start": "2400920",
    "end": "2406640"
  },
  {
    "text": "have the flexibility there is is intended to be very very very large very",
    "start": "2406640",
    "end": "2411880"
  },
  {
    "text": "easy it also lets different people who specialize in different things if I",
    "start": "2411880",
    "end": "2417040"
  },
  {
    "text": "specialize in a web interface I shouldn't have to know about code generation in the extension",
    "start": "2417040",
    "end": "2424920"
  },
  {
    "text": "language the design goals are are easy Dependable fast that's because a lot of mapar developers are involved but",
    "start": "2425200",
    "end": "2431800"
  },
  {
    "start": "2426000",
    "end": "2426000"
  },
  {
    "text": "flexible is a very high goal as well we want to be pluggable we want it to be",
    "start": "2431800",
    "end": "2437319"
  },
  {
    "text": "easy that you can unzip and run uh my ideal view is that this not only scales",
    "start": "2437319",
    "end": "2442359"
  },
  {
    "text": "to thousands of nodes for very large problems but it scales down as well why",
    "start": "2442359",
    "end": "2447520"
  },
  {
    "text": "not have the ultimate GP here that supports a nice language and it can read",
    "start": "2447520",
    "end": "2453040"
  },
  {
    "text": "interesting structured data and it runs on my laptop I shouldn't need a clust I shouldn't need uh an involved",
    "start": "2453040",
    "end": "2460040"
  },
  {
    "text": "installation should just be zero con away and we go fast they'll probably be",
    "start": "2460040",
    "end": "2465640"
  },
  {
    "text": "a C++ core for some kinds of scanners but flexible will also imply Java based",
    "start": "2465640",
    "end": "2471359"
  },
  {
    "text": "cores as well we want to minimize latency maximize throughput for flexible",
    "start": "2471359",
    "end": "2477520"
  },
  {
    "text": "queries I'd like to also talk now about a second thing which is big and exciting",
    "start": "2477520",
    "end": "2483440"
  },
  {
    "text": "and that's much less open- sourcy not so much what if I just touch this thing it",
    "start": "2483440",
    "end": "2489520"
  },
  {
    "start": "2489000",
    "end": "2489000"
  },
  {
    "text": "does that it's it's uh I think there's a shake detector in it or something uh so",
    "start": "2489520",
    "end": "2494720"
  },
  {
    "text": "this is an extension to the map R platform it should be hitting EMR before too long but the basic idea is that we",
    "start": "2494720",
    "end": "2502720"
  },
  {
    "text": "integrate key Value Store capabilities columnar database directly into the",
    "start": "2502720",
    "end": "2508960"
  },
  {
    "text": "Advanced Data platform that's already part of map Bar's M5 we get rid of Concepts from hpas like",
    "start": "2508960",
    "end": "2517400"
  },
  {
    "text": "region servers and manual splits or compactions uh we support snapshots we",
    "start": "2517400",
    "end": "2524160"
  },
  {
    "text": "support mirrors with this very high throughput no garbage collection overhead very consistent low latency",
    "start": "2524160",
    "end": "2531520"
  },
  {
    "text": "it's designed to be hpas compatible but a simpler architecture so with map",
    "start": "2531520",
    "end": "2538720"
  },
  {
    "start": "2532000",
    "end": "2532000"
  },
  {
    "text": "R using hpas you have multiple layers with I'm sorry with Hadoop using HP you have",
    "start": "2538720",
    "end": "2545359"
  },
  {
    "text": "multiple layers with map using hbas you have fewer layers because you put hbas",
    "start": "2545359",
    "end": "2550559"
  },
  {
    "text": "directly on the map R file system but with M7 you'll have the fewest number",
    "start": "2550559",
    "end": "2555839"
  },
  {
    "text": "possible because the key value store is integrated directly in the data",
    "start": "2555839",
    "end": "2562160"
  },
  {
    "text": "platform uh we have some some comments from early",
    "start": "2562160",
    "end": "2567720"
  },
  {
    "start": "2564000",
    "end": "2564000"
  },
  {
    "text": "uh early views uh from some of our customers Rubicon uh is one of the",
    "start": "2567720",
    "end": "2572960"
  },
  {
    "text": "largest independent ad networks uh r thing keeps advancing uh so they talk",
    "start": "2572960",
    "end": "2579920"
  },
  {
    "text": "about M7 taking hbas and Hadoop to the next level it it integrates these capabilities they're so commonly needed",
    "start": "2579920",
    "end": "2586920"
  },
  {
    "text": "ancestry.com is a uh surprisingly large data user because they have data from",
    "start": "2586920",
    "end": "2594400"
  },
  {
    "text": "all these genealogical records U Melinda said she was very very excited about what she saw in this and return path",
    "start": "2594400",
    "end": "2602000"
  },
  {
    "text": "where they're doing email intelligence applications uh big win for them because they have to deal with a very Dynamic",
    "start": "2602000",
    "end": "2609319"
  },
  {
    "text": "world uh what's happening in email delivery changes Moment by moment their analysts have to be able to look at very",
    "start": "2609319",
    "end": "2616079"
  },
  {
    "text": "large volumes of data in a uh in an ad hoc way so the summary then is that it's",
    "start": "2616079",
    "end": "2624240"
  },
  {
    "start": "2621000",
    "end": "2621000"
  },
  {
    "text": "fully integrated into the data platform that's inside map R API compatible with",
    "start": "2624240",
    "end": "2630079"
  },
  {
    "text": "hbase and highly available very stable and very good latency that very",
    "start": "2630079",
    "end": "2635800"
  },
  {
    "text": "well-known latency as well uh the integration gives you things like snapshots and you'll be able to take a",
    "start": "2635800",
    "end": "2641880"
  },
  {
    "text": "snapshot full operation no interruptions and access the snapshot as a table at",
    "start": "2641880",
    "end": "2647000"
  },
  {
    "text": "any time be able to do mirrors to deploy copies of the table or for backups no",
    "start": "2647000",
    "end": "2652240"
  },
  {
    "text": "single point of failure of course and crash recovery in milliseconds and so there'll be more",
    "start": "2652240",
    "end": "2658640"
  },
  {
    "text": "available uh well I guess this is John's slide uh if you have more questions",
    "start": "2658640",
    "end": "2663680"
  },
  {
    "text": "we'll have a little bit of time we are 8 minutes to go uh but uh yeah why why",
    "start": "2663680",
    "end": "2671160"
  },
  {
    "text": "don't we pull everybody up here also later today at 3:00 I'll be signing",
    "start": "2671160",
    "end": "2676520"
  },
  {
    "text": "copies complimentary copies of mahoot in action if you're interested in mahoot",
    "start": "2676520",
    "end": "2682119"
  },
  {
    "text": "try the book try EMR let's get going and of course I'll be there to answer further questions if you",
    "start": "2682119",
    "end": "2688720"
  },
  {
    "text": "like at the mapar booth that is really good question thank you so much uh",
    "start": "2688720",
    "end": "2694280"
  },
  {
    "text": "that's at Booth 131 it's right next to the big stage in the vendor area I believe that uh Informatica you also",
    "start": "2694280",
    "end": "2700880"
  },
  {
    "text": "have a booth downstairs um so I think we have I think am Amazon has a booth downstairs yeah I think I think so so we",
    "start": "2700880",
    "end": "2707920"
  },
  {
    "text": "have about uh six or seven minutes um before we do that what I wanted to put on the slide here is if you want to",
    "start": "2707920",
    "end": "2713760"
  },
  {
    "text": "learn more about elastic map ruce you can go to our website um we have video tutorials documentation um frequently",
    "start": "2713760",
    "end": "2721040"
  },
  {
    "text": "Asked question so uh If you're sort of just getting started or you're looking to get more advanced uh that's probably",
    "start": "2721040",
    "end": "2726240"
  },
  {
    "text": "your best best um so why don't we and then last thing I need to do is to ask that you please",
    "start": "2726240",
    "end": "2733359"
  },
  {
    "text": "submit feedback on the session uh we'd love to hear from you uh how we can improve this for for next year and so",
    "start": "2733359",
    "end": "2738839"
  },
  {
    "text": "now we have about six or seven minutes we'd love to take some questions so just raise your hand and we'll try to try to see you and call so I see a hand right",
    "start": "2738839",
    "end": "2745319"
  },
  {
    "text": "here",
    "start": "2745319",
    "end": "2748319"
  },
  {
    "text": "propretary transform if you could repeat that yeah so the question was what is supported um",
    "start": "2765839",
    "end": "2772359"
  },
  {
    "text": "I'll simplify the the question the question was what is supported within the informatical community Edition and",
    "start": "2772359",
    "end": "2777520"
  },
  {
    "text": "is the Cost U reasonable to sell internally for those of you that want to develop a custom transformation inside H",
    "start": "2777520",
    "end": "2784599"
  },
  {
    "text": "parser so the Community Edition does give you good support for development of a proprietary format as long as you are",
    "start": "2784599",
    "end": "2791480"
  },
  {
    "text": "not going into the complex binaries and uh the proprietary industry for uh formats which we are maintaining on",
    "start": "2791480",
    "end": "2797760"
  },
  {
    "text": "regular basis the Community Edition should be a good place to start why don't we take a question maybe",
    "start": "2797760",
    "end": "2804119"
  },
  {
    "text": "over here in the red hat",
    "start": "2804119",
    "end": "2807720"
  },
  {
    "text": "um generally what you everything that you can do in the web so everything you can do in the web UI you can do with the CLI there are some things you can do in",
    "start": "2828240",
    "end": "2834920"
  },
  {
    "text": "the CLI that are not currently supported in the web web UI um but very shortly we're aiming to have complete parity",
    "start": "2834920",
    "end": "2841359"
  },
  {
    "text": "between the two uh the most advanced features the newest stuff will always hit the CLI so if that's what you're",
    "start": "2841359",
    "end": "2847559"
  },
  {
    "text": "using that that that's probably what I'd recommend more Red",
    "start": "2847559",
    "end": "2854960"
  },
  {
    "text": "Hats uh R has a number of capabilities uh which you can install packages for",
    "start": "2861760",
    "end": "2868079"
  },
  {
    "text": "for integration with the dupe uh that situation is in flux and it's really not",
    "start": "2868079",
    "end": "2875200"
  },
  {
    "text": "super great yet yet the the best use I've seen of r with Hadoop is where you",
    "start": "2875200",
    "end": "2881400"
  },
  {
    "text": "have replication where you're doing parameter scans on hyper parameters things like that so you just want to run",
    "start": "2881400",
    "end": "2886800"
  },
  {
    "text": "a small R program many many many times typically against the same data that",
    "start": "2886800",
    "end": "2892520"
  },
  {
    "text": "works well so like uh so so stochastic modeling is a great",
    "start": "2892520",
    "end": "2898440"
  },
  {
    "text": "example where you're running the same simulation many many many maybe millions of times and you're just running that on",
    "start": "2898440",
    "end": "2903599"
  },
  {
    "text": "every node sorry I think I misheard you earlier I thought you were asking a question about map r i uh no R great but",
    "start": "2903599",
    "end": "2909319"
  },
  {
    "text": "but I do r as well so it's okay uh okay there's one additional thing and that is with map R you can use NFS to directly",
    "start": "2909319",
    "end": "2917680"
  },
  {
    "text": "access cluster storage and so then our programs can communicate more",
    "start": "2917680",
    "end": "2922760"
  },
  {
    "text": "easily we'll have a tutorial on uh the website as well um in the next couple of days to uh to kind of walk you through",
    "start": "2922760",
    "end": "2929280"
  },
  {
    "text": "an example of using R if that's something you're you're curious about see a question here",
    "start": "2929280",
    "end": "2937000"
  },
  {
    "text": "so so today you have uh three options there's the Amazon standard distribution M3 and M5 um I think between those",
    "start": "2941160",
    "end": "2948359"
  },
  {
    "text": "between those three you'll find um you know most of of what you what you need um we're we're very excited about the",
    "start": "2948359",
    "end": "2954440"
  },
  {
    "text": "other distributions you know who's to say in the",
    "start": "2954440",
    "end": "2958838"
  },
  {
    "text": "future yeah in the back Red Hat are you able to add REM no cler",
    "start": "2960559",
    "end": "2968119"
  },
  {
    "text": "launch yes there's some caveats to that sort of",
    "start": "2968119",
    "end": "2974040"
  },
  {
    "text": "operation you have to be careful how you do it so you don't lose all of the replicas of certain kind of data you may",
    "start": "2974040",
    "end": "2980240"
  },
  {
    "text": "need to position the data or you may want to only add and remove dataless task tracker",
    "start": "2980240",
    "end": "2986720"
  },
  {
    "text": "nodes yes and obviously one of the things that's really nice about Hadoop is it's designed to handle the loss or",
    "start": "2986720",
    "end": "2992680"
  },
  {
    "text": "the addition of nodes so you might want to yourself be kind of resizing but you",
    "start": "2992680",
    "end": "2997760"
  },
  {
    "text": "might also be in a situation where you lose some nodes for for whatever reason and Hadoop is perfectly designed for that is this an operation",
    "start": "2997760",
    "end": "3006558"
  },
  {
    "text": "perform uh you You' use the command line interface to to add and subtract nodes",
    "start": "3010440",
    "end": "3015480"
  },
  {
    "text": "and you would also choose you know what types of nodes and and as I mentioned earlier do you want to add spot nodes which could be a really great very",
    "start": "3015480",
    "end": "3021119"
  },
  {
    "text": "powerful way to save money you mentioned about",
    "start": "3021119",
    "end": "3028079"
  },
  {
    "text": "I'm sorry a script where you",
    "start": "3034119",
    "end": "3037160"
  },
  {
    "text": "can uh I think I shut down hook I'm sorry a shutdown hook yeah um uh so you",
    "start": "3040799",
    "end": "3047640"
  },
  {
    "text": "can build that into your application that you want to add and subtract at different points in your processing um",
    "start": "3047640",
    "end": "3052680"
  },
  {
    "text": "but you can also do it kind of at a certain point in time if you want to add or subtract sorry maybe I'm not completely understanding the the",
    "start": "3052680",
    "end": "3060720"
  },
  {
    "text": "question the nodes can terminate themselves so if you can execute a script on the Node then you can",
    "start": "3060799",
    "end": "3067000"
  },
  {
    "text": "terminate Hadoop you can terminate the node you you're all good to go there yeah the the purpose of a startup script",
    "start": "3067000",
    "end": "3074160"
  },
  {
    "text": "is to run before Hadoop starts but afterwards there's no there's no",
    "start": "3074160",
    "end": "3079240"
  },
  {
    "text": "cementry there that you can do it anytime you like generally where we see people resizing clusters is uh they know",
    "start": "3079240",
    "end": "3084920"
  },
  {
    "text": "that like like with Netflix for example um when it's Saturday night they have and it's either done dynamically or it's",
    "start": "3084920",
    "end": "3091000"
  },
  {
    "text": "somebody actually at the command line that is resizing that cluster that's typically how it's happening but you could also write it into your processing",
    "start": "3091000",
    "end": "3097359"
  },
  {
    "text": "that at a certain step you want to kind of resize see a hand here so it is possible",
    "start": "3097359",
    "end": "3103119"
  },
  {
    "text": "to dynamically add Andra us some of command line",
    "start": "3103119",
    "end": "3109880"
  },
  {
    "text": "inter yeah and if you have questions about you resizing clusters I would love to I can I'll be at the booth downstairs",
    "start": "3109880",
    "end": "3115760"
  },
  {
    "text": "later um and I can actually show you examples of the actual code You' use to to do that I think we have time for",
    "start": "3115760",
    "end": "3122400"
  },
  {
    "text": "maybe one more question I see a hand in the back",
    "start": "3122400",
    "end": "3126359"
  },
  {
    "text": "there the question is how does drill compare with Impala uh Impala is further",
    "start": "3129799",
    "end": "3135880"
  },
  {
    "text": "along uh it's several months ahead in development Impala is effectively",
    "start": "3135880",
    "end": "3141359"
  },
  {
    "text": "visible Source in opposed to open source Claud has said they're not looking for",
    "start": "3141359",
    "end": "3146559"
  },
  {
    "text": "outside contributions and you know you just basically can't change it also up to now you know there's been very",
    "start": "3146559",
    "end": "3152559"
  },
  {
    "text": "limited ability to even compile it drill as I said is considerably behind that it",
    "start": "3152559",
    "end": "3158480"
  },
  {
    "text": "it has a goal of being very open Community or oriented and much more flexible Impala has a specific goal in",
    "start": "3158480",
    "end": "3166440"
  },
  {
    "text": "mind uh of supporting a very specific narrow range of support it isn't even",
    "start": "3166440",
    "end": "3172720"
  },
  {
    "text": "Apache Hadoop that it supports requires special hooks uh drill wants to be much more",
    "start": "3172720",
    "end": "3179319"
  },
  {
    "text": "flexible so I think unfortunately we're out of time now I want to thank you all for coming if you have other questions",
    "start": "3179319",
    "end": "3184359"
  },
  {
    "text": "you can come find us uh we'll stick around here for a couple of minutes and then as we mentioned earlier we're all at we have booths downstairs so thank",
    "start": "3184359",
    "end": "3190440"
  },
  {
    "text": "you all very much",
    "start": "3190440",
    "end": "3193960"
  }
]
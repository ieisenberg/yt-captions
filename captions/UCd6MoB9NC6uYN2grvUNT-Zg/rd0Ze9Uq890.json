[
  {
    "start": "0",
    "end": "54000"
  },
  {
    "text": "that's the bag hey everyone good afternoon hope everyone is doing well",
    "start": "30",
    "end": "8010"
  },
  {
    "text": "hope you're enjoying the event I am Matt Ellis I'm a part of the product management team at at TIBCO",
    "start": "8010",
    "end": "13679"
  },
  {
    "text": "software I focus on our open source text acts so more specifically project logo",
    "start": "13679",
    "end": "18750"
  },
  {
    "text": "kind of kind of everything open source related is what falls under my my umbrella hi everyone I'm Erin van der",
    "start": "18750",
    "end": "31650"
  },
  {
    "text": "Geist I am the machine learning project manager working with Matt on flow go so",
    "start": "31650",
    "end": "36750"
  },
  {
    "text": "basically it's my job to make sure machine learning gets integrated with project flow go so so Abhiram here we'll",
    "start": "36750",
    "end": "43559"
  },
  {
    "text": "spend most of the time talking about all the cool stuff and I'll just kind of bore you with with some of the basic open source stuff and events but but I",
    "start": "43559",
    "end": "49739"
  },
  {
    "text": "suspect open source is something you guys probably like yeah awesome",
    "start": "49739",
    "end": "55170"
  },
  {
    "start": "54000",
    "end": "107000"
  },
  {
    "text": "so from an agenda perspective will will kind of kind of break this up into several different categories so we'll",
    "start": "55170",
    "end": "61230"
  },
  {
    "text": "talk about events and if you really think about event processing in general especially in the context of traditional",
    "start": "61230",
    "end": "66780"
  },
  {
    "text": "software I mean you've heard about event processing forever so I want to kind of debunk some of the myths and talk about",
    "start": "66780",
    "end": "72720"
  },
  {
    "text": "what we consider event processing today well we'll talk about how events kind of",
    "start": "72720",
    "end": "78840"
  },
  {
    "text": "make sense and how events are translated into or how events became the precursor to the big data movement which then fed",
    "start": "78840",
    "end": "84780"
  },
  {
    "text": "into IOT which fed back into big data and we'll kind of we'll kind of talk about some of this stuff and then finally talk about talk about some of",
    "start": "84780",
    "end": "92579"
  },
  {
    "text": "the ML techniques that you can use and then we'll jump into talking about specifically open source projects logo",
    "start": "92579",
    "end": "97759"
  },
  {
    "text": "and we've got a demo lined up for you here today as well so we'll walk through the demo show you how it was built and",
    "start": "97759",
    "end": "103340"
  },
  {
    "text": "and kick around a few boxes so an event",
    "start": "103340",
    "end": "109430"
  },
  {
    "start": "107000",
    "end": "145000"
  },
  {
    "text": "at its core is is nothing more than something that happens right typically",
    "start": "109430",
    "end": "114509"
  },
  {
    "text": "speaking it's it's it's can be something of importance but often times in a single event by itself is not usually",
    "start": "114509",
    "end": "121680"
  },
  {
    "text": "something of importance right usually it's it's multiple events that have occurred within a period of time that",
    "start": "121680",
    "end": "127439"
  },
  {
    "text": "can be aggregated into a certain window that becomes something important right like I said an event is just an event I",
    "start": "127439",
    "end": "134530"
  },
  {
    "text": "could I could kick my box on the floor and that's just an event but nobody really cares about that right but if I do it a million times and I clearly I've",
    "start": "134530",
    "end": "140890"
  },
  {
    "text": "got a problem so so that's a derived event so when you look at events in",
    "start": "140890",
    "end": "146770"
  },
  {
    "text": "general and you kind of think about how you can process events and you take a step back so again if we take a step",
    "start": "146770",
    "end": "152560"
  },
  {
    "text": "back and we say an event and it's most simple form is just something that happens and processing an event you can",
    "start": "152560",
    "end": "159580"
  },
  {
    "text": "process events in multiple different ways okay so you can process millions of events at any given time you can consume",
    "start": "159580",
    "end": "165760"
  },
  {
    "text": "those events into a pipeline stream those events aggregate those events over a period of time maybe produce some sort",
    "start": "165760",
    "end": "173440"
  },
  {
    "text": "of derived event after the fact okay you can also do something along the lines of",
    "start": "173440",
    "end": "179890"
  },
  {
    "text": "just integration so a single event comes in you integrate that event with something else so you maybe you write it",
    "start": "179890",
    "end": "185050"
  },
  {
    "text": "to a database or you store you you publish a CAF Kumasi jell bound or or you do something like that okay just as",
    "start": "185050",
    "end": "191200"
  },
  {
    "text": "you process a single event at any given time but you can also process events in",
    "start": "191200",
    "end": "197530"
  },
  {
    "text": "more what what used to be the traditional complex event processing paradigm right so the concept is simple",
    "start": "197530",
    "end": "202840"
  },
  {
    "text": "events come in you store events in historical memory you correlate events against past events like with new",
    "start": "202840",
    "end": "209350"
  },
  {
    "text": "incoming events and then you produce some or you infer some sort of derived event from that okay so all three ways",
    "start": "209350",
    "end": "215740"
  },
  {
    "text": "of processing the same simple concept and event okay so in this session we'll",
    "start": "215740",
    "end": "221500"
  },
  {
    "text": "spend some time kind of diving deeper into that notion we'll look at how you can process events and we'll explore the",
    "start": "221500",
    "end": "227110"
  },
  {
    "text": "open source framework projects logo that kind of led to or that enables you to consume process and build events in all",
    "start": "227110",
    "end": "233890"
  },
  {
    "text": "of these different different ways so making sense of an event so if you take",
    "start": "233890",
    "end": "240640"
  },
  {
    "start": "236000",
    "end": "303000"
  },
  {
    "text": "a step back and think about it so you've probably heard this phrase before so what data is king okay so data data that",
    "start": "240640",
    "end": "248340"
  },
  {
    "text": "what you can do with data produces you know if produces some sort of outcome",
    "start": "248340",
    "end": "253750"
  },
  {
    "text": "that that's tangible or relevant for your business well the fact is that yeah it sure data is important but all data",
    "start": "253750",
    "end": "260470"
  },
  {
    "text": "originated as a single event right so a single event came in and over time multiple multiple events",
    "start": "260470",
    "end": "267840"
  },
  {
    "text": "came in came in come in you stored them into a data Lake a data warehouse something like that and you started saving these events until you had a huge",
    "start": "267840",
    "end": "274979"
  },
  {
    "text": "chunk of data that you then needed to figure out what to do with right so data volumes continue to grow oftentimes you",
    "start": "274979",
    "end": "282270"
  },
  {
    "text": "can't take the the data itself is it's too large you can't process the data and",
    "start": "282270",
    "end": "287370"
  },
  {
    "text": "produce some sort of meaningful some sort of meaningful action with the data itself so you leverage something like",
    "start": "287370",
    "end": "293430"
  },
  {
    "text": "AWS for for cloud scale to process this mass amounts of data to Train data to produce machine learning models and and",
    "start": "293430",
    "end": "299790"
  },
  {
    "text": "produce insights and from the events but as I said the data is growing right so",
    "start": "299790",
    "end": "307889"
  },
  {
    "start": "303000",
    "end": "342000"
  },
  {
    "text": "more and more data sources are being produced every single day and if you really take a step back and look at that",
    "start": "307889",
    "end": "313500"
  },
  {
    "text": "a lot of that has to do with the concept of IOT so sensors are really literally everywhere there's a sensor put in",
    "start": "313500",
    "end": "320370"
  },
  {
    "text": "everything today and everything is producing data everything is producing an event okay so that data warehouse",
    "start": "320370",
    "end": "326970"
  },
  {
    "text": "continues to grow and and again it continues to push or the the focus needs",
    "start": "326970",
    "end": "333840"
  },
  {
    "text": "to shift on to cloud scale to truly process those events and actually perform something meaningful with those",
    "start": "333840",
    "end": "339510"
  },
  {
    "text": "those those events but that's all fine and good so all this mumbo-jumbo about",
    "start": "339510",
    "end": "345900"
  },
  {
    "start": "342000",
    "end": "492000"
  },
  {
    "text": "data on data's King and events and all that crap but what about what about",
    "start": "345900",
    "end": "351000"
  },
  {
    "text": "architecture paradigms so if you're a software developer then architectural paradigms have also shifted okay so with",
    "start": "351000",
    "end": "358200"
  },
  {
    "text": "the increase in data people expect more so so your customers expect more from you because you're using their data to",
    "start": "358200",
    "end": "364410"
  },
  {
    "text": "provide them some sort of insight for for example churn prediction if you've",
    "start": "364410",
    "end": "369870"
  },
  {
    "text": "predicted a customer is gonna churn then you might give them an offer to try to keep them within your company and oftentimes customers are okay with",
    "start": "369870",
    "end": "376500"
  },
  {
    "text": "giving a little if they get something in return so they're expecting more your businesses expect more they push back on",
    "start": "376500",
    "end": "382229"
  },
  {
    "text": "i.t they push back on the developers and the developers now need to start building software that that can scale",
    "start": "382229",
    "end": "388139"
  },
  {
    "text": "quicker that can change quicker right so monolith traditionally the way we build",
    "start": "388139",
    "end": "393870"
  },
  {
    "text": "software was a giant service with a ton different capabilities embedded in that single service hard to change if you did",
    "start": "393870",
    "end": "401729"
  },
  {
    "text": "make a change then oftentimes the the service itself would you break something",
    "start": "401729",
    "end": "408180"
  },
  {
    "text": "else right so you make one change you break something else you might crash the service upgrades were a nightmare you had these you know these all-night",
    "start": "408180",
    "end": "414509"
  },
  {
    "text": "marathon soft software upgrades things like that so a total disaster right so then we moved into the realm of",
    "start": "414509",
    "end": "422250"
  },
  {
    "text": "micro services where we took off we took that we took that service we broke it",
    "start": "422250",
    "end": "427259"
  },
  {
    "text": "apart into a into a bunch of different smaller services and each smaller service typically had three four five",
    "start": "427259",
    "end": "434009"
  },
  {
    "text": "operations associated with it each operation was or each service sorry was typically bound to a business capability",
    "start": "434009",
    "end": "441270"
  },
  {
    "text": "so when the business came to you and said hey we need something changed we need to do this we need to do that you're able to make a change to that",
    "start": "441270",
    "end": "447479"
  },
  {
    "text": "single service you didn't break the entire system you updated that single service but still you were potentially",
    "start": "447479",
    "end": "453090"
  },
  {
    "text": "impacting you know four or five other operations associated with that service so then we move into the realm of",
    "start": "453090",
    "end": "460139"
  },
  {
    "text": "serverless functions or functions right so server listen functions they're not they're not the same I'm not gonna get",
    "start": "460139",
    "end": "465509"
  },
  {
    "text": "into that that argument at the moment but but functions themselves we move into the realm of functions so you start",
    "start": "465509",
    "end": "471150"
  },
  {
    "text": "building single discrete components that are tightly bound to capabilities they perform one thing and one thing only and",
    "start": "471150",
    "end": "478289"
  },
  {
    "text": "that that could be a crutch you know an update operation a delete operation you know transform eight transforming",
    "start": "478289",
    "end": "484110"
  },
  {
    "text": "the data maybe you you invoke a machine learning model or something like that so you moved into that that realm of",
    "start": "484110",
    "end": "489990"
  },
  {
    "text": "software development but you've also got another change that's happening right so",
    "start": "489990",
    "end": "496039"
  },
  {
    "start": "492000",
    "end": "554000"
  },
  {
    "text": "that you've heard it before right so AI is eating software and and that may be",
    "start": "496039",
    "end": "502710"
  },
  {
    "text": "part through but but the fact is that AI is absorbing software okay",
    "start": "502710",
    "end": "508380"
  },
  {
    "text": "or AI is augmenting software so you don't write software the way you traditionally write software anymore",
    "start": "508380",
    "end": "514430"
  },
  {
    "text": "traditionally you'd write software in the sense that everything was a deterministic set of rules okay",
    "start": "514430",
    "end": "520440"
  },
  {
    "text": "if cells procedural logic things like that that was your software but today the software needs to start shifting it",
    "start": "520440",
    "end": "527250"
  },
  {
    "text": "needs to become both predictive and prescriptive in other words what's",
    "start": "527250",
    "end": "532380"
  },
  {
    "text": "going to happen and what can I do about it okay so with that shift in and how",
    "start": "532380",
    "end": "539310"
  },
  {
    "text": "you need to start approaching software you need to start taking machine learning models you need to be able to embed some of the ML techniques into",
    "start": "539310",
    "end": "546990"
  },
  {
    "text": "your traditional applications and then enable those applications to become predictive and descriptive so that means",
    "start": "546990",
    "end": "557279"
  },
  {
    "start": "554000",
    "end": "647000"
  },
  {
    "text": "machine learning is the answer for everything yeah of course it is right",
    "start": "557279",
    "end": "562430"
  },
  {
    "text": "minoo my marketing department told me that if I put ml on my marketing material that itself so that's why the",
    "start": "562430",
    "end": "569580"
  },
  {
    "text": "slide I created the slide joking aside anyway so so machine learning is not",
    "start": "569580",
    "end": "576209"
  },
  {
    "text": "always the answer guys so so sometimes you could actually solve a problem simply by performing some element of",
    "start": "576209",
    "end": "582390"
  },
  {
    "text": "streaming stream processing on the data or some element a deterministic rule rule sets on the data itself okay so as",
    "start": "582390",
    "end": "589589"
  },
  {
    "text": "the events come in you can you can aggregate data over a period of time and you could calculate the average over a period of time or the median or whatever",
    "start": "589589",
    "end": "596400"
  },
  {
    "text": "whatever derive value you're trying to calculate and you clearly didn't need machine learning for that okay some of",
    "start": "596400",
    "end": "601800"
  },
  {
    "text": "it's just simple math right but often times you do need ml when you're looking at classifying large quantities of data",
    "start": "601800",
    "end": "608279"
  },
  {
    "text": "so you want to maybe do a class image classification so maybe facial detection",
    "start": "608279",
    "end": "613740"
  },
  {
    "text": "or recognition or something like that then you start looking towards ml techniques and algorithms and things",
    "start": "613740",
    "end": "619529"
  },
  {
    "text": "along the that nature as well but there's a couple caveats so so you look",
    "start": "619529",
    "end": "626010"
  },
  {
    "text": "at ml when you have a broad set of problems that need to be identified and detected something that is far too broad",
    "start": "626010",
    "end": "631860"
  },
  {
    "text": "of a set that you could manually do yourself but that also means you need the data so kind of back to that",
    "start": "631860",
    "end": "638220"
  },
  {
    "text": "original point of data bingqing you need the data otherwise you can't train ml models and I'm gonna pass it over to two",
    "start": "638220",
    "end": "647190"
  },
  {
    "text": "Abhiram now and he's going to talk a little bit more hello so I'm gonna talk about a little",
    "start": "647190",
    "end": "655770"
  },
  {
    "text": "bit about deep learning AI and ml but first I'm gonna discuss a bit of the",
    "start": "655770",
    "end": "661560"
  },
  {
    "start": "658000",
    "end": "907000"
  },
  {
    "text": "differences between supervised and unsupervised learning and machine learning so basically as matt said we",
    "start": "661560",
    "end": "670890"
  },
  {
    "text": "often have to integrate new capabilities within the micro services and functions",
    "start": "670890",
    "end": "678089"
  },
  {
    "text": "that we are building supervised learning is one of the more common ways of doing",
    "start": "678089",
    "end": "683339"
  },
  {
    "text": "this this is where you are basically taking some inputs or features which in",
    "start": "683339",
    "end": "689250"
  },
  {
    "text": "this case can be represented by X and we know in a certain number of cases that",
    "start": "689250",
    "end": "695149"
  },
  {
    "text": "this should be the output Y so we're trying to build our models such that it determines what our function is and this",
    "start": "695149",
    "end": "702120"
  },
  {
    "text": "is the supervised learning approach in general it tries to preserve some si",
    "start": "702120",
    "end": "707940"
  },
  {
    "text": "predict some observed condition this",
    "start": "707940",
    "end": "713040"
  },
  {
    "text": "requires a lot of data but just not any kind of data it requires labelled data so you need to",
    "start": "713040",
    "end": "718740"
  },
  {
    "text": "know what the output should be so for my linear regression here on the lower left",
    "start": "718740",
    "end": "724670"
  },
  {
    "text": "basically we see that there is a large number of points needed to basically",
    "start": "724670",
    "end": "731160"
  },
  {
    "text": "determine what that line was with a fair amount of accuracy so that in the future",
    "start": "731160",
    "end": "736529"
  },
  {
    "text": "we can now say when we build it into our function that give if if the input of X",
    "start": "736529",
    "end": "742470"
  },
  {
    "text": "is given say at 5 we know that the output should be something around 0.75",
    "start": "742470",
    "end": "748410"
  },
  {
    "text": "or something like that that's basically the idea behind supervised learning now there are",
    "start": "748410",
    "end": "754050"
  },
  {
    "text": "subsets of machine learning sorry of supervised learning that unfortunately apparently got lost in the",
    "start": "754050",
    "end": "759690"
  },
  {
    "text": "trans trans ition to this a slide deck but they include semi-supervised learning active learning and reinforced",
    "start": "759690",
    "end": "767790"
  },
  {
    "text": "learning and all three of these are ways to use partial data to help you learn so",
    "start": "767790",
    "end": "775320"
  },
  {
    "text": "semi-supervised is using some incomplete set so if you're trying to determine outliers for example you might know that",
    "start": "775320",
    "end": "782730"
  },
  {
    "text": "10% of your data is an outlier and you can use that to train your model active learning is",
    "start": "782730",
    "end": "788750"
  },
  {
    "text": "where the algorithm decides what specific cases will be most useful for",
    "start": "788750",
    "end": "794780"
  },
  {
    "text": "it there's often integrated with interactive learning so when it determines a point should have a label",
    "start": "794780",
    "end": "800750"
  },
  {
    "text": "it'll kick that out to a human being who had been label it reinforced learning which is hidden behind the plot is",
    "start": "800750",
    "end": "808400"
  },
  {
    "text": "basically where your model makes a prediction and then you either punish it or reward it based on what its result",
    "start": "808400",
    "end": "815060"
  },
  {
    "text": "was such that it continues learning now all of this is supervised learning",
    "start": "815060",
    "end": "820520"
  },
  {
    "text": "you have example cases to make predictions from unsupervised learning",
    "start": "820520",
    "end": "827570"
  },
  {
    "text": "is where you just have your input data and you don't know what possible outputs",
    "start": "827570",
    "end": "833660"
  },
  {
    "text": "could be so this is often used to explore your data to understand the",
    "start": "833660",
    "end": "838910"
  },
  {
    "text": "structure detect anomalies is often very common but just generally to uncover new",
    "start": "838910",
    "end": "845900"
  },
  {
    "text": "phenomenon now one of the limitations of this is you depending on what your input",
    "start": "845900",
    "end": "852230"
  },
  {
    "text": "features are and how you decide your input data this can greatly change what your outputs are and so this leads to",
    "start": "852230",
    "end": "860090"
  },
  {
    "text": "why you were doing unsupervised learning so basically superevil unsupervised",
    "start": "860090",
    "end": "865160"
  },
  {
    "text": "learning can either be the point itself you want to know what your data looks like so whether it's clustered how many",
    "start": "865160",
    "end": "870860"
  },
  {
    "text": "clusters could exist in your data set or you can be trying to determine what your",
    "start": "870860",
    "end": "879590"
  },
  {
    "text": "classes should be such that you can put this into a supervised model or things like this for example my clustering data",
    "start": "879590",
    "end": "886130"
  },
  {
    "text": "set here in the lower right you can see that the data set really is clustered within three categories such that after",
    "start": "886130",
    "end": "895220"
  },
  {
    "text": "we run our unsupervised approach we will know that there's three clusters a let's",
    "start": "895220",
    "end": "900650"
  },
  {
    "text": "call them a B and C such that we can then use this two for our supervised",
    "start": "900650",
    "end": "906080"
  },
  {
    "text": "approach now both supervised and",
    "start": "906080",
    "end": "911420"
  },
  {
    "start": "907000",
    "end": "1074000"
  },
  {
    "text": "unsupervised learning can be applied to many many things here I have six categories of applications as you can",
    "start": "911420",
    "end": "917960"
  },
  {
    "text": "imagine there are many many more and within those categories there are lots of smaller",
    "start": "917960",
    "end": "924649"
  },
  {
    "text": "tasks that can be that machine learning can be applied to all of these have and",
    "start": "924649",
    "end": "931310"
  },
  {
    "text": "so on because these are just a quick sampling of what possibilities could exist now classification and regression",
    "start": "931310",
    "end": "938449"
  },
  {
    "text": "are probably the two more common types of machine learning applications or at least are the ones that you're probably",
    "start": "938449",
    "end": "944180"
  },
  {
    "text": "more most familiar with where classification is well you're classifying things you're trying to put",
    "start": "944180",
    "end": "949730"
  },
  {
    "text": "things detect whether it's a fraudulent event or not whether it's spam or you're",
    "start": "949730",
    "end": "956149"
  },
  {
    "text": "trying to bucket your data into any of a million different categories this is one",
    "start": "956149",
    "end": "961759"
  },
  {
    "text": "of the ways that recommendations engines work well regressions are basically any",
    "start": "961759",
    "end": "967100"
  },
  {
    "text": "time you're fitting a graph or trying to predict the value of something you're",
    "start": "967100",
    "end": "972410"
  },
  {
    "text": "doing a regression so these are the two most talked about and used types of",
    "start": "972410",
    "end": "977559"
  },
  {
    "text": "applications but you also run into clustering and pattern recognition which",
    "start": "977559",
    "end": "983360"
  },
  {
    "text": "is often an unsupervised approach where you can discover classes and features you can also do dimensionality reduction",
    "start": "983360",
    "end": "990170"
  },
  {
    "text": "which basically there are many many cases where you have a lot of possible inputs for your data that slows down",
    "start": "990170",
    "end": "997930"
  },
  {
    "text": "your your supervisor or machine learning approach and so you want to find the",
    "start": "997930",
    "end": "1005019"
  },
  {
    "text": "most important features this can either be for the supervisors approach or just because you want to know what what's",
    "start": "1005019",
    "end": "1011410"
  },
  {
    "text": "causing your client to churn and so that you can address that all this can be",
    "start": "1011410",
    "end": "1017500"
  },
  {
    "text": "done with dimensionality reduction one of the more famous dimensionality reduction examples is actually with",
    "start": "1017500",
    "end": "1024668"
  },
  {
    "text": "natural learning processing where originally people would have a very sparse matrix where every word that they",
    "start": "1024669",
    "end": "1031298"
  },
  {
    "text": "expect to see corresponds to a 1 or a 0 in a very long list however this can be",
    "start": "1031299",
    "end": "1037360"
  },
  {
    "text": "on the order of a hundred thousand columns in your row and can be very",
    "start": "1037360",
    "end": "1042730"
  },
  {
    "text": "difficult to handle word embeddings is basically a way to reduce this down such",
    "start": "1042730",
    "end": "1048548"
  },
  {
    "text": "that every word is represented by a float sorry 300 dimensional vector that's a",
    "start": "1048549",
    "end": "1056990"
  },
  {
    "text": "float this great is much more efficient than having a hundred thousand or a",
    "start": "1056990",
    "end": "1062060"
  },
  {
    "text": "million column a sparse array and then of course that we can also do outlier or",
    "start": "1062060",
    "end": "1068690"
  },
  {
    "text": "anomaly detection information filtering or any of a hundred other applications",
    "start": "1068690",
    "end": "1074500"
  },
  {
    "start": "1074000",
    "end": "1261000"
  },
  {
    "text": "so we sort started this section with deep learning machine learning AI what's",
    "start": "1074500",
    "end": "1081650"
  },
  {
    "text": "that well hopefully after this slide you'll have a more detailed understanding of at least my",
    "start": "1081650",
    "end": "1088160"
  },
  {
    "text": "interpretation of this so I want to add the caveat that if you get ten data scientists together in a room with this",
    "start": "1088160",
    "end": "1094760"
  },
  {
    "text": "slide you'll probably get twenty different opinions on how this all works but basically machine learning is",
    "start": "1094760",
    "end": "1104710"
  },
  {
    "text": "algorithms that you basically try to extract information out of data while",
    "start": "1104710",
    "end": "1111440"
  },
  {
    "text": "artificial intelligence is a computer system that seeks to emulate human",
    "start": "1111440",
    "end": "1117230"
  },
  {
    "text": "thought or human intelligence and activities so seeing listening",
    "start": "1117230",
    "end": "1123190"
  },
  {
    "text": "understanding now I have them here as two separate bubbles that overlap there",
    "start": "1123190",
    "end": "1131360"
  },
  {
    "text": "was recently an article on medium that actually had AI as the larger bubble with machine learning completely inside",
    "start": "1131360",
    "end": "1138050"
  },
  {
    "text": "I actually feel that this is not entirely accurate because there are forms of machine learning that is not",
    "start": "1138050",
    "end": "1144610"
  },
  {
    "text": "artificial intelligence I'll actually say a linear regression that I showed earlier is an example of this human",
    "start": "1144610",
    "end": "1151520"
  },
  {
    "text": "beings are horrible at drawing lines but we're seeing learnings sorry linear regressions are actually pretty good at",
    "start": "1151520",
    "end": "1157610"
  },
  {
    "text": "it well for artificial intelligence there are forms of AI that are not based",
    "start": "1157610",
    "end": "1163310"
  },
  {
    "text": "around data originally a lot of a I was rules based now of course the more",
    "start": "1163310",
    "end": "1169430"
  },
  {
    "text": "recent forms of AI and the more sexy forms are are more related to data but",
    "start": "1169430",
    "end": "1177560"
  },
  {
    "text": "that is not all cases of AI so that's why I break them apart into two overlapping circles now neural networks",
    "start": "1177560",
    "end": "1185250"
  },
  {
    "text": "is a class of algorithms that are modeled off basically human human neurons they use linear algebra to",
    "start": "1185250",
    "end": "1192330"
  },
  {
    "text": "basically try to replicate how the human brain works",
    "start": "1192330",
    "end": "1197150"
  },
  {
    "text": "now deep learning is a subset of neural networks basically a hierarchical form",
    "start": "1197790",
    "end": "1204780"
  },
  {
    "text": "so here you want to thank multiple layers where the lower layers try to",
    "start": "1204780",
    "end": "1210210"
  },
  {
    "text": "find their own representations within the data so an example of this is in",
    "start": "1210210",
    "end": "1216390"
  },
  {
    "text": "image recognition where the machine learning algorithm gets the pixels of",
    "start": "1216390",
    "end": "1223110"
  },
  {
    "text": "the image the first layer of the network will look at the pixels and try to form lines the second second layer will take",
    "start": "1223110",
    "end": "1230460"
  },
  {
    "text": "the lines to try to form shapes the third layer will try to take the shapes and try to form faces so on and so forth",
    "start": "1230460",
    "end": "1237180"
  },
  {
    "text": "until your final layer tries to predict facial expressions or things like that",
    "start": "1237180",
    "end": "1243800"
  },
  {
    "text": "so you can actually see that deep learning is a subset of neural networks",
    "start": "1243800",
    "end": "1249270"
  },
  {
    "text": "that is also a subset of both artificial intelligence and machine learning but",
    "start": "1249270",
    "end": "1254430"
  },
  {
    "text": "that AI and machine learning don't overlap them don't completely overlap themselves so I think at this point I'm",
    "start": "1254430",
    "end": "1263610"
  },
  {
    "text": "handing back off to Matt thanks for him so we figured we'd bounce around between each other just to try to keep keep you",
    "start": "1263610",
    "end": "1270450"
  },
  {
    "text": "guys entertained and keep you from getting too bored so I'm gonna shift gears entirely and talk about talking",
    "start": "1270450",
    "end": "1277440"
  },
  {
    "text": "about project logo so project logo is is are is an open source ecosystem for",
    "start": "1277440",
    "end": "1283020"
  },
  {
    "text": "event-driven apps okay so when we set out to build projects logo - about - two",
    "start": "1283020",
    "end": "1290310"
  },
  {
    "text": "ish years ago we kind of set out with it with a couple key initiatives in mind the first initiative is that it had to",
    "start": "1290310",
    "end": "1297120"
  },
  {
    "text": "be lightweight okay so it had to be efficient from a resource consumption",
    "start": "1297120",
    "end": "1302760"
  },
  {
    "text": "perspective you you know if you look at traditional Java apps and things like that enough of that crap",
    "start": "1302760",
    "end": "1309660"
  },
  {
    "text": "right where you you've got a JRE that's 190 megabytes you've got you know consuming at least several gigabytes of",
    "start": "1309660",
    "end": "1315090"
  },
  {
    "text": "RAM on your application and things like that so so 10 to 50 X light from a footprint perspective was one of",
    "start": "1315090",
    "end": "1321429"
  },
  {
    "text": "our goals another thing that we set out to do was was make this an open-source",
    "start": "1321429",
    "end": "1327039"
  },
  {
    "text": "project from the beginning so rather than than some projects that started as clinic closed source and then eventually",
    "start": "1327039",
    "end": "1333009"
  },
  {
    "text": "become open source we wanted this to be an open source project from the very beginning where you'll see a lot of the",
    "start": "1333009",
    "end": "1338979"
  },
  {
    "text": "proposals and the early proposals and some of the stuff that kind of drove the project to be what it is today was was",
    "start": "1338979",
    "end": "1345700"
  },
  {
    "text": "done through the community and that was incredibly important to us number two we",
    "start": "1345700",
    "end": "1351340"
  },
  {
    "text": "are number three sorry we wanted can't count number three we wanted to build a",
    "start": "1351340",
    "end": "1356470"
  },
  {
    "text": "common core or a common application kernel that would enable us to to",
    "start": "1356470",
    "end": "1362489"
  },
  {
    "text": "process events in varying different capacities so so kind of kind of what I talked about a little bit earlier our",
    "start": "1362489",
    "end": "1368769"
  },
  {
    "text": "initial implementation was a process based flow engine that that essentially",
    "start": "1368769",
    "end": "1375519"
  },
  {
    "text": "processed single events at any given time and then we we've expanded that going forward as well so one of the",
    "start": "1375519",
    "end": "1382479"
  },
  {
    "text": "elements is that we also needed to deploy anywhere so deploy on devices but",
    "start": "1382479",
    "end": "1388479"
  },
  {
    "text": "also deploy on serverless functions as well so flow go runs natively on AWS lambda so you can build an application",
    "start": "1388479",
    "end": "1394450"
  },
  {
    "text": "package it up deploy it on lambda take that exact same application package it up and push it on on an IOT device or",
    "start": "1394450",
    "end": "1400799"
  },
  {
    "text": "bundle it in a docker image and deploy it on k8s or something like that and then finally machine learning machine",
    "start": "1400799",
    "end": "1408309"
  },
  {
    "text": "learning was a a core pillar of the project and it was a core pillar of the project in the sense that we wanted to",
    "start": "1408309",
    "end": "1414489"
  },
  {
    "text": "build a set of tools that developers would consume to enable them to consume",
    "start": "1414489",
    "end": "1420249"
  },
  {
    "text": "ml models and techniques okay so it wasn't that we wanted to build and get",
    "start": "1420249",
    "end": "1425559"
  },
  {
    "text": "another tool for the data scientists but in fact we wanted to build a tool for software developers so that software",
    "start": "1425559",
    "end": "1431619"
  },
  {
    "text": "developers could then consume the the various ml models that people like gharam might build and in a spare time",
    "start": "1431619",
    "end": "1440610"
  },
  {
    "text": "so when you look at this so it's an ecosystem as I said right so when you look at this picture",
    "start": "1440610",
    "end": "1446970"
  },
  {
    "text": "you've got integration flows that we kind of talked about a little bit earlier you've also got stream processing you've got contextual rural",
    "start": "1446970",
    "end": "1453990"
  },
  {
    "text": "processing and you've got a micro gateway implementation so all of these various event processing capabilities",
    "start": "1453990",
    "end": "1461269"
  },
  {
    "text": "implemented within the flow go ecosystem that leverages the same common application kernel okay and by",
    "start": "1461269",
    "end": "1469350"
  },
  {
    "start": "1468000",
    "end": "1541000"
  },
  {
    "text": "leveraging the same common application kernel that allows us to consume and and",
    "start": "1469350",
    "end": "1474899"
  },
  {
    "text": "take advantage of the over 500 contributions that exist in github today",
    "start": "1474899",
    "end": "1480000"
  },
  {
    "text": "so all of the various contributions that other people have built and extended the",
    "start": "1480000",
    "end": "1486029"
  },
  {
    "text": "project with can be used in any single one of those event processing capabilities as well but just taking a",
    "start": "1486029",
    "end": "1492120"
  },
  {
    "text": "step back the common kernel also provides a powerful event-driven kind of",
    "start": "1492120",
    "end": "1498299"
  },
  {
    "text": "programming paradigm so from the ground up it was built to with this event-driven paradigm in mind you've got",
    "start": "1498299",
    "end": "1504870"
  },
  {
    "text": "this notion of both actions and and triggers as well ok so a trigger is what",
    "start": "1504870",
    "end": "1511260"
  },
  {
    "text": "produces the the data element so that could be a Kafka consumer okay so it's consuming messages off a Kafka topic and",
    "start": "1511260",
    "end": "1518850"
  },
  {
    "text": "then passing that over to an action and an action is implementing or processes that single event and an action can be a",
    "start": "1518850",
    "end": "1524909"
  },
  {
    "text": "stream processing action so you can consume thousands or millions or billions of events off of a Kafka topic",
    "start": "1524909",
    "end": "1530899"
  },
  {
    "text": "aggregate those over a period of time and do something with them or you can integrate every single individual event",
    "start": "1530899",
    "end": "1537269"
  },
  {
    "text": "depending on how you want to process the event itself so it's not Mario dressed",
    "start": "1537269",
    "end": "1544260"
  },
  {
    "start": "1541000",
    "end": "1630000"
  },
  {
    "text": "up as a bird or anything like that but but in fact if this is our this is our integration flows so so integration",
    "start": "1544260",
    "end": "1552179"
  },
  {
    "text": "flows as I said was kind of the first implementation of an action type okay",
    "start": "1552179",
    "end": "1558809"
  },
  {
    "text": "and this is this is fundamentally a process engine okay so it's a process",
    "start": "1558809",
    "end": "1564149"
  },
  {
    "text": "engine that was designed specifically for application integration but but you can leverage it in a lot of different capacities State",
    "start": "1564149",
    "end": "1571680"
  },
  {
    "text": "it does it can persist externalize state but typically speaking in the context of micro-services are function functions",
    "start": "1571680",
    "end": "1577980"
  },
  {
    "text": "most of the stuff is stateless you can do things like control flow implementation and things like that so",
    "start": "1577980",
    "end": "1584670"
  },
  {
    "text": "kind of control the the logic and implement procedural logic within your your application",
    "start": "1584670",
    "end": "1591420"
  },
  {
    "text": "but one of the other things that was important to us was that we wanted to reimagine the developer experience so a",
    "start": "1591420",
    "end": "1597030"
  },
  {
    "text": "couple years ago you take a look back at kind of the developer landscape and especially if you looked at the Java world you had things that that ran on",
    "start": "1597030",
    "end": "1604500"
  },
  {
    "text": "big beefy IDs you needed a gig of ram just to run the ide itself so we really",
    "start": "1604500",
    "end": "1610020"
  },
  {
    "text": "wanted to reimagine that experience as well and rather than having a thick client we built a web-based development",
    "start": "1610020",
    "end": "1615030"
  },
  {
    "text": "environment that web-based development environment supports unique features like like step back debugging so you",
    "start": "1615030",
    "end": "1621360"
  },
  {
    "text": "could debug your application and the web browser and you could step through the the activity and introspect the inputs",
    "start": "1621360",
    "end": "1627000"
  },
  {
    "text": "and outputs of each activity and things like that so when you look at the",
    "start": "1627000",
    "end": "1632280"
  },
  {
    "start": "1630000",
    "end": "1688000"
  },
  {
    "text": "process engine itself the the process engine does a couple things or it's designed to do a couple things so you",
    "start": "1632280",
    "end": "1638970"
  },
  {
    "text": "you build your or it orchestrates the execution of activities in an activity",
    "start": "1638970",
    "end": "1644400"
  },
  {
    "text": "is nothing more than a unit of work it's something to do okay so it's log a",
    "start": "1644400",
    "end": "1649500"
  },
  {
    "text": "message write something to a database publish something to Kafka read or write from a WebSocket server write to a",
    "start": "1649500",
    "end": "1656220"
  },
  {
    "text": "sequel database whatever the case is it's just a unit of work it does something so the the process engine",
    "start": "1656220",
    "end": "1663060"
  },
  {
    "text": "itself manages the execution of that so you can implement things like conditional logic and branching so you",
    "start": "1663060",
    "end": "1668520"
  },
  {
    "text": "can deviate the the execution flow in an order as well and and fundamentally it",
    "start": "1668520",
    "end": "1674880"
  },
  {
    "text": "does manage State there's an externalize state service that you could leverage that that would allow you to to do",
    "start": "1674880",
    "end": "1681600"
  },
  {
    "text": "things like if an engine were to shutdown it could it could startup and rehydrate from a certain point going",
    "start": "1681600",
    "end": "1686640"
  },
  {
    "text": "forward and things like that the the user interface looks something like this",
    "start": "1686640",
    "end": "1692690"
  },
  {
    "start": "1688000",
    "end": "1745000"
  },
  {
    "text": "so one of the unique elements of this particular interface is essentially everything in that grey area is",
    "start": "1692690",
    "end": "1698490"
  },
  {
    "text": "basically a function so if you go back to that initial concept of moving towards function development rather than",
    "start": "1698490",
    "end": "1704160"
  },
  {
    "text": "just microservices everything in that gray area is a function and you abstract the function call by defining it or function",
    "start": "1704160",
    "end": "1711520"
  },
  {
    "text": "input and output declaration so just like a function in any procedural programming language has both an input",
    "start": "1711520",
    "end": "1717100"
  },
  {
    "text": "and an output so does a flow go action ok the action has both an input and output and then",
    "start": "1717100",
    "end": "1723520"
  },
  {
    "text": "you can abstract away the triggers itself so I can have a Kafka trigger today I can put in a an mqtt trigger",
    "start": "1723520",
    "end": "1730420"
  },
  {
    "text": "tomorrow I can put in I don't know a physical general-purpose interface",
    "start": "1730420",
    "end": "1736480"
  },
  {
    "text": "trigger or something like that and consume off of an IOT device in a week from now without changing any application logic so flow go streams was",
    "start": "1736480",
    "end": "1748480"
  },
  {
    "start": "1745000",
    "end": "1790000"
  },
  {
    "text": "was something that we launched actually in September of this year and flow those",
    "start": "1748480",
    "end": "1754480"
  },
  {
    "text": "streams the the core purpose of this project initially set out as as ok so if",
    "start": "1754480",
    "end": "1760059"
  },
  {
    "text": "we're processing a set of IOT data or data off of sensors we need a oftentimes",
    "start": "1760059",
    "end": "1765070"
  },
  {
    "text": "that the data itself is far too granular so we need to aggregate the data and kind of up level it a couple levels so",
    "start": "1765070",
    "end": "1771429"
  },
  {
    "text": "we initially set out to build flow go streams and flow go streams provides a",
    "start": "1771429",
    "end": "1776500"
  },
  {
    "text": "couple key capabilities for for that particular mission which is both data aggregation provides grouping and",
    "start": "1776500",
    "end": "1783190"
  },
  {
    "text": "joining against multiple data streams and then also allows you to filter out any noise or any unwanted data elements",
    "start": "1783190",
    "end": "1789610"
  },
  {
    "text": "or events so when you think about the grouping and joining this is incredibly powerful so if you have the concept of",
    "start": "1789610",
    "end": "1795970"
  },
  {
    "start": "1790000",
    "end": "1828000"
  },
  {
    "text": "Kafka MQTT and that GPIO interface that I talked about producing events you can",
    "start": "1795970",
    "end": "1801400"
  },
  {
    "text": "group off of an element within the the payload of every single one of those",
    "start": "1801400",
    "end": "1806800"
  },
  {
    "text": "events group off of that element and then pass it and do that single stream pipeline so that you can aggregate",
    "start": "1806800",
    "end": "1813520"
  },
  {
    "text": "across event or cross event sources as well so you so incredibly powerful the",
    "start": "1813520",
    "end": "1820420"
  },
  {
    "text": "ability to both both jute grope sorry group and join off of off of those",
    "start": "1820420",
    "end": "1826210"
  },
  {
    "text": "events but also data aggregation so data",
    "start": "1826210",
    "end": "1831910"
  },
  {
    "start": "1828000",
    "end": "1864000"
  },
  {
    "text": "aggregation is clearly something that's pretty important from from from a stream processing perspective",
    "start": "1831910",
    "end": "1838360"
  },
  {
    "text": "so we support a number of different elements so we support both tumbling and sliding windows you could do time",
    "start": "1838360",
    "end": "1844659"
  },
  {
    "text": "tumbling or event-based tumbling windows and sliding windows and then from a function perspective at the",
    "start": "1844659",
    "end": "1850570"
  },
  {
    "text": "end of that aggregation window you can do an average of some a min max account or you can accumulate it so in other",
    "start": "1850570",
    "end": "1856899"
  },
  {
    "text": "words accumulate it into an array and then process that array later down the down the execution pipeline and then",
    "start": "1856899",
    "end": "1865840"
  },
  {
    "start": "1864000",
    "end": "1933000"
  },
  {
    "text": "lastly that brings us to flow go rules so flow go rules is our contextual",
    "start": "1865840",
    "end": "1872460"
  },
  {
    "text": "decisioning engine that's built on top of the same application kernel and that's part of the ecosystem okay so one",
    "start": "1872460",
    "end": "1881350"
  },
  {
    "text": "of the use cases with flow go rules is that is that classic event processing use case right so you you consume in you",
    "start": "1881350",
    "end": "1887950"
  },
  {
    "text": "consume events maybe you you've there's nothing to do with the events that come in so you persist those events in the",
    "start": "1887950",
    "end": "1893500"
  },
  {
    "text": "memory which we call a fact so you you persist them as a known fact",
    "start": "1893500",
    "end": "1898510"
  },
  {
    "text": "and then as new events come in you can group those new events and join those new events off of those the the known",
    "start": "1898510",
    "end": "1905049"
  },
  {
    "text": "facts that already sit in memory and then and then you can take action based",
    "start": "1905049",
    "end": "1910240"
  },
  {
    "text": "on that so the classic example is fraud right so if I use my credit card here in Las Vegas today that's probably fine",
    "start": "1910240",
    "end": "1917559"
  },
  {
    "text": "depends where but it's probably fine and if I use my credit card tomorrow and or in an hour from now in San Francisco",
    "start": "1917559",
    "end": "1925299"
  },
  {
    "text": "that that doesn't sound right so that's the classic example of contextual",
    "start": "1925299",
    "end": "1930330"
  },
  {
    "text": "deterministic processing so shifting",
    "start": "1930330",
    "end": "1936130"
  },
  {
    "text": "gears just a little bit so I said machine learning was a core pillar or a core construct of of the framework",
    "start": "1936130",
    "end": "1942010"
  },
  {
    "text": "entirely so we support natively tensorflow within within the within our",
    "start": "1942010",
    "end": "1948309"
  },
  {
    "text": "application you're the applications that you build with in flow go so any application that you build whether it's a stream processing app and integration",
    "start": "1948309",
    "end": "1954940"
  },
  {
    "text": "app a rules app whatever you can leverage the tensorflow inferencing capabilities and again that's all open",
    "start": "1954940",
    "end": "1961690"
  },
  {
    "text": "source and the way we built the tensorflow inferencing capabilities was was kind of in a modular form so we",
    "start": "1961690",
    "end": "1969399"
  },
  {
    "start": "1962000",
    "end": "2017000"
  },
  {
    "text": "initially set out so he built a a generic model and framework implementation or representation and then we have so we",
    "start": "1969399",
    "end": "1975910"
  },
  {
    "text": "abstracted away the the tensorflow details from the from flow NGO itself and then we built the the native flow go",
    "start": "1975910",
    "end": "1983290"
  },
  {
    "text": "implementation on top of that those interfaces but that does allow you to leverage maybe MX net in the future or",
    "start": "1983290",
    "end": "1990370"
  },
  {
    "text": "something like that but to be quite honest with you I mean our tensor flow has kind of become the de facto standard when it comes to deep",
    "start": "1990370",
    "end": "1997900"
  },
  {
    "text": "learning frameworks and and I'm quite comfortable with with our tensor flow implementation at the moment but that",
    "start": "1997900",
    "end": "2003060"
  },
  {
    "text": "doesn't mean someone in the community couldn't build MX net or something like that later as well so how many people",
    "start": "2003060",
    "end": "2009540"
  },
  {
    "text": "use tensor flow today it's a fair bit awesome ok so then in that case you'd be",
    "start": "2009540",
    "end": "2020010"
  },
  {
    "start": "2017000",
    "end": "2066000"
  },
  {
    "text": "familiar with the concept for an intensive flow has this concept of of saved model metadata so when you build a",
    "start": "2020010",
    "end": "2026010"
  },
  {
    "text": "model and you export the model the the metadata is essentially a definition of what that model does right so what is",
    "start": "2026010",
    "end": "2032880"
  },
  {
    "text": "the what is the input to the model so what is the feature set that it expects and what's the output of the model as",
    "start": "2032880",
    "end": "2038910"
  },
  {
    "text": "well okay so the the flow go implementation abstract all this and then leverages this for both validation",
    "start": "2038910",
    "end": "2044700"
  },
  {
    "text": "as well as as well as parsing data back and forth between between the raw",
    "start": "2044700",
    "end": "2050580"
  },
  {
    "text": "tensors and the the flow go object types themselves so I'm not going to get into a ton of data on this it's a little bit",
    "start": "2050580",
    "end": "2056700"
  },
  {
    "text": "boring and a ton of text so I'll let him finish his picture and move on ok",
    "start": "2056700",
    "end": "2066879"
  },
  {
    "text": "so so the everyone here that that's use tensorflow you know that you can operate",
    "start": "2066880",
    "end": "2071929"
  },
  {
    "text": "tensorflow at multiple different levels so you can operate tensorflow at the raw graft level to and to be quite honest",
    "start": "2071930",
    "end": "2078230"
  },
  {
    "text": "that that's that's a bit of a bit of an annoyance right being a it requires a",
    "start": "2078230",
    "end": "2084740"
  },
  {
    "text": "lot of boilerplate Python code and just lots and lots of code to build up your your complex graph so but a year and a",
    "start": "2084740",
    "end": "2094070"
  },
  {
    "text": "half ago something like that a year and a half ago tensorflow launched the the estimator package and the estimators has",
    "start": "2094070",
    "end": "2100610"
  },
  {
    "text": "a bunch of different benefits that albarran will go into detail with in just a few minutes but what really from",
    "start": "2100610",
    "end": "2106700"
  },
  {
    "text": "from our initial perspective was that it abstract away a lot of that so you can leverage the tensor or the estimator",
    "start": "2106700",
    "end": "2112580"
  },
  {
    "text": "package you get these pre-made estimators so things like DNA and classifiers regressors linear regress",
    "start": "2112580",
    "end": "2118280"
  },
  {
    "text": "classifiers things like that all come out of the box and you can build your own estimator as well and then leverage",
    "start": "2118280",
    "end": "2125660"
  },
  {
    "text": "that within the the same framework and then the exported output of the and flow models all fall into that save model",
    "start": "2125660",
    "end": "2132170"
  },
  {
    "text": "format which makes it easy to parse and manipulate so I'm kind of alluded to",
    "start": "2132170",
    "end": "2138830"
  },
  {
    "start": "2135000",
    "end": "2233000"
  },
  {
    "text": "this a little bit but if you talk in the context of IOT why why do you want to",
    "start": "2138830",
    "end": "2144770"
  },
  {
    "text": "place ml at the at the IOT edge right so I would also argue that in many sense in",
    "start": "2144770",
    "end": "2150950"
  },
  {
    "text": "many cases you actually hear the phrase IOT being replaced with edge compute and",
    "start": "2150950",
    "end": "2156470"
  },
  {
    "text": "I'd argue that that that's probably happening because these devices are becoming more and more smart right",
    "start": "2156470",
    "end": "2161900"
  },
  {
    "text": "they're becoming just powerful enough that they can apply some elements of smarts without needing to rely solely on",
    "start": "2161900",
    "end": "2168320"
  },
  {
    "text": "the cloud I mean if you look at some of the stuff that that green grass provides then then you can see that being able to",
    "start": "2168320",
    "end": "2175220"
  },
  {
    "text": "run app logic at the edge leveraging a framework like green grass pushing out models leveraging an application",
    "start": "2175220",
    "end": "2180920"
  },
  {
    "text": "framework like flow go to build your applications that then running green grass is pretty is pretty powerful so so",
    "start": "2180920",
    "end": "2186500"
  },
  {
    "text": "back to the initial question is why do UML at the edge well data volumes right so it's kind of like we talked about at the very",
    "start": "2186500",
    "end": "2192200"
  },
  {
    "text": "beginning of this presentation data volumes are continuing to grow and oftentimes being able to stream that",
    "start": "2192200",
    "end": "2198410"
  },
  {
    "text": "back to the cloud and then that's all at the cloud I mean you'd be streaming back massive amounts of data",
    "start": "2198410",
    "end": "2203670"
  },
  {
    "text": "so theoretically moving ML logic and inferencing to the edge you could theoretically reduce your ingress costs",
    "start": "2203670",
    "end": "2209970"
  },
  {
    "text": "alone by by a considerable amount and then also also the the predictions",
    "start": "2209970",
    "end": "2216869"
  },
  {
    "text": "are closer to the source of data as well so being able to predict and take action",
    "start": "2216869",
    "end": "2222420"
  },
  {
    "text": "at the source also reduces any sort of prediction latency that might occur if you were dependent solely on the cloud",
    "start": "2222420",
    "end": "2229050"
  },
  {
    "text": "for for inferencing so we do have a demo",
    "start": "2229050",
    "end": "2235550"
  },
  {
    "start": "2233000",
    "end": "2312000"
  },
  {
    "text": "I'm gonna pass it over to Rahm in just a second so so the demo itself is",
    "start": "2235550",
    "end": "2241700"
  },
  {
    "text": "interesting in the sense that what we did was we built a we took a Raspberry",
    "start": "2241700",
    "end": "2247980"
  },
  {
    "text": "Pi in fact I've got the I've got the Raspberry Pi right here so we took the Raspberry Pi stuffed it into a box and",
    "start": "2247980",
    "end": "2254760"
  },
  {
    "text": "then we said what if we could attach an accelerometer to the Raspberry Pi and what if the accelerometer could pass",
    "start": "2254760",
    "end": "2261150"
  },
  {
    "text": "pass its readings into the flow go application and then into a tensor flow model could we predict what's happening",
    "start": "2261150",
    "end": "2268590"
  },
  {
    "text": "to the box fast enough so that it appears to be occurring in real time and it turns out the answer is yes so I'll",
    "start": "2268590",
    "end": "2274980"
  },
  {
    "text": "show you this in just a few minutes for now I'm going to pass it over to Brahm to talk you know to actually talk the details okay so I'm gonna talk a little",
    "start": "2274980",
    "end": "2286950"
  },
  {
    "text": "bit of building the machine learning model that went into our box and",
    "start": "2286950",
    "end": "2292280"
  },
  {
    "text": "basically what this model needs to be able to do is to predict or to label",
    "start": "2292280",
    "end": "2298220"
  },
  {
    "text": "when the box is standing still moving or",
    "start": "2298220",
    "end": "2303450"
  },
  {
    "text": "when it has been dropped and here you see three examples one for each of those",
    "start": "2303450",
    "end": "2308760"
  },
  {
    "text": "cases oh wait now it's important to be",
    "start": "2308760",
    "end": "2315420"
  },
  {
    "start": "2312000",
    "end": "2381000"
  },
  {
    "text": "doing to label your data correctly so as you can see for the moving and stationary it's pretty easy for that",
    "start": "2315420",
    "end": "2322070"
  },
  {
    "text": "data set that we have the whole thing is moving the whole thing is stationary but for the drop it's more complicated you",
    "start": "2322070",
    "end": "2328650"
  },
  {
    "text": "can actually see by eye is a human being you can identify where the drop occurs it's the obvious right but then you need to",
    "start": "2328650",
    "end": "2336140"
  },
  {
    "text": "know what's happening before that is that moving is it stationary afterwards and this so this greatly complicates",
    "start": "2336140",
    "end": "2343970"
  },
  {
    "text": "some of our model building so basically what I've done for this case is I",
    "start": "2343970",
    "end": "2349160"
  },
  {
    "text": "actually went and looked at our several drop examples and by hand drew the",
    "start": "2349160",
    "end": "2355339"
  },
  {
    "text": "barrier lines now you'll see when I train the model that this ends up",
    "start": "2355339",
    "end": "2360829"
  },
  {
    "text": "causing to have a little bit of noise on either boundary so we'll see a little",
    "start": "2360829",
    "end": "2366019"
  },
  {
    "text": "bit of bouncing around of what the label is but for the most part that only happens at these boundaries because it's",
    "start": "2366019",
    "end": "2372740"
  },
  {
    "text": "ambiguous and even the human being has a hard time to draw of drawing where these lines happen exactly and so here I",
    "start": "2372740",
    "end": "2383269"
  },
  {
    "start": "2381000",
    "end": "2472000"
  },
  {
    "text": "quickly I apologize for the colors I'm just trying to make sure you guys are awake at this time of the day but",
    "start": "2383269",
    "end": "2389749"
  },
  {
    "text": "basically I end up creating a test train split of our data I will talk a little",
    "start": "2389749",
    "end": "2395210"
  },
  {
    "text": "bit about more than in a minute then I put this into a tensor flow estimator and end up putting that into our model",
    "start": "2395210",
    "end": "2404809"
  },
  {
    "text": "and we get about 90% accuracy for our labels however that's when I put in oops",
    "start": "2404809",
    "end": "2411499"
  },
  {
    "text": "sorry wrong direction that's when I actually labeled the left-hand part of the drop as moving and",
    "start": "2411499",
    "end": "2417049"
  },
  {
    "text": "the right-hand part as stationary when I leave those ambiguous regions off I actually pump up my accuracy to about",
    "start": "2417049",
    "end": "2424430"
  },
  {
    "text": "90% now part of that is because I am leaving out the cup of the messy",
    "start": "2424430",
    "end": "2429499"
  },
  {
    "text": "portions but also part of that is I'm improving my estimation such that I actually know discretely what what each",
    "start": "2429499",
    "end": "2437869"
  },
  {
    "text": "region is now I want to point out the estimator portion of this slide because",
    "start": "2437869",
    "end": "2445339"
  },
  {
    "text": "this is where it actually becomes very useful to use with sage maker because the estimator in tensorflow actually",
    "start": "2445339",
    "end": "2452539"
  },
  {
    "text": "extracts out or sorry abstracts out all the complications of mapping it to a GPU",
    "start": "2452539",
    "end": "2458839"
  },
  {
    "text": "versus CPU and doing a lot of the more complicated things that you can do when you build the graph yourself the",
    "start": "2458839",
    "end": "2465499"
  },
  {
    "text": "estimator does this all for you so when you go to Sage maker which I can go ahead and do here so here I have my",
    "start": "2465499",
    "end": "2475380"
  },
  {
    "start": "2472000",
    "end": "2536000"
  },
  {
    "text": "instances set up and I will go now I've already created the tab but I will go to my notebook or sorry my jupiter server",
    "start": "2475380",
    "end": "2484369"
  },
  {
    "text": "where i've already set up i think a nymph or something instance to run my",
    "start": "2484369",
    "end": "2491460"
  },
  {
    "text": "super notebook however i can choose something much larger than this if my model ends up being huge and the",
    "start": "2491460",
    "end": "2498270"
  },
  {
    "text": "estimator basically covers any complications and such that between the",
    "start": "2498270",
    "end": "2503579"
  },
  {
    "text": "estimator and sage maker i don't have to worry about GPUs versus cpus i just",
    "start": "2503579",
    "end": "2509790"
  },
  {
    "text": "select the larger model and then allow the tensorflow estimators are sorry the larger seat compute unit and i can allow",
    "start": "2509790",
    "end": "2518760"
  },
  {
    "text": "estimator from tensorflow to handle all the complications for me and so from",
    "start": "2518760",
    "end": "2523770"
  },
  {
    "text": "there I end up I have a notebook here for running and training my data and as",
    "start": "2523770",
    "end": "2529109"
  },
  {
    "text": "you can see I basically I will actually go ahead and create a terminal which is",
    "start": "2529109",
    "end": "2537329"
  },
  {
    "start": "2536000",
    "end": "2567000"
  },
  {
    "text": "one of the nice things about sage maker and I can go into my sis I'm not",
    "start": "2537329",
    "end": "2544230"
  },
  {
    "text": "selected on that there I can go into the sage maker directory and you can see this is just like my Jupiter servant and",
    "start": "2544230",
    "end": "2554180"
  },
  {
    "text": "I have all my data list I have all my",
    "start": "2554180",
    "end": "2560309"
  },
  {
    "text": "data in a all my data in this directory which I have unzipped using this",
    "start": "2560309",
    "end": "2566460"
  },
  {
    "text": "terminal previously from there I actually define my boundaries for my",
    "start": "2566460",
    "end": "2573569"
  },
  {
    "start": "2567000",
    "end": "2630000"
  },
  {
    "text": "drop so each of these this dictionary that I'm creating is basically just drawing the lines by hand so that I",
    "start": "2573569",
    "end": "2580740"
  },
  {
    "text": "don't have to worry about that later and then I basically process the file where",
    "start": "2580740",
    "end": "2587880"
  },
  {
    "text": "I take the XYZ accelerometer readings and I create the magnitude so for every",
    "start": "2587880",
    "end": "2594839"
  },
  {
    "text": "time period I have three accelerometer readings for each direction and then I the magnitude and from that I'm plotting",
    "start": "2594839",
    "end": "2602290"
  },
  {
    "text": "the magnitude for each of my files so this is one that's moving this is one of",
    "start": "2602290",
    "end": "2607360"
  },
  {
    "text": "my drop examples so on and so forth and the vertical lines are where I define the drop regions to event it and I do",
    "start": "2607360",
    "end": "2616810"
  },
  {
    "text": "this so a couple times so that you can see the graphs nice and pretty and as you can see unlike my earlier example",
    "start": "2616810",
    "end": "2622570"
  },
  {
    "text": "the sitting is actually scaled to everything else so it actually is stationary opposed to a lot of the",
    "start": "2622570",
    "end": "2629230"
  },
  {
    "text": "jiggle you saw earlier from there I actually need to do the same aggregation",
    "start": "2629230",
    "end": "2635920"
  },
  {
    "text": "that inflow go we do with the streaming engine so basically we take the previous 10 time steps for any given time step",
    "start": "2635920",
    "end": "2643570"
  },
  {
    "text": "and add that to our rows so for every time step we have the current X Y C",
    "start": "2643570",
    "end": "2650230"
  },
  {
    "text": "acceleration the magnitude of the acceleration and then I have the next",
    "start": "2650230",
    "end": "2655660"
  },
  {
    "text": "one over time - one time - - so on and so forth so I ended up having 44",
    "start": "2655660",
    "end": "2661900"
  },
  {
    "text": "features for every time step the nice thing about this is I have now basically extracted out time so it's not dependent",
    "start": "2661900",
    "end": "2669220"
  },
  {
    "text": "of my each column sorry each row is not dependent on the rows around it because I've already taken care of that so I can",
    "start": "2669220",
    "end": "2675490"
  },
  {
    "text": "now just shuffle and take a test train split from this data and sorry here's",
    "start": "2675490",
    "end": "2683020"
  },
  {
    "start": "2681000",
    "end": "2727000"
  },
  {
    "text": "where I actually apply my function and then I label the data because that's useful oh and I am leaving out one more",
    "start": "2683020",
    "end": "2691390"
  },
  {
    "text": "important here I take my test train",
    "start": "2691390",
    "end": "2696760"
  },
  {
    "text": "split but before that I actually choose one of my drop files such that it is not",
    "start": "2696760",
    "end": "2702130"
  },
  {
    "text": "included in the training set such that I can or the evaluation set so I can show",
    "start": "2702130",
    "end": "2708520"
  },
  {
    "text": "you the results of some data that it is never seen before and we can see how it",
    "start": "2708520",
    "end": "2713650"
  },
  {
    "text": "works and I realize that I actually forgot to run all here so it's going to be running",
    "start": "2713650",
    "end": "2719110"
  },
  {
    "text": "well I talked and so that's what I'm doing here is my extracting out one file",
    "start": "2719110",
    "end": "2726430"
  },
  {
    "text": "and then I do a little bit of overhead where I define which directory I want my",
    "start": "2726430",
    "end": "2732640"
  },
  {
    "start": "2727000",
    "end": "2804000"
  },
  {
    "text": "estimator to save the training data the training checkpoints from and I'd also defined",
    "start": "2732640",
    "end": "2740480"
  },
  {
    "text": "the size of my of my model so basically the estimator I'm using is called a deep",
    "start": "2740480",
    "end": "2746720"
  },
  {
    "text": "neural network which is basically just a standard fully connected multi-layer neural network that is one of the",
    "start": "2746720",
    "end": "2754220"
  },
  {
    "text": "estimators provided by tensorflow in this case I was trying to use an example",
    "start": "2754220",
    "end": "2759559"
  },
  {
    "text": "that use one of their pre-built estimators however if you wish you can also build your own model export this",
    "start": "2759559",
    "end": "2767299"
  },
  {
    "text": "into an estimator and so you can still get the benefits of sage maker with the parallelization across all the units",
    "start": "2767299",
    "end": "2774470"
  },
  {
    "text": "with your hand built models and in my case the DNN starts off with the first",
    "start": "2774470",
    "end": "2781819"
  },
  {
    "text": "layer with 100 nodes wide and then second layer is 40 nodes wide and then",
    "start": "2781819",
    "end": "2787730"
  },
  {
    "text": "since I am making a prediction of three objects moving standing still and",
    "start": "2787730",
    "end": "2793369"
  },
  {
    "text": "dropped I have three nodes from my last case it is now training I then end up",
    "start": "2793369",
    "end": "2800500"
  },
  {
    "text": "saving my model which is sort of interesting let's see where am I here so",
    "start": "2800500",
    "end": "2808759"
  },
  {
    "start": "2804000",
    "end": "2899000"
  },
  {
    "text": "in my models directory I end up getting a lot of the checkpoint information but",
    "start": "2808759",
    "end": "2815150"
  },
  {
    "text": "I also end up getting this timestamp directory which I will also point out",
    "start": "2815150",
    "end": "2820430"
  },
  {
    "text": "and here I get one file and one directory the file the saved model pbx",
    "start": "2820430",
    "end": "2829039"
  },
  {
    "text": "txt is the format you need to put into flow go so basically this has all the",
    "start": "2829039",
    "end": "2836769"
  },
  {
    "text": "descriptions of the neural network and all that metadata that Matt was talking",
    "start": "2836769",
    "end": "2841819"
  },
  {
    "text": "about earlier variables then has all the values of all the variables that are",
    "start": "2841819",
    "end": "2847819"
  },
  {
    "text": "included in that neural network so here is where all you basically once I'm in",
    "start": "2847819",
    "end": "2855079"
  },
  {
    "text": "that directory I just zip - are",
    "start": "2855079",
    "end": "2859990"
  },
  {
    "text": "and then I put in the ones I want and of",
    "start": "2863190",
    "end": "2869620"
  },
  {
    "text": "course it computer froze on me for a sec I then zip this with the variables and",
    "start": "2869620",
    "end": "2876730"
  },
  {
    "text": "this provides a zip file that you just put into your flow go app so basically",
    "start": "2876730",
    "end": "2882040"
  },
  {
    "text": "when you build your flow go app you just put this in the same directory as the app and that's all you need to do to",
    "start": "2882040",
    "end": "2888640"
  },
  {
    "text": "transfer your model across okay and okay",
    "start": "2888640",
    "end": "2895780"
  },
  {
    "text": "I because of the lag I screwed that up up but you get the idea so once I have",
    "start": "2895780",
    "end": "2903160"
  },
  {
    "start": "2899000",
    "end": "3039000"
  },
  {
    "text": "saved the model and then I can zip it and move it to flow go I evaluate it and",
    "start": "2903160",
    "end": "2908200"
  },
  {
    "text": "that accuracy is 1% I must 100% so I'm doing really good or",
    "start": "2908200",
    "end": "2913300"
  },
  {
    "text": "I made a mistake along the way and which is what I'm probably figuring is the",
    "start": "2913300",
    "end": "2918460"
  },
  {
    "text": "case but so you can do the evaluation but then that's from my 20% test split",
    "start": "2918460",
    "end": "2927250"
  },
  {
    "text": "but if I go and look at my extra dataset I can see here that I have in blue is",
    "start": "2927250",
    "end": "2934330"
  },
  {
    "text": "the accelerometer reading and you can see the region that should be a drop is labeled as such so having a value of 2",
    "start": "2934330",
    "end": "2942250"
  },
  {
    "text": "on the right for orange and green is drop so for the labels data it starts",
    "start": "2942250",
    "end": "2950560"
  },
  {
    "text": "off with a little bit of motion and then it jumps to dropped for the predicted",
    "start": "2950560",
    "end": "2956470"
  },
  {
    "text": "data it's showing that it's already acting pretty heavily and so it's calling it a drop from the beginning",
    "start": "2956470",
    "end": "2961980"
  },
  {
    "text": "then there's a little bit of noise around the transition from the drop to stationery but that's actually pretty",
    "start": "2961980",
    "end": "2970210"
  },
  {
    "text": "reasonable because I mean I have a hard time drawing what that line was I probably spent half an hour trying to",
    "start": "2970210",
    "end": "2976300"
  },
  {
    "text": "find where it was the most obvious and it's actually quite difficult to do so I",
    "start": "2976300",
    "end": "2983010"
  },
  {
    "text": "think this ends up showing that the model end up working pretty well and so",
    "start": "2983010",
    "end": "2988380"
  },
  {
    "text": "that is where my part of the demo ends and I will hand it off to Matt and hopefully he'll be able to demonstrate",
    "start": "2988380",
    "end": "2995770"
  },
  {
    "text": "actually what the end result is thanks from ya let's let's go ahead and so so",
    "start": "2995770",
    "end": "3001470"
  },
  {
    "text": "essentially what happened was while he was talking he trained the model in Sage maker and it finished before he was",
    "start": "3001470",
    "end": "3007110"
  },
  {
    "text": "finished talking so either he talks really long or sage maker actually treating the model pretty quickly probably the first okay so I talked",
    "start": "3007110",
    "end": "3015990"
  },
  {
    "text": "about this box so sorry for the the noise here I'm gonna just tape the box up so I don't lose my my Raspberry Pi",
    "start": "3015990",
    "end": "3021630"
  },
  {
    "text": "here I'll tape it up and we'll show you what what you can do here and and again",
    "start": "3021630",
    "end": "3027390"
  },
  {
    "text": "sorry we budget constraints we we didn't have money for scissors so okay thank",
    "start": "3027390",
    "end": "3035370"
  },
  {
    "text": "you sir alright let me go ahead and start this up so right now I've got a",
    "start": "3035370",
    "end": "3041840"
  },
  {
    "start": "3039000",
    "end": "3132000"
  },
  {
    "text": "shell open up to the the pie that's in the box so I don't have it running all the time so I'll go ahead and just start",
    "start": "3041840",
    "end": "3047790"
  },
  {
    "text": "it up it will start up the demo there's a what's happening is it's streaming data over to a WebSocket server with the",
    "start": "3047790",
    "end": "3054260"
  },
  {
    "text": "prediction so as I'm walking you can see the cartoon starts walking if I stop the cartoon will stop right but if I walk",
    "start": "3054260",
    "end": "3061290"
  },
  {
    "text": "some more the cartoon will walk some more so what's happening is that the data is being streamed off of the",
    "start": "3061290",
    "end": "3067260"
  },
  {
    "text": "accelerometer into into flow go and flow goes identifying what it is that that's",
    "start": "3067260",
    "end": "3072630"
  },
  {
    "text": "happening right using the tensor flow model that that album talked about but there's another key bit so if I set the box down with the box also does is it",
    "start": "3072630",
    "end": "3079530"
  },
  {
    "text": "uses the rules engine to to correlate against historical events so it knows that it's sitting it's keeping the",
    "start": "3079530",
    "end": "3085620"
  },
  {
    "text": "context of the the event itself and then after 15 seconds it can identify that it",
    "start": "3085620",
    "end": "3090900"
  },
  {
    "text": "hasn't moved when it should have and the box will start screaming at you okay so",
    "start": "3090900",
    "end": "3098100"
  },
  {
    "text": "even even further if I if I pick up the box and I show you another example so you saw that Abraham talked about the",
    "start": "3098100",
    "end": "3104220"
  },
  {
    "text": "dropping right so what if I take the box and I throw it then the cartoon will",
    "start": "3104220",
    "end": "3109560"
  },
  {
    "text": "also identify that it's its own and I probably shouldn't have thrown it so far",
    "start": "3109560",
    "end": "3114800"
  },
  {
    "text": "but it looks like it still works there we go so so all of that coming off of",
    "start": "3114800",
    "end": "3121200"
  },
  {
    "text": "the accelerometer being passed into flow though okay so again just will drop the box and then I'm gonna switch over to",
    "start": "3121200",
    "end": "3128100"
  },
  {
    "text": "the slide deck which is button here thank you okay let's let's",
    "start": "3128100",
    "end": "3135690"
  },
  {
    "text": "talk a little bit about that so what's actually happening is the there's an accelerometer attached to the Raspberry",
    "start": "3135690",
    "end": "3141750"
  },
  {
    "text": "Pi the accelerometer is producing three thousand data points per second okay so",
    "start": "3141750",
    "end": "3146940"
  },
  {
    "text": "it's producing an X Y Z value for essentially every millisecond what",
    "start": "3146940",
    "end": "3153510"
  },
  {
    "text": "what's happening is that's being fed straight into a flow go streaming application so we built a trigger that",
    "start": "3153510",
    "end": "3160230"
  },
  {
    "text": "that reads directly off of the ad excel three four five accelerometer we feed that into a stream pipeline the stream",
    "start": "3160230",
    "end": "3167160"
  },
  {
    "text": "stream pipeline in real time is aggregating the data over 50 millisecond windows and then it's passing it over to",
    "start": "3167160",
    "end": "3173910"
  },
  {
    "text": "another aggregate operation which is lagging the data so so Abram and I were",
    "start": "3173910",
    "end": "3179040"
  },
  {
    "text": "talking about this this morning and apparently I did it exact opposite of what he was expecting me to do but the",
    "start": "3179040",
    "end": "3184050"
  },
  {
    "text": "work so what i'm doing here is is aggregating the data but doing it in a tumbling window and collecting ten",
    "start": "3184050",
    "end": "3191430"
  },
  {
    "text": "events so so basically every half-second the machine learning model ends up inferencing so the tensorflow DNN ends",
    "start": "3191430",
    "end": "3198720"
  },
  {
    "text": "up being inference TEVAR ii half-second the result of the classification of that inference is passed over to the rules",
    "start": "3198720",
    "end": "3204960"
  },
  {
    "text": "engine okay the flow go rules engine that's that's running on device as well that's collecting in that event it's",
    "start": "3204960",
    "end": "3211980"
  },
  {
    "text": "it's persisting the current state of the box and then it's waiting for the state",
    "start": "3211980",
    "end": "3217080"
  },
  {
    "text": "to change using using various different timer triggers and things like that waiting for the state to change if it",
    "start": "3217080",
    "end": "3223290"
  },
  {
    "text": "doesn't change within a certain predefined window the rules engine kicks off a series of rules executes so series",
    "start": "3223290",
    "end": "3229410"
  },
  {
    "text": "of rules and then passes over to a flow so the flow application then just simply",
    "start": "3229410",
    "end": "3236670"
  },
  {
    "text": "logs the data so if you looked at my consoles there's got a huge set of logs log data entries and then there's a",
    "start": "3236670",
    "end": "3243570"
  },
  {
    "text": "WebSocket message outbound to the cartoon that you just saw and all of that is running on the flow go",
    "start": "3243570",
    "end": "3249869"
  },
  {
    "text": "application so the flow go application itself is ten megabytes in size okay we're actually sorry just under ten",
    "start": "3249869",
    "end": "3255420"
  },
  {
    "text": "megabytes so just under ten megabytes in size running on the Raspberry Pi taking in 3,000 data readings per second",
    "start": "3255420",
    "end": "3263010"
  },
  {
    "start": "3263000",
    "end": "3600000"
  },
  {
    "text": "so clearly you want to get started with this right now I'm sure you're gonna run",
    "start": "3263010",
    "end": "3269530"
  },
  {
    "text": "and do it immediately so you can you can go to our github page so tip github comm TIBCO software slash flow go in the",
    "start": "3269530",
    "end": "3277600"
  },
  {
    "text": "examples directory we've got a couple examples of Python notebooks and things like that that you could pull and you could bring into safe maker or you can",
    "start": "3277600",
    "end": "3283390"
  },
  {
    "text": "go to the sage maker github page and look at some of the examples there and then sage maker has a free tier as well",
    "start": "3283390",
    "end": "3289300"
  },
  {
    "text": "and you could leverage that also so with that any questions yes sir I think we",
    "start": "3289300",
    "end": "3300640"
  },
  {
    "text": "might need a mic though otherwise no one else is gonna hear you I can repeat it if you go ahead what is the memory and",
    "start": "3300640",
    "end": "3314470"
  },
  {
    "text": "CPU of the raspberry pi the raspberry pi is a PI 3 B but we've run it on a PI 0",
    "start": "3314470",
    "end": "3319930"
  },
  {
    "text": "as well the footprint or the the SD card is is a it's a 32 gigabyte SD card but",
    "start": "3319930",
    "end": "3326410"
  },
  {
    "text": "the application itself is only ten megabytes in size sorry he had the question let me just get in",
    "start": "3326410",
    "end": "3334290"
  },
  {
    "text": "Apache knife I well I mean it's it's radically different so flow goes is",
    "start": "3340420",
    "end": "3346040"
  },
  {
    "text": "built entirely and go so it's going baits though it's it's you know producer statically compiled binaries the from an",
    "start": "3346040",
    "end": "3353450"
  },
  {
    "text": "event processing perspective there there are clearly a lot more event processing capabilities that that flow go can can",
    "start": "3353450",
    "end": "3359810"
  },
  {
    "text": "accomplish as well so it's not just streaming flow go can implement a lot of other capabilities plus the native ml",
    "start": "3359810",
    "end": "3365240"
  },
  {
    "text": "inferencing stuff but happy to jump into a deeper discussion if you stopped by the TIBCO booth later this afternoon in",
    "start": "3365240",
    "end": "3372140"
  },
  {
    "text": "the exhibit hall as well yes sir",
    "start": "3372140",
    "end": "3376450"
  },
  {
    "text": "so so a couple of things so we wanted to do more than oh sorry the question was what what why use an accelerometer and",
    "start": "3393869",
    "end": "3402310"
  },
  {
    "text": "rather than just just bounding the the the edge why doing why do a machine",
    "start": "3402310",
    "end": "3408280"
  },
  {
    "text": "learning model instead of just two heading balances boundary detection yeah so so this case so why an ml model",
    "start": "3408280",
    "end": "3414670"
  },
  {
    "text": "rather than just boundary detection the answers is rather simple so so we wanted",
    "start": "3414670",
    "end": "3420340"
  },
  {
    "text": "to do more with the data than just detective drop we also want to detect the the the general movement and then",
    "start": "3420340",
    "end": "3426730"
  },
  {
    "text": "potentially the the lack of the data so so that that's that's why we chose that's why we chose the ml model unless",
    "start": "3426730",
    "end": "3433540"
  },
  {
    "text": "you have anything else dad really the so I did look at that I mean we were hoping",
    "start": "3433540",
    "end": "3439630"
  },
  {
    "text": "to have a machine learning model to demonstrate but I did look at the the",
    "start": "3439630",
    "end": "3445270"
  },
  {
    "text": "hard part's not the drop boundary it's or whether it's dropped or not it's",
    "start": "3445270",
    "end": "3450460"
  },
  {
    "text": "being able to tell the difference between moving and dropped right it's easy to determine when it's stationary",
    "start": "3450460",
    "end": "3456099"
  },
  {
    "text": "and actually the machine learning model is much better because of that having to",
    "start": "3456099",
    "end": "3461170"
  },
  {
    "text": "worry about the moving step so this is",
    "start": "3461170",
    "end": "3468940"
  },
  {
    "text": "not that different than that and so because of the history the history that",
    "start": "3468940",
    "end": "3475150"
  },
  {
    "text": "helps with the moving it actually works a lot better to have the machine learning model unfortunately the the",
    "start": "3475150",
    "end": "3483640"
  },
  {
    "text": "threshold is a little bit more robust ultimately but you do get a lot of value",
    "start": "3483640",
    "end": "3488920"
  },
  {
    "text": "out of the machine work any other questions yes sir",
    "start": "3488920",
    "end": "3493920"
  },
  {
    "text": "yeah so the question is if I've got two conditional branches one one branch that might require or might perform best",
    "start": "3519490",
    "end": "3526190"
  },
  {
    "text": "against the CPU and another that might perform best against a GPU in flow go identify which which hardware which",
    "start": "3526190",
    "end": "3533510"
  },
  {
    "text": "Hardware optimization techniques should be used and the answers flow goes for the most part dumb in that sense and leverages tensor flow so you can have",
    "start": "3533510",
    "end": "3540620"
  },
  {
    "text": "different inference activities added within your flow and then you could have each inference activity specifically",
    "start": "3540620",
    "end": "3546830"
  },
  {
    "text": "marked as CPU versus GPU though you do get into potential issues with the the",
    "start": "3546830",
    "end": "3551870"
  },
  {
    "text": "dynamic Lib that's built as well and how that's optimized so if it wasn't built with the GPU markers then then you're",
    "start": "3551870",
    "end": "3558170"
  },
  {
    "text": "not gonna get GPU optimization as well so it really falls on a tensor flow yes",
    "start": "3558170",
    "end": "3563330"
  },
  {
    "text": "sir",
    "start": "3563330",
    "end": "3565450"
  },
  {
    "text": "yep nope absolutely so the question is at",
    "start": "3571210",
    "end": "3577270"
  },
  {
    "text": "any point in time if I take data and I want to you know identify a key event and then right send that data up to to",
    "start": "3577270",
    "end": "3583630"
  },
  {
    "text": "the cloud so write on it write something to an s3 bucket or whatever right and the answer is quite simple so so flow go",
    "start": "3583630",
    "end": "3589840"
  },
  {
    "text": "has native activities that will allow you to write directly to s3 or mqtt outbound and things like that so so in",
    "start": "3589840",
    "end": "3595660"
  },
  {
    "text": "an ideal scenario you'd probably you do the aggregation and the processing at the edge dump out those Sarita you know",
    "start": "3595660",
    "end": "3602470"
  },
  {
    "text": "rather than sending 3,000 events per second to the cloud you'd send one every minute or two depending when it's",
    "start": "3602470",
    "end": "3608380"
  },
  {
    "text": "dropped so yes you can do that and it's fairly easy to do it's effectively just putting another box in this chain and",
    "start": "3608380",
    "end": "3615600"
  },
  {
    "text": "and it's really simple to add that extra box 22 seconds all right everyone thank",
    "start": "3615600",
    "end": "3627400"
  },
  {
    "text": "you very much [Applause]",
    "start": "3627400",
    "end": "3631719"
  }
]
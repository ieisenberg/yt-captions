[
  {
    "text": "my name is Jim plush senior director of engineering at crowdstrike and co-presenting with me today will be",
    "start": "120",
    "end": "5680"
  },
  {
    "text": "Dennis opaki our senior cloud system architect so just a quick intro on crowd",
    "start": "5680",
    "end": "11920"
  },
  {
    "text": "strike and so you get a sense of how we use Cassandra what kind of data we're working with so crowd strikes in the",
    "start": "11920",
    "end": "17840"
  },
  {
    "text": "Next Generation endpoint security market so essentially picking up where AV has failed uh doing a lot of realtime",
    "start": "17840",
    "end": "24960"
  },
  {
    "text": "detection indicators of attack indicators of compromise a lot of uh machine learning models on the back end",
    "start": "24960",
    "end": "31560"
  },
  {
    "text": "to determine potential threats for our",
    "start": "31560",
    "end": "36079"
  },
  {
    "text": "customers we are a cloud-based uh endpoint technology company which",
    "start": "37160",
    "end": "42559"
  },
  {
    "text": "essentially means we have a small uh kernel driver that sits on different operating systems and servers desktops",
    "start": "42559",
    "end": "49480"
  },
  {
    "text": "laptops and these systems are connected up to our cloud system and are constantly sending Telemetry up things",
    "start": "49480",
    "end": "56440"
  },
  {
    "text": "like process execution DNS queries uh internet IP connections uh lateral",
    "start": "56440",
    "end": "63079"
  },
  {
    "text": "movement detection all the sort of machine data that has to get processed in near real time to try and you know",
    "start": "63079",
    "end": "70640"
  },
  {
    "text": "outpace the ability to uh for the attacker to get the upper hand so given its machine data and",
    "start": "70640",
    "end": "78119"
  },
  {
    "text": "especially on things like servers a single large Enterprise customer can generate up to two",
    "start": "78119",
    "end": "83880"
  },
  {
    "text": "terabytes of this raw data per day that has to get uh processed as fast as",
    "start": "83880",
    "end": "89400"
  },
  {
    "text": "possible right now we're seeing about 500,000 events per second hitting our production",
    "start": "89400",
    "end": "94799"
  },
  {
    "text": "uh Cassandra cluster that is actually running on on EBS um and just within uh",
    "start": "94799",
    "end": "102680"
  },
  {
    "text": "our Network we have multiple pedabytes of data under management so what this talk is really",
    "start": "102680",
    "end": "109399"
  },
  {
    "text": "about is about breaking down uh a truism like a truism um that's been out there",
    "start": "109399",
    "end": "117320"
  },
  {
    "text": "about EBS and Cassandra and there's a lot of those right in engineering that are sometimes lower that you know people",
    "start": "117320",
    "end": "123799"
  },
  {
    "text": "get in their heads and they think well this is how it is forever things like htps is too expensive to run everywhere",
    "start": "123799",
    "end": "130200"
  },
  {
    "text": "right with the advancement of non chip crypto you know you see companies like Facebook and Google they're rolling htps",
    "start": "130200",
    "end": "137480"
  },
  {
    "text": "uh out across their entire stack with really no performance penalties uh things like all you need is antivirus",
    "start": "137480",
    "end": "144080"
  },
  {
    "text": "right tell that to Target and Sony now that's not generally the case and something applicable this crowd is never",
    "start": "144080",
    "end": "151160"
  },
  {
    "text": "run Cassandra on uh on EBS it's in the data Stacks documentation forever goes",
    "start": "151160",
    "end": "157800"
  },
  {
    "text": "back to 2011 that they say you know never run on EBS it's you know in the",
    "start": "157800",
    "end": "163599"
  },
  {
    "text": "community if you even mention it in IRC they'll kick you out of the channel uh so you know it's it's got a",
    "start": "163599",
    "end": "170440"
  },
  {
    "text": "really bad rap in the community not not for you know invalid reasons perfectly valid reasons so just a level set on EBS",
    "start": "170440",
    "end": "177599"
  },
  {
    "text": "just make sure we're all talking the same thing um think of EBS as a network mounted hard drive right you it's a",
    "start": "177599",
    "end": "184440"
  },
  {
    "text": "separate service outside of ec2 we're able to provision a data volume attach it to a running instance you could stop",
    "start": "184440",
    "end": "191440"
  },
  {
    "text": "an instance you can reattach it to another instance gives you a lot of flexibility uh including things like",
    "start": "191440",
    "end": "197400"
  },
  {
    "text": "native support for inflight and uh encryption at",
    "start": "197400",
    "end": "202440"
  },
  {
    "text": "rest so some of the issues in the past with EBS which which were valid at one",
    "start": "202720",
    "end": "208840"
  },
  {
    "text": "point were the jittery IO right Noisy Neighbor problem Netflix jumps on your box all of a sudden you know your",
    "start": "208840",
    "end": "214920"
  },
  {
    "text": "performance drops because they're hogging all the uh all the bandwidth um it was a single point of failure in a",
    "start": "214920",
    "end": "220319"
  },
  {
    "text": "region right with with Cassandra you want to replicate your data across availability zones if one a goes down",
    "start": "220319",
    "end": "226560"
  },
  {
    "text": "you lose all three copies of your data well that's not much fun um cost was",
    "start": "226560",
    "end": "231879"
  },
  {
    "text": "always a factor and I get all this free ephemeral disc why do I want to pay for EBS and now we're seeing the move uh",
    "start": "231879",
    "end": "238480"
  },
  {
    "text": "Within ec2 that they're going more into the EBS Direction and you're getting less",
    "start": "238480",
    "end": "244120"
  },
  {
    "text": "ephemeral choices and then there was the old bad volumes I'm going to spin up 10 volumes I'm going to run DD I'm going to",
    "start": "244120",
    "end": "250560"
  },
  {
    "text": "run fio and I'm going to pick the one with the the best consistency and throw the rest away so we had a recent project come up",
    "start": "250560",
    "end": "258519"
  },
  {
    "text": "that forced us to take a look at EBS again and we were in the same camp you know when we first started with",
    "start": "258519",
    "end": "264080"
  },
  {
    "text": "Cassandra we've been running it for uh almost four years in production and we were we were on Emeral",
    "start": "264080",
    "end": "270160"
  },
  {
    "text": "uh instances and we followed the same pattern like EBS no way not an Arcus Ander cluster um and Dennis will we'll",
    "start": "270160",
    "end": "278039"
  },
  {
    "text": "touch on that in a little bit but this project that came up forced us to re-evaluate the EBS story with Cassandra",
    "start": "278039",
    "end": "285880"
  },
  {
    "text": "because what we essentially want to do is build a large distributed graph of all this Telemetry we're collecting so",
    "start": "285880",
    "end": "292039"
  },
  {
    "text": "we can do some you know more advanced analysis and uh more advanced detection",
    "start": "292039",
    "end": "297600"
  },
  {
    "text": "capabilities and give given this amount of machine data we're modeling it out to be about a pyte um just at current",
    "start": "297600",
    "end": "304520"
  },
  {
    "text": "current levels of scale and needing to scale well past the uh the petabyte range for a cassander",
    "start": "304520",
    "end": "311400"
  },
  {
    "text": "cluster we also needed something that could at least handle you know 2 to 3x the current traffic uh so we can grow",
    "start": "311400",
    "end": "318440"
  },
  {
    "text": "into it so it had to be able to handle a million rights per second being able to build this this graph we need to age out",
    "start": "318440",
    "end": "325479"
  },
  {
    "text": "data really crisply you know in cassander when you delete data or TTL",
    "start": "325479",
    "end": "330560"
  },
  {
    "text": "uh it doesn't actually leave the disc until it it gets compacted out and the Tombstones uh align with that data so we",
    "start": "330560",
    "end": "337440"
  },
  {
    "text": "needed to be really clear and crisp on when that data was actually leaving disk uh and also reduce the io and right",
    "start": "337440",
    "end": "345319"
  },
  {
    "text": "amplification problems with really dense nodes and uh and heavy delete IO",
    "start": "345319",
    "end": "350919"
  },
  {
    "text": "operations and we were heavy heavy right to read so we really need to focus on right",
    "start": "350919",
    "end": "356199"
  },
  {
    "text": "performance so early on um we didn't want to re re build a wheel we said what's out there already that we could",
    "start": "356199",
    "end": "362160"
  },
  {
    "text": "you know build this big graph on uh there was Titan DB uh over Cassandra so",
    "start": "362160",
    "end": "367280"
  },
  {
    "text": "we spent a couple of months working with Titan working with their team and trying to you know build some prototypes in",
    "start": "367280",
    "end": "373800"
  },
  {
    "text": "production with our data and unfortunately what we found was just you know it just wasn't wasn't up to that",
    "start": "373800",
    "end": "379479"
  },
  {
    "text": "scale um for the kind of size workloads we had the uptime requirements we had",
    "start": "379479",
    "end": "386280"
  },
  {
    "text": "and uh the plans for future growth so we had to kind of go back to the drawing board and look at well what are the",
    "start": "386280",
    "end": "391479"
  },
  {
    "text": "other you know sharding options we have can we you know Shard Neo for Jay uh and unfortunately you know we were we were",
    "start": "391479",
    "end": "398080"
  },
  {
    "text": "too big for um even sharding uh Neo for J um after talking with those guys as",
    "start": "398080",
    "end": "404720"
  },
  {
    "text": "well so then we looked at well can we do you know sharded adjacency lists over",
    "start": "404720",
    "end": "409960"
  },
  {
    "text": "relational databases so we looked at you know postgress my Sly prototyped a bunch of uh different workloads there and then",
    "start": "409960",
    "end": "416280"
  },
  {
    "text": "we started getting down into the level DB rocks DB uh which which are essentially you know big table clones",
    "start": "416280",
    "end": "422280"
  },
  {
    "text": "and by that time you know we kind of just stopped and said hey we're we're actually just rebuilding Cassandra here",
    "start": "422280",
    "end": "428240"
  },
  {
    "text": "you know we're going to have to do our own replication we're going to have to do our own you know data movement and what happens in node failure and",
    "start": "428240",
    "end": "434199"
  },
  {
    "text": "reshuffling data and rearing the data so we really didn't want to be in that",
    "start": "434199",
    "end": "439479"
  },
  {
    "text": "business um so we said can we make Cassandra work and can we put enough",
    "start": "439479",
    "end": "444599"
  },
  {
    "text": "time into tuning to actually get it to match our workload so we came across uh",
    "start": "444599",
    "end": "449960"
  },
  {
    "text": "this great Netflix article on revisiting a million rights per second that they were kind enough to publish and we",
    "start": "449960",
    "end": "456280"
  },
  {
    "text": "really used that as a kind of a benchmark on you know what would a one petabyte cluster cost with the kind of",
    "start": "456280",
    "end": "463120"
  },
  {
    "text": "performance that we needed to see and what kind of Hardware like what do they",
    "start": "463120",
    "end": "469080"
  },
  {
    "text": "recommend and so when we dug into it they're using the I2 extra large in this uh in this article and that's ephemeral",
    "start": "469080",
    "end": "477159"
  },
  {
    "text": "disc 800 gig uh SSD local store um so",
    "start": "477159",
    "end": "482240"
  },
  {
    "text": "really good performance but when we modeled out well how much how many of those will we need for a petabyte of data you're looking at 1,750 nodes right",
    "start": "482240",
    "end": "490840"
  },
  {
    "text": "assuming a 40% compaction overhead which is a little more than any uh cluster you want to run with Cassandra um I think",
    "start": "490840",
    "end": "497680"
  },
  {
    "text": "Netflix just released some information that they try and keep it under 300 nodes because of uh you know cross a",
    "start": "497680",
    "end": "504800"
  },
  {
    "text": "latency so this started causing us to look at the EBS story a little bit and",
    "start": "504800",
    "end": "510520"
  },
  {
    "text": "so we said what would that look like with EBS and using c42 XLS and for that you know same pyte",
    "start": "510520",
    "end": "518159"
  },
  {
    "text": "workload with 40% compaction overhead if we ran 4 terabyte nodes you know denser nodes we would need about 350 which is a",
    "start": "518159",
    "end": "525839"
  },
  {
    "text": "more realistic size cluster and you know our kind of plans is to is to pod those",
    "start": "525839",
    "end": "531120"
  },
  {
    "text": "clusters right so we kind of have a few hundred uh Cassandra clusters that we",
    "start": "531120",
    "end": "536240"
  },
  {
    "text": "can route customers into when you look at the cost for that cluster um for that I2 on demand you're",
    "start": "536240",
    "end": "544640"
  },
  {
    "text": "looking at about $14 million um which would give our our sea level exec a heart attack uh even at",
    "start": "544640",
    "end": "552480"
  },
  {
    "text": "reserve price you're looking at you know around $8 million and when you look at the price for the C4 2XL reserved with EBS cost",
    "start": "552480",
    "end": "560839"
  },
  {
    "text": "Allin you know you're well under $4 million so significant savings uh if we could have you know get EBS working with",
    "start": "560839",
    "end": "567519"
  },
  {
    "text": "our our workload one of the other important uh things that we thought we could get working",
    "start": "567519",
    "end": "573800"
  },
  {
    "text": "with uh cassander was the introduction of date toer compaction which uh is new",
    "start": "573800",
    "end": "579200"
  },
  {
    "text": "in the 2 release um one of my colleagues Jeff Jus in the audience today also did",
    "start": "579200",
    "end": "585240"
  },
  {
    "text": "a great talk at cassander summon a few weeks ago on it it essentially allows you to do uh time windowed compaction so",
    "start": "585240",
    "end": "591800"
  },
  {
    "text": "we could say hey set a window for a day and anything after a day I don't want you to touch I don't want you to compact",
    "start": "591800",
    "end": "597720"
  },
  {
    "text": "it right so you're not paying that right amplification penalty since we have very um you know uh item potent right once uh",
    "start": "597720",
    "end": "606760"
  },
  {
    "text": "type of events that are never going to be updated they're just point in time time series data uh we don't need to pay",
    "start": "606760",
    "end": "612519"
  },
  {
    "text": "that compaction penalty for having to rec compact those big files so unfortunately I won't go into too much",
    "start": "612519",
    "end": "618839"
  },
  {
    "text": "detail but it it didn't work out as expected and we had to have Jeff write our own uh compaction strategy to kind",
    "start": "618839",
    "end": "624920"
  },
  {
    "text": "of to kind of fix it so um feel free to grab us after to talk about it",
    "start": "624920",
    "end": "630839"
  },
  {
    "text": "so we started with the premise that you know we didn't want to run 350 nodes",
    "start": "630839",
    "end": "636160"
  },
  {
    "text": "from day one right we want to be able to grow into that that 350 right we're not going to have a petabyte day one why do",
    "start": "636160",
    "end": "641519"
  },
  {
    "text": "we want to pay for a petabyte uh day one so we just you know picked it out of the air well we should be able to do you",
    "start": "641519",
    "end": "648120"
  },
  {
    "text": "know a million rights on 60 nodes based on um you know some benchmarks we were",
    "start": "648120",
    "end": "654000"
  },
  {
    "text": "reading and some other posts and everyone thought that was pretty reasonable so we started out",
    "start": "654000",
    "end": "659600"
  },
  {
    "text": "did our data model and we launched with uh Cassandra 20 we just went with M3 XL to see if we",
    "start": "659600",
    "end": "667120"
  },
  {
    "text": "could make it work there uh single 4T volume which gave us about 10,000 iops and just kind of the default tunings",
    "start": "667120",
    "end": "673440"
  },
  {
    "text": "really just a hey what can this cluster do uh unfortunately the results were",
    "start": "673440",
    "end": "679360"
  },
  {
    "text": "just disastrous uh she's not impressed um we",
    "start": "679360",
    "end": "684560"
  },
  {
    "text": "really only were able to push around 150,000 uh rights per second at RF what",
    "start": "684560",
    "end": "689880"
  },
  {
    "text": "would be rf3 on a a test cluster um when you modeled out from 12",
    "start": "689880",
    "end": "695320"
  },
  {
    "text": "nodes and it was just you know an order magnitude less than than we were expecting so we started going through",
    "start": "695320",
    "end": "701760"
  },
  {
    "text": "all the books and the blog post the videos you know how do we tune Cassandra what are we doing wrong and we just",
    "start": "701760",
    "end": "707360"
  },
  {
    "text": "weren't able to move the needle right we're just like we're just not good at tuning Cassandra let's bring in the experts we brought in data Stacks uh",
    "start": "707360",
    "end": "714240"
  },
  {
    "text": "we're a customer and we did a three-day engagement with them day one was about validating our model uh and then day two",
    "start": "714240",
    "end": "720839"
  },
  {
    "text": "and three we wanted to talk about you know tuning this cluster let's get as much right through put as we can so day",
    "start": "720839",
    "end": "726720"
  },
  {
    "text": "one went great model looked good uh we got into day two and three and again hit the wall weren't able to get any",
    "start": "726720",
    "end": "734160"
  },
  {
    "text": "performance Improvement we work with them we had five Engineers on a hangout uh for two days straight trying",
    "start": "734160",
    "end": "740399"
  },
  {
    "text": "different instance types uh different configurations yaml settings and at the end of the the third day still you know",
    "start": "740399",
    "end": "747639"
  },
  {
    "text": "we got it up to about2 200,00 th000 um on 60 nodes but just way way uh slower",
    "start": "747639",
    "end": "753600"
  },
  {
    "text": "than we were expecting we came across this um this post from last year's Summit where",
    "start": "753600",
    "end": "760120"
  },
  {
    "text": "family search seemed to go through the same problem that you know hey uh we're not seeing",
    "start": "760120",
    "end": "765880"
  },
  {
    "text": "any bottlenecks but I can't get any more throughput out of this cassander cluster you know where's the bottleneck and",
    "start": "765880",
    "end": "771800"
  },
  {
    "text": "that's what we thought originally too um when we first hit this bottleneck we're like oh it's got to be EBS this is why",
    "start": "771800",
    "end": "777079"
  },
  {
    "text": "people don't run EBS but but when we actually profiled it you know IAT dstat looked at our um graphing charts um disc",
    "start": "777079",
    "end": "785680"
  },
  {
    "text": "was completely bored the volumes were way underutilized CPU was fine Network bandwidth was fine just couldn't get any",
    "start": "785680",
    "end": "793639"
  },
  {
    "text": "throughput so essentially um you know we started blaming EBS originally because",
    "start": "793639",
    "end": "800399"
  },
  {
    "text": "you know the i2s have 43,000 iops and our lowly 4T volume is 10,000 iops like",
    "start": "800399",
    "end": "807720"
  },
  {
    "text": "clearly um you know it's an iops issue but we're actually doing is only about 1.3 th000 iops to that drive so you know",
    "start": "807720",
    "end": "815199"
  },
  {
    "text": "and well under 40 megabytes per second and that volume should be able to push",
    "start": "815199",
    "end": "820240"
  },
  {
    "text": "around 150 megabytes 160 megabytes per second with the latest release so very",
    "start": "820240",
    "end": "825959"
  },
  {
    "text": "underutilized so have all this this IO available um but wen't be weren't being",
    "start": "825959",
    "end": "831519"
  },
  {
    "text": "able to drive to it so then we just went back to the",
    "start": "831519",
    "end": "837000"
  },
  {
    "text": "drawing board and we spent spent the next 2 months really just digging in and and really feeling like we could get it",
    "start": "837000",
    "end": "843279"
  },
  {
    "text": "to work uh so we just built this huge Matrix of you know different instance types operating systems yaml settings",
    "start": "843279",
    "end": "850240"
  },
  {
    "text": "configuration kernel level dirty page flush uh and we we tuned everything um",
    "start": "850240",
    "end": "856720"
  },
  {
    "text": "to try and to see what we could tweak to actually make that big breakthrough and finally uh about 2",
    "start": "856720",
    "end": "864399"
  },
  {
    "text": "months in we were able to find the magic incantation of you you know uh instance",
    "start": "864399",
    "end": "870399"
  },
  {
    "text": "type and Os and file system and all the jvm settings to actually uh achieve that",
    "start": "870399",
    "end": "877279"
  },
  {
    "text": "accomplishment so before I get into what we actually picked I just want to kind of go over the testing methodology we Ed because we",
    "start": "877279",
    "end": "884040"
  },
  {
    "text": "wound up spinning up I mean I personally spent about 300 clusters trying various things uh so we put a lot of time into",
    "start": "884040",
    "end": "889759"
  },
  {
    "text": "automating it and just to to head check there because if you know you do improper testing you may uh be led to to",
    "start": "889759",
    "end": "897519"
  },
  {
    "text": "um false results so each test run we did was with clean instances we dropped the old key space",
    "start": "897519",
    "end": "903240"
  },
  {
    "text": "really wanted a clean test run uh we also wanted to load in plenty of data so at rf3 13 terabytes was a",
    "start": "903240",
    "end": "911279"
  },
  {
    "text": "decent amount of data to make sure we were actually taxing the iio subsystem right during compaction we wanted that",
    "start": "911279",
    "end": "917800"
  },
  {
    "text": "you know wanted to to see that contention between taking rights in and doing heavy compaction um at the same",
    "start": "917800",
    "end": "924160"
  },
  {
    "text": "time to see all that limited throughput and to apolog wise we tried",
    "start": "924160",
    "end": "929720"
  },
  {
    "text": "to follow the the Netflix topology uh as best we could from their article so splitting out the nodes across",
    "start": "929720",
    "end": "935680"
  },
  {
    "text": "availability zones using the ec2 snitch to balance uh the azs as racks and then",
    "start": "935680",
    "end": "941920"
  },
  {
    "text": "we launched separate uh c44 XL stress nodes so we launched 20 of those in",
    "start": "941920",
    "end": "947360"
  },
  {
    "text": "separate availability zones and we had a dedicated op Center so we can kind of monitor all this traffic we also had a",
    "start": "947360",
    "end": "952519"
  },
  {
    "text": "separate uh graphing Library um also we uh actually went with two EBS",
    "start": "952519",
    "end": "960560"
  },
  {
    "text": "volumes so we split out the commit and the Data Drive uh we never really saw the commit even even when we achieved",
    "start": "960560",
    "end": "967040"
  },
  {
    "text": "our Target we never saw the commit log go uh anywhere near really 3,000 iops so",
    "start": "967040",
    "end": "972759"
  },
  {
    "text": "we we felt that uh that was a pretty good buffer we hit about I think 2,000 iops a few times on the commit log so we",
    "start": "972759",
    "end": "979519"
  },
  {
    "text": "picked a uh a ont volume gp2 that gives us 3,000 iops and notice that these are",
    "start": "979519",
    "end": "985440"
  },
  {
    "text": "encrypted volumes too so again the performance penalty for or encryption um really isn't there with with EBS",
    "start": "985440",
    "end": "993160"
  },
  {
    "text": "either we want the cassander 21 stress tool huge huge improvement over previous",
    "start": "993160",
    "end": "999680"
  },
  {
    "text": "Cassandra stress in 20 and and earlier especially in 215 it gives you the ability to Define your own yaml file",
    "start": "999680",
    "end": "1007000"
  },
  {
    "text": "which really lets you model your workload in a realistic way you can do gajin distributions over your data key",
    "start": "1007000",
    "end": "1013480"
  },
  {
    "text": "sizes um you can tune it to what you think your read and write workload is going to be",
    "start": "1013480",
    "end": "1019040"
  },
  {
    "text": "uh you can put different stresses you know wde very wide rows very narrow rows so it gives you uh a ton of flexibility",
    "start": "1019040",
    "end": "1025918"
  },
  {
    "text": "there documentation is poor but once you get into it it's it's pretty impressive",
    "start": "1025919",
    "end": "1031000"
  },
  {
    "text": "uh another cool tool we used for testing was a page cach stat from Al toia data Stacks it's a really cool tool to let",
    "start": "1031000",
    "end": "1037760"
  },
  {
    "text": "you know when your SS tables are expiring out of page cache because what you don't want to do is you know do a performance test and then realize that",
    "start": "1037760",
    "end": "1044880"
  },
  {
    "text": "all your compactions coming from page cache and coming from memory and you're not pushing the io subsystem at all so",
    "start": "1044880",
    "end": "1050559"
  },
  {
    "text": "you're not getting a true test so you really want to kind of use this to make sure that you know your SS tables for",
    "start": "1050559",
    "end": "1056000"
  },
  {
    "text": "your data actually expiring so when the compaction happens you know you're actually um hitting that",
    "start": "1056000",
    "end": "1063200"
  },
  {
    "text": "IO so we started with the the same Netflix test from that paper uh we added",
    "start": "1063600",
    "end": "1069880"
  },
  {
    "text": "a little more data than needed just try to make it a little more realistic but this is essentially like a 0 to 60",
    "start": "1069880",
    "end": "1075159"
  },
  {
    "text": "quarter mile speed test right it may not be indicative of your workload but it's hey how fast can this cluster push btes",
    "start": "1075159",
    "end": "1081320"
  },
  {
    "text": "to dis um so we",
    "start": "1081320",
    "end": "1087919"
  },
  {
    "text": "essentially started around 350 rights per second th000 rights per second and then simulated a burst up to uh 1.1",
    "start": "1087919",
    "end": "1096480"
  },
  {
    "text": "million rights per second actually went around 1.2 and then throttled it back down and what we wanted to see was let's",
    "start": "1096480",
    "end": "1102480"
  },
  {
    "text": "let's burst there for an hour let's bring load back down to 350,000 rights per second and let's see you know how",
    "start": "1102480",
    "end": "1108919"
  },
  {
    "text": "the cluster reacts to that is it going to fall over was it actually healthy at that",
    "start": "1108919",
    "end": "1114240"
  },
  {
    "text": "point so here's something you can view offline slides will be available uh don't expect you to to see it here but",
    "start": "1114240",
    "end": "1120480"
  },
  {
    "text": "just kind of look at the full op Center picture one of the key things we wanted to do with this test is make sure that",
    "start": "1120480",
    "end": "1127200"
  },
  {
    "text": "you know hey we hit a million rights per second but the cluster fell over um we didn't want we want it to be an actual",
    "start": "1127200",
    "end": "1132840"
  },
  {
    "text": "you know healthy cluster at a million rights per second so across the entire cluster we had no drop m ation so no",
    "start": "1132840",
    "end": "1139080"
  },
  {
    "text": "rights were getting dropped on the floor uh all the systems were in a pretty healthy medium State uh nothing out of",
    "start": "1139080",
    "end": "1145200"
  },
  {
    "text": "memory uh nothing went into the red so very um very good uh consistent",
    "start": "1145200",
    "end": "1151880"
  },
  {
    "text": "performance on the io side you can see the commit drive on the top left here um",
    "start": "1151880",
    "end": "1157600"
  },
  {
    "text": "extremely consistent performance right none of the previous jittery I/O that would typically affect Cassandra on EBS",
    "start": "1157600",
    "end": "1165080"
  },
  {
    "text": "previously uh on the data drive on the top right uh probably can't see it but data dis",
    "start": "1165080",
    "end": "1170520"
  },
  {
    "text": "utilization even during heavy compaction at a million rights uh well under 60%",
    "start": "1170520",
    "end": "1176200"
  },
  {
    "text": "utilized and pushing you know around 40 uh 40 Megs per second through that volume and you can see uh on the bottom",
    "start": "1176200",
    "end": "1183360"
  },
  {
    "text": "left the uh the commit log just just super steady IO weight very low IO",
    "start": "1183360",
    "end": "1191520"
  },
  {
    "text": "weight consistent performance um we're pretty impressed with the uh the response times the 95th percenti latency",
    "start": "1191520",
    "end": "1199600"
  },
  {
    "text": "for these rights even at a million rights per second 1.1 million rights per second stayed in the uh stayed under 15",
    "start": "1199600",
    "end": "1206200"
  },
  {
    "text": "milliseconds which for our workload is is uh acceptable and then we went to the re",
    "start": "1206200",
    "end": "1212840"
  },
  {
    "text": "side we're like okay let's let's see how it is on the reads so as soon as we turned on reads we hit about 20,000",
    "start": "1212840",
    "end": "1219360"
  },
  {
    "text": "reads per second and IO just just we just crushed those that volume",
    "start": "1219360",
    "end": "1224799"
  },
  {
    "text": "utilization just hit the ceiling weren't able to push anything uh couldn't get",
    "start": "1224799",
    "end": "1229840"
  },
  {
    "text": "more than 20,000 reads on 60 nodes so like aha gotcha EBS this is why no one",
    "start": "1229840",
    "end": "1235120"
  },
  {
    "text": "runs EBS can't read your data so what actually wound up happening is we discovered that um we had a",
    "start": "1235120",
    "end": "1242360"
  },
  {
    "text": "compression on on the table with the default chunk size of",
    "start": "1242360",
    "end": "1247840"
  },
  {
    "text": "64k which meant that for our little tests where it's trying to read you know",
    "start": "1247840",
    "end": "1253799"
  },
  {
    "text": "couple hundred bytes it would actually have to decompress 64k uh best case maybe across blocks 128k just to get",
    "start": "1253799",
    "end": "1261240"
  },
  {
    "text": "that 200 bytes and then throw the rest away so extremely inefficient on the read side so um we wound up turning off",
    "start": "1261240",
    "end": "1269559"
  },
  {
    "text": "compression and then changing our read buffer to 4K uh lot smaller and as soon as we did",
    "start": "1269559",
    "end": "1276760"
  },
  {
    "text": "that we were able to Peak at a million reads per second on the same cluster and sustain 350,000 reads per second for",
    "start": "1276760",
    "end": "1284679"
  },
  {
    "text": "over 24 hours uh with you know no uh no cluster fall over and this was doing a",
    "start": "1284679",
    "end": "1291080"
  },
  {
    "text": "95% read to write ratio and again another kind of slide to",
    "start": "1291080",
    "end": "1296559"
  },
  {
    "text": "view offline and this shows the uh the",
    "start": "1296559",
    "end": "1302080"
  },
  {
    "text": "24-hour test of of just hanging out around 350 400,000 reads per",
    "start": "1302080",
    "end": "1307720"
  },
  {
    "text": "second and the nice part is now on the on the charts um you can see the iio",
    "start": "1307720",
    "end": "1313039"
  },
  {
    "text": "utilization was was pretty steady now we're at you know 60 to 80% utilized still plenty of Headroom uh on that",
    "start": "1313039",
    "end": "1319799"
  },
  {
    "text": "system weren't you know Peg uh pegging it or taxing it iostat looked good um so",
    "start": "1319799",
    "end": "1325679"
  },
  {
    "text": "much much healthier latency wise uh the reads 70 7.2 milliseconds at the 95th percenti",
    "start": "1325679",
    "end": "1332679"
  },
  {
    "text": "latency so acceptable uh for our use case so how do we do against the Netflix",
    "start": "1332679",
    "end": "1338559"
  },
  {
    "text": "cluster well again we were we were optimizing really for for cost",
    "start": "1338559",
    "end": "1343760"
  },
  {
    "text": "um so we use C4 4xls which are 16 core so may consider that uh some of an",
    "start": "1343760",
    "end": "1350440"
  },
  {
    "text": "unfair test but when you look at the cluster as a whole used 180 less cores",
    "start": "1350440",
    "end": "1356000"
  },
  {
    "text": "than they did with their test uh which is about 45 less instances but more importantly to our test it was almost a",
    "start": "1356000",
    "end": "1362080"
  },
  {
    "text": "third of the cost um which was which was key so we got the same performance with a much uh much better price",
    "start": "1362080",
    "end": "1369640"
  },
  {
    "text": "point so on the read side had mentioned we had a single uh 10K IOP uh gp2 volume",
    "start": "1369640",
    "end": "1377039"
  },
  {
    "text": "if you need more bigger reads you can certainly uh raid those volumes together",
    "start": "1377039",
    "end": "1382360"
  },
  {
    "text": "you can use provision iops to get uh more out of those drives but you know",
    "start": "1382360",
    "end": "1387559"
  },
  {
    "text": "10K is uh about what we needed so would",
    "start": "1387559",
    "end": "1392679"
  },
  {
    "text": "unlock performance major major tweak we made",
    "start": "1392679",
    "end": "1397760"
  },
  {
    "text": "was switching to hvm instances um all our previous images were PV and that was",
    "start": "1397760",
    "end": "1403720"
  },
  {
    "text": "one of the huge reasons why we couldn't see that throughput increase cuz we were actually gated on Network level um so",
    "start": "1403720",
    "end": "1410240"
  },
  {
    "text": "switching to hvm Unleashed uh a lot of performance gains from that cluster um",
    "start": "1410240",
    "end": "1416640"
  },
  {
    "text": "it's now faster than PV in almost every case it comes with the uh we went with the Ubuntu drro 1404 that's more",
    "start": "1416640",
    "end": "1424039"
  },
  {
    "text": "optimized for cloud type workloads and the xfs file system uh gave us really",
    "start": "1424039",
    "end": "1429120"
  },
  {
    "text": "great performance as well we went with Cassandra 21 uh we've",
    "start": "1429120",
    "end": "1434679"
  },
  {
    "text": "actually did this test with 217 and 219 um both had the same pretty much the",
    "start": "1434679",
    "end": "1440120"
  },
  {
    "text": "same results 20 was just uh I'll just be polite and say it was a dog um just",
    "start": "1440120",
    "end": "1446520"
  },
  {
    "text": "weren't able to get performance out of 20 we had other companies confirm the same when we triying to have them retest",
    "start": "1446520",
    "end": "1452039"
  },
  {
    "text": "our results um so switching to 21 huge Improvement in the right path they did a",
    "start": "1452039",
    "end": "1457320"
  },
  {
    "text": "lot of work around lock contention and a lot of work around having ss tables available right into page cach after U",
    "start": "1457320",
    "end": "1464679"
  },
  {
    "text": "compaction so big boost there um Java 8 G1 garbage collector gave us really good",
    "start": "1464679",
    "end": "1471000"
  },
  {
    "text": "uh consistency with garbage collection pauses so it brought down our 99th uh",
    "start": "1471000",
    "end": "1476520"
  },
  {
    "text": "and 90th percentiles we want the C4 4XL 16 core",
    "start": "1476520",
    "end": "1483440"
  },
  {
    "text": "EBS optimized for this test um we're kind of predicting that we'll be at the",
    "start": "1483440",
    "end": "1489039"
  },
  {
    "text": "C4 2XL as we expand out the cluster uh and have more nodes taking on uh that",
    "start": "1489039",
    "end": "1495159"
  },
  {
    "text": "data load but for this test we use the the c44 XLS which are EBS optimized so",
    "start": "1495159",
    "end": "1501120"
  },
  {
    "text": "essentially that means you have a dedicated pipe for EBS and you're not sharing traffic with the the rest of the",
    "start": "1501120",
    "end": "1508080"
  },
  {
    "text": "instance and we went out with the uh the two volumes as I mentioned Heap size went with 8 gig uh",
    "start": "1508080",
    "end": "1515559"
  },
  {
    "text": "due to the dense nodes we wanted to run we wanted to make sure we had a lot of off Heap uh space for things like Bloom",
    "start": "1515559",
    "end": "1522039"
  },
  {
    "text": "filters and other indexes and things cassander keeps off Heap and as you had denser nodes you need more of that",
    "start": "1522039",
    "end": "1528559"
  },
  {
    "text": "memory available um also wanted to make sure we had enough for uh for page",
    "start": "1528559",
    "end": "1535840"
  },
  {
    "text": "cache get some some magic sauce from Al from from data Stacks uh putting the",
    "start": "1535840",
    "end": "1542279"
  },
  {
    "text": "process into batch mode to reduce some some of the contact switching and interrupts um we masked off the zero CPU",
    "start": "1542279",
    "end": "1549080"
  },
  {
    "text": "so in some Ubunto dros you can check your irq balance but uh the zero CPU is",
    "start": "1549080",
    "end": "1555679"
  },
  {
    "text": "left for a lot of Kernel interrupts Network traffic traffic so by masking that off we were able to reduce a lot of",
    "start": "1555679",
    "end": "1561000"
  },
  {
    "text": "the Conta switching uh under high right load I don't necessarily maybe wouldn't run this in production normally but we",
    "start": "1561000",
    "end": "1567640"
  },
  {
    "text": "wanted to do a benchmark and we wanted to see how far we can push the cluster yaml wise um this is pretty much",
    "start": "1567640",
    "end": "1574840"
  },
  {
    "text": "all we really changed uh from the yl file again went with the ec2 snitch",
    "start": "1574840",
    "end": "1580039"
  },
  {
    "text": "which is available in there um we did turn off in node",
    "start": "1580039",
    "end": "1585320"
  },
  {
    "text": "compression we actually found in node compression caused a lot of right slowdown because",
    "start": "1585320",
    "end": "1590520"
  },
  {
    "text": "of uh how much CPU it caused to compress and decompress the data on all the nodes with replication so we turn that",
    "start": "1590520",
    "end": "1598000"
  },
  {
    "text": "off so some of the lessons we learned uh even though we thought we got EBS you",
    "start": "1598000",
    "end": "1603320"
  },
  {
    "text": "know a few times EBS was never the bottleneck during our during our testing gp2 is actually legitimately ready for",
    "start": "1603320",
    "end": "1610600"
  },
  {
    "text": "production workloads from a performance standpoint U built-in types like list",
    "start": "1610600",
    "end": "1616279"
  },
  {
    "text": "and map come at a huge huge performance penalty we got a 30% speed boost uh on",
    "start": "1616279",
    "end": "1622279"
  },
  {
    "text": "rights when we switch from a map to a serialized uh bite string um so that was",
    "start": "1622279",
    "end": "1629320"
  },
  {
    "text": "a big win dtcs is very young I probably wouldn't recommend it for for production",
    "start": "1629320",
    "end": "1634919"
  },
  {
    "text": "um we do have another compaction strategy you can ask us about that's on GitHub that does what dtcs um should be",
    "start": "1634919",
    "end": "1643679"
  },
  {
    "text": "doing um two1 stress tool again is is tricky to get your head around but once",
    "start": "1643679",
    "end": "1649399"
  },
  {
    "text": "you get it it's really great at being able to model these workloads and really understanding how",
    "start": "1649399",
    "end": "1655640"
  },
  {
    "text": "compression is going to affect your read path right compression is great to minimize how much disc you're going to",
    "start": "1655640",
    "end": "1660720"
  },
  {
    "text": "use but then you have to look at well how am I going to read that back how often how fast do I need to read it back",
    "start": "1660720",
    "end": "1665960"
  },
  {
    "text": "can I handle that decompression uh CPU hit and IO hit so the one thing we didn't want to",
    "start": "1665960",
    "end": "1672039"
  },
  {
    "text": "do is just say hey you know look at all the stuff we did it's great really wanted to enable you guys to you know test your own own profiles test your own",
    "start": "1672039",
    "end": "1679039"
  },
  {
    "text": "workload uh on your cassander instances so wind up releasing all the python fabric scripts that I Ed to uh automate",
    "start": "1679039",
    "end": "1686720"
  },
  {
    "text": "um how we brought up the Clusters and change the configuration uh supports things like",
    "start": "1686720",
    "end": "1691919"
  },
  {
    "text": "being able to run different profiles so we have a C4 profile an I2 profile it'll do all the you know the rating and the",
    "start": "1691919",
    "end": "1699559"
  },
  {
    "text": "file system format we did a ton of other tweaks you know turning off Swap and",
    "start": "1699559",
    "end": "1705080"
  },
  {
    "text": "more than I can get into in the talk but it's all uh all the details are in in that",
    "start": "1705080",
    "end": "1710640"
  },
  {
    "text": "repo allows you to you know launch nodes in a specific uh AZ bootstrap them again",
    "start": "1710640",
    "end": "1717399"
  },
  {
    "text": "which will install Cassandra and do all that formatting for you to make it as as fast as possible to test new",
    "start": "1717399",
    "end": "1723240"
  },
  {
    "text": "configurations you know what does this look like if I change this you know current",
    "start": "1723240",
    "end": "1728320"
  },
  {
    "text": "compactors uh supports multi noes support for running uh stress so one of the issues with testing stress I've seen",
    "start": "1728320",
    "end": "1734960"
  },
  {
    "text": "is people bring up a bunch of stress writers and and don't uh don't populate the sequence so you're writing the same",
    "start": "1734960",
    "end": "1741200"
  },
  {
    "text": "keys from all the files so you're just doing updates instead of actual inserts so this will um support making sure you",
    "start": "1741200",
    "end": "1747519"
  },
  {
    "text": "have uh sharded keys so where are we at today we are now",
    "start": "1747519",
    "end": "1754279"
  },
  {
    "text": "3 months on our EBS cluster we've got hundreds of terabytes uh loaded into it now it's powering a lot of our",
    "start": "1754279",
    "end": "1762120"
  },
  {
    "text": "applications including our user interface we've got billions of vertices and edges in the graph",
    "start": "1762120",
    "end": "1768640"
  },
  {
    "text": "and one of the interesting things is we're starting to change the perception based on the work we did around EBS and",
    "start": "1768640",
    "end": "1774320"
  },
  {
    "text": "Cassandra and just two days ago um Cassandra released an updated dock for",
    "start": "1774320",
    "end": "1780559"
  },
  {
    "text": "planning ec2 clusters where now they are acknowledging that gp2 is ready for",
    "start": "1780559",
    "end": "1785840"
  },
  {
    "text": "production workloads so that lifts basically a 4-year ban on not using EBS",
    "start": "1785840",
    "end": "1790919"
  },
  {
    "text": "so feel free to to uh hit that link in the slides and it'll uh go through it",
    "start": "1790919",
    "end": "1798200"
  },
  {
    "text": "I would also recommend hitting alto's guide for tuning Cassandra this was a lot of work we did with data Stacks uh",
    "start": "1798200",
    "end": "1804720"
  },
  {
    "text": "he's got a lot a lot more detail on a lot of the system level tunings that we did and uh the jvm",
    "start": "1804720",
    "end": "1811880"
  },
  {
    "text": "tunings and just thanks to all people at crowd Stag and data Stacks who uh who worked on",
    "start": "1811880",
    "end": "1817880"
  },
  {
    "text": "this so I talked about the performance side and as you can see based on our numbers and you know the tools available",
    "start": "1817880",
    "end": "1825200"
  },
  {
    "text": "uh you can see performance with EBS and cassand really is not an issue in in the current gp2 so I'm going to pass it off",
    "start": "1825200",
    "end": "1831480"
  },
  {
    "text": "to Dennis to uh talk about the stability side of of EBS great thanks Jim so the uh the work that Jim just",
    "start": "1831480",
    "end": "1838559"
  },
  {
    "text": "presented represents a very significant investment both in terms of engineering resources and cost to crowd strike uh we",
    "start": "1838559",
    "end": "1846720"
  },
  {
    "text": "spent uh months of time our most senior Engineers working on this project and it simply had to work like Jim said uh",
    "start": "1846720",
    "end": "1852679"
  },
  {
    "text": "because it really is the core of our Network we also spent over $100,000 in EBS and ec2 resources so we",
    "start": "1852679",
    "end": "1859320"
  },
  {
    "text": "hope that you guys can take something away from this and and really take advantage of of what we",
    "start": "1859320",
    "end": "1864679"
  },
  {
    "text": "learned one theme that Jim kept rigging up over and over in his talk was that uh",
    "start": "1864720",
    "end": "1870519"
  },
  {
    "text": "aha this is why people don't use EVS moves both on the read and the right side well this is a fio run against a 4T",
    "start": "1870519",
    "end": "1878519"
  },
  {
    "text": "10K eye up uh gb2 volume you can see it's pretty steady looks good right so",
    "start": "1878519",
    "end": "1883960"
  },
  {
    "text": "you have one little drop in there but certainly not enough to affect uh Cassandra so we wanted to do a bit of a",
    "start": "1883960",
    "end": "1889519"
  },
  {
    "text": "retrospective and understand why why all the hate for EBS I think it's clear the answer is haters going to",
    "start": "1889519",
    "end": "1897279"
  },
  {
    "text": "hate well crowd strike followed the crowd uh with uh using ephemeral and",
    "start": "1897279",
    "end": "1904120"
  },
  {
    "text": "instance door U images we we looked at EBS early on we were building the",
    "start": "1904120",
    "end": "1909600"
  },
  {
    "text": "production Network and and we discussed it we talked about risk and we decided that we it just there was just too much",
    "start": "1909600",
    "end": "1915120"
  },
  {
    "text": "risk at the time we needed to move with with the tried and true so we launched",
    "start": "1915120",
    "end": "1920159"
  },
  {
    "text": "with uh using entirely uh ephemeral route drives and and put all of our data",
    "start": "1920159",
    "end": "1926240"
  },
  {
    "text": "stores on uh on the ephemeral ssds we found it difficult and painful to start and stop instances uh if we needed to",
    "start": "1926240",
    "end": "1933120"
  },
  {
    "text": "resize something that was a a herculan effort for us uh we also couldn't avoid the big amazon rabuda paloa you guys",
    "start": "1933120",
    "end": "1939519"
  },
  {
    "text": "probably remember that affected about uh 10% of our Fleet uh and finally we're a security company so we have to encrypt",
    "start": "1939519",
    "end": "1945760"
  },
  {
    "text": "our customers data both at rest in uh in transit on the network so we were doing Shenanigans like Lux en Crypt FS uh you",
    "start": "1945760",
    "end": "1952919"
  },
  {
    "text": "know you reboot a machine and somebody's got to be there to type the encryption key in or it just doesn't come up well",
    "start": "1952919",
    "end": "1959639"
  },
  {
    "text": "guess what we still had failures uh we still had machines go down uh only now",
    "start": "1959639",
    "end": "1964720"
  },
  {
    "text": "guess what you get to rebuild from scratch so we wanted to understand why",
    "start": "1964720",
    "end": "1971200"
  },
  {
    "text": "we had this uh confirmation bias against EBS and so we went and we dug back",
    "start": "1971200",
    "end": "1976559"
  },
  {
    "text": "through uh you know what was going on in the news about the same time that that we made the decision to not go with EBS and",
    "start": "1976559",
    "end": "1983639"
  },
  {
    "text": "April 2011 was really the defining moment for this decision uh for folks to to not use evbs there was a big outage",
    "start": "1983639",
    "end": "1991200"
  },
  {
    "text": "uh IO became stuck on on a vast number of volumes and it it really took hours if not days for companies to recover uh",
    "start": "1991200",
    "end": "1998039"
  },
  {
    "text": "happened again in 2012 to a smaller extent you know it was some companies were affected by both outages and then",
    "start": "1998039",
    "end": "2003480"
  },
  {
    "text": "it happened again in in 2013 not not good right not a great great track record really the kiss of death though",
    "start": "2003480",
    "end": "2010919"
  },
  {
    "text": "was that first outage uh Netflix came out with a series of recommendations following the outage uh and they all",
    "start": "2010919",
    "end": "2016840"
  },
  {
    "text": "made really good sense right it was uh if you're going to run in the cloud you need to be multi-region so that if a",
    "start": "2016840",
    "end": "2022559"
  },
  {
    "text": "region goes down guess what you're not entirely offline uh they also introduced the the chaos monkey which I'm I'm sure",
    "start": "2022559",
    "end": "2028279"
  },
  {
    "text": "most of you heard heard about it it's kind of cool they just introduce random faults in into the environment and see",
    "start": "2028279",
    "end": "2033600"
  },
  {
    "text": "how it fails and then finally and unfortunately they made the recommendation that if you want",
    "start": "2033600",
    "end": "2039399"
  },
  {
    "text": "resilient uh cassander databases just stay away from EBS and we",
    "start": "2039399",
    "end": "2046159"
  },
  {
    "text": "did well Amazon moves quickly and quietly that it was clear that they knew even before that April 20111 outage that",
    "start": "2046159",
    "end": "2054520"
  },
  {
    "text": "they had a problem that EBS really wasn't being treated or resourced as a first class product within Amazon so",
    "start": "2054520",
    "end": "2061878"
  },
  {
    "text": "they they made some changes and I'll talk uh at greater length about what those changes were uh but then they",
    "start": "2061879",
    "end": "2067158"
  },
  {
    "text": "started moving forward they they sort of got their things together and they they started moving forward and introducing important features uh in July of 2012",
    "start": "2067159",
    "end": "2073599"
  },
  {
    "text": "they introduced provision iops so this was uh a means of using hard resource reservation on the back end to give you",
    "start": "2073599",
    "end": "2080638"
  },
  {
    "text": "uh guaranteed consistency uh it was really cool and and it it it really got our attention and we started using that",
    "start": "2080639",
    "end": "2086440"
  },
  {
    "text": "for uh for some of our spun clusters uh May 2014th this was wow this was a great",
    "start": "2086440",
    "end": "2092158"
  },
  {
    "text": "day for us this was uh the introduction of native EBS encryption so now we could get rid of the luck and the Crypt ofest",
    "start": "2092159",
    "end": "2097720"
  },
  {
    "text": "and all of the shenanigans there June 2014 though was really the game changer that's what got our attention for the",
    "start": "2097720",
    "end": "2103520"
  },
  {
    "text": "rest uh of our our applications uh the gp2 volumes where you you have both a a",
    "start": "2103520",
    "end": "2110640"
  },
  {
    "text": "guaranteed uh U IO uh capability that's",
    "start": "2110640",
    "end": "2115880"
  },
  {
    "text": "proportional to the number of gigs of storage that you want to buy uh and then you're able to burst to a higher level",
    "start": "2115880",
    "end": "2121240"
  },
  {
    "text": "it was uh 3,000 iops at the time in the march of 2015 they they raised really",
    "start": "2121240",
    "end": "2126359"
  },
  {
    "text": "raised the you can now have 16 T volumes where maybe it was only uh one t before",
    "start": "2126359",
    "end": "2131599"
  },
  {
    "text": "and you can now hit 10,000 iops on gp2 and 20,000 uh on uh on Pi Ops all really",
    "start": "2131599",
    "end": "2138599"
  },
  {
    "text": "great stuff for for Crow strike everybody so let's talk about some of the changes that the EBS team made to to",
    "start": "2138599",
    "end": "2145040"
  },
  {
    "text": "get the product back on track um the first thing they did was they stepped back and they said we need to prioritize",
    "start": "2145040",
    "end": "2152040"
  },
  {
    "text": "consistency and reliability of the product even above features and functionality so things like native",
    "start": "2152040",
    "end": "2157599"
  },
  {
    "text": "encryption uh gp2 and Pi Ops those were all on the road map well before those outages they put those product those",
    "start": "2157599",
    "end": "2164000"
  },
  {
    "text": "those products and features on hold and really got back down to the business of uh you know how do we make this a",
    "start": "2164000",
    "end": "2169079"
  },
  {
    "text": "product that people can trust again they compartmentalized the control plane so they remove cross a dependencies for",
    "start": "2169079",
    "end": "2174880"
  },
  {
    "text": "running volumes uh what this means is that even if they lose an entire availability Zone uh running volumes and",
    "start": "2174880",
    "end": "2181000"
  },
  {
    "text": "the other A's will continue to run unaffected by that that's that's great uh they simplified workflows to favor",
    "start": "2181000",
    "end": "2186720"
  },
  {
    "text": "sustained operation so whereas uh certain failure scenarios would result in you know as many as five steps in the",
    "start": "2186720",
    "end": "2193520"
  },
  {
    "text": "workflow to you know to to reattach a volume and make it work again now things just sort of tend to continue working",
    "start": "2193520",
    "end": "2200319"
  },
  {
    "text": "which is I think uh as operators what what we expect and desire they also did",
    "start": "2200319",
    "end": "2205920"
  },
  {
    "text": "some pretty cool things around uh formal uh specifications and models so uh they",
    "start": "2205920",
    "end": "2212280"
  },
  {
    "text": "they put to use some work by a uh a renowned computer scientist or respected computer comp scientist named leslee",
    "start": "2212280",
    "end": "2217680"
  },
  {
    "text": "Lamport uh TLA plus so this is a language for defining formal",
    "start": "2217680",
    "end": "2222920"
  },
  {
    "text": "specifications and it once you've Define your formal specifications you can do cool things like model testing so you",
    "start": "2222920",
    "end": "2228480"
  },
  {
    "text": "can Define the uh the constraint of the system uh you can model it and you can",
    "start": "2228480",
    "end": "2233960"
  },
  {
    "text": "understand all the ways in which it can fail uh and and this helped them find uh",
    "start": "2233960",
    "end": "2239040"
  },
  {
    "text": "sets of of uh operations as many as you know 15 20 deep that could lead to a",
    "start": "2239040",
    "end": "2244680"
  },
  {
    "text": "failure uh things that a a human uh sdt could never uh really",
    "start": "2244680",
    "end": "2250280"
  },
  {
    "text": "catch um lastly they they to this day devote a large portion of their",
    "start": "2250280",
    "end": "2255760"
  },
  {
    "text": "engineering resources to reliability and performance they they have dedicated folks that really just focus uh on",
    "start": "2255760",
    "end": "2260960"
  },
  {
    "text": "ensuring that all the right things are being do done so that we uh as operators as customers can trust the product",
    "start": "2260960",
    "end": "2267960"
  },
  {
    "text": "that's all really cool stuff so how are they doing well the EBS team internally targets five NES availability uh and",
    "start": "2267960",
    "end": "2275640"
  },
  {
    "text": "from our perspective they're exceeding expectations we're very happy in the",
    "start": "2275640",
    "end": "2280760"
  },
  {
    "text": "past 12 months at crowd strike we've seen zero EBS related failures uh well zero failures uh of EBS is doing we've",
    "start": "2280760",
    "end": "2288400"
  },
  {
    "text": "we've made our own failures uh we have thousands of gp2 data volumes approximately 2p of data and we're in",
    "start": "2288400",
    "end": "2294319"
  },
  {
    "text": "the Pro process of transitioning all of our volumes all of our our uh uh",
    "start": "2294319",
    "end": "2299599"
  },
  {
    "text": "instances to EBS root volumes we we've already moved all of our key data stores we've moved our Splunk we've moved our",
    "start": "2299599",
    "end": "2305480"
  },
  {
    "text": "Cassandra we've moved our kofka uh we've moved uh elastic search and postgress all it's all on EBS and it's been it's",
    "start": "2305480",
    "end": "2312560"
  },
  {
    "text": "been good to us this is a a screen grab from the AWS",
    "start": "2312560",
    "end": "2318000"
  },
  {
    "text": "status board uh during the Dynamo DB outage um you know we we learned that",
    "start": "2318000",
    "end": "2323240"
  },
  {
    "text": "day sort of what all the cross dependencies were within uh Amazon products how many of these things",
    "start": "2323240",
    "end": "2328400"
  },
  {
    "text": "depended on on Dynamo Dynamo DB and and you'll notice that uh the EBS volumes",
    "start": "2328400",
    "end": "2335040"
  },
  {
    "text": "were not affected and and we think that that's uh that that really tells a good story for uh reliability of",
    "start": "2335040",
    "end": "2342640"
  },
  {
    "text": "EBS so if you want to move your your cassander workloads to EBS what should you you do to stay safe well first",
    "start": "2342640",
    "end": "2349760"
  },
  {
    "text": "select a region that has more than two availability zones this is primarily either if you're in the US it' be East",
    "start": "2349760",
    "end": "2355599"
  },
  {
    "text": "one or west two um you know we we hear rumors there is a third a available in uh in West one but uh uh we don't seem",
    "start": "2355599",
    "end": "2362520"
  },
  {
    "text": "to have access to it uh use the EBS gp2 or Pi Up Storage uh is a magnetic storage option available as well uh",
    "start": "2362520",
    "end": "2369440"
  },
  {
    "text": "we're looking at that for some other applications it it seems pretty cool um but right now it's it's not something",
    "start": "2369440",
    "end": "2375319"
  },
  {
    "text": "that we're considering for Cassandra uh Jim also mentioned separating uh volumes for the commit logs and for the the data",
    "start": "2375319",
    "end": "2381880"
  },
  {
    "text": "that that just seems like a a really good practice what else can we can we do we",
    "start": "2381880",
    "end": "2386960"
  },
  {
    "text": "can uh use the cloudwatch monitoring knobs for EBS so we can look for uh IO",
    "start": "2386960",
    "end": "2392599"
  },
  {
    "text": "pauses we can look for uh you know running out of uh of burst tokens uh all",
    "start": "2392599",
    "end": "2398640"
  },
  {
    "text": "of those things or boost tokens all all the sorts of things um you notice pre-warming EBS volumes has crossed out",
    "start": "2398640",
    "end": "2404599"
  },
  {
    "text": "there this is another piece of folklore uh in the cloud Community it used to be you would you would start up your your",
    "start": "2404599",
    "end": "2410599"
  },
  {
    "text": "volumes you would run like Jim said you'd run uh Bonnie or or DD or fio",
    "start": "2410599",
    "end": "2416160"
  },
  {
    "text": "you'd pick the best ones uh and then you would you know you would just write to every block on the drive and and only",
    "start": "2416160",
    "end": "2422520"
  },
  {
    "text": "then could you be ensured that you would have Optimum performance we don't do that uh BS team tells me that's tells me",
    "start": "2422520",
    "end": "2428280"
  },
  {
    "text": "that's not necessary so we don't plan to do that going forward we don't think you should either uh use snapshots for back",
    "start": "2428280",
    "end": "2434079"
  },
  {
    "text": "backups uh before what we were doing with uh the femoral drives is we would attach an EBS volume to all of our our",
    "start": "2434079",
    "end": "2440000"
  },
  {
    "text": "cassander servers we would rsync the data over to that EBS volume and then we would snapshot it so we were still using",
    "start": "2440000",
    "end": "2445400"
  },
  {
    "text": "EBS snapshots but we had to pay the io penalty of that rsync and and that uh we had a bad",
    "start": "2445400",
    "end": "2451480"
  },
  {
    "text": "time so most importantly I think the take out take away from this retrospective here is is challenge",
    "start": "2451480",
    "end": "2457119"
  },
  {
    "text": "assumptions uh things change quickly in the cloud you know what was true yesterday uh what bid us yesterday may",
    "start": "2457119",
    "end": "2464640"
  },
  {
    "text": "not be true today stay Cent on the ads blog because that's where the changes",
    "start": "2464640",
    "end": "2470000"
  },
  {
    "text": "are are going to be announced uh a lot of times there'll be some cool new feature that's announced that's not",
    "start": "2470000",
    "end": "2475079"
  },
  {
    "text": "available in your primary region uh so you you sort of shelf that and and don't look at it again well keep an eye on the",
    "start": "2475079",
    "end": "2481480"
  },
  {
    "text": "blog it's probably available now talk to your peers come to conferences like this uh listen to talks understand what what",
    "start": "2481480",
    "end": "2487920"
  },
  {
    "text": "other folks are doing in your industry uh and what assumptions they're challenging there's a a link down to",
    "start": "2487920",
    "end": "2493280"
  },
  {
    "text": "their to the bottom of for the EBS team if you if you need more information so even more importantly than all that",
    "start": "2493280",
    "end": "2500079"
  },
  {
    "text": "stuff we're hiring if uh if the problems that that jimini I talked about are interesting to you come talk to us uh we",
    "start": "2500079",
    "end": "2507560"
  },
  {
    "text": "we would love to to uh have your help and in spending the 100 million we just raised from",
    "start": "2507560",
    "end": "2513280"
  },
  {
    "text": "Google so remember to complete your evaluations if you guys have any questions please feel freee to to find",
    "start": "2513280",
    "end": "2519160"
  },
  {
    "text": "us after the talk or or at the bar",
    "start": "2519160",
    "end": "2522599"
  },
  {
    "text": "later",
    "start": "2524520",
    "end": "2527520"
  }
]
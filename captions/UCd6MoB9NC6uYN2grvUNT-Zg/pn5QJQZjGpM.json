[
  {
    "start": "0",
    "end": "145000"
  },
  {
    "text": "okay good morning everyone good morning",
    "start": "350",
    "end": "5640"
  },
  {
    "text": "everyone yeah I'm Ashwin rom I'm a senior manager",
    "start": "5640",
    "end": "11460"
  },
  {
    "text": "on the Alexus AI science team is part of Alexa machine learning I also have with",
    "start": "11460",
    "end": "16619"
  },
  {
    "text": "me Spiros McLucas one of our scientists I'll introduce him in a little more detail we're gonna speak with you today",
    "start": "16619",
    "end": "23430"
  },
  {
    "text": "about the science that was developed for the elect surprise the elect surprise I",
    "start": "23430",
    "end": "28439"
  },
  {
    "text": "think many of you aware was a competition we ran all year for university students to develop",
    "start": "28439",
    "end": "33780"
  },
  {
    "text": "conversation skills for Alexa that could speak with customers engagingly",
    "start": "33780",
    "end": "39809"
  },
  {
    "text": "and coherently for 20 minutes about popular topics in current events things",
    "start": "39809",
    "end": "45360"
  },
  {
    "text": "in the news sports politics etcetera I'll tell you a little bit more about that and in doing so you know in doing",
    "start": "45360",
    "end": "52890"
  },
  {
    "text": "this we had to advance the state of conversational AI many of the advances",
    "start": "52890",
    "end": "58170"
  },
  {
    "text": "that were made also applied to other kinds of conversational interactions and so we're excited to share those advances",
    "start": "58170",
    "end": "63750"
  },
  {
    "text": "with you before I talk about the elect surprise let's set the context by talking about conversation you imagine a",
    "start": "63750",
    "end": "71040"
  },
  {
    "text": "customer speaking with Alexa or an Alexa enable device and having a conversation",
    "start": "71040",
    "end": "77570"
  },
  {
    "text": "so a conversation between people or between a person and a machine involves",
    "start": "77570",
    "end": "82770"
  },
  {
    "text": "so multiple steps of interactions around a set of topics in this example for",
    "start": "82770",
    "end": "87960"
  },
  {
    "text": "example we have a user saying is it hot outside Alexa responds where the sunny and warm",
    "start": "87960",
    "end": "94590"
  },
  {
    "text": "how about this weekend you now have to know how about refers to what's the",
    "start": "94590",
    "end": "100229"
  },
  {
    "text": "weather like this weekend as opposed to something else clouds are rolling in it will be overcast will I need an umbrella",
    "start": "100229",
    "end": "106880"
  },
  {
    "text": "it was the right answer now you don't really know unless you know the location Alexa I might ask you depends on where",
    "start": "106880",
    "end": "113460"
  },
  {
    "text": "you'll be I was thinking of hiking the dish okay so in that case etc so imagine",
    "start": "113460",
    "end": "119490"
  },
  {
    "text": "a multi turn natural conversation around weather or music or ordering something",
    "start": "119490",
    "end": "124500"
  },
  {
    "text": "online whatever your application may be where the user and an Alexa can sort of",
    "start": "124500",
    "end": "131610"
  },
  {
    "text": "have a natural conversation to unpack and with very little friction",
    "start": "131610",
    "end": "136740"
  },
  {
    "text": "get to what the right answer might be for the user answers are guessing and getting it wrong or giving them menus of",
    "start": "136740",
    "end": "142470"
  },
  {
    "text": "choices so that's sort of the aim when we started the elec surprised like with",
    "start": "142470",
    "end": "148440"
  },
  {
    "start": "145000",
    "end": "145000"
  },
  {
    "text": "many programs here at Amazon we start with what we call the North Star this is",
    "start": "148440",
    "end": "153750"
  },
  {
    "text": "so what success would look like if you can engage in a conversation like this so if you're conversing about everyday",
    "start": "153750",
    "end": "159780"
  },
  {
    "text": "social topics a user might come in and say Alexa let's chat about the Mars",
    "start": "159780",
    "end": "165420"
  },
  {
    "text": "mission so in this example we'll let you read it they're multiple Mars missions some projects are private who do you",
    "start": "165420",
    "end": "171570"
  },
  {
    "text": "think will succeed this is hard because now you're asking Alexa for an opinion about a future event that hasn't",
    "start": "171570",
    "end": "177390"
  },
  {
    "text": "occurred yet there's no right answer here but Alexa does have to respond I think more than one will succeed Sara",
    "start": "177390",
    "end": "183660"
  },
  {
    "text": "the user now says I'd love to go to Mars now the users expressing an opinion or a",
    "start": "183660",
    "end": "189030"
  },
  {
    "text": "preference you have to be able to incorporate that into the dialogue in this case we respond with humor",
    "start": "189030",
    "end": "195290"
  },
  {
    "text": "another hard problem right so we don't want to detract from the topic of the",
    "start": "195290",
    "end": "201870"
  },
  {
    "text": "conversation is still about going to Mars still about space but the humor",
    "start": "201870",
    "end": "208140"
  },
  {
    "text": "sort of woven in seamlessly Alexa then that's very funny relax are now changes the topic a little",
    "start": "208140",
    "end": "213900"
  },
  {
    "text": "bit it's the biggest challenges is is funding and now we are switching into",
    "start": "213900",
    "end": "219300"
  },
  {
    "text": "political political conversation even though still about technology and is still on topic so how do we maintain",
    "start": "219300",
    "end": "225390"
  },
  {
    "text": "topic across these turns you can imagine this for other kinds of contexts as well if you're interacting with Alexa about",
    "start": "225390",
    "end": "232770"
  },
  {
    "text": "say trying to find a movie to watch or planning a night out on the weekend you may be switching topics a little bit",
    "start": "232770",
    "end": "238650"
  },
  {
    "text": "where should I go was the weather going to be like I need a taxi can you get me a restaurant reservation and you're so",
    "start": "238650",
    "end": "243960"
  },
  {
    "text": "seamlessly moving around different intense and different entities but weaving that together into a natural",
    "start": "243960",
    "end": "249450"
  },
  {
    "text": "experience so that's the kind of capability we want to create it's very hard and it's hard for a number of",
    "start": "249450",
    "end": "255510"
  },
  {
    "start": "254000",
    "end": "254000"
  },
  {
    "text": "reasons speech recognition gets considerably harder we now have freeform conversational",
    "start": "255510",
    "end": "262140"
  },
  {
    "text": "speech we have users of speaking in longer sentences nope two previous previous eruptions as you",
    "start": "262140",
    "end": "269259"
  },
  {
    "text": "guess at them people paused more they restart what they're saying they're",
    "start": "269259",
    "end": "274419"
  },
  {
    "text": "armed and or and other things still have to get that right this language understanding how do we",
    "start": "274419",
    "end": "279729"
  },
  {
    "text": "understand what utterances mean particularly when someone says I'd love to go to Mars for example it's not an",
    "start": "279729",
    "end": "285490"
  },
  {
    "text": "intent necessarily we still have to get the meaning of that context modeling this is a hard problem this morning Roy",
    "start": "285490",
    "end": "292360"
  },
  {
    "text": "Prasad our chief scientist announced some of the context capabilities that we",
    "start": "292360",
    "end": "297430"
  },
  {
    "text": "are making available to developers being able to track what we are speaking about the intense in the entities in the",
    "start": "297430",
    "end": "304330"
  },
  {
    "text": "conversation across multiple terms of our dialogue and and carrying that context forward seamlessly dialogue",
    "start": "304330",
    "end": "311139"
  },
  {
    "text": "planning is about so picking the best response this gets particularly hard again when you have natural conversations and there is not a right",
    "start": "311139",
    "end": "318940"
  },
  {
    "text": "answer if there's a right answer the question we can give you an answer if it's not a question what do we say",
    "start": "318940",
    "end": "324490"
  },
  {
    "text": "what's the right thing to say language generation what's the best phrasing for this you want to tell the joke about",
    "start": "324490",
    "end": "330340"
  },
  {
    "text": "hitching a ride the serve away and it sounds funny and then there's sort of flat more flat ways of saying that how",
    "start": "330340",
    "end": "336130"
  },
  {
    "text": "do we adapt to two different users another key problem in speaking about",
    "start": "336130",
    "end": "341139"
  },
  {
    "text": "the daily news is knowledge ingestion if a social bot is what we call these",
    "start": "341139",
    "end": "346150"
  },
  {
    "text": "skills is able to talk about what's in the news this morning it has to have read the news and ingested it and",
    "start": "346150",
    "end": "351759"
  },
  {
    "text": "incorporate it into its models and this has to happen fairly dynamically pretty much in real-time or near real-time to",
    "start": "351759",
    "end": "358690"
  },
  {
    "text": "keep up with the current events and that's another hard problem common sense reasoning making inferences about these",
    "start": "358690",
    "end": "364810"
  },
  {
    "text": "things as saira so there are a lot of hard challenges in conversation there are also customer experience",
    "start": "364810",
    "end": "371110"
  },
  {
    "start": "369000",
    "end": "369000"
  },
  {
    "text": "challenges and these are some of them I won't go through all of these here but for example how do we break the ice how",
    "start": "371110",
    "end": "377770"
  },
  {
    "text": "do we start a conversation you know in the case of Alex surprise you start by saying Alexa let's chat and Alexa now",
    "start": "377770",
    "end": "384969"
  },
  {
    "text": "has to start sharing with you about what do we ask you your name first we ask you what you're interested in do we guess",
    "start": "384969",
    "end": "390669"
  },
  {
    "text": "that from what we know about you already and so forth how do we do a pause is how do we suggest topics do we want to sort",
    "start": "390669",
    "end": "398110"
  },
  {
    "text": "of sketch out a lot of different topics Bhuvana go really deep into a single topic what's more interesting what's",
    "start": "398110",
    "end": "404409"
  },
  {
    "text": "more engaging for a customer how do we lead the conversation on when the customer is not quite sure what to say",
    "start": "404409",
    "end": "409689"
  },
  {
    "text": "next how do we handle personal questions we don't want necessarily these",
    "start": "409689",
    "end": "414849"
  },
  {
    "text": "conversation skills to get too much private data out of users but users will talk about personal stuff expressing",
    "start": "414849",
    "end": "421539"
  },
  {
    "text": "opinions and sort of weighing that against controversy we don't want to be controversial",
    "start": "421539",
    "end": "427060"
  },
  {
    "text": "we don't want to be inflammatory but we do want to have opinions for example opinions that Alexa had in",
    "start": "427060",
    "end": "433659"
  },
  {
    "text": "the Mars mission example what do we do about frustration non-answer there's a ton of things that go into some",
    "start": "433659",
    "end": "440229"
  },
  {
    "text": "designing dialogue flow to maintain customer experience so to address these",
    "start": "440229",
    "end": "446199"
  },
  {
    "text": "challenges and I should add these challenges are currently unsolved there",
    "start": "446199",
    "end": "451509"
  },
  {
    "text": "is no mechanism there's no piece of software can download which does all of this already that you can just",
    "start": "451509",
    "end": "457389"
  },
  {
    "text": "incorporate so we have to invent this so to address this we decided we would take Alexa and create a research testbed",
    "start": "457389",
    "end": "466599"
  },
  {
    "text": "around Alexa that would enable university students to experiment with different techniques and learn from the",
    "start": "466599",
    "end": "473440"
  },
  {
    "text": "interactions that they might get from real users so we announced the relaxed",
    "start": "473440",
    "end": "479889"
  },
  {
    "text": "surprise a little over a year ago it was a two and a half million dollar competition to advance conversational AI",
    "start": "479889",
    "end": "485710"
  },
  {
    "text": "the challenge is to create one of these conversation skills a social bot a social chat bot that can converse",
    "start": "485710",
    "end": "491949"
  },
  {
    "text": "engagingly and coherently for 20 minutes and there's a million-dollar grand prize for reaching that bar we had over a",
    "start": "491949",
    "end": "501729"
  },
  {
    "text": "hundred teams up from different universities apply to participate we selected 18 of them and then 15 of them",
    "start": "501729",
    "end": "508930"
  },
  {
    "text": "actually developed and went public to the to the customer base on May 8th of",
    "start": "508930",
    "end": "514390"
  },
  {
    "text": "this year since for the last several weeks Alexa less chat has been our top ten",
    "start": "514390",
    "end": "521018"
  },
  {
    "text": "Alexis scale by usage that customers are very interested in chatting they've been over 40 thousand hours of conversation",
    "start": "521019",
    "end": "527500"
  },
  {
    "text": "with these social BOTS over the year over millions of interactions with customers and this provides",
    "start": "527500",
    "end": "533779"
  },
  {
    "text": "huge amount of data to the teams the universities to learn from feedback the customers rate the social about",
    "start": "533779",
    "end": "540170"
  },
  {
    "text": "conversations at the end and so all of that data and the feedback from customers was used to enhance and",
    "start": "540170",
    "end": "546860"
  },
  {
    "text": "improve these social BOTS until we finally ended up with three finalists and this morning announced the winner of",
    "start": "546860",
    "end": "553610"
  },
  {
    "text": "a half a million dollar prize that was the first prize none of the fine and none of these teams they already seemed exceedingly well if",
    "start": "553610",
    "end": "560629"
  },
  {
    "text": "you chat with them now it's quite amazing to see how far they've come but none of them were able to reach the 20",
    "start": "560629",
    "end": "566209"
  },
  {
    "text": "minute grand challenge and so we're going to run this challenge again next year so if any students here or folks",
    "start": "566209",
    "end": "572149"
  },
  {
    "text": "who have students at home or professors do encourage them to apply so what I",
    "start": "572149",
    "end": "578600"
  },
  {
    "text": "wanted to do today was share with you and some of the science advances that",
    "start": "578600",
    "end": "584629"
  },
  {
    "text": "were created in these areas language understanding dialogue modeling a sera that I mentioned over the course of the",
    "start": "584629",
    "end": "590870"
  },
  {
    "text": "year they're all 15 teams have written technical papers about the work they did which are available on the website alexa",
    "start": "590870",
    "end": "598100"
  },
  {
    "text": "price comm so you can actually read the science papers and get more details by",
    "start": "598100",
    "end": "603559"
  },
  {
    "text": "yourselves if you're interested but let me introduce Spiros masuka's he's a senior principal scientists on the Alexa",
    "start": "603559",
    "end": "609769"
  },
  {
    "text": "machine learning team who's been working closely with us in helping advance some of these technologies Spiros will tell",
    "start": "609769",
    "end": "616370"
  },
  {
    "text": "us more about some of these advances that were made Thank You Ashley so before we dive into",
    "start": "616370",
    "end": "623779"
  },
  {
    "text": "the details of the Alexa price competition I would like to give you an overview of the spoken language understanding technology in Alexa so",
    "start": "623779",
    "end": "632779"
  },
  {
    "start": "632000",
    "end": "632000"
  },
  {
    "text": "Alexa is a spoken language understanding service that lives in the cloud that",
    "start": "632779",
    "end": "637850"
  },
  {
    "text": "provides support for voice based interactions in a wide range of applications it is supported by two",
    "start": "637850",
    "end": "644959"
  },
  {
    "text": "powerful frameworks on the right hand side we show the Alexa voice service that enables Amazon devices such as echo",
    "start": "644959",
    "end": "652309"
  },
  {
    "text": "or parte V as well as third-party manufacturer devices to connect to Alexa and on the left hand side we show the",
    "start": "652309",
    "end": "659089"
  },
  {
    "text": "Alexa skills kit that enables third-party developers to extend Alexis functionality through what we call",
    "start": "659089",
    "end": "664939"
  },
  {
    "text": "skills so customers can use Alexa connected",
    "start": "664939",
    "end": "670170"
  },
  {
    "start": "667000",
    "end": "667000"
  },
  {
    "text": "devices to perform a wide range of tasks they can listen to music audiobooks they",
    "start": "670170",
    "end": "676050"
  },
  {
    "text": "can watch the big movies they can set timers alarms manage to-do lists shop on",
    "start": "676050",
    "end": "681450"
  },
  {
    "text": "amazon.com manage the calendar send messages place phone calls get information about weather traffic or",
    "start": "681450",
    "end": "688500"
  },
  {
    "text": "news control smartphone connected appliances such as lights thermostats switches and they have access to an",
    "start": "688500",
    "end": "695700"
  },
  {
    "text": "expanding set of skills over 25,000 currently that provide services such as",
    "start": "695700",
    "end": "701339"
  },
  {
    "text": "ordering food or managing finances or playing games and customers when they",
    "start": "701339",
    "end": "707460"
  },
  {
    "text": "access a lecture through a hands-free device such as Amazon echo they can do all of these things in the most natural",
    "start": "707460",
    "end": "712830"
  },
  {
    "text": "way by just using their voice from anywhere in the room without having to reach out for a phone or press any",
    "start": "712830",
    "end": "718200"
  },
  {
    "text": "buttons so every spoken language of the standing system is comprised of you know",
    "start": "718200",
    "end": "725520"
  },
  {
    "start": "720000",
    "end": "720000"
  },
  {
    "text": "four main components the automatic speech recognition natural language understanding a dialogue manager and a",
    "start": "725520",
    "end": "732510"
  },
  {
    "text": "text to speech synthesis module so let's see how each of these components is employed when processing a music request",
    "start": "732510",
    "end": "739860"
  },
  {
    "text": "such as play two steps behind by Def Leppard so first the automatic speech",
    "start": "739860",
    "end": "745020"
  },
  {
    "text": "recognition module is used to convert the audio into text then this is",
    "start": "745020",
    "end": "751140"
  },
  {
    "text": "processed by the natural language understanding component to extract the users intent and any salient elements",
    "start": "751140",
    "end": "757950"
  },
  {
    "text": "such as or slots associated with that intent in this specific example the",
    "start": "757950",
    "end": "763260"
  },
  {
    "text": "intent is playing music and there are two slots first is the artist name which is def leppard and the second is the song title",
    "start": "763260",
    "end": "770310"
  },
  {
    "text": "which is two steps behind then we reach the dialogue manager which takes in the text and the labels of the natural",
    "start": "770310",
    "end": "777660"
  },
  {
    "text": "language understanding component as long as as well as associated context and is",
    "start": "777660",
    "end": "784589"
  },
  {
    "text": "trying to decide what action to perform next so in this example it might decide to connect to the music skill and asking",
    "start": "784589",
    "end": "792510"
  },
  {
    "text": "to play the requested song or it might decide to engage the clarification dialogue with you",
    "start": "792510",
    "end": "797770"
  },
  {
    "text": "for example to clarify the name of the artist and in both cases it has to generate a text response or prompt that",
    "start": "797770",
    "end": "804910"
  },
  {
    "text": "then goes into the text to speech synthesis module to create an audio with Alexis voice to communicate the result",
    "start": "804910",
    "end": "811540"
  },
  {
    "text": "back to the user now the common underlying theme across",
    "start": "811540",
    "end": "817090"
  },
  {
    "start": "815000",
    "end": "815000"
  },
  {
    "text": "all of these components is data-driven machine learning and this consists primarily of two phases so at the bottom",
    "start": "817090",
    "end": "822520"
  },
  {
    "text": "of the slide we show the first page which is a training where input training data together with ground truth labels",
    "start": "822520",
    "end": "830470"
  },
  {
    "text": "are fed into an training component to generate statistical models these are physical models and then using the",
    "start": "830470",
    "end": "836680"
  },
  {
    "text": "second phase which is the inference or decoding phase the transit at run time",
    "start": "836680",
    "end": "841890"
  },
  {
    "text": "processing new inputs and trying to predict the Associated labels and so in",
    "start": "841890",
    "end": "847240"
  },
  {
    "text": "the case of the speech recognition the input is speech and the out was the sequence of the words whereas in the",
    "start": "847240",
    "end": "853330"
  },
  {
    "text": "case of the natural language understanding the input is the text and the output is the intention the slots so",
    "start": "853330",
    "end": "860020"
  },
  {
    "text": "this has several advantages first it relies on probabilistic modeling which",
    "start": "860020",
    "end": "865900"
  },
  {
    "text": "means that it's more robust to noise and ambiguity also it is relatively inexpensive to",
    "start": "865900",
    "end": "871630"
  },
  {
    "text": "generate ground truth you don't require experts in machine learning to do that",
    "start": "871630",
    "end": "877090"
  },
  {
    "text": "and third argument is that it's portable to new domains and languages so when you",
    "start": "877090",
    "end": "883450"
  },
  {
    "text": "want to put some new functionality let's say in a new language all you have to do is collect data in that language and",
    "start": "883450",
    "end": "889270"
  },
  {
    "text": "also provide you as you ground through the labels and you can reuse the same trainer and decoder modules you don't",
    "start": "889270",
    "end": "894880"
  },
  {
    "text": "have to implement anything now those of you who are familiar with the Alexa skill skied probably recognize these two",
    "start": "894880",
    "end": "901450"
  },
  {
    "text": "phases of machine learning during the skill development process when you provide the utterance samples these are",
    "start": "901450",
    "end": "908470"
  },
  {
    "text": "effectively used as training data to create energy models for intern recognition and name",
    "start": "908470",
    "end": "914010"
  },
  {
    "text": "entity recognition and so the more examples you provide the better these models become now another advantage of",
    "start": "914010",
    "end": "923400"
  },
  {
    "start": "921000",
    "end": "921000"
  },
  {
    "text": "data-driven machine learning is that once you have statistical models that you have deployed in production you can",
    "start": "923400",
    "end": "929340"
  },
  {
    "text": "continuously improve them using data that comes in from the field and so in",
    "start": "929340",
    "end": "934530"
  },
  {
    "text": "this slide we showed the maintenance life cycle for the ASR and then of your components in Alexa so data comes in we",
    "start": "934530",
    "end": "942420"
  },
  {
    "text": "have a portion of the data that is sampled to generate ground truth in this case audio transcriptions and also",
    "start": "942420",
    "end": "949920"
  },
  {
    "text": "labels for under new and we do that with smart selection techniques such as active learning to maximize the learning",
    "start": "949920",
    "end": "955800"
  },
  {
    "text": "value of the data that we that we annotate there is also a portion of unlabeled audio that is used as these to",
    "start": "955800",
    "end": "963990"
  },
  {
    "text": "train the ASR model without any human in the loop and such summer supervised techniques can also be applied to",
    "start": "963990",
    "end": "970320"
  },
  {
    "text": "natural language understanding then the resulting models undergo multiple",
    "start": "970320",
    "end": "975600"
  },
  {
    "text": "testing to be able to assess the impact of the model training in terms of accuracy and latency and once they pass",
    "start": "975600",
    "end": "982800"
  },
  {
    "text": "these tests they get deployed to production and then they start a new round of continuous improvement so now",
    "start": "982800",
    "end": "992880"
  },
  {
    "text": "let's go into the detail of each in each of the components of the spoken language understanding pipelines starting with",
    "start": "992880",
    "end": "999150"
  },
  {
    "text": "the automatic speech recognition now one of the biggest challenges in speech",
    "start": "999150",
    "end": "1004880"
  },
  {
    "start": "1002000",
    "end": "1002000"
  },
  {
    "text": "recognition certainly with a product like Amazon echo is the what you call",
    "start": "1004880",
    "end": "1010490"
  },
  {
    "text": "the far-field speech challenge which is that the speech is degraded due to phenomena such",
    "start": "1010490",
    "end": "1016040"
  },
  {
    "text": "as reverberation and sound bouncing off the walls in a room or ambient noise or",
    "start": "1016040",
    "end": "1021410"
  },
  {
    "text": "background speech and on top of that you have the standard challenges of speech",
    "start": "1021410",
    "end": "1026780"
  },
  {
    "text": "recognition which is large vocabulary high perplexity domains also is difficult sometimes to predict spoken",
    "start": "1026780",
    "end": "1033380"
  },
  {
    "text": "forms for catalog entries and there are social pronunciations especially with artist names artists tend to be creative",
    "start": "1033380",
    "end": "1039890"
  },
  {
    "text": "about how their in written form and then you also have acoustic confusions between you know",
    "start": "1039890",
    "end": "1046760"
  },
  {
    "text": "homophones so an example you know towards Sunday's versus the day of the week now a product like echo mitigates",
    "start": "1046760",
    "end": "1056900"
  },
  {
    "start": "1054000",
    "end": "1054000"
  },
  {
    "text": "the the far-field reverberation and ambient noise by using the microphone",
    "start": "1056900",
    "end": "1063590"
  },
  {
    "text": "that it has microphone array that he has at the top plate it has actually seven microphones six around the circumference",
    "start": "1063590",
    "end": "1069140"
  },
  {
    "text": "in the one in the center and with us with such a microphone array it can apply a technique called beamforming to",
    "start": "1069140",
    "end": "1075980"
  },
  {
    "text": "create six listening beams as we saw in the figure here and it's listening beam",
    "start": "1075980",
    "end": "1082040"
  },
  {
    "text": "enhances the signal that arrives from that direction while suppressing any signals that come from other directions",
    "start": "1082040",
    "end": "1087670"
  },
  {
    "text": "so in this example we show the user speaking to the device from Direction one and there is also a fan generating",
    "start": "1087670",
    "end": "1096380"
  },
  {
    "text": "noise from Direction six and I'm going to play a few audio samples from the different beams to see you know what is",
    "start": "1096380",
    "end": "1103790"
  },
  {
    "text": "the effect that that's happening through the beamforming first let's play the audio from the center channel the center",
    "start": "1103790",
    "end": "1109880"
  },
  {
    "text": "microphone without anything for me now",
    "start": "1109880",
    "end": "1119480"
  },
  {
    "text": "you heard that there is a mixture of the the two signals the speech from the user and the noise from the fan now if we",
    "start": "1119480",
    "end": "1126640"
  },
  {
    "text": "show the the beam in the direction number six which is pointing to the fan",
    "start": "1126640",
    "end": "1132410"
  },
  {
    "text": "you're going to listen you know the noise from they found more pronounced and the speeds were more suppressed",
    "start": "1132410",
    "end": "1140050"
  },
  {
    "text": "you now if we play the the audio that's",
    "start": "1142560",
    "end": "1147859"
  },
  {
    "text": "coming from being one you will see that the the reverse effect is happening a speech is enhanced and the noise is",
    "start": "1147859",
    "end": "1153769"
  },
  {
    "text": "suppressed play rock play The Rolling Stones play Radiohead could you play",
    "start": "1153769",
    "end": "1159559"
  },
  {
    "text": "better off alone and then we have the traditional problem is which beam to select and obviously we want to select",
    "start": "1159559",
    "end": "1166369"
  },
  {
    "text": "the beam that points in the direction of the user and we do that with a combination of signal-to-noise ratio and",
    "start": "1166369",
    "end": "1172039"
  },
  {
    "text": "speech activity detection now another problem that we have to deal with in a",
    "start": "1172039",
    "end": "1177769"
  },
  {
    "text": "device like echo is that usually a device is playing audio it's soft right",
    "start": "1177769",
    "end": "1183379"
  },
  {
    "text": "it can play music that you request before or it can have a response that is played through the text-to-speech module",
    "start": "1183379",
    "end": "1189139"
  },
  {
    "text": "and what happens is that each of these beams is now picking up this signal and that's interfering with its ability to",
    "start": "1189139",
    "end": "1195679"
  },
  {
    "text": "listen to the user and so we have this technique called acoustic echo cancellation which uses information",
    "start": "1195679",
    "end": "1202220"
  },
  {
    "text": "about the reference playback signal to subtract it from each of the beams before doing the beam selection and here",
    "start": "1202220",
    "end": "1208700"
  },
  {
    "text": "I'll show you two examples one is before the acoustic echo cancellation where three users are trying to wake up the",
    "start": "1208700",
    "end": "1215090"
  },
  {
    "text": "device by saying the world Alexa and then after ago cancellation so let's here first",
    "start": "1215090",
    "end": "1220159"
  },
  {
    "text": "without echo cancellation [Music]",
    "start": "1220159",
    "end": "1227810"
  },
  {
    "text": "[Applause]",
    "start": "1227810",
    "end": "1232069"
  },
  {
    "text": "so you can imagine in this case is very difficult for for Elektra to actually hear its name right when the user is",
    "start": "1234169",
    "end": "1241349"
  },
  {
    "text": "calling now after I got cancellation because we know what signal is playing",
    "start": "1241349",
    "end": "1246450"
  },
  {
    "text": "we can suppress it and therefore enhance this piece from the direction of the user élisa élisa Alexa",
    "start": "1246450",
    "end": "1259300"
  },
  {
    "text": "Alexa Alexa and so this has a very",
    "start": "1259300",
    "end": "1265220"
  },
  {
    "text": "pronounced effect and is very effective especially in detecting the way court during a playback ok so once we apply",
    "start": "1265220",
    "end": "1274280"
  },
  {
    "start": "1273000",
    "end": "1273000"
  },
  {
    "text": "these techniques on the device we send the enhanced audio to the cloud to carry out the speech recognition it so the",
    "start": "1274280",
    "end": "1280100"
  },
  {
    "text": "first step that we do in that process is feature extraction this consists of having a sliding window over the audio",
    "start": "1280100",
    "end": "1286700"
  },
  {
    "text": "waveform extracting a feature vector representation of the signal every 10",
    "start": "1286700",
    "end": "1291980"
  },
  {
    "text": "milliseconds and that feature vector basically encodes information about the energy level in each in different",
    "start": "1291980",
    "end": "1299030"
  },
  {
    "text": "frequency bands then we fed that in to repeat that into an acoustic model which",
    "start": "1299030",
    "end": "1305450"
  },
  {
    "text": "is in this case a deep neural network to map the feature vectors to phonetic probabilities and then this go into the",
    "start": "1305450",
    "end": "1312920"
  },
  {
    "text": "decoding or inference stage where along with the language model and pronunciation lexicon we try to find",
    "start": "1312920",
    "end": "1320960"
  },
  {
    "text": "what is the best sequence of words that corresponds to that speech signal and so we can have an example here where the",
    "start": "1320960",
    "end": "1327350"
  },
  {
    "text": "user said increase the 70 degrees you see the tokens coming out of the recognition and then optionally we have",
    "start": "1327350",
    "end": "1332960"
  },
  {
    "text": "a post-processing step to format that into a written form to display to the",
    "start": "1332960",
    "end": "1338150"
  },
  {
    "text": "user on the screen let's iron or Nicastro or FR TV now we mentioned the",
    "start": "1338150",
    "end": "1345170"
  },
  {
    "start": "1343000",
    "end": "1343000"
  },
  {
    "text": "language model as one of the components in that decoding step in the language",
    "start": "1345170",
    "end": "1350300"
  },
  {
    "text": "model consists of what we call under improbabilities basically the probability of a word following a",
    "start": "1350300",
    "end": "1355460"
  },
  {
    "text": "sequence of preceding words and in converis conversational free forms this",
    "start": "1355460",
    "end": "1360650"
  },
  {
    "text": "is this probabilities are very spread out basically it's not easy to predict",
    "start": "1360650",
    "end": "1366170"
  },
  {
    "text": "what word comes next given a sequence of words and in language model in terms",
    "start": "1366170",
    "end": "1372170"
  },
  {
    "text": "this is often characterized as having a high perplexity it is also addressing the branching factor during the search",
    "start": "1372170",
    "end": "1378800"
  },
  {
    "text": "for finding the best word sequence basically a high perplexity means higher branching factor more ambiguity and",
    "start": "1378800",
    "end": "1385730"
  },
  {
    "text": "therefore the search is more difficult so in order to improve that what we effectively what we have to do is",
    "start": "1385730",
    "end": "1391820"
  },
  {
    "text": "sharpen the probe of these engrams and we can do it by the easiest ways to increase the language",
    "start": "1391820",
    "end": "1397580"
  },
  {
    "text": "model capacity meaning you need to have more engrams and also bigger and graphs more context",
    "start": "1397580",
    "end": "1403520"
  },
  {
    "text": "now this increases the language model size unfortunately it can have a negative effect on latency so what we",
    "start": "1403520",
    "end": "1410900"
  },
  {
    "text": "did is we developed a new representation for the language models and the new decoder that allows us to actually use",
    "start": "1410900",
    "end": "1417740"
  },
  {
    "text": "language models as big as ten times more than what we used in ham before without any impact on latency and this",
    "start": "1417740",
    "end": "1424160"
  },
  {
    "text": "capability was very important for the electro prize program as we will see later enabling improvements in speech",
    "start": "1424160",
    "end": "1430309"
  },
  {
    "text": "recognition accuracy the other component that we referenced in the diagram was",
    "start": "1430309",
    "end": "1436130"
  },
  {
    "start": "1433000",
    "end": "1433000"
  },
  {
    "text": "the acoustic model and here we use as I mentioned earlier a deep neural network",
    "start": "1436130",
    "end": "1441440"
  },
  {
    "text": "that takes to the frame level speech features and is trying to predict the phonetic probabilities this network is",
    "start": "1441440",
    "end": "1447650"
  },
  {
    "text": "trained on data from lots of speakers so it can handle different accents and different speaking styles however we",
    "start": "1447650",
    "end": "1453650"
  },
  {
    "text": "found that we can do even better if we adapt this network or personalize it to each speaker on the fly and we can do",
    "start": "1453650",
    "end": "1459860"
  },
  {
    "text": "that by estimating a speaker level feature vector that characterizes the",
    "start": "1459860",
    "end": "1466250"
  },
  {
    "text": "the voice of the speaker in course course terms similar to the vector that we use for doing speaker identification",
    "start": "1466250",
    "end": "1472960"
  },
  {
    "text": "and we feed that as a site information to the deep neural network and that",
    "start": "1472960",
    "end": "1478010"
  },
  {
    "text": "effectively results in adapting the network to the speaker and we can update these estimates of the speaker features",
    "start": "1478010",
    "end": "1485420"
  },
  {
    "text": "with more utterances as the speaker's interact with the device so that led to about five to seven percent relative",
    "start": "1485420",
    "end": "1491540"
  },
  {
    "text": "reduction in word error rate compared to just using the speaker independent model",
    "start": "1491540",
    "end": "1496960"
  },
  {
    "text": "now another important aspect of speech recognition is the knowing when to stop listening right as we call the speech",
    "start": "1496960",
    "end": "1503960"
  },
  {
    "start": "1497000",
    "end": "1497000"
  },
  {
    "text": "and pointing and on a device like I call this is very much needed because there is no button so a user doesn't press a",
    "start": "1503960",
    "end": "1510920"
  },
  {
    "text": "button to indicate when they stop speaking so you have to detect it automatically a naive way to do this is",
    "start": "1510920",
    "end": "1516770"
  },
  {
    "text": "to have an energy level detector and when there is a pause the energy",
    "start": "1516770",
    "end": "1521809"
  },
  {
    "text": "naturally drops down and you can stop at long pause but consider this example where the user",
    "start": "1521809",
    "end": "1527330"
  },
  {
    "text": "might say play music by Sting so there is a pause before saying the artist name",
    "start": "1527330",
    "end": "1532370"
  },
  {
    "text": "a simple detector like an energy-based is going to more likely break at the",
    "start": "1532370",
    "end": "1538880"
  },
  {
    "text": "first pause interrupting the user so this is a form of early end pointing which is an error so what we've done to",
    "start": "1538880",
    "end": "1545630"
  },
  {
    "text": "mitigate this is to have we have a acoustic and linguistic information that we are combining so in this case the two",
    "start": "1545630",
    "end": "1552680"
  },
  {
    "text": "pauses are very similar from an acoustic perspective but they are very different from a linguistic perspective the second",
    "start": "1552680",
    "end": "1558500"
  },
  {
    "text": "pause is much more likely to be at the end of a sentence than the first one and so that that helps mitigate these",
    "start": "1558500",
    "end": "1563630"
  },
  {
    "text": "problems now earlier in point and pointing is one problem other is late",
    "start": "1563630",
    "end": "1569750"
  },
  {
    "start": "1566000",
    "end": "1566000"
  },
  {
    "text": "and pointing and this is best illustrated with an example where you can have the user saying Alexa play",
    "start": "1569750",
    "end": "1575330"
  },
  {
    "text": "music and then somebody else in the background saying something else and now you know the system might be confused",
    "start": "1575330",
    "end": "1581960"
  },
  {
    "text": "and think that this second speaker is actually directing the request to the device and keeping the audio stream open",
    "start": "1581960",
    "end": "1588170"
  },
  {
    "text": "for too long that increases the latency of responding to the first user and it",
    "start": "1588170",
    "end": "1593270"
  },
  {
    "text": "also introduces the opportunity for word insertion errors so what we want to do",
    "start": "1593270",
    "end": "1598940"
  },
  {
    "text": "effectively is to be able to listen to the first user who spoke the way card and ignore the second user right so what",
    "start": "1598940",
    "end": "1606650"
  },
  {
    "text": "we can do that is three technique we call anchored speech detection what we do basically is we use the wake word to",
    "start": "1606650",
    "end": "1613880"
  },
  {
    "text": "create a model of the anchor speaker in this case the person who spoke the way code using a recurrent neural network or",
    "start": "1613880",
    "end": "1620480"
  },
  {
    "text": "encoder to create a fixed length representation of this onkled speech and then we feed that as side information to",
    "start": "1620480",
    "end": "1627080"
  },
  {
    "text": "the decoder network which frame-by-frame is trying to predict whether this speech",
    "start": "1627080",
    "end": "1632450"
  },
  {
    "text": "is coming from the anchor speaker or not and this basically helps quite a bit with this problem it reduces the frame",
    "start": "1632450",
    "end": "1640130"
  },
  {
    "text": "classification error rate by 19% and also leads to 9% relative reduction in",
    "start": "1640130",
    "end": "1645200"
  },
  {
    "text": "order rate compared to just using a baseline approach okay so that was speech recognition is",
    "start": "1645200",
    "end": "1652370"
  },
  {
    "text": "gone now to the next component which is natural language understanding so here the goal is to understand the",
    "start": "1652370",
    "end": "1658950"
  },
  {
    "start": "1656000",
    "end": "1656000"
  },
  {
    "text": "spoken intent and the slots that may be associated with it and we talked about this in the beginning with the example",
    "start": "1658950",
    "end": "1665450"
  },
  {
    "text": "now the challenges here are that you have cross-domain intend recognition errors two very different requests may",
    "start": "1665450",
    "end": "1673980"
  },
  {
    "text": "share the same word so play remind me or remind me to go to the play refer to very different intents if you just use",
    "start": "1673980",
    "end": "1681059"
  },
  {
    "text": "bag of words or presentations you're not going to be able to distinguish them from each other the word order is very",
    "start": "1681059",
    "end": "1686250"
  },
  {
    "text": "important the other is that you challenge that you have to be robust to ASR errors you also have to be a to",
    "start": "1686250",
    "end": "1695040"
  },
  {
    "text": "accommodate user correction in context so in this case if a user wants to",
    "start": "1695040",
    "end": "1700070"
  },
  {
    "text": "rephrase the request without having to speak it again they can just say in all",
    "start": "1700070",
    "end": "1705120"
  },
  {
    "text": "the rolling stones meaning that they want the system to understand that they want to just change the the artist name",
    "start": "1705120",
    "end": "1711870"
  },
  {
    "text": "and they're not stating and you intent also the system has to be able to reject",
    "start": "1711870",
    "end": "1717120"
  },
  {
    "text": "out of the main utterances it basically has to know what are the things that it cannot support and we have to do all of",
    "start": "1717120",
    "end": "1723360"
  },
  {
    "text": "these things with high precision and recall because typically there is no screen connected for the user to select",
    "start": "1723360",
    "end": "1729900"
  },
  {
    "text": "between a set of options so if you look at the intent classification problem",
    "start": "1729900",
    "end": "1736230"
  },
  {
    "start": "1733000",
    "end": "1733000"
  },
  {
    "text": "even for a very simple request such as getting information about the weather there are many different ways that user",
    "start": "1736230",
    "end": "1742290"
  },
  {
    "text": "can access this information right then we have a list of examples here on top of this linguistic variability there is",
    "start": "1742290",
    "end": "1748380"
  },
  {
    "text": "also spoken language effects for example the user might hesitate or might",
    "start": "1748380",
    "end": "1753510"
  },
  {
    "text": "introduce some some Poly's or word restarts and the system has the bureau Buster those kinds of effects similarly",
    "start": "1753510",
    "end": "1761250"
  },
  {
    "start": "1761000",
    "end": "1761000"
  },
  {
    "text": "for the named entity recognition even for you know it's just a date type there",
    "start": "1761250",
    "end": "1766260"
  },
  {
    "text": "is many ways to refer to that and so the model should be able to recognize these",
    "start": "1766260",
    "end": "1772230"
  },
  {
    "text": "word sequences as having the same datatype related to that is the entity",
    "start": "1772230",
    "end": "1778620"
  },
  {
    "start": "1777000",
    "end": "1777000"
  },
  {
    "text": "resolution or entity linking so this is once you have detected a particular entity type let's say weather location",
    "start": "1778620",
    "end": "1785250"
  },
  {
    "text": "city or what date you have to now take those spoken terms and associate them or link them to",
    "start": "1785250",
    "end": "1793419"
  },
  {
    "text": "a real-world entity which may be an entity value in a catalog for example the spoken tokens la that we have to map",
    "start": "1793419",
    "end": "1800679"
  },
  {
    "text": "to Los Angeles in order to be able to execute on behalf of the user similarly tomorrow we have to be",
    "start": "1800679",
    "end": "1807039"
  },
  {
    "text": "resolved to an actual date okay so now",
    "start": "1807039",
    "end": "1812289"
  },
  {
    "text": "the another component we mentioned is text to speech synthesis this has its own set of challenges",
    "start": "1812289",
    "end": "1818049"
  },
  {
    "start": "1814000",
    "end": "1814000"
  },
  {
    "text": "so it has to do with homographs now this is words that are written identically",
    "start": "1818049",
    "end": "1823450"
  },
  {
    "text": "but they have different pronunciations like live and live and so it has to be",
    "start": "1823450",
    "end": "1828789"
  },
  {
    "text": "able to resolve that ambiguity by taking into account the context around the words another problem is normalizing the",
    "start": "1828789",
    "end": "1835299"
  },
  {
    "text": "text sometimes the text that you pull out from Wikipedia if you want to speak it back to the user",
    "start": "1835299",
    "end": "1840669"
  },
  {
    "text": "it has abbreviations that need to be expanded like am when need minutes or miles so depending on the context also",
    "start": "1840669",
    "end": "1849070"
  },
  {
    "text": "we have to convert the text to phonemes which is you know the graphing to phoneme conversion and for languages",
    "start": "1849070",
    "end": "1854619"
  },
  {
    "text": "with complex mappings this may be difficult English is one example the",
    "start": "1854619",
    "end": "1859629"
  },
  {
    "text": "pronunciation may vary also depending on the location of the user and then you have to deal with foreign words proper",
    "start": "1859629",
    "end": "1865629"
  },
  {
    "text": "names and slang so here we can see how all of these things come together in an",
    "start": "1865629",
    "end": "1872049"
  },
  {
    "start": "1869000",
    "end": "1869000"
  },
  {
    "text": "example so let's say that the text is she has 20 dollars in her pocket first",
    "start": "1872049",
    "end": "1877239"
  },
  {
    "text": "we have to do the text normalization to convert it to spoken for expanding the",
    "start": "1877239",
    "end": "1883299"
  },
  {
    "text": "digits into the spoken formal presentation a dollar sign as well then we have to predict the pronunciations",
    "start": "1883299",
    "end": "1890230"
  },
  {
    "text": "for each of these tokens using the graphing the phoneme conversion we can see now the sequence of all the phonemes",
    "start": "1890230",
    "end": "1895690"
  },
  {
    "text": "and then based on that you have to construct the waveform there is one",
    "start": "1895690",
    "end": "1900700"
  },
  {
    "text": "approach concatenative synthesis is trying to pull acoustic units and stitch them together to create the waveform",
    "start": "1900700",
    "end": "1906759"
  },
  {
    "text": "that sounds natural and then you have the overall the speech she has twenty dollars in her pocket and of course",
    "start": "1906759",
    "end": "1914940"
  },
  {
    "text": "developers can also use besides having the texture on here they can use I shall markup to indicate how this text",
    "start": "1914940",
    "end": "1922350"
  },
  {
    "text": "should be spoken by Alexa to indicate an emphasis for example by changing the porosity or adding pauses and stress",
    "start": "1922350",
    "end": "1930650"
  },
  {
    "text": "finally the other component we mentioned in the beginning is the dialogue manager and so this sits between the natural",
    "start": "1930710",
    "end": "1937380"
  },
  {
    "start": "1936000",
    "end": "1936000"
  },
  {
    "text": "language understanding and the application layer it is basically used to you know create multi turn",
    "start": "1937380",
    "end": "1944760"
  },
  {
    "text": "interactions with the user in the context of a dialogue the goal is to understand and satisfy the users need",
    "start": "1944760",
    "end": "1951390"
  },
  {
    "text": "through a sequence of interactions while minimizing the notion of accumulated frustration and there is many challenges",
    "start": "1951390",
    "end": "1957930"
  },
  {
    "text": "in doing that first the users goal might actually change or evolve during the",
    "start": "1957930",
    "end": "1963450"
  },
  {
    "text": "course of the conversation also the dialogue manager has to understand in context taking into account user",
    "start": "1963450",
    "end": "1969960"
  },
  {
    "text": "preferences as well I may have to coordinate with multiple skills for",
    "start": "1969960",
    "end": "1975000"
  },
  {
    "text": "example if you make a reservation for a dinner you might want also to create a",
    "start": "1975000",
    "end": "1980210"
  },
  {
    "text": "reminder in your calendar it has to be robust ways other than a few errors also",
    "start": "1980210",
    "end": "1987270"
  },
  {
    "text": "handle ambiguity and a list of proper tariff occation and with feedback from the user the response that it generates",
    "start": "1987270",
    "end": "1994170"
  },
  {
    "text": "they must be natural and engaging and you have to do all of these things maintaining a balance between eliciting",
    "start": "1994170",
    "end": "2000560"
  },
  {
    "text": "the required information and introducing friction so it's not an approach to",
    "start": "2000560",
    "end": "2006800"
  },
  {
    "text": "doing a dialogue manager in a probabilistic way is the using the Markov decision process and that",
    "start": "2006800",
    "end": "2012500"
  },
  {
    "text": "consists of several components there first is the set of dialogue States next",
    "start": "2012500",
    "end": "2018500"
  },
  {
    "text": "is the set of actions from the current state then you have pi which is the dialogue policy mapping States to",
    "start": "2018500",
    "end": "2024590"
  },
  {
    "text": "actions you also need to model the transition probabilities between states",
    "start": "2024590",
    "end": "2029750"
  },
  {
    "text": "so basically being able to predict what is the next state given the current state and an action then you have to",
    "start": "2029750",
    "end": "2037460"
  },
  {
    "text": "estimate a reward function from the input that the user is providing in each turn that basically is a link to user",
    "start": "2037460",
    "end": "2045530"
  },
  {
    "text": "satisfaction in some way and then you have this discount factor gamma that is trying to balance a short",
    "start": "2045530",
    "end": "2051908"
  },
  {
    "text": "versus long-term reward and then you know one one common approach is to apply",
    "start": "2051909",
    "end": "2058599"
  },
  {
    "text": "reinforcement learning to actually be able to learn from the sequence of interactions so what happens is that you",
    "start": "2058599",
    "end": "2064929"
  },
  {
    "text": "have the tuples of state action and reward from those you estimate the expected cumulative record given the",
    "start": "2064929",
    "end": "2071408"
  },
  {
    "text": "policy and then over time you alternate between these two phases of exploration and exploitation in the exploration",
    "start": "2071409",
    "end": "2077919"
  },
  {
    "text": "phase you take actions that may be deemed suboptimal but you're trying to search the space to see if there are",
    "start": "2077919",
    "end": "2083470"
  },
  {
    "text": "better better policies to leverage and then you have the exploitation phase where you take actions that maximize the",
    "start": "2083470",
    "end": "2090069"
  },
  {
    "text": "expected cumulative reward and this is basically the leading to the optimal policy okay so now let's talk about the",
    "start": "2090069",
    "end": "2099339"
  },
  {
    "text": "lexer prize competition in more detail some of the signs that took place in",
    "start": "2099339",
    "end": "2104500"
  },
  {
    "text": "each of these components of the spoken language understanding so first was the",
    "start": "2104500",
    "end": "2109809"
  },
  {
    "start": "2107000",
    "end": "2107000"
  },
  {
    "text": "conversational ASR the election team created a customized the ASR language",
    "start": "2109809",
    "end": "2115480"
  },
  {
    "text": "model to be able to improve the aspects that we discussed earlier about the",
    "start": "2115480",
    "end": "2120910"
  },
  {
    "text": "perplexity so this was a larger language model that was also trained with more conversational text and speech",
    "start": "2120910",
    "end": "2128109"
  },
  {
    "text": "transcripts the university teams to increase robustness they used and best output from the speech recognition on",
    "start": "2128109",
    "end": "2135430"
  },
  {
    "text": "the conversational energy side we introduced the conversational intent so that we can connect the customers to the",
    "start": "2135430",
    "end": "2142359"
  },
  {
    "text": "social BOTS when they want to say a lexical is chat or Alexa would you like to have a conversation about Mars",
    "start": "2142359",
    "end": "2149170"
  },
  {
    "text": "mission university teams used open-source knowledge bases in grass for",
    "start": "2149170",
    "end": "2154869"
  },
  {
    "text": "example Eevee freebase wiki data IMDB they also did an opera resolution",
    "start": "2154869",
    "end": "2161710"
  },
  {
    "text": "silence completion named entity extraction topic licking and more and",
    "start": "2161710",
    "end": "2169599"
  },
  {
    "text": "then we have the dialogue manager that was one key component of course in the conversational system there the",
    "start": "2169599",
    "end": "2175990"
  },
  {
    "text": "university teams used a range of approaches including combination of macro and micro BOTS",
    "start": "2175990",
    "end": "2183110"
  },
  {
    "text": "and the microbots different in many different ways the different dimensions so one dimensional variation was topics",
    "start": "2183110",
    "end": "2189200"
  },
  {
    "text": "for example you had microbots specializing on sports or politics or fashion another dimension was data",
    "start": "2189200",
    "end": "2196820"
  },
  {
    "text": "microbots trained only on reddit or Twitter or Washington Post corporate and",
    "start": "2196820",
    "end": "2202670"
  },
  {
    "text": "then intent so for example you could have a micro boy that was specializing on chit chat and another one on opinion",
    "start": "2202670",
    "end": "2209150"
  },
  {
    "text": "or knowledge of course they had to track State School through the dialogue",
    "start": "2209150",
    "end": "2216370"
  },
  {
    "text": "leveraging information about the user extracting sentiment also personal preferences some teams had specialized",
    "start": "2216370",
    "end": "2224870"
  },
  {
    "text": "modules for engagement and customer experience to be able to drive longer dialogues and more engaging",
    "start": "2224870",
    "end": "2230390"
  },
  {
    "text": "conversations and then what practically all teams had to have components to detect with profanity and on pensive",
    "start": "2230390",
    "end": "2237980"
  },
  {
    "text": "speech and try to mitigate at both offline when processing large collections of text for their training",
    "start": "2237980",
    "end": "2243650"
  },
  {
    "text": "as well as during runtime during the actual conversation with a customer on",
    "start": "2243650",
    "end": "2249620"
  },
  {
    "text": "the response generation side there were different approaches that were employed by the university teams one approach was",
    "start": "2249620",
    "end": "2256310"
  },
  {
    "text": "to have rule-based templates so using a high ml or eliezer systems another",
    "start": "2256310",
    "end": "2263240"
  },
  {
    "text": "approach was to have retrieval were basically you create offline a response Bank and then during runtime you relate",
    "start": "2263240",
    "end": "2271040"
  },
  {
    "text": "the users utterance to one of these responses in internal in the in the back",
    "start": "2271040",
    "end": "2277870"
  },
  {
    "text": "and this can be created from reddit twitter or washington post the the",
    "start": "2277870",
    "end": "2282980"
  },
  {
    "text": "matching can be done with similarity based on criteria such as tf-idf or worth of a course and a subheadings like",
    "start": "2282980",
    "end": "2289160"
  },
  {
    "text": "skip thoughts and anything matching another approach for more handling more",
    "start": "2289160",
    "end": "2295970"
  },
  {
    "text": "complex ambitious and Phatak responses was to use generative models that actually construct the response on the",
    "start": "2295970",
    "end": "2302720"
  },
  {
    "text": "fly and these are trained using LST m/s or memory networks some teams use",
    "start": "2302720",
    "end": "2309440"
  },
  {
    "text": "hierarchical neural networks attention and other sequence to sequence models there were also combinations of these",
    "start": "2309440",
    "end": "2316250"
  },
  {
    "text": "thing call hybrid systems so basically you have an assemble of retrieval and",
    "start": "2316250",
    "end": "2321600"
  },
  {
    "text": "generative models we have sometimes the retrieval models are executed first generating candidate responses which are",
    "start": "2321600",
    "end": "2327780"
  },
  {
    "text": "then ranked using a generative model or you have retrieval models but you fall",
    "start": "2327780",
    "end": "2332970"
  },
  {
    "text": "back to the generative model if the confidence of the retrieval system is low and there were also multiple",
    "start": "2332970",
    "end": "2340680"
  },
  {
    "text": "strategies so different techniques for different microbots for example using rules and tablets for",
    "start": "2340680",
    "end": "2347130"
  },
  {
    "text": "question and answering or a generative models for chitchat",
    "start": "2347130",
    "end": "2352070"
  },
  {
    "text": "now when you have microbots that provide the different responses you have the problem of you know how to select",
    "start": "2352430",
    "end": "2358740"
  },
  {
    "text": "between them and it's something some teams developed ranking modules to be",
    "start": "2358740",
    "end": "2364920"
  },
  {
    "text": "able to cope with that problem features that were used to train the rank are",
    "start": "2364920",
    "end": "2370230"
  },
  {
    "text": "included sentiment utterance response coherence relevance user feedback and",
    "start": "2370230",
    "end": "2375840"
  },
  {
    "text": "Graham and topical match and the best strategy was to continually update the rancor based on user feedback and rating",
    "start": "2375840",
    "end": "2383430"
  },
  {
    "text": "using using reinforcement learning now speaking of feedback the the",
    "start": "2383430",
    "end": "2390120"
  },
  {
    "start": "2387000",
    "end": "2387000"
  },
  {
    "text": "university teams had access to different forms so first there was the rating that",
    "start": "2390120",
    "end": "2395340"
  },
  {
    "text": "was provided by the actual customer that they were interacting with and this was in the number in the range of one to",
    "start": "2395340",
    "end": "2401460"
  },
  {
    "text": "five then there was feedback that was provided by the Alexa prize team itself",
    "start": "2401460",
    "end": "2406890"
  },
  {
    "text": "through some data analytics that was performed on the conversations that were carried out between the customers and",
    "start": "2406890",
    "end": "2413670"
  },
  {
    "text": "the social BOTS and that consisted of different dimensions so one was the topic conversational quality other was",
    "start": "2413670",
    "end": "2420510"
  },
  {
    "text": "response error rate coherence engagement and customer experience gaps for example",
    "start": "2420510",
    "end": "2426510"
  },
  {
    "text": "looking at cases where the dialogue navigation was not optimal or where the",
    "start": "2426510",
    "end": "2432780"
  },
  {
    "text": "intent recognition was not correct and then the Alexa price team also shared",
    "start": "2432780",
    "end": "2438930"
  },
  {
    "text": "utterance response pairs that were where the social boss had trouble and these",
    "start": "2438930",
    "end": "2444690"
  },
  {
    "text": "were used all of these including the customer feedback were used by the social was to provide better",
    "start": "2444690",
    "end": "2451080"
  },
  {
    "text": "experiences basically update components and to pattern in the dialogue some of",
    "start": "2451080",
    "end": "2458130"
  },
  {
    "start": "2457000",
    "end": "2457000"
  },
  {
    "text": "the key learnings from analyzing the feedback from the users now besides the rating the users also had an opportunity",
    "start": "2458130",
    "end": "2464400"
  },
  {
    "text": "to provide the open-ended feedback to the social posts that were interacting with and from those we could see that",
    "start": "2464400",
    "end": "2471270"
  },
  {
    "text": "basically they were generally interested in conversing with social BOTS they appreciate it when the social was",
    "start": "2471270",
    "end": "2478170"
  },
  {
    "text": "acknowledged they request even if they couldn't support it so basically knowing",
    "start": "2478170",
    "end": "2483540"
  },
  {
    "text": "what they didn't know this was a preferred thing for the users perspective users did not like switching",
    "start": "2483540",
    "end": "2490800"
  },
  {
    "text": "topics abruptly during the dialogue and some users were very engaged with some",
    "start": "2490800",
    "end": "2497070"
  },
  {
    "text": "of the games that social BOTS could employ I know at least my daughter was",
    "start": "2497070",
    "end": "2503010"
  },
  {
    "text": "very you know engaged with popularity and no personality quiz now of course",
    "start": "2503010",
    "end": "2511140"
  },
  {
    "start": "2509000",
    "end": "2509000"
  },
  {
    "text": "this this is a competition so we had to come up with evaluation metrics to be able to evaluate the social buzz that",
    "start": "2511140",
    "end": "2517590"
  },
  {
    "text": "were participating and so one dimensional evaluation was coherence so",
    "start": "2517590",
    "end": "2522990"
  },
  {
    "text": "basically taking taking a look at the turn level response quality and this was done through data annotation another",
    "start": "2522990",
    "end": "2530880"
  },
  {
    "text": "view was engagement this demonstrated by the user ratings number of turns the duration of the conversation domain",
    "start": "2530880",
    "end": "2538950"
  },
  {
    "text": "converts was another dimension basically trying to assess entropy across the top",
    "start": "2538950",
    "end": "2545520"
  },
  {
    "text": "five competing domains entertainment politics sports fashion and technology",
    "start": "2545520",
    "end": "2551300"
  },
  {
    "text": "topical diversity was another view trying to analyze the topic frequency",
    "start": "2551300",
    "end": "2556800"
  },
  {
    "text": "vocabulary and variation in topics across the conversations for each of the social BOTS conversational depth which",
    "start": "2556800",
    "end": "2564840"
  },
  {
    "text": "is the ability to have multi turn conversations about the topic before switching to another topic and then for",
    "start": "2564840",
    "end": "2572880"
  },
  {
    "text": "the finalist to intern to determine what were the three top social was to go into the finals we selected the top",
    "start": "2572880",
    "end": "2579850"
  },
  {
    "text": "- based on the customer ratings and the third one was selected based on the above metrics a large pool of eternal",
    "start": "2579850",
    "end": "2587440"
  },
  {
    "text": "evaluators and science paper reviews so the teams had to submit papers describing the technology and this was",
    "start": "2587440",
    "end": "2593140"
  },
  {
    "text": "part of the criteria that led to the finalists determination so now let's",
    "start": "2593140",
    "end": "2599020"
  },
  {
    "start": "2598000",
    "end": "2598000"
  },
  {
    "text": "look at the result so this graph shows the daily average rating for the social",
    "start": "2599020",
    "end": "2607540"
  },
  {
    "text": "BOTS we have two lines here the top line corresponds to the three finalists and",
    "start": "2607540",
    "end": "2612940"
  },
  {
    "text": "and the one at the bottom is four across all the social boots and these are",
    "start": "2612940",
    "end": "2618580"
  },
  {
    "text": "basically as we said earlier from ratings in the range of one to five and as we can see over the period of time",
    "start": "2618580",
    "end": "2624670"
  },
  {
    "text": "the ratings approved for the finalists by 24% relative now we can see here",
    "start": "2624670",
    "end": "2632260"
  },
  {
    "text": "there are three distinct phases first is the launch of the program on May 8 then",
    "start": "2632260",
    "end": "2638230"
  },
  {
    "text": "we have the semi-final period and then we have the post semi-final periods and",
    "start": "2638230",
    "end": "2643270"
  },
  {
    "text": "we can see that there is a marked difference in the performance certainly during the semi-final period which is from the end of June to end of August",
    "start": "2643270",
    "end": "2649890"
  },
  {
    "text": "for the three finalists and this is where we also got a lot of internal",
    "start": "2649890",
    "end": "2656700"
  },
  {
    "text": "users to interact with the social was to provide more opportunities for learning for the University teams and we can see",
    "start": "2656700",
    "end": "2665740"
  },
  {
    "text": "that there were actually several occasions where the ratings exceeded 3.5 during that period another interesting",
    "start": "2665740",
    "end": "2673870"
  },
  {
    "text": "aspect is that we had these echo newsletters if we were sending periodically",
    "start": "2673870",
    "end": "2679300"
  },
  {
    "text": "to all the customers all Alexa customers where we announce the availability of the lexer prize social BOTS and",
    "start": "2679300",
    "end": "2687140"
  },
  {
    "text": "and if you can see that there are some drops in the ratings with every of these new newsletters and that typically",
    "start": "2687140",
    "end": "2693799"
  },
  {
    "text": "indicates that there were new users that were starting to interact with the social boss and because they didn't know",
    "start": "2693799",
    "end": "2699680"
  },
  {
    "text": "to expect you could see this drop this is common but then as you can see it ramps up over time another aspect that",
    "start": "2699680",
    "end": "2706880"
  },
  {
    "text": "led to this improvement in ratings is also what we Alexa Price team did to",
    "start": "2706880",
    "end": "2713059"
  },
  {
    "text": "improve the conversational language model that we discussed earlier so through it you know the larger language",
    "start": "2713059",
    "end": "2719779"
  },
  {
    "text": "modeling and also training or more mass text and conversational text we saw a 41",
    "start": "2719779",
    "end": "2725569"
  },
  {
    "text": "percent reduction in areas are induced failures and that was very helpful now a",
    "start": "2725569",
    "end": "2732829"
  },
  {
    "text": "few other key metrics to see for the entire competition first there is average rating response error rate",
    "start": "2732829",
    "end": "2738890"
  },
  {
    "text": "average number of turns and media and dialogue duration and we can see that the finalist social BOTS did better than",
    "start": "2738890",
    "end": "2745640"
  },
  {
    "text": "you know compared to all social BOTS on all of each of these dimensions and then",
    "start": "2745640",
    "end": "2751249"
  },
  {
    "text": "this difference is more pronounced in the semifinals as we mentioned earlier between the two categories okay so we",
    "start": "2751249",
    "end": "2763039"
  },
  {
    "start": "2761000",
    "end": "2761000"
  },
  {
    "text": "reached the last slide so here's some conclusions and next step so let's start",
    "start": "2763039",
    "end": "2768140"
  },
  {
    "text": "with the conclusion so good progress this year but the problem is far from solved as I mentioned earlier today we",
    "start": "2768140",
    "end": "2775249"
  },
  {
    "text": "are intending to continue this competition next year just to have the",
    "start": "2775249",
    "end": "2780619"
  },
  {
    "text": "University teams leverage the data that they obtained through this phase and improve the technology further the",
    "start": "2780619",
    "end": "2787789"
  },
  {
    "text": "customer ratings depending on many factors in addition to ASR and response correctness obviously engagement is a",
    "start": "2787789",
    "end": "2794119"
  },
  {
    "text": "very complex term it's not just that you you have a very good technology you have to be able to have the right prompts and",
    "start": "2794119",
    "end": "2800739"
  },
  {
    "text": "engaging conversations of course high quality relevant data is critical",
    "start": "2800739",
    "end": "2806720"
  },
  {
    "text": "developing a good dialogue system and we hope that with the collection of this many hours forty thousand hours of a",
    "start": "2806720",
    "end": "2813230"
  },
  {
    "text": "million their actions now we have bigger opportunities for for growth and development in this space and the team's",
    "start": "2813230",
    "end": "2820710"
  },
  {
    "text": "not because this was the first year they spend a lot of time in actually engineering right the components",
    "start": "2820710",
    "end": "2826500"
  },
  {
    "text": "connecting them together making sure that the services were up and running we expect that the next year they will",
    "start": "2826500",
    "end": "2833700"
  },
  {
    "text": "focus more on actually developing the core technology and this would lead to further improvements so in terms of next",
    "start": "2833700",
    "end": "2840690"
  },
  {
    "text": "steps so we will share these years learnings with the research community through published proceedings I think",
    "start": "2840690",
    "end": "2846870"
  },
  {
    "text": "these are already up in the lexer prize comm website so I went karate together and and see what the university teams",
    "start": "2846870",
    "end": "2853230"
  },
  {
    "text": "did also we need to continue improving the conversational ASR this is a key",
    "start": "2853230",
    "end": "2859110"
  },
  {
    "text": "component in the dialogue this needs to be as accurate as possible and to",
    "start": "2859110",
    "end": "2864540"
  },
  {
    "text": "provide next year's election prize contestants with additional engineering support and tools and so this is the end",
    "start": "2864540",
    "end": "2871590"
  },
  {
    "text": "of the talk I would like also to ask you in this case you know what is the next gear that you would like to develop how",
    "start": "2871590",
    "end": "2878070"
  },
  {
    "text": "will you design your interaction model to create this engaging conversational experiences with the customers and I",
    "start": "2878070",
    "end": "2885150"
  },
  {
    "text": "would like to encourage you to take advantage of the many sessions and the tutorials this week and we'll do the",
    "start": "2885150",
    "end": "2891330"
  },
  {
    "text": "best to support you and answer your questions thank you [Applause]",
    "start": "2891330",
    "end": "2898670"
  }
]
[
  {
    "start": "0",
    "end": "40000"
  },
  {
    "text": "all right good afternoon everyone and welcome my name is America ani I'm a product manager for the Amazon s3 team",
    "start": "140",
    "end": "6690"
  },
  {
    "text": "very happy to have you guys here really excited to talk about some of the new announcements being made at for Amazon",
    "start": "6690",
    "end": "12389"
  },
  {
    "text": "s3 this week some very cool stuff coming up we also have here John Elliot from",
    "start": "12389",
    "end": "17910"
  },
  {
    "text": "Pinterest John helps John John helps manage the data and storage platform for Pinterest using Amazon s3 to build a",
    "start": "17910",
    "end": "25019"
  },
  {
    "text": "global visual petabyte scale search engine I think the way John put it for me was the world's catalogue of ideas got that",
    "start": "25019",
    "end": "32160"
  },
  {
    "text": "right yeah so so we'll hear about how Pinterest leverages Amazon s3 at scale",
    "start": "32160",
    "end": "37320"
  },
  {
    "text": "should be pretty exciting so with that let's get started so about this session",
    "start": "37320",
    "end": "43320"
  },
  {
    "start": "40000",
    "end": "84000"
  },
  {
    "text": "today I'm gonna spend a little bit of time talking about how we at Amazon s3 think about storage management and why",
    "start": "43320",
    "end": "49680"
  },
  {
    "text": "that's important for us and our customers after that we'll dive into some of the new stuff that we've",
    "start": "49680",
    "end": "55020"
  },
  {
    "text": "announced this this week which essentially helps customers understand which stories to have on s3 monitor how",
    "start": "55020",
    "end": "61800"
  },
  {
    "text": "their storage is being used and then use all of this intelligence and all of this information to more effectively manage",
    "start": "61800",
    "end": "67260"
  },
  {
    "text": "your storage in this 3 and get more value out of your data in s3 well then quickly pull that together and",
    "start": "67260",
    "end": "73590"
  },
  {
    "text": "talk about what that means for you and then I'll hand it over to John to talk about how Pinterest users Amazon s3 and",
    "start": "73590",
    "end": "79439"
  },
  {
    "text": "some of the new capabilities that that we just announced so why is storage",
    "start": "79439",
    "end": "87299"
  },
  {
    "start": "84000",
    "end": "103000"
  },
  {
    "text": "management important for our customers now our customers love Amazon s3 because it just works a lot of you in this room",
    "start": "87299",
    "end": "92820"
  },
  {
    "text": "I'm sure are either using Amazon s3 or at least are considering using s3 at scale for your data Lake for your data",
    "start": "92820",
    "end": "100290"
  },
  {
    "text": "leaks but you know the thing I hear about from customers about s3 all the",
    "start": "100290",
    "end": "106979"
  },
  {
    "start": "103000",
    "end": "130000"
  },
  {
    "text": "time is that it is simple to use that is sort of the biggest value proposition that I put my data it's always there",
    "start": "106979",
    "end": "112409"
  },
  {
    "text": "it's highly durable it's highly available it's always available for me to use and I can come back and get my",
    "start": "112409",
    "end": "117719"
  },
  {
    "text": "data whenever I need it and those principles are core to Amazon s3 and we're always focused on making sure that",
    "start": "117719",
    "end": "123149"
  },
  {
    "text": "we provide highest durability in the highest availability and the highest quality of service for our customers but",
    "start": "123149",
    "end": "129959"
  },
  {
    "text": "another big aspect of what we do is scale right we think of ourselves as the storage for",
    "start": "129959",
    "end": "135959"
  },
  {
    "start": "130000",
    "end": "164000"
  },
  {
    "text": "the Internet and as such we have to think internet scale and that is a big value for our customers because you",
    "start": "135959",
    "end": "142200"
  },
  {
    "text": "don't need to worry about scale we have customers you know who have trillions of objects in s3 we regularly serve up to",
    "start": "142200",
    "end": "148590"
  },
  {
    "text": "millions of transactions per second we have customers from the hundreds of petabytes all the way to exabytes on s3",
    "start": "148590",
    "end": "154170"
  },
  {
    "text": "and that really kind of speaks to how we help our customers grow their business in history without having to worry about",
    "start": "154170",
    "end": "159690"
  },
  {
    "text": "durability availability or even scale but as you get to that scale there are a",
    "start": "159690",
    "end": "166470"
  },
  {
    "text": "set of interesting problems that come in right because at the end of the day when you use s3 as your data they can put all",
    "start": "166470",
    "end": "171810"
  },
  {
    "text": "of this information in s3 you want to make sure that you can actually derive value from this data data sitting all by",
    "start": "171810",
    "end": "177330"
  },
  {
    "text": "itself doesn't really help what you want is to be able to understand what you have and then pull value from this data",
    "start": "177330",
    "end": "183780"
  },
  {
    "text": "you know leverage the ecosystem that we offer an Amazon Web Services such as you",
    "start": "183780",
    "end": "188910"
  },
  {
    "text": "know EMR use Hadoop using Hadoop analyze your information use the new Athena",
    "start": "188910",
    "end": "195510"
  },
  {
    "text": "service that we announced to crack open your August and look into and and query your data in s3 or use the use redshift",
    "start": "195510",
    "end": "202620"
  },
  {
    "text": "4 for your data warehouse and so forth so there's all of these different services that we have available that put",
    "start": "202620",
    "end": "207750"
  },
  {
    "text": "together make it very easy for you to derive value from your data but you can't really do that unless you know",
    "start": "207750",
    "end": "213900"
  },
  {
    "text": "what data you have and that is a very common question I get from customers is that you know I know my data secure it",
    "start": "213900",
    "end": "219569"
  },
  {
    "text": "sitting in s3 but I need help understanding what is that like what data do I have how is that being used",
    "start": "219569",
    "end": "225150"
  },
  {
    "text": "and then what can I do about it with this information and it all kind of comes down to data-driven intelligent",
    "start": "225150",
    "end": "230639"
  },
  {
    "text": "storage management and that was a big part of the focus that for the team this",
    "start": "230639",
    "end": "235650"
  },
  {
    "start": "233000",
    "end": "249000"
  },
  {
    "text": "year which led to these announcements that we have for s3 and we wanted to make sure that we provide you with a",
    "start": "235650",
    "end": "241109"
  },
  {
    "text": "robust set of tools that help you get to this this insight about your data on s3",
    "start": "241109",
    "end": "246510"
  },
  {
    "text": "and better manage this information so this is a busy slide and as I was kind",
    "start": "246510",
    "end": "253019"
  },
  {
    "start": "249000",
    "end": "602000"
  },
  {
    "text": "of building this I was thinking it's a lot of content but that really speaks to the focus that we have in s3 to",
    "start": "253019",
    "end": "259799"
  },
  {
    "text": "providing the right set of tools to you guys so that you have the right tools available to both understand your the",
    "start": "259799",
    "end": "265620"
  },
  {
    "text": "data that you have and really kind of make your data more useful derive value from it at the bottom you see the core core",
    "start": "265620",
    "end": "274090"
  },
  {
    "text": "platform for s3 and last year we added to this with a new storage class that is",
    "start": "274090",
    "end": "279190"
  },
  {
    "text": "standard infrequent axis so now you have a choice of storage class for you to select depending on what data you're",
    "start": "279190",
    "end": "285310"
  },
  {
    "text": "storing in s3 if you have active data that you read a lot you have s3 standard a lot for customers use that if you're",
    "start": "285310",
    "end": "292300"
  },
  {
    "text": "thinking about archival you can simply put your data into glacier and then have very very low cost storage and but still",
    "start": "292300",
    "end": "299440"
  },
  {
    "text": "have the same 11 nines of durability and of course in the middle there we announce standard infrequent access",
    "start": "299440",
    "end": "304840"
  },
  {
    "text": "specifically designed for those workloads that are infrequently access so you have all of this choice to make",
    "start": "304840",
    "end": "311259"
  },
  {
    "text": "sure that you move your data from standard to infrequent access if that's what makes sense for you and maybe even archive it and remove it but in order to",
    "start": "311259",
    "end": "320500"
  },
  {
    "text": "manage all of this data you need the right set of tools right one common example I hear is you know I've got",
    "start": "320500",
    "end": "326530"
  },
  {
    "text": "10,000 objects in this tree I can simply use the list API I can get a thousand of time I just need to call it 10 times",
    "start": "326530",
    "end": "331690"
  },
  {
    "text": "weight works perfectly what happens when you have 800 billion objects in history right you could still use the latest API",
    "start": "331690",
    "end": "338139"
  },
  {
    "text": "it absolutely works but it is going to be quite a few lists API calls right and",
    "start": "338139",
    "end": "343389"
  },
  {
    "text": "that kind of is kind of speaks to the the core principle of how we think about Storage Management and s3 is that we",
    "start": "343389",
    "end": "349389"
  },
  {
    "text": "think it's our job to make sure that we remove undifferentiated heavy lifting on a customer's part all of these",
    "start": "349389",
    "end": "355960"
  },
  {
    "text": "repetitive tasks that customers have to do you can still do but we want to make your lives easier so you can focus on",
    "start": "355960",
    "end": "362470"
  },
  {
    "text": "what's important to you what's important to your business and applications so let's look at some of these storage",
    "start": "362470",
    "end": "368860"
  },
  {
    "text": "management capabilities we have up there lifecycle it's been available for a few years a lot of our customers use this",
    "start": "368860",
    "end": "374289"
  },
  {
    "text": "and this is a simple service a configuration that you put on your bucket that automatically based on the rules that you've defined moves data",
    "start": "374289",
    "end": "380830"
  },
  {
    "text": "from one storage class to another or even expires data if that is what you choose so you can write a policy that",
    "start": "380830",
    "end": "386530"
  },
  {
    "text": "says all of my data that is 60 days old I don't really use much so just move it into standard and frequent access six",
    "start": "386530",
    "end": "393220"
  },
  {
    "text": "months later moving into into a glacier because it's ready to be archived so regardless of the size of data that you",
    "start": "393220",
    "end": "399760"
  },
  {
    "text": "have the number of objects that you have s3 automatically takes care of that for you so that you can focus again on your",
    "start": "399760",
    "end": "406170"
  },
  {
    "text": "applications we have cross region replication another feature for customers who want to replicate a copy of their data mostly for compliance",
    "start": "406170",
    "end": "412470"
  },
  {
    "text": "reasons a few hundred miles apart in those cases you could either you know write code to move data or you can",
    "start": "412470",
    "end": "418980"
  },
  {
    "text": "simply put a configuration on your bucket and s3 for any new object that comes into your bucket s3 will",
    "start": "418980",
    "end": "424440"
  },
  {
    "text": "automatically move that over to a destination bucket of your choice in a different region we have event",
    "start": "424440",
    "end": "430770"
  },
  {
    "text": "notifications that allow you to leverage again the ecosystem that we have available in AWS so you can trigger",
    "start": "430770",
    "end": "436860"
  },
  {
    "text": "multiple services when an event happens in s3 so when let's say a new object gets put you can trigger a notification",
    "start": "436860",
    "end": "443220"
  },
  {
    "text": "have that delivered either to sqs SNS or even trigger a lambda function to kick off those compute functions but to maybe",
    "start": "443220",
    "end": "449880"
  },
  {
    "text": "create a thumbnail for a new object that new image that that you upload it but again leveraging the the broader",
    "start": "449880",
    "end": "455460"
  },
  {
    "text": "ecosystem that you have that we have available for s3 to derive more value from your data and then we have a whole",
    "start": "455460",
    "end": "462030"
  },
  {
    "text": "suite of services that we announced this week in fact this curious how many of you guys were aware of the new features",
    "start": "462030",
    "end": "467670"
  },
  {
    "text": "that we announced in s3 this week there is a lot going on so okay so that's why",
    "start": "467670",
    "end": "472680"
  },
  {
    "text": "we're here that's great so the first one I want to quickly talk about and we will go into detail for each of these in the",
    "start": "472680",
    "end": "479730"
  },
  {
    "text": "session here is s3 object tags a completely new way for you to organize",
    "start": "479730",
    "end": "485040"
  },
  {
    "text": "data in s3 and manage your data based on the metadata that you have or",
    "start": "485040",
    "end": "490140"
  },
  {
    "text": "information that you have about your objects for instance you might add a tag on an object that says this is log data",
    "start": "490140",
    "end": "496380"
  },
  {
    "text": "and then you have an entire workflow defined on when you want to move that log data at the standard infrequent access when you want to archive that or",
    "start": "496380",
    "end": "503130"
  },
  {
    "text": "delete that but now you can manage your data based on what it is as opposed to where it's stored and that you think is",
    "start": "503130",
    "end": "509490"
  },
  {
    "text": "super powerful we also have we're also improving and making it easier for you to both operationally manage the",
    "start": "509490",
    "end": "516390"
  },
  {
    "text": "performance of your of your applications in s3 and understand what experience your users actually getting with a whole",
    "start": "516390",
    "end": "522270"
  },
  {
    "text": "suite of new cloud watch metrics we also announce a new feature called s3",
    "start": "522270",
    "end": "527940"
  },
  {
    "text": "inventory which really is an alternate an asynchronous alternate to list API going back to this example that I talked",
    "start": "527940",
    "end": "534240"
  },
  {
    "text": "about just now that if you've got hundreds of billions of objects you could either write code to list all of that or you can simply put this",
    "start": "534240",
    "end": "541440"
  },
  {
    "text": "configuration on your bucket and s3 will create that an entire list of all of",
    "start": "541440",
    "end": "546720"
  },
  {
    "text": "your data along with this relevant metadata and deliver that to an s3 bucket of your choice so you can then",
    "start": "546720",
    "end": "552210"
  },
  {
    "text": "simply pick that up and kick off your downstream workflows another very exciting service that we're announcing",
    "start": "552210",
    "end": "558060"
  },
  {
    "text": "is s3 analytics which essentially does analysis about your data it is data",
    "start": "558060",
    "end": "563490"
  },
  {
    "text": "about your data I in this case we're announcing a storage class analysis a new type of analysis in s3 analytics",
    "start": "563490",
    "end": "570480"
  },
  {
    "text": "which will automatically look at all of his usage patterns and I'll show you the observed usage patterns and actually I",
    "start": "570480",
    "end": "576870"
  },
  {
    "text": "hope you understand what parts of your storage are heavily used versus infrequently access so you can make the",
    "start": "576870",
    "end": "582000"
  },
  {
    "text": "right decisions around moving this data into the right storage class and then lastly we announced even better",
    "start": "582000",
    "end": "588660"
  },
  {
    "text": "integration with editors cloud trail with s3 data events which allows you to use a cloud trail service which is our",
    "start": "588660",
    "end": "594420"
  },
  {
    "text": "audit plug-in service to not only track bucket level operations but operations on your objects so let's dive a bit",
    "start": "594420",
    "end": "603750"
  },
  {
    "text": "deeper right so the first question of you know how do we help our customers understand what storage they have on s3",
    "start": "603750",
    "end": "609330"
  },
  {
    "text": "a lot of our customers today are using features like server access also now",
    "start": "609330",
    "end": "614970"
  },
  {
    "text": "these are logs that we have available in s3 and you can turn this on for your bucket for free and this delivers a",
    "start": "614970",
    "end": "621000"
  },
  {
    "text": "complete log activity log and puts it in an s3 bucket of your choice we have",
    "start": "621000",
    "end": "626040"
  },
  {
    "text": "customers who are listing all of s3 picking up these access logs and then running EMR jobs to then analyze all the",
    "start": "626040",
    "end": "633450"
  },
  {
    "text": "usage information and then come up with meaningful insights actionable insights for themselves and John's gonna talk a",
    "start": "633450",
    "end": "638940"
  },
  {
    "text": "bit about this you know it's you knows a little bit about this and so you know that's this that's great and a lot of",
    "start": "638940",
    "end": "645000"
  },
  {
    "text": "times there are very meaningful and there is very meaningful insights that you can derive from your usage patterns to improve your business processes but",
    "start": "645000",
    "end": "652800"
  },
  {
    "text": "we again want to make it easier for our customers to do so and that is where inventory and s3 analytics help so",
    "start": "652800",
    "end": "660390"
  },
  {
    "start": "659000",
    "end": "754000"
  },
  {
    "text": "looking at inventory a bit closer so this is about you know the most common use case I hear from your entry",
    "start": "660390",
    "end": "666010"
  },
  {
    "text": "really is that you know I want to trigger some downstream workflow and make decisions about my data but I",
    "start": "666010",
    "end": "671110"
  },
  {
    "text": "really can't do that without knowing what I have so a lot of these workflows really start with a list of data that",
    "start": "671110",
    "end": "676510"
  },
  {
    "text": "you have you might be kicking off a Big Data job which again needs to list all of the data before it pulls it into into",
    "start": "676510",
    "end": "681670"
  },
  {
    "text": "HDFS and you start kicking off your your your MapReduce job or you might have a downstream workflow for a secondary",
    "start": "681670",
    "end": "688720"
  },
  {
    "text": "index that you want to validate which again you need a list of all of the data in s3 so you can validate that your index is accurate or update your index",
    "start": "688720",
    "end": "695770"
  },
  {
    "text": "you know garbage collection or data auditing and offline analytics there's all of these different use cases that we have all of which start with customers",
    "start": "695770",
    "end": "703180"
  },
  {
    "text": "having to list all of their data or parts of their data in this tree and that's where as three inventory helps it",
    "start": "703180",
    "end": "709810"
  },
  {
    "text": "saves time because it is a simple configuration you can put it on a bucket and forget about it fire and forget and",
    "start": "709810",
    "end": "714850"
  },
  {
    "text": "s3 will automatically do the work get that create that list created in a simple CSV file format and deliver it to",
    "start": "714850",
    "end": "721930"
  },
  {
    "text": "an s3 bucket of your choice you can decide to do this on a daily basis you can get a daily daily list of your of",
    "start": "721930",
    "end": "729100"
  },
  {
    "text": "your objects in s3 or you can do this on a weekly basis as well and it is extremely cost efficient it is actually",
    "start": "729100",
    "end": "735310"
  },
  {
    "text": "half the price of the list API today not to mention that you'll have to use some sort of compute to kick off those",
    "start": "735310",
    "end": "741280"
  },
  {
    "text": "list list operations but just the list request costs itself it actually costs you half the price of that to enable",
    "start": "741280",
    "end": "748240"
  },
  {
    "text": "this so again making it very very easy low cost for customers to do to get",
    "start": "748240",
    "end": "754000"
  },
  {
    "start": "754000",
    "end": "809000"
  },
  {
    "text": "information about their data in s3 so here's the list of all of the",
    "start": "754000",
    "end": "759310"
  },
  {
    "text": "information that we provide as part of this right but I think the key point here really is that in addition to what",
    "start": "759310",
    "end": "764380"
  },
  {
    "text": "data you have we provide you provide you with all the relevant metadata that's available in list API today plus more",
    "start": "764380",
    "end": "770530"
  },
  {
    "text": "information for instance replication status that's not something that's available in the list API but we heard",
    "start": "770530",
    "end": "775540"
  },
  {
    "text": "customers ask for this because a lot of times for compliance reasons when I have cross region replication enabled I need",
    "start": "775540",
    "end": "781720"
  },
  {
    "text": "to go back and be able to answer what percentage of my data has successfully replicated or was in flight you know",
    "start": "781720",
    "end": "787300"
  },
  {
    "text": "10th of last month and for for use cases like those you can simply enable inventory and then store this in your in",
    "start": "787300",
    "end": "793510"
  },
  {
    "text": "your s3 bucket and when somebody asks a question you can simply go back and look at exactly what the status of replication",
    "start": "793510",
    "end": "799210"
  },
  {
    "text": "for any given object we will have",
    "start": "799210",
    "end": "804640"
  },
  {
    "text": "questions at the end so we'll make sure both John and I are available for questions all right so one thing I",
    "start": "804640",
    "end": "811450"
  },
  {
    "text": "wanted to call out is you know as I mentioned you you have the ability to deliver inventory to a bucket of your",
    "start": "811450",
    "end": "817540"
  },
  {
    "text": "choice that bucket does need to be in the same region and you need to make sure that you have the right set of permissions available on that you know",
    "start": "817540",
    "end": "824200"
  },
  {
    "text": "this kind of speaks to how important how much importance we give to security we want to make sure that your data is",
    "start": "824200",
    "end": "829330"
  },
  {
    "text": "always secure in s3 so so you know as a customer you need to make sure you go",
    "start": "829330",
    "end": "835150"
  },
  {
    "text": "put the right permissions in your destination bucket as well as enabling the configuration on your s3 bucket so",
    "start": "835150",
    "end": "841960"
  },
  {
    "text": "just something to keep in mind as you guys start playing around with this all",
    "start": "841960",
    "end": "848950"
  },
  {
    "text": "right so how does inventory work right it is basically a rolling snapshot of all of",
    "start": "848950",
    "end": "856050"
  },
  {
    "start": "849000",
    "end": "927000"
  },
  {
    "text": "your data in s3 right but a very common question I hear from customers is well when do I know that the list is complete",
    "start": "856050",
    "end": "861569"
  },
  {
    "text": "because I've got so many objects right it's gonna start showing up the CSV files it wouldn't be one file it like should be a set of different files just",
    "start": "861569",
    "end": "868769"
  },
  {
    "text": "so it's easier for you to pull that information in your in your workflows but how do you know what files are part",
    "start": "868769",
    "end": "874799"
  },
  {
    "text": "of my list how do I know that the list is complete so the way that structure would work is that once you specify a",
    "start": "874799",
    "end": "880259"
  },
  {
    "text": "destination bucket and prefix forests within that prefix we will create a data prefix as well as a date for the report",
    "start": "880259",
    "end": "887489"
  },
  {
    "text": "the data prefix is going to have a compressed list of all the CSVs for your inventory once that is complete as 3",
    "start": "887489",
    "end": "894929"
  },
  {
    "text": "will then come back and put a manifest file in in the the day of report the",
    "start": "894929",
    "end": "900540"
  },
  {
    "text": "date prefix so you can simply go into the date prefix and look for the manifest once that shows up the manifest",
    "start": "900540",
    "end": "906480"
  },
  {
    "text": "or checksum you can then again use event notifications that we just talked about",
    "start": "906480",
    "end": "911489"
  },
  {
    "text": "to trigger a notification to trigger maybe lamda code or put an SNS or sqs to",
    "start": "911489",
    "end": "917850"
  },
  {
    "text": "let your application know that the list is now complete and it can come in and pull data from s3 and then move on with",
    "start": "917850",
    "end": "923910"
  },
  {
    "text": "the downstream workflow so I mentioned",
    "start": "923910",
    "end": "929069"
  },
  {
    "start": "927000",
    "end": "1000000"
  },
  {
    "text": "s3 is is an is an is a rolling snapshot so there's a couple of important considerations for you for you guys one",
    "start": "929069",
    "end": "935910"
  },
  {
    "text": "is s3 is eventually consistent for for read after update operations for read",
    "start": "935910",
    "end": "941699"
  },
  {
    "text": "after write operations it is strongly consistent but if you're updating objects s3 is eventually consistent and",
    "start": "941699",
    "end": "947249"
  },
  {
    "text": "that kind of shows in the inventory as well where let's say you're triggered inventory for today and and you also put",
    "start": "947249",
    "end": "953100"
  },
  {
    "text": "in a bunch of objects you should not expect a guarantee for those objects to",
    "start": "953100",
    "end": "958410"
  },
  {
    "text": "be in your inventory so you need to check write and really the the thing to remember is you know validate before you",
    "start": "958410",
    "end": "963839"
  },
  {
    "text": "act right you need to make sure that if let's say you're putting an object in s3 and you want to make sure that you're not duplicating it so you're checking",
    "start": "963839",
    "end": "970230"
  },
  {
    "text": "the inventory make sure you check you do a head on the bucket as well to make sure that the object isn't there in your",
    "start": "970230",
    "end": "975869"
  },
  {
    "text": "clobbering or if you want to remove an object same same guidance there or if",
    "start": "975869",
    "end": "981089"
  },
  {
    "text": "you're trying to get an object right you don't really need to do a head in that case because Gabe will we return the appropriate error because",
    "start": "981089",
    "end": "986439"
  },
  {
    "text": "it is possible that you kicked off a list and at the same time you deleted an object it may be in your inventory list",
    "start": "986439",
    "end": "991720"
  },
  {
    "text": "but it will you know the object has actually been deleted so those are sort of considerations you need to think about as you use inventory for your",
    "start": "991720",
    "end": "998679"
  },
  {
    "text": "workflows alright so let's talk a bit",
    "start": "998679",
    "end": "1003749"
  },
  {
    "start": "1000000",
    "end": "1135000"
  },
  {
    "text": "about analytics the goal for this really is to help customers make data-driven decisions around storage management and the most",
    "start": "1003749",
    "end": "1011100"
  },
  {
    "text": "common question I hear from customers is that you know I I really interested in standard infrequent access I can know",
    "start": "1011100",
    "end": "1016230"
  },
  {
    "text": "that a lot of my data is infrequently access I just don't know what parts of it right in some cases it's a very easy",
    "start": "1016230",
    "end": "1022619"
  },
  {
    "text": "decision it's an archival workload I know I just never read the documents so you can simply move them into glaciar",
    "start": "1022619",
    "end": "1028019"
  },
  {
    "text": "but other times data actually cools down over time so you might be viewing a",
    "start": "1028019",
    "end": "1033360"
  },
  {
    "text": "video very very actively for one week maybe two maybe three and then over time it cools down and it becomes a valid",
    "start": "1033360",
    "end": "1040380"
  },
  {
    "text": "candidate for data into into standard infrequent access but how do I know that because I don't you know unless I build",
    "start": "1040380",
    "end": "1046470"
  },
  {
    "text": "those VM our jobs will be very hard for me to understand the actual usage pattern so that I can make an informed",
    "start": "1046470",
    "end": "1051899"
  },
  {
    "text": "decision and that's where analytics helps again a simple configuration you can enable on your bucket but we wanted",
    "start": "1051899",
    "end": "1058590"
  },
  {
    "text": "to go beyond there right we don't enable this just for your bucket we could if that's what you want but you also have the ability to enable this for specific",
    "start": "1058590",
    "end": "1065610"
  },
  {
    "text": "prefixes within your bucket and that's important because a lot of our customers have multiple workloads running within",
    "start": "1065610",
    "end": "1071880"
  },
  {
    "text": "the same bucket so in order to get the right kind of insight in the right level of understanding you want to analyze",
    "start": "1071880",
    "end": "1078750"
  },
  {
    "text": "these separately right because if you merge all this together you'll see an aggregate usage pattern so maybe I have a very very active workload and a",
    "start": "1078750",
    "end": "1084440"
  },
  {
    "text": "network load that just isn't being read at all if you were if you analyze everything together in your bucket you will lose some fidelity as opposed to",
    "start": "1084440",
    "end": "1091500"
  },
  {
    "text": "analyzing it just for that specific application and that's where prefixes help and then object tags is another way",
    "start": "1091500",
    "end": "1097679"
  },
  {
    "text": "we allow you to analyze and we'll talk a bit more about how tags work the goal",
    "start": "1097679",
    "end": "1103110"
  },
  {
    "text": "really is to make it easier for you to make decisions on storage cache analyses and find candidates for lifecycle",
    "start": "1103110",
    "end": "1108659"
  },
  {
    "text": "transitions and in addition to providing the analysis in the in the s3 console",
    "start": "1108659",
    "end": "1114389"
  },
  {
    "text": "itself we actually help you export we allow you to or this data as well in case you want to",
    "start": "1114389",
    "end": "1119399"
  },
  {
    "text": "use your own your own tools and it is extremely cost effective only 10 cents",
    "start": "1119399",
    "end": "1124590"
  },
  {
    "text": "per million objects analyzed per month much much lower cost and what it will cost you to build your own EMR job and",
    "start": "1124590",
    "end": "1130880"
  },
  {
    "text": "as I mentioned you do have the ability to to export this and use your own BI",
    "start": "1130880",
    "end": "1136140"
  },
  {
    "start": "1135000",
    "end": "1144000"
  },
  {
    "text": "tools so let's take a look real quick at what this looks like in action ok yes",
    "start": "1136140",
    "end": "1146730"
  },
  {
    "start": "1144000",
    "end": "1255000"
  },
  {
    "text": "and see that all right so another update that we made with this announcement is",
    "start": "1146730",
    "end": "1153149"
  },
  {
    "text": "actually a new console for for s3 you can opt into this by simply going to the announcements banner in your in your",
    "start": "1153149",
    "end": "1160070"
  },
  {
    "text": "previous on the older s3 console so when you do click in as three you to see a list of buckets there's an announcement",
    "start": "1160070",
    "end": "1165929"
  },
  {
    "text": "banner on the right you can opt into this new console and you can of course decide to opt out of this as well",
    "start": "1165929",
    "end": "1171029"
  },
  {
    "text": "within this new console so I over here I created a bunch of buckets that enable",
    "start": "1171029",
    "end": "1176340"
  },
  {
    "text": "cloud trails so that's been created and I created two different prefixes one is",
    "start": "1176340",
    "end": "1181620"
  },
  {
    "text": "for my data Lake Corp and another one I'm calling data Lake production so let's go into the data Lake production",
    "start": "1181620",
    "end": "1188010"
  },
  {
    "text": "so over here I have three different workloads I have I have archival I have",
    "start": "1188010",
    "end": "1194070"
  },
  {
    "text": "my my daily SPARC job and I have sales material as well so you know archival is",
    "start": "1194070",
    "end": "1200039"
  },
  {
    "text": "pretty obvious in you know I probably don't really use the archival so it might be a good candidate for transitioning into a lower-cost storage",
    "start": "1200039",
    "end": "1206340"
  },
  {
    "text": "option I have a daily SPARC jobs as the name indicates it's probably very heavily used and then I have sales",
    "start": "1206340",
    "end": "1211830"
  },
  {
    "text": "material and I have no idea of what the user pattern is on this so let's start with that you now have a new management",
    "start": "1211830",
    "end": "1218700"
  },
  {
    "text": "tab on the top that you can click which then shows you and allows you to configure and enable all the new",
    "start": "1218700",
    "end": "1224610"
  },
  {
    "text": "features we're talking about today such as analytics metrics and inventory so starting with analytics here so you see",
    "start": "1224610",
    "end": "1232380"
  },
  {
    "text": "storage class analysis here and on the left hand side is where you go to enable storage class analysis for your bucket prefix or tag I pre enable this for my",
    "start": "1232380",
    "end": "1241679"
  },
  {
    "text": "for the three prefixes that we just looked at I looked at for archival for daily SPARC job and sales material so in",
    "start": "1241679",
    "end": "1247500"
  },
  {
    "text": "the interest of time I'm going to focus on on my sales material here so when I click on this I see my",
    "start": "1247500",
    "end": "1252720"
  },
  {
    "text": "analyses and so let's go through what what we haven't available so the first thing to note is this console is updated",
    "start": "1252720",
    "end": "1260160"
  },
  {
    "start": "1255000",
    "end": "1398000"
  },
  {
    "text": "every single day every day s3 pulls all of this information for on your usage pattern analyzes it makes it available",
    "start": "1260160",
    "end": "1267030"
  },
  {
    "text": "in an easy to consume data output format and also updates the console so you can",
    "start": "1267030",
    "end": "1272190"
  },
  {
    "text": "come back and every day you will see data for for the latest analyses so on",
    "start": "1272190",
    "end": "1277770"
  },
  {
    "text": "the top here you can see that there's an election notification s3 actually has observed a usage pattern and wants to",
    "start": "1277770",
    "end": "1283920"
  },
  {
    "text": "let you know about wants to tell you about that so over here this was updated yesterday and says that you know based",
    "start": "1283920",
    "end": "1291330"
  },
  {
    "text": "on your usage pattern over the past 123 days and that's the amount of time I enable analytics we observe that you",
    "start": "1291330",
    "end": "1298440"
  },
  {
    "text": "your data that is older than 90 days is actually a good candidate for standard infrequent access now the good thing",
    "start": "1298440",
    "end": "1305220"
  },
  {
    "text": "about this is it is still your decision right you put you may have additional information about your data that you",
    "start": "1305220",
    "end": "1311190"
  },
  {
    "text": "might want to pull in but based on what's actually happening in the past we think that data that is we know that",
    "start": "1311190",
    "end": "1316200"
  },
  {
    "text": "there are that's over 90 days old is infrequently accessed but then we also",
    "start": "1316200",
    "end": "1322020"
  },
  {
    "text": "kind of sure work right we show you how we got to that that observation so if you see here on top you know what is the",
    "start": "1322020",
    "end": "1328680"
  },
  {
    "text": "status today well today or as of yesterday the last analysis here's how much data you have in standard and you",
    "start": "1328680",
    "end": "1334380"
  },
  {
    "text": "don't have anything in NSIA because we don't show that there and I've got 2.9 petabytes of storage and I actually",
    "start": "1334380",
    "end": "1340350"
  },
  {
    "text": "retrieved 2 petabytes of that just yesterday this seems like a very very heavily used pre-fit prefix and but but",
    "start": "1340350",
    "end": "1347610"
  },
  {
    "text": "then you still have that recommendation so let's see how we kind of got to that if you scroll down you see these two",
    "start": "1347610",
    "end": "1354780"
  },
  {
    "text": "graphs the first kind of helps you add a ticket at a glance view of you know how much of my storage am I actually reading",
    "start": "1354780",
    "end": "1361230"
  },
  {
    "text": "this graph shows you your bytes stored in standard as well as the bytes",
    "start": "1361230",
    "end": "1366360"
  },
  {
    "text": "retrieved every single day as a trend over time and you can kind of see that I do retrieve about 2 petabytes of the 2.9",
    "start": "1366360",
    "end": "1373440"
  },
  {
    "text": "better buys that I have stored so I assure you retrieving a lot the graph below this then shows you the actual",
    "start": "1373440",
    "end": "1379560"
  },
  {
    "text": "data for this right the actual percentage of your storage that you're retrieving so you can see here",
    "start": "1379560",
    "end": "1384630"
  },
  {
    "text": "that I retrieve you know between 64 and 72% of my data and it is turning down a little bit over time so that's",
    "start": "1384630",
    "end": "1390690"
  },
  {
    "text": "interesting information but it is still above 65% of my data that I retrieve on",
    "start": "1390690",
    "end": "1396150"
  },
  {
    "text": "a daily basis but if you scroll down here you see more detailed analysis that",
    "start": "1396150",
    "end": "1403350"
  },
  {
    "text": "we've done on your data not just based on the aggregate usage but also broken down by age tiers and that's important",
    "start": "1403350",
    "end": "1410190"
  },
  {
    "text": "because the decision that you're going to make around what data to move into standard and frequent access and you",
    "start": "1410190",
    "end": "1416520"
  },
  {
    "text": "know kind of configuring the lifecycle policy you'll need to know whether you set the policy to 60 days or 80 days or",
    "start": "1416520",
    "end": "1421800"
  },
  {
    "text": "90 days in this case and that's where this visualization helps right so we analyzed over past 122 days the age",
    "start": "1421800",
    "end": "1428160"
  },
  {
    "text": "breakdown of your data the first tile then shows you that that your data that is less than 30 days old on average you",
    "start": "1428160",
    "end": "1435240"
  },
  {
    "text": "know you read about 200 terabytes so you store about 206 terabytes and you read 288 terabytes of that on average so",
    "start": "1435240",
    "end": "1441540"
  },
  {
    "text": "it's very heavily read right the newer objects that you have and then you can see that for the 30 to 45 days 45 to 60",
    "start": "1441540",
    "end": "1448290"
  },
  {
    "text": "days 60 to 90 and so forth and you see here that for the last two tiles the 90 to 180 and 180 plus days actually don't",
    "start": "1448290",
    "end": "1455490"
  },
  {
    "text": "retrieve a lot even though I get on average two petabytes of my you know about 60 or 70 75% of my data every day",
    "start": "1455490",
    "end": "1464090"
  },
  {
    "text": "there is still an opportunity for me to move over a petabyte of data into standard infrequent axis now that is",
    "start": "1464090",
    "end": "1469950"
  },
  {
    "text": "something that you were not able in that is information that you did not have earlier and this is based on your actual",
    "start": "1469950",
    "end": "1475950"
  },
  {
    "text": "usage pattern now you have the data to make a confident decision to transition this one petabyte of information into si",
    "start": "1475950",
    "end": "1483630"
  },
  {
    "text": "a and you also know what to set in your lifecycle policy if you so choose so that again is an example of how we make",
    "start": "1483630",
    "end": "1490110"
  },
  {
    "start": "1487000",
    "end": "1515000"
  },
  {
    "text": "it easier for customers by providing the right data to manage their data in an",
    "start": "1490110",
    "end": "1495510"
  },
  {
    "text": "effective way and improve their storage footprint but we don't stop here right so this was a visualization that you see",
    "start": "1495510",
    "end": "1501540"
  },
  {
    "text": "in the console as I mentioned before you can actually export this data so you see here there's an export data option you",
    "start": "1501540",
    "end": "1507840"
  },
  {
    "text": "can click on that you can select the destination bucket and every day when we complete our analysis we will deliver",
    "start": "1507840",
    "end": "1513060"
  },
  {
    "text": "this to your s3 bucket as well and we in what I've done here is I",
    "start": "1513060",
    "end": "1518429"
  },
  {
    "start": "1515000",
    "end": "1611000"
  },
  {
    "text": "analyze this data in quick sight I'll quickly go into this and you see essentially this is the same data",
    "start": "1518429",
    "end": "1523919"
  },
  {
    "text": "visualize the same way but if I quickly go back to these analyses right you",
    "start": "1523919",
    "end": "1529559"
  },
  {
    "text": "might ask the question okay I I think I know that I can move data that's older than 90 days whatever what about data",
    "start": "1529559",
    "end": "1535529"
  },
  {
    "text": "from sixty to ninety days you know I know it's being heavily accessed today but I don't see a trend over time I",
    "start": "1535529",
    "end": "1540809"
  },
  {
    "text": "don't know if it's getting colder or hotter over time right can I get to that level information and the answer is yes",
    "start": "1540809",
    "end": "1546690"
  },
  {
    "text": "because in quick sight and I'll quickly scroll down to the visualization that is interesting for that right",
    "start": "1546690",
    "end": "1559080"
  },
  {
    "text": "so what I've done here is because all that export data is available for me I've plotted this day each for each of",
    "start": "1559080",
    "end": "1565200"
  },
  {
    "text": "the tiles I've plotted them separately as a trend over time so the orange one that you see at the top right is the",
    "start": "1565200",
    "end": "1570450"
  },
  {
    "text": "seventy-five to eighty nine days aged here and you can see here that you know I read about 200% of that and then over",
    "start": "1570450",
    "end": "1576809"
  },
  {
    "text": "time between August and November it's come down to about you know one hundred and forty percent hundred thirty six",
    "start": "1576809",
    "end": "1584580"
  },
  {
    "text": "percent so it is trending down not by a lot but it is getting colder over time so that's you know again more advanced",
    "start": "1584580",
    "end": "1590519"
  },
  {
    "text": "insights that you can get about your data by analyzing the data using using your own tools okay",
    "start": "1590519",
    "end": "1598249"
  },
  {
    "text": "right so a quick note because we allow you to",
    "start": "1608960",
    "end": "1615540"
  },
  {
    "start": "1611000",
    "end": "1651000"
  },
  {
    "text": "configure multiple multiple prefixes or tags for s3 analytics you have the",
    "start": "1615540",
    "end": "1620910"
  },
  {
    "text": "ability to set separate policy documents which makes it again easier for you to manage and you have the ability to",
    "start": "1620910",
    "end": "1626040"
  },
  {
    "text": "configure up to a thousand policy documents for for s3 analytics so let's",
    "start": "1626040",
    "end": "1632130"
  },
  {
    "text": "quickly talk about some of the other capabilities that we launched so the",
    "start": "1632130",
    "end": "1637260"
  },
  {
    "text": "first is you know this kind of goes back to how do we help you understand how your data is being used how would you",
    "start": "1637260",
    "end": "1642330"
  },
  {
    "text": "how do we help you monitor how your data is being used and we do that by allowed by providing additional CloudWatch",
    "start": "1642330",
    "end": "1649380"
  },
  {
    "text": "metrics as well as audit log capability so for a cloud watch we're providing",
    "start": "1649380",
    "end": "1655290"
  },
  {
    "start": "1651000",
    "end": "1702000"
  },
  {
    "text": "additional 13 new operational and performance related metrics that are available again by your entire bucket or",
    "start": "1655290",
    "end": "1662460"
  },
  {
    "text": "you have the ability to configure these based on your prefix or tag so again you",
    "start": "1662460",
    "end": "1668190"
  },
  {
    "text": "can create multiple sets of these metrics for your data depending on how you organize your data in s3 these are",
    "start": "1668190",
    "end": "1674760"
  },
  {
    "text": "one minute metrics and are delivered to cloud watch so you can actually use the multiple the the advanced capabilities",
    "start": "1674760",
    "end": "1681120"
  },
  {
    "text": "that are available in cloud watch set such as setting an alarm on metrics so quickly",
    "start": "1681120",
    "end": "1686580"
  },
  {
    "text": "going back to our demo I want to show you the metrics and we'll walk through all the metrics that are available as",
    "start": "1686580",
    "end": "1692370"
  },
  {
    "text": "well ok so if I go back to my bucket",
    "start": "1692370",
    "end": "1698850"
  },
  {
    "text": "list and log in to a bucket under management and if I click on the metrics",
    "start": "1698850",
    "end": "1704970"
  },
  {
    "start": "1702000",
    "end": "1721000"
  },
  {
    "text": "tab the first thing I say is storage related metrics you actually see your bytes stored on daily basis you see I",
    "start": "1704970",
    "end": "1710760"
  },
  {
    "text": "created this demo bucket about two or three days ago and I've been adding data to it since and I also have the number",
    "start": "1710760",
    "end": "1716760"
  },
  {
    "text": "of objects stored in this bucket so this is bucket level information at this point but if I click on your quests and",
    "start": "1716760",
    "end": "1724020"
  },
  {
    "start": "1721000",
    "end": "1761000"
  },
  {
    "text": "just click on one R and you can change the fidelity of this on the left-hand side you can see that I've enabled this",
    "start": "1724020",
    "end": "1729840"
  },
  {
    "text": "for the bucket or specific prefixes or n tags within the bucket so finance ABS 2",
    "start": "1729840",
    "end": "1735120"
  },
  {
    "text": "is actually a tag that I put it on data between different prefixes and then HR in sales ABS are our prefixes but at the",
    "start": "1735120",
    "end": "1743820"
  },
  {
    "text": "bucket level let's quickly go through this you you have requests level metrics such as jet request this hasn't count for guests",
    "start": "1743820",
    "end": "1749930"
  },
  {
    "text": "that you see delivered at one minute intervals to cloud watch and visualized here as well you also have put requests",
    "start": "1749930",
    "end": "1758680"
  },
  {
    "text": "list requests all requests post delete",
    "start": "1758680",
    "end": "1763930"
  },
  {
    "start": "1761000",
    "end": "1805000"
  },
  {
    "text": "and so forth so all the requests that you know can help you understand the usage pattern of your data and a better",
    "start": "1763930",
    "end": "1772340"
  },
  {
    "text": "operationally manage your data are available here such as 4x6 so if you see if we kind of call it this one for a",
    "start": "1772340",
    "end": "1777980"
  },
  {
    "text": "second here this this tells me the total for XS xx every response codes that I",
    "start": "1777980",
    "end": "1783230"
  },
  {
    "text": "have for this bucket you know for the past hour so that then helps me you know understand when there is an issue and I",
    "start": "1783230",
    "end": "1790070"
  },
  {
    "text": "can actually click on view in cloud watch and launch this will take me to cloud watch console and I can quickly set an alarm on this - to trigger and",
    "start": "1790070",
    "end": "1800060"
  },
  {
    "text": "let me know when my for xx count jumps up unexpectedly so I can take action on that",
    "start": "1800060",
    "end": "1805120"
  },
  {
    "start": "1805000",
    "end": "1834000"
  },
  {
    "text": "you also have data transfers there's also a number of metrics that help you understand the performance of your data in s3 so this here for instance shows",
    "start": "1805120",
    "end": "1813140"
  },
  {
    "text": "you the total request latency the first byte latency as well as the bytes",
    "start": "1813140",
    "end": "1819050"
  },
  {
    "text": "downloaded and uploaded for this specific bucket and if you click on the filter on the left you will be able to",
    "start": "1819050",
    "end": "1824420"
  },
  {
    "text": "see this by prefix or by tag as well",
    "start": "1824420",
    "end": "1828670"
  },
  {
    "text": "okay so next we want to talk about cloud",
    "start": "1830590",
    "end": "1836840"
  },
  {
    "start": "1834000",
    "end": "1880000"
  },
  {
    "text": "trail right so the audit logging service that allows you to keep track of who is accessing my data when are they",
    "start": "1836840",
    "end": "1842660"
  },
  {
    "text": "accessing it when are they accessing it and and you know enable audit ability",
    "start": "1842660",
    "end": "1848240"
  },
  {
    "text": "for both your bucket level operations and now also your object level operations which makes it easier for you",
    "start": "1848240",
    "end": "1854960"
  },
  {
    "text": "to perform security analysis and meet those IT and compliance auditing",
    "start": "1854960",
    "end": "1860330"
  },
  {
    "text": "requirements that you have and this this is again is very cost effective dollar",
    "start": "1860330",
    "end": "1866120"
  },
  {
    "text": "per million data events recorded by cloud trail and because this is cloud trail you get to use all the other tools",
    "start": "1866120",
    "end": "1872090"
  },
  {
    "text": "that surround the ecosystem for cloud trail again the ridging the other capabilities we have available in AWS so",
    "start": "1872090",
    "end": "1882200"
  },
  {
    "start": "1880000",
    "end": "2056000"
  },
  {
    "text": "let's talk about object tags right so this is really about taking action so all the features that we've been talking about is providing you with information",
    "start": "1882200",
    "end": "1888590"
  },
  {
    "text": "and arming you with knowledge and data so you can take intelligent decisions now let's talk about how do we enable",
    "start": "1888590",
    "end": "1894620"
  },
  {
    "text": "you to make those decisions all the services that I have listed there help with that right lifecycle for instance",
    "start": "1894620",
    "end": "1900050"
  },
  {
    "text": "simple policy should put in and then life cycle takes the action on your behalf but the new thing that we",
    "start": "1900050",
    "end": "1905720"
  },
  {
    "text": "launched here is object tags so let's talk about that for a second right object tags help you easily manage and",
    "start": "1905720",
    "end": "1911840"
  },
  {
    "text": "control access for your data in s3 and you can do that based on metadata that",
    "start": "1911840",
    "end": "1917090"
  },
  {
    "text": "you place on the object using the tags this is about co-locating the metadata you have information about your data",
    "start": "1917090",
    "end": "1923770"
  },
  {
    "text": "with the actual objects in s3 which makes it much easier for you to manage your manager data and take decisions",
    "start": "1923770",
    "end": "1930200"
  },
  {
    "text": "based on that metadata it allows you to classify your data you might add a tag such as HIPAA is equal to true to",
    "start": "1930200",
    "end": "1936290"
  },
  {
    "text": "identify objects that are subject to HIPAA compliance requirements it is a simple key value pair and and it gives",
    "start": "1936290",
    "end": "1943820"
  },
  {
    "text": "you a lot of capabilities like first off you can write I am policies based on this to then control access saying data",
    "start": "1943820",
    "end": "1949760"
  },
  {
    "text": "that is that is classified as application a only the folks working in this specific I am role or specific",
    "start": "1949760",
    "end": "1955580"
  },
  {
    "text": "group should have access to that data it is fully integrated with all the different capabilities we have in in",
    "start": "1955580",
    "end": "1961850"
  },
  {
    "text": "Amazon s3 such as lifecycle policies so now you have the ability to write lifecycle policies instead of for",
    "start": "1961850",
    "end": "1967370"
  },
  {
    "text": "specific prefixes you can regardless of where it's stored data that is HIPPA needs to be archived to glaciar data that's tagged logs I don't",
    "start": "1967370",
    "end": "1974090"
  },
  {
    "text": "care about can be deleted in 90 days so you know you get a lot of control over your data based on this and then of",
    "start": "1974090",
    "end": "1980119"
  },
  {
    "text": "course we talked about and the the new analysis services such as metrics and cloud and s3 analytics all of them allow",
    "start": "1980119",
    "end": "1987139"
  },
  {
    "text": "you to to filter your data based on tags so you can get all of those insights depending on how you've organized your",
    "start": "1987139",
    "end": "1993169"
  },
  {
    "text": "data a quick deeper look you can add up",
    "start": "1993169",
    "end": "1999320"
  },
  {
    "text": "to 10 tags per object because these are object level tags an important consideration is that these are",
    "start": "1999320",
    "end": "2004960"
  },
  {
    "text": "completely mutable you can change add edit remove these tags anytime you want",
    "start": "2004960",
    "end": "2009970"
  },
  {
    "text": "you have the ability to control access on it who can change what tag but they are mutable and you can add up to 10",
    "start": "2009970",
    "end": "2016989"
  },
  {
    "text": "tags per object and we follow the same conventions as AWS does for tag",
    "start": "2016989",
    "end": "2022179"
  },
  {
    "text": "definition so you know the same restrictions that we have on adding a tag for ec2 instance apply to this these",
    "start": "2022179",
    "end": "2027549"
  },
  {
    "text": "tags as well and there are two ways you can add these tags to your objects you",
    "start": "2027549",
    "end": "2033279"
  },
  {
    "text": "can either decide to put the tag with the individual object by using the simple put API that we have today to put",
    "start": "2033279",
    "end": "2038590"
  },
  {
    "text": "object API and optionally you can specify the tag or for existing objects there's a new API for put object tagging",
    "start": "2038590",
    "end": "2045639"
  },
  {
    "text": "that you can use and you can specify the tags set for that and and it's simple",
    "start": "2045639",
    "end": "2050858"
  },
  {
    "text": "per tag pricing a cent per 10,000 tags per month I mentioned that you can use",
    "start": "2050859",
    "end": "2058419"
  },
  {
    "start": "2056000",
    "end": "2101000"
  },
  {
    "text": "this with lifecycle policies so talking a bit about this right not only does it make it easier for you to take make make",
    "start": "2058419",
    "end": "2064868"
  },
  {
    "text": "lifecycle decisions based on the metadata you have in your tags but you can actually mix and match right you can",
    "start": "2064869",
    "end": "2070929"
  },
  {
    "text": "write a policy that says I wanted to archive all the data that is in prefix a that is you know in my archival folder",
    "start": "2070929",
    "end": "2077349"
  },
  {
    "text": "and that has a tag log logs is equal to true so that data I want to delete in 90",
    "start": "2077349",
    "end": "2082929"
  },
  {
    "text": "days and for all the other data that is in the archival folder that is tagged important data I do not delete I want to",
    "start": "2082929",
    "end": "2089079"
  },
  {
    "text": "archive that to glacier so you have all of this flexibility to actually have specify a policy with both a prefix and",
    "start": "2089079",
    "end": "2096730"
  },
  {
    "text": "a tag all right so so what does this mean for",
    "start": "2096730",
    "end": "2104020"
  },
  {
    "start": "2101000",
    "end": "2146000"
  },
  {
    "text": "you what this means is that s3 is providing you with a robust set of tools and a very complete storage management",
    "start": "2104020",
    "end": "2111640"
  },
  {
    "text": "portfolio of services for you to then understand what data you have in s3",
    "start": "2111640",
    "end": "2116970"
  },
  {
    "text": "understand how it's being used and then take meaningful intelligent data-driven",
    "start": "2116970",
    "end": "2122319"
  },
  {
    "text": "decisions on managing that data right this then enables you to derive more value from your data making your data",
    "start": "2122319",
    "end": "2128800"
  },
  {
    "text": "more useful and making it easier for you to add more value to your business so",
    "start": "2128800",
    "end": "2134589"
  },
  {
    "text": "with that let's hand it over to Jon to talk about how Pinterest uses these capabilities on s3 thank you you guys",
    "start": "2134589",
    "end": "2144130"
  },
  {
    "text": "really cool everybody I'm John Eliot I'm the manager of data and storage site",
    "start": "2144130",
    "end": "2151089"
  },
  {
    "text": "reliability at Pinterest I work in Petra's infrastructure engineering group I've been working there about two and a",
    "start": "2151089",
    "end": "2157480"
  },
  {
    "text": "half years so we're the team that manages all the infrastructure that powers all of the petrous services so",
    "start": "2157480",
    "end": "2164470"
  },
  {
    "text": "home feed online serving big data platform real time services search",
    "start": "2164470",
    "end": "2170500"
  },
  {
    "text": "serving search backends so Pinter's has been running on AWS 100 percent since",
    "start": "2170500",
    "end": "2176079"
  },
  {
    "text": "2010 so hopefully a lot of you already",
    "start": "2176079",
    "end": "2181990"
  },
  {
    "start": "2180000",
    "end": "2225000"
  },
  {
    "text": "know what Pinterest is if you don't we'd like to think of Pinterest as the world's catalogue of ideas so it's a",
    "start": "2181990",
    "end": "2189549"
  },
  {
    "text": "place where you can go search for just about anything anything you're interested in hopefully discover new things and then",
    "start": "2189549",
    "end": "2196210"
  },
  {
    "text": "become inspired by those things and then go do them in real life so that's kind of how we like to think of the service so we have pins on just about any topic",
    "start": "2196210",
    "end": "2203920"
  },
  {
    "text": "you can think of you know food style automotive travel anything you're interested in so we have 80 billion pins",
    "start": "2203920",
    "end": "2210849"
  },
  {
    "text": "in our system today and those pins are categorized by people into more than 2.6",
    "start": "2210849",
    "end": "2216339"
  },
  {
    "text": "billion boards so when you have that kind of scale that means you have a lot of infrastructure and you have a lot of",
    "start": "2216339",
    "end": "2223180"
  },
  {
    "text": "data so today in s3 we have over 140",
    "start": "2223180",
    "end": "2230090"
  },
  {
    "start": "2225000",
    "end": "2259000"
  },
  {
    "text": "petabytes of data we actually have 150 I think we added 10 since it rated this",
    "start": "2230090",
    "end": "2236030"
  },
  {
    "text": "slide so we probably added another one since I started talking so we're adding",
    "start": "2236030",
    "end": "2241190"
  },
  {
    "text": "80 terabytes of new raw log data every day that's not counting all the derived",
    "start": "2241190",
    "end": "2246260"
  },
  {
    "text": "data that are you know like Hadoop is trading and all of our data process is creating so almost entirely all of that",
    "start": "2246260",
    "end": "2253670"
  },
  {
    "text": "hundred and fifty petabytes that's an s3 is log data right and this is just a",
    "start": "2253670",
    "end": "2262220"
  },
  {
    "start": "2259000",
    "end": "2355000"
  },
  {
    "text": "high level overview of the logging ember structure that's creating all that data so there's probably nothing like to",
    "start": "2262220",
    "end": "2269900"
  },
  {
    "text": "novel about this set up you've probably seen logging pipelines like this before but just real quick the client sends a",
    "start": "2269900",
    "end": "2278000"
  },
  {
    "text": "request to our app fleet running an AWS our app services they write their log",
    "start": "2278000",
    "end": "2283430"
  },
  {
    "text": "files to an in-house open source consumer called singer singer then",
    "start": "2283430",
    "end": "2289280"
  },
  {
    "text": "streams that log data to our Kafka infrastructure from there there's",
    "start": "2289280",
    "end": "2294380"
  },
  {
    "text": "different real time consumers that actually read directly from Kafka like spark streaming Apache storm mem sequel",
    "start": "2294380",
    "end": "2301850"
  },
  {
    "text": "and then some other in-house consumers we have but the majority of the data gets consumed from Kafka by another",
    "start": "2301850",
    "end": "2308050"
  },
  {
    "text": "in-house open source service called sucker Merced and this service is mainly",
    "start": "2308050",
    "end": "2314140"
  },
  {
    "text": "concerned with kind of sanitizing that data converting it into different",
    "start": "2314140",
    "end": "2319160"
  },
  {
    "text": "formats like sequence file format or Kor C format then compressing that data and",
    "start": "2319160",
    "end": "2324920"
  },
  {
    "text": "uploading it into s3 one state is an s3 almost all of it gets consumed by a",
    "start": "2324920",
    "end": "2331340"
  },
  {
    "text": "Hadoop workflow at some point we have a pretty massive Hadoop deployment in",
    "start": "2331340",
    "end": "2337070"
  },
  {
    "text": "nativist and so we we use s3 is essentially our persistent data store",
    "start": "2337070",
    "end": "2342860"
  },
  {
    "text": "right through HDFS so Hadoop reads in the data from s3 it does it to",
    "start": "2342860",
    "end": "2347960"
  },
  {
    "text": "intermediate processing in the cluster and then writes that data back to s3 where it's persistent",
    "start": "2347960",
    "end": "2354730"
  },
  {
    "text": "and this is just a kind of a visualization of our growth in s3 over",
    "start": "2356349",
    "end": "2361430"
  },
  {
    "text": "the last three and a half years in June 2013 I think we had about five petabytes",
    "start": "2361430",
    "end": "2367910"
  },
  {
    "text": "of data and as our user growth user base is grown and our advertising business is",
    "start": "2367910",
    "end": "2373640"
  },
  {
    "text": "scaling the growth has just been rapidly increasing and it's also because we're",
    "start": "2373640",
    "end": "2379460"
  },
  {
    "text": "adding more products and more services to the site so a user session now generates farm or API calls and more",
    "start": "2379460",
    "end": "2385550"
  },
  {
    "text": "logging than it used to we're also adding more fields into those logs so we're just generating a lot of",
    "start": "2385550",
    "end": "2391010"
  },
  {
    "text": "data now so since January 2014 has grown almost 1500 percent and it's just",
    "start": "2391010",
    "end": "2397609"
  },
  {
    "text": "growing like crazy so all right so let me just digress for a second I'm gonna",
    "start": "2397609",
    "end": "2403880"
  },
  {
    "text": "explain what's going on it's slide so when you have that much data it's very",
    "start": "2403880",
    "end": "2410090"
  },
  {
    "text": "natural to start asking these questions like you know what is creating all this data do we need all this data who is the",
    "start": "2410090",
    "end": "2416300"
  },
  {
    "text": "owner of the data and so earlier in this year we had a kind of pressing cost",
    "start": "2416300",
    "end": "2424550"
  },
  {
    "text": "issue and underlying the cost issue were two other issues and one is attribution",
    "start": "2424550",
    "end": "2430580"
  },
  {
    "text": "as in who owns the data or what kind of categories is data in and that issue is",
    "start": "2430580",
    "end": "2437570"
  },
  {
    "text": "gonna actually be resolved to the object tagging I think that O'Meara was talking about earlier we're gonna start using",
    "start": "2437570",
    "end": "2442760"
  },
  {
    "text": "that in our workflows to start kind of creating this like taxonomy of our data in s3 but the other issue underlying",
    "start": "2442760",
    "end": "2449180"
  },
  {
    "text": "that is cost efficiency or efficiency so to address that we ended up writing",
    "start": "2449180",
    "end": "2454250"
  },
  {
    "text": "these these tools that would give us information about the access patterns of our data in s3 right so we end up",
    "start": "2454250",
    "end": "2460790"
  },
  {
    "text": "writing a series of spark jobs we chose spark because the Scala SDK has these",
    "start": "2460790",
    "end": "2466490"
  },
  {
    "text": "kind of very high performance paralized lists against s3 and the way it would",
    "start": "2466490",
    "end": "2471619"
  },
  {
    "text": "work is we would run this inventory job that would list the top 200 or 300 prefixes gain maybe hundred billion",
    "start": "2471619",
    "end": "2479780"
  },
  {
    "text": "objects so we had to be kind of limited in the scope of what we could list just going to the front end s3 API",
    "start": "2479780",
    "end": "2486350"
  },
  {
    "text": "wasn't feasible to list everything so we had to kind of just list like a subsection of the data and then when we",
    "start": "2486350",
    "end": "2492200"
  },
  {
    "text": "take the s3 API operations log for that bucket that you can just enable through normal bucket logging in s3 and the API",
    "start": "2492200",
    "end": "2500390"
  },
  {
    "text": "log is just a list of all that gets the puts the heads the list everything that's going on in s3 with that bucket",
    "start": "2500390",
    "end": "2507730"
  },
  {
    "text": "so we've generate these reports and then join the data by prefix and then that would create this thing we called the",
    "start": "2507730",
    "end": "2513500"
  },
  {
    "text": "efficiency report and we would load that into redshift and then do you like interactive queries against it it would kind of look like you'd have like prefix",
    "start": "2513500",
    "end": "2520940"
  },
  {
    "text": "and they'd have storaged here whether it was standard or infrequent and then you'd have like the ratio of gets and",
    "start": "2520940",
    "end": "2527240"
  },
  {
    "text": "puts relative to the total amount of storage you'd have total gets or puts",
    "start": "2527240",
    "end": "2532340"
  },
  {
    "text": "against a prefix over some like time horizon like 60 or 90 days and so what",
    "start": "2532340",
    "end": "2537740"
  },
  {
    "text": "that allowed us to see was there were some prefixes that had like nothing but",
    "start": "2537740",
    "end": "2544310"
  },
  {
    "text": "puts but no gits meaning some Hadoop job is just writing that data and nothing no one's ever",
    "start": "2544310",
    "end": "2550940"
  },
  {
    "text": "reading the data back like it's not being used for anything so then we can find out hey can we shut that workflow off or do we even need this data do what",
    "start": "2550940",
    "end": "2557150"
  },
  {
    "text": "other cases where there was just no gets or puts on the data at all and then we would say well can we just delete this",
    "start": "2557150",
    "end": "2562310"
  },
  {
    "text": "data and then there were some cases where there were gets in the first 30",
    "start": "2562310",
    "end": "2567860"
  },
  {
    "text": "days but then no gets beyond that right in the last 60 or 90 days so then we thought okay considering that can we",
    "start": "2567860",
    "end": "2573740"
  },
  {
    "text": "just move this infrequent access and achieve some kind of cost efficiency and that's what we did so we're able to move",
    "start": "2573740",
    "end": "2578870"
  },
  {
    "text": "like 35 to 40 percent of our data and infrequent access using that tool",
    "start": "2578870",
    "end": "2585160"
  },
  {
    "start": "2584000",
    "end": "2625000"
  },
  {
    "text": "so now we're using this thing that over I was just talking about the s3 inventory so this is now providing like",
    "start": "2585690",
    "end": "2592870"
  },
  {
    "text": "a full bucket inventory full object listing of everything that's in s3 which wasn't we weren't able to do that before",
    "start": "2592870",
    "end": "2598720"
  },
  {
    "text": "right and it's just available at s3 bucket and like a CSV format so we can just kind of take that and ingest it",
    "start": "2598720",
    "end": "2604600"
  },
  {
    "text": "into our workflow and now we can get like the full picture of what's going in on an s3 and it only takes 20 minutes to",
    "start": "2604600",
    "end": "2610480"
  },
  {
    "text": "run now because we don't have to do our own inventory before that was like a six to eight hour workflow and with any",
    "start": "2610480",
    "end": "2616510"
  },
  {
    "text": "workflow it's always like falling over and you know there's always like maintenance that goes along with that so",
    "start": "2616510",
    "end": "2621820"
  },
  {
    "text": "this has been like a huge game for us but in the new world we're gonna start",
    "start": "2621820",
    "end": "2627820"
  },
  {
    "start": "2625000",
    "end": "2730000"
  },
  {
    "text": "using s3 analytics so I just started using it the other day I was emailing a",
    "start": "2627820",
    "end": "2633040"
  },
  {
    "text": "mare like everyday like one can have access to it so this is going to kind of",
    "start": "2633040",
    "end": "2638530"
  },
  {
    "text": "provide the same functionality that that efficiency report was providing and perhaps you can like deprecated that",
    "start": "2638530",
    "end": "2644440"
  },
  {
    "text": "report all together but this tool is kind of a good example of like how an",
    "start": "2644440",
    "end": "2650860"
  },
  {
    "text": "ATS customer can really work closely with Ada West to influence their roadmap earlier in the year when we were working",
    "start": "2650860",
    "end": "2656950"
  },
  {
    "text": "on the efficiency report kind of kicked off this conversation with a DBS and kind of asking them like hey how can we",
    "start": "2656950",
    "end": "2663550"
  },
  {
    "text": "get this same data like through the s3 console or like look like how could we like operationalize this so we started",
    "start": "2663550",
    "end": "2669580"
  },
  {
    "text": "collaborating with them and you know giving them feedback and then they would show us mock-ups and then give us feedback about that we kind of had this",
    "start": "2669580",
    "end": "2675910"
  },
  {
    "text": "nice like collaboration loop going and I feel like SP Analects is kind of like the end result of that so it's a turning",
    "start": "2675910",
    "end": "2683620"
  },
  {
    "text": "it on for like I think a thousand prefixes already and gotta start monitoring and I anticipate in the next",
    "start": "2683620",
    "end": "2690490"
  },
  {
    "text": "sixty days or so achieving pretty good like cost savings by migrating data based on its",
    "start": "2690490",
    "end": "2695680"
  },
  {
    "text": "recommendations so yeah with that I just want to give a shout out to a Solutions",
    "start": "2695680",
    "end": "2701650"
  },
  {
    "text": "Architect Hashem as that AWS he really helped us a lot with this stuff and also careers benches",
    "start": "2701650",
    "end": "2708660"
  },
  {
    "text": "calm we're always hiring and with that I guess I'll turn over over here yeah yeah I think I think that's all the content",
    "start": "2708660",
    "end": "2721440"
  },
  {
    "text": "we have we've got plenty of time for questions if you want to come up to the mic so everyone can hear your questions both John and I are happy to answer any",
    "start": "2721440",
    "end": "2729090"
  },
  {
    "text": "questions you might have",
    "start": "2729090",
    "end": "2731630"
  }
]
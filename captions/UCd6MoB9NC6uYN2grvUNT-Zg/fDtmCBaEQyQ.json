[
  {
    "start": "0",
    "end": "21000"
  },
  {
    "text": "hello and welcome everyone my name is Sergey psycho lenka I'm a product manager at amazon ideas today I have",
    "start": "439",
    "end": "7770"
  },
  {
    "text": "with me Jeremiah Belton with the principal engineer at amazon web services and they're going to be talking",
    "start": "7770",
    "end": "14820"
  },
  {
    "text": "to you about oracle on AWS and Amazon RDS so in this session I would like to",
    "start": "14820",
    "end": "23310"
  },
  {
    "start": "21000",
    "end": "21000"
  },
  {
    "text": "spend a bit of time talking about building secure database environments for oracle then we're going to talk",
    "start": "23310",
    "end": "31710"
  },
  {
    "text": "about migrating Oracle databases into AWS we're also going to be talking about",
    "start": "31710",
    "end": "38460"
  },
  {
    "text": "building fast and scalable workloads on Amazon RDS as well as we're going to",
    "start": "38460",
    "end": "43500"
  },
  {
    "text": "present a new project that Gao has been working on on building oracle RAC clusters on AWS so let's get started",
    "start": "43500",
    "end": "53820"
  },
  {
    "text": "with secure database environments first thing about security in ews that you",
    "start": "53820",
    "end": "59219"
  },
  {
    "text": "should know is is about controlling access to your legalese you should start",
    "start": "59219",
    "end": "64860"
  },
  {
    "text": "with TW sexes and privileges by creating",
    "start": "64860",
    "end": "70110"
  },
  {
    "text": "a user that can only create would say create and update tables but not drop",
    "start": "70110",
    "end": "75810"
  },
  {
    "text": "them or trying to truncate them you don't want to be in a situation where one of your users execute say truncate",
    "start": "75810",
    "end": "82439"
  },
  {
    "text": "all and deletes substantial amounts of memory or storage in your database the",
    "start": "82439",
    "end": "90060"
  },
  {
    "text": "next level of security is network security and you achieve that by defining security groups should have a",
    "start": "90060",
    "end": "97680"
  },
  {
    "text": "security group for both your database as well as your application and when you",
    "start": "97680",
    "end": "103020"
  },
  {
    "text": "define the permissions for security groups for your database security group you should define the security group",
    "start": "103020",
    "end": "110490"
  },
  {
    "text": "name of your application so that you don't have to use scissors and everything is transparent yet another",
    "start": "110490",
    "end": "118950"
  },
  {
    "text": "level of security that AWS provides do RvB seas or virtual private clouds just",
    "start": "118950",
    "end": "125549"
  },
  {
    "text": "to be for a customer to subdivide amazon's web services environment into",
    "start": "125549",
    "end": "131190"
  },
  {
    "text": "logical logically separate partitions V pcs can be further",
    "start": "131190",
    "end": "136349"
  },
  {
    "text": "subdivided into subnets and you should have several of them you should have a subnet for your database a subnet for",
    "start": "136349",
    "end": "143430"
  },
  {
    "text": "your application servers and a sub subnet for your web servers the subnets",
    "start": "143430",
    "end": "149340"
  },
  {
    "text": "for your database and application servers should not be accessible to the internet because you don't want someone",
    "start": "149340",
    "end": "154500"
  },
  {
    "text": "from outside to potentially compromise your data now the subnet for your web",
    "start": "154500",
    "end": "160500"
  },
  {
    "text": "servers should definitely be accessible through the internet if you are building a web application lastly you control",
    "start": "160500",
    "end": "169109"
  },
  {
    "start": "163000",
    "end": "163000"
  },
  {
    "text": "access by using what we call the Identity and Access Management I am and",
    "start": "169109",
    "end": "175590"
  },
  {
    "text": "you should definitely use this technology and the service to better control your users and permissions of",
    "start": "175590",
    "end": "180659"
  },
  {
    "text": "your users now beyond controlling access there are many other things you can do",
    "start": "180659",
    "end": "186989"
  },
  {
    "start": "185000",
    "end": "185000"
  },
  {
    "text": "to improve the security of your database you can use encryption of data in",
    "start": "186989",
    "end": "192540"
  },
  {
    "text": "transit to better protect your data in transit you can also use auditing",
    "start": "192540",
    "end": "198540"
  },
  {
    "text": "functionality available in Oracle to exactly know what's going on on your database but i would like to dive deep",
    "start": "198540",
    "end": "205379"
  },
  {
    "text": "into one particular area which we improved quite a bit over the past year which is encryption of data a trust and",
    "start": "205379",
    "end": "212879"
  },
  {
    "text": "we're going to start with a simple setup where you have a application accessing",
    "start": "212879",
    "end": "218040"
  },
  {
    "text": "an oracle database without any security as some of you might know amazon RDS",
    "start": "218040",
    "end": "226019"
  },
  {
    "text": "provides you with Oracle processes running on ec2 boxes accessing",
    "start": "226019",
    "end": "231959"
  },
  {
    "text": "network-attached EBS storage so in the simple setup that we are starting with",
    "start": "231959",
    "end": "237709"
  },
  {
    "text": "there's no encryption you can get",
    "start": "237709",
    "end": "243959"
  },
  {
    "text": "encryption easily by relying on a new technology released this year which is",
    "start": "243959",
    "end": "250349"
  },
  {
    "text": "volume based encryption of VBS in this setup the Oracle database doesn't even",
    "start": "250349",
    "end": "256859"
  },
  {
    "text": "know this encryption going on so you can use your standard edition one standard edition Oracle Enterprise Edition",
    "start": "256859",
    "end": "263849"
  },
  {
    "text": "databases with this technology you don't need to have GD or Enterprise Edition to gain encryption we have",
    "start": "263849",
    "end": "272400"
  },
  {
    "text": "several options of how to manage keys with this technology you can either use",
    "start": "272400",
    "end": "277440"
  },
  {
    "text": "or choose to let Amazon RDS manage your master keys master encryption keys or",
    "start": "277440",
    "end": "283590"
  },
  {
    "text": "you can choose to use the key management system came as for short to manage and",
    "start": "283590",
    "end": "293070"
  },
  {
    "text": "maintain your keys it's really simple to set up this encryption technology when",
    "start": "293070",
    "end": "298260"
  },
  {
    "text": "you create your database or when you modify your database you select yes for",
    "start": "298260",
    "end": "303330"
  },
  {
    "text": "enable encryption and you choose which key is you want to use now in addition",
    "start": "303330",
    "end": "311100"
  },
  {
    "text": "to a volume level encryption in EBS you can definitely also use the TD",
    "start": "311100",
    "end": "316950"
  },
  {
    "text": "encryption available with the Enterprise Edition Oracle and again you have two options here you can either maintain",
    "start": "316950",
    "end": "325260"
  },
  {
    "text": "your or manage your keys or you can let Amazon LG has managed the keys for you in this particular example I'm starting",
    "start": "325260",
    "end": "331740"
  },
  {
    "text": "with a setup we are Amazon RDS is managing your keys how do you set this",
    "start": "331740",
    "end": "337830"
  },
  {
    "text": "up in the database options you choose the TD option some of you might be aware",
    "start": "337830",
    "end": "344310"
  },
  {
    "text": "of the way we enable options in RDS but for the rest I'll just quickly remind we",
    "start": "344310",
    "end": "350040"
  },
  {
    "text": "have a concept called options you can apply an option to a database and the",
    "start": "350040",
    "end": "355260"
  },
  {
    "text": "particular option you should be looking here for is called TD if if key is that",
    "start": "355260",
    "end": "367440"
  },
  {
    "text": "a manager Amazon RDS is not something you would like to consider if you would like to manage your own keys you have",
    "start": "367440",
    "end": "373650"
  },
  {
    "text": "the option to integrate with a hardware security module service that we provide",
    "start": "373650",
    "end": "378720"
  },
  {
    "text": "today it's called cloud hsm we have cloud hsm you are the owner and manager",
    "start": "378720",
    "end": "385140"
  },
  {
    "text": "of keys and we provide the integration with the service when you use TDE the",
    "start": "385140",
    "end": "392790"
  },
  {
    "text": "Oracle instance is definitely we are of the encryption that is going on so the channel between your Oracle instance",
    "start": "392790",
    "end": "399000"
  },
  {
    "text": "this processes and the blocks in abs is fully encrypted in addition in addition",
    "start": "399000",
    "end": "408270"
  },
  {
    "text": "to improving our encryption story over the past year we've also invested in making our workloads Oracle workloads",
    "start": "408270",
    "end": "415040"
  },
  {
    "text": "HIPAA eligible some of you who are working in the health care industry are",
    "start": "415040",
    "end": "421290"
  },
  {
    "text": "aware of the requirements that are imposed by the Health Insurance Portability and Accountability Act or",
    "start": "421290",
    "end": "427500"
  },
  {
    "text": "HIPAA for short thus legal framework imposes certain restrictions and",
    "start": "427500",
    "end": "433140"
  },
  {
    "text": "requirements for managing patient health care information so you'd be happy to",
    "start": "433140",
    "end": "438330"
  },
  {
    "text": "know that you can now sign business associate agreements with AWS and you",
    "start": "438330",
    "end": "443730"
  },
  {
    "text": "can cover RDS for Oracle in such agreements those of you who already have",
    "start": "443730",
    "end": "451410"
  },
  {
    "text": "paas with them Jean you can grandfather the addition of RDS Oracle you don't",
    "start": "451410",
    "end": "457770"
  },
  {
    "text": "have to do anything extra but even even those of you who are not in the",
    "start": "457770",
    "end": "462810"
  },
  {
    "text": "healthcare industry you'll also be benefiting from the additional external third party audits that we have to go",
    "start": "462810",
    "end": "470400"
  },
  {
    "text": "through to get certified and to get to become eligible for for being including",
    "start": "470400",
    "end": "475919"
  },
  {
    "text": "in include nba's so we get the extensive for heads of by third parties of",
    "start": "475919",
    "end": "482479"
  },
  {
    "text": "operational and security processes and every user of Amazon RDS for Oracle is benefiting from them now let's talk",
    "start": "482479",
    "end": "493590"
  },
  {
    "text": "about migrating databases to RDS we don't have secure environments let's talk about how to move data into AWS",
    "start": "493590",
    "end": "502460"
  },
  {
    "start": "503000",
    "end": "503000"
  },
  {
    "text": "there are several reasons why you would want to move data one is a one-time data",
    "start": "503090",
    "end": "509280"
  },
  {
    "text": "migration went for example you're moving your wore clothes from on-premises through the cloud or perhaps you're",
    "start": "509280",
    "end": "516060"
  },
  {
    "text": "starting with a you already have a database in the cloud but running on ec2 and you would like to move it to RDS",
    "start": "516060",
    "end": "523520"
  },
  {
    "text": "once you have your databases in the cloud you might choose to replicate them",
    "start": "523520",
    "end": "529240"
  },
  {
    "text": "you might want to continue replicating your own premises database to the cloud or you might want to choose to replicate",
    "start": "529240",
    "end": "537910"
  },
  {
    "text": "back for disaster recovery purposes or for compliance purposes yet another good",
    "start": "537910",
    "end": "545290"
  },
  {
    "text": "reason for having the ability to to do ongoing replication is for example",
    "start": "545290",
    "end": "550440"
  },
  {
    "text": "moving your transactional data from your transactional databases into bi systems",
    "start": "550440",
    "end": "555520"
  },
  {
    "text": "data warehouses read shaft ratchet comes to mind as a good source or so as a good",
    "start": "555520",
    "end": "561610"
  },
  {
    "text": "target for such a replication and last but not least you might want to choose",
    "start": "561610",
    "end": "567670"
  },
  {
    "text": "to the ongoing replication if you if you want to offload some of the queries on",
    "start": "567670",
    "end": "573339"
  },
  {
    "text": "your primary database and would like to do read replicas how do we do data",
    "start": "573339",
    "end": "581410"
  },
  {
    "start": "579000",
    "end": "579000"
  },
  {
    "text": "migration there are a couple of NASA methods one is doing data migration in",
    "start": "581410",
    "end": "587200"
  },
  {
    "text": "bulk and the other one has the same name as one of the use cases doing ongoing replication we have recently introduced",
    "start": "587200",
    "end": "595120"
  },
  {
    "text": "the AWS database migration service we be launched on wednesday launched in",
    "start": "595120",
    "end": "601060"
  },
  {
    "text": "preview and i'm going to talk about a little bit more but there are also other",
    "start": "601060",
    "end": "606520"
  },
  {
    "text": "methods of moving data so for bulk loads you can choose the standard Oracle tools",
    "start": "606520",
    "end": "612010"
  },
  {
    "text": "import export data pump sequel loader materialized views you can also do",
    "start": "612010",
    "end": "618160"
  },
  {
    "text": "create able s and inserts / database links for ongoing replication you also",
    "start": "618160",
    "end": "624820"
  },
  {
    "text": "have options including data pump and and materialized views as well as Golden",
    "start": "624820",
    "end": "631660"
  },
  {
    "text": "Gate amazon ideas for Oracle supports Golden Gate as source and target but you",
    "start": "631660",
    "end": "640089"
  },
  {
    "text": "definitely want you to consider signing up for the database migration service because in addition to work in Oracle",
    "start": "640089",
    "end": "646870"
  },
  {
    "text": "Gemma and I also working on the database migration service so we think it's a it's a great oh it simplifies a lot of",
    "start": "646870",
    "end": "653860"
  },
  {
    "text": "the manual tasks you have to do with the other tools I'm going to be talking",
    "start": "653860",
    "end": "660459"
  },
  {
    "start": "659000",
    "end": "659000"
  },
  {
    "text": "about a example of what we recommended in the past for a",
    "start": "660459",
    "end": "665920"
  },
  {
    "text": "high-speed database migration and into the cloud before we release the database",
    "start": "665920",
    "end": "671650"
  },
  {
    "text": "migration service and the reason i want to mention it because it highlights some of the features of Amazon RDS that you",
    "start": "671650",
    "end": "679600"
  },
  {
    "text": "should be aware and should be are still applicable even after you start using other tools so in my example here I'm",
    "start": "679600",
    "end": "686380"
  },
  {
    "text": "going to start with a 500 gigabyte database that I would like to move from on-premises to to Amazon to a RDS Oracle",
    "start": "686380",
    "end": "695050"
  },
  {
    "text": "instance i'm going to be using data pump",
    "start": "695050",
    "end": "700320"
  },
  {
    "text": "for extracting my data from from the on-premises engines and i also going to",
    "start": "700320",
    "end": "705730"
  },
  {
    "text": "be using a supplementary helper linux cost with multiple disks attached to it",
    "start": "705730",
    "end": "711760"
  },
  {
    "text": "so that i can paralyze my i owe the particular command i'm going to be using",
    "start": "711760",
    "end": "717270"
  },
  {
    "text": "you're seeing it right now on the screen i'm doing parallel export and then using",
    "start": "717270",
    "end": "723340"
  },
  {
    "text": "compression and this method allows me to compact my 500 500 gigabyte database in",
    "start": "723340",
    "end": "731470"
  },
  {
    "text": "about 200 gigabytes and it takes me about don't half hours to do the expert because i'm using parallel I or in",
    "start": "731470",
    "end": "738070"
  },
  {
    "text": "writing to multiple disks on the living sauce now after i got my multiple data",
    "start": "738070",
    "end": "746680"
  },
  {
    "text": "files extract it and by the way so this method that you've so right now will generate about 18 files written to the",
    "start": "746680",
    "end": "753580"
  },
  {
    "text": "theater three discs i can now start moving the stata to to amazon and i'll",
    "start": "753580",
    "end": "760750"
  },
  {
    "text": "be using a helper ec2 instance again with multiple disks attached to it so",
    "start": "760750",
    "end": "767170"
  },
  {
    "text": "they can paralyze the writing process as well we have a recommendation for using",
    "start": "767170",
    "end": "774700"
  },
  {
    "text": "a UDP based transfer method it works a bit faster and in this example i was",
    "start": "774700",
    "end": "781270"
  },
  {
    "text": "using tsunami which is a open source project that is optimizing the data",
    "start": "781270",
    "end": "786430"
  },
  {
    "text": "transfer rates and using with DP for transferring files so this process will",
    "start": "786430",
    "end": "792400"
  },
  {
    "text": "probably take you about two and a half hours once I have my data in my my helper ec2",
    "start": "792400",
    "end": "800570"
  },
  {
    "text": "instance I can now start moving it into my oracle rd essences and i'm going to",
    "start": "800570",
    "end": "809660"
  },
  {
    "text": "move it for us to the data pump director amazon RDS for oracle allows you to move",
    "start": "809660",
    "end": "814910"
  },
  {
    "text": "files into a data pump generally speaking we we manage the instance for you so you cannot really access data",
    "start": "814910",
    "end": "821570"
  },
  {
    "text": "files on our first but this is one of the directories you can access and can",
    "start": "821570",
    "end": "826790"
  },
  {
    "text": "write because you would like it to be using data pump being able to use data",
    "start": "826790",
    "end": "831830"
  },
  {
    "text": "pump and importing or exporting files from amazon RDS the process of moving",
    "start": "831830",
    "end": "838730"
  },
  {
    "text": "from my ec2 helper instance two RDS will take about three and a half hours and",
    "start": "838730",
    "end": "845230"
  },
  {
    "text": "lastly i need to ingest the files into my tables so i'm going to be using this",
    "start": "845230",
    "end": "851300"
  },
  {
    "text": "command it's a bit long but it does the trick it uses the DBMS data pump package",
    "start": "851300",
    "end": "859520"
  },
  {
    "text": "to import the files into my tables and",
    "start": "859520",
    "end": "866210"
  },
  {
    "text": "that step takes about four hours however because I'm using because I'm paralyzing",
    "start": "866210",
    "end": "873770"
  },
  {
    "text": "everything and not waiting until my data pump experts the files initially I'm not",
    "start": "873770",
    "end": "878930"
  },
  {
    "text": "waiting until I got all the files and discs to transfer them sending everything in a in a quick succession",
    "start": "878930",
    "end": "885010"
  },
  {
    "text": "the entire process can be done within about seven hours I mentioned this",
    "start": "885010",
    "end": "893450"
  },
  {
    "text": "process because it's useful and you should still be aware of it but fortunately with the database migration",
    "start": "893450",
    "end": "900230"
  },
  {
    "text": "service you don't have to do it these steps anymore you can get to your first",
    "start": "900230",
    "end": "906680"
  },
  {
    "text": "migration tasks task in less than 10 minutes now you can set up a replication",
    "start": "906680",
    "end": "912230"
  },
  {
    "text": "instance you can set up your connections to sources and targets and you can start replicating within 10 minutes it's good",
    "start": "912230",
    "end": "919310"
  },
  {
    "text": "to know that you can move data into data pump for data pump but this service is",
    "start": "919310",
    "end": "925220"
  },
  {
    "text": "simple enough for for not needing to know these steps the",
    "start": "925220",
    "end": "930830"
  },
  {
    "text": "other cool feature about the database migration services that you can keep your application separation all during",
    "start": "930830",
    "end": "936590"
  },
  {
    "text": "the database migration process in my previous example I had a down time of",
    "start": "936590",
    "end": "941750"
  },
  {
    "text": "about seven hours because my files were exported so I couldn't take any transactions on my source anymore with",
    "start": "941750",
    "end": "950300"
  },
  {
    "text": "the database migration service not anymore you can keep transactions running on the source database and you",
    "start": "950300",
    "end": "956720"
  },
  {
    "text": "can switch your applications whenever you are ready in addition to migrating",
    "start": "956720",
    "end": "963590"
  },
  {
    "text": "data the database migration service also allows you to replication either within",
    "start": "963590",
    "end": "969110"
  },
  {
    "text": "RDS over them AWS if you have multiple copies of the same database you would like to maintain this service will allow",
    "start": "969110",
    "end": "976190"
  },
  {
    "text": "you to do it but you can also replicate into AWS as well as out of AWS you can",
    "start": "976190",
    "end": "984350"
  },
  {
    "text": "for example establish a disaster recovery solution or help the stool help",
    "start": "984350",
    "end": "990410"
  },
  {
    "text": "you building a disaster recovery solution or perhaps integrating your data from the cloud into your",
    "start": "990410",
    "end": "997100"
  },
  {
    "text": "on-premises systems that still need to be operational for the next year's",
    "start": "997100",
    "end": "1003000"
  },
  {
    "text": "another cool feature of the database migration service is that it allows you to move data heterogeneously so you",
    "start": "1003840",
    "end": "1010000"
  },
  {
    "text": "don't always have to stay with the same engine your startech if you have a transactional load for example in oracle",
    "start": "1010000",
    "end": "1017220"
  },
  {
    "text": "but would like to use a post gas engine for reporting you can use the database",
    "start": "1017220",
    "end": "1024370"
  },
  {
    "text": "migration service to set up replication which are a genius lee and will move the",
    "start": "1024370",
    "end": "1029980"
  },
  {
    "text": "data from the oracle database to your post curse target if you'd like to sign",
    "start": "1029980",
    "end": "1038380"
  },
  {
    "text": "up for the database migration service please go to AWS amazon.com / TMS and",
    "start": "1038380",
    "end": "1044980"
  },
  {
    "text": "sign up for the video I want to spend a",
    "start": "1044980",
    "end": "1050050"
  },
  {
    "start": "1048000",
    "end": "1048000"
  },
  {
    "text": "bit of time talking about the the minimization of down time that the",
    "start": "1050050",
    "end": "1055900"
  },
  {
    "text": "database migration service allows you to accomplished I'm going to start with a",
    "start": "1055900",
    "end": "1062940"
  },
  {
    "text": "setup where my applications are accessing my source database on premises",
    "start": "1062940",
    "end": "1069590"
  },
  {
    "text": "and the first step I'm going to do is I'm going to create a duplication instance in Amazon using the AWS",
    "start": "1070100",
    "end": "1079560"
  },
  {
    "text": "database migration service so this instance is going to start pumping data",
    "start": "1079560",
    "end": "1085910"
  },
  {
    "text": "after I select my after i connect to my source and target database obviously and select the tables and databases have it",
    "start": "1085910",
    "end": "1093540"
  },
  {
    "text": "like to migrate the database migration",
    "start": "1093540",
    "end": "1098760"
  },
  {
    "text": "service will will do a bulk load and they'll start replicating all the changes on your source until the target",
    "start": "1098760",
    "end": "1107160"
  },
  {
    "text": "gets the point that's in transition point where it's pretty much the same as",
    "start": "1107160",
    "end": "1112470"
  },
  {
    "text": "the same as the source database once you see the transaction queue or the the",
    "start": "1112470",
    "end": "1119400"
  },
  {
    "text": "queue of changes that need to be replicated getting to zero this is a",
    "start": "1119400",
    "end": "1124560"
  },
  {
    "text": "good time point to switch your applications from the source database to",
    "start": "1124560",
    "end": "1129990"
  },
  {
    "text": "your target database and completely migrate your system this way I also also",
    "start": "1129990",
    "end": "1139470"
  },
  {
    "start": "1137000",
    "end": "1137000"
  },
  {
    "text": "wanted to share a few best practices for the database migration service in conjunction with operating Oracle",
    "start": "1139470",
    "end": "1145560"
  },
  {
    "text": "databases the database migration service is great for moving data and it also",
    "start": "1145560",
    "end": "1152100"
  },
  {
    "text": "provides a basic ability to my create your schema but it will only copy the",
    "start": "1152100",
    "end": "1157670"
  },
  {
    "text": "tables and the primary keys from your source database to your target database",
    "start": "1157670",
    "end": "1163070"
  },
  {
    "text": "dms does not yet support moving secondary objects secondary indices or",
    "start": "1163070",
    "end": "1169170"
  },
  {
    "text": "store procedures or triggers so for the secondary objects what you want to do is",
    "start": "1169170",
    "end": "1176610"
  },
  {
    "text": "to use either the native oracle DBA mass meta data package just to get the ddl of",
    "start": "1176610",
    "end": "1183480"
  },
  {
    "text": "your source database or you should use the some of the other tools available",
    "start": "1183480",
    "end": "1189300"
  },
  {
    "text": "with oracle such as sequel developer just make sure that when you export the schema don't export the data because GM",
    "start": "1189300",
    "end": "1196259"
  },
  {
    "text": "else will help you with that another recommendation I can I can share with",
    "start": "1196259",
    "end": "1202080"
  },
  {
    "text": "you today is to optimize the performance of the migration task you want to",
    "start": "1202080",
    "end": "1207749"
  },
  {
    "text": "consider dividing your your ddl into two parts the first one is the tables and",
    "start": "1207749",
    "end": "1214139"
  },
  {
    "text": "primary keys this is really just the required two objects that will that I",
    "start": "1214139",
    "end": "1219570"
  },
  {
    "text": "require to accept the data from the source database without imposing any",
    "start": "1219570",
    "end": "1224700"
  },
  {
    "text": "borden do two triggers or secondary indexes the second set of scripts should",
    "start": "1224700",
    "end": "1231149"
  },
  {
    "text": "include the manner of your schema and you should apply the second script when",
    "start": "1231149",
    "end": "1236609"
  },
  {
    "text": "you have transferred the data and are ready now to build secondary indices and enable triggers and store procedures to",
    "start": "1236609",
    "end": "1246690"
  },
  {
    "text": "optimize performance of the database migration process you should use our bigger see for instance types the",
    "start": "1246690",
    "end": "1254639"
  },
  {
    "text": "database migration service comes in two flavors supporting two instance types",
    "start": "1254639",
    "end": "1261259"
  },
  {
    "text": "t24 burstable loads as well as c4 for high performance data transfer so",
    "start": "1261259",
    "end": "1270179"
  },
  {
    "text": "definitely feel free to to use the larger instance types if you would like to minimize downtime if that is your",
    "start": "1270179",
    "end": "1276869"
  },
  {
    "text": "objective and another thing you should be watching out for is network because",
    "start": "1276869",
    "end": "1282330"
  },
  {
    "text": "in many cases network will be the bottleneck when you move data from on-premises to the cloud so what you",
    "start": "1282330",
    "end": "1289590"
  },
  {
    "text": "want to do is you want to either sign up for a direct connect connection or use",
    "start": "1289590",
    "end": "1294599"
  },
  {
    "text": "use the larger see for instance types because because they have a bigger",
    "start": "1294599",
    "end": "1299879"
  },
  {
    "text": "bigger network interface and allow more bandwidth i also want to talk about",
    "start": "1299879",
    "end": "1309499"
  },
  {
    "text": "building and improving the performance of your workloads on amazon ideas",
    "start": "1309499",
    "end": "1317508"
  },
  {
    "text": "and in this presentation I'm going to use a example of of a of a workload that",
    "start": "1324790",
    "end": "1332270"
  },
  {
    "text": "has a mix of reeds and right and I'm going to use this example to demonstrate some of the concepts I'm going to be",
    "start": "1332270",
    "end": "1339080"
  },
  {
    "text": "talking about so many customers when they when they start analyzing and",
    "start": "1339080",
    "end": "1344630"
  },
  {
    "text": "improving performance of the instances they start with metrics you can use the matrix available to you through the RDS",
    "start": "1344630",
    "end": "1352190"
  },
  {
    "text": "dashboard but you can also use the matrix available to you through cloud watch or Oracle Enterprise Manager",
    "start": "1352190",
    "end": "1358510"
  },
  {
    "text": "Amazon RDS integrates with supports Oracle Enterprise Manager Suki you can",
    "start": "1358510",
    "end": "1364460"
  },
  {
    "text": "use that tool to manage you or to review your metrics and analyze the performance in my particular workload I'm doing a",
    "start": "1364460",
    "end": "1376250"
  },
  {
    "text": "very long loop of inserts into a invoicing table so every every other",
    "start": "1376250",
    "end": "1383630"
  },
  {
    "text": "time I do an insert and every other time I do a select a quick select and delete",
    "start": "1383630",
    "end": "1390400"
  },
  {
    "text": "so the ratio of right streets here is about two to one and I'm executing this",
    "start": "1390400",
    "end": "1398780"
  },
  {
    "text": "workload on two connections to kind of demonstrate the what happens when you're",
    "start": "1398780",
    "end": "1405080"
  },
  {
    "text": "on multiple multiple heavy-hitting connections my instance is a m3 large",
    "start": "1405080",
    "end": "1414860"
  },
  {
    "start": "1410000",
    "end": "1410000"
  },
  {
    "text": "instance it has two virtual CPUs and about eight gigabyte of memory and I",
    "start": "1414860",
    "end": "1421610"
  },
  {
    "text": "have allocated about 400 gigabytes of space for storage so the first thing I'm",
    "start": "1421610",
    "end": "1428300"
  },
  {
    "text": "going to do when I when I want to improve the performance of my workload as well as my instance I'm going to look",
    "start": "1428300",
    "end": "1434300"
  },
  {
    "text": "at the CPU statistics and as you can see CP us being held pretty heavily here the",
    "start": "1434300",
    "end": "1440000"
  },
  {
    "text": "the average consumption of CPU is about eighty to eighty-five percent I'm also",
    "start": "1440000",
    "end": "1447530"
  },
  {
    "text": "going to look at my reads and writes as I said before the ratio of my rights to",
    "start": "1447530",
    "end": "1453590"
  },
  {
    "text": "my deeds is about two to one and you can see it easily and the in the dashboard I'm getting about 600",
    "start": "1453590",
    "end": "1460790"
  },
  {
    "text": "to 800 writes per second and about 200 to 400 reads per second yet another",
    "start": "1460790",
    "end": "1469130"
  },
  {
    "text": "statistic I want to look at is the amount of reebok memory but it doesn't seem to be a problem yet I still have",
    "start": "1469130",
    "end": "1475880"
  },
  {
    "text": "about two gigabytes of two gigabytes of RAM available to me free storage doesn't",
    "start": "1475880",
    "end": "1484220"
  },
  {
    "text": "seem to be an issue I have quite a bit of it and the number of database",
    "start": "1484220",
    "end": "1489950"
  },
  {
    "text": "connections is predictably too because I'm running to talk them in parallel right now when you go about scaling your",
    "start": "1489950",
    "end": "1500330"
  },
  {
    "start": "1497000",
    "end": "1497000"
  },
  {
    "text": "instance you typically have four things to to tweak the first one is the compute",
    "start": "1500330",
    "end": "1509330"
  },
  {
    "text": "capability of your instance and it's typically measured by the number of these cpus the other component of your",
    "start": "1509330",
    "end": "1515990"
  },
  {
    "text": "RDS instance is memory then you have network and lastly have storage we used",
    "start": "1515990",
    "end": "1525020"
  },
  {
    "text": "to offer a variety of instance families in the past starting with 81 m1 m2 m3",
    "start": "1525020",
    "end": "1530090"
  },
  {
    "text": "and we have recently launched support 42 and r3 instance types t2 instance types",
    "start": "1530090",
    "end": "1537590"
  },
  {
    "text": "are very cost-effective general purpose instance types that allow you to use",
    "start": "1537590",
    "end": "1543020"
  },
  {
    "text": "burstable that provide you with burstable capabilities so if you are",
    "start": "1543020",
    "end": "1548270"
  },
  {
    "text": "running a workload that is not consuming the CPU and a constant level of the duration of 24 hours a day but just need",
    "start": "1548270",
    "end": "1556790"
  },
  {
    "text": "to be able to spike maybe for a couple of hours a day t tools are definitely the instance types you want to consider",
    "start": "1556790",
    "end": "1563240"
  },
  {
    "text": "as they cheap and they give you credits you can use during these bursts the r3",
    "start": "1563240",
    "end": "1570440"
  },
  {
    "text": "instance types are the high end of our current capabilities and you can go up",
    "start": "1570440",
    "end": "1575990"
  },
  {
    "text": "to 32 virtual CPUs and 244 gigabytes of RAM the weeks ago we launched support",
    "start": "1575990",
    "end": "1585260"
  },
  {
    "text": "for the t2 large instance type the key to large is an interesting one because",
    "start": "1585260",
    "end": "1590740"
  },
  {
    "text": "it has to be CPUs but 8 gigabytes of RAM so you have if you have a reporting",
    "start": "1590740",
    "end": "1596470"
  },
  {
    "text": "workload for example that only is used maybe for a couple of hours a day but",
    "start": "1596470",
    "end": "1601990"
  },
  {
    "text": "needs access to a large amount of RAM that would be the instance type to",
    "start": "1601990",
    "end": "1607300"
  },
  {
    "text": "consider it's very cheap and it gives you it fits the profile of infinite",
    "start": "1607300",
    "end": "1614080"
  },
  {
    "text": "frequent use during the day we need access to a lot of RAM in my previous",
    "start": "1614080",
    "end": "1623470"
  },
  {
    "start": "1620000",
    "end": "1620000"
  },
  {
    "text": "example when I started talking about the the performance metrics you saw that the CPU of my own sins was spiking so I",
    "start": "1623470",
    "end": "1631600"
  },
  {
    "text": "realize this is this is a bottleneck in my account set up so I decided to scale my instance to the larger instance the",
    "start": "1631600",
    "end": "1640210"
  },
  {
    "text": "the next step up from my empty large is the m3 x-large so I decided to scale to",
    "start": "1640210",
    "end": "1646600"
  },
  {
    "text": "that instance type and during scale in what I'm going to do is I make sure going to use a multi easy configuration",
    "start": "1646600",
    "end": "1653260"
  },
  {
    "text": "for my instance to minimize the down time that I will realize till the scaling aberration here's a log of all",
    "start": "1653260",
    "end": "1662140"
  },
  {
    "text": "the events that are happening with my instance during the scaling process takes about 25 minutes to apply the",
    "start": "1662140",
    "end": "1671679"
  },
  {
    "text": "skill injector to scale my instance from the large size to the x large size but",
    "start": "1671679",
    "end": "1678250"
  },
  {
    "text": "because it's a multi instance my instance is only unavailable for about two minutes actually less than two",
    "start": "1678250",
    "end": "1685450"
  },
  {
    "text": "minutes only 105 seconds so I I was able to continue taking transactions on my",
    "start": "1685450",
    "end": "1691150"
  },
  {
    "text": "source database for the first 10 minutes of the scale operation and the last 10",
    "start": "1691150",
    "end": "1696460"
  },
  {
    "text": "minutes of the scale operation because what multi she does it it starts preparing the secondary host starts up",
    "start": "1696460",
    "end": "1703690"
  },
  {
    "text": "upgrading secondary my secondary I am my secretary costs while I can still",
    "start": "1703690",
    "end": "1709450"
  },
  {
    "text": "continue using doing transactions on the primary cost and only when the secondary",
    "start": "1709450",
    "end": "1714610"
  },
  {
    "text": "host is available does the multi g-technology switch and do a failover",
    "start": "1714610",
    "end": "1720400"
  },
  {
    "text": "and provide me with the replace the endpoints and give me a kind",
    "start": "1720400",
    "end": "1725490"
  },
  {
    "text": "of access to my new primary which was the old secondary so what happened to my",
    "start": "1725490",
    "end": "1734790"
  },
  {
    "start": "1732000",
    "end": "1732000"
  },
  {
    "text": "instance of the scaling CPU definitely went down it's now about fifty to",
    "start": "1734790",
    "end": "1740310"
  },
  {
    "text": "fifty-five percent my reads and my",
    "start": "1740310",
    "end": "1745980"
  },
  {
    "text": "rights increase and if you look in detail on on the detailed statistics the",
    "start": "1745980",
    "end": "1753060"
  },
  {
    "start": "1749000",
    "end": "1749000"
  },
  {
    "text": "duration of the previous ron was about 36 minutes after scaling I was able to",
    "start": "1753060",
    "end": "1759810"
  },
  {
    "text": "get it done within 23 minutes my cpu was around eighty percent in the past it",
    "start": "1759810",
    "end": "1765960"
  },
  {
    "text": "became around fifty five percent with the larger instance type my my rights",
    "start": "1765960",
    "end": "1777150"
  },
  {
    "start": "1773000",
    "end": "1773000"
  },
  {
    "text": "increased by twenty twenty five percent so it's definitely a CPU bound workload",
    "start": "1777150",
    "end": "1784830"
  },
  {
    "text": "it I didn't have any bottlenecks and rights the reason why I got more rights than just because I'm doing it faster",
    "start": "1784830",
    "end": "1791910"
  },
  {
    "text": "and so there's more more to be written to my to my desk I did not see a 2x",
    "start": "1791910",
    "end": "1797610"
  },
  {
    "text": "improvement in my rights but it's most probably because I'm running two connections and they can generate this",
    "start": "1797610",
    "end": "1802710"
  },
  {
    "text": "much load my reads increased as well by",
    "start": "1802710",
    "end": "1810660"
  },
  {
    "text": "another thirty five forty percent and if you want to see a quick comparison of",
    "start": "1810660",
    "end": "1816840"
  },
  {
    "start": "1814000",
    "end": "1814000"
  },
  {
    "text": "all the important metrics I was able to by scaling my instance by increasing the",
    "start": "1816840",
    "end": "1822540"
  },
  {
    "text": "number of V CPUs and by increasing number of memory will go to me i was able to reduce the duration of my",
    "start": "1822540",
    "end": "1828570"
  },
  {
    "text": "workload decrease the consumption of cpu increase my read and write rates the",
    "start": "1828570",
    "end": "1839190"
  },
  {
    "text": "last component that you can tweak in Amazon RDS is storage and one of the improvements we've done over the past",
    "start": "1839190",
    "end": "1844920"
  },
  {
    "text": "couple of months is was extending the available the maximum storage size",
    "start": "1844920",
    "end": "1851790"
  },
  {
    "text": "available to you from Phthia terabytes 26 terabytes I want to talk about the performance of",
    "start": "1851790",
    "end": "1859170"
  },
  {
    "start": "1857000",
    "end": "1857000"
  },
  {
    "text": "of storage and how to tweak it and what the what the different characteristics are all that some of you might know that",
    "start": "1859170",
    "end": "1867360"
  },
  {
    "text": "with Amazon RDS you don't get instant storage but what you get is network",
    "start": "1867360",
    "end": "1872910"
  },
  {
    "text": "attached storage there are three types of network attached storage you you can",
    "start": "1872910",
    "end": "1879060"
  },
  {
    "text": "choose you can start or you can choose magnetic storage my neck magnetic",
    "start": "1879060",
    "end": "1885120"
  },
  {
    "text": "storage comes into comes in varieties from 10 gigabytes to three terabytes and",
    "start": "1885120",
    "end": "1892170"
  },
  {
    "text": "you can get a performance of about a hundred IO operations per second burst",
    "start": "1892170",
    "end": "1898170"
  },
  {
    "text": "able to maybe a hundred several hundred I operations per second now the next",
    "start": "1898170",
    "end": "1907860"
  },
  {
    "text": "storage type you can choose is GP toe or a general-purpose storage using SSD and",
    "start": "1907860",
    "end": "1914660"
  },
  {
    "text": "you can go from 10 gigabytes 26 terabytes you get three io operations",
    "start": "1914660",
    "end": "1922260"
  },
  {
    "text": "per gigabyte that you reserve and this capacity can actually burst up to 3,000",
    "start": "1922260",
    "end": "1927540"
  },
  {
    "text": "I operations per volume we do recommend allocating at least a hundred gigabytes",
    "start": "1927540",
    "end": "1935010"
  },
  {
    "text": "because with with gp2 if you if you allocate smaller amounts of RAM as a",
    "start": "1935010",
    "end": "1942750"
  },
  {
    "text": "storage you get you might get lower performance than your magnetic storage",
    "start": "1942750",
    "end": "1948060"
  },
  {
    "text": "because of the three I your credits per gigabyte that year that you receive some",
    "start": "1948060",
    "end": "1958680"
  },
  {
    "text": "of you might know as but i'm gonna i'm going to mention this as well if you",
    "start": "1958680",
    "end": "1965160"
  },
  {
    "text": "create gp2 volumes that are larger than three terabytes in size you actually get",
    "start": "1965160",
    "end": "1970950"
  },
  {
    "text": "a baseline performance not burst of all but baseline performance of 10,000",
    "start": "1970950",
    "end": "1976470"
  },
  {
    "text": "tie-ups and so gp2 is definitely becoming a good alternative to using the",
    "start": "1976470",
    "end": "1983310"
  },
  {
    "text": "next storage step that i'll be talking about which is provisioned tie-ups production tie-ups are",
    "start": "1983310",
    "end": "1988890"
  },
  {
    "text": "or high-end storage type and it's it comes in varieties from a hundred",
    "start": "1988890",
    "end": "1994110"
  },
  {
    "text": "gigabytes 26 terabyte and you can allocate up to 10 I operations per",
    "start": "1994110",
    "end": "1999150"
  },
  {
    "text": "gigabyte deserved and your performance of the of the storage volume can go up",
    "start": "1999150",
    "end": "2004370"
  },
  {
    "text": "to 30,000 provision tariffs what are the",
    "start": "2004370",
    "end": "2012770"
  },
  {
    "start": "2011000",
    "end": "2011000"
  },
  {
    "text": "best practices for using or improving storage performance on Amazon ideas the",
    "start": "2012770",
    "end": "2020600"
  },
  {
    "text": "first one is realizing that you have a up to 1000 megabits per second on each",
    "start": "2020600",
    "end": "2027080"
  },
  {
    "text": "of the channels reads and writes this is the maximum performance of Amazon idea",
    "start": "2027080",
    "end": "2032660"
  },
  {
    "text": "storage so you get up to 105 megabits per second each direction or total are",
    "start": "2032660",
    "end": "2038990"
  },
  {
    "text": "your performance of 210 megabits per second the 110 applies if you have a",
    "start": "2038990",
    "end": "2046310"
  },
  {
    "text": "perfectly balanced 5050 read/write workload how many of you know what they",
    "start": "2046310",
    "end": "2054919"
  },
  {
    "text": "first touch panel t is any BS see a couple of hands so first touch penalty",
    "start": "2054919",
    "end": "2062720"
  },
  {
    "text": "means when you restore a snapshot or when you create a new instance the the",
    "start": "2062720",
    "end": "2069408"
  },
  {
    "text": "first operation on the storage volume and Amazon RDS as well as on abs will be",
    "start": "2069409",
    "end": "2075350"
  },
  {
    "text": "somewhat somewhat slower then subsequent operations with that that block storage",
    "start": "2075350",
    "end": "2082190"
  },
  {
    "text": "block there are a couple of techniques you can use to even out the performance",
    "start": "2082190",
    "end": "2088040"
  },
  {
    "text": "of of access for example you can do a you know just need all these blogs in",
    "start": "2088040",
    "end": "2093080"
  },
  {
    "text": "one big select statement after initialization of your instance this way you even know the performance it's just",
    "start": "2093080",
    "end": "2099320"
  },
  {
    "text": "the performance optimization technique you don't have to do it eventually after couple of minutes the performance of",
    "start": "2099320",
    "end": "2104720"
  },
  {
    "text": "your storage access will equalize but if you would like to have a consistent",
    "start": "2104720",
    "end": "2109870"
  },
  {
    "text": "performance then this is something you might want to consider and lastly",
    "start": "2109870",
    "end": "2118349"
  },
  {
    "text": "when you use gp2 it's a great storage type and you saw that you can realize",
    "start": "2118349",
    "end": "2125099"
  },
  {
    "text": "great performance with it especially on larger volumes on smaller volumes be aware of the three io credits per",
    "start": "2125099",
    "end": "2132359"
  },
  {
    "text": "gigabyte that you get so if you reserve less than 30 gigabytes for your GP to",
    "start": "2132359",
    "end": "2140279"
  },
  {
    "text": "database you will actually get lower performance than magnetic storage so you",
    "start": "2140279",
    "end": "2145349"
  },
  {
    "text": "might want to consider using magnetic storage for your smaller databases and using gp2 for somewhat larger databases",
    "start": "2145349",
    "end": "2156380"
  },
  {
    "text": "so so far we've talked about security and and scalability and performance",
    "start": "2156529",
    "end": "2162539"
  },
  {
    "text": "improvements in Amazon RDS you also have lots of customers who would like to run",
    "start": "2162539",
    "end": "2169170"
  },
  {
    "text": "oracle workloads on ec2 especially when they are rack based workloads and I",
    "start": "2169170",
    "end": "2176160"
  },
  {
    "text": "would like to invite Jeremiah to talk about his project on building oracle RAC on AWS thanks okay so who would like to",
    "start": "2176160",
    "end": "2196859"
  },
  {
    "text": "run rack on ec2 not that many hands okay well I tell you how anyway so sorry my",
    "start": "2196859",
    "end": "2208200"
  },
  {
    "text": "voice is just going to come back after half an hour on that chair so we believe",
    "start": "2208200",
    "end": "2213900"
  },
  {
    "text": "that we do have some significant number of customers that would like to be able to run rack on ec2 and for very long",
    "start": "2213900",
    "end": "2220920"
  },
  {
    "text": "time people have said well it's not possible but we started looking at all",
    "start": "2220920",
    "end": "2227099"
  },
  {
    "start": "2227000",
    "end": "2227000"
  },
  {
    "text": "the different reasons that our customers would want to be able to do that one",
    "start": "2227099",
    "end": "2235109"
  },
  {
    "text": "really simple reason is that a lot of customers would just like to be able to build out their non prod environments on",
    "start": "2235109",
    "end": "2242309"
  },
  {
    "text": "ec2 maybe keep their on-premises rack or traditionally hosted rack clusters for",
    "start": "2242309",
    "end": "2248099"
  },
  {
    "text": "production you know in a traditional hosting environment on a traditional hardware but for",
    "start": "2248099",
    "end": "2255430"
  },
  {
    "text": "developers it's just it's very expensive to have a rack cluster for every developer it's not economical so that's",
    "start": "2255430",
    "end": "2263470"
  },
  {
    "text": "one really good use case one good reason that you would want developers to have",
    "start": "2263470",
    "end": "2268630"
  },
  {
    "text": "access to rack as if they're developing",
    "start": "2268630",
    "end": "2273760"
  },
  {
    "text": "software against Oracle forint that's ultimately going to run in production",
    "start": "2273760",
    "end": "2279549"
  },
  {
    "text": "oracle RAC they want to be able to tell if they're introducing workloads that are going to affect that are going to be",
    "start": "2279549",
    "end": "2289150"
  },
  {
    "text": "affected by rack related regression cases such as if they were going to cause latency in the application there's",
    "start": "2289150",
    "end": "2295660"
  },
  {
    "text": "a result of forcing rack to share blocks across the interconnect or if they're going to affect the availability because",
    "start": "2295660",
    "end": "2301809"
  },
  {
    "text": "maybe their application doesn't know how to use a application failover or fan or",
    "start": "2301809",
    "end": "2308500"
  },
  {
    "text": "one of those kinds of things so that's those are kind of reasons why you want developers developing against track if",
    "start": "2308500",
    "end": "2314319"
  },
  {
    "text": "they're going to develop produce software for RAC another good thing that",
    "start": "2314319",
    "end": "2320230"
  },
  {
    "text": "we noticed is that one of the big selling points of RAC is that you can start with just a couple instances but",
    "start": "2320230",
    "end": "2326259"
  },
  {
    "text": "then like should you need more capacity you can add more instances to the cluster assuming you have a workload for",
    "start": "2326259",
    "end": "2332589"
  },
  {
    "text": "which that is an effective scaling technique and that is very very close to",
    "start": "2332589",
    "end": "2339359"
  },
  {
    "text": "what we say about ec2 if you need additional capacity add more instances",
    "start": "2339359",
    "end": "2345599"
  },
  {
    "text": "rack is actually a very good match for our elastic scaling characteristics then",
    "start": "2345599",
    "end": "2356259"
  },
  {
    "text": "there's also the question of peace of mind there are some customers who look at our largest instances which are",
    "start": "2356259",
    "end": "2362799"
  },
  {
    "text": "pretty beefy on ec2 and say well we can this will do for now with single",
    "start": "2362799",
    "end": "2369970"
  },
  {
    "text": "instance Oracle but what if our work load exceeds the largest instance that",
    "start": "2369970",
    "end": "2374980"
  },
  {
    "text": "you guys provide we've got nowhere to go if we were on traditionally hosted hardware we could go buy a gigantic",
    "start": "2374980",
    "end": "2381509"
  },
  {
    "text": "engineered system pay pay a bunch of money for that but at least we'd be able to scale beyond the",
    "start": "2381509",
    "end": "2387400"
  },
  {
    "text": "size of that that machine so if we can",
    "start": "2387400",
    "end": "2393340"
  },
  {
    "text": "run rack on ec2 would be pretty great because you could if you exhausted the",
    "start": "2393340",
    "end": "2399670"
  },
  {
    "text": "capacity of our largest instance you could go ahead and add another one add one after that so just expand beyond",
    "start": "2399670",
    "end": "2406630"
  },
  {
    "text": "that size another reason customers like",
    "start": "2406630",
    "end": "2412570"
  },
  {
    "text": "to use rack in general is to provide a like high availability at the instance",
    "start": "2412570",
    "end": "2418150"
  },
  {
    "text": "and app level and that's something that you would have to engineer around if you were doing this yourself on on ec2 and",
    "start": "2418150",
    "end": "2425670"
  },
  {
    "text": "even on RDS though we do have multi easy availability feature but the failover",
    "start": "2425670",
    "end": "2430900"
  },
  {
    "text": "time is slightly longer than the failover time would be for RAC if you",
    "start": "2430900",
    "end": "2436810"
  },
  {
    "text": "had everything implemented correctly at the application to take advantage of rec failover so some customers are looking",
    "start": "2436810",
    "end": "2442660"
  },
  {
    "text": "for that application continuity capability in Oracle near zero downtime and if you're you know from a instance",
    "start": "2442660",
    "end": "2451000"
  },
  {
    "text": "and host level perspective RAC provides you with that availability solution",
    "start": "2451000",
    "end": "2456990"
  },
  {
    "text": "another question a lot of our customers have is when they're going to reach a",
    "start": "2456990",
    "end": "2463060"
  },
  {
    "text": "point of diminishing returns on their instance count even if they're hosting their req cluster in in traditionally",
    "start": "2463060",
    "end": "2471430"
  },
  {
    "text": "hosted environment maybe they've gone up to like four or five or six nodes and they're scaling plan is should they",
    "start": "2471430",
    "end": "2478720"
  },
  {
    "text": "exhaust the capacity of six nodes are going to add a 7th 8th 9th 10th all the way up to a 64th the question is going",
    "start": "2478720",
    "end": "2486040"
  },
  {
    "text": "to be at what point are they going to saturate the interconnect at what point is adding nodes the rack cluster going",
    "start": "2486040",
    "end": "2492190"
  },
  {
    "text": "to stop scaling their workload and going to start causing it to scale inversely which will happen at some point in most",
    "start": "2492190",
    "end": "2497860"
  },
  {
    "text": "workloads if you could create lots and lots of nodes of rack and point your",
    "start": "2497860",
    "end": "2504760"
  },
  {
    "text": "workload at it in a virtual environment you could test this question without buying all that physical hardware to",
    "start": "2504760",
    "end": "2511150"
  },
  {
    "text": "test it out and find out at what point at what number of nodes your workload begins to scale inversely",
    "start": "2511150",
    "end": "2517780"
  },
  {
    "text": "so that's another great use case for running rack on ec2 and there are the applications third party apps that have",
    "start": "2517780",
    "end": "2524290"
  },
  {
    "text": "a list of requirements and some of them say they require rack and whether or not",
    "start": "2524290",
    "end": "2531610"
  },
  {
    "text": "you believe that's a good requirement for them to be putting out there that",
    "start": "2531610",
    "end": "2536740"
  },
  {
    "text": "requirement still seems to be in some third-party applications list of prerequisites so we want to be able to",
    "start": "2536740",
    "end": "2544090"
  },
  {
    "text": "provide what customers deed to run their apps on AWS another use cases customers",
    "start": "2544090",
    "end": "2551320"
  },
  {
    "text": "who want to get to AWS now but don't want to re-engineer everything for like multi AZ and RDS and all the other stuff",
    "start": "2551320",
    "end": "2558280"
  },
  {
    "text": "they just say look look we're buying into the cloud idea but we just want to",
    "start": "2558280",
    "end": "2563800"
  },
  {
    "text": "lift and shift into ec2 now and start taking advantage of the cloud native capabilities gradually over time once",
    "start": "2563800",
    "end": "2570490"
  },
  {
    "text": "we're in and being able to deploy rack and ec2 allows that allows them to lift their lift and shift their existing",
    "start": "2570490",
    "end": "2577260"
  },
  {
    "text": "design architecture using rack from on-premises into ec2 and finally",
    "start": "2577260",
    "end": "2583960"
  },
  {
    "text": "customers want it and we are interested in doing what our customers want and so",
    "start": "2583960",
    "end": "2589720"
  },
  {
    "text": "we have started thinking about this now historically we have said that rack",
    "start": "2589720",
    "end": "2598270"
  },
  {
    "text": "isn't supported on ec2 and there are a few reasons that that that was a message",
    "start": "2598270",
    "end": "2606010"
  },
  {
    "text": "that we had as you know we store data generally persistent data on EBS in easy",
    "start": "2606010",
    "end": "2612190"
  },
  {
    "text": "to the elastic block store and as you probably know EBS volumes can only be connected to one ec2 instance at a time",
    "start": "2612190",
    "end": "2621100"
  },
  {
    "text": "they can't be connected to multiple ec2 instances at a time so they can't serve that shared storage requirement the rack",
    "start": "2621100",
    "end": "2628210"
  },
  {
    "text": "has so we started thinking about a good",
    "start": "2628210",
    "end": "2633580"
  },
  {
    "start": "2632000",
    "end": "2632000"
  },
  {
    "text": "way to do this and we thought that it would be kind of interesting if instead",
    "start": "2633580",
    "end": "2639310"
  },
  {
    "text": "of serving the storage from EBS we built our own I scuzzy NAS device out of an",
    "start": "2639310",
    "end": "2644830"
  },
  {
    "text": "ec2 instance and served storage from there this allowed us to and we tried",
    "start": "2644830",
    "end": "2650410"
  },
  {
    "text": "this out and worked allowed us to take that EBS volume and share its storage across multiple nodes",
    "start": "2650410",
    "end": "2656670"
  },
  {
    "text": "using ice guzzi now some of you might be looking at this and already calculating",
    "start": "2656670",
    "end": "2662790"
  },
  {
    "text": "what the aisle agencies are going to be like in your heads does this pass the i/o latency sniff test no it does not",
    "start": "2662790",
    "end": "2670400"
  },
  {
    "text": "right one I Oh from the rack node down to the iscsi target one down to the EBS",
    "start": "2670400",
    "end": "2676410"
  },
  {
    "text": "volume EBS volume answers back finally the iscsi target can answer that I o request back unless you've like unless",
    "start": "2676410",
    "end": "2682980"
  },
  {
    "text": "we have like got the stars aligning perfectly you know it's not the it's not a production class io scenario it might",
    "start": "2682980",
    "end": "2690240"
  },
  {
    "text": "it might be valid for tests and Deb though or non prod or low low IO",
    "start": "2690240",
    "end": "2696420"
  },
  {
    "text": "requirement applications so don't rule this completely out but we we said like",
    "start": "2696420",
    "end": "2701820"
  },
  {
    "text": "look this is not going to serve the highest end customers that we want to serve so we tried to think of something else to do so back to the drawing board",
    "start": "2701820",
    "end": "2708990"
  },
  {
    "text": "on the iscsi target there that we were building for serving storage well if you",
    "start": "2708990",
    "end": "2714630"
  },
  {
    "text": "look at what instance classes we provide we actually provide some really interesting high-end instance classes in",
    "start": "2714630",
    "end": "2720390"
  },
  {
    "text": "ec two and one of them is the eye to 8xl and the eye to 8xl has onboard SSD quite",
    "start": "2720390",
    "end": "2728580"
  },
  {
    "text": "a bit of it five or six terabytes and so we thought wouldn't it be interesting if",
    "start": "2728580",
    "end": "2734130"
  },
  {
    "text": "we instead of serving EBS serve the onboard ephemeral SSD from the eye to",
    "start": "2734130",
    "end": "2740520"
  },
  {
    "text": "8xl instance at just as a as a standalone storage node and this passes",
    "start": "2740520",
    "end": "2748560"
  },
  {
    "text": "the i/o performance sniff test but there's another sniff test it doesn't pass which is the durability and",
    "start": "2748560",
    "end": "2756990"
  },
  {
    "text": "redundancy sniff test there's only one of these and it's ephemeral storage what if somebody terminates it your data is",
    "start": "2756990",
    "end": "2763620"
  },
  {
    "text": "gone what if it just fails for whatever reason could happen probably wouldn't",
    "start": "2763620",
    "end": "2768660"
  },
  {
    "text": "but it could your data would be gone so that's not acceptable fortunately we",
    "start": "2768660",
    "end": "2774510"
  },
  {
    "text": "have a sm at ASM has normal redundancy capability and can mirror your data in",
    "start": "2774510",
    "end": "2779820"
  },
  {
    "text": "between multiple multiple volume locations and so by",
    "start": "2779820",
    "end": "2785640"
  },
  {
    "text": "creating two of these we can use a SMS normal redundancy or even high",
    "start": "2785640",
    "end": "2790680"
  },
  {
    "text": "redundancy if we wanted to create three of them to create a highly redundant storage storage service for rack in ec2",
    "start": "2790680",
    "end": "2800069"
  },
  {
    "text": "and it turns out this works pretty well you can kill one of these and everything",
    "start": "2800069",
    "end": "2805980"
  },
  {
    "text": "just keeps on running bring it back up in it you can put it into you can have",
    "start": "2805980",
    "end": "2811650"
  },
  {
    "text": "it begin resyncing and you can of course choose the speed with which you have it",
    "start": "2811650",
    "end": "2816960"
  },
  {
    "text": "do that so this is the storage design we came up with we used open I scuzzy 2",
    "start": "2816960",
    "end": "2822210"
  },
  {
    "text": "point 0 for all this ok there's another reason that people have long said that",
    "start": "2822210",
    "end": "2827460"
  },
  {
    "text": "you can't do rack on ec2 and that is the lack of multicast Network support within",
    "start": "2827460",
    "end": "2834739"
  },
  {
    "text": "VPC rack requires multicast it doesn't require it all the time by the way req",
    "start": "2834739",
    "end": "2839849"
  },
  {
    "text": "only uses multicast when it's doing cluster configuration and reconfiguration so like if a node drops",
    "start": "2839849",
    "end": "2846569"
  },
  {
    "text": "and the cluster has to reconfigure or when you're creating the whole thing to begin with it has to be able to do",
    "start": "2846569",
    "end": "2851789"
  },
  {
    "text": "multicast communication so we needed some kind of solution to provide customers with multicast capability",
    "start": "2851789",
    "end": "2858299"
  },
  {
    "text": "within the VPC network that they would be using we actually looked around and",
    "start": "2858299",
    "end": "2863970"
  },
  {
    "text": "found an interesting solution we used a",
    "start": "2863970",
    "end": "2869700"
  },
  {
    "start": "2865000",
    "end": "2865000"
  },
  {
    "text": "product called n to n from n top which is a point-to-point VPN solution to",
    "start": "2869700",
    "end": "2875670"
  },
  {
    "text": "create an overlay interconnect on top of the 10 gigabit ethernet network that's",
    "start": "2875670",
    "end": "2883170"
  },
  {
    "text": "capable with in your v pc for cluster compute instances this is a really",
    "start": "2883170",
    "end": "2890700"
  },
  {
    "text": "versatile point-to-point VPN and it's super easy to set up it creates a community of nodes within the VPN that",
    "start": "2890700",
    "end": "2898049"
  },
  {
    "text": "can communicate with each other using multicast and normal IP and the whole",
    "start": "2898049",
    "end": "2903210"
  },
  {
    "text": "thing is coordinated by a single node which we actually installed on this on the storage server so that the storage",
    "start": "2903210",
    "end": "2909269"
  },
  {
    "text": "server acts both as I skazhi server and also as the end-to-end coordinator node",
    "start": "2909269",
    "end": "2914690"
  },
  {
    "text": "so that's how we did the interconnect we used n to n from n top alright let me",
    "start": "2914690",
    "end": "2925320"
  },
  {
    "text": "tell you a little bit more about how we built this thing out first of all I'm happy to announce that we have built a",
    "start": "2925320",
    "end": "2932130"
  },
  {
    "text": "prototype and we've we're making that prototype available to our customers at",
    "start": "2932130",
    "end": "2937830"
  },
  {
    "text": "this URL at AWS amazon.com / articles you'll find a tutorial there that will",
    "start": "2937830",
    "end": "2944910"
  },
  {
    "text": "walk you through the setup of this this reference architecture that I'm going to",
    "start": "2944910",
    "end": "2951330"
  },
  {
    "text": "tell you about in addition we've provided to marketplace amies that you",
    "start": "2951330",
    "end": "2956640"
  },
  {
    "text": "can get from the AWS marketplace and that tutorial gives you links directly to that and one of those amies is for",
    "start": "2956640",
    "end": "2963090"
  },
  {
    "text": "the storage server and the other ami is for the rack nodes you can use this to create as many as large of iraq cluster",
    "start": "2963090",
    "end": "2970680"
  },
  {
    "text": "as you like and this designed by the way that i'm about to show you is meant to provide you with a toehold it's not",
    "start": "2970680",
    "end": "2977160"
  },
  {
    "text": "meant to be your ultimate design it's meant to show you that you can create what ultimately is a scalable production",
    "start": "2977160",
    "end": "2983310"
  },
  {
    "text": "class architecture for rack on ec2 and from this point we expect you to also",
    "start": "2983310",
    "end": "2989040"
  },
  {
    "text": "innovate right innovate for your own workloads innovate for your own architectures designs and requirements",
    "start": "2989040",
    "end": "2994530"
  },
  {
    "text": "so this shouldn't be your endpoint this should be your toe hold to getting going with rach successfully on ec2 started",
    "start": "2994530",
    "end": "3001610"
  },
  {
    "text": "with a VPC this is something we recommend you only run with in a VPC for",
    "start": "3001610",
    "end": "3006620"
  },
  {
    "text": "a lot of reasons v pcs have much much have many more networking features than you can get in ec2 classic all kinds of",
    "start": "3006620",
    "end": "3013760"
  },
  {
    "text": "great network networking features in there we also use route 53 route 53 is",
    "start": "3013760",
    "end": "3019550"
  },
  {
    "text": "our dns service available in AWS and we use that for all the stuff that you",
    "start": "3019550",
    "end": "3024650"
  },
  {
    "text": "would need dns for for a rack cluster the scan addresses the VIP the VIP names and all that kind of stuff you have to",
    "start": "3024650",
    "end": "3030950"
  },
  {
    "text": "set up successfully and have working in order to have a working rack cluster and we use this in the form of a private",
    "start": "3030950",
    "end": "3038030"
  },
  {
    "text": "hosted zone turns out you can use route 53 to do dns for look public dns but if",
    "start": "3038030",
    "end": "3043040"
  },
  {
    "text": "you do it within VPC you can set it up as a private hosted zone so that you have",
    "start": "3043040",
    "end": "3048440"
  },
  {
    "text": "so that the the DNS resolution is restricted to just within your your VPC",
    "start": "3048440",
    "end": "3054940"
  },
  {
    "text": "we did the whole thing within a single subnet it seems like the best thing to do to keep Layton sees low and keep",
    "start": "3054940",
    "end": "3060500"
  },
  {
    "text": "everything neat and clean and easy to do we also used a feature of ec2 called placement groups which allows you when",
    "start": "3060500",
    "end": "3066980"
  },
  {
    "text": "you're using when when you bring up instances for those instances to be located nearby to each other from a",
    "start": "3066980",
    "end": "3075140"
  },
  {
    "text": "network topology perspective within the ec2 network so that you have minimized Layton sees in between components so",
    "start": "3075140",
    "end": "3081650"
  },
  {
    "text": "this is exactly what we want we want minimum Layton sees in between the rack nodes and the storage node components we",
    "start": "3081650",
    "end": "3088339"
  },
  {
    "text": "also use dedicated instances so we could get the entire capacity of the of the",
    "start": "3088339",
    "end": "3093890"
  },
  {
    "text": "box when we ran these things started out by building our I scuzzy target just",
    "start": "3093890",
    "end": "3101569"
  },
  {
    "text": "like I was telling you about on the I to 8xl with its 6400 gig of ephemeral storage we stripe that and made it",
    "start": "3101569",
    "end": "3108500"
  },
  {
    "text": "available to the operating system using lvm chopped it up into a chunk for a",
    "start": "3108500",
    "end": "3113770"
  },
  {
    "text": "data volume for ASM at a recovery recovery area volume and left about 800",
    "start": "3113770",
    "end": "3119869"
  },
  {
    "text": "gig free we served all this up using iscsi target software target d the the",
    "start": "3119869",
    "end": "3126349"
  },
  {
    "text": "demon software for I scuzzy then we created a second one for redundancy as we talked about before next we built out",
    "start": "3126349",
    "end": "3132980"
  },
  {
    "text": "our rack nodes on c-38 XL classed instances these are pretty beefy compute oriented instances in our in our first",
    "start": "3132980",
    "end": "3142569"
  },
  {
    "text": "run at this we did two nodes by the way it happens that there's more ephemeral",
    "start": "3142569",
    "end": "3149000"
  },
  {
    "text": "SSD available on the rack node as well and I'll tell you what we use that for in a minute so we presented this storage",
    "start": "3149000",
    "end": "3157430"
  },
  {
    "text": "up to the rack nodes using iscsi initiator software on the rack nodes which allows that to appear as devices",
    "start": "3157430",
    "end": "3164420"
  },
  {
    "text": "that storage to appear as devices on the rack nodes and we set up our virtual",
    "start": "3164420",
    "end": "3169609"
  },
  {
    "text": "interconnect over the 10 Gigabit Ethernet that's available within your VPC we set up a SM and great",
    "start": "3169609",
    "end": "3178730"
  },
  {
    "text": "infrastructure so that the cluster was formed and we were able to present all",
    "start": "3178730",
    "end": "3184920"
  },
  {
    "text": "that storage from the storage servers up by a SMS disk groups we use normal redundancy so that we would be protected",
    "start": "3184920",
    "end": "3191280"
  },
  {
    "text": "from loss of one of the storage nodes then we built out the database software using Database 12c this all works it",
    "start": "3191280",
    "end": "3200700"
  },
  {
    "text": "works pretty well as sort of like the coup de Grasse we decided to use that",
    "start": "3200700",
    "end": "3206730"
  },
  {
    "text": "640 gig of ephemeral SSD that comes with the c3 8xl as flash cache because we",
    "start": "3206730",
    "end": "3212369"
  },
  {
    "text": "built this out on Oh al seven which allows us to use flash cache which further improves the performance of this",
    "start": "3212369",
    "end": "3218550"
  },
  {
    "text": "reference architecture so we can look at",
    "start": "3218550",
    "end": "3224670"
  },
  {
    "text": "that again for a minute if you want and this is also a diagram which is available on that article so you can",
    "start": "3224670",
    "end": "3229890"
  },
  {
    "text": "sort of feast your eyes on that there I know it looks complex but the cool thing about it is the the amies that I've",
    "start": "3229890",
    "end": "3235740"
  },
  {
    "text": "given you in the marketplace are pretty much completely set up to do this",
    "start": "3235740",
    "end": "3240900"
  },
  {
    "text": "there's very little configuration and setup required by you when you when you deploy this it's basically the storage",
    "start": "3240900",
    "end": "3247890"
  },
  {
    "text": "nodes will come up the rack nodes will come up all the storage will already be there you have to download your own",
    "start": "3247890",
    "end": "3253020"
  },
  {
    "text": "software right because we're not oracle software distributors so you you go and you make you go and log into a delivery",
    "start": "3253020",
    "end": "3261569"
  },
  {
    "text": "yourself to get the database and cluster software and then once you've got that downloaded we've got response files that",
    "start": "3261569",
    "end": "3269160"
  },
  {
    "text": "set up everything else for you so it's pretty turnkey so we'll go over a little",
    "start": "3269160",
    "end": "3275280"
  },
  {
    "start": "3273000",
    "end": "3273000"
  },
  {
    "text": "bit what we've talked about today and then we'll have a couple minutes for questions we talked about securing",
    "start": "3275280",
    "end": "3281460"
  },
  {
    "text": "database environments on AWS and RDS talked about migration and our new migration service the database migration",
    "start": "3281460",
    "end": "3288329"
  },
  {
    "text": "service we talked about scalability on RDS and performance optimization and we",
    "start": "3288329",
    "end": "3295410"
  },
  {
    "text": "talked about the fact that you now can build rack clusters on ec2 should you want to that's about it thank you very",
    "start": "3295410",
    "end": "3303720"
  },
  {
    "text": "much please return evaluations or evaluate us on your mobile app and we're",
    "start": "3303720",
    "end": "3311700"
  },
  {
    "text": "ready for questions if you have any",
    "start": "3311700",
    "end": "3314780"
  }
]
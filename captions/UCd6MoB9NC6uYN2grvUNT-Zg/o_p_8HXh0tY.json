[
  {
    "text": "hi",
    "start": "5200",
    "end": "5839"
  },
  {
    "text": "my name is ben addicts and today i will",
    "start": "5839",
    "end": "7839"
  },
  {
    "text": "show you how to create",
    "start": "7839",
    "end": "9040"
  },
  {
    "text": "personalized recommendation using",
    "start": "9040",
    "end": "11360"
  },
  {
    "text": "machine learning on amazon sagemaker",
    "start": "11360",
    "end": "14160"
  },
  {
    "text": "amazon sagemaker helps data scientists",
    "start": "14160",
    "end": "16320"
  },
  {
    "text": "and developers",
    "start": "16320",
    "end": "17359"
  },
  {
    "text": "to quickly prepare build train",
    "start": "17359",
    "end": "20400"
  },
  {
    "text": "and deploy machine learning models by",
    "start": "20400",
    "end": "22560"
  },
  {
    "text": "bringing together a broad set",
    "start": "22560",
    "end": "24080"
  },
  {
    "text": "of purpose-built capabilities for this",
    "start": "24080",
    "end": "27279"
  },
  {
    "text": "demo",
    "start": "27279",
    "end": "27840"
  },
  {
    "text": "we'll be working in sagemaker studio",
    "start": "27840",
    "end": "29599"
  },
  {
    "text": "which is a fully integrated development",
    "start": "29599",
    "end": "31359"
  },
  {
    "text": "environment for machine learning",
    "start": "31359",
    "end": "33680"
  },
  {
    "text": "personalization at the highest level",
    "start": "33680",
    "end": "36239"
  },
  {
    "text": "describes how an organization",
    "start": "36239",
    "end": "37840"
  },
  {
    "text": "delivers more customized interactions",
    "start": "37840",
    "end": "40320"
  },
  {
    "text": "and unique experiences for users",
    "start": "40320",
    "end": "43120"
  },
  {
    "text": "it is a means to meet user expectations",
    "start": "43120",
    "end": "45600"
  },
  {
    "text": "by delivering the right experience at",
    "start": "45600",
    "end": "47360"
  },
  {
    "text": "the right time",
    "start": "47360",
    "end": "48399"
  },
  {
    "text": "and the right place the concept of",
    "start": "48399",
    "end": "50480"
  },
  {
    "text": "personalization",
    "start": "50480",
    "end": "51600"
  },
  {
    "text": "although not new now offers",
    "start": "51600",
    "end": "53680"
  },
  {
    "text": "organizations the ability to improve",
    "start": "53680",
    "end": "56079"
  },
  {
    "text": "brand loyalty grow revenue and increase",
    "start": "56079",
    "end": "58960"
  },
  {
    "text": "efficiency",
    "start": "58960",
    "end": "59920"
  },
  {
    "text": "by using data to create a more",
    "start": "59920",
    "end": "61760"
  },
  {
    "text": "sophisticated and customized",
    "start": "61760",
    "end": "64000"
  },
  {
    "text": "customer experience with traditional",
    "start": "64000",
    "end": "66720"
  },
  {
    "text": "approaches to personalization",
    "start": "66720",
    "end": "68560"
  },
  {
    "text": "they're typically based on broad",
    "start": "68560",
    "end": "70560"
  },
  {
    "text": "segments of users",
    "start": "70560",
    "end": "72000"
  },
  {
    "text": "not tailored for every individual user",
    "start": "72000",
    "end": "74240"
  },
  {
    "text": "and therefore the recommendations",
    "start": "74240",
    "end": "76080"
  },
  {
    "text": "often times miss the mark machine",
    "start": "76080",
    "end": "78799"
  },
  {
    "text": "learning provides a scalable way to",
    "start": "78799",
    "end": "80400"
  },
  {
    "text": "deliver unique experiences to",
    "start": "80400",
    "end": "82159"
  },
  {
    "text": "individuals",
    "start": "82159",
    "end": "83200"
  },
  {
    "text": "based on their behavior and inferred",
    "start": "83200",
    "end": "84960"
  },
  {
    "text": "preferences rather than generic segments",
    "start": "84960",
    "end": "87600"
  },
  {
    "text": "of users",
    "start": "87600",
    "end": "88960"
  },
  {
    "text": "machine learning can help by processing",
    "start": "88960",
    "end": "90720"
  },
  {
    "text": "customer data and selecting the right",
    "start": "90720",
    "end": "92720"
  },
  {
    "text": "algorithms to dynamically present the",
    "start": "92720",
    "end": "94720"
  },
  {
    "text": "most relevant products",
    "start": "94720",
    "end": "96240"
  },
  {
    "text": "or content to each user at the right",
    "start": "96240",
    "end": "98240"
  },
  {
    "text": "time",
    "start": "98240",
    "end": "99439"
  },
  {
    "text": "for today's demo i will show how to use",
    "start": "99439",
    "end": "101840"
  },
  {
    "text": "sagemaker studio",
    "start": "101840",
    "end": "103520"
  },
  {
    "text": "lineage model registry and pipelines",
    "start": "103520",
    "end": "107119"
  },
  {
    "text": "to build train and deploy a personalized",
    "start": "107119",
    "end": "110320"
  },
  {
    "text": "recommendation engine using ecommerce",
    "start": "110320",
    "end": "112799"
  },
  {
    "text": "data",
    "start": "112799",
    "end": "113520"
  },
  {
    "text": "this will be a great opportunity for",
    "start": "113520",
    "end": "115040"
  },
  {
    "text": "data scientists and developers",
    "start": "115040",
    "end": "116880"
  },
  {
    "text": "new to aws and sagemaker studio to",
    "start": "116880",
    "end": "119680"
  },
  {
    "text": "explore some of the sagemaker features",
    "start": "119680",
    "end": "121520"
  },
  {
    "text": "in action",
    "start": "121520",
    "end": "122479"
  },
  {
    "text": "and be able to quickly create their own",
    "start": "122479",
    "end": "124079"
  },
  {
    "text": "personal solutions to fit their business",
    "start": "124079",
    "end": "126159"
  },
  {
    "text": "needs",
    "start": "126159",
    "end": "127040"
  },
  {
    "text": "to get started we'll need to launch",
    "start": "127040",
    "end": "128560"
  },
  {
    "text": "sagemaker studio",
    "start": "128560",
    "end": "130720"
  },
  {
    "text": "from within the sagemaker console we can",
    "start": "130720",
    "end": "133599"
  },
  {
    "text": "select",
    "start": "133599",
    "end": "134160"
  },
  {
    "text": "amazon sagemaker studio in the top left",
    "start": "134160",
    "end": "137120"
  },
  {
    "text": "and we'll be taken to the sagemaker",
    "start": "137120",
    "end": "138560"
  },
  {
    "text": "studio control panel",
    "start": "138560",
    "end": "141440"
  },
  {
    "text": "here we can see all sagemaker studio",
    "start": "141440",
    "end": "144080"
  },
  {
    "text": "users associated with our account",
    "start": "144080",
    "end": "146160"
  },
  {
    "text": "if there are no users you can create one",
    "start": "146160",
    "end": "148080"
  },
  {
    "text": "by clicking the add user icon",
    "start": "148080",
    "end": "149760"
  },
  {
    "text": "in the top right i already have a user",
    "start": "149760",
    "end": "151840"
  },
  {
    "text": "here so i will",
    "start": "151840",
    "end": "153440"
  },
  {
    "text": "click open studio and this will take us",
    "start": "153440",
    "end": "156319"
  },
  {
    "text": "to our integrated development",
    "start": "156319",
    "end": "157599"
  },
  {
    "text": "environment",
    "start": "157599",
    "end": "160160"
  },
  {
    "text": "just like that we're in a jupiter",
    "start": "169040",
    "end": "170560"
  },
  {
    "text": "environment and can begin our data",
    "start": "170560",
    "end": "172080"
  },
  {
    "text": "science development work",
    "start": "172080",
    "end": "174560"
  },
  {
    "text": "once we're in sagemaker studio we're",
    "start": "174560",
    "end": "177599"
  },
  {
    "text": "presented with this launcher",
    "start": "177599",
    "end": "179280"
  },
  {
    "text": "the launcher has a variety of different",
    "start": "179280",
    "end": "181200"
  },
  {
    "text": "features that we can take advantage of",
    "start": "181200",
    "end": "183360"
  },
  {
    "text": "for example we could start a new data",
    "start": "183360",
    "end": "185360"
  },
  {
    "text": "flow or we could start by creating our",
    "start": "185360",
    "end": "187599"
  },
  {
    "text": "own",
    "start": "187599",
    "end": "188000"
  },
  {
    "text": "jupyter notebook",
    "start": "188000",
    "end": "190800"
  },
  {
    "text": "we also have the files icon in the top",
    "start": "191280",
    "end": "193680"
  },
  {
    "text": "left where you can see any folders or",
    "start": "193680",
    "end": "195280"
  },
  {
    "text": "notebooks that are available",
    "start": "195280",
    "end": "197360"
  },
  {
    "text": "here it's empty because there are no",
    "start": "197360",
    "end": "199360"
  },
  {
    "text": "folders or files available",
    "start": "199360",
    "end": "200879"
  },
  {
    "text": "yet but for this demo we will need to",
    "start": "200879",
    "end": "204319"
  },
  {
    "text": "clone",
    "start": "204319",
    "end": "204879"
  },
  {
    "text": "the aws personalization repository",
    "start": "204879",
    "end": "208000"
  },
  {
    "text": "so to do so we can click the get icon",
    "start": "208000",
    "end": "211440"
  },
  {
    "text": "and then click clone repository",
    "start": "211440",
    "end": "214959"
  },
  {
    "text": "and then we type in the name of their",
    "start": "214959",
    "end": "217120"
  },
  {
    "text": "repository that we're using",
    "start": "217120",
    "end": "220319"
  },
  {
    "text": "we then pass in our credentials",
    "start": "225280",
    "end": "228720"
  },
  {
    "text": "and then once we click clone it'll take",
    "start": "233120",
    "end": "235840"
  },
  {
    "text": "a few seconds",
    "start": "235840",
    "end": "237120"
  },
  {
    "text": "and then our repository will now show up",
    "start": "237120",
    "end": "239519"
  },
  {
    "text": "in this",
    "start": "239519",
    "end": "240239"
  },
  {
    "text": "files icon once the repository is cloned",
    "start": "240239",
    "end": "243840"
  },
  {
    "text": "we can click in and open our notebook",
    "start": "243840",
    "end": "248080"
  },
  {
    "text": "the example notebook that we're going to",
    "start": "248879",
    "end": "250159"
  },
  {
    "text": "go through today is using a sagemaker",
    "start": "250159",
    "end": "252239"
  },
  {
    "text": "built-in algorithm called factorization",
    "start": "252239",
    "end": "254239"
  },
  {
    "text": "machines",
    "start": "254239",
    "end": "255120"
  },
  {
    "text": "in order to predict which products to",
    "start": "255120",
    "end": "256880"
  },
  {
    "text": "recommend to different users",
    "start": "256880",
    "end": "258880"
  },
  {
    "text": "a factorization machine is a general",
    "start": "258880",
    "end": "260959"
  },
  {
    "text": "purpose supervised learning algorithm",
    "start": "260959",
    "end": "263600"
  },
  {
    "text": "that you can use for both classification",
    "start": "263600",
    "end": "265680"
  },
  {
    "text": "and regression tasks",
    "start": "265680",
    "end": "267600"
  },
  {
    "text": "it is an extension of a linear model",
    "start": "267600",
    "end": "269840"
  },
  {
    "text": "that is designed to capture interactions",
    "start": "269840",
    "end": "271759"
  },
  {
    "text": "between features",
    "start": "271759",
    "end": "272880"
  },
  {
    "text": "within high dimensional sparse data sets",
    "start": "272880",
    "end": "275680"
  },
  {
    "text": "efficiently",
    "start": "275680",
    "end": "276800"
  },
  {
    "text": "for recommendation engines we typically",
    "start": "276800",
    "end": "279280"
  },
  {
    "text": "only have high dimensional sparse data",
    "start": "279280",
    "end": "281840"
  },
  {
    "text": "since most customers only buy a tiny",
    "start": "281840",
    "end": "284000"
  },
  {
    "text": "subset of all of the products offered",
    "start": "284000",
    "end": "286720"
  },
  {
    "text": "factorization machines are particularly",
    "start": "286720",
    "end": "288800"
  },
  {
    "text": "well suited for this kind of data set",
    "start": "288800",
    "end": "291840"
  },
  {
    "text": "for the overall flow of this notebook",
    "start": "291840",
    "end": "294479"
  },
  {
    "text": "first we will read in the data",
    "start": "294479",
    "end": "296160"
  },
  {
    "text": "then do some data cleaning and feature",
    "start": "296160",
    "end": "297919"
  },
  {
    "text": "engineering to prepare the data",
    "start": "297919",
    "end": "299919"
  },
  {
    "text": "for model training second we'll train",
    "start": "299919",
    "end": "303199"
  },
  {
    "text": "our model using sagemaker's built-in",
    "start": "303199",
    "end": "305440"
  },
  {
    "text": "factorization machines algorithm third",
    "start": "305440",
    "end": "308720"
  },
  {
    "text": "we'll use amazon sagemaker lineage",
    "start": "308720",
    "end": "311759"
  },
  {
    "text": "tracking",
    "start": "311759",
    "end": "312479"
  },
  {
    "text": "to track several artifacts from our",
    "start": "312479",
    "end": "314240"
  },
  {
    "text": "model",
    "start": "314240",
    "end": "315600"
  },
  {
    "text": "fourth we'll create a model package",
    "start": "315600",
    "end": "318080"
  },
  {
    "text": "group to register our model in the",
    "start": "318080",
    "end": "320080"
  },
  {
    "text": "sagemaker model registry",
    "start": "320080",
    "end": "322240"
  },
  {
    "text": "and finally we'll use sagemaker",
    "start": "322240",
    "end": "324000"
  },
  {
    "text": "pipelines to create a pipeline",
    "start": "324000",
    "end": "326000"
  },
  {
    "text": "which will contain all of the",
    "start": "326000",
    "end": "327280"
  },
  {
    "text": "aforementioned steps and allow",
    "start": "327280",
    "end": "329039"
  },
  {
    "text": "us to automate them before we begin",
    "start": "329039",
    "end": "332479"
  },
  {
    "text": "let's make sure we have up-to-date",
    "start": "332479",
    "end": "333680"
  },
  {
    "text": "versions of sagemaker and boto3",
    "start": "333680",
    "end": "339680"
  },
  {
    "text": "next we will run a store magic command",
    "start": "339680",
    "end": "341680"
  },
  {
    "text": "which will let us save checkpoints",
    "start": "341680",
    "end": "343280"
  },
  {
    "text": "throughout the notebook",
    "start": "343280",
    "end": "345039"
  },
  {
    "text": "this way if we ever terminate the kernel",
    "start": "345039",
    "end": "347440"
  },
  {
    "text": "but then later need to pick back up in",
    "start": "347440",
    "end": "349039"
  },
  {
    "text": "the notebook",
    "start": "349039",
    "end": "350080"
  },
  {
    "text": "some of our variables will be stored for",
    "start": "350080",
    "end": "351919"
  },
  {
    "text": "us already for example",
    "start": "351919",
    "end": "353840"
  },
  {
    "text": "we will not need to fit our estimator",
    "start": "353840",
    "end": "355360"
  },
  {
    "text": "again",
    "start": "355360",
    "end": "357199"
  },
  {
    "text": "next let's import the packages that",
    "start": "357199",
    "end": "358720"
  },
  {
    "text": "we'll need including boto3",
    "start": "358720",
    "end": "361520"
  },
  {
    "text": "sagemaker and different sagemaker",
    "start": "361520",
    "end": "363840"
  },
  {
    "text": "lineage and workflow methods",
    "start": "363840",
    "end": "368240"
  },
  {
    "text": "next we'll configure our sagemaker",
    "start": "369759",
    "end": "371520"
  },
  {
    "text": "client and session",
    "start": "371520",
    "end": "374638"
  },
  {
    "text": "now that we have our configurations done",
    "start": "375520",
    "end": "377759"
  },
  {
    "text": "we're ready to begin looking at the data",
    "start": "377759",
    "end": "381840"
  },
  {
    "text": "we start by importing our data by taking",
    "start": "382560",
    "end": "384639"
  },
  {
    "text": "a look at the first few rows",
    "start": "384639",
    "end": "386639"
  },
  {
    "text": "the data is online retail data from the",
    "start": "386639",
    "end": "389600"
  },
  {
    "text": "uci",
    "start": "389600",
    "end": "390479"
  },
  {
    "text": "machine learning repository which spans",
    "start": "390479",
    "end": "393039"
  },
  {
    "text": "one year's time",
    "start": "393039",
    "end": "394800"
  },
  {
    "text": "we can see that we have transactional",
    "start": "394800",
    "end": "396160"
  },
  {
    "text": "data containing invoice numbers",
    "start": "396160",
    "end": "398880"
  },
  {
    "text": "stock codes or item ids product",
    "start": "398880",
    "end": "402080"
  },
  {
    "text": "descriptions",
    "start": "402080",
    "end": "403759"
  },
  {
    "text": "quantity sold date of purchase",
    "start": "403759",
    "end": "407520"
  },
  {
    "text": "price customer ids",
    "start": "407520",
    "end": "410880"
  },
  {
    "text": "and country of customer since we don't",
    "start": "410880",
    "end": "413759"
  },
  {
    "text": "have customer",
    "start": "413759",
    "end": "414560"
  },
  {
    "text": "ratings in our data we will use the",
    "start": "414560",
    "end": "416400"
  },
  {
    "text": "quantity purchased as a proxy for rating",
    "start": "416400",
    "end": "419440"
  },
  {
    "text": "in other words we'll try to predict",
    "start": "419440",
    "end": "421039"
  },
  {
    "text": "quantities and if we predict",
    "start": "421039",
    "end": "422880"
  },
  {
    "text": "a higher quantity for a certain customer",
    "start": "422880",
    "end": "425919"
  },
  {
    "text": "product",
    "start": "425919",
    "end": "426400"
  },
  {
    "text": "combination we will take that to mean a",
    "start": "426400",
    "end": "428720"
  },
  {
    "text": "higher likelihood",
    "start": "428720",
    "end": "429759"
  },
  {
    "text": "that the customer will purchase a given",
    "start": "429759",
    "end": "431680"
  },
  {
    "text": "product",
    "start": "431680",
    "end": "432960"
  },
  {
    "text": "if we did have a customer rating we",
    "start": "432960",
    "end": "435039"
  },
  {
    "text": "could use that for our prediction",
    "start": "435039",
    "end": "436240"
  },
  {
    "text": "instead",
    "start": "436240",
    "end": "437360"
  },
  {
    "text": "for example if we had thumbs up or",
    "start": "437360",
    "end": "439440"
  },
  {
    "text": "thumbs down readings",
    "start": "439440",
    "end": "440720"
  },
  {
    "text": "then we could use factorization machines",
    "start": "440720",
    "end": "442720"
  },
  {
    "text": "for binary classification",
    "start": "442720",
    "end": "445360"
  },
  {
    "text": "now let's do some pre-processing and",
    "start": "445360",
    "end": "447840"
  },
  {
    "text": "visualizations of our data",
    "start": "447840",
    "end": "450080"
  },
  {
    "text": "we'll need to do pre-processing to",
    "start": "450080",
    "end": "451680"
  },
  {
    "text": "format the data so that it's suitable",
    "start": "451680",
    "end": "453520"
  },
  {
    "text": "for machine learning",
    "start": "453520",
    "end": "455199"
  },
  {
    "text": "machine learning models can only take",
    "start": "455199",
    "end": "456800"
  },
  {
    "text": "numeric inputs and cannot handle missing",
    "start": "456800",
    "end": "459280"
  },
  {
    "text": "data",
    "start": "459280",
    "end": "460240"
  },
  {
    "text": "so we will need to remove any missing",
    "start": "460240",
    "end": "462000"
  },
  {
    "text": "values and convert our categorical",
    "start": "462000",
    "end": "464479"
  },
  {
    "text": "and text-based columns to numeric",
    "start": "464479",
    "end": "466479"
  },
  {
    "text": "representations",
    "start": "466479",
    "end": "469039"
  },
  {
    "text": "first we check to see if there are any",
    "start": "469039",
    "end": "470639"
  },
  {
    "text": "null values",
    "start": "470639",
    "end": "473440"
  },
  {
    "text": "there are substantial amount of missing",
    "start": "475919",
    "end": "477840"
  },
  {
    "text": "customer ids",
    "start": "477840",
    "end": "480160"
  },
  {
    "text": "if we don't know the customer then it",
    "start": "480160",
    "end": "481759"
  },
  {
    "text": "will not be helpful for us when we're",
    "start": "481759",
    "end": "483199"
  },
  {
    "text": "making recommendations",
    "start": "483199",
    "end": "485199"
  },
  {
    "text": "therefore let's drop these records",
    "start": "485199",
    "end": "488800"
  },
  {
    "text": "turns out that the rows with the missing",
    "start": "489919",
    "end": "491840"
  },
  {
    "text": "descriptions",
    "start": "491840",
    "end": "493280"
  },
  {
    "text": "also happen to be rows with missing",
    "start": "493280",
    "end": "494639"
  },
  {
    "text": "customer ids so",
    "start": "494639",
    "end": "496639"
  },
  {
    "text": "when we drop the rows of missing",
    "start": "496639",
    "end": "498720"
  },
  {
    "text": "customer ids",
    "start": "498720",
    "end": "500400"
  },
  {
    "text": "the rows of missing descriptions go away",
    "start": "500400",
    "end": "502240"
  },
  {
    "text": "as well",
    "start": "502240",
    "end": "504638"
  },
  {
    "text": "next let's plot the unit price",
    "start": "505199",
    "end": "508080"
  },
  {
    "text": "distribution",
    "start": "508080",
    "end": "510720"
  },
  {
    "text": "we can see that we have no negative",
    "start": "511199",
    "end": "512800"
  },
  {
    "text": "values which is good",
    "start": "512800",
    "end": "514959"
  },
  {
    "text": "but it does seem like there are some",
    "start": "514959",
    "end": "516560"
  },
  {
    "text": "extreme outliers",
    "start": "516560",
    "end": "519279"
  },
  {
    "text": "for now we're not going to have to do",
    "start": "519279",
    "end": "521839"
  },
  {
    "text": "anything to handle that",
    "start": "521839",
    "end": "522959"
  },
  {
    "text": "because items with high prices",
    "start": "522959",
    "end": "526800"
  },
  {
    "text": "are relatively normal",
    "start": "526800",
    "end": "529839"
  },
  {
    "text": "next we can look at a distribution of",
    "start": "530959",
    "end": "532480"
  },
  {
    "text": "the quantity",
    "start": "532480",
    "end": "534240"
  },
  {
    "text": "here we see a larger spike around zero",
    "start": "534240",
    "end": "537440"
  },
  {
    "text": "meaning small quantities but we do also",
    "start": "537440",
    "end": "540720"
  },
  {
    "text": "see",
    "start": "540720",
    "end": "541440"
  },
  {
    "text": "very large negative and large positive",
    "start": "541440",
    "end": "543680"
  },
  {
    "text": "quantities as well",
    "start": "543680",
    "end": "546640"
  },
  {
    "text": "these negative quantities might not make",
    "start": "546720",
    "end": "548880"
  },
  {
    "text": "intuitive sense",
    "start": "548880",
    "end": "550080"
  },
  {
    "text": "but it turns out that that's how",
    "start": "550080",
    "end": "551760"
  },
  {
    "text": "cancellations or returns are handled",
    "start": "551760",
    "end": "554399"
  },
  {
    "text": "in this case it looks like someone",
    "start": "554399",
    "end": "555760"
  },
  {
    "text": "placed a very large order",
    "start": "555760",
    "end": "557519"
  },
  {
    "text": "of 80 000 units",
    "start": "557519",
    "end": "561440"
  },
  {
    "text": "and then that was subsequently cancelled",
    "start": "561519",
    "end": "564160"
  },
  {
    "text": "by",
    "start": "564160",
    "end": "565279"
  },
  {
    "text": "the negative 80 000 negative quantity",
    "start": "565279",
    "end": "569519"
  },
  {
    "text": "this happens throughout the data set and",
    "start": "569519",
    "end": "571360"
  },
  {
    "text": "since quantity is our target we need to",
    "start": "571360",
    "end": "573360"
  },
  {
    "text": "make sure that it's relatively clean",
    "start": "573360",
    "end": "575279"
  },
  {
    "text": "and without these large positive and",
    "start": "575279",
    "end": "577040"
  },
  {
    "text": "negative amounts that cancel with each",
    "start": "577040",
    "end": "579200"
  },
  {
    "text": "other",
    "start": "579200",
    "end": "580880"
  },
  {
    "text": "to do that let's aggregate the data over",
    "start": "580880",
    "end": "583120"
  },
  {
    "text": "the year",
    "start": "583120",
    "end": "584160"
  },
  {
    "text": "and take the sum of the quantity",
    "start": "584160",
    "end": "586560"
  },
  {
    "text": "therefore any transactions that are",
    "start": "586560",
    "end": "588320"
  },
  {
    "text": "associated with a cancellation or a",
    "start": "588320",
    "end": "590160"
  },
  {
    "text": "refund will go away",
    "start": "590160",
    "end": "592320"
  },
  {
    "text": "we will also make sure that all final",
    "start": "592320",
    "end": "594000"
  },
  {
    "text": "quantities are greater than zero",
    "start": "594000",
    "end": "597519"
  },
  {
    "text": "now we still have some categorical",
    "start": "598480",
    "end": "600160"
  },
  {
    "text": "features and we will need to handle them",
    "start": "600160",
    "end": "602240"
  },
  {
    "text": "before",
    "start": "602240",
    "end": "603040"
  },
  {
    "text": "training a model handling these",
    "start": "603040",
    "end": "605279"
  },
  {
    "text": "categorical columns",
    "start": "605279",
    "end": "606640"
  },
  {
    "text": "will create many additional columns",
    "start": "606640",
    "end": "608399"
  },
  {
    "text": "resulting in sparse data",
    "start": "608399",
    "end": "610640"
  },
  {
    "text": "sparse matrices are our friend here",
    "start": "610640",
    "end": "612480"
  },
  {
    "text": "because they allow us to store",
    "start": "612480",
    "end": "614399"
  },
  {
    "text": "all the data without running into memory",
    "start": "614399",
    "end": "616839"
  },
  {
    "text": "errors since the description column is",
    "start": "616839",
    "end": "619360"
  },
  {
    "text": "text based",
    "start": "619360",
    "end": "620560"
  },
  {
    "text": "we can apply text featurization to it",
    "start": "620560",
    "end": "623760"
  },
  {
    "text": "the method that we will use is tf idf",
    "start": "623760",
    "end": "627519"
  },
  {
    "text": "which stands for term frequency inverse",
    "start": "627519",
    "end": "630480"
  },
  {
    "text": "document frequency",
    "start": "630480",
    "end": "632640"
  },
  {
    "text": "tf idf considers each term in the",
    "start": "632640",
    "end": "635040"
  },
  {
    "text": "descriptions",
    "start": "635040",
    "end": "636079"
  },
  {
    "text": "and measures how relevant that term is",
    "start": "636079",
    "end": "638079"
  },
  {
    "text": "to the description",
    "start": "638079",
    "end": "639519"
  },
  {
    "text": "compared to how relevant it is for all",
    "start": "639519",
    "end": "641360"
  },
  {
    "text": "descriptions",
    "start": "641360",
    "end": "642720"
  },
  {
    "text": "for example we can see",
    "start": "642720",
    "end": "646399"
  },
  {
    "text": "that there is a description for white",
    "start": "646399",
    "end": "649600"
  },
  {
    "text": "metal lantern",
    "start": "649600",
    "end": "652000"
  },
  {
    "text": "the output of our text featurization",
    "start": "652000",
    "end": "653839"
  },
  {
    "text": "will give us a column for each of those",
    "start": "653839",
    "end": "655360"
  },
  {
    "text": "three words",
    "start": "655360",
    "end": "657279"
  },
  {
    "text": "and the values we weighted based off how",
    "start": "657279",
    "end": "659200"
  },
  {
    "text": "frequent those words are in other",
    "start": "659200",
    "end": "660959"
  },
  {
    "text": "products",
    "start": "660959",
    "end": "663360"
  },
  {
    "text": "for the stock code customer id and",
    "start": "666800",
    "end": "669279"
  },
  {
    "text": "country",
    "start": "669279",
    "end": "670160"
  },
  {
    "text": "the values are distinct categories",
    "start": "670160",
    "end": "672399"
  },
  {
    "text": "therefore we will one hot encode those",
    "start": "672399",
    "end": "674880"
  },
  {
    "text": "as i mentioned before this will leave us",
    "start": "674880",
    "end": "677040"
  },
  {
    "text": "with very sparse data",
    "start": "677040",
    "end": "678560"
  },
  {
    "text": "since most users only buy a small subset",
    "start": "678560",
    "end": "681440"
  },
  {
    "text": "of all products",
    "start": "681440",
    "end": "683279"
  },
  {
    "text": "for other algorithms we might want to",
    "start": "683279",
    "end": "684959"
  },
  {
    "text": "choose a different approach for building",
    "start": "684959",
    "end": "686320"
  },
  {
    "text": "a data set",
    "start": "686320",
    "end": "687440"
  },
  {
    "text": "but for factorization machines it",
    "start": "687440",
    "end": "689360"
  },
  {
    "text": "handles sparse data very well",
    "start": "689360",
    "end": "691200"
  },
  {
    "text": "and is designed for users and products",
    "start": "691200",
    "end": "693120"
  },
  {
    "text": "to be one-hot encoded this way",
    "start": "693120",
    "end": "696480"
  },
  {
    "text": "in the end we are left with a sparse",
    "start": "700880",
    "end": "702480"
  },
  {
    "text": "matrix where the rows are each product",
    "start": "702480",
    "end": "704720"
  },
  {
    "text": "that a user bought",
    "start": "704720",
    "end": "705920"
  },
  {
    "text": "and our columns are all of our features",
    "start": "705920",
    "end": "708720"
  },
  {
    "text": "the stock codes the customer ids",
    "start": "708720",
    "end": "711120"
  },
  {
    "text": "country unit price as well as our target",
    "start": "711120",
    "end": "714320"
  },
  {
    "text": "which contains the quantity",
    "start": "714320",
    "end": "717760"
  },
  {
    "text": "you can see that our data is over 99.9",
    "start": "717760",
    "end": "720560"
  },
  {
    "text": "percent sparse",
    "start": "720560",
    "end": "722240"
  },
  {
    "text": "but like we mentioned factorization",
    "start": "722240",
    "end": "724480"
  },
  {
    "text": "machines",
    "start": "724480",
    "end": "726079"
  },
  {
    "text": "are designed to handle this kind of",
    "start": "726079",
    "end": "727519"
  },
  {
    "text": "sparse data and it will not cause any",
    "start": "727519",
    "end": "729680"
  },
  {
    "text": "issues",
    "start": "729680",
    "end": "731040"
  },
  {
    "text": "next we split our data into training and",
    "start": "731040",
    "end": "733120"
  },
  {
    "text": "testing sets",
    "start": "733120",
    "end": "735920"
  },
  {
    "text": "then we write the data to protobuf",
    "start": "736639",
    "end": "739200"
  },
  {
    "text": "record io format",
    "start": "739200",
    "end": "741120"
  },
  {
    "text": "because factorization machines take the",
    "start": "741120",
    "end": "743360"
  },
  {
    "text": "protobuf record io format",
    "start": "743360",
    "end": "745360"
  },
  {
    "text": "as an input",
    "start": "745360",
    "end": "748000"
  },
  {
    "text": "using this format allows you to take",
    "start": "753279",
    "end": "755200"
  },
  {
    "text": "advantage of pipe mode",
    "start": "755200",
    "end": "756880"
  },
  {
    "text": "in pipe mode your training data streams",
    "start": "756880",
    "end": "759600"
  },
  {
    "text": "data directly from s3",
    "start": "759600",
    "end": "761920"
  },
  {
    "text": "streaming data can provide faster start",
    "start": "761920",
    "end": "764800"
  },
  {
    "text": "times for training jobs and better",
    "start": "764800",
    "end": "766720"
  },
  {
    "text": "throughput",
    "start": "766720",
    "end": "768560"
  },
  {
    "text": "now our final data is stored in s3",
    "start": "768560",
    "end": "771680"
  },
  {
    "text": "and we are ready to move on to training",
    "start": "771680",
    "end": "775360"
  },
  {
    "text": "here we define our factorization machine",
    "start": "775519",
    "end": "778320"
  },
  {
    "text": "estimator",
    "start": "778320",
    "end": "780320"
  },
  {
    "text": "including parameters such as the",
    "start": "780320",
    "end": "782000"
  },
  {
    "text": "instance type",
    "start": "782000",
    "end": "784000"
  },
  {
    "text": "the instance count as well as the hyper",
    "start": "784000",
    "end": "786560"
  },
  {
    "text": "parameters to train the model",
    "start": "786560",
    "end": "788560"
  },
  {
    "text": "we can then fit the model passing in our",
    "start": "788560",
    "end": "791040"
  },
  {
    "text": "training and testing data",
    "start": "791040",
    "end": "793279"
  },
  {
    "text": "calling dot fit kicks off the training",
    "start": "793279",
    "end": "795360"
  },
  {
    "text": "job",
    "start": "795360",
    "end": "796320"
  },
  {
    "text": "this will take a few minutes to run and",
    "start": "796320",
    "end": "798160"
  },
  {
    "text": "we will pick back up once it's complete",
    "start": "798160",
    "end": "801120"
  },
  {
    "text": "once our model is trained we will want",
    "start": "801120",
    "end": "803440"
  },
  {
    "text": "to use sagemaker",
    "start": "803440",
    "end": "805600"
  },
  {
    "text": "ml lineage tracking to track different",
    "start": "805600",
    "end": "808079"
  },
  {
    "text": "artifacts about the model",
    "start": "808079",
    "end": "810160"
  },
  {
    "text": "an important aspect of transparency in",
    "start": "810160",
    "end": "812399"
  },
  {
    "text": "machine learning",
    "start": "812399",
    "end": "813600"
  },
  {
    "text": "is to be able to link a model with code",
    "start": "813600",
    "end": "815760"
  },
  {
    "text": "and data used to train it",
    "start": "815760",
    "end": "817360"
  },
  {
    "text": "so we can easily find how any given",
    "start": "817360",
    "end": "819279"
  },
  {
    "text": "model was produced",
    "start": "819279",
    "end": "820959"
  },
  {
    "text": "in the event that a model begins to",
    "start": "820959",
    "end": "822560"
  },
  {
    "text": "start performing poorly",
    "start": "822560",
    "end": "824399"
  },
  {
    "text": "we should be able to quickly find all",
    "start": "824399",
    "end": "826160"
  },
  {
    "text": "the artifacts used to create it",
    "start": "826160",
    "end": "828240"
  },
  {
    "text": "so we can debug the problem at the",
    "start": "828240",
    "end": "830000"
  },
  {
    "text": "source to do this we need to create an",
    "start": "830000",
    "end": "832560"
  },
  {
    "text": "artifact for every aspect of training we",
    "start": "832560",
    "end": "834639"
  },
  {
    "text": "like to save",
    "start": "834639",
    "end": "837199"
  },
  {
    "text": "first we will create an artifact",
    "start": "837519",
    "end": "839040"
  },
  {
    "text": "containing training data",
    "start": "839040",
    "end": "843680"
  },
  {
    "text": "then we will create an artifact",
    "start": "843680",
    "end": "845199"
  },
  {
    "text": "containing the model itself",
    "start": "845199",
    "end": "848880"
  },
  {
    "text": "we can then set the associations for",
    "start": "849760",
    "end": "852959"
  },
  {
    "text": "these artifacts",
    "start": "852959",
    "end": "857839"
  },
  {
    "text": "now for the sagemaker model registry",
    "start": "860639",
    "end": "863600"
  },
  {
    "text": "here we start to create",
    "start": "863600",
    "end": "865120"
  },
  {
    "text": "a model package group in order to store",
    "start": "865120",
    "end": "868000"
  },
  {
    "text": "the",
    "start": "868000",
    "end": "868320"
  },
  {
    "text": "model metadata including the artifacts",
    "start": "868320",
    "end": "870720"
  },
  {
    "text": "such as the data",
    "start": "870720",
    "end": "871920"
  },
  {
    "text": "and model parameters this allows you to",
    "start": "871920",
    "end": "874560"
  },
  {
    "text": "gain visibility and reproducibility",
    "start": "874560",
    "end": "876880"
  },
  {
    "text": "of the process by which we create the",
    "start": "876880",
    "end": "878560"
  },
  {
    "text": "models",
    "start": "878560",
    "end": "880480"
  },
  {
    "text": "we create model package groups that",
    "start": "880480",
    "end": "882320"
  },
  {
    "text": "contain different versions of the model",
    "start": "882320",
    "end": "885519"
  },
  {
    "text": "you can then register each model you",
    "start": "885519",
    "end": "887600"
  },
  {
    "text": "train and the model registry",
    "start": "887600",
    "end": "889519"
  },
  {
    "text": "adds it to the model group as a new",
    "start": "889519",
    "end": "891760"
  },
  {
    "text": "model version",
    "start": "891760",
    "end": "893199"
  },
  {
    "text": "so if you plan on tracking multiple",
    "start": "893199",
    "end": "894959"
  },
  {
    "text": "versions of a model",
    "start": "894959",
    "end": "896480"
  },
  {
    "text": "you need to create a model package group",
    "start": "896480",
    "end": "898560"
  },
  {
    "text": "first",
    "start": "898560",
    "end": "900959"
  },
  {
    "text": "once the model package group has been",
    "start": "903440",
    "end": "905360"
  },
  {
    "text": "created you can now add the first",
    "start": "905360",
    "end": "907279"
  },
  {
    "text": "version",
    "start": "907279",
    "end": "907920"
  },
  {
    "text": "of your trait model to it we will only",
    "start": "907920",
    "end": "910399"
  },
  {
    "text": "show one version of a model here",
    "start": "910399",
    "end": "912320"
  },
  {
    "text": "but in practice you may have different",
    "start": "912320",
    "end": "914720"
  },
  {
    "text": "versions as you try different features",
    "start": "914720",
    "end": "917199"
  },
  {
    "text": "different hyper parameters or even",
    "start": "917199",
    "end": "919360"
  },
  {
    "text": "update your model over time",
    "start": "919360",
    "end": "922399"
  },
  {
    "text": "along with the s3 location of the",
    "start": "922399",
    "end": "924000"
  },
  {
    "text": "trained model you need to add the",
    "start": "924000",
    "end": "925440"
  },
  {
    "text": "inference specification so we know",
    "start": "925440",
    "end": "927440"
  },
  {
    "text": "what docker image to use to deploy the",
    "start": "927440",
    "end": "929600"
  },
  {
    "text": "model and make the predictions",
    "start": "929600",
    "end": "931920"
  },
  {
    "text": "we can also use various training metrics",
    "start": "931920",
    "end": "934480"
  },
  {
    "text": "like",
    "start": "934480",
    "end": "934959"
  },
  {
    "text": "training and validation root mean",
    "start": "934959",
    "end": "937120"
  },
  {
    "text": "squared error",
    "start": "937120",
    "end": "939040"
  },
  {
    "text": "here we include every metric that is",
    "start": "939040",
    "end": "940800"
  },
  {
    "text": "associated with our training job",
    "start": "940800",
    "end": "944320"
  },
  {
    "text": "finally for model governance reasons we",
    "start": "950079",
    "end": "952560"
  },
  {
    "text": "can tag the model package",
    "start": "952560",
    "end": "954079"
  },
  {
    "text": "with a status so it's easy to tell which",
    "start": "954079",
    "end": "956320"
  },
  {
    "text": "models are actually approved",
    "start": "956320",
    "end": "958240"
  },
  {
    "text": "or declined for deployment into",
    "start": "958240",
    "end": "960160"
  },
  {
    "text": "production",
    "start": "960160",
    "end": "962000"
  },
  {
    "text": "here we tag this one with pending manual",
    "start": "962000",
    "end": "966800"
  },
  {
    "text": "approval",
    "start": "966839",
    "end": "969839"
  },
  {
    "text": "now that we've built our model we",
    "start": "974399",
    "end": "976639"
  },
  {
    "text": "probably want to get predictions back",
    "start": "976639",
    "end": "977839"
  },
  {
    "text": "from it",
    "start": "977839",
    "end": "979360"
  },
  {
    "text": "let's look at a single customer and try",
    "start": "979360",
    "end": "981279"
  },
  {
    "text": "to find which products to recommend",
    "start": "981279",
    "end": "984320"
  },
  {
    "text": "first we define a serializer which is",
    "start": "984320",
    "end": "987360"
  },
  {
    "text": "used to encode data",
    "start": "987360",
    "end": "988959"
  },
  {
    "text": "for an inference endpoint and a",
    "start": "988959",
    "end": "990800"
  },
  {
    "text": "deserializer",
    "start": "990800",
    "end": "992000"
  },
  {
    "text": "which decodes data from an inference",
    "start": "992000",
    "end": "993920"
  },
  {
    "text": "endpoint next we will make",
    "start": "993920",
    "end": "995839"
  },
  {
    "text": "inference for this customer and any",
    "start": "995839",
    "end": "998000"
  },
  {
    "text": "items in our catalog",
    "start": "998000",
    "end": "999440"
  },
  {
    "text": "and then we can recommend whichever",
    "start": "999440",
    "end": "1000800"
  },
  {
    "text": "products return the highest values",
    "start": "1000800",
    "end": "1004399"
  },
  {
    "text": "next we'll find the top customer who's",
    "start": "1004399",
    "end": "1006399"
  },
  {
    "text": "the customer who spent the most money",
    "start": "1006399",
    "end": "1008079"
  },
  {
    "text": "over the entirety of the data set",
    "start": "1008079",
    "end": "1011440"
  },
  {
    "text": "we will then try to make inference for",
    "start": "1011440",
    "end": "1012959"
  },
  {
    "text": "this customer and any items",
    "start": "1012959",
    "end": "1015040"
  },
  {
    "text": "in our catalog and then we'll recommend",
    "start": "1015040",
    "end": "1017440"
  },
  {
    "text": "whichever products return the highest",
    "start": "1017440",
    "end": "1019040"
  },
  {
    "text": "values",
    "start": "1019040",
    "end": "1020000"
  },
  {
    "text": "here i'll search through the top 100",
    "start": "1020000",
    "end": "1022320"
  },
  {
    "text": "most popular items to figure out which",
    "start": "1022320",
    "end": "1024079"
  },
  {
    "text": "to recommend",
    "start": "1024079",
    "end": "1024798"
  },
  {
    "text": "but alternatively you could search",
    "start": "1024799",
    "end": "1026400"
  },
  {
    "text": "through all products in the catalog",
    "start": "1026400",
    "end": "1028400"
  },
  {
    "text": "we then need to perform the same",
    "start": "1028400",
    "end": "1029760"
  },
  {
    "text": "transformations to the sparse vector as",
    "start": "1029760",
    "end": "1031839"
  },
  {
    "text": "we did before",
    "start": "1031839",
    "end": "1034558"
  },
  {
    "text": "we then will call dot predict",
    "start": "1035679",
    "end": "1039678"
  },
  {
    "text": "to get our predictions back from the",
    "start": "1039679",
    "end": "1041360"
  },
  {
    "text": "model",
    "start": "1041360",
    "end": "1042798"
  },
  {
    "text": "then by parsing and sorting the results",
    "start": "1042799",
    "end": "1045520"
  },
  {
    "text": "we can figure out the top products to",
    "start": "1045520",
    "end": "1047120"
  },
  {
    "text": "recommend",
    "start": "1047120",
    "end": "1049520"
  },
  {
    "text": "here i will look at the top five",
    "start": "1050880",
    "end": "1052400"
  },
  {
    "text": "products for this customer",
    "start": "1052400",
    "end": "1055520"
  },
  {
    "text": "and we can see the top recommended",
    "start": "1055520",
    "end": "1057440"
  },
  {
    "text": "product is regency cake stand three tier",
    "start": "1057440",
    "end": "1062000"
  },
  {
    "text": "in our final step we will take each of",
    "start": "1063520",
    "end": "1065520"
  },
  {
    "text": "the steps shown before",
    "start": "1065520",
    "end": "1067120"
  },
  {
    "text": "and work them into an automated workflow",
    "start": "1067120",
    "end": "1069360"
  },
  {
    "text": "using amazon sagemaker pipelines",
    "start": "1069360",
    "end": "1072720"
  },
  {
    "text": "model training is not a one and done",
    "start": "1072720",
    "end": "1074640"
  },
  {
    "text": "task",
    "start": "1074640",
    "end": "1075760"
  },
  {
    "text": "you will want to improve your model with",
    "start": "1075760",
    "end": "1077520"
  },
  {
    "text": "new data",
    "start": "1077520",
    "end": "1079039"
  },
  {
    "text": "as well as changes in customer purchase",
    "start": "1079039",
    "end": "1080960"
  },
  {
    "text": "behavior over time",
    "start": "1080960",
    "end": "1082960"
  },
  {
    "text": "improving models takes thousands of",
    "start": "1082960",
    "end": "1084960"
  },
  {
    "text": "repetitions of all the steps we just",
    "start": "1084960",
    "end": "1086960"
  },
  {
    "text": "went through",
    "start": "1086960",
    "end": "1088160"
  },
  {
    "text": "having these steps automated using",
    "start": "1088160",
    "end": "1089840"
  },
  {
    "text": "pipelines allows us to replay the whole",
    "start": "1089840",
    "end": "1092080"
  },
  {
    "text": "workflow with a single clip",
    "start": "1092080",
    "end": "1094080"
  },
  {
    "text": "and save hours of manual work",
    "start": "1094080",
    "end": "1097280"
  },
  {
    "text": "first let's upload our raw data to s3",
    "start": "1097280",
    "end": "1101919"
  },
  {
    "text": "we will then set a model approval status",
    "start": "1101919",
    "end": "1105039"
  },
  {
    "text": "of approved meaning this model is",
    "start": "1105039",
    "end": "1107360"
  },
  {
    "text": "approved for production",
    "start": "1107360",
    "end": "1109600"
  },
  {
    "text": "in practice you might want to set this",
    "start": "1109600",
    "end": "1111280"
  },
  {
    "text": "to pending manual approval",
    "start": "1111280",
    "end": "1114000"
  },
  {
    "text": "so that someone needs to go in and",
    "start": "1114000",
    "end": "1116000"
  },
  {
    "text": "manually approve the model for",
    "start": "1116000",
    "end": "1117440"
  },
  {
    "text": "production later",
    "start": "1117440",
    "end": "1122160"
  },
  {
    "text": "next we define a custom step for",
    "start": "1122160",
    "end": "1125120"
  },
  {
    "text": "pre-processing our data",
    "start": "1125120",
    "end": "1127520"
  },
  {
    "text": "our preprocessing.py file",
    "start": "1127520",
    "end": "1130559"
  },
  {
    "text": "has all the transformations that we",
    "start": "1130559",
    "end": "1132000"
  },
  {
    "text": "performed above including splitting the",
    "start": "1132000",
    "end": "1134320"
  },
  {
    "text": "data into training and testing sets and",
    "start": "1134320",
    "end": "1136480"
  },
  {
    "text": "saving them to protobuf formats",
    "start": "1136480",
    "end": "1138960"
  },
  {
    "text": "we specify the outputs to contain both",
    "start": "1138960",
    "end": "1141280"
  },
  {
    "text": "the training data",
    "start": "1141280",
    "end": "1143280"
  },
  {
    "text": "and the testing data so we can use them",
    "start": "1143280",
    "end": "1146160"
  },
  {
    "text": "in subsequent steps",
    "start": "1146160",
    "end": "1151840"
  },
  {
    "text": "sagemaker comes with a pre-made training",
    "start": "1152640",
    "end": "1155679"
  },
  {
    "text": "step in the sagemaker",
    "start": "1155679",
    "end": "1157200"
  },
  {
    "text": "sdk which abstracts away most of the",
    "start": "1157200",
    "end": "1160160"
  },
  {
    "text": "generic processor code",
    "start": "1160160",
    "end": "1162880"
  },
  {
    "text": "all we need to give this step is the",
    "start": "1162880",
    "end": "1165280"
  },
  {
    "text": "estimator",
    "start": "1165280",
    "end": "1167679"
  },
  {
    "text": "and an input which in this case",
    "start": "1167679",
    "end": "1171039"
  },
  {
    "text": "is the training and testing data",
    "start": "1171039",
    "end": "1175840"
  },
  {
    "text": "these are the same training and testing",
    "start": "1177039",
    "end": "1179280"
  },
  {
    "text": "data that we defined above",
    "start": "1179280",
    "end": "1182080"
  },
  {
    "text": "by defining the inputs to this step",
    "start": "1182080",
    "end": "1185360"
  },
  {
    "text": "as the outputs of the previous step it",
    "start": "1185360",
    "end": "1188160"
  },
  {
    "text": "informs sagemaker that this step has a",
    "start": "1188160",
    "end": "1190080"
  },
  {
    "text": "dependency",
    "start": "1190080",
    "end": "1191200"
  },
  {
    "text": "on the previous step and cannot be",
    "start": "1191200",
    "end": "1192960"
  },
  {
    "text": "executed until the previous step has",
    "start": "1192960",
    "end": "1194960"
  },
  {
    "text": "finished",
    "start": "1194960",
    "end": "1197360"
  },
  {
    "text": "similarly the sagemaker sdk has another",
    "start": "1202400",
    "end": "1205440"
  },
  {
    "text": "convenience step",
    "start": "1205440",
    "end": "1206640"
  },
  {
    "text": "called the create model step",
    "start": "1206640",
    "end": "1210080"
  },
  {
    "text": "the create model step takes an image uri",
    "start": "1210240",
    "end": "1214960"
  },
  {
    "text": "and the model data input from the",
    "start": "1214960",
    "end": "1216880"
  },
  {
    "text": "previous training step",
    "start": "1216880",
    "end": "1219039"
  },
  {
    "text": "this step creates a model for use in",
    "start": "1219039",
    "end": "1221760"
  },
  {
    "text": "transform steps",
    "start": "1221760",
    "end": "1223039"
  },
  {
    "text": "or later publication as an endpoint",
    "start": "1223039",
    "end": "1227360"
  },
  {
    "text": "next we define a register model step",
    "start": "1230799",
    "end": "1234120"
  },
  {
    "text": "[Music]",
    "start": "1234120",
    "end": "1235760"
  },
  {
    "text": "the register model step creates a model",
    "start": "1235760",
    "end": "1238480"
  },
  {
    "text": "package resource in the model registry",
    "start": "1238480",
    "end": "1240640"
  },
  {
    "text": "that can be used to create deployable",
    "start": "1240640",
    "end": "1242480"
  },
  {
    "text": "models in amazon's seatmaker",
    "start": "1242480",
    "end": "1248480"
  },
  {
    "text": "our final step is for deploying the",
    "start": "1248480",
    "end": "1251280"
  },
  {
    "text": "model",
    "start": "1251280",
    "end": "1253360"
  },
  {
    "text": "there is no pre-made step for model",
    "start": "1253360",
    "end": "1255120"
  },
  {
    "text": "deployment so instead we'll",
    "start": "1255120",
    "end": "1257520"
  },
  {
    "text": "create a processing step where the",
    "start": "1257520",
    "end": "1259840"
  },
  {
    "text": "deployment happens inside that",
    "start": "1259840",
    "end": "1261280"
  },
  {
    "text": "processing step",
    "start": "1261280",
    "end": "1264080"
  },
  {
    "text": "once all the steps have been defined we",
    "start": "1266880",
    "end": "1269280"
  },
  {
    "text": "add them to the pipeline class",
    "start": "1269280",
    "end": "1273039"
  },
  {
    "text": "in the sdk along with the processing",
    "start": "1273360",
    "end": "1275440"
  },
  {
    "text": "input variables that we created at the",
    "start": "1275440",
    "end": "1277200"
  },
  {
    "text": "outset of our pipeline",
    "start": "1277200",
    "end": "1280399"
  },
  {
    "text": "upsetting the pipeline registers the",
    "start": "1282880",
    "end": "1285039"
  },
  {
    "text": "pipeline with sagemaker",
    "start": "1285039",
    "end": "1288559"
  },
  {
    "text": "and then calling the start method",
    "start": "1288799",
    "end": "1292159"
  },
  {
    "text": "we'll kick it off once the pipeline is",
    "start": "1292159",
    "end": "1295760"
  },
  {
    "text": "kicked off",
    "start": "1295760",
    "end": "1297039"
  },
  {
    "text": "we can view the pipeline in the sidebar",
    "start": "1297039",
    "end": "1299120"
  },
  {
    "text": "and track its status there",
    "start": "1299120",
    "end": "1301200"
  },
  {
    "text": "in the sidebar we click sagemaker",
    "start": "1301200",
    "end": "1303039"
  },
  {
    "text": "components and registries",
    "start": "1303039",
    "end": "1306320"
  },
  {
    "text": "we can then go to our pipelines",
    "start": "1307440",
    "end": "1312960"
  },
  {
    "text": "and view the status of the pipeline that",
    "start": "1316159",
    "end": "1318080"
  },
  {
    "text": "we just created",
    "start": "1318080",
    "end": "1319280"
  },
  {
    "text": "as well as clicking into it which will",
    "start": "1319280",
    "end": "1321440"
  },
  {
    "text": "give us the",
    "start": "1321440",
    "end": "1322960"
  },
  {
    "text": "directed flow of all the steps that we",
    "start": "1322960",
    "end": "1325039"
  },
  {
    "text": "just created",
    "start": "1325039",
    "end": "1326880"
  },
  {
    "text": "well there you have it in this demo we",
    "start": "1326880",
    "end": "1328960"
  },
  {
    "text": "showed you how to integrate",
    "start": "1328960",
    "end": "1330080"
  },
  {
    "text": "various sagemaker features including a",
    "start": "1330080",
    "end": "1332559"
  },
  {
    "text": "sagemaker",
    "start": "1332559",
    "end": "1333360"
  },
  {
    "text": "built-in algorithm the factorization",
    "start": "1333360",
    "end": "1335679"
  },
  {
    "text": "machines",
    "start": "1335679",
    "end": "1336400"
  },
  {
    "text": "model training model lineage model",
    "start": "1336400",
    "end": "1339200"
  },
  {
    "text": "registry",
    "start": "1339200",
    "end": "1340480"
  },
  {
    "text": "deployment and pipelines we build a",
    "start": "1340480",
    "end": "1343520"
  },
  {
    "text": "recommendation engine for e-commerce",
    "start": "1343520",
    "end": "1345360"
  },
  {
    "text": "data",
    "start": "1345360",
    "end": "1346320"
  },
  {
    "text": "which can make it easier to create",
    "start": "1346320",
    "end": "1347679"
  },
  {
    "text": "personalized recommendations for your",
    "start": "1347679",
    "end": "1349280"
  },
  {
    "text": "customers",
    "start": "1349280",
    "end": "1350159"
  },
  {
    "text": "and enhance the customer experience",
    "start": "1350159",
    "end": "1352640"
  },
  {
    "text": "happy building",
    "start": "1352640",
    "end": "1360960"
  }
]
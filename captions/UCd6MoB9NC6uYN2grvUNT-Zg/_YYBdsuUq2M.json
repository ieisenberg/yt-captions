[
  {
    "text": "hello everybody my name is Michael Abbi I'm a specialist Solutions Architect here AWS I'm super super excited to be",
    "start": "30",
    "end": "6690"
  },
  {
    "text": "speaking with you about Amazon ElastiCache for for Redis so we recently",
    "start": "6690",
    "end": "12420"
  },
  {
    "text": "released a lot of really awesome features that we're gonna go through in today's talk and just the level set",
    "start": "12420",
    "end": "18990"
  },
  {
    "text": "we're gonna start off you know kind of getting everybody on the same page with what Amazon ElastiCache is then we're",
    "start": "18990",
    "end": "25560"
  },
  {
    "text": "gonna we're gonna dive in so how do you scale your Amazon ElastiCache cluster with online regarding then we'll review",
    "start": "25560",
    "end": "32369"
  },
  {
    "text": "you know our security footprint with respect to you know how do you set up that topology and and networking and all",
    "start": "32369",
    "end": "38940"
  },
  {
    "text": "those infrastructure associated with your cluster as well as encryption which is a new feature that we just recently",
    "start": "38940",
    "end": "44610"
  },
  {
    "text": "announced and then we'll take a look at some common usage patterns that a lot of",
    "start": "44610",
    "end": "49800"
  },
  {
    "text": "our customers are using today and it will close off with best practices so",
    "start": "49800",
    "end": "56430"
  },
  {
    "text": "year after year we're hearing increasingly from our customers that's Need for Speed and this is really coming",
    "start": "56430",
    "end": "63449"
  },
  {
    "text": "from virtually every workload and every vertical that you can imagine so what",
    "start": "63449",
    "end": "68850"
  },
  {
    "text": "customers are essentially asking for is they in their data platform they want a",
    "start": "68850",
    "end": "74310"
  },
  {
    "text": "fast data layer right and this is this need has has developed to the point",
    "start": "74310",
    "end": "80880"
  },
  {
    "text": "where we're no longer measuring performance in milliseconds this is a microsecond sub-millisecond gauge so",
    "start": "80880",
    "end": "89130"
  },
  {
    "text": "this is really where Amazon ElastiCache fits in Amazon ElastiCache is an in-memory key value store we support the",
    "start": "89130",
    "end": "95430"
  },
  {
    "text": "two most popular key value store engines Redis and memcache T it's fully managed",
    "start": "95430",
    "end": "101100"
  },
  {
    "text": "Xero administration no racking stacking failover that you have to worry about and it's hardened by Amazon and what",
    "start": "101100",
    "end": "108299"
  },
  {
    "text": "does that mean what it means is we have some engineers who are involved with the open source reddit's product and they're",
    "start": "108299",
    "end": "115560"
  },
  {
    "text": "you know they are constantly looking at the engine and the features and we",
    "start": "115560",
    "end": "120659"
  },
  {
    "text": "evaluate what our customers are asking us for and we enhance those areas that",
    "start": "120659",
    "end": "125969"
  },
  {
    "text": "we feel better serve our customers so if you were to take a second to think",
    "start": "125969",
    "end": "132220"
  },
  {
    "text": "about your data from a temperature gauge the hot data would be that data that you access most frequently and if you",
    "start": "132220",
    "end": "140050"
  },
  {
    "text": "thought about the the characteristics of that hot data what you would want it to be is the ability to support incredibly",
    "start": "140050",
    "end": "147220"
  },
  {
    "text": "high request rates very very low latency and that's basically where Amazon",
    "start": "147220",
    "end": "152980"
  },
  {
    "text": "ElastiCache fits and as data volume grows and sort of the the data starts",
    "start": "152980",
    "end": "158170"
  },
  {
    "text": "getting warmer and colder you'll see SSDs and you'll see other data stores",
    "start": "158170",
    "end": "163480"
  },
  {
    "text": "sort of fit in now this is not a you know a bit or an or operation so if you're building a data platform",
    "start": "163480",
    "end": "169660"
  },
  {
    "text": "essentially what you want to do is you want to think about your data access patterns and you want to utilize the",
    "start": "169660",
    "end": "175599"
  },
  {
    "text": "different data stores and databases that make sense for that specific data data access so Redis quick overview just a",
    "start": "175599",
    "end": "187599"
  },
  {
    "text": "level set make sure everybody here is on the same page Redis today is the most popular key value store in the market",
    "start": "187599",
    "end": "194560"
  },
  {
    "text": "and the reason it is is because it has a variety of different features it's a Swiss Army knife of key value source it",
    "start": "194560",
    "end": "202569"
  },
  {
    "text": "has a variety of different data structures so if you're a developer a lot of these are you know are you know",
    "start": "202569",
    "end": "208630"
  },
  {
    "text": "they ring a bell to you hashmaps list sorted set sets and it's very intuitive",
    "start": "208630",
    "end": "214359"
  },
  {
    "text": "with respect to how do you use Redis in fact I'd like to think of the API is you",
    "start": "214359",
    "end": "220630"
  },
  {
    "text": "know sort of genius because it's very rich in capability but syntactically it's very predictable and very easy to",
    "start": "220630",
    "end": "227799"
  },
  {
    "text": "use other things that make rhetta's very interesting is that it's a support h8 so",
    "start": "227799",
    "end": "234880"
  },
  {
    "text": "you can have a master or a primary or multiple primaries in a clustered",
    "start": "234880",
    "end": "240250"
  },
  {
    "text": "environment and you can failover in the event of a failed scenario and what is",
    "start": "240250",
    "end": "246639"
  },
  {
    "text": "that support it gives you that added HEA that you need for those critical workloads and those those those",
    "start": "246639",
    "end": "253540"
  },
  {
    "text": "solutions and infrastructures that you care most about other things that's great about a Redis",
    "start": "253540",
    "end": "260049"
  },
  {
    "text": "it's open-source and Amazon ElastiCache fully supports the open-source version",
    "start": "260049",
    "end": "265250"
  },
  {
    "text": "so from a syntactical standpoint from a protocol say a protocol standpoint is a you know it's a drop-in replacement and",
    "start": "265250",
    "end": "272750"
  },
  {
    "text": "another cool feature is it has transaction support so you can can have a multi execute various different",
    "start": "272750",
    "end": "279889"
  },
  {
    "text": "commands in a in a transaction block which simulates that transactions and",
    "start": "279889",
    "end": "286430"
  },
  {
    "text": "just like the commercials there's always more right so other things that Redis has it has Lua scripts so you can bake",
    "start": "286430",
    "end": "292729"
  },
  {
    "text": "in business logic that you can call and reference within your Redis cluster there's geospatial capabilities so",
    "start": "292729",
    "end": "301039"
  },
  {
    "text": "geospatial sports a special assorted set that supports longitude and latitude",
    "start": "301039",
    "end": "307160"
  },
  {
    "text": "this is great for mobile applications where maybe you're passing you know location-based information to the cloud",
    "start": "307160",
    "end": "314960"
  },
  {
    "text": "and to Redis and you're looking for points of interest that you want to serve to your end users",
    "start": "314960",
    "end": "320320"
  },
  {
    "text": "there's pub/sub capabilities so this allows you to build chat applications and notification systems and it's just",
    "start": "320320",
    "end": "327860"
  },
  {
    "text": "built into Redis so there's nothing that you need to turn on there's no additional cost it's just there now in",
    "start": "327860",
    "end": "335030"
  },
  {
    "text": "terms of ElastiCache features ElastiCache offers a variety of different ways that you can deploy and",
    "start": "335030",
    "end": "341780"
  },
  {
    "text": "monitor your Redis cluster now a lot of these are familiar to you because we support these and other services as well",
    "start": "341780",
    "end": "347750"
  },
  {
    "text": "so AWS CloudFormation template engine where you can run JSON yamo scripts and",
    "start": "347750",
    "end": "354169"
  },
  {
    "text": "this is great for if the structure is code so you can build you know what you would want your application and Redis",
    "start": "354169",
    "end": "359990"
  },
  {
    "text": "cluster to look like how many shards what no types all those sort of details with respect to your cluster you can",
    "start": "359990",
    "end": "367520"
  },
  {
    "text": "version eyes that template and it build it whenever you need to I use this all the time when I want to do benchmarking",
    "start": "367520",
    "end": "373280"
  },
  {
    "text": "or performance testing and it once I'm done I sort of turned out or collapsed",
    "start": "373280",
    "end": "378800"
  },
  {
    "text": "that that stack other capabilities of CLI SDK so all the operations associated",
    "start": "378800",
    "end": "386000"
  },
  {
    "text": "to ElastiCache you have full control on using CLI and SDK the SDK you'll use in your",
    "start": "386000",
    "end": "392340"
  },
  {
    "text": "your applications may be in lambda functions and in CLI you'll have you",
    "start": "392340",
    "end": "397920"
  },
  {
    "text": "know through the AWS CLI tool and and if you don't like a lot of excitement in",
    "start": "397920",
    "end": "403440"
  },
  {
    "text": "your life there's always the console right so a couple clicks and you can build a lettuce cluster that way as well",
    "start": "403440",
    "end": "410060"
  },
  {
    "text": "from a monitoring perspective there's cloud trail AWS cloud trail and so this",
    "start": "410060",
    "end": "415080"
  },
  {
    "text": "gives you all the the the the log essentially of every interaction to the",
    "start": "415080",
    "end": "421140"
  },
  {
    "text": "service you know when it happened who did it that sort of thing maybe OS config which is great to build",
    "start": "421140",
    "end": "426990"
  },
  {
    "text": "compliance how you want that cluster to look like Amazon Cloud watch which I",
    "start": "426990",
    "end": "432030"
  },
  {
    "text": "think pairs very nicely with Redis and so what's cool about cloud watch is in addition to us you know funneling up all",
    "start": "432030",
    "end": "438720"
  },
  {
    "text": "the Redis info data through cloud watch you also can be very proactive with",
    "start": "438720",
    "end": "444840"
  },
  {
    "text": "respect to this and how do you be proactive is issue an alarm you know set a metric that makes sense to you",
    "start": "444840",
    "end": "450990"
  },
  {
    "text": "issue an alarm consume that alarm through an SMS notification and then do something interesting right maybe have",
    "start": "450990",
    "end": "457500"
  },
  {
    "text": "an operation on your cluster I'm going to have an interesting an example about",
    "start": "457500",
    "end": "463200"
  },
  {
    "text": "this later in this presentation we'll talk elite we'll revisit that that architecture other things that we've",
    "start": "463200",
    "end": "472440"
  },
  {
    "text": "done so I mentioned earlier that you know it's a fully open source compatible our engineers are are very you know",
    "start": "472440",
    "end": "480630"
  },
  {
    "text": "involved with the open source project but we also have some enhancements that we've built into ElastiCache I'll review",
    "start": "480630",
    "end": "487979"
  },
  {
    "text": "some of these so the first one is a background save operation so optimize",
    "start": "487979",
    "end": "494430"
  },
  {
    "text": "swap memory so with rhetta's especially if you have a lot of writes happening to",
    "start": "494430",
    "end": "500340"
  },
  {
    "text": "your primary if you were to do a say a snapshot what happens is you have the",
    "start": "500340",
    "end": "506330"
  },
  {
    "text": "possibility of doubling your memory footprint alright this is this is true",
    "start": "506330",
    "end": "511470"
  },
  {
    "text": "for open source Redis and so what that means is if you wanted to be safe and conservative you would want to reserve",
    "start": "511470",
    "end": "518180"
  },
  {
    "text": "50% memory just for those background operations so we took a look at that and we thought",
    "start": "518180",
    "end": "524610"
  },
  {
    "text": "we could do better right so what we wanted to do is we wanted to give our customers the ability to use more memory",
    "start": "524610",
    "end": "531020"
  },
  {
    "text": "without you know putting them in a situation where it would you know sort",
    "start": "531020",
    "end": "536640"
  },
  {
    "text": "of create a possible problem right so what we did is we we we change the",
    "start": "536640",
    "end": "543780"
  },
  {
    "text": "algorithm with respect to how much memory you have available in your cluster and if we detect you have less",
    "start": "543780",
    "end": "549870"
  },
  {
    "text": "memory to do that fork based operation will do a fork listen which is",
    "start": "549870",
    "end": "555570"
  },
  {
    "text": "essentially a timer task job that will you know do this background snapshot in",
    "start": "555570",
    "end": "561420"
  },
  {
    "text": "a more efficient way the second feature that we did with with open source Redis",
    "start": "561420",
    "end": "567570"
  },
  {
    "text": "if you're experiencing a lot of writes to your primary and your primary se is",
    "start": "567570",
    "end": "572820"
  },
  {
    "text": "under a lot of pressure maybe memories very low there's the possibility that your replicas might fall out of sync and",
    "start": "572820",
    "end": "579810"
  },
  {
    "text": "that's not that's not a good scenario so what we did here is to protect your",
    "start": "579810",
    "end": "585000"
  },
  {
    "text": "primary to against failures and also to reduce the possibility that your",
    "start": "585000",
    "end": "590970"
  },
  {
    "text": "replicas are you know out of sync will throttle some of those rights they'll",
    "start": "590970",
    "end": "596100"
  },
  {
    "text": "still execute successfully we'll just slow them down just to make sure everything here is consistent and again",
    "start": "596100",
    "end": "601650"
  },
  {
    "text": "this is only an innocent in a scenario where you're you're doomed for failure so we're sort of mitigating that",
    "start": "601650",
    "end": "606930"
  },
  {
    "text": "possibility and then the the other one which we actually contributed it to open",
    "start": "606930",
    "end": "612540"
  },
  {
    "text": "source it's in Redis for today is is is",
    "start": "612540",
    "end": "618450"
  },
  {
    "text": "referred to as piecing to in the open source Redis and essentially what it is",
    "start": "618450",
    "end": "623610"
  },
  {
    "text": "is assume you have a primary in multiple replicas if that primary fails an",
    "start": "623610",
    "end": "631320"
  },
  {
    "text": "election takes place where one of your replicas becomes a new primary with open",
    "start": "631320",
    "end": "636510"
  },
  {
    "text": "source right as prior to run as for all the other replicas essentially all the",
    "start": "636510",
    "end": "641760"
  },
  {
    "text": "data gets flushed and then they have to resync the entire rehydrate all the data",
    "start": "641760",
    "end": "646860"
  },
  {
    "text": "from the newly-elected primary so what we wanted to do is make that whole failover process more effective more",
    "start": "646860",
    "end": "653310"
  },
  {
    "text": "efficient and we rewrote that in an earlier version of ElastiCache and we we",
    "start": "653310",
    "end": "659039"
  },
  {
    "text": "contributed a lots of that to the open source so some of our engineers you know",
    "start": "659039",
    "end": "665579"
  },
  {
    "text": "there's a you know as I mentioned earlier there has been bugs there's been various things that we've done ever",
    "start": "665579",
    "end": "670619"
  },
  {
    "text": "since - point 8 and I wouldn't I wouldn't imagine this trend to change so we're we support the open source project",
    "start": "670619",
    "end": "676769"
  },
  {
    "text": "this is a trend that we're going to continue obviously to support now Redis",
    "start": "676769",
    "end": "682709"
  },
  {
    "text": "comes in two different flavors there's two differents apologies the first one is a vertically scaled environment and",
    "start": "682709",
    "end": "689489"
  },
  {
    "text": "what that means is you have one primary all your your entire key space which is",
    "start": "689489",
    "end": "694499"
  },
  {
    "text": "the the 16384 a hash slots they live in",
    "start": "694499",
    "end": "699749"
  },
  {
    "text": "that one key space and so what this means is all your data can fit to the",
    "start": "699749",
    "end": "706529"
  },
  {
    "text": "largest size of that node and in this case would be a an r4 16 XL which is",
    "start": "706529",
    "end": "713369"
  },
  {
    "text": "four hundred and seven gigabytes and your replicas have the entire copy of",
    "start": "713369",
    "end": "718709"
  },
  {
    "text": "all the data right what what we would provide you is a primary endpoint your",
    "start": "718709",
    "end": "725039"
  },
  {
    "text": "applications would point to that primary endpoint you'd also have the replica",
    "start": "725039",
    "end": "730289"
  },
  {
    "text": "head points and if there was a failover what would happen is we would take that primary endpoint and we propagate that",
    "start": "730289",
    "end": "736949"
  },
  {
    "text": "on one of the replicas so we do the DNS swap for you nothing has changed with",
    "start": "736949",
    "end": "744569"
  },
  {
    "text": "that s-- apology we still support it but custom mode enabled there's a lot of new things so we're gonna focus in this talk",
    "start": "744569",
    "end": "751259"
  },
  {
    "text": "on custom mode enabled so the custom mode enabled what we're doing here is it's basically a horizontally scaled",
    "start": "751259",
    "end": "758699"
  },
  {
    "text": "environment so you have up to 15 shards a shard is made up of a primary and 0 to",
    "start": "758699",
    "end": "765209"
  },
  {
    "text": "5 replicas and each one of these shards essentially you know owns a portion of",
    "start": "765209",
    "end": "772439"
  },
  {
    "text": "that key space right so it's a hash slot range and a default distribution would",
    "start": "772439",
    "end": "777989"
  },
  {
    "text": "be to divide the the hash slots across the number of shards that you have",
    "start": "777989",
    "end": "784460"
  },
  {
    "text": "so that essentially is the difference the other thing with a cluster mode enable is we give you a configuration",
    "start": "784460",
    "end": "790200"
  },
  {
    "text": "endpoint and in your Redis cluster a where client the way it works is it",
    "start": "790200",
    "end": "795810"
  },
  {
    "text": "would communicate to through that Connect configuration endpoint it would get a map of all that's apology in the",
    "start": "795810",
    "end": "802290"
  },
  {
    "text": "nodes associated to your cluster and I'll know exactly which node and which shard to target for a specific key on a",
    "start": "802290",
    "end": "810330"
  },
  {
    "text": "get set like operation now there is",
    "start": "810330",
    "end": "815460"
  },
  {
    "text": "other differences so we'll sort of kind of recap a few other things between cluster mode enabled and disabled if I'm",
    "start": "815460",
    "end": "822600"
  },
  {
    "text": "a failover standpoint because there's no DNS involved cluster mode enabled is",
    "start": "822600",
    "end": "827670"
  },
  {
    "text": "much faster so if you care about failover speed enabled makes a lot of",
    "start": "827670",
    "end": "834690"
  },
  {
    "text": "sense right because a failover may take somewhere in the neighborhood of 15 with",
    "start": "834690",
    "end": "840270"
  },
  {
    "text": "the worst case scenario 30 seconds and remember this is on a an individual",
    "start": "840270",
    "end": "846530"
  },
  {
    "text": "shard so imagine you have you know three shards and you had a failure on one of",
    "start": "846530",
    "end": "852600"
  },
  {
    "text": "them only 33.3% of your data is affected and if you wanted to reduce that blast",
    "start": "852600",
    "end": "859260"
  },
  {
    "text": "radius even further I'm all you would just do is add additional shards so the",
    "start": "859260",
    "end": "865140"
  },
  {
    "text": "failure risk is also a better option for you if you wanted to lower the impact of",
    "start": "865140",
    "end": "870720"
  },
  {
    "text": "failures using rhetta's you would go with the the enabled version the other difference here is",
    "start": "870720",
    "end": "877800"
  },
  {
    "text": "with respect to performance because you have the ability to have many shards you",
    "start": "877800",
    "end": "883020"
  },
  {
    "text": "have the ability to write too many primaries at the same time because again a shard has consists of a primary and",
    "start": "883020",
    "end": "890370"
  },
  {
    "text": "its associated replicas so from a writing and from a reading perspective",
    "start": "890370",
    "end": "895650"
  },
  {
    "text": "you have more nodes to interact with so it's performance is going to be greater",
    "start": "895650",
    "end": "900770"
  },
  {
    "text": "the obvious difference here would also be storage so because you have more",
    "start": "900770",
    "end": "906090"
  },
  {
    "text": "nodes and your data is spread across many primaries you can have 6 plus",
    "start": "906090",
    "end": "911160"
  },
  {
    "text": "terabytes worth of data in a cluster mode enabled topology so that's mad right more connections the one trade-off",
    "start": "911160",
    "end": "920810"
  },
  {
    "text": "here is cost so the cost may be more expects more expensive because you have",
    "start": "920810",
    "end": "926509"
  },
  {
    "text": "more nodes however when you when you are architecting using cluster mode enabled your you're selecting smaller sized",
    "start": "926509",
    "end": "932449"
  },
  {
    "text": "nodes versus you know a larger node but the cost is certainly more expensive",
    "start": "932449",
    "end": "937730"
  },
  {
    "text": "with enabled so that would be your trade-off it's like a deeper look at",
    "start": "937730",
    "end": "943220"
  },
  {
    "text": "cluster mode enabled just to make sure we're sort of all on the same page with how it works you know under the hood that sort of thing",
    "start": "943220",
    "end": "949329"
  },
  {
    "text": "so I mentioned earlier Redis has 16384 hash slots and again these hash slots",
    "start": "949329",
    "end": "956449"
  },
  {
    "text": "are divided by the number of shards that you have and that would be the equal distribution although you have control",
    "start": "956449",
    "end": "963290"
  },
  {
    "text": "on changing that and a key essentially finds itself in a slot after doing a",
    "start": "963290",
    "end": "968959"
  },
  {
    "text": "search 16 modulo function an effort does that a live in essentially a slot and in",
    "start": "968959",
    "end": "975589"
  },
  {
    "text": "the client that you're using whether it's a Java client net Python as long as it's a cluster aware it will it will",
    "start": "975589",
    "end": "983149"
  },
  {
    "text": "ping the cluster issue a cluster slots command and I'll get a get a map of the",
    "start": "983149",
    "end": "989449"
  },
  {
    "text": "topology the nodes and also which node has is associated to what hash slot range so it knows where directed traffic",
    "start": "989449",
    "end": "997250"
  },
  {
    "text": "it also knows which node is a primary which nodes a replicas things of that",
    "start": "997250",
    "end": "1002649"
  },
  {
    "text": "nature now all clients are different so you obviously want to look at different characteristics of each client but",
    "start": "1002649",
    "end": "1010149"
  },
  {
    "text": "that's generally how the smart clients work now let's sort of visualize this",
    "start": "1010149",
    "end": "1015389"
  },
  {
    "text": "imagine this is your cluster this is an example of the three shard cluster each",
    "start": "1015389",
    "end": "1020740"
  },
  {
    "text": "shard here will be a different color and the border that gray border is will kind",
    "start": "1020740",
    "end": "1026740"
  },
  {
    "text": "of notice that the primary now again a cluster can be made up of 15 shards and",
    "start": "1026740",
    "end": "1033089"
  },
  {
    "text": "a shard can have up to 5 replicas so if you look closely here the replicas have",
    "start": "1033089",
    "end": "1039308"
  },
  {
    "text": "the same hash slot range of the primary and this is true obviously for all three",
    "start": "1039309",
    "end": "1046178"
  },
  {
    "text": "shards and what happens in a failure scenario so imagine one of your",
    "start": "1046179",
    "end": "1053169"
  },
  {
    "text": "primaries failed the impact that you have is only to the rights you can",
    "start": "1053169",
    "end": "1058900"
  },
  {
    "text": "always read during a failure assuming you have a replica now for 15 to 30",
    "start": "1058900",
    "end": "1066100"
  },
  {
    "text": "seconds what's going to happen here is we're gonna detect the failure and then we're going to immediately elect one of",
    "start": "1066100",
    "end": "1073570"
  },
  {
    "text": "your replicas to be the new primary as soon as that election happens your",
    "start": "1073570",
    "end": "1078789"
  },
  {
    "text": "client is made aware of that election and I'll be able to start writing to that newly elected to that newly elected",
    "start": "1078789",
    "end": "1086169"
  },
  {
    "text": "primary now if you wanted to reduce again as we mentioned earlier that blast",
    "start": "1086169",
    "end": "1091179"
  },
  {
    "text": "radius you just add more shorts right so if you had 10 shards only 10% of your data would have been affected in a",
    "start": "1091179",
    "end": "1097570"
  },
  {
    "text": "failure scenario like that now what happens if you lost majority this is",
    "start": "1097570",
    "end": "1103210"
  },
  {
    "text": "another difference that we have with open source so with open source if you",
    "start": "1103210",
    "end": "1108400"
  },
  {
    "text": "lost the majority of primaries you have a problem now with the election and your",
    "start": "1108400",
    "end": "1114700"
  },
  {
    "text": "cluster is unable to elect a replica a suitable replica to be the new primary",
    "start": "1114700",
    "end": "1119940"
  },
  {
    "text": "this is something that we we added some enhancements around and we're able to",
    "start": "1119940",
    "end": "1125049"
  },
  {
    "text": "make an intelligent election here and your cluster is recovered again this is nothing that you need to do there's no",
    "start": "1125049",
    "end": "1130600"
  },
  {
    "text": "intervention this is something that we're managing for you so the question",
    "start": "1130600",
    "end": "1136059"
  },
  {
    "text": "here is you know all right well imagine you have a cluster of three shards and you wanted to go to five how do you do",
    "start": "1136059",
    "end": "1143289"
  },
  {
    "text": "this there's an old way and I'll just call it the old way for now and then",
    "start": "1143289",
    "end": "1149559"
  },
  {
    "text": "there's a way that I want to introduce shortly so the old way would be and this",
    "start": "1149559",
    "end": "1154929"
  },
  {
    "text": "is only for cluster mode enabled is to leverage backup thermistor and we'll talk through why this is not efficient",
    "start": "1154929",
    "end": "1161700"
  },
  {
    "text": "as we're kind of building up this slide so the way you would do it is you take a",
    "start": "1161700",
    "end": "1167049"
  },
  {
    "text": "snapshot of this three shard cluster and after you take that snapshot",
    "start": "1167049",
    "end": "1173650"
  },
  {
    "text": "there's an obvious thing that you're noting here is that any new rights that",
    "start": "1173650",
    "end": "1179410"
  },
  {
    "text": "are happening to your cluster are not captured in that at RPO or that that that snapshot right so you're gonna have",
    "start": "1179410",
    "end": "1185830"
  },
  {
    "text": "to mitigate that but well we'll come back to that so after you take the snapshot what you do is you copy that",
    "start": "1185830",
    "end": "1192340"
  },
  {
    "text": "snapshot you place it into your s3 bucket then you create a new cluster and",
    "start": "1192340",
    "end": "1197530"
  },
  {
    "text": "then you pass the RTB files that were associated to the three shard cluster",
    "start": "1197530",
    "end": "1202660"
  },
  {
    "text": "that you had to the new cluster that you're creating so you're hydrating this new cluster with the whatever shard",
    "start": "1202660",
    "end": "1209740"
  },
  {
    "text": "count that you wanted we'll assume five here and then what we'll do is each",
    "start": "1209740",
    "end": "1215500"
  },
  {
    "text": "shard remember it has you know it's designated a certain hash range it will discard whatever you know keys or slots",
    "start": "1215500",
    "end": "1223090"
  },
  {
    "text": "don't belong to it and so the slots would distribute across the five the five shards and then after that after",
    "start": "1223090",
    "end": "1232929"
  },
  {
    "text": "you've created that cluster than what you're going to do is you're going to point your application to this newly elected cluster there's a new endpoint",
    "start": "1232929",
    "end": "1239730"
  },
  {
    "text": "they'll be some downtime which is never fun and then you have this new cluster",
    "start": "1239730",
    "end": "1246280"
  },
  {
    "text": "that you're working with right and so the the things that you're gonna have to mitigate with this solution is what do",
    "start": "1246280",
    "end": "1252760"
  },
  {
    "text": "you do with those rights that occurred after you took the snapshot so what some people would have done is it maybe write",
    "start": "1252760",
    "end": "1258850"
  },
  {
    "text": "to a queue or Kinesis or something like that and then once that new cluster is up they'll sort of hydrate those rights",
    "start": "1258850",
    "end": "1265110"
  },
  {
    "text": "not not the best solution but a solution but there's a better solution right and",
    "start": "1265110",
    "end": "1272200"
  },
  {
    "text": "this is what we're we're gonna review right now and so that solution here is zero downtime online restarting so we",
    "start": "1272200",
    "end": "1279370"
  },
  {
    "text": "just the recent recently announced us and we wanted to you know build this in",
    "start": "1279370",
    "end": "1285250"
  },
  {
    "text": "a way that we knew our customers wanted right and we're gonna talk about the difference that we've done and the",
    "start": "1285250",
    "end": "1291820"
  },
  {
    "text": "enhancements that we've done with this operation it's a little bit different than how open-source does this as well",
    "start": "1291820",
    "end": "1298740"
  },
  {
    "text": "so let's kind of go back to that three shard scenario imagine you have three shards and now all of a sudden you",
    "start": "1298740",
    "end": "1305950"
  },
  {
    "text": "do five this is a very very simple API in fact that's the CLI command for that",
    "start": "1305950",
    "end": "1311830"
  },
  {
    "text": "API what you do is you would pass the replication ID that's like your cluster",
    "start": "1311830",
    "end": "1318000"
  },
  {
    "text": "name you would pass a parameter which is apply immediately basically if you want",
    "start": "1318000",
    "end": "1324399"
  },
  {
    "text": "that operation occur start occurring and then you would also Pat past the node",
    "start": "1324399",
    "end": "1329409"
  },
  {
    "text": "count for the new shark right so in this case five and this API is also true for",
    "start": "1329409",
    "end": "1337059"
  },
  {
    "text": "scaling down so if you wanted to scale down the only additional value that you",
    "start": "1337059",
    "end": "1342159"
  },
  {
    "text": "would pass is which nodes you want to get rid of now everything after that is",
    "start": "1342159",
    "end": "1347549"
  },
  {
    "text": "completely we're managing we're doing for you right so what's happening here",
    "start": "1347549",
    "end": "1353019"
  },
  {
    "text": "is there's zero disruption to your app with application you're still using",
    "start": "1353019",
    "end": "1358659"
  },
  {
    "text": "Redis just like you were using Redis we're doing the retarding and doing a",
    "start": "1358659",
    "end": "1363850"
  },
  {
    "text": "uniform slot distribution across these new shards and slot by slot we're",
    "start": "1363850",
    "end": "1370090"
  },
  {
    "text": "migrating these shards in a very reliable and robust way and you don't have to worry about this right and so",
    "start": "1370090",
    "end": "1377470"
  },
  {
    "text": "one of the differences here that we did is with open source there's a key if I",
    "start": "1377470",
    "end": "1383380"
  },
  {
    "text": "key migration and we wanted to change that because when you do key by key there's a possibility where your where",
    "start": "1383380",
    "end": "1391090"
  },
  {
    "text": "your slot will be split across multiple shards and that problem basically limits",
    "start": "1391090",
    "end": "1399279"
  },
  {
    "text": "a few commands for example there's some Lua capabilities and multiple em gets",
    "start": "1399279",
    "end": "1404769"
  },
  {
    "text": "and things of that nature where you won't be able to use right so there's some limitations there and then when a",
    "start": "1404769",
    "end": "1411130"
  },
  {
    "text": "failure happens it's harder to recover from from that sort of scenario so we",
    "start": "1411130",
    "end": "1417190"
  },
  {
    "text": "decided to you know spend a little bit more time on this problem and we change that algorithm to do slot by slot so",
    "start": "1417190",
    "end": "1423909"
  },
  {
    "text": "will prevent the split slot a scenario and also we don't disrupt or change do",
    "start": "1423909",
    "end": "1429669"
  },
  {
    "text": "you at the behavior of your application we're not limiting the commands that you need to to run on us",
    "start": "1429669",
    "end": "1435580"
  },
  {
    "text": "now the only the only con here is that there is a possible performance impact",
    "start": "1435580",
    "end": "1440919"
  },
  {
    "text": "but there is no downtime right so that is one thing I'd like to call out now",
    "start": "1440919",
    "end": "1446950"
  },
  {
    "text": "the same thing is true for scaling in right so you want to scale in you have a cluster and all of a sudden you realize",
    "start": "1446950",
    "end": "1452769"
  },
  {
    "text": "you know what I don't need all these additional shards our memory consumption is good enough maybe you can support",
    "start": "1452769",
    "end": "1459759"
  },
  {
    "text": "three to scale in and how do you do that in a in an automated way right so now",
    "start": "1459759",
    "end": "1467230"
  },
  {
    "text": "we're revisiting we're cloud watch sort of pairs nicely with ElastiCache so",
    "start": "1467230",
    "end": "1472299"
  },
  {
    "text": "let's say for example you had a alarm set on memory and now that alarm went",
    "start": "1472299",
    "end": "1478450"
  },
  {
    "text": "off right so your memory is high what do you do right so you can issue an SNS",
    "start": "1478450",
    "end": "1485470"
  },
  {
    "text": "notification that SNS notification you're gonna basically trigger a lambda",
    "start": "1485470",
    "end": "1491529"
  },
  {
    "text": "function and that lambda function is going to parse the notification and then based on that alarm it's gonna do",
    "start": "1491529",
    "end": "1498609"
  },
  {
    "text": "something and in this case we're going to add some shards and you can automate this so you can add the logic that makes",
    "start": "1498609",
    "end": "1505720"
  },
  {
    "text": "sense to you to scale up and to scale down very similar to how auto scaling",
    "start": "1505720",
    "end": "1511359"
  },
  {
    "text": "groups would work for you C 2 but in this case you're sort of building that workflow using cloud watch SMS and AWS",
    "start": "1511359",
    "end": "1519340"
  },
  {
    "text": "lambda now the one thing I would advise if you're going to do this is that count for some of the time that would take for",
    "start": "1519340",
    "end": "1526149"
  },
  {
    "text": "the operation a complete so you might want to be a little conservative with your metric associated so like memory or",
    "start": "1526149",
    "end": "1533139"
  },
  {
    "text": "CPU or whatever you wanted to react to and again just like we we know we talked",
    "start": "1533139",
    "end": "1540279"
  },
  {
    "text": "about as soon as you kick off that function you're basically selling it ElastiCache scale up or scale out rather",
    "start": "1540279",
    "end": "1547980"
  },
  {
    "text": "and then everything is back to normal right now let's kind of look at this in another perspective so imagine this is",
    "start": "1547980",
    "end": "1554799"
  },
  {
    "text": "your application everything is healthy and if you're a business owner something",
    "start": "1554799",
    "end": "1562299"
  },
  {
    "text": "good just happened now you have more customers more customers are hitting your site and you know they want to buy",
    "start": "1562299",
    "end": "1568400"
  },
  {
    "text": "products if you're an infrastructure or developer something bad just happen right now you have heavy pressure heavy",
    "start": "1568400",
    "end": "1574340"
  },
  {
    "text": "loads your your database your application so what you would do again",
    "start": "1574340",
    "end": "1579920"
  },
  {
    "text": "you know just like what we talked about you'd trigger an alarm you scale up your",
    "start": "1579920",
    "end": "1585680"
  },
  {
    "text": "your ec2 instances and very similarly you can certainly have a conservative alarm to scale up your cluster the added",
    "start": "1585680",
    "end": "1593810"
  },
  {
    "text": "benefit here is that you're still sort of protecting your back-end database you're you're consuming for that",
    "start": "1593810",
    "end": "1600560"
  },
  {
    "text": "pressure in that cache layer and you're leaving your back-end sort of in the same state that it needs a bit it needs",
    "start": "1600560",
    "end": "1607040"
  },
  {
    "text": "to be which is really cost effective because scaling your your databases is costly or can be costly with licenses",
    "start": "1607040",
    "end": "1613520"
  },
  {
    "text": "and things of that nature and then the other thing is that when you do something like this you know your cache",
    "start": "1613520",
    "end": "1619220"
  },
  {
    "text": "can support much much greater operations per second and again the latency is much",
    "start": "1619220",
    "end": "1625670"
  },
  {
    "text": "faster than a back-end database so this is this is ideal so let's take a second",
    "start": "1625670",
    "end": "1632180"
  },
  {
    "text": "here to take a look at Amazon ElastiCache security will sort of review the basics that sort of build up from",
    "start": "1632180",
    "end": "1638540"
  },
  {
    "text": "that point so you know kind of starting from a clear canvas here",
    "start": "1638540",
    "end": "1645260"
  },
  {
    "text": "imagine you have a V PC few 3a Z's that you're working from the first thing that",
    "start": "1645260",
    "end": "1652490"
  },
  {
    "text": "you'll do with Amazon ElastiCache is you'll define a caste subnet group and this is a basically a collection of",
    "start": "1652490",
    "end": "1660790"
  },
  {
    "text": "private subnets that you would place your your cluster in that really spans",
    "start": "1660790",
    "end": "1666350"
  },
  {
    "text": "the AZ's that's your that you want to host your cluster in the second thing",
    "start": "1666350",
    "end": "1672530"
  },
  {
    "text": "that you're going to do is you're going to define a security group which is very similar to a firewall that's going to",
    "start": "1672530",
    "end": "1677930"
  },
  {
    "text": "have the you know the port and also the the protocol and then the the IP or the",
    "start": "1677930",
    "end": "1685010"
  },
  {
    "text": "you know the security group that's going to have access to your cluster and then",
    "start": "1685010",
    "end": "1692000"
  },
  {
    "text": "then you're gonna place your your you're going to create that replication group or your craze your cluster and you're",
    "start": "1692000",
    "end": "1697880"
  },
  {
    "text": "gonna place it in there right so you're gonna use that security group and a caste subnet group as part of that that",
    "start": "1697880",
    "end": "1703960"
  },
  {
    "text": "replication group creation now if you were to take a snapshot and you wanted",
    "start": "1703960",
    "end": "1709970"
  },
  {
    "text": "there to be some encryption at rest we have that feature that's a relatively new feature so your your snapshots will",
    "start": "1709970",
    "end": "1716810"
  },
  {
    "text": "be encrypted and then if you wanted application access you know you'll build your application they'll obviously be",
    "start": "1716810",
    "end": "1723560"
  },
  {
    "text": "security groups that are sort of protecting your application and then you'll want an able traffic from your",
    "start": "1723560",
    "end": "1729050"
  },
  {
    "text": "application security groups to your ElastiCache security group right and at",
    "start": "1729050",
    "end": "1735470"
  },
  {
    "text": "that point now you have access to your ElastiCache cluster so this is a very secure environment the only way you can",
    "start": "1735470",
    "end": "1742670"
  },
  {
    "text": "have access to your cache your ElastiCache cluster is if you enable access now what if you wanted to have",
    "start": "1742670",
    "end": "1751450"
  },
  {
    "text": "encryption between your application and your cluster so encryption in transit so",
    "start": "1751450",
    "end": "1759740"
  },
  {
    "text": "this is also relatively new so we just recently announced encryption in transit with Redis 32.6 and we also added Retta",
    "start": "1759740",
    "end": "1769850"
  },
  {
    "text": "saw you know if you're for some folks who want to use that token based authentication against the cluster using",
    "start": "1769850",
    "end": "1776930"
  },
  {
    "text": "their applications you also have that capability as well so to sort of recap",
    "start": "1776930",
    "end": "1783110"
  },
  {
    "text": "here encryption is new and this is both in transit at rest there's nothing that",
    "start": "1783110",
    "end": "1788180"
  },
  {
    "text": "you need to worry about with respect to keys and you know issuance and renewal of those keys we're taking care of all",
    "start": "1788180",
    "end": "1794090"
  },
  {
    "text": "that for you and then it's from a from a HIPAA standpoint if that's something that you care about it's it's included",
    "start": "1794090",
    "end": "1800720"
  },
  {
    "text": "in the AWS baa so it's a HIPAA eligible",
    "start": "1800720",
    "end": "1806380"
  },
  {
    "text": "now we'll review some common usage patterns with a loss of cash so this",
    "start": "1808050",
    "end": "1814260"
  },
  {
    "text": "first slide is just really a kind of a slide to show different types of",
    "start": "1814260",
    "end": "1820170"
  },
  {
    "text": "organizations that use ElastiCache it really it covers all sorts of verticals",
    "start": "1820170",
    "end": "1826050"
  },
  {
    "text": "and as I mentioned earlier today also all sorts of workloads and those",
    "start": "1826050",
    "end": "1832740"
  },
  {
    "text": "workloads really span from cashing to you know to sentiment analysis streaming",
    "start": "1832740",
    "end": "1839670"
  },
  {
    "text": "data some various things and and usually what happens is an organization will start with caching maybe they'll do like",
    "start": "1839670",
    "end": "1846179"
  },
  {
    "text": "database caching and then they'll move to maybe you know object caching maybe",
    "start": "1846179",
    "end": "1851760"
  },
  {
    "text": "they'll go into API caching they'll catch the response the responses for API",
    "start": "1851760",
    "end": "1857700"
  },
  {
    "text": "requests maybe they'll start caching you know elasticsearch responses and they'll",
    "start": "1857700",
    "end": "1864420"
  },
  {
    "text": "kind of grow into other use cases and it will start seeing additional things we also see some organizations use Redis as",
    "start": "1864420",
    "end": "1872760"
  },
  {
    "text": "a standalone database and you know this is certainly doable especially if you",
    "start": "1872760",
    "end": "1877890"
  },
  {
    "text": "can recreate that data because again you can take snapshots you also have a che",
    "start": "1877890",
    "end": "1883610"
  },
  {
    "text": "that you can you can do so a metadata store or something that you can create is certainly possible let's take a look",
    "start": "1883610",
    "end": "1892050"
  },
  {
    "text": "at caching so with caching typically the way people think about this is you're",
    "start": "1892050",
    "end": "1897690"
  },
  {
    "text": "you're placing a cache in front of a data store by our database and your caching the results that you would",
    "start": "1897690",
    "end": "1903179"
  },
  {
    "text": "typically get out of that database but",
    "start": "1903179",
    "end": "1908580"
  },
  {
    "text": "what where it gets interesting is imagine you have correlated data or data",
    "start": "1908580",
    "end": "1913800"
  },
  {
    "text": "that's that spans multiple databases so we'll just make up an example here",
    "start": "1913800",
    "end": "1919140"
  },
  {
    "text": "imagine you had a customer or maybe you're capturing clickstream data for",
    "start": "1919140",
    "end": "1925590"
  },
  {
    "text": "your particular customer maybe it's in dynamo maybe that specific customer you have transactional data like orders",
    "start": "1925590",
    "end": "1933030"
  },
  {
    "text": "order history things of that nature in your relational database and maybe you",
    "start": "1933030",
    "end": "1938940"
  },
  {
    "text": "also have you know product metadata in your s3 object store and what you",
    "start": "1938940",
    "end": "1945600"
  },
  {
    "text": "want to do is in addition to caching that back-end data you want to create like a cache hub right you want to",
    "start": "1945600",
    "end": "1952289"
  },
  {
    "text": "create a central location that really is capturing the activity of that user you",
    "start": "1952289",
    "end": "1958200"
  },
  {
    "text": "can easily do this and some people do this with Redis and what this does is it",
    "start": "1958200",
    "end": "1963600"
  },
  {
    "text": "simplifies your your your data access it puts everything in one spot for you that",
    "start": "1963600",
    "end": "1969360"
  },
  {
    "text": "aggregation is very natural with respect to how you might want to use this for analytics or you know various use cases",
    "start": "1969360",
    "end": "1976020"
  },
  {
    "text": "for your application and the one thing that you'll need to do is obviously make",
    "start": "1976020",
    "end": "1981299"
  },
  {
    "text": "sure that you could trigger and keep that cache fresh so whether it's through AWS lambda or some other process that",
    "start": "1981299",
    "end": "1988289"
  },
  {
    "text": "you might define whenever you're updating that back in datastore just keep that cache as fresh as possible",
    "start": "1988289",
    "end": "1993900"
  },
  {
    "text": "just so that aggregated view is as accurate as possible furthermore with",
    "start": "1993900",
    "end": "2001309"
  },
  {
    "text": "caching we also see organizations I mean taking caching they're essentially",
    "start": "2001309",
    "end": "2007190"
  },
  {
    "text": "caching everything right including other no sequel databases and to some this is",
    "start": "2007190",
    "end": "2012679"
  },
  {
    "text": "sort of like you know like they think about this at first like an ansi pattern they're like well why am i caching in a",
    "start": "2012679",
    "end": "2018740"
  },
  {
    "text": " database or Cassandra database well you're doing it for the same reasons you want to lower the latency",
    "start": "2018740",
    "end": "2025039"
  },
  {
    "text": "the data retrieval speed you want to increase the data retrieval speed from",
    "start": "2025039",
    "end": "2030350"
  },
  {
    "text": "your back-end data store and you may also want to lower your cost because again what Redis is support incredibly",
    "start": "2030350",
    "end": "2038330"
  },
  {
    "text": "high request rates at a low cost because you're not paying for that throughput or",
    "start": "2038330",
    "end": "2043460"
  },
  {
    "text": "those requests to allows the cache Redis and there's various techniques that you",
    "start": "2043460",
    "end": "2050210"
  },
  {
    "text": "can do to cache data whether you want to serialize the objects that you get out of those those back-end databases or",
    "start": "2050210",
    "end": "2057618"
  },
  {
    "text": "whether you want to convert them into a hash map or something that makes sense for your applications there's a variety",
    "start": "2057619",
    "end": "2063260"
  },
  {
    "text": "of different things that you might want to do all really depends on what you want to how your application wants to use that",
    "start": "2063260",
    "end": "2068679"
  },
  {
    "text": "data another interesting pattern that we we see a lot of organizations do because",
    "start": "2068679",
    "end": "2075520"
  },
  {
    "text": "Redis is very fast and very rich with respect to data structures and there's a lot of aggregate data structures like",
    "start": "2075520",
    "end": "2081760"
  },
  {
    "text": "the hash map the set sort of said linked lists what they might want to do is you",
    "start": "2081760",
    "end": "2087669"
  },
  {
    "text": "know as they're capturing fast moving data you know say maybe we'll go back to",
    "start": "2087669",
    "end": "2093970"
  },
  {
    "text": "sentiment analysis they're capturing tweets or you know things that are coming in very fast maybe they're",
    "start": "2093970",
    "end": "2100840"
  },
  {
    "text": "they're using Kinesis streams for this what they want to do is they want to interpret they want to kind of dive into",
    "start": "2100840",
    "end": "2107200"
  },
  {
    "text": "that data and they want to enrich it and they want to see if maybe that user did something previously on the on the",
    "start": "2107200",
    "end": "2114880"
  },
  {
    "text": "system so they'll take they'll peel off records from that stream and then",
    "start": "2114880",
    "end": "2121150"
  },
  {
    "text": "they'll take that maybe the user ID or something that they can correlate to the cache and they'll query the cache and",
    "start": "2121150",
    "end": "2127150"
  },
  {
    "text": "OCR do I have activity for this user if I do let's go ahead and summarize this",
    "start": "2127150",
    "end": "2132910"
  },
  {
    "text": "and for information maybe we'll do the data decorate it and you will enrich this data and then after they create",
    "start": "2132910",
    "end": "2139720"
  },
  {
    "text": "this aggregate view they'll store this information in a cleansed stream and in",
    "start": "2139720",
    "end": "2145750"
  },
  {
    "text": "that cloud stream now has a richer information processed information that",
    "start": "2145750",
    "end": "2150760"
  },
  {
    "text": "they might have some other you know sort of process may be additional analytics",
    "start": "2150760",
    "end": "2156910"
  },
  {
    "text": "that they might do or might might hydrate another back-end database for that other things that you can do we",
    "start": "2156910",
    "end": "2163450"
  },
  {
    "text": "talked about pub/sub you might want to if you saw something interesting maybe in that stream you might want to publish",
    "start": "2163450",
    "end": "2169450"
  },
  {
    "text": "that information to subscribers and those subscribers are doing something with that data maybe have a dashboard or",
    "start": "2169450",
    "end": "2175630"
  },
  {
    "text": "something else it can certainly build that wit with Redis and as we're sort of talking about",
    "start": "2175630",
    "end": "2181960"
  },
  {
    "text": "you know fast data fast moving data Kinesis streams the sort of big data",
    "start": "2181960",
    "end": "2187270"
  },
  {
    "text": "architectures is becoming more and more popular with Redis and what we're seeing",
    "start": "2187270",
    "end": "2194170"
  },
  {
    "text": "people do is they you know as they're processing and for me they still want to have that data you",
    "start": "2194170",
    "end": "2199940"
  },
  {
    "text": "know in their in their big data Lake but what they also might want to do is they might want to augment that data platform",
    "start": "2199940",
    "end": "2206119"
  },
  {
    "text": "that they're building and create this fast data layer right and this fast data",
    "start": "2206119",
    "end": "2211549"
  },
  {
    "text": "layer is gonna be for maybe you know that transient information the active data and something that they can really",
    "start": "2211549",
    "end": "2217849"
  },
  {
    "text": "pound on for for a low cost because again there's no added cost for that",
    "start": "2217849",
    "end": "2223069"
  },
  {
    "text": "throughput in deal with the requests so they might use a variety of different",
    "start": "2223069",
    "end": "2228339"
  },
  {
    "text": "engines or products to you know process the information whether it's Kafka in",
    "start": "2228339",
    "end": "2234770"
  },
  {
    "text": "Apache storm or a spark and then they'll use a connector to basically drop that",
    "start": "2234770",
    "end": "2241730"
  },
  {
    "text": "data into to ElastiCache Redis and and once it's there in those data stores",
    "start": "2241730",
    "end": "2248559"
  },
  {
    "text": "they'll use a variety of different tools it all depends on that workflow and then",
    "start": "2248559",
    "end": "2253819"
  },
  {
    "text": "they'll analyze that data both in the Fast datastore maybe they're also using obviously their Big Data Lake Forest",
    "start": "2253819",
    "end": "2260930"
  },
  {
    "text": "Oracle maybe aggregations and things of that nature IOC we're seeing a lot of usage with",
    "start": "2260930",
    "end": "2269329"
  },
  {
    "text": "Redis with IOT and you know this is a this really depends on the use case but",
    "start": "2269329",
    "end": "2276740"
  },
  {
    "text": "what a lot of times happens is an organization it might be building something and they don't know exactly at",
    "start": "2276740",
    "end": "2283490"
  },
  {
    "text": "first you know what type of data they didn't want to you know store you know",
    "start": "2283490",
    "end": "2288710"
  },
  {
    "text": "for historical reasons or they want to capture all the sort of sensor informations in the beginning and sort",
    "start": "2288710",
    "end": "2295040"
  },
  {
    "text": "of kind of tailor it down to what they really need and they're thinking about this and they want to build a solution",
    "start": "2295040",
    "end": "2301339"
  },
  {
    "text": "in the most cost effective way that does not hinder performance so what they'll",
    "start": "2301339",
    "end": "2307730"
  },
  {
    "text": "do is they'll capture sensor information they may use the AWS IOT service for",
    "start": "2307730",
    "end": "2315770"
  },
  {
    "text": "this which makes it incredibly easy and at once it's in the AWS IOT service",
    "start": "2315770",
    "end": "2320990"
  },
  {
    "text": "they'll trigger a rule from the funa rules engine that might have a lambda function and that lambda function will",
    "start": "2320990",
    "end": "2328490"
  },
  {
    "text": "essentially write data lettuce right and if this is you know",
    "start": "2328490",
    "end": "2334319"
  },
  {
    "text": "time series data this is very easy to do because you can capture the data and use",
    "start": "2334319",
    "end": "2340260"
  },
  {
    "text": "a sorted set and in this score which allows you to sort the data based on",
    "start": "2340260",
    "end": "2345960"
  },
  {
    "text": "that score or you can use a timestamp for that and as you're writing the data to that sorted set you can also have the",
    "start": "2345960",
    "end": "2352589"
  },
  {
    "text": "properties of that sensor in a hash map and wrap all that into you know a",
    "start": "2352589",
    "end": "2357930"
  },
  {
    "text": "transaction would make a lot of sense and if you also wanted that data for",
    "start": "2357930",
    "end": "2363150"
  },
  {
    "text": "historical reasons you wanted that raw data also write that to s3 the Kinesis",
    "start": "2363150",
    "end": "2369180"
  },
  {
    "text": "streams so that would be an approach that we see some customers leveraging",
    "start": "2369180",
    "end": "2374430"
  },
  {
    "text": "with ElastiCache Redis geospatial",
    "start": "2374430",
    "end": "2379829"
  },
  {
    "text": "capability with Retta really was a game-changer so we talked to a lot of organizations",
    "start": "2379829",
    "end": "2385290"
  },
  {
    "text": "who build mobile applications whether it's a ride-sharing organization whether",
    "start": "2385290",
    "end": "2390839"
  },
  {
    "text": "it's an organization that has a recommendation engine maybe a restaurant engine or something of that nature and",
    "start": "2390839",
    "end": "2396710"
  },
  {
    "text": "what they'll do is you know as you know maybe you're walking they'll take the",
    "start": "2396710",
    "end": "2402720"
  },
  {
    "text": "users information that longitude latitude data they'll pass it up",
    "start": "2402720",
    "end": "2407940"
  },
  {
    "text": "you know maybe through API gateway they'll hit a lambda function query Redis with that that geo information and",
    "start": "2407940",
    "end": "2415980"
  },
  {
    "text": "then recommend points of interest this is incredibly easy to do with Redis and",
    "start": "2415980",
    "end": "2422579"
  },
  {
    "text": "again Redis is very very fast this enriches that user experience because",
    "start": "2422579",
    "end": "2428880"
  },
  {
    "text": "your your recommendations are happening in incredibly fast you know performance and the only thing",
    "start": "2428880",
    "end": "2436500"
  },
  {
    "text": "that you would need to do here is just define a workflow that's constantly keeping those points of interests rush",
    "start": "2436500",
    "end": "2443220"
  },
  {
    "text": "into Redis if it's not your your primary database here so in this case we're",
    "start": "2443220",
    "end": "2449190"
  },
  {
    "text": "using dynamo DB as a primary database we're using dynamodb streams which every",
    "start": "2449190",
    "end": "2454890"
  },
  {
    "text": "time we write maybe it's a restaurant into dynamodb that information will go",
    "start": "2454890",
    "end": "2460560"
  },
  {
    "text": "through dynamodb streams be triggered off of lambda function which will write that data into Redis so in this case Radisson",
    "start": "2460560",
    "end": "2469359"
  },
  {
    "text": "Redis is really complimenting DynamoDB",
    "start": "2469359",
    "end": "2476200"
  },
  {
    "text": "ad sack is another use case that we see a lot with organizations using Greta s--",
    "start": "2476200",
    "end": "2482599"
  },
  {
    "text": "so kind of just to review the workflow here so what you have is you have the ad",
    "start": "2482599",
    "end": "2489049"
  },
  {
    "text": "publishers who are essentially you know placing ad ad slots for bids right and",
    "start": "2489049",
    "end": "2498109"
  },
  {
    "text": "so they send this information whether it's click stream information and user information with a particular you know",
    "start": "2498109",
    "end": "2507049"
  },
  {
    "text": "ad location into this ad network and then you have bidders who are essentially saying well do I want a bid",
    "start": "2507049",
    "end": "2513650"
  },
  {
    "text": "on that and place my advertisement in that and data in that slot and that",
    "start": "2513650",
    "end": "2520099"
  },
  {
    "text": "logic that's involved there needs to happen incredibly fast right that entire workflow needs to happen in less than 40",
    "start": "2520099",
    "end": "2527240"
  },
  {
    "text": "milliseconds so the most critical part here is when the bidder receives the",
    "start": "2527240",
    "end": "2533299"
  },
  {
    "text": "information about the ad they want to they want to execute whatever logic that",
    "start": "2533299",
    "end": "2538670"
  },
  {
    "text": "they have incredibly fast and they need a really fast database but what would be better is if the database provided",
    "start": "2538670",
    "end": "2545690"
  },
  {
    "text": "capabilities to do really quick operations so you know Redis has various",
    "start": "2545690",
    "end": "2551240"
  },
  {
    "text": "things what sets where you could do intersection join unions things things of that nature with a variety of other",
    "start": "2551240",
    "end": "2557329"
  },
  {
    "text": "data structures so they'll take advantage of some of those capabilities do very very quick you know operations",
    "start": "2557329",
    "end": "2565819"
  },
  {
    "text": "with Redis and then go ahead and bid or not bid in this use case",
    "start": "2565819",
    "end": "2571750"
  },
  {
    "text": "Chadd applications see a lot of this especially with like gaming companies so",
    "start": "2571750",
    "end": "2577490"
  },
  {
    "text": "if you're a gamer maybe you're playing a game and you see like maybe chat happening in a campaign a lot of",
    "start": "2577490",
    "end": "2584390"
  },
  {
    "text": "communication happening within a group of players that communication may be",
    "start": "2584390",
    "end": "2590029"
  },
  {
    "text": "powered by Redis other times I've spoken with customers who you know you'll be on a website and",
    "start": "2590029",
    "end": "2596630"
  },
  {
    "text": "in a chat application will just pop up that application is powered by Redis",
    "start": "2596630",
    "end": "2602019"
  },
  {
    "text": "using pub/sub capabilities and in",
    "start": "2602019",
    "end": "2607339"
  },
  {
    "text": "leaderboards this is like a go-to solution with gamers because what would",
    "start": "2607339",
    "end": "2614269"
  },
  {
    "text": "it what you can do with a leaderboard and kind of going back to this sorted set is this gives you very very easy",
    "start": "2614269",
    "end": "2620269"
  },
  {
    "text": "ways to rank information and then retrieve information and various different sort of different amounts of",
    "start": "2620269",
    "end": "2631369"
  },
  {
    "text": "users so for example I can say give me all the users with a specific rank or",
    "start": "2631369",
    "end": "2636499"
  },
  {
    "text": "give me the reverse rank of the first top users things of that nature natural",
    "start": "2636499",
    "end": "2641809"
  },
  {
    "text": "operations that would happen in a ranking engine which is a leaderboard right so you have that capability with",
    "start": "2641809",
    "end": "2648710"
  },
  {
    "text": "Redis rate limiting so we have organizations who within their API calls",
    "start": "2648710",
    "end": "2656390"
  },
  {
    "text": "maybe they you know they're building a solution where they want certain organizations to purchase maybe",
    "start": "2656390",
    "end": "2663289"
  },
  {
    "text": "different packages of how many times you can call a specific API right so this is",
    "start": "2663289",
    "end": "2669079"
  },
  {
    "text": "sort of bundled ins in different packages maybe a silver gold platinum type of deal and in what they'll do is",
    "start": "2669079",
    "end": "2676519"
  },
  {
    "text": "in their in their API that the the end user will consume they'll make a call",
    "start": "2676519",
    "end": "2682940"
  },
  {
    "text": "out so Redis which is really you know there's a variety of different ways you can implement this but essentially",
    "start": "2682940",
    "end": "2688430"
  },
  {
    "text": "you're using counters whether you're decrementing or incrementing a counter and it just making sure that that",
    "start": "2688430",
    "end": "2693979"
  },
  {
    "text": "customer didn't hit that limit and if they did you're just throttling it and again they use Redis here for speed and",
    "start": "2693979",
    "end": "2701359"
  },
  {
    "text": "they also use Redis here because you don't pay for all those requests so it",
    "start": "2701359",
    "end": "2706519"
  },
  {
    "text": "makes a lot of sense to do something like that all right so let's uh spend some time",
    "start": "2706519",
    "end": "2712849"
  },
  {
    "text": "here and talk about best practices so the first one that we're going to view is sizing cluster sizing so you",
    "start": "2712849",
    "end": "2722620"
  },
  {
    "text": "know when you when you're building a cluster there's a few things that you want to take it to really consider the",
    "start": "2722620",
    "end": "2730810"
  },
  {
    "text": "first one is storage right so this is sort of the default one you'll you'll",
    "start": "2730810",
    "end": "2736060"
  },
  {
    "text": "want to take a look at how much data you you actually need and then you wanna you",
    "start": "2736060",
    "end": "2742060"
  },
  {
    "text": "want to add 25% data this is a data that you want to reserve for Redis for those",
    "start": "2742060",
    "end": "2747640"
  },
  {
    "text": "background operations that we talked about and by default we'll reserve that for you so and then the next thing that",
    "start": "2747640",
    "end": "2755230"
  },
  {
    "text": "you want to do and this is really optional optional is you may want to add a little buffer for some growth right so",
    "start": "2755230",
    "end": "2761770"
  },
  {
    "text": "that would be a healthy way to size your cluster now the second thing you want to",
    "start": "2761770",
    "end": "2766840"
  },
  {
    "text": "do is you want to make sure and you want to review this with the developers if you're in the operations or if you're a",
    "start": "2766840",
    "end": "2772810"
  },
  {
    "text": "developer you want to review this as well you want to make sure that proper usage of TTLs is being done and and the",
    "start": "2772810",
    "end": "2781540"
  },
  {
    "text": "best way to do this is really understand the frequency of change of the underlying data so review how frequently",
    "start": "2781540",
    "end": "2788560"
  },
  {
    "text": "that data changes and make sure that whatever TTLs are being placed on that data reflects what the underlying change",
    "start": "2788560",
    "end": "2795580"
  },
  {
    "text": "makes does we talked about we talked about scale-up and out using cloud watch",
    "start": "2795580",
    "end": "2802150"
  },
  {
    "text": "so you might have a bunch of different alarms that are gonna be set to proactively react to your cluster and if",
    "start": "2802150",
    "end": "2810730"
  },
  {
    "text": "you wanted a size for memory you're gonna select a you know an R based instance our fours are great they're",
    "start": "2810730",
    "end": "2817000"
  },
  {
    "text": "memory optimized but in addition to memory they support incredibly high",
    "start": "2817000",
    "end": "2822030"
  },
  {
    "text": "networking it you know it's starting at a are for large for example as 10",
    "start": "2822030",
    "end": "2827170"
  },
  {
    "text": "gigabits of network performance so it's sort of network and memory optimized the",
    "start": "2827170",
    "end": "2835090"
  },
  {
    "text": "second thing you want to do is think about performance so once you've got sort of the storage out the way you want",
    "start": "2835090",
    "end": "2841900"
  },
  {
    "text": "to consider what type of operations are happening and have a game plan in terms of what you're gonna do when",
    "start": "2841900",
    "end": "2848950"
  },
  {
    "text": "one of those thresholds kind of is met so the first thing kind of obvious if",
    "start": "2848950",
    "end": "2856509"
  },
  {
    "text": "you're if you're spiking on read I ox and you need more read I ops you're gonna add more replicas if you need more",
    "start": "2856509",
    "end": "2863710"
  },
  {
    "text": "right I ops that means you need more sharps you need more primaries that you",
    "start": "2863710",
    "end": "2868779"
  },
  {
    "text": "can write to if you need more Network IO if you're somehow you're being scaled on",
    "start": "2868779",
    "end": "2875289"
  },
  {
    "text": "a you know a network you'll just pick a network based instance in general if",
    "start": "2875289",
    "end": "2883210"
  },
  {
    "text": "you're loading data use pipelining as much as you can for bulk reads bulk",
    "start": "2883210",
    "end": "2888609"
  },
  {
    "text": "writes and then consider the Big O complex time complexity associated to",
    "start": "2888609",
    "end": "2894579"
  },
  {
    "text": "the operations and this one is sort of a bigger topic but the point with this one",
    "start": "2894579",
    "end": "2899859"
  },
  {
    "text": "is really understand you know how what what is that operation what kind of impact is that operation have on that",
    "start": "2899859",
    "end": "2906400"
  },
  {
    "text": "data structure how many members does that operation that data structure have and what you can do the sort of reduce",
    "start": "2906400",
    "end": "2913509"
  },
  {
    "text": "that speed or the worst case scenario associated with that operation and then",
    "start": "2913509",
    "end": "2919299"
  },
  {
    "text": "finally the thing that you might want to do is think about you know the different",
    "start": "2919299",
    "end": "2924630"
  },
  {
    "text": "isolation cluster isolations associated to your cluster and what I mean by this",
    "start": "2924630",
    "end": "2930009"
  },
  {
    "text": "is you know when you create a cluster there's a variety of different parameters that you can define one of",
    "start": "2930009",
    "end": "2935499"
  },
  {
    "text": "them is like an addiction policy and what you might select for a caching",
    "start": "2935499",
    "end": "2940779"
  },
  {
    "text": "cluster may be very different than what you might select for a metadata store",
    "start": "2940779",
    "end": "2946239"
  },
  {
    "text": "and so what you might want to do is have caching workloads in a particular",
    "start": "2946239",
    "end": "2953829"
  },
  {
    "text": "cluster and maybe a different cluster for your queues maybe another cluster for something else your metadata store",
    "start": "2953829",
    "end": "2960309"
  },
  {
    "text": "so sort of group by purpose and then the more granular you get here the cost is",
    "start": "2960309",
    "end": "2966369"
  },
  {
    "text": "going to go up so you need to figure out what makes sense for your organization",
    "start": "2966369",
    "end": "2971940"
  },
  {
    "text": "the other thing that you'll always want to do is once you sort of have an idea",
    "start": "2971940",
    "end": "2977980"
  },
  {
    "text": "of what makes sense from sizing perspective you'll want to test this it's very easy to test this and",
    "start": "2977980",
    "end": "2984400"
  },
  {
    "text": "what I actually do is in my cloud formation templates I also build out an instance that has the Redis client and",
    "start": "2984400",
    "end": "2992380"
  },
  {
    "text": "built into it so it's very easy for me to test the performance before I hand it over to",
    "start": "2992380",
    "end": "2998619"
  },
  {
    "text": "somebody or before I start using it in a POC or a demo so this is another way to sort of kind of stamp that you have a",
    "start": "2998619",
    "end": "3005849"
  },
  {
    "text": "good idea that this is going to perform the way you want now when you we talked a little bit",
    "start": "3005849",
    "end": "3013980"
  },
  {
    "text": "about eviction policies and we'll just kind of talk a little bit further about this when you create that cluster if",
    "start": "3013980",
    "end": "3021570"
  },
  {
    "text": "you're doing it for you know for your developers you'll really want to evaluate what this cluster is being used",
    "start": "3021570",
    "end": "3028140"
  },
  {
    "text": "for and you know what caused a t'as being used more specifically right so",
    "start": "3028140",
    "end": "3034530"
  },
  {
    "text": "the different eviction policies that exist there everything from you know and all keys LRU which really takes any key",
    "start": "3034530",
    "end": "3043520"
  },
  {
    "text": "least recently used of key across your entire key space if you have for example",
    "start": "3043520",
    "end": "3051030"
  },
  {
    "text": "a volatile LRU you're basically going to vicked a key that has a you know that",
    "start": "3051030",
    "end": "3058080"
  },
  {
    "text": "has an expiration set right so a TTL set and the difference between the two is",
    "start": "3058080",
    "end": "3063690"
  },
  {
    "text": "big right because what if you have data that does not have TTLs and then you",
    "start": "3063690",
    "end": "3069660"
  },
  {
    "text": "also have data that has TTLs but the data that doesn't have TTL is you never want to evict because it's metadata",
    "start": "3069660",
    "end": "3075060"
  },
  {
    "text": "right so this would be a reason why you might use one versus the other",
    "start": "3075060",
    "end": "3080490"
  },
  {
    "text": "and so this is the kind of the kind of logic that you might have and then the same thing is true here for the the TTL",
    "start": "3080490",
    "end": "3087480"
  },
  {
    "text": "volatile TTL and so on and so forth from",
    "start": "3087480",
    "end": "3092490"
  },
  {
    "text": "a CloudWatch perspective you'll always want to look at CPU utilization make",
    "start": "3092490",
    "end": "3098280"
  },
  {
    "text": "sure that you know you're you're sort of monitoring how much processing is happening on your cluster if you feel",
    "start": "3098280",
    "end": "3106349"
  },
  {
    "text": "that you need more CPU support you might need more shards",
    "start": "3106349",
    "end": "3111450"
  },
  {
    "text": "from the swamp usage you you want to see that low if not zero",
    "start": "3111450",
    "end": "3117420"
  },
  {
    "text": "especially if memory is high you never really want to be in swapping an in-memory system from cache misses the",
    "start": "3117420",
    "end": "3124740"
  },
  {
    "text": "hits you always want to have more cache hits than misses right so you might want to target like a 90 and up ratio that",
    "start": "3124740",
    "end": "3132420"
  },
  {
    "text": "would be healthy and so if you had all the things that we talked about which was storage performance all those sort",
    "start": "3132420",
    "end": "3138059"
  },
  {
    "text": "of things built out but your developers aren't using the cluster effectively",
    "start": "3138059",
    "end": "3143099"
  },
  {
    "text": "it's kind of pointless right so you always want to sort of look at the cache hit to Miss ratio evictions you never",
    "start": "3143099",
    "end": "3152549"
  },
  {
    "text": "want to see evictions even though we just kind of talked about which one you would select really an eviction is",
    "start": "3152549",
    "end": "3157980"
  },
  {
    "text": "happening when you're overloading the cluster right so the cluster is at least",
    "start": "3157980",
    "end": "3164490"
  },
  {
    "text": "being nice to you and saying before I get rid of a key you know tell me what algorithm you want me to evict and it's",
    "start": "3164490",
    "end": "3170849"
  },
  {
    "text": "that's that's where you select those max memory policies but ideally you don't you don't ever want to hit that scenario",
    "start": "3170849",
    "end": "3177299"
  },
  {
    "text": "unless you have a specific use case when you're using a Russian Russian doll caching or you define it as an LRU cache",
    "start": "3177299",
    "end": "3183720"
  },
  {
    "text": "or something of that nature from a connection standpoint you always want to",
    "start": "3183720",
    "end": "3189000"
  },
  {
    "text": "see this as stable you always want to validate that your developers are using connection pooling just like they would",
    "start": "3189000",
    "end": "3195030"
  },
  {
    "text": "use with a database and as we mentioned earlier set alarms wherever you can keep",
    "start": "3195030",
    "end": "3202680"
  },
  {
    "text": "in mind from a client's perspective a connection perspective you can have up to 65,000 per node whether it's a",
    "start": "3202680",
    "end": "3210240"
  },
  {
    "text": "primary or replica there's parameters here where you can kill idle connections whether you use a",
    "start": "3210240",
    "end": "3217530"
  },
  {
    "text": "timeout or TCP keep alive so you want to take a look at that and figure out what value makes sense for your organization",
    "start": "3217530",
    "end": "3223079"
  },
  {
    "text": "I mention here for reserve memory we by default will reserve 25% of reserve",
    "start": "3223079",
    "end": "3230549"
  },
  {
    "text": "memory so that would be a recommendation there and then setting the max memory",
    "start": "3230549",
    "end": "3236099"
  },
  {
    "text": "policy as we earlier now its kind of take a quick look here at caching tips to the first",
    "start": "3236099",
    "end": "3245760"
  },
  {
    "text": "tip as we mentioned earlier understand the frequency of change of the underlying data and what I always do is",
    "start": "3245760",
    "end": "3252780"
  },
  {
    "text": "I always try to be a conservative with this right so the first question you want to ask yourself is what's the",
    "start": "3252780",
    "end": "3259440"
  },
  {
    "text": "impact if if you provide steel data to the end-user and if the impact is high",
    "start": "3259440",
    "end": "3265620"
  },
  {
    "text": "then be conservative if there's very little impact and you know use your best judgment here and work with your your",
    "start": "3265620",
    "end": "3272400"
  },
  {
    "text": "database administrators and your business owners to understand what what value makes sense",
    "start": "3272400",
    "end": "3277500"
  },
  {
    "text": "it's a place as we mentioned set the appropriate TCL's that match that",
    "start": "3277500",
    "end": "3283860"
  },
  {
    "text": "frequency choose the proper eviction policies that align to the requirements",
    "start": "3283860",
    "end": "3290450"
  },
  {
    "text": "isolate for purpose which we we discussed maintain the cache for us the",
    "start": "3290450",
    "end": "3297330"
  },
  {
    "text": "freshness to the right throughs so there's two main patterns when you're dealing with you know a cache so in this",
    "start": "3297330",
    "end": "3304860"
  },
  {
    "text": "case this is a kind of a cache aside but it's a sort of on the side of your your your architecture and what your",
    "start": "3304860",
    "end": "3310770"
  },
  {
    "text": "application is doing is you're either lazy loading you're checking your cache for a value if it's not there you're",
    "start": "3310770",
    "end": "3317550"
  },
  {
    "text": "clearing your back-end database you're grabbing the value from your back-end database and you're hydrating your cache",
    "start": "3317550",
    "end": "3323370"
  },
  {
    "text": "with it with a TTL so that way the next request that comes in the data is there",
    "start": "3323370",
    "end": "3329930"
  },
  {
    "text": "the other approach is proactive is this is where whatever process you have that's updating your back-end database",
    "start": "3329930",
    "end": "3336680"
  },
  {
    "text": "you're also writing that data to the cache maybe you're you're applying a",
    "start": "3336680",
    "end": "3342900"
  },
  {
    "text": "conservative TTL so you know if that data is not needed that's okay it's going to expire but if it's needed and",
    "start": "3342900",
    "end": "3350160"
  },
  {
    "text": "that a request comes in then you increase the likelihood that it's going to be there and you're maintaining a",
    "start": "3350160",
    "end": "3355500"
  },
  {
    "text": "better user experience because that data is always you know being found consistently in the cache so you're",
    "start": "3355500",
    "end": "3363660"
  },
  {
    "text": "using both lazy loading and that right through pattern with your cache",
    "start": "3363660",
    "end": "3369570"
  },
  {
    "text": "we talked about how to you know size or cluster so you always want to do that these are tenants to have a successful",
    "start": "3369570",
    "end": "3376000"
  },
  {
    "text": "cluster monitor the hit and miss ratio use the failover API I highly highly",
    "start": "3376000",
    "end": "3382660"
  },
  {
    "text": "recommend this and we expose an API here that allows you to kill primaries so do",
    "start": "3382660",
    "end": "3388599"
  },
  {
    "text": "this make sure the applications are built in a way that can withstand failures and the way you do that is by",
    "start": "3388599",
    "end": "3395020"
  },
  {
    "text": "testing the failover API and that's all we have today so thank you guys for your",
    "start": "3395020",
    "end": "3401740"
  },
  {
    "text": "time I hope you learned something new with elastic ass [Applause]",
    "start": "3401740",
    "end": "3410619"
  }
]
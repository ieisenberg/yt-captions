[
  {
    "start": "0",
    "end": "17000"
  },
  {
    "text": "so I'm profit",
    "start": "6480",
    "end": "9950"
  },
  {
    "text": "yeah customer payments for three years and food especially some big data",
    "start": "11969",
    "end": "18130"
  },
  {
    "start": "17000",
    "end": "17000"
  },
  {
    "text": "analysis and today we'll talk about analyzing genomic date said with kinds",
    "start": "18130",
    "end": "24369"
  },
  {
    "text": "in the team well quickly do is take a",
    "start": "24369",
    "end": "30429"
  },
  {
    "text": "step back it's a quick instruction of healthcare related with what we're doing",
    "start": "30429",
    "end": "35440"
  },
  {
    "text": "what we do given partners with customers and we jump straight into genomics",
    "start": "35440",
    "end": "40750"
  },
  {
    "text": "analysis on AWS hopefully in a few words and it will be like people opinion which",
    "start": "40750",
    "end": "50199"
  },
  {
    "text": "is our service platform and we do Q&A",
    "start": "50199",
    "end": "55660"
  },
  {
    "text": "and ok so speaking of decisions in",
    "start": "55660",
    "end": "61629"
  },
  {
    "start": "59000",
    "end": "59000"
  },
  {
    "text": "healthcare so as we know the growing populations of the patients you know",
    "start": "61629",
    "end": "68410"
  },
  {
    "text": "pressure on social media is a social and Human Services and the need to",
    "start": "68410",
    "end": "74049"
  },
  {
    "text": "effectively manage the benefits programs right so such research that you know this cetera are really really useful",
    "start": "74049",
    "end": "81270"
  },
  {
    "text": "because they generate insights that identify utilization trends find where",
    "start": "81270",
    "end": "86560"
  },
  {
    "text": "there are redundancy quality mattresses hopefully shape our app I have shaped",
    "start": "86560",
    "end": "94150"
  },
  {
    "text": "the future the way in the use of healthcare resources and so just a quick",
    "start": "94150",
    "end": "99579"
  },
  {
    "start": "98000",
    "end": "98000"
  },
  {
    "text": "look at the ecosystem of established healthcare part [Music]",
    "start": "99579",
    "end": "105360"
  },
  {
    "text": "so quickly look at that we have Simmons who have developed a health care",
    "start": "105360",
    "end": "110920"
  },
  {
    "text": "application that makes it easier for doctors and and provide personalized we",
    "start": "110920",
    "end": "118240"
  },
  {
    "text": "have bristol-myers Squibb yes we have",
    "start": "118240",
    "end": "126610"
  },
  {
    "text": "Johnson Johnson who have moved 120 applications in a hybrid mode bodyless",
    "start": "126610",
    "end": "136260"
  },
  {
    "text": "architecture and so yes most people's",
    "start": "136260",
    "end": "141310"
  },
  {
    "text": "using it address in a very creative way for healthcare",
    "start": "141310",
    "end": "146640"
  },
  {
    "text": "this is this I just wanna code this powerful have mercy of healthcare mental",
    "start": "146640",
    "end": "152709"
  },
  {
    "text": "solution from Phillip saying we combine data to make it actionable we are doing",
    "start": "152709",
    "end": "158080"
  },
  {
    "text": "that together with Amazon because there is only one hoping that we can do this",
    "start": "158080",
    "end": "163480"
  },
  {
    "text": "way which gives us reliability scale and performance we need fewer a few other",
    "start": "163480",
    "end": "169870"
  },
  {
    "text": "people were hope health care especially",
    "start": "169870",
    "end": "175510"
  },
  {
    "text": "a focus Ramon with big data analytics wider genomics base to it the Pfizer",
    "start": "175510",
    "end": "182650"
  },
  {
    "text": "11 runs some large-scale data analytics research forest and analysis and",
    "start": "182650",
    "end": "188830"
  },
  {
    "text": "modeling on AWS the seven bridges which does you know",
    "start": "188830",
    "end": "193940"
  },
  {
    "text": "analyze DNA sequencing only the best",
    "start": "193940",
    "end": "198920"
  },
  {
    "text": "shape we'll start now so that let's prepare enough back the topic to do 7n",
    "start": "199310",
    "end": "206190"
  },
  {
    "text": "genomics analysis if you look at what's on the background that was not my",
    "start": "206190",
    "end": "211740"
  },
  {
    "text": "two-year-old daughter thinking my keyboard and this is all live in artists",
    "start": "211740",
    "end": "220290"
  },
  {
    "text": "the result of these sequences so we have to call these base pairs and so when you",
    "start": "220290",
    "end": "228180"
  },
  {
    "text": "put them in specific order they may contain instructions that kick of processes that eventually form all",
    "start": "228180",
    "end": "235790"
  },
  {
    "text": "characteristics and traits everyone else in the net everyone in the nature and so",
    "start": "235790",
    "end": "242520"
  },
  {
    "text": "questions like which species at this come from and which function does absorb",
    "start": "242520",
    "end": "249709"
  },
  {
    "start": "251000",
    "end": "251000"
  },
  {
    "text": "refreshing myself biology 101 and so",
    "start": "252320",
    "end": "257850"
  },
  {
    "text": "those were base pairs so let's Leslie the basic unit of life apart from the virus is set and genetic",
    "start": "257850",
    "end": "268770"
  },
  {
    "text": "information is encoded by the DNA so and then is put in specific order and",
    "start": "268770",
    "end": "275300"
  },
  {
    "text": "transcribed into an RNA so let's look at in the computing world a little bit and",
    "start": "275300",
    "end": "281700"
  },
  {
    "text": "say the DNA is a point right which produces the assembly language unless",
    "start": "281700",
    "end": "289190"
  },
  {
    "text": "assume the cell is the processor it's no good could have come out here",
    "start": "289190",
    "end": "295460"
  },
  {
    "text": "cross-listed architecture diagram together so the DNA gives replication",
    "start": "295460",
    "end": "302190"
  },
  {
    "text": "instructions step1 step2 a portion of the the DNA sequence is",
    "start": "302190",
    "end": "309479"
  },
  {
    "text": "converted into an RNA and then RNA converts into messenger RNA which",
    "start": "309479",
    "end": "317860"
  },
  {
    "text": "converts into protein and proteins is assigned a role it's almost like roads",
    "start": "317860",
    "end": "325629"
  },
  {
    "text": "like this react with an I am beautiful knives that in abeyance items over the I",
    "start": "325629",
    "end": "330970"
  },
  {
    "text": "am roads so it's like almost thinking like this let's choose car so when you",
    "start": "330970",
    "end": "336610"
  },
  {
    "text": "try to encourage a few roads right so you say talented political you saying",
    "start": "336610",
    "end": "344229"
  },
  {
    "text": "gas down and to go function in the in the case of no it's saying we produce",
    "start": "344229",
    "end": "351550"
  },
  {
    "text": "more self-regulatory saying no that's we go in ourselves already",
    "start": "351550",
    "end": "356770"
  },
  {
    "text": "they say structure is all right this is my destination so this is what an amazing themselves so what happens is we",
    "start": "356770",
    "end": "368379"
  },
  {
    "text": "have a reference sequence which we get from that genomics project and there are",
    "start": "368379",
    "end": "374830"
  },
  {
    "text": "little variations everyone in this room every of one of the audiences were 2.5 billion of this and you extend that we",
    "start": "374830",
    "end": "384610"
  },
  {
    "text": "own this room and to the rest of the human species and then if you want to",
    "start": "384610",
    "end": "390490"
  },
  {
    "text": "really run analytics with other species and see what differences are there and",
    "start": "390490",
    "end": "397440"
  },
  {
    "text": "there's a big big problem no no this is a trick scream or",
    "start": "397440",
    "end": "402909"
  },
  {
    "text": "financial action analysis this is a big problem of major business so what what solutions do",
    "start": "402909",
    "end": "413770"
  },
  {
    "text": "you having AWS to address the solutions you can have one solution don't have one",
    "start": "413770",
    "end": "419350"
  },
  {
    "text": "CERN's that gets all we need we need services that can analyze data in any",
    "start": "419350",
    "end": "425380"
  },
  {
    "text": "format and we can scale as much as you",
    "start": "425380",
    "end": "431530"
  },
  {
    "text": "need and very little cost so I'm gonna quickly run through our big data",
    "start": "431530",
    "end": "439120"
  },
  {
    "start": "435000",
    "end": "435000"
  },
  {
    "text": "analytics platform so on the Left we have a series of services that's waiting",
    "start": "439120",
    "end": "445090"
  },
  {
    "text": "for you to collect data Direct Connect recently blocks and plate and a snowmobile import/export IOT we",
    "start": "445090",
    "end": "454389"
  },
  {
    "text": "talked about yesterday not necess for stream processing and moving databases",
    "start": "454389",
    "end": "460090"
  },
  {
    "text": "from various genes a table so",
    "start": "460090",
    "end": "465280"
  },
  {
    "text": "sustainably as call innovative is migration cells we can always straight the process of moving data and most ET",
    "start": "465280",
    "end": "473860"
  },
  {
    "text": "le using some services in the middle such as an administrative pipeline a",
    "start": "473860",
    "end": "480210"
  },
  {
    "text": "batch which is coming and then we store",
    "start": "480210",
    "end": "485530"
  },
  {
    "text": "the data we can store the data sgs3 is object storage web-scale object storage",
    "start": "485530",
    "end": "493020"
  },
  {
    "text": "I grow as much as you need very very next answer and then you can",
    "start": "493020",
    "end": "498569"
  },
  {
    "text": "archive it into place you know sequel databases with dynamo TV and analysis",
    "start": "498569",
    "end": "506219"
  },
  {
    "text": "eyes because he a mom you should manage to do cluster you can use ratchet a lot",
    "start": "506219",
    "end": "513599"
  },
  {
    "text": "Janice was actually run on man health information system for example one their",
    "start": "513599",
    "end": "520529"
  },
  {
    "text": "commonalities with our on redshift we have the machine learning in essence",
    "start": "520529",
    "end": "526260"
  },
  {
    "text": "analogous to the visualization side and",
    "start": "526260",
    "end": "531930"
  },
  {
    "text": "then I was in Tina which is server less Big Data Platform",
    "start": "531930",
    "end": "537779"
  },
  {
    "text": "so we really focus on ESPN tomorrow today today whatever and EEMA",
    "start": "537779",
    "end": "546980"
  },
  {
    "text": "quantitative software the Queen's data and finally run some queries using a",
    "start": "546980",
    "end": "554040"
  },
  {
    "text": "Latino sorry apologies a simple storage",
    "start": "554040",
    "end": "560339"
  },
  {
    "start": "556000",
    "end": "556000"
  },
  {
    "text": "service this is an object storage in",
    "start": "560339",
    "end": "569080"
  },
  {
    "text": "to my terabyte and as much as you want many of those some customers from Pennywise research take the size of",
    "start": "569080",
    "end": "579490"
  },
  {
    "text": "honor that means it is very important to a researcher especially between genomics work we provide a variety of open-source",
    "start": "579490",
    "end": "589590"
  },
  {
    "text": "data analytics the designs platforms on debris s Sigma and just a few clicks our",
    "start": "589590",
    "end": "598000"
  },
  {
    "text": "managed to do cluster elastic MapReduce and so when you kick off with check",
    "start": "598000",
    "end": "606190"
  },
  {
    "text": "boxes you can say that after an MRI for example with hive that plane which is",
    "start": "606190",
    "end": "613330"
  },
  {
    "text": "again a solution to really not much",
    "start": "613330",
    "end": "618640"
  },
  {
    "text": "total of you can just be a few clicks install and run all those only on top of",
    "start": "618640",
    "end": "624370"
  },
  {
    "text": "EMR and also you may want other node new services like Jupiter service begin",
    "start": "624370",
    "end": "634780"
  },
  {
    "text": "service also part in white masses and Salter's SAS tablet and this SQL",
    "start": "634780",
    "end": "643480"
  },
  {
    "text": "language SQL SQL runs very well on it a",
    "start": "643480",
    "end": "649940"
  },
  {
    "text": "new yes manager new using spot or a festive spot senior pastor so that let's",
    "start": "649940",
    "end": "658339"
  },
  {
    "text": "say Harry acceptor I want to go through what we have and not a few to solve",
    "start": "658339",
    "end": "664779"
  },
  {
    "text": "large-scale challenges such as genomics and strip we'll focus a little bit on",
    "start": "664779",
    "end": "670399"
  },
  {
    "start": "667000",
    "end": "667000"
  },
  {
    "text": "the spot and which came Berkeley and",
    "start": "670399",
    "end": "676570"
  },
  {
    "text": "project you to popular in the science and so it's very easy to run spark on",
    "start": "676570",
    "end": "684290"
  },
  {
    "text": "areas mainly few reasons in the previous lecture with a few clips inside to have",
    "start": "684290",
    "end": "690050"
  },
  {
    "text": "a spark cluster on the Emma so is easy to install configure quickly add and",
    "start": "690050",
    "end": "696649"
  },
  {
    "text": "remove capacity as Spock submit you can send Spock jobs on images pops up it's",
    "start": "696649",
    "end": "703839"
  },
  {
    "text": "come online or you use exactly another good service and if you like to",
    "start": "703839",
    "end": "710180"
  },
  {
    "text": "use highlighting for example if you use high spot and then which is go to some",
    "start": "710180",
    "end": "717800"
  },
  {
    "text": "custom example later on but some customers especially in economic space enough to use Amazon ec2 so you can",
    "start": "717800",
    "end": "723470"
  },
  {
    "text": "build for how much you want to spend on say you get up to 90% of the demand",
    "start": "723470",
    "end": "732730"
  },
  {
    "text": "pricing is secure and we can use and you",
    "start": "732730",
    "end": "738940"
  },
  {
    "text": "can use s3 to be couple computers so this is extremely part why is it",
    "start": "738940",
    "end": "744220"
  },
  {
    "text": "powerful so when you are not computing the data can sit to pay for computer you",
    "start": "744220",
    "end": "750880"
  },
  {
    "text": "do not have to launch in our customer so we can for example if you run into work",
    "start": "750880",
    "end": "756070"
  },
  {
    "text": "within my friend isn't working you take the space and s3 you only come",
    "start": "756070",
    "end": "761410"
  },
  {
    "text": "back on this thing opinion on May 23 that's a great advantage of separating",
    "start": "761410",
    "end": "768850"
  },
  {
    "text": "compute and from storage right and for",
    "start": "768850",
    "end": "775829"
  },
  {
    "text": "today's demo I'm going to use a library called Hana which is specifically geared",
    "start": "775829",
    "end": "782680"
  },
  {
    "text": "to collapse so what is that that is a",
    "start": "782680",
    "end": "789310"
  },
  {
    "start": "787000",
    "end": "787000"
  },
  {
    "text": "genomics analysis platform with specialized body file format is built",
    "start": "789310",
    "end": "794890"
  },
  {
    "text": "using Apache ivory which is a data format and oh and Parker and spot which",
    "start": "794890",
    "end": "801430"
  },
  {
    "text": "you top slightly is an open source project it's available on github feel free to write up and integrate very",
    "start": "801430",
    "end": "809829"
  },
  {
    "text": "easily we need appears to be a modern stock some basic requirements in running",
    "start": "809829",
    "end": "818200"
  },
  {
    "text": "and to be running yes you want launching him our cluster",
    "start": "818200",
    "end": "823710"
  },
  {
    "text": "is attached to the M to the master net and then install Allen over there and",
    "start": "823710",
    "end": "832460"
  },
  {
    "text": "you need to build a because source codes in use made into building so step step",
    "start": "832460",
    "end": "839820"
  },
  {
    "start": "836000",
    "end": "836000"
  },
  {
    "text": "at a time you get a repository and then so made them and then in a clone a good",
    "start": "839820",
    "end": "849510"
  },
  {
    "text": "clamp and they're there and then this builders for those of you familiar with",
    "start": "849510",
    "end": "855630"
  },
  {
    "text": "- you know very very basic standard steps to get back and I'm running in one",
    "start": "855630",
    "end": "862200"
  },
  {
    "text": "side and is running you get this prompt [Music]",
    "start": "862200",
    "end": "867839"
  },
  {
    "text": "now the places but yet that's Adam is ready to to work for you so produce PCF",
    "start": "869330",
    "end": "878370"
  },
  {
    "start": "875000",
    "end": "875000"
  },
  {
    "text": "some hundred genomes project so VCF files variable cell format files this is",
    "start": "878370",
    "end": "886530"
  },
  {
    "text": "how the whole thousand genomes project data we host an AWS s3 for free and we",
    "start": "886530",
    "end": "893640"
  },
  {
    "text": "make it publicly available as part for public dataset program for you to do your research so that's available you",
    "start": "893640",
    "end": "900510"
  },
  {
    "text": "can just get in there and start getting those parts analysis you want to do but one of the",
    "start": "900510",
    "end": "908250"
  },
  {
    "text": "steps we do with Adam submit we convert the VCF files and to have format which",
    "start": "908250",
    "end": "915420"
  },
  {
    "text": "sparklines was just parking and what is",
    "start": "915420",
    "end": "920490"
  },
  {
    "start": "917000",
    "end": "917000"
  },
  {
    "text": "converts to park a you have various options you can go back to Z which is",
    "start": "920490",
    "end": "927920"
  },
  {
    "text": "nice web Facebook where you can run either spark sequel or a skull if you",
    "start": "927920",
    "end": "935639"
  },
  {
    "text": "test your language of choice a lot of data centers graphic these days and what even from the come online the SSH",
    "start": "935639",
    "end": "942500"
  },
  {
    "text": "terminal that you're going into the master node you can run commands like",
    "start": "942500",
    "end": "948240"
  },
  {
    "text": "very simple here variable and say we read my five ten table they said okay",
    "start": "948240",
    "end": "960990"
  },
  {
    "text": "that needle straight away starts start running and queries sir",
    "start": "960990",
    "end": "968510"
  },
  {
    "start": "966000",
    "end": "966000"
  },
  {
    "text": "so let's let's quickly go to that data set a little bit more that you know mix industry is in the midst of an alien's",
    "start": "968510",
    "end": "974670"
  },
  {
    "text": "pollution because the drop in prices to sequence genomes you notice it's not",
    "start": "974670",
    "end": "980850"
  },
  {
    "text": "central to many advances when did you know this sequence and analyze raw",
    "start": "980850",
    "end": "986819"
  },
  {
    "text": "sequencing files a process and multi-step workflow to identify where your genome differs from a standard",
    "start": "986819",
    "end": "994079"
  },
  {
    "text": "reference so we have standard reference and then you find the differences with",
    "start": "994079",
    "end": "1000440"
  },
  {
    "text": "whatever your subject is your variations are stored in a variation call Foreman",
    "start": "1000440",
    "end": "1006800"
  },
  {
    "text": "is dimension which is then combined with other individuals to enable population",
    "start": "1006800",
    "end": "1012610"
  },
  {
    "text": "scale analysis many of these data's is a public variable the project that you",
    "start": "1012610",
    "end": "1017620"
  },
  {
    "text": "mentioned quickly and sir questions a genomic scientists might have what",
    "start": "1017620",
    "end": "1025240"
  },
  {
    "start": "1018000",
    "end": "1018000"
  },
  {
    "text": "variations in genomic cause the risk of developing particular disease or what",
    "start": "1025240",
    "end": "1031808"
  },
  {
    "text": "position in the genome has a known level of variation suggesting that the data",
    "start": "1031809",
    "end": "1037000"
  },
  {
    "text": "quality hasn't met what variations in genomic events how individual response",
    "start": "1037000",
    "end": "1044770"
  },
  {
    "text": "to a particular drug race response to a",
    "start": "1044770",
    "end": "1050020"
  },
  {
    "text": "particular truck does a group of individuals contain a higher frequency",
    "start": "1050020",
    "end": "1055120"
  },
  {
    "text": "of genomic variant known to alter response to a drug relative to a general",
    "start": "1055120",
    "end": "1061090"
  },
  {
    "text": "population so all this work on the genetic genomic analysis can be combs",
    "start": "1061090",
    "end": "1069640"
  },
  {
    "text": "reflects a paradigm corner select aggregates annotate and some of our",
    "start": "1069640",
    "end": "1075040"
  },
  {
    "text": "genomics customers such as human longevity in routinely uses with this",
    "start": "1075040",
    "end": "1080350"
  },
  {
    "text": "pattern in their work so we look at what",
    "start": "1080350",
    "end": "1085960"
  },
  {
    "start": "1083000",
    "end": "1083000"
  },
  {
    "text": "what I meant by the selectively identity paradigm to select specified a cohort of",
    "start": "1085960",
    "end": "1092440"
  },
  {
    "text": "individuals you select them and meeting a certain criteria incubation seven this is there anything",
    "start": "1092440",
    "end": "1100800"
  },
  {
    "text": "I could basin and track response would be their age which with a particular BMI it could be the entire population so",
    "start": "1100800",
    "end": "1110840"
  },
  {
    "text": "aggregate that generates summary statistics of the genomic variation across that for heart that you selected",
    "start": "1110840",
    "end": "1117240"
  },
  {
    "text": "and then annotated assign meaning to each of the variants by joining on no",
    "start": "1117240",
    "end": "1123030"
  },
  {
    "text": "information about each variant so we",
    "start": "1123030",
    "end": "1128730"
  },
  {
    "start": "1126000",
    "end": "1126000"
  },
  {
    "text": "went to that quickly as I'm going to be a demo but I'm gonna skip some of the",
    "start": "1128730",
    "end": "1133860"
  },
  {
    "text": "steps because it takes time quickly jump",
    "start": "1133860",
    "end": "1138990"
  },
  {
    "start": "1137000",
    "end": "1137000"
  },
  {
    "text": "into so aluminum strokes I'm being stopped added last night and to run the",
    "start": "1138990",
    "end": "1145290"
  },
  {
    "text": "spot the all these steps at the end of the time this point you guys to a block",
    "start": "1145290",
    "end": "1150450"
  },
  {
    "text": "where all the codes away we want to try it out in stone atom and then I run and",
    "start": "1150450",
    "end": "1157560"
  },
  {
    "text": "the command which is available could VCF file and to okay so could you go back so",
    "start": "1157560",
    "end": "1167730"
  },
  {
    "start": "1166000",
    "end": "1166000"
  },
  {
    "text": "what are we going to do in today's demo gonna focus on a particular chromosome chromosome 22 for all 2500 for sample is",
    "start": "1167730",
    "end": "1176460"
  },
  {
    "text": "a palomino project the data set you can scale the page size that Kloster",
    "start": "1176460",
    "end": "1182010"
  },
  {
    "text": "depending whether you're looking at Jeff's chromosome 22 or entire genomes for my case it's been a virtual cluster",
    "start": "1182010",
    "end": "1189680"
  },
  {
    "text": "to the work but if you're going to look at beyond chromosome 22 all the",
    "start": "1189680",
    "end": "1195070"
  },
  {
    "text": "[Music] and then finally reduce your party fun",
    "start": "1195070",
    "end": "1202450"
  },
  {
    "text": "to me the film's you week so I don't need everything in that and that's the",
    "start": "1202450",
    "end": "1208060"
  },
  {
    "text": "command do that and then how many usual reference date what I'm gonna say that is very important and and then compare",
    "start": "1208060",
    "end": "1216490"
  },
  {
    "start": "1209000",
    "end": "1209000"
  },
  {
    "text": "with it 2005 and they said that I had so I'm",
    "start": "1216490",
    "end": "1222310"
  },
  {
    "text": "going to use a publicly available data set and that's available called a clean bore dataset and then this is the few",
    "start": "1222310",
    "end": "1231820"
  },
  {
    "text": "steps to copy the data set and cheers three firm and now launched as an Athena",
    "start": "1231820",
    "end": "1240300"
  },
  {
    "text": "200 pairs so it's very important to see the power of the King and why I might suggest anything in life so at this",
    "start": "1240300",
    "end": "1247330"
  },
  {
    "text": "point of time has been very funny because you actually want dataset that was publicly available soon s3 another",
    "start": "1247330",
    "end": "1257110"
  },
  {
    "text": "cluster you do not know we're not using anything complicated as I will show you",
    "start": "1257110",
    "end": "1264730"
  },
  {
    "text": "just throw you a web interface where you can start writing queries on the water that we produce to my Athena because you",
    "start": "1264730",
    "end": "1273310"
  },
  {
    "text": "can start squaring instantly serverless is no ETM schema on read very good",
    "start": "1273310",
    "end": "1279730"
  },
  {
    "text": "do you not spending hours and days and pushed a kid to attend a warehouse which",
    "start": "1279730",
    "end": "1284740"
  },
  {
    "text": "conforms to a particular human you have to put in schema on read you might define the scheme all right you know",
    "start": "1284740",
    "end": "1292950"
  },
  {
    "text": "you pay for query only pay for data scan you know spinning up infrastructure is a",
    "start": "1293690",
    "end": "1299509"
  },
  {
    "text": "managed service so it just gives you a community if you're not using it you",
    "start": "1299509",
    "end": "1305389"
  },
  {
    "text": "know Spain to anything you penguin you and you start creating the data and it's",
    "start": "1305389",
    "end": "1311179"
  },
  {
    "text": "open powerful standard builder presto run standard SQL so again very important run",
    "start": "1311179",
    "end": "1317899"
  },
  {
    "text": "standard SQL not learning any new tricks new language for analysis you need to",
    "start": "1317899",
    "end": "1324409"
  },
  {
    "text": "know SQL it's really fast and interactive performance in a large",
    "start": "1324409",
    "end": "1330739"
  },
  {
    "text": "dataset I don't know how much time we get we can query the billions of rows of data in less than 10 seconds using this",
    "start": "1330739",
    "end": "1339789"
  },
  {
    "text": "and almost interesting we see the data is not on the server dated separate",
    "start": "1339789",
    "end": "1345799"
  },
  {
    "text": "sitting on s3 we are trained computers which is which is very power",
    "start": "1345799",
    "end": "1352149"
  },
  {
    "text": "I guess someone has to degeneracy",
    "start": "1355300",
    "end": "1367020"
  },
  {
    "text": "[Music]",
    "start": "1373000",
    "end": "1376130"
  },
  {
    "text": "as when it's just a great medicine - yeah it's the same thing my lady",
    "start": "1383539",
    "end": "1401148"
  },
  {
    "text": "yes there is a process the open beta protocol is a page that he needed to talk to how he did participate to it sir",
    "start": "1401480",
    "end": "1408410"
  },
  {
    "text": "we have people from all verticals in Mt engineering degree sets in ended said and so good what you mentioned once we",
    "start": "1408410",
    "end": "1419480"
  },
  {
    "text": "analyze the data and you know what genes are replicating that en etc most of the",
    "start": "1419480",
    "end": "1428930"
  },
  {
    "text": "time the active sometimes is in heaven those errors are responsible to diseases",
    "start": "1428930",
    "end": "1434390"
  },
  {
    "text": "or animals often and also interesting if those same errors are also important for",
    "start": "1434390",
    "end": "1440720"
  },
  {
    "text": "our evolution that drives it forward so",
    "start": "1440720",
    "end": "1446420"
  },
  {
    "text": "when we're doing these analysis we're finding results what happens the peanuts stores and resolves on Institute as well",
    "start": "1446420",
    "end": "1453380"
  },
  {
    "text": "so you can make that dataset publicly readable or 3s3 you give it to a",
    "start": "1453380",
    "end": "1460250"
  },
  {
    "text": "particular account so you think you can have owners restrict access within a community or you can make it public so",
    "start": "1460250",
    "end": "1467740"
  },
  {
    "text": "this is again I did last night rather than I'm going to do it now to create a",
    "start": "1468340",
    "end": "1473360"
  },
  {
    "text": "database ten use standard SQL syntax print a space and Athena green pigments",
    "start": "1473360",
    "end": "1478700"
  },
  {
    "start": "1477000",
    "end": "1477000"
  },
  {
    "text": "and then create and take notice that external team which is saying that the",
    "start": "1478700",
    "end": "1486950"
  },
  {
    "text": "data external to systems exam and you see the location over here I'm saying s3",
    "start": "1486950",
    "end": "1493550"
  },
  {
    "text": "so everything else stand is it's seven high Q L and I'm pointing me",
    "start": "1493550",
    "end": "1499370"
  },
  {
    "text": "too they said that I have on my feet and",
    "start": "1499370",
    "end": "1504980"
  },
  {
    "text": "I was saying stored as Park Asia suggesting that the location is biggest",
    "start": "1504980",
    "end": "1510650"
  },
  {
    "text": "or the spot okay so that's my first a like create don't create another table",
    "start": "1510650",
    "end": "1516860"
  },
  {
    "text": "which is the reference data that I downloaded from Cleveland so that I can compare my dataset with reference datum",
    "start": "1516860",
    "end": "1523430"
  },
  {
    "text": "so again same same thing by interesting what I want to the point of the year you see that was a park a volume City one as",
    "start": "1523430",
    "end": "1531410"
  },
  {
    "start": "1525000",
    "end": "1525000"
  },
  {
    "text": "to this in this one this is a text type",
    "start": "1531410",
    "end": "1536620"
  },
  {
    "text": "separated file stored in application s3 that shows you the dignity of the Tina",
    "start": "1536620",
    "end": "1544580"
  },
  {
    "text": "to be able to work various data formats the same interface and what we're going to do in Excel",
    "start": "1544580",
    "end": "1550520"
  },
  {
    "text": "we're going to combine those two tables right so pink body so you have quite",
    "start": "1550520",
    "end": "1555650"
  },
  {
    "text": "well together sitting in a format of parquet we didn't care about you worry",
    "start": "1555650",
    "end": "1561020"
  },
  {
    "text": "about how we story debating what Foreman mr. in the data we through a definition",
    "start": "1561020",
    "end": "1566510"
  },
  {
    "text": "to the data on the read rather forcing the data to a particular definition we",
    "start": "1566510",
    "end": "1572630"
  },
  {
    "text": "met the data in and then we assigned it on reading so that saves a lot of time and then completely people native form",
    "start": "1572630",
    "end": "1580580"
  },
  {
    "text": "that we created in a similar table structure and I'm going to join them",
    "start": "1580580",
    "end": "1585620"
  },
  {
    "text": "together so the first query will do is applying the Select aggregate and",
    "start": "1585620",
    "end": "1591860"
  },
  {
    "text": "annotate paradigm so we're gonna try and find finds in Lingle population drug response what small molecules are drugs",
    "start": "1591860",
    "end": "1598700"
  },
  {
    "start": "1597000",
    "end": "1597000"
  },
  {
    "text": "I most likely to effect a sub population of individuals based on their genetic",
    "start": "1598700",
    "end": "1604250"
  },
  {
    "text": "information in this query gunrunner issue that you have some phenotype about",
    "start": "1604250",
    "end": "1611300"
  },
  {
    "text": "your population in this case assume that all the samples shared in",
    "start": "1611300",
    "end": "1616809"
  },
  {
    "text": "the pattern in a 12 part of the specifically more graphic so what are",
    "start": "1616809",
    "end": "1622179"
  },
  {
    "text": "you gonna do do something good pushed on I'm going to filter the samples aggregate join it with a",
    "start": "1622179",
    "end": "1627970"
  },
  {
    "text": "reference data filter it out and order it let's try and see if the demo work so",
    "start": "1627970",
    "end": "1633279"
  },
  {
    "text": "I'd say so I saw the data in a bucket",
    "start": "1633279",
    "end": "1641100"
  },
  {
    "text": "widen us is to unjust to show you how the data looks like so that's the",
    "start": "1641100",
    "end": "1647830"
  },
  {
    "text": "clinvar data which is simply a text gzip file and if I go back the previous",
    "start": "1647830",
    "end": "1656649"
  },
  {
    "text": "folder and the thousand genomes data is stored after filtering as as a parquet",
    "start": "1656649",
    "end": "1668799"
  },
  {
    "text": "format and here the dot parquet Falls so that's my data set that we're gonna play",
    "start": "1668799",
    "end": "1676599"
  },
  {
    "text": "with now I'm going to quickly run a service called Amazon Tina right say I'm",
    "start": "1676599",
    "end": "1689019"
  },
  {
    "text": "gonna switch onto the scheme I called it kg for reason I can't remember and so",
    "start": "1689019",
    "end": "1694389"
  },
  {
    "text": "let's look at how big our data set is",
    "start": "1694389",
    "end": "1698099"
  },
  {
    "text": "live demo is already fun so yeah that's about one hundred and fifty two million",
    "start": "1702899",
    "end": "1710039"
  },
  {
    "text": "seven and eight seven thousand rows",
    "start": "1710039",
    "end": "1715269"
  },
  {
    "text": "approximately and it took about less than five seconds that shows you and the power",
    "start": "1715269",
    "end": "1721720"
  },
  {
    "text": "straightaway I'm going to quickly for for argument's sake I'm going to jump into it just to show the power of 18 I'm",
    "start": "1721720",
    "end": "1728830"
  },
  {
    "text": "gonna jump into another data set I wanted to show you guys default and so",
    "start": "1728830",
    "end": "1734769"
  },
  {
    "text": "this is this is another openly available data made available but New York taxi",
    "start": "1734769",
    "end": "1741970"
  },
  {
    "text": "service NYC taxi trips and it's got over Billy",
    "start": "1741970",
    "end": "1747370"
  },
  {
    "text": "in rows of data and I want to do a group boy so I want you to think about you",
    "start": "1747370",
    "end": "1752500"
  },
  {
    "text": "doing it with your existing data warehouse a group by over a billion rows of data and the data is not even in the",
    "start": "1752500",
    "end": "1759970"
  },
  {
    "text": "data warehouse it is somewhere in a different storage so if I run that see",
    "start": "1759970",
    "end": "1769270"
  },
  {
    "text": "how it takes right so 6.3 seconds over a",
    "start": "1769270",
    "end": "1778030"
  },
  {
    "text": "billion rows of data and I did a group by and some at the same time that it's",
    "start": "1778030",
    "end": "1786490"
  },
  {
    "text": "all on us three computers on latina and it data is nowhere near the computers on",
    "start": "1786490",
    "end": "1791980"
  },
  {
    "text": "s3 so that is that is powerful and just to just to show that I was not lying",
    "start": "1791980",
    "end": "1797740"
  },
  {
    "text": "look at the data I'm gonna do a quick count stir so now you can see how why",
    "start": "1797740",
    "end": "1804220"
  },
  {
    "text": "this becomes so powerful for someone doing genomics analysis right 2.5 billion genes each a sequences each",
    "start": "1804220",
    "end": "1812040"
  },
  {
    "text": "world population I do not have my head over 8 billion and then if we add the",
    "start": "1812040",
    "end": "1817540"
  },
  {
    "text": "other species as well and do comparison this is the dataset unless it's cheap",
    "start": "1817540",
    "end": "1823260"
  },
  {
    "text": "inexpensive to run store the data and to execute experiments wouldn't wouldn't",
    "start": "1823260",
    "end": "1828760"
  },
  {
    "text": "happen right so yeah that's about 1.2 billion rows of data straight away okay",
    "start": "1828760",
    "end": "1836710"
  },
  {
    "text": "let's quickly go back to our reason for today is the data set so I wrote the",
    "start": "1836710",
    "end": "1843670"
  },
  {
    "text": "query so that I don't do typos so this is my fast query but I wanted to run on",
    "start": "1843670",
    "end": "1851800"
  },
  {
    "text": "a teener all right",
    "start": "1851800",
    "end": "1858809"
  },
  {
    "text": "and no-no nana is my best practice just",
    "start": "1861740",
    "end": "1866760"
  },
  {
    "text": "so that I know what I'm running when I have quite a few queries in yeah whatever you the car suppose position is",
    "start": "1866760",
    "end": "1871980"
  },
  {
    "text": "it run that particular line yes that particular Road yeah good question so we",
    "start": "1871980",
    "end": "1881370"
  },
  {
    "text": "make Athena available through an API so and it's a JDBC connector so you can",
    "start": "1881370",
    "end": "1888540"
  },
  {
    "text": "have your existing desktop application that connects to it uses a JDBC",
    "start": "1888540",
    "end": "1893580"
  },
  {
    "text": "connector to connect to Athena could be a standard standard one so that you know",
    "start": "1893580",
    "end": "1900600"
  },
  {
    "text": "doc took about seven point one six it's reasonably complex query if let's have a",
    "start": "1900600",
    "end": "1906660"
  },
  {
    "text": "quick look at the query itself you know again we decided going to look at any",
    "start": "1906660",
    "end": "1913440"
  },
  {
    "text": "and twelve sequence and yes that ran",
    "start": "1913440",
    "end": "1919310"
  },
  {
    "text": "very fast I think so quickly going back",
    "start": "1919310",
    "end": "1924480"
  },
  {
    "text": "to the presentation so what did that",
    "start": "1924480",
    "end": "1930270"
  },
  {
    "text": "show us write that query when you",
    "start": "1930270",
    "end": "1936690"
  },
  {
    "start": "1933000",
    "end": "1933000"
  },
  {
    "text": "inspect what we could clearly see is we found a high frequency of variants",
    "start": "1936690",
    "end": "1943020"
  },
  {
    "text": "associated with the metabolism of I can't pronounce it so did debris so",
    "start": "1943020",
    "end": "1949290"
  },
  {
    "text": "Queen right so based on the data set I ran I found a high frequency of variants",
    "start": "1949290",
    "end": "1955230"
  },
  {
    "text": "associated with it so let's go back and look at the results again apologies to",
    "start": "1955230",
    "end": "1960480"
  },
  {
    "text": "change screens so if you can see it",
    "start": "1960480",
    "end": "1967580"
  },
  {
    "text": "right yeah so poor metabolism of that",
    "start": "1967580",
    "end": "1973610"
  },
  {
    "text": "can everyone see it so I mean just expand it a little bit alright okay",
    "start": "1973610",
    "end": "1982430"
  },
  {
    "text": "say right now what are we gonna next as",
    "start": "1982430",
    "end": "1991950"
  },
  {
    "text": "a next step what we want to see is we can do some quality control look at okay",
    "start": "1991950",
    "end": "1997440"
  },
  {
    "text": "so you found we found a variant and now let's see is that a false positive or",
    "start": "1997440",
    "end": "2002480"
  },
  {
    "text": "not and yeah in this query the entire population is needed we note that",
    "start": "2002480",
    "end": "2008510"
  },
  {
    "text": "particular one so I'm going to run another set of query on 18 again say",
    "start": "2008510",
    "end": "2016100"
  },
  {
    "text": "what is my so I'm going to choose this query looks reasonably similar but you",
    "start": "2016100",
    "end": "2022730"
  },
  {
    "text": "use the entire data set and now so just to go back to 18 again I'm going to use",
    "start": "2022730",
    "end": "2028820"
  },
  {
    "text": "a new query so you can open a new window and run the query that way",
    "start": "2028820",
    "end": "2035350"
  },
  {
    "text": "and hopefully is gonna come back and show us something interesting right so",
    "start": "2045460",
    "end": "2057129"
  },
  {
    "text": "what do we see we see what we noticed before is coming both as a pathogenic",
    "start": "2057130",
    "end": "2063980"
  },
  {
    "text": "and also as a benign and so there is which shows which shows you is a data",
    "start": "2063980",
    "end": "2070520"
  },
  {
    "text": "quality aspect of that we need to revise the data and next time you can run the query you're going to eliminate and that",
    "start": "2070520",
    "end": "2076780"
  },
  {
    "text": "particular data set right with that in",
    "start": "2076780",
    "end": "2085908"
  },
  {
    "text": "mind what yeah so that's the quality",
    "start": "2085909",
    "end": "2091908"
  },
  {
    "start": "2090000",
    "end": "2090000"
  },
  {
    "text": "control from the results the highest frequency results have conflicting information being listed both as",
    "start": "2091909",
    "end": "2098150"
  },
  {
    "text": "potential disease-causing and benign in genomics variants with a high frequency and less likely to cause a disease your",
    "start": "2098150",
    "end": "2106070"
  },
  {
    "text": "quick analysis allows you to discount the pathogenic clinical significance annotation of these high generative",
    "start": "2106070",
    "end": "2112610"
  },
  {
    "text": "frequency variants right so what I hopefully was able to demonstrate to you",
    "start": "2112610",
    "end": "2119000"
  },
  {
    "text": "guys is very quickly and very inexpensively you ran queries on a large massively",
    "start": "2119000",
    "end": "2127070"
  },
  {
    "text": "large data sets and I want to quickly go through is how other customers do that now so first of all if you got a phone",
    "start": "2127070",
    "end": "2135470"
  },
  {
    "text": "as a QR image of whatever we did is now available the source code and everything",
    "start": "2135470",
    "end": "2141590"
  },
  {
    "text": "is available in this blog which Aaron is also a Solutions Architect but he's a",
    "start": "2141590",
    "end": "2147980"
  },
  {
    "text": "doctor he's got a PhD he knows more about the topic than I do and he he's",
    "start": "2147980",
    "end": "2153020"
  },
  {
    "text": "written this blog I really like it I wanted to share with you guys and the",
    "start": "2153020",
    "end": "2158150"
  },
  {
    "text": "URL is also available that if you don't want to take the Cure image and I also",
    "start": "2158150",
    "end": "2163760"
  },
  {
    "text": "wanted to point to you guys sorry you you don't think you got it so I want to talk you talk to you about reinvent this",
    "start": "2163760",
    "end": "2170960"
  },
  {
    "start": "2169000",
    "end": "2169000"
  },
  {
    "text": "year in December we",
    "start": "2170960",
    "end": "2175330"
  },
  {
    "text": "pecking talk about a project the deed and that is available a YouTube video",
    "start": "2176440",
    "end": "2184840"
  },
  {
    "text": "very powerful and it talks about how in a how inexpensive it was to run an",
    "start": "2184840",
    "end": "2193160"
  },
  {
    "text": "experiment which normally would take many years I think initially took him a",
    "start": "2193160",
    "end": "2198320"
  },
  {
    "text": "good few years to even think about how they could do it on AWS say they used",
    "start": "2198320",
    "end": "2206560"
  },
  {
    "text": "remember yeah 5800 whole whole genome from two",
    "start": "2206560",
    "end": "2212720"
  },
  {
    "text": "thousand eight hundred cancer donors and did RNA sequence of data the data grew",
    "start": "2212720",
    "end": "2220100"
  },
  {
    "text": "from three hundred terabytes nine hundred terabytes and they use fourteen cloud and HPC environments and at some",
    "start": "2220100",
    "end": "2228050"
  },
  {
    "text": "point they were running fifteen thousand course to do the analysis and they found",
    "start": "2228050",
    "end": "2233240"
  },
  {
    "text": "AWS extremely useful and often more",
    "start": "2233240",
    "end": "2238460"
  },
  {
    "text": "flexible than the open stack platforms they also were running experiments in",
    "start": "2238460",
    "end": "2243710"
  },
  {
    "text": "parallel and yeah have a look at that video is a good it's worth listening to",
    "start": "2243710",
    "end": "2250400"
  },
  {
    "text": "it then I wanted to also highlight to you with we had another blog very useful",
    "start": "2250400",
    "end": "2257869"
  },
  {
    "start": "2251000",
    "end": "2251000"
  },
  {
    "text": "so this is for data again you say using",
    "start": "2257869",
    "end": "2263359"
  },
  {
    "text": "here MA rather than Athena I demonstrate Athena so again we've got we've got a whole area of tools you have to choose",
    "start": "2263359",
    "end": "2269660"
  },
  {
    "text": "the right ones that you need for that particular exam experiment so did this",
    "start": "2269660",
    "end": "2277310"
  },
  {
    "text": "this particular project and talks about we need to over thirteen years and several billions of dollars to do a",
    "start": "2277310",
    "end": "2284869"
  },
  {
    "text": "particular project that was done under three three thousand US dollars today in the cloud so yes that's very useful and",
    "start": "2284869",
    "end": "2295010"
  },
  {
    "text": "again there's a link to it for you to listen in and they use Amazon redshift",
    "start": "2295010",
    "end": "2300820"
  },
  {
    "text": "along with EMR for this particular experiment and then I want those are is again a",
    "start": "2300820",
    "end": "2309380"
  },
  {
    "text": "very popular tool for data scientists say by informatics yeah so by a",
    "start": "2309380",
    "end": "2316520"
  },
  {
    "text": "conductor there is an our library our packet dedicated to run our",
    "start": "2316520",
    "end": "2322880"
  },
  {
    "text": "experimentation and genomics data set and that you can run along with and as a redshift again thus that's a blog and",
    "start": "2322880",
    "end": "2331280"
  },
  {
    "text": "that Chris wrote and that's available if you wanna take your image of it and try",
    "start": "2331280",
    "end": "2337040"
  },
  {
    "text": "it out yourself is very powerful yeah",
    "start": "2337040",
    "end": "2343160"
  },
  {
    "text": "some more homework interested so we recently published blocks a creative",
    "start": "2343160",
    "end": "2348950"
  },
  {
    "text": "healthcare data hub with AWS and mirth connect and it talks about step by step",
    "start": "2348950",
    "end": "2354770"
  },
  {
    "text": "guides on how to do that and one of our solutions architect also recently wrote",
    "start": "2354770",
    "end": "2360980"
  },
  {
    "text": "a blog about readmission predictions and so in a readmissions costs every comment",
    "start": "2360980",
    "end": "2367340"
  },
  {
    "text": "a huge amount of money and how to do some predictions using that and that's also available on our website and our",
    "start": "2367340",
    "end": "2374720"
  },
  {
    "text": "blog and finally I want to go through another recent block that one of our",
    "start": "2374720",
    "end": "2382280"
  },
  {
    "text": "Solutions Architect Bell wrote recently so again in this particular one if I",
    "start": "2382280",
    "end": "2388940"
  },
  {
    "text": "quickly go back in this particular one he had connected devices such as heart",
    "start": "2388940",
    "end": "2395090"
  },
  {
    "text": "rate monitor and he used Amazon IOT pushed the data through Amazon Canisius",
    "start": "2395090",
    "end": "2400370"
  },
  {
    "text": "stored in s3 and use athina like I did in this particular demo and then once",
    "start": "2400370",
    "end": "2407690"
  },
  {
    "text": "the analysis was done in Athena he used Amazon quick site for BI visualization of exactly what he was looking at and if",
    "start": "2407690",
    "end": "2414560"
  },
  {
    "text": "you want to have a look at it is also available on our blog and you can try it out very very easily",
    "start": "2414560",
    "end": "2422680"
  },
  {
    "text": "see his quick side is connected to Athena yes exactly",
    "start": "2426059",
    "end": "2435369"
  },
  {
    "text": "yeah because the Athena also we also give you the SDK and a JDBC driver for",
    "start": "2435369",
    "end": "2442450"
  },
  {
    "text": "Athena so yeah that's just average heart rate by user ID over a date/time which",
    "start": "2442450",
    "end": "2448900"
  },
  {
    "text": "she plotted on quick side her oops",
    "start": "2448900",
    "end": "2453970"
  },
  {
    "text": "sorry sorry abuse direction well that's what I wanted to show you so how easily",
    "start": "2453970",
    "end": "2459660"
  },
  {
    "text": "so possible questions",
    "start": "2459660",
    "end": "2463380"
  },
  {
    "text": "so I have a degree in biophysics so this is interesting to me I'm just wondering",
    "start": "2466480",
    "end": "2472130"
  },
  {
    "text": "if there's been any advances in artificial intelligence deep learning and applied through these genomic data",
    "start": "2472130",
    "end": "2477770"
  },
  {
    "text": "sets because I'm a programmer I won't have a clue where to create algorithms to draw parents permission or make",
    "start": "2477770",
    "end": "2484360"
  },
  {
    "text": "basically random strings so you know you know Cagle as a data scientist II",
    "start": "2484360",
    "end": "2489800"
  },
  {
    "text": "probably know Kegel is like a data science community they are actually running a competition at the moment on",
    "start": "2489800",
    "end": "2496460"
  },
  {
    "text": "trying to find cancer related genes using a data science project so there's",
    "start": "2496460",
    "end": "2503630"
  },
  {
    "text": "a competition you feel free to join it and and yet there are lots of libraries deep learning libraries like MX net you",
    "start": "2503630",
    "end": "2511430"
  },
  {
    "text": "can use for example let's let's look at image recognition right so if you can't",
    "start": "2511430",
    "end": "2518150"
  },
  {
    "text": "have scan of the biopsy data of various cells let's look at something like a",
    "start": "2518150",
    "end": "2525350"
  },
  {
    "text": "lung lung cancer cell and if we analyze it with deep learning image recognition",
    "start": "2525350",
    "end": "2532010"
  },
  {
    "text": "and find a pattern if the machine develops pattern so you can utilize that",
    "start": "2532010",
    "end": "2537460"
  },
  {
    "text": "in terms of detecting lung cancer early right so the answer to your question is",
    "start": "2537460",
    "end": "2542900"
  },
  {
    "text": "yes there is a huge amount of research especially on deep learning that's currently ongoing in terms of solving",
    "start": "2542900",
    "end": "2551090"
  },
  {
    "text": "these particular challenges for society",
    "start": "2551090",
    "end": "2555760"
  }
]
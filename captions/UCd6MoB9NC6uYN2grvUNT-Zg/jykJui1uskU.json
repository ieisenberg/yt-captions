[
  {
    "start": "0",
    "end": "36000"
  },
  {
    "text": "good afternoon New York I'm Sunil Mallya I'm part of the machine learning",
    "start": "60",
    "end": "5130"
  },
  {
    "text": "solutions tab team at AWS today we're actually going to talk about how we can",
    "start": "5130",
    "end": "11160"
  },
  {
    "text": "use sage maker to simplify machine learning just get a quick sense of who's",
    "start": "11160",
    "end": "17130"
  },
  {
    "text": "in the room how many of you would consider yourself first time or new to machine learning that's a living",
    "start": "17130",
    "end": "26490"
  },
  {
    "text": "majority and my hope is by the end you actually get a good sense of how you can",
    "start": "26490",
    "end": "31679"
  },
  {
    "text": "simplify apply machine learning to your business problems machine learning has",
    "start": "31679",
    "end": "38850"
  },
  {
    "start": "36000",
    "end": "165000"
  },
  {
    "text": "been helpful in solving some of the hardest problems in computer science ranging from be it face detection to",
    "start": "38850",
    "end": "46170"
  },
  {
    "text": "analysis to medical imaging with cancer etc so we've been applying this at",
    "start": "46170",
    "end": "54289"
  },
  {
    "text": "Amazon for more than 20 years now and you've seen this with our personalized",
    "start": "54289",
    "end": "60600"
  },
  {
    "text": "recommendation when you go to the amazon.com website you see the personalized recommendations on products",
    "start": "60600",
    "end": "67760"
  },
  {
    "text": "in our inventory and fulfillment centers we have robots who actually lift and",
    "start": "67760",
    "end": "75090"
  },
  {
    "text": "bring the ordered items to actual workers and be drones and also something",
    "start": "75090",
    "end": "86640"
  },
  {
    "text": "that's really common these days with the Alexa device the echo device you see us",
    "start": "86640",
    "end": "93140"
  },
  {
    "text": "interacting with a computer in a human language interface and he also so there",
    "start": "93140",
    "end": "101700"
  },
  {
    "text": "you might have seen this at Amazon go store where you can literally walk into a store and pick up things almost feels",
    "start": "101700",
    "end": "108509"
  },
  {
    "text": "like shoplifting but you get charged we",
    "start": "108509",
    "end": "114240"
  },
  {
    "text": "have tens of thousands of customers running machine learning workloads on AWS today and it varies from",
    "start": "114240",
    "end": "123869"
  },
  {
    "text": "you almost every industry vertical is represented here and you can look at in the financial sector into it",
    "start": "123869",
    "end": "131190"
  },
  {
    "text": "Moody's using Amazon AWS to actually build machine",
    "start": "131190",
    "end": "138570"
  },
  {
    "text": "learning solutions you see finra as well and then if you go",
    "start": "138570",
    "end": "145470"
  },
  {
    "text": "to other sectors of GE healthcare and and certain are actually using machine",
    "start": "145470",
    "end": "154020"
  },
  {
    "text": "learning in healthcare and we have a lot of startups including clarify AI etc ZocDoc using machine",
    "start": "154020",
    "end": "163620"
  },
  {
    "text": "learning on AWS what's our mission we",
    "start": "163620",
    "end": "170250"
  },
  {
    "start": "165000",
    "end": "350000"
  },
  {
    "text": "literally want to put machine learning in the hands of every developer we want",
    "start": "170250",
    "end": "176190"
  },
  {
    "text": "to simplify the machine learning process and we want you to concentrate on applying machine learning and unlocking",
    "start": "176190",
    "end": "183450"
  },
  {
    "text": "business potential let's take a look at",
    "start": "183450",
    "end": "188490"
  },
  {
    "text": "how we categorize different services and how we look at machine learning at AWS",
    "start": "188490",
    "end": "195080"
  },
  {
    "text": "so at the top level you have application services here we actually provide",
    "start": "195080",
    "end": "202970"
  },
  {
    "text": "whether it's computer vision or natural language services as an API which means",
    "start": "202970",
    "end": "209580"
  },
  {
    "text": "you as a developer with few lines of code can actually have access to pre",
    "start": "209580",
    "end": "216150"
  },
  {
    "text": "trained models that our research teams have worked hard on building and as far",
    "start": "216150",
    "end": "221190"
  },
  {
    "text": "as you're concerned you can just call an API and do facial analysis or get",
    "start": "221190",
    "end": "228200"
  },
  {
    "text": "understanding of natural language or your processing for sentences or",
    "start": "228200",
    "end": "234270"
  },
  {
    "text": "documents etc also you can build chat BOTS using Amazon Lex now a layer or the",
    "start": "234270",
    "end": "244350"
  },
  {
    "text": "bottommost layer is where we say the bleeding edge this is where a lot of the",
    "start": "244350",
    "end": "250560"
  },
  {
    "text": "research where you're building a lot of cutting-edge technology we have provided",
    "start": "250560",
    "end": "257130"
  },
  {
    "text": "and made it easy for you to access the latest and greatest of deep learning and",
    "start": "257130",
    "end": "263669"
  },
  {
    "text": "machine learning frameworks like patchy MX NAT pie tarts tensorflow all that is accessible and",
    "start": "263669",
    "end": "270169"
  },
  {
    "text": "we'll sort of concentrate more on the platform side which is Amazon sage maker",
    "start": "270169",
    "end": "275580"
  },
  {
    "text": "today now if you're a data scientist or",
    "start": "275580",
    "end": "283050"
  },
  {
    "text": "you happen to be an advanced researcher or practitioner we have we provide the",
    "start": "283050",
    "end": "291000"
  },
  {
    "text": "most popular of the deep learning frameworks now from an infrastructure",
    "start": "291000",
    "end": "297060"
  },
  {
    "text": "point of view we have we provide access to the latest and technology here with",
    "start": "297060",
    "end": "304110"
  },
  {
    "text": "respect to GPU we provide the volta hundreds GPUs which have you know pair",
    "start": "304110",
    "end": "312210"
  },
  {
    "text": "of flops of compute or 5000 tensor cores and proprietary and we link to link",
    "start": "312210",
    "end": "320160"
  },
  {
    "text": "between the GPU interconnect but also we have the latest in the CPU world as well",
    "start": "320160",
    "end": "328620"
  },
  {
    "text": "from Intel so we have skylake GPUs in our c5 family where our instances have",
    "start": "328620",
    "end": "336599"
  },
  {
    "text": "72 V CPUs 144 gigs of memory but also",
    "start": "336599",
    "end": "342680"
  },
  {
    "text": "you know improved instruction set the AIX 512 and the nitro hypervisor as well",
    "start": "342680",
    "end": "351560"
  },
  {
    "start": "350000",
    "end": "658000"
  },
  {
    "text": "let's get an idea of what a typical machine learning workflow looks like you",
    "start": "352729",
    "end": "361260"
  },
  {
    "text": "always start with the business problem so clearly define this is the problem we're trying to solve and the next step",
    "start": "361260",
    "end": "370380"
  },
  {
    "text": "is you know you have business objectives but this needs to be formalized as a",
    "start": "370380",
    "end": "375510"
  },
  {
    "text": "machine learning problem whether you're trying to classify something or you're trying to predict something or forecast",
    "start": "375510",
    "end": "382889"
  },
  {
    "text": "so we need to model the problem with the right objective functions the next",
    "start": "382889",
    "end": "389400"
  },
  {
    "text": "process we go after data collection we try and identify or clean the data right",
    "start": "389400",
    "end": "397260"
  },
  {
    "text": "like they did the data in practice is probably not in the format directly that we want to consume the",
    "start": "397260",
    "end": "405039"
  },
  {
    "text": "next point is we want to understand what are the features that are in the data",
    "start": "405039",
    "end": "410800"
  },
  {
    "text": "that are going to help us solve the problem at hand and so the next step is",
    "start": "410800",
    "end": "417750"
  },
  {
    "text": "we pick a model or an algorithm that we think is gonna solve and then we're",
    "start": "417750",
    "end": "424150"
  },
  {
    "text": "going to build it we're gonna tune the model we're gonna evaluate at this point",
    "start": "424150",
    "end": "429759"
  },
  {
    "text": "we sort of want to check hey has this model or algorithm solve the problem",
    "start": "429759",
    "end": "436930"
  },
  {
    "text": "that we are trying to tackle if no you go back right like we go back hey is",
    "start": "436930",
    "end": "444160"
  },
  {
    "text": "that more data that I can collect can I extract new features that are actually",
    "start": "444160",
    "end": "449800"
  },
  {
    "text": "going to help me solve the problem so it's a very iterative process and",
    "start": "449800",
    "end": "455190"
  },
  {
    "text": "sometimes it also involves augmentation of features it can be for example let's",
    "start": "455190",
    "end": "462580"
  },
  {
    "text": "say time series as an example you you might want to if you have discrete or",
    "start": "462580",
    "end": "469090"
  },
  {
    "text": "continuous time maybe aggregating or adding another feature saying hey is this weekend or not or is this day or",
    "start": "469090",
    "end": "476590"
  },
  {
    "text": "night is may help your model to better solve the problem so things like these",
    "start": "476590",
    "end": "482470"
  },
  {
    "text": "you do at the step and then once you have met the business objectives what",
    "start": "482470",
    "end": "489310"
  },
  {
    "text": "you'll do next is go build or deploy the",
    "start": "489310",
    "end": "494530"
  },
  {
    "text": "model in production and then we do the predictions but really important that",
    "start": "494530",
    "end": "500530"
  },
  {
    "text": "this step is you you want to know if how a your model infrastructure is performing but also you want to really",
    "start": "500530",
    "end": "508509"
  },
  {
    "text": "be sure that whatever predictions are being happening was the performance",
    "start": "508509",
    "end": "513578"
  },
  {
    "text": "accuracy because oftentimes what you have in the wild may not know translate",
    "start": "513579",
    "end": "521169"
  },
  {
    "text": "what you've built so you want to be constantly monitoring and checking what as how does it looking in production and",
    "start": "521169",
    "end": "529050"
  },
  {
    "text": "then at this point with that information that you have you feed that back",
    "start": "529050",
    "end": "535360"
  },
  {
    "text": "hey do I need more data can i rebuild a model collect more data so it's it's a",
    "start": "535360",
    "end": "541089"
  },
  {
    "text": "continuous cycle of building models identifying the performance tuning it",
    "start": "541089",
    "end": "548259"
  },
  {
    "text": "and then redeploying it so let's",
    "start": "548259",
    "end": "554980"
  },
  {
    "text": "identify like who are the actors for each of these steps so if the analysts",
    "start": "554980",
    "end": "561579"
  },
  {
    "text": "who help you frame the problem and you know this is where domain knowledge is",
    "start": "561579",
    "end": "568209"
  },
  {
    "text": "really important right like if you're a finance or healthcare there might be specific things that help you formulate",
    "start": "568209",
    "end": "574809"
  },
  {
    "text": "the problem and data collection and ingestion we've we have services that",
    "start": "574809",
    "end": "581920"
  },
  {
    "text": "help you clean the data format the data or that ecosystem exists today with",
    "start": "581920",
    "end": "590189"
  },
  {
    "text": "Amazon s3 as your data storage to help you store but once you have that you've",
    "start": "590189",
    "end": "596739"
  },
  {
    "text": "serverless AWS glue service to do ETL if",
    "start": "596739",
    "end": "601869"
  },
  {
    "text": "that attina again you can query at scale with the data that's in s3 but you can also use",
    "start": "601869",
    "end": "609279"
  },
  {
    "text": "elastic MapReduce Amazon EMR a spark to transform the data create features have",
    "start": "609279",
    "end": "617499"
  },
  {
    "text": "that so next let's let's look at what",
    "start": "617499",
    "end": "625179"
  },
  {
    "text": "we're trying to do here is we're trying to do the underlying undifferentiated heavy lifting so that it's simpler for",
    "start": "625179",
    "end": "632379"
  },
  {
    "text": "our customers to build solutions on top of our services so with sage maker we'll",
    "start": "632379",
    "end": "640329"
  },
  {
    "text": "dive more deeper in in the coming slides but there's a hosted notebook",
    "start": "640329",
    "end": "646299"
  },
  {
    "text": "environment where you can explore the data understand what features all the",
    "start": "646299",
    "end": "652209"
  },
  {
    "text": "data analysis visualization and training is combined here with Amazon Sage maker",
    "start": "652209",
    "end": "660360"
  },
  {
    "start": "658000",
    "end": "858000"
  },
  {
    "text": "so let's come to where as a user or a developer data scientist where should",
    "start": "660360",
    "end": "667059"
  },
  {
    "text": "you be spending time that we have defined and agree on you know a machine learning process so I'd",
    "start": "667059",
    "end": "676180"
  },
  {
    "text": "like you to remember three things by the end of the talk first built",
    "start": "676180",
    "end": "682860"
  },
  {
    "text": "so with build we provide a notebook interface where you can go build up",
    "start": "682860",
    "end": "690180"
  },
  {
    "text": "where you can collaborate and build your notebooks second train once you identify",
    "start": "690180",
    "end": "696790"
  },
  {
    "text": "the problem formulated you code and you you say hey sage maker train the model",
    "start": "696790",
    "end": "703380"
  },
  {
    "text": "once you've trained that then you can go deploy the model on to your",
    "start": "703380",
    "end": "709240"
  },
  {
    "text": "infrastructure and we simplify this for you so typically as we talked with the",
    "start": "709240",
    "end": "716290"
  },
  {
    "text": "training you have the GPU and CPU option again with a deploy as well you've got",
    "start": "716290",
    "end": "722260"
  },
  {
    "text": "both the options also on the model",
    "start": "722260",
    "end": "727959"
  },
  {
    "text": "deployment side what we've seen a lot of customers tell us is using the c5 family",
    "start": "727959",
    "end": "733870"
  },
  {
    "text": "to host the models which have the Intel skylake GPUs your we've seen customers",
    "start": "733870",
    "end": "741130"
  },
  {
    "text": "get better price for performance with that to summarize with the build step we",
    "start": "741130",
    "end": "751510"
  },
  {
    "text": "have pre-built notebooks high-performance algorithms all that provided you as far as the building",
    "start": "751510",
    "end": "758410"
  },
  {
    "text": "aspect with training we've simplified training it's one-click training you can",
    "start": "758410",
    "end": "765339"
  },
  {
    "text": "also tune and auto tune your models as well and then deploy one click deploy",
    "start": "765339",
    "end": "772920"
  },
  {
    "text": "you have a scaleable end point where you don't need to manage your scaling",
    "start": "772920",
    "end": "781959"
  },
  {
    "text": "infrastructure so in all build train and deploy all of this is actually managed",
    "start": "781959",
    "end": "789100"
  },
  {
    "text": "by Amazon sage maker and taught to top",
    "start": "789100",
    "end": "795550"
  },
  {
    "text": "that compliance that are capabilities so Amazon sage maker is HIPAA eligibles",
    "start": "795550",
    "end": "803400"
  },
  {
    "text": "it's a pay-as-you-go service which means that if you happen to train your model",
    "start": "803400",
    "end": "809560"
  },
  {
    "text": "training happens to take 519 seconds you're only going to be charged for 519",
    "start": "809560",
    "end": "814660"
  },
  {
    "text": "seconds and to end encryption with kms the data stored in s3 when you bring it",
    "start": "814660",
    "end": "822220"
  },
  {
    "text": "in to your and your training infrastructure it's end-to-end encrypted",
    "start": "822220",
    "end": "829470"
  },
  {
    "text": "all of this can be in your V PC is execution so security has been I want to",
    "start": "829470",
    "end": "838240"
  },
  {
    "text": "say a priority zero as far as the product has been concerned so we we've been very mindful of treating that and",
    "start": "838240",
    "end": "844900"
  },
  {
    "text": "bring that as a first-class citizen so really really important as you've seen",
    "start": "844900",
    "end": "851530"
  },
  {
    "text": "with customers and health care and finance and other sensitive sectors using this product let's actually look",
    "start": "851530",
    "end": "860710"
  },
  {
    "start": "858000",
    "end": "1298000"
  },
  {
    "text": "at how H make our training looks like let's go take a console view",
    "start": "860710",
    "end": "869190"
  },
  {
    "text": "so fortunately I don't have a dual-screen here but we'll follow here",
    "start": "890460",
    "end": "898560"
  },
  {
    "text": "so we actually support multiple frameworks as we saw PI torch was one of",
    "start": "898560",
    "end": "905290"
  },
  {
    "text": "the latest ones we added so I'll show you a quick idea of how that training in",
    "start": "905290",
    "end": "910960"
  },
  {
    "text": "sage maker looks like but before that this is the sage maker console where you",
    "start": "910960",
    "end": "917830"
  },
  {
    "text": "have a view of what notebooks instances that you want to have you can look at",
    "start": "917830",
    "end": "924630"
  },
  {
    "text": "configurations training jobs etc so a notebook instance is a place where you",
    "start": "924630",
    "end": "932860"
  },
  {
    "text": "get a hosted Jupiter environment where you can collaborate with your colleagues your building and sort of sanity checks",
    "start": "932860",
    "end": "940510"
  },
  {
    "text": "all can be done in this infrastructure I if you're familiar with launching an",
    "start": "940510",
    "end": "945700"
  },
  {
    "text": "instance in ec2 it's even more simplified here where you enter a",
    "start": "945700",
    "end": "951160"
  },
  {
    "text": "notebook name you've got different instance type all the way from T to",
    "start": "951160",
    "end": "956170"
  },
  {
    "text": "instances to medium to instances with GPU attached",
    "start": "956170",
    "end": "962760"
  },
  {
    "text": "so once you hit create notebook you can get a list of notebook instances and",
    "start": "975440",
    "end": "982620"
  },
  {
    "text": "what's great is you can just hit open and you get a nice landing page of your",
    "start": "982620",
    "end": "987630"
  },
  {
    "text": "jupiter console where you will you'll see with Noli comes pre-populated with a",
    "start": "987630",
    "end": "997200"
  },
  {
    "text": "lot of example notebooks to get this nice browsing interface where you have",
    "start": "997200",
    "end": "1005120"
  },
  {
    "text": "examples varying from you know simple ones even if you're new to machine learning on doing say turn prediction or",
    "start": "1005120",
    "end": "1013490"
  },
  {
    "text": "or if you just want to look at hey how can I bring in a docker container and",
    "start": "1013490",
    "end": "1019340"
  },
  {
    "text": "train my own algorithm to using some of the available ones with tensorflow",
    "start": "1019340",
    "end": "1025640"
  },
  {
    "text": "apache MX net or pi torch so I've",
    "start": "1025640",
    "end": "1031160"
  },
  {
    "text": "already clicked one here so we'll we'll take a look at how to train a model with",
    "start": "1031160",
    "end": "1037819"
  },
  {
    "text": "PI torch now the problem is we're",
    "start": "1037820",
    "end": "1044300"
  },
  {
    "text": "building a language generation model so we'll concentrate less on what the model",
    "start": "1044300",
    "end": "1049370"
  },
  {
    "text": "actually does but more on the process of how easy it is to actually build these models so so as you so what we do is",
    "start": "1049370",
    "end": "1062710"
  },
  {
    "text": "initialize a sage maker session here's you see that and then this is the part",
    "start": "1062710",
    "end": "1069050"
  },
  {
    "text": "where we get the data so in this case we're using a Creative Commons data set",
    "start": "1069050",
    "end": "1074350"
  },
  {
    "text": "which basically is a lot of documents but once you've done that and transform",
    "start": "1074350",
    "end": "1081380"
  },
  {
    "text": "the data the next step is we'll upload the data to s3 and that will be where",
    "start": "1081380",
    "end": "1087050"
  },
  {
    "text": "our data gets ingested into our training infrastructure and what you can have is",
    "start": "1087050",
    "end": "1098590"
  },
  {
    "text": "is you package your code into a training script which basically has a hook to",
    "start": "1098590",
    "end": "1105770"
  },
  {
    "text": "call a train func so you you will we can have a train you",
    "start": "1105770",
    "end": "1111440"
  },
  {
    "text": "can have a load we provide you four functions that you can override as entry points for various steps then this is",
    "start": "1111440",
    "end": "1122690"
  },
  {
    "text": "this is where we'll concentrate most of the time what you do is you provide your",
    "start": "1122690",
    "end": "1128450"
  },
  {
    "text": "training script so you've come up with the model that you want to train and you give hey I want to use the PI torch give",
    "start": "1128450",
    "end": "1136910"
  },
  {
    "text": "it because we are launching a PI torch and then we're gonna give it a trained eye that is our file with all the code",
    "start": "1136910",
    "end": "1144310"
  },
  {
    "text": "the second line is we specify which I am role which defines what access it has",
    "start": "1144310",
    "end": "1150970"
  },
  {
    "text": "framework version again different we provide different multiple versions for",
    "start": "1150970",
    "end": "1157850"
  },
  {
    "text": "different frameworks you specify the instance count you specify the type of",
    "start": "1157850",
    "end": "1164210"
  },
  {
    "text": "instance you want to train and then hyper parameters in this case we're saying hey run for six epochs now what's",
    "start": "1164210",
    "end": "1174200"
  },
  {
    "text": "what's great here is I can just I can just hit the fit function the training",
    "start": "1174200",
    "end": "1181430"
  },
  {
    "text": "cluster gets spun up we train the model and the model gets saved in s3 and we",
    "start": "1181430",
    "end": "1189710"
  },
  {
    "text": "can actually stream in the logs here it has integration into cloud watch so",
    "start": "1189710",
    "end": "1195920"
  },
  {
    "text": "cloud watch logs whatever logging you put in your scripts you can see it there but also cloud watch metrics as to how",
    "start": "1195920",
    "end": "1204260"
  },
  {
    "text": "much is your instance utilize and what's great is imagine like our data corpus",
    "start": "1204260",
    "end": "1210410"
  },
  {
    "text": "here was you know around one gigabyte let's say I had 100 gigabytes of data",
    "start": "1210410",
    "end": "1217270"
  },
  {
    "text": "now it's ideal that hey you know III I'm doing this in AWS I need I love the",
    "start": "1217270",
    "end": "1223850"
  },
  {
    "text": "scalability and the distributed aspects of that how do I do that with with sage",
    "start": "1223850",
    "end": "1230600"
  },
  {
    "text": "maker all I need to do is with a single line code change now I can run this",
    "start": "1230600",
    "end": "1237800"
  },
  {
    "text": "distributed so I just had more data what I do is change the instance count",
    "start": "1237800",
    "end": "1242870"
  },
  {
    "text": "and sage maker handles the distributed scaling aspect for you so you don't need",
    "start": "1242870",
    "end": "1249800"
  },
  {
    "text": "to write any extra code for you to do this and this is true for the other frameworks as well with tencel flow and",
    "start": "1249800",
    "end": "1257300"
  },
  {
    "text": "apache MX net on sage maker in addition",
    "start": "1257300",
    "end": "1265550"
  },
  {
    "text": "we do provide we do provide algorithms a",
    "start": "1265550",
    "end": "1271360"
  },
  {
    "text": "built-in algorithm so I'll summarize some of them later or and what what you",
    "start": "1271360",
    "end": "1277760"
  },
  {
    "text": "need to do is just like we selected a framework we need to select a different",
    "start": "1277760",
    "end": "1283280"
  },
  {
    "text": "image to say hey I want to build a forecasting model with a built-in algorithm or I want to use XG boost at",
    "start": "1283280",
    "end": "1290200"
  },
  {
    "text": "Sage maker provides let's go back to the",
    "start": "1290200",
    "end": "1295940"
  },
  {
    "text": "presentation so to summarize these are the",
    "start": "1295940",
    "end": "1303770"
  },
  {
    "text": "capabilities you can have your data format that for the machine learning process and then you have the option of",
    "start": "1303770",
    "end": "1310490"
  },
  {
    "text": "selecting one of the dozens of algorithms we have that are built in the",
    "start": "1310490",
    "end": "1317650"
  },
  {
    "text": "second is we have a lot of notebook templates like the template that we you saw earlier we have a lot of code and",
    "start": "1317650",
    "end": "1326000"
  },
  {
    "text": "documentation what you can do is take that code which is open source modify that use the process and apply to your",
    "start": "1326000",
    "end": "1333260"
  },
  {
    "text": "data so we want you we're encouraging you to use that as a template for you to",
    "start": "1333260",
    "end": "1339980"
  },
  {
    "text": "build on top of and then for custom you can write your code in Apache MX nav",
    "start": "1339980",
    "end": "1347990"
  },
  {
    "text": "gluon tensorflow pi torch chain ER and then launch just",
    "start": "1347990",
    "end": "1355340"
  },
  {
    "text": "like the job we saw earlier but also there are cases or customers have told",
    "start": "1355340",
    "end": "1360980"
  },
  {
    "text": "hey I've my own algorithm I want to use a version that you don't support yet for",
    "start": "1360980",
    "end": "1367370"
  },
  {
    "text": "all those cases all you you can do is build your car docker container we have",
    "start": "1367370",
    "end": "1372800"
  },
  {
    "text": "templates you can take that template modify that build your own custom docker and then",
    "start": "1372800",
    "end": "1379840"
  },
  {
    "text": "spin up your training and training is supported either be it single machine or",
    "start": "1379840",
    "end": "1387110"
  },
  {
    "text": "cluster and as you saw doing distributed training it's as simple as changing one",
    "start": "1387110",
    "end": "1395600"
  },
  {
    "text": "line of code let's look at well what",
    "start": "1395600",
    "end": "1406550"
  },
  {
    "text": "what we want you to focus on which is we we've removed or we've done the",
    "start": "1406550",
    "end": "1413630"
  },
  {
    "text": "undifferentiated heavy lifting so that you can increase the training speed by you know we've we've done optimizations",
    "start": "1413630",
    "end": "1420650"
  },
  {
    "text": "as far as getting data in be it at the hardware hypervisor level be it with the",
    "start": "1420650",
    "end": "1429890"
  },
  {
    "text": "framework level where we provide and make it easy for you to distribute training on the inference side where",
    "start": "1429890",
    "end": "1437660"
  },
  {
    "text": "we've deployed the model I you know it's it's Auto scales you can set the",
    "start": "1437660",
    "end": "1444380"
  },
  {
    "text": "parameters as to min and Max instances but more more importantly what we've",
    "start": "1444380",
    "end": "1451790"
  },
  {
    "text": "tried to do is provide a platform where you can I try it faster and we",
    "start": "1451790",
    "end": "1458630"
  },
  {
    "text": "understand the business needs or not you know static we want you to be dynamic",
    "start": "1458630",
    "end": "1463730"
  },
  {
    "text": "make it easier for you to I trait and build algorithms so I want to actually",
    "start": "1463730",
    "end": "1473270"
  },
  {
    "start": "1468000",
    "end": "1548000"
  },
  {
    "text": "talk a little bit about some of the new features which we launched in a little",
    "start": "1473270",
    "end": "1478850"
  },
  {
    "text": "detail so as you saw here I spun up my notebook instance I have to now you know",
    "start": "1478850",
    "end": "1485930"
  },
  {
    "text": "submit my job and spin up a cluster what a lot of customers found that was hey",
    "start": "1485930",
    "end": "1491390"
  },
  {
    "text": "you know I I need to wait for my training cluster to spin up so he had a",
    "start": "1491390",
    "end": "1498200"
  },
  {
    "text": "mistake I had to go back and you know collect it and launch again but turns out have another mistake so we wanted",
    "start": "1498200",
    "end": "1505370"
  },
  {
    "text": "people to write rate fast so what we did is we local mode what that allows you to do is",
    "start": "1505370",
    "end": "1512320"
  },
  {
    "text": "run the code that you have maybe for a couple of epochs on a single epoch where",
    "start": "1512320",
    "end": "1518450"
  },
  {
    "text": "you can go test your code because sometimes these jobs can run for hours or you know days you want to make sure",
    "start": "1518450",
    "end": "1525440"
  },
  {
    "text": "that there are no issues as far as you know your code you need to do a sanity",
    "start": "1525440",
    "end": "1531259"
  },
  {
    "text": "check beat on the algorithm side or the code side so now what we allow you to do",
    "start": "1531259",
    "end": "1537619"
  },
  {
    "text": "is strain you can do complete training on the notebook instance that you have or you can do sanity checks and then",
    "start": "1537619",
    "end": "1545059"
  },
  {
    "text": "submit the jobs the next thing is",
    "start": "1545059",
    "end": "1550869"
  },
  {
    "start": "1548000",
    "end": "1623000"
  },
  {
    "text": "automatic model tuning when you've sort of found the model architecture that",
    "start": "1550869",
    "end": "1556460"
  },
  {
    "text": "helps you solve the problem you know let's say you you're at ninety percent accuracy but what you really want is try",
    "start": "1556460",
    "end": "1563809"
  },
  {
    "text": "and get to that ninety-five percent and oftentimes what you find is it's it's",
    "start": "1563809",
    "end": "1569239"
  },
  {
    "text": "those parameters that build up your model need to be tweaked now you know",
    "start": "1569239",
    "end": "1576320"
  },
  {
    "text": "there are various ways to do this and you know traditionally people have used things like random search or great",
    "start": "1576320",
    "end": "1583340"
  },
  {
    "text": "search but grid search or other you know how do you how do you start what where's",
    "start": "1583340",
    "end": "1589849"
  },
  {
    "text": "my base and things can have with grid search you can have combinatorial extra",
    "start": "1589849",
    "end": "1595220"
  },
  {
    "text": "you know explosion as the number of parameters increase so we've made this",
    "start": "1595220",
    "end": "1602269"
  },
  {
    "text": "easier for customers by allowing you to do do automatic model training here's an",
    "start": "1602269",
    "end": "1610700"
  },
  {
    "text": "example for hyper parameters with XC",
    "start": "1610700",
    "end": "1616940"
  },
  {
    "text": "boost where we have gamma what's the tree depth etc so this is the how the",
    "start": "1616940",
    "end": "1626119"
  },
  {
    "start": "1623000",
    "end": "1771000"
  },
  {
    "text": "process for doing hyper parameter optimization our model tuning look like",
    "start": "1626119",
    "end": "1631249"
  },
  {
    "text": "so we have the client the console we saw we specify and configure a job the next",
    "start": "1631249",
    "end": "1640129"
  },
  {
    "text": "thing is we pick tuning algorithm are rather the tuning algorithm picks and understands the",
    "start": "1640129",
    "end": "1646940"
  },
  {
    "text": "hyperparameters picks one the we actually use Bayesian optimization here",
    "start": "1646940",
    "end": "1653360"
  },
  {
    "text": "to pick the best algorithm or the hyperparameters and then we kick off the",
    "start": "1653360",
    "end": "1658760"
  },
  {
    "text": "training job now what the training job is looking or rather the whole process",
    "start": "1658760",
    "end": "1665990"
  },
  {
    "text": "is looking at the objective metrics that you've defined this can be something that you've custom-built or you're",
    "start": "1665990",
    "end": "1673070"
  },
  {
    "text": "saying hey look at the validation accuracy or look at the area under the",
    "start": "1673070",
    "end": "1678140"
  },
  {
    "text": "curve whatever is the important metric that you want to tune on and then we",
    "start": "1678140",
    "end": "1684200"
  },
  {
    "text": "collect the objective metrics and then we feed that back to the tuning",
    "start": "1684200",
    "end": "1690530"
  },
  {
    "text": "algorithm and understand hey I moved these things this is the result how can",
    "start": "1690530",
    "end": "1696890"
  },
  {
    "text": "I pick the next best type of parameter so that I can get the best of the metric",
    "start": "1696890",
    "end": "1702050"
  },
  {
    "text": "that we picked and this is done iteratively and you know we the training",
    "start": "1702050",
    "end": "1709130"
  },
  {
    "text": "happens and what's great is all of this is happening in parallel right like",
    "start": "1709130",
    "end": "1715670"
  },
  {
    "text": "that's you can say hey I want to tune my model but don't do it serially spin up",
    "start": "1715670",
    "end": "1720920"
  },
  {
    "text": "for jobs or spin up ten jobs in parallel and find me the best model and and all",
    "start": "1720920",
    "end": "1728930"
  },
  {
    "text": "this is completely managed for you all you need to do is write those lines of",
    "start": "1728930",
    "end": "1735680"
  },
  {
    "text": "code that define your objective metric and parameters and then you know do it",
    "start": "1735680",
    "end": "1742460"
  },
  {
    "text": "exactly how you did with your training previously and we'll look at the code next and then you get this nice you know",
    "start": "1742460",
    "end": "1753050"
  },
  {
    "text": "tabular data which says hey what was my objective metric what are the other parameters hyper parameters that were",
    "start": "1753050",
    "end": "1759800"
  },
  {
    "text": "used so this allows you to pick what we think is the best model that you want to",
    "start": "1759800",
    "end": "1766670"
  },
  {
    "text": "go ahead and put it into production and",
    "start": "1766670",
    "end": "1772150"
  },
  {
    "start": "1771000",
    "end": "1893000"
  },
  {
    "text": "here's some code so this is a job it you know we we pick",
    "start": "1772150",
    "end": "1780179"
  },
  {
    "text": "certain hyperparameters ranges and with neural networks it's typically you'll see the bat size learning rate give me",
    "start": "1780179",
    "end": "1788909"
  },
  {
    "text": "what are the number of epochs I want to run so there's no manual you don't need to manually run something for say 50",
    "start": "1788909",
    "end": "1795750"
  },
  {
    "text": "epochs and then try and run it for 100 or change different setting right like if these many dials the best way to",
    "start": "1795750",
    "end": "1803009"
  },
  {
    "text": "think about this there are many dials for a machine learning model and which one to sort of",
    "start": "1803009",
    "end": "1810750"
  },
  {
    "text": "pick and dial is made simple by the automatic model tuning feature and then",
    "start": "1810750",
    "end": "1817559"
  },
  {
    "text": "in this case you know we pick the objective metric which is validation accuracy and you know as you can see you",
    "start": "1817559",
    "end": "1825539"
  },
  {
    "text": "know it's got reject support so if you're logging custom things it's easy to extract and tune for and then you",
    "start": "1825539",
    "end": "1835649"
  },
  {
    "text": "wrap your estimator we saw earlier in the hyper parameter tune or job you specify the ranges and then you hit the",
    "start": "1835649",
    "end": "1843600"
  },
  {
    "text": "fit function just as we did before and now jobs are running in parallel being",
    "start": "1843600",
    "end": "1849419"
  },
  {
    "text": "optimized in the process that I walked through earlier and then this is an",
    "start": "1849419",
    "end": "1855000"
  },
  {
    "text": "actual job that was run it's it's it's plotting time versus accuracy so as you",
    "start": "1855000",
    "end": "1862289"
  },
  {
    "text": "can see you know it doesn't mean if the model runs all the longer you know you",
    "start": "1862289",
    "end": "1870389"
  },
  {
    "text": "pick the best model it's it's there's a sweet spot somewhere and as you can see our highest you know we want to get the",
    "start": "1870389",
    "end": "1877139"
  },
  {
    "text": "best accurate model and we can see the hyperparameters there hey was batch 16",
    "start": "1877139",
    "end": "1882419"
  },
  {
    "text": "it ran for 39 a box so that's the model I want to pick and deploy to production",
    "start": "1882419",
    "end": "1890450"
  },
  {
    "start": "1893000",
    "end": "1928000"
  },
  {
    "text": "so let's look at some of the customer success stories we've we've had and you",
    "start": "1893820",
    "end": "1902500"
  },
  {
    "text": "have a lot of enterprise customers like GE Healthcare Dow Jones build built on",
    "start": "1902500",
    "end": "1909400"
  },
  {
    "text": "top stage maker but at the same time we've had a lot of startups including",
    "start": "1909400",
    "end": "1915910"
  },
  {
    "text": "tinder you probably saw some if you've followed the keynote you saw Matt talked",
    "start": "1915910",
    "end": "1921940"
  },
  {
    "text": "about how tinder was using sage maker grammerly into it was a launch customer",
    "start": "1921940",
    "end": "1941800"
  },
  {
    "start": "1928000",
    "end": "1983000"
  },
  {
    "text": "for sage maker so we saw what was great was interior told us that hey we wanted",
    "start": "1941800",
    "end": "1950470"
  },
  {
    "text": "to accelerate our machine learning and some of the core principles that I talked about is we wanted to decrease",
    "start": "1950470",
    "end": "1956740"
  },
  {
    "text": "the time that it took to build a model and we were able to reduce and we've",
    "start": "1956740",
    "end": "1962290"
  },
  {
    "text": "seen this with multiple customers is reduce that time that took six months to",
    "start": "1962290",
    "end": "1967330"
  },
  {
    "text": "go from an idea to production and reduce that in a matter of weeks",
    "start": "1967330",
    "end": "1972430"
  },
  {
    "text": "so currently we've Intuit churning up models and building new",
    "start": "1972430",
    "end": "1978520"
  },
  {
    "text": "models in less than a week and production izing them so this is a",
    "start": "1978520",
    "end": "1985120"
  },
  {
    "start": "1983000",
    "end": "2053000"
  },
  {
    "text": "architecture of a fraud detection real time fraud detection system that into it uses they use Kafka to ingest data and",
    "start": "1985120",
    "end": "1995500"
  },
  {
    "text": "then to actually transform the features they use Amazon EMR and spark so as you",
    "start": "1995500",
    "end": "2005220"
  },
  {
    "text": "see the reader cleanser and processing is happening and they've built this",
    "start": "2005220",
    "end": "2010980"
  },
  {
    "text": "features store where all these features get mapped once",
    "start": "2010980",
    "end": "2017580"
  },
  {
    "text": "you have all these features what we do is they kick off a training job on sage",
    "start": "2017580",
    "end": "2024390"
  },
  {
    "text": "maker and then the model gets bill it's stored in s3 and then as you saw",
    "start": "2024390",
    "end": "2032250"
  },
  {
    "text": "like with a single line of code you can specify the number of instances that you want the model to be hosted on and then",
    "start": "2032250",
    "end": "2040190"
  },
  {
    "text": "it gets hosted in this auto scaling infrastructure and then you can have",
    "start": "2040190",
    "end": "2046830"
  },
  {
    "text": "your client services consume that as an API so the next ten minutes or so we're",
    "start": "2046830",
    "end": "2057960"
  },
  {
    "start": "2053000",
    "end": "2178000"
  },
  {
    "text": "going to dive into key differentiators like what separates sage maker from or",
    "start": "2057960",
    "end": "2066000"
  },
  {
    "text": "what are the key features there there's literally zero setup required for you to",
    "start": "2066000",
    "end": "2072750"
  },
  {
    "text": "do data analysis and explore your data and as you saw all you need to go is in",
    "start": "2072750",
    "end": "2079290"
  },
  {
    "text": "that console specify a couple of things and then you have your notebook instance",
    "start": "2079290",
    "end": "2085560"
  },
  {
    "text": "ready to be accessed now the the notebook depending upon the role you",
    "start": "2085560",
    "end": "2091888"
  },
  {
    "text": "said already has access to s3 so you can bring in your data you can kick off your ETL jobs and then because this is a",
    "start": "2091889",
    "end": "2101070"
  },
  {
    "text": "Jupiter notebook interface which is popular among a lot of data scientists",
    "start": "2101070",
    "end": "2106710"
  },
  {
    "text": "and developers you can explore the data you know write plots all of that but",
    "start": "2106710",
    "end": "2115170"
  },
  {
    "text": "also as you saw we have a lot of these notebook templates that make it simpler",
    "start": "2115170",
    "end": "2121530"
  },
  {
    "text": "for you to get started with machine learning so you can go from data and transform the data and then use one of",
    "start": "2121530",
    "end": "2130050"
  },
  {
    "text": "these notebooks so we've got algorithms like a deep AR which is which is an",
    "start": "2130050",
    "end": "2137490"
  },
  {
    "text": "algorithm that Amazon internally uses to forecast inventory so that algorithm is",
    "start": "2137490",
    "end": "2144270"
  },
  {
    "text": "available for you so if you wanted to do forecasting any time series forecasting",
    "start": "2144270",
    "end": "2149880"
  },
  {
    "text": "as long as you can format the data in what the algorithm requires in this case",
    "start": "2149880",
    "end": "2155670"
  },
  {
    "text": "DPR takes a JSON format once you transform that data you can kick off a",
    "start": "2155670",
    "end": "2161740"
  },
  {
    "text": "and get a model you don't need scientist or data scientists on your team to go",
    "start": "2161740",
    "end": "2167800"
  },
  {
    "text": "and build these algorithms such algorithms are available readily for you",
    "start": "2167800",
    "end": "2172869"
  },
  {
    "text": "on Amazon sage maker the next what we",
    "start": "2172869",
    "end": "2181780"
  },
  {
    "start": "2178000",
    "end": "2273000"
  },
  {
    "text": "were really mindful is the scale we we operate at scale or at AWS so we want to",
    "start": "2181780",
    "end": "2189640"
  },
  {
    "text": "be mindful and bring that capability to all the algorithms that we we provide so",
    "start": "2189640",
    "end": "2197050"
  },
  {
    "text": "for example we have anywhere between like matrix factorization with k-means clustering gradient boosted trees all",
    "start": "2197050",
    "end": "2204130"
  },
  {
    "text": "these algorithms are available and what we've done is we've actually built these",
    "start": "2204130",
    "end": "2211300"
  },
  {
    "text": "algorithms from the ground up but keeping the functionality the same and",
    "start": "2211300",
    "end": "2217080"
  },
  {
    "text": "these algorithms are built so that it can work on streaming data so we have constant memory footprint and you can",
    "start": "2217080",
    "end": "2225190"
  },
  {
    "text": "stream in any amount of data and which allows us to scale and build these",
    "start": "2225190",
    "end": "2230200"
  },
  {
    "text": "models what that means is you can you know if you have more data and a trained",
    "start": "2230200",
    "end": "2235750"
  },
  {
    "text": "model you can load that up and keep training that again and get a better model but so we've typically seen is",
    "start": "2235750",
    "end": "2247060"
  },
  {
    "text": "these algorithms have performed 10x better than the nearest in",
    "start": "2247060",
    "end": "2252220"
  },
  {
    "text": "implementation that's out there and you",
    "start": "2252220",
    "end": "2257440"
  },
  {
    "text": "know the same like you know we've capabilities with these built-in algorithms the notebook algorithms that",
    "start": "2257440",
    "end": "2263380"
  },
  {
    "text": "we saw you can have build your own models you know darker eyes and bring",
    "start": "2263380",
    "end": "2270550"
  },
  {
    "text": "them into Sage maker next is managed",
    "start": "2270550",
    "end": "2277869"
  },
  {
    "start": "2273000",
    "end": "2353000"
  },
  {
    "text": "distributed training so it's as easy as",
    "start": "2277869",
    "end": "2282940"
  },
  {
    "text": "a single line code change to go from training on a single instance to a",
    "start": "2282940",
    "end": "2288339"
  },
  {
    "text": "distributed cluster but we understand that you know our customers have",
    "start": "2288339",
    "end": "2294849"
  },
  {
    "text": "different knee so there's flexibility there in terms of you know you could bring your own",
    "start": "2294849",
    "end": "2301950"
  },
  {
    "text": "container as well and configure to do that so in case of if you if you happen",
    "start": "2301950",
    "end": "2309360"
  },
  {
    "text": "to use say Apache iMac snare tensorflow chain or PI torch you can get your fetch",
    "start": "2309360",
    "end": "2314580"
  },
  {
    "text": "your data you can put it through the training code and then your model artifacts get saved in s3 and on top of",
    "start": "2314580",
    "end": "2324510"
  },
  {
    "text": "that for any of these combinations automatic model tuning or hyper my",
    "start": "2324510",
    "end": "2330090"
  },
  {
    "text": "parameter tuning is provided so you can find the best model for you to take to production and all this is happening in",
    "start": "2330090",
    "end": "2339600"
  },
  {
    "text": "your PC and all that we talked about is being fully managed so AWS or in this",
    "start": "2339600",
    "end": "2345780"
  },
  {
    "text": "case Amazon sage maker is doing the undifferentiated heavy lifting on behalf of the next is deployment I want to I",
    "start": "2345780",
    "end": "2360330"
  },
  {
    "start": "2353000",
    "end": "2448000"
  },
  {
    "text": "want to get a sense of how many people think that training models you know cost",
    "start": "2360330",
    "end": "2367830"
  },
  {
    "text": "more than say hosting how many of you believe training is more like a few a",
    "start": "2367830",
    "end": "2373830"
  },
  {
    "text": "lot of smart people here yeah it turns out like a lot of time is actually spent",
    "start": "2373830",
    "end": "2379770"
  },
  {
    "text": "or other the cost side is on the hosting side so because this is when you've",
    "start": "2379770",
    "end": "2386130"
  },
  {
    "text": "packaged the model and you're actually exposing this to derive business value right so what we've made it simple for",
    "start": "2386130",
    "end": "2395300"
  },
  {
    "text": "model hosting and we understand that not just having a single model may be",
    "start": "2395300",
    "end": "2400770"
  },
  {
    "text": "sufficient but you need to try and find the right model so apart from hosting say a single model",
    "start": "2400770",
    "end": "2409320"
  },
  {
    "text": "which is great we also understand that you might want to have multiple versions of the model or you might want to test",
    "start": "2409320",
    "end": "2416910"
  },
  {
    "text": "out a model and pick the best that works in practice so you can have different",
    "start": "2416910",
    "end": "2422520"
  },
  {
    "text": "model versions you can set a be testing different weights for each of those",
    "start": "2422520",
    "end": "2427980"
  },
  {
    "text": "models so that yeah you are actually getting metrics objective metrics on what",
    "start": "2427980",
    "end": "2433980"
  },
  {
    "text": "performs best for you so that you can use that and on full traffic so all this",
    "start": "2433980",
    "end": "2441779"
  },
  {
    "text": "is actually managed for you so to",
    "start": "2441779",
    "end": "2452190"
  },
  {
    "start": "2448000",
    "end": "2493000"
  },
  {
    "text": "summarize on the model deployment its one-click AV testing is supported low",
    "start": "2452190",
    "end": "2459420"
  },
  {
    "text": "latency and all the parts are disconnected of each other which means",
    "start": "2459420",
    "end": "2466559"
  },
  {
    "text": "that let's say you have already happen to have a training infrastructure and trained your models you can bring those",
    "start": "2466559",
    "end": "2472500"
  },
  {
    "text": "models in and package them and host them on or on Sage maker the same is true",
    "start": "2472500",
    "end": "2480630"
  },
  {
    "text": "with training you can train your models it's still stored in s3 you can download the models and if you want to push it",
    "start": "2480630",
    "end": "2487200"
  },
  {
    "text": "down to the edge or if you want to use that in a different environment you're free to do so let's look at some we've",
    "start": "2487200",
    "end": "2497130"
  },
  {
    "start": "2493000",
    "end": "2648000"
  },
  {
    "text": "actually been keeping up and building its building a lot of new enhancements I",
    "start": "2497130",
    "end": "2502950"
  },
  {
    "text": "just wanted to summarize those for you recently we launched new deep learning",
    "start": "2502950",
    "end": "2508589"
  },
  {
    "text": "framework support with chainer and fight arch security and compliance features so",
    "start": "2508589",
    "end": "2514170"
  },
  {
    "text": "sage maker was a HIPAA eligible a month or so ago we've expanded worldwide so",
    "start": "2514170",
    "end": "2521910"
  },
  {
    "text": "Tokyo Frankfurt Sydney it's available in those regions automatic model tuning",
    "start": "2521910",
    "end": "2527760"
  },
  {
    "text": "that we saw release recently the local mode where you can train train locally",
    "start": "2527760",
    "end": "2536279"
  },
  {
    "text": "or train partially locally and then spin on a different cluster that that's in",
    "start": "2536279",
    "end": "2543380"
  },
  {
    "text": "we've been constantly I trading on the algorithms for example with deep deep a",
    "start": "2543380",
    "end": "2549930"
  },
  {
    "text": "are we actually to do timeseriesforecasting now it can for example hand handle missing values we",
    "start": "2549930",
    "end": "2558299"
  },
  {
    "text": "are and more enhancements to blazing tax to build your own were to act like more",
    "start": "2558299",
    "end": "2564920"
  },
  {
    "text": "and today we actually announced tensorflow pipeline pipe mode to be using tensor flow what",
    "start": "2565299",
    "end": "2572440"
  },
  {
    "text": "that means is you don't need to download all of the data onto your training instance before you kick off the job",
    "start": "2572440",
    "end": "2579359"
  },
  {
    "text": "well you can now stream your data directly from s3 which means that your",
    "start": "2579359",
    "end": "2585489"
  },
  {
    "text": "training jobs start faster which means they end faster which means you pay less",
    "start": "2585489",
    "end": "2591489"
  },
  {
    "text": "so it's a win-win situation with the pipe mode and we've done a lot of",
    "start": "2591489",
    "end": "2598420"
  },
  {
    "text": "benchmarks and one of the benchmarks Sharra's on like 78 gig data set we saw",
    "start": "2598420",
    "end": "2604989"
  },
  {
    "text": "the startup times increased by about 87 percent and the aural training job was",
    "start": "2604989",
    "end": "2610890"
  },
  {
    "text": "35 percent faster than why you had to wait for all the all the job Batz",
    "start": "2610890",
    "end": "2621130"
  },
  {
    "text": "transform is a important feature a lot of customers asked here rather than",
    "start": "2621130",
    "end": "2627339"
  },
  {
    "text": "calling a single end point how can I give a bunch of images or text and get",
    "start": "2627339",
    "end": "2634180"
  },
  {
    "text": "inference but not only that if you have large files like HD video or in case of",
    "start": "2634180",
    "end": "2641019"
  },
  {
    "text": "medical image analysis these DMR images tend to be really huge how do you get",
    "start": "2641019",
    "end": "2646420"
  },
  {
    "text": "that and process in an a batch I also",
    "start": "2646420",
    "end": "2653170"
  },
  {
    "start": "2648000",
    "end": "2768000"
  },
  {
    "text": "wanted to present end-to-end architecture a sample architecture in",
    "start": "2653170",
    "end": "2658539"
  },
  {
    "text": "this case to do style transfer so we build we build using you know the",
    "start": "2658539",
    "end": "2668319"
  },
  {
    "text": "notebook instance and what we've also added now capability is you can isolate",
    "start": "2668319",
    "end": "2673959"
  },
  {
    "text": "the notebook instance which means that there's no internet connectivity right when you're working with sensitive data",
    "start": "2673959",
    "end": "2680259"
  },
  {
    "text": "it's really important that you isolate the access the next is it also has",
    "start": "2680259",
    "end": "2688319"
  },
  {
    "text": "lifecycle hooks which means you can integrate to code command which is",
    "start": "2688319",
    "end": "2693489"
  },
  {
    "text": "really nice because now let's say you stop somebody can check in the code and you",
    "start": "2693489",
    "end": "2699279"
  },
  {
    "text": "can stop your notebook instance but the next time you check actually spin up if somebody has had a new commit you can",
    "start": "2699279",
    "end": "2706479"
  },
  {
    "text": "actually have the latest commit and code for you to work on so all that is",
    "start": "2706479",
    "end": "2711900"
  },
  {
    "text": "posited and then in this example we pick up the training algorithm you kick off",
    "start": "2711900",
    "end": "2719410"
  },
  {
    "text": "the sage maker training job then it trains the model artifacts get saved in",
    "start": "2719410",
    "end": "2725619"
  },
  {
    "text": "s3 and then you can use api gateway and lambda to utilize or actually hook and",
    "start": "2725619",
    "end": "2734019"
  },
  {
    "text": "decision maker hosting to provide an external endpoint for customers your end",
    "start": "2734019",
    "end": "2740410"
  },
  {
    "text": "customers to consume of course you can use s3 and CloudFront to accelerate the",
    "start": "2740410",
    "end": "2745720"
  },
  {
    "text": "access to static assets again to highlight you can have n - n V PC",
    "start": "2745720",
    "end": "2751930"
  },
  {
    "text": "support here but also let's say on the training data you you have n - an",
    "start": "2751930",
    "end": "2758289"
  },
  {
    "text": "encryption so that none of your your data is securely transferred from s3 to",
    "start": "2758289",
    "end": "2765549"
  },
  {
    "text": "your instances so train and then deploy",
    "start": "2765549",
    "end": "2772440"
  },
  {
    "start": "2768000",
    "end": "2838000"
  },
  {
    "text": "so so summarize important is we have the",
    "start": "2772619",
    "end": "2778809"
  },
  {
    "text": "broadest in easiest to use machine learning platform with the most customers so for your data Lake storage",
    "start": "2778809",
    "end": "2788319"
  },
  {
    "text": "needs you have s3 then compute you can use the GPU instances with our p2 p3",
    "start": "2788319",
    "end": "2795519"
  },
  {
    "text": "family but also if you want it and that's when you'll have to manage but as",
    "start": "2795519",
    "end": "2802749"
  },
  {
    "text": "you've seen Sage maker can simplify that immensely where you're Bill train and",
    "start": "2802749",
    "end": "2808539"
  },
  {
    "text": "deploy aspects are managed for you by Amazon Sage maker",
    "start": "2808539",
    "end": "2814509"
  },
  {
    "text": "it's got enhance security capabilities and compliance but and also we have a",
    "start": "2814509",
    "end": "2822910"
  },
  {
    "text": "lot of customers in different segments be finance or healthcare",
    "start": "2822910",
    "end": "2829960"
  },
  {
    "text": "or even a lot of startups using Amazon sage maker to you know solve business",
    "start": "2829960",
    "end": "2835840"
  },
  {
    "text": "problems so thank you so much so I hope",
    "start": "2835840",
    "end": "2843520"
  },
  {
    "start": "2838000",
    "end": "2872000"
  },
  {
    "text": "you'll submit feedback I also want to leave you with useful resources that you",
    "start": "2843520",
    "end": "2851140"
  },
  {
    "text": "can get to learn a lot of different things I talked about a lot of github",
    "start": "2851140",
    "end": "2858460"
  },
  {
    "text": "there's a lot of open source code out there please feel free to reach out if you have questions and I'll be here",
    "start": "2858460",
    "end": "2865890"
  },
  {
    "text": "after the session to answer questions offstage thank you so much [Applause]",
    "start": "2865890",
    "end": "2874260"
  }
]
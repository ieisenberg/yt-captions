[
  {
    "start": "0",
    "end": "17000"
  },
  {
    "text": "hello everyone my name is Alex yanowski I'm a principal Solutions architect in",
    "start": "3520",
    "end": "8679"
  },
  {
    "text": "the worldwide specialist organization and today I'd like to share with you Amazon eks support in Sag maker hyperpod",
    "start": "8679",
    "end": "17520"
  },
  {
    "start": "17000",
    "end": "59000"
  },
  {
    "text": "what is sagemaker hyperpod it's a sagemaker service that",
    "start": "17520",
    "end": "23320"
  },
  {
    "text": "provides purpose buil machine learning infrastructure with built-in resiliency",
    "start": "23320",
    "end": "28480"
  },
  {
    "text": "features work loads on sagemaker hyperpod can be orchestrated either VI",
    "start": "28480",
    "end": "34200"
  },
  {
    "text": "slurm or kubernetes and today we'll focus on the",
    "start": "34200",
    "end": "39719"
  },
  {
    "text": "kubernetes interface which is provided by Amazon eks the elastic kubernetes",
    "start": "39719",
    "end": "47280"
  },
  {
    "text": "service even though this is a sag maker service customers can still access uh",
    "start": "47280",
    "end": "54399"
  },
  {
    "text": "their underlying infrastructure using cctl or SSH",
    "start": "54399",
    "end": "60160"
  },
  {
    "start": "59000",
    "end": "162000"
  },
  {
    "text": "a typical hyperpod cluster looks like this the compute lives in a service",
    "start": "60160",
    "end": "66560"
  },
  {
    "text": "account and in addition to that there's the customer account and uh an eks",
    "start": "66560",
    "end": "72320"
  },
  {
    "text": "cluster the demo that i' like to show you today has",
    "start": "72320",
    "end": "78200"
  },
  {
    "text": "four separate instance groups in the compute",
    "start": "78200",
    "end": "83280"
  },
  {
    "text": "cluster one is a generic CPU group provided by M5 uh 2x large inance",
    "start": "83280",
    "end": "90600"
  },
  {
    "text": "es uh two is a G5 aex large node Group",
    "start": "90600",
    "end": "96000"
  },
  {
    "text": "which has one EFA interface one uh Nvidia A10 GPU for each node then a node",
    "start": "96000",
    "end": "105000"
  },
  {
    "text": "group with P5 instances uh which has uh 32 EFA adapters and eight Nvidia h100",
    "start": "105000",
    "end": "114640"
  },
  {
    "text": "gpus and finally a tranium one instance group uh each tranium instance has 16",
    "start": "114640",
    "end": "123200"
  },
  {
    "text": "EFA adapters and 16 neuron devices each neuron device has two neuron cores so",
    "start": "123200",
    "end": "130879"
  },
  {
    "text": "there are total of 32 neuron cores on each trinium instance and this instance",
    "start": "130879",
    "end": "137280"
  },
  {
    "text": "group will basically have uh 64 neuron callers Al",
    "start": "137280",
    "end": "143599"
  },
  {
    "text": "together in uh the user uh or the customer VPC uh we'll use uh the Amazon",
    "start": "143599",
    "end": "151360"
  },
  {
    "text": "elastic uh container registry will have a shared uh FSX for luster volume and uh",
    "start": "151360",
    "end": "158720"
  },
  {
    "text": "we'll use uh Amazon cloudwatch container insights the features of hyperpod are",
    "start": "158720",
    "end": "165000"
  },
  {
    "start": "162000",
    "end": "293000"
  },
  {
    "text": "grouped around three experiences uh first is the admin experience this provides uh you the",
    "start": "165000",
    "end": "172080"
  },
  {
    "text": "ability to create update delete clusters um access uh your clusters via Cube C uh",
    "start": "172080",
    "end": "180080"
  },
  {
    "text": "and if you need to you can access the nodes via SSH uh and the admin UI",
    "start": "180080",
    "end": "187120"
  },
  {
    "text": "experience also includes access from uh the AWS console through the sagemaker UI",
    "start": "187120",
    "end": "195480"
  },
  {
    "text": "the resiliency U feature includes deep health checks uh Health monitoring uh",
    "start": "195480",
    "end": "203120"
  },
  {
    "text": "that's ongoing while the nodes are in service and job Auto resume if the",
    "start": "203120",
    "end": "210400"
  },
  {
    "text": "running jobs are interrupted due to Hardware failure uh finally the",
    "start": "210400",
    "end": "215680"
  },
  {
    "text": "scientist experience is provided by um hyperpod CLI and uh it",
    "start": "215680",
    "end": "224040"
  },
  {
    "text": "enables um users who are not familiar with uh the kubernetes API to have an",
    "start": "224040",
    "end": "230920"
  },
  {
    "text": "easy interface to submit and manage uh their jobs on hyperpod uh clusters of",
    "start": "230920",
    "end": "238400"
  },
  {
    "text": "course we'll also cover observability features of hyperpod um one thing I",
    "start": "238400",
    "end": "245879"
  },
  {
    "text": "wanted to note is that uh you can start from scratch and provision all of the",
    "start": "245879",
    "end": "253400"
  },
  {
    "text": "resources that are necessary uh to create a hyperpod cluster but if you",
    "start": "253400",
    "end": "258680"
  },
  {
    "text": "already have a VPC and an existing eks cluster you can actually attach uh",
    "start": "258680",
    "end": "265800"
  },
  {
    "text": "hyperpod compute to your existing infrastructure and if you've already",
    "start": "265800",
    "end": "271520"
  },
  {
    "text": "built things on top of the kubernetes API uh this would be an easy transition",
    "start": "271520",
    "end": "278039"
  },
  {
    "text": "for you because you can bring uh things like job submission interfaces queuing",
    "start": "278039",
    "end": "284520"
  },
  {
    "text": "or monitoring tools that run on top of uh the kubernetes API uh and they uh",
    "start": "284520",
    "end": "291000"
  },
  {
    "text": "should work on uh hyperpod to create a cluster as I mentioned first you need um",
    "start": "291000",
    "end": "297320"
  },
  {
    "text": "to create some basic resources in your bpc and then I need to provision a eks",
    "start": "297320",
    "end": "304880"
  },
  {
    "text": "cluster some life cycle scripts get pushed to an S3 bucket that help",
    "start": "304880",
    "end": "312919"
  },
  {
    "text": "initialize nodes um when they're about to join the cluster and um",
    "start": "312919",
    "end": "320360"
  },
  {
    "text": "with this information we create a hyperpod cluster configuration which is",
    "start": "320360",
    "end": "325919"
  },
  {
    "text": "displayed on the right um I want to point out here uh that we're in this",
    "start": "325919",
    "end": "332160"
  },
  {
    "text": "example we're config configuring one instance group with p548 x large",
    "start": "332160",
    "end": "338840"
  },
  {
    "text": "instances uh we're saying that uh we want those to have deep health checks",
    "start": "338840",
    "end": "346639"
  },
  {
    "text": "enabled by specifying this U enable uh burning test uh setting and uh",
    "start": "346639",
    "end": "357360"
  },
  {
    "text": "node Auto Recovery is also config configurable um in this configuration",
    "start": "357360",
    "end": "362759"
  },
  {
    "text": "file so once we have the cluster configuration we execute a create",
    "start": "362759",
    "end": "368639"
  },
  {
    "text": "cluster command and then the nodes get provisioned and a user can interact with",
    "start": "368639",
    "end": "375720"
  },
  {
    "text": "them using uh qctl all of these steps are documented",
    "start": "375720",
    "end": "382520"
  },
  {
    "start": "378000",
    "end": "498000"
  },
  {
    "text": "and provided to you in uh the workshop that uh we have released uh this is a",
    "start": "382520",
    "end": "389080"
  },
  {
    "text": "view of the workshop as uh you can see here um it has everything from uh",
    "start": "389080",
    "end": "397199"
  },
  {
    "text": "creating the cluster to running different examples on it",
    "start": "397199",
    "end": "403680"
  },
  {
    "text": "uh setting up observability and uh testing resiliency",
    "start": "403680",
    "end": "410400"
  },
  {
    "text": "features as well as cleaning everything up at the end so this is an endtoend",
    "start": "410400",
    "end": "416000"
  },
  {
    "text": "walkth through uh for the entire process one thing I want to point out is the",
    "start": "416000",
    "end": "422039"
  },
  {
    "text": "sample um cluster configuration file as we discussed um there are settings which",
    "start": "422039",
    "end": "429120"
  },
  {
    "text": "allow you to control the Behavior Uh of uh the resiliency features if the um",
    "start": "429120",
    "end": "437560"
  },
  {
    "text": "deep health checks are disabled then uh the health monitoring agent will still",
    "start": "437560",
    "end": "443879"
  },
  {
    "text": "monitor your nodes but um the initialization at initialization uh time",
    "start": "443879",
    "end": "450039"
  },
  {
    "text": "we're not going to run all of these uh stress tests and connectivity tests it",
    "start": "450039",
    "end": "456240"
  },
  {
    "text": "will accelerate the time a new provision node is added to the cluster uh but it",
    "start": "456240",
    "end": "462319"
  },
  {
    "text": "will also uh trade off the uh deep help",
    "start": "462319",
    "end": "467879"
  },
  {
    "text": "verification that happens prior to the node joining uh if the Deep health",
    "start": "467879",
    "end": "474039"
  },
  {
    "text": "checks are enabled they do take some time sometimes it uh it can take up to",
    "start": "474039",
    "end": "479560"
  },
  {
    "text": "to a couple of hours for all of uh the checks to take place before a node joins",
    "start": "479560",
    "end": "486840"
  },
  {
    "text": "in so there are very very extensive U uh deep health checks that um we're going",
    "start": "486840",
    "end": "494720"
  },
  {
    "text": "to see in action uh during the demo so to automate um all of the steps that",
    "start": "494720",
    "end": "503800"
  },
  {
    "start": "498000",
    "end": "553000"
  },
  {
    "text": "the workshop is walking you through we have created this uh AWS do hyperpod",
    "start": "503800",
    "end": "509039"
  },
  {
    "text": "container project this is an open source project that we'll share with you uh on the resources slide and um the purpose",
    "start": "509039",
    "end": "517959"
  },
  {
    "text": "of it is to make it easy for you to get started and to interact with your hyperpod infrastructure without us",
    "start": "517959",
    "end": "525120"
  },
  {
    "text": "asking you to install several things in your environment first this uh project",
    "start": "525120",
    "end": "530720"
  },
  {
    "text": "lets you run a build script uh which builds a container for you that H",
    "start": "530720",
    "end": "536480"
  },
  {
    "text": "already has everything in it and by um everything I um mean all tools that we",
    "start": "536480",
    "end": "545040"
  },
  {
    "text": "have found useful when uh interacting with Amazon eks as well as sag maker",
    "start": "545040",
    "end": "552120"
  },
  {
    "text": "hyperpod that includes the hyperpod CLI which provides scientists experience if",
    "start": "552120",
    "end": "559600"
  },
  {
    "text": "you type uh just hyperpod inside that uh container shell that we just looked at",
    "start": "559600",
    "end": "565320"
  },
  {
    "text": "you'll see the help and uh the commands that are um available are",
    "start": "565320",
    "end": "574000"
  },
  {
    "text": "pretty self-explanatory uh you can list your compute and then you can start a job",
    "start": "574000",
    "end": "579680"
  },
  {
    "text": "manage your jobs and see the the logs of those uh jobs on the right here is an",
    "start": "579680",
    "end": "586160"
  },
  {
    "text": "example of how we've run the hyperpod list clusters command and it shows the",
    "start": "586160",
    "end": "593160"
  },
  {
    "text": "uh different instance groups that uh we have in the cluster so with this let me",
    "start": "593160",
    "end": "598959"
  },
  {
    "start": "597000",
    "end": "839000"
  },
  {
    "text": "uh switch over to one of my uh demo screens and show you the aws2 hyperpod",
    "start": "598959",
    "end": "606519"
  },
  {
    "text": "project I have cloned it here um already and uh I've run the build script so I've",
    "start": "606519",
    "end": "613680"
  },
  {
    "text": "built the container I've also executed the run. sh command which started my",
    "start": "613680",
    "end": "619160"
  },
  {
    "text": "container and if I check my current status I will see that uh the container",
    "start": "619160",
    "end": "625360"
  },
  {
    "text": "is actually up and running this gives me the ability to just exact in the container which gives me a Shell inside",
    "start": "625360",
    "end": "633040"
  },
  {
    "text": "uh this um AWS do hyperpod container uh",
    "start": "633040",
    "end": "638279"
  },
  {
    "text": "the command that I just executed with each of these scripts gets printed out so if you really wanted to type uh the",
    "start": "638279",
    "end": "645480"
  },
  {
    "text": "long command you could do that as well but now that I'm inside this shell I",
    "start": "645480",
    "end": "651160"
  },
  {
    "text": "have um scripts that allow me to uh configure uh a hyperpod cluster and then",
    "start": "651160",
    "end": "658399"
  },
  {
    "text": "create it with just one command and this supports both uh creating everything",
    "start": "658399",
    "end": "663680"
  },
  {
    "text": "from scratch or attaching to an existing cluster let me uh just show the",
    "start": "663680",
    "end": "669360"
  },
  {
    "text": "configuration uh real quick and by the way the environment config U opens the",
    "start": "669360",
    "end": "675639"
  },
  {
    "text": "um the project configuration uh and you can switch between eks and slurm",
    "start": "675639",
    "end": "683279"
  },
  {
    "text": "behavior for this uh container if you wanted to uh use this for slurm as well",
    "start": "683279",
    "end": "691320"
  },
  {
    "text": "so showing the configuration of the cluster that um I have built for this",
    "start": "691320",
    "end": "697959"
  },
  {
    "text": "demonstration uh I have these uh four node groups uh G5 P5 tranium 1n and uh",
    "start": "697959",
    "end": "706839"
  },
  {
    "text": "M5 instances uh each of them have two nodes and my uh health checks are they were",
    "start": "706839",
    "end": "715959"
  },
  {
    "text": "enabled in the beginning and then I switched it to uh disabled the Deep health checks so I can add new nodes",
    "start": "715959",
    "end": "723160"
  },
  {
    "text": "quickly uh and I have um",
    "start": "723160",
    "end": "729120"
  },
  {
    "text": "then uh updated the cluster So currently my checks uh deep heeld checks are",
    "start": "729120",
    "end": "735199"
  },
  {
    "text": "disabled but if I switch that to true and ran the hyperpod update command it will enable them it's that easy if I",
    "start": "735199",
    "end": "742519"
  },
  {
    "text": "wanted to attach to an existing uh EK cluster then I just um uh specify these",
    "start": "742519",
    "end": "749920"
  },
  {
    "text": "settings here and uh run the cluster create command to attach to existing",
    "start": "749920",
    "end": "759120"
  },
  {
    "text": "um I can um demonstrate for example uh",
    "start": "759800",
    "end": "765279"
  },
  {
    "text": "the hyperpod status command and here is uh showing my uh cluster and uh it is in",
    "start": "765279",
    "end": "773639"
  },
  {
    "text": "service a number of useful commands are available uh here at as I",
    "start": "773639",
    "end": "780040"
  },
  {
    "text": "mentioned uh the hyperpod CLI is already installed but um uh there",
    "start": "780040",
    "end": "787079"
  },
  {
    "text": "is um things like node viewer uh which shows uh the cluster configuration the",
    "start": "787079",
    "end": "795320"
  },
  {
    "text": "nodes running on it and how pods are distributed between the different nodes uh we also have k9's uh which is a tool",
    "start": "795320",
    "end": "804320"
  },
  {
    "text": "many people use to um kind of interact with their their uh e cluster using this",
    "start": "804320",
    "end": "811760"
  },
  {
    "text": "text user interface uh and uh there uh is there are a number of",
    "start": "811760",
    "end": "821279"
  },
  {
    "text": "aliases uh which you can see by typing the Alias command uh which saves a lot",
    "start": "821279",
    "end": "827120"
  },
  {
    "text": "of typing for example I wouldn't be typing uh Cube CTL all the time I'll",
    "start": "827120",
    "end": "832320"
  },
  {
    "text": "just type K and uh that will be equivalent um so",
    "start": "832320",
    "end": "839600"
  },
  {
    "start": "839000",
    "end": "878000"
  },
  {
    "text": "I have already ran a few commands and I'm going to split my screen here to",
    "start": "839600",
    "end": "844880"
  },
  {
    "text": "show um under upper right corner I've run the watch nodes command or WN and I",
    "start": "844880",
    "end": "852759"
  },
  {
    "text": "am seeing uh the list of nodes I have in the cluster as well as their instance",
    "start": "852759",
    "end": "859240"
  },
  {
    "text": "types and their current uh health status uh I on the upper left here I'm seeing",
    "start": "859240",
    "end": "866360"
  },
  {
    "text": "the list of running pods in my uh default namespace and uh here I'm just",
    "start": "866360",
    "end": "873320"
  },
  {
    "text": "running uh K9 and looking at the different uh name spaces that are in the",
    "start": "873320",
    "end": "881680"
  },
  {
    "start": "878000",
    "end": "966000"
  },
  {
    "text": "cluster uh the Amazon cloudwatch name space",
    "start": "881680",
    "end": "886920"
  },
  {
    "text": "um is created when you deploy the um eks",
    "start": "886920",
    "end": "892199"
  },
  {
    "text": "Cloud watch observability add-on uh and it uh basically collects uh health and",
    "start": "892199",
    "end": "900440"
  },
  {
    "text": "metrics utilization information from the cluster and uh publishes it on",
    "start": "900440",
    "end": "907079"
  },
  {
    "text": "cloudwatch container insights we'll see that later uh the uh hyperpod name space here has",
    "start": "907079",
    "end": "917440"
  },
  {
    "text": "um a number of uh heal check uh pods the ones that",
    "start": "917440",
    "end": "925600"
  },
  {
    "text": "we see uh as completed are de health checks that ran at initialization time",
    "start": "925600",
    "end": "932720"
  },
  {
    "text": "um their uh stress tests their connectivity tests for the EFA adopters",
    "start": "932720",
    "end": "938839"
  },
  {
    "text": "very very comprehensive and then for each of the nodes there is a uh Health",
    "start": "938839",
    "end": "944959"
  },
  {
    "text": "monitoring agent that is constantly uh screening for Hardware uh and uh uh",
    "start": "944959",
    "end": "954360"
  },
  {
    "text": "kernel um level failures which then can be remediated either by reboot or",
    "start": "954360",
    "end": "962000"
  },
  {
    "text": "replacement of the node um so let's run uh an example of",
    "start": "962000",
    "end": "971079"
  },
  {
    "start": "966000",
    "end": "1200000"
  },
  {
    "text": "distributed uh training in this cluster and since we have all of these node",
    "start": "971079",
    "end": "976480"
  },
  {
    "text": "groups we're going to run one uh training example on each node group on",
    "start": "976480",
    "end": "983480"
  },
  {
    "text": "the CPU uh instances we're going to run um",
    "start": "983480",
    "end": "989040"
  },
  {
    "text": "an image net CPU example on the uh A10 GPU instances we run the same",
    "start": "989040",
    "end": "997319"
  },
  {
    "text": "example only on gpus then on the h100s on the P5 nodes we're going to uh run a",
    "start": "997319",
    "end": "1004319"
  },
  {
    "text": "Lama 2 fsdp pre-training and on the um",
    "start": "1004319",
    "end": "1011440"
  },
  {
    "text": "neuron uh course on the trinium one nodes we're going to run llama 3",
    "start": "1011440",
    "end": "1017319"
  },
  {
    "text": "pre-training so uh I have",
    "start": "1017319",
    "end": "1022240"
  },
  {
    "text": "uh set up my uh cursor to broadcast what I type to all windows here uh so this is",
    "start": "1022639",
    "end": "1030438"
  },
  {
    "text": "the common part and here I want to do image net",
    "start": "1030439",
    "end": "1035640"
  },
  {
    "text": "CPU here I want imag net GPU here I",
    "start": "1035640",
    "end": "1043600"
  },
  {
    "text": "want um fsdp and here I I",
    "start": "1043600",
    "end": "1049640"
  },
  {
    "text": "want uh Lama Tree Train uh these uh",
    "start": "1049640",
    "end": "1055280"
  },
  {
    "text": "first two examples are available in the awsd hyperpod project the um latter two",
    "start": "1055280",
    "end": "1062000"
  },
  {
    "text": "are available in the awesome distributed training project uh we'll share all of",
    "start": "1062000",
    "end": "1067440"
  },
  {
    "text": "these uh links in the resources slide at the end but now I'm ready to basically",
    "start": "1067440",
    "end": "1073720"
  },
  {
    "text": "with one click kick off four training jobs and um each of them will go to",
    "start": "1073720",
    "end": "1080400"
  },
  {
    "text": "their respective compute resource on the hyperpod cluster and uh we're going to",
    "start": "1080400",
    "end": "1088320"
  },
  {
    "text": "see uh I'll just get the list of PODS here to see if uh everything is up and",
    "start": "1089720",
    "end": "1096760"
  },
  {
    "text": "running um so now everything is up and running and I'll use a command called",
    "start": "1096760",
    "end": "1104039"
  },
  {
    "text": "Cube tail or just KT uh as an alias and on the",
    "start": "1104039",
    "end": "1113559"
  },
  {
    "text": "first uh window I'll monitor the CPUs here the uh A10 gpus for image net here",
    "start": "1113559",
    "end": "1123039"
  },
  {
    "text": "I'll uh I'll do fsdp so I'm just specifying a",
    "start": "1123039",
    "end": "1129400"
  },
  {
    "text": "unique substring that grabs the pods that I'm interested in seeing and",
    "start": "1129400",
    "end": "1137200"
  },
  {
    "text": "then um this one will be Lama 3 so now with",
    "start": "1137200",
    "end": "1145559"
  },
  {
    "text": "one click I'm able to see an aggregated log of all of my all of my relevant",
    "start": "1145559",
    "end": "1153919"
  },
  {
    "text": "pods on each of the compute uh instance groups um on the CPUs training has",
    "start": "1153919",
    "end": "1163320"
  },
  {
    "text": "started we can see that it's going kind of slow on the A10 gpus training started",
    "start": "1163320",
    "end": "1170000"
  },
  {
    "text": "we can see it's going much faster than the CPUs and then uh on the",
    "start": "1170000",
    "end": "1176280"
  },
  {
    "text": "h100s um Lama 2 training is uh already started on the neuron course uh we're",
    "start": "1176280",
    "end": "1184440"
  },
  {
    "text": "going through initialization and um then we're going to compile uh the graph of the",
    "start": "1184440",
    "end": "1193039"
  },
  {
    "text": "model yeah it says successfully compiled graph over here and uh then training",
    "start": "1193039",
    "end": "1199520"
  },
  {
    "text": "will start so what are our nodes doing uh it would be really interesting to see",
    "start": "1199520",
    "end": "1205799"
  },
  {
    "start": "1200000",
    "end": "1381000"
  },
  {
    "text": "right now all of the compute and how uh the utilization is going um so we can do",
    "start": "1205799",
    "end": "1212000"
  },
  {
    "text": "this from the command line um and I'll do that now later we'll show also how to",
    "start": "1212000",
    "end": "1217520"
  },
  {
    "text": "do this from container insights uh for like immediate um view into uh the",
    "start": "1217520",
    "end": "1225039"
  },
  {
    "text": "utilization we can use uh uh h top for the",
    "start": "1225039",
    "end": "1230520"
  },
  {
    "text": "CPUs um NV top for the gpus and neuron top for the neuron course I've have set",
    "start": "1230520",
    "end": "1238280"
  },
  {
    "text": "up uh this uh view here on my next demo screen",
    "start": "1238280",
    "end": "1245159"
  },
  {
    "text": "on the top line uh we're running the htop command on both of these nodes uh",
    "start": "1245159",
    "end": "1251679"
  },
  {
    "text": "example of this is included the uh AWS do hyperpod project so um we're seeing",
    "start": "1251679",
    "end": "1259480"
  },
  {
    "text": "that the CPUs are utilized at close to 100% And then on the next line here we",
    "start": "1259480",
    "end": "1267280"
  },
  {
    "text": "have the uh two",
    "start": "1267280",
    "end": "1272360"
  },
  {
    "text": "gpus uh one of them has disconnected uh but I uh can reconnect",
    "start": "1272520",
    "end": "1281240"
  },
  {
    "text": "it here real quick and um to enlarge this screen uh this is",
    "start": "1281240",
    "end": "1287039"
  },
  {
    "text": "what we're looking at uh the GPU utilization single GPU on a G5",
    "start": "1287039",
    "end": "1294159"
  },
  {
    "text": "instance has um High GPU utilization and",
    "start": "1294159",
    "end": "1299279"
  },
  {
    "text": "since imet is a pretty small model the memory utilization on that GPU is",
    "start": "1299279",
    "end": "1305559"
  },
  {
    "text": "lower next uh line is the P5 instances with the eight h100 gpus uh this uh",
    "start": "1305559",
    "end": "1313600"
  },
  {
    "text": "looks like this our uh Lama 2 pre-training is going well and and uh",
    "start": "1313600",
    "end": "1319799"
  },
  {
    "text": "we're utilizing our gpus and uh here's a a visualization of",
    "start": "1319799",
    "end": "1326600"
  },
  {
    "text": "the memory and GPU utilization as well and",
    "start": "1326600",
    "end": "1332640"
  },
  {
    "text": "U finally uh when the uh neuron job is",
    "start": "1332640",
    "end": "1337880"
  },
  {
    "text": "started uh we can also see utilization of all of the neuron devices each node",
    "start": "1337880",
    "end": "1345159"
  },
  {
    "text": "has 16 neuron devices here and each neuron device has two neuron cores so in",
    "start": "1345159",
    "end": "1351720"
  },
  {
    "text": "all you have 32 neuron cores that are working in parallel on this um",
    "start": "1351720",
    "end": "1358559"
  },
  {
    "text": "pre-training of lamat Tre and uh we can",
    "start": "1358559",
    "end": "1364360"
  },
  {
    "text": "um uh drill down into each of the neuron",
    "start": "1364360",
    "end": "1370080"
  },
  {
    "text": "cores and basically uh see the uh",
    "start": "1370080",
    "end": "1376320"
  },
  {
    "text": "processes and the the utilization that uh it has so with this uh let me uh dive a little",
    "start": "1376320",
    "end": "1385200"
  },
  {
    "start": "1381000",
    "end": "1551000"
  },
  {
    "text": "deeper into resiliency uh as I mentioned",
    "start": "1385200",
    "end": "1392440"
  },
  {
    "text": "uh the health monitoring agent is uh",
    "start": "1392440",
    "end": "1397919"
  },
  {
    "text": "constantly looking for uh any errors to occur and I'm going to use my um uh CLI",
    "start": "1397919",
    "end": "1407760"
  },
  {
    "text": "in the uh do hyperpod project to inject a failure and simulate a failure in one",
    "start": "1407760",
    "end": "1415279"
  },
  {
    "text": "of my G5 nodes and see what happens so uh scripts for that are already provided",
    "start": "1415279",
    "end": "1423200"
  },
  {
    "text": "in um the deployment",
    "start": "1423200",
    "end": "1427559"
  },
  {
    "text": "folder so I have two ways of of simulating that failure one is um this",
    "start": "1435679",
    "end": "1443159"
  },
  {
    "text": "is a little bit of a of a hack it it actually injects a a log line in the",
    "start": "1443159",
    "end": "1450600"
  },
  {
    "text": "instance uh by running this uh script and then the other way is just um",
    "start": "1450600",
    "end": "1456799"
  },
  {
    "text": "tagging the instance for uh reboot or replacement but U I'll uh I'll do",
    "start": "1456799",
    "end": "1464880"
  },
  {
    "text": "um this one because it's more fun to inject the fault into the instance",
    "start": "1464880",
    "end": "1471480"
  },
  {
    "text": "so uh we'll inject a fault that requires a reboot to um remediate and I'll pick",
    "start": "1471480",
    "end": "1480880"
  },
  {
    "text": "this G5 instance over here",
    "start": "1480880",
    "end": "1486760"
  },
  {
    "text": "and as soon as I run this you will notice",
    "start": "1488480",
    "end": "1494080"
  },
  {
    "text": "that the Pod um a job was run that inserted this",
    "start": "1494080",
    "end": "1500919"
  },
  {
    "text": "failure uh into the uh system log and",
    "start": "1500919",
    "end": "1507080"
  },
  {
    "text": "then uh the the the node was immediately marked as unschedulable pending reboot",
    "start": "1507080",
    "end": "1514080"
  },
  {
    "text": "uh by uh the hyperpod service and now the node is in reboot mode the um job",
    "start": "1514080",
    "end": "1522880"
  },
  {
    "text": "that is running on it will the the Pod that that is running on",
    "start": "1522880",
    "end": "1529000"
  },
  {
    "text": "it will fail uh the job um will go into",
    "start": "1529000",
    "end": "1534320"
  },
  {
    "text": "a holding pattern while the job the node is rebooting but um then uh when the",
    "start": "1534320",
    "end": "1542919"
  },
  {
    "text": "node becomes uh ready and uh schedulable again uh the job will resume from the",
    "start": "1542919",
    "end": "1550159"
  },
  {
    "text": "last save checkpoint I this takes a little bit of time about 10 minutes or so uh so I've taken screenshots to show",
    "start": "1550159",
    "end": "1559120"
  },
  {
    "text": "how this looks uh there may be a little small but um here is the point where we",
    "start": "1559120",
    "end": "1566000"
  },
  {
    "text": "have injected the fault and then uh we have uh the uh worker pod uh error out",
    "start": "1566000",
    "end": "1576159"
  },
  {
    "text": "but the job continues to uh run the node becomes not ready",
    "start": "1576159",
    "end": "1582720"
  },
  {
    "text": "reboots become schedulable again and uh the job is resumed by uh",
    "start": "1582720",
    "end": "1591640"
  },
  {
    "text": "restarting that uh failed pod and uh it continues to work from the last save",
    "start": "1591640",
    "end": "1598960"
  },
  {
    "text": "checkpoint let's take a look at um how this cluster can be visualized in the",
    "start": "1598960",
    "end": "1606440"
  },
  {
    "start": "1599000",
    "end": "1815000"
  },
  {
    "text": "AWS console I have a view of uh AWS Sage",
    "start": "1606440",
    "end": "1611960"
  },
  {
    "text": "maker over here so now you can um in the menu uh drill down to hyperpod clusters",
    "start": "1611960",
    "end": "1619120"
  },
  {
    "text": "and go to Cluster management and you'll see a list of your",
    "start": "1619120",
    "end": "1625679"
  },
  {
    "text": "um uh hyperpod clusters when you drill down into your cluster you will uh see",
    "start": "1625679",
    "end": "1632440"
  },
  {
    "text": "its information uh the nodes their health status and uh the work groups",
    "start": "1632440",
    "end": "1639120"
  },
  {
    "text": "that are part of of this node of this uh of this cluster",
    "start": "1639120",
    "end": "1645000"
  },
  {
    "text": "um to observe the workloads that are running",
    "start": "1645000",
    "end": "1650120"
  },
  {
    "text": "on uh this um cluster there are many ways as we saw you can do that from the",
    "start": "1650120",
    "end": "1656520"
  },
  {
    "text": "command line also uh you're able to um just use a standard uh Prometheus",
    "start": "1656520",
    "end": "1664919"
  },
  {
    "text": "graphos stack uh instructions for that are provided in the workshop um and um in my opinion the",
    "start": "1664919",
    "end": "1672559"
  },
  {
    "text": "best way to visualize um the workloads is in your",
    "start": "1672559",
    "end": "1679159"
  },
  {
    "text": "cluster uh or and uh uh utilization metrics is through cloudwatch container",
    "start": "1679159",
    "end": "1687279"
  },
  {
    "text": "insights um which come out of the box with many um default tiles that are um",
    "start": "1687279",
    "end": "1695760"
  },
  {
    "text": "useful but can be customized to your liking as well so when you navigate to",
    "start": "1695760",
    "end": "1701240"
  },
  {
    "text": "uh Cloud watch and container insights uh then uh you're able to see kind of a",
    "start": "1701240",
    "end": "1708880"
  },
  {
    "text": "graph of your clusters and in the performance and summary tile right out",
    "start": "1708880",
    "end": "1714480"
  },
  {
    "text": "of the box you have uh hyperpod node health status uh then when you drill",
    "start": "1714480",
    "end": "1721000"
  },
  {
    "text": "into uh the cluster of your choice at uh cluster you",
    "start": "1721000",
    "end": "1727399"
  },
  {
    "text": "you can uh visualize metrics at all levels but uh hyperpod specific metrics",
    "start": "1727399",
    "end": "1733159"
  },
  {
    "text": "are um included on the cluster and uh nodes level by default",
    "start": "1733159",
    "end": "1738799"
  },
  {
    "text": "uh as we can see here uh since we're running um a lot uh of training jobs uh",
    "start": "1738799",
    "end": "1746840"
  },
  {
    "text": "our utilization is high uh both for uh CPUs gpus and neuron cores uh we have um",
    "start": "1746840",
    "end": "1757399"
  },
  {
    "text": "currently seven healthy and one unhealthy nodes because we injected that failure but uh this is in the process of",
    "start": "1757399",
    "end": "1764760"
  },
  {
    "text": "auto recovery so it will um eventually get to eight uh healthy nodes again uh",
    "start": "1764760",
    "end": "1774320"
  },
  {
    "text": "and on the Node level uh if we take a look we have",
    "start": "1774320",
    "end": "1779880"
  },
  {
    "text": "detailed um again uh CPU GPU",
    "start": "1779880",
    "end": "1786679"
  },
  {
    "text": "utilization uh disk utilization including EFA Network",
    "start": "1786679",
    "end": "1792360"
  },
  {
    "text": "utilization uh this is important how the interconnect between all of our nodes in",
    "start": "1792360",
    "end": "1797679"
  },
  {
    "text": "in our distributed um training infrastructure uh is",
    "start": "1797679",
    "end": "1802760"
  },
  {
    "text": "working and um finally we have the um hyperpod",
    "start": "1802760",
    "end": "1811080"
  },
  {
    "text": "resiliency metrics as well included right here so this all comes out of the box",
    "start": "1811080",
    "end": "1818039"
  },
  {
    "start": "1815000",
    "end": "2075000"
  },
  {
    "text": "you can build custom dashboards but it is really really convenient to just uh",
    "start": "1818039",
    "end": "1823159"
  },
  {
    "text": "deploy the observability add-on and um",
    "start": "1823159",
    "end": "1828559"
  },
  {
    "text": "get all of this information right in your cloudwatch container insights next I would like to go over",
    "start": "1828559",
    "end": "1835960"
  },
  {
    "text": "some resources that might be helpful uh for you um first and foremost the",
    "start": "1835960",
    "end": "1841919"
  },
  {
    "text": "hyperpod eks workshop is a resource that",
    "start": "1841919",
    "end": "1847120"
  },
  {
    "text": "you could use either in your own account or as part of an aw AWS event or",
    "start": "1847120",
    "end": "1853320"
  },
  {
    "text": "enablement um series uh or talk to your uh account uh Team about setting uh up a",
    "start": "1853320",
    "end": "1862880"
  },
  {
    "text": "dedicated uh event for you um this would",
    "start": "1862880",
    "end": "1869039"
  },
  {
    "text": "uh give you all um information about how to use and uh provision and manage your",
    "start": "1869039",
    "end": "1877799"
  },
  {
    "text": "uh workloads on uh sagemaker hyperpod the getting started quickly out of the",
    "start": "1877799",
    "end": "1884880"
  },
  {
    "text": "box experience uh you get from the the AWS do hyperpod project is available",
    "start": "1884880",
    "end": "1891080"
  },
  {
    "text": "from GitHub just clone the project run the build and run scripts and you you're",
    "start": "1891080",
    "end": "1896279"
  },
  {
    "text": "up and running uh if uh you prefer you could just pull uh the container from uh",
    "start": "1896279",
    "end": "1904000"
  },
  {
    "text": "the uh public catalog on uh the public uh elastic container registry Amazon",
    "start": "1904000",
    "end": "1912320"
  },
  {
    "text": "hosts uh so you don't even have to clone and build the project and um next",
    "start": "1912320",
    "end": "1918440"
  },
  {
    "text": "the sagemaker hyperpod CLI is also available on GitHub and uh you're able",
    "start": "1918440",
    "end": "1924600"
  },
  {
    "text": "to uh install that in any environment that you wish um the awesome distributed",
    "start": "1924600",
    "end": "1931440"
  },
  {
    "text": "training project is a resource that uh provides examples architectures and",
    "start": "1931440",
    "end": "1939559"
  },
  {
    "text": "tests both for slurm and eks based clusters the AWS duay project is is not",
    "start": "1939559",
    "end": "1948600"
  },
  {
    "text": "hyperpod specific but because it's built on top of eks uh it runs out of the box",
    "start": "1948600",
    "end": "1956159"
  },
  {
    "text": "on um sagemaker hyperpod uh with eks support and it enables you to create uh",
    "start": "1956159",
    "end": "1965720"
  },
  {
    "text": "Ray clusters on eks and run distributed training and inference jobs there are",
    "start": "1965720",
    "end": "1971519"
  },
  {
    "text": "examples for that provided in the project and finally the awesome inference project uh have has uh several",
    "start": "1971519",
    "end": "1979519"
  },
  {
    "text": "useful inference uh examples uh for",
    "start": "1979519",
    "end": "1984639"
  },
  {
    "text": "eks um including running Nvidia Nims um i' like to wrap up by these",
    "start": "1984639",
    "end": "1992080"
  },
  {
    "text": "three takeaways first Sage maker hyperpod provides purpose-built infrastructure",
    "start": "1992080",
    "end": "1999799"
  },
  {
    "text": "for your ml Andi workloads um it has resilience",
    "start": "1999799",
    "end": "2006519"
  },
  {
    "text": "capabilities which ensure that Hardware failures are detected and resolved",
    "start": "2006519",
    "end": "2012360"
  },
  {
    "text": "automatically on the customer's behalf and you can orchestrate your jobs on",
    "start": "2012360",
    "end": "2019679"
  },
  {
    "text": "sagemaker hyperpod using slurm or eks or hyperpod CLI it's a very open system and",
    "start": "2019679",
    "end": "2029279"
  },
  {
    "text": "um it um adjusts to uh what is most",
    "start": "2029279",
    "end": "2034320"
  },
  {
    "text": "comfortable for you uh to make using uh AWS infrastructure uh easier and uh more",
    "start": "2034320",
    "end": "2043120"
  },
  {
    "text": "productive for our customers last I'd like to say thank you",
    "start": "2043120",
    "end": "2048398"
  },
  {
    "text": "to all of my colleagues who worked on the um Sage maker hyperpod service and",
    "start": "2048399",
    "end": "2055480"
  },
  {
    "text": "made this possible I also want to say thank you to our viewers I hope you",
    "start": "2055480",
    "end": "2061320"
  },
  {
    "text": "found this video useful and I look forward to learning about all the",
    "start": "2061320",
    "end": "2066440"
  },
  {
    "text": "amazing things you're going to build on AWS using Sage maker hyperpod",
    "start": "2066440",
    "end": "2074319"
  }
]
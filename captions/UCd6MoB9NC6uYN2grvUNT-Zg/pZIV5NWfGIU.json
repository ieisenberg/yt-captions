[
  {
    "start": "0",
    "end": "120000"
  },
  {
    "text": "good morning good afternoon everybody thanks so much for joining us today we've got a great webinar lined up for",
    "start": "4600",
    "end": "11350"
  },
  {
    "text": "you we are this is the fourth webinar in our private series that is just for you guys the AWS machine learning competency",
    "start": "11350",
    "end": "18190"
  },
  {
    "text": "partners so we're thrilled to have you today we've got I just want to introduce our presenters our main presenter today",
    "start": "18190",
    "end": "25360"
  },
  {
    "text": "is Pratap Rama Murthy he is a partner Solutions Architect he works with AWS partners and helps them build their",
    "start": "25360",
    "end": "31000"
  },
  {
    "text": "solutions on top of AWS he works with partners that specialize in machine learning and AI prior to AWS he was a",
    "start": "31000",
    "end": "37870"
  },
  {
    "text": "researcher where he worked on creating quantum dot lasers test tools for web servers and optimized Wi-Fi using game",
    "start": "37870",
    "end": "43960"
  },
  {
    "text": "theory currently he focuses on machine learning specifically natural language processing which is a lot of what we're",
    "start": "43960",
    "end": "50379"
  },
  {
    "text": "going to talk about today also on the call with us today is Chris burns and he's going to be kind of handling the",
    "start": "50379",
    "end": "55989"
  },
  {
    "text": "the QA and the chat in the bottom right corner of your nav chris is also a",
    "start": "55989",
    "end": "62469"
  },
  {
    "text": "senior partner solutions architect with an AI ml specialty he used to be a mechanical engineer who installed and",
    "start": "62469",
    "end": "67870"
  },
  {
    "text": "maintained industrial robots and now uses his 18 years of industry experience in software development distributed",
    "start": "67870",
    "end": "73899"
  },
  {
    "text": "solution architecture and machine learning to help partners across the entire AWS ml stack so those are the the",
    "start": "73899",
    "end": "82390"
  },
  {
    "text": "folks that are going to be presenting and answering your questions on the call today that I said that in the kind of",
    "start": "82390",
    "end": "89380"
  },
  {
    "text": "the bottom right nav of this right toolbar you see it questions pane and",
    "start": "89380",
    "end": "94600"
  },
  {
    "text": "you also see a chat pane either wet either place is fine to put your questions Chris is going to be monitoring those and we'll try to answer",
    "start": "94600",
    "end": "100869"
  },
  {
    "text": "some of those live throughout the call but in any case they'll be documented as we answer those questions here so that",
    "start": "100869",
    "end": "107530"
  },
  {
    "text": "people who see this recording or if you want to come back and look at it again you can kind of take a look at what those questions were so without further",
    "start": "107530",
    "end": "115659"
  },
  {
    "text": "ado I would love to introduce / top and let's get started oh thank you sue and",
    "start": "115659",
    "end": "122140"
  },
  {
    "start": "120000",
    "end": "201000"
  },
  {
    "text": "thanks everyone for joining us today like she said this is the fourth in the",
    "start": "122140",
    "end": "128020"
  },
  {
    "text": "webinar series and my name is Pratap I'm a partner solution Sark's and I work with machine learning partners today",
    "start": "128020",
    "end": "134230"
  },
  {
    "text": "we're going to be talking about sequence to sequence algorithm one of the most complex algorithms in",
    "start": "134230",
    "end": "141480"
  },
  {
    "text": "the suite alright so this is the schedule that we have I think we had two",
    "start": "141480",
    "end": "147930"
  },
  {
    "text": "before and today is the sequence to sequence algorithm and here is a tentative schedule for the next ones I",
    "start": "147930",
    "end": "155040"
  },
  {
    "text": "just want to give a upfront information about I think the title of the webinar",
    "start": "155040",
    "end": "161130"
  },
  {
    "text": "initially said that it's going to be sequence to sequence and blazing text these these two are related",
    "start": "161130",
    "end": "168360"
  },
  {
    "text": "algorithms related to natural language processing usually blazing text is what people would use to convert words into a",
    "start": "168360",
    "end": "177780"
  },
  {
    "text": "lower dimensional space and then run on a sequence of sequence algorithms or other algorithms but based on feedback",
    "start": "177780",
    "end": "184710"
  },
  {
    "text": "and popular demand we're going to be focusing on one of the algorithms today and we will be focusing looking at",
    "start": "184710",
    "end": "192000"
  },
  {
    "text": "blazing text at a future date right now we have the date of September 6th up as",
    "start": "192000",
    "end": "197910"
  },
  {
    "text": "you can see in light number 6 here all right let's get on with the today's",
    "start": "197910",
    "end": "203040"
  },
  {
    "start": "201000",
    "end": "561000"
  },
  {
    "text": "webinar a sequence to sequence algorithm what is a sequence a sequence algorithm",
    "start": "203040",
    "end": "208200"
  },
  {
    "text": "a sequel to sequence algorithm is an algorithm which takes a string of inputs",
    "start": "208200",
    "end": "215010"
  },
  {
    "text": "and produces another string of inputs so you may remain I've heard about regression algorithms which predicts a",
    "start": "215010",
    "end": "222300"
  },
  {
    "text": "number or classification algorithm which predicts one among the N classes this is",
    "start": "222300",
    "end": "229530"
  },
  {
    "text": "a different kind of a machine learning problem or we can say this is a classification problem where it's trying",
    "start": "229530",
    "end": "234900"
  },
  {
    "text": "to a class find the predictor sequence but this is that is that does not really",
    "start": "234900",
    "end": "241380"
  },
  {
    "text": "help because the metrics are different and so on right what is the use for sequence the sequence while it's it's a",
    "start": "241380",
    "end": "248520"
  },
  {
    "text": "general-purpose sequence to sequence you can think of like providing this algorithm with any sequence and",
    "start": "248520",
    "end": "255450"
  },
  {
    "text": "expecting another sequence but this problem is usually handled in natural",
    "start": "255450",
    "end": "260459"
  },
  {
    "text": "language processing our NLP our computational linguistics and this has",
    "start": "260460",
    "end": "266970"
  },
  {
    "text": "been a the primary driver four dramatically improving the accuracy",
    "start": "266970",
    "end": "274889"
  },
  {
    "text": "of translation services so a new field of of translation is called neural",
    "start": "274889",
    "end": "282539"
  },
  {
    "text": "machine translation nmt that is a first use case here is what is being",
    "start": "282539",
    "end": "289759"
  },
  {
    "text": "dramatically improved by by this class of algorithms and this is this is like I",
    "start": "289759",
    "end": "297240"
  },
  {
    "text": "think it becomes immediately intuitive right so you provide a string of words or a sentence a sentence is a sequence",
    "start": "297240",
    "end": "304440"
  },
  {
    "text": "of words and into this algorithm and after its trained when you are predicting when you give this input it",
    "start": "304440",
    "end": "311520"
  },
  {
    "text": "produces another string of words in another language so you can translate use the machine to translate from one",
    "start": "311520",
    "end": "319110"
  },
  {
    "text": "human language to another language this is a this is a as you can see you can",
    "start": "319110",
    "end": "325259"
  },
  {
    "text": "you can read many of the papers this has improved the blue scores quite a bit the second kind second use case our",
    "start": "325259",
    "end": "331979"
  },
  {
    "text": "summarize errs summarize errs are very important for media where you take you",
    "start": "331979",
    "end": "339840"
  },
  {
    "text": "provide a large text like a like an entire document like a article this",
    "start": "339840",
    "end": "347009"
  },
  {
    "text": "could be like 2,000 words and so on and it produces a one paragraph that",
    "start": "347009",
    "end": "352169"
  },
  {
    "text": "summarizes the content of that large article these there are several",
    "start": "352169",
    "end": "358560"
  },
  {
    "text": "different ways of doing this but sequels to sequences is one of the ways you can do this the third of speech to text this",
    "start": "358560",
    "end": "365940"
  },
  {
    "text": "is a slightly different form and where you provide the speech and then it",
    "start": "365940",
    "end": "373710"
  },
  {
    "text": "creates a string of of words which which maximizes the prediction but the first",
    "start": "373710",
    "end": "379919"
  },
  {
    "text": "two use cases are much more relevant where you really provide a string and",
    "start": "379919",
    "end": "384930"
  },
  {
    "text": "expect the screen ok but even there are there are subtleties to this right let's",
    "start": "384930",
    "end": "390780"
  },
  {
    "text": "take it so this in this webinar I'm going to be focusing on the neural machine translation and let's let's look",
    "start": "390780",
    "end": "397650"
  },
  {
    "text": "at machine translation what is uh what is the use cases even with machine",
    "start": "397650",
    "end": "403199"
  },
  {
    "text": "translation this problem is not a single problem but is more of a class of problems let me",
    "start": "403199",
    "end": "408900"
  },
  {
    "text": "explain how that works right so when you take translation when we as human beings know a language when we know more than",
    "start": "408900",
    "end": "415830"
  },
  {
    "text": "one language and then we can translate we actually do it intuitively but we actually do several things at the same",
    "start": "415830",
    "end": "422249"
  },
  {
    "text": "time that is the problem of translation of a single word is is just like a",
    "start": "422249",
    "end": "428580"
  },
  {
    "text": "lookup right from one vocabulary to another vocabulary based on the context that is a different problem compared to",
    "start": "428580",
    "end": "435840"
  },
  {
    "text": "a short phrase how do you translate a short phrase from one language to",
    "start": "435840",
    "end": "441509"
  },
  {
    "text": "another I compared to a sentence level translation where you provide a sentence",
    "start": "441509",
    "end": "447689"
  },
  {
    "text": "the sentence is usually anywhere between a few words up to 60 or 70 words",
    "start": "447689",
    "end": "453210"
  },
  {
    "text": "typically but there are sentences that are much longer the the problem becomes",
    "start": "453210",
    "end": "459509"
  },
  {
    "text": "very different at that point where there should be a grammatical structure and it",
    "start": "459509",
    "end": "465150"
  },
  {
    "text": "should capture all the things said in the sentence at the same time it should",
    "start": "465150",
    "end": "470400"
  },
  {
    "text": "it should be within the length a different translation would be a",
    "start": "470400",
    "end": "475439"
  },
  {
    "text": "document level translation where the context so for example you could take of",
    "start": "475439",
    "end": "481169"
  },
  {
    "text": "a think of a entire book being translated in this case a the B problem",
    "start": "481169",
    "end": "487770"
  },
  {
    "text": "becomes very different because things said in the like say the first chapter such as introduction of characters in",
    "start": "487770",
    "end": "494969"
  },
  {
    "text": "that story might not be repeated in the fourth with an illness chapters that",
    "start": "494969",
    "end": "500099"
  },
  {
    "text": "come after that so but but when folks read this when human beings read in a",
    "start": "500099",
    "end": "505589"
  },
  {
    "text": "book or a story is that said in the book they would remember the characters and",
    "start": "505589",
    "end": "511710"
  },
  {
    "text": "what they did before the first chapters and then continue to understand what is happening through the entire text of the",
    "start": "511710",
    "end": "518010"
  },
  {
    "text": "book and this this becomes a much bigger problem for here for machines because",
    "start": "518010",
    "end": "524490"
  },
  {
    "text": "machines really do not understand the meaning of words they only have a",
    "start": "524490",
    "end": "529769"
  },
  {
    "text": "representation and it is not possible for machines to do this very easily so",
    "start": "529769",
    "end": "534899"
  },
  {
    "text": "that becomes a very different problem when it's trying to translate things they like the chat that in the",
    "start": "534899",
    "end": "540400"
  },
  {
    "text": "later chapters right some even machine translations as you can see is is very varied and that that is what beings with",
    "start": "540400",
    "end": "548620"
  },
  {
    "text": "which richness to this problem today what we'll be seeing is sentence level",
    "start": "548620",
    "end": "555240"
  },
  {
    "text": "translations that that is a use case you'll be looking at for sequence to sequence algorithm ok and so just a",
    "start": "555240",
    "end": "565420"
  },
  {
    "start": "561000",
    "end": "715000"
  },
  {
    "text": "quick warning that I will start slow like this is a this is a very in-depth",
    "start": "565420",
    "end": "571630"
  },
  {
    "text": "in a topic there's a there's several levels of depth to this so I was trying",
    "start": "571630",
    "end": "578200"
  },
  {
    "text": "to start to bring everybody the same page but it would wrap up pretty quickly so don't worry if you are not if you're",
    "start": "578200",
    "end": "586450"
  },
  {
    "text": "new to this topic it may not be easy to follow but you can always refer back to this and and be able to catch on all",
    "start": "586450",
    "end": "592990"
  },
  {
    "text": "right so before we understand sequence the sequence the core of this is our names are LST ins but before we may",
    "start": "592990",
    "end": "599650"
  },
  {
    "text": "understand Arlen's or LS CMS which is a form of deep learning let's first understand how neural networks this is",
    "start": "599650",
    "end": "606400"
  },
  {
    "text": "an example neural network the yellow ones yellow nodes are the input neurons and",
    "start": "606400",
    "end": "613990"
  },
  {
    "text": "that's where you insert you provide input it flows through propagates",
    "start": "613990",
    "end": "619620"
  },
  {
    "text": "through the network and you get an output at the end to the right so there's propagation from left to",
    "start": "619620",
    "end": "625690"
  },
  {
    "text": "right in this diagram but the important point about this is it each node you are",
    "start": "625690",
    "end": "631510"
  },
  {
    "text": "each neuron calculates a linear combination of the inputs that applies",
    "start": "631510",
    "end": "636880"
  },
  {
    "text": "an activation function and then sends the input to the next layer since the",
    "start": "636880",
    "end": "642130"
  },
  {
    "text": "output sorry the next layer but if you notice one thing about this is the input the the",
    "start": "642130",
    "end": "649300"
  },
  {
    "text": "neural network does not maintain any state that is you provide an input it",
    "start": "649300",
    "end": "654700"
  },
  {
    "text": "gives you an output the story ends there right so if you want another prediction you probably a different input it never",
    "start": "654700",
    "end": "660850"
  },
  {
    "text": "remembers what the input was before this input is this during the inference face",
    "start": "660850",
    "end": "668290"
  },
  {
    "text": "that is I'm not talking about the training face doing inference face each input is taken separately and it does",
    "start": "668290",
    "end": "675660"
  },
  {
    "text": "not maintain any state at all the only thing the neural network remembers is its own weights and the network model",
    "start": "675660",
    "end": "682350"
  },
  {
    "text": "impressed architecture itself okay now this is a problem when you're looking at",
    "start": "682350",
    "end": "688770"
  },
  {
    "text": "a string of words like a sentence where and this is not how we process things in",
    "start": "688770",
    "end": "696480"
  },
  {
    "text": "natural language right so when I speak the sentence you are hearing the first word and the next words and so it's more",
    "start": "696480",
    "end": "703710"
  },
  {
    "text": "of a sequence of words and you progressively understand what MB I'm saying or when you're reading as well so",
    "start": "703710",
    "end": "710250"
  },
  {
    "text": "that this does not amend very well for those kinds of problems so so what we",
    "start": "710250",
    "end": "716550"
  },
  {
    "start": "715000",
    "end": "783000"
  },
  {
    "text": "have is a is a different kind of network called record neural networks are RN",
    "start": "716550",
    "end": "721830"
  },
  {
    "text": "ends what you're seeing is a single neuron and it operates pretty if there",
    "start": "721830",
    "end": "728580"
  },
  {
    "text": "is some intuition to this and as we let explain this so here the input is sent",
    "start": "728580",
    "end": "733770"
  },
  {
    "text": "from the bottom right where a is the neuron here it has some computational",
    "start": "733770",
    "end": "740370"
  },
  {
    "text": "power in there right it does some computation like maybe a paper exposure",
    "start": "740370",
    "end": "747960"
  },
  {
    "text": "publication or activation functions and so on and you then get output that is",
    "start": "747960",
    "end": "754410"
  },
  {
    "text": "represented as HT it's called hidden state and what happens next is it",
    "start": "754410",
    "end": "761970"
  },
  {
    "text": "remembers something that was said about the first input and so when you send the",
    "start": "761970",
    "end": "767910"
  },
  {
    "text": "second word in the in the sequence it is going to use that it's going to use that",
    "start": "767910",
    "end": "773900"
  },
  {
    "text": "to combine that with the second input and then make a computation of that and then return a sequence of outputs so",
    "start": "773900",
    "end": "781890"
  },
  {
    "text": "this is a single neuron right but it's a little harder to understand so we",
    "start": "781890",
    "end": "787020"
  },
  {
    "start": "783000",
    "end": "1069000"
  },
  {
    "text": "usually represent in is what's called unrolled diagram it's these two diagrams",
    "start": "787020",
    "end": "792510"
  },
  {
    "text": "are pretty much the same but this is makes it a little easier to visualize what is going on please note that the",
    "start": "792510",
    "end": "800580"
  },
  {
    "text": "picture on the right side is the same as a picture on the left the picture on the right does not have four",
    "start": "800580",
    "end": "806010"
  },
  {
    "text": "it's the same Arnon node or cell right so let me restate what I said before",
    "start": "806010",
    "end": "812340"
  },
  {
    "text": "so the first stage is let's say you're you're giving input x0 to the neuron",
    "start": "812340",
    "end": "819560"
  },
  {
    "text": "it's going to do some kind of a processing maintain some state also a given output of h0 right and then you",
    "start": "819560",
    "end": "828210"
  },
  {
    "text": "move on to time step T equals 1 and now you're you're providing input number x1",
    "start": "828210",
    "end": "834540"
  },
  {
    "text": "that is the second word maybe and now it takes this it senses maintain the state",
    "start": "834540",
    "end": "840420"
  },
  {
    "text": "now you're adding a new input is going to take that processing and also create a second output that is h1 and then it",
    "start": "840420",
    "end": "847980"
  },
  {
    "text": "moves on until you provide X n again it this would be the final character or a",
    "start": "847980",
    "end": "855270"
  },
  {
    "text": "terminating word which would term it which would tell the the the cell are in",
    "start": "855270",
    "end": "860370"
  },
  {
    "text": "cells that the sequence has terminated and this would this would also be absorbed there will be some computation",
    "start": "860370",
    "end": "867480"
  },
  {
    "text": "and it would it would emit HN so this is this is the intuition or a very",
    "start": "867480",
    "end": "873120"
  },
  {
    "text": "high-level use of RN a recurrent neural networks but the problem was that so this is this",
    "start": "873120",
    "end": "881070"
  },
  {
    "text": "is also an unroll another way to look at things and it's the same picture as",
    "start": "881070",
    "end": "886200"
  },
  {
    "text": "before here we mark inputs as XT minus 1 T and T plus 1 what you're seeing in the",
    "start": "886200",
    "end": "893520"
  },
  {
    "text": "middle is like an x-ray view of what is happening internally where when you are",
    "start": "893520",
    "end": "898910"
  },
  {
    "text": "providing the XT T input to the cell it",
    "start": "898910",
    "end": "905220"
  },
  {
    "text": "has from that you can see from the left side that it has it is taking some input from before this is this is the hidden",
    "start": "905220",
    "end": "912690"
  },
  {
    "text": "state or s state of these cells it takes that input or that state combines that",
    "start": "912690",
    "end": "920820"
  },
  {
    "text": "with a new input and then you apply it performs some kind of a computation a plays an activation function at an itch",
    "start": "920820",
    "end": "928320"
  },
  {
    "text": "for example here you made aware of tannish function from neural networks as well and once it's computed computed",
    "start": "928320",
    "end": "935070"
  },
  {
    "text": "this is going to emit an external output called HT at Pitt State and then",
    "start": "935070",
    "end": "942140"
  },
  {
    "text": "it's continuing to going to save this as a state to be passed on to the next state so this is this if you look at",
    "start": "942140",
    "end": "949010"
  },
  {
    "text": "this this is kind of very similar to a neuron how new networks except that now you have a state being maintained in",
    "start": "949010",
    "end": "956300"
  },
  {
    "text": "this in this cell this is what is what what is called what we would call a cell",
    "start": "956300",
    "end": "962560"
  },
  {
    "text": "but there are they found that there are some real heart problems with this like",
    "start": "962560",
    "end": "969230"
  },
  {
    "text": "all this was fine but the main problem was that the organs are really hard to",
    "start": "969230",
    "end": "976279"
  },
  {
    "text": "train and they are extremely hard to to",
    "start": "976279",
    "end": "982730"
  },
  {
    "text": "find the right parameters to make it work Ireland's do work but there anybody",
    "start": "982730",
    "end": "988060"
  },
  {
    "text": "it's like a it's it's super hard to find the right parameters to make it work",
    "start": "988060",
    "end": "993290"
  },
  {
    "text": "there are additional - parameters in addition to the ones you are familiar with in a normal neural network so what",
    "start": "993290",
    "end": "1002050"
  },
  {
    "text": "happens is it also suffers from from a concept called vanishing gradient or exploding gradient",
    "start": "1002050",
    "end": "1008260"
  },
  {
    "text": "the vanishing gradient says that as you're multiplying this across a",
    "start": "1008260",
    "end": "1013630"
  },
  {
    "text": "sequence let's say you have a sequence of 60 words you're multiplying these",
    "start": "1013630",
    "end": "1019480"
  },
  {
    "text": "words are inputs with a very small number let's say it's like point zero",
    "start": "1019480",
    "end": "1024520"
  },
  {
    "text": "one and if you multiply this say 60 times it becomes a really small number",
    "start": "1024520",
    "end": "1030610"
  },
  {
    "text": "so that's called a vanishing gradient problem or in other words it could either be it could have a very large",
    "start": "1030610",
    "end": "1037720"
  },
  {
    "text": "number and so what would happen is it would explore that they learn as you continue to multiply in this operation",
    "start": "1037720",
    "end": "1044350"
  },
  {
    "text": "right here this one continued to explore and it become a really large number at which point at both these points either",
    "start": "1044350",
    "end": "1051340"
  },
  {
    "text": "at zero are at a really large number the gradient is not the where you have the",
    "start": "1051340",
    "end": "1056470"
  },
  {
    "text": "right variance where it would it would it would stop learning it would go to",
    "start": "1056470",
    "end": "1061660"
  },
  {
    "text": "one end of the spectrum and would stop learning so you need to make really careful the way that you configure this",
    "start": "1061660",
    "end": "1070240"
  },
  {
    "text": "right so that's how that's one peep came with a new something a new type of cell called long short-term memory this",
    "start": "1070240",
    "end": "1078520"
  },
  {
    "text": "is kind of very similar to Ireland except that it has some more additional operations right let's look at it list",
    "start": "1078520",
    "end": "1086230"
  },
  {
    "text": "briefly because this is the core of a sequence to sequence model right so if",
    "start": "1086230",
    "end": "1092170"
  },
  {
    "text": "you look at this as you can see this is a hidden state right this horizontal line that is passing through the cell",
    "start": "1092170",
    "end": "1097660"
  },
  {
    "text": "this is the state that is maintained by the cell a new input comes in there is",
    "start": "1097660",
    "end": "1103210"
  },
  {
    "text": "some more additional parameters additional other operations that are done on the on the on the inputs and",
    "start": "1103210",
    "end": "1110650"
  },
  {
    "text": "you're adding to the state in addition to that what you're doing is you're also be sending an output but don't worry too",
    "start": "1110650",
    "end": "1117820"
  },
  {
    "text": "much about the operations here because this is only a sample operation as",
    "start": "1117820",
    "end": "1122830"
  },
  {
    "text": "people realize that the state or the operation of cells need not be confined",
    "start": "1122830",
    "end": "1128530"
  },
  {
    "text": "to a simple operation they came up with many different kinds of LS TMS so it's",
    "start": "1128530",
    "end": "1133750"
  },
  {
    "text": "not just a single Elliston that's out there there are lots and lots of different kinds of LS CMS and that does",
    "start": "1133750",
    "end": "1140620"
  },
  {
    "text": "each one could do a different thing but the main important thing to note is what is called a a B gating factor right so",
    "start": "1140620",
    "end": "1148780"
  },
  {
    "text": "this part is probably the most important where it takes the input and what it tells you is the problem it's tries to",
    "start": "1148780",
    "end": "1156550"
  },
  {
    "text": "solve the problem with regular ireland's that is it tries to tell you which of",
    "start": "1156550",
    "end": "1162970"
  },
  {
    "text": "the words does which of the sequences in the past",
    "start": "1162970",
    "end": "1168190"
  },
  {
    "text": "needs to be taken into account for this output right so this is called a gating",
    "start": "1168190",
    "end": "1174010"
  },
  {
    "text": "factor where in addition to the sequence in addition to the state it also tells",
    "start": "1174010",
    "end": "1179590"
  },
  {
    "text": "takes a opinion on whether whether a sequence from the history should be",
    "start": "1179590",
    "end": "1186340"
  },
  {
    "text": "considered as a for this computation at this point a tee-time is equal to t",
    "start": "1186340",
    "end": "1193360"
  },
  {
    "text": "right so that is the most important concept and this has enabled to solve",
    "start": "1193360",
    "end": "1199570"
  },
  {
    "text": "the exploding or vanishing gradient a problem to a large extent and you right",
    "start": "1199570",
    "end": "1205420"
  },
  {
    "text": "now you almost never see Ireland's the the plain old Ireland's being you Cleese",
    "start": "1205420",
    "end": "1210790"
  },
  {
    "text": "utilized it's usually the LST ins that are being utilized right so obviously",
    "start": "1210790",
    "end": "1217900"
  },
  {
    "text": "that this is this has worked for a lot of folks and I do want to at this point refer to the blog post from which I've",
    "start": "1217900",
    "end": "1225850"
  },
  {
    "text": "taken these excellent pictures and the references in the bottom I would highly recommend that you read this blog post",
    "start": "1225850",
    "end": "1231460"
  },
  {
    "text": "as well which describes LSC aims to a great extent alright so those are Ellis",
    "start": "1231460",
    "end": "1237070"
  },
  {
    "text": "teams right now I this provides a sequence the sequence right you provide",
    "start": "1237070",
    "end": "1242500"
  },
  {
    "text": "XPS 0 to n and then it gives you H 0 to n but this is not how you would actually",
    "start": "1242500",
    "end": "1250570"
  },
  {
    "text": "use this you could use this a lsdm just",
    "start": "1250570",
    "end": "1256030"
  },
  {
    "text": "like this but this is not proven to work very well for machine translations right",
    "start": "1256030",
    "end": "1262990"
  },
  {
    "start": "1261000",
    "end": "1473000"
  },
  {
    "text": "let's look at how how it was modified so a new architecture was proposed I think",
    "start": "1262990",
    "end": "1269920"
  },
  {
    "text": "the year 2014 which is called an encoder decoder architecture let's look at how",
    "start": "1269920",
    "end": "1275290"
  },
  {
    "text": "it works right this is this is probably the most important picture of this presentation",
    "start": "1275290",
    "end": "1281590"
  },
  {
    "text": "right so what you're looking here is a sequence and how an input and output",
    "start": "1281590",
    "end": "1288100"
  },
  {
    "text": "input is being presented to the LST M and how the output is taken out as you",
    "start": "1288100",
    "end": "1293590"
  },
  {
    "text": "can see the rectangular boxes represent lsdm cells right this is unrolled picture so this is 1 and this is 1 so",
    "start": "1293590",
    "end": "1301300"
  },
  {
    "text": "what you're doing is you're providing the input is ABC and you would always see in NLP you'll always see the symbol",
    "start": "1301300",
    "end": "1307990"
  },
  {
    "text": "called a OS it stands for end of sentence right so here the input sequence we are",
    "start": "1307990",
    "end": "1313930"
  },
  {
    "text": "giving here is ABC and a sentence and the output that it's providing you is W",
    "start": "1313930",
    "end": "1321190"
  },
  {
    "text": "X Y Z end of sentence right but there is a key difference between this and the",
    "start": "1321190",
    "end": "1327550"
  },
  {
    "text": "previous picture right the picture is at T equals 0 you are percent providing the",
    "start": "1327550",
    "end": "1333550"
  },
  {
    "text": "input a - the lsdm it does some processing changes internal state also gives you",
    "start": "1333550",
    "end": "1340670"
  },
  {
    "text": "moves on to the next stage if you notice there is no output at a at T equal to",
    "start": "1340670",
    "end": "1346250"
  },
  {
    "text": "zero and then you are providing the the input B the second word",
    "start": "1346250",
    "end": "1353090"
  },
  {
    "text": "it changes the state it continues on there is no output and then you provide",
    "start": "1353090",
    "end": "1358160"
  },
  {
    "text": "a C and finally you provide the end of sentence or a termination word - this",
    "start": "1358160",
    "end": "1365450"
  },
  {
    "text": "I just want if you notice it is not provided any output and you come to this point so what they have been able to",
    "start": "1365450",
    "end": "1372200"
  },
  {
    "text": "identify with this or achieved with this method is that it's absorbed the",
    "start": "1372200",
    "end": "1377420"
  },
  {
    "text": "sequence of words until the end of sentence that it's not given as not started translating and until this point",
    "start": "1377420",
    "end": "1384200"
  },
  {
    "text": "so at this point the internal state actually contains a representation of",
    "start": "1384200",
    "end": "1389960"
  },
  {
    "text": "the entire sentence sequence right it's not just this it is not just a bag of",
    "start": "1389960",
    "end": "1396680"
  },
  {
    "text": "words representation this is this contains the representation of the",
    "start": "1396680",
    "end": "1402680"
  },
  {
    "text": "person this particular sequence of words and and at this point now that it's",
    "start": "1402680",
    "end": "1408590"
  },
  {
    "text": "noted that it's received all the inputs that it can receive from this input string it starts to emit an output here",
    "start": "1408590",
    "end": "1416300"
  },
  {
    "text": "it starts with the word W right that's the first but now here comes the",
    "start": "1416300",
    "end": "1422480"
  },
  {
    "text": "interesting part what we do is what we take we take this output W and we",
    "start": "1422480",
    "end": "1429950"
  },
  {
    "text": "provide that as the input to the same cell and this triggers something else so",
    "start": "1429950",
    "end": "1435950"
  },
  {
    "text": "this this is going to trigger that hey okay I'm seeing the word W now the results I see is the next it provides",
    "start": "1435950",
    "end": "1443030"
  },
  {
    "text": "you the next word it's almost like a train rolling after this right you get the word X this is the output that",
    "start": "1443030",
    "end": "1449930"
  },
  {
    "text": "emitted X and then you provide this input again and if this rolls over until",
    "start": "1449930",
    "end": "1455000"
  },
  {
    "text": "the LST M gives you the termination word us so what it what did we achieve with",
    "start": "1455000",
    "end": "1462440"
  },
  {
    "text": "this there is a very important difference a key difference with",
    "start": "1462440",
    "end": "1468980"
  },
  {
    "text": "this and a previous way and it and it it left let us achieve a big very big thing that",
    "start": "1468980",
    "end": "1475760"
  },
  {
    "start": "1473000",
    "end": "1619000"
  },
  {
    "text": "is this architecture so if you notice Amazon's translation also uses something like this Amazon's",
    "start": "1475760",
    "end": "1482390"
  },
  {
    "text": "translation service and if you notice Amazon's translation service offers several language pairs right so you have",
    "start": "1482390",
    "end": "1490130"
  },
  {
    "text": "English French German Chinese and so on and if you imagine the this translator",
    "start": "1490130",
    "end": "1496750"
  },
  {
    "text": "providing training this on every single language pair this would soon explode",
    "start": "1496750",
    "end": "1503780"
  },
  {
    "text": "right so there are so many language pairs let's say you could you could have English French in this German is very",
    "start": "1503780",
    "end": "1510169"
  },
  {
    "text": "common but what about French Chinese what about German Chinese but there may not be enough data to be able to train",
    "start": "1510169",
    "end": "1517330"
  },
  {
    "text": "every single pair of languages right now that becomes a bottleneck or a challenge",
    "start": "1517330",
    "end": "1524600"
  },
  {
    "text": "so what they did is they don't even it can translate even though they don't",
    "start": "1524600",
    "end": "1529880"
  },
  {
    "text": "have every data training data for every single pair so what they do is they use",
    "start": "1529880",
    "end": "1535220"
  },
  {
    "text": "the source language and they roll over until the end of sentence right so at",
    "start": "1535220",
    "end": "1541880"
  },
  {
    "text": "this point it has encoding of the words right this is this is already available this part does not change so and then if",
    "start": "1541880",
    "end": "1550220"
  },
  {
    "text": "you want to translate to a different language you just start with the we just",
    "start": "1550220",
    "end": "1558860"
  },
  {
    "text": "change the decoder Park that is you provide with a different decoder and that would start with drawl over the",
    "start": "1558860",
    "end": "1565549"
  },
  {
    "text": "first word of that language and you provide this then if you unroll into that language so in this way they've",
    "start": "1565549",
    "end": "1572419"
  },
  {
    "text": "been able to combine languages for which there are no pairing or bilingual",
    "start": "1572419",
    "end": "1579220"
  },
  {
    "text": "addresses so this has been a huge advantage in providing large-scale",
    "start": "1579220",
    "end": "1584660"
  },
  {
    "text": "language services translation services I'm sorry alright so and and II may have",
    "start": "1584660",
    "end": "1592070"
  },
  {
    "text": "noticed that I mentioned there is a single layer l SCM but it's typically usually two layer LS themes here you're",
    "start": "1592070",
    "end": "1599630"
  },
  {
    "text": "giving an input sentence of ABCD and NF it goes in there and this two layers it",
    "start": "1599630",
    "end": "1606420"
  },
  {
    "text": "absorbs this there's alien state here there so he didn't stay in the second layer and this red piece is the decoder",
    "start": "1606420",
    "end": "1613590"
  },
  {
    "text": "part be color layer of the of the of the translator or nmp right now there is",
    "start": "1613590",
    "end": "1622410"
  },
  {
    "start": "1619000",
    "end": "1946000"
  },
  {
    "text": "there is an interesting piece here it's called a beam search right if you notice",
    "start": "1622410",
    "end": "1630450"
  },
  {
    "text": "the I'm going to go back and explain to you what beam searches as soon as you give the end of sentence symbol into the",
    "start": "1630450",
    "end": "1638040"
  },
  {
    "text": "decoder it emits an output the decoder does not emit really output words so",
    "start": "1638040",
    "end": "1645870"
  },
  {
    "text": "what this does provide is it provides a distribution function probability distribution across all words in the",
    "start": "1645870",
    "end": "1652080"
  },
  {
    "text": "language and the world let's say here X is probably the one that has the maximum",
    "start": "1652080",
    "end": "1658020"
  },
  {
    "text": "problems you are the highest weight associated with that and some of you mark this as X but usually it's never",
    "start": "1658020",
    "end": "1667140"
  },
  {
    "text": "going to be the case that there's only one word that's provided and all words are zero that is like X would be 1 and",
    "start": "1667140",
    "end": "1673919"
  },
  {
    "text": "all others or it would never be the case it should usually be a distribution right X could have some value and then",
    "start": "1673919",
    "end": "1680669"
  },
  {
    "text": "there could be other words also but with a slightly lower value um and what you do here is in this case off of the",
    "start": "1680669",
    "end": "1688290"
  },
  {
    "text": "distribution across all the words we have chosen the word X because probably it's it's a palette it's called a greedy",
    "start": "1688290",
    "end": "1694440"
  },
  {
    "text": "algorithm what we did here is called a greedy algorithm where you always take the word that has the maximum weight and",
    "start": "1694440",
    "end": "1700980"
  },
  {
    "text": "you take that word and you provide that as a second word here to get your second",
    "start": "1700980",
    "end": "1705990"
  },
  {
    "text": "word right so in this part when you always choose in this distribute when",
    "start": "1705990",
    "end": "1713010"
  },
  {
    "text": "you always choose the word with a maximum weight that is called a greedy algorithm but they did realize that this",
    "start": "1713010",
    "end": "1720210"
  },
  {
    "text": "may always not give you the best approach so what if then they started",
    "start": "1720210",
    "end": "1725340"
  },
  {
    "text": "working on something called a beam search a beam search works like this in this case we've got on several paths",
    "start": "1725340",
    "end": "1733400"
  },
  {
    "text": "here the first word that was output is the word a right and then when you want",
    "start": "1733400",
    "end": "1739980"
  },
  {
    "text": "to give a it gives you a distribution across several words you have a train steam black and locomotive right now",
    "start": "1739980",
    "end": "1747660"
  },
  {
    "text": "what you do is you look at this and you're let's say a train and steam have",
    "start": "1747660",
    "end": "1753440"
  },
  {
    "text": "equally high rates and what you do is you choose train and you go down the",
    "start": "1753440",
    "end": "1759570"
  },
  {
    "text": "path and you unroll it and you find the sequence so this is what's called us you're searching through it's called a beam search a beam search is pretty much",
    "start": "1759570",
    "end": "1767040"
  },
  {
    "text": "it's very similar to a breadth-first search in a tree and but I think it's",
    "start": "1767040",
    "end": "1772380"
  },
  {
    "text": "constrained by the width is called a beam width or beam length depending on how they call it so what you would do is",
    "start": "1772380",
    "end": "1778680"
  },
  {
    "text": "you would unroll this by providing this sequence you'd provide first probably we received a and then let's say you've got",
    "start": "1778680",
    "end": "1785490"
  },
  {
    "text": "strain and steam you would choose to first send a train and see where it goes",
    "start": "1785490",
    "end": "1791640"
  },
  {
    "text": "right and you would any what you would do is you would find the cumulative",
    "start": "1791640",
    "end": "1796670"
  },
  {
    "text": "probability of this sequence and then you find end of sentence and then you would go back and then there's you would",
    "start": "1796670",
    "end": "1802890"
  },
  {
    "text": "also do this and then you would find several different sequences from the",
    "start": "1802890",
    "end": "1808170"
  },
  {
    "text": "same encoding right at this point when you got this at this point when you reach the end of the encoding right you",
    "start": "1808170",
    "end": "1814800"
  },
  {
    "text": "have encoding now what you do is it's not just XYZ and a sentence that you got you start with X and you explore all the",
    "start": "1814800",
    "end": "1822000"
  },
  {
    "text": "possible searches and you would find the cumulative a tidge of of several",
    "start": "1822000",
    "end": "1830430"
  },
  {
    "text": "different sequences and at the end of which and you would find which is the",
    "start": "1830430",
    "end": "1836460"
  },
  {
    "text": "sequence that gave you the best score the best Korres in the cumulative weight",
    "start": "1836460",
    "end": "1842130"
  },
  {
    "text": "is that is you multiply one of the ways rules you multiply the weights provided for each of these words and that would",
    "start": "1842130",
    "end": "1848070"
  },
  {
    "text": "be your score and you would then finally choose the sequence of words with the",
    "start": "1848070",
    "end": "1854130"
  },
  {
    "text": "best best accumulative score this has",
    "start": "1854130",
    "end": "1859770"
  },
  {
    "text": "been important because what happens is this what this beam search did was and",
    "start": "1859770",
    "end": "1865260"
  },
  {
    "text": "they're also several ways in being doing deep search but the main concept is that let's say when you're starting early and",
    "start": "1865260",
    "end": "1873060"
  },
  {
    "text": "this this word train let's not take the word train let's say I was team had a",
    "start": "1873060",
    "end": "1880590"
  },
  {
    "text": "really high breakage but then afterwards when you provided the words team ALS TM",
    "start": "1880590",
    "end": "1885690"
  },
  {
    "text": "the rest of the words had really low values it's kind of lost its case obey maybe you can think of ways in which",
    "start": "1885690",
    "end": "1890940"
  },
  {
    "text": "like you start a sentence very strong but then then you realize this sentence",
    "start": "1890940",
    "end": "1896280"
  },
  {
    "text": "may not be a grammatically accurate and so you kind of trail off it's a very",
    "start": "1896280",
    "end": "1901500"
  },
  {
    "text": "similar concept here that is it starts strong and so it kind of plays off so I",
    "start": "1901500",
    "end": "1906900"
  },
  {
    "text": "bet the Train the word train but I've had a lower score initially but as you change these words together eventually",
    "start": "1906900",
    "end": "1914370"
  },
  {
    "text": "this cumulating sequence of words could have had a cumulative better score than the other sequence so that's what that's",
    "start": "1914370",
    "end": "1921270"
  },
  {
    "text": "the way in which they found that they were able to explore all possible sequences of words that was able that",
    "start": "1921270",
    "end": "1929700"
  },
  {
    "text": "that could be a valid translations right so that's that's that is an important",
    "start": "1929700",
    "end": "1936480"
  },
  {
    "text": "part of this and the reason I'm giving you all this is all these would be an important hyper parameter that you would",
    "start": "1936480",
    "end": "1942120"
  },
  {
    "text": "tune in the sequence of sequence am algorithm in Amazon Rossum algorithms okay so but even then we saw that this",
    "start": "1942120",
    "end": "1952530"
  },
  {
    "text": "was this was not sufficient what they found this in this mechanism you would",
    "start": "1952530",
    "end": "1957840"
  },
  {
    "text": "notice a certain problem here that is a b c and d and end of sentence after",
    "start": "1957840",
    "end": "1963600"
  },
  {
    "text": "which you start to decode in a different language there was a problem with this",
    "start": "1963600",
    "end": "1969480"
  },
  {
    "text": "that is when it comes up with the word x and starts outputting it does not know",
    "start": "1969480",
    "end": "1975420"
  },
  {
    "text": "which of these words it needs to focus on looks like right now it's taking the",
    "start": "1975420",
    "end": "1981990"
  },
  {
    "text": "entire sentence and it's focusing on the entire sentence and starts unraveling this is usually not the very humans",
    "start": "1981990",
    "end": "1990120"
  },
  {
    "text": "translate as well that is every word ha usually as in translation or a word",
    "start": "1990120",
    "end": "1995160"
  },
  {
    "text": "could have a whether you translate could have relevance only for a few other",
    "start": "1995160",
    "end": "2000770"
  },
  {
    "text": "words for example let's take this for example a train at steam engine",
    "start": "2000770",
    "end": "2007549"
  },
  {
    "text": "train traveling down train tracks right the oh so for example the word traveling",
    "start": "2007549",
    "end": "2015580"
  },
  {
    "text": "is related to only to the train and to two tracks right or let's say let's take",
    "start": "2015580",
    "end": "2024020"
  },
  {
    "text": "the eggs the fifth example a steam engine train traveling through a lush green countryside and this is not a good",
    "start": "2024020",
    "end": "2030710"
  },
  {
    "text": "example but let's say you have the example the tree this the steam engine was travelling fast and it was going and",
    "start": "2030710",
    "end": "2038450"
  },
  {
    "text": "it was going through a lush green countryside the word it here corresponds",
    "start": "2038450",
    "end": "2045440"
  },
  {
    "text": "to the steam engine train right so the word it is only related to that three",
    "start": "2045440",
    "end": "2051230"
  },
  {
    "text": "words and not other words so this is what is called attention that is like when you are translating a particular",
    "start": "2051230",
    "end": "2057080"
  },
  {
    "text": "word or a sequence which of the set of words subset of the words should the",
    "start": "2057080",
    "end": "2064580"
  },
  {
    "text": "neural network focus on to translate it is a big question here when they did",
    "start": "2064580",
    "end": "2070398"
  },
  {
    "start": "2066000",
    "end": "2213000"
  },
  {
    "text": "that they found that this this improved this course very very much for example",
    "start": "2070399",
    "end": "2076878"
  },
  {
    "text": "this is what is called a blue score for for translations we look at what blue",
    "start": "2076879",
    "end": "2082099"
  },
  {
    "text": "scores are you need to understand this to be able to fine tune this this is a",
    "start": "2082099",
    "end": "2087230"
  },
  {
    "text": "very typical graph of a blue score for for 4ls teams without attention if you",
    "start": "2087230",
    "end": "2095990"
  },
  {
    "text": "look at this when you plot the blue scores of translations Blue Square represents the score are how good a",
    "start": "2095990",
    "end": "2102050"
  },
  {
    "text": "translation is of a sentence it goes up initially as the sentence length increases this is because it's",
    "start": "2102050",
    "end": "2110030"
  },
  {
    "text": "kind of hard to translate very short sentences that's less than on a five",
    "start": "2110030",
    "end": "2115280"
  },
  {
    "text": "words so the blue score is kind of low this is harder to solve but but the blue",
    "start": "2115280",
    "end": "2120320"
  },
  {
    "text": "score increases as the number of words increase in essence for example it Peaks around 15 words but then the blue store",
    "start": "2120320",
    "end": "2127099"
  },
  {
    "text": "kind of drops off trails off and it's pretty low when it comes to like 60 words sentences or 70 word sentences the",
    "start": "2127099",
    "end": "2134030"
  },
  {
    "text": "reason is that as the sentences grow in this day as the sentences grow let's say this is",
    "start": "2134030",
    "end": "2139070"
  },
  {
    "text": "a very long sequence after which when you first output the first word it means",
    "start": "2139070",
    "end": "2144710"
  },
  {
    "text": "to like take into account all the words that were said and kind of loses the context and that's where attention",
    "start": "2144710",
    "end": "2150380"
  },
  {
    "text": "really comes in that is which once you have attention that is for example like this I think this is German I cannot",
    "start": "2150380",
    "end": "2158540"
  },
  {
    "text": "read German but the example is kind of its intuitive right you provide this",
    "start": "2158540",
    "end": "2163790"
  },
  {
    "text": "sentence and when you outputting the words when you're getting the outputs as",
    "start": "2163790",
    "end": "2168860"
  },
  {
    "text": "you can see these two words are paying attention to economic rather than other",
    "start": "2168860",
    "end": "2174260"
  },
  {
    "text": "words so it gives you a mapping of outputs link puts on what needs to be focused on so that is what is called",
    "start": "2174260",
    "end": "2181280"
  },
  {
    "text": "attention here these darker lines represent stronger attention weights and",
    "start": "2181280",
    "end": "2186380"
  },
  {
    "text": "lighter lines represent lower attention",
    "start": "2186380",
    "end": "2191660"
  },
  {
    "text": "rates you could be paying attention to more than one words that's perfectly fine and as you can see once you give",
    "start": "2191660",
    "end": "2197540"
  },
  {
    "text": "attention you can see that the blue scores actually goes up and maintains",
    "start": "2197540",
    "end": "2203300"
  },
  {
    "text": "its if you get a pretty high blue score even for sentence lenses lengths of up",
    "start": "2203300",
    "end": "2208310"
  },
  {
    "text": "to 60 words right so that has been a huge improvement in in nmp our neural",
    "start": "2208310",
    "end": "2215600"
  },
  {
    "start": "2213000",
    "end": "2316000"
  },
  {
    "text": "machine translation this is an interesting graph as to say which words are getting attention and you can see",
    "start": "2215600",
    "end": "2223520"
  },
  {
    "text": "that this is as it's providing the output you can see that it's paying",
    "start": "2223520",
    "end": "2228530"
  },
  {
    "text": "attention to one word the lighter shade means that's what's paying attention",
    "start": "2228530",
    "end": "2233930"
  },
  {
    "text": "darker shade means it's not paying attention so as you can see the card it's related to agreement and it's not",
    "start": "2233930",
    "end": "2241580"
  },
  {
    "text": "this word accord is not paying attention to any of the other words here in the sentence right and you can see this this",
    "start": "2241580",
    "end": "2248450"
  },
  {
    "text": "word up it's actually evident in these three words right zone economic European",
    "start": "2248450",
    "end": "2253550"
  },
  {
    "text": "it's paying attention to these three words in the reverse order because I",
    "start": "2253550",
    "end": "2259790"
  },
  {
    "text": "think this is French it needs to pay attention and disorder so now this knows that what is the sequence or which of",
    "start": "2259790",
    "end": "2266270"
  },
  {
    "text": "the words it needs to pay attention to attention is now really big and there have been newer",
    "start": "2266270",
    "end": "2273080"
  },
  {
    "text": "architectures of that claim that attention is all you need and you do not even need LS TMS that's called a",
    "start": "2273080",
    "end": "2280430"
  },
  {
    "text": "transformer model a transformer architecture that is a newer version we",
    "start": "2280430",
    "end": "2286550"
  },
  {
    "text": "do not follow the the sequence the sequence algorithm in Amazon is not the transformer model it does have attention",
    "start": "2286550",
    "end": "2294410"
  },
  {
    "text": "mechanism but you also have a lsdm sequence going on okay",
    "start": "2294410",
    "end": "2299510"
  },
  {
    "text": "this is also important understand I'm not doing it enough justice in the explaining attention five minutes but",
    "start": "2299510",
    "end": "2306410"
  },
  {
    "text": "I'm going to continue and refer you to this paper which first described attention and there have been much more",
    "start": "2306410",
    "end": "2312160"
  },
  {
    "text": "advancements in attention in this pace I would highly encourage you to read",
    "start": "2312160",
    "end": "2317480"
  },
  {
    "start": "2316000",
    "end": "2493000"
  },
  {
    "text": "through that alright so now you we need to look at scoring right this is also very important the Commons accurate",
    "start": "2317480",
    "end": "2325010"
  },
  {
    "text": "score that we use usually in machine learning is the accuracy score but in accuracy score has very little meaning",
    "start": "2325010",
    "end": "2332120"
  },
  {
    "text": "in NLP right for example let's say you're given your your network provided this sequence the cat caught the mouse",
    "start": "2332120",
    "end": "2338810"
  },
  {
    "text": "with the dot end of sentence and usually in translations is not like a right or",
    "start": "2338810",
    "end": "2345920"
  },
  {
    "text": "wrong there could be several ways in which a single sentence could be translated like for example you can see",
    "start": "2345920",
    "end": "2350960"
  },
  {
    "text": "on the right side but how are you going to score this right this does not match the sequence of the versus translate",
    "start": "2350960",
    "end": "2356930"
  },
  {
    "text": "does not match exactly with any of the three but as you can see if this was what is generated as you can read it is",
    "start": "2356930",
    "end": "2363440"
  },
  {
    "text": "a good match right but how would do the machine score this so that's when we came up with something called a",
    "start": "2363440",
    "end": "2369350"
  },
  {
    "text": "bilingual evaluation understudy this is a paper that was published in 2002 as to",
    "start": "2369350",
    "end": "2374570"
  },
  {
    "text": "how to make a score a translation one on the left is what is called a candidate a",
    "start": "2374570",
    "end": "2381260"
  },
  {
    "text": "string on the right is what you call reference strings it usually will have multi more than one you could have one",
    "start": "2381260",
    "end": "2387230"
  },
  {
    "text": "or you could have more than one and what if what it tries to do is it creates these engrams 3grams and then tries to",
    "start": "2387230",
    "end": "2395420"
  },
  {
    "text": "match with the reference strings and then there is a complete match it gives",
    "start": "2395420",
    "end": "2402770"
  },
  {
    "text": "you a score of one when there is a complete mismatch it gives a score of zero there are lots of",
    "start": "2402770",
    "end": "2410480"
  },
  {
    "text": "cases where that that is taken into account and it's this is considered the",
    "start": "2410480",
    "end": "2417380"
  },
  {
    "text": "gold standard for storing in nmt or even in international language processing whenever you are generating a string",
    "start": "2417380",
    "end": "2423050"
  },
  {
    "text": "right this is a very quick and inexpensive the score I'm not going to be giving more details about this",
    "start": "2423050",
    "end": "2431210"
  },
  {
    "text": "because that could take like a whole day to explain all the different ways there's one gram to gram three German",
    "start": "2431210",
    "end": "2437120"
  },
  {
    "text": "for gram and there's also cumulative and there's a sentence level blue score and so on but typically in research papers",
    "start": "2437120",
    "end": "2443990"
  },
  {
    "text": "they usually use 4 gram of new scores ok it's quick and inexpensive the score",
    "start": "2443990",
    "end": "2450890"
  },
  {
    "text": "it's easy to understand it's language independent because this is applicable to any language it does not say it's",
    "start": "2450890",
    "end": "2457490"
  },
  {
    "text": "based on languages although this may be little tricky for for languages which do",
    "start": "2457490",
    "end": "2462950"
  },
  {
    "text": "not define words for example Chinese could be different it's also very",
    "start": "2462950",
    "end": "2468710"
  },
  {
    "text": "intuitive as to how we would compare this which it you have to understand that it still does not take the meaning",
    "start": "2468710",
    "end": "2475760"
  },
  {
    "text": "of the of the sentence it still only tries to do kind of a a partial string match right all right it also has white",
    "start": "2475760",
    "end": "2483350"
  },
  {
    "text": "adoption you would see blue scores everywhere and a blue score right now of the most the best translators are on I",
    "start": "2483350",
    "end": "2491570"
  },
  {
    "text": "think it's 36 or 37 that's where it's at right all right so we understood we",
    "start": "2491570",
    "end": "2497240"
  },
  {
    "start": "2493000",
    "end": "2509000"
  },
  {
    "text": "looked at the architecture of a sequence of sequence algorithm and and we looked",
    "start": "2497240",
    "end": "2503000"
  },
  {
    "text": "at a beam search at the end we also looked at attention mechanisms if you look if you try to do this yourself it's",
    "start": "2503000",
    "end": "2510470"
  },
  {
    "start": "2509000",
    "end": "2555000"
  },
  {
    "text": "going to take you a long time so we publish something called mxs Sakai Sokka is infrastructure that probably do all",
    "start": "2510470",
    "end": "2517550"
  },
  {
    "text": "of this the variations of all the things we talked about are just hyper parameters that you can set we release",
    "start": "2517550",
    "end": "2523670"
  },
  {
    "text": "this early last year and you can look at Sakai this is based on MX net and there",
    "start": "2523670",
    "end": "2531530"
  },
  {
    "text": "are no newer ways of doing this it also provides what you can see that this gives a recurrent",
    "start": "2531530",
    "end": "2537870"
  },
  {
    "text": "is also potentional and convolutional way of doing things there's me a lot of work done in Mt",
    "start": "2537870",
    "end": "2544020"
  },
  {
    "text": "the reason I mentioned Sakai is Amazon sequels to sequences based on Sakai but",
    "start": "2544020",
    "end": "2549570"
  },
  {
    "text": "they have made some changes to make it align with the other Amazon in both sage",
    "start": "2549570",
    "end": "2555000"
  },
  {
    "start": "2555000",
    "end": "2903000"
  },
  {
    "text": "maitreya algorithms all right so I would encourage you to look at the Sakai but",
    "start": "2555000",
    "end": "2562260"
  },
  {
    "text": "let's look at a quick demo I've started a notebook on on on sage maker and there is a",
    "start": "2562260",
    "end": "2571680"
  },
  {
    "text": "sample notebook here it's from English to German you guys can",
    "start": "2571680",
    "end": "2576960"
  },
  {
    "text": "try this out yourself the first step is you need to provide a bucket as usual",
    "start": "2576960",
    "end": "2582120"
  },
  {
    "text": "and it downloads the data set it's a fairly large data set it takes about a few minutes at least to download this",
    "start": "2582120",
    "end": "2589130"
  },
  {
    "text": "and then it tries to take a small subset of the data set this is to help you run",
    "start": "2589130",
    "end": "2598620"
  },
  {
    "text": "this training faster I tried this but the small data set does not give you good results at all so this is more to",
    "start": "2598620",
    "end": "2606510"
  },
  {
    "text": "see the notebook really runs and go through the motions but I did change it to the full full data set harpus",
    "start": "2606510",
    "end": "2614790"
  },
  {
    "text": "we also provide you with this example gives you a Python file which which extracts the vocabulary and and here we",
    "start": "2614790",
    "end": "2624660"
  },
  {
    "text": "are we're topping it at 50,000 pipes and then you provide the training the the",
    "start": "2624660",
    "end": "2633810"
  },
  {
    "text": "hyper parameters and the main thing that I would like to show this I'm using P",
    "start": "2633810",
    "end": "2639300"
  },
  {
    "text": "316 extra-large that is the largest type and the fastest instance type with with",
    "start": "2639300",
    "end": "2646890"
  },
  {
    "text": "the latest a P 3 is the latest a family of GPU instances and it has I think",
    "start": "2646890",
    "end": "2653700"
  },
  {
    "text": "eight GPUs and it can do it's it's 14 times faster than P 2 and I I provided",
    "start": "2653700",
    "end": "2662010"
  },
  {
    "text": "that and you can see the hyper parameters that are provided right you need to provide a maximum sequence",
    "start": "2662010",
    "end": "2668040"
  },
  {
    "text": "length right now I'm providing 60 the maximum sequence target that's also 60 the optimized metric this",
    "start": "2668040",
    "end": "2674220"
  },
  {
    "text": "blue it does also provide accuracy as a metric I would highly recommend not using that but that really depends on",
    "start": "2674220",
    "end": "2680550"
  },
  {
    "text": "whether you're using translation this for translation or not so this is a general sequence the sequence algorithm",
    "start": "2680550",
    "end": "2686270"
  },
  {
    "text": "it is not limited to translations right but this this page this notebook works",
    "start": "2686270",
    "end": "2693270"
  },
  {
    "text": "on the translation you also have an iron in a number of",
    "start": "2693270",
    "end": "2698490"
  },
  {
    "text": "hidden a number of layers in the encoder one and two and then the number of batches is 2100 I did not provide the",
    "start": "2698490",
    "end": "2708660"
  },
  {
    "text": "other Viper parameters and I ran this it took I was quite surprised that it took",
    "start": "2708660",
    "end": "2716460"
  },
  {
    "text": "I ran this yesterday as you can see this took just over 40 minutes to complete",
    "start": "2716460",
    "end": "2722420"
  },
  {
    "text": "that was the latest run that is actually fairly phenomenal I think it's the power",
    "start": "2722420",
    "end": "2727950"
  },
  {
    "text": "of the p3 16x our large instance type so it takes less than one hour that is I",
    "start": "2727950",
    "end": "2734370"
  },
  {
    "text": "was I was very happy with that sequence and and and it this actually makes it",
    "start": "2734370",
    "end": "2740820"
  },
  {
    "text": "really simple I would actually call it a deceptively simple and because all of",
    "start": "2740820",
    "end": "2747060"
  },
  {
    "text": "that architecture the encoder decoder architecture attention and beam search",
    "start": "2747060",
    "end": "2752820"
  },
  {
    "text": "is all just define these hyper parameters and once you're done with this you should be the training job",
    "start": "2752820",
    "end": "2759890"
  },
  {
    "text": "takes five minutes and we're done right and I also loaded this deploy this model",
    "start": "2759890",
    "end": "2768620"
  },
  {
    "text": "and I'm going to try out a different sentence here and see what we get",
    "start": "2768620",
    "end": "2777740"
  },
  {
    "text": "this webinar webinar may not be word this class talks about machine",
    "start": "2778630",
    "end": "2787730"
  },
  {
    "text": "translation all right let's see what is",
    "start": "2787730",
    "end": "2794390"
  },
  {
    "text": "it okay we get u NK means it's unknown word I don't think that worked very well",
    "start": "2794390",
    "end": "2802990"
  },
  {
    "text": "this works great till now",
    "start": "2802990",
    "end": "2812770"
  },
  {
    "text": "okay some and wrong I think my deployment is not",
    "start": "2812770",
    "end": "2817850"
  },
  {
    "text": "working very well right now but this should be deploying about five minutes and you should be good to go this is the",
    "start": "2817850",
    "end": "2826730"
  },
  {
    "text": "attention I think we have examples here you are so good what stress it to sie sind I can't read",
    "start": "2826730",
    "end": "2835250"
  },
  {
    "text": "German so I apologize for that can drive a car is this and I want to watch a",
    "start": "2835250",
    "end": "2842840"
  },
  {
    "text": "movie is translated as this UNK means it's unknown word there is a flag that",
    "start": "2842840",
    "end": "2849020"
  },
  {
    "text": "sets that you can you can replace this unknown word up by the original word like movie if movie is the word that it",
    "start": "2849020",
    "end": "2855110"
  },
  {
    "text": "did not know I do not have in the Indy Indy vocabulary German vocabulary you",
    "start": "2855110",
    "end": "2862610"
  },
  {
    "text": "can you can make it use the original word in there so there is a flag for that as well alright so this is the",
    "start": "2862610",
    "end": "2869810"
  },
  {
    "text": "attention matrix for this for example for the sentence you are so good what's translated as this I think this is in",
    "start": "2869810",
    "end": "2877190"
  },
  {
    "text": "the worse you is this it was being attention to this this word sin was",
    "start": "2877190",
    "end": "2883700"
  },
  {
    "text": "paying attention to our and these three words are paying attention to good okay",
    "start": "2883700",
    "end": "2890030"
  },
  {
    "text": "these two words sorry target is the is the x-axis alright that's pretty much it",
    "start": "2890030",
    "end": "2897920"
  },
  {
    "text": "the rest is all closing the notebook I do want to bring your attention to the",
    "start": "2897920",
    "end": "2904630"
  },
  {
    "start": "2903000",
    "end": "3023000"
  },
  {
    "text": "second find this this page this is the main documentation",
    "start": "2904630",
    "end": "2911390"
  },
  {
    "text": "page for our sequence to sequence and it talks about how it works does not give",
    "start": "2911390",
    "end": "2917210"
  },
  {
    "text": "you real details of how it works but does provide you links the various papers it's based upon I don't want to",
    "start": "2917210",
    "end": "2924290"
  },
  {
    "text": "show a little bit about all the high parameters I think we saw a subset of these you have this atom accident max",
    "start": "2924290",
    "end": "2930230"
  },
  {
    "text": "length target encoder/decoder type number of layers RN and cell type and",
    "start": "2930230",
    "end": "2936010"
  },
  {
    "text": "you have seen n cell types you have our attention type there are a couple of different types of attentions for you to",
    "start": "2936010",
    "end": "2944240"
  },
  {
    "text": "be able to play with you need to like do a little bit more search then you have the blue score blue sample size and the",
    "start": "2944240",
    "end": "2954410"
  },
  {
    "text": "last is you have quite a bit of this all this is pretty much inherited from the",
    "start": "2954410",
    "end": "2962829"
  },
  {
    "text": "Sakai framework you can you also finally have the beam size so for it so I think",
    "start": "2962829",
    "end": "2969230"
  },
  {
    "text": "I have given you the most important parts of these how the sequence to",
    "start": "2969230",
    "end": "2975020"
  },
  {
    "text": "sequence model works and dig a little",
    "start": "2975020",
    "end": "2980359"
  },
  {
    "text": "deeper try this notebook out and you would be able to achieve your objective",
    "start": "2980359",
    "end": "2986420"
  },
  {
    "text": "all right so I'm going to switch over to questions and to see",
    "start": "2986420",
    "end": "2992200"
  },
  {
    "text": "where we are right now all right Chris",
    "start": "2993980",
    "end": "3000860"
  },
  {
    "text": "do we have any questions my apologies has I've mute no questions",
    "start": "3000860",
    "end": "3007910"
  },
  {
    "text": "yet Pratap okay cool awesome",
    "start": "3007910",
    "end": "3014359"
  },
  {
    "text": "so the main reference paper I would point to from the documentation is here",
    "start": "3014359",
    "end": "3021490"
  },
  {
    "text": "that is",
    "start": "3021490",
    "end": "3024640"
  },
  {
    "start": "3023000",
    "end": "3173000"
  },
  {
    "text": "so as you can see colas blog that I mentioned is also mentioned here and",
    "start": "3027299",
    "end": "3034099"
  },
  {
    "text": "attention paper is here but the main looking for thee",
    "start": "3034099",
    "end": "3041630"
  },
  {
    "text": "I think this model was first infused by such camera tell this is the main paper that talks about the in coatings but the",
    "start": "3048960",
    "end": "3056490"
  },
  {
    "text": "attention mechanism is what really kicked in this is the paper that seminal",
    "start": "3056490",
    "end": "3062400"
  },
  {
    "text": "paper that dramatically improved the scores blue scores as you can see as I",
    "start": "3062400",
    "end": "3070619"
  },
  {
    "text": "was talking before I can zoom this thing",
    "start": "3070619",
    "end": "3076310"
  },
  {
    "text": "at the end of the at the end of the the",
    "start": "3076310",
    "end": "3081990"
  },
  {
    "text": "input sequence you would get embedding or representation of the entire sentence",
    "start": "3081990",
    "end": "3087390"
  },
  {
    "text": "and that is what it's kind of shown here is in a two-dimensional way even though it's most really high dimensional space",
    "start": "3087390",
    "end": "3093650"
  },
  {
    "text": "as you can see kinds of tries to collocate sentences that are similar and from",
    "start": "3093650",
    "end": "3101490"
  },
  {
    "text": "which you would go to extract a different sequence of words right I do I",
    "start": "3101490",
    "end": "3107460"
  },
  {
    "text": "don't have mentioned that this is cutting edge the paved this main product",
    "start": "3107460",
    "end": "3113310"
  },
  {
    "text": "or the algorithms base of a 2014 paper and attention is from a 2015 there is",
    "start": "3113310",
    "end": "3118980"
  },
  {
    "text": "also a 16 paper so there would be a little bit of literature reading that as",
    "start": "3118980",
    "end": "3125910"
  },
  {
    "text": "we done to effectively harness the power of this but that is that is only for",
    "start": "3125910",
    "end": "3131369"
  },
  {
    "text": "fine-tuning your hyper parameters but otherwise they have made a huge job",
    "start": "3131369",
    "end": "3138330"
  },
  {
    "text": "great job of creating the Sakai in these sequence elegans which which brings this",
    "start": "3138330",
    "end": "3143510"
  },
  {
    "text": "enormous framework and the flexible framework to be used by everybody so you",
    "start": "3143510",
    "end": "3149820"
  },
  {
    "text": "can get started in about ten minutes and you have the latest cutting edge",
    "start": "3149820",
    "end": "3155839"
  },
  {
    "text": "algorithm running in your Amazon account",
    "start": "3155839",
    "end": "3160970"
  },
  {
    "text": "fingers up we do have a couple questions rolling in here the first one will this notebook with code example be made",
    "start": "3160970",
    "end": "3167339"
  },
  {
    "text": "available after the webinar yes thanks for the question this code",
    "start": "3167339",
    "end": "3173010"
  },
  {
    "start": "3173000",
    "end": "3263000"
  },
  {
    "text": "example is already available I'm going to google for it I'm going to google for sage maker examples right",
    "start": "3173010",
    "end": "3182769"
  },
  {
    "text": "this is the github page which showcases 100-plus notebooks that we have and I",
    "start": "3182769",
    "end": "3190599"
  },
  {
    "text": "hope this opens now and under this you would find this in introduction to",
    "start": "3190599",
    "end": "3197410"
  },
  {
    "text": "Amazon's algorithms and if you search for sequence in sequence here this is",
    "start": "3197410",
    "end": "3205269"
  },
  {
    "text": "the notebook we just tried if you are using Amazon site maker the entire GTA",
    "start": "3205269",
    "end": "3210940"
  },
  {
    "text": "requester is already preloaded into into the notebook instance for example if I",
    "start": "3210940",
    "end": "3217539"
  },
  {
    "text": "look at this notebook this is my notebook you usually have a",
    "start": "3217539",
    "end": "3223239"
  },
  {
    "text": "tab the fourth tab called safe maker examples and I drop down here",
    "start": "3223239",
    "end": "3232700"
  },
  {
    "text": "you it's exactly the same as the github repo let me close this one so in under an",
    "start": "3232700",
    "end": "3239130"
  },
  {
    "text": "introduction to Amazon's algorithms this is the notebook I just tried you can",
    "start": "3239130",
    "end": "3245250"
  },
  {
    "text": "click on preview which will just view this notebook or you can click on use which would make a copy of your in your",
    "start": "3245250",
    "end": "3251460"
  },
  {
    "text": "workspace and you can start to run your notebook thanks for that question okay so we got",
    "start": "3251460",
    "end": "3260890"
  },
  {
    "text": "another question here why should we use our own language translation model instead of Amazon translates and if",
    "start": "3260890",
    "end": "3267550"
  },
  {
    "start": "3263000",
    "end": "3433000"
  },
  {
    "text": "you'd like what's up I think I'll take a swipe at that first if you so in classic",
    "start": "3267550",
    "end": "3273040"
  },
  {
    "text": "AWS fashion we provide building blocks so we have obviously our translating transcribed services which give you text",
    "start": "3273040",
    "end": "3279310"
  },
  {
    "text": "speech and language translation services but seek the seek is a little bit more than language - like English translation",
    "start": "3279310",
    "end": "3286330"
  },
  {
    "text": "you could do long sentence - shorter sentence its essence summaries you could run into an instance where we have a",
    "start": "3286330",
    "end": "3292300"
  },
  {
    "text": "partner who is actually taking the language of the stock room I'm sorry that yeah the Wall Street Stock Exchange",
    "start": "3292300",
    "end": "3298480"
  },
  {
    "text": "floor which is I guess from what I understand a pretty bizarre shorthand of language and they've actually used",
    "start": "3298480",
    "end": "3303970"
  },
  {
    "text": "translation rhythms to translate that into layman's terms so anytime you need",
    "start": "3303970",
    "end": "3309280"
  },
  {
    "text": "to map one entity to another entity that could be speech to text it could be language to language there are a lot of",
    "start": "3309280",
    "end": "3315460"
  },
  {
    "text": "opportunities there to use seek to seek rather than simple language translations so like I said classic a tubules fashion",
    "start": "3315460",
    "end": "3321880"
  },
  {
    "text": "we provide building blocks and occasion we're gonna provide services that do something similar to that building block but that building block is there for you",
    "start": "3321880",
    "end": "3328360"
  },
  {
    "text": "to customize in whatever fashion that you might need all right if you don't",
    "start": "3328360",
    "end": "3336850"
  },
  {
    "text": "want if you want to ask them to that no otherwise we could we have a question I think you answered it I could add",
    "start": "3336850",
    "end": "3343090"
  },
  {
    "text": "something to that they for example I think you mentioned some razors from long sentence sharp sentences they're",
    "start": "3343090",
    "end": "3349810"
  },
  {
    "text": "also one more very popular use cases where the Amazon Translate is a gender prosperous general general-purpose",
    "start": "3349810",
    "end": "3356590"
  },
  {
    "text": "translator which translates between languages and it may or may not be aware",
    "start": "3356590",
    "end": "3362380"
  },
  {
    "text": "of domain-specific words for example if you are in the healthcare industry there may be names of drugs or medical",
    "start": "3362380",
    "end": "3371260"
  },
  {
    "text": "terms that it may not be able be aware of or affects if you are operating the",
    "start": "3371260",
    "end": "3376330"
  },
  {
    "text": "legal industry we'd have a different vocabulary the way in which the sentence of sentences are form and the legal",
    "start": "3376330",
    "end": "3384070"
  },
  {
    "text": "legalese is it could be very different from the general conversation this this could be used to fine-tune your",
    "start": "3384070",
    "end": "3392320"
  },
  {
    "text": "translation for those those purposes for and and but the main challenge there is",
    "start": "3392320",
    "end": "3399820"
  },
  {
    "text": "you like to come up with your own data set which provides you that translation or that sequence to the sequence so",
    "start": "3399820",
    "end": "3407320"
  },
  {
    "text": "that's that's where it comes in this this is a this is like I said we provide",
    "start": "3407320",
    "end": "3413500"
  },
  {
    "text": "building blocks and and this is a great way to experiment with the latest technology",
    "start": "3413500",
    "end": "3420360"
  },
  {
    "text": "thanks for table I think we get time for one more question here and the question is do you have to start",
    "start": "3420360",
    "end": "3426280"
  },
  {
    "text": "training a machine translation model from scratch or are there pre-trained models that you can base your model off",
    "start": "3426280",
    "end": "3431710"
  },
  {
    "text": "of Oh excellent question even this notebook if you look at this",
    "start": "3431710",
    "end": "3438850"
  },
  {
    "start": "3433000",
    "end": "3599000"
  },
  {
    "text": "notebook we do provide a pre trained model right here it's hosted in s3 as",
    "start": "3438850",
    "end": "3444880"
  },
  {
    "text": "you can see here it shows you how to download that and and load that model as",
    "start": "3444880",
    "end": "3450340"
  },
  {
    "text": "well okay so this is we also have a model Zoo on",
    "start": "3450340",
    "end": "3459480"
  },
  {
    "text": "MX net which also has other models that have been three built all right great",
    "start": "3459480",
    "end": "3466320"
  },
  {
    "text": "thanks for Tom and it looks like we have time for just one more than the question",
    "start": "3466320",
    "end": "3471600"
  },
  {
    "text": "is can we use any of the deep learning framework such as such as pi torch um",
    "start": "3471600",
    "end": "3479360"
  },
  {
    "text": "this okay I'm gonna I'm gonna take a stab at this I'm not a Pytor tech expert but what we",
    "start": "3479390",
    "end": "3486840"
  },
  {
    "text": "saw here used Python in this example only to invoke sage maker that is for",
    "start": "3486840",
    "end": "3494250"
  },
  {
    "text": "example you're sitting here creating parameters this is JSON and and then",
    "start": "3494250",
    "end": "3499890"
  },
  {
    "text": "you're making a bottle call to initiate to start the training session you're not really you could use this on Java as",
    "start": "3499890",
    "end": "3506790"
  },
  {
    "text": "well to do the same thing I use the Java library but I'm not sure if pipe arch",
    "start": "3506790",
    "end": "3512490"
  },
  {
    "text": "provides any value because you're not doing the deep learning on the notebook instance you're only invoking the sage",
    "start": "3512490",
    "end": "3519420"
  },
  {
    "text": "maker through the API so we want to add to this Chris because I'm not familiar with",
    "start": "3519420",
    "end": "3524670"
  },
  {
    "text": "Python yes you're all add a little bit we got a few seconds left so so we welcome all all deep learning frameworks",
    "start": "3524670",
    "end": "3531810"
  },
  {
    "text": "in languages AWS our notebooks use MX net at their base because of X net is used internally here at AWS not because",
    "start": "3531810",
    "end": "3538260"
  },
  {
    "text": "we favor that over any others for partners or customers use and the CT",
    "start": "3538260",
    "end": "3543480"
  },
  {
    "text": "seek is based on Sakai which is also an MX net project so if you were to recreate this and pi2 which nothing is",
    "start": "3543480",
    "end": "3548910"
  },
  {
    "text": "stopping you sage maker supports pi torch and training and deployment endpoints you would however have to",
    "start": "3548910",
    "end": "3554310"
  },
  {
    "text": "create your own basically your own RNN in pi torch and then feed that your own",
    "start": "3554310",
    "end": "3559590"
  },
  {
    "text": "data set because the MX net prepared data set this and the sage maker pre-canned image if you will would not",
    "start": "3559590",
    "end": "3567480"
  },
  {
    "text": "be able to support that so hopefully that makes sense the the built in sage maker algorithms that we call them call",
    "start": "3567480",
    "end": "3572670"
  },
  {
    "text": "them the built-ins those all are based on MX net algorithms thanks very kind of",
    "start": "3572670",
    "end": "3582360"
  },
  {
    "text": "prototype yeah thanks guys that was great and thanks",
    "start": "3582360",
    "end": "3588480"
  },
  {
    "text": "everybody who attended for those great questions we've got a couple more that we didn't get to so we'd like to try to summarize those and send them out in an",
    "start": "3588480",
    "end": "3594690"
  },
  {
    "text": "email you will get an email that's automated coming from GoToWebinar today in about six hours it will contain the",
    "start": "3594690",
    "end": "3601289"
  },
  {
    "text": "recording of this everybody who registered for this webinar will get that recording as well so if you have",
    "start": "3601289",
    "end": "3607529"
  },
  {
    "text": "colleagues that weren't able to join us today but they did register they will get that also in that email will be a",
    "start": "3607529",
    "end": "3612869"
  },
  {
    "text": "link to the next webinar which is two weeks from today so look forward to seeing many of you in two more weeks and",
    "start": "3612869",
    "end": "3620010"
  },
  {
    "text": "if you have any other questions the other thing in that email will be Chris and port ops emails if you'd like to",
    "start": "3620010",
    "end": "3625260"
  },
  {
    "text": "send them any messages directly and address anything that you had questions about today so that's it thanks so much",
    "start": "3625260",
    "end": "3632400"
  },
  {
    "text": "hope you guys all have a fantastic day",
    "start": "3632400",
    "end": "3636140"
  }
]
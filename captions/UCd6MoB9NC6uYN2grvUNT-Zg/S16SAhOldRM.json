[
  {
    "start": "0",
    "end": "168000"
  },
  {
    "text": "and now we're gonna go into another segment talking about deep dive on accelerated computing instances on ec2",
    "start": "30",
    "end": "6930"
  },
  {
    "text": "and so just as a quick recap from our previous session the overview of the ec2",
    "start": "6930",
    "end": "13040"
  },
  {
    "text": "instance types we have a variety of different options for you to meet your needs in terms of general purpose",
    "start": "13040",
    "end": "19109"
  },
  {
    "text": "compute such as our m5 our mainstream instance five compute optimized like our",
    "start": "19109",
    "end": "26480"
  },
  {
    "text": "you know see instance types like C five and C 4 and then storage optimized",
    "start": "26480",
    "end": "33390"
  },
  {
    "text": "instances these are ideal for things like analytics and for storing large",
    "start": "33390",
    "end": "40980"
  },
  {
    "text": "amounts of data and processing data and then memory optimized for in-memory databases like x1 e and r for these are",
    "start": "40980",
    "end": "48930"
  },
  {
    "text": "great for things like si P Hana workloads and others and then we also",
    "start": "48930",
    "end": "54090"
  },
  {
    "text": "have mentioned in brief but we'll go into more depth in this session about our accelerated instance types which are",
    "start": "54090",
    "end": "59760"
  },
  {
    "text": "things like our p3 instance for machine learning our f1 FPGA and then g3 which",
    "start": "59760",
    "end": "66090"
  },
  {
    "text": "is a graphics instance so that's what we focused on in this session ok so let's",
    "start": "66090",
    "end": "72270"
  },
  {
    "text": "just take a look at an overview here of what we're gonna cover so at the top first of all our p3 compute instances",
    "start": "72270",
    "end": "78330"
  },
  {
    "text": "these are the fastest machine learning instances that are available and they have up to eight Nvidia v100 GPUs each",
    "start": "78330",
    "end": "87960"
  },
  {
    "text": "with 32 gigs of memory and they have envy link for peer-to-peer communication this enables faster communication",
    "start": "87960",
    "end": "94290"
  },
  {
    "text": "between the different nodes for machine learning workloads and reduces the latency they support a",
    "start": "94290",
    "end": "100829"
  },
  {
    "text": "wide variety of use cases including machine learning but also HPC simulations we've had customers using",
    "start": "100829",
    "end": "106710"
  },
  {
    "text": "that like shrew dinger is doing drug discovery of their clients do drug discovery using HPC on p3 and financial",
    "start": "106710",
    "end": "114810"
  },
  {
    "text": "computing risk analysis then we have our graphics instances our GPU based",
    "start": "114810",
    "end": "120540"
  },
  {
    "text": "graphics instances g3 is the latest in that line and these supports up to 4",
    "start": "120540",
    "end": "126630"
  },
  {
    "text": "NVIDIA GPUs and can be run in the grid virtual workstation mode and these are great for",
    "start": "126630",
    "end": "133760"
  },
  {
    "text": "3d rendering this is also can be virtualized so you can support many clients simultaneously and it's great",
    "start": "133760",
    "end": "141500"
  },
  {
    "text": "for any graphic intensive you know workload and then we'll talk about our",
    "start": "141500",
    "end": "146540"
  },
  {
    "text": "field programmable gate arrays or FPGA instances these enable tremendously high",
    "start": "146540",
    "end": "154280"
  },
  {
    "text": "volumes of parallel compute and we'll get into more depth about that but they include the Xilinx FPGA s up to eight of",
    "start": "154280",
    "end": "162740"
  },
  {
    "text": "those in a single instance and now support OpenCL and so we'll talk about that here a little bit more depth ok so",
    "start": "162740",
    "end": "169160"
  },
  {
    "start": "168000",
    "end": "168000"
  },
  {
    "text": "first of all just at the highest level the difference between CPUs GPUs and",
    "start": "169160",
    "end": "174739"
  },
  {
    "text": "FPGA so CPUs have many cores and arithmetic logic units or al use and",
    "start": "174739",
    "end": "181790"
  },
  {
    "text": "those can be run in parallel and so it enables a very flexible and broad",
    "start": "181790",
    "end": "189290"
  },
  {
    "text": "instruction set and it has a set data path width and this is great for",
    "start": "189290",
    "end": "195920"
  },
  {
    "text": "general-purpose computing where you need to do a variety such a wide variety of different things GPUs enable more parallel processing",
    "start": "195920",
    "end": "203840"
  },
  {
    "text": "with thousands of parallel al use and processing cores and this is great for",
    "start": "203840",
    "end": "210230"
  },
  {
    "text": "operations that are more limited in scope but can be parallelized for faster",
    "start": "210230",
    "end": "215600"
  },
  {
    "text": "throughput and this is great for things like graphics rendering for machine learning and then FPGA actually has",
    "start": "215600",
    "end": "222769"
  },
  {
    "text": "millions of these programmable logic cores and they don't have a fixed data",
    "start": "222769",
    "end": "228920"
  },
  {
    "text": "path width so you can change it from let's say 8-bit or 7 bit you can define it so that you're maximizing the usage",
    "start": "228920",
    "end": "236269"
  },
  {
    "text": "of these programmable logic core cells and taking advantage of you know",
    "start": "236269",
    "end": "241840"
  },
  {
    "text": "potentially hundreds of thousands or up to millions of simultaneous small operations on these FPGAs so it's a",
    "start": "241840",
    "end": "251720"
  },
  {
    "text": "hardware timed execution and you know you have the ability to set that data",
    "start": "251720",
    "end": "257150"
  },
  {
    "text": "path width so there a lot of flexibility in terms of how you define it and a lot of parallel processing",
    "start": "257150",
    "end": "263160"
  },
  {
    "text": "possible so let's start with the p3 and dive into this so the p3 instances gives",
    "start": "263160",
    "end": "270840"
  },
  {
    "start": "266000",
    "end": "266000"
  },
  {
    "text": "you up to a petaflop of compute performance so the new p3 is now 14 up",
    "start": "270840",
    "end": "277230"
  },
  {
    "text": "to 14 times faster than the p2 the prior generation and with 300 gigabytes per",
    "start": "277230",
    "end": "283350"
  },
  {
    "text": "second of GPU to GPU communication through that env link and that's about nine times faster than the p2 instance",
    "start": "283350",
    "end": "290730"
  },
  {
    "text": "the prior version so with 16 gigabytes of GPU memory and up to 32 gigs on the",
    "start": "290730",
    "end": "298200"
  },
  {
    "text": "very latest instances and 900 gigabytes per second Peaks GPU memory bandwidth it",
    "start": "298200",
    "end": "305070"
  },
  {
    "text": "enables you to process a lot of data in parallel and we're seeing a wide variety",
    "start": "305070",
    "end": "310650"
  },
  {
    "text": "of use cases by our customers so a couple of examples Airbnb is able to use",
    "start": "310650",
    "end": "317010"
  },
  {
    "start": "313000",
    "end": "313000"
  },
  {
    "text": "p3 to help their hosts optimize the price that they list their their real",
    "start": "317010",
    "end": "324300"
  },
  {
    "text": "estate for by leveraging machine learning on p3 and they can process this much faster and stay up to date with the",
    "start": "324300",
    "end": "330810"
  },
  {
    "text": "latest market trends we're seeing examples like salesforce is using machine learning for image recognition",
    "start": "330810",
    "end": "337380"
  },
  {
    "text": "so they can look for for example your logo in certain places to measure impact",
    "start": "337380",
    "end": "342720"
  },
  {
    "text": "and impressions they can use it for detecting you know for visual search for",
    "start": "342720",
    "end": "352070"
  },
  {
    "text": "identifying your products as well and so this can be really helpful for sales",
    "start": "352070",
    "end": "357360"
  },
  {
    "text": "teams and then we also see examples like in Western Digital we talked a little bit about them designing doing material",
    "start": "357360",
    "end": "364830"
  },
  {
    "text": "design and measuring performance of those materials with simulations and shrewd injure doing chemical simulations",
    "start": "364830",
    "end": "371310"
  },
  {
    "text": "for their customers who are doing drug discovery but it can also use for you",
    "start": "371310",
    "end": "376650"
  },
  {
    "text": "know weather simulation computational fluid dynamics we've seen it used in oil",
    "start": "376650",
    "end": "382500"
  },
  {
    "text": "and gas for seismic analysis so a wide variety of potential use cases here ok",
    "start": "382500",
    "end": "389520"
  },
  {
    "start": "388000",
    "end": "388000"
  },
  {
    "text": "so here are the details for the p3 instances so they're available across 8",
    "start": "389520",
    "end": "394569"
  },
  {
    "text": "regions so we've got a lot more availability of p3 and now with support",
    "start": "394569",
    "end": "400449"
  },
  {
    "text": "for all the major frameworks such as tensorflow MX net pi torch cafe - and CNT k it",
    "start": "400449",
    "end": "408879"
  },
  {
    "text": "really makes it more flexible for our customers to be able to run the kind of machine learning they want to but really",
    "start": "408879",
    "end": "414369"
  },
  {
    "text": "accelerate that's the pace at which it's done and so what we're seeing is customers are able to dramatically",
    "start": "414369",
    "end": "420819"
  },
  {
    "text": "reduce the time required to wait for results so one of the things to point",
    "start": "420819",
    "end": "427569"
  },
  {
    "text": "out is on the p3 instances the new GPU to GPU communication is really improved",
    "start": "427569",
    "end": "432909"
  },
  {
    "text": "with envy link and that's part of what's delivering a lot of the faster performance versus the PCI Express in",
    "start": "432909",
    "end": "439330"
  },
  {
    "text": "the prior generation so as we look at p2 versus p3 performance when you look at",
    "start": "439330",
    "end": "445270"
  },
  {
    "text": "like mixed performance mixed floating-point mixed precision floating point you see about a 14 up to 14 times",
    "start": "445270",
    "end": "453159"
  },
  {
    "text": "faster for p3 and part of the reason for that is you know the support for mixed",
    "start": "453159",
    "end": "459610"
  },
  {
    "text": "performance and 1/2 precision on p3 and then when you look at a single precision",
    "start": "459610",
    "end": "465639"
  },
  {
    "text": "FP 32 performance still a 1.7 X improvement and then for double",
    "start": "465639",
    "end": "471490"
  },
  {
    "text": "precision that's you over 2x improvement in performance so big increase in",
    "start": "471490",
    "end": "477639"
  },
  {
    "text": "performance with the p3 and then we've just recently announced the new larger",
    "start": "477639",
    "end": "484589"
  },
  {
    "text": "24x large so this gives you 32 gigabytes of GPU memory that was a big increase in",
    "start": "484589",
    "end": "491559"
  },
  {
    "text": "total memory available much faster networking with up to 100 gigabits per second and that's where we're seeing",
    "start": "491559",
    "end": "498249"
  },
  {
    "text": "some of our customers really pushed the limits like fast a I and 96 skylake CPUs",
    "start": "498249",
    "end": "506729"
  },
  {
    "text": "so you've got avx-512 which is great for imprint so machine learning and training",
    "start": "506729",
    "end": "512380"
  },
  {
    "text": "data pre-processing training data so now you've got an instance that can really push the boundaries of what was possible",
    "start": "512380",
    "end": "519370"
  },
  {
    "text": "in terms of performance with machine learning the processors are 3.1",
    "start": "519370",
    "end": "524860"
  },
  {
    "text": "gigahertz scalable you know this skylake xeon processors and in",
    "start": "524860",
    "end": "532110"
  },
  {
    "start": "527000",
    "end": "527000"
  },
  {
    "text": "terms of scaling performance what we've been able to see is using a single p three-inch instance with Volta GPUs you",
    "start": "532110",
    "end": "539670"
  },
  {
    "text": "know customers are really reducing the training times for their machine learning models and we've seen it go",
    "start": "539670",
    "end": "545430"
  },
  {
    "text": "from days to just hours and when we talk to our customers who are doing that like Intuit to find out like what does that",
    "start": "545430",
    "end": "551250"
  },
  {
    "text": "mean for you it means their development teams can have now a much faster iteration cycle and they can try a bunch",
    "start": "551250",
    "end": "556800"
  },
  {
    "text": "of new ideas much more quickly and that's what we hope to enable for you with p3 is that you can unleash",
    "start": "556800",
    "end": "562380"
  },
  {
    "text": "innovation at an even faster pace to come up and try and test new ideas to",
    "start": "562380",
    "end": "567810"
  },
  {
    "text": "put new things to the test and get the results quickly so we've been able to train the reson at 52 top one validation",
    "start": "567810",
    "end": "576089"
  },
  {
    "text": "accuracy at 76 percent in just 47 minutes using eight of the p3 16x large",
    "start": "576089",
    "end": "583020"
  },
  {
    "text": "instances so this is incredible performance improvement and what's",
    "start": "583020",
    "end": "588180"
  },
  {
    "text": "really what it really means at the end of the day is much lower cost when you think about all the costs of operating",
    "start": "588180",
    "end": "593970"
  },
  {
    "text": "these and and being able to have the staff and all of your data and the",
    "start": "593970",
    "end": "599370"
  },
  {
    "text": "things that are there waiting in order for those results you're really reducing the cost to be able to handle a certain",
    "start": "599370",
    "end": "605220"
  },
  {
    "text": "amount of work we also have the broadest availability so now in 14 regions we",
    "start": "605220",
    "end": "614010"
  },
  {
    "start": "607000",
    "end": "607000"
  },
  {
    "text": "have across all these different regions we have p3 and the the largest size is",
    "start": "614010",
    "end": "619470"
  },
  {
    "text": "in US East and us West so that now more and more countries can in regions can",
    "start": "619470",
    "end": "627480"
  },
  {
    "text": "take advantage of this this is particularly important for areas where the the data set being processed needs",
    "start": "627480",
    "end": "634440"
  },
  {
    "text": "to remain in region for compliance or regulatory requirements and also just to",
    "start": "634440",
    "end": "639839"
  },
  {
    "text": "speed up the the workflow for teams that are located in those different geographies and by the way those are",
    "start": "639839",
    "end": "647610"
  },
  {
    "start": "646000",
    "end": "646000"
  },
  {
    "text": "available on spot as well so if you're looking at the largest instance sizes and you're saying how am I going to",
    "start": "647610",
    "end": "652830"
  },
  {
    "text": "afford that take a look at spot you'll be surprised that with up to 90 percent cost savings it's amazing you can just",
    "start": "652830",
    "end": "659190"
  },
  {
    "text": "spin one of those up and start right away with using that and it's a really great way to get",
    "start": "659190",
    "end": "664640"
  },
  {
    "text": "introduced to the ADA goes platform and start using machine learning on the cloud is with these really fast instances the only trouble will be going",
    "start": "664640",
    "end": "671720"
  },
  {
    "text": "back to the you know you're your own laptop or desktop after you see the performance of these you know it's amazing so in terms of storage of course",
    "start": "671720",
    "end": "679010"
  },
  {
    "text": "your machine learning needs to be fed a lot of data data is what really is the heart and soul so you've got to feed a",
    "start": "679010",
    "end": "684770"
  },
  {
    "text": "lot of data in and how do you do that well there's several different options so we have EFS the elastic file storage",
    "start": "684770",
    "end": "691070"
  },
  {
    "text": "and this is highly available multi AZ file storage that's there for you this",
    "start": "691070",
    "end": "697430"
  },
  {
    "text": "enables you to do read often temporary storage and this is great for you know",
    "start": "697430",
    "end": "703940"
  },
  {
    "text": "highly available storage in you know NFS format now you've also got the option to",
    "start": "703940",
    "end": "710120"
  },
  {
    "text": "use EBS and you can actually connect multiple EBS volumes to a single instance so you can mix and match those",
    "start": "710120",
    "end": "716210"
  },
  {
    "text": "but it gives you the kind of I ops that you need in order to saturate your GPUs",
    "start": "716210",
    "end": "721250"
  },
  {
    "text": "for high i/o performance and now with s3 we offer up to 100 gigabits ingestion",
    "start": "721250",
    "end": "727670"
  },
  {
    "text": "from s3 so talk about loading up your data really quickly and to do machine",
    "start": "727670",
    "end": "732830"
  },
  {
    "text": "learning workloads you can actually store an s3 and get very very fast load performance and now with glaciar you can",
    "start": "732830",
    "end": "740260"
  },
  {
    "text": "archive that data off that's been processed where you've fed it into your machine learning model and you don't",
    "start": "740260",
    "end": "745610"
  },
  {
    "text": "need to look at it again for a while you can archive that longer-term at a much lower cost point and then we recently",
    "start": "745610",
    "end": "753620"
  },
  {
    "start": "752000",
    "end": "752000"
  },
  {
    "text": "announced and was on fsx for lustre this is a shared file system for high",
    "start": "753620",
    "end": "759830"
  },
  {
    "text": "performance computing so this enables you know a lot of use cases of p3 and",
    "start": "759830",
    "end": "765980"
  },
  {
    "text": "and RC five instances where you need to have that shared file storage to keep",
    "start": "765980",
    "end": "771200"
  },
  {
    "text": "the job state or to be able to pull data in for these different jobs and in addition to that we also supports",
    "start": "771200",
    "end": "777950"
  },
  {
    "start": "777000",
    "end": "777000"
  },
  {
    "text": "Windows File server with Amazon FS X so it's actually windows native this is",
    "start": "777950",
    "end": "783770"
  },
  {
    "text": "actual a Windows file server hosted on the cloud and it's fully managed for you so there's no need to manage that file",
    "start": "783770",
    "end": "790220"
  },
  {
    "text": "server performance is very fast and it's secure and compliant so it",
    "start": "790220",
    "end": "796130"
  },
  {
    "text": "gives you windows native capability for compatibility with the industry standard SMB protocol so if you have software",
    "start": "796130",
    "end": "803210"
  },
  {
    "text": "that uses that you know it's it you don't have to worry about detecting or",
    "start": "803210",
    "end": "809180"
  },
  {
    "text": "correcting hardware failures it does that for you automatically including performing regular backups and it's",
    "start": "809180",
    "end": "815090"
  },
  {
    "text": "secure and compliant so it's PCI DSS compliance and it's the first service to",
    "start": "815090",
    "end": "821900"
  },
  {
    "text": "be both PCI DSS and HIPAA eligible at launch so this can be great for you know",
    "start": "821900",
    "end": "828440"
  },
  {
    "text": "protected health information or other sensitive data and it delivers really",
    "start": "828440",
    "end": "833450"
  },
  {
    "text": "fast performance so up to ten gigabytes per second of throughput yeah across",
    "start": "833450",
    "end": "838940"
  },
  {
    "text": "petabytes of data so skills really nicely okay so in terms of data",
    "start": "838940",
    "end": "845480"
  },
  {
    "start": "844000",
    "end": "844000"
  },
  {
    "text": "ingestion options here are a couple so as we talked about briefly before you can attach multiple EBS volumes to your",
    "start": "845480",
    "end": "852320"
  },
  {
    "text": "instance and you can provision the I ops on those so that you can get you know",
    "start": "852320",
    "end": "857720"
  },
  {
    "text": "the maximum saturation of your GPUs that you need so you can either use",
    "start": "857720",
    "end": "862730"
  },
  {
    "text": "independent and independent EBS volume or combine multiple volumes via raid so",
    "start": "862730",
    "end": "869000"
  },
  {
    "text": "that's a couple different options that we've seen customers use and then the other one we mentioned briefly is you",
    "start": "869000",
    "end": "875930"
  },
  {
    "text": "know you can configure s3 to connect to your ec2 instance and that's a very fast",
    "start": "875930",
    "end": "881510"
  },
  {
    "text": "way to ingest and you can use the s3 Java SDK to do that to pull in those",
    "start": "881510",
    "end": "887540"
  },
  {
    "text": "data so in terms of software support you need these hardware driver versions so",
    "start": "887540",
    "end": "895400"
  },
  {
    "start": "889000",
    "end": "889000"
  },
  {
    "text": "you need three 84.8 one or newer the cuda nine or newer driver and these are",
    "start": "895400",
    "end": "903920"
  },
  {
    "text": "you know the CU d NN 7 or newer is usually packaged with with cuda so you",
    "start": "903920",
    "end": "909170"
  },
  {
    "text": "need that as well and then in order to take advantage of the all the cores you're gonna be needing to use the",
    "start": "909170",
    "end": "915590"
  },
  {
    "text": "latest ml framework distro so make sure you get the latest versions of those but",
    "start": "915590",
    "end": "921320"
  },
  {
    "text": "we support all these different versions of tests tensorflow and my",
    "start": "921320",
    "end": "926750"
  },
  {
    "text": "at PI torch cafe - so take a look at those docks the NVIDIA docks for specifics but make sure you get the",
    "start": "926750",
    "end": "932839"
  },
  {
    "text": "latest drivers and are using the latest frameworks to be able to get the maximum performance we also offer our own deep",
    "start": "932839",
    "end": "941389"
  },
  {
    "start": "938000",
    "end": "938000"
  },
  {
    "text": "learning Amazon machine image so we basically provide to you a machine image that comes with all the latest frameworks and that just helps you",
    "start": "941389",
    "end": "948170"
  },
  {
    "text": "maintain and manage all the dependencies to make sure you have the latest versions installed and that you're",
    "start": "948170",
    "end": "953779"
  },
  {
    "text": "getting the best possible support and try them in terms of drivers of being",
    "start": "953779",
    "end": "958970"
  },
  {
    "text": "able to tap into the hardware performance so we have some great customer examples using machine learning",
    "start": "958970",
    "end": "964970"
  },
  {
    "text": "so for example ZocDoc uses machine learning to help with patient scheduling",
    "start": "964970",
    "end": "970430"
  },
  {
    "text": "and they actually have two different use cases in production right now one is a patient powered search so it basically",
    "start": "970430",
    "end": "977689"
  },
  {
    "text": "helps you know quickly find the specialists that they that you would need for the service you need so it uses",
    "start": "977689",
    "end": "983660"
  },
  {
    "text": "a semantic model and it basically Maps the intent of your search to a",
    "start": "983660",
    "end": "989029"
  },
  {
    "text": "specialist because sometimes the terminology in melton healthcare is kind of you know foreign to us as consumers",
    "start": "989029",
    "end": "996410"
  },
  {
    "text": "and so consumers can just type in words and it'll understand the intent of what you're looking for and it uses inference",
    "start": "996410",
    "end": "1002800"
  },
  {
    "text": "but they build that machine learning model using this Amazon machine learning",
    "start": "1002800",
    "end": "1008019"
  },
  {
    "text": "image and then they have a relevancy model to help find the most relevant doctor in your area and then the new",
    "start": "1008019",
    "end": "1016990"
  },
  {
    "text": "thing that they've added recently is an insurance checker that helps to leverage AI to make sure that you're getting the",
    "start": "1016990",
    "end": "1023800"
  },
  {
    "text": "best possible insurance coverage and then taking the advantage of your current insurance to understand the",
    "start": "1023800",
    "end": "1031240"
  },
  {
    "text": "coverage better so it'll scan your ID card and based on that be able to identify you know who's in network and",
    "start": "1031240",
    "end": "1036970"
  },
  {
    "text": "where you should be going for those appointments",
    "start": "1036970",
    "end": "1041010"
  },
  {
    "start": "1041000",
    "end": "1041000"
  },
  {
    "text": "okay so Amazon sage maker takes advantage of p3 instances this is",
    "start": "1042000",
    "end": "1048390"
  },
  {
    "text": "basically in two end machine learning platform for you on AWS so you don't have to do any setup it's fully managed",
    "start": "1048390",
    "end": "1054990"
  },
  {
    "text": "for you and what's great is it'll even tune your model by you know doing the",
    "start": "1054990",
    "end": "1061080"
  },
  {
    "text": "hyper parameter optimization for you you just pay by the second for you know the",
    "start": "1061080",
    "end": "1066900"
  },
  {
    "text": "machine learning the model development and then in execution and what's great is it gives you a way to put your model",
    "start": "1066900",
    "end": "1073980"
  },
  {
    "text": "into production because typically those are two separate steps and with sage maker you can actually go from you know",
    "start": "1073980",
    "end": "1081030"
  },
  {
    "text": "building and creating your model tuning it to now going into production and",
    "start": "1081030",
    "end": "1086760"
  },
  {
    "text": "being able to update it on a regular basis with the latest data that have come in so a lot of customers have seen",
    "start": "1086760",
    "end": "1093240"
  },
  {
    "text": "this as a great way to especially for people who are new to machine learning to help them understand the concepts and",
    "start": "1093240",
    "end": "1098700"
  },
  {
    "text": "get up and running with it quickly so if they need Jupiter notebooks they want to share some data and be able to",
    "start": "1098700",
    "end": "1104820"
  },
  {
    "text": "collaborate and then be able to push that into production there's usually several teams involved with that whole",
    "start": "1104820",
    "end": "1110220"
  },
  {
    "text": "workflow and sage maker you know simplifies that pretty dramatically and",
    "start": "1110220",
    "end": "1116630"
  },
  {
    "text": "especially for developers you know sometimes for developers it feels like",
    "start": "1116870",
    "end": "1122010"
  },
  {
    "text": "machine learning is a lot more difficult than it needs to be this enables your developers who already have skills with",
    "start": "1122010",
    "end": "1128039"
  },
  {
    "text": "different languages and frameworks to quickly get up and running at scale on the cloud okay so let's talk now about",
    "start": "1128039",
    "end": "1135510"
  },
  {
    "text": "g3 so these are for graphics intensive use cases and include up to four GPUs in",
    "start": "1135510",
    "end": "1143280"
  },
  {
    "start": "1141000",
    "end": "1141000"
  },
  {
    "text": "these instances so with the g3 16x large",
    "start": "1143280",
    "end": "1148710"
  },
  {
    "text": "you've got four GPUs those can be dedicated to a particular workstation or",
    "start": "1148710",
    "end": "1153720"
  },
  {
    "text": "you can actually virtualize using the grid software that is included Nvidia",
    "start": "1153720",
    "end": "1160320"
  },
  {
    "text": "grid virtual application to virtualize these applications so you can support up to 25 concurrent users per GPU so this",
    "start": "1160320",
    "end": "1170520"
  },
  {
    "text": "can be a great way to build a graphically intense application on the cloud render it on the cloud and stream it",
    "start": "1170520",
    "end": "1176970"
  },
  {
    "text": "back to to those clients we've seen this used in a number of different cases such",
    "start": "1176970",
    "end": "1183659"
  },
  {
    "text": "as 3d visualizations particularly for you know if you're doing some sort of",
    "start": "1183659",
    "end": "1189299"
  },
  {
    "text": "workstation or 3d rendering this is a great way to do that with industry standard software and then this slide",
    "start": "1189299",
    "end": "1195840"
  },
  {
    "text": "shows a little bit about these four different modes of using the g3 so you can take advantage of the memory CPU",
    "start": "1195840",
    "end": "1203269"
  },
  {
    "start": "1196000",
    "end": "1196000"
  },
  {
    "text": "networking and GPU across these different use cases so one is you know video encoding for example using the ec2",
    "start": "1203269",
    "end": "1211470"
  },
  {
    "text": "instance instance and the Nvidia drivers then you can use the Nvidia grid for like a workstation of virtual",
    "start": "1211470",
    "end": "1217620"
  },
  {
    "text": "workstation and then rather than having to buy a massive you know physical",
    "start": "1217620",
    "end": "1223139"
  },
  {
    "text": "workstation and install this and you can actually put it to sleep as we talked about the hibernate capability works so",
    "start": "1223139",
    "end": "1229590"
  },
  {
    "text": "that you can put that instance to sleep and not pay for it when it's not being used and then you can also set it up for",
    "start": "1229590",
    "end": "1236970"
  },
  {
    "text": "up to 25 concurrent connections for these virtual apps so that you're taking advantage of all that capability across",
    "start": "1236970",
    "end": "1243990"
  },
  {
    "text": "many different end-users and then we've also seen it used for gaming services as well so you can build custom gaming",
    "start": "1243990",
    "end": "1251039"
  },
  {
    "text": "solutions that use this as part of the rendering or maybe for you know",
    "start": "1251039",
    "end": "1257429"
  },
  {
    "start": "1254000",
    "end": "1254000"
  },
  {
    "text": "collision detection things like that where there's you know GPU required and some rendering as well",
    "start": "1257429",
    "end": "1263299"
  },
  {
    "text": "so here's the comparison of the workstation versus of the virtual application modes so you can see you",
    "start": "1263299",
    "end": "1269700"
  },
  {
    "text": "know can support up to four monitors so again it comes with up to four GPUs on the g3 so you actually have a four",
    "start": "1269700",
    "end": "1275399"
  },
  {
    "text": "monitor workstation all powered virtually in the cloud and this is a use",
    "start": "1275399",
    "end": "1281850"
  },
  {
    "text": "case we're seeing especially with studios and media and entertainment as well as in engineering and design the",
    "start": "1281850",
    "end": "1289139"
  },
  {
    "text": "customers are able to do this and it just saves on the upgrade cycle they don't have to wait four or five years",
    "start": "1289139",
    "end": "1294360"
  },
  {
    "text": "for that normal upgrade Hardware cycle as soon as we have new graphics instances in the cloud they can just",
    "start": "1294360",
    "end": "1300210"
  },
  {
    "text": "immediately use their Amazon machine image and start it up",
    "start": "1300210",
    "end": "1305179"
  },
  {
    "start": "1305000",
    "end": "1305000"
  },
  {
    "text": "so here's some of the available marketplace offerings that you can get to run with these g3 instances so we",
    "start": "1305679",
    "end": "1313549"
  },
  {
    "text": "have Windows Server 26 2016 with the Nvidia grid driver for example and then",
    "start": "1313549",
    "end": "1320960"
  },
  {
    "text": "these those first two are no additional charge for some of these with the grid driver you're going to have an",
    "start": "1320960",
    "end": "1326809"
  },
  {
    "text": "additional fee but you can launch them straight from the marketplace with all the software pre-configured in the",
    "start": "1326809",
    "end": "1332000"
  },
  {
    "text": "Amazon machine image so let's talk about some of the use cases we talked a little",
    "start": "1332000",
    "end": "1339080"
  },
  {
    "start": "1335000",
    "end": "1335000"
  },
  {
    "text": "bit about energy and like oil and gas seismic analysis so Halliburton was a",
    "start": "1339080",
    "end": "1344960"
  },
  {
    "text": "great example where they needed to render this oil field a 3d visualization",
    "start": "1344960",
    "end": "1350419"
  },
  {
    "text": "of that and in order to do that they were able to tap into those four GPUs on",
    "start": "1350419",
    "end": "1356150"
  },
  {
    "text": "the g3 to be able to render in real time and it gave their team such an amazing new perspective on this data because",
    "start": "1356150",
    "end": "1364100"
  },
  {
    "text": "typically it was difficult to render it especially in real time to be able to move and manipulate it and see it and so",
    "start": "1364100",
    "end": "1370820"
  },
  {
    "text": "if you have use cases where you can take advantage of you know GPUs for graphics and rendering g3 is phenomenal",
    "start": "1370820",
    "end": "1379510"
  },
  {
    "text": "ok so now let's talk about f1 so f1 is our FPGA instance on the cloud and this",
    "start": "1380320",
    "end": "1387350"
  },
  {
    "text": "is basically for custom hardware acceleration so FPGA is very good at",
    "start": "1387350",
    "end": "1393169"
  },
  {
    "text": "processing massive amounts of data in parallel and what's great is the FPGA",
    "start": "1393169",
    "end": "1399049"
  },
  {
    "text": "does not come with an instruction set so it doesn't have a fixed data with path it's very flexible of course it requires",
    "start": "1399049",
    "end": "1405409"
  },
  {
    "text": "some skill set to program it but there's no complex control logic and you can run",
    "start": "1405409",
    "end": "1412610"
  },
  {
    "text": "millions of these things in parallel so now you gives you the ability to do a",
    "start": "1412610",
    "end": "1418460"
  },
  {
    "text": "lot of video processing we've seen it used for encryption we've seen it used for things like genomics and so for as",
    "start": "1418460",
    "end": "1427159"
  },
  {
    "text": "an example of this Edda code genome which has now been acquired by Illumina they were able to",
    "start": "1427159",
    "end": "1433190"
  },
  {
    "start": "1428000",
    "end": "1428000"
  },
  {
    "text": "set the Guinness Book of World Records for the fastest process into a thousand and genomes by spinning up a thousand of",
    "start": "1433190",
    "end": "1439470"
  },
  {
    "text": "these in the cloud on AWS so they were able to spin up a thousand of these",
    "start": "1439470",
    "end": "1444540"
  },
  {
    "text": "simultaneously and able to set a new record processing the thousand genomes",
    "start": "1444540",
    "end": "1450260"
  },
  {
    "text": "for an amazingly low cost of approximately $3 per whole human genome",
    "start": "1450260",
    "end": "1456059"
  },
  {
    "text": "which is just amazingly inexpensive and they did that with this fixed size they",
    "start": "1456059",
    "end": "1462990"
  },
  {
    "text": "basically created a rather than the fixed size data with paths on the CPU",
    "start": "1462990",
    "end": "1470220"
  },
  {
    "text": "which is 32 or 64 bit they were able to use a custom bit data path to be able to",
    "start": "1470220",
    "end": "1478530"
  },
  {
    "text": "maximize the throughput and basically they saw a 30x speed-up because they",
    "start": "1478530",
    "end": "1483660"
  },
  {
    "text": "were able to encode that algorithm on FPGA",
    "start": "1483660",
    "end": "1487909"
  },
  {
    "start": "1500000",
    "end": "1500000"
  },
  {
    "text": "ok so these are the FPGA instance types on AWS so there's three different",
    "start": "1500950",
    "end": "1506239"
  },
  {
    "text": "instance sizes available with up to eight FPGAs each with over 2 million",
    "start": "1506239",
    "end": "1512980"
  },
  {
    "text": "field programmable gate arrays or logic units and 5000 programmable DSP blocks",
    "start": "1512980",
    "end": "1520820"
  },
  {
    "text": "now one of the things that has been introduced recently is the ability to quickly load new Amazon FPGA images into",
    "start": "1520820",
    "end": "1530299"
  },
  {
    "text": "that FPGA and you can have multiple on each instance so we have we've recently",
    "start": "1530299",
    "end": "1538220"
  },
  {
    "text": "launched two new instance types one supporting up to eight Xilinx FPGA s and",
    "start": "1538220",
    "end": "1547249"
  },
  {
    "text": "we've added a lot more local nvme storage SSD storage so that you can",
    "start": "1547249",
    "end": "1552679"
  },
  {
    "text": "store a lot more of the data that you need because that was one of the customer feedbacks that we heard was hey",
    "start": "1552679",
    "end": "1558950"
  },
  {
    "text": "in order to process all this I need to be able to cache some data on the instance and so we've added a lot more instance store ok so there's three",
    "start": "1558950",
    "end": "1566869"
  },
  {
    "start": "1565000",
    "end": "1565000"
  },
  {
    "text": "different ways to use f1 so first of all if you have Hardware engineers of course the tools they're familiar with like ver",
    "start": "1566869",
    "end": "1572090"
  },
  {
    "text": "log they can create their hardware designs or FPGA designs and deploy those",
    "start": "1572090",
    "end": "1577179"
  },
  {
    "text": "using the ver log and VHDL for software engineers those who are not necessarily",
    "start": "1577179",
    "end": "1582980"
  },
  {
    "text": "that familiar with hardware development they can now use the open CL C++ library",
    "start": "1582980",
    "end": "1587989"
  },
  {
    "text": "to be able to convert these algorithms into Hardware instructions and then for",
    "start": "1587989",
    "end": "1594679"
  },
  {
    "text": "software engineers and developers if they're not proficient in FPGA design they can also use pre-built AF is on the",
    "start": "1594679",
    "end": "1602359"
  },
  {
    "text": "AWS marketplace and just be able to call into those to get the speed ups that",
    "start": "1602359",
    "end": "1607820"
  },
  {
    "text": "they need for various functions so here's an example so for an f1 instance",
    "start": "1607820",
    "end": "1613639"
  },
  {
    "start": "1610000",
    "end": "1610000"
  },
  {
    "text": "you're going to load an ami a machine image just like you would on our other instance types and then you're also",
    "start": "1613639",
    "end": "1619460"
  },
  {
    "text": "going to load an FPGA image or an AFI and offi and the AFI can be loaded in just a few",
    "start": "1619460",
    "end": "1626359"
  },
  {
    "text": "seconds so you can actually store multiple of those afi's on the instance and swap them out so if you need to do",
    "start": "1626359",
    "end": "1631879"
  },
  {
    "text": "video encoding then decrypt you can use a variety of different algorithms so you can just cache those on the instance and the Xilinx card",
    "start": "1631879",
    "end": "1638510"
  },
  {
    "text": "actually has onboard memory to store some of those images so you can quickly swap them and there's a great set of",
    "start": "1638510",
    "end": "1646010"
  },
  {
    "text": "tools there's a FPGA developer ami that's available in the marketplace that",
    "start": "1646010",
    "end": "1651920"
  },
  {
    "text": "comes with the tools pre-installed so that you can develop and debug and",
    "start": "1651920",
    "end": "1656930"
  },
  {
    "text": "deploy all these and test it out and then once you're ready you can make it available on the Atos marketplace and",
    "start": "1656930",
    "end": "1662750"
  },
  {
    "text": "start making money for you know converting your algorithm into a hardware accelerated AFI and so with",
    "start": "1662750",
    "end": "1672890"
  },
  {
    "start": "1672000",
    "end": "1672000"
  },
  {
    "text": "OpenCL this is a big improvement now you can use c and c++ to be able to create",
    "start": "1672890",
    "end": "1678590"
  },
  {
    "text": "new hardware accelerated afi's and bring your algorithms to the cloud so if you",
    "start": "1678590",
    "end": "1684230"
  },
  {
    "text": "have proprietary algorithms and you would like to accelerate those and make those available to other Atos customers",
    "start": "1684230",
    "end": "1690080"
  },
  {
    "text": "you can do that using the open CL and there's no need to you know upgrade or",
    "start": "1690080",
    "end": "1695780"
  },
  {
    "text": "install anything on the developer ami it's already part of that so you can grab that from the marketplace so here's",
    "start": "1695780",
    "end": "1703970"
  },
  {
    "start": "1703000",
    "end": "1703000"
  },
  {
    "text": "an example from the marketplace so you can go up there and search and find you know the existing options that are",
    "start": "1703970",
    "end": "1710750"
  },
  {
    "text": "available from third parties as well as from AWS so you'll see the the developer",
    "start": "1710750",
    "end": "1715760"
  },
  {
    "text": "army is in the upper left there and then you'll see a variety of other offerings",
    "start": "1715760",
    "end": "1721100"
  },
  {
    "text": "now on the cloud and we'd love to see your company or startup you know put some offerings up there and and make",
    "start": "1721100",
    "end": "1726920"
  },
  {
    "text": "those available as well or you can take advantage of the ones that are there",
    "start": "1726920",
    "end": "1732440"
  },
  {
    "start": "1731000",
    "end": "1731000"
  },
  {
    "text": "already up there in your applications so again delivering these to you know as a",
    "start": "1732440",
    "end": "1739429"
  },
  {
    "text": "partner delivering these solutions we have the machine image and then you can",
    "start": "1739429",
    "end": "1745700"
  },
  {
    "text": "deploy via the marketplace both the afi's that are encrypted and secured so",
    "start": "1745700",
    "end": "1753110"
  },
  {
    "text": "your algorithm is safe if you put your proprietary algorithm in there it's encrypted and secured and then both of",
    "start": "1753110",
    "end": "1758960"
  },
  {
    "text": "those are loaded simultaneously into on the marketplace and pushed out to",
    "start": "1758960",
    "end": "1764039"
  },
  {
    "text": "their instances as they deploy it so they never see your code they'll never see your algorithm but they'll get the",
    "start": "1764039",
    "end": "1769049"
  },
  {
    "text": "speed up that that you're able to deliver with the Xilinx FPGA cards so",
    "start": "1769049",
    "end": "1776580"
  },
  {
    "start": "1772000",
    "end": "1772000"
  },
  {
    "text": "again there's a summary of our accelerated computing instances so we have p3 for GPU machine learning",
    "start": "1776580",
    "end": "1782400"
  },
  {
    "text": "acceleration the g3 instance for graphics intensive rendering applications and the f1 which is our",
    "start": "1782400",
    "end": "1789510"
  },
  {
    "text": "FPGA instance in the cloud so again we're putting in a wide variety of different options out there in terms of",
    "start": "1789510",
    "end": "1795690"
  },
  {
    "text": "processor architecture and in terms of parallel computing and accelerated computing and the goal is to you know",
    "start": "1795690",
    "end": "1803190"
  },
  {
    "text": "enable new innovation that you know hasn't been possible in the past and that you're gonna help bring - you know",
    "start": "1803190",
    "end": "1810450"
  },
  {
    "text": "- AWS so please connect with me right afterwards would love to help answer",
    "start": "1810450",
    "end": "1815730"
  },
  {
    "text": "your questions and also connect you with us some of our solutions architects to design your solution or help with your",
    "start": "1815730",
    "end": "1821730"
  },
  {
    "text": "migration and also to hear your feedback and needs in terms of capabilities on",
    "start": "1821730",
    "end": "1826890"
  },
  {
    "text": "the cloud again we want to deliver our vision is to bring compute to the around the world wherever you need it and to",
    "start": "1826890",
    "end": "1833490"
  },
  {
    "text": "provide at you know very low cost and the scalability performance and availability that you need and do that",
    "start": "1833490",
    "end": "1839970"
  },
  {
    "text": "in a secure way so thanks again for your time today and look forward to chatting with you afterwards appreciate it",
    "start": "1839970",
    "end": "1847340"
  }
]
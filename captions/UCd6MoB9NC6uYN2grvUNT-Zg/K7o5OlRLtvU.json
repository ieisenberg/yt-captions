[
  {
    "text": "good afternoon and uh welcome my name is Sia raghupati uh just a little bit of",
    "start": "480",
    "end": "6919"
  },
  {
    "text": "introduction about myself I've been with uh Amazon web services for the last six and a half years um I uh helped build a",
    "start": "6919",
    "end": "14160"
  },
  {
    "text": "couple of services Amazon Dynamo DB which is our nosql database tour and Amazon RDS which is our relational",
    "start": "14160",
    "end": "21119"
  },
  {
    "text": "database service for the last four years I've been working with customers including amazon.com on building some of",
    "start": "21119",
    "end": "27519"
  },
  {
    "text": "the Big Data guiding them build some of the Big Data Solutions on AWS I'm here to share some of my experiences with you",
    "start": "27519",
    "end": "34760"
  },
  {
    "text": "uh hopefully you'll find that interesting thank you for being here um I'm delighted to delighted to be here as",
    "start": "34760",
    "end": "41120"
  },
  {
    "text": "well uh so I think uh I think you went through the keynote this morning I think it was phenomenal so I think I'm going",
    "start": "41120",
    "end": "46680"
  },
  {
    "text": "to touch on some of those pieces or services that Andre introduced this morning as well to see where it fits into the Big Data ecosystem my slides",
    "start": "46680",
    "end": "53120"
  },
  {
    "text": "are already a little bit old I'm missing a couple of pieces as well so so in",
    "start": "53120",
    "end": "58440"
  },
  {
    "text": "terms of what to expect from this session uh we'll go through some of the Big Data challenges uh I'll give you my",
    "start": "58440",
    "end": "63879"
  },
  {
    "text": "perspective as an architect on what I'm seeing com in these days and what kind of problems I'm solving uh you know are",
    "start": "63879",
    "end": "70960"
  },
  {
    "text": "helping solve on behalf of customers uh then we'll also go through I I'll go through a uh my view of how to simplify",
    "start": "70960",
    "end": "77520"
  },
  {
    "text": "big data processing and um you know what technologies to use why and how and uh",
    "start": "77520",
    "end": "85040"
  },
  {
    "text": "we'll also go through some reference architectures and design patterns towards the end of the presentation so",
    "start": "85040",
    "end": "90479"
  },
  {
    "text": "uh I'm not going to go through any code if you're looking to see code I believe that you should get the architecture",
    "start": "90479",
    "end": "95640"
  },
  {
    "text": "first and then start coding after so I'm going to concentrate on architecture in this talk",
    "start": "95640",
    "end": "101360"
  },
  {
    "text": "so and uh well the way I see this is it's ever increasing Big Data the volume",
    "start": "101360",
    "end": "107560"
  },
  {
    "text": "velocity and variety of data is ever increasing what that means to me on a daily basis today is customers are",
    "start": "107560",
    "end": "115200"
  },
  {
    "text": "wanting to build systems that can handle millions of requests per second again I repeat that millions of requests per",
    "start": "115200",
    "end": "121320"
  },
  {
    "text": "second and billions of events per day about 4 years ago somebody doing 150 or",
    "start": "121320",
    "end": "127159"
  },
  {
    "text": "200,000 requests per second was was a little bit rare and it it happened but today uh a lot of the vendors who are",
    "start": "127159",
    "end": "134280"
  },
  {
    "text": "actually especially you know companies doing energy meters Etc are testing things with a 100 thou you know million",
    "start": "134280",
    "end": "141000"
  },
  {
    "text": "requests per second so that's becoming the norm these days the interesting thing that I observe is that even though",
    "start": "141000",
    "end": "148360"
  },
  {
    "text": "this is large workload and uh you know ingesting probably tens of terabytes of",
    "start": "148360",
    "end": "153400"
  },
  {
    "text": "data per day the time to build these systems have really shrunk uh we're looking at maybe a handful of developers",
    "start": "153400",
    "end": "160680"
  },
  {
    "text": "in some cases one building the system in about 3 to four weeks in a Sprint uh the",
    "start": "160680",
    "end": "166480"
  },
  {
    "text": "cloud services that I'll go through has enabled this Innovation possible so um",
    "start": "166480",
    "end": "171720"
  },
  {
    "text": "it's no longer needed to you know you know no longer have to wait for weeks or months to build these systems you can",
    "start": "171720",
    "end": "176879"
  },
  {
    "text": "build them in weeks if you have the architecture right so getting the architecture right is key for Building",
    "start": "176879",
    "end": "182480"
  },
  {
    "text": "Systems fast and that will scale to any throughput or any workload and um sort",
    "start": "182480",
    "end": "190040"
  },
  {
    "text": "of the Big Data Evolution um you know from my perspective a lot of the workloads are moving from batch to real",
    "start": "190040",
    "end": "197080"
  },
  {
    "text": "time and some of the companies are moving from real time to predictions",
    "start": "197080",
    "end": "203080"
  },
  {
    "text": "right um for example instead of actually if you're building a building system",
    "start": "203080",
    "end": "208519"
  },
  {
    "text": "rather than creating a monthly report or a weekly report uh would it be nice to actually alert someone if your bill you",
    "start": "208519",
    "end": "215879"
  },
  {
    "text": "know if if your thresholds are going to be breached and interestingly enough in in in addition to alerting alerting also",
    "start": "215879",
    "end": "222080"
  },
  {
    "text": "tells you after the fact would it be nice to say you're on a trajectory that you may actually exceed your budget",
    "start": "222080",
    "end": "227879"
  },
  {
    "text": "right so again you can apply the semantics to pretty much anything that you build um so there are systems now",
    "start": "227879",
    "end": "234840"
  },
  {
    "text": "and for example Amazon machine learning service enables you to do some predictions um on on fast moving data as",
    "start": "234840",
    "end": "241599"
  },
  {
    "text": "well as batch workloads so how do you build predictions in addition to real time into your data processing pipeline",
    "start": "241599",
    "end": "248040"
  },
  {
    "text": "is getting pretty key I have a couple of kids uh 6 years old and 10 years old",
    "start": "248040",
    "end": "253239"
  },
  {
    "text": "they got pretty excited when when they saw this slide I've been drawing pictures for the last one month in preparation for this talk but when they",
    "start": "253239",
    "end": "259400"
  },
  {
    "text": "saw this slide because what I did was I really destroyed the entire little city my son and daughter created to take",
    "start": "259400",
    "end": "265320"
  },
  {
    "text": "those three pictures at the very bottom and I was looking for a good contrast between the colors and I really had to",
    "start": "265320",
    "end": "270919"
  },
  {
    "text": "apologize to my son when he came back and found out from a football game that Dad has completely destroyed uh his his",
    "start": "270919",
    "end": "276600"
  },
  {
    "text": "Lego City you know so well I when he showed this slide hopefully I'll show this slide to him in you YouTube and",
    "start": "276600",
    "end": "282240"
  },
  {
    "text": "it'll be feel cool so so in essence that's what is happening in other words we're we're putting like a head uh our",
    "start": "282240",
    "end": "288240"
  },
  {
    "text": "intelligence into you know big data processing systems and uh you know if",
    "start": "288240",
    "end": "293919"
  },
  {
    "text": "you're familiar with Lego there's a lot more to that to that uh picture you know the toy on the top on the right side so",
    "start": "293919",
    "end": "300160"
  },
  {
    "text": "we can do a lot more uh so uh well so we're not alone uh there's a plora of",
    "start": "300160",
    "end": "306800"
  },
  {
    "text": "tools to solve big data problems on the left side the Apache ecosystem is creating some amazing tools uh I want to",
    "start": "306800",
    "end": "313880"
  },
  {
    "text": "call this the zoo of Technologies with the Zookeeper you know starting with the Hadoop the elephant uh Hive uh Pig spark",
    "start": "313880",
    "end": "321319"
  },
  {
    "text": "nowadays if you go to any big data conference spark is the answer no matter what the question is so I think I think",
    "start": "321319",
    "end": "328360"
  },
  {
    "text": "you looks like that's probably true so we'll see how to how to use spark you know what are the you know pros and cons",
    "start": "328360",
    "end": "334720"
  },
  {
    "text": "of spark how should how how it fits into the Big Data ecosystem as well um you",
    "start": "334720",
    "end": "339840"
  },
  {
    "text": "know I thought spark was the answer but turns out that that squirel at the very bottom on the left which is uh which is",
    "start": "339840",
    "end": "346319"
  },
  {
    "text": "pink you anyone know what that is it's called Apache Flink I think that some some people are raising their hands",
    "start": "346319",
    "end": "352039"
  },
  {
    "text": "apparently the squirrel is going to compete with the spark to see who does better so the the key point for me uh in",
    "start": "352039",
    "end": "359639"
  },
  {
    "text": "in this slide uh before I get there on the right side right every time you come to reinvent we we gleefully announce",
    "start": "359639",
    "end": "366080"
  },
  {
    "text": "we're excited to announce a whole bunch of other services for the next next year probably if I do the talk again um you",
    "start": "366080",
    "end": "371720"
  },
  {
    "text": "know I don't know maybe one slide I need to have two slides there to fit more more pieces into this so uh the key",
    "start": "371720",
    "end": "377560"
  },
  {
    "text": "Point here is that when you build your architecture it needs to be amable for change so in other words you know if",
    "start": "377560",
    "end": "384160"
  },
  {
    "text": "there is a new technology that's born all of these new technologies are born to solve specific problems that we're seeing how does it fit into your",
    "start": "384160",
    "end": "390639"
  },
  {
    "text": "architecture if you have to redo every single time every two years the landscape changes right so that's",
    "start": "390639",
    "end": "396120"
  },
  {
    "text": "something that I factored into some of the design patterns that I'm going to be suggesting in the course of the talk and",
    "start": "396120",
    "end": "402440"
  },
  {
    "text": "um so you know this is sort of the question that most people have when they",
    "start": "402440",
    "end": "407880"
  },
  {
    "text": "call a Solutions architect for help you know hey is there a reference architecture what tool should I use how",
    "start": "407880",
    "end": "414919"
  },
  {
    "text": "and more importantly why uh we don't tend to visit why in many cases I think we should get started there and",
    "start": "414919",
    "end": "420599"
  },
  {
    "text": "explaining why then the what and how kind of falls into place I'm going to try to touch on some wise uh which I",
    "start": "420599",
    "end": "427160"
  },
  {
    "text": "have some visibility into this as I was Building Services so I'm going to try to lay out in terms of why it makes sense",
    "start": "427160",
    "end": "432800"
  },
  {
    "text": "to use specific Technologies so before I get started I'm going to lay down some fundamental principles um you know these",
    "start": "432800",
    "end": "440400"
  },
  {
    "text": "principles have been tried and tested for a long time and they hold good if these promises are wrong then you know",
    "start": "440400",
    "end": "446720"
  },
  {
    "text": "my architecture doesn't won't work so but I you know I've seen this work for the last four and a half or five years",
    "start": "446720",
    "end": "452479"
  },
  {
    "text": "so I'm pretty confident of this first I think when we think about Big Data pipelines or building Big Data pipelines",
    "start": "452479",
    "end": "457960"
  },
  {
    "text": "we should be Building decoupled Systems so in other words if there is a producer and the consumer both have to go in",
    "start": "457960",
    "end": "463919"
  },
  {
    "text": "their own speed doing whatever they have to do and then putting a storage in between to decouple these systems allows",
    "start": "463919",
    "end": "470680"
  },
  {
    "text": "both of them to go at their own speed right when you L look at a big data pipeline it's typically you know sort of",
    "start": "470680",
    "end": "476479"
  },
  {
    "text": "that process repeats itself we'll see how during the course of the talk and you should be using the right tool for",
    "start": "476479",
    "end": "482400"
  },
  {
    "text": "the job and um and you know what that means is really you know you do have various access patterns and various",
    "start": "482400",
    "end": "488479"
  },
  {
    "text": "tools give you different access patterns you know marrying the two making the right match is pretty critical and uh",
    "start": "488479",
    "end": "494560"
  },
  {
    "text": "when we build services at AWS we typically build them to do a few functions extremely well at the lowest",
    "start": "494560",
    "end": "500599"
  },
  {
    "text": "cost typically what happens is when the cost goes off act it typically means that you're not using the right tool for",
    "start": "500599",
    "end": "506479"
  },
  {
    "text": "the job I'll I'll go through an example as to how to you know how that how that shows up be ready for a quest so and",
    "start": "506479",
    "end": "513080"
  },
  {
    "text": "using Lambda architecture principles I'm not talking about the product AWS Lambda I'm talking about the Lambda",
    "start": "513080",
    "end": "518440"
  },
  {
    "text": "architecture um which which is about actually building batch systems using",
    "start": "518440",
    "end": "524880"
  },
  {
    "text": "batch systems batch processing as well as real-time processing doing the balancing between throughput and latency",
    "start": "524880",
    "end": "530480"
  },
  {
    "text": "and answering your questions in terms of building batch views and realtime views and compositing your answers from batch",
    "start": "530480",
    "end": "536839"
  },
  {
    "text": "views and realtime views this has been tried and tested across many many many installations literally if you look at",
    "start": "536839",
    "end": "543519"
  },
  {
    "text": "any kind of a ad attech company serving let's say millions of requests per second under the covers their pipeline",
    "start": "543519",
    "end": "549440"
  },
  {
    "text": "is really actually a Lambda architecture pipeline you know compositing batch and realtime systems and serving these you",
    "start": "549440",
    "end": "556800"
  },
  {
    "text": "know workloads massive workloads if you will both massive throughput and massive massive scale and um you know leveraging",
    "start": "556800",
    "end": "564640"
  },
  {
    "text": "AWS Services I talked about customers building these systems in 3 weeks a single developer building the system in",
    "start": "564640",
    "end": "570560"
  },
  {
    "text": "about 3 weeks how is that possible I think that's possible because of managed Services you know when we use thing",
    "start": "570560",
    "end": "576720"
  },
  {
    "text": "services such as Amazon Dynamo DB for no SQL or S3 or Kinesis you know you don't",
    "start": "576720",
    "end": "582120"
  },
  {
    "text": "have to deal with managing clusters you know maintaining software Etc day one you create your table or you create your",
    "start": "582120",
    "end": "588320"
  },
  {
    "text": "stream you put data into this and you get data out of this I mean there goes you know probably around 6 months worth",
    "start": "588320",
    "end": "593519"
  },
  {
    "text": "of work uh that you would have done you know managing and getting the cluster ready uh for for Building Systems last",
    "start": "593519",
    "end": "599800"
  },
  {
    "text": "but not the least I firmly believe Big Data you know should not be equal to Big cost um and uh that's a fundamental",
    "start": "599800",
    "end": "606720"
  },
  {
    "text": "premise of some of the architecture patterns I'm going to lay out so let's simplify big data",
    "start": "606720",
    "end": "614040"
  },
  {
    "text": "processing the more pipelines I build more big data processing looks",
    "start": "614839",
    "end": "620160"
  },
  {
    "text": "like this it looks like a pipeline with data coming in one side and answer is going up from the other side and um",
    "start": "620160",
    "end": "627240"
  },
  {
    "text": "there's multiple stages in the pipeline you know typical stages are ingest or collect I'm going to use these terms",
    "start": "627240",
    "end": "633279"
  },
  {
    "text": "interchangeably store and after that it's processed or analyze and consume or",
    "start": "633279",
    "end": "638560"
  },
  {
    "text": "Vis visualize you know those are the typical stages again depending upon what you do these stages may be slightly",
    "start": "638560",
    "end": "643639"
  },
  {
    "text": "different and uh and also what I see is the idea of store and process kind of",
    "start": "643639",
    "end": "648839"
  },
  {
    "text": "fundamentally gets repeated itself there is a cyclical process there and this process happens many times around and",
    "start": "648839",
    "end": "655120"
  },
  {
    "text": "why does it happen many times around to actually satisfy your time to answer there's a whole idea of time to answer",
    "start": "655120",
    "end": "660440"
  },
  {
    "text": "between the data coming in and you getting answers and uh you know there's certain throughput that you expect these",
    "start": "660440",
    "end": "666240"
  },
  {
    "text": "pipelines to operate at and obviously there's a bottom line which is the cost you know this needs to not break the",
    "start": "666240",
    "end": "672279"
  },
  {
    "text": "bank right um so that's ESS that's that's essentially it and um so now",
    "start": "672279",
    "end": "678240"
  },
  {
    "text": "let's get into each stage and figure out what's going on in each stage and um so",
    "start": "678240",
    "end": "683639"
  },
  {
    "text": "in terms of data collection you know whatever is your stack that is actually feeding the data I see few data patterns",
    "start": "683639",
    "end": "690560"
  },
  {
    "text": "here um typically you're either dealing with transactional data what I call as transactional data which looks like",
    "start": "690560",
    "end": "696200"
  },
  {
    "text": "you're talking to a database you know the client you know and an application server talking to a database you're doing probably tens or thousands or",
    "start": "696200",
    "end": "702639"
  },
  {
    "text": "millions of reads and writes per second right you know small data sets moving really fast back and forth and uh as you",
    "start": "702639",
    "end": "709680"
  },
  {
    "text": "go down you know then you have logging Frameworks that send you know log collection pieces that send larger",
    "start": "709680",
    "end": "716320"
  },
  {
    "text": "amounts of data this could be megabytes of data that are accumulated in machines and then upload it to some endpoint and",
    "start": "716320",
    "end": "723880"
  },
  {
    "text": "most recently we're seeing stream processing Technologies whereas rather than sending all these logs in in one",
    "start": "723880",
    "end": "730480"
  },
  {
    "text": "file you just send individual brackets as the individual brackets are being born you know for example if somebody is",
    "start": "730480",
    "end": "735680"
  },
  {
    "text": "in in a you know if you're thinking about amazon.com as people are buying things on amazon.com we capture the",
    "start": "735680",
    "end": "741120"
  },
  {
    "text": "clickstream rather than actually packaging this clickstream each application server packaging this clickstream and sending this and",
    "start": "741120",
    "end": "746600"
  },
  {
    "text": "uploading this you know if you actually send the clicks you can you can see things like well you know where did this",
    "start": "746600",
    "end": "752680"
  },
  {
    "text": "person abandon the cart what were doing just before they abandon the cart or buy the product you know what was the kind of the process that was going on or what",
    "start": "752680",
    "end": "759399"
  },
  {
    "text": "was mentally going on you know um on your customer's mind as you're doing we can pretty much do all those guesses so",
    "start": "759399",
    "end": "764560"
  },
  {
    "text": "that's why a lot of workloads are moving from batch to real time I also introduced uh a search data type you",
    "start": "764560",
    "end": "771279"
  },
  {
    "text": "know search is getting pretty popular the El stack elk elastic elastic search",
    "start": "771279",
    "end": "776920"
  },
  {
    "text": "log stash and kibana is very popular and in fact we launched a service you know managed service called Amazon elastic",
    "start": "776920",
    "end": "782600"
  },
  {
    "text": "search service um that is CED to handling search data I should have added one more category called",
    "start": "782600",
    "end": "790800"
  },
  {
    "text": "snowball so I you know we introduced snowball so UPS would be the mechanism",
    "start": "790800",
    "end": "796040"
  },
  {
    "text": "that that moves the snowball but uh you know probably next year I'll add snowball over there and then maybe right",
    "start": "796040",
    "end": "801240"
  },
  {
    "text": "on top of uh you know our somewhere around S3 uh but even if you think about Snowball the data is really uh going",
    "start": "801240",
    "end": "808079"
  },
  {
    "text": "into the file system in this case it's going to be S3 right uh so in terms of a",
    "start": "808079",
    "end": "814360"
  },
  {
    "text": "store let's go bottom up you know if you're actually capturing streaming data uh what type of store should you use um",
    "start": "814360",
    "end": "823160"
  },
  {
    "text": "so these are some of the manag services available on AWS for actually dealing with streaming data Amazon Kinesis which",
    "start": "823160",
    "end": "829519"
  },
  {
    "text": "is a managed service for for dealing with stream storage and stream processing and uh Dynamo DB streams",
    "start": "829519",
    "end": "836519"
  },
  {
    "text": "which was introduced recently also can be used for stream processing uh I'll kind of contrast these Services as I go",
    "start": "836519",
    "end": "842920"
  },
  {
    "text": "along and uh sqs and SNS simple simple Q service and SNS can also be used for",
    "start": "842920",
    "end": "849320"
  },
  {
    "text": "managing streams but will actually compare and contrast you know what what they what kind of problems that they're",
    "start": "849320",
    "end": "855320"
  },
  {
    "text": "supposed to solve in terms of the unmanaged solutions Apache Kafka is very very popular and um and let's contrast",
    "start": "855320",
    "end": "863800"
  },
  {
    "text": "these Technologies so before we do that uh what don't we explore wi stream storage",
    "start": "863800",
    "end": "869920"
  },
  {
    "text": "stream storage does a few functions first it decouples producers from consumers you know in this case I've",
    "start": "869920",
    "end": "875639"
  },
  {
    "text": "represented producers you know there there's producers one through n starting from Red through Violet on the left side",
    "start": "875639",
    "end": "881360"
  },
  {
    "text": "and the consumers there's two applications consumer one and consumer 2 so the reason for producers to write to",
    "start": "881360",
    "end": "887959"
  },
  {
    "text": "a stream storage is the decoupling piece that they bring in right and then it",
    "start": "887959",
    "end": "893199"
  },
  {
    "text": "also persist so the stream storage gives you a persistent buffer where let's assume",
    "start": "893199",
    "end": "900040"
  },
  {
    "text": "we're dealing with sensors or iot Internet of think gateways Those sensors",
    "start": "900040",
    "end": "905440"
  },
  {
    "text": "and gateways can pretty much hand off that hot potato to an intermediate storage Seer and then move on because",
    "start": "905440",
    "end": "912040"
  },
  {
    "text": "you often times they don't have the necessary memory or this to actually accumulate these messages so third they",
    "start": "912040",
    "end": "920680"
  },
  {
    "text": "collect multiple streams you may have a million devices writing to an endpoint",
    "start": "920680",
    "end": "925959"
  },
  {
    "text": "and uh so the decoupled producers from consumers so the producer producers can actually all these million producers can really log their data into a stream um",
    "start": "925959",
    "end": "934399"
  },
  {
    "text": "or whatever construct for example kka calls it a topic uh Kinesis calls it a",
    "start": "934399",
    "end": "939440"
  },
  {
    "text": "stream and Dynamo DB calls it a table these abstractions are the same there are end points that all these producers",
    "start": "939440",
    "end": "945279"
  },
  {
    "text": "write to and when these producers write there you have an option of specifying",
    "start": "945279",
    "end": "950480"
  },
  {
    "text": "some piece of your data is the key uh what does that do we'll go over this in a moment so basically it produces before",
    "start": "950480",
    "end": "957519"
  },
  {
    "text": "we get there um another property that the stream storage allows you to do is it preserves client ordering what that",
    "start": "957519",
    "end": "963880"
  },
  {
    "text": "means is if the producer one is sending packets one 2 3 and four the consumer is",
    "start": "963880",
    "end": "969519"
  },
  {
    "text": "guaranteed to receive the packets 1 2 3 and four in the same sequence the producer sent it and which is a pretty",
    "start": "969519",
    "end": "975319"
  },
  {
    "text": "important property um of of the stream storage and that's one of the primary reasons uh in some scenarios need stream",
    "start": "975319",
    "end": "982440"
  },
  {
    "text": "storage and the other piece is really streaming map produce what that really means is if you're building an",
    "start": "982440",
    "end": "988360"
  },
  {
    "text": "application that is going to answer a question that says give me the top you know what happened to what is the",
    "start": "988360",
    "end": "994480"
  },
  {
    "text": "sequence of packets that producer once sent and give me the maximum minimum on the average value let's assume if if the",
    "start": "994480",
    "end": "1000279"
  },
  {
    "text": "producer one is really sending pressure or temperature you want to find out what the maximum temperature is or average temperates you want to write an",
    "start": "1000279",
    "end": "1006680"
  },
  {
    "text": "application that computes these kind of things so the Frameworks that go along with these Services allow you to do",
    "start": "1006680",
    "end": "1013319"
  },
  {
    "text": "things like you know finding out the max Min average or a 1 minute metric or a 10-minute metric or whatever uh you wish",
    "start": "1013319",
    "end": "1020839"
  },
  {
    "text": "so that property is possible because all of these Frameworks latch on a single thread to a specific you know partition",
    "start": "1020839",
    "end": "1027520"
  },
  {
    "text": "or A Shard and that that aspect is guaranteed so that thread is guaranteed to get all the inputs produced by a",
    "start": "1027520",
    "end": "1033880"
  },
  {
    "text": "producer one and uh so such computations are possible um and then last but not",
    "start": "1033880",
    "end": "1040120"
  },
  {
    "text": "the least um you know if you an IT manager or or a CEO you want marious teams to run independently let's assume",
    "start": "1040120",
    "end": "1047438"
  },
  {
    "text": "clickstream data is coming into we have multiple teams actually looking at the clickstream data you want team",
    "start": "1047439",
    "end": "1052440"
  },
  {
    "text": "one to take the clickstream data and process this and do whatever they want at their own speed not wait on team two",
    "start": "1052440",
    "end": "1058039"
  },
  {
    "text": "to actually write the code and then pass on the output to them so in other words you can have independent teams",
    "start": "1058039",
    "end": "1064160"
  },
  {
    "text": "processing the data not only it's a technological advantage it's also a time to Market Advantage so you can build parallel applications that can process",
    "start": "1064160",
    "end": "1070960"
  },
  {
    "text": "this data and simultaneously at their own speed and have their own time to Market if you will uh so those are the",
    "start": "1070960",
    "end": "1077679"
  },
  {
    "text": "some of the advantages that stream storage provides now what about q and",
    "start": "1077679",
    "end": "1083120"
  },
  {
    "text": "pubsub Q and pubsub also have the first three characteristics are the same uh in",
    "start": "1083400",
    "end": "1089559"
  },
  {
    "text": "terms of decoupling producers and consumers and uh persistent buffer and being having the ability to collect",
    "start": "1089559",
    "end": "1095919"
  },
  {
    "text": "multiple streams they're the same but they don't have any client ordering and there's no parallel consumption possible",
    "start": "1095919",
    "end": "1102960"
  },
  {
    "text": "and then unless there's one exception to that which is if you use Simple notification service and if the",
    "start": "1102960",
    "end": "1108159"
  },
  {
    "text": "subscribers are multiple cues potentially the SNS can paralyze this into multiple multiple cues and uh and",
    "start": "1108159",
    "end": "1115760"
  },
  {
    "text": "also there's no streaming there's no notion of streaming map reduced because literally these most in most of the",
    "start": "1115760",
    "end": "1120919"
  },
  {
    "text": "cases these become decoupling mechanisms um so this question often comes up in my design reviews I thought I'll just add",
    "start": "1120919",
    "end": "1126799"
  },
  {
    "text": "just for just for just for comparison here now what I've done in this slide is",
    "start": "1126799",
    "end": "1132400"
  },
  {
    "text": "to actually put down all these Technologies and I've come up with a with a criteria for measuring these Tech",
    "start": "1132400",
    "end": "1138760"
  },
  {
    "text": "Technologies I thought I wanted to share this with you so you can when you evaluate these Technologies you can think on these Dimensions maybe I you",
    "start": "1138760",
    "end": "1145159"
  },
  {
    "text": "know you can maybe add other dimensions to it but these are the key dimensions in my opinion for example line one says",
    "start": "1145159",
    "end": "1150679"
  },
  {
    "text": "which services are managed you know yes or no whether ordering you know does the there's the specific service support",
    "start": "1150679",
    "end": "1156880"
  },
  {
    "text": "ordering guarantee in the case of Kinesis Dynamo DB streams and kofka there's an ordering guarantee whereas in",
    "start": "1156880",
    "end": "1162120"
  },
  {
    "text": "the case of sqs and SNS there's no ordering guarantee and then the delivery let's assume you write to a to to a",
    "start": "1162120",
    "end": "1168919"
  },
  {
    "text": "stream or a table um when you read the data back when you consume it you know",
    "start": "1168919",
    "end": "1175240"
  },
  {
    "text": "is the delivery at least once or you know exactly once right so what happens",
    "start": "1175240",
    "end": "1180919"
  },
  {
    "text": "in normal circumstances you get exactly once semantics under Edge conditions",
    "start": "1180919",
    "end": "1186440"
  },
  {
    "text": "some of these Technologies you know can give the same piece of data twice suppose you're building a build you're",
    "start": "1186440",
    "end": "1191960"
  },
  {
    "text": "you're building a building system you don't want to build your customer twice so you may want to think of dding uh",
    "start": "1191960",
    "end": "1197440"
  },
  {
    "text": "when customers get double bu they they lose they lose confidence and trust in you it's pretty important for you to think about these Primitives so that you",
    "start": "1197440",
    "end": "1204799"
  },
  {
    "text": "can make the right you know um you can build the right systems with the right",
    "start": "1204799",
    "end": "1209880"
  },
  {
    "text": "guarantees and uh in terms of the lifetime when you put data into these systems how long does the data stay and",
    "start": "1209880",
    "end": "1216440"
  },
  {
    "text": "before it goes away so in the case of Kinesis it's 7 days and in the case of",
    "start": "1216440",
    "end": "1221880"
  },
  {
    "text": "Dynamo DB it's 24 hours and in the case of sqs andsn is 14 days and Kafka is",
    "start": "1221880",
    "end": "1227320"
  },
  {
    "text": "configurable you know for example um Netflix is doing a talk they they're using kovka there and then they have a",
    "start": "1227320",
    "end": "1234919"
  },
  {
    "text": "couple of priorities of systems you know there some high priority systems where they they keep the data for 24 hours for",
    "start": "1234919",
    "end": "1240640"
  },
  {
    "text": "lower priority systems they keep it for 12 hours so such configurations are possible in Kafka for",
    "start": "1240640",
    "end": "1246120"
  },
  {
    "text": "example uh so in terms of the throughput literally you know all Technologies you can scale scale to any level that you",
    "start": "1246120",
    "end": "1253080"
  },
  {
    "text": "want and then these are intended for Big Data consumption there's no limits on how much of data that you can put into",
    "start": "1253080",
    "end": "1259480"
  },
  {
    "text": "these systems you literally have to scale the table or scale the scale the stream by adding more shots Etc but you",
    "start": "1259480",
    "end": "1266159"
  },
  {
    "text": "can scale them to any level you want uh in terms of the map reduce um other than",
    "start": "1266159",
    "end": "1271640"
  },
  {
    "text": "sqs and SNS uh all allow you to do streaming map reduce so in terms of the",
    "start": "1271640",
    "end": "1277840"
  },
  {
    "text": "record sizes 1 Megabyte is the maximum record size in the case of kinis whereas it is",
    "start": "1277840",
    "end": "1283799"
  },
  {
    "text": "400 kiloby for Dynamo DB and then it's 256 kiloby for Qs SNS and it's",
    "start": "1283799",
    "end": "1289559"
  },
  {
    "text": "configurable in C Cur and in terms of the cost that's a pretty important line um you know typically when you are",
    "start": "1289559",
    "end": "1295480"
  },
  {
    "text": "confronted with these kinds of decisions it is good to actually go through an exercise of doing the cost what I did in",
    "start": "1295480",
    "end": "1300679"
  },
  {
    "text": "my case was you know for example you you go to the you know page for Kinesis",
    "start": "1300679",
    "end": "1306559"
  },
  {
    "text": "pricing and typically they give a pricing example you basically run the example through all of these scenarios",
    "start": "1306559",
    "end": "1312200"
  },
  {
    "text": "right the example there is you know 100 puts per second and each payload is I think 25 or 35k if you actually take",
    "start": "1312200",
    "end": "1318720"
  },
  {
    "text": "that data point and do the computation you'll see that the Kinesis price is very fairly low for that kind of a",
    "start": "1318720",
    "end": "1323760"
  },
  {
    "text": "scenario in the case of Dynamo DB it was higher because in data doesn't go away in Dynamo DB it is it is a table storage",
    "start": "1323760",
    "end": "1330840"
  },
  {
    "text": "mechanism plus a stream so it's higher but if you need that functionality you",
    "start": "1330840",
    "end": "1336360"
  },
  {
    "text": "you want to use that technology um so in the case of sqs it's slightly higher um",
    "start": "1336360",
    "end": "1342080"
  },
  {
    "text": "than than Kinesis and Kafka I presume I could not compute the actual cost it should be the same but the the challenge",
    "start": "1342080",
    "end": "1348039"
  },
  {
    "text": "there is I don't know how to factor out the admin cost you know how much does somebody how much of time that somebody spend to build these clusters maintain",
    "start": "1348039",
    "end": "1354520"
  },
  {
    "text": "these clusters that comes in but in terms of the machine cost it should be fairly low to to Reg up a you know CA",
    "start": "1354520",
    "end": "1360840"
  },
  {
    "text": "cluster as well and uh now moving into the next phase which is the which is the file storage what what file storage",
    "start": "1360840",
    "end": "1367760"
  },
  {
    "text": "technology should you use for storing file data and um I think the overwhelming answer is",
    "start": "1367760",
    "end": "1375120"
  },
  {
    "text": "Amazon S3 so why is Amazon three so important are critical for Big Data so",
    "start": "1375120",
    "end": "1381960"
  },
  {
    "text": "it basically decouples storage from processing you a lot of these big files",
    "start": "1381960",
    "end": "1388120"
  },
  {
    "text": "were actually stored in hdfs before so if you if you're using you know Flume or flu and D chances are you may be writing",
    "start": "1388120",
    "end": "1394919"
  },
  {
    "text": "to hdfs the problem with that is actually you need to run a cluster you need to keep a cluster alive all the time and keep it running and keep",
    "start": "1394919",
    "end": "1401480"
  },
  {
    "text": "feeding it whereas if you write to S3 you don't have to actually have a cluster running so you can literally",
    "start": "1401480",
    "end": "1407080"
  },
  {
    "text": "shut down your cluster if you have to do processing you you turn on a cluster you process your data you shut down the cluster and then the data stays it's",
    "start": "1407080",
    "end": "1414159"
  },
  {
    "text": "designed for Lev 9's durability so there is very unlikely that you will ever lose anything that you put in S3 and um it",
    "start": "1414159",
    "end": "1420600"
  },
  {
    "text": "has unlimited objects you can put any number of objects in S3 the aggregate bandwidth that S3 gives is there's no",
    "start": "1420600",
    "end": "1426640"
  },
  {
    "text": "limits on aggregate bandwidth if you have multiple clients accessing S3 you can do any number of reads and writes",
    "start": "1426640",
    "end": "1431960"
  },
  {
    "text": "per second you need to be careful with naming the files properly so you don't get into any kind of hot keys or partition scenarios as long as you",
    "start": "1431960",
    "end": "1438039"
  },
  {
    "text": "confirm to that best practice you can put as much of data and get as much of data out of S3 um and then you don't",
    "start": "1438039",
    "end": "1444200"
  },
  {
    "text": "have to have a cluster running also when you're doing big data processing the ec2",
    "start": "1444200",
    "end": "1449720"
  },
  {
    "text": "gives you the spot Market when you bid you you throw in a bid price that you can bid for a instances typically these",
    "start": "1449720",
    "end": "1454880"
  },
  {
    "text": "bit prices or spot instances are 50% the cost of the regular you know on demand instances so if you're using S3 as your",
    "start": "1454880",
    "end": "1461200"
  },
  {
    "text": "storage mechanism you know for getting a job done you can bid at half the price and get the instances in some cases",
    "start": "1461200",
    "end": "1466880"
  },
  {
    "text": "customers bid more than the price Because the actual price that they give them is half the price so that they're guaranteed to get some of these machines",
    "start": "1466880",
    "end": "1472720"
  },
  {
    "text": "so I think so such such such things are possible if you use S3 so my recommendation would be you know use S3",
    "start": "1472720",
    "end": "1479919"
  },
  {
    "text": "and you need to really find a reason why that won't work before you use something else and um so we also recently",
    "start": "1479919",
    "end": "1487760"
  },
  {
    "text": "introduced um various tiered storage options for example um standard S3",
    "start": "1487760",
    "end": "1494279"
  },
  {
    "text": "standard and we also introduced a new tiered storage option which is infrequent access so if you designate",
    "start": "1494279",
    "end": "1499399"
  },
  {
    "text": "some object as infrequent you get charged much less if you really infrequently use this and you can",
    "start": "1499399",
    "end": "1504799"
  },
  {
    "text": "actually set a policy in S3 that says after 6 months move all these objects with this prefix from one storage option",
    "start": "1504799",
    "end": "1511000"
  },
  {
    "text": "to another storage option it could be from standard to IIA standard IIA or it could be from standard to Glacier for",
    "start": "1511000",
    "end": "1518080"
  },
  {
    "text": "example and um so what about hdfs and um and and Glacier typically",
    "start": "1518080",
    "end": "1525919"
  },
  {
    "text": "hdfs these days is used for storing you know keeping intermediate files if you have a you know a batch processing job",
    "start": "1525919",
    "end": "1532960"
  },
  {
    "text": "that has you know multiple stages and and the output of one stage is keep being passed on to the second stage many",
    "start": "1532960",
    "end": "1539039"
  },
  {
    "text": "customers use hdfs for storing the intermediates intermediate files and then passing along um and then that's",
    "start": "1539039",
    "end": "1545039"
  },
  {
    "text": "you know for dealing with your heart data uh I think of this as a heart cache you know for your pipeline for your",
    "start": "1545039",
    "end": "1550640"
  },
  {
    "text": "processing Pipeline and what about Amazon Glacier again Glacier in relation you know with respect to the cost S3 is",
    "start": "1550640",
    "end": "1557520"
  },
  {
    "text": "3 cents per G per month Glacier is you know 7/10 of a penny per gigabyte per",
    "start": "1557520",
    "end": "1562559"
  },
  {
    "text": "month and then so it's significantly cheaper as well even though Amazon S3 is really cheap um and so you can also",
    "start": "1562559",
    "end": "1570399"
  },
  {
    "text": "again set a policy to to move the data between the various tiers and uh moving on to the next stage",
    "start": "1570399",
    "end": "1577200"
  },
  {
    "text": "which is the database storage what kind of database storage technology should you use uh for storing search and uh",
    "start": "1577200",
    "end": "1584600"
  },
  {
    "text": "database data uh well well this is an anti pattern for the",
    "start": "1584600",
    "end": "1591360"
  },
  {
    "text": "cloud I love I love swis Arm me knives so I figured I'll use that Paradigm here um they're pretty cool they have all the",
    "start": "1592320",
    "end": "1598360"
  },
  {
    "text": "tools you need and they can pretty much do anything you want the only problem is if you need a big screwdriver for for",
    "start": "1598360",
    "end": "1605240"
  },
  {
    "text": "fixing something you need to probably get a big Swiss army knife now one of this about a few years ago when I C this",
    "start": "1605240",
    "end": "1611480"
  },
  {
    "text": "picture from amazon.com it was about $800 and that price seems to be going up and up right so these things are cool",
    "start": "1611480",
    "end": "1619039"
  },
  {
    "text": "but you know if you need to scale one specific Dimension it's hard to do for example if you used Dynamo DB for the",
    "start": "1619039",
    "end": "1625360"
  },
  {
    "text": "same use case if you're doing a million rights per second if you're doing 10 reads per second when you provision a table you can simply say I want to do a",
    "start": "1625360",
    "end": "1631399"
  },
  {
    "text": "million rights per second and 10 reads per second you pay for what what you provision whereas if you use a relational database you really have to",
    "start": "1631399",
    "end": "1638159"
  },
  {
    "text": "you know get read capacity as part of the rights you may not be able to slice and dice this and get just what you want",
    "start": "1638159",
    "end": "1644640"
  },
  {
    "text": "uh so this is the anti pattern um for the database here so what is the right pattern so the right pattern would be",
    "start": "1644640",
    "end": "1650960"
  },
  {
    "text": "thinking your database tier as comprising of SQL and no SQL and really complimenting that with cash and search",
    "start": "1650960",
    "end": "1658919"
  },
  {
    "text": "they are amazing nosql and SQL Technologies I included you know Cassandra hbas mongod DB as well",
    "start": "1658919",
    "end": "1666240"
  },
  {
    "text": "as you know in the SQL we have Amazon Aurora which Andy talked about this morning you know my SQL postc crust",
    "start": "1666240",
    "end": "1671880"
  },
  {
    "text": "Oracle and SQL Server uh RDS runs all of these engines as well if you want to",
    "start": "1671880",
    "end": "1677080"
  },
  {
    "text": "manage solution you can run this yourself on ec2 as well and um and again",
    "start": "1677080",
    "end": "1682440"
  },
  {
    "text": "on the search we have Amazon elastic search service and the cloud search service um now often I get asked the",
    "start": "1682440",
    "end": "1688919"
  },
  {
    "text": "question like you suggested this and how do you keep all these things in sync right and um now this is one of the",
    "start": "1688919",
    "end": "1696960"
  },
  {
    "text": "architecture that's kind of evolving for example you can use an",
    "start": "1696960",
    "end": "1702360"
  },
  {
    "text": "Amazon Dynamo DB stream and have a stream processing application using AWS Lambda service or or a KCl service to",
    "start": "1702360",
    "end": "1710360"
  },
  {
    "text": "actually capture the data in this case I'm assuming I'm storing actually the database data in a nosql in this case",
    "start": "1710360",
    "end": "1715399"
  },
  {
    "text": "Dynamo DB and then I capture the stream data and apply those changes to my search engine as well as my caching",
    "start": "1715399",
    "end": "1721960"
  },
  {
    "text": "engine this way your application can look in the cache uh if there's the cache Miss and then update the database",
    "start": "1721960",
    "end": "1728960"
  },
  {
    "text": "and the cache gets propagated from from the update stream this would be a predominant pattern you know that's that",
    "start": "1728960",
    "end": "1735480"
  },
  {
    "text": "that will come into being I see already customers starting to do this pattern I thought I I would lay this out for you",
    "start": "1735480",
    "end": "1741279"
  },
  {
    "text": "and uh the key Point here is that your search and the and the cache data are going to be a little bit stale and the",
    "start": "1741279",
    "end": "1747480"
  },
  {
    "text": "staleness is usually in the order of a few maybe tens of milliseconds and that's usually okay for most most",
    "start": "1747480",
    "end": "1753399"
  },
  {
    "text": "applications um and then if you if it's not okay some cases what people do is they actually check in both places uh to",
    "start": "1753399",
    "end": "1759840"
  },
  {
    "text": "to to see if the document exists in the nosql store to move forward and um so",
    "start": "1759840",
    "end": "1766559"
  },
  {
    "text": "again how do you how do you pick the right technology amongst all these four different",
    "start": "1766559",
    "end": "1772120"
  },
  {
    "text": "pieces it comes down to four dimensions for me you know data structure access pattern you know and the database and",
    "start": "1772120",
    "end": "1779480"
  },
  {
    "text": "the data and access characteristics and the cost you know those are the four criterias typically I use to pick the right storage choice and um I think the",
    "start": "1779480",
    "end": "1788200"
  },
  {
    "text": "second point I want to emphasize a little bit because in a way after I look through all these mult building multiple",
    "start": "1788200",
    "end": "1794799"
  },
  {
    "text": "Big Data Systems the one thing that I want to drive home is you know storing the data in the form that you access it",
    "start": "1794799",
    "end": "1801159"
  },
  {
    "text": "eventually is the secret behind you know building Big Data Systems the moment you",
    "start": "1801159",
    "end": "1806600"
  },
  {
    "text": "do that most of your pro Downstream problems are solved you can look up you know if you if you are doing a key lookup as long as you can store this as",
    "start": "1806600",
    "end": "1812760"
  },
  {
    "text": "a key value type you can look it up any number of times whether it's million or 10 depends upon you provisioning the",
    "start": "1812760",
    "end": "1818320"
  },
  {
    "text": "right throughput capacity on your backend system that's very easily doable so I'll leave you with that secret but",
    "start": "1818320",
    "end": "1824679"
  },
  {
    "text": "moving forward so if your data access pattern is you know key value you potentially you could use caches or no",
    "start": "1824679",
    "end": "1829760"
  },
  {
    "text": "SQL if it's a simple one to many or many to many relationship you should use no SQL and if it's a cross table if you",
    "start": "1829760",
    "end": "1836000"
  },
  {
    "text": "have cross table joins and massive transactions obviously SQL uh can do that and uh if you have fating and",
    "start": "1836000",
    "end": "1843120"
  },
  {
    "text": "search if you go to amazon.com on the left side we show you you know all these products Prime eligible are these you",
    "start": "1843120",
    "end": "1848360"
  },
  {
    "text": "know why you can actually facet by you know manufacturer facet by you know specific um property such as if this is",
    "start": "1848360",
    "end": "1855639"
  },
  {
    "text": "prime eligible or not so if you want fast in and search you know a search service is the obviously right choice in",
    "start": "1855639",
    "end": "1861960"
  },
  {
    "text": "terms of data structure if you have a fixed schema using SQL or no SQL makes sense Json these days most nosql",
    "start": "1861960",
    "end": "1868320"
  },
  {
    "text": "databases support Json as a first class data type you know clearly using nosql or search there makes a lot of sense and",
    "start": "1868320",
    "end": "1875080"
  },
  {
    "text": "then again for key value its caches are no SQL right um this is you know when I",
    "start": "1875080",
    "end": "1881760"
  },
  {
    "text": "think about the access patterns and data uh I often think about a temperature",
    "start": "1881760",
    "end": "1887399"
  },
  {
    "text": "gauge and uh in terms of hot data warm data",
    "start": "1887399",
    "end": "1892519"
  },
  {
    "text": "and the cold data right so typically these are some of the characteristics of the hot data when you're dealing with you know think of you know data in your",
    "start": "1892519",
    "end": "1899639"
  },
  {
    "text": "cache data in an SSD and data in a spinning dis for example corresponding to hot warm and cold data you know",
    "start": "1899639",
    "end": "1906320"
  },
  {
    "text": "typically the hot data the data set size is small you're doing a very large number of request per second the",
    "start": "1906320",
    "end": "1913039"
  },
  {
    "text": "latencies that your demand of hot data is very low in the order of milliseconds and so on As you move towards the right",
    "start": "1913039",
    "end": "1919080"
  },
  {
    "text": "the data set sizes become bigger the latencies you can wait to get some data",
    "start": "1919080",
    "end": "1924519"
  },
  {
    "text": "you know from because the data sizes are bigger and then the request rate tends to be lower but the payload seems to be",
    "start": "1924519",
    "end": "1930279"
  },
  {
    "text": "much bigger and then the cost per gigabyte tends to go from you know anywhere from dollars per gigabyte to",
    "start": "1930279",
    "end": "1936519"
  },
  {
    "text": "per month to you know maybe tens of cents or per per gigabyte per month to",
    "start": "1936519",
    "end": "1942120"
  },
  {
    "text": "penny per gigabyte per month for example and then in terms of the mental map uh this is sort of the mental MIP I carry",
    "start": "1942120",
    "end": "1949039"
  },
  {
    "text": "around in my head um I try to sometimes it's hard to actually draw a picture of what's in your head um so in this case",
    "start": "1949039",
    "end": "1956080"
  },
  {
    "text": "what I've done is really you know on the left side there's a data structure which is sort of going from high at the bottom",
    "start": "1956080",
    "end": "1962320"
  },
  {
    "text": "to low at the top and then there's various attributes of request rate cost per gigabyte latency and data volume and",
    "start": "1962320",
    "end": "1968159"
  },
  {
    "text": "if you look at all these Services there's a little bit of an overlap between them but each one of them has a center of excellence let's say if you're",
    "start": "1968159",
    "end": "1974639"
  },
  {
    "text": "dealing with very hot data if you're doing tens of thousands of reest per second chances are you know some kind of",
    "start": "1974639",
    "end": "1980840"
  },
  {
    "text": "a cache in or no SQL would be the right choice if you're doing searches",
    "start": "1980840",
    "end": "1986159"
  },
  {
    "text": "somewhere it's in the middle you're dealing with really hard data sets with the with with the latency characteristics of a few milliseconds or",
    "start": "1986159",
    "end": "1992039"
  },
  {
    "text": "a second potentially something like a SQL or a search or no SQL may be the right thing to do as you go towards the",
    "start": "1992039",
    "end": "1999080"
  },
  {
    "text": "right uh Glacier if you put data in glacer when you when you ask it back uh you'll get it back in about 3.5 hours so",
    "start": "1999080",
    "end": "2006639"
  },
  {
    "text": "so that's you know that's that's cold storage if you will right so to be more concrete what I did in the slide is to",
    "start": "2006639",
    "end": "2012799"
  },
  {
    "text": "actually pick specific services and then I've Associated all these various characteristics I I didn't",
    "start": "2012799",
    "end": "2019519"
  },
  {
    "text": "put actual numbers because those keep to be tends to be varying but actually I will walk through some of this for",
    "start": "2019519",
    "end": "2024559"
  },
  {
    "text": "example if you're looking at average latency if you put if you if you're actually putting the data in elastic elastic cache you know the latency would",
    "start": "2024559",
    "end": "2032279"
  },
  {
    "text": "be about a millisecond for Dynamo DB it'll be it'll be again a single- digit millisecond about three Mill you know",
    "start": "2032279",
    "end": "2037440"
  },
  {
    "text": "three 3 milliseconds for a put or a gap As you move into Aurora and in know RDS",
    "start": "2037440",
    "end": "2043440"
  },
  {
    "text": "or SQL in and search it may be from milliseconds to seconds and again if you put data in S3 maybe it's hundreds of",
    "start": "2043440",
    "end": "2049839"
  },
  {
    "text": "hundreds of milliseconds you know 100 or 200 milliseconds for a gigabyte of data is sort of normal and uh again Glacier",
    "start": "2049839",
    "end": "2056358"
  },
  {
    "text": "it will be probably hours to get the data back right so there is this is sort of the spectrum you know of sort of hot",
    "start": "2056359",
    "end": "2061919"
  },
  {
    "text": "data to cold data and what various Technologies can do I'm not going to go through each and every line here but I",
    "start": "2061919",
    "end": "2067118"
  },
  {
    "text": "want to leave this slide for you for a future reference so when you're choosing between these Technologies it's sort of good to know which region you're in and",
    "start": "2067119",
    "end": "2074679"
  },
  {
    "text": "then zero in on a specific technology for your use case and this has been very helpful for some you a lot of our",
    "start": "2074679",
    "end": "2080358"
  },
  {
    "text": "customers and then I keep updating this slide every year again you know this is not precise and these things keep",
    "start": "2080359",
    "end": "2087040"
  },
  {
    "text": "changing but as a designer it gives you a sense of what to look for and what kind of you know characteristics to look",
    "start": "2087040",
    "end": "2092398"
  },
  {
    "text": "for in various Services if you will and uh now is are you ready for a quest",
    "start": "2092399",
    "end": "2099320"
  },
  {
    "text": "so okay this is an email that a a developer at amazon.com sent me so",
    "start": "2099320",
    "end": "2106760"
  },
  {
    "text": "um the person is currently scoping out a project that will greatly increase the person's team's use of S3 hoping person",
    "start": "2107240",
    "end": "2114440"
  },
  {
    "text": "says hoping you could answer some questions the current iteration of design calls for many small files perhaps up to a billion during Peak the",
    "start": "2114440",
    "end": "2120960"
  },
  {
    "text": "total size would be in the order of 1.5 terabytes per month typically when I hear something like this I fire up an",
    "start": "2120960",
    "end": "2127079"
  },
  {
    "text": "Excel spread sheet or some kind of a spreadsheet and start plugging the numbers in when I plug the numbers in this is the way it looks like well the",
    "start": "2127079",
    "end": "2132400"
  },
  {
    "text": "person is trying to do a request rate of 300 rights per second the object size is about 2k and then you know totally per",
    "start": "2132400",
    "end": "2138720"
  },
  {
    "text": "month the person is going to store about 1.5 terabytes of data in terms of the number of objects per month it's going",
    "start": "2138720",
    "end": "2143880"
  },
  {
    "text": "to be 777 you know million objects per month this is a very tiny workload for Big Data but it's an interesting example",
    "start": "2143880",
    "end": "2150400"
  },
  {
    "text": "so how many of you think that we should be using Dynamo DB for this and how many think ask three Dynamo DB raise your",
    "start": "2150400",
    "end": "2155599"
  },
  {
    "text": "hands please okay I count like maybe about 10 S3 W lot more than S3 well I'm you know",
    "start": "2155599",
    "end": "2164880"
  },
  {
    "text": "one of you are going is going to lose right is that okay okay let's there's",
    "start": "2164880",
    "end": "2169920"
  },
  {
    "text": "this thing called Simple monthly calculator how many of you used this one it's a pretty interesting Tool uh it's",
    "start": "2169920",
    "end": "2176240"
  },
  {
    "text": "not perfect but it's it's pretty cool it it helps me a lot uh as an architect and",
    "start": "2176240",
    "end": "2181520"
  },
  {
    "text": "uh if you plug in those numbers it has various tabs for each services and then if you take that thing and plug it into",
    "start": "2181520",
    "end": "2186920"
  },
  {
    "text": "into the Dynamo DB page and S3 in this case it turns out that Dynamo DB is",
    "start": "2186920",
    "end": "2192160"
  },
  {
    "text": "going to cost $644 whereas S3 is going to cost $ 3,932 who said S3 folks I'm",
    "start": "2192160",
    "end": "2202000"
  },
  {
    "text": "sorry somebody's pointing to their friend in the N side I'm not sure how that's going to play out when they leave",
    "start": "2202000",
    "end": "2207240"
  },
  {
    "text": "this room so whenever I do a slide like this and showed it to the S3 you know",
    "start": "2207240",
    "end": "2212440"
  },
  {
    "text": "product manager the person was really upset right you're not actually pitching my product in the favorable set so I",
    "start": "2212440",
    "end": "2218160"
  },
  {
    "text": "figured I'll put a compensating scenario what I did in this case was you know scenario 2 I I made up a scenario two I",
    "start": "2218160",
    "end": "2225079"
  },
  {
    "text": "actually change the object size to 32 kilobytes right well it turns out S3 is the winner in this case for uh for for",
    "start": "2225079",
    "end": "2232240"
  },
  {
    "text": "for for that workload you know why actually if you look at the pricing details over there it turns out the",
    "start": "2232240",
    "end": "2237359"
  },
  {
    "text": "reason why the old price were where Dynamo was the winner is in along those",
    "start": "2237359",
    "end": "2243160"
  },
  {
    "text": "lines if you on the right side if you see uh the put of the list request costed",
    "start": "2243160",
    "end": "2248960"
  },
  {
    "text": "$3,888 in the case of S3 that's what actually threw this out of shape you know uh that's what made Dynamo win in a",
    "start": "2248960",
    "end": "2255960"
  },
  {
    "text": "way because S3 is priced in built for dealing with large number of files but a",
    "start": "2255960",
    "end": "2262800"
  },
  {
    "text": "little lower frequency in terms of the number of Rights per second for Dynamo DB Dynamo DB is designed to handle small workloads super fast right it really",
    "start": "2262800",
    "end": "2270640"
  },
  {
    "text": "allows small objects you can do you know millions or zillions of Rights per second and zillion is not a number but",
    "start": "2270640",
    "end": "2276960"
  },
  {
    "text": "just just a term so and um but then in the case of S3 it likes very large",
    "start": "2276960",
    "end": "2282040"
  },
  {
    "text": "objects you can do a few rights per second you know that's the normal usage pattern so when we build Services we the",
    "start": "2282040",
    "end": "2287480"
  },
  {
    "text": "pricing equation really works out to actually push you in the right direction so having this tool when I do design",
    "start": "2287480",
    "end": "2293000"
  },
  {
    "text": "reviews about 20 minutes into the thing I pass and I tell the customer let's do a cost computation let's see if you're",
    "start": "2293000",
    "end": "2298359"
  },
  {
    "text": "going the right direction usually it ends up ends up in one or two ways one the customer gives two thumbs up and says going the second thing they say",
    "start": "2298359",
    "end": "2305160"
  },
  {
    "text": "well let's stop right here right maybe I should redes design or I should change my requirements you know either one of",
    "start": "2305160",
    "end": "2310240"
  },
  {
    "text": "those happens both are good actually Solutions rather than finding out that you know something didn't work as you",
    "start": "2310240",
    "end": "2315760"
  },
  {
    "text": "anticipated or it broke the bank a little bit later on so let's go into the processor analyze stage so in the case",
    "start": "2315760",
    "end": "2322160"
  },
  {
    "text": "of processor analyze uh just a confession here I copied literally from",
    "start": "2322160",
    "end": "2327599"
  },
  {
    "text": "Wikipedia what what analysis meant because I wanted to validate what I was saying was right right so you know in a",
    "start": "2327599",
    "end": "2333720"
  },
  {
    "text": "short sense analysis really means you're shaping and slicing and you know slicing the data making it you",
    "start": "2333720",
    "end": "2341040"
  },
  {
    "text": "know kind of building or creating answers from your data you know shaping it modeling it cleansing it Etc all",
    "start": "2341040",
    "end": "2346920"
  },
  {
    "text": "those things are Loosely called analysis I didn't know whether to call this process or analyze so I'm going to call this analyze for now on but you know",
    "start": "2346920",
    "end": "2353160"
  },
  {
    "text": "think process as well so some of the examples are in know interactive SQL you know if you if you have a large body of",
    "start": "2353160",
    "end": "2358839"
  },
  {
    "text": "data of pedabytes you know if you want to run an interactive SQL uh if you want to actually fire up um some",
    "start": "2358839",
    "end": "2364280"
  },
  {
    "text": "visualization dashboard against this and process the data I'm going to call the interactive analytics kind of workload",
    "start": "2364280",
    "end": "2370160"
  },
  {
    "text": "and then obviously you have you know batch processing realtime analytics and machine learning as well as examples so",
    "start": "2370160",
    "end": "2376720"
  },
  {
    "text": "let's look at each one of these in the case of interactive analytics you're taking large amounts of data you know warm or cold data and you want to you",
    "start": "2376720",
    "end": "2383760"
  },
  {
    "text": "want the answers to come back in seconds so somebody is slicing and dicing the data in front of the dashboard you want you don't want them to wait for you know",
    "start": "2383760",
    "end": "2389880"
  },
  {
    "text": "five minutes or half hour right this data has to come back in a few seconds and um so that's interactive analytics",
    "start": "2389880",
    "end": "2396480"
  },
  {
    "text": "in a batch process you know we all have lived this you know basically running your hive job um or a",
    "start": "2396480",
    "end": "2402480"
  },
  {
    "text": "map Produce job to actually you know it it runs for hours or days and comes back",
    "start": "2402480",
    "end": "2407680"
  },
  {
    "text": "with a with a result uh that's batch processing you know daily weekly monthly reports are examples there and real time",
    "start": "2407680",
    "end": "2413680"
  },
  {
    "text": "analytics this is fairly new uh it takes small amount of hot data and you ask",
    "start": "2413680",
    "end": "2418760"
  },
  {
    "text": "questions like you know is was there is this a fraudulent trans transaction that's in flight or can you give me a",
    "start": "2418760",
    "end": "2425720"
  },
  {
    "text": "one minute metric of the specific Dimension you know what is my latency for the last one minute give me the a",
    "start": "2425720",
    "end": "2431359"
  },
  {
    "text": "Max men average or you know the 99th percentile so that that's sort of sort of the near real time you know when I'm",
    "start": "2431359",
    "end": "2438680"
  },
  {
    "text": "talking about real time here I'm talking about business real time now business real time in my mind is in the order of",
    "start": "2438680",
    "end": "2443839"
  },
  {
    "text": "maybe 250 milliseconds to a second something around there right for most of the customers you know they have been",
    "start": "2443839",
    "end": "2450800"
  },
  {
    "text": "doing bad jobs in about hours right anywhere in the realm of a minute or so",
    "start": "2450800",
    "end": "2457960"
  },
  {
    "text": "is reasonably close to real time for them you know for various kpis so I just want to set that up so if",
    "start": "2457960",
    "end": "2464400"
  },
  {
    "text": "you if you then we go to you know predictions via machine learning machine",
    "start": "2464400",
    "end": "2469920"
  },
  {
    "text": "learning gives computers the ability to learn without being actually programmed another words what you're trying to do is you're training the you're training",
    "start": "2469920",
    "end": "2477560"
  },
  {
    "text": "you're building a model and you're using some training data to build the model so",
    "start": "2477560",
    "end": "2482720"
  },
  {
    "text": "when later on when you ask a question such as is this a fraudulent transaction yes or no",
    "start": "2482720",
    "end": "2487800"
  },
  {
    "text": "and then the system is able to give you an answer yes or no and that can happen in real time but that can happen in a",
    "start": "2487800",
    "end": "2493280"
  },
  {
    "text": "batch mode right and then for example if you look at Amazon machine learning service we support both classification",
    "start": "2493280",
    "end": "2499000"
  },
  {
    "text": "and regression so you can you can you can ask questions like is this transaction fraud or not you know if a",
    "start": "2499000",
    "end": "2504160"
  },
  {
    "text": "customer is shopping your site this is a new customer you never seen them before you can ask the question whether what do",
    "start": "2504160",
    "end": "2509960"
  },
  {
    "text": "you think knowing that all the characteristics of the customer I have fed in and built a model is this a high",
    "start": "2509960",
    "end": "2515200"
  },
  {
    "text": "probability is there a high probability that this customer is going to be a high value customer for me you know and then",
    "start": "2515200",
    "end": "2521520"
  },
  {
    "text": "what could be the what could be the lifetime value of this customer in terms of maybe dollars per month or dollars per year such questions can be answered",
    "start": "2521520",
    "end": "2528680"
  },
  {
    "text": "by by predictive Predictive Analytics there's another one which is called supervised learning which is which is",
    "start": "2528680",
    "end": "2534200"
  },
  {
    "text": "clustering let's assume in Amazon we have various kinds of shoes if you want the system to automatically classify",
    "start": "2534200",
    "end": "2539480"
  },
  {
    "text": "based on the picture whether this is a sandal or whether this is a shoe the machines can do this on your behalf if",
    "start": "2539480",
    "end": "2544680"
  },
  {
    "text": "you have trained them with enough data they can actually do this classifications as various algorithms in",
    "start": "2544680",
    "end": "2549720"
  },
  {
    "text": "let's say spark ML and others that support these kinds of questions and answers and um so so what are the",
    "start": "2549720",
    "end": "2557839"
  },
  {
    "text": "analysis tools and Frameworks that you can use um for machine learning obviously mahoot spark ml or Amazon",
    "start": "2557839",
    "end": "2565440"
  },
  {
    "text": "machine Learning Works fairly well for interactive analytics Amazon red shift Presto Impala and Spark work fairly well",
    "start": "2565440",
    "end": "2572559"
  },
  {
    "text": "for batch processing again you can use classic map Produce High Peg or spark and for stream processing you could use",
    "start": "2572559",
    "end": "2579720"
  },
  {
    "text": "spark streaming or AWS Lambda or KCl and if you're doing batch analytics on on",
    "start": "2579720",
    "end": "2585559"
  },
  {
    "text": "streaming data you can use um emo Hive and pig uh what I've done on the right side is really actually stack up this",
    "start": "2585559",
    "end": "2592319"
  },
  {
    "text": "system so for example Presto Impala spark Hive and pig can be run on Amazon",
    "start": "2592319",
    "end": "2598720"
  },
  {
    "text": "elastic map ruce Amazon elastic map Ru is a managed service for running Big Data applications such as you know spark",
    "start": "2598720",
    "end": "2606440"
  },
  {
    "text": "Hive Pig Etc and Spark streaming included so that's sort of the technology stack for",
    "start": "2606440",
    "end": "2612319"
  },
  {
    "text": "you to analyze so you know what stream processing technology should I use now what I've done here is actually taken",
    "start": "2612319",
    "end": "2618599"
  },
  {
    "text": "all the stream processing Technologies and compared them side by side I'm I'm not going to go through each one of those but those are some of the",
    "start": "2618599",
    "end": "2624000"
  },
  {
    "text": "dimensions that you want to think about in terms of the throughput all of them can handle any amount of throughput and",
    "start": "2624000",
    "end": "2629240"
  },
  {
    "text": "whether they're batch or real time if you're using the hive Handler for EMR you know that's a batch analytics batch",
    "start": "2629240",
    "end": "2635200"
  },
  {
    "text": "batch processing mechanism if you in terms of manageability uh in that dimension for",
    "start": "2635200",
    "end": "2640520"
  },
  {
    "text": "example spark streaming can be run on top of Amazon elastic map reduce Apache stom you you really have to you know",
    "start": "2640520",
    "end": "2647400"
  },
  {
    "text": "manage the entire cluster yourself whereas in the case of Kinesis client Library you can use ec2 and auto scaling",
    "start": "2647400",
    "end": "2653920"
  },
  {
    "text": "or if you're writing a beanock application you can actually run your KCl application on top of beanock so it",
    "start": "2653920",
    "end": "2659160"
  },
  {
    "text": "can automatically do the auto scaling on your behalf and actually run the cluster across multiple availability zones as",
    "start": "2659160",
    "end": "2665240"
  },
  {
    "text": "well and um Lambda is a fully managed service you don't have to do anything literally you write your function",
    "start": "2665240",
    "end": "2671200"
  },
  {
    "text": "associate that Lambda function with with the Kines with with Kinesis uh stream",
    "start": "2671200",
    "end": "2676599"
  },
  {
    "text": "and then the function gets triggered as your events come into the Kinesis stream that's a fully managed service but only",
    "start": "2676599",
    "end": "2682160"
  },
  {
    "text": "applicable for for Kinesis right now it doesn't work with Kafka as far as I know and um the other piece the important",
    "start": "2682160",
    "end": "2688520"
  },
  {
    "text": "piece that some people Miss is fa tolerance or multi-az so for example spark streaming is single a because it",
    "start": "2688520",
    "end": "2696440"
  },
  {
    "text": "is running on on an EMR cluster if for some reason usually data centers are Fairly reliable as's are reliable but",
    "start": "2696440",
    "end": "2702680"
  },
  {
    "text": "you know if you're building a distributed system we ask you to build multi-az Solutions so it is a single a solution if you're building this you",
    "start": "2702680",
    "end": "2708319"
  },
  {
    "text": "should be building multiple if this is you need you need this to be Fairly reliable you should be running um spark",
    "start": "2708319",
    "end": "2714720"
  },
  {
    "text": "streaming on more than one availability zone for example in the case of storm again you can do it in one a or multiple",
    "start": "2714720",
    "end": "2721800"
  },
  {
    "text": "a this is you know you have to actually rig up a cluster that runs on multiple availability zones in the case of",
    "start": "2721800",
    "end": "2727119"
  },
  {
    "text": "Kinesis client Library if you use autoscaling you can actually span span multiple availability zones but in the",
    "start": "2727119",
    "end": "2732359"
  },
  {
    "text": "case of Lambda it's automatically multi-az even if an availability Zone goes down the",
    "start": "2732359",
    "end": "2738000"
  },
  {
    "text": "Lambda infrastructure will launch the underlying servers to still continue to",
    "start": "2738000",
    "end": "2743599"
  },
  {
    "text": "process the stream even so it's even when when a single availability Zone goes down so it's a multi-az solution",
    "start": "2743599",
    "end": "2749800"
  },
  {
    "text": "and uh again I'm going Amazon EMR based Hive or Peg is going to be a single easy solution and the various language",
    "start": "2749800",
    "end": "2755400"
  },
  {
    "text": "Frameworks I've included there I'm not going to go through all of them but I think often customers miss the fall tolerance aspect of it I wanted to",
    "start": "2755400",
    "end": "2761319"
  },
  {
    "text": "highlight that in this presentation so that you would build a very reliable stack in terms of data processing Technologies what data processing",
    "start": "2761319",
    "end": "2767599"
  },
  {
    "text": "technology should you use so in terms of the query latencies um red shift is red",
    "start": "2767599",
    "end": "2775319"
  },
  {
    "text": "shift Stacks up very high uh because it's very easy to provision very easy to",
    "start": "2775319",
    "end": "2780520"
  },
  {
    "text": "manage fairly easy to use again I the maximum data you can store theoretically is 1.6 paby as Andy announced in in his",
    "start": "2780520",
    "end": "2787119"
  },
  {
    "text": "keynote this morning NTT doomo is already having four pedabytes of data so if you really want more than 1.6 paby of",
    "start": "2787119",
    "end": "2793920"
  },
  {
    "text": "data you want to store in S3 sorry red shift you can tell us and we can basically allow you to launch more nodes",
    "start": "2793920",
    "end": "2800520"
  },
  {
    "text": "um more than 100 nodes for example and um so um the other key point I want to",
    "start": "2800520",
    "end": "2806559"
  },
  {
    "text": "highlight here is that um in terms of the Native storage Amazon red shift has its own storage mechanism it basically",
    "start": "2806559",
    "end": "2813760"
  },
  {
    "text": "stores data on local diss even though it keeps a copy of the data in S3 all the time and it automatically backs up to S3",
    "start": "2813760",
    "end": "2820680"
  },
  {
    "text": "whereas all the other Technologies can work with files both in hdfs and S3 impola did not have the S3 support they",
    "start": "2820680",
    "end": "2827559"
  },
  {
    "text": "recently added that and uh Presto works with files in S3 in fact a lot of the customers for very large workloads are",
    "start": "2827559",
    "end": "2834920"
  },
  {
    "text": "actually leaving the data in S3 and running something like Presto to to access the data uh to run queries",
    "start": "2834920",
    "end": "2841559"
  },
  {
    "text": "against this data so in terms of SQL compatibility again Amazon red shift is fully SQL you know almost you know full",
    "start": "2841559",
    "end": "2848760"
  },
  {
    "text": "native SQL compliant uh MC compliant so you know various other pieces have various levels of compliancy so in terms",
    "start": "2848760",
    "end": "2856400"
  },
  {
    "text": "of ETL I'll just highlight this there is a product called AWS data pipeline that allows you to actually you know run a",
    "start": "2856400",
    "end": "2862319"
  },
  {
    "text": "crownlike semantic where you can actually wake up a process you know actually run an EMR cluster every every",
    "start": "2862319",
    "end": "2869319"
  },
  {
    "text": "15 minutes or so or more and then take the data in S3 and process this and put this in another store we also have an",
    "start": "2869319",
    "end": "2876240"
  },
  {
    "text": "amazing techn Technologies from from various Partners it's in our partner page whether ATU or Informatica or",
    "start": "2876240",
    "end": "2882000"
  },
  {
    "text": "metallion or snap logic uh alter x uh there's a lot of Partners uh that have amazing integration Solutions as well",
    "start": "2882000",
    "end": "2888599"
  },
  {
    "text": "I've included that for for completeness so in terms of the consume layer uh let's spend some time in the consume",
    "start": "2888599",
    "end": "2894520"
  },
  {
    "text": "consume area so in the case of consume so I basically there's two types of",
    "start": "2894520",
    "end": "2900880"
  },
  {
    "text": "consumers here business users are data scientists and developers in the case of business users",
    "start": "2900880",
    "end": "2907160"
  },
  {
    "text": "you know using products such as Amazon quick site which Andy demoed in the",
    "start": "2907160",
    "end": "2912400"
  },
  {
    "text": "keynote um the product that we launched today and uh various other partner",
    "start": "2912400",
    "end": "2917480"
  },
  {
    "text": "Solutions are Tableau looker you know tipco micro strategy kibana Etc or you",
    "start": "2917480",
    "end": "2922599"
  },
  {
    "text": "can have your own libraries such as flat or D3 that actually access the data both",
    "start": "2922599",
    "end": "2928760"
  },
  {
    "text": "from your storage subsystem analysis subsystems and also these days notebooks are very popular uh such as IPython",
    "start": "2928760",
    "end": "2936040"
  },
  {
    "text": "notebook for for example you can launch a EMR cluster and install IPython notebook to process to actually have a",
    "start": "2936040",
    "end": "2941640"
  },
  {
    "text": "notebook view you know to do your slicing and dicing of the data and share the notebooks across data scientists Etc",
    "start": "2941640",
    "end": "2948720"
  },
  {
    "text": "and um putting it all together I'm going to leave this reference architecture",
    "start": "2948720",
    "end": "2954160"
  },
  {
    "text": "with you and um and I'm going to go through some of the design patterns fairly rapidly and um in terms of the",
    "start": "2954160",
    "end": "2961200"
  },
  {
    "text": "design patterns um you know think of your data processing pipeline as a multi-staged",
    "start": "2961200",
    "end": "2966520"
  },
  {
    "text": "pip Pipeline with having storage decoupled various processing tiers and",
    "start": "2966520",
    "end": "2972280"
  },
  {
    "text": "if you have various processing tiers when you as soon as you decouple that you could have multiple processing tiers read data from a storage tiers such as",
    "start": "2972280",
    "end": "2979160"
  },
  {
    "text": "Amazon Kinesis here and write to multiple stages in this case Amazon s Kinesis S3 connector is reading data",
    "start": "2979160",
    "end": "2985119"
  },
  {
    "text": "from Kinesis and writing it to S3 whereas AWS Lambda is processing the data that you put in Kinesis and writing",
    "start": "2985119",
    "end": "2991240"
  },
  {
    "text": "to Dynamo DB so you know decoupling these systems allows you to run multiple par processes",
    "start": "2991240",
    "end": "2997240"
  },
  {
    "text": "for you to you know slice and dice the data in a way we want in a way you want and um as soon as you again separate",
    "start": "2997240",
    "end": "3005520"
  },
  {
    "text": "processing and storage in this case Hive is processing data both from Amazon",
    "start": "3005520",
    "end": "3010599"
  },
  {
    "text": "Dynamo DB through an external table and S3 and doing a join between the data and two stages so this is the beauty of",
    "start": "3010599",
    "end": "3017200"
  },
  {
    "text": "actually decoupling storage from computer allows you to do Downstream computations such as these and um now",
    "start": "3017200",
    "end": "3023559"
  },
  {
    "text": "putting two Dimensions together um you know these these these colors can be a little bit overwhelming I just wanted to still you",
    "start": "3023559",
    "end": "3031040"
  },
  {
    "text": "know present the idea that's why I left those colors um there's two Dimensions here when you're dealing with data stores you're dealing with hot data or",
    "start": "3031040",
    "end": "3036839"
  },
  {
    "text": "cold data on the x- axis hot to cold on the y- axis your data processing latency",
    "start": "3036839",
    "end": "3042400"
  },
  {
    "text": "you know when somebody something has a as you go from low to high as let's",
    "start": "3042400",
    "end": "3049559"
  },
  {
    "text": "say if Hive takes much longer to process compared to for example spark or Impala",
    "start": "3049559",
    "end": "3055359"
  },
  {
    "text": "so hi was a higher process latency that's the that's what I'm meaning here so if you when you're building realtime",
    "start": "3055359",
    "end": "3061040"
  },
  {
    "text": "systems so that's your stack for building real-time systems um you know for example putting a data in Kinesis or",
    "start": "3061040",
    "end": "3066760"
  },
  {
    "text": "kovka and Dynamo DB and running spark streaming or Apache stom or AWS Lambda",
    "start": "3066760",
    "end": "3072040"
  },
  {
    "text": "for processing the data would be a real-time stack and or you could put data in Dynamo DB and run native Native",
    "start": "3072040",
    "end": "3079240"
  },
  {
    "text": "Dynamo queries as as well as using KCl or AWS Lambda to process Dynamo Dynamo",
    "start": "3079240",
    "end": "3085359"
  },
  {
    "text": "DB streams to do realtime processing so if you're dealing with interactive analytics typically data goes into",
    "start": "3085359",
    "end": "3091280"
  },
  {
    "text": "Dynamo DB or S3 or you can copy this over to hdfs as well and you can run red",
    "start": "3091280",
    "end": "3097920"
  },
  {
    "text": "shift you know copy the data over to Red shift or run spark impol Presto on the data you you put in hdfs or S3 you know",
    "start": "3097920",
    "end": "3105559"
  },
  {
    "text": "for doing interactive analytics so in terms of the batch as you put your data in various you know uh data stores you",
    "start": "3105559",
    "end": "3112079"
  },
  {
    "text": "can run high on them to do batch analytics so that's sort of a mental picture of how to think think about uh",
    "start": "3112079",
    "end": "3117720"
  },
  {
    "text": "these two dimensions and the various types of things you can do processing you can do now let's actually assemble",
    "start": "3117720",
    "end": "3123400"
  },
  {
    "text": "some concrete Stacks here this is sort of a you know maybe a you know think of this as a design pattern for realtime",
    "start": "3123400",
    "end": "3129240"
  },
  {
    "text": "analytics you have producer putting the data in Kinesis kavka or Dynamo DB",
    "start": "3129240",
    "end": "3134520"
  },
  {
    "text": "streams and you have consumers consuming the data and in this case for example you can have either KCl or AWS Lambda or",
    "start": "3134520",
    "end": "3142119"
  },
  {
    "text": "spark streaming or Apache strong process the data that's in a stream and generate alert and put the alerts in SNS and",
    "start": "3142119",
    "end": "3149960"
  },
  {
    "text": "notify you know send send an SMS message or it can actually activate a q or call",
    "start": "3149960",
    "end": "3155480"
  },
  {
    "text": "a Lambda function Downstream to notify other Downstream systems or in many cases what happens is you have a key",
    "start": "3155480",
    "end": "3161640"
  },
  {
    "text": "performance indicator for your company for amazon.com for example we have a graph that shows order inflow anytime there's a little bit of a dip we",
    "start": "3161640",
    "end": "3168119"
  },
  {
    "text": "actually cut a sell one and then we have various teams looking at what may be happening because we sort of know what our key performance indicator and how",
    "start": "3168119",
    "end": "3174520"
  },
  {
    "text": "how typically the graph looks like so for each company there's a key performance indicator and ideally you can build real-time systems to actually",
    "start": "3174520",
    "end": "3180960"
  },
  {
    "text": "show you what the key performance indicator is real time this is a typical architecture for do that where you keep the state in in an appropriate data",
    "start": "3180960",
    "end": "3188400"
  },
  {
    "text": "store and uh one thing I missed out here just to go back a tiny bit is you can also",
    "start": "3188400",
    "end": "3194680"
  },
  {
    "text": "run um real-time predictions when when a when a fraud when a transaction is",
    "start": "3194680",
    "end": "3199880"
  },
  {
    "text": "happening if this is a new customer you never seen you can also basically call Amazon machine learning service um to",
    "start": "3199880",
    "end": "3206720"
  },
  {
    "text": "figure out whe whether this looks like a fraud and actually you know either do the alert or not do the alert as well so",
    "start": "3206720",
    "end": "3212079"
  },
  {
    "text": "you can this is how you would add real time you you You' learn predictions into your real-time processing pipeline so",
    "start": "3212079",
    "end": "3218640"
  },
  {
    "text": "here's an example of interactive and batch processing on the top is interactive analytics again putting the data in S3 is key and then you can",
    "start": "3218640",
    "end": "3224799"
  },
  {
    "text": "either Run Red shift or EMR um with Presto or impal and Spark to do realtime",
    "start": "3224799",
    "end": "3230280"
  },
  {
    "text": "analytics and then you can also trigger a real-time prediction so you can also look up as you're processing data with",
    "start": "3230280",
    "end": "3235799"
  },
  {
    "text": "this you can run a UDF you can write a UDF function and to quickly look up uh Amazon machine learning to see if this",
    "start": "3235799",
    "end": "3242280"
  },
  {
    "text": "is a fraudulent transaction or if you're doing some kinds of um you know analytics such as give me the lifetime",
    "start": "3242280",
    "end": "3248200"
  },
  {
    "text": "value of a customer Etc so in the case of batch um we've been doing this for a long time putting data in S3 and running",
    "start": "3248200",
    "end": "3254480"
  },
  {
    "text": "Hive pegar spark to process the data uh is the right pattern there and Lambda",
    "start": "3254480",
    "end": "3260480"
  },
  {
    "text": "architecture um as I talked about is is is very popular in large High scale",
    "start": "3260480",
    "end": "3265640"
  },
  {
    "text": "sites and here is a here is an idea for how to create a Lambda architecture put your data in Amazon Kinesis and build a",
    "start": "3265640",
    "end": "3272000"
  },
  {
    "text": "batch layer and the batch layer would comprise of an S3 connector and the S3",
    "start": "3272000",
    "end": "3277400"
  },
  {
    "text": "connector will take the data from Kinesis and actually put that into S3 you can actually you know compress the",
    "start": "3277400",
    "end": "3283720"
  },
  {
    "text": "best practice there is to compress the files as you put that in S3 and properly do a window function you know wait for a",
    "start": "3283720",
    "end": "3289119"
  },
  {
    "text": "few minutes or where the size of the file is a specific size to actually write the file this way you can write",
    "start": "3289119",
    "end": "3294559"
  },
  {
    "text": "big files and don't have to pay the big price the we went through the cost you know pricing calculator um and then once",
    "start": "3294559",
    "end": "3299960"
  },
  {
    "text": "the data is in S3 you can run various Technologies to process the data and generate an answer in the case of a speed layer this is one way of actually",
    "start": "3299960",
    "end": "3305920"
  },
  {
    "text": "building the speed layer you can use AWS Lambda or spark streaming or storm to do",
    "start": "3305920",
    "end": "3310960"
  },
  {
    "text": "your speed layer in many of the scenarios what happens is when you build Downstream applications you also need um",
    "start": "3310960",
    "end": "3317880"
  },
  {
    "text": "a serving layer typically the serving layer is your database layer and which",
    "start": "3317880",
    "end": "3323079"
  },
  {
    "text": "is you know typically no SQL or SQL complemented by caches and Searchers to to serve any number of requests per",
    "start": "3323079",
    "end": "3329119"
  },
  {
    "text": "second millions of requests per second for example right you really need a serving layer uh to seres as requests",
    "start": "3329119",
    "end": "3335520"
  },
  {
    "text": "and you can add machine learning into this by both the batch processing as well as the stream processing layer you",
    "start": "3335520",
    "end": "3341480"
  },
  {
    "text": "know Consulting a machine learning stack to be able to you know do machine learning on both your batch analytics",
    "start": "3341480",
    "end": "3346559"
  },
  {
    "text": "and realtime analytics so in summary Building decoupled Systems if",
    "start": "3346559",
    "end": "3353160"
  },
  {
    "text": "you're building a big data processing pipeline Building decoupled Systems is fairly important and using the right",
    "start": "3353160",
    "end": "3359200"
  },
  {
    "text": "tool for the job is per amount we've gone through some examples of what kind",
    "start": "3359200",
    "end": "3364760"
  },
  {
    "text": "type of characteristics that you should look for in matching your access patterns to what the various",
    "start": "3364760",
    "end": "3369839"
  },
  {
    "text": "Technologies can provide and we walk through Lambda architecture ideas you know that your your log is your database",
    "start": "3369839",
    "end": "3376359"
  },
  {
    "text": "is our current thinking in big data and then having an immutable up and Only log in S3 is super critical so in many of my",
    "start": "3376359",
    "end": "3384039"
  },
  {
    "text": "design reviews I ensure that that one pipeline right rights to S3 properly and then you know thinking of your",
    "start": "3384039",
    "end": "3389839"
  },
  {
    "text": "processing layer as a batch or stream processing layer is super critical as well and then obviously use AWS manage",
    "start": "3389839",
    "end": "3396119"
  },
  {
    "text": "services there's no reason to reinvent the wheel unless you have a specific region reason why these Services won't",
    "start": "3396119",
    "end": "3401599"
  },
  {
    "text": "actually car to your needs and last but not the least be costc conscious and thank you so much for your time and that",
    "start": "3401599",
    "end": "3408000"
  },
  {
    "text": "brings the end of my presentation thank you",
    "start": "3408000",
    "end": "3414640"
  }
]
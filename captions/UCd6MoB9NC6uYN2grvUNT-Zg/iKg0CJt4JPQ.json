[
  {
    "start": "0",
    "end": "117000"
  },
  {
    "text": "sorry all right my name is coburn watson and i work for netflix i manage the cloud",
    "start": "480",
    "end": "5920"
  },
  {
    "text": "performance engineering team and today i'm going to talk to you about optimizing costs with aws some of the",
    "start": "5920",
    "end": "11280"
  },
  {
    "text": "lessons we've learned and hopefully share some best practices to help you guys out in your business as well i'll",
    "start": "11280",
    "end": "16320"
  },
  {
    "text": "try to fit in the time allocated and have some time for question at the end but if for some reason um we can't we",
    "start": "16320",
    "end": "21760"
  },
  {
    "text": "have a booth set up and i'll be there after this so you can swing by and chat with myself or others from netflix",
    "start": "21760",
    "end": "27840"
  },
  {
    "text": "so hopefully everybody knows what netflix does um we have about 30 million people worldwide that use our streaming",
    "start": "27840",
    "end": "33520"
  },
  {
    "text": "service and that's what we're focusing on a lot now you can see the different countries we're in we have about 25 million streaming subscribers in the u.s",
    "start": "33520",
    "end": "41840"
  },
  {
    "text": "one thing i want to point out was people get a little confused in terms of where the content comes from right so when",
    "start": "41840",
    "end": "47120"
  },
  {
    "text": "you're navigating the netflix experience and you're adding users in browsing that's on aws when you click play it's",
    "start": "47120",
    "end": "53120"
  },
  {
    "text": "coming off of a content delivery network so we're not delivering the media from aws although we do have a huge amount of",
    "start": "53120",
    "end": "58879"
  },
  {
    "text": "traffic coming back from your device into aws because we're tracking all your bookmarks and other information",
    "start": "58879",
    "end": "65759"
  },
  {
    "text": "okay what i'm going to talk about is the rationale behind how we do you know more capacity planning on our side on aws and",
    "start": "67200",
    "end": "74080"
  },
  {
    "text": "the associated methodology we apply i think we have a distinct enough environment and maybe that's not the case but i want to share how we do",
    "start": "74080",
    "end": "80720"
  },
  {
    "text": "things and how we run engineering at netflix and it drives a lot of how we handle management of our resources and",
    "start": "80720",
    "end": "86159"
  },
  {
    "text": "then i'm going to go into some specific optimizations you know we don't always spend the same amount of money on every",
    "start": "86159",
    "end": "91920"
  },
  {
    "text": "aspect of aws some are more expensive than others so i'll break it down for say our top three and then i'll talk a little bit about",
    "start": "91920",
    "end": "98000"
  },
  {
    "text": "performance testing so that's something my team owns as well we're validating stuff before it goes into production and",
    "start": "98000",
    "end": "103040"
  },
  {
    "text": "we have some frameworks that run on aws talk a little bit about results i really can't talk about dollars here but i'll",
    "start": "103040",
    "end": "108720"
  },
  {
    "text": "talk about things in the context of workload and footprint and that type of thing so at least it's a bit relative",
    "start": "108720",
    "end": "113759"
  },
  {
    "text": "and they'll have some q a so from a rationale perspective you know what really drives us to control our",
    "start": "113759",
    "end": "120399"
  },
  {
    "start": "117000",
    "end": "117000"
  },
  {
    "text": "costs in aws is we operate at a pretty massive scale right netflix itself is running tens of thousands of instances a",
    "start": "120399",
    "end": "126320"
  },
  {
    "text": "day on aws across multiple regions and multiple zones and you can imagine if we had a big burst for some reason at that",
    "start": "126320",
    "end": "133360"
  },
  {
    "text": "number of instances or even a subset of it on demand could become a pretty significant cost for us because it's not",
    "start": "133360",
    "end": "138480"
  },
  {
    "text": "it's not a small a small fleet we have a service oriented architecture",
    "start": "138480",
    "end": "143520"
  },
  {
    "text": "so there's probably about 20 teams that operate uh very independently right at netflix each of the teams owns their",
    "start": "143520",
    "end": "149520"
  },
  {
    "text": "service they own everything from designing it deploying it they own the performance",
    "start": "149520",
    "end": "154720"
  },
  {
    "text": "there on the functional aspects of that and they only on call responsibilities so it's really like 20 teams of complete",
    "start": "154720",
    "end": "159760"
  },
  {
    "text": "operational folks but that gives us that many more parts that are moving in general and people",
    "start": "159760",
    "end": "164800"
  },
  {
    "text": "that are sharing resources in a dynamic fashion with different push schedules for their code maybe once a week maybe every four weeks",
    "start": "164800",
    "end": "171440"
  },
  {
    "text": "and we have these unconstrained deployment capabilities i'll talk more about that as we go forward and it ties",
    "start": "171440",
    "end": "177040"
  },
  {
    "text": "into the netflix freedom and responsibility culture right now when i first took a job at netflix and we started talking about",
    "start": "177040",
    "end": "182959"
  },
  {
    "text": "capacity planning and i understood a lot of these factors i thought well this is going to be like herding cats you know like this is going",
    "start": "182959",
    "end": "188879"
  },
  {
    "text": "to be a real challenge and then you know once i really got involved in netflix and i worked all the engineers i",
    "start": "188879",
    "end": "194879"
  },
  {
    "text": "realized you know their level of experience with large distributed systems is just amazing and a lot of",
    "start": "194879",
    "end": "200400"
  },
  {
    "text": "them are very careful about what they deploy when they deploy and they really operate in the best interest of the company and they help it's just a nice",
    "start": "200400",
    "end": "206480"
  },
  {
    "text": "ecosystem in terms of they can deploy whatever they want whenever they want and i'm it's interesting later maybe i'll talk to",
    "start": "206480",
    "end": "212319"
  },
  {
    "text": "some of you because i'm wondering how other people manage their aws capacity because we have hundreds of engineers that can stand up",
    "start": "212319",
    "end": "218799"
  },
  {
    "text": "whatever they want whenever they want um and i don't know if other companies do that it was a big shift for me coming",
    "start": "218799",
    "end": "224319"
  },
  {
    "text": "from a company where you're more of a procurement cycle model right you request some servers you wait six months",
    "start": "224319",
    "end": "229599"
  },
  {
    "text": "it's less than what you need and this really gives us some great capabilities",
    "start": "229599",
    "end": "234959"
  },
  {
    "text": "we want to improve availability you know we've had a couple outages some of them have been aws related some of them been",
    "start": "234959",
    "end": "240879"
  },
  {
    "text": "our own and what we want to do is since we have so many teams leveraging at ws resources we need to make sure that we maintain",
    "start": "240879",
    "end": "247120"
  },
  {
    "text": "the right level of availability there's going to be a lot of presentations this here this week about how we have a",
    "start": "247120",
    "end": "252239"
  },
  {
    "text": "highly available architecture running on aws and part of that is avoiding saturation",
    "start": "252239",
    "end": "258239"
  },
  {
    "start": "258000",
    "end": "258000"
  },
  {
    "text": "of key resources if you have teams that are pushing code and we have a red black model i don't know if you've heard about",
    "start": "258239",
    "end": "263680"
  },
  {
    "text": "that where through our console we've created the concept of a cluster and someone has an auto scaling group",
    "start": "263680",
    "end": "268960"
  },
  {
    "text": "running with their current ami and when it's time to push new code they spin up another asg of the same size they start",
    "start": "268960",
    "end": "274639"
  },
  {
    "text": "rolling traffic over and if there's a functional or performance problem they can click a button in about 10 minutes they're back up at full scale in the old",
    "start": "274639",
    "end": "280960"
  },
  {
    "text": "code base and so if you have it once some you know a few of your really large teams doing",
    "start": "280960",
    "end": "286000"
  },
  {
    "text": "that at the exact same time you can have a doubling of all these asgs you can have a burst of many thousands of instances",
    "start": "286000",
    "end": "292240"
  },
  {
    "text": "and aws has a lot of capacity but we really don't want to try to push that boundary and hit a situation where we",
    "start": "292240",
    "end": "297759"
  },
  {
    "text": "can't get the instances we need and we also want to adjust our capacity you know we have a pretty well defined",
    "start": "297759",
    "end": "303199"
  },
  {
    "text": "workload pattern of our users in the us you know people watch things at a certain time they add things to their queue",
    "start": "303199",
    "end": "308560"
  },
  {
    "text": "but uh it changes over time you know the business changes holidays come up there's things that we might not be predicting as well and so we want to",
    "start": "308560",
    "end": "315520"
  },
  {
    "text": "improve availability by managing our resources and having enough spare capacity for those burst periods",
    "start": "315520",
    "end": "321360"
  },
  {
    "text": "and when you you know you go about capacity planning at netflix since everybody owns their resources all the individual um teams and you approach the",
    "start": "321360",
    "end": "328560"
  },
  {
    "text": "topic of managing aws costs it's not a real popular cost with engineering teams to you know control cost so you come at",
    "start": "328560",
    "end": "334560"
  },
  {
    "text": "it from the perspective of you know our goal isn't to reduce our current footprint and try to get our",
    "start": "334560",
    "end": "340240"
  },
  {
    "text": "amazon bill down i mean that's good right that that helps um but our real goal is that we still think we're in a",
    "start": "340240",
    "end": "345600"
  },
  {
    "text": "pretty early stage of our growth as a company especially internationally and the more optimization we can get around",
    "start": "345600",
    "end": "350720"
  },
  {
    "text": "aws now will help us extend our aws infrastructure growth in a non-linear fashion with subscriber",
    "start": "350720",
    "end": "357680"
  },
  {
    "text": "growth right we don't really want to be adding the exact same amount of resources when we're at 60 million subscribers and so there's a lot of",
    "start": "357680",
    "end": "364319"
  },
  {
    "text": "reasons to optimize your footprint reid talked a little bit about it today in the keynote where we you know our",
    "start": "364319",
    "end": "371360"
  },
  {
    "text": "real differentiator is a personalization of content for people because you have a little tiny window and you have 10 000",
    "start": "371360",
    "end": "376639"
  },
  {
    "text": "titles as a business we're finding that we need to apply more and more computing power",
    "start": "376639",
    "end": "382160"
  },
  {
    "text": "to get the right recommendations in front of the right people and we don't really want to go out and have to procure a whole other set of instances",
    "start": "382160",
    "end": "388160"
  },
  {
    "text": "just to run that workload so one thing i have under here is an assumption which might not be true for everyone is we",
    "start": "388160",
    "end": "395120"
  },
  {
    "text": "really operate in the world at netflix of reserved instances we pretty much try to stay out of on",
    "start": "395120",
    "end": "400160"
  },
  {
    "text": "demand at almost all times just because of the size of our footprint so i'll get more in detail about",
    "start": "400160",
    "end": "406400"
  },
  {
    "text": "reserved instances and how we can use those troughs a little bit better and how it's a real cool capacity planning problem",
    "start": "406400",
    "end": "412000"
  },
  {
    "text": "um and the general principle is that whatever you measure improves right and we see that you know last year we were having some cost runoffs",
    "start": "412000",
    "end": "419440"
  },
  {
    "text": "wasn't looking good and then we went around and started talking to the various teams and they're like oh i did that i didn't know that and they would",
    "start": "419440",
    "end": "424639"
  },
  {
    "text": "take that down or move something over and so in general just applying a little eye",
    "start": "424639",
    "end": "429680"
  },
  {
    "text": "or a little attention to our aws footprint really helps improve things over time",
    "start": "429680",
    "end": "435360"
  },
  {
    "start": "435000",
    "end": "435000"
  },
  {
    "text": "here's an example of when i talk about unconstrained deployment i wanted to put in here people might have heard about asgard which is sort of our aws console",
    "start": "435520",
    "end": "442560"
  },
  {
    "text": "it's an open source framework um everybody uses it at netflix for their deployments so all engineers have full access to",
    "start": "442560",
    "end": "449039"
  },
  {
    "text": "this you know and the thing i wanted to point out and i'll come to a little bit later is",
    "start": "449039",
    "end": "454080"
  },
  {
    "text": "the way we're solving a lot of our you know optimizing our usage is by getting data to the engineers so they can make better",
    "start": "454080",
    "end": "460160"
  },
  {
    "text": "decisions at deployment time so that little box up on the side that has some numbers grayed out that's basically",
    "start": "460160",
    "end": "466479"
  },
  {
    "text": "real-time reservation capacity so if you're an engineer at netflix and you bring up asgard and you say i want to create a new auto scaling group and",
    "start": "466479",
    "end": "472720"
  },
  {
    "text": "you're going to go fill in those boxes which the arrow's not pointing to correctly but there's three boxes down below that say min desired and max and",
    "start": "472720",
    "end": "479360"
  },
  {
    "text": "those are just free form fields right i could be any engineer on netflix of the many hundreds and i could type in a thousand a thousand a thousand go and",
    "start": "479360",
    "end": "485520"
  },
  {
    "text": "i'll get a thousand instances um but what that box up above says for the instance type that you're trying to",
    "start": "485520",
    "end": "491280"
  },
  {
    "text": "deploy this is our current amount of available reservations out in aws so people can make better decisions we've",
    "start": "491280",
    "end": "496800"
  },
  {
    "text": "had cases where teams are going to do a really large coat large code bush and they saw that",
    "start": "496800",
    "end": "502080"
  },
  {
    "text": "there was not enough available reserved instances to really get it out there without just bursting into on demand and",
    "start": "502080",
    "end": "507280"
  },
  {
    "text": "so what they'll do is they'll oh that's your guy's computer",
    "start": "507280",
    "end": "513120"
  },
  {
    "text": "thanks i know it's not my mac that's all i know um so uh",
    "start": "515760",
    "end": "521518"
  },
  {
    "text": "by getting that in front of people we'll find teams that will actually communicate more with each other and say hey i need to push a thousand instances",
    "start": "521519",
    "end": "526880"
  },
  {
    "text": "for my new uh push it looks like there aren't that many how do we coordinate better and it helps us avoid these real unexpected uh bursting",
    "start": "526880",
    "end": "533760"
  },
  {
    "text": "on on demand so from a methodology we have a mixture of manual and automated processes you",
    "start": "533760",
    "end": "539920"
  },
  {
    "text": "know ideally everything's automated right your deployment's automated your testing is automated you know if you're lucky your espresso machine's automated",
    "start": "539920",
    "end": "546080"
  },
  {
    "text": "whatever but you know automating the entire process a lot of the trends we see tend to be unique in",
    "start": "546080",
    "end": "552560"
  },
  {
    "text": "their nature there's a new architecture coming in it's something that through automation we wouldn't necessarily be",
    "start": "552560",
    "end": "557839"
  },
  {
    "text": "able to predict that we need to for instance increase a given uh reservation pool for an instance class so what we do",
    "start": "557839",
    "end": "564320"
  },
  {
    "text": "um is we meet about once a week it's only 30 minutes and what we do is we take a few stakeholders from the organization someone from the finance",
    "start": "564320",
    "end": "571279"
  },
  {
    "text": "team that's responsible for communicating reservation purchases some people that run various engineering teams and we just i'll show you in a",
    "start": "571279",
    "end": "577440"
  },
  {
    "text": "second we bring up something we call our aws usage tool and it basically gives us a bird's eye view",
    "start": "577440",
    "end": "583120"
  },
  {
    "text": "on our usage over time up to date up to like the last hour and you can slice along along any dimension",
    "start": "583120",
    "end": "588959"
  },
  {
    "text": "and what we look for is we're looking for really unexpected on-demand trends like we had a case recently where one service had to move",
    "start": "588959",
    "end": "595839"
  },
  {
    "text": "out of an m22xl into an m24 xl very quickly for some problem we didn't have enough reservations for",
    "start": "595839",
    "end": "602079"
  },
  {
    "text": "that and it was a big burst in on demand so we'll see graphically that we're having a big burst and we'll go off and sort of investigate that determine well",
    "start": "602079",
    "end": "608880"
  },
  {
    "text": "it's something we need to do or it's a trend we need to prepare for and then we'll look at our reservation efficiency so sometimes we'll look at um",
    "start": "608880",
    "end": "616560"
  },
  {
    "text": "well most of the times we'll look at what is our reservation by class and i'll talk about how we manage that better and then we'll look at our cost",
    "start": "616560",
    "end": "622560"
  },
  {
    "text": "per key event so you know a key thing for us is when you look at our business we have a bunch of important high-level",
    "start": "622560",
    "end": "628079"
  },
  {
    "text": "business metrics it might be the number of users starting a movie per second or a stream start something along those",
    "start": "628079",
    "end": "633440"
  },
  {
    "text": "lines and you might have atm transactions an hour or something if you're running your bank on aws",
    "start": "633440",
    "end": "639680"
  },
  {
    "text": "and so setting your cost in that context lets you look over time to see if you're generally improving your cost and one",
    "start": "639680",
    "end": "646640"
  },
  {
    "text": "thing i meant to call out earlier is our capacity planning approach at netflix it's really more of a journey not a",
    "start": "646640",
    "end": "652320"
  },
  {
    "text": "destination we don't go into a room and say this is how much we're allowed to spend this year for aws and we're going",
    "start": "652320",
    "end": "657360"
  },
  {
    "text": "to get down to that point and just you know stick it to everybody so our goal is to improve the efficiency",
    "start": "657360",
    "end": "663360"
  },
  {
    "text": "through all these other processes have teams adopt them and in general what we've seen is the cost do come down significantly and then as needed we'll",
    "start": "663360",
    "end": "670160"
  },
  {
    "text": "have a manual process where we'll see a team that isn't auto scaling and we'll go out and engage with them and evaluate",
    "start": "670160",
    "end": "675760"
  },
  {
    "text": "their workload profile have them configure auto scaling and make sure it's efficient in nature",
    "start": "675760",
    "end": "681279"
  },
  {
    "text": "the automated stuff is are things that we're really ramping up on we have a weekly email that goes out to teams so we found out we had this great",
    "start": "681279",
    "end": "687760"
  },
  {
    "text": "dashboard nope not that way we had this dashboard",
    "start": "687760",
    "end": "693920"
  },
  {
    "text": "which allows you to see all the utilization information by instance type and different resources and engineers had it available to them",
    "start": "693920",
    "end": "700079"
  },
  {
    "text": "but they weren't necessarily looking at it right everybody has a day job and so what we said was what would be ideal is",
    "start": "700079",
    "end": "705279"
  },
  {
    "text": "if we could take this information and we could bundle it up and each week send all of the engineering teams",
    "start": "705279",
    "end": "710480"
  },
  {
    "text": "an email which i'll show you in a second which breaks down their cost so they can distract themselves uh i showed previously how we",
    "start": "710480",
    "end": "717920"
  },
  {
    "text": "expose reservations real time you know just getting that data in front of the engineers and then janitor monkey um",
    "start": "717920",
    "end": "723360"
  },
  {
    "text": "ariel's down here his team runs a lot of the tooling for our company he'll be talking on friday and a lot of these",
    "start": "723360",
    "end": "728560"
  },
  {
    "text": "automated aspects of our you know capacity management are really driven by tooling that comes out of his team which",
    "start": "728560",
    "end": "734079"
  },
  {
    "text": "is invaluable so here's the aws usage screen with everything really interesting sort of stripped out",
    "start": "734079",
    "end": "740240"
  },
  {
    "start": "735000",
    "end": "735000"
  },
  {
    "text": "of it so the color the legends would be our key services right so i can probably",
    "start": "740240",
    "end": "746240"
  },
  {
    "text": "tell you that the blue is probably ec2 and then the red is probably let's say s3 and the one below that simple db or",
    "start": "746240",
    "end": "753440"
  },
  {
    "text": "something like that which we're moving away from a bit but in general those are the types of aws resources so through this tool",
    "start": "753440",
    "end": "759519"
  },
  {
    "text": "we have the data that goes back about 14 months and in the meeting we can take say the last four weeks and we can very",
    "start": "759519",
    "end": "764800"
  },
  {
    "text": "quickly split across the dimensions of region zone instance type application",
    "start": "764800",
    "end": "771519"
  },
  {
    "text": "group and aws i think i might have said resource type already but it very easily lets us identify if there's a trend and",
    "start": "771519",
    "end": "778240"
  },
  {
    "text": "if it's going into on demand which is which is real handy there are some open sourcing plans for that but i don't think anything's been officially",
    "start": "778240",
    "end": "784399"
  },
  {
    "text": "announced so we took that data and we said well no one's really going and looking at it that much so why don't",
    "start": "784399",
    "end": "790800"
  },
  {
    "text": "we send each of the engineering teams an email that shows them for the past four weeks how their aws costs are trending",
    "start": "790800",
    "end": "797440"
  },
  {
    "start": "792000",
    "end": "792000"
  },
  {
    "text": "and so what this does is for ec2 s3 and simpledb it shows and i've taken the service name out of this you know we have 20 or 30",
    "start": "797440",
    "end": "803760"
  },
  {
    "text": "services but the managers have actually found this very interesting to have because a lot",
    "start": "803760",
    "end": "809760"
  },
  {
    "text": "of times when you see a trend running off most cases where we end up having large on-demand or a large shift in aws usage",
    "start": "809760",
    "end": "816560"
  },
  {
    "text": "the teams aren't really aware of it they're like oh i stood that up i didn't realize that or oh i didn't know i was supposed to be on that instance type and",
    "start": "816560",
    "end": "822480"
  },
  {
    "text": "so it really comes down in almost all cases to getting the right information in front of the team so they can make the",
    "start": "822480",
    "end": "828399"
  },
  {
    "text": "right choices versus saying you know versus saying you are allowed to have 30 instances this week um but it does tie",
    "start": "828399",
    "end": "834079"
  },
  {
    "text": "back to our culture a bit and you guys probably have leads and other people on your team that manage",
    "start": "834079",
    "end": "839760"
  },
  {
    "text": "capacity and they could probably leverage something like this to sort of push information down",
    "start": "839760",
    "end": "845279"
  },
  {
    "start": "845000",
    "end": "845000"
  },
  {
    "text": "and then janitor monkey that's one of part of our simeon army people have probably heard of chaos monkey goes around kills things",
    "start": "845519",
    "end": "852000"
  },
  {
    "text": "janitor monkey is something that helps us keep our test environment pretty clean so it goes around and it looks for",
    "start": "852000",
    "end": "857680"
  },
  {
    "text": "resources which fit a certain case of a set of criteria like an instance that",
    "start": "857680",
    "end": "862720"
  },
  {
    "text": "was launched that is not part of an asg that's been around for more than four days and then it sends an email to the",
    "start": "862720",
    "end": "867839"
  },
  {
    "text": "engineer and it says this instance is going to be killed in five days and you can kill it before then if you want to",
    "start": "867839",
    "end": "873279"
  },
  {
    "text": "or take some action to ignore it and this is a set of rules that we continue to evolve over time but it really keeps",
    "start": "873279",
    "end": "879040"
  },
  {
    "text": "our test environment pretty clean and since our test account leverages reservations from our prod account um it helps us keep tests from",
    "start": "879040",
    "end": "886160"
  },
  {
    "text": "running off into the woods it comes in valuable tooth performance testing because most of the development",
    "start": "886160",
    "end": "892720"
  },
  {
    "text": "most of the engineers stand up relatively few number of instances to evaluate something but when we go to run a really big load test you know we'll",
    "start": "892720",
    "end": "899199"
  },
  {
    "text": "spin up like 150 jmeter instances and just hammer the crap out of something right and if we don't take that down",
    "start": "899199",
    "end": "906320"
  },
  {
    "text": "that demand will just run into on demand pretty quickly over time so it helps us reduce our cost and clutter but these",
    "start": "906320",
    "end": "911440"
  },
  {
    "text": "are the automated aspects that have brought us significant value and you know your own company just have to think well how could i get that information to",
    "start": "911440",
    "end": "917680"
  },
  {
    "text": "the to the teams to make those decisions better so let me talk a little bit about um",
    "start": "917680",
    "end": "924320"
  },
  {
    "text": "aws specific optimizations they're probably going to be you know fairly valuable to people and this is one where we've spent quite a bit of time",
    "start": "924320",
    "end": "931120"
  },
  {
    "text": "in terms of optimizing those resources so from an ec2 perspective this has you know been an adventure so",
    "start": "931120",
    "end": "938399"
  },
  {
    "start": "933000",
    "end": "933000"
  },
  {
    "text": "it's a combination of taking best practices looking across all the services and being able to push out to them what are the what those best",
    "start": "938399",
    "end": "944560"
  },
  {
    "text": "practices are and how to apply it and sometimes the best practices aren't things that teams necessarily want but",
    "start": "944560",
    "end": "950240"
  },
  {
    "text": "you know you can discuss it with them in the first case here what we've tried to do is you know they",
    "start": "950240",
    "end": "955360"
  },
  {
    "text": "talked today you know reid talked about we live in this world where we have to go by reservations and reservations are by zone by region right so we balance",
    "start": "955360",
    "end": "962880"
  },
  {
    "text": "across that our asg's balance we can still get a little bit out of alignment but at the same time you have to do that",
    "start": "962880",
    "end": "968639"
  },
  {
    "text": "by instance class so if you have a team over here that says hey this cc2 instance class is just hot i'm going to",
    "start": "968639",
    "end": "974079"
  },
  {
    "text": "go stand up 500 of it you know and it's like you know you can do that we need to get some reservations but it's not an area",
    "start": "974079",
    "end": "980000"
  },
  {
    "text": "that other people are in currently so we'll help them a little bit on the performance evaluation maybe it is a good instance class to move to or not",
    "start": "980000",
    "end": "985839"
  },
  {
    "text": "but if you look at our overall reservations split within aws probably about 40 percent of our",
    "start": "985839",
    "end": "991600"
  },
  {
    "text": "instances are of a specific class and all of our big services live within there and when i talked about that red",
    "start": "991600",
    "end": "997040"
  },
  {
    "text": "black push where you stand up two gigantic asgs run for like a day then take one down that gives us enough flex capacity where",
    "start": "997040",
    "end": "1004079"
  },
  {
    "text": "those teams can stand them up for a period of days and they don't have to go push us into on demand so if you can align your teams across fewer instance",
    "start": "1004079",
    "end": "1010959"
  },
  {
    "text": "types it tends to help in that regard and common classes are good too i don't know",
    "start": "1010959",
    "end": "1016639"
  },
  {
    "text": "if other people do conversions with with amazon it's something we've done infrequently but when you think about the large",
    "start": "1016639",
    "end": "1022800"
  },
  {
    "text": "you know large workload we have let's say that we encode a certain amount of data and we've just changed our encoding",
    "start": "1022800",
    "end": "1028160"
  },
  {
    "text": "model and we need a new type of instance class and we have a zillion of this type of class sometimes we can work out conversions",
    "start": "1028160",
    "end": "1035120"
  },
  {
    "text": "it's very infrequent and it's almost always within the same instance class but it's i think it's so infrequent i probably shouldn't even mention it",
    "start": "1035120",
    "end": "1042400"
  },
  {
    "text": "auto scale auto scale auto scale that's my absolute favorite thing so auto scaling your asgs especially if you you",
    "start": "1042400",
    "end": "1048400"
  },
  {
    "text": "have a bursty workload you know maybe you have a very flat workload a consistent amount of work over time and auto scaling doesn't benefit you we have",
    "start": "1048400",
    "end": "1054960"
  },
  {
    "text": "some teams that auto scale less like maybe our encoding team or some of our data science engineering teams",
    "start": "1054960",
    "end": "1061280"
  },
  {
    "text": "but everything that tracks with user activity is heavily sinusoidal within a given day and so what we do is we engage",
    "start": "1061280",
    "end": "1067360"
  },
  {
    "text": "the teams and we help them auto scan i'll talk about the benefits of that in a minute and then we try to get per instance",
    "start": "1067360",
    "end": "1073039"
  },
  {
    "text": "utilization up a little bit you know there's obviously the virtualization factor in there you don't want to push it too high and i'll talk a little bit",
    "start": "1073039",
    "end": "1078799"
  },
  {
    "text": "about through performance testing and squeeze tests we call them how people evaluate what are the right thresholds before they start degrading performance",
    "start": "1078799",
    "end": "1086640"
  },
  {
    "text": "and then the last one there when i talked about that um overlap where you have code pushes uh",
    "start": "1086640",
    "end": "1092080"
  },
  {
    "text": "you know we've worked with teams and they'll stand up to asgs at full capacity and they'll run it for a period of time until they're comfortable with",
    "start": "1092080",
    "end": "1097760"
  },
  {
    "text": "the new build and then they'll drop the old one away and over time we've tried to reduce that window a little bit because our instance",
    "start": "1097760",
    "end": "1103360"
  },
  {
    "text": "startup time is pretty quick right and so if there's a decision to roll back to a previous previous asg for a big",
    "start": "1103360",
    "end": "1109280"
  },
  {
    "text": "problem it's probably going to happen in the first few hours of the first day if you're two days out and you decide there's a bad problem and you have to",
    "start": "1109280",
    "end": "1115360"
  },
  {
    "text": "roll back to the old asg there's probably enough decision time involved in that you can spin the old asg back up so we try to have the teams",
    "start": "1115360",
    "end": "1121919"
  },
  {
    "text": "not run with multiple asgs at peak for more than maybe a day or so",
    "start": "1121919",
    "end": "1127919"
  },
  {
    "text": "so benefits of auto scaling you get this improved efficiency and availability you know if you don't use auto scaling",
    "start": "1128720",
    "end": "1135600"
  },
  {
    "text": "you're manually controlling your capacity and you have to make decisions about what to set your max value at and you can take a guess engineering teams",
    "start": "1135600",
    "end": "1142000"
  },
  {
    "text": "normally set that you know conservatively low or excessively high you know a lot of people don't want to be woken up so",
    "start": "1142000",
    "end": "1147919"
  },
  {
    "text": "they'll sit a little bit higher they'll say well i'm seeing each day i'm using this minute need as much cpu so i'm going to set my max at like",
    "start": "1147919",
    "end": "1154799"
  },
  {
    "text": "90 and i'll just lock my desired there as well so i'll be comfortable that i'm not",
    "start": "1154799",
    "end": "1160160"
  },
  {
    "text": "and our guest visitor somebody's behind that curtain um",
    "start": "1160480",
    "end": "1165919"
  },
  {
    "text": "and so people will set it arbitrarily high and it's and i'll talk why you don't really want to do that now this is the part that's interesting",
    "start": "1165919",
    "end": "1171840"
  },
  {
    "text": "if you're living in a reservation um a reservation world with your instances so you know when you think about capacity",
    "start": "1171840",
    "end": "1177520"
  },
  {
    "text": "planning whether it was in mainframes or open systems right they're teams that deal with capacity planning right they have to procure in advance they you know",
    "start": "1177520",
    "end": "1184640"
  },
  {
    "text": "optimize the workloads they determine what they're going to need for the next three months and they work with the teams and with cloud the you know the",
    "start": "1184640",
    "end": "1189840"
  },
  {
    "text": "perception is well it's a burst environment right everybody needs something they just stand it up and they're done with it and it mitigates",
    "start": "1189840",
    "end": "1195760"
  },
  {
    "text": "the need for someone who does formal capacity planning of the system and that's actually not the case when you",
    "start": "1195760",
    "end": "1200880"
  },
  {
    "text": "have reservations you've gone on you've purchased all this capacity and once you implement auto scaling a lot of teams",
    "start": "1200880",
    "end": "1206480"
  },
  {
    "text": "will say well you know why do i need to auto scale because all my partners are auto scaling on the same schedule right my api's scaling with my subscribers",
    "start": "1206480",
    "end": "1213440"
  },
  {
    "text": "scaling with my license system but what ends up happening and i'll talk about in a minute is you build up these troughs",
    "start": "1213440",
    "end": "1219280"
  },
  {
    "text": "of unused capacity that you can go out and figure out you have to creatively figure out how you can consume that it's pretty much free compute power you paid",
    "start": "1219280",
    "end": "1225840"
  },
  {
    "text": "for it but it's just going idle offline and then auto scaling another one is it basically insulates you from",
    "start": "1225840",
    "end": "1232400"
  },
  {
    "text": "unexpected bursts in demand so some of the teams that really like having auto scaling are like say customer support right there could be a big event that",
    "start": "1232400",
    "end": "1238480"
  },
  {
    "text": "happens something comes in or we have a big offer and there's a lot of calls that come in by setting auto scaling you have the",
    "start": "1238480",
    "end": "1245120"
  },
  {
    "text": "ability to dynamically grow and not be woken up when you hit that ceiling that you didn't expect to hit",
    "start": "1245120",
    "end": "1251360"
  },
  {
    "text": "when i put on here that changed services that scale to together stay together you know think about queuing analysis think",
    "start": "1251760",
    "end": "1257919"
  },
  {
    "text": "about all these series of queues they have a certain capacity when you're tuning something you'll you know make",
    "start": "1257919",
    "end": "1262960"
  },
  {
    "text": "the largest cue a little bit bigger or you'll opt it might reduce its service time to some aspect and it just moves the bottleneck downstream well",
    "start": "1262960",
    "end": "1268799"
  },
  {
    "text": "eventually someone's probably going to break or ideally they won't break they'll just be the bottleneck but what you do is once you start auto",
    "start": "1268799",
    "end": "1274880"
  },
  {
    "text": "scaling you know and i talked we have somewhere between say 20 and 30 services you want to have auto scaling down the",
    "start": "1274880",
    "end": "1280159"
  },
  {
    "text": "entire tree because then they can all adjust dynamically and sometimes when we have issues that's how we identify a new",
    "start": "1280159",
    "end": "1286400"
  },
  {
    "text": "service that might need to auto scale because they didn't have auto scaling set up originally we have a burst in activity and that service feels the pain",
    "start": "1286400",
    "end": "1292640"
  },
  {
    "text": "so then we get them on an auto scaling plan so here's those are the benefits so when",
    "start": "1292640",
    "end": "1298000"
  },
  {
    "start": "1298000",
    "end": "1298000"
  },
  {
    "text": "you look at the challenges it's sort of like a freeway right it's either full at times or it's empty at times and so when",
    "start": "1298000",
    "end": "1303679"
  },
  {
    "text": "you look at that graph down below i put that was fictitious but",
    "start": "1303679",
    "end": "1309360"
  },
  {
    "text": "i think it is fictitious it goes down to zero but each day at netflix we probably auto scale and usc somewhere between two",
    "start": "1309360",
    "end": "1315440"
  },
  {
    "text": "and four thousand instances that's about our flux based on auto scaling so when you think about that and you marry it",
    "start": "1315440",
    "end": "1320880"
  },
  {
    "text": "with the traffic we have you suddenly have all of that since that's unused reservation hours that's",
    "start": "1320880",
    "end": "1327280"
  },
  {
    "text": "all free compute time someone could be using if they knew how to get at it right and it's obviously not the old tp",
    "start": "1327280",
    "end": "1332320"
  },
  {
    "text": "teams and the people user facing it's probably other people in the organization so what we started to do recently i",
    "start": "1332320",
    "end": "1337760"
  },
  {
    "text": "don't think i have on the next slide no is we started working with our data",
    "start": "1337760",
    "end": "1342799"
  },
  {
    "text": "science team as an example and they have a lot of hadoop clusters so what they do now is they come in at midnight and they spin up",
    "start": "1342799",
    "end": "1348559"
  },
  {
    "text": "hundreds and hundreds of hadoop nodes in each of the azs and they do it in a balanced way so we don't get our reservations off balance but then for",
    "start": "1348559",
    "end": "1354559"
  },
  {
    "text": "about seven hours they basically have many many hundreds of free compute large systems our average heap size on our",
    "start": "1354559",
    "end": "1360640"
  },
  {
    "text": "applications is about 30 gigs at netflix we have a lot of very large java large heap java applications",
    "start": "1360640",
    "end": "1366480"
  },
  {
    "text": "and so the good news is the instance type that we have the majority of our services sort of gravitate around is",
    "start": "1366480",
    "end": "1371679"
  },
  {
    "text": "also an instance type that works well for a hadoop team and so they're basically getting free compute capacity at night and that's where the capacity",
    "start": "1371679",
    "end": "1378000"
  },
  {
    "text": "planning aspect comes back into it from a methodology perspective",
    "start": "1378000",
    "end": "1384960"
  },
  {
    "text": "um see am i doing on time i'm flying am i is it going up or down it's down",
    "start": "1384960",
    "end": "1391200"
  },
  {
    "text": "so when you work the different organizations you want to put auto scaling in place typically i put in here star with the largest services you",
    "start": "1391200",
    "end": "1397440"
  },
  {
    "text": "typically want to do that once you've identified what a good auto scaling methodology is you don't want to put the largest portion of your service",
    "start": "1397440",
    "end": "1402640"
  },
  {
    "text": "infrastructure at risk right away but once you want to see the benefits of auto scaling you know within netflix of these",
    "start": "1402640",
    "end": "1408640"
  },
  {
    "text": "services there's probably 10 that consume 50 of the demand right so those are the ones we work with for auto",
    "start": "1408640",
    "end": "1413840"
  },
  {
    "text": "scaling and it gives us gives us the big bang for the buck and then we start working downstream the",
    "start": "1413840",
    "end": "1418880"
  },
  {
    "text": "dependent services and also by doing that there tends to be a little bit more complexity in the upstream workloads and",
    "start": "1418880",
    "end": "1424799"
  },
  {
    "text": "the downstream teams can benefit from that knowledge they talk together we collect best practices from the teams we",
    "start": "1424799",
    "end": "1430080"
  },
  {
    "text": "push it out onto the wiki and sort of provide them guidance on how to evaluate what the best auto scaling approach is",
    "start": "1430080",
    "end": "1435840"
  },
  {
    "text": "then we also help them identify the metric and once you i don't know how many people do auto scaling in here",
    "start": "1435840",
    "end": "1443279"
  },
  {
    "text": "excellent it's probably about 15 or something that's good um i think it's something that's",
    "start": "1443279",
    "end": "1449039"
  },
  {
    "text": "sufficiently underused uh but it's it's just awesome and so when you work with the teams",
    "start": "1449039",
    "end": "1454880"
  },
  {
    "text": "there can be a fair amount of religious discussions about what the right metric is to to use should i use cpu should i",
    "start": "1454880",
    "end": "1460320"
  },
  {
    "text": "use my request rate should i use load average and you know netflix is an organization it's not my job to tell those teams what they should use my job",
    "start": "1460320",
    "end": "1466880"
  },
  {
    "text": "is to say well api is using this this other team's using this and these are the benefits of the up and down and a",
    "start": "1466880",
    "end": "1472080"
  },
  {
    "text": "lot of times they'll go off in almost all cases they'll arrive at the right decision and probably a better one",
    "start": "1472080",
    "end": "1477200"
  },
  {
    "text": "that i could make because they understand their model better themselves right their devops type type model and",
    "start": "1477200",
    "end": "1482240"
  },
  {
    "text": "so once they settle on the rate the the metric that they or the alarm that they want to consume for",
    "start": "1482240",
    "end": "1487760"
  },
  {
    "text": "their scaling policy um we have them set a more aggressive scale up versus scale down right it's",
    "start": "1487760",
    "end": "1493279"
  },
  {
    "text": "it's much more important to make sure we stay ahead of the workload and not have a diminished user experience",
    "start": "1493279",
    "end": "1498400"
  },
  {
    "text": "and then we have an open source library called servo so netflix gathers a huge amount of metric",
    "start": "1498400",
    "end": "1504080"
  },
  {
    "text": "information extremely large volumes and what we've done is we've built this",
    "start": "1504080",
    "end": "1509200"
  },
  {
    "text": "library that can take metrics that are captured by our monitoring framework and",
    "start": "1509200",
    "end": "1515120"
  },
  {
    "text": "it publishes them directly to cloudwatch and so then you can consume them cloudwatch can consume those as alarms",
    "start": "1515120",
    "end": "1520559"
  },
  {
    "text": "so if i set up a metric like oh my my q size for my you know this batch system",
    "start": "1520559",
    "end": "1526559"
  },
  {
    "text": "i'm going to publish the size of that queue up to cloudwatch using servo and then for auto scaling i want to make",
    "start": "1526559",
    "end": "1531760"
  },
  {
    "text": "sure that whenever my queue drops below in a certain amount i want to scale down or i want to scale back up so it gives",
    "start": "1531760",
    "end": "1536880"
  },
  {
    "text": "you the ability to move beyond just the metrics that cloudwatch exposes to you natively and it's extremely valuable for",
    "start": "1536880",
    "end": "1543200"
  },
  {
    "text": "us most of our scaling alarms are tied to rate-based metrics we find those work",
    "start": "1543200",
    "end": "1548559"
  },
  {
    "text": "pretty well so we validated with load tests and i'll",
    "start": "1548559",
    "end": "1554480"
  },
  {
    "start": "1551000",
    "end": "1551000"
  },
  {
    "text": "talk in a minute about some of the things you have to worry about with auto scaling and i have so much on auto scaling because that's the area where",
    "start": "1554480",
    "end": "1559840"
  },
  {
    "text": "we've had the biggest benefit in terms of our usage and then combined with the s3 price drop today we'll just spend",
    "start": "1559840",
    "end": "1565279"
  },
  {
    "text": "more time focusing on ec2 less time on s3 so in terms of validating with load",
    "start": "1565279",
    "end": "1570559"
  },
  {
    "text": "tests um we have that benefit of a cluster in multiple asgs and we have some proxies we built",
    "start": "1570559",
    "end": "1576240"
  },
  {
    "text": "so what teams will do is they will go into production and they will basically differentiate the traffic a bit and drive more load gradually to one of the",
    "start": "1576240",
    "end": "1582880"
  },
  {
    "text": "instances and watch the utilization watch the response time and they'll use that as their baseline of what they",
    "start": "1582880",
    "end": "1588320"
  },
  {
    "text": "should be using their alarm metric to and it's good because it's production data and it doesn't impact the user at all and they don't do it radically they",
    "start": "1588320",
    "end": "1594320"
  },
  {
    "text": "don't like really crank it over and see if it falls down the goal isn't to have a stress test it's just like a miniature load test and we call that a squeeze",
    "start": "1594320",
    "end": "1601120"
  },
  {
    "text": "test now auto scaling batch applications is a little bit different right so you have",
    "start": "1601120",
    "end": "1606799"
  },
  {
    "text": "auto scaling with scaling policies tied to rate metrics or load metrics and then you have scheduled actions and",
    "start": "1606799",
    "end": "1612799"
  },
  {
    "text": "that's what our current team that runs hadoop um is using and so that's you can uh it's sort of an extension to auto",
    "start": "1612799",
    "end": "1618640"
  },
  {
    "text": "scaling where within a given window the goal isn't to adjust your desired you can adjust the size of the box right",
    "start": "1618640",
    "end": "1624960"
  },
  {
    "text": "you're basically adjusting your min and your max and so you can say well at night i want hadoop to be able to go",
    "start": "1624960",
    "end": "1630240"
  },
  {
    "text": "up to 600 nodes and then at midnight or 6am i want to come back down to 100. so scheduled actions will let you",
    "start": "1630240",
    "end": "1636559"
  },
  {
    "text": "box things in a certain window rather than having to rely on a scaling policy and so we have a mixture of the two",
    "start": "1636559",
    "end": "1641760"
  },
  {
    "text": "right now and it's working out pretty well here's how we expose that information",
    "start": "1641760",
    "end": "1647919"
  },
  {
    "text": "through our our asgard tool which is sort of like aws console and so we have scaling policies and scheduled actions",
    "start": "1647919",
    "end": "1654960"
  },
  {
    "text": "that are both exposed to the engineers and so each time that we expose this and start um you know",
    "start": "1654960",
    "end": "1660320"
  },
  {
    "text": "advocating for its use uh in among the engineering teams we put up wikis we talk about best practices we keep a list",
    "start": "1660320",
    "end": "1666399"
  },
  {
    "text": "of the teams that are currently implementing it and the decisions they took well not really decisions but we",
    "start": "1666399",
    "end": "1671760"
  },
  {
    "text": "indicate the teams that they can go talk to if they want to get more more feedback on what they're doing",
    "start": "1671760",
    "end": "1676880"
  },
  {
    "start": "1673000",
    "end": "1673000"
  },
  {
    "text": "we are looking to extend our batch how should i say this we're going to",
    "start": "1676880",
    "end": "1683120"
  },
  {
    "text": "expand our batch auto scaling policy it's something we're working on right now so we talk about servo publishing",
    "start": "1683120",
    "end": "1688399"
  },
  {
    "text": "information up to the cloud when you saw in that previous asgard example it showed the number of instances or reservations we have",
    "start": "1688399",
    "end": "1695200"
  },
  {
    "text": "available that's also a metric we can consume right so right now it's just engineers consuming it through their eyeballs and saying well maybe i",
    "start": "1695200",
    "end": "1701200"
  },
  {
    "text": "shouldn't do this right now but in the future we're going to tie that to alarms and so our batch applications will be feeding off",
    "start": "1701200",
    "end": "1707679"
  },
  {
    "text": "available reservations and dynamically fill in the troughs we should have much less much less wastage in there",
    "start": "1707679",
    "end": "1714559"
  },
  {
    "text": "but that's not there yet here's an example of auto scaling profile examples i took from one um one",
    "start": "1714559",
    "end": "1721200"
  },
  {
    "start": "1717000",
    "end": "1717000"
  },
  {
    "text": "cluster over time yeah so on the left there that's a pretty healthy profile that tracks very closely with our daily",
    "start": "1721200",
    "end": "1727520"
  },
  {
    "text": "activity this is just one of the services um this is exposed by one of our metric system it's a number of",
    "start": "1727520",
    "end": "1732640"
  },
  {
    "text": "instances in there so it goes somewhere from as low as 60 up to about a 180 190",
    "start": "1732640",
    "end": "1737919"
  },
  {
    "text": "oh 210 on that one what you want to do is once you start playing with auto scaling to improve",
    "start": "1737919",
    "end": "1743520"
  },
  {
    "text": "your efficiency you want to go in and make sure that your policies are set up correctly because if you don't in the upper right",
    "start": "1743520",
    "end": "1749279"
  },
  {
    "text": "what you see is thrashing which is my whatever metric i've chosen for my alarm",
    "start": "1749279",
    "end": "1754799"
  },
  {
    "text": "is increasing at such a gradual rate that when i actually do a scale up i'm kicking my scale down rule and so in",
    "start": "1754799",
    "end": "1760640"
  },
  {
    "text": "these periods of slower growth you'll have instances come in and go out and go in and out and it's sort of a hassle it can cause some problems probably",
    "start": "1760640",
    "end": "1766799"
  },
  {
    "text": "functionally um you're also getting charged for all the instances you spin up in there right so you just want to validate that your uh",
    "start": "1766799",
    "end": "1773200"
  },
  {
    "text": "your auto scaling policy metrics are tuned appropriately and then you have the double jump and this is one um so it",
    "start": "1773200",
    "end": "1780240"
  },
  {
    "text": "really should have just gone up one increment there on the bottom but it actually added more instances and then it added additional ones and so the",
    "start": "1780240",
    "end": "1786880"
  },
  {
    "text": "trickiest factor i think in auto scaling to work with is what we call cool down which tells cloudwatch once you make a",
    "start": "1786880",
    "end": "1793039"
  },
  {
    "text": "change based on a scaling policy ignore evaluation and don't make any changes until this window has passed and so even",
    "start": "1793039",
    "end": "1800080"
  },
  {
    "text": "though amazon can spin up our instances in a matter of minutes i think adrian who's given a presentation this week he",
    "start": "1800080",
    "end": "1806080"
  },
  {
    "text": "did some analysis of how long it took to stand up you know 100 500 node clusters and it was our asgs and it was on the",
    "start": "1806080",
    "end": "1811520"
  },
  {
    "text": "order of you know minutes a few minutes here and there to get them all up but",
    "start": "1811520",
    "end": "1816559"
  },
  {
    "text": "that doesn't include the application startup time right when you think about the data that we have to deal with is netflix you know we have to deal with 10",
    "start": "1816559",
    "end": "1822720"
  },
  {
    "text": "000 titles we need to get that in a way where you can efficiently consume it so and we initially we initialize a bunch",
    "start": "1822720",
    "end": "1828960"
  },
  {
    "text": "of libraries to other services in the system like subscriber and other sources so your application startup time really",
    "start": "1828960",
    "end": "1835039"
  },
  {
    "text": "drives your cool down and when this double jump can happen is when there's a there's a change in the",
    "start": "1835039",
    "end": "1841120"
  },
  {
    "text": "startup profile of your application that causes your cooldown window to be exceeded so the new capacity you've",
    "start": "1841120",
    "end": "1847760"
  },
  {
    "text": "added has yet to reduce the metric and cloudwatch says oh you know i'm still violating this alarm and it adds another",
    "start": "1847760",
    "end": "1854000"
  },
  {
    "text": "10 or 20 percent it's not a big deal but we i mean we have asgs that scale up you",
    "start": "1854000",
    "end": "1859039"
  },
  {
    "text": "know above a thousand and they add in percent increments so if you're up at about 900 you do a double jump that's a",
    "start": "1859039",
    "end": "1864159"
  },
  {
    "text": "really big jump to go up so it's just something to be cognizant of and it's a feedback loop that internally",
    "start": "1864159",
    "end": "1869440"
  },
  {
    "text": "we're working on figuring out a way to consume that into one of our automated tools so that people get an",
    "start": "1869440",
    "end": "1875200"
  },
  {
    "text": "email saying your cooldown on your asg is set in appropriately based on what your current application startup time is",
    "start": "1875200",
    "end": "1880880"
  },
  {
    "text": "because they don't track that over time i mean they shouldn't have to but it's like a feedback loop for us",
    "start": "1880880",
    "end": "1887200"
  },
  {
    "start": "1887000",
    "end": "1887000"
  },
  {
    "text": "we obviously want to improve system utilization this is probably the next area we're sort of moving into from an",
    "start": "1887360",
    "end": "1892559"
  },
  {
    "text": "optimizing database usage pattern you know we're taking it in chunks right it's it's a journey and so the first one",
    "start": "1892559",
    "end": "1899120"
  },
  {
    "text": "was a line across relatively few instance types right get everybody using common pools second one was get auto",
    "start": "1899120",
    "end": "1905519"
  },
  {
    "text": "scaling broadly adopted third one was get the batch applications to efficiently use the trough",
    "start": "1905519",
    "end": "1911120"
  },
  {
    "text": "and now we're going to move a little bit more into the area of you know we've tackled those three we feel pretty good about it now we're going to actually go",
    "start": "1911120",
    "end": "1917200"
  },
  {
    "text": "and work on utilization and get those applications you know we have batch applications that are running at like 60",
    "start": "1917200",
    "end": "1922640"
  },
  {
    "text": "cpu we want to get it to like over 90. you know for oltp we're a little bit less strict right now because being a",
    "start": "1922640",
    "end": "1928399"
  },
  {
    "text": "service architecture it isn't necessarily cpu related related weights right you can be blocking on a lot of other services so there's a lot more",
    "start": "1928399",
    "end": "1934320"
  },
  {
    "text": "analysis analysis that has to go into making sure utilization is appropriate",
    "start": "1934320",
    "end": "1941120"
  },
  {
    "start": "1941000",
    "end": "1941000"
  },
  {
    "text": "all right take some water",
    "start": "1941440",
    "end": "1945559"
  },
  {
    "text": "so the second service i'm going to talk about is sqs and these are a little lighter than the ec2 stuff",
    "start": "1949039",
    "end": "1954640"
  },
  {
    "text": "so we use sqs a ton all right we push a lot of messages around a lot of it information feeds straight off the servers we send stuff",
    "start": "1954640",
    "end": "1960880"
  },
  {
    "text": "into chukwu it goes on the cues goes into like a big data oven we call it for analysis",
    "start": "1960880",
    "end": "1967200"
  },
  {
    "text": "and so you know the cost is really a function of the data transfer volume and so even",
    "start": "1967200",
    "end": "1973440"
  },
  {
    "text": "though the messages are typically small a lot of our optimizations have been around reducing the request rate right",
    "start": "1973440",
    "end": "1979039"
  },
  {
    "text": "because we just get up to touch five volumes right so you can see in cube like q1 of 2012 we were pushing about 5",
    "start": "1979039",
    "end": "1984880"
  },
  {
    "text": "million messages a day into sqs and it was getting a little bit untenable you know just it was a lot a lot of data",
    "start": "1984880",
    "end": "1990480"
  },
  {
    "text": "everybody's throwing billions around so it's not that big and so what we did is we started adopting the um the api batch",
    "start": "1990480",
    "end": "1998000"
  },
  {
    "text": "capabilities as they came out so amazon behind the scene is obviously always improving ways for efficiency for your",
    "start": "1998000",
    "end": "2003760"
  },
  {
    "text": "end user right and so i'll talk a little bit about an s3 as well but we have a platform team and",
    "start": "2003760",
    "end": "2010000"
  },
  {
    "text": "what we do is when people are going to use xus or they're going to use s3 we try to incorporate the logic that deals",
    "start": "2010000",
    "end": "2015279"
  },
  {
    "text": "with the access patterns and the retention times and all that into the platform libraries so that each service",
    "start": "2015279",
    "end": "2020399"
  },
  {
    "text": "team doesn't have to think about well how should i efficiently store stuff in s3 or how should i manage my my queues",
    "start": "2020399",
    "end": "2025600"
  },
  {
    "text": "in sqs right they worry about a little bit but we don't want 20 teams to have to figure out that they need to implement a",
    "start": "2025600",
    "end": "2031519"
  },
  {
    "text": "batch get functionality for sqs it just probably wouldn't happen so this goes back to the first part of",
    "start": "2031519",
    "end": "2038320"
  },
  {
    "start": "2035000",
    "end": "2035000"
  },
  {
    "text": "the year and that was our request per day and so you can see as we adopted various aspects of it so we implemented",
    "start": "2038320",
    "end": "2044480"
  },
  {
    "text": "batch delete and then we started the adoption of batch send and then basically later in the year we",
    "start": "2044480",
    "end": "2049919"
  },
  {
    "text": "reached the point in time where we had adopted as much of the batch capability of the sqs access as we could in our platform libraries and so the requests",
    "start": "2049919",
    "end": "2056720"
  },
  {
    "text": "per day and that pretty much tracks very closely with cost went way down and i will point out that in this time the",
    "start": "2056720",
    "end": "2062638"
  },
  {
    "text": "activity on our system probably went up like 40 30 or 40 percent so it isn't just a level workload so if you use sqs",
    "start": "2062639",
    "end": "2069200"
  },
  {
    "text": "a lot my recommendation is make sure that you're leveraging the batch capabilities of the aws offering",
    "start": "2069200",
    "end": "2076960"
  },
  {
    "start": "2077000",
    "end": "2077000"
  },
  {
    "text": "so s3 buckets uh s3 i'm glad they announced that cost reduction today but s3 usage can take",
    "start": "2077599",
    "end": "2083760"
  },
  {
    "text": "off quickly right s3 is sort of like your garage you just put stuff in there now with amazon it's probably not going",
    "start": "2083760",
    "end": "2089200"
  },
  {
    "text": "to fill up but you get to a point in time where suddenly the cost of s3 are a problem for you and you have to go clean it out",
    "start": "2089200",
    "end": "2095200"
  },
  {
    "text": "and everybody has their own little buckets and it's not a very pleasant process because there tend to be lots of buckets",
    "start": "2095200",
    "end": "2100800"
  },
  {
    "text": "so um you know our goal was basically to reduce the payload size and also reduce the number of accesses right and so we",
    "start": "2100800",
    "end": "2107839"
  },
  {
    "text": "can do that through our platform libraries i'll talk about one in a minute and making sure to age your data out with ttl our data has a relatively",
    "start": "2107839",
    "end": "2114640"
  },
  {
    "text": "well-known life cycle in terms of retention policy and so even though deleting things from s3 is free scanning to find them is not",
    "start": "2114640",
    "end": "2122640"
  },
  {
    "text": "so what you do is when we put our log data out there we set a ttl on that bucket like okay this data can or that",
    "start": "2122640",
    "end": "2128000"
  },
  {
    "text": "the data itself this data can survive for three weeks if people need it they can go out there and get it or extend",
    "start": "2128000",
    "end": "2133119"
  },
  {
    "text": "that retention but in general you want to put in place your sort of purging policy and it hasn't been a problem for",
    "start": "2133119",
    "end": "2138480"
  },
  {
    "text": "us especially as we've moved more of our log data to go into like uh you know like a data oven slash hadoop type",
    "start": "2138480",
    "end": "2144160"
  },
  {
    "text": "environment where people are getting more you know they run map reduce jobs they get more useful information out of that than going and finding logs",
    "start": "2144160",
    "end": "2151839"
  },
  {
    "text": "in general um when you have large bursts in s3 it's worthwhile digging in and seeing what",
    "start": "2151839",
    "end": "2157040"
  },
  {
    "text": "the real cause for it is we had a case where um it's one of our persistence tiers",
    "start": "2157040",
    "end": "2162480"
  },
  {
    "text": "i mean we are up and i don't know how many petabytes of archive storage and when you look back at the the trend over",
    "start": "2162480",
    "end": "2168160"
  },
  {
    "text": "many months you would notice that it doesn't trend very well with our workload right we're like there was no",
    "start": "2168160",
    "end": "2173520"
  },
  {
    "text": "reason for that to happen and so working with the various teams it turns out that there was a mis-configuration and the",
    "start": "2173520",
    "end": "2180000"
  },
  {
    "text": "policy of a 15-day or 30-day retention wasn't being applied so it was just building up and building up and it's one of our largest tiers from a data",
    "start": "2180000",
    "end": "2186079"
  },
  {
    "text": "perspective and so then they changed it and over one weekend i think we cut the number of",
    "start": "2186079",
    "end": "2191280"
  },
  {
    "text": "petabytes in half i mean and when we do things like that it actually triggers alarms like our",
    "start": "2191280",
    "end": "2197040"
  },
  {
    "text": "teams that deal with reliability start calling us aws will contact us like is something wrong where did i you know you",
    "start": "2197040",
    "end": "2203359"
  },
  {
    "text": "just cut out half of your s3 data because that's that's the size of the data we move around so when you have things that run off keep",
    "start": "2203359",
    "end": "2210000"
  },
  {
    "text": "an eye on it and so we did have a case once where people had misconfigured their security",
    "start": "2210000",
    "end": "2215040"
  },
  {
    "text": "for access to the s3 bucket right because you have to authenticate with with an amazon key and it wasn't caught right away it was",
    "start": "2215040",
    "end": "2221200"
  },
  {
    "text": "only a subset of the services but we were getting a huge amount of auth fails each of those was a charge right it was",
    "start": "2221200",
    "end": "2227520"
  },
  {
    "text": "in the order of millions a day like let me put my data only put my data let's put my data and it just kept ringing up the bill for us so once we found that we",
    "start": "2227520",
    "end": "2234640"
  },
  {
    "text": "took care of that and then you deal with really large files um it'll break it down into a multi-part upload",
    "start": "2234640",
    "end": "2240560"
  },
  {
    "text": "um look at this but i think each part is really considered an access right so you",
    "start": "2240560",
    "end": "2245680"
  },
  {
    "text": "can think about i want to put a lot of data out there but there's a way for you to reduce your data before you put it out there in an easy fashion just put",
    "start": "2245680",
    "end": "2250960"
  },
  {
    "text": "less out there and it also helps with the it's real common sense but just um put less data out there if you can",
    "start": "2250960",
    "end": "2258000"
  },
  {
    "text": "so logs became a real problem for us over time um in terms of our s3 usage that was our biggest uh",
    "start": "2258000",
    "end": "2264160"
  },
  {
    "text": "consumer of s3 capacity for a while and so the way that we addressed it i talked about as we go through platform",
    "start": "2264160",
    "end": "2270079"
  },
  {
    "text": "libraries so everybody who wants to put data into s3 uses our logging libraries and we have a utility called like ec2",
    "start": "2270079",
    "end": "2276800"
  },
  {
    "text": "log rotate something along those lines and we actually age data out we set the expiration so people don't have to think",
    "start": "2276800",
    "end": "2282640"
  },
  {
    "text": "about their log data and you effectively manage it behind the scenes i think probably less than you know one half of one percent of the",
    "start": "2282640",
    "end": "2289200"
  },
  {
    "text": "data was looked at once a week actually now that we're redirecting that data off through check one into our analytics",
    "start": "2289200",
    "end": "2294560"
  },
  {
    "text": "system people are getting a lot more value out of that data than having it go just into s3 and sit there maybe it ties",
    "start": "2294560",
    "end": "2299920"
  },
  {
    "text": "into some of the i saw that presentation earlier where they feed from s3 through emr and into some other systems so maybe",
    "start": "2299920",
    "end": "2306880"
  },
  {
    "text": "you know getting that data that could have more value out of an s3 bucket or at least getting people to access it more is important",
    "start": "2306880",
    "end": "2314720"
  },
  {
    "start": "2314000",
    "end": "2314000"
  },
  {
    "text": "so performance testing we we run load tests ourselves",
    "start": "2314880",
    "end": "2320320"
  },
  {
    "text": "we tend to run them more frequently when we're doing a new service release we want to validate the auto scaling capabilities um you know the size of the",
    "start": "2320320",
    "end": "2327520"
  },
  {
    "text": "cassandra cluster the size of uh our memcache extension called evcash and and so we built a framework that",
    "start": "2327520",
    "end": "2334079"
  },
  {
    "text": "uses jenkins jenkins is our build system and behind the scenes it actually you specify a bunch of",
    "start": "2334079",
    "end": "2340400"
  },
  {
    "text": "characteristics how many instances to drive the load the jmeter test plan where your data sources are",
    "start": "2340400",
    "end": "2345599"
  },
  {
    "text": "the jenkins job will spin up instantiate all the instances push the data out to it run the test",
    "start": "2345599",
    "end": "2351280"
  },
  {
    "text": "suck the data back and bring it back to the server for analysis it's something where we want to open source it it's a",
    "start": "2351280",
    "end": "2356720"
  },
  {
    "text": "little too brittle right now and so we're going to be spending probably the next year sort of refactoring making it more usable and my hope is in the long",
    "start": "2356720",
    "end": "2362480"
  },
  {
    "text": "run we can we can get that out to people because it really is a luxury if you guys have done that before just to spin",
    "start": "2362480",
    "end": "2368400"
  },
  {
    "text": "up a ton of instances for a load test you know you can almost run production scale on things",
    "start": "2368400",
    "end": "2373520"
  },
  {
    "text": "it also helps you find out where the limiting resources without having to be in production so we have one situation",
    "start": "2373520",
    "end": "2379359"
  },
  {
    "text": "where one of our services actually pushes so much data that it saturates the network interfaces before we saturate the",
    "start": "2379359",
    "end": "2385359"
  },
  {
    "text": "capacity of the asg that's driving the load test so we had to stand up like you know 150 instances to drive against 100",
    "start": "2385359",
    "end": "2392640"
  },
  {
    "text": "nodes or something else so it's good at helping you get a resource profile on your applications as well",
    "start": "2392640",
    "end": "2399280"
  },
  {
    "text": "and then squeeze tests i talked about you know we run canaries in production a lot of companies do we also there's a",
    "start": "2399280",
    "end": "2405359"
  },
  {
    "text": "huge amount of functional testing that's performed by the teams on themselves back to the performance testing aspect",
    "start": "2405359",
    "end": "2411040"
  },
  {
    "text": "what we're doing now is we have it so within the jenkins job when it gets to the end uh they can specify which",
    "start": "2411040",
    "end": "2416960"
  },
  {
    "text": "performance test to run it'll take the new mi it's in the bakery already cause you have an automatic bakery that pushes our builds right out registers it with",
    "start": "2416960",
    "end": "2423040"
  },
  {
    "text": "aws it will spin up the instance from the performance test and collect the results so it really should be a lights",
    "start": "2423040",
    "end": "2428160"
  },
  {
    "text": "out from from build through performance test pretty soon",
    "start": "2428160",
    "end": "2432880"
  },
  {
    "text": "so here's our results compared to about 10 months ago we've",
    "start": "2433839",
    "end": "2438880"
  },
  {
    "text": "doubled our traffic in terms of activity on the system and we're using the same amount of aws resource right so it's",
    "start": "2438880",
    "end": "2444319"
  },
  {
    "text": "like you start with a big piece of the pie in our case it was ec2 you get auto scaling and you start following that",
    "start": "2444319",
    "end": "2449839"
  },
  {
    "text": "process right it's like a weight loss program you just work through the steps and at the end of it you have all this additional capacity",
    "start": "2449839",
    "end": "2456079"
  },
  {
    "text": "and it puts us in a very good position going forward not only do we have a much better understanding of our workload and each of the teams have an understanding",
    "start": "2456079",
    "end": "2462000"
  },
  {
    "text": "of their workload but we have that additional capacity we need as our business continues to grow",
    "start": "2462000",
    "end": "2467440"
  },
  {
    "text": "you know optimize ec2 that's really worked teams are on board you might have a team that really wants this one instance type",
    "start": "2467440",
    "end": "2473599"
  },
  {
    "text": "but you can help them you know run performance studies and verify this other instance type works just as well for them even if they need more right",
    "start": "2473599",
    "end": "2479520"
  },
  {
    "text": "like maybe instead of 100 instances they need 200 but if it fits with the fewer instance classes we're trying to stick",
    "start": "2479520",
    "end": "2485359"
  },
  {
    "text": "with excuse me it's usually something we try to bring in and pass that around to get it",
    "start": "2485359",
    "end": "2491680"
  },
  {
    "text": "formalized with people and then this batch activity is really turning out to be great you know our one",
    "start": "2491680",
    "end": "2496800"
  },
  {
    "text": "concern is since we're using scheduled actions if there happened to be a bunch of really big pushes in production you know we",
    "start": "2496800",
    "end": "2503200"
  },
  {
    "text": "aren't necessarily saying don't stand up hadoop so we could hit some on demand but we've just started doing this in the past few weeks",
    "start": "2503200",
    "end": "2509440"
  },
  {
    "text": "i think once we get the capabilities in there to have like a little check beforehand of what the spare reservations are",
    "start": "2509440",
    "end": "2515119"
  },
  {
    "text": "we'll be able to handle that much better and you know the number one thing i've seen at netflix compared to other",
    "start": "2515119",
    "end": "2520240"
  },
  {
    "text": "companies i've been at is we have no constraints on the engineering teams regarding deployment right capacity",
    "start": "2520240",
    "end": "2526079"
  },
  {
    "text": "management none of that right so think about and you guys probably have this too where how fast can you develop new",
    "start": "2526079",
    "end": "2531839"
  },
  {
    "text": "code if you don't have to worry about infrastructure planning right and that's sort of a you know a curve sander and a",
    "start": "2531839",
    "end": "2537280"
  },
  {
    "text": "benefit but in our case you know our small team that works on evaluating stuff manually getting the tooling out",
    "start": "2537280",
    "end": "2542560"
  },
  {
    "text": "there our goal is to really get out of the way the engineers and it's helped us with our agility we just crank code out there",
    "start": "2542560",
    "end": "2547839"
  },
  {
    "text": "we get new features like i'm i'm super amazed that in like six weeks we can replace the or eight weeks we can",
    "start": "2547839",
    "end": "2553359"
  },
  {
    "text": "replace the entire cue system you know like your playlist and your list of movies like have the entire back end",
    "start": "2553359",
    "end": "2558560"
  },
  {
    "text": "completely swapped out run through performance tests and the team before people got it running in production in like two months right and they couldn't",
    "start": "2558560",
    "end": "2564800"
  },
  {
    "text": "have done that if they had to go through a procurement cycle and say well in six months i want to get this much capacity",
    "start": "2564800",
    "end": "2570079"
  },
  {
    "text": "so it was great and i think the engineers appreciate it because they don't like running out of capacity themselves",
    "start": "2570079",
    "end": "2576000"
  },
  {
    "text": "and i you know when you start talking to the teams about performance and auto scaling and managing their resources",
    "start": "2576000",
    "end": "2582160"
  },
  {
    "text": "i've had very few engineers that have not taken a positive approach to that they like getting involved in performance their application it's a",
    "start": "2582160",
    "end": "2588000"
  },
  {
    "text": "nice break from the day-to-day of um coding and dealing with some more of the production facing aspects",
    "start": "2588000",
    "end": "2594720"
  },
  {
    "text": "there's that okay here's my plug for netflix open source you guys will probably hear this a little bit this week um wrestling",
    "start": "2594720",
    "end": "2601119"
  },
  {
    "text": "who's down here runs a couple of teams including cassandra is a big driver of our open source effort we have a large",
    "start": "2601119",
    "end": "2606800"
  },
  {
    "text": "amount of open source projects and people say well is it a risky to give so much stuff to open source but you know you aren't",
    "start": "2606800",
    "end": "2612400"
  },
  {
    "text": "going to see our recommendation algorithms on open source but if it's anything related to making the platform",
    "start": "2612400",
    "end": "2617599"
  },
  {
    "text": "easier to use right like making cassandra more durable making memcache replicate across zones those type of",
    "start": "2617599",
    "end": "2622800"
  },
  {
    "text": "things you'll see that come out as open source and it's been a really big positive us for us within the company",
    "start": "2622800",
    "end": "2628800"
  },
  {
    "text": "and a big factor is the code is a lot cleaner you know when people are going to open source stuff they go back and they start digging through it and",
    "start": "2628800",
    "end": "2634160"
  },
  {
    "text": "they're like i really shouldn't be doing this you know because it's a point of pride for them so uh it's it's a big factor for us",
    "start": "2634160",
    "end": "2641280"
  },
  {
    "start": "2640000",
    "end": "2640000"
  },
  {
    "text": "here's an example of all of our open source projects it'll be in the deck later if you want to check it out some of them are already out on github",
    "start": "2641280",
    "end": "2647599"
  },
  {
    "text": "you can search for our tech blog every time we do an open source release like last week we released uh",
    "start": "2647599",
    "end": "2653200"
  },
  {
    "text": "histrix which is a dependency command framework we use internally based on sort of mike nygard's dependency command",
    "start": "2653200",
    "end": "2658880"
  },
  {
    "text": "model and uh so we open sourced that last week and some of the others that are in",
    "start": "2658880",
    "end": "2664079"
  },
  {
    "text": "flight like coming soon there aren't dates on those but you know anytime you're going to do something i hear this like i saw the yelp somebody from yelp",
    "start": "2664079",
    "end": "2671119"
  },
  {
    "text": "was talking a bit before and they had some really cool open source things too so you know anytime you guys are looking to to implement something new that",
    "start": "2671119",
    "end": "2677520"
  },
  {
    "text": "you're going to do with aws always check around at the open source stuff it's really something we put a lot of effort on",
    "start": "2677520",
    "end": "2684560"
  },
  {
    "text": "here's the schedule there's a lot of netflix presentations so i just talked about managing aws resources today right",
    "start": "2684720",
    "end": "2690319"
  },
  {
    "text": "but if you attend even a subset or a large part of these you're going to know just about everything about our architecture and",
    "start": "2690319",
    "end": "2696160"
  },
  {
    "text": "how we run like a very high performance scalable and fault tolerant system i had someone last night come by the booth and",
    "start": "2696160",
    "end": "2702400"
  },
  {
    "text": "say yeah that guy that memcached thing you guys are doing and some of that other stuff like like why aren't other people",
    "start": "2702400",
    "end": "2708079"
  },
  {
    "text": "doing that you know why why not and it's like you know it's just within our organization we really focus on taking",
    "start": "2708079",
    "end": "2713359"
  },
  {
    "text": "the tooling improving it giving it back to the community and so it all plays into our overall",
    "start": "2713359",
    "end": "2719680"
  },
  {
    "text": "picture if we find that there's a certain you know availability limitation of aws we'll figure out a way in three to six",
    "start": "2719680",
    "end": "2725359"
  },
  {
    "text": "months or whatever time frame to solve it by putting something in place to take care of that right so you might have heard of like pre-m which is what we use",
    "start": "2725359",
    "end": "2731359"
  },
  {
    "text": "to access cassandra we continually add logic in that to make it more of an efficient and you know more effective",
    "start": "2731359",
    "end": "2737040"
  },
  {
    "text": "data access layer um so we're gonna have a bunch of talks this week you already heard reed hastings and myself",
    "start": "2737040",
    "end": "2744480"
  },
  {
    "text": "and that's it and we have five minutes does anybody have any",
    "start": "2744960",
    "end": "2750960"
  }
]
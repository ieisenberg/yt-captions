[
  {
    "text": "my name is Antonio Rodriguez and I work",
    "start": "640",
    "end": "2720"
  },
  {
    "text": "as a principal genative AI solutions",
    "start": "2720",
    "end": "4720"
  },
  {
    "text": "architect in the Amazon Bedrock",
    "start": "4720",
    "end": "7080"
  },
  {
    "text": "team we are going to see a demo about",
    "start": "7080",
    "end": "9920"
  },
  {
    "text": "Amazon Bedrock prom management prom",
    "start": "9920",
    "end": "12639"
  },
  {
    "text": "management is a feature that allows you",
    "start": "12639",
    "end": "14320"
  },
  {
    "text": "to create store and optimize prompts",
    "start": "14320",
    "end": "17520"
  },
  {
    "text": "that you can then use in all of your",
    "start": "17520",
    "end": "20199"
  },
  {
    "text": "applications you can have a prom catalog",
    "start": "20199",
    "end": "22560"
  },
  {
    "text": "as part of the feature that is provided",
    "start": "22560",
    "end": "24400"
  },
  {
    "text": "to you as an added value without",
    "start": "24400",
    "end": "28240"
  },
  {
    "text": "additional cost we can create the",
    "start": "28240",
    "end": "30720"
  },
  {
    "text": "prompts directly from the console or",
    "start": "30720",
    "end": "32719"
  },
  {
    "text": "using the SDK APIs in this case I'm",
    "start": "32719",
    "end": "35920"
  },
  {
    "text": "going to create a classification prompt",
    "start": "35920",
    "end": "38399"
  },
  {
    "text": "in example I can create my name and I",
    "start": "38399",
    "end": "42160"
  },
  {
    "text": "can say this prompt is for",
    "start": "42160",
    "end": "47399"
  },
  {
    "text": "classification of incoming",
    "start": "47399",
    "end": "51320"
  },
  {
    "text": "orders i can access create and then I'm",
    "start": "51320",
    "end": "54719"
  },
  {
    "text": "ready to use it and test it in the",
    "start": "54719",
    "end": "56960"
  },
  {
    "text": "console here I have a sample text that I",
    "start": "56960",
    "end": "60399"
  },
  {
    "text": "can replace with my own variables and my",
    "start": "60399",
    "end": "62399"
  },
  {
    "text": "own uh template in this case I can",
    "start": "62399",
    "end": "66760"
  },
  {
    "text": "say",
    "start": "66760",
    "end": "69320"
  },
  {
    "text": "classify the",
    "start": "69320",
    "end": "71400"
  },
  {
    "text": "following",
    "start": "71400",
    "end": "73000"
  },
  {
    "text": "orders according to their",
    "start": "73000",
    "end": "76360"
  },
  {
    "text": "importance and then I can add in example",
    "start": "76360",
    "end": "79840"
  },
  {
    "text": "any type of variables later on I can say",
    "start": "79840",
    "end": "85040"
  },
  {
    "text": "answer",
    "start": "85040",
    "end": "87560"
  },
  {
    "text": "in format and then it will expose that",
    "start": "87560",
    "end": "91600"
  },
  {
    "text": "format at the end as you can see it",
    "start": "91600",
    "end": "94079"
  },
  {
    "text": "created the test variables automatically",
    "start": "94079",
    "end": "95840"
  },
  {
    "text": "for me and I can create more complicated",
    "start": "95840",
    "end": "98720"
  },
  {
    "text": "prompts including system tools and other",
    "start": "98720",
    "end": "101479"
  },
  {
    "text": "parameters i can select a model in",
    "start": "101479",
    "end": "103920"
  },
  {
    "text": "example that I want this prompt to be",
    "start": "103920",
    "end": "105520"
  },
  {
    "text": "used for example I could say this is a",
    "start": "105520",
    "end": "108840"
  },
  {
    "text": "Nova",
    "start": "108840",
    "end": "110759"
  },
  {
    "text": "Prompt and then I can set influence",
    "start": "110759",
    "end": "114119"
  },
  {
    "text": "parameters and so on and so",
    "start": "114119",
    "end": "116600"
  },
  {
    "text": "forth you can test it right away from",
    "start": "116600",
    "end": "119040"
  },
  {
    "text": "the console in example I can access test",
    "start": "119040",
    "end": "122479"
  },
  {
    "text": "in this case I will have to pass some",
    "start": "122479",
    "end": "124159"
  },
  {
    "text": "variables uh I would say",
    "start": "124159",
    "end": "126520"
  },
  {
    "text": "orders in",
    "start": "126520",
    "end": "129239"
  },
  {
    "text": "example",
    "start": "129239",
    "end": "131239"
  },
  {
    "text": "domestic",
    "start": "131239",
    "end": "133640"
  },
  {
    "text": "purchase international",
    "start": "133640",
    "end": "136760"
  },
  {
    "text": "order and then the format can be a",
    "start": "136760",
    "end": "140440"
  },
  {
    "text": "list so in this case I'm it's going to",
    "start": "140440",
    "end": "143920"
  },
  {
    "text": "replace or inject automatically my",
    "start": "143920",
    "end": "146640"
  },
  {
    "text": "variables into my prompt template and",
    "start": "146640",
    "end": "149360"
  },
  {
    "text": "then it will test it right away",
    "start": "149360",
    "end": "152640"
  },
  {
    "text": "once I'm happy with my prompt I can save",
    "start": "152640",
    "end": "154720"
  },
  {
    "text": "it and I can also create versions of it",
    "start": "154720",
    "end": "156959"
  },
  {
    "text": "so that I can work with those and I can",
    "start": "156959",
    "end": "159280"
  },
  {
    "text": "also compare different variants of the",
    "start": "159280",
    "end": "161040"
  },
  {
    "text": "prompt side to side by comparing those",
    "start": "161040",
    "end": "164400"
  },
  {
    "text": "uh side to side variants I can in",
    "start": "164400",
    "end": "166400"
  },
  {
    "text": "example start doing optimizations or",
    "start": "166400",
    "end": "168560"
  },
  {
    "text": "variations so that I can compare the",
    "start": "168560",
    "end": "170640"
  },
  {
    "text": "performance of those and run tests again",
    "start": "170640",
    "end": "172959"
  },
  {
    "text": "all of",
    "start": "172959",
    "end": "174120"
  },
  {
    "text": "them let's explore a couple of uh more",
    "start": "174120",
    "end": "176959"
  },
  {
    "text": "complicated prompts here you can see a",
    "start": "176959",
    "end": "179120"
  },
  {
    "text": "prompt that is uh for healthcare in this",
    "start": "179120",
    "end": "181519"
  },
  {
    "text": "case uh we have a system instruction",
    "start": "181519",
    "end": "183599"
  },
  {
    "text": "already added we have a user and",
    "start": "183599",
    "end": "186319"
  },
  {
    "text": "assistant messages added here and then a",
    "start": "186319",
    "end": "189360"
  },
  {
    "text": "new input that I want to work out on",
    "start": "189360",
    "end": "191680"
  },
  {
    "text": "this prompt in this case for uh",
    "start": "191680",
    "end": "193440"
  },
  {
    "text": "classifying healthcare patients u",
    "start": "193440",
    "end": "196480"
  },
  {
    "text": "according to the criteria that I'm",
    "start": "196480",
    "end": "198080"
  },
  {
    "text": "passing in this f uh future example that",
    "start": "198080",
    "end": "201200"
  },
  {
    "text": "you",
    "start": "201200",
    "end": "202040"
  },
  {
    "text": "see we also are using claw 3.5 uh 3.7",
    "start": "202040",
    "end": "206560"
  },
  {
    "text": "set but you could use any of the models",
    "start": "206560",
    "end": "208640"
  },
  {
    "text": "available in Amazon",
    "start": "208640",
    "end": "210360"
  },
  {
    "text": "bedrock and as you can see we also have",
    "start": "210360",
    "end": "213680"
  },
  {
    "text": "a tool definition so that we can uh keep",
    "start": "213680",
    "end": "216400"
  },
  {
    "text": "track of our tool specs for the case",
    "start": "216400",
    "end": "219200"
  },
  {
    "text": "that we are actually doing tool use or",
    "start": "219200",
    "end": "221200"
  },
  {
    "text": "function calling with our",
    "start": "221200",
    "end": "224640"
  },
  {
    "text": "prompts i can also set variables so that",
    "start": "224920",
    "end": "227680"
  },
  {
    "text": "I can test it right away as uh we saw",
    "start": "227680",
    "end": "229680"
  },
  {
    "text": "before and so on and so forth",
    "start": "229680",
    "end": "232879"
  },
  {
    "text": "now the best thing of uh working with",
    "start": "232879",
    "end": "234799"
  },
  {
    "text": "this uh type of uh uh prom management",
    "start": "234799",
    "end": "237519"
  },
  {
    "text": "interfaces is that I can actually",
    "start": "237519",
    "end": "239840"
  },
  {
    "text": "optimize the models right away so that I",
    "start": "239840",
    "end": "242319"
  },
  {
    "text": "can in example select a model like cloud",
    "start": "242319",
    "end": "244319"
  },
  {
    "text": "uh 3.5 haiku and then I can ask it to",
    "start": "244319",
    "end": "247439"
  },
  {
    "text": "optimize for that model this helps me",
    "start": "247439",
    "end": "250400"
  },
  {
    "text": "not only starting from scratch when I",
    "start": "250400",
    "end": "252640"
  },
  {
    "text": "have a new prompt that I want to",
    "start": "252640",
    "end": "253920"
  },
  {
    "text": "optimize uh into a better version that",
    "start": "253920",
    "end": "256079"
  },
  {
    "text": "provides better quality of my outputs",
    "start": "256079",
    "end": "258160"
  },
  {
    "text": "but it can also help me migrating from",
    "start": "258160",
    "end": "260239"
  },
  {
    "text": "an existing model to another so if I",
    "start": "260239",
    "end": "262960"
  },
  {
    "text": "click on optimize it will actually start",
    "start": "262960",
    "end": "265680"
  },
  {
    "text": "running and uh just in a few seconds are",
    "start": "265680",
    "end": "268080"
  },
  {
    "text": "going to have a new version of the",
    "start": "268080",
    "end": "269919"
  },
  {
    "text": "prompt that is uh recommended for",
    "start": "269919",
    "end": "271759"
  },
  {
    "text": "improving the quality according to the",
    "start": "271759",
    "end": "273919"
  },
  {
    "text": "target model that I have selected in",
    "start": "273919",
    "end": "275919"
  },
  {
    "text": "this case I have selected clot 35 Iiku",
    "start": "275919",
    "end": "279360"
  },
  {
    "text": "so as you can see it is actually",
    "start": "279360",
    "end": "280960"
  },
  {
    "text": "following the best practices of entropic",
    "start": "280960",
    "end": "283360"
  },
  {
    "text": "for making sure that the prompt is",
    "start": "283360",
    "end": "285280"
  },
  {
    "text": "passed with the proper XML tagging the",
    "start": "285280",
    "end": "287600"
  },
  {
    "text": "instructions clearly defined and",
    "start": "287600",
    "end": "289680"
  },
  {
    "text": "actually asking what is exactly the",
    "start": "289680",
    "end": "291280"
  },
  {
    "text": "output format that you're expecting from",
    "start": "291280",
    "end": "292880"
  },
  {
    "text": "the prompt and so on and so",
    "start": "292880",
    "end": "294759"
  },
  {
    "text": "forth this can have a dramatic impact in",
    "start": "294759",
    "end": "297600"
  },
  {
    "text": "the quality of the uh responses that you",
    "start": "297600",
    "end": "300160"
  },
  {
    "text": "get from the motors by using the prompt",
    "start": "300160",
    "end": "301840"
  },
  {
    "text": "templates we can explore uh some",
    "start": "301840",
    "end": "304759"
  },
  {
    "text": "examples here you see that we are",
    "start": "304759",
    "end": "306960"
  },
  {
    "text": "optimizing a prompt for cloud3 file",
    "start": "306960",
    "end": "309520"
  },
  {
    "text": "haiku this is a proming example where I",
    "start": "309520",
    "end": "311680"
  },
  {
    "text": "want u a summarization of an email this",
    "start": "311680",
    "end": "315360"
  },
  {
    "text": "is typical from a user that has uh no",
    "start": "315360",
    "end": "318160"
  },
  {
    "text": "knowledge on how to prom a specific",
    "start": "318160",
    "end": "320080"
  },
  {
    "text": "model like uh the entropic haiku in this",
    "start": "320080",
    "end": "323199"
  },
  {
    "text": "case so a user might be adding uh some",
    "start": "323199",
    "end": "327039"
  },
  {
    "text": "repetitive instructions the order might",
    "start": "327039",
    "end": "328960"
  },
  {
    "text": "not be ideal uh it might follow some",
    "start": "328960",
    "end": "331120"
  },
  {
    "text": "antiatterns in the way that is written",
    "start": "331120",
    "end": "332720"
  },
  {
    "text": "and so on and so forth when I optimize",
    "start": "332720",
    "end": "335039"
  },
  {
    "text": "with the uh Amazon better provided uh",
    "start": "335039",
    "end": "337840"
  },
  {
    "text": "from optimization it will actually get",
    "start": "337840",
    "end": "340160"
  },
  {
    "text": "to a version that is uh way cleaner and",
    "start": "340160",
    "end": "343280"
  },
  {
    "text": "is having a way better format uh also",
    "start": "343280",
    "end": "346000"
  },
  {
    "text": "for the output that I'm getting if we",
    "start": "346000",
    "end": "348240"
  },
  {
    "text": "test it side by side you can see here",
    "start": "348240",
    "end": "350800"
  },
  {
    "text": "that uh actually the summary email that",
    "start": "350800",
    "end": "353039"
  },
  {
    "text": "I'm getting from uh the models is a bit",
    "start": "353039",
    "end": "355199"
  },
  {
    "text": "different in the optimize prompt you",
    "start": "355199",
    "end": "357520"
  },
  {
    "text": "actually get uh a final and uh very uh",
    "start": "357520",
    "end": "361680"
  },
  {
    "text": "consistent summary of the email that we",
    "start": "361680",
    "end": "363840"
  },
  {
    "text": "were analyzing and uh you can see that",
    "start": "363840",
    "end": "366319"
  },
  {
    "text": "it even helps improving the overall",
    "start": "366319",
    "end": "368319"
  },
  {
    "text": "quality of the responses from the model",
    "start": "368319",
    "end": "369919"
  },
  {
    "text": "like an example the urgency is now",
    "start": "369919",
    "end": "371840"
  },
  {
    "text": "properly classified as four out of five",
    "start": "371840",
    "end": "374400"
  },
  {
    "text": "for the use uh example email that I",
    "start": "374400",
    "end": "376680"
  },
  {
    "text": "input um while in the original prompt it",
    "start": "376680",
    "end": "379520"
  },
  {
    "text": "was classifying as five out of five and",
    "start": "379520",
    "end": "382720"
  },
  {
    "text": "other things that are important in",
    "start": "382720",
    "end": "384160"
  },
  {
    "text": "example is getting that my meeting is",
    "start": "384160",
    "end": "386479"
  },
  {
    "text": "actually uh having an avail availability",
    "start": "386479",
    "end": "388800"
  },
  {
    "text": "from this person for June 16 uh at this",
    "start": "388800",
    "end": "392560"
  },
  {
    "text": "time while in the original prompt it was",
    "start": "392560",
    "end": "395199"
  },
  {
    "text": "actually reading it wrong and it was uh",
    "start": "395199",
    "end": "397360"
  },
  {
    "text": "assuming that it was June 17 and so on",
    "start": "397360",
    "end": "400000"
  },
  {
    "text": "and so forth so as you can see it really",
    "start": "400000",
    "end": "402720"
  },
  {
    "text": "has an impact in the overall result that",
    "start": "402720",
    "end": "405360"
  },
  {
    "text": "we can get uh at the",
    "start": "405360",
    "end": "407479"
  },
  {
    "text": "end now uh it's not only about the",
    "start": "407479",
    "end": "410479"
  },
  {
    "text": "quality sometimes we can also use it for",
    "start": "410479",
    "end": "413120"
  },
  {
    "text": "helping especially with reasoning models",
    "start": "413120",
    "end": "415039"
  },
  {
    "text": "in example when we are trying to",
    "start": "415039",
    "end": "416400"
  },
  {
    "text": "optimize for reducing the number of",
    "start": "416400",
    "end": "418319"
  },
  {
    "text": "tokens for being more cost effective and",
    "start": "418319",
    "end": "420400"
  },
  {
    "text": "also reducing the latency we can see an",
    "start": "420400",
    "end": "422880"
  },
  {
    "text": "example here when we are optimizing for",
    "start": "422880",
    "end": "424800"
  },
  {
    "text": "deep cigar one which is a reasoning",
    "start": "424800",
    "end": "426639"
  },
  {
    "text": "model that therefore tends to generate a",
    "start": "426639",
    "end": "429599"
  },
  {
    "text": "lot of tokens also in our responses and",
    "start": "429599",
    "end": "431840"
  },
  {
    "text": "sometimes it might get to explore",
    "start": "431840",
    "end": "433919"
  },
  {
    "text": "alternatives that are really not needed",
    "start": "433919",
    "end": "435440"
  },
  {
    "text": "for our case once again I have a prompt",
    "start": "435440",
    "end": "438080"
  },
  {
    "text": "that was written uh pretty much uh as a",
    "start": "438080",
    "end": "440639"
  },
  {
    "text": "person would normally talk and not",
    "start": "440639",
    "end": "442319"
  },
  {
    "text": "following the guidelines of the model",
    "start": "442319",
    "end": "444840"
  },
  {
    "text": "prompting in this case Deepseek is",
    "start": "444840",
    "end": "447199"
  },
  {
    "text": "typically trained using markdown so we",
    "start": "447199",
    "end": "449680"
  },
  {
    "text": "can see how the prom optimization",
    "start": "449680",
    "end": "451520"
  },
  {
    "text": "provided in Amazon is actually giving",
    "start": "451520",
    "end": "453440"
  },
  {
    "text": "you the proper format following markdown",
    "start": "453440",
    "end": "456240"
  },
  {
    "text": "and is having a cleaner instructions in",
    "start": "456240",
    "end": "458479"
  },
  {
    "text": "this case for analyzing uh CSV data that",
    "start": "458479",
    "end": "461599"
  },
  {
    "text": "I'm passing in this",
    "start": "461599",
    "end": "463000"
  },
  {
    "text": "example um we can run it side by side uh",
    "start": "463000",
    "end": "466000"
  },
  {
    "text": "once again and we can see that the model",
    "start": "466000",
    "end": "468240"
  },
  {
    "text": "is performing its reasoning and then",
    "start": "468240",
    "end": "470080"
  },
  {
    "text": "it's providing a final answer and the",
    "start": "470080",
    "end": "472400"
  },
  {
    "text": "interesting thing to note is that",
    "start": "472400",
    "end": "473840"
  },
  {
    "text": "actually in the optimized version we are",
    "start": "473840",
    "end": "475759"
  },
  {
    "text": "having less tokens and the latency is",
    "start": "475759",
    "end": "477919"
  },
  {
    "text": "reduced so we can actually get a better",
    "start": "477919",
    "end": "480400"
  },
  {
    "text": "response and also the format of the",
    "start": "480400",
    "end": "482560"
  },
  {
    "text": "response is going to be better we can uh",
    "start": "482560",
    "end": "484879"
  },
  {
    "text": "test it out in the playground in example",
    "start": "484879",
    "end": "487120"
  },
  {
    "text": "where we can compare here the original",
    "start": "487120",
    "end": "489520"
  },
  {
    "text": "format of the responses that we were",
    "start": "489520",
    "end": "491120"
  },
  {
    "text": "getting uh with the nonoptimize uh",
    "start": "491120",
    "end": "493039"
  },
  {
    "text": "prompt that I was passing uh here at the",
    "start": "493039",
    "end": "495479"
  },
  {
    "text": "beginning it was taking uh 55 seconds uh",
    "start": "495479",
    "end": "498960"
  },
  {
    "text": "to respond after all the thinking it was",
    "start": "498960",
    "end": "502080"
  },
  {
    "text": "uh uh consuming a total of uh",
    "start": "502080",
    "end": "505960"
  },
  {
    "text": "2,663 tokens in the output that that is",
    "start": "505960",
    "end": "509440"
  },
  {
    "text": "an amount of tokens that we are paying",
    "start": "509440",
    "end": "511039"
  },
  {
    "text": "at the end and you can see how the",
    "start": "511039",
    "end": "513279"
  },
  {
    "text": "optimiz iz version is actually reducing",
    "start": "513279",
    "end": "515360"
  },
  {
    "text": "that number uh dramatically also reduces",
    "start": "515360",
    "end": "518000"
  },
  {
    "text": "the latency to 53 seconds and the format",
    "start": "518000",
    "end": "520880"
  },
  {
    "text": "that I'm getting at the end is way",
    "start": "520880",
    "end": "522560"
  },
  {
    "text": "cleaner having a summary of uh the",
    "start": "522560",
    "end": "524880"
  },
  {
    "text": "analysis of the CSV data and so on and",
    "start": "524880",
    "end": "527040"
  },
  {
    "text": "so",
    "start": "527040",
    "end": "528519"
  },
  {
    "text": "forth so once again um consider using uh",
    "start": "528519",
    "end": "532240"
  },
  {
    "text": "prompt management in Amazon it is a",
    "start": "532240",
    "end": "534720"
  },
  {
    "text": "feature that allows you to uh catalog",
    "start": "534720",
    "end": "537279"
  },
  {
    "text": "and store your prompts uh you can uh",
    "start": "537279",
    "end": "540000"
  },
  {
    "text": "create variants and versions of those",
    "start": "540000",
    "end": "541760"
  },
  {
    "text": "prompts so that you can later on attach",
    "start": "541760",
    "end": "544080"
  },
  {
    "text": "uh to your applications in an easy way",
    "start": "544080",
    "end": "546800"
  },
  {
    "text": "and the best part is that you can also",
    "start": "546800",
    "end": "548800"
  },
  {
    "text": "use it programmatically you can do",
    "start": "548800",
    "end": "550800"
  },
  {
    "text": "direct invocations once you create the",
    "start": "550800",
    "end": "552959"
  },
  {
    "text": "prompts uh through the SDK or through",
    "start": "552959",
    "end": "554959"
  },
  {
    "text": "the console and uh you just have to use",
    "start": "554959",
    "end": "557839"
  },
  {
    "text": "the commerce API in the Amazon perro uh",
    "start": "557839",
    "end": "560880"
  },
  {
    "text": "use the prompt ARM directly uh setting",
    "start": "560880",
    "end": "563519"
  },
  {
    "text": "your input variables at runtime and then",
    "start": "563519",
    "end": "566399"
  },
  {
    "text": "you can see how you can do direct",
    "start": "566399",
    "end": "567920"
  },
  {
    "text": "invocations without having to",
    "start": "567920",
    "end": "569440"
  },
  {
    "text": "materialize the prompt templates at any",
    "start": "569440",
    "end": "571920"
  },
  {
    "text": "point so this helps you saving a lot of",
    "start": "571920",
    "end": "574720"
  },
  {
    "text": "time and also it helps you uh avoiding",
    "start": "574720",
    "end": "577839"
  },
  {
    "text": "the additional step of having to read",
    "start": "577839",
    "end": "579680"
  },
  {
    "text": "the prompts or having to write the",
    "start": "579680",
    "end": "581519"
  },
  {
    "text": "prompts hardcoded in your code uh in",
    "start": "581519",
    "end": "583839"
  },
  {
    "text": "your applications and so on and so forth",
    "start": "583839",
    "end": "586880"
  },
  {
    "text": "uh the same in the same way for doing",
    "start": "586880",
    "end": "588399"
  },
  {
    "text": "prom optimization uh you can also rely",
    "start": "588399",
    "end": "590959"
  },
  {
    "text": "on the APIs that we have in this example",
    "start": "590959",
    "end": "593040"
  },
  {
    "text": "we are actually collecting this prompt",
    "start": "593040",
    "end": "594720"
  },
  {
    "text": "that says please summarize this text and",
    "start": "594720",
    "end": "597440"
  },
  {
    "text": "uh we are trying to optimize for a",
    "start": "597440",
    "end": "598800"
  },
  {
    "text": "target model that is a plot 35 haiku and",
    "start": "598800",
    "end": "602240"
  },
  {
    "text": "you can see how we are using the",
    "start": "602240",
    "end": "603600"
  },
  {
    "text": "optimize prom API and in this case we",
    "start": "603600",
    "end": "606399"
  },
  {
    "text": "get an analysis of the prom and",
    "start": "606399",
    "end": "608160"
  },
  {
    "text": "immediately we get an optimized version",
    "start": "608160",
    "end": "610000"
  },
  {
    "text": "that is recommended by the Amazon perro",
    "start": "610000",
    "end": "613440"
  },
  {
    "text": "optimization feature",
    "start": "613440",
    "end": "616320"
  },
  {
    "text": "With that I hope that uh you can test it",
    "start": "616880",
    "end": "619440"
  },
  {
    "text": "out and you get uh the most out of the",
    "start": "619440",
    "end": "622160"
  },
  {
    "text": "features that we are providing you for",
    "start": "622160",
    "end": "623519"
  },
  {
    "text": "the prompting life cycle thank you for",
    "start": "623519",
    "end": "626000"
  },
  {
    "text": "watching",
    "start": "626000",
    "end": "629000"
  }
]
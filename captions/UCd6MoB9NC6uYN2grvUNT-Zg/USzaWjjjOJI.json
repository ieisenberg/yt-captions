[
  {
    "text": "If you’re like many of our customers, you’re\nprobably using SaaS applications like Salesforce,",
    "start": "0",
    "end": "4500"
  },
  {
    "text": "Marketo, or Slack as an important part of your\ndaily operations. Sharing data between these",
    "start": "4500",
    "end": "9300"
  },
  {
    "text": "applications and AWS services is essential for\nbuilding insights and automating workflows;",
    "start": "9300",
    "end": "14800"
  },
  {
    "text": "however, transferring data between those apps\nand services can be a challenge. Managing",
    "start": "14800",
    "end": "20600"
  },
  {
    "text": "custom connectors typically requires coding and\non-going maintenance, and can often introduce a",
    "start": "20600",
    "end": "24900"
  },
  {
    "text": "risk of data leaks.  With Amazon AppFlow, you\ncan now securely transfer data bi-directionally",
    "start": "24900",
    "end": "30700"
  },
  {
    "text": "between SaaS applications and AWS services in\njust a few clicks.  In this demonstration we'll",
    "start": "30700",
    "end": "39000"
  },
  {
    "text": "create a new flow to transfer opportunities created\nin Salesforce within the last 30 days to Amazon",
    "start": "39000",
    "end": "44700"
  },
  {
    "text": "S3, which can then be used as backups, as data\nfor other AWS services, or to use with applications",
    "start": "44700",
    "end": "50400"
  },
  {
    "text": "of your own.  To do this, we first need to\nestablish a connection with Salesforce to use as",
    "start": "50400",
    "end": "55200"
  },
  {
    "text": "our data source. For the destination, we're going\nto be using an existing S3 bucket. OK, let's start",
    "start": "55200",
    "end": "61200"
  },
  {
    "text": "configuring our AppFlow by clicking Create Flow\nfrom the AppFlow home screen.   We'll name",
    "start": "61200",
    "end": "65800"
  },
  {
    "text": "our flow “new-salesforce-opps”, and then select\nour encryption key from the Amazon Key",
    "start": "65800",
    "end": "71200"
  },
  {
    "text": "Management Service (KMS). We'll stick with the\ndefault key for this demonstration, but you can",
    "start": "71200",
    "end": "76200"
  },
  {
    "text": "also use your own custom KMS key if you'd like.\n Next, we'll specify the source of our data, which",
    "start": "76200",
    "end": "82200"
  },
  {
    "text": "for this example will be Salesforce, and create a\nnew connection. We'll select our environment,",
    "start": "82200",
    "end": "88299"
  },
  {
    "text": "give the connection a name, and authenticate with\nSalesforce.  Now that we've set up our",
    "start": "88300",
    "end": "97000"
  },
  {
    "text": "connection, let's select the “Opportunity” object.\n We now need to select a destination where our",
    "start": "97000",
    "end": "102400"
  },
  {
    "text": "opportunities will flow. Let's use this existing\nAmazon S3 bucket from the dropdown.  Next",
    "start": "102400",
    "end": "108300"
  },
  {
    "text": "we'll choose our flow trigger. An on-demand flow\nwill run as-needed whenever we kick it off",
    "start": "108300",
    "end": "113800"
  },
  {
    "text": "manually, a scheduled flow runs at a specified\ninterval, and an event-based flow runs in response",
    "start": "113800",
    "end": "119700"
  },
  {
    "text": "to business events like the creation of a\nSalesforce opportunity or a status change in a",
    "start": "119700",
    "end": "124299"
  },
  {
    "text": "support ticket.  In this example, we'll create an\non-demand trigger.  Next, we'll map source",
    "start": "124300",
    "end": "130700"
  },
  {
    "text": "fields to destination fields. For this demonstration,\nwe'll map our fields using the AppFlow interface,",
    "start": "130700",
    "end": "136300"
  },
  {
    "text": "but you could also upload a CSV file to bulk map\na large number of fields.  From the “Source",
    "start": "136300",
    "end": "142300"
  },
  {
    "text": "Field Name” drop-down we’ll select the “Map all\nfields directly” option. This will grab all the fields",
    "start": "142300",
    "end": "148700"
  },
  {
    "text": "from the Opportunity Object in Salesforce, and\nmap them to a field with the same name in our",
    "start": "148700",
    "end": "153000"
  },
  {
    "text": "output file in S3.  We can choose to add data\nfield transformations, like masking or merging.",
    "start": "153000",
    "end": "159400"
  },
  {
    "text": "We're going to mask the account ID for this flow.\n Next, we’ll add some validation to ensure we'll",
    "start": "159400",
    "end": "168400"
  },
  {
    "text": "only be grabbing Opportunities that have an\namount that isn’t null or missing.  We can also",
    "start": "168400",
    "end": "176900"
  },
  {
    "text": "use data filters to limit the transferred results\nfurther, such as limiting them to only records",
    "start": "176900",
    "end": "182200"
  },
  {
    "text": "created in the last 30 days.  We’ll now review\nthe details and click Create Flow.  Our new",
    "start": "182200",
    "end": "191300"
  },
  {
    "text": "Flow is now available in the console. It's an\nOn-Demand flow, so let's click Run Flow to",
    "start": "191300",
    "end": "196300"
  },
  {
    "text": "execute it.  Once the flow is completed, we can\nview our Salesforce data in the S3 bucket that we",
    "start": "196300",
    "end": "201700"
  },
  {
    "text": "selected earlier.  To learn more about Amazon\nAppFlow, visit aws.amazon.com/appflow and set",
    "start": "201700",
    "end": "210099"
  },
  {
    "text": "up your first flow in minutes.",
    "start": "210100",
    "end": "213400"
  }
]
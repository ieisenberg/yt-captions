[
  {
    "text": "buongiorno a tutti io sono giorgio nobile sono soluzioni per amazon web services è specializzata appunto nella",
    "start": "0",
    "end": "6810"
  },
  {
    "text": "parte di big data di analisi dati di collezione di collezione dati e tutto",
    "start": "6810",
    "end": "13710"
  },
  {
    "text": "quello di cui parleremo nella giornata di oggi e volevo partire appunto con una",
    "start": "13710",
    "end": "19410"
  },
  {
    "text": "domanda per capire se qualcuno di voi ad oggi gestisce cluster di calcolo",
    "start": "19410",
    "end": "26099"
  },
  {
    "text": "distribuito o appunto a che fare con questi grandi moli di dati per",
    "start": "26099",
    "end": "31830"
  },
  {
    "text": "effettuare appunto l'aggregazione è togliere valore in modo da adattare anche un po la presentazione su questo",
    "start": "31830",
    "end": "39320"
  },
  {
    "text": "bene volevo iniziare appunto con un overview su che cosa vuol dire big data appunto è una è una parola molto comune",
    "start": "40910",
    "end": "47160"
  },
  {
    "text": "negli ultimi gli ultimi tempi ma che cosa vuol dire veramente big data qui vi ho portato appunto una serie di",
    "start": "47160",
    "end": "52949"
  },
  {
    "text": "esempi su dati che vengono prodotti generati o consumati da una serie di",
    "start": "52949",
    "end": "58980"
  },
  {
    "text": "servizi molto conosciuti come per esempio è lato netflix vengono ogni",
    "start": "58980",
    "end": "64588"
  },
  {
    "text": "minuto vengono stremati stemate 70 mila ore di video piuttosto che vengono",
    "start": "64589",
    "end": "70979"
  },
  {
    "text": "twittati appunto tramite twitter 450 mila messaggi al minuto o vengono condivise circa 530 mila foto da utenti",
    "start": "70979",
    "end": "79860"
  },
  {
    "text": "snapshots per cui stiamo parlando veramente di una grandissima mole di",
    "start": "79860",
    "end": "85049"
  },
  {
    "text": "dati che vengono sia appunto prodotti devono essere consumati dagli utenti e devono essere analizzati per appunto",
    "start": "85049",
    "end": "92790"
  },
  {
    "text": "dare un valore aggiuntivo da appunto da dai gestori di questi servizi",
    "start": "92790",
    "end": "98990"
  },
  {
    "text": "che cosa vuol dire analizzare e gestire questi dati c'è uno strumento unico per",
    "start": "99829",
    "end": "106829"
  },
  {
    "text": "farlo la nostra risposta alla società blue air se no ci sono una serie ci sono una",
    "start": "106829",
    "end": "113710"
  },
  {
    "text": "serie di servizi che sono appunto dedicati a gestire ogni singola fase",
    "start": "113710",
    "end": "121650"
  },
  {
    "text": "della pipeline di analisi di di un dato",
    "start": "121650",
    "end": "127110"
  },
  {
    "text": "per gestire ogni singola fase che portano appunto come vedremo poi in seguito nella presentazione un valore",
    "start": "138850",
    "end": "146860"
  },
  {
    "text": "aggiunto che cosa vuol dire big data onda blu es perché ed eterne la brioche",
    "start": "146860",
    "end": "153640"
  },
  {
    "text": "che cosa che cosa ci dà e da blu es per per risolvere appunto questo problema di analytics di di analisi dei",
    "start": "153640",
    "end": "161050"
  },
  {
    "text": "dati principalmente ci dà una disponibilità immediata delle risorse per cui in pochi",
    "start": "161050",
    "end": "167380"
  },
  {
    "text": "minuti noi potremmo provvigionale macchine virtuali a utilizzare servizi come per esempio la stigma played ius",
    "start": "167380",
    "end": "174040"
  },
  {
    "text": "che ci permettono di avere in pochi minuti senza dover effettuare nessuna fronte a livello di costi delle risorse",
    "start": "174040",
    "end": "181530"
  },
  {
    "text": "immediatamente disponibili e scalabili in base appunto alle esigenze e alla",
    "start": "181530",
    "end": "187210"
  },
  {
    "text": "quantità di dati che vogliamo analizzare un determinato momento ci sono una serie",
    "start": "187210",
    "end": "192970"
  },
  {
    "text": "di servizi più di cento servizi ad oggi che dall us può offrire e tra quali appunto servizi di analytics gestiti da",
    "start": "192970",
    "end": "200170"
  },
  {
    "text": "strumenti di visualizzazione strumenti di data streaming e senza appunto dover",
    "start": "200170",
    "end": "206080"
  },
  {
    "text": "necessariamente utilizzare risorse infrastructure as a service per cui macchine virtuali sicurezza quando",
    "start": "206080",
    "end": "214800"
  },
  {
    "text": "parliamo appunto di big data a noi vogliamo essere sicuri che ci siano che",
    "start": "214800",
    "end": "220500"
  },
  {
    "text": "i dati abbiano una un'apposita sicurezza appunto una diversi livelli di sicurezza",
    "start": "220500",
    "end": "228030"
  },
  {
    "text": "a seconda della classificazione del dato e oltre a questo appunto e da blu es mette anche a disposizione e modalità di",
    "start": "228030",
    "end": "236459"
  },
  {
    "text": "consultazione una serie di certificazioni ottenute come per esempio fede ram non per ultimo l'ecosistema di",
    "start": "236459",
    "end": "244560"
  },
  {
    "text": "partner e di soluzioni che è da brewer soffre contiamo appunto un grande numero",
    "start": "244560",
    "end": "250349"
  },
  {
    "text": "di partner e di e di soluzioni e pronti all'uso per effettuare diversi tipi di",
    "start": "250349",
    "end": "256200"
  },
  {
    "text": "di analisi di dati per diversi tipi di workload vorrei appunto prima di prima",
    "start": "256200",
    "end": "263910"
  },
  {
    "text": "di partire definire un concetto che è quello di data lake e nello specifico che cosa intendiamo per data lakeside a",
    "start": "263910",
    "end": "270270"
  },
  {
    "text": "blu es per cui data lei che è una è un'architettura un'implementazione di di",
    "start": "270270",
    "end": "278100"
  },
  {
    "text": "storage di dati centralizzata appunto in un unico posto il quale deve deve",
    "start": "278100",
    "end": "285090"
  },
  {
    "text": "permettere agli utilizzatori di in maniera veloce in maniera agile di poter",
    "start": "285090",
    "end": "290580"
  },
  {
    "text": "storicizzare salvare archiviare analizzare è una maul eterogenea di dati per definire una data lei ci sono ci",
    "start": "290580",
    "end": "300570"
  },
  {
    "text": "sono cinque diversi piller è il primo il primo tra tra tutti è quello della separazione dello dello storage dal",
    "start": "300570",
    "end": "307650"
  },
  {
    "text": "computer non con un concetto ideata lake non siamo più obbligati a tenere lo storage locale alle macchine che",
    "start": "307650",
    "end": "313169"
  },
  {
    "text": "verranno utilizzate per analizzare il dato ma riuscendo a separare questo dato riceva appunto a scalare",
    "start": "313169",
    "end": "319289"
  },
  {
    "text": "indipendentemente la componente di storage dalla componente di computer",
    "start": "319289",
    "end": "325220"
  },
  {
    "text": "con diversi vantaggi sia appunto in ottica di costi sia in ottica appunto di",
    "start": "325220",
    "end": "331550"
  },
  {
    "text": "approccio all'accesso del dato e acquisizione trasformazione molto rapida",
    "start": "331550",
    "end": "337139"
  },
  {
    "text": "appunto noi vogliamo lavorare in una maniera molto agile vogliamo riuscire appunto a a dare la possibilità agli",
    "start": "337139",
    "end": "343199"
  },
  {
    "text": "utenti di investire in maniera veloce i dati in quanto ci possono essere diverse",
    "start": "343199",
    "end": "349139"
  },
  {
    "text": "fonti come per esempio realtime piuttosto quebec che il nostro data lei chi vuole la nostra impostazione data",
    "start": "349139",
    "end": "354389"
  },
  {
    "text": "lei vuole soddisfare tutti questi requisiti multi tenancy quando parliamo",
    "start": "354389",
    "end": "360300"
  },
  {
    "text": "di data lei che noi vogliamo dare accesso a svariate line of business",
    "start": "360300",
    "end": "365340"
  },
  {
    "text": "all'interno dell'organizzazione sullo stesso dataset per far questo appunto dobbiamo essere in grado di di segregare",
    "start": "365340",
    "end": "371970"
  },
  {
    "text": "in maniera sicura una parte di dati in modo da permettere alle persone che",
    "start": "371970",
    "end": "378090"
  },
  {
    "text": "andranno a consumare questi dati e di poter vedere solamente una piccola porzione dei dati piuttosto appunto che",
    "start": "378090",
    "end": "385380"
  },
  {
    "text": "l'interesse voi siano data scientist che devono fare data exploration sul set di",
    "start": "385380",
    "end": "390810"
  },
  {
    "text": "dati come per esempio e analisti che devono correlare un numero maggiore di",
    "start": "390810",
    "end": "395909"
  },
  {
    "text": "dati un'altra delle caratteristiche è la possibilità di effettuare le cosiddette",
    "start": "395909",
    "end": "402810"
  },
  {
    "text": "guerre in place ossia non ha non dobbiamo importare questi dati in un altro strumento per poterli analizzare ma possiamo direttamente interrogare",
    "start": "402810",
    "end": "409680"
  },
  {
    "text": "questo strumento è secondo me il pil è fondamentale è quello dello del",
    "start": "409680",
    "end": "415710"
  },
  {
    "text": "cosiddetto schema un read ossia noi una volta che collezioniamo i dati i dati possono come abbiamo detto esser",
    "start": "415710",
    "end": "421500"
  },
  {
    "text": "eterogenei non siamo obbligati ad applicare uno schema su questi dati lo facciamo solamente quando dobbiamo",
    "start": "421500",
    "end": "426570"
  },
  {
    "text": "analizzarle per cui questi dati non andranno a confluire in una sorta di",
    "start": "426570",
    "end": "431970"
  },
  {
    "text": "database ma appunto in questo pozzo di input poi vedremo meglio che servizi utilizziamo per far questo senza avere",
    "start": "431970",
    "end": "439169"
  },
  {
    "text": "una struttura fissa uno schema fisso l'architettura dati moderna",
    "start": "439169",
    "end": "446590"
  },
  {
    "text": "ad oggi appunto soprattutto nel settore pubblico ci possono essere gli skate differenti che vanno a velocità differenti",
    "start": "446590",
    "end": "451750"
  },
  {
    "text": "prendete per esempio l'analisi dell'andamento di delle scuole per esempio è un flusso di dati che non è",
    "start": "451750",
    "end": "458980"
  },
  {
    "text": "costante arriverà a berci in determinati periodi dell'anno in contrapposizione ci",
    "start": "458980",
    "end": "465160"
  },
  {
    "text": "sono appunto per esempio fibs di social network dove andiamo analizzare il sentimento degli utenti rispetto a un",
    "start": "465160",
    "end": "471730"
  },
  {
    "text": "determinato argomento piuttosto che è dati che possono essere raccolti da da",
    "start": "471730",
    "end": "478300"
  },
  {
    "text": "sensori e da sensoristica spassa per la città piuttosto che per esempio non lo so il traffico generato dallo spot",
    "start": "478300",
    "end": "485020"
  },
  {
    "text": "pubblici per cui come si comportano uno spot pubblico nel momento di picco della giornata per cui appunto ci sono diverse",
    "start": "485020",
    "end": "491980"
  },
  {
    "text": "velocità diversi tipi di dati relazionabili non relazionabili per cui in maniera agile noi dobbiamo essere in",
    "start": "491980",
    "end": "499540"
  },
  {
    "text": "grado di poter raccogliere tutto tutto questo dataset ad oggi appunto parlando",
    "start": "499540",
    "end": "509350"
  },
  {
    "text": "di di tutta questa mole di dati di tutti questi flussi di in gesti non ci sono diverse operazioni che vanno fatte sul",
    "start": "509350",
    "end": "517450"
  },
  {
    "text": "dato dall incerto nella preparazione allo storage che non danno nessun valore",
    "start": "517450",
    "end": "522909"
  },
  {
    "text": "finale ad oggi cubano circa l'ottanta per cento del lavoro di appunto di su",
    "start": "522910",
    "end": "529180"
  },
  {
    "text": "una pipeline globale di di analytics solo il 20 per cento di questo ci porterà ci porterà un valore in un",
    "start": "529180",
    "end": "536050"
  },
  {
    "text": "architettura tradizionale questi per esempio sicurezza storage indicizzazione",
    "start": "536050",
    "end": "543310"
  },
  {
    "text": "accesso sono tutte delle attività che adesso andremo a vedere un pochino più nel dettaglio che sono riferite al mondo",
    "start": "543310",
    "end": "548380"
  },
  {
    "text": "analytics sono necessari ma in un architettura tradizionale portano via in gran parte gran parte del tempo tempo",
    "start": "548380",
    "end": "555370"
  },
  {
    "text": "speso senza appunto avere nessun ritorno senza riuscire a estrarre nessuna feature da dai dati che stiamo andando",
    "start": "555370",
    "end": "561670"
  },
  {
    "text": "ad analizzare acquisizione dei dati per cui appunto è tutta la prima parte della",
    "start": "561670",
    "end": "567040"
  },
  {
    "text": "pipeline dove il nostro servizio deve poter permettere di gestire dati in",
    "start": "567040",
    "end": "572560"
  },
  {
    "text": "streaming appunto consumare un feed piuttosto che consumare dati generati da da device ios è piuttosto che appunto",
    "start": "572560",
    "end": "579700"
  },
  {
    "text": "match per cui dobbiamo avere un canale di streaming e dobbiamo configurarlo a",
    "start": "579700",
    "end": "584990"
  },
  {
    "text": "mantenerlo attivo e assicurarci che possa ospitare il flusso di dati che",
    "start": "584990",
    "end": "590180"
  },
  {
    "text": "stanno transitando conservazione dei dati in formato originale questo è un requisito di storage per cui",
    "start": "590180",
    "end": "597290"
  },
  {
    "text": "noi dobbiamo in un architettura tradizionale avere appunto uno storage che permetta di ospitare questa mole di",
    "start": "597290",
    "end": "603140"
  },
  {
    "text": "dati sempre crescente e svariati motivi per esempio motivi di compliance",
    "start": "603140",
    "end": "608800"
  },
  {
    "text": "piuttosto che appunto vogliamo far rigirare uniti l che abbiamo fatto in passato perché abbiamo",
    "start": "608800",
    "end": "614570"
  },
  {
    "text": "avuto dei problemi per cui dobbiamo ripartire dal dato originale e per cui appunto la componente di storage qua e",
    "start": "614570",
    "end": "620930"
  },
  {
    "text": "la chiave è necessaria appunto fare investimenti per il per lo storage",
    "start": "620930",
    "end": "626360"
  },
  {
    "text": "mantenerlo pensare appunto al disaster recovery del dato per cui appunto backup replicazione geografica e questa serie",
    "start": "626360",
    "end": "633860"
  },
  {
    "text": "di operazioni che cubano sia in tempo che è che appunto i soldi ciclo di vita",
    "start": "633860",
    "end": "641630"
  },
  {
    "text": "dello storage una volta appunto che il dato entrato nel nostro nel nostro adatta lake il suo valore può essere può",
    "start": "641630",
    "end": "647900"
  },
  {
    "text": "essere differente se estratto immediatamente oppure se estratto dopo ore mesi giorni settimane per cui",
    "start": "647900",
    "end": "654500"
  },
  {
    "text": "dobbiamo comunque pensare ad avere più livelli di storage quello che di solito viene chiamato tiered storage ossia",
    "start": "654500",
    "end": "661010"
  },
  {
    "text": "riuscire a spostare in livelli di storage meno efficienti ma meno costosi",
    "start": "661010",
    "end": "667460"
  },
  {
    "text": "i dati di cui non abbiamo bisogno comunque che per compliance dobbiamo tenere per per un tot numero di anni e",
    "start": "667460",
    "end": "673940"
  },
  {
    "text": "anche qua la componente storage e tutta la parte di management di gestione dello spostamento di questi dati in un",
    "start": "673940",
    "end": "679880"
  },
  {
    "text": "architettura tradizionale ha appunto a un costo è un tempo acquisizione",
    "start": "679880",
    "end": "686330"
  },
  {
    "text": "metadati questo è uno e uno è una è un è un punto fondamentale metadati cosa vuol",
    "start": "686330",
    "end": "692990"
  },
  {
    "text": "dire quando noi investiamo nel nostro data lake o comunque quando noi gestiamo anche in un architettura tradizionale un",
    "start": "692990",
    "end": "698390"
  },
  {
    "text": "dato dobbiamo riuscire a definire che cos'è questo dato non possiamo gestire",
    "start": "698390",
    "end": "703850"
  },
  {
    "text": "un dato è dire ok poi lo lo vedremo in futuro perché",
    "start": "703850",
    "end": "709059"
  },
  {
    "text": "questo è un quot di gartner è si è osservato che la presenza di questi questi dati dark data ossia senza",
    "start": "709059",
    "end": "716769"
  },
  {
    "text": "applicare un metadata uno schema i dati che non mette uno schema appunto una una",
    "start": "716769",
    "end": "722949"
  },
  {
    "text": "definizione di che cosa c'è dentro i nostri dati quello che succede e acquisire una grande quantità di dati",
    "start": "722949",
    "end": "728289"
  },
  {
    "text": "senza sapere poi che cosa farne per cui questo implica solamente un aumento dei costi di storage e senza appunto tra le",
    "start": "728289",
    "end": "736269"
  },
  {
    "text": "nessun valore ed è proporzionale con l'aumento dal cup sono proporzionali con",
    "start": "736269",
    "end": "741309"
  },
  {
    "text": "l'aumento del numero di dati gestiti",
    "start": "741309",
    "end": "745289"
  },
  {
    "text": "abbiamo invece abbiamo visto prima mettendo appunto tutti i dati in un unico punto è necessario avere diversi",
    "start": "746889",
    "end": "756909"
  },
  {
    "text": "livelli di accesso al dato appunto a seconda della sua classificazione per cui dobbiamo essere in grado di poter",
    "start": "756909",
    "end": "762789"
  },
  {
    "text": "applicare delle policy di sicurezza a seconda della della classificazione del",
    "start": "762789",
    "end": "769659"
  },
  {
    "text": "nostro dato è anche questo appunto a livello di management del dato nell'architettura tradizionale è un",
    "start": "769659",
    "end": "777399"
  },
  {
    "text": "aspetto molto importante e non sempre agilmente raggiungibile dobbiamo una",
    "start": "777399",
    "end": "785469"
  },
  {
    "text": "volta che abbiamo appunto i gestito è classificato i dati è importante e renderli renderli disponibili per",
    "start": "785469",
    "end": "791829"
  },
  {
    "text": "esempio appunto farle consumare via e tia e appunto con un'interfaccia per esempio rest per cui è importante",
    "start": "791829",
    "end": "797789"
  },
  {
    "text": "prevedere un architettura tradizionale una sorta appunto di layer che permetta",
    "start": "797789",
    "end": "804170"
  },
  {
    "text": "a singoli a singole line of business singoli utenti di poter accedere al dato",
    "start": "804170",
    "end": "809360"
  },
  {
    "text": "e poterlo consumare qualità del dato",
    "start": "809360",
    "end": "814910"
  },
  {
    "text": "qualità del dato una volta che abbiamo investito i nostri dati non siamo sicuri che il dato può essere utile per il",
    "start": "814910",
    "end": "822050"
  },
  {
    "text": "nostro scopo gli analytics dobbiamo sincerarci di avere tutte le informazioni per cui tutti i campi che",
    "start": "822050",
    "end": "828380"
  },
  {
    "text": "ci aspettiamo siano presenti siano in un formato consumabile a seconda del tipo",
    "start": "828380",
    "end": "834170"
  },
  {
    "text": "di workload per analytics avremmo un tipo di formato preferito rispetto a una",
    "start": "834170",
    "end": "840020"
  },
  {
    "text": "trasposizione che possiamo avere per per quello che riguarda il machine learning",
    "start": "840020",
    "end": "846280"
  },
  {
    "text": "quindi a seconda delle analisi noi dobbiamo avere un meccanismo che analizzi la qualità di questo dato e",
    "start": "846540",
    "end": "854670"
  },
  {
    "text": "nello step successivo appunto ci aiuti in base alle mancanze a preparare questo",
    "start": "854670",
    "end": "859960"
  },
  {
    "text": "dato all'analisi che vogliamo effettuare quindi preparazione per l'analisi una",
    "start": "859960",
    "end": "868450"
  },
  {
    "text": "parte di questo processo appunto è in base alla qualità del dato aggiustarlo",
    "start": "868450",
    "end": "874180"
  },
  {
    "text": "per cui cambiare formato delle colonne cambiare aggiungere colonne per cui fare hinrich mendel dato in caso appunto",
    "start": "874180",
    "end": "879700"
  },
  {
    "text": "servisse per un internato tipo di analisi e molto importante è il formato del tipo del file che abbiamo acquisito",
    "start": "879700",
    "end": "885550"
  },
  {
    "text": "per cui per analytics la compressione molto importante in quanto si vanno a movimentare grosse quantità di dati e",
    "start": "885550",
    "end": "892980"
  },
  {
    "text": "che il file sia spettabile per cui in un processo di calcolo distribuito",
    "start": "892980",
    "end": "899040"
  },
  {
    "text": "aggredire il vostro data 7 in parallelo è quello che voi volete fare per",
    "start": "899040",
    "end": "904270"
  },
  {
    "text": "analizzare i maya più veloce e più efficiente il dato è il formato stesso del file appunto formati come il csv che",
    "start": "904270",
    "end": "912040"
  },
  {
    "text": "sono formati definiti per riga occupano molto più tempo in una fase di estrazione rispetto a un formato",
    "start": "912040",
    "end": "917410"
  },
  {
    "text": "colonnare dove noi andiamo a prendere la singola colonna di interesse dal dato invece che scansionare ad estrarre",
    "start": "917410",
    "end": "923170"
  },
  {
    "text": "l'intera riga e prendere subset del dato interessato l'orchestrazione dobbiamo",
    "start": "923170",
    "end": "930250"
  },
  {
    "text": "avere comunque una serie di strumenti che ci orchestrano tutta questa pipe line per cui appunto una sorta di crohn",
    "start": "930250",
    "end": "940060"
  },
  {
    "text": "distribuito piuttosto che appunto servizi back che ci permettano al verificarsi di determinati eventi di far",
    "start": "940060",
    "end": "946600"
  },
  {
    "text": "scaturire appunto step nella pipeline per acquisizione analisi esportazioni di",
    "start": "946600",
    "end": "952540"
  },
  {
    "text": "dati aggregazione e tutta questa parte cdc per cui change data capture dobbiamo",
    "start": "952540",
    "end": "961530"
  },
  {
    "text": "comunque avere uno strumento che ci permetta di ospitare tutte le modifiche che vengono",
    "start": "961530",
    "end": "967579"
  },
  {
    "text": "fatte a un dato e e pro pagarle per cui",
    "start": "967579",
    "end": "972610"
  },
  {
    "text": "dobbiamo avere appunto uno strumento che a seconda della fonte che sia relazionale che sia appunto bacio",
    "start": "972610",
    "end": "978199"
  },
  {
    "text": "streaming che sia in grado di estrarre questa informazione di far emergere di ed inserirla all'interno appunto del",
    "start": "978199",
    "end": "985399"
  },
  {
    "text": "nostro della nostra componente dati questo è uno schema riepilogativo di",
    "start": "985399",
    "end": "992000"
  },
  {
    "text": "tutto quello che abbiamo detto e sono tutti pilla fondamentali che in un architettura tradizionale occupano",
    "start": "992000",
    "end": "997370"
  },
  {
    "text": "veramente circa l'ottanta per tempo del tempo ma che cosa che perché noi",
    "start": "997370",
    "end": "1009610"
  },
  {
    "text": "riuscissimo a automatizzare tutta questa",
    "start": "1009610",
    "end": "1015160"
  },
  {
    "text": "parte per avere l'ottanta per cento del valore mentre contro il 20 per cento del lavoro e che cosa succederebbe appunto",
    "start": "1015160",
    "end": "1021730"
  },
  {
    "text": "riusciremo molto di più a concentrarci sul nostro business per cui appunto analisi quelle stazioni di dati",
    "start": "1021730",
    "end": "1028058"
  },
  {
    "text": "esplorazioni di dati per riuscire estrarre maggior valore dal dal nostro",
    "start": "1028059",
    "end": "1033400"
  },
  {
    "text": "dataset e da blue air ci permette di fare proprio proprio questo",
    "start": "1033400",
    "end": "1038908"
  },
  {
    "text": "riuscirà appunto a concentrarci meno su quello che riguarda le risorse ti la gestione macchine virtuali servizi",
    "start": "1038950",
    "end": "1046089"
  },
  {
    "text": "storage ma appunto riuscire a concentrarci molto di più sul sul valore",
    "start": "1046090",
    "end": "1051160"
  },
  {
    "text": "è stato dai nostri dati che cosa vuol dire sue da blu es",
    "start": "1051160",
    "end": "1057100"
  },
  {
    "text": "mettere tutto quello di cui abbiamo parlato insieme questa è una è una",
    "start": "1057100",
    "end": "1064450"
  },
  {
    "text": "figura di esempio una una tipica architettura che comprende tutti i punti",
    "start": "1064450",
    "end": "1071590"
  },
  {
    "text": "di cui abbiamo appena discusso sulla parte sinistra e potrete vedere appunto",
    "start": "1071590",
    "end": "1076810"
  },
  {
    "text": "una serie di servizi messi a disposizione da brooks che riguardano la parte di teen gestio alcune ri andremo a",
    "start": "1076810",
    "end": "1084280"
  },
  {
    "text": "vedere un filo più nel dettaglio nelle prossime slide per esempio appunto chinesi sia un servizio di data streaming direct connect è un servizio",
    "start": "1084280",
    "end": "1091360"
  },
  {
    "text": "che fisicamente connette le vostre location ei vostri i vostri data center",
    "start": "1091360",
    "end": "1097180"
  },
  {
    "text": "con le infrastrutture da blu es e snowboard è un'appliance fisica che",
    "start": "1097180",
    "end": "1102220"
  },
  {
    "text": "per partire con una migrazione di grossa mole di dati vi permette fisicamente di caricare su questo device fino a 100",
    "start": "1102220",
    "end": "1109300"
  },
  {
    "text": "tera e rispedire in una location per fare le in gesti hanno invece che consumare la banda per spostarle appunto",
    "start": "1109300",
    "end": "1114930"
  },
  {
    "text": "via internet e di ms database migration services è un servizio che funziona",
    "start": "1114930",
    "end": "1121420"
  },
  {
    "text": "appunto a due layer di funzionamento il primo è replicato tale di una fonte relazionale dai dal da un engine allo",
    "start": "1121420",
    "end": "1129970"
  },
  {
    "text": "stesso engine oppure in maniera eterogenea da un engine a un engine differente oppure è una volta effettuata appunto la",
    "start": "1129970",
    "end": "1136840"
  },
  {
    "text": "prima migrazione in grado di tenere in sync il vostro dato fino a quando voi deciderete di fare lo lo switch del",
    "start": "1136840",
    "end": "1143500"
  },
  {
    "text": "vostro database on premises con una fonte relazionale su amazon web services",
    "start": "1143500",
    "end": "1151840"
  },
  {
    "text": "tutti questi dati in gesti un funzione confluiscono in uno storage centrale per cui il nostro concetto di cui abbiamo discusso data lake e come data lake lato",
    "start": "1151840",
    "end": "1159910"
  },
  {
    "text": "amazon web services la soluzione principe amazon s3 simple storage service ossia è uno storage e oggetti è",
    "start": "1159910",
    "end": "1168310"
  },
  {
    "text": "rappresentato come un file system ma non è un file system in quanto appunto voi andrete a chiedere",
    "start": "1168310",
    "end": "1174940"
  },
  {
    "text": "una chiave che appunto è il vostro pad il vostro baker più prefix è l'oggetto",
    "start": "1174940",
    "end": "1180010"
  },
  {
    "text": "ritornato sarà il contenuto del file nella sede dei file che voi volete andare ad analizzare e rispecchia tutti",
    "start": "1180010",
    "end": "1187930"
  },
  {
    "text": "pillar che abbiamo visto di questo data lake e durabilità in primis s3 offre un dc9 di durabilità per cui se dobbiamo",
    "start": "1187930",
    "end": "1195160"
  },
  {
    "text": "pensare di mettere tutti i dati nello stesso punto vogliamo che questo dato che questo servizio sia offra una grande",
    "start": "1195160",
    "end": "1202030"
  },
  {
    "text": "e durabilità del dato verso s iii possono essere applicate delle policy di sicurezza per cui potete definire a",
    "start": "1202030",
    "end": "1209740"
  },
  {
    "text": "livello di singolo oggetto chi può accedere e che cosa può fare se possono leggerlo può scriverlo può modificarlo o",
    "start": "1209740",
    "end": "1217200"
  },
  {
    "text": "applica appunto diversi di diverse perché me lo chiamate batte policy su su tutti i contenuti ds3 per quello che",
    "start": "1217200",
    "end": "1225730"
  },
  {
    "text": "riguarda il ciclo di vita dello storage è possibile applicare quelle che noi",
    "start": "1225730",
    "end": "1231190"
  },
  {
    "text": "chiamiamo livecycle policy ossia una serie di eventi di trasformazione dello",
    "start": "1231190",
    "end": "1238090"
  },
  {
    "text": "storage di spostamento dello storage in in lei sa di storia più freddi partendo da s3 standard appunto abbiamo",
    "start": "1238090",
    "end": "1244750"
  },
  {
    "text": "la modalità più calda fino a arrivare a a glazer che è la nostra forma di dati appunto di retention di dati per il",
    "start": "1244750",
    "end": "1252010"
  },
  {
    "text": "lungo periodo che appunto un costo a giga molto più basso ma sono dati che noi non pensiamo di dover recuperare o",
    "start": "1252010",
    "end": "1258130"
  },
  {
    "text": "accedere frequentemente e di default e",
    "start": "1258130",
    "end": "1263320"
  },
  {
    "text": "s3 replica il dato cinque volte all'interno della stessa ragion per cui abbiamo anche risolto il problema del",
    "start": "1263320",
    "end": "1269860"
  },
  {
    "text": "disaster recovery facendo una singola punte verso verso il web services ds3 il",
    "start": "1269860",
    "end": "1274990"
  },
  {
    "text": "nostro dato sarà sarà replicato per cui possiamo pensare di separare",
    "start": "1274990",
    "end": "1280150"
  },
  {
    "text": "completamente decuplicare completamente lo storage rispetto a qualsiasi altro tipo di risorse che ci deve accedere",
    "start": "1280150",
    "end": "1286680"
  },
  {
    "text": "nella parte destra appunto vediamo una serie di servizi anche qua alcuni di questi li vedremo un filo che nel",
    "start": "1286680",
    "end": "1292600"
  },
  {
    "text": "dettaglio all'interno di questa presentazione di analytics per cui",
    "start": "1292600",
    "end": "1298200"
  },
  {
    "text": "e da bruna soffre dei servizi come amazon a tina che è un servizio di query",
    "start": "1298200",
    "end": "1303930"
  },
  {
    "text": "serverless ossia voi potrete scrivere la vostra query anzi sequel via gb vco",
    "start": "1303930",
    "end": "1311370"
  },
  {
    "text": "dalla nostra console in gb ceo di visivi non c'è un vero e proprio database 8",
    "start": "1311370",
    "end": "1317070"
  },
  {
    "text": "sono flat file presenti su s3 che verranno interrogati e restituiranno appunto un risultato di amare la stigma",
    "start": "1317070",
    "end": "1327150"
  },
  {
    "text": "previous è un servizio di di cluster aduc gestiti all'interno di questo",
    "start": "1327150",
    "end": "1333330"
  },
  {
    "text": "cluster voi potrete andare a specificare che tipo di applicazione volete usare per le nostre le vostre analytics",
    "start": "1333330",
    "end": "1338400"
  },
  {
    "text": "appunto da sono supportate circa 25 applicazioni ad oggi delle più comuni dell'ecosistema di bigg detta quali",
    "start": "1338400",
    "end": "1344850"
  },
  {
    "text": "appunto ai big spark presto anche per la",
    "start": "1344850",
    "end": "1350040"
  },
  {
    "text": "parte di visualizzazione abbiamo jupiter lo zeppelin per esempio ho io per la parte di visualizzazione e",
    "start": "1350040",
    "end": "1357150"
  },
  {
    "text": "redshift che è il nostro servizio di data warehouse gestito anche questo lo",
    "start": "1357150",
    "end": "1363120"
  },
  {
    "text": "vedremo più in dettaglio nella nella parte alta sinistra appunto abbiamo",
    "start": "1363120",
    "end": "1369030"
  },
  {
    "text": "abbiamo detto che che vogliamo catalogare i nostri metadati per cui ci sono una serie di servizi di tra",
    "start": "1369030",
    "end": "1375930"
  },
  {
    "text": "virgolette indicizzazione del nostro dato come dynamo di b che è il servizio da blu es per data business sequel",
    "start": "1375930",
    "end": "1383870"
  },
  {
    "text": "totalmente gestito voi non dovrete far altro che creare una un'equipe il minimo",
    "start": "1383870",
    "end": "1392850"
  },
  {
    "text": "che dovete fare è creare un husky e volee e dovete definire le performance che vi aspettate in termini di letture o",
    "start": "1392850",
    "end": "1400380"
  },
  {
    "text": "scrittore per secondo e il servizio si occuperà di scalare il vostro vi accoglie il vostro dato di scalarlo in",
    "start": "1400380",
    "end": "1406560"
  },
  {
    "text": "base al trucco che voi avete provvisionato per cui si occuperà lui stesso di fare la replica del dato",
    "start": "1406560",
    "end": "1412830"
  },
  {
    "text": "supporta repliche geografiche per cui il vostro dataset lo potete servire su più regioni per poter tenere il dato più",
    "start": "1412830",
    "end": "1419160"
  },
  {
    "text": "vicino all'utente ed avere latenza inferiore per esempio elastic sergio un servizio che hanno inserito qualche",
    "start": "1419160",
    "end": "1424800"
  },
  {
    "text": "abbastanza recente che si chiama gru che andava a vedere nel dettaglio che è un servizio di data catalog ed è tl gestito",
    "start": "1424800",
    "end": "1430950"
  },
  {
    "text": "e esporre il dato per farlo consumare ad",
    "start": "1430950",
    "end": "1436360"
  },
  {
    "text": "altri ed altri altri stakeholder per esempio con atti gatwick è appunto un servizio di epia e gestite dove voi",
    "start": "1436360",
    "end": "1441760"
  },
  {
    "text": "andrete a definire i vostri metodi e ogni metodo verrà agganciato a una",
    "start": "1441760",
    "end": "1448030"
  },
  {
    "text": "funzione lamanna piuttosto che appunto un qualsiasi altro tipo di risorsa sui c2 o qualsiasi altro tipo di cosa",
    "start": "1448030",
    "end": "1455730"
  },
  {
    "text": "cognato che è un servizio che permette lato client di effettuare autenticazione su diversi altri servizi quindi non",
    "start": "1455730",
    "end": "1463840"
  },
  {
    "text": "avete la necessità di scolpire credenziali di accesso ma appunto è questo questo servizio",
    "start": "1463840",
    "end": "1469270"
  },
  {
    "text": "utilizzerò una sorta di totem vending machine dove verrà generato un token per",
    "start": "1469270",
    "end": "1477400"
  },
  {
    "text": "accedere hanno terminato tipo di risorse valido solamente per la richiesta e security",
    "start": "1477400",
    "end": "1484240"
  },
  {
    "text": "ci sono una serie di servizi che sono associati alla security compliance e audit per esempio appunto aim che il",
    "start": "1484240",
    "end": "1492040"
  },
  {
    "text": "nostro servizio di identity asset management voi potrete definire account",
    "start": "1492040",
    "end": "1497200"
  },
  {
    "text": "utente gruppi una serie di permessi di che cosa possono fare le persone o",
    "start": "1497200",
    "end": "1503940"
  },
  {
    "text": "servizi potete definire dei ruoli e associarli a un determinato tipo di",
    "start": "1503940",
    "end": "1509560"
  },
  {
    "text": "servizio per esempio potete definire un ruolo su un'istanza virtuale c2 e dire questa istanza può parlare con s3 per",
    "start": "1509560",
    "end": "1516790"
  },
  {
    "text": "fare questo tipo di ep ai solamente su questo basket per cui non dovrete più",
    "start": "1516790",
    "end": "1522960"
  },
  {
    "text": "implementare credenziali anche all'interno dell'istanza cloud trail per esempio un servizio di dio dite dove",
    "start": "1522960",
    "end": "1528720"
  },
  {
    "text": "tutte le chiamate e piaia effettuate all'interno di un account verranno brano logate e rese disponibili appunto per",
    "start": "1528720",
    "end": "1534850"
  },
  {
    "text": "capire che cosa è stato fatto a livello di eps su tutte le risorse e dabliu est",
    "start": "1534850",
    "end": "1540040"
  },
  {
    "text": "presenti nello specifico account",
    "start": "1540040",
    "end": "1544690"
  },
  {
    "text": "vediamo più nel dettaglio una serie di servizi in questo caso per la parte di",
    "start": "1546320",
    "end": "1552350"
  },
  {
    "text": "ingestione per la parte di cataloghi in kinesis els e il nostro servizio di di",
    "start": "1552350",
    "end": "1557900"
  },
  {
    "text": "data streaming per cui appunto voi potrete pubblicare i vostri dati su un",
    "start": "1557900",
    "end": "1563300"
  },
  {
    "text": "bocchettone e consumarli appunto dall'altra parte per cui per esempio avete avrete un'applicazione mobile e",
    "start": "1563300",
    "end": "1570500"
  },
  {
    "text": "genererà dei log questa applicazione e voi con kinesis potete far confluire all'interno dello stesso bocchettone",
    "start": "1570500",
    "end": "1576410"
  },
  {
    "text": "questi log consumarli dalla lav e da blu es per poter non lo so creare un ad ascom",
    "start": "1576410",
    "end": "1584270"
  },
  {
    "text": "realta inter appunto analizzare una serie di errori che si verificano all'interno della vostra applicazione e",
    "start": "1584270",
    "end": "1590630"
  },
  {
    "text": "per poter avere un insight su quello che sta succedendo è una new skies cinesi si",
    "start": "1590630",
    "end": "1596390"
  },
  {
    "text": "rivede si divide in quattro principali servizi quelli che noi vedremo per lo più nel dettaglio sono i primi tre",
    "start": "1596390",
    "end": "1602500"
  },
  {
    "text": "datastream appunto è il servizio come vi ho descritto e voi dovrete andare a definire il",
    "start": "1602500",
    "end": "1608240"
  },
  {
    "text": "vostro bocchettone di stream e la sua quante richieste sia in scrittura che in",
    "start": "1608240",
    "end": "1615950"
  },
  {
    "text": "lettura voi vi aspettate di avere e potete dimensionare lo potete far scalare internamente questo bocchettone",
    "start": "1615950",
    "end": "1621800"
  },
  {
    "text": "in modo da poter ospitare picchi oppure il traffico crescente nell'esempio di",
    "start": "1621800",
    "end": "1627890"
  },
  {
    "text": "prima di un'applicazione mobile appunto quanti e device hanno installato oggi la",
    "start": "1627890",
    "end": "1633290"
  },
  {
    "text": "vostra applicazione per cui in base a quelli voi potrete far crescere o ridurre il numero di richieste in",
    "start": "1633290",
    "end": "1638990"
  },
  {
    "text": "scrittura al secondo che possono che può ospitare di default ospita il 1000",
    "start": "1638990",
    "end": "1645890"
  },
  {
    "text": "record in scrittura al secondo per cui ci sono clienti che come per esempio",
    "start": "1645890",
    "end": "1651560"
  },
  {
    "text": "data data zucche è un che è un cliente che fa programmatico marketing che",
    "start": "1651560",
    "end": "1657799"
  },
  {
    "text": "con kinesis riesce a gestire un milione di record al secondo cyrus allo stesso",
    "start": "1657799",
    "end": "1664519"
  },
  {
    "text": "funzionamento di stream ossia voi producete un dato e l'ho inviata in questo stream ma il dato viene consumato in maniera",
    "start": "1664519",
    "end": "1670909"
  },
  {
    "text": "automatica voi potrete decidere come ci sono una serie di modalità come per",
    "start": "1670909",
    "end": "1676129"
  },
  {
    "text": "esempio voglio che tutti i dati che entrano vengano scritti su s3 quindi il mio data lake voglio che vengano messi",
    "start": "1676129",
    "end": "1681830"
  },
  {
    "text": "direttamente sul mio cluster redshift per cui data house o voglio che i dati vengano gestiti direttamente da elastic",
    "start": "1681830",
    "end": "1687590"
  },
  {
    "text": "search per esempio fa heroes vi permette di automatizzare tutta la parte di consumo inventato analytics è in",
    "start": "1687590",
    "end": "1696409"
  },
  {
    "text": "servizio un po più particolare ossia sul dato che voi mettete nello stream avete la possibilità di applicare uno schema e",
    "start": "1696409",
    "end": "1703279"
  },
  {
    "text": "di effettuare una query per cui estrarre e o aggregare e una serie un subset di",
    "start": "1703279",
    "end": "1708320"
  },
  {
    "text": "dati che stanno passando in tempo reale sul vostro stream per esempio tipico caso di una dashboard in real time di",
    "start": "1708320",
    "end": "1714399"
  },
  {
    "text": "televoto per esempio voi potrete andare a vedere tutto quello che vi sta arrivando sullo stream aggregare questo",
    "start": "1714399",
    "end": "1721070"
  },
  {
    "text": "dato per tipo di voto e aggiunge una sede di informazione come per esempio lo",
    "start": "1721070",
    "end": "1726200"
  },
  {
    "text": "user agent del device che ha effettuato questo televoto e con l'utilizzo di",
    "start": "1726200",
    "end": "1732350"
  },
  {
    "text": "altri servizi da brewers potete creare una sportina realtà in sul dato che sta transitando in quel momento clou è un",
    "start": "1732350",
    "end": "1740779"
  },
  {
    "text": "servizio che sia si compone di due componenti preziosi è formato da due componenti principali la prima è quella",
    "start": "1740779",
    "end": "1745879"
  },
  {
    "text": "appunto di data catalogo ossia voi potrete creare quelli che vengono definiti crawler ossia degli agenti che",
    "start": "1745879",
    "end": "1753350"
  },
  {
    "text": "vanno a fare una scansione dei vostri dati nel vostro data lake e applicano uno schema per cui capiscono il formato",
    "start": "1753350",
    "end": "1761499"
  },
  {
    "text": "sono configurati per capire i più comuni formati performance per cui csv tsv",
    "start": "1761499",
    "end": "1767299"
  },
  {
    "text": "perché sia vero e simili oppure voi potrete definire il vostro",
    "start": "1767299",
    "end": "1772600"
  },
  {
    "text": "classificatore custom e in modo da punto da permettere di capire la struttura il vostro dato e rendono disponibile il",
    "start": "1772600",
    "end": "1779450"
  },
  {
    "text": "meta dato tramite a rimetter store la cosa molto interessante è che tutte",
    "start": "1779450",
    "end": "1786559"
  },
  {
    "text": "queste questi metadati sono versión abili per cui voi nel tempo potrete decidere di utilizzare una specifica",
    "start": "1786559",
    "end": "1792440"
  },
  {
    "text": "versione se il dato che volete analizzare un dato vecchio o comunque potete capire come è cambiato il vostro",
    "start": "1792440",
    "end": "1797869"
  },
  {
    "text": "dato all'interno di una della finestra temporale la seconda parte dell'ue il servizio di",
    "start": "1797869",
    "end": "1803299"
  },
  {
    "text": "etl ossia blu vi permette di scegliere tra una serie di etl integrate nel",
    "start": "1803299",
    "end": "1809779"
  },
  {
    "text": "servizio le tl più comuni per esempio trasformazione di un da un formato un formato piuttosto che aggiunta o",
    "start": "1809779",
    "end": "1815720"
  },
  {
    "text": "soppressione di colonne oppure vi da la possibilità di scrivere la vostra etl su framework spark è un",
    "start": "1815720",
    "end": "1825979"
  },
  {
    "text": "servizio totalmente gestito ossia voi dovrete solamente scrive il vostro codice o scegliere una delle belle che l",
    "start": "1825979",
    "end": "1833149"
  },
  {
    "text": "built in e lui potrà applicare queste tl su base temporale o su base evento non",
    "start": "1833149",
    "end": "1839210"
  },
  {
    "text": "dovrete preoccuparvi dell'infrastruttura sottostante per cui tutta quella parte",
    "start": "1839210",
    "end": "1844429"
  },
  {
    "text": "gestita voi sarete al ponte su lati da dover mantenere e configurare una serie",
    "start": "1844429",
    "end": "1849710"
  },
  {
    "text": "di macchine che fanno appunto questo tipo di data processing elaborazione del",
    "start": "1849710",
    "end": "1856970"
  },
  {
    "text": "dato abbiamo visto prima sulla parte destra una serie di servizi che offre da blu es",
    "start": "1856970",
    "end": "1863929"
  },
  {
    "text": "per per elaborare per lavorare questo dato più o meno in maniera agile più o meno in maniera serverless questo perché",
    "start": "1863929",
    "end": "1872659"
  },
  {
    "text": "perché appunto in base al al flusso di dati al tipo di dati al tipo di formato al tipo di vostre risorse che devono",
    "start": "1872659",
    "end": "1880849"
  },
  {
    "text": "accedere il dato è lo scopo può essere differente appunto può essere data",
    "start": "1880849",
    "end": "1887149"
  },
  {
    "text": "exploration piuttosto che può essere reporting per questo appunto ci sono una",
    "start": "1887149",
    "end": "1892609"
  },
  {
    "text": "serie di servizi lato latte dabliu esche che agevolano che già fanno questo",
    "start": "1892609",
    "end": "1899929"
  },
  {
    "text": "compito mantenendo appunto costante",
    "start": "1899929",
    "end": "1904999"
  },
  {
    "text": "quello che abbiamo appena visto quindi sulla parte sinistra del data lake possiamo avere appunto match per cui",
    "start": "1904999",
    "end": "1912409"
  },
  {
    "text": "appunto per esempio è la stigma prelios per cui jobs park o iron qualsiasi altro",
    "start": "1912409",
    "end": "1918139"
  },
  {
    "text": "tipo di applicazione supportata possono direttamente interfacciarsi al vostro",
    "start": "1918139",
    "end": "1923149"
  },
  {
    "text": "data lake per leggere scrivere e tra database transazionali o non",
    "start": "1923149",
    "end": "1929989"
  },
  {
    "text": "transazionali per cui dynamo di b lo abbiamo visto prima rds il nostro servizio di database gestito che può",
    "start": "1929989",
    "end": "1936799"
  },
  {
    "text": "appunto interfacciarsi a fare l'ingestione di contenuti presenti sul",
    "start": "1936799",
    "end": "1942230"
  },
  {
    "text": "posto data lake visualizzazione a amazon è labile soffre un servizio chiamato",
    "start": "1942230",
    "end": "1948470"
  },
  {
    "text": "quick site che appunto che è un servizio che permette su partendo dal vostro data lei che partendo da una seria altri",
    "start": "1948470",
    "end": "1954019"
  },
  {
    "text": "servizi di creare delle delle dashboard interattive ciò non",
    "start": "1954019",
    "end": "1959300"
  },
  {
    "text": "toglie appunto che voi potete andare a utilizzare più comuni strumenti che state già magari utilizzando ad oggi che",
    "start": "1959300",
    "end": "1964520"
  },
  {
    "text": "siano compatibili jdbc è possibile interfacciarsi con una serie di servizi vierge di b si e continua a utilizzare",
    "start": "1964520",
    "end": "1969890"
  },
  {
    "text": "il vostro strumento tempo reale appunto",
    "start": "1969890",
    "end": "1975430"
  },
  {
    "text": "svariati casi anche appunto nel settore pubblico come per esempio l'ingestione",
    "start": "1975460",
    "end": "1980540"
  },
  {
    "text": "di dati provenienti da sensori sparsi per la città e anche qui appunto abbiamo",
    "start": "1980540",
    "end": "1986360"
  },
  {
    "text": "diversi tipi di applicazioni gestite dalla blu di di servizi gestiti dai blacks come per esempio amazon elastic",
    "start": "1986360",
    "end": "1992150"
  },
  {
    "text": "serre si è basato su sulla versione open source di elasti search lambda in",
    "start": "1992150",
    "end": "1998930"
  },
  {
    "text": "servizio appunto di fanciulle service ossia voi potrebbe definire a verificarsi di un determinato evento una",
    "start": "1998930",
    "end": "2005560"
  },
  {
    "text": "porzione di codice da eseguire in maniera ripetitiva per esempio controllo della della qualità del dato il dato che",
    "start": "2005560",
    "end": "2010990"
  },
  {
    "text": "mi sta entrando devo controllare che abbia tutti questi campi lo posso fare in tempo reale su un dato che paziente un pò reale in maniera totalmente",
    "start": "2010990",
    "end": "2016660"
  },
  {
    "text": "serverless per quello che riguarda invece la parte di intelligenza artificiale ci sono una serie di web",
    "start": "2016660",
    "end": "2024670"
  },
  {
    "text": "service dal dal più gestito come per esempio appunto recognition mi viene caricata un'immagine nel mio data lake",
    "start": "2024670",
    "end": "2032770"
  },
  {
    "text": "tramite recognition io posso estrarre una serie di informazioni la storia di lei ball da questa da questa immagine",
    "start": "2032770",
    "end": "2040390"
  },
  {
    "text": "piuttosto che man mano che scendiamo",
    "start": "2040390",
    "end": "2045730"
  },
  {
    "text": "appunto in questa parte del grafico ci sono servizi che più indicati verso",
    "start": "2045730",
    "end": "2051520"
  },
  {
    "text": "appunto data scientist il quale si devono interfacciare con un framework come per esempio mx net per andare a",
    "start": "2051520",
    "end": "2057129"
  },
  {
    "text": "scrivere il loro algoritmi di machine learning la possibilità di effettuare training and deployment con con servizi",
    "start": "2057130",
    "end": "2063879"
  },
  {
    "text": "come mx net che vedremo nel pomeriggio abbiamo parlato prima di chiamare la",
    "start": "2063880",
    "end": "2070179"
  },
  {
    "text": "stigma peius è un servizio gestito nel quale",
    "start": "2070180",
    "end": "2076129"
  },
  {
    "text": "il contropiede da blu es prende in carico tutto il ciclo di vita del cluster per cui lancio del cluster",
    "start": "2076130",
    "end": "2082250"
  },
  {
    "text": "numerosità distanze ct di applicazioni installate sul cluster configurazione di queste applicazioni ciclo di vita di un",
    "start": "2082250",
    "end": "2088520"
  },
  {
    "text": "nodo in quanto c'è un nodo appunto dovesse avere dei problemi hardware in servizio si occupa di rimpiazzarlo e di replicare il dato e ha determinate",
    "start": "2088520",
    "end": "2096379"
  },
  {
    "text": "caratteristiche se pensate appunto a separare lo storage dal compiuto voi non avete più la",
    "start": "2096380",
    "end": "2103010"
  },
  {
    "text": "necessità di avere un cluster sempre running magari appunto per l'ottanta per cento",
    "start": "2103010",
    "end": "2109520"
  },
  {
    "text": "idol ma potrete lanciare un cluster solamente nella finestra temporale in cui avete bisogno di effettuare una",
    "start": "2109520",
    "end": "2115370"
  },
  {
    "text": "determinata analisi e spegnerlo salvare il risultato sul vostro data lei che spegnerlo cerchiamo di visto che si",
    "start": "2115370",
    "end": "2124160"
  },
  {
    "text": "parla di ecolsystema big data sono tutti i progetti open source siano dei cicli di dire liz molto veloci per cui noi",
    "start": "2124160",
    "end": "2131120"
  },
  {
    "text": "tendiamo di avere ad avere la la stable release disponibile sui classe per",
    "start": "2131120",
    "end": "2138080"
  },
  {
    "text": "questo servizio per cui ci sono circoli di release è di questo servizio di circa 30 giorni ed è molto semplice da da",
    "start": "2138080",
    "end": "2145850"
  },
  {
    "text": "lanciare e di default a configurare con un ep ai voi potrete avere il vostro cluster potenzialmente di migliaia di",
    "start": "2145850",
    "end": "2153020"
  },
  {
    "text": "nodi run in pochi minuti e poche decine di minuti subito disponibile per",
    "start": "2153020",
    "end": "2161000"
  },
  {
    "text": "accedere i vostri dati che saranno nel nel data lake atina attiva lo abbiamo",
    "start": "2161000",
    "end": "2166760"
  },
  {
    "text": "visto prima appunto è un modello di di quelle interattive totalmente serverless",
    "start": "2166760",
    "end": "2172520"
  },
  {
    "text": "dove voi andrete appunto a scrivere la vostra la vostra query e i dati verranno",
    "start": "2172520",
    "end": "2177730"
  },
  {
    "text": "interrogati aggregati partendo da dal vostro da play che da s3",
    "start": "2177730",
    "end": "2183790"
  },
  {
    "text": "se vi ricordate prima abbiamo visto glu glu si occupa tra le altre cose di andare a fare una scansione dei vostri dati e mettere a disposizione dei",
    "start": "2183830",
    "end": "2189620"
  },
  {
    "text": "metadati ad altri servizi come per esempio a tina una volta che il vostro dato entra nella dark blue sea per me si",
    "start": "2189620",
    "end": "2195230"
  },
  {
    "text": "occuperà di generare uno schema e di metterlo a disposizione di altri servizi come prese in piattina quindi in maniera",
    "start": "2195230",
    "end": "2201500"
  },
  {
    "text": "totalmente automatica voi avrete a disposizione l'accesso a schemi dei vostri dati",
    "start": "2201500",
    "end": "2206510"
  },
  {
    "text": "qui avrete appena fatto l'ingestione e potrete andare immediatamente interrogarli",
    "start": "2206510",
    "end": "2211580"
  },
  {
    "text": "la modalità deep ice inviati nei molto interessante ogni singola query e tariffata in base",
    "start": "2211580",
    "end": "2217250"
  },
  {
    "text": "al throughput di dati che voi avete scansionato a 5 dollari al terabyte di dati scansionati per cui maggiore è",
    "start": "2217250",
    "end": "2225890"
  },
  {
    "text": "l'efficienza sul dato per cui compressione formati colonnari",
    "start": "2225890",
    "end": "2231610"
  },
  {
    "text": "come scrivete la query appunto si evita di fare futebol scan per esempio voi",
    "start": "2231770",
    "end": "2237560"
  },
  {
    "text": "riuscirete ad avere query che terminano veramente pochi minuti in pochi secondi",
    "start": "2237560",
    "end": "2243200"
  },
  {
    "text": "su dataset molto grandi e pagare solamente per per il risultato della della numerosità di dati che avete",
    "start": "2243200",
    "end": "2249860"
  },
  {
    "text": "scanzonato e appunto a degli utilizzi particolari può essere appunto adottato per generare realtà investor piuttosto",
    "start": "2249860",
    "end": "2257090"
  },
  {
    "text": "che appunto data scientist possono utilizzarlo per per andare appunto esplorare date da post location redshift",
    "start": "2257090",
    "end": "2266420"
  },
  {
    "text": "e invece è sempre appunto per la parte di elaborazione e è un servizio di dato",
    "start": "2266420",
    "end": "2271460"
  },
  {
    "text": "vale fausto basato su pos cles e supporta appunto molti paul parallel",
    "start": "2271460",
    "end": "2278900"
  },
  {
    "text": "processing per cui tutti i nodi del vostro cluster in parallelo una volta che viene sottomessa una query eseguono",
    "start": "2278900",
    "end": "2286130"
  },
  {
    "text": "una porzione della vostra guerra in modo da ritornare poi all'interno del risultato è una risorsa scalabile come",
    "start": "2286130",
    "end": "2292070"
  },
  {
    "text": "per esempio la stima tra di voi in base a alla al tipo di calcolo o alla",
    "start": "2292070",
    "end": "2299150"
  },
  {
    "text": "quantità di storage locale se decide di tenere un dato locale avete bisogno voi potrete aggiungere o ridurre i nodi e",
    "start": "2299150",
    "end": "2305810"
  },
  {
    "text": "supporta una serie di open file format appunto come abbiamo visto prima parquet aversi avro csv e voi parte dal vostro",
    "start": "2305810",
    "end": "2313100"
  },
  {
    "text": "da tale che in caso di dati locali potrete fare direttamente l'ingestione di questi dati partendo da s3 con",
    "start": "2313100",
    "end": "2318350"
  },
  {
    "text": "un'opzione appunto di d messi a disposizione da redshift ereditata da posters che il copy koman e",
    "start": "2318350",
    "end": "2324209"
  },
  {
    "text": "potete fare anche l'inverso con la love con voi potrete andare a recuperare una",
    "start": "2324209",
    "end": "2329339"
  },
  {
    "text": "parte dei dati locali andarle a salvare nel vostro da tale per cui potrete decidere di fare una sorta di etl",
    "start": "2329339",
    "end": "2335219"
  },
  {
    "text": "un'aggregazione con redshift eri esportava nel vostro data lake per metterla a disposizione di un altro team appunto a livello di costo è molto",
    "start": "2335219",
    "end": "2344429"
  },
  {
    "text": "conveniente decide potrete voi decidere quanto pagare in base alle dimensioni del vostro cluster e in automatico",
    "start": "2344429",
    "end": "2350910"
  },
  {
    "text": "appunto c'è tutto un processo di snapshot che viene fatto da dal servizio",
    "start": "2350910",
    "end": "2356579"
  },
  {
    "text": "per cui anche la parte di di fotografia del vostro dato rispetto a data quale",
    "start": "2356579",
    "end": "2361619"
  },
  {
    "text": "house viene gestito completamente ed è incluso nel costo spectrum è",
    "start": "2361619",
    "end": "2367439"
  },
  {
    "text": "un'estensione di redshift abbiamo parti di data lake quello che spectrum",
    "start": "2367439",
    "end": "2372749"
  },
  {
    "text": "permette di fare eseguire query da redshift senza avere un dato locale ossia andare a pescare direttamente il",
    "start": "2372749",
    "end": "2378779"
  },
  {
    "text": "dato su sul vostro data lake ci sono clienti che non fanno più l'ingestione dei dati nei loro data uguale house ma",
    "start": "2378779",
    "end": "2384900"
  },
  {
    "text": "usano la potenza parallela di spectrum per andare a interrogare un dato che appunto magari in tempo reale sta",
    "start": "2384900",
    "end": "2391439"
  },
  {
    "text": "arrivando e voi a livello di marketing volete creare una dashboard real time che",
    "start": "2391439",
    "end": "2396449"
  },
  {
    "text": "faccio vedere l'andamento di quella particolare esempio campagna e ci sono dei clienti che usano redshift spectrum",
    "start": "2396449",
    "end": "2402809"
  },
  {
    "text": "in questa modalità per appunto riuscirà",
    "start": "2402809",
    "end": "2408359"
  },
  {
    "text": "veloci dare ad analizzare veramente terabyte di dati in pochissimo tempo senza dovere fare nessun tipo di import",
    "start": "2408359",
    "end": "2416219"
  },
  {
    "text": "a livello del database colonnare ma c'è",
    "start": "2416219",
    "end": "2422130"
  },
  {
    "text": "che tipo di problemi amazon ha risolto con l'uso della analytics è colluso di machine learning",
    "start": "2422130",
    "end": "2430829"
  },
  {
    "text": "qui potete vedere alcuni esempi per esempio come facciamo a risolvere il",
    "start": "2430829",
    "end": "2436529"
  },
  {
    "text": "problema delle code in uscita in un negozio amazon go è appunto 11 straw",
    "start": "2436529",
    "end": "2443339"
  },
  {
    "text": "fisico che tramite l'utilizzo di dip learning peter vision permette",
    "start": "2443339",
    "end": "2450580"
  },
  {
    "text": "all'utente di entrare in uno shop scansionando appunto un qr code dell'oro",
    "start": "2450580",
    "end": "2455590"
  },
  {
    "text": "account dei propri account fare la spesa e uscire senza dover effettuare nessun tipo di di coda o di checkout e il",
    "start": "2455590",
    "end": "2462850"
  },
  {
    "text": "sistema è in grado appunto di capire di addebitare la corretta spesa l'utente è",
    "start": "2462850",
    "end": "2468130"
  },
  {
    "text": "come facciamo appunto a offrire al cliente una migliore esperienza nell'evasione degli ordini chi va robot",
    "start": "2468130",
    "end": "2474880"
  },
  {
    "text": "sono i robot che magari avete visto video online sono dei robot che ne",
    "start": "2474880",
    "end": "2480040"
  },
  {
    "text": "winehouse di amazon aiutano lo spostamento di dirac di bancali all'utente che deve poi effettuare",
    "start": "2480040",
    "end": "2486880"
  },
  {
    "text": "download dello specifico dello specifico bene piuttosto come facciamo appunto a risolvere il problema di una delivery",
    "start": "2486880",
    "end": "2492100"
  },
  {
    "text": "più veloce verso verso l'utente premier o come ridisegnamo come ripensiamo",
    "start": "2492100",
    "end": "2498700"
  },
  {
    "text": "l'interfaccia utente verso appunto un mondo digitale che non sia appunto un",
    "start": "2498700",
    "end": "2504070"
  },
  {
    "text": "touch screen alexa appunto un interfaccia vocale rispetto ad amazon go mi volevo fare",
    "start": "2504070",
    "end": "2510310"
  },
  {
    "text": "vedere un breve video adesso rispetto a al servizio",
    "start": "2510310",
    "end": "2516570"
  },
  {
    "text": "furiosi conquistare domanda [Musica]",
    "start": "2530329",
    "end": "2544419"
  },
  {
    "text": "mons",
    "start": "2550200",
    "end": "2553200"
  },
  {
    "text": "local cm sancat gtm sangue",
    "start": "2556130",
    "end": "2563170"
  },
  {
    "text": "iphone [Musica]",
    "start": "2563340",
    "end": "2568910"
  },
  {
    "text": "sei pure",
    "start": "2568910",
    "end": "2571630"
  },
  {
    "text": "[Musica]",
    "start": "2579300",
    "end": "2587630"
  },
  {
    "text": "si no",
    "start": "2587630",
    "end": "2601599"
  },
  {
    "text": "non ci pare abitini bon",
    "start": "2602280",
    "end": "2605330"
  },
  {
    "text": "da oggi è già più che il gip",
    "start": "2607369",
    "end": "2616160"
  },
  {
    "text": "è un santo le mans series",
    "start": "2616160",
    "end": "2622550"
  },
  {
    "text": "[Musica]",
    "start": "2622550",
    "end": "2629820"
  },
  {
    "text": "[Applauso] [Musica]",
    "start": "2629820",
    "end": "2637359"
  },
  {
    "text": "ok vediamo appunto ci sono una serie di casi di uso che volevo farvi vedere di",
    "start": "2637400",
    "end": "2642780"
  },
  {
    "text": "che cosa fanno i nostri clienti reali per quello che riguarda i big data analytics and machine learning già",
    "start": "2642780",
    "end": "2651900"
  },
  {
    "text": "skipping è una è una piattaforma di",
    "start": "2651900",
    "end": "2657570"
  },
  {
    "text": "cerreti founding per cui appunto loro si occupano di di effettuare queste questa",
    "start": "2657570",
    "end": "2664330"
  },
  {
    "text": "raccolta fondi da devolvere a specifiche risorse come per esempio alzheimer",
    "start": "2664330",
    "end": "2672190"
  },
  {
    "text": "piuttosto che appunto cercano di risolvere il problema del traffico dei minori e ci sono ad oggi circa 24 mila",
    "start": "2672190",
    "end": "2681250"
  },
  {
    "text": "utenti che supportano perché sono attivi nell'utilizzo di questa piattaforma e la",
    "start": "2681250",
    "end": "2688360"
  },
  {
    "text": "compagnia è stata in grado appunto di aiutare a devolvere a 13 a circa 13 mila",
    "start": "2688360",
    "end": "2693490"
  },
  {
    "text": "cause 3.5 miliardi e il problema che",
    "start": "2693490",
    "end": "2698650"
  },
  {
    "text": "dovevano risolvere appunto era un problema di bicletta avevano una sola sorgente di verità che era appunto",
    "start": "2698650",
    "end": "2706270"
  },
  {
    "text": "sequel server ma che non riusciva più a scalare rispetto alla mole di utenti per",
    "start": "2706270",
    "end": "2711760"
  },
  {
    "text": "cui hanno deciso di andare su e dabliu s ridisegnando completamente la loro",
    "start": "2711760",
    "end": "2716980"
  },
  {
    "text": "architettura un approccio quindi serverless micro servizi per per",
    "start": "2716980",
    "end": "2722650"
  },
  {
    "text": "accedere per poter far consumare i propri dati e la fanali tix hanno scelto appunto svariate svariati servizi",
    "start": "2722650",
    "end": "2729130"
  },
  {
    "text": "partendo da voi che abbiamo appena visto elastic mapreduce chi in varie varie forme di kinesis",
    "start": "2729130",
    "end": "2735910"
  },
  {
    "text": "il tutor crestato e orchestrato tramite esse può essere che il nostro sistema di",
    "start": "2735910",
    "end": "2741900"
  },
  {
    "text": "code simplicio service e sms dalla gestione appunto di messaggi che passano",
    "start": "2741900",
    "end": "2747700"
  },
  {
    "text": "all'interno di uno specifico topic e oltre appunto alla possibilità di",
    "start": "2747700",
    "end": "2753160"
  },
  {
    "text": "lanciare cluster specifici per effettuare un determinato uno specifico tipo di analisi hanno appunto anche",
    "start": "2753160",
    "end": "2759670"
  },
  {
    "text": "visto la possibilità di salvare in termini di costi moltissimo in quanto il",
    "start": "2759670",
    "end": "2766329"
  },
  {
    "text": "loro da formale house precedente era sempre attivo con momenti veramente idol",
    "start": "2766329",
    "end": "2772030"
  },
  {
    "text": "in questo caso appunto tutto quello che viene lanciato è super ottimizzato",
    "start": "2772030",
    "end": "2778529"
  },
  {
    "text": "sembra finora è la",
    "start": "2778559",
    "end": "2784020"
  },
  {
    "text": "financial industry regulatory authority per cui è un ente indipendente americano",
    "start": "2784330",
    "end": "2789410"
  },
  {
    "text": "che controlla sorveglianza su tutte le transazioni nel mercato finanziario americano per cui tutte le transazioni",
    "start": "2789410",
    "end": "2796670"
  },
  {
    "text": "di per esempio tutti gli exchange passano da loro per essere analizzata in tempo reale e",
    "start": "2796670",
    "end": "2803450"
  },
  {
    "text": "principalmente per for the nation per cui loro controllano in tempo reale tutte le transazioni e le comparano con",
    "start": "2803450",
    "end": "2810260"
  },
  {
    "text": "transazioni precedenti per poter capire se c'è qualche tipo di tentativo di frode all'interno del mercato il mercato",
    "start": "2810260",
    "end": "2818840"
  },
  {
    "text": "e molto imprevedibile loro hanno avuto picchi di 75 miliardi di 20 al giorno ad analizzare contro una media di circa 20",
    "start": "2818840",
    "end": "2827000"
  },
  {
    "text": "miliardi e non ci sono neanche accorti quando ci sono stati questi eventi se non guardando a fine giornata sui log in",
    "start": "2827000",
    "end": "2832910"
  },
  {
    "text": "quanto l'architettura utilizzata appunto principalmente lustig mapreduce è una",
    "start": "2832910",
    "end": "2838940"
  },
  {
    "text": "serie di database relazionali qui abbiamo uno schema architetturale di quello che che loro stanno facendo per",
    "start": "2838940",
    "end": "2844190"
  },
  {
    "text": "loro hanno fatto permette appunto in maniera gestita con il minore errore in",
    "start": "2844190",
    "end": "2850370"
  },
  {
    "text": "quanto è totalmente automatizzata di analizzare questa questa enorme mole di dati riuscendo a salvare fino a 20",
    "start": "2850370",
    "end": "2857270"
  },
  {
    "text": "milioni rispetto all'implementazione sulla su una loro location sono loro",
    "start": "2857270",
    "end": "2864470"
  },
  {
    "text": "data center l'ultimo gli scherzi volevo presentare poi siamo in ritardo ma abbiamo finito e",
    "start": "2864470",
    "end": "2872090"
  },
  {
    "text": "appunto lente e sardegna del turismo con il progetto dell'osservatorio del",
    "start": "2872090",
    "end": "2878570"
  },
  {
    "text": "turismo ossia appunto uno strumento un ad escort che che raccoglie i dati i dati",
    "start": "2878570",
    "end": "2887920"
  },
  {
    "text": "turistici dati appunto vengono aggregati tutti i dati inerenti al turismo e vengono visualizzati e avevano una serie",
    "start": "2887920",
    "end": "2894220"
  },
  {
    "text": "di problemi circa appunto la ventosità della infrastruttura e dei framework",
    "start": "2894220",
    "end": "2902799"
  },
  {
    "text": "utilizzati per arrivare a questo obiettivo e costi costi molto alti e",
    "start": "2902799",
    "end": "2908650"
  },
  {
    "text": "soprattutto i tempi di lavorazione dei dati contabili versi si sono approcciati appunto a un approccio di tipo data lake",
    "start": "2908650",
    "end": "2915190"
  },
  {
    "text": "dove un'interfaccia ip ai esposta dal",
    "start": "2915190",
    "end": "2920349"
  },
  {
    "text": "loro data center espressione dabliu est permetteva di consumare di salvare tutti questi tipi di dati nel data lake e",
    "start": "2920349",
    "end": "2926799"
  },
  {
    "text": "applicare appunto schemi di security e in modalità totalmente serverless analizzare questi dati",
    "start": "2926799",
    "end": "2933869"
  },
  {
    "text": "sono riusciti anche a implementare appunto un nuovo engine di di dashboard per cui in pochi minuti vedremo ecco qua",
    "start": "2934330",
    "end": "2943040"
  },
  {
    "text": "questi sono una serie degli outcome di questo progetto sono uscita ottimizzare i costi a ottenere analisi del dato da",
    "start": "2943040",
    "end": "2950660"
  },
  {
    "text": "giorni da giorni o giorno in pochi minuti ed ad avere più cicli di",
    "start": "2950660",
    "end": "2956270"
  },
  {
    "text": "deployment in maniera totalmente automatica sia per quanto riguarda la parte di test per quanto riguarda la produzione per cui rilasciare nuove",
    "start": "2956270",
    "end": "2961670"
  },
  {
    "text": "componenti nuove ed escort in real time",
    "start": "2961670",
    "end": "2967430"
  },
  {
    "text": "e con una tecnologia totalmente serverless per cui tutta la parte di",
    "start": "2967430",
    "end": "2972530"
  },
  {
    "text": "management e di gestione di patching di backup viene totalmente scorporata si",
    "start": "2972530",
    "end": "2978830"
  },
  {
    "text": "pensa solamente alla logica di business per per arrivare appunto questi obiettivi una conclusione di quello di",
    "start": "2978830",
    "end": "2988220"
  },
  {
    "text": "cui abbiamo appena parlato per cui un approccio di tipo da fa lake il perché approcciarsi in questa modalità",
    "start": "2988220",
    "end": "2993250"
  },
  {
    "text": "strumenti con una serie appunto di link che che voi potrà consultare per vedere",
    "start": "2993250",
    "end": "2999170"
  },
  {
    "text": "questi specifici approcci soluzioni casi d'uso quindi questa la domanda che vi lascio",
    "start": "2999170",
    "end": "3005560"
  },
  {
    "text": "rispetto a quello che abbiamo visto potrete farvi una domanda su quale sarà",
    "start": "3005560",
    "end": "3011020"
  },
  {
    "text": "il prossimo business cayce che potete applicare questo tipo di approccio proceda tale grazie mille",
    "start": "3011020",
    "end": "3018930"
  }
]
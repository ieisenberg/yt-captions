[
  {
    "start": "0",
    "end": "127000"
  },
  {
    "text": "all righty good afternoon ladies and gentlemen thank you so much for joining us my name is matt woods i'm the chief data",
    "start": "2159",
    "end": "7680"
  },
  {
    "text": "scientist here at amazon web services that basically means that i get to talk to smart people such as yourselves about",
    "start": "7680",
    "end": "12960"
  },
  {
    "text": "how you're using data and then take all of your feedback and roll that into our product roadmap back in seattle at",
    "start": "12960",
    "end": "18960"
  },
  {
    "text": "amazon headquarters um now i have to be open and honest with you that you have been brought here under",
    "start": "18960",
    "end": "25840"
  },
  {
    "text": "false pretenses i am here to ask for your help as much as you are to hear about some of the awesome applications",
    "start": "25840",
    "end": "31760"
  },
  {
    "text": "that our customers are working on are using open data and so i'm just going to get that out in front right now if you",
    "start": "31760",
    "end": "37520"
  },
  {
    "text": "have data sets particularly open data sets that you think other people would find useful please drop me an email",
    "start": "37520",
    "end": "43360"
  },
  {
    "text": "matthew at amazon.com you can all write that down now i'll pause for a bit",
    "start": "43360",
    "end": "49120"
  },
  {
    "text": "so matthew amazon.com if you have open data that you think other people can benefit from we operate an open data open data program and we would love to",
    "start": "50719",
    "end": "58160"
  },
  {
    "text": "host your data and have more people interacting with it help others build tools around that data so that you can",
    "start": "58160",
    "end": "63280"
  },
  {
    "text": "use that data to build the sort of awesome applications that we're going to hear today so i'm going to talk a little",
    "start": "63280",
    "end": "68640"
  },
  {
    "text": "bit about how customers are using data in general i'm going to talk a little bit and introduce",
    "start": "68640",
    "end": "73920"
  },
  {
    "text": "the common crawl which is a data set that we host under the public data set program and i'm going to introduce ravi",
    "start": "73920",
    "end": "79280"
  },
  {
    "text": "who's going to talk a little bit about globus online which is a tool for moving data in and out of the cloud so my",
    "start": "79280",
    "end": "86159"
  },
  {
    "text": "background is very much in data before i worked at amazon i was the head of production software at the welcome trust",
    "start": "86159",
    "end": "91520"
  },
  {
    "text": "sanger institute where i worked on building out the next generation dna sequencing pipeline if you're not",
    "start": "91520",
    "end": "96640"
  },
  {
    "text": "familiar with that the original human genome took about a decade about 13",
    "start": "96640",
    "end": "102240"
  },
  {
    "text": "years and several billion dollars to sequence this was a quest to sequence every individual base of the entire",
    "start": "102240",
    "end": "108159"
  },
  {
    "text": "human genome three billion bases now you're all data people so you're thinking three billion bases no big deal",
    "start": "108159",
    "end": "113520"
  },
  {
    "text": "but that took a remarkably a large number of people a remarkably long time the sequence was very very labor",
    "start": "113520",
    "end": "119119"
  },
  {
    "text": "intensive the ultimately ultimate resulting data was actually relatively small it's only about three gig of data",
    "start": "119119",
    "end": "124719"
  },
  {
    "text": "that goes inside a full human genome there was a quantum leap uh",
    "start": "124719",
    "end": "130000"
  },
  {
    "start": "127000",
    "end": "156000"
  },
  {
    "text": "probably about six years ago now which was the arrival of next generation dna sequencing technologies which allowed us",
    "start": "130000",
    "end": "135920"
  },
  {
    "text": "to sequence genomes not in decade time spans but in week a month time spans and",
    "start": "135920",
    "end": "141200"
  },
  {
    "text": "not for billions of dollars but tens of thousands and now are thousands of dollars and once that drops beneath",
    "start": "141200",
    "end": "146879"
  },
  {
    "text": "about a thousand dollars that's the point at which uh it becomes uh economical to start having genomes",
    "start": "146879",
    "end": "152480"
  },
  {
    "text": "screened as part of regular healthcare uh provision the flip side of being able to sequence",
    "start": "152480",
    "end": "158640"
  },
  {
    "start": "156000",
    "end": "184000"
  },
  {
    "text": "all that data is that you have to generate that the you actually end up generating a huge amount of data so when",
    "start": "158640",
    "end": "165599"
  },
  {
    "text": "i came to join amazon from from the sanger institute we're generating around 250 terabytes each and every week that's",
    "start": "165599",
    "end": "171840"
  },
  {
    "text": "a challenging amount of data to move around uh internally it's a very challenging amount of data to to operate",
    "start": "171840",
    "end": "177200"
  },
  {
    "text": "with it's very challenging amount of data to process and so i'm probably familiar with some of the very large data challenges that some of our",
    "start": "177200",
    "end": "183120"
  },
  {
    "text": "customers are facing but that's not the biggest problem of data it's not the biggest problem with data sets the size of the original data",
    "start": "183120",
    "end": "189680"
  },
  {
    "start": "184000",
    "end": "248000"
  },
  {
    "text": "set isn't the biggest problem the lots of data isn't really the the core of the problem the problem is that",
    "start": "189680",
    "end": "195519"
  },
  {
    "text": "there's a multiplication effect when you start working with data sets of of of any size basically and particularly when",
    "start": "195519",
    "end": "201440"
  },
  {
    "text": "you start integrating data sets across multiple uh across multiple locations and multiple uh use cases and that's you",
    "start": "201440",
    "end": "208000"
  },
  {
    "text": "end up with lots of data that has lots of uses data which is useful will end up having lots of uses and things that have",
    "start": "208000",
    "end": "213840"
  },
  {
    "text": "a lot of uses will end up having a lot of users and if you have a lot of users then you're going to end up having to",
    "start": "213840",
    "end": "219040"
  },
  {
    "text": "process and access that data from lots of locations and these end up being forced multipliers",
    "start": "219040",
    "end": "224400"
  },
  {
    "text": "in the uh complexity of managing and handling the data that you're working with",
    "start": "224400",
    "end": "230000"
  },
  {
    "text": "the ultimate force multiplier of course is cost you want to be able to do that for a smaller price as possible so all",
    "start": "230000",
    "end": "235760"
  },
  {
    "text": "of these are forced multipliers in terms of the complexity of managing data the complexity of storing data and",
    "start": "235760",
    "end": "241280"
  },
  {
    "text": "particularly the complexity of making data available to people that might want to take advantage of it",
    "start": "241280",
    "end": "246640"
  },
  {
    "text": "so the complexity is significant so one of the data sets that we house in",
    "start": "246640",
    "end": "253040"
  },
  {
    "start": "248000",
    "end": "292000"
  },
  {
    "text": "addition to the common crawl which we'll hear about in a minute on the amazon public data sets program is the thousand",
    "start": "253040",
    "end": "258239"
  },
  {
    "text": "genome data this is a very large data set it's the world's largest collection of human variation it's 200 terabytes in",
    "start": "258239",
    "end": "265919"
  },
  {
    "text": "size and managing the complexity of the 200 terabytes even if you're a",
    "start": "265919",
    "end": "272479"
  },
  {
    "text": "significant pi in a large university is going to be very very challenging it's going to be very complex you have to be",
    "start": "272479",
    "end": "277600"
  },
  {
    "text": "able to ask for the storage that you need to be able to store those 200 terabytes you have to be able to ask then for the compute that you're going",
    "start": "277600",
    "end": "283600"
  },
  {
    "text": "to need on premise to be able to access that data and work with it in a way which allows you to try and derive some",
    "start": "283600",
    "end": "289440"
  },
  {
    "text": "value from it so the complexity is what kills you and what we've seen from customers large and small is that the",
    "start": "289440",
    "end": "295759"
  },
  {
    "start": "292000",
    "end": "319000"
  },
  {
    "text": "cloud and aws whether it's a public data sets program or privately house data is the house the",
    "start": "295759",
    "end": "301759"
  },
  {
    "text": "cloud is becoming the canonical source of the data way back when with the original human genome we were able to",
    "start": "301759",
    "end": "307199"
  },
  {
    "text": "put those three gigabytes on an mp3 drive and just ship them around the place in a jiffy bag",
    "start": "307199",
    "end": "313120"
  },
  {
    "text": "it's uh it's high latency but it's got good bandwidth and we still do that today to",
    "start": "313120",
    "end": "318160"
  },
  {
    "text": "some degree here at amazon but what we've seen is that you you could at that point at the gigabyte level you can",
    "start": "318160",
    "end": "323759"
  },
  {
    "text": "start moving your storage to where your computer is even in a large supercomputing facility you can take",
    "start": "323759",
    "end": "328880"
  },
  {
    "text": "your data and load it onto all the uh individual nodes on your cluster and then you can start processing and singing against it when you're dealing",
    "start": "328880",
    "end": "334880"
  },
  {
    "text": "with 100 terabyte 200 terabyte data sets and larger petabytes we have customers at petabyte scale when you start working",
    "start": "334880",
    "end": "341039"
  },
  {
    "text": "at that solar level the benefit of moving the storage to the compute is completely removed and so",
    "start": "341039",
    "end": "347520"
  },
  {
    "text": "what we found is that customers are creating canonical sources of their data set in s3 on the web on",
    "start": "347520",
    "end": "353440"
  },
  {
    "text": "ebs and then bringing the compute alongside it and this is really what started us thinking that we might um",
    "start": "353440",
    "end": "359840"
  },
  {
    "text": "want to provide some of these common data sets that we're seeing a lot of customers going to the uh going to the effort of uploading for their own uh for",
    "start": "359840",
    "end": "366720"
  },
  {
    "text": "their own uses and to make available to other people and that's what basically led us to uh to create the public data",
    "start": "366720",
    "end": "371919"
  },
  {
    "text": "sets program and make that data available as a canonical source in as many ways possible and with the thousand",
    "start": "371919",
    "end": "378160"
  },
  {
    "text": "genome data set we're actually hooked into the nih production pipeline so once a week that data will be uploaded and",
    "start": "378160",
    "end": "384639"
  },
  {
    "text": "updated onto s3 in exactly the same way as it's pushed out to all the other sources so what you end up is the with the uh",
    "start": "384639",
    "end": "391600"
  },
  {
    "start": "389000",
    "end": "409000"
  },
  {
    "text": "opportunity of taking advantage of utility infrastructure so you to make available the data that",
    "start": "391600",
    "end": "397919"
  },
  {
    "text": "you're working with by having a canonical source that you can attach up the compute to you can basically make not only the",
    "start": "397919",
    "end": "404080"
  },
  {
    "text": "data available but you can make the computation available to anybody that has an aws account",
    "start": "404080",
    "end": "409199"
  },
  {
    "start": "409000",
    "end": "444000"
  },
  {
    "text": "so this fosters a remarkable amount of of collaboration and we've seen this with open data we've also seen this with",
    "start": "409199",
    "end": "415280"
  },
  {
    "text": "uh with with closed internal data sets again using the genomic space as an example the people that make the",
    "start": "415280",
    "end": "421680"
  },
  {
    "text": "sequences now stream the data from those sequences directly up to s3 and then they have a",
    "start": "421680",
    "end": "427039"
  },
  {
    "text": "data space effectively of tools around that data which partners and other people can provide to the data and to",
    "start": "427039",
    "end": "433360"
  },
  {
    "text": "their customers so you get the you get the idea that you can foster a remarkable amount of collaboration as a remarkable",
    "start": "433360",
    "end": "439280"
  },
  {
    "text": "opportunity for tools developers to add value to the data sets that are already up there",
    "start": "439280",
    "end": "444960"
  },
  {
    "start": "444000",
    "end": "483000"
  },
  {
    "text": "it's also critical for reproducibility so in scientific research the concept of",
    "start": "444960",
    "end": "450720"
  },
  {
    "text": "reproducibility is really at the core of what we're trying to do the goal of writing a paper and getting it",
    "start": "450720",
    "end": "456960"
  },
  {
    "text": "published is so that you can well today it's so you can get more funding but the original goal is that you can pull it",
    "start": "456960",
    "end": "463199"
  },
  {
    "text": "down and reproduce what somebody else has done so you don't have to go to the effort of creating that information yourself and you can build on top of it",
    "start": "463199",
    "end": "469599"
  },
  {
    "text": "going forwards we've lost a lot of that with traditional on-premise infrastructure as scientific research has been uh becoming",
    "start": "469599",
    "end": "477280"
  },
  {
    "text": "more and more computationally demanding we've lost a lot of that opportunity for reproducibility",
    "start": "477280",
    "end": "483440"
  },
  {
    "start": "483000",
    "end": "502000"
  },
  {
    "text": "governed by the fact that the data sets are getting larger the complexity of the processing pipelines is increasing all",
    "start": "483440",
    "end": "488639"
  },
  {
    "text": "the time and these multiplier effects means that it's very very difficult to be able to resolve all the dependencies",
    "start": "488639",
    "end": "494000"
  },
  {
    "text": "and build out exactly the same environment that your collaborators may be built even down the road or that have",
    "start": "494000",
    "end": "500240"
  },
  {
    "text": "been provided in a scientific paper if you start providing data in a canonical source up in the cloud and as",
    "start": "500240",
    "end": "506240"
  },
  {
    "text": "i say if it's open we'll host it for you if you can provide that that's a very good starting point that's a good",
    "start": "506240",
    "end": "511840"
  },
  {
    "text": "crystallization point for future research if you then start adding out the code and the pipeline that works",
    "start": "511840",
    "end": "517680"
  },
  {
    "text": "with that data now you've got a reproducible environment because we have a programmable infrastructure so you can take your cloud formation template you",
    "start": "517680",
    "end": "524000"
  },
  {
    "text": "can take your provisioning scripts place it all in the version control and give that to your collaborators now they're",
    "start": "524000",
    "end": "529200"
  },
  {
    "text": "not working with trying to resolve the dependencies and compile the binaries and figure out which flags are used to get the results that you need they're",
    "start": "529200",
    "end": "535519"
  },
  {
    "text": "working with the exact environment that you are working with so reproducibility is dramatically enhanced and what i hope",
    "start": "535519",
    "end": "542480"
  },
  {
    "text": "to see is that this is going to be significant in accelerating the rate of scientific research that we're seeing",
    "start": "542480",
    "end": "548560"
  },
  {
    "start": "548000",
    "end": "579000"
  },
  {
    "text": "it also benefits reuse so reproducibility is one thing but the sort of corollary to that is that you",
    "start": "548560",
    "end": "554640"
  },
  {
    "text": "have a reusable environment that the tools that you're building if they are data intensive or data driven can be",
    "start": "554640",
    "end": "560240"
  },
  {
    "text": "much more easily reused when you're built on a utility environment and to be able to remix the components",
    "start": "560240",
    "end": "566160"
  },
  {
    "text": "of those tools either remix the data or remix the code for processing the data which brings me on to the opportunity of",
    "start": "566160",
    "end": "571920"
  },
  {
    "text": "open data and the opportunity of taking data and making it available to other people so they can reproduce reuse and remix",
    "start": "571920",
    "end": "579920"
  },
  {
    "start": "579000",
    "end": "615000"
  },
  {
    "text": "so if you're interested in uh in in contributing to this i would love to talk to you we have some fantastic data",
    "start": "579920",
    "end": "586240"
  },
  {
    "text": "sets up here on aws.amazon.com datasets we have we have the common crawl we have the",
    "start": "586240",
    "end": "592240"
  },
  {
    "text": "thousand genome data set we have a the million song data set which is a collection of million uh million",
    "start": "592240",
    "end": "597839"
  },
  {
    "text": "different songs and artists and song metadata we have the whole of the ensemble data set we have triplet stores",
    "start": "597839",
    "end": "603680"
  },
  {
    "text": "and everything else that you can possibly imagine so if you're interested in working with open data this is a great resource to get started uh if",
    "start": "603680",
    "end": "610240"
  },
  {
    "text": "you're interested in and you have data as a data producer then please get in touch i'm matthew amazon.com and with",
    "start": "610240",
    "end": "616240"
  },
  {
    "start": "615000",
    "end": "829000"
  },
  {
    "text": "that i would like to welcome up lisa green who's going to talk a little bit about the common core lisa thank you",
    "start": "616240",
    "end": "623680"
  },
  {
    "text": "my name is lisa and i'm the director of the common craw foundation common crawl builds and maintains an",
    "start": "624720",
    "end": "631839"
  },
  {
    "text": "open repository of web crawl data so common like the commons no intellectual property restrictions and crawl web",
    "start": "631839",
    "end": "638399"
  },
  {
    "text": "crawler i love my job i'm really passionate about the work i do and everybody on the team is",
    "start": "638399",
    "end": "645360"
  },
  {
    "text": "and that comes from two beliefs one that the web is the greatest data set of all time",
    "start": "645360",
    "end": "650720"
  },
  {
    "text": "i mean it's huge first of all and second of all it touches on every aspect of human society",
    "start": "650720",
    "end": "656560"
  },
  {
    "text": "health science business family so we think that the web is the greatest data set of all time and the second",
    "start": "656560",
    "end": "663519"
  },
  {
    "text": "belief that makes me so passionate about my work is that everyone should have access to this data",
    "start": "663519",
    "end": "669839"
  },
  {
    "text": "it's not fair that the only people who have access to it are employees of a few large search engines right",
    "start": "669839",
    "end": "676000"
  },
  {
    "text": "so we collect this data and we store it on s3 so that everyone can access it and",
    "start": "676000",
    "end": "681600"
  },
  {
    "text": "compute against it and that's why amazon is such a crucial",
    "start": "681600",
    "end": "686880"
  },
  {
    "text": "part of our fulfilling our mission we store our data on s3 and the public data sets that matt was talking about",
    "start": "686880",
    "end": "693200"
  },
  {
    "text": "but it's not enough to just have access if you have access but you can't run a job against it it might as well be in a",
    "start": "693200",
    "end": "699519"
  },
  {
    "text": "silo so having the ability to use ec2 tools",
    "start": "699519",
    "end": "704560"
  },
  {
    "text": "to run jobs against this data allows us to really fulfill the mission of letting everyone utilize this tremendous",
    "start": "704560",
    "end": "710800"
  },
  {
    "text": "resource web data um",
    "start": "710800",
    "end": "716480"
  },
  {
    "text": "matt can you click oh stinks so here are just uh",
    "start": "716480",
    "end": "724000"
  },
  {
    "text": "nope there we go here's a few facts about it it's about 8 billion web pages",
    "start": "724399",
    "end": "730560"
  },
  {
    "text": "total is about 120 terabytes and we've been doing this since 2008",
    "start": "730560",
    "end": "736000"
  },
  {
    "text": "and the formats that we have include arc files json metadata files and plain text",
    "start": "736000",
    "end": "741279"
  },
  {
    "text": "files and like i said it's available to anyone on amazon's public data sets if you want to know more about the",
    "start": "741279",
    "end": "747040"
  },
  {
    "text": "formats go to our website commoncrawl.org go to our public data set page on the url that matt showed",
    "start": "747040",
    "end": "754240"
  },
  {
    "text": "you'll be able to search through the public data sets and you can find common crawl and from there you can get to our wiki",
    "start": "754240",
    "end": "760240"
  },
  {
    "text": "it has more details about the file formats example code advice about how to use it some things that other people",
    "start": "760240",
    "end": "766720"
  },
  {
    "text": "have done so when i first met first gave me the opportunity to come here and talk to",
    "start": "766720",
    "end": "772720"
  },
  {
    "text": "everyone i was really excited and i had planned on standing up here and telling you about other people's projects",
    "start": "772720",
    "end": "778880"
  },
  {
    "text": "telling you some of the things that other people have done with the common crawl data and talking about other people's code",
    "start": "778880",
    "end": "784720"
  },
  {
    "text": "but then one day i was talking to matthew from lucky oyster and",
    "start": "784720",
    "end": "790639"
  },
  {
    "text": "he is so excited about common crawl use and he is such the use case that we're trying to enable",
    "start": "790639",
    "end": "796399"
  },
  {
    "text": "i said before that we don't think it's fair that people in large search com engine companies",
    "start": "796399",
    "end": "802480"
  },
  {
    "text": "have access to this type of data but your everyday developer doesn't matthew is a computer scientist that",
    "start": "802480",
    "end": "807600"
  },
  {
    "text": "started playing with common crawl data out of personal curiosity but then actually wove his findings into",
    "start": "807600",
    "end": "813519"
  },
  {
    "text": "his new startup and that's exactly what we're hoping to enable so i'm going to let you hear straight from the horse's",
    "start": "813519",
    "end": "818639"
  },
  {
    "text": "mouth and matthew's going to talk about the code and the work that he's done with the common crawl data matthew",
    "start": "818639",
    "end": "825880"
  },
  {
    "start": "829000",
    "end": "870000"
  },
  {
    "text": "hi i'm matthew burke founder ceo cto janitor",
    "start": "830560",
    "end": "836560"
  },
  {
    "text": "accounts payable accounts receivable and so on for lucky oyster as lisa said",
    "start": "836560",
    "end": "842079"
  },
  {
    "text": "i'm super enthusiastic about anyone having access to the web",
    "start": "842079",
    "end": "847600"
  },
  {
    "text": "and that as she mentioned has effectively turned into a new business for me so we're funded we've hired",
    "start": "847600",
    "end": "853600"
  },
  {
    "text": "employee number one and we were able using the data to formulate not just a hypothesis but to test that and to roll",
    "start": "853600",
    "end": "860079"
  },
  {
    "text": "it into a whole bunch of product ideas that we think have some muscle and so that's kind of what we're working on",
    "start": "860079",
    "end": "866720"
  },
  {
    "text": "so i'm going to take you through a bit of that anyone here ever try and crawl the web",
    "start": "866720",
    "end": "872959"
  },
  {
    "start": "870000",
    "end": "941000"
  },
  {
    "text": "anyone all right so the web is the greatest data set in the",
    "start": "872959",
    "end": "878000"
  },
  {
    "text": "world the problem is that you can't iterate over it if you could iterate over it we wouldn't really have a problem you can iterate over small",
    "start": "878000",
    "end": "884079"
  },
  {
    "text": "portions of it using things like site maps or traversing links but in bulk you simply cannot do that so",
    "start": "884079",
    "end": "890880"
  },
  {
    "text": "it's kind of an irony that the greatest data set in the world is completely inaccessible to lisa's point if you're",
    "start": "890880",
    "end": "896000"
  },
  {
    "text": "sitting at yahoo or google or a large university you might be able to have access to part of that but it's super",
    "start": "896000",
    "end": "902720"
  },
  {
    "text": "cost intensive and resource intensive to iterate over the web and effectively the common crawl foundation does that for",
    "start": "902720",
    "end": "909600"
  },
  {
    "text": "you they provide it through s3 you pull the arc files from s3 and you can uh",
    "start": "909600",
    "end": "915199"
  },
  {
    "text": "compute on it from there but we did an experiment we actually did two versions of the experiment in the second",
    "start": "915199",
    "end": "921519"
  },
  {
    "text": "one i'm going to describe basically what we got for 100 bucks so it's not just that the data is available but the tools",
    "start": "921519",
    "end": "927839"
  },
  {
    "text": "are now available for anybody even a lone guy with a wacky idea or two to get",
    "start": "927839",
    "end": "933519"
  },
  {
    "text": "their hands on the data and to effectively apply compute resource to it to validate a hypothesis or formulate a",
    "start": "933519",
    "end": "939920"
  },
  {
    "text": "new product i think the other thing about crawling the web that's sort of",
    "start": "939920",
    "end": "945360"
  },
  {
    "start": "941000",
    "end": "1085000"
  },
  {
    "text": "interesting is a lot of it is highly structured and so decomposing the web",
    "start": "945360",
    "end": "950880"
  },
  {
    "text": "also kind of deconstructing it requires a whole bunch of resource that i think about 10 years ago i started fantasizing",
    "start": "950880",
    "end": "957360"
  },
  {
    "text": "about what it would mean to have a collection of a billion web pages so to do the crawl to have the collection to",
    "start": "957360",
    "end": "963360"
  },
  {
    "text": "store and persist the collection and then to iterate over it and i never got beyond thinking about how to store it",
    "start": "963360",
    "end": "970480"
  },
  {
    "text": "because the cost of storage were so high so for those who have actually tried to crawl sections of the web or large",
    "start": "970480",
    "end": "977199"
  },
  {
    "text": "portions of it the other thing that you'll know is that while web search technology has come",
    "start": "977199",
    "end": "983120"
  },
  {
    "text": "very very far what hasn't come very far is how to actually work with the data so the spec",
    "start": "983120",
    "end": "988320"
  },
  {
    "text": "the arc file spec it's still available in this sort of antiquated file format with headers and sections and it",
    "start": "988320",
    "end": "995360"
  },
  {
    "text": "streamed and compressed the spec for that was written correct me if i'm wrong in 1994. and the bulk of research around",
    "start": "995360",
    "end": "1002000"
  },
  {
    "text": "traversing the web and making it uh iterable was really done in the late 90s and there hasn't been a lot done since",
    "start": "1002000",
    "end": "1008000"
  },
  {
    "text": "so with a little bit of horsepower and using aws spot spot instances in particular",
    "start": "1008000",
    "end": "1014000"
  },
  {
    "text": "you can actually go through it so we start out with a pretty simple experiment my hypothesis was that the",
    "start": "1014000",
    "end": "1020160"
  },
  {
    "text": "web was not the best and ultimate and future repository",
    "start": "1020160",
    "end": "1025438"
  },
  {
    "text": "of human activity as we once thought it would be and that social would be that repository",
    "start": "1025439",
    "end": "1031120"
  },
  {
    "text": "and so i thought about two things number one is that the locus of that data is changing it's shifting from the open web",
    "start": "1031120",
    "end": "1037839"
  },
  {
    "text": "which we barely have access to but through efforts like this we can to the sort of social graph which we cannot",
    "start": "1037839",
    "end": "1043918"
  },
  {
    "text": "read today so there are no efforts to give access access to that you can iterate over very very tiny portions of",
    "start": "1043919",
    "end": "1050640"
  },
  {
    "text": "it so the locus of activity is changing but also the nature of activity is changing as well because of how we",
    "start": "1050640",
    "end": "1057039"
  },
  {
    "text": "interact socially what we find on the web today is not only references into the social graph",
    "start": "1057039",
    "end": "1063679"
  },
  {
    "text": "but it's highly structured and so what you get today is highly structured data on web pages that you never really had",
    "start": "1063679",
    "end": "1069840"
  },
  {
    "text": "before representations of things on pages you never had before like hikes",
    "start": "1069840",
    "end": "1075120"
  },
  {
    "text": "and runs and recipes and what songs we're listening to and that's available on the open web as sort of an artifact",
    "start": "1075120",
    "end": "1081520"
  },
  {
    "text": "of all the social work we do through other networks so to do this we really use the",
    "start": "1081520",
    "end": "1087760"
  },
  {
    "text": "horsepower of aws in the very first experiment we operated on about 1.2",
    "start": "1087760",
    "end": "1093840"
  },
  {
    "text": "billion pages worth of data we used the on-demand instances more or less the",
    "start": "1093840",
    "end": "1098960"
  },
  {
    "text": "same configuration as you'll see in a second and for about 500 we processed that 1.2",
    "start": "1098960",
    "end": "1106000"
  },
  {
    "text": "or 1.3 billion pages and i thought wow that's really great that's utility computing and it makes it affordable a",
    "start": "1106000",
    "end": "1113360"
  },
  {
    "text": "guy can write a check or use his credit card and can actually get some findings out of that in the second version we",
    "start": "1113360",
    "end": "1119200"
  },
  {
    "text": "went through his three plus billion pages and the cost actually went down so",
    "start": "1119200",
    "end": "1124400"
  },
  {
    "text": "a couple of code tweaks uh the pages went up three-fold the cost went down",
    "start": "1124400",
    "end": "1129520"
  },
  {
    "text": "five-fold to a hundred bucks and in order to do that we leveraged spot instances so spot instances for those",
    "start": "1129520",
    "end": "1135600"
  },
  {
    "text": "who don't really know it you basically bid on unused capacity so",
    "start": "1135600",
    "end": "1141760"
  },
  {
    "text": "when i think about the cost of computing resources or material in a previous job",
    "start": "1141760",
    "end": "1147440"
  },
  {
    "text": "where i worked for a public company we had to operate at a very low ratio of sort of resource",
    "start": "1147440",
    "end": "1154240"
  },
  {
    "text": "utilization and so what that meant is we had thousands and thousands of servers but generally we kept capacity across",
    "start": "1154240",
    "end": "1161280"
  },
  {
    "text": "all types of resource at about 40 percent and we would have spikes that would take us up to like 50 60 70",
    "start": "1161280",
    "end": "1167039"
  },
  {
    "text": "percent but generally when i thought about computing cost bless you what i actually thought about was the unused",
    "start": "1167039",
    "end": "1174720"
  },
  {
    "text": "cost of all of that iron sitting in our data centers the power it was the cooling it was the real estate it was",
    "start": "1174720",
    "end": "1180480"
  },
  {
    "text": "the servers that weren't being used when you bid for unused capacity effectively not just",
    "start": "1180480",
    "end": "1186080"
  },
  {
    "text": "your costs go down but you're sort of acting in a more green i believe responsible",
    "start": "1186080",
    "end": "1191919"
  },
  {
    "text": "way and so we moved to spot instances and we had a very simple architecture so",
    "start": "1191919",
    "end": "1196960"
  },
  {
    "text": "a lot of people when they look at large data sets they like using the mapreduce model there's elastic mapreduce and what",
    "start": "1196960",
    "end": "1203360"
  },
  {
    "text": "we wanted to do was we wanted to reduce the exercise to its simplest possible",
    "start": "1203360",
    "end": "1208559"
  },
  {
    "text": "component so it's one operation that operation is an extract that data gets moved on pipeline fashion and then",
    "start": "1208559",
    "end": "1215679"
  },
  {
    "text": "we do an indexing so we have a master and the master basically coordinates what data needs to be extracted so what",
    "start": "1215679",
    "end": "1223120"
  },
  {
    "text": "s3 paths actually get routed to the worker nodes and then the master also collects data as the worker nodes do",
    "start": "1223120",
    "end": "1229919"
  },
  {
    "text": "their work and do their extraction the worker nodes wake up and in order to use spot instances you have to have to have",
    "start": "1229919",
    "end": "1235919"
  },
  {
    "text": "nodes that are resilient to interruption what that means effectively is creating an ami where when the little worker",
    "start": "1235919",
    "end": "1241919"
  },
  {
    "text": "wakes up it says i know where the queue is let me pull work from the queue let me do my",
    "start": "1241919",
    "end": "1246960"
  },
  {
    "text": "extraction and let me forward the extracted data over to the master master then receives it stores it persists it",
    "start": "1246960",
    "end": "1253840"
  },
  {
    "text": "and then does a whole bunch of indexing and the output",
    "start": "1253840",
    "end": "1259200"
  },
  {
    "start": "1257000",
    "end": "1459000"
  },
  {
    "text": "is for us a whole bunch of things so at the end i'll pop up a slide some of the original findings but we've gotten a lot",
    "start": "1259200",
    "end": "1265280"
  },
  {
    "text": "deeper since then but the output for us is a couple of other things number one it's a super cost effective way for us",
    "start": "1265280",
    "end": "1271600"
  },
  {
    "text": "to as i said iterate through the web without being at a large institution and this is some of the advantage that's",
    "start": "1271600",
    "end": "1277840"
  },
  {
    "text": "underwritten i think if amazon had their way we might be spending uh not a hundred maybe a thousand maybe ten",
    "start": "1277840",
    "end": "1284720"
  },
  {
    "text": "thousand maybe a hundred thousand dollars and a couple of years ago it would have cost me hundreds of thousands of dollars to",
    "start": "1284720",
    "end": "1291200"
  },
  {
    "text": "do what i'm doing today for very very little the other artifact of what we what we've",
    "start": "1291200",
    "end": "1296640"
  },
  {
    "text": "done here is sort of a reusable framework so we can modify the extraction we can modify the post",
    "start": "1296640",
    "end": "1302159"
  },
  {
    "text": "processing we can modify the indexing and we can simply change the worker nodes repopulate the queue on the master",
    "start": "1302159",
    "end": "1309520"
  },
  {
    "text": "and then fire up the worker nodes we fire them up they read through when the queue is empty we're done and we have",
    "start": "1309520",
    "end": "1315200"
  },
  {
    "text": "our output so the second artifact is that we have a reusable framework we simply tweak the code and we can go",
    "start": "1315200",
    "end": "1321679"
  },
  {
    "text": "again at any time and the third bit when i do data mining i typically do it through indexes and basically a reuse of",
    "start": "1321679",
    "end": "1328559"
  },
  {
    "text": "search technology upside down and so we've built these indexes of the extracted metadata this is the entity",
    "start": "1328559",
    "end": "1335120"
  },
  {
    "text": "metadata we've found from across the web it's on the order of about 400 million entities and so we're able to slice and",
    "start": "1335120",
    "end": "1342320"
  },
  {
    "text": "dice that and search through it and look at the distribution of tags and facets and attributes and that's a huge asset",
    "start": "1342320",
    "end": "1349200"
  },
  {
    "text": "for us to play with while we went ahead very far",
    "start": "1349200",
    "end": "1355440"
  },
  {
    "text": "we're going to show you one of the outputs of the study so that was the original one",
    "start": "1355440",
    "end": "1361919"
  },
  {
    "text": "and if you look at the lucky oyster blog it'll point you to our write-up of the first study and the second study we have",
    "start": "1361919",
    "end": "1367840"
  },
  {
    "text": "a third one underway and we want to take the code that we've used for this very simple framework and promote it up to",
    "start": "1367840",
    "end": "1373679"
  },
  {
    "text": "github so other people can use it as well the other thing that's kind of neat about",
    "start": "1373679",
    "end": "1379120"
  },
  {
    "text": "what we did in the beginning is that i time boxed it and so i started using hadoop and i really gave myself a couple",
    "start": "1379120",
    "end": "1386080"
  },
  {
    "text": "of days and taking the emr approach would have taken a much longer investment of time and again i wanted to",
    "start": "1386080",
    "end": "1392720"
  },
  {
    "text": "keep things simple simple architecture reusable reproducible not get lost in",
    "start": "1392720",
    "end": "1398000"
  },
  {
    "text": "configuration and effectively i wanted from scratch now most of the time that's not a great way to do this but for our",
    "start": "1398000",
    "end": "1404720"
  },
  {
    "text": "approach given two days writing code from scratch with a very simple queue and worker nodes was the best way to do",
    "start": "1404720",
    "end": "1411039"
  },
  {
    "text": "it and that was kind of the approach that we took most people won't take that but for us if it's reusable it's uh",
    "start": "1411039",
    "end": "1417840"
  },
  {
    "text": "we'll be very very happy and this these are some of the findings again the other key output for us is a set of indexes",
    "start": "1417840",
    "end": "1424480"
  },
  {
    "text": "that we can use to look at the extracted data and that's hugely valuable",
    "start": "1424480",
    "end": "1430480"
  },
  {
    "text": "go to blog.luckyoyster.com you can see the write-ups and if we have time for questions",
    "start": "1430480",
    "end": "1436559"
  },
  {
    "text": "if anyone has questions",
    "start": "1436559",
    "end": "1439600"
  },
  {
    "start": "1459000",
    "end": "1541000"
  },
  {
    "text": "yeah so the question was the sort of veracity of data that you export through a data provider and uh matt was talking",
    "start": "1459600",
    "end": "1466320"
  },
  {
    "text": "about this before s3 is effectively becoming a canonical locus for this data",
    "start": "1466320",
    "end": "1472400"
  },
  {
    "text": "and so when it comes to the web really in terms of its veracity or it's for me it's really the utility is it",
    "start": "1472400",
    "end": "1478880"
  },
  {
    "text": "actually coming from the web and that's pretty simple i have two options i can either go with an open data set which is",
    "start": "1478880",
    "end": "1485279"
  },
  {
    "text": "what i've done with common crawl on the foundation or i can do it myself and so if i do it myself i may",
    "start": "1485279",
    "end": "1491760"
  },
  {
    "text": "i may be able to control how deep i go or what links i follow or don't follow the problem is that it's so even today",
    "start": "1491760",
    "end": "1498880"
  },
  {
    "text": "with spot instances in utility computing it's so expensive to traverse the web to",
    "start": "1498880",
    "end": "1504159"
  },
  {
    "text": "make it iteratable and that is kind of prohibitive in terms of other data sets what i'd like to see",
    "start": "1504159",
    "end": "1510559"
  },
  {
    "text": "so there are some others that are out there like freebase from metaweb that's out there and available the uh",
    "start": "1510559",
    "end": "1517919"
  },
  {
    "text": "and they're a ton if you go and you look at the open data sets they're a lot and as i said making making s3 or those data",
    "start": "1517919",
    "end": "1524320"
  },
  {
    "text": "sets sort of the output of your pipeline when you're pulling the data makes it effectively canonical and i think that's",
    "start": "1524320",
    "end": "1530559"
  },
  {
    "text": "where you sort of build up the trust",
    "start": "1530559",
    "end": "1533840"
  },
  {
    "text": "yeah it it does lisa",
    "start": "1540840",
    "end": "1545440"
  },
  {
    "start": "1541000",
    "end": "1602000"
  },
  {
    "text": "so the question was how current is the crawl data uh we crawl about once a year right now we're hoping to do six crawls",
    "start": "1550480",
    "end": "1556640"
  },
  {
    "text": "in 2013. this year we should have two done in 2012.",
    "start": "1556640",
    "end": "1562640"
  },
  {
    "text": "we're not as frequent as google or bing or anything like that but we're a lot more frequent than say clue web for",
    "start": "1562640",
    "end": "1568480"
  },
  {
    "text": "those of you from the information retrieval community and we're hoping to increase the frequency we're also",
    "start": "1568480",
    "end": "1574480"
  },
  {
    "text": "in 2013 planning on adding targeted subset crawls that would be happening very frequently on the order of once a",
    "start": "1574480",
    "end": "1581520"
  },
  {
    "text": "week or maybe once a month something a subset of very high interest it's much smaller and can be accomplished faster",
    "start": "1581520",
    "end": "1589360"
  },
  {
    "text": "okay so i think we have um i really want to get to ravi so we'll maybe have other questions in thanks",
    "start": "1590799",
    "end": "1598559"
  },
  {
    "text": "thanks man this data um i was playing with it the",
    "start": "1598559",
    "end": "1605120"
  },
  {
    "start": "1602000",
    "end": "1658000"
  },
  {
    "text": "other day i pulled down the million song data set uh i parsed it with just a simple cue-based um approach using some",
    "start": "1605120",
    "end": "1612640"
  },
  {
    "text": "ruby passed out all the artist names and then i queried the entire of the web to see",
    "start": "1612640",
    "end": "1617919"
  },
  {
    "text": "where those artist names co-occurred on web pages then i built up a ginormous graph of how all these artists related",
    "start": "1617919",
    "end": "1623679"
  },
  {
    "text": "to each other and built like a big family tree uh just for fun but it did show me that there is a sort of musical",
    "start": "1623679",
    "end": "1628880"
  },
  {
    "text": "uh royalty at the top to which almost everybody is compared to elvis and madonna so there you go um so the the",
    "start": "1628880",
    "end": "1635919"
  },
  {
    "text": "point i'm trying to make is that all of that was done for i think there's less than 200 lines of code in all of that",
    "start": "1635919",
    "end": "1641440"
  },
  {
    "text": "and i was able to run it uh more or less in about four hours i think uh so it was a",
    "start": "1641440",
    "end": "1646559"
  },
  {
    "text": "very interesting way to navigate a couple of different data sets so on that point i want to introduce ravi maduri",
    "start": "1646559",
    "end": "1653120"
  },
  {
    "text": "who's going to talk a little bit about how you can orchestrate and move your data sets around review thanks hey thanks uh can you guys hear me okay all",
    "start": "1653120",
    "end": "1660080"
  },
  {
    "start": "1658000",
    "end": "1915000"
  },
  {
    "text": "right um so my name is ravi maduri thanks thanks matt for for for this opportunity",
    "start": "1660080",
    "end": "1666720"
  },
  {
    "text": "so i'm a i work at the university of chicago arga national laboratory and and various other institutions",
    "start": "1666720",
    "end": "1672640"
  },
  {
    "text": "um uh i come from land of big iron uh so i'm i work at an eoe lab so so these are",
    "start": "1672640",
    "end": "1680159"
  },
  {
    "text": "the kind of machines that that we have at our disposal we have a big blue jean",
    "start": "1680159",
    "end": "1685679"
  },
  {
    "text": "which is one of the top 10 uh super fast computers in the world right now uh it's",
    "start": "1685679",
    "end": "1690720"
  },
  {
    "text": "10 petaflops so we have i have accounts on all of these machines so we have two cray two crates that i have icons on one at",
    "start": "1690720",
    "end": "1697279"
  },
  {
    "text": "lawrence berkeley labs one at an argonne one at um one ibm dataplex again at berkeley and",
    "start": "1697279",
    "end": "1703919"
  },
  {
    "text": "one petascale active data storage system so we do have a lot of compute and a lot of storage as you can see so why i'm here",
    "start": "1703919",
    "end": "1711039"
  },
  {
    "text": "right so this is a cloud computing conference what am i doing here uh actually it's pretty interesting so so i",
    "start": "1711039",
    "end": "1716320"
  },
  {
    "text": "have two two interesting actually three uh three interesting projects that i'm working on that that",
    "start": "1716320",
    "end": "1721520"
  },
  {
    "text": "made me kind of look at amazon and and you know a light bulb uh went on went off and i'm i was really",
    "start": "1721520",
    "end": "1728640"
  },
  {
    "text": "happy that um that i had this opportunity to show you uh so i wanted to kind of start with uh",
    "start": "1728640",
    "end": "1734640"
  },
  {
    "text": "with this code um this is um uh i mean i don't i haven't heard about",
    "start": "1734640",
    "end": "1740799"
  },
  {
    "text": "this guy before my boss showed me the slide but one of the things that you know civilization advances um by",
    "start": "1740799",
    "end": "1746640"
  },
  {
    "text": "extending the number of operations that you can do without thinking this is a big big code and and one of the reasons why",
    "start": "1746640",
    "end": "1754320"
  },
  {
    "text": "um we people we do a lot of things uh today uh we don't actually have to think",
    "start": "1754320",
    "end": "1759440"
  },
  {
    "text": "about them and uh what we do at the university of chicago and computation institute is that we're trying to apply",
    "start": "1759440",
    "end": "1765679"
  },
  {
    "text": "um the the the essence of this code uh to scientific data management right so",
    "start": "1765679",
    "end": "1772240"
  },
  {
    "text": "uh so you'll see a lot of things that matt talked about uh kind of reflecting some of my slides uh",
    "start": "1772240",
    "end": "1778559"
  },
  {
    "text": "both in terms of reproducibility of research and and uh how you can make",
    "start": "1778559",
    "end": "1783760"
  },
  {
    "text": "uh research data management much more easier and flexible uh at some level uh",
    "start": "1783760",
    "end": "1788799"
  },
  {
    "text": "i'm is just just like lisa you know i'm really passionate about what i'm doing right because uh i'm not really working",
    "start": "1788799",
    "end": "1795520"
  },
  {
    "text": "on um showing the right ad in the 20 microseconds you have before the user can wander off his gaze",
    "start": "1795520",
    "end": "1802399"
  },
  {
    "text": "we're actually trying to advance a civilization right we're trying to do things we're trying to we're working",
    "start": "1802399",
    "end": "1808320"
  },
  {
    "text": "with researchers trying to find the cure for cancer and other things so",
    "start": "1808320",
    "end": "1813679"
  },
  {
    "text": "so this is sort of a list of tasks that people do in scientific research today",
    "start": "1813679",
    "end": "1819840"
  },
  {
    "text": "these are the time consuming tasks when you you know in order to do scientific research you run experiments you collect",
    "start": "1819840",
    "end": "1825760"
  },
  {
    "text": "data you manage data you acquire computers you i mean anybody who's been in the scientific research enterprise",
    "start": "1825760",
    "end": "1832000"
  },
  {
    "text": "for longer know that the science science uh has become computational so if you're",
    "start": "1832000",
    "end": "1838880"
  },
  {
    "text": "take a pic of your favorite scientific discipline and see what's going on in that scientific discipline it's all",
    "start": "1838880",
    "end": "1844240"
  },
  {
    "text": "about computation so as you can see a lot of these stats are about doing data management right",
    "start": "1844240",
    "end": "1850480"
  },
  {
    "text": "and what we did what we want to do and what we're trying to do and what we are running this experiment on is to",
    "start": "1850480",
    "end": "1857679"
  },
  {
    "text": "what would happen if you outsource all the data management activities from the researchers uh the reason because your",
    "start": "1857679",
    "end": "1865679"
  },
  {
    "text": "traditional comp your traditional bioinformaticians are biologists are uh chemistry researchers they're not really",
    "start": "1865679",
    "end": "1872799"
  },
  {
    "text": "i.t people are not they're not really computer scientists so but what do they do they spend a lot of time on these",
    "start": "1872799",
    "end": "1879600"
  },
  {
    "text": "data management activities and and they spend uh correspondingly the amount of time they spend on doing actual science",
    "start": "1879600",
    "end": "1885679"
  },
  {
    "text": "goes down so what we are trying to do at the university of chicago is we're trying to outsource the data management",
    "start": "1885679",
    "end": "1891919"
  },
  {
    "text": "so how how would what would it look like if you if you provide research i.t as a service what would that mean what would",
    "start": "1891919",
    "end": "1899519"
  },
  {
    "text": "how how would that affect the researchers and how would that make them more efficient and do what they do",
    "start": "1899519",
    "end": "1904880"
  },
  {
    "text": "really good so oops this is really so one of the things that",
    "start": "1904880",
    "end": "1912159"
  },
  {
    "text": "we okay right so",
    "start": "1912159",
    "end": "1917519"
  },
  {
    "text": "so you can see that this is how we see science getting done so i kind of had",
    "start": "1917519",
    "end": "1923039"
  },
  {
    "text": "some representative science experiments there there's a big telescope that's going online uh you know in a few months",
    "start": "1923039",
    "end": "1930000"
  },
  {
    "text": "and there's there's genome sequencing as you can as you probably already know the amount of",
    "start": "1930000",
    "end": "1936159"
  },
  {
    "text": "data that's generated by the sequencing missions is growing exponentially and there are there are a lot of super",
    "start": "1936159",
    "end": "1941760"
  },
  {
    "text": "computers that are generating a lot of data and simulations so uh i'll probably talk",
    "start": "1941760",
    "end": "1946799"
  },
  {
    "text": "about one of uh i'll take one one of those use cases and talk a little bit more as you can see uh",
    "start": "1946799",
    "end": "1953760"
  },
  {
    "text": "each of these processes have uh have these multiple data management activities that go in in",
    "start": "1953760",
    "end": "1960480"
  },
  {
    "text": "that they do staging of data they do ingest they do uh analysis and and and then",
    "start": "1960480",
    "end": "1966640"
  },
  {
    "text": "finally they archive it and and for for uh for for future so the our goal is to",
    "start": "1966640",
    "end": "1972880"
  },
  {
    "text": "sort of accelerate discovery and innovation by outsourcing the mundane stuff that people that",
    "start": "1972880",
    "end": "1978720"
  },
  {
    "text": "researchers have to do in their in their daily uh in their in every day",
    "start": "1978720",
    "end": "1984320"
  },
  {
    "start": "1983000",
    "end": "2040000"
  },
  {
    "text": "so one of the things that we did initially is to pick data movement as as a as our first challenge that we want to",
    "start": "1984320",
    "end": "1991279"
  },
  {
    "text": "attack because a lot a typical scientific endure kind of becomes",
    "start": "1991279",
    "end": "1997120"
  },
  {
    "text": "moving data from where the data is available to where compute is just what matt was talking about about the",
    "start": "1997120",
    "end": "2002720"
  },
  {
    "text": "thousand genome data set um so what we did was uh we took data movement",
    "start": "2002720",
    "end": "2008320"
  },
  {
    "text": "and we created a service out of it uh called and call it globus online which is a sort of a globus online is a data",
    "start": "2008320",
    "end": "2015760"
  },
  {
    "text": "movement as a service it provides a secure automatic reliable high-speed data movement",
    "start": "2015760",
    "end": "2021760"
  },
  {
    "text": "across multiple globus online endpoints so if you are actually if you're using",
    "start": "2021760",
    "end": "2027519"
  },
  {
    "text": "amazon today to do your compute you should definitely look at globus online to move your data from from where",
    "start": "2027519",
    "end": "2033840"
  },
  {
    "text": "it is available to amazon to get uh to get analysis done um as you can see",
    "start": "2033840",
    "end": "2039760"
  },
  {
    "text": "this is uh if you go to global's online dark globusonline.org you'll see a counter",
    "start": "2039760",
    "end": "2045600"
  },
  {
    "start": "2040000",
    "end": "2218000"
  },
  {
    "text": "that's the counter that that we kind of programmed it to uh to talk about the number of uh data",
    "start": "2045600",
    "end": "2052800"
  },
  {
    "text": "number of bytes of data that has been moved so it's close to 8.5 petabytes now",
    "start": "2052800",
    "end": "2058240"
  },
  {
    "text": "the the service has launched um uh two years ago and we already got 7500 users",
    "start": "2058240",
    "end": "2064398"
  },
  {
    "text": "and and people moving data very reliably um so this is sort of uh and and one",
    "start": "2064399",
    "end": "2070320"
  },
  {
    "text": "thing the reason i kind of talked about this data service this service is entirely based on amazon web services so",
    "start": "2070320",
    "end": "2076398"
  },
  {
    "text": "we built it completely using various components of amazon aws and and we're pretty happy to report",
    "start": "2076399",
    "end": "2083919"
  },
  {
    "text": "that our site our globusonline.org is 99.9 percent available except when we when we",
    "start": "2083919",
    "end": "2090398"
  },
  {
    "text": "have things that we need to fix um so so far the service has moved five hundred and four five hundred millions of files",
    "start": "2090399",
    "end": "2097359"
  },
  {
    "text": "uh for a lot of different scientific uh scientific groups um so i have some examples um",
    "start": "2097359",
    "end": "2104000"
  },
  {
    "text": "so catherine heightman she's a collaborator of mine she moved close to 22 terabytes of data and this",
    "start": "2104000",
    "end": "2110560"
  },
  {
    "text": "is an interesting uh so what what katrina and her her team does uh is is",
    "start": "2110560",
    "end": "2116640"
  },
  {
    "text": "they're building a simulator for cosmology okay what that means is that",
    "start": "2116640",
    "end": "2122640"
  },
  {
    "text": "they take a visible universe ah actually let me take a step back they they get time from a super",
    "start": "2122640",
    "end": "2128880"
  },
  {
    "text": "supercomputer and they start with the with two billion particles and they run a simulation uh for a few days on the",
    "start": "2128880",
    "end": "2135760"
  },
  {
    "text": "supercomputer and then they create a a universe in the supercomputer and then",
    "start": "2135760",
    "end": "2141680"
  },
  {
    "text": "they map it they match it with existing universe and then they run the simulation again to make the simulator",
    "start": "2141680",
    "end": "2147920"
  },
  {
    "text": "better so at some level they're sort of creating universes in in in the super computer but what happens after they",
    "start": "2147920",
    "end": "2154480"
  },
  {
    "text": "generate the level zero data is that they want to make it available to everybody every cosmologist in the world",
    "start": "2154480",
    "end": "2161200"
  },
  {
    "text": "to do their own analysis to make the simulation better so one other thing they do they did was they used globus",
    "start": "2161200",
    "end": "2166880"
  },
  {
    "text": "online to move the data from one of the super computers to to where they can make it available for other people so",
    "start": "2166880",
    "end": "2172880"
  },
  {
    "text": "there are other examples of of these people who are moving large amounts of data using globus online",
    "start": "2172880",
    "end": "2179839"
  },
  {
    "text": "so we know we've done really good job with data movement but but we didn't want to",
    "start": "2179839",
    "end": "2184880"
  },
  {
    "text": "stop there because as i talked about before uh scientific endure scientific research requires a lot of other",
    "start": "2184880",
    "end": "2191119"
  },
  {
    "text": "components that are more than just data movement as you can see there's uh",
    "start": "2191119",
    "end": "2197519"
  },
  {
    "text": "there's in just catalog integration kind of trying to find the right data sets that you're looking for sharing",
    "start": "2197680",
    "end": "2203200"
  },
  {
    "text": "collaboration annotating data sets identity group management security these are all really important when you want",
    "start": "2203200",
    "end": "2209520"
  },
  {
    "text": "to share your data sets with other people the reason i say it is you know i have a background working with high energy",
    "start": "2209520",
    "end": "2215440"
  },
  {
    "text": "physicists who are really careful of sharing their data and you ask them why they say well there might be a nobel",
    "start": "2215440",
    "end": "2221760"
  },
  {
    "start": "2218000",
    "end": "2622000"
  },
  {
    "text": "prize in it i don't want to share it with 10 other people so it's very important to kind of have a really good",
    "start": "2221760",
    "end": "2227040"
  },
  {
    "text": "solution to do manage to manage identity and security and analysis and simulation",
    "start": "2227040",
    "end": "2232240"
  },
  {
    "text": "visualization so i'll talk a little bit about analysis uh in two use cases that i wanted to talk here so matt kind of",
    "start": "2232240",
    "end": "2240800"
  },
  {
    "text": "i'll just run this simulation through um so matt talked about genome sequencing analysis right now there are a lot of",
    "start": "2240800",
    "end": "2247760"
  },
  {
    "text": "genome sequencing centers um in the in the world and the favorite way of",
    "start": "2247760",
    "end": "2252880"
  },
  {
    "text": "transferring data is using fedex because as matt said it's high bandwidth",
    "start": "2252880",
    "end": "2258400"
  },
  {
    "text": "but very bad latency the the other problem with fedex is also that some drives can go bad during the transit and",
    "start": "2258400",
    "end": "2266640"
  },
  {
    "text": "it's it just gets into an interesting situation so what we did with our globus online solution is that",
    "start": "2266640",
    "end": "2273359"
  },
  {
    "text": "we connected all this all the broad institute and other sequence centers",
    "start": "2273359",
    "end": "2278880"
  },
  {
    "text": "as globus online endpoints and and we made it really easy for researchers who are doing",
    "start": "2278880",
    "end": "2284400"
  },
  {
    "text": "uh drug discovery and other sorts of analysis to try to move data from the",
    "start": "2284400",
    "end": "2289520"
  },
  {
    "text": "sequence centers to amazon and then we provided a managed platform on amazon",
    "start": "2289520",
    "end": "2294880"
  },
  {
    "text": "using a framework called galaxy to make it easy to run this analysis at scale on amazon so at some level",
    "start": "2294880",
    "end": "2302240"
  },
  {
    "text": "we're trying to automate all of these tasks for researchers so they don't have to do",
    "start": "2302240",
    "end": "2307839"
  },
  {
    "text": "do it themselves i was at a biology conference recently and uh one",
    "start": "2307839",
    "end": "2312960"
  },
  {
    "text": "of the pis went up and and gave a talk she said you know my postdoc keeps talking to me",
    "start": "2312960",
    "end": "2318480"
  },
  {
    "text": "about these keys you know i don't know what keys he's talking about and then she later realized that he didn't",
    "start": "2318480",
    "end": "2324240"
  },
  {
    "text": "actually mean physical keys he was actually talking about amazon keys um there's a lot of i mean i mean the",
    "start": "2324240",
    "end": "2330560"
  },
  {
    "text": "researcher is really good at what she does she doesn't need to know what amazon keys is all about so that's",
    "start": "2330560",
    "end": "2336320"
  },
  {
    "text": "where we are trying to fill the gap between you know providing a service the researcher focuses on the",
    "start": "2336320",
    "end": "2342880"
  },
  {
    "text": "science and outsources the mundane activities of of the scientific condor to to services like us",
    "start": "2342880",
    "end": "2349920"
  },
  {
    "text": "um so we we run this galaxy on on amazon and we run it at scale",
    "start": "2349920",
    "end": "2356560"
  },
  {
    "text": "one of the the other interesting thing i want to talk to you about is that i work with type 2 diabetes researchers",
    "start": "2356560",
    "end": "2362560"
  },
  {
    "text": "and they've been acquiring a lot of data sets from different families who are",
    "start": "2362560",
    "end": "2367599"
  },
  {
    "text": "affected by type 2 diabetes right one of the things uh this post doc at a lab",
    "start": "2367599",
    "end": "2372960"
  },
  {
    "text": "told me is that you know we're probably sitting on two or three nature papers nature is a big publication",
    "start": "2372960",
    "end": "2381520"
  },
  {
    "text": "venue but we don't know because we can't really analyze all this data and that's that's actually affecting all",
    "start": "2381520",
    "end": "2388320"
  },
  {
    "text": "of you here right at some level the the researchers are are not being able to do their job",
    "start": "2388320",
    "end": "2395280"
  },
  {
    "text": "because they're being stifled by uh be it the the campus computing resources are not adequate or they don't know the",
    "start": "2395280",
    "end": "2402320"
  },
  {
    "text": "know-how of to how to get this one get this analysis run at scale so that's",
    "start": "2402320",
    "end": "2407760"
  },
  {
    "text": "where we're trying to focus on making it really easy for researchers like that to do their work",
    "start": "2407760",
    "end": "2413359"
  },
  {
    "text": "this is other use case that this is other project that that we worked with amazon on",
    "start": "2413359",
    "end": "2419520"
  },
  {
    "text": "is to rebuild a proton so the proton cancer therapy is",
    "start": "2419520",
    "end": "2425680"
  },
  {
    "text": "a is getting very popular in in treating different types of cancer so one of the",
    "start": "2425680",
    "end": "2431119"
  },
  {
    "text": "challenges in the in the therapy is that the patient comes into the treatment plant and they have to wait a day before",
    "start": "2431119",
    "end": "2438079"
  },
  {
    "text": "the before his tumor can be uh can be uh create an image and reconstructed and",
    "start": "2438079",
    "end": "2444160"
  },
  {
    "text": "analyzed so what we did with that is that we took the uh",
    "start": "2444160",
    "end": "2450480"
  },
  {
    "text": "they called them histories um we took two 2.1 billions of billion particle",
    "start": "2450480",
    "end": "2455839"
  },
  {
    "text": "traces from this proton treatment plant and we ran them on amazon to do the",
    "start": "2455839",
    "end": "2461280"
  },
  {
    "text": "image reconstruction using amazon gpus and we were able to get that number",
    "start": "2461280",
    "end": "2467119"
  },
  {
    "text": "of uh the time it takes to reconstruct an image to 11 minutes so",
    "start": "2467119",
    "end": "2472240"
  },
  {
    "text": "i can give you more details about why that is important um but i'll probably you know take more time than than i can",
    "start": "2472240",
    "end": "2479680"
  },
  {
    "text": "the other things that that i do that that we do as a team is you know we have we're doing something very similar",
    "start": "2479680",
    "end": "2486480"
  },
  {
    "text": "to cardiovascular research analysis for ecg analysis at scale",
    "start": "2486480",
    "end": "2492160"
  },
  {
    "text": "we also have a service that provides uh proteomics analysis on on on",
    "start": "2492160",
    "end": "2497839"
  },
  {
    "text": "at scale too um so if you want more information um come",
    "start": "2497839",
    "end": "2503200"
  },
  {
    "text": "and talk to me after the talk and you know at some level our goal is to to accelerate discovery and innovation",
    "start": "2503200",
    "end": "2510079"
  },
  {
    "text": "worldwide by making it by making research i.t available as a service and",
    "start": "2510079",
    "end": "2515119"
  },
  {
    "text": "and we're leveraging amazon at every given point and to make it possible to to make this",
    "start": "2515119",
    "end": "2521839"
  },
  {
    "text": "research idea available as a service so um the goal is to accelerate the rate at",
    "start": "2521839",
    "end": "2528000"
  },
  {
    "text": "which the scientific discovery happens right and the way that and the way we are trying to make that happen is to",
    "start": "2528000",
    "end": "2534960"
  },
  {
    "text": "use appropriate computational techniques and making research i.t available as a service so researchers can focus on what",
    "start": "2534960",
    "end": "2542319"
  },
  {
    "text": "they're good at rather than figuring out how to do uh how to do it",
    "start": "2542319",
    "end": "2547920"
  },
  {
    "text": "so i got some funding from from dod nih and and amazon has been really kind to",
    "start": "2547920",
    "end": "2553680"
  },
  {
    "text": "give us some educational grants uh so we could bootstrap some of these efforts and show value to to the researchers and",
    "start": "2553680",
    "end": "2560960"
  },
  {
    "text": "and um and and continue our work i have a lot of people at uchicago and",
    "start": "2560960",
    "end": "2566640"
  },
  {
    "text": "aragon that i work with who who did a lot of the work that i'm presenting here and that's just",
    "start": "2566640",
    "end": "2573040"
  },
  {
    "text": "thank you",
    "start": "2573040",
    "end": "2576280"
  },
  {
    "text": "x cheers all right fantastic so i think um we",
    "start": "2579599",
    "end": "2585440"
  },
  {
    "text": "sort of gone through uh some really exceptionally interesting areas here and",
    "start": "2585440",
    "end": "2592000"
  },
  {
    "text": "talked a little bit about how data is accelerating the state of the",
    "start": "2592000",
    "end": "2597040"
  },
  {
    "text": "art accelerating the state of science and if you have any interest in this area",
    "start": "2597040",
    "end": "2602880"
  },
  {
    "text": "please do drop me an email i'm matthew amazon.com if you have data sets you'd like to make available please do let me",
    "start": "2602880",
    "end": "2608880"
  },
  {
    "text": "know if you have more interest in the education grants program that ravi mentioned then please do get in touch as",
    "start": "2608880",
    "end": "2614480"
  },
  {
    "text": "well with that i'd like to wrap up if you have any questions then i'll hang around for a few extra minutes along with the rest of my speakers thanks a",
    "start": "2614480",
    "end": "2619839"
  },
  {
    "text": "lot",
    "start": "2619839",
    "end": "2622839"
  }
]
[
  {
    "text": "Graff noon and welcome to the introductory session to Amazon redshift",
    "start": "0",
    "end": "5509"
  },
  {
    "text": "my name is Pavan petha Coetzee I lead the product team for redshift and I'm",
    "start": "5509",
    "end": "11910"
  },
  {
    "text": "glad to have with me namwon from RetailMeNot who is going to talk about their journey with red shift so in",
    "start": "11910",
    "end": "24090"
  },
  {
    "text": "today's session we're going to talk about what red shift is and why you would want to consider using it we'll",
    "start": "24090",
    "end": "32430"
  },
  {
    "text": "talk about some of the key features of red shift and their benefits we'll talk",
    "start": "32430",
    "end": "38640"
  },
  {
    "text": "about how customers are using Amazon redshift and of course we'll have Nam",
    "start": "38640",
    "end": "44700"
  },
  {
    "text": "talk about how redshift fits into their analytical platform at RetailMeNot and",
    "start": "44700",
    "end": "52050"
  },
  {
    "text": "we'll have some time for questions so",
    "start": "52050",
    "end": "55850"
  },
  {
    "text": "this is the ever-changing snapshot of the AWS big data portfolio so you can",
    "start": "57199",
    "end": "65549"
  },
  {
    "text": "bring large amounts of data into AWS using Direct Connect we have import/export and as of today",
    "start": "65549",
    "end": "72330"
  },
  {
    "text": "morning snowball we have kinases through which you can stream data from hundreds of thousands",
    "start": "72330",
    "end": "79049"
  },
  {
    "text": "of data producers and process them across multiple services within AWS and",
    "start": "79049",
    "end": "85290"
  },
  {
    "text": "of course is another service there that got added Kinesis firehose on the",
    "start": "85290",
    "end": "90420"
  },
  {
    "text": "storage side depending on the data format you can store just about anything in s3 you can if the data has relational",
    "start": "90420",
    "end": "98670"
  },
  {
    "text": "semantics you can use Amazon or aura for that for key value data we have dynamo",
    "start": "98670",
    "end": "105750"
  },
  {
    "text": "DB for lifecycle policies and moving data to a lower storage low cost storage",
    "start": "105750",
    "end": "113070"
  },
  {
    "text": "system you can do that through place here from Amazon s3 for text search and",
    "start": "113070",
    "end": "119100"
  },
  {
    "text": "indexing we have cloud search that can be utilized once you store all of this",
    "start": "119100",
    "end": "124979"
  },
  {
    "text": "data we have a set of services through which you can analyze them we have",
    "start": "124979",
    "end": "130340"
  },
  {
    "text": "Amazon EMR that can be used to process unstructured data very quickly through",
    "start": "130340",
    "end": "135659"
  },
  {
    "text": "Hadoop once you process that data you can bring into Amazon redshift for quick",
    "start": "135659",
    "end": "141420"
  },
  {
    "text": "sequel axes so we have machine learning through which you can run predictive",
    "start": "141420",
    "end": "147120"
  },
  {
    "text": "analytics on data sitting in Amazon redshift we have a data orchestration",
    "start": "147120",
    "end": "152280"
  },
  {
    "text": "layer called data pipeline that can help you move data across these various services and schedule jobs again this",
    "start": "152280",
    "end": "161010"
  },
  {
    "text": "picture guard a little bit little bit bigger as of today morning on the analytics side we have quick side on the",
    "start": "161010",
    "end": "168120"
  },
  {
    "text": "orchestration side we have the data migration service that can help you move data across database engines so one of",
    "start": "168120",
    "end": "174599"
  },
  {
    "text": "the occupational hazards of working for AWS is our slides tend to get stale very quickly so what is redshift in simple",
    "start": "174599",
    "end": "186599"
  },
  {
    "text": "terms redshift is data warehousing made fast simple and very cost effective",
    "start": "186599",
    "end": "194060"
  },
  {
    "text": "redshift is a sequel based relational data warehouse it's based on a massively",
    "start": "194060",
    "end": "202049"
  },
  {
    "text": "parallel processing architecture and uses columnar storage it's an order of",
    "start": "202049",
    "end": "207540"
  },
  {
    "text": "magnitude faster than a lot of the comparable row stores out there it's",
    "start": "207540",
    "end": "213599"
  },
  {
    "text": "very easy to use you can provision hundreds of gigabytes or hundreds of",
    "start": "213599",
    "end": "219299"
  },
  {
    "text": "terabytes with in under three minutes you can scale you can add capacity you",
    "start": "219299",
    "end": "224849"
  },
  {
    "text": "can remove capacity through a few clicks on the management console it's a managed service in that we manage",
    "start": "224849",
    "end": "233250"
  },
  {
    "text": "backups we make recovery very easy we manage patching we manage a bunch of",
    "start": "233250",
    "end": "242819"
  },
  {
    "text": "other aspects around disaster recovery and make it very easy for you to set it up it's very cost effective like a",
    "start": "242819",
    "end": "251250"
  },
  {
    "text": "described earlier it's an order of magnitude cheaper than a lot of other data warehousing solutions available in",
    "start": "251250",
    "end": "257099"
  },
  {
    "text": "the market so the traditional view of",
    "start": "257099",
    "end": "262529"
  },
  {
    "text": "data warehousing and if you have been to Andy's keynote it sort of reflects some of the points that he has in Tehran it has largely centered around",
    "start": "262529",
    "end": "271420"
  },
  {
    "text": "multi year deployments multi-year deals multi-million dollar deals and",
    "start": "271420",
    "end": "278920"
  },
  {
    "text": "multi-year commitments so all of this means that data warehousing has largely",
    "start": "278920",
    "end": "284090"
  },
  {
    "text": "been in the realm of usage within the top thousand to 2,000 global enterprises",
    "start": "284090",
    "end": "289960"
  },
  {
    "text": "and it has largely been sold to central IT teams within enterprises we believe",
    "start": "289960",
    "end": "297140"
  },
  {
    "text": "that this is a very narrow view as a lot of you in this audience today can vouch small companies have big data -",
    "start": "297140",
    "end": "305140"
  },
  {
    "text": "especially in the last five years or so that the proliferation of mobile gaming",
    "start": "305140",
    "end": "311330"
  },
  {
    "text": "social and IOT this is increasingly the case even within enterprises long",
    "start": "311330",
    "end": "318020"
  },
  {
    "text": "deployment cycles high operational complexity and a lot of cost costs that",
    "start": "318020",
    "end": "327710"
  },
  {
    "text": "are involved across both provisioning managing and procuring warehouses",
    "start": "327710",
    "end": "332840"
  },
  {
    "text": "warehouse infrastructure means that departmental groups within enterprises",
    "start": "332840",
    "end": "338360"
  },
  {
    "text": "are not able to move as fast as they want to on projects this leads to what",
    "start": "338360",
    "end": "345530"
  },
  {
    "text": "we believe is a lot of dark data and this is a analysis from one of the",
    "start": "345530",
    "end": "350710"
  },
  {
    "text": "analyst companies that shows more than accept and it more than an exabyte of",
    "start": "350710",
    "end": "357590"
  },
  {
    "text": "dark data sitting in enterprise data stores so our view of data warehousing",
    "start": "357590",
    "end": "365960"
  },
  {
    "text": "is more inclusive so we believe that red shift is appealing to enterprises",
    "start": "365960",
    "end": "371720"
  },
  {
    "text": "because of the cost advantage it's also appealing because it's extremely easy to",
    "start": "371720",
    "end": "376940"
  },
  {
    "text": "provision it and so central IT teams can provision hard data warehouse infrastructure very quickly and scale it",
    "start": "376940",
    "end": "383450"
  },
  {
    "text": "very easily increasingly we are also seeing central ID setting guidelines and",
    "start": "383450",
    "end": "390520"
  },
  {
    "text": "letting the departmental groups go build their own infrastructure as a see fit",
    "start": "390520",
    "end": "398419"
  },
  {
    "text": "red shift also enables hi DBA productivity given the manager aspect of the service we're also seeing",
    "start": "398419",
    "end": "405840"
  },
  {
    "text": "of course a lot of big data companies leveraging great shift very efficiently and the key selling point for big data",
    "start": "405840",
    "end": "412980"
  },
  {
    "text": "companies is redshift is an order of magnitude faster than how do sequel on",
    "start": "412980",
    "end": "418830"
  },
  {
    "text": "harue analyst within companies don't need to",
    "start": "418830",
    "end": "426030"
  },
  {
    "text": "learn scripting don't need to look don't need to learn programming it's a standard sequel interface that can go",
    "start": "426030",
    "end": "431910"
  },
  {
    "text": "and that they can go and execute queries against redshift also ties pretty well",
    "start": "431910",
    "end": "440700"
  },
  {
    "text": "into a lot of other technologies that companies with big data use it ties very well with Hadoop you can run your ETL",
    "start": "440700",
    "end": "447420"
  },
  {
    "text": "jobs or MapReduce jobs on how dupe you can bring the data into redshift through",
    "start": "447420",
    "end": "453180"
  },
  {
    "text": "a copy command that is available on the data on the database directly you can",
    "start": "453180",
    "end": "460950"
  },
  {
    "text": "parallel e load data from services like EMR you can leverage data science technologies like machine learning on",
    "start": "460950",
    "end": "468750"
  },
  {
    "text": "top of redshift we also are seeing increasingly seeing a lot of SAS",
    "start": "468750",
    "end": "475200"
  },
  {
    "text": "companies leveraging redshift and that the key selling point for them is they want to provide more analytical",
    "start": "475200",
    "end": "481650"
  },
  {
    "text": "horsepower to their customers and don't want to wait until all the data is",
    "start": "481650",
    "end": "487860"
  },
  {
    "text": "processed they want to show the analytical capabilities right within the process flows of their applications they",
    "start": "487860",
    "end": "494550"
  },
  {
    "text": "also like the fact that they can pay on demand they can grow on demand easily with redshift and the manage nature with",
    "start": "494550",
    "end": "501660"
  },
  {
    "text": "availability manage for them dr manage for them is also appealing so this sort",
    "start": "501660",
    "end": "507810"
  },
  {
    "text": "of a view is leading to a pretty broad growth for redshift across a variety of",
    "start": "507810",
    "end": "513659"
  },
  {
    "text": "verticals and variety of custom segments",
    "start": "513660",
    "end": "519259"
  },
  {
    "text": "so we have companies like Nasdaq which which is very security focused a",
    "start": "519290",
    "end": "524850"
  },
  {
    "text": "traditional enterprise that is using redshift to load about five to eight",
    "start": "524850",
    "end": "530070"
  },
  {
    "text": "billion rows of data all day for trading day and analyze orders codes and trades you have",
    "start": "530070",
    "end": "538380"
  },
  {
    "text": "Yelp using redshift for analyzing ad campaign performance as well as",
    "start": "538380",
    "end": "543830"
  },
  {
    "text": "understanding how their end users are using their mobile app features see if",
    "start": "543830",
    "end": "549510"
  },
  {
    "text": "companies like des comm which is the SAS company that is owned by salesforce.com",
    "start": "549510",
    "end": "555510"
  },
  {
    "text": "now that is leveraging redshift to provide more analytical capabilities to their end customers an upon and for the",
    "start": "555510",
    "end": "564360"
  },
  {
    "text": "last two years as Andy pointed in the keynote today redshift has been the fastest growing aw service until Aurora",
    "start": "564360",
    "end": "571740"
  },
  {
    "text": "uprooted it a bit ago and with all your help I'm hoping we can grab that title back by next year it's taking a step",
    "start": "571740",
    "end": "582120"
  },
  {
    "text": "back I'm going to go over a little bit of detail around redshifts architecture",
    "start": "582120",
    "end": "589230"
  },
  {
    "text": "so we talked about redshift being an MP baby NPP based engine so we have a",
    "start": "589230",
    "end": "594870"
  },
  {
    "text": "leader node through which you access the cluster if you will and the leader node",
    "start": "594870",
    "end": "601320"
  },
  {
    "text": "stores the metadata for all your database objects it generates an optimized query plan and pushes code",
    "start": "601320",
    "end": "608730"
  },
  {
    "text": "into the compute nodes so that the queries can be executed all and pathol the compute node themselves store the",
    "start": "608730",
    "end": "616230"
  },
  {
    "text": "data locally in columnar format and processes a variety of operations in a",
    "start": "616230",
    "end": "622980"
  },
  {
    "text": "distributed and paralyzed manner for fast performance you can start with",
    "start": "622980",
    "end": "629070"
  },
  {
    "text": "redshift at 25 cents an hour for one sit there for 460 gigabytes and you can",
    "start": "629070",
    "end": "634860"
  },
  {
    "text": "scale it up to 2 petabytes of compressed data and we have customers running multiple petabytes today on redshift",
    "start": "634860",
    "end": "643279"
  },
  {
    "text": "so some of the key features on their benefits redshift is fast because of a",
    "start": "645110",
    "end": "652500"
  },
  {
    "text": "variety of reasons it uses columnar storage which means you perform",
    "start": "652500",
    "end": "659010"
  },
  {
    "text": "dramatically less higher than row stores which fetched a lot of data discard significant percentage of it",
    "start": "659010",
    "end": "665979"
  },
  {
    "text": "that is not required redshift does automatic data compression which again",
    "start": "665979",
    "end": "671319"
  },
  {
    "text": "means faster i/o performance but also lower storage costs so we typically see",
    "start": "671319",
    "end": "676569"
  },
  {
    "text": "customers getting an average of four times compression ratio with redshift so",
    "start": "676569",
    "end": "681939"
  },
  {
    "text": "if you're bringing a hundred terabyte data warehouse it could as well be 25 30 terabytes of redshift we use direct",
    "start": "681939",
    "end": "690519"
  },
  {
    "text": "attacks or storage and the block sizes that redshift uses is a megabyte which",
    "start": "690519",
    "end": "696759"
  },
  {
    "text": "is pretty large compared to transactional systems and this enables very fast scan rates so with redshift",
    "start": "696759",
    "end": "703569"
  },
  {
    "text": "you can get up to four gigabytes per second or node of scan rate given data",
    "start": "703569",
    "end": "708639"
  },
  {
    "text": "warehousing is very read intensive scan performance is pretty important redshift",
    "start": "708639",
    "end": "716079"
  },
  {
    "text": "also uses zone maps for fast performance so the way zone Maps work is each column",
    "start": "716079",
    "end": "724289"
  },
  {
    "text": "within a table gets an MB of several MB of contiguous blocks and each block as",
    "start": "724289",
    "end": "730629"
  },
  {
    "text": "we discussed is a megabyte in size and we store the min max value of each block",
    "start": "730629",
    "end": "736119"
  },
  {
    "text": "in memory so that for a starter data set when when you're executing a query we",
    "start": "736119",
    "end": "742059"
  },
  {
    "text": "fetch the minimal number of blocks possible to give you answers very quickly we'll talk a little bit more",
    "start": "742059",
    "end": "749049"
  },
  {
    "text": "about zone maps and sort keys in a bit next slide so here is an example of sort",
    "start": "749049",
    "end": "755169"
  },
  {
    "text": "of zone maps and how sort keys play a significant role in redshift so as you",
    "start": "755169",
    "end": "762789"
  },
  {
    "text": "think about getting started with redshift understanding sort keys and what does what do they mean in your",
    "start": "762789",
    "end": "769269"
  },
  {
    "text": "environment is very important so here is an example of a table with unsorted data so it's a date field and each block as",
    "start": "769269",
    "end": "778029"
  },
  {
    "text": "you can see here it has a min and Max value but there's significant amount of overlap because the data is not sorted",
    "start": "778029",
    "end": "784379"
  },
  {
    "text": "so if you perform a query where you're selecting count star from the stable",
    "start": "784379",
    "end": "791349"
  },
  {
    "text": "where you're trying to get data for a specific date and this sort of a query will hit",
    "start": "791349",
    "end": "799420"
  },
  {
    "text": "three of the four blocks so we have to read three of the four blocks to process this query because ninth June falls in",
    "start": "799420",
    "end": "808209"
  },
  {
    "text": "the first block second block as well as a fourth block if you have a sorted data set and you can see here that there's no",
    "start": "808209",
    "end": "815529"
  },
  {
    "text": "overlap between the ranges in any of these blocks it'll be just one block and",
    "start": "815529",
    "end": "822420"
  },
  {
    "text": "this is a simplistic example but the difference in the execution times can be",
    "start": "822420",
    "end": "829209"
  },
  {
    "text": "thought through in terms of complexity so the first data model has an order of",
    "start": "829209",
    "end": "835660"
  },
  {
    "text": "n complexity the second data model has an order one complexity so if you have a million blocks the second query will",
    "start": "835660",
    "end": "842290"
  },
  {
    "text": "return results significantly faster than the first one and we also have an",
    "start": "842290",
    "end": "848290"
  },
  {
    "text": "intermediary stage there with what we call as interleaved sort keys that enable you to get performance that's",
    "start": "848290",
    "end": "855850"
  },
  {
    "text": "somewhere in between so there's some trade-offs with using interleaved sort keys we have an advanced session tomorrow about red shift encourage you",
    "start": "855850",
    "end": "864310"
  },
  {
    "text": "to attend if you want to learn more about it red shift is also fast because",
    "start": "864310",
    "end": "870790"
  },
  {
    "text": "of the way the various operations that are needed for processing queries for",
    "start": "870790",
    "end": "876790"
  },
  {
    "text": "maintenance of the clusters so all of these happen in a parallel and distributed manner so queries happen",
    "start": "876790",
    "end": "883709"
  },
  {
    "text": "perrolli and and they're distributed loads unloads backups illustration",
    "start": "883709",
    "end": "890350"
  },
  {
    "text": "recites all of these operations are parallel which means the performance of your cluster across these operations grows",
    "start": "890350",
    "end": "898389"
  },
  {
    "text": "linearly as you add more nodes",
    "start": "898389",
    "end": "901949"
  },
  {
    "text": "distribution Keys is another concept that you want to understand before getting started with redshift so here is",
    "start": "903720",
    "end": "912399"
  },
  {
    "text": "a simple example where we have a table with a set of rows and typically you",
    "start": "912399",
    "end": "918490"
  },
  {
    "text": "want to load data into redshift through s 3 there are the mechanisms if you use in dynamodb other services but by far as three tends",
    "start": "918490",
    "end": "926700"
  },
  {
    "text": "to be the most common source for customers to load data into redshift and when you're loading data through the",
    "start": "926700",
    "end": "933600"
  },
  {
    "text": "copy command each core within a compute Nord picks up a file in parallel and starts",
    "start": "933600",
    "end": "941190"
  },
  {
    "text": "loading that data so if you have three compute nodes in this example let's say each compute node has 30 cores so you",
    "start": "941190",
    "end": "947730"
  },
  {
    "text": "have 90 course that is available for processing loads and paddle each code",
    "start": "947730",
    "end": "953820"
  },
  {
    "text": "will go to s3 and pick up a file so we encourage you to have multiples of 90 in",
    "start": "953820",
    "end": "959160"
  },
  {
    "text": "this particular case or multiples of the number of cores so that the data load happens very quickly so once the data",
    "start": "959160",
    "end": "966870"
  },
  {
    "text": "gets loaded each of the data points that",
    "start": "966870",
    "end": "972029"
  },
  {
    "text": "you have will need to find a home based on how you are distributing the data so",
    "start": "972029",
    "end": "978210"
  },
  {
    "text": "one way to distribute the data is evenly so in this particular case is just a round-robin way of distributing the data",
    "start": "978210",
    "end": "985430"
  },
  {
    "text": "so we have two other ways through which you can distribute data you can have all",
    "start": "985430",
    "end": "990870"
  },
  {
    "text": "of the all of this data sit in all the compute nodes instead of distributing it",
    "start": "990870",
    "end": "998220"
  },
  {
    "text": "so you have the exact same copy of the data in all the nodes this is typically the option for smaller dimension tables",
    "start": "998220",
    "end": "1004790"
  },
  {
    "text": "where you perform new cups so the idea would be any joint that you are performing you would want to aim for",
    "start": "1004790",
    "end": "1012460"
  },
  {
    "text": "having the joint performed locally so that there's no chattiness across the",
    "start": "1012460",
    "end": "1017870"
  },
  {
    "text": "nodes the other way to distribute data is through a key so if you have a large",
    "start": "1017870",
    "end": "1023690"
  },
  {
    "text": "fact table and a large dimension table that you're joining you would want to distribute the data using that",
    "start": "1023690",
    "end": "1029150"
  },
  {
    "text": "particular key so that all of your giants between those tables get served within each context of a compute node",
    "start": "1029150",
    "end": "1037880"
  },
  {
    "text": "and there's not much interaction between the nodes at that point there'll be more discussion around it in the advanced",
    "start": "1037880",
    "end": "1045620"
  },
  {
    "text": "session my idea was to just give you a taste of the things that you need to",
    "start": "1045620",
    "end": "1051320"
  },
  {
    "text": "keep in mind before you get started with redshift sort and distribution keys are very important",
    "start": "1051320",
    "end": "1056780"
  },
  {
    "text": "is the bottom line redshift is also fast",
    "start": "1056780",
    "end": "1061940"
  },
  {
    "text": "because we run on optimized hardware hardware there is optimized for i/o intensive workloads so we talked about",
    "start": "1061940",
    "end": "1068390"
  },
  {
    "text": "the 4gb per second scanned rate per node we have n were enhanced networking that enables a million packets per second of",
    "start": "1068390",
    "end": "1077210"
  },
  {
    "text": "retrieval you have the choice to pick",
    "start": "1077210",
    "end": "1082610"
  },
  {
    "text": "between SSD nodes and magnetic storage SSD storage offers 10 to 15 times more",
    "start": "1082610",
    "end": "1090080"
  },
  {
    "text": "performance than magnetic storage but it's 5 times more expensive so depending on your cost performance requirements",
    "start": "1090080",
    "end": "1096290"
  },
  {
    "text": "you would pick one versus other we also",
    "start": "1096290",
    "end": "1102280"
  },
  {
    "text": "have a very easy way for customers to migrate from one generation of hardware",
    "start": "1102280",
    "end": "1108380"
  },
  {
    "text": "to another generation one recent example as we launched support for ds2 instance",
    "start": "1108380",
    "end": "1115760"
  },
  {
    "text": "drive which is a next-generation hard disk based platform and it provides 2",
    "start": "1115760",
    "end": "1122630"
  },
  {
    "text": "times more memory 2 times more compute capacity 1.5 times more bandwidth as a",
    "start": "1122630",
    "end": "1127760"
  },
  {
    "text": "previous generation of the instance family at the exact same cost so as we",
    "start": "1127760",
    "end": "1134030"
  },
  {
    "text": "get more efficiencies in the hardware we passed it along to customers across all",
    "start": "1134030",
    "end": "1139430"
  },
  {
    "text": "the services as you may be familiar the AWS pricing philosophy that takes us to",
    "start": "1139430",
    "end": "1147890"
  },
  {
    "text": "the cost aspect redshift as we talked about is very inexpensive compared to a lot of other options in the market so",
    "start": "1147890",
    "end": "1155360"
  },
  {
    "text": "you can process data at less than thousand dollars per terabyte per year",
    "start": "1155360",
    "end": "1162100"
  },
  {
    "text": "when most of the other options in the market costs anywhere between 10 to 25",
    "start": "1162100",
    "end": "1168650"
  },
  {
    "text": "times in some cases 50 times more we don't charge for the leader node pricing",
    "start": "1168650",
    "end": "1175010"
  },
  {
    "text": "is pretty simple we have two different pricing types you can choose on-demand",
    "start": "1175010",
    "end": "1180290"
  },
  {
    "text": "or you can choose our eyes if you're familiar with how our eyes work in the",
    "start": "1180290",
    "end": "1185960"
  },
  {
    "text": "ec2 world we talked a little bit about the managed",
    "start": "1185960",
    "end": "1192410"
  },
  {
    "text": "nature of red shell so one of the things that is very appealing the customer see",
    "start": "1192410",
    "end": "1197930"
  },
  {
    "text": "is very appealing to them is red ship does continuous and incremental backups",
    "start": "1197930",
    "end": "1203920"
  },
  {
    "text": "so you have whenever you write data into red shift copies of the data are",
    "start": "1203920",
    "end": "1209720"
  },
  {
    "text": "propagated to other nodes in a synchronous manner for higher data durability and data is also backed up",
    "start": "1209720",
    "end": "1218660"
  },
  {
    "text": "into s3 in a continuous manner and incremental is a very important concept",
    "start": "1218660",
    "end": "1224540"
  },
  {
    "text": "so if you have a terabyte large data warehouse that you've just backed up and",
    "start": "1224540",
    "end": "1230180"
  },
  {
    "text": "you loaded hundred gigs of data the next backup will only pick the delta of one",
    "start": "1230180",
    "end": "1237200"
  },
  {
    "text": "hundred gigs and not the entire 1.1 terabytes the often I think probably the",
    "start": "1237200",
    "end": "1248270"
  },
  {
    "text": "understated feature here is streaming restore the this is something that a lot of our customers say they're pleasantly",
    "start": "1248270",
    "end": "1255260"
  },
  {
    "text": "surprised by after we talked to talk through word so streaming restore enables you to create a cluster from",
    "start": "1255260",
    "end": "1263990"
  },
  {
    "text": "your backup even if it's no matter the size it could be 100 terabytes it could",
    "start": "1263990",
    "end": "1269270"
  },
  {
    "text": "be a petabyte you can start querying your restore cluster within under three",
    "start": "1269270",
    "end": "1274790"
  },
  {
    "text": "minutes you can do writes on it you can do reads on it the data behind the scenes gets streamed from s3 and the",
    "start": "1274790",
    "end": "1283550"
  },
  {
    "text": "queries that you are performing on the cluster will determine the priority of the blocks that are being fetched in",
    "start": "1283550",
    "end": "1289490"
  },
  {
    "text": "most cases and data warehousing 1989-90 eighty to ninety percent of the data is you know not frequently accessed so the",
    "start": "1289490",
    "end": "1297080"
  },
  {
    "text": "ten percent of the data is loaded first and the rest later that enables quicker processing cooker you know time to query",
    "start": "1297080",
    "end": "1304880"
  },
  {
    "text": "for restores the red ship is also fault",
    "start": "1304880",
    "end": "1310190"
  },
  {
    "text": "tolerant so we have we monitor the health of each node within your redshift",
    "start": "1310190",
    "end": "1317600"
  },
  {
    "text": "clusters and and detect failures and take Recovery",
    "start": "1317600",
    "end": "1322760"
  },
  {
    "text": "Act remedial actions based on that so we tolerate red shift can tolerate multiple disk failures multiple node failures and",
    "start": "1322760",
    "end": "1329980"
  },
  {
    "text": "whenever the failure occurs did we detect it and then we provision a replacement and the replacement process",
    "start": "1329980",
    "end": "1336670"
  },
  {
    "text": "works very similar to the streaming restore process where the replacement node is provisioned with the bare",
    "start": "1336670",
    "end": "1342980"
  },
  {
    "text": "minimum schema that is necessary to continue the queries and then the node gets hydrated behind the scenes from the",
    "start": "1342980",
    "end": "1348950"
  },
  {
    "text": "copies of the data that we have in other nodes it's very easy to set up disaster",
    "start": "1348950",
    "end": "1356090"
  },
  {
    "text": "recovery with redshift with a few clicks on the management console you can say here is my source region and here are my",
    "start": "1356090",
    "end": "1362060"
  },
  {
    "text": "backups move those backups through destination region and keep them in sync and the restoration from the backups and",
    "start": "1362060",
    "end": "1372680"
  },
  {
    "text": "the other region happened in a streaming restore manner so it's very fast",
    "start": "1372680",
    "end": "1378550"
  },
  {
    "text": "security is an aspect that I'm sure is near and dear to most of you here and from the get-go redshift has been",
    "start": "1379000",
    "end": "1385790"
  },
  {
    "text": "designed with enterprise level security in mind so we have end-to-end encryption",
    "start": "1385790",
    "end": "1391490"
  },
  {
    "text": "starting with loading the data in an encrypted manner in a s3 loading from",
    "start": "1391490",
    "end": "1397910"
  },
  {
    "text": "that loading that data from s3 into redshift in an encrypted manner or transit you have variety of encryption",
    "start": "1397910",
    "end": "1404090"
  },
  {
    "text": "options available to you you can use flour HSM you can use on-premise HSM to secure the data at rest and have control",
    "start": "1404090",
    "end": "1413750"
  },
  {
    "text": "over it there are several levels of audit logging available so that you can",
    "start": "1413750",
    "end": "1418760"
  },
  {
    "text": "understand who is executing queries what roles do they have what times are those are those queries executed who is",
    "start": "1418760",
    "end": "1425540"
  },
  {
    "text": "logging in etc we also have several compliance initiatives that we have been",
    "start": "1425540",
    "end": "1430580"
  },
  {
    "text": "through and notably BAA which is in the",
    "start": "1430580",
    "end": "1435620"
  },
  {
    "text": "healthcare specific compliance requirement FedRAMP which is the federal government standard which is pretty",
    "start": "1435620",
    "end": "1441530"
  },
  {
    "text": "stringent so all of these are enterprise level compliance requirements that",
    "start": "1441530",
    "end": "1447650"
  },
  {
    "text": "redshift satisfies so one of the",
    "start": "1447650",
    "end": "1452790"
  },
  {
    "text": "interesting aspects that that is made possible in a cloud-based environment is the ability for us to do continuous",
    "start": "1452790",
    "end": "1460320"
  },
  {
    "text": "deployments as I'm sure a lot of you strive to achieve on the services so",
    "start": "1460320",
    "end": "1465600"
  },
  {
    "text": "this on the product side we strive to achieve continuous deployments as well so which means you have cold coming in",
    "start": "1465600",
    "end": "1471600"
  },
  {
    "text": "features new features coming in reliability improvements security",
    "start": "1471600",
    "end": "1476640"
  },
  {
    "text": "improvements all of those streaming in in a very continuous manner we we actually have patterns coming every two",
    "start": "1476640",
    "end": "1482100"
  },
  {
    "text": "weeks for the most part so we released over 100 new features in the last two plus years that redshift has been around",
    "start": "1482100",
    "end": "1488940"
  },
  {
    "text": "and most on-premise data warehousing systems you know you have to wait for six months one year to get new features",
    "start": "1488940",
    "end": "1498290"
  },
  {
    "text": "redshift provides you a lot of analytical horsepower it enables you to do a lot of interesting things around",
    "start": "1498620",
    "end": "1505680"
  },
  {
    "text": "data science so we have approximate functions that enable you to do count",
    "start": "1505680",
    "end": "1511080"
  },
  {
    "text": "distinct sort of queries extremely quickly with some margin of error which",
    "start": "1511080",
    "end": "1517650"
  },
  {
    "text": "is typically in the range of one to two percent we have recently released",
    "start": "1517650",
    "end": "1524240"
  },
  {
    "text": "user-defined functions which makes thousands of Python functions available to you you can define your own functions",
    "start": "1524240",
    "end": "1532260"
  },
  {
    "text": "you can bring your own libraries call those functions from sequel for doing",
    "start": "1532260",
    "end": "1538670"
  },
  {
    "text": "advanced analytical functions as well as",
    "start": "1538670",
    "end": "1543720"
  },
  {
    "text": "data related functions as well as optimization research or some operations",
    "start": "1543720",
    "end": "1549330"
  },
  {
    "text": "research our optimization related function so Python makes all of these available and with the support for the",
    "start": "1549330",
    "end": "1555450"
  },
  {
    "text": "user-defined functions you can take advantage of them we talked a little bit about machine learning and the ability",
    "start": "1555450",
    "end": "1560970"
  },
  {
    "text": "to run define predictive analytics models and use redshift as a data source",
    "start": "1560970",
    "end": "1566010"
  },
  {
    "text": "and run these models again straight through the machine learning servers you also can use a variety of partner tools",
    "start": "1566010",
    "end": "1573210"
  },
  {
    "text": "so we work with sass pretty closely so if you're using advanced statistical",
    "start": "1573210",
    "end": "1579920"
  },
  {
    "text": "technologies access you can take advantage of the processing power of redshift",
    "start": "1579920",
    "end": "1585940"
  },
  {
    "text": "and then feed the results into size for advanced analytics you can do the same",
    "start": "1585940",
    "end": "1590950"
  },
  {
    "text": "with our as well so we have a fairly large ecosystem and we understand that",
    "start": "1590950",
    "end": "1598690"
  },
  {
    "text": "in the warehousing world a lot of you probably a migrating from other systems you have existing investments in bi to",
    "start": "1598690",
    "end": "1606309"
  },
  {
    "text": "laying and ETL to laying that we respect so we work with a lot of data",
    "start": "1606309",
    "end": "1612250"
  },
  {
    "text": "integration partners we work with a lot of bi partners in addition there are a",
    "start": "1612250",
    "end": "1617500"
  },
  {
    "text": "lot of system integrators that we work with to enable you to either migrate or",
    "start": "1617500",
    "end": "1623289"
  },
  {
    "text": "get started with redshift very quickly",
    "start": "1623289",
    "end": "1627990"
  },
  {
    "text": "so we follow a service-oriented architecture across AWS so we have multiple services that you",
    "start": "1629519",
    "end": "1637210"
  },
  {
    "text": "can use as building blocks to put together any solution that you desire in the analytics side so the variety of",
    "start": "1637210",
    "end": "1644259"
  },
  {
    "text": "services we talked a little bit about machine learning you can plug trout",
    "start": "1644259",
    "end": "1649419"
  },
  {
    "text": "search into red shift for doing text related search and you know other",
    "start": "1649419",
    "end": "1655620"
  },
  {
    "text": "analytics with red shift so we have kinases and our firehose",
    "start": "1655620",
    "end": "1660789"
  },
  {
    "text": "so with firehose you can set redshift as one of the destinations all you have to do is define a throughput that you",
    "start": "1660789",
    "end": "1666850"
  },
  {
    "text": "require for your stream and then specify a copy command that can be executed by redshift on a periodical basis typically",
    "start": "1666850",
    "end": "1674110"
  },
  {
    "text": "every five minutes so that you are able to do analytics in a real near near",
    "start": "1674110",
    "end": "1681279"
  },
  {
    "text": "real-time manner so a few use cases and",
    "start": "1681279",
    "end": "1687250"
  },
  {
    "text": "how customers are leveraging these features and functionality to enable",
    "start": "1687250",
    "end": "1693870"
  },
  {
    "text": "interesting things in their analytics environments so first one is sort of a hypothetical use case so we looked at",
    "start": "1693870",
    "end": "1701350"
  },
  {
    "text": "how much would it would cost for somebody to stream the entire Twitter firehose and analyze it through the",
    "start": "1701350",
    "end": "1708970"
  },
  {
    "text": "various building blocks we have within our analytics portfolio so you have the",
    "start": "1708970",
    "end": "1714279"
  },
  {
    "text": "Kinesis stream that can I think Twitter has around it is a year ago it used to generate",
    "start": "1714279",
    "end": "1721050"
  },
  {
    "text": "around 500 million tweets a day and let's say you stream those bikini",
    "start": "1721050",
    "end": "1726930"
  },
  {
    "text": "scissors move that into bread shift or s3 depending on where you want to",
    "start": "1726930",
    "end": "1733170"
  },
  {
    "text": "purchase them so different costs for each of these services and it comes to",
    "start": "1733170",
    "end": "1741810"
  },
  {
    "text": "around comes to less than three dollars an hour to stream the entire Twitter firehose and perform analytics on and",
    "start": "1741810",
    "end": "1748950"
  },
  {
    "text": "using these various building blocks less than how much it would cost you for a Starbucks coffee so the idea here is you",
    "start": "1748950",
    "end": "1758370"
  },
  {
    "text": "can perform really powerful analytics with with redshift and Kinesis and the",
    "start": "1758370",
    "end": "1765240"
  },
  {
    "text": "other services that you have a very cost effective price point you can scale",
    "start": "1765240",
    "end": "1773250"
  },
  {
    "text": "these services as you need you have our eyes through which you can get more discounts if you decide that's a path",
    "start": "1773250",
    "end": "1779370"
  },
  {
    "text": "that you want to go for a year more or three years another interesting example",
    "start": "1779370",
    "end": "1786300"
  },
  {
    "text": "is Amazon com so amazon.com as you know is one of the highly trafficked website",
    "start": "1786300",
    "end": "1794190"
  },
  {
    "text": "in the world so we get around 150 million visits on a monthly basis so in",
    "start": "1794190",
    "end": "1802140"
  },
  {
    "text": "an in commerce sort of a use case you want to get this data you want to get the clickstream data and analyze",
    "start": "1802140",
    "end": "1809150"
  },
  {
    "text": "purchase patterns and behaviors who is purchasing what products who is moving",
    "start": "1809150",
    "end": "1814860"
  },
  {
    "text": "through the cart and on purchasing eventually and then go back into the reasons of why that's happening this is",
    "start": "1814860",
    "end": "1821190"
  },
  {
    "text": "a big data workload it's a petabyte scale they're generating 2 terabytes of",
    "start": "1821190",
    "end": "1827100"
  },
  {
    "text": "clickstream data ad and growing it around 67 percent year-over-year so the",
    "start": "1827100",
    "end": "1833400"
  },
  {
    "text": "largest table is 400 terabytes that's a significantly large footprint",
    "start": "1833400",
    "end": "1838820"
  },
  {
    "text": "also their legacy data warehouse solution which is based on Oracle RAC",
    "start": "1838820",
    "end": "1844550"
  },
  {
    "text": "through that they were able to do scans of a1 scan of one week of data per hour",
    "start": "1844550",
    "end": "1850620"
  },
  {
    "text": "so in an hour they were able to process one week worth of data and that's what",
    "start": "1850620",
    "end": "1856200"
  },
  {
    "text": "that was not enough for them they wanted to do more longitudinal analysis and there's also space and storage",
    "start": "1856200",
    "end": "1861870"
  },
  {
    "text": "constraints if you're using rack the number of nodes that you can have there so they moved to a hardwood based system",
    "start": "1861870",
    "end": "1868620"
  },
  {
    "text": "and that enabled them to grow to do this much faster so they were able to query",
    "start": "1868620",
    "end": "1874260"
  },
  {
    "text": "one month of data in an hour with redshift which is when they two years",
    "start": "1874260",
    "end": "1883170"
  },
  {
    "text": "ago that they started looking at this project which was when redshift was released they were able to query 15",
    "start": "1883170",
    "end": "1888990"
  },
  {
    "text": "months of data in under 14 minutes so they went from querying one week of data",
    "start": "1888990",
    "end": "1894360"
  },
  {
    "text": "to one month of data to 15 months in less than 15 minutes they are able to",
    "start": "1894360",
    "end": "1900270"
  },
  {
    "text": "load five billion rows in under ten minutes and join and perform really",
    "start": "1900270",
    "end": "1906210"
  },
  {
    "text": "complex joins across huge data sets and tables in in this particular case one of",
    "start": "1906210",
    "end": "1913800"
  },
  {
    "text": "the queries that used to take three days started taking two hours in redshift and their load pipeline for ETL became",
    "start": "1913800",
    "end": "1921600"
  },
  {
    "text": "significantly faster as well so it's a fairly large footprint they have lots of",
    "start": "1921600",
    "end": "1927540"
  },
  {
    "text": "clusters and lots of nodes across lots",
    "start": "1927540",
    "end": "1932820"
  },
  {
    "text": "of different groups within Amazon that is using that is now using redshift and all of this are able to do with 2d beers",
    "start": "1932820",
    "end": "1941000"
  },
  {
    "text": "and I think that's a significant part of this equation it's just not the DBA aspect there's also the data engineering",
    "start": "1941000",
    "end": "1947750"
  },
  {
    "text": "aspect and data engineers typically spend a ton of time trying to figure out",
    "start": "1947750",
    "end": "1953190"
  },
  {
    "text": "the ETL process trying to recover from failures of jobs fail and so that is also another significant investment in",
    "start": "1953190",
    "end": "1959520"
  },
  {
    "text": "time all of that reduced considerably with redshift another example that we",
    "start": "1959520",
    "end": "1967160"
  },
  {
    "text": "talked a little bit about in the keynote is NTT DoCoMo so they are one of they're",
    "start": "1967160",
    "end": "1972480"
  },
  {
    "text": "probably the largest telecom company in Japan and generate petabytes of data",
    "start": "1972480",
    "end": "1980000"
  },
  {
    "text": "corresponding to their cellphone towers and mobile usage within the company and",
    "start": "1980000",
    "end": "1987010"
  },
  {
    "text": "the the work on a hybrid sort of a model where all of this data gets generated in",
    "start": "1987010",
    "end": "1992360"
  },
  {
    "text": "their on-premises environment then they move this data to redshift and AWS to",
    "start": "1992360",
    "end": "1999050"
  },
  {
    "text": "analyze it so this is another use case that is that it had very stringent",
    "start": "1999050",
    "end": "2004450"
  },
  {
    "text": "security requirements to move the data",
    "start": "2004450",
    "end": "2010919"
  },
  {
    "text": "so the various components within redshift that enable the secure security",
    "start": "2011370",
    "end": "2018070"
  },
  {
    "text": "requirements to be satisfied include some of the things that we already talked about encryption at rest aspects",
    "start": "2018070",
    "end": "2025000"
  },
  {
    "text": "with the various levels of key management available so redshift were",
    "start": "2025000",
    "end": "2030370"
  },
  {
    "text": "runs in a you can wonder shift in V PC and define your own subnet subnets and",
    "start": "2030370",
    "end": "2035980"
  },
  {
    "text": "networking topologies to secure your date you can audit all your sequel",
    "start": "2035980",
    "end": "2041200"
  },
  {
    "text": "queries and user logins so all of this is made possible and you know done in a",
    "start": "2041200",
    "end": "2047440"
  },
  {
    "text": "very fast time frame the migration their migration took I think a few weeks to",
    "start": "2047440",
    "end": "2053889"
  },
  {
    "text": "get it all the way so at this point they believe that cloud is at least as secure",
    "start": "2053890",
    "end": "2059290"
  },
  {
    "text": "or more secure than the environment that they are being running in so another",
    "start": "2059290",
    "end": "2064629"
  },
  {
    "text": "interesting use case and we somehow tend to see these in Japan so there's a sushi",
    "start": "2064630",
    "end": "2070510"
  },
  {
    "text": "chain with 380 art stores in Japan they",
    "start": "2070510",
    "end": "2076179"
  },
  {
    "text": "have they use their plates the sushi plates as IOT devices they plug them in",
    "start": "2076179",
    "end": "2082929"
  },
  {
    "text": "onto the plates the plates move across the store and of course you know people",
    "start": "2082929",
    "end": "2089290"
  },
  {
    "text": "order and consume sushis and they stream the data related to the food consumption",
    "start": "2089290",
    "end": "2097330"
  },
  {
    "text": "through Kinesis and then that data finds its way into redshift within 5 minutes",
    "start": "2097330",
    "end": "2103990"
  },
  {
    "text": "or so so this sort of architecture enables them to combine their inventory",
    "start": "2103990",
    "end": "2109300"
  },
  {
    "text": "in with information with consumption and confirm a so that they can better understand the",
    "start": "2109300",
    "end": "2115080"
  },
  {
    "text": "supply see and behavior control cause and bring in more efficiencies so one of",
    "start": "2115080",
    "end": "2121350"
  },
  {
    "text": "the interesting things around big data is it tends to with art has a more batch oriented workflow and immediate",
    "start": "2121350",
    "end": "2130110"
  },
  {
    "text": "operation and intelligence is something that we see we hear customers are saying",
    "start": "2130110",
    "end": "2136140"
  },
  {
    "text": "extremely difficult or hard to do so that services like kinases and the",
    "start": "2136140",
    "end": "2142260"
  },
  {
    "text": "ability to move that data very quickly into redshift enables you to enables you to do near real-time analysis it's it's",
    "start": "2142260",
    "end": "2149700"
  },
  {
    "text": "not real time but it's near real time and you can mix and match environments",
    "start": "2149700",
    "end": "2156270"
  },
  {
    "text": "like NTT DoCoMo they even run your keep running your own from his environments and move your analytics into the cloud",
    "start": "2156270",
    "end": "2162530"
  },
  {
    "text": "to unleash value so overall if there's",
    "start": "2162530",
    "end": "2169860"
  },
  {
    "text": "one thought that I want you to take from this session is these continuously strive so that you spend less and less",
    "start": "2169860",
    "end": "2177510"
  },
  {
    "text": "time on your data bases and more time on your data I think we have achieved that",
    "start": "2177510",
    "end": "2183860"
  },
  {
    "text": "quite a bit over the last two years and we have you know more ways to go and you",
    "start": "2183860",
    "end": "2190530"
  },
  {
    "text": "know happy for happy that you came here and listen to this and I'm gonna turn it on to now and have them talk about how",
    "start": "2190530",
    "end": "2197280"
  },
  {
    "text": "redshift fits into their analytical platform thanks so much come on so my name is Nam",
    "start": "2197280",
    "end": "2203520"
  },
  {
    "text": "I'm an engineering manager at RetailMeNot lesser known my sister's",
    "start": "2203520",
    "end": "2209070"
  },
  {
    "text": "used to call me pepperoni nipples when I was growing up to be honest I feel like that nickname applies to a lot more",
    "start": "2209070",
    "end": "2214470"
  },
  {
    "text": "people in this room than they realize so who is RetailMeNot you tell me not is",
    "start": "2214470",
    "end": "2220020"
  },
  {
    "text": "a digital offers destination that connects consumers to savings we have",
    "start": "2220020",
    "end": "2226080"
  },
  {
    "text": "50,000 stores we typically have half a million coupons on at all time and we",
    "start": "2226080",
    "end": "2231570"
  },
  {
    "text": "connect every year to half a billion users this is our overall data flow it",
    "start": "2231570",
    "end": "2238890"
  },
  {
    "text": "kind of starts at the top with visits and you know people come to your site",
    "start": "2238890",
    "end": "2244410"
  },
  {
    "text": "click around that's kind of the presentation platforms activity section and we track everything from impressions",
    "start": "2244410",
    "end": "2251160"
  },
  {
    "text": "to your favorites to your likes or dislikes you know when you come to our site and find something that you like",
    "start": "2251160",
    "end": "2256770"
  },
  {
    "text": "you'll typically go to like a Kohl's or Macy's sports stores for me my personal",
    "start": "2256770",
    "end": "2263820"
  },
  {
    "text": "like triathlon equipment but whenever I click and make a purchase goes to financials all that gets tracked",
    "start": "2263820",
    "end": "2271070"
  },
  {
    "text": "typically we also record a lot of third-party data so Google web toolkit for SEO ExactTarget for email tracking",
    "start": "2271070",
    "end": "2278960"
  },
  {
    "text": "we do a lot of demographics tracking as well as IP location tracking and this",
    "start": "2278960",
    "end": "2284040"
  },
  {
    "text": "data processing box here is probably the majority of we're going to be talking about this produces a lot of interesting",
    "start": "2284040",
    "end": "2289620"
  },
  {
    "text": "analytics for our content operations marketing and statistics that we then",
    "start": "2289620",
    "end": "2295530"
  },
  {
    "text": "feed back into our presentation activities content operations obviously",
    "start": "2295530",
    "end": "2300690"
  },
  {
    "text": "they're the ones in charge of making sure the coupons and presentation of",
    "start": "2300690",
    "end": "2306060"
  },
  {
    "text": "information on our website meets our customers needs gives them the best experience marketing operations of",
    "start": "2306060",
    "end": "2312330"
  },
  {
    "text": "course is in charge of making sure that money spent on marketing goes to the right channels and all that is based on",
    "start": "2312330",
    "end": "2317940"
  },
  {
    "text": "information that we do they decide how much money we spend on SEO marketing email campaigns TV ads stuff like that",
    "start": "2317940",
    "end": "2324720"
  },
  {
    "text": "which in turns lead to more visits kind of completing the cycle of coupon",
    "start": "2324720",
    "end": "2329760"
  },
  {
    "text": "activity at RetailMeNot so our data is",
    "start": "2329760",
    "end": "2334800"
  },
  {
    "text": "typically in the hundreds of terabytes now you know I would say that's kind of the new norm of information back when I",
    "start": "2334800",
    "end": "2342060"
  },
  {
    "text": "first started processing with data I think I had you know systems that were in the tens of gigs and hundreds of gigs",
    "start": "2342060",
    "end": "2347760"
  },
  {
    "text": "and I thought that was big data but typically these days if you're not in",
    "start": "2347760",
    "end": "2353400"
  },
  {
    "text": "the terabytes you probably could just look under your couch cushion and find a terabyte of data somewhere what's more",
    "start": "2353400",
    "end": "2359910"
  },
  {
    "text": "interesting for us is kind of our data growth we started out in with our data",
    "start": "2359910",
    "end": "2365250"
  },
  {
    "text": "warehousing strategy or project back in 2012 and I think we had 500 gigs of data",
    "start": "2365250",
    "end": "2370650"
  },
  {
    "text": "starting then every year we had growth over a hundred percent and that created a lot of problems for us using",
    "start": "2370650",
    "end": "2377520"
  },
  {
    "text": "our at the time legacy warehousing strategy which I think was basically",
    "start": "2377520",
    "end": "2383400"
  },
  {
    "text": "taking you know physical Hardware strategies you're using legacy data warehousing systems and kind of just",
    "start": "2383400",
    "end": "2388500"
  },
  {
    "text": "implementing them in the cloud the like C so I think a lot of people in this",
    "start": "2388500",
    "end": "2395340"
  },
  {
    "text": "room hopefully you guys can relate to different sources of data for warehousing we have a lot of operational data stores",
    "start": "2395340",
    "end": "2401820"
  },
  {
    "text": "these are our my sequel databases that house user information and coupon information things that get presented to",
    "start": "2401820",
    "end": "2407640"
  },
  {
    "text": "the site we have a lot of log data this is web logs beacon event logs this is",
    "start": "2407640",
    "end": "2413460"
  },
  {
    "text": "probably the larger collection of data that we have and we also have the third-party data that we collected as",
    "start": "2413460",
    "end": "2419550"
  },
  {
    "text": "mentioned before in the legacy world we basically took this data and shoved it",
    "start": "2419550",
    "end": "2424650"
  },
  {
    "text": "straight into our data warehouse and it was a single monolithic system single",
    "start": "2424650",
    "end": "2429750"
  },
  {
    "text": "point of failure and for us this happened to be Vertica you know I think a single monolithic data warehouse is",
    "start": "2429750",
    "end": "2436700"
  },
  {
    "text": "kind of moving towards the wayside I think a lot of people are realizing that these systems are very very hard to maintain and redshift is definitely",
    "start": "2436700",
    "end": "2443790"
  },
  {
    "text": "given us a strategy to kind of escape this paradigm from the data warehouse",
    "start": "2443790",
    "end": "2448800"
  },
  {
    "text": "you know we obviously produce a lot of deliverables reports to various people we did a be testing for our websites and",
    "start": "2448800",
    "end": "2455550"
  },
  {
    "text": "our vertical system and we also produce statistics for content presentation and",
    "start": "2455550",
    "end": "2461900"
  },
  {
    "text": "this produced a lot of pain points for us first one is firefights I don't know",
    "start": "2461900",
    "end": "2469380"
  },
  {
    "text": "is could I get a raise of hands for anyone that's ever been on call for support for database systems yeah",
    "start": "2469380",
    "end": "2476430"
  },
  {
    "text": "firefighters kind of suck especially if you've ever dealt with a multi parallel",
    "start": "2476430",
    "end": "2481500"
  },
  {
    "text": "cluster database system you know you have the opportunity for disk drives on any of the notes to fail if a node fails",
    "start": "2481500",
    "end": "2488190"
  },
  {
    "text": "you could call in the middle of the night it's very time consuming to fix especially when you deal with some of",
    "start": "2488190",
    "end": "2493230"
  },
  {
    "text": "these very specific database systems where you have a lot of steps in order",
    "start": "2493230",
    "end": "2498240"
  },
  {
    "text": "to go through recovery and readers data and kind of recovery of data that's always a pain point the next problem",
    "start": "2498240",
    "end": "2506210"
  },
  {
    "text": "that we had in the central monolithic system were traffic jams I don't know",
    "start": "2506210",
    "end": "2512150"
  },
  {
    "text": "how many people have actually queried database systems but if you're in a big shared clustered environment you may",
    "start": "2512150",
    "end": "2518270"
  },
  {
    "text": "start to run a query query just sits there kind of waiting nothing's going on",
    "start": "2518270",
    "end": "2525920"
  },
  {
    "text": "it's not your fault select top one it's",
    "start": "2525920",
    "end": "2530960"
  },
  {
    "text": "just sitting waiting around and you know in some of these cases there are the analysts that you can blame Joe who has",
    "start": "2530960",
    "end": "2537320"
  },
  {
    "text": "the thousand line sequel statement with a whole bunch of cases aggregating on you know the join of a case statement",
    "start": "2537320",
    "end": "2544640"
  },
  {
    "text": "with the case statement on a joint on another table and it's just ridiculous but a lot of times this can also happen",
    "start": "2544640",
    "end": "2551270"
  },
  {
    "text": "just with too many people on the system and you know in the past we didn't",
    "start": "2551270",
    "end": "2556400"
  },
  {
    "text": "really have a strategy for dealing with traffic jams other than killing people's queries or telling people they couldn't",
    "start": "2556400",
    "end": "2562250"
  },
  {
    "text": "run their queries on the system this is obviously problematic bad PR for your data team you know you want to try to",
    "start": "2562250",
    "end": "2568820"
  },
  {
    "text": "avoid that processing windows when we first started back in 2012 you know it's",
    "start": "2568820",
    "end": "2574640"
  },
  {
    "text": "really easy to process 500 gigs of data in an hour start our processing typically around 2:00 a.m. you know we",
    "start": "2574640",
    "end": "2582230"
  },
  {
    "text": "finished by 3:00 turned into 5 turned into 7 turned into noon and then someone",
    "start": "2582230",
    "end": "2588590"
  },
  {
    "text": "was like hey come on you guys you got to do better than this it's starting become problem our consumers neither data first",
    "start": "2588590",
    "end": "2595850"
  },
  {
    "text": "thing in the morning and you have how to get it done somehow in some way the other thing was scaling so in these",
    "start": "2595850",
    "end": "2602360"
  },
  {
    "text": "systems adding more nodes replacing instance types these kinds of things",
    "start": "2602360",
    "end": "2609110"
  },
  {
    "text": "very manual it'd be great if there was some kind of manage database service",
    "start": "2609110",
    "end": "2614150"
  },
  {
    "text": "where you just do a couple button clicks and kind of solve this problem you know we had to do typically do it through our",
    "start": "2614150",
    "end": "2620630"
  },
  {
    "text": "stage environments test environments dev environments and production environments there's just a lot of extra work for not",
    "start": "2620630",
    "end": "2627890"
  },
  {
    "text": "a lot of productivity gains so how did we kind of solve this well I",
    "start": "2627890",
    "end": "2634430"
  },
  {
    "text": "would classify it as adopting more cloud strategies for data warehousing and",
    "start": "2634430",
    "end": "2640390"
  },
  {
    "text": "overall we didn't really have to change too much so we still have the same source to bees same log data all of that",
    "start": "2640390",
    "end": "2647930"
  },
  {
    "text": "stuff didn't really change one of the big changes for us was that we started loading everything into s3 if you're",
    "start": "2647930",
    "end": "2654980"
  },
  {
    "text": "going to use redshift the fastest way to load data into redshift is from s3 we",
    "start": "2654980",
    "end": "2660350"
  },
  {
    "text": "don't really have a lot of DynamoDB that's another option but s3 gives you a lot of flexibility and I'm sure there's",
    "start": "2660350",
    "end": "2666170"
  },
  {
    "text": "lots of talks about how awesome s3 is they're true next is Amazon redshift",
    "start": "2666170",
    "end": "2673730"
  },
  {
    "text": "instances notice how here there's not a single redshift cluster I think for us",
    "start": "2673730",
    "end": "2680260"
  },
  {
    "text": "redshift does solve a lot of the administration problems by itself but if we would have had a single redshift",
    "start": "2680260",
    "end": "2687410"
  },
  {
    "text": "cluster I don't think it would have solved a lot of the concurrency issues or resource contention issues that we",
    "start": "2687410",
    "end": "2692690"
  },
  {
    "text": "had I'll dive into the details of why we have so many clusters in a moment we",
    "start": "2692690",
    "end": "2701510"
  },
  {
    "text": "still have the same number of deliverables we essentially replace the sources of data with data coming out of",
    "start": "2701510",
    "end": "2707330"
  },
  {
    "text": "redshift still did reporting still did AV testing content presentation but we",
    "start": "2707330",
    "end": "2713210"
  },
  {
    "text": "were able after doing this migration start to do other types of things because we had some additional time on",
    "start": "2713210",
    "end": "2719570"
  },
  {
    "text": "our hands after we were able to perform this migration to redshift so the",
    "start": "2719570",
    "end": "2725780"
  },
  {
    "text": "on-demand breakdown I would say if there was anything that you guys were to take out of this meeting aside from the",
    "start": "2725780",
    "end": "2731390"
  },
  {
    "text": "pepperoni nipples comment it would be this slide so from s3 the way that we",
    "start": "2731390",
    "end": "2738500"
  },
  {
    "text": "use redshift the first class of clusters that we have are are only as needed you",
    "start": "2738500",
    "end": "2743600"
  },
  {
    "text": "know we have a lot of analysts they don't like to learn different languages and things like that they're very I",
    "start": "2743600",
    "end": "2751190"
  },
  {
    "text": "guess fixed on their sequel and you know with Vertica and sequel 99 compliant",
    "start": "2751190",
    "end": "2756860"
  },
  {
    "text": "sequel they were able to use redshift and spin up on demand clusters for them to do kind of ad hoc analysis these",
    "start": "2756860",
    "end": "2763100"
  },
  {
    "text": "clusters typically live you know only for a day and they shut down and you",
    "start": "2763100",
    "end": "2769160"
  },
  {
    "text": "never need them again so this was a very flexible way for us to expose information to analysts for stuff that",
    "start": "2769160",
    "end": "2776090"
  },
  {
    "text": "they had never seen before they would one crazy queries that you typically don't want them running on your production system without any impact to",
    "start": "2776090",
    "end": "2783320"
  },
  {
    "text": "any other person in the organization the next class of clusters we have our",
    "start": "2783320",
    "end": "2790040"
  },
  {
    "text": "ephemeral processing clusters these are pretty medium sized clusters they generally are only on one to three hours",
    "start": "2790040",
    "end": "2796730"
  },
  {
    "text": "a day and they kick off early in the morning 2:00 a.m. ish this was actually",
    "start": "2796730",
    "end": "2803510"
  },
  {
    "text": "probably the biggest shift for us we basically split out a lot of the systems and data processing and art editions",
    "start": "2803510",
    "end": "2809660"
  },
  {
    "text": "from our central cluster and said how many of these actually depend on each other and for things that don't depend",
    "start": "2809660",
    "end": "2815119"
  },
  {
    "text": "on each other we're able to scale them out horizontally using these ephemeral processing clusters one of the nice",
    "start": "2815119",
    "end": "2820820"
  },
  {
    "text": "things about redshift is that it maintains state when it shuts down so every time you bring it up it has all",
    "start": "2820820",
    "end": "2827930"
  },
  {
    "text": "the data exactly as it was from the prior state or from the priority of processing and you can just pick up",
    "start": "2827930",
    "end": "2833600"
  },
  {
    "text": "where you left off so this was actually a huge benefit for us the next class is",
    "start": "2833600",
    "end": "2839960"
  },
  {
    "text": "business hours most of your analysts I hope do not work 24/7 and you know when",
    "start": "2839960",
    "end": "2846980"
  },
  {
    "text": "we started implementing some of these business our clusters we've got some resistance for people that were saying",
    "start": "2846980",
    "end": "2852560"
  },
  {
    "text": "hey I need I need access to my data on Saturday at 10:00 p.m. and I'm like well you know we can give you a way to do it",
    "start": "2852560",
    "end": "2858440"
  },
  {
    "text": "but we'd like to shut it down over the weekends to save money and we're like you really don't have to work on",
    "start": "2858440",
    "end": "2865160"
  },
  {
    "text": "Saturday at 10:00 p.m. most of the time so they were begrudgingly accepted and",
    "start": "2865160",
    "end": "2870350"
  },
  {
    "text": "they seemed to be a lot happier on Mondays when they come in I don't know this is my interaction with some of these guys the next class of clusters",
    "start": "2870350",
    "end": "2879140"
  },
  {
    "text": "are the always up clusters these clusters typically or what our tableau is connect to you know external",
    "start": "2879140",
    "end": "2885500"
  },
  {
    "text": "customers if they have reports that they need to hit they kind of connect to these we're also an international",
    "start": "2885500",
    "end": "2890570"
  },
  {
    "text": "company so we have internal customer in the UK France they will hit these always up clusters and the workflow here",
    "start": "2890570",
    "end": "2898400"
  },
  {
    "text": "is that the ephemeral processing will turn on data produce aggregates spit it",
    "start": "2898400",
    "end": "2904190"
  },
  {
    "text": "out to s3 and the always up clusters will then consume data and when it becomes available",
    "start": "2904190",
    "end": "2909740"
  },
  {
    "text": "there usually only one to two terabytes of clusters sized clusters because they",
    "start": "2909740",
    "end": "2916160"
  },
  {
    "text": "don't need all of that raw data and usually if you're turning on all that raw data for your reports the reports",
    "start": "2916160",
    "end": "2921440"
  },
  {
    "text": "are really slow we like to have slightly faster reports so what does this mean",
    "start": "2921440",
    "end": "2927740"
  },
  {
    "text": "for the data team overall shifting the redshift as Pavan mention redshift is",
    "start": "2927740",
    "end": "2933350"
  },
  {
    "text": "data as a service our administration and firefights have become a lot easier I",
    "start": "2933350",
    "end": "2939310"
  },
  {
    "text": "typically look like this notice that guys not wearing any pants when I get called the middle of the",
    "start": "2939310",
    "end": "2944690"
  },
  {
    "text": "night I'm also not wearing pants but the time that I spend is more just logging",
    "start": "2944690",
    "end": "2951350"
  },
  {
    "text": "in checking to make sure the status I'm not actively doing you know migration or",
    "start": "2951350",
    "end": "2956869"
  },
  {
    "text": "bringing up of instances and a tree adding stuff to nodes like all of that is handled by AWS most recently I think",
    "start": "2956869",
    "end": "2963380"
  },
  {
    "text": "we had a cluster go down probably last month for half an hour in the middle of the night I think we just woke up in the",
    "start": "2963380",
    "end": "2968720"
  },
  {
    "text": "middle and the next day and we're like did you guys actually do anything no well okay it's up so it was a lot easier",
    "start": "2968720",
    "end": "2974990"
  },
  {
    "text": "for us after we switched over to redshift scaling the number of clusters",
    "start": "2974990",
    "end": "2981230"
  },
  {
    "text": "is a lot easier I mean it's if you guys have ever worked with RDS scaling up a scaling number of redshift clusters is",
    "start": "2981230",
    "end": "2987920"
  },
  {
    "text": "basically the same as scaling the number of artist instances and once again this",
    "start": "2987920",
    "end": "2993470"
  },
  {
    "text": "provides us the ability to scale our data processing horizontally",
    "start": "2993470",
    "end": "2998890"
  },
  {
    "text": "oops greatly expanding the number of jobs that we can do in a single night",
    "start": "2998890",
    "end": "3006720"
  },
  {
    "text": "scaling the size of the clusters is just as easy as doing it with RDS as well you",
    "start": "3006720",
    "end": "3012970"
  },
  {
    "text": "basically click select the instance type select the number redshift goes into a",
    "start": "3012970",
    "end": "3019390"
  },
  {
    "text": "read-only mode state probably for us it typically takes about five ish hours for 32",
    "start": "3019390",
    "end": "3024829"
  },
  {
    "text": "by 200 terabyte closer sizes and it's more based on the amount of disk space you use so if you're using a hundred",
    "start": "3024829",
    "end": "3031400"
  },
  {
    "text": "percent of disk space of a cluster it'll probably take a little bit longer but when you're right around the sweet spot at 50 percent disk space uses you're",
    "start": "3031400",
    "end": "3037190"
  },
  {
    "text": "probably take about five hours the cluster is in a read only once it's done resizing it automatically switches to",
    "start": "3037190",
    "end": "3043219"
  },
  {
    "text": "the new cluster instance sizes and instance types does all the rebalancing",
    "start": "3043219",
    "end": "3048279"
  },
  {
    "text": "behind-the-scenes for you and you really didn't have to do very much work or spend time to babysit processing windows",
    "start": "3048279",
    "end": "3056029"
  },
  {
    "text": "you know now we seem to just have so much more time and our analysts have",
    "start": "3056029",
    "end": "3061579"
  },
  {
    "text": "actually started kind of spinning up their own redshift clusters to do their own processing my favorite analysts",
    "start": "3061579",
    "end": "3070940"
  },
  {
    "text": "basically giggled when I told him about this and he's been a huge adopter and they each get their own little data",
    "start": "3070940",
    "end": "3077359"
  },
  {
    "text": "ecosystems where they can process data completely untouched by other teams and other systems and then redistributed",
    "start": "3077359",
    "end": "3084349"
  },
  {
    "text": "throughout the organization once they unload it back to s3",
    "start": "3084349",
    "end": "3089680"
  },
  {
    "text": "lessons learned these are my Homer Simpson's moments that we kind of experienced during our migration I",
    "start": "3095180",
    "end": "3100890"
  },
  {
    "text": "wasn't allowed to put a Homer Simpson picture on here automated cluster shut",
    "start": "3100890",
    "end": "3106590"
  },
  {
    "text": "down a lot of these can be very very large clusters I think one of ours is I",
    "start": "3106590",
    "end": "3112110"
  },
  {
    "text": "think $350,000 a year which for some of you guys may not be a lot of money for some of you guys it is a lot of money if",
    "start": "3112110",
    "end": "3119460"
  },
  {
    "text": "you leave these clusters up I think we had one cluster that was up for a month and nobody was really using it and we",
    "start": "3119460",
    "end": "3125010"
  },
  {
    "text": "just kind of accidentally left it on I would highly recommend having an automated shutdown process like every",
    "start": "3125010",
    "end": "3130230"
  },
  {
    "text": "night having a cluster shutdown especially for data warehousing when nobody's using it and starting one up",
    "start": "3130230",
    "end": "3136410"
  },
  {
    "text": "again is a lot easier to do than trying to get a rebate back from Amazon for a",
    "start": "3136410",
    "end": "3143220"
  },
  {
    "text": "cluster that's been up for an extra month I don't think they offer that future sorting distribution Keys Pavan",
    "start": "3143220",
    "end": "3150240"
  },
  {
    "text": "mentioned this before it's hugely important I think to get the sort and",
    "start": "3150240",
    "end": "3155670"
  },
  {
    "text": "distribution Keys correct especially for joinings across multiple datasets if you",
    "start": "3155670",
    "end": "3160770"
  },
  {
    "text": "don't it starts to do chatter and cross communication between all of the clustered nodes and our queries",
    "start": "3160770",
    "end": "3167040"
  },
  {
    "text": "typically and the worst case took like three to five hours after fixing the",
    "start": "3167040",
    "end": "3172170"
  },
  {
    "text": "sort pains and things like that it went down to 15 minutes I think query optimization and performance optimization optimization on",
    "start": "3172170",
    "end": "3178740"
  },
  {
    "text": "the databases is very very well worthwhile reserved instances you know I",
    "start": "3178740",
    "end": "3185760"
  },
  {
    "text": "think that with RDS and ec2 when other types of instances there's a lot of",
    "start": "3185760",
    "end": "3191400"
  },
  {
    "text": "options and sometimes because of the size of those instances the benefit for reserved instances aren't as pronounced",
    "start": "3191400",
    "end": "3198660"
  },
  {
    "text": "redshift only has two instance types or for instance types so I think it's a lot",
    "start": "3198660",
    "end": "3205230"
  },
  {
    "text": "more compelling to be able and a lot easier to select the instance type that you're going to be working with with",
    "start": "3205230",
    "end": "3210510"
  },
  {
    "text": "redshift much earlier and since you're probably dealing with multi terabyte systems the cost is good the cost",
    "start": "3210510",
    "end": "3217290"
  },
  {
    "text": "benefits going to be a lot greater so I think for us choosing reserved instances early on in the process would have been",
    "start": "3217290",
    "end": "3223770"
  },
  {
    "text": "very well worth for us and the last one is automated versus manual backups so with redshift",
    "start": "3223770",
    "end": "3231109"
  },
  {
    "text": "they definitely have the automated backups similar to RDS you can pick the number of days for the retention period",
    "start": "3231109",
    "end": "3237549"
  },
  {
    "text": "but the tricky part is that when the cluster goes down so do the automated",
    "start": "3237549",
    "end": "3242930"
  },
  {
    "text": "backups so automated backups are really good for forking your data or kind of",
    "start": "3242930",
    "end": "3248650"
  },
  {
    "text": "spinning off another or recovering from a prior state while your system is up",
    "start": "3248650",
    "end": "3254539"
  },
  {
    "text": "but if your system goes down and your automated backups disappear you're kind of Sol",
    "start": "3254539",
    "end": "3259640"
  },
  {
    "text": "so definitely always do manual backups on a regular basis otherwise you kind of",
    "start": "3259640",
    "end": "3265549"
  },
  {
    "text": "might be wishing you had someplace to restore from benefits to the business so",
    "start": "3265549",
    "end": "3273740"
  },
  {
    "text": "obviously the data team loves redshift I think unless the business it benefits",
    "start": "3273740",
    "end": "3279170"
  },
  {
    "text": "the business in some way shape or form you know it's really just the data toy for us instance type alone you know we",
    "start": "3279170",
    "end": "3286760"
  },
  {
    "text": "had Vertica and our monolithic system on ec2 x' with multiple terabytes of EBS",
    "start": "3286760",
    "end": "3294020"
  },
  {
    "text": "volumes attached to them switching over a redshift will netted roughly a 50% cost reduction and ec2 instance types",
    "start": "3294020",
    "end": "3301789"
  },
  {
    "text": "alone the other benefit of redshift is the licensing cost so on these kind of",
    "start": "3301789",
    "end": "3309079"
  },
  {
    "text": "legacy data bit data warehousing systems you're charged either by scores on your",
    "start": "3309079",
    "end": "3314890"
  },
  {
    "text": "instance types or by storage with redshift that's already baked into the cost and it's a very compelling reason",
    "start": "3314890",
    "end": "3321710"
  },
  {
    "text": "for moving over to redshift 50% reduction time on administration I would",
    "start": "3321710",
    "end": "3328400"
  },
  {
    "text": "say this is more database administration you know you still have to do kind of the query optimization but",
    "start": "3328400",
    "end": "3334660"
  },
  {
    "text": "database-as-a-service I've loved it I don't know if I could ever go back to",
    "start": "3334660",
    "end": "3340130"
  },
  {
    "text": "being a DBA and then internal customers",
    "start": "3340130",
    "end": "3345529"
  },
  {
    "text": "so I think the number one measure of success for a project in your company is how adopted it becomes typically we had",
    "start": "3345529",
    "end": "3354619"
  },
  {
    "text": "the BA system in the financial teams our primary customers for the data warehouse team at root Oh me not we",
    "start": "3354619",
    "end": "3360769"
  },
  {
    "text": "basically doubled those when I made these slides it's gone up even more since then people are just once they see",
    "start": "3360769",
    "end": "3369229"
  },
  {
    "text": "how easy it is to get access to information using this system without impacting other teams or production",
    "start": "3369229",
    "end": "3376130"
  },
  {
    "text": "systems they jump on it right away I mean information is quickly becoming the lifeblood of a lot of companies and",
    "start": "3376130",
    "end": "3382239"
  },
  {
    "text": "quick and easy access to your information is hugely beneficial for the organization with that I think I'd like",
    "start": "3382239",
    "end": "3391160"
  },
  {
    "text": "to open it up to Q&A",
    "start": "3391160",
    "end": "3393969"
  }
]
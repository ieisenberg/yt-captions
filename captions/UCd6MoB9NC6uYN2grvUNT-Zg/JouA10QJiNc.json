[
  {
    "start": "0",
    "end": "72000"
  },
  {
    "text": "hello everyone it's a great pleasure to be here today my name is Rick Wong I'm a software",
    "start": "89",
    "end": "6210"
  },
  {
    "text": "engineer and Netflix now in case you're wondering if you come to the right talk I'm 99% sure that you are if this is",
    "start": "6210",
    "end": "14639"
  },
  {
    "text": "what the recommendations say so in this talk we'll take you to a journey into",
    "start": "14639",
    "end": "20670"
  },
  {
    "text": "how Netflix and coda scale now you wonder how is the malla to be me",
    "start": "20670",
    "end": "25949"
  },
  {
    "text": "well we use ourselves as a use case as a case study so we can kind of figure out",
    "start": "25949",
    "end": "31500"
  },
  {
    "text": "and how we solve a problem and in this talk we discuss about our challenges",
    "start": "31500",
    "end": "38100"
  },
  {
    "text": "your particular approaches we take and of course we'll share with you some of",
    "start": "38100",
    "end": "43290"
  },
  {
    "text": "the learnings that we made both positive and negative and hopefully they will resonate and we can take it home maybe",
    "start": "43290",
    "end": "49260"
  },
  {
    "text": "maybe we'll we'll also hear from some great ideas from you after the session",
    "start": "49260",
    "end": "55489"
  },
  {
    "text": "so finally at the end we'll also pond a",
    "start": "55489",
    "end": "61649"
  },
  {
    "text": "little bit about what we might be doing the future but that's that let's have a",
    "start": "61649",
    "end": "67049"
  },
  {
    "text": "quick introduction Netflix is the",
    "start": "67049",
    "end": "73740"
  },
  {
    "start": "72000",
    "end": "115000"
  },
  {
    "text": "world's leading internet entertainment service with for over 100 million",
    "start": "73740",
    "end": "80729"
  },
  {
    "text": "members in 190 countries we have a",
    "start": "80729",
    "end": "85860"
  },
  {
    "text": "Content budget of six billion dollars in 2017 alone and that result in one",
    "start": "85860",
    "end": "92130"
  },
  {
    "text": "hundred one thousand hours of original programming with 400 original series and",
    "start": "92130",
    "end": "98610"
  },
  {
    "text": "movies along with a lot of great content from a licensed content across the globe",
    "start": "98610",
    "end": "105240"
  },
  {
    "text": "all of these exciting contents are shared of a play on 1,500 internet ready",
    "start": "105240",
    "end": "113070"
  },
  {
    "text": "devices now about team media cloud",
    "start": "113070",
    "end": "118380"
  },
  {
    "start": "115000",
    "end": "142000"
  },
  {
    "text": "engineering our team is responsible handling all media processing in efflux",
    "start": "118380",
    "end": "124020"
  },
  {
    "text": "that means anything that you watch on TV it comes to our team the infrastructure",
    "start": "124020",
    "end": "130500"
  },
  {
    "text": "team in particular is responsible for build a distributed processing platform that",
    "start": "130500",
    "end": "136920"
  },
  {
    "text": "is specialized in media processing and this is what this talk is based on",
    "start": "136920",
    "end": "143060"
  },
  {
    "text": "similar to now how Netflix brings binge-watching experience to our subscribers our team's mission is simple",
    "start": "143060",
    "end": "150569"
  },
  {
    "text": "we want to bring pinch and coding to Netflix this graph was taking some time",
    "start": "150569",
    "end": "156599"
  },
  {
    "start": "153000",
    "end": "233000"
  },
  {
    "text": "ago in October over a span of two weeks and there is number of interesting",
    "start": "156599",
    "end": "161790"
  },
  {
    "text": "observations we can find in this graph first on the right side you can see that",
    "start": "161790",
    "end": "166890"
  },
  {
    "text": "with pikas 300,000 CPU hours what does that mean 300,000 CPU roughly translate",
    "start": "166890",
    "end": "175410"
  },
  {
    "text": "to about 19,000 M for 4x large machine with 16 CPU each that's 19,000 machines",
    "start": "175410",
    "end": "183480"
  },
  {
    "text": "and another interesting thing to observe is that this level of intense computing",
    "start": "183480",
    "end": "190500"
  },
  {
    "text": "only happened in four days if you see that on the Left most of the time we",
    "start": "190500",
    "end": "195810"
  },
  {
    "text": "don't use a lot of compute we probably who've around a thousand instances and what not and that shows a",
    "start": "195810",
    "end": "202350"
  },
  {
    "text": "little bit about the dynamic type of workload that we have to deal with and when it rings report and the third thing",
    "start": "202350",
    "end": "211170"
  },
  {
    "text": "I think is interesting point out that this is it happened pretty recently we have three color bands here accosted",
    "start": "211170",
    "end": "217500"
  },
  {
    "text": "three different regions it's only until Region II recently were able to do",
    "start": "217500",
    "end": "222930"
  },
  {
    "text": "encoding across three regions doing so give us a lot more capacity but also",
    "start": "222930",
    "end": "228209"
  },
  {
    "text": "brings us some new problems that we haven't followed before that we will talk about later",
    "start": "228209",
    "end": "233870"
  },
  {
    "start": "233000",
    "end": "243000"
  },
  {
    "text": "all of this was accomplished by a very talented team that we have that work",
    "start": "233870",
    "end": "238919"
  },
  {
    "text": "with every day and we have a lot of fun doing this let's talk about compute",
    "start": "238919",
    "end": "244950"
  },
  {
    "start": "243000",
    "end": "261000"
  },
  {
    "text": "capacity we saw this graph that we have 19,000 machines to me there's a lot of machines because it's a lot of money the",
    "start": "244950",
    "end": "251880"
  },
  {
    "text": "first thing we have to ask ourself is why do we need so much compute are we really just doing it because we can and",
    "start": "251880",
    "end": "258690"
  },
  {
    "text": "what the justifications for it first let's take a look at media assets",
    "start": "258690",
    "end": "264930"
  },
  {
    "start": "261000",
    "end": "325000"
  },
  {
    "text": "we have a lot of high quality media assets arrived to Netflix from a post",
    "start": "264930",
    "end": "270180"
  },
  {
    "text": "production partners in 2016 when Netflix goes global we have increased a global",
    "start": "270180",
    "end": "277860"
  },
  {
    "text": "content catalog significantly every day we see receive huge number of feature",
    "start": "277860",
    "end": "284669"
  },
  {
    "text": "content there is the movies and TV shows that we love in addition we have a lot",
    "start": "284669",
    "end": "291900"
  },
  {
    "text": "of localized content that is our language assets this is a very important",
    "start": "291900",
    "end": "299160"
  },
  {
    "text": "assets that includes audio and subtitles they are so important because this is",
    "start": "299160",
    "end": "305580"
  },
  {
    "text": "this affects the user experience for our global members finally we have a huge",
    "start": "305580",
    "end": "312750"
  },
  {
    "text": "number of supplemental materials that are used for promotional so so and in",
    "start": "312750",
    "end": "317970"
  },
  {
    "text": "general just to improve our user experience such as montage and various",
    "start": "317970",
    "end": "323910"
  },
  {
    "text": "assets so what are we including how much encode do we need let's take a look a",
    "start": "323910",
    "end": "331050"
  },
  {
    "start": "325000",
    "end": "450000"
  },
  {
    "text": "quick simple example we'll use def note as as an example how many of you have",
    "start": "331050",
    "end": "337020"
  },
  {
    "text": "watched deaf note okay not many so too",
    "start": "337020",
    "end": "342389"
  },
  {
    "text": "late to change now anyway def note is one of the Netflix",
    "start": "342389",
    "end": "348080"
  },
  {
    "text": "production that supports Toby vision so",
    "start": "348080",
    "end": "353360"
  },
  {
    "text": "we have a Toby vision TV if you want to enjoy the content there what does it take to get there obviously we apply or",
    "start": "353360",
    "end": "361009"
  },
  {
    "text": "fire up a video encoder with a copy Toby vision codec and the output will be HEV",
    "start": "361009",
    "end": "368089"
  },
  {
    "text": "C main profile maintain profile for these discussions let's focus on a",
    "start": "368089",
    "end": "374300"
  },
  {
    "text": "single bitrate 1750 variable bitrate and the source material is IMF",
    "start": "374300",
    "end": "380449"
  },
  {
    "text": "interchangeable file format which is a very high quality format so after",
    "start": "380449",
    "end": "387439"
  },
  {
    "text": "encoding we have the output trmD and ready to go to the TV simple it's",
    "start": "387439",
    "end": "394580"
  },
  {
    "text": "very simple linear process there's slight problem over here this encode",
    "start": "394580",
    "end": "402559"
  },
  {
    "text": "takes 51 hours it requires quite a bit of patience first of all and not",
    "start": "402559",
    "end": "410119"
  },
  {
    "text": "everybody here at Netflix is very patient now the second problem is that",
    "start": "410119",
    "end": "415759"
  },
  {
    "text": "sometimes bad things happened the last thing you want to see is at the 50th",
    "start": "415759",
    "end": "420829"
  },
  {
    "text": "hour then code fail what do you do what is the material comes late and we get 24",
    "start": "420829",
    "end": "427279"
  },
  {
    "text": "hours in code that won't work we trying for another 51 hours it's another pain point for this title only",
    "start": "427279",
    "end": "435550"
  },
  {
    "text": "we see the multiplier then for every second we take 30 seconds to encode for",
    "start": "435550",
    "end": "441680"
  },
  {
    "text": "this particular Cobra Kodak and this particular bitrate it changes different",
    "start": "441680",
    "end": "446930"
  },
  {
    "text": "depends on different codec period so instead of doing it linearly some small",
    "start": "446930",
    "end": "453769"
  },
  {
    "start": "450000",
    "end": "500000"
  },
  {
    "text": "people figure out how to break it up instead of encoding the entire things from from top to bottom for",
    "start": "453769",
    "end": "459589"
  },
  {
    "text": "second-to-last seconds we break it up in 30 seconds each one of them can be",
    "start": "459589",
    "end": "465259"
  },
  {
    "text": "encoded independently and all the bits and pieces of the outputs finally glue",
    "start": "465259",
    "end": "470659"
  },
  {
    "text": "together and form the final output and the rest of the pipeline looks exactly the same",
    "start": "470659",
    "end": "476269"
  },
  {
    "text": "do you know what changes it makes with this organization we change it from 51 hours to 15 minutes so with this",
    "start": "476269",
    "end": "485509"
  },
  {
    "text": "little change is great assuming that you have enough capacities to do all 200 and",
    "start": "485509",
    "end": "491360"
  },
  {
    "text": "code at the same time so this is one of the reasons why we need a lot of capacity so that we can be very Swift",
    "start": "491360",
    "end": "497120"
  },
  {
    "text": "very agile but this is just for one one single bit rate and one single profile",
    "start": "497120",
    "end": "504319"
  },
  {
    "start": "500000",
    "end": "518000"
  },
  {
    "text": "in order to satisfy all 1500 types of Netflix ready devices we support a lot",
    "start": "504319",
    "end": "510949"
  },
  {
    "text": "of different codec a lot of different profiles and four different bandwidth we",
    "start": "510949",
    "end": "516919"
  },
  {
    "text": "also support a bit rail error so in what in reality when we receive a single title we do a bunch of stuff there and",
    "start": "516919",
    "end": "524680"
  },
  {
    "start": "518000",
    "end": "535000"
  },
  {
    "text": "that requires a lot of computer pasady this is just one title so if it's not",
    "start": "524680",
    "end": "532640"
  },
  {
    "text": "deaf no story some other some other favorite shows that you may like and in practice we often time receive a lot of",
    "start": "532640",
    "end": "539089"
  },
  {
    "start": "535000",
    "end": "571000"
  },
  {
    "text": "different titles at the same time if it's a TV show we may receive entire",
    "start": "539089",
    "end": "544190"
  },
  {
    "text": "season and sometimes you get lucky we make it multiple season to arrive at a",
    "start": "544190",
    "end": "549529"
  },
  {
    "text": "doorstep and this is the reasons why when it rings your pores and when we",
    "start": "549529",
    "end": "555920"
  },
  {
    "text": "receive the material we want to be able to encode them as fast as we can now we",
    "start": "555920",
    "end": "565550"
  },
  {
    "text": "have a simple formula many or many it's many many and this is what we do so far",
    "start": "565550",
    "end": "572720"
  },
  {
    "start": "571000",
    "end": "689000"
  },
  {
    "text": "we talk about what we do for production so from the source material all the way",
    "start": "572720",
    "end": "578990"
  },
  {
    "text": "to your your favorite paper device a TV or your phone we haven't talked about",
    "start": "578990",
    "end": "584029"
  },
  {
    "text": "research and development in the world of encoding there's a very fast change it's",
    "start": "584029",
    "end": "590450"
  },
  {
    "text": "very fast change pace we always have new coder new profile and we have h TVC HDR",
    "start": "590450",
    "end": "596899"
  },
  {
    "text": "double vision we have VP knife or a mobile mobile outputs very very for high",
    "start": "596899",
    "end": "603320"
  },
  {
    "text": "compressions and the great quality and most recently we engaging a lot of research and development of eb1 code",
    "start": "603320",
    "end": "611089"
  },
  {
    "text": "all that requires a lot of iterative process to encode assess and reassess",
    "start": "611089",
    "end": "619110"
  },
  {
    "text": "and Riaan code to the point where we think the final output is of a quality that our members will enjoy that takes a",
    "start": "619110",
    "end": "626910"
  },
  {
    "text": "lot of research and development and compute capacities in terms of innovations our very talented video",
    "start": "626910",
    "end": "634560"
  },
  {
    "text": "algorithm algorithm team came up with what we call vmf perceptual visual",
    "start": "634560",
    "end": "639899"
  },
  {
    "text": "quality in addition to psnr we use this in depth to evaluate the encode to",
    "start": "639899",
    "end": "647220"
  },
  {
    "text": "figure out what is the perceptual quality in a very consistent manner and",
    "start": "647220",
    "end": "654380"
  },
  {
    "text": "with this we were able to detect any degradation of a video encode or any",
    "start": "654380",
    "end": "659700"
  },
  {
    "text": "improvement it is based on this tool we can evolve recently and do the dynamic",
    "start": "659700",
    "end": "666060"
  },
  {
    "text": "optimization we're able to do video compressions on per shot basis given the",
    "start": "666060",
    "end": "674339"
  },
  {
    "text": "premise that within the same shot the pictures are alike and then can find an optimal curve and optimal path to",
    "start": "674339",
    "end": "681089"
  },
  {
    "text": "find the right resolutions the right bitrate and various additional parameters and you will find the perfect",
    "start": "681089",
    "end": "686579"
  },
  {
    "text": "one based on the remap so we talked about video audio subtitles what we",
    "start": "686579",
    "end": "693510"
  },
  {
    "start": "689000",
    "end": "706000"
  },
  {
    "text": "think about media that this is what we're familiar with that means we have three types of services maybe it would",
    "start": "693510",
    "end": "701190"
  },
  {
    "text": "not be very simple well what you're",
    "start": "701190",
    "end": "707220"
  },
  {
    "text": "seeing here is the actual number of media processors that we have at Netflix",
    "start": "707220",
    "end": "713959"
  },
  {
    "text": "we mentioned that we can do chunk encode obviously you have to have something to",
    "start": "713959",
    "end": "720029"
  },
  {
    "text": "put it back together so I have a video assembler now we can encode the video we",
    "start": "720029",
    "end": "725670"
  },
  {
    "text": "can also run the video as asset inspector when to answer the inspection to verify that the source material that",
    "start": "725670",
    "end": "732899"
  },
  {
    "text": "we receive from a post-production partner is of the Netflix quality we can",
    "start": "732899",
    "end": "738540"
  },
  {
    "text": "do video complex complexity and allows analysis so that you can do potato",
    "start": "738540",
    "end": "744280"
  },
  {
    "text": "encode so our bitrate ladder could be different for each title based on the complexity",
    "start": "744280",
    "end": "749500"
  },
  {
    "text": "or title so if you have animations we may save a lot of bits because having more bits on it",
    "start": "749500",
    "end": "755200"
  },
  {
    "text": "may not make any difference and if we",
    "start": "755200",
    "end": "762040"
  },
  {
    "text": "put all of this together and put it into one unique environment that is the",
    "start": "762040",
    "end": "769000"
  },
  {
    "text": "Netflix encoding services in a box now this is all great for production value",
    "start": "769000",
    "end": "778890"
  },
  {
    "text": "but we also need to do development previously you mention about research and development experiments and we also",
    "start": "778890",
    "end": "786400"
  },
  {
    "text": "need to do testing we do weekly regressions we need to figure out what are their stack rotations between change",
    "start": "786400",
    "end": "791710"
  },
  {
    "text": "of the video codec or algorithms or recipes so what we actually do is that",
    "start": "791710",
    "end": "798520"
  },
  {
    "text": "we wrap all these services together into I get a picture of marbles so so just",
    "start": "798520",
    "end": "807220"
  },
  {
    "text": "imagine that each one of them is a unique environment that they're isolated they don't interfere with each other",
    "start": "807220",
    "end": "813690"
  },
  {
    "text": "anybody who's got a copy of this have full freedom to mess of it you can do",
    "start": "813690",
    "end": "819370"
  },
  {
    "text": "encode try new Kodak write a new media processor without worrying about",
    "start": "819370",
    "end": "824380"
  },
  {
    "text": "affecting production and before you know we have 70 of those we use of production",
    "start": "824380",
    "end": "829900"
  },
  {
    "text": "in canary a be testing this is a special kind of production where we have limited",
    "start": "829900",
    "end": "835360"
  },
  {
    "text": "release of a particular video algorithm and then we do assessments on that the",
    "start": "835360",
    "end": "841930"
  },
  {
    "text": "development of uses the majority of the farms that every engineer get a few",
    "start": "841930",
    "end": "848850"
  },
  {
    "text": "farms they can do full experiment on so",
    "start": "848850",
    "end": "853860"
  },
  {
    "text": "how do we scale the clock this talk is based on the current FX media processing",
    "start": "853860",
    "end": "860740"
  },
  {
    "start": "857000",
    "end": "881000"
  },
  {
    "text": "platform that we built and that was we have a code name how we loaded that's",
    "start": "860740",
    "end": "866350"
  },
  {
    "text": "why you see the picture here it is a third-generation of the platform that",
    "start": "866350",
    "end": "871420"
  },
  {
    "text": "was the post since 2013 and it's completely cloud based and most recently were able to encode across",
    "start": "871420",
    "end": "878470"
  },
  {
    "text": "multiple regions I have a simplified architecture here because I don't want",
    "start": "878470",
    "end": "883870"
  },
  {
    "start": "881000",
    "end": "894000"
  },
  {
    "text": "to bore you too much they're so simple that were fitting a single piece of paper napkin it is based on two very",
    "start": "883870",
    "end": "890440"
  },
  {
    "text": "common pattern that we are all familiar with the first is microservice we all",
    "start": "890440",
    "end": "897220"
  },
  {
    "start": "894000",
    "end": "934000"
  },
  {
    "text": "heard about that it is a great way to build surfaces and as you can imagine a",
    "start": "897220",
    "end": "903430"
  },
  {
    "text": "video in color is a micro surface it is single purpose doesn't do anything else",
    "start": "903430",
    "end": "908890"
  },
  {
    "text": "all right Justin would know how to do audio and code it is decoupled and it's",
    "start": "908890",
    "end": "915850"
  },
  {
    "text": "stateless being statelessness is a very important aspect of micro service in",
    "start": "915850",
    "end": "921310"
  },
  {
    "text": "such a way in terms of scaling we can scale up and scale down instances without worrying about any history and",
    "start": "921310",
    "end": "927430"
  },
  {
    "text": "in memory losing losing affecting one another so this is a very important",
    "start": "927430",
    "end": "932590"
  },
  {
    "text": "thing the next things is message oriented if it's good it well with a work pattern because we don't have a",
    "start": "932590",
    "end": "938710"
  },
  {
    "start": "934000",
    "end": "986000"
  },
  {
    "text": "steady stream to work all the time work is always event-driven it is not uncommon to have some services that have",
    "start": "938710",
    "end": "945790"
  },
  {
    "text": "no work and certainly you get millions of jobs in moments notice it is",
    "start": "945790",
    "end": "951400"
  },
  {
    "text": "asynchronous what I don't show you is that we have a workflow engine that",
    "start": "951400",
    "end": "957760"
  },
  {
    "text": "would just it will figure out what jobs need to be produced and it is very easy",
    "start": "957760",
    "end": "963100"
  },
  {
    "text": "for the workflow engine to pump down millions of jobs without being tied up because sending a job does not mean the",
    "start": "963100",
    "end": "970540"
  },
  {
    "text": "job will be run immediately job there's a little different about what we do with",
    "start": "970540",
    "end": "976990"
  },
  {
    "text": "message and cue in this case we have a priority queue we will go into a little bit later why priority queue marriage",
    "start": "976990",
    "end": "986759"
  },
  {
    "text": "scalability we are all about scale and this talks about scalable scalability according to this definition scalability",
    "start": "986940",
    "end": "993850"
  },
  {
    "text": "is ability to scale up and scale down changes in sizing includes both we",
    "start": "993850",
    "end": "999010"
  },
  {
    "text": "wouldn't need to have a way to do this elastically so in the previous example in the slide we saw that we get up to 19",
    "start": "999010",
    "end": "1006220"
  },
  {
    "start": "1006000",
    "end": "1036000"
  },
  {
    "text": "in census in order to achieve that which depends on Amazon Web Services but use",
    "start": "1006220",
    "end": "1012790"
  },
  {
    "text": "easy to coupled with other scaring groups to handle all of our encoder and",
    "start": "1012790",
    "end": "1017920"
  },
  {
    "text": "media processors and three is a persistent storage that we can use for",
    "start": "1017920",
    "end": "1023140"
  },
  {
    "text": "stick for security and durability for all input and outputs are all on s3 I",
    "start": "1023140",
    "end": "1030480"
  },
  {
    "text": "forgot to mention Aurora we use a row as a way to implement our priority queue so",
    "start": "1030480",
    "end": "1037449"
  },
  {
    "start": "1036000",
    "end": "1071000"
  },
  {
    "text": "this is a screen shot of our auto scaling groups using our internal tools spinnaker is also open source project",
    "start": "1037450",
    "end": "1044110"
  },
  {
    "text": "and in this picture you can see that we have fifty thousand thousand instances",
    "start": "1044110",
    "end": "1049690"
  },
  {
    "text": "across multiple aSG's they have all video encoder running in a farm on USGS",
    "start": "1049690",
    "end": "1056380"
  },
  {
    "text": "we use vinegar because spinnaker gives us a distraction allow us to have the",
    "start": "1056380",
    "end": "1061450"
  },
  {
    "text": "notions of an application that maps would it well with micro service I don't have to come up with my own scheme of",
    "start": "1061450",
    "end": "1067270"
  },
  {
    "text": "naming ASG name it's being heard kind of takes care of that the next example is",
    "start": "1067270",
    "end": "1072670"
  },
  {
    "start": "1071000",
    "end": "1086000"
  },
  {
    "text": "to show how the dolby vision encoders give up over a period of time in this",
    "start": "1072670",
    "end": "1078400"
  },
  {
    "text": "case i think it's about twelve hours and the video encoder and they scale independently now we talked about AWS",
    "start": "1078400",
    "end": "1088120"
  },
  {
    "text": "and we have all the scaling groups and we have micro services that map's woody",
    "start": "1088120",
    "end": "1094180"
  },
  {
    "text": "well worth all the scaling groups so is this a simple s just filling up and will",
    "start": "1094180",
    "end": "1100000"
  },
  {
    "text": "be will apply a all extinct group scaling policy and we all go home and because we're done well I would like",
    "start": "1100000",
    "end": "1108520"
  },
  {
    "text": "that the case but it's actually it'll be more complicated because of our unique environment let's start with how we map",
    "start": "1108520",
    "end": "1115750"
  },
  {
    "text": "all the scaling group and micro services to a SGS this is how we were a vision we have",
    "start": "1115750",
    "end": "1122140"
  },
  {
    "text": "each one of this ASG filling up with instances and these are all micro services and this is a picture that it's",
    "start": "1122140",
    "end": "1129520"
  },
  {
    "text": "very easy to understand however because the work is dynamic we would like to",
    "start": "1129520",
    "end": "1137680"
  },
  {
    "text": "ideally scale of each of the ASG based on amount of work we have in each of the",
    "start": "1137680",
    "end": "1143890"
  },
  {
    "text": "individual queue in this case you can see that video encoder has a bigger queue and it would need more instances",
    "start": "1143890",
    "end": "1151090"
  },
  {
    "text": "to finish his work in a timely manner we know that ec2 is incredibly elastic",
    "start": "1151090",
    "end": "1160140"
  },
  {
    "text": "but we also know that we live in the world of East easy reservations for",
    "start": "1160140",
    "end": "1167110"
  },
  {
    "text": "economy most of us purchase the easier is easy to reservations and because it",
    "start": "1167110",
    "end": "1173380"
  },
  {
    "text": "saves us more money then fix worth of reservations is the same we do monthly evaluation we make more purchases but at",
    "start": "1173380",
    "end": "1180280"
  },
  {
    "text": "the end of the day at any moment we have a pretty stable amount of reservations that we want to observe in this example",
    "start": "1180280",
    "end": "1187870"
  },
  {
    "text": "for you we see that we have 10 instances and let's pretend for the moment that",
    "start": "1187870",
    "end": "1193600"
  },
  {
    "text": "entire Netflix has the reservations of 10 machines we use them all up and we",
    "start": "1193600",
    "end": "1199900"
  },
  {
    "text": "notice that the audio encoder increased in queue size now what do we do if we",
    "start": "1199900",
    "end": "1206020"
  },
  {
    "text": "simply scaled order encoder with a scaling policy then we will go over our",
    "start": "1206020",
    "end": "1211450"
  },
  {
    "text": "reservation and were people on demand a little bit small percentage of on-demand",
    "start": "1211450",
    "end": "1216670"
  },
  {
    "text": "is okay but if we consistently use this in an in constraint manner and it will",
    "start": "1216670",
    "end": "1221890"
  },
  {
    "text": "catch up on you so what we really want to do is to respect our reservation so",
    "start": "1221890",
    "end": "1229179"
  },
  {
    "text": "that we don't scale up more than what we are we own and also ideally we want to",
    "start": "1229179",
    "end": "1235420"
  },
  {
    "text": "be able share our instances are crossed and distributed evenly and fairly at the",
    "start": "1235420",
    "end": "1241270"
  },
  {
    "text": "same time try to maintain the reservation stop being overused the next",
    "start": "1241270",
    "end": "1248890"
  },
  {
    "text": "example is a little bit unique to us so how many of you have watched Star Trek",
    "start": "1248890",
    "end": "1256050"
  },
  {
    "text": "the most recent Star Trek discovery right how many of you are",
    "start": "1256050",
    "end": "1261100"
  },
  {
    "text": "aware that Netflix also have a ask attract show okay so the stature of a",
    "start": "1261100",
    "end": "1267610"
  },
  {
    "text": "show show is broadcast pretty much an hour immediately after the",
    "start": "1267610",
    "end": "1272820"
  },
  {
    "text": "the Sasha show and we have a very small window that we need to encode everything within 30 minutes so that the language",
    "start": "1272820",
    "end": "1279900"
  },
  {
    "text": "translator across the world can do subtitle translation so we have such a",
    "start": "1279900",
    "end": "1285120"
  },
  {
    "text": "tight window so what happened if our video encoder has a lot of work and we",
    "start": "1285120",
    "end": "1291570"
  },
  {
    "text": "need to be able to do the most important thing first and in this case we may have",
    "start": "1291570",
    "end": "1296760"
  },
  {
    "text": "just a few messages in deep color that those are high priority messages and",
    "start": "1296760",
    "end": "1302910"
  },
  {
    "text": "then in this case we have audio encoder having a lot of more high quality",
    "start": "1302910",
    "end": "1308070"
  },
  {
    "text": "message than video encoder we won't be able to ideally spam put more instances",
    "start": "1308070",
    "end": "1313290"
  },
  {
    "text": "in the audio and colder than the video encoder because the number of hypotheses exceeds the video encoder so in essence",
    "start": "1313290",
    "end": "1325710"
  },
  {
    "text": "we want to balance our resources not only based on the size of the queue but also based on the priority in it and the",
    "start": "1325710",
    "end": "1335310"
  },
  {
    "start": "1333000",
    "end": "1410000"
  },
  {
    "text": "next things about is with I like to talk about is rebalancing instances so I mentioned that in the worst case in the",
    "start": "1335310",
    "end": "1342480"
  },
  {
    "text": "PV example we could spend 51 hours but we don't and a video encoder can spend",
    "start": "1342480",
    "end": "1349170"
  },
  {
    "text": "from 30 minutes and for certain coda and bitrate you could go all the way up in an hour so we want to be balanced the",
    "start": "1349170",
    "end": "1356010"
  },
  {
    "text": "instances we really don't want to lose any work that is in progress so if we simply scale down ASG and you have a",
    "start": "1356010",
    "end": "1363750"
  },
  {
    "text": "chance of randomly killing and any particular instance and if you're",
    "start": "1363750",
    "end": "1368760"
  },
  {
    "text": "unlucky you will kill video encoder in case v1 the color bar shows the amount",
    "start": "1368760",
    "end": "1374310"
  },
  {
    "text": "of progress that has been made in this case it's almost finished and it will be ashamed this is the one that get picked",
    "start": "1374310",
    "end": "1380190"
  },
  {
    "text": "up but you don't have all our choices so that means we can't really just use a",
    "start": "1380190",
    "end": "1385710"
  },
  {
    "text": "simple scaling algorithm just to strengthen ASG and there are some ways",
    "start": "1385710",
    "end": "1391590"
  },
  {
    "text": "to mitigate it for example we can we can save work in progress with some kind of checkpoint but that's not possible for a",
    "start": "1391590",
    "end": "1398190"
  },
  {
    "text": "lot of type a lot of media processors so the conclusion is that terminations",
    "start": "1398190",
    "end": "1406390"
  },
  {
    "text": "of in-flight jobs can be expensive we want to avoid that if possible putting it all together we want to be able to",
    "start": "1406390",
    "end": "1413610"
  },
  {
    "start": "1410000",
    "end": "1435000"
  },
  {
    "text": "share all the instances and resources across all the farms remember we have",
    "start": "1413610",
    "end": "1421270"
  },
  {
    "text": "about 70 farms each one of them has a bunch of aSG's in it and often time will be of service that",
    "start": "1421270",
    "end": "1427720"
  },
  {
    "text": "our demand exceeds supply supply and we won't do it fairly as if this is not",
    "start": "1427720",
    "end": "1437049"
  },
  {
    "start": "1435000",
    "end": "1445000"
  },
  {
    "text": "enough of a problem we have some additional constraints we have capacity fluctuations while the Netflix has a",
    "start": "1437049",
    "end": "1445799"
  },
  {
    "start": "1445000",
    "end": "1499000"
  },
  {
    "text": "fixed number of reservations at the moment but the number of instances that we can use depends on what's available",
    "start": "1445799",
    "end": "1453270"
  },
  {
    "text": "what is in use so for example for the rest of the Netflix we have API services",
    "start": "1453270",
    "end": "1459190"
  },
  {
    "text": "that are directly title and user experience and playback experience and the last thing we what happen is that",
    "start": "1459190",
    "end": "1465309"
  },
  {
    "text": "we're doing some encode that would causes rebuffering on some players so we",
    "start": "1465309",
    "end": "1470740"
  },
  {
    "text": "give us out the lowest priority it can't we constantly observe and figure out whether we are in",
    "start": "1470740",
    "end": "1476290"
  },
  {
    "text": "competitions with the rest of the network services and we want to yield when that happens that means the capacity fluctuates over",
    "start": "1476290",
    "end": "1482679"
  },
  {
    "text": "time we also have a lot of different instance types and in order to make full",
    "start": "1482679",
    "end": "1488770"
  },
  {
    "text": "utilized orders of capacity we need to be adapt adaptive we have to be able to",
    "start": "1488770",
    "end": "1495370"
  },
  {
    "text": "teach our micro services to be able use different instance ID so we'll figure out how we approach that now we have a",
    "start": "1495370",
    "end": "1503620"
  },
  {
    "text": "revisions of how we look at a farm in this case a video encoder is not made up",
    "start": "1503620",
    "end": "1508660"
  },
  {
    "text": "of one single ASG based on what we just saw we have different instance types and",
    "start": "1508660",
    "end": "1513760"
  },
  {
    "text": "because the majority of our reservations are solo some combinations of regional",
    "start": "1513760",
    "end": "1518919"
  },
  {
    "text": "reservations we have to observe our reservations by zone so if you look at",
    "start": "1518919",
    "end": "1524620"
  },
  {
    "text": "video encoder here we may have a number of aSG's tied to a Patek",
    "start": "1524620",
    "end": "1530210"
  },
  {
    "text": "song and particular instance type and those are complexity that we're dealing with just checking if you're paying",
    "start": "1530210",
    "end": "1539299"
  },
  {
    "start": "1536000",
    "end": "1546000"
  },
  {
    "text": "attention and if you're looking the remote it's right here it's caring",
    "start": "1539299",
    "end": "1545390"
  },
  {
    "text": "strategy so how do we do that the way we talked about how we approached the",
    "start": "1545390",
    "end": "1551720"
  },
  {
    "start": "1546000",
    "end": "1750000"
  },
  {
    "text": "scaling problem well we won't have a system that observed the weight of the",
    "start": "1551720",
    "end": "1556850"
  },
  {
    "text": "job for example if for some micro-services if this is in production it would Trump",
    "start": "1556850",
    "end": "1562070"
  },
  {
    "text": "anything does it could be an experiment or our testing phase and we want to",
    "start": "1562070",
    "end": "1567860"
  },
  {
    "text": "assign instances also based on the job pressure so even if you have a lot of job in particular q obviously you want",
    "start": "1567860",
    "end": "1574460"
  },
  {
    "text": "you have a higher pressure you want to get more resources assigned to it but at",
    "start": "1574460",
    "end": "1579740"
  },
  {
    "text": "the same time we want to account for priority higher party jobs would we have",
    "start": "1579740",
    "end": "1586370"
  },
  {
    "text": "higher weight and finally we as we mentioned before because we don't want",
    "start": "1586370",
    "end": "1592400"
  },
  {
    "text": "to lose any work in progress all of this has to be done gently and we need to reel orchestrate and it scaling up and",
    "start": "1592400",
    "end": "1598280"
  },
  {
    "text": "scaling down scale-up is easy if you have enough resources but you don't you have to wait until one of the",
    "start": "1598280",
    "end": "1604429"
  },
  {
    "text": "applications yields the instances before you can scale up and all of that is done in a cycle continuously so we you know",
    "start": "1604429",
    "end": "1612080"
  },
  {
    "text": "every cycle we look at what we really want individually across the entire farm",
    "start": "1612080",
    "end": "1617380"
  },
  {
    "text": "and we have to look at what we have based on the ever changing amount of capacity apply the Delta and then try to",
    "start": "1617380",
    "end": "1626330"
  },
  {
    "text": "remediate it and we do it continuously this is a picture I found of a heartbeat",
    "start": "1626330",
    "end": "1634580"
  },
  {
    "text": "and I'm imagining that this is a a healthy person's heartbeat this is great",
    "start": "1634580",
    "end": "1642350"
  },
  {
    "text": "for a person but in terms of scaling is actually pretty bad because if you if",
    "start": "1642350",
    "end": "1647720"
  },
  {
    "text": "you notice this if you scare in this pattern we're end up spending more time scaling than computing and that's not",
    "start": "1647720",
    "end": "1655250"
  },
  {
    "text": "what we want to go so in computing we want to spend we want to be smooth for once going to",
    "start": "1655250",
    "end": "1661260"
  },
  {
    "text": "be smooth and stable it's a delicate balance how do we do that if we scale",
    "start": "1661260",
    "end": "1670830"
  },
  {
    "text": "very quickly in this in this example and we run the danger of overshooting how do",
    "start": "1670830",
    "end": "1678720"
  },
  {
    "text": "we know how much how many we don't encode out do we need the Whitney 8000 do we need 1200 that's a very difficult",
    "start": "1678720",
    "end": "1686130"
  },
  {
    "text": "question to ask and if you make a mistake you could easily over scale and",
    "start": "1686130",
    "end": "1692250"
  },
  {
    "text": "then regret later and you and then you shrink and then you may end up",
    "start": "1692250",
    "end": "1697520"
  },
  {
    "text": "overcompensating then you've spent most of the time just getting up and spinning up and spin down instances that we",
    "start": "1697520",
    "end": "1703200"
  },
  {
    "text": "approach it the way we approaches is that instead of using a crystal ball to figure out how many instances we need we",
    "start": "1703200",
    "end": "1709980"
  },
  {
    "text": "use a smaller crystal ball to say what we think this is how much we need but we're not quite sure but we're not going",
    "start": "1709980",
    "end": "1715980"
  },
  {
    "text": "to take everything we just say for example we will do a percentage of it maybe we just scale up or scale down by",
    "start": "1715980",
    "end": "1721920"
  },
  {
    "text": "10% or what we think we need and then come back later in terminus to look to see hey if",
    "start": "1721920",
    "end": "1728340"
  },
  {
    "text": "anything changes is helping do we need more so being incremental woody",
    "start": "1728340",
    "end": "1733830"
  },
  {
    "text": "alleviate and help us to be able to scale more accurately instead in fact",
    "start": "1733830",
    "end": "1739800"
  },
  {
    "text": "and not having having to be overly precise so this is a very difficult game",
    "start": "1739800",
    "end": "1746310"
  },
  {
    "text": "to be able to scale up and down in a delicate balance so putting it all",
    "start": "1746310",
    "end": "1752760"
  },
  {
    "text": "together if you imagine we have 70 70 different forms each one of them has 40 some type",
    "start": "1752760",
    "end": "1759180"
  },
  {
    "text": "of pedia processors across three regions we build our own custom autoscaler",
    "start": "1759180",
    "end": "1765390"
  },
  {
    "start": "1762000",
    "end": "1770000"
  },
  {
    "text": "that understand all of this we call it the world and then what this scaler does",
    "start": "1765390",
    "end": "1773120"
  },
  {
    "text": "is that it would maintain the deployment deployment model understand what's been",
    "start": "1773120",
    "end": "1778170"
  },
  {
    "text": "deployed and has a resource monitor that continually figure out how many how many",
    "start": "1778170",
    "end": "1783960"
  },
  {
    "text": "wish was available for our including needs are we overspending because the via overspend will also shrink and we'll",
    "start": "1783960",
    "end": "1791550"
  },
  {
    "text": "scale down and then of course we have the cue martyr we also call it the barometer that looks at every cue for every micro",
    "start": "1791550",
    "end": "1799620"
  },
  {
    "text": "service in every farm I would maintain that you know to the help us and guide us in to figure out how much resources",
    "start": "1799620",
    "end": "1806820"
  },
  {
    "text": "are needed and all of these informations are fed into the planner we have a planet that makes plan every 10 minutes",
    "start": "1806820",
    "end": "1813200"
  },
  {
    "start": "1813000",
    "end": "1844000"
  },
  {
    "text": "because we believe that things changes in 10 minutes and and and the plans that",
    "start": "1813200",
    "end": "1818790"
  },
  {
    "text": "are made are realized by the Obscure and down scaler for any scaling operations",
    "start": "1818790",
    "end": "1824670"
  },
  {
    "text": "that cannot be done immediately we have an Orchestrator to figure out how to wind down an instance and when it",
    "start": "1824670",
    "end": "1831990"
  },
  {
    "text": "finally goes away or wind up another instance in a different in a different micro surface so you know just this is",
    "start": "1831990",
    "end": "1840060"
  },
  {
    "text": "what we have the next problem we want to solve is different instance type our",
    "start": "1840060",
    "end": "1846000"
  },
  {
    "start": "1844000",
    "end": "1877000"
  },
  {
    "text": "goal is very simple when we get in instance when we know what's available",
    "start": "1846000",
    "end": "1851490"
  },
  {
    "text": "there we want to use anything is possible and we were used as many instance type as possible and not having",
    "start": "1851490",
    "end": "1857760"
  },
  {
    "text": "to leave too many things on a table when we can actually use them but when we do have an instance we want to make maximum",
    "start": "1857760",
    "end": "1863970"
  },
  {
    "text": "use of it obviously if you landed on m416 excel machine with 64 cpu and then",
    "start": "1863970",
    "end": "1871830"
  },
  {
    "text": "you end up spending just 10% CPU utilization they were big waste we don't",
    "start": "1871830",
    "end": "1876840"
  },
  {
    "text": "want to have to happen how do we do that there a couple of projects you can be",
    "start": "1876840",
    "end": "1881850"
  },
  {
    "start": "1877000",
    "end": "2008000"
  },
  {
    "text": "very very precise you can match a particular instance type to a particular type of micro surface and have a perfect",
    "start": "1881850",
    "end": "1888630"
  },
  {
    "text": "match but the problem is asking an engineer to figure out which machine type to run for it for each micro surface it's very",
    "start": "1888630",
    "end": "1895680"
  },
  {
    "text": "difficult and because I try to up how much memory I need I don't know because",
    "start": "1895680",
    "end": "1902850"
  },
  {
    "text": "anything that officer from the moment may be wrong or maybe I just don't have the right amount of data to come in that",
    "start": "1902850",
    "end": "1908100"
  },
  {
    "text": "hits the worst-case scenario and if I do make a bit of estimation it can get",
    "start": "1908100",
    "end": "1913440"
  },
  {
    "text": "stale decay over time to be wrong the next month so what do we do you usually",
    "start": "1913440",
    "end": "1920810"
  },
  {
    "text": "you know overestimate just to be safe and that resolves very low",
    "start": "1920810",
    "end": "1926310"
  },
  {
    "text": "CP utilization and and there goes the efficiency finally it's very complicated",
    "start": "1926310",
    "end": "1932160"
  },
  {
    "text": "imp in this you know if you have the autoscaler trying to find a mix-and-match of many many different instance type across 40",
    "start": "1932160",
    "end": "1939000"
  },
  {
    "text": "or 100 different microprocessor it's a very difficult problem to solve so",
    "start": "1939000",
    "end": "1944220"
  },
  {
    "text": "instead what we do is we try to treat the instance type generically and let's",
    "start": "1944220",
    "end": "1950130"
  },
  {
    "text": "leave aside for the moment that all our three and our four has a lot of memory let's not solve the problem for the",
    "start": "1950130",
    "end": "1956010"
  },
  {
    "text": "moment we teach each of the micro service to self inflate given the",
    "start": "1956010",
    "end": "1961890"
  },
  {
    "text": "particular instance type we just figure out the best way to maximize the CPU utilization by doing so we have a very",
    "start": "1961890",
    "end": "1970290"
  },
  {
    "text": "nice side effect of oversubscription now we no longer have to plan for the",
    "start": "1970290",
    "end": "1976440"
  },
  {
    "text": "peak utilization we can actually nudge the ball a little lower hoping for the best that you don't hit the worst case",
    "start": "1976440",
    "end": "1982590"
  },
  {
    "text": "scenario for F is concurrent session and if you do we are able to recover from it",
    "start": "1982590",
    "end": "1989580"
  },
  {
    "text": "because jobs are resilient so only if you can incredibly unlucky that you run",
    "start": "1989580",
    "end": "1995340"
  },
  {
    "text": "everything at the same time in a single instance and every one of those discussions means worst case scenario",
    "start": "1995340",
    "end": "2000650"
  },
  {
    "text": "that doesn't really happen in real life and because of all this arrangement now",
    "start": "2000650",
    "end": "2006770"
  },
  {
    "text": "our estimation can be a little fuzzy so let's look at video and code as an example in this case we landed an m3",
    "start": "2006770",
    "end": "2014680"
  },
  {
    "start": "2008000",
    "end": "2031000"
  },
  {
    "text": "extra-extra-large instance we've run a single session in it but if we get a bigger box we'll run for and if you're",
    "start": "2014680",
    "end": "2022040"
  },
  {
    "text": "more ambitions we may run five just to see what happened so give us a lot of",
    "start": "2022040",
    "end": "2027170"
  },
  {
    "text": "room to tune it and this is what I mean by oversubscription so so far we talked about how we",
    "start": "2027170",
    "end": "2034940"
  },
  {
    "start": "2031000",
    "end": "2051000"
  },
  {
    "text": "approached it one of our lessons learned I would like to think that we all sit",
    "start": "2034940",
    "end": "2042500"
  },
  {
    "text": "down and follow everything and follow fresh solutions at the beginning but",
    "start": "2042500",
    "end": "2048440"
  },
  {
    "text": "that's not the case in fact we learn a lot of things that based on based on",
    "start": "2048440",
    "end": "2054080"
  },
  {
    "start": "2051000",
    "end": "2115000"
  },
  {
    "text": "what didn't work so if there's an it one thing that I think I like our audience to get out",
    "start": "2054080",
    "end": "2059360"
  },
  {
    "text": "this room is that when you do something that scales very large you have to be very concerned about the efficiency",
    "start": "2059360",
    "end": "2066340"
  },
  {
    "text": "about your API calls for example if I make an ad based call s3 call should it",
    "start": "2066340",
    "end": "2074120"
  },
  {
    "text": "be one call so they be to call can it be combined every little bit of an invasion",
    "start": "2074120",
    "end": "2079610"
  },
  {
    "text": "inefficiency may not be revealed when you run several hundred instances but we start going to the thousands then",
    "start": "2079610",
    "end": "2086060"
  },
  {
    "text": "suddenly you will noticed it sometimes is you know you get throttles you know",
    "start": "2086060",
    "end": "2091790"
  },
  {
    "text": "it's your it's your every extra key properly hashed in such a way that you don't create hot spots you may not",
    "start": "2091790",
    "end": "2098660"
  },
  {
    "text": "notice that when you run a very small amount of scale but when you scale up and you will notice it right away cause",
    "start": "2098660",
    "end": "2104750"
  },
  {
    "text": "wise is the same if you a little bit inefficiency about cost you may not",
    "start": "2104750",
    "end": "2110330"
  },
  {
    "text": "notice it until you start running tens of thousands and instances and and it will show you so let me give you a",
    "start": "2110330",
    "end": "2115910"
  },
  {
    "text": "couple of examples where I learned our encoding has been we have been doing",
    "start": "2115910",
    "end": "2121220"
  },
  {
    "text": "encoding in US East one for the last few years all our assets are stolen s3 in US",
    "start": "2121220",
    "end": "2128570"
  },
  {
    "text": "East one and we pre used to just grabbing the resources reading and",
    "start": "2128570",
    "end": "2134150"
  },
  {
    "text": "writing to the s3 buckets in the same regions and and those it was easy there was never a problem but when we start",
    "start": "2134150",
    "end": "2141110"
  },
  {
    "text": "going to do two additional other regions we thought we'd just cookie cut it and",
    "start": "2141110",
    "end": "2147770"
  },
  {
    "text": "we did notice that because you know half a cent for gigabyte and didn't that",
    "start": "2147770",
    "end": "2155090"
  },
  {
    "text": "didn't feel like a big deal for us at a time because based on our observations and the amount the cost was reasonable",
    "start": "2155090",
    "end": "2163190"
  },
  {
    "text": "but what we fail to realize was that the recent change of the per shot and",
    "start": "2163190",
    "end": "2168620"
  },
  {
    "text": "holding that changes entire access pattern so we received quite a shocker when we finally get a bill and we look",
    "start": "2168620",
    "end": "2176060"
  },
  {
    "text": "at it and thought oh I wish I thought of that but because we're able to tune down",
    "start": "2176060",
    "end": "2181490"
  },
  {
    "text": "and and and shut off the two additional regions until we find a fix we're able",
    "start": "2181490",
    "end": "2187100"
  },
  {
    "text": "to find a solution the way we access our data our files on us",
    "start": "2187100",
    "end": "2193280"
  },
  {
    "text": "is to a file system that we implement and we're able to use the regional filed hash that by putting a file cache we",
    "start": "2193280",
    "end": "2201440"
  },
  {
    "text": "store a block as 16 mega byte blocks every on the range cat would put it up there and for any subsequent you know",
    "start": "2201440",
    "end": "2209690"
  },
  {
    "text": "repeater access at the same block will fetch from the region which in a bucket this very simple change was done by you",
    "start": "2209690",
    "end": "2216770"
  },
  {
    "text": "know a couple of threes very smart engineers in about a week and we immediately we observe that we gained",
    "start": "2216770",
    "end": "2225100"
  },
  {
    "text": "ninety percent hit cache hit that means we're saving we're only paying 10% that",
    "start": "2225100",
    "end": "2232100"
  },
  {
    "text": "we have the poor materials all the way from the US east to the US West or EU s",
    "start": "2232100",
    "end": "2237460"
  },
  {
    "text": "so this is an example that the cost can catch up on you if you if you don't pay",
    "start": "2237460",
    "end": "2243170"
  },
  {
    "text": "attention the next example is a true",
    "start": "2243170",
    "end": "2248930"
  },
  {
    "start": "2245000",
    "end": "2308000"
  },
  {
    "text": "story and if you get a call from the",
    "start": "2248930",
    "end": "2254270"
  },
  {
    "text": "Amazon Technical Account Manager at 2:00 a.m. in the morning he doesn't call you",
    "start": "2254270",
    "end": "2260540"
  },
  {
    "text": "to say hello Rick how you doing he called you to say hallo Rick stop doing",
    "start": "2260540",
    "end": "2267230"
  },
  {
    "text": "what you're doing and in this case it happened and we made",
    "start": "2267230",
    "end": "2272750"
  },
  {
    "text": "it to internal systems but we cannot really shut off but he asked to shut",
    "start": "2272750",
    "end": "2279470"
  },
  {
    "text": "down but we didn't really shut down because we can't shut down my business so fortunately we also have a limit some",
    "start": "2279470",
    "end": "2288590"
  },
  {
    "text": "color knobs that we turn and turn down our instances from 12,000 instances all",
    "start": "2288590",
    "end": "2294350"
  },
  {
    "text": "the way down 2000 instance and because our jobs are prioritized we know that",
    "start": "2294350",
    "end": "2300070"
  },
  {
    "text": "all the important jobs will be done first our downstream customer probably would notice it even though we have a",
    "start": "2300070",
    "end": "2306230"
  },
  {
    "text": "very big padlock so we were to sleep and before we found a solution at 11 a.m. I",
    "start": "2306230",
    "end": "2314390"
  },
  {
    "start": "2308000",
    "end": "2367000"
  },
  {
    "text": "get an email that says that my shipping is delayed so I call the term and he",
    "start": "2314390",
    "end": "2321860"
  },
  {
    "text": "said this is unrelated but I don't believe him so we found a solution of 1/2 X a 5 p.m.",
    "start": "2321860",
    "end": "2330540"
  },
  {
    "text": "you can see the little tick up and we did a rolling upgrade we observed it for",
    "start": "2330540",
    "end": "2336309"
  },
  {
    "text": "two hours and you look everything good and we're back to business so the lesson",
    "start": "2336309",
    "end": "2345130"
  },
  {
    "text": "we learned here is again a little things can can become magnified when you're",
    "start": "2345130",
    "end": "2350589"
  },
  {
    "text": "running tens of thousands of instances but fortunately if you build enough switches cut off a shutoff valve you can",
    "start": "2350589",
    "end": "2359109"
  },
  {
    "text": "at least get that you know get by today until your final fix so some words about",
    "start": "2359109",
    "end": "2367720"
  },
  {
    "start": "2367000",
    "end": "2382000"
  },
  {
    "text": "micro services will of micro services this is what get us where we are today as you can see we have very good",
    "start": "2367720",
    "end": "2374619"
  },
  {
    "text": "partitioning of the order problem in terms of in terms of micro services video encoder ever is different from",
    "start": "2374619",
    "end": "2381160"
  },
  {
    "text": "audio encoder and will give you many of those but we also have some difficulties here and she can see we have about 45",
    "start": "2381160",
    "end": "2389230"
  },
  {
    "start": "2382000",
    "end": "2410000"
  },
  {
    "text": "micro services out there and we start off with 10 but what we started getting about 40-45 was trying to feel a lot of",
    "start": "2389230",
    "end": "2396369"
  },
  {
    "text": "pain doesn't that in terms of Soviet development life cycles that includes",
    "start": "2396369",
    "end": "2403150"
  },
  {
    "text": "bill pay test deploy and it continues so to manage all of this it's very",
    "start": "2403150",
    "end": "2408880"
  },
  {
    "text": "difficult I mentioned previously that we",
    "start": "2408880",
    "end": "2414220"
  },
  {
    "start": "2410000",
    "end": "2449000"
  },
  {
    "text": "wanted to multiple sessions at the same time that's great we achieve a great efficiency but we also forces we",
    "start": "2414220",
    "end": "2422079"
  },
  {
    "text": "also force the programmers to have to understand concurrent programming and how many of you think that concurrent",
    "start": "2422079",
    "end": "2428440"
  },
  {
    "text": "programming is easy I don't think it's easy I'm sorry but that's just me and if",
    "start": "2428440",
    "end": "2437710"
  },
  {
    "text": "you have to think about threat safety is a distraction in my mind for the persons",
    "start": "2437710",
    "end": "2445119"
  },
  {
    "text": "the programmers who want to write a video and holders for this particular coder and at the same time we also",
    "start": "2445119",
    "end": "2451990"
  },
  {
    "start": "2449000",
    "end": "2476000"
  },
  {
    "text": "forces the idea that they are building not a video encoder they're building a video encoder service",
    "start": "2451990",
    "end": "2457819"
  },
  {
    "text": "needs to be 24/7 you want to make sure you have travel resource you mix wanna",
    "start": "2457819",
    "end": "2463339"
  },
  {
    "text": "make sure we release everything so that the only memories you'd only file handle or anything that can cause you grief",
    "start": "2463339",
    "end": "2468739"
  },
  {
    "text": "over time and all of this becomes the distractions and that might be the reasons why we don't have to have any",
    "start": "2468739",
    "end": "2474859"
  },
  {
    "text": "microt surfaces and finally always dependency is not being captured the way",
    "start": "2474859",
    "end": "2481910"
  },
  {
    "start": "2476000",
    "end": "2502000"
  },
  {
    "text": "we will build today if we have the image converter that require a very specific",
    "start": "2481910",
    "end": "2488420"
  },
  {
    "text": "versions of image image magic library we have a difficult time doing that because",
    "start": "2488420",
    "end": "2494410"
  },
  {
    "text": "everything is paid into one single image so I think and pretty much see where",
    "start": "2494410",
    "end": "2500449"
  },
  {
    "text": "we're leading up to in terms of container the next thing spot not not so great and",
    "start": "2500449",
    "end": "2507019"
  },
  {
    "text": "they save us you know quite a bit of times except that if we tune by human",
    "start": "2507019",
    "end": "2512180"
  },
  {
    "text": "there is really hard and we forget a lot of times so today we have knobs on how",
    "start": "2512180",
    "end": "2518989"
  },
  {
    "text": "to scale for each microservices they have different behavior that we have to",
    "start": "2518989",
    "end": "2524119"
  },
  {
    "text": "ask the human to give those parameters so basically it's a giant list of questionnaire you have to fill out and",
    "start": "2524119",
    "end": "2531099"
  },
  {
    "text": "we want to do better than that but not everything is bad obviously I think we",
    "start": "2531099",
    "end": "2537199"
  },
  {
    "start": "2533000",
    "end": "2641000"
  },
  {
    "text": "did something good Ellis telemetry so we put a lot of effort into metrics inside",
    "start": "2537199",
    "end": "2545089"
  },
  {
    "text": "and if it's with these informations we're able to tune the system in such a way that maximize efficiency and if",
    "start": "2545089",
    "end": "2550999"
  },
  {
    "text": "anything goes wrong if you don't scale correctly we'll know that right away before bad things what happens we talk",
    "start": "2550999",
    "end": "2559489"
  },
  {
    "text": "about how we break up video encoding into little chunks of encode that makes up small unit work think the result of",
    "start": "2559489",
    "end": "2566239"
  },
  {
    "text": "doing that make it a lot more agile and we also can leverage the scale ability",
    "start": "2566239",
    "end": "2571400"
  },
  {
    "text": "to increase parallelism and speed up the final output all jobs are resilient it",
    "start": "2571400",
    "end": "2580039"
  },
  {
    "text": "is okay if you're running a job we don't want to but if you're running a job that failed and instance died it is okay",
    "start": "2580039",
    "end": "2587569"
  },
  {
    "text": "because you can recover it and coupling with small Uddhav work and job with students we have small unit",
    "start": "2587569",
    "end": "2594260"
  },
  {
    "text": "of recovery which is a great thing to have job priority as I mentioned is",
    "start": "2594260",
    "end": "2600680"
  },
  {
    "text": "pretty good when we when we're running then with the capacity we can still get through the day without impacting",
    "start": "2600680",
    "end": "2607190"
  },
  {
    "text": "downstream customers so I'm so happy that we have that automation we invest a",
    "start": "2607190",
    "end": "2612980"
  },
  {
    "text": "lot of efforts the automations we believe in going home to see our family and if we do it right we don't have to",
    "start": "2612980",
    "end": "2620480"
  },
  {
    "text": "be staring at the screen all the time and I think that we have come a long way there's still more improvement we can do",
    "start": "2620480",
    "end": "2627440"
  },
  {
    "text": "in the future shutoff valves as I mentioned before and all limiter these are the things that we",
    "start": "2627440",
    "end": "2634310"
  },
  {
    "text": "pay into the system every time we do anything new we wanna make sure that there's an escape route looking forward",
    "start": "2634310",
    "end": "2644140"
  },
  {
    "start": "2641000",
    "end": "2664000"
  },
  {
    "text": "we happen to be in a moment where we are",
    "start": "2644140",
    "end": "2649690"
  },
  {
    "text": "thinking about the next versions of architecture how we evolve how we can",
    "start": "2649690",
    "end": "2655160"
  },
  {
    "text": "make a systems more scalable and we think of three very important quality that we want to do the first one",
    "start": "2655160",
    "end": "2664420"
  },
  {
    "start": "2664000",
    "end": "2711000"
  },
  {
    "text": "service computing this is not just a buzzword to us it matters a lot because",
    "start": "2664420",
    "end": "2669940"
  },
  {
    "text": "for us as an infrastructure team would build this distributed computing platform our end customers are the ones",
    "start": "2669940",
    "end": "2676430"
  },
  {
    "text": "that who have to write a video encoder and audio encoder we don't want them to write a video encoder we wanted to write",
    "start": "2676430",
    "end": "2683240"
  },
  {
    "text": "a video encoding function for this particular profile and this particular",
    "start": "2683240",
    "end": "2688550"
  },
  {
    "text": "particular Kodak and to make it so easy that they just focus on the business",
    "start": "2688550",
    "end": "2695000"
  },
  {
    "text": "writing our function and we worry about scaling it we were we don't have to ask",
    "start": "2695000",
    "end": "2700070"
  },
  {
    "text": "them to worry about how much memory do you need writing a service that's 24/7 so that's a neat memory and it won't die",
    "start": "2700070",
    "end": "2707210"
  },
  {
    "text": "myself so those are all distractions we want to get away container technology",
    "start": "2707210",
    "end": "2713660"
  },
  {
    "start": "2711000",
    "end": "2744000"
  },
  {
    "text": "does a bit of a no-brainer we want to be able to encapsulate always dependency but what other things another thing that",
    "start": "2713660",
    "end": "2721520"
  },
  {
    "text": "is really great for container is that the cost of contacts which is so much lower than spinning up and spinning",
    "start": "2721520",
    "end": "2726890"
  },
  {
    "text": "down instances so that and then that you have a very stable allocation of",
    "start": "2726890",
    "end": "2732820"
  },
  {
    "text": "instances and you can just switch containers in it so this is another",
    "start": "2732820",
    "end": "2737900"
  },
  {
    "text": "great step that we can improve our efficiency by spending less time on",
    "start": "2737900",
    "end": "2742970"
  },
  {
    "text": "scaling finally I think that I already kind of mention it about aces in order",
    "start": "2742970",
    "end": "2751970"
  },
  {
    "start": "2744000",
    "end": "2792000"
  },
  {
    "text": "for function as a service to be successful it has to be through administrations I don't want to hand out",
    "start": "2751970",
    "end": "2758180"
  },
  {
    "text": "a questionnaire to all our our customer and to have to give us tell us how much",
    "start": "2758180",
    "end": "2764270"
  },
  {
    "text": "memory do you need how much EBS volumes do you need what is the i/o rate you need for the",
    "start": "2764270",
    "end": "2770450"
  },
  {
    "text": "EBS volume and that again these are distractions if we if we're able to",
    "start": "2770450",
    "end": "2775970"
  },
  {
    "text": "extract this power for our customers the probably the information is probably wrong few months down the road so those",
    "start": "2775970",
    "end": "2782840"
  },
  {
    "text": "are the things that we want to invest a lot of time and we're doing the time right now as we speak and we're really",
    "start": "2782840",
    "end": "2789380"
  },
  {
    "text": "excited about that these are all the materials I have for today today's",
    "start": "2789380",
    "end": "2795350"
  },
  {
    "start": "2792000",
    "end": "2830000"
  },
  {
    "text": "Thursday and we spend better part of the week but we have a lot of great",
    "start": "2795350",
    "end": "2800480"
  },
  {
    "text": "materials coming off of different talks from Netflix and and I encourage you to",
    "start": "2800480",
    "end": "2806060"
  },
  {
    "text": "take a look at the rest of the talks on Friday and on today and look at the",
    "start": "2806060",
    "end": "2811670"
  },
  {
    "text": "videos and some of those because we interact with all these team together to make this possible this is all materials",
    "start": "2811670",
    "end": "2817970"
  },
  {
    "text": "I have I like to thank you very much for coming",
    "start": "2817970",
    "end": "2822609"
  },
  {
    "text": "and I'm happy to answer any questions after the talk thank you",
    "start": "2826030",
    "end": "2832080"
  }
]
[
  {
    "text": "okay so let's go ahead and get started by way of introductions uh i'm josh",
    "start": "399",
    "end": "5839"
  },
  {
    "text": "evans i'm the director of operations engineering at netflix with me is nireshko palani he's a",
    "start": "5839",
    "end": "11360"
  },
  {
    "text": "software engineer and architect he'll be coming up about halfway through",
    "start": "11360",
    "end": "17240"
  },
  {
    "text": "so we're going to talk to you today about embracing failure and about introducing failure",
    "start": "17680",
    "end": "22960"
  },
  {
    "text": "into your systems to make them more resilient before i do that i want to talk a little bit about the netflix infrastructure as",
    "start": "22960",
    "end": "30320"
  },
  {
    "text": "hopefully most of you know we serve video and audio to our customers so they can watch movies and tv shows",
    "start": "30320",
    "end": "37120"
  },
  {
    "text": "the echo system at a very high level of abstraction looks something like this we have many many devices out there in the",
    "start": "37120",
    "end": "42559"
  },
  {
    "text": "world customers homes in their hands as they're moving around for mobile devices",
    "start": "42559",
    "end": "48079"
  },
  {
    "text": "connecting over the internet and really connecting to a set of clouds uh the one we're going to focus on today",
    "start": "48079",
    "end": "53680"
  },
  {
    "text": "is what we call our aws netflix control plane this is where our distributed systems live",
    "start": "53680",
    "end": "59039"
  },
  {
    "text": "that provide the majority of the customer experience other than playback and a few other elements",
    "start": "59039",
    "end": "64478"
  },
  {
    "text": "in addition we have our own purpose built cdn also called open connect",
    "start": "64479",
    "end": "70320"
  },
  {
    "text": "and that that serves our video directly to our customers plus we also have other partners for",
    "start": "70320",
    "end": "75759"
  },
  {
    "text": "things like static content for serving box shots css javascript kinds of files",
    "start": "75759",
    "end": "81119"
  },
  {
    "text": "and service partners uh like xbox live and psn for device authentication services and",
    "start": "81119",
    "end": "87280"
  },
  {
    "text": "various other things like that to give you a sense of scale",
    "start": "87280",
    "end": "92640"
  },
  {
    "text": "we have over 50 million members we're in over 50 countries every month we serve over a billion",
    "start": "92640",
    "end": "99280"
  },
  {
    "text": "hours of streaming video we run on over a thousand different device types",
    "start": "99280",
    "end": "106399"
  },
  {
    "text": "from an infrastructure perspective we run in three aws regions with three availability zones in each one of those",
    "start": "106399",
    "end": "112079"
  },
  {
    "text": "regions and we have hundreds of services and at peak",
    "start": "112079",
    "end": "117759"
  },
  {
    "text": "we run at uh hundreds of thousands of requests per second and some services somewhere upwards of a million requests",
    "start": "117759",
    "end": "124399"
  },
  {
    "text": "per second has been achieved and our cdn has a footprint in the petabyte range",
    "start": "124399",
    "end": "131200"
  },
  {
    "text": "and serves at terabits per second when we talk about availability it",
    "start": "131200",
    "end": "137920"
  },
  {
    "text": "really comes down to these four fundamental things our customers can sign up or sign in",
    "start": "137920",
    "end": "144319"
  },
  {
    "text": "they can activate a device that isn't already activated they can browse through a fairly rich",
    "start": "144319",
    "end": "149840"
  },
  {
    "text": "experience to find the content that they want to watch and then hopefully we'll hit a play button and that will work well",
    "start": "149840",
    "end": "157599"
  },
  {
    "text": "so of course this is what keeps us up at night those error dialogues that come up sometimes cannot connect to netflix",
    "start": "157599",
    "end": "163519"
  },
  {
    "text": "there are various other variations on this so this is what we are striving to prevent",
    "start": "163519",
    "end": "170840"
  },
  {
    "text": "so the reality is is that failures are going to happen you can't stop them from happening you can try really hard but they're just",
    "start": "171040",
    "end": "177200"
  },
  {
    "text": "going to happen hardware fails disks will fail other kinds of hardware will fail",
    "start": "177200",
    "end": "182879"
  },
  {
    "text": "periodically you can encounter power outages or other types of things along those lines",
    "start": "182879",
    "end": "189360"
  },
  {
    "text": "natural disasters are extremely rare obviously but everybody wants their service to continue running even when",
    "start": "189360",
    "end": "196640"
  },
  {
    "text": "there is a severe condition like that software bugs obviously can affect the",
    "start": "196640",
    "end": "202480"
  },
  {
    "text": "availability of your service whether they are immediate when you deploy them or latent",
    "start": "202480",
    "end": "207519"
  },
  {
    "text": "and of course we all make mistakes so as we're deploying software out into our production environments or making configuration changes",
    "start": "207519",
    "end": "214720"
  },
  {
    "text": "things go wrong so failure is going to happen",
    "start": "214720",
    "end": "220000"
  },
  {
    "text": "so in response to that we design for failure we plan for it and we do basic things like exception",
    "start": "220560",
    "end": "226640"
  },
  {
    "text": "handling of bread and butter kind of stuff we design for fault tolerance and isolation so if we have services",
    "start": "226640",
    "end": "233280"
  },
  {
    "text": "depending on other services we try to isolate those services from",
    "start": "233280",
    "end": "238840"
  },
  {
    "text": "breakage we have fallbacks and degraded experiences so that if a service that provides certain functionality is",
    "start": "238840",
    "end": "245040"
  },
  {
    "text": "unavailable we can provide an experience even if we can't provide the perfect experience for our customers",
    "start": "245040",
    "end": "252799"
  },
  {
    "text": "we also do auto scaling so that we can deal with unexpected waves of traffic or if we introduce a bug into our code that",
    "start": "253120",
    "end": "259199"
  },
  {
    "text": "degrades performance and throughput and we rely on redundancy",
    "start": "259199",
    "end": "264720"
  },
  {
    "text": "in various cases a good use case for that is cassandra which we use for the majority of our database storage that",
    "start": "264720",
    "end": "271199"
  },
  {
    "text": "has redundant data replication so if we lose a node we'll still be able to serve our customers requests",
    "start": "271199",
    "end": "278240"
  },
  {
    "text": "so that's about designing for failure the next step is testing and making sure that it actually works",
    "start": "278240",
    "end": "284000"
  },
  {
    "text": "it's one thing to design and code as you all know it's another thing to see what happens uh when you're really executing",
    "start": "284000",
    "end": "289280"
  },
  {
    "text": "this code in anger so we have web scale traffic which makes things quite challenging",
    "start": "289280",
    "end": "296240"
  },
  {
    "text": "massive changing data sets whether it's metadata about movies or actors various things like that or customer",
    "start": "296240",
    "end": "302960"
  },
  {
    "text": "data membership data payment information we have complex interactions and request",
    "start": "302960",
    "end": "309360"
  },
  {
    "text": "patterns we have hundreds of services there are many many pathways through those distributed systems and it's",
    "start": "309360",
    "end": "315199"
  },
  {
    "text": "unpredictable in many cases what's going to happen or certainly for us to know every variation of what's going to",
    "start": "315199",
    "end": "320479"
  },
  {
    "text": "happen things are becoming more and more asynchronous we're experimenting with more asynchronous platforms for our code",
    "start": "320479",
    "end": "327440"
  },
  {
    "text": "to improve throughput and of course all of this is happening at web scale which then drives issues",
    "start": "327440",
    "end": "332720"
  },
  {
    "text": "around concurrency potentially and of course things don't always fail completely sometimes they do",
    "start": "332720",
    "end": "339199"
  },
  {
    "text": "but more often than not they start out failing in a partial way and then bail completely",
    "start": "339199",
    "end": "345600"
  },
  {
    "text": "so all of this is happening against a backdrop of constant change we're constantly deploying new code building",
    "start": "346000",
    "end": "351759"
  },
  {
    "text": "new services changing our architecture so even if you do know how things are going to work even if you test and",
    "start": "351759",
    "end": "358160"
  },
  {
    "text": "verified everything tomorrow it could all be different",
    "start": "358160",
    "end": "363360"
  },
  {
    "text": "so we asked ourselves several years ago what if we regularly inject failures into our systems what if we break it on",
    "start": "363919",
    "end": "369520"
  },
  {
    "text": "purpose and do this in production which is the place where we get all of that scale",
    "start": "369520",
    "end": "374880"
  },
  {
    "text": "and that was the impetus behind the simeon army",
    "start": "374880",
    "end": "381319"
  },
  {
    "text": "when we're talking about the simeon army we're going to talk about just a few select ones from uh from that group",
    "start": "381520",
    "end": "387680"
  },
  {
    "text": "we're going to talk about the ones that affect the scope of an outage so we talk a lot about internally about blast",
    "start": "387680",
    "end": "394319"
  },
  {
    "text": "radius the impact of an effect and this could be a unit of isolation it could be an instance it could be a",
    "start": "394319",
    "end": "401440"
  },
  {
    "text": "region or a zone it is also the potential scope of an actual outage and when we're trying to",
    "start": "401440",
    "end": "407120"
  },
  {
    "text": "simulate those outages it is also those boundaries or scope of a chaos exercise when we're actually intentionally trying",
    "start": "407120",
    "end": "413280"
  },
  {
    "text": "to break things we start with at the beginning with the basics let's start with an instance",
    "start": "413280",
    "end": "420840"
  },
  {
    "text": "failing and to address this we built the first and probably the most famous member of",
    "start": "420840",
    "end": "426000"
  },
  {
    "text": "the simeon army which we call chaos monkey and the concept behind chaos monkey is",
    "start": "426000",
    "end": "431840"
  },
  {
    "text": "that you've just let a monkey loose in your data center and he's pulling out cables he's pulling out your boxes he's",
    "start": "431840",
    "end": "437120"
  },
  {
    "text": "messing with the cooling system doing all kinds of things to damage that environment",
    "start": "437120",
    "end": "442960"
  },
  {
    "text": "now he's actually fairly well behaved because we only let him loose during business hours we'd rather have him do things during",
    "start": "442960",
    "end": "449120"
  },
  {
    "text": "the day when we can respond to a problem instead of having it happen at two o'clock in the morning so fairly well behaved from that",
    "start": "449120",
    "end": "455440"
  },
  {
    "text": "perspective what we learned from cast monkey was really pretty straightforward if you have stateless systems auto",
    "start": "455440",
    "end": "463039"
  },
  {
    "text": "replacement using things like asgs works quite well your system can get killed off a new one",
    "start": "463039",
    "end": "468800"
  },
  {
    "text": "spins up and it's really relatively straightforward so there really isn't any reason for somebody not to adopt",
    "start": "468800",
    "end": "474800"
  },
  {
    "text": "this kind of technology where it gets more challenging is when you have state when you have caches when",
    "start": "474800",
    "end": "480160"
  },
  {
    "text": "you have databases if you take out a node that's a much more problematic kind of thing and you can't just necessarily",
    "start": "480160",
    "end": "486720"
  },
  {
    "text": "auto replace that and so you have to do additional engineering work to make sure that new nodes let's say in a cassandra",
    "start": "486720",
    "end": "493520"
  },
  {
    "text": "cluster come up in a good and healthy state and can bootstrap themselves and start taking traffic",
    "start": "493520",
    "end": "500080"
  },
  {
    "text": "we were able to do that successfully for our cassandra clusters we've been using chaos monkey against cassandra for quite",
    "start": "500080",
    "end": "505520"
  },
  {
    "text": "some time now and when uh reboot again or choose your word of choice",
    "start": "505520",
    "end": "511360"
  },
  {
    "text": "happened when many many instances within aws were being rebooted as a result of",
    "start": "511360",
    "end": "516399"
  },
  {
    "text": "the vulnerability in the zen hypervisor our systems were rebooted as well",
    "start": "516399",
    "end": "521680"
  },
  {
    "text": "out of our 2700 cassandra nodes 218 needed to be rebooted and some of those",
    "start": "521680",
    "end": "526959"
  },
  {
    "text": "did not reboot correctly but we had automation in place to detect that and they are corrected for that we spun",
    "start": "526959",
    "end": "533120"
  },
  {
    "text": "up new fresh instances that were able to bootstrap and we cruised right through that event",
    "start": "533120",
    "end": "538480"
  },
  {
    "text": "so it was a great story for us and i think a good story around why fault injection at this level works",
    "start": "538480",
    "end": "543760"
  },
  {
    "text": "quite well so let's move up a level to an availability zone failing",
    "start": "543760",
    "end": "550399"
  },
  {
    "text": "a much more rare event instances are clearly going to fail more often than a zone might fail or you might need to",
    "start": "550399",
    "end": "555519"
  },
  {
    "text": "evacuate from the zone for some reason so to address this we created the next",
    "start": "555519",
    "end": "561040"
  },
  {
    "text": "and slightly heftier member of the simeon army chaos gorilla",
    "start": "561040",
    "end": "567279"
  },
  {
    "text": "and chaos gorilla is very much analogous to chaos monkey it simulates an availability zone outage we use a three",
    "start": "567279",
    "end": "574080"
  },
  {
    "text": "zone configuration and so we essentially eliminate one zone and exit",
    "start": "574080",
    "end": "579519"
  },
  {
    "text": "and then we want to make sure that the other two zones can handle the traffic and that nothing breaks",
    "start": "579519",
    "end": "585760"
  },
  {
    "text": "the challenges there is that doing this quickly is actually pretty pretty challenging rapidly shifting traffic",
    "start": "585760",
    "end": "592640"
  },
  {
    "text": "along the lines of things like load balancers timing out connections uh is",
    "start": "592640",
    "end": "597760"
  },
  {
    "text": "required you need to change your ttls for dns to make sure that the devices out in the world start connecting to the",
    "start": "597760",
    "end": "604240"
  },
  {
    "text": "right elbs that are not going to be shut down we had lingering connections uh to our",
    "start": "604240",
    "end": "609839"
  },
  {
    "text": "caches such as where we might be sending traffic to a node that's no longer there while we were shutting things down",
    "start": "609839",
    "end": "617360"
  },
  {
    "text": "and service configuration was also a bit of a challenge not all clusters at the time were set up",
    "start": "617360",
    "end": "622720"
  },
  {
    "text": "for auto scaling or pinned high to handle the additional load not all our services were configured for",
    "start": "622720",
    "end": "629360"
  },
  {
    "text": "cross zone calls we have some technology that allows us to try to favor the current zone unless that's not available",
    "start": "629360",
    "end": "635760"
  },
  {
    "text": "and then route over to another zone if an instance is in an area that we're currently shutting down",
    "start": "635760",
    "end": "640880"
  },
  {
    "text": "so we needed to make sure that those configuration changes were made and we have multiple layers in our",
    "start": "640880",
    "end": "646320"
  },
  {
    "text": "technology stack our ipc layer and also our fallback layer really two different layers",
    "start": "646320",
    "end": "652160"
  },
  {
    "text": "if the mist if the timeouts are not tuned correctly you can end up failing fast instead of routing your traffic",
    "start": "652160",
    "end": "657360"
  },
  {
    "text": "over to another zone which would be the desired experience so you can have a full experience for your customers",
    "start": "657360",
    "end": "664160"
  },
  {
    "text": "so let's move up one more level let's talk about regional failure again an even more uh rare scenario but certainly",
    "start": "664399",
    "end": "671040"
  },
  {
    "text": "one that we would all want to survive if it happened if there was a large natural disaster that took out a particular",
    "start": "671040",
    "end": "676160"
  },
  {
    "text": "region so for that we created yet another",
    "start": "676160",
    "end": "681360"
  },
  {
    "text": "member of the siemian army chaos kong and before i get into that let me just talk a little bit about what we call our",
    "start": "681360",
    "end": "687040"
  },
  {
    "text": "active active architecture we're running this way in the united states today",
    "start": "687040",
    "end": "692480"
  },
  {
    "text": "what you can see is one region on the left-hand side where we use elbs as regional load balancers we have our",
    "start": "692480",
    "end": "699360"
  },
  {
    "text": "own traffic shaping technology and routing technology called zuul behind that are three availability zones",
    "start": "699360",
    "end": "706320"
  },
  {
    "text": "and our storage layer which replicates data between zones so that you can hit any zone and still",
    "start": "706320",
    "end": "711519"
  },
  {
    "text": "service a customer request then we do that times two and we use dns",
    "start": "711519",
    "end": "716959"
  },
  {
    "text": "geo routing to get the right customers to the right region",
    "start": "716959",
    "end": "722000"
  },
  {
    "text": "in addition these regions actually are talking to each other because just like at the zone level we want to make sure the customer data is always where you",
    "start": "722000",
    "end": "728240"
  },
  {
    "text": "want to access it we replicate that data across regions as well and if we end up misrouting a customer",
    "start": "728240",
    "end": "734399"
  },
  {
    "text": "to the wrong place we can pass them back through and send them to the correct region",
    "start": "734399",
    "end": "739440"
  },
  {
    "text": "so a chaos exercise is really again fairly straightforward we exit a region and we start migrating our traffic using",
    "start": "739440",
    "end": "746079"
  },
  {
    "text": "dns over to the region and have it take a hundred percent of our us traffic",
    "start": "746079",
    "end": "751519"
  },
  {
    "text": "and then when we're done we turn the geo routing back on and we restore things back to their previous state",
    "start": "751519",
    "end": "759040"
  },
  {
    "text": "so the challenges here are going to seem really familiar most of them i've already covered and the same thing happens with a kong exercise for the",
    "start": "759040",
    "end": "765040"
  },
  {
    "text": "most part that happens with a gorilla exercise auto scaling configuration really matters we're trying to shift traffic",
    "start": "765040",
    "end": "770959"
  },
  {
    "text": "again very rapidly but instead of between zones between regions static configuration and pinning really",
    "start": "770959",
    "end": "776720"
  },
  {
    "text": "matters you have to make sure you have enough capacity for those stateful systems that maybe can't auto scale",
    "start": "776720",
    "end": "783200"
  },
  {
    "text": "instant startup time matters in terms of how quickly you can spin up an auto scale for a given service",
    "start": "783200",
    "end": "789839"
  },
  {
    "text": "and cache fill time if you don't have data for a particular customer it means your fault filling from database",
    "start": "789839",
    "end": "795600"
  },
  {
    "text": "and that can take some time to ramp up so you don't necessarily want to slam the other region very quickly",
    "start": "795600",
    "end": "801519"
  },
  {
    "text": "and deliver a bad experience to customers in addition again something very",
    "start": "801519",
    "end": "806720"
  },
  {
    "text": "familiar service configuration is a challenge timeout configurations surfaced again",
    "start": "806720",
    "end": "812320"
  },
  {
    "text": "fallbacks we discovered sometimes fail so you have a failure you have what you think is a great fallback and that",
    "start": "812320",
    "end": "817839"
  },
  {
    "text": "fallback also fails sometimes you don't get the desired experience",
    "start": "817839",
    "end": "822959"
  },
  {
    "text": "when you're doing those kinds of things the most challenging thing about kong",
    "start": "822959",
    "end": "828880"
  },
  {
    "text": "is not as is not having a course set a small set of the most critical services",
    "start": "828880",
    "end": "834240"
  },
  {
    "text": "that can run your overall service um and have others that are optional and this is something that we've been working",
    "start": "834240",
    "end": "839519"
  },
  {
    "text": "through recently the result of that is that any service",
    "start": "839519",
    "end": "845040"
  },
  {
    "text": "if you are not properly isolated from it even if you think of it as an optional thing",
    "start": "845040",
    "end": "850240"
  },
  {
    "text": "let's say ratings and recommendations not core playback but a valuable service or social",
    "start": "850240",
    "end": "855360"
  },
  {
    "text": "any of those services can take down your entire customer experience if you're not careful and so that was a bit of a challenge for",
    "start": "855360",
    "end": "861360"
  },
  {
    "text": "us as well and continues to do so so we've talked about instances and",
    "start": "861360",
    "end": "867040"
  },
  {
    "text": "zones and regions let's talk about another slice of scope and that's the service itself a body of code that you",
    "start": "867040",
    "end": "874079"
  },
  {
    "text": "deploy that performs a certain function within your distributed system and the reality of services is depending",
    "start": "874079",
    "end": "881519"
  },
  {
    "text": "on when you deploy something and whether a bug immediately manifests itself or has some kind of latent time delay",
    "start": "881519",
    "end": "888800"
  },
  {
    "text": "you can either in effect an instance if you're doing essentially a canary and testing out that code on a single",
    "start": "888800",
    "end": "893920"
  },
  {
    "text": "instance or you could have fully rolled it out and then have a problem manifest usually at peak",
    "start": "893920",
    "end": "899600"
  },
  {
    "text": "and it could take out either your retirement service a region or a zone depending on where you are in the stage of your deployment and so defending",
    "start": "899600",
    "end": "906240"
  },
  {
    "text": "against service failures is really sort of the next frontier in the big area that we need to focus on",
    "start": "906240",
    "end": "913279"
  },
  {
    "text": "other than being functionally incorrect there's really only two things that serve two ways that services can fail",
    "start": "913279",
    "end": "919680"
  },
  {
    "text": "they either get slow or they completely fail and to test this we created another",
    "start": "919680",
    "end": "924880"
  },
  {
    "text": "member of the simeon army called latency monkey and latexy monkey is again fairly simple",
    "start": "924880",
    "end": "929920"
  },
  {
    "text": "and straightforward the goal is to simulate a latent or failed service",
    "start": "929920",
    "end": "934959"
  },
  {
    "text": "inject arbitrary latency or errors and then again observe for effects and",
    "start": "934959",
    "end": "940079"
  },
  {
    "text": "then go and correct for things that don't work the way that you expect them to",
    "start": "940079",
    "end": "945199"
  },
  {
    "text": "uh it's a fairly straightforward exercise we go and do this on the server side",
    "start": "947920",
    "end": "953440"
  },
  {
    "text": "change its configuration and say hey when you get requests pretend like they're twice as slow as they normally",
    "start": "953440",
    "end": "958480"
  },
  {
    "text": "would be or respond with errors",
    "start": "958480",
    "end": "962560"
  },
  {
    "text": "so challenges around this some new things we discovered startup resiliency is a challenge your dependencies when",
    "start": "964639",
    "end": "969839"
  },
  {
    "text": "you're starting up your service are going to be likely be different than the ones that you have when you're in a steady state",
    "start": "969839",
    "end": "975680"
  },
  {
    "text": "and so going and correcting for those and coming up with solutions is pretty important",
    "start": "975680",
    "end": "980880"
  },
  {
    "text": "service owners don't always know all their dependencies and it's hard to defend against something when you don't know that you've pulled in some kind of",
    "start": "980880",
    "end": "986800"
  },
  {
    "text": "transitive dependency against another service fallbacks can fail too as i mentioned",
    "start": "986800",
    "end": "992800"
  },
  {
    "text": "earlier and sometimes you want to test second order effects or aggregate effects which can be challenging",
    "start": "992800",
    "end": "999279"
  },
  {
    "text": "so instead of service a calling service b passing through other services and indirectly accessing that service",
    "start": "999279",
    "end": "1006880"
  },
  {
    "text": "our dependencies are constantly in flux as i mentioned we're constantly deploying new code so that of course introduces challenges",
    "start": "1007040",
    "end": "1014320"
  },
  {
    "text": "but the biggest challenge with latency monkey was actually in the design itself",
    "start": "1014320",
    "end": "1019360"
  },
  {
    "text": "it tested both function and scale at the same time there's no staged approach to get",
    "start": "1019360",
    "end": "1024400"
  },
  {
    "text": "confidence that your your fallbacks will function well from a functional perspective before throwing a lot of",
    "start": "1024400",
    "end": "1030959"
  },
  {
    "text": "traffic uh at that same service in that state and so we found a lot of our engineering",
    "start": "1030959",
    "end": "1036720"
  },
  {
    "text": "team said hang on a second i'm not sure i want to do this i'm not sure what's going to happen",
    "start": "1036720",
    "end": "1043120"
  },
  {
    "text": "so i'm going to opt out and so we didn't get as much traction as we would have liked with latency monkey and we were",
    "start": "1043120",
    "end": "1049919"
  },
  {
    "text": "essentially trying to crack a walnut with a sledgehammer sort of the analogy and we really want something much more precise",
    "start": "1049919",
    "end": "1058080"
  },
  {
    "text": "and so for our next generation system which naresh is going to talk about we really want two things we want a",
    "start": "1058080",
    "end": "1064320"
  },
  {
    "text": "precision instrument that allows us to test functional things separate from scale",
    "start": "1064320",
    "end": "1069840"
  },
  {
    "text": "and we want to be able to run it continuously without worrying about the effect on our production environment and",
    "start": "1069840",
    "end": "1075520"
  },
  {
    "text": "our customers so that as things change we can detect those changes",
    "start": "1075520",
    "end": "1081840"
  },
  {
    "text": "so i'm going to hand it over to naresh and he'll go into that next generation technology",
    "start": "1082000",
    "end": "1088799"
  },
  {
    "text": "thank you josh hello everyone i'm naresh gopalani and i'm going to talk more about the",
    "start": "1090960",
    "end": "1097120"
  },
  {
    "text": "service failure testing as you had seen in josh's slides earlier",
    "start": "1097120",
    "end": "1102480"
  },
  {
    "text": "instance failing zone failing asg failing or are pretty defined scoped",
    "start": "1102480",
    "end": "1109039"
  },
  {
    "text": "problems but services failing is a totally different kind of worms and why is that",
    "start": "1109039",
    "end": "1116240"
  },
  {
    "text": "let me go back to the fundamentals of distributed systems distributed systems fail they are inherently prone to",
    "start": "1116240",
    "end": "1123120"
  },
  {
    "text": "failure some of the reasons why they fail are because of the complex interactions that",
    "start": "1123120",
    "end": "1128799"
  },
  {
    "text": "scale and there are so many different services in a distributed system",
    "start": "1128799",
    "end": "1135280"
  },
  {
    "text": "and that creates a complexity in the whole system there's variability across services",
    "start": "1135280",
    "end": "1142400"
  },
  {
    "text": "that same single service can be called by multiple other services in a service oriented architecture",
    "start": "1142400",
    "end": "1148320"
  },
  {
    "text": "and the latency component is different the response times may be different for example if there's service a that's been",
    "start": "1148320",
    "end": "1154960"
  },
  {
    "text": "called by service b and c the response time seen by b and c are could be different and that could cause",
    "start": "1154960",
    "end": "1161120"
  },
  {
    "text": "failures distributed systems have bayes and scene failures byzantine failures essentially could be",
    "start": "1161120",
    "end": "1167760"
  },
  {
    "text": "a mission type where your packet loss happens the network fails a router fails",
    "start": "1167760",
    "end": "1173840"
  },
  {
    "text": "you don't get an answer or could be a commission failure where you know eventually consistent system gives",
    "start": "1173840",
    "end": "1180480"
  },
  {
    "text": "different answers so taking the same example if service a is being called by b and c depending on",
    "start": "1180480",
    "end": "1187280"
  },
  {
    "text": "the time you could have different answers from that same service if you're having an eventually consistent system",
    "start": "1187280",
    "end": "1194559"
  },
  {
    "text": "and the combinatorial complexity creates it very challenging in terms of",
    "start": "1194559",
    "end": "1199679"
  },
  {
    "text": "availability so if you're striving for four nines and you have a service oriented",
    "start": "1199679",
    "end": "1204799"
  },
  {
    "text": "architecture in a distributed systems all the other services have to be better than four nights otherwise you cannot",
    "start": "1204799",
    "end": "1211360"
  },
  {
    "text": "achieve the four nines the math just doesn't add up netflix has embraced microservices",
    "start": "1211360",
    "end": "1219440"
  },
  {
    "text": "architecture there's a talk today at 4 30 to about this more in more",
    "start": "1219440",
    "end": "1225440"
  },
  {
    "text": "detail you can go listen to that but this is a call graph of a single request",
    "start": "1225440",
    "end": "1232159"
  },
  {
    "text": "that it enters the netflix ecosystem from the elb to our proxy layer",
    "start": "1232159",
    "end": "1237760"
  },
  {
    "text": "as you can see the breadth and depth of this fan out is humongous",
    "start": "1237760",
    "end": "1243200"
  },
  {
    "text": "it represents an interesting challenges for us what we've seen is",
    "start": "1243200",
    "end": "1248960"
  },
  {
    "text": "any single service can cause cascading failures i'll show you an example",
    "start": "1248960",
    "end": "1255679"
  },
  {
    "text": "a service or a cluster fails in its own right because of varied reasons somebody",
    "start": "1255679",
    "end": "1262000"
  },
  {
    "text": "pushed in a bad code or the asg crashed",
    "start": "1262000",
    "end": "1267600"
  },
  {
    "text": "but this affects the calling service now the callers of this service slow down",
    "start": "1267600",
    "end": "1273600"
  },
  {
    "text": "they cause failures because their threat pools start blocking",
    "start": "1273600",
    "end": "1278799"
  },
  {
    "text": "and pretty soon there is a cascading effect a snowball effect a small snowflake now becomes a big snowball and",
    "start": "1278880",
    "end": "1286000"
  },
  {
    "text": "rushing at you at very high speeds and before you know it your whole entire",
    "start": "1286000",
    "end": "1291039"
  },
  {
    "text": "system collapses like a big jenga tower and has happened to us at netflix",
    "start": "1291039",
    "end": "1296960"
  },
  {
    "text": "what did we do to prevent that we created histrix our fault tolerance system or library",
    "start": "1296960",
    "end": "1304640"
  },
  {
    "text": "which has all the goodness of fallbacks load shedding bulkheading",
    "start": "1304640",
    "end": "1311280"
  },
  {
    "text": "and it prevents us from a single service taking out a whole system but histrix also needs tuning and",
    "start": "1311280",
    "end": "1318480"
  },
  {
    "text": "configuration you need to tune the thread pools you need to ensure that the fallbacks work",
    "start": "1318480",
    "end": "1324480"
  },
  {
    "text": "there's also a great talk today again at 3 30 about a massive",
    "start": "1324480",
    "end": "1330799"
  },
  {
    "text": "load at our edge and how we tackle that you can get more in details in that",
    "start": "1330799",
    "end": "1337279"
  },
  {
    "text": "before i go here let me tell you a quick story we were running trying to run latency",
    "start": "1338480",
    "end": "1345440"
  },
  {
    "text": "monkey on a service and i went to the service owner and i was talking about the latency monkey run to him",
    "start": "1345440",
    "end": "1352400"
  },
  {
    "text": "and how what the timing is and there was another service owner with",
    "start": "1352400",
    "end": "1357440"
  },
  {
    "text": "him he was as was a batch application owner and he asked the service owner how does it affect my batch application",
    "start": "1357440",
    "end": "1364559"
  },
  {
    "text": "and the service owner goes because it's latency monkey your service will get latency problems and the batch owned",
    "start": "1364559",
    "end": "1370799"
  },
  {
    "text": "application owner is like no no no i'm a batch application owner guy i don't care about latency don't do the latency",
    "start": "1370799",
    "end": "1376799"
  },
  {
    "text": "monkey test and there was a device ui guy working there too",
    "start": "1376799",
    "end": "1383200"
  },
  {
    "text": "his question was how does the ui f get affected if we do latency monkey test",
    "start": "1383200",
    "end": "1389120"
  },
  {
    "text": "and the service owner had no answer and as josh pointed out there is a low adoption of latency",
    "start": "1389120",
    "end": "1395679"
  },
  {
    "text": "monkey in netflix the reason was people are scared of running that in production because",
    "start": "1395679",
    "end": "1402320"
  },
  {
    "text": "they didn't know what would happen and how their system affects any other system or the ui or the",
    "start": "1402320",
    "end": "1408640"
  },
  {
    "text": "whole general ecosystem so it was an aha moment for us",
    "start": "1408640",
    "end": "1415039"
  },
  {
    "text": "it was a big hammer or i would say we were trying to slice an apple with a chainsaw don't try that at home by the",
    "start": "1415280",
    "end": "1421679"
  },
  {
    "text": "way we needed a very precise way of",
    "start": "1421679",
    "end": "1426720"
  },
  {
    "text": "injecting failures request level simulations and we created fit",
    "start": "1426720",
    "end": "1433520"
  },
  {
    "text": "fit is our request level precise failure injection system",
    "start": "1433520",
    "end": "1438960"
  },
  {
    "text": "so this is a chart of this how our architecture overall looks like and how the devices connect to the",
    "start": "1438960",
    "end": "1444720"
  },
  {
    "text": "internet and how the system flows through let's say you were failing service a and b",
    "start": "1444720",
    "end": "1451679"
  },
  {
    "text": "a request from the elb comes to zoo zul is our proxy layer it introspects",
    "start": "1451679",
    "end": "1459360"
  },
  {
    "text": "the request and sees if the device or account has been configured for failure",
    "start": "1459360",
    "end": "1465600"
  },
  {
    "text": "and this configuration is pushed to zoom in asynchronously it's not a network call",
    "start": "1465600",
    "end": "1472799"
  },
  {
    "text": "zuul decorates that request with the failure context and passes it on to our",
    "start": "1472799",
    "end": "1477919"
  },
  {
    "text": "edge layer then the edge layer makes a call to service b",
    "start": "1477919",
    "end": "1483600"
  },
  {
    "text": "and service b is failed because fit has decorated the request and our fit",
    "start": "1483600",
    "end": "1488640"
  },
  {
    "text": "library failed injects failure the failure could be complete failure or latency",
    "start": "1488640",
    "end": "1496159"
  },
  {
    "text": "now let's say edge calls service a and that has been configured to fail too and that occurs",
    "start": "1496159",
    "end": "1503919"
  },
  {
    "text": "second order effect that josh mentioned earlier it was hard to test that using latency monkey but with fit",
    "start": "1503919",
    "end": "1510240"
  },
  {
    "text": "veeam enabled that as well so if service a then goes ahead and calls service b",
    "start": "1510240",
    "end": "1515840"
  },
  {
    "text": "that gets affected too we wanted our",
    "start": "1515840",
    "end": "1521520"
  },
  {
    "text": "failures to be as close to and realistic as possible so who injects those failures in our",
    "start": "1521520",
    "end": "1527760"
  },
  {
    "text": "failure in the injection system it's the failure injection points",
    "start": "1527760",
    "end": "1532960"
  },
  {
    "text": "most of the services at netflix are built using common building blocks and those are the places where we inject",
    "start": "1532960",
    "end": "1539919"
  },
  {
    "text": "failures some of the building blocks that we use is ribbon that's used for our ipc",
    "start": "1539919",
    "end": "1546400"
  },
  {
    "text": "framework as tinyx our cassandra client",
    "start": "1546400",
    "end": "1552320"
  },
  {
    "text": "memcached client is ev cache that is an injection point as well",
    "start": "1552400",
    "end": "1557600"
  },
  {
    "text": "carion is a service container that all our services inherit you can know more about these open",
    "start": "1557600",
    "end": "1564080"
  },
  {
    "text": "source components at a 330 talk today about netflix oss if you want to",
    "start": "1564080",
    "end": "1569679"
  },
  {
    "text": "get some detailed view of those and histrix our fault tolerance system",
    "start": "1569679",
    "end": "1575360"
  },
  {
    "text": "is an injection point too you may think why is a hysterex a fault tolerance system an injection point",
    "start": "1575360",
    "end": "1581679"
  },
  {
    "text": "injecting failures the reason is we want to test that it's working and his fallbacks are working",
    "start": "1581679",
    "end": "1587679"
  },
  {
    "text": "correctly the bulk heading works correctly",
    "start": "1587679",
    "end": "1592559"
  },
  {
    "text": "let me give you a little more detail about fit as you saw all these injection points",
    "start": "1593279",
    "end": "1599520"
  },
  {
    "text": "are different some of them are ipc some of them are persistence caching",
    "start": "1599520",
    "end": "1604720"
  },
  {
    "text": "what fit provides is a common simulation syntax across all these different",
    "start": "1604720",
    "end": "1610000"
  },
  {
    "text": "injection points it provides a single simulation interface that all these libraries",
    "start": "1610000",
    "end": "1616480"
  },
  {
    "text": "interface with and if we create more of some similar injection points or",
    "start": "1616480",
    "end": "1621520"
  },
  {
    "text": "building blocks they will integrate with fit and all this failure metadata",
    "start": "1621520",
    "end": "1628400"
  },
  {
    "text": "and configuration is passed through http request headers because we want it to be",
    "start": "1628400",
    "end": "1633440"
  },
  {
    "text": "really fast it's in memory lookup",
    "start": "1633440",
    "end": "1637840"
  },
  {
    "text": "i'll show you how we integrate this whole failure how it flows through our soa graph",
    "start": "1638480",
    "end": "1644799"
  },
  {
    "text": "this is an example of two services at netflix they are built using our open source building blocks",
    "start": "1644799",
    "end": "1650720"
  },
  {
    "text": "there is the filter which is part of the carrion server container then you have your service",
    "start": "1650720",
    "end": "1656240"
  },
  {
    "text": "application logic and then ribbon to make ipc calls to other services",
    "start": "1656240",
    "end": "1662399"
  },
  {
    "text": "when a request comes into service a it is already decorated by zuul with the",
    "start": "1662399",
    "end": "1669360"
  },
  {
    "text": "failure injection metadata here's an example of that",
    "start": "1669360",
    "end": "1674559"
  },
  {
    "text": "it has a common name space to define then you have a list of injection points",
    "start": "1674559",
    "end": "1680320"
  },
  {
    "text": "that you need to effect it has a concept of white list the white what the white list does is it",
    "start": "1680320",
    "end": "1686559"
  },
  {
    "text": "defines whether these injection points should fail or not i'll touch more upon that",
    "start": "1686559",
    "end": "1692720"
  },
  {
    "text": "in a later slide and we have an id a session associated with this failure injection session",
    "start": "1692720",
    "end": "1699440"
  },
  {
    "text": "because one single user interaction could result in multiple requests to our whole systems and we",
    "start": "1699440",
    "end": "1706480"
  },
  {
    "text": "need to tie all of that big together when this request is received by caryon",
    "start": "1706480",
    "end": "1713760"
  },
  {
    "text": "it looks at that request header via fit and then determines whether there should",
    "start": "1713760",
    "end": "1720159"
  },
  {
    "text": "be a failure and if so failure occurs if not service a then call service b",
    "start": "1720159",
    "end": "1727840"
  },
  {
    "text": "before calling that two ribbon integrates with fit again this is an in",
    "start": "1727840",
    "end": "1733360"
  },
  {
    "text": "memory lookup call that tells it whether it needs to inject any failures",
    "start": "1733360",
    "end": "1739679"
  },
  {
    "text": "and if so it injects that helps us enable client-side failure injection",
    "start": "1739679",
    "end": "1745840"
  },
  {
    "text": "then this request moves on to service b let's say we injected latency after certain latency is injected it",
    "start": "1745840",
    "end": "1752320"
  },
  {
    "text": "moves to service b there from there on its rinse and repeat the same thing",
    "start": "1752320",
    "end": "1757919"
  },
  {
    "text": "happens again and then the response is sent back so as you can see we've added failure",
    "start": "1757919",
    "end": "1763840"
  },
  {
    "text": "injection through our entire call graph using fit and very in a very precise manner",
    "start": "1763840",
    "end": "1771279"
  },
  {
    "text": "let me touch upon failure scenarios failure scenarios is a set of injection",
    "start": "1771840",
    "end": "1778159"
  },
  {
    "text": "points that we want to fail how do we define those failure scenarios",
    "start": "1778159",
    "end": "1785520"
  },
  {
    "text": "these can be defined based on past outages if you have a seen that a certain set of",
    "start": "1785520",
    "end": "1791279"
  },
  {
    "text": "failures have caused outages what we do is we create these failure scenarios and run through our system",
    "start": "1791279",
    "end": "1797760"
  },
  {
    "text": "again to validate that we become resilient and we fix those problems",
    "start": "1797760",
    "end": "1803520"
  },
  {
    "text": "specific dependency interactions what we do is based on different",
    "start": "1803520",
    "end": "1809279"
  },
  {
    "text": "dependency interactions between multiple services we define failure scenarios",
    "start": "1809279",
    "end": "1814960"
  },
  {
    "text": "to inject failures a white list of critical services i'll touch more about critical service",
    "start": "1814960",
    "end": "1821760"
  },
  {
    "text": "in my slides later on but it essentially is a white list saying don't affect",
    "start": "1821760",
    "end": "1827440"
  },
  {
    "text": "these services but i don't know about all the other services that are going to be interacting",
    "start": "1827440",
    "end": "1833039"
  },
  {
    "text": "fail all of them and that's the failure scenario you can define",
    "start": "1833039",
    "end": "1838799"
  },
  {
    "text": "fit is not only used for injecting failures what we use it is also for dynamic",
    "start": "1838799",
    "end": "1844559"
  },
  {
    "text": "tracing of in dependencies as you saw in the previous call graph it's a big fan out and we want to trace",
    "start": "1844559",
    "end": "1851600"
  },
  {
    "text": "the whole dependency tree and we use fit for that as well",
    "start": "1851600",
    "end": "1857278"
  },
  {
    "text": "defining these scenarios and tracing these dependencies require insights",
    "start": "1859039",
    "end": "1865200"
  },
  {
    "text": "fit insights are derived through self self is a transparent sea creature",
    "start": "1865200",
    "end": "1871440"
  },
  {
    "text": "that's why we chose the name salp because it's transparency by design it's a distributed tracing system we've",
    "start": "1871440",
    "end": "1878960"
  },
  {
    "text": "created at netflix which has been inspired by the dapper paper it provides us insight into dependencies",
    "start": "1878960",
    "end": "1885679"
  },
  {
    "text": "the call graph the service call graph that you see there was all created using salp",
    "start": "1885679",
    "end": "1891039"
  },
  {
    "text": "it helps us define and visualize those scenarios for failure",
    "start": "1891039",
    "end": "1897120"
  },
  {
    "text": "as much as we love our monkeys we love our customers more for us every",
    "start": "1898399",
    "end": "1903679"
  },
  {
    "text": "single stream is important so we run our failures in production but we do it carefully so that we don't",
    "start": "1903679",
    "end": "1910960"
  },
  {
    "text": "affect our customer experience and this is how we do it we slowly dial up these failures",
    "start": "1910960",
    "end": "1917760"
  },
  {
    "text": "we first do functional validation using fit we have isolated synthetic transactions",
    "start": "1917760",
    "end": "1924640"
  },
  {
    "text": "hitting our production systems through a well-known set of devices and causing failures for only those set",
    "start": "1924640",
    "end": "1931440"
  },
  {
    "text": "of devices that helps us functionally validate that our system is more resilient",
    "start": "1931440",
    "end": "1938399"
  },
  {
    "text": "then once we are comfortable that this failures won't affect customer experience",
    "start": "1938399",
    "end": "1944080"
  },
  {
    "text": "we start dialing up the chaos in our production environment by slowly lifting the gates of our simian army that's",
    "start": "1944080",
    "end": "1951039"
  },
  {
    "text": "waiting there to come out and cause problems we use traffic based",
    "start": "1951039",
    "end": "1957600"
  },
  {
    "text": "dialing we have a small percentage of our traffic injected to failure",
    "start": "1957600",
    "end": "1964240"
  },
  {
    "text": "and slowly and gradually we dial up this knob while we are observing that there's no",
    "start": "1964240",
    "end": "1970240"
  },
  {
    "text": "side effect on customer experience and once it's comfortable we are comfortable we ratchet up to 100",
    "start": "1970240",
    "end": "1977840"
  },
  {
    "text": "we built this tool for fit we've created the simian army but a great tool set is useless if you",
    "start": "1979679",
    "end": "1985440"
  },
  {
    "text": "don't use it continuously and we use it to con to continuous validation",
    "start": "1985440",
    "end": "1992240"
  },
  {
    "text": "as you saw in the earlier diagram there are so many services microservices at netflix",
    "start": "1992240",
    "end": "1997919"
  },
  {
    "text": "and the combinatorial complexity creates the challenge around availability you cannot treat all these services equally",
    "start": "1997919",
    "end": "2005760"
  },
  {
    "text": "we've defined a set of services that are critical for our click and play",
    "start": "2005760",
    "end": "2010799"
  },
  {
    "text": "scenario social is a great example social provides very nice feature set",
    "start": "2010799",
    "end": "2017840"
  },
  {
    "text": "from netflix for you to share your information viewing history get recommendations from your friends",
    "start": "2017840",
    "end": "2024080"
  },
  {
    "text": "have social interaction but it is not important for a click and play use case so we",
    "start": "2024080",
    "end": "2030640"
  },
  {
    "text": "considered that as a non-critical service we've defined a set of critical services",
    "start": "2030640",
    "end": "2036240"
  },
  {
    "text": "we feed that in the fifth scenario to make it whitelist and fail everything else",
    "start": "2036240",
    "end": "2042799"
  },
  {
    "text": "then we have a set of devices that continuously run in production",
    "start": "2042799",
    "end": "2048079"
  },
  {
    "text": "we run it at hourly on all the different device platforms we have",
    "start": "2048079",
    "end": "2053760"
  },
  {
    "text": "and these are continuously validating that none of the critical non-critical services becomes critical service",
    "start": "2053760",
    "end": "2061440"
  },
  {
    "text": "the reason is that if that happens that whole",
    "start": "2061440",
    "end": "2067040"
  },
  {
    "text": "service collapsing like a jenga tower happens and we don't want that to happen",
    "start": "2067119",
    "end": "2073040"
  },
  {
    "text": "so now if you remember the story i told you about the latency monkey where the user",
    "start": "2073040",
    "end": "2078560"
  },
  {
    "text": "the service owners were very hesitant to running it in production",
    "start": "2078560",
    "end": "2083760"
  },
  {
    "text": "now they don't have to because we have created this ability to do functional testing first",
    "start": "2083760",
    "end": "2091040"
  },
  {
    "text": "then slowly dialing up our chaos so now they don't have to fear these monkeys",
    "start": "2091040",
    "end": "2096800"
  },
  {
    "text": "whenever we could schedule latency monkeys they're like yeah bring it on we're ready for it",
    "start": "2096800",
    "end": "2103440"
  },
  {
    "text": "what are the key takeaways from this talk today you shouldn't wait for random failures",
    "start": "2103440",
    "end": "2109760"
  },
  {
    "text": "because in a distributed system in a cloud random failures will occur",
    "start": "2109760",
    "end": "2115520"
  },
  {
    "text": "you should cause these failures to validate resiliency that's really important",
    "start": "2115520",
    "end": "2120720"
  },
  {
    "text": "you should remove uncertainty by forcing failures regularly constantly",
    "start": "2120720",
    "end": "2126240"
  },
  {
    "text": "ensure that your system is resilient to failures why because it's better to fail at 2pm",
    "start": "2126240",
    "end": "2132480"
  },
  {
    "text": "rather than 2am you don't want an outage at 2am where you're scrambling to wake",
    "start": "2132480",
    "end": "2137520"
  },
  {
    "text": "up everybody and try to fix the problem it's better to have people awake and ready when they're needed",
    "start": "2137520",
    "end": "2144720"
  },
  {
    "text": "and always test design assumptions by stressing them",
    "start": "2144720",
    "end": "2149760"
  },
  {
    "text": "embrace failure failure will happen so be prepared",
    "start": "2150320",
    "end": "2155920"
  },
  {
    "text": "a lot of our simian army apes are open sourced a bunch of our building block systems",
    "start": "2157040",
    "end": "2163359"
  },
  {
    "text": "are open sourced you can leverage those these are rest of the netflix stocks we",
    "start": "2163359",
    "end": "2169839"
  },
  {
    "text": "have at reinvent going on very interesting talks about our open source technology how do we maintain a",
    "start": "2169839",
    "end": "2176480"
  },
  {
    "text": "resilient front door at massive scale the microservices architecture",
    "start": "2176480",
    "end": "2181839"
  },
  {
    "text": "and so on thank you again for coming and listening",
    "start": "2181839",
    "end": "2187119"
  },
  {
    "text": "to josh and naresh now we can open up for questions if you have any questions",
    "start": "2187119",
    "end": "2194000"
  },
  {
    "text": "yes",
    "start": "2194000",
    "end": "2197000"
  },
  {
    "text": "that kind of define when you feel comfortable enough that",
    "start": "2201680",
    "end": "2206720"
  },
  {
    "text": "your fault injection testing is never going to fail is that kind of the",
    "start": "2206720",
    "end": "2213280"
  },
  {
    "text": "the deciding factor of when you scale it up to 100 percent um live traffic in production",
    "start": "2213280",
    "end": "2219040"
  },
  {
    "text": "um so i'll repeat the question the question is when we dial up our failure",
    "start": "2219040",
    "end": "2224240"
  },
  {
    "text": "uh do we ensure that these failures don't cause any problems completely",
    "start": "2224240",
    "end": "2230560"
  },
  {
    "text": "the answer is yes and no the no part is the yes part is because",
    "start": "2230560",
    "end": "2236320"
  },
  {
    "text": "of the critical services we want to ensure our critical services are robust",
    "start": "2236320",
    "end": "2241359"
  },
  {
    "text": "so we make sure that they are running fine for the non-critical services it's absolutely okay we ratchet it up 100",
    "start": "2241359",
    "end": "2248800"
  },
  {
    "text": "because we know for sure this is not going to cause customer pain for the click and play scenario",
    "start": "2248800",
    "end": "2256599"
  },
  {
    "text": "sorry can you repeat",
    "start": "2264800",
    "end": "2268280"
  },
  {
    "text": "um so so the question is how does chaos gorilla work uh is it done through",
    "start": "2274720",
    "end": "2280160"
  },
  {
    "text": "network tricks no it's not done through network tricks because most of our services are deployed through our asgs",
    "start": "2280160",
    "end": "2287760"
  },
  {
    "text": "what we usually do is and our asgs are striped across three availability zones we shrink our asgs to",
    "start": "2287760",
    "end": "2294960"
  },
  {
    "text": "two zones and essentially we have a script that goes in takes one zone out",
    "start": "2294960",
    "end": "2301440"
  },
  {
    "text": "that's correct we're just eliminating the services in that zone such that traffic has to go to the other",
    "start": "2301440",
    "end": "2306880"
  },
  {
    "text": "two zones and all the services that are not auto scaled we know we have tagged them and then we essentially kill the",
    "start": "2306880",
    "end": "2313520"
  },
  {
    "text": "instances from there",
    "start": "2313520",
    "end": "2317240"
  },
  {
    "text": "um that's a good question the question is uh after we done with a guerrilla",
    "start": "2334960",
    "end": "2340400"
  },
  {
    "text": "exercise where we take away a zone and when we bring back a zone that could cause a problem because of the",
    "start": "2340400",
    "end": "2345520"
  },
  {
    "text": "replication delays and everything yes but we've create architectured a system such that",
    "start": "2345520",
    "end": "2351599"
  },
  {
    "text": "most of our data is replicated and even when the zone comes up especially our cassandra data store",
    "start": "2351599",
    "end": "2358720"
  },
  {
    "text": "we don't bring back those nodes in service until they have",
    "start": "2358720",
    "end": "2364320"
  },
  {
    "text": "failed filled up otherwise there will be problems yes i'd say in general also",
    "start": "2364320",
    "end": "2369440"
  },
  {
    "text": "anytime you're moving traffic there's that same risk that things will not have spun up quickly enough and so that's",
    "start": "2369440",
    "end": "2375440"
  },
  {
    "text": "something you just have to handle in a careful way and make sure you're not overwhelming your systems during this",
    "start": "2375440",
    "end": "2380480"
  },
  {
    "text": "exercise",
    "start": "2380480",
    "end": "2383480"
  },
  {
    "text": "that's correct that's correct as you mentioned cassandra's obviously a",
    "start": "2389280",
    "end": "2396240"
  },
  {
    "text": "stateful system um so a bit of a different beast when you introduce chaos there how do you handle that i mean i've",
    "start": "2396240",
    "end": "2403119"
  },
  {
    "text": "had some bad experiences there so i'm curious sure um so uh",
    "start": "2403119",
    "end": "2409040"
  },
  {
    "text": "we have our cassandra experts at our booth here they can they're better equipped to answer that questions uh but",
    "start": "2409040",
    "end": "2415359"
  },
  {
    "text": "uh for a chaos monkey exercise we've hardened our cassandra cluster through our pream sidecar that it's open source",
    "start": "2415359",
    "end": "2422240"
  },
  {
    "text": "as well to withstand the monkey attacks but to be more to give if",
    "start": "2422240",
    "end": "2427280"
  },
  {
    "text": "you want more detail you can stop by our booth for some of our cd folks out there",
    "start": "2427280",
    "end": "2433599"
  },
  {
    "text": "there's a question at the back",
    "start": "2434960",
    "end": "2438760"
  },
  {
    "text": "so the fault injection tests are always running in the background it's they're running hourly on 11",
    "start": "2444160",
    "end": "2450880"
  },
  {
    "text": "different device platforms and when there's uh we still are working on making that as a",
    "start": "2450880",
    "end": "2457920"
  },
  {
    "text": "failure detection system where it will get paged and things like that but it's running all the time so naresh is",
    "start": "2457920",
    "end": "2463280"
  },
  {
    "text": "talking specifically about fit for chaos gorilla and chaos kong exercises those are definitely scheduled",
    "start": "2463280",
    "end": "2470079"
  },
  {
    "text": "those are fairly large scale events chaos monkey is running randomly throughout business hours",
    "start": "2470079",
    "end": "2476480"
  },
  {
    "text": "and has limits on how many instances it can take down let's say at a given time so some of them are scheduled but the",
    "start": "2476480",
    "end": "2482800"
  },
  {
    "text": "goal with fit is for us to be continuously running that and because of synthetic transactions there's very little risk in doing so or need to",
    "start": "2482800",
    "end": "2489440"
  },
  {
    "text": "notify people that it's happening",
    "start": "2489440",
    "end": "2492800"
  },
  {
    "text": "um what was that conversation like was it just",
    "start": "2498480",
    "end": "2503720"
  },
  {
    "text": "conversation there were certainly a lot of",
    "start": "2506880",
    "end": "2512640"
  },
  {
    "text": "conversations and a and a need to better understand the resistance and it took us a little while to figure that out so of",
    "start": "2512640",
    "end": "2519200"
  },
  {
    "text": "course we were a little bullheaded and kept going well we really should be doing this let's let's push on this",
    "start": "2519200",
    "end": "2524800"
  },
  {
    "text": "and then as we really dug in and understood the function versus scale argument we stepped back and we said hey",
    "start": "2524800",
    "end": "2531119"
  },
  {
    "text": "you know what latency monkey is too much of a sledgehammer let's come up with something better like",
    "start": "2531119",
    "end": "2536400"
  },
  {
    "text": "fit in order to build that confidence um and so we fairly quickly figured that out",
    "start": "2536400",
    "end": "2541839"
  },
  {
    "text": "and then shifted along those lines um other exercises like active like our active active failovers using kong or",
    "start": "2541839",
    "end": "2548160"
  },
  {
    "text": "chaos gorilla those we feel like were as good as we were going to make them and so",
    "start": "2548160",
    "end": "2554400"
  },
  {
    "text": "we were a little bit more adamant that we needed to do those exercises even if people weren't",
    "start": "2554400",
    "end": "2559760"
  },
  {
    "text": "necessarily comfortable with it we did give people time to get ready but we still schedule those and",
    "start": "2559760",
    "end": "2565520"
  },
  {
    "text": "executed on those",
    "start": "2565520",
    "end": "2569079"
  },
  {
    "text": "so fit as it stands today it uses you need the netflix building blocks but it is it is",
    "start": "2580400",
    "end": "2586720"
  },
  {
    "text": "not open source yet um but it is pluggable so we've created it to be as a plugable module where you can",
    "start": "2586720",
    "end": "2593200"
  },
  {
    "text": "plug in your own injection points you don't have to use the netflix injection points you can plug in a",
    "start": "2593200",
    "end": "2600000"
  },
  {
    "text": "relational database as an injection point or something like that",
    "start": "2600000",
    "end": "2605640"
  },
  {
    "text": "i'll go at the back",
    "start": "2607680",
    "end": "2611160"
  },
  {
    "text": "i think we need you to repeat the question with the microphone",
    "start": "2622960",
    "end": "2627200"
  },
  {
    "text": "uh have you ever encountered a part of your architecture that was",
    "start": "2630400",
    "end": "2635839"
  },
  {
    "text": "particularly difficult to simulate a failure or that you you couldn't simulate a failure based on some sort of",
    "start": "2635839",
    "end": "2643119"
  },
  {
    "text": "maybe a limitation of how the systems are you know chained or something like that",
    "start": "2643119",
    "end": "2648720"
  },
  {
    "text": "um so we essentially when we architect our systems we",
    "start": "2648720",
    "end": "2654480"
  },
  {
    "text": "are the first goal for our in our minds is things will fail and they are bound to fail and we've",
    "start": "2654480",
    "end": "2661200"
  },
  {
    "text": "seen in our environment or in the cloud environment things fail and we make no assumptions",
    "start": "2661200",
    "end": "2667200"
  },
  {
    "text": "around making it very uh tightly coupled so",
    "start": "2667200",
    "end": "2672480"
  },
  {
    "text": "as a as a philosophy in the architecture we assume that we will fail and there",
    "start": "2672480",
    "end": "2678160"
  },
  {
    "text": "are things like stateful services which we don't have many of those",
    "start": "2678160",
    "end": "2684319"
  },
  {
    "text": "most of our services are stateless but the stateful services are the ones that we are a little more careful about and",
    "start": "2684319",
    "end": "2690720"
  },
  {
    "text": "there are previous outages that have been learned from and created failure scenarios around that does that answer",
    "start": "2690720",
    "end": "2697680"
  },
  {
    "text": "your question yeah you mentioned",
    "start": "2697680",
    "end": "2703200"
  },
  {
    "text": "please have some insights but now i'm pretty sure that as a tool",
    "start": "2703200",
    "end": "2709318"
  },
  {
    "text": "so that's a that's a good question the question is fit has all these insights that it publishes does that add any",
    "start": "2719440",
    "end": "2726960"
  },
  {
    "text": "extra toll to the request processing um because it needs to process data to cassandra or not",
    "start": "2726960",
    "end": "2734079"
  },
  {
    "text": "that was one of the biggest considerations we had while we were building salp and we modeled it after the dapper paper i would encourage you",
    "start": "2734079",
    "end": "2740640"
  },
  {
    "text": "to read that paper it's really good paper and this is not the our publishing is",
    "start": "2740640",
    "end": "2745920"
  },
  {
    "text": "not done as part of request processing uh it is done asynchronously",
    "start": "2745920",
    "end": "2750960"
  },
  {
    "text": "and it's pushed off uh in a different manner and we use a lot of technologies",
    "start": "2750960",
    "end": "2756240"
  },
  {
    "text": "for that we use elasticsearch we have our own suro",
    "start": "2756240",
    "end": "2761680"
  },
  {
    "text": "system that publishes those data so as a request processing piece there is no tax it's essentially",
    "start": "2761680",
    "end": "2768640"
  },
  {
    "text": "free",
    "start": "2768640",
    "end": "2771640"
  },
  {
    "text": "yes so the question is how do we instrument other services that are not part of the building blocks",
    "start": "2781440",
    "end": "2787520"
  },
  {
    "text": "ninety percent of our services are built using our building blocks i would say almost hundred percent",
    "start": "2787520",
    "end": "2793040"
  },
  {
    "text": "so we haven't had any others like we also i didn't mention uh all of the aws",
    "start": "2793040",
    "end": "2799599"
  },
  {
    "text": "services are also injection points for us because we've written wrappers around it like s3 sqs",
    "start": "2799599",
    "end": "2805200"
  },
  {
    "text": "uh all those and whenever we create new ones that make network calls we integrate with fit",
    "start": "2805200",
    "end": "2810800"
  },
  {
    "text": "and it's very simple it's it's just ask the question is there a failure what is the failure and i'll do the failure",
    "start": "2810800",
    "end": "2817839"
  },
  {
    "text": "this is probably a good time for us to break um naresh and i are going to be downstairs at the netflix booth",
    "start": "2817839",
    "end": "2824880"
  },
  {
    "text": "if you guys want to come down and have one-on-one chats we're happy to go into more detail on all this and our simian army posters are in our",
    "start": "2824880",
    "end": "2831680"
  },
  {
    "text": "booth too so if you want a selfie with them come down",
    "start": "2831680",
    "end": "2837078"
  }
]
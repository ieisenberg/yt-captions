[
  {
    "text": "This is My Architecture\nInawisdom:",
    "start": "83",
    "end": "2302"
  },
  {
    "text": "How Insurance Companies are Using IDP to\nOptimize Document Processing",
    "start": "2303",
    "end": "4208"
  },
  {
    "text": "Welcome to This is My Architecture.",
    "start": "4506",
    "end": "6346"
  },
  {
    "text": "My name is Andrea",
    "start": "6346",
    "end": "7338"
  },
  {
    "text": "and I'm here with Phil from Inawisdom.",
    "start": "7338",
    "end": "9610"
  },
  {
    "text": "-Hi, Phil. Welcome to the show.\n-Hi.",
    "start": "9610",
    "end": "11811"
  },
  {
    "text": "What do you guys do?",
    "start": "11812",
    "end": "13092"
  },
  {
    "text": "So, we develop AI and ML solutions\nfor our clients.",
    "start": "13092",
    "end": "16490"
  },
  {
    "text": "Great. So today we are here\nto talk about your IDP platform,",
    "start": "16490",
    "end": "19684"
  },
  {
    "text": "which is intelligent document processing.",
    "start": "19684",
    "end": "21642"
  },
  {
    "text": "Tell our viewers what is that?",
    "start": "21642",
    "end": "23828"
  },
  {
    "text": "So it allows insurance companies\nto understand",
    "start": "23828",
    "end": "27116"
  },
  {
    "text": "what's inside policy documents,",
    "start": "27116",
    "end": "28817"
  },
  {
    "text": "so they know it's there\nand they can use it in their business.",
    "start": "28818",
    "end": "31900"
  },
  {
    "text": "Let's dive straight into the architecture.",
    "start": "31900",
    "end": "34242"
  },
  {
    "text": "Assume that I am a company\nrequesting a quote.",
    "start": "34242",
    "end": "37298"
  },
  {
    "text": "So talk us through the flow\nfrom the intake stage.",
    "start": "37298",
    "end": "40498"
  },
  {
    "text": "Yeah. So the first bit is the preprocessing,",
    "start": "40498",
    "end": "43506"
  },
  {
    "text": "and a Lambda kicks that off\nby going to the inbox,",
    "start": "43506",
    "end": "47254"
  },
  {
    "text": "and getting the email,\nand all the attachments.",
    "start": "47254",
    "end": "49686"
  },
  {
    "text": "-Okay.\n-And then puts that into S3.",
    "start": "49686",
    "end": "53019"
  },
  {
    "text": "I see. And what different types\nof intake attachments do you get?",
    "start": "53019",
    "end": "57600"
  },
  {
    "text": "Typically they're PDF, Word file, Excel,",
    "start": "58690",
    "end": "62362"
  },
  {
    "text": "that kind of thing,\nbut we can do more if needed.",
    "start": "62362",
    "end": "64963"
  },
  {
    "text": "Okay. So that's the first stage.",
    "start": "64964",
    "end": "67409"
  },
  {
    "text": "Walk us through the logic.\nI do see AI/ML in the middle.",
    "start": "67750",
    "end": "71560"
  },
  {
    "text": "Where does that come\ninto the context of the use case?",
    "start": "71560",
    "end": "74584"
  },
  {
    "text": "So the next stage is\nkicked off by the Lambda,",
    "start": "74584",
    "end": "77838"
  },
  {
    "text": "-and it starts a step function.\n-Okay.",
    "start": "77838",
    "end": "80364"
  },
  {
    "text": "And then based on\nwhat kind of document it is,",
    "start": "80364",
    "end": "83549"
  },
  {
    "text": "what line of business this is,",
    "start": "83550",
    "end": "85036"
  },
  {
    "text": "it will use\neither Textract or custom model",
    "start": "85036",
    "end": "88012"
  },
  {
    "text": "to work, extract the text from the document.",
    "start": "88012",
    "end": "91554"
  },
  {
    "text": "And what order do they do use these?",
    "start": "91554",
    "end": "94720"
  },
  {
    "text": "So most of the time, we'll be using Textract,",
    "start": "94720",
    "end": "97210"
  },
  {
    "text": "and we'll use\na custom model for very specific--",
    "start": "97630",
    "end": "102191"
  },
  {
    "text": "If it's very specific form data\nin a very specific format,",
    "start": "102192",
    "end": "105062"
  },
  {
    "text": "we can hardly tune a model to that exact.",
    "start": "105062",
    "end": "107060"
  },
  {
    "text": "I see. Where do you take\nthe information from,",
    "start": "107060",
    "end": "109635"
  },
  {
    "text": "and then where do you put it in?",
    "start": "109636",
    "end": "111412"
  },
  {
    "text": "So everything works around S3.",
    "start": "111412",
    "end": "112979"
  },
  {
    "text": "So Textract will load\nthose documents from S3,",
    "start": "112979",
    "end": "118159"
  },
  {
    "text": "do what it needs to do,",
    "start": "118385",
    "end": "119816"
  },
  {
    "text": "and it will output its results to S3.",
    "start": "119816",
    "end": "122456"
  },
  {
    "text": "I see.",
    "start": "122456",
    "end": "123416"
  },
  {
    "text": "And does it work the same way",
    "start": "123416",
    "end": "125496"
  },
  {
    "text": "with your custom model and Sagemaker?",
    "start": "125496",
    "end": "126904"
  },
  {
    "text": "Yeah, exactly. Data goes in, model runs,",
    "start": "126904",
    "end": "131310"
  },
  {
    "text": "and then the results come back out,\nand stored back to S3.",
    "start": "131310",
    "end": "133985"
  },
  {
    "text": "I see.",
    "start": "133985",
    "end": "134886"
  },
  {
    "text": "So for most cases, you can deal\nwith the intake forms through Textract,",
    "start": "134886",
    "end": "138572"
  },
  {
    "text": "but some custom intakes require\nthat custom model of its Sagemaker.",
    "start": "138572",
    "end": "143110"
  },
  {
    "text": "And then I do see Comprehend.",
    "start": "143110",
    "end": "145174"
  },
  {
    "text": "Walk us through that.\nWhere does that come in?",
    "start": "145174",
    "end": "147045"
  },
  {
    "text": "So we use that for classification,\nand also named entity recognition.",
    "start": "147045",
    "end": "151430"
  },
  {
    "text": "Basically, that allows us\nto work out if it's a person,",
    "start": "151430",
    "end": "154079"
  },
  {
    "text": "if it's a location, organization, or a date.",
    "start": "154450",
    "end": "158244"
  },
  {
    "text": "Again, it works in a similar format.",
    "start": "158244",
    "end": "160454"
  },
  {
    "text": "It will load the files from S3,",
    "start": "160455",
    "end": "165064"
  },
  {
    "text": "actually the results from the other stages,",
    "start": "165810",
    "end": "167870"
  },
  {
    "text": "and then process it,",
    "start": "167870",
    "end": "169655"
  },
  {
    "text": "and then put the results back into S3.",
    "start": "169656",
    "end": "172172"
  },
  {
    "text": "I see.",
    "start": "172172",
    "end": "173080"
  },
  {
    "text": "So you have a preprocessing stage.",
    "start": "173080",
    "end": "175550"
  },
  {
    "text": "I do see a step function.",
    "start": "175550",
    "end": "177640"
  },
  {
    "text": "And then I assume\nthis is the post processing.",
    "start": "177640",
    "end": "180350"
  },
  {
    "text": "-Yeah.\n-Walk us through that.",
    "start": "180350",
    "end": "182028"
  },
  {
    "text": "The heart of this is a Lambda again.",
    "start": "182028",
    "end": "183729"
  },
  {
    "text": "So that Lambda will load",
    "start": "183729",
    "end": "186519"
  },
  {
    "text": "the final results",
    "start": "187783",
    "end": "189282"
  },
  {
    "text": "from all the different stages,",
    "start": "189282",
    "end": "190818"
  },
  {
    "text": "and work out what to do with it.",
    "start": "190818",
    "end": "191984"
  },
  {
    "text": "So, for example, Textract\nwhen it has extracted a document.",
    "start": "191984",
    "end": "197030"
  },
  {
    "text": "We extract it per page at a time,",
    "start": "197030",
    "end": "198816"
  },
  {
    "text": "but things like tables\ncan span multiple pages.",
    "start": "198816",
    "end": "201142"
  },
  {
    "text": "So in that Lambda,",
    "start": "201142",
    "end": "202422"
  },
  {
    "text": "we're stitching that\nall back together to understand, really,",
    "start": "202422",
    "end": "205252"
  },
  {
    "text": "the whole of that table\nand all the different values within it,",
    "start": "205252",
    "end": "207972"
  },
  {
    "text": "for example.",
    "start": "207972",
    "end": "208985"
  },
  {
    "text": "The other thing\nwe're doing is looking for synonyms.",
    "start": "208986",
    "end": "211577"
  },
  {
    "text": "So, for example,\nthe different styles of documents",
    "start": "211578",
    "end": "215802"
  },
  {
    "text": "from different insurers will come through,",
    "start": "215802",
    "end": "218164"
  },
  {
    "text": "and they have policy number,\npolicy numb, policy hash.",
    "start": "218164",
    "end": "222526"
  },
  {
    "text": "They're all the same thing.",
    "start": "222526",
    "end": "223688"
  },
  {
    "text": "We've got it here.",
    "start": "223688",
    "end": "225128"
  },
  {
    "text": "But we still need to bring them\nall back together",
    "start": "225128",
    "end": "227462"
  },
  {
    "text": "to that one data point.",
    "start": "227462",
    "end": "228904"
  },
  {
    "text": "So that's what synonym is about.",
    "start": "228904",
    "end": "230364"
  },
  {
    "text": "Okay, and where do you store\nthat information?",
    "start": "230364",
    "end": "232316"
  },
  {
    "text": "-So we store them in DynamoDB.\n-Okay.",
    "start": "232316",
    "end": "234347"
  },
  {
    "text": "So the Lambda will load that from DynamoDB.",
    "start": "234348",
    "end": "237604"
  },
  {
    "text": "I see.",
    "start": "237604",
    "end": "238680"
  },
  {
    "text": "So let's assume an intake comes in,",
    "start": "239370",
    "end": "242155"
  },
  {
    "text": "and this is information\nyou've never processed before.",
    "start": "242156",
    "end": "244880"
  },
  {
    "text": "So you may not have\nthe synonyms in the DynamoDB.",
    "start": "244880",
    "end": "247766"
  },
  {
    "text": "How do you train that model?",
    "start": "247766",
    "end": "249456"
  },
  {
    "text": "So the first thing is we're monitoring\nin the process",
    "start": "249456",
    "end": "252819"
  },
  {
    "text": "the accuracy,",
    "start": "253239",
    "end": "254326"
  },
  {
    "text": "and if it's poor,\nwe'll send it to Sagemaker Ground Truth.",
    "start": "254326",
    "end": "257924"
  },
  {
    "text": "What that means is we can then send it",
    "start": "257924",
    "end": "259350"
  },
  {
    "text": "to a subject matter expert\nthat can understand that document,",
    "start": "259350",
    "end": "262729"
  },
  {
    "text": "labor that document up to us,",
    "start": "262729",
    "end": "264484"
  },
  {
    "text": "and we can retrain the models as needed,",
    "start": "264484",
    "end": "267236"
  },
  {
    "text": "particularly this model.",
    "start": "267237",
    "end": "268196"
  },
  {
    "text": "But you may do things\nwith these two models.",
    "start": "268196",
    "end": "271008"
  },
  {
    "text": "Also, we can put new\nsynonyms into that database.",
    "start": "271008",
    "end": "273616"
  },
  {
    "text": "Okay, wonderful.",
    "start": "273616",
    "end": "274730"
  },
  {
    "text": "So thank you, Phil,\nfor walking us through this architecture",
    "start": "274730",
    "end": "277442"
  },
  {
    "text": "where you're using the power of AI/ML",
    "start": "277442",
    "end": "279442"
  },
  {
    "text": "to be able to extract information\nfrom the intake forms.",
    "start": "279442",
    "end": "282047"
  },
  {
    "text": "-Thank you so much.\n-Thank you.",
    "start": "282047",
    "end": "283564"
  },
  {
    "text": "And thank you for watching\nThis is My Architecture.",
    "start": "283564",
    "end": "285820"
  },
  {
    "text": "Thank you for Watching",
    "start": "286450",
    "end": "289389"
  }
]
[
  {
    "text": "Welcome to another episode of 'This is My Architecture'.",
    "start": "7386",
    "end": "10577"
  },
  {
    "text": "My name is Aarthi,\nand joining me today is Eric from Hudl.",
    "start": "10844",
    "end": "14514"
  },
  {
    "text": "-Eric, welcome to the show.\n-Thank you.",
    "start": "14781",
    "end": "16683"
  },
  {
    "text": "So, Eric, tell us what Hudl does.",
    "start": "17050",
    "end": "19019"
  },
  {
    "text": "Hudl is a sports video and analytics company\nthat works with over 60 million customers worldwide.",
    "start": "19586",
    "end": "24958"
  },
  {
    "text": "Great. So, Eric, talk to us\nabout what we are going to see today.",
    "start": "25359",
    "end": "29062"
  },
  {
    "text": "Yep, so, with our video and data,\ndata is obviously nothing without the content itself.",
    "start": "29696",
    "end": "34001"
  },
  {
    "text": "So, at the core of what we do\nis ingesting our coaching video,",
    "start": "34368",
    "end": "38805"
  },
  {
    "text": "and returning that back to our coaches\nin a playable format as quickly as possible.",
    "start": "39139",
    "end": "42743"
  },
  {
    "text": "Okay, can you walk us through this architecture?",
    "start": "42910",
    "end": "45211"
  },
  {
    "text": "Absolutely. So, our coaches\nhave one of many ways to get content into Hudl.",
    "start": "45279",
    "end": "50951"
  },
  {
    "text": "They can do it through our mobile app, our web platform,\nor our Hudl Focus cameras that we provide ourselves.",
    "start": "50984",
    "end": "56490"
  },
  {
    "text": "Programmatically, then we initiate the upload\nand get that content into our S3 bucket.",
    "start": "57090",
    "end": "61762"
  },
  {
    "text": "At the same time, we take that message",
    "start": "62229",
    "end": "65999"
  },
  {
    "text": "and we create an SQS message\nin one of the given queues within SQS.",
    "start": "66033",
    "end": "70469"
  },
  {
    "text": "So, do you have multiple queues here,\nand how are these messages prioritized?",
    "start": "70604",
    "end": "75042"
  },
  {
    "text": "Absolutely. There's kind of two factors\nthat play into that for us.",
    "start": "75142",
    "end": "78312"
  },
  {
    "text": "One is performance, and time sensitivity.",
    "start": "78779",
    "end": "81982"
  },
  {
    "text": "Some users just have different demands than others.",
    "start": "82249",
    "end": "84551"
  },
  {
    "text": "The other factor is just how long that job is going to take,\ngiven the size of the content that we're ingesting.",
    "start": "84952",
    "end": "89890"
  },
  {
    "text": "We don't want that clogging up another queue\nthat could be in its own separate one.",
    "start": "90123",
    "end": "94294"
  },
  {
    "text": "Great. So, once that prioritization\nis complete on these SQS queues,",
    "start": "95195",
    "end": "99967"
  },
  {
    "text": "how do you transport this data now?",
    "start": "100000",
    "end": "101668"
  },
  {
    "text": "Yep, so once we have those messages,\nwe're able to deliver it to its appropriate Auto Scaling group.",
    "start": "102169",
    "end": "107507"
  },
  {
    "text": "Leveraging Spot Fleet then, we have over 20 instances\nthat we have defined as being appropriate for transcoding,",
    "start": "107875",
    "end": "114715"
  },
  {
    "text": "and we're able to toss those jobs through our EC2 instances,\nto then deliver that content back to our users.",
    "start": "115082",
    "end": "121755"
  },
  {
    "text": "You talked about millions of users\nwhen we started this conversation,",
    "start": "122823",
    "end": "126393"
  },
  {
    "text": "what scale are we talking in terms of the transcoding jobs\nthat are running on these EC2 instances?",
    "start": "126426",
    "end": "131298"
  },
  {
    "text": "Yeah, even on our most recent season\nwith American Football,",
    "start": "131565",
    "end": "134234"
  },
  {
    "text": "you know, Friday, Saturday nights\nare very big nights for us,",
    "start": "134835",
    "end": "137371"
  },
  {
    "text": "at scale, we're looking at something\naround 30,000 messages per minute,",
    "start": "138739",
    "end": "143377"
  },
  {
    "text": "ingested across 10,000 instances at scale.",
    "start": "144077",
    "end": "148948"
  },
  {
    "text": "That's big numbers,\nhow are you optimizing for this scale here?",
    "start": "149750",
    "end": "153420"
  },
  {
    "text": "So, going back to the two factors,\none is performance, and one is cost effectiveness.",
    "start": "154054",
    "end": "158258"
  },
  {
    "text": "So, what we've done is initiate our own lambda\nthat leverages CloudWatch metrics,",
    "start": "158592",
    "end": "162562"
  },
  {
    "text": "to see the number of SQS messages\nthat we have in a given queue,",
    "start": "162829",
    "end": "165799"
  },
  {
    "text": "and compare it to the number of instances that we have.",
    "start": "166099",
    "end": "168669"
  },
  {
    "text": "It's target-tracking scaling.",
    "start": "168702",
    "end": "170237"
  },
  {
    "text": "Once we have that current ratio,\nwe're able to inform the Auto Scaling group.",
    "start": "171138",
    "end": "175375"
  },
  {
    "text": "And so that way,\nit can make the decision on whether to scale in",
    "start": "175742",
    "end": "178846"
  },
  {
    "text": "and produce more instances for a workload\nor scale out and hit that cost effectiveness piece, like I said.",
    "start": "178879",
    "end": "183851"
  },
  {
    "text": "That also helps with the seasonality as well,",
    "start": "184084",
    "end": "186553"
  },
  {
    "text": "keeping only instances up and running\nduring the seasonal period.",
    "start": "186587",
    "end": "190224"
  },
  {
    "text": "Absolutely.",
    "start": "190257",
    "end": "191358"
  },
  {
    "text": "You talked about cost.",
    "start": "191592",
    "end": "192659"
  },
  {
    "text": "I'm curious to know,\nwhat was the cost reduction with this architecture?",
    "start": "192693",
    "end": "196696"
  },
  {
    "text": "Yeah, at the end of the day, given the infrastructure\nthat we were currently running ourselves,",
    "start": "197164",
    "end": "200634"
  },
  {
    "text": "we saw a total of 28% decrease\nin our total compute costs for transcoding services.",
    "start": "200968",
    "end": "206607"
  },
  {
    "text": "Another area of interest, Eric, is performance.",
    "start": "207107",
    "end": "209943"
  },
  {
    "text": "How long does it take for your end-to-end,",
    "start": "210911",
    "end": "213312"
  },
  {
    "text": "like transcoding from the time\nthe user uploads for the entire process to complete?",
    "start": "213347",
    "end": "217718"
  },
  {
    "text": "And going along with that is,\nhow do you handle failures as well?",
    "start": "218018",
    "end": "221188"
  },
  {
    "text": "Yep, so once we have receipt\nof that content in our S3 bucket,",
    "start": "221889",
    "end": "225192"
  },
  {
    "text": "end-to-end, introducing that content to our ESGs",
    "start": "225959",
    "end": "229429"
  },
  {
    "text": "and bringing that back into our S3 buckets in a playable format,\nhas never taken us longer than two minutes.",
    "start": "230898",
    "end": "235969"
  },
  {
    "text": "And you mentioned interruptions and failures.",
    "start": "236336",
    "end": "238138"
  },
  {
    "text": "It's always a concern with Spot.",
    "start": "238405",
    "end": "239773"
  },
  {
    "text": "Two things that we do is watch\nfor those messages alerting us",
    "start": "240807",
    "end": "243644"
  },
  {
    "text": "that an instance is going to scale out",
    "start": "243677",
    "end": "245312"
  },
  {
    "text": "so that way we know\nthat we can't send any more jobs to it.",
    "start": "245679",
    "end": "248582"
  },
  {
    "text": "That said, too, we've also leveraged Spot Advisor.",
    "start": "249716",
    "end": "252085"
  },
  {
    "text": "Knowing which instances\nare going to be the most available at a given time,",
    "start": "252719",
    "end": "256190"
  },
  {
    "text": "We've gone through one of our busiest nights,",
    "start": "256790",
    "end": "258725"
  },
  {
    "text": "like I mentioned, 30,000 jobs a minute,\n10,000 instances plus,",
    "start": "258759",
    "end": "262829"
  },
  {
    "text": "and we'd never saw a single Spot interruption.",
    "start": "263163",
    "end": "265264"
  },
  {
    "text": "That's impressive.",
    "start": "265566",
    "end": "266433"
  },
  {
    "text": "Eric, thank you for sharing this transcoding architecture,\nwhere you've optimized for both cost and performance.",
    "start": "266733",
    "end": "273440"
  },
  {
    "text": "And thank you for watching 'This is My Architecture'.\nSee you soon.",
    "start": "274708",
    "end": "278545"
  }
]
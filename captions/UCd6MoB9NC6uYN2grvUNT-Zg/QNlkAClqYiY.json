[
  {
    "start": "0",
    "end": "32000"
  },
  {
    "text": "good afternoon everybody my name is David Nunnally I'm the senior",
    "start": "390",
    "end": "5430"
  },
  {
    "text": "development manager on the x-ray service and we're going to talk for the next",
    "start": "5430",
    "end": "11700"
  },
  {
    "text": "hour we're gonna dive somewhat deeply into the x-ray service but focus",
    "start": "11700",
    "end": "16740"
  },
  {
    "text": "specifically on how we can leverage the data that we put into the service so the",
    "start": "16740",
    "end": "21810"
  },
  {
    "text": "trace data to gain and analyze that data to get to get interesting insights from",
    "start": "21810",
    "end": "29369"
  },
  {
    "text": "the data so what can we expect from the",
    "start": "29369",
    "end": "35760"
  },
  {
    "start": "32000",
    "end": "32000"
  },
  {
    "text": "session we're going to walk through an analytics app and in fact I'm going to",
    "start": "35760",
    "end": "42450"
  },
  {
    "text": "at the end give you a github repository where you can go and download it and use it for yourselves I'm expecting great",
    "start": "42450",
    "end": "49530"
  },
  {
    "text": "things in terms of you guys extending it I'm gonna do a short high-level overview",
    "start": "49530",
    "end": "54780"
  },
  {
    "text": "of the service itself this is a 400 level talk so I'm hoping that most of",
    "start": "54780",
    "end": "60600"
  },
  {
    "text": "you are somewhat familiar with the x-ray service but we'll touch on it just to make sure that most people get some at",
    "start": "60600",
    "end": "66840"
  },
  {
    "text": "least an overview of what the service does and then we'll tack back and talk about how you will actually build an",
    "start": "66840",
    "end": "74580"
  },
  {
    "text": "analytics app using the x-ray api's and then if we have time we'll do some Q&A",
    "start": "74580",
    "end": "80549"
  },
  {
    "text": "at the end so let's actually talk a",
    "start": "80549",
    "end": "86189"
  },
  {
    "text": "little bit about the application that we're going to walk through and build during the session this first screen",
    "start": "86189",
    "end": "94920"
  },
  {
    "text": "here is if you're familiar with x-ray is what we call the service map this is",
    "start": "94920",
    "end": "102350"
  },
  {
    "text": "what you get in the x-ray console you start sending traces to x-ray we'll",
    "start": "102350",
    "end": "108060"
  },
  {
    "text": "start to build the service map for you we post process the traces and we",
    "start": "108060",
    "end": "115549"
  },
  {
    "text": "identify the various micro services that you have that making up your application",
    "start": "115549",
    "end": "120930"
  },
  {
    "text": "the relationships between them what we call edges and it's color-coded with a",
    "start": "120930",
    "end": "127890"
  },
  {
    "text": "bunch of information which we'll talk about with it further but one of the things I can do is I can",
    "start": "127890",
    "end": "133280"
  },
  {
    "text": "click into one of these nodes using the mouse and I can then see a histogram of",
    "start": "133280",
    "end": "140900"
  },
  {
    "text": "my response times and I can also see various other things like what error",
    "start": "140900",
    "end": "146060"
  },
  {
    "text": "codes HTTP status codes etc I might be seeing in that particular microservice",
    "start": "146060",
    "end": "152349"
  },
  {
    "text": "and it actually updates in real time so you can use it and monitor for",
    "start": "152349",
    "end": "157700"
  },
  {
    "text": "monitoring but it's painful to have to keep clicking into each of those nodes",
    "start": "157700",
    "end": "165019"
  },
  {
    "text": "into each of the micro service nodes on the service map to see what's going on with respect to response times so",
    "start": "165019",
    "end": "173920"
  },
  {
    "text": "instead we're going to talk about building this application today which is",
    "start": "173920",
    "end": "179450"
  },
  {
    "start": "176000",
    "end": "176000"
  },
  {
    "text": "a scatter graph application that will display the response times for any of",
    "start": "179450",
    "end": "186230"
  },
  {
    "text": "the particular micro-services that you're interested in it displays the top half you can",
    "start": "186230",
    "end": "191360"
  },
  {
    "text": "actually see the distribution and in the bottom half it will actually show you",
    "start": "191360",
    "end": "196540"
  },
  {
    "text": "HTTP status codes and then we can actually highlight different areas that",
    "start": "196540",
    "end": "202639"
  },
  {
    "text": "we may be interested in and go and investigate what's going on in particular outliers etc but it gives a",
    "start": "202639",
    "end": "210950"
  },
  {
    "text": "real nice visual view of what's actually going on in one of your micro services",
    "start": "210950",
    "end": "217130"
  },
  {
    "text": "or indeed what we call the edge the Micra so is a cording microservice B and then you want to dig into that",
    "start": "217130",
    "end": "223609"
  },
  {
    "text": "particular relationship the way the app is written is it gives you three hours",
    "start": "223609",
    "end": "229669"
  },
  {
    "text": "of information in 118 one-minute slices and then every minute a timer fires a",
    "start": "229669",
    "end": "236510"
  },
  {
    "text": "sync timer fires and another one-minute slice gets added and the whole thing Scrolls to the left hand side when we",
    "start": "236510",
    "end": "245590"
  },
  {
    "text": "built this ourselves and pointed at one of our test apps immediately visually",
    "start": "245590",
    "end": "251569"
  },
  {
    "text": "see things that you would not necessarily see but from the service map for example you can see the banding here",
    "start": "251569",
    "end": "258039"
  },
  {
    "text": "with clustering of response times these two areas in our case it turned",
    "start": "258039",
    "end": "263330"
  },
  {
    "text": "out the first lower band was actually cache misses and the upper band was a",
    "start": "263330",
    "end": "268400"
  },
  {
    "text": "under configured dynamodb table where we were performing retries but you can see how by having something visual like this",
    "start": "268400",
    "end": "275270"
  },
  {
    "text": "you can immediately sort of see things you would not otherwise have an insight",
    "start": "275270",
    "end": "280580"
  },
  {
    "text": "about so we'll come back to the details",
    "start": "280580",
    "end": "286910"
  },
  {
    "text": "as to how that app gets constructed using the API but as I said let me do a quick overview of the x-ray service for",
    "start": "286910",
    "end": "294620"
  },
  {
    "text": "those that may not be familiar with it as I said we build this thing called a",
    "start": "294620",
    "end": "301700"
  },
  {
    "start": "298000",
    "end": "298000"
  },
  {
    "text": "service map it's constructed from the traces that you send us we post process",
    "start": "301700",
    "end": "308600"
  },
  {
    "text": "process this typically a trace that you send to us will show up for you to be",
    "start": "308600",
    "end": "313850"
  },
  {
    "text": "able to look at in around 10 to 15 seconds and we build the service Maps in",
    "start": "313850",
    "end": "319400"
  },
  {
    "text": "about 15 to 30 seconds and so you if you just had it open and have it set to say",
    "start": "319400",
    "end": "325670"
  },
  {
    "text": "the last five minutes as the state changes occur inside your overall",
    "start": "325670",
    "end": "332180"
  },
  {
    "text": "service the combination of micro services you'll see it update in real time and you see there's some color",
    "start": "332180",
    "end": "339440"
  },
  {
    "text": "coding that goes on if everything is great then it's all green if there are HTTP status issues maybe faults or",
    "start": "339440",
    "end": "348080"
  },
  {
    "text": "errors or the third one being throttling if you for example are quoting a",
    "start": "348080",
    "end": "353420"
  },
  {
    "text": "dynamodb table and we start throttling you that will show up on here as purple so you can use you can visually inspect",
    "start": "353420",
    "end": "360320"
  },
  {
    "text": "by running the service map here to see exactly what's going on at any point in",
    "start": "360320",
    "end": "368390"
  },
  {
    "text": "time the other thing that's interesting about this is is that you can set the start and stop time up to 30 days ago so",
    "start": "368390",
    "end": "374840"
  },
  {
    "text": "you so if you know that a week ago something bad happened and you want to roll back and see the state of your",
    "start": "374840",
    "end": "380210"
  },
  {
    "text": "service then you can set the end point and the end point to be say an hour a week ago and",
    "start": "380210",
    "end": "386169"
  },
  {
    "text": "and be able to see exactly what was happening and then this is an entry point then to be able to click down into",
    "start": "386169",
    "end": "392020"
  },
  {
    "text": "more detail and see the individual traces that made up this map at the time",
    "start": "392020",
    "end": "399569"
  },
  {
    "text": "so you can click on one of these nodes and will display for you the histogram",
    "start": "399569",
    "end": "408099"
  },
  {
    "start": "400000",
    "end": "400000"
  },
  {
    "text": "of response times and also the collection of all the groupings of any",
    "start": "408099",
    "end": "414610"
  },
  {
    "text": "error codes status codes at the bottom and then you can again use the mouse to",
    "start": "414610",
    "end": "420279"
  },
  {
    "text": "drag and drop over an area of the histogram such that you can then go",
    "start": "420279",
    "end": "425740"
  },
  {
    "text": "inspect that particular area and in this particular case you can see we've checked the box for faults which are",
    "start": "425740",
    "end": "431710"
  },
  {
    "text": "HTTP 500s and what that does for you is is then automatically constructs what we",
    "start": "431710",
    "end": "438610"
  },
  {
    "text": "call a filter expression so in this case we just selected the faults the 500s and",
    "start": "438610",
    "end": "446339"
  },
  {
    "start": "445000",
    "end": "445000"
  },
  {
    "text": "what we then get is a summary list of traces that meet that criteria so I",
    "start": "446339",
    "end": "452080"
  },
  {
    "text": "don't know if you can see it always a problem with putting this kind of information on the screen but at the top",
    "start": "452080",
    "end": "458159"
  },
  {
    "text": "you can see a very top you can see we've constructed a filter expression of the",
    "start": "458159",
    "end": "463689"
  },
  {
    "text": "particular micro-service we're interested in in this case called W W and a the second part of the filter",
    "start": "463689",
    "end": "473800"
  },
  {
    "text": "expression being fault equals true fault meaning HTTP 500s and it's in in curly",
    "start": "473800",
    "end": "480069"
  },
  {
    "text": "brackets meaning please apply this only to this particular microservice not to",
    "start": "480069",
    "end": "486399"
  },
  {
    "text": "the full end-to-end trace so in this case now we pull back all of the summary",
    "start": "486399",
    "end": "492399"
  },
  {
    "text": "traces that have a 500 error code and then we can actually look at it from",
    "start": "492399",
    "end": "498490"
  },
  {
    "text": "different perspectives you can see there's a group by box there but spice standard we give you five or six",
    "start": "498490",
    "end": "504969"
  },
  {
    "text": "different ways to slice and dice so for example maybe by URL in this particular",
    "start": "504969",
    "end": "510520"
  },
  {
    "text": "case when the traces were created we populated the user field so that we're",
    "start": "510520",
    "end": "517448"
  },
  {
    "text": "able to see how the traces are map to particular users maybe this is an account ID or something like that so",
    "start": "517449",
    "end": "523919"
  },
  {
    "text": "this becomes a real useful way to understand customer impact when you're having an issue some kind of issue you",
    "start": "523919",
    "end": "529230"
  },
  {
    "text": "want to understand is it all our customers which is in this case or is it some subset of those customers you can",
    "start": "529230",
    "end": "536399"
  },
  {
    "text": "very quickly use the fact that you've populated that field to understand that",
    "start": "536399",
    "end": "542459"
  },
  {
    "text": "the customer impact that you're having and then we can click down even further",
    "start": "542459",
    "end": "548610"
  },
  {
    "text": "into an individual trace so this was a request the request passed through a set",
    "start": "548610",
    "end": "554010"
  },
  {
    "text": "of micro services and in this particular",
    "start": "554010",
    "end": "559200"
  },
  {
    "text": "case this threw off a trace traces can be at a hundred percent or some subset of that you can set a sampling rate now",
    "start": "559200",
    "end": "568380"
  },
  {
    "text": "we're them around how you want to sample and in this particular case we can see that there were a series of retries you",
    "start": "568380",
    "end": "577680"
  },
  {
    "text": "can see each retry had an exponential back-off which got a little bit longer and then after four or five attempts the",
    "start": "577680",
    "end": "586680"
  },
  {
    "text": "in this case this is the AWS SDK which does this automatically for you it",
    "start": "586680",
    "end": "591750"
  },
  {
    "text": "actually fails and you can see there's an error message there saying is because we're under provisioned on our dynamo DB",
    "start": "591750",
    "end": "597959"
  },
  {
    "text": "table so how do you get your traces",
    "start": "597959",
    "end": "605640"
  },
  {
    "start": "602000",
    "end": "602000"
  },
  {
    "text": "flowing out of your out of your your system your micro services there's",
    "start": "605640",
    "end": "612420"
  },
  {
    "text": "really two components to this there is the X ray SDK that we have been over the",
    "start": "612420",
    "end": "618810"
  },
  {
    "text": "last 12 months since we launched the service busily adding more and more languages so we're currently it's",
    "start": "618810",
    "end": "626279"
  },
  {
    "text": "available for java.net nodejs go which is in beta but will be final fairly soon",
    "start": "626279",
    "end": "634980"
  },
  {
    "text": "Python and other ones that are are in the wings and essentially what you do is",
    "start": "634980",
    "end": "640890"
  },
  {
    "text": "you add this SDK in with your code and it we call it a helper SDK and it",
    "start": "640890",
    "end": "646470"
  },
  {
    "text": "simplifies for you the work you have to do to get tracing enable for example just",
    "start": "646470",
    "end": "653430"
  },
  {
    "text": "by including the x-ray SDK in most of",
    "start": "653430",
    "end": "658470"
  },
  {
    "text": "the languages with a few statements it'll automatically start tracing your",
    "start": "658470",
    "end": "663930"
  },
  {
    "text": "HTTP requests pretty easily and you will call out to downstream AWS services so",
    "start": "663930",
    "end": "671340"
  },
  {
    "text": "that kind of gets you going get you a service map and then you can choose then to do further levels of instrumentation",
    "start": "671340",
    "end": "678720"
  },
  {
    "text": "yourself if you want to wrap certain functions or what have you you can do that such that your traces get more and",
    "start": "678720",
    "end": "685860"
  },
  {
    "text": "more useful as you invest more and more time there's also a second part of this",
    "start": "685860",
    "end": "692550"
  },
  {
    "text": "which is a daemon which you install on whether it be ec2 or ECS or elastic",
    "start": "692550",
    "end": "699330"
  },
  {
    "text": "Beanstalk and you can also do this on premise by the way because as long as",
    "start": "699330",
    "end": "705090"
  },
  {
    "text": "you can reach us and you have the credentials you can you can certainly use the the service the x-ray service",
    "start": "705090",
    "end": "711380"
  },
  {
    "text": "and the daemons job is to collect the output from the SDK essentially each",
    "start": "711380",
    "end": "718560"
  },
  {
    "text": "micro service throws off as a request passes through the set of micro services",
    "start": "718560",
    "end": "724110"
  },
  {
    "text": "each one as it gets lit up is going to send a piece of the trace which we call",
    "start": "724110",
    "end": "729990"
  },
  {
    "text": "a segment they all tie together with a common trace ID and each segment then",
    "start": "729990",
    "end": "736710"
  },
  {
    "text": "gets created for the request by the SDK and then gets sent to the local daemon",
    "start": "736710",
    "end": "742290"
  },
  {
    "text": "using UDP and the daemons job is to send that along then to the x-ray service and",
    "start": "742290",
    "end": "750410"
  },
  {
    "text": "the demon will buffer for about a second which is useful for very very high",
    "start": "750410",
    "end": "758520"
  },
  {
    "text": "performance situations where you maybe have thousands or hundreds of thousands of requests a second and the demon will",
    "start": "758520",
    "end": "765630"
  },
  {
    "text": "buffer that up and send it out in batches it's a pretty dumb in that all it is is it collects things and sends",
    "start": "765630",
    "end": "772560"
  },
  {
    "text": "them on it's written in go to be very very efficient and the important thing",
    "start": "772560",
    "end": "777960"
  },
  {
    "text": "is is that the linkage is a loosely coupled linkage between the SD kay and the demon through UDP the reason",
    "start": "777960",
    "end": "786060"
  },
  {
    "text": "why that's important is is that if anything happens to the demon or anything happens to our service it's not",
    "start": "786060",
    "end": "794550"
  },
  {
    "text": "going to impact your software your your software using our SDK will send these",
    "start": "794550",
    "end": "800490"
  },
  {
    "text": "segments that get created they're basically many JSON documents gets sent",
    "start": "800490",
    "end": "805590"
  },
  {
    "text": "out over UDP and then it's just a fire forget deal so it's a one-way thing if",
    "start": "805590",
    "end": "810600"
  },
  {
    "text": "anything happens downstream your software will not be impacted in any way which obviously is it's a critical",
    "start": "810600",
    "end": "816000"
  },
  {
    "text": "requirement the one exception to that is lambda our lambda friends did a",
    "start": "816000",
    "end": "821700"
  },
  {
    "text": "fantastic job of integrating x-ray directly into lambda if you have a lambda function you can go turn that on",
    "start": "821700",
    "end": "829970"
  },
  {
    "text": "and either through the console through the API and it will automatically start",
    "start": "829970",
    "end": "837240"
  },
  {
    "text": "tracing the function for you it puts an outer wrapper around the function if you",
    "start": "837240",
    "end": "843390"
  },
  {
    "text": "want find the grain detail you can also add in our sdk to your function and and",
    "start": "843390",
    "end": "850860"
  },
  {
    "text": "and use it to create sub segments yourself for your own code but lambda",
    "start": "850860",
    "end": "858090"
  },
  {
    "text": "very nicely gets you into the game and the interesting thing about lambda is is and not only do they trace your code the",
    "start": "858090",
    "end": "864900"
  },
  {
    "text": "functions that you provide but they also trace their code so the the lambda data",
    "start": "864900",
    "end": "870660"
  },
  {
    "text": "plane so you'll typically see on a latter when you use x-ray with lambda you actually see two nodes appear on",
    "start": "870660",
    "end": "876840"
  },
  {
    "text": "that service map the first one is their data plane showing you the time how long it takes them to invoke the function if",
    "start": "876840",
    "end": "883350"
  },
  {
    "text": "there are any retries startup periods etc useful for those of you that are",
    "start": "883350",
    "end": "888570"
  },
  {
    "text": "familiar with cold starts that can occur with lambda and tells you the complete",
    "start": "888570",
    "end": "895200"
  },
  {
    "text": "story not only about your function but also about what's going on inside there as I said the lambda data plane and this",
    "start": "895200",
    "end": "900840"
  },
  {
    "text": "kind of port ends the direction that we want to go with x-ray in that over time we would hope that this will be the case",
    "start": "900840",
    "end": "906600"
  },
  {
    "text": "with many other services as well so as you build solutions that are combinations of your",
    "start": "906600",
    "end": "913680"
  },
  {
    "text": "code and combinations of the building blocks the AWS building blocks we provide you'll be able to get really",
    "start": "913680",
    "end": "920850"
  },
  {
    "text": "good sense over time as to exactly what's going on where so they'll sort of",
    "start": "920850",
    "end": "931140"
  },
  {
    "start": "929000",
    "end": "929000"
  },
  {
    "text": "finish up this that pretty quick overview of x-ray itself you know the",
    "start": "931140",
    "end": "938040"
  },
  {
    "text": "traces that get sent to the x-ray service are very interesting on an",
    "start": "938040",
    "end": "944010"
  },
  {
    "text": "individual basis but also in aggregate the so the analogy I like to use is like",
    "start": "944010",
    "end": "950790"
  },
  {
    "text": "a loom when you're weaving a piece of fabric you know every time you put a",
    "start": "950790",
    "end": "956430"
  },
  {
    "text": "particular thread in place you're adding one more piece of the of the product",
    "start": "956430",
    "end": "964740"
  },
  {
    "text": "you're trying to build and each thread is interesting and useful and can give you information but in aggregate as they",
    "start": "964740",
    "end": "970440"
  },
  {
    "text": "keep adding you start to see a bigger picture and so because of the level of",
    "start": "970440",
    "end": "975660"
  },
  {
    "text": "granularity of information the traces give you on a on a per request basis we",
    "start": "975660",
    "end": "981990"
  },
  {
    "text": "can ask the x-ray service a whole bunch of interesting questions for example",
    "start": "981990",
    "end": "987840"
  },
  {
    "text": "things like you know what was the we had a bunch of API faults yesterday what was",
    "start": "987840",
    "end": "993030"
  },
  {
    "text": "the root cause you know we can roll back with our service map look at that time period and actually dig in and see well",
    "start": "993030",
    "end": "999300"
  },
  {
    "text": "what was going on at that particular point and we can do customer impact",
    "start": "999300",
    "end": "1004370"
  },
  {
    "text": "analysis how many api's we can we can slice and dice our data to see which a P",
    "start": "1004370",
    "end": "1011060"
  },
  {
    "text": "eyes have problems which ones were fine when I call downstream to one of my",
    "start": "1011060",
    "end": "1016580"
  },
  {
    "text": "partners are they meeting their SLA are the people that are calling me upstream",
    "start": "1016580",
    "end": "1022850"
  },
  {
    "text": "are they are we meeting their SLA that we gave to them how can I do my critical",
    "start": "1022850",
    "end": "1028069"
  },
  {
    "text": "code paths I can look at a trace see honor on a consistent basis that certain",
    "start": "1028070",
    "end": "1034579"
  },
  {
    "text": "parts of my API path say through multiple micro services one is being",
    "start": "1034579",
    "end": "1039740"
  },
  {
    "text": "particularly slow I can use that as a hint then to go and look at my code and to improve that is",
    "start": "1039740",
    "end": "1046569"
  },
  {
    "text": "AWS throttling me as AWS customers I'm sure you're familiar that you run into",
    "start": "1046570",
    "end": "1052060"
  },
  {
    "text": "this from time to time do I have a dynamodb table that I was running very hot and they've started throttling me",
    "start": "1052060",
    "end": "1058090"
  },
  {
    "text": "and I need to go and increase the number of I ops that I can have at my disposal",
    "start": "1058090",
    "end": "1065340"
  },
  {
    "text": "are some API is less performant than others and why and what does the stack",
    "start": "1065340",
    "end": "1071380"
  },
  {
    "text": "trace say when you when you in use our X ray SDK and you and you get a stack",
    "start": "1071380",
    "end": "1078250"
  },
  {
    "text": "trace that gets sent along with the segment that makes up the trace so that you can actually go look at errors and",
    "start": "1078250",
    "end": "1083920"
  },
  {
    "text": "look at the stack traces and have a good census of what's the the root issue so",
    "start": "1083920",
    "end": "1089470"
  },
  {
    "text": "this is just scraping the surface but that low-level trace by Trace request by",
    "start": "1089470",
    "end": "1096880"
  },
  {
    "text": "request information either individually or an aggregate can tell us a lot of",
    "start": "1096880",
    "end": "1102280"
  },
  {
    "text": "things about our service that we're trying to build and deliver to our customers by the way just a piece of",
    "start": "1102280",
    "end": "1109390"
  },
  {
    "text": "trivia we actually instrument x-ray on x-ray I call it x-ray on x-ray pricing they made",
    "start": "1109390",
    "end": "1118030"
  },
  {
    "start": "1116000",
    "end": "1116000"
  },
  {
    "text": "me put this in here there's a free tier the first hundred thousand traces are",
    "start": "1118030",
    "end": "1123760"
  },
  {
    "text": "recorded for free the first million trace is retrieved or scanned or free that works out to be",
    "start": "1123760",
    "end": "1131430"
  },
  {
    "text": "slightly less than one request a minute I think if you do the math so there's a lot of people that couldn't use x-ray",
    "start": "1131430",
    "end": "1138280"
  },
  {
    "text": "essentially for free beyond that beyond the free tier Tracey's recorded cost $5",
    "start": "1138280",
    "end": "1145210"
  },
  {
    "text": "per million traces so we count traces not the segments or partial segments so",
    "start": "1145210",
    "end": "1150910"
  },
  {
    "text": "if you have a trace with say 50 microservices or a trace with one micro service that they're going to cost the",
    "start": "1150910",
    "end": "1157360"
  },
  {
    "text": "same we don't charge you extra for having more complexity and then",
    "start": "1157360",
    "end": "1163240"
  },
  {
    "text": "retrieving or scanning traces cost 50 cents per million",
    "start": "1163240",
    "end": "1168810"
  },
  {
    "text": "okay so now let's get back to our magic application of the so called scatter",
    "start": "1170590",
    "end": "1175789"
  },
  {
    "text": "graph application and let's talk about what it does and then we'll figure out",
    "start": "1175789",
    "end": "1182149"
  },
  {
    "text": "how we can build it using the the api's so the way this works is the first thing",
    "start": "1182149",
    "end": "1188690"
  },
  {
    "text": "when you open up the application it will go and populate a drop-down on the top",
    "start": "1188690",
    "end": "1194809"
  },
  {
    "text": "left-hand corner there that drop down that will list all of the micro-services and edges that make up your particular",
    "start": "1194809",
    "end": "1202700"
  },
  {
    "text": "application and then what you do is you",
    "start": "1202700",
    "end": "1208129"
  },
  {
    "text": "select one of those particular micro-services or an edge between them",
    "start": "1208129",
    "end": "1213940"
  },
  {
    "text": "and the application will what it then",
    "start": "1213940",
    "end": "1219139"
  },
  {
    "text": "does is it goes off initially and will read three hours worth of response times",
    "start": "1219139",
    "end": "1226340"
  },
  {
    "text": "so 180 slices or one minute each and then it will plot on the horizontal each",
    "start": "1226340",
    "end": "1233629"
  },
  {
    "text": "one of those so you can see the distribution and response times and then at the bottom it will also plot the HTTP",
    "start": "1233629",
    "end": "1244309"
  },
  {
    "text": "statuses as well in in steady state this will just keep doing that every minute",
    "start": "1244309",
    "end": "1250279"
  },
  {
    "text": "that will add another another line of minutes worth of information and it'll",
    "start": "1250279",
    "end": "1257299"
  },
  {
    "text": "keep scrolling off to the left-hand side there so you have a rolling three hour window so as I said you can also",
    "start": "1257299",
    "end": "1266899"
  },
  {
    "text": "highlight areas and go and do a deep dive on that we'll come to that in a minute but let's just figure out how",
    "start": "1266899",
    "end": "1272840"
  },
  {
    "text": "this part alone works how we can use the x-ray API is to build this so this is",
    "start": "1272840",
    "end": "1280340"
  },
  {
    "start": "1280000",
    "end": "1280000"
  },
  {
    "text": "the list of api's that we have currently I'm sure we'll add more over time but",
    "start": "1280340",
    "end": "1286429"
  },
  {
    "text": "there's just five of them at the moment there's the put trace segment API this",
    "start": "1286429",
    "end": "1292460"
  },
  {
    "text": "is how you actually once you construct one of those segments typically done for you by the SDK this is how you get the",
    "start": "1292460",
    "end": "1302330"
  },
  {
    "text": "segment to our service now most folks are going to use that demon remember the relationship",
    "start": "1302330",
    "end": "1309170"
  },
  {
    "text": "between the SDK talking to the demon the demon does the job of sending the",
    "start": "1309170",
    "end": "1314380"
  },
  {
    "text": "segments on the particular micro service to the X ray service so most people are",
    "start": "1314380",
    "end": "1322160"
  },
  {
    "text": "not going to use this but it is there it's available should you want to write to our service directly yourself why",
    "start": "1322160",
    "end": "1328820"
  },
  {
    "text": "would you want to do that or maybe you have some special use case or that",
    "start": "1328820",
    "end": "1334430"
  },
  {
    "text": "doesn't the way the demon doesn't apply or maybe you want to do something with a framework or language that we don't yet",
    "start": "1334430",
    "end": "1340400"
  },
  {
    "text": "support so the functionality is there for you to override what we do and send",
    "start": "1340400",
    "end": "1346400"
  },
  {
    "text": "us traces directly we we document the schema of the JSON document that we",
    "start": "1346400",
    "end": "1355370"
  },
  {
    "text": "expect to be sent and then you can you can then send that along with the",
    "start": "1355370",
    "end": "1361850"
  },
  {
    "text": "information populated my only thing I",
    "start": "1361850",
    "end": "1367820"
  },
  {
    "text": "would say is be very very careful that you you do that if you're going to do it",
    "start": "1367820",
    "end": "1373430"
  },
  {
    "text": "directly on some kind of parallel thread or something that is a sync so that there's no tight coupling between your",
    "start": "1373430",
    "end": "1379610"
  },
  {
    "text": "application and us because things happen as we all know networks go down etc you don't want us to be able to do any harm",
    "start": "1379610",
    "end": "1386270"
  },
  {
    "text": "to you the batch get traces API that's about actually pulling back an",
    "start": "1386270",
    "end": "1392600"
  },
  {
    "text": "individual trace so once you've you've got say 50 micro services each of sent the request passes through all of them",
    "start": "1392600",
    "end": "1399380"
  },
  {
    "text": "and goes back again each sends their segments and their little sub segments all of that gets sent to us we assemble",
    "start": "1399380",
    "end": "1405020"
  },
  {
    "text": "it all into into one trace in the back and now you at some point you actually want to see that trace and if you know",
    "start": "1405020",
    "end": "1412070"
  },
  {
    "text": "the trace idea exactly you can supply that in the batch get traces API or a list of of trace IDs and then we'll pull",
    "start": "1412070",
    "end": "1421730"
  },
  {
    "text": "back in all its glory all its great depth of detail the traces for you they",
    "start": "1421730",
    "end": "1428930"
  },
  {
    "text": "get service graph API we're going to talk about that in a fair amount of depth in a minute but basically that's",
    "start": "1428930",
    "end": "1434960"
  },
  {
    "text": "the API that's turns for you a pretty complex JSON document with lots of goodies in it it's",
    "start": "1434960",
    "end": "1443240"
  },
  {
    "text": "what we use for example to build that service graph and it has all kinds of things like aggregate error counts and",
    "start": "1443240",
    "end": "1450320"
  },
  {
    "text": "faults response times and then for each of the micro-services and the edges",
    "start": "1450320",
    "end": "1459140"
  },
  {
    "text": "between them we are includes a histogram of the response times and that has that",
    "start": "1459140",
    "end": "1466820"
  },
  {
    "text": "then it has a lot of uses of course the get trace graph is similar to the get",
    "start": "1466820",
    "end": "1473030"
  },
  {
    "text": "service graph except that you provide it with a trace ID and then it will then",
    "start": "1473030",
    "end": "1479150"
  },
  {
    "text": "tell you for that given request for that particular trace ID exactly which subset",
    "start": "1479150",
    "end": "1484640"
  },
  {
    "text": "of all of the nodes actually did the",
    "start": "1484640",
    "end": "1489740"
  },
  {
    "text": "trace pass-through so you can use it as a way to say well for this particular ID trace ID for this particular request",
    "start": "1489740",
    "end": "1496450"
  },
  {
    "text": "which part of the of all my micro services did I pass through and then",
    "start": "1496450",
    "end": "1502520"
  },
  {
    "text": "they get trace summaries API it's about retrieving sort of summary abstractions",
    "start": "1502520",
    "end": "1510320"
  },
  {
    "text": "it'll digest if you will of the traces and its claim to fame and what sets it",
    "start": "1510320",
    "end": "1516470"
  },
  {
    "text": "apart is it's the API that you you give a filter a filter expression to so you",
    "start": "1516470",
    "end": "1523850"
  },
  {
    "text": "can build a fairly complex filter expression you saw a very simple one earlier where we had the service ID at",
    "start": "1523850",
    "end": "1532070"
  },
  {
    "text": "the top of the previous example but you can do things like you know response time greater than a particular number",
    "start": "1532070",
    "end": "1538580"
  },
  {
    "text": "and less than a particular number and",
    "start": "1538580",
    "end": "1543909"
  },
  {
    "text": "not okay and not okay shorthand for any HTTP response other than a 200 so you",
    "start": "1545320",
    "end": "1552680"
  },
  {
    "text": "can do construct fairly complicated filter expressions which then get put",
    "start": "1552680",
    "end": "1559700"
  },
  {
    "text": "into the get tray summaries API that then brings back subsets of the of the",
    "start": "1559700",
    "end": "1565550"
  },
  {
    "text": "individual traces and then you can take the ID IDs from that and plug that into the batch get traces",
    "start": "1565550",
    "end": "1572279"
  },
  {
    "text": "API if you then want to pull back all of the full information about a given trace",
    "start": "1572279",
    "end": "1581238"
  },
  {
    "start": "1581000",
    "end": "1581000"
  },
  {
    "text": "so let's look a little bit more at the service graph API as I said it's",
    "start": "1581330",
    "end": "1587789"
  },
  {
    "text": "actually derived for you from the traces that gets sent to the to the service you don't build it or anything it's built",
    "start": "1587789",
    "end": "1593669"
  },
  {
    "text": "for you and essentially it's returning the state of the service during this applied time range so as I had mentioned",
    "start": "1593669",
    "end": "1600269"
  },
  {
    "text": "earlier if you want to go back and see what the heck was going on with your your all your micro services together as",
    "start": "1600269",
    "end": "1606779"
  },
  {
    "text": "a single service last week for an hour you can plug that information in and",
    "start": "1606779",
    "end": "1612359"
  },
  {
    "text": "then go and go see what that is it has all the components services and edges",
    "start": "1612359",
    "end": "1618710"
  },
  {
    "text": "during that time range that you you are included and it has these sort of",
    "start": "1618710",
    "end": "1624720"
  },
  {
    "text": "aggregate things like response time request counts errors faults throttle counts for each of the individual",
    "start": "1624720",
    "end": "1630929"
  },
  {
    "text": "services and edges and then a set of histograms some for response times and",
    "start": "1630929",
    "end": "1638070"
  },
  {
    "text": "some for duration what's the difference between a response time and duration so",
    "start": "1638070",
    "end": "1643799"
  },
  {
    "text": "let's imagine I make an API call and my API has some payload information that my",
    "start": "1643799",
    "end": "1651480"
  },
  {
    "text": "code once I hit the API the code extracts the payload and fires up some",
    "start": "1651480",
    "end": "1656970"
  },
  {
    "text": "async threads so I call my API to dump my payload and immediately I signal back",
    "start": "1656970",
    "end": "1664080"
  },
  {
    "text": "that the API was successful whatever that time was would be the response time meanwhile now I fired up",
    "start": "1664080",
    "end": "1670830"
  },
  {
    "text": "some async activity it runs for five six seconds and then completes the total",
    "start": "1670830",
    "end": "1677129"
  },
  {
    "text": "time from when I emitted the API call to when the async activity finished is duration so in a sync world a",
    "start": "1677129",
    "end": "1684330"
  },
  {
    "text": "synchronous world we have a bunch of synchronous api's then response time and",
    "start": "1684330",
    "end": "1689429"
  },
  {
    "text": "duration is going to be the same but sometimes they're going to be different when you have these async components and",
    "start": "1689429",
    "end": "1694980"
  },
  {
    "text": "so we make this distinction so the we can model that in the in the x-ray",
    "start": "1694980",
    "end": "1702710"
  },
  {
    "text": "console and org we make that distinction also for you to model it in the API response so let's take a look at what",
    "start": "1702710",
    "end": "1714799"
  },
  {
    "start": "1711000",
    "end": "1711000"
  },
  {
    "text": "this API looks like when we use it we're going to use the AWS CLI here so the",
    "start": "1714799",
    "end": "1722510"
  },
  {
    "text": "first thing we have to do is establish a start time and an end time so it likes",
    "start": "1722510",
    "end": "1729169"
  },
  {
    "text": "its times in epoch so we'll create a variable here called epoch and stick in",
    "start": "1729169",
    "end": "1734299"
  },
  {
    "text": "it the current time in the epoch format and then we'll call the get service",
    "start": "1734299",
    "end": "1739549"
  },
  {
    "text": "Grass API with a start time of 10 minutes ago and then in time essentially",
    "start": "1739549",
    "end": "1746720"
  },
  {
    "text": "of now and so we've established our window in that way and what we get now",
    "start": "1746720",
    "end": "1752720"
  },
  {
    "text": "is a service graph and this is a very very short snippet and I apologize as",
    "start": "1752720",
    "end": "1758389"
  },
  {
    "start": "1753000",
    "end": "1753000"
  },
  {
    "text": "you know putting this stuff on slides is very difficult but essentially what you're going to get is a JSON document that will tell you everything you need",
    "start": "1758389",
    "end": "1764750"
  },
  {
    "text": "to know about what was going on with the state of yours of your world in that 10",
    "start": "1764750",
    "end": "1770360"
  },
  {
    "text": "minute period and it will give you a lots and lots of information that then you can use in various ways and in",
    "start": "1770360",
    "end": "1778580"
  },
  {
    "text": "addition to that also comes these histograms one for the duration and one",
    "start": "1778580",
    "end": "1785990"
  },
  {
    "text": "for the response time and there's going to be one of these for every service in every edge every micro service an edge",
    "start": "1785990",
    "end": "1791779"
  },
  {
    "text": "that is part of your world at that particular time so that sort of",
    "start": "1791779",
    "end": "1798230"
  },
  {
    "start": "1798000",
    "end": "1798000"
  },
  {
    "text": "summarized the get service graph for API um it's a cornucopia of information I",
    "start": "1798230",
    "end": "1805010"
  },
  {
    "text": "was really looking a way to use that word and it's it's it's a really really",
    "start": "1805010",
    "end": "1812090"
  },
  {
    "text": "useful a lot of information that is done by us in the service post-processing",
    "start": "1812090",
    "end": "1819769"
  },
  {
    "text": "those traces that you send us so the services have a name obviously so you",
    "start": "1819769",
    "end": "1824779"
  },
  {
    "text": "can reference them we indicate whether or not it is currently active in sending segments the",
    "start": "1824779",
    "end": "1831770"
  },
  {
    "text": "segments being the the piece of the story from that particular microservice for the overall trace request counts and",
    "start": "1831770",
    "end": "1837980"
  },
  {
    "text": "response times where status counters the histograms and something we're going to",
    "start": "1837980",
    "end": "1843020"
  },
  {
    "text": "talk about bit later is the get trace summaries time range which basically",
    "start": "1843020",
    "end": "1848300"
  },
  {
    "text": "says for this particular return from the service graph API what was the start and",
    "start": "1848300",
    "end": "1857180"
  },
  {
    "text": "end time of the traces that were considered to build it same thing for",
    "start": "1857180",
    "end": "1862250"
  },
  {
    "text": "the edges and we also have a one for the client on our service map you'll see a",
    "start": "1862250",
    "end": "1869240"
  },
  {
    "text": "little stick figure of course it's not always a person right sometimes there's another machine making an API call but",
    "start": "1869240",
    "end": "1874490"
  },
  {
    "text": "we chose to use a stick figure and that's the edge from the stick figure to",
    "start": "1874490",
    "end": "1880430"
  },
  {
    "text": "the first entry point or maybe there you have any of them the entry point that's why if you look at that edge you can see",
    "start": "1880430",
    "end": "1886220"
  },
  {
    "text": "the full end-to-end experience that that would that a consumer would use would",
    "start": "1886220",
    "end": "1892190"
  },
  {
    "text": "experience made up of all of the elements of the micro-services in",
    "start": "1892190",
    "end": "1897680"
  },
  {
    "text": "aggregate ok let's talk about these histograms a little bit as I said",
    "start": "1897680",
    "end": "1904880"
  },
  {
    "start": "1901000",
    "end": "1901000"
  },
  {
    "text": "response time and duration they are sparse and nonlinear in terms of the",
    "start": "1904880",
    "end": "1911600"
  },
  {
    "text": "scale so basically that means that means that the histograms do not use to fix bins so we don't have multiple bins for",
    "start": "1911600",
    "end": "1920450"
  },
  {
    "text": "you know particular it's a one second two second three second one have you if you did that that many of them would be",
    "start": "1920450",
    "end": "1926330"
  },
  {
    "text": "empty so instead we use this open source algorithm called a tea chai tea digest",
    "start": "1926330",
    "end": "1932480"
  },
  {
    "text": "here's the link to it and essentially what happens is that the histograms are",
    "start": "1932480",
    "end": "1938090"
  },
  {
    "text": "built dynamically to sort of fit the data so this particular example you can",
    "start": "1938090",
    "end": "1946190"
  },
  {
    "text": "see that the their sparse in that the deltas between the buckets and on the left hand side here the the buckets are",
    "start": "1946190",
    "end": "1952280"
  },
  {
    "text": "essentially this is the mean of each bucket so so the first one 0.1 seconds",
    "start": "1952280",
    "end": "1959450"
  },
  {
    "text": "there were 22 requests which were clustered this area and the mean was 0.1 and yeah",
    "start": "1959450",
    "end": "1966140"
  },
  {
    "text": "then you can see we go all the way out to suddenly from one point one zero to six point two nine and that's because",
    "start": "1966140",
    "end": "1972350"
  },
  {
    "text": "for some reason we had a bunch of really outliers and so we built a bucket out there to be able to capture those",
    "start": "1972350",
    "end": "1979520"
  },
  {
    "text": "outliers and at the P 99 or P 100 so it's dynamic in the way that it gets",
    "start": "1979520",
    "end": "1986450"
  },
  {
    "text": "built to hopefully do a much better job of then being able to be interpreted and to read to rebuild the the shape of the",
    "start": "1986450",
    "end": "1996350"
  },
  {
    "text": "histogram okay so having talked about",
    "start": "1996350",
    "end": "2001390"
  },
  {
    "text": "all of that let's go back to our little application here and let's talk about how we use that information to build and",
    "start": "2001390",
    "end": "2009940"
  },
  {
    "text": "use this API to actually build the scatter graph application so the first",
    "start": "2009940",
    "end": "2014950"
  },
  {
    "text": "thing we want to do is to populate that top left-hand corner drop-down so we want to list all of our services and all",
    "start": "2014950",
    "end": "2022450"
  },
  {
    "text": "of our micro services and all of our edges so what we do there is we call the",
    "start": "2022450",
    "end": "2029830"
  },
  {
    "text": "get service graph API we ask it we give it for the last five minutes and then we",
    "start": "2029830",
    "end": "2035770"
  },
  {
    "text": "pull out of the return all of the services and edges and then we put that",
    "start": "2035770",
    "end": "2040990"
  },
  {
    "text": "into the drop-down then we you then select one of those so let's say you",
    "start": "2040990",
    "end": "2047620"
  },
  {
    "text": "want to select micro service a so you click on on on that in the drop down and then what we do is we go off and we",
    "start": "2047620",
    "end": "2055419"
  },
  {
    "text": "issue 180 times each of one minute slice we call the get service graph API and we",
    "start": "2055420",
    "end": "2063639"
  },
  {
    "text": "pull back then and and use those histograms in the top half to plot the",
    "start": "2063640",
    "end": "2069970"
  },
  {
    "text": "distribution of response times and we use the information at the bottom the",
    "start": "2069970",
    "end": "2076840"
  },
  {
    "text": "other counts for HTTP status codes 200 300 400 etc 500 to then plot a an area",
    "start": "2076840",
    "end": "2084940"
  },
  {
    "text": "at the bottom that shows color-coded the various statuses we were using an",
    "start": "2084940",
    "end": "2093010"
  },
  {
    "text": "open-source graphics package with called Vega light again here's the link",
    "start": "2093010",
    "end": "2099490"
  },
  {
    "text": "to the github and then this in a steady",
    "start": "2099490",
    "end": "2104500"
  },
  {
    "text": "state every second an async timer fires and goes and gets into the next one",
    "start": "2104500",
    "end": "2110380"
  },
  {
    "text": "minute service graph and then adds that to the right-hand side and then the whole thing just Scrolls to the left so",
    "start": "2110380",
    "end": "2117910"
  },
  {
    "text": "that's sort of the steady state notice we do everything here from one API it's a very rich API but everything we need",
    "start": "2117910",
    "end": "2123970"
  },
  {
    "text": "to do this is in there now sort of part",
    "start": "2123970",
    "end": "2130270"
  },
  {
    "text": "two is well once we start seeing things of interest we're going to want to actually dig into those and understand",
    "start": "2130270",
    "end": "2136630"
  },
  {
    "text": "what's going on so we can actually highlight using the mouse we can highlight an area say outliers in the",
    "start": "2136630",
    "end": "2144600"
  },
  {
    "text": "response timer area at the top here or similarly we can suddenly we see a bunch",
    "start": "2144600",
    "end": "2149950"
  },
  {
    "text": "of say 500s at the bottom we can highlight that and with the view being",
    "start": "2149950",
    "end": "2155020"
  },
  {
    "text": "to going to see what's going on in the next level of detail diving down into that so we want to see the traces or the",
    "start": "2155020",
    "end": "2161800"
  },
  {
    "text": "trace information that's contributing to this problem so we selected this area",
    "start": "2161800",
    "end": "2169690"
  },
  {
    "text": "here at the bottom and what we then get are a set of traces that meet that",
    "start": "2169690",
    "end": "2175390"
  },
  {
    "text": "criteria so that the time range and in this particular case we're interested in",
    "start": "2175390",
    "end": "2181650"
  },
  {
    "text": "traces that are not okay ie non 200 response times",
    "start": "2181650",
    "end": "2191070"
  },
  {
    "text": "once we get their responses back we can actually pop them open and see a bit more information about each of the",
    "start": "2192560",
    "end": "2198740"
  },
  {
    "text": "traces in terms of summary information and we can also follow a deep link to",
    "start": "2198740",
    "end": "2206690"
  },
  {
    "text": "the console and actually see all of the specifics of the trace similarly we can",
    "start": "2206690",
    "end": "2213320"
  },
  {
    "text": "do the same thing up in the response time area we can select an area for say",
    "start": "2213320",
    "end": "2219320"
  },
  {
    "text": "a response time outliers this is a little different because now we have an x and a y axis we have the time over",
    "start": "2219320",
    "end": "2225950"
  },
  {
    "text": "which this is happening and then we also have the y axis in terms of the response",
    "start": "2225950",
    "end": "2231590"
  },
  {
    "text": "time range that we're interested in but again we're going to get a set of",
    "start": "2231590",
    "end": "2237380"
  },
  {
    "text": "returns that meet this criteria and then if we really want to get down into the",
    "start": "2237380",
    "end": "2244370"
  },
  {
    "text": "low level details that we can follow the link to the console a deep link and it will pop open for that particular trace",
    "start": "2244370",
    "end": "2251000"
  },
  {
    "text": "exactly what was going on in in detail so that we can try to understand why it",
    "start": "2251000",
    "end": "2257090"
  },
  {
    "text": "was that we had such a latent outlier so",
    "start": "2257090",
    "end": "2264800"
  },
  {
    "text": "how do we do that second part well here we're going to use a different API we",
    "start": "2264800",
    "end": "2270740"
  },
  {
    "text": "touched on it earlier but let's talk about a little bit more in detail it was just the get trace summaries API what",
    "start": "2270740",
    "end": "2278540"
  },
  {
    "text": "this does is it allows you to pull back a set of traces that meet the selection criteria they come back in this digest",
    "start": "2278540",
    "end": "2285170"
  },
  {
    "text": "form it's a subset of information typically it's things that are",
    "start": "2285170",
    "end": "2291850"
  },
  {
    "text": "searchable or considered to be very important you can for example add your",
    "start": "2291850",
    "end": "2297200"
  },
  {
    "text": "own annotations to traces so you might overlay the traces with business",
    "start": "2297200",
    "end": "2303650"
  },
  {
    "text": "information and then you can then use the get Trace summaries API to use a to",
    "start": "2303650",
    "end": "2310580"
  },
  {
    "text": "add a inject a filter expression and you can actually then search against those annotations that you put in place so you",
    "start": "2310580",
    "end": "2319280"
  },
  {
    "text": "typically what comes back from this API will be a set of trace IDs and then once you have those trace ideas you plug",
    "start": "2319280",
    "end": "2325970"
  },
  {
    "text": "that into the back get traces API to get the low-level detail so here's example",
    "start": "2325970",
    "end": "2332600"
  },
  {
    "text": "usage again with the CLI we can set our time again and now we call the get trace",
    "start": "2332600",
    "end": "2340400"
  },
  {
    "text": "summaries API with a start time of two minutes ago and an end time of one minute ago and this is just using time",
    "start": "2340400",
    "end": "2348230"
  },
  {
    "text": "and what we'll get back is a bunch of summaries so here's a couple of traces",
    "start": "2348230",
    "end": "2353420"
  },
  {
    "text": "that came back with summary information and you can see some of it you know what was the HTTP status what was the client",
    "start": "2353420",
    "end": "2360320"
  },
  {
    "text": "IP what was the calling URL what was the user agent etcetera etcetera in this",
    "start": "2360320",
    "end": "2367790"
  },
  {
    "text": "bottom top on the left hand side at the bottom there that were not any annotations but the response time was",
    "start": "2367790",
    "end": "2373640"
  },
  {
    "text": "0.8 for the duration was 0.8 for remember those are the same things in in",
    "start": "2373640",
    "end": "2378830"
  },
  {
    "text": "a sink case so you get that information back in this particular case if you look",
    "start": "2378830",
    "end": "2389630"
  },
  {
    "text": "we've we've added a filter expression so at the top there we we changed our time",
    "start": "2389630",
    "end": "2395090"
  },
  {
    "text": "here we went back 360 seconds 6 minutes",
    "start": "2395090",
    "end": "2400640"
  },
  {
    "text": "and went back and set the end time to 1 minute so this is now a 5-minute time slice but then we added the filter",
    "start": "2400640",
    "end": "2406310"
  },
  {
    "text": "expression - - filter expression to be a response time less than 0.02 and so you",
    "start": "2406310",
    "end": "2412160"
  },
  {
    "text": "can see that now here we have two responses both of which have response times less than 0.02 so that's kind of",
    "start": "2412160",
    "end": "2419810"
  },
  {
    "text": "the claim to fame for get trace summaries is the fact that you can plug in these filter expressions",
    "start": "2419810",
    "end": "2425950"
  },
  {
    "text": "the basket races API is then used to actually go get the specific traces",
    "start": "2427750",
    "end": "2433030"
  },
  {
    "text": "themselves and you're going to want to plug in a trace ID for that so typically these two api's go hand-in-hand and so",
    "start": "2433030",
    "end": "2440710"
  },
  {
    "text": "here's an example we've said our time again we we make a call to the get trace",
    "start": "2440710",
    "end": "2449320"
  },
  {
    "start": "2441000",
    "end": "2441000"
  },
  {
    "text": "summaries API with a start end time and the trace summaries asterisk ID that's",
    "start": "2449320",
    "end": "2458950"
  },
  {
    "text": "actually a AWS CLI construct that basically allows you to pull information",
    "start": "2458950",
    "end": "2464260"
  },
  {
    "text": "out of the JSON that gets returned so in this particular case we filter it out to only be the trace ID so what gets put in",
    "start": "2464260",
    "end": "2471910"
  },
  {
    "text": "the trace IDs variable is just a list of trace IDs that meet this criteria within",
    "start": "2471910",
    "end": "2477130"
  },
  {
    "text": "this case just the time window we don't have any filter expression and then we call the battacor trace API with the",
    "start": "2477130",
    "end": "2485349"
  },
  {
    "text": "list of trace IDs in the trace ID variable and we get back these very",
    "start": "2485349",
    "end": "2491520"
  },
  {
    "text": "complex long trace ID information that do not show very well on a slide okay so",
    "start": "2491520",
    "end": "2501220"
  },
  {
    "start": "2500000",
    "end": "2500000"
  },
  {
    "text": "going back to our application how do we use those API is to allow us to dig down",
    "start": "2501220",
    "end": "2508420"
  },
  {
    "text": "and find the areas of interest so in the case of where we're at the bottom here",
    "start": "2508420",
    "end": "2513609"
  },
  {
    "text": "were just interested in HTTP status requests that are typically not okay so",
    "start": "2513609",
    "end": "2521910"
  },
  {
    "text": "four hundred five hundred non 200s then",
    "start": "2521910",
    "end": "2527410"
  },
  {
    "text": "we select the area with our mouse we do some time alignment which I will talk to specifically in a minute cuz there's a",
    "start": "2527410",
    "end": "2533619"
  },
  {
    "text": "little foo there and then we make our",
    "start": "2533619",
    "end": "2538960"
  },
  {
    "text": "construct our filter expression which in this particular case is going to be service name or edge name and then in",
    "start": "2538960",
    "end": "2546790"
  },
  {
    "text": "curly bracket not okay and the curly brackets means apply this criteria to this particular",
    "start": "2546790",
    "end": "2553150"
  },
  {
    "text": "node or edge as opposed to the full trace so this allows you to sort of look",
    "start": "2553150",
    "end": "2560290"
  },
  {
    "text": "at micro-services and the undetermined look",
    "start": "2560290",
    "end": "2565670"
  },
  {
    "text": "for errors in that particular or faults in that particular place and then we",
    "start": "2565670",
    "end": "2572450"
  },
  {
    "text": "call the get trace summaries API with that filter expression and then we in our app we display up to 100 responses",
    "start": "2572450",
    "end": "2579370"
  },
  {
    "text": "and then use the summaries to allow you to pop it open to see that summary",
    "start": "2579370",
    "end": "2585200"
  },
  {
    "text": "information and then constructed the deep link back into the console using the trace ID so here we are this is the",
    "start": "2585200",
    "end": "2594020"
  },
  {
    "text": "response who is our list of traces from that area we highlighted this is our",
    "start": "2594020",
    "end": "2602030"
  },
  {
    "text": "ability to pop it open and see the summary information and start to give",
    "start": "2602030",
    "end": "2610130"
  },
  {
    "text": "you information about what's going on in here and of course you can always follow the deep link back to the console in the",
    "start": "2610130",
    "end": "2617900"
  },
  {
    "text": "other situation where we are now interested in outliers for our response",
    "start": "2617900",
    "end": "2624020"
  },
  {
    "text": "time this is a little different in that now we have both an X and a y-axis and",
    "start": "2624020",
    "end": "2630520"
  },
  {
    "text": "again we do some time adjustment here which I'll talk about in a second but",
    "start": "2630520",
    "end": "2635720"
  },
  {
    "text": "we're basically we are on the x axis we have the time period they were interested in the y axis the response",
    "start": "2635720",
    "end": "2642740"
  },
  {
    "text": "range but again now we call get trace summaries API with the right filter expression and then we display the",
    "start": "2642740",
    "end": "2649040"
  },
  {
    "text": "returns and that meet that criteria so",
    "start": "2649040",
    "end": "2655540"
  },
  {
    "text": "I've sort of referred to this now a couple of times that there's a little bit of finesse work that needs to be",
    "start": "2655540",
    "end": "2661730"
  },
  {
    "text": "done to to adjust the times let me explain that if we take this area we",
    "start": "2661730",
    "end": "2667910"
  },
  {
    "text": "highlight it here in terms of the outliers response time outliers we have",
    "start": "2667910",
    "end": "2674780"
  },
  {
    "text": "a it turns out we have an x-axis which was from 8:50 a.m. to 8:55 a.m. and a",
    "start": "2674780",
    "end": "2681680"
  },
  {
    "text": "y-axis which is 2.5 seconds and 3 seconds excuse me if we now index into",
    "start": "2681680",
    "end": "2690080"
  },
  {
    "text": "our histogram if you remember that's in the get service graph API return we can see that we have two",
    "start": "2690080",
    "end": "2698310"
  },
  {
    "text": "buckets there the one which has a mean of 2.6 and one that has a mean of 2.8",
    "start": "2698310",
    "end": "2704960"
  },
  {
    "text": "but that three-second upper band and",
    "start": "2704960",
    "end": "2712260"
  },
  {
    "text": "that 2.5 second lower band potentially could because of the fact that these are",
    "start": "2712260",
    "end": "2718370"
  },
  {
    "text": "means in the bucket there could be traces that are participating to that in",
    "start": "2718370",
    "end": "2725520"
  },
  {
    "text": "the upper bucket and the lower bucket which case the three seconds would be contributing to the 3.2 at the lower end",
    "start": "2725520",
    "end": "2731670"
  },
  {
    "text": "and the 2.5 will be contributing to the two point to in the law in the the three",
    "start": "2731670",
    "end": "2738600"
  },
  {
    "text": "seconds at the upper end and the 2.5 seconds in the 2.2 bucket at the lower end so what we do is is we widen our",
    "start": "2738600",
    "end": "2746910"
  },
  {
    "text": "time here our response time range so that we increase the chances we're going",
    "start": "2746910",
    "end": "2753390"
  },
  {
    "text": "to get all the right traces so we index into essentially the next bucket up and",
    "start": "2753390",
    "end": "2759020"
  },
  {
    "text": "adjust our time accordingly and the",
    "start": "2759020",
    "end": "2765300"
  },
  {
    "text": "other dimension the x-axis we requested",
    "start": "2765300",
    "end": "2770660"
  },
  {
    "text": "that we would were interested in the",
    "start": "2770660",
    "end": "2775770"
  },
  {
    "text": "time period of 852 855 so five minutes so as we know each one of these slices",
    "start": "2775770",
    "end": "2782720"
  },
  {
    "text": "are 5 minute 1 or 1 minute each of which we have five of them but the way the",
    "start": "2782720",
    "end": "2792690"
  },
  {
    "text": "trace is potentially mapped to this some of the traces might start beforehand and",
    "start": "2792690",
    "end": "2798690"
  },
  {
    "text": "some of them may start or finish before the 5 minutes is up so what we want to",
    "start": "2798690",
    "end": "2805530"
  },
  {
    "text": "do is to adjust this time to make sure that we are including all of the traces",
    "start": "2805530",
    "end": "2810900"
  },
  {
    "text": "and that we're not missing any and so it turns out luckily that the start time",
    "start": "2810900",
    "end": "2818220"
  },
  {
    "text": "and the stop time for the traces that make up the time slices we get out of",
    "start": "2818220",
    "end": "2825840"
  },
  {
    "text": "the get service graph a P I the the traces that contributed to",
    "start": "2825840",
    "end": "2830910"
  },
  {
    "text": "those that returned the start time and the stop time is actually in the return so we can pass through excuse me each",
    "start": "2830910",
    "end": "2839549"
  },
  {
    "text": "one of those find the earliest time and the latest time and then we can adjust our time range so we actually in this",
    "start": "2839549",
    "end": "2848369"
  },
  {
    "text": "case ended up adjusting our time from 8:50 a.m. to eight forty nine and ten seconds and eight 54 and 42 seconds",
    "start": "2848369",
    "end": "2857099"
  },
  {
    "text": "instead of 855 so now when we put these two things together we had originally",
    "start": "2857099",
    "end": "2863999"
  },
  {
    "start": "2860000",
    "end": "2860000"
  },
  {
    "text": "asked for a time window 852 a 55 and a response time window two point five and",
    "start": "2863999",
    "end": "2870599"
  },
  {
    "text": "three seconds we make these adjustments and what we actually end up doing now is calling the the API they get trace",
    "start": "2870599",
    "end": "2880289"
  },
  {
    "text": "summaries API with an adjusted time as you can see here in 49 10 and the end of",
    "start": "2880289",
    "end": "2886170"
  },
  {
    "text": "854 42 and similarly adjust our response time range so that we are confident that",
    "start": "2886170",
    "end": "2893910"
  },
  {
    "text": "we're going to get the right traces to be able to get the information that we're interested in",
    "start": "2893910",
    "end": "2900619"
  },
  {
    "start": "2903000",
    "end": "2903000"
  },
  {
    "text": "okay so one last look at the application",
    "start": "2904150",
    "end": "2909550"
  },
  {
    "text": "in action here here's one another one that we we looked at recently you can",
    "start": "2909550",
    "end": "2915790"
  },
  {
    "text": "see that on the right there what we started to get a lot of banding outliers",
    "start": "2915790",
    "end": "2922540"
  },
  {
    "text": "or bad outliers so when we selected it and dug in and then followed it all the",
    "start": "2922540",
    "end": "2929530"
  },
  {
    "text": "way to the particular specific example traces into the console this was a",
    "start": "2929530",
    "end": "2938470"
  },
  {
    "text": "particularly interesting one because it actually responded with a 200",
    "start": "2938470",
    "end": "2943680"
  },
  {
    "text": "but had a high latency and when you dig in here what you can see is is that this",
    "start": "2943680",
    "end": "2950050"
  },
  {
    "text": "is our friend again dynamodb not being appropriately provisioned and what's",
    "start": "2950050",
    "end": "2956230"
  },
  {
    "text": "happening is is the AWS SDK is retrying and it keeps retrying and backs off",
    "start": "2956230",
    "end": "2962110"
  },
  {
    "text": "exponentially does this multiple title and then ultimately succeeds and so you",
    "start": "2962110",
    "end": "2968650"
  },
  {
    "text": "get a success but it took a long time to do it because of the exponential back-off so that's the kind of insights",
    "start": "2968650",
    "end": "2975490"
  },
  {
    "text": "that you can begin to get with this that otherwise you would be scratching your head as to why why am I getting high",
    "start": "2975490",
    "end": "2981190"
  },
  {
    "text": "latency there it's a 200 everything seems fine all right",
    "start": "2981190",
    "end": "2989250"
  },
  {
    "start": "2987000",
    "end": "2987000"
  },
  {
    "text": "further extension ideas well what else can you do with this here's a few ideas",
    "start": "2989250",
    "end": "2995410"
  },
  {
    "text": "I thought of once you download the code and play with it one thing you could do",
    "start": "2995410",
    "end": "3000570"
  },
  {
    "text": "is maybe have a way in which you can put a line on the for each of your services",
    "start": "3000570",
    "end": "3008780"
  },
  {
    "text": "microservices you can indicate a threshold over which if it gets exceeded",
    "start": "3008780",
    "end": "3014160"
  },
  {
    "text": "by some number of incursions you'd emits a cloud watch event sent to email or",
    "start": "3014160",
    "end": "3020220"
  },
  {
    "text": "through your favorite paging service you could take a previous period say",
    "start": "3020220",
    "end": "3026850"
  },
  {
    "text": "yesterday or a week ago and overlay the two on top of each other and look to see if maybe yesterday you did a deployment",
    "start": "3026850",
    "end": "3035790"
  },
  {
    "text": "and now 24 hours later you want to compare this with the same day yesterday to see are there any differences now",
    "start": "3035790",
    "end": "3042870"
  },
  {
    "text": "that we've done the deployment another idea would be to make sure that in your",
    "start": "3042870",
    "end": "3048930"
  },
  {
    "text": "logging if you using cloud watch logs you always write the trace ID and then you could using this app you could also",
    "start": "3048930",
    "end": "3057140"
  },
  {
    "text": "go to do a search in cloud watch logs and pull back some of the log lines and",
    "start": "3057140",
    "end": "3062430"
  },
  {
    "text": "compare that also and overlay that with with the trace information so this is",
    "start": "3062430",
    "end": "3069660"
  },
  {
    "text": "just some ideas I'm sure you could think of plenty more yourselves this is where",
    "start": "3069660",
    "end": "3075720"
  },
  {
    "start": "3075000",
    "end": "3075000"
  },
  {
    "text": "it is it's on github AWS - samples AWS -",
    "start": "3075720",
    "end": "3081900"
  },
  {
    "text": "x-ray - scatter - sample it's actually written in JavaScript and Ruby so",
    "start": "3081900",
    "end": "3088680"
  },
  {
    "text": "download it play with it extend it and hopefully you'll find just by itself",
    "start": "3088680",
    "end": "3095040"
  },
  {
    "text": "some of you will just be able to use it as an adjunct tool in addition to what",
    "start": "3095040",
    "end": "3100830"
  },
  {
    "text": "we currently provide and then hopefully some of you will be able to extend it and do some more interesting things with",
    "start": "3100830",
    "end": "3106440"
  },
  {
    "text": "it so that's it thank you for staying we're down to eight minutes there are",
    "start": "3106440",
    "end": "3114120"
  },
  {
    "text": "any questions [Applause]",
    "start": "3114120",
    "end": "3122679"
  }
]
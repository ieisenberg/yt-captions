[
  {
    "start": "0",
    "end": "106000"
  },
  {
    "text": "Hi, everyone. My name is Lester, and I am an Associate Solutions Architect at AWS.",
    "start": "0",
    "end": "5000"
  },
  {
    "text": "In this demo video, I'll be covering on how you can use Generative AI to query your structured data with Amazon Bedrock structured data retrieval.",
    "start": "5000",
    "end": "14000"
  },
  {
    "text": "As part of Amazon Bedrock knowledge base, it is now able to support natural language querying to retrieve structured data from your data sources.",
    "start": "14000",
    "end": "23000"
  },
  {
    "text": "Here's an illustration showing the process.",
    "start": "23000",
    "end": "26000"
  },
  {
    "text": "The user first submits a question such as which day of the week usually generates the most sales.",
    "start": "26000",
    "end": "31000"
  },
  {
    "text": "With Bedrock knowledge base connected to your structured data sources, it is able to read the relevant database schemas",
    "start": "31000",
    "end": "38000"
  },
  {
    "text": "and then understands how to generate the SQL query",
    "start": "38000",
    "end": "41000"
  },
  {
    "text": "including statements such as joining different tables, running group bys, or even performing calculations on columns.",
    "start": "41000",
    "end": "49000"
  },
  {
    "text": "The SQL query is then executed on the querying engine to return the results, such as the table showing the total sales grouped by different days of the week.",
    "start": "49000",
    "end": "58000"
  },
  {
    "text": "Bedrock uses this data returned to reply the user in a summarized narrative response.",
    "start": "58000",
    "end": "65000"
  },
  {
    "text": "For example, the response to the earlier question will be \"The highest sales occurs on Sundays with 60 million..\", followed by any other information that is returned.",
    "start": "65000",
    "end": "75000"
  },
  {
    "text": "Here's the architecture diagram where you will first create a Bedrock knowledge base for your structured data store and then you will select a querying engine such as Amazon Redshift, which is our AWS data warehouse service.",
    "start": "75000",
    "end": "88000"
  },
  {
    "text": "You will also select the location of the metadata storage, such as Redshift or Glue data catalog to inform Bedrock on where the data schemas are stored and specify which databases or schemas to query from.",
    "start": "88000",
    "end": "102000"
  },
  {
    "text": "For the demo itself, we have a fictitious company called AnyCompany, which is an events company and they have data sets storing ticket sales, user information, and event details.",
    "start": "102000",
    "end": "112000"
  },
  {
    "start": "106000",
    "end": "166000"
  },
  {
    "text": "And they are interested in building a Generative AI chatbot assistant where internal employees can query their structured data to retrieve insights.",
    "start": "112000",
    "end": "122000"
  },
  {
    "text": "For example, they want to know which event has the highest sales.",
    "start": "122000",
    "end": "126000"
  },
  {
    "text": "On average, do holidays generate more sales and which timing of the day usually generate the most number of ticket transactions?",
    "start": "126000",
    "end": "134000"
  },
  {
    "text": "For the demo architecture diagram, I have a Redshift serverless already being set up, and I have a few tables related to sales and events, being loaded into my Redshift serverless workgroup.",
    "start": "134000",
    "end": "148000"
  },
  {
    "text": "And so for my metadata storage that I'm selecting, it will also be within Redshift as well.",
    "start": "148000",
    "end": "153000"
  },
  {
    "text": "Here is the example of the data schema that we will be using in this demo, and we'll be focusing on the tables for sales, event, and date.",
    "start": "153000",
    "end": "162000"
  },
  {
    "text": "Let's move to the AWS console to showcase the demo.",
    "start": "162000",
    "end": "166000"
  },
  {
    "start": "166000",
    "end": "209000"
  },
  {
    "text": "So I've provisioned a Redshift serverless with a few tables being provisioned inside already.",
    "start": "166000",
    "end": "172000"
  },
  {
    "text": "So for example, we have the sales table, the date table, as well as the event table.",
    "start": "172000",
    "end": "177000"
  },
  {
    "text": "So the sales table contains information about each sales transaction in terms of quantity sold, the price paid, which event is this for and which date was this on.",
    "start": "177000",
    "end": "187000"
  },
  {
    "text": "For the date data set, we have information about what the date is and also whether if it's a holiday or not.",
    "start": "187000",
    "end": "197000"
  },
  {
    "text": "For the events data set, it shows information about the events itself, for example, the date of the event, the event name, and the start time.",
    "start": "197000",
    "end": "208000"
  },
  {
    "text": "So let's proceed to the AWS console and search for Amazon Bedrock.",
    "start": "208000",
    "end": "215000"
  },
  {
    "start": "209000",
    "end": "355000"
  },
  {
    "text": "We can then scroll down to click on knowledge bases.",
    "start": "215000",
    "end": "220000"
  },
  {
    "text": "We will proceed to create a new knowledge base with a structured data store.",
    "start": "220000",
    "end": "224000"
  },
  {
    "text": "We can give the knowledge base a name and select Redshift as the query engine.",
    "start": "224000",
    "end": "230000"
  },
  {
    "text": "We will then select the IAM role.",
    "start": "230000",
    "end": "232000"
  },
  {
    "text": "In this case, I created a new service role or you could use an existing one.",
    "start": "232000",
    "end": "236000"
  },
  {
    "text": "And for the query engine, I have already set up a Redshift serverless workgroup, so I'll proceed to select that.",
    "start": "236000",
    "end": "244000"
  },
  {
    "text": "And for the authentication to Redshift, I will be using via an IAM role.",
    "start": "244000",
    "end": "248000"
  },
  {
    "text": "And on the storage metadata, there is the option to use Redshift or Glue data catalog.",
    "start": "248000",
    "end": "253000"
  },
  {
    "text": "In my case, I have Redshift and I'll be accessing the dev database.",
    "start": "253000",
    "end": "260000"
  },
  {
    "text": "There are a few things that you can set in the query configurations.",
    "start": "260000",
    "end": "263000"
  },
  {
    "text": "The first thing is descriptions whereby you can provide the table name, the column name, as well as the description.",
    "start": "263000",
    "end": "269000"
  },
  {
    "text": "This can help to improve the query accuracy, for example, if you are using short form for column names.",
    "start": "269000",
    "end": "276000"
  },
  {
    "text": "Next up, you'll be able to specify specific table names or column names that you would like to include or to exclude for SQL generation too.",
    "start": "276000",
    "end": "285000"
  },
  {
    "text": "And lastly, you'll be able to select curated queries whereby you can include sample questions and SQL queries that correspond to them to improve the generation of these queries.",
    "start": "285000",
    "end": "295000"
  },
  {
    "text": "Once that's done, I can go ahead and click next and create the knowledge base itself.",
    "start": "295000",
    "end": "300000"
  },
  {
    "text": "And the next thing I have to do is to actually grant permissions to the IAM service role that was created by Bedrock to be able to have access to the schemas in Redshift.",
    "start": "300000",
    "end": "310000"
  },
  {
    "text": "So I run a command called SELECT * from SVV_USER_INFO to see the users in my Redshift workgroup currently.",
    "start": "310000",
    "end": "317000"
  },
  {
    "text": "So here I have the IAM service role that is shown below, and this corresponds to the service role that was created in Bedrock.",
    "start": "317000",
    "end": "328000"
  },
  {
    "text": "The next thing I have to do is to run the grant command and in my case, I granted them permissions to all tables in the public schemas.",
    "start": "328000",
    "end": "338000"
  },
  {
    "text": "Now Bedrock would then be able to access these Redshift schemas in the query generation.",
    "start": "338000",
    "end": "344000"
  },
  {
    "text": "Once it's done, let's go ahead and click on sync in the query engine.",
    "start": "344000",
    "end": "348000"
  },
  {
    "text": "So this will be syncing with the data source which is in Redshift.",
    "start": "348000",
    "end": "353000"
  },
  {
    "text": "And after a while, it will be completed and I can go ahead and test this knowledge base and I selected Claude as my foundation model for this testing purpose.",
    "start": "353000",
    "end": "364000"
  },
  {
    "start": "355000",
    "end": "648000"
  },
  {
    "text": "So I'll just do a simple query on what is the total sales and you can see that the results is returned to me and you'll be able to see the SQL query that is actually running behind the scenes.",
    "start": "364000",
    "end": "376000"
  },
  {
    "text": "Now let's run this SQL query to ensure that the data shown is correct.",
    "start": "376000",
    "end": "382000"
  },
  {
    "text": "And yes, it matches with the value that is being returned by Amazon Bedrock.",
    "start": "382000",
    "end": "389000"
  },
  {
    "text": "Now we also have to be able to run a command from my system query history to see that the Bedrock has actually ran the SQL query command into my Redshift workgroup as well.",
    "start": "389000",
    "end": "403000"
  },
  {
    "text": "Now I can ask another question eg. which event has the highest sales.",
    "start": "403000",
    "end": "407000"
  },
  {
    "text": "So in this case, it returns to me the name of the event as well as how many tickets sold and how much was the total revenue.",
    "start": "407000",
    "end": "413000"
  },
  {
    "text": "Now, let's go ahead and see what was the SQL command that was given to us.",
    "start": "413000",
    "end": "417000"
  },
  {
    "text": "And in this case, you can actually see that it actually combines different data sets together, different tables, the sales table as well as the events table, and understands which column to join based on.",
    "start": "417000",
    "end": "431000"
  },
  {
    "text": "which columns to group by and which columns to order by.",
    "start": "431000",
    "end": "437000"
  },
  {
    "text": "And let's run this query and this is where you're able to see the data that is being returned to Bedrock and from there it was then replied to you back in natural language as well.",
    "start": "437000",
    "end": "449000"
  },
  {
    "text": "Now, as a marketing person, I'm perhaps interested in asking a question like, on average, do holidays generate more sales?",
    "start": "449000",
    "end": "455000"
  },
  {
    "text": "So we can see the reply given by Bedrock, but let's first check out the SQL query that is being ran.",
    "start": "455000",
    "end": "462000"
  },
  {
    "text": "So, in this case, you'll be able to see that it structured a query whereby it created different cases for holidays and non-holidays and it joined the two tables together, the sales table as well as the date table which contains information about whether a date is a holiday.",
    "start": "462000",
    "end": "477000"
  },
  {
    "text": "It groups by and then it orders by certain columns as well, and this is the table that is returned back to Bedrock.",
    "start": "477000",
    "end": "484000"
  },
  {
    "text": "It returns to you in a natural language reply.",
    "start": "484000",
    "end": "487000"
  },
  {
    "text": "So that we can see that on average there is higher sales for holidays compared to non-holiday events.",
    "start": "487000",
    "end": "494000"
  },
  {
    "text": "Next, I'm also interested to understand which day of the week would generate the most sales?",
    "start": "494000",
    "end": "500000"
  },
  {
    "text": "So over here it states that Sundays followed by Wednesdays and Thursdays have the highest sales wheares Saturdays have the lowest total sales.",
    "start": "500000",
    "end": "507000"
  },
  {
    "text": "So let's look at the SQL query that was being generated by Bedrock itself.",
    "start": "507000",
    "end": "514000"
  },
  {
    "text": "Let's copy that and run that in Redshift so you can see that it has created the query and has joined the two tables - sales and date table, and has grouped by the day column.",
    "start": "514000",
    "end": "526000"
  },
  {
    "text": "So let's see the final table that is being returned.",
    "start": "526000",
    "end": "531000"
  },
  {
    "text": "And you'll be able to see that even though we are using short form for the day, Bedrock is actually able to interpret this as the weekday names and be able to reply back to you in natural language as well.",
    "start": "531000",
    "end": "550000"
  },
  {
    "text": "Now, lastly, I'm interested in understanding which is the timing of the day that usually generates the most number of ticket transactions.",
    "start": "550000",
    "end": "556000"
  },
  {
    "text": "This may matter to me because if I'm running marketing promotions, maybe there are certain timing of the day that I want to run at.",
    "start": "556000",
    "end": "565000"
  },
  {
    "text": "So let's click on show details to copy the SQL query that was being generated.",
    "start": "565000",
    "end": "571000"
  },
  {
    "text": "And in Redshift itself, let's look at the sales table first, and for each row it's a sales transaction and it also includes the sales timing in datetime format.",
    "start": "571000",
    "end": "582000"
  },
  {
    "text": "Now, when I copy the SQL that was being generated.",
    "start": "582000",
    "end": "587000"
  },
  {
    "text": "And I paste it into Redshift.",
    "start": "587000",
    "end": "589000"
  },
  {
    "text": "You'll see that it actually even helps me to extract the hours from the saletime column into the hours, and then after that it performs the GROUP BY and then does the ORDER BY as well.",
    "start": "589000",
    "end": "602000"
  },
  {
    "text": "So this exactly replies to what I needed, which is understanding which timing of the day, whereby we have the most number of transactions as well as the total sales amount.",
    "start": "602000",
    "end": "615000"
  },
  {
    "text": "And this tallies with the information that was being returned to Bedrock as well.",
    "start": "615000",
    "end": "620000"
  },
  {
    "text": "Next up, we can see that there are 3 different types of responses we can generate.",
    "start": "620000",
    "end": "623000"
  },
  {
    "text": "The first one is just retrieving the data only.",
    "start": "623000",
    "end": "626000"
  },
  {
    "text": "So for example, in my query of what is the total sales, for example, it's only the data that is being written to me.",
    "start": "626000",
    "end": "633000"
  },
  {
    "text": "I can also just return the SQL query itself, with the same query of what is the total sales, the response would then just be the SQL statement itself.",
    "start": "633000",
    "end": "645000"
  },
  {
    "text": "So instead of the Bedrock playground, this is how you can do it if you are using Bedrock APIs.",
    "start": "645000",
    "end": "651000"
  },
  {
    "start": "648000",
    "end": "709000"
  },
  {
    "text": "In my case, I have set up a Juypter notebook to use the boto3 library for Python to call my Bedrock APIs.",
    "start": "651000",
    "end": "658000"
  },
  {
    "text": "I'll first create a boto3 client for Bedrock agent runtime and use the retrieve_and_generate API.",
    "start": "658000",
    "end": "665000"
  },
  {
    "text": "I'll give this as my input text, which is the prompt, and then give it the knowledge base ID as well as the model ARN that I want to use, which I'm using Claude 3.5 Sonnet v2.",
    "start": "665000",
    "end": "675000"
  },
  {
    "text": "So here you can see the raw response that is being written to me, but let's break it down into the three parts that Bedrock can return the results to me in.",
    "start": "675000",
    "end": "683000"
  },
  {
    "text": "So the first one is the retrieval and response generation in terms of replying back to you in natural language.",
    "start": "683000",
    "end": "689000"
  },
  {
    "text": "The next one is that you can return back just the data only and in this case, I have converted that into a dataframe to display.",
    "start": "689000",
    "end": "699000"
  },
  {
    "text": "And lastly, you can be able to generate and return just the SQL query only and in this case, you will be able to see the SELECT statement that is being returned.",
    "start": "699000",
    "end": "709000"
  },
  {
    "start": "709000",
    "end": "740000"
  },
  {
    "text": "So now with Bedrock knowledge base supporting structured data stores, you are able to query both unstructured data as well as structured data.",
    "start": "709000",
    "end": "717000"
  },
  {
    "text": "In your querying engine, you'll be selecting Redshift as the querying engine, and your underlying data, it could come from RDS having a zero ETL into Redshift, or perhaps you have set up a data lake using S3 as well as Glue data catalog.",
    "start": "717000",
    "end": "731000"
  },
  {
    "text": "In both cases, Redshift will be able to query this underlying data and be able to return these results back to your users.",
    "start": "731000",
    "end": "739000"
  },
  {
    "text": "And with that we have come to the end of this demo.",
    "start": "739000",
    "end": "742000"
  },
  {
    "text": "Thank you for listening in.",
    "start": "742000",
    "end": "745000"
  }
]
[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "good morning everyone and welcome to this session so today we'll be talking",
    "start": "469",
    "end": "5520"
  },
  {
    "text": "about cost effective dated management with s3 batch operations and the s3",
    "start": "5520",
    "end": "10679"
  },
  {
    "text": "storage classes am i coming through all right on the audio looking good great thanks for joining me this morning my",
    "start": "10679",
    "end": "16770"
  },
  {
    "text": "name is Rob Wilson I'm a product manager on the Amazon s3 team and I'm excited to go through this session with you we'll",
    "start": "16770",
    "end": "22410"
  },
  {
    "text": "have a lot of information here about a couple of our new product launches and how they fit into the overall s3 portfolio and we'll also have a demo",
    "start": "22410",
    "end": "28710"
  },
  {
    "text": "that we walkthrough so for s3 batch operations you'll see a console view and we'll walk through it step by step so recapping some of that",
    "start": "28710",
    "end": "36989"
  },
  {
    "start": "35000",
    "end": "129000"
  },
  {
    "text": "talking at a high level about the pillars of cost optimization we want to",
    "start": "36989",
    "end": "42000"
  },
  {
    "text": "kind of highlight some of the different considerations you might go through when you're thinking about how to huge storage in Amazon s3 then we'll talk",
    "start": "42000",
    "end": "48360"
  },
  {
    "text": "about how to place your data so how to use the different storage classes we use things like lifecycle management and",
    "start": "48360",
    "end": "53850"
  },
  {
    "text": "then storage class analysis together and see how you could do that manually yourself but then we'll move ahead to intelligent tearing which is our new",
    "start": "53850",
    "end": "59820"
  },
  {
    "text": "storage class where it automatically moves from our frequent ear to an infrequent ear so that will help you get",
    "start": "59820",
    "end": "65760"
  },
  {
    "text": "the cost savings but it automates that work for you so you just put the data in that storage class and then it'll move over time and we'll talk about exactly",
    "start": "65760",
    "end": "72510"
  },
  {
    "text": "how that works then we'll go through some different examples so we get a lot of questions from customers about like",
    "start": "72510",
    "end": "78420"
  },
  {
    "text": "here's roughly the workload I'm working with the size of the objects here's how they're accessed what's the right storage class for me we've got a few",
    "start": "78420",
    "end": "85320"
  },
  {
    "text": "examples we'll walk through we can talk through some of the considerations and some of the decisions you might some of",
    "start": "85320",
    "end": "90570"
  },
  {
    "text": "the my considerations that might help you make that decision and then last will go to s3 batch operations so we'll",
    "start": "90570",
    "end": "95729"
  },
  {
    "text": "talk about the feature overall this is a feature that's really about convenience and simplicity so whenever you have that",
    "start": "95729",
    "end": "101340"
  },
  {
    "text": "moment where somebody says we really need to go back and encrypt all our data and you have hundreds of millions of objects and you say how do I even get",
    "start": "101340",
    "end": "107159"
  },
  {
    "text": "started I don't want my development team to shift over to a tool just for that one-time work you can just take a list",
    "start": "107159",
    "end": "112710"
  },
  {
    "text": "of those objects hand it to s3 batch operations and do work like that in an automated fashion so that's a way to get",
    "start": "112710",
    "end": "118290"
  },
  {
    "text": "started and get up and running with that and then the demo will show you step-by-step how it's really simple to get started in the console and then",
    "start": "118290",
    "end": "124799"
  },
  {
    "text": "that'll map easily over to the SDKs API CLI if you're doing it that way so we'll start first with the pillars of",
    "start": "124799",
    "end": "132209"
  },
  {
    "start": "129000",
    "end": "289000"
  },
  {
    "text": "cost optimization this is a few different factors that we'll talk about when you're starting to",
    "start": "132209",
    "end": "137280"
  },
  {
    "text": "think about how should I use storage in the cloud and I think this will be applicable whether you already have",
    "start": "137280",
    "end": "142950"
  },
  {
    "text": "storage in Amazon s3 or whether you're looking at it as something that might be in the future or something on the horizon for you so first you want to",
    "start": "142950",
    "end": "149820"
  },
  {
    "text": "think about application requirements and you want to say how is this data got to be accessed and used something like log",
    "start": "149820",
    "end": "155280"
  },
  {
    "text": "files where it might be likely that within the first 30 days someone might go back and ask questions or do some",
    "start": "155280",
    "end": "160920"
  },
  {
    "text": "analysis but after that it's really just held onto for retention and compliance purposes where you hold on to it for",
    "start": "160920",
    "end": "166350"
  },
  {
    "text": "another 5 years 10 years whatever the right number is for you that gives you a lot of information about how you might",
    "start": "166350",
    "end": "172170"
  },
  {
    "text": "want to use our storage classes or about what might be the right kind of savings",
    "start": "172170",
    "end": "177180"
  },
  {
    "text": "that you could get from using that to glacier over time the next one is thinking about data organization and",
    "start": "177180",
    "end": "182459"
  },
  {
    "text": "this will come into play in a few different places so if you want to put all your data in one bucket there are",
    "start": "182459",
    "end": "187830"
  },
  {
    "text": "benefits to that and that's gonna help you decide ok well now I'd need to think about the policies and how I might be",
    "start": "187830",
    "end": "192990"
  },
  {
    "text": "able to treat data differently within that bucket we also have customers that when you're designing new workloads and",
    "start": "192990",
    "end": "198510"
  },
  {
    "text": "new applications if you do things like put the data in different prefixes or apply different object tags that can",
    "start": "198510",
    "end": "205440"
  },
  {
    "text": "also help you design different policies that are specific to that type of data",
    "start": "205440",
    "end": "210450"
  },
  {
    "text": "so the data organization you'll see filters come up a few times about prefixes and object tags then",
    "start": "210450",
    "end": "216330"
  },
  {
    "text": "right-sizing take some information from the application requirements and then helps you make decisions about how much data",
    "start": "216330",
    "end": "222570"
  },
  {
    "text": "should be an s3 standard how much should be and maybe the infrequent access storage classes and then is there a long",
    "start": "222570",
    "end": "228060"
  },
  {
    "text": "tail and is most of the data moving to glacier over time so that's something that the initial information you might",
    "start": "228060",
    "end": "233370"
  },
  {
    "text": "go through when you think about the application requirements will drive that decision later on about how to use the",
    "start": "233370",
    "end": "238410"
  },
  {
    "text": "different storage classes and then lastly and you'll see this come up again when we talk about lifecycle policies",
    "start": "238410",
    "end": "243750"
  },
  {
    "text": "and storage class analysis there's that first step where you start saying how is",
    "start": "243750",
    "end": "248820"
  },
  {
    "text": "this application going to behave what's going to be the certain uptick of a particular feature among my customer base but then you might find that your",
    "start": "248820",
    "end": "255870"
  },
  {
    "text": "initial assumptions don't exactly match with reality and you're seeing different patterns and different usage patterns",
    "start": "255870",
    "end": "261959"
  },
  {
    "text": "over time so you want to decide like is that worth it for you to go back",
    "start": "261959",
    "end": "267280"
  },
  {
    "text": "can change what you might be doing with lifecycle policies change what storage class you're using or is that something",
    "start": "267280",
    "end": "273280"
  },
  {
    "text": "where intelligent hearing might be a better fit because you've just offloaded that work and then this monitor optimized repeat never really comes",
    "start": "273280",
    "end": "279730"
  },
  {
    "text": "across you're never really comes to mind because you can see that automated savings by using intelligent hearing",
    "start": "279730",
    "end": "284830"
  },
  {
    "text": "storage class so skipping ahead here",
    "start": "284830",
    "end": "290490"
  },
  {
    "start": "289000",
    "end": "352000"
  },
  {
    "text": "customers choose Amazon s3 for a number of different reasons this slide really highlights the benefits of Amazon s3",
    "start": "290490",
    "end": "296410"
  },
  {
    "text": "overall a few of them will really highlight today are that manageability and that'll come into play for storage",
    "start": "296410",
    "end": "301450"
  },
  {
    "text": "class analysis lifecycle policies and s3 batch operations and then when we talk about the storage classes and look at",
    "start": "301450",
    "end": "307360"
  },
  {
    "text": "the overall storage portfolio you'll see things like availability and durability and how they differ across the different",
    "start": "307360",
    "end": "313000"
  },
  {
    "text": "storage classes the scalability of s3 is something where you can grow to petabytes or exabytes of scale so you do",
    "start": "313000",
    "end": "319540"
  },
  {
    "text": "have the flexibility to start growing an s3 and really scale over time and then on security it really is the focus of",
    "start": "319540",
    "end": "326200"
  },
  {
    "text": "other talks but it is absolutely the focus of giving you the controls you need to control security at the account",
    "start": "326200",
    "end": "331900"
  },
  {
    "text": "level with something like block public access and at the bucket level with the same feature or doing things like",
    "start": "331900",
    "end": "337510"
  },
  {
    "text": "controlling access at the object level with object access control lists or doing that with iam policies as well so",
    "start": "337510",
    "end": "344979"
  },
  {
    "text": "you have all the flexibility to design the security and access control requirements that your business needs so",
    "start": "344979",
    "end": "352500"
  },
  {
    "start": "352000",
    "end": "663000"
  },
  {
    "text": "now I want to introduce you to the overall s3 storage class kind of",
    "start": "352500",
    "end": "357520"
  },
  {
    "text": "portfolio and depending on when you've last looked at s3 there are some new additions to this so intelligent tearing",
    "start": "357520",
    "end": "363190"
  },
  {
    "text": "is a new storage class announced at reinvent and then glacier deep archive launched as generally available earlier",
    "start": "363190",
    "end": "368979"
  },
  {
    "text": "this year so that helped us to expand our portfolio and really gives you that many more choices when you say what's",
    "start": "368979",
    "end": "374740"
  },
  {
    "text": "the right storage class for me and we'll talk about a lot of these when we talk about the different workloads later on at a high level",
    "start": "374740",
    "end": "381520"
  },
  {
    "text": "s3 standard is really for kind of a general purpose storage class so it's for frequently accessed data it's about",
    "start": "381520",
    "end": "388300"
  },
  {
    "text": "two cents a month and it's really gonna meet your needs there's no retrieval fees no object size requirements so a lot of customers find themselves",
    "start": "388300",
    "end": "394390"
  },
  {
    "text": "starting with s3 standard and saying when I learn more over time then I'll take advantage of the other storage",
    "start": "394390",
    "end": "399400"
  },
  {
    "text": "classes in the middle of this slide you see standard infrequent access and one zone infrequent access so as the name implies",
    "start": "399400",
    "end": "406910"
  },
  {
    "text": "they're really designed for infrequently access storage but you're gonna see later on it still has millisecond access",
    "start": "406910",
    "end": "412730"
  },
  {
    "text": "your end-users not gonna see any performance difference and then as long as that data is being accessed about one",
    "start": "412730",
    "end": "418700"
  },
  {
    "text": "time or less per month you're probably gonna see savings by using these infrequent access storage classes so if",
    "start": "418700",
    "end": "424910"
  },
  {
    "text": "your data is only really being frequently accessed for the first month you really want to think about how you can use infrequent access after that to",
    "start": "424910",
    "end": "431390"
  },
  {
    "text": "still get the performance you need but to save on the cost and then as we move to the right on this slide you see",
    "start": "431390",
    "end": "437330"
  },
  {
    "text": "glacier and then glacier deep archive glacier and glacial deep archive give",
    "start": "437330",
    "end": "442370"
  },
  {
    "text": "you the cost savings you need especially when data is kept for compliance purposes or something you want to maintain for the long term but you're",
    "start": "442370",
    "end": "448850"
  },
  {
    "text": "not sure exactly when it's gonna be needed if it's not customer-facing and it doesn't need to be there in milliseconds when they click on a webpage or when they try to access the",
    "start": "448850",
    "end": "455330"
  },
  {
    "text": "data through another means then glacier can be a great fit you can move terabytes and petabytes of historical",
    "start": "455330",
    "end": "460760"
  },
  {
    "text": "data to glacier when you need it you can get it back in minutes or hours but if you don't need it you're saving that",
    "start": "460760",
    "end": "466460"
  },
  {
    "text": "much on the storage because you're really using a storage class that's optimized for the archive storage so",
    "start": "466460",
    "end": "472160"
  },
  {
    "text": "that's an overview of these different storage classes let's look at some different specifics here the millisecond",
    "start": "472160",
    "end": "477770"
  },
  {
    "text": "access that we talked about applies to every storage class all the way over to the glacier ones and then with glacier",
    "start": "477770",
    "end": "483170"
  },
  {
    "text": "you get two minutes or hours of access so that's the real difference there when customers say when should I think about",
    "start": "483170",
    "end": "488420"
  },
  {
    "text": "glacier you'll want to think about workloads that can tolerate waiting that additional latency to get the data back",
    "start": "488420",
    "end": "493870"
  },
  {
    "text": "but for a lot of customers they'll find that whether it's a matter of object age",
    "start": "493870",
    "end": "498980"
  },
  {
    "text": "or there might be some data that can always fit that profile and you can just put it to glacier right away so that'll",
    "start": "498980",
    "end": "504320"
  },
  {
    "text": "give you the flexibility there the next one we want to look at is of the storage footprint and we use the term resiliency",
    "start": "504320",
    "end": "511100"
  },
  {
    "text": "when we think of how we store your data within s3 we're storing it not only across addition different data centers",
    "start": "511100",
    "end": "518150"
  },
  {
    "text": "but across different availability zones so for nearly all of our storage classes",
    "start": "518150",
    "end": "523460"
  },
  {
    "text": "your data is going to be stored in three or more availability zones and each of those availability zones may be multiple",
    "start": "523460",
    "end": "529250"
  },
  {
    "text": "data centers so you have to think about how much redundancy is built into that a system where we can have multiple",
    "start": "529250",
    "end": "535519"
  },
  {
    "text": "failures and your data will still be safe it will still be accessible the one exception to this where you want to",
    "start": "535519",
    "end": "540950"
  },
  {
    "text": "think about well what data might be recreated or what data might be less important if it is lost for whatever",
    "start": "540950",
    "end": "547070"
  },
  {
    "text": "reason that's where you see the additional savings of one's own in frequent access relative to standard infrequent access where there is about a",
    "start": "547070",
    "end": "553730"
  },
  {
    "text": "20% savings between the two storage classes but it is stored in a single availability zone so if anything happens",
    "start": "553730",
    "end": "559760"
  },
  {
    "text": "to that single availability zone your data may not be accessible or it may not be recoverable so that's where you want",
    "start": "559760",
    "end": "564860"
  },
  {
    "text": "to say is one Zone in frequent access worth it and what storage might be able to fit that type of profile and the kind",
    "start": "564860",
    "end": "572149"
  },
  {
    "text": "of less resiliency of that particular storage class and then you see the prices going across so glacier deep",
    "start": "572149",
    "end": "577940"
  },
  {
    "text": "archive is the one I want to highlight here that price there where there are a number of decimal points before you get to any significant digits it is about $1",
    "start": "577940",
    "end": "585139"
  },
  {
    "text": "per terabyte per month so that is really inexpensive storage especially for that archive and large amounts of storage",
    "start": "585139",
    "end": "591019"
  },
  {
    "text": "that you might be keeping compliance as a theme I'm going to keep coming back to but if you have requirements to hold on to data for the long term but you know",
    "start": "591019",
    "end": "597019"
  },
  {
    "text": "you're not going to be accessing it glacier deep archive a 7 thing customers are really excited about because of the cost savings and then down the bottom",
    "start": "597019",
    "end": "605089"
  },
  {
    "text": "here are some other considerations so with standard what we talked about the general purpose storage class really",
    "start": "605089",
    "end": "610430"
  },
  {
    "text": "great for any type of workloads there's no additional data that we've added when we add this slide but for the other",
    "start": "610430",
    "end": "615470"
  },
  {
    "text": "storage classes there may be retrieval fees monitoring fees or minimum object",
    "start": "615470",
    "end": "621230"
  },
  {
    "text": "sizes minimum storage durations so because these storage classes are optimized for infrequent access they're",
    "start": "621230",
    "end": "626329"
  },
  {
    "text": "optimized for archive storage and storing data for longer periods of time these are some of the things you want to",
    "start": "626329",
    "end": "632930"
  },
  {
    "text": "think about so when we talk about accessing data about one time or less per month that's where something like the retrieval fee for standard",
    "start": "632930",
    "end": "639260"
  },
  {
    "text": "infrequent access or one zone and frequent access comes into play and having that minimum object size then",
    "start": "639260",
    "end": "645760"
  },
  {
    "text": "allows us to optimize a storage class differently but then also helps you get the right amount of savings because when we have a",
    "start": "645760",
    "end": "652040"
  },
  {
    "text": "minimum object size of 128 kilobytes if you're storing something much smaller than that it'll still be charged at 128",
    "start": "652040",
    "end": "658459"
  },
  {
    "text": "kilobytes so it may not be a good fit to move to those particular storage causes now now that we've seen all these",
    "start": "658459",
    "end": "665660"
  },
  {
    "start": "663000",
    "end": "692000"
  },
  {
    "text": "different storage class options I want to talk about how you can move data across these storage classes because that initial moment when you put",
    "start": "665660",
    "end": "671990"
  },
  {
    "text": "data in Amazon s3 that's not the moment where you're locked in you have a lot of flexibility to then move to different",
    "start": "671990",
    "end": "677629"
  },
  {
    "text": "storage classes over time and that's a pretty common pattern for customers I may start in standard and then after a",
    "start": "677629",
    "end": "683149"
  },
  {
    "text": "period of time move it to infrequent access and then after the first year say now the state is ready to move to glacier because it's not going to be",
    "start": "683149",
    "end": "689089"
  },
  {
    "text": "accessed it's not going to require that millisecond access pattern so every year",
    "start": "689089",
    "end": "694610"
  },
  {
    "start": "692000",
    "end": "703000"
  },
  {
    "text": "I just want to highlight one of the messages here customers save millions of dollars using storage class analysis and",
    "start": "694610",
    "end": "699649"
  },
  {
    "text": "life cycle policies because they're moving data to these lower cost storage classes so how does that work and you",
    "start": "699649",
    "end": "706009"
  },
  {
    "start": "703000",
    "end": "845000"
  },
  {
    "text": "know how can you get the information you need to make those decisions about what storage class to use well look at some",
    "start": "706009",
    "end": "711170"
  },
  {
    "text": "of those things now for storage class analysis so this is a portion of the console view that I put up on the screen",
    "start": "711170",
    "end": "716629"
  },
  {
    "text": "and it's really showing you that transition point between when data's classified is frequently accessed and",
    "start": "716629",
    "end": "722240"
  },
  {
    "text": "when it's classified is infrequently accessed and that's really the the deciding moment or that's the the moment",
    "start": "722240",
    "end": "728089"
  },
  {
    "text": "you're looking for when you look at your storage class analysis output results so how this feature works is you turn it on",
    "start": "728089",
    "end": "733730"
  },
  {
    "text": "you can turn it on at the bucket level and monitor everything in a bucket or you could turn it on for a single prefix",
    "start": "733730",
    "end": "739639"
  },
  {
    "text": "within that bucket or all the tag data within a bucket so it allows you to be more specific on what data you want to",
    "start": "739639",
    "end": "745220"
  },
  {
    "text": "monitor after about 30 days so it looks at that data's access for about a month maybe a",
    "start": "745220",
    "end": "750439"
  },
  {
    "text": "little bit more than a month depending on what it's seeing and then it gives you this output so right here you're",
    "start": "750439",
    "end": "755600"
  },
  {
    "text": "seeing a classification on the the kind of console view here so from 60 to 90",
    "start": "755600",
    "end": "761000"
  },
  {
    "text": "days any data that's within that age range you see that the data retrieval of",
    "start": "761000",
    "end": "766100"
  },
  {
    "text": "about a petabyte is actually larger than the data stored which is 682 terabytes",
    "start": "766100",
    "end": "771199"
  },
  {
    "text": "so because the amount of access and the retrievals are larger that's where you",
    "start": "771199",
    "end": "776269"
  },
  {
    "text": "won't see the savings yet in the infrequent access storage classes because of that retrieval fee even though the storage is less the retrieval",
    "start": "776269",
    "end": "782870"
  },
  {
    "text": "fee would mean you'll likely be paying more if you used infrequent access storage but once that data crosses the",
    "start": "782870",
    "end": "788480"
  },
  {
    "text": "three-month mark and gets that 90 to 180 days category there's about 400 terabytes of data but it's a very low",
    "start": "788480",
    "end": "794930"
  },
  {
    "text": "access there's still some access customers still are trying to access this data maybe internal users are still accessing",
    "start": "794930",
    "end": "800779"
  },
  {
    "text": "them but you see the amount of data retrieved is so much smaller than the amount of storage so then storage class analysis",
    "start": "800779",
    "end": "807679"
  },
  {
    "text": "classifies that isn't frequently accessed and it may be a good fit to move to standard infrequent access or if your data resiliency requirements are",
    "start": "807679",
    "end": "814819"
  },
  {
    "text": "such that one's own infrequent access might be a good fit you can move it there as well so we're monitoring the",
    "start": "814819",
    "end": "819829"
  },
  {
    "text": "access patterns giving you a recommendation and then you're gonna take that and build a lifecycle policy so if you like this number you say 90",
    "start": "819829",
    "end": "825799"
  },
  {
    "text": "days looks like the clear mark for this particular workload then build a lifecycle policy and say at 90 days all",
    "start": "825799",
    "end": "831079"
  },
  {
    "text": "the data moves to standard infrequent access and then you can kind of decide how long should it stay in standard infrequent access is that in perpetuity",
    "start": "831079",
    "end": "837379"
  },
  {
    "text": "does it move to glacier after that but this amount of data allows you to make that decision and it does so in a data-driven way off of historical",
    "start": "837379",
    "end": "843589"
  },
  {
    "text": "patterns so for those familiar with lifecycle policies or those who are new to them this might be a recap for some",
    "start": "843589",
    "end": "850309"
  },
  {
    "start": "845000",
    "end": "962000"
  },
  {
    "text": "so lifecycle policies can be used to move data across our storage classes so to tear down to lower cost storage",
    "start": "850309",
    "end": "856220"
  },
  {
    "text": "classes or you can use the same policies to actually expire storage so we talked about a few examples where you might be",
    "start": "856220",
    "end": "862369"
  },
  {
    "text": "moving the data to you know lower cost storage classes but you might say after five years I actually want to just",
    "start": "862369",
    "end": "868730"
  },
  {
    "text": "delete all the data that meets a certain criteria so you can use lifecycle policies for that as well the storage",
    "start": "868730",
    "end": "874399"
  },
  {
    "text": "class analysis results will guide your writing of a lifecycle policy or you may know enough about an application that",
    "start": "874399",
    "end": "879889"
  },
  {
    "text": "you can just write that policy yourself and then on the last part here something that we talked about before but you can",
    "start": "879889",
    "end": "885769"
  },
  {
    "text": "filter these rules so it might not make sense to write something for an entire bucket you could filter that down to an individual prefix or everything tagged",
    "start": "885769",
    "end": "892489"
  },
  {
    "text": "with certain value so let's walk through some examples here's one where the data",
    "start": "892489",
    "end": "897529"
  },
  {
    "text": "starts in standard and then after 60 days it's all moving to Sandra infrequent access and then after 180",
    "start": "897529",
    "end": "903559"
  },
  {
    "text": "days from the creation time from when it was first put then it moves to glacier so there's a pretty common pattern for",
    "start": "903559",
    "end": "909350"
  },
  {
    "text": "customers where you want to maintain that millisecond access for some period of time but then after a half a year",
    "start": "909350",
    "end": "914480"
  },
  {
    "text": "here it's fine moving to glacier and you're saving that much on the storage in this next example start everything in",
    "start": "914480",
    "end": "921619"
  },
  {
    "text": "intelligent hearing we're going to talk about that storage class in more detail in a second but starting an intelligent",
    "start": "921619",
    "end": "926959"
  },
  {
    "text": "hearing where it's already moving between a frequent and an infrequent hear but I only need that for about a half a year and then I'm going to move",
    "start": "926959",
    "end": "932660"
  },
  {
    "text": "it to and then in this example we add that final step where it's still an intelligent earring moves to glacier and",
    "start": "932660",
    "end": "939290"
  },
  {
    "text": "now glacier deep archive where we saw at $1 per terabyte per month may be a great fit for data for the long term so that's",
    "start": "939290",
    "end": "945800"
  },
  {
    "text": "something you may want to consider and you may already have life cycle policies that are moving data to glacier that you may think well maybe a half a year or a",
    "start": "945800",
    "end": "952100"
  },
  {
    "text": "year after that maybe I should just move it to Glacier deep archive for the rest of its life so that might be something where you have existing rules today that",
    "start": "952100",
    "end": "958459"
  },
  {
    "text": "you say hey it does make sense to add a glacier deep archive step at the end so",
    "start": "958459",
    "end": "963800"
  },
  {
    "text": "now let's talk about our newest in one of our newest storage classes which is intelligent hearing and we'll first kind",
    "start": "963800",
    "end": "969740"
  },
  {
    "text": "of talk about the basics of how it works and then go into where this might be a really good fit for you to get started",
    "start": "969740",
    "end": "974779"
  },
  {
    "start": "974000",
    "end": "1151000"
  },
  {
    "text": "with so here you see how data comes into intelligent hearing and it all starts in",
    "start": "974779",
    "end": "980690"
  },
  {
    "text": "the frequent access here so all data that goes to intelligent hearing you can directly put it there or you can use a",
    "start": "980690",
    "end": "986029"
  },
  {
    "text": "lifecycle policy to move to intelligent hearing it will all start in the frequent accessed here and then after 30",
    "start": "986029",
    "end": "991519"
  },
  {
    "text": "days we're looking at the access patterns on that object if that individual object is not accessed for 30",
    "start": "991519",
    "end": "997010"
  },
  {
    "text": "days so then it moves to the infrequent ear and the way to think about these tiers is the frequent ears price the",
    "start": "997010",
    "end": "1002200"
  },
  {
    "text": "same as s3 standard and the infrequent ear is priced the same as standard infrequent access so you getting the",
    "start": "1002200",
    "end": "1008620"
  },
  {
    "text": "three or more availability zone resiliency of those storage classes after 30 days if the objects not touched",
    "start": "1008620",
    "end": "1014380"
  },
  {
    "text": "it moves to the infrequent ear if it's accessed again then it moves back to the frequent ear and then 30 days later it",
    "start": "1014380",
    "end": "1019990"
  },
  {
    "text": "may move back down again so it's looking at each individual object and making that decision so you want to think about",
    "start": "1019990",
    "end": "1025569"
  },
  {
    "text": "how kind of heterogeneous your objects may be and it may be that ten objects are read very frequently and they're",
    "start": "1025569",
    "end": "1031839"
  },
  {
    "text": "read all the time and it kind of masked the overall numbers where you see a lot of access in a particular bucket but it",
    "start": "1031839",
    "end": "1036880"
  },
  {
    "text": "may be a very small subset of the data well we'll just keep those objects in the frequent ear but everything else that's never been touched moves to the",
    "start": "1036880",
    "end": "1042850"
  },
  {
    "text": "infrequent ear and you see what's typically about 40 percent savings depending on the object size and",
    "start": "1042850",
    "end": "1048188"
  },
  {
    "text": "depending on how much data moves but you're getting that savings between the frequent and infrequent ear so let's go",
    "start": "1048189",
    "end": "1053860"
  },
  {
    "text": "into a little more detail on this next slide so it's automatically moving them and it's moving them on the object level",
    "start": "1053860",
    "end": "1059820"
  },
  {
    "text": "it's monitoring the access patterns over time so once data is moved to this storage class it really starts to make",
    "start": "1059820",
    "end": "1066400"
  },
  {
    "text": "that optimization and really starts to make those decisions right away it will be in the frequent ear for the first 30 days",
    "start": "1066400",
    "end": "1071680"
  },
  {
    "text": "but those accesses that happen over that period of time will affect the timing of subsequent transitions there's no",
    "start": "1071680",
    "end": "1078700"
  },
  {
    "text": "performance impact so I'll come back to this theme this is a question we get from a lot of customers like should I be",
    "start": "1078700",
    "end": "1083950"
  },
  {
    "text": "worried about my internal users external users of my storage are they gonna notice that I'm now using intelligent hearing and saving more in the storage",
    "start": "1083950",
    "end": "1089920"
  },
  {
    "text": "no performance impact they're still gonna get millisecond access they're still gonna see the same performance they were before and there's no",
    "start": "1089920",
    "end": "1096430"
  },
  {
    "text": "operational overhead for you so all of the steps we talked about where storage class analysis taking that data drive",
    "start": "1096430",
    "end": "1102820"
  },
  {
    "text": "building a lifecycle policy that is some manual work it's not a lot it's pretty convenient the information is readily",
    "start": "1102820",
    "end": "1108490"
  },
  {
    "text": "available but as things change over time if you're an intelligent hearing you've just offloaded all that work you don't",
    "start": "1108490",
    "end": "1114070"
  },
  {
    "text": "have to think about how it might change over time millisecond access more than three AZ's and then the monitoring fee",
    "start": "1114070",
    "end": "1119830"
  },
  {
    "text": "per object is just something I'll mention if you have a lot of small objects in kind of the kilobyte range that monitoring fee which is per object",
    "start": "1119830",
    "end": "1126730"
  },
  {
    "text": "because we are looking at the access patterns over time when the objects are smaller that monitoring fee becomes a",
    "start": "1126730",
    "end": "1132100"
  },
  {
    "text": "larger kind of percentage of your bill and what you'd be paying for in storage when your objects are larger in the",
    "start": "1132100",
    "end": "1137410"
  },
  {
    "text": "megabyte gigabyte range that monitoring fee is so small that it really won't affect the savings that you're achieving between those two tiers so it's",
    "start": "1137410",
    "end": "1144190"
  },
  {
    "text": "something to think about and when we look at a few examples you'll see how that guides some different customers decisions about whether to use",
    "start": "1144190",
    "end": "1149800"
  },
  {
    "text": "intelligent hearing or not so there's some few few ideal use cases and this is",
    "start": "1149800",
    "end": "1156280"
  },
  {
    "start": "1151000",
    "end": "1233000"
  },
  {
    "text": "kind of big picture but may help you think about what might be a good fit so first is Big Data data Lakes where you",
    "start": "1156280",
    "end": "1162640"
  },
  {
    "text": "may have a lot of different applications trying to access the data you've worked hard to aggregate a lot of data into the",
    "start": "1162640",
    "end": "1168550"
  },
  {
    "text": "data link but it's hard to map to exactly what teams what applications are reading that data and what that access",
    "start": "1168550",
    "end": "1174010"
  },
  {
    "text": "patterns going to look like is it going to be very discrete moments over time or are you going to get pretty heavy reads on a consistent basis and how do you",
    "start": "1174010",
    "end": "1181000"
  },
  {
    "text": "think about an overall bucket worth of data where there may be a lot of access on 10% of that data but almost everything else is never touched so by",
    "start": "1181000",
    "end": "1187570"
  },
  {
    "text": "having an intelligent hearing storage class we're making object by object decisions it's something where what",
    "start": "1187570",
    "end": "1193180"
  },
  {
    "text": "could have been a complex access pattern over an entire data like now become something you can just hand off and do",
    "start": "1193180",
    "end": "1198190"
  },
  {
    "text": "that at the object level for enterprises it may be about the amount of teams that are accessing data",
    "start": "1198190",
    "end": "1203590"
  },
  {
    "text": "so with a lot of different teams using the data with a lot of different teams using the same place to store the data can be hard to map to and understand",
    "start": "1203590",
    "end": "1210770"
  },
  {
    "text": "exactly what the data patterns are going to look like so intelligent tearing may be a really good fit there as well and for startups we'll just highlight",
    "start": "1210770",
    "end": "1217040"
  },
  {
    "text": "where startups want to put their investment and their time into growing their business and managing storage",
    "start": "1217040",
    "end": "1223400"
  },
  {
    "text": "classes may not be the best place to spend their time so using something like intelligent hearing is a way to offload",
    "start": "1223400",
    "end": "1228680"
  },
  {
    "text": "that work but also see the savings that then can be fed back into the business so here's the first pattern I put up on",
    "start": "1228680",
    "end": "1235850"
  },
  {
    "start": "1233000",
    "end": "1295000"
  },
  {
    "text": "the screen while I take a quick sip of water but we'll talk through these examples and why a certain storage class",
    "start": "1235850",
    "end": "1241040"
  },
  {
    "text": "might be a good choice so here we're",
    "start": "1241040",
    "end": "1247820"
  },
  {
    "text": "using the same colors we did before in the storage class analysis where you see the blue is the storage growing over",
    "start": "1247820",
    "end": "1252950"
  },
  {
    "text": "time so it's pretty steady growth in the storage but the access remains kind of high relative to that storage so there's",
    "start": "1252950",
    "end": "1258890"
  },
  {
    "text": "a lot more access and data retrieved relative to the data stored so it's frequently accessed it's more than 100",
    "start": "1258890",
    "end": "1264860"
  },
  {
    "text": "percent of the storage being retrieved over time this could be something like origin storage for a CDN it could be",
    "start": "1264860",
    "end": "1270500"
  },
  {
    "text": "something like a big data analytics workload where those queries are running all the time and here you may see a case",
    "start": "1270500",
    "end": "1276800"
  },
  {
    "text": "where s3 standard is a good fit because you're avoiding those retrieval fees or if you find that it's a maybe a small",
    "start": "1276800",
    "end": "1282980"
  },
  {
    "text": "subset of the objects being accessed a lot and a lot of the objects are colder then intelligent tearing will help you achieve that savings because it will be",
    "start": "1282980",
    "end": "1289520"
  },
  {
    "text": "moving objects to the infrequent ear when they're not being accessed so that's our first example kind of a basic",
    "start": "1289520",
    "end": "1294800"
  },
  {
    "text": "one here we're seeing more of a predictable pattern where the storage is",
    "start": "1294800",
    "end": "1299810"
  },
  {
    "text": "still growing over time but a lot of access right up front actually really tails off over time and it's somewhat",
    "start": "1299810",
    "end": "1305600"
  },
  {
    "text": "predictable where you see these spikes but you see how they kind of drop off over time so this could be something like kind of assets stored for gaming",
    "start": "1305600",
    "end": "1313340"
  },
  {
    "text": "workloads so you may have history of particular users and see that drop-off over time because it's relevant right",
    "start": "1313340",
    "end": "1319670"
  },
  {
    "text": "away but after time it's more of a historical analysis it's less likely you're gonna go back to that another one",
    "start": "1319670",
    "end": "1325100"
  },
  {
    "text": "might be user-generated content so you can think of something like uploading photos or videos from a recent vacation",
    "start": "1325100",
    "end": "1331100"
  },
  {
    "text": "where there might be a lot of access as you share that right Way but then it's gonna drop off over time and it's kind of that nostalgia",
    "start": "1331100",
    "end": "1336800"
  },
  {
    "text": "moment where you go back and read it but you're not gonna see that as frequently over time so here lifecycle policies are a good",
    "start": "1336800",
    "end": "1343580"
  },
  {
    "text": "fit because you are seeing a predictable drop-off over time so you could use standard than lifecycle policies to",
    "start": "1343580",
    "end": "1348830"
  },
  {
    "text": "transition it over time you could put it directly to intelligent hearing and achieve that savings as the access",
    "start": "1348830",
    "end": "1354470"
  },
  {
    "text": "patterns die off and then towards the tail end here where it's less likely that the data is gonna be touched at all",
    "start": "1354470",
    "end": "1360290"
  },
  {
    "text": "then glacier may be a really good fit so once again kind of a basic scenario and something that a lot of folks will see",
    "start": "1360290",
    "end": "1366980"
  },
  {
    "text": "in their data if you use something like storage class analysis this is a pretty common pattern next we'll look at data",
    "start": "1366980",
    "end": "1373040"
  },
  {
    "text": "with changing access patterns so once again the storage is fairly steady maybe a slight growth over time but now I have",
    "start": "1373040",
    "end": "1379520"
  },
  {
    "text": "these unpredictable spikes it looks like there may be some periodicity here and you may get some idea of that but if",
    "start": "1379520",
    "end": "1385160"
  },
  {
    "text": "these are unpredictable and you're not sure when they're gonna happen then you absolutely want to look at something like intelligent hearing this is larger",
    "start": "1385160",
    "end": "1391580"
  },
  {
    "text": "storage so it looks like geo spatial data so this might be satellite imagery this might be something like autonomous",
    "start": "1391580",
    "end": "1397490"
  },
  {
    "text": "vehicle data and then there's large amounts of analytics that might look at that data over a period of time and when",
    "start": "1397490",
    "end": "1402650"
  },
  {
    "text": "you're using intelligent hearing with no retrieval fee and the ability to move to that infrequent here in these pockets in",
    "start": "1402650",
    "end": "1407960"
  },
  {
    "text": "between where the data is not accessed may be a really good fit for intelligent hearing on this last one we've got two",
    "start": "1407960",
    "end": "1414260"
  },
  {
    "start": "1412000",
    "end": "1483000"
  },
  {
    "text": "scenarios where you don't know as much information so this may reflect a scenario where a lot of people are in",
    "start": "1414260",
    "end": "1419600"
  },
  {
    "text": "where something's newer or it's just hard to gather the information about data's usage so the one up top you don't",
    "start": "1419600",
    "end": "1426679"
  },
  {
    "text": "know a lot about the workload but you know the objects are larger so they're kind of in the megabyte range and then the storage durations along so we're",
    "start": "1426679",
    "end": "1432500"
  },
  {
    "text": "gonna keep this data for months or years that sounds like a good fit for intelligent hearing where you could",
    "start": "1432500",
    "end": "1437750"
  },
  {
    "text": "start an intelligent hearing and even though you don't know a lot about the workload the access patterns over time will help intelligent tearing to move",
    "start": "1437750",
    "end": "1443480"
  },
  {
    "text": "that to the infrequent ear and save some money and then the second one once again an unknown workload but we're seeing a",
    "start": "1443480",
    "end": "1450260"
  },
  {
    "text": "mix of object sizes so there are a mix of those and it's really uncertain as to",
    "start": "1450260",
    "end": "1455720"
  },
  {
    "text": "where those really clump around and what the average might look like and then there are a lot of short-lived objects so if things are only living for days",
    "start": "1455720",
    "end": "1461120"
  },
  {
    "text": "hours you have a lot of things on that shorter end of the spectrum with those minimum storage durations on the",
    "start": "1461120",
    "end": "1466280"
  },
  {
    "text": "infrequent ears until tearing and glacier you may just want to start with standard here and then as you gain more information over time",
    "start": "1466280",
    "end": "1472099"
  },
  {
    "text": "intelligent hearing might prove to be a fit in the longer term but you really want to learn more before you might try that storage class out that's a few",
    "start": "1472099",
    "end": "1478849"
  },
  {
    "text": "different patterns hope that helped you guys kind of think through how the different storage classes may come in handy",
    "start": "1478849",
    "end": "1483909"
  },
  {
    "start": "1483000",
    "end": "1601000"
  },
  {
    "text": "the next topic we'll talk about is another recently launched product so right from the end of April this year so",
    "start": "1483909",
    "end": "1489529"
  },
  {
    "text": "customers are really ramping up on it now Amazon s3 batch operations and the",
    "start": "1489529",
    "end": "1495529"
  },
  {
    "text": "headline here is you're gonna save time on developing tools to do batch operations so anything that's",
    "start": "1495529",
    "end": "1500839"
  },
  {
    "text": "large-scale where you're operating on thousands millions billions of objects you just want to hand off that work and",
    "start": "1500839",
    "end": "1506089"
  },
  {
    "text": "you don't want to write your own script or tool that can handle that scale you're gonna save a lot of development time and then we'll see some of the",
    "start": "1506089",
    "end": "1512179"
  },
  {
    "text": "conveniences built into this feature where somebody who's doing this themselves and kind of doing it manually there may not be the monitoring tools",
    "start": "1512179",
    "end": "1519049"
  },
  {
    "text": "and the way to really see well is this resilient is this gonna keep running through any kind of errors I run into or",
    "start": "1519049",
    "end": "1524119"
  },
  {
    "text": "am I gonna keep having to rerun this thing and then how do I get progress of visibility so I can share with others in my organization like here's how the work",
    "start": "1524119",
    "end": "1530599"
  },
  {
    "text": "is progressing and here's what I think it's gonna be done you've got those tools here and it's built in so it's gonna be that much more convenient for",
    "start": "1530599",
    "end": "1536659"
  },
  {
    "text": "you and it's something where you can take this large amount of objects hand it off to a3 and it's really one request",
    "start": "1536659",
    "end": "1542059"
  },
  {
    "text": "to kick off an entire job so even though the scale may be large it's really very little work on your part to kick that",
    "start": "1542059",
    "end": "1547339"
  },
  {
    "text": "off so it's the kind of most basic way we can look over it you're gonna develop",
    "start": "1547339",
    "end": "1553219"
  },
  {
    "text": "a list of the objects so you can use something like our inventory feature which already gives you lists of contents in a particular bucket so you",
    "start": "1553219",
    "end": "1560029"
  },
  {
    "text": "can use that to get your list of objects or if you have a secondary database or other metadata store about your storage",
    "start": "1560029",
    "end": "1565219"
  },
  {
    "text": "in Amazon s3 you can use that to generate a list of objects once you have that list then it's just a matter of",
    "start": "1565219",
    "end": "1570440"
  },
  {
    "text": "telling us through batch operations what operation you want to perform copies one of the basic examples there so if you",
    "start": "1570440",
    "end": "1575749"
  },
  {
    "text": "want to copy the data to another bucket another account altogether and you want to just transfer data over and that",
    "start": "1575749",
    "end": "1581389"
  },
  {
    "text": "could be one of the simple operations you can kick off with this and then the progress of visibility and some of the other tools you have means that you can",
    "start": "1581389",
    "end": "1587719"
  },
  {
    "text": "always check in on the dashboard you can use the API is SDK to actually check in and see how a particular job is",
    "start": "1587719",
    "end": "1593329"
  },
  {
    "text": "progressing and you have other tools to then make changes about what jobs more important than which and which one you",
    "start": "1593329",
    "end": "1598459"
  },
  {
    "text": "want to kick off and kind of take precedence over the others so this slide will then",
    "start": "1598459",
    "end": "1603470"
  },
  {
    "start": "1601000",
    "end": "1650000"
  },
  {
    "text": "go into more detail about kind of how this works step-by-step so it can be your own CSV list that you create",
    "start": "1603470",
    "end": "1609289"
  },
  {
    "text": "depending on the scale of the objects and what information you have you could even start with the s3 inventory report",
    "start": "1609289",
    "end": "1614419"
  },
  {
    "text": "which is something where you can generate a list of everything in a bucket or you could say I'm only care about what's in this particular prefix",
    "start": "1614419",
    "end": "1619760"
  },
  {
    "text": "and we'll talk through some scenarios later on but that list of everything in a bucket might not be exactly what",
    "start": "1619760",
    "end": "1625370"
  },
  {
    "text": "you're looking for you might see that giant list and say well I don't want to operate on all billion objects there's really like 25 million objects here that",
    "start": "1625370",
    "end": "1631850"
  },
  {
    "text": "are really relevant to me use a tool like Athena you use something like s3 select and use that to filter down the",
    "start": "1631850",
    "end": "1637730"
  },
  {
    "text": "list based on the criteria you're looking for and then you'll be able to have a more targeted list and kick off that job at batch operations operate on",
    "start": "1637730",
    "end": "1644450"
  },
  {
    "text": "only what you want to operate on and then it's going to be done that much quicker when you're able to filter down the set of objects so selecting the set",
    "start": "1644450",
    "end": "1651830"
  },
  {
    "text": "of objects there are four native s3 operations so copy tagging objects changing the access",
    "start": "1651830",
    "end": "1657980"
  },
  {
    "text": "control list on a particular object or restoring objects from glacier so all those use cases we talked about before",
    "start": "1657980",
    "end": "1664250"
  },
  {
    "text": "where you're moving data to glacier there me built there there may be moments where you're moving hundreds of",
    "start": "1664250",
    "end": "1669260"
  },
  {
    "text": "thousands or millions of objects back to s3 because you either need to send them off to a third party or you want to do",
    "start": "1669260",
    "end": "1674929"
  },
  {
    "text": "analysis of your glacier objects this is a great way to get that data back in bulk and kick off all those restores at",
    "start": "1674929",
    "end": "1680149"
  },
  {
    "text": "once and then the last one you see here listed on the list really opens up a whole lot of possibilities and that's",
    "start": "1680149",
    "end": "1685640"
  },
  {
    "text": "running AWS lambda functions so for each object that you've listed in your manifest you can say okay I want you to",
    "start": "1685640",
    "end": "1692450"
  },
  {
    "text": "read that object look for particular properties or perform machine learning on a particular object then I want you",
    "start": "1692450",
    "end": "1697820"
  },
  {
    "text": "to send the results here and I want you to also put those results into a file where I can look at after the batch operations job the demo that we walk",
    "start": "1697820",
    "end": "1704570"
  },
  {
    "text": "through will be a WS lambda function using recognition so that's image recognition on the",
    "start": "1704570",
    "end": "1710090"
  },
  {
    "text": "objects basically think of the scenario where you have a whole lot of static images in s3 but you're not quite sure",
    "start": "1710090",
    "end": "1715789"
  },
  {
    "text": "what the mix of those objects is using batch operations to go through that entire list run recognition and then",
    "start": "1715789",
    "end": "1721730"
  },
  {
    "text": "start to put together pieces of metadata on what you have stored in s3 now you've taken what was kind of static storage",
    "start": "1721730",
    "end": "1727460"
  },
  {
    "text": "you weren't quite sure how you were going to use it you weren't sure how you're going to share with your end users and now you've got something like a searchable catalog you've got a way",
    "start": "1727460",
    "end": "1734090"
  },
  {
    "text": "for you users to query it you've got ways for yourselves to make recommendations about what they might be interested in based on the properties of something so that's",
    "start": "1734090",
    "end": "1740730"
  },
  {
    "text": "one case for lambda we've had customers really interested in transforming the kind of data formats of particular",
    "start": "1740730",
    "end": "1746340"
  },
  {
    "text": "pieces of data so something where you want to unify a data Lake into one particular format a lambda function",
    "start": "1746340",
    "end": "1751529"
  },
  {
    "text": "could help you do that lambda functions for making thumbnails running the machine learning workloads a lot of",
    "start": "1751529",
    "end": "1756600"
  },
  {
    "text": "different flexibility with the way you can do with lambda and then you could have your own custom code that's scanning objects and looking for",
    "start": "1756600",
    "end": "1761700"
  },
  {
    "text": "particular characteristics and an object you could absolutely do that as well with batch operations plus lambda and",
    "start": "1761700",
    "end": "1767450"
  },
  {
    "text": "then you have the ability to view progress so at an overall level you're viewing how many operations were",
    "start": "1767450",
    "end": "1772860"
  },
  {
    "text": "successful how many were failed what's the percentage progress we've made along the way job notifications allow you to",
    "start": "1772860",
    "end": "1778950"
  },
  {
    "text": "use cloud watch events to say well I want to know when this job starts I want to know when it goes active when it actually starts executing and then I",
    "start": "1778950",
    "end": "1785220"
  },
  {
    "text": "want a notification when it's complete so it's something where you're not checking in but you're getting that push notification to let you know when a",
    "start": "1785220",
    "end": "1790860"
  },
  {
    "text": "particular job has reached a certain milestone and then the completion report is something you can customize so when",
    "start": "1790860",
    "end": "1797159"
  },
  {
    "text": "you request a completion report you can say I want a list of everything batch operations did its a CSV that we're just",
    "start": "1797159",
    "end": "1802679"
  },
  {
    "text": "gonna list out everything we did and it could be everything successful and failed basically all tasks or you can",
    "start": "1802679",
    "end": "1808230"
  },
  {
    "text": "filter that down and say I only want a list of all the failures and then it shows you the error so you can go back",
    "start": "1808230",
    "end": "1813360"
  },
  {
    "text": "say okay if I fix this issue now I'm gonna go back and rerun this set of objects from this failure report and now",
    "start": "1813360",
    "end": "1818490"
  },
  {
    "text": "I know that everything is complete and I can move on with my day I was able to check that off my box and now we can",
    "start": "1818490",
    "end": "1824490"
  },
  {
    "text": "move on with whatever else we're doing in our business so that completion report gives you a one-stop shop for everything the batch operations job did",
    "start": "1824490",
    "end": "1831919"
  },
  {
    "start": "1831000",
    "end": "1885000"
  },
  {
    "text": "the s3 inventory report this is a quick recap or for folks that aren't familiar with it so it can be a list of",
    "start": "1831919",
    "end": "1837990"
  },
  {
    "text": "everything in a bucket or prefix customers use this for auditing analytics so that filtering we talked",
    "start": "1837990",
    "end": "1843600"
  },
  {
    "text": "about earlier you can also use it to answer questions like hey I know there's a lot of data stored in this bucket and it was stored over the last five years I",
    "start": "1843600",
    "end": "1850110"
  },
  {
    "text": "turned on default encryption maybe somewhere in the middle of that so I know I have a lot of unencrypted storage and then I started encrypting the more",
    "start": "1850110",
    "end": "1855990"
  },
  {
    "text": "recent objects I want to answer the question of how much is unencrypted how much is encrypted that's something where",
    "start": "1855990",
    "end": "1860999"
  },
  {
    "text": "this inventory report + Athena could just give you a quick way to access that information based on some of the columns",
    "start": "1860999",
    "end": "1866190"
  },
  {
    "text": "that are there so if you want to you know more about the storage classes of your objects you have that filter criteria in",
    "start": "1866190",
    "end": "1871410"
  },
  {
    "text": "here creation date encryption status replication status object size so you have a number of different criteria you",
    "start": "1871410",
    "end": "1877500"
  },
  {
    "text": "also have the strings of the names of the object and the bucket therein so you can use those to filter them as well we'll talk through one example towards",
    "start": "1877500",
    "end": "1883800"
  },
  {
    "text": "the end of these slides and here you have the overall console view and don't",
    "start": "1883800",
    "end": "1889740"
  },
  {
    "text": "spend a lot of time on it now we'll kind of walk through this when we go through the demo but you have all the information about a particular job you",
    "start": "1889740",
    "end": "1896130"
  },
  {
    "text": "have information about one that was created you can customize the name of a job basically added descriptions so you know what jobs map to what teams or why",
    "start": "1896130",
    "end": "1902970"
  },
  {
    "text": "a particular job was kicked off especially if that job doesn't run to completion you want to say like is it more important that I go back and fix",
    "start": "1902970",
    "end": "1908730"
  },
  {
    "text": "this job or this job that's something that might be helpful to put something in that character right there then you",
    "start": "1908730",
    "end": "1913770"
  },
  {
    "text": "see the job state how large the job is you see the progress and then you're seeing the priority number priority I'll",
    "start": "1913770",
    "end": "1919680"
  },
  {
    "text": "address here briefly when you have a number of different jobs running that priority number is a way where you say",
    "start": "1919680",
    "end": "1924750"
  },
  {
    "text": "well this job I just started is kind of paused because it's behind all these other jobs in the queue that's actually",
    "start": "1924750",
    "end": "1930150"
  },
  {
    "text": "the most important thing I want this kicked off right now change that priority value the system will look at it they'll see a higher priority and",
    "start": "1930150",
    "end": "1935970"
  },
  {
    "text": "that job will activate while another job pauses so there is a certain number of jobs you can run at once and that's",
    "start": "1935970",
    "end": "1941550"
  },
  {
    "text": "really to ensure you're getting enough throughput on the jobs that are running so then priority is your way of shifting those around and changing the precedence",
    "start": "1941550",
    "end": "1948630"
  },
  {
    "text": "as needed so I just want to highlight here s3 batch operations it's really a",
    "start": "1948630",
    "end": "1953760"
  },
  {
    "start": "1949000",
    "end": "2043000"
  },
  {
    "text": "managed solution it's doing the automatic retries so if for any reason operation doesn't run right away and",
    "start": "1953760",
    "end": "1959190"
  },
  {
    "text": "it's something we can retry we'll just retry that with in batch operations so we want to get 200% completion and we'll",
    "start": "1959190",
    "end": "1965130"
  },
  {
    "text": "work through things like any transient failures you'll see the progress along the way you have the management controls",
    "start": "1965130",
    "end": "1970200"
  },
  {
    "text": "to cancel jobs to update their priority levels over time and then you have those notifications when jobs transition to",
    "start": "1970200",
    "end": "1976230"
  },
  {
    "text": "different states the auditing refers to that completion report and the information you're going to get there and I think the overall message here is",
    "start": "1976230",
    "end": "1983430"
  },
  {
    "text": "you know if your company is already doing something where you have a tool and you're doing work overtime to maintain it if you can hand that work",
    "start": "1983430",
    "end": "1989400"
  },
  {
    "text": "off to s3 batch operations then that's one less thing your company is doing and then you've got a manage tool where you",
    "start": "1989400",
    "end": "1994530"
  },
  {
    "text": "say all I really want to focus on is generating the right list and then I can hand that off to batch operations on a daily basis every hour whatever the",
    "start": "1994530",
    "end": "2001070"
  },
  {
    "text": "right periodicity is but it's something where it takes away that kind of execution phase and managing that work and actually managing",
    "start": "2001070",
    "end": "2007370"
  },
  {
    "text": "the individual tasks the next thing I'll highlight is kind of if you're if you've had that job sitting around like the",
    "start": "2007370",
    "end": "2013610"
  },
  {
    "text": "encryption case we talked about where there's a lot of unencrypted data and nobody's ever gotten around to going back and encrypting it something want to",
    "start": "2013610",
    "end": "2019310"
  },
  {
    "text": "do for compliance purposes now you've got a tool where in a few steps and I can talk to anyone who wants to talk",
    "start": "2019310",
    "end": "2024500"
  },
  {
    "text": "about it afterwards but something like Athena and s3 Select ramping up on them simple query filter down kick off the",
    "start": "2024500",
    "end": "2030710"
  },
  {
    "text": "batch operations job and now it's something where you can go to somebody and probably within fifteen or thirty minutes of work you now kicked off a job",
    "start": "2030710",
    "end": "2037400"
  },
  {
    "text": "to encrypt all your existing objects and that feels really good when you can get something like that done in a very short period of time so now I want to",
    "start": "2037400",
    "end": "2045050"
  },
  {
    "text": "introduce and talk about the demo that we're gonna look at and then we'll walk through it step-by-step so the demo",
    "start": "2045050",
    "end": "2050960"
  },
  {
    "start": "2049000",
    "end": "2144000"
  },
  {
    "text": "overview is we talked about its batch operations used with AWS lambda they're images stored in an s3 bucket we have a",
    "start": "2050960",
    "end": "2057110"
  },
  {
    "text": "fairly small number here because I just want to show you guys how it works it's about 800 images and these are things",
    "start": "2057110",
    "end": "2062389"
  },
  {
    "text": "just crawled from the web so they're images of space satellites rockets it's really from a NASA database so",
    "start": "2062390",
    "end": "2068030"
  },
  {
    "text": "you'll see that in the categorizations and the different metadata that labels that we pull from these particular images we're going to invoke the lambda",
    "start": "2068030",
    "end": "2075050"
  },
  {
    "text": "function that's then going to use recognition and recognition is our machine learning service that does image recognition so it's going to take those",
    "start": "2075050",
    "end": "2081139"
  },
  {
    "text": "labels send them to an elastic search database elastic search service that",
    "start": "2081140",
    "end": "2087290"
  },
  {
    "text": "then the cabana dashboard is actually looking at that elastic search labels so as the labels are made by recognition",
    "start": "2087290",
    "end": "2093889"
  },
  {
    "text": "they go to elastic search and then kibana updates and we'll see the dashboard change over time as those results start to make their way through",
    "start": "2093890",
    "end": "2100070"
  },
  {
    "text": "the pipeline here's a quick visual of what that looks like had a lot of questions from customers about kind of what what lives",
    "start": "2100070",
    "end": "2106490"
  },
  {
    "text": "inside the lambda function for this particular job so batch operations create the jobs specified this lambda",
    "start": "2106490",
    "end": "2112130"
  },
  {
    "text": "function but then within that lambda an individual object gets passed from the manifest so that will be a particular",
    "start": "2112130",
    "end": "2118340"
  },
  {
    "text": "image recognition goes to the bucket gets that image reads it looks at the particular image generates those labels",
    "start": "2118340",
    "end": "2124610"
  },
  {
    "text": "and then sends them to the elastics centum to elasticsearch as part of the lambda function so that's all happening",
    "start": "2124610",
    "end": "2129920"
  },
  {
    "text": "within lambda and then the dashboard is something where I just open it separately and then we see the results change once information store",
    "start": "2129920",
    "end": "2135890"
  },
  {
    "text": "to flow to elasticsearch so with that we'll switch over to the demo view and then we can see how this looks in action",
    "start": "2135890",
    "end": "2144430"
  },
  {
    "start": "2144000",
    "end": "2210000"
  },
  {
    "text": "excellent so we're back to that overall console view that we talked about before and one of the cool things you can do",
    "start": "2144430",
    "end": "2151130"
  },
  {
    "text": "through the console is basically I have this job so this is a case where I ran this job earlier so I'm gonna use what's",
    "start": "2151130",
    "end": "2158150"
  },
  {
    "text": "called a clone feature where we're gonna take all the properties from an existing job and just run that job again in this",
    "start": "2158150",
    "end": "2163970"
  },
  {
    "text": "case we're gonna make no changes we may make some minor tweaks along the way for priority for example but where you can",
    "start": "2163970",
    "end": "2169550"
  },
  {
    "text": "see this being valuable in your own business is let's say that job to encrypt your existing objects if you get",
    "start": "2169550",
    "end": "2175280"
  },
  {
    "text": "that up and running for one bucket then running it on different buckets is just a matter of changing the list of objects",
    "start": "2175280",
    "end": "2180410"
  },
  {
    "text": "every other property is gonna be the same along the way so then you can click clone job update the list of objects and",
    "start": "2180410",
    "end": "2186140"
  },
  {
    "text": "then you're just going through this console view and saying ok it's basically the same job click click click",
    "start": "2186140",
    "end": "2191270"
  },
  {
    "text": "kick off a job to then encrypt the objects in a different bucket so you could do that here in the console view",
    "start": "2191270",
    "end": "2196940"
  },
  {
    "text": "depending on how many you have or when you're doing this programmatically you can once again see how nearly all the parameters will be the same and it's",
    "start": "2196940",
    "end": "2203360"
  },
  {
    "text": "just a matter of shifting the list of objects switching the list of objects when you're doing something similar so let's go ahead and click clone job we're",
    "start": "2203360",
    "end": "2211400"
  },
  {
    "start": "2210000",
    "end": "2235000"
  },
  {
    "text": "here and we're in Northern Virginia for this particular job so the job location",
    "start": "2211400",
    "end": "2216920"
  },
  {
    "text": "and looking at that region it's really just about matching to what is the region where the objects are located so",
    "start": "2216920",
    "end": "2222380"
  },
  {
    "text": "where is the bucket located where's the storage and then for copy jobs you want to put in the destination region for a",
    "start": "2222380",
    "end": "2227510"
  },
  {
    "text": "particular job so if it's within the same region that's pretty self-explanatory but when you're doing cross region jobs you'll create the job",
    "start": "2227510",
    "end": "2233810"
  },
  {
    "text": "in the destination location here we're using an s3 inventory report so that's",
    "start": "2233810",
    "end": "2239360"
  },
  {
    "start": "2235000",
    "end": "2255000"
  },
  {
    "text": "exactly what we talked about before I didn't want to create a list of these objects granted the scale is very small but once you get to a larger scale if",
    "start": "2239360",
    "end": "2245600"
  },
  {
    "text": "you don't want to go through a list and creating your own kind of set of the objects and building your own CSV just",
    "start": "2245600",
    "end": "2250820"
  },
  {
    "text": "generate an s3 inventory report and then get started with selecting it here so we're gonna click Next on this step you",
    "start": "2250820",
    "end": "2258620"
  },
  {
    "text": "see how you can choose the different types of operations at the top fairly simple to go through them and they're all pretty self-explanatory parameters",
    "start": "2258620",
    "end": "2264590"
  },
  {
    "text": "we'll look at some examples later on in this one I just want to use a lambda function it called the NASA demo and I'm going to",
    "start": "2264590",
    "end": "2270800"
  },
  {
    "text": "use the latest version so once again very simple to specify it's a lambda function here's the one we're looking",
    "start": "2270800",
    "end": "2275840"
  },
  {
    "text": "for next step and then here so I'll just add summit to the end to make it even",
    "start": "2275840",
    "end": "2281690"
  },
  {
    "start": "2278000",
    "end": "2328000"
  },
  {
    "text": "more clear what we're doing today priority so the way to think about",
    "start": "2281690",
    "end": "2286760"
  },
  {
    "text": "priority is the numbers you choose for priority are all relative to the other jobs you created so you can choose quite",
    "start": "2286760",
    "end": "2293450"
  },
  {
    "text": "a few numbers on the number scale here I use numbers typically between about 1 and 25 and that gives me enough room",
    "start": "2293450",
    "end": "2300410"
  },
  {
    "text": "that when I have different jobs running I can say well 15 is a more important job most of my jobs will just default to",
    "start": "2300410",
    "end": "2305510"
  },
  {
    "text": "priority 10 but when you start thinking about this and growing it at scale at your own company you can kind of set",
    "start": "2305510",
    "end": "2310820"
  },
  {
    "text": "those different thresholds and when a jobs of a certain type maybe it always gets set a priority 50 and when jobs are",
    "start": "2310820",
    "end": "2316400"
  },
  {
    "text": "of a lower value it's kind of something just running in the background set them a priority 5 so it's really just relative to one another",
    "start": "2316400",
    "end": "2322250"
  },
  {
    "text": "you could just use sequential numbers to do that as well but I try to leave some room in between if I kick off a number",
    "start": "2322250",
    "end": "2327290"
  },
  {
    "text": "of different jobs in this case I'm gonna generate a completion report and I'm gonna do all tasks that's kind of",
    "start": "2327290",
    "end": "2333620"
  },
  {
    "start": "2328000",
    "end": "2402000"
  },
  {
    "text": "influenced by the fact that this is a very small job so with about 800 images I'm only gonna have 800 lines in the CSV",
    "start": "2333620",
    "end": "2338660"
  },
  {
    "text": "quite easy to open that up just do it in Excel but when you start getting to billions of objects in a particular job",
    "start": "2338660",
    "end": "2343850"
  },
  {
    "text": "you may not want to sift through all of the successful tests or it may not even be useful that you keep a record of all",
    "start": "2343850",
    "end": "2349280"
  },
  {
    "text": "of those so there you might want to select I only want the failed tests and likely that's going to be a much smaller",
    "start": "2349280",
    "end": "2355010"
  },
  {
    "text": "percentage we've seen customers run larger jobs and in some cases if",
    "start": "2355010",
    "end": "2360080"
  },
  {
    "text": "something like the permissions aren't set correctly a job may fail right away so we may run 5,000 tasks if they all",
    "start": "2360080",
    "end": "2365270"
  },
  {
    "text": "fail there's a short-circuit feature so it'll just cancel the it'll basically fail the job at that point and you can",
    "start": "2365270",
    "end": "2371420"
  },
  {
    "text": "go back and troubleshoot based on okay there were five thousand failures here's the issue correct that run the job but",
    "start": "2371420",
    "end": "2376670"
  },
  {
    "text": "for something like running across five billion objects let's say a hundred of those objects were deleted by another",
    "start": "2376670",
    "end": "2381740"
  },
  {
    "text": "application while the job was running that's a reason where you'd see a failure you'd go into your completion report and say okay the object was not",
    "start": "2381740",
    "end": "2388550"
  },
  {
    "text": "found you could do some additional diving into the logs but that's a pretty clear case of why it failed something",
    "start": "2388550",
    "end": "2394430"
  },
  {
    "text": "like permissions on specific objects something you can go back to correct and then kick the job off so when the job gets larger may make sense to just look",
    "start": "2394430",
    "end": "2401180"
  },
  {
    "text": "at the failed tests only I'm just specifying where to store that completion report and then here is I'll",
    "start": "2401180",
    "end": "2407310"
  },
  {
    "start": "2402000",
    "end": "2414000"
  },
  {
    "text": "open this up briefly and talk about it this isn't really a security session focus but you'll be able to see how this",
    "start": "2407310",
    "end": "2412650"
  },
  {
    "text": "works and kind of talk through it so batch operations assumes an iam role to",
    "start": "2412650",
    "end": "2418440"
  },
  {
    "start": "2414000",
    "end": "2432000"
  },
  {
    "text": "actually perform the work on your behalf so it's acting within your account and performing the work so then you can be",
    "start": "2418440",
    "end": "2423480"
  },
  {
    "text": "very clear-cut on what you want batch operations to be able to do and not be able to do for this one I need the permission to invoke a lambda",
    "start": "2423480",
    "end": "2430230"
  },
  {
    "text": "function so you see that up on the screen and then I want permission to in this section you're looking at reading",
    "start": "2430230",
    "end": "2436589"
  },
  {
    "text": "the manifests so I have an s3 inventory report and I need batch operations to be able to read that to know what to",
    "start": "2436589",
    "end": "2441930"
  },
  {
    "text": "operate on so this section of permissions is about reading the manifest and then this section of the permissions down here is about writing",
    "start": "2441930",
    "end": "2448440"
  },
  {
    "text": "the completion report so there's just a few steps here where depending on what you want to do for a particular job you",
    "start": "2448440",
    "end": "2454079"
  },
  {
    "text": "would just have to build a role that includes those permissions we've got examples here in the console we've also got some of the documentation to help",
    "start": "2454079",
    "end": "2459660"
  },
  {
    "text": "you ramp up and get started and for those familiar with I am roles the other",
    "start": "2459660",
    "end": "2464819"
  },
  {
    "start": "2461000",
    "end": "2482000"
  },
  {
    "text": "thing I'll highlight is the trust policy so this is guidance on who can assume a role and who can perform work on my",
    "start": "2464819",
    "end": "2470550"
  },
  {
    "text": "behalf in this case s3 batch operations needs the ability to assume this role so this",
    "start": "2470550",
    "end": "2475650"
  },
  {
    "text": "is something where when you're plugging in a trust policy you can just cut and paste this into your iam role and get up",
    "start": "2475650",
    "end": "2480690"
  },
  {
    "text": "and running that way so everything here is already specified I've run this job before so I have an IM role already",
    "start": "2480690",
    "end": "2486930"
  },
  {
    "text": "created and then here is a review screen and the one thing I'll highlight here is",
    "start": "2486930",
    "end": "2492030"
  },
  {
    "text": "not in detail but looking down the screen one thing we don't know what this phase is how many objects are in a",
    "start": "2492030",
    "end": "2497490"
  },
  {
    "text": "particular job so I've specified a manifest I've said go read this object in s3 and operate on everything but s3",
    "start": "2497490",
    "end": "2504150"
  },
  {
    "text": "batch operations doesn't know anything about the scale of this job and this is something I want to encourage everyone to when you start to test this and when",
    "start": "2504150",
    "end": "2510119"
  },
  {
    "text": "you start to run in production if you're doing one-off jobs through the console or even if you're doing something programmatically there's the ability to",
    "start": "2510119",
    "end": "2516240"
  },
  {
    "text": "set what's called kind of an awaiting confirmation step and when you do this programmatically you can set whether",
    "start": "2516240",
    "end": "2521849"
  },
  {
    "text": "that's required or not and when you're doing it through the console is always required but what's happening is s3",
    "start": "2521849",
    "end": "2527010"
  },
  {
    "text": "batch operations reads that list in this case the number will be 799 objects but I know that that's my expectation going",
    "start": "2527010",
    "end": "2533579"
  },
  {
    "text": "in I then look at the job later on as three batch operations has read the job it's at this awaiting confirmation step",
    "start": "2533579",
    "end": "2538890"
  },
  {
    "text": "I'm gonna check all these parameters again for the job but then I see that number 799 that matches what I'm looking",
    "start": "2538890",
    "end": "2544560"
  },
  {
    "text": "for I'm gonna click run job and then we'll kick it off but you can see yourselves doing testing here and you",
    "start": "2544560",
    "end": "2549600"
  },
  {
    "text": "say well I'm just gonna test this on about a hundred objects if you get to that screen where you're confirming the job and the job says 150,000 objects",
    "start": "2549600",
    "end": "2557100"
  },
  {
    "text": "well then either the wrong object was selected or the wrong manifest like something went wrong where you said I",
    "start": "2557100",
    "end": "2562109"
  },
  {
    "text": "was gonna do a test on 100 I see this large number I want to slow down at that point cancel that job go back kind of",
    "start": "2562109",
    "end": "2567900"
  },
  {
    "text": "figure out what went wrong and then go back and kick off the job so that's the reason we put that step in place was really one more check to make sure the",
    "start": "2567900",
    "end": "2574320"
  },
  {
    "text": "parameters look correct and make sure that object looks correct before you kick it off so here we'll go ahead and",
    "start": "2574320",
    "end": "2579869"
  },
  {
    "start": "2578000",
    "end": "2622000"
  },
  {
    "text": "clone this job takes us back to this confirmation state kind of the overall",
    "start": "2579869",
    "end": "2585570"
  },
  {
    "text": "dashboard view and because we have such a large small manifest it's gonna go",
    "start": "2585570",
    "end": "2590910"
  },
  {
    "text": "ahead and run very quickly so we now have a job at the awaiting your confirmation step and here we see that",
    "start": "2590910",
    "end": "2597119"
  },
  {
    "text": "799 is now populated and I could scroll down here I mean jobs of various sizes will add up over time I've got jobs in",
    "start": "2597119",
    "end": "2604230"
  },
  {
    "text": "the millions we've run this demo a few times to test it and everything but when jobs get 250 million 100 million and so",
    "start": "2604230",
    "end": "2610920"
  },
  {
    "text": "forth may take a little bit longer to read that manifest but that's the goal is we're looking for errors and issues",
    "start": "2610920",
    "end": "2616140"
  },
  {
    "text": "and kind of the key names themselves but we're also giving you a count so it helps you to understand what's going to",
    "start": "2616140",
    "end": "2621180"
  },
  {
    "text": "be kicked off next and then like any good kind of magician or any demo I'm going to show you that the dashboard is",
    "start": "2621180",
    "end": "2626970"
  },
  {
    "start": "2622000",
    "end": "2642000"
  },
  {
    "text": "empty before we go there because otherwise you wouldn't buy it at all so we've got a dashboard here that's",
    "start": "2626970",
    "end": "2632190"
  },
  {
    "text": "updating every 5 seconds it's empty right now we've just got a few things we're gonna look at in this dashboard once those labels start",
    "start": "2632190",
    "end": "2637740"
  },
  {
    "text": "populating but I want to show you this before we go ahead and kick off the job so here's that DC summer job we created",
    "start": "2637740",
    "end": "2644510"
  },
  {
    "start": "2642000",
    "end": "2662000"
  },
  {
    "text": "confirm and run as I pointed out you're really looking through the same parameters as you scroll down here just",
    "start": "2644510",
    "end": "2651840"
  },
  {
    "text": "making sure everything was correct and everything is as you expected that objects listed in the manifest is now",
    "start": "2651840",
    "end": "2657119"
  },
  {
    "text": "populated with 799 and then we are going to run this job so we successfully",
    "start": "2657119",
    "end": "2664080"
  },
  {
    "start": "2662000",
    "end": "2673000"
  },
  {
    "text": "receive confirmation for the job and now we'll sit here on the dashboard view and we'll see as the individual Lam",
    "start": "2664080",
    "end": "2669810"
  },
  {
    "text": "as lambda functions are invoked for each object in the manifest we're gonna see this dashboard populate and one thing",
    "start": "2669810",
    "end": "2675900"
  },
  {
    "start": "2673000",
    "end": "2721000"
  },
  {
    "text": "I'll highlight at this phase is this number right here that's 74 right now is bucket keys so we ran on 799 objects but",
    "start": "2675900",
    "end": "2685350"
  },
  {
    "text": "within this lambda function we're looking at a pretty high confidence interval where we said anything where we're not 97% or more confident in a",
    "start": "2685350",
    "end": "2692310"
  },
  {
    "text": "particular label just throw it out I don't want to see it in this dashboard view I don't want to see those labels get passed through so they actually get",
    "start": "2692310",
    "end": "2699210"
  },
  {
    "text": "written to the final report so you can go back and look at that completion report and say what went wrong with the particular image why didn't I get a",
    "start": "2699210",
    "end": "2704970"
  },
  {
    "text": "particular label for it you can see those confidence intervals that's something where we're using the completion report to store a lot of",
    "start": "2704970",
    "end": "2710130"
  },
  {
    "text": "metadata and then here you're seeing a few different things so these are the different labels that are identified for",
    "start": "2710130",
    "end": "2715320"
  },
  {
    "text": "those images so 400 images 1400 labels there's multiple labels per image as you",
    "start": "2715320",
    "end": "2720690"
  },
  {
    "text": "might expect and then here I talked about where some of these images are coming from so human and person are",
    "start": "2720690",
    "end": "2726450"
  },
  {
    "start": "2721000",
    "end": "2794000"
  },
  {
    "text": "pretty popular but rocket transportation some of the things about crowds and kind of larger shots that you might see and",
    "start": "2726450",
    "end": "2732840"
  },
  {
    "text": "then outdoors night nature things down here as far as building towers you could",
    "start": "2732840",
    "end": "2737940"
  },
  {
    "text": "picture a launch pad might be in that particular image so that's just giving you an idea of some of the labels you'd get from recognition and then over here",
    "start": "2737940",
    "end": "2745020"
  },
  {
    "text": "in this bottom left is looking at some of our most popular labels so there's enough people kind of astronauts or",
    "start": "2745020",
    "end": "2751410"
  },
  {
    "text": "spectators in this particular images where that's popping up pretty high but then outdoors astronomy outer space this",
    "start": "2751410",
    "end": "2757770"
  },
  {
    "text": "is a pretty kind of homogeneous group of images where it's kind of the the space industry but you could do this for",
    "start": "2757770",
    "end": "2763530"
  },
  {
    "text": "user-generated content where you might have a lot of user-generated content that's aged but you want to say how can",
    "start": "2763530",
    "end": "2769050"
  },
  {
    "text": "I make this more interesting for my end users how can I make product recommendations how can I do other things using batch operations is a way",
    "start": "2769050",
    "end": "2775260"
  },
  {
    "text": "where you can access a whole lot of images in a hurry kick off machine learning and then allow batch operations",
    "start": "2775260",
    "end": "2780420"
  },
  {
    "text": "to do the work rather than you thinking of that phase you can think more about what do I do with the information once I have it and this particular lambda was",
    "start": "2780420",
    "end": "2786900"
  },
  {
    "text": "really built to give you some visualization of how this feature works but you can do so many things in lambda I'd love to talk to folks afterwards if",
    "start": "2786900",
    "end": "2793230"
  },
  {
    "text": "you have more questions about this feature so we've got that there the job now shifts to",
    "start": "2793230",
    "end": "2799610"
  },
  {
    "start": "2794000",
    "end": "2815000"
  },
  {
    "text": "you'll see it walk through the completing and then now it's in the complete phase so that means if I went to go look for that completion report I",
    "start": "2799610",
    "end": "2805970"
  },
  {
    "text": "could go open that up now and actually see what ran on a particular job so with that we'll jump back into the slides and",
    "start": "2805970",
    "end": "2811690"
  },
  {
    "text": "kind of walk through some other examples briefly excellent so walk through the",
    "start": "2811690",
    "end": "2817970"
  },
  {
    "start": "2815000",
    "end": "2820000"
  },
  {
    "text": "demo hope you all enjoy kind of seeing the feature in action and then here are some other common uses for batch operations that I hinted at earlier so",
    "start": "2817970",
    "end": "2825500"
  },
  {
    "start": "2824000",
    "end": "2882000"
  },
  {
    "text": "encrypting existing objects is a case where you'll just copy objects to the same bucket so because the key name will",
    "start": "2825500",
    "end": "2832700"
  },
  {
    "text": "just overwrite existing objects there's differences on whether your objects are versioned or not but this is a way that",
    "start": "2832700",
    "end": "2838130"
  },
  {
    "text": "we'd recommend you go back and say well I have all the data I want I just want to encrypt it you're doing a copy operation you're specifying encryption",
    "start": "2838130",
    "end": "2844760"
  },
  {
    "text": "so in this case I'll use the server-side encryption with a s3 keys and just write those objects back to themselves because",
    "start": "2844760",
    "end": "2851540"
  },
  {
    "text": "I don't want to do that with every object unnecessarily I can go ahead and use s3 select or athina to take my",
    "start": "2851540",
    "end": "2857869"
  },
  {
    "text": "inventory report say anything that's not encrypted basically look for that field and do that filtering and then run on",
    "start": "2857869",
    "end": "2864230"
  },
  {
    "text": "only the unencrypted objects and perform this work in batch operations then I could go back two days later look at an",
    "start": "2864230",
    "end": "2870470"
  },
  {
    "text": "inventory report run that same query and see that now all my objects are encrypted so you could do multiple steps here and kind of go back and verify but",
    "start": "2870470",
    "end": "2877100"
  },
  {
    "text": "it's an easy way to get up and running and use those filtering tools to narrow down your criteria then here we're",
    "start": "2877100",
    "end": "2883520"
  },
  {
    "start": "2882000",
    "end": "2917000"
  },
  {
    "text": "looking at copying objects to a new location so I just want to emphasize here the flexibility that you can copy",
    "start": "2883520",
    "end": "2888890"
  },
  {
    "text": "within regions across regions or across accounts there are a number of customers I like the phrase kind of meet me in the",
    "start": "2888890",
    "end": "2894950"
  },
  {
    "text": "cloud which I've heard a few times but if you've got partners you work with and you just want to copy data over to their bucket batch operations is a great way",
    "start": "2894950",
    "end": "2901609"
  },
  {
    "text": "to do that because you have all the ability to set an iam role that's going to be able to work across those accounts",
    "start": "2901609",
    "end": "2906859"
  },
  {
    "text": "and then you could even have a role in their account do the copy so then they have ownership of those objects when it",
    "start": "2906859",
    "end": "2912140"
  },
  {
    "text": "gets to their bucket so that's something you might want to think about and we have some cross account examples in our documentation here when you're restoring",
    "start": "2912140",
    "end": "2919490"
  },
  {
    "start": "2917000",
    "end": "2961000"
  },
  {
    "text": "objects from glacier it's so simple that I wanted to show you this screen it's just specifying how long you want that",
    "start": "2919490",
    "end": "2925490"
  },
  {
    "text": "copy to restore from glacier it's a temporary copy of the object so the objects of data itself is still stored",
    "start": "2925490",
    "end": "2931820"
  },
  {
    "text": "in glacier and you also have a temporary copy in s3 so you're really just saying how many days do I want that temporary copy available",
    "start": "2931820",
    "end": "2937500"
  },
  {
    "text": "or you're paying for s3 storage for that data while you're using it more actively whether to download it copy it perform",
    "start": "2937500",
    "end": "2944070"
  },
  {
    "text": "some analytics on it and then you can use the glacier restore notifications to actually understand when are these",
    "start": "2944070",
    "end": "2949440"
  },
  {
    "text": "objects available in s3 what batch operations does is initiate the restore and then once the object lands in s3 and",
    "start": "2949440",
    "end": "2955710"
  },
  {
    "text": "you can actually go ahead and download it or use that object you can use notifications to track that progress as well so those are just a few examples",
    "start": "2955710",
    "end": "2963210"
  },
  {
    "start": "2961000",
    "end": "2984000"
  },
  {
    "text": "here we'll just go over what we talked about so we talked about application requirements understanding how your data",
    "start": "2963210",
    "end": "2968640"
  },
  {
    "text": "is used the organization of your data will then influence how lifecycle policies or some other tools might work",
    "start": "2968640",
    "end": "2973830"
  },
  {
    "text": "for you batch operations great for common tasks really about simplicity intelligent tearing for that automated",
    "start": "2973830",
    "end": "2979920"
  },
  {
    "text": "cost savings at the object level so I'm glad we were able to review those and then please complete your session survey",
    "start": "2979920",
    "end": "2987270"
  },
  {
    "start": "2984000",
    "end": "2992000"
  },
  {
    "text": "so thank you for doing that and thank you all for coming today I'll appreciate it",
    "start": "2987270",
    "end": "2994880"
  }
]
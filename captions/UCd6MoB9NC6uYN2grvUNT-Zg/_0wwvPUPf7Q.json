[
  {
    "text": "In this video, you'll learn how to use Amazon Elastic Compute Cloud\n(Amazon EC2) Auto Scaling with Amazon Managed Service for Prometheus.",
    "start": "480",
    "end": "7450"
  },
  {
    "text": "With this solution, you can migrate existing \nPrometheus workloads to the cloud",
    "start": "8242",
    "end": "11943"
  },
  {
    "text": "and manage demand and costs by using Prometheus\nalerting rules to control Amazon EC2 Auto Scaling.",
    "start": "11944",
    "end": "17312"
  },
  {
    "text": "For this example, we’ll scale an Amazon Managed Service\nfor Prometheus workspace based on CPU usage.",
    "start": "20122",
    "end": "25402"
  },
  {
    "text": "This is our Amazon EC2 Auto Scaling group.",
    "start": "26064",
    "end": "28326"
  },
  {
    "text": "We have defined the group's minimum size\nas two instances, so it has high availability,",
    "start": "28797",
    "end": "33051"
  },
  {
    "text": "but set the maximum size as\n10 instances to control cost.",
    "start": "33051",
    "end": "36107"
  },
  {
    "text": "Both EC2 instances contained in this Auto Scaling group are remote-writing\nmetrics to our Amazon Managed Service for Prometheus workspace,",
    "start": "36795",
    "end": "43336"
  },
  {
    "text": "which we'll review momentarily.",
    "start": "43336",
    "end": "44774"
  },
  {
    "text": "We used the Prometheus launch\ntemplate to launch this instance.",
    "start": "45462",
    "end": "48102"
  },
  {
    "text": "Let's take a look.",
    "start": "48229",
    "end": "48927"
  },
  {
    "text": "The launch template provided the Amazon \nMachine Image (AMI) ID and instance type.",
    "start": "50297",
    "end": "54680"
  },
  {
    "text": "Let's view the Advanced details tab.",
    "start": "55387",
    "end": "57129"
  },
  {
    "text": "The template also provided the security groups and AWS Identity and Access\nManagement (AWS IAM) instance profile needed for setting up the EC2 instances.",
    "start": "59119",
    "end": "67482"
  },
  {
    "text": "Next, we'll go to the Amazon \nManaged Service for Prometheus.",
    "start": "68402",
    "end": "71174"
  },
  {
    "text": "Let's find the workspace \nfor our Auto Scaling group.",
    "start": "73772",
    "end": "75885"
  },
  {
    "text": "Here we can see a summary \nof its status and details.",
    "start": "80042",
    "end": "82522"
  },
  {
    "text": "Let's open the Rules management tab.",
    "start": "83438",
    "end": "85138"
  },
  {
    "text": "We configured an alerting rule to \nsupport Auto Scaling of the workspace.",
    "start": "87032",
    "end": "90386"
  },
  {
    "text": "Let's view the rule.",
    "start": "90797",
    "end": "91676"
  },
  {
    "text": "Per the rule code, we established \"high\"\nand \"low\" CPU usage boundaries.",
    "start": "95473",
    "end": "99398"
  },
  {
    "text": "The high CPU load rule is triggered when the average CPU\nutilization over a five-minute period is greater than 60%.  ",
    "start": "100243",
    "end": "106451"
  },
  {
    "text": "The low CPU load rule is triggered when the average CPU\nutilization over a five-minute period is less than 30%.",
    "start": "107272",
    "end": "112992"
  },
  {
    "text": "Any CPU usage measured outside of\nthose boundaries results in a warning",
    "start": "114000",
    "end": "117577"
  },
  {
    "text": "and prompts an event to \"scale up\"\nor \"scale down\" the number of instances.",
    "start": "117577",
    "end": "121089"
  },
  {
    "text": "We also configured an alert manager\ndefinition to coordinate with the alerting rule.",
    "start": "121839",
    "end": "125391"
  },
  {
    "text": "Let's take a look.",
    "start": "125601",
    "end": "126359"
  },
  {
    "text": "If CPU usage goes beyond the \"high\" or \"low\" boundaries,\nalert manager sends an alert to a specified Amazon SNS topic.",
    "start": "134275",
    "end": "140922"
  },
  {
    "text": "It shares the alert type and the event type, which, as we defined in the rule,\nwould be a directive to increase or decrease the number of instances.",
    "start": "141476",
    "end": "148209"
  },
  {
    "text": "Let's go to the Amazon SNS \nconsole to review the topic.",
    "start": "149382",
    "end": "152160"
  },
  {
    "text": "Let’s find the topic that corresponds with our \nAmazon Managed Service for Prometheus workspace.",
    "start": "156057",
    "end": "160215"
  },
  {
    "text": "Here we see the details of the topic.",
    "start": "163074",
    "end": "164674"
  },
  {
    "text": "We've subscribed an AWS \nLambda function to the topic.",
    "start": "165642",
    "end": "168282"
  },
  {
    "text": "Let's visit the AWS Lambda console \nto take a look at this function.",
    "start": "169432",
    "end": "172565"
  },
  {
    "text": "In its source code, we can see that the Lambda \nfunction inspects the alert sent to Amazon SNS",
    "start": "178274",
    "end": "183287"
  },
  {
    "text": "and determines whether a \"scale up\" \nor \"scale down\" event should happen.",
    "start": "183287",
    "end": "186297"
  },
  {
    "text": "Lambda then sends a request to the Auto Scaling group to increment\nor decrement the number of instances to the desired capacity.",
    "start": "186944",
    "end": "192704"
  },
  {
    "text": "To visualize how this Auto Scaling solution is \nmanifested, let’s go to Amazon Managed Grafana.",
    "start": "193679",
    "end": "198639"
  },
  {
    "text": "We’ve already built a dashboard\nfor our auto-scaled workload.",
    "start": "201920",
    "end": "204555"
  },
  {
    "text": "Let’s find it.",
    "start": "204712",
    "end": "205362"
  },
  {
    "text": "Here we can see how the CPU and number of EC2 instances changed\nin response to traffic being sent to the Auto Scaling group.",
    "start": "213627",
    "end": "219586"
  },
  {
    "text": "Let's edit the dashboard.",
    "start": "220000",
    "end": "221120"
  },
  {
    "text": "To review our data more closely, \nlet’s narrow the time range.",
    "start": "223912",
    "end": "226552"
  },
  {
    "text": "We can see from the graph that when CPU usage \nspiked to 100%, the number of instances increased,  ",
    "start": "228932",
    "end": "234062"
  },
  {
    "text": "eventually reaching 10 instances, the maximum \namount we set in the Auto Scaling group.",
    "start": "234062",
    "end": "238429"
  },
  {
    "text": "Then, as CPU usage gradually declined, \nso did the number of instances.",
    "start": "239130",
    "end": "243082"
  },
  {
    "text": "You've just seen how to use Amazon EC2 Auto Scaling\nwith Amazon Managed Service for Prometheus.",
    "start": "245832",
    "end": "250792"
  },
  {
    "text": "You can learn more about this topic in \nthe description and links for this video.",
    "start": "251824",
    "end": "254880"
  },
  {
    "text": "Thanks for watching.\nNow it's your turn to try.",
    "start": "255089",
    "end": "257001"
  }
]
[
  {
    "text": "you may occasionally need to create scale out databases so that duplicate copies of data reside",
    "start": "1120",
    "end": "6640"
  },
  {
    "text": "in multiple places for performance or business continuity purposes while",
    "start": "6640",
    "end": "12000"
  },
  {
    "text": "this goal could seemingly be accomplished with traditional uni-directional replication",
    "start": "12000",
    "end": "17119"
  },
  {
    "text": "such an architecture would be unlikely to meet the needs of an evolving organization with multiple business units",
    "start": "17119",
    "end": "23920"
  },
  {
    "text": "traditionally this required difficult trade-offs between performance cost and data integrity in some",
    "start": "23920",
    "end": "31039"
  },
  {
    "text": "situations routine maintenance tasks like database upgrades could become a real",
    "start": "31039",
    "end": "36079"
  },
  {
    "text": "issue if there's significant downtime involved in the upgrade process hello everyone my name is shion sanyal",
    "start": "36079",
    "end": "44160"
  },
  {
    "text": "i'm a senior database specialist solutions architect here at aws i specialize in the postgres database",
    "start": "44160",
    "end": "51039"
  },
  {
    "text": "engines including amazon aurora and amazon rds postgres in this video",
    "start": "51039",
    "end": "57280"
  },
  {
    "text": "we will learn about bi-directional replication solutions offered on amazon aurora postgres",
    "start": "57280",
    "end": "62800"
  },
  {
    "text": "that lets your databases scale out across regions and gives you a plan to be always up and",
    "start": "62800",
    "end": "68080"
  },
  {
    "text": "running so our agenda for today is we'll discuss",
    "start": "68080",
    "end": "73360"
  },
  {
    "text": "what amazon error is we'll discuss the distributed storage architecture",
    "start": "73360",
    "end": "79360"
  },
  {
    "text": "we'll cover some use cases for bidirectional replication next we'll take a look at a few",
    "start": "79360",
    "end": "85520"
  },
  {
    "text": "different ways of achieving this in amazon error postgres finally we'll take a look at a quick demo with a",
    "start": "85520",
    "end": "91920"
  },
  {
    "text": "couple of solutions let's start with a short background on",
    "start": "91920",
    "end": "97119"
  },
  {
    "text": "amazon aurora amazon aurora is an enterprise database built for the cloud",
    "start": "97119",
    "end": "104159"
  },
  {
    "text": "it has the speed and availability of high-end commercial databases with the simplicity and cost",
    "start": "104159",
    "end": "110320"
  },
  {
    "text": "effectiveness of open source databases this means that there's no licenses to",
    "start": "110320",
    "end": "115680"
  },
  {
    "text": "manage and no licensing cost it's drop-in compatible with two open",
    "start": "115680",
    "end": "121280"
  },
  {
    "text": "source relational database engines you can either choose mysql or postgres",
    "start": "121280",
    "end": "126960"
  },
  {
    "text": "which means that the code that you wrote for either of these database engines will continue to work with amazon aurora",
    "start": "126960",
    "end": "132959"
  },
  {
    "text": "without making any changes all of this comes with the aws promise of simple pay",
    "start": "132959",
    "end": "139200"
  },
  {
    "text": "as you go pricing let's take a look at the storage",
    "start": "139200",
    "end": "145440"
  },
  {
    "text": "architecture of amazon aurora amazon aurora has a purpose-built log",
    "start": "145440",
    "end": "151200"
  },
  {
    "text": "structure distributed storage under the covers storage volumes get striped across",
    "start": "151200",
    "end": "156879"
  },
  {
    "text": "hundreds of storage nodes the bottom part of the slide with the orange boxes here represent these",
    "start": "156879",
    "end": "162640"
  },
  {
    "text": "storage nodes these nodes are machines with processing power and memory with locally attached",
    "start": "162640",
    "end": "169040"
  },
  {
    "text": "high speed non-volatile memory express or nvme ssds the database doesn't really",
    "start": "169040",
    "end": "176400"
  },
  {
    "text": "know the intricacies of this storage to the database this is simply represented as a cluster storage volume",
    "start": "176400",
    "end": "184480"
  },
  {
    "text": "we also continuously backup and stream the data analogs to amazon s3",
    "start": "184480",
    "end": "189519"
  },
  {
    "text": "for additional durability as part of the distributed storage",
    "start": "189519",
    "end": "195680"
  },
  {
    "text": "architecture we replicate the data six ways each page is replicated across three",
    "start": "195680",
    "end": "200800"
  },
  {
    "text": "availability zones with two copies in each availability zone",
    "start": "200800",
    "end": "206400"
  },
  {
    "text": "this helps us survive failure of an entire az plus an additional failed node we",
    "start": "206400",
    "end": "212959"
  },
  {
    "text": "segment the storage volume into 10 gig protection groups and each protection group is made up of six",
    "start": "212959",
    "end": "218799"
  },
  {
    "text": "10 gig segments these are the six copies of replicated data that we discussed",
    "start": "218799",
    "end": "223840"
  },
  {
    "text": "earlier two in each availability zone with amazon aurora storage scales",
    "start": "223840",
    "end": "230319"
  },
  {
    "text": "automatically in 10 gig increments up to 128 terabyte of maximum database size",
    "start": "230319",
    "end": "237439"
  },
  {
    "text": "now let's talk about a few use cases for bidirectional replication the most common ones include right",
    "start": "238000",
    "end": "245840"
  },
  {
    "text": "scalability within a single region right scalability across multiple",
    "start": "245840",
    "end": "250879"
  },
  {
    "text": "regions blue-green deployment and zero downtime database patching",
    "start": "250879",
    "end": "258720"
  },
  {
    "text": "now with the use cases identified let's take a look at what tools we have in amazon error postgres for enabling these",
    "start": "258959",
    "end": "266840"
  },
  {
    "text": "capabilities first let's take a look at pg logical",
    "start": "266840",
    "end": "273440"
  },
  {
    "text": "the pg logical extension provides logical streaming replication capabilities for postgres",
    "start": "273440",
    "end": "279360"
  },
  {
    "text": "using a publish subscribe model the pg logical extension serves as a basis for many of the",
    "start": "279360",
    "end": "285600"
  },
  {
    "text": "underlying replication technologies and postgres today postgres is a very flexible",
    "start": "285600",
    "end": "290800"
  },
  {
    "text": "platform and we can configure two read write instances in amazon aurora",
    "start": "290800",
    "end": "296000"
  },
  {
    "text": "to work as a bidirectional replication solution without resorting to unwieldy triggers",
    "start": "296000",
    "end": "302240"
  },
  {
    "text": "in this architecture each is truly an independent database so your application must not depend on",
    "start": "302240",
    "end": "308400"
  },
  {
    "text": "any kind of read consensus some of the key features for pg logical",
    "start": "308400",
    "end": "314000"
  },
  {
    "text": "are pg logical is postgres major version agnostic",
    "start": "314000",
    "end": "319199"
  },
  {
    "text": "it's been supported in postgres since version 9.4 and are still supported on later",
    "start": "319199",
    "end": "324560"
  },
  {
    "text": "versions there's no additional cost it's offered as an extension",
    "start": "324560",
    "end": "331280"
  },
  {
    "text": "it's easy to set up and deploy and very well documented in the postgres",
    "start": "331280",
    "end": "336840"
  },
  {
    "text": "community pg logical supports aurora postgres both as a source and a target",
    "start": "336840",
    "end": "344720"
  },
  {
    "text": "the pgeological extension can be used to migrate critical workloads migrate data between postgres major",
    "start": "346320",
    "end": "353280"
  },
  {
    "text": "versions something we call as mvus within the amazon aurora ecosystem",
    "start": "353280",
    "end": "359039"
  },
  {
    "text": "it can also be used to replicate data between two or more postgres instances regardless of where those",
    "start": "359039",
    "end": "365039"
  },
  {
    "text": "instances are located for example you can have a postgres instance on prem",
    "start": "365039",
    "end": "370720"
  },
  {
    "text": "and you can migrate data from on-prem to rds or aurora postgres you can also have data in the source on",
    "start": "370720",
    "end": "378720"
  },
  {
    "text": "aurora postgres and you can migrate data off of aurora postgres to a self-managed postgres",
    "start": "378720",
    "end": "386800"
  },
  {
    "text": "with pg logical you can migrate whole clusters specific tables specific rows or",
    "start": "386960",
    "end": "393199"
  },
  {
    "text": "specific columns you can also replicate specific parts of a schema to other systems",
    "start": "393199",
    "end": "399840"
  },
  {
    "text": "for etl reporting etc",
    "start": "399840",
    "end": "404160"
  },
  {
    "text": "now let's take a look at some of the use cases for pg logical you can use pg logical to migrate from",
    "start": "404960",
    "end": "412400"
  },
  {
    "text": "older versions of postgres into rds or aurora postpress",
    "start": "412400",
    "end": "417599"
  },
  {
    "text": "you can use pg logical to replicate specific tables from source to target",
    "start": "417599",
    "end": "423840"
  },
  {
    "text": "you can also use pg logical for bi-directional replication between two postgres instances as you can see",
    "start": "424080",
    "end": "432240"
  },
  {
    "text": "it's the ideal choice for bi-directional homogeneous replication",
    "start": "432240",
    "end": "437440"
  },
  {
    "text": "it's important to call out that although pg logical is a powerful logical replication tool",
    "start": "437440",
    "end": "442479"
  },
  {
    "text": "it has a few limitations currently pure logical replication and administration",
    "start": "442479",
    "end": "447840"
  },
  {
    "text": "requires super user privileges it may be later extended to allow more granular privileges",
    "start": "447840",
    "end": "455199"
  },
  {
    "text": "unlocked and temporary tables cannot be replicated much like with physical replication",
    "start": "455199",
    "end": "461440"
  },
  {
    "text": "pg logical works on a per database basis to replicate multiple databases you must",
    "start": "461440",
    "end": "467039"
  },
  {
    "text": "set up individual provider subscriber relationships for each updates and deletes cannot be replicated",
    "start": "467039",
    "end": "474240"
  },
  {
    "text": "for tables that lack a primary key or other valid replica identities such as a unique constraint",
    "start": "474240",
    "end": "481280"
  },
  {
    "text": "replication has no way to find the tuple that should be updated or deleted since there is no unique",
    "start": "481280",
    "end": "486720"
  },
  {
    "text": "identifier automatic ddl replication is not supported managing ddls",
    "start": "486720",
    "end": "493120"
  },
  {
    "text": "so that the provider and subscriber databases remain compatible is the sole responsibility of the user",
    "start": "493120",
    "end": "499520"
  },
  {
    "text": "pglogical however provides the replicate ddl command to allow ddls to be run on the provider",
    "start": "499520",
    "end": "505759"
  },
  {
    "text": "and subscriber at a consistent point for more details please visit the link",
    "start": "505759",
    "end": "511120"
  },
  {
    "text": "at the bottom of this slide when would you actually choose pgeological for replication you would",
    "start": "511120",
    "end": "518880"
  },
  {
    "text": "choose pg logical when you need full database replication capabilities between two or more",
    "start": "518880",
    "end": "524159"
  },
  {
    "text": "postgresql databases and this database could be on prem it could be on ec2 instance",
    "start": "524159",
    "end": "530880"
  },
  {
    "text": "or it could be on rds or postgres you would choose pg logical when you",
    "start": "530880",
    "end": "536080"
  },
  {
    "text": "need selective replication of sets of tables through what we call replication sets",
    "start": "536080",
    "end": "542560"
  },
  {
    "text": "you would also choose pgeological if you need selective replication of table rows at either the publisher",
    "start": "542560",
    "end": "548320"
  },
  {
    "text": "or the subscriber side through something called as a row filter",
    "start": "548320",
    "end": "553680"
  },
  {
    "text": "you would choose pgeological if you need selective replication of table columns at publisher side and also",
    "start": "553680",
    "end": "561279"
  },
  {
    "text": "pgeological does support advanced conflict detection and resolution capabilities",
    "start": "561279",
    "end": "567200"
  },
  {
    "text": "the best part all of this comes for free now let's take a look at replication",
    "start": "567200",
    "end": "573200"
  },
  {
    "text": "using oracle golden gate for postgres",
    "start": "573200",
    "end": "577839"
  },
  {
    "text": "oracle announced the general availability of oracle golden gate postgres capture support last year the golden gate postgres",
    "start": "578880",
    "end": "586640"
  },
  {
    "text": "delivery has been supported since golden gate version 12.1 release",
    "start": "586640",
    "end": "591760"
  },
  {
    "text": "and this allows users to replicate the data from golden gate supported heterogeneous databases",
    "start": "591760",
    "end": "596880"
  },
  {
    "text": "example oracle to amazon rds or amazon era postgres databases",
    "start": "596880",
    "end": "603360"
  },
  {
    "text": "with golden gate 19c it now also supports the capture of data from postgres database versions",
    "start": "603360",
    "end": "609680"
  },
  {
    "text": "10 and above let's take a look at a high level",
    "start": "609680",
    "end": "615279"
  },
  {
    "text": "deployment architecture with oracle goldengate and amazon era postgres used for bi-directional replication",
    "start": "615279",
    "end": "622959"
  },
  {
    "text": "in this architecture since this is a cross region setup we set up vpc peering between the source",
    "start": "622959",
    "end": "629200"
  },
  {
    "text": "and target regions in our example this is usc 1 and us west 2.",
    "start": "629200",
    "end": "635519"
  },
  {
    "text": "we then set up source and target bastion hosts on amazon linux ec2 instances to log in securely",
    "start": "635519",
    "end": "642800"
  },
  {
    "text": "to another ec2 instance that has the golden gate software installed",
    "start": "642800",
    "end": "648320"
  },
  {
    "text": "we then set up the extract pump and replicate processes for golden gate on ec2",
    "start": "648320",
    "end": "653680"
  },
  {
    "text": "instances in those two regions next we set up two aurora postgres",
    "start": "653680",
    "end": "659360"
  },
  {
    "text": "database clusters in the source and target regions then we create a source and target",
    "start": "659360",
    "end": "665440"
  },
  {
    "text": "postgres databases tables and users with required privileges",
    "start": "665440",
    "end": "670880"
  },
  {
    "text": "one thing to keep in mind is to ensure that your source and target tables have primary keys",
    "start": "670880",
    "end": "676160"
  },
  {
    "text": "this is primarily useful for cdc or change data capture",
    "start": "676160",
    "end": "682079"
  },
  {
    "text": "enable logical replication by setting rds dot logical replication parameter to 1 in the aurora parameter group",
    "start": "682240",
    "end": "691200"
  },
  {
    "text": "let's look at some of the reasons on when you would want to choose oracle golden gate for replication",
    "start": "691200",
    "end": "697680"
  },
  {
    "text": "you would want to choose golden gate if your use case involves multi-master active active",
    "start": "697680",
    "end": "703200"
  },
  {
    "text": "bi-directional capabilities if you have in-house oracle golden gate",
    "start": "703200",
    "end": "708560"
  },
  {
    "text": "skills expertise as well as existing golden gate licenses that's another reason for",
    "start": "708560",
    "end": "713760"
  },
  {
    "text": "you to choose this solution if you need advanced conflict detection and resolution",
    "start": "713760",
    "end": "720000"
  },
  {
    "text": "capabilities as well as if you need some advanced functionality offered through integrated capture mode",
    "start": "720000",
    "end": "726399"
  },
  {
    "text": "for certain database engines this becomes a really good solution all of this",
    "start": "726399",
    "end": "731920"
  },
  {
    "text": "comes at a cost out of all the solutions oracle golden gate is the most expensive",
    "start": "731920",
    "end": "739600"
  },
  {
    "text": "finally we will take a look at some aws partner network tools available on the aws marketplace for data",
    "start": "739760",
    "end": "745920"
  },
  {
    "text": "replication we will look at them at a very high level",
    "start": "745920",
    "end": "751440"
  },
  {
    "text": "hvr is a powerful software product that enables real-time homogeneous and heterogeneous",
    "start": "751440",
    "end": "757120"
  },
  {
    "text": "data replication hvr uses change data capture methods to",
    "start": "757120",
    "end": "762240"
  },
  {
    "text": "replicate changes between databases directories as well as between databases",
    "start": "762240",
    "end": "767360"
  },
  {
    "text": "and directories that hvr calls locations hvr uses its own internal log mining",
    "start": "767360",
    "end": "774800"
  },
  {
    "text": "technology along with certain database vendor apis the cdc method that hvr uses during a",
    "start": "774800",
    "end": "782240"
  },
  {
    "text": "replication depends on various settings defined or configured within hvr streams enterprise grade",
    "start": "782240",
    "end": "790720"
  },
  {
    "text": "streaming integration platform makes it easy to build continuous streaming data pipelines including",
    "start": "790720",
    "end": "796959"
  },
  {
    "text": "change data capture to power real-time cloud integration log correlation edge processing and",
    "start": "796959",
    "end": "803600"
  },
  {
    "text": "streaming analytics stream moves real-time data from virtually any data source",
    "start": "803600",
    "end": "809360"
  },
  {
    "text": "including enterprise databases via log-based change data capture with real-time data",
    "start": "809360",
    "end": "816160"
  },
  {
    "text": "synchronization capabilities stream also helps companies move data from legacy databases to amazon rds",
    "start": "816160",
    "end": "823839"
  },
  {
    "text": "or aurora databases with near zero downtime and zero data loss and enables an immediate switch over to",
    "start": "823839",
    "end": "830399"
  },
  {
    "text": "the aws environment click replicate formerly at unity",
    "start": "830399",
    "end": "835600"
  },
  {
    "text": "replicate is a data replication and transfer solution that simplifies and accelerates data migration from many",
    "start": "835600",
    "end": "843040"
  },
  {
    "text": "databases to many cloud platforms it does this efficiently and securely",
    "start": "843040",
    "end": "848959"
  },
  {
    "text": "with near zero downtime migration and minimal impact with log based cdc",
    "start": "848959",
    "end": "855040"
  },
  {
    "text": "technology click enables continuous replication to minimize downtime and reduce impact on source",
    "start": "855040",
    "end": "862320"
  },
  {
    "text": "database systems you can also use an intuitive and configurable gui",
    "start": "862320",
    "end": "868320"
  },
  {
    "text": "to quickly and easily set up data migrations with no manual coding",
    "start": "868320",
    "end": "874160"
  },
  {
    "text": "let's look at some of the reasons on when you would want to choose an apn tool for replication",
    "start": "874160",
    "end": "880399"
  },
  {
    "text": "typically when you already have an existing relationship with an apn partner or a vendor",
    "start": "880399",
    "end": "885839"
  },
  {
    "text": "or are looking to develop a new relationship this is when this solution will come in handy",
    "start": "885839",
    "end": "892320"
  },
  {
    "text": "when you need logical database replication capabilities with the ability to do selective replication such as filter",
    "start": "892320",
    "end": "898880"
  },
  {
    "text": "tables columns and rows as well as the ability to deliver changes in a heterogeneous",
    "start": "898880",
    "end": "904480"
  },
  {
    "text": "environment this is also one of the common use cases",
    "start": "904480",
    "end": "909680"
  },
  {
    "text": "when you're looking for more cost effective options with similar change data capture capabilities",
    "start": "909680",
    "end": "915519"
  },
  {
    "text": "and richer support for heterogeneous environments than that is offered by oracle goldengate as well as some multi-master",
    "start": "915519",
    "end": "923279"
  },
  {
    "text": "active active bi-directional capabilities and advanced conflict detection and resolution capabilities",
    "start": "923279",
    "end": "930079"
  },
  {
    "text": "you would want to typically choose an apn partner or a vendor from the aws marketplace",
    "start": "930079",
    "end": "936959"
  },
  {
    "text": "in terms of pricing compared to other solutions like pg logical or oracle golden gate this",
    "start": "936959",
    "end": "943040"
  },
  {
    "text": "fits right in the center with that let's jump into a quick demo okay",
    "start": "943040",
    "end": "950079"
  },
  {
    "text": "so for the demo we'll be actually taking a look at pg logical first and for pg logical what we do is",
    "start": "950079",
    "end": "956639"
  },
  {
    "text": "basically we have two database clusters db1 and db2",
    "start": "956639",
    "end": "962320"
  },
  {
    "text": "one of them is compatible with postpress version 11.9 and the other is 12.4 the first thing",
    "start": "962320",
    "end": "969120"
  },
  {
    "text": "that we need to do is as a prerequisite we need to go to the parameter groups and you'll notice that i've created four",
    "start": "969120",
    "end": "976240"
  },
  {
    "text": "custom parameter groups two for each database cluster and one is",
    "start": "976240",
    "end": "981680"
  },
  {
    "text": "for the cluster levels so db cluster parameter group db1 and similarly one is at the instance",
    "start": "981680",
    "end": "988000"
  },
  {
    "text": "level parameter group and the changes that we need to do here before we do any sort of",
    "start": "988000",
    "end": "993279"
  },
  {
    "text": "replication test is we need to update two parameters so one of them is rds",
    "start": "993279",
    "end": "1001199"
  },
  {
    "text": "dot logical replication set this to one i've already set it to one for my test",
    "start": "1001199",
    "end": "1007920"
  },
  {
    "text": "and the other parameter that we need to change is shared preload libraries we need to include pg logical",
    "start": "1007920",
    "end": "1014480"
  },
  {
    "text": "which is one of the allowed extensions on aurora postgres into the allowed value here",
    "start": "1014480",
    "end": "1020959"
  },
  {
    "text": "similarly if we go to the other cluster parameter group we'll do the same",
    "start": "1020959",
    "end": "1026079"
  },
  {
    "text": "changes i've already done this here just to show you this how it looks like and",
    "start": "1026079",
    "end": "1031199"
  },
  {
    "text": "the other parameter is of course enable logical replication set it to one",
    "start": "1031199",
    "end": "1036480"
  },
  {
    "text": "note that these parameters are apply type static what basically this means is that you",
    "start": "1036480",
    "end": "1043199"
  },
  {
    "text": "will need to reboot your clusters for these parameters to take effect",
    "start": "1043199",
    "end": "1049360"
  },
  {
    "text": "now at the instance level we have two different parameters so db1 instance parameter group so here we need",
    "start": "1049679",
    "end": "1055840"
  },
  {
    "text": "to just make one change which is adding pg logical to shared preload libraries i've already said this",
    "start": "1055840",
    "end": "1062320"
  },
  {
    "text": "and similarly for my db2 instance parameter group i will actually add pg logical as well",
    "start": "1062320",
    "end": "1068559"
  },
  {
    "text": "once you've added it saved your changes you'll notice again the apply type is static for the instance level parameter",
    "start": "1068559",
    "end": "1074640"
  },
  {
    "text": "group as well so we'll go back to the dashboard to the instances and then we'll just",
    "start": "1074640",
    "end": "1080000"
  },
  {
    "text": "reboot our clusters and the way to reboot these clusters would be you select your",
    "start": "1080000",
    "end": "1085360"
  },
  {
    "text": "writer instance and from the actions drop down you can just click on reboot and then confirm",
    "start": "1085360",
    "end": "1092720"
  },
  {
    "text": "okay so my clusters are now rebooted and you'll see the status change to available from rebooting once the reboot",
    "start": "1093679",
    "end": "1101360"
  },
  {
    "text": "is complete so for the next step we'll be using",
    "start": "1101360",
    "end": "1106840"
  },
  {
    "text": "cloud9 and cloud9 is basically a cloud-based ide that lets",
    "start": "1106840",
    "end": "1113280"
  },
  {
    "text": "you write run and debug your code with just a browser it includes a code editor debugger as",
    "start": "1113280",
    "end": "1119919"
  },
  {
    "text": "well as a terminal and you'll see here that i'm using the terminal so i've split up my terminal into two",
    "start": "1119919",
    "end": "1126320"
  },
  {
    "text": "different panes on the left i'll be using uh for logging into my db1 cluster",
    "start": "1126320",
    "end": "1132240"
  },
  {
    "text": "and on the right i'll be using that to log into my db2 cluster the tool that i use to log into my",
    "start": "1132240",
    "end": "1137919"
  },
  {
    "text": "postgres cluster is going to be p sql and p sql is a pretty lightweight easy",
    "start": "1137919",
    "end": "1143520"
  },
  {
    "text": "to use terminal based command line utility that you can use to query your postgres",
    "start": "1143520",
    "end": "1150240"
  },
  {
    "text": "clusters so the first step is to log into my cluster so i've",
    "start": "1150240",
    "end": "1155840"
  },
  {
    "text": "i'll log into my cluster using p sql in db1 on the left and db2 on the right",
    "start": "1155840",
    "end": "1162480"
  },
  {
    "text": "you'll notice the server version so db1 is 11.9 db2 is 12.4 the first step is to create",
    "start": "1162480",
    "end": "1170000"
  },
  {
    "text": "a user and grant that user super user privileges for us to go ahead with the replication so the",
    "start": "1170000",
    "end": "1177039"
  },
  {
    "text": "way we do this is i'll create a user pg user and grant the rds super user privilege to this",
    "start": "1177039",
    "end": "1183440"
  },
  {
    "text": "user similar steps on the other cluster",
    "start": "1183440",
    "end": "1188480"
  },
  {
    "text": "once that's done we'll need to use or create a table test table for our replication purposes",
    "start": "1189520",
    "end": "1196400"
  },
  {
    "text": "and i'm just creating a test table table one pretty basic with an id int primary key",
    "start": "1196400",
    "end": "1203440"
  },
  {
    "text": "and info text and value end with three columns and similar table will be created on the",
    "start": "1203440",
    "end": "1209600"
  },
  {
    "text": "subscriber side the next step is to actually insert some",
    "start": "1209600",
    "end": "1216240"
  },
  {
    "text": "rows or insert some values into this test table i'll insert some five values so let's test what was",
    "start": "1216240",
    "end": "1223280"
  },
  {
    "text": "inserted i have these five values here notice that i'm not inserting anything",
    "start": "1223280",
    "end": "1229039"
  },
  {
    "text": "on the subscriber's side yet so if i do a select star from table one there's nothing here the way we'll fill in this",
    "start": "1229039",
    "end": "1236480"
  },
  {
    "text": "table is actually going to be a one-way replication from the publisher to the subscriber's",
    "start": "1236480",
    "end": "1241600"
  },
  {
    "text": "side and we'll see this in action so the next step is to actually set up",
    "start": "1241600",
    "end": "1247120"
  },
  {
    "text": "pg logical extension at the database level so the way we do this is using the create extension command",
    "start": "1247120",
    "end": "1254080"
  },
  {
    "text": "that's done uh we'll also do this on the subscriber side so let me do that",
    "start": "1254080",
    "end": "1260400"
  },
  {
    "text": "as well next we need to create the publisher and the",
    "start": "1260400",
    "end": "1265600"
  },
  {
    "text": "subscriber nodes now nodes within pg logical are nothing but these are your postgres database",
    "start": "1265600",
    "end": "1271520"
  },
  {
    "text": "instances and the way to create these nodes is using the create node sql interface",
    "start": "1271520",
    "end": "1279039"
  },
  {
    "text": "so i'm just calling my node node one publisher node as node one i pass in the dsn so these are the only",
    "start": "1279360",
    "end": "1285919"
  },
  {
    "text": "two parameters for create node similarly i'll create",
    "start": "1285919",
    "end": "1291520"
  },
  {
    "text": "a subscriber node call it node 2",
    "start": "1291520",
    "end": "1295520"
  },
  {
    "text": "and now what i need to do is there's this concept of a replication set within pg logical so replication",
    "start": "1299360",
    "end": "1305679"
  },
  {
    "text": "sets provide a mechanism to control which tables and the database will be replicated",
    "start": "1305679",
    "end": "1311280"
  },
  {
    "text": "as well as which actions on those tables will be replicated and these actions are nothing but these",
    "start": "1311280",
    "end": "1316559"
  },
  {
    "text": "could be dmls like inserts updates to deletes or ddls like truncates and the way you",
    "start": "1316559",
    "end": "1323120"
  },
  {
    "text": "specify this is using the replication set add table sql interface here what we are doing is",
    "start": "1323120",
    "end": "1330880"
  },
  {
    "text": "we are basically adding all tables in the public schema to our replication set and the way to do this is using the",
    "start": "1330880",
    "end": "1337120"
  },
  {
    "text": "replication set add all table sql interface",
    "start": "1337120",
    "end": "1342240"
  },
  {
    "text": "now once all the tables in a public schema are added there's just one table table one so this should pretty much",
    "start": "1342240",
    "end": "1349919"
  },
  {
    "text": "be replicated over to the subscriber but then we need to we are missing a step which is where we",
    "start": "1349919",
    "end": "1355520"
  },
  {
    "text": "need to create a subscription first and the way to create a subscription on the subscriber side is",
    "start": "1355520",
    "end": "1361200"
  },
  {
    "text": "using the create subscription sql interface so this creates",
    "start": "1361200",
    "end": "1366799"
  },
  {
    "text": "our subscription note that we are just calling it subscription one the provider",
    "start": "1366799",
    "end": "1372799"
  },
  {
    "text": "dsn is the db1 cluster that we are using here as a provider",
    "start": "1372799",
    "end": "1378159"
  },
  {
    "text": "and the replication set is the default so this is basically uh what we are using here at the",
    "start": "1378159",
    "end": "1383440"
  },
  {
    "text": "publisher side so now if i do a select star from table one",
    "start": "1383440",
    "end": "1388720"
  },
  {
    "text": "i should actually be able to see the rows getting populated so boom there we go we have the five",
    "start": "1388720",
    "end": "1395760"
  },
  {
    "text": "rows from our publisher side replicated over to the subscriber's side",
    "start": "1395760",
    "end": "1402000"
  },
  {
    "text": "okay so now that we've completed the initial setup let's actually proceed by testing one way replication",
    "start": "1402000",
    "end": "1409360"
  },
  {
    "text": "the way we'll do that is i'll try inserting one row into my table one",
    "start": "1409360",
    "end": "1417840"
  },
  {
    "text": "see that it gets inserted and also try to see at the same time on the rep on the subscriber side it gets populated",
    "start": "1420080",
    "end": "1429360"
  },
  {
    "text": "similarly if i try to update the same row",
    "start": "1429360",
    "end": "1434640"
  },
  {
    "text": "i'm updating the same row with id 11 and i'm setting the value to 10.",
    "start": "1435520",
    "end": "1444000"
  },
  {
    "text": "let's see if it flows through to the subscriber side",
    "start": "1444000",
    "end": "1449039"
  },
  {
    "text": "all right that looks good and now we'll actually see if a delete can also work exactly",
    "start": "1449039",
    "end": "1455120"
  },
  {
    "text": "the same way i'm deleting the row that i just added",
    "start": "1455120",
    "end": "1460158"
  },
  {
    "text": "see that it gets deleted and the changes flow through to the subscriber side",
    "start": "1460559",
    "end": "1466320"
  },
  {
    "text": "all right so that looks good so one way replication looks good now we'll proceed with",
    "start": "1466320",
    "end": "1472559"
  },
  {
    "text": "setting up the bi-directional replication and the way to set up bi-directional replication",
    "start": "1472559",
    "end": "1477679"
  },
  {
    "text": "there's just a few couple of more steps to this so one thing we need to do is set up",
    "start": "1477679",
    "end": "1483440"
  },
  {
    "text": "publication on our db2 cluster so now because this will become a new",
    "start": "1483440",
    "end": "1488559"
  },
  {
    "text": "publisher and this will become a new subscriber so the way we'll do this is using the sql",
    "start": "1488559",
    "end": "1494159"
  },
  {
    "text": "interface and the final step is to actually",
    "start": "1494159",
    "end": "1501919"
  },
  {
    "text": "set publisher the original publisher as a subscriber so we'll do this using this command note",
    "start": "1501919",
    "end": "1509440"
  },
  {
    "text": "that the provider dsn in this case becomes your db2 cluster which is your new publisher or provider in this case",
    "start": "1509440",
    "end": "1517760"
  },
  {
    "text": "all right so that should set up bi-directional replication so now let's actually proceed with testing the bi-directional replication",
    "start": "1518080",
    "end": "1526000"
  },
  {
    "text": "so what i'll do is on my database cluster one i'll insert a value",
    "start": "1526000",
    "end": "1532960"
  },
  {
    "text": "check the results here so my new row got inserted let me also",
    "start": "1533279",
    "end": "1540960"
  },
  {
    "text": "verify um here okay so the one way still works now let",
    "start": "1540960",
    "end": "1547600"
  },
  {
    "text": "me do it uh the reverse order so i'll try inserting a value here and",
    "start": "1547600",
    "end": "1556400"
  },
  {
    "text": "see the value here first so 30 gets inserted also see the value here so 30 is also",
    "start": "1556400",
    "end": "1563120"
  },
  {
    "text": "inserted so it works both ways so now actually with that in place we see",
    "start": "1563120",
    "end": "1569360"
  },
  {
    "text": "that the basic bi-directional replication works let's do a conflict test",
    "start": "1569360",
    "end": "1575600"
  },
  {
    "text": "and what we'll do is let's actually run an update statement on",
    "start": "1575600",
    "end": "1582000"
  },
  {
    "text": "db cluster 2. now what i'm doing here is where id equal to 1 i'm setting the value to 20.",
    "start": "1582000",
    "end": "1589919"
  },
  {
    "text": "and similarly on host 1 i'm running a similar update statement",
    "start": "1590559",
    "end": "1596880"
  },
  {
    "text": "but i'm setting a value to a different value i'm setting it to 30 where id equal to one so you'll see that",
    "start": "1596880",
    "end": "1602720"
  },
  {
    "text": "both of them flow through successfully however let's see which one is the final",
    "start": "1602720",
    "end": "1608480"
  },
  {
    "text": "result on the tables which one gets updated so we'll see that the latest commit",
    "start": "1608480",
    "end": "1613840"
  },
  {
    "text": "value so this in this case this is the this is coming from the original public publisher side or the new subscriber",
    "start": "1613840",
    "end": "1620640"
  },
  {
    "text": "side which was the most recent committed value gets populated in both the sides so you",
    "start": "1620640",
    "end": "1628720"
  },
  {
    "text": "have your id 1 with value 30 id1 with value 30.",
    "start": "1628720",
    "end": "1634640"
  },
  {
    "text": "so that's the default behavior so basically in pg logical you get a number of conflict resolution options",
    "start": "1634640",
    "end": "1641520"
  },
  {
    "text": "by default it is configured to accept the remote version of the change in case of a conflict",
    "start": "1641520",
    "end": "1647279"
  },
  {
    "text": "and you can always change this parameter by going to your rds console and actually",
    "start": "1647279",
    "end": "1654000"
  },
  {
    "text": "going to the parameter groups if you go to the cluster level parameter",
    "start": "1654000",
    "end": "1660320"
  },
  {
    "text": "and then search for conflict resolution so these are the various",
    "start": "1660320",
    "end": "1666640"
  },
  {
    "text": "values that you can actually set it to the default value of course is applied remote which is where the remote",
    "start": "1666640",
    "end": "1672159"
  },
  {
    "text": "changes got applied and then the values got synchronized across both both the sides",
    "start": "1672159",
    "end": "1677679"
  },
  {
    "text": "and that's basically bi-directional replication with pg logical",
    "start": "1677679",
    "end": "1683840"
  },
  {
    "text": "so for our oracle goldengate for postgres demo we need to look at a few prerequisites",
    "start": "1684000",
    "end": "1690080"
  },
  {
    "text": "first we need to enable logical replication for our source and target aurora postgres databases by setting the",
    "start": "1690080",
    "end": "1696320"
  },
  {
    "text": "rds logical replication parameter to one second we need to ensure the source and",
    "start": "1696320",
    "end": "1702159"
  },
  {
    "text": "target tables for both our aurora postgres databases have the same primary keys",
    "start": "1702159",
    "end": "1708000"
  },
  {
    "text": "and third we need to enable supplemental logging using add tran data and tran log options",
    "start": "1708000",
    "end": "1714080"
  },
  {
    "text": "filter table parameter to enable bi-directional replication oracle has also published a pretty",
    "start": "1714080",
    "end": "1720320"
  },
  {
    "text": "detailed blog on how to set up this on the oracle side so i've posted the link here we'll also",
    "start": "1720320",
    "end": "1727200"
  },
  {
    "text": "share this link in the description box so that you can go and follow along",
    "start": "1727200",
    "end": "1732559"
  },
  {
    "text": "now let's jump into the demo so for our oracle postgres demo we have a cross region",
    "start": "1733120",
    "end": "1740000"
  },
  {
    "text": "setup where you'll see the region here on the left is northern virginia which is my source",
    "start": "1740000",
    "end": "1746559"
  },
  {
    "text": "and i have a source database cluster called apg source and on the right side i have my target",
    "start": "1746559",
    "end": "1752240"
  },
  {
    "text": "region which is oregon which is usq and the target database instance is called uh",
    "start": "1752240",
    "end": "1758240"
  },
  {
    "text": "apg target instance the cluster is a vg target so let's make sure that logical",
    "start": "1758240",
    "end": "1764240"
  },
  {
    "text": "replication for my database parameter group is actually set to one",
    "start": "1764240",
    "end": "1771120"
  },
  {
    "text": "so that's one here i'll check the same on the target side",
    "start": "1772399",
    "end": "1781840"
  },
  {
    "text": "so that's set to one all right now on this",
    "start": "1781919",
    "end": "1788720"
  },
  {
    "text": "screen you'll see four terminals on the left is my source and on the",
    "start": "1788720",
    "end": "1795039"
  },
  {
    "text": "right is my target top left is my source golden gate installation with ec2",
    "start": "1795039",
    "end": "1801760"
  },
  {
    "text": "instance and on the bottom is my i'll use this as a window to as a terminal to query my",
    "start": "1801760",
    "end": "1809360"
  },
  {
    "text": "postgres source database at the top right i'll be using this to",
    "start": "1809360",
    "end": "1815200"
  },
  {
    "text": "log into my goldengate ec2 instance and then on the bottom right i'll be using this to log into",
    "start": "1815200",
    "end": "1820559"
  },
  {
    "text": "my postgres target instance using p sql so let's actually make sure on the",
    "start": "1820559",
    "end": "1827440"
  },
  {
    "text": "source that golden gate processes are running perfectly so i'll",
    "start": "1827440",
    "end": "1835120"
  },
  {
    "text": "do i'll log into ggsci and then check info all so this tells me",
    "start": "1835120",
    "end": "1841919"
  },
  {
    "text": "that the extract and the replicate processors are running on the source let's also verify this on",
    "start": "1841919",
    "end": "1848080"
  },
  {
    "text": "the target site so ggsci and then info all",
    "start": "1848080",
    "end": "1854480"
  },
  {
    "text": "i have my extract and the replica processors running on the target side as well",
    "start": "1854480",
    "end": "1860159"
  },
  {
    "text": "so with that let's actually see what is in the database so i have",
    "start": "1860159",
    "end": "1865679"
  },
  {
    "text": "my pc client libraries installed here and what i'll do is uh",
    "start": "1865679",
    "end": "1872159"
  },
  {
    "text": "you see what we are starting with so i have preloaded a set of tables here from a sample schema called dms sample and that has",
    "start": "1875760",
    "end": "1883600"
  },
  {
    "text": "16 rows let's also make sure that we are at the same page on the",
    "start": "1883600",
    "end": "1889840"
  },
  {
    "text": "target side so we are at the same starting point so we have a sample schema with 16 tables",
    "start": "1889840",
    "end": "1896399"
  },
  {
    "text": "loaded in both the source and the target side now what i want to do is first and",
    "start": "1896399",
    "end": "1902320"
  },
  {
    "text": "foremost i want to test basic replication and i will see",
    "start": "1902320",
    "end": "1908480"
  },
  {
    "text": "i'll start inserting data from the source and see whether it gets populated to the target so let me",
    "start": "1908480",
    "end": "1916640"
  },
  {
    "text": "start inserting value into one table so i'll be using mlb data as my test table and i'm inserting",
    "start": "1916640",
    "end": "1924240"
  },
  {
    "text": "some values here and i'll look for whether that gets inserted successfully",
    "start": "1924240",
    "end": "1930320"
  },
  {
    "text": "on the source first yes and the target so yes",
    "start": "1930320",
    "end": "1937039"
  },
  {
    "text": "and you see the speed at which it got inside it's really near instantaneous and what i'll do is",
    "start": "1937039",
    "end": "1944240"
  },
  {
    "text": "on the target side i'll do the same test and try inserting some data here i'll call it 201",
    "start": "1944240",
    "end": "1951600"
  },
  {
    "text": "and verify my data exists in the target side first",
    "start": "1951600",
    "end": "1959279"
  },
  {
    "text": "it does and then on the source side all right so both",
    "start": "1959279",
    "end": "1966240"
  },
  {
    "text": "both the ways work and similar is true for update as well as delete now let's move on to conflict",
    "start": "1966240",
    "end": "1974000"
  },
  {
    "text": "detection and resolution so p sql by default has autocomplete set to on",
    "start": "1974000",
    "end": "1980080"
  },
  {
    "text": "and for this test what we will do is set out a commit to off on both source and target",
    "start": "1980080",
    "end": "1991360"
  },
  {
    "text": "and there's one specific table that i'll be testing with which is called ticket purchase history",
    "start": "1991360",
    "end": "1997279"
  },
  {
    "text": "and let's actually look at the schema for that on the source so we noticed that",
    "start": "1997279",
    "end": "2004159"
  },
  {
    "text": "we have a primary key on sporting event ticket id and the purchase by id",
    "start": "2004159",
    "end": "2010960"
  },
  {
    "text": "and let's also verify the schema on the target side i'll use this command so backslash d is",
    "start": "2010960",
    "end": "2017760"
  },
  {
    "text": "a quick and dirty way np sql it's called the meta command to look at the structure of your table",
    "start": "2017760",
    "end": "2024399"
  },
  {
    "text": "as well as look at the indexes column level details and so on so this has the exact same primary key",
    "start": "2024399",
    "end": "2032960"
  },
  {
    "text": "so notice that we had a prerequisite of both the tables having the same primary key so this is satisfied so now",
    "start": "2032960",
    "end": "2039519"
  },
  {
    "text": "what i'll do is try updating a particular row in this table",
    "start": "2039519",
    "end": "2047840"
  },
  {
    "text": "from the source side so what i'm doing is setting a purchase price of 30 where supporting event ticket id is some",
    "start": "2048879",
    "end": "2056079"
  },
  {
    "text": "number remember that this is not yet committed on the source side",
    "start": "2056079",
    "end": "2062480"
  },
  {
    "text": "and let's also view what is the current value so we saw that there's 133 rows",
    "start": "2062480",
    "end": "2068800"
  },
  {
    "text": "that got updated and it's updated to 30 so the purchase",
    "start": "2068800",
    "end": "2075358"
  },
  {
    "text": "price is 30 the transaction date time is now so this is what we used",
    "start": "2075359",
    "end": "2081440"
  },
  {
    "text": "and i'll use the similar query but i'll do a different update so i'll update it to a different",
    "start": "2081440",
    "end": "2087118"
  },
  {
    "text": "value on the target side i'm updating it to a value 57 on the",
    "start": "2087119",
    "end": "2092800"
  },
  {
    "text": "target side this also updated 133 rows let's see",
    "start": "2092800",
    "end": "2097839"
  },
  {
    "text": "whether the values got updated yes and notice that the transaction date time is a",
    "start": "2097839",
    "end": "2103599"
  },
  {
    "text": "little ahead so this is the most recent timestamp that we have and this is the most recent value",
    "start": "2103599",
    "end": "2110960"
  },
  {
    "text": "now if i press commit so basically committing the",
    "start": "2112320",
    "end": "2117599"
  },
  {
    "text": "value let me commit it at the source first and then i'll commit",
    "start": "2117599",
    "end": "2122720"
  },
  {
    "text": "it and the target doesn't matter it can be either way now let's actually look at the values",
    "start": "2122720",
    "end": "2128320"
  },
  {
    "text": "that put the source and the target size for this transaction",
    "start": "2128320",
    "end": "2133599"
  },
  {
    "text": "so there was a little bit of a delay there but you'll notice that the latest value that we are using for the time",
    "start": "2138400",
    "end": "2144079"
  },
  {
    "text": "stamp that gets updated near instantaneously to both the",
    "start": "2144079",
    "end": "2149599"
  },
  {
    "text": "sides and this is primarily because we use",
    "start": "2149599",
    "end": "2154640"
  },
  {
    "text": "something called as resolved calls to actually resolve this conflict",
    "start": "2154640",
    "end": "2160160"
  },
  {
    "text": "and the way it'll look like is you can see this in your",
    "start": "2160160",
    "end": "2172400"
  },
  {
    "text": "parameter files so i'll look at my",
    "start": "2172400",
    "end": "2177760"
  },
  {
    "text": "replicat parameter file as an example so you'll notice that i'm using whenever",
    "start": "2177760",
    "end": "2184640"
  },
  {
    "text": "there is a row that's that exists on both the source and the target in this case it was seven three eight",
    "start": "2184640",
    "end": "2189680"
  },
  {
    "text": "one four four eight two one with the ticket id i'm using um use max transaction date",
    "start": "2189680",
    "end": "2197200"
  },
  {
    "text": "time so whatever is the maximum transaction date time that is going to be updated as the",
    "start": "2197200",
    "end": "2202640"
  },
  {
    "text": "conflict resolution protocol and this is what we saw here where our value became 57",
    "start": "2202640",
    "end": "2208640"
  },
  {
    "text": "on both the sides there are various other ways of handling this there's good documentation from oracle",
    "start": "2208640",
    "end": "2214000"
  },
  {
    "text": "on this but this proves that oracle golden gate can now be used as a",
    "start": "2214000",
    "end": "2219760"
  },
  {
    "text": "fully uh baked solution for enabling bi-directional replication",
    "start": "2219760",
    "end": "2225119"
  },
  {
    "text": "for aurora post databases to wrap up i will leave you with a bunch",
    "start": "2225119",
    "end": "2230640"
  },
  {
    "text": "of resources here to learn more about the various solutions we looked at in this session",
    "start": "2230640",
    "end": "2237520"
  },
  {
    "text": "so that brings us to the end of this video i hope this was useful and you will take",
    "start": "2237920",
    "end": "2243839"
  },
  {
    "text": "advantage of the various bi-directional replication solutions offered on amazon aurora postgres today",
    "start": "2243839",
    "end": "2251040"
  },
  {
    "text": "thank you so much for watching and happy cloud computing from all of us here at aws",
    "start": "2251040",
    "end": "2268319"
  }
]
[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "good afternoon and thank you for being here if people is still sitting there's",
    "start": "979",
    "end": "6870"
  },
  {
    "text": "lots of space on the other side of the room so my name is Danilo I'm part of the Evangelist team and I will be",
    "start": "6870",
    "end": "14009"
  },
  {
    "text": "leatherby joined on stage by Toninho greco head of infrastructure and DevOps in donal and the idea is to explain what",
    "start": "14009",
    "end": "22050"
  },
  {
    "text": "we learn from our customer bakunin and how to be successful with continuous",
    "start": "22050",
    "end": "27599"
  },
  {
    "text": "integration and continuous deployment on AWS and the reason why we think that this is really important is because the",
    "start": "27599",
    "end": "37440"
  },
  {
    "start": "30000",
    "end": "70000"
  },
  {
    "text": "fastest you can bring the new feature you're building the new feature you're planning in the hands of your customer and get a feedback the faster you",
    "start": "37440",
    "end": "44190"
  },
  {
    "text": "understand you're going in the right direction with your development then this is the the faster you can improve",
    "start": "44190",
    "end": "50219"
  },
  {
    "text": "and add new features this is really giving you the speed of your development team it's not a number of release per",
    "start": "50219",
    "end": "56670"
  },
  {
    "text": "day or release or the code lines that you write is leading how fast is a new feature that you build to go in the",
    "start": "56670",
    "end": "63300"
  },
  {
    "text": "hands of your customers and this is really improving innovation a lot this is something we learn inside Amazon and",
    "start": "63300",
    "end": "69689"
  },
  {
    "text": "with our customers and to be successful we see three pillars that you should",
    "start": "69689",
    "end": "75000"
  },
  {
    "start": "70000",
    "end": "98000"
  },
  {
    "text": "implement first is to start to manage your infrastructure as code then",
    "start": "75000",
    "end": "80960"
  },
  {
    "text": "implement on top of that a continuous integration progress process that can also implement your own infrastructure",
    "start": "80960",
    "end": "88140"
  },
  {
    "text": "and then continuously be able being able to continuously deploy new features",
    "start": "88140",
    "end": "93409"
  },
  {
    "text": "safely in the hands of your customers so let's start with infrastructure as code so infrastructure as code means as the",
    "start": "93409",
    "end": "101070"
  },
  {
    "start": "98000",
    "end": "141000"
  },
  {
    "text": "term implies that you have some files normally certain plate but we will see that there are other options that",
    "start": "101070",
    "end": "107270"
  },
  {
    "text": "describes the infrastructure you need for your for your architecture in this way building your infrastructure becomes",
    "start": "107270",
    "end": "113759"
  },
  {
    "text": "is easily to be repeatable so that you can build new environment maybe you want",
    "start": "113759",
    "end": "119310"
  },
  {
    "text": "to create and spin up a performance environment just for a few minutes if you want and also the release management",
    "start": "119310",
    "end": "125310"
  },
  {
    "text": "of infrastructure as plates can follow the same approach that you have with software you can do small release of",
    "start": "125310",
    "end": "133090"
  },
  {
    "text": "you can test them in your test environment to the tube maybe spin up just for the purpose and so on in this",
    "start": "133090",
    "end": "139720"
  },
  {
    "text": "way you is that really the basis for for what we want to build today normally on",
    "start": "139720",
    "end": "145540"
  },
  {
    "start": "141000",
    "end": "203000"
  },
  {
    "text": "AWS we have a tool is called AWS CloudFormation and you can connect that",
    "start": "145540",
    "end": "150730"
  },
  {
    "text": "with your source repository using tools like auth pipeline that we will see later and when you commit your code you",
    "start": "150730",
    "end": "158050"
  },
  {
    "text": "go into a build stage where your template is prepared depending on the syntax that you use and then you can",
    "start": "158050",
    "end": "164110"
  },
  {
    "text": "implement multiple staging environment for example stage environment a user acceptance environment and of course the",
    "start": "164110",
    "end": "171010"
  },
  {
    "text": "production environment when you apply a change to an environment transformation",
    "start": "171010",
    "end": "176799"
  },
  {
    "text": "works with two steps two steps that first create and then execute what we",
    "start": "176799",
    "end": "183250"
  },
  {
    "text": "call a change set a change that describes what are the changes that this update in the infrastructure is building",
    "start": "183250",
    "end": "190120"
  },
  {
    "text": "to that environment and optionally you can put a manual approval so that you can verify that the change set is",
    "start": "190120",
    "end": "195670"
  },
  {
    "text": "compliant with your process in your rules for example if someone is changing the configuration of a security group that is okay before it's released for",
    "start": "195670",
    "end": "204700"
  },
  {
    "start": "203000",
    "end": "248000"
  },
  {
    "text": "specific applications confirmation can be a little bit verbose because it was designed really to be generic so we over",
    "start": "204700",
    "end": "211810"
  },
  {
    "text": "the years create a different simplification on top of transformation so one of these is the possibility to",
    "start": "211810",
    "end": "217720"
  },
  {
    "text": "have macros that can process a template and output a confirmation template and the first one that we releases when",
    "start": "217720",
    "end": "224200"
  },
  {
    "text": "matters were still not a public feature for our customer is Sam the civiles application model this is a open source",
    "start": "224200",
    "end": "231090"
  },
  {
    "text": "temp language that is a superset of Confirmation you can still use code for",
    "start": "231090",
    "end": "237069"
  },
  {
    "text": "measure inside I'm not entering into too much the face of Sam now because there's a session that I'm presenting as well",
    "start": "237069",
    "end": "243700"
  },
  {
    "text": "later on in this room on severest functions so I'd like to talk you about another project that we're working on",
    "start": "243700",
    "end": "249700"
  },
  {
    "start": "248000",
    "end": "408000"
  },
  {
    "text": "currently it's still in the palaver preview but it's really interesting and it's called the cloud development kit so",
    "start": "249700",
    "end": "256269"
  },
  {
    "text": "lots of the times when people talks about infrastructure as code we actually use templates that are mostly written in",
    "start": "256269",
    "end": "262659"
  },
  {
    "text": "camel and people start to say that this is actually infrastructure as not infrastructure as code so with the",
    "start": "262659",
    "end": "268659"
  },
  {
    "text": "city came we want to change that so the idea is that you can use your favorite programming language to describe your",
    "start": "268659",
    "end": "274870"
  },
  {
    "text": "infrastructure and we provide you our series of high-level construct that are",
    "start": "274870",
    "end": "282030"
  },
  {
    "text": "altered by developers so and try to simplify the implementation of resources",
    "start": "282030",
    "end": "288690"
  },
  {
    "text": "beyond the normal syntax of CloudFormation but the output of the silica is still a valid confirmation",
    "start": "288690",
    "end": "295539"
  },
  {
    "text": "template this is an open source project that's the the link and you can start",
    "start": "295539",
    "end": "301509"
  },
  {
    "text": "experimenting with the cdk today you can install it with NPM it's written in ojs",
    "start": "301509",
    "end": "307900"
  },
  {
    "text": "and then you have this DK command line that you can use to initialize your first project and you can choose the",
    "start": "307900",
    "end": "314379"
  },
  {
    "text": "language that you want to use this is not the language you're going to use for developing your application in this case this is the language you're going to use",
    "start": "314379",
    "end": "320680"
  },
  {
    "text": "to describe your infrastructure so normally a strongly typed language works better because if you have an IDE that",
    "start": "320680",
    "end": "327039"
  },
  {
    "text": "can see the GDK libraries it will automatically complete the code as you've right so strongly typed language",
    "start": "327039",
    "end": "333069"
  },
  {
    "text": "with a robust ID work very well and most of the examples that we do today are",
    "start": "333069",
    "end": "339159"
  },
  {
    "text": "using typescript that is typed version of JavaScript but there's we currently support C sharp F sharp Java Python that",
    "start": "339159",
    "end": "346599"
  },
  {
    "text": "is not strongly typed and we are planning to add more before of the GA of",
    "start": "346599",
    "end": "351909"
  },
  {
    "text": "the of the city K when you start this new application you can edit and we will",
    "start": "351909",
    "end": "358569"
  },
  {
    "text": "see how the code appears and then you can use the CD command line to synthetize this will transform the",
    "start": "358569",
    "end": "364960"
  },
  {
    "text": "programming language into a confirmation template in output you can automatically deploy from the city K this will",
    "start": "364960",
    "end": "370599"
  },
  {
    "text": "implement a confirmation stack automatically you can compare the difference between what's in your files",
    "start": "370599",
    "end": "376990"
  },
  {
    "text": "and what is already deployed on AWS so for example if you change the configuration on s3 bucket you can see",
    "start": "376990",
    "end": "383289"
  },
  {
    "text": "that actually your current configuration is different from the deployed one and then you can deploy the change and you",
    "start": "383289",
    "end": "391000"
  },
  {
    "text": "can of course destroy the stack maybe especially if it's a test stack that you were building and this this comma line",
    "start": "391000",
    "end": "397870"
  },
  {
    "text": "is designed to be easily other than implemented in an automation pipeline so if you have us here putting delivery pipeline if you",
    "start": "397870",
    "end": "405520"
  },
  {
    "text": "use Jenkins for example or code builder called pipeline this is an example of",
    "start": "405520",
    "end": "411130"
  },
  {
    "start": "408000",
    "end": "482000"
  },
  {
    "text": "our cdk template in typescript appears so here I'm creating a CD case TOC I'm",
    "start": "411130",
    "end": "417160"
  },
  {
    "text": "extending a CD case tak that means that these are full stuff that I can then implement with confirmation and these",
    "start": "417160",
    "end": "423790"
  },
  {
    "text": "few lines of code create a V PC so all the networking that I need for my application then I create an SES cluster",
    "start": "423790",
    "end": "431140"
  },
  {
    "text": "for my containers and then I create a lot balanced service using forget for my",
    "start": "431140",
    "end": "436660"
  },
  {
    "text": "containers to run the container in a severus way based on a specific docker",
    "start": "436660",
    "end": "442060"
  },
  {
    "text": "image and as you see this is really high-level you don't need to enter into the older the taste normally you have",
    "start": "442060",
    "end": "447850"
  },
  {
    "text": "with with the CloudFormation and then you can run the app and this will be transformed into a confirmation template",
    "start": "447850",
    "end": "454000"
  },
  {
    "text": "these 22 lines of code generate around 400 lines of transformation that's why",
    "start": "454000",
    "end": "459160"
  },
  {
    "text": "it's much easier to manage and when you work with code is also interesting because you can create components that",
    "start": "459160",
    "end": "466510"
  },
  {
    "text": "we call constructs that you can reuse in other stuff so instead of copying and pasting llaman configuration files that",
    "start": "466510",
    "end": "473770"
  },
  {
    "text": "is prone to error especially Yama because it's not very well delimited you can just create a high level component",
    "start": "473770",
    "end": "480250"
  },
  {
    "text": "and then import that into another stack this is an example of using the cdk with",
    "start": "480250",
    "end": "485320"
  },
  {
    "start": "482000",
    "end": "613000"
  },
  {
    "text": "lambda to create along the function that is executed with a cron schedule so here",
    "start": "485320",
    "end": "490480"
  },
  {
    "text": "I again I'm extending a CD case stack then I create so this is a cut will",
    "start": "490480",
    "end": "496300"
  },
  {
    "text": "become a confirmation stack here I'm declaring a lambda function and there are this normal option that you have",
    "start": "496300",
    "end": "502660"
  },
  {
    "text": "when you create a function of what is the angular the time out the runtime that I use then I create a rule for",
    "start": "502660",
    "end": "509410"
  },
  {
    "text": "cloud watch events that is based on the cron syntax this is executed I think every day Monday to Friday at 6 p.m. and",
    "start": "509410",
    "end": "517719"
  },
  {
    "text": "then I connect this rule with the the lambda function as a target that means that this function will be triggered",
    "start": "517720",
    "end": "523570"
  },
  {
    "text": "every day Monday to Friday with that schedule it's I think it's very much readable you can have similar syntax in",
    "start": "523570",
    "end": "529510"
  },
  {
    "text": "Java as I said before or a in other languages and it's easy to maintain and with the silicon you can",
    "start": "529510",
    "end": "536550"
  },
  {
    "text": "also think of managing that the deployment infrastructure as code so let's imagine that you have micro",
    "start": "536550",
    "end": "542730"
  },
  {
    "text": "services and maybe you have five ten 20 micro services each of those micro services will have their own delivery",
    "start": "542730",
    "end": "548519"
  },
  {
    "text": "pipeline and you have to configure that probably in a similar way because you have your own standard for delivery you",
    "start": "548519",
    "end": "554819"
  },
  {
    "text": "can do that with the city case so here I'm not creating extending a CD case stock but I am extending a cdk",
    "start": "554819",
    "end": "561420"
  },
  {
    "text": "constructor that means this is a resources that we'll be able to use inside a stack and I'm basically",
    "start": "561420",
    "end": "567029"
  },
  {
    "text": "configuring my own generic pipeline that is based on corporate line is connected",
    "start": "567029",
    "end": "573689"
  },
  {
    "text": "with the data using my access token a specific generic configuration and some",
    "start": "573689",
    "end": "579300"
  },
  {
    "text": "configuration comes as parameter where when I use will use this constructor and",
    "start": "579300",
    "end": "584519"
  },
  {
    "text": "then for example if I have four services that have to use this micro service",
    "start": "584519",
    "end": "590370"
  },
  {
    "text": "pipeline I then can create my own micro service pipeline stack where I use the",
    "start": "590370",
    "end": "597480"
  },
  {
    "text": "constructor I defined before so I import it and use it four times in this case",
    "start": "597480",
    "end": "602730"
  },
  {
    "text": "with different options so it's much if so that's why I was saying you don't need to cut copy and paste you can just",
    "start": "602730",
    "end": "608339"
  },
  {
    "text": "reference a construct that you've declared before inside the stack that you want to configure so this is for",
    "start": "608339",
    "end": "615059"
  },
  {
    "start": "613000",
    "end": "647000"
  },
  {
    "text": "infrastructure as code the next step is continuous integration with continuous integration we want to make it easier so",
    "start": "615059",
    "end": "623250"
  },
  {
    "text": "that every time somebody's committing their code into the central repo you get",
    "start": "623250",
    "end": "628800"
  },
  {
    "text": "an automatic build or you get a failure that tells you that the build is not working so this is giving you a first",
    "start": "628800",
    "end": "634709"
  },
  {
    "text": "very fast feedback for the developers that they're gone in the right direction and also allows you to always have an",
    "start": "634709",
    "end": "640470"
  },
  {
    "text": "artifact ready for deployment in case you want to deploy the new features in production to do that you can use",
    "start": "640470",
    "end": "649139"
  },
  {
    "start": "647000",
    "end": "668000"
  },
  {
    "text": "different tools of course only the breath we have a tool that is called code pipeline that comes from the",
    "start": "649139",
    "end": "655319"
  },
  {
    "text": "experience inside Amazon we have a tools that with extreme fantasy we call it we",
    "start": "655319",
    "end": "661170"
  },
  {
    "text": "call it pipelines and code pipeline is a sternal implementation of debt and the",
    "start": "661170",
    "end": "667630"
  },
  {
    "text": "idea here is to help you automate the delivery and you can connect different",
    "start": "667630",
    "end": "673720"
  },
  {
    "start": "668000",
    "end": "728000"
  },
  {
    "text": "resources as triggers for the start of the delivery pipeline so if you want to use a git repo you can use github or you",
    "start": "673720",
    "end": "680860"
  },
  {
    "text": "can use code Kermit our fully managed git repo on AWS or you can integrate",
    "start": "680860",
    "end": "686290"
  },
  {
    "text": "with external tools by uploading your source code to Amazon s3 as a as a zip",
    "start": "686290",
    "end": "692440"
  },
  {
    "text": "file or you can integrate with ECR so the container repository on AWS so when",
    "start": "692440",
    "end": "699310"
  },
  {
    "text": "you release a new image of a container this starts your delivery process actually there are in fact two schools",
    "start": "699310",
    "end": "705520"
  },
  {
    "text": "here and there is really no no process there's pros and cons in both strategy",
    "start": "705520",
    "end": "711010"
  },
  {
    "text": "so some people they prefer to trigger the pipeline with source code commit all",
    "start": "711010",
    "end": "716320"
  },
  {
    "text": "the people they want to have they use already are a specific tool to create the container image when they commit and",
    "start": "716320",
    "end": "722110"
  },
  {
    "text": "then they want to use this upload of the new docker image as the start of the delivery pipeline Kota Bank can support",
    "start": "722110",
    "end": "730330"
  },
  {
    "start": "728000",
    "end": "803000"
  },
  {
    "text": "also different triggers so it can be integrated with cloud watch events calvache events is a part of cloud watch",
    "start": "730330",
    "end": "736840"
  },
  {
    "text": "that the same one that was using before for the cron schedule so you can for example schedule a nightly release if",
    "start": "736840",
    "end": "743410"
  },
  {
    "text": "you want or a nightly build and also toddler events can intercept lots of different events on the WS platform so",
    "start": "743410",
    "end": "750310"
  },
  {
    "text": "for example if you use Fargate is container environment where your containers don't need to be provisioning",
    "start": "750310",
    "end": "756430"
  },
  {
    "text": "on top of an easy distance we manage the infrastructure for you up to the kernel of the operating system and we have some",
    "start": "756430",
    "end": "763030"
  },
  {
    "text": "versioning on on Fargate so maybe you want to be alerted by automatically by carwash events when there is a new",
    "start": "763030",
    "end": "769030"
  },
  {
    "text": "version or when an old version is being retired because maybe there's some security and you need to update to a",
    "start": "769030",
    "end": "775780"
  },
  {
    "text": "newer version using a newer kernel and this events can trigger a pipeline that can automatically build tests and",
    "start": "775780",
    "end": "782500"
  },
  {
    "text": "eventually also deploy the application using the new version of the of our gate will be release this of course SDK and",
    "start": "782500",
    "end": "789130"
  },
  {
    "text": "CLI and also we recently added support at the end of last year for web books so",
    "start": "789130",
    "end": "794470"
  },
  {
    "text": "that means that you can integrate using web hooks with docker hub and other tools that you can use for dog",
    "start": "794470",
    "end": "802030"
  },
  {
    "text": "repositories for the build process we also have a tool so in case you don't",
    "start": "802030",
    "end": "808870"
  },
  {
    "text": "want to use Jenkins that's the tool that lots of people are using but you want to have something that is fully managed you",
    "start": "808870",
    "end": "814600"
  },
  {
    "text": "can have abuse could build you pay by the minute for the build environment and you can monitor the build in different",
    "start": "814600",
    "end": "821380"
  },
  {
    "text": "ways including using cloud watch events and code build tries to runs the builds",
    "start": "821380",
    "end": "827350"
  },
  {
    "text": "every time in a consistent environment so every time you get a container image that is clean is never reused",
    "start": "827350",
    "end": "832870"
  },
  {
    "text": "where you run the build process in this way the build process is always consistent we have standard docker image",
    "start": "832870",
    "end": "838900"
  },
  {
    "text": "for most programming languages and or you can bring your own container image if you prefer and to to talk to code",
    "start": "838900",
    "end": "846700"
  },
  {
    "text": "build how the build process works you have to prepare a build spec file and this is an example of how you would",
    "start": "846700",
    "end": "851980"
  },
  {
    "text": "build a build spec file for a lambda function you have a list of faces in",
    "start": "851980",
    "end": "857890"
  },
  {
    "text": "this case the first phase is built then you have the usual command for building in case of not GS you can use an NPM if",
    "start": "857890",
    "end": "864580"
  },
  {
    "text": "it's Java you use maven or something like that and then with confirmation you package the service application and you",
    "start": "864580",
    "end": "871180"
  },
  {
    "text": "upload it to Ana's three bucket and you write an output template that is they",
    "start": "871180",
    "end": "877180"
  },
  {
    "text": "are actually the artifact of this build since the code is uploaded to s3 and the",
    "start": "877180",
    "end": "882190"
  },
  {
    "text": "output is this artifact that is can be then be passed to transformation to implement the changes this the same",
    "start": "882190",
    "end": "889810"
  },
  {
    "text": "version can be reimplemented in this I think a slightly cleaner way using the same CLI the same salaices a CLI that we",
    "start": "889810",
    "end": "897610"
  },
  {
    "text": "created for using the several application model so in this case I added a new face in my build process the",
    "start": "897610",
    "end": "903610"
  },
  {
    "text": "install face where I install and upgrade the SS July and the same CLI",
    "start": "903610",
    "end": "909040"
  },
  {
    "text": "then the build process can use the same CLI to do the build and the packaging and then everything is similar to the",
    "start": "909040",
    "end": "915250"
  },
  {
    "text": "previous case same bill supports not all round times just for now but suppose Java not GSM Python for example that are",
    "start": "915250",
    "end": "922839"
  },
  {
    "text": "probably among the most common ones if you use containers you can use docker",
    "start": "922839",
    "end": "929160"
  },
  {
    "text": "to Parker to prepare them image tag the image and push the image to your favorite repo if you use the elastic",
    "start": "929160",
    "end": "936000"
  },
  {
    "text": "container registry on AWS you can use this command to create and get the login",
    "start": "936000",
    "end": "941699"
  },
  {
    "text": "to get the login for your account and execute the login as output of the",
    "start": "941699",
    "end": "947100"
  },
  {
    "text": "command so that then the docker command will upload the image for you so this",
    "start": "947100",
    "end": "952199"
  },
  {
    "start": "951000",
    "end": "1038000"
  },
  {
    "text": "was for container for continuous integration let's move now on continuous deployment so continuous deployment is",
    "start": "952199",
    "end": "959819"
  },
  {
    "text": "the most important step is also the most delicate one now the idea here is that we want to mostly in an automated way",
    "start": "959819",
    "end": "966899"
  },
  {
    "text": "bring a committee of your code in the hands of your customer some people they",
    "start": "966899",
    "end": "972930"
  },
  {
    "text": "want to add an approval stage a manual approval stage may be between tests and",
    "start": "972930",
    "end": "978389"
  },
  {
    "text": "productions is something that you can do especially at the beginning when you gain confidence and the key here is",
    "start": "978389",
    "end": "983519"
  },
  {
    "text": "really to do small deployments that have a very minimal blast radius in case",
    "start": "983519",
    "end": "990779"
  },
  {
    "text": "something goes wrong so don't expect to do a large deployment in this way you need to do multiple deployments per day",
    "start": "990779",
    "end": "996959"
  },
  {
    "text": "probably in each deployment there are very narrow scope so that can be easy to understand if it works or not",
    "start": "996959",
    "end": "1002779"
  },
  {
    "text": "and if there are side effects so continuous deployment really means that we want to automate the process up to at",
    "start": "1002779",
    "end": "1010430"
  },
  {
    "text": "least up to the staging environment the idea is really to build process that can",
    "start": "1010430",
    "end": "1016519"
  },
  {
    "text": "help you with deploy safely and we will see how different strategies can be used here like Canada deployments and what",
    "start": "1016519",
    "end": "1023060"
  },
  {
    "text": "which tools we created to help you doing that on AWS and this is probably the",
    "start": "1023060",
    "end": "1029058"
  },
  {
    "text": "most important part of representation so if you can deploy automatically and faster to your customers then you can",
    "start": "1029059",
    "end": "1035418"
  },
  {
    "text": "quickly get feedback and improve your application so for deployment we have a tool on AWS that is called code deploy",
    "start": "1035419",
    "end": "1042339"
  },
  {
    "start": "1038000",
    "end": "1363000"
  },
  {
    "text": "it's based on an internal tool that comes from Amazon it is called Apollo and when we release code deploy a few",
    "start": "1042339",
    "end": "1049220"
  },
  {
    "text": "years ago it was able to deploy only to ec2 instances but over time we added more features so you can deploy also to",
    "start": "1049220",
    "end": "1056299"
  },
  {
    "text": "build a machine on premise if you want to use the same approach in an ibrid architecture you can deploy",
    "start": "1056299",
    "end": "1063110"
  },
  {
    "text": "with PCs and it can also deploy now lambda function this is a feature that",
    "start": "1063110",
    "end": "1068750"
  },
  {
    "text": "we added not this room vent the previous rate vent at the end of 2017",
    "start": "1068750",
    "end": "1074320"
  },
  {
    "text": "so with lambda we wanted to make it easy to do deployment and candidate",
    "start": "1074320",
    "end": "1080179"
  },
  {
    "text": "deployment the idea here is that with civilization deployment is very fast you upload your new with a new version of",
    "start": "1080179",
    "end": "1086840"
  },
  {
    "text": "your function and what happens is that immediately all your customers start to see the new version of your application",
    "start": "1086840",
    "end": "1093049"
  },
  {
    "text": "this is good for the speed but can be risky because lots of people want to",
    "start": "1093049",
    "end": "1098120"
  },
  {
    "text": "have a canary strategy where you maybe test with a small subset of invocation to see if the function works and then",
    "start": "1098120",
    "end": "1104179"
  },
  {
    "text": "you roll out maybe slowly to all your customers so to do that we integrate",
    "start": "1104179",
    "end": "1109309"
  },
  {
    "text": "these deployment strategies in code deploy and we also simplify the configuration of code deploy using some",
    "start": "1109309",
    "end": "1117460"
  },
  {
    "text": "adding some configuration option to Sam so with just a few lines of code in Sam",
    "start": "1117460",
    "end": "1122929"
  },
  {
    "text": "and we will see which lines you can automate all everything that I'm showing now so let's say that you have verse from one of your lambda function in in",
    "start": "1122929",
    "end": "1130490"
  },
  {
    "text": "production this function is serving behind an API gateway and and you use an",
    "start": "1130490",
    "end": "1137150"
  },
  {
    "text": "alias analysis a dynamic link that you can have a for a different version of",
    "start": "1137150",
    "end": "1143090"
  },
  {
    "text": "your function in this case we use the alias live you can use the ugliest broad or something like that and live links",
    "start": "1143090",
    "end": "1150280"
  },
  {
    "text": "100% of the invocations are sent to version 1 of my function then I create",
    "start": "1150280",
    "end": "1156049"
  },
  {
    "text": "verse from 2 I upload my new code of the function I create version 2 of my lambda",
    "start": "1156049",
    "end": "1161660"
  },
  {
    "text": "function and the alias is still still sending everything to the to version 1 and we can at this point run what we",
    "start": "1161660",
    "end": "1168860"
  },
  {
    "text": "call a pre traffic hook so normally with deployments you the idea is to add hooks",
    "start": "1168860",
    "end": "1175010"
  },
  {
    "text": "that are tests that you run during the deployment to see if everything works so in this case we run a protracted hook",
    "start": "1175010",
    "end": "1182090"
  },
  {
    "text": "that means that when the new version of the function is being created but still no customer has had access to this new",
    "start": "1182090",
    "end": "1188120"
  },
  {
    "text": "version you can run a lambda function that is the pre traffic hook that does whatever you want so it's your code and",
    "start": "1188120",
    "end": "1194809"
  },
  {
    "text": "at the end hold back Oh deploy giving success or failure so that Cody Boyd knows if he",
    "start": "1194809",
    "end": "1200520"
  },
  {
    "text": "needs to go on with the deployment or rollback immediately so for example you can run here some",
    "start": "1200520",
    "end": "1205710"
  },
  {
    "text": "final smoke test on the function in a production environment maybe you prepare some synthetic transactions that you",
    "start": "1205710",
    "end": "1213090"
  },
  {
    "text": "would execute safely in production to see that everything works with the data also that you end the integration that",
    "start": "1213090",
    "end": "1218159"
  },
  {
    "text": "you have in production you can also run if you want a stress test because",
    "start": "1218159",
    "end": "1224100"
  },
  {
    "text": "there's no timely limit here since the lambda function is executed by code deploy but code deploy is not waiting",
    "start": "1224100",
    "end": "1230250"
  },
  {
    "text": "for the lambda function to terminate is waiting for an explicit call back the lambda function can call other lambda",
    "start": "1230250",
    "end": "1235350"
  },
  {
    "text": "function or containers or whatever application you want it needs to pass an ID of the deployment and then with this",
    "start": "1235350",
    "end": "1241890"
  },
  {
    "text": "ID any application can call back called deploy and say go on or roll back this deployment so you can even run three",
    "start": "1241890",
    "end": "1248669"
  },
  {
    "text": "hours of stress test in this stage if you want when you when the free traffic book that gives the okay we start to",
    "start": "1248669",
    "end": "1256200"
  },
  {
    "text": "move traffic and here we have different strategies so the canary strategies maybe you give 10% of the invocation to",
    "start": "1256200",
    "end": "1262320"
  },
  {
    "text": "the new version and 90% of the invocation of the function remain to the old version and during this phase you we",
    "start": "1262320",
    "end": "1269909"
  },
  {
    "text": "can monitor up I think to five cloud",
    "start": "1269909",
    "end": "1275010"
  },
  {
    "text": "watch alarms that you can define to monitor your application so you can for example module if this is an API if you",
    "start": "1275010",
    "end": "1282419"
  },
  {
    "text": "get an error for your API from the API gateway you can monitor the latency of your API so if the latency of your API",
    "start": "1282419",
    "end": "1288210"
  },
  {
    "text": "is too high this is another alarm if any of those alarms are raised we roll back",
    "start": "1288210",
    "end": "1293610"
  },
  {
    "text": "to the end 100% of the vocation go back to the version 1 of your application",
    "start": "1293610",
    "end": "1299399"
  },
  {
    "text": "this is managed automatically you can define the alarm before the deployment if no alarm is raised all the traffic at",
    "start": "1299399",
    "end": "1306330"
  },
  {
    "text": "some point will be moved to the new version depending on the deployment strategy and then you can run another",
    "start": "1306330",
    "end": "1311549"
  },
  {
    "text": "hook the post traffic hook so this is executed when 100% of the load is on the",
    "start": "1311549",
    "end": "1317399"
  },
  {
    "text": "new version and you can do from final check if you want on the latency you can",
    "start": "1317399",
    "end": "1322830"
  },
  {
    "text": "run maybe other synthetic transaction to see that everything works you can also use this to annotate your get read",
    "start": "1322830",
    "end": "1329560"
  },
  {
    "text": "to tell that this specific version is actually being deployed in production this is important because with CIN CD",
    "start": "1329560",
    "end": "1336340"
  },
  {
    "text": "people assumes that if you commit code this goes in in production but as we saw deployment can be rejected if you get an",
    "start": "1336340",
    "end": "1343420"
  },
  {
    "text": "error so this is a can be a good way to say okay this commit ID is actually the",
    "start": "1343420",
    "end": "1348550"
  },
  {
    "text": "one that I have in production so that if you have a bug you know which is the right version of your source code to look at to find the bug so if this post",
    "start": "1348550",
    "end": "1356650"
  },
  {
    "text": "traffic hook again gives success then we everything goes to the new version and",
    "start": "1356650",
    "end": "1362350"
  },
  {
    "text": "the deployment is completed so to do all this configuration you just need to add these few lines in your same template so",
    "start": "1362350",
    "end": "1369700"
  },
  {
    "start": "1363000",
    "end": "1447000"
  },
  {
    "text": "you have to give an auto publish alias so in this case live you need to give a",
    "start": "1369700",
    "end": "1375460"
  },
  {
    "text": "deployment preference and we have a list of pre-baked to deployment preferences Kennedy deployments are two stages like",
    "start": "1375460",
    "end": "1383290"
  },
  {
    "text": "10% and then after some time 100% of the user has access to the new version for",
    "start": "1383290",
    "end": "1390160"
  },
  {
    "text": "five up to 30 minutes linear deployments are more gradual so you can have for",
    "start": "1390160",
    "end": "1395260"
  },
  {
    "text": "example a linear 10% every one minute it's one of my favorite actually where every minute we move 10% of an",
    "start": "1395260",
    "end": "1401110"
  },
  {
    "text": "invocation on the new version and then in 10 minutes you complete the deployment or if you prefer you can be",
    "start": "1401110",
    "end": "1406360"
  },
  {
    "text": "slower you can do 10% every 2 minutes or 10 minutes or you can still have all at once and this is something that you can",
    "start": "1406360",
    "end": "1413470"
  },
  {
    "text": "have if you have non interactive API for example if you're processing a stream of data it doesn't make sense to do cannery",
    "start": "1413470",
    "end": "1419590"
  },
  {
    "text": "deployment for a data processing of a stream of data because then you have mixed result in the stream so in that case you use all at once or your test",
    "start": "1419590",
    "end": "1426790"
  },
  {
    "text": "environment where you want to quickly test the new version for everybody after",
    "start": "1426790",
    "end": "1432250"
  },
  {
    "text": "the deployment preference type you have the alarms that we should model during the deployment and the hooks that are",
    "start": "1432250",
    "end": "1437560"
  },
  {
    "text": "executed before and after both alarms and hooks are optional but are especially the alarms are strongly",
    "start": "1437560",
    "end": "1443860"
  },
  {
    "text": "suggested for an automatic rollback there is another option that we launched",
    "start": "1443860",
    "end": "1449830"
  },
  {
    "start": "1447000",
    "end": "1566000"
  },
  {
    "text": "at the same time and not a lot of people notice that there is the canary stage also in the API gateway so this works",
    "start": "1449830",
    "end": "1456820"
  },
  {
    "text": "only for API the previous feature is at lambda level so any lambda function can use them so with the via gateway you",
    "start": "1456820",
    "end": "1462990"
  },
  {
    "text": "have the concept of stages normally you have a production stage and maybe a test stage or you can have multiple stages",
    "start": "1462990",
    "end": "1468659"
  },
  {
    "text": "for different version of your API you can now create a scan early stage and then tell today a gateway to move us",
    "start": "1468659",
    "end": "1475440"
  },
  {
    "text": "even a small percentage of the API invocation to the canary stage like 0.1%",
    "start": "1475440",
    "end": "1481200"
  },
  {
    "text": "or 0.5% so it's very small gray very fine-grained here the difference here is",
    "start": "1481200",
    "end": "1488820"
  },
  {
    "text": "that first of all you're moving traffic across a whole stage so if you have multiple lambda function behind a single",
    "start": "1488820",
    "end": "1495539"
  },
  {
    "text": "API gateway you can control the rollout from one version to the other version",
    "start": "1495539",
    "end": "1501210"
  },
  {
    "text": "all at once while the previous example is per function so if you have ten functions they are deployed in parallel",
    "start": "1501210",
    "end": "1507659"
  },
  {
    "text": "and here there is no automation so we don't manage this with code deploy you have to use either the console or the",
    "start": "1507659",
    "end": "1514980"
  },
  {
    "text": "CLI to to manage and change the percentage and then eventually you can",
    "start": "1514980",
    "end": "1520350"
  },
  {
    "text": "promote the canary stage to production or delete the canary stage and roll back to the previous version so you can add",
    "start": "1520350",
    "end": "1527490"
  },
  {
    "text": "this command in any tool and do the your own automation actually we also think",
    "start": "1527490",
    "end": "1532740"
  },
  {
    "text": "that this feature can be used for doing something more similar to an a/b development test",
    "start": "1532740",
    "end": "1537870"
  },
  {
    "text": "so what you can do here is maybe you'd send 0.5% of your in API invocation to",
    "start": "1537870",
    "end": "1543389"
  },
  {
    "text": "the new version for one hour or even one day and then you can all the metrics",
    "start": "1543389",
    "end": "1550169"
  },
  {
    "text": "that we collect with cloud watch will be tagged with this version of the API and the stage of the API that you using so",
    "start": "1550169",
    "end": "1557279"
  },
  {
    "text": "you can check and then you can compare if for example your customer actually using better the new version and the old",
    "start": "1557279",
    "end": "1562860"
  },
  {
    "text": "version or not we also added Bluegreen",
    "start": "1562860",
    "end": "1568139"
  },
  {
    "start": "1566000",
    "end": "1728000"
  },
  {
    "text": "deployments for containers so this is ECS I'm actually not talking about",
    "start": "1568139",
    "end": "1573600"
  },
  {
    "text": "kubernetes and AEK s during my session because in that case you use of course the kubernetes toolset for doing",
    "start": "1573600",
    "end": "1579510"
  },
  {
    "text": "Bluegreen deployments with ECS we added this feature at the end of last year",
    "start": "1579510",
    "end": "1584960"
  },
  {
    "text": "after event and the idea is to do to be able to deploy in parallel a new",
    "start": "1584960",
    "end": "1590830"
  },
  {
    "text": "environment test it and and and again hooks that can test that everything",
    "start": "1590830",
    "end": "1595990"
  },
  {
    "text": "works at different stages so here you have lots of granularity with the stage that you can add hooks so before the",
    "start": "1595990",
    "end": "1603250"
  },
  {
    "text": "installation of the new environment after the installation before any traffic is allowed to the new green",
    "start": "1603250",
    "end": "1609039"
  },
  {
    "text": "version or after the traffic has been allowed to the to the new version so",
    "start": "1609039",
    "end": "1615070"
  },
  {
    "text": "this is an example of an app spec file that you can give to ECS to deploy in a",
    "start": "1615070",
    "end": "1621850"
  },
  {
    "text": "Bluegreen way an update to an ICS service so do you have an updated task",
    "start": "1621850",
    "end": "1627970"
  },
  {
    "text": "definition this is like an update of a podunk uber nades and then you can had hooks that are executed before and after",
    "start": "1627970",
    "end": "1636159"
  },
  {
    "text": "install before and after you allow traffic and so on and what happens is",
    "start": "1636159",
    "end": "1641380"
  },
  {
    "text": "that at the beginning you have a lot balancer that sends your production traffic maybe import a tour for Fort Lee",
    "start": "1641380",
    "end": "1648059"
  },
  {
    "text": "to a target group that sends everything to your version one of your tasks of",
    "start": "1648059",
    "end": "1655029"
  },
  {
    "text": "your application then with a Bluegreen deployment you will create a test",
    "start": "1655029",
    "end": "1661690"
  },
  {
    "text": "listener maybe on a port that you can access but your customer don't have access like port 9000 this creates a new",
    "start": "1661690",
    "end": "1669190"
  },
  {
    "text": "target group that sends traffic to the new version the green version of your task and at this point the customers",
    "start": "1669190",
    "end": "1675850"
  },
  {
    "text": "still have no access to the new version but when you create when we connect to test it the test traffic listener we can",
    "start": "1675850",
    "end": "1683710"
  },
  {
    "text": "execute the hooks these are lambda function in this case that can test the",
    "start": "1683710",
    "end": "1689139"
  },
  {
    "text": "new version of your container based application and and do whatever you want again you can do a quick test or you can",
    "start": "1689139",
    "end": "1696250"
  },
  {
    "text": "stay here for a few hours running a performance test and when you are satisfied you give succeed or fail back",
    "start": "1696250",
    "end": "1704260"
  },
  {
    "text": "to code deploy is the same syntax as the lambda hooks before and and then we move",
    "start": "1704260",
    "end": "1709870"
  },
  {
    "text": "the traffic from the production port to the new target group we drain the old",
    "start": "1709870",
    "end": "1717279"
  },
  {
    "text": "environment because here there is a legacy environment needs to have all previous connection to be",
    "start": "1717279",
    "end": "1722280"
  },
  {
    "text": "drained and then we destroy the previous environment so that everything is on a new version to make it easier to",
    "start": "1722280",
    "end": "1730530"
  },
  {
    "start": "1728000",
    "end": "1786000"
  },
  {
    "text": "configure code pipeline in a complex setup we also deployed is actually being",
    "start": "1730530",
    "end": "1737970"
  },
  {
    "text": "deployed by our professional services this is an open-source project it's called the SS deployment framework",
    "start": "1737970",
    "end": "1743300"
  },
  {
    "text": "because when we talk with customers we realized that most of the time they need to deploy in multiple accounts because",
    "start": "1743300",
    "end": "1749460"
  },
  {
    "text": "maybe an account is production account is test this is our strong suggestion and across multiple regions maybe they",
    "start": "1749460",
    "end": "1755520"
  },
  {
    "text": "have parallel environment in multiple regions or they have a region for test and another region for production so to",
    "start": "1755520",
    "end": "1760980"
  },
  {
    "text": "do that with the normal tools that we provide can be complex so this framework can help you create a single",
    "start": "1760980",
    "end": "1766890"
  },
  {
    "text": "configuration files that then is translated in all the configuration that you need to run to configure code pipeline across different accounts and",
    "start": "1766890",
    "end": "1773490"
  },
  {
    "text": "different regions so I strongly suggest if you want to do that to have a look at this tool with this we set the three",
    "start": "1773490",
    "end": "1781590"
  },
  {
    "text": "pillars that can help you run see ICD well on a de Bresse and let's see our",
    "start": "1781590",
    "end": "1787380"
  },
  {
    "text": "case study from quite interesting customer so let's invite Tonino on stage",
    "start": "1787380",
    "end": "1792690"
  },
  {
    "start": "1792000",
    "end": "2274000"
  },
  {
    "text": "and let's welcome to Nino [Applause]",
    "start": "1792690",
    "end": "1801519"
  },
  {
    "text": "so who here knows dan Alma not that many so done Alma's over 170",
    "start": "1801519",
    "end": "1810049"
  },
  {
    "text": "stores nationwide we have a lot of warehouses and Depot's we have our own",
    "start": "1810049",
    "end": "1815179"
  },
  {
    "text": "delivery network we have a bunch of offices and us being in London we're also the UK's number one home wares",
    "start": "1815179",
    "end": "1822409"
  },
  {
    "text": "retailer we have over 9,000 employees within the company we manufacture in the",
    "start": "1822409",
    "end": "1828470"
  },
  {
    "text": "UK and we in a bit we are a billion pound company interesting part about dan",
    "start": "1828470",
    "end": "1834919"
  },
  {
    "text": "army is that we're in undergoing a radical change to our technology stack we're moving away from traditional",
    "start": "1834919",
    "end": "1841370"
  },
  {
    "text": "waterfall we're moving into the Spotify model and this presents us with a bunch of opportunities we moved on to a new",
    "start": "1841370",
    "end": "1850370"
  },
  {
    "text": "web platform onto service and this compounded our challenges as we moved",
    "start": "1850370",
    "end": "1857149"
  },
  {
    "text": "onto the Spotify model we have multiple independent tribes all wanting to deploy into AWS not just normal deployments but",
    "start": "1857149",
    "end": "1864049"
  },
  {
    "text": "civilus deployments these civilized employments were quite complex and we",
    "start": "1864049",
    "end": "1869960"
  },
  {
    "text": "had to find a solution DevOps team specifically and we wanted to be able to do the complete CI CD capability so",
    "start": "1869960",
    "end": "1876260"
  },
  {
    "text": "deploy often and deploy rapidly so our answer well we started using sem CLI and",
    "start": "1876260",
    "end": "1883929"
  },
  {
    "text": "we wrapped it in ansible mainly because we wanted to create a pipeline library a",
    "start": "1883929",
    "end": "1889490"
  },
  {
    "text": "library of functions that the developers could use that will enable them to deploy and create pipelines themselves",
    "start": "1889490",
    "end": "1895820"
  },
  {
    "text": "we use the Jenkins planners code plug-in from from Jenkins and we wanted to make",
    "start": "1895820",
    "end": "1902929"
  },
  {
    "text": "our functions and our library extensible reproducible and simple so that",
    "start": "1902929",
    "end": "1908210"
  },
  {
    "text": "developers were able to quickly on board and do what they needed to do and deploy rapidly and as a nice thing we added",
    "start": "1908210",
    "end": "1915440"
  },
  {
    "text": "slack integrations everybody had slack integrations so how does it work so we",
    "start": "1915440",
    "end": "1922340"
  },
  {
    "text": "start out with a git commit and this would be within any sort of git repository within get",
    "start": "1922340",
    "end": "1928790"
  },
  {
    "text": "this sends a Jenkins webhook to Jenkins and from there we download the",
    "start": "1928790",
    "end": "1934550"
  },
  {
    "text": "automation code and the product code we do some validation on the code to make sure that everything is okay some basic",
    "start": "1934550",
    "end": "1941450"
  },
  {
    "text": "linting and we create a worker node this is the node that all the work is going",
    "start": "1941450",
    "end": "1946700"
  },
  {
    "text": "to get done on you know whether it be testing compiling building separate node so that will give that scalability",
    "start": "1946700",
    "end": "1953240"
  },
  {
    "text": "options so as 10 or 15 or 20 developers are all deploying at the same time we",
    "start": "1953240",
    "end": "1958730"
  },
  {
    "text": "have ten or fifteen or twenty worker nodes that are created and we create these nodes on spot instances so we can",
    "start": "1958730",
    "end": "1964550"
  },
  {
    "text": "save a bit of cash on the load we have all these software that's required to",
    "start": "1964550",
    "end": "1969620"
  },
  {
    "text": "run the build and we have very few nodes worker nodes different types from there",
    "start": "1969620",
    "end": "1977240"
  },
  {
    "text": "we do some security validation this was quite a contentious thing with the developers they didn't like the fact",
    "start": "1977240",
    "end": "1983120"
  },
  {
    "text": "that we were stopping their bills because they had obsolete libraries in their code we also do some library scans",
    "start": "1983120",
    "end": "1989470"
  },
  {
    "text": "vulnerability scans to make sure that what we're putting out for our customers is is safe we then compile the software",
    "start": "1989470",
    "end": "1997220"
  },
  {
    "text": "or build it in in in most cases it's compiled we have very few containers with our environment and those",
    "start": "1997220",
    "end": "2003310"
  },
  {
    "text": "containers are you know they're getting less and less daily we run a bunch of tests against it",
    "start": "2003310",
    "end": "2009640"
  },
  {
    "text": "mostly unit tests functional testing some of the developers of added additional stages into this again our",
    "start": "2009640",
    "end": "2016840"
  },
  {
    "text": "pipelines are highly customizable and with that they've added whole bunch other text like for instance our",
    "start": "2016840",
    "end": "2022060"
  },
  {
    "text": "front-end guys have added you know performance tests on the front-end site you know is this deployment going to",
    "start": "2022060",
    "end": "2027790"
  },
  {
    "text": "make our site slower if so stop it is this deployment game to make our site",
    "start": "2027790",
    "end": "2033060"
  },
  {
    "text": "you know have a higher latency stop it you know all those kind of things this",
    "start": "2033060",
    "end": "2038290"
  },
  {
    "text": "gives us an early warning capability before we deploy to a production environment or through any of the environments and then we run a deploying",
    "start": "2038290",
    "end": "2045690"
  },
  {
    "text": "now the deploy as mentioned earlier is is Sam CLI wrapped in ansible and the",
    "start": "2045690",
    "end": "2052658"
  },
  {
    "text": "reason we wrap it is because we want to be able to control how that's done you know give give all the developers all",
    "start": "2052659",
    "end": "2058720"
  },
  {
    "text": "the tribes the same [Music] process that they would use and we",
    "start": "2058720",
    "end": "2063908"
  },
  {
    "text": "wrapped it and ansible because the rest of our infrastructure as code is also written in ansible and with that any",
    "start": "2063909",
    "end": "2070780"
  },
  {
    "text": "changes to you things like security groups or routing tables or DNS entries or any of that kind of stuff it's all",
    "start": "2070780",
    "end": "2076600"
  },
  {
    "text": "wrapped in the same pipeline as part of this stack we've got quite a few benefits out of it because we have a",
    "start": "2076600",
    "end": "2084190"
  },
  {
    "text": "central library we've had a simple mechanism for the developers to use it was reproducible and it was security",
    "start": "2084190",
    "end": "2090820"
  },
  {
    "text": "conscious which means security was built in from the beginning we didn't have to try and add it in afterwards and upset everybody everybody knew that it was",
    "start": "2090820",
    "end": "2097300"
  },
  {
    "text": "gonna have a security scan everybody knew their security was gonna be part of the original thing and we had",
    "start": "2097300",
    "end": "2103060"
  },
  {
    "text": "scalability from performance so each pipeline as I mentioned has its own worker node running on spot instances so",
    "start": "2103060",
    "end": "2108520"
  },
  {
    "text": "if ten developers are deploying we have ten spots in two spot nodes after the pipeline is concluded whether it was",
    "start": "2108520",
    "end": "2114100"
  },
  {
    "text": "successfully deployed or not that worker node is removed and it was highly",
    "start": "2114100",
    "end": "2119440"
  },
  {
    "text": "customisable our pipeline library was made up of a lot of functions and developers could pick and choose from",
    "start": "2119440",
    "end": "2124480"
  },
  {
    "text": "that and eventually they started developing their own functions which we then merged into our library and we grew",
    "start": "2124480",
    "end": "2129700"
  },
  {
    "text": "that so adding so for instance tri basis we need this new capability to run a performance test against the site or the",
    "start": "2129700",
    "end": "2136300"
  },
  {
    "text": "front-end we would make that available to all developers via the functional I the pipeline function library and it",
    "start": "2136300",
    "end": "2145150"
  },
  {
    "text": "also gave us the ability to adapt to change and if we needed to change direction we needed to add a new capability that was easy and simple",
    "start": "2145150",
    "end": "2151930"
  },
  {
    "text": "because we had that central library another another nice benefit was the four new developers that were joining",
    "start": "2151930",
    "end": "2158350"
  },
  {
    "text": "the team they were able to onboard very quickly because the functions were easy to use we had a bunch of templates which",
    "start": "2158350",
    "end": "2164530"
  },
  {
    "text": "they could you know users start to templates and as they deployed and as they started using it it became easier",
    "start": "2164530",
    "end": "2170650"
  },
  {
    "text": "because the library functions were documented they were available and they were easy to use and this allowed us to",
    "start": "2170650",
    "end": "2177310"
  },
  {
    "text": "do rata rapid development of our CSEE pipelines because we banded together and",
    "start": "2177310",
    "end": "2182380"
  },
  {
    "text": "we had a central library all the information all the benefits of a central library were apparent and we",
    "start": "2182380",
    "end": "2189850"
  },
  {
    "text": "have over a hundred developers using the pipeline's all across the dynamic jeez Dax some stats so daily there are",
    "start": "2189850",
    "end": "2200360"
  },
  {
    "text": "over 200 pipelines that are active across all environments and each deployment and sorry each of those",
    "start": "2200360",
    "end": "2207260"
  },
  {
    "text": "pipelines are deployed roughly 15 times a day and this is the continuous delivery capabilities on average we",
    "start": "2207260",
    "end": "2215600"
  },
  {
    "text": "started off with only about seven stages within the pipeline it quickly grew to ten stages per pipeline and all these",
    "start": "2215600",
    "end": "2222560"
  },
  {
    "text": "stages is validations in each stage if any of those stages failed the developer had the ability to decide whether or not",
    "start": "2222560",
    "end": "2231110"
  },
  {
    "text": "that was a failure of a whole pipeline and do a complete rollback or carry on",
    "start": "2231110",
    "end": "2236380"
  },
  {
    "text": "productivity gains were also quite good 90% 95% of our pipelines or six",
    "start": "2236380",
    "end": "2241790"
  },
  {
    "text": "successfully deployed this allowed the tribes to be 30% more effective they didn't have to worry",
    "start": "2241790",
    "end": "2247760"
  },
  {
    "text": "about you know deploying writing deployment capabilities to figuring out how to do the CI CD stuff we had already",
    "start": "2247760",
    "end": "2255320"
  },
  {
    "text": "done that for him and the benefit of allowing us to do tests and ordered a security order to automatically was was",
    "start": "2255320",
    "end": "2262100"
  },
  {
    "text": "was something that we really wanted to have security is quite a top most in our mind especially if we if we our products",
    "start": "2262100",
    "end": "2269990"
  },
  {
    "text": "are used by customers we want to give them the safety that they need as well some additional benefits as I mentioned",
    "start": "2269990",
    "end": "2277430"
  },
  {
    "start": "2274000",
    "end": "2407000"
  },
  {
    "text": "slack integration with Jenkins so each tribe is their own snack channel",
    "start": "2277430",
    "end": "2282470"
  },
  {
    "text": "well they have multiple channels but there is one channel dedicated to the Jenkins builds we're all the output of",
    "start": "2282470",
    "end": "2287900"
  },
  {
    "text": "those Jenkins builds go into the slack Channel it allows them to monitor it to see how it goes it doesn't have to log on to Jenkins to",
    "start": "2287900",
    "end": "2294320"
  },
  {
    "text": "check it out they can see in their slack Channel gives them a whole bunch of information which they would normally",
    "start": "2294320",
    "end": "2299330"
  },
  {
    "text": "see and if you ever looked at a Jenkins trace its enormous it's a lot of verbose velocity in there these updates are very",
    "start": "2299330",
    "end": "2305840"
  },
  {
    "text": "topical at each stage it says this is what's deployed this was successful this was the outcome and it also allows us to",
    "start": "2305840",
    "end": "2312980"
  },
  {
    "text": "kick off a doc bills from slack directly so if for instance if we didn't want to do it for a commit and we said you know what we just need another one of these",
    "start": "2312980",
    "end": "2318980"
  },
  {
    "text": "environments quickly we could then kick that off we took slack integration a",
    "start": "2318980",
    "end": "2324500"
  },
  {
    "text": "step further we integrated it directly with AWS because we are using Sam CLI and all the",
    "start": "2324500",
    "end": "2331460"
  },
  {
    "text": "artifacts created or within AWS CloudFormation stacks we wanted the developers to be able to delete those",
    "start": "2331460",
    "end": "2337640"
  },
  {
    "text": "stacks if they needed to say they deployed something didn't quite work and",
    "start": "2337640",
    "end": "2343040"
  },
  {
    "text": "they wanted to delete it they were able to do that you also use AWS Systems",
    "start": "2343040",
    "end": "2348140"
  },
  {
    "text": "Manager quite heavily for parameter store and this allowed us to provide a mechanism via slack for the developers",
    "start": "2348140",
    "end": "2355160"
  },
  {
    "text": "to create and modify parameters directly and also creating Amazon route 53 DNS",
    "start": "2355160",
    "end": "2361430"
  },
  {
    "text": "entries for instance if they want to spin up a new environment and they just they don't want to use the same name and want to use a different name and they",
    "start": "2361430",
    "end": "2366890"
  },
  {
    "text": "wanna do some testing or they want to give it to someone else it's used to integrate with it they were able to do that directly and then we also wrote a",
    "start": "2366890",
    "end": "2374780"
  },
  {
    "text": "bunch of lambda functions to delete these AWS CloudFormation stacks so we wrote the functions that monitored the",
    "start": "2374780",
    "end": "2381440"
  },
  {
    "text": "bid package repositories directly and then when we found that for instance a branch had been merged and it was no",
    "start": "2381440",
    "end": "2387230"
  },
  {
    "text": "longer available we were able to go and delete that stack out of AWS and and that saved us quite a bit of cash as",
    "start": "2387230",
    "end": "2393470"
  },
  {
    "text": "well because they weren't artifacts running in AWS that didn't have a release candidate or a branch associated",
    "start": "2393470",
    "end": "2400760"
  },
  {
    "text": "to it and again these were all part of the benefits that we had thank you very",
    "start": "2400760",
    "end": "2410000"
  },
  {
    "start": "2407000",
    "end": "2493000"
  },
  {
    "text": "much thank you",
    "start": "2410000",
    "end": "2416059"
  },
  {
    "text": "Vanina can you just a little bit deeper in how you compute that they increase in productivity because that was coming out",
    "start": "2416059",
    "end": "2422480"
  },
  {
    "text": "from our conversation so the productivity was what we had was a lot",
    "start": "2422480",
    "end": "2428690"
  },
  {
    "text": "of developers were trying to do their own thing they kept building their own mechanisms we were spinning our wheels",
    "start": "2428690",
    "end": "2434119"
  },
  {
    "text": "trying different mechanisms all the time when we came up with the pipeline solution it was a lot easier for them to",
    "start": "2434119",
    "end": "2439280"
  },
  {
    "text": "come back and say okay this is something that we will use I mean we kind of forced everyone to use the same mechanism because we knew long term that",
    "start": "2439280",
    "end": "2447799"
  },
  {
    "text": "the benefit gain of having a central library would be enormous and it proved itself in the end and to measure you use",
    "start": "2447799",
    "end": "2453109"
  },
  {
    "text": "the yes so we we started pumping metrics directly from Jenkins in the pipeline",
    "start": "2453109",
    "end": "2459240"
  },
  {
    "text": "stages into a time series database to tell how long the stages were and we could tell which part of which stages",
    "start": "2459240",
    "end": "2466440"
  },
  {
    "text": "were were longer and then we would go back to those stages optimize them reanalyze we know where there were and I",
    "start": "2466440",
    "end": "2472500"
  },
  {
    "text": "remember we changed we changed the instance size of our working nodes because the work was getting too much for it and was just overloaded so we",
    "start": "2472500",
    "end": "2480360"
  },
  {
    "text": "changed the worker node up against pot instances really cheap efficient and we figured out you know we could easily",
    "start": "2480360",
    "end": "2486030"
  },
  {
    "text": "just do that thank you thank you again thank you [Applause]",
    "start": "2486030",
    "end": "2494909"
  }
]
[
  {
    "text": "- Hello, everyone. My\nname is Bhanu Pittampally.",
    "start": "0",
    "end": "2640"
  },
  {
    "text": "I'm a Redshift specialist\nsolution architect at AWS.",
    "start": "2640",
    "end": "5827"
  },
  {
    "text": "Today I'm gonna talk about and demonstrate",
    "start": "6780",
    "end": "9690"
  },
  {
    "text": "data warehouse migration\nto Amazon Redshift.",
    "start": "9690",
    "end": "12320"
  },
  {
    "text": "Specifically, how to use\nAWS Schema Conversion Tool",
    "start": "12320",
    "end": "16010"
  },
  {
    "text": "to migrate a data warehouse\nto Amazon Redshift.",
    "start": "16010",
    "end": "18750"
  },
  {
    "text": "The solution architecture\nfor the demo is shown here.",
    "start": "18750",
    "end": "22610"
  },
  {
    "text": "On the left-hand side, we have\non-premise data warehouse,",
    "start": "22610",
    "end": "25960"
  },
  {
    "text": "along with some ETL scripts",
    "start": "25960",
    "end": "27519"
  },
  {
    "text": "download in the proprietary language.",
    "start": "27520",
    "end": "29860"
  },
  {
    "text": "On the right-hand side",
    "start": "29860",
    "end": "30790"
  },
  {
    "text": "we have Amazon Redshift\ncloud data warehouse.",
    "start": "30790",
    "end": "33480"
  },
  {
    "text": "We're going to use AWS SCT to\nconvert the SQL core objects",
    "start": "33480",
    "end": "38370"
  },
  {
    "text": "and database objects.",
    "start": "38370",
    "end": "39899"
  },
  {
    "text": "We're going to use AWS\nSCT data extraction agent",
    "start": "39900",
    "end": "43420"
  },
  {
    "text": "to migrate data to Redshift server,",
    "start": "43420",
    "end": "45800"
  },
  {
    "text": "and finally, we're going to\nuse AWS SCT ETL converter",
    "start": "45800",
    "end": "49920"
  },
  {
    "text": "to migrate BTEQ script to RSQL script.",
    "start": "49920",
    "end": "53059"
  },
  {
    "text": "So let's start the demo now.",
    "start": "53060",
    "end": "54707"
  },
  {
    "text": "Can see, the SCT tool is\nalready open on my machine,",
    "start": "54707",
    "end": "58690"
  },
  {
    "text": "which is a Windows system.",
    "start": "58690",
    "end": "60719"
  },
  {
    "text": "I downloaded, installed,\nand configured the SCT tool",
    "start": "60720",
    "end": "65019"
  },
  {
    "text": "as per the instructions\nfound on the product page.",
    "start": "65020",
    "end": "67740"
  },
  {
    "text": "It's very easy, you can do it yourself.",
    "start": "67740",
    "end": "71280"
  },
  {
    "text": "The first thing I'm gonna do in this tool",
    "start": "71280",
    "end": "73409"
  },
  {
    "text": "is click on \"File,\"",
    "start": "73410",
    "end": "74777"
  },
  {
    "text": "and click on \"New project.\"",
    "start": "75640",
    "end": "77207"
  },
  {
    "text": "And I wanna call my project as",
    "start": "78240",
    "end": "80420"
  },
  {
    "text": "teradata_migration.",
    "start": "82757",
    "end": "84340"
  },
  {
    "text": "As you can see, we have the main view,",
    "start": "89720",
    "end": "92370"
  },
  {
    "text": "where we have sources and targets,",
    "start": "92370",
    "end": "94350"
  },
  {
    "text": "which are empty.",
    "start": "94350",
    "end": "95750"
  },
  {
    "text": "Then I'm gonna add a\nsource, which is Teradata.",
    "start": "95750",
    "end": "98523"
  },
  {
    "text": "I have this information prepopulated,",
    "start": "99730",
    "end": "101580"
  },
  {
    "text": "based on my configuration\nthat I have done,",
    "start": "102663",
    "end": "104910"
  },
  {
    "text": "so now I'm gonna simply enter my password,",
    "start": "104910",
    "end": "107473"
  },
  {
    "text": "and name my connection.",
    "start": "108540",
    "end": "110950"
  },
  {
    "text": "It's onprem_teradata_edw.",
    "start": "110950",
    "end": "112930"
  },
  {
    "text": "I'm gonna click on \"Store\npassword,\" and connect.",
    "start": "117430",
    "end": "120010"
  },
  {
    "text": "I'm gonna accept the risk and continue",
    "start": "120010",
    "end": "122250"
  },
  {
    "text": "of not encrypting the data,",
    "start": "122250",
    "end": "124730"
  },
  {
    "text": "since this is a demo.",
    "start": "124730",
    "end": "125893"
  },
  {
    "text": "Give it some time here,",
    "start": "131320",
    "end": "133050"
  },
  {
    "text": "while it connects to Teradata machine.",
    "start": "133050",
    "end": "135223"
  },
  {
    "text": "I have successful\nconnection to the source.",
    "start": "148110",
    "end": "151240"
  },
  {
    "text": "Now let's add target.",
    "start": "151240",
    "end": "152683"
  },
  {
    "text": "Target is going to be Amazon Redshift.",
    "start": "153770",
    "end": "155670"
  },
  {
    "text": "Click on \"Next,\" again, I got\nthis information prepopulated,",
    "start": "157620",
    "end": "160739"
  },
  {
    "text": "I'm just gonna enter my password,",
    "start": "160740",
    "end": "162990"
  },
  {
    "text": "and call my connection, give it a name,",
    "start": "162990",
    "end": "166953"
  },
  {
    "text": "cloud_redshift_edw.",
    "start": "166953",
    "end": "170403"
  },
  {
    "text": "Store password, I'm\ngonna uncheck Glue here,",
    "start": "171440",
    "end": "173660"
  },
  {
    "text": "'cause we're not using\nthat for this demo purpose,",
    "start": "173660",
    "end": "176380"
  },
  {
    "text": "so click on \"Connect.\"",
    "start": "176380",
    "end": "177797"
  },
  {
    "text": "And now I have my cloud_redshift_edw",
    "start": "179120",
    "end": "181680"
  },
  {
    "text": "populated on the target side.",
    "start": "181680",
    "end": "183129"
  },
  {
    "text": "Next thing we want to do\nis create the mapping.",
    "start": "183130",
    "end": "186240"
  },
  {
    "text": "Mapping establishes the\npath for the objects",
    "start": "186240",
    "end": "189540"
  },
  {
    "text": "to flow from source to target.",
    "start": "189540",
    "end": "191719"
  },
  {
    "text": "So I'm gonna go ahead,",
    "start": "191720",
    "end": "192980"
  },
  {
    "text": "click on the schema that I\nwant to use for this demo,",
    "start": "192980",
    "end": "197230"
  },
  {
    "text": "I want to use the td_migration_demo",
    "start": "197230",
    "end": "198980"
  },
  {
    "text": "to demonstrate the conversion process,",
    "start": "200580",
    "end": "202680"
  },
  {
    "text": "so I'm gonna select on that.",
    "start": "202680",
    "end": "204959"
  },
  {
    "text": "And create mapping, I\nclick on \"Create mapping.\"",
    "start": "204960",
    "end": "208490"
  },
  {
    "text": "Once I do that,",
    "start": "208490",
    "end": "209350"
  },
  {
    "text": "the mapping source to\ntarget path is established.",
    "start": "209350",
    "end": "212473"
  },
  {
    "text": "Then I'm gonna go back to main view.",
    "start": "213380",
    "end": "215283"
  },
  {
    "text": "Once I do that, you can see",
    "start": "216290",
    "end": "218140"
  },
  {
    "text": "the information is again populated.",
    "start": "219180",
    "end": "222349"
  },
  {
    "text": "I'm gonna uncheck all schemas,",
    "start": "222350",
    "end": "224600"
  },
  {
    "text": "since we're gonna use only one schema.",
    "start": "224600",
    "end": "227290"
  },
  {
    "text": "As you can see, we have 10 tables,",
    "start": "227290",
    "end": "229379"
  },
  {
    "text": "four views, and two macros.",
    "start": "229380",
    "end": "231283"
  },
  {
    "text": "Go ahead and expand that,",
    "start": "232120",
    "end": "233840"
  },
  {
    "text": "we have some fact\ntables, dimension tables,",
    "start": "233840",
    "end": "236599"
  },
  {
    "text": "we have some views, and then two macros.",
    "start": "236600",
    "end": "239893"
  },
  {
    "text": "So what we're gonna do next",
    "start": "240760",
    "end": "242560"
  },
  {
    "text": "is we're gonna select the schema,",
    "start": "242560",
    "end": "244800"
  },
  {
    "text": "and click on \"Converge schema.\"",
    "start": "244800",
    "end": "247397"
  },
  {
    "text": "Click \"Yes,\" it's warning\nif objects already exist,",
    "start": "248950",
    "end": "252220"
  },
  {
    "text": "it's gonna replace, which is\nfine, click on \"Continue.\"",
    "start": "252220",
    "end": "255307"
  },
  {
    "text": "Then now it's working on\nthe conversion process.",
    "start": "256600",
    "end": "260200"
  },
  {
    "text": "So, conversion process is\nwhere SCT is going to convert",
    "start": "260200",
    "end": "265200"
  },
  {
    "text": "or rewrite your tables,\nor views, or macros,",
    "start": "266120",
    "end": "270540"
  },
  {
    "text": "to a format compatible\nwith Amazon Redshift.",
    "start": "270540",
    "end": "273803"
  },
  {
    "text": "It is also going to give\nus an assessment report",
    "start": "274690",
    "end": "278310"
  },
  {
    "text": "where you can download and review that",
    "start": "278310",
    "end": "281350"
  },
  {
    "text": "to understand how the\nconversion process went through.",
    "start": "281350",
    "end": "285470"
  },
  {
    "text": "To access the assessment report,",
    "start": "285470",
    "end": "287600"
  },
  {
    "text": "you can go to \"Main view,\"",
    "start": "287600",
    "end": "289380"
  },
  {
    "text": "click on \"Assessment report view.\"",
    "start": "289380",
    "end": "291137"
  },
  {
    "text": "And here you can see,\nwe worked on one schema,",
    "start": "292690",
    "end": "296500"
  },
  {
    "text": "10 tables, and four views,",
    "start": "296500",
    "end": "299270"
  },
  {
    "text": "or four indexes.",
    "start": "299270",
    "end": "301270"
  },
  {
    "text": "And when it comes to\ndatabase code objects,",
    "start": "301270",
    "end": "303470"
  },
  {
    "text": "we worked on four views and two macros.",
    "start": "303470",
    "end": "305903"
  },
  {
    "text": "The light green is for the objects",
    "start": "307845",
    "end": "311080"
  },
  {
    "text": "which are automatically converted,",
    "start": "311080",
    "end": "313772"
  },
  {
    "text": "the darker green for the\nobjects with simple actions,",
    "start": "315060",
    "end": "318460"
  },
  {
    "text": "the light blue for the objects",
    "start": "318460",
    "end": "321210"
  },
  {
    "text": "with medium complexity actions,",
    "start": "321210",
    "end": "323039"
  },
  {
    "text": "and the darker blue with the\nobjects with complex actions.",
    "start": "323040",
    "end": "326193"
  },
  {
    "text": "So today we have 10% of the tables",
    "start": "327070",
    "end": "331460"
  },
  {
    "text": "with the medium complexity actions,",
    "start": "332485",
    "end": "334629"
  },
  {
    "text": "and the rest went through\nwithout any issues.",
    "start": "334630",
    "end": "337283"
  },
  {
    "text": "Let's review what those are,",
    "start": "338160",
    "end": "339560"
  },
  {
    "text": "and then we will convert these\nobjects to Redshift side.",
    "start": "339560",
    "end": "343463"
  },
  {
    "text": "We can see the issues\nthat have been encountered",
    "start": "344530",
    "end": "346810"
  },
  {
    "text": "during the conversion process.",
    "start": "346810",
    "end": "349000"
  },
  {
    "text": "I'll go ahead, click on\nthe first issue here.",
    "start": "349000",
    "end": "352470"
  },
  {
    "text": "It's about loa_duration column.",
    "start": "352470",
    "end": "354623"
  },
  {
    "text": "So once I click on that,",
    "start": "355630",
    "end": "357640"
  },
  {
    "text": "we can see that it's coming\nfrom the loa_durations table.",
    "start": "357640",
    "end": "361220"
  },
  {
    "text": "It's about the interval data type.",
    "start": "361220",
    "end": "363513"
  },
  {
    "text": "Our SCT is clever enough",
    "start": "364622",
    "end": "365880"
  },
  {
    "text": "to convert that into character\nvarying (indistinct),",
    "start": "365880",
    "end": "368647"
  },
  {
    "text": "since Redshift doesn't have it yet.",
    "start": "370060",
    "end": "372639"
  },
  {
    "text": "Another issue that is reported here is",
    "start": "372640",
    "end": "375490"
  },
  {
    "text": "about the view top_five_months,",
    "start": "376348",
    "end": "377800"
  },
  {
    "text": "it's about the qualifier rank,",
    "start": "377800",
    "end": "379259"
  },
  {
    "text": "and we can see that Redshift\nis able to mimic the logic",
    "start": "379260",
    "end": "382840"
  },
  {
    "text": "with a subquery,",
    "start": "382840",
    "end": "384510"
  },
  {
    "text": "and the filtering that is\nhappening with the qualifier rank",
    "start": "384510",
    "end": "387740"
  },
  {
    "text": "less than or equal to five",
    "start": "387740",
    "end": "389020"
  },
  {
    "text": "is now being handled by the (indistinct),",
    "start": "389020",
    "end": "391069"
  },
  {
    "text": "and the view works the same\nway as the Teradata side,",
    "start": "392000",
    "end": "395500"
  },
  {
    "text": "and you get the consistent results.",
    "start": "395500",
    "end": "398020"
  },
  {
    "text": "And we can also see that\nSCT is able to convert",
    "start": "398020",
    "end": "401900"
  },
  {
    "text": "some of the macros to store procedures,",
    "start": "401900",
    "end": "404900"
  },
  {
    "text": "and you can witness that here.",
    "start": "404900",
    "end": "407080"
  },
  {
    "text": "It is also able to apply the case-specific",
    "start": "407080",
    "end": "411889"
  },
  {
    "text": "or case not specific\nlogic in the where filter.",
    "start": "411890",
    "end": "415290"
  },
  {
    "text": "So here in the where clause,",
    "start": "415290",
    "end": "416650"
  },
  {
    "text": "you can see that the string_par\nis complete to ci column",
    "start": "416650",
    "end": "420699"
  },
  {
    "text": "with the not casespecific.",
    "start": "420700",
    "end": "422707"
  },
  {
    "text": "On the Redshift side, the\nsame thing is happening.",
    "start": "423544",
    "end": "426767"
  },
  {
    "text": "Collate function is used",
    "start": "428290",
    "end": "429710"
  },
  {
    "text": "where we're applying\ncase_insensitive type,",
    "start": "429710",
    "end": "433030"
  },
  {
    "text": "so both the columns are matched\nirrespective of the case.",
    "start": "433030",
    "end": "436533"
  },
  {
    "text": "So there are some ways where\nAWS SCT really helps you",
    "start": "437410",
    "end": "442210"
  },
  {
    "text": "automate your conversion process",
    "start": "442210",
    "end": "444302"
  },
  {
    "text": "(indistinct) interventions for you,",
    "start": "444302",
    "end": "446800"
  },
  {
    "text": "and makes your migration\nexperience very easy.",
    "start": "446800",
    "end": "450970"
  },
  {
    "text": "The next step for us is to\napply these converted objects",
    "start": "450970",
    "end": "455320"
  },
  {
    "text": "to Redshift side.",
    "start": "455320",
    "end": "456680"
  },
  {
    "text": "On my target side, on the right-hand side,",
    "start": "456680",
    "end": "458880"
  },
  {
    "text": "this is my schema td_migration_demo.",
    "start": "458880",
    "end": "460680"
  },
  {
    "text": "It's ready with the converted\nscript, the objects.",
    "start": "461540",
    "end": "465370"
  },
  {
    "text": "I'm gonna right-click and\nselect \"Apply to database,\"",
    "start": "465370",
    "end": "468930"
  },
  {
    "text": "and click okay, click \"Yes.\"",
    "start": "468930",
    "end": "470960"
  },
  {
    "text": "Now, it is in the process\nof applying those objects",
    "start": "470960",
    "end": "474639"
  },
  {
    "text": "onto my target system.",
    "start": "474640",
    "end": "476460"
  },
  {
    "text": "While that is happening,",
    "start": "476460",
    "end": "477860"
  },
  {
    "text": "I will show you...",
    "start": "477860",
    "end": "479030"
  },
  {
    "text": "This is my client tool SQL Workbench/J,",
    "start": "480540",
    "end": "482990"
  },
  {
    "text": "I have a connection with my target system.",
    "start": "482990",
    "end": "486410"
  },
  {
    "text": "These are our current schemas\non my Redshift cluster.",
    "start": "486410",
    "end": "491310"
  },
  {
    "text": "I don't see the td_migration yet,",
    "start": "491310",
    "end": "493410"
  },
  {
    "text": "because it's not created yet,",
    "start": "493410",
    "end": "495380"
  },
  {
    "text": "so if I...",
    "start": "495380",
    "end": "496213"
  },
  {
    "text": "Query tried to select\none of the fact table,",
    "start": "497980",
    "end": "501230"
  },
  {
    "text": "says doesn't exist.",
    "start": "501230",
    "end": "502870"
  },
  {
    "text": "So the process is still, there it is,",
    "start": "502870",
    "end": "506260"
  },
  {
    "text": "the process is done now,",
    "start": "506260",
    "end": "508690"
  },
  {
    "text": "and you can check the status by going to,",
    "start": "508690",
    "end": "512520"
  },
  {
    "text": "on the target side, on the main view,",
    "start": "512520",
    "end": "514219"
  },
  {
    "text": "you can check the status,",
    "start": "514220",
    "end": "515680"
  },
  {
    "text": "accessing the applied status.",
    "start": "515680",
    "end": "517690"
  },
  {
    "text": "So as you can see, the schema,\ntables, views, procedures,",
    "start": "517690",
    "end": "522450"
  },
  {
    "text": "all have been successfully\ncreated on the Redshift side.",
    "start": "522450",
    "end": "526070"
  },
  {
    "text": "Now let's go back to my client tool,",
    "start": "526070",
    "end": "529030"
  },
  {
    "text": "and refresh the dev.",
    "start": "529030",
    "end": "530373"
  },
  {
    "text": "The object explorer.",
    "start": "532330",
    "end": "533913"
  },
  {
    "text": "Right-click \"Schemas,\" reload it,",
    "start": "536520",
    "end": "538630"
  },
  {
    "text": "now I see my td_migration_demo schema now,",
    "start": "538630",
    "end": "542050"
  },
  {
    "text": "and I see my tables here, my views.",
    "start": "542050",
    "end": "545180"
  },
  {
    "text": "Now when I try to run this query now,",
    "start": "545180",
    "end": "548149"
  },
  {
    "text": "it should run successfully,",
    "start": "548150",
    "end": "549350"
  },
  {
    "text": "but you don't get any data,",
    "start": "549350",
    "end": "550529"
  },
  {
    "text": "because we haven't loaded any data yet.",
    "start": "550530",
    "end": "553180"
  },
  {
    "text": "Now we move to the next step in the demo,",
    "start": "553180",
    "end": "556520"
  },
  {
    "text": "it's about loading the\ndata into Redshift cluster",
    "start": "556520",
    "end": "560010"
  },
  {
    "text": "from Teradata warehouse.",
    "start": "560010",
    "end": "561423"
  },
  {
    "text": "(indistinct) we're gonna do\nis, while in the mapping view,",
    "start": "563367",
    "end": "566623"
  },
  {
    "text": "so we get to the mapping view here,",
    "start": "567810",
    "end": "569779"
  },
  {
    "text": "so while in the mapping view,\nright-click on the schema.",
    "start": "569780",
    "end": "572580"
  },
  {
    "text": "Actually, on the set of tables here.",
    "start": "573600",
    "end": "575399"
  },
  {
    "text": "Right-click there.",
    "start": "576270",
    "end": "577710"
  },
  {
    "text": "And you want to first,\nstep is register agent.",
    "start": "577710",
    "end": "580850"
  },
  {
    "text": "The registering agent\nis actually registering",
    "start": "580850",
    "end": "583089"
  },
  {
    "text": "the data extraction agent\nthat SCT comes with.",
    "start": "583090",
    "end": "587380"
  },
  {
    "text": "So you want to give it a name,",
    "start": "587380",
    "end": "588620"
  },
  {
    "text": "so I'm gonna call it as a td_agent,",
    "start": "588620",
    "end": "590370"
  },
  {
    "text": "host name, the agent is\ninstalled on the local machine,",
    "start": "591500",
    "end": "594780"
  },
  {
    "text": "so I'm gonna call it localhost.",
    "start": "594780",
    "end": "596750"
  },
  {
    "text": "And the port is 8192.",
    "start": "596750",
    "end": "599440"
  },
  {
    "text": "This information, you\nprovide this information",
    "start": "599440",
    "end": "603360"
  },
  {
    "text": "when you're installing the product, so,",
    "start": "603360",
    "end": "605290"
  },
  {
    "text": "that's why I remembered these,",
    "start": "605290",
    "end": "606899"
  },
  {
    "text": "so I'm using them here.",
    "start": "606900",
    "end": "608780"
  },
  {
    "text": "And I will uncheck SSL.",
    "start": "608780",
    "end": "610620"
  },
  {
    "text": "I'm not using that,",
    "start": "610620",
    "end": "611650"
  },
  {
    "text": "and I will go ahead\nand register the agent.",
    "start": "611650",
    "end": "613893"
  },
  {
    "text": "So accept the risk and continue.",
    "start": "614840",
    "end": "616713"
  },
  {
    "text": "Now, I'm in data migration\nview, the agent is registered,",
    "start": "620010",
    "end": "624294"
  },
  {
    "text": "its status is active.",
    "start": "624294",
    "end": "625850"
  },
  {
    "text": "And once agent is successfully registered,",
    "start": "625850",
    "end": "628920"
  },
  {
    "text": "I right-click on my tables,",
    "start": "628920",
    "end": "630810"
  },
  {
    "text": "and then I will create a local task.",
    "start": "630810",
    "end": "633763"
  },
  {
    "text": "The local task is actually the agent,",
    "start": "635060",
    "end": "637610"
  },
  {
    "text": "now you're creating\nthe data movement task,",
    "start": "637610",
    "end": "639700"
  },
  {
    "text": "so I'm gonna name it as\ntd_migration_demo_schema_load,",
    "start": "639700",
    "end": "644673"
  },
  {
    "text": "and then I wanna select\n\"Extract, upload and copy.\"",
    "start": "648360",
    "end": "652360"
  },
  {
    "text": "So the data extraction agent\ngives you three option,",
    "start": "652360",
    "end": "655230"
  },
  {
    "text": "where you can extract\ndata to local system,",
    "start": "655230",
    "end": "657829"
  },
  {
    "text": "extract and upload data\nto Amazon S3 or data lake,",
    "start": "657830",
    "end": "661420"
  },
  {
    "text": "extract, upload and copy\ndata to Amazon Redshift.",
    "start": "661420",
    "end": "664380"
  },
  {
    "text": "So in this demo,",
    "start": "664380",
    "end": "665230"
  },
  {
    "text": "I'm gonna demonstrate how\nto do all three in one go.",
    "start": "665230",
    "end": "669339"
  },
  {
    "text": "So I wanna select the third option.",
    "start": "669340",
    "end": "671160"
  },
  {
    "text": "I don't have LOBs in this case,",
    "start": "671160",
    "end": "673240"
  },
  {
    "text": "so I'm gonna uncheck that,",
    "start": "673240",
    "end": "674640"
  },
  {
    "text": "and then we're gonna go\nahead and create the task.",
    "start": "674640",
    "end": "677853"
  },
  {
    "text": "So task has been created,",
    "start": "679390",
    "end": "681063"
  },
  {
    "text": "so this is my new task,\nTeradata migration schema load.",
    "start": "682220",
    "end": "685959"
  },
  {
    "text": "I have three phases in this task,",
    "start": "685960",
    "end": "690000"
  },
  {
    "text": "extract, upload, and copy.",
    "start": "690000",
    "end": "692100"
  },
  {
    "text": "So I'm gonna go ahead, select the start,",
    "start": "692100",
    "end": "695352"
  },
  {
    "text": "now as you can see, start has\ninitiated extraction process,",
    "start": "696320",
    "end": "701320"
  },
  {
    "text": "and then the uploading to S3,",
    "start": "701770",
    "end": "703320"
  },
  {
    "text": "and then also running copy commands,",
    "start": "703320",
    "end": "705520"
  },
  {
    "text": "which you know, loads data to Redshift,",
    "start": "705520",
    "end": "709130"
  },
  {
    "text": "also being in action.",
    "start": "709130",
    "end": "711040"
  },
  {
    "text": "So we have completed for many tables,",
    "start": "711040",
    "end": "714329"
  },
  {
    "text": "the fact sales table is also finished.",
    "start": "714330",
    "end": "716560"
  },
  {
    "text": "Now if we click on that,\nit extracted 60,000 rows",
    "start": "716560",
    "end": "721560"
  },
  {
    "text": "from source,",
    "start": "722240",
    "end": "724980"
  },
  {
    "text": "uploaded 60,398 to S3 and\n60,398 to Redshift side.",
    "start": "724980",
    "end": "729980"
  },
  {
    "text": "So if we go back to my client tool,",
    "start": "732100",
    "end": "735852"
  },
  {
    "text": "if I run this query now,",
    "start": "737310",
    "end": "738773"
  },
  {
    "text": "you can see that I have\ndata return for my query.",
    "start": "740033",
    "end": "743970"
  },
  {
    "text": "That's how easy it is to move\ndata from Teradata tables",
    "start": "743970",
    "end": "747529"
  },
  {
    "text": "to Redshift tables.",
    "start": "747530",
    "end": "749400"
  },
  {
    "text": "Now let's move on to the\nnext step in the process,",
    "start": "749400",
    "end": "752550"
  },
  {
    "text": "which is about converting\nETL scripts like BTEQ",
    "start": "752550",
    "end": "755589"
  },
  {
    "text": "to Amazon RSQL.",
    "start": "755590",
    "end": "758964"
  },
  {
    "text": "(indistinct) now our demonstration\nis converting ELT script",
    "start": "758964",
    "end": "761470"
  },
  {
    "text": "to Amazon Redshift RSQL.",
    "start": "761470",
    "end": "763670"
  },
  {
    "text": "In this demo, I'm gonna show\nyou how to convert BTEQ script.",
    "start": "763670",
    "end": "766740"
  },
  {
    "text": "On the left-hand side, on the source side,",
    "start": "766740",
    "end": "769660"
  },
  {
    "text": "at the bottom, there is a\nsection called \"Scripts.\"",
    "start": "769660",
    "end": "772560"
  },
  {
    "text": "Under it you can see that\nthere is a BTEQ option",
    "start": "772560",
    "end": "775690"
  },
  {
    "text": "for BTEQ Shell,",
    "start": "775690",
    "end": "776800"
  },
  {
    "text": "FastLoad, FastExport and MultiLoad.",
    "start": "776800",
    "end": "779550"
  },
  {
    "text": "These are some scripts you can convert",
    "start": "779550",
    "end": "781380"
  },
  {
    "text": "by using AWS SCT.",
    "start": "781380",
    "end": "783500"
  },
  {
    "text": "So let me load up BTEQ script.",
    "start": "783500",
    "end": "786540"
  },
  {
    "text": "So they're in this folder.",
    "start": "786540",
    "end": "788779"
  },
  {
    "text": "The script is gonna look like this.",
    "start": "788780",
    "end": "791800"
  },
  {
    "text": "It has a merge statement,",
    "start": "791800",
    "end": "793140"
  },
  {
    "text": "it has a logic based on the row count,",
    "start": "793140",
    "end": "796250"
  },
  {
    "text": "if the row count exists.",
    "start": "796250",
    "end": "797310"
  },
  {
    "text": "If the rows exist in product stage,",
    "start": "797310",
    "end": "799420"
  },
  {
    "text": "then it's gonna run this merge statement,",
    "start": "799420",
    "end": "801290"
  },
  {
    "text": "otherwise it's gonna exit.",
    "start": "801290",
    "end": "803250"
  },
  {
    "text": "So let's see how AWS SCT\ngonna convert that script.",
    "start": "803250",
    "end": "806347"
  },
  {
    "text": "Let's select the folder.",
    "start": "806347",
    "end": "808690"
  },
  {
    "text": "It's asking if there are any variables,",
    "start": "808690",
    "end": "810220"
  },
  {
    "text": "I don't have any variables,\nso I'm gonna click OK.",
    "start": "810220",
    "end": "812803"
  },
  {
    "text": "Then, you can see, the scripts are loaded.",
    "start": "813670",
    "end": "817709"
  },
  {
    "text": "This is my BTEQ script here.",
    "start": "817710",
    "end": "820193"
  },
  {
    "text": "Now, let's get into main view here.",
    "start": "821200",
    "end": "824523"
  },
  {
    "text": "And then if you go to\nthe script view here,",
    "start": "826320",
    "end": "830290"
  },
  {
    "text": "you can see the BTEQ script loaded.",
    "start": "830290",
    "end": "832839"
  },
  {
    "text": "In order to script, before\nyou convert the script,",
    "start": "832840",
    "end": "835170"
  },
  {
    "text": "we need to set the schema.",
    "start": "835170",
    "end": "836750"
  },
  {
    "text": "So current schema I'm working\non is td_migration_demo,",
    "start": "836750",
    "end": "840410"
  },
  {
    "text": "and then apply.",
    "start": "840410",
    "end": "842139"
  },
  {
    "text": "Then I go to the script here,",
    "start": "842140",
    "end": "843930"
  },
  {
    "text": "and right-click on the left side,",
    "start": "843930",
    "end": "845480"
  },
  {
    "text": "I right-click on the script\nand convert it to RSQL.",
    "start": "845480",
    "end": "848149"
  },
  {
    "text": "Click okay.",
    "start": "850800",
    "end": "852589"
  },
  {
    "text": "So it identified the merge statement,",
    "start": "852590",
    "end": "854580"
  },
  {
    "text": "it highlighted that,",
    "start": "854580",
    "end": "855630"
  },
  {
    "text": "and it converted the merge\nstatement to update or insert.",
    "start": "855630",
    "end": "859130"
  },
  {
    "text": "And other parts are equally converted",
    "start": "859130",
    "end": "861610"
  },
  {
    "text": "to RSQL compatible commands.",
    "start": "861610",
    "end": "864380"
  },
  {
    "text": "So it's doing row count,",
    "start": "864380",
    "end": "866060"
  },
  {
    "text": "and using if logic,",
    "start": "866060",
    "end": "867670"
  },
  {
    "text": "if activities go to\nzero, then go to no data,",
    "start": "867670",
    "end": "870519"
  },
  {
    "text": "otherwise go and run this command.",
    "start": "870520",
    "end": "873810"
  },
  {
    "text": "And it also converted\nlabels, remark, everything,",
    "start": "873810",
    "end": "877600"
  },
  {
    "text": "as compatible with the RSQL.",
    "start": "877600",
    "end": "879602"
  },
  {
    "text": "You can save the SQL.",
    "start": "880470",
    "end": "881642"
  },
  {
    "text": "I'm gonna save it to same folder.",
    "start": "884501",
    "end": "886151"
  },
  {
    "text": "It's gonna ask me to replace, select yes,",
    "start": "887380",
    "end": "889770"
  },
  {
    "text": "and this is how the converted\nscript's gonna look like.",
    "start": "889770",
    "end": "893310"
  },
  {
    "text": "It has update, and equate,\nand same as the BTEQ side.",
    "start": "893310",
    "end": "898310"
  },
  {
    "text": "In today's demo,",
    "start": "898530",
    "end": "900040"
  },
  {
    "text": "we have seen how to\nconnect to Teradata system,",
    "start": "900040",
    "end": "902850"
  },
  {
    "text": "we have seen how to convert\ntables, views, objects,",
    "start": "902850",
    "end": "907850"
  },
  {
    "text": "from Teradata to Redshift.",
    "start": "907900",
    "end": "909480"
  },
  {
    "text": "We have seen how to handle some\nof the proprietary features",
    "start": "909480",
    "end": "912839"
  },
  {
    "text": "from Teradata to Redshift.",
    "start": "912840",
    "end": "914363"
  },
  {
    "text": "We have seen how to load the\ndata from Teradata tables",
    "start": "915300",
    "end": "917670"
  },
  {
    "text": "to Redshift side,",
    "start": "917670",
    "end": "918829"
  },
  {
    "text": "and then finally we\nhave seen how to convert",
    "start": "918830",
    "end": "920830"
  },
  {
    "text": "a BTEQ script to Amazon\nRedshift RSQL script.",
    "start": "920830",
    "end": "925163"
  }
]
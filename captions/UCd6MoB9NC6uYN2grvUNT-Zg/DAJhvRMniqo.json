[
  {
    "text": "are you doing today alright thank you for joining us here at reinvent 2017 and",
    "start": "0",
    "end": "8940"
  },
  {
    "text": "thank you for joining us for this Aurora session I'm the bongeunsa hi I'm general manager",
    "start": "8940",
    "end": "14519"
  },
  {
    "text": "for Amazon Aurora and a few other services I'm also delighted to have here good meet Zynga Thor and Brandon O'Brien",
    "start": "14519",
    "end": "22250"
  },
  {
    "text": "from Expedia and they are going to join me in a short while to share their experience with Laura they have been an",
    "start": "22250",
    "end": "29279"
  },
  {
    "text": "ally customer they have been adding a lot of work Laura I'm sure you like to hear from them so before I start let me",
    "start": "29279",
    "end": "37350"
  },
  {
    "text": "do a quick poll how many of you have hired about Aurora before a fair number",
    "start": "37350",
    "end": "44340"
  },
  {
    "text": "and how many of you have used Aurora okay all right not that many I'm hoping",
    "start": "44340",
    "end": "51239"
  },
  {
    "text": "that after this talk I'll have lot of new customers so quickly what is Amazon",
    "start": "51239",
    "end": "58590"
  },
  {
    "text": "Aurora so this is a fully managed relational database service that's",
    "start": "58590",
    "end": "64530"
  },
  {
    "text": "optimized for the cloud from a user's perspective or Ora is a database that has speed and availability of high-end",
    "start": "64530",
    "end": "71640"
  },
  {
    "text": "commercial databases but maintaining simplicity and cost-effectiveness of open-source databases its drop-in",
    "start": "71640",
    "end": "79470"
  },
  {
    "text": "compatible with my sequel and Postgres sequel so if you me if you have application which is today running on my",
    "start": "79470",
    "end": "86100"
  },
  {
    "text": "sequel and Postgres sequel you can migrate without any change to your application it's a simple P as you go",
    "start": "86100",
    "end": "93299"
  },
  {
    "text": "pricing model and as I mentioned it's delivered as a fully managed service now",
    "start": "93299",
    "end": "98430"
  },
  {
    "text": "from a technical perspective we have reimagined the relational databases for",
    "start": "98430",
    "end": "104040"
  },
  {
    "text": "the cloud and there are many things that we have done differently I picked here three as an example and",
    "start": "104040",
    "end": "110240"
  },
  {
    "text": "the first one is it's a fully scale out and distributed design I'm going to talk",
    "start": "110240",
    "end": "116310"
  },
  {
    "text": "about you know what I mean by that it's also a service-oriented architecture leveraging other AWS services both to",
    "start": "116310",
    "end": "124290"
  },
  {
    "text": "build various different features of Aurora as well as making those services available for people who are building",
    "start": "124290",
    "end": "130590"
  },
  {
    "text": "cloud native applications using Aurora and the third is that we have automated",
    "start": "130590",
    "end": "136640"
  },
  {
    "text": "a lot of administrative tasks this is using the RDS management platform we use",
    "start": "136640",
    "end": "142160"
  },
  {
    "text": "the RDS management platform and have extended that further so that many of the common database management tasks you",
    "start": "142160",
    "end": "149030"
  },
  {
    "text": "don't have to worry about that anymore that's already taken care of so let's talk a little bit about what I mean by",
    "start": "149030",
    "end": "155540"
  },
  {
    "text": "scale-out distributed architecture if you look at a database stack there are",
    "start": "155540",
    "end": "160640"
  },
  {
    "text": "multiple layers so you have a sequel processing layer you have a transaction processing layer you have a caching",
    "start": "160640",
    "end": "165830"
  },
  {
    "text": "layer and the two things that you don't see there because we have changed it in Aurora that there is a logging layer and",
    "start": "165830",
    "end": "171860"
  },
  {
    "text": "there is a storage layer we have combined the logging and storage layer together to create a log structure",
    "start": "171860",
    "end": "178580"
  },
  {
    "text": "distributed storage layer which is a key innovation in Aurora and that's what you see for example in the green shaded area",
    "start": "178580",
    "end": "186380"
  },
  {
    "text": "as well as the number of boxes below which are essentially storage nodes so",
    "start": "186380",
    "end": "192440"
  },
  {
    "text": "what we do is that in the storage layer we take slices of data ten gigabytes slices and then stripe it across",
    "start": "192440",
    "end": "200060"
  },
  {
    "text": "hundreds of storage nodes so that you get the aggregate capacity and the throughput of hundreds of storage node",
    "start": "200060",
    "end": "207170"
  },
  {
    "text": "behind your storage volume it is also replicated six ways across three",
    "start": "207170",
    "end": "212630"
  },
  {
    "text": "availability zones which are essentially three different data centers and with two copies in each data center this is",
    "start": "212630",
    "end": "219680"
  },
  {
    "text": "purpose-built for databases so you are not using any standard storage protocol like ice Kazi or NFS or anything like",
    "start": "219680",
    "end": "226459"
  },
  {
    "text": "that all we do is that we stream redo logs from the head node which is where",
    "start": "226459",
    "end": "231709"
  },
  {
    "text": "the database processing is happening to the storage node where we recreate all the pages and that reduces the network",
    "start": "231709",
    "end": "238489"
  },
  {
    "text": "traffic between the head node and the storage node and this is good both for",
    "start": "238489",
    "end": "243590"
  },
  {
    "text": "performance because we are white striping it this is good for availability because we have six copies",
    "start": "243590",
    "end": "248750"
  },
  {
    "text": "this is also good in order to reduce network traffic which ultimately results",
    "start": "248750",
    "end": "254360"
  },
  {
    "text": "in better performance both throughput and latency and I'm going to talk about some of the advantages in the features",
    "start": "254360",
    "end": "260840"
  },
  {
    "text": "that we are going to talk about now we also leverage the cloud ecosystem here",
    "start": "260840",
    "end": "266150"
  },
  {
    "text": "are sound example for example or aura is tightly integrated with lambda functions so you",
    "start": "266150",
    "end": "271460"
  },
  {
    "text": "can for example trigger lambda functions from Aurora stored procedures or triggers so let's say you want to create",
    "start": "271460",
    "end": "278389"
  },
  {
    "text": "a function where if you have three failed logins in a span of five minutes you want to send an SMS message to the",
    "start": "278389",
    "end": "284599"
  },
  {
    "text": "DBA that you know integration with lambda function make it very simple it's also integrated with s3 for example you",
    "start": "284599",
    "end": "291620"
  },
  {
    "text": "can load you know your CSV files your Excel files from s3 inter Ora you can",
    "start": "291620",
    "end": "298220"
  },
  {
    "text": "store your snapshot or your backups into s3 which you do automatically for you it is integrated with Identity and Access",
    "start": "298220",
    "end": "306020"
  },
  {
    "text": "Management service so you don't have to do it yourself you can use your I M roles to do access control of the Laura",
    "start": "306020",
    "end": "311750"
  },
  {
    "text": "databases we have recently integrated order with cloud watch a lot of order logs for example audit logs slow query",
    "start": "311750",
    "end": "319340"
  },
  {
    "text": "logs and other logs you can stream them into cloud watch and you can monitor it in cloud wats automation of the",
    "start": "319340",
    "end": "328580"
  },
  {
    "text": "administrative tasks is what RDS provides so as a DBA you have to do a",
    "start": "328580",
    "end": "333590"
  },
  {
    "text": "lot of things now things on the right hand side is what a typical DBA will do",
    "start": "333590",
    "end": "338960"
  },
  {
    "text": "when you are managing an on-prem database but if you are using all our RDS you don't have to for example",
    "start": "338960",
    "end": "345530"
  },
  {
    "text": "monitoring and failover backup and point-in-time recoveries security and compliance scaling of your instances or",
    "start": "345530",
    "end": "352820"
  },
  {
    "text": "your storage all these things are taken care of so that the DBS can focus on our application developers can focus on",
    "start": "352820",
    "end": "359630"
  },
  {
    "text": "things that really matter to the business like schema design query construction query optimization etc so",
    "start": "359630",
    "end": "367930"
  },
  {
    "text": "are people using it yes I'm happy to report that Aurora is still the fastest",
    "start": "367930",
    "end": "374090"
  },
  {
    "text": "growing service in the AWS history of the top 100 AWS customer 3/4 of them",
    "start": "374090",
    "end": "380990"
  },
  {
    "text": "user Ora today here are some of the examples these are of course the people who are public references we have tens",
    "start": "380990",
    "end": "387919"
  },
  {
    "text": "of thousands of customers using Aurora today so why are people who are moving",
    "start": "387919",
    "end": "393530"
  },
  {
    "text": "toward or and why are they moving toward Ora so there are two types of customers who are moving toward Ora people who are",
    "start": "393530",
    "end": "399800"
  },
  {
    "text": "using source databases today we had my sequel version opera route for roughly about",
    "start": "399800",
    "end": "405620"
  },
  {
    "text": "two and a half years and we recently announced our Postgres sequel version so people from the open source engines are",
    "start": "405620",
    "end": "411710"
  },
  {
    "text": "moving to rora because of the higher performance in case of my sequel it's up to 5x in case of post-credits up to 3x",
    "start": "411710",
    "end": "417919"
  },
  {
    "text": "you get much better availability and durability and in many cases depending",
    "start": "417919",
    "end": "423650"
  },
  {
    "text": "of course on your workload customers save a lot of money up to 60% I have a couple of examples of that and",
    "start": "423650",
    "end": "428919"
  },
  {
    "text": "especially when people are coming from my sequel and post credits it's actually very easy to migrate because it's fully",
    "start": "428919",
    "end": "435800"
  },
  {
    "text": "compatible with my sequel and Postgres any application that is running on those two databases can migrate without any",
    "start": "435800",
    "end": "442460"
  },
  {
    "text": "application change now we also have lot of customers migrating from commercial",
    "start": "442460",
    "end": "447560"
  },
  {
    "text": "databases and the reasons they are migrating is slightly different so first is it's much cheaper literally",
    "start": "447560",
    "end": "455090"
  },
  {
    "text": "about one tenth of the cost of commercial databases there is no licenses to manage it's very well",
    "start": "455090",
    "end": "461090"
  },
  {
    "text": "integrated with the cloud ecosystems so especially for people who want to build applications in the cloud it's almost a",
    "start": "461090",
    "end": "467360"
  },
  {
    "text": "no-brainer that order provides a much better platform at the relational database than some commercial databases",
    "start": "467360",
    "end": "472940"
  },
  {
    "text": "it has comparable performance and availability and migration while not as",
    "start": "472940",
    "end": "478340"
  },
  {
    "text": "simple as migrating from open source databases we have built a lot of tools schema conversion tool database",
    "start": "478340",
    "end": "485990"
  },
  {
    "text": "migration service and we also have professional services which help customer migrate from commercial",
    "start": "485990",
    "end": "491569"
  },
  {
    "text": "databases to Ora now let me give you a couple of examples of you know interesting use cases these are probably",
    "start": "491569",
    "end": "498560"
  },
  {
    "text": "not typical because most of the typical database applications are people you know moving their operational databases",
    "start": "498560",
    "end": "505159"
  },
  {
    "text": "inter Ora so this in this particular case genealogy company who needed a high",
    "start": "505159",
    "end": "511880"
  },
  {
    "text": "performance data store for their DNA matching application and they started with no sequel database Cassandra and",
    "start": "511880",
    "end": "518479"
  },
  {
    "text": "that grew in size as their business grew 200 nodes and it became not only",
    "start": "518479",
    "end": "525649"
  },
  {
    "text": "difficult to manage but also very expensive so they recently moved to Aurora and they have actually moved to a",
    "start": "525649",
    "end": "531829"
  },
  {
    "text": "ten node cluster ten nodes up x-large which is not that big really and you know they do millions of reads and",
    "start": "531829",
    "end": "539270"
  },
  {
    "text": "millions of lights and millions of lights per second and they have absorbed",
    "start": "539270",
    "end": "545180"
  },
  {
    "text": "less than 10 millisecond latency and their projected cost has gone down significantly because it's actually a",
    "start": "545180",
    "end": "551450"
  },
  {
    "text": "lot easier to manage they're spending a lot of money both in storage as well as managing their Cassandra cluster this is",
    "start": "551450",
    "end": "560030"
  },
  {
    "text": "another interesting example this is on-demand video streaming service which was using a Redis cluster to store lot",
    "start": "560030",
    "end": "566870"
  },
  {
    "text": "of their metadata and what they had to do is that because they needed some persistence in their data they had to do",
    "start": "566870",
    "end": "572960"
  },
  {
    "text": "occasional backup of that metadata and that as the business grew again became",
    "start": "572960",
    "end": "577970"
  },
  {
    "text": "very complicated error-prone and also expensive so they replace their backup",
    "start": "577970",
    "end": "583730"
  },
  {
    "text": "infrastructure essentially with the Aurora cluster behind their Redis cluster and using Aurora as a persistent",
    "start": "583730",
    "end": "589940"
  },
  {
    "text": "data store and you know they also in terms of both management and cost this",
    "start": "589940",
    "end": "595280"
  },
  {
    "text": "was a significant improvement from what they had before let me give one more",
    "start": "595280",
    "end": "600950"
  },
  {
    "text": "example this is also kind of an interesting example this is a financial services company where there are lot of",
    "start": "600950",
    "end": "606680"
  },
  {
    "text": "data which are coming from various different trading platform in front in form of transaction streams sometime in",
    "start": "606680",
    "end": "613010"
  },
  {
    "text": "spreadsheets and they put that data in s3 and what they do is that as data",
    "start": "613010",
    "end": "618740"
  },
  {
    "text": "comes into s3 they have a lambda function which triggers and moves that data into Ora we have a function called",
    "start": "618740",
    "end": "624020"
  },
  {
    "text": "read from s3 and then they do some essentially what I would call ETL processing they do transformation of the",
    "start": "624020",
    "end": "630740"
  },
  {
    "text": "data they do different types of projection and joins etc etc and then they move that data either to EMR or",
    "start": "630740",
    "end": "636920"
  },
  {
    "text": "redshift for further processing right they also do some reporting and analysis on that data some quite interesting use",
    "start": "636920",
    "end": "644060"
  },
  {
    "text": "cases now let me move to the next section which is some of the attributes",
    "start": "644060",
    "end": "650510"
  },
  {
    "text": "which people like about Aurora so Aurora is fast it is 5x faster than my sequel",
    "start": "650510",
    "end": "656830"
  },
  {
    "text": "this is you know some slide that I show a lot of people this is essentially",
    "start": "656830",
    "end": "662360"
  },
  {
    "text": "running sis bench which is a popular my sequel benchmark on",
    "start": "662360",
    "end": "667790"
  },
  {
    "text": "ada Excel node which is 32 V CPUs and 244 gigabyte of memory and as you can",
    "start": "667790",
    "end": "674990"
  },
  {
    "text": "see from the graph on the right side Aurora gives about 120 K writes 20,000",
    "start": "674990",
    "end": "680800"
  },
  {
    "text": "120,000 writes per second on the read side we get about 600,000 reads per",
    "start": "680800",
    "end": "686570"
  },
  {
    "text": "second and that's roughly about 5x of what you see in my sequel five seven or",
    "start": "686570",
    "end": "691850"
  },
  {
    "text": "five six we have we have recently released our are 416 Excel which is",
    "start": "691850",
    "end": "697910"
  },
  {
    "text": "twice the size of our 380 Excel and in some of that performance dip-dyed talks you will see some results from those",
    "start": "697910",
    "end": "704960"
  },
  {
    "text": "experiments that we have done and it's not just about simple read and write or actually scales very well it scales well",
    "start": "704960",
    "end": "712760"
  },
  {
    "text": "with number of user connections in this particular case as you grow the number of connections from 50 mm it scales much",
    "start": "712760",
    "end": "722360"
  },
  {
    "text": "better than my sequel up to 5x faster in with 5,000 connections it also scales",
    "start": "722360",
    "end": "728240"
  },
  {
    "text": "well with the growth in metadata for example number of tables in this",
    "start": "728240",
    "end": "733460"
  },
  {
    "text": "particular case you see the example from growing from 10 tables to 10,000 tables and the performance was better by up to",
    "start": "733460",
    "end": "740960"
  },
  {
    "text": "11 X same similarly with size of the database from 1 gigabyte to almost 1",
    "start": "740960",
    "end": "746540"
  },
  {
    "text": "terabyte both using sis bench at TPC see like benchmark or performance was much better than what you see in stock my",
    "start": "746540",
    "end": "753230"
  },
  {
    "text": "sequel now the question is how do we do that it was essentially a two-track approach",
    "start": "753230",
    "end": "759770"
  },
  {
    "text": "I talked about some of the architectural innovation in Aurora that was a major",
    "start": "759770",
    "end": "764990"
  },
  {
    "text": "part of it and there's also a lot of engineering optimization just going through the code path and optimizing the",
    "start": "764990",
    "end": "771470"
  },
  {
    "text": "code path in a very painstaking way so there are two types of things which gives better performance one is that we",
    "start": "771470",
    "end": "777980"
  },
  {
    "text": "actually do less work we generate lot fewer i/o which minimizes network",
    "start": "777980",
    "end": "783950"
  },
  {
    "text": "traffic we cache prior results we offload database engines so lot of",
    "start": "783950",
    "end": "789230"
  },
  {
    "text": "things actually help in terms of doing less work and then we are also more",
    "start": "789230",
    "end": "794270"
  },
  {
    "text": "efficient this is where the engineering optimizations come into play we process things as synchronously we",
    "start": "794270",
    "end": "800640"
  },
  {
    "text": "use the latency path we use lot of lock-free data structures and we batch",
    "start": "800640",
    "end": "805950"
  },
  {
    "text": "lot of operations together right let me give you couple of examples so here is an example of aurora io",
    "start": "805950",
    "end": "813270"
  },
  {
    "text": "profile now any database generates lot of i/o so I have essentially compared on",
    "start": "813270",
    "end": "819870"
  },
  {
    "text": "the left hand side io profile up my sequel and this is actually close to any",
    "start": "819870",
    "end": "826020"
  },
  {
    "text": "other database and on the right hand side Aurora and without getting into too",
    "start": "826020",
    "end": "831390"
  },
  {
    "text": "much details what you see here is that even after 6 copies up writes that you",
    "start": "831390",
    "end": "837690"
  },
  {
    "text": "need to do because we have 6 different copies we actually generate lot less i/o and that is because we are not using",
    "start": "837690",
    "end": "844920"
  },
  {
    "text": "standard storage protocols we are using reduced streaming the differences in a",
    "start": "844920",
    "end": "850620"
  },
  {
    "text": "standard storage protocol every time you have a dirty page you have to write a 4k byte block in our case we are not doing",
    "start": "850620",
    "end": "857310"
  },
  {
    "text": "that we are essentially sending just the delta which is where if you scribble on",
    "start": "857310",
    "end": "862470"
  },
  {
    "text": "in a row you are generating a few tens of bytes of data right we of course batch that now just getting into some",
    "start": "862470",
    "end": "869970"
  },
  {
    "text": "results here we ran sis bench on both setups and on the my sequel side after",
    "start": "869970",
    "end": "876210"
  },
  {
    "text": "running sis bench for half an hour we completed 780 k transaction and",
    "start": "876210",
    "end": "881490"
  },
  {
    "text": "generated about 7.3 million iOS which is roughly about 7.4 REO per transaction on",
    "start": "881490",
    "end": "888840"
  },
  {
    "text": "the Aurora side in that 30 minutes is been run we had 27 million transactions",
    "start": "888840",
    "end": "895920"
  },
  {
    "text": "and roughly about 0.95 io / transactions so we had 35 X more transactions in half",
    "start": "895920",
    "end": "902820"
  },
  {
    "text": "an hour and each transaction took 7.7 X less IO that's an example of doing less",
    "start": "902820",
    "end": "909930"
  },
  {
    "text": "work which is one of the reason why Aurora has much better throughput let me",
    "start": "909930",
    "end": "915420"
  },
  {
    "text": "give another example from our engineering optimization you know one of the critical component in any database",
    "start": "915420",
    "end": "921810"
  },
  {
    "text": "is the lock Manager and my sequel has a lock manager one of the problems with my",
    "start": "921810",
    "end": "926910"
  },
  {
    "text": "sequel lock manager is that there is a big latch or a mutex in front of the lock manager so when a transaction is",
    "start": "926910",
    "end": "933690"
  },
  {
    "text": "trying to acquire lock in the lock manager it essentially gets serialized to that mutex and at one",
    "start": "933690",
    "end": "939699"
  },
  {
    "text": "point in time there is only one transaction which can go inside the lock manager we completely rewrote the lock",
    "start": "939699",
    "end": "946810"
  },
  {
    "text": "manager and made it a latch free implementation on the lock manager and as you can see we have multiple",
    "start": "946810",
    "end": "953860"
  },
  {
    "text": "transactions which can work on multiple lock chains if they are update or delete",
    "start": "953860",
    "end": "959589"
  },
  {
    "text": "or insert operations but if they're scan operations they actually can be multiple",
    "start": "959589",
    "end": "965440"
  },
  {
    "text": "scan operations on the same lock chain it essentially parallelizes that way the",
    "start": "965440",
    "end": "970660"
  },
  {
    "text": "lock manager works and that's one of the reasons we can handle lot more connections in parallel there is that is",
    "start": "970660",
    "end": "977230"
  },
  {
    "text": "the reason we can hand a lot more throughput so we have been doing a lot",
    "start": "977230",
    "end": "982959"
  },
  {
    "text": "of other things I am of course not going to get into all of this there is there are a couple of other oral",
    "start": "982959",
    "end": "988449"
  },
  {
    "text": "representations where you will see some of these things explained in more detail on the read performance side we worked",
    "start": "988449",
    "end": "995560"
  },
  {
    "text": "on smart selector logical read ahead read views to new things which are",
    "start": "995560",
    "end": "1001290"
  },
  {
    "text": "coming next is hash join and parallel query and you are going to hear about",
    "start": "1001290",
    "end": "1006839"
  },
  {
    "text": "that in the deep dive talk on the right side we have improved new malware scheduler laterally locked manager this",
    "start": "1006839",
    "end": "1014190"
  },
  {
    "text": "has helped tremendously on the metadata side we have improved for example our",
    "start": "1014190",
    "end": "1019829"
  },
  {
    "text": "online DDL or online schema change b-tree concurrency catalog concurrency",
    "start": "1019829",
    "end": "1025319"
  },
  {
    "text": "index build etc let me give a quick example where you know this has been",
    "start": "1025319",
    "end": "1031350"
  },
  {
    "text": "very helpful online DDL or online schema change when you want to change the structure of your database and change",
    "start": "1031350",
    "end": "1038220"
  },
  {
    "text": "the schema now that's a pretty complex operation you are on the fly",
    "start": "1038220",
    "end": "1043438"
  },
  {
    "text": "changing the table structure which is very fundamental to the database so in my sequel the way it happens it actually",
    "start": "1043439",
    "end": "1050400"
  },
  {
    "text": "does a full table copy in the backend right so while things are going on in",
    "start": "1050400",
    "end": "1055950"
  },
  {
    "text": "the background it is creating a new table with the new structure and copying old data over of course it takes a lot",
    "start": "1055950",
    "end": "1062820"
  },
  {
    "text": "of time it's pretty heavy-duty and some time it slows down your DM",
    "start": "1062820",
    "end": "1068400"
  },
  {
    "text": "operation tremendously because it is taking lock on that table we do it in a very different way for us it is a",
    "start": "1068400",
    "end": "1075090"
  },
  {
    "text": "metadata operation so what we do is that we have a table where we keep different",
    "start": "1075090",
    "end": "1080100"
  },
  {
    "text": "versions of the schema so you are not really changing anything with respect to the table structure by copying data",
    "start": "1080100",
    "end": "1087450"
  },
  {
    "text": "there are different schemas which are activated at different times and we",
    "start": "1087450",
    "end": "1092910"
  },
  {
    "text": "actually do a read modify write we actually do a primitive which essentially modify data in flight as we",
    "start": "1092910",
    "end": "1101220"
  },
  {
    "text": "are writing it and figures out which particular schema applies to that and do that transform on-the-fly to do that",
    "start": "1101220",
    "end": "1107400"
  },
  {
    "text": "right and the result of this is actually pretty amazing if you look at the online DDL performance on our three large",
    "start": "1107400",
    "end": "1115530"
  },
  {
    "text": "machine which is a small machine if you look at the size of the database or aura takes about 0.25 seconds right this is",
    "start": "1115530",
    "end": "1122280"
  },
  {
    "text": "because we are not really doing anything on the data side it's independent of the size of the data estimated data",
    "start": "1122280",
    "end": "1127800"
  },
  {
    "text": "operation and then my sequel depending on you know the size of the table it might take one hour to up to 14 hours on",
    "start": "1127800",
    "end": "1135350"
  },
  {
    "text": "r38 x-large which is 8 times larger than or 16 times larger than our three large",
    "start": "1135350",
    "end": "1141390"
  },
  {
    "text": "again our time is kind of almost tough not mentionable and my sequel the",
    "start": "1141390",
    "end": "1147600"
  },
  {
    "text": "performance is better because now the data transfer is little faster because it's a larger machine but it takes",
    "start": "1147600",
    "end": "1154080"
  },
  {
    "text": "considerable amount of time so let me switch over to availability no",
    "start": "1154080",
    "end": "1160950"
  },
  {
    "text": "performance of course matters but performance only matters if your database is up and this is one thing",
    "start": "1160950",
    "end": "1167280"
  },
  {
    "text": "where we spend a lot of time and one of our core innovation architectural side",
    "start": "1167280",
    "end": "1172890"
  },
  {
    "text": "is our storage system it's a six way replicated storage system and you might",
    "start": "1172890",
    "end": "1178860"
  },
  {
    "text": "be wondering why is it's six copies that you came find out two copies or three",
    "start": "1178860",
    "end": "1183930"
  },
  {
    "text": "copies which is more common what we do actually is that it's a quorum based",
    "start": "1183930",
    "end": "1189120"
  },
  {
    "text": "system when we write we write to all six nodes but we wait for four of those",
    "start": "1189120",
    "end": "1194490"
  },
  {
    "text": "nodes to return and when they say that they are stable we consider that right",
    "start": "1194490",
    "end": "1199650"
  },
  {
    "text": "to be stable and on the read side it's a three out of six read quorum now",
    "start": "1199650",
    "end": "1205830"
  },
  {
    "text": "the advantage of doing it that way is that you know remember we have two copies in each availability zone or data",
    "start": "1205830",
    "end": "1212070"
  },
  {
    "text": "center so if you have a complete data center outage you still have full read",
    "start": "1212070",
    "end": "1217620"
  },
  {
    "text": "and write availability and if you have a full data center outage plus one more",
    "start": "1217620",
    "end": "1222780"
  },
  {
    "text": "failure that this failure or a node failure you still have full read availability right and that is actually",
    "start": "1222780",
    "end": "1228660"
  },
  {
    "text": "very very important not from just from the point of view of availability it also helps us in writing out some of for",
    "start": "1228660",
    "end": "1237270"
  },
  {
    "text": "example Network latencies and jitter in the system because we are waiting for the fastest for nodes to return and the",
    "start": "1237270",
    "end": "1244290"
  },
  {
    "text": "quorum based systems gives us much better jitter we have fifteen promotable",
    "start": "1244290",
    "end": "1251580"
  },
  {
    "text": "read replicas meaning that each replica could be a failover target so if the",
    "start": "1251580",
    "end": "1256830"
  },
  {
    "text": "master fails then we pick one of the read replicas and that becomes the new",
    "start": "1256830",
    "end": "1261900"
  },
  {
    "text": "master and that operation is pretty fast I'll show you some data from the field the read replicas also work as work as",
    "start": "1261900",
    "end": "1271640"
  },
  {
    "text": "for handling read traffic and we recently added something called a reader endpoint which essentially load balances",
    "start": "1271640",
    "end": "1279480"
  },
  {
    "text": "across multiple read replicas you have and very recently I think it was last week we added auto scaling feature to the",
    "start": "1279480",
    "end": "1286350"
  },
  {
    "text": "read replicas so if you have traffic on the read replicas side drawing we",
    "start": "1286350",
    "end": "1291360"
  },
  {
    "text": "automatically can add more read replicas and if that load is going down we can reduce the number of replicas so",
    "start": "1291360",
    "end": "1299840"
  },
  {
    "text": "some data from the field this is from our entire population of databases that",
    "start": "1300470",
    "end": "1306750"
  },
  {
    "text": "we have in terms of failover time 30% of the failover happens within 0 to 5",
    "start": "1306750",
    "end": "1312780"
  },
  {
    "text": "seconds another 40% happens in 5 to 10 seconds and 25% happens in 10 to 20",
    "start": "1312780",
    "end": "1320220"
  },
  {
    "text": "seconds only about 5% of the failover is above 30 seconds so it's actually very",
    "start": "1320220",
    "end": "1325290"
  },
  {
    "text": "quick turnaround we do support cross region read replicas manage read",
    "start": "1325290",
    "end": "1333300"
  },
  {
    "text": "replicas we actually support one but you and create more read replicas if you want read replicas in multiple region we",
    "start": "1333300",
    "end": "1342539"
  },
  {
    "text": "do support cross region snapshot copies so if you don't want to have live replication you can copy your snapshot",
    "start": "1342539",
    "end": "1349769"
  },
  {
    "text": "every 30 minutes or every hour depending on the rpoS or recovery point objective",
    "start": "1349769",
    "end": "1355919"
  },
  {
    "text": "that you want to set read replicas are quite popular both for dr as well as",
    "start": "1355919",
    "end": "1361070"
  },
  {
    "text": "storing your data close to where your customers are but you know availability",
    "start": "1361070",
    "end": "1369779"
  },
  {
    "text": "is more than just hardware failures or software defects there are you know you",
    "start": "1369779",
    "end": "1374909"
  },
  {
    "text": "need to patch your database for example right we created zero downtime patching",
    "start": "1374909",
    "end": "1380099"
  },
  {
    "text": "for that sometime you need to do large-scale database reorganization that",
    "start": "1380099",
    "end": "1385580"
  },
  {
    "text": "requires you to take your system down so we created fast cloning for that some",
    "start": "1385580",
    "end": "1390809"
  },
  {
    "text": "time DBS actually make unforced user errors and you know you'd like to have",
    "start": "1390809",
    "end": "1396659"
  },
  {
    "text": "an undelete operation so that you can go back in time right so we created online point in time restore or backtrack",
    "start": "1396659",
    "end": "1405659"
  },
  {
    "text": "operation which is not out yet should be out in another couple of weeks or so so",
    "start": "1405659",
    "end": "1411629"
  },
  {
    "text": "let me give a couple of quick examples here zero downtime patching so when you",
    "start": "1411629",
    "end": "1417470"
  },
  {
    "text": "do patching typically what happens in the database that you shut down your old",
    "start": "1417470",
    "end": "1423539"
  },
  {
    "text": "database process and when you do that all that user sessions which are connected to that process essentially",
    "start": "1423539",
    "end": "1430349"
  },
  {
    "text": "gets terminated then you restart the database with the new patch process and you have to re-establish all that user",
    "start": "1430349",
    "end": "1437129"
  },
  {
    "text": "sessions to that new process right that is disruptive to applications so what",
    "start": "1437129",
    "end": "1443009"
  },
  {
    "text": "you have done instead that we first start the new process with a new path",
    "start": "1443009",
    "end": "1449249"
  },
  {
    "text": "and the child process of the current my sequel D right and then we transfer that",
    "start": "1449249",
    "end": "1455879"
  },
  {
    "text": "user sessions and the socket state and the network state everything to the new my sequel D process and after that we",
    "start": "1455879",
    "end": "1463169"
  },
  {
    "text": "shut down the old one as a result the user actually doesn't see the database",
    "start": "1463169",
    "end": "1468480"
  },
  {
    "text": "sessions going down it seems like a delay or a bump on the way right lot less deceptive it works",
    "start": "1468480",
    "end": "1475100"
  },
  {
    "text": "95% of the cases there are some cases where we don't handle it very well for example when you have been log on or",
    "start": "1475100",
    "end": "1482340"
  },
  {
    "text": "whether you have SSL connections etc but we are working on those database",
    "start": "1482340",
    "end": "1489179"
  },
  {
    "text": "backtrack as I mentioned this is a feature which is coming soon what it does is that you can move your database",
    "start": "1489179",
    "end": "1496590"
  },
  {
    "text": "back in time as it's on a time machine so let's say you by mistake drop a table",
    "start": "1496590",
    "end": "1501919"
  },
  {
    "text": "deleted a row and you want to get it back you can put us put it on a slider",
    "start": "1501919",
    "end": "1507270"
  },
  {
    "text": "go back in time get your database back realize that it's too far back in the past you can move forward so you can do",
    "start": "1507270",
    "end": "1513990"
  },
  {
    "text": "back and forth and make sure that you get to the point which is most optimal for you moving to the next section",
    "start": "1513990",
    "end": "1525080"
  },
  {
    "text": "security and monitoring so you of course spend a lot of time in security and",
    "start": "1525080",
    "end": "1530279"
  },
  {
    "text": "monitoring so we support encryption at rest using your own keys this is",
    "start": "1530279",
    "end": "1537779"
  },
  {
    "text": "integrated with IMS we support encryption in transit this includes",
    "start": "1537779",
    "end": "1544230"
  },
  {
    "text": "cross regional application which is all encrypted using SSL we also use the same",
    "start": "1544230",
    "end": "1551220"
  },
  {
    "text": "technique for cross region snapshot copy we support advanced auditing and logging",
    "start": "1551220",
    "end": "1556919"
  },
  {
    "text": "without any performance impact the emphasis here is really without any performance impact because doing logging",
    "start": "1556919",
    "end": "1563730"
  },
  {
    "text": "is not difficult what is difficult is doing it without any performance impact and we recently released what we call",
    "start": "1563730",
    "end": "1570179"
  },
  {
    "text": "database activity monitoring where you can monitor what's going on in your database using various different tools",
    "start": "1570179",
    "end": "1576600"
  },
  {
    "text": "so Aurora auditing if you look at my sequel auditing what it does is that",
    "start": "1576600",
    "end": "1582960"
  },
  {
    "text": "every operation that is happening a query a DDL a DML catalog query catalog",
    "start": "1582960",
    "end": "1590700"
  },
  {
    "text": "entry a connect operation all of this operation is converted into a string then it goes to a sequencer then we",
    "start": "1590700",
    "end": "1598919"
  },
  {
    "text": "write it to a file and when you do that you a huge performance set which is something we wanted to avoid it's",
    "start": "1598919",
    "end": "1605429"
  },
  {
    "text": "particularly important to us because our performance is much higher meaning that we generate lot more events that you",
    "start": "1605429",
    "end": "1612029"
  },
  {
    "text": "need to log right so if we are impacted by the same thing that happens in my sequel that will be the long pole in our",
    "start": "1612029",
    "end": "1618239"
  },
  {
    "text": "performance path so we do it in a different way again we use load up lock",
    "start": "1618239",
    "end": "1625590"
  },
  {
    "text": "free data structures and all of these operations are parallel are putting in a",
    "start": "1625590",
    "end": "1632129"
  },
  {
    "text": "lock free data structure and then we write to multiple files so that we can speed operations up and the results are",
    "start": "1632129",
    "end": "1639899"
  },
  {
    "text": "quite indicate about what we get we can actually sustain up to 500 K events per",
    "start": "1639899",
    "end": "1645269"
  },
  {
    "text": "second without any impact right so that's actually per and if you look at",
    "start": "1645269",
    "end": "1651389"
  },
  {
    "text": "the performance difference between my sequel and Ora it's pretty clear with audit up we are 6.4 x time better with",
    "start": "1651389",
    "end": "1658259"
  },
  {
    "text": "audit on we are actually 15.9 x times better this is a new feature that we",
    "start": "1658259",
    "end": "1664049"
  },
  {
    "text": "recently added database activity monitoring the audit logs that we generate we stream that audit logs to",
    "start": "1664049",
    "end": "1670169"
  },
  {
    "text": "Amazon Cloud Watch and once it is in cloud watch you can search it for specific events in the log file you can",
    "start": "1670169",
    "end": "1677070"
  },
  {
    "text": "set various different metrics on it you can do different visualization using",
    "start": "1677070",
    "end": "1682590"
  },
  {
    "text": "Cubana or your favorite tool you can set alarms and get notified on specific",
    "start": "1682590",
    "end": "1688470"
  },
  {
    "text": "actions that you want to be notified on and you can then move that data to s3 and once it is in s3 you can do various",
    "start": "1688470",
    "end": "1696330"
  },
  {
    "text": "different kinds of log analytics using amazon athena and can visualize that",
    "start": "1696330",
    "end": "1701940"
  },
  {
    "text": "using amazon quick site this is essentially you know way of doing better",
    "start": "1701940",
    "end": "1707519"
  },
  {
    "text": "service telemetry using athena and quick side at this point we pretty much have",
    "start": "1707519",
    "end": "1714269"
  },
  {
    "text": "all the industry certification Sauk ISO PCI DSS which is very important for the",
    "start": "1714269",
    "end": "1722070"
  },
  {
    "text": "financial industry HIPAA and most recently FedRAMP the new feature which",
    "start": "1722070",
    "end": "1729990"
  },
  {
    "text": "is coming soon this is actually available on or a Postgres sequel it's going to come to",
    "start": "1729990",
    "end": "1735539"
  },
  {
    "text": "my sequel sometime very soon what we call performance insight right so what it does is that we have a feature called",
    "start": "1735539",
    "end": "1742109"
  },
  {
    "text": "enhanced monitoring and enhanced monitoring gets lot of information on",
    "start": "1742109",
    "end": "1747450"
  },
  {
    "text": "system level match metrics and performance inside will give you a lot of information about database queries",
    "start": "1747450",
    "end": "1754739"
  },
  {
    "text": "for example you can figure out what are the top queries which are taking the most of the time you can actually drill",
    "start": "1754739",
    "end": "1760830"
  },
  {
    "text": "down into each one of the queries and see where it is spending time is they do anything on a lock is iterating on",
    "start": "1760830",
    "end": "1766710"
  },
  {
    "text": "storage is it star for CPU etc it's easy",
    "start": "1766710",
    "end": "1773429"
  },
  {
    "text": "to use one of the things that people really like about our aura is the storage management people actually are",
    "start": "1773429",
    "end": "1780899"
  },
  {
    "text": "very worried about storage management so worried that they often over provision it when I look at our complete RDS fleet",
    "start": "1780899",
    "end": "1787919"
  },
  {
    "text": "I have seen people over provisioning storage by 30 to 300 percent you don't really need to do that in our aura you",
    "start": "1787919",
    "end": "1794820"
  },
  {
    "text": "start with a 10 gig storage segment and as you add more data we automatically",
    "start": "1794820",
    "end": "1800190"
  },
  {
    "text": "add more storage up to 64 terabyte we also do continuous backup and",
    "start": "1800190",
    "end": "1806399"
  },
  {
    "text": "point-in-time recovery you can take snapshot as mini snapshot you want does not have any performance impact and we",
    "start": "1806399",
    "end": "1814169"
  },
  {
    "text": "of course on the back end of it do automatic heat management restriping etc so that performance is well-balanced",
    "start": "1814169",
    "end": "1821450"
  },
  {
    "text": "dinner base cloning this is a new feature that just came out so the idea here is that you can clone your database",
    "start": "1821450",
    "end": "1829919"
  },
  {
    "text": "very quickly let's say you have a production database you want to test your test to workload on that you can",
    "start": "1829919",
    "end": "1836729"
  },
  {
    "text": "create a fast clone which takes a couple of minutes run your application or product a test to upload on the clone",
    "start": "1836729",
    "end": "1843029"
  },
  {
    "text": "application and once you are done you can delete it right it's not only fast it's also cheap because it's a",
    "start": "1843029",
    "end": "1849840"
  },
  {
    "text": "copy-on-write clone it's not doing deep copy so you only pay for change data if",
    "start": "1849840",
    "end": "1856109"
  },
  {
    "text": "anything is different between the clone and the parent volume that's the only incremental data that you pay for this",
    "start": "1856109",
    "end": "1863129"
  },
  {
    "text": "is as you can imagine very popular with the test 2 workload people create clones",
    "start": "1863129",
    "end": "1868500"
  },
  {
    "text": "in a different account run tests to upload on that and after that they delete that I mentioned this before we",
    "start": "1868500",
    "end": "1877530"
  },
  {
    "text": "are very interested in leveraging our ecosystem there are two types of ecosystem that we are integrated with",
    "start": "1877530",
    "end": "1883290"
  },
  {
    "text": "one is AWS ecosystem like lambda is 3 I am etc but since we are fully my sequel",
    "start": "1883290",
    "end": "1890130"
  },
  {
    "text": "compatible we also can leverage the full my sequel ecosystem so pretty much every",
    "start": "1890130",
    "end": "1895230"
  },
  {
    "text": "is V which runs on my sequel and now Postgres sequel they run unchanged on Aurora so here are some examples of",
    "start": "1895230",
    "end": "1902310"
  },
  {
    "text": "different ice bees which are supported on Aurora now the advantage of being",
    "start": "1902310",
    "end": "1908160"
  },
  {
    "text": "fully compatible with my sequel or Postgres sequel that you can create hybrid operation this is an example",
    "start": "1908160",
    "end": "1914820"
  },
  {
    "text": "where provider of an online marketplace they are actually moving from on-prem my",
    "start": "1914820",
    "end": "1920070"
  },
  {
    "text": "sequel into aura but they are doing it in multiple steps the first step is that they have created an Aurora replica in",
    "start": "1920070",
    "end": "1926820"
  },
  {
    "text": "AWS and they have set up bin log replication but from there on Prem database into the Aurora database and",
    "start": "1926820",
    "end": "1933650"
  },
  {
    "text": "they are actually starting to do some analytical operations on Aurora the next",
    "start": "1933650",
    "end": "1939480"
  },
  {
    "text": "step of that they want to cut over the rate traffic to Aurora and the final step is cutting over the right traffic",
    "start": "1939480",
    "end": "1945390"
  },
  {
    "text": "Tarara so my sequel compatibility and replication support between the two",
    "start": "1945390",
    "end": "1950520"
  },
  {
    "text": "really helps in doing that next",
    "start": "1950520",
    "end": "1956480"
  },
  {
    "text": "migration it depends on where you are migrating from if you are migrating from",
    "start": "1956480",
    "end": "1961590"
  },
  {
    "text": "my sequel and you are migrating from RDS it's really simple couple of clicks on the console if you are migrating from my",
    "start": "1961590",
    "end": "1968670"
  },
  {
    "text": "sequel percona or Mario DB and you are on ec2 or on Prem you have to take a",
    "start": "1968670",
    "end": "1974670"
  },
  {
    "text": "snapshot put it in s3 and we can ingest that snapshot into Dora if you are",
    "start": "1974670",
    "end": "1979680"
  },
  {
    "text": "migrating from Oracle or sequel server or some other database then the best option is to use database migration",
    "start": "1979680",
    "end": "1987180"
  },
  {
    "text": "service and schema conversion to Postgres is kind of similar yes",
    "start": "1987180",
    "end": "1996920"
  },
  {
    "text": "so hope I made the sell but ultimately boils down to the bottom line and Aurora",
    "start": "1997470",
    "end": "2005690"
  },
  {
    "text": "saves you money it's no surprise that we are cheaper than commercial databases if",
    "start": "2005690",
    "end": "2011480"
  },
  {
    "text": "we are not that will be news but what is surprising the Aurora can actually be",
    "start": "2011480",
    "end": "2016490"
  },
  {
    "text": "cheaper than my sequel or Postgres sequel and the reason for that is that you know the way we operate our",
    "start": "2016490",
    "end": "2022790"
  },
  {
    "text": "infrastructure this is an example of a my sequel cluster a multi a Z RDS",
    "start": "2022790",
    "end": "2029000"
  },
  {
    "text": "cluster where you have a primary and standby which does not take any traffic and then you have to read replicas and",
    "start": "2029000",
    "end": "2036230"
  },
  {
    "text": "each of these instances have storage attached to it and the cost of this configuration is",
    "start": "2036230",
    "end": "2042850"
  },
  {
    "text": "$13 62 cents an hour when you go to Aurora your configuration looks like",
    "start": "2042850",
    "end": "2048080"
  },
  {
    "text": "this first you don't need the idol standby because you're read replica is really a target for your failover right",
    "start": "2048080",
    "end": "2055669"
  },
  {
    "text": "so you get rid of one of the instances you don't really need separate in separate storage volumes because you",
    "start": "2055669",
    "end": "2062750"
  },
  {
    "text": "have a shared storage volume and your entire cluster runs on that shared storage volume also there is not",
    "start": "2062750",
    "end": "2068659"
  },
  {
    "text": "provision no provision I office to pay for you pay for I owe that we use and because of some of the optimizations I",
    "start": "2068660",
    "end": "2076100"
  },
  {
    "text": "talked about in terms of using redo logs rather than standard storage protocol there is overall reduction in amount of",
    "start": "2076100",
    "end": "2083360"
  },
  {
    "text": "i/o so the cost of this in this particular example is $9 29 cents an",
    "start": "2083360",
    "end": "2088820"
  },
  {
    "text": "hour which is about 32 percent cheaper now in many situations depending on your",
    "start": "2088820",
    "end": "2094370"
  },
  {
    "text": "workload because of the higher performance you'll be able to use a smaller instance and if you can go down",
    "start": "2094370",
    "end": "2100490"
  },
  {
    "text": "for example from 8 Excel to four Excel then your cost can be further reduced",
    "start": "2100490",
    "end": "2105560"
  },
  {
    "text": "and in this particular example by 50/50 percent now you don't have to take my",
    "start": "2105560",
    "end": "2111680"
  },
  {
    "text": "word for it there are multiple customers who have publicly talked about cost savings that they have seen from Aurora",
    "start": "2111680",
    "end": "2119360"
  },
  {
    "text": "safe software for example cept 40% in their consolidation effort double down",
    "start": "2119360",
    "end": "2125090"
  },
  {
    "text": "interactive cept 67% these are public statements from them Autodesk who",
    "start": "2125090",
    "end": "2131150"
  },
  {
    "text": "central moved to Aurora they saw their database connection that they can support going up by up to 7x the",
    "start": "2131150",
    "end": "2138680"
  },
  {
    "text": "response time went down by 2x their CPU utilization went down by 10x and they",
    "start": "2138680",
    "end": "2144650"
  },
  {
    "text": "also save money because they are using smaller instances now let me pause here",
    "start": "2144650",
    "end": "2151510"
  },
  {
    "text": "good meat and Blandon if you guys want to take it and share your experience",
    "start": "2151510",
    "end": "2157010"
  },
  {
    "text": "with Aurora hello everyone my name is",
    "start": "2157010",
    "end": "2172250"
  },
  {
    "text": "Greg Mead Couture I work for Expedia primarily with the databases migration",
    "start": "2172250",
    "end": "2178700"
  },
  {
    "text": "to AWS and also adoption of the native databases in it obvious my name is",
    "start": "2178700",
    "end": "2185450"
  },
  {
    "text": "Brendan O'Brien I work on all kinds of high scale high-performance streaming data systems at Expedia okay so today we",
    "start": "2185450",
    "end": "2196490"
  },
  {
    "text": "are going to share with you or experiences with Aurora database even though we have quite a few installations",
    "start": "2196490",
    "end": "2203750"
  },
  {
    "text": "of our database but there's a particular very interesting use case which we want",
    "start": "2203750",
    "end": "2209029"
  },
  {
    "text": "to share with you and hopefully you will be able to relate to your applications and take with you the lessons which we",
    "start": "2209029",
    "end": "2215270"
  },
  {
    "text": "all learned so the use case is to provide some experience to the Expedia",
    "start": "2215270",
    "end": "2220819"
  },
  {
    "text": "travelers on shopping experience with some contextual pricing for example",
    "start": "2220819",
    "end": "2227450"
  },
  {
    "text": "strikethrough price I'm sure you know most of you when you go to a grocery",
    "start": "2227450",
    "end": "2232670"
  },
  {
    "text": "shopping you see the prices which are you know a little strikethrough price and that tells you that you are getting",
    "start": "2232670",
    "end": "2238520"
  },
  {
    "text": "a good deal so the use case is to provide a similar experience to the Expedia shoppers so there's a strike to",
    "start": "2238520",
    "end": "2245990"
  },
  {
    "text": "price you may have noticed that the difference is that the the strike two is",
    "start": "2245990",
    "end": "2252109"
  },
  {
    "text": "calculated on a constantly changing prices underneath so we have to ingest",
    "start": "2252109",
    "end": "2258440"
  },
  {
    "text": "the data and process the data and feed it back to our life system",
    "start": "2258440",
    "end": "2264740"
  },
  {
    "text": "that's quite challenge at the same time we have to build a system that will",
    "start": "2264740",
    "end": "2270079"
  },
  {
    "text": "compute all this lodging prices in real time and also built a exposing all this",
    "start": "2270079",
    "end": "2277970"
  },
  {
    "text": "data build a serving layer to provide it back to the customers so I will hand it",
    "start": "2277970",
    "end": "2284780"
  },
  {
    "text": "over to Brandon to explain you how the architecture is designed all right so as",
    "start": "2284780",
    "end": "2291349"
  },
  {
    "text": "you heard we were trying to provide real-time aggregates they were computer",
    "start": "2291349",
    "end": "2296720"
  },
  {
    "text": "from individual priced components and those are constantly changing so we needed a real-time streaming system that",
    "start": "2296720",
    "end": "2302510"
  },
  {
    "text": "could handle modifying all those prices as they came in so let me show you what we built conceptually the data flow is",
    "start": "2302510",
    "end": "2309829"
  },
  {
    "text": "very simple we have a large volume data stream in Kafka with all the lodging prices we use apache storm for streaming",
    "start": "2309829",
    "end": "2317150"
  },
  {
    "text": "distributed processing it's pulling the data from Kafka and it's saving it into the data store that we started with",
    "start": "2317150",
    "end": "2323150"
  },
  {
    "text": "which was Cassandra and we chose Cassandra to begin with because we knew we needed something with high",
    "start": "2323150",
    "end": "2328910"
  },
  {
    "text": "performance high scale and that would work for what we thought we needed and",
    "start": "2328910",
    "end": "2334339"
  },
  {
    "text": "then on the serving side we used nodejs to pull the data from from Cassandra and",
    "start": "2334339",
    "end": "2341240"
  },
  {
    "text": "serve it to the clients now we wired this all up we turned it live and and it",
    "start": "2341240",
    "end": "2347930"
  },
  {
    "text": "worked and it gave us the performance and the scale that we were looking for and we thought we were done but then we",
    "start": "2347930",
    "end": "2354740"
  },
  {
    "text": "ran into all these other problems and we realized the operational overhead that we were running into was a little bit",
    "start": "2354740",
    "end": "2361160"
  },
  {
    "text": "higher than what we were expecting we had one guy he was spending about half of his time just keeping the whole thing",
    "start": "2361160",
    "end": "2367609"
  },
  {
    "text": "running and the biggest piece of how was Cassandra we realized we couldn't do ad hoc queries we need to actually write a",
    "start": "2367609",
    "end": "2373790"
  },
  {
    "text": "spark MapReduce program and deploy that to actually just query run and then in",
    "start": "2373790",
    "end": "2380480"
  },
  {
    "text": "terms of flexibility so if we wanted to make any schema changes that was a little bit more painful than we thought",
    "start": "2380480",
    "end": "2385849"
  },
  {
    "text": "and so and because this is the way the universe works we only realized how painful this was",
    "start": "2385849",
    "end": "2392240"
  },
  {
    "text": "becoming after our clients had taken a production dependency on us and so now we had to just to support it so we",
    "start": "2392240",
    "end": "2398089"
  },
  {
    "text": "immediately started looking for another solution that would give us that performance and scale with",
    "start": "2398089",
    "end": "2403369"
  },
  {
    "text": "lower operational cost and we had heard about Aurora and we tried it out so we",
    "start": "2403369",
    "end": "2409069"
  },
  {
    "text": "write it up we started testing traffic we looked at the performance we looked at what it took to run it in production",
    "start": "2409069",
    "end": "2415099"
  },
  {
    "text": "and immediately we saw that this was going to work much much better for our use case now ad hoc queries were much",
    "start": "2415099",
    "end": "2422569"
  },
  {
    "text": "simpler changes to the schema as Dermott will explain later were much easier and we this this has been working for us so",
    "start": "2422569",
    "end": "2430759"
  },
  {
    "text": "what we're doing with Aurora today we're storing a billion rows we have 4,000 writes per second and we have 25,000",
    "start": "2430759",
    "end": "2437089"
  },
  {
    "text": "reads per second and across those 25,000 reads in aggregate it's returning about",
    "start": "2437089",
    "end": "2442789"
  },
  {
    "text": "500,000 rows per second the infrastructure that we're doing this with is on the Aurora side it's we have",
    "start": "2442789",
    "end": "2449869"
  },
  {
    "text": "six read replicas so the 500,000 rows are distributed across the six read",
    "start": "2449869",
    "end": "2455269"
  },
  {
    "text": "replicas on the storm side for doing the processing to get the data into Aurora we have 12 nodes so more detail on what",
    "start": "2455269",
    "end": "2464029"
  },
  {
    "text": "the infrastructure and what the architecture looks like so we have we have the system deployed in two separate",
    "start": "2464029",
    "end": "2469880"
  },
  {
    "text": "regions and let's start over on the the right US east in the upper left-hand",
    "start": "2469880",
    "end": "2475069"
  },
  {
    "text": "corner there we have lodging system and that's publishing data into Kafka we have storm taking that data up from",
    "start": "2475069",
    "end": "2480769"
  },
  {
    "text": "Kafka and we keep Redis to the side and we're just looking for duplicate keys so that when we're writing that data into",
    "start": "2480769",
    "end": "2487219"
  },
  {
    "text": "Aurora we can avoid writing some duplicate keys and that lets us reduce total write load on the system and an",
    "start": "2487219",
    "end": "2494719"
  },
  {
    "text": "interesting thing here we actually have two separate independent Aurora instances and storm is writing to both",
    "start": "2494719",
    "end": "2501799"
  },
  {
    "text": "the local the local Aurora instance and a remote one and one note to do that",
    "start": "2501799",
    "end": "2508759"
  },
  {
    "text": "cross region write that actually took ten times the number of threads and Kermit will explain why we needed to",
    "start": "2508759",
    "end": "2516019"
  },
  {
    "text": "separate Aurora instances on the read side we have no js' and one interesting",
    "start": "2516019",
    "end": "2526909"
  },
  {
    "text": "thing in this case is agreement will also explain why this is necessary the",
    "start": "2526909",
    "end": "2532189"
  },
  {
    "text": "clients a very large request say say for example it's all hotels in Paris thousands of hotels nodejs chunks that",
    "start": "2532189",
    "end": "2539900"
  },
  {
    "text": "into much smaller requests and then does round-robin distribution of those queries across all",
    "start": "2539900",
    "end": "2546500"
  },
  {
    "text": "the reed replicas and for our use case that was actually key for achieving uniform resource utilization across the",
    "start": "2546500",
    "end": "2553640"
  },
  {
    "text": "lead replicas and again we have a standard Redis cash just for recently",
    "start": "2553640",
    "end": "2558770"
  },
  {
    "text": "recently an access data and so now I'll hand it over back to agreement to explain in more",
    "start": "2558770",
    "end": "2564020"
  },
  {
    "text": "detail what we did with Aurora to make this all work okay",
    "start": "2564020",
    "end": "2570200"
  },
  {
    "text": "Thank You Brendan so let me show you what were the requirements which we had",
    "start": "2570200",
    "end": "2576890"
  },
  {
    "text": "to fulfill and what kind of solutions we adopted along the way so this is a",
    "start": "2576890",
    "end": "2582110"
  },
  {
    "text": "journey and journey has a lot of you know bumps on the road and a lot of governments to start with so one of the",
    "start": "2582110",
    "end": "2588980"
  },
  {
    "text": "key requirements we had is we need to serve 99% of a traffic with the less",
    "start": "2588980",
    "end": "2594500"
  },
  {
    "text": "than hundred millisecond that that was a very tough requirement especially with",
    "start": "2594500",
    "end": "2600680"
  },
  {
    "text": "the high volume and the underlying data changes on the way so the way we did it is the nodejs is splitting the incoming",
    "start": "2600680",
    "end": "2608840"
  },
  {
    "text": "traffic and the incoming request from our clients and then into smaller",
    "start": "2608840",
    "end": "2614780"
  },
  {
    "text": "batches and then each batch is sent over to individual read replicas so each read",
    "start": "2614780",
    "end": "2622040"
  },
  {
    "text": "replica is processing it sending it back to the application and then the application is doing the further",
    "start": "2622040",
    "end": "2627890"
  },
  {
    "text": "processing so that way we were able to spread the load across different Draper up the coast the the second key",
    "start": "2627890",
    "end": "2636140"
  },
  {
    "text": "requirement is how do we utilize all these resources in a balanced way",
    "start": "2636140",
    "end": "2641920"
  },
  {
    "text": "initially we try Aurora's inbuilt load balance but that somehow didn't work",
    "start": "2641920",
    "end": "2649610"
  },
  {
    "text": "because it was balancing on the connections so across the reed replicas",
    "start": "2649610",
    "end": "2655220"
  },
  {
    "text": "a few of our replicas were getting all the load and the remaining one were kind",
    "start": "2655220",
    "end": "2660980"
  },
  {
    "text": "of getting underutilized so then we also have to you take some kind of a custom solution",
    "start": "2660980",
    "end": "2667510"
  },
  {
    "text": "and we what we did is we take the application connection pool on to the",
    "start": "2667510",
    "end": "2673240"
  },
  {
    "text": "load balance and we spread it across the different feed replicas and that was based on the queries which we are",
    "start": "2673240",
    "end": "2678910"
  },
  {
    "text": "sending again the high volume data ingestion about four thousand writes per",
    "start": "2678910",
    "end": "2685360"
  },
  {
    "text": "second again rather than taking every single individual insert state coming in",
    "start": "2685360",
    "end": "2691000"
  },
  {
    "text": "so we batch it hold it and then we send it as a small batches like a micro batch",
    "start": "2691000",
    "end": "2697710"
  },
  {
    "text": "that the storm is taking care of that I want to talk a little bit more about the",
    "start": "2697710",
    "end": "2703630"
  },
  {
    "text": "multi region presence and we saw as Brandon mentioned it we are sending to",
    "start": "2703630",
    "end": "2711070"
  },
  {
    "text": "two different regions from the application okay Aurora has inbuilt",
    "start": "2711070",
    "end": "2717130"
  },
  {
    "text": "feature of cross regional application but there was one limitation we can have",
    "start": "2717130",
    "end": "2724030"
  },
  {
    "text": "only one managed cross region replica that wasn't working for us so then by",
    "start": "2724030",
    "end": "2731770"
  },
  {
    "text": "sending the traffic from the application to to multiple regions what I did we are",
    "start": "2731770",
    "end": "2737950"
  },
  {
    "text": "heading only with one time cross region cost and on the other region now we are",
    "start": "2737950",
    "end": "2744070"
  },
  {
    "text": "able to create again a set of different real replicas because now we got two",
    "start": "2744070",
    "end": "2749980"
  },
  {
    "text": "masters so it served the purpose of having local traffic served by a local",
    "start": "2749980",
    "end": "2755980"
  },
  {
    "text": "region as long as if one reason goes down it serves us the deer as well okay",
    "start": "2755980",
    "end": "2763440"
  },
  {
    "text": "the bündchen mentioned about the online DDL and i just can tell you like how",
    "start": "2763440",
    "end": "2772000"
  },
  {
    "text": "beneficial this feature is and those of you working on the database migration or",
    "start": "2772000",
    "end": "2777130"
  },
  {
    "text": "database changes you know the pain when you have to make a schema change right",
    "start": "2777130",
    "end": "2783300"
  },
  {
    "text": "so the usual way is you create a new table with the new schema you transfer",
    "start": "2783300",
    "end": "2790869"
  },
  {
    "text": "the data to that and that requires a lot of lot of processing or maybe",
    "start": "2790869",
    "end": "2796600"
  },
  {
    "text": "customization creating smaller batches managing the process quite a painful",
    "start": "2796600",
    "end": "2802420"
  },
  {
    "text": "process so we tried fast DDL that that's what",
    "start": "2802420",
    "end": "2808360"
  },
  {
    "text": "the feature is called and within an instant the new schema change is in",
    "start": "2808360",
    "end": "2813910"
  },
  {
    "text": "place and obviously this is for the inaudible columns if you're adding at",
    "start": "2813910",
    "end": "2819400"
  },
  {
    "text": "end of the table it worked beautiful thank you for that dungeon now in some cases the fast DDR",
    "start": "2819400",
    "end": "2828850"
  },
  {
    "text": "may not be applicable in that case you either go with the traditional approach and have your own custom scripts",
    "start": "2828850",
    "end": "2836740"
  },
  {
    "text": "Whitnall but we did we tried the DMS feature the data migration generally you",
    "start": "2836740",
    "end": "2843970"
  },
  {
    "text": "use that to transfer data from one database to other one in this case we",
    "start": "2843970",
    "end": "2849160"
  },
  {
    "text": "would copy from one table to a different table and that way we didn't have to",
    "start": "2849160",
    "end": "2855580"
  },
  {
    "text": "write our own custom small batch process kind of thing so DMS has its own",
    "start": "2855580",
    "end": "2860860"
  },
  {
    "text": "internal batching and it keeps bringing in the new data it maintains that if the",
    "start": "2860860",
    "end": "2866500"
  },
  {
    "text": "process breaks it just picks up from there it was quite useful and once the",
    "start": "2866500",
    "end": "2871870"
  },
  {
    "text": "DMS is finished we swap the tables and now we have a new schema again it really",
    "start": "2871870",
    "end": "2878500"
  },
  {
    "text": "really worked really well pretty pleased with that now this is a slide which I",
    "start": "2878500",
    "end": "2885100"
  },
  {
    "text": "really want to share a few extra thoughts on that along the journey we",
    "start": "2885100",
    "end": "2892000"
  },
  {
    "text": "had some performance snags when the system is up and running the new clients are on-boarded the volume is increasing",
    "start": "2892000",
    "end": "2900900"
  },
  {
    "text": "from 30 milliseconds of select latency we saw that it starts creeping up and",
    "start": "2900900",
    "end": "2906760"
  },
  {
    "text": "within a couple of weeks it went beyond a millisecond okay no problem so we add",
    "start": "2906760",
    "end": "2913360"
  },
  {
    "text": "a few additional reed replicas and we were back in business it dropped to 50 milliseconds still not",
    "start": "2913360",
    "end": "2920770"
  },
  {
    "text": "quite happy with that so we had some discussions with the Aurora team and",
    "start": "2920770",
    "end": "2926990"
  },
  {
    "text": "initially we had a system in place having a smaller batch processing",
    "start": "2926990",
    "end": "2932059"
  },
  {
    "text": "solution and again we dropped from 50",
    "start": "2932059",
    "end": "2937279"
  },
  {
    "text": "select statement per batch to 20 slacks or even to 10 slacks and the performance",
    "start": "2937279",
    "end": "2944270"
  },
  {
    "text": "was back in line there was one down size which we are concerned off because now when we're",
    "start": "2944270",
    "end": "2949490"
  },
  {
    "text": "decreasing the bed size is increasing our transactions per second not because",
    "start": "2949490",
    "end": "2954500"
  },
  {
    "text": "we're sending more transactions but because the database was doing less work",
    "start": "2954500",
    "end": "2960650"
  },
  {
    "text": "it was quickly getting the request sending the data back so the benefit of",
    "start": "2960650",
    "end": "2966020"
  },
  {
    "text": "having a smaller batch far outweigh the decrease with the multiple or a higher",
    "start": "2966020",
    "end": "2973970"
  },
  {
    "text": "number of transactions per second so it was a combination of scaling out with",
    "start": "2973970",
    "end": "2980450"
  },
  {
    "text": "the read replicas and also the paralyzation with the smaller batches so",
    "start": "2980450",
    "end": "2987770"
  },
  {
    "text": "here's some performance numbers replicas lag is very low or CPU utilization is",
    "start": "2987770",
    "end": "2994609"
  },
  {
    "text": "low insert latency Froebel memory these are the some of the main ones very",
    "start": "2994609",
    "end": "3000670"
  },
  {
    "text": "healthy quite happy with that so what",
    "start": "3000670",
    "end": "3007990"
  },
  {
    "text": "does this buy us what are the different benefits - one is the monetary one",
    "start": "3007990",
    "end": "3015869"
  },
  {
    "text": "switching from the earlier solution from Cassandra we had about ten fifteen",
    "start": "3015869",
    "end": "3021369"
  },
  {
    "text": "percent in the dollar savings but the the real saving comes from the multiple",
    "start": "3021369",
    "end": "3027460"
  },
  {
    "text": "uses from the same data set now we were able to slice and dice do different",
    "start": "3027460",
    "end": "3033430"
  },
  {
    "text": "querying ad hoc wiring much much easily as compared to Cassandra and that's",
    "start": "3033430",
    "end": "3039819"
  },
  {
    "text": "where the real savings were also as far as the maintenance is concerned",
    "start": "3039819",
    "end": "3045869"
  },
  {
    "text": "initially we spend a little bit extra time when the system was kind of getting stabilized and later on we literally",
    "start": "3045869",
    "end": "3054910"
  },
  {
    "text": "spend no time except for some patches to be applied or maybe some",
    "start": "3054910",
    "end": "3060110"
  },
  {
    "text": "updates to be done and on average I don't think we have spent more than 10",
    "start": "3060110",
    "end": "3065600"
  },
  {
    "text": "minutes from end to end so overall this system is working pretty",
    "start": "3065600",
    "end": "3071270"
  },
  {
    "text": "well for us now I'll hand it over to Brandon like what are different some key",
    "start": "3071270",
    "end": "3078290"
  },
  {
    "text": "takeaways all right so just to summarize so for high scale streaming data system",
    "start": "3078290",
    "end": "3084440"
  },
  {
    "text": "in this case parallelization at every level of the system was key so kafka for scalable Message Queuing",
    "start": "3084440",
    "end": "3091280"
  },
  {
    "text": "storm for distributed message processing and then aurora to be able to scale out",
    "start": "3091280",
    "end": "3097580"
  },
  {
    "text": "with the reed replicas and really the the key takeaway here is that Aurora let us easily create new managed Reed",
    "start": "3097580",
    "end": "3105440"
  },
  {
    "text": "replicas in a way that was low maintenance and offered the level of scalability that we were looking for and",
    "start": "3105440",
    "end": "3110570"
  },
  {
    "text": "then as as a corollary to that in the application level we realized we needed to do a couple things to really take",
    "start": "3110570",
    "end": "3117830"
  },
  {
    "text": "advantage of that parallelization at the data storage layer which is namely to create database connection pool to each",
    "start": "3117830",
    "end": "3125900"
  },
  {
    "text": "one of the rear Ebla cos from the application and then chunk down the work to the right level that gave us the",
    "start": "3125900",
    "end": "3131360"
  },
  {
    "text": "performance and resource utilization that we were looking for in our case we",
    "start": "3131360",
    "end": "3136850"
  },
  {
    "text": "needed to manually do the cross region data transfer and again that was so that we can have multiple read replicas in",
    "start": "3136850",
    "end": "3143660"
  },
  {
    "text": "each region and only take the cross region data hit once in terms of",
    "start": "3143660",
    "end": "3149450"
  },
  {
    "text": "flexibility for changing a schema so that we can iterate on what the the data looks like and what kind of use cases we",
    "start": "3149450",
    "end": "3156350"
  },
  {
    "text": "can support those two features DMS and fast DDO really let us execute those",
    "start": "3156350",
    "end": "3162020"
  },
  {
    "text": "changes much more easily and bottom line across all of this Aurora gave us the",
    "start": "3162020",
    "end": "3169280"
  },
  {
    "text": "performance and the scalability that we were looking for it's much much lower operational overhead and with more",
    "start": "3169280",
    "end": "3177140"
  },
  {
    "text": "flexibility and that really let us spend more time developing product features and improving ultimately the product and",
    "start": "3177140",
    "end": "3184850"
  },
  {
    "text": "the customer experience so that's our story thank you so much for",
    "start": "3184850",
    "end": "3201269"
  },
  {
    "text": "listening to us very patiently there there's there are some few additional",
    "start": "3201269",
    "end": "3206839"
  },
  {
    "text": "sessions on Aurora okay which you can",
    "start": "3206839",
    "end": "3214319"
  },
  {
    "text": "attend take me about five minutes for Q&A yes we have a few minutes for Q&A",
    "start": "3214319",
    "end": "3220469"
  },
  {
    "text": "but will also be outside hanging around Dave is going to be there so you can take some questions I think people are",
    "start": "3220469",
    "end": "3226619"
  },
  {
    "text": "already starting early all right right thank you thank you",
    "start": "3226619",
    "end": "3235640"
  }
]
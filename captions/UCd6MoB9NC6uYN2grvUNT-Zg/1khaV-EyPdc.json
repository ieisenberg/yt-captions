[
  {
    "start": "0",
    "end": "37000"
  },
  {
    "text": "thanks for coming everybody all right thanks guys we appreciate you guys",
    "start": "0",
    "end": "6899"
  },
  {
    "text": "coming especially we know that we're competing with the lunch hour so it's is an honor that you've you made it here today thank you so my name is Nina vison",
    "start": "6899",
    "end": "14549"
  },
  {
    "text": "the product manager for Amazon comprehend and then today will actually be joined by Ben Snively a solution",
    "start": "14549",
    "end": "22140"
  },
  {
    "text": "architect for AWS as well as yasser who runs science for amazon comprehend and",
    "start": "22140",
    "end": "28740"
  },
  {
    "text": "we have a special guest a customer joining us today on stage to talk to you about how they're using the service",
    "start": "28740",
    "end": "34140"
  },
  {
    "text": "today so let's get started here so you know I we like to sort of think about",
    "start": "34140",
    "end": "40140"
  },
  {
    "text": "positioning comprehend we'll talk about what the service is but this talk really you should leave this talk with an",
    "start": "40140",
    "end": "45780"
  },
  {
    "text": "understanding of how to process all of your data right so what I mean by that",
    "start": "45780",
    "end": "50850"
  },
  {
    "text": "is we have been traditionally very comfortable processing structured data sort of data warehouses relational",
    "start": "50850",
    "end": "57960"
  },
  {
    "text": "database applications no sequel type databases but a lot of this text date has been pretty difficult to get to and",
    "start": "57960",
    "end": "64680"
  },
  {
    "text": "what I mean by that is it required a pretty jump pretty significant leap and skill set to be able to make sense of",
    "start": "64680",
    "end": "70590"
  },
  {
    "text": "this data right traditionally behind a skill set to get to text data you would",
    "start": "70590",
    "end": "76680"
  },
  {
    "start": "71000",
    "end": "137000"
  },
  {
    "text": "have had to do things like you know effectively learn machine learning you'd have had to specialize in NLP there's a",
    "start": "76680",
    "end": "82740"
  },
  {
    "text": "variety of frameworks out there today and while they're all making significant progress it's still not as simple as",
    "start": "82740",
    "end": "88140"
  },
  {
    "text": "working with the relational database and then once you understand the concepts you have to continuously learn and",
    "start": "88140",
    "end": "93810"
  },
  {
    "text": "retrain models and this in itself is a task it's a feat and that's something in comprehend that we're removing for you",
    "start": "93810",
    "end": "100259"
  },
  {
    "text": "and then finally after all of this you can start to use this text data this unstructured data that we like to talk",
    "start": "100259",
    "end": "105720"
  },
  {
    "text": "about it so the way that you know we'd like for you to think about this talk think about using this service Ben's",
    "start": "105720",
    "end": "111990"
  },
  {
    "text": "gonna come up and he's going to show you really nice code level demos that you can then take and go apply we'll make sure all that codes available",
    "start": "111990",
    "end": "117930"
  },
  {
    "text": "to you but think about Amazon comprehend is almost being like a machine learning",
    "start": "117930",
    "end": "123030"
  },
  {
    "text": "based data connector to unstructured data it's sort of how you think about it but we're really gonna focus on we're",
    "start": "123030",
    "end": "128819"
  },
  {
    "text": "not gonna dive deep on the machine learning part we're gonna dive deep on the use cases and how you use the technology so the service itself we like",
    "start": "128819",
    "end": "139290"
  },
  {
    "start": "137000",
    "end": "200000"
  },
  {
    "text": "to say it's fully managed and continuously trained so what this isn't is a library that we just sort of host",
    "start": "139290",
    "end": "145530"
  },
  {
    "text": "for you what it is is a service that is backed by a full time engineering and",
    "start": "145530",
    "end": "150989"
  },
  {
    "text": "full-time science team that thinks deeply about text analytics non-stop so",
    "start": "150989",
    "end": "156450"
  },
  {
    "text": "we think about what are the common what is the state-of-the-art algorithm approaches what are the standard state-of-the-art algorithms that we can",
    "start": "156450",
    "end": "162810"
  },
  {
    "text": "use for text analytics how do we continuously think deeply around connect collecting more data to continuously",
    "start": "162810",
    "end": "169260"
  },
  {
    "text": "make sure the service becomes more accurate over time right and if you're a customer we don't we don't use your data",
    "start": "169260",
    "end": "175290"
  },
  {
    "text": "if you want to share your data with us you can otherwise you can simply opt out we have a full-time team that goes and",
    "start": "175290",
    "end": "181049"
  },
  {
    "text": "collects data on your behalf we implement things like transfer learning so that when you know I'll talk about",
    "start": "181049",
    "end": "186420"
  },
  {
    "text": "custom comprehend later we provide the data we provide the science expertise and we actually take care of the",
    "start": "186420",
    "end": "192540"
  },
  {
    "text": "training for you so this this service really removes all of that and then of course we make it available to you with",
    "start": "192540",
    "end": "198209"
  },
  {
    "text": "the availability of typical AWS services the service itself here's a quick functional overview the service itself",
    "start": "198209",
    "end": "205169"
  },
  {
    "start": "200000",
    "end": "397000"
  },
  {
    "text": "has a number of API s so the first API is the entity API so that that API",
    "start": "205169",
    "end": "211620"
  },
  {
    "text": "extracts and again we'll go through code level details show you guys what these look like but that API extracts think of it as",
    "start": "211620",
    "end": "217889"
  },
  {
    "text": "proper nouns as typed proper nouns so what I mean by that is will extract people and will have an entity type",
    "start": "217889",
    "end": "224069"
  },
  {
    "text": "called person will extract organizations will extract events will extract locations in time so a lot of our",
    "start": "224069",
    "end": "230940"
  },
  {
    "text": "customers have been using this to do things like you know I'm gonna go through and find out deeply find out",
    "start": "230940",
    "end": "236430"
  },
  {
    "text": "what's in this document what's contained in this document we have a key phrase API the key phase API is typically used",
    "start": "236430",
    "end": "243180"
  },
  {
    "text": "in conjunction with the entity API the key phrase API really does common nouns right and common noun phrases so",
    "start": "243180",
    "end": "249959"
  },
  {
    "text": "using these two api's together you're getting a really nice understanding of what's actually in the document we",
    "start": "249959",
    "end": "256349"
  },
  {
    "text": "identify language so the service itself will identify up to a hundred different languages right so if you're doing",
    "start": "256349",
    "end": "262019"
  },
  {
    "text": "business with a multiple set of markets or you need to understand what a language is before you maybe go try",
    "start": "262019",
    "end": "267270"
  },
  {
    "text": "lated or have another business process workflow will identify the language for you the service identifies sentiment so",
    "start": "267270",
    "end": "274139"
  },
  {
    "text": "sent to its very popular and applications like understanding what your customers are saying maybe",
    "start": "274139",
    "end": "279539"
  },
  {
    "text": "understanding the experience that they're having are they neutral are they negative are they positive on something so a lot of our",
    "start": "279539",
    "end": "286349"
  },
  {
    "text": "customers want to know pave what was what was being said in the call center conversations yesterday maybe they were",
    "start": "286349",
    "end": "291539"
  },
  {
    "text": "using Amazon transcribed to transcribe the calls and then they want to go through and analyze those calls and say",
    "start": "291539",
    "end": "297090"
  },
  {
    "text": "you know what let me let me just you know this is the glass half-full thought process but let me go through and find",
    "start": "297090",
    "end": "302819"
  },
  {
    "text": "out what were all the negative comments that our customers had yesterday and then let me now that I've identified",
    "start": "302819",
    "end": "308250"
  },
  {
    "text": "those let me go use some of the other api's and let me go find out specifically what did they say what",
    "start": "308250",
    "end": "313740"
  },
  {
    "text": "brand did they mention what's what product of ours did they mention what were the descriptive words they used",
    "start": "313740",
    "end": "319349"
  },
  {
    "text": "right so this is sort of how you think about using these api's together to have fully understand text we've introduced",
    "start": "319349",
    "end": "325740"
  },
  {
    "text": "the syntax API which is a lower-level API that helps you parse word boundaries grammatically correct word boundaries",
    "start": "325740",
    "end": "331560"
  },
  {
    "text": "and applies a part of speech so you'll know something's a noun or an adjective for example so again as you build on",
    "start": "331560",
    "end": "338069"
  },
  {
    "text": "these api's together you can really go down to the low lowest level granularity of understanding what's in that text we",
    "start": "338069",
    "end": "344219"
  },
  {
    "text": "have another API that helps you organize documents right so it's it's topic modeling and it this effectively helps",
    "start": "344219",
    "end": "349349"
  },
  {
    "text": "you group documents based on similar keywords so we'll have customers come in and say look we just got a dump of",
    "start": "349349",
    "end": "355620"
  },
  {
    "text": "documents yesterday from some business workflow there's 2,000 of them we don't really understand what's in them you can",
    "start": "355620",
    "end": "361860"
  },
  {
    "text": "take topic modeling pointed at that corpus of documents they'd be stored in an s3 bucket and then the service will",
    "start": "361860",
    "end": "367949"
  },
  {
    "text": "organize the documents based on however many topics or cat or groups you've asked it to do what that does is it",
    "start": "367949",
    "end": "374729"
  },
  {
    "text": "looks at the actual words themselves and does the statistical grouping of those like words so that you could see okay",
    "start": "374729",
    "end": "380219"
  },
  {
    "text": "yesterday we had a thousand documents come in and now they're if I organize them these like words are showing me the",
    "start": "380219",
    "end": "385590"
  },
  {
    "text": "categories so you could say these things really look like customer complaints these things really look like product",
    "start": "385590",
    "end": "390900"
  },
  {
    "text": "orders so it's a nice fast way to analyze they're organized documents one",
    "start": "390900",
    "end": "398099"
  },
  {
    "start": "397000",
    "end": "469000"
  },
  {
    "text": "of the biggest things that we just saw we just announced actually on on November 15th and 16th respectively",
    "start": "398099",
    "end": "403350"
  },
  {
    "text": "is custom Amazon comprehend this is actually quite a big step forward for comprehend so as I was talking about is",
    "start": "403350",
    "end": "409740"
  },
  {
    "text": "the service initially went to market actually last year at reinvent and we we effect we had something we call pre",
    "start": "409740",
    "end": "415500"
  },
  {
    "text": "train models so what that meant was the service would train our entity models to go look for things like people",
    "start": "415500",
    "end": "421470"
  },
  {
    "text": "organizations locations events now what if your business has entities you care",
    "start": "421470",
    "end": "426930"
  },
  {
    "text": "about that not aren't necessarily popular entities that everybody cares about well that what we found was our",
    "start": "426930",
    "end": "433170"
  },
  {
    "text": "customers loved the pre trade models but then they wanted those they wanted the ability to customize the service to do",
    "start": "433170",
    "end": "438570"
  },
  {
    "text": "their own entity types so I'll show you an example things like you know policy number or things like you know a maker",
    "start": "438570",
    "end": "445230"
  },
  {
    "text": "model that's specific to your company the problem was if you remember that first slide I showed you then you'd have",
    "start": "445230",
    "end": "450330"
  },
  {
    "text": "to go all the way back to the drawing board learn machine learning prepare and annotate data train a model deploy the",
    "start": "450330",
    "end": "456390"
  },
  {
    "text": "model so we are the team took on the challenge of saying let's actually remove all of those steps on behalf of our customers let's make customization",
    "start": "456390",
    "end": "463620"
  },
  {
    "text": "of NOP as easy to this is to use comprehend today and then we'll talk about what that means",
    "start": "463620",
    "end": "469550"
  },
  {
    "start": "469000",
    "end": "534000"
  },
  {
    "text": "the first service we are the first feature we introduced in custom comprehend is custom classification so",
    "start": "469670",
    "end": "475800"
  },
  {
    "text": "in NLP a classifier is simply something that looks at a document and applies a label it's categorization of documents",
    "start": "475800",
    "end": "482190"
  },
  {
    "text": "and so the way that you train a classifier so it's really good for doing things like automatically triage support",
    "start": "482190",
    "end": "488010"
  },
  {
    "text": "tickets I mean how many of us I know at Amazon we do this I'll locate a ticket and log that's I've seen that one before",
    "start": "488010",
    "end": "494220"
  },
  {
    "text": "and I I do the drop-down and I assign a label so you know you can imagine that those routine tickets can now can get",
    "start": "494220",
    "end": "499440"
  },
  {
    "text": "automatically trans triage right you can moderate forums we have customers training classification models to go",
    "start": "499440",
    "end": "506340"
  },
  {
    "text": "through their customer forums to do things like are these guy you know is there bullying going on is there",
    "start": "506340",
    "end": "511920"
  },
  {
    "text": "explicit no is there is there profanity are they mentioning our products or brands maybe in a negative way so you",
    "start": "511920",
    "end": "518700"
  },
  {
    "text": "can train these classifiers to do a multiple set of things and then so and the for example for the picture as your",
    "start": "518700",
    "end": "525720"
  },
  {
    "text": "documents will come into class your file will run and for each document you little append a label and then your",
    "start": "525720",
    "end": "531450"
  },
  {
    "text": "business workflow can start doing what it needs to do with those documents now here's the neat IP if for how many",
    "start": "531450",
    "end": "537810"
  },
  {
    "text": "folks in the room have actually trained a classifier before okay great as you know we know it's not very easy",
    "start": "537810",
    "end": "544860"
  },
  {
    "text": "right there's that there's some knowledge required you've probably built up quite a bit of knowledge you'd have to do things like select the right",
    "start": "544860",
    "end": "551279"
  },
  {
    "text": "algorithm one algorithm for short text data could be different than another classifier algorithm for longer form",
    "start": "551279",
    "end": "557430"
  },
  {
    "text": "data so there's a lot of things you have to learn to build a highly effective classifier so what we've done is we've",
    "start": "557430",
    "end": "563519"
  },
  {
    "text": "effectively built an automated way to train these classifier models for you and the Oscar is going to come up and",
    "start": "563519",
    "end": "569399"
  },
  {
    "text": "talk a little bit about how we've done this but what's amazing is all you need to do now is if you can build a CSV file",
    "start": "569399",
    "end": "575730"
  },
  {
    "text": "you can train a classifier so this is literally the schema that you'll have to provide you'll provide us the text",
    "start": "575730",
    "end": "581910"
  },
  {
    "text": "itself for each category and then you'll provide the label that you want for that category so you could open up your",
    "start": "581910",
    "end": "587790"
  },
  {
    "text": "favorite spreadsheet software go get a bunch of examples label those examples you might have a business analyst of",
    "start": "587790",
    "end": "593160"
  },
  {
    "text": "your company do this work now and then you can save that file and then submit it to the service and then the service",
    "start": "593160",
    "end": "599370"
  },
  {
    "text": "will automatically look at the it will look at the data it will select the right algorithm based on the data set",
    "start": "599370",
    "end": "604949"
  },
  {
    "text": "that that is the most optimum it will actually automatically tune and test the model so it'll take some of that data",
    "start": "604949",
    "end": "611040"
  },
  {
    "text": "you've provided and set it aside and build a test set and then and then you can do all of this today through our",
    "start": "611040",
    "end": "616500"
  },
  {
    "text": "WYSIWYG console you can open a console and write zero code to train the classifier just by simply pointing at",
    "start": "616500",
    "end": "623100"
  },
  {
    "text": "your CSV file and then and then and then explaining to us where you'd like the document submitted or you can fully do",
    "start": "623100",
    "end": "629430"
  },
  {
    "text": "this through the SDK through API is and automate the training and the consumption of classifiers custom",
    "start": "629430",
    "end": "636630"
  },
  {
    "start": "635000",
    "end": "675000"
  },
  {
    "text": "entities is the second key custom feature we've released so custom entities if you look at the example on",
    "start": "636630",
    "end": "641820"
  },
  {
    "text": "the board you know things in red and actually so for folks the things at the top the two entities at the top are",
    "start": "641820",
    "end": "648510"
  },
  {
    "text": "entities that comprehend does today so person and organization the entities on",
    "start": "648510",
    "end": "653880"
  },
  {
    "text": "the far right part number and the entities on the bottom-left account action are in yellow those are entities",
    "start": "653880",
    "end": "659610"
  },
  {
    "text": "that were custom so we wanted to show you that now what you can do at your business is you can use our pre trained",
    "start": "659610",
    "end": "666000"
  },
  {
    "text": "entities go train your own and model and then get a full superset of all the entities that are key to your",
    "start": "666000",
    "end": "672060"
  },
  {
    "text": "business the same thing applies in terms",
    "start": "672060",
    "end": "677639"
  },
  {
    "start": "675000",
    "end": "784000"
  },
  {
    "text": "of ease of use and automated training for custom entities so we've removed all the complex steps involved here how many",
    "start": "677639",
    "end": "683550"
  },
  {
    "text": "folks in the room again as is so fun to ask how many folks have trained a custom entity model okay so this hurdle is even",
    "start": "683550",
    "end": "691350"
  },
  {
    "text": "bigger than the classification one and so the way what we've done is we've we've reduced this set of steps you",
    "start": "691350",
    "end": "696810"
  },
  {
    "text": "require no machine learning we've reduced the set of steps down to two things you need to prepare the entity",
    "start": "696810",
    "end": "703410"
  },
  {
    "text": "examples so for example let's say we want to create an entity type for parts it's our maybe our unique part for codes",
    "start": "703410",
    "end": "708959"
  },
  {
    "text": "for our company go get those entity types put them in a CSV file put them in a single column give the column a header which is your",
    "start": "708959",
    "end": "715680"
  },
  {
    "text": "type name the second thing we want you to do is point us to it about a thousand documents that contain your part numbers",
    "start": "715680",
    "end": "722550"
  },
  {
    "text": "in the context of how your business uses them so of course we all probably have documents laying around that contain",
    "start": "722550",
    "end": "727949"
  },
  {
    "text": "things that are important to us like part numbers so you just want to go collect those and put those in an s3 bucket what the service does is it",
    "start": "727949",
    "end": "734550"
  },
  {
    "text": "synthetically annotates the data so this is a key step in training machine learning models we'll take those out of the examples you gave us we'll go look",
    "start": "734550",
    "end": "741779"
  },
  {
    "text": "at the actual documents that you've given us that contain those entities as an example and we'll prepare the data set for you so this way what you're",
    "start": "741779",
    "end": "748410"
  },
  {
    "text": "getting is a machine learning model that's contextual to your business for example you can imagine that the word",
    "start": "748410",
    "end": "754079"
  },
  {
    "text": "chip is different to an insurance company than it is to frito-lay and this is the kind of this is the deep neural",
    "start": "754079",
    "end": "759720"
  },
  {
    "text": "accuracy that you're training by providing us the sample data and again similar to classification the service",
    "start": "759720",
    "end": "765269"
  },
  {
    "text": "will automatically annotate the data it will select the right algorithm amongst a few different algorithm choices that",
    "start": "765269",
    "end": "770430"
  },
  {
    "text": "our team continuously monitors and changes and updates and then we'll tune tests and you can again do all of this",
    "start": "770430",
    "end": "776490"
  },
  {
    "text": "through the console with no code or you can also use the SDK in the api's to automate all of this for you one of the",
    "start": "776490",
    "end": "785850"
  },
  {
    "start": "784000",
    "end": "854000"
  },
  {
    "text": "other things that I like to show is when we're doing you know kind of a short customer conversation a face-to-face we",
    "start": "785850",
    "end": "791339"
  },
  {
    "text": "we always tend to draw this picture and I think this picture is really helpful if you're new to NLP and you really want",
    "start": "791339",
    "end": "797309"
  },
  {
    "text": "to understand what the service is doing in this case you know a lot we all like to think of at least and a lot of us do you think about data",
    "start": "797309",
    "end": "803650"
  },
  {
    "text": "in a structured way so this is an example of what comprehends doing for you for example on the left hand side",
    "start": "803650",
    "end": "809680"
  },
  {
    "text": "you can see the column headers which is person organization or location and you can see that the service itself is",
    "start": "809680",
    "end": "815050"
  },
  {
    "text": "extracting those actual variables we're taking out all the people and all the locations being mentioned and then the",
    "start": "815050",
    "end": "821050"
  },
  {
    "text": "two columns on the right are custom entities those are the two entities I just added so now I'm now you can imagine I'm building a really complete",
    "start": "821050",
    "end": "827280"
  },
  {
    "text": "superset structured view of my data this you know what what what created this",
    "start": "827280",
    "end": "832300"
  },
  {
    "text": "this table was actually comprehend going through unstructured documents and extracting these words these terms and",
    "start": "832300",
    "end": "839320"
  },
  {
    "text": "these end these short phrases and allowing you to compile this data in a structured way so you can do things like join sort filter provide you know search",
    "start": "839320",
    "end": "847060"
  },
  {
    "text": "predicate switch Ben's going to show you code level detail so we like to show this this this is effectively what structured output looks like so what I'm",
    "start": "847060",
    "end": "855520"
  },
  {
    "start": "854000",
    "end": "876000"
  },
  {
    "text": "gonna do at this point let me please invite yasser up to the stage yasser is our science lead for comprehend he leads",
    "start": "855520",
    "end": "861490"
  },
  {
    "text": "the team of scientists that are thinking all the time about how the service can improve how can improve accuracy and",
    "start": "861490",
    "end": "867700"
  },
  {
    "text": "what what new state-of-the-art of approach could we bring into the service to increase make it better for customers",
    "start": "867700",
    "end": "872890"
  },
  {
    "text": "so yasser oh good afternoon my name is",
    "start": "872890",
    "end": "879040"
  },
  {
    "start": "876000",
    "end": "1039000"
  },
  {
    "text": "Jocelyn Eisen and the science manager for comprehend and the mission of my",
    "start": "879040",
    "end": "884950"
  },
  {
    "text": "team is to abstract away the complexity the ml ml NLP complexity and make the",
    "start": "884950",
    "end": "892240"
  },
  {
    "text": "latest and greatest advances available to you as a as a as a user of comprehend so the mission of the team is wading",
    "start": "892240",
    "end": "901090"
  },
  {
    "text": "through the all the scientific advances that happen in deep learning and machine",
    "start": "901090",
    "end": "907000"
  },
  {
    "text": "learning and so on and so forth and making sure that we make that available without you having to know about the",
    "start": "907000",
    "end": "914230"
  },
  {
    "text": "technical details that go beyond just using the service so we started first",
    "start": "914230",
    "end": "919540"
  },
  {
    "text": "with the algorithms that are needed for pre-trained down pre-trained models and for that we do the training and we do",
    "start": "919540",
    "end": "927010"
  },
  {
    "text": "the optimization and so on and so forth and then now we are advancing into making these custom models that you can",
    "start": "927010",
    "end": "933550"
  },
  {
    "text": "actually bring in your data so now we have to worry about making all the optimizations that happen available",
    "start": "933550",
    "end": "939620"
  },
  {
    "text": "to you as well so that you don't have to worry about optimizing this for so",
    "start": "939620",
    "end": "944629"
  },
  {
    "text": "basically the mission of the team is you know wading through all the different state-of-the-art algorithms and you know",
    "start": "944629",
    "end": "950870"
  },
  {
    "text": "the the secret is that there is no one-size-fits-all certain algorithms are",
    "start": "950870",
    "end": "956180"
  },
  {
    "text": "suitable for certain tasks and datasets and so on and so forth so instead of you worrying - you know you having to worry",
    "start": "956180",
    "end": "962689"
  },
  {
    "text": "about that we worry about it and we do it under the hood so you don't have to and you know just it's ready to use you",
    "start": "962689",
    "end": "970100"
  },
  {
    "text": "bring in your data if you're using custom or you can just use the pre trained models and and and do that and",
    "start": "970100",
    "end": "976279"
  },
  {
    "text": "so the algorithm selection for example this is something that we we do under",
    "start": "976279",
    "end": "981350"
  },
  {
    "text": "the hood so you don't have to worry about do I use this you know buy torch",
    "start": "981350",
    "end": "986870"
  },
  {
    "text": "or do I use tensorflow do I use MX net do I use this particular architecture or",
    "start": "986870",
    "end": "992360"
  },
  {
    "text": "that architecture and so on and so forth I was going to show a slide of a neural net architecture but needle vetoed that",
    "start": "992360",
    "end": "998750"
  },
  {
    "text": "so so I'm staying with these four bullets so anyway so we we do all of",
    "start": "998750",
    "end": "1004839"
  },
  {
    "text": "that you know choosing the appropriate algorithm doing the tuning of the model and so on",
    "start": "1004839",
    "end": "1010509"
  },
  {
    "text": "whether that's for the pre trained models or also for the custom models that you you train with your own data so",
    "start": "1010509",
    "end": "1016000"
  },
  {
    "text": "we do the tuning and the testing and finding the appropriate algorithm for that particular set for that particular task and we make it available to you and",
    "start": "1016000",
    "end": "1023170"
  },
  {
    "text": "then we also manage the deployment of the models and managing the usage of that after so that's all I have thank",
    "start": "1023170",
    "end": "1029829"
  },
  {
    "text": "you thanks so much",
    "start": "1029829",
    "end": "1032880"
  },
  {
    "text": "that's great yes so one of the things that the comprehend team is it's",
    "start": "1037510",
    "end": "1043970"
  },
  {
    "text": "actually like all AWS teams we're very customer obsessed we've been very fortunate to have some really great",
    "start": "1043970",
    "end": "1049580"
  },
  {
    "text": "early customers that are helping us driving feedback and these are these are large text analytics customers so",
    "start": "1049580",
    "end": "1056029"
  },
  {
    "text": "they're really beating up the service they're giving us great feedback we're getting better and better every day so",
    "start": "1056029",
    "end": "1061279"
  },
  {
    "text": "we're very fortunate today what we wanted to do is take a chance to four let you hear directly from some of those",
    "start": "1061279",
    "end": "1066559"
  },
  {
    "text": "customers in the particular today FINRA so if Fenriz been a great customer a great early partner and it's matt and de",
    "start": "1066559",
    "end": "1073159"
  },
  {
    "text": "metrio from FINRA and we're excited to have them so matt would you like to come up Thanks oh my god yeah there we go",
    "start": "1073159",
    "end": "1083090"
  },
  {
    "text": "thanks Nina I'm Matt Cardillo and I'm a senior director at FINRA I've been there",
    "start": "1083090",
    "end": "1089360"
  },
  {
    "text": "for 11 years and I was one of the senior",
    "start": "1089360",
    "end": "1094399"
  },
  {
    "text": "managers responsible for the public move for moving to the public cloud that kicked off in 2014",
    "start": "1094399",
    "end": "1100610"
  },
  {
    "text": "specifically around self-service analytics and complex market",
    "start": "1100610",
    "end": "1105679"
  },
  {
    "text": "reconstructions so applicant user facing applications Demetriou Dell gobble off",
    "start": "1105679",
    "end": "1111409"
  },
  {
    "text": "we've been working together that the entire time I've been here and he is",
    "start": "1111409",
    "end": "1116809"
  },
  {
    "text": "kind of our beachhead he understands content and unstructured data and he's",
    "start": "1116809",
    "end": "1123200"
  },
  {
    "text": "our beachhead for text analytics at FINRA so let's get into it so about five",
    "start": "1123200",
    "end": "1132770"
  },
  {
    "start": "1128000",
    "end": "1257000"
  },
  {
    "text": "years ago the high-water mark that you see on screen here was it's about half of what it is today the hundred the",
    "start": "1132770",
    "end": "1139909"
  },
  {
    "text": "hundred and thirty five billion records that we took in was just this past",
    "start": "1139909",
    "end": "1145159"
  },
  {
    "text": "October so it's it's pretty staggering how these numbers just keep changing we",
    "start": "1145159",
    "end": "1150649"
  },
  {
    "text": "bring in a massive amount of data so for those of you don't know us we are FINRA the financial regulatory authority we",
    "start": "1150649",
    "end": "1159919"
  },
  {
    "text": "regulate the entire nearly the entire equities market and the majority of the options markets",
    "start": "1159919",
    "end": "1167030"
  },
  {
    "text": "our mission is to provide market integrity by ensuring that the markets",
    "start": "1167030",
    "end": "1172980"
  },
  {
    "text": "are fair and orderly so that investors are protected and essentially people",
    "start": "1172980",
    "end": "1178650"
  },
  {
    "text": "feel safe investing their hard-earned dollars in the marketplace so as I said",
    "start": "1178650",
    "end": "1183900"
  },
  {
    "text": "we have a massive amounts of data we perform complex reconstructions on this to make sense of these market events",
    "start": "1183900",
    "end": "1189540"
  },
  {
    "text": "that are coming in and flooding flooding into the company every day in the past",
    "start": "1189540",
    "end": "1195179"
  },
  {
    "text": "five years we developed a core competency around structured data and",
    "start": "1195179",
    "end": "1200600"
  },
  {
    "text": "managing that structured data in the cloud so namely as an organization no",
    "start": "1200600",
    "end": "1206580"
  },
  {
    "text": "longer we don't think of our infrastructure is fixed any longer we",
    "start": "1206580",
    "end": "1212460"
  },
  {
    "text": "also developed robust data management solutions which we've also open sourced",
    "start": "1212460",
    "end": "1218720"
  },
  {
    "text": "we've employed innovative partitioning strategies and this is really to account",
    "start": "1218720",
    "end": "1223830"
  },
  {
    "text": "for the fact that our data is very highly skewed and we don't know what questions people are going to ask of the",
    "start": "1223830",
    "end": "1230340"
  },
  {
    "text": "data we also employ multiple query engines based on different usage",
    "start": "1230340",
    "end": "1237090"
  },
  {
    "text": "scenarios so that we're using the right tool for the right purpose so if it's a user waiting at a laptop they're they're",
    "start": "1237090",
    "end": "1244080"
  },
  {
    "text": "getting their answer back very quickly versus our one of our surveillance",
    "start": "1244080",
    "end": "1249150"
  },
  {
    "text": "programs that's combing through data looking for nefarious behavior so we've done a lot around structured data so",
    "start": "1249150",
    "end": "1255809"
  },
  {
    "text": "what's next and I would say our challenge is really a so thinner has a",
    "start": "1255809",
    "end": "1261360"
  },
  {
    "start": "1257000",
    "end": "1282000"
  },
  {
    "text": "very large backlog of casework we that we refer to as matters and working on",
    "start": "1261360",
    "end": "1267540"
  },
  {
    "text": "these matters there's there's a there's lots of unstructured content coming in and this includes things like",
    "start": "1267540",
    "end": "1276889"
  },
  {
    "text": "there it is form filings documents we get nearly a million documents a year",
    "start": "1281220",
    "end": "1289230"
  },
  {
    "start": "1282000",
    "end": "1329000"
  },
  {
    "text": "email correspondence and also reference data or data that we use as reference as",
    "start": "1289230",
    "end": "1295150"
  },
  {
    "text": "part of our analysis so unearthing key",
    "start": "1295150",
    "end": "1302110"
  },
  {
    "text": "features like the who the what the where the when how is very time-consuming",
    "start": "1302110",
    "end": "1308680"
  },
  {
    "text": "it's very error-prone and sometimes downright painful for our regulators",
    "start": "1308680",
    "end": "1314250"
  },
  {
    "text": "some of our more complex cases have thousands of files associated so having",
    "start": "1314250",
    "end": "1321220"
  },
  {
    "text": "to go through these things manually how do our analyst really know if you know high confidence a high degree of",
    "start": "1321220",
    "end": "1326290"
  },
  {
    "text": "confidence that they haven't missed something so here's a simple example where of",
    "start": "1326290",
    "end": "1334540"
  },
  {
    "start": "1329000",
    "end": "1419000"
  },
  {
    "text": "information that that comes into FINRA so that top paragraph that's the information that we receive so we've got",
    "start": "1334540",
    "end": "1340410"
  },
  {
    "text": "essentially an investor John Doe that invested in some annuities that he's",
    "start": "1340410",
    "end": "1346600"
  },
  {
    "text": "that was sold to him by William Smith but he didn't he's claiming he didn't understand these these investments so",
    "start": "1346600",
    "end": "1353290"
  },
  {
    "text": "that's the kind of stuff we receive the kind of stuff we need is essentially",
    "start": "1353290",
    "end": "1358450"
  },
  {
    "text": "that the investors John Doe the broker is William Smith and what his unique",
    "start": "1358450",
    "end": "1364480"
  },
  {
    "text": "identifier is and this is where comprehend comes into play so we're",
    "start": "1364480",
    "end": "1369520"
  },
  {
    "text": "building text analytics solutions using key features of comprehends such as",
    "start": "1369520",
    "end": "1374670"
  },
  {
    "text": "entity recognition and text the context classifier to help us basically unearth",
    "start": "1374670",
    "end": "1382780"
  },
  {
    "text": "these these features important to the regulator's to sift this out of the pile of content that we're constantly",
    "start": "1382780",
    "end": "1389440"
  },
  {
    "text": "bringing in through filings through information requests through tips and so",
    "start": "1389440",
    "end": "1394690"
  },
  {
    "text": "on but we want to go further and we'll be considering comprehends custom",
    "start": "1394690",
    "end": "1400960"
  },
  {
    "text": "capabilities that ninu spoke of today so that so that we can get even you know",
    "start": "1400960",
    "end": "1407620"
  },
  {
    "text": "get more complicated in terms of the things that we're going to unearth that our term is more specific to to our",
    "start": "1407620",
    "end": "1413350"
  },
  {
    "text": "business of regulations so that's what we're working on and the capability that",
    "start": "1413350",
    "end": "1423640"
  },
  {
    "start": "1419000",
    "end": "1451000"
  },
  {
    "text": "we that that we're building we call it the the Comex command center of organization of people and organizations",
    "start": "1423640",
    "end": "1430570"
  },
  {
    "text": "sorry let me say that again the Comex command center of people and organizations so an organization like",
    "start": "1430570",
    "end": "1436870"
  },
  {
    "text": "finra we have we're over cited by the government so true to form like any",
    "start": "1436870",
    "end": "1442120"
  },
  {
    "text": "organization that has governmental oversight we've gotten really good at naming capabilities that just roll right",
    "start": "1442120",
    "end": "1448420"
  },
  {
    "text": "off the tongue could you tell but they always seem to very conveniently fit",
    "start": "1448420",
    "end": "1455980"
  },
  {
    "text": "into an acronym so all kidding aside I'm going to invite",
    "start": "1455980",
    "end": "1461350"
  },
  {
    "text": "Demetriou up to talk about c-3po and what we're doing to make that a reality of FINRA Demetriou hello everyone my",
    "start": "1461350",
    "end": "1474130"
  },
  {
    "start": "1469000",
    "end": "1585000"
  },
  {
    "text": "name is Dmitry Dolgopolov I'm a senior director at FINRA in charge of document",
    "start": "1474130",
    "end": "1479770"
  },
  {
    "text": "management and obviously was a document management without the text analytics so let's talk about what we've built with",
    "start": "1479770",
    "end": "1486220"
  },
  {
    "text": "our c-3po what you see on screen right now is actually a real application name",
    "start": "1486220",
    "end": "1491770"
  },
  {
    "text": "names almost real if you squint you may even recognize some of them but that's",
    "start": "1491770",
    "end": "1497800"
  },
  {
    "text": "actual real document that comes into our system and it's a 200 page document this",
    "start": "1497800",
    "end": "1505060"
  },
  {
    "text": "particular one and this application you see on the screen allows our users to",
    "start": "1505060",
    "end": "1510180"
  },
  {
    "text": "sift through that huge document in a matter of minutes and not days I'm okay",
    "start": "1510180",
    "end": "1516550"
  },
  {
    "text": "maybe hours and being able to identify the key information in this document and",
    "start": "1516550",
    "end": "1522670"
  },
  {
    "text": "as regulators what we are looking for our key pieces of information things",
    "start": "1522670",
    "end": "1528160"
  },
  {
    "text": "like we called bad actors and bad actors are people with some known regulatory",
    "start": "1528160",
    "end": "1534070"
  },
  {
    "text": "history with some known problems from the past or some people who are not like",
    "start": "1534070",
    "end": "1541480"
  },
  {
    "text": "following all the rules over comply so this particular application allows",
    "start": "1541480",
    "end": "1546870"
  },
  {
    "text": "our users with the help of cambric and of course gets the most important pieces",
    "start": "1546870",
    "end": "1553260"
  },
  {
    "text": "right away you can see users can identify now there are three bad actors",
    "start": "1553260",
    "end": "1559890"
  },
  {
    "text": "on in that particular document and why is it important that means they need to spend more time analyzing and reviewing",
    "start": "1559890",
    "end": "1567360"
  },
  {
    "text": "this document and if there is another submission another document or another set of documents that's you know all",
    "start": "1567360",
    "end": "1574860"
  },
  {
    "text": "clean is the whistle they can spend less time and focus on the you know it is",
    "start": "1574860",
    "end": "1580980"
  },
  {
    "text": "based approach this is all very very",
    "start": "1580980",
    "end": "1587940"
  },
  {
    "start": "1585000",
    "end": "1724000"
  },
  {
    "text": "high-level architecture it's not even ten thousand views I don't start this fear and as you can see we've built some",
    "start": "1587940",
    "end": "1596100"
  },
  {
    "text": "modules around comprehend and how we can leverage comprehend for text analytics",
    "start": "1596100",
    "end": "1602000"
  },
  {
    "text": "so in this particular case you know you need to prepare your data before you can",
    "start": "1602000",
    "end": "1608910"
  },
  {
    "text": "fit it to you know comprehend and as you know pointed out it takes some time but",
    "start": "1608910",
    "end": "1615630"
  },
  {
    "text": "but comprehend makes it easier however you still need to spend some time lots let's not fool ourselves you need to",
    "start": "1615630",
    "end": "1621960"
  },
  {
    "text": "spend some time prepare data and because as self-regulatory organization we",
    "start": "1621960",
    "end": "1628050"
  },
  {
    "text": "actually try to make it simple to our forms to become client and we actually",
    "start": "1628050",
    "end": "1636380"
  },
  {
    "text": "reckon the whole meaning of unstructured data it's super instructions so it's freestyle almost that makes it a bit",
    "start": "1636380",
    "end": "1644100"
  },
  {
    "text": "easier for our forms but obviously makes it more complicated for our reviewers so",
    "start": "1644100",
    "end": "1650550"
  },
  {
    "text": "that's why we leverage a lot of AWS services we use as their functions and",
    "start": "1650550",
    "end": "1656850"
  },
  {
    "text": "that they were it starts from and then we have modules that do data preparation some cleanup or CR sometimes then if",
    "start": "1656850",
    "end": "1664350"
  },
  {
    "text": "you'da to comprehend we have our own modules to do entity magic which I will talk about in details later and that",
    "start": "1664350",
    "end": "1671850"
  },
  {
    "text": "allows us to do Sauron in a very very cool stuff so it's not that comprehend is not cool",
    "start": "1671850",
    "end": "1679740"
  },
  {
    "text": "it's cool but you see on the right side if a bamas on neptune elastics you're sure and actually this is where we ran",
    "start": "1679740",
    "end": "1686730"
  },
  {
    "text": "out of space there are so many other things that comprehensive Mabel's us to do we can do we can build like now",
    "start": "1686730",
    "end": "1693990"
  },
  {
    "text": "better models for machines or we can feed this information to stage Baker we",
    "start": "1693990",
    "end": "1699360"
  },
  {
    "text": "can make our enterprise source you provide more precise information better results better quality results so you",
    "start": "1699360",
    "end": "1708180"
  },
  {
    "text": "know the way I see it it's if you wanna have dessert you need to eat your vegetables so that that that purple",
    "start": "1708180",
    "end": "1715860"
  },
  {
    "text": "broccoli in the middle very important part of our diet so let's now look under",
    "start": "1715860",
    "end": "1727860"
  },
  {
    "start": "1724000",
    "end": "1888000"
  },
  {
    "text": "the hood and let's see how exactly we implemented the entity matching that we are bragging so much about so it all",
    "start": "1727860",
    "end": "1735390"
  },
  {
    "text": "starts with yeah you have a pile of documents and you prepare it and then you unleash comprehend on it so as a",
    "start": "1735390",
    "end": "1742560"
  },
  {
    "text": "result it brings back how we call it feature sets what is the feature set it's essentially is information about",
    "start": "1742560",
    "end": "1751370"
  },
  {
    "text": "individuals so we use some semi proprietary techniques such as proximity",
    "start": "1751370",
    "end": "1758000"
  },
  {
    "text": "context the nature of a document in order to combine together all the",
    "start": "1758000",
    "end": "1763680"
  },
  {
    "text": "information about single individual so you see on the screen that feature set",
    "start": "1763680",
    "end": "1769920"
  },
  {
    "text": "typically consists of things like name email address employment history",
    "start": "1769920",
    "end": "1775590"
  },
  {
    "text": "so comprehend allows us to bring all of that information and we use our tricks",
    "start": "1775590",
    "end": "1781320"
  },
  {
    "text": "to combine it all together now what it gives us it's actually unbelievable so",
    "start": "1781320",
    "end": "1787260"
  },
  {
    "text": "our database of registry to individuals that we need to measure or in the NI",
    "start": "1787260",
    "end": "1794280"
  },
  {
    "text": "identify it's pretty large I mean we're talking about a few million records and",
    "start": "1794280",
    "end": "1799640"
  },
  {
    "text": "about 600,000 of them are actually actively you know participating in the",
    "start": "1799640",
    "end": "1806040"
  },
  {
    "text": "market activities individuals so you can imagine that going through one even throat reusing technology is",
    "start": "1806040",
    "end": "1812159"
  },
  {
    "text": "impossible not to mention doing it that manually like our investigators had to",
    "start": "1812159",
    "end": "1817529"
  },
  {
    "text": "do it in the past and we use some full text or techniques to narrow down the",
    "start": "1817529",
    "end": "1823649"
  },
  {
    "text": "set and this is you see where we move to the right to the comparator area now",
    "start": "1823649",
    "end": "1828989"
  },
  {
    "text": "it's not 2 million that we are 3 million we need to compare with its now you know",
    "start": "1828989",
    "end": "1834689"
  },
  {
    "text": "manageable subsets so we've built additional comparators using machine learning where we now can quickly go",
    "start": "1834689",
    "end": "1842399"
  },
  {
    "text": "through all of the dozens of candidates for matching and after that it brings",
    "start": "1842399",
    "end": "1849539"
  },
  {
    "text": "back typically handful I mean for very very common names like William Smith our",
    "start": "1849539",
    "end": "1856379"
  },
  {
    "text": "favorite guy might talked about it's very manageable in addition to that we",
    "start": "1856379",
    "end": "1862709"
  },
  {
    "text": "provide to our investigators to our users very good view of this is a high",
    "start": "1862709",
    "end": "1869249"
  },
  {
    "text": "confidence match this is a low confidence match it and now they can just focus on very very narrow set very",
    "start": "1869249",
    "end": "1878039"
  },
  {
    "text": "important individuals and we'll flag them for that for them saying hey you want to look at",
    "start": "1878039",
    "end": "1883259"
  },
  {
    "text": "this guy more or more carefully than the other two so benefits what do we get by",
    "start": "1883259",
    "end": "1890999"
  },
  {
    "start": "1888000",
    "end": "1992000"
  },
  {
    "text": "you know eating our vegetables so benefits are all over the place I mean",
    "start": "1890999",
    "end": "1897059"
  },
  {
    "text": "there are benefits to technology there are benefits to our customers forty",
    "start": "1897059",
    "end": "1902159"
  },
  {
    "text": "known as technologists what we benefit from we can extract individuals and organizations okay good we can now match",
    "start": "1902159",
    "end": "1909059"
  },
  {
    "text": "them as I explained to entities with all since it is the funeral records we can flag individuals so out of all William",
    "start": "1909059",
    "end": "1917189"
  },
  {
    "text": "Smith's maybe only one of them is required special attention so you can skip there the other 3,000 and we it",
    "start": "1917189",
    "end": "1925859"
  },
  {
    "text": "also enables us to do higher level analytics like machine learning like",
    "start": "1925859",
    "end": "1931129"
  },
  {
    "text": "community detection and you saw that Neptune referenced on the previous slide that's what we get by using comprehend",
    "start": "1931129",
    "end": "1939079"
  },
  {
    "text": "now benefits our customers our investigators our",
    "start": "1939079",
    "end": "1944170"
  },
  {
    "text": "so we bring information to them so they don't have to mind it manually so in the past when the investigator receives a",
    "start": "1944170",
    "end": "1952000"
  },
  {
    "text": "200-page or eight hundred page document which is not on court offer they have to manually highlight they use a lot of",
    "start": "1952000",
    "end": "1958900"
  },
  {
    "text": "highlighters run all of them very quickly and then manually search for those names in our internal systems it",
    "start": "1958900",
    "end": "1966160"
  },
  {
    "text": "takes time as you can imagine it's very error-prone now they can just look on the screen and see what we get",
    "start": "1966160",
    "end": "1973180"
  },
  {
    "text": "we can flag individuals so we don't have to do it themselves and that's in always",
    "start": "1973180",
    "end": "1978880"
  },
  {
    "text": "a result it reclaims hours of you know tedious error-prone work and they allow",
    "start": "1978880",
    "end": "1986290"
  },
  {
    "text": "our users to focus on you know strategic efforts instead net result regulatory",
    "start": "1986290",
    "end": "1994960"
  },
  {
    "start": "1992000",
    "end": "2028000"
  },
  {
    "text": "reviews made easy thank you Ron yeah we",
    "start": "1994960",
    "end": "2005930"
  },
  {
    "text": "we really enjoy working with dinner and we we really appreciate it you know when one of the world one of",
    "start": "2005930",
    "end": "2011760"
  },
  {
    "text": "the world's leading financial analytics companies comes D and says they want to work with you to analyze tax we don't",
    "start": "2011760",
    "end": "2018120"
  },
  {
    "text": "you know we're so appreciative we don't take that opportunity lightly so we're really excited to work with FINRA and continue working with you guys so thank",
    "start": "2018120",
    "end": "2024150"
  },
  {
    "text": "you Matt to meet you so let's let's get",
    "start": "2024150",
    "end": "2030570"
  },
  {
    "start": "2028000",
    "end": "2169000"
  },
  {
    "text": "into architecture patterns we'll do this quickly and then Ben's going to come up and show you guys some code level stuff just you can see but real quick one",
    "start": "2030570",
    "end": "2036870"
  },
  {
    "text": "thing one thing Demetrio said it and it really stood out for me yesterday we were going through his slides he said you know he gave you a little preview up",
    "start": "2036870",
    "end": "2042990"
  },
  {
    "text": "there he said you know I don't mean to be offended but come prions just a little piece of this we're really excited just to kind of go in and",
    "start": "2042990",
    "end": "2048389"
  },
  {
    "text": "analyze the data and I was telling you about actually I think that's a huge compliment you know that's actually what we're trying to do we're actually trying",
    "start": "2048390",
    "end": "2054840"
  },
  {
    "text": "to remove anything related to machine learning or any complex set of work or set of skills that you have to learn to",
    "start": "2054840",
    "end": "2061560"
  },
  {
    "text": "go bill graph databases or to go build better search solutions right so so we're very we're very honored to get",
    "start": "2061560",
    "end": "2067020"
  },
  {
    "text": "that feedback so real quick for those of you new to kind of NLP and you're starting your NLP journey and we know",
    "start": "2067020",
    "end": "2072419"
  },
  {
    "text": "there's a number of you in the audience today we wanted to show you a couple of the top use cases and I know it's a very verbose",
    "start": "2072419",
    "end": "2077550"
  },
  {
    "text": "we're gonna make these available after the talk but let me call it a couple of these really quick we'll get let have been come up here one of the biggest",
    "start": "2077550",
    "end": "2084360"
  },
  {
    "text": "things we see is semantic search and he's going to show you that today what that means is with with comprehend you",
    "start": "2084360",
    "end": "2089610"
  },
  {
    "text": "can do things like boost and rank search solutions for better accuracy so you can when you're indexing your documents you",
    "start": "2089610",
    "end": "2095550"
  },
  {
    "text": "can run them through comprehend to do things like extract the entities extract key phrases and store that as metadata",
    "start": "2095550",
    "end": "2100950"
  },
  {
    "text": "you can even extract the sentiment of documents and then we'll show you how to do this and filter on sentiment so it",
    "start": "2100950",
    "end": "2106440"
  },
  {
    "text": "gives you really rich search solutions we see customers doing things like saying hey you know we've got a lot of",
    "start": "2106440",
    "end": "2111690"
  },
  {
    "text": "unstructured text either in our data Lake or in our data warehouse or you know modern data warehouse really covers both and we actually love the fact that",
    "start": "2111690",
    "end": "2118740"
  },
  {
    "text": "we can structure eyes that text to go do joins filters and sorting right so you",
    "start": "2118740",
    "end": "2124200"
  },
  {
    "text": "know when you're thinking about how to apply NLP think about how do you join or augment or make your unstructured text",
    "start": "2124200",
    "end": "2130320"
  },
  {
    "text": "analytics better by now leveraging the unstructured text and bringing it into that environment and another thing we",
    "start": "2130320",
    "end": "2137010"
  },
  {
    "text": "see which is of course a really popular use case for NLP social analytics so we have customers saying I want to know",
    "start": "2137010",
    "end": "2143220"
  },
  {
    "text": "what my customers are saying I want to know what's going on in my call center conversations we've got a really nice",
    "start": "2143220",
    "end": "2148380"
  },
  {
    "text": "solution with transcribe you should go search for that content but they want to understand you know what are people",
    "start": "2148380",
    "end": "2154110"
  },
  {
    "text": "saying on Twitter what are they saying in our forums so we see a lot of this these kinds of use cases applied in",
    "start": "2154110",
    "end": "2159300"
  },
  {
    "text": "addition to the enterprise great use cases around financial analysis you know tomorrow we'll talk about we have a big",
    "start": "2159300",
    "end": "2164910"
  },
  {
    "text": "customer and legal analytics as well one of the other slides we find that",
    "start": "2164910",
    "end": "2171500"
  },
  {
    "start": "2169000",
    "end": "2234000"
  },
  {
    "text": "helps a lot of customers start their NLP journey now and I'll pass it to you then next is really how does this how does",
    "start": "2171500",
    "end": "2177500"
  },
  {
    "text": "comprehend fit in again it's like a machine learning NLP data adapter so it",
    "start": "2177500",
    "end": "2182600"
  },
  {
    "text": "takes your unstructured text structures eyes structure gives your text structure and that allows you to go into any",
    "start": "2182600",
    "end": "2188780"
  },
  {
    "text": "analytic service you want and work with that text so you can use Kinesis to do near real-time understanding of maybe",
    "start": "2188780",
    "end": "2194810"
  },
  {
    "text": "tweets are coming in you want to know what's what's trending up or what's trending down in terms of negative or positive sentiment you can work with",
    "start": "2194810",
    "end": "2201050"
  },
  {
    "text": "elasticsearch as I said to build smarter search domains better search you could use things like redshift and Aurora",
    "start": "2201050",
    "end": "2207320"
  },
  {
    "text": "right to take that unstructured text structure eyes it and do things like sorting and of course if you if you're",
    "start": "2207320",
    "end": "2212960"
  },
  {
    "text": "on if you're if you're invested in the Hoodoo platform in the EMR you can go take the structure eyes text or comprehend and go do larger scale",
    "start": "2212960",
    "end": "2219770"
  },
  {
    "text": "analytics things in EMR as well so just think of it as sort of it sits between unstructured texts and structured",
    "start": "2219770",
    "end": "2225170"
  },
  {
    "text": "analytic services or semi structured analytic services and it's and it really removes any knowledge of machine",
    "start": "2225170",
    "end": "2230840"
  },
  {
    "text": "learning that you previously would have had to learn to do this all right so Ben why don't you go ahead and come",
    "start": "2230840",
    "end": "2236930"
  },
  {
    "text": "on up and we'll talk about thanks man thanks all right so we're actually going",
    "start": "2236930",
    "end": "2242660"
  },
  {
    "text": "to switch over to some demonstrations now and in doing so first one just set",
    "start": "2242660",
    "end": "2249680"
  },
  {
    "start": "2245000",
    "end": "2319000"
  },
  {
    "text": "the stage really quickly so we're the first thing that we're gonna show here is how you could use comprehend in",
    "start": "2249680",
    "end": "2256580"
  },
  {
    "text": "conjunction with a graph database Neptune how many folks in the room are familiar with Neptune okay pretty good",
    "start": "2256580",
    "end": "2264830"
  },
  {
    "text": "amount so Neptune is our graph database that lets you store both property graphs as well as RDF graphs it's really great",
    "start": "2264830",
    "end": "2270560"
  },
  {
    "text": "to be able to do very very rich querying over various types of languages like gremlin or sparkled and what we're going",
    "start": "2270560",
    "end": "2277970"
  },
  {
    "text": "to be showing here is we're gonna be showing how you take news article feeds so we went ahead and we grabbed RSS",
    "start": "2277970",
    "end": "2284540"
  },
  {
    "text": "feeds that we're downloading into s3 and then we're going to be processing those",
    "start": "2284540",
    "end": "2290810"
  },
  {
    "text": "using lambda and then storing those in a graph database a named entity graph and then we're gonna start squaring some of",
    "start": "2290810",
    "end": "2296930"
  },
  {
    "text": "those the second one we're gonna show is actually how to also do this with elasticsearch and enrich your",
    "start": "2296930",
    "end": "2303109"
  },
  {
    "text": "search capabilities with with semantic technologies with with really cut the",
    "start": "2303109",
    "end": "2308210"
  },
  {
    "text": "NLP capability so let's go ahead and switch over to show the demo here the",
    "start": "2308210",
    "end": "2316640"
  },
  {
    "text": "first thing I'm going to show is what this data looks like and I promise I'll",
    "start": "2316640",
    "end": "2321710"
  },
  {
    "start": "2319000",
    "end": "2327000"
  },
  {
    "text": "zoom in here as well let me double check the Wi-Fi connection really quickly so",
    "start": "2321710",
    "end": "2328099"
  },
  {
    "text": "what we're showing over here is we're gonna I'm gonna show you some of the data we're ingesting so this is news our",
    "start": "2328099",
    "end": "2335030"
  },
  {
    "text": "cold data we're using s3 select to actually look at this data and what we're doing is we're actually bringing",
    "start": "2335030",
    "end": "2340309"
  },
  {
    "text": "this into Neptune and let me make this quite a bit bigger for folks in the back",
    "start": "2340309",
    "end": "2346240"
  },
  {
    "text": "so this is just bringing in a property graph and if we take a look at this data its news articles from our blogs so",
    "start": "2346240",
    "end": "2353450"
  },
  {
    "text": "we're taking RSS feeds we're ingesting them into s3 use in s3 lambda notifications to be able to ingest them",
    "start": "2353450",
    "end": "2359270"
  },
  {
    "text": "into Neptune and if we go ahead and bring up Neptune now what we're going to",
    "start": "2359270",
    "end": "2368690"
  },
  {
    "text": "show is we're gonna show how you can start querying this this data so we're",
    "start": "2368690",
    "end": "2380150"
  },
  {
    "start": "2379000",
    "end": "2429000"
  },
  {
    "text": "gonna go over here make this bigger for everybody so I'm actually just logged in",
    "start": "2380150",
    "end": "2386390"
  },
  {
    "text": "to an instance and I'm actually gonna bring up a grandma interface this is an open source technology Apache gremlin",
    "start": "2386390",
    "end": "2393170"
  },
  {
    "text": "but since I'm running Neptune I don't have to worry about any of the match management up the graph database and",
    "start": "2393170",
    "end": "2399200"
  },
  {
    "text": "anything like that I could start doing my craze right away and what we're gonna do here is we're actually going to start",
    "start": "2399200",
    "end": "2404809"
  },
  {
    "text": "doing some some queries some graph queries against this news data that we've ingested into here so the first",
    "start": "2404809",
    "end": "2414200"
  },
  {
    "text": "query I'm going to do is I'm actually going to just query for the actually",
    "start": "2414200",
    "end": "2419240"
  },
  {
    "text": "skip to a Augen vector so this is actually going to query for the most influential entities in our system and",
    "start": "2419240",
    "end": "2426140"
  },
  {
    "text": "what you'll notice and let me make this a little bit bigger is these are all",
    "start": "2426140",
    "end": "2431630"
  },
  {
    "text": "entities that got extracted using comprehend and I can show some of the code here in a minute but you",
    "start": "2431630",
    "end": "2436940"
  },
  {
    "text": "comprehend it's just a very simple API I called detect entities and holds those entities out it posed the types of those",
    "start": "2436940",
    "end": "2443510"
  },
  {
    "text": "entities out and now we have all these different entities and you see AWS and Amazon not too surprising since this is",
    "start": "2443510",
    "end": "2450170"
  },
  {
    "text": "from blog post some of the top entities talked about the most influential entities and then you can see various",
    "start": "2450170",
    "end": "2456500"
  },
  {
    "text": "entities kind of listed here as well but what I could also do is I could actually start visualizing a lot of this data so",
    "start": "2456500",
    "end": "2465050"
  },
  {
    "start": "2464000",
    "end": "2495000"
  },
  {
    "text": "if I actually want to start looking at this graph data what I could do is I could bring up I happen to be using a",
    "start": "2465050",
    "end": "2471980"
  },
  {
    "text": "open source project to visualize this this graph but you could we have lots of partners that integrate with Neptune to",
    "start": "2471980",
    "end": "2478460"
  },
  {
    "text": "be able to visualize graph data which is being enriched all through the entity extraction here but what I could do here",
    "start": "2478460",
    "end": "2485599"
  },
  {
    "text": "is I could actually do things like search for MySQL for the name it search",
    "start": "2485599",
    "end": "2496010"
  },
  {
    "text": "so this is actually entity that got extracted from blog posts referring to",
    "start": "2496010",
    "end": "2502220"
  },
  {
    "text": "MySQL and I guess looked over here I don't know what happened to that projector over there what we can also do",
    "start": "2502220",
    "end": "2510170"
  },
  {
    "text": "here is since these are all the different types you can see you know persons events organizations those are",
    "start": "2510170",
    "end": "2516170"
  },
  {
    "text": "all the different types pulled out of entity extraction what we could do here is we could also start browsing this so",
    "start": "2516170",
    "end": "2523040"
  },
  {
    "text": "if I wanted to take a look at the different names here I could start",
    "start": "2523040",
    "end": "2528230"
  },
  {
    "text": "looking at these are all the different articles that are talking about the entity my sequel but I can start",
    "start": "2528230",
    "end": "2534920"
  },
  {
    "text": "browsing this graph and start expanding this out more and more so the other",
    "start": "2534920",
    "end": "2541099"
  },
  {
    "text": "thing that we could do here is we can also visualize this data so that the color coding on the knowledge graph of",
    "start": "2541099",
    "end": "2547280"
  },
  {
    "text": "the graph here indicates what are the different types of entities being used",
    "start": "2547280",
    "end": "2552550"
  },
  {
    "text": "in more time and feel free to ping me after this I could show how you can start doing some really really rich",
    "start": "2552550",
    "end": "2557569"
  },
  {
    "text": "querying over the graph database here so you can actually do very very complex recursion over the different nodes and",
    "start": "2557569",
    "end": "2564380"
  },
  {
    "text": "edges on this so some really really powerful to be able to query this data but in the interest of",
    "start": "2564380",
    "end": "2570910"
  },
  {
    "text": "time I do want to show the elasticsearch piece so on the elastic search piece",
    "start": "2570910",
    "end": "2578109"
  },
  {
    "start": "2576000",
    "end": "2604000"
  },
  {
    "text": "we're actually doing a little bit more in terms of extracting data so what we're going to show here is taking the",
    "start": "2578109",
    "end": "2583750"
  },
  {
    "text": "same news articles running it through comprehend and extracting not only entities but those key phrases the",
    "start": "2583750",
    "end": "2590079"
  },
  {
    "text": "sediment and also syntax so you can see some of the syntax fields of these articles coming in and we're storing",
    "start": "2590079",
    "end": "2595780"
  },
  {
    "text": "that into elasticsearch and we're gonna bring up some Cabana dashboards to be able to visualize the data so this is",
    "start": "2595780",
    "end": "2606309"
  },
  {
    "start": "2604000",
    "end": "2633000"
  },
  {
    "text": "the elastic search question that we have running and if I look over here I can",
    "start": "2606309",
    "end": "2611559"
  },
  {
    "text": "actually see under my indexes these are the are two articles that we're gonna be",
    "start": "2611559",
    "end": "2616690"
  },
  {
    "text": "showing there's forty-seven thousand something like that pretty small when it comes to cluster size that you can't",
    "start": "2616690",
    "end": "2623170"
  },
  {
    "text": "have an elastic search place not like a little ten record hello world type thing here but if we actually go ahead and go",
    "start": "2623170",
    "end": "2630730"
  },
  {
    "text": "back over here I'm gonna dive into some of the Cabana so let's bring up Cabana",
    "start": "2630730",
    "end": "2637109"
  },
  {
    "start": "2633000",
    "end": "2658000"
  },
  {
    "text": "Cabana is a nice that dashboard or a nice UI that you can put on top of last",
    "start": "2637109",
    "end": "2642279"
  },
  {
    "text": "to search to be able to query all types of information you could build visualizations you could build dashboards it's a really nice tool to be",
    "start": "2642279",
    "end": "2649359"
  },
  {
    "text": "able to start searching that textual analytics so what we're gonna do here is we can actually go over to discover and",
    "start": "2649359",
    "end": "2658589"
  },
  {
    "start": "2658000",
    "end": "2688000"
  },
  {
    "text": "in the last 15 minutes we haven't had any new post ingested but if I take a",
    "start": "2658589",
    "end": "2664329"
  },
  {
    "text": "look at year today here we can also see all the different articles flowing in",
    "start": "2664329",
    "end": "2670089"
  },
  {
    "text": "here the nice thing here is combining the leucine based indexing with the NLP",
    "start": "2670089",
    "end": "2677710"
  },
  {
    "text": "lets me do some kind of advanced querying here now so what I could do is I could go ahead and search for things",
    "start": "2677710",
    "end": "2685329"
  },
  {
    "text": "like sage maker and we see 19 of these",
    "start": "2685329",
    "end": "2691690"
  },
  {
    "start": "2688000",
    "end": "2698000"
  },
  {
    "text": "posts have to do a sage maker what we could do is we could actually take a look at this content and what we see is",
    "start": "2691690",
    "end": "2699880"
  },
  {
    "start": "2698000",
    "end": "2821000"
  },
  {
    "text": "we actually see both the raw data as well as this is this was a post from dr. Matt would hear we could also see",
    "start": "2699880",
    "end": "2707080"
  },
  {
    "text": "all the different types for these entities so the organization's the commercial items as well as various",
    "start": "2707080",
    "end": "2714550"
  },
  {
    "text": "confidence scores so here you actually see a score value the nice thing about",
    "start": "2714550",
    "end": "2719770"
  },
  {
    "text": "this here is what you could do is these are actually 19 hits that just got",
    "start": "2719770",
    "end": "2725230"
  },
  {
    "text": "returned I can start applying confidence intervals on my searches here or do",
    "start": "2725230",
    "end": "2730660"
  },
  {
    "text": "things like query boosting and other advanced creams so let's go ahead and do that next all in two minutes I promise",
    "start": "2730660",
    "end": "2740430"
  },
  {
    "text": "so what we're gonna do here is I want to show you first how you wouldn't",
    "start": "2741060",
    "end": "2750160"
  },
  {
    "text": "necessarily do this because this is a common thing I see customers try to do and it's actually not doing exactly what",
    "start": "2750160",
    "end": "2756760"
  },
  {
    "text": "they think is happening and then I'll show you the right way of doing it so what I just queried here is I actually",
    "start": "2756760",
    "end": "2762010"
  },
  {
    "text": "just queried sage maker with a confidence score greater than point 99 but what I did is since in elasticsearch",
    "start": "2762010",
    "end": "2769300"
  },
  {
    "text": "I actually have a element in here that's not nested what that means is it's actually matching any entity that has or",
    "start": "2769300",
    "end": "2775930"
  },
  {
    "text": "any documents any article that has sage maker in it and then any document that has any entity that has a point 99 it's",
    "start": "2775930",
    "end": "2783160"
  },
  {
    "text": "not keeping that correlation in this example in order to keep that correlation in elasticsearch what you",
    "start": "2783160",
    "end": "2788320"
  },
  {
    "text": "want to do is you want to create that nested element underneath and be able to query that nested element which we're",
    "start": "2788320",
    "end": "2793480"
  },
  {
    "text": "going to do next so if we actually just to show some of the query in here if we",
    "start": "2793480",
    "end": "2800080"
  },
  {
    "text": "actually go into here this is what applications would be querying and I created this just with sage maker we see",
    "start": "2800080",
    "end": "2807010"
  },
  {
    "text": "14 documents getting returned if we actually go down here and now query the",
    "start": "2807010",
    "end": "2814630"
  },
  {
    "text": "same sort of thing that we did before",
    "start": "2814630",
    "end": "2819119"
  },
  {
    "start": "2821000",
    "end": "2837000"
  },
  {
    "text": "and say within this nested elements called entities we want to keep in the",
    "start": "2822520",
    "end": "2828070"
  },
  {
    "text": "same nested fields now and search for the point 99 and sage maker if I",
    "start": "2828070",
    "end": "2833859"
  },
  {
    "text": "actually now execute this query you'll see it only actually returned the five",
    "start": "2833859",
    "end": "2839530"
  },
  {
    "text": "five documents that we're talking we're related to it so really really powerful what you want to be cognizant of is how",
    "start": "2839530",
    "end": "2847570"
  },
  {
    "text": "the reverse indexing actually collapses nested elements when you're setting this up just as a pattern but if you actually",
    "start": "2847570",
    "end": "2854350"
  },
  {
    "text": "set it up this way you can query any of these fields within within here just to",
    "start": "2854350",
    "end": "2860230"
  },
  {
    "start": "2859000",
    "end": "2871000"
  },
  {
    "text": "show another example really quickly this is a last query that we have that is",
    "start": "2860230",
    "end": "2867400"
  },
  {
    "text": "actually creating the parts of speech and in this example we're actually",
    "start": "2867400",
    "end": "2873970"
  },
  {
    "start": "2871000",
    "end": "2947000"
  },
  {
    "text": "praying for the word build where it's a verb and it's a score at point 999 so",
    "start": "2873970",
    "end": "2880420"
  },
  {
    "text": "this is actually showing some of the parts of speech capabilities I could really be querying for all types of",
    "start": "2880420",
    "end": "2886090"
  },
  {
    "text": "different things rather than just you know build is usually a verb so not not",
    "start": "2886090",
    "end": "2891160"
  },
  {
    "text": "probably the greatest example there but what you can see is you can actually see the various returned elements the",
    "start": "2891160",
    "end": "2897460"
  },
  {
    "text": "various entities and then down here you'll notice all the different parts of speech you know down here with the",
    "start": "2897460",
    "end": "2904270"
  },
  {
    "text": "various scores related to I so the punctuation is the nouns the pronouns that sort of thing so a very very quick",
    "start": "2904270",
    "end": "2912040"
  },
  {
    "text": "demos of how you start integrating some of these things together so and I think",
    "start": "2912040",
    "end": "2917530"
  },
  {
    "text": "that's a jump so yeah you know it just",
    "start": "2917530",
    "end": "2923290"
  },
  {
    "text": "it shows you that you can now approach text analytics with zero knowledge of",
    "start": "2923290",
    "end": "2928359"
  },
  {
    "text": "machine learning using comprehend we want to use a couple of these use cases if you go to our blog we link to a bunch",
    "start": "2928359",
    "end": "2934330"
  },
  {
    "text": "of formation templates that were fully deployable solutions you can go ahead and try out on your own by changing the",
    "start": "2934330",
    "end": "2939609"
  },
  {
    "text": "data source connectivity I know we got a run so we really appreciate it everybody and thanks so much for your time",
    "start": "2939609",
    "end": "2944770"
  },
  {
    "text": "appreciate it [Applause]",
    "start": "2944770",
    "end": "2949790"
  }
]
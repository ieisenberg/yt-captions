[
  {
    "text": "In this video, you’ll see how to send \nVPC flow log data to Splunk using",
    "start": "0",
    "end": "4148"
  },
  {
    "text": "Amazon Kinesis Data Firehose.",
    "start": "4148",
    "end": "6208"
  },
  {
    "text": "With this solution, you can create a Kinesis \nData Firehose delivery stream with Splunk",
    "start": "6819",
    "end": "10964"
  },
  {
    "text": "as the destination, deploy a Lambda function \nfor data transformation, and create Amazon",
    "start": "10964",
    "end": "15938"
  },
  {
    "text": "Virtual Private Cloud (Amazon VPC) \nflow logs to send data into Splunk.",
    "start": "15939",
    "end": "20559"
  },
  {
    "text": "Let’s review the architecture for sending\n AWS VPC flow log data into Splunk.",
    "start": "21664",
    "end": "26264"
  },
  {
    "text": "We have a Kinesis Data Firehose delivery",
    "start": "27194",
    "end": "29240"
  },
  {
    "text": "stream with Splunk as a destination \nvia the HTTP Event Collector (HEC).",
    "start": "29240",
    "end": "33922"
  },
  {
    "text": "The Splunk endpoint could \nbe on AWS infrastructure",
    "start": "34591",
    "end": "37378"
  },
  {
    "text": "or hosted in an on-premises data center.",
    "start": "37379",
    "end": "39611"
  },
  {
    "text": "An AWS Lambda function transforms \nVPC flow logs from their native JSON",
    "start": "40585",
    "end": "44746"
  },
  {
    "text": "to the required Splunk format.",
    "start": "44747",
    "end": "46334"
  },
  {
    "text": "Once set up, traffic in the identified \nVPC generates flow log data that is",
    "start": "46886",
    "end": "51331"
  },
  {
    "text": "sent to Kinesis Data Firehose and \ningested into the Splunk destination.",
    "start": "51331",
    "end": "55181"
  },
  {
    "text": "Please review the pre-requisites shown here.",
    "start": "56213",
    "end": "58377"
  },
  {
    "text": "For the purposes of this video, we’ve \nalready taken care of these prerequisites.",
    "start": "58784",
    "end": "62288"
  },
  {
    "text": "We’ll begin in Splunk, where we can see the \nSplunk Add-On for AWS in the left navigation.",
    "start": "67057",
    "end": "71770"
  },
  {
    "text": "Let’s go to Settings to create a \nnew HTTP Event Collector token.",
    "start": "72323",
    "end": "75882"
  },
  {
    "text": "For this we’ll go to Data inputs.",
    "start": "77075",
    "end": "78883"
  },
  {
    "text": "We’ll give our HEC a name and description.",
    "start": "81734",
    "end": "83920"
  },
  {
    "text": "We’ll also enable indexer acknowledgment.",
    "start": "87497",
    "end": "89617"
  },
  {
    "text": "This is required for Kinesis \nData Firehose destinations.",
    "start": "89865",
    "end": "93000"
  },
  {
    "text": "Next, we’ll select our input settings, \nbeginning with the source type.",
    "start": "95370",
    "end": "98439"
  },
  {
    "text": "We’ll select aws:cloudwatchlogs:vpcflow.",
    "start": "100387",
    "end": "103773"
  },
  {
    "text": "This source type was made available \nby installing the Splunk Add-on for AWS.",
    "start": "104384",
    "end": "108402"
  },
  {
    "text": "Next, we’ll select the index where \nwe want our Splunk data sent to.",
    "start": "110598",
    "end": "113612"
  },
  {
    "text": "Now we can review our settings \nand submit our HEC token.",
    "start": "116011",
    "end": "118828"
  },
  {
    "text": "Let’s note the token value, as we’ll \nneed it when we configure our Kinesis",
    "start": "120893",
    "end": "124090"
  },
  {
    "text": "Data Firehose destination settings.",
    "start": "124091",
    "end": "126235"
  },
  {
    "text": "Next, let’s go to the AWS Management \nconsole and open the AWS Lambda page.",
    "start": "128503",
    "end": "132927"
  },
  {
    "text": "We’ll create a new function.",
    "start": "134061",
    "end": "135346"
  },
  {
    "text": "We can browse the serverless app repository \nto find the Lambda application we need.",
    "start": "137425",
    "end": "141276"
  },
  {
    "text": "We’ll use this processor from Splunk \nto transform data when streaming AWS",
    "start": "145420",
    "end": "149116"
  },
  {
    "text": "VPC flow logs to Splunk \nvia Kinesis Data Firehose.",
    "start": "149116",
    "end": "152554"
  },
  {
    "text": "Let’s deploy the processor.",
    "start": "154677",
    "end": "156000"
  },
  {
    "text": "Let’s look at what we deployed.",
    "start": "159199",
    "end": "160516"
  },
  {
    "text": "The resources associated with the \nprocessor include the IAM role for the",
    "start": "162581",
    "end": "166096"
  },
  {
    "text": "Lambda function as well \nas the Lambda function itself.",
    "start": "166096",
    "end": "168719"
  },
  {
    "text": "We'll make sure to note the Physical ID \nof the Lambda function, as we will need to",
    "start": "169548",
    "end": "172889"
  },
  {
    "text": "provide it on the next step, when we create \nthe Kinesis Data Firehose delivery stream.",
    "start": "172889",
    "end": "177231"
  },
  {
    "text": "Now, let’s navigate to \nAmazon Kinesis services.",
    "start": "178380",
    "end": "180966"
  },
  {
    "text": "We’ll create a Kinesis Data \nFirehose delivery stream.",
    "start": "185502",
    "end": "188104"
  },
  {
    "text": "First, we’ll specify Direct PUT as the \nsource and Splunk as the destination.",
    "start": "190692",
    "end": "194718"
  },
  {
    "text": "Let’s provide a different \nname for the delivery stream.",
    "start": "200854",
    "end": "202935"
  },
  {
    "text": "Transforming records is optional.",
    "start": "208577",
    "end": "210194"
  },
  {
    "text": "Let’s enable data transformation and\nchoose the Lambda function we created.",
    "start": "210544",
    "end": "213923"
  },
  {
    "text": "We’ll expand our buffer size to 1 MB",
    "start": "218838",
    "end": "220912"
  },
  {
    "text": "but keep the buffer interval to the \nminimum setting of 60 seconds.",
    "start": "220912",
    "end": "224066"
  },
  {
    "text": "Under Destination settings, we’ll \nspecify our Splunk cluster endpoint.",
    "start": "224735",
    "end": "228348"
  },
  {
    "text": "For the authentication token, we’ll specify \nthe HEC token value we noted earlier.",
    "start": "230427",
    "end": "234633"
  },
  {
    "text": "Under Backup settings, we’ll choose \nan existing Amazon S3 bucket",
    "start": "237163",
    "end": "240472"
  },
  {
    "text": "where failed events can be saved.",
    "start": "240472",
    "end": "242043"
  },
  {
    "text": "Let’s create the delivery stream.",
    "start": "247394",
    "end": "249000"
  },
  {
    "text": "Next, we’ll navigate to the VPC Management \nconsole to create our VPC flow logs.",
    "start": "252126",
    "end": "256591"
  },
  {
    "text": "We’ll select VPCs to see the VPCs that\n we already have in our environment.",
    "start": "257638",
    "end": "261691"
  },
  {
    "text": "We’ll select this one.",
    "start": "262754",
    "end": "263859"
  },
  {
    "text": "Let’s create a new flow log.",
    "start": "267465",
    "end": "268951"
  },
  {
    "text": "Let’s give our flow log a name and \nleave the Filter settings to the default",
    "start": "272179",
    "end": "275300"
  },
  {
    "text": "in order to capture all traffic.",
    "start": "275300",
    "end": "276974"
  },
  {
    "text": "We’ll reduce our Maximum \naggregation interval to 1 minute.",
    "start": "279000",
    "end": "282112"
  },
  {
    "text": "Let’s change the destination where flow\n log data will be published to Kinesis",
    "start": "285165",
    "end": "288652"
  },
  {
    "text": "Firehose in the same account and then \nspecify the name of our delivery stream.",
    "start": "288652",
    "end": "292648"
  },
  {
    "text": "We’ll keep everything else as the \ndefault and create the flow log.",
    "start": "294698",
    "end": "297532"
  },
  {
    "text": "Let’s view the flow log.",
    "start": "299132",
    "end": "300422"
  },
  {
    "text": "When the flow log is \navailable, we can see it’s ID.",
    "start": "303826",
    "end": "306294"
  },
  {
    "text": "Now let’s go to Splunk and open \nSearch & Reporting, where we can",
    "start": "309000",
    "end": "312094"
  },
  {
    "text": "verify that our integration is working.",
    "start": "312094",
    "end": "313955"
  },
  {
    "text": "We’ll search for the index that we \nspecified in our HEC input settings.",
    "start": "315220",
    "end": "318805"
  },
  {
    "text": "We’ll also choose to show data \nfrom the last 15 minutes only.",
    "start": "319227",
    "end": "322349"
  },
  {
    "text": "Data is already coming into Splunk.",
    "start": "324806",
    "end": "326628"
  },
  {
    "text": "We can select the sourcetype field to confirm \nthat VPC flow logs are the source of our data.",
    "start": "327311",
    "end": "331795"
  },
  {
    "text": "The integration has been successful.",
    "start": "333000",
    "end": "334687"
  },
  {
    "text": "You’ve seen how to send VPC flow log data \nto Splunk using Amazon Kinesis Data Firehose.",
    "start": "337449",
    "end": "342477"
  },
  {
    "text": "You can learn more about this topic in \nthe description and links for this video.",
    "start": "343800",
    "end": "347018"
  },
  {
    "text": "Thanks for watching. Now it’s your turn to try.",
    "start": "347179",
    "end": "349439"
  }
]
[
  {
    "text": "hi my name is Emily Weber I'm a machine",
    "start": "30",
    "end": "2790"
  },
  {
    "text": "learning specialist at Amazon Web",
    "start": "2790",
    "end": "4350"
  },
  {
    "text": "Services and today we're going to learn",
    "start": "4350",
    "end": "5970"
  },
  {
    "text": "about batch transform this is your deep",
    "start": "5970",
    "end": "8670"
  },
  {
    "text": "dive",
    "start": "8670",
    "end": "10880"
  },
  {
    "text": "so first someone says to you you know",
    "start": "11759",
    "end": "14490"
  },
  {
    "text": "endpoints are really easy to spin up",
    "start": "14490",
    "end": "16860"
  },
  {
    "text": "right that's just a single line of code",
    "start": "16860",
    "end": "18270"
  },
  {
    "text": "you're right it it's up there but what",
    "start": "18270",
    "end": "20789"
  },
  {
    "text": "if I need something to serve predictions",
    "start": "20789",
    "end": "22619"
  },
  {
    "text": "on a schedule what's your architect",
    "start": "22619",
    "end": "24900"
  },
  {
    "text": "gonna say batch transform so a very",
    "start": "24900",
    "end": "29070"
  },
  {
    "text": "common design pattern with batch",
    "start": "29070",
    "end": "31019"
  },
  {
    "text": "transform is gonna look like the",
    "start": "31019",
    "end": "32910"
  },
  {
    "text": "following you'll start with some event",
    "start": "32910",
    "end": "35460"
  },
  {
    "text": "trigger right and that event trigger can",
    "start": "35460",
    "end": "37620"
  },
  {
    "text": "be something gets uploaded to an s3",
    "start": "37620",
    "end": "39870"
  },
  {
    "text": "bucket or it can be a cron job which",
    "start": "39870",
    "end": "42449"
  },
  {
    "text": "tells you the time of day right so if",
    "start": "42449",
    "end": "44610"
  },
  {
    "text": "you want this to run every week if you",
    "start": "44610",
    "end": "46680"
  },
  {
    "text": "want this to run every day at certain",
    "start": "46680",
    "end": "48300"
  },
  {
    "text": "times of the day all that you can",
    "start": "48300",
    "end": "50190"
  },
  {
    "text": "specify with your cron job that's gonna",
    "start": "50190",
    "end": "52199"
  },
  {
    "text": "start a lambda function right and the",
    "start": "52199",
    "end": "55020"
  },
  {
    "text": "lambda function is gonna let you execute",
    "start": "55020",
    "end": "56640"
  },
  {
    "text": "your code right as long as they're",
    "start": "56640",
    "end": "57930"
  },
  {
    "text": "sitting in the lambda parameters you're",
    "start": "57930",
    "end": "59850"
  },
  {
    "text": "gonna get to run that code and that is",
    "start": "59850",
    "end": "61289"
  },
  {
    "text": "our that is our service architecture and",
    "start": "61289",
    "end": "63090"
  },
  {
    "text": "that is going to kick off an s3 bucket",
    "start": "63090",
    "end": "66000"
  },
  {
    "text": "well it's going to connect to the s3",
    "start": "66000",
    "end": "68520"
  },
  {
    "text": "bucket right and that's where your data",
    "start": "68520",
    "end": "69869"
  },
  {
    "text": "is gonna live after that of your s3",
    "start": "69869",
    "end": "73200"
  },
  {
    "text": "bucket is gonna connect to Amazon sage",
    "start": "73200",
    "end": "76020"
  },
  {
    "text": "maker which will start off the batch",
    "start": "76020",
    "end": "78030"
  },
  {
    "text": "transform job that turns on new ec2",
    "start": "78030",
    "end": "80910"
  },
  {
    "text": "instances right and those ec2 instances",
    "start": "80910",
    "end": "83310"
  },
  {
    "text": "against inflow that's coming out of the",
    "start": "83310",
    "end": "85349"
  },
  {
    "text": "elastic container registry the image for",
    "start": "85349",
    "end": "87209"
  },
  {
    "text": "those that process is gonna run and then",
    "start": "87209",
    "end": "90810"
  },
  {
    "text": "the data goes back to s3 write the",
    "start": "90810",
    "end": "93330"
  },
  {
    "text": "inference results go back to s3 and then",
    "start": "93330",
    "end": "96270"
  },
  {
    "text": "the entire process comes back down on",
    "start": "96270",
    "end": "98550"
  },
  {
    "text": "completion and so essentially you'll",
    "start": "98550",
    "end": "101069"
  },
  {
    "text": "have your model your trained model that",
    "start": "101069",
    "end": "104310"
  },
  {
    "text": "the image is living in in ECR and has",
    "start": "104310",
    "end": "107550"
  },
  {
    "text": "been registered in Amazon Sage Maker and",
    "start": "107550",
    "end": "109619"
  },
  {
    "text": "then the process will spin up and you",
    "start": "109619",
    "end": "111420"
  },
  {
    "text": "can run inference on that data set so",
    "start": "111420",
    "end": "113819"
  },
  {
    "text": "you can run predictions on that data set",
    "start": "113819",
    "end": "115619"
  },
  {
    "text": "and send those predictions back to s3",
    "start": "115619",
    "end": "117660"
  },
  {
    "text": "and so how to make it happen right first",
    "start": "117660",
    "end": "121080"
  },
  {
    "text": "step is just getting your data in an s3",
    "start": "121080",
    "end": "122819"
  },
  {
    "text": "bucket and write that that's just a",
    "start": "122819",
    "end": "124050"
  },
  {
    "text": "requirement so we'll want to load that",
    "start": "124050",
    "end": "125759"
  },
  {
    "text": "data into an s3 bucket to initiate the",
    "start": "125759",
    "end": "128970"
  },
  {
    "text": "batch transform job the second step is",
    "start": "128970",
    "end": "132209"
  },
  {
    "text": "getting our code into a docker container",
    "start": "132209",
    "end": "135599"
  },
  {
    "text": "right and so if we're using a built in",
    "start": "135599",
    "end": "137940"
  },
  {
    "text": "algorithm well we don't have to worry",
    "start": "137940",
    "end": "139890"
  },
  {
    "text": "about this but if we're using some of",
    "start": "139890",
    "end": "141239"
  },
  {
    "text": "the other algorithms that are out there",
    "start": "141239",
    "end": "143129"
  },
  {
    "text": "you know that people enjoy writing",
    "start": "143129",
    "end": "145290"
  },
  {
    "text": "we're gonna want to get that into a",
    "start": "145290",
    "end": "146849"
  },
  {
    "text": "docker container so the way that works",
    "start": "146849",
    "end": "148409"
  },
  {
    "text": "is you'll take your script and you'll",
    "start": "148409",
    "end": "151260"
  },
  {
    "text": "take your s3 location I'll point to both",
    "start": "151260",
    "end": "154409"
  },
  {
    "text": "of those in your docker file and then",
    "start": "154409",
    "end": "156420"
  },
  {
    "text": "register that docker file on ECR you can",
    "start": "156420",
    "end": "159780"
  },
  {
    "text": "also avoid docker when you're utilizing",
    "start": "159780",
    "end": "161220"
  },
  {
    "text": "script mode which we learn about in a",
    "start": "161220",
    "end": "163140"
  },
  {
    "text": "later video and then the last thing you",
    "start": "163140",
    "end": "165810"
  },
  {
    "text": "want to do is just execute that call",
    "start": "165810",
    "end": "167489"
  },
  {
    "text": "right it's just call the job to actually",
    "start": "167489",
    "end": "169980"
  },
  {
    "text": "come on line and so most commonly",
    "start": "169980",
    "end": "171709"
  },
  {
    "text": "customers will do this from the notebook",
    "start": "171709",
    "end": "173819"
  },
  {
    "text": "instance right you'll actually be",
    "start": "173819",
    "end": "175140"
  },
  {
    "text": "developing on your notebook instance you",
    "start": "175140",
    "end": "176730"
  },
  {
    "text": "be configuring all the content for",
    "start": "176730",
    "end": "178920"
  },
  {
    "text": "running your job you'll point to a",
    "start": "178920",
    "end": "180569"
  },
  {
    "text": "transformer and the newest a transformer",
    "start": "180569",
    "end": "182579"
  },
  {
    "text": "dot transform right and then that spins",
    "start": "182579",
    "end": "184650"
  },
  {
    "text": "up that new ec2 instance that's gonna",
    "start": "184650",
    "end": "186510"
  },
  {
    "text": "run inference over your data set and",
    "start": "186510",
    "end": "188040"
  },
  {
    "text": "shoot it back to s3 another common way",
    "start": "188040",
    "end": "190680"
  },
  {
    "text": "of making this happen is in a lambda",
    "start": "190680",
    "end": "192540"
  },
  {
    "text": "function right you just want to point to",
    "start": "192540",
    "end": "194579"
  },
  {
    "text": "your transformer from within that lambda",
    "start": "194579",
    "end": "196620"
  },
  {
    "text": "function and then call transformer dot",
    "start": "196620",
    "end": "198720"
  },
  {
    "text": "transform and then it's nice because",
    "start": "198720",
    "end": "199890"
  },
  {
    "text": "that lambda function is totally done",
    "start": "199890",
    "end": "201599"
  },
  {
    "text": "right there's no dependency between the",
    "start": "201599",
    "end": "204390"
  },
  {
    "text": "batch transform job that's running on",
    "start": "204390",
    "end": "206370"
  },
  {
    "text": "ec2 and that lambda function they're",
    "start": "206370",
    "end": "208019"
  },
  {
    "text": "actually decoupled and so you can run",
    "start": "208019",
    "end": "210269"
  },
  {
    "text": "that batch transform process having",
    "start": "210269",
    "end": "212099"
  },
  {
    "text": "executed and then finished that lambda",
    "start": "212099",
    "end": "214500"
  },
  {
    "text": "function and so just remember this is a",
    "start": "214500",
    "end": "217799"
  },
  {
    "text": "RESTful API response so as as we learned",
    "start": "217799",
    "end": "221280"
  },
  {
    "text": "it in some previous videos the sage",
    "start": "221280",
    "end": "223200"
  },
  {
    "text": "maker endpoints are restful api s and",
    "start": "223200",
    "end": "225810"
  },
  {
    "text": "that's actually gonna be the same with",
    "start": "225810",
    "end": "227549"
  },
  {
    "text": "your sage maker batch transform jobs i'm",
    "start": "227549",
    "end": "230370"
  },
  {
    "text": "so first off you want to be thinking",
    "start": "230370",
    "end": "231989"
  },
  {
    "text": "json right you're gonna be sending json",
    "start": "231989",
    "end": "234389"
  },
  {
    "text": "objects to that endpoint or to that",
    "start": "234389",
    "end": "237209"
  },
  {
    "text": "batch transformer and then are gonna get",
    "start": "237209",
    "end": "239190"
  },
  {
    "text": "a json response back from that you also",
    "start": "239190",
    "end": "241560"
  },
  {
    "text": "want to be careful about your payload",
    "start": "241560",
    "end": "243209"
  },
  {
    "text": "size frequently having smaller payload",
    "start": "243209",
    "end": "246239"
  },
  {
    "text": "sizes on average works out and we'll",
    "start": "246239",
    "end": "248400"
  },
  {
    "text": "talk through some common design patterns",
    "start": "248400",
    "end": "249959"
  },
  {
    "text": "to make that happen",
    "start": "249959",
    "end": "250829"
  },
  {
    "text": "number three is actually thinking about",
    "start": "250829",
    "end": "253560"
  },
  {
    "text": "data that we're gonna store in that",
    "start": "253560",
    "end": "255329"
  },
  {
    "text": "image my data I mean lines of code right",
    "start": "255329",
    "end": "258150"
  },
  {
    "text": "let's let's talk through that okay so",
    "start": "258150",
    "end": "260849"
  },
  {
    "text": "we've got our docker file right and",
    "start": "260849",
    "end": "262410"
  },
  {
    "text": "again that's either a literal docker",
    "start": "262410",
    "end": "264360"
  },
  {
    "text": "file that we're bringing ourselves and",
    "start": "264360",
    "end": "266310"
  },
  {
    "text": "writing from scratch or that's a script",
    "start": "266310",
    "end": "268590"
  },
  {
    "text": "mode docker file that we're basically",
    "start": "268590",
    "end": "269820"
  },
  {
    "text": "using for the manage containers but so",
    "start": "269820",
    "end": "272550"
  },
  {
    "text": "we've got a docker file and we're gonna",
    "start": "272550",
    "end": "273990"
  },
  {
    "text": "put a script inside of that docker file",
    "start": "273990",
    "end": "276930"
  },
  {
    "text": "on that screen",
    "start": "276930",
    "end": "277650"
  },
  {
    "text": "is going to be doing one of two things",
    "start": "277650",
    "end": "279600"
  },
  {
    "text": "it's either gonna be doing ETL so it's",
    "start": "279600",
    "end": "282780"
  },
  {
    "text": "actually gonna be doing data",
    "start": "282780",
    "end": "283979"
  },
  {
    "text": "transformation or it's going to be",
    "start": "283979",
    "end": "286740"
  },
  {
    "text": "running inference so it's gonna take a",
    "start": "286740",
    "end": "288389"
  },
  {
    "text": "trained model and then run inference",
    "start": "288389",
    "end": "290610"
  },
  {
    "text": "with that model and both of those you",
    "start": "290610",
    "end": "292620"
  },
  {
    "text": "can do in batch transform and so a",
    "start": "292620",
    "end": "294840"
  },
  {
    "text": "couple things your Python script could",
    "start": "294840",
    "end": "296699"
  },
  {
    "text": "have you might want to have it include a",
    "start": "296699",
    "end": "299310"
  },
  {
    "text": "file header right so when that new CSV",
    "start": "299310",
    "end": "301919"
  },
  {
    "text": "comes in and you want to want to",
    "start": "301919",
    "end": "302940"
  },
  {
    "text": "transformation on it you'll want to",
    "start": "302940",
    "end": "305040"
  },
  {
    "text": "include the file header in that CSV",
    "start": "305040",
    "end": "307130"
  },
  {
    "text": "you'll also potentially want to include",
    "start": "307130",
    "end": "309680"
  },
  {
    "text": "your fitted transformations what I mean",
    "start": "309680",
    "end": "313050"
  },
  {
    "text": "by this is let's say you are using batch",
    "start": "313050",
    "end": "315900"
  },
  {
    "text": "transform to clean your data and not",
    "start": "315900",
    "end": "318990"
  },
  {
    "text": "just to clean your data while you're",
    "start": "318990",
    "end": "320430"
  },
  {
    "text": "developing but to clean your data while",
    "start": "320430",
    "end": "322740"
  },
  {
    "text": "you're running in production right",
    "start": "322740",
    "end": "324120"
  },
  {
    "text": "because you can actually utilize batch",
    "start": "324120",
    "end": "326220"
  },
  {
    "text": "transform as a production scenario so it",
    "start": "326220",
    "end": "329400"
  },
  {
    "text": "can actually transform some of your data",
    "start": "329400",
    "end": "331280"
  },
  {
    "text": "on on a schedule right and so if you're",
    "start": "331280",
    "end": "334710"
  },
  {
    "text": "doing that you're gonna want to include",
    "start": "334710",
    "end": "337229"
  },
  {
    "text": "some data from your training set and",
    "start": "337229",
    "end": "339389"
  },
  {
    "text": "this is where I think in the data",
    "start": "339389",
    "end": "340800"
  },
  {
    "text": "science community we could up our game a",
    "start": "340800",
    "end": "342360"
  },
  {
    "text": "little bit because when we're getting",
    "start": "342360",
    "end": "344880"
  },
  {
    "text": "averages and we're getting standard",
    "start": "344880",
    "end": "346680"
  },
  {
    "text": "deviations and everything that we're",
    "start": "346680",
    "end": "347940"
  },
  {
    "text": "learning from our training data set we",
    "start": "347940",
    "end": "350039"
  },
  {
    "text": "actually want to carry those over into",
    "start": "350039",
    "end": "351960"
  },
  {
    "text": "our production side right when we're",
    "start": "351960",
    "end": "353940"
  },
  {
    "text": "taking a batch data set and we need to",
    "start": "353940",
    "end": "356430"
  },
  {
    "text": "run inference on that it's not gonna be",
    "start": "356430",
    "end": "358740"
  },
  {
    "text": "sufficient to use the batch transform",
    "start": "358740",
    "end": "361800"
  },
  {
    "text": "mean and standard deviation on that new",
    "start": "361800",
    "end": "363930"
  },
  {
    "text": "data set that's coming and we actually",
    "start": "363930",
    "end": "365370"
  },
  {
    "text": "want to use it from that previous data",
    "start": "365370",
    "end": "367620"
  },
  {
    "text": "set because that's what the model is",
    "start": "367620",
    "end": "369060"
  },
  {
    "text": "actually turning on and then lastly you",
    "start": "369060",
    "end": "371099"
  },
  {
    "text": "can also have your ETL code and so",
    "start": "371099",
    "end": "373770"
  },
  {
    "text": "you're typically going to point to your",
    "start": "373770",
    "end": "375330"
  },
  {
    "text": "ETL code in some type of git integration",
    "start": "375330",
    "end": "378720"
  },
  {
    "text": "right if that's a git repository",
    "start": "378720",
    "end": "380520"
  },
  {
    "text": "solution that you're gonna have",
    "start": "380520",
    "end": "382340"
  },
  {
    "text": "unfortunately we have some capabilities",
    "start": "382340",
    "end": "384780"
  },
  {
    "text": "whereby you can connect to a git",
    "start": "384780",
    "end": "387030"
  },
  {
    "text": "repository and then run code on that git",
    "start": "387030",
    "end": "389490"
  },
  {
    "text": "repository without actually having",
    "start": "389490",
    "end": "391229"
  },
  {
    "text": "copied it over to your notebook instance",
    "start": "391229",
    "end": "393360"
  },
  {
    "text": "which is pretty nice so some other key",
    "start": "393360",
    "end": "396030"
  },
  {
    "text": "points right you'll get your estimator",
    "start": "396030",
    "end": "398099"
  },
  {
    "text": "for your model in this case a PCA and",
    "start": "398099",
    "end": "400710"
  },
  {
    "text": "then once you've got that estimator",
    "start": "400710",
    "end": "402539"
  },
  {
    "text": "you're just gonna say PCA dot transform",
    "start": "402539",
    "end": "404639"
  },
  {
    "text": "write the methods already there and then",
    "start": "404639",
    "end": "407130"
  },
  {
    "text": "same flow you'll set up your ec2",
    "start": "407130",
    "end": "409110"
  },
  {
    "text": "instance utilization so in this case",
    "start": "409110",
    "end": "410940"
  },
  {
    "text": "one m4 for Excel but then you'll have a",
    "start": "410940",
    "end": "414060"
  },
  {
    "text": "couple of the things too so here the",
    "start": "414060",
    "end": "416730"
  },
  {
    "text": "strategy is multi-record that we're",
    "start": "416730",
    "end": "418890"
  },
  {
    "text": "specifying and so that's either single",
    "start": "418890",
    "end": "420540"
  },
  {
    "text": "or multiple records per call there's",
    "start": "420540",
    "end": "423510"
  },
  {
    "text": "also an assembler for the output of this",
    "start": "423510",
    "end": "425850"
  },
  {
    "text": "so in this case it's assembled with line",
    "start": "425850",
    "end": "427530"
  },
  {
    "text": "and so that's again single or multiple",
    "start": "427530",
    "end": "429510"
  },
  {
    "text": "output config and lastly we want to",
    "start": "429510",
    "end": "433140"
  },
  {
    "text": "understand why streaming is your friend",
    "start": "433140",
    "end": "435630"
  },
  {
    "text": "right because you think about data",
    "start": "435630",
    "end": "437250"
  },
  {
    "text": "that's hitting your model right and so",
    "start": "437250",
    "end": "438960"
  },
  {
    "text": "either that data is gonna be hitting",
    "start": "438960",
    "end": "440550"
  },
  {
    "text": "your model all at one time",
    "start": "440550",
    "end": "442350"
  },
  {
    "text": "or you're gonna stream it out and here I",
    "start": "442350",
    "end": "444360"
  },
  {
    "text": "want to help you understand why",
    "start": "444360",
    "end": "445380"
  },
  {
    "text": "streaming can actually make your life",
    "start": "445380",
    "end": "446730"
  },
  {
    "text": "easier so first off you can train your",
    "start": "446730",
    "end": "449910"
  },
  {
    "text": "models faster when you're streaming your",
    "start": "449910",
    "end": "452280"
  },
  {
    "text": "data second is you can run inferencing",
    "start": "452280",
    "end": "454980"
  },
  {
    "text": "faster when you're streaming and lastly",
    "start": "454980",
    "end": "457860"
  },
  {
    "text": "is again you're gonna use that smaller",
    "start": "457860",
    "end": "459390"
  },
  {
    "text": "payload size so everything just works a",
    "start": "459390",
    "end": "461430"
  },
  {
    "text": "little bit easier you're just gonna get",
    "start": "461430",
    "end": "462780"
  },
  {
    "text": "responses faster when you have a smaller",
    "start": "462780",
    "end": "465090"
  },
  {
    "text": "payload size and so streaming and staged",
    "start": "465090",
    "end": "468180"
  },
  {
    "text": "make are a couple ways we're gonna make",
    "start": "468180",
    "end": "469380"
  },
  {
    "text": "this happen you're gonna need a manifest",
    "start": "469380",
    "end": "471870"
  },
  {
    "text": "file right so that manifest file is",
    "start": "471870",
    "end": "474000"
  },
  {
    "text": "typically a big long line of JSON",
    "start": "474000",
    "end": "475800"
  },
  {
    "text": "objects and so that is going to live in",
    "start": "475800",
    "end": "479850"
  },
  {
    "text": "s3 you're gonna point to that after that",
    "start": "479850",
    "end": "482130"
  },
  {
    "text": "you're gonna set up pipe mode right and",
    "start": "482130",
    "end": "484380"
  },
  {
    "text": "so pipe mode is actually setting up a",
    "start": "484380",
    "end": "486900"
  },
  {
    "text": "FIFO queue from your s3 bucket to that",
    "start": "486900",
    "end": "490260"
  },
  {
    "text": "cluster and so it's gonna be streaming",
    "start": "490260",
    "end": "492090"
  },
  {
    "text": "your data from your s3 bucket to that",
    "start": "492090",
    "end": "495120"
  },
  {
    "text": "cluster and the last thing you want to",
    "start": "495120",
    "end": "496680"
  },
  {
    "text": "know about is record IO record IO is a",
    "start": "496680",
    "end": "498840"
  },
  {
    "text": "data format that you will see and lots",
    "start": "498840",
    "end": "501330"
  },
  {
    "text": "of places in Sage Maker and many places",
    "start": "501330",
    "end": "503010"
  },
  {
    "text": "in MX and that essentially it's gonna",
    "start": "503010",
    "end": "505440"
  },
  {
    "text": "take your data and then make it really",
    "start": "505440",
    "end": "508230"
  },
  {
    "text": "nice to work with reads and writes on so",
    "start": "508230",
    "end": "510510"
  },
  {
    "text": "it's gonna be highly optimized for model",
    "start": "510510",
    "end": "512219"
  },
  {
    "text": "training alright let's go into an",
    "start": "512219",
    "end": "514800"
  },
  {
    "text": "example ok so here we go we are on a",
    "start": "514800",
    "end": "519150"
  },
  {
    "text": "notebook instance right you'll notice",
    "start": "519150",
    "end": "521130"
  },
  {
    "text": "from the the URL up here where you're on",
    "start": "521130",
    "end": "523140"
  },
  {
    "text": "a stage maker on notebook instance in US",
    "start": "523140",
    "end": "525990"
  },
  {
    "text": "East one this is called test emic test",
    "start": "525990",
    "end": "528480"
  },
  {
    "text": "erson and let's let's check this out",
    "start": "528480",
    "end": "530670"
  },
  {
    "text": "here so this is a bunch of code that's",
    "start": "530670",
    "end": "533580"
  },
  {
    "text": "available online you can get this from a",
    "start": "533580",
    "end": "535950"
  },
  {
    "text": "git repository called architecting 4ml",
    "start": "535950",
    "end": "538290"
  },
  {
    "text": "on amazon sage maker and essentially",
    "start": "538290",
    "end": "540570"
  },
  {
    "text": "we're gonna walk through this so first",
    "start": "540570",
    "end": "542430"
  },
  {
    "text": "off this notebook instance",
    "start": "542430",
    "end": "544660"
  },
  {
    "text": "is going to let us run a large number of",
    "start": "544660",
    "end": "548579"
  },
  {
    "text": "tuning jobs in parallel against each of",
    "start": "548579",
    "end": "552100"
  },
  {
    "text": "our models right so we're gonna run a",
    "start": "552100",
    "end": "553930"
  },
  {
    "text": "hyper parameter tuner on actually boost",
    "start": "553930",
    "end": "555879"
  },
  {
    "text": "and then linear learner then k and n",
    "start": "555879",
    "end": "558639"
  },
  {
    "text": "then factorization machines right and",
    "start": "558639",
    "end": "560620"
  },
  {
    "text": "all of those can be formatted to work in",
    "start": "560620",
    "end": "563170"
  },
  {
    "text": "in binary classification will copy our",
    "start": "563170",
    "end": "565569"
  },
  {
    "text": "data over to s3 right and then what's",
    "start": "565569",
    "end": "568060"
  },
  {
    "text": "kind of cool is that this process is",
    "start": "568060",
    "end": "569829"
  },
  {
    "text": "actually gonna run in parallel right",
    "start": "569829",
    "end": "571750"
  },
  {
    "text": "where it's gonna run the single training",
    "start": "571750",
    "end": "573189"
  },
  {
    "text": "job will call ku tuner dot fit but then",
    "start": "573189",
    "end": "576040"
  },
  {
    "text": "we're actually gonna map that out over",
    "start": "576040",
    "end": "577569"
  },
  {
    "text": "all of the models that we want to run so",
    "start": "577569",
    "end": "581110"
  },
  {
    "text": "down here you can specify the models",
    "start": "581110",
    "end": "583089"
  },
  {
    "text": "that you want to run and then actually",
    "start": "583089",
    "end": "585220"
  },
  {
    "text": "set up this magic loop to run all of",
    "start": "585220",
    "end": "587170"
  },
  {
    "text": "those concurrently which is pretty cool",
    "start": "587170",
    "end": "588839"
  },
  {
    "text": "after that we're gonna use sage maker",
    "start": "588839",
    "end": "591819"
  },
  {
    "text": "search to find the best performing model",
    "start": "591819",
    "end": "593709"
  },
  {
    "text": "so here's that sage maker search right",
    "start": "593709",
    "end": "596230"
  },
  {
    "text": "input data config contains our buckets",
    "start": "596230",
    "end": "599319"
  },
  {
    "text": "all right the name of our bucket",
    "start": "599319",
    "end": "601149"
  },
  {
    "text": "training job has completed and we'll",
    "start": "601149",
    "end": "603550"
  },
  {
    "text": "look at the validation and you see",
    "start": "603550",
    "end": "604839"
  },
  {
    "text": "that's descending after that we're gonna",
    "start": "604839",
    "end": "606970"
  },
  {
    "text": "want to convert those into models right",
    "start": "606970",
    "end": "609399"
  },
  {
    "text": "we need to actually get the formal sage",
    "start": "609399",
    "end": "611980"
  },
  {
    "text": "maker model so that we can call",
    "start": "611980",
    "end": "614170"
  },
  {
    "text": "transformer from that model and so this",
    "start": "614170",
    "end": "617170"
  },
  {
    "text": "is one way of doing that right and this",
    "start": "617170",
    "end": "619630"
  },
  {
    "text": "one way of doing that basically we need",
    "start": "619630",
    "end": "621490"
  },
  {
    "text": "the image so we need oh yeah yeah we",
    "start": "621490",
    "end": "625120"
  },
  {
    "text": "need the image alright that's over here",
    "start": "625120",
    "end": "627220"
  },
  {
    "text": "and that's the code for the algorithm we",
    "start": "627220",
    "end": "629170"
  },
  {
    "text": "need the model artifact so what the",
    "start": "629170",
    "end": "632110"
  },
  {
    "text": "model learned during that training",
    "start": "632110",
    "end": "634420"
  },
  {
    "text": "process right and how it's actually back",
    "start": "634420",
    "end": "635920"
  },
  {
    "text": "in s3 we need our sage maker session and",
    "start": "635920",
    "end": "638589"
  },
  {
    "text": "we just want to name it in this case I",
    "start": "638589",
    "end": "640509"
  },
  {
    "text": "just named it with a job name great and",
    "start": "640509",
    "end": "642220"
  },
  {
    "text": "so that's say a formal sage maker model",
    "start": "642220",
    "end": "644380"
  },
  {
    "text": "right so once we've got the model we can",
    "start": "644380",
    "end": "647800"
  },
  {
    "text": "run batch transform on that model right",
    "start": "647800",
    "end": "650470"
  },
  {
    "text": "and this part is super easy because",
    "start": "650470",
    "end": "653649"
  },
  {
    "text": "everything is all set up so I'm gonna",
    "start": "653649",
    "end": "655600"
  },
  {
    "text": "loop through my models right and in that",
    "start": "655600",
    "end": "658089"
  },
  {
    "text": "case right I just collected the top 15",
    "start": "658089",
    "end": "660329"
  },
  {
    "text": "models so the first 15 models and so I'm",
    "start": "660329",
    "end": "662889"
  },
  {
    "text": "gonna loop through those guys for each",
    "start": "662889",
    "end": "664930"
  },
  {
    "text": "one of them I'm calling a separate batch",
    "start": "664930",
    "end": "667329"
  },
  {
    "text": "transform shop and again no",
    "start": "667329",
    "end": "668939"
  },
  {
    "text": "interdependencies here right these are",
    "start": "668939",
    "end": "670540"
  },
  {
    "text": "decoupled these are decoupled processes",
    "start": "670540",
    "end": "673449"
  },
  {
    "text": "and so for each of my 15 models I'm",
    "start": "673449",
    "end": "676120"
  },
  {
    "text": "gonna have a set",
    "start": "676120",
    "end": "677379"
  },
  {
    "text": "m4x large that's coming up online right",
    "start": "677379",
    "end": "680179"
  },
  {
    "text": "so we have 15 m4 excels that are all",
    "start": "680179",
    "end": "683029"
  },
  {
    "text": "coming up online they're all collecting",
    "start": "683029",
    "end": "685309"
  },
  {
    "text": "my test data",
    "start": "685309",
    "end": "686269"
  },
  {
    "text": "they're running inference on my test",
    "start": "686269",
    "end": "688279"
  },
  {
    "text": "data and they're writing it into this",
    "start": "688279",
    "end": "690350"
  },
  {
    "text": "directory in s3 that's called batch",
    "start": "690350",
    "end": "693230"
  },
  {
    "text": "results all right and so that's using my",
    "start": "693230",
    "end": "695990"
  },
  {
    "text": "models to run inference after that I'm",
    "start": "695990",
    "end": "700970"
  },
  {
    "text": "gonna copy that directory from s3 to my",
    "start": "700970",
    "end": "705980"
  },
  {
    "text": "notebook instance right so that's that",
    "start": "705980",
    "end": "707240"
  },
  {
    "text": "batch results folder right over here now",
    "start": "707240",
    "end": "711800"
  },
  {
    "text": "I'm gonna loop through those 15",
    "start": "711800",
    "end": "715730"
  },
  {
    "text": "inference response responses I'm gonna",
    "start": "715730",
    "end": "718309"
  },
  {
    "text": "consolidate all of them and I'm gonna",
    "start": "718309",
    "end": "720920"
  },
  {
    "text": "compare them and that's gonna let us",
    "start": "720920",
    "end": "722540"
  },
  {
    "text": "actually do some ensemble approvers alts",
    "start": "722540",
    "end": "727939"
  },
  {
    "text": "the the results from the batch transform",
    "start": "727939",
    "end": "731059"
  },
  {
    "text": "job are actually gonna come in two in",
    "start": "731059",
    "end": "732649"
  },
  {
    "text": "this dot out format so I just copied it",
    "start": "732649",
    "end": "735110"
  },
  {
    "text": "over to say just dot CSV instead of that",
    "start": "735110",
    "end": "737269"
  },
  {
    "text": "out there we go so that's a copy then",
    "start": "737269",
    "end": "741110"
  },
  {
    "text": "I'm turning that into its own data frame",
    "start": "741110",
    "end": "743540"
  },
  {
    "text": "right and then we'll just concatenate",
    "start": "743540",
    "end": "745040"
  },
  {
    "text": "ooh frames and then this function",
    "start": "745040",
    "end": "748990"
  },
  {
    "text": "basically is gonna let us consolidate",
    "start": "748990",
    "end": "751279"
  },
  {
    "text": "those results and so for each new point",
    "start": "751279",
    "end": "754939"
  },
  {
    "text": "of data that we're shooting up to those",
    "start": "754939",
    "end": "757129"
  },
  {
    "text": "15 separate batch transform clusters",
    "start": "757129",
    "end": "760519"
  },
  {
    "text": "that are running those are all unique",
    "start": "760519",
    "end": "762980"
  },
  {
    "text": "predictions for that one single point",
    "start": "762980",
    "end": "764929"
  },
  {
    "text": "and so for each row in my test data set",
    "start": "764929",
    "end": "767600"
  },
  {
    "text": "I'm gonna have 15 models right so think",
    "start": "767600",
    "end": "770540"
  },
  {
    "text": "spreadsheet with me right each row is",
    "start": "770540",
    "end": "772519"
  },
  {
    "text": "gonna be a point of data that we want to",
    "start": "772519",
    "end": "776540"
  },
  {
    "text": "classify and then each column is a",
    "start": "776540",
    "end": "778610"
  },
  {
    "text": "different models response and so after",
    "start": "778610",
    "end": "781999"
  },
  {
    "text": "that we just want to add the labels to",
    "start": "781999",
    "end": "784309"
  },
  {
    "text": "our consolidated data frame that happens",
    "start": "784309",
    "end": "786769"
  },
  {
    "text": "down here and then check this out right",
    "start": "786769",
    "end": "788509"
  },
  {
    "text": "so these are the index spaces for all of",
    "start": "788509",
    "end": "790790"
  },
  {
    "text": "the data and then these are the",
    "start": "790790",
    "end": "792529"
  },
  {
    "text": "different versions of actually boost",
    "start": "792529",
    "end": "794589"
  },
  {
    "text": "that we want to run and these are the",
    "start": "794589",
    "end": "797749"
  },
  {
    "text": "remodel responses from all those",
    "start": "797749",
    "end": "799399"
  },
  {
    "text": "different versions of extra boost and",
    "start": "799399",
    "end": "801139"
  },
  {
    "text": "then here's one column that's the max",
    "start": "801139",
    "end": "803179"
  },
  {
    "text": "right the men the difference between",
    "start": "803179",
    "end": "805220"
  },
  {
    "text": "those two just to make sure that we we",
    "start": "805220",
    "end": "806600"
  },
  {
    "text": "did actually run a run a correct process",
    "start": "806600",
    "end": "808339"
  },
  {
    "text": "there and then there's that label y true",
    "start": "808339",
    "end": "811040"
  },
  {
    "text": "and so down here we're going to generate",
    "start": "811040",
    "end": "814250"
  },
  {
    "text": "a confusion matrix for different models",
    "start": "814250",
    "end": "817010"
  },
  {
    "text": "or for different combination of models",
    "start": "817010",
    "end": "818839"
  },
  {
    "text": "and so down here we're gonna get the",
    "start": "818839",
    "end": "821420"
  },
  {
    "text": "results without ensembl",
    "start": "821420",
    "end": "823370"
  },
  {
    "text": "right and so our precision in this case",
    "start": "823370",
    "end": "826190"
  },
  {
    "text": "is going to be just under 20% our recall",
    "start": "826190",
    "end": "828889"
  },
  {
    "text": "is going to be 67% we've got an overall",
    "start": "828889",
    "end": "831680"
  },
  {
    "text": "binary classification accuracy of 89%",
    "start": "831680",
    "end": "833690"
  },
  {
    "text": "and that's just looking at one model",
    "start": "833690",
    "end": "836870"
  },
  {
    "text": "right but then if we look at the results",
    "start": "836870",
    "end": "838760"
  },
  {
    "text": "with a different model precision goes up",
    "start": "838760",
    "end": "841279"
  },
  {
    "text": "right precision went up by about five",
    "start": "841279",
    "end": "843019"
  },
  {
    "text": "percentage points which is which is",
    "start": "843019",
    "end": "844339"
  },
  {
    "text": "awesome",
    "start": "844339",
    "end": "845209"
  },
  {
    "text": "interestingly the recall dropped right",
    "start": "845209",
    "end": "848180"
  },
  {
    "text": "and that's that's most likely because",
    "start": "848180",
    "end": "849829"
  },
  {
    "text": "there's there's so much content here",
    "start": "849829",
    "end": "851329"
  },
  {
    "text": "that it's it's actually getting more",
    "start": "851329",
    "end": "852769"
  },
  {
    "text": "precise but it's doing less less",
    "start": "852769",
    "end": "855290"
  },
  {
    "text": "classifying which it which is definitely",
    "start": "855290",
    "end": "856850"
  },
  {
    "text": "interesting it's probably a little bit",
    "start": "856850",
    "end": "857990"
  },
  {
    "text": "too strong on that negative class and",
    "start": "857990",
    "end": "861050"
  },
  {
    "text": "overall binary classification is is",
    "start": "861050",
    "end": "863180"
  },
  {
    "text": "staying pretty comparable so that in",
    "start": "863180",
    "end": "864680"
  },
  {
    "text": "that Canario it just moved over some of",
    "start": "864680",
    "end": "868399"
  },
  {
    "text": "our classical classification to the",
    "start": "868399",
    "end": "869899"
  },
  {
    "text": "other class so let's let's switch back",
    "start": "869899",
    "end": "872680"
  },
  {
    "text": "all right so some pro tips here remember",
    "start": "872680",
    "end": "875899"
  },
  {
    "text": "keep it small that that is a RESTful API",
    "start": "875899",
    "end": "877850"
  },
  {
    "text": "response and so you are gonna want to",
    "start": "877850",
    "end": "880430"
  },
  {
    "text": "have results coming out of batch",
    "start": "880430",
    "end": "881870"
  },
  {
    "text": "transform that are that are relatively",
    "start": "881870",
    "end": "883550"
  },
  {
    "text": "on the small side you can increase that",
    "start": "883550",
    "end": "885350"
  },
  {
    "text": "but generally keeping it smaller is",
    "start": "885350",
    "end": "887480"
  },
  {
    "text": "helpful it is also a very common design",
    "start": "887480",
    "end": "891079"
  },
  {
    "text": "pattern to cache your results in a",
    "start": "891079",
    "end": "894589"
  },
  {
    "text": "database right so let's say you actually",
    "start": "894589",
    "end": "896690"
  },
  {
    "text": "need real-time responses and you just",
    "start": "896690",
    "end": "899089"
  },
  {
    "text": "don't want to have the overhead of",
    "start": "899089",
    "end": "900620"
  },
  {
    "text": "managing that endpoint right or having",
    "start": "900620",
    "end": "902480"
  },
  {
    "text": "that endpoint hanging that can be an",
    "start": "902480",
    "end": "904579"
  },
  {
    "text": "expensive instance in some cases and so",
    "start": "904579",
    "end": "906620"
  },
  {
    "text": "it's very common for customers to run",
    "start": "906620",
    "end": "908839"
  },
  {
    "text": "batch transform to get the inference",
    "start": "908839",
    "end": "910790"
  },
  {
    "text": "responses and then load those instance",
    "start": "910790",
    "end": "913100"
  },
  {
    "text": "responses into a database which can then",
    "start": "913100",
    "end": "915769"
  },
  {
    "text": "serve those responses in real time and",
    "start": "915769",
    "end": "917540"
  },
  {
    "text": "then you'll just periodically update",
    "start": "917540",
    "end": "919069"
  },
  {
    "text": "those prediction responses the last",
    "start": "919069",
    "end": "921560"
  },
  {
    "text": "thing you want to think about is a",
    "start": "921560",
    "end": "922579"
  },
  {
    "text": "pipeline model right and so you can",
    "start": "922579",
    "end": "924949"
  },
  {
    "text": "string together multiple models in order",
    "start": "924949",
    "end": "927380"
  },
  {
    "text": "to run these processes we're gonna learn",
    "start": "927380",
    "end": "929089"
  },
  {
    "text": "about that in a later video",
    "start": "929089",
    "end": "930440"
  },
  {
    "text": "and so with that thank you very much my",
    "start": "930440",
    "end": "932899"
  },
  {
    "text": "name is Emily Weber I'm the machine",
    "start": "932899",
    "end": "934339"
  },
  {
    "text": "learning specialist at Amazon Web",
    "start": "934339",
    "end": "935720"
  },
  {
    "text": "Services and I'm very happy to talk with",
    "start": "935720",
    "end": "937490"
  },
  {
    "text": "you today about batch transform have a",
    "start": "937490",
    "end": "939740"
  },
  {
    "text": "great day",
    "start": "939740",
    "end": "942069"
  }
]
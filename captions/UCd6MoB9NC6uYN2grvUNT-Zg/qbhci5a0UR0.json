[
  {
    "text": "let's get started thanks everyone for coming my name is Brian and I'm here with Luis today we're both software engineers on the",
    "start": "60",
    "end": "6180"
  },
  {
    "text": "front end infrastructure team at Coursera and today we're gonna walk you through a couple different of problems that we found around site performance",
    "start": "6180",
    "end": "12630"
  },
  {
    "text": "reliability and developer productivity and have we leverage different tools and technologies from AWS to help us solve",
    "start": "12630",
    "end": "19289"
  },
  {
    "text": "these problems but before I get into that I want to just give a quick overview of Coursera actually I'm",
    "start": "19289",
    "end": "24960"
  },
  {
    "text": "curious maybe a show of hands how many of you have actually taken a course on Coursera before oh that's a lot of",
    "start": "24960",
    "end": "31500"
  },
  {
    "text": "people as awesome so for those of you who aren't familiar courser is an online education platform and we envision a",
    "start": "31500",
    "end": "38340"
  },
  {
    "text": "world where anyone anywhere can transform their life by accessing the world's best learning experience we've",
    "start": "38340",
    "end": "44370"
  },
  {
    "text": "been around for about five or six years now over that time we've had actually over 30 million learners for edge astir",
    "start": "44370",
    "end": "50100"
  },
  {
    "text": "on our platform and we've partnered with over 150 different partners both the top",
    "start": "50100",
    "end": "55170"
  },
  {
    "text": "universities in the world as well as some leading industry partners and together we've worked with them to create over 2,200 courses that we make",
    "start": "55170",
    "end": "62550"
  },
  {
    "text": "available to all of our learners and one thing that I'm really proud about is that 70% of those 30 million learners",
    "start": "62550",
    "end": "69000"
  },
  {
    "text": "actually come from outside of the United States so we have really a worldwide audience over that time we've we've",
    "start": "69000",
    "end": "77159"
  },
  {
    "text": "grown the platform a lot but we've also grown a lot as a company too so actually the last time I checked I saw that we",
    "start": "77159",
    "end": "82740"
  },
  {
    "text": "have over 70 engineers working at Coursera and that's a lot of people but there's a lot of work to do in order to",
    "start": "82740",
    "end": "88560"
  },
  {
    "text": "build this world-class platform and Louis and I we're on the front end infrastructure team so on that team we",
    "start": "88560",
    "end": "94619"
  },
  {
    "text": "actually have kind of two different goals the first one is to keep Coursera site as fast and reliable as possible",
    "start": "94619",
    "end": "100790"
  },
  {
    "text": "but the other one is to empower Coursera's engineers especially our front-end engineers to be as productive",
    "start": "100790",
    "end": "106649"
  },
  {
    "text": "and as efficient as possible so for the next 45 minutes or so we're gonna walk you through a couple different stories",
    "start": "106649",
    "end": "112920"
  },
  {
    "text": "of problems that we faced and then different tools and technologies from AWS that we abused to help solve these",
    "start": "112920",
    "end": "118469"
  },
  {
    "text": "problems so Luis is gonna kick things off by discussing some problems that we face with our build tooling",
    "start": "118469",
    "end": "125450"
  },
  {
    "text": "all right thanks Brian so before I really get into code build I just wanted",
    "start": "133750",
    "end": "140959"
  },
  {
    "text": "to kind of go over one thing that Brian mentioned about productivity right something that we look to do is optimize",
    "start": "140959",
    "end": "146750"
  },
  {
    "text": "productivity and we found that actually productivity a Corsair increases when we",
    "start": "146750",
    "end": "152870"
  },
  {
    "text": "decrease the time between when a code commits goes in and when the deploy goes out and we recently used code build to",
    "start": "152870",
    "end": "160280"
  },
  {
    "text": "make this process better but before I kind of go into code build itself I wanted to walk you through the problem",
    "start": "160280",
    "end": "165650"
  },
  {
    "text": "that we were actually facing at Coursera so a Coursera we have always treated our",
    "start": "165650",
    "end": "171680"
  },
  {
    "text": "back-end in front and a separate kind of code entities right our back-end was always organized as microservices and",
    "start": "171680",
    "end": "177129"
  },
  {
    "text": "honestly that worked really well for us and that kind of stood the test of time very well so I'm not going to talk about",
    "start": "177129",
    "end": "182329"
  },
  {
    "text": "that today what I want to talk about actually is our front end in 2013",
    "start": "182329",
    "end": "189620"
  },
  {
    "text": "instead of having our front end code split up like you would in Microsoft and micro services architecture our front",
    "start": "189620",
    "end": "194629"
  },
  {
    "text": "end code base was actually organized as a monolith and this wasn't something that happened on purpose it just kind of",
    "start": "194629",
    "end": "200209"
  },
  {
    "text": "happened that way right we started with javascript code for one page and as we added more and more products we just",
    "start": "200209",
    "end": "205849"
  },
  {
    "text": "kept adding those pages to the same codebase and so in 2013 we had a monolith where if a developer changed",
    "start": "205849",
    "end": "212569"
  },
  {
    "text": "any of the JavaScript code for Coursera we would rebuild and redeploy all the JavaScript code for our front-end but",
    "start": "212569",
    "end": "221870"
  },
  {
    "text": "this was fine right because in 2013 we didn't have that much JavaScript code and so the time between the time after",
    "start": "221870",
    "end": "228979"
  },
  {
    "text": "committing sorry commits to build to deploy that all just took five minutes",
    "start": "228979",
    "end": "234220"
  },
  {
    "text": "and so developers could actually treat commit and deploy as a single task and",
    "start": "234220",
    "end": "240650"
  },
  {
    "text": "what we saw from that was that with really granular deploys regression debugging was really easy because we",
    "start": "240650",
    "end": "246500"
  },
  {
    "text": "could just look at our air monitors or see or look at the time stone reports of regression and then match up that with",
    "start": "246500",
    "end": "253150"
  },
  {
    "text": "when they're deployed fence actually happened and then we could figure out exactly what code change caused the",
    "start": "253150",
    "end": "258650"
  },
  {
    "text": "regression but with this approach we didn't at the time we didn't ask",
    "start": "258650",
    "end": "264290"
  },
  {
    "text": "if that would actually scale right this process and this process actually didn't scale as we hired more developers built",
    "start": "264290",
    "end": "271790"
  },
  {
    "text": "more products and increase the size of our friend and model with our builds went from five minutes to 15 to 30",
    "start": "271790",
    "end": "279410"
  },
  {
    "text": "minutes now in Coursera in 2016 the builds are taking over 30 minutes and as",
    "start": "279410",
    "end": "286070"
  },
  {
    "text": "a result of that developers could no longer treat commit and deploy as a single task and so they would actually",
    "start": "286070",
    "end": "292130"
  },
  {
    "text": "end up switching to another task and sometimes forgetting to actually deploy",
    "start": "292130",
    "end": "296710"
  },
  {
    "text": "and as a result of that actually we had the deploys that would go out with 10 15",
    "start": "298300",
    "end": "303980"
  },
  {
    "text": "20 different commits and so if we actually wanted to have the regression bugging process that we had before we",
    "start": "303980",
    "end": "310220"
  },
  {
    "text": "had it just wouldn't work we had to actually go and investigate the deploy see what commits went out with that and actually look at every single code",
    "start": "310220",
    "end": "316760"
  },
  {
    "text": "change within that deploy increasing build times wasn't the only problem that",
    "start": "316760",
    "end": "322880"
  },
  {
    "text": "we had with the monolith because we treat our monolith as a single unit to build and deploy we saw some we saw that",
    "start": "322880",
    "end": "329210"
  },
  {
    "text": "sometimes when one bad commit caused a bug on master it would actually stop all the developers from deploying all right",
    "start": "329210",
    "end": "335780"
  },
  {
    "text": "so here's an example say we have five commits that landed kind of within the same time of each other the first two",
    "start": "335780",
    "end": "342200"
  },
  {
    "text": "are fine so we actually go ahead and deploy those changes during testing",
    "start": "342200",
    "end": "348740"
  },
  {
    "text": "however we discovered that the third commit actually introduces a regression for instance let's say that commit Cod's",
    "start": "348740",
    "end": "355010"
  },
  {
    "text": "a lecture video player to default to playing stuff at 2x speed and that's not something that we actually want all our users doing unless they actually desire",
    "start": "355010",
    "end": "362840"
  },
  {
    "text": "it so we don't want to deploy this but let's say after this after this commit",
    "start": "362840",
    "end": "369800"
  },
  {
    "text": "goes in another commit comes in where we actually want to update the Terms of Use",
    "start": "369800",
    "end": "375650"
  },
  {
    "text": "page and our legal team wants it out as soon as possible if we actually deploy this change though we would deploy that",
    "start": "375650",
    "end": "382220"
  },
  {
    "text": "video regression too right even though the video player and the Terms of Use page are completely different parts of",
    "start": "382220",
    "end": "388160"
  },
  {
    "text": "our site so with this problem with these problems in minds we decided that we have to take our front end monolith and",
    "start": "388160",
    "end": "394840"
  },
  {
    "text": "split it up all right and in order to do that we did two things we actually decided to treat",
    "start": "394840",
    "end": "405150"
  },
  {
    "text": "every single we actually decided to treat every single application is its own buildable unit and so instead of a",
    "start": "405150",
    "end": "412480"
  },
  {
    "text": "build script saying let's just build all the things that we see that look like front-end code we would have a script that was parameterize by application so",
    "start": "412480",
    "end": "419950"
  },
  {
    "text": "that we could actually build individual applications another thing that we did was we added a source base dependency",
    "start": "419950",
    "end": "426040"
  },
  {
    "text": "analysis so that we could take a look at it we could take a code change and then inspect it and figure out the minimal",
    "start": "426040",
    "end": "432370"
  },
  {
    "text": "number of applications that we had to build with these two changes in harmony whenever developer landed a code change",
    "start": "432370",
    "end": "439240"
  },
  {
    "text": "instead of taking off a monolith bill for the whole repository we would only kick off the build for singular applications that were affected and this",
    "start": "439240",
    "end": "447010"
  },
  {
    "text": "is so this was the result say for instance we have a bug fix that comes in for the learning plans application we",
    "start": "447010",
    "end": "453370"
  },
  {
    "text": "would only really need to build this app write our dependency resolution system that we had built would figure out that this is the only application he needs to",
    "start": "453370",
    "end": "459190"
  },
  {
    "text": "get built in another case where let's say there's a code change to a UI component that's being used by three of",
    "start": "459190",
    "end": "465910"
  },
  {
    "text": "our applications we would only have to build those three applications so in both of these cases we've kind of",
    "start": "465910",
    "end": "471850"
  },
  {
    "text": "succeeded we've sped up our build times by only building by building less code now we've also separated the built the",
    "start": "471850",
    "end": "480220"
  },
  {
    "text": "build and deploy process for all the different applications but we weren't done yet",
    "start": "480220",
    "end": "485260"
  },
  {
    "text": "right because at worst case a component that all of our applications use like",
    "start": "485260",
    "end": "490540"
  },
  {
    "text": "our page header could be changed and then we'd have to actually deploy build",
    "start": "490540",
    "end": "497290"
  },
  {
    "text": "and deploy all of our applications at that moment and what happened with this",
    "start": "497290",
    "end": "503800"
  },
  {
    "text": "is that we actually saw that we still had issues right and these issues came because for our build system at the time",
    "start": "503800",
    "end": "509830"
  },
  {
    "text": "we were using Jenkins and it isn't necessarily the fault of Jenkins itself but how we were using Jenkins we kept a",
    "start": "509830",
    "end": "516310"
  },
  {
    "text": "pool of workers on ec2 and we set up an auto scaling configuration that would approximate the capacity needed to work",
    "start": "516310",
    "end": "523900"
  },
  {
    "text": "through our build queue during the day without it getting too back right and I think this is fairly standard what people do with Jenkins so",
    "start": "523900",
    "end": "531050"
  },
  {
    "text": "at night you might get away with just two workers but during the day we would scale up right and at that time we set a",
    "start": "531050",
    "end": "537019"
  },
  {
    "text": "max limit of eight workers because we want it to be cost conscious now eight",
    "start": "537019",
    "end": "542240"
  },
  {
    "text": "workers definitely is not enough if you know a code commit could suddenly trigger 50 different builds and add",
    "start": "542240",
    "end": "547610"
  },
  {
    "text": "those to the build queue right so what we saw was that when 50 build land the",
    "start": "547610",
    "end": "555559"
  },
  {
    "text": "build queue the eight workers would pick up eight builds take five minutes to turn through those builds pick up",
    "start": "555559",
    "end": "561259"
  },
  {
    "text": "another eight builds and each time it does this it'd be five minute increments eventually finishing everything right",
    "start": "561259",
    "end": "568579"
  },
  {
    "text": "but the problem is it would take thirty five minutes in this case to actually produce a full build right so we're back",
    "start": "568579",
    "end": "575420"
  },
  {
    "text": "to square one we haven't really improved their build time at all but we knew that",
    "start": "575420",
    "end": "582410"
  },
  {
    "text": "we wanted to go from nothing being built to everything being built within five minutes and the way to do that was that",
    "start": "582410",
    "end": "589459"
  },
  {
    "text": "we needed to have access to n workers where n is the number of applications that need to be built the moat from the",
    "start": "589459",
    "end": "594889"
  },
  {
    "text": "moment that a code change in the worst case scenario lands so at first we said",
    "start": "594889",
    "end": "601399"
  },
  {
    "text": "okay can we automatically scalar Jenkins worker pool quick enough to do this and as we tried this we found that it was",
    "start": "601399",
    "end": "610399"
  },
  {
    "text": "too slow to boot up these ec2 instances to support the bursty build behavior",
    "start": "610399",
    "end": "615589"
  },
  {
    "text": "that we were saying next thing we thought of is can we actually over prove it over provisioned Jenkins",
    "start": "615589",
    "end": "622149"
  },
  {
    "text": "unfortunately that isn't cost-effective because then you might have a lot of idle workers sitting around that you're",
    "start": "622149",
    "end": "627589"
  },
  {
    "text": "paying for that aren't doing anything but to make matters worse right",
    "start": "627589",
    "end": "633939"
  },
  {
    "text": "multiple commits might actually land minutes from each other and we've actually seen this happen pretty often",
    "start": "633939",
    "end": "639129"
  },
  {
    "text": "we had an example where a growth team needed to land commits for a feature",
    "start": "639129",
    "end": "644420"
  },
  {
    "text": "that they're working on in time for a demo session and so maybe they need to",
    "start": "644420",
    "end": "649730"
  },
  {
    "text": "update the page header then add links to a footer and update a button component",
    "start": "649730",
    "end": "655069"
  },
  {
    "text": "to support some things needed for that feature these comets land we actually saw that",
    "start": "655069",
    "end": "662210"
  },
  {
    "text": "we would have over a hundred builds only queued up in our build system and so eight workers turning through this would",
    "start": "662210",
    "end": "667910"
  },
  {
    "text": "take a really long time that was just something that we couldn't do so that's",
    "start": "667910",
    "end": "673160"
  },
  {
    "text": "when we asked ourselves can we do better is there something we can do to make sure that we can actually trigger all these builds from the beginning and work",
    "start": "673160",
    "end": "680000"
  },
  {
    "text": "through them all at the same time and that's when we turn to code build and for those of you who haven't used code",
    "start": "680000",
    "end": "687830"
  },
  {
    "text": "build before or maybe you've only heard a little bit about it I wanted to give a quick overview of what it is I'm code",
    "start": "687830",
    "end": "693950"
  },
  {
    "text": "build is a fully managed build service that AWS launched late last year it",
    "start": "693950",
    "end": "700250"
  },
  {
    "text": "provides on-demand build resources so you don't have to actually reserve build resources you don't have to have them",
    "start": "700250",
    "end": "705709"
  },
  {
    "text": "sitting around the moment you trigger a build code build will provide resources for you in addition to that all of this",
    "start": "705709",
    "end": "712880"
  },
  {
    "text": "happens inside a docker container so you get fresh environments every time so you don't have to maintain your build",
    "start": "712880",
    "end": "718760"
  },
  {
    "text": "systems and there's also a near infinite elastic capacity right so you basically",
    "start": "718760",
    "end": "724070"
  },
  {
    "text": "get as much as you're willing to pay for now I have to caveat that with by",
    "start": "724070",
    "end": "730610"
  },
  {
    "text": "default I believe that you can have 20 concurrent builds running at the same time but that's a that's something that",
    "start": "730610",
    "end": "736220"
  },
  {
    "text": "you can reach out to AWS support for if you want to trigger more than 20 builds apparently another thing about code",
    "start": "736220",
    "end": "743240"
  },
  {
    "text": "build that we really like is that is the pricing model they charge per build",
    "start": "743240",
    "end": "748880"
  },
  {
    "text": "minute so you're really only ever paying for what you need you're not paying for",
    "start": "748880",
    "end": "754700"
  },
  {
    "text": "idle resources and not paying for idle resources and so if you what we wanted",
    "start": "754700",
    "end": "763040"
  },
  {
    "text": "to go from nothing being built to everything being built within five minutes that was really good right",
    "start": "763040",
    "end": "769160"
  },
  {
    "text": "because we didn't have to pay for instances that were sitting around after",
    "start": "769160",
    "end": "774320"
  },
  {
    "text": "the before and after the build in the case of that example with the growth",
    "start": "774320",
    "end": "780470"
  },
  {
    "text": "team everything would happen in five minutes as well and we'd pay for only the resources that we need so some of",
    "start": "780470",
    "end": "788900"
  },
  {
    "text": "you might be wondering like what was the process of migrating from Jenkins to code build and I'm not gonna go into this in too much",
    "start": "788900",
    "end": "794990"
  },
  {
    "text": "detail but I can just say it in our experience it was actually relatively easy we were able to take our build scripts that we were running on Jenkins",
    "start": "794990",
    "end": "802340"
  },
  {
    "text": "and make some minor modifications to get it to run on code build and those modifications were to just make it",
    "start": "802340",
    "end": "808850"
  },
  {
    "text": "compliant with what code build expects right so I would definitely recommend",
    "start": "808850",
    "end": "813860"
  },
  {
    "text": "checking out the documentation because it's very concise and it explains to you how you can set up an optimal build",
    "start": "813860",
    "end": "819110"
  },
  {
    "text": "environment and also to set up a build specification cool so another thing that",
    "start": "819110",
    "end": "829160"
  },
  {
    "text": "we realized once we moved to code build was that the optimized optics almost",
    "start": "829160",
    "end": "835370"
  },
  {
    "text": "entirely instead of thinking about how do we actually Auto scale effect our",
    "start": "835370",
    "end": "840500"
  },
  {
    "text": "worker pool effectively we could start thinking about how do we optimize the slowest individual build time because if",
    "start": "840500",
    "end": "846410"
  },
  {
    "text": "your parallelizing or your build tasks then the slowest thing is the weakest link so now we can just think about",
    "start": "846410",
    "end": "854560"
  },
  {
    "text": "taking the slowest process to figure out why it's inefficient and then optimizing that I want to go through a couple of",
    "start": "854560",
    "end": "861920"
  },
  {
    "text": "tips and tricks these are things that we kind of learned along the way the first thing is build visualization so code",
    "start": "861920",
    "end": "870140"
  },
  {
    "text": "build is just a generalized build runner in our case there is actually a relationship between a code commit and",
    "start": "870140",
    "end": "875870"
  },
  {
    "text": "the different builds that it triggered so we actually built the visualization for for our developers that kind of",
    "start": "875870",
    "end": "882650"
  },
  {
    "text": "showed that off something else that we did was we supercharge our logs because",
    "start": "882650",
    "end": "889040"
  },
  {
    "text": "code build build logs are actually hooked up to cloud watch and it's very easy to set up third party integrations between cloud watch and other services",
    "start": "889040",
    "end": "896720"
  },
  {
    "text": "we actually now funnel all of our code build blocks of sumo logic so our developers can use sumo logics powerful",
    "start": "896720",
    "end": "902570"
  },
  {
    "text": "search operators to debug their own build issues the last thing that I",
    "start": "902570",
    "end": "908810"
  },
  {
    "text": "wanted to mention was that there is a aw Scovill jenkins plugin so if your",
    "start": "908810",
    "end": "915140"
  },
  {
    "text": "thought is code build sounds great but it might be a lot of work to move off Jenkins you can actually now using this",
    "start": "915140",
    "end": "922580"
  },
  {
    "text": "plug-in use code build to work through your bill queue on Jenkins",
    "start": "922580",
    "end": "928340"
  },
  {
    "text": "so I definitely recommend checking that out cool",
    "start": "928340",
    "end": "933960"
  },
  {
    "text": "so next Brian is going to talk a little bit about um how I use ec2 container service thanks Liz so now I'll talk a",
    "start": "933960",
    "end": "949740"
  },
  {
    "text": "little bit about how we actually use ec2 container service to make our site a little bit more reliable but before I go",
    "start": "949740",
    "end": "955470"
  },
  {
    "text": "too far into this let's just go over a little bit of context and history first so of course service entire website is",
    "start": "955470",
    "end": "961470"
  },
  {
    "text": "built using a single page application architecture we dynamically render our entire page using javascript and react",
    "start": "961470",
    "end": "967470"
  },
  {
    "text": "and this is a really great way to separate concerns it makes our front-end developers much happier much more efficient but it can",
    "start": "967470",
    "end": "974310"
  },
  {
    "text": "come with a little bit of a performance cost that's because when you first load page on Coursera at least if you did",
    "start": "974310",
    "end": "980040"
  },
  {
    "text": "this I get year or two ago you wouldn't actually get this beautiful homepage here you'd see something that looks a",
    "start": "980040",
    "end": "985440"
  },
  {
    "text": "little bit like this that's because when you first load the page we don't actually have any content in there we",
    "start": "985440",
    "end": "991080"
  },
  {
    "text": "just have a link to JavaScript files that we need to render the page so what your browser will do it'll go download",
    "start": "991080",
    "end": "996690"
  },
  {
    "text": "that javascript file and they'll start rendering the page and then you'll probably get something that looks like",
    "start": "996690",
    "end": "1001730"
  },
  {
    "text": "this it'll probably get the header bar in there or something but now what your browser needs to do is go make some API",
    "start": "1001730",
    "end": "1007550"
  },
  {
    "text": "calls and fetch the data that it needs to render the rest of the page and then finally you'll make those API calls get",
    "start": "1007550",
    "end": "1013760"
  },
  {
    "text": "the data back and then be able to render our full page but this is a really",
    "start": "1013760",
    "end": "1019910"
  },
  {
    "text": "crappy user experience just imagine Sonne telling you about Coursera and going to our site for the first time and",
    "start": "1019910",
    "end": "1025579"
  },
  {
    "text": "waiting 20 seconds for the page to load I mean no one's actually gonna do that if it was me I'd probably wait five",
    "start": "1025580",
    "end": "1030770"
  },
  {
    "text": "seconds then go watch some cat videos I'm ready instead and that was just read",
    "start": "1030770",
    "end": "1036589"
  },
  {
    "text": "at school and everything but we really want to be able to transform lives and let people learn skills like machine",
    "start": "1036590",
    "end": "1041810"
  },
  {
    "text": "learning or accounting of Coursera so we need to fix this problem but one problem",
    "start": "1041810",
    "end": "1046819"
  },
  {
    "text": "we had is that our entire site is rendered using this single page application architecture and we couldn't throw away five years worth of code and",
    "start": "1046820",
    "end": "1053600"
  },
  {
    "text": "start over start doing things on the server so we embraced it a technique referred to",
    "start": "1053600",
    "end": "1058970"
  },
  {
    "text": "server-side rendering and react which basically allows us to execute nodejs on the server and make all of these API",
    "start": "1058970",
    "end": "1065750"
  },
  {
    "text": "calls on the server and then send fully rendered HTML to the client so on the",
    "start": "1065750",
    "end": "1071240"
  },
  {
    "text": "left here is kind of that skeleton page that we had before where we'd send the HTML to the browser with just a link to",
    "start": "1071240",
    "end": "1077840"
  },
  {
    "text": "JavaScript and a loading indicator then the browser would go execute everything but on the right this is a slightly",
    "start": "1077840",
    "end": "1084230"
  },
  {
    "text": "truncated example of what you'll see if you actually use server-side rendering to send the full content and the full",
    "start": "1084230",
    "end": "1090680"
  },
  {
    "text": "HTML to the client and this means that once the browser gets this HTML it's able to render it immediately instead of",
    "start": "1090680",
    "end": "1096710"
  },
  {
    "text": "having to go download the JavaScript and then make API calls to get all that data so we wanted to build this service to",
    "start": "1096710",
    "end": "1104510"
  },
  {
    "text": "render these pages and I'll admit we're not the most creative people when it comes to naming things we have a user",
    "start": "1104510",
    "end": "1110720"
  },
  {
    "text": "service we have an authentication service and payment service so we need to build a service for rendering pages",
    "start": "1110720",
    "end": "1116210"
  },
  {
    "text": "and you can probably guess we called it the render service but what we lack in",
    "start": "1116210",
    "end": "1121790"
  },
  {
    "text": "naming creativity I think we make up for in expertise in running Scala services you run like 50 or 60 of them now and",
    "start": "1121790",
    "end": "1128600"
  },
  {
    "text": "we've done pretty good at it we know how to deploy them we can monitor them we know all the tuning and everything that",
    "start": "1128600",
    "end": "1134270"
  },
  {
    "text": "we need to do we got all that pretty much taken care of and we didn't want to build a new service and like nodejs or",
    "start": "1134270",
    "end": "1140150"
  },
  {
    "text": "something and watch that into our infrastructure because that would be a lot to maintain and manage so we made",
    "start": "1140150",
    "end": "1145460"
  },
  {
    "text": "the service of Scala service but unfortunately Scala can't really execute an execute JavaScript but no js' is",
    "start": "1145460",
    "end": "1154190"
  },
  {
    "text": "really good at that so we took this Scala service and we just added some nodejs to it we basically set up an otoscope",
    "start": "1154190",
    "end": "1160670"
  },
  {
    "text": "process to run alongside the Scala service with the nodejs executing the JavaScript and the Scala part doing",
    "start": "1160670",
    "end": "1166790"
  },
  {
    "text": "everything else but this nodejs part acts a little bit differently than the",
    "start": "1166790",
    "end": "1172310"
  },
  {
    "text": "Scala part as Luis mentioned before our commit to deploy process is very",
    "start": "1172310",
    "end": "1177770"
  },
  {
    "text": "streamlined we could have people deploying code within five minutes of committing it but for our scholar",
    "start": "1177770",
    "end": "1183500"
  },
  {
    "text": "services the deploys typically take a little bit longer because there's a bit more in that process we have to compile",
    "start": "1183500",
    "end": "1188870"
  },
  {
    "text": "the code build Debian packages upload them launch ec2 and PSA's installed the debian package wait",
    "start": "1188870",
    "end": "1195059"
  },
  {
    "text": "for it to health check and then slowly ship traffic over and that whole process can take like 20 or 30 minutes so in",
    "start": "1195059",
    "end": "1201809"
  },
  {
    "text": "order to keep our deploy is really fast for our JavaScript part we add in a dynamic way to update that nodejs part",
    "start": "1201809",
    "end": "1207830"
  },
  {
    "text": "so in every JavaScript to play will download a new version of the JavaScript and then we'll use Bluegreen deployments",
    "start": "1207830",
    "end": "1214529"
  },
  {
    "text": "I will slowly shift traffic over from the old version to the new version and then after we shipped to a hundred",
    "start": "1214529",
    "end": "1219989"
  },
  {
    "text": "percent we'll clean things up and this we do entirely without actually",
    "start": "1219989",
    "end": "1225059"
  },
  {
    "text": "launching any new ec2 instances and this actually worked out really well for us but just like Luis mentioned earlier",
    "start": "1225059",
    "end": "1232440"
  },
  {
    "text": "when we ran into a problem once we split up all of our applications and the builds took much longer we began to see",
    "start": "1232440",
    "end": "1237960"
  },
  {
    "text": "some problems in this render service too because now there wasn't just one version of code that we're running there",
    "start": "1237960",
    "end": "1244049"
  },
  {
    "text": "were like 50 or 60 and it made a lot of things like asset downloading and shifting traffic over and cleaning up",
    "start": "1244049",
    "end": "1250409"
  },
  {
    "text": "much more complicated but we also ran into a couple of weird situations too as",
    "start": "1250409",
    "end": "1255659"
  },
  {
    "text": "a result from the multi tendency that we had here basically where we were running all these applications on a single host",
    "start": "1255659",
    "end": "1262190"
  },
  {
    "text": "so every once in a while one of our applications is going to break it's",
    "start": "1262190",
    "end": "1267809"
  },
  {
    "text": "there could be like a buggy code deploy that's own commits maybe one of our back-end services breaks or slows down",
    "start": "1267809",
    "end": "1273649"
  },
  {
    "text": "database has an issue or maybe even some third party that we depend on breaks and we've kind of accepted that we're never",
    "start": "1273649",
    "end": "1280259"
  },
  {
    "text": "actually going to have 100% uptime instead we really just want to optimize for finding and fixing the problem as",
    "start": "1280259",
    "end": "1286649"
  },
  {
    "text": "quickly as possible and keeping all of our problems as contained as possible we don't want if one application breaks are",
    "start": "1286649",
    "end": "1292440"
  },
  {
    "text": "sewn deploys one code in one bad application that's buggy we don't want that to affect the rest of Coursera but",
    "start": "1292440",
    "end": "1299970"
  },
  {
    "text": "what we saw in this case is that actually was the problem where errors in one application could actually bleed",
    "start": "1299970",
    "end": "1305369"
  },
  {
    "text": "over into other applications and caused the entire site to slow down and this is",
    "start": "1305369",
    "end": "1310919"
  },
  {
    "text": "because we actually use a shared node worker pool with all of these applications so if one application",
    "start": "1310919",
    "end": "1316080"
  },
  {
    "text": "slowed down or start using a lot of CPU it could cause all the other applications to get backed up or crash",
    "start": "1316080",
    "end": "1321450"
  },
  {
    "text": "or there could be random errors between them and this was really a problem that we couldn't live with so we tried to figure out some",
    "start": "1321450",
    "end": "1328980"
  },
  {
    "text": "of their solutions for how to really make sure that an Aaron one application didn't bleed over to the others so we",
    "start": "1328980",
    "end": "1335460"
  },
  {
    "text": "brainstormed some different things and we came up with a couple different ideas and the first one we thought about was basically just going to the extreme",
    "start": "1335460",
    "end": "1341940"
  },
  {
    "text": "other end instead of running all of our applications on a single host what if we just took every application and put it",
    "start": "1341940",
    "end": "1348450"
  },
  {
    "text": "in its own ec2 instance and this would actually probably worked pretty well for us but we'd still have to figure out how",
    "start": "1348450",
    "end": "1354840"
  },
  {
    "text": "to do the dynamic asset downloading but I'll be completely honest when we were thinking about this approach we",
    "start": "1354840",
    "end": "1360450"
  },
  {
    "text": "estimated some cost for this and we saw they would end up costing about like five or ten times as much money as running everything on a single host",
    "start": "1360450",
    "end": "1367070"
  },
  {
    "text": "especially because a lot of our applications are maybe they get little traffic or their internal use only and",
    "start": "1367070",
    "end": "1373080"
  },
  {
    "text": "we didn't want the overhead of running an ec2 instance for all of those applications - so we kept brainstorming",
    "start": "1373080",
    "end": "1379919"
  },
  {
    "text": "and we found another solution that I think worked out pretty well for us and it came in the form of containers using",
    "start": "1379919",
    "end": "1385740"
  },
  {
    "text": "the ec2 container service and this really gives us the best of both worlds we get the multi tendency that we need",
    "start": "1385740",
    "end": "1392880"
  },
  {
    "text": "to keep our costs down by being able to run all these containers on a single host but it also gives us that isolation",
    "start": "1392880",
    "end": "1398760"
  },
  {
    "text": "to make sure that if one application breaks it doesn't take down the rest of Coursera but before we go too far into",
    "start": "1398760",
    "end": "1405929"
  },
  {
    "text": "this let's just go over quickly a little bit more about ECS so at its heart ECS",
    "start": "1405929",
    "end": "1412740"
  },
  {
    "text": "is basically a container management or orchestration system so this means that you just tell it what you wanted to do",
    "start": "1412740",
    "end": "1418799"
  },
  {
    "text": "for instance take these containers and run them across these hosts and it'll do it all for you it really hides a lot of",
    "start": "1418799",
    "end": "1426390"
  },
  {
    "text": "that complexity around managing docker and distributing tasks find a really nice API but under the hood though it's",
    "start": "1426390",
    "end": "1434220"
  },
  {
    "text": "actually just running all these containers on just ec2 instances that are running the ECS agent so this means",
    "start": "1434220",
    "end": "1441000"
  },
  {
    "text": "that you're not actually losing any control over things you're able to SSH into the machine you could run it using",
    "start": "1441000",
    "end": "1446610"
  },
  {
    "text": "your own ami run any arbitrary applications like monitoring applications on there and anything else",
    "start": "1446610",
    "end": "1452880"
  },
  {
    "text": "say you could do with ec2 you're able to do with these ECS hosts also",
    "start": "1452880",
    "end": "1458500"
  },
  {
    "text": "but while this does give you a lot of control ECS is really able to manage a lot of this for you so it could help you",
    "start": "1458500",
    "end": "1465670"
  },
  {
    "text": "with auto scaling you could set up a couple of rules saying if maybe CPU usage on these containers goes above a",
    "start": "1465670",
    "end": "1471220"
  },
  {
    "text": "certain threshold add more containers it could also handle dynamic resource",
    "start": "1471220",
    "end": "1476650"
  },
  {
    "text": "reservations so you could include along with each container specification how much CPU and how much memory you want it",
    "start": "1476650",
    "end": "1482950"
  },
  {
    "text": "to have and ECS will make sure that that container has always at least that amount of memory it could always go more",
    "start": "1482950",
    "end": "1489040"
  },
  {
    "text": "if there's more on the hose but make sure that that amount of memory or CPU is always available to that container",
    "start": "1489040",
    "end": "1495000"
  },
  {
    "text": "it also can handle health checking for you so you could set up a couple different rules and say if some",
    "start": "1495000",
    "end": "1500560"
  },
  {
    "text": "container ever dies or sub standing to health checks or something just kill that container and launch a new one and",
    "start": "1500560",
    "end": "1505780"
  },
  {
    "text": "then new one will launch normally within seconds unless Lia as I mentioned",
    "start": "1505780",
    "end": "1511600"
  },
  {
    "text": "earlier these are all really complicated processes under the hood but ECS hides",
    "start": "1511600",
    "end": "1516610"
  },
  {
    "text": "all that away behind some really nice api's that make it really easy to do everything that you need to do so",
    "start": "1516610",
    "end": "1523810"
  },
  {
    "text": "switching to e CS for us was actually pretty easy we took those code build jobs at Louis mentioned earlier and then",
    "start": "1523810",
    "end": "1530290"
  },
  {
    "text": "had them export a docker image with those assets and we built in there and upload it to the ec2 container registry",
    "start": "1530290",
    "end": "1536740"
  },
  {
    "text": "and then when a user wanted to deploy we just took our existing deployment",
    "start": "1536740",
    "end": "1541750"
  },
  {
    "text": "pipeline and made some API calls ECS to launch a service register with the auto scaling group and then slowly shift",
    "start": "1541750",
    "end": "1548290"
  },
  {
    "text": "traffic over to that new version and there honestly wasn't anything too",
    "start": "1548290",
    "end": "1553300"
  },
  {
    "text": "unique or special about our approach with moving DCs everything that we did was pretty much straight out of the AWS",
    "start": "1553300",
    "end": "1559030"
  },
  {
    "text": "documentation and all those guys and it that really just kind of covered everything that we needed to do so I",
    "start": "1559030",
    "end": "1565000"
  },
  {
    "text": "don't want to go into those details too much but what I do want to discuss is some of the results that we saw and some",
    "start": "1565000",
    "end": "1570970"
  },
  {
    "text": "tips and tricks that we learn from this so the first thing that I want to point out so so that our pagers were actually",
    "start": "1570970",
    "end": "1577960"
  },
  {
    "text": "being served 30% faster than they used to once we switched EES yes I think one",
    "start": "1577960",
    "end": "1583540"
  },
  {
    "text": "of the reasons for this is that extra isolation that we had between all of our different applications because we were",
    "start": "1583540",
    "end": "1588730"
  },
  {
    "text": "using the shared node workers before we would have some problems where they would parce javascript files for one",
    "start": "1588730",
    "end": "1593740"
  },
  {
    "text": "application and then go start serving request to another application and then they would garbage collect those original application files and then that",
    "start": "1593740",
    "end": "1601720"
  },
  {
    "text": "extra overhead of having to parse those JavaScript files over and over again was really adding up but now that we had our",
    "start": "1601720",
    "end": "1608679"
  },
  {
    "text": "JavaScript files bundled into our container and each node worker is only responsible for one application they",
    "start": "1608679",
    "end": "1614710"
  },
  {
    "text": "were just running much more efficiently we also saw a lot of benefits from being",
    "start": "1614710",
    "end": "1620230"
  },
  {
    "text": "able to scale containers much more quickly so we're running all these things on our ec2 hosts and we generally",
    "start": "1620230",
    "end": "1626559"
  },
  {
    "text": "leave a little bit of extra capacity along with all of our hosts so if we ever need to scale one application up we",
    "start": "1626559",
    "end": "1632500"
  },
  {
    "text": "had some room for that there and every once in a while some certain part of Coursera site normally gets or sometimes",
    "start": "1632500",
    "end": "1639580"
  },
  {
    "text": "gets some rapid influx of traffic such as the time that uber tweeted to her millions of followers about the Coursera",
    "start": "1639580",
    "end": "1645670"
  },
  {
    "text": "course that she really liked and in these instances we needed to make sure that Coursera didn't go down we",
    "start": "1645670",
    "end": "1652000"
  },
  {
    "text": "definitely didn't want to disappoint Oprah so we needed to find a way to make sure that we could scale up maybe double",
    "start": "1652000",
    "end": "1658330"
  },
  {
    "text": "or triple triple the amount of traffic that we were getting before without actually going down or causing any",
    "start": "1658330",
    "end": "1663850"
  },
  {
    "text": "problems or anything but before we were running on ECS with those ec2 instances",
    "start": "1663850",
    "end": "1669370"
  },
  {
    "text": "we saw that if we needed to scale up it would take like five or so minutes for us to launch those new ec2 instances and",
    "start": "1669370",
    "end": "1675970"
  },
  {
    "text": "get them fully ready and if we waited five minutes while our traffic was doubling that could actually cause some outages of Coursera so the other",
    "start": "1675970",
    "end": "1683740"
  },
  {
    "text": "approach that we took was to basically run everything in a very over-provision state we ran like two or three times as",
    "start": "1683740",
    "end": "1689530"
  },
  {
    "text": "much capacity as we needed just to make sure when we got those sudden bursts that we were able to handle the load",
    "start": "1689530",
    "end": "1695550"
  },
  {
    "text": "this ended up costing us a lot of extra money both ECS were able to run much",
    "start": "1695550",
    "end": "1701290"
  },
  {
    "text": "closer to the capacity that we actually need at any given time because we're able to scale up and launch new",
    "start": "1701290",
    "end": "1706480"
  },
  {
    "text": "containers within seconds instead of minutes but I'll be honest all of these",
    "start": "1706480",
    "end": "1712690"
  },
  {
    "text": "things are really cool and everyone is really happy that we're saving money and things were paster but this wasn't",
    "start": "1712690",
    "end": "1718179"
  },
  {
    "text": "actually the main reason that we switched DCs in the first place the main reason was to make sure that if one",
    "start": "1718179",
    "end": "1723400"
  },
  {
    "text": "application broke it didn't cause other parts of coursera to go down but i'm really happy",
    "start": "1723400",
    "end": "1728530"
  },
  {
    "text": "to say that we actually did solve that problem too so I pulled this graph from a recent outage I guess that we had I",
    "start": "1728530",
    "end": "1734710"
  },
  {
    "text": "pull this from data dog and you can see each of the blue lines here represents the latency from one of our applications",
    "start": "1734710",
    "end": "1740380"
  },
  {
    "text": "and around 7:30 or so I think it was one of our back-end services that started just slowing down a lot and we can see",
    "start": "1740380",
    "end": "1746830"
  },
  {
    "text": "that the front-end application also slowed down a lot there but only one application slowed down every other",
    "start": "1746830",
    "end": "1752530"
  },
  {
    "text": "application began or kept working just as they were before they didn't know that there was any problem going on so",
    "start": "1752530",
    "end": "1759250"
  },
  {
    "text": "we're really happy that we did solve this problem and made sure that if there is some problem that happens it's contained to just the one application",
    "start": "1759250",
    "end": "1765700"
  },
  {
    "text": "that it affects and one last thing that I want to point out about this project",
    "start": "1765700",
    "end": "1771010"
  },
  {
    "text": "is that it was honestly actually pretty easy to do it only took one developer about two months or so to migrate",
    "start": "1771010",
    "end": "1777430"
  },
  {
    "text": "everything over this involves writing a whole bunch of documentation also and writing nice guides and building a nice",
    "start": "1777430",
    "end": "1782830"
  },
  {
    "text": "UI for everything honestly the ECS API is we just kind of plugged them in wherever you're launching things before everything just",
    "start": "1782830",
    "end": "1789160"
  },
  {
    "text": "pretty much worked for us so it doesn't take too much investment at all to move",
    "start": "1789160",
    "end": "1794800"
  },
  {
    "text": "to ECS but I'll say that there were a couple decisions or some things that we long learned along the way that I want",
    "start": "1794800",
    "end": "1800950"
  },
  {
    "text": "to just share with all of you one thing that you want to think about is how to scale your containers and your hosts so",
    "start": "1800950",
    "end": "1808240"
  },
  {
    "text": "I'd really recommend for your containers to just pick a single metric that you want to scale on pick either CPU usage",
    "start": "1808240",
    "end": "1814060"
  },
  {
    "text": "or memory usage and figure out which one you're most bound by as your traffic increases and just scale by that don't",
    "start": "1814060",
    "end": "1820390"
  },
  {
    "text": "over complicate things too much on your containers but for your ECS host",
    "start": "1820390",
    "end": "1825610"
  },
  {
    "text": "sometimes picking just one metric isn't enough especially because these containers can have reservations for CPU",
    "start": "1825610",
    "end": "1832360"
  },
  {
    "text": "and memory usage so you might see that you're launching five containers that each use or have a reservation for one",
    "start": "1832360",
    "end": "1838630"
  },
  {
    "text": "fifth of the memory on the host but in reality they're only actually using maybe a quarter of what they're",
    "start": "1838630",
    "end": "1844390"
  },
  {
    "text": "reserving so if you're trying to scale based on memory in that case the memory usage might only be 25% but if you tried",
    "start": "1844390",
    "end": "1851770"
  },
  {
    "text": "to launch a new container there wouldn't actually be any room on the host so actually found this great blog post that",
    "start": "1851770",
    "end": "1857680"
  },
  {
    "text": "describes a different way scale your ecs hosts and it works by computing a new metric that basically",
    "start": "1857680",
    "end": "1863890"
  },
  {
    "text": "asks at any given time how many new containers can I launch on this host so looks at the highest memory reservation",
    "start": "1863890",
    "end": "1871090"
  },
  {
    "text": "and CPU reservation and looks at how much is available on your host and then basically computes the number of new",
    "start": "1871090",
    "end": "1877390"
  },
  {
    "text": "containers you can launch at any given time and then you can use that number to scale up or down accordingly",
    "start": "1877390",
    "end": "1884040"
  },
  {
    "text": "additionally you'll want to try to find a way to automate your deployments so we ended up building kind of a homegrown",
    "start": "1886650",
    "end": "1892570"
  },
  {
    "text": "system that managed our whole deployment but there's a lot of other great utilities such as code deploy or cloud",
    "start": "1892570",
    "end": "1897700"
  },
  {
    "text": "formation that are able to manage your deployments for you you probably don't want to go into the console every time and click a whole bunch of buttons to",
    "start": "1897700",
    "end": "1903880"
  },
  {
    "text": "launch new things so these tools can actually kind of automate that entire process and then they even like you use",
    "start": "1903880",
    "end": "1910420"
  },
  {
    "text": "Bluegreen deployments so you can launch new containers and then slowly shift traffic over and then delete the old ones so there's another great blog post",
    "start": "1910420",
    "end": "1917770"
  },
  {
    "text": "here that kind of describes how to do that it has some code samples there too",
    "start": "1917770",
    "end": "1922650"
  },
  {
    "text": "another thing that we learned when we first created our containers we basically made each of them a mini",
    "start": "1923640",
    "end": "1929470"
  },
  {
    "text": "replica of what we were running on ec2 so we had our application in there but we also had some extra utilities such as",
    "start": "1929470",
    "end": "1935590"
  },
  {
    "text": "log monitoring and collection metrics collection and some security tools in there too we found that this made our",
    "start": "1935590",
    "end": "1942070"
  },
  {
    "text": "containers very heavyweight and took them a while to launch and health check and everything and it seemed a little",
    "start": "1942070",
    "end": "1947500"
  },
  {
    "text": "excessive so one technique that we've read about and actually implemented was to take all of these extra utilities and",
    "start": "1947500",
    "end": "1953590"
  },
  {
    "text": "pull them out to their own containers and then share those amongst all the different containers on the host so for",
    "start": "1953590",
    "end": "1960400"
  },
  {
    "text": "instance we're using sumo logic and we have a log collector on there but we don't need a different log collector for",
    "start": "1960400",
    "end": "1965650"
  },
  {
    "text": "each of our containers they can all just for their logs to that one container running on the host and that works fine",
    "start": "1965650",
    "end": "1970990"
  },
  {
    "text": "so that keeps our containers much smaller and they're able to launch much more quickly and one last thing that I",
    "start": "1970990",
    "end": "1978400"
  },
  {
    "text": "want to leave you with about ECS you're probably gonna have a lot of different options and how to actually size your",
    "start": "1978400",
    "end": "1983740"
  },
  {
    "text": "containers so you might want to run fewer containers that have larger usage or larger reservations or you could have",
    "start": "1983740",
    "end": "1990850"
  },
  {
    "text": "more containers that are a bit smaller honestly there's no great answer here there's no one way to do it I'd really",
    "start": "1990850",
    "end": "1997630"
  },
  {
    "text": "just recommend kind of experimenting doing some load tests see how quickly things boot up and figure out which one",
    "start": "1997630",
    "end": "2002910"
  },
  {
    "text": "works best for your application architecture and honestly I think this overall theme is kind of the approach",
    "start": "2002910",
    "end": "2008760"
  },
  {
    "text": "that we took with these yes just try things out and experiment with it and see if it works for you we didn't go",
    "start": "2008760",
    "end": "2014430"
  },
  {
    "text": "into this project knowing that we definitely wanted to use ecs for this we experimented we launched a few",
    "start": "2014430",
    "end": "2019530"
  },
  {
    "text": "containers we ran some load tests and so how things worked for us and so that ecs was a good option for us so I'd really",
    "start": "2019530",
    "end": "2025530"
  },
  {
    "text": "encourage you to just kind of give EECS to try and see how well it works for you next Lewis is going to talk a little bit",
    "start": "2025530",
    "end": "2031980"
  },
  {
    "text": "about how we put everything together with the application load balancer cool",
    "start": "2031980",
    "end": "2038790"
  },
  {
    "text": "so earlier I kind of walked through how we build applications with code build and then Brian just kind of demonstrated",
    "start": "2038790",
    "end": "2044550"
  },
  {
    "text": "how we run things with ECS but there's one more thing that we need to do",
    "start": "2044550",
    "end": "2049970"
  },
  {
    "text": "there's one more thing that we actually need to do we need to actually route requests to different URLs on",
    "start": "2052730",
    "end": "2058860"
  },
  {
    "text": "coursera.org to the actual applications running in ACS right so for instance if one of our users wants to view the",
    "start": "2058860",
    "end": "2065070"
  },
  {
    "text": "catalog and goes to coursera.org slash browse we need to make sure that request actually gets to the catalog application",
    "start": "2065070",
    "end": "2070740"
  },
  {
    "text": "running ECS so we actually knew that with their with their aptitude running",
    "start": "2070740",
    "end": "2076020"
  },
  {
    "text": "acs we needed a load balancer and that combined with the whole need of needing",
    "start": "2076020",
    "end": "2082350"
  },
  {
    "text": "to actually route these requests come to production we were actually able to satisfy these needs using application load balancer and since application load",
    "start": "2082350",
    "end": "2089520"
  },
  {
    "text": "balancer is quite the mouthful I'm gonna start referring to it as a lb for short",
    "start": "2089520",
    "end": "2095210"
  },
  {
    "text": "so quick overview of a lb lb is actually you know it's not similar but it's",
    "start": "2095210",
    "end": "2101460"
  },
  {
    "text": "actually a relatively new load balancer product that launched last year I'm I believe in August 2016 and it is part of",
    "start": "2101460",
    "end": "2107970"
  },
  {
    "text": "the LB ecosystem so I wanted to just give a quick overview just in case just",
    "start": "2107970",
    "end": "2114060"
  },
  {
    "text": "like classic load balancer alb is able to distribute traffic across multiple targets in different target groups in",
    "start": "2114060",
    "end": "2121350"
  },
  {
    "text": "different AZ's it provides support for load-balancing containers in ECS and",
    "start": "2121350",
    "end": "2127279"
  },
  {
    "text": "this is something that classic load balancer did not support and so for us using AES this was a no-brainer we had to use this but alb also comes with an",
    "start": "2127279",
    "end": "2136730"
  },
  {
    "text": "interesting feature called content based routing and it does this via listener rules and what content based routing is",
    "start": "2136730",
    "end": "2142910"
  },
  {
    "text": "is that it's actually able to look at the content of the request or at least some parts of the content of the request and figure out from that information",
    "start": "2142910",
    "end": "2150079"
  },
  {
    "text": "where that request should go and right now there are two different methods",
    "start": "2150079",
    "end": "2155329"
  },
  {
    "text": "available there's path based routing where you're actually able to inspect the URL and figure out where this request should go",
    "start": "2155329",
    "end": "2161150"
  },
  {
    "text": "and there's host based routing where you inspect the host field the host HTTP",
    "start": "2161150",
    "end": "2167690"
  },
  {
    "text": "header to figure out where to route and how many requests and so you have to set",
    "start": "2167690",
    "end": "2174140"
  },
  {
    "text": "up listener rules right the listener rules are the things that are able to match up the host header or the path",
    "start": "2174140",
    "end": "2179359"
  },
  {
    "text": "with where or question go fortunately setting up these listener roles is really easy to do you can do",
    "start": "2179359",
    "end": "2185180"
  },
  {
    "text": "these via the AWS SDK or via the CLI and we actually set up these listener roles",
    "start": "2185180",
    "end": "2190519"
  },
  {
    "text": "when we actually boot up our applications and ECS okay so that's",
    "start": "2190519",
    "end": "2195799"
  },
  {
    "text": "that's a quick al beat overview back to the problem at hand so we have many different applications running in ECS",
    "start": "2195799",
    "end": "2203589"
  },
  {
    "text": "how do we actually route requests to the correct applications so our first thought here was maybe wish use path",
    "start": "2203589",
    "end": "2210230"
  },
  {
    "text": "based routing right because there's a pretty good mapping of the path that a",
    "start": "2210230",
    "end": "2215450"
  },
  {
    "text": "user is visiting to which application should go do but as we started to try",
    "start": "2215450",
    "end": "2221150"
  },
  {
    "text": "this out we realized that path based routing was actually a little bit too limited right because things like",
    "start": "2221150",
    "end": "2227210"
  },
  {
    "text": "authentication can affect routing maybe experiments maybe for one user who's in variant a you want sent to one",
    "start": "2227210",
    "end": "2233450"
  },
  {
    "text": "application for a user in variant B wants them to another application and we've actually seen this happen where",
    "start": "2233450",
    "end": "2238460"
  },
  {
    "text": "our growth team was trying to roll out a new onboarding experience and they wanted to compare the conversion rate",
    "start": "2238460",
    "end": "2244339"
  },
  {
    "text": "between the old onboarding experience and the new onboarding experience so we actually do routing based on",
    "start": "2244339",
    "end": "2249950"
  },
  {
    "text": "experimental variant so we actually started looking at",
    "start": "2249950",
    "end": "2255650"
  },
  {
    "text": "host-based routing and what we realized is that this can actually be really flexible right and you can it can be",
    "start": "2255650",
    "end": "2261350"
  },
  {
    "text": "flexible if you're able to actually intercept the request and an edge tear and generate your own host header and so",
    "start": "2261350",
    "end": "2267650"
  },
  {
    "text": "that's actually what we did at Coursera right we we had the requests that come in hit the edge tier first the edge tier",
    "start": "2267650",
    "end": "2274550"
  },
  {
    "text": "will be able to talk to our authentication service and our experiment service and any other service he needs to talk to you to figure out or",
    "start": "2274550",
    "end": "2281000"
  },
  {
    "text": "to gather the information needs to determine whether a question go it would",
    "start": "2281000",
    "end": "2286220"
  },
  {
    "text": "compile the information and generate a proper host header that would that al B",
    "start": "2286220",
    "end": "2291920"
  },
  {
    "text": "would then be able to recognize to redirect a request to the correct set of containers for our host headers the way",
    "start": "2291920",
    "end": "2298400"
  },
  {
    "text": "we approached it was we had basically concatenated the application name with",
    "start": "2298400",
    "end": "2303590"
  },
  {
    "text": "like a version hash right and that version house was just a hash that uniquely identified the build so after",
    "start": "2303590",
    "end": "2312620"
  },
  {
    "text": "after we generate that host header we would for that to Ale be remember we have already set up listener rules on",
    "start": "2312620",
    "end": "2317840"
  },
  {
    "text": "ale beef so alb will be able to figure out okay this Hodor or this host header is something that I recognize I'm going",
    "start": "2317840",
    "end": "2323810"
  },
  {
    "text": "to afford this request along to the proper locate target and so then we'd",
    "start": "2323810",
    "end": "2329390"
  },
  {
    "text": "have a bunch of targets that are ready to set this request more concretely in the example of the catalog if a user",
    "start": "2329390",
    "end": "2336290"
  },
  {
    "text": "visits hits our site trying to visit the Browse page edge would generate a host",
    "start": "2336290",
    "end": "2342020"
  },
  {
    "text": "header in this case catalog - a380 F which is the version for that along to a",
    "start": "2342020",
    "end": "2348170"
  },
  {
    "text": "lb and a lb would know how to actually for this request along to our catalog cluster running in UCS so there's this",
    "start": "2348170",
    "end": "2362840"
  },
  {
    "text": "is so we're done here right we've set up routing for our production services but there's something else that our developers are asking for our developers",
    "start": "2362840",
    "end": "2369470"
  },
  {
    "text": "actually wanted to be able to preview changes that they were working on in a production like environment so kind of",
    "start": "2369470",
    "end": "2375590"
  },
  {
    "text": "like a staging environment so we want to see if this is possible to do with alb",
    "start": "2375590",
    "end": "2381310"
  },
  {
    "text": "so we looked into a little bit more and we noticed that okay so we already have",
    "start": "2381310",
    "end": "2386570"
  },
  {
    "text": "our catalog cluster running an ale let's say to developers Alice and Bob are both working on catalog features",
    "start": "2386570",
    "end": "2393380"
  },
  {
    "text": "Alice has two branches catalog feature a one on catalog feature a two and Bob has",
    "start": "2393380",
    "end": "2398719"
  },
  {
    "text": "catalog feature be one feature be two so",
    "start": "2398719",
    "end": "2403880"
  },
  {
    "text": "what we realized was that just by changing our build process to trigger on",
    "start": "2403880",
    "end": "2409099"
  },
  {
    "text": "pull requests as well we could then spin up spin up containers running",
    "start": "2409099",
    "end": "2414979"
  },
  {
    "text": "development branch code I'm side by side with their production clusters and then",
    "start": "2414979",
    "end": "2422839"
  },
  {
    "text": "when we go back to this when we go back to this picture we're able to then when",
    "start": "2422839",
    "end": "2428930"
  },
  {
    "text": "we go back to this picture by default even though Alice and Alice request the catalog page we get the production",
    "start": "2428930",
    "end": "2434660"
  },
  {
    "text": "version she's actually able to specify an override so she can ask for catalog",
    "start": "2434660",
    "end": "2441109"
  },
  {
    "text": "zxw and again edgewood generate the proper host header before that's alb and",
    "start": "2441109",
    "end": "2447769"
  },
  {
    "text": "then LB would then be able to redirect that to her preview build Bob can do the same thing and request bz4 and",
    "start": "2447769",
    "end": "2454670"
  },
  {
    "text": "throughout this whole process he would be able to view his changes and they can",
    "start": "2454670",
    "end": "2461359"
  },
  {
    "text": "toggle between these pretty easily right if you set up an override in the via like a cookie or a header and edie the",
    "start": "2461359",
    "end": "2467779"
  },
  {
    "text": "edge tier understands that then it's something that they can just switch very quickly in their browsers using some",
    "start": "2467779",
    "end": "2473150"
  },
  {
    "text": "development tools so this was really",
    "start": "2473150",
    "end": "2479209"
  },
  {
    "text": "cool because we were able to use al B to do something that maybe it wasn't necessarily designed for but through it",
    "start": "2479209",
    "end": "2485779"
  },
  {
    "text": "we were actually able to set up a staging environment but there were some limitations that I want to make you guys",
    "start": "2485779",
    "end": "2491449"
  },
  {
    "text": "kind of aware of actually one of the limitations that we ran into was that",
    "start": "2491449",
    "end": "2496549"
  },
  {
    "text": "the max number of listener rules you can set up at al B is a hundred and given that we have 50 apps and we might want",
    "start": "2496549",
    "end": "2502459"
  },
  {
    "text": "to have a bunch of preview builds for these our listener rules could quickly get out of hand so we had to actually clean these up as we were going along",
    "start": "2502459",
    "end": "2509890"
  },
  {
    "text": "and there are other kind of hard limits that exist I would recommend checking the documentation if you're looking to",
    "start": "2509890",
    "end": "2516109"
  },
  {
    "text": "design kind of a solution like we have here and just make sure that your solution works well within these",
    "start": "2516109",
    "end": "2523060"
  },
  {
    "text": "limitations another limitation that we ran into was that we do Bluegreen",
    "start": "2523060",
    "end": "2529840"
  },
  {
    "text": "deployments and something that we want to be able to do is slowly shift traffic from an older version to a new version but alb does not support traffic waiting",
    "start": "2529840",
    "end": "2536920"
  },
  {
    "text": "out of the box fortunately for us this was actually pretty easy to for us to implement in our edge tier so that's",
    "start": "2536920",
    "end": "2543610"
  },
  {
    "text": "just something to keep in mind if you guys are looking to do something very similar and so that's all I got for alb",
    "start": "2543610",
    "end": "2550420"
  },
  {
    "text": "brand Xena do a quick recap of what we went over today thanks yes we don't",
    "start": "2550420",
    "end": "2557050"
  },
  {
    "text": "actually we have a piece amount of time left we'll have some time for questions after but just real quickly kind of what we went over today so as Lewis first",
    "start": "2557050",
    "end": "2564280"
  },
  {
    "text": "mentioned you can really use AWS code build to scale your build environment on demand and we really like the pricing",
    "start": "2564280",
    "end": "2570460"
  },
  {
    "text": "model here where you're only paying for what you're actually using you don't have to worry about idle instances sitting around costing you money you can",
    "start": "2570460",
    "end": "2576880"
  },
  {
    "text": "really take advantage of this elasticity then we spoke a little bit about ECS and how it really lets you keep all of your",
    "start": "2576880",
    "end": "2582880"
  },
  {
    "text": "applications independent without having to worry about problems with multi-tenancy but it also keeps the cost",
    "start": "2582880",
    "end": "2588370"
  },
  {
    "text": "down by letting you run a lot of things on a single UC to host and you're able to scale a lot faster to lastly Lewis",
    "start": "2588370",
    "end": "2596470"
  },
  {
    "text": "just mentioned how a elby's can be used in a lot of different creative ways to maybe build staging environments or some",
    "start": "2596470",
    "end": "2602200"
  },
  {
    "text": "other cool ideas that you have for different creative ways to route things so that's actually all that we have now",
    "start": "2602200",
    "end": "2608350"
  },
  {
    "text": "we have geese amount of time if anyone has questions we'll we will ask them here now and then we'll be over here",
    "start": "2608350",
    "end": "2614920"
  },
  {
    "text": "later to talk a little bit more thanks everyone",
    "start": "2614920",
    "end": "2618990"
  }
]
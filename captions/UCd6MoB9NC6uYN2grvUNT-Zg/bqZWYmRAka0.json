[
  {
    "text": "- Hi, I'm Gerardo, from AWS",
    "start": "450",
    "end": "1923"
  },
  {
    "text": "- Hi, Jinjun, from DBS,\nthis is \"My Architecture.\"",
    "start": "3030",
    "end": "7444"
  },
  {
    "text": "- Today we're gonna talk about",
    "start": "16440",
    "end": "17430"
  },
  {
    "text": "DBS Banks' quantitative pricing engine.",
    "start": "17430",
    "end": "20670"
  },
  {
    "text": "What can you tell me\nabout this application?",
    "start": "20670",
    "end": "22710"
  },
  {
    "text": "- DBS is one of the largest bank in Asia.",
    "start": "22710",
    "end": "25800"
  },
  {
    "text": "We are providing variety\nof financial services",
    "start": "25800",
    "end": "28230"
  },
  {
    "text": "to our customers, including\ntrading companies.",
    "start": "28230",
    "end": "30990"
  },
  {
    "text": "Quantitative pricing engine\nis one of the systems",
    "start": "30990",
    "end": "33329"
  },
  {
    "text": "that we build in-house\non top of AW Services",
    "start": "33330",
    "end": "36630"
  },
  {
    "text": "for processing highly dynamic workload.",
    "start": "36630",
    "end": "40560"
  },
  {
    "text": "- Okay, let's dive in.",
    "start": "40560",
    "end": "42030"
  },
  {
    "text": "So how do the traders\ninteract with the application?",
    "start": "42030",
    "end": "45539"
  },
  {
    "text": "- The traders will initially\ntrigger the pricing",
    "start": "45540",
    "end": "48810"
  },
  {
    "text": "from DBS internal trading platform,",
    "start": "48810",
    "end": "51120"
  },
  {
    "text": "taking the external data",
    "start": "51120",
    "end": "52539"
  },
  {
    "text": "to the application load balancer,",
    "start": "53400",
    "end": "55050"
  },
  {
    "text": "application load balancer\nwill further traffic",
    "start": "55050",
    "end": "57180"
  },
  {
    "text": "into pricing engine.",
    "start": "57180",
    "end": "58650"
  },
  {
    "text": "Pricing engine will store the\naccurate payload into Redis",
    "start": "58650",
    "end": "63150"
  },
  {
    "text": "and get the job ID\nstored in the task queue.",
    "start": "63150",
    "end": "66480"
  },
  {
    "text": "- I'm guessing, a subset\nof that market data",
    "start": "66480",
    "end": "69810"
  },
  {
    "text": "gets into the payload",
    "start": "69810",
    "end": "71430"
  },
  {
    "text": "and then these are these queues\nbeing pulled by the workers.",
    "start": "71430",
    "end": "74910"
  },
  {
    "text": "- The trade information\nas well as market data",
    "start": "74910",
    "end": "76890"
  },
  {
    "text": "will stored in the payload.",
    "start": "76890",
    "end": "78330"
  },
  {
    "text": "The worker will monitor a task queue.",
    "start": "78330",
    "end": "80700"
  },
  {
    "text": "The CPU worker once found\nthe task queue has some item,",
    "start": "80700",
    "end": "85590"
  },
  {
    "text": "will pop one and put\ninto the processing queue",
    "start": "85590",
    "end": "88710"
  },
  {
    "text": "and then the pricing worker will retrieve",
    "start": "88710",
    "end": "92850"
  },
  {
    "text": "that payload from Redis",
    "start": "92850",
    "end": "94590"
  },
  {
    "text": "and get a payload, go\nthrough a mathematic mutation",
    "start": "94590",
    "end": "98310"
  },
  {
    "text": "and produce the result and store\nback the result into Redis.",
    "start": "98310",
    "end": "101939"
  },
  {
    "text": "- I can see you have two different\ntypes of pricing workers.",
    "start": "101940",
    "end": "104640"
  },
  {
    "text": "Why is that?",
    "start": "104640",
    "end": "105473"
  },
  {
    "text": "- Some of the job itself",
    "start": "105473",
    "end": "106860"
  },
  {
    "text": "had a high competition power intensity,",
    "start": "106860",
    "end": "110700"
  },
  {
    "text": "so we are actually\nleveraging the GPU instances",
    "start": "110700",
    "end": "113549"
  },
  {
    "text": "to do acceleration in case CPU",
    "start": "113550",
    "end": "115890"
  },
  {
    "text": "is not able to process in time.",
    "start": "115890",
    "end": "118740"
  },
  {
    "text": "So similarly will the GPU worker",
    "start": "118740",
    "end": "122049"
  },
  {
    "text": "will monitor the task queue\nfor dedicated GPU task queue",
    "start": "122910",
    "end": "127200"
  },
  {
    "text": "and pop one into the GPU processing queue",
    "start": "127200",
    "end": "131370"
  },
  {
    "text": "and retrieve the payload in from the Redis",
    "start": "131370",
    "end": "135629"
  },
  {
    "text": "and similarly do the computation",
    "start": "135630",
    "end": "137340"
  },
  {
    "text": "and save the result back into Redis.",
    "start": "137340",
    "end": "139800"
  },
  {
    "text": "- How spiky are these workloads?",
    "start": "139800",
    "end": "142980"
  },
  {
    "text": "Are they on auto scaling groups?",
    "start": "142980",
    "end": "144569"
  },
  {
    "text": "- Yes, they are on auto scaling group.",
    "start": "144570",
    "end": "147150"
  },
  {
    "text": "The pricing engine, the worker\nfor two CPU and GPU cluster,",
    "start": "147150",
    "end": "152150"
  },
  {
    "text": "they're all in a different\nautoscaling group",
    "start": "152340",
    "end": "154680"
  },
  {
    "text": "and sometimes they can even\nscale up to 5,000 workers.",
    "start": "154680",
    "end": "159540"
  },
  {
    "text": "- That's a lot of workers.\n- Yes, they are.",
    "start": "159540",
    "end": "161790"
  },
  {
    "text": "- How do you optimize cost of that?",
    "start": "161790",
    "end": "163769"
  },
  {
    "text": "- One way is actually\nby autoscale them down",
    "start": "163770",
    "end": "167370"
  },
  {
    "text": "in case there's no much job per se.",
    "start": "167370",
    "end": "170580"
  },
  {
    "text": "On top of that, we're also\nleveraging the spot instance",
    "start": "170580",
    "end": "173190"
  },
  {
    "text": "to reduce cost.",
    "start": "173190",
    "end": "174390"
  },
  {
    "text": "- All right, and what happens next?",
    "start": "174390",
    "end": "175500"
  },
  {
    "text": "So after the results being\nstored in the payload,",
    "start": "175500",
    "end": "178830"
  },
  {
    "text": "how does that get back to the traders?",
    "start": "178830",
    "end": "180780"
  },
  {
    "text": "- Yeah, that's a very good question.",
    "start": "180780",
    "end": "182190"
  },
  {
    "text": "We have two mechanism to get\nthe result back into traders.",
    "start": "182190",
    "end": "185310"
  },
  {
    "text": "One is the pricing engine.",
    "start": "185310",
    "end": "186870"
  },
  {
    "text": "We do fairly pulling from Redis",
    "start": "186870",
    "end": "189480"
  },
  {
    "text": "to see whether the result is available.",
    "start": "189480",
    "end": "191310"
  },
  {
    "text": "On the second approach,\nwe actually trigger",
    "start": "191310",
    "end": "195090"
  },
  {
    "text": "result available from the worker",
    "start": "195090",
    "end": "197910"
  },
  {
    "text": "and publishing the popup channel.",
    "start": "197910",
    "end": "199893"
  },
  {
    "text": "Then the popup channel will get notified",
    "start": "200760",
    "end": "204269"
  },
  {
    "text": "to the pricing engine",
    "start": "204270",
    "end": "205740"
  },
  {
    "text": "and the pricing engine\nwill return that result",
    "start": "205740",
    "end": "207690"
  },
  {
    "text": "back to the traders.",
    "start": "207690",
    "end": "210000"
  },
  {
    "text": "- Could you tell me why you're\nusing Elastic Edge for Redis",
    "start": "210000",
    "end": "213990"
  },
  {
    "text": "for all of this functionality?",
    "start": "213990",
    "end": "215280"
  },
  {
    "text": "- Yeah, the Redis was pick\nthe fundamental reason",
    "start": "215280",
    "end": "218970"
  },
  {
    "text": "because it's a performance\nin terms of saving",
    "start": "218970",
    "end": "221273"
  },
  {
    "text": "as well as retrieving the data.",
    "start": "221273",
    "end": "223950"
  },
  {
    "text": "On top of that it providing\nthe popup feature,",
    "start": "223950",
    "end": "226200"
  },
  {
    "text": "which is add on, and we just leverage that",
    "start": "226200",
    "end": "228750"
  },
  {
    "text": "to improve the performance as well.",
    "start": "228750",
    "end": "230550"
  },
  {
    "text": "- And why using popup for this final step",
    "start": "230550",
    "end": "233670"
  },
  {
    "text": "instead of just pulling a queue?",
    "start": "233670",
    "end": "235590"
  },
  {
    "text": "- So pulling a queue\nmay have a certain lag",
    "start": "235590",
    "end": "238560"
  },
  {
    "text": "because even talk about 100 millisecond",
    "start": "238560",
    "end": "241440"
  },
  {
    "text": "or 10s of millisecond, that's still a gap.",
    "start": "241440",
    "end": "244800"
  },
  {
    "text": "So instead of doing that,",
    "start": "244800",
    "end": "246270"
  },
  {
    "text": "the worker can just publish saying,",
    "start": "246270",
    "end": "248047"
  },
  {
    "text": "\"Hey, my result is available.\"",
    "start": "248047",
    "end": "249720"
  },
  {
    "text": "Then the pricing engine\nwill pick up from there.",
    "start": "249720",
    "end": "252660"
  },
  {
    "text": "- Right, so, I can see how\nall of these architectures",
    "start": "252660",
    "end": "255720"
  },
  {
    "text": "being optimized for speed.",
    "start": "255720",
    "end": "257280"
  },
  {
    "text": "And I'm presuming those\npricing requests from traders",
    "start": "257280",
    "end": "260519"
  },
  {
    "text": "are quite time sensitive sometimes.",
    "start": "260520",
    "end": "262680"
  },
  {
    "text": "- Yes, they are.",
    "start": "262680",
    "end": "264180"
  },
  {
    "text": "The trader are actually\nexpecting for ad hoc pricing",
    "start": "264180",
    "end": "268139"
  },
  {
    "text": "to be near real time.",
    "start": "268140",
    "end": "270270"
  },
  {
    "text": "So they are on the spot with pricing,",
    "start": "270270",
    "end": "273147"
  },
  {
    "text": "expecting to come back\nto them immediately.",
    "start": "273147",
    "end": "275130"
  },
  {
    "text": "So previously we have this\nin the on-prem cluster.",
    "start": "275130",
    "end": "279600"
  },
  {
    "text": "The pricing is actually\nrunning in two minutes.",
    "start": "279600",
    "end": "281910"
  },
  {
    "text": "Now with this new architecture,",
    "start": "281910",
    "end": "283560"
  },
  {
    "text": "we actually reduce the timing\nto nearly half a second.",
    "start": "283560",
    "end": "287820"
  },
  {
    "text": "So it's almost like 100 times improvement",
    "start": "287820",
    "end": "290220"
  },
  {
    "text": "in terms of performance.",
    "start": "290220",
    "end": "291420"
  },
  {
    "text": "- It's a massive performance boost.",
    "start": "291420",
    "end": "293220"
  },
  {
    "text": "- Yes it is.",
    "start": "293220",
    "end": "294233"
  },
  {
    "text": "- Jinjun, thank you so much",
    "start": "294233",
    "end": "295680"
  },
  {
    "text": "for sharing this\narchitecture with us today.",
    "start": "295680",
    "end": "297690"
  },
  {
    "text": "- Thank you.",
    "start": "297690",
    "end": "298740"
  },
  {
    "text": "- And thank you for watching\n\"This is My Architecture.\"",
    "start": "298740",
    "end": "301020"
  },
  {
    "text": "See you next time.",
    "start": "301020",
    "end": "302356"
  },
  {
    "text": "- Thank you.",
    "start": "302356",
    "end": "303436"
  }
]
[
  {
    "start": "0",
    "end": "95000"
  },
  {
    "text": "alright everybody let's get started welcome to session debt 309 best",
    "start": "30",
    "end": "5040"
  },
  {
    "text": "practices for migrating from oracle and sequel server to amazon RDS my name is",
    "start": "5040",
    "end": "11070"
  },
  {
    "text": "kevin durand I'm a product manager working on Aurora Postgres and I'm working today with John Winfred who's a",
    "start": "11070",
    "end": "17310"
  },
  {
    "text": "product manager in the AWS database services team who spends a lot of his time on database migrations and John's",
    "start": "17310",
    "end": "23910"
  },
  {
    "text": "going to come up a little later the second part of this session so first off thanks for taking your time and you're",
    "start": "23910",
    "end": "30599"
  },
  {
    "text": "busy reinvents to this session especially Monday at 7 o'clock actually",
    "start": "30599",
    "end": "38040"
  },
  {
    "text": "excited to see how many people are here I didn't expect this many at this hour",
    "start": "38040",
    "end": "44239"
  },
  {
    "text": "sorry that's going to be me okay now I'm",
    "start": "44239",
    "end": "51420"
  },
  {
    "text": "back okay but I'd like to get a feel for who's here and kind of your use of",
    "start": "51420",
    "end": "56670"
  },
  {
    "text": "databases so like to see a show of hands first off who here is using Microsoft",
    "start": "56670",
    "end": "61859"
  },
  {
    "text": "sequel server Wow a lot of sequel server users okay and who here is using Oracle",
    "start": "61859",
    "end": "67740"
  },
  {
    "text": "I guess I should ask who here is using both yeah okay yeah maybe not too much",
    "start": "67740",
    "end": "75780"
  },
  {
    "text": "of a surprise okay and now different different databases who's using my sequel okay and finally of course who's",
    "start": "75780",
    "end": "84869"
  },
  {
    "text": "using Postgres all right",
    "start": "84869",
    "end": "89960"
  },
  {
    "text": "a debase really no we're not gonna go that far back in the past um all right",
    "start": "90170",
    "end": "96140"
  },
  {
    "start": "95000",
    "end": "171000"
  },
  {
    "text": "so have a feel for who's here and and and what kinds of databases you're using and I'll try to leave time at the end",
    "start": "96140",
    "end": "103610"
  },
  {
    "text": "for questions specific to your migration scenarios from all these different databases to all your different favorite",
    "start": "103610",
    "end": "109789"
  },
  {
    "text": "targets but what we plan to cover today is - first off just talk about what RDS",
    "start": "109789",
    "end": "115009"
  },
  {
    "text": "is Amazon relational database service I'm not going to spend a lot of time on that but just want to give a brief",
    "start": "115009",
    "end": "120049"
  },
  {
    "text": "overview and then I'll talk about homogeneous migrations migrations from",
    "start": "120049",
    "end": "126140"
  },
  {
    "text": "Oracle and sequel server on-premises or an ec2 - their RDS equivalents and then",
    "start": "126140",
    "end": "133549"
  },
  {
    "text": "we'll dive into the possibilities of migrating those databases to other databases such as my sequel or Postgres",
    "start": "133549",
    "end": "139400"
  },
  {
    "text": "or Amazon or Ora and then John will take over and he'll dive in into how to use",
    "start": "139400",
    "end": "144920"
  },
  {
    "text": "AWS database migration service schema conversion tool and related services to",
    "start": "144920",
    "end": "150830"
  },
  {
    "text": "help do those migrations and then of course we'll wrap up with a look at some detail best practices and of course",
    "start": "150830",
    "end": "157220"
  },
  {
    "text": "we'll get into some Q&A so before we get",
    "start": "157220",
    "end": "163730"
  },
  {
    "text": "into the all these nitty gritty details let's talk about migrating databases to AWS from on-premises environments and",
    "start": "163730",
    "end": "171350"
  },
  {
    "start": "171000",
    "end": "230000"
  },
  {
    "text": "the first question to answer is well why migrate databases to the cloud in the first place and our customers have",
    "start": "171350",
    "end": "178160"
  },
  {
    "text": "helped us answer this question and lots of different ways over the years and their answers generally fall into these",
    "start": "178160",
    "end": "183470"
  },
  {
    "text": "three categories they want to reduce costs by moving their IT costs from",
    "start": "183470",
    "end": "188480"
  },
  {
    "text": "capex from buying and maintaining hardware and software and data center power space and cooling etc to optics",
    "start": "188480",
    "end": "196340"
  },
  {
    "text": "where you pay as you go you pay for what you use rather than purchasing for peak usage and carrying that cost the whole",
    "start": "196340",
    "end": "202340"
  },
  {
    "text": "time customers also want to simplify operations by moving the responsibility",
    "start": "202340",
    "end": "207620"
  },
  {
    "text": "for maintaining data centers and servers and networking and storage and software as much as possible - AWS to us and and",
    "start": "207620",
    "end": "216739"
  },
  {
    "text": "they want to increase flexibility and agility by freeing themselves up to focus on what score for their cut",
    "start": "216739",
    "end": "223610"
  },
  {
    "text": "for their businesses and for their customers rather than spending time on all all that boring stuff but the",
    "start": "223610",
    "end": "231710"
  },
  {
    "start": "230000",
    "end": "295000"
  },
  {
    "text": "previous slide really just scratches the surface of the benefits of moving your databases to AWS with Amazon relational",
    "start": "231710",
    "end": "240020"
  },
  {
    "text": "database service RDS we take things a big step further by automating most of the boring repetitive day-to-day",
    "start": "240020",
    "end": "246320"
  },
  {
    "text": "drudgery of running relational databases this means RDS automatically monitors your database instances and will replace",
    "start": "246320",
    "end": "253400"
  },
  {
    "text": "or recover an instance which fails due to software or hardware failures and RDS",
    "start": "253400",
    "end": "260030"
  },
  {
    "text": "will automatically take backups of your databases and retain those backups for up to 35 days that's up to you how long",
    "start": "260030",
    "end": "265610"
  },
  {
    "text": "we retain backups RDS can also provide automatic and transparent high availability with RDS multi a-z which",
    "start": "265610",
    "end": "273710"
  },
  {
    "text": "one enabled will automatically create a second copy of your database and a separate availability zone and keep it",
    "start": "273710",
    "end": "279890"
  },
  {
    "text": "in sync with your primary database with synchronous replication and RDS provides",
    "start": "279890",
    "end": "285500"
  },
  {
    "text": "these benefits for multiple database engines including my sequel Postgres Oracle's sequel server Umbria DB and",
    "start": "285500",
    "end": "292040"
  },
  {
    "text": "Amazon Aurora now to help visualize the",
    "start": "292040",
    "end": "297350"
  },
  {
    "text": "benefits of moving your databases to Amazon RDS let's look at the stack of",
    "start": "297350",
    "end": "303800"
  },
  {
    "text": "activities you're responsible for when running your databases on-premises this stack includes everything from the",
    "start": "303800",
    "end": "309710"
  },
  {
    "text": "basics of data centers power space cooling racks of servers and storage and networking gear and then installing and",
    "start": "309710",
    "end": "316790"
  },
  {
    "text": "maintaining the software and the firmware on each device and ensuring they're kept in sync with each other for",
    "start": "316790",
    "end": "322970"
  },
  {
    "text": "compatibility and ensuring you have the latest patches installed to protect against security vulnerabilities and so",
    "start": "322970",
    "end": "329960"
  },
  {
    "text": "on up the stack through higher-level responsibilities such as taking database backups and setting up and maintaining",
    "start": "329960",
    "end": "335950"
  },
  {
    "text": "replication for scale-out and high availability and last but not least working with your application",
    "start": "335950",
    "end": "341870"
  },
  {
    "text": "development teams to ensure they're building apps that make optimal use of your database infrastructure and",
    "start": "341870",
    "end": "347900"
  },
  {
    "text": "ensuring that you are providing the database infrastructure they need to move fast",
    "start": "347900",
    "end": "353080"
  },
  {
    "text": "and that looks and feels like a lot to do and not very much of this picture core and unique to your business is it",
    "start": "353080",
    "end": "360159"
  },
  {
    "text": "and so if you decide well great I want to move my databases into AWS you might",
    "start": "360159",
    "end": "367339"
  },
  {
    "start": "361000",
    "end": "406000"
  },
  {
    "text": "decide to move them onto ec2 where you'll provision some ec2 compute instances provision some storage from",
    "start": "367339",
    "end": "374330"
  },
  {
    "text": "EBS and you'll install some database software and you'll manage it yourself and that will save you some of that",
    "start": "374330",
    "end": "381679"
  },
  {
    "text": "boring drudgery all the stuff that's moved over to the right on this slide so you know managing",
    "start": "381679",
    "end": "387229"
  },
  {
    "text": "the data center side of things you have now moved on to AWS but you're still responsible for all that stuff on the",
    "start": "387229",
    "end": "392779"
  },
  {
    "text": "left the OS patches and installing database software and patching database software and doing backups and setting",
    "start": "392779",
    "end": "398869"
  },
  {
    "text": "up replication and H a and dr and all that other fun stuff and oh by the way you still have to work with the",
    "start": "398869",
    "end": "404719"
  },
  {
    "text": "application teams too so if you move your databases into Amazon RDS you move",
    "start": "404719",
    "end": "411409"
  },
  {
    "text": "almost everything over to the right over to AWS and you are left with the stuff",
    "start": "411409",
    "end": "417679"
  },
  {
    "text": "that's the most important thing for you and your customers app application optimization optimizing your database",
    "start": "417679",
    "end": "424459"
  },
  {
    "text": "infrastructure to run your applications in the best way possible and give your",
    "start": "424459",
    "end": "429469"
  },
  {
    "text": "application development teams the best environments in which to innovate and to grow your apps so now let's talk about",
    "start": "429469",
    "end": "439699"
  },
  {
    "start": "437000",
    "end": "491000"
  },
  {
    "text": "homogeneous migrations let's say you're running Oracle or Microsoft sequel server on-premises and you're excited",
    "start": "439699",
    "end": "446179"
  },
  {
    "text": "about all these benefits I just covered and you want to migrate to Amazon RDS to",
    "start": "446179",
    "end": "451339"
  },
  {
    "text": "move into the cloud you have lots of choices as you probably realized you can move your databases to self-manage ec2",
    "start": "451339",
    "end": "456919"
  },
  {
    "text": "like we just talked about you can move your databases to Amazon RDS for Oracle",
    "start": "456919",
    "end": "462139"
  },
  {
    "text": "or RDS for sequel server or you can migrate from Oracle or sequel server to my sequel Postgres or the my sequel or",
    "start": "462139",
    "end": "468860"
  },
  {
    "text": "Postgres compatible editions of Amazon Aurora and of course he can mix and match your strategy so you don't need to",
    "start": "468860",
    "end": "475249"
  },
  {
    "text": "move all the of your databases to one target you can separate things out and you have lots of different choices well",
    "start": "475249",
    "end": "481849"
  },
  {
    "text": "let's say you choose the simplest pass for path first and you decide to migrate your on-premises Oracle or sequel server",
    "start": "481849",
    "end": "487550"
  },
  {
    "text": "databases to self-manage - ec2 hosted databases in that scenario you can move your data",
    "start": "487550",
    "end": "494090"
  },
  {
    "start": "491000",
    "end": "537000"
  },
  {
    "text": "using the native tools available with each database engine including back file import sequel server or various tools",
    "start": "494090",
    "end": "501440"
  },
  {
    "text": "including sequel developer data pump import export arm and backups etcetera for Oracle and note that Armen backups",
    "start": "501440",
    "end": "508280"
  },
  {
    "text": "can't be used to migrate into RDS for Oracle but you can move them use them to migrate into Oracle on ec2 and of course",
    "start": "508280",
    "end": "515510"
  },
  {
    "text": "if you're running my sequel or Postgres on-premises then you can use tools native to those database engines to move",
    "start": "515510",
    "end": "521750"
  },
  {
    "text": "into self-managed on ec2 or you can move redraw use read replicas to migrate my",
    "start": "521750",
    "end": "527900"
  },
  {
    "text": "sequel into RDS for my sequel and PG Delta PG restore Postgres specific tools to migrate post res into RDS for",
    "start": "527900",
    "end": "534980"
  },
  {
    "text": "Postgres now I've talked about the",
    "start": "534980",
    "end": "540800"
  },
  {
    "start": "537000",
    "end": "578000"
  },
  {
    "text": "benefits of using RDS to manage your databases for all the engines supported in RDS but what about the benefits",
    "start": "540800",
    "end": "547880"
  },
  {
    "text": "specific to Oracle and sequel server the major areas supported by RDS are listed",
    "start": "547880",
    "end": "553550"
  },
  {
    "text": "on this slide they include the same benefits as for all the engines fast provisioning built-in security easy",
    "start": "553550",
    "end": "560450"
  },
  {
    "text": "configuration of high availability and easy scaling of both storage and compute and for both engines we also support",
    "start": "560450",
    "end": "566810"
  },
  {
    "text": "bring your own license or be IOL and license included licensing models and of",
    "start": "566810",
    "end": "572810"
  },
  {
    "text": "course specific release releases and additions for both engines now some more",
    "start": "572810",
    "end": "579590"
  },
  {
    "text": "specifics on RDS for Oracle's some recently shipped features for RDS for Oracle include support for the latest",
    "start": "579590",
    "end": "585530"
  },
  {
    "text": "release of Oracle Enterprise Manager support for Oracle spatial and Apex version 5 support for more instance",
    "start": "585530",
    "end": "592040"
  },
  {
    "text": "types to give you more flexibility in compute and memory capacities and support for up to 16 terabytes of",
    "start": "592040",
    "end": "597680"
  },
  {
    "text": "storage up from the previous RDS limit of 6 terabytes now for sequel server",
    "start": "597680",
    "end": "604280"
  },
  {
    "start": "602000",
    "end": "649000"
  },
  {
    "text": "we've recently shipped support for forced SSL which allows you to force all connections to be secure to use SSL",
    "start": "604280",
    "end": "611150"
  },
  {
    "text": "we've also added inclusion in our baa to allow you to use RDS for sequel server in the HIPAA compliant environments and",
    "start": "611150",
    "end": "617780"
  },
  {
    "text": "note that now all RDS engines including both Aurora engine are now part of the BAA and so therefore",
    "start": "617780",
    "end": "624770"
  },
  {
    "text": "all RTS engines are eligible for HIPAA compliant environments we've also done an expansion of the regions where you",
    "start": "624770",
    "end": "630770"
  },
  {
    "text": "can provision sequel server Enterprise Edition and we've added storage scaling up to 16 terabytes the previous limit",
    "start": "630770",
    "end": "637370"
  },
  {
    "text": "for sequel server was 4 terabytes and we've added support for more instance types so he continuing to add more",
    "start": "637370",
    "end": "643670"
  },
  {
    "text": "capabilities for both RDS for Oracle and RDS sequel server inside the RDS environments now I've talked to about",
    "start": "643670",
    "end": "651800"
  },
  {
    "start": "649000",
    "end": "675000"
  },
  {
    "text": "some of the capabilities of RDS for Oracle and sequel server and in a few minutes John is going to dive into",
    "start": "651800",
    "end": "657280"
  },
  {
    "text": "deeper details on how to migrate from those databases on-premises and RDS but",
    "start": "657280",
    "end": "662870"
  },
  {
    "text": "before we go there I want to talk about heterogeneous migrations moving from Oracle and sequel server to open source",
    "start": "662870",
    "end": "668840"
  },
  {
    "text": "databases and RDS including both the standard open source engines and the Amazon aurora engines and the first",
    "start": "668840",
    "end": "677030"
  },
  {
    "start": "675000",
    "end": "756000"
  },
  {
    "text": "question to answer is why migrate from oracle or sequel server to open source isn't that a lot of work you know don't",
    "start": "677030",
    "end": "684230"
  },
  {
    "text": "I have to change my schemas and my data and my stored procedures and my app code or my triggers and the operational procedures and all that stuff and the",
    "start": "684230",
    "end": "691160"
  },
  {
    "text": "answer is yes it can be a lot of work but many customers are very motivated to go through that transition for a variety",
    "start": "691160",
    "end": "697610"
  },
  {
    "text": "of reasons including the need to reduce licensing costs Oracle and sequel server are good database engines but they are",
    "start": "697610",
    "end": "704120"
  },
  {
    "text": "very expensive and customers are always looking for ways to reduce costs and",
    "start": "704120",
    "end": "709720"
  },
  {
    "text": "replacing expensive commercial database license with open source engines which have no licensing costs is a compelling",
    "start": "709720",
    "end": "716750"
  },
  {
    "text": "opportunity for many customers but what many customers find even more compelling is moving from on-premises traditional",
    "start": "716750",
    "end": "724910"
  },
  {
    "text": "legacy databases to cloud optimized open source databases they see opportunities",
    "start": "724910",
    "end": "730070"
  },
  {
    "text": "to rethink and rearch attacked their monolithic on-premises apps to take",
    "start": "730070",
    "end": "735440"
  },
  {
    "text": "advantage of the wide range of data processing and data management capabilities in AWS where we've",
    "start": "735440",
    "end": "741950"
  },
  {
    "text": "optimized different services for different use cases and the RDS open source engines especially Aurora are",
    "start": "741950",
    "end": "748790"
  },
  {
    "text": "engineered to make it easy for you to start that journey towards a more nimble more flexible and more agile environment",
    "start": "748790",
    "end": "756040"
  },
  {
    "start": "756000",
    "end": "805000"
  },
  {
    "text": "so a brief history of my sequel a little more detail about where my sequel came from and why our customers love both of",
    "start": "756040",
    "end": "763850"
  },
  {
    "text": "the my sequel services already asked for my sequel and Aurora my sequel most people recognize my sequel as the most",
    "start": "763850",
    "end": "770240"
  },
  {
    "text": "commonly used relational database out there given its prominence in the lamp stack that became popular starting in",
    "start": "770240",
    "end": "777500"
  },
  {
    "text": "the late 1990s where the emaan lamp of course stands for my sequel and it's",
    "start": "777500",
    "end": "782810"
  },
  {
    "text": "Linux and Apache and Python is the other letters in the acronym and so my sequel",
    "start": "782810",
    "end": "790550"
  },
  {
    "text": "is a first engine we launched with RDS back in 2009 now there are multiple variants today popular variants",
    "start": "790550",
    "end": "796940"
  },
  {
    "text": "including Maria DB which we also support and RDS and Aurora my sequel and I'll",
    "start": "796940",
    "end": "802610"
  },
  {
    "text": "talk a little bit more about Aurora in a couple minutes now for postcards is a different history postcards was started",
    "start": "802610",
    "end": "808640"
  },
  {
    "start": "805000",
    "end": "933000"
  },
  {
    "text": "in 1996 as the outgrowth of essentially a graduate research project at UC Berkeley and unlike my sequel postcards",
    "start": "808640",
    "end": "816860"
  },
  {
    "text": "is not owned by a company you can't buy a company and get control Postgres the Postgres foundation nonprofit foundation",
    "start": "816860",
    "end": "823880"
  },
  {
    "text": "manages the community that develops and supports Postgres and the license used by post grads encourages innovation and",
    "start": "823880",
    "end": "830300"
  },
  {
    "text": "extensions and Forks so much so that the PostgreSQL org website lists 44 Forks as",
    "start": "830300",
    "end": "836720"
  },
  {
    "text": "of yesterday and and I know that list is by no means complete now at the same",
    "start": "836720",
    "end": "843350"
  },
  {
    "text": "time the core community has remained very focused on code quality and Postgres has a reputation as being very",
    "start": "843350",
    "end": "849050"
  },
  {
    "text": "stable and delivering high performance out of the box for most database workloads now in addition postgrads",
    "start": "849050",
    "end": "856220"
  },
  {
    "text": "provides the most ANSI sequel compatible implementation of sequel of any relational database you'll find and also",
    "start": "856220",
    "end": "863329"
  },
  {
    "text": "has rich really deep and rich support for geospatial capabilities so any kind",
    "start": "863329",
    "end": "868579"
  },
  {
    "text": "of IOT related application does really well with Postgres and also supports",
    "start": "868579",
    "end": "873829"
  },
  {
    "text": "store procedures in multiple languages including P o PG sequel which is very similar to Oracle's Peele sequel and the",
    "start": "873829",
    "end": "880970"
  },
  {
    "text": "bottom line for a lot of these capabilities that many customers have told us that when they look at which",
    "start": "880970",
    "end": "886760"
  },
  {
    "text": "open source database they want to move Oracle or sequel server workloads - they find that they usually choose Postgres",
    "start": "886760",
    "end": "894110"
  },
  {
    "text": "because it's the most consistently closed database - Oracle in terms of",
    "start": "894110",
    "end": "899899"
  },
  {
    "text": "semantics and transactional model and the MVCC model and etc now that's what customers tell us kind of as anecdotes",
    "start": "899899",
    "end": "905959"
  },
  {
    "text": "we also see that in the data produced by the schema conversion tool which is part of the AWS database migration service",
    "start": "905959",
    "end": "912649"
  },
  {
    "text": "John will talk about in a minute but customers can use SCT to assess automatically assess how much work it",
    "start": "912649",
    "end": "918649"
  },
  {
    "text": "will take to migrate from a given source to a given target database ESET shows the highest automatic conversion rates",
    "start": "918649",
    "end": "924559"
  },
  {
    "text": "for an Oracle and sequel server database when you target Postgres as the landing point so we have data to back up the",
    "start": "924559",
    "end": "932059"
  },
  {
    "text": "anecdotes now I've mentioned Amazon Aurora a few times in this session I",
    "start": "932059",
    "end": "937850"
  },
  {
    "start": "933000",
    "end": "951000"
  },
  {
    "text": "want to give you a very brief tour of Amazon Aurora to help you understand why customers have made it the fastest",
    "start": "937850",
    "end": "943790"
  },
  {
    "text": "growing service in the history of AWS and why we've doubled down on a rora by adding Postgres compatibility so like",
    "start": "943790",
    "end": "952009"
  },
  {
    "text": "almost everything we do Amazon or org was born out of customer demand and customer feedback in using RDS remember",
    "start": "952009",
    "end": "959089"
  },
  {
    "text": "back in 2009 we started with my sequel customers got accustomed to seeing both commercial and open source databases",
    "start": "959089",
    "end": "965029"
  },
  {
    "text": "side-by-side in a managed database environment and they started asking for the best in both worlds they want the",
    "start": "965029",
    "end": "971750"
  },
  {
    "text": "speed of Cape and capabilities of commercial databases combined with the low cost and simplicity of open source",
    "start": "971750",
    "end": "977509"
  },
  {
    "text": "and so this caused us to eventually after we listened for a while caused us to rethink how relational",
    "start": "977509",
    "end": "983809"
  },
  {
    "text": "databases are built and to focus on reimplemented the caching and logging in",
    "start": "983809",
    "end": "989480"
  },
  {
    "text": "the storage layers for the cloud for AWS now we did this initially for my sequel",
    "start": "989480",
    "end": "994910"
  },
  {
    "text": "launching the my sequel compatible edition of Amazon Aurora in July 2015 with up to five times the throughput of",
    "start": "994910",
    "end": "1002050"
  },
  {
    "text": "standard my sequel at 1/10 the cost of commercial database engines now the core",
    "start": "1002050",
    "end": "1009399"
  },
  {
    "start": "1007000",
    "end": "1081000"
  },
  {
    "text": "of Aurora is the Aurora storage engine which is a distributed massively parallel log based and database aware",
    "start": "1009399",
    "end": "1015759"
  },
  {
    "text": "storage system that's kind of a big mouthful I say distributed because it's distributed",
    "start": "1015759",
    "end": "1021360"
  },
  {
    "text": "three availability zones it's massively parallel because a typical Aurora storage cluster will have hundreds or",
    "start": "1021360",
    "end": "1026910"
  },
  {
    "text": "sometimes thousands of storage nodes in it it's log based which means we only ever write log records into the storage",
    "start": "1026910",
    "end": "1032640"
  },
  {
    "text": "system and its database aware which means we've taught the storage system the format of those log records and the",
    "start": "1032640",
    "end": "1037860"
  },
  {
    "text": "format of database pages for my sequel and now Postgres that allows us to do",
    "start": "1037860",
    "end": "1042870"
  },
  {
    "text": "all kinds of fancy things including improving performance by 3x by up to 3x for post-grad up to 5x for my sequel it",
    "start": "1042870",
    "end": "1050490"
  },
  {
    "text": "also allows us to support up to 15 read notes attached to the same storage volume spread across three availability",
    "start": "1050490",
    "end": "1056160"
  },
  {
    "text": "zones and provide failover failover times of 30 seconds or less to those",
    "start": "1056160",
    "end": "1062040"
  },
  {
    "text": "read notes now both the storage layer and the database instance layers are monitored and managed automatically just",
    "start": "1062040",
    "end": "1068490"
  },
  {
    "text": "like normal RDS engines to ensure that the failure of disks or storage nodes or database instances or other components",
    "start": "1068490",
    "end": "1075390"
  },
  {
    "text": "are automatically recovered from without requiring manual intervention by by the end user",
    "start": "1075390",
    "end": "1081559"
  },
  {
    "start": "1081000",
    "end": "1126000"
  },
  {
    "text": "now we've recently added Postgres compatible addition to Amazon Aurora we",
    "start": "1081559",
    "end": "1086820"
  },
  {
    "text": "went ga on October 24th and for AWS regions and we've added four more regions just last week",
    "start": "1086820",
    "end": "1092910"
  },
  {
    "text": "now both editions provide the same benefits higher performance fast failover read scale-out and dynamic and",
    "start": "1092910",
    "end": "1100380"
  },
  {
    "text": "automatic storage scaling up to 64 terabytes all with full compatibility with my sequel and with Postgres and",
    "start": "1100380",
    "end": "1106559"
  },
  {
    "text": "many customers are choosing to migrate their commercial databases to the Aurora",
    "start": "1106559",
    "end": "1112410"
  },
  {
    "text": "database engines because of this combination of commercial database level performance and durability and high",
    "start": "1112410",
    "end": "1117720"
  },
  {
    "text": "availability together with the low costs of open source and the compatibility offered by my sequel and Postgres for",
    "start": "1117720",
    "end": "1124830"
  },
  {
    "text": "their workloads so I'm now going to ask John Winfred to take over he'll review",
    "start": "1124830",
    "end": "1130650"
  },
  {
    "text": "how to use the AWS database migration service to migrate your databases and talk through some of the scenarios",
    "start": "1130650",
    "end": "1136110"
  },
  {
    "text": "related to that thanks Kevin hopefully everyone's learned some stuff so far I",
    "start": "1136110",
    "end": "1142230"
  },
  {
    "text": "myself have learned not to walk in front of a speaker with a live mic I hopefully I don't make that mistake again",
    "start": "1142230",
    "end": "1148250"
  },
  {
    "text": "but yeah I'm here to talk a little bit about database migrations and also run a",
    "start": "1148250",
    "end": "1154140"
  },
  {
    "text": "bit of a demo to show you guys actually how it works so I'm just unlocking my computer we'll get to that in a few",
    "start": "1154140",
    "end": "1160200"
  },
  {
    "text": "minutes but before that we'll do a bit of a background on how we do database migrations at AWS",
    "start": "1160200",
    "end": "1168290"
  },
  {
    "start": "1168000",
    "end": "1235000"
  },
  {
    "text": "so head AWS we're all about being responsive to customers for many years",
    "start": "1168290",
    "end": "1173970"
  },
  {
    "text": "customers are like great you've got this great managed database software called RDS well how do I actually migrate to",
    "start": "1173970",
    "end": "1182580"
  },
  {
    "text": "the cloud how do we make it easy how do we make it less intrusive for our end users you know it's one thing to say",
    "start": "1182580",
    "end": "1187740"
  },
  {
    "text": "that I can do a database migration and you know it'll all work but if you read the fine print somewhere and there's",
    "start": "1187740",
    "end": "1193320"
  },
  {
    "text": "somebody said you need to take a two-week outage I mean that's just not really feasible as part of those",
    "start": "1193320",
    "end": "1199290"
  },
  {
    "text": "migrations people wanted to have some flexibility you know either I stick with the same database engine that I'm running or maybe I want to go to use",
    "start": "1199290",
    "end": "1206250"
  },
  {
    "text": "something else and then once that migration happened what are our options how can we do ongoing synchronization",
    "start": "1206250",
    "end": "1213330"
  },
  {
    "text": "how can we sync between on-prem and the cloud is that kind of thing possible and",
    "start": "1213330",
    "end": "1219480"
  },
  {
    "text": "it's this mobility between different engines different locations that brings us to one of the biggest requests that",
    "start": "1219480",
    "end": "1226169"
  },
  {
    "text": "is the ability to migrate off commercial license intensive engines onto cloud native open source solutions and those",
    "start": "1226169",
    "end": "1232500"
  },
  {
    "text": "are the solutions that Kevin was mainly talking about so he's done a bit of an introduction to DMS and SCT do you - NS",
    "start": "1232500",
    "end": "1240960"
  },
  {
    "start": "1235000",
    "end": "1383000"
  },
  {
    "text": "CTR AWS is solutions to database migration DMS is what moves the data SCT",
    "start": "1240960",
    "end": "1249630"
  },
  {
    "text": "is what moves the schema so they're very closely related cousins you use SCT first to move your schema and then DMS",
    "start": "1249630",
    "end": "1256350"
  },
  {
    "text": "to move your data you can see to this point we've moved over 45,000 unique customer databases with the products",
    "start": "1256350",
    "end": "1262679"
  },
  {
    "text": "since we launched there's some minor details in there SCT actually you use it",
    "start": "1262679",
    "end": "1267900"
  },
  {
    "text": "to move your data as well for data warehouses but I'll talk a little bit more about that later it's also",
    "start": "1267900",
    "end": "1272970"
  },
  {
    "text": "important to note as Kevin mentioned early in the slide that there are other solutions for your migration as well if",
    "start": "1272970",
    "end": "1278970"
  },
  {
    "text": "you're doing a homogeneous migration that is you're sticking with the same database engine DMS n SCT can definitely help but there",
    "start": "1278970",
    "end": "1286210"
  },
  {
    "text": "might be a better solution for you out there so just go in there with your eyes open evaluate the scenario you're trying to",
    "start": "1286210",
    "end": "1292510"
  },
  {
    "text": "do and use the best tool so in particular when you treat you use it a",
    "start": "1292510",
    "end": "1298690"
  },
  {
    "text": "little bit more detail on a similar slide Kevin had earlier DMS can help you do through things they can help you",
    "start": "1298690",
    "end": "1304780"
  },
  {
    "text": "modernize migrate and replicate so migrates the obvious one you're looking to migrate from on-prem to the cloud or",
    "start": "1304780",
    "end": "1311530"
  },
  {
    "text": "maybe you're doing something like moving data from your transactional online",
    "start": "1311530",
    "end": "1317170"
  },
  {
    "text": "system to a data warehouse people have used it for some other neat things like upgrading minor versions with RDS you",
    "start": "1317170",
    "end": "1323500"
  },
  {
    "text": "can upgrade your database version with a click so go from say nine three to nine four but it does still have an outage",
    "start": "1323500",
    "end": "1330520"
  },
  {
    "text": "outage of about four minutes for some people four minutes is too long so you can use DMS to actually spin up a newer",
    "start": "1330520",
    "end": "1336640"
  },
  {
    "text": "version of a database engine and migrate the data across with essentially zero downtime just as long as it takes you to",
    "start": "1336640",
    "end": "1342100"
  },
  {
    "text": "updated DNS entry it can be used for ongoing replication so people tend to",
    "start": "1342100",
    "end": "1347680"
  },
  {
    "text": "use it for things like synchronizing data into a data warehouse other people",
    "start": "1347680",
    "end": "1353860"
  },
  {
    "text": "use it for a dr type scenario or where cross region replication isn't available natively DMS can move data from anywhere",
    "start": "1353860",
    "end": "1361390"
  },
  {
    "text": "to anywhere else doesn't matter if that anywhere else is in a different availability zone a different region or possibly from AWS back to your",
    "start": "1361390",
    "end": "1368560"
  },
  {
    "text": "on-premise system DMS can do that but it's key power is to help modernize your",
    "start": "1368560",
    "end": "1373690"
  },
  {
    "text": "engine so if you're looking at moving from a commercial engine to an open source engine DMS is your friend it will",
    "start": "1373690",
    "end": "1379300"
  },
  {
    "text": "definitely help you migrate your data between the two systems",
    "start": "1379300",
    "end": "1383370"
  },
  {
    "start": "1383000",
    "end": "1460000"
  },
  {
    "text": "no it's it's incremental we'll get to Italy in a few more minutes how DMS does what we call change data",
    "start": "1386890",
    "end": "1393350"
  },
  {
    "text": "capture but we basically read the logs and get the changes as it goes across so again just reiterating DMS you use it",
    "start": "1393350",
    "end": "1401300"
  },
  {
    "text": "to migrate applications you can go from classic to Amazon VP see if anybody's",
    "start": "1401300",
    "end": "1406370"
  },
  {
    "text": "been using AWS for quite a while you know we changed our networking infrastructure a while back so that can",
    "start": "1406370",
    "end": "1412490"
  },
  {
    "text": "help you move between versions you can do shard consolidation another really popular thing so unlike arora my sequel",
    "start": "1412490",
    "end": "1421310"
  },
  {
    "text": "doesn't scale up very well so people have quite often used shards so essentially multiple my sequel",
    "start": "1421310",
    "end": "1426620"
  },
  {
    "text": "instances if you realize now that with Aurora I do - it's better storage and better performance you can move all",
    "start": "1426620",
    "end": "1432830"
  },
  {
    "text": "those shards into one single instance and save money as part of the process DMS is your tool to help do that it can",
    "start": "1432830",
    "end": "1439460"
  },
  {
    "text": "also help you go from sequel to no sequel or vice versa so we've had a fair number for a bit of interest to people that have gone down",
    "start": "1439460",
    "end": "1446000"
  },
  {
    "text": "that no sequel path for databases that maybe shouldn't have been no sequel and use DMS to get back to the relational",
    "start": "1446000",
    "end": "1453290"
  },
  {
    "text": "side of the fence and then of course vice versa lots of people have used it to migrate information - DynamoDB it's",
    "start": "1453290",
    "end": "1462560"
  },
  {
    "start": "1460000",
    "end": "1597000"
  },
  {
    "text": "actually just forgot to mention something that only came into effect a couple weeks ago as far as costs go for",
    "start": "1462560",
    "end": "1469160"
  },
  {
    "text": "DMS DMS is actually free if you are going to the open source engines so",
    "start": "1469160",
    "end": "1476450"
  },
  {
    "text": "you're looking at going to Aurora or - dynamo there's no cost for DMS in there",
    "start": "1476450",
    "end": "1482090"
  },
  {
    "text": "- Aurora redshift and dynamo targets so that's just one thing to help incentivize your migrations that's",
    "start": "1482090",
    "end": "1488030"
  },
  {
    "text": "something new that was just last launched in the last couple weeks so when to use SCT as I said SC t is all",
    "start": "1488030",
    "end": "1495500"
  },
  {
    "text": "about converting your database schema so step one of your migration convert your schema step to move your data but it can",
    "start": "1495500",
    "end": "1501470"
  },
  {
    "text": "also help move your data warehouses so data warehouses are a bit of a different beast we don't have an ongoing replication",
    "start": "1501470",
    "end": "1509090"
  },
  {
    "text": "solution for warehouses because generally speaking these are things that are created as part of bad jobs have",
    "start": "1509090",
    "end": "1515000"
  },
  {
    "text": "nightly processes that sort of thing so SCT can actually do a dump of that data it does a dump out into essentially what",
    "start": "1515000",
    "end": "1521960"
  },
  {
    "text": "is redshift native format which of course gets ingested in via s3 but",
    "start": "1521960",
    "end": "1527180"
  },
  {
    "text": "what's also new with SCT is some direct integration with snowball so if you have",
    "start": "1527180",
    "end": "1534350"
  },
  {
    "text": "really big datasets these are datasets that are say above the ten terabytes size or you have a",
    "start": "1534350",
    "end": "1540140"
  },
  {
    "text": "whole fleet of databases you want to move to the cloud scg can now help move all that data onto a snowball spin up a",
    "start": "1540140",
    "end": "1547400"
  },
  {
    "text": "DMS task to keep track of any changes well that snowball gets shipped by a FedEx to the cloud and then ingest it in",
    "start": "1547400",
    "end": "1555250"
  },
  {
    "text": "to AWS and then DMS will apply any changes that happened while that snowball has been in transit we have a",
    "start": "1555250",
    "end": "1562370"
  },
  {
    "text": "session on Thursday that goes into that a bit more detail in fact there's a sort of a demo if you will with some some",
    "start": "1562370",
    "end": "1568760"
  },
  {
    "text": "recording at showing how it all happens and some live snowball integrations so if you're interested in how you do these",
    "start": "1568760",
    "end": "1574820"
  },
  {
    "text": "really big migrations do come along it's also important to note that DMS actually",
    "start": "1574820",
    "end": "1580340"
  },
  {
    "text": "does not have any size limitations so there's no nothing say when you need to use a snowball versus when you don't but",
    "start": "1580340",
    "end": "1586850"
  },
  {
    "text": "people tend to stick in sort of the 5 terabyte max time to do a migration with DMS purely because how long are you",
    "start": "1586850",
    "end": "1594110"
  },
  {
    "text": "really willing to wait for data and move over an internet connection so in summary when do you use DMS and SCT",
    "start": "1594110",
    "end": "1601330"
  },
  {
    "start": "1597000",
    "end": "1619000"
  },
  {
    "text": "you're looking to have a new order near zero downtime migration allow database",
    "start": "1601330",
    "end": "1606920"
  },
  {
    "text": "freedom moving between engines and of course it's very cost effective as I said it's downright free for some",
    "start": "1606920",
    "end": "1612050"
  },
  {
    "text": "targets and it's literally on the cost of dollars to move for the others it's a it's a pretty minimal cost service so",
    "start": "1612050",
    "end": "1619850"
  },
  {
    "start": "1619000",
    "end": "1634000"
  },
  {
    "text": "there were some questions on how DMS works that's what we're going to talk about first I know I've said it about three times already so I'm gonna just go",
    "start": "1619850",
    "end": "1626330"
  },
  {
    "text": "pretty quick your database migration process step one move your schema with SC T step to move your data with DMS SCT",
    "start": "1626330",
    "end": "1635570"
  },
  {
    "start": "1634000",
    "end": "1709000"
  },
  {
    "text": "to get into a bit more detail it converts that schema it'll also convert a data warehouse schema it'll also",
    "start": "1635570",
    "end": "1641570"
  },
  {
    "text": "convert application sequels so if you have a bunch of procedures or reviews or what have you written with a lot of",
    "start": "1641570",
    "end": "1646700"
  },
  {
    "text": "pl/sql SCT will actually automatically convert it it will scan your database",
    "start": "1646700",
    "end": "1651920"
  },
  {
    "text": "and it will be you an estimate as to what percentage of your schema it can convert automatically and then compare between different",
    "start": "1651920",
    "end": "1658490"
  },
  {
    "text": "database targets which is likely to achieve a higher conversion success rate",
    "start": "1658490",
    "end": "1663850"
  },
  {
    "text": "it's a bit different for an Amazon product it's actually a client tool it's",
    "start": "1663850",
    "end": "1669170"
  },
  {
    "text": "a free download off our website there's no cost at all to use SCT it's available for your operating system of choice it",
    "start": "1669170",
    "end": "1675200"
  },
  {
    "text": "can help you convert your schema or interestingly it can also help analyze your existing database from a licensing",
    "start": "1675200",
    "end": "1681020"
  },
  {
    "text": "perspective so say you're you just got to stick with Oracle for whatever reason what SCT will do it will look at what",
    "start": "1681020",
    "end": "1687710"
  },
  {
    "text": "you're using from Oracle and give you a recommendation going hey look if you did migrate to the cloud you could possibly",
    "start": "1687710",
    "end": "1693230"
  },
  {
    "text": "go from ant reprise license down to Standard Edition or something like that so it looks at your existing licensing",
    "start": "1693230",
    "end": "1698960"
  },
  {
    "text": "and says what what are your options out there but of course its primary goal is to give you a bit of insight as to what",
    "start": "1698960",
    "end": "1705410"
  },
  {
    "text": "it would take to convert to an open-source platform here's that assessment report that we",
    "start": "1705410",
    "end": "1711500"
  },
  {
    "start": "1709000",
    "end": "1744000"
  },
  {
    "text": "mentioned essentially it gives you a nice executive summary at the top something to just you know your one paragraph to send off to the boss and go",
    "start": "1711500",
    "end": "1717890"
  },
  {
    "text": "hey look this is sort of what we're thinking and down below you get with some bar charts telling you for the",
    "start": "1717890",
    "end": "1723260"
  },
  {
    "text": "different components of your schema you know your tables your procedures your triggers what-have-you what percentage",
    "start": "1723260",
    "end": "1728330"
  },
  {
    "text": "you're going to get converted automatically and it does this for every of the available targets so it'll be a",
    "start": "1728330",
    "end": "1733610"
  },
  {
    "text": "section of the report for my sequel a section report for Aurora and a section report for Postgres and it does that for",
    "start": "1733610",
    "end": "1740720"
  },
  {
    "text": "any of the engines that it works with a little bit more detail you'll see this",
    "start": "1740720",
    "end": "1746270"
  },
  {
    "start": "1744000",
    "end": "1768000"
  },
  {
    "text": "in action in a few minutes when I do my demo it's an essentially an integrated development environment so anybody",
    "start": "1746270",
    "end": "1751400"
  },
  {
    "text": "that's used any other IDE you're gonna feel pretty much at home the idea being you you launch your client you connect",
    "start": "1751400",
    "end": "1757580"
  },
  {
    "text": "your database on the left is your source schema on the right is your target schema and in between are the objects",
    "start": "1757580",
    "end": "1763610"
  },
  {
    "text": "that you're working with at the present time to do the conversion so how does",
    "start": "1763610",
    "end": "1769820"
  },
  {
    "start": "1768000",
    "end": "1936000"
  },
  {
    "text": "DMS work I alluded to it earlier but we'll get into the details now if you",
    "start": "1769820",
    "end": "1774950"
  },
  {
    "text": "soon what you're seeing up on the screen is a migration I know it says customer premise on the left and the AWS on the right just think of a more source and",
    "start": "1774950",
    "end": "1781640"
  },
  {
    "text": "target because if you actually wanted to move from AWS on premise you could do that so to",
    "start": "1781640",
    "end": "1788100"
  },
  {
    "text": "contradict anything that some of the competitors say we don't believe in vendor lock-in you can use our own tools to move back out of AWS if you want to",
    "start": "1788100",
    "end": "1795120"
  },
  {
    "text": "it's not something we see very often but you can do it so you could be moving from an ec2 instance to an RDS instance",
    "start": "1795120",
    "end": "1802169"
  },
  {
    "text": "from already s back to ec2 or of course the more obvious thing is from on-premise to the clouds so lots of",
    "start": "1802169",
    "end": "1808950"
  },
  {
    "text": "options just look at its source and target the only thing you can't do with DMS is an on-premise to an on-premise",
    "start": "1808950",
    "end": "1814169"
  },
  {
    "text": "migration so you kick off by launching the replication instance this",
    "start": "1814169",
    "end": "1819210"
  },
  {
    "text": "replication instance is in essence just an ec2 box with our replication software installed on it you never log on to the",
    "start": "1819210",
    "end": "1825899"
  },
  {
    "text": "Box yourself we fully manage it for you you interact with it through the console API or SDK everything with DMS is fully",
    "start": "1825899",
    "end": "1834570"
  },
  {
    "text": "API driven there are actually more features and knobs available if you use the API versus even the console you'll",
    "start": "1834570",
    "end": "1840869"
  },
  {
    "text": "find that's a pretty standard trait across AWS services you know we're very service driven as opposed to GUI GUI",
    "start": "1840869",
    "end": "1847289"
  },
  {
    "text": "driven so just know that everything you can do through the console you can definitely do through programmatic",
    "start": "1847289",
    "end": "1852960"
  },
  {
    "text": "methods which becomes very handy if you have a mass database migration with a lot of similar databases to move once",
    "start": "1852960",
    "end": "1860879"
  },
  {
    "text": "that instance is launched you define your connections so your connections are essentially no DC connection string it's",
    "start": "1860879",
    "end": "1867179"
  },
  {
    "text": "your source into your target one replication instance can have many different sources many different targets",
    "start": "1867179",
    "end": "1872610"
  },
  {
    "text": "and many different replication jobs it's just a processor like a big CPU for migrations so you can use one box to do",
    "start": "1872610",
    "end": "1879330"
  },
  {
    "text": "many things or just one thing you've got these connections defined then you say which tables schemas or databases you",
    "start": "1879330",
    "end": "1885960"
  },
  {
    "text": "want to move DMS is a logical replication tool that means we don't just say grab the whole database we can",
    "start": "1885960",
    "end": "1893070"
  },
  {
    "text": "grab certain tables certain schemas or down to certain records you can say look I only want to grab the records from",
    "start": "1893070",
    "end": "1899279"
  },
  {
    "text": "last five years out of the table and they can pull that across once you've selected what it is you want to move you",
    "start": "1899279",
    "end": "1905940"
  },
  {
    "text": "sit back relax and watch DMS move the data across and optionally if you've enabled it it will read the transactions",
    "start": "1905940",
    "end": "1913649"
  },
  {
    "text": "that happen during the migration to allow you to get those two databases in sync to the point that you're cus",
    "start": "1913649",
    "end": "1918899"
  },
  {
    "text": "or rather your users of the database don't even know the migration is happening and at some point you take a",
    "start": "1918899",
    "end": "1925169"
  },
  {
    "text": "small outage update your applications to point from your old database to your new database and you're done so it is very",
    "start": "1925169",
    "end": "1932849"
  },
  {
    "text": "much a minimal downtime migration product bit more detail as to how it",
    "start": "1932849",
    "end": "1938879"
  },
  {
    "start": "1936000",
    "end": "2018000"
  },
  {
    "text": "does it behind the scenes every database has logs we are literally using the native",
    "start": "1938879",
    "end": "1946830"
  },
  {
    "text": "api's that those database engines make available to read the transactions from the log follow them through the",
    "start": "1946830",
    "end": "1952710"
  },
  {
    "text": "replication instance and apply them to your target once the first step of the migration what we call the bulk load is",
    "start": "1952710",
    "end": "1958440"
  },
  {
    "text": "complete so when everything the bulk load is there we bring across the transactions and it happens on a table",
    "start": "1958440",
    "end": "1964409"
  },
  {
    "text": "by table manner so if you've got ten tables you're migrating or a thousand doesn't really matter once the first",
    "start": "1964409",
    "end": "1970259"
  },
  {
    "text": "table makes it to your target you start replicating the changes across for that table as we're working on the load for",
    "start": "1970259",
    "end": "1976679"
  },
  {
    "text": "the second table so on and so forth really lose a lot of it happens in parallel but that's the general idea",
    "start": "1976679",
    "end": "1982519"
  },
  {
    "text": "what this does require is for you to enable logging on your source database so with Oracle that's supplemental",
    "start": "1982519",
    "end": "1988950"
  },
  {
    "text": "logging with my sequel that's row level bin logging and so on and so forth for all the other engines what's really good",
    "start": "1988950",
    "end": "1995460"
  },
  {
    "text": "about the solution though is we don't need any agent installed on your source system we literally reach out through",
    "start": "1995460",
    "end": "2001219"
  },
  {
    "text": "the connection and get the information back from the API what this does mean though is we don't work with some really",
    "start": "2001219",
    "end": "2007279"
  },
  {
    "text": "old database engines that don't have his api's so if you're running something from circa 2000 we're probably not going",
    "start": "2007279",
    "end": "2012979"
  },
  {
    "text": "to be able to pull those transactions across for CDC so that's been a lot of",
    "start": "2012979",
    "end": "2019909"
  },
  {
    "start": "2018000",
    "end": "2068000"
  },
  {
    "text": "talking a lot of slides I'm sure everyone's seen a lot of slides today it's probably time we get into a bit of",
    "start": "2019909",
    "end": "2024950"
  },
  {
    "text": "a demo and show you how this thing actually works so providing technology behaves from here I'm just going to",
    "start": "2024950",
    "end": "2031789"
  },
  {
    "text": "press the magic button and hopefully we get my laptop up on the screen look at that alright so this is a live demo this",
    "start": "2031789",
    "end": "2040519"
  },
  {
    "text": "is not some pre-recorded thing what this means is anything go wrong at any time but that just becomes entertainment for",
    "start": "2040519",
    "end": "2046309"
  },
  {
    "text": "you guys so that's good we're going to go through and the idea is of course",
    "start": "2046309",
    "end": "2051529"
  },
  {
    "text": "that we're going to do a very simple migration from Oracle to Arora Kevin spoke a fair bit about",
    "start": "2051529",
    "end": "2057378"
  },
  {
    "text": "Aurora today so I figured that was that was a good target will show actually how to do this migration and then once a",
    "start": "2057379",
    "end": "2063289"
  },
  {
    "text": "wraps up we're gonna dive into some of the best practices on how you actually do it so here we are this is my an ec2",
    "start": "2063289",
    "end": "2071329"
  },
  {
    "start": "2068000",
    "end": "2170000"
  },
  {
    "text": "box I have running up in the AWS cloud again doesn't matter the operating system you decide to use I've just got",
    "start": "2071329",
    "end": "2077299"
  },
  {
    "text": "this this running here and we're gonna kick off by showing some of the basics so I'm just gonna use this open source",
    "start": "2077299",
    "end": "2083839"
  },
  {
    "text": "product I have called D beaver again use any query tool you want rather amusingly",
    "start": "2083839",
    "end": "2088908"
  },
  {
    "text": "a new version came out today but thankfully it's not prompted me to install it right now but the reason I",
    "start": "2088909",
    "end": "2094220"
  },
  {
    "text": "use this product is you can see I've got connections made to a whole range of different database engines right so I've",
    "start": "2094220",
    "end": "2099829"
  },
  {
    "text": "got my sequel of Postgres sequel server Oracle you name it it's it's all there so a first thing to show just to make",
    "start": "2099829",
    "end": "2107480"
  },
  {
    "text": "sure there's no smoke and mirrors here I'm going to connect to my Aurora Postgres destination and you can see in",
    "start": "2107480",
    "end": "2113839"
  },
  {
    "text": "here I really don't have anything it's it's an empty database just a few default schemas created there nothing",
    "start": "2113839",
    "end": "2121309"
  },
  {
    "text": "really oh it's empty so we're gonna actually move some data in here my Oracle source in this case is just down",
    "start": "2121309",
    "end": "2128240"
  },
  {
    "text": "below I've got a number of different schemas we're going to look at moving across the Chinook schema so some of you",
    "start": "2128240",
    "end": "2135890"
  },
  {
    "text": "guys may have heard of the Chinook schema it's just a common demo database that's available out there on the",
    "start": "2135890",
    "end": "2141380"
  },
  {
    "text": "Internet has a few tables in it I believe the general idea is it's some online music type database where you can you know",
    "start": "2141380",
    "end": "2148160"
  },
  {
    "text": "purchase your latest mp3 what I have here is just for your own interests sake",
    "start": "2148160",
    "end": "2153470"
  },
  {
    "text": "there's a relationship diagram between all the different tables so that's the idea of what we're going to try to move",
    "start": "2153470",
    "end": "2158990"
  },
  {
    "text": "now it's currently in Oracle we're looking to move it across to Postgres or R or Postgres in particular so we're",
    "start": "2158990",
    "end": "2165319"
  },
  {
    "text": "going to convert the schema into an Aurora schema as part of this demo so",
    "start": "2165319",
    "end": "2171019"
  },
  {
    "start": "2170000",
    "end": "2241000"
  },
  {
    "text": "the first thing we do is launch the schema conversion tool as I mentioned earlier the schema conversion tool is a",
    "start": "2171019",
    "end": "2177559"
  },
  {
    "text": "free download from our website so I'll just kick that off fires up",
    "start": "2177559",
    "end": "2186009"
  },
  {
    "text": "you know here it is this is the IDE it's not not too amazing to look at but it does some pretty cool stuff behind the",
    "start": "2189500",
    "end": "2195839"
  },
  {
    "text": "scenes I'm just gonna kick off and do a new project and let's do Oracle to",
    "start": "2195839",
    "end": "2206420"
  },
  {
    "text": "[Music] Postgres so I'm gonna choose my targets here as you can see I can choose between",
    "start": "2206420",
    "end": "2212279"
  },
  {
    "text": "a transactional database or a data warehouse actually know what I'm gonna start with the wizard the wizards always",
    "start": "2212279",
    "end": "2218579"
  },
  {
    "text": "a better way to do these things new project wizard that way it's like you don't know which engine you're gonna use",
    "start": "2218579",
    "end": "2224339"
  },
  {
    "text": "you're making a decision so similar kind of thing I know my sources Oracle I don't know what my destination is yet",
    "start": "2224339",
    "end": "2229349"
  },
  {
    "text": "remember I mentioned that you can use this to optimize your licensing you know",
    "start": "2229349",
    "end": "2234930"
  },
  {
    "text": "this is where this second option comes in it'll look at your licenses and and give you some recommendations here so",
    "start": "2234930",
    "end": "2241589"
  },
  {
    "text": "next I'm going to connect to my database now you guys are gonna laugh at this cuz it's like super secure me having my",
    "start": "2241589",
    "end": "2247200"
  },
  {
    "text": "password and text file on the desktop but it is just a sample database if you want to go mess with it I really don't care here we go I'm going to connect to",
    "start": "2247200",
    "end": "2255119"
  },
  {
    "text": "my RDS instance hit next so it's gonna scan the database looks at everything",
    "start": "2255119",
    "end": "2260190"
  },
  {
    "text": "that's in here I'm gonna say which schema do I want to analyze in this case I know we're gonna look at Chinook later",
    "start": "2260190",
    "end": "2266160"
  },
  {
    "text": "but I'm gonna be honest you know cuz a pretty simple schema let's just have a look at the the DB master schema because",
    "start": "2266160",
    "end": "2271710"
  },
  {
    "text": "it's a bit more interesting I'll just do a quick scan of it it's looking at",
    "start": "2271710",
    "end": "2276809"
  },
  {
    "text": "everything in the schema from you know those procedures to the triggers the packages what-have-you goes through",
    "start": "2276809",
    "end": "2282359"
  },
  {
    "text": "everything and then pops up on the screen this thing called the assessment report now if there's any AWS branding",
    "start": "2282359",
    "end": "2288930"
  },
  {
    "text": "people in the room I apologize we have an updated the logo yet but you know we're getting there when this report has",
    "start": "2288930",
    "end": "2295140"
  },
  {
    "text": "run you can see it starts up at the top we've got an executive summary it tells you all the objects it found what kind",
    "start": "2295140",
    "end": "2301529"
  },
  {
    "text": "of conversion ratio you're going to expect but the really fun stuff is when you scroll down and you have a look at",
    "start": "2301529",
    "end": "2306809"
  },
  {
    "text": "some of these graphs so this is saying if I targeted my sequel as an engine you",
    "start": "2306809",
    "end": "2312450"
  },
  {
    "text": "know I'm gonna have pretty good conversion ratios for my sequences for example you get a bit further down and well there's gonna be some manual work",
    "start": "2312450",
    "end": "2318720"
  },
  {
    "text": "for my procedures and you get to compare it of course to or or my sequel go further down again and",
    "start": "2318720",
    "end": "2324500"
  },
  {
    "text": "Postgres you can see that we've got you know slightly different conversion ratios all right but that's actually not",
    "start": "2324500",
    "end": "2331730"
  },
  {
    "text": "the schema I want to analyze I want to have a look at Chinook so render your",
    "start": "2331730",
    "end": "2336859"
  },
  {
    "text": "Chinook hit next all right you can see",
    "start": "2336859",
    "end": "2346849"
  },
  {
    "text": "the Chinook schema we're doing a little bit better on our conversions next again",
    "start": "2346849",
    "end": "2352550"
  },
  {
    "text": "and what it's asking me right now is which of those engines do I want to choose I'm going to choose the Postgres",
    "start": "2352550",
    "end": "2358910"
  },
  {
    "text": "engine and connect in with just again standard details so this is you know the the name of the host up in AWS cloud",
    "start": "2358910",
    "end": "2366140"
  },
  {
    "text": "username password and press finish so",
    "start": "2366140",
    "end": "2371210"
  },
  {
    "text": "once I've done that we get into the IDE which looks like so alright so the IDB",
    "start": "2371210",
    "end": "2377839"
  },
  {
    "text": "idea being in here I'm going to look at the Chinook schema and I want to convert it so I'm just gonna right click and go",
    "start": "2377839",
    "end": "2384140"
  },
  {
    "text": "convert schema which is okay it might already be something they're not a big deal and once that's converted what I",
    "start": "2384140",
    "end": "2393170"
  },
  {
    "text": "can do is expand the objects you can see I've converted those tables packages procedures and so on if I have a look at",
    "start": "2393170",
    "end": "2400310"
  },
  {
    "text": "some of my tables I will just say click on the first one what you can see at the top is what the table DDL looked like",
    "start": "2400310",
    "end": "2407780"
  },
  {
    "text": "for Oracle and at the bottom what the equivalent Postgres DDL looks like you",
    "start": "2407780",
    "end": "2413540"
  },
  {
    "text": "can go through and look at any object in here and you can see that it's converted them all likewise when you get into",
    "start": "2413540",
    "end": "2419180"
  },
  {
    "text": "things like the views you can see we've got another view here here's what the view look like an Oracle here's what the",
    "start": "2419180",
    "end": "2424940"
  },
  {
    "text": "view looks like in Postgres all right so I've now done a conversion I'm gonna be",
    "start": "2424940",
    "end": "2430760"
  },
  {
    "text": "honest and say you know for big databases it's a much more complicated procedure but the same general thing",
    "start": "2430760",
    "end": "2436700"
  },
  {
    "text": "holds true with how you do it I'm just going to go and apply it now to the target so as I hit apply two things are",
    "start": "2436700",
    "end": "2446420"
  },
  {
    "text": "gonna happen it's going to apply the full schema for Chinook so if I go back",
    "start": "2446420",
    "end": "2451880"
  },
  {
    "text": "to my query tool and go to my Postgres instance and I'll",
    "start": "2451880",
    "end": "2458640"
  },
  {
    "text": "just do a refresh you can see I now have this Chinook schema so Chinook schemas",
    "start": "2458640",
    "end": "2464700"
  },
  {
    "text": "in here there's all the tables notice a bit of a difference they're all lowercase but they've all been created",
    "start": "2464700",
    "end": "2470580"
  },
  {
    "text": "inside my Aurora instance but if I have a read of the data you can see it's",
    "start": "2470580",
    "end": "2475890"
  },
  {
    "text": "empty so remember step one is convert your schema step two is move your data there's also something else has been",
    "start": "2475890",
    "end": "2481860"
  },
  {
    "text": "created automatically this is the extension pack it gets created on any target where we use SCT and all it does",
    "start": "2481860",
    "end": "2488220"
  },
  {
    "text": "is it mimics functions that are available in your source engine that aren't necessarily available in your target engine to make the conversions",
    "start": "2488220",
    "end": "2494670"
  },
  {
    "text": "easier so if we have a quick look at this say go and look at the procedures here's a bunch of procedures that we've",
    "start": "2494670",
    "end": "2501030"
  },
  {
    "text": "created in this library to make it easier to do the conversions so you know a good one to look at down here is a",
    "start": "2501030",
    "end": "2508410"
  },
  {
    "text": "bunch of casts so you know to char for example the to char function in Oracle behaves differently than Postgres so",
    "start": "2508410",
    "end": "2514410"
  },
  {
    "text": "with we have created essentially the equivalent in the Postgres target",
    "start": "2514410",
    "end": "2520670"
  },
  {
    "text": "alright so to prevent an error during this migration I'm going to tell you one thing that happens best practices for",
    "start": "2520670",
    "end": "2527790"
  },
  {
    "start": "2521000",
    "end": "2601000"
  },
  {
    "text": "migration is that you disable triggers and foreign key constraints during the full load if you don't do that some",
    "start": "2527790",
    "end": "2535080"
  },
  {
    "text": "strange things can happen if you don't maintain consistency or in the order of the information that you move so I have",
    "start": "2535080",
    "end": "2541260"
  },
  {
    "text": "a quick script here to actually remove the constraints so this is just again",
    "start": "2541260",
    "end": "2547230"
  },
  {
    "text": "easy thing you can just find it on the internet yourself if you want but I'm going to run this make sure I'm against",
    "start": "2547230",
    "end": "2554370"
  },
  {
    "text": "the right schema here all right so what",
    "start": "2554370",
    "end": "2562170"
  },
  {
    "text": "what I'm gonna happen here I'm gonna create this table I'm gonna run it and",
    "start": "2562170",
    "end": "2567620"
  },
  {
    "text": "then this little script here loops through my database schema and gets rid",
    "start": "2567620",
    "end": "2574230"
  },
  {
    "text": "of all the constraints so if I go back now and have a quick look at my Chinook",
    "start": "2574230",
    "end": "2580260"
  },
  {
    "text": "schema do a refresh you'll see here I have this table called dropped foreign keys",
    "start": "2580260",
    "end": "2585760"
  },
  {
    "text": "and if you have a look in the table it's just created scripts for every key",
    "start": "2585760",
    "end": "2591640"
  },
  {
    "text": "that I've removed so that at the end if I want I can just rerun this and it'll recreate all the foreign key constraints",
    "start": "2591640",
    "end": "2597850"
  },
  {
    "text": "in my database pretty straightforward so now let's actually move some data so AWS",
    "start": "2597850",
    "end": "2608230"
  },
  {
    "start": "2601000",
    "end": "2647000"
  },
  {
    "text": "website again no magic here I'm gonna sign into my console DMS is available in",
    "start": "2608230",
    "end": "2614290"
  },
  {
    "text": "every region around the world right now so you can pick your region I'm",
    "start": "2614290",
    "end": "2619390"
  },
  {
    "text": "operating out of Oregon but totally up to you guys where you want to run it and I'm gonna go and click on DMS so as I",
    "start": "2619390",
    "end": "2628510"
  },
  {
    "text": "mentioned earlier there's a replication instance so this is that replication instance in my case I'm running on a C",
    "start": "2628510",
    "end": "2634240"
  },
  {
    "text": "for large you can use either T twos or C fours and just to save some time I've pre created all my endpoints so these",
    "start": "2634240",
    "end": "2640960"
  },
  {
    "text": "endpoints point to that those same databases you saw listed in my query tool but you know you can go create them",
    "start": "2640960",
    "end": "2646030"
  },
  {
    "text": "yourself the main idea here is you create a task so I'm gonna create a replication task and we're gonna call it",
    "start": "2646030",
    "end": "2653500"
  },
  {
    "start": "2647000",
    "end": "2709000"
  },
  {
    "text": "a let's just call it Chinook which replication server do you want to use because of course you can have more than",
    "start": "2653500",
    "end": "2658990"
  },
  {
    "text": "one and we're gonna move information from my Oracle source endpoint to my",
    "start": "2658990",
    "end": "2664600"
  },
  {
    "text": "Aurora Postgres target endpoint and again these are just the endpoints that you saw on the last screen that were",
    "start": "2664600",
    "end": "2670660"
  },
  {
    "text": "created I'm looking to migrate the data I want to start it on create and I don't",
    "start": "2670660",
    "end": "2676660"
  },
  {
    "text": "want to do anything to my tables because we need EMS can create tables for you but it can't create triggers and",
    "start": "2676660",
    "end": "2681730"
  },
  {
    "text": "procedures and what-have-you so that's why it has that drop option in here and I don't have any logs in my database so",
    "start": "2681730",
    "end": "2687040"
  },
  {
    "text": "I'm just gonna speed it up for for time purposes here all right just one make",
    "start": "2687040",
    "end": "2692410"
  },
  {
    "text": "sure I'm not missing anything alright let's let's do some data validation - this is a new feature that we've added",
    "start": "2692410",
    "end": "2698500"
  },
  {
    "text": "and I'm also going to turn on logging data validation just make sure that the records got moved across without any",
    "start": "2698500",
    "end": "2704080"
  },
  {
    "text": "issues and logging of course if there is a problem you want to be able to see what the problem is so what do I want to",
    "start": "2704080",
    "end": "2711160"
  },
  {
    "text": "move I want to move my Chinook schema all tables the % is a wild card and I",
    "start": "2711160",
    "end": "2716920"
  },
  {
    "text": "just want to include them remember I mentioned it's a law surgical tools so you can filter down and say look only some records I want to",
    "start": "2716920",
    "end": "2722859"
  },
  {
    "text": "move if you want and I need to add a couple transformation rules basically everything in Oracle is uppercase so I",
    "start": "2722859",
    "end": "2730540"
  },
  {
    "text": "want to make sure that when I migrate things over to Postgres I want to make",
    "start": "2730540",
    "end": "2736690"
  },
  {
    "text": "everything lowercase so let me just get this on my screen let me go here and",
    "start": "2736690",
    "end": "2742390"
  },
  {
    "text": "make lowercase and my transformation rule so that that's for the schema and I'm also going to do it for the table",
    "start": "2742390",
    "end": "2749230"
  },
  {
    "text": "technically speaking you should do it for the column too but I don't the",
    "start": "2749230",
    "end": "2755680"
  },
  {
    "text": "column only becomes important when you're actually replicating changes across and there's no changes at this",
    "start": "2755680",
    "end": "2762700"
  },
  {
    "text": "point so I'm just gonna skip that to save some time so we're gonna move things across again schema to lowercase",
    "start": "2762700",
    "end": "2768849"
  },
  {
    "start": "2765000",
    "end": "2910000"
  },
  {
    "text": "and table to lowercase once that's done I just hit create the task is going to",
    "start": "2768849",
    "end": "2775380"
  },
  {
    "text": "start creating and then it'll start moving data now when I did this I did it",
    "start": "2775380",
    "end": "2784900"
  },
  {
    "text": "this way to show you guys how you could create your task from scratch there's actually some tight integrations between",
    "start": "2784900",
    "end": "2790140"
  },
  {
    "text": "DMS and SC TS so because I'd already created my Mike my conversion if you",
    "start": "2790140",
    "end": "2796480"
  },
  {
    "text": "will inside SCT I could have actually created my DMS task automatically from",
    "start": "2796480",
    "end": "2801970"
  },
  {
    "text": "SCT so if I went back here instead of doing everything that I just did there in DMS I could have just right clicked",
    "start": "2801970",
    "end": "2808630"
  },
  {
    "text": "and said create DMS task right so that option is there I just wanted to show",
    "start": "2808630",
    "end": "2813880"
  },
  {
    "text": "you how you would do it right from the console itself so it takes a little takes a minute or two to get going",
    "start": "2813880",
    "end": "2819250"
  },
  {
    "text": "eventually it'll kick off and you'll start getting some data in here you can see now it's just starting and if I move",
    "start": "2819250",
    "end": "2826780"
  },
  {
    "text": "this up just a touch and we go to table statistics I'm gonna have some screen",
    "start": "2826780",
    "end": "2833530"
  },
  {
    "text": "real estate issues here on time go down I'm just gonna hit a refresh all right",
    "start": "2833530",
    "end": "2839619"
  },
  {
    "text": "it's not ready quite yet well there we go so now you can see here's all the",
    "start": "2839619",
    "end": "2844809"
  },
  {
    "text": "tables that were migrating it knows how many rows of data that we're moving across and validation pending so that's",
    "start": "2844809",
    "end": "2852010"
  },
  {
    "text": "that validation option labeled so it knows okay I'm moving some data but I still have thirty three hundred and forty seven rows of data to",
    "start": "2852010",
    "end": "2858249"
  },
  {
    "text": "validate that actually got moved across properly but as that's running what we",
    "start": "2858249",
    "end": "2863769"
  },
  {
    "text": "can do if we switch back to the database query tool if I go here and I read the",
    "start": "2863769",
    "end": "2870009"
  },
  {
    "text": "data in the console you can see I now have data in my Aurora Postgres targets",
    "start": "2870009",
    "end": "2875229"
  },
  {
    "text": "so we've moved data from Oracle to Postgres using DMS go back here might",
    "start": "2875229",
    "end": "2883269"
  },
  {
    "text": "get lucky there's the refresh button and you can",
    "start": "2883269",
    "end": "2888759"
  },
  {
    "text": "see actually that everything's been validated so I've moved all my records across except for 1212 more yet to come",
    "start": "2888759",
    "end": "2894459"
  },
  {
    "text": "but basically the validations occurred and what it does there is it looks at the primary key and makes sure that all",
    "start": "2894459",
    "end": "2900729"
  },
  {
    "text": "of those columns of data are there and row counts on what-have-you so it's basically preventing you from having to",
    "start": "2900729",
    "end": "2906549"
  },
  {
    "text": "do the validation yourself after the fact so that's kind of the idea of what",
    "start": "2906549",
    "end": "2912219"
  },
  {
    "text": "I wanted to show with respect to how a database migration happens create your",
    "start": "2912219",
    "end": "2917589"
  },
  {
    "text": "schema create a DMS task move the data across and away you go now just to reiterate your schema",
    "start": "2917589",
    "end": "2924940"
  },
  {
    "text": "conversion is not always going to be totally straightforward rule of thumb what we've found for if we take Oracle",
    "start": "2924940",
    "end": "2931359"
  },
  {
    "text": "to Aurora Postgres as an example we collect anonymous statistics behind the scenes we tend to find that we get about",
    "start": "2931359",
    "end": "2937269"
  },
  {
    "text": "85% conversion ratio your mileage will vary somebody better somebody worse but we",
    "start": "2937269",
    "end": "2942339"
  },
  {
    "text": "can certainly save a lot of time and I need to press the button to foot back to this all right so best practices things",
    "start": "2942339",
    "end": "2950799"
  },
  {
    "start": "2947000",
    "end": "2963000"
  },
  {
    "text": "to consider when doing a migration various things to consider basically",
    "start": "2950799",
    "end": "2956049"
  },
  {
    "text": "first and obvious you need to make sure that you know we can do like if we're",
    "start": "2956049",
    "end": "2963759"
  },
  {
    "text": "talking native migration in that case you want to make sure you can do ongoing replication you know you can have access",
    "start": "2963759",
    "end": "2969910"
  },
  {
    "text": "to those logs you can pull the information across you only do a native replication if you need to move all the",
    "start": "2969910",
    "end": "2975849"
  },
  {
    "text": "data because you can't filter records with a with a replication dump restore",
    "start": "2975849",
    "end": "2981190"
  },
  {
    "text": "another great option especially if you can take a downtime say you're doing a sequel server to a sequel server migration",
    "start": "2981190",
    "end": "2987079"
  },
  {
    "text": "you could use DMS but you don't want to the best thing to do there if you can take a bit of downtime is to take a back",
    "start": "2987079",
    "end": "2992150"
  },
  {
    "text": "file export and then just dump it in an s3 bucket and RDS sequel can ingest it or you could combine methods you could",
    "start": "2992150",
    "end": "2998809"
  },
  {
    "text": "use that and use DMS or may replicate across any changes that occurred during the time it took you to get that back",
    "start": "2998809",
    "end": "3005140"
  },
  {
    "text": "file import it in your gonna use AWS DMS and SCT when you're switching engines",
    "start": "3005140",
    "end": "3011170"
  },
  {
    "text": "but again it's not your only solution right it is order PG that's a great tool out there to help you do your migrations",
    "start": "3011170",
    "end": "3017049"
  },
  {
    "text": "if you prefer using that but of course you know ours are always there to help other things to consider if you did is",
    "start": "3017049",
    "end": "3023859"
  },
  {
    "text": "so large you need to use a snowball while DMS handles this natively in conjunction with SCT it's also important",
    "start": "3023859",
    "end": "3032380"
  },
  {
    "start": "3030000",
    "end": "3067000"
  },
  {
    "text": "to realize that migration is a project it's not a point-and-click done in five minutes sort of thing based on our past",
    "start": "3032380",
    "end": "3038890"
  },
  {
    "text": "experience this is kind of where we see the breakdown of effort and what you can see in there is your schema conversion",
    "start": "3038890",
    "end": "3045729"
  },
  {
    "text": "and your data migration is actually not a huge percentage of your effort your big effort comes in when you have to do",
    "start": "3045729",
    "end": "3051609"
  },
  {
    "text": "your testing definitely factored that in right because it's one thing if I can do point click look yes you saw I migrated",
    "start": "3051609",
    "end": "3058299"
  },
  {
    "text": "my Chinook schema then in there but I want to test all the applications that are relying on that database to make",
    "start": "3058299",
    "end": "3064809"
  },
  {
    "text": "sure things migrated properly it's also important you understand your environment your database what do you",
    "start": "3064809",
    "end": "3072609"
  },
  {
    "start": "3067000",
    "end": "3155000"
  },
  {
    "text": "know about it I can tell you one of the most problematic areas we have during database migration are databases that",
    "start": "3072609",
    "end": "3079119"
  },
  {
    "text": "have logs in it DMS does handle lobs no problem there but they're slow whoever",
    "start": "3079119",
    "end": "3085660"
  },
  {
    "text": "thought it was a great idea to embed movies inside a database is just beyond me but people do it and you know you",
    "start": "3085660",
    "end": "3093969"
  },
  {
    "text": "just need to be aware of it you need to know what's out there other things that can slow it down you want to make sure you have primary and or primary indexes",
    "start": "3093969",
    "end": "3101229"
  },
  {
    "text": "and all your tables if you don't well and you're enabling change data capture we're probably going to be doing full",
    "start": "3101229",
    "end": "3106359"
  },
  {
    "text": "table scans to see you know what's changed what needs inserting and that's gonna slow it down other things to",
    "start": "3106359",
    "end": "3112719"
  },
  {
    "text": "consider your network you saw I managed to connect to my source and target databases quite easily well I'm gonna",
    "start": "3112719",
    "end": "3118569"
  },
  {
    "text": "let you know that's because it's all inside my own VP's your network infrastructure is probably a lot more complicated than what I had",
    "start": "3118569",
    "end": "3124840"
  },
  {
    "text": "set up there for demo you're gonna have some assisted min that probably wants to lock down every port left right in the",
    "start": "3124840",
    "end": "3130630"
  },
  {
    "text": "center you know you may be you've got to get a VPN setup or a Direct Connect connection going these are all things",
    "start": "3130630",
    "end": "3136390"
  },
  {
    "text": "that take time and you need to make sure you factored in it when you're doing your migrations and then of course",
    "start": "3136390",
    "end": "3141640"
  },
  {
    "text": "there's bandwidth if you're already running hot and you know utilizing 99% of your internet capacity for Facebook",
    "start": "3141640",
    "end": "3148360"
  },
  {
    "text": "messages you know you just need to to think these things into account when you're doing your migrations so what if",
    "start": "3148360",
    "end": "3156280"
  },
  {
    "start": "3155000",
    "end": "3201000"
  },
  {
    "text": "xspeed sized the database of course it's the obvious thing bandwidth yes but it's also things like the structure of your",
    "start": "3156280",
    "end": "3162730"
  },
  {
    "text": "database if you have a terabyte database and your neighbor has a terabyte database but his has tables evenly",
    "start": "3162730",
    "end": "3169330"
  },
  {
    "text": "dispersed making up that terabyte it's gonna move a lot faster than you if you have one database that are one table",
    "start": "3169330",
    "end": "3175270"
  },
  {
    "text": "that's 900 megabytes or nine hundred gigabytes rather and a few other tables that make up that last few gigs right so",
    "start": "3175270",
    "end": "3181770"
  },
  {
    "text": "very big tables will slow things down versus an evenly dispersed database of",
    "start": "3181770",
    "end": "3187810"
  },
  {
    "text": "course you know how much power you put behind things the bigger instance size you can give the better in fact even",
    "start": "3187810",
    "end": "3194320"
  },
  {
    "text": "though some of the c4s costs a lot more than at e2 for DMS they'll finish so much faster it will actually be cheaper",
    "start": "3194320",
    "end": "3200970"
  },
  {
    "text": "other things find the right people if your people don't understand databases you might have some trouble make sure",
    "start": "3200970",
    "end": "3208690"
  },
  {
    "start": "3201000",
    "end": "3241000"
  },
  {
    "text": "you start small do a point point of concept or a proof of concept rather and then also make sure you read we've got",
    "start": "3208690",
    "end": "3214390"
  },
  {
    "text": "lots of good blogs out there and we've recently released released something that has a nifty name known as a cookbook on our website that gives you",
    "start": "3214390",
    "end": "3221380"
  },
  {
    "text": "step by step things to consider when during a migration especially from Oracle to Postgres so these are things",
    "start": "3221380",
    "end": "3226720"
  },
  {
    "text": "to look at now with that I'm gonna hand over to Kevin to finish off a few more best practices that we've come across in our",
    "start": "3226720",
    "end": "3234370"
  },
  {
    "text": "time thanks John that was awesome some",
    "start": "3234370",
    "end": "3242230"
  },
  {
    "start": "3241000",
    "end": "3417000"
  },
  {
    "text": "other best practices these come from a specific large customer I've been working with who has about 5,000 Oracle",
    "start": "3242230",
    "end": "3250480"
  },
  {
    "text": "databases to migrate and so they decided to migrate all of them off to post grads either RTS for",
    "start": "3250480",
    "end": "3256569"
  },
  {
    "text": "postcards or or Postgres and so these are some of their best practices that they're putting together as they go",
    "start": "3256569",
    "end": "3262210"
  },
  {
    "text": "through this this massive project one of the things is as you can see here keep database sorry keep backups disabled",
    "start": "3262210",
    "end": "3269430"
  },
  {
    "text": "just so that the migrations can go faster they also have discovered that it",
    "start": "3269430",
    "end": "3274539"
  },
  {
    "text": "makes sense to have a separate parameter group you know this is an RDS concept where you can create parameter groups",
    "start": "3274539",
    "end": "3279940"
  },
  {
    "text": "with database configuration parameters they suggest having a separate group for each instance because they found they",
    "start": "3279940",
    "end": "3287019"
  },
  {
    "text": "need to you know tune each instance differently in the landing zone and then",
    "start": "3287019",
    "end": "3292750"
  },
  {
    "text": "they also kind of early on it's a sort of refer referenced in John's previous slide they used SCT kind of unmask they",
    "start": "3292750",
    "end": "3301049"
  },
  {
    "text": "started with a thousand databases ran SCT against all thousand of them and looked at the assessment reports to",
    "start": "3301049",
    "end": "3307150"
  },
  {
    "text": "classify their databases into easy medium and hard because they wanted to start with the easy ones and build up",
    "start": "3307150",
    "end": "3312369"
  },
  {
    "text": "their confidence and their experience and their abilities in their momentum and move on from there so if you have a",
    "start": "3312369",
    "end": "3317920"
  },
  {
    "text": "large number of databases it's really useful to use SAT just to be method with methodical about their migrations John",
    "start": "3317920",
    "end": "3326500"
  },
  {
    "text": "covered this there's stuff built into SVT and DMS to handle this but you know",
    "start": "3326500",
    "end": "3331990"
  },
  {
    "text": "by default Oracle does everything in uppercase and post goes does everything in lowercase and so you've got to make sure you do the conversions right",
    "start": "3331990",
    "end": "3338109"
  },
  {
    "text": "whether you're using DMS and SCT or other tools otherwise you're going to get very confused when you move to",
    "start": "3338109",
    "end": "3345880"
  },
  {
    "text": "Postgres and so some other best practices in terms of planning your cut",
    "start": "3345880",
    "end": "3351460"
  },
  {
    "text": "over John mentioned some of this as well you want to make sure that you you know disable things at the right time disable",
    "start": "3351460",
    "end": "3358450"
  },
  {
    "text": "triggers and then rename the right time make sure you're planning to turn on or rebuild your foreign keys at the right",
    "start": "3358450",
    "end": "3363670"
  },
  {
    "text": "time think through what your validation steps will be both before you cut over and",
    "start": "3363670",
    "end": "3369490"
  },
  {
    "text": "after and make sure you have a rollback strategy you know you need to make sure that yeah you think everything's gonna",
    "start": "3369490",
    "end": "3375339"
  },
  {
    "text": "be great in your Postgres target maybe you got something wrong maybe you missed something despite your validation steps you need to make sure you know how to",
    "start": "3375339",
    "end": "3381700"
  },
  {
    "text": "fall back if you have to and then there's specific extensions that are specific to Postgres available",
    "start": "3381700",
    "end": "3388900"
  },
  {
    "text": "in both RDS post president or Postgres that let you do things like you sequel to look at your post quiz logs that's",
    "start": "3388900",
    "end": "3394359"
  },
  {
    "text": "the log FTW extension PG repack helps reclaim space and tables and PG audit",
    "start": "3394359",
    "end": "3400479"
  },
  {
    "text": "actually implements auditing at a level that some of our financial services customers say is sufficient for their",
    "start": "3400479",
    "end": "3405669"
  },
  {
    "text": "auditors so these are extensions that are really useful just post migration to",
    "start": "3405669",
    "end": "3411069"
  },
  {
    "text": "help you make your environments more capable and more compliant alright so we have a few minutes for questions",
    "start": "3411069",
    "end": "3418949"
  }
]
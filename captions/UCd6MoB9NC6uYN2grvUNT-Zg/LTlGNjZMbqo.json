[
  {
    "text": "bonjour à tous pour ce qui est me connaissent pas déjà je m'appelle michael garcia je fais partie des",
    "start": "4850",
    "end": "9950"
  },
  {
    "text": "architectes solution de l'équipe amazon web services n'oubliez",
    "start": "9950",
    "end": "14960"
  },
  {
    "text": "notre compte twitter à w s actuelle si vous voulez être tenues être tenu au courant des dernières actualités en",
    "start": "14960",
    "end": "20240"
  },
  {
    "text": "france dans cette session de 45 minutes on va commencer par aborder le sujet du",
    "start": "20240",
    "end": "25460"
  },
  {
    "text": "traitement d'événements en temps réel de manière assez générique apprendre à la chance d'accueillir nicolas baron est de",
    "start": "25460",
    "end": "32360"
  },
  {
    "text": "recueillir son témoignage de son expérience sur la plateforme avec en particulier d'utilisation d'amazon",
    "start": "32360",
    "end": "37760"
  },
  {
    "text": "redshift et après je reprendrai la main pour terminer cette session et on réservera quelques minutes à la fin pour",
    "start": "37760",
    "end": "43969"
  },
  {
    "text": "que vous ayez l'opportunité de poser toutes les questions vous avez donc le traitement d'événements en temps",
    "start": "43969",
    "end": "50300"
  },
  {
    "text": "réel une des premières choses à laquelle on va penser c'est l' internet of things l'internet des objets qui est vraiment",
    "start": "50300",
    "end": "56539"
  },
  {
    "text": "une tendance qu'on voit arriver sur le marché aujourd'hui il ya déjà certains objets qui sont connectés plus tôt pour",
    "start": "56539",
    "end": "63890"
  },
  {
    "text": "des usages assez simple donc ça peut être des lampes par exemple qui sont connectés à l'internet on le sait pas il ya dans l'industrie",
    "start": "63890",
    "end": "70520"
  },
  {
    "text": "déjà énormément de capteurs en fait qu'ils sont déjà connectés qui renvoie des informations ces capteurs and sons",
    "start": "70520",
    "end": "77150"
  },
  {
    "text": "général pas encore connectés directement sur le cloud et avec une porte vers",
    "start": "77150",
    "end": "82729"
  },
  {
    "text": "l'internet mais ça ne saurait tarder et on voit en fait que dans le futur on va avoir de plus en plus de device",
    "start": "82729",
    "end": "88850"
  },
  {
    "text": "connectés il ya déjà des gens qui ont construit des machines à laver connecter",
    "start": "88850",
    "end": "93920"
  },
  {
    "text": "avec des races perry paille ou des arts du hainaut il faut savoir qu'il ya déjà des start up qui font ça avec des",
    "start": "93920",
    "end": "99530"
  },
  {
    "text": "brosses à dents par exemple donc vraiment ça va faire partie de notre quotidien et tous ces censeurs en fait",
    "start": "99530",
    "end": "105979"
  },
  {
    "text": "que ce soit des brosses à dents mais machine à laver ou autres vont devoir envoyer des données pour qu'elles soient traitées en temps réel et qu'on puisse",
    "start": "105979",
    "end": "112759"
  },
  {
    "text": "faire un processing simple de cette information pour prévenir un utilisateur par exemple pour dire voilà le cycle 2",
    "start": "112759",
    "end": "120159"
  },
  {
    "text": "moi pour laver les vêtements est terminé maintenant on peut récupérer son âge donc",
    "start": "120159",
    "end": "126090"
  },
  {
    "text": "quand on parle de traitement d'événements en temps réel on pense tout de suite à big data pourquoi parce qu'on",
    "start": "126090",
    "end": "131769"
  },
  {
    "text": "va avoir énormément énormément de données à collecter et à traiter pour un",
    "start": "131769",
    "end": "137349"
  },
  {
    "text": "mot d'introduction sur le big data on parle souvent des 3 et le premier v ça va être le volume pourquoi ce que lacan",
    "start": "137349",
    "end": "143800"
  },
  {
    "text": "on va avoir une flotte de device à gérer on va souvent avoir des millions de device et pas des dizaines de millions",
    "start": "143800",
    "end": "149650"
  },
  {
    "text": "ou des centaines de millions donc même si c'est device là on voit peu de données ils vont le faire de manière",
    "start": "149650",
    "end": "154930"
  },
  {
    "text": "régulière pendant la journée et donc au final à la fin de la journée on va se retrouver avec des volumes de données",
    "start": "154930",
    "end": "160959"
  },
  {
    "text": "qui sont vraiment colossaux le deuxième baissé pour la variété pourquoi parce",
    "start": "160959",
    "end": "165970"
  },
  {
    "text": "qu'on va être capable d'agréger plusieurs sources d'information on va souvent récupéré de la donner par",
    "start": "165970",
    "end": "171760"
  },
  {
    "text": "exemple de capteurs ou autres mais surtout ce qui va être intéressant c'est de croiser ces données là avec des",
    "start": "171760",
    "end": "177790"
  },
  {
    "text": "données qui viennent d'ailleurs d'une base de données de log pour vraiment mettre en valeur de l'information est",
    "start": "177790",
    "end": "183549"
  },
  {
    "text": "corrélé justement ces différentes informations le dernier v c'est la vélocité donc c'est la rapidité avec",
    "start": "183549",
    "end": "190720"
  },
  {
    "text": "laquelle justement on peut arriver à un résultat et avoir en retour extraire de l'information de ces données là",
    "start": "190720",
    "end": "197069"
  },
  {
    "text": "évidemment c'est quelque chose de critique également donc le big data marche plutôt jusqu'à",
    "start": "197069",
    "end": "203439"
  },
  {
    "text": "aujourd'hui en tout cas marché plutôt sur un modèle de baigts où on devait lancer un calcul qui pouvaient durer",
    "start": "203439",
    "end": "209110"
  },
  {
    "text": "plusieurs dizaines de minutes plusieurs heures c'est pas rare de voir des clients qui ont des clusters eux mêmes",
    "start": "209110",
    "end": "216010"
  },
  {
    "text": "donc c'est notre service de l'adhuc manager avec plusieurs centaines de noeux et il lance par exemple un calcul",
    "start": "216010",
    "end": "221469"
  },
  {
    "text": "tous les quatre heures qui durent lui-même deux heures aujourd'hui on a vraiment une tendance à",
    "start": "221469",
    "end": "228430"
  },
  {
    "text": "se rapprocher du temps réel pourquoi parce que c'est toujours de plus en plus critique pour prendre des décisions au",
    "start": "228430",
    "end": "234250"
  },
  {
    "text": "niveau métier d'avoir un retour rapidement et de pouvoir adapter son",
    "start": "234250",
    "end": "239469"
  },
  {
    "text": "comportement donc même c'est ce qu'on voit émerger aujourd'hui c'est une tendance en fait qui est là depuis très",
    "start": "239469",
    "end": "244689"
  },
  {
    "text": "longtemps si on prend par exemple les années 90 à l'époque on n'avait pas les systèmes technologiques qu'on a notre",
    "start": "244689",
    "end": "251299"
  },
  {
    "text": "disposition aujourd'hui donc quand on prenait des décisions au niveau du business par exemple est ce que pour une",
    "start": "251299",
    "end": "256310"
  },
  {
    "text": "entreprise américaine je vais faire une pub au super bowl cette année où je vais lancer une campagne marketing c'est pas",
    "start": "256310",
    "end": "262729"
  },
  {
    "text": "quelque chose qu'on pouvait faire beaucoup de fois dans l'année faire souvent donc quand on prenait la décision elle avait un impact business",
    "start": "262729",
    "end": "269870"
  },
  {
    "text": "qui était énorme avec les années 2000 on a eu des moyens informatiques plus",
    "start": "269870",
    "end": "275180"
  },
  {
    "text": "performant plus rapide donc par exemple on était capable de faire des campagnes marketing automatisé sur une base de",
    "start": "275180",
    "end": "281750"
  },
  {
    "text": "données de contacts en filtrant justement les gens qu'on allait cibler dans cette campagne et tout ça deux",
    "start": "281750",
    "end": "287330"
  },
  {
    "text": "factions industriels et automatique donc avec ça on pouvait faire des campagnes",
    "start": "287330",
    "end": "292669"
  },
  {
    "text": "marketing plus souvent tous les deux semaines trois semaines ou autres l'impact business étaient réduits par",
    "start": "292669",
    "end": "299810"
  },
  {
    "text": "campagne vu qu'il y en avait plusieurs mais ça permettait de faire de ces campagnes date de plus en plus",
    "start": "299810",
    "end": "306199"
  },
  {
    "text": "souvent et enfin ce à quoi on tend aujourd'hui donc plutôt les années 2010",
    "start": "306199",
    "end": "311810"
  },
  {
    "text": "c'est vraiment de prendre des décisions de manière extrêmement rapide et d'en",
    "start": "311810",
    "end": "317030"
  },
  {
    "text": "prendre beaucoup et surtout ces décisions vont être prises en une fraction de seconde pourquoi parce qu'en fait ça va être complètement automatisés",
    "start": "317030",
    "end": "323960"
  },
  {
    "text": "il y aura des alertes et en fait c'est des systèmes informatiques qui vont collecter ces données et qui vont ils",
    "start": "323960",
    "end": "329720"
  },
  {
    "text": "réagir on verra un exemple plus tard justement avec super celle par exemple",
    "start": "329720",
    "end": "336280"
  },
  {
    "text": "on a beaucoup d'outils vous voyez l'écosystème est vaste volontairement",
    "start": "336280",
    "end": "341660"
  },
  {
    "text": "j'ai mis beaucoup d'outils sur cette slide là rassurez-vous en plus je ne les",
    "start": "341660",
    "end": "346789"
  },
  {
    "text": "ai pas tous mis donc on peut vraiment voir que l'écosystème est très grand c'est dû à deux choses la première c'est",
    "start": "346789",
    "end": "353360"
  },
  {
    "text": "que même si certaines technologies sont matures aujourd'hui comme les technologies type hadoop par exemple il",
    "start": "353360",
    "end": "359539"
  },
  {
    "text": "ya beaucoup de mouvement dans cet écosystème là c'est quelque chose justement vers lequel on tend aujourd'hui c'est encore des",
    "start": "359539",
    "end": "364580"
  },
  {
    "text": "technologiques sont nouvelles donc il ya beaucoup d'outils qui se crée peut-être que dans quelques années il y aura un",
    "start": "364580",
    "end": "369590"
  },
  {
    "text": "phénomène de darwinisme et il en restera un peu moins le deuxième deuxième raison qui explique",
    "start": "369590",
    "end": "375830"
  },
  {
    "text": "pourquoi on a autant d'outils c'est le fait qu'il ya un an ti pattern dans le big data en se disant ben voilà ça va",
    "start": "375830",
    "end": "382580"
  },
  {
    "text": "être comme une application web je vais pouvoir mettre ma couche rouge et mon client m'a couché où j'aimais web server",
    "start": "382580",
    "end": "388430"
  },
  {
    "text": "et mes applications serveurs et dans ma base de données relationnelle classique donc erdimi ms je mets toutes mes",
    "start": "388430",
    "end": "395030"
  },
  {
    "text": "données que ça soit des données que j'archive que ce soit des données dont j'ai besoin rapidement que ce soit des",
    "start": "395030",
    "end": "400460"
  },
  {
    "text": "données qu'il faut que je requêtes de manière compliquée que ce soit des noës qu'il faut que je regarde de manière simple et on va vraiment utiliser la",
    "start": "400460",
    "end": "407420"
  },
  {
    "text": "base d'une ère relationnel comme un couteau suisse donc ça c'est quelque chose qu'il faut éviter absolument",
    "start": "407420",
    "end": "413360"
  },
  {
    "text": "pourquoi pas ça ne va pas fonctionner surtout si vous passez à l'échelle et que vous avez des terrains et des terrains a analysé enfin des dizaines de",
    "start": "413360",
    "end": "420410"
  },
  {
    "text": "terrains des centaines de terrains des pétaoctets de données donc c'est pour ça qu'on a plutôt dans",
    "start": "420410",
    "end": "425930"
  },
  {
    "text": "ce monde-là la philosophie de dire à chaque fois on va avoir un outil qui correspond vraiment à une tâche est ce",
    "start": "425930",
    "end": "432800"
  },
  {
    "text": "que je dois archives et de la donnée est ce que je dois à la stocker rapidement est-ce que je dois l'arc était rapidement en fonction de ça en fait on",
    "start": "432800",
    "end": "439190"
  },
  {
    "text": "va avoir un outil qui est adaptée et c'est pour ça qu ici on peut voir donc différents services amazon qui n'ont pas",
    "start": "439190",
    "end": "445310"
  },
  {
    "text": "les mêmes fonctions amazon elastic âge ça va être un service de cash in memory manager donc avec du riz 10 et même",
    "start": "445310",
    "end": "453830"
  },
  {
    "text": "cachent des amazones dynamo db c'est notre service de base de données nosql amazon s3 ça va être plus pour stocker",
    "start": "453830",
    "end": "460010"
  },
  {
    "text": "des fichiers voilà donc à chaque fois on va avoir vraiment un service qui correspond à un usage bien précis donc j'en profite dans",
    "start": "460010",
    "end": "467900"
  },
  {
    "text": "cette session pour vous dire que vous avez qu'il ya énormément d'outils on va parcourir certains d'entre eux le but",
    "start": "467900",
    "end": "474200"
  },
  {
    "text": "c'est pas de ressortir de cette session en disant ça y est je sais que je vais utiliser tel métier à tel endroit pour ça mais c'est que déjà vous ayez une",
    "start": "474200",
    "end": "480740"
  },
  {
    "text": "première vue d'ensemble du sujet et que vous sachez au moins vers vous vous",
    "start": "480740",
    "end": "485870"
  },
  {
    "text": "orientez par rapport à votre cas d' usage dernier servi sur la droite et amazon",
    "start": "485870",
    "end": "491630"
  },
  {
    "text": "redshift qui est notre data warehouse à ce service donc je n'ai pas je ne vais",
    "start": "491630",
    "end": "497150"
  },
  {
    "text": "pas vous en parler c'est nico baron qui va me rejoindre sur scène de la société folle analytics qui va nous faire un",
    "start": "497150",
    "end": "503330"
  },
  {
    "text": "retour d'expérience justement sur son utilisation je vous prie de l'acquérir",
    "start": "503330",
    "end": "509110"
  },
  {
    "text": "pour acquise alors ça devrait marcher dans quelques",
    "start": "512950",
    "end": "519820"
  },
  {
    "text": "instants c'est bon donc je vais très rapidement présenter notre entreprise donc folle",
    "start": "519820",
    "end": "526720"
  },
  {
    "text": "analytics la plateforme construite une plateforme de marketing automation donc c'est",
    "start": "526720",
    "end": "532230"
  },
  {
    "text": "globalement ça s'oriente autour de deux grands services la capacité à comprendre ce que les utilisateurs vont faire dans",
    "start": "532230",
    "end": "538990"
  },
  {
    "text": "des applications mobiles qui sont des applications mobiles natives et la capacité à utiliser ces données pour",
    "start": "538990",
    "end": "545070"
  },
  {
    "text": "essayer de construire des services à valeur ajoutée au dessus et notamment tout ce qui est campagne marketing qui",
    "start": "545070",
    "end": "550240"
  },
  {
    "text": "vont être des campagnes marketing de deux types la première qui vont être des campagnes classiques avec du ciblage d'utilisateurs et l'envoi de campagne et",
    "start": "550240",
    "end": "556960"
  },
  {
    "text": "la deuxième qui justement la partie marketing automation qui va nous donner la possibilité de réagir à des",
    "start": "556960",
    "end": "561970"
  },
  {
    "text": "événements utilisateurs et essayer de personnaliser l'interaction que la marque va avoir avec cette utilisateurs",
    "start": "561970",
    "end": "567790"
  },
  {
    "text": "au travers du canal mobile donc c'est une plateforme qui est une plateforme édité en saas sur laquelle on a pris un",
    "start": "567790",
    "end": "573670"
  },
  {
    "text": "positionnement qui est clair qu'ils aient prendre un positionnement grand compte donc nous on va plutôt travailler pour des gens dans le banking ou dans",
    "start": "573670",
    "end": "579130"
  },
  {
    "text": "les télécoms ou dans l'industrie par opposition à certains services qui vont par exemple cibler les gens qui vont",
    "start": "579130",
    "end": "586000"
  },
  {
    "text": "être dans le jeu ou dans ce genre d'industrie donc voilà un focus qui éclaire sur sur une verticale business c'est une certaine qui a été créée à",
    "start": "586000",
    "end": "592240"
  },
  {
    "text": "paris et dont aujourd'hui le et de carter est à san francisco",
    "start": "592240",
    "end": "597900"
  },
  {
    "text": "alors les fonctionnalités j'ai commencé à vous en parlez donc globalement va couvrir suspecte de fonctionnalités la",
    "start": "598050",
    "end": "604090"
  },
  {
    "text": "partie analyse de comportement utilisateurs dans l'application donc une très grosse volumétrie de l'ogs je",
    "start": "604090",
    "end": "610510"
  },
  {
    "text": "reviendrai par la suite sur sur ce point qui est un des points clés de cette présentation a essayé de créer des profils d'utilisateurs et de la",
    "start": "610510",
    "end": "616630"
  },
  {
    "text": "segmentation sur les bases de ces données de ce volume de données qu'on va collecter avec une finalité en fait deux",
    "start": "616630",
    "end": "622300"
  },
  {
    "text": "finalités plus exactement la première c'est de créer de l'engagement donc d'être capable via le canal mobile soit",
    "start": "622300",
    "end": "627520"
  },
  {
    "text": "via des notifications push soit via des messages qu'on va appeler message in hope capables de créer de l'interaction",
    "start": "627520",
    "end": "632800"
  },
  {
    "text": "très personnalisé et très contextuelle pour les utilisateurs de ces applications mobiles et une deuxième",
    "start": "632800",
    "end": "639010"
  },
  {
    "text": "finalité de notre plateforme vu qu'on l'a ciblé les grands comptes c'est d'être capable de réconcilier le monde du mobile avec le monde rm notamment en",
    "start": "639010",
    "end": "645819"
  },
  {
    "text": "étant capable d'enrichir le crm et la connaissance client qu'on va avoir dans ce crm avec les données issues des",
    "start": "645819",
    "end": "651639"
  },
  {
    "text": "usages mobiles mais également d'avoir une boucle de feedback et dans le ciblage des campagnes marketing mobile qu'on va être capable de créer de",
    "start": "651639",
    "end": "658209"
  },
  {
    "text": "réutiliser ces données de crm et de connaissances utilisateurs qu'on peut avoir par ailleurs pour faire un meilleur ciblage et des choses encore",
    "start": "658209",
    "end": "664209"
  },
  {
    "text": "une fois plus plus personnalisés voilà notre stack technique très",
    "start": "664209",
    "end": "669339"
  },
  {
    "text": "rapidement donc il ya une variété de services qu'on va rendre sur la plate forme et je rejoins ce que ce que",
    "start": "669339",
    "end": "674350"
  },
  {
    "text": "michael disait tout à l'heure du court aujourd'hui c'est impossible je pense de créer une architecture avec une base de",
    "start": "674350",
    "end": "679449"
  },
  {
    "text": "données qui va répondre à toutes les problématiques donc nous globalement les a séparés en trois grandes problématiques on a tout",
    "start": "679449",
    "end": "684999"
  },
  {
    "text": "ce qui va être analyse de log est remontée d'informations de log puis analyse le plus possible en temps réel",
    "start": "684999",
    "end": "690009"
  },
  {
    "text": "de ses logs donc ça c'est la partie de gauche avec leur ai dit ce qui va s'attaquer les log",
    "start": "690009",
    "end": "695529"
  },
  {
    "text": "et ensuite c'est l'eau qui vont être déversées dans l'amazone redshift j'y reviens juste après des données dit",
    "start": "695529",
    "end": "700869"
  },
  {
    "text": "qu'on va dire plus transactionnel donc ça va être de la configuration le stockage de même utilisateur la",
    "start": "700869",
    "end": "705999"
  },
  {
    "text": "configuration de mes campagnes voilà un certain nombre de données où il ya très peu de volume par contiennent contraintes transactionnel qui est",
    "start": "705999",
    "end": "711579"
  },
  {
    "text": "importante qu'on va stocker dans un storage classique qui est paul gray et une dernière typologie de données qu'on",
    "start": "711579",
    "end": "717850"
  },
  {
    "text": "utilise qui sont les données qui vont venir soit de l'app store soit de google plaît donc un certain nombre de données publiques par exemple les writings où",
    "start": "717850",
    "end": "725709"
  },
  {
    "text": "les rankings d'applications qui sont globalement des données à très grosse volumétrie et sur lesquels nous on va avoir plus tôt des problématiques de",
    "start": "725709",
    "end": "731679"
  },
  {
    "text": "recherche doit la recherche d'une application aux recherches d'un ranking spécifiques etc etc ont adressé par un",
    "start": "731679",
    "end": "737289"
  },
  {
    "text": "couple élastique search et poserait dans cette présentation moi je vais plutôt me focaliser sur la partie de gauche donc",
    "start": "737289",
    "end": "742660"
  },
  {
    "text": "c'est à dire parler notamment de notre utilisation d'amazon redshift notre contexte contexte de start up",
    "start": "742660",
    "end": "749679"
  },
  {
    "text": "c'est à dire qu'il a fallu faire rapidement une première version de produits premier élément de contexte donc un",
    "start": "749679",
    "end": "756160"
  },
  {
    "text": "élément technique on utilisait on utilisait on utilise encore un petit peu mungo db qui avait pour rôle de récoltez",
    "start": "756160",
    "end": "763350"
  },
  {
    "text": "les log et de rené un certain nombre de traitements sur ces logs donc principalement du map reduce dans mango",
    "start": "763350",
    "end": "768990"
  },
  {
    "text": "qui avait pour but de calculer des agrégats et des statistiques assez classique on va retrouver dans notre métier des lits acquis viewers de lastic",
    "start": "768990",
    "end": "775800"
  },
  {
    "text": "inès ce genre à ce genre de metric un deuxième élément de contexte donc on va dire un problème de riches plutôt des",
    "start": "775800",
    "end": "782370"
  },
  {
    "text": "perspectives business intéressante pour l'entreprise donc une croissance importante du nombre de clients et du",
    "start": "782370",
    "end": "788430"
  },
  {
    "text": "nombre d'applications qu'on allait traiter dans la plateforme conséquence directe pour une équipe technique a évidemment beaucoup beaucoup plus de",
    "start": "788430",
    "end": "794820"
  },
  {
    "text": "volume de données à traiter tous les mois pour vous donner un ordre de grandeur sur les deux derniers mois on a géré plus de donner plus de l'ogs que",
    "start": "794820",
    "end": "801990"
  },
  {
    "text": "sur l'ensemble de l'existence de l'entreprise soit l'analytics qui a maintenant deux ans et demi voire quasiment trois ans et le dernier point",
    "start": "801990",
    "end": "809430"
  },
  {
    "text": "c'est un quelques problèmes de performances qui commencent à arriver à la fois sur nos calculs donc sur",
    "start": "809430",
    "end": "815310"
  },
  {
    "text": "l'agrégation de données dans mungo mais également enfin j'utilise le même terme pour parler de la performance mais",
    "start": "815310",
    "end": "821160"
  },
  {
    "text": "plutôt du point de vue de la vélocité des développements c'est à dire qu'on se retrouvait dans une situation où on",
    "start": "821160",
    "end": "826350"
  },
  {
    "text": "devait offrir beaucoup d'agrégats beaucoup de mapreduce du code qui était assez compliqué assez difficile à relier",
    "start": "826350",
    "end": "832440"
  },
  {
    "text": "avec globalement un constat qui étaient partagés dans l'équipe qui était qu'on commençait à toucher les limites de cette première architecture et",
    "start": "832440",
    "end": "838320"
  },
  {
    "text": "finalement on commence à se poser la question savoir si cette utilisation cette base de données en l'occurrence mungo dans notre cas était vraiment",
    "start": "838320",
    "end": "844410"
  },
  {
    "text": "adaptée aux métiers à ce qu'on avait envie de faire en terme de traitement de données donc voilà pour les pour les éléments de contexte et à quelques",
    "start": "844410",
    "end": "852210"
  },
  {
    "text": "challenges donc le premier un challenge assez évident pour une start up on avait globalement la possibilité de faire une",
    "start": "852210",
    "end": "857940"
  },
  {
    "text": "refonte assez large de la plate forme mais fallait que ça tienne ans maximum 6 mois parce qu'on pensait que c'était après ces six mois on commencera",
    "start": "857940",
    "end": "864270"
  },
  {
    "text": "réellement avoir des vrais problèmes de performance et avoir des vrais problèmes du coup à rendre le service qu'on a avec",
    "start": "864270",
    "end": "869430"
  },
  {
    "text": "une qualité de service suffisante le deuxième set on souhaitait vraiment un changement de",
    "start": "869430",
    "end": "874700"
  },
  {
    "text": "paradigme c'est à dire plutôt que d'avoir du prêt calcul systématique et du calcul d'agrégats systématique à",
    "start": "874700",
    "end": "880400"
  },
  {
    "text": "priori c'était plutôt d'essayer d'avoir une règle était plutôt du 80/20 c'est à dire autant que possible être capable",
    "start": "880400",
    "end": "885800"
  },
  {
    "text": "d'aller recruter la donner en temps réel et pour les 10 à 20 % de cas les plus compliqués avoir une stratégie qui était",
    "start": "885800",
    "end": "891950"
  },
  {
    "text": "du pré calculées voilà du rock et cas du requêtage plutôt d'agrégats qui avait été stocké à priori et je voulais je",
    "start": "891950",
    "end": "897950"
  },
  {
    "text": "vous en ai déjà parlé améliorer la productivité des développements on voulait retourner vers un modèle de",
    "start": "897950",
    "end": "903020"
  },
  {
    "text": "requêtage plus simple de la donner et surtout plus adaptées à ce qu'on construit comme produit donc autant que",
    "start": "903020",
    "end": "909710"
  },
  {
    "text": "possible et c'est de retourner vers un rock étages de type de type sql et globalement on a essayé de procéder",
    "start": "909710",
    "end": "917050"
  },
  {
    "text": "le plus possible de manière scientifique c'est à dire qu'on a regardé un peu le champ des possibles qui s'offrait à nous",
    "start": "917050",
    "end": "922670"
  },
  {
    "text": "on l'avait divisé en deux grands axes les bases de type mpp comme amazon red shift et par stream et toute la famille",
    "start": "922670",
    "end": "930740"
  },
  {
    "text": "donc c'est on a juste mis en doute mais globalement l'écosystème complet qui tournait autour d'hadoop",
    "start": "930740",
    "end": "936550"
  },
  {
    "text": "pourquoi on s'est focalisé plutôt sur un choix qui étaient autour des bases mpp pour la raison que j'ai évoqué juste",
    "start": "936550",
    "end": "942950"
  },
  {
    "text": "avant qu'ils étaient autant que possible on voulait un pattern requêtage en temps réel de la donne est plutôt essayer d'éviter le mode batch et le map reduce",
    "start": "942950",
    "end": "949100"
  },
  {
    "text": "qu'on avait déjà largement utilisées avant globalement le facteur de choix qu'on a fait entre amazon redshift éparses très",
    "start": "949100",
    "end": "955400"
  },
  {
    "text": "mal parce que je sais pas si beaucoup d'entre vous connaissent c'est une technologie qui est assez assez",
    "start": "955400",
    "end": "960589"
  },
  {
    "text": "confidentiel mais qui a dû qu'à des caractéristiques qui était qui était très intéressante pour nous notamment la possibilité de recruter en 6 kw elle de",
    "start": "960589",
    "end": "967760"
  },
  {
    "text": "la donner sur un très très gros volumes de données donc comme on a procédé globalement on a pris la volumétrie",
    "start": "967760",
    "end": "972890"
  },
  {
    "text": "qu'on avait de données actuelles on a essayé de créer des jeux de données aussi représentatif que possible et on",
    "start": "972890",
    "end": "978560"
  },
  {
    "text": "apprenait ces jeux de données ou mesurer nos performances sur sur les deux technologies performance assez similaire en fait",
    "start": "978560",
    "end": "985100"
  },
  {
    "text": "entre entre les deux technologies donc ce n'est pas forcément un bon axe de choix de dugny comprendre cet art",
    "start": "985100",
    "end": "990200"
  },
  {
    "text": "e-performance pardon il ya un autre axe qui est très important surtout dans une équipe comme la mienne qui est globalement une équipe où il ya plutôt",
    "start": "990200",
    "end": "996410"
  },
  {
    "text": "des profils développeurs que des profils obs c'était la facilité à maintenir à faire ce qu'elle est la plateforme a",
    "start": "996410",
    "end": "1002500"
  },
  {
    "text": "rajouté un nouveau né au cluster et globalement toute cette simplicité cette facilité d'administration",
    "start": "1002500",
    "end": "1007970"
  },
  {
    "text": "qui était beaucoup moins présente chez par stream est beaucoup plus présente dans l'écosystème amazon donc c'est",
    "start": "1007970",
    "end": "1013680"
  },
  {
    "text": "plutôt ce deuxième axe en fait qui nous a fait nous orienter une fois qu'on avait pris la décision de partir sur des bases mbp plutôt sur sur red shift que",
    "start": "1013680",
    "end": "1020970"
  },
  {
    "text": "sur par stream rapidement la façon dont on ingère les log ont fêté les perspectives qu'on va",
    "start": "1020970",
    "end": "1027120"
  },
  {
    "text": "avoir notamment autour de la stac kws aujourd'hui en fait tous les téléphones donc ce qu'il faut voir dans notre",
    "start": "1027120",
    "end": "1033209"
  },
  {
    "text": "métier c'est que globalement on va développer un sdk donc à une librairie à ios android qui va être installé dans",
    "start": "1033209",
    "end": "1039780"
  },
  {
    "text": "chaque application de chacun de nos clients et globalement ce qu'il faut comprendre c'est qu'à chaque fois qu'il ya un utilisateur qui va faire une",
    "start": "1039780",
    "end": "1045990"
  },
  {
    "text": "action même si on n'en voit pas ligne à ligne et on arrive à avoir un petit mode batch dans notre sdk on va voir les",
    "start": "1045990",
    "end": "1051090"
  },
  {
    "text": "volumétries de données qui remonte minute par minute qui est plutôt très importante donc on a tendance en fait à",
    "start": "1051090",
    "end": "1056340"
  },
  {
    "text": "découpler a stocké dans un premier temps dans les dix ce qui va permettre notamment de décrire très vite ce qui est une des caractéristiques de cette",
    "start": "1056340",
    "end": "1062460"
  },
  {
    "text": "technologie surtout de rendre la main rapidement au sdk pour éviter d'être interruptif autant que possible on va",
    "start": "1062460",
    "end": "1068730"
  },
  {
    "text": "avoir dans un deuxième temps une chaîne de traitement qui va prendre ses loques de pury 10 et qui va être capable de les déverser donc d'abord dans amazon s3 et",
    "start": "1068730",
    "end": "1075600"
  },
  {
    "text": "ensuite dans rennes chief in fine et sur laquelle sur ce storage on va être capable de lancer toutes nos requêtes de",
    "start": "1075600",
    "end": "1082470"
  },
  {
    "text": "capable de lancer nos analyses des calculs de fumel de parcours utilisateur des calculs des événements précédents événements suivants et des métriques par",
    "start": "1082470",
    "end": "1089130"
  },
  {
    "text": "agrégation à délire qui faisaient route ce genre ce genre de metric perspective pardon sur le slide avant du",
    "start": "1089130",
    "end": "1095970"
  },
  {
    "text": "coup évidemment quand vous regardez ce slide vous pouvez vous poser la question de ce qu'est ce qu'on peut faire de plus avec la stac amazon web service is et",
    "start": "1095970",
    "end": "1102870"
  },
  {
    "text": "d'opportunités intéressantes pour nous qui serait d'utiliser kinesis qui pourraient venir en remplacement de ray",
    "start": "1102870",
    "end": "1108480"
  },
  {
    "text": "10 et nous permettent notamment de faire un certain nombre de traitements dans le flux de d'agrégation et d'insertion des",
    "start": "1108480",
    "end": "1114000"
  },
  {
    "text": "données sur le amazon ricci dont globalement les tests qu'on a mené nous ce sont les tests suivants conseillers",
    "start": "1114000",
    "end": "1119190"
  },
  {
    "text": "on a pris plusieurs milliards de lignes de logs on a essayé autant que possible d'avoir des temps de réponse qui était",
    "start": "1119190",
    "end": "1124530"
  },
  {
    "text": "acceptable c'est à dire d'avoir le plus possible de nos requêtes qui tenait en moins de 10 secondes 10 secondes sur un",
    "start": "1124530",
    "end": "1130080"
  },
  {
    "text": "service d'analytics comme le nôtre donc un service sur lequel on va ingéré beaucoup de données mais on va avoir très peu",
    "start": "1130080",
    "end": "1135809"
  },
  {
    "text": "d'utilisateurs connectés en même temps sur la plateforme le but c'était quand même d'avoir une qualité une expérience utilisateur qui reste est acceptable",
    "start": "1135809",
    "end": "1142320"
  },
  {
    "text": "malgré tout on a quand même des utilisateurs qu'ils comprennent que derrière il ya beaucoup de volume de données donc on n'est pas à la",
    "start": "1142320",
    "end": "1147450"
  },
  {
    "text": "milliseconde par contre on essaye quand même de rester dans les temps de réponses qui sont acceptables pour ses utilisateurs et du coup voilà c'est ce",
    "start": "1147450",
    "end": "1152519"
  },
  {
    "text": "qu'on s'est fixés c'est d'essayer d'avoir 90 % de nos requêtes en moins de 10 secondes donc globalement voilà pour vous",
    "start": "1152519",
    "end": "1159360"
  },
  {
    "text": "comparer les deux avants mungo on était plutôt à sur mon goût on était plutôt à une échelle qui était à des dizaines de",
    "start": "1159360",
    "end": "1164370"
  },
  {
    "text": "millions de log et 11 et après calcul quasiment systématique même pour les métriques les plus simples aujourd'hui",
    "start": "1164370",
    "end": "1170220"
  },
  {
    "text": "on a des perspectives intéressantes à plusieurs milliards de lignes stockés dans red shift avec globalement encore",
    "start": "1170220",
    "end": "1175649"
  },
  {
    "text": "une fois un profil de requêtes inférieur à 10 secondes un point qui est très important pour ceux d'entre vous qui ont",
    "start": "1175649",
    "end": "1181799"
  },
  {
    "text": "envie de partir vers cette techno un redshift cd très jolie techno c'est pour ça que j'ai décidé de faire ce retour",
    "start": "1181799",
    "end": "1188580"
  },
  {
    "text": "d'expérience aujourd'hui parce que c'est un service dont on est très satisfait aujourd'hui malgré tout il ya quelques points d'attention à avoir qui est",
    "start": "1188580",
    "end": "1194460"
  },
  {
    "text": "notamment la partie design du schéma en amont et réflexion sur la façon dont laquelle on va structurer les données",
    "start": "1194460",
    "end": "1200240"
  },
  {
    "text": "quelques caractéristiques de la technologie dans lesquels je vais dans laquelle je vais pas rentrer aujourd'hui mais qui sont des patterns sur ce qui",
    "start": "1200240",
    "end": "1206279"
  },
  {
    "text": "s'appelle sorte qu'ils disent qu'ils des choses qu'il faut réfléchir en amont pour essayer d'avoir les choses les plus",
    "start": "1206279",
    "end": "1211740"
  },
  {
    "text": "optimisées par la suite ça passe aussi par des phases d'itérations c'est à dire qu'à un moment donné on va jouer avec notre jeu de données regardez ce qui se",
    "start": "1211740",
    "end": "1218370"
  },
  {
    "text": "passe et essayer de tuer un peu les choses pour qu'une fois qu'on va livrer le service et le mettre en production on est quelque chose qui soit le plus",
    "start": "1218370",
    "end": "1224460"
  },
  {
    "text": "performant possible ça demande globalement dans votre équipe d'avoir une ou plusieurs personnes qui",
    "start": "1224460",
    "end": "1231670"
  },
  {
    "text": "ce sont plutôt des plus vieux entre guillemets c'est à dire des gens avec des très bons réflexes autour du sql des très bons réflexes de modélisation de",
    "start": "1231670",
    "end": "1238120"
  },
  {
    "text": "données et nous fait on a la chance dans l'équipe d'avoir d'avoir une ou deux personnes avec ses caractéristiques là",
    "start": "1238120",
    "end": "1243400"
  },
  {
    "text": "et c'est vrai que ça a été un vrai accélérateur pour nous pour imaginer ce qu'il fallait faire et et construire le bon schéma est le bon service",
    "start": "1243400",
    "end": "1250560"
  },
  {
    "text": "les bénéfices pour nous et je reprends ce que ce que disait michael je pense que ces all white ou le ford my job donc",
    "start": "1250560",
    "end": "1257500"
  },
  {
    "text": "voilà c'est fait de l'analyse de log on a une problématique qui est peu d'utilisateurs en parallèle énormément",
    "start": "1257500",
    "end": "1263860"
  },
  {
    "text": "de données à procès c'est pour pour rendre le service et les quelques le qu'on doit faire je pense que red shift est très adapté à ça le deuxième point",
    "start": "1263860",
    "end": "1270730"
  },
  {
    "text": "qui était importante pour nous et qui était également un axe de choix entre la stac hadoop et et ce choix d'amazon red",
    "start": "1270730",
    "end": "1275890"
  },
  {
    "text": "shift c'est que 1 on avait une contrainte de six mois de dans l'équipe on n'avait ni compétences java puisque",
    "start": "1275890",
    "end": "1282010"
  },
  {
    "text": "sur notre stack on fait plutôt du rugby à noël ni compétence hadoop en tant que tel donc on pensait que le cap à franchir pour passer de notre",
    "start": "1282010",
    "end": "1288280"
  },
  {
    "text": "architecture existante à l' architecture cible était plus simple en passant par une technologie comme amazon red shift",
    "start": "1288280",
    "end": "1293650"
  },
  {
    "text": "quant à l'envers une stack à doute complète avec tous les écueils je pense qu'on aurait rencontré faute d'expérience et de vrais retours sur sur",
    "start": "1293650",
    "end": "1299890"
  },
  {
    "text": "la technologie dans l'équipe et puis le dernier point donc dont je vous ai déjà parlé qui est bien évidemment c'est un service manager donc avec le très bon",
    "start": "1299890",
    "end": "1306760"
  },
  {
    "text": "goût d'avoir tout ce qui est administration et opération qui est largement simplifié et qui nous permet",
    "start": "1306760",
    "end": "1312820"
  },
  {
    "text": "globalement dans l'équipe avec 1,2 me up ce de rendre un service qui je pense aujourd'hui est de qualité",
    "start": "1312820",
    "end": "1318690"
  },
  {
    "text": "je vais repasser la main amicale et je vous remercie de votre attention",
    "start": "1318690",
    "end": "1324030"
  },
  {
    "text": "merci beaucoup nicolas pour ce retour d'expérience on va maintenant décortiquer ensemble les différents",
    "start": "1326340",
    "end": "1333240"
  },
  {
    "text": "stades qui existe dans le big data ya toujours ces quatre stades qu'on retrouve le premier c'est de pouvoir",
    "start": "1333240",
    "end": "1338720"
  },
  {
    "text": "ingéré la donne et ensuite de pouvoir la stocker quelque part pour ensuite mener",
    "start": "1338720",
    "end": "1344190"
  },
  {
    "text": "une analyse justement sur cette donnée est partagée visualiser le résultat de",
    "start": "1344190",
    "end": "1349860"
  },
  {
    "text": "cette analyse donc ses stats sont très générique quand on parle par exemple de visualisation ça peut être une",
    "start": "1349860",
    "end": "1355679"
  },
  {
    "text": "application web avec des métriques d'ashbourne ça peut être un rapport excellent donc c'est vraiment des stades",
    "start": "1355679",
    "end": "1362580"
  },
  {
    "text": "qui sont assez générique on va mettre en opposition en fait dans le reste de cette présentation de mode de",
    "start": "1362580",
    "end": "1369150"
  },
  {
    "text": "fonctionnement le premier c'est le big data traditionnelle en mode batch donc c'est un calcul qui va être fait de",
    "start": "1369150",
    "end": "1375390"
  },
  {
    "text": "manière régulière et récurrentes et lorsqu'on va traverser en fait tous ces",
    "start": "1375390",
    "end": "1380610"
  },
  {
    "text": "différents stades c4 stan on a une réponse normalement en plusieurs minutes",
    "start": "1380610",
    "end": "1386520"
  },
  {
    "text": "dizaine de minutes voire heures et ce qui change en fait dans l'analyse en temps réel c'est qu'on va traverser de",
    "start": "1386520",
    "end": "1391950"
  },
  {
    "text": "la même façon ces différents stades mais cette fois signe on va effectuer cette traversée en seulement quelques secondes",
    "start": "1391950",
    "end": "1399380"
  },
  {
    "text": "donc c'est vraiment ça qui change et qu'on va mettre en un peu en opposition tout le reste de la présentation de la",
    "start": "1399380",
    "end": "1406289"
  },
  {
    "text": "première partie on va reprendre sur l'ingestion si on parle plutôt du mode batch",
    "start": "1406289",
    "end": "1412350"
  },
  {
    "text": "traditionnel ce qui va se passer on va essayer d'agréger des sources d'informations différentes donc ça peut être des informations qui sont déjà dans",
    "start": "1412350",
    "end": "1419010"
  },
  {
    "text": "une base de données ou des log sur un disque par exemple toutes les quatre heures il ya un petit procès ce qui va",
    "start": "1419010",
    "end": "1424679"
  },
  {
    "text": "tourner pour venir prendre c log et les envoyer à l'outil d'ingestion",
    "start": "1424679",
    "end": "1430529"
  },
  {
    "text": "cette fois ci quand on est dedans le temps réel on va plus pouvoir faire ça toutes les quatre heures il va",
    "start": "1430529",
    "end": "1436980"
  },
  {
    "text": "falloir stream et la donne est donc l'envoyer en continu vers l'outil",
    "start": "1436980",
    "end": "1442470"
  },
  {
    "text": "d'ingestion donc toutes les données qu'on peut stream et c'est vraiment n'importe quoi vous pouvez stream et des",
    "start": "1442470",
    "end": "1448830"
  },
  {
    "text": "log des données d écriture de base de données vous pouvez aussi récupérer déclic utilisateurs sur un site web",
    "start": "1448830",
    "end": "1455720"
  },
  {
    "text": "n'importe quel objet connecté à internet of things des smartphones voilà tout ce à quoi vous pouvez penser l'important là",
    "start": "1455720",
    "end": "1461909"
  },
  {
    "text": "dedans c'est vraiment que dès qu'il ya l'action qui va créer l'événement cet événement sera directement envoyé un",
    "start": "1461909",
    "end": "1468120"
  },
  {
    "text": "outil d'ingestion donc cet outil d'ingestion c'est quelque chose de nouveau c'est quelque chose qu'on n'avait pas avant et c'est ça qui permet",
    "start": "1468120",
    "end": "1474779"
  },
  {
    "text": "justement de traiter la donner en temps réel donc cet outil doit avoir plusieurs caractéristiques d'abord il doit être",
    "start": "1474779",
    "end": "1480510"
  },
  {
    "text": "capable de ce cas il est énormément pourquoi parce que sur la gauche envoyer les différentes sources d'information",
    "start": "1480510",
    "end": "1486570"
  },
  {
    "text": "ainsi j'ai des millions de smartphones et des millions de device qui m'envoient des informations faut que je sois capable de récupérer ce flux de données",
    "start": "1486570",
    "end": "1493650"
  },
  {
    "text": "qui est très important la deuxième chose c'est que je vais devoir persister la donne et aussi donc en fait l'outil d'ingestion dans ce cas là on tend elle",
    "start": "1493650",
    "end": "1500490"
  },
  {
    "text": "doit aussi gérer la partie stockage pour pouvoir directement renvoyer",
    "start": "1500490",
    "end": "1505950"
  },
  {
    "text": "l'information comme en voit sur la droite au processing la troisième chose c'est que tout ça ça",
    "start": "1505950",
    "end": "1512700"
  },
  {
    "text": "doit être fait en temps réel donc cette partie justement quand on traverse l'outil d'ingestion en fait on doit",
    "start": "1512700",
    "end": "1517710"
  },
  {
    "text": "mettre une seconde où quelques secondes maximum pour le traverser sinon on perd cette capacité de temps réel et la",
    "start": "1517710",
    "end": "1524250"
  },
  {
    "text": "dernière chose c'est qu'on doit avoir une flexibilité architecturale qui est mise à disposition sur la gauche on voit on a énormément de",
    "start": "1524250",
    "end": "1531360"
  },
  {
    "text": "sources qui arrive un peu de différents contextes et sur la droite on a des",
    "start": "1531360",
    "end": "1537090"
  },
  {
    "text": "lignes de processing qui sont claires donc en fait on a ça qui est ordonnée et on va pouvoir justement avoir différents",
    "start": "1537090",
    "end": "1543890"
  },
  {
    "text": "traitements et différents process donc c'est pour ça qu'on a créé et amazon kinesis qui est vraiment",
    "start": "1543890",
    "end": "1551970"
  },
  {
    "text": "représente cet outil là avec toutes ses propriétés là pour rentrer un peu plus dans la technique on voit sur la gauche",
    "start": "1551970",
    "end": "1558460"
  },
  {
    "text": "justement qu on a différentes sources de données on va pouvoir traverser amazon",
    "start": "1558460",
    "end": "1564039"
  },
  {
    "text": "kinesis tous les devices sur la gauche où les différents production de données",
    "start": "1564039",
    "end": "1569109"
  },
  {
    "text": "vont se connecter un endpoint kinesis et sur la droite on voit dans cet exemple",
    "start": "1569109",
    "end": "1574210"
  },
  {
    "text": "qu'on a trois types de traitements le premier c'est une application qui va juste prendre les données qui sont",
    "start": "1574210",
    "end": "1580419"
  },
  {
    "text": "envoyés les agrégés dédupliqués et les mettre sur s3 donc par exemple si je",
    "start": "1580419",
    "end": "1585639"
  },
  {
    "text": "vais être capable de log et toutes les données qui sont passés à travers kinésie je peux faire ça la plupart de clients de la plupart de nos clients",
    "start": "1585639",
    "end": "1592359"
  },
  {
    "text": "font ça pourquoi parce qu'ils veulent garder vraiment tout l'historique de toutes les données pourquoi parce",
    "start": "1592359",
    "end": "1598419"
  },
  {
    "text": "qu'aujourd'hui font peut-être des traitements sur ces données mais ils n'exploitent pas tous les champs donc demain s'ils se rendent compte que ah",
    "start": "1598419",
    "end": "1603519"
  },
  {
    "text": "bah tiens dentelle log il y avait tellement que maman je veut exploiter ils ont toujours cette donnée qui est à",
    "start": "1603519",
    "end": "1608619"
  },
  {
    "text": "disposition sur et ce trois noms qui peuvent revenir et faire de nouveaux calculs pour voir si effectivement cette donnée-là est intéressante ou non une",
    "start": "1608619",
    "end": "1616239"
  },
  {
    "text": "deuxième application ça va être par exemple créer une application web avec un dashboard et des métriques pour des",
    "start": "1616239",
    "end": "1622289"
  },
  {
    "text": "utilisateurs métier et leur dire rapidement d'un voilà il vient de se",
    "start": "1622289",
    "end": "1627639"
  },
  {
    "text": "passer ça dans les cinq dernières minutes dans la dernière heure dans les dernières deux heures et avoir juste des métriques reviennent donc là le",
    "start": "1627639",
    "end": "1633879"
  },
  {
    "text": "traitement c'est juste à partir de l'information qui passe d'extraire des métriques de faire un petit calcul et de",
    "start": "1633879",
    "end": "1639100"
  },
  {
    "text": "mettre sa disposition dans une base nosql comme dynamo db et enfin l'application 3 peut faire des choses",
    "start": "1639100",
    "end": "1645249"
  },
  {
    "text": "plus compliquées en se reposant sur par exemple amazon redshift c'est un datawarehouse à ce service ça reste une",
    "start": "1645249",
    "end": "1651190"
  },
  {
    "text": "base de données relationnelle donc il ya un schéma à respecter peut-être que les informations qui sont envoyées depuis",
    "start": "1651190",
    "end": "1657220"
  },
  {
    "text": "les smartphones ou les device ne respecte pas ce schéma-là donc l'application numéro 3 ce qu'elle va faire c'est que elle va filtrer la donne",
    "start": "1657220",
    "end": "1664239"
  },
  {
    "text": "et l'harmoniser peut-être l'enrichir pour qu'elle puisse rentrer dans le schéma du datawarehouse et ce qui est important",
    "start": "1664239",
    "end": "1670749"
  },
  {
    "text": "dans ce modèle là c'est qu'on sépare de manière très claire en fait tous les traits différents traitements fonctionnel",
    "start": "1670749",
    "end": "1676590"
  },
  {
    "text": "et la deuxième chose c'est que vous pouvez rajouter autant d'applications ici que vous voulez donc ça c'est",
    "start": "1676590",
    "end": "1681990"
  },
  {
    "text": "vraiment le point qui vous permet d'avoir une architecture qui est extrêmement flexible qui va répondre à",
    "start": "1681990",
    "end": "1687090"
  },
  {
    "text": "vos besoins aujourd'hui mais si demain vous changez d'avis vous dites voilà maintenant je veux faire un traitement différent sur m'a donné vous avez juste",
    "start": "1687090",
    "end": "1694110"
  },
  {
    "text": "à rajouter une nouvelle application encore un peu plus loin dans le détail",
    "start": "1694110",
    "end": "1699900"
  },
  {
    "text": "sur amazon kinesis l'unité de mesure c'est ce qu'on appelle le shard donc c'est vraiment l'unité de base un char",
    "start": "1699900",
    "end": "1706020"
  },
  {
    "text": "nhtsa permet de récupérer en entrée un mégaoctet par seconde en gérer un mégaoctet par seconde est d'avoir",
    "start": "1706020",
    "end": "1711840"
  },
  {
    "text": "jusqu'à 1000 transactions par seconde donc pour amener justement le scale si",
    "start": "1711840",
    "end": "1717330"
  },
  {
    "text": "vous avez un flux de données qui grossit vous allez pouvoir demander qu'il",
    "start": "1717330",
    "end": "1722400"
  },
  {
    "text": "n'existe de rajouter descharnes est à chaque fois vous allez gagner 1 mégaoctet par seconde en capacité en",
    "start": "1722400",
    "end": "1727890"
  },
  {
    "text": "entrée la deuxième chose c'est que amazon qui n'existent pas stocker vos données pendant 24 heures donc à partir",
    "start": "1727890",
    "end": "1734700"
  },
  {
    "text": "du moment où ça rentre dans kinesis vous n'avez plus à vous en soucier la donnée est stockée et accessible",
    "start": "1734700",
    "end": "1740669"
  },
  {
    "text": "pendant 24 heures donc toutes les applications qui vont être des riens qui n'hésite peuvent accéder à cette donnée",
    "start": "1740669",
    "end": "1746340"
  },
  {
    "text": "là pendant les prochaines 24 heures et le dernier élément qui est sûrement le",
    "start": "1746340",
    "end": "1752250"
  },
  {
    "text": "plus important c'est qu'encore une fois c'est complètement manager donc comme l'a dit nicolas c'est vraiment un",
    "start": "1752250",
    "end": "1758159"
  },
  {
    "text": "élément qui est non négligeable pourquoi parce que gérer ce type de système soi même oui on peut se dire je m en load",
    "start": "1758159",
    "end": "1765539"
  },
  {
    "text": "balancers et des instances ec2 et un auto scanning groupe si on essaye de faire ça c'est des choses qui sont très",
    "start": "1765539",
    "end": "1771000"
  },
  {
    "text": "complexes en fait qu'on est allé à déchets laissés nos clients qui nous ont dit justement qu'il avait beaucoup de difficulté à créer ce type de système",
    "start": "1771000",
    "end": "1776820"
  },
  {
    "text": "c'est pour ça qu'on a travaillé aussi sur amazon qui n'hésite donc le côté",
    "start": "1776820",
    "end": "1781830"
  },
  {
    "text": "manager vraiment un gros avantage d'amazon qui n'hésite je sais que quand",
    "start": "1781830",
    "end": "1787140"
  },
  {
    "text": "on dit à mégoter par seconde en termes de flux ça parle pas forcément beaucoup en tout cas moi ça me parlait pas",
    "start": "1787140",
    "end": "1792659"
  },
  {
    "text": "forcément beaucoup au début donc je vais prendre un exemple avec vous je pense que tout le monde connaît ici le fin",
    "start": "1792659",
    "end": "1797820"
  },
  {
    "text": "heureuse de twitter ceux qui ne connaissent pas en fait c'est le flux twitter avec tous les tweets qui passe",
    "start": "1797820",
    "end": "1803010"
  },
  {
    "text": "sur la planète donc ça représente nombre de données qui est assez conséquent on va prendre une hypothèse",
    "start": "1803010",
    "end": "1809669"
  },
  {
    "text": "donc c'est peut-être pas les hypothèses les plus récentes qui correspondent à ce que twitter est aujourd'hui mais c'est",
    "start": "1809669",
    "end": "1814809"
  },
  {
    "text": "ce que j'ai pu trouver en me baladant sur le net on va imaginer qu on a 500 millions de tweets par jour ce qui est",
    "start": "1814809",
    "end": "1820600"
  },
  {
    "text": "déjà pas mal ça fait un demi milliard de tweets à collecter quand même chaque",
    "start": "1820600",
    "end": "1825879"
  },
  {
    "text": "tweet il va peser de 4 ko et on va partir du principe que en a 24 heures",
    "start": "1825879",
    "end": "1832090"
  },
  {
    "text": "dans la journée s'est réparti de manière uniforme ya pas de pic est-ce que vous avez idée de combien ça peut représenter",
    "start": "1832090",
    "end": "1839169"
  },
  {
    "text": "en termes de mégaoctets par seconde est ce que c'est un 5 10 milles",
    "start": "1839169",
    "end": "1845700"
  },
  {
    "text": "allez-y soyez pas timides",
    "start": "1846029",
    "end": "1849690"
  },
  {
    "text": "combien 12 est-ce que j'ai mieux ailleurs",
    "start": "1851399",
    "end": "1857580"
  },
  {
    "text": "je vois les calculettes les calculettes sont interdites donc effectivement on est à 13h04",
    "start": "1858600",
    "end": "1864519"
  },
  {
    "text": "mégaoctets par seconde donc jean-pierre mas qui ont peut-être déjà travaillé le sujet",
    "start": "1864519",
    "end": "1869789"
  },
  {
    "text": "donc voilà voilà ce que ça représente 13 rue le 4 méga octets par seconde ça",
    "start": "1869789",
    "end": "1875169"
  },
  {
    "text": "représente cette charte dans amazon kinesis et là on est quand même en train de parler d'un flux de 500 millions de",
    "start": "1875169",
    "end": "1883210"
  },
  {
    "text": "tweets par jour donc c'est quelque chose de colossal tout ça pour vous dire que amazon kinesis pourra supporter la",
    "start": "1883210",
    "end": "1888909"
  },
  {
    "text": "charge de n'importe quel flux de données et en général avant d'arriver à ce type de volumétrie on en est loin très loin",
    "start": "1888909",
    "end": "1895629"
  },
  {
    "text": "quand on démarre l'autre point c'est que en plus d'être complètement manager ça",
    "start": "1895629",
    "end": "1900669"
  },
  {
    "text": "coûte par mois avec ce modèle 1 577 dollars donc pareil si on essaye de construire",
    "start": "1900669",
    "end": "1907509"
  },
  {
    "text": "le système soit même et qu'on arrive à l'opérer pour repérer ça il y en a justement qui ont bloqué sur le sujet",
    "start": "1907509",
    "end": "1914320"
  },
  {
    "text": "c'est des systèmes qui sont extrêmement complexes et en termes de prix on n'est pas du tout dans les mêmes échelles",
    "start": "1914320",
    "end": "1920669"
  },
  {
    "text": "l'exemple vous avez une ans stéphane a parlé ce matin c'est super c'est l' éditeur de clash of plein boom beach où",
    "start": "1920669",
    "end": "1928330"
  },
  {
    "text": "ils ont construit un dashboard en temps réel justement avec kinesis en ingérant tout ce qui venait la télémétrie de tous",
    "start": "1928330",
    "end": "1934059"
  },
  {
    "text": "les smartphones la valeur ajoutée ce que ça leur donne c'est que au niveau business ça leur permet vraiment de",
    "start": "1934059",
    "end": "1940549"
  },
  {
    "text": "prendre des décisions quant à la direction de leurs applicatifs mobiles aujourd'hui c'est juste un dashboard",
    "start": "1940549",
    "end": "1946789"
  },
  {
    "text": "mais si je refais le parallèle avec ce que j'ai présenté en début de session on peut imaginer bien voilà à tel niveau en",
    "start": "1946789",
    "end": "1952520"
  },
  {
    "text": "ce moment les utilisateurs en bloc et pour se débloquer de cette situation il a su est tous un marteau ou un canon je",
    "start": "1952520",
    "end": "1959690"
  },
  {
    "text": "ne sais quoi et on pourrait dire on a vu que tout le monde achète ce même objet je vais décider de faire une promotion",
    "start": "1959690",
    "end": "1964850"
  },
  {
    "text": "donc de manière automatique et industrialisés je vais passer une promotion sur le in app sur cet objet en",
    "start": "1964850",
    "end": "1970909"
  },
  {
    "text": "particulier à cet endroit là du jeu voilà c'est des choses qu'on pourrait imaginer dans le futur",
    "start": "1970909",
    "end": "1977260"
  },
  {
    "text": "donc si je reviens à mes différents stades on a vu amazon kinesis pour le",
    "start": "1977260",
    "end": "1984080"
  },
  {
    "text": "stockage il y en a un autre qui existe qui s'appelle apache kafka donc ceux qui ont peut-être déjà se sont peut-être",
    "start": "1984080",
    "end": "1989600"
  },
  {
    "text": "déjà renseigné sur le sujet l'ont déjà vu on va dire que ils ont beaucoup de",
    "start": "1989600",
    "end": "1995330"
  },
  {
    "text": "caractéristiques communes les différences qui va y avoir c'est le fait que amazon kinesis on retient la donne",
    "start": "1995330",
    "end": "2000940"
  },
  {
    "text": "et 24 heures apache carcasse est configurable et amazon kinesis sommes entrés en fait les enregistrements font",
    "start": "2000940",
    "end": "2006250"
  },
  {
    "text": "50 ko maximum et dans la page carcasse est configurable ces chiffres-là côté",
    "start": "2006250",
    "end": "2011890"
  },
  {
    "text": "amazon kinesis c'est des choses qu'on a établi par rapport à notre base de clients si demain on a des retours comme",
    "start": "2011890",
    "end": "2019750"
  },
  {
    "text": "quoi c'est pas suffisant en terme de 2 ko qu'il faut par exemple plus que 50",
    "start": "2019750",
    "end": "2026910"
  },
  {
    "text": "ko c'est des choses sur lesquelles on peut travailler donc là on sera ravi en fait de requiert votre feedback là",
    "start": "2026910",
    "end": "2033210"
  },
  {
    "text": "dessus et de se mettre à travailler là dessus on a vu déjà sur dynamo db le fait qu' on rajoute par exemple les",
    "start": "2033210",
    "end": "2039240"
  },
  {
    "text": "haythem qu'on puisse stocker soit plus gros parce que pareil on a eu en retour utilisateur là dessus le point le plus",
    "start": "2039240",
    "end": "2044490"
  },
  {
    "text": "important c'est que encore une fois amazon kinesis est complètement aménagé ce qui est pas le cas de apache kafka ça",
    "start": "2044490",
    "end": "2052050"
  },
  {
    "text": "va être à vous de gérer vos kloster et tout ce système là pareil niveau prix c'est ça va pas",
    "start": "2052050",
    "end": "2059310"
  },
  {
    "text": "forcément être comparables en termes de d'instance scapêche kafka ça va être des instances à manager à faire tourner donc",
    "start": "2059310",
    "end": "2065490"
  },
  {
    "text": "notre recommandation c'est vraiment si vous utilisez amazon kinésie vous serez capable d'arriver beaucoup plus vite au",
    "start": "2065490",
    "end": "2070830"
  },
  {
    "text": "même résultat si petits problèmes de connexion avec la",
    "start": "2070830",
    "end": "2077940"
  },
  {
    "text": "télécommande moi aussi",
    "start": "2077940",
    "end": "2080869"
  },
  {
    "text": "alors excusez moi et un petit problème de télécommande alors pendant que c'est réglé je vais",
    "start": "2083390",
    "end": "2089370"
  },
  {
    "text": "quand même continuer maintenant qu'on a vu en fait la partie sur le stockage",
    "start": "2089370",
    "end": "2095399"
  },
  {
    "text": "après on va avoir le processing et là aussi vous allez trouver différents",
    "start": "2095400",
    "end": "2100490"
  },
  {
    "text": "outils dans le processing alors avant de passer là dessus on à la partie stockage à excuser moi sur le",
    "start": "2100490",
    "end": "2107070"
  },
  {
    "text": "bash on va pas rentrer dans le détail du match c'est pas forcément l'objet",
    "start": "2107070",
    "end": "2112320"
  },
  {
    "text": "aujourd'hui on est plus sur l'analyse en temps réel sachez que dans le match il ya encore une fois beaucoup d'outils",
    "start": "2112320",
    "end": "2117380"
  },
  {
    "text": "les pointeurs c'est de vous poser les bonnes questions donc pourquoi je vais utiliser une base de données plutôt",
    "start": "2117380",
    "end": "2122670"
  },
  {
    "text": "qu'une autre les questions à se poser c'est qu'elle est la donnée que je stocke cdu structurées et non structurées qui va faire les requêtes",
    "start": "2122670",
    "end": "2129450"
  },
  {
    "text": "pour qu'à l'udc du skate quelles charges doit avoir et ça ça vous permettra de vous orienter vers les bons les bons",
    "start": "2129450",
    "end": "2136500"
  },
  {
    "text": "outils sur la partie process maintenant là aussi on va avoir différents outils",
    "start": "2136500",
    "end": "2142980"
  },
  {
    "text": "les questions sont assez similaires en fait donc est ce que vous allez faire de",
    "start": "2142980",
    "end": "2148859"
  },
  {
    "text": "l'analytique et par là j'entends est ce que les requêtes que vous allez faire ont besoin de faire des scans sur des",
    "start": "2148859",
    "end": "2155670"
  },
  {
    "text": "millions d'enregistrements voir mire donc par exemple une requête analytique c'est sur un site e-commerce je veux",
    "start": "2155670",
    "end": "2161099"
  },
  {
    "text": "connaître le panier moyen des utilisateurs sur les 20 dernières années donc là effectivement je vais devoir",
    "start": "2161099",
    "end": "2166170"
  },
  {
    "text": "faire une analyse sur des milliards d'enregistrements ou est-ce que c'est plus des requêtes",
    "start": "2166170",
    "end": "2172369"
  },
  {
    "text": "différentes par exemple l'analyse et du sentiment ou récupérer des métriques qui sont pré calculées auquel cas je",
    "start": "2172369",
    "end": "2179309"
  },
  {
    "text": "n'aurais pas besoin du même type de base encore une fois l'autre partie importante c'est qu'ils posent ces",
    "start": "2179309",
    "end": "2185250"
  },
  {
    "text": "questions là est-ce que c'est à destination de gens du métier est-ce que c'est à destination des haines user",
    "start": "2185250",
    "end": "2191329"
  },
  {
    "text": "directement pareil on va pas mettre le même type de base de données il ya",
    "start": "2191329",
    "end": "2196530"
  },
  {
    "text": "certaines bases de données qui ne sont pas fait pour avoir des centaines de milliers de connexions ouverte mais plutôt très peu donc ça c'est quelque",
    "start": "2196530",
    "end": "2203369"
  },
  {
    "text": "chose d'important au cygne à prendre en compte et enfin quand est ce qu'on désire avoir le résultat est ce que",
    "start": "2203369",
    "end": "2208500"
  },
  {
    "text": "c'est de manière régulière toutes les semaines tous les mois ou est ce que c'est vraiment quelque chose dont j'ai besoin de temps et donc sur la partie",
    "start": "2208500",
    "end": "2215280"
  },
  {
    "text": "batch on a les outils traditionnels avec principalement du mrp big eyes et et",
    "start": "2215280",
    "end": "2223589"
  },
  {
    "text": "c'est sur la partie realtime sur laquelle je vais me concentrer on a dû apache spark",
    "start": "2223589",
    "end": "2230819"
  },
  {
    "text": "streaming qui permet de faire des analyses et côté amazon on va avoir plus tôt ce qu'on appelle les kinesis ap donc",
    "start": "2230819",
    "end": "2237690"
  },
  {
    "text": "en fait on a une librairie cliente qui n'existe que vous pouvez télécharger et en fait ce que cette libre effet",
    "start": "2237690",
    "end": "2243599"
  },
  {
    "text": "séquelles package les appels à kinesis pour dire voilà j'ai besoin d'avoir le prochain enregistrement rend le mois et",
    "start": "2243599",
    "end": "2249869"
  },
  {
    "text": "je peux le traité dont vous avez juste à vous préoccuper vraiment du code logique et de votre processing à cette étape là",
    "start": "2249869",
    "end": "2256630"
  },
  {
    "text": "et enfin le dernier composant c'est à w ce lambda non pour ceux qui ont vu la présentation précédente ça va vous",
    "start": "2256630",
    "end": "2263350"
  },
  {
    "text": "permettre en fait une intégration facile entre kinesis et lambda pour pouvoir procéder ces enregistrements encore une",
    "start": "2263350",
    "end": "2269560"
  },
  {
    "text": "fois en temps réel donc le schéma que vous allez voir est volontairement encore une fois il est assez exhaustif",
    "start": "2269560",
    "end": "2276310"
  },
  {
    "text": "donc il est assez grand on va classer justement ces différentes solutions en",
    "start": "2276310",
    "end": "2282340"
  },
  {
    "text": "fonction de deux choses le premier axe c'est la température de la donner est ce que c'est une donnée qui va changer bouger souvent ou est ce que c'est",
    "start": "2282340",
    "end": "2288670"
  },
  {
    "text": "quelque chose qui est très froid presque de l'archivage et la deuxième chose c'est quand je vais poser une question à",
    "start": "2288670",
    "end": "2294520"
  },
  {
    "text": "cette donnée en utilisant la solution est ce que je vais avoir une réponse de manière très rapide ou au contraire il",
    "start": "2294520",
    "end": "2299770"
  },
  {
    "text": "va falloir que j'attende un peu plus donc dans tout ce qui est en haut à gauche on va retrouver bien sûr sur de",
    "start": "2299770",
    "end": "2306340"
  },
  {
    "text": "la donne et qui est très chaude et un temps de réponse qui est très court ben tout ce dont je vous ai parlé avec amazon kinesis apache kafka spark les",
    "start": "2306340",
    "end": "2313480"
  },
  {
    "text": "kinesis hop là on est vraiment on peut pas être plus temps réel que ça et après",
    "start": "2313480",
    "end": "2318880"
  },
  {
    "text": "sur la droite on a par exemple dû dinamo db avec différents systèmes de requêtage et si je parte plutôt sur le côté droit",
    "start": "2318880",
    "end": "2326350"
  },
  {
    "text": "donc là on va être plutôt sur quelque chose d'assez froid si je prends par exemple la meule tout à droite amazon s3",
    "start": "2326350",
    "end": "2332380"
  },
  {
    "text": "c'est vraiment du stockage fichiers en général on on met le fichier on laisse là après on va peut venir le lire chaque",
    "start": "2332380",
    "end": "2337990"
  },
  {
    "text": "seconde là on peut connecter faire des intégrations avec par exemple redshift ou des clusters spark ou encore live et",
    "start": "2337990",
    "end": "2345790"
  },
  {
    "text": "jeu suivant ce qu'on utilise on va avoir la réponse plus ou moins rapidement donc encore une fois le but c'est pas de",
    "start": "2345790",
    "end": "2352210"
  },
  {
    "text": "sortir d'ici en sachant voilà je vais mettre du hive et du spark etc mais sait",
    "start": "2352210",
    "end": "2358750"
  },
  {
    "text": "plus où donner vraiment une vue d'ensemble l'équipe a w s est vraiment là pour vous accompagner aujourd'hui",
    "start": "2358750",
    "end": "2365320"
  },
  {
    "text": "mais aussi au quotidien nous là dessus on peut vraiment vous aider à avancer vous prodiguer des conseils en fonction",
    "start": "2365320",
    "end": "2371410"
  },
  {
    "text": "de vos cas d'usagé encore une fois l'écosystème est très riche c'est bien qu'il ya la demande de l'autre côté en",
    "start": "2371410",
    "end": "2377080"
  },
  {
    "text": "termes de cas des usages donc il faut vraiment prendre votre cas d' usage pour arriver à la bonne solution technique",
    "start": "2377080",
    "end": "2384610"
  },
  {
    "text": "donc si j'ai une vue d'ensemble il me manque la dernière étape qui est la visualisation donc là encore une fois",
    "start": "2384610",
    "end": "2392050"
  },
  {
    "text": "il ya beaucoup d'outils sur le marché je vous conseille de faire un tour sur la marketplace à w est ce qu on a des",
    "start": "2392050",
    "end": "2397930"
  },
  {
    "text": "éditeurs qui proposent des outils de visualisation et qui peuvent se connecter sur par exemple",
    "start": "2397930",
    "end": "2403830"
  },
  {
    "text": "redshift ou d'autres solutions pour visualiser les données et les partager",
    "start": "2403830",
    "end": "2409110"
  },
  {
    "text": "je vais vous faire une petite démo amazon kinesis alors est-ce qu'on peut changer switcher sur le mac s'il vous",
    "start": "2409110",
    "end": "2416920"
  },
  {
    "text": "plaît donc dans cette démo en fait ce que je vais vous montrer ses seins dashboard en",
    "start": "2416920",
    "end": "2424030"
  },
  {
    "text": "temps réel d'utilisateurs imaginons qu'on a un site",
    "start": "2424030",
    "end": "2429130"
  },
  {
    "text": "web avec chaque visite en fait chaque utilisateur va générer des données ces",
    "start": "2429130",
    "end": "2435280"
  },
  {
    "text": "données sont envoyées à kinesis et on a par exemple le département marketing qui veut être tenu au courant avec un",
    "start": "2435280",
    "end": "2441790"
  },
  {
    "text": "tableau en temps réel de combien le site à d'utilisateurs et d'autres métriques",
    "start": "2441790",
    "end": "2447310"
  },
  {
    "text": "de ce genre là donc je vais vous montrer côté",
    "start": "2447310",
    "end": "2452340"
  },
  {
    "text": "amazon ec2 les différentes instances qu'on a donc les instances qu'on a ici",
    "start": "2452340",
    "end": "2457660"
  },
  {
    "text": "en fait sont à la fois des instances qui perd qui permettent de faire tourner l'application web derrière en base de",
    "start": "2457660",
    "end": "2465100"
  },
  {
    "text": "données on a dû dinamo db et d'autres pas en fait cédé instance qui vont simuler les",
    "start": "2465100",
    "end": "2470670"
  },
  {
    "text": "utilisateurs donc elles vont faire des posts en fait sur amazon kinesis donc ici on a notre appli web qui",
    "start": "2470670",
    "end": "2478619"
  },
  {
    "text": "s'appelle le poste data analyzer je vais renseigner des données qui sont",
    "start": "2478619",
    "end": "2484230"
  },
  {
    "text": "présentes dans le stade que j'ai lancé donc toute cette démo en fête a été générée grâce à des thèmes plaide claude",
    "start": "2484230",
    "end": "2492029"
  },
  {
    "text": "formation donc c'est un un architecte de l'équipe que je remercie au passage qui s'appelle julien lépine qui a créé cette",
    "start": "2492029",
    "end": "2497519"
  },
  {
    "text": "démonstration est donc ici on peut voir dans le script l'autre formation",
    "start": "2497519",
    "end": "2502559"
  },
  {
    "text": "certaines informations des choses qui ont été créés automatiquement comme la table dynamo db qui contient ses",
    "start": "2502559",
    "end": "2509819"
  },
  {
    "text": "métriques là donc si je vais renseigner le nom de ma table et j'ai aussi un token vendor pour",
    "start": "2509819",
    "end": "2517799"
  },
  {
    "text": "générer des jetons et pouvoir faire mes requêtes sur la base dynamo db donc là",
    "start": "2517799",
    "end": "2523259"
  },
  {
    "text": "pour reprendre le flux on a des utilisateurs qui sont simulés ses utilisateurs vont via leur trafic en",
    "start": "2523259",
    "end": "2530640"
  },
  {
    "text": "fait et leur clique générer de l'information cette information est envoyé à kinesis directement et derrière",
    "start": "2530640",
    "end": "2537359"
  },
  {
    "text": "j'ai une application kinesis qui va faire un calcul léger pour avoir une",
    "start": "2537359",
    "end": "2543180"
  },
  {
    "text": "métrique et mettre ça dans la base dynamo db et nous on va consulter cette base dynamo db via cette interface web",
    "start": "2543180",
    "end": "2550680"
  },
  {
    "text": "donc là si je clique sur le bouton run je vais avoir justement des requêtes qui",
    "start": "2550680",
    "end": "2556440"
  },
  {
    "text": "vont passer derrière donc là elles sont en train de passer demandé à la base dynamo db ce qui",
    "start": "2556440",
    "end": "2563359"
  },
  {
    "text": "ce qu'il y a comme information et on va récupérer différentes métriques donc dans ce cas là c'est par exemple le",
    "start": "2563359",
    "end": "2569759"
  },
  {
    "text": "nombre de pages vues par navigateur il ya des navigateurs en dessous le nombre d'utilisateurs par navigateur",
    "start": "2569759",
    "end": "2577100"
  },
  {
    "text": "etc etc le nombre de sessions et là vous voyez en fait de temps en temps les graphiques vont sauter pourquoi parce",
    "start": "2577100",
    "end": "2583700"
  },
  {
    "text": "que toutes les 20 secondes en fait s'est mis à jour avec les derniers résultats qui ont été mis dans dynamo db donc là",
    "start": "2583700",
    "end": "2590900"
  },
  {
    "text": "on est vraiment sur le temps réel avec ce dashboard comme vous voyez naïade et des incréments qui sont faits toutes les",
    "start": "2590900",
    "end": "2597920"
  },
  {
    "text": "20 secondes ici et donc vous avez vraiment une vue à 20 secondes d'un trafic réel sur un site web donc là il",
    "start": "2597920",
    "end": "2604190"
  },
  {
    "text": "fait après effectivement vous pouvez mettre n'importe quel cas d'utilisation derrière la deuxième chose je n'ai pas",
    "start": "2604190",
    "end": "2610730"
  },
  {
    "text": "su me rappeler au milieu de la présentation on a aussi montré que la plupart des clients utilisent s3 pour",
    "start": "2610730",
    "end": "2616090"
  },
  {
    "text": "archiver toutes les données qu'ils peuvent voir ça aussi été fait dans",
    "start": "2616090",
    "end": "2621320"
  },
  {
    "text": "cette démonstration donc si je vais sur mon budget amazon s3 des mots kinesis je",
    "start": "2621320",
    "end": "2626450"
  },
  {
    "text": "vais voir en fait le résultat juste les données brutes qui ont été stockés sur reste roi donc on voit qu'on est l'année",
    "start": "2626450",
    "end": "2632900"
  },
  {
    "text": "2015 entre 31 et je vais prendre cette",
    "start": "2632900",
    "end": "2638390"
  },
  {
    "text": "heure-là et là je vais avoir un ensemble en fait d' archives donc c'est juste des archives j'ai z si j'essaie d'ouvrir",
    "start": "2638390",
    "end": "2645110"
  },
  {
    "text": "dedans je vais voir de juste des log et qui apparaissent donc là on a vraiment",
    "start": "2645110",
    "end": "2651620"
  },
  {
    "text": "la partie archimage ce qu'on peut revenir sur la fin de la présentation s'il vous plaît donc là voilà on a cet",
    "start": "2651620",
    "end": "2657650"
  },
  {
    "text": "exemple kinesis avec ses deux branches encore une fois le but c'est que vous",
    "start": "2657650",
    "end": "2662930"
  },
  {
    "text": "pouvez rajouter une branche supplémentaires et avoir n'importe quel",
    "start": "2662930",
    "end": "2668680"
  },
  {
    "text": "n'importe quelle application qui ferait n'importe quel traitement",
    "start": "2668680",
    "end": "2673539"
  },
  {
    "text": "juste redemander est-ce qu'on peut repasser sur le le slide ppt s'il vous plaît donc la démo est fini je vais",
    "start": "2673750",
    "end": "2682010"
  },
  {
    "text": "passer pour gagner du temps donc ce qui est à retenir en fait dans cette présentation c'est que kinesis",
    "start": "2682010",
    "end": "2688760"
  },
  {
    "text": "c'est vraiment votre point d'entrée pour toutes vos analyses temps réel ça vous permettra vraiment de faire rentrer",
    "start": "2688760",
    "end": "2694460"
  },
  {
    "text": "votre données de manière scalable de manière manager et derrière ça d'utiliser toute la puissance du cloud",
    "start": "2694460",
    "end": "2701480"
  },
  {
    "text": "amazon donc après ça vous pourrez utiliser le service qui vous va bien la base de données qui vous va bien",
    "start": "2701480",
    "end": "2707050"
  },
  {
    "text": "et satisfaire n'importe quel cas d'utilisation que vous voulez donc ça va",
    "start": "2707050",
    "end": "2712600"
  },
  {
    "text": "vous permettre de faire et de l'analyse en temps réel mais aussi toujours de satisfaire l'analyse en mode batch une",
    "start": "2712600",
    "end": "2719080"
  },
  {
    "text": "fois que les données sont stockées sur s3 par exemple vous pouvez déclencher des traitements er pour venir faire",
    "start": "2719080",
    "end": "2724930"
  },
  {
    "text": "d'autres types de calculs avant de finir cette présentation je",
    "start": "2724930",
    "end": "2730660"
  },
  {
    "text": "voulais vous rappeler deux choses la première c'est qu'on a le ce mythe a w s qui aura lieu le 23 juin on aura notre",
    "start": "2730660",
    "end": "2738340"
  },
  {
    "text": "city au werder vos gueules ce qui sera là présents le matin l'après-midi des breaks out séssion un peu comme cet",
    "start": "2738340",
    "end": "2744550"
  },
  {
    "text": "après midi donc n'hésitez pas à faire un tour sur le site pour voir le programme et vous inscrire la deuxième pour ce",
    "start": "2744550",
    "end": "2750730"
  },
  {
    "text": "qu'ils n'ont pas fait n'hésitez pas à vous inscrire activate donc si vous",
    "start": "2750730",
    "end": "2756100"
  },
  {
    "text": "n'avez pas les liens ou que vous avez eu du mal à flasher le qr code n'hésitez pas à venir au stand on sera disponible",
    "start": "2756100",
    "end": "2763390"
  },
  {
    "text": "donc je rappeler nicolas pour qu'il revienne sur scène on va je sais qu'on a un peu dépassé l'horaire ci en a qui",
    "start": "2763390",
    "end": "2770620"
  },
  {
    "text": "veulent poser quelques questions on va prendre deux trois minutes 300 minutes pour répondre aux questions après on",
    "start": "2770620",
    "end": "2777340"
  },
  {
    "text": "sera de toute façon disponible sur les stands et je vous invite aussi pour ceux qui veulent directement sorti en a",
    "start": "2777340",
    "end": "2783580"
  },
  {
    "text": "maintenant une demi-heure de cocktails et de networking donc c'est à l'étagé du",
    "start": "2783580",
    "end": "2788830"
  },
  {
    "text": "dessus vous avez déjà eu les rafraîchissements donc je vous remercie pour votre attention",
    "start": "2788830",
    "end": "2796230"
  },
  {
    "text": "est question là bas au fond un bon",
    "start": "2801150",
    "end": "2805380"
  },
  {
    "text": "jour bonjour pour vous utilisiez mungo dans",
    "start": "2808200",
    "end": "2813629"
  },
  {
    "text": "la première version 2 de votre applicatifs et je voulais vous",
    "start": "2813629",
    "end": "2818710"
  },
  {
    "text": "demander à partir de combien à peu près de 2 millions de lignes vous avez",
    "start": "2818710",
    "end": "2825340"
  },
  {
    "text": "commencé à remarquer des problèmes sur les sur les agrégats et est ce que ces",
    "start": "2825340",
    "end": "2831060"
  },
  {
    "text": "millions de documents étaient dans des collections différentes ou pas avec des",
    "start": "2831060",
    "end": "2836500"
  },
  {
    "text": "index ou pas enfin une réponse simple réponse à la deuxième partie de votre",
    "start": "2836500",
    "end": "2842290"
  },
  {
    "text": "question réponse ah oui quasiment à tous donc faire la façon dont globalement nous l'unité de mesure qu'on utilisant",
    "start": "2842290",
    "end": "2848140"
  },
  {
    "text": "la plateforme ce qu'on appelle une mobile session une nouvelle session elle est composée d'un certain nombre de log",
    "start": "2848140",
    "end": "2854890"
  },
  {
    "text": "voilà pour le faire très simple et donc du coup ce qu'on ne peut qu est-ce qu on stocke et seront stockés dans mon corps",
    "start": "2854890",
    "end": "2859900"
  },
  {
    "text": "c'était ce document qui représentait la mauvaise session qui était du coup accéder de plusieurs manières par la",
    "start": "2859900",
    "end": "2866350"
  },
  {
    "text": "suite notamment pour le calcul de l'agrégat je crois que votre trop de questions c'était sur la volumétrie à partir de quand on a commencé à",
    "start": "2866350",
    "end": "2872020"
  },
  {
    "text": "ressentir des problèmes globalement je vous donnerai un ordre de grandeur qui a plusieurs de dizaines de millions log on",
    "start": "2872020",
    "end": "2878770"
  },
  {
    "text": "a commencé à sentir des choses qui commencent à être plus compliquée encore une fois je reviens sur mon autre point au delà de je pense qu'on aurait pu",
    "start": "2878770",
    "end": "2884920"
  },
  {
    "text": "faire plein d'autres choses sur la perf plan d'optimisation plein de choses on aurait pu aller plus loin dans du char d'ingo dans ce genre de choses le point",
    "start": "2884920",
    "end": "2893140"
  },
  {
    "text": "de difficultés qu'on rencontre s était également un coût de développement qui était assez important par rapport au type d' analyse qu'on voulait faire et",
    "start": "2893140",
    "end": "2899290"
  },
  {
    "text": "c'est ça aussi qui nous fait nous poser la question de la migration et de bouger vers le service donc c'est celle un plus",
    "start": "2899290",
    "end": "2905800"
  },
  {
    "text": "l'autre mon but encore une fois j'ai oublié de le préciser mais ce n'est pas du tout de faire du pointage du doigt",
    "start": "2905800",
    "end": "2911500"
  },
  {
    "text": "pour dire mungo ces biens ne s'est pas bien etc c'est jusqu'à un moment donné on a enfin comme dans une start-up ya",
    "start": "2911500",
    "end": "2917440"
  },
  {
    "text": "une notion qui est qui est vraiment centrale qui est le temps et la vitesse à exécuter être capable de skier et de s'adapter on a pensé que si on irait",
    "start": "2917440",
    "end": "2924160"
  },
  {
    "text": "plus vite à faire cette migration plutôt qu'à essayer d'optimiser notre existants et et re travailler dessus et on avait",
    "start": "2924160",
    "end": "2929260"
  },
  {
    "text": "vraiment des problèmes de maintenabilité dans le code donc mon logo s'est orientée documents donc ça veut dire qu'on stocke des documents avec à chaque",
    "start": "2929260",
    "end": "2935410"
  },
  {
    "text": "fois le nom de là la donne et qui est répétait lula colonnes en quelque sorte",
    "start": "2935410",
    "end": "2940839"
  },
  {
    "text": "et donc du coup on se retrouve avec des collections qui était assez peu explicite sur la façon de les racketter et désagréable après douze qui étaient",
    "start": "2940839",
    "end": "2946180"
  },
  {
    "text": "assez dur à lire donc encore une fois cette partie lisibilité et maintenabilité du code c'était aussi un gros axe pour nous voilà à retravailler",
    "start": "2946180",
    "end": "2953019"
  },
  {
    "text": "donc c'était le plus l'autre qui ont fait qu'on a migré merci vous en prie",
    "start": "2953019",
    "end": "2959249"
  },
  {
    "text": "oui",
    "start": "2959910",
    "end": "2962910"
  },
  {
    "text": "bonjour concernant la problématique inédit je voulais savoir quel était votre pricing vis-à-vis des différents",
    "start": "2968480",
    "end": "2974850"
  },
  {
    "text": "chars qui vous aviez vous proposiez et aussi la facilité ou pas de mettre en place en fait ce système de monitoring",
    "start": "2974850",
    "end": "2981990"
  },
  {
    "text": "et de pouvoir réguler le nombre de charges en fonction de la volumétrie de données qui augmente ou diminue alors le",
    "start": "2981990",
    "end": "2988470"
  },
  {
    "text": "prix en fait sur amazon kinesis il va être fonction de deux axes le premier c'est le nombre de chardes à l'heure",
    "start": "2988470",
    "end": "2994890"
  },
  {
    "text": "qu'on a et le deuxième en fait c'est le nombre de poutres et quand qu'on va faire un qui n'hésite donc combien",
    "start": "2994890",
    "end": "3000410"
  },
  {
    "text": "d'informations en fait on va envoyer donc le pouls tricorne de mémoire on pourra confirmer ça après ensemble sur",
    "start": "3000410",
    "end": "3006530"
  },
  {
    "text": "le site ce que tous les tous les prix sont affichés sur le site en public mais c'est aux millions de poux tricorne qui coûte quelques centimes est pareil le",
    "start": "3006530",
    "end": "3013430"
  },
  {
    "text": "shard à l'heure ces quelques centimes donc ça c'est les deux axes on peut",
    "start": "3013430",
    "end": "3019940"
  },
  {
    "text": "regarder ça après vraiment sur le site pendant le prix précis mais l'ordre de grandeur c'est ça et après pour tout",
    "start": "3019940",
    "end": "3025940"
  },
  {
    "text": "l'aspect monitoring en fait vous avez des métriques de base qui viennent avec votre utilisation de kinesis ça va être",
    "start": "3025940",
    "end": "3032390"
  },
  {
    "text": "des métriques claude watch donc là dessus justement vous avez le nombre de poterie corne qui ont été faits vous",
    "start": "3032390",
    "end": "3038600"
  },
  {
    "text": "avez le nombre de la volumétrie de données qui rentre dans votre flux qui en sort donc en fait toutes ses",
    "start": "3038600",
    "end": "3044000"
  },
  {
    "text": "métriques là ça va vous donner les infos d'utilisation de votre stream kinesis et comme ce sont des métriques claude watch",
    "start": "3044000",
    "end": "3050030"
  },
  {
    "text": "vous pouvez facilement mettre des alertes donc par exemple quand je dépasse tel seuil de volumétrie je veux",
    "start": "3050030",
    "end": "3057350"
  },
  {
    "text": "être averti par l' alerte et donc réagir en conséquence donc en fait c'est via ce mécanisme là que vous allez être capable",
    "start": "3057350",
    "end": "3064100"
  },
  {
    "text": "de réagir et dire et en effet je peux ajouter un char doit au contraire les marges est d'accord et donc cette",
    "start": "3064100",
    "end": "3069560"
  },
  {
    "text": "opération l emmanuel fait venir ajouter un char ne s'est pas utile et pas forcément la notion d'auto d'âge ou de",
    "start": "3069560",
    "end": "3076490"
  },
  {
    "text": "suppression de charges alors la scalabilité elle n'est pas gérée automatiquement par amazon donc",
    "start": "3076490",
    "end": "3081890"
  },
  {
    "text": "effectivement cette action-là une fois qu'il ya une alerte c'est à vous de passer à un autre appel à pays pour dire je veux rajouter un charles ou au",
    "start": "3081890",
    "end": "3087770"
  },
  {
    "text": "contraire je veux en vers",
    "start": "3087770",
    "end": "3091430"
  },
  {
    "text": "qu'on a d'autres questions oui",
    "start": "3094790",
    "end": "3101030"
  },
  {
    "text": "alors la question c'est en utilisant un projet qui en ruby et redshift est ce qu",
    "start": "3113999",
    "end": "3120059"
  },
  {
    "text": "un driver justement à w s pour rubis ou est-ce qu'on doit utiliser ceux qui sont émis par la communauté donc aujourd'hui",
    "start": "3120059",
    "end": "3127199"
  },
  {
    "text": "effectivement il ya ceux de la communauté dont on peut se servir on n'a pas de drivers encore officiel ruby par",
    "start": "3127199",
    "end": "3134519"
  },
  {
    "text": "contre c'est un excellent feedback donc toutes les demandes en fait à chaque fois on va les prendre",
    "start": "3134519",
    "end": "3140149"
  },
  {
    "text": "les faire remonter aux équipes produit donc moi je pourrais faire remonter sa également et s'il ya effectivement une",
    "start": "3140149",
    "end": "3146519"
  },
  {
    "text": "demande de la part de la communauté là dessus oui c'est des choses sur lesquelles on se mettra à travailler",
    "start": "3146519",
    "end": "3151769"
  },
  {
    "text": "comme par exemple sur la casse et l amazone kinesis on vient de la rendre disponible en othe jsk ce qui est",
    "start": "3151769",
    "end": "3157769"
  },
  {
    "text": "beaucoup de demandes en eau -js donc pour tous ceux qui ont ce type de demandes là n'hésitez pas à le faire",
    "start": "3157769",
    "end": "3162929"
  },
  {
    "text": "remonter et je rebondis aussi sur la question d'avant le fait que ça soit automatique par exemple pour rajouter",
    "start": "3162929",
    "end": "3169289"
  },
  {
    "text": "des charges nous autres faut pas hésiter à nous faire remonter suite bac parce qu'effectivement il ya beaucoup de gens qui le demandent c'est des choses sur",
    "start": "3169289",
    "end": "3175589"
  },
  {
    "text": "lesquelles on m a dit",
    "start": "3175589",
    "end": "3178159"
  },
  {
    "text": "je pense qu'on va pouvoir clore la session de questions donc encore une",
    "start": "3181429",
    "end": "3186449"
  },
  {
    "text": "fois merci pour votre attention et on se retrouvera en eau pour l'espace cocktail",
    "start": "3186449",
    "end": "3192809"
  },
  {
    "text": "et networking merci beaucoup et merci merci à nicolas",
    "start": "3192809",
    "end": "3197989"
  }
]
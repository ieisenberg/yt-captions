[
  {
    "start": "0",
    "end": "46000"
  },
  {
    "text": "afternoon everyone my name is John I'm cough I'm the lead product manager for elastic MapReduce which is Amazon's",
    "start": "0",
    "end": "5819"
  },
  {
    "text": "managed Hadoop service I'm going to talk for about 15 20 minutes about Big Data",
    "start": "5819",
    "end": "11370"
  },
  {
    "text": "at AWS and specifically elastic MapReduce and then we're very fortunate",
    "start": "11370",
    "end": "16410"
  },
  {
    "text": "to have a speaker from Intel to talk about some of the very interesting things that Intel and Amazon are doing",
    "start": "16410",
    "end": "22320"
  },
  {
    "text": "together to enable Big Data want to just say before I get started I recognize",
    "start": "22320",
    "end": "28050"
  },
  {
    "text": "this is the last session in a packed day it's beautiful weather out so we'll probably try to get through the material",
    "start": "28050",
    "end": "34530"
  },
  {
    "text": "and if possible give you back 15 or 20 minutes to go and enjoy the weather or you can check out the expo which I",
    "start": "34530",
    "end": "40170"
  },
  {
    "text": "believe starts at 5 o'clock which is downstairs where we're lunch was served",
    "start": "40170",
    "end": "46399"
  },
  {
    "start": "46000",
    "end": "73000"
  },
  {
    "text": "so let's get started I'm going to talk about four things we're gonna talk a little bit about Big Data we're going to",
    "start": "46399",
    "end": "51660"
  },
  {
    "text": "talk about some examples of organizations that have turned data into actionable information we're gonna talk",
    "start": "51660",
    "end": "58590"
  },
  {
    "text": "a little bit about analytics and cloud computing and then we're gonna talk for a few minutes about the big data",
    "start": "58590",
    "end": "63809"
  },
  {
    "text": "ecosystem and in particular Amazon our AWS data pipeline which if you were here for the keynote this morning you heard a",
    "start": "63809",
    "end": "70200"
  },
  {
    "text": "little bit about so first let's talk a little bit about Big Data I'm sure",
    "start": "70200",
    "end": "75570"
  },
  {
    "start": "73000",
    "end": "126000"
  },
  {
    "text": "everybody in the room has heard the cliche at this point pitch around the",
    "start": "75570",
    "end": "81180"
  },
  {
    "text": "three V's around volume velocity variety I'm not gonna do that I'll spare you that I think another way to think about",
    "start": "81180",
    "end": "88320"
  },
  {
    "text": "big data is to think about the data lifecycle so if you think about it in terms of these four stages you've got",
    "start": "88320",
    "end": "94560"
  },
  {
    "text": "generation of data collection and storage of data the analytics and the computation on that data and then",
    "start": "94560",
    "end": "100860"
  },
  {
    "text": "finally the collaboration and sharing of that data and what we've seen over the",
    "start": "100860",
    "end": "105990"
  },
  {
    "text": "last few years is that the cost of data generation has fallen dramatically it's now very affordable to generate lots of",
    "start": "105990",
    "end": "114000"
  },
  {
    "text": "data very very quickly and as a result what we see is a bottleneck at stage two",
    "start": "114000",
    "end": "119880"
  },
  {
    "text": "which is the collection and storage and it follows through to analytics and again collaboration and sharing the",
    "start": "119880",
    "end": "127409"
  },
  {
    "start": "126000",
    "end": "670000"
  },
  {
    "text": "result is what we see here in this chart this is a chart put together by IDC and Gartner",
    "start": "127409",
    "end": "133440"
  },
  {
    "text": "the orange we're looking at the amount of data that is being generated and in blue is the amount of data that is",
    "start": "133440",
    "end": "138540"
  },
  {
    "text": "actually available and being used for an analysis there's clearly a very large gap here and that's a problem there's a",
    "start": "138540",
    "end": "145080"
  },
  {
    "text": "big missed opportunity what do you need to close that gap so there's a few",
    "start": "145080",
    "end": "151230"
  },
  {
    "text": "things that you really need you need elastic and highly scalable infrastructure you ideally want to pay for that without any big upfront capital",
    "start": "151230",
    "end": "158310"
  },
  {
    "text": "expense you only want to pay for what you use as you use it and you want everything to be available with the",
    "start": "158310",
    "end": "164100"
  },
  {
    "text": "click of a button or with a single API call you want it available on demand in",
    "start": "164100",
    "end": "169260"
  },
  {
    "text": "other words if you can have all of these things you can remove the constraints that we looked at on the previous slide around the data lifecycle so this is",
    "start": "169260",
    "end": "176820"
  },
  {
    "text": "what we're looking at before with the constraints removed what we see is that",
    "start": "176820",
    "end": "181830"
  },
  {
    "text": "this lifecycle is accelerated and organizations are able to ask more questions of more data they're more",
    "start": "181830",
    "end": "187650"
  },
  {
    "text": "interesting questions you can have hypotheses test the hypothesis if it's a",
    "start": "187650",
    "end": "192900"
  },
  {
    "text": "fit if it's incorrect you fail quickly and it's very cheap this whole process is accelerated you get to insight a lot",
    "start": "192900",
    "end": "198330"
  },
  {
    "text": "faster and organizations are getting a lot of value out of that so what we really need with to contain",
    "start": "198330",
    "end": "206160"
  },
  {
    "text": "big data or to get value out of big data are technologies and techniques for working productively with data at any",
    "start": "206160",
    "end": "213090"
  },
  {
    "text": "scale ok so that's all I really want to say super high level about Big Data",
    "start": "213090",
    "end": "218430"
  },
  {
    "text": "let's talk a little bit about we have four examples of organizations that are taking data and pulling out insight and",
    "start": "218430",
    "end": "225120"
  },
  {
    "text": "information so first example Razorfish this is a digital marketing company here",
    "start": "225120",
    "end": "230970"
  },
  {
    "text": "in the United States they work with companies all around the world one example that I want to share with you",
    "start": "230970",
    "end": "236760"
  },
  {
    "text": "today is they were working with a large big-box retailer in the United States and their client this retailer wanted to",
    "start": "236760",
    "end": "243870"
  },
  {
    "text": "know who buys video games ultimately what they wanted to do was serve advertisements to the users on their",
    "start": "243870",
    "end": "249330"
  },
  {
    "text": "website that would entice the the retailers users to buy video games so",
    "start": "249330",
    "end": "255959"
  },
  {
    "text": "they want to serve up ads and have them be very effective so what razorfish helped this client do",
    "start": "255959",
    "end": "261419"
  },
  {
    "text": "is to set up a process in the cloud that processes three and a half billion records a day",
    "start": "261419",
    "end": "267270"
  },
  {
    "text": "10 to 20 terabytes of clickstream logs tens of millions of cookies it's a lot of data a lot of it is unstructured a",
    "start": "267270",
    "end": "273360"
  },
  {
    "text": "lot of it is existing in different places they built the process that did this and they got a they got a number of",
    "start": "273360",
    "end": "279600"
  },
  {
    "text": "insights out of them one perhaps not surprising is people who buy large",
    "start": "279600",
    "end": "285870"
  },
  {
    "text": "flat-screen TVs tend to buy video games that's by itself maybe not that interesting what was interesting is they",
    "start": "285870",
    "end": "292530"
  },
  {
    "text": "were able to go much much deeper and they were able to get insight that ultimately allowed them to on the on the",
    "start": "292530",
    "end": "299520"
  },
  {
    "text": "retailer's website when customers are looking at specific movies and specific TV models they're able to deliver up ads",
    "start": "299520",
    "end": "306240"
  },
  {
    "text": "for specific video games and what they found was that the return on adspend would not five hundred five hundred",
    "start": "306240",
    "end": "311790"
  },
  {
    "text": "percent the procurement time went down by 17,000 percent the in the comment from the the client",
    "start": "311790",
    "end": "318960"
  },
  {
    "text": "in this case was not that they weren't really so much talking about the reduction in cost or any of that stuff",
    "start": "318960",
    "end": "326370"
  },
  {
    "text": "they what they talked about was the agility that it gave them the ability to move really really fast so this",
    "start": "326370",
    "end": "331530"
  },
  {
    "text": "reduction in procurement time allowed them to move a lot faster and try more hypotheses try more experiments ok let's",
    "start": "331530",
    "end": "338730"
  },
  {
    "text": "talk about a second example Yelp I think most people here are probably familiar with Yelp a couple of years ago they",
    "start": "338730",
    "end": "345150"
  },
  {
    "text": "want Yelp wanted to know who is using our service they this is a basic question a lot of companies want to know",
    "start": "345150",
    "end": "350550"
  },
  {
    "text": "this they wanted insight about their customers and what's challenging is that",
    "start": "350550",
    "end": "356250"
  },
  {
    "text": "Yelp was generating and Yelp users was generating a lot of data but it's really difficult to get the signal and the",
    "start": "356250",
    "end": "362430"
  },
  {
    "text": "value out of that data one of the things that they were able to figure out by analyzing that data is that people were",
    "start": "362430",
    "end": "369870"
  },
  {
    "text": "visiting the site on mobile devices they figured this out a couple of years ago this was really before a lot of",
    "start": "369870",
    "end": "375390"
  },
  {
    "text": "companies had clued in to the shift towards mobile and as a result Yelp was",
    "start": "375390",
    "end": "380970"
  },
  {
    "text": "able to make investments in mobile that has served them very well over the last few years so today our in January 2013",
    "start": "380970",
    "end": "387090"
  },
  {
    "text": "they're serving nine and a half million unique mobile devices and they've been able to invest in particular features",
    "start": "387090",
    "end": "393660"
  },
  {
    "text": "and particular things on the site that have allowed them to succeed in it all kind of comes back to this initial",
    "start": "393660",
    "end": "398669"
  },
  {
    "text": "insight that they were able to pull out of many many terabytes of log data",
    "start": "398669",
    "end": "404630"
  },
  {
    "text": "look at another example very different Amazon has a public data sets program",
    "start": "404630",
    "end": "410009"
  },
  {
    "text": "where we host datasets for free on the Amazon Cloud one of those data sets is the common crawl data set this is an",
    "start": "410009",
    "end": "416130"
  },
  {
    "text": "open index of the entire web there's a lot of data in there it's a lot of very",
    "start": "416130",
    "end": "421590"
  },
  {
    "text": "unstructured very messy data there's about three and a half billion records the last time we looked at it and again",
    "start": "421590",
    "end": "427110"
  },
  {
    "text": "as I mentioned available to everybody for free there's a lot of interesting things potentially that you might want",
    "start": "427110",
    "end": "433410"
  },
  {
    "text": "to get out of that data set and one of those might be a researcher who wants to know what is the impact of social",
    "start": "433410",
    "end": "439440"
  },
  {
    "text": "networks on the internet and not just the Internet in this country but the Internet globally so we had a researcher",
    "start": "439440",
    "end": "445470"
  },
  {
    "text": "do this and they wrote 300 lines of Ruby code it took them 14 hours and they were",
    "start": "445470",
    "end": "450479"
  },
  {
    "text": "able to get to an interesting result this is an example where they had they're dealing with a lot of very messy",
    "start": "450479",
    "end": "457080"
  },
  {
    "text": "unstructured data many many terabytes of data and all you really need is a little",
    "start": "457080",
    "end": "462360"
  },
  {
    "text": "bit of code and access to the resources that it'll us provides and they were able to get actionable insight out of",
    "start": "462360",
    "end": "468599"
  },
  {
    "text": "that data let's look at one more example this is in the public health space and",
    "start": "468599",
    "end": "473820"
  },
  {
    "text": "kind of social media and public health so what we're looking at here is a chart showing two things in blue our tweets",
    "start": "473820",
    "end": "480360"
  },
  {
    "text": "about the flu the dotted black line our CDC CDC data about actual incidences of",
    "start": "480360",
    "end": "488490"
  },
  {
    "text": "the flu and what is interesting here is that there's a very tight correlation between the two and what maybe what I'm",
    "start": "488490",
    "end": "495270"
  },
  {
    "text": "sure many people in the room would probably already know is that the CDC and other organizations spend a lot of money to generate this data it's very",
    "start": "495270",
    "end": "502020"
  },
  {
    "text": "expensive very time consuming it's very it's very capital intensive to generate the data and what's interesting here is",
    "start": "502020",
    "end": "508199"
  },
  {
    "text": "that this actionable info is actually available in freely available social",
    "start": "508199",
    "end": "513630"
  },
  {
    "text": "media data on Twitter begs really interesting questions about you know are there better ways for organizations like",
    "start": "513630",
    "end": "519599"
  },
  {
    "text": "the CDC they be getting this information getting it faster getting a cheaper ok",
    "start": "519599",
    "end": "526079"
  },
  {
    "text": "let's talk a little bit about analytics and cloud computing so back to our data life cycle chart here AWS has a number",
    "start": "526079",
    "end": "533940"
  },
  {
    "text": "of services that map to each of these components I'm not going to spend too much time on each of them I'll just kind of very quickly",
    "start": "533940",
    "end": "540120"
  },
  {
    "text": "highlight some of them on collection and storage there's s3 this is our highly durable storage service I think we very",
    "start": "540120",
    "end": "547680"
  },
  {
    "text": "recently announced that we've hit I think two trillion objects in s3 well over a million requests per second",
    "start": "547680",
    "end": "554339"
  },
  {
    "text": "absolutely enormous highly highly durable storage system glacier is a cold",
    "start": "554339",
    "end": "560310"
  },
  {
    "text": "storage if you were in the keynote this morning I think Andy talked about this a little bit the extremely cheap really great for",
    "start": "560310",
    "end": "567440"
  },
  {
    "text": "backup of data anytime that you've got data that you don't want to throw away but you don't want to keep and it needs",
    "start": "567440",
    "end": "572880"
  },
  {
    "text": "to be cheap storage gateway Andy talked about that this morning DynamoDB is our",
    "start": "572880",
    "end": "578190"
  },
  {
    "text": "no sequel offering so columnar database single-digit a single second server-side",
    "start": "578190",
    "end": "585360"
  },
  {
    "text": "latency on reads and writes absolutely phenomenal performance really great for web apps and other",
    "start": "585360",
    "end": "590399"
  },
  {
    "text": "applications where you need really really fast access to the data redshift",
    "start": "590399",
    "end": "595560"
  },
  {
    "text": "was announced just a few months ago it's our data warehouse as a service offering RDS is our relational database service",
    "start": "595560",
    "end": "601350"
  },
  {
    "text": "so this is the relational database as a service basically HBase is a no sequel",
    "start": "601350",
    "end": "606870"
  },
  {
    "text": "database that sits on top of Hadoop I'll talk about it a little bit more detail a little bit later",
    "start": "606870",
    "end": "612470"
  },
  {
    "text": "clearly there are lots of options here for collecting the data so analytics and computation there's many many options",
    "start": "612470",
    "end": "618660"
  },
  {
    "text": "here two of the most common are ec2 and elastic MapReduce elastic MapReduce is the manage to dupe service that I happen",
    "start": "618660",
    "end": "624899"
  },
  {
    "text": "to work on collaboration and sharing again lots of services ec2 S 3 RDS cloud",
    "start": "624899",
    "end": "631199"
  },
  {
    "text": "formation some of you may have attended a session on cloud formation earlier it's our content delivery service",
    "start": "631199",
    "end": "636720"
  },
  {
    "text": "again dynamodb redshift lots of options across all of these stages you really",
    "start": "636720",
    "end": "643170"
  },
  {
    "text": "want to look at what are you trying to do in your application and with your workload and you pick the services and the tools the best map to that and",
    "start": "643170",
    "end": "649500"
  },
  {
    "text": "ultimately you hopefully end up with a topology that makes the most sense for you and finally we have a service that",
    "start": "649500",
    "end": "656610"
  },
  {
    "text": "was announced just a couple of months ago called AWS data pipeline this is the service that helps you to schedule",
    "start": "656610",
    "end": "662699"
  },
  {
    "text": "data-driven recurring workflows I'll talk a little bit more about it in a moment so I won't spend too much time on",
    "start": "662699",
    "end": "668010"
  },
  {
    "text": "it okay let's spend two three minutes",
    "start": "668010",
    "end": "673320"
  },
  {
    "start": "670000",
    "end": "878000"
  },
  {
    "text": "talking about elastic MapReduce this is the managed to dupe service before I go into too much detail here I'd like to",
    "start": "673320",
    "end": "678660"
  },
  {
    "text": "just with a quick show of hands see how many of you have ever used elastic MapReduce okay so I see maybe maybe 25%",
    "start": "678660",
    "end": "688110"
  },
  {
    "text": "30% so we have some users in the room the the folks that didn't raise your hand how many raise your hand if you're",
    "start": "688110",
    "end": "694500"
  },
  {
    "text": "using Hadoop today okay so maybe a little bit less than half okay so let me",
    "start": "694500",
    "end": "703260"
  },
  {
    "text": "let me kind of explain a little bit how it works this is a simplistic view I'm not going to get into a lot of detail",
    "start": "703260",
    "end": "708540"
  },
  {
    "text": "here but hopefully this will be enough for those of you that aren't familiar with EMR to get a sense of what it could",
    "start": "708540",
    "end": "713700"
  },
  {
    "text": "do and why it might make sense for you so first you put your data and your code",
    "start": "713700",
    "end": "718860"
  },
  {
    "text": "into s3 you then come to the EMR service and you can use the command line you can",
    "start": "718860",
    "end": "724530"
  },
  {
    "text": "use the SDKs you can use the api's or the management console you have a number of options there and you make a couple",
    "start": "724530",
    "end": "730770"
  },
  {
    "text": "of decisions you decide what Hadoop distribution you want to run and there's there's several options there for you",
    "start": "730770",
    "end": "736470"
  },
  {
    "text": "you decide how many nodes you want to provision in your cluster so anything from one or two nodes to thousands of",
    "start": "736470",
    "end": "742830"
  },
  {
    "text": "nodes you decide you tell us what types of nodes we want to use so these are ec2 instances underneath so you might decide",
    "start": "742830",
    "end": "749970"
  },
  {
    "text": "for your cluster that you want high CPU because maybe you're doing image processing or maybe you decide you want",
    "start": "749970",
    "end": "755250"
  },
  {
    "text": "high storage nodes because you have a lot of data those nodes come with 48 terabytes per node you might use high",
    "start": "755250",
    "end": "761910"
  },
  {
    "text": "memory you might use standard you might use a mixture depending on what you're trying to do you also tell the EMR",
    "start": "761910",
    "end": "768089"
  },
  {
    "text": "service what applications you want to install on that cluster so within the Hadoop ecosystem there's a number of",
    "start": "768089",
    "end": "773339"
  },
  {
    "text": "projects and applications that you can use for different purposes hive is a no sequel data warehouse for Hadoop Pig is",
    "start": "773339",
    "end": "780510"
  },
  {
    "text": "great for dataflow and scripting type workflows HBase is the no sequel offering then there's a variety of other",
    "start": "780510",
    "end": "787920"
  },
  {
    "text": "Apache projects that you can run there's there's non Apache but also open source",
    "start": "787920",
    "end": "793190"
  },
  {
    "text": "ganglia for example as a monitoring application mahute is a machine learning library and then there's a bunch of",
    "start": "793190",
    "end": "800370"
  },
  {
    "text": "things that you get by default you get are by fault you get mahute by default there's a lot of stuff that you get in the cluster some of it comes by default some",
    "start": "800370",
    "end": "807230"
  },
  {
    "text": "of it you choose you'd basically tell EMR I want this this and this after",
    "start": "807230",
    "end": "812930"
  },
  {
    "text": "you've made those decisions the EMR service will grab the data will do the processing and then it will put the results back into s3 wherever you told",
    "start": "812930",
    "end": "819530"
  },
  {
    "text": "us to put where you want the data to go you could pick it up as a human or most",
    "start": "819530",
    "end": "824780"
  },
  {
    "text": "often some downstream process would grab the data and one of the things you can",
    "start": "824780",
    "end": "830720"
  },
  {
    "text": "do that's really interesting is you can expand and shrink your cluster you can",
    "start": "830720",
    "end": "835970"
  },
  {
    "text": "do this manually you can script this but and the reason that you might want to do this is let's say you're using EMR and",
    "start": "835970",
    "end": "842330"
  },
  {
    "text": "Hadoop to process a certain amount of data every day but then let's say you have an idea or you have a hypothesis",
    "start": "842330",
    "end": "848660"
  },
  {
    "text": "that you want to test against a month of data or a year of data or all of your data you might take that cluster which",
    "start": "848660",
    "end": "854960"
  },
  {
    "text": "is steady-state 20 nodes and expand it to a thousand nodes and then when you're done with that hypothesis you just bring",
    "start": "854960",
    "end": "861680"
  },
  {
    "text": "it back down to 20 or you get rid of the cluster what we have many customers that",
    "start": "861680",
    "end": "867260"
  },
  {
    "text": "will very often have steady-state 20 or 30 nodes in the day and then they'll have 500 or a thousand at night and it",
    "start": "867260",
    "end": "873110"
  },
  {
    "text": "just continuously goes up and down and it's based on how much data and what they're trying to do now one of the",
    "start": "873110",
    "end": "879950"
  },
  {
    "start": "878000",
    "end": "927000"
  },
  {
    "text": "other interesting things here is you can use spot nodes so spot are unused ec2",
    "start": "879950",
    "end": "886250"
  },
  {
    "text": "instances that you bid on so there's a spot market price and then there's your bid price and as long as your bid price",
    "start": "886250",
    "end": "891740"
  },
  {
    "text": "is above the market price you will get those nodes and you as a result you end up paying pennies on the dollar we have",
    "start": "891740",
    "end": "898880"
  },
  {
    "text": "many more customers are actually saving on the order of 70 or 80 percent by using spot now you want to be careful",
    "start": "898880",
    "end": "906410"
  },
  {
    "text": "about using spot because if the market price changes you can lose those nodes so you might not want to use a spot for",
    "start": "906410",
    "end": "912800"
  },
  {
    "text": "your master node you might not want to use spot on a cluster that has a mission-critical tight SLA attached to",
    "start": "912800",
    "end": "919100"
  },
  {
    "text": "it so you want to be Kari it's a great really great tool to save money and save time but you want to be careful about it and architects appropriately another",
    "start": "919100",
    "end": "928280"
  },
  {
    "start": "927000",
    "end": "987000"
  },
  {
    "text": "thing you can do is if the data in is in s3 you can launch parallel clusters against the same data source so an",
    "start": "928280",
    "end": "934700"
  },
  {
    "text": "example of a customer this is Netflix so they will have one cluster that they use for their",
    "start": "934700",
    "end": "940230"
  },
  {
    "text": "continuously processing all of the data coming from the devices around the world that are streaming Netflix movie so all",
    "start": "940230",
    "end": "945450"
  },
  {
    "text": "of the data around latency and what people are looking at and what people are clicking on all of that is streaming into the cloud and being processed by",
    "start": "945450",
    "end": "950880"
  },
  {
    "text": "one massive Hadoop cluster then they have another cluster that their bi analysts use and there's a different",
    "start": "950880",
    "end": "956190"
  },
  {
    "text": "instance type and it's a different size and there's a different configuration and then they have other clusters that they will spin up for specific jobs and",
    "start": "956190",
    "end": "962040"
  },
  {
    "text": "specific hypotheses that they want to test and the neat thing about this is that if you have these parallel clusters",
    "start": "962040",
    "end": "967890"
  },
  {
    "text": "against the same data you can tune and configure each cluster so that it is ideally configured for what it's doing",
    "start": "967890",
    "end": "974190"
  },
  {
    "text": "and maybe some of your clusters you have up all the time and they never go away other clusters you spin up for a few",
    "start": "974190",
    "end": "980250"
  },
  {
    "text": "hours for a particular hypothesis and then you tear it down it's really up to you we want to provide that choice to you as I mentioned if you don't need the",
    "start": "980250",
    "end": "990300"
  },
  {
    "text": "cluster anymore you can tear it down and like whatever like everything else with AWS if you terminate the resources you immediately stop paying so this is",
    "start": "990300",
    "end": "997200"
  },
  {
    "text": "interesting because we have customers like whether bill that are calculate calculating and recalculating insurance",
    "start": "997200",
    "end": "1002750"
  },
  {
    "text": "prices and they I believe they only you they only spin up a single cluster every",
    "start": "1002750",
    "end": "1007910"
  },
  {
    "text": "month they use thousands of nodes one or two days out of the month and then the rest of the month they're not using",
    "start": "1007910",
    "end": "1013580"
  },
  {
    "text": "anything and they're not paying for the resources during that period of the month it's pretty phenomenal it's very very different obviously than what you",
    "start": "1013580",
    "end": "1019850"
  },
  {
    "text": "can do outside of the cloud and be remiss to mention if I didn't mention",
    "start": "1019850",
    "end": "1025220"
  },
  {
    "text": "that you don't have to use s3 you can also spin up your cluster and store everything on the local ephemeral disk",
    "start": "1025220",
    "end": "1032030"
  },
  {
    "text": "on HDFS and we have some customers that use use HDFS on the local drives other",
    "start": "1032030",
    "end": "1038930"
  },
  {
    "text": "customers use s3 some use a mixture again really is up to you and if you are",
    "start": "1038930",
    "end": "1044180"
  },
  {
    "text": "gonna if you do have a lot of data and you want to keep it there for a long term you I would suggest taking a look",
    "start": "1044180",
    "end": "1051020"
  },
  {
    "text": "at some of our larger beefier instance types like high storage which comes with 48 terabytes per node think 10 gig",
    "start": "1051020",
    "end": "1056750"
  },
  {
    "text": "networking there's a lot of really cool things and it's really great if you are at the scale of a petabyte or more and",
    "start": "1056750",
    "end": "1064370"
  },
  {
    "text": "lastly you can run all of this inside a virtual private cloud so for anybody that's concerned about security",
    "start": "1064370",
    "end": "1069800"
  },
  {
    "text": "the confidentiality of the data everything is supported in V PC and it's",
    "start": "1069800",
    "end": "1074930"
  },
  {
    "text": "it's a matter of selecting DPC from a drop-down our service started in 2009",
    "start": "1074930",
    "end": "1082010"
  },
  {
    "text": "since then we've launched a little over 5 million clusters I think it's at five and a half million now the customers",
    "start": "1082010",
    "end": "1088700"
  },
  {
    "text": "range from all across all industries in all use cases one of our biggest users",
    "start": "1088700",
    "end": "1093980"
  },
  {
    "text": "is actually amazon.com which has something like five hundred teams now using EMR to do everything from figuring",
    "start": "1093980",
    "end": "1101600"
  },
  {
    "text": "out identifying fraudulent buyers and sellers to routing of packages to a be testing the website many many very",
    "start": "1101600",
    "end": "1108800"
  },
  {
    "text": "interesting things that they're doing and a lot of that is running on EMR I would I'm kind of getting toward the end",
    "start": "1108800",
    "end": "1116420"
  },
  {
    "text": "here I want to encourage you to give it a try Hadoop is not easy but the whole",
    "start": "1116420",
    "end": "1122360"
  },
  {
    "text": "goal of our service is to make it as easy as possible and to make it as performant as possible and take a lot of",
    "start": "1122360",
    "end": "1128480"
  },
  {
    "text": "the the management mess out so that you",
    "start": "1128480",
    "end": "1133670"
  },
  {
    "text": "can focus on getting the value out of the data the cost to run a 100 note EMR cluster",
    "start": "1133670",
    "end": "1138770"
  },
  {
    "text": "if you want to try this yourself today is seven dollars and fifty cents an hour",
    "start": "1138770",
    "end": "1144820"
  },
  {
    "text": "that's less than the cost of a movie ticket you can do quite a lot of damage with a hundred nodes for an hour and",
    "start": "1144820",
    "end": "1151820"
  },
  {
    "text": "obviously the this the the saying holds that what you can do with 100 notes for an hour is the same as what you can do",
    "start": "1151820",
    "end": "1157850"
  },
  {
    "text": "with the hundred hours on one node and that's one of the core reasons why people are so drawn to Hadoop and services like a mark so the last section",
    "start": "1157850",
    "end": "1166400"
  },
  {
    "start": "1165000",
    "end": "1191000"
  },
  {
    "text": "is on the Big Data ecosystem one of the issues that that our customers face is",
    "start": "1166400",
    "end": "1171920"
  },
  {
    "text": "that they have data in many different locations there's the data in different silos even just within AWS we have lots",
    "start": "1171920",
    "end": "1178700"
  },
  {
    "text": "of different services where data potentially could be stored you've got dynamodb s3 HBase you've got",
    "start": "1178700",
    "end": "1185030"
  },
  {
    "text": "EMR redshift RDS and this is just a subset of where the data might be living",
    "start": "1185030",
    "end": "1191020"
  },
  {
    "start": "1191000",
    "end": "1248000"
  },
  {
    "text": "kind of a question that comes out of that is well how do I get my data into the cloud into all of those different",
    "start": "1191020",
    "end": "1197360"
  },
  {
    "text": "locations AWS provides a number of mechanisms for you one is that you can generate a lot of data just by",
    "start": "1197360",
    "end": "1203620"
  },
  {
    "text": "your apps on ec2 you can transfer data into s3 for free you can upload very",
    "start": "1203620",
    "end": "1209890"
  },
  {
    "text": "large objects using multi-part upload into s3 it makes it much easier if you've got lots of data and large objects you can actually put your data",
    "start": "1209890",
    "end": "1217300"
  },
  {
    "text": "on physical media and ship it to us you can use Direct Connect which allows you",
    "start": "1217300",
    "end": "1222760"
  },
  {
    "text": "to lease a one or ten gig line or multiple lines especially this is especially useful if you have lots of",
    "start": "1222760",
    "end": "1227770"
  },
  {
    "text": "data that's continuously moving in or out or both and then we've got regional replication of Ami's and snapshots and",
    "start": "1227770",
    "end": "1234309"
  },
  {
    "text": "and and again this is a subset of all of the different options but depending on what you're trying to do the amount of",
    "start": "1234309",
    "end": "1239410"
  },
  {
    "text": "data whether it's one time whether it's continuous there are different tools that are available for you and you can",
    "start": "1239410",
    "end": "1244780"
  },
  {
    "text": "let us know what you're trying to do and we can try to work with you on that so then the next question is once you've",
    "start": "1244780",
    "end": "1250420"
  },
  {
    "start": "1248000",
    "end": "1258000"
  },
  {
    "text": "got your data into the cloud are you kind of comfortable that you can get the data there the question is how do i integrate my data to get the maximum",
    "start": "1250420",
    "end": "1256990"
  },
  {
    "text": "impact out of it so an example might be of how you might want to pull data and",
    "start": "1256990",
    "end": "1263440"
  },
  {
    "start": "1258000",
    "end": "1335000"
  },
  {
    "text": "move it from one place to another is let's say you've got some hot data in dynamo dB so this might be Product data",
    "start": "1263440",
    "end": "1268929"
  },
  {
    "text": "dimension data something you're using in a web app and you're on some schedule",
    "start": "1268929",
    "end": "1274120"
  },
  {
    "text": "backing it up to s3 where you've got some of your cold or kind of warm warmish data that data is periodically",
    "start": "1274120",
    "end": "1282460"
  },
  {
    "text": "being streamed into an HBase cluster on EMR maybe you're using it for some sort of analytic application or multiple",
    "start": "1282460",
    "end": "1288880"
  },
  {
    "text": "analytic applications then you've got EMR clusters that are going to spin up to process and analyze that data and",
    "start": "1288880",
    "end": "1295809"
  },
  {
    "text": "maybe it also will integrate ideally data from an on-premise source like a",
    "start": "1295809",
    "end": "1300970"
  },
  {
    "text": "data warehouse the result of that processing and that flow is some sort of",
    "start": "1300970",
    "end": "1306010"
  },
  {
    "text": "structured output that you want to put into redshift so that your analyst can query against it using sequel and the tools that they're comfortable with what",
    "start": "1306010",
    "end": "1313450"
  },
  {
    "text": "I've described here is a relatively generic but it kind of shows that you might there are many situations where",
    "start": "1313450",
    "end": "1319000"
  },
  {
    "text": "you might want to have data in dynamo that's moving into s3 that's then moving into EMR to be analyzed and then some",
    "start": "1319000",
    "end": "1325270"
  },
  {
    "text": "output is moving into redshift you're needing to move the data from one place to another you're needing to process it",
    "start": "1325270",
    "end": "1330640"
  },
  {
    "text": "and transform it what would be really helpful is if there was a service that made all this easy so data pipeline",
    "start": "1330640",
    "end": "1337580"
  },
  {
    "start": "1335000",
    "end": "1433000"
  },
  {
    "text": "is designed to handle data-driven recurring workflows it was announced in",
    "start": "1337580",
    "end": "1343250"
  },
  {
    "text": "November it's available now in u.s. East it will be available in other regions soon the this is kind of what a simple",
    "start": "1343250",
    "end": "1351950"
  },
  {
    "text": "pipeline looks like you've got an input data node and this might be an on-premise data warehouse it might be an",
    "start": "1351950",
    "end": "1357680"
  },
  {
    "text": "s3 location it could be you know it could be DynamoDB it could be something",
    "start": "1357680",
    "end": "1363620"
  },
  {
    "text": "in HBase anyway you have an input data node and then you have an activity that you attach to that data node and that",
    "start": "1363620",
    "end": "1369170"
  },
  {
    "text": "activity might be something like an EMR job so a Hadoop job and then optionally you could have an output data node the",
    "start": "1369170",
    "end": "1375590"
  },
  {
    "text": "output data node just like the input data node could be an s3 bucket could be DynamoDB it could be something",
    "start": "1375590",
    "end": "1381260"
  },
  {
    "text": "on-premise but this is what a simple pipeline looks like and now you can make",
    "start": "1381260",
    "end": "1387290"
  },
  {
    "text": "it a little bit more complicated by attaching precondition checks to the input data node so you might set up a",
    "start": "1387290",
    "end": "1392570"
  },
  {
    "text": "pipeline that actually checks the s3 location for the arrival of a file and the pipeline won't start until that file",
    "start": "1392570",
    "end": "1399380"
  },
  {
    "text": "appears and then attach to the activity you might want to have failure and delay",
    "start": "1399380",
    "end": "1404870"
  },
  {
    "text": "notifications you might want to set up control logic around if this then so and so and then again you've got your output",
    "start": "1404870",
    "end": "1412400"
  },
  {
    "text": "did you note and then obviously you can make the pipeline as complex as you want",
    "start": "1412400",
    "end": "1418400"
  },
  {
    "text": "to suit your needs want to thank you very much I want to",
    "start": "1418400",
    "end": "1424070"
  },
  {
    "text": "also invite you to if you are curious about any of these services you can check check out the websites here elastic MapReduce data pipeline big dash",
    "start": "1424070",
    "end": "1432080"
  },
  {
    "text": "data and now we want to introduce garish Geneva from Intel and we're gonna queue",
    "start": "1432080",
    "end": "1438680"
  },
  {
    "text": "up a video while we come up on stage thank you very much appreciate your time and hope you enjoy",
    "start": "1438680",
    "end": "1444140"
  },
  {
    "text": "the rest of the event",
    "start": "1444140",
    "end": "1447040"
  },
  {
    "start": "1447000",
    "end": "1549000"
  },
  {
    "text": "one way of thinking about big data is data for competitive advantage for",
    "start": "1458900",
    "end": "1464040"
  },
  {
    "text": "customers one of the big challenges of dealing with big data is turning all of",
    "start": "1464040",
    "end": "1470130"
  },
  {
    "text": "this data into information Schrodinger was able to spin up a 50000 core",
    "start": "1470130",
    "end": "1475740"
  },
  {
    "text": "supercomputer that allowed them to synthesize over a hundred million molecules in just eight hours the AWS",
    "start": "1475740",
    "end": "1482940"
  },
  {
    "text": "cloud makes supercomputer capacity by the hour available to everybody with high performance cluster compute",
    "start": "1482940",
    "end": "1489330"
  },
  {
    "text": "instances part by Intel Xeon e5 processors in 60 minutes NASA JPL builds",
    "start": "1489330",
    "end": "1496590"
  },
  {
    "text": "gigapixel images from Mars so scientists wait less and export war there are",
    "start": "1496590",
    "end": "1502170"
  },
  {
    "text": "several technologies that Intel and Amazon Web Services have incorporated into these hype high performance or",
    "start": "1502170",
    "end": "1508590"
  },
  {
    "text": "cluster compute instances advanced vector extensions within the intel xeon",
    "start": "1508590",
    "end": "1514320"
  },
  {
    "text": "e5 series processors really allows us to take and perform two operations within",
    "start": "1514320",
    "end": "1520500"
  },
  {
    "text": "one clock cycle and the cloud provides high performance at low cost to",
    "start": "1520500",
    "end": "1526800"
  },
  {
    "text": "customers so Rath and customers happen to spend lots of capital on infrastructure that sits unused when",
    "start": "1526800",
    "end": "1532770"
  },
  {
    "text": "they're using the cloud they pay only for what they use the most exciting thing about Intel and Amazon Web",
    "start": "1532770",
    "end": "1538620"
  },
  {
    "text": "Services now you can get high performance computing cost-effectively",
    "start": "1538620",
    "end": "1544909"
  },
  {
    "text": "that was great setup by John I'll give you a brief review of how in turn Amazon",
    "start": "1550899",
    "end": "1556119"
  },
  {
    "text": "Web Services are working together to make it easier for you to try out Amazon MapReduce and they do so you know",
    "start": "1556119",
    "end": "1564399"
  },
  {
    "text": "often times question is asked what should I use big data for you know I did my log analysis I did my you know kind",
    "start": "1564399",
    "end": "1569470"
  },
  {
    "text": "of usual use case is there a bigger value bigger v-vector to be derived out",
    "start": "1569470",
    "end": "1574479"
  },
  {
    "text": "of this and what we have seen is actually profoundly you know important",
    "start": "1574479",
    "end": "1580210"
  },
  {
    "text": "changes can be made if you get real value or data I'll give you a few examples we work with some customers",
    "start": "1580210",
    "end": "1586599"
  },
  {
    "text": "that are using gene data analysis and essentially combining the genomics data",
    "start": "1586599",
    "end": "1591940"
  },
  {
    "text": "with the clinical data in order to come up with gene markers that can help cure",
    "start": "1591940",
    "end": "1597340"
  },
  {
    "text": "diseases so you know we are really talking about our health care and and how we can all live better we have seen",
    "start": "1597340",
    "end": "1604330"
  },
  {
    "text": "customers come up with completely new business models where they used you know historical data sets that they had with",
    "start": "1604330",
    "end": "1611590"
  },
  {
    "text": "some social media data sets in order to monetize or price things that earlier they were not even charging users for so",
    "start": "1611590",
    "end": "1619179"
  },
  {
    "text": "you know they have completely changed their business models and then in many",
    "start": "1619179",
    "end": "1624519"
  },
  {
    "text": "places across the globe we have been working with companies and governments",
    "start": "1624519",
    "end": "1629950"
  },
  {
    "text": "where the national transportation systems the smart grid and power",
    "start": "1629950",
    "end": "1636970"
  },
  {
    "text": "management systems are been modified based on the amount of sampling of data you can do from that sensor network and",
    "start": "1636970",
    "end": "1643809"
  },
  {
    "text": "the kind of knowledge you can derive by analyzing that data so it is much more than log analysis much more than you",
    "start": "1643809",
    "end": "1650289"
  },
  {
    "text": "know kind of common mundane use cases you you think and here about to do that you can do if the technology is",
    "start": "1650289",
    "end": "1657639"
  },
  {
    "text": "available at scale in a way that it can be set up and tear down the way you can",
    "start": "1657639",
    "end": "1662710"
  },
  {
    "text": "do an Amazon Web Services so you know that this is where what I'll talk about",
    "start": "1662710",
    "end": "1669159"
  },
  {
    "start": "1666000",
    "end": "1687000"
  },
  {
    "text": "is how we are helping the infrastructure to allow for unlocking of value that is",
    "start": "1669159",
    "end": "1675009"
  },
  {
    "text": "there in some of the optimizations we are putting silicon how we're supporting open platforms so that the cost of doing this",
    "start": "1675009",
    "end": "1681590"
  },
  {
    "text": "analysis comes down eventually in order to deliver the kind of business value I discussed and why until right you would",
    "start": "1681590",
    "end": "1688730"
  },
  {
    "start": "1687000",
    "end": "1776000"
  },
  {
    "text": "think Intel is a silicon company and you know what do how close they are to actually understanding value from data",
    "start": "1688730",
    "end": "1695170"
  },
  {
    "text": "so this is kind of to give you a perspective we have been in high performance computing and XSL exascale",
    "start": "1695170",
    "end": "1700760"
  },
  {
    "text": "environment as you heard in the video for over ten years so we have dealt with very large data sets and how to compute",
    "start": "1700760",
    "end": "1706490"
  },
  {
    "text": "in technical computing environment how to compute with those large data sets efficiently we've been working with",
    "start": "1706490",
    "end": "1712160"
  },
  {
    "text": "cloud providers Amazon Web Services included in order to optimize the infrastructure so that it can deliver",
    "start": "1712160",
    "end": "1717800"
  },
  {
    "text": "value at lower cost and finally Intel is a big promoter and contributor to open source we are the you know one of the",
    "start": "1717800",
    "end": "1725240"
  },
  {
    "text": "largest contributors to Linux and we are also now the largest contributor to OpenStack and contributing to the dip as",
    "start": "1725240",
    "end": "1730730"
  },
  {
    "text": "well so you know as you bring these three trends together that is what's allowing for the cost reduction that we",
    "start": "1730730",
    "end": "1738470"
  },
  {
    "text": "are saying for data analytics where it used to be tens of thousands of dollars per terabyte of analysis we just saw how",
    "start": "1738470",
    "end": "1745250"
  },
  {
    "text": "you can do 100 core 100 machine analysis on 700 $7.50 less than the cost of a",
    "start": "1745250",
    "end": "1751250"
  },
  {
    "text": "movie so the areas I'll talk about are the optimizations and the things we are",
    "start": "1751250",
    "end": "1757490"
  },
  {
    "text": "putting in as it relates to storage server network and software you saw a",
    "start": "1757490",
    "end": "1762890"
  },
  {
    "text": "great flow from John earlier where he was talking about data collection he was talking about data storage computation",
    "start": "1762890",
    "end": "1771110"
  },
  {
    "text": "and collaboration and access and I will refer to each one of them as I go through this so you know in the Intel",
    "start": "1771110",
    "end": "1779090"
  },
  {
    "start": "1776000",
    "end": "1809000"
  },
  {
    "text": "Xeon processor in the e5 line we have we have put several optimizations that actually allow for scale out",
    "start": "1779090",
    "end": "1785240"
  },
  {
    "text": "architecture to perform at the best possible value it can and I will refer",
    "start": "1785240",
    "end": "1791480"
  },
  {
    "text": "to a few few of the details around advanced vector extensions technology turbo boost technology and AES and I",
    "start": "1791480",
    "end": "1798590"
  },
  {
    "text": "instruction set using Advanced Encryption standard and what performance profile they are providing in order to",
    "start": "1798590",
    "end": "1805400"
  },
  {
    "text": "change to allow for the scale or environment to to work so to start with in the AVX",
    "start": "1805400",
    "end": "1812470"
  },
  {
    "text": "instructions said we have been innovating on instruction sets for you know decades this is in this is in that",
    "start": "1812470",
    "end": "1819040"
  },
  {
    "text": "series of instruction sets and and all foreign technical computing you heard about HPC use cases you are dealing with",
    "start": "1819040",
    "end": "1824620"
  },
  {
    "text": "large numbers and you're doing a lot of floating-point analysis and and in using",
    "start": "1824620",
    "end": "1829660"
  },
  {
    "text": "these instructions that now you can do more processing because you have you're",
    "start": "1829660",
    "end": "1835360"
  },
  {
    "text": "increasing essentially the number of floating-point operation you can do per clock cycle and doubling it up so if",
    "start": "1835360",
    "end": "1841630"
  },
  {
    "text": "you're dealing with technical compute use cases you will see an increase in performance and we've worked with AWS to",
    "start": "1841630",
    "end": "1847990"
  },
  {
    "text": "kind of have that available in that infrastructure I'll talk about turbo",
    "start": "1847990",
    "end": "1853600"
  },
  {
    "start": "1849000",
    "end": "1924000"
  },
  {
    "text": "boost so you know often cases we heard how you you know during the day the the cluster might be performing and being",
    "start": "1853600",
    "end": "1860200"
  },
  {
    "text": "used very efficiently and in the evening the cluster might not be used that that",
    "start": "1860200",
    "end": "1865330"
  },
  {
    "text": "efficient that a with that much data because not that much data is streaming in so how do you allow for more",
    "start": "1865330",
    "end": "1873250"
  },
  {
    "text": "efficient power and well up and thermal envelope in that processing so that the total cost of infrastructure is lower",
    "start": "1873250",
    "end": "1879610"
  },
  {
    "text": "which is eventually what gets passed down to the user so they can draw they can do more processing and with turbo",
    "start": "1879610",
    "end": "1887050"
  },
  {
    "text": "boost technology what what we do is we are able to on as-needed basis and based",
    "start": "1887050",
    "end": "1894160"
  },
  {
    "text": "on OS request improve the frequency of the core and allow for more processing",
    "start": "1894160",
    "end": "1899650"
  },
  {
    "text": "to be done but once it is done to be brought back to what is the average power and thermal envelope so that over",
    "start": "1899650",
    "end": "1907210"
  },
  {
    "text": "the long run when the core is not being used in a high computer in a computationally intensive environment",
    "start": "1907210",
    "end": "1914010"
  },
  {
    "text": "you do not have the kind of power and thermal usage that you would have when the frequency was higher so it allow for",
    "start": "1914010",
    "end": "1920770"
  },
  {
    "text": "allow some more optimized infrastructure to be used and then finally we heard about storage now one",
    "start": "1920770",
    "end": "1927070"
  },
  {
    "start": "1924000",
    "end": "1992000"
  },
  {
    "text": "of the things in storage is around data encryption you know data at rest needs to be protected",
    "start": "1927070",
    "end": "1932350"
  },
  {
    "text": "encryption often has had significant overhead in terms of processing cycle",
    "start": "1932350",
    "end": "1939760"
  },
  {
    "text": "and we introduced a instruction sets which are seven instructions but they are pretty powerful one and they provide 10x",
    "start": "1939760",
    "end": "1947599"
  },
  {
    "text": "performance improvement over doing AES encryption so often cases what we see is",
    "start": "1947599",
    "end": "1953090"
  },
  {
    "text": "the cost of encrypting data at rest is neutralized by the performance benefit",
    "start": "1953090",
    "end": "1958399"
  },
  {
    "text": "you get by using the instruction set and we work with our ecosystem so that that instruction set is being used when you",
    "start": "1958399",
    "end": "1965059"
  },
  {
    "text": "encrypt the data on on some of some of the environments you'll be working on so",
    "start": "1965059",
    "end": "1970669"
  },
  {
    "text": "this allows for not just to have acceleration on encryption but protect",
    "start": "1970669",
    "end": "1976460"
  },
  {
    "text": "against attacks like side-channel attacks where the the malware or the threat tries to detect the interaction",
    "start": "1976460",
    "end": "1983479"
  },
  {
    "text": "between memory and the core and by using this instruction set we actually protect",
    "start": "1983479",
    "end": "1988519"
  },
  {
    "text": "against those kind of threats in the encryption processing so when you",
    "start": "1988519",
    "end": "1994759"
  },
  {
    "start": "1992000",
    "end": "2070000"
  },
  {
    "text": "combine these value proposition what do you get as you use the e5 2600 using",
    "start": "1994759",
    "end": "2002499"
  },
  {
    "text": "we're on a terrace or benchmark using one terabyte data and what you see is a",
    "start": "2002499",
    "end": "2007570"
  },
  {
    "text": "performance benefit by moving on to the xeon e5 2600 50% reduction in the in the",
    "start": "2007570",
    "end": "2016299"
  },
  {
    "text": "time that it takes further performance boost can be had by using SSDs for storage so going back to the point about",
    "start": "2016299",
    "end": "2023049"
  },
  {
    "text": "storage that John mentioned the next in the cycle is compute and when you're running Hadoop clusters you are doing a",
    "start": "2023049",
    "end": "2029259"
  },
  {
    "text": "lot of parallel computer where there's an i/o data movement going on between these cores and that is where 10 Big E",
    "start": "2029259",
    "end": "2037419"
  },
  {
    "text": "reduces the time taken by additional 50% and if you were using Intel's",
    "start": "2037419",
    "end": "2045909"
  },
  {
    "text": "distribution for a patch idea where we have put additional performance optimizations that are tied to silicon",
    "start": "2045909",
    "end": "2051549"
  },
  {
    "text": "there is an additional 40 percent performance benefit to be had so you know you start from a you know Turner",
    "start": "2051549",
    "end": "2057849"
  },
  {
    "text": "start over one terabyte that would take 4 hours on the previous generation processor and bring it down all the way",
    "start": "2057849",
    "end": "2063970"
  },
  {
    "text": "to less than 10 minutes it by using all of these optimizations and there are",
    "start": "2063970",
    "end": "2069730"
  },
  {
    "text": "they're all available for you for use in in Amazon Web Services or at least most of them are",
    "start": "2069730",
    "end": "2074919"
  },
  {
    "text": "and you know they'd be what we are seeing is the as more and more applications end up being driven by",
    "start": "2074919",
    "end": "2082480"
  },
  {
    "text": "mobile users the amount of data that's getting generated is increasing most of that data is getting collected in the",
    "start": "2082480",
    "end": "2088329"
  },
  {
    "text": "cloud environments like AWS and then the new business models that are actually",
    "start": "2088329",
    "end": "2094750"
  },
  {
    "text": "making use of that data and then offering new services based on that data are coming up and some of the examples",
    "start": "2094750",
    "end": "2100420"
  },
  {
    "text": "were mentioned earlier by John and with that I would encourage you to give this",
    "start": "2100420",
    "end": "2109269"
  },
  {
    "start": "2107000",
    "end": "2130000"
  },
  {
    "text": "a try you have 600 hours of free supercomputing time made available on",
    "start": "2109269",
    "end": "2115210"
  },
  {
    "text": "AWS for you so if you're a user of Hadoop go ahead and expand your cluster and try out with",
    "start": "2115210",
    "end": "2121299"
  },
  {
    "text": "bigger datasets if you're not a user of a dupe this is a great time to try it because you know there's a easy way to get started at no",
    "start": "2121299",
    "end": "2129130"
  },
  {
    "text": "cost thank you",
    "start": "2129130",
    "end": "2132210"
  }
]
[
  {
    "text": "Amazon Timestream is serverless time series database service that can scale to handle",
    "start": "0",
    "end": "5600"
  },
  {
    "text": "trillions of events per day for as low as 1/10th the cost of relational databases and up to 1000X faster!",
    "start": "5600",
    "end": "11180"
  },
  {
    "text": "In this demo, we’re going to see how easy it is to get started with Amazon Timestream and interact with",
    "start": "11180",
    "end": "17000"
  },
  {
    "text": "it using the AWS SDK. Let’s begin by going to the Timestream service page in the",
    "start": "17000",
    "end": "22119"
  },
  {
    "text": "AWS Console and clicking “Create database”. \nWe’ll call our database: “getting_started_demo”.",
    "start": "22120",
    "end": "29400"
  },
  {
    "text": "To ensure the security of our time series data (both in \ntransit and at rest), Timestream supports encryption",
    "start": "29400",
    "end": "38280"
  },
  {
    "text": "using the Amazon Key Management Service \n(or KMS) key of your choice",
    "start": "38280",
    "end": "40280"
  },
  {
    "text": "or an automatically created default account key.",
    "start": "40280",
    "end": "43100"
  },
  {
    "text": "Encryption is enabled by default \nand cannot be  turned off.",
    "start": "43100",
    "end": "46340"
  },
  {
    "text": "We’ll use the default key for this demo.",
    "start": "46900",
    "end": "49800"
  },
  {
    "text": "Finally, we’ll choose the “Sample database” option",
    "start": "49800",
    "end": "52600"
  },
  {
    "text": "and ask Timestream to pre-populate \nour database with some sample",
    "start": "52600",
    "end": "55719"
  },
  {
    "text": "EC2 instance metrics data to explore.",
    "start": "55720",
    "end": "59140"
  },
  {
    "text": "When we open the DevOps  table in our demo database,",
    "start": "59260",
    "end": "61927"
  },
  {
    "text": "we can see it was automatically created with a \n“Memory store retention” period of 1 day,",
    "start": "61928",
    "end": "65980"
  },
  {
    "text": "and a “Magnetic store retention” period of 5 years.",
    "start": "65980",
    "end": "69120"
  },
  {
    "text": "All data written to Timestream initially resides in its \nwrite-optimized memory store and is then automatically",
    "start": "69120",
    "end": "75400"
  },
  {
    "text": "migrated to its read-optimized magnetic store after aging past the “Memory store retention” period.",
    "start": "75400",
    "end": "81120"
  },
  {
    "text": "Depending on your needs, you can also have Timestream delete your older data automatically",
    "start": "81120",
    "end": "86460"
  },
  {
    "text": "or retain it indefinitely.",
    "start": "86460",
    "end": "88560"
  },
  {
    "text": "These retention settings can be configured when creating a table or edited from this screen.",
    "start": "88560",
    "end": "93399"
  },
  {
    "text": "Let’s head over to the query editor and take a \ncloser look at our sample table.",
    "start": "93400",
    "end": "98280"
  },
  {
    "text": "All rows in a Timestream table consist of one or more \ndimensions, which identify the time series,",
    "start": "98560",
    "end": "104399"
  },
  {
    "text": "a measure, which is the value that was recorded at a \nparticular timestamp, and the timestamp itself.",
    "start": "104400",
    "end": "112000"
  },
  {
    "text": "Our sample DevOps table has recordings of the CPU utilization and memory utilization for",
    "start": "112000",
    "end": "117160"
  },
  {
    "text": "individual EC2 instances in a given availability \nzone and region.",
    "start": "117160",
    "end": "122160"
  },
  {
    "text": "Timestream’s query language is based on SQL to \nhelp users get started quickly and easily,",
    "start": "122160",
    "end": "128399"
  },
  {
    "text": "but its real power lies in the added support for \nfirst-class handling of time series data.",
    "start": "128400",
    "end": "133799"
  },
  {
    "text": "We’re going to run a couple of the built-in sample \nqueries to see this in action.",
    "start": "133800",
    "end": "137400"
  },
  {
    "text": "But first, I’m going to load some additional sample data into the DevOps table, which will help demonstrate those",
    "start": "137400",
    "end": "142120"
  },
  {
    "text": "additional capabilities like interpolation, \nintegration, derivation,",
    "start": "142120",
    "end": "147280"
  },
  {
    "text": "and smoothing operations directly on \nour time series data.",
    "start": "147280",
    "end": "150200"
  },
  {
    "text": "If you’d like to try this yourself, you can visit the link in \nthe video description to download the sample code",
    "start": "150200",
    "end": "155200"
  },
  {
    "text": "provided by the Amazon Timestream team, which is \navailable in Python, Node.js, Java, Go, and .NET.",
    "start": "155200",
    "end": "162140"
  },
  {
    "text": "While we wait for it to finish loading the sample data, let’s take a look at the monitoring dashboard.",
    "start": "162140",
    "end": "168000"
  },
  {
    "text": "Metrics for all Timestream databases and tables we create are automatically included in the built-in",
    "start": "168000",
    "end": "173200"
  },
  {
    "text": "Account Metrics dashboard for a convenient overall \nview of their health, and we can navigate",
    "start": "173200",
    "end": "177140"
  },
  {
    "text": "over to CloudWatch to drill down further into a specific database or table for more details.",
    "start": "177140",
    "end": "183400"
  },
  {
    "text": "Now that the sample data is done loading, \nlet’s go back to the query editor.",
    "start": "183400",
    "end": "187599"
  },
  {
    "text": "There are several different example queries to choose from, but let’s walk through this one first.",
    "start": "187600",
    "end": "193000"
  },
  {
    "text": "This query is going to figure out what the average CPU \nutilization across our entire sample EC2 fleet was over",
    "start": "193000",
    "end": "199800"
  },
  {
    "text": "the past two hours, calculate the average CPU \nutilization for each individual instance in our",
    "start": "199800",
    "end": "205400"
  },
  {
    "text": "fleet across that same time period, and then tell \nus which ones were consuming more than 10%",
    "start": "205400",
    "end": "210159"
  },
  {
    "text": "of whatever the average was. We can see this first \none at the top has the highest average compared",
    "start": "210160",
    "end": "217000"
  },
  {
    "text": "to the rest of the fleet, so let’s make note of its hostname and run another query to investigate further.",
    "start": "217000",
    "end": "223120"
  },
  {
    "text": "This next query is going to show us the average CPU \nutilization for a specific EC2 instance over the past",
    "start": "223120",
    "end": "229120"
  },
  {
    "text": "two hours, but with two helpful additions. First, it’s \ngoing to aggregate the running CPU utilization",
    "start": "229120",
    "end": "236000"
  },
  {
    "text": "across 30-second intervals (or “bins”) so that we can \nmore easily interpret these values at a glance, rather",
    "start": "236000",
    "end": "242000"
  },
  {
    "text": "than having to make sense of potentially hundreds of \ndata points per minute.",
    "start": "242000",
    "end": "246400"
  },
  {
    "text": "It’s also going to use a technique called “cubic spline \ninterpolation” to fill in any gaps in the data where",
    "start": "246400",
    "end": "251799"
  },
  {
    "text": "the monitoring agent on the EC2 instance may have \nfailed to record the CPU utilization measurement.",
    "start": "251800",
    "end": "257100"
  },
  {
    "text": "Now that we have the interpolated CPU values \navailable, we can see that even though this",
    "start": "257100",
    "end": "263000"
  },
  {
    "text": "instance was consuming more CPU than average across the fleet, its peak was only slightly above 80%.",
    "start": "263000",
    "end": "269200"
  },
  {
    "text": "Depending on your application, an occurrence like \nthis might be a fluke that's no cause for concern, or,",
    "start": "269200",
    "end": "274140"
  },
  {
    "text": "it might call for further investigation \nand corrective action.",
    "start": "274140",
    "end": "278400"
  },
  {
    "text": "Sending data to Timestream from your applications is \neasy as well. In this example, we’ll use the Timestream",
    "start": "278400",
    "end": "284199"
  },
  {
    "text": "client from the Python AWS SDK to add some \nadditional data to our DevOps table.",
    "start": "284200",
    "end": "289200"
  },
  {
    "text": "Let’s insert some example random disk space \nmetrics for our sample EC2 instances.",
    "start": "289200",
    "end": "294800"
  },
  {
    "text": "After running this script, we can see back in the AWS \nConsole that Timestream not only saved our data,",
    "start": "294800",
    "end": "300120"
  },
  {
    "text": "but it also automatically detected the new measure \nname and datatype for the disk space metrics.",
    "start": "300120",
    "end": "305180"
  },
  {
    "text": "Having the convenience of a flexible schema \nmeans that we can start recording new metric",
    "start": "305180",
    "end": "310000"
  },
  {
    "text": "data at any time without needing to run any potentially \nexpensive schema changes first.",
    "start": "310000",
    "end": "315400"
  },
  {
    "text": "Amazon Timestream is available now \nin select AWS regions.",
    "start": "315400",
    "end": "318180"
  },
  {
    "text": "Visit aws.amazon.com/timestream to learn \nmore about how you can get started today!",
    "start": "318180",
    "end": "325800"
  }
]
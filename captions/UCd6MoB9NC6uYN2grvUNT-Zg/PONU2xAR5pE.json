[
  {
    "start": "0",
    "end": "52000"
  },
  {
    "text": "okay let's get started first off thanks very much for taking some time to attend",
    "start": "30",
    "end": "6180"
  },
  {
    "text": "this session we're super excited to share some information about scheduling on Amazon ECS to a quick deep dive into",
    "start": "6180",
    "end": "13889"
  },
  {
    "text": "how it works some of the primitives that we've built that we feel enable customers to operate and manage",
    "start": "13889",
    "end": "21769"
  },
  {
    "text": "containers at scale and then we've got some I'm going to do the dry stuff I just shared this with Shuba and Matt and",
    "start": "21769",
    "end": "27570"
  },
  {
    "text": "then we're gonna get them up here talking about real-world use cases that are super cool how customers are",
    "start": "27570",
    "end": "33000"
  },
  {
    "text": "building on PCs today Matt's joined us from Expedia and Shuba who will follow",
    "start": "33000",
    "end": "38100"
  },
  {
    "text": "him as a senior product manager on our team working on the Amazon ECS product so my name's Anthony I've run the",
    "start": "38100",
    "end": "46200"
  },
  {
    "text": "product and engineering teams for ECS and ECR and I let's just jump right into the topic so first off when we think",
    "start": "46200",
    "end": "53699"
  },
  {
    "start": "52000",
    "end": "52000"
  },
  {
    "text": "about containers really what the Ucker has done providing a mechanism for",
    "start": "53699",
    "end": "62010"
  },
  {
    "text": "packaging distribution and for the",
    "start": "62010",
    "end": "67680"
  },
  {
    "text": "portability right of containers that's this is something that really changed the landscape and when we started",
    "start": "67680",
    "end": "74010"
  },
  {
    "text": "working with dr. several years back we realized and talking to our customers so we're running doctrine containers on ec2",
    "start": "74010",
    "end": "80100"
  },
  {
    "text": "that running one container was actually",
    "start": "80100",
    "end": "85229"
  },
  {
    "text": "fairly simple they started on their laptop did some local development figured out how to package up their",
    "start": "85229",
    "end": "91439"
  },
  {
    "text": "application and then as they started figuring out how to scale that how does",
    "start": "91439",
    "end": "96540"
  },
  {
    "text": "then you know move more to maybe a micro services model where they were breaking up these monolithic applications into",
    "start": "96540",
    "end": "103220"
  },
  {
    "text": "components they went from having one ten hundreds to thousands of containers that",
    "start": "103220",
    "end": "111509"
  },
  {
    "text": "now made up the different services across their infrastructure and that really changed the landscape right you",
    "start": "111509",
    "end": "117329"
  },
  {
    "text": "went from you know something of a suit that we're really attractive the the portability the manageability of what",
    "start": "117329",
    "end": "124170"
  },
  {
    "text": "docker gave customers and then it became at scale really complex you had to think",
    "start": "124170",
    "end": "130349"
  },
  {
    "text": "about the problem differently you had to think about how to keep you track of all the containers that",
    "start": "130349",
    "end": "135520"
  },
  {
    "text": "were running across your infrastructure what happened if a container failed right it raised new problems all of a",
    "start": "135520",
    "end": "142150"
  },
  {
    "text": "sudden now you had to think about how to maximize the utilization of all your infrastructure all those nodes you know",
    "start": "142150",
    "end": "147670"
  },
  {
    "text": "where they properly utilized as you move to this sort of new distribution model and running containers and so that",
    "start": "147670",
    "end": "154510"
  },
  {
    "text": "really was the primitives that we considered and the problems that we were trying to solve when we decided to build",
    "start": "154510",
    "end": "161440"
  },
  {
    "start": "155000",
    "end": "155000"
  },
  {
    "text": "Amazon ECS back in 2014 and our commitment as we thought through this problem for our",
    "start": "161440",
    "end": "167709"
  },
  {
    "text": "customers and as we engaged customers and said how can we help they had taken their applications and the way that they",
    "start": "167709",
    "end": "174549"
  },
  {
    "text": "were running them then they started to have to run all the side infrastructure in order to do this at scale they had to",
    "start": "174549",
    "end": "179830"
  },
  {
    "text": "run things like their own schedulers maybe they were using Mesa sauce or marathon they had to keep track of the",
    "start": "179830",
    "end": "185980"
  },
  {
    "text": "state so they were running things like zookeeper or @cd and this was infrastructure that was not necessarily",
    "start": "185980",
    "end": "192190"
  },
  {
    "text": "familiar with them they hadn't necessarily had to do that before right they were running their their applications on virtual machines and it",
    "start": "192190",
    "end": "198670"
  },
  {
    "text": "was a pretty pretty well-defined and solve problem and so our goal in building ECS was to remove that heavy",
    "start": "198670",
    "end": "205660"
  },
  {
    "text": "lifting we wanted to give a service or a set of services api's to customers to",
    "start": "205660",
    "end": "212019"
  },
  {
    "text": "manage the lifecycle of running containers and the cloud and so that's where we started",
    "start": "212019",
    "end": "218260"
  },
  {
    "text": "we established a set of goals for ourselves that have really evolved",
    "start": "218260",
    "end": "224079"
  },
  {
    "text": "around security scalability and performance like those were some things that we wanted to commit to customers",
    "start": "224079",
    "end": "229600"
  },
  {
    "text": "and give them as guarantees that if they chose to run containers on top of a tea",
    "start": "229600",
    "end": "234760"
  },
  {
    "text": "bus they would get those guarantees as they went and started scaling out and committing to this new new application",
    "start": "234760",
    "end": "240880"
  },
  {
    "text": "model and what we've seen is customers love containers we love containers and",
    "start": "240880",
    "end": "249150"
  },
  {
    "text": "today that infrastructure that we showed what we were building has really supporting massive scale we're launching",
    "start": "249150",
    "end": "256419"
  },
  {
    "text": "hundreds of millions of containers each week on behalf of customers across clusters with millions of container",
    "start": "256419",
    "end": "263380"
  },
  {
    "text": "instances so really it was important for us to get that underlying architecture correct and to think about how we could",
    "start": "263380",
    "end": "273190"
  },
  {
    "text": "help customers solve the the management process of those containers so we've",
    "start": "273190",
    "end": "278530"
  },
  {
    "text": "kind of broke this into three key areas this is kind of how we think about it we might think about this a little bit",
    "start": "278530",
    "end": "283960"
  },
  {
    "start": "280000",
    "end": "280000"
  },
  {
    "text": "differently schedulers mean a lot of different things depending on on the the technology or the stack that you use for",
    "start": "283960",
    "end": "290620"
  },
  {
    "text": "us we think about these is with three three real key components the first is a scheduling engine the second is a",
    "start": "290620",
    "end": "297430"
  },
  {
    "text": "placement engine and then the third piece is really about the extensions or extensibility that you get that really",
    "start": "297430",
    "end": "303730"
  },
  {
    "text": "the how you can build on top of that stack for custom schedulers custom workflows or be able to build UIs on top",
    "start": "303730",
    "end": "312610"
  },
  {
    "text": "of your cluster state so all right let's talk first just about the scheduling",
    "start": "312610",
    "end": "318640"
  },
  {
    "text": "engine from from our perspective the scheduling engines role is just to start",
    "start": "318640",
    "end": "325510"
  },
  {
    "text": "the task so let me define what that term is for for folks that have used VCS a",
    "start": "325510",
    "end": "331180"
  },
  {
    "text": "task is really just a group of containers so if you have three four five ten containers that make up your",
    "start": "331180",
    "end": "337660"
  },
  {
    "text": "application we give you a logical unit that we call a task that runs all those containers together and then when we",
    "start": "337660",
    "end": "344290"
  },
  {
    "text": "schedule that task for you we make sure that all those containers are running on the same instance right so that's how",
    "start": "344290",
    "end": "350740"
  },
  {
    "text": "you sort of we can't give you that guarantee you define your task in what we call task definition it's a",
    "start": "350740",
    "end": "356440"
  },
  {
    "text": "declarative way where you say here's the CPU the memory the ports the container",
    "start": "356440",
    "end": "361690"
  },
  {
    "text": "image that I need for this application to work or container images if you have multiple and you store that task",
    "start": "361690",
    "end": "367570"
  },
  {
    "text": "definition with our service and when you start the task you specify the task definition that you want to start and",
    "start": "367570",
    "end": "373600"
  },
  {
    "text": "that's exactly how we get the tasks on the right running in the right way so some of the poor underlying parts of the",
    "start": "373600",
    "end": "380530"
  },
  {
    "text": "scheduler but really the primary role of the scheduling engine is to actually",
    "start": "380530",
    "end": "386830"
  },
  {
    "text": "make the calls to the control plane our control plane that starts the task on",
    "start": "386830",
    "end": "392230"
  },
  {
    "text": "the specific node that's been identified so who does the work to determine the most optimal place to start that task",
    "start": "392230",
    "end": "400860"
  },
  {
    "text": "well that's our placement engine and we'll talk a little bit about that and how that works after we get through the",
    "start": "400860",
    "end": "407430"
  },
  {
    "text": "the different types of scheduling schedulers that we're offering to you so we want to give you choice right so as",
    "start": "407430",
    "end": "413639"
  },
  {
    "text": "you have different types of applications they have different types of requirements so we have four different",
    "start": "413639",
    "end": "418800"
  },
  {
    "text": "types of schedulers that we think about the first is a service scheduler and that really the role the service",
    "start": "418800",
    "end": "424680"
  },
  {
    "text": "scheduler is you tell us the task that you want to run how many copies of that",
    "start": "424680",
    "end": "430469"
  },
  {
    "text": "tasks you want to run and that has a lot to do with scaling right and you can integrate this back into auto scaling",
    "start": "430469",
    "end": "437039"
  },
  {
    "text": "groups right and load balancers so you basically model out how you want these tasks to run on on top of your ec2",
    "start": "437039",
    "end": "444210"
  },
  {
    "text": "instances and that comes in a service definition and what we do with our",
    "start": "444210",
    "end": "449610"
  },
  {
    "text": "service scheduler is if you say I need ten of these running at any given time or a hundred or a thousand is that we're",
    "start": "449610",
    "end": "456180"
  },
  {
    "text": "constantly monitoring the health of every single one of those tasks that are running across your instances and if one",
    "start": "456180",
    "end": "461189"
  },
  {
    "text": "fails or ten fail for whatever reason whether it's a docker run time or memory out of memory on the instance whatever",
    "start": "461189",
    "end": "467339"
  },
  {
    "text": "might be we go and start another task for you and if a node becomes unhealthy and that node fails and we have auto",
    "start": "467339",
    "end": "475710"
  },
  {
    "text": "scaling group we can go start in their instance for you and then start a task for you if we have to write so that really the the service is an important",
    "start": "475710",
    "end": "482430"
  },
  {
    "text": "construct when we think about scheduling because it's really sort of the start it and forget it because you've got all the",
    "start": "482430",
    "end": "489839"
  },
  {
    "text": "met the sort of functionality to for us to maintain and do all the heavy lifting for you to keep that service up and",
    "start": "489839",
    "end": "496139"
  },
  {
    "text": "running and we expose a lot of metrics and health checks out of that service for you so that you can go into our",
    "start": "496139",
    "end": "501779"
  },
  {
    "text": "console or look at cloud watch metrics or things of that nature to kind of get",
    "start": "501779",
    "end": "506909"
  },
  {
    "text": "a sense of how your service is actually functioning the second type of workload that we support with our schedulers are",
    "start": "506909",
    "end": "512219"
  },
  {
    "text": "batch type workloads so we've got integration with things like spot fleet we allow you to use your own our eyes",
    "start": "512219",
    "end": "519419"
  },
  {
    "text": "with your ECS cluster within your ECS cluster and we support both long running",
    "start": "519419",
    "end": "524579"
  },
  {
    "text": "and short running jobs so there's no limit you can actually run a task for just a few seconds if you want to so we have customers that use that Plus spot",
    "start": "524579",
    "end": "532290"
  },
  {
    "text": "the spot fleet market and actually run only run there's jobs",
    "start": "532290",
    "end": "537600"
  },
  {
    "text": "when it's optimal based off cost or time on when they want that job to complete",
    "start": "537600",
    "end": "543320"
  },
  {
    "text": "we've also built a service entirely on top of VCS I'm called a Tobias batch which gives you a nice friendly UI and",
    "start": "543320",
    "end": "550050"
  },
  {
    "text": "job queue so that you can run millions of these tasks or or workloads at any",
    "start": "550050",
    "end": "555690"
  },
  {
    "text": "given point and we actually make all the decisions for you based off the criteria that you set the third scheduler is an",
    "start": "555690",
    "end": "562890"
  },
  {
    "text": "evented scheduler super-important maybe just want to schedule some workload to run maybe it's once every day or once a",
    "start": "562890",
    "end": "568320"
  },
  {
    "text": "month some sort of processing we do this based off cloud watch events so you can",
    "start": "568320",
    "end": "573480"
  },
  {
    "text": "actually set triggers if this event happens start up a task or on a schedule start up a task and so this is an",
    "start": "573480",
    "end": "579510"
  },
  {
    "text": "important use case that we wanted to solve as well and the fourth one is a daemon scheduler and what a daemon",
    "start": "579510",
    "end": "585420"
  },
  {
    "text": "scheduler does is it it's responsible for making sure within your cluster that that a specific task perhaps a",
    "start": "585420",
    "end": "592080"
  },
  {
    "text": "monitoring agent or a logging agent is running at all times on each gnome within your cluster as your cluster",
    "start": "592080",
    "end": "598740"
  },
  {
    "text": "scales up it's responsible for understanding that there are new nodes entering into the cluster and ensuring that that task is running you you want",
    "start": "598740",
    "end": "606030"
  },
  {
    "text": "to make sure generally that those logging or monitoring agents start up before any other task land on it so it",
    "start": "606030",
    "end": "611370"
  },
  {
    "text": "also has to take into consideration things like preemption or prioritization to make sure that there's resources on",
    "start": "611370",
    "end": "617370"
  },
  {
    "text": "the node before any other other tasks start up we're currently working on the daemon scheduler and we're doing that",
    "start": "617370",
    "end": "624360"
  },
  {
    "start": "624000",
    "end": "624000"
  },
  {
    "text": "under our open sort of scheduling framework called blocks you might have heard us talk about blocks a year ago",
    "start": "624360",
    "end": "629570"
  },
  {
    "text": "and what we've done if you followed along the project what we heard from customers is first we really liked the",
    "start": "629570",
    "end": "636060"
  },
  {
    "text": "idea of you open sourcing your schedulers because that's like really close to our business logic and if we want to have some sort of custom",
    "start": "636060",
    "end": "641640"
  },
  {
    "text": "workflows to be really great to be able to integrate this into the the ECS schedulers and we said sure yeah it",
    "start": "641640",
    "end": "647400"
  },
  {
    "text": "makes a ton of sense to us right we want to open-source that entire stack the next thing we heard is but at the same",
    "start": "647400",
    "end": "652530"
  },
  {
    "text": "time even though we might want to run these on our own if we have to kind of fork this and insert some different",
    "start": "652530",
    "end": "657870"
  },
  {
    "text": "capabilities that are unique to our business we really don't want to manage these right we really like the fact that",
    "start": "657870",
    "end": "663089"
  },
  {
    "text": "we were able to use e CS and API as you give us to not have to manage any of the",
    "start": "663089",
    "end": "668190"
  },
  {
    "text": "infrastructure which also made a lot of sense to us and so what we've done is",
    "start": "668190",
    "end": "673670"
  },
  {
    "text": "built the framework for open sourcing our schedulers and all of our new schedulers will all be open source under",
    "start": "673670",
    "end": "679680"
  },
  {
    "text": "blocks they'll be available on github you'll be able to run them on your own contribute to them and the same",
    "start": "679680",
    "end": "684990"
  },
  {
    "text": "schedulers that we build under the blocks framework will be the same schedules that actually running in ECS so why is that important well let's say",
    "start": "684990",
    "end": "691230"
  },
  {
    "text": "you have a capability that you want added into the scheduler and you open up a pull request we're able to vet it make sure that it makes sense for the broad",
    "start": "691230",
    "end": "697560"
  },
  {
    "text": "community or we can implement it in a way that solves your your use case at the scale and we'll work with you on",
    "start": "697560",
    "end": "703620"
  },
  {
    "text": "that right make sure they can we can operate that at scale eventually that that feature and capability make it into",
    "start": "703620",
    "end": "709649"
  },
  {
    "text": "our control plane is actually running us part of the ECS control plan and then you won't even have to run your own version of this you'll actually just",
    "start": "709649",
    "end": "715259"
  },
  {
    "text": "start being able to call the ECS api's so we're really excited about that lifecycle and being able to open these",
    "start": "715259",
    "end": "720750"
  },
  {
    "text": "via this aspect of ECS up to the community so i've got some links up",
    "start": "720750",
    "end": "726750"
  },
  {
    "text": "there if you want to follow along there's a get up page an hour an hour blocks page take a look at the project the daemon scheduler and the design and the work",
    "start": "726750",
    "end": "733290"
  },
  {
    "text": "that we're doing it that is currently available so take a look and follow on for progress now let's jump a little bit",
    "start": "733290",
    "end": "741000"
  },
  {
    "text": "into the placement engine so this is the second core component that we want to expose to customers what we do when you",
    "start": "741000",
    "end": "747899"
  },
  {
    "start": "746000",
    "end": "746000"
  },
  {
    "text": "have an instance join your ECS cluster is we make important metadata",
    "start": "747899",
    "end": "754050"
  },
  {
    "text": "information about the instances when the nodes running in your cluster available to you so that's everything from meid",
    "start": "754050",
    "end": "759300"
  },
  {
    "text": "availability zone the instance type and then we also added capabilities where",
    "start": "759300",
    "end": "765990"
  },
  {
    "text": "you can create a custom tag so you can say these instances that I just added maybe they have a specific resource",
    "start": "765990",
    "end": "772589"
  },
  {
    "text": "maybe they're got a GPU or maybe you've launched a larger instance it has more",
    "start": "772589",
    "end": "778259"
  },
  {
    "text": "networking bandwidth and you might want to you know identify those for specific placement constraints in the future you",
    "start": "778259",
    "end": "786209"
  },
  {
    "text": "might want to do something around Bluegreen deployments and say these here are you know for my my blue set of",
    "start": "786209",
    "end": "792540"
  },
  {
    "text": "deployments this is from I'm a green on my development and prod so you really can do a lot of things with with the",
    "start": "792540",
    "end": "798389"
  },
  {
    "text": "custom attributes and the placement groups that we provide as part of that",
    "start": "798389",
    "end": "803520"
  },
  {
    "text": "so once once you understand the the different metadata that's exposed to you can start making decisions about how to",
    "start": "803520",
    "end": "809940"
  },
  {
    "text": "run workloads on top of your underlying cluster resources and I want to talk a little bit about how that decision",
    "start": "809940",
    "end": "815820"
  },
  {
    "start": "813000",
    "end": "813000"
  },
  {
    "text": "process is made so the first thing you can almost think about this as a funnel right and so at the top you might have a",
    "start": "815820",
    "end": "820980"
  },
  {
    "text": "hundred instances or a thousand instances available in your cluster and as we analyze your requests we try and",
    "start": "820980",
    "end": "829950"
  },
  {
    "text": "find the best fit right so it might be on what's if you ask for a bin packing out there and for example like how do we",
    "start": "829950",
    "end": "836370"
  },
  {
    "text": "make sure that we're honoring that request and and packing as dense as we",
    "start": "836370",
    "end": "841500"
  },
  {
    "text": "can on the instances before we start utilizing new ones right or if it's spread these tasks as cross availability",
    "start": "841500",
    "end": "848010"
  },
  {
    "text": "zones we have to go make sure that enough of the instances to satisfy the requester I need zone for you so first",
    "start": "848010",
    "end": "854459"
  },
  {
    "text": "we look at the sort of the hardware requirements of fewer the CPU the memory of the ports that you've asked us for we",
    "start": "854459",
    "end": "859500"
  },
  {
    "text": "we might take that number of a hundred instances maybe it goes down to 50 that actually fit the requirement you asked",
    "start": "859500",
    "end": "865170"
  },
  {
    "text": "for then we look at the custom constraints that you've given us so that could be anything from the zones or",
    "start": "865170",
    "end": "871560"
  },
  {
    "text": "maybe it's an omni ID maybe have a custom omni ID and this workload I mean it's a compliance type workload it has to run on a specific army we then make",
    "start": "871560",
    "end": "880050"
  },
  {
    "text": "sure that we only select the instance that fit those constraints as part of",
    "start": "880050",
    "end": "885660"
  },
  {
    "text": "the placement workflow then we honor the algorithm around plate the the bin",
    "start": "885660",
    "end": "890970"
  },
  {
    "text": "packing or spread we have support for a couple other different strategies which is showing in a second and at the very",
    "start": "890970",
    "end": "897089"
  },
  {
    "text": "end we apply that filter and maybe there's ten instances left then we pass",
    "start": "897089",
    "end": "902100"
  },
  {
    "text": "that back to our scheduling engine so that's how we close the loop and then the scheduler starts the tasks appropriately on the instances that were",
    "start": "902100",
    "end": "909300"
  },
  {
    "text": "selected here are the default strategies that we offer with ECS today we talked a",
    "start": "909300",
    "end": "916529"
  },
  {
    "start": "912000",
    "end": "912000"
  },
  {
    "text": "little bit up in packing we have spread or the high availability scheduling we",
    "start": "916529",
    "end": "922079"
  },
  {
    "text": "have affinity you might have two tests that you really want to run together or maybe you have two that never should run",
    "start": "922079",
    "end": "927180"
  },
  {
    "text": "together for whatever reason you want to make sure they're for maybe for availability purposes or maybe you want to make sure they're not",
    "start": "927180",
    "end": "932940"
  },
  {
    "text": "sharing memory or something like that right or two cpu intensive workloads you want to keep those apart so you can do things",
    "start": "932940",
    "end": "939029"
  },
  {
    "text": "like affinity or anti affinity in your placement and then we have something called distinct instances so this is the",
    "start": "939029",
    "end": "944550"
  },
  {
    "text": "foundational premise of a daemon scheduler which is I need one of these to always be running they have to spread",
    "start": "944550",
    "end": "949649"
  },
  {
    "text": "these across multiple instances I really",
    "start": "949649",
    "end": "956370"
  },
  {
    "start": "954000",
    "end": "954000"
  },
  {
    "text": "like this feature I think it's super powerful is we also support what we call strategy chaining so in real world you",
    "start": "956370",
    "end": "964350"
  },
  {
    "text": "might actually want high availability like I don't think we always do we want our tasks to stay up in our services to",
    "start": "964350",
    "end": "970470"
  },
  {
    "text": "stay running but at the same time we're cost conscious so we might create a strategy where we say run these tasks as",
    "start": "970470",
    "end": "978149"
  },
  {
    "text": "and impact them across availability zones so we'll run them across the three",
    "start": "978149",
    "end": "984209"
  },
  {
    "text": "availability zones where your instances are located but within each zone will impact them so you get the the most cost",
    "start": "984209",
    "end": "989790"
  },
  {
    "text": "optimal solution all these I'm the fall strategies are also available right in",
    "start": "989790",
    "end": "994950"
  },
  {
    "start": "992000",
    "end": "992000"
  },
  {
    "text": "the console so you can actually just go to the console and choose a default strategy trying to make it super simple to get started and we also let you in",
    "start": "994950",
    "end": "1002149"
  },
  {
    "text": "the console to customize this right so give us prioritization so that we understand what order you want us to pry",
    "start": "1002149",
    "end": "1008690"
  },
  {
    "text": "or when we make that placement decision what's the most important thing to you is it availability or is it bin packing and then at that time of well we'll",
    "start": "1008690",
    "end": "1015949"
  },
  {
    "text": "apply it even a custom strategy based off how you create your rules this is",
    "start": "1015949",
    "end": "1022220"
  },
  {
    "start": "1020000",
    "end": "1020000"
  },
  {
    "text": "just some visualization we'll go through these quickly and also to show you sort of how you can do this all from the command line so you just run a task",
    "start": "1022220",
    "end": "1028928"
  },
  {
    "text": "choose a placement strategy in this case it's spread and so we start those tasks across available instances in each of",
    "start": "1028929",
    "end": "1035780"
  },
  {
    "text": "the availability zones here's the spread and bin pack so you can visualize that within each availability zone we're",
    "start": "1035780",
    "end": "1042168"
  },
  {
    "text": "going to bin pack in an instance to drive up utilization for you lower cost and then we've built a multi-tenant",
    "start": "1042169",
    "end": "1049429"
  },
  {
    "start": "1047000",
    "end": "1047000"
  },
  {
    "text": "scheduler and all these scheduling options that we've talked about can all run on your your single cluster at the",
    "start": "1049429",
    "end": "1055910"
  },
  {
    "text": "same time and that's kind of unique and the value proposition there is that you with one single cluster you can actually",
    "start": "1055910",
    "end": "1061610"
  },
  {
    "text": "run hundreds of services with all different types of placement strategy we'll find the best fit for each of",
    "start": "1061610",
    "end": "1066799"
  },
  {
    "text": "those okay so in this example you have one service that you just want to keep then packing and so we're gonna you know",
    "start": "1066799",
    "end": "1072440"
  },
  {
    "text": "bin pack every time you scale will always just take a single note and so I've been packing till it's fully",
    "start": "1072440",
    "end": "1078080"
  },
  {
    "text": "utilized and then at the same time we'll have another scheduler that's actually running your server a service that is",
    "start": "1078080",
    "end": "1084229"
  },
  {
    "text": "making sure that we honor your availability requirements and spreading across nodes so jumping into the",
    "start": "1084229",
    "end": "1091129"
  },
  {
    "text": "extensibility this is really important because as we talk to customers we try",
    "start": "1091129",
    "end": "1097369"
  },
  {
    "text": "and build these rich scheduling and placement functionality directly in the control plane so again like we can",
    "start": "1097369",
    "end": "1103489"
  },
  {
    "text": "remove that heavy lifting from the customer but at the same time we know it's super important to help use all",
    "start": "1103489",
    "end": "1109909"
  },
  {
    "text": "sorts of different use cases that customers might have and so there's two things I wanted to share that we've done that I think are super powerful the",
    "start": "1109909",
    "end": "1117349"
  },
  {
    "start": "1114000",
    "end": "1114000"
  },
  {
    "text": "first is we've added a cluster query language and what that lets you do is from the API you can make calls against",
    "start": "1117349",
    "end": "1124879"
  },
  {
    "text": "your cluster list container instances and PLAs in through a cluster query",
    "start": "1124879",
    "end": "1130879"
  },
  {
    "text": "language I'm certain constraints so you can say tell me all the clusters in my or tell me all the instances within my",
    "start": "1130879",
    "end": "1137840"
  },
  {
    "text": "cluster that are of the t2 family or tell me all the instances that are",
    "start": "1137840",
    "end": "1143119"
  },
  {
    "text": "running this specific am i right or tell me all the instances that are running this specific specific operating system",
    "start": "1143119",
    "end": "1150109"
  },
  {
    "text": "right so lots of different things that you can choose then you'll get a return set of the instances that meet that criteria and then you can actually have",
    "start": "1150109",
    "end": "1157099"
  },
  {
    "text": "your own custom scheduler or own workflow that says go start these tasks on there and we have a we have a start",
    "start": "1157099",
    "end": "1162499"
  },
  {
    "text": "task API that you can use to target a specific Container instance ID and the",
    "start": "1162499",
    "end": "1168979"
  },
  {
    "text": "second thing we did last year is we built an event stream so it's one thing to pull the service and to get this",
    "start": "1168979",
    "end": "1175460"
  },
  {
    "start": "1169000",
    "end": "1169000"
  },
  {
    "text": "information on you know when you need it but a lot of times we want to be a lot more reactive we actually have one an",
    "start": "1175460",
    "end": "1181489"
  },
  {
    "text": "event to come to us to notify that something in our cluster has changed the state has changed and that there's an",
    "start": "1181489",
    "end": "1187099"
  },
  {
    "text": "appropriate action that should take place as a result of that and so the event stream lets you actually absorb",
    "start": "1187099",
    "end": "1194539"
  },
  {
    "text": "tasks state changes and cluster state changes from your environments",
    "start": "1194539",
    "end": "1199670"
  },
  {
    "text": "and and filter for different types of events whether it's a stopped instance new instance added stop task there's",
    "start": "1199670",
    "end": "1206540"
  },
  {
    "text": "lots of the things you can filter on then you can build again custom schedulers or we see a lot of people",
    "start": "1206540",
    "end": "1211610"
  },
  {
    "text": "using this to keep real-time you eyes of what's going on across their cluster and there's no polling it's all you don't",
    "start": "1211610",
    "end": "1217400"
  },
  {
    "text": "have to worry about hitting throttles with limits or anything like that because this is all event-driven like we're just pushing events to you and you",
    "start": "1217400",
    "end": "1223190"
  },
  {
    "text": "consume them and you can you know call this local cluster state that we give",
    "start": "1223190",
    "end": "1228590"
  },
  {
    "text": "you as often as you need to okay so the",
    "start": "1228590",
    "end": "1237169"
  },
  {
    "text": "next part here I want to invite Matt up and and what Matt's going to do is spend some time talking about how to use the",
    "start": "1237169",
    "end": "1242450"
  },
  {
    "text": "primitives that I just went through and sort of a real-world scenario thanks back my name is Matt Callen Dan yeah and",
    "start": "1242450",
    "end": "1254120"
  },
  {
    "text": "I'm a engineering manager at Expedia so I in the cloud acceleration team a",
    "start": "1254120",
    "end": "1260570"
  },
  {
    "text": "routine that kind of sits between the AWS platform and our development teams and we aim to speed up our development",
    "start": "1260570",
    "end": "1266600"
  },
  {
    "text": "teams and how they get to the cloud how they deploy out of our brisbane australia office where i'm from we help",
    "start": "1266600",
    "end": "1272510"
  },
  {
    "text": "to manage and maintain the automation around our ECS clusters so today i want to talk about a specific use case of",
    "start": "1272510",
    "end": "1279830"
  },
  {
    "text": "placement constraints that we found helps us when we automate the updates of production clusters so when we talk",
    "start": "1279830",
    "end": "1286700"
  },
  {
    "text": "about replacing all of the instances within a cluster when we do maintenance we we have a because we have an",
    "start": "1286700",
    "end": "1293090"
  },
  {
    "text": "immutable server approach that we take to make maintaining our clusters we never patch instances if we want to make",
    "start": "1293090",
    "end": "1298850"
  },
  {
    "text": "a change to it to an instance we will build a new ami and we'll roll that out to all all instances in the cluster",
    "start": "1298850",
    "end": "1305299"
  },
  {
    "text": "before I get into that just some background about how we use ECS so we have around 2600 ECS services out there",
    "start": "1305299",
    "end": "1313820"
  },
  {
    "text": "that's made up of 1100 unique applications internally we have a micro service generation tool developers can",
    "start": "1313820",
    "end": "1320090"
  },
  {
    "text": "go in and click a button and generate a micro service and they do that 20 times a day so we've got you know 4,000 of",
    "start": "1320090",
    "end": "1326540"
  },
  {
    "text": "these of these applications we have around 860 ec2 instances in our fleets",
    "start": "1326540",
    "end": "1332929"
  },
  {
    "text": "we have 13 clusters in five different regions our biggest cluster in production is 230",
    "start": "1332929",
    "end": "1338370"
  },
  {
    "text": "instances all up we run about 13,000 containers so we we've done a lot of",
    "start": "1338370",
    "end": "1343800"
  },
  {
    "text": "automation around how do we have you most effectively update update those clusters and one of the one of the",
    "start": "1343800",
    "end": "1349350"
  },
  {
    "text": "issues that we face when replacing all the instances in a cluster was how do we make sure that the the tasks that are",
    "start": "1349350",
    "end": "1356520"
  },
  {
    "text": "being relocated from old instances to new instances don't go on to an instance that itself is about to be replaced if",
    "start": "1356520",
    "end": "1363690"
  },
  {
    "text": "that makes sense so we want to make sure that they when they when they get relocated only go on to the new",
    "start": "1363690",
    "end": "1369060"
  },
  {
    "text": "instances that we have there so so what we what we came up with was this idea of",
    "start": "1369060",
    "end": "1375180"
  },
  {
    "start": "1371000",
    "end": "1371000"
  },
  {
    "text": "a placement constraint at deploy time that says when you deploy only deploy to",
    "start": "1375180",
    "end": "1380580"
  },
  {
    "text": "instances that are in this that are not in this state that we call pre drain so",
    "start": "1380580",
    "end": "1387030"
  },
  {
    "text": "state is a custom attribute that we've created and we only we only set that on",
    "start": "1387030",
    "end": "1393210"
  },
  {
    "text": "instances at this cluster management cluster update time so let me show you what that looks like in pictures so our",
    "start": "1393210",
    "end": "1400650"
  },
  {
    "start": "1399000",
    "end": "1399000"
  },
  {
    "text": "cluster update process takes a cloud formation stack with an auto scaling group which all of these five instances in this example will be connected to any",
    "start": "1400650",
    "end": "1407370"
  },
  {
    "text": "CCS cluster these are running ten tasks you can see so si there is running two tasks in that one service what we do as",
    "start": "1407370",
    "end": "1415860"
  },
  {
    "text": "part of our first phase of our update is we will duplicate the entire stack so if this stack was a hundred instances will",
    "start": "1415860",
    "end": "1422250"
  },
  {
    "text": "create a new stack new auto scaling group those 100 instances will start up immediately and join the exact same cluster we double the capacity and then",
    "start": "1422250",
    "end": "1429360"
  },
  {
    "text": "what we're going to do is we're going to go through in batches in the old cluster in the old stack sorry I'm going to go",
    "start": "1429360",
    "end": "1434970"
  },
  {
    "text": "through batteries maybe 50 percent of the cluster and we want to say we want to drain those instances and start",
    "start": "1434970",
    "end": "1440070"
  },
  {
    "start": "1439000",
    "end": "1439000"
  },
  {
    "text": "moving those tasks off there onto the new stack now at this point in time we don't want those six tasks going on to",
    "start": "1440070",
    "end": "1446790"
  },
  {
    "text": "the two other old instances that are still serving serving tasks and serving serving requests we want to make sure",
    "start": "1446790",
    "end": "1453150"
  },
  {
    "text": "that they only go into the new and the new stack on the right hand side so that's where we've got this state",
    "start": "1453150",
    "end": "1458880"
  },
  {
    "text": "attribute that we set on all of the five old instances which say they're state",
    "start": "1458880",
    "end": "1464490"
  },
  {
    "text": "attribute for these instances only is pre drain state there is no state attribute on those new instances so we go through",
    "start": "1464490",
    "end": "1471090"
  },
  {
    "text": "that training process those six tasks only relocate on to the the new stack and then we'll go through wait for that",
    "start": "1471090",
    "end": "1477690"
  },
  {
    "text": "draining process to finish and we'll say okay the second batch also put that into draining mode and they'll get relocated",
    "start": "1477690",
    "end": "1483929"
  },
  {
    "text": "across to to those new instances and in Phase three of our update process is to remove the old stack it's something that",
    "start": "1483929",
    "end": "1491130"
  },
  {
    "text": "we've come up with this year a major project that we've had internally just to help with the ID impedance the rollback ability the safety the speed we",
    "start": "1491130",
    "end": "1498000"
  },
  {
    "text": "can do a full 100 instance cluster update in about half an hour an important part of it is disabling and",
    "start": "1498000",
    "end": "1504570"
  },
  {
    "text": "resuming auto scaling processes as well and this is what it looks like in the UI we don't use the UI we use automation",
    "start": "1504570",
    "end": "1510720"
  },
  {
    "start": "1507000",
    "end": "1507000"
  },
  {
    "text": "with with the SDK behind the scenes but this is essentially what we say at deploy time make sure at deployment that",
    "start": "1510720",
    "end": "1518130"
  },
  {
    "text": "you go to a instance that is either doesn't have the state attribute at all or the state is only in pre drained",
    "start": "1518130",
    "end": "1525030"
  },
  {
    "text": "state so it's a custom attribute it doesn't exist by default I only said it during cluster update prevent CCS from",
    "start": "1525030",
    "end": "1530820"
  },
  {
    "text": "scheduling tasks that are about to be drained and we only have a remove it from an instance like that old stack if",
    "start": "1530820",
    "end": "1536250"
  },
  {
    "text": "we have to do the rollback if we have to reverse the process then we would remove that pre drain attribute that state",
    "start": "1536250",
    "end": "1542039"
  },
  {
    "text": "attribute so that we could reverse the draining process back to the to the old instances it's just a quick example a",
    "start": "1542039",
    "end": "1548730"
  },
  {
    "text": "quick use case of how we use the the placement constraints by default we use AZ spread for our consumer services as",
    "start": "1548730",
    "end": "1557490"
  },
  {
    "text": "well I'm gonna head off to Shuba now is going to talk about more more use cases",
    "start": "1557490",
    "end": "1563240"
  },
  {
    "text": "also using scheduling tools scheduling parameters that we just described I'll",
    "start": "1573280",
    "end": "1580430"
  },
  {
    "text": "cover what ECS does and how you can actually use issues for linking it with the other",
    "start": "1580430",
    "end": "1587810"
  },
  {
    "start": "1583000",
    "end": "1583000"
  },
  {
    "text": "triggers that you would like to lie on to scale up your applications so first",
    "start": "1587810",
    "end": "1593120"
  },
  {
    "start": "1591000",
    "end": "1591000"
  },
  {
    "text": "of all you you have an application you are running some X tax for that application how do you know when do you",
    "start": "1593120",
    "end": "1599360"
  },
  {
    "text": "want to scale it up we give you primitives to actually trigger cloud watch alarms based on how much CPU and",
    "start": "1599360",
    "end": "1606440"
  },
  {
    "text": "how much memory your service is currently utilizing and based on that you can decide how many more instances",
    "start": "1606440",
    "end": "1612710"
  },
  {
    "text": "of that service that is tasks of that service you want to spin up and this is tightly integrated with cloud watch you",
    "start": "1612710",
    "end": "1619940"
  },
  {
    "text": "can actually use the console workflow to set this up it will automatically trigger more copies based on how much",
    "start": "1619940",
    "end": "1626510"
  },
  {
    "text": "application load you are saying for your service so you you know that for",
    "start": "1626510",
    "end": "1634280"
  },
  {
    "start": "1632000",
    "end": "1632000"
  },
  {
    "text": "long-running services what do you do for these services which don't really require to be running all the time you",
    "start": "1634280",
    "end": "1639920"
  },
  {
    "text": "could have some accounting reporting auditing applications which only need to",
    "start": "1639920",
    "end": "1645230"
  },
  {
    "text": "come up I am based on some time scheduler and for that we integrate with cloud watch so with cloud watch you can",
    "start": "1645230",
    "end": "1651590"
  },
  {
    "text": "actually set a trigger either as a cron command or based on some parameters we",
    "start": "1651590",
    "end": "1657470"
  },
  {
    "text": "expose in the console and with that that alarm will get rigored based on your requirement and the tasks get spun up",
    "start": "1657470",
    "end": "1664520"
  },
  {
    "text": "based on that event so essentially we are making it easy for you to trigger",
    "start": "1664520",
    "end": "1669590"
  },
  {
    "text": "and trigger spinning up your micro services only when you need it and scale",
    "start": "1669590",
    "end": "1674720"
  },
  {
    "text": "it down when you don't need it that's the fundamental concept of how you can control what exactly you want to run at",
    "start": "1674720",
    "end": "1680360"
  },
  {
    "text": "what point in time based on your demand based on your users so it's not just",
    "start": "1680360",
    "end": "1686270"
  },
  {
    "start": "1684000",
    "end": "1684000"
  },
  {
    "text": "about issues you could be using a lot of other Amazon services and we want to make it easy for you to tie it with all",
    "start": "1686270",
    "end": "1692060"
  },
  {
    "text": "other Amazon services as well so we integrate with cloud watch for every",
    "start": "1692060",
    "end": "1697820"
  },
  {
    "text": "other service which which can send events and triggers to cloud watch for example your application may be seeing",
    "start": "1697820",
    "end": "1705200"
  },
  {
    "text": "a lot of traffic on your load-balancing queues maybe having longer queue lines",
    "start": "1705200",
    "end": "1710570"
  },
  {
    "text": "than you expect or you may be seeing higher latencies or you're sqs or SNS",
    "start": "1710570",
    "end": "1716000"
  },
  {
    "text": "may be seeing higher than normal traffic and events so you can actually tie ECS",
    "start": "1716000",
    "end": "1722240"
  },
  {
    "text": "into any of these triggers and automatically scale up the tasks that you have in the service same way we have",
    "start": "1722240",
    "end": "1730820"
  },
  {
    "text": "some customers using lambda based on an event you trigger a lambda function the",
    "start": "1730820",
    "end": "1735919"
  },
  {
    "text": "lambda function puts something into a queue like a sqs queue and then you trigger a easiest task the task comes up",
    "start": "1735919",
    "end": "1743210"
  },
  {
    "text": "reads from the queue and then does whatever processing or whatever it needs",
    "start": "1743210",
    "end": "1748340"
  },
  {
    "text": "to do so essentially we are making it simpler for you to cross connect across",
    "start": "1748340",
    "end": "1753380"
  },
  {
    "text": "AWS services thereby your scheduling your tasks and running your micro services only in a very easy manner all",
    "start": "1753380",
    "end": "1760519"
  },
  {
    "text": "these are reference architectures you could look them up on github we give you a template to set all this up together",
    "start": "1760519",
    "end": "1765889"
  },
  {
    "text": "or you are just changing with your task definitions and your image IDs and then",
    "start": "1765889",
    "end": "1771590"
  },
  {
    "text": "we are good to go we have a lot of",
    "start": "1771590",
    "end": "1778399"
  },
  {
    "start": "1774000",
    "end": "1774000"
  },
  {
    "text": "customers using ECS via the batch API so",
    "start": "1778399",
    "end": "1783440"
  },
  {
    "text": "I'm a double us batch exposes parameters to have you specify jobs jobs actually",
    "start": "1783440",
    "end": "1789380"
  },
  {
    "text": "take easiest tasks they also let you specify where and how you want to run those tasks we tie a knot with a lot of",
    "start": "1789380",
    "end": "1796130"
  },
  {
    "text": "common workflow models either Amazon our third-party tools and help you do your",
    "start": "1796130",
    "end": "1802190"
  },
  {
    "text": "batch processing on easiest in a very simple manner so you could specify things like my job depends on me so only",
    "start": "1802190",
    "end": "1809419"
  },
  {
    "text": "spin up job B after a is complete for example if there are a lot of our",
    "start": "1809419",
    "end": "1815899"
  },
  {
    "text": "scientific and financial customers require jobs where there are multiple elements in each job and there are clear",
    "start": "1815899",
    "end": "1822139"
  },
  {
    "text": "dependencies between each element in one job - each element on the other job so this is new introducing array jobs for",
    "start": "1822139",
    "end": "1828529"
  },
  {
    "text": "batch this helps you tie in all the specific entities in each of your jobs",
    "start": "1828529",
    "end": "1833870"
  },
  {
    "text": "very tightly with the other entities in the other jobs so and and we also have priorities so some",
    "start": "1833870",
    "end": "1842090"
  },
  {
    "start": "1840000",
    "end": "1840000"
  },
  {
    "text": "jobs may be more important than others you may want to run some jobs with asking for an undermanned instance and",
    "start": "1842090",
    "end": "1848300"
  },
  {
    "text": "maybe you want to run some other jobs based on Venice as part instance becomes available so we let you put your jobs",
    "start": "1848300",
    "end": "1854030"
  },
  {
    "text": "into different priority queues and and only run them based on your specific",
    "start": "1854030",
    "end": "1859400"
  },
  {
    "text": "needs for that application and for the cost and the capacity that you want to",
    "start": "1859400",
    "end": "1864650"
  },
  {
    "text": "provide for those applications so with all this you are making it easy we are",
    "start": "1864650",
    "end": "1870260"
  },
  {
    "text": "making it easy for you to run micro services well how do you do actual deployments when you think about your",
    "start": "1870260",
    "end": "1876190"
  },
  {
    "text": "application developers how do you make it easy for them to really build build",
    "start": "1876190",
    "end": "1881900"
  },
  {
    "text": "applications focus on your customers and then push out all the code changes that they are constantly developing into ECS",
    "start": "1881900",
    "end": "1890030"
  },
  {
    "text": "so that's something we've worked done a lot in the last year and we we are",
    "start": "1890030",
    "end": "1895760"
  },
  {
    "start": "1894000",
    "end": "1894000"
  },
  {
    "text": "introducing integration it's called pipeline to simplify automate a simplify and automate continuous deployment ezs",
    "start": "1895760",
    "end": "1902690"
  },
  {
    "text": "so what this means is that once you have a code repository which code pipeline",
    "start": "1902690",
    "end": "1908870"
  },
  {
    "text": "understands it could be either on code comet or on github or any other partner which code pipeline works with once",
    "start": "1908870",
    "end": "1916220"
  },
  {
    "text": "there is a code check in you can trigger automatically a pipeline that takes the new code changes does all the testing",
    "start": "1916220",
    "end": "1924050"
  },
  {
    "text": "and you know deployments it compiles image pushes it to HDR and deploys a new",
    "start": "1924050",
    "end": "1930830"
  },
  {
    "text": "service on ECS again code pipeline is very flexible you can define your own release process you can specify",
    "start": "1930830",
    "end": "1938410"
  },
  {
    "text": "checkpoints either a manual approval if you need it or you can even specify different environments how do you want",
    "start": "1938410",
    "end": "1945470"
  },
  {
    "text": "to automate testing between environments and then failover or fallback if you see any errors in that so with all this it's",
    "start": "1945470",
    "end": "1951860"
  },
  {
    "text": "easy for you to focus on your application and leave the heavy lifting of deploying your code on TCS to us with",
    "start": "1951860",
    "end": "1958730"
  },
  {
    "text": "all these integrations so you have a new service and you want to apply it and",
    "start": "1958730",
    "end": "1965150"
  },
  {
    "start": "1962000",
    "end": "1962000"
  },
  {
    "text": "code pipeline puts it on ECS so what happens next ECS gives you services which",
    "start": "1965150",
    "end": "1971450"
  },
  {
    "text": "today lets you specify the number of tasks and we also do our deploying in a rolling manners so you let's take an example of a",
    "start": "1971450",
    "end": "1978710"
  },
  {
    "text": "service where you have four tasks we give you connect we give you we expose",
    "start": "1978710",
    "end": "1983779"
  },
  {
    "text": "Max and min attributes essentially you can say how many maximum healthy tasks can you have for the service and how",
    "start": "1983779",
    "end": "1991039"
  },
  {
    "text": "many minimum do you want to keep up and running at any point in time so so for",
    "start": "1991039",
    "end": "1996350"
  },
  {
    "text": "the service if you say I want four tasks I want all four of them to always be available and I can actually spare some",
    "start": "1996350",
    "end": "2004299"
  },
  {
    "text": "extra compute to make a deployment in the sense that if you you know reply the new version and then one ensure that it",
    "start": "2004299",
    "end": "2011889"
  },
  {
    "text": "is running unhealthy and the load balancer is connecting to it and marks that task as healthy only then spin off",
    "start": "2011889",
    "end": "2018940"
  },
  {
    "text": "my existing tasks that's something we can do it could do for you very seamlessly without you having to do",
    "start": "2018940",
    "end": "2024010"
  },
  {
    "text": "anything again the same with an application where you may not really want to provide it more additional",
    "start": "2024010",
    "end": "2029950"
  },
  {
    "text": "compute you can specify I want to keep my my 75% of the attributes healthy in",
    "start": "2029950",
    "end": "2036220"
  },
  {
    "text": "that case we do our rolling deployment you'll have a new sir new our new version of the task come up and only",
    "start": "2036220",
    "end": "2042429"
  },
  {
    "text": "then take down the old versions of the applications so that works if you are",
    "start": "2042429",
    "end": "2049658"
  },
  {
    "start": "2043000",
    "end": "2043000"
  },
  {
    "text": "okay with running only one version what do you do if you want multiple versions and test them all before you actually",
    "start": "2049659",
    "end": "2055750"
  },
  {
    "text": "switch over your application traffic blue-green deployment we make it easy for you to apply the canary in the",
    "start": "2055750",
    "end": "2063460"
  },
  {
    "text": "coalmine for you to deploy the green version and actually test it out in a weighted phase manner before spinning",
    "start": "2063460",
    "end": "2070329"
  },
  {
    "text": "down the existing application so this is a reference architecture we have on github we used route 53 and the weighted",
    "start": "2070329",
    "end": "2076780"
  },
  {
    "text": "groups on route 53 if your customers are so it uses step functions behind the",
    "start": "2076780",
    "end": "2083319"
  },
  {
    "text": "scenes to actually roll the wall traffic from the old version to the new version in a real gradual manner so it gives you",
    "start": "2083319",
    "end": "2089260"
  },
  {
    "text": "a visual workflow where you can see what percentage of the traffic is actually sent to the new version can see what all",
    "start": "2089260",
    "end": "2095108"
  },
  {
    "text": "the metrics of how the new version is faring and based on how happy and comfortable you are you can actually",
    "start": "2095109",
    "end": "2101349"
  },
  {
    "text": "either make it go faster or slower or even justly work back to your existing stack we also are introducing services",
    "start": "2101349",
    "end": "2110859"
  },
  {
    "start": "2108000",
    "end": "2108000"
  },
  {
    "text": "cover for ECS so you have multiple services how do each of them discover the new versions of the other services",
    "start": "2110859",
    "end": "2117430"
  },
  {
    "text": "this is something that we are working with route 53 to sell we have a concept",
    "start": "2117430",
    "end": "2122800"
  },
  {
    "text": "called namespace you can register all your services into a namespace and thereby how multiple versions of the",
    "start": "2122800",
    "end": "2128500"
  },
  {
    "text": "services running in parallel is he a scheduler does all the heavy lifting behind the scenes to make sure that the",
    "start": "2128500",
    "end": "2134619"
  },
  {
    "text": "route 53 service registry is always up to date so with that your clients can always do",
    "start": "2134619",
    "end": "2139720"
  },
  {
    "text": "a DNS query get the latest healthy end points and then connect to them to get the latest version of other dependent",
    "start": "2139720",
    "end": "2145839"
  },
  {
    "text": "services I'll be speaking more about service discovery in my session on",
    "start": "2145839",
    "end": "2150970"
  },
  {
    "text": "Friday so feel free to attend so all this good for making sure that your new",
    "start": "2150970",
    "end": "2158349"
  },
  {
    "text": "applications are up and running and they're connected with all the other dependent services how do we do how do",
    "start": "2158349",
    "end": "2164140"
  },
  {
    "text": "you manage where exactly it runs so you need to there are a couple of pattern",
    "start": "2164140",
    "end": "2169510"
  },
  {
    "text": "common patterns that are Thomas customers are using today we have our integration it's part and not a scaling",
    "start": "2169510",
    "end": "2175180"
  },
  {
    "start": "2175000",
    "end": "2175000"
  },
  {
    "text": "so spot lets you bid for the instances that are additional capacity that you",
    "start": "2175180",
    "end": "2180910"
  },
  {
    "text": "can get at our radius price we have integrated with spot fleet spot fleet",
    "start": "2180910",
    "end": "2185920"
  },
  {
    "text": "enables you to maintain the fixed number of CPUs our fixed number of instances at",
    "start": "2185920",
    "end": "2191260"
  },
  {
    "text": "all points in time and that does the work of ensuring the bidding process is going on behind the scenes to give you",
    "start": "2191260",
    "end": "2198339"
  },
  {
    "text": "high availability as well so spot instances could be spread across availability zones and it will",
    "start": "2198339",
    "end": "2203849"
  },
  {
    "text": "automatically be configured to be a part of the cluster which is the spot fleet cluster so ECS integrates with spotlit",
    "start": "2203849",
    "end": "2212440"
  },
  {
    "text": "and runs your services on spot when it's available and and this is something that",
    "start": "2212440",
    "end": "2218500"
  },
  {
    "text": "you can leverage to either increase your compute capacity at the same class or to",
    "start": "2218500",
    "end": "2223720"
  },
  {
    "text": "run your services which are okay for being interrupted at lower prices so how",
    "start": "2223720",
    "end": "2232119"
  },
  {
    "start": "2231000",
    "end": "2231000"
  },
  {
    "text": "do we do this order scaling essentially so if you have developers who are building your applications that's always",
    "start": "2232119",
    "end": "2237640"
  },
  {
    "text": "good if you have automated it all to go on a cluster which has a fixed capacity then",
    "start": "2237640",
    "end": "2243920"
  },
  {
    "text": "it may not really have the additional memory and CPU that's required to to deploy earning applications so our if",
    "start": "2243920",
    "end": "2251059"
  },
  {
    "text": "your application increases if your service increases the number of tasks is running then how do you make sure that",
    "start": "2251059",
    "end": "2256279"
  },
  {
    "text": "there is always compute capacity to handle that load we we integrate with spy auto-scaling groups with cloud watch",
    "start": "2256279",
    "end": "2262789"
  },
  {
    "text": "events we send out events based on existing CPU and memory reservation",
    "start": "2262789",
    "end": "2268190"
  },
  {
    "text": "which means you are actually always optimizing for everything that a task or a service could potentially use or we",
    "start": "2268190",
    "end": "2274460"
  },
  {
    "text": "also gives metrics on actual usage so that's how much it's exactly using way I will despite how much it had reserve you",
    "start": "2274460",
    "end": "2281720"
  },
  {
    "text": "can tie that in into an auto scaling group which automatically increases the size of the number of instances that are",
    "start": "2281720",
    "end": "2288859"
  },
  {
    "text": "a part of the cluster and then the schedulers will kick in to actually place them place new tasks or the place",
    "start": "2288859",
    "end": "2295789"
  },
  {
    "text": "the tasks that are pending we waiting for computer resources into the new instances so we so you have you know",
    "start": "2295789",
    "end": "2306020"
  },
  {
    "start": "2305000",
    "end": "2305000"
  },
  {
    "text": "growing clusters how do you collapse them so we also give you metrics for utilization which you can tie in into a",
    "start": "2306020",
    "end": "2313069"
  },
  {
    "text": "lambda function and then spin down the number of instances that you have in the cluster if you are not using it again we",
    "start": "2313069",
    "end": "2321079"
  },
  {
    "text": "give you a flag called training this is going to help you simplify how we actually scale down the lambda functions",
    "start": "2321079",
    "end": "2327260"
  },
  {
    "text": "second set of flag call training on an instance which is running love which is running low on utilization then what",
    "start": "2327260",
    "end": "2333170"
  },
  {
    "text": "that triggers is that the easier scheduler will be aware that it's an instance which is about to go down so it",
    "start": "2333170",
    "end": "2339319"
  },
  {
    "text": "will not place any new tasks on an instance which is in training State also if there are if there if your service",
    "start": "2339319",
    "end": "2346099"
  },
  {
    "text": "allows the tasks to be complacent the number desired essentially if the",
    "start": "2346099",
    "end": "2352190"
  },
  {
    "text": "max healthy percentage is beyond 100 then you see a scheduler can also place new tasks and actively spin down the",
    "start": "2352190",
    "end": "2357890"
  },
  {
    "text": "tasks that are on your training instance so with that you can free up your",
    "start": "2357890",
    "end": "2364990"
  },
  {
    "text": "instances that are going down essentially your applications do not see any impact in terms of availability",
    "start": "2364990",
    "end": "2372080"
  },
  {
    "text": "latency because you are always because we are always ensuring that there are the desired number of tasks available",
    "start": "2372080",
    "end": "2377930"
  },
  {
    "text": "for you on your behalf behind the scenes doing all the training and the task placement adjustments as",
    "start": "2377930",
    "end": "2385310"
  },
  {
    "text": "required so all this will go away with",
    "start": "2385310",
    "end": "2391880"
  },
  {
    "start": "2389000",
    "end": "2389000"
  },
  {
    "text": "the introduction of our gate you may have heard about it in keynote today so we are making it easy for you to focus purely on your application and not worry",
    "start": "2391880",
    "end": "2398810"
  },
  {
    "text": "about the instances that you need to provision to have these tasks and have",
    "start": "2398810",
    "end": "2404270"
  },
  {
    "text": "your micro services always be easily deployed and always running so we",
    "start": "2404270",
    "end": "2409990"
  },
  {
    "text": "introduced forget with with ECS it will",
    "start": "2409990",
    "end": "2415460"
  },
  {
    "text": "make it easy for you to scale up your services or to scale down your services directly thinking about containers as",
    "start": "2415460",
    "end": "2421100"
  },
  {
    "text": "the primitive or tasks as the primitive without having to think about all the compute the four previous slides where I",
    "start": "2421100",
    "end": "2426530"
  },
  {
    "text": "spoke about patterns it's not relevant anymore forget is forget is integrated",
    "start": "2426530",
    "end": "2434000"
  },
  {
    "text": "with all the same integrations that if your supports today you can use AWS be pcs you can get a task IP you can use",
    "start": "2434000",
    "end": "2441200"
  },
  {
    "text": "security groups you can use load balancers you can use cloud voice you can use it with all the other services",
    "start": "2441200",
    "end": "2447350"
  },
  {
    "text": "that AWS has it's fully managed by Amazon so you're not really thinking",
    "start": "2447350",
    "end": "2453290"
  },
  {
    "text": "about how many instances are there and how do you scale it up we are doing it for you behind the scenes and your",
    "start": "2453290",
    "end": "2459620"
  },
  {
    "text": "service guarantees of how many tasks are running and how exactly are they placed across availability zones that still is",
    "start": "2459620",
    "end": "2465950"
  },
  {
    "text": "applicable so the placement constraints that you give to spread it across is ease for having high availability high",
    "start": "2465950",
    "end": "2471710"
  },
  {
    "text": "reliability that's still applicable all your scheduling all the scheduling that we provide is are still applicable but",
    "start": "2471710",
    "end": "2478190"
  },
  {
    "text": "you still but you just don't have to think about bin packing to sell cars or to really optimize the for CPU memory",
    "start": "2478190",
    "end": "2485500"
  },
  {
    "text": "reservations and stuff like that so so",
    "start": "2485500",
    "end": "2491000"
  },
  {
    "text": "with that you'll have more about forget in the upcoming sessions please attend them to really understand how exactly",
    "start": "2491000",
    "end": "2497090"
  },
  {
    "text": "four gate works thank you this all we had we can we can take",
    "start": "2497090",
    "end": "2505630"
  }
]
[
  {
    "start": "0",
    "end": "88000"
  },
  {
    "text": "hi everybody good to have you on this session my name is Julian I'm a tech",
    "start": "410",
    "end": "6690"
  },
  {
    "text": "evangelist with the WS focusing on artificial intelligence and machine learning in this session I'm going to",
    "start": "6690",
    "end": "15000"
  },
  {
    "text": "show you how to use deep learning library called Kara's and how to combine",
    "start": "15000",
    "end": "22350"
  },
  {
    "text": "it with Apache an excellent another open source library and how to run everything",
    "start": "22350",
    "end": "28859"
  },
  {
    "text": "on Amazon sage maker our managed service for machine learning okay so we'll start",
    "start": "28859",
    "end": "36270"
  },
  {
    "text": "with a very quick intro to Kara's and our next net just to to tell you a",
    "start": "36270",
    "end": "41969"
  },
  {
    "text": "little bit more about those two libraries and and then we'll see how to run a basic example with Kara's how to",
    "start": "41969",
    "end": "49739"
  },
  {
    "text": "train a basic neural network with Kara's and then we will move on to modifying",
    "start": "49739",
    "end": "56190"
  },
  {
    "text": "this Kara script to run it on say drinker and and we'll see how we can use",
    "start": "56190",
    "end": "62460"
  },
  {
    "text": "an excellent as a back-end as well okay so lots of stuff to cover and of course",
    "start": "62460",
    "end": "68100"
  },
  {
    "text": "you can ask all your questions on the twitch channel we'll take a look periodically of those questions I'll try",
    "start": "68100",
    "end": "74070"
  },
  {
    "text": "to answer as many as I can and I've got a bunch of friendly people also helping",
    "start": "74070",
    "end": "79770"
  },
  {
    "text": "me answering those questions so thanks to them okay and all questions welcome",
    "start": "79770",
    "end": "85259"
  },
  {
    "text": "so fire away so let's get started so so I guess the first thing we should talk",
    "start": "85259",
    "end": "91140"
  },
  {
    "text": "about is is garrus as you probably know we have a quite a bunch of libraries to",
    "start": "91140",
    "end": "99930"
  },
  {
    "text": "choose from now when it comes to building deep running applications tensorflow",
    "start": "99930",
    "end": "105750"
  },
  {
    "text": "Kara's Apache annex the PI torch chain er and more and specifically I wanted to",
    "start": "105750",
    "end": "114600"
  },
  {
    "text": "talk about Kara's today because it is a it is a developer's favorite I have to say and and as of today there is no",
    "start": "114600",
    "end": "122939"
  },
  {
    "text": "built-in support for Kara's in Amazon sage maker so I felt well this was a",
    "start": "122939",
    "end": "128310"
  },
  {
    "text": "good idea too show all the carrots users out there how they can how they can integrate their",
    "start": "128310",
    "end": "133959"
  },
  {
    "text": "favorite library on the sage maker so carrots is no rituals project started by",
    "start": "133959",
    "end": "139629"
  },
  {
    "text": "fall squash relay so kudos to him it grew really really popular and in a",
    "start": "139629",
    "end": "146049"
  },
  {
    "text": "nutshell Kara's is a high level API that lets you easily build and train all",
    "start": "146049",
    "end": "153129"
  },
  {
    "text": "kinds of neural networks all kinds of different architectures and and then",
    "start": "153129",
    "end": "158680"
  },
  {
    "text": "train those those models train those networks using different backends and",
    "start": "158680",
    "end": "164650"
  },
  {
    "text": "initially Kara supported tensorflow and piano ok another another popular library",
    "start": "164650",
    "end": "173349"
  },
  {
    "text": "for deep learning and with the release of carrots - carrots version - apache MX",
    "start": "173349",
    "end": "180790"
  },
  {
    "text": "net is now supported ok so we'll talk about that in a second but basically if you're new to Kara's I would recommend",
    "start": "180790",
    "end": "187659"
  },
  {
    "text": "going to the carrots website there are some pretty good tutorials out there and",
    "start": "187659",
    "end": "194220"
  },
  {
    "text": "again it's probably the one of the easiest ways to to get started with deep",
    "start": "194220",
    "end": "201819"
  },
  {
    "text": "learning so it might take you a little more than 30 seconds but yeah the good",
    "start": "201819",
    "end": "208540"
  },
  {
    "text": "thing what I like about Kara's is thanks to the high level API you don't write a",
    "start": "208540",
    "end": "213909"
  },
  {
    "text": "lot of code it's it's Python it's quite easy to write and understand and and the",
    "start": "213909",
    "end": "221079"
  },
  {
    "text": "fact that it's high level helps you build or builder or reuse models with",
    "start": "221079",
    "end": "227979"
  },
  {
    "text": "very little code and so you can focus not on actually writing the code but you can focus on solving the problem and as",
    "start": "227979",
    "end": "235000"
  },
  {
    "text": "you can see here there's a all kinds of layers all kinds of network",
    "start": "235000",
    "end": "242319"
  },
  {
    "text": "architectures that are supported so if you want to build convolution layers you",
    "start": "242319",
    "end": "247720"
  },
  {
    "text": "will find those available in cars and enough to say the online documentation",
    "start": "247720",
    "end": "253810"
  },
  {
    "text": "for parents is very very good so this is really a good place to start I can also",
    "start": "253810",
    "end": "259299"
  },
  {
    "text": "recommend looking at the blog okay",
    "start": "259299",
    "end": "267630"
  },
  {
    "text": "Kerris io okay and you'll find lots of",
    "start": "267630",
    "end": "273490"
  },
  {
    "text": "tutorials out there and again this is a this is a really really valuable",
    "start": "273490",
    "end": "278710"
  },
  {
    "text": "resource very high quality examples and showing you how to perform a number of",
    "start": "278710",
    "end": "286120"
  },
  {
    "text": "tasks in with with curves okay so a good resource to get started with deep",
    "start": "286120",
    "end": "291670"
  },
  {
    "text": "running so let's look at let's look at her under the other an example so to",
    "start": "291670",
    "end": "298270"
  },
  {
    "text": "keep things pretty simple we're going to work with a dataset that I'm sure you've",
    "start": "298270",
    "end": "303430"
  },
  {
    "text": "heard about probably used are called M missed and M missed is a collection of",
    "start": "303430",
    "end": "310830"
  },
  {
    "text": "60,000 handwritten digits from 0 to 9 10 classes okay so 60,000 for training and",
    "start": "310830",
    "end": "320620"
  },
  {
    "text": "10,000 for validation and of course the name of the game here is to learn how to",
    "start": "320620",
    "end": "326080"
  },
  {
    "text": "classify those 10 those ten classes correctly right recognizes that this",
    "start": "326080",
    "end": "331360"
  },
  {
    "text": "picture is a 0 or a 5 or 7 etc with the right level of accuracy so let's face it",
    "start": "331360",
    "end": "338020"
  },
  {
    "text": "this is really good for anything except learning and experimenting and testing",
    "start": "338020",
    "end": "343290"
  },
  {
    "text": "and the fact that it is a pretty small data set also helps with the training time so you can quickly try different",
    "start": "343290",
    "end": "349780"
  },
  {
    "text": "things so these are as you can see black and white images 28 by 28 pixels so it's",
    "start": "349780",
    "end": "355900"
  },
  {
    "text": "a really tiny data set and and that's why it's a good it's a good thing so",
    "start": "355900",
    "end": "361530"
  },
  {
    "text": "this is actually the first the first",
    "start": "361530",
    "end": "366790"
  },
  {
    "start": "362000",
    "end": "455000"
  },
  {
    "text": "example we're gonna look at so here we're going to train a simple",
    "start": "366790",
    "end": "372090"
  },
  {
    "text": "convolution neural network on M mist get trying to classify those 10 categories",
    "start": "372090",
    "end": "378840"
  },
  {
    "text": "correctly so I'm actually using sage maker right now this is this is a",
    "start": "378840",
    "end": "385360"
  },
  {
    "text": "notebook instance just to give you a quick look here at",
    "start": "385360",
    "end": "390919"
  },
  {
    "text": "the stage maker console this is it you can easily create a notebook instance by",
    "start": "390919",
    "end": "396830"
  },
  {
    "text": "clicking on that fancy orange button here filling in a few pieces of",
    "start": "396830",
    "end": "402680"
  },
  {
    "text": "information and off you go right you wait for a few minutes for that instance to come up and then you can",
    "start": "402680",
    "end": "408470"
  },
  {
    "text": "just open it and and when you open it you actually dive in directly into",
    "start": "408470",
    "end": "413900"
  },
  {
    "text": "Jupiter right which is the preferred tool for machine learning engineers and there are scientists these days and",
    "start": "413900",
    "end": "420020"
  },
  {
    "text": "that's why they're called notebook instances so it's an easy way to create your your test your dev and test",
    "start": "420020",
    "end": "427009"
  },
  {
    "text": "environment with a fully managed instance running in AWS and and you",
    "start": "427009",
    "end": "432710"
  },
  {
    "text": "don't have to mess with anything right tensorflow is pre-installed Chara's to",
    "start": "432710",
    "end": "437870"
  },
  {
    "text": "install and next net is pre-installed Jupiter obviously so pretty cool way to",
    "start": "437870",
    "end": "443740"
  },
  {
    "text": "to get started quickly but of course if you run Jupiter on your own machine on",
    "start": "443740",
    "end": "448969"
  },
  {
    "text": "your laptop that works too this is really a vanilla Jupiter here okay so let's look at this example so",
    "start": "448969",
    "end": "457039"
  },
  {
    "text": "I'm importing a few things and let's run those cells as we go I'm using the AMEX",
    "start": "457039",
    "end": "463909"
  },
  {
    "text": "that back-end but we'll get to that later okay doesn't really matter this code would run exactly the same if we",
    "start": "463909",
    "end": "469909"
  },
  {
    "text": "used tensorflow let's check the Paris version here to 1/6 not the latest but good enough for",
    "start": "469909",
    "end": "477469"
  },
  {
    "text": "our purpose we're going to use the batch size of 128 we have ten classes we're",
    "start": "477469",
    "end": "484940"
  },
  {
    "text": "going to train for 10 epochs and the image is like I said before are 28 by 28",
    "start": "484940",
    "end": "490340"
  },
  {
    "text": "okay so pretty straightforward there and this is a very well known dataset and",
    "start": "490340",
    "end": "497389"
  },
  {
    "text": "most deep learning libraries have utility functions to load or unload and",
    "start": "497389",
    "end": "502819"
  },
  {
    "text": "load the DMV's data set so that's the case here for for chaos it's one of",
    "start": "502819",
    "end": "508039"
  },
  {
    "text": "those data set API is here so we can just load it and automatically",
    "start": "508039",
    "end": "515620"
  },
  {
    "text": "we're gonna get the training set the set and each of them comes with the",
    "start": "515620",
    "end": "521550"
  },
  {
    "text": "samples the X matrix and the labels okay",
    "start": "521550",
    "end": "526710"
  },
  {
    "text": "so the ground truth you have two labels for each of those pictures and that's the Y vector okay",
    "start": "526710",
    "end": "534450"
  },
  {
    "start": "534000",
    "end": "727000"
  },
  {
    "text": "let's ignore this bit for our for now I'll get back to that this is a due to",
    "start": "534450",
    "end": "540300"
  },
  {
    "text": "the fact that we are either using MX net or or tensorflow let's get back to that later so then I'm",
    "start": "540300",
    "end": "547920"
  },
  {
    "text": "just going to normalize my dataset basically these dates that contains pixel values right and I'm just gonna",
    "start": "547920",
    "end": "556430"
  },
  {
    "text": "normalize them between 0 and 1 again remember these are black and white pictures so the pixel values are from 0",
    "start": "556430",
    "end": "564600"
  },
  {
    "text": "to 255 so normalizing them to values between 0 & 1 and then printing the shape and and then",
    "start": "564600",
    "end": "573390"
  },
  {
    "text": "using this utility function to actually encode the labels to to beat vectors",
    "start": "573390",
    "end": "584490"
  },
  {
    "text": "okay this is a technical one heart encoding and if you already do machine learning you may know that we don't",
    "start": "584490",
    "end": "590880"
  },
  {
    "text": "really like to work with categorical variables so here the labels for the",
    "start": "590880",
    "end": "596190"
  },
  {
    "text": "samples are integer values right 0 to 9 okay and and we don't we don't",
    "start": "596190",
    "end": "602550"
  },
  {
    "text": "specifically like to do that we'd rather do one hard encoding and let's maybe",
    "start": "602550",
    "end": "608730"
  },
  {
    "text": "look at an example here so if we had a label that says 2 we would actually",
    "start": "608730",
    "end": "613920"
  },
  {
    "text": "convert this to and we have 10 categories so we'd build a vector of 10",
    "start": "613920",
    "end": "621000"
  },
  {
    "text": "bits okay so that's six seven eight nine 10",
    "start": "621000",
    "end": "626160"
  },
  {
    "text": "right okay four yep and this is category two so we would flip beat two to one so",
    "start": "626160",
    "end": "634050"
  },
  {
    "text": "beat zero bit 1b - okay so this is called one heart encoding okay and this",
    "start": "634050",
    "end": "641970"
  },
  {
    "text": "is how you typically deal with categorical variables in in machine of course in deep running as well so",
    "start": "641970",
    "end": "648209"
  },
  {
    "text": "this this function is going to do just that okay it's gonna do it's gonna take",
    "start": "648209",
    "end": "653579"
  },
  {
    "text": "all of the labels for all of the pictures and transform the actual integer value into a bit vector where",
    "start": "653579",
    "end": "661949"
  },
  {
    "text": "the corresponding bit is flipped okay so this is what this is how we work with",
    "start": "661949",
    "end": "668069"
  },
  {
    "text": "categories okay so we do this for the training set and for the test set alright so let's run this cell okay so",
    "start": "668069",
    "end": "676699"
  },
  {
    "text": "in your case it would download and list from from the web of course I've done this before and I can see the shape okay",
    "start": "676699",
    "end": "684029"
  },
  {
    "text": "of X train so sixty thousand samples 28",
    "start": "684029",
    "end": "690839"
  },
  {
    "text": "by 28 pixels and just one channel because these are black and white images",
    "start": "690839",
    "end": "696209"
  },
  {
    "text": "if I if I had red green and blue images I've had color images I would have read many channels so I would have three",
    "start": "696209",
    "end": "702749"
  },
  {
    "text": "channels okay so actually my X train data structure is a four dimension array",
    "start": "702749",
    "end": "713939"
  },
  {
    "text": "okay it's called if you want to be fancy you're gonna call this a tensor but if",
    "start": "713939",
    "end": "719939"
  },
  {
    "text": "you learned how to code in the previous century like I did you just call this a multi-dimensional array right same thing",
    "start": "719939",
    "end": "725939"
  },
  {
    "text": "and we get 60,000 samples for training and 10,000 samples for testing okay so",
    "start": "725939",
    "end": "732899"
  },
  {
    "start": "727000",
    "end": "882000"
  },
  {
    "text": "there we go our dataset is ready then we can build our our simple convolution Network and",
    "start": "732899",
    "end": "739309"
  },
  {
    "text": "and I'm not gonna go into the theory of convolutional networks but basically",
    "start": "739309",
    "end": "745740"
  },
  {
    "text": "here I've got a first convolutional layer with 32 filters and during the",
    "start": "745740",
    "end": "753480"
  },
  {
    "text": "training process we will learn the actual values that are stored in those",
    "start": "753480",
    "end": "759299"
  },
  {
    "text": "filters and as you can see there are 3 by 3 filters so for each filter I need to learn 9 parameters that will show me",
    "start": "759299",
    "end": "766199"
  },
  {
    "text": "how to extract the right features from those images ok and I'm using the relu",
    "start": "766199",
    "end": "773490"
  },
  {
    "text": "activation function then I have another convolution with 64 filters so convoluted",
    "start": "773490",
    "end": "779610"
  },
  {
    "text": "convoluting again the the pictures that came out of the first layer and then I'm",
    "start": "779610",
    "end": "786840"
  },
  {
    "text": "using pooling pooling is an operation that tricks pictures just keeping the the brightest pixels so to speak and",
    "start": "786840",
    "end": "794790"
  },
  {
    "text": "throwing over everything else and then I use drop out which is a way to randomly",
    "start": "794790",
    "end": "801570"
  },
  {
    "text": "set connections to zero and this actually helps with generalization",
    "start": "801570",
    "end": "808290"
  },
  {
    "text": "okay dropout is a technique that fights overfitting which is a problem that",
    "start": "808290",
    "end": "813930"
  },
  {
    "text": "happens very quickly with deep running and overfitting means you you learn the training sets so well that you can't",
    "start": "813930",
    "end": "819480"
  },
  {
    "text": "generalize to anything else so drop that is a good thing to have and then I can",
    "start": "819480",
    "end": "825630"
  },
  {
    "text": "flatten all those tiny images that come out of the pooling layer and classify",
    "start": "825630",
    "end": "830970"
  },
  {
    "text": "them using a fully connected layer with 128 neurons then adding more dropout and",
    "start": "830970",
    "end": "836820"
  },
  {
    "text": "then actually outputting the probabilities for the 10 classes in that",
    "start": "836820",
    "end": "843570"
  },
  {
    "text": "layer ok and don't worry if you're not familiar with those operations that comes the convolution the pooling the",
    "start": "843570",
    "end": "850980"
  },
  {
    "text": "dropout etc and the dense layers you will find again lots of information in",
    "start": "850980",
    "end": "857460"
  },
  {
    "text": "the in the carrots in the carrot documentation and I will share some",
    "start": "857460",
    "end": "863010"
  },
  {
    "text": "resources at the end that give you kind of an introduction to to what deep",
    "start": "863010",
    "end": "868080"
  },
  {
    "text": "learning is and what convolution is so for now let's just accept but this works",
    "start": "868080",
    "end": "873450"
  },
  {
    "text": "and that it's going to excessively classify and and then you can dig into",
    "start": "873450",
    "end": "879510"
  },
  {
    "text": "the theory later on ok and then finally I compiled my model I pick an",
    "start": "879510",
    "end": "885480"
  },
  {
    "start": "882000",
    "end": "1100000"
  },
  {
    "text": "optimization function and I define a metric which is of course accuracy ok",
    "start": "885480",
    "end": "892310"
  },
  {
    "text": "all right and then I can I can train okay so I",
    "start": "892310",
    "end": "898980"
  },
  {
    "text": "call the fit API passing my training set the batch size the number of epochs the",
    "start": "898980",
    "end": "905220"
  },
  {
    "text": "validation set okay and let's let's try okay so this is training on my notebook instance okay",
    "start": "905220",
    "end": "912549"
  },
  {
    "text": "and this one has a GPU so it's it's reasonably fast if you try this on your",
    "start": "912549",
    "end": "917829"
  },
  {
    "text": "on your laptop or non GPU machine of course it's going to be quite quite",
    "start": "917829",
    "end": "924549"
  },
  {
    "text": "slower okay so it takes about it takes about maybe ten or twelve seconds for",
    "start": "924549",
    "end": "930670"
  },
  {
    "text": "epic so we can we can wait and just go all the way and let's take a look at",
    "start": "930670",
    "end": "937660"
  },
  {
    "text": "questions for a second",
    "start": "937660",
    "end": "941069"
  },
  {
    "text": "okay",
    "start": "946890",
    "end": "949640"
  },
  {
    "text": "Aurra",
    "start": "952300",
    "end": "954899"
  },
  {
    "text": "okay not too many questions than rx that's fine there will come later",
    "start": "957870",
    "end": "965570"
  },
  {
    "text": "oh I shouldn't do this okay all right so",
    "start": "971100",
    "end": "976290"
  },
  {
    "text": "we see what do we see here we see the training process ongoing pretty much and",
    "start": "976290",
    "end": "984180"
  },
  {
    "text": "we see the accuracy here right going up and this typically gets to 99% plus okay",
    "start": "984180",
    "end": "994980"
  },
  {
    "text": "so the way this works is we train on the 60,000 samples and then we use the",
    "start": "994980",
    "end": "1001460"
  },
  {
    "text": "validation tips that the 10,000 samples to measure to measure accuracy okay and",
    "start": "1001460",
    "end": "1007070"
  },
  {
    "text": "we see here the training accuracy for that last batch and we see the",
    "start": "1007070",
    "end": "1012770"
  },
  {
    "text": "validation accuracy here which is those 10,000 samples being predicted and at",
    "start": "1012770",
    "end": "1019040"
  },
  {
    "text": "the end of each epoch and this goes up again yeah so there you go 99 point of",
    "start": "1019040",
    "end": "1025040"
  },
  {
    "text": "three and let's see if we can go up a little more 99.1 maybe oh come on no we",
    "start": "1025040",
    "end": "1043339"
  },
  {
    "text": "went down a bit okay so the best epic was actually this one so this is if we",
    "start": "1043339",
    "end": "1049490"
  },
  {
    "text": "wanted to predict with this model this is the one we would this is the one we would keep right the one with the",
    "start": "1049490",
    "end": "1054830"
  },
  {
    "text": "highest validation accuracy okay so as you can see and again don't worry if you",
    "start": "1054830",
    "end": "1061070"
  },
  {
    "text": "if you're not super familiar with the I would say the theory of deep running the",
    "start": "1061070",
    "end": "1066620"
  },
  {
    "text": "the important things here are it's 5m code it's not a lot of code right and",
    "start": "1066620",
    "end": "1073700"
  },
  {
    "text": "and you can really easily build in just a few few lines of code you can build a",
    "start": "1073700",
    "end": "1079540"
  },
  {
    "text": "convolutional neural network it would be the same for other network architectures and and you can quickly train within",
    "start": "1079540",
    "end": "1085610"
  },
  {
    "text": "minutes by using like I said high-level api's and not worrying about being",
    "start": "1085610",
    "end": "1092090"
  },
  {
    "text": "kernels the low-level stuff that's that's happening during the training",
    "start": "1092090",
    "end": "1098330"
  },
  {
    "text": "process okay so this is Karis alright and I mentioned Kara's can use different",
    "start": "1098330",
    "end": "1107429"
  },
  {
    "start": "1100000",
    "end": "1428000"
  },
  {
    "text": "backends so I guess we could find",
    "start": "1107429",
    "end": "1113609"
  },
  {
    "text": "something in the documentation right oh yeah",
    "start": "1113609",
    "end": "1120169"
  },
  {
    "text": "so we can actually we can actually use we can actually use multiple backends so",
    "start": "1121309",
    "end": "1127109"
  },
  {
    "text": "like I said Karis is a high-level API that plugs into a lower-level library such as tensorflow piano and MX then",
    "start": "1127109",
    "end": "1136049"
  },
  {
    "text": "even though it's not given though it's not mentioned here so quick word about",
    "start": "1136049",
    "end": "1141209"
  },
  {
    "text": "MX net X it's part of the Apache Incubator you'll find a lots of",
    "start": "1141209",
    "end": "1147449"
  },
  {
    "text": "information on that website tutorials etc and you could use MX net standalone",
    "start": "1147449",
    "end": "1153629"
  },
  {
    "text": "right just like you could use of course tensorflow standalone but developers",
    "start": "1153629",
    "end": "1160019"
  },
  {
    "text": "fine again the Charis api to be to be friendly and especially for beginners it's it's a good way to get started so",
    "start": "1160019",
    "end": "1166889"
  },
  {
    "text": "you could have the best of both worlds you could use the high level easy to learn caris API and you could plug a very fast",
    "start": "1166889",
    "end": "1174839"
  },
  {
    "text": "very optimized back in like MX 9mx that is natively written in C++ and and it's",
    "start": "1174839",
    "end": "1182039"
  },
  {
    "text": "quite fast and I won't go into the discussion of why we would like to use them exdeath versus tensorflow",
    "start": "1182039",
    "end": "1187489"
  },
  {
    "text": "run your own benchmarks i run mine and i rather use the next net so there's your",
    "start": "1187489",
    "end": "1193979"
  },
  {
    "text": "answer okay benchmarks are touchy topic and they're not my topic today so MX net is",
    "start": "1193979",
    "end": "1203359"
  },
  {
    "text": "scalable it would support multi-gpu training it will support multi instance",
    "start": "1203359",
    "end": "1208589"
  },
  {
    "text": "training distributes training etc so it's it's probably a good choice for a",
    "start": "1208589",
    "end": "1214709"
  },
  {
    "text": "for a Karass back-end okay and again you can learn a whole lot more about MX net and please feel free to try",
    "start": "1214709",
    "end": "1220559"
  },
  {
    "text": "em XS alone as well just to get a feel for it so if we want to use if we want to use",
    "start": "1220559",
    "end": "1229669"
  },
  {
    "text": "Cara's with a different back-end",
    "start": "1229669",
    "end": "1234018"
  },
  {
    "text": "actually we have to change the config file and of course I close that window",
    "start": "1234889",
    "end": "1241679"
  },
  {
    "text": "so let's reopen the window so I'm just",
    "start": "1241679",
    "end": "1248490"
  },
  {
    "text": "gonna get to my terminal here so this is",
    "start": "1248490",
    "end": "1254399"
  },
  {
    "text": "a terminal on my online notebook instance and this would works the same",
    "start": "1254399",
    "end": "1259950"
  },
  {
    "text": "on on your own machine all right and you",
    "start": "1259950",
    "end": "1265559"
  },
  {
    "text": "have this file called care a stop Jason okay that takes a few parameters and in",
    "start": "1265559",
    "end": "1274139"
  },
  {
    "text": "and one of them is called backend and by default it's gonna say Tasha flow right",
    "start": "1274139",
    "end": "1280289"
  },
  {
    "text": "and if you change that to an ex net and of course you have MX net installed on your machine then you're gonna start",
    "start": "1280289",
    "end": "1286440"
  },
  {
    "text": "using it makes them okay as a matter of fact there's an extra",
    "start": "1286440",
    "end": "1291570"
  },
  {
    "text": "setting you should use coming back to that part I didn't explain before where",
    "start": "1291570",
    "end": "1300149"
  },
  {
    "text": "is that window okay so when we train",
    "start": "1300149",
    "end": "1305879"
  },
  {
    "text": "here it complained it complained about this so the problem here is different",
    "start": "1305879",
    "end": "1315509"
  },
  {
    "text": "libraries are optimized for different data shapes so we saw the shape of the",
    "start": "1315509",
    "end": "1322649"
  },
  {
    "text": "data here was sixty thousand samples 28",
    "start": "1322649",
    "end": "1328440"
  },
  {
    "text": "by 20 images one channel okay so tensorflow will require that channel",
    "start": "1328440",
    "end": "1334799"
  },
  {
    "text": "number to be last and actually MX networks faster if you put that channel",
    "start": "1334799",
    "end": "1340759"
  },
  {
    "text": "first okay that's what it says for performance improvement please change to",
    "start": "1340759",
    "end": "1346710"
  },
  {
    "text": "channel first format and this is what we should do here okay",
    "start": "1346710",
    "end": "1352760"
  },
  {
    "text": "so we can do it right away",
    "start": "1352760",
    "end": "1355720"
  },
  {
    "text": "and and just get a little performance and of course it's not gonna make a big difference it's not gonna make a big",
    "start": "1360300",
    "end": "1369840"
  },
  {
    "text": "difference for a tiny tiny dataset like this one and so it should say channels",
    "start": "1369840",
    "end": "1376920"
  },
  {
    "text": "first so that's the explanation for that",
    "start": "1376920",
    "end": "1383750"
  },
  {
    "text": "that weird message okay so this should be fine let's quickly try it again",
    "start": "1383750",
    "end": "1393170"
  },
  {
    "text": "hopefully this is gone okay see that that message is gone and if you train",
    "start": "1393170",
    "end": "1399870"
  },
  {
    "text": "again okay it's hard for me to say that's really faster but if you had a",
    "start": "1399870",
    "end": "1405000"
  },
  {
    "text": "bigger data set you would see you would see difference and again the only thing that changes is that it's gonna load the",
    "start": "1405000",
    "end": "1411930"
  },
  {
    "text": "data with the channels first okay so the shape of the data that gets loaded on",
    "start": "1411930",
    "end": "1418530"
  },
  {
    "text": "the GPU is actually one by 60,000 by 28 by 28 okay took me a while to figure",
    "start": "1418530",
    "end": "1424560"
  },
  {
    "text": "this message out but okay now we know all right so here we go now we're so",
    "start": "1424560",
    "end": "1429960"
  },
  {
    "start": "1428000",
    "end": "1483000"
  },
  {
    "text": "we're using an X net with Kara's in the optimized in an optimized way so the",
    "start": "1429960",
    "end": "1439080"
  },
  {
    "text": "next the next step would be let's say we so we train here on the notebook",
    "start": "1439080",
    "end": "1445320"
  },
  {
    "text": "instance and again we could have trained locally on your on the laptop on any machine right this this is not taking",
    "start": "1445320",
    "end": "1453390"
  },
  {
    "text": "anything into account and infrastructure to account now what if what if we need",
    "start": "1453390",
    "end": "1458520"
  },
  {
    "text": "to train on sage maker okay let's say we have a big data set we need to scale our",
    "start": "1458520",
    "end": "1465960"
  },
  {
    "text": "training process we can't just train on a local machine and we don't want to",
    "start": "1465960",
    "end": "1471120"
  },
  {
    "text": "manage the infrastructure and we want to rely on them on the stage maker manage",
    "start": "1471120",
    "end": "1476220"
  },
  {
    "text": "infrastructure to do this okay so let's take a look right so like I",
    "start": "1476220",
    "end": "1482970"
  },
  {
    "text": "said there is as of today there is no",
    "start": "1482970",
    "end": "1490850"
  },
  {
    "start": "1483000",
    "end": "1698000"
  },
  {
    "text": "buildings or for carrots and sage maker you can bring your tensorflow script into an",
    "start": "1490850",
    "end": "1498080"
  },
  {
    "text": "existing tensorflow environments you can bring your MX net code you can bring pi",
    "start": "1498080",
    "end": "1503690"
  },
  {
    "text": "torch you can bring chain code directly on Sage Maker and run it there but when",
    "start": "1503690",
    "end": "1510260"
  },
  {
    "text": "it comes to chaos it's it's not available so fortunately stage maker",
    "start": "1510260",
    "end": "1515330"
  },
  {
    "text": "provides a way for for developers to literally run anything and that means",
    "start": "1515330",
    "end": "1522920"
  },
  {
    "text": "building a custom container a docker container that you will push to AWS and",
    "start": "1522920",
    "end": "1529429"
  },
  {
    "text": "that you will run with sage maker okay in case you didn't know all the training",
    "start": "1529429",
    "end": "1536390"
  },
  {
    "text": "and all the prediction activity in sage maker is taking place with docker containers so when you use built-in",
    "start": "1536390",
    "end": "1542540"
  },
  {
    "text": "algos or when you use building environments for chance of flow and extended cetera you actually use",
    "start": "1542540",
    "end": "1547820"
  },
  {
    "text": "containers that AWS built and and pushed for you right but like I said you have",
    "start": "1547820",
    "end": "1554799"
  },
  {
    "text": "the option to build your own container and this is what I want to show you right now okay so let's let's see how we",
    "start": "1554799",
    "end": "1562370"
  },
  {
    "text": "can how we can do this and if you're not familiar with docker",
    "start": "1562370",
    "end": "1567530"
  },
  {
    "text": "you know don't don't run away there's nothing complicated here I would suggest",
    "start": "1567530",
    "end": "1574100"
  },
  {
    "text": "going to a darker calm and running the tutorial over there it's gonna take you",
    "start": "1574100",
    "end": "1579770"
  },
  {
    "text": "an hour maybe less and you will know more than enough to to understand",
    "start": "1579770",
    "end": "1585710"
  },
  {
    "text": "everything here so I will explain what we were doing with the docker",
    "start": "1585710",
    "end": "1590750"
  },
  {
    "text": "but don't blur docker stop you if you're not familiar with it okay all right so",
    "start": "1590750",
    "end": "1596929"
  },
  {
    "text": "so let's get started so let's import a few things and let's look at Dhaka files",
    "start": "1596929",
    "end": "1606440"
  },
  {
    "text": "so when you build a docker container you need a file called a docker file that",
    "start": "1606440",
    "end": "1611870"
  },
  {
    "text": "will list all the actions that are required to build a container okay so here for fun",
    "start": "1611870",
    "end": "1619429"
  },
  {
    "text": "and for a little more fun actually I decided to write to dr. Dwyers",
    "start": "1619429",
    "end": "1626089"
  },
  {
    "text": "one for cpu-based training and one for gpu-based training okay and you could",
    "start": "1626089",
    "end": "1633169"
  },
  {
    "text": "argue that well I guess the GPU version knows how to trade on CPU as well so why",
    "start": "1633169",
    "end": "1638960"
  },
  {
    "text": "do you make us look at two files here there's one good reason as you will see",
    "start": "1638960",
    "end": "1645849"
  },
  {
    "text": "the the GPU container needs to store of",
    "start": "1645849",
    "end": "1651649"
  },
  {
    "text": "course all the cuda environments right all the nvidia libraries that are",
    "start": "1651649",
    "end": "1657799"
  },
  {
    "text": "required to to drive the GPUs and these are a little heavy so the the CPU based",
    "start": "1657799",
    "end": "1664460"
  },
  {
    "text": "container ends up being one point one gigabyte or something and the GPU",
    "start": "1664460",
    "end": "1669769"
  },
  {
    "text": "container ends up being maybe 2.5 gigabytes okay so there's a bit of a GPU",
    "start": "1669769",
    "end": "1677119"
  },
  {
    "text": "tax to pay here so if you if you don't need that if you if you're not training on GPU machines then it's it's really a",
    "start": "1677119",
    "end": "1684739"
  },
  {
    "text": "waste of of network bandwidth - and storage I guess to carry around this",
    "start": "1684739",
    "end": "1690859"
  },
  {
    "text": "bigger container so now and then it will show you two examples instead of one which is good I guess",
    "start": "1690859",
    "end": "1696950"
  },
  {
    "text": "okay so let's look at the docker file for CPU so this from a directive tells",
    "start": "1696950",
    "end": "1703999"
  },
  {
    "start": "1698000",
    "end": "1863000"
  },
  {
    "text": "me which image I should start from okay you when you build a container you don't start from scratch even though you're",
    "start": "1703999",
    "end": "1709759"
  },
  {
    "text": "good right but here I'm I want to start from a boot to 16 and I'm going to run these package",
    "start": "1709759",
    "end": "1716779"
  },
  {
    "text": "commands to install some dependencies for MX net and some and make sure I got",
    "start": "1716779",
    "end": "1723440"
  },
  {
    "text": "the latest Python environment as well okay just objecting everything I'm going",
    "start": "1723440",
    "end": "1728929"
  },
  {
    "text": "to copy my script so my Charis script into the container",
    "start": "1728929",
    "end": "1734719"
  },
  {
    "text": "okay and this is this is important because it needs to be in that special place it needs to be called slash on PG",
    "start": "1734719",
    "end": "1741229"
  },
  {
    "text": "slash programs last train this is actually the script that sage maker will invoke it's the entry point if you will",
    "start": "1741229",
    "end": "1747499"
  },
  {
    "text": "okay so we need to make it executable as well okay so the the very few things that you need to",
    "start": "1747499",
    "end": "1754320"
  },
  {
    "text": "learn and maybe adapt to when use when you move existing deep learning code to",
    "start": "1754320",
    "end": "1760649"
  },
  {
    "text": "search maker is all related to they're all related to interfacing stage maker with that code okay this is one one",
    "start": "1760649",
    "end": "1767190"
  },
  {
    "text": "example of that then I'm going to copy my configuration file okay because I",
    "start": "1767190",
    "end": "1773100"
  },
  {
    "text": "want to use an x net so exact same file that you saw before copied into the container then I'm going to install MX",
    "start": "1773100",
    "end": "1781350"
  },
  {
    "text": "net okay and I'm going to install Karen s MX net which is the version of Cara's",
    "start": "1781350",
    "end": "1789000"
  },
  {
    "text": "that supports M extent as a back-end then I clean up a few things and that's",
    "start": "1789000",
    "end": "1794309"
  },
  {
    "text": "it okay so like it like I said if you don't know docker you can you can follow",
    "start": "1794309",
    "end": "1800070"
  },
  {
    "text": "along right you can understand what this does so again don't let docker stop you it is very easy to build those images",
    "start": "1800070",
    "end": "1805830"
  },
  {
    "text": "and and bring them to stage maker and run everything there okay let's look at",
    "start": "1805830",
    "end": "1810929"
  },
  {
    "text": "the GPU version it's almost the same I will just highlight the differences so",
    "start": "1810929",
    "end": "1817379"
  },
  {
    "text": "this time I'm starting from a CUDA 9 image from Nvidia and this gives me all",
    "start": "1817379",
    "end": "1823769"
  },
  {
    "text": "the other CUDA libraries and the Nvidia drivers etc and this can be a little",
    "start": "1823769",
    "end": "1830190"
  },
  {
    "text": "tricky to install so it's good to start from this image and avoid an issue",
    "start": "1830190",
    "end": "1835909"
  },
  {
    "text": "everything else is the same except this right installing the version of MX net that",
    "start": "1835909",
    "end": "1844379"
  },
  {
    "text": "has scrutinized support okay that is that that is actually linked against",
    "start": "1844379",
    "end": "1850860"
  },
  {
    "text": "those those CUDA libraries and the rest is the same ok so as you can see you don't need to",
    "start": "1850860",
    "end": "1856350"
  },
  {
    "text": "be a darker expert to do this I'm I'm not one and I know I pulled through so if I if I did it anyone can",
    "start": "1856350",
    "end": "1863100"
  },
  {
    "text": "alright so I'm going to copy those files to a local directory to build my my",
    "start": "1863100",
    "end": "1870059"
  },
  {
    "text": "container I'm going to copy my Kara script and my config file to that start",
    "start": "1870059",
    "end": "1878129"
  },
  {
    "text": "to this directory called build and I can stuff here right so this is local on my",
    "start": "1878129",
    "end": "1884020"
  },
  {
    "text": "notebook instance okay my docket files my config file my script and we'll look",
    "start": "1884020",
    "end": "1889600"
  },
  {
    "text": "at that one later because it has a few changes compared to the version use so before ok and now I should be ready to",
    "start": "1889600",
    "end": "1898990"
  },
  {
    "text": "build right so because I'm because this",
    "start": "1898990",
    "end": "1905140"
  },
  {
    "text": "notebook would let will let you will let you build the CPU version on a GPU very light I need to define some sub",
    "start": "1905140",
    "end": "1911890"
  },
  {
    "text": "variables we can build let's build the GPU ver ok those settings are pretty",
    "start": "1911890",
    "end": "1919660"
  },
  {
    "text": "much the same so I need to define a repository name in ECR so ECR is the",
    "start": "1919660",
    "end": "1927010"
  },
  {
    "text": "darker repository in AWS and this is where we're going to push that docker container stage maker needs the",
    "start": "1927010",
    "end": "1934059"
  },
  {
    "text": "containers to to be in ECR to be able to grab them okay so that's the name that's",
    "start": "1934059",
    "end": "1939610"
  },
  {
    "text": "the tag I will apply on the container okay just uh just a name that I define",
    "start": "1939610",
    "end": "1945100"
  },
  {
    "text": "and this is just another name for the training job that I'm gonna run on Sage maker ok just makes it easier to to find",
    "start": "1945100",
    "end": "1952570"
  },
  {
    "text": "those in the in the stage maker console and we'll see them here I guess right",
    "start": "1952570",
    "end": "1958090"
  },
  {
    "text": "when we start training okay I'm going to",
    "start": "1958090",
    "end": "1963179"
  },
  {
    "text": "train on the p-38 excel instance that's a big one",
    "start": "1963179",
    "end": "1968580"
  },
  {
    "text": "it's completely unneeded for a small dataset like this but I say all the time",
    "start": "1968580",
    "end": "1973870"
  },
  {
    "text": "I'm not paying my liberalism bills so hey let's have fun I'm gonna use two",
    "start": "1973870",
    "end": "1979660"
  },
  {
    "text": "GPUs from that instance okay and the batch size will be 256 alright so just",
    "start": "1979660",
    "end": "1987120"
  },
  {
    "text": "just some constants and defining and I'm also making them available as",
    "start": "1987120",
    "end": "1993390"
  },
  {
    "text": "environment variables so that I can refer to them in my script below okay",
    "start": "1993390",
    "end": "1998940"
  },
  {
    "start": "1998000",
    "end": "2043000"
  },
  {
    "text": "now the next step is to make sure I have an ECR repository and",
    "start": "1998940",
    "end": "2006890"
  },
  {
    "text": "of course I have one already I just quickly show you VCR",
    "start": "2006890",
    "end": "2012490"
  },
  {
    "text": "okay so private talker repository",
    "start": "2014710",
    "end": "2020210"
  },
  {
    "text": "service in in AWS so I've got I've got a repo already here okay and this is where",
    "start": "2020210",
    "end": "2028429"
  },
  {
    "text": "I will push my image right so if it didn't exist it would have been created",
    "start": "2028429",
    "end": "2035870"
  },
  {
    "text": "using the AWS command line and then I login to that repository okay and from",
    "start": "2035870",
    "end": "2041809"
  },
  {
    "text": "now on from now on the the rest is a standard darker stuff so let's build the",
    "start": "2041809",
    "end": "2047510"
  },
  {
    "start": "2043000",
    "end": "2088000"
  },
  {
    "text": "image so I call darker build using the darker file that I showed you and the",
    "start": "2047510",
    "end": "2054919"
  },
  {
    "text": "tag that I defined okay and as you can see it's going to run all those",
    "start": "2054919",
    "end": "2061358"
  },
  {
    "text": "instructions from the docket file okay so updating packages copying my script",
    "start": "2061359",
    "end": "2067750"
  },
  {
    "text": "okay and I hear it's quite fast because it's cached I already did this on the",
    "start": "2067750",
    "end": "2073878"
  },
  {
    "text": "instance so if you do this for the first time it's going to download packages from the web it's gonna take a little",
    "start": "2073879",
    "end": "2078919"
  },
  {
    "text": "longer but there's no point in wasting minutes to to look at this and then my",
    "start": "2078919",
    "end": "2086000"
  },
  {
    "text": "image has been tagged okay and I yes",
    "start": "2086000",
    "end": "2092600"
  },
  {
    "start": "2088000",
    "end": "2148000"
  },
  {
    "text": "okay now it tagged it with the repository name and I can see if I call",
    "start": "2092600",
    "end": "2099590"
  },
  {
    "text": "that docker images command I will see this image that I created on my laptop",
    "start": "2099590",
    "end": "2106820"
  },
  {
    "text": "okay and again it's cached so it's a little older but you would see the same result",
    "start": "2106820",
    "end": "2112910"
  },
  {
    "text": "and as you can see it is three gigabytes large compared to the CPU version which",
    "start": "2112910",
    "end": "2118310"
  },
  {
    "text": "is 1.4 so now you could say well okay who cares it's not so much about storage it's",
    "start": "2118310",
    "end": "2126200"
  },
  {
    "text": "really about the size of the containers that get deployed to Sage maker why for",
    "start": "2126200",
    "end": "2132109"
  },
  {
    "text": "Sage maker to to bring three gigabytes worth of content to an instance if you only need one",
    "start": "2132109",
    "end": "2138080"
  },
  {
    "text": "point for it's your training jobs will just start faster if you have smaller containers so that's that's good",
    "start": "2138080",
    "end": "2144740"
  },
  {
    "text": "good reason to have a small containers okay and and now I can push it right so",
    "start": "2144740",
    "end": "2153440"
  },
  {
    "start": "2148000",
    "end": "2178000"
  },
  {
    "text": "again this is instant this takes place instantly because the image didn't",
    "start": "2153440",
    "end": "2159470"
  },
  {
    "text": "change and it's already been pushed to to the ECR repository if you run this for the first time it will push the",
    "start": "2159470",
    "end": "2166130"
  },
  {
    "text": "layers and it takes a couple of minutes to push this to to VCR okay but that's",
    "start": "2166130",
    "end": "2172220"
  },
  {
    "text": "the process alright so now we have a custom container it's been pushed to ECR",
    "start": "2172220",
    "end": "2179600"
  },
  {
    "start": "2178000",
    "end": "2223000"
  },
  {
    "text": "and and we're ready to strain with it okay and from now on I would say we're",
    "start": "2179600",
    "end": "2187700"
  },
  {
    "text": "back into sage maker world there's nothing specific from now on we're going",
    "start": "2187700",
    "end": "2193790"
  },
  {
    "text": "to train with the sage maker SDK in exactly the same fashion as we would",
    "start": "2193790",
    "end": "2199880"
  },
  {
    "text": "with built-in containers okay so again like you see like it like you can see as",
    "start": "2199880",
    "end": "2207140"
  },
  {
    "text": "you can see here that the only specific part is building the container making",
    "start": "2207140",
    "end": "2212600"
  },
  {
    "text": "sure the entry point for the container is is well-defined pushing that to VCR",
    "start": "2212600",
    "end": "2221030"
  },
  {
    "text": "okay and and then you can just use that",
    "start": "2221030",
    "end": "2226370"
  },
  {
    "start": "2223000",
    "end": "2258000"
  },
  {
    "text": "container and on stage maker just like everything else so what should we do now",
    "start": "2226370",
    "end": "2232430"
  },
  {
    "text": "so we should upload our amnesty data set to s3 okay because that's where stage",
    "start": "2232430",
    "end": "2240590"
  },
  {
    "text": "maker will grab data from it needs to be an s3 okay so I need to put this in the",
    "start": "2240590",
    "end": "2249710"
  },
  {
    "text": "training set in the right place and the test set in the right place okay now of",
    "start": "2249710",
    "end": "2256160"
  },
  {
    "text": "course I need to run that cell otherwise have problems okay and then we have a",
    "start": "2256160",
    "end": "2261410"
  },
  {
    "start": "2258000",
    "end": "2313000"
  },
  {
    "text": "bucket that will be used to save the train model and training like I said now is a",
    "start": "2261410",
    "end": "2267360"
  },
  {
    "text": "completely standard we just use the stage maker SDK we use this estimator object which is the generic training",
    "start": "2267360",
    "end": "2274950"
  },
  {
    "text": "object in Sage ranker and it requires a few parameters so the image name so",
    "start": "2274950",
    "end": "2280350"
  },
  {
    "text": "that's really the name of the container that we are that we created okay and yeah that that name here right the",
    "start": "2280350",
    "end": "2290520"
  },
  {
    "text": "best name so that's just the text string that I defined earlier to visualize my",
    "start": "2290520",
    "end": "2296910"
  },
  {
    "text": "jobs in the console I'm gonna pick one instance of the type that I defined",
    "start": "2296910",
    "end": "2302760"
  },
  {
    "text": "earlier so that's a p38 Excel and the output path is where sage maker is going",
    "start": "2302760",
    "end": "2309150"
  },
  {
    "text": "to write the train model okay and again this is really no different from what",
    "start": "2309150",
    "end": "2316080"
  },
  {
    "start": "2313000",
    "end": "2348000"
  },
  {
    "text": "you would do with a built-in containers then I need to set some hyper parameters",
    "start": "2316080",
    "end": "2321210"
  },
  {
    "text": "so these are parameters that will be passed to my Kara script and of course as you can guess this does require a bit",
    "start": "2321210",
    "end": "2327390"
  },
  {
    "text": "of code into the script we'll look at those while the training runs and so I'm",
    "start": "2327390",
    "end": "2333570"
  },
  {
    "text": "passing a learning rate the number of epochs the number of GPUs you'll see why",
    "start": "2333570",
    "end": "2338700"
  },
  {
    "text": "it's not strictly a hyper parameter but that's a convenient way to to pass it here and the batch size okay and then",
    "start": "2338700",
    "end": "2346050"
  },
  {
    "text": "I'm training so let's get started okay and so what's gonna happen now is",
    "start": "2346050",
    "end": "2351560"
  },
  {
    "start": "2348000",
    "end": "2383000"
  },
  {
    "text": "standard sage maker stuff sage maker creates that p-38 Excel instance it's",
    "start": "2351560",
    "end": "2358230"
  },
  {
    "text": "going to pull the container that I created to that instance and it's going",
    "start": "2358230",
    "end": "2363600"
  },
  {
    "text": "to invoke that train script that I copied into the container with those",
    "start": "2363600",
    "end": "2369330"
  },
  {
    "text": "parameters and the location of my data set okay and once this starts within a",
    "start": "2369330",
    "end": "2375780"
  },
  {
    "text": "few minutes we'll see the carers training log and we'll get the train model at the end all right so let's the",
    "start": "2375780",
    "end": "2386520"
  },
  {
    "start": "2383000",
    "end": "2418000"
  },
  {
    "text": "the wireless starts we need to look at the Kara script okay because as I said",
    "start": "2386520",
    "end": "2394890"
  },
  {
    "text": "before a few times we need to do a few modifications and those mostly are related to they're",
    "start": "2394890",
    "end": "2403260"
  },
  {
    "text": "exclusively related actually to interfacing that code with sage paper so let's let's take a look okay here it is",
    "start": "2403260",
    "end": "2418490"
  },
  {
    "start": "2418000",
    "end": "2468000"
  },
  {
    "text": "okay so just to be clear this is the exact same example that we trained before on the notebook instance",
    "start": "2420140",
    "end": "2427109"
  },
  {
    "text": "initially with a few modifications to run it on Sage maker so I guess you know",
    "start": "2427109",
    "end": "2433560"
  },
  {
    "text": "you can you know you can guess what I had to change it's all about interfacing so the interface between sage maker and",
    "start": "2433560",
    "end": "2441840"
  },
  {
    "text": "this code is I would say the input interface is passing hyper parameters",
    "start": "2441840",
    "end": "2448520"
  },
  {
    "text": "passing the location of the training set okay and the output interface is saving",
    "start": "2448520",
    "end": "2458100"
  },
  {
    "text": "the model okay and that's about it so nothing scary nothing scary and and",
    "start": "2458100",
    "end": "2465180"
  },
  {
    "text": "this is how we do it so you'll find in",
    "start": "2465180",
    "end": "2470490"
  },
  {
    "start": "2468000",
    "end": "2498000"
  },
  {
    "text": "the documentation that stage maker provides all the input information in",
    "start": "2470490",
    "end": "2475859"
  },
  {
    "text": "well-known locations right thank God no surprises so you will find the hyper parameters in",
    "start": "2475859",
    "end": "2484109"
  },
  {
    "text": "inside the container at /opt / ml / input / config slash hyper parameters -",
    "start": "2484109",
    "end": "2492540"
  },
  {
    "text": "chaser okay so those hyper parameters here right they end up being written by",
    "start": "2492540",
    "end": "2501540"
  },
  {
    "start": "2498000",
    "end": "2538000"
  },
  {
    "text": "sage maker into a JSON file inside the container right simple enough so of",
    "start": "2501540",
    "end": "2508260"
  },
  {
    "text": "course I need to read those hyper parameters and apply them to my code",
    "start": "2508260",
    "end": "2513740"
  },
  {
    "text": "okay so that's that's pretty much it for",
    "start": "2513740",
    "end": "2521040"
  },
  {
    "text": "hyperparameters the location of the data will be also passed in",
    "start": "2521040",
    "end": "2528210"
  },
  {
    "text": "in in there okay so no worries so of",
    "start": "2528210",
    "end": "2534540"
  },
  {
    "text": "course I had to change this because I couldn't if you look at that initial",
    "start": "2534540",
    "end": "2541530"
  },
  {
    "start": "2538000",
    "end": "2588000"
  },
  {
    "text": "script okay I use this utility function in Cara's to load them list right in a",
    "start": "2541530",
    "end": "2548070"
  },
  {
    "text": "very lazy and friendly way so that was great of course here I want to really really",
    "start": "2548070",
    "end": "2553800"
  },
  {
    "text": "do it in the sage maker way so I'm loading the files from s3 okay yes I",
    "start": "2553800",
    "end": "2559349"
  },
  {
    "text": "could have been lazy again and used that API but I would have done loaded the dataset from an Internet and and that's",
    "start": "2559349",
    "end": "2566130"
  },
  {
    "text": "not really what I want to do what I want to do is pretend this is a real life",
    "start": "2566130",
    "end": "2571530"
  },
  {
    "text": "data set and load it from s3 okay so I just took that loading function and",
    "start": "2571530",
    "end": "2577580"
  },
  {
    "text": "hacked it to to load to load from from",
    "start": "2577580",
    "end": "2584160"
  },
  {
    "text": "the container right anyway and you wouldn't have to do this with a with a",
    "start": "2584160",
    "end": "2589530"
  },
  {
    "start": "2588000",
    "end": "2628000"
  },
  {
    "text": "real data set it's just because I needed to be placed at utility function okay so",
    "start": "2589530",
    "end": "2594780"
  },
  {
    "text": "I let's go let's let's move on to the to the main code so as we just said we need",
    "start": "2594780",
    "end": "2602490"
  },
  {
    "text": "to load the hyper parameters so it's pretty easy I just need to open that",
    "start": "2602490",
    "end": "2607859"
  },
  {
    "text": "file /opt slash blah blah blah blah right and read the learning rate the",
    "start": "2607859",
    "end": "2614460"
  },
  {
    "text": "batch size the epics and the GPU count and I provide default values just in",
    "start": "2614460",
    "end": "2621089"
  },
  {
    "text": "case I forgot to cut something to my script okay I can read the input data",
    "start": "2621089",
    "end": "2628560"
  },
  {
    "start": "2628000",
    "end": "2673000"
  },
  {
    "text": "config actually I'm not using it here with this basic example but if you",
    "start": "2628560",
    "end": "2635099"
  },
  {
    "text": "wanted to here the data set is really small so it's going to be replicated to all instances that trained on it so I'm",
    "start": "2635099",
    "end": "2643080"
  },
  {
    "text": "just using one instance anyway but if I want you to do distributed training here it would be be replicated if you have a",
    "start": "2643080",
    "end": "2651240"
  },
  {
    "text": "larger dataset you probably don't want to do this and stage wrecker will let you shard the data",
    "start": "2651240",
    "end": "2658420"
  },
  {
    "text": "across instances using a certain key etc and this is what you would get that",
    "start": "2658420",
    "end": "2663430"
  },
  {
    "text": "input data config parameters okay but okay I don't want to dive too deep on",
    "start": "2663430",
    "end": "2668500"
  },
  {
    "text": "say a drink over here all right and now that we have our hyper parameters as you",
    "start": "2668500",
    "end": "2674349"
  },
  {
    "text": "can see everything else here right is exactly the same and this is that",
    "start": "2674349",
    "end": "2682930"
  },
  {
    "text": "channel or a thing again that we saw previously so just reading from the config file",
    "start": "2682930",
    "end": "2689319"
  },
  {
    "text": "basically if I'm using a max net I need to have channels first so I need to",
    "start": "2689319",
    "end": "2694569"
  },
  {
    "text": "reshape my data if I have tensorflow I can I need two other channels at the end",
    "start": "2694569",
    "end": "2701410"
  },
  {
    "text": "and so I need to make sure they there that's where they are okay",
    "start": "2701410",
    "end": "2706500"
  },
  {
    "text": "normalizing converting building the model all that stuff is identical and",
    "start": "2706529",
    "end": "2711910"
  },
  {
    "text": "which is great because it means the bulk of your Kerris code will not have to",
    "start": "2711910",
    "end": "2717700"
  },
  {
    "text": "change when you when you port it when you adapt it for Sage maker you will",
    "start": "2717700",
    "end": "2723400"
  },
  {
    "text": "just have to adapt interface but the actual Chara's code itself stays the same the one cool thing here is this",
    "start": "2723400",
    "end": "2734200"
  },
  {
    "start": "2728000",
    "end": "2778000"
  },
  {
    "text": "version of cara's supports MX that as a back-end and as I've said before MX then",
    "start": "2734200",
    "end": "2739839"
  },
  {
    "text": "it makes it very easy to use multiple GPUs to train okay with other libraries",
    "start": "2739839",
    "end": "2745089"
  },
  {
    "text": "you may have to do this manually split the data across GPUs but nothing like",
    "start": "2745089",
    "end": "2750759"
  },
  {
    "text": "this with MX net so in this version of cara's there's an extra MX that specific",
    "start": "2750759",
    "end": "2756700"
  },
  {
    "text": "API called multi-gpu model that lets you say hey you know what the model that we",
    "start": "2756700",
    "end": "2762130"
  },
  {
    "text": "just created here let's just run it on multiple GPUs okay and this is one of",
    "start": "2762130",
    "end": "2768369"
  },
  {
    "text": "the hyper parameters that I passed okay and that's all it takes to distribute the training job over multiple GPUs in",
    "start": "2768369",
    "end": "2775150"
  },
  {
    "text": "the same instance okay the rest is the same okay and then once I'm done",
    "start": "2775150",
    "end": "2782529"
  },
  {
    "start": "2778000",
    "end": "2883000"
  },
  {
    "text": "training of course I want to save the model because maybe I want to grab it from s3 and it's a boy",
    "start": "2782529",
    "end": "2790470"
  },
  {
    "text": "she non-tested or where you guys want to do with it or I could go on and deploy",
    "start": "2790470",
    "end": "2796590"
  },
  {
    "text": "it on sage maker deployed to Sage make you manage infrastructure okay so I need",
    "start": "2796590",
    "end": "2801840"
  },
  {
    "text": "to make sure it's saved in s3 in the path that has been defined up there and again since I'm using MX that I can",
    "start": "2801840",
    "end": "2809550"
  },
  {
    "text": "actually save a Karass model in a THD five format so that's done the native",
    "start": "2809550",
    "end": "2815609"
  },
  {
    "text": "Kerris format but as I used MX that as a back-end I can also save this as an MX",
    "start": "2815609",
    "end": "2821369"
  },
  {
    "text": "10 model so now I will have the opportunity either to use the correct model in Kharis or I could use MX that",
    "start": "2821369",
    "end": "2829349"
  },
  {
    "text": "model in MX them even though I trained it with carrots I could now take it and predict with MX net only not using",
    "start": "2829349",
    "end": "2837000"
  },
  {
    "text": "carrots and probably getting even better performance so like I said you get the",
    "start": "2837000",
    "end": "2842190"
  },
  {
    "text": "best of both worlds you get the easy flexible API in Cara's but you can still grab an MX that model at the end and and",
    "start": "2842190",
    "end": "2849660"
  },
  {
    "text": "predict maybe with the native C++ API dynamic set to get the fastest",
    "start": "2849660",
    "end": "2855890"
  },
  {
    "text": "prediction possible not going through the Python layers of jairus okay and and",
    "start": "2855890",
    "end": "2862200"
  },
  {
    "text": "that's it okay so again just modifying that script for the input which pretty",
    "start": "2862200",
    "end": "2870480"
  },
  {
    "text": "much means hyper parameters and data configuration and modifying the script",
    "start": "2870480",
    "end": "2875580"
  },
  {
    "text": "for output just saving the models so let's go back to our training instance",
    "start": "2875580",
    "end": "2884700"
  },
  {
    "text": "here so what do we see now we see okay we were using MX 10 that's good news",
    "start": "2884700",
    "end": "2891109"
  },
  {
    "text": "these are the I for parameters that have been passed okay which match the ones",
    "start": "2891109",
    "end": "2897540"
  },
  {
    "text": "that have been passed here some good use the input parameters that's the input",
    "start": "2897540",
    "end": "2903210"
  },
  {
    "text": "data config I mentioned earlier so I said data is fully replicated so sage",
    "start": "2903210",
    "end": "2909869"
  },
  {
    "text": "maker grabs the full dataset copies into each of the training instances that",
    "start": "2909869",
    "end": "2915390"
  },
  {
    "text": "doesn't matter here because it's a single instance and it's more than I said anyway if you had a hundred terabytes of data you wouldn't",
    "start": "2915390",
    "end": "2921370"
  },
  {
    "text": "want to do that you would want you to distributed training and sharp the data across different instances then you'll",
    "start": "2921370",
    "end": "2927850"
  },
  {
    "text": "see how to do this in the stage maker talk okay I see the shade and then I see",
    "start": "2927850",
    "end": "2934930"
  },
  {
    "text": "my training log right and well there's a",
    "start": "2934930",
    "end": "2941010"
  },
  {
    "text": "lot of surprise here right the first epic takes 12 seconds and well the last",
    "start": "2941010",
    "end": "2948460"
  },
  {
    "text": "one takes two right so there's a bit of each initialization happening here but",
    "start": "2948460",
    "end": "2954100"
  },
  {
    "text": "pretty much all the other air box take two seconds okay so you see the boost",
    "start": "2954100",
    "end": "2960190"
  },
  {
    "text": "that we get on that on that previous training I was training on I was",
    "start": "2960190",
    "end": "2965410"
  },
  {
    "text": "training on a p2 instance right so 1 G 1",
    "start": "2965410",
    "end": "2971230"
  },
  {
    "text": "p2 GPU it's the k80 from Nvidia previous generation and it took 12 or 15 seconds",
    "start": "2971230",
    "end": "2978610"
  },
  {
    "text": "whatever it was with that without GPU let's yeah 11 seconds and now if I use",
    "start": "2978610",
    "end": "2987340"
  },
  {
    "text": "two of those newer GPUs the p3 family and these are the v-102 the latest GPU",
    "start": "2987340",
    "end": "2994450"
  },
  {
    "text": "chips then it takes two seconds training is six times faster even on a very small",
    "start": "2994450",
    "end": "3000240"
  },
  {
    "text": "data set like this so imagine what you can get with a real life data set the p3",
    "start": "3000240",
    "end": "3006480"
  },
  {
    "text": "family is blazingly fast okay and we get to the end of our training we get",
    "start": "3006480",
    "end": "3012720"
  },
  {
    "start": "3008000",
    "end": "3033000"
  },
  {
    "text": "accuracy of 99 point 15 which is a little better than before I'm not sure",
    "start": "3012720",
    "end": "3017910"
  },
  {
    "text": "why but I'll take that and we save our models to /opt slash blah blah blah",
    "start": "3017910",
    "end": "3025680"
  },
  {
    "text": "okay whatever locations are say to make ariza is expecting the models to be saved up okay we took about two minutes",
    "start": "3025680",
    "end": "3034350"
  },
  {
    "text": "to run all of this and then of course sage maker will grab the models here the",
    "start": "3034350",
    "end": "3041400"
  },
  {
    "text": "content of that file of that directory is is a transform",
    "start": "3041400",
    "end": "3048230"
  },
  {
    "text": "gzip tar file and that's copy to history okay so if we if we take a look in the",
    "start": "3048230",
    "end": "3056420"
  },
  {
    "text": "s3 bucket we should see okay so that's",
    "start": "3056420",
    "end": "3064480"
  },
  {
    "text": "yeah looks like that time okay",
    "start": "3064480",
    "end": "3071150"
  },
  {
    "text": "yep July 1912 23 that's that's about right",
    "start": "3071150",
    "end": "3076460"
  },
  {
    "text": "I can I can grab this",
    "start": "3076460",
    "end": "3080200"
  },
  {
    "text": "okay and I should be able to look at it",
    "start": "3088900",
    "end": "3095710"
  },
  {
    "text": "yeah that looks correct all right and",
    "start": "3111690",
    "end": "3116970"
  },
  {
    "text": "this is what we expect okay we see the HD 5 model in the chaos format so again",
    "start": "3116970",
    "end": "3126210"
  },
  {
    "text": "now on my local machine I could load this and work with it and I see my MX",
    "start": "3126210",
    "end": "3131970"
  },
  {
    "text": "that model and MX that models come in two files the the parameters right and",
    "start": "3131970",
    "end": "3140010"
  },
  {
    "text": "let's let's extract this the parameters and this is a this is a binary file",
    "start": "3140010",
    "end": "3147109"
  },
  {
    "text": "storing the weights okay that we learned during training and of course we have a",
    "start": "3147109",
    "end": "3153839"
  },
  {
    "text": "JSON file which stores the definition of",
    "start": "3153839",
    "end": "3160670"
  },
  {
    "text": "ok so we see exactly the model that we created the convolutional layers the 32",
    "start": "3160670",
    "end": "3167549"
  },
  {
    "text": "filters in the first layer cetera et cetera ok so no no big surprise and",
    "start": "3167549",
    "end": "3174770"
  },
  {
    "text": "again we could use that JSON file to load the model from the parameters and",
    "start": "3174770",
    "end": "3180900"
  },
  {
    "text": "and work with it it makes that okay so",
    "start": "3180900",
    "end": "3186059"
  },
  {
    "text": "we went all the way there so what we'll",
    "start": "3186059",
    "end": "3194579"
  },
  {
    "start": "3188000",
    "end": "3233000"
  },
  {
    "text": "take a look at questions in a minute but in the nutshell this is how you would",
    "start": "3194579",
    "end": "3201660"
  },
  {
    "text": "use care us on stage maker ok and as you can see it is as easy as adding a few",
    "start": "3201660",
    "end": "3209069"
  },
  {
    "text": "lines of code to read I per parameters few lines of code to save your model in",
    "start": "3209069",
    "end": "3215789"
  },
  {
    "text": "the right place put everything in a custom container CPU base GPU based and",
    "start": "3215789",
    "end": "3222140"
  },
  {
    "text": "again don't let docker scary if you don't know docker run the tutorial on",
    "start": "3222140",
    "end": "3228059"
  },
  {
    "text": "docker calm and you will know more than enough to to write those files I showed",
    "start": "3228059",
    "end": "3234839"
  },
  {
    "start": "3233000",
    "end": "3600000"
  },
  {
    "text": "you how to use a different back-end for Kara so it's very easy to use",
    "start": "3234839",
    "end": "3240050"
  },
  {
    "text": "to run faster than all the libraries and and brings you a multi GPU support in",
    "start": "3240050",
    "end": "3246440"
  },
  {
    "text": "chaos they're easily as well and and in",
    "start": "3246440",
    "end": "3251630"
  },
  {
    "text": "yeah I guess that's it that's what we that's what we saw that's what we saw today and you could reuse the same",
    "start": "3251630",
    "end": "3258080"
  },
  {
    "text": "technique to run everything else actually I wrote a similar example for",
    "start": "3258080",
    "end": "3264320"
  },
  {
    "text": "pi torch but whatever library you use and even if it's not a Python library",
    "start": "3264320",
    "end": "3269930"
  },
  {
    "text": "C++ or it could be your own custom code this exact same technique building a",
    "start": "3269930",
    "end": "3276350"
  },
  {
    "text": "container reading parameters etc would work the same so you can use this as a",
    "start": "3276350",
    "end": "3281960"
  },
  {
    "text": "hopefully as a blueprint to customize your own your own examples so before we",
    "start": "3281960",
    "end": "3288350"
  },
  {
    "text": "look at questions I want to point out a few resources that you might find useful",
    "start": "3288350",
    "end": "3295190"
  },
  {
    "text": "so if you're curious about sage maker of course you should go and read about it on the",
    "start": "3295190",
    "end": "3301040"
  },
  {
    "text": "web you'll find documentation and plenty of good stuff in there and we are",
    "start": "3301040",
    "end": "3306380"
  },
  {
    "text": "announced a whole whole bunch of you are sage make your features at the New York",
    "start": "3306380",
    "end": "3312200"
  },
  {
    "text": "summit just days ago batch prediction and some you are built in our goals so",
    "start": "3312200",
    "end": "3317420"
  },
  {
    "text": "it keeps moving pretty fast so you might need to read the dot for that say the",
    "start": "3317420",
    "end": "3323920"
  },
  {
    "text": "github repo for the stage maker examples is a great collection of notebooks that",
    "start": "3323920",
    "end": "3330230"
  },
  {
    "text": "show you how to use the built-in algos how to use tensorflow and magpie",
    "start": "3330230",
    "end": "3336050"
  },
  {
    "text": "torchic's tetra on sage maker this keeps growing as well so if you haven't checked it out lately",
    "start": "3336050",
    "end": "3342440"
  },
  {
    "text": "should there surely there will be new examples here the sage maker sdk is on",
    "start": "3342440",
    "end": "3348619"
  },
  {
    "text": "github as well so the one that you use to create the training jobs prediction shelter cetera he you spark there's a",
    "start": "3348619",
    "end": "3355970"
  },
  {
    "text": "spark sdk as well so you can fire up training jobs or prediction jobs in sage",
    "start": "3355970",
    "end": "3363290"
  },
  {
    "text": "maker from spark from your EMR cluster or your spark cost or you run on trends",
    "start": "3363290",
    "end": "3368810"
  },
  {
    "text": "okay so that's that's really good it's really an interesting topic that",
    "start": "3368810",
    "end": "3373819"
  },
  {
    "text": "would be worthy of another session how to mix sport and sage maker",
    "start": "3373819",
    "end": "3379359"
  },
  {
    "text": "and if you are if you want to stay in touch well I'd be more than happy to share",
    "start": "3379359",
    "end": "3385609"
  },
  {
    "text": "content with your Twitter and again if you have cool projects involving sage maker Chara's and whatnot feel free to",
    "start": "3385609",
    "end": "3393500"
  },
  {
    "text": "ping me on Twitter I'm more than happy to retweet and share all your good stuff my blog of medium and actually this",
    "start": "3393500",
    "end": "3402099"
  },
  {
    "text": "example that we saw today comes from one of my blog posts and yeah like I said",
    "start": "3402099",
    "end": "3408349"
  },
  {
    "text": "there's there's another one for a four point torch as well okay so keep an eye",
    "start": "3408349",
    "end": "3413510"
  },
  {
    "text": "out for more blog post as soon as I some time to write them and I've got also a",
    "start": "3413510",
    "end": "3421420"
  },
  {
    "text": "growing collection of videos on YouTube from AWS summits and and third-party",
    "start": "3421420",
    "end": "3427190"
  },
  {
    "text": "conferences etc and if you're specifically interested in the theory of",
    "start": "3427190",
    "end": "3432500"
  },
  {
    "text": "deep pruning there's a there's a session there it's in the dev days playlist",
    "start": "3432500",
    "end": "3437890"
  },
  {
    "text": "where you you'll learn about a fully connected Network Santa and convolution",
    "start": "3437890",
    "end": "3444770"
  },
  {
    "text": "networks and I go a little deeper quite deeper into the theory well plenty of",
    "start": "3444770",
    "end": "3450650"
  },
  {
    "text": "good videos to learn about sales etc and the code that I use today is on my blog",
    "start": "3450650",
    "end": "3457010"
  },
  {
    "text": "we PO D our notebooks and you'll find notebooks for a sage maker and spark and",
    "start": "3457010",
    "end": "3463180"
  },
  {
    "text": "care awesome again more stuff coming as soon as I have time to to write it so",
    "start": "3463180",
    "end": "3469640"
  },
  {
    "text": "there you go plenty of stuff to read let's let's take",
    "start": "3469640",
    "end": "3475069"
  },
  {
    "text": "a look we have a few more minutes",
    "start": "3475069",
    "end": "3478779"
  },
  {
    "text": "let's see",
    "start": "3481300",
    "end": "3484560"
  },
  {
    "text": "let's see if we have questions okay",
    "start": "3486970",
    "end": "3499690"
  },
  {
    "text": "let's grab so I'll grab the last few questions okay but feel free to ask your questions again if you're up the list so",
    "start": "3499690",
    "end": "3507420"
  },
  {
    "text": "you don't know you don't need to change the cast code for for CPU and GPU",
    "start": "3507420",
    "end": "3514900"
  },
  {
    "text": "basically that's why I passed this hyper parameter the GPU count parameter if I",
    "start": "3514900",
    "end": "3525160"
  },
  {
    "text": "wanted to train on CPU I would just say zero right I would say zero GPUs need to be used and then that that multi-gpu",
    "start": "3525160",
    "end": "3534010"
  },
  {
    "text": "model function that I used here right",
    "start": "3534010",
    "end": "3542200"
  },
  {
    "text": "would not be used okay so that's it's a bit of a hack but I like it so this",
    "start": "3542200",
    "end": "3549880"
  },
  {
    "text": "gives me the same script for CPU and GPU and thanks to that GPU count hyper",
    "start": "3549880",
    "end": "3556930"
  },
  {
    "text": "parameter okay but yeah the rest of the code is exactly the same which which is",
    "start": "3556930",
    "end": "3562240"
  },
  {
    "text": "very convenient I think so next question any timeline on when the cars containers",
    "start": "3562240",
    "end": "3568089"
  },
  {
    "text": "will be provided out of the box I don't know is the honest answer so in the",
    "start": "3568089",
    "end": "3576010"
  },
  {
    "text": "chaos if sorry in the tensorflow container oh this gets",
    "start": "3576010",
    "end": "3583210"
  },
  {
    "text": "weaker Cena in the in the tensorflow container you you can use the TF dot",
    "start": "3583210",
    "end": "3591790"
  },
  {
    "text": "Kara's layers okay so it's not quite the same as using cars directly but with in",
    "start": "3591790",
    "end": "3598510"
  },
  {
    "text": "terms of flow you could use the Kara's layers to build a model and then use the",
    "start": "3598510",
    "end": "3603880"
  },
  {
    "text": "the rest of the chaos the rest of the tensorflow api's so that's possible now with the built-in the built-in container",
    "start": "3603880",
    "end": "3610780"
  },
  {
    "text": "but if you want to use Kara's only and not tensorflow you have to build a custom container okay so I guess it's",
    "start": "3610780",
    "end": "3617680"
  },
  {
    "text": "gonna come but for now you have to use my way okay",
    "start": "3617680",
    "end": "3626280"
  },
  {
    "text": "next question what are the differences of running the containers in the Fargate versus sage maker",
    "start": "3626280",
    "end": "3631410"
  },
  {
    "text": "so what sage maker really brings is the is that the the scaling right it's it's",
    "start": "3631410",
    "end": "3640079"
  },
  {
    "text": "gonna especially when you do distributed training it and distributed training",
    "start": "3640079",
    "end": "3645390"
  },
  {
    "text": "with Karis is not easy to achieve but if you use that's a MX net or tensorflow and you use those those built in",
    "start": "3645390",
    "end": "3653970"
  },
  {
    "text": "containers then sage maker takes care of everything automatically so you just",
    "start": "3653970",
    "end": "3659790"
  },
  {
    "text": "literally use an object in the sage maker SDK called tensorflow or MX net the script that you pass is a",
    "start": "3659790",
    "end": "3666900"
  },
  {
    "text": "the your scrip becomes a parameter that you pass to this object and it takes care of everything automatically so you",
    "start": "3666900",
    "end": "3673230"
  },
  {
    "text": "don't have to set up anything so if you enjoy setting up distributed training in",
    "start": "3673230",
    "end": "3679079"
  },
  {
    "text": "terms of low overheads that yourself yeah sure you could run on you could run",
    "start": "3679079",
    "end": "3684210"
  },
  {
    "text": "on the Fargate on PCs if you want it but you know again I'm lazy and I find that",
    "start": "3684210",
    "end": "3691109"
  },
  {
    "text": "the sage Maker SDK and the sage maker manage infrastructure make it much easier and and I can I can just run",
    "start": "3691109",
    "end": "3698460"
  },
  {
    "text": "anything that I want on depend on any scale and I never have to set up anything when it comes to infrastructure",
    "start": "3698460",
    "end": "3707270"
  },
  {
    "text": "all right",
    "start": "3711500",
    "end": "3714580"
  },
  {
    "text": "okay so yeah there are questions about the",
    "start": "3721590",
    "end": "3728380"
  },
  {
    "text": "but the cost so the cost of sage maker is the cost of the notebook instance",
    "start": "3728380",
    "end": "3736839"
  },
  {
    "text": "issue if you use one you don't have to you could use the sage maker SDK directly from your laptop and that works",
    "start": "3736839",
    "end": "3744339"
  },
  {
    "text": "as well of course so the notebook instance it's like ec2 you pay you know per second depending on",
    "start": "3744339",
    "end": "3750700"
  },
  {
    "text": "the type after notebook instance that you use then of course you pay for the training time per second and again",
    "start": "3750700",
    "end": "3757450"
  },
  {
    "text": "depending on the instance type that you use but the really cool thing here is that sage maker starts and stops and",
    "start": "3757450",
    "end": "3763270"
  },
  {
    "text": "starts and terminates those instances automatically so you will never overpay",
    "start": "3763270",
    "end": "3768310"
  },
  {
    "text": "for training which which is a typical problem that a lot of customers have they create infrastructure for training",
    "start": "3768310",
    "end": "3774220"
  },
  {
    "text": "and they leave it on whenever even if they don't need it right and and that's",
    "start": "3774220",
    "end": "3780250"
  },
  {
    "text": "that's a shame because you're paying for sis for machines that you don't really use so here that's never gonna happen",
    "start": "3780250",
    "end": "3786339"
  },
  {
    "text": "because sage makeup terminates the the training instance is automatically and then when you deploy to instances again",
    "start": "3786339",
    "end": "3793530"
  },
  {
    "text": "you pay per per second per instance type so this is mostly what say how you get",
    "start": "3793530",
    "end": "3801280"
  },
  {
    "text": "charged for sage maker so so demo like this you know it's literally gonna cost",
    "start": "3801280",
    "end": "3806589"
  },
  {
    "text": "me two minutes of p-38 Excel which you know which is I guess at that instance",
    "start": "3806589",
    "end": "3813160"
  },
  {
    "text": "is probably a few dollars per hour so you know I can't count so I'll let you count how much that cost but anyway this",
    "start": "3813160",
    "end": "3820000"
  },
  {
    "text": "is overkill for this kind of a dataset and you could you could get away with using c4 or very small instances for",
    "start": "3820000",
    "end": "3827830"
  },
  {
    "text": "that I'll refer you to the sage maker pricing page that's so that's where",
    "start": "3827830",
    "end": "3833109"
  },
  {
    "text": "you'll find all the information alright let me scroll back a little more",
    "start": "3833109",
    "end": "3844950"
  },
  {
    "text": "not sure how much time we have left so please feel free to shut me down when",
    "start": "3844950",
    "end": "3850480"
  },
  {
    "text": "you need to",
    "start": "3850480",
    "end": "3852840"
  },
  {
    "text": "all right yeah so there's a question here that's that something that I didn't cover today",
    "start": "3863490",
    "end": "3870660"
  },
  {
    "text": "because we have to stop at some point but I showed you how to train now the",
    "start": "3870660",
    "end": "3876990"
  },
  {
    "text": "next step but post possibly on sage maker would be deploying of course okay so you'll find some examples again in",
    "start": "3876990",
    "end": "3885780"
  },
  {
    "text": "the sample notebooks in the sage maker collection there are you could build a",
    "start": "3885780",
    "end": "3891060"
  },
  {
    "text": "custom container to serve those predictions it would be quite similar or",
    "start": "3891060",
    "end": "3896910"
  },
  {
    "text": "the only thing that you need to do is have a simple web server set up inside",
    "start": "3896910",
    "end": "3902430"
  },
  {
    "text": "the container this is how the tensorflow and the UH next ed containers that we provide to each other nginx web starter",
    "start": "3902430",
    "end": "3909630"
  },
  {
    "text": "in there creating just a with a little bit of Python code just creating the endpoint I think it's a flask app",
    "start": "3909630",
    "end": "3916710"
  },
  {
    "text": "actually and just loading the model and serving predictions but that's just one way of doing it you could look these",
    "start": "3916710",
    "end": "3922950"
  },
  {
    "text": "containers are open source anywhere the chance of flow and DMX that container and so on our are open source so you",
    "start": "3922950",
    "end": "3928710"
  },
  {
    "text": "could look at that and we use that if you want it or you can do it any other way some some people will have the same",
    "start": "3928710",
    "end": "3934950"
  },
  {
    "text": "container to train and predict why not you just need to account for the fact",
    "start": "3934950",
    "end": "3942960"
  },
  {
    "text": "that in some cases stage maker will call them for training and we'll call them for predicting so he used the same",
    "start": "3942960",
    "end": "3948840"
  },
  {
    "text": "script for everything there's a mode that stage maker passes as well to let you know hey I'm training or predicting",
    "start": "3948840",
    "end": "3955380"
  },
  {
    "text": "the look at the tensorflow examples in say in the second notebook will show you how to do that or you could have",
    "start": "3955380",
    "end": "3962190"
  },
  {
    "text": "different scripts to train and predict but pretty much what it means is loading the model that you train loading it from",
    "start": "3962190",
    "end": "3968820"
  },
  {
    "text": "history and and and serving predictions using your favorite library interface",
    "start": "3968820",
    "end": "3976980"
  },
  {
    "text": "with a simple web okay so not a lot of difficulty again please look at the",
    "start": "3976980",
    "end": "3982859"
  },
  {
    "text": "stage maker examples on github and you'll find that you'll find out okay",
    "start": "3982859",
    "end": "3988940"
  },
  {
    "text": "all right it's time so thank you very much for listening I hope this was I hope this was useful I was a definitely",
    "start": "3989600",
    "end": "3997880"
  },
  {
    "text": "fun for me to do it and if you have questions later on if you again if you",
    "start": "3997880",
    "end": "4003070"
  },
  {
    "text": "need to get in touch I guess the easiest way is just to ping me on Twitter and ask me your questions share your project",
    "start": "4003070",
    "end": "4009790"
  },
  {
    "text": "and go and build cool stuff alright thank you very much to the colleagues that helped me set this up moderating",
    "start": "4009790",
    "end": "4017050"
  },
  {
    "text": "and organizing everything great work guys and thank you very much for listening so I hope to talk to you soon",
    "start": "4017050",
    "end": "4023170"
  },
  {
    "text": "right see you on the road probably bye",
    "start": "4023170",
    "end": "4027180"
  }
]
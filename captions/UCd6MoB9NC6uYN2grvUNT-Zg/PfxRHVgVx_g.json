[
  {
    "start": "0",
    "end": "248000"
  },
  {
    "text": "[Music] hello and welcome back",
    "start": "360",
    "end": "7120"
  },
  {
    "text": "we're here with episode four of aws what's next you're joined i'm joined by my host rob",
    "start": "7120",
    "end": "13440"
  },
  {
    "text": "zoo and my name is nick walsh with two developer advocates here at amazon web services we've got next twitch yeah hello twitch",
    "start": "13440",
    "end": "20480"
  },
  {
    "text": "linkedin we're streaming live to quite a few platforms here um again let's emphasize this is a live show so if you have at any point in the",
    "start": "20480",
    "end": "26640"
  },
  {
    "text": "broadcast any comments questions um for our service team members or for rob and i please get those in and chat",
    "start": "26640",
    "end": "33120"
  },
  {
    "text": "um but rob i mentioned we're here episode four of what's next we clearly haven't been canceled yet we must be doing something right",
    "start": "33120",
    "end": "38800"
  },
  {
    "text": "uh for anyone who's tuning in for the first time can you tell me a little bit about what we do here on this show yeah absolutely so we have a lot of",
    "start": "38800",
    "end": "45760"
  },
  {
    "text": "service features launching all the time across aws it's kind of hard to keep track of it all um we have a couple resources to help",
    "start": "45760",
    "end": "52079"
  },
  {
    "text": "you out one of them is our news blog and there you can follow along and see a list of detailed launches and the corresponding articles",
    "start": "52079",
    "end": "58079"
  },
  {
    "text": "we also like to pick out a couple of those and dive deep and when we do that we can also invite members from the service teams that",
    "start": "58079",
    "end": "64158"
  },
  {
    "text": "built these services to kind of have an in-depth conversation give us a demo and tell us about the service from",
    "start": "64159",
    "end": "69439"
  },
  {
    "text": "their perspective yeah and we know that some of these launches make their way sort of to the forefront",
    "start": "69439",
    "end": "74880"
  },
  {
    "text": "in the form of talks at some of our major summits that reinvent uh but we also know that a lot of these",
    "start": "74880",
    "end": "79920"
  },
  {
    "text": "demos a lot of these really powerful functionalities are available out of the gate here and and so with this show we wanted to",
    "start": "79920",
    "end": "84960"
  },
  {
    "text": "be able to find a way to sort of provide a platform for all of the aws users at home to actually get a sense of what it means to",
    "start": "84960",
    "end": "91439"
  },
  {
    "text": "actually use some of these features and not have to wait around for the next nearest summit or hands-on demo to be to be produced",
    "start": "91439",
    "end": "98000"
  },
  {
    "text": "because a lot of those already exist um so again we've got an action-packed lineup today i mentioned it before",
    "start": "98000",
    "end": "103280"
  },
  {
    "text": "i won't keep you all waiting in suspense we have four separate demos that we're doing today trying out a bit of a different",
    "start": "103280",
    "end": "109520"
  },
  {
    "text": "format uh we're going to have graviton 2 and the new m6g ec2 instances",
    "start": "109520",
    "end": "115439"
  },
  {
    "text": "then we will be joined to see a little bit about the latest launch from aws glue for streaming etl",
    "start": "115439",
    "end": "120640"
  },
  {
    "text": "then we have the ga launch of amazon a2i amazon augmented ai something i'm really excited about",
    "start": "120640",
    "end": "126399"
  },
  {
    "text": "and then lastly another one that i know lots of folks have been waiting for is the launch of amazon kendra enterprise grade search um so four very",
    "start": "126399",
    "end": "134239"
  },
  {
    "text": "very exciting demos again joining us are going to be each of the respective service teams um rob which one are you looking most",
    "start": "134239",
    "end": "140720"
  },
  {
    "text": "forward to oh those are all so exciting it's very hard for me to pick um you know as somebody who uh built",
    "start": "140720",
    "end": "147520"
  },
  {
    "text": "their own pc for uh you know for many years uh i'm kind of a hardware geek so i really like",
    "start": "147520",
    "end": "152959"
  },
  {
    "text": "the um the graviton 2 deep dive i'm really looking forward to that um an awesome guest for that segment but um",
    "start": "152959",
    "end": "160160"
  },
  {
    "text": "i'm also very excited about kendra i think this is um you know i i've",
    "start": "160160",
    "end": "165360"
  },
  {
    "text": "spent my fair share of time uh fruitlessly searching for answers on various corporate you know",
    "start": "165360",
    "end": "171519"
  },
  {
    "text": "search portals and uh i think kendra can really um make that better for everyone",
    "start": "171519",
    "end": "177840"
  },
  {
    "text": "so i'm really looking forward to that as well uh kind of a cop-out answer i have two favorites today i mean four four demos in one episode we",
    "start": "177840",
    "end": "184560"
  },
  {
    "text": "haven't done this before episode four four demos does that mean episode five five demos oh god this is gonna be a",
    "start": "184560",
    "end": "190000"
  },
  {
    "text": "slippery slope here rob i mean episode one had one demo so i'm sensing a trend here even if it's not deliberate",
    "start": "190000",
    "end": "195200"
  },
  {
    "text": "um again beginning of a trend and we're just going to be approaching 24 hour streams before we know it there's just",
    "start": "195200",
    "end": "201120"
  },
  {
    "text": "going to be we're just going to be hooked up here in front of the webcam all day as the the real time live feed of launches",
    "start": "201120",
    "end": "208400"
  },
  {
    "text": "yeah other weeks rob you and i have sort of gone through some of our exciting launches but again the one of the unique parts about the",
    "start": "208400",
    "end": "214000"
  },
  {
    "text": "show we get to dive deep we get to see demos we get to um sort of platform the these service teams that make these amazing features",
    "start": "214000",
    "end": "220239"
  },
  {
    "text": "so we won't waste any more of your time again thank you for joining us uh first up as i mentioned before we're",
    "start": "220239",
    "end": "226319"
  },
  {
    "text": "going to be talking to the graviton 2 team uh as a members from the graviton 2",
    "start": "226319",
    "end": "231920"
  },
  {
    "text": "team that were launching the new m6g instance classes so stick around we're going to be right back with the first guest uh so",
    "start": "231920",
    "end": "239519"
  },
  {
    "text": "don't leave we'll be right back [Music]",
    "start": "239519",
    "end": "248799"
  },
  {
    "text": "all right i promised we'd be back very quickly and here we are i don't know how many seconds it was but it was less than 30.",
    "start": "248799",
    "end": "254080"
  },
  {
    "text": "so for all you counted at home plus one for us okay cool so i mentioned first we're talking about graviton 2 and the new m6g",
    "start": "254080",
    "end": "260720"
  },
  {
    "text": "ec2 instance classes here to tell us a little bit more about that is sudhir rahman principal product manager for ec2 sodium here thank you",
    "start": "260720",
    "end": "267199"
  },
  {
    "text": "for joining us today hi thank you for having me okay so obviously a very very exciting launch",
    "start": "267199",
    "end": "273680"
  },
  {
    "text": "i know we have a very large number of ec2 instances instance types it can be sometimes",
    "start": "273680",
    "end": "279520"
  },
  {
    "text": "confusing to wrap our head around all of them but let's start a little bit with graviton 2 which is what's going to be",
    "start": "279520",
    "end": "284560"
  },
  {
    "text": "making these new instances very very um unique so to say um can you tell us a little bit about at",
    "start": "284560",
    "end": "290639"
  },
  {
    "text": "a high glance what we're launching today with graviton too sure yeah so um we are actually",
    "start": "290639",
    "end": "296160"
  },
  {
    "start": "293000",
    "end": "353000"
  },
  {
    "text": "launching our next generation ec2 general purpose instance so across",
    "start": "296160",
    "end": "301840"
  },
  {
    "text": "our ec2 portfolio we have a large number of instances to serve pretty much every single workload that our customers",
    "start": "301840",
    "end": "308160"
  },
  {
    "text": "run in the cloud and this particular focus today is on the general purpose instance family",
    "start": "308160",
    "end": "314000"
  },
  {
    "text": "and by that we mean essentially a broad spectrum of workloads like containerized micro services be it web",
    "start": "314000",
    "end": "320000"
  },
  {
    "text": "tier mid size databases caching fleets and things of that nature and we are specifically launching",
    "start": "320000",
    "end": "326800"
  },
  {
    "text": "talking about the m6g instance which is our next generation general purpose instance",
    "start": "326800",
    "end": "332240"
  },
  {
    "text": "powered by the aws graviton 2 processors and what these delivers do these",
    "start": "332240",
    "end": "338880"
  },
  {
    "text": "instances do for our customers is they can enable up to 40 price performance benefits",
    "start": "338880",
    "end": "344800"
  },
  {
    "text": "versus our previous generation m5 instance i mean and i understand that this is a",
    "start": "344800",
    "end": "351280"
  },
  {
    "text": "custom chip is that correct yes absolutely so this is an in-house aws designed um custom chip",
    "start": "351280",
    "end": "360160"
  },
  {
    "start": "353000",
    "end": "422000"
  },
  {
    "text": "that we've as aws partnered with annapurna labs a company that amazon acquired a few",
    "start": "360160",
    "end": "365280"
  },
  {
    "text": "years ago and this is a company that we've partnered with to deliver many custom",
    "start": "365280",
    "end": "371600"
  },
  {
    "text": "silicon initiatives some of those in the past have been the building blocks and the offload",
    "start": "371600",
    "end": "376800"
  },
  {
    "text": "cards as part of the aws nitrous system that essentially increases the overall",
    "start": "376800",
    "end": "381919"
  },
  {
    "text": "resource efficiency on an ec2 instance type and also the aws inferential chip that we released",
    "start": "381919",
    "end": "387759"
  },
  {
    "text": "back in 2019 so we've collaborated with that team we've now introduced our next generation graviton",
    "start": "387759",
    "end": "394400"
  },
  {
    "text": "2 processor uh built using 64-bit omniovers course",
    "start": "394400",
    "end": "399520"
  },
  {
    "text": "can we just take a second to actually appreciate that to the extent in which i think we should a custom chip",
    "start": "399520",
    "end": "406319"
  },
  {
    "text": "right like this is something that's pretty monumental um we obviously didn't make this decision lately",
    "start": "406319",
    "end": "411840"
  },
  {
    "text": "is there any particular set of reasons why we created our own chips i know obviously we created some unique value there but typically we",
    "start": "411840",
    "end": "417759"
  },
  {
    "text": "think of creating new things as a purpose-built solution to a problem can we walk through some of those",
    "start": "417759",
    "end": "422800"
  },
  {
    "start": "422000",
    "end": "527000"
  },
  {
    "text": "yeah absolutely i think that's that's a great question so um as part of our workload optimization",
    "start": "422800",
    "end": "428080"
  },
  {
    "text": "journey we've invested in many custom chip initiatives",
    "start": "428080",
    "end": "433199"
  },
  {
    "text": "so that we can build targeted optimizations for cloud native workloads also based on our extensive knowledge of",
    "start": "433199",
    "end": "440000"
  },
  {
    "text": "running cloud workflows at scale so in the past you know i touched on the nitro system",
    "start": "440000",
    "end": "445840"
  },
  {
    "text": "we built custom chips where essentially we build dedicated cards that can offload",
    "start": "445840",
    "end": "452400"
  },
  {
    "text": "some of our networking and elastic block store functionalities so that the host processor essentially",
    "start": "452400",
    "end": "458400"
  },
  {
    "text": "gets all the resources that we can deliver back to our customer as part of that journey we've continued",
    "start": "458400",
    "end": "464160"
  },
  {
    "text": "to innovate at various levels of our infrastructure and uh using our own cpus we are now",
    "start": "464160",
    "end": "470400"
  },
  {
    "text": "able to deliver essentially optimized cost and performance points for our instance types that essentially",
    "start": "470400",
    "end": "477120"
  },
  {
    "text": "translates into a significant price performance benefit for our customers and",
    "start": "477120",
    "end": "482240"
  },
  {
    "text": "one other major benefit here is that we're also able to build innovate and iterate",
    "start": "482240",
    "end": "487840"
  },
  {
    "text": "directly on behalf of our customers based on direct customer feedback and and finally with now bringing the",
    "start": "487840",
    "end": "494240"
  },
  {
    "text": "arm architecture into the cloud we're also able to expand the selection of compute choices and",
    "start": "494240",
    "end": "499280"
  },
  {
    "text": "architectures for our customers wonderful so deeper efficiencies from",
    "start": "499280",
    "end": "504720"
  },
  {
    "text": "deeper vertical integration in our own infrastructure always really exciting to see so going back",
    "start": "504720",
    "end": "510000"
  },
  {
    "text": "again you said that this new the new instance um the m6g is again uh general-purpose compute right and",
    "start": "510000",
    "end": "517039"
  },
  {
    "text": "there's lots of different types of ec2 instances i mentioned before what does the m instance class",
    "start": "517039",
    "end": "522080"
  },
  {
    "text": "uh sort of mean and what are other instance types that are available for folks that may not have looked into that",
    "start": "522080",
    "end": "528240"
  },
  {
    "start": "527000",
    "end": "622000"
  },
  {
    "text": "sure yeah so the m instance class is basically you know multi-purpose general purpose so this is sort of for your",
    "start": "528240",
    "end": "533279"
  },
  {
    "text": "broad set of you know the classic the web tiers and the micro services and the caching fleet kind of workloads that you can run",
    "start": "533279",
    "end": "539680"
  },
  {
    "text": "a majority of our customers you know count on these core m instance types for a large",
    "start": "539680",
    "end": "545360"
  },
  {
    "text": "proportion of their workloads and the other instance types that we have within our ec2 families we",
    "start": "545360",
    "end": "550640"
  },
  {
    "text": "essentially have these categorized by the workloads and the optimizations that we built for these instance types for",
    "start": "550640",
    "end": "557200"
  },
  {
    "text": "a specific category of workloads an example would be the compute optimized c instance type that is targeted for",
    "start": "557200",
    "end": "564560"
  },
  {
    "text": "workloads that are more sensitive to single threaded compute performance for example say a gaming server",
    "start": "564560",
    "end": "571279"
  },
  {
    "text": "or a high performance computing workload another class of instance we have is the memory optimized",
    "start": "571279",
    "end": "577040"
  },
  {
    "text": "r instance types that are targeted more at larger databases in memory workloads workloads that are",
    "start": "577040",
    "end": "583839"
  },
  {
    "text": "more sensitive to memory both capacity and memory performance",
    "start": "583839",
    "end": "588880"
  },
  {
    "text": "see i've always thought that it would make more sense to have the m-class instance be the memory optimized instance",
    "start": "588880",
    "end": "594240"
  },
  {
    "text": "but you know just got to do a little translation every time i'm looking up the pricing chart for ec2 yeah yeah that's",
    "start": "594240",
    "end": "601040"
  },
  {
    "text": "interesting i'm sure you get that a lot there's a multi-purpose part of it and then the ram part of it which is the r",
    "start": "601040",
    "end": "606640"
  },
  {
    "text": "which oh yeah so so now the other important thing about",
    "start": "606640",
    "end": "611920"
  },
  {
    "text": "this announcement is that this is the m6g right this is the the sixth gen instance i haven't seen any other 6th gen",
    "start": "611920",
    "end": "618399"
  },
  {
    "text": "ec2 instances is this the first 6th gen ec2 instance yup that's correct so this is the first",
    "start": "618399",
    "end": "624640"
  },
  {
    "start": "622000",
    "end": "691000"
  },
  {
    "text": "6th gen ec2 instance that's now generally available what we've also announced are",
    "start": "624640",
    "end": "630640"
  },
  {
    "text": "corresponding six gen ec2 instances that are powered by graviton cpus again",
    "start": "630640",
    "end": "636000"
  },
  {
    "text": "as part of our compute optimize c family which will be the c6g instance",
    "start": "636000",
    "end": "641200"
  },
  {
    "text": "and we will also have it part of our memory optimized r family which is the r60 instance and both of those instance",
    "start": "641200",
    "end": "646959"
  },
  {
    "text": "types will be available in the coming months i just want to pause there for a second i think this is very significant ec2 is one of the most heavily used services",
    "start": "646959",
    "end": "654000"
  },
  {
    "text": "on aws lots of customers depend on ec2 every day for their workloads and what we're doing here is we think",
    "start": "654000",
    "end": "660800"
  },
  {
    "text": "that the performance and price improvements here are significant enough to designate this as a brand new generation of ec2 offering",
    "start": "660800",
    "end": "667600"
  },
  {
    "text": "i feel like we should have had a bottle of champagne ready for this nick i mean there's so many causes for celebration right new regions new ec2",
    "start": "667600",
    "end": "674399"
  },
  {
    "text": "instances we need a sponsorship at that point but um yeah but but can we yeah elaborate on that a",
    "start": "674399",
    "end": "681040"
  },
  {
    "text": "little bit you know what what does a generational improvement mean i mean when we see something like an m5 or an",
    "start": "681040",
    "end": "687040"
  },
  {
    "text": "m6 what should what should customer expect customers expect",
    "start": "687040",
    "end": "692240"
  },
  {
    "start": "691000",
    "end": "752000"
  },
  {
    "text": "yeah one of our key tenants as we go through a generational improvement is we want to provide compelling value",
    "start": "692240",
    "end": "697279"
  },
  {
    "text": "for something that meets the bar of a generational refresh and a lot of times our customers value",
    "start": "697279",
    "end": "702720"
  },
  {
    "text": "you know essentially the price performance benefit that you get from going from one generation to the other uh but but it doesn't just end there",
    "start": "702720",
    "end": "709760"
  },
  {
    "text": "there's also other benefits that we've typically brought in in terms of enhanced capabilities uh just pure",
    "start": "709760",
    "end": "715760"
  },
  {
    "text": "performance across different dimensions be it you know compute networking or abs um so when you put all of this together",
    "start": "715760",
    "end": "723519"
  },
  {
    "text": "uh that really is what qualifies as a next generation improvement in an instance and in this case with the m6g with a 40",
    "start": "723519",
    "end": "731600"
  },
  {
    "text": "perform price performance benefit uh we feel that's a significant leap going from gen 5 to gen 6.",
    "start": "731600",
    "end": "739120"
  },
  {
    "text": "very exciting um you know do we want to dive a little bit deeper on sort of like the architecture the the",
    "start": "740079",
    "end": "745839"
  },
  {
    "text": "chipset for graviton 2 and how this sort of powers these improvements that we see under the hood",
    "start": "745839",
    "end": "752480"
  },
  {
    "start": "752000",
    "end": "1085000"
  },
  {
    "text": "yeah absolutely i think happy to share some of those details in terms of taking a closer look at the",
    "start": "752480",
    "end": "758800"
  },
  {
    "text": "gravitational processor and lifting the lid a little bit um let me share some supporting slides",
    "start": "758800",
    "end": "764480"
  },
  {
    "text": "as we walk through uh some of the deeper features here and please let me know when this comes",
    "start": "764480",
    "end": "769680"
  },
  {
    "text": "through yeah",
    "start": "769680",
    "end": "773839"
  },
  {
    "text": "yeah it looks good to me yep i can see that on my end okay awesome so what you see on the left",
    "start": "779120",
    "end": "785839"
  },
  {
    "text": "side of your screen is our first generation graviton processor that we announced back in reinvent 2018",
    "start": "785839",
    "end": "792240"
  },
  {
    "text": "it was built on the 16 nanometer process technology 5 billion transistors and it was the first essentially the arm",
    "start": "792240",
    "end": "799120"
  },
  {
    "text": "instance in inside aws and also as part of a major cloud so it enabled the arm architecture to be a",
    "start": "799120",
    "end": "805680"
  },
  {
    "text": "first class citizen in ec2 and it also enabled a certain class of workloads called scale out workloads",
    "start": "805680",
    "end": "813519"
  },
  {
    "text": "where a lot of our customers have been able to transition to the first generation graviton and take",
    "start": "813519",
    "end": "819519"
  },
  {
    "text": "advantage of the cost benefits now what you see on the right side is graviton 2 that is powering our",
    "start": "819519",
    "end": "826079"
  },
  {
    "text": "newest m6g instance and this is a completely different beast so this brings in an order of magnitude",
    "start": "826079",
    "end": "832959"
  },
  {
    "text": "improvement in terms of performance and capabilities right and the pictures are are actually two-scale",
    "start": "832959",
    "end": "839920"
  },
  {
    "text": "so you can actually see that the graviton to cpu is much larger just in terms of pure size and as it",
    "start": "839920",
    "end": "845839"
  },
  {
    "text": "packs 30 billion transistors and it's built on the latest generation seven nanometer manufacturing technology",
    "start": "845839",
    "end": "853279"
  },
  {
    "text": "you know sodium from just from looking at these these specs it almost seems like uh moore's law is",
    "start": "853279",
    "end": "859360"
  },
  {
    "text": "alive and well yeah yeah absolutely i think uh one of the biggest things that we've been also",
    "start": "859360",
    "end": "864399"
  },
  {
    "text": "been able to achieve through our partnership where we've worked with arm to essentially shape the",
    "start": "864399",
    "end": "869680"
  },
  {
    "text": "n1 core is the performance improvements that we're able to deliver here so going from our previous gen to the",
    "start": "869680",
    "end": "875920"
  },
  {
    "text": "graviton 2 it's on a per vcpu basis almost 2x performance improvement",
    "start": "875920",
    "end": "881279"
  },
  {
    "text": "and an aggregate with 4x the number of cores from from graviton one to two that's a",
    "start": "881279",
    "end": "886560"
  },
  {
    "text": "7x performance improvement or an aggregate cpu level",
    "start": "886560",
    "end": "891040"
  },
  {
    "text": "and i just want to dive a little bit deeper as we lift the lid and look into the cores as well so like i said we've integrated 64-bit",
    "start": "892320",
    "end": "899760"
  },
  {
    "text": "arm neoverse n1 class cores and along with that there's a lot of the",
    "start": "899760",
    "end": "904800"
  },
  {
    "text": "custom silicon design that aws has built and integrated and the cpu itself",
    "start": "904800",
    "end": "911199"
  },
  {
    "text": "delivers a number of cash significantly large cash so both l1 and l2 caches there are a lot",
    "start": "911199",
    "end": "918079"
  },
  {
    "text": "of optimizations built in that essentially lowers the overheads of some of our virtualization and context switching",
    "start": "918079",
    "end": "924000"
  },
  {
    "text": "and we also have additional instruction support for specific workloads uh for example if you can look at the n8",
    "start": "924000",
    "end": "931120"
  },
  {
    "text": "and the fp16 that's built into the cpu as separate instructions that you can use to accelerate say a machine learning",
    "start": "931120",
    "end": "937360"
  },
  {
    "text": "inference application and there's also dual cmd units that essentially help to deliver improved",
    "start": "937360",
    "end": "944000"
  },
  {
    "text": "floating point performance so uh great for a lot of the encoding workloads hpc kind of class workloads as",
    "start": "944000",
    "end": "950800"
  },
  {
    "text": "well and significant um a point to note here is that each vcpu that we vent here in an m6g",
    "start": "950800",
    "end": "958560"
  },
  {
    "text": "instance or a graviton to a cpu is actually a full physical core so we don't have uh simultaneous",
    "start": "958560",
    "end": "965839"
  },
  {
    "text": "multi-threading which actually means that you can actually rend out a full core with dedicated caches more isolation",
    "start": "965839",
    "end": "974000"
  },
  {
    "text": "back to our customers as part of a vcpu",
    "start": "974000",
    "end": "979120"
  },
  {
    "text": "and also the interconnect when it comes to how all these different cores are communicating with each other so we have 64 cores in a graviton to cpu",
    "start": "980560",
    "end": "988320"
  },
  {
    "text": "connected together in a mesh significant amount of bisection bandwidth up to two terabytes per second that allows them to",
    "start": "988320",
    "end": "994160"
  },
  {
    "text": "communicate with each other very quickly and then as with a single core uh without",
    "start": "994160",
    "end": "1000800"
  },
  {
    "text": "multi-threading and also because it's a single socket so you actually don't have any numera concerns",
    "start": "1000800",
    "end": "1006399"
  },
  {
    "text": "so every core is actually seeing the same latency and a path to the memory",
    "start": "1006399",
    "end": "1012079"
  },
  {
    "text": "and a lot of ios plenty of pci gen4 to give us the flexibility in terms of connectivity and enabling multiple instance",
    "start": "1012079",
    "end": "1018320"
  },
  {
    "text": "configurations and finally on the memory side a couple of key features to call out so",
    "start": "1018320",
    "end": "1024640"
  },
  {
    "text": "to feed all these cores we want to make sure that the memory bandwidth keeps up so we have eight channels of ddr4",
    "start": "1024640",
    "end": "1030720"
  },
  {
    "text": "running at the highest speeds of 3200 and this is also improving our overall",
    "start": "1030720",
    "end": "1035918"
  },
  {
    "text": "security posture here because we have always on 256 bit encrypted",
    "start": "1035919",
    "end": "1041199"
  },
  {
    "text": "memory um that's supported with our graviton to cpus and the m60 instances",
    "start": "1041199",
    "end": "1048558"
  },
  {
    "text": "you know i would like to boast that i overclocked my own computer's ram to above 3 200 megahertz but",
    "start": "1049280",
    "end": "1055039"
  },
  {
    "text": "uh i don't think aws would let me anywhere near the data center to mess with these graviton two chips uh so we'll we'll leave that to those",
    "start": "1055039",
    "end": "1062080"
  },
  {
    "text": "experts but some really amazing advancements here um there are some folks asking in twitch",
    "start": "1062080",
    "end": "1067679"
  },
  {
    "text": "chat you know so what does this look like for actually getting to use this value as far as a consumer product",
    "start": "1067679",
    "end": "1073520"
  },
  {
    "text": "in the m6g instance class um what are the exact instance sizes that are now available to",
    "start": "1073520",
    "end": "1079600"
  },
  {
    "text": "consumers as part of this ga ga launch um yeah absolutely",
    "start": "1079600",
    "end": "1084720"
  },
  {
    "text": "um i have some of these sizes over here and i'll quickly summarize so so basically it's we start from a",
    "start": "1084720",
    "end": "1091760"
  },
  {
    "start": "1085000",
    "end": "1255000"
  },
  {
    "text": "medium instance size so one of the benefits of being able to deliver a full core is that with better isolation we can now",
    "start": "1091760",
    "end": "1098320"
  },
  {
    "text": "offer a medium instant size which we were not able to offer with an m5 instance so it starts with one vcpu",
    "start": "1098320",
    "end": "1105039"
  },
  {
    "text": "and across the board what you're going to see is you will see 4gb of dram per vcpu that's the ratio we have for a",
    "start": "1105039",
    "end": "1111280"
  },
  {
    "text": "standard m instance type so we go from a medium with one vcpu and 4gb of dram",
    "start": "1111280",
    "end": "1116880"
  },
  {
    "text": "all the way to a 16 extra large that has 64 vcpus and 256 gigabytes",
    "start": "1116880",
    "end": "1123600"
  },
  {
    "text": "all of them come with enhanced networking support so we go up to 25 gigabits per second of networking bandwidth",
    "start": "1123600",
    "end": "1129760"
  },
  {
    "text": "we also have ebs supported so there's ebs optimized burst going up to 19 gigabits per second of",
    "start": "1129760",
    "end": "1136640"
  },
  {
    "text": "ebs bandwidth and um and yeah so that's basically the the full set of instances",
    "start": "1136640",
    "end": "1142960"
  },
  {
    "text": "what i also don't show here which we support as part of the launch is also a bare metal version so it's not",
    "start": "1142960",
    "end": "1148240"
  },
  {
    "text": "just the words but we also have a bare metal version of m6g that's currently available yeah i know i think",
    "start": "1148240",
    "end": "1156480"
  },
  {
    "text": "another uh interpretation of the questions going on in twitch is um is this a product so this is a",
    "start": "1156480",
    "end": "1163679"
  },
  {
    "text": "question from denny1111 this is a customer product or is this used only by aws",
    "start": "1163679",
    "end": "1169600"
  },
  {
    "text": "i think what he means is can i go to best buy and pick up one of these chips",
    "start": "1169600",
    "end": "1175840"
  },
  {
    "text": "no so the short answer is no this is part of our infrastructure within the ec2 infrastructure that's too",
    "start": "1176880",
    "end": "1183280"
  },
  {
    "text": "bad i imagine you know bring a couple of these home and tinkering with them pretty fun i imagine a long answer that's like if you subscribe to",
    "start": "1183280",
    "end": "1189840"
  },
  {
    "text": "an aws magazine i can mail in and get one delivered to my house but unfortunately i don't think that's the case either",
    "start": "1189840",
    "end": "1197039"
  },
  {
    "text": "uh so okay so and again i as a reminder i mean these these are all the under the instance tag they all begin with m6g so",
    "start": "1198400",
    "end": "1204880"
  },
  {
    "text": "these are all using the graviton 2 processor which is an arm processor and that raises the question are we",
    "start": "1204880",
    "end": "1211440"
  },
  {
    "text": "going to see non-arm-based ec2 instances under the 6th gen tag",
    "start": "1211440",
    "end": "1218000"
  },
  {
    "text": "yes so we will plan to introduce um both intel and amd based six generation instances",
    "start": "1218080",
    "end": "1224240"
  },
  {
    "text": "um over time and uh we don't have a specific timeline to share yet but yes",
    "start": "1224240",
    "end": "1230000"
  },
  {
    "text": "we should fully expect that we will have we'll continue to offer multiple choices within every generation",
    "start": "1230000",
    "end": "1236960"
  },
  {
    "text": "great to hear uh you know we talked before about sort of the the benchmark number around you know 20",
    "start": "1237679",
    "end": "1242960"
  },
  {
    "text": "lower cost versus m5 or 40 savings on on particular workloads do we have any specific benchmarks or other",
    "start": "1242960",
    "end": "1249280"
  },
  {
    "text": "workloads that we can cite that graviton 2 and m6g instances will will improve",
    "start": "1249280",
    "end": "1255519"
  },
  {
    "start": "1255000",
    "end": "1507000"
  },
  {
    "text": "yeah absolutely so i have a few different uh benchmarks over here that we can talk through so um now spec",
    "start": "1256159",
    "end": "1264080"
  },
  {
    "text": "tends to be pretty much a conversation starter when we're talking about cpu performance",
    "start": "1264080",
    "end": "1269440"
  },
  {
    "text": "so um what you see here is um i'm gonna show you a few different benchmarks and workloads that we've tried out",
    "start": "1269440",
    "end": "1275360"
  },
  {
    "text": "and there's also some customer examples because we ran an extensive m6g preview program and we got a lot of",
    "start": "1275360",
    "end": "1281200"
  },
  {
    "text": "customers to actually test it out and provide feedback as well so um the summary is that across the board in",
    "start": "1281200",
    "end": "1288640"
  },
  {
    "text": "the number of workloads that we've tried we've seen anywhere between 20 to 45 percent higher performance per vcpu",
    "start": "1288640",
    "end": "1295120"
  },
  {
    "text": "on m6g compared to m5 some examples here is you're looking at spec cpu",
    "start": "1295120",
    "end": "1300640"
  },
  {
    "text": "uh based on 2017 you can see here it's a little more than 40 percent performance improvement and",
    "start": "1300640",
    "end": "1306880"
  },
  {
    "text": "you know on the spec fp the floating point performance we are seeing a little over 20",
    "start": "1306880",
    "end": "1312320"
  },
  {
    "text": "some other workload level examples so here is uh memcache d workload",
    "start": "1312559",
    "end": "1319120"
  },
  {
    "text": "so we gave this a try where we had a load generator through coming from some of the c5",
    "start": "1319120",
    "end": "1326720"
  },
  {
    "text": "instances that then you know essentially connect to uh d that's running you know on m6g versus",
    "start": "1326720",
    "end": "1333919"
  },
  {
    "text": "m5 and here again the number of requests per second that you see is pretty much",
    "start": "1333919",
    "end": "1339039"
  },
  {
    "text": "significantly over the 20 mark and it's not just a number of requests per second um the other part note here",
    "start": "1339039",
    "end": "1345679"
  },
  {
    "text": "is the latency so you can also see that the latency of serving these requests is also",
    "start": "1345679",
    "end": "1350799"
  },
  {
    "text": "significantly lower when you look at the m6g versus m5",
    "start": "1350799",
    "end": "1356960"
  },
  {
    "text": "again media encoding um we've tried here a lot of video being created every day um you know we need some of the media",
    "start": "1358400",
    "end": "1365360"
  },
  {
    "text": "encoding part to overall reduce the bandwidth and store it so here again with h.264 encoding we've",
    "start": "1365360",
    "end": "1371679"
  },
  {
    "text": "seen a significantly higher performance with m6g",
    "start": "1371679",
    "end": "1377520"
  },
  {
    "text": "and i'll just walk through a couple of other examples we also tried an ada workload um as you know chip design can be super",
    "start": "1377520",
    "end": "1384240"
  },
  {
    "text": "complex so a lot of cycles are spent in doing simulation",
    "start": "1384240",
    "end": "1389280"
  },
  {
    "text": "to model the chip to make sure that you know things look okay because going back and fixing the chip can be super expensive so here we took an",
    "start": "1389280",
    "end": "1396400"
  },
  {
    "text": "example of an idea workload cadence running on an arm processor simulating the arm cpu",
    "start": "1396400",
    "end": "1402000"
  },
  {
    "text": "itself and again the performance per vcpu that we saw here and and the point to note is we are",
    "start": "1402000",
    "end": "1407840"
  },
  {
    "text": "comparing an m524 extra large with an m6g16 extra large so",
    "start": "1407840",
    "end": "1413679"
  },
  {
    "text": "significantly uh smaller sized but also a performance improvement that",
    "start": "1413679",
    "end": "1419440"
  },
  {
    "text": "we see here overall i'm going to switch to some examples from customers who have tried m6g as",
    "start": "1419440",
    "end": "1426159"
  },
  {
    "text": "part of the preview and here's what they observe right so here's an example of",
    "start": "1426159",
    "end": "1431440"
  },
  {
    "text": "eq alpha that benchmarked the key db as a database workload and what they saw",
    "start": "1431440",
    "end": "1437600"
  },
  {
    "text": "is up front when they compared the large extra large to medium type instances",
    "start": "1437600",
    "end": "1442799"
  },
  {
    "text": "up to 65 percent better performance on the kdb workload than m6g",
    "start": "1442799",
    "end": "1449759"
  },
  {
    "text": "here's another feedback that we got from honeycomb as they compared their existing fleet of",
    "start": "1451360",
    "end": "1458320"
  },
  {
    "text": "c5 instances uh they tested it out replacing them with m6g and found that they can actually use now 30",
    "start": "1458320",
    "end": "1464480"
  },
  {
    "text": "fewer instance types so that's in a nutshell some of the",
    "start": "1464480",
    "end": "1470400"
  },
  {
    "text": "different benchmarks and some of the early feedback we have from customers we also have our m60 web page where we",
    "start": "1470400",
    "end": "1476559"
  },
  {
    "text": "published more customer stories as part of the preview program so definitely encourage",
    "start": "1476559",
    "end": "1482080"
  },
  {
    "text": "folks to go take a look at that when they're headed in a moment okay so dear i think it's been a little bit creepy how every question you ask you",
    "start": "1482080",
    "end": "1488799"
  },
  {
    "text": "seem to we ask you seem to have a slide ready for it um how about i throw your curveball can we see a demo of all",
    "start": "1488799",
    "end": "1494320"
  },
  {
    "text": "this stuff um certainly yes let me",
    "start": "1494320",
    "end": "1501840"
  },
  {
    "text": "let me bring up my screen and and for everyone uh who's at home",
    "start": "1503120",
    "end": "1509679"
  },
  {
    "start": "1507000",
    "end": "1816000"
  },
  {
    "text": "waiting to see uh the demo we're actually gonna talk a little bit about how you can migrate to use this",
    "start": "1509679",
    "end": "1514720"
  },
  {
    "text": "going forward if depending on what studio covers in the demo so stick around uh if you're excited to actually get to",
    "start": "1514720",
    "end": "1520240"
  },
  {
    "text": "use these new m6g instances okay is this coming through okay yeah",
    "start": "1520240",
    "end": "1526480"
  },
  {
    "text": "great so um this is going to be a pretty quick demo and pretty straightforward so what we're showing here is a um a web",
    "start": "1526480",
    "end": "1533840"
  },
  {
    "text": "tier kind of setup where you have a client that's uh sending a bunch of requests",
    "start": "1533840",
    "end": "1538880"
  },
  {
    "text": "to an nginx server um proxying back to a bunch of child processes which is a",
    "start": "1538880",
    "end": "1545120"
  },
  {
    "text": "simple um ao http program uh we look at the code in just a little bit but what it's",
    "start": "1545120",
    "end": "1550240"
  },
  {
    "text": "really doing is uh serving these requests sending back a hello world along with the architecture type",
    "start": "1550240",
    "end": "1556080"
  },
  {
    "text": "and we're also using supervisor d as a process manager with the different processes that we have spun up to",
    "start": "1556080",
    "end": "1563279"
  },
  {
    "text": "serve these requests and we're running the exact same setup on an m6g",
    "start": "1563279",
    "end": "1568480"
  },
  {
    "text": "and also an m5 and we'll compare you know the time it takes to complete and also the requests per second",
    "start": "1568480",
    "end": "1576720"
  },
  {
    "text": "i'm just going to start the demo so we're going into the console and",
    "start": "1577919",
    "end": "1584000"
  },
  {
    "text": "we're going to spin up the m6g instance in the top window",
    "start": "1584000",
    "end": "1589360"
  },
  {
    "text": "and as you can see the union dash a that's an ar-64 that's an arm 64 machine",
    "start": "1589360",
    "end": "1595760"
  },
  {
    "text": "and then down at the bottom we basically spun up an m5 instance",
    "start": "1595840",
    "end": "1601360"
  },
  {
    "text": "so let's look at the different pieces of code here so we start with the hello bench the process that's serving the requests",
    "start": "1603279",
    "end": "1612640"
  },
  {
    "text": "simple python code and what it's basically doing is the hello world",
    "start": "1612640",
    "end": "1618159"
  },
  {
    "text": "and calling out the architecture and it's also setting up the traces for",
    "start": "1618159",
    "end": "1623279"
  },
  {
    "text": "the datadog monitor that we're going to use so a monitoring agent that you can use just like you do on any other x86",
    "start": "1623279",
    "end": "1629679"
  },
  {
    "text": "instance you can do it on an arm 64 instance as well supervisor d config so basically that",
    "start": "1629679",
    "end": "1636320"
  },
  {
    "text": "points to the hello bench process and manages that",
    "start": "1636320",
    "end": "1643600"
  },
  {
    "text": "and let's look at the nginx web proxy web server that we are running",
    "start": "1645679",
    "end": "1651039"
  },
  {
    "text": "as you can see that's pointing back to the iohttp hellobench 16 processes that we have",
    "start": "1651200",
    "end": "1657200"
  },
  {
    "text": "kicked off so i look at what all we have running",
    "start": "1657200",
    "end": "1664000"
  },
  {
    "text": "together so we have the datadog traces we have the nginx worker process",
    "start": "1664000",
    "end": "1673440"
  },
  {
    "text": "and then we also have our hello bench processes that have been kicked off",
    "start": "1674080",
    "end": "1681200"
  },
  {
    "text": "so now the benchmark",
    "start": "1681200",
    "end": "1684158"
  },
  {
    "text": "so the benchmark here is we're going to send uh 500 requests concurrently and up to 5 million in",
    "start": "1687039",
    "end": "1693200"
  },
  {
    "text": "total and we're going to look at the m6g in the top window the m5 on the bottom",
    "start": "1693200",
    "end": "1698880"
  },
  {
    "text": "and we're going to compare sort of the runtimes and how they stack up against each other",
    "start": "1698880",
    "end": "1705520"
  },
  {
    "text": "so this demo is accelerated by the way just so we can get to the final result",
    "start": "1706080",
    "end": "1712799"
  },
  {
    "text": "and you can see datadog is capturing some of those traces for both m6g and m5",
    "start": "1715440",
    "end": "1725840"
  },
  {
    "text": "m60 is nearly done here we're gonna accelerate and move forward to the finish and take a look at the final",
    "start": "1726960",
    "end": "1734559"
  },
  {
    "text": "result just be completing m5 here in just a second there you go",
    "start": "1736840",
    "end": "1744000"
  },
  {
    "text": "and what you see here in total time taken the m6g has taken um around thousand",
    "start": "1745600",
    "end": "1753440"
  },
  {
    "text": "seconds which is about 25 lower than what you see on an m5",
    "start": "1753440",
    "end": "1759919"
  },
  {
    "text": "and correspondingly if you look at the requests per second that were served you can see that that also correlates uh",
    "start": "1759919",
    "end": "1766080"
  },
  {
    "text": "to about 25 more requests per second on an m6g versus an m5",
    "start": "1766080",
    "end": "1773200"
  },
  {
    "text": "cool awesome well this this sounds great to me i have some questions folks in the chat",
    "start": "1775120",
    "end": "1781279"
  },
  {
    "text": "have some questions i know your time is valuable studios so we'll try to make it quick um my first question is how can i",
    "start": "1781279",
    "end": "1789039"
  },
  {
    "text": "migrate so i'm sold right i get all the uh the benefits of the new graviton ship and the m6g over the m5",
    "start": "1789039",
    "end": "1795440"
  },
  {
    "text": "um but people are probably wondering how can i migrate my workloads to m6g it's a new architecture with the",
    "start": "1795440",
    "end": "1801360"
  },
  {
    "text": "arm with arm-based architecture right like what does this migration actually look like yeah i think that's a that's a perfectly",
    "start": "1801360",
    "end": "1808159"
  },
  {
    "text": "valid question that we get all the time from our customers and it's usually top of their minds especially when they're dealing with an",
    "start": "1808159",
    "end": "1814240"
  },
  {
    "text": "architecture like harm and what i want to share here is some of the progress and the momentum that we've",
    "start": "1814240",
    "end": "1819840"
  },
  {
    "start": "1816000",
    "end": "1975000"
  },
  {
    "text": "seen overall in the arm software ecosystem and some of the building blocks that we have that will",
    "start": "1819840",
    "end": "1825760"
  },
  {
    "text": "allow you to take advantage and migrate some of your workloads so",
    "start": "1825760",
    "end": "1832399"
  },
  {
    "text": "what we've seen is that ever since we announced graviton and now onwards to graviton too uh the",
    "start": "1832399",
    "end": "1839200"
  },
  {
    "text": "momentum within the army ecosystem has been significant so firstly starting off with the osv and",
    "start": "1839200",
    "end": "1844720"
  },
  {
    "text": "isv support what we have today is broad support for on 6400 architecture across",
    "start": "1844720",
    "end": "1851039"
  },
  {
    "text": "all the key linux distributions so from amazon linux 2 um ubuntu red hat souza",
    "start": "1851039",
    "end": "1859600"
  },
  {
    "text": "and and then more right like debian we have fedora just pretty much all the popular linux",
    "start": "1859600",
    "end": "1864720"
  },
  {
    "text": "distribution support arm64 as a first class citizen and you know we have the exact same",
    "start": "1864720",
    "end": "1869840"
  },
  {
    "text": "armies available for our customers if you go to the console it's basically a radio button that just say okay do i want x86 or do i want",
    "start": "1869840",
    "end": "1876960"
  },
  {
    "text": "arm just pick it and you can run the army and launch the instance so and and you get all your key packages uh",
    "start": "1876960",
    "end": "1884080"
  },
  {
    "text": "in much the same way as you would with any other instance secondly in terms of containers so we",
    "start": "1884080",
    "end": "1890080"
  },
  {
    "text": "are finding that a lot of our customers use you know containers docker has",
    "start": "1890080",
    "end": "1895519"
  },
  {
    "text": "added support for arm you know and and pretty much most of the docker",
    "start": "1895519",
    "end": "1901200"
  },
  {
    "text": "official images that support x86 they also have support for arm64 today",
    "start": "1901200",
    "end": "1906399"
  },
  {
    "text": "and amazon's own ecs and eks services um support the r64",
    "start": "1906399",
    "end": "1911440"
  },
  {
    "text": "architecture as well as we've now most recently as a couple of weeks ago added support for arm in the",
    "start": "1911440",
    "end": "1917120"
  },
  {
    "text": "ecr the elastic container registries as well and for micro vms we're also making sure",
    "start": "1917120",
    "end": "1923360"
  },
  {
    "text": "that firecracker now includes support for ram in addition to x86",
    "start": "1923360",
    "end": "1929120"
  },
  {
    "text": "and for a lot of the tools and software that our developers rely on so be it our marketplace which is our",
    "start": "1929120",
    "end": "1934960"
  },
  {
    "text": "curated collection of software software catalog be it all the",
    "start": "1934960",
    "end": "1940559"
  },
  {
    "text": "popular agents like systems manager inspector that our customers use on x86",
    "start": "1940559",
    "end": "1947679"
  },
  {
    "text": "instances and also our entire aws code suite for code deploy code pipeline code build",
    "start": "1947679",
    "end": "1953200"
  },
  {
    "text": "code commit all of that today fully supports arm as well and",
    "start": "1953200",
    "end": "1958640"
  },
  {
    "text": "java applications tend to be architecture agnostic for the most part so it's super popular what we've seen in",
    "start": "1958640",
    "end": "1965039"
  },
  {
    "text": "customers use adopting graviton and we have amazon coretta which is amazon's own distribution of open jdk",
    "start": "1965039",
    "end": "1971360"
  },
  {
    "text": "um also releasing support for rms first class citizen so across the board a lot of momentum",
    "start": "1971360",
    "end": "1976399"
  },
  {
    "start": "1975000",
    "end": "2283000"
  },
  {
    "text": "and we believe there are a lot of really good building blocks for customers to use and i also you know mentioned datadog",
    "start": "1976399",
    "end": "1982240"
  },
  {
    "text": "that we just showed in the demo uh we have other big isvs like crowdstrike security monitoring tool",
    "start": "1982240",
    "end": "1987919"
  },
  {
    "text": "that also supports uh both the a1 and the m6g as part of graviton instances",
    "start": "1987919",
    "end": "1994799"
  },
  {
    "text": "yeah that's pretty comprehensive and just to add to that there are a lot of other workloads that also work within the arm ecosystem",
    "start": "1994799",
    "end": "2000240"
  },
  {
    "text": "for example uh you mentioned docker containers so one of the most popular run times for web applications these",
    "start": "2000240",
    "end": "2005760"
  },
  {
    "text": "days node.js there's a very well supported docker image for node.js that runs on",
    "start": "2005760",
    "end": "2010880"
  },
  {
    "text": "arm likewise if you're a net developer there are net images that can run on arm so um you know the ecosystem is is way",
    "start": "2010880",
    "end": "2018159"
  },
  {
    "text": "ahead of where it was just a few years ago and it's really interesting to see the amount of momentum around it",
    "start": "2018159",
    "end": "2023360"
  },
  {
    "text": "yeah absolutely yep now there's a there's a question in chat about um you know when did we launch this i",
    "start": "2023360",
    "end": "2029840"
  },
  {
    "text": "saw that was answered but i think to kind of bring that question home that demo that you showed us uh for those of the people watching",
    "start": "2029840",
    "end": "2036320"
  },
  {
    "text": "twitch can they go and launch an m6g instance right now and run those exact same benchmarks that they saw",
    "start": "2036320",
    "end": "2042320"
  },
  {
    "text": "yeah absolutely so we launched m6g just earlier this week on monday which",
    "start": "2042320",
    "end": "2048560"
  },
  {
    "text": "is 511 and it's generally available in six regions so we have three regions of the",
    "start": "2048560",
    "end": "2053919"
  },
  {
    "text": "u.s so north virginia oregon and ohio we have two regions in europe which is",
    "start": "2053919",
    "end": "2060878"
  },
  {
    "text": "frankfurt and ireland and we also have one region in the apac in the apac region which is tokyo so six",
    "start": "2060879",
    "end": "2068720"
  },
  {
    "text": "regions today you can go launch it um and we'll be adding more regions going forward",
    "start": "2068720",
    "end": "2074158"
  },
  {
    "text": "another question here from werner g imagine is this the new amazon redshift r83",
    "start": "2074159",
    "end": "2081280"
  },
  {
    "text": "instance um so i guess the more general version that question would be you know what are",
    "start": "2081280",
    "end": "2086720"
  },
  {
    "text": "the various aws services that that this thing powers for example you showed memcache d earlier on we know that",
    "start": "2086720",
    "end": "2092720"
  },
  {
    "text": "memcache d we offer a managed version of memcache d via elastic cache that runs on a variety of different class",
    "start": "2092720",
    "end": "2098000"
  },
  {
    "text": "instances is this uh you know is this integrated with that and potentially other services across aws yeah so there are a number of",
    "start": "2098000",
    "end": "2104880"
  },
  {
    "text": "services that are actually actively testing these m6g instances and plan to support it um specifically elastic cache we'll",
    "start": "2104880",
    "end": "2112240"
  },
  {
    "text": "expect some more support here actually in the coming months very soon and one of the data points we have from the",
    "start": "2112240",
    "end": "2118079"
  },
  {
    "text": "elastic cache team as they tested m6g was they saw up to a 50 improvement uh on redis",
    "start": "2118079",
    "end": "2124720"
  },
  {
    "text": "versus m5 so it's definitely looking very encouraging from that perspective and uh we expect elastic cache",
    "start": "2124720",
    "end": "2131200"
  },
  {
    "text": "um emr um even our own elastic load balancing services",
    "start": "2131200",
    "end": "2136480"
  },
  {
    "text": "um all of those to uh support m6 very soon can i just take a moment to digest all",
    "start": "2136480",
    "end": "2142480"
  },
  {
    "text": "of this usually in the you know in the hardware world we don't see this kind of",
    "start": "2142480",
    "end": "2149839"
  },
  {
    "text": "massive improvement very often right if you look at the kind of delta improvements between different",
    "start": "2149839",
    "end": "2155119"
  },
  {
    "text": "generations of processors or architectures or memory solutions they're usually in like",
    "start": "2155119",
    "end": "2160400"
  },
  {
    "text": "the single digit range double you know a low you know double digit between 10 to 20 improvement is",
    "start": "2160400",
    "end": "2166000"
  },
  {
    "text": "considered very significant right you also see this in the gpu space but to have this kind of performance for",
    "start": "2166000",
    "end": "2172560"
  },
  {
    "text": "general compute just blows my mind yeah and i think i think a lot of that goes into some of",
    "start": "2172560",
    "end": "2179599"
  },
  {
    "text": "the optimizations that we've been able to do as part of our custom silicon initiatives um so uh yeah",
    "start": "2179599",
    "end": "2186320"
  },
  {
    "text": "i completely agree with you i think this is an order of magnitude improvement um not just in performance but also the",
    "start": "2186320",
    "end": "2192240"
  },
  {
    "text": "lower price and the combination of the two um we hope our customers find very compelling",
    "start": "2192240",
    "end": "2198960"
  },
  {
    "text": "so really quickly top to bottom and correct me if i miss anything launch of the new graviton to custom",
    "start": "2198960",
    "end": "2204560"
  },
  {
    "text": "silicon processors in collaboration with annapurna labs uh available generally to everyone as of",
    "start": "2204560",
    "end": "2210880"
  },
  {
    "text": "this past monday in the m6g instance class again as being the first",
    "start": "2210880",
    "end": "2215920"
  },
  {
    "text": "sixth generation instance and being specifically tied to the general compute class so again applicable to a large",
    "start": "2215920",
    "end": "2221760"
  },
  {
    "text": "number of workloads um a large number of benchmarks that we included in here that again this",
    "start": "2221760",
    "end": "2226960"
  },
  {
    "text": "this is recorded so folks can go in and check those out as well as a large number of um integrations uh with partners such as",
    "start": "2226960",
    "end": "2234400"
  },
  {
    "text": "you know datadog we saw the testimonial from honeycomb as well there for the",
    "start": "2234400",
    "end": "2240000"
  },
  {
    "text": "price of performance improvements over the m5 uh class instances previous to this",
    "start": "2240000",
    "end": "2246640"
  },
  {
    "text": "yep absolutely those uh those are right on awesome well i wish we could sit here",
    "start": "2246640",
    "end": "2251920"
  },
  {
    "text": "and geek out about uh you know the new m6gs all day but we do have",
    "start": "2251920",
    "end": "2256960"
  },
  {
    "text": "three other launches to get to uh so without further ado i wanted to say thank you sudhir again for joining us",
    "start": "2256960",
    "end": "2263359"
  },
  {
    "text": "from the ec2 team talking a little bit about graviton 2 and the new m6gs thank you again for coming out stick",
    "start": "2263359",
    "end": "2269920"
  },
  {
    "text": "around we will be right back with another guest this time we're going to be looking at a demo on uh",
    "start": "2269920",
    "end": "2275680"
  },
  {
    "text": "aws glue new launch for streaming etl so stick around we'll be right back",
    "start": "2275680",
    "end": "2284400"
  },
  {
    "text": "all right we're back i promised another demo and we've got another two after this one as well so we're going to fly through it so",
    "start": "2284400",
    "end": "2290000"
  },
  {
    "text": "again here we are going to be talking about a very exciting launch and it is streaming etl via aws glue here to talk",
    "start": "2290000",
    "end": "2296720"
  },
  {
    "text": "to us a little bit more about this is mehul shah gm for aws glue and lake formation well thank you again for joining us on the",
    "start": "2296720",
    "end": "2302640"
  },
  {
    "text": "show today thank you for having us it's a pleasure here okay so",
    "start": "2302640",
    "end": "2308079"
  },
  {
    "text": "um again not launching an instance class like we spoke about before but this is a very exciting launch um",
    "start": "2308079",
    "end": "2314800"
  },
  {
    "text": "can we talk a little bit about you know what etl is because i think that's an important primer before we get into the",
    "start": "2314800",
    "end": "2320160"
  },
  {
    "text": "streaming component and how it fits into glue largely absolutely so etl stands for",
    "start": "2320160",
    "end": "2326880"
  },
  {
    "text": "extract transform and load and it's actually a very large industry behind etl tools",
    "start": "2326880",
    "end": "2335119"
  },
  {
    "text": "that you can find in the market it's an eight billion dollar industry and it's really it's actually growing pretty fast",
    "start": "2335280",
    "end": "2341599"
  },
  {
    "text": "etl in some some sense is the first mile for uh doing data analysis so if you",
    "start": "2341599",
    "end": "2347359"
  },
  {
    "text": "want to do any kind of analysis over your data typically you need to prepare that data you need to restructure that data",
    "start": "2347359",
    "end": "2354320"
  },
  {
    "text": "enrich that data format that data so that you know a bunch of different engines can analyze that data",
    "start": "2354320",
    "end": "2361119"
  },
  {
    "text": "sometimes you'll have sql engines data warehouses analyzing that data you might do big data processing over",
    "start": "2361119",
    "end": "2367920"
  },
  {
    "text": "that data you might want to do some stream processing or",
    "start": "2367920",
    "end": "2373040"
  },
  {
    "text": "monitoring and inline analytics machine learning over that data in all of these cases you really need to",
    "start": "2373040",
    "end": "2379520"
  },
  {
    "text": "canonicalize and prepare that data so the analysis can go really well and so etl",
    "start": "2379520",
    "end": "2385839"
  },
  {
    "text": "is sort of the the uh you know the the short form of data preparation and and data cleaning",
    "start": "2385839",
    "end": "2392480"
  },
  {
    "text": "um it's really born from the the the term extract transform and load",
    "start": "2392480",
    "end": "2398800"
  },
  {
    "text": "when people used to just do all of their data and data management on databases and they would spend time",
    "start": "2398800",
    "end": "2404800"
  },
  {
    "text": "extracting it transforming it and loading it into data warehouses yeah and we won't dive too deep on the",
    "start": "2404800",
    "end": "2410880"
  },
  {
    "start": "2408000",
    "end": "2588000"
  },
  {
    "text": "history of inefficient practices of etl yeah yeah yeah but broadly i think you know you",
    "start": "2410880",
    "end": "2416000"
  },
  {
    "text": "hit the nail on the head again like taking data from where it's collected and transforming it for some sort of consumer down the road",
    "start": "2416000",
    "end": "2422079"
  },
  {
    "text": "is very fundamental to to being able to actually achieve business value from whatever you're trying to do with",
    "start": "2422079",
    "end": "2427520"
  },
  {
    "text": "that data right um and so you mentioned before you know this is a very large part of the backbone of a lot",
    "start": "2427520",
    "end": "2433280"
  },
  {
    "text": "of downstream applications that are trying to consume this uh so i've messed around with glue a few times and i'm a big fan of it uh but could we",
    "start": "2433280",
    "end": "2440400"
  },
  {
    "text": "review again for for those that may not be as familiar what aws glue does as a service",
    "start": "2440400",
    "end": "2446000"
  },
  {
    "text": "sure so glue is a managed etl service um it actually has three main components",
    "start": "2446000",
    "end": "2451760"
  },
  {
    "text": "uh for uh for you um the at the core of glue is a serverless etl engine based on apache",
    "start": "2451760",
    "end": "2459760"
  },
  {
    "text": "spark apache spark is a big data processing framework for doing all the transformations that you",
    "start": "2459760",
    "end": "2465520"
  },
  {
    "text": "want to do it works over structured data as well as unstructured data which is nice because that's a lot",
    "start": "2465520",
    "end": "2471920"
  },
  {
    "text": "of the data that's coming in today through you know say iot applications iot logs application logs news feeds",
    "start": "2471920",
    "end": "2480240"
  },
  {
    "text": "social feeds um ad tech logs and so on a lot of this stuff is is unstructured to varying degrees and",
    "start": "2480240",
    "end": "2487280"
  },
  {
    "text": "spark is actually you know the perfect sort of um uh perfect sort of engine for for running",
    "start": "2487280",
    "end": "2493920"
  },
  {
    "text": "uh transformations over that kind of data so at the core of glue is a serverless spark vtl engine that you can use",
    "start": "2493920",
    "end": "2501280"
  },
  {
    "text": "um glue also offers in its console a number of ways of monitoring and",
    "start": "2501280",
    "end": "2506800"
  },
  {
    "text": "actually generating jobs for doing transformations so you actually don't have to know a lot about",
    "start": "2506800",
    "end": "2512000"
  },
  {
    "text": "spark to get started with glue it'll generate those scripts automatically for you",
    "start": "2512000",
    "end": "2517200"
  },
  {
    "text": "and then you know off you go you know prior to glue streaming",
    "start": "2517200",
    "end": "2522319"
  },
  {
    "text": "the etl components around glue were entirely focused around batch processing and now with glue",
    "start": "2522319",
    "end": "2529599"
  },
  {
    "text": "streaming what we can do is allow you to do a lot of that transformations inline as the data streaming through",
    "start": "2529599",
    "end": "2535760"
  },
  {
    "text": "from various streaming sources and make all of that available to you inside of your databases data lakes and",
    "start": "2535760",
    "end": "2541359"
  },
  {
    "text": "data warehouses um other portions of glue are around organizing your data in a and or the metadata in a data",
    "start": "2541359",
    "end": "2548240"
  },
  {
    "text": "catalog and a workflow system for scheduling for scheduling your jobs but the core",
    "start": "2548240",
    "end": "2555119"
  },
  {
    "text": "that piece that i think we're going to talk about today is that etl engine yeah one of the",
    "start": "2555119",
    "end": "2560160"
  },
  {
    "text": "things that you said earlier that caught my attention was how people used to do this the genesis of",
    "start": "2560160",
    "end": "2565200"
  },
  {
    "text": "this kind of etl style workflow comes from an era where everybody did everything in a single database",
    "start": "2565200",
    "end": "2571839"
  },
  {
    "text": "right and the landscape has changed so much now there's it's so much more common to see these kinds of polyglot",
    "start": "2571839",
    "end": "2577040"
  },
  {
    "text": "back ends where you have data spread across across various silos which kind of puts more of a focus on how",
    "start": "2577040",
    "end": "2582800"
  },
  {
    "text": "efficient you can make this kind of etl workflow right um so you mentioned that you mentioned",
    "start": "2582800",
    "end": "2589359"
  },
  {
    "start": "2588000",
    "end": "2707000"
  },
  {
    "text": "serverless a few times can you talk about how does that work exactly how do we wrap our heads around",
    "start": "2589359",
    "end": "2594560"
  },
  {
    "text": "that how do you apply this kind of serverless workflow to a streaming model i think that's a great question so let's",
    "start": "2594560",
    "end": "2600640"
  },
  {
    "text": "first talk about what serverless means serverless in our context means that you give us",
    "start": "2600640",
    "end": "2607200"
  },
  {
    "text": "a spark script typically these scripts are written in python scala or java those are the three",
    "start": "2607200",
    "end": "2614560"
  },
  {
    "text": "languages that are supported glue will generate those scripts for you if you need but if you want to customize those",
    "start": "2614560",
    "end": "2620800"
  },
  {
    "text": "scripts as you as you want you can you can certainly write your own and you submit those scripts and behind the scenes what we do is",
    "start": "2620800",
    "end": "2626960"
  },
  {
    "text": "we spin up the necessary resources to run those scripts at scale you don't have to spin up any machines",
    "start": "2626960",
    "end": "2634560"
  },
  {
    "text": "configure any machines configure any software do any kind of upgrades none of that so serverless is just",
    "start": "2634560",
    "end": "2640640"
  },
  {
    "text": "entirely exactly what it says as you give us the job we do the rest for you now we we have",
    "start": "2640640",
    "end": "2646480"
  },
  {
    "text": "that technology and we built that technology for jobs that you run off on a schedule for example a daily",
    "start": "2646480",
    "end": "2652640"
  },
  {
    "text": "or hourly or you know every 15 minutes but in some cases you really want to be",
    "start": "2652640",
    "end": "2657760"
  },
  {
    "text": "processing your your your data continuously and so using that same technology we now",
    "start": "2657760",
    "end": "2662960"
  },
  {
    "text": "allow you to run spark scripts that are um streaming and what that means is it's running all the",
    "start": "2662960",
    "end": "2669119"
  },
  {
    "text": "time and the underlying resources are being optimized for you continuously and so that that's how we",
    "start": "2669119",
    "end": "2675839"
  },
  {
    "text": "actually apply that technology to uh streaming jobs you give us a job that's defined as a job",
    "start": "2675839",
    "end": "2681680"
  },
  {
    "text": "taking data from uh streaming sources like kinesis or kafka that are continuously giving",
    "start": "2681680",
    "end": "2688240"
  },
  {
    "text": "your data and then what we do is we run the transformations that are in that that described in that",
    "start": "2688240",
    "end": "2694480"
  },
  {
    "text": "start spark script and then the output goes into you know one of many destinations",
    "start": "2694480",
    "end": "2700319"
  },
  {
    "text": "s3 data warehouses like redshift or other databases like jdbc databases",
    "start": "2700319",
    "end": "2707520"
  },
  {
    "start": "2707000",
    "end": "3020000"
  },
  {
    "text": "so it's really exciting to me how far sort of data pre-processing and etl technology has come in a very short time",
    "start": "2707520",
    "end": "2713680"
  },
  {
    "text": "you know we talk about spark here and glue being a fully managed serverless you know offering of spark",
    "start": "2713680",
    "end": "2719680"
  },
  {
    "text": "folks previously had to run and manage their own spark clusters and and batch was sort of the default there",
    "start": "2719680",
    "end": "2725040"
  },
  {
    "text": "right um and now as we sort of go on you know we have a serverless streaming offering",
    "start": "2725040",
    "end": "2730800"
  },
  {
    "text": "here in this launch with glue this is it's immensely exciting um and to sort of touch on you know how",
    "start": "2730800",
    "end": "2736240"
  },
  {
    "text": "easy it is to write some of this etl code you know previously there was a lot of skill that went into not just managing those clusters but",
    "start": "2736240",
    "end": "2742079"
  },
  {
    "text": "interfacing with spark using python you can use pi spark libraries and just thinly wrap some of",
    "start": "2742079",
    "end": "2747920"
  },
  {
    "text": "these very common python um data munching tools like pandas for example or apache arrow",
    "start": "2747920",
    "end": "2753359"
  },
  {
    "text": "um and and get you know the transformations you need and those work directly in spark so i'm just interested to see now with the",
    "start": "2753359",
    "end": "2759760"
  },
  {
    "text": "streaming offering you know what are the control levers here i know previously you could define maximum batch sizes and",
    "start": "2759760",
    "end": "2765200"
  },
  {
    "text": "and maybe like your max throughput for example but what does that look like for streaming now",
    "start": "2765200",
    "end": "2770480"
  },
  {
    "text": "i think that's a great question um so today what we're really focused on is is giving you the",
    "start": "2770480",
    "end": "2776480"
  },
  {
    "text": "ability to process the incoming data at the rate that it's coming in so the biggest lever",
    "start": "2776480",
    "end": "2781599"
  },
  {
    "text": "that you have with spark streaming is the amount of resources that are actually dedicated to your streaming job",
    "start": "2781599",
    "end": "2787119"
  },
  {
    "text": "it's not just a single machine that you can actually dedicate which is the nice you know the nice thing about spark",
    "start": "2787119",
    "end": "2792400"
  },
  {
    "text": "which is a distributed platform so you give us you know a sort of a maximum dpu gpu is",
    "start": "2792400",
    "end": "2798400"
  },
  {
    "text": "how we uh how we how we allocate how we measure the resources that are used behind the",
    "start": "2798400",
    "end": "2804640"
  },
  {
    "text": "scenes and then what we'll do is we'll automatically spin up just enough resources so that we can",
    "start": "2804640",
    "end": "2810160"
  },
  {
    "text": "incorporate all the the the the stream that's coming in and do all the computation over the",
    "start": "2810160",
    "end": "2815680"
  },
  {
    "text": "stream and then bring that data as i said into you know one of the various destinations so that's one of your",
    "start": "2815680",
    "end": "2821359"
  },
  {
    "text": "biggest levers another lever that you have in spark streaming and this is actually pertinent for for later downstream",
    "start": "2821359",
    "end": "2828079"
  },
  {
    "text": "analysis is how you're going to organize that data does that data get organized in a way where it's useful",
    "start": "2828079",
    "end": "2835280"
  },
  {
    "text": "for doing sql analytics or is it organized in a way where it's useful for doing some other type of analytics",
    "start": "2835280",
    "end": "2840800"
  },
  {
    "text": "and it just it depends on depending on the kind of analytics you want to do you want to organize organize your data differently",
    "start": "2840800",
    "end": "2847599"
  },
  {
    "text": "and so what spark streaming allows you to do is re-partition your data as it's coming in",
    "start": "2847599",
    "end": "2854000"
  },
  {
    "text": "based on the the attributes that are in the data and this is actually a non-trivial uh transformation you've got to buffer a",
    "start": "2854000",
    "end": "2861359"
  },
  {
    "text": "lot of data as it's coming through and make sure that it's you know allocated just right and it shows up in the in the right place",
    "start": "2861359",
    "end": "2868240"
  },
  {
    "text": "another lever that you have is of course how often um you actually load the data into one of",
    "start": "2868240",
    "end": "2874319"
  },
  {
    "text": "many destinations you can do that based on some kind of timeout so you know instead of",
    "start": "2874319",
    "end": "2879680"
  },
  {
    "text": "saying hey this is the size of your buffer you know every second every minute and that's going to control",
    "start": "2879680",
    "end": "2885359"
  },
  {
    "text": "sort of the the latency that you have for that data appearing downstream for your analytics um so",
    "start": "2885359",
    "end": "2891599"
  },
  {
    "text": "latency layout compute size are your three main levers and of course all the other levers that",
    "start": "2891599",
    "end": "2898960"
  },
  {
    "text": "you get as you're writing your spark streaming scripts in terms of",
    "start": "2898960",
    "end": "2904000"
  },
  {
    "text": "you know all the various transformations and operations that you can do for combining data for enriching data",
    "start": "2904000",
    "end": "2910880"
  },
  {
    "text": "for doing machine learning graph analytics on the fly all that is available to you at your",
    "start": "2910880",
    "end": "2917119"
  },
  {
    "text": "fingertips you mentioned the uh the real time stream processing aspect",
    "start": "2917119",
    "end": "2922400"
  },
  {
    "text": "of this kind of workload and uh with these control levers let's say i go in and define a set of resources that are",
    "start": "2922400",
    "end": "2928960"
  },
  {
    "text": "not quite sufficient to keep up with the rate of data coming in from my real-time data source uh what happens if there's a",
    "start": "2928960",
    "end": "2934880"
  },
  {
    "text": "bottleneck in the pipeline there oh i think i think that's a that's a great question one you can monitor",
    "start": "2934880",
    "end": "2941040"
  },
  {
    "text": "if there's a bottleneck in the pipeline or not because you can see the data actually backing up in some of the",
    "start": "2941040",
    "end": "2946319"
  },
  {
    "text": "sources so kafka and kinesis you can actually take a look at number of records that you kind of that are kind of building up and",
    "start": "2946319",
    "end": "2953520"
  },
  {
    "text": "you know for spark streaming jobs what you can do is you can actually just allocate more resources and it'll",
    "start": "2953520",
    "end": "2958960"
  },
  {
    "text": "automatically kind of you know scale to the number of the amount of resources you need to bring to bring the workload",
    "start": "2958960",
    "end": "2965920"
  },
  {
    "text": "um in balance with how fast you can how fast you can process that workload so it's actually pretty simple for you",
    "start": "2965920",
    "end": "2972000"
  },
  {
    "text": "to do that um today you know you still have to monitor it yourself you can either put a an actuation loop around it or",
    "start": "2972000",
    "end": "2980240"
  },
  {
    "text": "you can do it manually soon enough what we're going to do is we're going to be working on what we are",
    "start": "2980240",
    "end": "2986319"
  },
  {
    "text": "working on auto scaling technology that will automatically scale based on the amount of load that's coming in so right now",
    "start": "2986319",
    "end": "2992720"
  },
  {
    "text": "you you know you kind of pick a pretty good number and based on the number of shards that you have for example in kinesis or",
    "start": "2992720",
    "end": "2999359"
  },
  {
    "text": "um or kafka it actually works pretty well but for more bursty workloads you'll be",
    "start": "2999359",
    "end": "3005040"
  },
  {
    "text": "seeing you'll see auto scaling coming soon so is it fair to kind of draw an analogy to let's say dynamodb instead of kind of",
    "start": "3005040",
    "end": "3010960"
  },
  {
    "text": "saying the amount of provision read and write units i'm going to want up front i can choose a an on-demand version of",
    "start": "3010960",
    "end": "3016800"
  },
  {
    "text": "that instead exactly that's exactly right well when we we cover a lot of launches",
    "start": "3016800",
    "end": "3022800"
  },
  {
    "start": "3020000",
    "end": "3294000"
  },
  {
    "text": "on this show and and while for some you know if it's a very foundational technology in the stack even incremental percentages are",
    "start": "3022800",
    "end": "3028640"
  },
  {
    "text": "important something that's really cool here to me is is how much of a game changer this launches for the actual",
    "start": "3028640",
    "end": "3034800"
  },
  {
    "text": "architectures for managing etl on streaming or uh streaming implementations right",
    "start": "3034800",
    "end": "3040640"
  },
  {
    "text": "this is not something that's very trivial to launch and i think that maybe walking through some of the ways customers tried to implement this",
    "start": "3040640",
    "end": "3047040"
  },
  {
    "text": "previously will be a really strong testament to that again these are still performant architectures but when we think about",
    "start": "3047040",
    "end": "3053040"
  },
  {
    "text": "having a truly purpose-built uh sort of tool having streaming for glue here really does change the game",
    "start": "3053040",
    "end": "3058640"
  },
  {
    "text": "uh so you know could could you walk through some of the architectures that we've seen customers use to try and implement",
    "start": "3058640",
    "end": "3063839"
  },
  {
    "text": "you know streaming etl previously sure um so uh as you can imagine",
    "start": "3063839",
    "end": "3070000"
  },
  {
    "text": "uh because everything is based on spark uh we've seen customers actually you know roll their own uh streaming",
    "start": "3070000",
    "end": "3075839"
  },
  {
    "text": "architectures uh using a variety of of services so you could just for example run spark on ec2",
    "start": "3075839",
    "end": "3083599"
  },
  {
    "text": "or um you could actually use emr which is our managed hadoop offering and you can run spark on those offerings",
    "start": "3083599",
    "end": "3091040"
  },
  {
    "text": "now of course you get you get similar benefits of being able to run spark scripts",
    "start": "3091040",
    "end": "3096079"
  },
  {
    "text": "that make it easy for you to incorporate and and sort of uh run analysis in real time but the the",
    "start": "3096079",
    "end": "3102480"
  },
  {
    "text": "benefits around server lists aren't there you still have to manage all of those virtual machines you have to know how how to configure",
    "start": "3102480",
    "end": "3109599"
  },
  {
    "text": "those virtual machines you have to monitor if those machines are going down so new machines can come back up",
    "start": "3109599",
    "end": "3115760"
  },
  {
    "text": "um you just you know you're basically doing both uh system administration as well as as",
    "start": "3115760",
    "end": "3122400"
  },
  {
    "text": "as as running your your streaming jobs and now at least that entire component",
    "start": "3122400",
    "end": "3127520"
  },
  {
    "text": "is completely gone um another alternative is for people to you know use existing",
    "start": "3127520",
    "end": "3133680"
  },
  {
    "text": "streaming platforms like kinesis to get their data into a data lake or a data warehouse",
    "start": "3133680",
    "end": "3140559"
  },
  {
    "text": "kinesis fire hose is actually a great example it's a very popular product the challenge with uh of products like",
    "start": "3140559",
    "end": "3146880"
  },
  {
    "text": "kinesis fire hose is that it's really intended for getting the data into the destination",
    "start": "3146880",
    "end": "3152000"
  },
  {
    "text": "and you can't really do very complex on-the-fly analytics as the data is coming by and sometimes",
    "start": "3152000",
    "end": "3158880"
  },
  {
    "text": "you really need to do that for example if you want to enrich your data as the data is coming by",
    "start": "3158880",
    "end": "3164559"
  },
  {
    "text": "with data coming from say a a customer profile database so that people know what to do",
    "start": "3164559",
    "end": "3170559"
  },
  {
    "text": "with the you know customer records or transactions that are coming through or imagine you want to join two",
    "start": "3170559",
    "end": "3176319"
  },
  {
    "text": "streams together one coming from you know sort of an ingress and another one coming from say",
    "start": "3176319",
    "end": "3181440"
  },
  {
    "text": "an egress to find out the common you know packets that are coming through um you won't be able to do those kinds",
    "start": "3181440",
    "end": "3187200"
  },
  {
    "text": "of things on the fly uh with something like uh with kinesis firehose uh you have to do it",
    "start": "3187200",
    "end": "3192559"
  },
  {
    "text": "post hoc talk here you'll be able to do it you know in line another example is fraud detection or",
    "start": "3192559",
    "end": "3199599"
  },
  {
    "text": "machine learning that you can again implement in spark streaming that you have to do post hoc",
    "start": "3199599",
    "end": "3204800"
  },
  {
    "text": "um when you're using a a traditional streaming service just to get the data",
    "start": "3204800",
    "end": "3209839"
  },
  {
    "text": "into into a data roster data lake so the idea that you can do complex undefined analytics is very powerful so both the ability to",
    "start": "3209839",
    "end": "3218480"
  },
  {
    "text": "you know avoid all of the system administration and management and also insert complex analytics on the",
    "start": "3218480",
    "end": "3225839"
  },
  {
    "text": "fly i think are the two two main value propositions here that uh that we've enabled with live streaming",
    "start": "3225839",
    "end": "3232160"
  },
  {
    "text": "yeah it really feels like again best of both worlds you just covered it it's you know you get all the customizability of of manage it working",
    "start": "3232160",
    "end": "3238720"
  },
  {
    "text": "directly with spark but then you don't have to use some of these workarounds that can increase latency for actually performing complex",
    "start": "3238720",
    "end": "3244640"
  },
  {
    "text": "real-time analytics um that you know the fire hose to s3 to lambda to another s3 to another",
    "start": "3244640",
    "end": "3250559"
  },
  {
    "text": "lambda may actually pose so very exciting and again anytime we can sort of streamline the number of",
    "start": "3250559",
    "end": "3255920"
  },
  {
    "text": "services folks need to use or the amount of system administration or undifferentiated heavy lifting",
    "start": "3255920",
    "end": "3260960"
  },
  {
    "text": "that's always a win in my book so you know i'm sold i know this sounds",
    "start": "3260960",
    "end": "3267680"
  },
  {
    "text": "very easy to use but is there any chance we'd be able to actually see this in action",
    "start": "3267680",
    "end": "3272800"
  },
  {
    "text": "um absolutely we have our product manager andy betty um who's uh ready with a demo",
    "start": "3272800",
    "end": "3279200"
  },
  {
    "text": "um to show you uh show you an example of how actually you can use it uh for a very relevant use case today okay",
    "start": "3279200",
    "end": "3286640"
  },
  {
    "text": "awesome so we're gonna actually take a quick like five second break i don't know what you'll be able to do in five seconds but",
    "start": "3286640",
    "end": "3291920"
  },
  {
    "text": "hang in there we will be right back a little longer than five seconds but we're back just like i promised so again",
    "start": "3291920",
    "end": "3298480"
  },
  {
    "start": "3294000",
    "end": "3599000"
  },
  {
    "text": "here joining us to show us a demo of glue streaming etl is andy from the glue uh",
    "start": "3298480",
    "end": "3304480"
  },
  {
    "text": "aws glue team andy thank you for joining us thanks for having me cool so uh why",
    "start": "3304480",
    "end": "3310000"
  },
  {
    "text": "don't you walk us through exactly what we're gonna see here with glue streaming etl uh absolutely",
    "start": "3310000",
    "end": "3315359"
  },
  {
    "text": "uh so today i'm gonna demonstrate how streaming detail functionality in aws glue",
    "start": "3315359",
    "end": "3320720"
  },
  {
    "text": "allows you to ingest streaming data like iot logs uh and move them into a data lake so",
    "start": "3320720",
    "end": "3326319"
  },
  {
    "text": "that the records are available for analysis in near real time like michael was discussing a little bit",
    "start": "3326319",
    "end": "3331599"
  },
  {
    "text": "earlier all right in this example uh we're going to be simulating logs",
    "start": "3331599",
    "end": "3337040"
  },
  {
    "text": "from medical ventilators like those being used in hospitals during the current pandemic",
    "start": "3337040",
    "end": "3343279"
  },
  {
    "text": "this is the log format we're using uh it contains metrics like oxygen level pressure",
    "start": "3344720",
    "end": "3350640"
  },
  {
    "text": "device serial number and manufacturer we're sending these logs over an amazon kinesis data stream",
    "start": "3350640",
    "end": "3357599"
  },
  {
    "text": "processing them using aws glue and then writing them to an amazon s3 based data lake so the first thing",
    "start": "3357599",
    "end": "3365119"
  },
  {
    "text": "that i'm going to show you is that the data stream is being populated so i'm going to go here to the amazon kinesis data streams",
    "start": "3365119",
    "end": "3372319"
  },
  {
    "text": "console and in these charts you can see that there's data coming over the stream",
    "start": "3372319",
    "end": "3377839"
  },
  {
    "text": "the next thing i'm going to show you is the uh aws glue console this is the glue jobs",
    "start": "3377839",
    "end": "3385119"
  },
  {
    "text": "console and you can see here that we've got a spark streaming job",
    "start": "3385119",
    "end": "3390240"
  },
  {
    "text": "uh currently running it's been running for over 19 hours now and uh because uh streaming etl jobs can",
    "start": "3390240",
    "end": "3398799"
  },
  {
    "text": "run indefinitely i haven't set a timeout on this one and it'll continue running until i shut it down",
    "start": "3398799",
    "end": "3405839"
  },
  {
    "text": "on this screen you can see the script that michael was talking about earlier uh it was so aws glue generates the",
    "start": "3405839",
    "end": "3412799"
  },
  {
    "text": "script for you so you don't have to write spark code yourself to get started with streaming",
    "start": "3412799",
    "end": "3417920"
  },
  {
    "text": "etl but if you're familiar with spark's structured streaming code it's easy to customize the starting",
    "start": "3417920",
    "end": "3424640"
  },
  {
    "text": "point that glue gives you for your own needs this particular job is like i said",
    "start": "3424640",
    "end": "3431040"
  },
  {
    "text": "reading data from the amazon kinesis stream it's converting the data format then writing it to s3",
    "start": "3431040",
    "end": "3437359"
  },
  {
    "text": "it's also updating the glue data catalog so that it's available for analytics services like amazon athena and amazon",
    "start": "3437359",
    "end": "3443599"
  },
  {
    "text": "quicksite which i'm going to show you next so first we're going to start with amazon athena let's see what data",
    "start": "3443599",
    "end": "3449920"
  },
  {
    "text": "that we've processed so on this screen on the left you can actually see the",
    "start": "3449920",
    "end": "3455040"
  },
  {
    "text": "data table that the streaming etl job is populating note here",
    "start": "3455040",
    "end": "3461040"
  },
  {
    "text": "that these items marked partitioned one of the cool features of streaming",
    "start": "3461040",
    "end": "3466640"
  },
  {
    "text": "etl in aws glue is that you can organize the data not just by",
    "start": "3466640",
    "end": "3471760"
  },
  {
    "text": "year month and day but by the contents of the data itself and so in this case",
    "start": "3471760",
    "end": "3476799"
  },
  {
    "text": "the manufacturer field in each record and you just saw this query complete over here",
    "start": "3476799",
    "end": "3483200"
  },
  {
    "text": "and as you can see this data arrived just moments ago uh",
    "start": "3483200",
    "end": "3488640"
  },
  {
    "text": "seconds ago it's 103 on my clock and it's 102 for this last most recent record so",
    "start": "3488640",
    "end": "3494400"
  },
  {
    "text": "you're able to analyze the data in very close to real time i'm also going",
    "start": "3494400",
    "end": "3499760"
  },
  {
    "text": "to show you dashboards that are built on the same data so that you can do more online analysis",
    "start": "3499760",
    "end": "3506799"
  },
  {
    "text": "so this is a simple dashboard that's built in amazon quick site",
    "start": "3508240",
    "end": "3513280"
  },
  {
    "text": "and in this first chart you can see the rate at which data is coming over the stream and being written to s3 so that it's",
    "start": "3513280",
    "end": "3521040"
  },
  {
    "text": "ready for analysis now imagine in this case that we want to check on whether",
    "start": "3521040",
    "end": "3526240"
  },
  {
    "text": "there's a problem with the hypothetical ventilators that we're simulating we can use these second two charts to",
    "start": "3526240",
    "end": "3532559"
  },
  {
    "text": "see if there are anomalies in the data as well as to identify where the problem lies",
    "start": "3532559",
    "end": "3538079"
  },
  {
    "text": "so as you can see you know these oxygen levels do have anomalies and in the second chart we can look here",
    "start": "3538079",
    "end": "3544240"
  },
  {
    "text": "and see that the problem seems to be with devices manufactured by acme corporation",
    "start": "3544240",
    "end": "3549680"
  },
  {
    "text": "uh and in the real world that we might go and investigate those devices to see what the problem is",
    "start": "3549680",
    "end": "3556880"
  },
  {
    "text": "so these are just a couple of examples of what you can do with this new functionality",
    "start": "3556880",
    "end": "3562880"
  },
  {
    "text": "so in the demo i showed you how streaming utl in aws glue allows you to move streaming data into",
    "start": "3562880",
    "end": "3569520"
  },
  {
    "text": "your data lake in just seconds uh and makes it available for both batch and online analysis",
    "start": "3569520",
    "end": "3575040"
  },
  {
    "text": "using aws analytics services uh and so for more information uh we've got an aws blog post on this",
    "start": "3575040",
    "end": "3581599"
  },
  {
    "text": "topic as well as documentation that's available today aws glue a purpose-built etl solution",
    "start": "3581599",
    "end": "3587680"
  },
  {
    "text": "that uh service from from aws that enables entirely serverless etl",
    "start": "3587680",
    "end": "3592720"
  },
  {
    "text": "now affording streaming uh streaming capabilities for streaming etl so rather than having to stream together a",
    "start": "3592720",
    "end": "3598880"
  },
  {
    "text": "bunch of services in what would otherwise still be an event-driven architecture you can now take a uh like a data stream",
    "start": "3598880",
    "end": "3605760"
  },
  {
    "text": "like kinesis uh kafka apache ms or amazon msk managed service for kafka and now",
    "start": "3605760",
    "end": "3611920"
  },
  {
    "text": "directly thai glue streaming etl jobs as either ongoing or or time gated",
    "start": "3611920",
    "end": "3618000"
  },
  {
    "text": "as a consumer of the data from the stream to deliver real-time data processing awesome very very exciting stuff",
    "start": "3618000",
    "end": "3625280"
  },
  {
    "text": "let's see right now if we have any further questions from chat i'm not seeing anything else on my end",
    "start": "3625280",
    "end": "3630799"
  },
  {
    "text": "uh but again andy and previously mehul whose name is on the screen right now thank you again for joining us to show us a little bit",
    "start": "3630799",
    "end": "3637200"
  },
  {
    "text": "about this very exciting launch um for streaming etl for aws glue",
    "start": "3637200",
    "end": "3643838"
  },
  {
    "text": "thanks for having me yeah any time all right well next up we have a very exciting launch",
    "start": "3644240",
    "end": "3649760"
  },
  {
    "text": "i know i say this every single time but again there are just so many very exciting launches to get through here on the show",
    "start": "3649760",
    "end": "3655119"
  },
  {
    "text": "um next up we are going to have a deep dive on amazon augmented ai i also abbreviated",
    "start": "3655119",
    "end": "3660799"
  },
  {
    "text": "a2i uh so if any of you are interested in that stick around we will be right back all right we're at the midway",
    "start": "3660799",
    "end": "3667920"
  },
  {
    "text": "point here on the show we have two demos down and we've got two more to go but before we get into the next one",
    "start": "3667920",
    "end": "3673680"
  },
  {
    "text": "we've got an exciting opportunity for everyone here who's tuning in yeah that's right we have ten dollars of",
    "start": "3673680",
    "end": "3680160"
  },
  {
    "text": "promotional aws credits if you can help us fill out a survey let us know how we're doing what topics you'd like to see what topics you",
    "start": "3680160",
    "end": "3687359"
  },
  {
    "text": "want to see less of perhaps but just give us feedback because a lot of the stuff that we do",
    "start": "3687359",
    "end": "3692559"
  },
  {
    "text": "is centered around what you want to see and it really helps us improve the show so please do us a favor go fill out the survey and uh we'll have",
    "start": "3692559",
    "end": "3700480"
  },
  {
    "text": "a link in the chat where you can go and visit to uh get that credit code and file the",
    "start": "3700480",
    "end": "3705599"
  },
  {
    "text": "survey for us and it just takes a few seconds it's very brief i promise okay enough of the the survey pitching",
    "start": "3705599",
    "end": "3712160"
  },
  {
    "text": "again check that out if you'd like to help improve the show or get some aws credits but more importantly we've got another exciting",
    "start": "3712160",
    "end": "3718640"
  },
  {
    "text": "demo lined up for all of you so without further ado with the magic of production",
    "start": "3718640",
    "end": "3724000"
  },
  {
    "text": "we have anuj gupta senior technical product manager from amazon augmented ai joining us",
    "start": "3724000",
    "end": "3729039"
  },
  {
    "text": "today to talk a little bit about this very exciting service that has recently gone generally available anuj thanks for",
    "start": "3729039",
    "end": "3735359"
  },
  {
    "text": "joining us why don't you tell us a little bit about amazon augmented yep definitely thanks",
    "start": "3735359",
    "end": "3740559"
  },
  {
    "text": "for having me over here so amazon augmented air is a new service we launched in the preview air train",
    "start": "3740559",
    "end": "3745920"
  },
  {
    "text": "when 2019 so a few months back and based on the customer feedback we went general availability in 12 regions uh on",
    "start": "3745920",
    "end": "3754480"
  },
  {
    "text": "24th april like just two three weeks back um inherently like before we get into a toy or",
    "start": "3754480",
    "end": "3760960"
  },
  {
    "text": "augmented ai let's talk a bit about machine learning in general so machine learning models a lot of them inherently give you",
    "start": "3760960",
    "end": "3767039"
  },
  {
    "text": "probabilistic answers so machine learning model is going to tell you it's like 80 percent confident",
    "start": "3767039",
    "end": "3772319"
  },
  {
    "text": "or it's 90 confident that a dog is present in this photo or not uh many of the times there are not like",
    "start": "3772319",
    "end": "3778480"
  },
  {
    "text": "black and white answers and these kind of scenarios whenever the machine learning model is not confident",
    "start": "3778480",
    "end": "3784559"
  },
  {
    "text": "or as we call it like it's a low confidence result you want a human to come in and have a",
    "start": "3784559",
    "end": "3789920"
  },
  {
    "text": "look at that piece of data and say whether it's a dog or a cat or something else so people want to conditionally route",
    "start": "3789920",
    "end": "3796880"
  },
  {
    "text": "their machine learning inferences for a human uh to have a look at and make sure like they are getting",
    "start": "3796880",
    "end": "3802720"
  },
  {
    "text": "consistently highly accurate is accurate results from their workflows so",
    "start": "3802720",
    "end": "3807760"
  },
  {
    "text": "you know i've worked to design a lot of machine learning systems in the past and and sort of what you're describing is folks",
    "start": "3807760",
    "end": "3813680"
  },
  {
    "text": "want the auto automatability and the speed and the cost savings that come along with automated machine learning oriented",
    "start": "3813680",
    "end": "3819520"
  },
  {
    "text": "inferences but they also have situations where they want to have this sort of higher quality uh higher cost human review and it's",
    "start": "3819520",
    "end": "3827440"
  },
  {
    "text": "hard to build previous systems have done either entirely one or the other but there's been a lot of customers that are trying",
    "start": "3827440",
    "end": "3832720"
  },
  {
    "text": "to sort of build a hybrid system before uh and this is no small feat",
    "start": "3832720",
    "end": "3838640"
  },
  {
    "text": "yep yep definitely i mean uh customers either have to go to like ml only route or they have to go to like",
    "start": "3838640",
    "end": "3844240"
  },
  {
    "text": "100 human-only route but at the end of the day customers have been telling us they want like the scale and the speed of the machine",
    "start": "3844240",
    "end": "3850880"
  },
  {
    "text": "learning and they really want to use the human intelligence where it's truly truly needed and then",
    "start": "3850880",
    "end": "3856640"
  },
  {
    "text": "there's a large demand for it like people also want to use human oversight to really make sure they",
    "start": "3856640",
    "end": "3862400"
  },
  {
    "text": "can trust their machine learning models whether it's internally or externally and we were fortunate enough to work",
    "start": "3862400",
    "end": "3868400"
  },
  {
    "text": "with t-mobile as a customer even before our launch uh where they were trying to build this machine learning trust within their",
    "start": "3868400",
    "end": "3875359"
  },
  {
    "text": "organization by randomly selecting let's say 10 or 20 of the data and then passing it",
    "start": "3875359",
    "end": "3881119"
  },
  {
    "text": "for a human review and this way you can really make sure that your machine learning model is giving you the output",
    "start": "3881119",
    "end": "3886640"
  },
  {
    "text": "you expect and people can calculate like machine learning metrics like accuracy precision",
    "start": "3886640",
    "end": "3892079"
  },
  {
    "text": "and things like that so if i recall back to the you know the big picture machine",
    "start": "3892079",
    "end": "3898960"
  },
  {
    "text": "learning workflow you know you start with a data set you go through labeling you go through training and then you know you optimize this",
    "start": "3898960",
    "end": "3904799"
  },
  {
    "text": "thing you deploy into a fleet you do some inference this is a very large set of tasks to do can you kind of",
    "start": "3904799",
    "end": "3910319"
  },
  {
    "text": "situate us within that that space where exactly does adai fit in",
    "start": "3910319",
    "end": "3915359"
  },
  {
    "text": "yep yep definitely so as you um kind of pointed out probably there are multiple steps in a machine learning pipeline",
    "start": "3915359",
    "end": "3921200"
  },
  {
    "text": "or the workflow that customers take the first step is training your data set uh and once you have a very good data",
    "start": "3921200",
    "end": "3927680"
  },
  {
    "text": "set you can train your machine learning models and aws provides a lot of different services like sagemaker sagemaker ground",
    "start": "3927680",
    "end": "3934079"
  },
  {
    "text": "truth to help you really train the model then you can deploy your machine learning models into production",
    "start": "3934079",
    "end": "3939839"
  },
  {
    "text": "and you start like serving the inferences or start serving the production data through your machine learning model and that's where really",
    "start": "3939839",
    "end": "3946160"
  },
  {
    "text": "hy comes in hy can pick up the low confidence predictions from your machine learning models",
    "start": "3946160",
    "end": "3951920"
  },
  {
    "text": "whether it's hosted on siege maker whether it's any of the aws ai service like recognition text track or even if",
    "start": "3951920",
    "end": "3958640"
  },
  {
    "text": "you are having like machine learning models hosted on any of the other cloud providers or any other places you can bring in those low",
    "start": "3958640",
    "end": "3965039"
  },
  {
    "text": "confidence predictions and you as a customer have complete flexibility in defining what is low confidence for you",
    "start": "3965039",
    "end": "3971200"
  },
  {
    "text": "and you can bring in that low confidence production and ask a human to review it in the inference stage which is generally",
    "start": "3971200",
    "end": "3977680"
  },
  {
    "text": "the step three or step four of the machine learning workflow overall so what we really start to see here is",
    "start": "3977680",
    "end": "3983920"
  },
  {
    "text": "this spectrum where if we don't have to go full human or full ai model automation we have the ability to conditionally route our",
    "start": "3983920",
    "end": "3990240"
  },
  {
    "text": "requests as we desire and you hit on the topic of you know confident or good enough responses",
    "start": "3990240",
    "end": "3996799"
  },
  {
    "text": "um are subjective right i would very much think we would all be in agreeance that the confidence value we want for",
    "start": "3996799",
    "end": "4002079"
  },
  {
    "text": "detecting a medical condition will be substantially higher than you know some sort of much lower level task that has a smaller blast radius",
    "start": "4002079",
    "end": "4008720"
  },
  {
    "text": "right um and so again you mentioned customers can entirely set the threshold for routing these requests um",
    "start": "4008720",
    "end": "4014960"
  },
  {
    "text": "you know when i think about this this uh this largely sounds like a you know very undifferentiated problem",
    "start": "4014960",
    "end": "4021680"
  },
  {
    "text": "right like anybody implementing an ai or ml system is going to face this at some point regardless of whether i'm trying to classify cats or dogs",
    "start": "4021680",
    "end": "4028000"
  },
  {
    "text": "or corn from apples right so the ability to offer this as a service in augmented ai sounds",
    "start": "4028000",
    "end": "4034880"
  },
  {
    "text": "really appealing to me i'd much rather use a managed service here than to have to build this from scratch so i'm curious that i'm going to pose",
    "start": "4034880",
    "end": "4041520"
  },
  {
    "text": "the question to you now you said there's a lot of flexibility i can i can alter the confidence threshold what does it actually look like to use augmented",
    "start": "4041520",
    "end": "4047760"
  },
  {
    "text": "ai yeah yeah definitely so uh there are kind of two steps as we define in using",
    "start": "4047760",
    "end": "4053359"
  },
  {
    "text": "augmented ai the first step we call is the initial configuration uh and in this first step you as a customer",
    "start": "4053359",
    "end": "4059440"
  },
  {
    "text": "have complete flexibility in defining like what does your data look like what is the low confidence result for you",
    "start": "4059440",
    "end": "4065520"
  },
  {
    "text": "or if you want to do random sampling you can define those conditions you can define what is the choice of",
    "start": "4065520",
    "end": "4070880"
  },
  {
    "text": "human review workforce you want to use so with a2i you have options to use amazon mechanical turk as a workforce",
    "start": "4070880",
    "end": "4077520"
  },
  {
    "text": "you can use any of the vendors listed on aws marketplace or you can even bring your own uh",
    "start": "4077520",
    "end": "4082720"
  },
  {
    "text": "employees or your own private workforce on the hy platform so and then the next thing you",
    "start": "4082720",
    "end": "4088880"
  },
  {
    "text": "also have to do kind of as a part of initial configuration is like what is going to be that ui or what is that user interface that",
    "start": "4088880",
    "end": "4095680"
  },
  {
    "text": "people are going to see when they review these machine learning predictions once you do this initial",
    "start": "4095680",
    "end": "4101040"
  },
  {
    "text": "setup and all of this can be done through very easily on console and i can quickly show you that as well uh once you do this initial setup the",
    "start": "4101040",
    "end": "4108159"
  },
  {
    "text": "next step is to start using aui so you can uh directly call hy apis in",
    "start": "4108159",
    "end": "4113199"
  },
  {
    "text": "case you're using an ehr in your custom machine learning models or in case you are using hybrid let's",
    "start": "4113199",
    "end": "4118560"
  },
  {
    "text": "say pre-integrated services like recognition in text drug uh and these are like amazon recognition",
    "start": "4118560",
    "end": "4123679"
  },
  {
    "text": "and amazon extractor aws ai services you can just pass in a single parameter",
    "start": "4123679",
    "end": "4129278"
  },
  {
    "text": "in your extractor recognition calls and it will conditionally route to a ui so to kind of recap like the first step",
    "start": "4129279",
    "end": "4136080"
  },
  {
    "text": "is do your configuration really set it up what you want and then the second step is just start using it",
    "start": "4136080",
    "end": "4142719"
  },
  {
    "text": "so this starts to bring in the conversation around observability and behavior for a machine learning system we mentioned before that there's",
    "start": "4142719",
    "end": "4149199"
  },
  {
    "text": "things on the training side again ati focused on observability and control over the inference side",
    "start": "4149199",
    "end": "4155120"
  },
  {
    "text": "you mentioned a lot of different options for bringing my own model i heard you say sage maker or text track recognition",
    "start": "4155120",
    "end": "4160560"
  },
  {
    "text": "which are managed ai services from aws um but in all honesty it sounds like i should be able to plug any sort of model",
    "start": "4160560",
    "end": "4166960"
  },
  {
    "text": "uh machine learning model into a2i are there any other options like what is the breadth of options",
    "start": "4166960",
    "end": "4172318"
  },
  {
    "text": "available there yeah the breadth of options is completely like up to the uh customer like we do not uh let's say uh",
    "start": "4172319",
    "end": "4179679"
  },
  {
    "text": "like restrict in any way has to say uh so customer like hy apis are public",
    "start": "4179679",
    "end": "4184719"
  },
  {
    "text": "uh customers can directly use a2 api so in case customer is hosting their model on",
    "start": "4184719",
    "end": "4190318"
  },
  {
    "text": "sagemaker on case customer is hosting their custom comprehend model or in case customer is using",
    "start": "4190319",
    "end": "4196480"
  },
  {
    "text": "amazon extract or amazon recognition or in case customer has like some of the machine learning models on",
    "start": "4196480",
    "end": "4202320"
  },
  {
    "text": "other cloud providers or on on data and things like that as well they can still use a2i because",
    "start": "4202320",
    "end": "4207360"
  },
  {
    "text": "inherently customers have been telling us they need human in the loop irrespective of the fact where their machine learning",
    "start": "4207360",
    "end": "4213360"
  },
  {
    "text": "models are and you want to make sure customers can like really use this human in the loop capability",
    "start": "4213360",
    "end": "4219600"
  },
  {
    "text": "that's super exciting i know you that was like a subtle footnote thrown in there at the end but essentially anyone can front an ml api",
    "start": "4219600",
    "end": "4227440"
  },
  {
    "text": "regardless of whether it's a rolled custom model on another cloud provider and even a managed service on another",
    "start": "4227440",
    "end": "4232560"
  },
  {
    "text": "cloud provider and actually access easy off-the-shelf human and loop functionality by uh you know sending those requests",
    "start": "4232560",
    "end": "4239679"
  },
  {
    "text": "through amazon e2i yeah before we go on i i want to call out an interesting uh question",
    "start": "4239679",
    "end": "4245920"
  },
  {
    "text": "in chat by runner g underscore imagine i don't think he was being serious but he asked you know is is bill vert",
    "start": "4245920",
    "end": "4252800"
  },
  {
    "text": "a human or a bot now i know you work with your teammate um yeah i i think it's a",
    "start": "4252800",
    "end": "4259360"
  },
  {
    "text": "silly question but it kind of brings up the point you know let's say let's take this kind of chat support uh",
    "start": "4259360",
    "end": "4265040"
  },
  {
    "text": "and automated question and answer kind of use case you know we've seen this as one of the most",
    "start": "4265040",
    "end": "4270960"
  },
  {
    "text": "common use cases for ai and ml um how applicable is adai",
    "start": "4270960",
    "end": "4276719"
  },
  {
    "text": "in this case is it applicable at all yeah yeah definitely as i mentioned like uh whenever let's say you are doing any",
    "start": "4276719",
    "end": "4283199"
  },
  {
    "text": "kind of machine learning application you can like let ml take the majority of the workload through its predictions so even in this scenario as",
    "start": "4283199",
    "end": "4290159"
  },
  {
    "text": "well like ml can be responding to let's say your customers wherever you think you can provide a",
    "start": "4290159",
    "end": "4295280"
  },
  {
    "text": "good service through ml alone and again you as a customer has preference of choosing what is that good enough",
    "start": "4295280",
    "end": "4300400"
  },
  {
    "text": "service for your use case and you can ask let's say a human to come in and provide some answers or",
    "start": "4300400",
    "end": "4305840"
  },
  {
    "text": "provide additional data or flag it for someone to review in an offline manner",
    "start": "4305840",
    "end": "4310880"
  },
  {
    "text": "and really use that human intelligence wherever you need it and just to kind of i think rob you bring up",
    "start": "4310880",
    "end": "4316320"
  },
  {
    "text": "a very interesting use case but like there are a lot of other use cases we see in this kind of a domain like",
    "start": "4316320",
    "end": "4321600"
  },
  {
    "text": "whether it's document processing or image analytics or video processing or advertising or medical field like we",
    "start": "4321600",
    "end": "4328320"
  },
  {
    "text": "see a lot of different applications where people want to use the symbiosis of humans and ml together",
    "start": "4328320",
    "end": "4335199"
  },
  {
    "text": "so we talk through the chatbot scenario right here again sort of low confidence sort of inferences to a human uh are",
    "start": "4335199",
    "end": "4341360"
  },
  {
    "text": "there any customers that have been using a2i that we can sort of share their experience with as a testament to",
    "start": "4341360",
    "end": "4347280"
  },
  {
    "text": "the value that they they receive by using this yeah in addition to the t-mobile example that i shared like a",
    "start": "4347280",
    "end": "4352800"
  },
  {
    "text": "few moments back like we uh we were fortunate enough to work with national health services in uk",
    "start": "4352800",
    "end": "4358400"
  },
  {
    "text": "so national health services business service authority is a uh public organization it's a government",
    "start": "4358400",
    "end": "4363440"
  },
  {
    "text": "organization in uk and they process medical prescriptions for uk citizens",
    "start": "4363440",
    "end": "4368719"
  },
  {
    "text": "they process um approximately 54 million prescriptions per month and that's a lot of volume and these",
    "start": "4368719",
    "end": "4374239"
  },
  {
    "text": "prescriptions could be either printed hand written and they come in a lot of variety like when you're dealing with such a large",
    "start": "4374239",
    "end": "4380400"
  },
  {
    "text": "kind of data the standardization uh gets kind of really tricky and they want to extract with a very high",
    "start": "4380400",
    "end": "4386239"
  },
  {
    "text": "confidence the details like what is the prescription what is the name of the person what is the drug and",
    "start": "4386239",
    "end": "4392480"
  },
  {
    "text": "these kind of use cases are very critical like you won't want anything uh going wrong",
    "start": "4392480",
    "end": "4397600"
  },
  {
    "text": "in this kind of a use case and they are using uh machine learning they look forward to using",
    "start": "4397600",
    "end": "4402800"
  },
  {
    "text": "machine learning and in this case amazon takes track for a lot of their workloads and really",
    "start": "4402800",
    "end": "4408960"
  },
  {
    "text": "include or call upon the human intelligence where it's truly needed and they can have the",
    "start": "4408960",
    "end": "4414320"
  },
  {
    "text": "accuracy of the human intelligence with the speed and automation of ml uh interestingly this is a customer also",
    "start": "4414320",
    "end": "4420640"
  },
  {
    "text": "referenced on our augmented ar website i will highly encourage to read more about that in case you guys are interested",
    "start": "4420640",
    "end": "4428719"
  },
  {
    "text": "wonderful so again you know any sort of aiml model whether it's sort of a you know a chat bot or a text prediction",
    "start": "4430480",
    "end": "4436640"
  },
  {
    "text": "model whether it is ocr in the form of text tracks for prescription processing uh we mentioned recognition as another",
    "start": "4436640",
    "end": "4443840"
  },
  {
    "text": "uh sort of common use case here for for maybe image recognition or or object classification",
    "start": "4443840",
    "end": "4449520"
  },
  {
    "text": "um do we have any customers using that that we can talk about yep yep definitely so um let me talk",
    "start": "4449520",
    "end": "4455679"
  },
  {
    "text": "about this customer bid mob uh wig mom is a creative ad agency and uh again we were fortunate enough to",
    "start": "4455679",
    "end": "4461280"
  },
  {
    "text": "work with them they used uh recognition video to extract a lot of data from their advertising videos so",
    "start": "4461280",
    "end": "4469280"
  },
  {
    "text": "they process and create like a lot of intelligence around these ads that are created and they really",
    "start": "4469280",
    "end": "4474320"
  },
  {
    "text": "want to make sure that they are able to not only provide why did a ad perform like or how did the",
    "start": "4474320",
    "end": "4480560"
  },
  {
    "text": "ad perform but why did it perform the way it did and uh this customer using",
    "start": "4480560",
    "end": "4485679"
  },
  {
    "text": "amazon recognition their customer model and amazon hoi they were able to make their workflows",
    "start": "4485679",
    "end": "4491120"
  },
  {
    "text": "over 90 efficient and another thing was like because they could rely on a human backstop this",
    "start": "4491120",
    "end": "4498400"
  },
  {
    "text": "means that they couldn't push their machine learning models into production really quickly they don't have to wait",
    "start": "4498400",
    "end": "4504239"
  },
  {
    "text": "for their machine learning models to be really perfect over a long period of time you know that there's a human backstop",
    "start": "4504239",
    "end": "4510239"
  },
  {
    "text": "that's going to catch any of the low confidence stuff and they were able to decrease their time to market by 3x",
    "start": "4510239",
    "end": "4516800"
  },
  {
    "text": "and again this is a reference customer available on our website as well uh really really happy and glad to be",
    "start": "4516800",
    "end": "4522480"
  },
  {
    "text": "working with customers like these the time to market thing is very interesting i that had not really",
    "start": "4522480",
    "end": "4528239"
  },
  {
    "text": "occurred to me as one of the main benefits of using a hybrid model like this but now that you mention it it's kind of",
    "start": "4528239",
    "end": "4533760"
  },
  {
    "text": "uh it's it's very powerful yeah i mean definitely because like customers",
    "start": "4533760",
    "end": "4539120"
  },
  {
    "text": "keep on telling us like they want to use the machine learning but uh they also want to start using it quickly and all of us know like",
    "start": "4539120",
    "end": "4546000"
  },
  {
    "text": "uh deploying a machine learning model requires a bunch of talent uh aws provides a bunch of services to",
    "start": "4546000",
    "end": "4551120"
  },
  {
    "text": "help customers in this area but a2i can really help customers really push their models into production",
    "start": "4551120",
    "end": "4556960"
  },
  {
    "text": "quickly knowing that there's a human backstop yeah yeah definitely i i really want to see a demo now i",
    "start": "4556960",
    "end": "4564080"
  },
  {
    "text": "we've talked so much about this service there's there's so much going on here and i think",
    "start": "4564080",
    "end": "4569199"
  },
  {
    "text": "uh i i can't be the only person who's really on the edge of my seat waiting for a demo",
    "start": "4569199",
    "end": "4574400"
  },
  {
    "text": "awesome definitely uh let me share my screen over here",
    "start": "4574400",
    "end": "4580880"
  },
  {
    "text": "okay so i'm just gonna go into uh my aws account over here um and i'm going to search for",
    "start": "4580880",
    "end": "4588719"
  },
  {
    "text": "amazon augmented ai so this is the h2i console you can come over here and do a",
    "start": "4588719",
    "end": "4593840"
  },
  {
    "text": "lot of initial configuration that i was talking about so you can say like okay where do you want the results",
    "start": "4593840",
    "end": "4600239"
  },
  {
    "text": "to be stored what is your task type you can select extract recognition or you can select any of the custom ones",
    "start": "4600239",
    "end": "4606719"
  },
  {
    "text": "and for example if you select extract the you can define the conditions based on the task",
    "start": "4606719",
    "end": "4612320"
  },
  {
    "text": "and these conditions are very dependent on the task type you're choosing so for example for document processing",
    "start": "4612320",
    "end": "4617840"
  },
  {
    "text": "use case you might want to say in case i am not able to find first name",
    "start": "4617840",
    "end": "4623280"
  },
  {
    "text": "on the con on the document i want a human to come in and have a look or something like that so you can do all",
    "start": "4623280",
    "end": "4628960"
  },
  {
    "text": "of this setup in console but another good thing that i just wanted to show you guys is we have actually created",
    "start": "4628960",
    "end": "4634960"
  },
  {
    "text": "a lot of end-to-end notebooks and these are directly hosted on github so you can just download this notebook",
    "start": "4634960",
    "end": "4640719"
  },
  {
    "text": "and get started over here so that's what i'm going to go through now because that is going to really show you how easy these",
    "start": "4640719",
    "end": "4646880"
  },
  {
    "text": "notebooks are to use for a demo purposes so i have created a notebook instance under",
    "start": "4646880",
    "end": "4653120"
  },
  {
    "text": "amazon sage maker let's just open that up let's open the jupiter",
    "start": "4653120",
    "end": "4660080"
  },
  {
    "text": "and the notebook that i'm showing you you can go and download it from our github like right today itself as well",
    "start": "4660239",
    "end": "4665760"
  },
  {
    "text": "uh let's wait for this network to open up",
    "start": "4665760",
    "end": "4671040"
  },
  {
    "text": "and i'm gonna just restart and clear everything so that we have a clean state to start with",
    "start": "4671040",
    "end": "4677280"
  },
  {
    "text": "now uh you will notice i am only going to click run in this notebook i'm not going to do anything else because as i mentioned",
    "start": "4677280",
    "end": "4684159"
  },
  {
    "text": "a lot of things have already been set up for you what you will need to do is just to make sure that you have",
    "start": "4684159",
    "end": "4689600"
  },
  {
    "text": "some of the prerequisites set up you will need to set up your work team which is a set of group of people that",
    "start": "4689600",
    "end": "4696640"
  },
  {
    "text": "you want to work on the tasks and then you need to tell us what is your s3 bucket where you want the human",
    "start": "4696640",
    "end": "4702400"
  },
  {
    "text": "reviewed results to store and that's all you need and those are the two things i have already input over here",
    "start": "4702400",
    "end": "4708239"
  },
  {
    "text": "so now uh let me just click on run a few times and as i'm clicking through the run you",
    "start": "4708239",
    "end": "4714320"
  },
  {
    "text": "also have a lot of instructions in this notebook so that you can help understand what is the notebook actually doing uh",
    "start": "4714320",
    "end": "4720480"
  },
  {
    "text": "so in this scenario i'm going to run this document through amazon extract and i'm trying to identify",
    "start": "4720480",
    "end": "4727520"
  },
  {
    "text": "full name phone number and a bunch of other fields from this document so this is a sample document i'm using",
    "start": "4727520",
    "end": "4732880"
  },
  {
    "text": "for the demo purposes so i'm doing that initial configuration step",
    "start": "4732880",
    "end": "4738000"
  },
  {
    "text": "that i was talking about previously through our apis and um given that it's",
    "start": "4738000",
    "end": "4743520"
  },
  {
    "text": "essentially a notebook and all i have to do is press my initial configuration was initializing and within like two three",
    "start": "4743520",
    "end": "4749520"
  },
  {
    "text": "seconds now it's active so the next step i'm going to send the document through",
    "start": "4749520",
    "end": "4754560"
  },
  {
    "text": "amazon extract and let's see what the result comes out of amazon extract",
    "start": "4754560",
    "end": "4760560"
  },
  {
    "text": "the way i had set up the conditions uh in this demo was that uh in a way that now a human",
    "start": "4760560",
    "end": "4767360"
  },
  {
    "text": "loop has been created and what it means is that a piece of uh document or this page",
    "start": "4767360",
    "end": "4773280"
  },
  {
    "text": "of document is now sent for human review so and now you can see the status as well as the",
    "start": "4773280",
    "end": "4778960"
  },
  {
    "text": "human loop stages status is in progress so the next thing is i'm going to search around the",
    "start": "4778960",
    "end": "4784239"
  },
  {
    "text": "persona and let's say now i'm the worker who needs to work on this document so",
    "start": "4784239",
    "end": "4789280"
  },
  {
    "text": "i'm going to go into this login website and this is a website that customers get for their own accounts at the end of the day",
    "start": "4789280",
    "end": "4797760"
  },
  {
    "text": "and this is behind a login screen so let me just log out and make sure you see the login screen as well",
    "start": "4797760",
    "end": "4802880"
  },
  {
    "text": "and customer can fully manage who logs into this website we are not sending all this work over anyone emails or something this is a",
    "start": "4802880",
    "end": "4809040"
  },
  {
    "text": "very secure way to make sure work is done uh as per customer requirements",
    "start": "4809040",
    "end": "4814320"
  },
  {
    "text": "and then what i'm going to do is i see that there is a document analysis sample",
    "start": "4814320",
    "end": "4819360"
  },
  {
    "text": "task in my queue i'm going to say start working and this is one of the pre-built templates that",
    "start": "4819360",
    "end": "4824719"
  },
  {
    "text": "we provide so you as a customer do not have to go and create this ui we provide over 60",
    "start": "4824719",
    "end": "4830159"
  },
  {
    "text": "different templates that are again available on github on the left hand side there are instructions that tell me how to",
    "start": "4830159",
    "end": "4836639"
  },
  {
    "text": "complete this task in the middle there's the document and on the right hand side is the data i",
    "start": "4836639",
    "end": "4842239"
  },
  {
    "text": "wanted to extract out of this document now you will see a lot of efficiency mechanisms that we",
    "start": "4842239",
    "end": "4847760"
  },
  {
    "text": "have already pre-built from our worker perspective so for example if i click on this phone number you see that the phone number has",
    "start": "4847760",
    "end": "4854480"
  },
  {
    "text": "already been pre-populated by what amazon extract output was so that i",
    "start": "4854480",
    "end": "4859520"
  },
  {
    "text": "as a worker do not have to type in and at the same time you see this orange box around this",
    "start": "4859520",
    "end": "4865120"
  },
  {
    "text": "field as well so that it's easy for me to find it on the document and then we can see like this full name",
    "start": "4865120",
    "end": "4870800"
  },
  {
    "text": "as well or we can see this home address as well i also wanted to extract mail address out of this document but as we",
    "start": "4870800",
    "end": "4877440"
  },
  {
    "text": "can see it's blurred and it's crossed out uh it was not really identified by machine learning model over here",
    "start": "4877440",
    "end": "4883920"
  },
  {
    "text": "so i as a worker can come in and type in like two three four main street any town usa everything else looks to me",
    "start": "4883920",
    "end": "4893280"
  },
  {
    "text": "looks good to me so i'm just going to submit this task now once the task is submitted we",
    "start": "4893280",
    "end": "4898560"
  },
  {
    "text": "automatically send a cloud watch event to the customer's account so that customers know like this piece of work",
    "start": "4898560",
    "end": "4904960"
  },
  {
    "text": "has been done and at the same time we also store the result in the customers s3 bucket",
    "start": "4904960",
    "end": "4911040"
  },
  {
    "text": "and you can come to the console and see this initial configuration that i had done on the console as well over here so",
    "start": "4911040",
    "end": "4918560"
  },
  {
    "text": "let's just look at the thing at the bottom over here that says human loops you can see this has been created like",
    "start": "4918560",
    "end": "4924080"
  },
  {
    "text": "just a few moments back and the work has been completed because i just went to the ui and did the work",
    "start": "4924080",
    "end": "4930239"
  },
  {
    "text": "so let's open this up and see what does the output look like",
    "start": "4930239",
    "end": "4935360"
  },
  {
    "text": "uh so as i mentioned we store the output in the customers s3 bucket it's a json",
    "start": "4935360",
    "end": "4940639"
  },
  {
    "text": "output so let's open up this output now this is kind of difficult to read like this so",
    "start": "4940639",
    "end": "4947120"
  },
  {
    "text": "let me just open it in a json parser and an online json parser",
    "start": "4947120",
    "end": "4953840"
  },
  {
    "text": "now in the output you will see there is a section called as human answers and that contains whatever answers i",
    "start": "4954560",
    "end": "4960159"
  },
  {
    "text": "provided as a human so over here you can see mail address is a key",
    "start": "4960159",
    "end": "4965199"
  },
  {
    "text": "that i specifically input in the document and if i scroll down i can see over here that 2 3",
    "start": "4965199",
    "end": "4972880"
  },
  {
    "text": "4 any street should be showing up as a value over here so you can see this thing 234",
    "start": "4972880",
    "end": "4980639"
  },
  {
    "text": "main street any town usa now this is available to you as an output as a customer",
    "start": "4980639",
    "end": "4986080"
  },
  {
    "text": "and it's up to you like how you want to use this data you can parse it or you can use it in any form and",
    "start": "4986080",
    "end": "4991360"
  },
  {
    "text": "fashion you want in case you are using a2i with custom machine learning models you can also use this hui",
    "start": "4991360",
    "end": "4997760"
  },
  {
    "text": "output to retrain your models over a certain frequency so for example if you say like three",
    "start": "4997760",
    "end": "5003520"
  },
  {
    "text": "months later now i have a lot of hy output and i want to retrain my custom model",
    "start": "5003520",
    "end": "5008560"
  },
  {
    "text": "you can absolutely take this data and retrain your model as well",
    "start": "5008560",
    "end": "5015600"
  },
  {
    "text": "this is some super exciting stuff i mean again after every organization goes zero to",
    "start": "5015600",
    "end": "5021440"
  },
  {
    "text": "one with machine learning where they can ingest new data and serve inferences whether they've trained their model",
    "start": "5021440",
    "end": "5026960"
  },
  {
    "text": "let's say they've they've gotten past that hump once it's in production this is the exact problem that every single one of",
    "start": "5026960",
    "end": "5032400"
  },
  {
    "text": "them faces that not mu or i shouldn't say most but like not many teams sort of anticipate because it's",
    "start": "5032400",
    "end": "5038480"
  },
  {
    "text": "you know a higher order sort of problem once you've once you've implemented your machine learning system um but truly",
    "start": "5038480",
    "end": "5044560"
  },
  {
    "text": "a2 amazon a2i is this fully fledged managed application proxy for uh taking",
    "start": "5044560",
    "end": "5051280"
  },
  {
    "text": "the that raw output from your machine learning model and being able to either directly serve that to your customers or",
    "start": "5051280",
    "end": "5057840"
  },
  {
    "text": "to have that human-loop uh reviewing with an entirely pre-baked front end",
    "start": "5057840",
    "end": "5063120"
  },
  {
    "text": "to serve this to your reviewing task force right yup yup absolutely definitely and uh i",
    "start": "5063120",
    "end": "5069520"
  },
  {
    "text": "think you summarized it really well um over here like and also i just wanted to show like on the screen share like all the",
    "start": "5069520",
    "end": "5075040"
  },
  {
    "text": "resources that i shared with you guys today are present in these resources tab over here so you like right after this",
    "start": "5075040",
    "end": "5082159"
  },
  {
    "text": "conversation or whenever you want you can directly go and run any of these jupiter notebooks we also have some other",
    "start": "5082159",
    "end": "5088239"
  },
  {
    "text": "material over here that it can help you get started on ui and at the same time you can also see some of the other",
    "start": "5088239",
    "end": "5094320"
  },
  {
    "text": "customers like nhs deloitte t-mobile and how these customers are using hy in their different",
    "start": "5094320",
    "end": "5100320"
  },
  {
    "text": "workflows yeah and the thing that really impressed me was how",
    "start": "5100320",
    "end": "5105360"
  },
  {
    "text": "portable everything was and how well thought out everything so when you showed us the json schema of the the data from the human augmented",
    "start": "5105360",
    "end": "5112800"
  },
  {
    "text": "data you know that that really convinces me that i i mean i might have a bespoke system i",
    "start": "5112800",
    "end": "5117920"
  },
  {
    "text": "might have a custom workflow it might not be all in on the various solutions across uh aws for running my uh my ml powered",
    "start": "5117920",
    "end": "5125440"
  },
  {
    "text": "workload but this can still help me i can still stop this incrementally and then um you know you",
    "start": "5125440",
    "end": "5132000"
  },
  {
    "text": "mentioned that we can take this data and feed it back into the system to train an improved version the model that's also very interesting",
    "start": "5132000",
    "end": "5137679"
  },
  {
    "text": "and you also touched on something that's very important which is access control right as you were clicking through the jupyter notebook you were saying look like the user actually has to log",
    "start": "5137679",
    "end": "5144159"
  },
  {
    "text": "on here there's a point at which you have fine-grained control over who can access this information because chances are",
    "start": "5144159",
    "end": "5149360"
  },
  {
    "text": "it's going to be very sensitive to the domain that your business operates under exactly exactly and customers can like",
    "start": "5149360",
    "end": "5154880"
  },
  {
    "text": "maintain this team they can remove anyone they can do uh their cognitive user pool integration so customers have a lot of",
    "start": "5154880",
    "end": "5161679"
  },
  {
    "text": "control on who is accessing their data there are also things like task timeout and things like that where",
    "start": "5161679",
    "end": "5167040"
  },
  {
    "text": "customers can automatically take something out of the queue in case it's very time sensitive or things like that",
    "start": "5167040",
    "end": "5174080"
  },
  {
    "text": "yeah and sort of to recap something we didn't actually say before when we talked about you know the two worlds of either full automation or no",
    "start": "5174080",
    "end": "5180880"
  },
  {
    "text": "automation in terms of serving requests like this i think that something that's important to call out",
    "start": "5180880",
    "end": "5186080"
  },
  {
    "text": "is that there are a large number of customers out there who due to the lack of of ability to implement observability uh",
    "start": "5186080",
    "end": "5192960"
  },
  {
    "text": "sort of defaults to not having that automation right so the launch of a2i is not just about",
    "start": "5192960",
    "end": "5198400"
  },
  {
    "text": "improving the efficiency of folks that are already um you know trying to implement or have implemented",
    "start": "5198400",
    "end": "5203840"
  },
  {
    "text": "a machine learning um you know workflow but is actually going to open up the door to a lot of",
    "start": "5203840",
    "end": "5209120"
  },
  {
    "text": "organizations that have wanted and are bought into implementing ai and ml but haven't had the bandwidth to implement this sort of observability mechanism",
    "start": "5209120",
    "end": "5215600"
  },
  {
    "text": "previously so uh sort of a supplementary good to core functionality and machine learning",
    "start": "5215600",
    "end": "5220719"
  },
  {
    "text": "but i think it's really going to open the doors for for a lot of peop a lot of teams that are looking to to get started with this absolutely",
    "start": "5220719",
    "end": "5228080"
  },
  {
    "text": "absolutely yeah so i think it's not only like you can add a layer of human oversight to the ml but",
    "start": "5228080",
    "end": "5234239"
  },
  {
    "text": "also to the customers like who are really wanting to start their machine learning journey with a very critical",
    "start": "5234239",
    "end": "5239679"
  },
  {
    "text": "workflow and they want to make sure that they're not only using ml but they have this oversight as well",
    "start": "5239679",
    "end": "5244800"
  },
  {
    "text": "those customers can definitely benefit from each way as well last thing that you didn't you touched",
    "start": "5244800",
    "end": "5250880"
  },
  {
    "text": "on but sort of didn't spin it in this way um what even even if you know so assume a certain",
    "start": "5250880",
    "end": "5257600"
  },
  {
    "text": "percentage of requests go to a human right for review as we dictated by a threshold here um",
    "start": "5257600",
    "end": "5262960"
  },
  {
    "text": "let's not undersell sort of the value of being able to have the pre-baked sort of inference",
    "start": "5262960",
    "end": "5268960"
  },
  {
    "text": "already filled in on that template right so even if it's a low confidence value it's significantly",
    "start": "5268960",
    "end": "5274880"
  },
  {
    "text": "lower lift for the human reviewer to simply change one letter than it is to completely review from scratch a blank",
    "start": "5274880",
    "end": "5281360"
  },
  {
    "text": "template we saw the outline as well so you know you still get additional value from your ml",
    "start": "5281360",
    "end": "5287120"
  },
  {
    "text": "powered inference and that's all baked in sort of by default in those workloads so it makes even your human reviews more efficient",
    "start": "5287120",
    "end": "5293120"
  },
  {
    "text": "than they would be previously absolutely and kind of the example that i showed like that had only like kind of",
    "start": "5293120",
    "end": "5298239"
  },
  {
    "text": "four fields in a document like imagine kind of a mortgage application kind of a document or some kind of a",
    "start": "5298239",
    "end": "5304639"
  },
  {
    "text": "other document that has like around 40 or 50 fields in the single page in that kind of document or in that kind",
    "start": "5304639",
    "end": "5310800"
  },
  {
    "text": "of a use case you don't want each and every field to be input manually you want to",
    "start": "5310800",
    "end": "5316239"
  },
  {
    "text": "pre-fill it show it to the worker save them a lot of time and make sure they are only present as a",
    "start": "5316239",
    "end": "5321280"
  },
  {
    "text": "validator of this data rather than entering everything manually over there i think that's a really good point that you brought up",
    "start": "5321280",
    "end": "5327600"
  },
  {
    "text": "as well awesome well i'm not seeing too many questions uh",
    "start": "5327600",
    "end": "5333120"
  },
  {
    "text": "in chat but sort of to again go around the globe again for for a toy",
    "start": "5333120",
    "end": "5339360"
  },
  {
    "text": "fully managed human in the loop interface for machine learning inference uh bring your own model the ability to",
    "start": "5339360",
    "end": "5346159"
  },
  {
    "text": "either use your own custom model from aws on sagemaker ai managed services or",
    "start": "5346159",
    "end": "5351280"
  },
  {
    "text": "even any you know a model you may have hosted on another cloud provider if you so desire",
    "start": "5351280",
    "end": "5356480"
  },
  {
    "text": "and the ability to then implement this observability custom setting of thresholds and to improve the efficiency of those",
    "start": "5356480",
    "end": "5363360"
  },
  {
    "text": "human in the loop inferences uh really bang on job especially with the fact that we have such a large trough of uh jupiter",
    "start": "5363360",
    "end": "5370400"
  },
  {
    "text": "notebooks so that customers can actually walk through the exact same flow that you showed us today and plug in their own",
    "start": "5370400",
    "end": "5375840"
  },
  {
    "text": "models to get started with that very very quickly um again great this is the",
    "start": "5375840",
    "end": "5381040"
  },
  {
    "text": "amazon a2i augmented ai launch this is this is ga we have the",
    "start": "5381040",
    "end": "5387840"
  },
  {
    "text": "customer references we have the um jupiter notebooks on there as well as that talk from re invent that i see",
    "start": "5387840",
    "end": "5393440"
  },
  {
    "text": "there on the product page if folks are interested in uh seeing a little bit more about",
    "start": "5393440",
    "end": "5398719"
  },
  {
    "text": "augmented ai in action yeah and special thanks to bill there one in chat uh",
    "start": "5398719",
    "end": "5404080"
  },
  {
    "text": "total human being hundred percent uh the news nick and i all agree that that",
    "start": "5404080",
    "end": "5409520"
  },
  {
    "text": "is a human being um the next week we'll have bill vert 2 in chat to help us moderate",
    "start": "5409520",
    "end": "5416159"
  },
  {
    "text": "or concurrently will a b test them yeah awesome well uh anuj thank you again for",
    "start": "5416320",
    "end": "5423600"
  },
  {
    "text": "joining us again amazon augmented ai everyone stick around we've got one more demo that is",
    "start": "5423600",
    "end": "5428639"
  },
  {
    "text": "amazon kendra enterprise uh powered uh enterprise search powered by machine learning stick around",
    "start": "5428639",
    "end": "5434080"
  },
  {
    "text": "we will be right back all right we are back last launch of the day uh well it",
    "start": "5434080",
    "end": "5440800"
  },
  {
    "text": "launched previous to this but is still very exciting and very hot off the presses nonetheless uh without further ado we are here to",
    "start": "5440800",
    "end": "5446719"
  },
  {
    "text": "talk about amazon kendra joining us from the kendra and the aws ai team is jp dodell thank you for",
    "start": "5446719",
    "end": "5453040"
  },
  {
    "text": "joining us jp thanks for having us okay so amazon kendra i hinted at it before",
    "start": "5453040",
    "end": "5458560"
  },
  {
    "text": "it's enterprise grade search powered by machine learning but i know that we're going to talk about it in much greater detail than",
    "start": "5458560",
    "end": "5465120"
  },
  {
    "text": "that let's just kick things off you know what is amazon kendra sure so um kendra is a fully managed",
    "start": "5465120",
    "end": "5472560"
  },
  {
    "text": "service and in a nutshell it's a highly accurate and easy to use enterprise search service",
    "start": "5472560",
    "end": "5477920"
  },
  {
    "text": "that was built from the ground up using machine learning so basically you give kendra all your",
    "start": "5477920",
    "end": "5483760"
  },
  {
    "text": "pdfs your web pages your faqs wikis reports manuals any document any",
    "start": "5483760",
    "end": "5490080"
  },
  {
    "text": "text document you wish you could search more effectively and kendra allows you to ask questions using",
    "start": "5490080",
    "end": "5495280"
  },
  {
    "text": "everyday language instead of clunky combinations of keywords so you can still use keywords of course",
    "start": "5495280",
    "end": "5500800"
  },
  {
    "text": "but now you can also ask your questions in much more natural and precise ways when you choose to and",
    "start": "5500800",
    "end": "5507760"
  },
  {
    "text": "using a combination of state-of-the-art deep learning models kendra will find precise answers words phrases",
    "start": "5507760",
    "end": "5514719"
  },
  {
    "text": "or passages that are buried in millions of documents and it can do this with pain point accuracy",
    "start": "5514719",
    "end": "5519920"
  },
  {
    "text": "so instead of getting these long list of documents when you search and with questionable relevance you get",
    "start": "5519920",
    "end": "5525440"
  },
  {
    "text": "accurate answers from kendra this is one of kendra's key value propositions and i'll show you some",
    "start": "5525440",
    "end": "5530639"
  },
  {
    "text": "examples shortly and of course all of your data is encrypted in transit at rest",
    "start": "5530639",
    "end": "5536000"
  },
  {
    "text": "with aws kms keys or even you can bring your own customer managed kms keys and best part about it",
    "start": "5536000",
    "end": "5542320"
  },
  {
    "text": "is that it doesn't require any machine learning expertise well i think we've all had that",
    "start": "5542320",
    "end": "5547520"
  },
  {
    "text": "experience of trying to find something on some sort of uh document search portal and just",
    "start": "5547520",
    "end": "5553920"
  },
  {
    "text": "coming up with some really noisy results you mentioned a couple of the ways that kendra was designed to address the pain",
    "start": "5553920",
    "end": "5560239"
  },
  {
    "text": "points of this kind of customer search use case or the enterprise search use case are there any other pain points that",
    "start": "5560239",
    "end": "5566400"
  },
  {
    "text": "that we use to kind of inform how we built kendra yeah so i mean we we talked to our customers a lot right and so our",
    "start": "5566400",
    "end": "5572800"
  },
  {
    "text": "customers kept telling us that their search applications could not come up with good search results when searching",
    "start": "5572800",
    "end": "5578000"
  },
  {
    "text": "documents and after years of trying different solutions and vendors enterprises are still challenged today",
    "start": "5578000",
    "end": "5584159"
  },
  {
    "text": "with two main problems around enterprise search the first one is low search accuracy as we mentioned earlier",
    "start": "5584159",
    "end": "5590159"
  },
  {
    "text": "and the problem there is that 80 percent of the enterprise data today is unstructured again that's your pdfs",
    "start": "5590159",
    "end": "5597199"
  },
  {
    "text": "your word documents your html files basically any document or record that contains textual information",
    "start": "5597199",
    "end": "5603440"
  },
  {
    "text": "and on top of that many of the open source and commercial solutions out there are built on keyword engines that are",
    "start": "5603440",
    "end": "5609760"
  },
  {
    "text": "really not fit to find precise answers in documents they're great for some specialized applications",
    "start": "5609760",
    "end": "5615040"
  },
  {
    "text": "but they're not designed to understand context and the subtleties of human language",
    "start": "5615040",
    "end": "5620239"
  },
  {
    "text": "so that's one aspect the second challenge is um that enterprises are facing is the",
    "start": "5620239",
    "end": "5626480"
  },
  {
    "text": "complexity involved in implementing search so to connect all the data silos to make them searchable",
    "start": "5626480",
    "end": "5633040"
  },
  {
    "text": "from a single place is a really big challenge every repository uh every repository",
    "start": "5633040",
    "end": "5638880"
  },
  {
    "text": "type like sharepoint salesforce or even s3 has its own special set of rules to govern the documents and metadata stored",
    "start": "5638880",
    "end": "5645600"
  },
  {
    "text": "in them it's like their own little universes so how do you create a unified and seamless experience",
    "start": "5645600",
    "end": "5651040"
  },
  {
    "text": "out of so much diversity well that's the second challenge we're addressing with kendra",
    "start": "5651040",
    "end": "5656400"
  },
  {
    "text": "so i think we're all sort of accustomed to over time learning how to craft the queries we ask",
    "start": "5656400",
    "end": "5662080"
  },
  {
    "text": "search engines typically based on the results we get and i think that if we took things we search in a search engine",
    "start": "5662080",
    "end": "5668080"
  },
  {
    "text": "verbatim and send them to someone that's around us they'd look at us like we were crazy and so you know this has been sort of a very",
    "start": "5668080",
    "end": "5674159"
  },
  {
    "text": "long ongoing process for us to learn how to ask questions to search engines we mentioned you or at least you",
    "start": "5674159",
    "end": "5679840"
  },
  {
    "text": "mentioned here that kendra enables us to ask more naturally can we walk through some examples of what those natural queries look like",
    "start": "5679840",
    "end": "5686880"
  },
  {
    "text": "sure so there's many variations or many scenarios and situations and use cases right",
    "start": "5686880",
    "end": "5692320"
  },
  {
    "text": "uh it's about making that experience more intuitive so say you're an employee and you're planning your upcoming",
    "start": "5692320",
    "end": "5697520"
  },
  {
    "text": "maternally and you want to ask a question how long is maternity leave right and instead of returning a long",
    "start": "5697520",
    "end": "5703199"
  },
  {
    "text": "list of documents where you have to dig through kendra will just give you 14 weeks or whatever the duration is at your company",
    "start": "5703199",
    "end": "5709520"
  },
  {
    "text": "right or if if you're a new employee and you're having issues with your vpn you can ask a more descriptive question",
    "start": "5709520",
    "end": "5715520"
  },
  {
    "text": "how do i configure my vpn now the answer is slightly longer and you'll get a very specific passage",
    "start": "5715520",
    "end": "5721679"
  },
  {
    "text": "describing that task right how about where is the it support desk right and again you get first floor",
    "start": "5721679",
    "end": "5728080"
  },
  {
    "text": "instead of a long list of of documents so you can also ask keywords",
    "start": "5728080",
    "end": "5733360"
  },
  {
    "text": "keyword queries of course like health benefits right if you just want general information or parking allowance that's still",
    "start": "5733360",
    "end": "5738400"
  },
  {
    "text": "possible of course um and for those examples you'll still get these sections pulled out of documents",
    "start": "5738400",
    "end": "5744000"
  },
  {
    "text": "to help you get to your answer much faster well you know i feel like uh jp we're",
    "start": "5744000",
    "end": "5750320"
  },
  {
    "text": "skipping over the step where instead of using kendra we can have every talk in query keywords right so instead of",
    "start": "5750320",
    "end": "5756639"
  },
  {
    "text": "asking what do you want to grab for lunch i could say launch options what question ambiguity",
    "start": "5756639",
    "end": "5761760"
  },
  {
    "text": "yeah exactly so yeah you know indexing and searching for",
    "start": "5761760",
    "end": "5768560"
  },
  {
    "text": "information is not something that i think few people do it's something we all have to do in some way shape or form",
    "start": "5768560",
    "end": "5774000"
  },
  {
    "text": "uh but i'm trying to think here now kendra as a service um you know who should really be looking",
    "start": "5774000",
    "end": "5779360"
  },
  {
    "text": "towards kendra to solve their problems who are going to be the users in terms of implementing or consuming from kendra can we talk a little bit",
    "start": "5779360",
    "end": "5785920"
  },
  {
    "text": "about that yeah so so kendra simplifies the implementation of enterprise search",
    "start": "5785920",
    "end": "5792320"
  },
  {
    "text": "to empower both technical and business decision makers to get started quickly without",
    "start": "5792320",
    "end": "5798480"
  },
  {
    "text": "installing any packages without configuring any servers or writing any code kendra is a fully",
    "start": "5798480",
    "end": "5803600"
  },
  {
    "text": "managed service in aws like i mentioned earlier you just point kendra at your data sources and you can have your sharepoint",
    "start": "5803600",
    "end": "5809600"
  },
  {
    "text": "or s3 data searchable in the console within minutes that was really important for us we wanted to simplify the aggregation",
    "start": "5809600",
    "end": "5816000"
  },
  {
    "text": "process getting started quickly so what was that i mean it's very easy",
    "start": "5816000",
    "end": "5822719"
  },
  {
    "text": "to get started what are the kind of setup steps can you walk us through that yeah when when i want to point kendra some of these these data sources yeah so so basically",
    "start": "5822719",
    "end": "5830320"
  },
  {
    "text": "um so to get started with kendra right so you you have and i'm going to show you how you set up a data source in in the demo",
    "start": "5830320",
    "end": "5837440"
  },
  {
    "text": "but basically um how do you get set up how you get started with kendra is that you have we have two editions",
    "start": "5837440",
    "end": "5843679"
  },
  {
    "text": "uh we recently launched the kendra developer edition but basically we have the kendra enterprise edition",
    "start": "5843679",
    "end": "5848880"
  },
  {
    "text": "that provides high availability and runs on three availability zones and is designed for production workloads",
    "start": "5848880",
    "end": "5855600"
  },
  {
    "text": "the second edition we just launched was is the kendra developer edition it provides developers",
    "start": "5855600",
    "end": "5861119"
  },
  {
    "text": "with a lower cost option to build a proof of concept and experiment with kendra this edition also has a free tier that",
    "start": "5861119",
    "end": "5868080"
  },
  {
    "text": "includes 750 hours of free usage for the first 30 days so it's a great option to get started with kendra",
    "start": "5868080",
    "end": "5875360"
  },
  {
    "text": "and setting up any one of these two editions is really simple you just go to aws.amazon.com kendra and",
    "start": "5875360",
    "end": "5881360"
  },
  {
    "text": "you can get started right away so yeah yeah and i think you have you",
    "start": "5881360",
    "end": "5886880"
  },
  {
    "text": "added the question is that what does it look like uh to is that was that the uh your question i guess",
    "start": "5886880",
    "end": "5893600"
  },
  {
    "text": "well i think you mentioned demo and so it sounds like you're going to cover that in demo so we can hold off i think there's some",
    "start": "5893600",
    "end": "5898880"
  },
  {
    "text": "other questions uh it sounds like nick had one right now yeah i mean i was just going to say i sort of the pie in the sky pitch in the",
    "start": "5898880",
    "end": "5905199"
  },
  {
    "text": "beginning of being able to ask natural queries uh directly in some sort of search bar i'd imagine is is a very clear sort of",
    "start": "5905199",
    "end": "5911920"
  },
  {
    "text": "user experience uh but you know on the other side of things indexing you mentioned is one of the large problems here so",
    "start": "5911920",
    "end": "5918400"
  },
  {
    "text": "uh how do you set up indexing data from all these various sources using kendra",
    "start": "5918400",
    "end": "5924880"
  },
  {
    "text": "yeah so basically we have a series of connectors one of the key things for us was to make sure the",
    "start": "5924880",
    "end": "5930480"
  },
  {
    "text": "aggregation of content was very straightforward and that everything was integrated and available in the console so you could",
    "start": "5930480",
    "end": "5937440"
  },
  {
    "text": "quickly access it configure it and get your data in so we offer we launched kendra with uh",
    "start": "5937440",
    "end": "5943760"
  },
  {
    "text": "six connectors that are native in the console today and we have plans for other ones so basically you go in",
    "start": "5943760",
    "end": "5948960"
  },
  {
    "text": "the console and you configure your connectors you point them to your sources and you schedule them and they start",
    "start": "5948960",
    "end": "5954719"
  },
  {
    "text": "bringing data in and it becomes available as soon as it uh comes into kendra",
    "start": "5954719",
    "end": "5960000"
  },
  {
    "text": "and can you share some of those data sources what are those data sources yeah so we have we launched six data",
    "start": "5960000",
    "end": "5966000"
  },
  {
    "text": "sources s3 rds databases like mysql and postgres we have sharepoint online",
    "start": "5966000",
    "end": "5971520"
  },
  {
    "text": "servicenow salesforce and onedrive and we'll be releasing many more in the next",
    "start": "5971520",
    "end": "5976719"
  },
  {
    "text": "few months to cover to cover confluence for example uh sharepoint on-prem google drive and others uh and again",
    "start": "5976719",
    "end": "5983920"
  },
  {
    "text": "those are some of the most common kind of documents storage solutions that enterprises use that you're trying to cover first right",
    "start": "5983920",
    "end": "5989760"
  },
  {
    "text": "yeah exactly we're talking to our customers again to see you know what are those most prominent data sources they want to",
    "start": "5989760",
    "end": "5995040"
  },
  {
    "text": "get their knowledge from and that's how we prioritize the development on our side from that list though uh rds kind of",
    "start": "5995040",
    "end": "6001920"
  },
  {
    "text": "stands out because rds uh for those of you don't know is our relational database service and this is basically just a you know",
    "start": "6001920",
    "end": "6008320"
  },
  {
    "text": "hosted sql server with various kinds of sql engines backing it and there i can kind of define my own",
    "start": "6008320",
    "end": "6013440"
  },
  {
    "text": "schema i can store whatever data i want according to that schema so what kinds of constraints are there when you're consuming data from a dynamic data",
    "start": "6013440",
    "end": "6019840"
  },
  {
    "text": "source like rds yeah so that's a good example so and rds is not a special case you have",
    "start": "6019840",
    "end": "6025440"
  },
  {
    "text": "different schemas from different repositories as well so there isn't really a constraint in",
    "start": "6025440",
    "end": "6030960"
  },
  {
    "text": "kendra our connectors are flexible and we wanted to make sure that was the case when we designed them but we put special",
    "start": "6030960",
    "end": "6036880"
  },
  {
    "text": "attention when designing the connectors to ensure customers always had an option to get started quickly with default",
    "start": "6036880",
    "end": "6042880"
  },
  {
    "text": "configurations and schemas right this allows them to get their data indexed into kendra quickly",
    "start": "6042880",
    "end": "6048000"
  },
  {
    "text": "and that works great for pocs and quick experiments on data sources right so we want to make sure there was",
    "start": "6048000",
    "end": "6053280"
  },
  {
    "text": "an easy path to get started there and if further fine tuning is required we provide lots of easy to use",
    "start": "6053280",
    "end": "6060000"
  },
  {
    "text": "options for customizing the index schema normalizing and merging the fields you want to bring",
    "start": "6060000",
    "end": "6065520"
  },
  {
    "text": "from multiple data sources because a lot of times when you're creating that unified experience you want to map these fields from these",
    "start": "6065520",
    "end": "6072239"
  },
  {
    "text": "various data sources into common ones in the index and we provide those tools in a very easy user",
    "start": "6072239",
    "end": "6078239"
  },
  {
    "text": "experience in the console and of course the connectors you can refine the choice of documents you want index as well so",
    "start": "6078239",
    "end": "6084880"
  },
  {
    "text": "there's a lot of flexibility there but there's also a quick start path for uh for for your first experience in the",
    "start": "6084880",
    "end": "6090880"
  },
  {
    "text": "connector and for each of these connections let's say i choose one of these connectors and i want to integrate it with one drive how much technical knowledge do i need",
    "start": "6090880",
    "end": "6097360"
  },
  {
    "text": "in order to configure one of these connectors it really doesn't require a lot of technical knowledge again we wanted to",
    "start": "6097360",
    "end": "6103040"
  },
  {
    "text": "start by offering um you know out-of-the-box mappings so you don't have to actually customize",
    "start": "6103040",
    "end": "6108560"
  },
  {
    "text": "anything but of course if somebody has let's say a salesforce repository or a servicenow",
    "start": "6108560",
    "end": "6113920"
  },
  {
    "text": "repository and they want to be very specific uh with what they want to extract from it",
    "start": "6113920",
    "end": "6119040"
  },
  {
    "text": "usually those administrators of those data sources are somewhat familiar with those data sources already so they'll find the familiar things and",
    "start": "6119040",
    "end": "6125920"
  },
  {
    "text": "objects in the connector to be able to customize that in an intuitive way so",
    "start": "6125920",
    "end": "6131040"
  },
  {
    "text": "for onedrive it's very simple you just point it to your source you can just let it pull all the content",
    "start": "6131040",
    "end": "6136159"
  },
  {
    "text": "from the users that you have there and then you can go back and you know iterate or refine",
    "start": "6136159",
    "end": "6141360"
  },
  {
    "text": "the uh the criteria by which you want to pull the content from there so okay i'm i'm bought into the idea",
    "start": "6141360",
    "end": "6148639"
  },
  {
    "text": "that i can easily load my data these connectors work really seamlessly for me and i know they'll be performant",
    "start": "6148639",
    "end": "6154320"
  },
  {
    "text": "because they're built in-house by aws to to you know ingest this data into kendra um when i think of anything that's",
    "start": "6154320",
    "end": "6161520"
  },
  {
    "text": "powered by machine learning i always think okay well there's a training phase and there's an inference phase and",
    "start": "6161520",
    "end": "6167199"
  },
  {
    "text": "here if it's performing machine learning powered results that's the inference does the",
    "start": "6167199",
    "end": "6172400"
  },
  {
    "text": "training have to happen on my sort of data you know every organization has their own data sources their own subject matters",
    "start": "6172400",
    "end": "6178639"
  },
  {
    "text": "does kendra actually have to have this like training phase for my data before it can start serving me search results it doesn't actually and",
    "start": "6178639",
    "end": "6186320"
  },
  {
    "text": "as i mentioned earlier kendra does not require any machine learning expertise that that was really the tennis for",
    "start": "6186320",
    "end": "6192880"
  },
  {
    "text": "designing it we did the heavy lift thing already by pre-training kendra in 14 domains including i.t hr pharma",
    "start": "6192880",
    "end": "6200159"
  },
  {
    "text": "financial services energy industrials and we're doing more work to actually improve those uh",
    "start": "6200159",
    "end": "6206800"
  },
  {
    "text": "those models so that you can get an out-of-the-box experience that's very very effective so kendra can perform",
    "start": "6206800",
    "end": "6212960"
  },
  {
    "text": "very well out of the box now having said this we are building some exciting functionality for kendra",
    "start": "6212960",
    "end": "6218159"
  },
  {
    "text": "to further improve its accuracy and one of these pieces is called incremental learning",
    "start": "6218159",
    "end": "6223760"
  },
  {
    "text": "and when we roll it out later this year kendra will capture the user search behavior",
    "start": "6223760",
    "end": "6229040"
  },
  {
    "text": "so it'll actually look at what users are searching what they're clicking on what they're opening their thumbs up and down all that",
    "start": "6229040",
    "end": "6235199"
  },
  {
    "text": "feedback will be automatically fed back into the engine to update the machine learning engine and keep its",
    "start": "6235199",
    "end": "6241520"
  },
  {
    "text": "accuracy optimized over time and the second component that we're hearing a lot from our customers is",
    "start": "6241520",
    "end": "6246960"
  },
  {
    "text": "also being able to inject very custom very specific vocabulary in there uh or synonyms so that uh kendra so they",
    "start": "6246960",
    "end": "6254480"
  },
  {
    "text": "can expand kendra's understanding of a specific domain or business context so for example if you're if you're a",
    "start": "6254480",
    "end": "6261679"
  },
  {
    "text": "pharmaceutical company and you have a particular chemical compound that's also referred to as a",
    "start": "6261679",
    "end": "6266880"
  },
  {
    "text": "particular product that you're developing then customers will be able to provide this data typically if you're via",
    "start": "6266880",
    "end": "6272080"
  },
  {
    "text": "synonyms for knowledge expansion one of the questions from twitch chat from uh",
    "start": "6272080",
    "end": "6278000"
  },
  {
    "text": "werner g was also around sort of this use of historical data to improve the model",
    "start": "6278000",
    "end": "6283440"
  },
  {
    "text": "over time or improve the search results so as i understand correctly uh this",
    "start": "6283440",
    "end": "6288639"
  },
  {
    "text": "this sort of live feedback as folks use the as folks use kendra uh will be usable to improve those",
    "start": "6288639",
    "end": "6294800"
  },
  {
    "text": "results over time is there any uh way to ingest previous search history or is that really not something that's",
    "start": "6294800",
    "end": "6300000"
  },
  {
    "text": "available here on launch so today the incremental learning feature is not available this is",
    "start": "6300000",
    "end": "6305840"
  },
  {
    "text": "something that we are designing for something we'll we'll uh launch a little later this year",
    "start": "6305840",
    "end": "6311760"
  },
  {
    "text": "so we will we will consider all sources of signals right whether it's past logs uh search history",
    "start": "6311760",
    "end": "6317920"
  },
  {
    "text": "that may be captured in the existing system and feed that into the models to uh prime the pump if",
    "start": "6317920",
    "end": "6323520"
  },
  {
    "text": "you will on the models and just kind of come out with uh with a pre-trained um experience uh so we're still assessing",
    "start": "6323520",
    "end": "6330719"
  },
  {
    "text": "you know what are the things that we can do to make it come out of the gate with the highest accuracy if that history exists",
    "start": "6330719",
    "end": "6337040"
  },
  {
    "text": "but uh the sure thing is that over time the machine learning models will continuously receive these signals",
    "start": "6337040",
    "end": "6342400"
  },
  {
    "text": "uh to stay up to date on relevance so i just wanted to revisit the uh the",
    "start": "6342400",
    "end": "6348080"
  },
  {
    "text": "line of questioning we had earlier with all these data connectors there's the source of the data and then there's",
    "start": "6348080",
    "end": "6354000"
  },
  {
    "text": "where that data lives right what if i have a number of",
    "start": "6354000",
    "end": "6359119"
  },
  {
    "text": "on-prem data sources how does the integration work there yeah so i mean as you know in the",
    "start": "6359119",
    "end": "6365360"
  },
  {
    "text": "enterprise knowledge is is is everywhere right i mean we have stuff uh even on laptops right i mean it's",
    "start": "6365360",
    "end": "6371840"
  },
  {
    "text": "just uh we talk to customers and it's a you know knowledge is everywhere so uh",
    "start": "6371840",
    "end": "6377119"
  },
  {
    "text": "we recognize this fact and um and it's the reality of enterprise knowledge so",
    "start": "6377119",
    "end": "6382320"
  },
  {
    "text": "uh the data since it doesn't live necessarily in a uniform and easy reachable places",
    "start": "6382320",
    "end": "6388159"
  },
  {
    "text": "in fact it's rarely a simple landscape in the enterprise so we actually are building what our",
    "start": "6388159",
    "end": "6393360"
  },
  {
    "text": "customers tell us they need and so we're building both cloud and on-premise connectors to popular data sources like confluence",
    "start": "6393360",
    "end": "6399760"
  },
  {
    "text": "and that's going to be cloud and on-prem sharepoint for example we have the sharepoint online connector today but",
    "start": "6399760",
    "end": "6405760"
  },
  {
    "text": "we're also going to look at the on-prem version same for file systems websites",
    "start": "6405760",
    "end": "6411119"
  },
  {
    "text": "so we want to make sure that customers that we build what our customers need to tap into those",
    "start": "6411119",
    "end": "6416480"
  },
  {
    "text": "knowledge areas and some of these connectors are available today like i said uh others will come later this year",
    "start": "6416480",
    "end": "6423679"
  },
  {
    "text": "so we really feel strongly about this right because by covering both cloud and on-prem use cases",
    "start": "6423679",
    "end": "6429040"
  },
  {
    "text": "this will allow customers to reach and aggregate more pockets of knowledge in the enterprise and tap into all of their knowledge",
    "start": "6429040",
    "end": "6435040"
  },
  {
    "text": "capital [Music] all right well anytime someone tells me",
    "start": "6435040",
    "end": "6440800"
  },
  {
    "text": "it's easy to do something like setting up kendra i'm gonna ask them that i'm gonna tell them actions speak louder than words so",
    "start": "6440800",
    "end": "6447119"
  },
  {
    "text": "i'm gonna hold you to that is there any chance we'll be able to see you setting up kendra for everyone at home because i know that's probably the",
    "start": "6447119",
    "end": "6453920"
  },
  {
    "text": "first step for all of them to actually be able to use it yup actually i have a little bit a",
    "start": "6453920",
    "end": "6459280"
  },
  {
    "text": "little demo here that i want to show you guys in the audience so let me see here if i",
    "start": "6459280",
    "end": "6464400"
  },
  {
    "text": "can share my screen",
    "start": "6464400",
    "end": "6471360"
  },
  {
    "text": "and before i share my screen i'm just going to actually describe here a little bit some context on the on the on the demo",
    "start": "6471360",
    "end": "6477760"
  },
  {
    "text": "um so i thought it'd be fun to actually do a side-by-side comparison between traditional search experience on a",
    "start": "6477760",
    "end": "6483440"
  },
  {
    "text": "website with the kendra experience right so the data set i chose for this is from our own retail website",
    "start": "6483440",
    "end": "6490159"
  },
  {
    "text": "amazon.com help which is basically a search box for retail customers to find public information about kindle products",
    "start": "6490159",
    "end": "6497119"
  },
  {
    "text": "echo devices prime services uh and other amazon products and services uh and before we look at a",
    "start": "6497119",
    "end": "6503280"
  },
  {
    "text": "search uh there we're gonna look at how you can actually ingest data very quickly with kendra so",
    "start": "6503280",
    "end": "6511119"
  },
  {
    "text": "uh share my screen so this is the kendra console and basically the interface uh",
    "start": "6511119",
    "end": "6518159"
  },
  {
    "text": "takes me to a place where um you know i've created an index and basically to get started with with kendra there's",
    "start": "6518159",
    "end": "6523920"
  },
  {
    "text": "this three step process you first number one as shown here you create an index",
    "start": "6523920",
    "end": "6529199"
  },
  {
    "text": "and that's basically a container to define the scope of the documents and the search",
    "start": "6529199",
    "end": "6534560"
  },
  {
    "text": "that you want to perform over your content so the first step was to create an index and i already did that and it provisioned",
    "start": "6534560",
    "end": "6540719"
  },
  {
    "text": "all the infrastructure that i need to do that without having to manage anything so this was done as a step one now my",
    "start": "6540719",
    "end": "6546480"
  },
  {
    "text": "second step is to actually add a data source this is where you actually connect your index to your data sources like s3",
    "start": "6546480",
    "end": "6553119"
  },
  {
    "text": "sharepoint etc to bring the content and make it searchable so i'm going to show you here for this particular demo",
    "start": "6553119",
    "end": "6559199"
  },
  {
    "text": "we talked about those help pages right that were on the website so i've copied those into an s3 bucket",
    "start": "6559199",
    "end": "6565040"
  },
  {
    "text": "already so i'm just going to say add a data source here and this brings me to",
    "start": "6565040",
    "end": "6570080"
  },
  {
    "text": "my list of connectors that are available to me and we mentioned these before rds amazon s3 onedrive sharepoint",
    "start": "6570080",
    "end": "6576880"
  },
  {
    "text": "so since my content isn't as three bucket i'm just going to choose s3 and add a connector to s3 and here",
    "start": "6576880",
    "end": "6584000"
  },
  {
    "text": "very simply i can just type my s3",
    "start": "6584000",
    "end": "6590239"
  },
  {
    "text": "help pages um that's just the name for the data source right just so i can",
    "start": "6590239",
    "end": "6595280"
  },
  {
    "text": "identify it and know what's in there i'm going to skip the description for now just click on next",
    "start": "6595280",
    "end": "6602320"
  },
  {
    "text": "and here i can tell the connector where my data is so i can actually browse",
    "start": "6602480",
    "end": "6608560"
  },
  {
    "text": "my s3 buckets it tells me it lists here the s3 buckets that i have access to and i've already copied my pages in this",
    "start": "6608560",
    "end": "6615360"
  },
  {
    "text": "bucket so i'm just going to choose that one right and if i had any additional",
    "start": "6615360",
    "end": "6620400"
  },
  {
    "text": "metadata i can always point the connector to the metadata folder as well and it'll associate that metadata with",
    "start": "6620400",
    "end": "6625520"
  },
  {
    "text": "the content but i can actually get started very quickly without it so i'm just going to continue here",
    "start": "6625520",
    "end": "6630800"
  },
  {
    "text": "and then i'm going to associate a particular im role which i already created in the past for accessing this data or if you don't",
    "start": "6630800",
    "end": "6638080"
  },
  {
    "text": "have one you can kendra can create one automatically for you very quickly here i'm just going to use this one that i",
    "start": "6638080",
    "end": "6643920"
  },
  {
    "text": "have and then the last step here is to actually set the schedule at which you",
    "start": "6643920",
    "end": "6649199"
  },
  {
    "text": "want the connector to run so you know it'll run automatically to sync the data",
    "start": "6649199",
    "end": "6654960"
  },
  {
    "text": "and i could say well let's make it run daily right and you can set the time and then",
    "start": "6654960",
    "end": "6662400"
  },
  {
    "text": "you know it takes you to the last final page where you review your configuration and your settings and you're pretty much",
    "start": "6662400",
    "end": "6668800"
  },
  {
    "text": "done right you create the data source i'm not going to create it now because there's a lot of content and i've already",
    "start": "6668800",
    "end": "6674320"
  },
  {
    "text": "you know for the interest of this demo um it's already pre-indexed it's ready to go for for our searches but basically",
    "start": "6674320",
    "end": "6680480"
  },
  {
    "text": "you're done creating your data source and the next step after this is that the connector is going to pick up that content automatically",
    "start": "6680480",
    "end": "6686000"
  },
  {
    "text": "and keep the index in sync with that repository every hour by scanning it every hour hold on that",
    "start": "6686000",
    "end": "6693119"
  },
  {
    "text": "button can you tell us a little bit about that schedule at the bottom what are we seeing there yeah so this is the last step that i",
    "start": "6693119",
    "end": "6698639"
  },
  {
    "text": "covered earlier uh basically it's going to run um at this particular time on a daily basis",
    "start": "6698639",
    "end": "6705520"
  },
  {
    "text": "um so that's um that's basically the schedule that you said in the previous",
    "start": "6705520",
    "end": "6710719"
  },
  {
    "text": "uh in the previous page right that's the variable it is so um let me see here",
    "start": "6710719",
    "end": "6716800"
  },
  {
    "text": "we went back configure settings",
    "start": "6716800",
    "end": "6722480"
  },
  {
    "text": "so down here uh this is basically the um the schedule that you configure",
    "start": "6722480",
    "end": "6728080"
  },
  {
    "text": "at which you want to run the connector if i want to say daily hourly or weekly right so the connector",
    "start": "6728080",
    "end": "6733520"
  },
  {
    "text": "basically is going to connect the data source and sync the data there with the index so it's going to pull",
    "start": "6733520",
    "end": "6739040"
  },
  {
    "text": "all the new documents all the deleted documents or any modified documents it's going to connect the data source",
    "start": "6739040",
    "end": "6744560"
  },
  {
    "text": "and keep the index up to date so that's the schedule and this configurable solution",
    "start": "6744560",
    "end": "6750480"
  },
  {
    "text": "right you can make it start at any time you want right and at whatever frequency that works for you and if you want to",
    "start": "6750480",
    "end": "6756719"
  },
  {
    "text": "run this manually you can just say run on demand and you can basically just kind of tell",
    "start": "6756719",
    "end": "6762159"
  },
  {
    "text": "it when you want it to run if you wanted to run you know what during your poc you may want to run this manually and",
    "start": "6762159",
    "end": "6767920"
  },
  {
    "text": "then you schedule it to uh you know the most convenient time that works for you out of curiosity",
    "start": "6767920",
    "end": "6773520"
  },
  {
    "text": "um is there any sort of estimate on on the time for that sync i'd imagine it doesn't include downtime",
    "start": "6773520",
    "end": "6780080"
  },
  {
    "text": "but um you know how approximately how long should folks expect to see those updates",
    "start": "6780080",
    "end": "6785840"
  },
  {
    "text": "occurring once it triggers the the sync yeah so it depends on the data source",
    "start": "6785840",
    "end": "6791040"
  },
  {
    "text": "right some data sources are you know like sharepoint and servicenow they do those",
    "start": "6791040",
    "end": "6796960"
  },
  {
    "text": "data sources have their throttling or their limits at which you know content can be pulled from but",
    "start": "6796960",
    "end": "6803040"
  },
  {
    "text": "but repositories like s3 or databases can go much faster right and so you know it depends on the",
    "start": "6803040",
    "end": "6809920"
  },
  {
    "text": "amount of documents you have in there so it varies uh and it really depends on the the document size",
    "start": "6809920",
    "end": "6815840"
  },
  {
    "text": "and the um the repository type you're pulling data from so you know you could get um you know",
    "start": "6815840",
    "end": "6822639"
  },
  {
    "text": "uh you know 100 000 documents and you know maybe 10 20 minutes uh maybe faster maybe slower depending",
    "start": "6822639",
    "end": "6829760"
  },
  {
    "text": "on again the limitations of the data source yeah good to know sorry we're holding up the",
    "start": "6829760",
    "end": "6835119"
  },
  {
    "text": "demo here yeah no worries no worries so so that's it right we just kind of reviewed uh the setup here we we set the schedule",
    "start": "6835119",
    "end": "6842960"
  },
  {
    "text": "and then the last step was to just create the data source and it starts pulling content and that's it as soon as it's uh synced and it pulled",
    "start": "6842960",
    "end": "6849280"
  },
  {
    "text": "the content it's searchable so now let's go to the search page because i want to show you the search",
    "start": "6849280",
    "end": "6854320"
  },
  {
    "text": "experience so we've indexed our help pages and let's try some some some pages here some",
    "start": "6854320",
    "end": "6861280"
  },
  {
    "text": "queries so let's say i'm a you know amazon customer i bought a kindle book and i want to",
    "start": "6861280",
    "end": "6868000"
  },
  {
    "text": "return it i want to know what the process for returning that book is so i can just type",
    "start": "6868000",
    "end": "6873199"
  },
  {
    "text": "return kindle book",
    "start": "6873199",
    "end": "6877840"
  },
  {
    "text": "and the experience you get here is that you have a card that gets presented to you at the top here",
    "start": "6879040",
    "end": "6884800"
  },
  {
    "text": "which is basically looking at the content of every document and pulling the most relevant passage where it feels the",
    "start": "6884800",
    "end": "6891679"
  },
  {
    "text": "answer is the most confident answer is and and it boils the elements of interest so i can see like to return a",
    "start": "6891679",
    "end": "6898239"
  },
  {
    "text": "legible kindle book i get the process you know the the steps you know go to the managed content devices from there the content tab etc so it",
    "start": "6898239",
    "end": "6905760"
  },
  {
    "text": "gives me a process right it's it's pretty relevant i'm done with my search or i can go to the web page and",
    "start": "6905760",
    "end": "6910880"
  },
  {
    "text": "get more information about that but i actually get a lot of information just by looking at that box",
    "start": "6910880",
    "end": "6916719"
  },
  {
    "text": "okay so that's kind of a simple keyword example let's say now um i bought a real hardcover book",
    "start": "6916719",
    "end": "6923679"
  },
  {
    "text": "and i want to return it but i'm wondering how much amazon is going to refund for postage so",
    "start": "6923679",
    "end": "6929520"
  },
  {
    "text": "i can get a more precise question and say how much for postage refund",
    "start": "6929520",
    "end": "6938400"
  },
  {
    "text": "and again i get i get amazon's kendra suggested answer at the top which extracts these passages very precise",
    "start": "6940000",
    "end": "6945679"
  },
  {
    "text": "sections from documents and i can see right away that the refund up to 20 is coming back in my search results so",
    "start": "6945679",
    "end": "6953440"
  },
  {
    "text": "it's very specific right i mean i'm done with my search here this is the answer i'm looking for and let's compare the",
    "start": "6953440",
    "end": "6958719"
  },
  {
    "text": "experience with let's say the website so just to be to have the same question i'm just going to copy this",
    "start": "6958719",
    "end": "6964960"
  },
  {
    "text": "query and i'm just going to drop it in the amazon.com help which basically takes you to this",
    "start": "6964960",
    "end": "6970639"
  },
  {
    "text": "page and i'm gonna type in the same question",
    "start": "6970639",
    "end": "6976400"
  },
  {
    "text": "okay when i get back is a list of results uh it seems pretty relevant i have returns and refunds um but i need",
    "start": "6977760",
    "end": "6984239"
  },
  {
    "text": "to click here because there's no answer yet in this page in this results page okay i",
    "start": "6984239",
    "end": "6989679"
  },
  {
    "text": "click on that and i'm basically navigating now the the help pages right i still don't have an answer",
    "start": "6989679",
    "end": "6995599"
  },
  {
    "text": "and you know i'll skip the process of digging into these documents and scanning but it turns out that the answer is actually",
    "start": "6995599",
    "end": "7002080"
  },
  {
    "text": "buried in this particular document about our return policies so when i open this document i still",
    "start": "7002080",
    "end": "7008159"
  },
  {
    "text": "have to read right and try to figure out where is that amount how much i'm going to get back from amazon and okay right here right it will",
    "start": "7008159",
    "end": "7015920"
  },
  {
    "text": "automatically refund up to 20 so it's this exact same answer that kendra brought difference is that kendra brought it",
    "start": "7015920",
    "end": "7022400"
  },
  {
    "text": "back instantly after clicking on that search button right so let's cover another example",
    "start": "7022400",
    "end": "7028320"
  },
  {
    "text": "here for example um let's say i happen to have bought that book that i'm returning i bought it with my",
    "start": "7028320",
    "end": "7033760"
  },
  {
    "text": "prime card rewards points right and i'm wondering okay well i'm gonna get refunded but you know how long does it take to get those points back into my",
    "start": "7033760",
    "end": "7040480"
  },
  {
    "text": "account so i can say how long to refund points",
    "start": "7040480",
    "end": "7047280"
  },
  {
    "text": "and here it extracted a precise very very narrow answer within 24 hours",
    "start": "7050000",
    "end": "7056800"
  },
  {
    "text": "from this passage that was found from this document that i've indexed and i'm done my search",
    "start": "7056800",
    "end": "7062719"
  },
  {
    "text": "is done i'm not going into documents i'm not scanning for anything this is this is the end of my search",
    "start": "7062719",
    "end": "7067920"
  },
  {
    "text": "very precise right um now my last question my last example here on points",
    "start": "7067920",
    "end": "7073040"
  },
  {
    "text": "is for example i'm wondering okay i'm gonna get those points back but uh do my points ever expire",
    "start": "7073040",
    "end": "7078400"
  },
  {
    "text": "so i can ask the question do my rewards uh reward points expire",
    "start": "7078400",
    "end": "7087840"
  },
  {
    "text": "and again i get my kendra suggested answer at the top here that pulls out that specific section and it bolds",
    "start": "7089360",
    "end": "7095679"
  },
  {
    "text": "the answer points do not expire as long as you are a card holder",
    "start": "7095679",
    "end": "7100719"
  },
  {
    "text": "so it understood the question and it bolded the element that would be my answer precisely there in this section so this",
    "start": "7100719",
    "end": "7107040"
  },
  {
    "text": "passage and the highlighted answer were spot on so this shows you the",
    "start": "7107040",
    "end": "7114639"
  },
  {
    "text": "kendra's ability to perform out of the box really well for this particular use case which happens to be you know customer service",
    "start": "7114639",
    "end": "7121440"
  },
  {
    "text": "and self-serve pages on on a website i want to show you another example here",
    "start": "7121440",
    "end": "7129840"
  },
  {
    "text": "this is a project we recently launched to help accelerate research on kobit 19 for the scientific community",
    "start": "7130000",
    "end": "7136800"
  },
  {
    "text": "and so here we we indexed the publicly available core",
    "start": "7136800",
    "end": "7142400"
  },
  {
    "text": "19 data set which basically contains over 40 000 highly technical articles from leading scientists and institutions",
    "start": "7142400",
    "end": "7149199"
  },
  {
    "text": "about kobe 19. and the search tool is powered by kendra and offers the same natural language",
    "start": "7149199",
    "end": "7154400"
  },
  {
    "text": "understanding capabilities to find very precise answers without any prior training on the data set so let's see how",
    "start": "7154400",
    "end": "7161199"
  },
  {
    "text": "kendra performs in this particular scenario let's actually try some queries here",
    "start": "7161199",
    "end": "7168560"
  },
  {
    "text": "okay so let's say okay i'm searching all of this covet 19 stuff right so i might start with a simple question like where",
    "start": "7168560",
    "end": "7174880"
  },
  {
    "text": "uh did kovid 19 start to see if it finds a location for",
    "start": "7174880",
    "end": "7182840"
  },
  {
    "text": "me okay it brought back this particular passage and it highlighted",
    "start": "7182840",
    "end": "7188000"
  },
  {
    "text": "a location the hubei province in china from this document right so this is spot",
    "start": "7188000",
    "end": "7193360"
  },
  {
    "text": "on i have my answer that's great what if i say okay this is finding a location what about",
    "start": "7193360",
    "end": "7199199"
  },
  {
    "text": "a time frame so what about a time so when did kobe 19 start",
    "start": "7199199",
    "end": "7206320"
  },
  {
    "text": "and right here it extracted december 19 again from this passage from this",
    "start": "7206400",
    "end": "7211520"
  },
  {
    "text": "document in the data set so again very precise um let's keep",
    "start": "7211520",
    "end": "7218159"
  },
  {
    "text": "trying something maybe a little more technical let's find let's ask it um [Music]",
    "start": "7218159",
    "end": "7224400"
  },
  {
    "text": "let's see what's the what's the incubation time [Music] four of it 19.",
    "start": "7224400",
    "end": "7233599"
  },
  {
    "text": "uh what's the incubation",
    "start": "7233920",
    "end": "7240159"
  },
  {
    "text": "i'm for cover 19.",
    "start": "7240159",
    "end": "7243280"
  },
  {
    "text": "okay and uh it tells me five to six days same situation i'm asking different",
    "start": "7246400",
    "end": "7251920"
  },
  {
    "text": "kinds of questions right i'm asking about locations about i'm asking about durations uh i'm asking",
    "start": "7251920",
    "end": "7257440"
  },
  {
    "text": "about uh you know time frames and you know another example could be",
    "start": "7257440",
    "end": "7262560"
  },
  {
    "text": "let's say i'm wondering about how long does the does the virus last or live",
    "start": "7262560",
    "end": "7268000"
  },
  {
    "text": "on different surfaces which is something that has been circulating around so i might ask you know how long um",
    "start": "7268000",
    "end": "7276159"
  },
  {
    "text": "how long covet 19 on plastic and again you know these questions the grammar is not perfect i just want",
    "start": "7276159",
    "end": "7282880"
  },
  {
    "text": "to go quickly but give it enough context to be able to find an answer so how long cover 19 on plastic",
    "start": "7282880",
    "end": "7290000"
  },
  {
    "text": "and again it actually extracted the exact answer for me up to 72 hours from this document here",
    "start": "7290639",
    "end": "7298239"
  },
  {
    "text": "so let's say that wraps up my second demo showing kandra perform in a very different domain a scientific domain highly",
    "start": "7299199",
    "end": "7306400"
  },
  {
    "text": "technical context out of the box no training on this data set so it gives you an idea of how you can",
    "start": "7306400",
    "end": "7312080"
  },
  {
    "text": "deploy kandra in a multitude of of use cases and context and be able to perform",
    "start": "7312080",
    "end": "7317440"
  },
  {
    "text": "really well out of the box and we don't have time today to cover the uh the the relevance tuning options",
    "start": "7317440",
    "end": "7322480"
  },
  {
    "text": "that we have that are very intuitive but there's um a lot of easy to use options in kendra to",
    "start": "7322480",
    "end": "7328239"
  },
  {
    "text": "further refine and fine-tune these uh you know its relevance uh algorithms yeah yeah",
    "start": "7328239",
    "end": "7335920"
  },
  {
    "text": "that is very cool the ability to kind of go in there and",
    "start": "7335920",
    "end": "7340960"
  },
  {
    "text": "type in natural language what you're searching for and the ability for kind of to find those high quality matches is very impressive",
    "start": "7340960",
    "end": "7347920"
  },
  {
    "text": "yeah i think what jumps out to me is in the in the search for an answer to a query or a piece of",
    "start": "7347920",
    "end": "7353599"
  },
  {
    "text": "information we start with sort of like our question in natural language in our head and and you showed sort of the default",
    "start": "7353599",
    "end": "7359679"
  },
  {
    "text": "status quo of the path right it's like a search engine may return a document and then you need to open the document",
    "start": "7359679",
    "end": "7365199"
  },
  {
    "text": "you have to find the passage that may contain the information and then you have to parse that to see if it has it but what kendra's doing here is it tries",
    "start": "7365199",
    "end": "7372639"
  },
  {
    "text": "to abstract away as many of those steps as possible to the point where from a natural language query hopefully it could give",
    "start": "7372639",
    "end": "7378320"
  },
  {
    "text": "us a direct answer we see here on the screen up to 72 hours for this question but even if it can't you know confidently return that it's",
    "start": "7378320",
    "end": "7385119"
  },
  {
    "text": "doing things like pulling out relevant passages it's going another step further and highlighting specific key phrases that",
    "start": "7385119",
    "end": "7390800"
  },
  {
    "text": "are very likely to have relevant information to your answers so that your time from",
    "start": "7390800",
    "end": "7395840"
  },
  {
    "text": "you know questioning your head or query to actual answer is minimized as much as possible",
    "start": "7395840",
    "end": "7401040"
  },
  {
    "text": "that's exactly right that's that's the objective right is to minimize the time from the question to excuse me to the",
    "start": "7401040",
    "end": "7407520"
  },
  {
    "text": "answer so when kendra is very very confident you'll see it up here at the top and when it feels that it",
    "start": "7407520",
    "end": "7414719"
  },
  {
    "text": "requires a little more context then it'll show that passage which still provides your answer right there you're",
    "start": "7414719",
    "end": "7420560"
  },
  {
    "text": "done with your search it just provides a little more context for you to read around it and and get more confidence on the answer so",
    "start": "7420560",
    "end": "7427040"
  },
  {
    "text": "in both cases you your search stops right there on your search results",
    "start": "7427040",
    "end": "7432800"
  },
  {
    "text": "wonderful are there any customers that are using this in the wild i mean we showed you know some examples of how easy it is to set up we showed what it",
    "start": "7432960",
    "end": "7438960"
  },
  {
    "text": "looks like with uh you know the that that data set for covid19 are there any organizations that are using kendra",
    "start": "7438960",
    "end": "7445040"
  },
  {
    "text": "successfully right now yeah so uh some of the examples uh pwc for example uh has a product called",
    "start": "7445040",
    "end": "7452400"
  },
  {
    "text": "regranger and um it's a service offering they have for regulatory compliance",
    "start": "7452400",
    "end": "7457840"
  },
  {
    "text": "and their goal is to help their customers get to the answers they need faster and even when the answer may be buried",
    "start": "7457840",
    "end": "7464800"
  },
  {
    "text": "in documents that are 100 pages long right so they have these really really long documents and just obviously",
    "start": "7464800",
    "end": "7470560"
  },
  {
    "text": "even if you have a search engine on top of that that would give you a match it tells you okay the answer is in the document but now you got to go through",
    "start": "7470560",
    "end": "7476400"
  },
  {
    "text": "100 pages to find what the answer is so here it's really important for them to get to",
    "start": "7476400",
    "end": "7482079"
  },
  {
    "text": "that passage to get to that needle in the haystack basically to go faster right",
    "start": "7482079",
    "end": "7487199"
  },
  {
    "text": "so this is important because they want to make sure their clients understand regulatory information faster and make decisions more quickly and confidently right so as an",
    "start": "7487199",
    "end": "7494800"
  },
  {
    "text": "early early kendra adopter pwc is now developing and testing enhanced search capabilities for their",
    "start": "7494800",
    "end": "7500000"
  },
  {
    "text": "next version of regranger that will allow users to ask natural language questions and this is a dramatic improvement over",
    "start": "7500000",
    "end": "7506560"
  },
  {
    "text": "the traditional keyword searching methods and manual reviews of documents that they've been doing so far another",
    "start": "7506560",
    "end": "7513040"
  },
  {
    "text": "example is 3m which is similar to this covid19 demo that i showed you",
    "start": "7513040",
    "end": "7518480"
  },
  {
    "text": "at 3m it's it's all about accelerating material science research right",
    "start": "7518480",
    "end": "7523920"
  },
  {
    "text": "with over 8 000 material scientists and 1200 new projects every year 3m needs access to",
    "start": "7523920",
    "end": "7530079"
  },
  {
    "text": "information from prior relevant research information that's buried in many patents they hold in their huge",
    "start": "7530079",
    "end": "7536000"
  },
  {
    "text": "knowledge base they've been doing this for years right so kendra lets their scientists find the information they need by handling",
    "start": "7536000",
    "end": "7542079"
  },
  {
    "text": "natural language queries quickly and accurately allowing them to innovate faster collaborate more effectively and",
    "start": "7542079",
    "end": "7548320"
  },
  {
    "text": "accelerate the ongoing stream of unique products for their customers so imagine being able then being able to get the similar",
    "start": "7548320",
    "end": "7554320"
  },
  {
    "text": "the same kinds of answers that we just saw here today on kobe 19 but on a different uh set of technical documents um so this",
    "start": "7554320",
    "end": "7561679"
  },
  {
    "text": "is really key for research as someone who many moons ago did a lot of scientific research i could only imagine how",
    "start": "7561679",
    "end": "7567679"
  },
  {
    "text": "valuable it would be to search like a reagent name and you know be able to come up with an exact passage",
    "start": "7567679",
    "end": "7572800"
  },
  {
    "text": "from a standard operating procedure to know exactly what you need to do instead of having to find the paper dig",
    "start": "7572800",
    "end": "7578239"
  },
  {
    "text": "through those those are maybe not 100 pages long but you know something in that order of magnitude they're very dense um a lot of friction there i'm really",
    "start": "7578239",
    "end": "7585040"
  },
  {
    "text": "excited to see 3m using kendra to solve that pain point yeah and you know it's not just about you know speeding up the the process of",
    "start": "7585040",
    "end": "7592320"
  },
  {
    "text": "finding the information it's it's about liability as well right when you cannot find the information that you're looking for or when your employees cannot find",
    "start": "7592320",
    "end": "7598560"
  },
  {
    "text": "it cannot find the right slp or standard operating procedure it's a liability problem or it can be right so there's a lot of consequences",
    "start": "7598560",
    "end": "7605199"
  },
  {
    "text": "for having uh you know uh low accuracy search in in the enterprise um another another customer is baker",
    "start": "7605199",
    "end": "7612000"
  },
  {
    "text": "tilly uh they're a large consulting services company offering accounting and service and financial advisory and",
    "start": "7612000",
    "end": "7618480"
  },
  {
    "text": "they work very closely with their customers to give them insights on market conditions uh customer preference and trends",
    "start": "7618480",
    "end": "7624000"
  },
  {
    "text": "uh and with kendra they reported that their clients were able to service relevant information 10 times faster",
    "start": "7624000",
    "end": "7630079"
  },
  {
    "text": "than with their sharepoint search so for example uh amazon kendra allowed their product",
    "start": "7630079",
    "end": "7635280"
  },
  {
    "text": "managers to ask questions in everyday language such as what parts are made out of titanium and quickly",
    "start": "7635280",
    "end": "7641440"
  },
  {
    "text": "surface an answer or a list of relevant product manuals technical bulletins service alerts and patent registrations",
    "start": "7641440",
    "end": "7648560"
  },
  {
    "text": "something that was previously not possible with their keyword search solutions they were using in the past",
    "start": "7648560",
    "end": "7654320"
  },
  {
    "text": "so that's a really encouraging use of the technology and we're super excited to work with them",
    "start": "7654320",
    "end": "7659599"
  },
  {
    "text": "and the last example i have here and we have other customers in our customer reference list on the website but this was interesting also because uh",
    "start": "7659599",
    "end": "7665920"
  },
  {
    "text": "workgrid is a fully uh is a wholly owned subsidiary of liberty mutual and they developed a platform to quickly implement chatbot",
    "start": "7665920",
    "end": "7672719"
  },
  {
    "text": "applications that allow employees to get quick answers to frequent ask questions and automate tasks using friendly",
    "start": "7672719",
    "end": "7679119"
  },
  {
    "text": "natural language interface and one of the key things about enterprise chatbot is the ability",
    "start": "7679119",
    "end": "7685679"
  },
  {
    "text": "or one of the key challenges i would say is the ability to answer the myriad of questions that come from employees",
    "start": "7685679",
    "end": "7690960"
  },
  {
    "text": "but that can get really challenging very quickly because chatbots are trained on predefined intents",
    "start": "7690960",
    "end": "7696560"
  },
  {
    "text": "so how do you anticipate all of the variety of questions you can get but now with amazon kendra makes it",
    "start": "7696560",
    "end": "7702320"
  },
  {
    "text": "possible to extract answers directly from unstructured data across multiple repositories so we're",
    "start": "7702320",
    "end": "7707679"
  },
  {
    "text": "super excited to work with workgrid to explore kendra's natural language capabilities to enhance their chatbot",
    "start": "7707679",
    "end": "7712719"
  },
  {
    "text": "platform yeah awesome so just wanted to reiterate what we're announcing today uh",
    "start": "7712719",
    "end": "7719040"
  },
  {
    "text": "well this kendra g8 a few days ago right correct yeah we launched on uh yeah",
    "start": "7719040",
    "end": "7724079"
  },
  {
    "text": "customers can start using this thing yes it's rarely available they just go to aws.amazon.com kendra and",
    "start": "7724079",
    "end": "7730560"
  },
  {
    "text": "again they have those two editions available there um and they can get started today that's",
    "start": "7730560",
    "end": "7736079"
  },
  {
    "text": "wonderful what regions is available in it's available on u.s east u.s west and dublin",
    "start": "7736079",
    "end": "7741520"
  },
  {
    "text": "okay and we'll have plans to expand to many more regions later this year",
    "start": "7741520",
    "end": "7748880"
  },
  {
    "text": "we had a we had a question in chat actually um about whether it recognizes voice input or if it's possible to write",
    "start": "7749199",
    "end": "7754639"
  },
  {
    "text": "an app that embeds it into alexa for example and i think you mentioned before that uh text is the only input for kendra",
    "start": "7754639",
    "end": "7760880"
  },
  {
    "text": "right now but i can imagine that it would be uh not too difficult to take either amazon transcribe or",
    "start": "7760880",
    "end": "7766480"
  },
  {
    "text": "some of the existing tech and alexa to sort of convert that vocal input to text and then query kendra",
    "start": "7766480",
    "end": "7772639"
  },
  {
    "text": "directly with that right absolutely absolutely kendra is really you can you know it it's offered as an",
    "start": "7772639",
    "end": "7778320"
  },
  {
    "text": "api as well right so you can build an application uh to either take input from a web you",
    "start": "7778320",
    "end": "7784000"
  },
  {
    "text": "know search box on a web page or it could be a chat bot application or it could be taken from an alexa scale for example right where",
    "start": "7784000",
    "end": "7790320"
  },
  {
    "text": "the input is actually voice um as long as you're sending us the um the utterance from the from the end user",
    "start": "7790320",
    "end": "7797760"
  },
  {
    "text": "we can perform the search and send it back to you and you can convert that back to uh to voice with the other tools that we offer",
    "start": "7797760",
    "end": "7803679"
  },
  {
    "text": "in the aws services wonderful well rob was hanging out before but kendra",
    "start": "7803679",
    "end": "7809760"
  },
  {
    "text": "now generally available i see three regions here uss u.s east u.s west and dublin with uh",
    "start": "7809760",
    "end": "7816719"
  },
  {
    "text": "seven more by end of year does that sound about right that's correct that's correct yes awesome very exciting very very",
    "start": "7816719",
    "end": "7821840"
  },
  {
    "text": "rapid expansion for service availability um but without further ado yeah jp thank",
    "start": "7821840",
    "end": "7827040"
  },
  {
    "text": "you again for the time the demo was wonderful again in just a few moments we saw how easy it is to set up from scratch",
    "start": "7827040",
    "end": "7832320"
  },
  {
    "text": "integrate with one of the uh provided data sources in this case amazon s3 amongst the many that we have",
    "start": "7832320",
    "end": "7837920"
  },
  {
    "text": "uh first party data connectors for um and then we saw it in action getting to",
    "start": "7837920",
    "end": "7843280"
  },
  {
    "text": "see some of those natural language queries speak like a human and not have to reverse engineer how we need to ask the system to provide us the data",
    "start": "7843280",
    "end": "7849920"
  },
  {
    "text": "that we need um so again jp thank you for the demo uh we will be going to a very quick",
    "start": "7849920",
    "end": "7856079"
  },
  {
    "text": "break yet again uh but then we will be right back to close out the show and with some closing remarks thank you again see you very very soon",
    "start": "7856079",
    "end": "7863840"
  },
  {
    "text": "thank you folks if you're making it through here",
    "start": "7863840",
    "end": "7869360"
  },
  {
    "text": "to the end uh we've been streaming for a little over two hours now almost two and a half hours but uh that's for good reason we've had",
    "start": "7869360",
    "end": "7876480"
  },
  {
    "text": "a lot of very exciting launches that we want to be able to cover here and uh we've gone through quite a few today",
    "start": "7876480",
    "end": "7882320"
  },
  {
    "text": "actually uh this is a record first episode covering four launches we had so much uh so many demos we wanted",
    "start": "7882320",
    "end": "7888719"
  },
  {
    "text": "to show we actually cut out one of the sections in the beginning which i know everyone wants to hear more of rob and i talking but",
    "start": "7888719",
    "end": "7894560"
  },
  {
    "text": "uh we think servicing more of the demos is one of the more important things we can do on this show",
    "start": "7894560",
    "end": "7900079"
  },
  {
    "text": "yeah definitely been one of the more information packed episodes uh thanks to everybody who stuck through",
    "start": "7900079",
    "end": "7905840"
  },
  {
    "text": "you know it's a lot of information but you know i i was excited the whole way through i hope you were as well uh you know nick",
    "start": "7905840",
    "end": "7912079"
  },
  {
    "text": "now that we've seen all the demos can you can you go through uh you know what was most exciting to you what really jumped out at you yeah so",
    "start": "7912079",
    "end": "7918239"
  },
  {
    "text": "i knew coming in i was really excited about a2i amazon augmented ai because i'm an ml geek i",
    "start": "7918239",
    "end": "7924320"
  },
  {
    "text": "work help to build ai systems and this solves a problem that i know everybody has been facing and there has not been a good solution for",
    "start": "7924320",
    "end": "7930480"
  },
  {
    "text": "uh but actually over the course of the broadcast i was probably most impressed by graviton 2 m6g instances like uh i think after you",
    "start": "7930480",
    "end": "7938480"
  },
  {
    "text": "sort of put it into perspective saying that you know all of these other fundamental services built on top of ec2",
    "start": "7938480",
    "end": "7944000"
  },
  {
    "text": "at aws will benefit from this uh you know it's not even just a small percentage single",
    "start": "7944000",
    "end": "7949040"
  },
  {
    "text": "digit percent increase this is you know orders of magnitude like 20 to 40 in some workloads um so i'm",
    "start": "7949040",
    "end": "7954800"
  },
  {
    "text": "really excited to see this and especially you know our own custom hardware our own chips with graviton 2 with annapurna labs that's",
    "start": "7954800",
    "end": "7960880"
  },
  {
    "text": "extremely exciting it's extremely groundbreaking uh it felt like that was way more than just one launch right like our first sixth",
    "start": "7960880",
    "end": "7967360"
  },
  {
    "text": "gen instance class too right this is that one really sort of blew my socks off but again you know four very very exciting",
    "start": "7967360",
    "end": "7974000"
  },
  {
    "text": "launches yeah definitely the uh the the graviton two launch is going to be huge and i can't",
    "start": "7974000",
    "end": "7980480"
  },
  {
    "text": "wait to go and spin a couple instances and play around with myself um i mean you hit the nail on the head",
    "start": "7980480",
    "end": "7986239"
  },
  {
    "text": "this is going to create so many downstream benefits across all number of aws services even if you don't use graviton to directly",
    "start": "7986239",
    "end": "7992880"
  },
  {
    "text": "you're going to benefit from cost savings coming down the road and this is something that we're constantly doing aws to try to deliver better cost structures to customers",
    "start": "7992880",
    "end": "7999040"
  },
  {
    "text": "and the other thing is that you know we keep going back to this custom chip thing it's it's really not an easy thing i mean",
    "start": "7999040",
    "end": "8004239"
  },
  {
    "text": "could you imagine starting a project and going yeah all right uh here's the costing document and the first thing we're going to do is uh",
    "start": "8004239",
    "end": "8010000"
  },
  {
    "text": "you know design a custom chip right we need a new login form step one design a custom chip it doesn't",
    "start": "8010000",
    "end": "8016079"
  },
  {
    "text": "work like that right um but but at aws what we have is uh we have so many workloads across",
    "start": "8016079",
    "end": "8021679"
  },
  {
    "text": "so many industries that making this kind of investment for us is a no-brainer and we're continuously",
    "start": "8021679",
    "end": "8027840"
  },
  {
    "text": "doing it this isn't even our first custom chip um and so you can see that this is the kind of uh um",
    "start": "8027840",
    "end": "8033360"
  },
  {
    "text": "innovation at scale that we referred to in a lot of our talks at re invent this is the kind of investment that we're constantly making",
    "start": "8033360",
    "end": "8039760"
  },
  {
    "text": "to improve these cost structures and deliver better performance lower price for all of our services so it's just really",
    "start": "8039760",
    "end": "8045040"
  },
  {
    "text": "exciting to see that all come together but you know i don't want to to short change any of the other demos",
    "start": "8045040",
    "end": "8051119"
  },
  {
    "text": "this is really an action-packed line probably my favorite episode so far it's been an absolute treat just kind of uh seeing all of the the",
    "start": "8051119",
    "end": "8058079"
  },
  {
    "text": "demos uh really kind of back to back to back um but i want to bring it back to one of",
    "start": "8058079",
    "end": "8063119"
  },
  {
    "text": "the segments that that we do at the end of the show for the past three episodes which is that we we like to play this game where",
    "start": "8063119",
    "end": "8068719"
  },
  {
    "text": "we string together all the announcements into one imaginary service how exactly would we make",
    "start": "8068719",
    "end": "8073840"
  },
  {
    "text": "uh graviton glue adai and kendra work together nick you want to take a first stab at that oh man okay kicking",
    "start": "8073840",
    "end": "8081360"
  },
  {
    "text": "things off here uh so we have a graviton 2 obviously because or the m6g new instance type uh",
    "start": "8081360",
    "end": "8089440"
  },
  {
    "text": "glue streaming etl a2i so all right i'm thinking we've got some sort of data-driven workload here where",
    "start": "8089440",
    "end": "8096000"
  },
  {
    "text": "i don't know how we're going to ingest the data but we're going to have some sort of streaming data source that will power a machine",
    "start": "8096000",
    "end": "8102400"
  },
  {
    "text": "learning model in the middle and then we'll have to fit into a2i so let's say hmm",
    "start": "8102400",
    "end": "8109679"
  },
  {
    "text": "let me think uh let's say we have a uh streaming etl",
    "start": "8109679",
    "end": "8116400"
  },
  {
    "text": "solution for um video data that's coming in maybe we're monitoring this broadcast",
    "start": "8116400",
    "end": "8122159"
  },
  {
    "text": "right and every single time um i don't know like a dog walks across",
    "start": "8122159",
    "end": "8127840"
  },
  {
    "text": "behind me which will have to be front it which will be predicted by a machine learning model it doesn't matter where it is right it could be sagemaker",
    "start": "8127840",
    "end": "8134079"
  },
  {
    "text": "it could be whatever but that video feed those frames where recognition is detecting whether it thinks there's a dog there",
    "start": "8134079",
    "end": "8140239"
  },
  {
    "text": "those will get fed into a2i and if it's not too confident it'll feed those to a human reviewer who's sitting on",
    "start": "8140239",
    "end": "8145280"
  },
  {
    "text": "standby to review if there's a dog that's walking across the frame all right back to you oh",
    "start": "8145280",
    "end": "8152159"
  },
  {
    "text": "crap i thought you were gonna take this the whole way we'll go back and forth uh okay yeah so",
    "start": "8152159",
    "end": "8158079"
  },
  {
    "text": "i i think you're you're in the right ballpark i'm just gonna riff off of that um it has to be kind of uh document",
    "start": "8158079",
    "end": "8163360"
  },
  {
    "text": "based streaming data so i'm thinking maybe um how about",
    "start": "8163360",
    "end": "8168960"
  },
  {
    "text": "a tax prep software and what we can do is use kendra to kind of organize all the irs documents to make",
    "start": "8168960",
    "end": "8176719"
  },
  {
    "text": "answers kind of readily available with natural language processing based search and then as these documents",
    "start": "8176719",
    "end": "8183760"
  },
  {
    "text": "are submitted during tax season let's say that's all coming through with etl",
    "start": "8183760",
    "end": "8189199"
  },
  {
    "text": "streaming via glue and these documents can kind of um we can basically run these different transform jobs extracting various",
    "start": "8189199",
    "end": "8195120"
  },
  {
    "text": "different pieces of data and storing them into a data lake somewhere and in the process uh what we can do is",
    "start": "8195120",
    "end": "8200638"
  },
  {
    "text": "um we can run the augmented ai solution on top of that and say like well okay hold on this document is a little bit abnormal right it's missing this field",
    "start": "8200639",
    "end": "8206960"
  },
  {
    "text": "but it has these amended documents can rai system figure out just what's going on here and if not flag a human",
    "start": "8206960",
    "end": "8212080"
  },
  {
    "text": "down and then they can kind of go through and fill that data out and then if the something's really missing",
    "start": "8212080",
    "end": "8217439"
  },
  {
    "text": "and we need to do some some processing you know some heavy work uh maybe some some compression uh to sort somewhere we can send that",
    "start": "8217440",
    "end": "8223840"
  },
  {
    "text": "off to a um a graviton instance and it can do that uh more quickly more cheaply yeah i",
    "start": "8223840",
    "end": "8229439"
  },
  {
    "text": "actually like the approach you took a little bit better i think it ties everything together a bit more cleanly than mine did but essentially let's say like",
    "start": "8229440",
    "end": "8236080"
  },
  {
    "text": "you said a tax processing software or or foreign processing software document processing software",
    "start": "8236080",
    "end": "8241359"
  },
  {
    "text": "um comes in over glue streaming etl as you know data like let's say like it's",
    "start": "8241360",
    "end": "8246719"
  },
  {
    "text": "real time really as you're filling out on a tablet you can actually get that data being streamed over uh glue etl and processed um that could",
    "start": "8246719",
    "end": "8254399"
  },
  {
    "text": "be sent over to techstract and then that's going to hit our a2i endpoint uh it's searchable maybe those results",
    "start": "8254400",
    "end": "8259920"
  },
  {
    "text": "are searchable via kendra to the internal side of the company or maybe some of the results like the",
    "start": "8259920",
    "end": "8265120"
  },
  {
    "text": "information for how to fill it out is searchable via kendra and then we have graviton too could maybe host our web app right at extremely reduced cost",
    "start": "8265120",
    "end": "8271598"
  },
  {
    "text": "savings we could maybe host like memcached on it to to be able to more quickly serve those cache results to customers um so",
    "start": "8271599",
    "end": "8278558"
  },
  {
    "text": "yeah there we go i think that i think that hits the pass for uh stringing all four of these very different launches",
    "start": "8278559",
    "end": "8284000"
  },
  {
    "text": "together but this is by far the most stressful segment of the show by the way like being put on the spot and say hey",
    "start": "8284000",
    "end": "8290080"
  },
  {
    "text": "look here's here's the secret ingredients for everything toss it together in 30 seconds and come up with something semi-plausible",
    "start": "8290080",
    "end": "8295200"
  },
  {
    "text": "but i mean i think that now that i'm now that we're talking about it it would be a very interesting idea right kind of the demo that jp showed us where",
    "start": "8295200",
    "end": "8300960"
  },
  {
    "text": "you know we basically took a whole bunch of covid related documents and we we pointed kendra at them and we",
    "start": "8300960",
    "end": "8307040"
  },
  {
    "text": "ended up with a nice tool that people can go and search for search through and find really common answers to",
    "start": "8307040",
    "end": "8312478"
  },
  {
    "text": "you know i mean what if we did that with all the irs documents what if we did that with uh you know any document database that has really complicated",
    "start": "8312479",
    "end": "8318638"
  },
  {
    "text": "rules and interconnections between them i feel like kendra kind of really shines in that space",
    "start": "8318639",
    "end": "8324000"
  },
  {
    "text": "yeah i'd be really curious to see i know like tax forms and understanding how to fill out certain sections are a really hard problem i'd be curious",
    "start": "8324000",
    "end": "8330558"
  },
  {
    "text": "how much uh value would be provided of just literally taking the tax uh like like the formal government",
    "start": "8330559",
    "end": "8337040"
  },
  {
    "text": "tax sort of guidance and putting that into kendra and seeing how how effectively it could answer people's questions or or",
    "start": "8337040",
    "end": "8343280"
  },
  {
    "text": "or how about taking the kendra's suggested answer and then feeding it back via a chat bot and the customer says that's not good enough",
    "start": "8343281",
    "end": "8349040"
  },
  {
    "text": "then trigger adai i feel like we're getting in dangerous territory where i'm about to just like do twitch plays fill out my taxes",
    "start": "8349040",
    "end": "8355280"
  },
  {
    "text": "and uh i feel like if we keep going we're gonna be like we're quitting our day jobs we're building this tax startup and we're gonna you know use kendra and we're gonna",
    "start": "8355281",
    "end": "8361920"
  },
  {
    "text": "we'll we'll pitch that show right all of these ridiculous ideas we we take at the end of the show and we have to actually build them live",
    "start": "8361920",
    "end": "8367280"
  },
  {
    "text": "but uh that that's for another time i know some people in chat are excited for that idea but uh we've",
    "start": "8367281",
    "end": "8373120"
  },
  {
    "text": "already been live for two and a half hours so i don't know how much longer we can go on we need uh food and water unfortunately we can't",
    "start": "8373120",
    "end": "8378638"
  },
  {
    "text": "sustain ourselves on the joy of aws service launches um but yeah again this is episode four",
    "start": "8378639",
    "end": "8385840"
  },
  {
    "text": "of aws what's next live thank you again for tuning in we're co-streaming to both twitch on the twitch.tv slash aws channel as",
    "start": "8385840",
    "end": "8393120"
  },
  {
    "text": "well as linkedin live so if you've tuned in either recently or where you've been here for the whole broadcast thank you uh we're happy to always get",
    "start": "8393120",
    "end": "8399359"
  },
  {
    "text": "your questions answered we're also looking into distributing this show on a few other platforms as well we're interested in maybe cutting",
    "start": "8399359",
    "end": "8405520"
  },
  {
    "text": "out the audio and making that available as a podcast some of these sections will be redistributed on some of the service",
    "start": "8405520",
    "end": "8412160"
  },
  {
    "text": "pages and available both as vods here on twitch um on our linkedin page as well as potentially on youtube",
    "start": "8412160",
    "end": "8418479"
  },
  {
    "text": "um so yeah again if you have any feedback please get that sent over to us i believe we have some links in the chat for surveys they come with some",
    "start": "8418479",
    "end": "8426000"
  },
  {
    "text": "you know some aws credits for to thank you for your time but again this is our uh faster than",
    "start": "8426000",
    "end": "8432560"
  },
  {
    "text": "monthly cadence show uh most importantly our next episode is going to be",
    "start": "8432560",
    "end": "8437760"
  },
  {
    "text": "june 5th i believe is that right rob yes that looks like the next episode our",
    "start": "8437760",
    "end": "8442880"
  },
  {
    "text": "date cool yeah running on about a three week cadence so um that is going to about do it from us today we had a",
    "start": "8442880",
    "end": "8449680"
  },
  {
    "text": "blast we hope you did as well uh and again a huge thanks to all the service team members who took the time to join and showcase all the",
    "start": "8449680",
    "end": "8457120"
  },
  {
    "text": "exciting demos uh but with that we are done for today there are many demos that",
    "start": "8457120",
    "end": "8462479"
  },
  {
    "text": "uh we were not able to get to because there are just so many launches uh but we have taken the liberty of",
    "start": "8462479",
    "end": "8468399"
  },
  {
    "text": "assigning those all into a rolling credit slide to close out the show rob any last words before i hit the",
    "start": "8468399",
    "end": "8473520"
  },
  {
    "text": "credits no that's it thanks for sticking uh sticking with us and uh hope you enjoyed the demos yeah and",
    "start": "8473520",
    "end": "8480640"
  },
  {
    "text": "again any and all updates for the show you can follow us on twitter those links are in the chat they should also be on screen now but uh",
    "start": "8480640",
    "end": "8487359"
  },
  {
    "text": "without further ado happy friday everyone have a great weekend and that's closing and signing out from",
    "start": "8487359",
    "end": "8492800"
  },
  {
    "text": "episode four of aws what's next see ya see ya everyone",
    "start": "8492800",
    "end": "8500670"
  },
  {
    "text": "[Music]",
    "start": "8500670",
    "end": "8513280"
  },
  {
    "text": "oh [Music]",
    "start": "8513280",
    "end": "8548530"
  },
  {
    "text": "uh [Music]",
    "start": "8554840",
    "end": "8566700"
  },
  {
    "text": "[Music]",
    "start": "8569140",
    "end": "8591630"
  },
  {
    "text": "[Applause] [Music]",
    "start": "8591630",
    "end": "8595620"
  },
  {
    "text": "so [Applause]",
    "start": "8596840",
    "end": "8603999"
  },
  {
    "text": "[Applause] here we go here we go here we go here we",
    "start": "8610210",
    "end": "8619200"
  },
  {
    "text": "go",
    "start": "8619560",
    "end": "8622560"
  }
]
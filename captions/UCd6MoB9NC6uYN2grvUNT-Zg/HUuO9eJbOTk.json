[
  {
    "start": "0",
    "end": "33000"
  },
  {
    "text": "welcome to part two of the multi-art",
    "start": "5520",
    "end": "8200"
  },
  {
    "text": "series covering best practices building",
    "start": "8200",
    "end": "11080"
  },
  {
    "text": "gen applications on",
    "start": "11080",
    "end": "13679"
  },
  {
    "text": "AWS in this part two video you will",
    "start": "13679",
    "end": "16278"
  },
  {
    "text": "learn how to select the right llm",
    "start": "16279",
    "end": "18800"
  },
  {
    "text": "starting from your business Problem by",
    "start": "18800",
    "end": "21199"
  },
  {
    "text": "going through this Jupiter notebook step",
    "start": "21199",
    "end": "23439"
  },
  {
    "text": "by",
    "start": "23439",
    "end": "24400"
  },
  {
    "text": "step my name is Felix hutmaker I'm an",
    "start": "24400",
    "end": "27840"
  },
  {
    "text": "AWS solution architect covering",
    "start": "27840",
    "end": "30160"
  },
  {
    "text": "analytics and AI mail",
    "start": "30160",
    "end": "33000"
  },
  {
    "start": "33000",
    "end": "153000"
  },
  {
    "text": "services with thousands of llms out",
    "start": "33000",
    "end": "36440"
  },
  {
    "text": "there and new ones coming out every day",
    "start": "36440",
    "end": "39120"
  },
  {
    "text": "it is difficult to figure out which one",
    "start": "39120",
    "end": "41680"
  },
  {
    "text": "to pick evaluating llms is a complex",
    "start": "41680",
    "end": "45960"
  },
  {
    "text": "task and while we have benchmarks like",
    "start": "45960",
    "end": "48440"
  },
  {
    "text": "Helm and hugging faces leaderboard they",
    "start": "48440",
    "end": "51160"
  },
  {
    "text": "only provide a general view of how a",
    "start": "51160",
    "end": "54000"
  },
  {
    "text": "particular llm would perform in some",
    "start": "54000",
    "end": "56840"
  },
  {
    "text": "common NLP tasks most most of the",
    "start": "56840",
    "end": "60519"
  },
  {
    "text": "evaluation Frameworks and approaches are",
    "start": "60519",
    "end": "62640"
  },
  {
    "text": "still evolving and none of them cover",
    "start": "62640",
    "end": "65040"
  },
  {
    "text": "everything therefore figuring out which",
    "start": "65040",
    "end": "68040"
  },
  {
    "text": "Benchmark is the most relevant for your",
    "start": "68040",
    "end": "70640"
  },
  {
    "text": "use case and to be mindful of the social",
    "start": "70640",
    "end": "73640"
  },
  {
    "text": "aspects as well is a task by itself and",
    "start": "73640",
    "end": "77720"
  },
  {
    "text": "ultimately you still need to evaluate",
    "start": "77720",
    "end": "80400"
  },
  {
    "text": "llms against the data of your specific",
    "start": "80400",
    "end": "83439"
  },
  {
    "text": "use",
    "start": "83439",
    "end": "84360"
  },
  {
    "text": "case this notebook attempts to provide a",
    "start": "84360",
    "end": "87640"
  },
  {
    "text": "systematic approach for large language",
    "start": "87640",
    "end": "90000"
  },
  {
    "text": "model evaluation starting from a given",
    "start": "90000",
    "end": "93200"
  },
  {
    "text": "business",
    "start": "93200",
    "end": "94600"
  },
  {
    "text": "problem so what is the business problem",
    "start": "94600",
    "end": "98040"
  },
  {
    "text": "that this notebook covers let's assume",
    "start": "98040",
    "end": "101159"
  },
  {
    "text": "we are a financial analyst who wants to",
    "start": "101159",
    "end": "103600"
  },
  {
    "text": "use financial statements like balance",
    "start": "103600",
    "end": "106200"
  },
  {
    "text": "sheets income statements operational",
    "start": "106200",
    "end": "108840"
  },
  {
    "text": "reports or annual reports to better",
    "start": "108840",
    "end": "112479"
  },
  {
    "text": "understand the financial strength of a",
    "start": "112479",
    "end": "114759"
  },
  {
    "text": "company to help assess risk and guide",
    "start": "114759",
    "end": "118159"
  },
  {
    "text": "future investment decisions",
    "start": "118159",
    "end": "120799"
  },
  {
    "text": "and to do this efficiently we need to",
    "start": "120799",
    "end": "123399"
  },
  {
    "text": "extract information from these documents",
    "start": "123399",
    "end": "125960"
  },
  {
    "text": "which consist largely of unstructured",
    "start": "125960",
    "end": "128840"
  },
  {
    "text": "text so our use case is really",
    "start": "128840",
    "end": "132120"
  },
  {
    "text": "information extraction and as a sample",
    "start": "132120",
    "end": "135160"
  },
  {
    "text": "document we use Amazon's annual report",
    "start": "135160",
    "end": "137879"
  },
  {
    "text": "in this notebook for which we have a set",
    "start": "137879",
    "end": "140280"
  },
  {
    "text": "of questions and answers that function",
    "start": "140280",
    "end": "142879"
  },
  {
    "text": "as our Crown Toof data set but this",
    "start": "142879",
    "end": "146360"
  },
  {
    "text": "approach can easily be adopted to other",
    "start": "146360",
    "end": "149080"
  },
  {
    "text": "documents and as well as an entire",
    "start": "149080",
    "end": "151280"
  },
  {
    "text": "Corpus of documents in general there are",
    "start": "151280",
    "end": "154879"
  },
  {
    "text": "various options for you to choose from",
    "start": "154879",
    "end": "156920"
  },
  {
    "text": "then implementing this Pipeline and",
    "start": "156920",
    "end": "159480"
  },
  {
    "text": "changing any of them can have a big",
    "start": "159480",
    "end": "162200"
  },
  {
    "text": "impact on the overall result in this",
    "start": "162200",
    "end": "165840"
  },
  {
    "text": "notebook we use Amazon Titans embedding",
    "start": "165840",
    "end": "168480"
  },
  {
    "text": "model and open search serverless as a",
    "start": "168480",
    "end": "171200"
  },
  {
    "text": "vector store as we're both fully managed",
    "start": "171200",
    "end": "174560"
  },
  {
    "text": "serverless AWS Services as orchestrator",
    "start": "174560",
    "end": "178400"
  },
  {
    "text": "we are using the Lang chain Library",
    "start": "178400",
    "end": "180840"
  },
  {
    "text": "which we leverage for text splitting and",
    "start": "180840",
    "end": "183959"
  },
  {
    "text": "retrieving relevant chunks from our",
    "start": "183959",
    "end": "186200"
  },
  {
    "text": "Vector",
    "start": "186200",
    "end": "187080"
  },
  {
    "text": "store in addition to the model size and",
    "start": "187080",
    "end": "190239"
  },
  {
    "text": "model type there are other variables",
    "start": "190239",
    "end": "192799"
  },
  {
    "text": "that impact the response of an llm and",
    "start": "192799",
    "end": "197120"
  },
  {
    "text": "experimenting with different user",
    "start": "197120",
    "end": "199040"
  },
  {
    "text": "prompts and templates can improve",
    "start": "199040",
    "end": "201400"
  },
  {
    "text": "results significantly and this alone can",
    "start": "201400",
    "end": "204680"
  },
  {
    "text": "be its own topic so for the purpose of",
    "start": "204680",
    "end": "207760"
  },
  {
    "text": "this model evaluation we just adjusted",
    "start": "207760",
    "end": "210840"
  },
  {
    "text": "the prompts to the specifics of each",
    "start": "210840",
    "end": "214080"
  },
  {
    "start": "214000",
    "end": "275000"
  },
  {
    "text": "lolm once you decided on which options",
    "start": "214080",
    "end": "217799"
  },
  {
    "text": "you want to move forward with you have",
    "start": "217799",
    "end": "220040"
  },
  {
    "text": "to determine which evaluation methods",
    "start": "220040",
    "end": "223360"
  },
  {
    "text": "and metrics you want to consider for",
    "start": "223360",
    "end": "225360"
  },
  {
    "text": "your use case for example if your use",
    "start": "225360",
    "end": "228159"
  },
  {
    "text": "case is text summarization then you",
    "start": "228159",
    "end": "230720"
  },
  {
    "text": "might want to look at a metric like PL",
    "start": "230720",
    "end": "233560"
  },
  {
    "text": "or Rouge but given that the focus of",
    "start": "233560",
    "end": "237040"
  },
  {
    "text": "this notebook is on information",
    "start": "237040",
    "end": "239239"
  },
  {
    "text": "extraction ction we will focus on human",
    "start": "239239",
    "end": "242640"
  },
  {
    "text": "review chard and cine similarity which",
    "start": "242640",
    "end": "246360"
  },
  {
    "text": "compares the llm responses to our Crown",
    "start": "246360",
    "end": "249280"
  },
  {
    "text": "proof data and we will perform a",
    "start": "249280",
    "end": "252360"
  },
  {
    "text": "qualitative assessment of the responses",
    "start": "252360",
    "end": "255680"
  },
  {
    "text": "using Claude as a judge and using",
    "start": "255680",
    "end": "259880"
  },
  {
    "text": "another llm to evaluate the responses is",
    "start": "259880",
    "end": "263919"
  },
  {
    "text": "becoming a very popular approach and",
    "start": "263919",
    "end": "266960"
  },
  {
    "text": "while it's not without its own risks it",
    "start": "266960",
    "end": "270120"
  },
  {
    "text": "is a great way to argument and scale",
    "start": "270120",
    "end": "273280"
  },
  {
    "text": "human evaluations step one is to",
    "start": "273280",
    "end": "276720"
  },
  {
    "start": "275000",
    "end": "395000"
  },
  {
    "text": "understand the capabilities of the top",
    "start": "276720",
    "end": "279120"
  },
  {
    "text": "performing open source and proprietary",
    "start": "279120",
    "end": "281680"
  },
  {
    "text": "llms there are quite a few things that",
    "start": "281680",
    "end": "284240"
  },
  {
    "text": "you want to consider for example what",
    "start": "284240",
    "end": "287080"
  },
  {
    "text": "does the licensing look like for the llm",
    "start": "287080",
    "end": "290360"
  },
  {
    "text": "or whether or not it is fine-tunable and",
    "start": "290360",
    "end": "293520"
  },
  {
    "text": "what data it was trained on also the",
    "start": "293520",
    "end": "296639"
  },
  {
    "text": "number of parameters the maximum context",
    "start": "296639",
    "end": "299560"
  },
  {
    "text": "window length and the speed of the llm",
    "start": "299560",
    "end": "301759"
  },
  {
    "text": "are all important factors to review and",
    "start": "301759",
    "end": "305400"
  },
  {
    "text": "all of these Dimensions will have an",
    "start": "305400",
    "end": "308000"
  },
  {
    "text": "impact on the overall TCO of the",
    "start": "308000",
    "end": "310759"
  },
  {
    "text": "solution and might exclude it from",
    "start": "310759",
    "end": "313199"
  },
  {
    "text": "consideration for this use case",
    "start": "313199",
    "end": "316080"
  },
  {
    "text": "altogether for this use case we",
    "start": "316080",
    "end": "318479"
  },
  {
    "text": "identified the scenarios that best fit",
    "start": "318479",
    "end": "321400"
  },
  {
    "text": "are between question ansers Q&A and",
    "start": "321400",
    "end": "325800"
  },
  {
    "text": "information extraction and upon",
    "start": "325800",
    "end": "327759"
  },
  {
    "text": "reviewing the helm leaderboard we",
    "start": "327759",
    "end": "329720"
  },
  {
    "text": "identified coher command uh llama 270b",
    "start": "329720",
    "end": "333840"
  },
  {
    "text": "and an trophic models for further review",
    "start": "333840",
    "end": "337400"
  },
  {
    "text": "and for the purpose of this demo we",
    "start": "337400",
    "end": "339840"
  },
  {
    "text": "picked cohere command llama",
    "start": "339840",
    "end": "343240"
  },
  {
    "text": "27b and an Tropic CLA V2 since coher and",
    "start": "343240",
    "end": "347720"
  },
  {
    "text": "atropic are available on Amazon batr",
    "start": "347720",
    "end": "351240"
  },
  {
    "text": "which provides the best-in-class lolms",
    "start": "351240",
    "end": "353800"
  },
  {
    "text": "with a fully managed serverless",
    "start": "353800",
    "end": "355840"
  },
  {
    "text": "inference and a simple API which makes",
    "start": "355840",
    "end": "358520"
  },
  {
    "text": "it easy to BU build gen applications",
    "start": "358520",
    "end": "361880"
  },
  {
    "text": "with we also use Lama 27b instead of the",
    "start": "361880",
    "end": "365560"
  },
  {
    "text": "70b version since the 70b version does",
    "start": "365560",
    "end": "369360"
  },
  {
    "text": "not support instruction fine tuning and",
    "start": "369360",
    "end": "372759"
  },
  {
    "text": "7B requires less compute and memory",
    "start": "372759",
    "end": "375960"
  },
  {
    "text": "therefore further reducing the",
    "start": "375960",
    "end": "378520"
  },
  {
    "text": "cost and these are very similar",
    "start": "378520",
    "end": "381440"
  },
  {
    "text": "requirements you will encounter in the",
    "start": "381440",
    "end": "383960"
  },
  {
    "text": "real world where you need to make",
    "start": "383960",
    "end": "385759"
  },
  {
    "text": "decisions between cost boundaries the",
    "start": "385759",
    "end": "388479"
  },
  {
    "text": "ability to customize and not having to",
    "start": "388479",
    "end": "391759"
  },
  {
    "text": "manage inference servers using",
    "start": "391759",
    "end": "394039"
  },
  {
    "text": "serverless",
    "start": "394039",
    "end": "395160"
  },
  {
    "start": "395000",
    "end": "471000"
  },
  {
    "text": "inference having done this we now want",
    "start": "395160",
    "end": "397639"
  },
  {
    "text": "to do a quick short listing using a",
    "start": "397639",
    "end": "399639"
  },
  {
    "text": "subset of test proms for the given task",
    "start": "399639",
    "end": "402440"
  },
  {
    "text": "for a human",
    "start": "402440",
    "end": "404360"
  },
  {
    "text": "inspection and to keep this notebook",
    "start": "404360",
    "end": "407120"
  },
  {
    "text": "digestible we demonstrate this using our",
    "start": "407120",
    "end": "410560"
  },
  {
    "text": "top three models clad V2 coher command",
    "start": "410560",
    "end": "413599"
  },
  {
    "text": "and llama 2 and to run and compare these",
    "start": "413599",
    "end": "417240"
  },
  {
    "text": "prompts quickly we use Lang chains model",
    "start": "417240",
    "end": "421360"
  },
  {
    "text": "laboratory",
    "start": "421360",
    "end": "423319"
  },
  {
    "text": "class and we use prompts like what are",
    "start": "423319",
    "end": "427160"
  },
  {
    "text": "the three main business units of the",
    "start": "427160",
    "end": "431680"
  },
  {
    "text": "company to assess as human evaluator the",
    "start": "431680",
    "end": "436000"
  },
  {
    "text": "quality of the Ln output in terms of",
    "start": "436000",
    "end": "439879"
  },
  {
    "text": "relevance fluency coherence and overall",
    "start": "439879",
    "end": "443680"
  },
  {
    "text": "quality so this approach really offers a",
    "start": "443680",
    "end": "446840"
  },
  {
    "text": "subjective feedback on the model's",
    "start": "446840",
    "end": "448879"
  },
  {
    "text": "performance and just by doing a quick",
    "start": "448879",
    "end": "452080"
  },
  {
    "text": "visual",
    "start": "452080",
    "end": "453240"
  },
  {
    "text": "inspection you can already gauge that",
    "start": "453240",
    "end": "456120"
  },
  {
    "text": "llama 2 which is the purple output here",
    "start": "456120",
    "end": "460280"
  },
  {
    "text": "is a bit chattier compared to coher",
    "start": "460280",
    "end": "464120"
  },
  {
    "text": "commands output based on the question",
    "start": "464120",
    "end": "467120"
  },
  {
    "text": "what are the three main business units",
    "start": "467120",
    "end": "469440"
  },
  {
    "text": "of the",
    "start": "469440",
    "end": "471479"
  },
  {
    "start": "471000",
    "end": "535000"
  },
  {
    "text": "company now after doing the visual",
    "start": "471479",
    "end": "474319"
  },
  {
    "text": "inspection we want to evaluate these",
    "start": "474319",
    "end": "476759"
  },
  {
    "text": "models more systematically and how we",
    "start": "476759",
    "end": "479599"
  },
  {
    "text": "can do this will vary slightly depending",
    "start": "479599",
    "end": "481720"
  },
  {
    "text": "on your use case and what data is",
    "start": "481720",
    "end": "484400"
  },
  {
    "text": "available to you for our use case we",
    "start": "484400",
    "end": "487440"
  },
  {
    "text": "happen to have labeled CR proof data",
    "start": "487440",
    "end": "489560"
  },
  {
    "text": "which we can use for our test therefore",
    "start": "489560",
    "end": "491960"
  },
  {
    "text": "we can leverage classic ml metrics like",
    "start": "491960",
    "end": "496039"
  },
  {
    "text": "accuracy to evaluate the performance of",
    "start": "496039",
    "end": "499280"
  },
  {
    "text": "the different llms but we will also look",
    "start": "499280",
    "end": "502919"
  },
  {
    "text": "at similarity metrics like chard and",
    "start": "502919",
    "end": "505800"
  },
  {
    "text": "cine similarity and human inel is also a",
    "start": "505800",
    "end": "510240"
  },
  {
    "text": "very common technique which we have",
    "start": "510240",
    "end": "512719"
  },
  {
    "text": "touched on briefly during our visual",
    "start": "512719",
    "end": "514919"
  },
  {
    "text": "inspection earlier and finally we will",
    "start": "514919",
    "end": "518159"
  },
  {
    "text": "also use the lolm as a greater approach",
    "start": "518159",
    "end": "521000"
  },
  {
    "text": "in our evaluation after downloading our",
    "start": "521000",
    "end": "524640"
  },
  {
    "text": "raw data in our case the Amazon annual",
    "start": "524640",
    "end": "527839"
  },
  {
    "text": "report use Lang chains token text",
    "start": "527839",
    "end": "530640"
  },
  {
    "text": "splitter to split the document into 189",
    "start": "530640",
    "end": "535160"
  },
  {
    "text": "chunks and then we create a",
    "start": "535160",
    "end": "538360"
  },
  {
    "text": "corresponding in index with a KNN Vector",
    "start": "538360",
    "end": "541720"
  },
  {
    "text": "in open search serverless for our rack",
    "start": "541720",
    "end": "546440"
  },
  {
    "text": "Pipeline and then we Define our prompt",
    "start": "546440",
    "end": "549720"
  },
  {
    "text": "templates and you can see here that we",
    "start": "549720",
    "end": "552240"
  },
  {
    "text": "have specific prompt templates for each",
    "start": "552240",
    "end": "555160"
  },
  {
    "text": "of the",
    "start": "555160",
    "end": "557639"
  },
  {
    "text": "llms and then finally we run all three",
    "start": "558440",
    "end": "561680"
  },
  {
    "text": "of our llms through our prompt catalog",
    "start": "561680",
    "end": "565640"
  },
  {
    "start": "565000",
    "end": "627000"
  },
  {
    "text": "now that we have done that we can start",
    "start": "565640",
    "end": "568680"
  },
  {
    "text": "the evaluation where we use our prompt",
    "start": "568680",
    "end": "571760"
  },
  {
    "text": "catalog with around 200 questions and",
    "start": "571760",
    "end": "574480"
  },
  {
    "text": "answer Pairs and we can look at how",
    "start": "574480",
    "end": "577680"
  },
  {
    "text": "these three llms perform from different",
    "start": "577680",
    "end": "581200"
  },
  {
    "text": "dimensions the first one we are using",
    "start": "581200",
    "end": "583519"
  },
  {
    "text": "here is jackard similarity which is a",
    "start": "583519",
    "end": "586279"
  },
  {
    "text": "common proximity measurement used to",
    "start": "586279",
    "end": "588880"
  },
  {
    "text": "compute the similarity between two items",
    "start": "588880",
    "end": "591880"
  },
  {
    "text": "like for example to Tex",
    "start": "591880",
    "end": "594240"
  },
  {
    "text": "documents the index ranges from 0 to 1",
    "start": "594240",
    "end": "598079"
  },
  {
    "text": "and the closer is is to one the closer",
    "start": "598079",
    "end": "600480"
  },
  {
    "text": "it is to the crown trof",
    "start": "600480",
    "end": "603560"
  },
  {
    "text": "answer",
    "start": "603560",
    "end": "605079"
  },
  {
    "text": "and here you can see a sample output so",
    "start": "605079",
    "end": "608120"
  },
  {
    "text": "here the score was",
    "start": "608120",
    "end": "610800"
  },
  {
    "text": "0.8 and if you do the average across our",
    "start": "610800",
    "end": "614440"
  },
  {
    "text": "200 questions we can see",
    "start": "614440",
    "end": "617519"
  },
  {
    "text": "that here Claud V2 is slightly ahead of",
    "start": "617519",
    "end": "622160"
  },
  {
    "text": "llama 27b with the highest average check",
    "start": "622160",
    "end": "625360"
  },
  {
    "text": "our similarity score the next one is",
    "start": "625360",
    "end": "629399"
  },
  {
    "start": "627000",
    "end": "675000"
  },
  {
    "text": "coine similarity which has a similar",
    "start": "629399",
    "end": "631920"
  },
  {
    "text": "idea the smaller the angle between the",
    "start": "631920",
    "end": "635040"
  },
  {
    "text": "two vectors the more similar they are to",
    "start": "635040",
    "end": "637839"
  },
  {
    "text": "each",
    "start": "637839",
    "end": "640000"
  },
  {
    "text": "other and again green ak1 indicates that",
    "start": "640000",
    "end": "644200"
  },
  {
    "text": "the lolm produced output is very similar",
    "start": "644200",
    "end": "647560"
  },
  {
    "text": "to our Crown trof answer and red in this",
    "start": "647560",
    "end": "651040"
  },
  {
    "text": "heat map indicates that the answer is",
    "start": "651040",
    "end": "653760"
  },
  {
    "text": "not very similar to our Crown roof",
    "start": "653760",
    "end": "658000"
  },
  {
    "text": "data",
    "start": "658040",
    "end": "660399"
  },
  {
    "text": "and just by going through this visually",
    "start": "660399",
    "end": "664200"
  },
  {
    "text": "you can already see that CLA has",
    "start": "664200",
    "end": "667160"
  },
  {
    "text": "slightly more green than llama 2 and",
    "start": "667160",
    "end": "670079"
  },
  {
    "text": "again is slightly ahead compared to the",
    "start": "670079",
    "end": "674160"
  },
  {
    "text": "other two and finally the llm creater",
    "start": "674160",
    "end": "677959"
  },
  {
    "start": "675000",
    "end": "717000"
  },
  {
    "text": "approach where we use another llm in",
    "start": "677959",
    "end": "680959"
  },
  {
    "text": "this case CLA to assess the responses",
    "start": "680959",
    "end": "684279"
  },
  {
    "text": "and determine whether or not the",
    "start": "684279",
    "end": "686120"
  },
  {
    "text": "response is correct and for this here we",
    "start": "686120",
    "end": "689120"
  },
  {
    "text": "use the 2A eval chain class from L chain",
    "start": "689120",
    "end": "694839"
  },
  {
    "text": "which makes it easy to do with ADD scale",
    "start": "694839",
    "end": "698320"
  },
  {
    "text": "and ultimately we can look at each",
    "start": "698320",
    "end": "700720"
  },
  {
    "text": "metric and dimension",
    "start": "700720",
    "end": "704199"
  },
  {
    "text": "individually but we can also use all",
    "start": "704639",
    "end": "707880"
  },
  {
    "text": "three metrics to calculate overall",
    "start": "707880",
    "end": "710639"
  },
  {
    "text": "accuracy and we can see here that claw",
    "start": "710639",
    "end": "713600"
  },
  {
    "text": "overall performs slightly better than",
    "start": "713600",
    "end": "715560"
  },
  {
    "text": "the other",
    "start": "715560",
    "end": "716639"
  },
  {
    "text": "two everything we went through in this",
    "start": "716639",
    "end": "719720"
  },
  {
    "start": "717000",
    "end": "751000"
  },
  {
    "text": "notebook so far focused on accuracy but",
    "start": "719720",
    "end": "724279"
  },
  {
    "text": "speed and cost are two other important",
    "start": "724279",
    "end": "727399"
  },
  {
    "text": "dimensions for llm evaluation as well",
    "start": "727399",
    "end": "731480"
  },
  {
    "text": "for this use case speed is not of",
    "start": "731480",
    "end": "734279"
  },
  {
    "text": "importance as it is not a real-time",
    "start": "734279",
    "end": "737240"
  },
  {
    "text": "pipeline but if it was Amazon sagemaker",
    "start": "737240",
    "end": "740720"
  },
  {
    "text": "inference recommender is a great tool",
    "start": "740720",
    "end": "743160"
  },
  {
    "text": "for performance benchmarks to determine",
    "start": "743160",
    "end": "746199"
  },
  {
    "text": "an inference endpoint that delivers V",
    "start": "746199",
    "end": "749040"
  },
  {
    "text": "best performance at the lowest cost now",
    "start": "749040",
    "end": "752160"
  },
  {
    "start": "751000",
    "end": "899000"
  },
  {
    "text": "a word about cost Amazon betrock",
    "start": "752160",
    "end": "754839"
  },
  {
    "text": "provides llms as a service and offers a",
    "start": "754839",
    "end": "758240"
  },
  {
    "text": "consumption based pay as you go pricing",
    "start": "758240",
    "end": "761079"
  },
  {
    "text": "option as well as a provisioned fruit",
    "start": "761079",
    "end": "763600"
  },
  {
    "text": "put option which is similar to a compute",
    "start": "763600",
    "end": "766920"
  },
  {
    "text": "based pricing model this is different",
    "start": "766920",
    "end": "770000"
  },
  {
    "text": "from Amazon sagemaker while Amazon",
    "start": "770000",
    "end": "773000"
  },
  {
    "text": "sagemaker also has a serverless option",
    "start": "773000",
    "end": "775880"
  },
  {
    "text": "with pays you go pricing serverless",
    "start": "775880",
    "end": "778160"
  },
  {
    "text": "sagemaker and points don't support gpus",
    "start": "778160",
    "end": "780920"
  },
  {
    "text": "or large",
    "start": "780920",
    "end": "782160"
  },
  {
    "text": "instances yet and in this scenario here",
    "start": "782160",
    "end": "785680"
  },
  {
    "text": "we used Amazon betrock with the token",
    "start": "785680",
    "end": "788000"
  },
  {
    "text": "based AK a consumption based pricing",
    "start": "788000",
    "end": "790000"
  },
  {
    "text": "model for coher command and clot V2 and",
    "start": "790000",
    "end": "794480"
  },
  {
    "text": "while llama 2 will be available via",
    "start": "794480",
    "end": "796839"
  },
  {
    "text": "Amazon Bedrock shortly llama 27b in this",
    "start": "796839",
    "end": "800519"
  },
  {
    "text": "test was hosted on a realtime H maker",
    "start": "800519",
    "end": "803360"
  },
  {
    "text": "inference endpoint making this slightly",
    "start": "803360",
    "end": "806120"
  },
  {
    "text": "more expensive at a small volume",
    "start": "806120",
    "end": "809600"
  },
  {
    "text": "but at a bigger volume this can change",
    "start": "809600",
    "end": "811839"
  },
  {
    "text": "quickly for example if you assume 1",
    "start": "811839",
    "end": "814279"
  },
  {
    "text": "million documents then Lama 27b on",
    "start": "814279",
    "end": "818040"
  },
  {
    "text": "sagemaker is significantly more cost",
    "start": "818040",
    "end": "820959"
  },
  {
    "text": "effective than command or clot on",
    "start": "820959",
    "end": "825199"
  },
  {
    "text": "betrock therefore which approach in",
    "start": "825199",
    "end": "827839"
  },
  {
    "text": "model is more cost effective largely",
    "start": "827839",
    "end": "830639"
  },
  {
    "text": "depends on the volume of documents for",
    "start": "830639",
    "end": "833600"
  },
  {
    "text": "this use case and given that our use",
    "start": "833600",
    "end": "835920"
  },
  {
    "text": "case has a high document volume like",
    "start": "835920",
    "end": "838759"
  },
  {
    "text": "Lama 27b wins in the cost category and",
    "start": "838759",
    "end": "842920"
  },
  {
    "text": "given that it performed reasonably well",
    "start": "842920",
    "end": "845560"
  },
  {
    "text": "in terms of accuracy this is the llm",
    "start": "845560",
    "end": "849240"
  },
  {
    "text": "that we will choose to move forward with",
    "start": "849240",
    "end": "852160"
  },
  {
    "text": "given our success criteria this",
    "start": "852160",
    "end": "855040"
  },
  {
    "text": "concludes our model evaluation we looked",
    "start": "855040",
    "end": "857720"
  },
  {
    "text": "predominantly at accuracy but also",
    "start": "857720",
    "end": "860839"
  },
  {
    "text": "discussed speed and cost which is",
    "start": "860839",
    "end": "864480"
  },
  {
    "text": "crucial when you are evaluating your",
    "start": "864480",
    "end": "867040"
  },
  {
    "text": "business case and we will link this",
    "start": "867040",
    "end": "870079"
  },
  {
    "text": "notebook in the description below to",
    "start": "870079",
    "end": "872320"
  },
  {
    "text": "give you a blueprint on how to get",
    "start": "872320",
    "end": "874360"
  },
  {
    "text": "started and of course there's a lot more",
    "start": "874360",
    "end": "877240"
  },
  {
    "text": "that can be done in terms of the",
    "start": "877240",
    "end": "879120"
  },
  {
    "text": "evaluation and I included some thoughts",
    "start": "879120",
    "end": "881639"
  },
  {
    "text": "here as",
    "start": "881639",
    "end": "883120"
  },
  {
    "text": "well thank you for watching part two in",
    "start": "883120",
    "end": "885759"
  },
  {
    "text": "this multi-art series and be on the",
    "start": "885759",
    "end": "888320"
  },
  {
    "text": "lookout for part three which covers how",
    "start": "888320",
    "end": "890839"
  },
  {
    "text": "to improve the llm",
    "start": "890839",
    "end": "894440"
  },
  {
    "text": "performance",
    "start": "897680",
    "end": "900680"
  }
]
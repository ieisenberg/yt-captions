[
  {
    "text": "[Music]",
    "start": "0",
    "end": "11310"
  },
  {
    "text": "to get the most out of this video you",
    "start": "14559",
    "end": "16358"
  },
  {
    "text": "should already have an account with AWS",
    "start": "16359",
    "end": "18560"
  },
  {
    "text": "know how to sign up for AWS Services",
    "start": "18560",
    "end": "21000"
  },
  {
    "text": "know what an Amazon S3 bucket is know",
    "start": "21000",
    "end": "23480"
  },
  {
    "text": "what an Amazon ec2 instances have an",
    "start": "23480",
    "end": "26199"
  },
  {
    "text": "interest in performing data intensive",
    "start": "26199",
    "end": "27960"
  },
  {
    "text": "tasks with your application and our",
    "start": "27960",
    "end": "30039"
  },
  {
    "text": "familiar with the dupe not ready yet",
    "start": "30039",
    "end": "32920"
  },
  {
    "text": "here are some links to each of the",
    "start": "32920",
    "end": "34320"
  },
  {
    "text": "services we will be using in this video",
    "start": "34320",
    "end": "36600"
  },
  {
    "text": "when you're more familiar with them come",
    "start": "36600",
    "end": "38320"
  },
  {
    "text": "back and try out this sample",
    "start": "38320",
    "end": "41280"
  },
  {
    "text": "exercise so just what is Amazon elastic",
    "start": "41280",
    "end": "44440"
  },
  {
    "text": "map ruce basically it's a dupe running",
    "start": "44440",
    "end": "47160"
  },
  {
    "text": "on Amazon web services it uses Amazon E2",
    "start": "47160",
    "end": "50600"
  },
  {
    "text": "for computing power and Amazon S3 for",
    "start": "50600",
    "end": "53160"
  },
  {
    "text": "storage a typical but simplified process",
    "start": "53160",
    "end": "56199"
  },
  {
    "text": "goes like this one store input data two",
    "start": "56199",
    "end": "60120"
  },
  {
    "text": "run a process on the input data across a",
    "start": "60120",
    "end": "62199"
  },
  {
    "text": "bunch of compute instances and three",
    "start": "62199",
    "end": "64080"
  },
  {
    "text": "store the",
    "start": "64080",
    "end": "66600"
  },
  {
    "text": "results so what does that look like here",
    "start": "67159",
    "end": "70080"
  },
  {
    "text": "we have a master instance that assigns",
    "start": "70080",
    "end": "72040"
  },
  {
    "text": "and monitors the job flow a few core",
    "start": "72040",
    "end": "74520"
  },
  {
    "text": "instances that do the heavy work with",
    "start": "74520",
    "end": "76040"
  },
  {
    "text": "the data a few task instances for work",
    "start": "76040",
    "end": "78560"
  },
  {
    "text": "that doesn't require data persistence a",
    "start": "78560",
    "end": "80960"
  },
  {
    "text": "bucket to store the input data that also",
    "start": "80960",
    "end": "83240"
  },
  {
    "text": "contains the script for the process and",
    "start": "83240",
    "end": "85759"
  },
  {
    "text": "a bucket for storing the",
    "start": "85759",
    "end": "87400"
  },
  {
    "text": "results a job flow might go like this",
    "start": "87400",
    "end": "90400"
  },
  {
    "text": "the master instance says you guys go do",
    "start": "90400",
    "end": "93079"
  },
  {
    "text": "this thing with this data and split the",
    "start": "93079",
    "end": "95439"
  },
  {
    "text": "work up this way then put it all back",
    "start": "95439",
    "end": "97399"
  },
  {
    "text": "together over there I will replace you",
    "start": "97399",
    "end": "100040"
  },
  {
    "text": "if you fail meaning that if any of the",
    "start": "100040",
    "end": "102560"
  },
  {
    "text": "core or task instances fail during the",
    "start": "102560",
    "end": "104560"
  },
  {
    "text": "job flow another instance will be",
    "start": "104560",
    "end": "106399"
  },
  {
    "text": "created to take its place we will be",
    "start": "106399",
    "end": "108920"
  },
  {
    "text": "using the word count streaming example",
    "start": "108920",
    "end": "111159"
  },
  {
    "text": "available in the AWS Management console",
    "start": "111159",
    "end": "114200"
  },
  {
    "text": "the sample uses a python script to count",
    "start": "114200",
    "end": "116560"
  },
  {
    "text": "the words in several text files that",
    "start": "116560",
    "end": "118680"
  },
  {
    "text": "exist in an S3 but bucket and then puts",
    "start": "118680",
    "end": "121159"
  },
  {
    "text": "the results in another S3 bucket to show",
    "start": "121159",
    "end": "124280"
  },
  {
    "text": "you the data we are working with we will",
    "start": "124280",
    "end": "126799"
  },
  {
    "text": "navigate to the S3 bucket using S3",
    "start": "126799",
    "end": "129160"
  },
  {
    "text": "organizer for Firefox the files are in a",
    "start": "129160",
    "end": "132040"
  },
  {
    "text": "public bucket called elastic map ruce SL",
    "start": "132040",
    "end": "135120"
  },
  {
    "text": "samples forword count here is the python",
    "start": "135120",
    "end": "139120"
  },
  {
    "text": "script and here are the input files that",
    "start": "139120",
    "end": "141680"
  },
  {
    "text": "contain the words that the python script",
    "start": "141680",
    "end": "143599"
  },
  {
    "text": "will count here we've opened one of the",
    "start": "143599",
    "end": "146200"
  },
  {
    "text": "text files in",
    "start": "146200",
    "end": "147640"
  },
  {
    "text": "notepad we assume that you have an 8 WS",
    "start": "147640",
    "end": "150400"
  },
  {
    "text": "account and have signed up for Amazon",
    "start": "150400",
    "end": "152080"
  },
  {
    "text": "elastic map reduce these are the steps",
    "start": "152080",
    "end": "154480"
  },
  {
    "text": "of the job flow first you would upload",
    "start": "154480",
    "end": "157120"
  },
  {
    "text": "data to an S3 bucket we already have",
    "start": "157120",
    "end": "159640"
  },
  {
    "text": "that data in place in the elastic map",
    "start": "159640",
    "end": "161480"
  },
  {
    "text": "produce samples word count",
    "start": "161480",
    "end": "164120"
  },
  {
    "text": "bucket then we will create our job flow",
    "start": "164120",
    "end": "167159"
  },
  {
    "text": "using the python script to process the",
    "start": "167159",
    "end": "169120"
  },
  {
    "text": "data in this case we're counting words",
    "start": "169120",
    "end": "171280"
  },
  {
    "text": "in text",
    "start": "171280",
    "end": "172560"
  },
  {
    "text": "documents next we'll watch the job flow",
    "start": "172560",
    "end": "174920"
  },
  {
    "text": "start and take a look at our results",
    "start": "174920",
    "end": "177319"
  },
  {
    "text": "let's move over to the Amazon S3 panel",
    "start": "177319",
    "end": "179400"
  },
  {
    "text": "of the 8 WS Management console and",
    "start": "179400",
    "end": "181280"
  },
  {
    "text": "create a bucket for our",
    "start": "181280",
    "end": "184319"
  },
  {
    "text": "results now we'll go back to the Amazon",
    "start": "196959",
    "end": "199200"
  },
  {
    "text": "elastic map produce panel and start our",
    "start": "199200",
    "end": "201360"
  },
  {
    "text": "job flow give your job flow a name then",
    "start": "201360",
    "end": "204879"
  },
  {
    "text": "select the run a sample application",
    "start": "204879",
    "end": "207480"
  },
  {
    "text": "radio button and choose the word count",
    "start": "207480",
    "end": "209439"
  },
  {
    "text": "string sample application then click",
    "start": "209439",
    "end": "212319"
  },
  {
    "text": "continue in the input location field is",
    "start": "212319",
    "end": "215040"
  },
  {
    "text": "the full path to the input bucket we",
    "start": "215040",
    "end": "217200"
  },
  {
    "text": "showed you earlier in the output",
    "start": "217200",
    "end": "219720"
  },
  {
    "text": "location is the full path to the output",
    "start": "219720",
    "end": "221879"
  },
  {
    "text": "bucket we just created change your",
    "start": "221879",
    "end": "224319"
  },
  {
    "text": "bucket to the name you gave the bucket",
    "start": "224319",
    "end": "226000"
  },
  {
    "text": "where you will store your results the",
    "start": "226000",
    "end": "228360"
  },
  {
    "text": "path to the python script is in the",
    "start": "228360",
    "end": "230080"
  },
  {
    "text": "mapper field we will leave the reducer",
    "start": "230080",
    "end": "233040"
  },
  {
    "text": "as Aggregate and click continue for more",
    "start": "233040",
    "end": "236079"
  },
  {
    "text": "information about reducers see the",
    "start": "236079",
    "end": "237720"
  },
  {
    "text": "Amazon elastic map reduce developer go",
    "start": "237720",
    "end": "241400"
  },
  {
    "text": "this is the panel where you will set the",
    "start": "241400",
    "end": "243400"
  },
  {
    "text": "Master Core and task instance groups for",
    "start": "243400",
    "end": "245680"
  },
  {
    "text": "your job flow the master instance group",
    "start": "245680",
    "end": "248360"
  },
  {
    "text": "assigns Hadoop tasks to core and task",
    "start": "248360",
    "end": "250319"
  },
  {
    "text": "nodes and monitors their status you can",
    "start": "250319",
    "end": "253280"
  },
  {
    "text": "select a larger type than the one we",
    "start": "253280",
    "end": "255159"
  },
  {
    "text": "have selected and request a spot",
    "start": "255159",
    "end": "257040"
  },
  {
    "text": "instance here only one of these is",
    "start": "257040",
    "end": "259720"
  },
  {
    "text": "needed the core instance group runs the",
    "start": "259720",
    "end": "262160"
  },
  {
    "text": "Hadoop tasks and stores data using the",
    "start": "262160",
    "end": "264120"
  },
  {
    "text": "Hadoop distributed file system we will",
    "start": "264120",
    "end": "266440"
  },
  {
    "text": "leave this count at two the task",
    "start": "266440",
    "end": "268840"
  },
  {
    "text": "instance group runs Hadoop tasks but",
    "start": "268840",
    "end": "270720"
  },
  {
    "text": "does not persist data and is optional we",
    "start": "270720",
    "end": "273039"
  },
  {
    "text": "won't be using those you can run your",
    "start": "273039",
    "end": "275320"
  },
  {
    "text": "instances without a key pair or select",
    "start": "275320",
    "end": "277479"
  },
  {
    "text": "one you've already created if you want",
    "start": "277479",
    "end": "279880"
  },
  {
    "text": "to be able to SSH into your instances",
    "start": "279880",
    "end": "282320"
  },
  {
    "text": "you must use a key pair we will leave",
    "start": "282320",
    "end": "284960"
  },
  {
    "text": "the rest of the settings on this panel",
    "start": "284960",
    "end": "286840"
  },
  {
    "text": "as is and click continue you can",
    "start": "286840",
    "end": "289880"
  },
  {
    "text": "configure bootstrap actions for now we",
    "start": "289880",
    "end": "292560"
  },
  {
    "text": "will leave the bootstrap actions",
    "start": "292560",
    "end": "294320"
  },
  {
    "text": "settings as they are check that your job",
    "start": "294320",
    "end": "297199"
  },
  {
    "text": "flow settings are correct and if so",
    "start": "297199",
    "end": "299199"
  },
  {
    "text": "click create job flow refresh the screen",
    "start": "299199",
    "end": "302400"
  },
  {
    "text": "and you will see that the job flow",
    "start": "302400",
    "end": "304039"
  },
  {
    "text": "status is",
    "start": "304039",
    "end": "305440"
  },
  {
    "text": "start after the job flow has completed",
    "start": "305440",
    "end": "308039"
  },
  {
    "text": "the status will change to",
    "start": "308039",
    "end": "311000"
  },
  {
    "text": "completed now we'll go back to our",
    "start": "311000",
    "end": "312880"
  },
  {
    "text": "bucket and see the results you have a",
    "start": "312880",
    "end": "315080"
  },
  {
    "text": "number of options in the action dropdown",
    "start": "315080",
    "end": "317880"
  },
  {
    "text": "we're going to select open and open a",
    "start": "317880",
    "end": "320199"
  },
  {
    "text": "result file in",
    "start": "320199",
    "end": "322160"
  },
  {
    "text": "notepad the word a has been used",
    "start": "322160",
    "end": "326280"
  },
  {
    "text": "14716 times a a car",
    "start": "326280",
    "end": "331639"
  },
  {
    "text": "three times accurately two times and",
    "start": "331759",
    "end": "335880"
  },
  {
    "text": "bayth 18 times hm I wonder what this",
    "start": "335880",
    "end": "340000"
  },
  {
    "text": "document was about back at the Amazon",
    "start": "340000",
    "end": "342800"
  },
  {
    "text": "elastic map produce panel we can see",
    "start": "342800",
    "end": "344720"
  },
  {
    "text": "that the instances we created for this",
    "start": "344720",
    "end": "346520"
  },
  {
    "text": "job are in the ended State and the job",
    "start": "346520",
    "end": "349000"
  },
  {
    "text": "has been",
    "start": "349000",
    "end": "350360"
  },
  {
    "text": "terminated for more information about",
    "start": "350360",
    "end": "352639"
  },
  {
    "text": "Amazon elastic map produce visit",
    "start": "352639",
    "end": "356720"
  },
  {
    "text": "http aws.amazon.com",
    "start": "356720",
    "end": "360440"
  },
  {
    "text": "SL elastic map reduce",
    "start": "360440",
    "end": "364680"
  }
]
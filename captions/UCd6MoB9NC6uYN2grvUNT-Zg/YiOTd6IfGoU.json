[
  {
    "text": "Welcome to \"This is My Architecture\".",
    "start": "5568",
    "end": "8424"
  },
  {
    "text": "I'm Orit, and I have with me Yotam from Go Global.\n-Hi, Orit.",
    "start": "8424",
    "end": "11993"
  },
  {
    "text": "Tell us about Go Global.\nGo Global is a hotel consolidator",
    "start": "11996",
    "end": "17339"
  },
  {
    "text": "and technology supplier for the tourism industry.",
    "start": "17339",
    "end": "19962"
  },
  {
    "text": "We have over 230,000 hotels\nand apartments around the world",
    "start": "19962",
    "end": "24632"
  },
  {
    "text": "spread across 15,000 destinations\nin over 200 countries.",
    "start": "24632",
    "end": "29331"
  },
  {
    "text": "Sounds great.\nWhat are we going to talk about today?",
    "start": "29615",
    "end": "31729"
  },
  {
    "text": "Today we'll be talking about the data platforms\nthat our company has developed.",
    "start": "31729",
    "end": "35399"
  },
  {
    "text": "We receive an average of 40 million searches\non our platform each day",
    "start": "35644",
    "end": "41239"
  },
  {
    "text": "and generate 20 million events on a daily basis,\nwhich we send to Kinesis Firehose.",
    "start": "41749",
    "end": "48719"
  },
  {
    "text": "The events are formatted in AVRO,\nwe write them in AVRO",
    "start": "49201",
    "end": "55390"
  },
  {
    "text": "because it's easier for us to send them out\nin this format using our app right from the start.",
    "start": "55404",
    "end": "61583"
  },
  {
    "text": "They all reach one single Kinesis Firehose,\nand from there continue flowing through the platform.",
    "start": "61583",
    "end": "70127"
  },
  {
    "text": "What happens after the Firehose?",
    "start": "70127",
    "end": "73012"
  },
  {
    "text": "Okay, so all of the events reach the Firehose,",
    "start": "73012",
    "end": "79494"
  },
  {
    "text": "which then aggregates different kinds of events\ninto the object that is written into  S3.",
    "start": "79749",
    "end": "85749"
  },
  {
    "text": "Once it's written, we use CloudWatch Events",
    "start": "85749",
    "end": "89359"
  },
  {
    "text": "to trigger the Step Function,",
    "start": "89402",
    "end": "92521"
  },
  {
    "text": "which basically does two things:\nFirstly, it manages the life cycle",
    "start": "92521",
    "end": "97056"
  },
  {
    "text": "of the object itself, that is to say,\nit moves it from the appropriate folders,",
    "start": "97213",
    "end": "100665"
  },
  {
    "text": "and secondly, all done with Lambdas,\nwe take the incoming data",
    "start": "101308",
    "end": "108558"
  },
  {
    "text": "and split it.",
    "start": "108772",
    "end": "111535"
  },
  {
    "text": "As mentioned,\nwe get many different kinds of data here,",
    "start": "111893",
    "end": "115810"
  },
  {
    "text": "many data types, so now we split\naccording to the data type we receive.",
    "start": "115820",
    "end": "122539"
  },
  {
    "text": "Since we sent it through AVRO,\nwe also know the schema,",
    "start": "122539",
    "end": "125424"
  },
  {
    "text": "and each data type has several mandatory fields\naccording to which we know",
    "start": "125457",
    "end": "129521"
  },
  {
    "text": "which data type it is.\nSo we split each data type",
    "start": "129625",
    "end": "137698"
  },
  {
    "text": "and from there we can do -\nthe Lambda does several things.",
    "start": "138327",
    "end": "142881"
  },
  {
    "text": "Firstly, it writes it into the proper place\nin  S3 for further processing.",
    "start": "142938",
    "end": "148600"
  },
  {
    "text": "Secondly, we update an index\nin Elasticsearch as required.",
    "start": "148610",
    "end": "154814"
  },
  {
    "text": "And we also know to maintain\nall the partitions in Glue in Athena,",
    "start": "154932",
    "end": "164598"
  },
  {
    "text": "which Athena uses thanks to this Lambda.",
    "start": "165001",
    "end": "168381"
  },
  {
    "text": "Sounds great. How many different types\nof events do you have?",
    "start": "168531",
    "end": "172277"
  },
  {
    "text": "Today we have about 80 events,\nwith the aim of adding many more.",
    "start": "172299",
    "end": "178329"
  },
  {
    "text": "What happens when a new event is created,\nwhen the app decides to create a new event?",
    "start": "178439",
    "end": "183894"
  },
  {
    "text": "The developer is in charge\nof adding new events.",
    "start": "183895",
    "end": "189826"
  },
  {
    "text": "They need to define the class -\nwhich is actually the event -",
    "start": "189826",
    "end": "193128"
  },
  {
    "text": "define it with code, fill it with data",
    "start": "193679",
    "end": "195720"
  },
  {
    "text": "and use a standard tool\nin order to send the data to Firehose.",
    "start": "195721",
    "end": "200456"
  },
  {
    "text": "That's all you need to do code-wise,\nit's a matter of minutes.",
    "start": "201082",
    "end": "206276"
  },
  {
    "text": "Another thing they need to do\nis define the table in Athena,",
    "start": "206608",
    "end": "209539"
  },
  {
    "text": "there's a small utility in the code that generates\nthe DDL needed to create the table,",
    "start": "209545",
    "end": "215584"
  },
  {
    "text": "but other than that,\nyou don't need to do anything else,",
    "start": "215590",
    "end": "218540"
  },
  {
    "text": "and the distance between needing a data type\nand a data type that's already in  S3",
    "start": "218584",
    "end": "225025"
  },
  {
    "text": "and is queryable in Athena\nis a matter of about five minutes.",
    "start": "225048",
    "end": "228936"
  },
  {
    "text": "So a developer who decides to add a new event\ndoesn't need to know how the data platform is built",
    "start": "228936",
    "end": "235873"
  },
  {
    "text": "and doesn't need to change the infrastructure.\nThey simply add the event, update it,",
    "start": "236047",
    "end": "241689"
  },
  {
    "text": "and the system already knows to receive it and...\n-Right.",
    "start": "241689",
    "end": "246911"
  },
  {
    "text": "To bring it to the data lake.\n-The whole idea, or one of the needs we had",
    "start": "247064",
    "end": "252095"
  },
  {
    "text": "when building this system was actually,\nas you said,",
    "start": "252425",
    "end": "254709"
  },
  {
    "text": "so that the developers won't need to do\nanything in the system or even know it.",
    "start": "254956",
    "end": "261423"
  },
  {
    "text": "This only creates friction, which slows down\ndevelopment. They need things to just work:",
    "start": "261634",
    "end": "267215"
  },
  {
    "text": "define the data type, define the table\nin Athena if required, and run with it.",
    "start": "267381",
    "end": "272370"
  },
  {
    "text": "Great. Who are the users of the data lake?\nWho are the consumers?",
    "start": "272677",
    "end": "276598"
  },
  {
    "text": "We have four main consumers:\nFirstly, R&D who  use Elasticsearch",
    "start": "277000",
    "end": "285583"
  },
  {
    "text": "and Athena both for immediate needs\nas well as for investigating issues.",
    "start": "285960",
    "end": "294737"
  },
  {
    "text": "The second group is Operations,\nwho also use both Elasticsearch and Athena",
    "start": "295172",
    "end": "301775"
  },
  {
    "text": "and to a certain extent also QuickSight.",
    "start": "302452",
    "end": "306514"
  },
  {
    "text": "We should mention that the data passes\nfrom S3 to Redshift through an Airflow Cluster",
    "start": "306600",
    "end": "311880"
  },
  {
    "text": "which runs ETLs hourly or daily,\nas required.",
    "start": "311913",
    "end": "316724"
  },
  {
    "text": "The third group of users\nis our Customer Success team",
    "start": "318315",
    "end": "321107"
  },
  {
    "text": "who actually make use of all these tools,\nboth for customers with a pressing issue -",
    "start": "321801",
    "end": "330152"
  },
  {
    "text": "for which they use Elasticsearch - as well as\nfor things requiring targeted investigation",
    "start": "330240",
    "end": "334233"
  },
  {
    "text": "or to get an aggregation that isn't currently\ncalculated in Airflow. This is done on Athena,",
    "start": "334240",
    "end": "340005"
  },
  {
    "text": "through the console. And also for data -\nwe use QuickSight dashboards",
    "start": "340010",
    "end": "347345"
  },
  {
    "text": "that read the data from Redshift\nwritten through Airflow.",
    "start": "347345",
    "end": "350184"
  },
  {
    "text": "And the fourth group is  business users,\nwho also use QuickSight",
    "start": "350441",
    "end": "355883"
  },
  {
    "text": "with the dashboards we have there,\nand also use a third party app",
    "start": "355890",
    "end": "360900"
  },
  {
    "text": "called ClickView in order to read Redshift data\nthat is aggregated through Airflow.",
    "start": "360900",
    "end": "367272"
  },
  {
    "text": "Sounds amazing.\nYou've actually built a generic data platform",
    "start": "367272",
    "end": "372989"
  },
  {
    "text": "to be used on top of data lake architecture and S3,\nwith a materialized view in Elasticsearch,",
    "start": "372989",
    "end": "382569"
  },
  {
    "text": "Redshift, different consumers\nin the organization who can consume the data.\nSounds great. Thank you, Yotam,",
    "start": "382883",
    "end": "389378"
  },
  {
    "text": "and thanks for watching\n\"This is My Architecture\".",
    "start": "389690",
    "end": "393222"
  },
  {
    "text": "Thank you for watching\nFor more information visit\naws.amazon.com/this-is-my-architecture",
    "start": "394172",
    "end": "398253"
  },
  {
    "text": "aws",
    "start": "398600",
    "end": "400000"
  }
]
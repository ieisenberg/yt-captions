[
  {
    "start": "0",
    "end": "42000"
  },
  {
    "text": "hi there my name is Carmen sharmajev and",
    "start": "659",
    "end": "3360"
  },
  {
    "text": "I'm a senior specialist Solutions",
    "start": "3360",
    "end": "4740"
  },
  {
    "text": "architect with AWS today I want to show",
    "start": "4740",
    "end": "7799"
  },
  {
    "text": "you how to copy data from Salesforce",
    "start": "7799",
    "end": "10200"
  },
  {
    "text": "into Amazon simple storage service with",
    "start": "10200",
    "end": "13259"
  },
  {
    "text": "Amazon upflow",
    "start": "13259",
    "end": "14820"
  },
  {
    "text": "Amazon upflow is a fully managed",
    "start": "14820",
    "end": "17100"
  },
  {
    "text": "integration service that helps you",
    "start": "17100",
    "end": "19080"
  },
  {
    "text": "securely transfer data between software",
    "start": "19080",
    "end": "21480"
  },
  {
    "text": "as a service applications such as",
    "start": "21480",
    "end": "23699"
  },
  {
    "text": "Salesforce sap Google analytics Facebook",
    "start": "23699",
    "end": "27660"
  },
  {
    "text": "ads service now and many owners and AWS",
    "start": "27660",
    "end": "32340"
  },
  {
    "text": "services such as Amazon simple storage",
    "start": "32340",
    "end": "34500"
  },
  {
    "text": "service and Amazon redshift with just a",
    "start": "34500",
    "end": "38040"
  },
  {
    "text": "few clicks and without writing any code",
    "start": "38040",
    "end": "42559"
  },
  {
    "start": "42000",
    "end": "61000"
  },
  {
    "text": "here is the reference architecture of",
    "start": "42660",
    "end": "44340"
  },
  {
    "text": "what we're gonna build today we will use",
    "start": "44340",
    "end": "46680"
  },
  {
    "text": "Amazon upflow to connect to our",
    "start": "46680",
    "end": "48780"
  },
  {
    "text": "Salesforce instance and securely",
    "start": "48780",
    "end": "50760"
  },
  {
    "text": "transfer data such as leads accounts and",
    "start": "50760",
    "end": "54239"
  },
  {
    "text": "opportunities into Amazon S3 now join me",
    "start": "54239",
    "end": "58320"
  },
  {
    "text": "on the AWS console and let's build the",
    "start": "58320",
    "end": "60539"
  },
  {
    "text": "solution",
    "start": "60539",
    "end": "61920"
  },
  {
    "start": "61000",
    "end": "108000"
  },
  {
    "text": "we are on the AWS console where you can",
    "start": "61920",
    "end": "64559"
  },
  {
    "text": "find Amazon upflow under the application",
    "start": "64559",
    "end": "66840"
  },
  {
    "text": "integration group",
    "start": "66840",
    "end": "68700"
  },
  {
    "text": "in order for upflow to work there are",
    "start": "68700",
    "end": "71280"
  },
  {
    "text": "two constructs that we need to build the",
    "start": "71280",
    "end": "73439"
  },
  {
    "text": "first one is called a connection and",
    "start": "73439",
    "end": "75540"
  },
  {
    "text": "this is the physical connection between",
    "start": "75540",
    "end": "77520"
  },
  {
    "text": "the Amazon upflow service and your SAS",
    "start": "77520",
    "end": "80700"
  },
  {
    "text": "application so we will choose a",
    "start": "80700",
    "end": "82920"
  },
  {
    "text": "connector Salesforce and we will create",
    "start": "82920",
    "end": "85200"
  },
  {
    "text": "a new connection",
    "start": "85200",
    "end": "86640"
  },
  {
    "text": "we will give the connection a name",
    "start": "86640",
    "end": "90360"
  },
  {
    "text": "and we will click connect",
    "start": "90360",
    "end": "92220"
  },
  {
    "text": "Amazon upflow will launch a dialogue and",
    "start": "92220",
    "end": "95040"
  },
  {
    "text": "ask us to log in into our Salesforce",
    "start": "95040",
    "end": "97020"
  },
  {
    "text": "application",
    "start": "97020",
    "end": "97979"
  },
  {
    "text": "and to allow the Amazon upflow embedded",
    "start": "97979",
    "end": "100619"
  },
  {
    "text": "login application to be installed so",
    "start": "100619",
    "end": "102960"
  },
  {
    "text": "that upload can securely connect and",
    "start": "102960",
    "end": "105600"
  },
  {
    "text": "communicate with our Salesforce instance",
    "start": "105600",
    "end": "107579"
  },
  {
    "text": "now that we have our connection created",
    "start": "107579",
    "end": "109740"
  },
  {
    "start": "108000",
    "end": "220000"
  },
  {
    "text": "let's create our first flow from the",
    "start": "109740",
    "end": "112979"
  },
  {
    "text": "left menu navigate to flows and click",
    "start": "112979",
    "end": "115439"
  },
  {
    "text": "create flow give the flow a name",
    "start": "115439",
    "end": "118920"
  },
  {
    "text": "click next",
    "start": "118920",
    "end": "120299"
  },
  {
    "text": "select your source of data which is",
    "start": "120299",
    "end": "122759"
  },
  {
    "text": "Salesforce and then select the",
    "start": "122759",
    "end": "124740"
  },
  {
    "text": "connection that we just created now with",
    "start": "124740",
    "end": "127140"
  },
  {
    "text": "Salesforce you can ingest either objects",
    "start": "127140",
    "end": "129360"
  },
  {
    "text": "or events for our use case we're gonna",
    "start": "129360",
    "end": "132599"
  },
  {
    "text": "ingest objects so that we're gonna",
    "start": "132599",
    "end": "134819"
  },
  {
    "text": "select an account object",
    "start": "134819",
    "end": "138599"
  },
  {
    "text": "as a destination let's choose Amazon S3",
    "start": "138599",
    "end": "141540"
  },
  {
    "text": "and for the purpose of this",
    "start": "141540",
    "end": "143340"
  },
  {
    "text": "demonstration I have already created an",
    "start": "143340",
    "end": "146099"
  },
  {
    "text": "S3 bucket which I'm going to select",
    "start": "146099",
    "end": "149340"
  },
  {
    "text": "when transferring Salesforce object with",
    "start": "149340",
    "end": "151739"
  },
  {
    "text": "Amazon app flow you have two options to",
    "start": "151739",
    "end": "155099"
  },
  {
    "text": "trigger your flow when on demand means",
    "start": "155099",
    "end": "158160"
  },
  {
    "text": "that we will need to trigger this flow",
    "start": "158160",
    "end": "160200"
  },
  {
    "text": "manually through the AWS console via an",
    "start": "160200",
    "end": "163440"
  },
  {
    "text": "API call or an SDK",
    "start": "163440",
    "end": "166319"
  },
  {
    "text": "around flow on schedule means we can",
    "start": "166319",
    "end": "168660"
  },
  {
    "text": "configure a flow to run on a regular",
    "start": "168660",
    "end": "171000"
  },
  {
    "text": "time interval and bring data in",
    "start": "171000",
    "end": "173879"
  },
  {
    "text": "we're going to run overflow on demand",
    "start": "173879",
    "end": "175860"
  },
  {
    "text": "and on the next screen we need to select",
    "start": "175860",
    "end": "178680"
  },
  {
    "text": "the source and destination field mapping",
    "start": "178680",
    "end": "181920"
  },
  {
    "text": "in this step we need to select What",
    "start": "181920",
    "end": "184620"
  },
  {
    "text": "fields from our account object we want",
    "start": "184620",
    "end": "186780"
  },
  {
    "text": "to bring into Amazon S3 and because",
    "start": "186780",
    "end": "189420"
  },
  {
    "text": "Amazon S3 is a seamless destination we",
    "start": "189420",
    "end": "192239"
  },
  {
    "text": "can opt in and choose map all Fields",
    "start": "192239",
    "end": "194580"
  },
  {
    "text": "directly which will create a one-to-one",
    "start": "194580",
    "end": "196920"
  },
  {
    "text": "mapping I'm not going to create any",
    "start": "196920",
    "end": "199379"
  },
  {
    "text": "partitioning aggregations for",
    "start": "199379",
    "end": "201540"
  },
  {
    "text": "validations now I'm gonna add any",
    "start": "201540",
    "end": "204360"
  },
  {
    "text": "filters into my setup this is everything",
    "start": "204360",
    "end": "208019"
  },
  {
    "text": "that we need to do the last step is just",
    "start": "208019",
    "end": "210180"
  },
  {
    "text": "a preview and then we need to create our",
    "start": "210180",
    "end": "212640"
  },
  {
    "text": "flow and because this flow is an",
    "start": "212640",
    "end": "214739"
  },
  {
    "text": "on-demand flow we will manually have to",
    "start": "214739",
    "end": "217080"
  },
  {
    "text": "run it to the AWS console by clicking",
    "start": "217080",
    "end": "219360"
  },
  {
    "text": "the Run flow button and as you can see",
    "start": "219360",
    "end": "221640"
  },
  {
    "text": "in less than six seconds upflow was able",
    "start": "221640",
    "end": "226080"
  },
  {
    "text": "to connect to our Salesforce instance",
    "start": "226080",
    "end": "227700"
  },
  {
    "text": "and bring in 16 records from our",
    "start": "227700",
    "end": "230940"
  },
  {
    "text": "instance into Amazon S3 now if we go to",
    "start": "230940",
    "end": "234599"
  },
  {
    "text": "our Amazon S3 destination we can see",
    "start": "234599",
    "end": "237540"
  },
  {
    "text": "that we have a folder and inside this",
    "start": "237540",
    "end": "240120"
  },
  {
    "text": "folder we have one file Amazon upflow",
    "start": "240120",
    "end": "243299"
  },
  {
    "text": "implements incremental query model which",
    "start": "243299",
    "end": "245940"
  },
  {
    "text": "means it will bring data in Pages if our",
    "start": "245940",
    "end": "249659"
  },
  {
    "text": "data set is large that means that by",
    "start": "249659",
    "end": "252420"
  },
  {
    "text": "default if you don't use any",
    "start": "252420",
    "end": "253920"
  },
  {
    "text": "aggregations upflow will bring the data",
    "start": "253920",
    "end": "257100"
  },
  {
    "text": "into several different files and because",
    "start": "257100",
    "end": "259859"
  },
  {
    "text": "our Salesforce data was relatively small",
    "start": "259859",
    "end": "262280"
  },
  {
    "text": "upflow was able to write all these data",
    "start": "262280",
    "end": "265080"
  },
  {
    "text": "into a single S3 option now we can",
    "start": "265080",
    "end": "268440"
  },
  {
    "text": "choose to preview our data by using S3",
    "start": "268440",
    "end": "271380"
  },
  {
    "text": "select so I will select our object and I",
    "start": "271380",
    "end": "274259"
  },
  {
    "text": "will click query with S3 select",
    "start": "274259",
    "end": "277199"
  },
  {
    "text": "by default app flow will bring the data",
    "start": "277199",
    "end": "279780"
  },
  {
    "text": "in Json format it is a Json lines and we",
    "start": "279780",
    "end": "283680"
  },
  {
    "text": "will run a select star from S3 object",
    "start": "283680",
    "end": "286380"
  },
  {
    "text": "query",
    "start": "286380",
    "end": "287580"
  },
  {
    "text": "and as you can see we have our data",
    "start": "287580",
    "end": "290639"
  },
  {
    "text": "visualized here",
    "start": "290639",
    "end": "292560"
  },
  {
    "text": "thank you for joining me for this five",
    "start": "292560",
    "end": "294360"
  },
  {
    "text": "minutes demonstration of how you can",
    "start": "294360",
    "end": "296639"
  },
  {
    "text": "bring data from Salesforce into Amazon",
    "start": "296639",
    "end": "298800"
  },
  {
    "text": "simple storage service using a fully",
    "start": "298800",
    "end": "301259"
  },
  {
    "text": "managed no code service called Amazon",
    "start": "301259",
    "end": "303600"
  },
  {
    "text": "app flow",
    "start": "303600",
    "end": "306440"
  }
]
[
  {
    "start": "0",
    "end": "41000"
  },
  {
    "text": "all right sorry about that guys so thank you all for joining and waiting",
    "start": "1129",
    "end": "6210"
  },
  {
    "text": "patiently we have a really awesome session for you guys to see here today my name is Martin cyril with AWS",
    "start": "6210",
    "end": "12120"
  },
  {
    "text": "professional services so we work with large enterprises on their migration to the cloud",
    "start": "12120",
    "end": "17539"
  },
  {
    "text": "we started working with Toyota Racing Development beginning of this year on their architecture for real-time data",
    "start": "17539",
    "end": "23699"
  },
  {
    "text": "ingestion and what they ended up running with and building is one of the coolest things I think I've ever seen so I you",
    "start": "23699",
    "end": "29789"
  },
  {
    "text": "know we knew that we had to get them up here to talk about the awesome stuff they're doing so without further ado I'll give you Jason chambers and Philip",
    "start": "29789",
    "end": "37440"
  },
  {
    "text": "Lowe with Toyota Racing Development",
    "start": "37440",
    "end": "41390"
  },
  {
    "start": "41000",
    "end": "247000"
  },
  {
    "text": "hello thank you is how Troy racing development makes racing decisions in real time with AWS in this session today",
    "start": "43670",
    "end": "51149"
  },
  {
    "text": "we're gonna talk about how we use DynamoDB and may the challenges that it brings to our particular data set",
    "start": "51149",
    "end": "56910"
  },
  {
    "text": "specifically time series data will be we use this with dynamic DB and we stream",
    "start": "56910",
    "end": "63000"
  },
  {
    "text": "it out using dynamic DV streams we'll be talking about that and also how we take these dynamic these DB streams and use",
    "start": "63000",
    "end": "69479"
  },
  {
    "text": "the data real time and also how we have what we call a turbo mode which is going to be an accelerated way to reread these",
    "start": "69479",
    "end": "75930"
  },
  {
    "text": "streams something you can't do natively with dynamic do these dreams we are Toyota Racing Development we",
    "start": "75930",
    "end": "83130"
  },
  {
    "text": "handle all of the technical aspects of Toyotas Motorsports program in the United States we develop and fabricate",
    "start": "83130",
    "end": "90990"
  },
  {
    "text": "engines for all of Toyotas motorsports programs in Costa Mesa California and we also provide data and software solutions",
    "start": "90990",
    "end": "98400"
  },
  {
    "text": "to our team partners for the major series NASCAR that would be we have five drivers in that series",
    "start": "98400",
    "end": "104310"
  },
  {
    "text": "number eleven Denny Hamlin number eighteen Kyle Busch number 19 Carl Edwards number 20 Matt Kenseth and",
    "start": "104310",
    "end": "111360"
  },
  {
    "text": "number 78 Martin Truex Jr so at Toyota racing we use data in",
    "start": "111360",
    "end": "117810"
  },
  {
    "text": "almost everything we do it's on a day to day basis it's all about data and analyzing data so we kind of take our",
    "start": "117810",
    "end": "123780"
  },
  {
    "text": "data and divide it into two two types of data one is more batching this happens pre-race this is stuff that happens",
    "start": "123780",
    "end": "129929"
  },
  {
    "text": "during the week leading up to a race our race engineers will and model",
    "start": "129929",
    "end": "135290"
  },
  {
    "text": "simulations that they can do to modify cars even though it's stopped stock",
    "start": "135290",
    "end": "140430"
  },
  {
    "text": "racing for NASCAR there's still a number of things that we can change modify and swap parts in it out and our race",
    "start": "140430",
    "end": "146310"
  },
  {
    "text": "engineers use our systems to make better predictions and make better decisions on how to modify the cars and prepare them",
    "start": "146310",
    "end": "152400"
  },
  {
    "text": "for the coming week they do this so we can have the fastest car every weekend we also work with the drivers so we'll",
    "start": "152400",
    "end": "159450"
  },
  {
    "text": "take data that we have in between practice and qualifying sessions and give them visualizations they can use to",
    "start": "159450",
    "end": "165180"
  },
  {
    "text": "help improve their lap times we want every time to qualify in the top and be starting every every Sunday in the top",
    "start": "165180",
    "end": "171510"
  },
  {
    "text": "of the field any this is data that we batch this is something that doesn't need to be real-time we have time to",
    "start": "171510",
    "end": "178020"
  },
  {
    "text": "batch it process and get it ready but we do need it within minutes and this is opposed to live data well",
    "start": "178020",
    "end": "184110"
  },
  {
    "text": "we'll be talking about today this happens during the race this is real-time data we're feeding through",
    "start": "184110",
    "end": "189390"
  },
  {
    "text": "we're making real-time and a little analytics on this analyzing this running it through simulations and we use this",
    "start": "189390",
    "end": "196140"
  },
  {
    "text": "for split-second decisions during the race our crew chiefs use the visualizations and data we provide them",
    "start": "196140",
    "end": "201630"
  },
  {
    "text": "in order to make real-time race strategy decisions so these that and they need this data",
    "start": "201630",
    "end": "207480"
  },
  {
    "text": "right away in NASCAR there's you know things happen very quickly some of our tracks are only a quarter mile long and",
    "start": "207480",
    "end": "212959"
  },
  {
    "text": "they have you know our lap times are 25 seconds they have they have to make a decision if there's a caution they need",
    "start": "212959",
    "end": "218880"
  },
  {
    "text": "to decide right away whether or not they're going to pit if they pit how many tires are gonna do and what other modifications are gonna go they're gonna",
    "start": "218880",
    "end": "226049"
  },
  {
    "text": "go into the car and we need this data within seconds we don't have time to wait around for it",
    "start": "226049",
    "end": "231440"
  },
  {
    "text": "in fact one of the favorite things I like working about Toyota Racing Development is every week I get to see",
    "start": "231440",
    "end": "237570"
  },
  {
    "text": "the results of my work unfold every day live or every week unfold live on Sunday",
    "start": "237570",
    "end": "243350"
  },
  {
    "text": "here's bill so",
    "start": "243350",
    "end": "249110"
  },
  {
    "text": "I'm not going to talk about how our services are set up at TRD to provide this real-time data to the track",
    "start": "249110",
    "end": "257328"
  },
  {
    "text": "most of our real-time services and software are developed on JavaScript",
    "start": "257700",
    "end": "262960"
  },
  {
    "text": "here at TR d in relation to the application we're going to deep dive into colatina we've built the backend on",
    "start": "262960",
    "end": "270210"
  },
  {
    "text": "no js' the dynamic data which we receive life during the race sessions that i",
    "start": "270210",
    "end": "276340"
  },
  {
    "text": "includes practice qualifying at the race we store that in two DynamoDB streams",
    "start": "276340",
    "end": "282040"
  },
  {
    "text": "and also and for the persistent data so the storage of that dynamic data",
    "start": "282040",
    "end": "287110"
  },
  {
    "text": "for long-term use we also use dynamo DB but in addition we keep a copy of that",
    "start": "287110",
    "end": "292240"
  },
  {
    "text": "in s3 and finally for the caching services we use Amazon ElastiCache",
    "start": "292240",
    "end": "298890"
  },
  {
    "text": "for the front-end also done in JavaScript we've pasted the framework on",
    "start": "298890",
    "end": "304090"
  },
  {
    "text": "Google Paulo polymer and the dynamic data which the backend is processing is",
    "start": "304090",
    "end": "309580"
  },
  {
    "text": "served up to the clients via a meteo stream so I'm gonna talk about how the data",
    "start": "309580",
    "end": "316600"
  },
  {
    "text": "flows through our components in the Athene application and we'll start from",
    "start": "316600",
    "end": "321940"
  },
  {
    "text": "the left and we'll walk away to the right so the starting point is the raw",
    "start": "321940",
    "end": "328060"
  },
  {
    "text": "data feed we get from nasca which is the live timing feed so that comes in it arrives into our first component called",
    "start": "328060",
    "end": "335110"
  },
  {
    "text": "the data scraper in this sense it's the nazca track data scraper and the function of that component is simple it",
    "start": "335110",
    "end": "341700"
  },
  {
    "text": "passes the raw data feed into a JSON object and stores into dynamo dB we also",
    "start": "341700",
    "end": "347320"
  },
  {
    "text": "have other data scrapers such as the weather data scraper and as you can guess that scrapes live weather from the",
    "start": "347320",
    "end": "353169"
  },
  {
    "text": "track and also store that into dynamo dB in addition to storing in dynamo we have",
    "start": "353169",
    "end": "360400"
  },
  {
    "text": "a lambda that's running which takes a copy of that and keeps pushing that into s3 fire firehose service",
    "start": "360400",
    "end": "366780"
  },
  {
    "text": "so once all the data is in dynamo DB the first component which actually works at",
    "start": "366780",
    "end": "372580"
  },
  {
    "text": "this raw data and starts adding value to it is the arbiter component and what",
    "start": "372580",
    "end": "378220"
  },
  {
    "text": "that does it takes the raw data interleaves it by time and then starts adding additional metrics to it such as",
    "start": "378220",
    "end": "384400"
  },
  {
    "text": "gap to the confront or gap to the leader and doing all those calculations we need",
    "start": "384400",
    "end": "389979"
  },
  {
    "text": "to be able to maintain should there be any outages so we are constantly caching it periodically to ElastiCache should",
    "start": "389979",
    "end": "397090"
  },
  {
    "text": "there be any problems in addition we also take note of the sequence number",
    "start": "397090",
    "end": "402580"
  },
  {
    "text": "which were reading off the dynamodb stream and we checkpoint that with our state and we also cache that together so",
    "start": "402580",
    "end": "409120"
  },
  {
    "text": "there is something bad that happens we can resume our calculations and also resume exactly where in the stream we",
    "start": "409120",
    "end": "415150"
  },
  {
    "text": "last left off when the crash happened once the arbiter is done processing all",
    "start": "415150",
    "end": "421060"
  },
  {
    "text": "the calculations it stores it into three separate locations firstly a subset of the calculations are",
    "start": "421060",
    "end": "427720"
  },
  {
    "text": "stored into MongoDB where that gets streamed up to the end clients via media",
    "start": "427720",
    "end": "432940"
  },
  {
    "text": "stream and second and thirdly we start back into dynamo DB and to s3 again and",
    "start": "432940",
    "end": "439120"
  },
  {
    "text": "that purpose serves as the support of race and genius to do that pre race and post race analysis on this data",
    "start": "439120",
    "end": "447449"
  },
  {
    "start": "449000",
    "end": "915000"
  },
  {
    "text": "all right let's talk dynamo DB this is the first point where data comes in",
    "start": "449040",
    "end": "454260"
  },
  {
    "text": "there's number reasons we chose DynamoDB of course we want the decoupling of the",
    "start": "454260",
    "end": "461770"
  },
  {
    "text": "collection of data to our analysis we never want an issue and analyzing the data to ever cause an interruption in",
    "start": "461770",
    "end": "468280"
  },
  {
    "text": "our ability to collect raw data and done a MIDI B provides an easy abstraction where people can write and we can read",
    "start": "468280",
    "end": "474430"
  },
  {
    "text": "it out we can have multiple data sources coming in to die at dynamic DV and it's very",
    "start": "474430",
    "end": "479680"
  },
  {
    "text": "easy to scale up as we are adding more data sources we can increase our write throughput to handle additional data sources",
    "start": "479680",
    "end": "486180"
  },
  {
    "text": "and we can listen to this as a stream this is very important live during the race we can we can stream the data out",
    "start": "486180",
    "end": "492240"
  },
  {
    "text": "dynamodb has what's called dynamic DB streams and is essentially an op log of dynamo DB every create update or delete",
    "start": "492240",
    "end": "499630"
  },
  {
    "text": "gets streamed out through dynamic DB streams and then as a byproduct because",
    "start": "499630",
    "end": "505390"
  },
  {
    "text": "we're using dynamic DB this data is stored permanently we can go back our race engineers can go back to previous",
    "start": "505390",
    "end": "511000"
  },
  {
    "text": "races if we're we as we return to the track they can look at previous years we've been there and they can run more",
    "start": "511000",
    "end": "517390"
  },
  {
    "text": "macro level analysis on this data and it'll persist as long as we want it which is forever",
    "start": "517390",
    "end": "523550"
  },
  {
    "text": "and of course it's an AWS managed service unlike some of the other databases that a device offers DynamoDB",
    "start": "523550",
    "end": "530420"
  },
  {
    "text": "is completely managed in fact really the only two settings you have are how much write throughput you want and how much",
    "start": "530420",
    "end": "535430"
  },
  {
    "text": "read throughput you want and we also have the added benefit that using I am roles we can easily do access",
    "start": "535430",
    "end": "542150"
  },
  {
    "text": "control and it's not just on a table level basis with DynamoDB we can we can control who can see what columns and we",
    "start": "542150",
    "end": "548780"
  },
  {
    "text": "can even use access control to determine which rows are shown",
    "start": "548780",
    "end": "553750"
  },
  {
    "text": "let's go a little let's go even deeper into dynamic DB and how it works because",
    "start": "554230",
    "end": "560090"
  },
  {
    "text": "we want to talk about hot hashes eventually so I like to describe dynamo DB as a map",
    "start": "560090",
    "end": "567080"
  },
  {
    "text": "of binary trees and our and we use on them a DB you when you play your primary",
    "start": "567080",
    "end": "572600"
  },
  {
    "text": "Keys you divide your primary Keys into a hash and arrange your hash is going to determine where what partition your data",
    "start": "572600",
    "end": "578360"
  },
  {
    "text": "is stored on and eventually which node within dynamic DB that is which means records with equal hashes will end up on",
    "start": "578360",
    "end": "585380"
  },
  {
    "text": "the same partition and put and also in the same node but this also means that if we want a",
    "start": "585380",
    "end": "591230"
  },
  {
    "text": "query data and get a specific record we have to add a minimum know the hash if we don't know the hash that's gonna end",
    "start": "591230",
    "end": "597260"
  },
  {
    "text": "up doing a table scan which are very bad and dynamit EB once we get to the partition and the",
    "start": "597260",
    "end": "602600"
  },
  {
    "text": "node where it's stored we can use the range the range part of the primary key determines how the data is sorted within",
    "start": "602600",
    "end": "609560"
  },
  {
    "text": "that partition which means we have a combination of both a hash and the range then we can go immediately to the record",
    "start": "609560",
    "end": "615560"
  },
  {
    "text": "that we're looking for and these are very fast queries but also means that when we decide when",
    "start": "615560",
    "end": "621980"
  },
  {
    "text": "you first start developing our dynamic DB solution will you the selection of the hash in the rain has probably the",
    "start": "621980",
    "end": "627380"
  },
  {
    "text": "largest performance impact of your dynamic DB solution and it can cause and",
    "start": "627380",
    "end": "632870"
  },
  {
    "text": "it can make or break whether you're whether your queries happen on time and if it's able to scale up",
    "start": "632870",
    "end": "639430"
  },
  {
    "text": "and if on the Amazon website through the developer guide they have a number of",
    "start": "639790",
    "end": "645760"
  },
  {
    "text": "suggestions and maybe the ideas for how you might how you might choose a hash",
    "start": "645760",
    "end": "653410"
  },
  {
    "text": "and we have one here for time series data item creation date we can round to",
    "start": "653650",
    "end": "658900"
  },
  {
    "text": "the nearest day hour minute it doesn't matter the amazon says it's bad it is because all of our day is gonna",
    "start": "658900",
    "end": "665860"
  },
  {
    "text": "end up in the same partition it'll end up in the same node and by the nature of our race we're always gonna be very much",
    "start": "665860",
    "end": "671380"
  },
  {
    "text": "interested in what's happening now our race engineers are always going to be interested in what happened last week whereas races that were in the in the",
    "start": "671380",
    "end": "679270"
  },
  {
    "text": "past a little less a little less access to those but remember in order to access data at",
    "start": "679270",
    "end": "685420"
  },
  {
    "text": "a minimum we have to know the hash so this means our desire to eliminate hot hashes is in direct conflict with our",
    "start": "685420",
    "end": "692230"
  },
  {
    "text": "desire to access data for a particular query for a particular race",
    "start": "692230",
    "end": "697740"
  },
  {
    "text": "so we need to eliminate the hot hashes but still be able to query our data in a time-series way",
    "start": "697830",
    "end": "703170"
  },
  {
    "text": "so there's a few ways we can we can mitigate this now we can use separate tables we can use manual hashing or we",
    "start": "703170",
    "end": "710830"
  },
  {
    "text": "can use composite keys separate tables is pretty simple we just",
    "start": "710830",
    "end": "718839"
  },
  {
    "text": "create a different table for every race or every day and it all goes together",
    "start": "718839",
    "end": "725670"
  },
  {
    "text": "but we can do some things such as older races where we're not accessing them very often we can we can tone down the",
    "start": "725670",
    "end": "732279"
  },
  {
    "text": "read throughput and the right throughput whereas most the most recent races everyone's gonna be interested in we can we can tone that up",
    "start": "732279",
    "end": "739650"
  },
  {
    "text": "next is manual partitioning this is something where we have time series data",
    "start": "740790",
    "end": "746080"
  },
  {
    "text": "we have a lot of data that's coming in on in this case November 20th we don't know how that we want to make",
    "start": "746080",
    "end": "752680"
  },
  {
    "text": "sure it's not all going into the same node we can just manually take a random number and add it to it in this case I",
    "start": "752680",
    "end": "757750"
  },
  {
    "text": "took a random number from 1 to 10 this is good this gives us a real good",
    "start": "757750",
    "end": "762760"
  },
  {
    "text": "random even distribution because we're using a random number on here we're not limited to 10 depending on how much we",
    "start": "762760",
    "end": "768100"
  },
  {
    "text": "need to scale we go up to a hundred or a thousand the important thing to note though is when it's time to query this data we're",
    "start": "768100",
    "end": "773830"
  },
  {
    "text": "gonna have to increase the number of queries we do if we want an entire race worth of data we have to now do 10",
    "start": "773830",
    "end": "779140"
  },
  {
    "text": "queries and this isn't as problematic as it might first seem because of the",
    "start": "779140",
    "end": "784420"
  },
  {
    "text": "nature of dynamic DB data is already partitioned out amongst loads so in fact the our ability to query this and ten",
    "start": "784420",
    "end": "790880"
  },
  {
    "text": "different parallel queries actually can increase our throughput to getting this data",
    "start": "790880",
    "end": "796390"
  },
  {
    "text": "the next the next solution is composite keys and this is what we used a TRD it's essentially the same thing as manual",
    "start": "796930",
    "end": "803450"
  },
  {
    "text": "partitions except instead of using a random value we're gonna use a known value that pertains to that record",
    "start": "803450",
    "end": "810100"
  },
  {
    "text": "one example we first started with is the record type the record type for us tells us where",
    "start": "810100",
    "end": "818180"
  },
  {
    "text": "the record came from the source of the data what kind of type of data it has so if we have roughly 20 record types",
    "start": "818180",
    "end": "824360"
  },
  {
    "text": "this could cause the same distribution to say a random number but it has the added benefit is if we're",
    "start": "824360",
    "end": "832190"
  },
  {
    "text": "looking for a particular piece of data or a particular source of data we can narrow in on that right away and not get",
    "start": "832190",
    "end": "837920"
  },
  {
    "text": "extraneous data we're not interested in when we first started doing our proof of concept we start with the easiest what",
    "start": "837920",
    "end": "843800"
  },
  {
    "text": "we thought was just the the race ID or the date and this works great for one or two",
    "start": "843800",
    "end": "849710"
  },
  {
    "text": "races but as as we add more and more data we start seeing that it's taking several minutes to come back which is",
    "start": "849710",
    "end": "856580"
  },
  {
    "text": "not a great experience for our race engineers as we add as we added its record type that helped us out a little",
    "start": "856580",
    "end": "862310"
  },
  {
    "text": "bit we got our queries down to about a minute still not good enough which then leads us to our final iteration which",
    "start": "862310",
    "end": "867620"
  },
  {
    "text": "was also adding lap number so if we have a race with 500 laps and 2020 record",
    "start": "867620",
    "end": "873140"
  },
  {
    "text": "types we're gonna be a partition our data up into 10,000 different partitions and potentially up to 10,000 different",
    "start": "873140",
    "end": "879050"
  },
  {
    "text": "nodes within dynamodb for parallel queries and it's important to note that",
    "start": "879050",
    "end": "884800"
  },
  {
    "text": "if you miss not called a date if it behaves like a date we're gonna have the same problem with with hot hashes if we",
    "start": "884800",
    "end": "891680"
  },
  {
    "text": "call it race ID it's behaving just like a date and we're still going to have the same issue",
    "start": "891680",
    "end": "897730"
  },
  {
    "text": "so with this solution we can now query the data all at once and we get the data as fast as we need and pacing as fast as",
    "start": "898720",
    "end": "904850"
  },
  {
    "text": "we can analyze it we can stream it out of dynamic DP",
    "start": "904850",
    "end": "908860"
  },
  {
    "start": "915000",
    "end": "1407000"
  },
  {
    "text": "so I'm not gonna talk about the real-time aspect of dine over TV DynamoDB streams let's hope that stays",
    "start": "915499",
    "end": "924040"
  },
  {
    "text": "so as you recall in my earlier slide the arbiter component was created to monitor",
    "start": "924040",
    "end": "929389"
  },
  {
    "text": "dynamo DB as streams and it does this by issuing a set of AWS API calls to",
    "start": "929389",
    "end": "935420"
  },
  {
    "text": "essentially tail the stream for updates however here tre we've written a",
    "start": "935420",
    "end": "940610"
  },
  {
    "text": "JavaScript wrapper which simplifies all these calls and makes the invocation a lot easier and we share this across all",
    "start": "940610",
    "end": "947180"
  },
  {
    "text": "the other trt components and services which you need to do this as well now it's important to note that if your",
    "start": "947180",
    "end": "953499"
  },
  {
    "text": "native Java developer that AWS already offers this library on their website",
    "start": "953499",
    "end": "958759"
  },
  {
    "text": "it's the Kinesis client library you can download it now available at the box and it does the same thing however do you",
    "start": "958759",
    "end": "965480"
  },
  {
    "text": "feel it's important to understand what's going on underneath the hood so you can so appreciate what KCl is doing to",
    "start": "965480",
    "end": "971120"
  },
  {
    "text": "handle the complexities of managing or tailing a dynamodb stream",
    "start": "971120",
    "end": "978040"
  },
  {
    "text": "so let's run through the basic calls that you need to do to actually tail the",
    "start": "978040",
    "end": "983629"
  },
  {
    "text": "stream so you first start off by issuing the list stream API call and what that",
    "start": "983629",
    "end": "989029"
  },
  {
    "text": "does it returns you all the stream arms which are associated with your AWS",
    "start": "989029",
    "end": "994399"
  },
  {
    "text": "account so these are the blue arrows here so we're interested in the biggest blue arrows for this example and so we",
    "start": "994399",
    "end": "1001209"
  },
  {
    "text": "find that based on the description and we'll take that string on which is a good unique identifier and we'll feed at",
    "start": "1001209",
    "end": "1007449"
  },
  {
    "text": "your next called describe stream 1 what the describe stream call does it will return to you all the shards associated",
    "start": "1007449",
    "end": "1014740"
  },
  {
    "text": "with that stream so depending on how long you're running it you may have multiple shards and what we're after is",
    "start": "1014740",
    "end": "1021160"
  },
  {
    "text": "the active shot the shot that's we're currently receiving data",
    "start": "1021160",
    "end": "1026610"
  },
  {
    "text": "once we've identified it so in this case is the box right at the bottom here we'll take the shot ID and we'll feed it",
    "start": "1026610",
    "end": "1034240"
  },
  {
    "text": "into the next call get shot iterator and the function that gets shot aerator is to give you a pointer on where the batch",
    "start": "1034240",
    "end": "1042788"
  },
  {
    "text": "of records you want to pull out and I'm gonna elaborate on this a little bit more because a charity the options",
    "start": "1042789",
    "end": "1049480"
  },
  {
    "text": "given for the cash are iterators made it very easy for us to move around the stream based on different racing areas",
    "start": "1049480",
    "end": "1055830"
  },
  {
    "text": "so the get shot or the iterator has three to four options you can feed into",
    "start": "1055830",
    "end": "1061150"
  },
  {
    "text": "it first and secondly it's these after a sequence number and as you recall we can",
    "start": "1061150",
    "end": "1068140"
  },
  {
    "text": "do that to pinpoint exactly where in the stream we want to resume from which is perfect for traffic covery so every time",
    "start": "1068140",
    "end": "1076060"
  },
  {
    "text": "we read a record you get a sequence number you can stall that cash it away and can resume to it whenever you want",
    "start": "1076060",
    "end": "1083070"
  },
  {
    "text": "thirdly there's the trim horizon and the trim horizon allows you to move right to",
    "start": "1083070",
    "end": "1088540"
  },
  {
    "text": "the beginning of the stream so if you were to start up our services late we can move straight to the beginning of the race without faffing around looking",
    "start": "1088540",
    "end": "1095470"
  },
  {
    "text": "for a sequence number looking for time dates and all that we just hit supervise and off we go now it's ponder to note",
    "start": "1095470",
    "end": "1101260"
  },
  {
    "text": "that you can only go back as far as 24 hours that's the maximum retention period for a dynamodb stream",
    "start": "1101260",
    "end": "1109060"
  },
  {
    "text": "and finally you have the latest and that moves you to the tail of the stream so",
    "start": "1109060",
    "end": "1114760"
  },
  {
    "text": "that's our default operation mode whenever we started up we go straight to the tail stream and off we go so they'll",
    "start": "1114760",
    "end": "1119980"
  },
  {
    "text": "be raced on now as tables have partitions as Jason",
    "start": "1119980",
    "end": "1128020"
  },
  {
    "text": "was talking about shards streams have shots and shards are bounded by a",
    "start": "1128020",
    "end": "1133240"
  },
  {
    "text": "min/max hash ID and a min max sequence number so shown by the box at the top in",
    "start": "1133240",
    "end": "1140470"
  },
  {
    "text": "the diagram now if you think about it logically as you fill up the shard finally you will get full and a new shot",
    "start": "1140470",
    "end": "1147940"
  },
  {
    "text": "will be created and dynamodb does this automatically so you'll get expired shots and you get new active shots now",
    "start": "1147940",
    "end": "1154620"
  },
  {
    "text": "DynamoDB will also automatically shot for you if you had increased throughput requirements specifically increase write",
    "start": "1154620",
    "end": "1161290"
  },
  {
    "text": "throughput requirements and it does this by splitting your shot which is great it's very useful you can scale your",
    "start": "1161290",
    "end": "1167290"
  },
  {
    "text": "input automatically you don't have to do anything it just does it for you however it does pose as a double-edged sword",
    "start": "1167290",
    "end": "1174270"
  },
  {
    "text": "because as you as you recall from the previous slide you need to track the shot iterators to get your records so",
    "start": "1174270",
    "end": "1181480"
  },
  {
    "text": "you're no longer tracking one shot it already tracking two or if you have it shot it up for you again automatically",
    "start": "1181480",
    "end": "1187690"
  },
  {
    "text": "to all eight or more so then tracking becomes could become problematic",
    "start": "1187690",
    "end": "1195750"
  },
  {
    "text": "so this is one of the key problems we hit during our early development cycles",
    "start": "1196140",
    "end": "1202980"
  },
  {
    "text": "where when streaming we had to actively monitor the shot to determine when it",
    "start": "1202980",
    "end": "1209200"
  },
  {
    "text": "expired because you don't get any notifications on when a expires and when it does you",
    "start": "1209200",
    "end": "1216160"
  },
  {
    "text": "start looking for the new active shot now the culture for us was we always",
    "start": "1216160",
    "end": "1221260"
  },
  {
    "text": "expected the new shot to be available straight out once it seems expired where's the next one we'll grab it and",
    "start": "1221260",
    "end": "1226930"
  },
  {
    "text": "off we go but that's not the case there is a time like from the point that it expires to the point of new shot gets",
    "start": "1226930",
    "end": "1232990"
  },
  {
    "text": "created so in order to overcome that you have to continuously be looking for new",
    "start": "1232990",
    "end": "1238300"
  },
  {
    "text": "active shots also the handle when the shot splits into",
    "start": "1238300",
    "end": "1243660"
  },
  {
    "text": "so you can imagine in early the development cycles doing a race out",
    "start": "1243660",
    "end": "1249780"
  },
  {
    "text": "of the blue the system would just stop and that's because we didn't handle the",
    "start": "1249780",
    "end": "1255370"
  },
  {
    "text": "shot incorrectly and we just we didn't pick up the new active shot or in an order case we only had half the cars",
    "start": "1255370",
    "end": "1261880"
  },
  {
    "text": "updating because the shot had split and we only caught one of the active shots",
    "start": "1261880",
    "end": "1267630"
  },
  {
    "text": "so how do we mitigate this commonly we'll do functional tests to mitigate this but it's difficult to do with",
    "start": "1269580",
    "end": "1277810"
  },
  {
    "text": "dynamodb streams because you cannot control when a stream three shots however those who have what if Kinesis",
    "start": "1277810",
    "end": "1284640"
  },
  {
    "text": "may realize that the api is very similar not the same as Kinesis and you can",
    "start": "1284640",
    "end": "1290650"
  },
  {
    "text": "leverage this you can use Kinesis to simulate the streams and forestry sharding so we can test the handling of",
    "start": "1290650",
    "end": "1296170"
  },
  {
    "text": "your code in nodejs here we use kins electoral functional testing and a view",
    "start": "1296170",
    "end": "1302440"
  },
  {
    "text": "on the same boat I highly recommend it's a very nice light package which can do to simulate this and trigger these shots",
    "start": "1302440",
    "end": "1309340"
  },
  {
    "text": "and just to reiterate almost devastating bugs were due to the",
    "start": "1309340",
    "end": "1315820"
  },
  {
    "text": "inability to handle the sharding within a dynamodb stream",
    "start": "1315820",
    "end": "1321059"
  },
  {
    "text": "since I've talked about Kinesis I thought it'd be good to provide a quick",
    "start": "1322470",
    "end": "1328049"
  },
  {
    "text": "table just to show you the differences between the two so let's talk about persistence first",
    "start": "1328049",
    "end": "1333690"
  },
  {
    "text": "DynamoDB allows you to persist data in two forms first as a stream which allows",
    "start": "1333690",
    "end": "1339279"
  },
  {
    "text": "you to store data up to 24 hours and secondly as a table and you can store that for as long as you need to for",
    "start": "1339279",
    "end": "1344940"
  },
  {
    "text": "Kinesis of our hand its stream only so you can do that from 24 hours or up to 7",
    "start": "1344940",
    "end": "1350499"
  },
  {
    "text": "days that's configurable in the console shouting as I was talking about for",
    "start": "1350499",
    "end": "1355929"
  },
  {
    "text": "dynamodb is automatic which is good and bad and for Canisius it's manual so if",
    "start": "1355929",
    "end": "1361419"
  },
  {
    "text": "you know your load upfront you can set it off you go for querying you can query",
    "start": "1361419",
    "end": "1367200"
  },
  {
    "text": "DynamoDB either as a stream which is series data or as a table at hall",
    "start": "1367200",
    "end": "1372570"
  },
  {
    "text": "Kinesis as it's just a stream that's that's all you got you can only query as series data stream latency so we did",
    "start": "1372570",
    "end": "1380470"
  },
  {
    "text": "tests at TR D is a full round-trip running out reading back in diamo DVD so",
    "start": "1380470",
    "end": "1385480"
  },
  {
    "text": "about one second latency but for Kinesis we saw it drop to about two to four hundred milliseconds so there's some",
    "start": "1385480",
    "end": "1391240"
  },
  {
    "text": "gains there and finally form of billing perspective dynamodb the charge on a per read basis",
    "start": "1391240",
    "end": "1397389"
  },
  {
    "text": "and Kinesis it's a per shot and write basis so depending on use case one may favor the other",
    "start": "1397389",
    "end": "1405059"
  },
  {
    "text": "cool all right let's talk turbo mode we're gonna bring in fire hose and",
    "start": "1406720",
    "end": "1412360"
  },
  {
    "start": "1407000",
    "end": "1553000"
  },
  {
    "text": "lambda so we have a scenario we're running we the race is going great we're analyzing data we're we're making our",
    "start": "1412360",
    "end": "1420340"
  },
  {
    "text": "visualizations for our race engineers and now our race engineers have discovered that the model is either incorrect or they found a better model",
    "start": "1420340",
    "end": "1427510"
  },
  {
    "text": "that we want to switch to and the problems we want to reprocess all of the data as fast as we can and then catch",
    "start": "1427510",
    "end": "1433030"
  },
  {
    "text": "back up live because dynamic DB streams has a read limit you can only read so",
    "start": "1433030",
    "end": "1438190"
  },
  {
    "text": "fast if we were to if we were to read it through the dynamo DB stream the race would be over by the time we reprocessed everything so a solution is to read the",
    "start": "1438190",
    "end": "1446080"
  },
  {
    "text": "data from an alternative source and then switch back to the stream right where we left off but the problem is we need to",
    "start": "1446080",
    "end": "1452020"
  },
  {
    "text": "know exactly where in the stream we want to pick back up from so our solution is when we're storing the data out to an",
    "start": "1452020",
    "end": "1458830"
  },
  {
    "text": "alternative source we want to store both the raw record and the sequence number for that record for where it word exists",
    "start": "1458830",
    "end": "1465490"
  },
  {
    "text": "in the stream and lambda provides a good way for us to",
    "start": "1465490",
    "end": "1470559"
  },
  {
    "text": "do this so nice easy scenario what we all we really want is we want our raw record and our sequence numbers so we",
    "start": "1470559",
    "end": "1476500"
  },
  {
    "text": "have our data coming in through dynamic DB we've set up our streams and then the",
    "start": "1476500",
    "end": "1481990"
  },
  {
    "text": "top right box is our lambda and all we need is every time a new record gets gets created is to output it to firehose",
    "start": "1481990",
    "end": "1489580"
  },
  {
    "text": "which will then output it to s3 remember we want when you write it to firehose we want both the record in the sequence number this is important and if you",
    "start": "1489580",
    "end": "1496150"
  },
  {
    "text": "haven't used firehose before it's a simple AWS product it gives you an endpoint you throw as much data as you",
    "start": "1496150",
    "end": "1502000"
  },
  {
    "text": "want into it and then it will a granade it together and store it in an endpoint in this case we chose s3",
    "start": "1502000",
    "end": "1508530"
  },
  {
    "text": "it handles all that for you so you just you just feed a data in it sends at s3 so now it's time to run turbo mode so",
    "start": "1508530",
    "end": "1515770"
  },
  {
    "text": "step one we can now look at the s3 copy of all of this data we can read it as fast as we can as fast as we can process",
    "start": "1515770",
    "end": "1521919"
  },
  {
    "text": "it and analyze it and as soon as we're done processing as much as we as much as",
    "start": "1521919",
    "end": "1526929"
  },
  {
    "text": "we can that's on s3 we now know the exact point in time within the dynamic DB stream for where we want to pick up",
    "start": "1526929",
    "end": "1532919"
  },
  {
    "text": "so now based on this sequence number we can go back to our stream and we have neither a duplicate record nor we missed",
    "start": "1532919",
    "end": "1539470"
  },
  {
    "text": "any records because we can we can pick up at that exact moment a result is now we can't process in turbo",
    "start": "1539470",
    "end": "1547370"
  },
  {
    "text": "mode and then switch back live as soon as we've reprocessed with the new model",
    "start": "1547370",
    "end": "1552880"
  },
  {
    "text": "and in fact it's so easy to set up we can actually use to do this from scratch",
    "start": "1552880",
    "end": "1557930"
  },
  {
    "text": "in a few minutes alright so before we started here we set up a empty table called reinvent",
    "start": "1557930",
    "end": "1565750"
  },
  {
    "text": "nothing in it and we have a fire hose that we set up and like I said fire hose is simply you give it a name and an end",
    "start": "1565750",
    "end": "1572540"
  },
  {
    "text": "point in this case we gave it an s3 bucket for where we want the data to go you can have a few settings as far as",
    "start": "1572540",
    "end": "1579020"
  },
  {
    "text": "how often you write the lowest you can go is 60 seconds so now to connect these two together all",
    "start": "1579020",
    "end": "1586040"
  },
  {
    "text": "we have to do is create a lambda and AWS creates a blueprint for you so you can process any kind of data coming out of",
    "start": "1586040",
    "end": "1592190"
  },
  {
    "text": "dynamic DV but before we do that we need to turn on the stream for our table so if we go to",
    "start": "1592190",
    "end": "1597260"
  },
  {
    "text": "our table turning us on from the console is very easy they have a managed stream button",
    "start": "1597260",
    "end": "1602690"
  },
  {
    "text": "here and to turn it on all we have to do is determine what kind of data we want to go to the stream and we can choose",
    "start": "1602690",
    "end": "1607730"
  },
  {
    "text": "again it's just an oblong of every create update and delete and we can have just the keys that were affected the new",
    "start": "1607730",
    "end": "1612950"
  },
  {
    "text": "image the old image or both if we want so we turn that on and that's turning on",
    "start": "1612950",
    "end": "1618020"
  },
  {
    "text": "dynamic DV streams so now that we have that set up we can come back to our our",
    "start": "1618020",
    "end": "1623150"
  },
  {
    "text": "lambda dashboard and create a dynamo DB process stream",
    "start": "1623150",
    "end": "1630050"
  },
  {
    "text": "and you just tell it where you want it to come from in this case our reinvent table and you can pick you can do the",
    "start": "1630050",
    "end": "1636230"
  },
  {
    "text": "whole last 24 hours if you want when you're creating the lambda or we can just start at the end which we'll do and then you can you can batch them if you",
    "start": "1636230",
    "end": "1642860"
  },
  {
    "text": "want and we'll turn that on",
    "start": "1642860",
    "end": "1649510"
  },
  {
    "text": "so you give it a name and by default that just prints the contents of the stream out to the console we'll start",
    "start": "1655530",
    "end": "1661170"
  },
  {
    "text": "with that just to see what it would have prints out we can give it a roll I already created one that gives it access to that firehose that we saw earlier",
    "start": "1661170",
    "end": "1669710"
  },
  {
    "text": "so we actually did see that it did not quite hook up we'll come back to that still creating the stream that we did",
    "start": "1672590",
    "end": "1678690"
  },
  {
    "text": "earlier so now if you look at the code we can actually test it",
    "start": "1678690",
    "end": "1684080"
  },
  {
    "text": "then I would DB it gives us an example event called dynamic update that we can",
    "start": "1684080",
    "end": "1689820"
  },
  {
    "text": "use for testing it and we can see it just prints out to the",
    "start": "1689820",
    "end": "1694920"
  },
  {
    "text": "prints out to the console what we're really interested here is this record dynamodb and we see it prints out the",
    "start": "1694920",
    "end": "1702360"
  },
  {
    "text": "keys the new item and most importantly the sequence number right along with it so",
    "start": "1702360",
    "end": "1708540"
  },
  {
    "text": "for a simple case if we were to just simply process out this record DynamoDB",
    "start": "1708540",
    "end": "1713850"
  },
  {
    "text": "and send it out to the firehose that will have everything we need both the raw data and the sequence number that we",
    "start": "1713850",
    "end": "1719550"
  },
  {
    "text": "can use for coming back to the stream to pick up so 808 of us by default in the lambdas",
    "start": "1719550",
    "end": "1727580"
  },
  {
    "text": "already has the AWS SDK so we can use this to create a firehose",
    "start": "1727580",
    "end": "1734990"
  },
  {
    "text": "and then inside here we just send this out to firehose and this is just two",
    "start": "1739670",
    "end": "1745800"
  },
  {
    "text": "lines of code you get a copy over so the firehose SDK has a method called put",
    "start": "1745800",
    "end": "1750960"
  },
  {
    "text": "record and it only takes a delivery stream name and the raw data firehose is",
    "start": "1750960",
    "end": "1756240"
  },
  {
    "text": "all text all strings and it just aggregates them together so it's important that you also give it some",
    "start": "1756240",
    "end": "1762690"
  },
  {
    "text": "sort of delimiter because it won't so you need to add in this case we're adding a carriage return",
    "start": "1762690",
    "end": "1768050"
  },
  {
    "text": "so we'll go ahead add that in assuming I copied and pasted correctly",
    "start": "1772430",
    "end": "1779510"
  },
  {
    "text": "so we can see now yeah the callback I just printed both the air and the result up to the screen",
    "start": "1781010",
    "end": "1786870"
  },
  {
    "text": "so we're putting the record and then looking at the air and the result",
    "start": "1786870",
    "end": "1792140"
  },
  {
    "text": "no error and the result from firehose is a record ID so these are now being sent",
    "start": "1792140",
    "end": "1797280"
  },
  {
    "text": "out to firehose so we're all set now we just need to send data from the from dynamic DB",
    "start": "1797280",
    "end": "1803630"
  },
  {
    "text": "we didn't have an issue editing the trigger earlier but because we use the blueprint when we go to add the trigger it's all it's all set up for us it'll",
    "start": "1803630",
    "end": "1810360"
  },
  {
    "text": "should work this time so now we're now we're all hooked up so now everything is set up end to end any data we add to",
    "start": "1810360",
    "end": "1817020"
  },
  {
    "text": "dynamic DB is going to call our lambda and our lambda will then feed that on through to firehose we were like lambda",
    "start": "1817020",
    "end": "1822300"
  },
  {
    "text": "for kind of gluing components together it's really easy and we're not limited obviously to firehose if we want to look",
    "start": "1822300",
    "end": "1827970"
  },
  {
    "text": "for anomalies in the data and put an alert and slack if there's a problem with the data there's really no limit to",
    "start": "1827970",
    "end": "1834210"
  },
  {
    "text": "what we can do as the data is coming through to look at it",
    "start": "1834210",
    "end": "1838430"
  },
  {
    "text": "and i actually have example what it looks like it is a little earlier so",
    "start": "1840470",
    "end": "1845670"
  },
  {
    "text": "this is be the raw file it comes in through s3 so s3 will be a series of files of these each one covering one",
    "start": "1845670",
    "end": "1852330"
  },
  {
    "text": "minute of data and it we can see it has the the raw data and the",
    "start": "1852330",
    "end": "1857600"
  },
  {
    "text": "sequence number which is the important part that we can use to going back to correlating that from our raw data back",
    "start": "1857600",
    "end": "1864270"
  },
  {
    "text": "to the feed okay great so",
    "start": "1864270",
    "end": "1870719"
  },
  {
    "start": "1867000",
    "end": "2146000"
  },
  {
    "text": "what you're seeing on screen right now are three of the common applets the race",
    "start": "1870719",
    "end": "1876009"
  },
  {
    "text": "engineers use on track to monitor the race status this applications call Athena on for",
    "start": "1876009",
    "end": "1883119"
  },
  {
    "text": "she's not a WS Athena thanks Amazon as Jason was alluding to and",
    "start": "1883119",
    "end": "1890159"
  },
  {
    "text": "briefly the three outlets which you see the top right corner is the race",
    "start": "1890159",
    "end": "1895330"
  },
  {
    "text": "positions applet and that gives the engineers a visual indication way all the cars are on track the bottom right",
    "start": "1895330",
    "end": "1901419"
  },
  {
    "text": "hand corner is the grass applet that gives them a historical view of the lap times which have taken place on",
    "start": "1901419",
    "end": "1908379"
  },
  {
    "text": "a per lap basis for all the cars and finally in the top left hand corner the",
    "start": "1908379",
    "end": "1913450"
  },
  {
    "text": "leaderboard so for anyone who's done any racing go-kart you'd be familiar with this table format gives you a table view",
    "start": "1913450",
    "end": "1920529"
  },
  {
    "text": "of all the cars and tracked by their positions and their lap times so let's talk about each applet a bit more in",
    "start": "1920529",
    "end": "1925629"
  },
  {
    "text": "detail just to give you guys an insight on what we use the live data for so the",
    "start": "1925629",
    "end": "1930639"
  },
  {
    "text": "race positions applet gives indication to the engineers on where all the cars",
    "start": "1930639",
    "end": "1935919"
  },
  {
    "text": "on track relative to the leader that's why the cars don't move around non-stop",
    "start": "1935919",
    "end": "1941799"
  },
  {
    "text": "like a GPS coordinates because if you have a 25 second lap with 40 cars going around that it's gets quite busy you",
    "start": "1941799",
    "end": "1947889"
  },
  {
    "text": "can't really watch it so the leader is static and everyone moves back and forth based on their relative time to the",
    "start": "1947889",
    "end": "1954399"
  },
  {
    "text": "leader the three rings you see the outermost ring is the are cars which on",
    "start": "1954399",
    "end": "1960099"
  },
  {
    "text": "the lead lap the middle ring are cars which are that behind and the innermost ring are cars which are more than a lap",
    "start": "1960099",
    "end": "1966609"
  },
  {
    "text": "behind now what's useful for the engineers when",
    "start": "1966609",
    "end": "1972219"
  },
  {
    "text": "looking at this is that as they hover the mouse over the",
    "start": "1972219",
    "end": "1977589"
  },
  {
    "text": "card interests they can see three additional icons are appear those square ones going",
    "start": "1977589",
    "end": "1984489"
  },
  {
    "text": "to get the pointer just so you can see these square boxes appear for car 19 and",
    "start": "1984489",
    "end": "1989619"
  },
  {
    "text": "that indicates where the car would come out if he had pit at that point in time",
    "start": "1989619",
    "end": "1995200"
  },
  {
    "text": "and the three options you have a space of what they do at the pit so would they take north",
    "start": "1995200",
    "end": "2001539"
  },
  {
    "text": "no Tyus just feel lonely do they take two tires or did it take four tires so this is all very useful for them because",
    "start": "2001539",
    "end": "2007269"
  },
  {
    "text": "then they can start predicting what can they do to get the car clear air if it's on a green lap and it's important",
    "start": "2007269",
    "end": "2013419"
  },
  {
    "text": "because as you pit you don't want to come out in traffic yeah ideally you want to come and clear and then you can make pace afterwards and do an undercut",
    "start": "2013419",
    "end": "2019869"
  },
  {
    "text": "if you need to next the graphs applet so the graphs applet like I said earlier gives a",
    "start": "2019869",
    "end": "2026919"
  },
  {
    "text": "historical view of all the lap times that have that has happened and that allows trend analysis",
    "start": "2026919",
    "end": "2033389"
  },
  {
    "text": "you know and one of the things they like to to look at is",
    "start": "2033389",
    "end": "2039419"
  },
  {
    "text": "how is the lap tire the tire degradation taking effect because as you run more on",
    "start": "2039419",
    "end": "2046599"
  },
  {
    "text": "track it tries to create your lap time drops off or that's always counted by the fuel burn so the more fuel you burn",
    "start": "2046599",
    "end": "2053020"
  },
  {
    "text": "the faster you go so these these are these lines allow them to do the self",
    "start": "2053020",
    "end": "2059138"
  },
  {
    "text": "analysis and it's very interesting to them to do it live during the race and as you can see by my virtual mouse it's",
    "start": "2059139",
    "end": "2064990"
  },
  {
    "text": "going up and down as you hover across the dots on the graph you can see the lap times and finally the leaderboard on the top",
    "start": "2064990",
    "end": "2073179"
  },
  {
    "text": "left-hand corner that gives them table format of where all the cars on track based on position",
    "start": "2073179",
    "end": "2080440"
  },
  {
    "text": "it tells them their lap last lap time was it their",
    "start": "2080440",
    "end": "2085898"
  },
  {
    "text": "personal best which is indicated by a green highlight is it their overall best which is indicated by a purple highlight",
    "start": "2085899",
    "end": "2092280"
  },
  {
    "text": "it tells them when their last pass is lap time was the rank is how the lap",
    "start": "2092280",
    "end": "2099160"
  },
  {
    "text": "times are performing to the field at that point in time and also it gives them time gaps to the leader and that's",
    "start": "2099160",
    "end": "2104950"
  },
  {
    "text": "very useful for them because if you were point eight of a second behind the",
    "start": "2104950",
    "end": "2110799"
  },
  {
    "text": "leader and you knew that you're laughing significantly faster you can do basic math to work out that I could catch up",
    "start": "2110799",
    "end": "2116319"
  },
  {
    "text": "with this kind eight laps so that place in the strategy should you be fuel saving should you be pushing should I",
    "start": "2116319",
    "end": "2122829"
  },
  {
    "text": "pit so all these things are happening live and that's what we use the data for",
    "start": "2122829",
    "end": "2127869"
  },
  {
    "text": "that's why it's very important that we don't have any dropouts oh and have that continuity",
    "start": "2127869",
    "end": "2132870"
  },
  {
    "text": "the time but that concludes our presentation",
    "start": "2132870",
    "end": "2140690"
  },
  {
    "text": "thank you very much for sticking around with us",
    "start": "2140690",
    "end": "2146150"
  }
]
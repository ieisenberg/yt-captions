[
  {
    "start": "0",
    "end": "36000"
  },
  {
    "text": "Hi, welcome to another episode\nof 'Back to Basics'.",
    "start": "5714",
    "end": "8634"
  },
  {
    "text": "I'm Peter.",
    "start": "8926",
    "end": "9676"
  },
  {
    "text": "Today, we'll talk about patterns\nthat allow you to analyze",
    "start": "10135",
    "end": "13597"
  },
  {
    "text": "and respond to your application's logs\nin near-real-time.",
    "start": "13639",
    "end": "17059"
  },
  {
    "text": "You might want to do this for monitoring,\nsetting up alerts, or anomaly detection,",
    "start": "17768",
    "end": "23022"
  },
  {
    "text": "so that you can quickly respond\nto sudden changes in your environment",
    "start": "23273",
    "end": "27069"
  },
  {
    "text": "or unusually high error rates.",
    "start": "27152",
    "end": "29071"
  },
  {
    "text": "How would you aggregate\nand process your logs",
    "start": "29863",
    "end": "32324"
  },
  {
    "text": "so that you can respond to any situation?",
    "start": "32741",
    "end": "35327"
  },
  {
    "start": "36000",
    "end": "102000"
  },
  {
    "text": "The easiest way to process streaming data in real-time\nis with Amazon Kinesis.",
    "start": "36370",
    "end": "42209"
  },
  {
    "text": "Kinesis is massively scalable, durable,",
    "start": "43210",
    "end": "46212"
  },
  {
    "text": "and can continuously\ncapture gigabytes of data per second",
    "start": "46421",
    "end": "49925"
  },
  {
    "text": "from hundreds and thousdands of sources.",
    "start": "50175",
    "end": "52218"
  },
  {
    "text": "And the best place to store,\nsearch and analyze the stream data",
    "start": "53095",
    "end": "57808"
  },
  {
    "text": "is with Amazon OpenSearch Service.",
    "start": "58016",
    "end": "60101"
  },
  {
    "text": "OpenSearch makes it easy to perform\ninteractive log analytics,",
    "start": "60936",
    "end": "64815"
  },
  {
    "text": "real-time application monitoring and anomaly detection\nusing machine learning.",
    "start": "65232",
    "end": "70320"
  },
  {
    "text": "I'm going to show you how to use\nthese two services together.",
    "start": "71154",
    "end": "74157"
  },
  {
    "text": "Let's dive in.",
    "start": "74491",
    "end": "75325"
  },
  {
    "text": "Kinesis acts as your log\naggregation delivery stream",
    "start": "75951",
    "end": "79328"
  },
  {
    "text": "to ingest logs into\nan Amazon OpenSearch domain.",
    "start": "79621",
    "end": "82791"
  },
  {
    "text": "Then, the anomaly detection feature of OpenSearch",
    "start": "83333",
    "end": "86628"
  },
  {
    "text": "uses the random cut forest algorithm\nto detect outliers in your data.",
    "start": "86795",
    "end": "91424"
  },
  {
    "text": "Using this pattern,\nyou can quickly identifyand respond",
    "start": "92676",
    "end": "95971"
  },
  {
    "text": "to a sudden increase in server errors\nfor your web application.",
    "start": "96013",
    "end": "99850"
  },
  {
    "text": "Let's see what this looks like in action.",
    "start": "100726",
    "end": "102519"
  },
  {
    "text": "The first step is to identify all the services\nyou want to collect information from.",
    "start": "103228",
    "end": "108191"
  },
  {
    "text": "This could be applications running\non Amazon EC2, ECS, EKS, or AWS Fargate.",
    "start": "109109",
    "end": "116491"
  },
  {
    "text": "You can easily pull logs directly from the services\nusing the Kinesis Agent.",
    "start": "117284",
    "end": "121829"
  },
  {
    "text": "Ultimately, you want the logs to be in JSON format\nfor indexing in OpenSearch.",
    "start": "122706",
    "end": "127794"
  },
  {
    "text": "You can use the Kinesis Agent\nto convert the logs to JSON",
    "start": "128670",
    "end": "132549"
  },
  {
    "text": "by adding the data processing options configuration setting\nand specify the log to JSON processing option.",
    "start": "132841",
    "end": "140766"
  },
  {
    "text": "Next, your applications then will log\nto an Amazon Kinesis Data Firehose delivery stream.",
    "start": "141934",
    "end": "148440"
  },
  {
    "text": "What I like about this service is you don't need to define\na shard strategy with Data Firehose.",
    "start": "149233",
    "end": "154196"
  },
  {
    "text": "It scales automatically,\nwhich reduces the complexity.",
    "start": "154655",
    "end": "157991"
  },
  {
    "text": "And because Data Firehose\nsupports multiple destinations,",
    "start": "158825",
    "end": "162496"
  },
  {
    "text": "you can reduce costs by sending the logs\nthat are relevant for anomaly detection to Kinesis,",
    "start": "162829",
    "end": "168584"
  },
  {
    "text": "and the others to Amazon S3.",
    "start": "169002",
    "end": "170921"
  },
  {
    "text": "We use S3 as one destination\nfor long-term storage,",
    "start": "171880",
    "end": "175884"
  },
  {
    "text": "and the ability to use Amazon Athena\nto run ad hoc analyses on historical data.",
    "start": "176176",
    "end": "181431"
  },
  {
    "text": "We also use Kinesis Data Analytics\nas a second destination to continuously run SQL statements",
    "start": "182266",
    "end": "188939"
  },
  {
    "text": "against the streaming data\nand aggregate the data every minute.",
    "start": "188981",
    "end": "192317"
  },
  {
    "start": "192000",
    "end": "311000"
  },
  {
    "text": "Let's say you want it to aggregate your data\nover a one-minute tumbling window",
    "start": "193735",
    "end": "198073"
  },
  {
    "text": "to get an error count per source application.",
    "start": "198323",
    "end": "200742"
  },
  {
    "text": "Tumbling windows help you aggregate your data\nover fixed, open and close intervals.",
    "start": "201410",
    "end": "206248"
  },
  {
    "text": "You can also choose between\nstagger and sliding windows.",
    "start": "206832",
    "end": "210294"
  },
  {
    "text": "Stagger windows help reduce\nany late or out-of-order data,",
    "start": "210961",
    "end": "214798"
  },
  {
    "text": "while sliding windows continuously aggregate your data\nover a fixed time or rowCount.",
    "start": "215132",
    "end": "220012"
  },
  {
    "text": "You can create a Kinesis Data Analytics application\nto do this aggregation",
    "start": "221180",
    "end": "225976"
  },
  {
    "text": "by configuring the Kinesis Firehose\ndelivery stream as a source.",
    "start": "226268",
    "end": "230397"
  },
  {
    "text": "You can edit the inferred JSON schema if needed,",
    "start": "231064",
    "end": "234318"
  },
  {
    "text": "then add application code using SQL\nto determine error counts per source.",
    "start": "234818",
    "end": "240032"
  },
  {
    "text": "We then set the destination as a second Kinesis Data Firehose\ndelivery stream.",
    "start": "241158",
    "end": "246163"
  },
  {
    "text": "Data Firehose supports\nAmazon OpenSearch as a destination,",
    "start": "246872",
    "end": "251000"
  },
  {
    "text": "so it's the simplest way to get your data\nin an OpenSearch domain.",
    "start": "251376",
    "end": "255339"
  },
  {
    "text": "I've seen customers use Kafka\nfor their delivery stream",
    "start": "256089",
    "end": "259426"
  },
  {
    "text": "because it's open source and has been\nused for a number of years.",
    "start": "259468",
    "end": "262470"
  },
  {
    "text": "You can certainly use Kafka as your delivery stream,",
    "start": "263055",
    "end": "265807"
  },
  {
    "text": "but many find it cumbersome to have\nto manage their own Kafka servers.",
    "start": "266266",
    "end": "269811"
  },
  {
    "text": "If you want AWS to worry about that heavy lifting,",
    "start": "270395",
    "end": "273357"
  },
  {
    "text": "I'd recommend using Amazon Managed Streaming for Kafka\nfor your delivery stream.",
    "start": "273649",
    "end": "277944"
  },
  {
    "text": "Now back to OpenSearch,\nyou can configure alerts with Amazon SNS",
    "start": "279530",
    "end": "283992"
  },
  {
    "text": "when your application log is more than five HTTP 500 errors\nin our one-minute window.",
    "start": "284368",
    "end": "289748"
  },
  {
    "text": "You can also create a detector\nfor an individual anomaly detection task,",
    "start": "290624",
    "end": "295044"
  },
  {
    "text": "or multiple detectors that run simultaneously.",
    "start": "295379",
    "end": "298006"
  },
  {
    "text": "OpenSearch will detect and alert you on anomalies it finds\nbased on the aggregation method you choose.",
    "start": "298882",
    "end": "304805"
  },
  {
    "text": "There you have it, an end-to-end streaming pipeline",
    "start": "305597",
    "end": "308392"
  },
  {
    "text": "to ingest your application's logs,\ndo long-term storage and for anomaly detection.",
    "start": "308433",
    "end": "313564"
  },
  {
    "start": "311000",
    "end": "348000"
  },
  {
    "text": "One last tip, to optimize on performance\nand cost with OpenSearch,",
    "start": "314439",
    "end": "318360"
  },
  {
    "text": "consider the window of log data you need to analyze.",
    "start": "318777",
    "end": "321780"
  },
  {
    "text": "Let's say it's a week, for anything older,\nyou should set a policy to move data older than seven days",
    "start": "322197",
    "end": "328871"
  },
  {
    "text": "to OpenSearches UltraWarm tier and pocket the savings.",
    "start": "329246",
    "end": "332791"
  },
  {
    "text": "In this episode, we looked at how you can stream\nyour applications logs for analysis,",
    "start": "333709",
    "end": "338213"
  },
  {
    "text": "monitoring and anomaly detection.",
    "start": "338463",
    "end": "341091"
  },
  {
    "text": "Check out the links below for more details.",
    "start": "341717",
    "end": "344011"
  },
  {
    "text": "Thanks, and see you next time.",
    "start": "344511",
    "end": "346013"
  }
]
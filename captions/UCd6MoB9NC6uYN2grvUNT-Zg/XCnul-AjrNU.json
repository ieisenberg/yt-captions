[
  {
    "start": "0",
    "end": "149000"
  },
  {
    "text": "- Hi, I'm Andrea from AWS.",
    "start": "0",
    "end": "2130"
  },
  {
    "text": "- Hi, I'm Chris from CCC, and\n\"This is My Architecture.\"",
    "start": "2130",
    "end": "5261"
  },
  {
    "text": "(upbeat music)",
    "start": "5261",
    "end": "7844"
  },
  {
    "text": "- Thanks for being here\non the show, Chris.",
    "start": "13890",
    "end": "15780"
  },
  {
    "text": "What do you guys do at CCC?",
    "start": "15780",
    "end": "17910"
  },
  {
    "text": "And what problem are you solving",
    "start": "17910",
    "end": "19380"
  },
  {
    "text": "with this architecture on AWS?",
    "start": "19380",
    "end": "21303"
  },
  {
    "text": "- So CCC, we work in the\nproperty and casualty industry,",
    "start": "22170",
    "end": "25770"
  },
  {
    "text": "and we create a lot of products",
    "start": "25770",
    "end": "27450"
  },
  {
    "text": "for a variety of types of companies,",
    "start": "27450",
    "end": "29880"
  },
  {
    "text": "so insurance companies, body shops,",
    "start": "29880",
    "end": "31890"
  },
  {
    "text": "parts suppliers, and\neverything in between.",
    "start": "31890",
    "end": "33899"
  },
  {
    "text": "So what we were trying to\nsolve With this architecture,",
    "start": "33900",
    "end": "37140"
  },
  {
    "text": "is how we can more easily manage",
    "start": "37140",
    "end": "40260"
  },
  {
    "text": "all of our current and\nfuture AI solutions.",
    "start": "40260",
    "end": "45059"
  },
  {
    "text": "As we create more models, our\nsolutions get more complex,",
    "start": "45060",
    "end": "48630"
  },
  {
    "text": "and we wanted to find out how\nwe can use managed services",
    "start": "48630",
    "end": "51630"
  },
  {
    "text": "to remove some of the burden\non our development teams",
    "start": "51630",
    "end": "54270"
  },
  {
    "text": "for managing all of this.",
    "start": "54270",
    "end": "55320"
  },
  {
    "text": "- Wonderful, so let's walk\nthrough one of those examples.",
    "start": "55320",
    "end": "57989"
  },
  {
    "text": "- So one of the examples that we have",
    "start": "57990",
    "end": "60750"
  },
  {
    "text": "is a product called Estimate STP,",
    "start": "60750",
    "end": "63270"
  },
  {
    "text": "Straight-Through Processing.",
    "start": "63270",
    "end": "64589"
  },
  {
    "text": "So the typical flow of this product",
    "start": "64590",
    "end": "67740"
  },
  {
    "text": "is when a policy holder\ngets in an accident,",
    "start": "67740",
    "end": "70380"
  },
  {
    "text": "they submit their photos\nto the insurance company,",
    "start": "70380",
    "end": "73079"
  },
  {
    "text": "and then we ultimately produce\nline level estimates for the",
    "start": "73080",
    "end": "76080"
  },
  {
    "text": "insurance company to use-\n- I see.",
    "start": "76080",
    "end": "77280"
  },
  {
    "text": "- And make business decisions on.",
    "start": "77280",
    "end": "78659"
  },
  {
    "text": "- Okay, and then how do\nthey initiate the request?",
    "start": "78660",
    "end": "81300"
  },
  {
    "text": "- Yeah, so the application",
    "start": "81300",
    "end": "83160"
  },
  {
    "text": "would first send in a\nrequest through API gateway",
    "start": "83160",
    "end": "86860"
  },
  {
    "text": "signaling which a service\nthey'd like to use,",
    "start": "88020",
    "end": "89969"
  },
  {
    "text": "in this case Estimate STP,",
    "start": "89970",
    "end": "91710"
  },
  {
    "text": "along with sending a callback URL",
    "start": "91710",
    "end": "94680"
  },
  {
    "text": "so that the platform can notify them",
    "start": "94680",
    "end": "96450"
  },
  {
    "text": "once the prediction is ready.",
    "start": "96450",
    "end": "97890"
  },
  {
    "text": "So that goes through a Lambda function,",
    "start": "97890",
    "end": "100979"
  },
  {
    "text": "and then that Lambda function",
    "start": "100980",
    "end": "102540"
  },
  {
    "text": "creates a unique prediction ID",
    "start": "102540",
    "end": "103920"
  },
  {
    "text": "to track the entire transaction,",
    "start": "103920",
    "end": "105869"
  },
  {
    "text": "and then creates a database\nrecord for tracking,",
    "start": "105870",
    "end": "109950"
  },
  {
    "text": "and then it produces a pre-signed S3 URL",
    "start": "109950",
    "end": "114632"
  },
  {
    "text": "that is then returned to the application.",
    "start": "114633",
    "end": "117360"
  },
  {
    "text": "And that pre-signed URL is used",
    "start": "117360",
    "end": "121050"
  },
  {
    "text": "to upload the vehicle\nphotos and other information",
    "start": "121050",
    "end": "125220"
  },
  {
    "text": "related to the claim into S3.",
    "start": "125220",
    "end": "127800"
  },
  {
    "text": "- I see, so why could the user,",
    "start": "127800",
    "end": "129990"
  },
  {
    "text": "or in this case the insurance firm,",
    "start": "129990",
    "end": "131160"
  },
  {
    "text": "not upload that information",
    "start": "131160",
    "end": "132510"
  },
  {
    "text": "straight through the API gateway\nin the first transaction?",
    "start": "132510",
    "end": "136290"
  },
  {
    "text": "- So we encountered payload limitations",
    "start": "136290",
    "end": "138989"
  },
  {
    "text": "when using API gateway\nbecause we deal with photos",
    "start": "138990",
    "end": "142740"
  },
  {
    "text": "that are always increasing in resolution,",
    "start": "142740",
    "end": "145200"
  },
  {
    "text": "we needed to bypass that\nlimitation and go directly to S3.",
    "start": "145200",
    "end": "149129"
  },
  {
    "text": "- Wonderful, so this is kind of one step",
    "start": "149130",
    "end": "150810"
  },
  {
    "text": "of the process, right?",
    "start": "150810",
    "end": "152069"
  },
  {
    "text": "So you initiate the request,\nyou upload the files,",
    "start": "152070",
    "end": "154440"
  },
  {
    "text": "what's the next thing that happens?",
    "start": "154440",
    "end": "155910"
  },
  {
    "text": "- Yep, so once the\ninput is uploaded to S3,",
    "start": "155910",
    "end": "159000"
  },
  {
    "text": "we have a listener on these buckets",
    "start": "159000",
    "end": "160620"
  },
  {
    "text": "to then create a message\nthat is sent to Lambda,",
    "start": "160620",
    "end": "163922"
  },
  {
    "text": "and that Lambda function",
    "start": "164790",
    "end": "166469"
  },
  {
    "text": "will then do a quick lookup\non our database table,",
    "start": "166470",
    "end": "168990"
  },
  {
    "text": "and identify which step\nfunction needs to be invoked",
    "start": "168990",
    "end": "172140"
  },
  {
    "text": "to initiate the predictions\nthat need to be used.",
    "start": "172140",
    "end": "176910"
  },
  {
    "text": "- [Andrea] I see.\n- So it'll send in",
    "start": "176910",
    "end": "178760"
  },
  {
    "text": "the S3 pointers for the\nuser's original input",
    "start": "180090",
    "end": "183360"
  },
  {
    "text": "and the location of where the output",
    "start": "183360",
    "end": "185220"
  },
  {
    "text": "needs to be saved at the end.",
    "start": "185220",
    "end": "186420"
  },
  {
    "start": "186000",
    "end": "232000"
  },
  {
    "text": "- Okay, so let's dive\ninto the step function,",
    "start": "186420",
    "end": "188730"
  },
  {
    "text": "and see the logic behind it.",
    "start": "188730",
    "end": "191129"
  },
  {
    "text": "So how would that work,",
    "start": "191130",
    "end": "192510"
  },
  {
    "text": "if you could maybe describe\nthis to our viewers?",
    "start": "192510",
    "end": "194730"
  },
  {
    "text": "- Yeah, so we use step functions",
    "start": "194730",
    "end": "196530"
  },
  {
    "text": "to orchestrate all of the steps",
    "start": "196530",
    "end": "199470"
  },
  {
    "text": "that need to run for\nany given AI ensemble.",
    "start": "199470",
    "end": "202380"
  },
  {
    "text": "So an AI ensemble for us",
    "start": "202380",
    "end": "204420"
  },
  {
    "text": "is really just again, a\ncollection of AI services",
    "start": "204420",
    "end": "208290"
  },
  {
    "text": "that work together to\nproduce one final output.",
    "start": "208290",
    "end": "211620"
  },
  {
    "text": "So all of these nodes in the graph",
    "start": "211620",
    "end": "213450"
  },
  {
    "text": "represent individual AI models",
    "start": "213450",
    "end": "216090"
  },
  {
    "text": "that need to work in parallel,",
    "start": "216090",
    "end": "218430"
  },
  {
    "text": "or in sequence depending\non what their input is.",
    "start": "218430",
    "end": "221670"
  },
  {
    "text": "- So these AI models, I see\nSageMaker, is that what you use?",
    "start": "221670",
    "end": "225540"
  },
  {
    "text": "- Correct, each of these\nnodes represent an AI model",
    "start": "225540",
    "end": "228420"
  },
  {
    "text": "that is hosted using asynchronous\nendpoints on SageMaker.",
    "start": "228420",
    "end": "232209"
  },
  {
    "start": "232000",
    "end": "300000"
  },
  {
    "text": "- Okay, and how do you invoke that?",
    "start": "232210",
    "end": "234600"
  },
  {
    "text": "- So each node in the step function",
    "start": "234600",
    "end": "239600"
  },
  {
    "text": "will be calling a unique AI model",
    "start": "240390",
    "end": "243810"
  },
  {
    "text": "that is hosted in SageMaker.",
    "start": "243810",
    "end": "245370"
  },
  {
    "text": "So when the payload is\nsent to an endpoint,",
    "start": "245370",
    "end": "249780"
  },
  {
    "text": "the prediction is made,",
    "start": "249780",
    "end": "251190"
  },
  {
    "text": "and that's automatically saved in S3.",
    "start": "251190",
    "end": "253260"
  },
  {
    "text": "And then once the prediction's complete,",
    "start": "253260",
    "end": "256049"
  },
  {
    "text": "a notification is created,",
    "start": "256050",
    "end": "257940"
  },
  {
    "text": "and a Lambda function will consume that,",
    "start": "257940",
    "end": "259920"
  },
  {
    "text": "and then send back a\ntoken to the step function",
    "start": "259920",
    "end": "264920"
  },
  {
    "text": "notifying it that it can now\ncontinue on to the next node",
    "start": "265170",
    "end": "267750"
  },
  {
    "text": "of the graph.\n- To the second step.",
    "start": "267750",
    "end": "268647"
  },
  {
    "text": "- [Chris] And this repeats\nuntil all of the steps",
    "start": "268647",
    "end": "273540"
  },
  {
    "text": "in the graph are complete.",
    "start": "273540",
    "end": "274980"
  },
  {
    "text": "- So assume that the insurance firm",
    "start": "274980",
    "end": "276450"
  },
  {
    "text": "uploads an image that is invalid,",
    "start": "276450",
    "end": "279090"
  },
  {
    "text": "how do you address this\nwith this architecture?",
    "start": "279090",
    "end": "281910"
  },
  {
    "text": "- So if the user input doesn't\nmeet the minimum requirements",
    "start": "281910",
    "end": "286910"
  },
  {
    "text": "for running the entire AI\nensemble, what we do is",
    "start": "286920",
    "end": "290250"
  },
  {
    "text": "we run input validation in the\nvery beginning to ensure that",
    "start": "290250",
    "end": "294090"
  },
  {
    "text": "we don't run a downstream\nAI models unnecessarily,",
    "start": "294090",
    "end": "297150"
  },
  {
    "text": "and the user's notified\nimmediately if they don't provide",
    "start": "297150",
    "end": "300180"
  },
  {
    "start": "300000",
    "end": "372000"
  },
  {
    "text": "correct input.\n- And you can immediate that.",
    "start": "300180",
    "end": "301410"
  },
  {
    "text": "Okay, and then after sort of\ngoing through an ensemble,",
    "start": "301410",
    "end": "304500"
  },
  {
    "text": "what do you get?",
    "start": "304500",
    "end": "306210"
  },
  {
    "text": "What do you find after\nthe last kind of step?",
    "start": "306210",
    "end": "309690"
  },
  {
    "text": "- Right, so in this case of Estimate STP,",
    "start": "309690",
    "end": "312480"
  },
  {
    "text": "we produce line level estimates,\nand all of that information",
    "start": "312480",
    "end": "315870"
  },
  {
    "text": "is then automatically saved in S3",
    "start": "315870",
    "end": "318300"
  },
  {
    "text": "using the original input from this step",
    "start": "318300",
    "end": "321389"
  },
  {
    "text": "where we save the output\nin a predefined location.",
    "start": "321390",
    "end": "325110"
  },
  {
    "text": "Once that final prediction is saved in S3,",
    "start": "325110",
    "end": "328409"
  },
  {
    "text": "we have a Lambda function that\nwill query our database table",
    "start": "328410",
    "end": "333150"
  },
  {
    "text": "to grab the callback URL that\nthe user originally provided.",
    "start": "333150",
    "end": "337410"
  },
  {
    "text": "- [Andrea] Okay.",
    "start": "337410",
    "end": "338243"
  },
  {
    "text": "- [Chris] So with that callback URL,",
    "start": "338243",
    "end": "340530"
  },
  {
    "text": "the Lambda function will\ncreate a pre-signed S3 URL",
    "start": "340530",
    "end": "344490"
  },
  {
    "text": "and send that back to the user.",
    "start": "344490",
    "end": "347283"
  },
  {
    "text": "And that user will then\nuse the pre-signed URL",
    "start": "348900",
    "end": "353250"
  },
  {
    "text": "to download the final output from S3.",
    "start": "353250",
    "end": "357240"
  },
  {
    "text": "- Chris, I'm sure you're\ndoing this at scale,",
    "start": "357240",
    "end": "359190"
  },
  {
    "text": "how many transactions are\nyou handling per week?",
    "start": "359190",
    "end": "361650"
  },
  {
    "text": "- We're handling about\n4.1 million transactions.",
    "start": "361650",
    "end": "364650"
  },
  {
    "text": "- Oh, wonderful.",
    "start": "364650",
    "end": "365483"
  },
  {
    "text": "Thank you so much, Chris for\nsharing this architecture.",
    "start": "365483",
    "end": "367800"
  },
  {
    "text": "- Thank you.",
    "start": "367800",
    "end": "368840"
  },
  {
    "text": "(upbeat music)",
    "start": "368840",
    "end": "371423"
  }
]
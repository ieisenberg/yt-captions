[
  {
    "text": "45 because of the keynotes earlier today",
    "start": "320",
    "end": "3360"
  },
  {
    "text": "but anyway um welcome everybody i'm Kurt",
    "start": "3360",
    "end": "5920"
  },
  {
    "text": "Brown i'm the director of the data",
    "start": "5920",
    "end": "8240"
  },
  {
    "text": "science and engineering platform at",
    "start": "8240",
    "end": "9840"
  },
  {
    "text": "Netflix and today I'm going to talk",
    "start": "9840",
    "end": "11360"
  },
  {
    "text": "about uh what does our data science",
    "start": "11360",
    "end": "13519"
  },
  {
    "text": "infrastructure look like how has it",
    "start": "13519",
    "end": "15280"
  },
  {
    "text": "evolved over time and how specifically",
    "start": "15280",
    "end": "17520"
  },
  {
    "text": "do we leverage",
    "start": "17520",
    "end": "19480"
  },
  {
    "text": "EMR but first I want to start with a",
    "start": "19480",
    "end": "21880"
  },
  {
    "text": "question what do you guys think is",
    "start": "21880",
    "end": "24400"
  },
  {
    "text": "Netflix's data warehouse do you think",
    "start": "24400",
    "end": "26560"
  },
  {
    "text": "it's Cassandra Terodata Hive or S3 or at",
    "start": "26560",
    "end": "30480"
  },
  {
    "text": "least internally what do we think of as",
    "start": "30480",
    "end": "32160"
  },
  {
    "text": "our data warehouse so what's that well",
    "start": "32160",
    "end": "35040"
  },
  {
    "text": "no answers no answers yet so hold your",
    "start": "35040",
    "end": "37360"
  },
  {
    "text": "thoughts i'm going to go through the",
    "start": "37360",
    "end": "38480"
  },
  {
    "text": "presentation and then it'll be obvious",
    "start": "38480",
    "end": "40399"
  },
  {
    "text": "as we go through it and it could be a",
    "start": "40399",
    "end": "42079"
  },
  {
    "text": "little",
    "start": "42079",
    "end": "44120"
  },
  {
    "text": "surprising so first let's go like way",
    "start": "44120",
    "end": "46640"
  },
  {
    "text": "back ancient history 2008 this is what",
    "start": "46640",
    "end": "50160"
  },
  {
    "text": "our infrastructure looked like in data",
    "start": "50160",
    "end": "52320"
  },
  {
    "text": "science and engineering so very classic",
    "start": "52320",
    "end": "54559"
  },
  {
    "text": "sort of business intelligence stack we",
    "start": "54559",
    "end": "56879"
  },
  {
    "text": "had Oracle as our source system where uh",
    "start": "56879",
    "end": "59680"
  },
  {
    "text": "our end users were served out of we had",
    "start": "59680",
    "end": "62079"
  },
  {
    "text": "abonio which is an ETL tool so would",
    "start": "62079",
    "end": "64400"
  },
  {
    "text": "take data out of Oracle transform it and",
    "start": "64400",
    "end": "66720"
  },
  {
    "text": "then load it into terod data um that's",
    "start": "66720",
    "end": "69280"
  },
  {
    "text": "where all our data warehousing was done",
    "start": "69280",
    "end": "71360"
  },
  {
    "text": "uh all the reports all the analytics and",
    "start": "71360",
    "end": "73920"
  },
  {
    "text": "then finally micro strategy is where you",
    "start": "73920",
    "end": "76080"
  },
  {
    "text": "actually see those reports or you could",
    "start": "76080",
    "end": "77439"
  },
  {
    "text": "get them emailed out to you on a daily",
    "start": "77439",
    "end": "79280"
  },
  {
    "text": "basis so all best of breed technologies",
    "start": "79280",
    "end": "82000"
  },
  {
    "text": "we actually still use them all today but",
    "start": "82000",
    "end": "83920"
  },
  {
    "text": "a lot has changed since",
    "start": "83920",
    "end": "85799"
  },
  {
    "text": "2008 one thing that happened in 2008",
    "start": "85799",
    "end": "88159"
  },
  {
    "text": "which was not so pleasant is that we had",
    "start": "88159",
    "end": "90000"
  },
  {
    "text": "a meltdown at Netflix so we were offline",
    "start": "90000",
    "end": "92560"
  },
  {
    "text": "for nearly 3 days and this is Netflix as",
    "start": "92560",
    "end": "94720"
  },
  {
    "text": "a company not data science and",
    "start": "94720",
    "end": "96240"
  },
  {
    "text": "engineering and we were unable to ship",
    "start": "96240",
    "end": "98320"
  },
  {
    "text": "discs um off and on for three days so",
    "start": "98320",
    "end": "101439"
  },
  {
    "text": "that was a big deal for us um we were",
    "start": "101439",
    "end": "103439"
  },
  {
    "text": "fortunate at the time that we were",
    "start": "103439",
    "end": "105119"
  },
  {
    "text": "mostly a DVD company versus a streaming",
    "start": "105119",
    "end": "107360"
  },
  {
    "text": "company and we knew we already starting",
    "start": "107360",
    "end": "109439"
  },
  {
    "text": "to dabble in streaming that this would",
    "start": "109439",
    "end": "110880"
  },
  {
    "text": "be catastrophic if we had something like",
    "start": "110880",
    "end": "112720"
  },
  {
    "text": "this in streaming time so we need to",
    "start": "112720",
    "end": "114640"
  },
  {
    "text": "make a change and on top of that we knew",
    "start": "114640",
    "end": "117280"
  },
  {
    "text": "international was coming our our",
    "start": "117280",
    "end": "119439"
  },
  {
    "text": "subscriber count was exploding like we",
    "start": "119439",
    "end": "121600"
  },
  {
    "text": "had to do something on the hardware",
    "start": "121600",
    "end": "122960"
  },
  {
    "text": "front and enter the cloud so obviously",
    "start": "122960",
    "end": "126399"
  },
  {
    "text": "that's why Netflix is here um we made",
    "start": "126399",
    "end": "128879"
  },
  {
    "text": "the big investment on Amazon and the",
    "start": "128879",
    "end": "131280"
  },
  {
    "text": "goal is to move all of our",
    "start": "131280",
    "end": "132480"
  },
  {
    "text": "infrastructure up there um but it's",
    "start": "132480",
    "end": "134480"
  },
  {
    "text": "pretty radical across the entire company",
    "start": "134480",
    "end": "136160"
  },
  {
    "text": "what had to be done and then back to",
    "start": "136160",
    "end": "138400"
  },
  {
    "text": "data science this was the first phase",
    "start": "138400",
    "end": "140640"
  },
  {
    "text": "for us so um supplementing that stuff on",
    "start": "140640",
    "end": "143920"
  },
  {
    "text": "the bottom I gradeed out just for",
    "start": "143920",
    "end": "145200"
  },
  {
    "text": "visibility but it's still all there um",
    "start": "145200",
    "end": "147120"
  },
  {
    "text": "we had a chucka which is open sourced as",
    "start": "147120",
    "end": "149520"
  },
  {
    "text": "hanu um by Netflix which um is basically",
    "start": "149520",
    "end": "152720"
  },
  {
    "text": "just a data pipeline so uh app servers",
    "start": "152720",
    "end": "156080"
  },
  {
    "text": "and web servers would log events they'd",
    "start": "156080",
    "end": "158000"
  },
  {
    "text": "go through Chuckwa and they'd land in S3",
    "start": "158000",
    "end": "159920"
  },
  {
    "text": "so we would know somebody hit a play",
    "start": "159920",
    "end": "161680"
  },
  {
    "text": "button or hit a pause button or got",
    "start": "161680",
    "end": "164239"
  },
  {
    "text": "authenticated for watching a movie so",
    "start": "164239",
    "end": "166480"
  },
  {
    "text": "this is all this event data that's",
    "start": "166480",
    "end": "168080"
  },
  {
    "text": "flowing into S3 then on top of that we",
    "start": "168080",
    "end": "171440"
  },
  {
    "text": "used Hadoop and Hive heavily so mostly",
    "start": "171440",
    "end": "173519"
  },
  {
    "text": "Hive some Java map produce jobs and Hive",
    "start": "173519",
    "end": "176800"
  },
  {
    "text": "is mainly used for summarizing the data",
    "start": "176800",
    "end": "178640"
  },
  {
    "text": "so in order for it to be usable in terod",
    "start": "178640",
    "end": "180480"
  },
  {
    "text": "data and also not overwhelm terod data",
    "start": "180480",
    "end": "182560"
  },
  {
    "text": "we'd crunch it down and say well we",
    "start": "182560",
    "end": "184239"
  },
  {
    "text": "don't care about every play or every",
    "start": "184239",
    "end": "186080"
  },
  {
    "text": "minute of every movie let's say somebody",
    "start": "186080",
    "end": "188159"
  },
  {
    "text": "watched a movie and condense that into a",
    "start": "188159",
    "end": "190159"
  },
  {
    "text": "given event so a lot of hive queries are",
    "start": "190159",
    "end": "192480"
  },
  {
    "text": "used for that and then engineering teams",
    "start": "192480",
    "end": "194879"
  },
  {
    "text": "more so than um the data science team",
    "start": "194879",
    "end": "197120"
  },
  {
    "text": "would also go in there and they do ad",
    "start": "197120",
    "end": "198560"
  },
  {
    "text": "hoc querying in Hive it's not the most",
    "start": "198560",
    "end": "200879"
  },
  {
    "text": "friendly environment as you guys",
    "start": "200879",
    "end": "202400"
  },
  {
    "text": "probably know if you use Hive because",
    "start": "202400",
    "end": "203760"
  },
  {
    "text": "it's a batch processing system not a not",
    "start": "203760",
    "end": "205760"
  },
  {
    "text": "a database so it's slow but you can also",
    "start": "205760",
    "end": "208800"
  },
  {
    "text": "process a lot of data so this is this",
    "start": "208800",
    "end": "211440"
  },
  {
    "text": "worked quite well for us we have a a",
    "start": "211440",
    "end": "213120"
  },
  {
    "text": "parallelized pipeline between terod data",
    "start": "213120",
    "end": "214799"
  },
  {
    "text": "and S3 that um in parallel we can send a",
    "start": "214799",
    "end": "217519"
  },
  {
    "text": "lot of data down and then oddly we have",
    "start": "217519",
    "end": "219360"
  },
  {
    "text": "to send some data up because as I said",
    "start": "219360",
    "end": "221840"
  },
  {
    "text": "Oracle is in the next lightly still so",
    "start": "221840",
    "end": "224400"
  },
  {
    "text": "we need to get dimension data up into",
    "start": "224400",
    "end": "226480"
  },
  {
    "text": "the cloud which if you're not in data",
    "start": "226480",
    "end": "228239"
  },
  {
    "text": "warehousing um it's basically like what",
    "start": "228239",
    "end": "230560"
  },
  {
    "text": "is that members um are they subscribed",
    "start": "230560",
    "end": "232640"
  },
  {
    "text": "are they not subscribed so information",
    "start": "232640",
    "end": "234400"
  },
  {
    "text": "about those",
    "start": "234400",
    "end": "236360"
  },
  {
    "text": "events so everything was well and good",
    "start": "236360",
    "end": "238720"
  },
  {
    "text": "on the data science front until",
    "start": "238720",
    "end": "240239"
  },
  {
    "text": "Cassandra came along so Cassandra is a",
    "start": "240239",
    "end": "242720"
  },
  {
    "text": "beautiful technology it scales",
    "start": "242720",
    "end": "244920"
  },
  {
    "text": "wonderfully um it can deal with multiple",
    "start": "244920",
    "end": "247840"
  },
  {
    "text": "data centers and keep the data in sync",
    "start": "247840",
    "end": "250080"
  },
  {
    "text": "very fast reads very fast writes so it's",
    "start": "250080",
    "end": "252560"
  },
  {
    "text": "good at everything except what my team",
    "start": "252560",
    "end": "254720"
  },
  {
    "text": "needed it to do which is we just wanted",
    "start": "254720",
    "end": "256720"
  },
  {
    "text": "the data out um and talking to some",
    "start": "256720",
    "end": "259359"
  },
  {
    "text": "people that were very Cassandracentric",
    "start": "259359",
    "end": "260880"
  },
  {
    "text": "they were like \"Hey why don't you just",
    "start": "260880",
    "end": "261840"
  },
  {
    "text": "put all the data into Cassandra?\" But",
    "start": "261840",
    "end": "263680"
  },
  {
    "text": "that's Cassandra is not a data warehouse",
    "start": "263680",
    "end": "265440"
  },
  {
    "text": "so there's a there's a hint for that",
    "start": "265440",
    "end": "266720"
  },
  {
    "text": "question I asked before um it's really",
    "start": "266720",
    "end": "268639"
  },
  {
    "text": "good at serving enduser queries in very",
    "start": "268639",
    "end": "270800"
  },
  {
    "text": "very fast time but we needed all the",
    "start": "270800",
    "end": "272960"
  },
  {
    "text": "data out in bulk and a couple engineers",
    "start": "272960",
    "end": "275120"
  },
  {
    "text": "on my team tried a whole bunch of",
    "start": "275120",
    "end": "276639"
  },
  {
    "text": "different ways to get that to happen we",
    "start": "276639",
    "end": "278720"
  },
  {
    "text": "ran Hadoop over Cassandra um among other",
    "start": "278720",
    "end": "282000"
  },
  {
    "text": "things and in the end we just crushed",
    "start": "282000",
    "end": "283680"
  },
  {
    "text": "Cassandra so it was unusable if it was a",
    "start": "283680",
    "end": "285919"
  },
  {
    "text": "production system it would be horrible",
    "start": "285919",
    "end": "287680"
  },
  {
    "text": "but even taking a backup of Cassandra",
    "start": "287680",
    "end": "289440"
  },
  {
    "text": "restoring it and running Hadoop over it",
    "start": "289440",
    "end": "291360"
  },
  {
    "text": "unusable so it was either unusable or we",
    "start": "291360",
    "end": "293759"
  },
  {
    "text": "had to throttle back our our um",
    "start": "293759",
    "end": "295759"
  },
  {
    "text": "processing so far that um we couldn't",
    "start": "295759",
    "end": "298400"
  },
  {
    "text": "get the data out in a timely fashion so",
    "start": "298400",
    "end": "300320"
  },
  {
    "text": "not digging Cassandra we love Cassandra",
    "start": "300320",
    "end": "302080"
  },
  {
    "text": "for what it's good for but don't try to",
    "start": "302080",
    "end": "303600"
  },
  {
    "text": "use a technology what it's not good for",
    "start": "303600",
    "end": "306000"
  },
  {
    "text": "so um late one night the these same",
    "start": "306000",
    "end": "309360"
  },
  {
    "text": "engineers on my team got really",
    "start": "309360",
    "end": "311039"
  },
  {
    "text": "frustrated with Cassandra and they were",
    "start": "311039",
    "end": "312560"
  },
  {
    "text": "like how can we just get this data we",
    "start": "312560",
    "end": "314880"
  },
  {
    "text": "don't really about care about Cassandra",
    "start": "314880",
    "end": "316560"
  },
  {
    "text": "we just want the data and underlying",
    "start": "316560",
    "end": "318880"
  },
  {
    "text": "Cassandra is something called an SS",
    "start": "318880",
    "end": "320639"
  },
  {
    "text": "table and that's really what we wanted",
    "start": "320639",
    "end": "322720"
  },
  {
    "text": "it's just the data we don't need the",
    "start": "322720",
    "end": "324160"
  },
  {
    "text": "overhead in our case of all the other",
    "start": "324160",
    "end": "326240"
  },
  {
    "text": "stuff that Cassandra does so we built a",
    "start": "326240",
    "end": "328720"
  },
  {
    "text": "process that takes these SS tables that",
    "start": "328720",
    "end": "331280"
  },
  {
    "text": "actually get archived automatically um",
    "start": "331280",
    "end": "333360"
  },
  {
    "text": "into S3 and that's by this tool called",
    "start": "333360",
    "end": "335520"
  },
  {
    "text": "PUM which Netflix is open sourced and we",
    "start": "335520",
    "end": "338720"
  },
  {
    "text": "get these SS tables as they're being",
    "start": "338720",
    "end": "340639"
  },
  {
    "text": "incremented um onto S3 we crunch them",
    "start": "340639",
    "end": "343759"
  },
  {
    "text": "down using Hadoop so there's three",
    "start": "343759",
    "end": "345440"
  },
  {
    "text": "copies of each piece of data because we",
    "start": "345440",
    "end": "347199"
  },
  {
    "text": "have three copies in Cassandra crunch it",
    "start": "347199",
    "end": "349199"
  },
  {
    "text": "down into one version take the most",
    "start": "349199",
    "end": "351120"
  },
  {
    "text": "recent timestamp version to get rid of",
    "start": "351120",
    "end": "352880"
  },
  {
    "text": "eventual consistency and now we're good",
    "start": "352880",
    "end": "355120"
  },
  {
    "text": "to go um and then we created a custom um",
    "start": "355120",
    "end": "358080"
  },
  {
    "text": "input split format in order to deal with",
    "start": "358080",
    "end": "360080"
  },
  {
    "text": "SS tables so where did this kind of",
    "start": "360080",
    "end": "362639"
  },
  {
    "text": "horrible name agis come from um as I",
    "start": "362639",
    "end": "365759"
  },
  {
    "text": "said the engineers in my team were a",
    "start": "365759",
    "end": "367039"
  },
  {
    "text": "little bit frustrated and a Google",
    "start": "367039",
    "end": "368560"
  },
  {
    "text": "search later they found the guy who",
    "start": "368560",
    "end": "370240"
  },
  {
    "text": "helped kill Cassandra and that's who",
    "start": "370240",
    "end": "372400"
  },
  {
    "text": "this",
    "start": "372400",
    "end": "374039"
  },
  {
    "text": "is so what what does Augustus do well at",
    "start": "374039",
    "end": "377840"
  },
  {
    "text": "the output of Austis is it just puts the",
    "start": "377840",
    "end": "380479"
  },
  {
    "text": "data in JSON format on S3 so no more",
    "start": "380479",
    "end": "383199"
  },
  {
    "text": "easy format for our ETL developers to",
    "start": "383199",
    "end": "385680"
  },
  {
    "text": "work with they don't have to think about",
    "start": "385680",
    "end": "386880"
  },
  {
    "text": "Cassandra um from their perspective the",
    "start": "386880",
    "end": "389120"
  },
  {
    "text": "data is JSON it's on S3 any tool could",
    "start": "389120",
    "end": "392000"
  },
  {
    "text": "work with that so the tool that we",
    "start": "392000",
    "end": "393759"
  },
  {
    "text": "choose at Netflix because we're dealing",
    "start": "393759",
    "end": "395199"
  },
  {
    "text": "with a lot of data in many cases is um",
    "start": "395199",
    "end": "397919"
  },
  {
    "text": "pig and python so we use this for ETL in",
    "start": "397919",
    "end": "401120"
  },
  {
    "text": "the cloud uh the data flow part of it we",
    "start": "401120",
    "end": "403520"
  },
  {
    "text": "use pig and then the business logic our",
    "start": "403520",
    "end": "405520"
  },
  {
    "text": "best practice is using python you can do",
    "start": "405520",
    "end": "407919"
  },
  {
    "text": "some b business logic in pig but it's",
    "start": "407919",
    "end": "409840"
  },
  {
    "text": "usually you're you're you're jumping",
    "start": "409840",
    "end": "411440"
  },
  {
    "text": "through hoops",
    "start": "411440",
    "end": "413919"
  },
  {
    "text": "unnecessarily so this is what the",
    "start": "415080",
    "end": "416960"
  },
  {
    "text": "infrastructure looked like you know come",
    "start": "416960",
    "end": "419880"
  },
  {
    "text": "2010 2011ish",
    "start": "419880",
    "end": "422560"
  },
  {
    "text": "um again all the stuff that's grayed out",
    "start": "422560",
    "end": "424160"
  },
  {
    "text": "is still in the mix um but I just didn't",
    "start": "424160",
    "end": "427199"
  },
  {
    "text": "want to overwhelm you with",
    "start": "427199",
    "end": "429000"
  },
  {
    "text": "colors so next is we got a lot of",
    "start": "429000",
    "end": "432160"
  },
  {
    "text": "requests for I just want to see the data",
    "start": "432160",
    "end": "433840"
  },
  {
    "text": "i want to interact with it as I said and",
    "start": "433840",
    "end": "435840"
  },
  {
    "text": "you guys probably know hive is not good",
    "start": "435840",
    "end": "438080"
  },
  {
    "text": "for interacting with you can run a batch",
    "start": "438080",
    "end": "440160"
  },
  {
    "text": "job and let it go and come back the next",
    "start": "440160",
    "end": "442400"
  },
  {
    "text": "morning or if it's a really really",
    "start": "442400",
    "end": "444000"
  },
  {
    "text": "simple query it might come back in a",
    "start": "444000",
    "end": "445440"
  },
  {
    "text": "couple minutes um but people wanted to",
    "start": "445440",
    "end": "447599"
  },
  {
    "text": "interact with it so we created a",
    "start": "447599",
    "end": "449280"
  },
  {
    "text": "lightweight tool called Sting which lets",
    "start": "449280",
    "end": "451360"
  },
  {
    "text": "you slice and dice data and I'll give a",
    "start": "451360",
    "end": "453199"
  },
  {
    "text": "demo on it later on um and I'll talk",
    "start": "453199",
    "end": "455120"
  },
  {
    "text": "about how it integrates with our current",
    "start": "455120",
    "end": "456639"
  },
  {
    "text": "infrastructure",
    "start": "456639",
    "end": "458639"
  },
  {
    "text": "the other thing that we did is um it's",
    "start": "458639",
    "end": "460880"
  },
  {
    "text": "kind of a holy grail of a lot of people",
    "start": "460880",
    "end": "462319"
  },
  {
    "text": "in classic business intelligence to get",
    "start": "462319",
    "end": "464479"
  },
  {
    "text": "micro strategy running against Hive and",
    "start": "464479",
    "end": "467599"
  },
  {
    "text": "we did it so it works yay but we don't",
    "start": "467599",
    "end": "471120"
  },
  {
    "text": "actually use it very much um and the",
    "start": "471120",
    "end": "473759"
  },
  {
    "text": "reason is that we already have Micro",
    "start": "473759",
    "end": "475280"
  },
  {
    "text": "Strategy in the data center our data",
    "start": "475280",
    "end": "476879"
  },
  {
    "text": "models are already in terod data our",
    "start": "476879",
    "end": "478639"
  },
  {
    "text": "Micro Strategy models are already in",
    "start": "478639",
    "end": "480240"
  },
  {
    "text": "Micro Strategy so it's like it's a lot",
    "start": "480240",
    "end": "482160"
  },
  {
    "text": "extra work to build all the same stuff",
    "start": "482160",
    "end": "484160"
  },
  {
    "text": "against Hive and then also deal with it",
    "start": "484160",
    "end": "486000"
  },
  {
    "text": "being slow so there's very few use cases",
    "start": "486000",
    "end": "488479"
  },
  {
    "text": "where it really helps us anyway um but",
    "start": "488479",
    "end": "491039"
  },
  {
    "text": "an example that we did use it because it",
    "start": "491039",
    "end": "493120"
  },
  {
    "text": "actually was better than the alternative",
    "start": "493120",
    "end": "495759"
  },
  {
    "text": "is we recently launched in the Nordics",
    "start": "495759",
    "end": "497919"
  },
  {
    "text": "and we wanted hourly launch reports they",
    "start": "497919",
    "end": "500160"
  },
  {
    "text": "were going to be emailed so that gets",
    "start": "500160",
    "end": "501520"
  },
  {
    "text": "rid of any of the the batch nature",
    "start": "501520",
    "end": "503039"
  },
  {
    "text": "waiting of it and we would have had to",
    "start": "503039",
    "end": "504800"
  },
  {
    "text": "do the same summary job anyway and then",
    "start": "504800",
    "end": "506639"
  },
  {
    "text": "push it to terod data and then do micro",
    "start": "506639",
    "end": "508479"
  },
  {
    "text": "strategy on top of it so we said well",
    "start": "508479",
    "end": "510479"
  },
  {
    "text": "forget it let's just skip that step and",
    "start": "510479",
    "end": "512080"
  },
  {
    "text": "then put micro strategy directly against",
    "start": "512080",
    "end": "513919"
  },
  {
    "text": "hive email email it out nobody cares",
    "start": "513919",
    "end": "516560"
  },
  {
    "text": "about the latency so there are use cases",
    "start": "516560",
    "end": "518479"
  },
  {
    "text": "where it does work and it's at the point",
    "start": "518479",
    "end": "520800"
  },
  {
    "text": "where most of the bugs have been worked",
    "start": "520800",
    "end": "522240"
  },
  {
    "text": "through it still has some wrinkles about",
    "start": "522240",
    "end": "524320"
  },
  {
    "text": "Hive server not being thread safe and",
    "start": "524320",
    "end": "526240"
  },
  {
    "text": "like little wrinkles like that um but",
    "start": "526240",
    "end": "528560"
  },
  {
    "text": "some distributions have taken care of",
    "start": "528560",
    "end": "531000"
  },
  {
    "text": "that um and one of the other big pieces",
    "start": "531000",
    "end": "533839"
  },
  {
    "text": "of our infrastructure for data science",
    "start": "533839",
    "end": "535519"
  },
  {
    "text": "is R this is the tool of choice at",
    "start": "535519",
    "end": "538080"
  },
  {
    "text": "Netflix for statistics so our algorithms",
    "start": "538080",
    "end": "541200"
  },
  {
    "text": "and analytics teams um they've got their",
    "start": "541200",
    "end": "543200"
  },
  {
    "text": "Macs on their desktops and they build",
    "start": "543200",
    "end": "544880"
  },
  {
    "text": "their models um when it overwhelms their",
    "start": "544880",
    "end": "547760"
  },
  {
    "text": "desktop then we have AMIs baked in",
    "start": "547760",
    "end": "549920"
  },
  {
    "text": "Amazon that have 68 gigabytes of memory",
    "start": "549920",
    "end": "553360"
  },
  {
    "text": "and all the tools baked in already and",
    "start": "553360",
    "end": "556000"
  },
  {
    "text": "they can just spin it up and build their",
    "start": "556000",
    "end": "558000"
  },
  {
    "text": "model and then spin it down and then the",
    "start": "558000",
    "end": "560080"
  },
  {
    "text": "output of all this stuff is usually",
    "start": "560080",
    "end": "561760"
  },
  {
    "text": "pretty simple its coefficients for",
    "start": "561760",
    "end": "564040"
  },
  {
    "text": "regressions toss it into some flat file",
    "start": "564040",
    "end": "566640"
  },
  {
    "text": "or JSON file and then as users are",
    "start": "566640",
    "end": "568959"
  },
  {
    "text": "coming in we score them against the",
    "start": "568959",
    "end": "570959"
  },
  {
    "text": "model and say \"Oh I think we should",
    "start": "570959",
    "end": "572480"
  },
  {
    "text": "recommend this movie for this person.\"",
    "start": "572480",
    "end": "573920"
  },
  {
    "text": "And then another person comes in we",
    "start": "573920",
    "end": "575200"
  },
  {
    "text": "should recommend it for that person",
    "start": "575200",
    "end": "576800"
  },
  {
    "text": "because it's too much processing for",
    "start": "576800",
    "end": "579200"
  },
  {
    "text": "every single user to figure out every",
    "start": "579200",
    "end": "581200"
  },
  {
    "text": "single recommendation offline especially",
    "start": "581200",
    "end": "583279"
  },
  {
    "text": "because most users aren't going to come",
    "start": "583279",
    "end": "584720"
  },
  {
    "text": "back so we just need to make sure we can",
    "start": "584720",
    "end": "586800"
  },
  {
    "text": "recommend fast enough for as users come",
    "start": "586800",
    "end": "589519"
  },
  {
    "text": "in and then other things which don't",
    "start": "589519",
    "end": "591600"
  },
  {
    "text": "require on the-fly scoring like um",
    "start": "591600",
    "end": "594480"
  },
  {
    "text": "related movies we can do that offline",
    "start": "594480",
    "end": "596720"
  },
  {
    "text": "and we'll often do that with pig and",
    "start": "596720",
    "end": "600240"
  },
  {
    "text": "python so this is what the",
    "start": "600680",
    "end": "602640"
  },
  {
    "text": "infrastructure looks like now getting a",
    "start": "602640",
    "end": "604160"
  },
  {
    "text": "lot more heavy but still all very",
    "start": "604160",
    "end": "606000"
  },
  {
    "text": "heavily used tools and help us a",
    "start": "606000",
    "end": "608680"
  },
  {
    "text": "lot so back to our question what is",
    "start": "608680",
    "end": "611760"
  },
  {
    "text": "Netflix's data warehouse so how many",
    "start": "611760",
    "end": "614560"
  },
  {
    "text": "people here think it's Cassandra raise",
    "start": "614560",
    "end": "616560"
  },
  {
    "text": "your hands",
    "start": "616560",
    "end": "619760"
  },
  {
    "text": "good brave soul um how many people think",
    "start": "619760",
    "end": "622160"
  },
  {
    "text": "it's terod",
    "start": "622160",
    "end": "623800"
  },
  {
    "text": "data how many people think it's",
    "start": "623800",
    "end": "627079"
  },
  {
    "text": "Hive how many people think it's",
    "start": "627079",
    "end": "629560"
  },
  {
    "text": "S3 wow okay all right either I gave it",
    "start": "629560",
    "end": "632399"
  },
  {
    "text": "away in the the the uh meeting agenda or",
    "start": "632399",
    "end": "635760"
  },
  {
    "text": "you guys are a little too sharp um so",
    "start": "635760",
    "end": "639040"
  },
  {
    "text": "you can see from this picture it is the",
    "start": "639040",
    "end": "641040"
  },
  {
    "text": "central data hub of everything um and",
    "start": "641040",
    "end": "643440"
  },
  {
    "text": "this actually even underounts how much",
    "start": "643440",
    "end": "645040"
  },
  {
    "text": "S3 is part of the fabric of everything",
    "start": "645040",
    "end": "647279"
  },
  {
    "text": "we do uh at Netflix but here you can see",
    "start": "647279",
    "end": "650399"
  },
  {
    "text": "the pipeline back up and down from terod",
    "start": "650399",
    "end": "652640"
  },
  {
    "text": "data for Hadoop for Sting chuckqua feeds",
    "start": "652640",
    "end": "655760"
  },
  {
    "text": "into it uh Augustus feeds into it in",
    "start": "655760",
    "end": "658560"
  },
  {
    "text": "addition Cassandra I told you that wrote",
    "start": "658560",
    "end": "660320"
  },
  {
    "text": "to S3 and then Augustus read from it",
    "start": "660320",
    "end": "662880"
  },
  {
    "text": "augustus wrote it back in JSON format to",
    "start": "662880",
    "end": "664959"
  },
  {
    "text": "S3 chakqua has intermediate stages where",
    "start": "664959",
    "end": "667440"
  },
  {
    "text": "it uses S3 so I can't say enough how",
    "start": "667440",
    "end": "670560"
  },
  {
    "text": "much S3 has helped us um as a company",
    "start": "670560",
    "end": "673519"
  },
  {
    "text": "not worry about storage and elast like",
    "start": "673519",
    "end": "676160"
  },
  {
    "text": "volume and we just throw the data there",
    "start": "676160",
    "end": "678240"
  },
  {
    "text": "and we're good to",
    "start": "678240",
    "end": "680120"
  },
  {
    "text": "go so how specifically do we use S3 with",
    "start": "680120",
    "end": "683839"
  },
  {
    "text": "Hadoop and this EMR part of this",
    "start": "683839",
    "end": "686640"
  },
  {
    "text": "presentation where does that come in so",
    "start": "686640",
    "end": "688480"
  },
  {
    "text": "quite simple and very different than",
    "start": "688480",
    "end": "690320"
  },
  {
    "text": "most people that are in a data center",
    "start": "690320",
    "end": "692160"
  },
  {
    "text": "environment would use um uh Hadoop and",
    "start": "692160",
    "end": "696320"
  },
  {
    "text": "even in in the cloud very few people use",
    "start": "696320",
    "end": "698160"
  },
  {
    "text": "Hadoop this way so most people the",
    "start": "698160",
    "end": "700240"
  },
  {
    "text": "natural what people think of as Hadoop",
    "start": "700240",
    "end": "701839"
  },
  {
    "text": "is it's two components it's map produce",
    "start": "701839",
    "end": "703680"
  },
  {
    "text": "and it's HDFS so HDFS is the storage",
    "start": "703680",
    "end": "707040"
  },
  {
    "text": "layer map produce is the processing on",
    "start": "707040",
    "end": "708640"
  },
  {
    "text": "top of it um but you can use other",
    "start": "708640",
    "end": "710560"
  },
  {
    "text": "backends besides HDFS and we've chosen",
    "start": "710560",
    "end": "713200"
  },
  {
    "text": "to use S3 so all it is is you want to",
    "start": "713200",
    "end": "715279"
  },
  {
    "text": "kick off a Hadoop job which could be",
    "start": "715279",
    "end": "717360"
  },
  {
    "text": "Java Pig or um Hive and the data streams",
    "start": "717360",
    "end": "721680"
  },
  {
    "text": "in parallel from S3 to all the different",
    "start": "721680",
    "end": "724160"
  },
  {
    "text": "map tasks at the same time so yes you're",
    "start": "724160",
    "end": "726240"
  },
  {
    "text": "going to have a little bit of latency",
    "start": "726240",
    "end": "727440"
  },
  {
    "text": "versus HDFS but it's not too bad because",
    "start": "727440",
    "end": "729760"
  },
  {
    "text": "it's the data is all going at once and",
    "start": "729760",
    "end": "732480"
  },
  {
    "text": "then when the job's done the data is all",
    "start": "732480",
    "end": "734000"
  },
  {
    "text": "written back to S3 so given that it's",
    "start": "734000",
    "end": "737279"
  },
  {
    "text": "slower a little bit sometimes like why",
    "start": "737279",
    "end": "739600"
  },
  {
    "text": "would we do that uh the first is",
    "start": "739600",
    "end": "742399"
  },
  {
    "text": "durability so this gives us 11 9 of",
    "start": "742399",
    "end": "745519"
  },
  {
    "text": "durability which is a pretty big deal um",
    "start": "745519",
    "end": "747839"
  },
  {
    "text": "if you've been running a Hadoop cluster",
    "start": "747839",
    "end": "749279"
  },
  {
    "text": "for a while things go wrong things go",
    "start": "749279",
    "end": "751440"
  },
  {
    "text": "wrong with our Hadoop clusters but the",
    "start": "751440",
    "end": "753519"
  },
  {
    "text": "fact that our data is not on the Hadoop",
    "start": "753519",
    "end": "755279"
  },
  {
    "text": "cluster in a persistent fashion has been",
    "start": "755279",
    "end": "757680"
  },
  {
    "text": "a huge win for us we don't have to think",
    "start": "757680",
    "end": "759680"
  },
  {
    "text": "about it we just keep the data on S3 and",
    "start": "759680",
    "end": "761839"
  },
  {
    "text": "then we pull it when we need it another",
    "start": "761839",
    "end": "764880"
  },
  {
    "text": "is versioning so if somebody messes",
    "start": "764880",
    "end": "767839"
  },
  {
    "text": "something up and the data is in a bad",
    "start": "767839",
    "end": "770320"
  },
  {
    "text": "state on HDFS you would have the current",
    "start": "770320",
    "end": "772959"
  },
  {
    "text": "copy unless you have a much more",
    "start": "772959",
    "end": "774399"
  },
  {
    "text": "complicated infrastructure that's",
    "start": "774399",
    "end": "775839"
  },
  {
    "text": "dealing with its own backups and and",
    "start": "775839",
    "end": "777600"
  },
  {
    "text": "versioning but with S3 versioning turned",
    "start": "777600",
    "end": "780000"
  },
  {
    "text": "on for u for our data we can undo at any",
    "start": "780000",
    "end": "783440"
  },
  {
    "text": "point that we want and we also have like",
    "start": "783440",
    "end": "786320"
  },
  {
    "text": "a rolling um pattern of deleting data",
    "start": "786320",
    "end": "788560"
  },
  {
    "text": "that's more than seven days just so that",
    "start": "788560",
    "end": "790160"
  },
  {
    "text": "we don't have it infinitely um costing",
    "start": "790160",
    "end": "792720"
  },
  {
    "text": "us money",
    "start": "792720",
    "end": "794800"
  },
  {
    "text": "so again how does this work in practice",
    "start": "794800",
    "end": "796560"
  },
  {
    "text": "you have the data back and forth from a",
    "start": "796560",
    "end": "798560"
  },
  {
    "text": "Hadoop cluster to S3 what happens to us",
    "start": "798560",
    "end": "801440"
  },
  {
    "text": "when a Hadoop cluster goes down as I",
    "start": "801440",
    "end": "803360"
  },
  {
    "text": "said this is pretty catastrophic for a",
    "start": "803360",
    "end": "805120"
  },
  {
    "text": "lot of companies it's going to take if",
    "start": "805120",
    "end": "806720"
  },
  {
    "text": "nothing else if you've got you know",
    "start": "806720",
    "end": "808480"
  },
  {
    "text": "hundreds of terabytes of data on HDFS",
    "start": "808480",
    "end": "810480"
  },
  {
    "text": "you got to get all that data over there",
    "start": "810480",
    "end": "812079"
  },
  {
    "text": "and not just in our case we just need",
    "start": "812079",
    "end": "813839"
  },
  {
    "text": "the data for the job at hand this is all",
    "start": "813839",
    "end": "815760"
  },
  {
    "text": "the data you want to get in HDFS so for",
    "start": "815760",
    "end": "818079"
  },
  {
    "text": "us we just do this spin up another",
    "start": "818079",
    "end": "820959"
  },
  {
    "text": "cluster 20 or 30 minutes later we're",
    "start": "820959",
    "end": "823120"
  },
  {
    "text": "back in business um and then the old",
    "start": "823120",
    "end": "825279"
  },
  {
    "text": "cluster is gone we've provisioned",
    "start": "825279",
    "end": "826959"
  },
  {
    "text": "hundreds more nodes and we're rolling",
    "start": "826959",
    "end": "830240"
  },
  {
    "text": "and we can take this further and we do",
    "start": "830240",
    "end": "832079"
  },
  {
    "text": "is that instead of just having one",
    "start": "832079",
    "end": "833680"
  },
  {
    "text": "cluster that goes down and then we spin",
    "start": "833680",
    "end": "835200"
  },
  {
    "text": "up a new cluster we have multiple",
    "start": "835200",
    "end": "836959"
  },
  {
    "text": "clusters running and we actually another",
    "start": "836959",
    "end": "838720"
  },
  {
    "text": "thing that's a little different than",
    "start": "838720",
    "end": "839680"
  },
  {
    "text": "most companies is that we have",
    "start": "839680",
    "end": "841360"
  },
  {
    "text": "persistent clusters we really don't like",
    "start": "841360",
    "end": "844399"
  },
  {
    "text": "blow away our clusters every day and",
    "start": "844399",
    "end": "846079"
  },
  {
    "text": "spin them back up because we're always",
    "start": "846079",
    "end": "848079"
  },
  {
    "text": "running jobs against to-do so we have",
    "start": "848079",
    "end": "850240"
  },
  {
    "text": "one big cluster hundreds of nodes that",
    "start": "850240",
    "end": "852720"
  },
  {
    "text": "we call our high SLA cluster and then we",
    "start": "852720",
    "end": "855120"
  },
  {
    "text": "have another uh cluster that we call our",
    "start": "855120",
    "end": "856959"
  },
  {
    "text": "query cluster and high SLA is the sort",
    "start": "856959",
    "end": "859120"
  },
  {
    "text": "of vetted jobs that run our nightly",
    "start": "859120",
    "end": "861519"
  },
  {
    "text": "batch processing um we know that they're",
    "start": "861519",
    "end": "864079"
  },
  {
    "text": "they play nice and the query cluster is",
    "start": "864079",
    "end": "866480"
  },
  {
    "text": "cowboy anything goes um you can crush",
    "start": "866480",
    "end": "868720"
  },
  {
    "text": "your neighbor but hopefully not too bad",
    "start": "868720",
    "end": "871519"
  },
  {
    "text": "and on top of that this is also",
    "start": "871519",
    "end": "873040"
  },
  {
    "text": "underells a little bit how much we're",
    "start": "873040",
    "end": "874480"
  },
  {
    "text": "using S3 as a backing we have test",
    "start": "874480",
    "end": "876000"
  },
  {
    "text": "clusters hitting production data we spin",
    "start": "876000",
    "end": "877680"
  },
  {
    "text": "up temporary clusters to hit production",
    "start": "877680",
    "end": "879519"
  },
  {
    "text": "data if we need",
    "start": "879519",
    "end": "881399"
  },
  {
    "text": "it but it does pose the question about",
    "start": "881399",
    "end": "884160"
  },
  {
    "text": "what about HTFS do we really not use",
    "start": "884160",
    "end": "886720"
  },
  {
    "text": "HTFS like isn't that crazy um and it's a",
    "start": "886720",
    "end": "890639"
  },
  {
    "text": "little sensational to say we don't use",
    "start": "890639",
    "end": "892079"
  },
  {
    "text": "HTFS if we're running a pig job or a",
    "start": "892079",
    "end": "894399"
  },
  {
    "text": "hive job it's going to have a lot of",
    "start": "894399",
    "end": "896000"
  },
  {
    "text": "intram map produce jobs and those are",
    "start": "896000",
    "end": "898079"
  },
  {
    "text": "going to write to HDFS and read from",
    "start": "898079",
    "end": "899680"
  },
  {
    "text": "HDFS so you're going to get some",
    "start": "899680",
    "end": "901040"
  },
  {
    "text": "economies there um but we'll just have a",
    "start": "901040",
    "end": "903839"
  },
  {
    "text": "little bit of a hit at the beginning and",
    "start": "903839",
    "end": "905279"
  },
  {
    "text": "at the end but it's been a worthwhile",
    "start": "905279",
    "end": "907040"
  },
  {
    "text": "trade-off for us and the only way that",
    "start": "907040",
    "end": "908639"
  },
  {
    "text": "it makes sense is you have to think of",
    "start": "908639",
    "end": "910079"
  },
  {
    "text": "it as a batch processing system which is",
    "start": "910079",
    "end": "912399"
  },
  {
    "text": "hard for people to get in their heads",
    "start": "912399",
    "end": "914240"
  },
  {
    "text": "especially if they're using Hive and",
    "start": "914240",
    "end": "915839"
  },
  {
    "text": "it's a SQL like syntax so they expect",
    "start": "915839",
    "end": "917839"
  },
  {
    "text": "databased",
    "start": "917839",
    "end": "920399"
  },
  {
    "text": "performance and one of the last sort of",
    "start": "921160",
    "end": "923680"
  },
  {
    "text": "traditional EMR things that we do is",
    "start": "923680",
    "end": "926160"
  },
  {
    "text": "that we do expand and shrink our",
    "start": "926160",
    "end": "927760"
  },
  {
    "text": "clusters so during the day we expand our",
    "start": "927760",
    "end": "930320"
  },
  {
    "text": "cowboy query cluster so that people can",
    "start": "930320",
    "end": "932399"
  },
  {
    "text": "get more um fun work stuff done and then",
    "start": "932399",
    "end": "935199"
  },
  {
    "text": "at night we expand our our batch",
    "start": "935199",
    "end": "937040"
  },
  {
    "text": "processing um high SLA cluster and it's",
    "start": "937040",
    "end": "940639"
  },
  {
    "text": "been pretty good it's not perfect so",
    "start": "940639",
    "end": "942639"
  },
  {
    "text": "we're still working with Amazon to to",
    "start": "942639",
    "end": "944639"
  },
  {
    "text": "perfect this um one problem that we're",
    "start": "944639",
    "end": "946480"
  },
  {
    "text": "having right now is that sometimes when",
    "start": "946480",
    "end": "948480"
  },
  {
    "text": "we shrink our clusters um some of the",
    "start": "948480",
    "end": "951040"
  },
  {
    "text": "reduced jobs can get stuck because when",
    "start": "951040",
    "end": "953360"
  },
  {
    "text": "the map task dies it doesn't time out",
    "start": "953360",
    "end": "955920"
  },
  {
    "text": "fast enough and it's still trying to get",
    "start": "955920",
    "end": "957279"
  },
  {
    "text": "the data and it just hangs so it could",
    "start": "957279",
    "end": "960079"
  },
  {
    "text": "make our jobs take longer than we want",
    "start": "960079",
    "end": "962079"
  },
  {
    "text": "and what we're we're pushing Amazon to",
    "start": "962079",
    "end": "963680"
  },
  {
    "text": "do is um we lowest common denominator",
    "start": "963680",
    "end": "966320"
  },
  {
    "text": "will just be like hey fix the timeout",
    "start": "966320",
    "end": "968480"
  },
  {
    "text": "fix make it better the timeout so that",
    "start": "968480",
    "end": "970399"
  },
  {
    "text": "it it moves on to a new map task that's",
    "start": "970399",
    "end": "972800"
  },
  {
    "text": "another thing of Hadoop it's it's built",
    "start": "972800",
    "end": "974320"
  },
  {
    "text": "into retry when something fails but even",
    "start": "974320",
    "end": "976399"
  },
  {
    "text": "better would be graceful shutdown so if",
    "start": "976399",
    "end": "978560"
  },
  {
    "text": "with an Amazon if we're deprovisioning",
    "start": "978560",
    "end": "980480"
  },
  {
    "text": "nodes and they know we're doing it like",
    "start": "980480",
    "end": "982560"
  },
  {
    "text": "not catastrophically has to happen right",
    "start": "982560",
    "end": "984480"
  },
  {
    "text": "now then they can gracefully shut down",
    "start": "984480",
    "end": "986000"
  },
  {
    "text": "nodes and stop map tasks from running so",
    "start": "986000",
    "end": "988079"
  },
  {
    "text": "I think that'll help a lot with um",
    "start": "988079",
    "end": "989759"
  },
  {
    "text": "making this up and down much more",
    "start": "989759",
    "end": "991279"
  },
  {
    "text": "seamless and it is pretty Amazon",
    "start": "991279",
    "end": "992880"
  },
  {
    "text": "specific because you're not going to do",
    "start": "992880",
    "end": "994000"
  },
  {
    "text": "a lot of this in a in a data center but",
    "start": "994000",
    "end": "995920"
  },
  {
    "text": "it's a a real win in the cloud um a",
    "start": "995920",
    "end": "999120"
  },
  {
    "text": "couple other just interesting points",
    "start": "999120",
    "end": "1001120"
  },
  {
    "text": "about expanding and shrinking if you",
    "start": "1001120",
    "end": "1002720"
  },
  {
    "text": "haven't done it one is that there's two",
    "start": "1002720",
    "end": "1004560"
  },
  {
    "text": "kinds of nodes um there's task nodes and",
    "start": "1004560",
    "end": "1006560"
  },
  {
    "text": "core nodes in Hadoop and the core nodes",
    "start": "1006560",
    "end": "1009680"
  },
  {
    "text": "have HTFS on them the task nodes don't",
    "start": "1009680",
    "end": "1012800"
  },
  {
    "text": "so you actually can't go crazy with your",
    "start": "1012800",
    "end": "1016000"
  },
  {
    "text": "expansion as I said we do use HDFS as",
    "start": "1016000",
    "end": "1018240"
  },
  {
    "text": "intrum for pig and hive jobs so if you",
    "start": "1018240",
    "end": "1021279"
  },
  {
    "text": "had like 10 core nodes and you added 50",
    "start": "1021279",
    "end": "1023759"
  },
  {
    "text": "task nodes then when those task nodes",
    "start": "1023759",
    "end": "1025600"
  },
  {
    "text": "try to write some data as an intram step",
    "start": "1025600",
    "end": "1027199"
  },
  {
    "text": "they'd have to send it to a core node so",
    "start": "1027199",
    "end": "1028798"
  },
  {
    "text": "you have tons of in addition to normal",
    "start": "1028799",
    "end": "1030319"
  },
  {
    "text": "Hadoop you'd have tons of cross traffic",
    "start": "1030319",
    "end": "1032319"
  },
  {
    "text": "where all the HDFS stuff is going to",
    "start": "1032319",
    "end": "1034480"
  },
  {
    "text": "those few core nodes so practically",
    "start": "1034480",
    "end": "1036319"
  },
  {
    "text": "speaking Amazon recommends not more than",
    "start": "1036319",
    "end": "1038000"
  },
  {
    "text": "a 2:1 task core to task node ratio which",
    "start": "1038000",
    "end": "1041520"
  },
  {
    "text": "is it means it's not infinitely scalable",
    "start": "1041520",
    "end": "1043918"
  },
  {
    "text": "if you really want to scale it start",
    "start": "1043919",
    "end": "1045360"
  },
  {
    "text": "from scratch with a brand new cluster",
    "start": "1045360",
    "end": "1047120"
  },
  {
    "text": "with all core nodes if you needed to do",
    "start": "1047120",
    "end": "1048799"
  },
  {
    "text": "that um so that's one one consideration",
    "start": "1048799",
    "end": "1051679"
  },
  {
    "text": "um another thing is that um we've",
    "start": "1051679",
    "end": "1053840"
  },
  {
    "text": "actually paid for all of our nodes ahead",
    "start": "1053840",
    "end": "1055840"
  },
  {
    "text": "of time for the most part so almost all",
    "start": "1055840",
    "end": "1057840"
  },
  {
    "text": "reservations at Netflix are heavy",
    "start": "1057840",
    "end": "1060000"
  },
  {
    "text": "utilization so if you don't use the",
    "start": "1060000",
    "end": "1061919"
  },
  {
    "text": "nodes you still pay for them um what we",
    "start": "1061919",
    "end": "1064160"
  },
  {
    "text": "don't pay is the EMR search charge on",
    "start": "1064160",
    "end": "1066000"
  },
  {
    "text": "top of it plus if we can have someone",
    "start": "1066000",
    "end": "1067840"
  },
  {
    "text": "else in Netflix use these nodes then",
    "start": "1067840",
    "end": "1069760"
  },
  {
    "text": "that can be a win if we don't need them",
    "start": "1069760",
    "end": "1071280"
  },
  {
    "text": "at that time",
    "start": "1071280",
    "end": "1074559"
  },
  {
    "text": "so that's sort of like the core like",
    "start": "1074720",
    "end": "1077760"
  },
  {
    "text": "goodness of EMR um but what we try to do",
    "start": "1077760",
    "end": "1080960"
  },
  {
    "text": "because we always like to get extra",
    "start": "1080960",
    "end": "1082559"
  },
  {
    "text": "credit at Netflix is take it a step",
    "start": "1082559",
    "end": "1084880"
  },
  {
    "text": "further um and the same way that you you",
    "start": "1084880",
    "end": "1087760"
  },
  {
    "text": "hear a lot of presentations um this",
    "start": "1087760",
    "end": "1089600"
  },
  {
    "text": "these last couple days is that Amazon",
    "start": "1089600",
    "end": "1091520"
  },
  {
    "text": "opens up capabilities to developers they",
    "start": "1091520",
    "end": "1093440"
  },
  {
    "text": "had never had before you want to spin up",
    "start": "1093440",
    "end": "1095280"
  },
  {
    "text": "a machine you don't have to go talk to",
    "start": "1095280",
    "end": "1097200"
  },
  {
    "text": "it and get it provisioned up um but that",
    "start": "1097200",
    "end": "1099600"
  },
  {
    "text": "doesn't always extend to all",
    "start": "1099600",
    "end": "1100880"
  },
  {
    "text": "applications so data is historically",
    "start": "1100880",
    "end": "1103360"
  },
  {
    "text": "been very tough for engineering teams to",
    "start": "1103360",
    "end": "1105840"
  },
  {
    "text": "get at um like interestingly they don't",
    "start": "1105840",
    "end": "1108240"
  },
  {
    "text": "most of the engineering teams don't like",
    "start": "1108240",
    "end": "1109360"
  },
  {
    "text": "terod data just because it's not in the",
    "start": "1109360",
    "end": "1111440"
  },
  {
    "text": "cloud and they got to like go through",
    "start": "1111440",
    "end": "1112720"
  },
  {
    "text": "DBAs and even though they don't have to",
    "start": "1112720",
    "end": "1114480"
  },
  {
    "text": "go through DBAs at Netflix but it feels",
    "start": "1114480",
    "end": "1116320"
  },
  {
    "text": "like you have to go through DBAs and how",
    "start": "1116320",
    "end": "1118000"
  },
  {
    "text": "do you get to it and you don't know that",
    "start": "1118000",
    "end": "1119600"
  },
  {
    "text": "that infrastructure as well so what we",
    "start": "1119600",
    "end": "1122080"
  },
  {
    "text": "wanted to do is open up our data to",
    "start": "1122080",
    "end": "1124640"
  },
  {
    "text": "whoever needs it to optimize their area",
    "start": "1124640",
    "end": "1127200"
  },
  {
    "text": "so we call this data science as a",
    "start": "1127200",
    "end": "1128880"
  },
  {
    "text": "service and we created a few service",
    "start": "1128880",
    "end": "1130720"
  },
  {
    "text": "that that do what um this enabling this",
    "start": "1130720",
    "end": "1133039"
  },
  {
    "text": "opening up that I just mentioned so the",
    "start": "1133039",
    "end": "1135120"
  },
  {
    "text": "first is called the execution service or",
    "start": "1135120",
    "end": "1137919"
  },
  {
    "text": "genie and what this lets you do is",
    "start": "1137919",
    "end": "1140080"
  },
  {
    "text": "through a restful API you can just kick",
    "start": "1140080",
    "end": "1142160"
  },
  {
    "text": "kick off a java map produce job or a",
    "start": "1142160",
    "end": "1144480"
  },
  {
    "text": "hive job or a pig job you don't have to",
    "start": "1144480",
    "end": "1146320"
  },
  {
    "text": "get on a command line or ssh onto a",
    "start": "1146320",
    "end": "1148720"
  },
  {
    "text": "gateway machine and have all the client",
    "start": "1148720",
    "end": "1150400"
  },
  {
    "text": "software installed you can just restful",
    "start": "1150400",
    "end": "1152799"
  },
  {
    "text": "API here's the pig query I wanna I want",
    "start": "1152799",
    "end": "1155120"
  },
  {
    "text": "to fire off go and then the your results",
    "start": "1155120",
    "end": "1157760"
  },
  {
    "text": "will get put into s S3 and we call it",
    "start": "1157760",
    "end": "1160160"
  },
  {
    "text": "genie because it grants any wish you",
    "start": "1160160",
    "end": "1161760"
  },
  {
    "text": "want as long as it's hive pig or java",
    "start": "1161760",
    "end": "1164400"
  },
  {
    "text": "map",
    "start": "1164400",
    "end": "1165080"
  },
  {
    "text": "produce and then um the next is the",
    "start": "1165080",
    "end": "1167520"
  },
  {
    "text": "event service so this is um what",
    "start": "1167520",
    "end": "1169600"
  },
  {
    "text": "happened and when so if you want to know",
    "start": "1169600",
    "end": "1172000"
  },
  {
    "text": "like did the last hour of viewing data",
    "start": "1172000",
    "end": "1174160"
  },
  {
    "text": "is it available for my graphing",
    "start": "1174160",
    "end": "1176400"
  },
  {
    "text": "application for example um you can just",
    "start": "1176400",
    "end": "1178799"
  },
  {
    "text": "interrogate the event service and it'll",
    "start": "1178799",
    "end": "1180400"
  },
  {
    "text": "tell you that and then finally we have a",
    "start": "1180400",
    "end": "1182640"
  },
  {
    "text": "metadata service which is what data is",
    "start": "1182640",
    "end": "1184640"
  },
  {
    "text": "out there and where so rather than get",
    "start": "1184640",
    "end": "1187039"
  },
  {
    "text": "all the technical side of it I'm going",
    "start": "1187039",
    "end": "1188480"
  },
  {
    "text": "to show you how we put it into practice",
    "start": "1188480",
    "end": "1190559"
  },
  {
    "text": "and we're looking at open sourcing some",
    "start": "1190559",
    "end": "1192320"
  },
  {
    "text": "of these technologies um next year so",
    "start": "1192320",
    "end": "1195440"
  },
  {
    "text": "the first is uh we created a lightweight",
    "start": "1195440",
    "end": "1197520"
  },
  {
    "text": "hive UI on top of uh Genie it's not the",
    "start": "1197520",
    "end": "1201600"
  },
  {
    "text": "prettiest thing in the world because",
    "start": "1201600",
    "end": "1202960"
  },
  {
    "text": "we're not a vendor we don't have to make",
    "start": "1202960",
    "end": "1204320"
  },
  {
    "text": "it that pretty but it does the job for",
    "start": "1204320",
    "end": "1206160"
  },
  {
    "text": "us which is you",
    "start": "1206160",
    "end": "1208440"
  },
  {
    "text": "can enter a You can't really see the",
    "start": "1208440",
    "end": "1211120"
  },
  {
    "text": "pointer you can enter a SQL query in the",
    "start": "1211120",
    "end": "1214000"
  },
  {
    "text": "left and on the right you can see the",
    "start": "1214000",
    "end": "1215520"
  },
  {
    "text": "metadata that it pulls from the the Hive",
    "start": "1215520",
    "end": "1217280"
  },
  {
    "text": "meta store and run a simple query and",
    "start": "1217280",
    "end": "1220160"
  },
  {
    "text": "then you're good to go so what's a",
    "start": "1220160",
    "end": "1223360"
  },
  {
    "text": "little different is you kind of expect",
    "start": "1223360",
    "end": "1224640"
  },
  {
    "text": "if you're used to classical um terod",
    "start": "1224640",
    "end": "1227120"
  },
  {
    "text": "data assistant kind of uh tools you get",
    "start": "1227120",
    "end": "1229840"
  },
  {
    "text": "the results right away but it's Hive",
    "start": "1229840",
    "end": "1231679"
  },
  {
    "text": "you're not going to get the results",
    "start": "1231679",
    "end": "1232720"
  },
  {
    "text": "right away and things could fail and you",
    "start": "1232720",
    "end": "1234640"
  },
  {
    "text": "might want to know the status of the job",
    "start": "1234640",
    "end": "1235919"
  },
  {
    "text": "as it's running so we toss up some of",
    "start": "1235919",
    "end": "1238000"
  },
  {
    "text": "the information that you get for free um",
    "start": "1238000",
    "end": "1240400"
  },
  {
    "text": "from Hadoop and then we just wrap it in",
    "start": "1240400",
    "end": "1242320"
  },
  {
    "text": "a nice little uh web page where at the",
    "start": "1242320",
    "end": "1245440"
  },
  {
    "text": "top of it you can kill the job if you",
    "start": "1245440",
    "end": "1247039"
  },
  {
    "text": "want if it was an something accidental",
    "start": "1247039",
    "end": "1249440"
  },
  {
    "text": "you can see a status in the middle that",
    "start": "1249440",
    "end": "1251440"
  },
  {
    "text": "says it's running and then that red URL",
    "start": "1251440",
    "end": "1254080"
  },
  {
    "text": "near the bottom is you can click that at",
    "start": "1254080",
    "end": "1255520"
  },
  {
    "text": "any time to see the status of your job",
    "start": "1255520",
    "end": "1257280"
  },
  {
    "text": "the results errors",
    "start": "1257280",
    "end": "1259799"
  },
  {
    "text": "etc auto refreshes every few seconds now",
    "start": "1259799",
    "end": "1263200"
  },
  {
    "text": "it says it succeeded in the",
    "start": "1263200",
    "end": "1265480"
  },
  {
    "text": "middle click on that URL and here's you",
    "start": "1265480",
    "end": "1268799"
  },
  {
    "text": "know classic results from from Hadoop",
    "start": "1268799",
    "end": "1271039"
  },
  {
    "text": "plus a few other things that we get",
    "start": "1271039",
    "end": "1272159"
  },
  {
    "text": "through Genie you can see your standard",
    "start": "1272159",
    "end": "1273840"
  },
  {
    "text": "out your standard error and here's your",
    "start": "1273840",
    "end": "1276480"
  },
  {
    "text": "results beautifully formatted for",
    "start": "1276480",
    "end": "1280320"
  },
  {
    "text": "you so that's that's a pretty",
    "start": "1281000",
    "end": "1284240"
  },
  {
    "text": "lightweight like enabler that is a lot",
    "start": "1284240",
    "end": "1286640"
  },
  {
    "text": "easier for a lot of people than sshing",
    "start": "1286640",
    "end": "1288880"
  },
  {
    "text": "on a machine and using a command line so",
    "start": "1288880",
    "end": "1291039"
  },
  {
    "text": "it's been really helpful for us um but",
    "start": "1291039",
    "end": "1293919"
  },
  {
    "text": "there's more so the next thing that our",
    "start": "1293919",
    "end": "1296880"
  },
  {
    "text": "infrastructure enables us to do is um as",
    "start": "1296880",
    "end": "1300080"
  },
  {
    "text": "I said before we have multiple clusters",
    "start": "1300080",
    "end": "1301760"
  },
  {
    "text": "that are sharing data and we've had some",
    "start": "1301760",
    "end": "1303919"
  },
  {
    "text": "times where we're like oh shoot we",
    "start": "1303919",
    "end": "1305440"
  },
  {
    "text": "really want to bounce the job tracker",
    "start": "1305440",
    "end": "1307440"
  },
  {
    "text": "let's say on the high SLA cluster",
    "start": "1307440",
    "end": "1309679"
  },
  {
    "text": "because we want to change some parameter",
    "start": "1309679",
    "end": "1311440"
  },
  {
    "text": "and the only way to do it is to bounce",
    "start": "1311440",
    "end": "1312960"
  },
  {
    "text": "the job tracker now the problem with",
    "start": "1312960",
    "end": "1315200"
  },
  {
    "text": "that historically is that you either",
    "start": "1315200",
    "end": "1316960"
  },
  {
    "text": "have to tell all your users sorry at",
    "start": "1316960",
    "end": "1319280"
  },
  {
    "text": "this time the cluster is going to get",
    "start": "1319280",
    "end": "1320640"
  },
  {
    "text": "down make sure your jobs are all done by",
    "start": "1320640",
    "end": "1322640"
  },
  {
    "text": "this point or you just kill it on them",
    "start": "1322640",
    "end": "1324480"
  },
  {
    "text": "anyway and then they have to restart it",
    "start": "1324480",
    "end": "1326799"
  },
  {
    "text": "but it's nice if we had a more graceful",
    "start": "1326799",
    "end": "1328799"
  },
  {
    "text": "way of doing it so our more graceful way",
    "start": "1328799",
    "end": "1330960"
  },
  {
    "text": "of doing it is we say okay well the job",
    "start": "1330960",
    "end": "1333760"
  },
  {
    "text": "was being routed through Genie anyway on",
    "start": "1333760",
    "end": "1335679"
  },
  {
    "text": "this high SLA cluster routing let's just",
    "start": "1335679",
    "end": "1338320"
  },
  {
    "text": "repoint all those jobs the user said \"I",
    "start": "1338320",
    "end": "1340400"
  },
  {
    "text": "want on the high SLA cluster but let's",
    "start": "1340400",
    "end": "1342320"
  },
  {
    "text": "repoint them all to the query cluster",
    "start": "1342320",
    "end": "1344520"
  },
  {
    "text": "instead.\" And we can pick a time where",
    "start": "1344520",
    "end": "1346799"
  },
  {
    "text": "we know there's a low in the query",
    "start": "1346799",
    "end": "1348080"
  },
  {
    "text": "cluster or we could expand the query",
    "start": "1348080",
    "end": "1349600"
  },
  {
    "text": "cluster to handle the extra capacity and",
    "start": "1349600",
    "end": "1351840"
  },
  {
    "text": "the real beauty of this is that we don't",
    "start": "1351840",
    "end": "1354480"
  },
  {
    "text": "kill the high cluster right away we let",
    "start": "1354480",
    "end": "1356799"
  },
  {
    "text": "it finish so any jobs that are already",
    "start": "1356799",
    "end": "1358720"
  },
  {
    "text": "running the person doesn't have to worry",
    "start": "1358720",
    "end": "1359919"
  },
  {
    "text": "about restarting them when all the jobs",
    "start": "1359919",
    "end": "1361760"
  },
  {
    "text": "have finally finished then we bounce the",
    "start": "1361760",
    "end": "1364080"
  },
  {
    "text": "high SLA cluster and then we reroute",
    "start": "1364080",
    "end": "1367520"
  },
  {
    "text": "Genie to point to the high SLA cluster",
    "start": "1367520",
    "end": "1369760"
  },
  {
    "text": "all the jobs that are high SLA that",
    "start": "1369760",
    "end": "1371679"
  },
  {
    "text": "started in the query cluster they'll",
    "start": "1371679",
    "end": "1373200"
  },
  {
    "text": "finish as they normally did return their",
    "start": "1373200",
    "end": "1375360"
  },
  {
    "text": "results the user doesn't really even",
    "start": "1375360",
    "end": "1376799"
  },
  {
    "text": "care what cluster it's running on and",
    "start": "1376799",
    "end": "1378799"
  },
  {
    "text": "we're back in business so it's it's a",
    "start": "1378799",
    "end": "1380799"
  },
  {
    "text": "pretty novel capability of having that",
    "start": "1380799",
    "end": "1383120"
  },
  {
    "text": "abstraction layer um in front of",
    "start": "1383120",
    "end": "1387000"
  },
  {
    "text": "Hadoop but high SLA cluster is not good",
    "start": "1387000",
    "end": "1389760"
  },
  {
    "text": "enough we need a super SLA cluster and",
    "start": "1389760",
    "end": "1393200"
  },
  {
    "text": "as I said before we are sharing machines",
    "start": "1393200",
    "end": "1396640"
  },
  {
    "text": "you know thousands and thousands of",
    "start": "1396640",
    "end": "1398320"
  },
  {
    "text": "machines across Netflix and there are",
    "start": "1398320",
    "end": "1400559"
  },
  {
    "text": "trough periods so and as I said we're",
    "start": "1400559",
    "end": "1402640"
  },
  {
    "text": "we're mostly using heavy utilization",
    "start": "1402640",
    "end": "1404480"
  },
  {
    "text": "reservations so we're paying for those",
    "start": "1404480",
    "end": "1406080"
  },
  {
    "text": "machines whether we use them or not so",
    "start": "1406080",
    "end": "1408080"
  },
  {
    "text": "what we started doing is borrowing",
    "start": "1408080",
    "end": "1410159"
  },
  {
    "text": "machines from this central pool at these",
    "start": "1410159",
    "end": "1413039"
  },
  {
    "text": "trough periods and then what we can do",
    "start": "1413039",
    "end": "1415280"
  },
  {
    "text": "is it just it happened to work out that",
    "start": "1415280",
    "end": "1417440"
  },
  {
    "text": "the trough periods is around midnight",
    "start": "1417440",
    "end": "1419440"
  },
  {
    "text": "PST because people on the east coast are",
    "start": "1419440",
    "end": "1421600"
  },
  {
    "text": "well asleep and people on the Pacific",
    "start": "1421600",
    "end": "1423200"
  },
  {
    "text": "time are finally winding down and that's",
    "start": "1423200",
    "end": "1425280"
  },
  {
    "text": "just when we need extra nodes to do our",
    "start": "1425280",
    "end": "1427280"
  },
  {
    "text": "nightly processing so we say rock on",
    "start": "1427280",
    "end": "1430400"
  },
  {
    "text": "spin up this extra cluster at midnight",
    "start": "1430400",
    "end": "1432880"
  },
  {
    "text": "put the jobs that are what we call the",
    "start": "1432880",
    "end": "1434960"
  },
  {
    "text": "long pole for our ETL the things that if",
    "start": "1434960",
    "end": "1437120"
  },
  {
    "text": "they don't finish all the reports get",
    "start": "1437120",
    "end": "1438880"
  },
  {
    "text": "delayed so the really critical jobs we",
    "start": "1438880",
    "end": "1441200"
  },
  {
    "text": "can run those in complete isolation on",
    "start": "1441200",
    "end": "1443200"
  },
  {
    "text": "the super SLA cluster get our reports",
    "start": "1443200",
    "end": "1445840"
  },
  {
    "text": "out earlier and then return those those",
    "start": "1445840",
    "end": "1448400"
  },
  {
    "text": "uh machines to the central pool and then",
    "start": "1448400",
    "end": "1450400"
  },
  {
    "text": "the nice thing is it's a little more",
    "start": "1450400",
    "end": "1451520"
  },
  {
    "text": "elastic than that like worst case",
    "start": "1451520",
    "end": "1453200"
  },
  {
    "text": "scenario if we didn't finish our jobs in",
    "start": "1453200",
    "end": "1455679"
  },
  {
    "text": "time then we pay on demand charges or um",
    "start": "1455679",
    "end": "1458880"
  },
  {
    "text": "we could just kill it if we had to and",
    "start": "1458880",
    "end": "1461120"
  },
  {
    "text": "then the jobs we have um a best practice",
    "start": "1461120",
    "end": "1463440"
  },
  {
    "text": "of automatically restarting all of your",
    "start": "1463440",
    "end": "1465520"
  },
  {
    "text": "Hadoop jobs if they fail how depending",
    "start": "1465520",
    "end": "1467520"
  },
  {
    "text": "on how you schedule it and then even",
    "start": "1467520",
    "end": "1468960"
  },
  {
    "text": "that are exponential decay restarting",
    "start": "1468960",
    "end": "1470799"
  },
  {
    "text": "and all sorts of fun stuff like that so",
    "start": "1470799",
    "end": "1473919"
  },
  {
    "text": "and then during the day if somebody",
    "start": "1473919",
    "end": "1475520"
  },
  {
    "text": "kicks off a super SLA cluster job and",
    "start": "1475520",
    "end": "1477760"
  },
  {
    "text": "there is no super SLA cluster then we",
    "start": "1477760",
    "end": "1480480"
  },
  {
    "text": "can just route them to the high SLA",
    "start": "1480480",
    "end": "1482240"
  },
  {
    "text": "cluster so again it's a level of",
    "start": "1482240",
    "end": "1484320"
  },
  {
    "text": "abstraction that is on top of what",
    "start": "1484320",
    "end": "1486640"
  },
  {
    "text": "Hadoop builds and it's leveraging this",
    "start": "1486640",
    "end": "1488960"
  },
  {
    "text": "this shared S3 capability and EMR",
    "start": "1488960",
    "end": "1494000"
  },
  {
    "text": "the last thing I'm going to show",
    "start": "1494000",
    "end": "1496279"
  },
  {
    "text": "you I'll take a a chance with the demo",
    "start": "1496279",
    "end": "1499120"
  },
  {
    "text": "gods um vPNing into Netflix and hoping",
    "start": "1499120",
    "end": "1501919"
  },
  {
    "text": "none of my teammates mess with the",
    "start": "1501919",
    "end": "1503600"
  },
  {
    "text": "system is this is Sting that I mentioned",
    "start": "1503600",
    "end": "1506640"
  },
  {
    "text": "before this is this lightweight",
    "start": "1506640",
    "end": "1508159"
  },
  {
    "text": "visualization tool um probably the",
    "start": "1508159",
    "end": "1510880"
  },
  {
    "text": "biggest challenge in doing a demo on a",
    "start": "1510880",
    "end": "1513840"
  },
  {
    "text": "tool that shows data is not getting",
    "start": "1513840",
    "end": "1515440"
  },
  {
    "text": "myself in trouble by showing some",
    "start": "1515440",
    "end": "1517600"
  },
  {
    "text": "sensitive data so what this query",
    "start": "1517600",
    "end": "1520960"
  },
  {
    "text": "actually does is it shows when people",
    "start": "1520960",
    "end": "1523840"
  },
  {
    "text": "are watching particular genres relative",
    "start": "1523840",
    "end": "1526640"
  },
  {
    "text": "to that genre so it actually doesn't",
    "start": "1526640",
    "end": "1528480"
  },
  {
    "text": "give anything away in terms of like how",
    "start": "1528480",
    "end": "1530720"
  },
  {
    "text": "much are people watching thrillers but",
    "start": "1530720",
    "end": "1532400"
  },
  {
    "text": "it shows when people are actually",
    "start": "1532400",
    "end": "1533840"
  },
  {
    "text": "watching thrillers so not too",
    "start": "1533840",
    "end": "1535679"
  },
  {
    "text": "surprisingly you can see oh on Monday",
    "start": "1535679",
    "end": "1539279"
  },
  {
    "text": "you know peaks around six o'clock PST",
    "start": "1539279",
    "end": "1541919"
  },
  {
    "text": "and then similar pattern on Tuesday and",
    "start": "1541919",
    "end": "1544240"
  },
  {
    "text": "Wednesday and Thursday oh it starts",
    "start": "1544240",
    "end": "1546000"
  },
  {
    "text": "increasing on Friday Saturday it really",
    "start": "1546000",
    "end": "1548320"
  },
  {
    "text": "rocks on and then Sunday it's down and",
    "start": "1548320",
    "end": "1550799"
  },
  {
    "text": "you could run a hive query and you could",
    "start": "1550799",
    "end": "1553200"
  },
  {
    "text": "put Excel and you could put a graph on",
    "start": "1553200",
    "end": "1555279"
  },
  {
    "text": "top of it and that would work um but you",
    "start": "1555279",
    "end": "1557120"
  },
  {
    "text": "can't really interact with it and you",
    "start": "1557120",
    "end": "1558320"
  },
  {
    "text": "can't deal with millions of records at",
    "start": "1558320",
    "end": "1559840"
  },
  {
    "text": "the same time so um actually the same",
    "start": "1559840",
    "end": "1562799"
  },
  {
    "text": "guys that worked on the Aegus project",
    "start": "1562799",
    "end": "1565039"
  },
  {
    "text": "built this tool and it lets you deal",
    "start": "1565039",
    "end": "1567919"
  },
  {
    "text": "with millions of rows at the same time",
    "start": "1567919",
    "end": "1570799"
  },
  {
    "text": "so some of the coolness you could do is",
    "start": "1570799",
    "end": "1572640"
  },
  {
    "text": "you might think well maybe all genres",
    "start": "1572640",
    "end": "1574559"
  },
  {
    "text": "are like this at Netflix but they're not",
    "start": "1574559",
    "end": "1577679"
  },
  {
    "text": "so here I just added children and family",
    "start": "1577679",
    "end": "1579919"
  },
  {
    "text": "and you'll see it's a very different",
    "start": "1579919",
    "end": "1581679"
  },
  {
    "text": "pattern let me remove thrillers to make",
    "start": "1581679",
    "end": "1583679"
  },
  {
    "text": "it even more obvious so forget Monday",
    "start": "1583679",
    "end": "1587120"
  },
  {
    "text": "for a second let's look at Tuesday you",
    "start": "1587120",
    "end": "1589360"
  },
  {
    "text": "see Tuesday Wednesday and Thursday all",
    "start": "1589360",
    "end": "1591760"
  },
  {
    "text": "show a very similar pattern where it's",
    "start": "1591760",
    "end": "1593360"
  },
  {
    "text": "ramping up how much people are watching",
    "start": "1593360",
    "end": "1595200"
  },
  {
    "text": "it peaks at around four and then drops",
    "start": "1595200",
    "end": "1599159"
  },
  {
    "text": "down and then Friday or uh let's see",
    "start": "1599159",
    "end": "1601919"
  },
  {
    "text": "Friday does the same thing then Saturday",
    "start": "1601919",
    "end": "1603360"
  },
  {
    "text": "and Sunday drastically different pattern",
    "start": "1603360",
    "end": "1605600"
  },
  {
    "text": "not surprising at all it's because kids",
    "start": "1605600",
    "end": "1607520"
  },
  {
    "text": "will wake up in the morning and they",
    "start": "1607520",
    "end": "1608799"
  },
  {
    "text": "start watching their cartoons and",
    "start": "1608799",
    "end": "1609840"
  },
  {
    "text": "they're watching cartoons all day and",
    "start": "1609840",
    "end": "1611440"
  },
  {
    "text": "then it drops off heavily at the end of",
    "start": "1611440",
    "end": "1613200"
  },
  {
    "text": "the day so there's an example so you saw",
    "start": "1613200",
    "end": "1615679"
  },
  {
    "text": "how quickly I could add and remove",
    "start": "1615679",
    "end": "1617279"
  },
  {
    "text": "filters where you can slice and dice",
    "start": "1617279",
    "end": "1618880"
  },
  {
    "text": "data and it would take a you couldn't do",
    "start": "1618880",
    "end": "1620559"
  },
  {
    "text": "that in Hive you'd be pulling your hair",
    "start": "1620559",
    "end": "1621919"
  },
  {
    "text": "out if you had to do that um and then",
    "start": "1621919",
    "end": "1625200"
  },
  {
    "text": "the reason I skipped Monday is at first",
    "start": "1625200",
    "end": "1626720"
  },
  {
    "text": "I looked at this data i thought it was",
    "start": "1626720",
    "end": "1627919"
  },
  {
    "text": "an error and I was like what's wrong",
    "start": "1627919",
    "end": "1629520"
  },
  {
    "text": "with our data and then I realized it was",
    "start": "1629520",
    "end": "1631279"
  },
  {
    "text": "Veterans Day on November 12th so the",
    "start": "1631279",
    "end": "1633279"
  },
  {
    "text": "data is smarter than the analyst in this",
    "start": "1633279",
    "end": "1635120"
  },
  {
    "text": "case and um the pattern changed so there",
    "start": "1635120",
    "end": "1638400"
  },
  {
    "text": "was a lot more um viewing in the",
    "start": "1638400",
    "end": "1640240"
  },
  {
    "text": "throughout the",
    "start": "1640240",
    "end": "1641799"
  },
  {
    "text": "day so and then it does other cool stuff",
    "start": "1641799",
    "end": "1644480"
  },
  {
    "text": "um you know like you can do it by date",
    "start": "1644480",
    "end": "1646320"
  },
  {
    "text": "if you want you can email links to",
    "start": "1646320",
    "end": "1649080"
  },
  {
    "text": "people um you can change the time",
    "start": "1649080",
    "end": "1653559"
  },
  {
    "text": "slider that's not a very interesting",
    "start": "1653559",
    "end": "1655840"
  },
  {
    "text": "time",
    "start": "1655840",
    "end": "1657720"
  },
  {
    "text": "slider let me add thrillers back in",
    "start": "1657720",
    "end": "1660960"
  },
  {
    "text": "that's because I have date in there so",
    "start": "1660960",
    "end": "1662400"
  },
  {
    "text": "remove",
    "start": "1662400",
    "end": "1663720"
  },
  {
    "text": "date and super super fast this can",
    "start": "1663720",
    "end": "1667200"
  },
  {
    "text": "handle millions of records and the",
    "start": "1667200",
    "end": "1668640"
  },
  {
    "text": "technologies if anyone's interested are",
    "start": "1668640",
    "end": "1670640"
  },
  {
    "text": "it's Cherry Pie NumPy Pandas um SciPie",
    "start": "1670640",
    "end": "1676080"
  },
  {
    "text": "D3JS pie charts and Twitter Bootstrap",
    "start": "1676080",
    "end": "1679120"
  },
  {
    "text": "but it makes for a really nice",
    "start": "1679120",
    "end": "1680559"
  },
  {
    "text": "application and super fast in-memory",
    "start": "1680559",
    "end": "1683080"
  },
  {
    "text": "aggregations but the really the main",
    "start": "1683080",
    "end": "1685039"
  },
  {
    "text": "reason I showed it is it's really a",
    "start": "1685039",
    "end": "1686640"
  },
  {
    "text": "showcase of those services that I",
    "start": "1686640",
    "end": "1688399"
  },
  {
    "text": "mentioned before so where does this data",
    "start": "1688399",
    "end": "1690399"
  },
  {
    "text": "set come from it's a Hive query it's a",
    "start": "1690399",
    "end": "1693200"
  },
  {
    "text": "it's an Uber set of data that you can",
    "start": "1693200",
    "end": "1695360"
  },
  {
    "text": "slice and dice different ways um but",
    "start": "1695360",
    "end": "1697919"
  },
  {
    "text": "it's a high query executed through the",
    "start": "1697919",
    "end": "1699600"
  },
  {
    "text": "execution service genie the data is all",
    "start": "1699600",
    "end": "1702640"
  },
  {
    "text": "stored in the metadata service so that's",
    "start": "1702640",
    "end": "1704240"
  },
  {
    "text": "what we know what data sets are",
    "start": "1704240",
    "end": "1705520"
  },
  {
    "text": "available and then the event service can",
    "start": "1705520",
    "end": "1707360"
  },
  {
    "text": "be used to when should I rebuild this",
    "start": "1707360",
    "end": "1709039"
  },
  {
    "text": "graph did I get another hour of data",
    "start": "1709039",
    "end": "1711120"
  },
  {
    "text": "that I want to toss on to the end of",
    "start": "1711120",
    "end": "1712799"
  },
  {
    "text": "this thing so again this abstraction",
    "start": "1712799",
    "end": "1714480"
  },
  {
    "text": "lets us build tools on top of it and the",
    "start": "1714480",
    "end": "1716880"
  },
  {
    "text": "funny thing too is that we actually",
    "start": "1716880",
    "end": "1718640"
  },
  {
    "text": "didn't intend this to be the end all and",
    "start": "1718640",
    "end": "1720880"
  },
  {
    "text": "beall visualization tool this was all",
    "start": "1720880",
    "end": "1723120"
  },
  {
    "text": "built to be a back-end data service that",
    "start": "1723120",
    "end": "1725440"
  },
  {
    "text": "people could put whatever visualization",
    "start": "1725440",
    "end": "1726799"
  },
  {
    "text": "they wanted to put on top of it but of",
    "start": "1726799",
    "end": "1728480"
  },
  {
    "text": "course you give someone a tool they just",
    "start": "1728480",
    "end": "1729840"
  },
  {
    "text": "want you to keep adding features versus",
    "start": "1729840",
    "end": "1731760"
  },
  {
    "text": "building their own um",
    "start": "1731760",
    "end": "1733960"
  },
  {
    "text": "UIs so that in a",
    "start": "1733960",
    "end": "1738440"
  },
  {
    "text": "nutshell",
    "start": "1738440",
    "end": "1741320"
  },
  {
    "text": "is is it let's see oh yeah here we go",
    "start": "1741320",
    "end": "1747440"
  }
]
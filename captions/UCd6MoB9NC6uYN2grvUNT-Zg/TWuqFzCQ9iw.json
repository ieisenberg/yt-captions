[
  {
    "text": " Welcome to #GraphThat episode three GenAI and Knowledge Graphs.",
    "start": "0",
    "end": "8766"
  },
  {
    "text": " If you aren't familiar with the #GraphThat series, we take public data sets  and convert them to a graph model optimized for Amazon Neptune.",
    "start": "8766",
    "end": "17566"
  },
  {
    "text": " Amazon Neptune is a fast, reliable, fully managed database service that makes it easy to build",
    "start": "17566",
    "end": "24666"
  },
  {
    "text": "and run applications that rely on highly connected data sets.  The core of Neptune is a high performance, purpose built, graph database engine.",
    "start": "24666",
    "end": "33166"
  },
  {
    "text": " This engine is optimized for storing billions of relationships and querying the graph with millisecond latency.",
    "start": "33166",
    "end": "39166"
  },
  {
    "text": " Customers frequently ask for assistance on modeling their data for graphs.",
    "start": "39166",
    "end": "44299"
  },
  {
    "text": " So we hope this series will inspire on the subject.  In this episode,",
    "start": "44300",
    "end": "49699"
  },
  {
    "text": " I'm going to cheat a bit and brush the dust off an old data set from a blog post.",
    "start": "49700",
    "end": "54733"
  },
  {
    "text": " In that post, I took press releases from amazon.com,  ran them through Amazon Comprehend Events to",
    "start": "54733",
    "end": "60933"
  },
  {
    "text": "extract entities and events from the unstructured data  and then modeled it into a graph.",
    "start": "60933",
    "end": "66833"
  },
  {
    "text": " Today, we are going to reuse that data set as the foundation of our knowledge graph.",
    "start": "66833",
    "end": "72100"
  },
  {
    "text": "And then we're going to utilize an LLM to query it  the original blog and source code to create the knowledge",
    "start": "72100",
    "end": "78566"
  },
  {
    "text": "graph can be found using this URL or QR code. ",
    "start": "78566",
    "end": "86066"
  },
  {
    "text": "I know that a lot of information exists about retrieval augmented generation or RAG. ",
    "start": "86066",
    "end": "91433"
  },
  {
    "text": "the variant called GraphRAG  and GenAI in general,  many of these toolkits abstract the basics away",
    "start": "91433",
    "end": "99298"
  },
  {
    "text": "and focus on just raw unstructured information.  But what if we already have structured knowledge?",
    "start": "99300",
    "end": "105800"
  },
  {
    "text": " So before we dive in to our knowledge graph, first, I'm gonna cover the essentials about RAG.",
    "start": "105800",
    "end": "111832"
  },
  {
    "text": " And then I'm going to show why GraphRAG is an improvement over RAG. ",
    "start": "111833",
    "end": "117799"
  },
  {
    "text": "Then we'll do a quick recap of our existing knowledge graph model from the blog post. ",
    "start": "117800",
    "end": "123266"
  },
  {
    "text": "And finally, I'll show you how we can connect it up to an LLM easily just using the AWS SDK and some prompt engineering,",
    "start": "123266",
    "end": "130366"
  },
  {
    "text": " no external toolkit required.  So with that,  let's get started.",
    "start": "130366",
    "end": "135666"
  },
  {
    "text": " So first, how does retrieval augmented generation (RAG) work ",
    "start": "135666",
    "end": "141333"
  },
  {
    "text": "RAG is a machine learning technique that combines the strengths of language models and retrieval systems to",
    "start": "141333",
    "end": "146632"
  },
  {
    "text": "generate more informative and accurate outputs.  The key idea behind RAG is to use a",
    "start": "146633",
    "end": "152465"
  },
  {
    "text": "retrieval module to find relevant information from a knowledge base or corpus and then use that information to",
    "start": "152466",
    "end": "158166"
  },
  {
    "text": "guide the language model during the generation process.  The main advantage of RAG is that it can",
    "start": "158166",
    "end": "163199"
  },
  {
    "text": "generate more accurate outputs compared to traditional language models ",
    "start": "163200",
    "end": "168299"
  },
  {
    "text": "which may struggle with factual inconsistencies or lack of relevant information  commonly known as hallucinations",
    "start": "168300",
    "end": "174532"
  },
  {
    "text": " by leveraging the retrieval component,  RAG can dynamically access and integrate external knowledge as",
    "start": "174533",
    "end": "181599"
  },
  {
    "text": "needed leading to more informed and contextually relevant responses.  So how does all of this work?",
    "start": "181600",
    "end": "187800"
  },
  {
    "text": " RAG generally involves taking unstructured documents, splitting them up into chunks",
    "start": "187800",
    "end": "193333"
  },
  {
    "text": " and then creating vector embeddings on each chunk  vector embeddings are a way of representing words, phrases,",
    "start": "193333",
    "end": "200566"
  },
  {
    "text": " or other data as numerical vectors  where each element in the vector corresponds to a particular feature or dimension.",
    "start": "200566",
    "end": "208099"
  },
  {
    "text": " The key idea is to capture the semantic relationships and meaning of the input in a compact mathematical representation.",
    "start": "208100",
    "end": "216032"
  },
  {
    "text": " Then we calculate vectors on the questions we are asking ",
    "start": "216033",
    "end": "221066"
  },
  {
    "text": "and search for those chunks that are most similar  and share them with the LLM for use in generating the model.",
    "start": "221066",
    "end": "226433"
  },
  {
    "text": " Let's see this in action. ",
    "start": "226433",
    "end": "232633"
  },
  {
    "text": "So first, here we are taking  two press releases ",
    "start": "232633",
    "end": "237799"
  },
  {
    "text": "from our corpus.  The first describes Amazon and Whole Foods Markets and their merger",
    "start": "237800",
    "end": "243965"
  },
  {
    "text": " back in 2017.  And the second one is   the text from a press release",
    "start": "243966",
    "end": "251866"
  },
  {
    "text": " that talks about Amazon selling partner conferences,  selling partner conferences selling out in six weeks.",
    "start": "251866",
    "end": "258631"
  },
  {
    "text": "So as you can see it doesn't have anything to do with Whole Foods. ",
    "start": "258633",
    "end": "264133"
  },
  {
    "text": "So I'm going to add  this text into my  Neptune notebook here ",
    "start": "264133",
    "end": "272499"
  },
  {
    "text": "and I'm going to install some tools, some Python tools that's gonna help me analyze these.  So I have semchunk,",
    "start": "272500",
    "end": "278432"
  },
  {
    "text": " tiktoken,  and  scikit-learn. ",
    "start": "278433",
    "end": "283633"
  },
  {
    "text": "So first thing that needs to happen is what is tokenizing. So what does tokenizing mean?",
    "start": "283633",
    "end": "288766"
  },
  {
    "text": " Tokenizing is a way of taking a sequence of characters and it maps them",
    "start": "288766",
    "end": "294332"
  },
  {
    "text": "to a set of numbers and those numbers are going to be fed into",
    "start": "294333",
    "end": "299366"
  },
  {
    "text": " the  large learning model.  So in this case, I'm using  the CL100K base, which is one of the  tokenizing models.",
    "start": "299366",
    "end": "309133"
  },
  {
    "text": " each  LM model uses its own tokenizer. So I'm just using this as an example.",
    "start": "309133",
    "end": "315166"
  },
  {
    "text": " And I took the first few words from that first press release.  And so you can see that this generates 26 tokens.",
    "start": "315166",
    "end": "322066"
  },
  {
    "text": "   Each one of them is assigned a number. So the word Amazon becomes token 26,948.",
    "start": "322066",
    "end": "328798"
  },
  {
    "text": " open parentheses is 00320.",
    "start": "328800",
    "end": "333900"
  },
  {
    "text": " And you can see if the token appears more than once, right, a space and then open parentheses that is assigned the same number.",
    "start": "333900",
    "end": "340166"
  },
  {
    "text": " And so the way that these token models are generated is that they, represent either a word or a part of a word",
    "start": "340166",
    "end": "347300"
  },
  {
    "text": " that has meaning.  So after we generate all these tokens, now,",
    "start": "347300",
    "end": "353766"
  },
  {
    "text": "what we do is we break up that document into a number of chunks based on a chunk size",
    "start": "353766",
    "end": "360766"
  },
  {
    "text": "that's best for our model  for here, I just arbitrarily chose 128 tokens.  I'm gonna run that same chunker",
    "start": "360766",
    "end": "367700"
  },
  {
    "text": " and over those two press releases  and you could see that the first document ",
    "start": "367700",
    "end": "372900"
  },
  {
    "text": "had, you know, there's 13 chunks total. The first document  makes up these first three chunks and then the second document is the other 10.",
    "start": "372900",
    "end": "381366"
  },
  {
    "text": " So now we have 13 chunks from those two documents. ",
    "start": "381366",
    "end": "387266"
  },
  {
    "text": "And now what we're going to do is we are going to generate  the  vectors",
    "start": "387266",
    "end": "392533"
  },
  {
    "text": " on each one of these chunks.  So here we we're gonna use the boto3",
    "start": "392533",
    "end": "400199"
  },
  {
    "text": " library, to call bedrock runtime.  And we're gonna use the model ",
    "start": "400200",
    "end": "405298"
  },
  {
    "text": "Titan  embed text  V2. So this is going to generate",
    "start": "405300",
    "end": "410698"
  },
  {
    "text": " ua sequence of vectors  for each one of our chunks. So I run this and it's gonna take a second to",
    "start": "410700",
    "end": "418866"
  },
  {
    "text": " make the calls out to bedrock.    And we could see that So for instance, the first chunk we had that end up being 129 tokens.",
    "start": "418866",
    "end": "427233"
  },
  {
    "text": " The size of the embedding was 1024 which is the output of the model.",
    "start": "427233",
    "end": "432266"
  },
  {
    "text": " And you could see, so these are a bunch of numbers that represent essentially the semantic meaning of that",
    "start": "432266",
    "end": "439800"
  },
  {
    "text": " chunk of text in a way that  can be understood by machine model. ",
    "start": "439800",
    "end": "445298"
  },
  {
    "text": "And then we continue this for each one of these chunks. ",
    "start": "445300",
    "end": "451832"
  },
  {
    "text": "And then we're gonna do the same process with the question we want to ask the LLM model  So in this case, our question is what are the connections between Amazon and Whole Foods?",
    "start": "451833",
    "end": "460166"
  },
  {
    "text": " So we go and we",
    "start": "460166",
    "end": "466000"
  },
  {
    "text": "create the vectors for that as well.  So you can see that the connection between Amazon and Whole Foods,",
    "start": "466000",
    "end": "471433"
  },
  {
    "text": " the number of input tokens  is 11 from this question. And again, it generates 1024 embeddings",
    "start": "471433",
    "end": "477900"
  },
  {
    "text": " and then we're going to calculate ",
    "start": "477900",
    "end": "483266"
  },
  {
    "text": "cosine  similarity.  So  what we do here is we take each one of these documents,",
    "start": "483266",
    "end": "489866"
  },
  {
    "text": "each one of these chunks of documents.  And we, we calculate how far they are ",
    "start": "489866",
    "end": "495132"
  },
  {
    "text": "in terms of  the 1024 vectors ",
    "start": "495133",
    "end": "500566"
  },
  {
    "text": "from the    from our question. [Breaking News Music]",
    "start": "500566",
    "end": "508732"
  },
  {
    "text": "So first  let's take a little bit closer look at  exactly what cosine",
    "start": "508733",
    "end": "513966"
  },
  {
    "text": " similarity is  Here, we just have two sample documents",
    "start": "513966",
    "end": "520266"
  },
  {
    "text": "   that are completely fabricated and a question. So remember in the case, we had 1024 dimensions in our vectors to make this simple,",
    "start": "520266",
    "end": "529666"
  },
  {
    "text": "I just have two.  right? So for our question, the vectors are zero and negative one.  There are two document chunks,",
    "start": "529666",
    "end": "536966"
  },
  {
    "text": "one that's -2 and 3, and one that's 2 and 1.  So what we want to do first is we want to calculate the distance between",
    "start": "536966",
    "end": "544966"
  },
  {
    "text": " each of these points.  And so for just two dimensions, it's just the difference of the",
    "start": "544966",
    "end": "553599"
  },
  {
    "text": " X1 and X2  multiply them by each other. And same thing with Y1 and Y2.",
    "start": "553600",
    "end": "560599"
  },
  {
    "text": " -2 times 0 is 0. 3 times -1 is -3.",
    "start": "560600",
    "end": "566466"
  },
  {
    "text": " And then we add them together. So X plus Y is -3,",
    "start": "566466",
    "end": "571666"
  },
  {
    "text": "-3 is the distance in this case.  And down here, we can see the distance is -1",
    "start": "571666",
    "end": "577899"
  },
  {
    "text": " So now we've calculated distance what we want to do is calculate the magnitude.",
    "start": "577900",
    "end": "583299"
  },
  {
    "text": " So the magnitude is, and there's libraries to do all this for you, so you don't really need to memorize this math",
    "start": "583300",
    "end": "590000"
  },
  {
    "text": " but essentially what it comes down to is we want to take the X and Y, square each one of them,",
    "start": "590000",
    "end": "597432"
  },
  {
    "text": "add them together, and then calculate the square root. So the magnitude on the first document is 3.61",
    "start": "597433",
    "end": "603498"
  },
  {
    "text": " magnitude on the second document is 2.24. And the magnitude on original question is 1.0.",
    "start": "603500",
    "end": "609332"
  },
  {
    "text": " And so now we can calculate now that we have the distance and the magnitude, we can calculate the",
    "start": "609333",
    "end": "615799"
  },
  {
    "text": " cosine similarity by taking the distance and dividing that by  ",
    "start": "615800",
    "end": "621933"
  },
  {
    "text": "the magnitude of the two points, the distance between two points and divide that by the  the factor of",
    "start": "621933",
    "end": "628099"
  },
  {
    "text": " the two magnitudes multiplied by each other.  So we can see the  cosine similarity between",
    "start": "628100",
    "end": "634566"
  },
  {
    "text": " the first document and our question is  minus 0.832. ",
    "start": "634566",
    "end": "639733"
  },
  {
    "text": "And for the second document, it is minus 0.447.",
    "start": "639733",
    "end": "645298"
  },
  {
    "text": " So you can see that the smaller value is to the right. And if you look at the distance of the lines, you can see that",
    "start": "645300",
    "end": "652933"
  },
  {
    "text": " the second document is actually closer  to  our original question than the first one.",
    "start": "652933",
    "end": "659900"
  },
  {
    "text": " So what we would say is we would say that the second document is more similar  and the first document is less similar.",
    "start": "659900",
    "end": "666466"
  },
  {
    "start": "666466",
    "end": "671866"
  },
  {
    "text": "So I run this and I'm telling it to return the top three   ",
    "start": "671866",
    "end": "677032"
  },
  {
    "text": "most similar documents.  And so you can see the first document is,",
    "start": "677033",
    "end": "682266"
  },
  {
    "text": " you know, what we saw was our first chunk, which obviously had a lot to do with Whole Foods Market. So did the second one.",
    "start": "682266",
    "end": "687966"
  },
  {
    "text": "   and then the third most, the third closest document actually had nothing to do with it.",
    "start": "687966",
    "end": "693633"
  },
  {
    "text": "It talks about the the Selling Partner Summit.  And so I'm just gonna print out these three chunks. So we can see",
    "start": "693633",
    "end": "700399"
  },
  {
    "text": " and you can see the first one right? It's clearly talking about the Whole Foods Market acquisition that's very relevant to our question.",
    "start": "700400",
    "end": "706966"
  },
  {
    "text": " The second one talks more about details about Whole Foods. John Mackey is the cofounder and CEO",
    "start": "706966",
    "end": "713766"
  },
  {
    "text": " what they will continue to do under Amazon and  so forth.  And the third chunk is just the summary of the press release about",
    "start": "713766",
    "end": "722633"
  },
  {
    "text": " the Selling Partner Summit Series, talking about  different principles of Amazon and products,",
    "start": "722633",
    "end": "730233"
  },
  {
    "text": "but it doesn't actually talk about Whole Foods at all here.  So you can see  the main issue here is that we were not able to",
    "start": "730233",
    "end": "739699"
  },
  {
    "text": "   you know, we arbitrarily chose top three",
    "start": "739700",
    "end": "746099"
  },
  {
    "text": "but we don't really know if  all three of them are actually relevant.  So if we take these three chunks of documents and pass it into the LLM",
    "start": "746100",
    "end": "754266"
  },
  {
    "text": " it may  hallucinate, it may bring things up talking about partners or something like that",
    "start": "754266",
    "end": "760199"
  },
  {
    "text": "  isn't really relevant  to the question. ",
    "start": "760200",
    "end": "765632"
  },
  {
    "text": "Where you might especially see this is if you're  covering areas where ",
    "start": "765633",
    "end": "772300"
  },
  {
    "text": "   the context is missing, like let's say one document is talking about health care records and the other",
    "start": "772300",
    "end": "779266"
  },
  {
    "text": " document is talk about like financial markets.  There might be information in both of those",
    "start": "779266",
    "end": "784300"
  },
  {
    "text": " if you care about healthcare markets, that financial market information probably isn't relevant to you,",
    "start": "784300",
    "end": "791233"
  },
  {
    "text": "but things might get injected into the answer because of it. ",
    "start": "791233",
    "end": "796366"
  },
  {
    "text": "So we're gonna pause there and we're gonna move on to GraphRAG. ",
    "start": "796366",
    "end": "802766"
  },
  {
    "text": "OK, what is  GraphRAG then?  So GraphRAG extends the RAG that we just",
    "start": "802766",
    "end": "809298"
  },
  {
    "text": "spoke about by also incorporating a graph element.  Generally, the data will also be organized with nodes",
    "start": "809300",
    "end": "815399"
  },
  {
    "text": "representing key entities from the chunk of information  and relationships between those key entities will be stored. Also,",
    "start": "815400",
    "end": "822666"
  },
  {
    "text": " this allows us to retrieve information not directly referenced  in the most similar documents and also validate that",
    "start": "822666",
    "end": "830365"
  },
  {
    "text": "those similar documents are refering to the key entities.  So let's take a look at this",
    "start": "830366",
    "end": "836266"
  },
  {
    "text": " here. We have those same document chunks that we had before.",
    "start": "836266",
    "end": "842365"
  },
  {
    "text": " And what we're gonna do is we're going to define a prompt  ",
    "start": "842366",
    "end": "847666"
  },
  {
    "text": "using the Claude Haiku model.  And what we're going to ask the ",
    "start": "847666",
    "end": "852965"
  },
  {
    "text": "LLM to do is identify entities from the text, from that chunk of document.",
    "start": "852966",
    "end": "860099"
  },
  {
    "text": " And to keep this very similar to the original content from",
    "start": "860100",
    "end": "865799"
  },
  {
    "text": "   Amazon Comprehend Events  we are going to identify similar",
    "start": "865800",
    "end": "870998"
  },
  {
    "text": " entities that were found in there. So I'm saying the identities,  the entities that it can identify are organizations, dates, people, facilities,",
    "start": "871000",
    "end": "879500"
  },
  {
    "text": "people titles, locations, monetary value, stock codes, and quantity.  And",
    "start": "879500",
    "end": "884533"
  },
  {
    "text": " I also want to give it some more complex instructions.  The way that Comprehend Events works is if it extracts a stock code,",
    "start": "884533",
    "end": "891800"
  },
  {
    "text": "it formats in a way that the market  identifier is in front of it,",
    "start": "891800",
    "end": "897433"
  },
  {
    "text": "a colon and then the stock ticker code, because you can have the same stock ticker on multiple markets.",
    "start": "897433",
    "end": "904133"
  },
  {
    "text": " So I'm telling you if it's a stock code,  I wanted to do this where, for instance,",
    "start": "904133",
    "end": "910632"
  },
  {
    "text": "the Citigroup is traded on the New York Stock Exchange.  And this is how it would format the output Apple is traded on the NASDAQ,",
    "start": "910633",
    "end": "916699"
  },
  {
    "text": "it would format it like this.  And if it doesn't know which market the symbols traded on, it can just use unknown.",
    "start": "916700",
    "end": "923366"
  },
  {
    "text": " And when somebody gives it text, I want to identify these and return the,",
    "start": "923366",
    "end": "929599"
  },
  {
    "text": "the output in this  JSON format.  So I'm gonna take all 13 chunks of document",
    "start": "929600",
    "end": "936200"
  },
  {
    "text": " that I have and I'm going to run it through this model  or through this. I'm gonna send it to the LLM and have it identify",
    "start": "936200",
    "end": "943465"
  },
  {
    "text": " these entities. ",
    "start": "943466",
    "end": "949299"
  },
  {
    "text": "So you can see here that we have  some  that's cut off on the string",
    "start": "949300",
    "end": "954832"
  },
  {
    "text": " but it's OK, we'll see these more in detail later.  But what it did is it went through all 13 chunks.",
    "start": "954833",
    "end": "961699"
  },
  {
    "text": "This is a zero referenced list, so it's 0 to 12  and identified the sets of entities",
    "start": "961700",
    "end": "966900"
  },
  {
    "text": " from those documents.  And now we're gonna ask it to do the same thing for our",
    "start": "966900",
    "end": "974433"
  },
  {
    "text": " question  right? So the instructions prompt here is",
    "start": "974433",
    "end": "980632"
  },
  {
    "text": " you are excellent identifying  these from a question. It makes you happy to provide the correct answer ",
    "start": "980633",
    "end": "985799"
  },
  {
    "text": "pretty much the same instructions.  And again, to return the  JSON.  So I'm going to ask you the question,",
    "start": "985800",
    "end": "991432"
  },
  {
    "text": "what are the connections between Amazon and Whole Foods Markets  Incorporated?  And it's gonna look at that question and it's gonna say, OK,",
    "start": "991433",
    "end": "999200"
  },
  {
    "text": "I found basically I found two entities in that question, Amazon  and Whole Foods Market Incorporated.",
    "start": "999200",
    "end": "1005100"
  },
  {
    "text": " And so to give you an example of a subset of those entities that are extracted.",
    "start": "1005100",
    "end": "1011965"
  },
  {
    "text": " Here's we have document one, document two, here's the chunks that were taken from each document and here's the entities that are referenced.",
    "start": "1011966",
    "end": "1018733"
  },
  {
    "text": "So you can see like Jeff Bezos and Whole Foods Market is in chunk zero and Amazon,",
    "start": "1018733",
    "end": "1024032"
  },
  {
    "text": " Chunk one identified Whole Foods Market Incorporated and John Mackey  ",
    "start": "1024033",
    "end": "1029066"
  },
  {
    "text": " chunk two has 2017 and Amazon.    and then you can see some examples from the second document as well.",
    "start": "1029066",
    "end": "1036699"
  },
  {
    "text": "It's not a fully inclusive list, it's just some examples to give you an idea.",
    "start": "1036700",
    "end": "1042166"
  },
  {
    "text": " And  so what I'm gonna do now is now that I have all the",
    "start": "1042166",
    "end": "1048166"
  },
  {
    "text": " chunks  and the entities extracted from each of these chunks, including my question.",
    "start": "1048166",
    "end": "1053599"
  },
  {
    "text": " I'm just gonna create two simple Pandas functions here. That's going to pull out of the list if there's any entities",
    "start": "1053600",
    "end": "1061600"
  },
  {
    "text": " that reference the certain words. So here I'm gonna look for  Amazon or Whole Foods Market Incorporated or Whole Foods Market.",
    "start": "1061600",
    "end": "1068933"
  },
  {
    "text": "   and I'm gonna create new columns.  \"Has Amazon\" \"Has Whole Foods Market\"",
    "start": "1068933",
    "end": "1074132"
  },
  {
    "text": " and I want to  kind of show the results here, right? So",
    "start": "1074133",
    "end": "1080033"
  },
  {
    "text": " these are all sorted in order of similarity that we calculated before.  So",
    "start": "1080033",
    "end": "1085399"
  },
  {
    "text": " remember when we did just RAG, we essentially have this set of information. the first three columns",
    "start": "1085400",
    "end": "1091565"
  },
  {
    "text": " by adding in GraphRAG, now we have these extra columns here, right?",
    "start": "1091566",
    "end": "1096933"
  },
  {
    "text": " And so we can see that    almost all of these documents reference Amazon,",
    "start": "1096933",
    "end": "1102766"
  },
  {
    "text": "which you probably expect given they are Amazon press releases,  only the first two documents reference Whole Foods Market",
    "start": "1102766",
    "end": "1109366"
  },
  {
    "text": " and notice that the second chunk there doesn't actually  talk about Amazon at all. If you go back and look at it again.",
    "start": "1109366",
    "end": "1116199"
  },
  {
    "text": " It was talking mostly about John Mackey",
    "start": "1116200",
    "end": "1121799"
  },
  {
    "text": "and Whole Foods market and what Whole Foods Market was gonna be under Amazon, but it never actually spoke about Amazon.",
    "start": "1121800",
    "end": "1127032"
  },
  {
    "text": " So  GraphRAG we can see takes that original RAG concept,",
    "start": "1127033",
    "end": "1134133"
  },
  {
    "text": "which would have found this third document  and  would have included it if we said show me the the K=3 nearest",
    "start": "1134133",
    "end": "1143166"
  },
  {
    "text": "   documents.  But now we can actually add to our  search and say, oh wait, this doesn't actually talk about Whole Foods at all.",
    "start": "1143166",
    "end": "1151999"
  },
  {
    "text": " So maybe I don't want to include that  and this one does talk about Whole Foods, but it doesn't talk about Amazon.",
    "start": "1152000",
    "end": "1157700"
  },
  {
    "text": "But you can see that the RAG part of this was able to identify the context and say,",
    "start": "1157700",
    "end": "1163000"
  },
  {
    "text": "well, this really is very similar to the question    as much as anything because it mentions Whole Foods Market directly.",
    "start": "1163000",
    "end": "1170899"
  },
  {
    "text": "And so we probably want to include this.  So this is why GraphRAG gives you better results, right?",
    "start": "1170900",
    "end": "1175999"
  },
  {
    "text": "Because in this case, it would omit this information  that  isn't really related to Whole Foods at all.",
    "start": "1176000",
    "end": "1184165"
  },
  {
    "text": "Even though it's the third closest document,  the fact of the matter is all these documents are not very similar, you know,",
    "start": "1184166",
    "end": "1189699"
  },
  {
    "text": "are not very relevant to our query.  So",
    "start": "1189700",
    "end": "1196366"
  },
  {
    "text": " where are we going to go from this?  And this is what I'm going to demonstrate today, is that  what if you already have all your documents in a knowledge base like this? Right?",
    "start": "1196366",
    "end": "1205799"
  },
  {
    "text": "And you don't have these vectors, you don't have this, but you want to make do with what you have.  It is expensive to go and take all this text out",
    "start": "1205800",
    "end": "1214266"
  },
  {
    "text": "and reorganize my entire knowledge graph.  And so that is going to be our next section where we're going to talk about",
    "start": "1214266",
    "end": "1220066"
  },
  {
    "text": " What if I don't want to use RAG right now? Maybe RAG is down the road how can I still take advantage of my knowledge graph using an LLM?",
    "start": "1220066",
    "end": "1228799"
  },
  {
    "text": " So we'll be back in a second to talk about that topic ",
    "start": "1228800",
    "end": "1233900"
  },
  {
    "text": "Before we get into the code  I want to give a quick overview of what the model from my existing knowledge graph looks like.",
    "start": "1233900",
    "end": "1241132"
  },
  {
    "text": " So again, this is all detailed in the blog post that I shared at the beginning.",
    "start": "1241133",
    "end": "1247132"
  },
  {
    "text": " But  to give you a quick update. Our graph is formatted as a series of documents,",
    "start": "1247133",
    "end": "1253766"
  },
  {
    "text": " documents have one or more events  and events have one or more entities.",
    "start": "1253766",
    "end": "1259833"
  },
  {
    "text": " In this case, the document references the full document. Remember we're using our existing knowledge graph here, not the output from the RAG process that",
    "start": "1259833",
    "end": "1268566"
  },
  {
    "text": "we described in the GraphRAG process  So a document in this case is a full press release,",
    "start": "1268566",
    "end": "1274066"
  },
  {
    "text": " inside that press release Amazon Comprehend Events identified one or more events",
    "start": "1274066",
    "end": "1280266"
  },
  {
    "text": " and each one of those events has a number of entities that are associated with that event",
    "start": "1280266",
    "end": "1285866"
  },
  {
    "text": " and each has a role.  So it goes document, document has an edge called event that leads to the event.",
    "start": "1285866",
    "end": "1293233"
  },
  {
    "text": " The name   of the event is actually the",
    "start": "1293233",
    "end": "1298466"
  },
  {
    "text": " proper name itself. So for example, like \"acquires\"  or corporate acquisition",
    "start": "1298466",
    "end": "1304900"
  },
  {
    "text": " and then there's entities in the role. So for example, acquirer might be Amazon",
    "start": "1304900",
    "end": "1311566"
  },
  {
    "text": " and acquiree  would be Whole Foods Market",
    "start": "1311566",
    "end": "1318100"
  },
  {
    "text": "   So we just describe the model, so now what do we want",
    "start": "1318100",
    "end": "1326966"
  },
  {
    "text": "Let's demonstrate how we can interact with that  existing knowledge graph.  So I want to use the LLM, I want this to be a natural language",
    "start": "1326966",
    "end": "1335399"
  },
  {
    "text": " interface, a chatbot interface.  And so, first what I need to do is I need to setup how I'm going to interact with this.",
    "start": "1335400",
    "end": "1345366"
  },
  {
    "text": " So I'm gonna set up bedrock to speak to our desired LLM. In this case, we're going to use Claude",
    "start": "1345366",
    "end": "1350866"
  },
  {
    "text": " Haiku.  And I have a series of questions here. I'll just go through the first one",
    "start": "1350866",
    "end": "1356500"
  },
  {
    "text": " and my question is gonna be, \"what are the connections between the ticker  AMZN",
    "start": "1356500",
    "end": "1362000"
  },
  {
    "text": " and John Mackey?\" ",
    "start": "1362000",
    "end": "1367566"
  },
  {
    "text": "and much like we did before,  I'm going to prompt the LLM to extract the entities that are coming out of that.",
    "start": "1367566",
    "end": "1375800"
  },
  {
    "text": "that I'm asking about  and I'm gonna take this one step further from before.",
    "start": "1375800",
    "end": "1381233"
  },
  {
    "text": "And then I'm also gonna have the LLM identify what type of question this was.  There's two types that I'm supporting. One is an inquiry question.",
    "start": "1381233",
    "end": "1390233"
  },
  {
    "text": "So this is something like \"tell me everything about  the entity\"  or a connections question which is \"show",
    "start": "1390233",
    "end": "1395933"
  },
  {
    "text": "me the similarities or the connections between  entity one and entity two\". ",
    "start": "1395933",
    "end": "1401032"
  },
  {
    "text": "  As you can see here  that  I'll put it in the",
    "start": "1401033",
    "end": "1408533"
  },
  {
    "text": " JSON format like I did before. So I'm going to run this  and we will see that the LLM identified that it's a connection type question.",
    "start": "1408533",
    "end": "1416799"
  },
  {
    "text": "The entities are the stock code  which is NASDAQ:AMZN  and the person John Mackey.",
    "start": "1416800",
    "end": "1423066"
  },
  {
    "text": " And note I did not tell it anywhere. There's nowhere in my knowledge graph that says the stock code for Amazon is",
    "start": "1423066",
    "end": "1430566"
  },
  {
    "text": "   traded on NASDAQ,  right? The prompt said, the stock AMZN.",
    "start": "1430566",
    "end": "1436566"
  },
  {
    "text": " And in my prompts, I gave it examples for uh New York Stock Exchange and NASDAQ,",
    "start": "1436566",
    "end": "1443133"
  },
  {
    "text": "but for the Apple stock  it just knew from its training that Amazon was part of NASDAQ and therefore",
    "start": "1443133",
    "end": "1450400"
  },
  {
    "text": " it inserted that in front of it for us.  So now that we've extracted those entities,",
    "start": "1450400",
    "end": "1459000"
  },
  {
    "text": " we need to query our knowledge graph.  So again, I could rely on a plugin",
    "start": "1459000",
    "end": "1466233"
  },
  {
    "text": " like Langchain to try to automatically generate the query,",
    "start": "1466233",
    "end": "1472300"
  },
  {
    "text": "that I want given the scheme of my graph.  but I already know how to interact with my knowledge graph.",
    "start": "1472300",
    "end": "1478633"
  },
  {
    "text": "So what I'm gonna do is I'm gonna just template the queries that I know needs to run.  You know, I'm very familiar with the structure of my graph.",
    "start": "1478633",
    "end": "1485799"
  },
  {
    "text": "I've been using this for a while  and so I am going to generate queries and what these queries are gonna show",
    "start": "1485800",
    "end": "1491832"
  },
  {
    "text": " is they're gonna extract the connection. So the first one is gonna extract  basically everything that is within a couple of hops.",
    "start": "1491833",
    "end": "1499833"
  },
  {
    "text": " So remember we have document to event, event has a role, and the entity that filling that role.",
    "start": "1499833",
    "end": "1508099"
  },
  {
    "text": " So what we're doing is we're going backwards from the entity that was identified to the event and then finding the other entities that are associated with it.",
    "start": "1508100",
    "end": "1514231"
  },
  {
    "text": " And then we're also gonna find other events that those entities are referencing We're essentially doing a friend of a friend type query or two hop query",
    "start": "1514233",
    "end": "1521266"
  },
  {
    "text": " something you might commonly see in recommendation engines.  And if we do want to find the connections,",
    "start": "1521266",
    "end": "1527966"
  },
  {
    "text": "then we're also gonna substitute in these extra little parts that tell it to filter where the beginning and the end",
    "start": "1527966",
    "end": "1534565"
  },
  {
    "text": " or the intermediate parts. The intermediate parts are those entities that we want.",
    "start": "1534566",
    "end": "1540599"
  },
  {
    "text": " because we are looking for a specific path. ",
    "start": "1540600",
    "end": "1546132"
  },
  {
    "text": "So I've created this query, these query templates.  And now what I want to do is I want to have the Neptune dataplane",
    "start": "1546133",
    "end": "1554165"
  },
  {
    "text": " API, I'm gonna run these templated queries on the Neptune Dataplane API ",
    "start": "1554166",
    "end": "1560133"
  },
  {
    "text": "So what I'm gonna do is I'm gonna go through that list of entities that I extracted and I have some checks here to make sure that,",
    "start": "1560133",
    "end": "1567299"
  },
  {
    "text": "it's sending the proper information. It's not identified two entities in the case of a connections query.",
    "start": "1567300",
    "end": "1574133"
  },
  {
    "text": " not more, not less. So there are guardrails here.",
    "start": "1574133",
    "end": "1580100"
  },
  {
    "text": " And then what it's gonna do is it's going to go and actually  extract the facts that I told it to",
    "start": "1580100",
    "end": "1587300"
  },
  {
    "text": " and  write the queries.  So I run this  and you can see the query that was generated. That's",
    "start": "1587300",
    "end": "1595033"
  },
  {
    "text": " the query  and I'm telling it to get at most 20",
    "start": "1595033",
    "end": "1601132"
  },
  {
    "text": " facts and entities here.  And you can see the parameters that we're passing as well.",
    "start": "1601133",
    "end": "1606766"
  },
  {
    "text": "If you look at this query, you can see how it's parameterized like there, you know,  entity one text and entity one label",
    "start": "1606766",
    "end": "1613000"
  },
  {
    "text": " and down here you can see that it's the entity text  NASDAQ:AMZN, the label \"STOCK_CODE\".",
    "start": "1613000",
    "end": "1619033"
  },
  {
    "text": " And then John Mackey, who's a PERSON.  So now let's go and look at all the statements that were generated",
    "start": "1619033",
    "end": "1627800"
  },
  {
    "text": " by this. And so you can see the event type of corporate merger involving NASDAQ:AMZN in the role of participant and Whole Foods Market, Inc.",
    "start": "1627800",
    "end": "1635633"
  },
  {
    "text": "in the role of participant.  And the document that that was extracted from is this document here.",
    "start": "1635633",
    "end": "1641166"
  },
  {
    "text": "There's a corporate acquisition  there is employment",
    "start": "1641166",
    "end": "1646398"
  },
  {
    "text": " Whole Foods Market was the employer of John Mackey  and Whole Foods Market, you know, again,",
    "start": "1646400",
    "end": "1653433"
  },
  {
    "text": " employer.  and this is referenced in a couple of different documents. ",
    "start": "1653433",
    "end": "1659132"
  },
  {
    "text": "So now what we're gonna do is because we want to show what references that these were in part of, I'm gonna load the",
    "start": "1659133",
    "end": "1667199"
  },
  {
    "text": "the raw data and inside the raw data, it has the URL of the actual  ",
    "start": "1667200",
    "end": "1672633"
  },
  {
    "text": " document. So I'm gonna create this little reference table for the LLM",
    "start": "1672633",
    "end": "1679166"
  },
  {
    "text": " that is going to get  the ",
    "start": "1679166",
    "end": "1684233"
  },
  {
    "text": "actual URL of the press release that these are extracted from, so they can return references and show me where it found",
    "start": "1684233",
    "end": "1691066"
  },
  {
    "text": " the information that was  extracted. ",
    "start": "1691066",
    "end": "1699833"
  },
  {
    "text": "All right. So now let's finally pull this all together.  We are going to ask the LLM to answer the question",
    "start": "1699833",
    "end": "1707100"
  },
  {
    "text": " concerning the facts that we extracted  using the LLM in the previous call.",
    "start": "1707100",
    "end": "1712666"
  },
  {
    "text": " So our prompt here is giving very specific instructions.  You know, again, we're praising it, telling the LLM",
    "start": "1712666",
    "end": "1719266"
  },
  {
    "text": "That it is excellent at answering questions and it makes it happy to  we're giving it that list of facts and the references that we had",
    "start": "1719266",
    "end": "1726466"
  },
  {
    "text": " shared with it before.  And we're telling it we want to create a narrative paragraph,",
    "start": "1726466",
    "end": "1731898"
  },
  {
    "text": "answering the question below.  And after the narrative paragraph, we want to include the facts as a bulleted list,",
    "start": "1731900",
    "end": "1737599"
  },
  {
    "text": " but  omit all those XML tags, I just want to see the facts.  And finally, we want to list the references that it used after that list of facts.",
    "start": "1737600",
    "end": "1745766"
  },
  {
    "text": "And so again, we then template it with the question which was show me the relationships between",
    "start": "1745766",
    "end": "1752366"
  },
  {
    "text": " AMZN  and John Mackey. So I'm gonna run this guy",
    "start": "1752366",
    "end": "1758199"
  },
  {
    "text": " and  you can see first it's gonna output all the prompt that we have.",
    "start": "1758200",
    "end": "1766333"
  },
  {
    "text": " So the full prompt that ends up getting sent to the LLM is your excellent at answering questions like we saw",
    "start": "1766333",
    "end": "1771799"
  },
  {
    "text": " and then notice how it substituted in all the facts and the references that we gave it",
    "start": "1771800",
    "end": "1777366"
  },
  {
    "text": " and  it's telling it to create the narrative list.  ",
    "start": "1777366",
    "end": "1782700"
  },
  {
    "text": " And so we can see the output now, right? So here is how it answered  the facts provided indicate that Amazon acquired Whole Foods",
    "start": "1782700",
    "end": "1791166"
  },
  {
    "text": " with Whole Foods Market and its CEO John Mackey being involved in the transaction specifically and",
    "start": "1791166",
    "end": "1796466"
  },
  {
    "text": " facts show that Amazon Whole Foods were participants in a corporate merger acquisition  that John Mackey was employee of Whole Foods Market.",
    "start": "1796466",
    "end": "1803165"
  },
  {
    "text": " These connections suggest that the acquisition of Whole Foods Market by Amazon had a direct impact on John Mackey's employment status.",
    "start": "1803166",
    "end": "1808900"
  },
  {
    "text": " And we can see the facts that were used that were extracted. Remember this is these are facts that were directly from",
    "start": "1808900",
    "end": "1814399"
  },
  {
    "text": " our knowledge graph, right? And  then also the references that those facts were from.",
    "start": "1814400",
    "end": "1820600"
  },
  {
    "text": " So we reviewed how LLMs and databases interact for RAG and GraphRAG use cases.",
    "start": "1820600",
    "end": "1826565"
  },
  {
    "text": " And then we explored how you can use LLMs with your already constructed knowledge graph without having to start over.",
    "start": "1826566",
    "end": "1833300"
  },
  {
    "text": "Even if you don't have vector embeddings,  you don't even need to use a popular RAG or GraphRAG toolkit. Just the AWS SDK will do",
    "start": "1833300",
    "end": "1841599"
  },
  {
    "text": " If you have an open data set in mind you'd like to see transform to a graph model or a use case,",
    "start": "1841600",
    "end": "1848999"
  },
  {
    "text": "you'd like to see prototyped.  Please let us know in the comments in this video or reach out to me on LinkedIn",
    "start": "1849000",
    "end": "1855533"
  },
  {
    "text": " at this URL or QR code.  So again, this is Brian O'Keefe, AWS Neptune Specialist",
    "start": "1855533",
    "end": "1862532"
  },
  {
    "text": "Solutions Architect and thank you for watching. Keep on the lookout for our next episode of #GraphThat.",
    "start": "1862533",
    "end": "1867833"
  },
  {
    "text": " ",
    "start": "1867833",
    "end": "1875833"
  },
  {
    "text": " ",
    "start": "1875833",
    "end": "1883833"
  }
]
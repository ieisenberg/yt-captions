[
  {
    "text": "uh my name is Ben snively I'm a specialist essay in the public sector team uh my specialization is in big data",
    "start": "359",
    "end": "6359"
  },
  {
    "text": "and analytics uh you could kind of consider myself an opening act uh to really uh have uh Dean clus uh come up",
    "start": "6359",
    "end": "14599"
  },
  {
    "text": "here and talk a a little bit about the research that um you know uh Johns Hopkins APL did in collaboration with",
    "start": "14599",
    "end": "21720"
  },
  {
    "text": "many different universities uh they put together a really Innovative solution uh to be able to have folks collaborate and",
    "start": "21720",
    "end": "28599"
  },
  {
    "text": "analyze in the neuros science field uh so you know I'll just spend about 10 minutes talking a little bit about the",
    "start": "28599",
    "end": "34000"
  },
  {
    "text": "services they're leveraging and then he'll jump up here on stage and uh talk a little bit more in detail a little bit",
    "start": "34000",
    "end": "40239"
  },
  {
    "text": "about the lessons to learn and give a live demonstration of of some of the",
    "start": "40239",
    "end": "45280"
  },
  {
    "text": "capabilities and uh they're leveraging a lot of serverless Technologies uh within their",
    "start": "45280",
    "end": "52360"
  },
  {
    "text": "solution so when we talk about serverless uh for folks that may not be",
    "start": "58920",
    "end": "64119"
  },
  {
    "text": "familiar what serverless is really it's part of what we've seen in the cloud Evolution so if you look back uh when",
    "start": "64119",
    "end": "71400"
  },
  {
    "text": "when Cloud was started uh it really started with virtualized servers uh this was really powerful because customers",
    "start": "71400",
    "end": "77320"
  },
  {
    "text": "could spin up servers they could elastically scale servers as a unit scale them back down and do work based",
    "start": "77320",
    "end": "84640"
  },
  {
    "text": "on feedback you know we started offering managed Services uh again a very powerful concept uh and managed Services",
    "start": "84640",
    "end": "91280"
  },
  {
    "text": "really allowed customers to go higher in the stack and really focus on the application focus on optimizing datab",
    "start": "91280",
    "end": "98079"
  },
  {
    "text": "bases focused on writing Hadoop analytics uh but still even with managed",
    "start": "98079",
    "end": "104040"
  },
  {
    "text": "Services customers had to think about servers when you allocated a managed database you specified how many CPUs do",
    "start": "104040",
    "end": "110119"
  },
  {
    "text": "I want how much RAM do you want you didn't have to worry about the provisioning managing the backup High",
    "start": "110119",
    "end": "115600"
  },
  {
    "text": "availability of those services but you still thought about servers with server listed it's really a new paradigm you",
    "start": "115600",
    "end": "121200"
  },
  {
    "text": "don't have to worry about servers at all uh if you're writing code it could be inest Lo logic it could be uh ETL it",
    "start": "121200",
    "end": "128280"
  },
  {
    "text": "could be uh leveraging SQL uh but you don't really worry about servers as a unit anymore you're really writing your",
    "start": "128280",
    "end": "135080"
  },
  {
    "text": "business logic and then configuring the system to be able to horizontally",
    "start": "135080",
    "end": "140959"
  },
  {
    "text": "scale and that that gives you a couple key benefits uh the first is you don't",
    "start": "140959",
    "end": "146160"
  },
  {
    "text": "have to worry about managing servers you don't have to worry about the provisioning of actual servers the patching of servers uh the fault",
    "start": "146160",
    "end": "153560"
  },
  {
    "text": "tolerance of a single server uh the other really powerful aspect of serverless is you never pay for Idol so",
    "start": "153560",
    "end": "161000"
  },
  {
    "text": "we're going to really dive deep into Lambda some best practices of Lambda with Lambda you really pay at a subse uh",
    "start": "161000",
    "end": "168840"
  },
  {
    "text": "metering per execution time so if your your Lambda function takes 500",
    "start": "168840",
    "end": "174800"
  },
  {
    "text": "milliseconds to execute you only charge based on that time and then it's really able to Scale",
    "start": "174800",
    "end": "181959"
  },
  {
    "text": "based on your usage there's some things to be aware of in terms of limits uh some best practices that Dean's going to",
    "start": "181959",
    "end": "187879"
  },
  {
    "text": "dive into uh but really really powerful services and that really fits into a a",
    "start": "187879",
    "end": "195519"
  },
  {
    "text": "big data ecosystem so where does some of the services that you're going to hear about today fit into a common Big Data",
    "start": "195519",
    "end": "203319"
  },
  {
    "text": "pipeline so there's a wide range of different services within the AWS platform that handles things like High",
    "start": "203319",
    "end": "209760"
  },
  {
    "text": "velocity data kesa streams is a fully managed service to be able to be able to capture and allow you to process with",
    "start": "209760",
    "end": "216959"
  },
  {
    "text": "our services or open source Technologies High Velocity data coming into your system you might need to transfer very",
    "start": "216959",
    "end": "224040"
  },
  {
    "text": "large volumes of data using things like snowball and snowmobile um and and be able to once",
    "start": "224040",
    "end": "230519"
  },
  {
    "text": "you ingest that data trigger uh and bring it into your into your system so a",
    "start": "230519",
    "end": "235920"
  },
  {
    "text": "wide range of services to help with that ingest of of the data once you have that you you need to be able to store so we",
    "start": "235920",
    "end": "242640"
  },
  {
    "text": "have a suite of services to be able to help with that we're really going to talk about Dynamo DB and S3 uh today uh",
    "start": "242640",
    "end": "249599"
  },
  {
    "text": "two really great Services used together dyo DB is a nosql database and it's",
    "start": "249599",
    "end": "254720"
  },
  {
    "text": "really great to do things like create indexes and lookups and uh store key value pairs Json documents and Dynamo DB",
    "start": "254720",
    "end": "262320"
  },
  {
    "text": "and then you can have very large files in S3 that you reference from those artifacts in analyze and process uh",
    "start": "262320",
    "end": "270120"
  },
  {
    "text": "there's services like EMR elastic map ruce which is really the Hadoop ecosystem spark ecosystem as a service",
    "start": "270120",
    "end": "277720"
  },
  {
    "text": "so you can focus on writing your analytics there's things like red shift uh if you're in the session prior to",
    "start": "277720",
    "end": "283199"
  },
  {
    "text": "this uh you heard a little bit about the best practices and customer experiences with red shift a cloud uh built for the",
    "start": "283199",
    "end": "289759"
  },
  {
    "text": "cloud data warehouse that you can scale up to multiple pedabytes or scale down uh to a few hundred",
    "start": "289759",
    "end": "296240"
  },
  {
    "text": "gigs services like Athena that provides uh SE based inter uh interactive queries",
    "start": "296240",
    "end": "301840"
  },
  {
    "text": "against your data in S3 and Kinesis analytics to do real-time analytics so",
    "start": "301840",
    "end": "306919"
  },
  {
    "text": "we're really going to dive into a few services today but it fits into this bigger architecture a bigger Pipeline",
    "start": "306919",
    "end": "313320"
  },
  {
    "text": "and the nice thing about this is you can start using pieces of this when you're ready you can start with uh you know",
    "start": "313320",
    "end": "319120"
  },
  {
    "text": "bringing in a smaller amount of data start analyzing and then add real-time analytics and various uh Technologies on",
    "start": "319120",
    "end": "325039"
  },
  {
    "text": "top of it so of the folks in the room who's",
    "start": "325039",
    "end": "330919"
  },
  {
    "text": "already familiar with AWS Lambda fantastic uh so AWS Lambda allows",
    "start": "330919",
    "end": "337160"
  },
  {
    "text": "you to run code within AWS without provisioning any servers and you pay for that compute time that you're",
    "start": "337160",
    "end": "344199"
  },
  {
    "text": "consuming so as we were mentioning uh there's no servers to manage it has that",
    "start": "344199",
    "end": "349520"
  },
  {
    "text": "subc metering the way you scale your functions you allocate a certain amount",
    "start": "349520",
    "end": "354600"
  },
  {
    "text": "of memory and then the uh networking and the CPUs uh allocated to that those",
    "start": "354600",
    "end": "359680"
  },
  {
    "text": "Lambda function execution scale uh with that uh memory",
    "start": "359680",
    "end": "365240"
  },
  {
    "text": "allocation but what we found is folks that are running Lambda might start with a single function but soon they might",
    "start": "366680",
    "end": "373960"
  },
  {
    "text": "have three functions all calling each other and they need to start calling these various uh functions together and",
    "start": "373960",
    "end": "380039"
  },
  {
    "text": "then this could quickly grow uh to call multiple surfaces multiple functions all",
    "start": "380039",
    "end": "385160"
  },
  {
    "text": "together and what we find is as as bu people build uh various Solutions on AWS",
    "start": "385160",
    "end": "391560"
  },
  {
    "text": "they might have this really complex topology where each function does a unit of work it's very good at doing that",
    "start": "391560",
    "end": "397639"
  },
  {
    "text": "unit of work but they need surfaces that help choreograph this",
    "start": "397639",
    "end": "403080"
  },
  {
    "text": "orchestration so that's where AWS step functions comes in uh AWS step functions",
    "start": "403080",
    "end": "408639"
  },
  {
    "text": "allows you to uh really orchestrate multiple Lambda functions together uh you could have other types of functions",
    "start": "408639",
    "end": "414319"
  },
  {
    "text": "as well it's not solely Lambda uh but what it allows you to do is really focus",
    "start": "414319",
    "end": "420199"
  },
  {
    "text": "on your business productivity uh you could chain your services together very easily you could",
    "start": "420199",
    "end": "426039"
  },
  {
    "text": "execute Lambda functions in parallel handle uh retries very effectively uh",
    "start": "426039",
    "end": "431639"
  },
  {
    "text": "really be able to process uh a more complicated workflow uh very very powerfully within uh",
    "start": "431639",
    "end": "438599"
  },
  {
    "text": "AWS a lot of resiliency uh built into the services as well being able to handle uh various failure",
    "start": "438599",
    "end": "446720"
  },
  {
    "text": "conditions the way a step function get defined is through a Json document and",
    "start": "446720",
    "end": "452360"
  },
  {
    "text": "uh the team that's going to present here shortly have uh even improved this process even better uh and they're going",
    "start": "452360",
    "end": "458039"
  },
  {
    "text": "to talk about that uh but you have this Json definition that defines your workflow or your uh orchestration that",
    "start": "458039",
    "end": "465440"
  },
  {
    "text": "ends up being visualized in the console uh through a series of steps and then you could have many many uh executions",
    "start": "465440",
    "end": "472080"
  },
  {
    "text": "of uh essentially step functions in parallel uh this allows you to be able",
    "start": "472080",
    "end": "477199"
  },
  {
    "text": "to monitor track uh a single step function may be able to run uh for even",
    "start": "477199",
    "end": "482240"
  },
  {
    "text": "a full year so you could have very long lift step functions uh um within your",
    "start": "482240",
    "end": "489680"
  },
  {
    "text": "system and then another service want to set context around because uh Dean's going to talk about it shortly is Dynamo",
    "start": "490360",
    "end": "497039"
  },
  {
    "text": "DB Dynamo DB is our managed nosql offering and what that means is it's a",
    "start": "497039",
    "end": "503840"
  },
  {
    "text": "fully managed service that you could store key value pairs or Json documents in and within this fully managed service",
    "start": "503840",
    "end": "511560"
  },
  {
    "text": "all you have to do is specify how many reads per second you want how many writes per second you want and the the",
    "start": "511560",
    "end": "518599"
  },
  {
    "text": "system automatically will scale under the covers to be able to support that and you don't have to necessarily",
    "start": "518599",
    "end": "524600"
  },
  {
    "text": "pre-allocate how much storage you want to store in Dynamo DB you just start storing data in there start provisioning",
    "start": "524600",
    "end": "531120"
  },
  {
    "text": "how many reads and writes per second you want and the system will automatically scale for you it's very easily to start",
    "start": "531120",
    "end": "536399"
  },
  {
    "text": "small and very easy to uh do The Logical mapping of how much infrastructure I do",
    "start": "536399",
    "end": "543000"
  },
  {
    "text": "I need to reads and writes per second within dyn DB and regardless of how much",
    "start": "543000",
    "end": "548240"
  },
  {
    "text": "data you store in there it provides very reliable uh singled digigit millisecond",
    "start": "548240",
    "end": "553480"
  },
  {
    "text": "Lanes uh we use it uh very very heavily uh you know and our customers use it",
    "start": "553480",
    "end": "559079"
  },
  {
    "text": "very heavily within AWS so you know mentioned it's fully uh",
    "start": "559079",
    "end": "566720"
  },
  {
    "text": "fully managed no SQL uh you can store Json documents in there as well so it's",
    "start": "566720",
    "end": "572519"
  },
  {
    "text": "not only key value storage but it stores Json as well and really fits into wide",
    "start": "572519",
    "end": "577720"
  },
  {
    "text": "number of use cases including research uh research use cases and very very fast",
    "start": "577720",
    "end": "583279"
  },
  {
    "text": "cons consistent um like all of our AWS Services it's wrapped with an I am you",
    "start": "583279",
    "end": "589079"
  },
  {
    "text": "have to when you're executing uh Dynamo DB and in calling getting operations it",
    "start": "589079",
    "end": "594959"
  },
  {
    "text": "has to be validated through I am credentials uh and it has something called Dynamo DB streams uh with Dynamo",
    "start": "594959",
    "end": "602120"
  },
  {
    "text": "DB streams you could actually set up a set of event triggers based on anytime",
    "start": "602120",
    "end": "607519"
  },
  {
    "text": "new data gets stored data changes uh you know data gets deleted within your no",
    "start": "607519",
    "end": "612920"
  },
  {
    "text": "SQL database so I know that was just a very very quick uh primer in terms of some of",
    "start": "612920",
    "end": "619440"
  },
  {
    "text": "the services you're going to hear about but we wanted to set that stage uh before Dean uh uh really took over so on",
    "start": "619440",
    "end": "625920"
  },
  {
    "text": "that note um you want to welcome Dean to the stage here [Applause]",
    "start": "625920",
    "end": "634040"
  },
  {
    "text": "hi um so I'm Dean clis I'm a research engineer at the Johns Hopkins University applies Physics laboratory and today I'm",
    "start": "634040",
    "end": "640399"
  },
  {
    "text": "going to tell you a little bit about a field we've been in for about the past six years called high resolution",
    "start": "640399",
    "end": "645440"
  },
  {
    "text": "connectomic that's grown a little bit and a program we've been supporting um yeah oh this is working right program",
    "start": "645440",
    "end": "652240"
  },
  {
    "text": "we've been supporting for the past two um the program is called irpa microns it's created and funded by the",
    "start": "652240",
    "end": "659120"
  },
  {
    "text": "intelligence Advanced research projects activity and the program stands for machine intelligence from cortical networks um and this is a very large",
    "start": "659120",
    "end": "665760"
  },
  {
    "text": "multi-discipline discipline program it's part of the brain initiative it's one of the largest projects in the brain initiative right now and it seeks to",
    "start": "665760",
    "end": "672880"
  },
  {
    "text": "revolutionize machine learning by trying to understand the representations Transformations and learning roles uh",
    "start": "672880",
    "end": "679320"
  },
  {
    "text": "that are employed by the brain in in in learning and um it was kind of interesting in",
    "start": "679320",
    "end": "686079"
  },
  {
    "text": "that um kind of everybody in this program don't do that everyone in this program kind of is under the assumption",
    "start": "686079",
    "end": "692200"
  },
  {
    "text": "that possibly with a better understanding of the brain we can further constrain machine learning models Advance AI forward and it's kind",
    "start": "692200",
    "end": "699200"
  },
  {
    "text": "of reached the point in time where uh they needed this engineering support you had to scale things up and this program",
    "start": "699200",
    "end": "704720"
  },
  {
    "text": "was designed to be this dialogue between computer science data science and the biologists and neuroscientists and so the way it's set",
    "start": "704720",
    "end": "711519"
  },
  {
    "text": "up is you start in phase one which we just completed um like this week um",
    "start": "711519",
    "end": "716639"
  },
  {
    "text": "where you know teams came up with some nurly plot aible machine learning framework framework largely based on",
    "start": "716639",
    "end": "721760"
  },
  {
    "text": "literature some Behavior Experiment they did lots of functional Imaging structural Imaging data analysis and",
    "start": "721760",
    "end": "727200"
  },
  {
    "text": "then we iterate and now we scale up a thousand times and we'll go in detail a little bit about what that means we go through this whole process again over",
    "start": "727200",
    "end": "733279"
  },
  {
    "text": "the next two years where we generate um around 6 to 10 pedabytes of data of raw data that's need to be analyzed and",
    "start": "733279",
    "end": "739320"
  },
  {
    "text": "that's kind of what we're we're here to talk about now is how do we deal with that um",
    "start": "739320",
    "end": "745639"
  },
  {
    "text": "so right so why is this so exciting um why why do",
    "start": "745639",
    "end": "751519"
  },
  {
    "text": "we think this is different from previous efforts you know the neural networks are huge now in machine learning um but and",
    "start": "751519",
    "end": "757680"
  },
  {
    "text": "they're maybe nurly inspired but they're not necessar necessarily considered biopedic or nurly plausible and there",
    "start": "757680",
    "end": "763240"
  },
  {
    "text": "are other projects that have um come before this where people have tried to model the brain a little bit to come up with better ways to build machine",
    "start": "763240",
    "end": "769279"
  },
  {
    "text": "learning algorithms um but those are largely focused on macro and micro information or lower Fidelity",
    "start": "769279",
    "end": "775040"
  },
  {
    "text": "statistical summaries of how the brain operates and that's mainly because that's all we really could know um when",
    "start": "775040",
    "end": "780079"
  },
  {
    "text": "I say micro we're like one to 100 neurons and how they work and macro is how do entire brain regions work so the",
    "start": "780079",
    "end": "787000"
  },
  {
    "text": "macro scale we're talking about like MRI imaging and very high res um very low resolution zoomed out picture of how the",
    "start": "787000",
    "end": "792320"
  },
  {
    "text": "brain works and for the first time you know this field is able to interrogate what we call the Miso scale which is a",
    "start": "792320",
    "end": "798560"
  },
  {
    "text": "thousand to a million neurons and how are these things wired together and and firing um and so this program is unique",
    "start": "798560",
    "end": "806680"
  },
  {
    "text": "in that we're going after this miso scale for the first time at the scale and doing it both with structure and function and co-registering these data",
    "start": "806680",
    "end": "813199"
  },
  {
    "text": "together to have an understanding of how these compute circuits are kind of under learning under underpinning learning um",
    "start": "813199",
    "end": "819360"
  },
  {
    "text": "in a brain and so um give you a quick overview of some of the things we're",
    "start": "819360",
    "end": "825040"
  },
  {
    "text": "talking about so some of these terms make a little bit more sense um when I say functional Imaging I'm talking about",
    "start": "825040",
    "end": "831079"
  },
  {
    "text": "measuring how neurons are firing and an alive behaving animal in 3D so what",
    "start": "831079",
    "end": "836199"
  },
  {
    "text": "you're going to see here is a video uh taken um at Labs at Cornell and Baylor where",
    "start": "836199",
    "end": "842920"
  },
  {
    "text": "we're actually moving through in sections through 800 microns of of Cortex in a mouse you can see these",
    "start": "842920",
    "end": "849160"
  },
  {
    "text": "slices lay out and then in the second you're going see this thing animate and what you're seeing in green are actually",
    "start": "849160",
    "end": "854279"
  },
  {
    "text": "um neurons firing these are um genetically modified neurons that are",
    "start": "854279",
    "end": "860320"
  },
  {
    "text": "producing a marker that fluoresces when that neuron fires is getting picked up with this really fancy microscope called",
    "start": "860320",
    "end": "865600"
  },
  {
    "text": "a three Photon microscope that's a would actually image through the scattering medium of the brain and can record",
    "start": "865600",
    "end": "871759"
  },
  {
    "text": "individual neurons firing um volumetrically and we're going to be doing this over a cubic millimeter which",
    "start": "871759",
    "end": "877680"
  },
  {
    "text": "is surprisingly huge and so when I say cubic millimeter this is important because this is where people think um",
    "start": "877680",
    "end": "883959"
  },
  {
    "text": "kind of the fundamental unit of computing lies is at this scale but the challenge is a cubic millimeter has",
    "start": "883959",
    "end": "889759"
  },
  {
    "text": "about 50 to 100,000 neurons maybe 100 million synapses and uh for the",
    "start": "889759",
    "end": "895160"
  },
  {
    "text": "structural Imaging data set which we're going to talk about here is going to be two to 2 and half paby so a single image",
    "start": "895160",
    "end": "900320"
  },
  {
    "text": "threedimensional image is two to 2 and half petabytes we have to not only store this we have to analyze it put it all",
    "start": "900320",
    "end": "905920"
  },
  {
    "text": "together so three Tech three techniques are used in this program scan electron microscopy uh transmission electron",
    "start": "905920",
    "end": "911880"
  },
  {
    "text": "microscopy and this really interesting genetic method called physique which we're not really going to go into um but",
    "start": "911880",
    "end": "918240"
  },
  {
    "text": "mainly we we're going to focus on electron microscopy because that's where the Big Challenge on data storage and Analysis lies um so as I play this video",
    "start": "918240",
    "end": "924519"
  },
  {
    "text": "what you're going to see is it's a very small chunk of tissue but when I say threedimensional it you can see this 3D Volume and if you",
    "start": "924519",
    "end": "930519"
  },
  {
    "text": "watch this kind of paint by numbers as each slice goes away you're looking at a little piece of a neuron and as we blow",
    "start": "930519",
    "end": "936680"
  },
  {
    "text": "this whole stack away you can see you actually can reconstruct the entire morphology of that neuron and I can actually zoom in the resolution is so",
    "start": "936680",
    "end": "943360"
  },
  {
    "text": "high that we can see in an individual synapse so this is where two neurons connect so this is what we're trying to understand how does Neuron a connect a",
    "start": "943360",
    "end": "949560"
  },
  {
    "text": "neuron B and the way this is done um is researchers use literally a Diamond",
    "start": "949560",
    "end": "954920"
  },
  {
    "text": "Knife so it's a little piece of diamond that they sharpen down to like an atom f thick and they're slicing off a 30 NM",
    "start": "954920",
    "end": "961959"
  },
  {
    "text": "section of brain and it's floating here on the surface tension of a boat of water getting picked up by some tape and",
    "start": "961959",
    "end": "967800"
  },
  {
    "text": "that's how we get to our 4x4 by 30 NM resolution um and we can zoom in here and this gives you a feel of how rich",
    "start": "967800",
    "end": "974560"
  },
  {
    "text": "and detailed these data are each one of those circles is a cell body as we keep going in we finally arrive at a synapse",
    "start": "974560",
    "end": "980800"
  },
  {
    "text": "and so we're going to see some more of this later as we go but kind of the high takeaway is that uh because we need this",
    "start": "980800",
    "end": "987800"
  },
  {
    "text": "high resolution IM to be able to see these individual synapses but also image a cubic millimeter we end up with these",
    "start": "987800",
    "end": "993720"
  },
  {
    "text": "enormous data sets and the final challenge that's unique to this program is we're doing at scale co-registration",
    "start": "993720",
    "end": "999279"
  },
  {
    "text": "and that's key because it lets researchers kind of pause it an experiment know the input somewhat know",
    "start": "999279",
    "end": "1005560"
  },
  {
    "text": "the output somewhat get the connecto which is the circuit diagram and get the neural activity which is um you know the",
    "start": "1005560",
    "end": "1011800"
  },
  {
    "text": "voltages or how these things are firing and you can imagine that would help you maybe reverse engineer a little bit or",
    "start": "1011800",
    "end": "1018120"
  },
  {
    "text": "understand better what's going on and so this is a video of um x-ray tomography of a of a sample that shows that we can",
    "start": "1018120",
    "end": "1024038"
  },
  {
    "text": "these researchers are able to align the functional Imaging which is showed in red there that's blood vessels that have",
    "start": "1024039",
    "end": "1029640"
  },
  {
    "text": "been dyed with the structural Imaging so we can actually now in the same sample in the same animal understand how the",
    "start": "1029640",
    "end": "1036760"
  },
  {
    "text": "neurons are firing and how they're connected and so we this program is running now Full",
    "start": "1036760",
    "end": "1043720"
  },
  {
    "text": "Speed Ahead we think we can do this because of the new Imaging techniques that let these teams in arrogate um",
    "start": "1043720",
    "end": "1049799"
  },
  {
    "text": "these miso scale circuits we've got the increase in computing power that's going to allow for automated analysis using",
    "start": "1049799",
    "end": "1054880"
  },
  {
    "text": "machine learning one of the big challenges if I even if I could collect two pedabytes of image data we can't",
    "start": "1054880",
    "end": "1060240"
  },
  {
    "text": "have humans go through and analyze that um you know we've just had an army of undergrads uh for the past couple weeks",
    "start": "1060240",
    "end": "1066640"
  },
  {
    "text": "manually annotating data to help um evaluate the accuracy of some of these algorithms and we can only do this tiny",
    "start": "1066640",
    "end": "1072520"
  },
  {
    "text": "sub sample of the data with a million people working on it right and so you need the computing power and that's here",
    "start": "1072520",
    "end": "1078159"
  },
  {
    "text": "now and reduce storage cost is critical these data sets are huge and finally what's also important to this cl to this",
    "start": "1078159",
    "end": "1083679"
  },
  {
    "text": "um project is the collaborative nature we've got lots of universities um we'll show them at the end working on this",
    "start": "1083679",
    "end": "1088880"
  },
  {
    "text": "they need to share they need to collaborate um and so we're using the cloud to help facilitate that and",
    "start": "1088880",
    "end": "1095280"
  },
  {
    "text": "so um the main part of this talk I want to get to now is talking about this system we've built at the Applied",
    "start": "1095280",
    "end": "1101640"
  },
  {
    "text": "Physics lab um called we call it the boss it very very Loosely stands for block and object storage service because",
    "start": "1101640",
    "end": "1108640"
  },
  {
    "text": "everything has to have an acronym even though I'm like strictly against acronyms so that's why we like lowercase it um but the boss is a",
    "start": "1108640",
    "end": "1115520"
  },
  {
    "text": "multi-dimensional spatial database that we provide as a managed service on AWS and so when I say multi-dimensional we",
    "start": "1115520",
    "end": "1121960"
  },
  {
    "text": "are able to store these 3D multi- channel Time series data sets uh in a",
    "start": "1121960",
    "end": "1127120"
  },
  {
    "text": "way that's both cost efficient and performant for the users and what ends up happening and we'll go into much more",
    "start": "1127120",
    "end": "1133280"
  },
  {
    "text": "detail on this is there's some microscope at some lab um they generate a bunch of image dat data and those",
    "start": "1133280",
    "end": "1139000"
  },
  {
    "text": "images are going to be traditional image files tiffs pings they're going to be a stack on some file system um they do a",
    "start": "1139000",
    "end": "1145640"
  },
  {
    "text": "bunch of complex registration to build this 3D Volume but it's still these flat files which are very inefficient to do",
    "start": "1145640",
    "end": "1151480"
  },
  {
    "text": "any sort of arbitrary access to and so what we do is we ingest these Tiff or",
    "start": "1151480",
    "end": "1156640"
  },
  {
    "text": "ping Stacks into small cubes we call them cuboids um and kind of to um what",
    "start": "1156640",
    "end": "1162600"
  },
  {
    "text": "was alluded earlier is we store those cubes in S3 CU S3 is really great for storing large objects um and we",
    "start": "1162600",
    "end": "1168840"
  },
  {
    "text": "spatially index these cubes and write that index in Dynamo DB and that's kind of like the main core of our entire",
    "start": "1168840",
    "end": "1174159"
  },
  {
    "text": "system it lets us do arbitrary access to um you know arbitrary spatial cutouts of these large 3D uh time series data sets",
    "start": "1174159",
    "end": "1182120"
  },
  {
    "text": "and the other big feature with the boss is that we we can store um annotations that are on the same data",
    "start": "1182120",
    "end": "1189200"
  },
  {
    "text": "and so when we say an annotation uh that mean all that is is just a unique 64-bit identifier that we can assign to any",
    "start": "1189200",
    "end": "1195640"
  },
  {
    "text": "voxel and and a voxel is like a a 3 dimensional pixel we say voxel volumetric pixel um and so we can assign",
    "start": "1195640",
    "end": "1203360"
  },
  {
    "text": "these voxels unique identifiers and these then represent some object in the",
    "start": "1203360",
    "end": "1208679"
  },
  {
    "text": "data that can have some meaning to the user that they use some computer vision algorithm to label membranes or to label",
    "start": "1208679",
    "end": "1214440"
  },
  {
    "text": "cells or synapses and they can build up these graphs of you know neuron 1000 Links of neuron 2000 through synapse 40",
    "start": "1214440",
    "end": "1221679"
  },
  {
    "text": "and you're able to build up um these rich graphs and and and uh kind of like a semantic understanding of these images",
    "start": "1221679",
    "end": "1227880"
  },
  {
    "text": "uh and store it all in this Central system so we're not going to get into",
    "start": "1227880",
    "end": "1233000"
  },
  {
    "text": "this too much cuz like Ben said we really want to talk about serverless stuff in this section but kind of just to orient you a little bit um this is",
    "start": "1233000",
    "end": "1239760"
  },
  {
    "text": "the high level architecture of the boss uh we spin this whole thing up in its own VP VPC and we've wrode a bunch of",
    "start": "1239760",
    "end": "1246400"
  },
  {
    "text": "our own automation on top of Packer salt and cloud formation to do this for the",
    "start": "1246400",
    "end": "1252320"
  },
  {
    "text": "user so as a developer we can run a single command spin up an entire stack that's much smaller than our integration",
    "start": "1252320",
    "end": "1257520"
  },
  {
    "text": "stack or production stack um we run our own single sign on service just because",
    "start": "1257520",
    "end": "1263080"
  },
  {
    "text": "uh we need to stay kind of Open Source and non-commercial and it lets users build 30 party third party apps that",
    "start": "1263080",
    "end": "1269280"
  },
  {
    "text": "plug in so we'll show see one at the end which is actually a visualization tool that was originally developed by researchers at Google that we now run on",
    "start": "1269280",
    "end": "1276000"
  },
  {
    "text": "top of this to do uh 3D Vis of the data um right in your browser that all integrates with our single sign on",
    "start": "1276000",
    "end": "1282200"
  },
  {
    "text": "server we've use vault which is a product from hashy Corp to do our secret store we also rent uh generate temporary",
    "start": "1282200",
    "end": "1288120"
  },
  {
    "text": "AWS credentials out of there and do some other little things um and then on the left is like the main core boss boss",
    "start": "1288120",
    "end": "1294120"
  },
  {
    "text": "architecture where we've got a fleet of autoscaling API servers that sit on top of a big reddis in memory cache caching",
    "start": "1294120",
    "end": "1302039"
  },
  {
    "text": "layer that then sits on top of S3 and we use lamb that a shuttle data between the two in parallel um do pagin do",
    "start": "1302039",
    "end": "1309000"
  },
  {
    "text": "pre-etching and whatnot um that's kind of how we can balance for certain workloads access performance for the",
    "start": "1309000",
    "end": "1316120"
  },
  {
    "text": "user with you know massive and Affordable Storage uh you know S3 is kind of the best place for us to put",
    "start": "1316120",
    "end": "1322080"
  },
  {
    "text": "these large data sets um we're starting to look into some more interesting things about actually instrumenting what's being used and starting playing",
    "start": "1322080",
    "end": "1328039"
  },
  {
    "text": "games with like infrequent access and Glacier and whatnot for some of these data sets to really push our costs down",
    "start": "1328039",
    "end": "1333440"
  },
  {
    "text": "uh in the long term um and I mentioned uh there's there's an API so the way",
    "start": "1333440",
    "end": "1339120"
  },
  {
    "text": "that users interact with the boss is through this a pretty rich API and again we're not going to really get into much",
    "start": "1339120",
    "end": "1345000"
  },
  {
    "text": "of this but the idea is you you know there's like a management layer where we can create users and groups and we have",
    "start": "1345000",
    "end": "1350520"
  },
  {
    "text": "this abstraction on how we organize data um so you can create um essentially Collections and experiments and channels",
    "start": "1350520",
    "end": "1357840"
  },
  {
    "text": "um apply permissions so you can share your data you can work uh privately if you want for a little bit share it with",
    "start": "1357840",
    "end": "1363080"
  },
  {
    "text": "your collaborators make it publicly accessible we can store experimental data uh metadata as key value Pairs and",
    "start": "1363080",
    "end": "1368960"
  },
  {
    "text": "anything in the in the the in the system and then you've got your core data access Services where we have this",
    "start": "1368960",
    "end": "1374640"
  },
  {
    "text": "cutout service it's kind of like the main volum metric I can ask for any arbitrary region in this two petabyte",
    "start": "1374640",
    "end": "1379960"
  },
  {
    "text": "data set and get it packed pretty quickly um object services that let us do things uh we not only spatially index",
    "start": "1379960",
    "end": "1386320"
  },
  {
    "text": "the images but we spatially index our annotation so you can say give me all of the objects in some spatial region",
    "start": "1386320",
    "end": "1393200"
  },
  {
    "text": "what's the bounding box of this object which is actually surprisingly useful when these things get massive um a single neuron can span um terabytes of",
    "start": "1393200",
    "end": "1401240"
  },
  {
    "text": "image data and so how do they know where that thing is in this petabyte data set it's quite challenging actually uh we",
    "start": "1401240",
    "end": "1407200"
  },
  {
    "text": "have a t tile service that renders images um and then a down sample service and an injest service and so these are",
    "start": "1407200",
    "end": "1413760"
  },
  {
    "text": "two that we're going to kind of dig into a little bit today um a down sample",
    "start": "1413760",
    "end": "1419039"
  },
  {
    "text": "service we use to create a resolution hierarchy that allows us to browse the data a little bit better because when",
    "start": "1419039",
    "end": "1424360"
  },
  {
    "text": "these data are super highr and huge it's very challenging to and unwieldy to manage them um and then an injest",
    "start": "1424360",
    "end": "1430840"
  },
  {
    "text": "service is how we get data from that microscope at some University into the cloud and into the boss and both these",
    "start": "1430840",
    "end": "1438320"
  },
  {
    "text": "these uh workflows sit heavily on serverless components and so we're going to get into that now in some",
    "start": "1438320",
    "end": "1444799"
  },
  {
    "text": "detail um so we use serverless stuff in the boss pretty heavily we use Dynamo",
    "start": "1444799",
    "end": "1450720"
  },
  {
    "text": "Lambda sqs step functions and S3 all for various pieces that are kind of listed down here um like Ben alluded to we use",
    "start": "1450720",
    "end": "1458679"
  },
  {
    "text": "Dynamo for all of our key value pair storage all of our indexing we like it cuz it's fast um you you get consistent",
    "start": "1458679",
    "end": "1466520"
  },
  {
    "text": "uh response times it scales really nicely um and uh that's kind of how we use that",
    "start": "1466520",
    "end": "1473240"
  },
  {
    "text": "to store up all our indexes whereas you know we use S3 to store all of our big things our image tiles our cubes uh we",
    "start": "1473240",
    "end": "1479000"
  },
  {
    "text": "statically host some things out of S3 in cloudfront um and like I said we use uh Lambda a",
    "start": "1479000",
    "end": "1486240"
  },
  {
    "text": "lot as well so we're going to talk in pretty heavily about how we use Lambda for down sampling and ingest um but we",
    "start": "1486240",
    "end": "1492360"
  },
  {
    "text": "also use it to do big parallel paging operations we want to move a bunch of data from S3 into our cach or we want to",
    "start": "1492360",
    "end": "1498600"
  },
  {
    "text": "move a big right into S3 we want to automatically update some DNS stuff so we do some other things with Lambda and",
    "start": "1498600",
    "end": "1505799"
  },
  {
    "text": "I want to make a quick aside on step functions before we go forward um because when step functions got",
    "start": "1505799",
    "end": "1511960"
  },
  {
    "text": "announced at reinvent um we were pretty excited because we kind of had already built some of these similar",
    "start": "1511960",
    "end": "1517520"
  },
  {
    "text": "functionality that step functions give you ourselves you know one of our big things is especially with like a right",
    "start": "1517520",
    "end": "1523159"
  },
  {
    "text": "operation and if we're going to use Lambda in a right operation um you know that user and we do this as an",
    "start": "1523159",
    "end": "1528520"
  },
  {
    "text": "asynchronous eventually consistent thing we told that user we accepted that right so we cannot fail that right now and so",
    "start": "1528520",
    "end": "1535360"
  },
  {
    "text": "um we use we're using sqs and dead letter q's and a bunch of other stuff and a bunch of logic we were maintaining",
    "start": "1535360",
    "end": "1541640"
  },
  {
    "text": "ourselves to make sure that if we took a right and use Lambda to put it down in S3 we were guaranteeing that that was",
    "start": "1541640",
    "end": "1547240"
  },
  {
    "text": "going to occur without uh without getting lost and that's kind of one of the benefits of Step functions is it",
    "start": "1547240",
    "end": "1552760"
  },
  {
    "text": "bakes in Lambda retry Lambda back off and all these types of things for you without having to manage that yourself",
    "start": "1552760",
    "end": "1558360"
  },
  {
    "text": "and build that spin up a que and spin up your Lambda function and hook them all together and get your dead letter q and",
    "start": "1558360",
    "end": "1563720"
  },
  {
    "text": "all of that yourself um and so while we started using step functions uh found uh",
    "start": "1563720",
    "end": "1569919"
  },
  {
    "text": "there's this state machine language you use to define your step function uh well we found it super flexible we also found",
    "start": "1569919",
    "end": "1575720"
  },
  {
    "text": "it kind of hard to write and maintain it can get really long and complicated and so what we ended up writing is this",
    "start": "1575720",
    "end": "1581200"
  },
  {
    "text": "python Library we call it heavy side and it's a package that provides a couple different components to make using step",
    "start": "1581200",
    "end": "1587279"
  },
  {
    "text": "function easier the first is a domain specific language um and compiler so",
    "start": "1587279",
    "end": "1593200"
  },
  {
    "text": "it's a pretty simple short scripting language that lets you define what you want your step function to do um and it",
    "start": "1593200",
    "end": "1599559"
  },
  {
    "text": "actually runs through a full compiler that then generates the proper Json spec um and verifies it that it's correct um",
    "start": "1599559",
    "end": "1607039"
  },
  {
    "text": "and it makes it a lot easier to maintain your step functions uh we also created a library for um creating and executing",
    "start": "1607039",
    "end": "1614360"
  },
  {
    "text": "step functions in Amazon so this will send it up and configure things for you kick things off monitor them get status",
    "start": "1614360",
    "end": "1620720"
  },
  {
    "text": "and finally a framework for running activities if you want to run an activity server locally uh an easy framework that lets you just spin it up",
    "start": "1620720",
    "end": "1626919"
  },
  {
    "text": "on on an ec2 instance and go um and this is all open source available in our organization it's a JHU ap- boss all of",
    "start": "1626919",
    "end": "1634720"
  },
  {
    "text": "our code will be there I'll put it up at the end as well um so just to give you a feel of what this means uh might be hard",
    "start": "1634720",
    "end": "1640320"
  },
  {
    "text": "to see from the back especially the middle column but at the far right is uh our delete workflow so",
    "start": "1640320",
    "end": "1648000"
  },
  {
    "text": "this is we have kind of a complicated delete because we've got a bunch of foreign key constraints and potentially we have to delete terabytes or hundreds",
    "start": "1648000",
    "end": "1653960"
  },
  {
    "text": "of terabytes of data so we have to do this we actually fan it out over Lambda um and so on the right is the actual",
    "start": "1653960",
    "end": "1660679"
  },
  {
    "text": "step function workflow State machine that uh this executes on the left is the",
    "start": "1660679",
    "end": "1666399"
  },
  {
    "text": "heavy side script and if you look at it um might be hard to see but it's actually predominantly comments uh the",
    "start": "1666399",
    "end": "1672840"
  },
  {
    "text": "actual lines of code are pretty simple where you're just saying you know a directive kind of like run these things in parallel run this step function run",
    "start": "1672840",
    "end": "1679679"
  },
  {
    "text": "this activity run this Lambda function do this retry there's a catch statement if that catch happens do this and that",
    "start": "1679679",
    "end": "1686159"
  },
  {
    "text": "actually renders that Json for you um which we found to be uh really useful and U makes maintain",
    "start": "1686159",
    "end": "1693320"
  },
  {
    "text": "these things a lot easier and so let's go into a little bit of actually using these these tools into a real use case",
    "start": "1693320",
    "end": "1700799"
  },
  {
    "text": "in our system that's really simple to start and we'll do something a little bit more complex so the easy thing to think about is down sample so for here",
    "start": "1700799",
    "end": "1707200"
  },
  {
    "text": "we have have a native resolution data set that's been loaded into our platform we need to down sample it build like a",
    "start": "1707200",
    "end": "1712559"
  },
  {
    "text": "resolution hierarchy kind of like when you zoom out in Google Maps you get more details you zoom in less details you",
    "start": "1712559",
    "end": "1718000"
  },
  {
    "text": "zoom out um so we want to be able to like render that on demand and the challenge is like I just said we have we",
    "start": "1718000",
    "end": "1723320"
  },
  {
    "text": "have to do that on demand we don't know when a user is going to want to do this um and we need to scale this from gigabytes to to pedabytes of data so we",
    "start": "1723320",
    "end": "1730120"
  },
  {
    "text": "don't want to keep a huge cluster running or keep resources going um for no reason we need to be able to scale",
    "start": "1730120",
    "end": "1735919"
  },
  {
    "text": "really well uh when a user does click down sample and so what we did did is we",
    "start": "1735919",
    "end": "1741240"
  },
  {
    "text": "built uh a little workflow that uses a step function to ma manage failures and to do this iterative down sampling",
    "start": "1741240",
    "end": "1747159"
  },
  {
    "text": "process and drive the down sampling process and then we just fan proc the image processing out over over Lambda",
    "start": "1747159",
    "end": "1754760"
  },
  {
    "text": "um and so I'm just going to stop using this so what this kind of looks like in the end is um and what this kind of",
    "start": "1754760",
    "end": "1762480"
  },
  {
    "text": "shows you is this relative scale what we're doing on the left is a 1,000 by 1,000 pixel tile and it gets down",
    "start": "1762480",
    "end": "1768360"
  },
  {
    "text": "sampled all the way down to that last spec at the end there and so you know your native data set might be two",
    "start": "1768360",
    "end": "1773679"
  },
  {
    "text": "pedabytes and we kind of itely scale down and we store each um each version",
    "start": "1773679",
    "end": "1778960"
  },
  {
    "text": "of the data set as we go down excuse",
    "start": "1778960",
    "end": "1784278"
  },
  {
    "text": "me so at a high level what we're doing is the user requests that our a to our",
    "start": "1785000",
    "end": "1790679"
  },
  {
    "text": "API says down sample this data set and what's kind of nice is after that part our API the thing we have to manage",
    "start": "1790679",
    "end": "1797279"
  },
  {
    "text": "manes out of the loop and it just kicks off this process completely on Amazon infrastructure so it starts a step",
    "start": "1797279",
    "end": "1804159"
  },
  {
    "text": "function that um will then query the index table that tells us what data we",
    "start": "1804159",
    "end": "1810120"
  },
  {
    "text": "have figure out what cubes need to be what our cubes are present which ones can be downsampled in this large spatial",
    "start": "1810120",
    "end": "1816840"
  },
  {
    "text": "volume and um kicks off Lambda functions those Lambda functions then actually",
    "start": "1816840",
    "end": "1822360"
  },
  {
    "text": "independently will go read the set of data out that need it needs to do some image processing that data will come",
    "start": "1822360",
    "end": "1827840"
  },
  {
    "text": "down in these Lambda functions we'll do a down sample operation so we'll take for example four cubes turn it into one",
    "start": "1827840",
    "end": "1833760"
  },
  {
    "text": "Cube write those cubes back to that same bucket and update our index table and",
    "start": "1833760",
    "end": "1839000"
  },
  {
    "text": "this happens massively parallel we fan this out big over over Lambda Let's us do this do this uh quickly and reliably",
    "start": "1839000",
    "end": "1847840"
  },
  {
    "text": "so it's kind of like a very easy obvious way that we can use Lambda and step functions to get reliable uh and and",
    "start": "1847840",
    "end": "1854880"
  },
  {
    "text": "kind of distributed image processing in our system uh but now let's talk a little bit something a little bit more complicated",
    "start": "1854880",
    "end": "1860240"
  },
  {
    "text": "about ingest which is um kind of a technically challenging thing for us",
    "start": "1860240",
    "end": "1865279"
  },
  {
    "text": "because we need to be able to move large amounts of data from on-prem that can be stored in all sorts of different ways",
    "start": "1865279",
    "end": "1873000"
  },
  {
    "text": "and into the boss and we need to deal with different network architecture infrastructure that's available all kinds of different problems um and again",
    "start": "1873000",
    "end": "1880240"
  },
  {
    "text": "this is run on Demand by users so a user can just decide in the middle of the night which has happened many times that",
    "start": "1880240",
    "end": "1885880"
  },
  {
    "text": "they want to just send us you know 10 terabytes of data and just start sending it right and so we need to be able to",
    "start": "1885880",
    "end": "1892080"
  },
  {
    "text": "automatically on demand scale out from gigabytes and eventually in this next phase the pedabytes when we're we're",
    "start": "1892080",
    "end": "1897960"
  },
  {
    "text": "anticipating just to be catching data for months at a time um and what we ended up doing was building this uh",
    "start": "1897960",
    "end": "1905000"
  },
  {
    "text": "scalable injust Pipeline and processing Pipeline on top of sqs S3 Lambda and",
    "start": "1905000",
    "end": "1911480"
  },
  {
    "text": "Dynamo DB and again the benefits here for us is we don't actually need to keep anything up for this workflow to run it",
    "start": "1911480",
    "end": "1916760"
  },
  {
    "text": "can been up on demand when people need to need to use it and and we can massively scale we've been doing some",
    "start": "1916760",
    "end": "1921960"
  },
  {
    "text": "pretty good testing um and scale testing with Amazon's help uh at times um so",
    "start": "1921960",
    "end": "1927880"
  },
  {
    "text": "kind of to step you through this because it can be there's some some some moving Parts um the way this works is we also",
    "start": "1927880",
    "end": "1935559"
  },
  {
    "text": "have written an injest client for users to to to use it's pretty simple little python application um it can run",
    "start": "1935559",
    "end": "1942159"
  },
  {
    "text": "distributed it can run multi-threaded um practically what it's doing is it's finding a file opening it and sending it",
    "start": "1942159",
    "end": "1948480"
  },
  {
    "text": "up to S3 um and so the way this thing works is the user we have this really",
    "start": "1948480",
    "end": "1954000"
  },
  {
    "text": "simple Json definition they they write up that says uh you know this is the data set I want to load I want to put it",
    "start": "1954000",
    "end": "1960720"
  },
  {
    "text": "here um I want this spatial region and they send it up to the boss API we read",
    "start": "1960720",
    "end": "1966480"
  },
  {
    "text": "that in verify it's correct and we provision some temporary resources and one of those things being an upload task",
    "start": "1966480",
    "end": "1972600"
  },
  {
    "text": "Q so we create a new sqsq for this job that's going to hold all these tasks to",
    "start": "1972600",
    "end": "1977639"
  },
  {
    "text": "upload files and so for us each task is a file that needs to get sent up to to us to",
    "start": "1977639",
    "end": "1984440"
  },
  {
    "text": "injest um we then kick off a step function and that step function populates this upload task you one of",
    "start": "1984440",
    "end": "1991240"
  },
  {
    "text": "the interesting things with sqs is that it it scales out really well and it'll handle really high throughput of both",
    "start": "1991240",
    "end": "1996559"
  },
  {
    "text": "reading and writing messages but it's single threaded or single worker very limiting you can only put 15 messages in",
    "start": "1996559",
    "end": "2003480"
  },
  {
    "text": "a single post and it's not that fast and so uh we have an injust job that has six",
    "start": "2003480",
    "end": "2010360"
  },
  {
    "text": "million files that needs to get written into our system it can take hours to populate that queue from a single worker",
    "start": "2010360",
    "end": "2016799"
  },
  {
    "text": "and so what we do is we use a step function it's pretty simple that's kind of shown here that fans out populating",
    "start": "2016799",
    "end": "2022600"
  },
  {
    "text": "the queue over Lambda so we can do it much faster and sqs will scale out and happily take all those messages very",
    "start": "2022600",
    "end": "2027679"
  },
  {
    "text": "fast um with these parallel workers and we can use step functions to kind of verify that it worked so the step",
    "start": "2027679",
    "end": "2033039"
  },
  {
    "text": "functions make sure none of the lambas fail if they do they retry it then Waits a couple minutes minutes to make sure everything's consistent and then it",
    "start": "2033039",
    "end": "2038960"
  },
  {
    "text": "verifies that the Q is Happy before moving on and then once we do that we now have an sqsq that has a message in",
    "start": "2038960",
    "end": "2045679"
  },
  {
    "text": "it for every file that needs to get written up to the boss at this point we can move on to kind of our um oops this",
    "start": "2045679",
    "end": "2052919"
  },
  {
    "text": "point we can move on to oh my bad to the uh the the uploading phase where uh kind",
    "start": "2052919",
    "end": "2062079"
  },
  {
    "text": "of the state changes on the job the injest client knows it's good to grab data and it starts popping a message off",
    "start": "2062079",
    "end": "2068079"
  },
  {
    "text": "the queue that message then uses some pretty simple code to Define to decide",
    "start": "2068079",
    "end": "2073480"
  },
  {
    "text": "what file to open how to open it essentially it generates a file that then gets put up into an S3 bucket a",
    "start": "2073480",
    "end": "2080040"
  },
  {
    "text": "temporary bucket when that happens we use um a",
    "start": "2080040",
    "end": "2086520"
  },
  {
    "text": "Lambda invocation based on an S3 put event so then we're we have the guarantee that that object made it to S3",
    "start": "2086520",
    "end": "2093398"
  },
  {
    "text": "because that event has fired and then that Lambda function checks some metadata on the object and uses that",
    "start": "2093399",
    "end": "2099560"
  },
  {
    "text": "metadata to uh update an index we know that that file has now arrived and this",
    "start": "2099560",
    "end": "2104880"
  },
  {
    "text": "happens over and over and over really really fast um where we're the user is",
    "start": "2104880",
    "end": "2109960"
  },
  {
    "text": "popping up a message opening a file putting into a bucket firing an event",
    "start": "2109960",
    "end": "2115240"
  },
  {
    "text": "using a Lambda function to do a quick check of an index table in Dynamo seeing if enough data has arrived and",
    "start": "2115240",
    "end": "2121240"
  },
  {
    "text": "eventually because I said we we're representing these data as these 3D chunks eventually there's going to be enough contiguous files in some random",
    "start": "2121240",
    "end": "2128480"
  },
  {
    "text": "spatial region to to load that chunk of files into the boss and we know this because of this this index we're keeping",
    "start": "2128480",
    "end": "2135119"
  },
  {
    "text": "in this secondary this Dynamo DB table and when that happens that data is now ready to go we can take that data and",
    "start": "2135119",
    "end": "2141480"
  },
  {
    "text": "actually put it into the system and so what happens there is we do an asynchronous invocation of another",
    "start": "2141480",
    "end": "2147920"
  },
  {
    "text": "Lambda function to do the actual image processing and that function grabs those tiles and usually for us right now it's",
    "start": "2147920",
    "end": "2154440"
  },
  {
    "text": "a multiple of 16 so 16 image files will get loaded out of S3 out of that same",
    "start": "2154440",
    "end": "2159680"
  },
  {
    "text": "bucket they're going to get transformed into 3D matrices that are going to get compressed into individual objects",
    "start": "2159680",
    "end": "2166280"
  },
  {
    "text": "individual blobs and we then insert those into a bucket and update an index",
    "start": "2166280",
    "end": "2171520"
  },
  {
    "text": "in another Dynamo DB table and now this is considered like in the boss uh once those cubes land in this bucket and that",
    "start": "2171520",
    "end": "2177240"
  },
  {
    "text": "index is updated if you made a request to the API if you open up in the viewer the data is there now we have it in our",
    "start": "2177240",
    "end": "2182839"
  },
  {
    "text": "format and it's loaded into our system and so um",
    "start": "2182839",
    "end": "2187960"
  },
  {
    "text": "and then oh yeah and finally we go and we delete this is essentially temporary data these tiles were kind of temporary data and so we that Lambda function",
    "start": "2187960",
    "end": "2194720"
  },
  {
    "text": "deletes that data and and you're good to go and so what we love about this",
    "start": "2194720",
    "end": "2200880"
  },
  {
    "text": "process once we got it working is that it supports multiple users ingesting in parallel because it's sitting on their",
    "start": "2200880",
    "end": "2207160"
  },
  {
    "text": "own essentially their own infrastructure in Amazon um and it really doesn't impact the rest of the system so other",
    "start": "2207160",
    "end": "2212480"
  },
  {
    "text": "users can be uh you know visualizing data doing analysis doing doing other things through our API which is going to",
    "start": "2212480",
    "end": "2218599"
  },
  {
    "text": "be scaling out on its own completely independent of this process and this is kind of important for us because while",
    "start": "2218599",
    "end": "2224960"
  },
  {
    "text": "everybody has uh could be delivering their data whenever they do for this program at least right now have the same",
    "start": "2224960",
    "end": "2231160"
  },
  {
    "text": "deadlines so uh they all deliver their data at like the same time right and so we had to actually essentially support",
    "start": "2231160",
    "end": "2237160"
  },
  {
    "text": "worst case of the of of everybody loading stuff at the same time and what's also nice about this is that you",
    "start": "2237160",
    "end": "2243800"
  },
  {
    "text": "know this injest rate we push that down to the users's Loc local resources the users locals bandwidth right they're not",
    "start": "2243800",
    "end": "2249960"
  },
  {
    "text": "uploading slowly because of us it's because of what they have and um what's been interesting is we've been doing a",
    "start": "2249960",
    "end": "2255119"
  },
  {
    "text": "lot of testing one of our teams uh Harvard has a pretty big data center they have an internet 2 connection um so we've been able to transfer great more",
    "start": "2255119",
    "end": "2261440"
  },
  {
    "text": "than 4 gigabits per second um from them right into the system which is pretty",
    "start": "2261440",
    "end": "2266640"
  },
  {
    "text": "which is pretty great just using this pure Lambda Dynamo S3 uh workflow and so",
    "start": "2266640",
    "end": "2273640"
  },
  {
    "text": "that is a problem though right not all teams not all users have the same resources uh we have a team that had",
    "start": "2273640",
    "end": "2280000"
  },
  {
    "text": "doesn't have the kind of bandwidth doesn't have internet to connection like like like Harvard does and so what we're going to be working on soon is the ideas",
    "start": "2280000",
    "end": "2286760"
  },
  {
    "text": "is like well because of this is all works the way it does it works on Amazon straight on S3 we can swap out some this",
    "start": "2286760",
    "end": "2292880"
  },
  {
    "text": "network transfer to actually a snowball and now using the same client using the same tools we'll load data into a",
    "start": "2292880",
    "end": "2298240"
  },
  {
    "text": "snowball mail it in and the whole thing should go and then once you know the brain initiative budget gets quadrupled",
    "start": "2298240",
    "end": "2304880"
  },
  {
    "text": "we're going to swap this thing out for snow mobile and send in you know four paby or 40 pedabytes of data at once",
    "start": "2304880",
    "end": "2311119"
  },
  {
    "text": "it's going to be great um so now I want to touch on a",
    "start": "2311119",
    "end": "2317520"
  },
  {
    "text": "couple kind of tips and Lessons Learned and things we did that crashed and burned um because we spent a lot of time",
    "start": "2317520",
    "end": "2326000"
  },
  {
    "text": "really pushing on some of these Technologies and found them extremely useful after we got through that that",
    "start": "2326000",
    "end": "2331880"
  },
  {
    "text": "process um so a couple things to take away from from Lambda cuz uh I love Lambda Lambda is",
    "start": "2331880",
    "end": "2338640"
  },
  {
    "text": "like an awesome tool to work with but it's not a Panacea right it doesn't solve every problem for you it's not",
    "start": "2338640",
    "end": "2344119"
  },
  {
    "text": "good for every application so you got to keep that in mind um you got to remember if you you can only run a lamb for 5",
    "start": "2344119",
    "end": "2350240"
  },
  {
    "text": "minutes you only can get one and a half gigabytes of memory um another thing we use Python pretty heavily your python",
    "start": "2350240",
    "end": "2356240"
  },
  {
    "text": "virtual environment is limited to 250 megabytes you might not really realize that so we tried to just recently add",
    "start": "2356240",
    "end": "2361720"
  },
  {
    "text": "scipi as a dependency and scipi is huge and it actually is too big with all of our other dependencies we couldn't do it",
    "start": "2361720",
    "end": "2367440"
  },
  {
    "text": "so I had to start breaking things apart so something to keep in mind that um you know there are these limitations to Lambda um another thing to remember is",
    "start": "2367440",
    "end": "2375280"
  },
  {
    "text": "when you get asked for more money I mean for more memory uh you're getting more CPU so your Lambda function function",
    "start": "2375280",
    "end": "2382480"
  },
  {
    "text": "will will run faster it'll cost more per 100 millisecond but it will execute faster so there is this trade-off you",
    "start": "2382480",
    "end": "2388119"
  },
  {
    "text": "can play with there it's not always the smallest Lambda is the cheapest or the biggest Lambda is the most expensive um",
    "start": "2388119",
    "end": "2394160"
  },
  {
    "text": "so something to keep in mind something to play with there um the biggest thing that we struggle with for a while is is",
    "start": "2394160",
    "end": "2400839"
  },
  {
    "text": "your Lambda capacity is tied to your execution duration and so if your execution duration is impacted by other",
    "start": "2400839",
    "end": "2407800"
  },
  {
    "text": "thing so if you make a call out to Dynamo you make a call out over your network you write get something out of",
    "start": "2407800",
    "end": "2412880"
  },
  {
    "text": "S3 like you do anything besides just in that Lambda function your Lambda function execution time will vary and it",
    "start": "2412880",
    "end": "2419720"
  },
  {
    "text": "will eventually at some point like go get pegged and timeout like something's going to happen and so you need to be",
    "start": "2419720",
    "end": "2426040"
  },
  {
    "text": "able to deal with that gracefully because if you don't you can get these crazy cascading failures because you",
    "start": "2426040",
    "end": "2431440"
  },
  {
    "text": "know the the most obvious one that happens is going to happen as soon as you do this is you're not going to have enough Dynamo DB provisioned Dynamo is",
    "start": "2431440",
    "end": "2437640"
  },
  {
    "text": "going to start throttling Lambda your Lambda invocation your Lambda execution time is going to go so your timeout it's",
    "start": "2437640",
    "end": "2443319"
  },
  {
    "text": "going to fail it's going to retry meanwhile users are still sending more stuff in so you have like twice as many",
    "start": "2443319",
    "end": "2448920"
  },
  {
    "text": "lambas trying to run and eventually get to this cascading failure where just like the whole thing tips over and so there are some useful design patterns",
    "start": "2448920",
    "end": "2456079"
  },
  {
    "text": "you can can use to help you here like uh circuit breakers or other resilient design patterns um so we have one where",
    "start": "2456079",
    "end": "2463200"
  },
  {
    "text": "if a user does a right and it goes through the back end and causes a Lambda failure to happen we write a key into a",
    "start": "2463200",
    "end": "2468920"
  },
  {
    "text": "reddest table that will like cut off that user right into that channel so that we can at least limit the number of",
    "start": "2468920",
    "end": "2474359"
  },
  {
    "text": "errors that we're stacking up for that user if if something's going on you know if some weird thing happened with our",
    "start": "2474359",
    "end": "2479800"
  },
  {
    "text": "Network or something we have no way to control that at least we can shut that right off let things recover and then resume so something to think about that",
    "start": "2479800",
    "end": "2485599"
  },
  {
    "text": "you want to be able to hand handle when things go badly um Dynamo DB considerations couple",
    "start": "2485599",
    "end": "2493400"
  },
  {
    "text": "things just to keep in mind the big thing is object size drives Your Capacity um so we had something where we",
    "start": "2493400",
    "end": "2499599"
  },
  {
    "text": "were like uh keys will never get above 40 kilobytes and then all of a",
    "start": "2499599",
    "end": "2505040"
  },
  {
    "text": "sudden we have a bunch of 400 kilobyte keys and they take um you know 10 times more capacity so something to keep in",
    "start": "2505040",
    "end": "2510760"
  },
  {
    "text": "mind um the big thing is I said Beware of this hot partition problem um when this happens it can get really really",
    "start": "2510760",
    "end": "2517400"
  },
  {
    "text": "confusing you you'll be looking in your console you'll be thinking I have tons of capacity why am I getting throttled",
    "start": "2517400",
    "end": "2522880"
  },
  {
    "text": "um and so what this is this when I say hot partition what I mean is um you know you have a key or a couple keys that are",
    "start": "2522880",
    "end": "2528880"
  },
  {
    "text": "hitting the same partition in Dynamo and those ones are getting read and read a ton compared to the rest of your keys",
    "start": "2528880",
    "end": "2534200"
  },
  {
    "text": "and so all your capacity is really Limited in that Shard and what you have to remember is that capacity you're",
    "start": "2534200",
    "end": "2539720"
  },
  {
    "text": "paying for is kind of more I mean Amazon guys can maybe chime on this more but I think practically you're paying for",
    "start": "2539720",
    "end": "2545480"
  },
  {
    "text": "partitions and so if you need to fix that problem you have to actually double Your Capacity to split that partition",
    "start": "2545480",
    "end": "2551040"
  },
  {
    "text": "into two so that those keys that were both like destroying that partition now are in new partitions um and so you know",
    "start": "2551040",
    "end": "2557880"
  },
  {
    "text": "you might up it a little bit up it a little bit you're still getting thrott like crazy and it's not going to be until you actually double Your Capacity that that hot key that hot partition is",
    "start": "2557880",
    "end": "2564680"
  },
  {
    "text": "going to go away um and so we do something where we prepend to Hash to all of our keys this helps it doesn't",
    "start": "2564680",
    "end": "2571280"
  },
  {
    "text": "solve all the problems but if you have some deterministic key you just hash that with something fast prepend it to",
    "start": "2571280",
    "end": "2577280"
  },
  {
    "text": "the front and now you still have a deterministic key but it's random in the beginning and that lets it spread out",
    "start": "2577280",
    "end": "2582319"
  },
  {
    "text": "nicely over your part over your partitions um and then finally when you",
    "start": "2582319",
    "end": "2589160"
  },
  {
    "text": "glue this thing all this all together and you actually try to scale things up um you need to be ready to take some",
    "start": "2589160",
    "end": "2596240"
  },
  {
    "text": "time to do this break a bunch of things kind of turns out to be whack you're going to essentially fix one thing and",
    "start": "2596240",
    "end": "2601960"
  },
  {
    "text": "fix one thing and fix another thing until finally you've got this whole thing working at scale it's going to cost a little bit of money when things",
    "start": "2601960",
    "end": "2608359"
  },
  {
    "text": "go wrong you got to wait especially for Lambda you have to wait for it to stop ringing you know when things are all re",
    "start": "2608359",
    "end": "2614160"
  },
  {
    "text": "trying and crashing you just got to like let it ride out for 15 minutes while all these Lambda functions finish um but",
    "start": "2614160",
    "end": "2619680"
  },
  {
    "text": "once you get it working it's really reliable um and so as you start to scale up Lambda the things you're need to think about are all your limits you got",
    "start": "2619680",
    "end": "2626480"
  },
  {
    "text": "to open so obviously Lambda capacity but the things that we didn't think about um until we ran into them was you know your",
    "start": "2626480",
    "end": "2633680"
  },
  {
    "text": "network architecture you you might lose your into ition a little bit about the bandwidth your Lambda functions are",
    "start": "2633680",
    "end": "2638839"
  },
  {
    "text": "using when they start Fanning out massively in parallel you have a thousand Lambda functions firing at once",
    "start": "2638839",
    "end": "2644160"
  },
  {
    "text": "uh you got to remember that it's going to be really um if you project into your VPC your vpc's network needs to be able",
    "start": "2644160",
    "end": "2649559"
  },
  {
    "text": "to handle that um we didn't do that at first at all um another interesting thing we struggled a lot with and",
    "start": "2649559",
    "end": "2655599"
  },
  {
    "text": "actually figured out with like a live stream with a bunch of AWS Engineers um is that you need to up your eni limit if",
    "start": "2655599",
    "end": "2662000"
  },
  {
    "text": "you're not a heavy ec2 instance user which we aren't we don't really have that many ec2 inst is running um your",
    "start": "2662000",
    "end": "2667880"
  },
  {
    "text": "your uh elastic network interface limit is actually be kind of small and so if you try to spin out 2,000 Lambda",
    "start": "2667880",
    "end": "2674559"
  },
  {
    "text": "functions they're actually going to and those Lambda functions are in a VPC so they use multiple network adapters to",
    "start": "2674559",
    "end": "2680480"
  },
  {
    "text": "talk to multiple availability zones you're going to consume all of your network interfaces and get some sort of",
    "start": "2680480",
    "end": "2686119"
  },
  {
    "text": "crazy timeout failure thing that starts happening um and finally if you're using S3 heavily you can make a request to",
    "start": "2686119",
    "end": "2692680"
  },
  {
    "text": "support put in a support ticket to have your bucket pre-shared which can make a huge difference um both in getting",
    "start": "2692680",
    "end": "2699040"
  },
  {
    "text": "throttled by S3 but also performance and making things scale well",
    "start": "2699040",
    "end": "2704160"
  },
  {
    "text": "um again we recommend Dynamo DB to do a lot of indexing it's great using a third party Auto scaling Library makes it um",
    "start": "2704160",
    "end": "2711200"
  },
  {
    "text": "scale and not cause your Lambda functions to crash um testing is super important and trying to model your",
    "start": "2711200",
    "end": "2717280"
  },
  {
    "text": "user's Behavior like we tried to did it super poorly then they broke everything",
    "start": "2717280",
    "end": "2722680"
  },
  {
    "text": "now we try to do it a little bit better um that's really important and then finally uh especially with these",
    "start": "2722680",
    "end": "2729000"
  },
  {
    "text": "asynchronous lambdas fying all over the place log aggregators air aggregators they're going to be very helpful we know",
    "start": "2729000",
    "end": "2735480"
  },
  {
    "text": "x-ray is going to start helping out with this more especially with python um you know our quick and",
    "start": "2735480",
    "end": "2740960"
  },
  {
    "text": "dirty devops eror catching was we'll just send a message to SNS like no big deal until it's like 1:00 a.m. and my",
    "start": "2740960",
    "end": "2750319"
  },
  {
    "text": "cell phone is freaking out and doing essentially this um which which I didn't think was",
    "start": "2750319",
    "end": "2756640"
  },
  {
    "text": "possible but that's like 2,000 text messages arriving so when Lambda fails it can fail really really big so you got",
    "start": "2756640",
    "end": "2763359"
  },
  {
    "text": "to be prepared for that um that's",
    "start": "2763359",
    "end": "2769680"
  },
  {
    "text": "yeah um all right so got a minute or two I'll just show you real quick kind of",
    "start": "2769960",
    "end": "2776200"
  },
  {
    "text": "the end product of some of this awesome work which is uh see if this actually works based",
    "start": "2776200",
    "end": "2784200"
  },
  {
    "text": "on internet connections and what not so what this is is this tool it's called neurog glancer it was developed",
    "start": "2784200",
    "end": "2790720"
  },
  {
    "text": "originally out of Google and it's open source and now a bunch of people are starting to develop and use it which is pretty great um it's a web uh webg based",
    "start": "2790720",
    "end": "2799920"
  },
  {
    "text": "tool that lets me do do uh real realtime navigation of our data we can do this 3D",
    "start": "2799920",
    "end": "2807079"
  },
  {
    "text": "View kind of what you're looking up in this top quadrant here is we've got a",
    "start": "2807079",
    "end": "2812280"
  },
  {
    "text": "synapse here and two neurons this green one this purple one I can make these things",
    "start": "2812280",
    "end": "2819000"
  },
  {
    "text": "look brighter and what's cool is all of these annotations were done by the",
    "start": "2819000",
    "end": "2824800"
  },
  {
    "text": "Princeton team led by Sebastian Sun this em data um was collected at the Allen Institute for um brain",
    "start": "2824800",
    "end": "2833000"
  },
  {
    "text": "science and all these annotations were done automatically using computer vision so this is where this program is heading",
    "start": "2833000",
    "end": "2838839"
  },
  {
    "text": "they used computer vision to automatically find the Sy synapse find these neuron fragments and I can kind of",
    "start": "2838839",
    "end": "2846200"
  },
  {
    "text": "potentially zoom out a little bit we'll see how this loads if it loads and if I",
    "start": "2846200",
    "end": "2852240"
  },
  {
    "text": "keep going out here what you can kind of see is actually I wonder if me do",
    "start": "2852240",
    "end": "2861599"
  },
  {
    "text": "a um so you can see that this data set I can kind of tick through and this is a",
    "start": "2864680",
    "end": "2870960"
  },
  {
    "text": "blood vessel here these are cell bodies it kind of gives you an idea of the scale and we can navigate around let me",
    "start": "2870960",
    "end": "2877079"
  },
  {
    "text": "open up another one what's also really cool is we can do these 3D mesh generation and 3D mesh rendering so over",
    "start": "2877079",
    "end": "2883280"
  },
  {
    "text": "here on the right we're actually looking at some awesome reconstructed neurons and all these spines that the synapses",
    "start": "2883280",
    "end": "2890280"
  },
  {
    "text": "exist on we can kind of zoom in here and kind of see how this thing comes in this",
    "start": "2890280",
    "end": "2896359"
  },
  {
    "text": "axon here comes in and synapsing here and we can navigate through this data and all this is",
    "start": "2896359",
    "end": "2903079"
  },
  {
    "text": "getting dynamically loaded out of our system through our our cutout service and that cutout service um what's cool",
    "start": "2903079",
    "end": "2910119"
  },
  {
    "text": "about is we use content negotiation so the user can ask for what format they want and so we can say I want an image",
    "start": "2910119",
    "end": "2915880"
  },
  {
    "text": "JPEG encoded version of this chunk and we'll render a film strip send it up to this tool and it'll turn into a Shader",
    "start": "2915880",
    "end": "2922119"
  },
  {
    "text": "and throw it on or into a texture and throw it up in here to uh so we can analyze and visualize it and now all the",
    "start": "2922119",
    "end": "2928559"
  },
  {
    "text": "teams are going to start to use this platform to not only deliver their data share their data um and eventually use it in their workflows to do their",
    "start": "2928559",
    "end": "2934720"
  },
  {
    "text": "analysis um so I got one minute left I just want",
    "start": "2934720",
    "end": "2944040"
  },
  {
    "text": "to acknowledge everybody involved this is a huge project a huge program um we",
    "start": "2944040",
    "end": "2950640"
  },
  {
    "text": "got a great team at APL that did a lot of work to build this system we built it fast we've been working on this for about a year only from maybe a little",
    "start": "2950640",
    "end": "2957440"
  },
  {
    "text": "bit more than a year from scratch um we've got some collaboratives at John Hopkins University out of Rand Burns's",
    "start": "2957440",
    "end": "2963240"
  },
  {
    "text": "lab um we've worked with them for years kind of built the pred predecessor to this system at the open connectone",
    "start": "2963240",
    "end": "2969720"
  },
  {
    "text": "project which is now neurodata um this program was run is run now by David",
    "start": "2969720",
    "end": "2975119"
  },
  {
    "text": "marwitz at AA and started by Jacob vogelstein you got three great teams and all these universities on the right are",
    "start": "2975119",
    "end": "2980680"
  },
  {
    "text": "participating in this program um and so like I said we just finished the first phase and we're entering the second one",
    "start": "2980680",
    "end": "2986720"
  },
  {
    "text": "where we're going to be generating these pedabytes of data it's going to be really exciting um and so yeah",
    "start": "2986720",
    "end": "2994520"
  },
  {
    "text": "thanks oh yeah also just to point out we have um",
    "start": "2994520",
    "end": "3000400"
  },
  {
    "text": "all of our codes open source uh so we have our GitHub repos if you just go to organization you'll see everything there",
    "start": "3000400",
    "end": "3006200"
  },
  {
    "text": "heavy sides there most things that are useful are pip installable so you can pip install heavy side and everything like that and uh the mic runs program if",
    "start": "3006200",
    "end": "3012880"
  },
  {
    "text": "you're interested is there as well and there's press releases and all that interesting stuff so thank",
    "start": "3012880",
    "end": "3019838"
  },
  {
    "text": "you",
    "start": "3020799",
    "end": "3023799"
  }
]
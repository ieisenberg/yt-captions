[
  {
    "start": "0",
    "end": "81000"
  },
  {
    "text": "good afternoon can you hear me where's your hands if you can hear me at the back very good",
    "start": "890",
    "end": "7259"
  },
  {
    "text": "welcome my name is and I'll jati I'm a principal engineer with AWS and I am",
    "start": "7259",
    "end": "15210"
  },
  {
    "text": "joined by Michael Chi who is the director of engineering for the National Football League next-gen starts we're",
    "start": "15210",
    "end": "22590"
  },
  {
    "text": "going to be talking about machine learning and we will be talking about Amazon sage maker and how to build train",
    "start": "22590",
    "end": "29910"
  },
  {
    "text": "and deploy ml models we're going to be",
    "start": "29910",
    "end": "35430"
  },
  {
    "text": "having a brief review of sage maker what it is what it does how it works and we",
    "start": "35430",
    "end": "42840"
  },
  {
    "text": "will describe the various ways in which customers like you can use Amazon sage",
    "start": "42840",
    "end": "48059"
  },
  {
    "text": "maker we'll be talking about deployments and how to take machine learning models",
    "start": "48059",
    "end": "53129"
  },
  {
    "text": "and deploy them at scale and we will",
    "start": "53129",
    "end": "58440"
  },
  {
    "text": "then talk about auto scaling which is the art of how to grow and shrink your",
    "start": "58440",
    "end": "64978"
  },
  {
    "text": "capacity to accommodate the changing needs of your business and lastly we",
    "start": "64979",
    "end": "72720"
  },
  {
    "text": "will be talking about a real story of how Michael and his team implemented next-gen starts using Amazon sage maker",
    "start": "72720",
    "end": "81740"
  },
  {
    "start": "81000",
    "end": "81000"
  },
  {
    "text": "let's start with a broad description of the Amazon machine learning stack the",
    "start": "81740",
    "end": "87960"
  },
  {
    "text": "this stack is catered for people who have different backgrounds different needs and we're going to start by",
    "start": "87960",
    "end": "94619"
  },
  {
    "text": "describing the top level of the stack these are the AI fully managed services these are services that provide computer",
    "start": "94619",
    "end": "102390"
  },
  {
    "text": "vision speech language and chat box contact center tools based on machine",
    "start": "102390",
    "end": "110549"
  },
  {
    "text": "learning for every developer now the interesting thing about this level of the stack is that developers don't need",
    "start": "110549",
    "end": "117630"
  },
  {
    "text": "to understand machine learning they don't need to be experts we at AWS have",
    "start": "117630",
    "end": "123210"
  },
  {
    "text": "built a complete service a complete solution for very very very common needs",
    "start": "123210",
    "end": "129970"
  },
  {
    "text": "I'm gonna start by describing describing the recognition stack which provides computer vision at scale recognition",
    "start": "129970",
    "end": "137740"
  },
  {
    "text": "allows its customers to do object record object detection phase",
    "start": "137740",
    "end": "143170"
  },
  {
    "text": "detection face recognition text and there's a whole bunch of tools content",
    "start": "143170",
    "end": "148750"
  },
  {
    "text": "moderation that other risk users have access to just at the click of a button",
    "start": "148750",
    "end": "153870"
  },
  {
    "text": "we have done the work of creating all these tools for images and for videos that you can integrate into your system",
    "start": "153870",
    "end": "161130"
  },
  {
    "text": "we have speech speed generation like poly that can now speak speak in",
    "start": "161130",
    "end": "166660"
  },
  {
    "text": "multiple languages multiple dialects multiple accents and transcribe that allows a direct customers to actually to",
    "start": "166660",
    "end": "175380"
  },
  {
    "text": "recognize spoken words and spoken language we have translate and",
    "start": "175380",
    "end": "181810"
  },
  {
    "text": "comprehend that allow translation between languages and understanding the",
    "start": "181810",
    "end": "187330"
  },
  {
    "text": "semantics of what is being written and we have systems like legs that allow",
    "start": "187330",
    "end": "194230"
  },
  {
    "text": "chat ports and conversational interfaces to be built again this is all without",
    "start": "194230",
    "end": "200170"
  },
  {
    "text": "and understand of machine learning this is for those developers they have these particular needs",
    "start": "200170",
    "end": "206280"
  },
  {
    "text": "now we also understand that not everybody's needs are covered by these",
    "start": "206280",
    "end": "211320"
  },
  {
    "text": "techniques by these technologies by these services for that class of developers we're going to be we we built",
    "start": "211320",
    "end": "218620"
  },
  {
    "text": "and delivered sage maker and that will be the main topic of this talk so we",
    "start": "218620",
    "end": "227290"
  },
  {
    "text": "will get to that in a second let's jump below to the engine that powers all this",
    "start": "227290",
    "end": "233530"
  },
  {
    "text": "technology we Amazon have made its significant investment with separable",
    "start": "233530",
    "end": "240250"
  },
  {
    "text": "teams on these frameworks the machine learning framework they are evolving so rapidly that power all this technology",
    "start": "240250",
    "end": "247060"
  },
  {
    "text": "tens of lummix net fighters change the high-level interfaces on top of them like glue and carers and the systems to",
    "start": "247060",
    "end": "254489"
  },
  {
    "text": "orchestrate them all like horror vault all these run on the Amazon ec2",
    "start": "254489",
    "end": "260620"
  },
  {
    "text": "instances are either super-powered like rc5 family",
    "start": "260620",
    "end": "266470"
  },
  {
    "text": "or GPU power like our p3 family and you as a developer have access to all this",
    "start": "266470",
    "end": "273070"
  },
  {
    "text": "stack of technologies that whatever level makes sense for you and we're",
    "start": "273070",
    "end": "278710"
  },
  {
    "text": "gonna jump right into stage maker and we're gonna really talk about how sage maker can help you build trained and",
    "start": "278710",
    "end": "284050"
  },
  {
    "text": "deployed machine learning models okay so",
    "start": "284050",
    "end": "289330"
  },
  {
    "text": "let's start with one statement ml is complicated I believe so if you believe",
    "start": "289330",
    "end": "295720"
  },
  {
    "text": "so raise your hand it's complicated there you go I see if your hands it's complicated because it encompasses a",
    "start": "295720",
    "end": "302710"
  },
  {
    "text": "bunch of steps a number of steps each one difficult in its own reality in its",
    "start": "302710",
    "end": "308800"
  },
  {
    "text": "own complexity from data preparation to the choice of algorithm to the",
    "start": "308800",
    "end": "314080"
  },
  {
    "text": "management of environments for training the tuning the deployment in production and there's a there's a continuum that",
    "start": "314080",
    "end": "322270"
  },
  {
    "text": "goes from science to engineering and our customers told us that this is hard and",
    "start": "322270",
    "end": "330480"
  },
  {
    "text": "so we built sage maker to make this simple to really take the pain out of",
    "start": "330480",
    "end": "337690"
  },
  {
    "start": "332000",
    "end": "332000"
  },
  {
    "text": "this process why sage repair allows a one-click model",
    "start": "337690",
    "end": "344770"
  },
  {
    "text": "training of machine learning models and one-click deployment no longer do you have to provision your machines and",
    "start": "344770",
    "end": "351490"
  },
  {
    "text": "group them together I'm sage maker it does all this for you sage maker has",
    "start": "351490",
    "end": "357210"
  },
  {
    "text": "built-in algorithms that work at 10x the speed of other into other",
    "start": "357210",
    "end": "363070"
  },
  {
    "text": "implementations of the same our garden these are some very common algorithms and Michael will talk about one of them",
    "start": "363070",
    "end": "368410"
  },
  {
    "text": "later on these are real live algorithms that can solve concrete business",
    "start": "368410",
    "end": "373540"
  },
  {
    "text": "problems for you not only do these algorithms have incredible speed but",
    "start": "373540",
    "end": "380560"
  },
  {
    "text": "they also scale out to the real business needs to the real data set yet all of",
    "start": "380560",
    "end": "387730"
  },
  {
    "text": "you have to deal with all this allows sage maker customers to gain predictive",
    "start": "387730",
    "end": "393520"
  },
  {
    "text": "insights into decisions that they need to make for their business and again Michael will",
    "start": "393520",
    "end": "400120"
  },
  {
    "text": "describe one such case so as I said earlier on there are three steps build",
    "start": "400120",
    "end": "407020"
  },
  {
    "text": "train and deploy and we will start with building building the the build part of",
    "start": "407020",
    "end": "413860"
  },
  {
    "start": "410000",
    "end": "410000"
  },
  {
    "text": "stage maker allows customers to instantiate notebooks on managed",
    "start": "413860",
    "end": "420669"
  },
  {
    "text": "instances with all the right versions of all the right permits installed for you",
    "start": "420669",
    "end": "426720"
  },
  {
    "text": "I'm a situated takes away the pain of managing all these instances and allows",
    "start": "426720",
    "end": "433360"
  },
  {
    "text": "data scientists to focus on the problem at hand it allows them to call API",
    "start": "433360",
    "end": "440320"
  },
  {
    "text": "scholar the systems from the device from the instance or from other devices and",
    "start": "440320",
    "end": "446560"
  },
  {
    "text": "it allows a complete development environment think of it as an IDE for machine learning once an algorithm has",
    "start": "446560",
    "end": "455740"
  },
  {
    "text": "been created and it's been tested then stage maker has facilities to manage it",
    "start": "455740",
    "end": "462030"
  },
  {
    "text": "to manage the training of it manage all the machines that can that you want to",
    "start": "462030",
    "end": "468070"
  },
  {
    "text": "use during the training phase and this can be a significant number of high power GPU instances sage maker takes",
    "start": "468070",
    "end": "474250"
  },
  {
    "text": "care of all that for you it takes care of the distribution of data it takes care of the high performance AO often",
    "start": "474250",
    "end": "481060"
  },
  {
    "text": "the data lives in s3 and there are several innovations that sage maker brought to the table to bring this data",
    "start": "481060",
    "end": "487389"
  },
  {
    "text": "into your training cluster efficiently now you have a model how do you deploy",
    "start": "487389",
    "end": "493510"
  },
  {
    "text": "it how do you put into production again one click one command allows you to take",
    "start": "493510",
    "end": "499030"
  },
  {
    "text": "this model and send it to endpoints for actual live traffic not only can you do",
    "start": "499030",
    "end": "507310"
  },
  {
    "text": "that but you can also adapt your capacity to the very needs of your",
    "start": "507310",
    "end": "514450"
  },
  {
    "text": "business and we're going to talk about that you can test different models you can swap them in real time you make one",
    "start": "514450",
    "end": "523120"
  },
  {
    "text": "work and then see how it works and then go back to the previous one if that's not what you'd like",
    "start": "523120",
    "end": "528730"
  },
  {
    "text": "so again looking again at the features",
    "start": "528730",
    "end": "535520"
  },
  {
    "start": "530000",
    "end": "530000"
  },
  {
    "text": "we have algorithms designed for speed and skill and these are going to encompass supervised learning",
    "start": "535520",
    "end": "542150"
  },
  {
    "text": "unsupervised learning computer vision and NLP these are very easy to use we created them you can use them to train",
    "start": "542150",
    "end": "549230"
  },
  {
    "text": "your own models as a baseline but if that's not enough if you want more",
    "start": "549230",
    "end": "556120"
  },
  {
    "text": "control you can bring your own model you can write your machine learning models",
    "start": "556120",
    "end": "563420"
  },
  {
    "text": "in your favorite framework and we support tensorflow pythor trainer and MX nets you can write as little as 20 lines",
    "start": "563420",
    "end": "570890"
  },
  {
    "text": "of Python code put your put this code in your notebook and start training all of",
    "start": "570890",
    "end": "578480"
  },
  {
    "text": "this is open source all the infrastructure is open source and you can also use it on a laptop using what",
    "start": "578480",
    "end": "584060"
  },
  {
    "text": "we call local mode for testing so that you have an even faster cycle of iteration if this is still not enough",
    "start": "584060",
    "end": "591800"
  },
  {
    "text": "for you you can bring your own docker model you can build it using whatever tool you like you can use you can use",
    "start": "591800",
    "end": "598760"
  },
  {
    "text": "whatever language you like you can push this docker container to a registry and",
    "start": "598760",
    "end": "605960"
  },
  {
    "text": "then tell sage maker to use that container and sage maker will use it as",
    "start": "605960",
    "end": "611720"
  },
  {
    "text": "if it were a native container and you can use whatever language you want our Java Julia if you're so inclined while",
    "start": "611720",
    "end": "621200"
  },
  {
    "text": "you're doing all these three things you can also use automatic model tuning which is something that we call hyper",
    "start": "621200",
    "end": "627380"
  },
  {
    "text": "parameter tuning which allows which uses machine learning to choose the best machine learning model for your business",
    "start": "627380",
    "end": "634010"
  },
  {
    "text": "you can tell the system to find in the forest in sorry in the space of all the",
    "start": "634010",
    "end": "640130"
  },
  {
    "text": "possible models different learning rates different regularization zs-- whatever you want different number of layers",
    "start": "640130",
    "end": "646270"
  },
  {
    "text": "hyper parameter tuning allows you to find the best model for your business",
    "start": "646270",
    "end": "651860"
  },
  {
    "text": "and it works for with all the three modes of operation that I just described",
    "start": "651860",
    "end": "657220"
  },
  {
    "text": "okay so for the rest of this section we're",
    "start": "657220",
    "end": "663470"
  },
  {
    "text": "going to talk about the third part of the of the pipeline build train deploy",
    "start": "663470",
    "end": "669290"
  },
  {
    "text": "we're going to focus on the deployment we're going to talk about how one can deploy a machine learning model at scale",
    "start": "669290",
    "end": "676400"
  },
  {
    "text": "in real time the key concept that we",
    "start": "676400",
    "end": "686510"
  },
  {
    "start": "682000",
    "end": "682000"
  },
  {
    "text": "need to use here is that of endpoints an endpoint is and then a RESTful API",
    "start": "686510",
    "end": "693280"
  },
  {
    "text": "endpoint that allows clients written in",
    "start": "693280",
    "end": "698990"
  },
  {
    "text": "any language of course to obtain predictions whatever predictions you you may want and again Michael will describe",
    "start": "698990",
    "end": "705440"
  },
  {
    "text": "some of those these endpoints are scalable they have high throughput they",
    "start": "705440",
    "end": "711710"
  },
  {
    "text": "have high reliability the whole AWS infrastructure and the whole management of a fault-tolerant system is delegated",
    "start": "711710",
    "end": "719840"
  },
  {
    "text": "to Sage Maker and all you have to do is say I want to build an endpoint I wanted",
    "start": "719840",
    "end": "725420"
  },
  {
    "text": "with this much capacity I wanted of this type I want it with this model and so you make your mind saw that for you you",
    "start": "725420",
    "end": "732620"
  },
  {
    "text": "still with me okay so so that's that's jump this just",
    "start": "732620",
    "end": "737930"
  },
  {
    "text": "reading let's look at some code this is the basic command that you will need to",
    "start": "737930",
    "end": "745250"
  },
  {
    "text": "execute to call to create a model in sage maker you say you have to say I",
    "start": "745250",
    "end": "750320"
  },
  {
    "text": "want to create model one and I want it to be the Association of a container",
    "start": "750320",
    "end": "756800"
  },
  {
    "text": "which describes the code they are gonna execute and a data for a model which is",
    "start": "756800",
    "end": "762290"
  },
  {
    "text": "the parameters that your model is going to have to execute on you put all these",
    "start": "762290",
    "end": "768500"
  },
  {
    "text": "together and while you I telophase maker is that you want to create a system that",
    "start": "768500",
    "end": "774410"
  },
  {
    "text": "merges all these things together and creates a model called model one you also have to pass an execution role to",
    "start": "774410",
    "end": "780680"
  },
  {
    "text": "make sure that the right permissions are are propagated now the other part is now",
    "start": "780680",
    "end": "787850"
  },
  {
    "text": "that I have a model I want to tell sage maker what kind of for structure I want to serve that model",
    "start": "787850",
    "end": "794779"
  },
  {
    "text": "and we call that an end point configuration think of it as a blueprint to create an endpoint and in this case",
    "start": "794779",
    "end": "801500"
  },
  {
    "text": "we are calling that configuration model one config and we say I want to base it on a particular instance instance type",
    "start": "801500",
    "end": "808700"
  },
  {
    "text": "ml M for extra-large I want to start with two and I want this particular",
    "start": "808700",
    "end": "816649"
  },
  {
    "text": "assistant to serve model one and there is something else about the way it's which we're going to talk about in a",
    "start": "816649",
    "end": "822560"
  },
  {
    "text": "second so once you have these two things you have a model you have a blueprint for how to deploy this model you can",
    "start": "822560",
    "end": "828740"
  },
  {
    "text": "actually deploy this model you can call a create endpoint verb which will take",
    "start": "828740",
    "end": "838070"
  },
  {
    "text": "the configuration and work that you specified which internally refers to the model and will create an actual endpoint",
    "start": "838070",
    "end": "845510"
  },
  {
    "text": "there you can now start calling using the the SDK which comes in multiple languages so far so good so now you have",
    "start": "845510",
    "end": "853910"
  },
  {
    "text": "a living breathing endpoint that you can start calling but life doesn't stop",
    "start": "853910",
    "end": "860480"
  },
  {
    "text": "there your business doesn't stand still things will change your scientists will",
    "start": "860480",
    "end": "867380"
  },
  {
    "text": "say hey I have a great new model that I want to deploy production you now have",
    "start": "867380",
    "end": "872600"
  },
  {
    "text": "traffic how do you make that happen how do you test this new model how do you switch it we have this concept of",
    "start": "872600",
    "end": "880250"
  },
  {
    "text": "blue-green deployments which allow you to deploy essentially two versions of",
    "start": "880250",
    "end": "885380"
  },
  {
    "text": "the same of two different models and we're going to talk about how these models can differ from each other and",
    "start": "885380",
    "end": "891860"
  },
  {
    "text": "you can also in and behind the same endpoint so that you can take traffic and every directly to one of the two",
    "start": "891860",
    "end": "898339"
  },
  {
    "text": "fleets and kind of bring them up and down turn them on and off as you wish",
    "start": "898339",
    "end": "903579"
  },
  {
    "text": "you do so by saying hey I want to create another model and a very typical usage",
    "start": "903579",
    "end": "913490"
  },
  {
    "text": "of this is to say I want to reuse the same container but now I have an update and update a set of weights that's a",
    "start": "913490",
    "end": "920120"
  },
  {
    "text": "very common thing to do here but this is not the only thing that you can do it you can also say",
    "start": "920120",
    "end": "925880"
  },
  {
    "text": "hey four for the same business problem I want to create a completely new container and Ryan are completely",
    "start": "925880",
    "end": "932300"
  },
  {
    "text": "different sets of weights you can do that too you create another end point",
    "start": "932300",
    "end": "938329"
  },
  {
    "text": "configuration that is just like the first one it just refers to a different set of weights and now you say okay now",
    "start": "938329",
    "end": "946370"
  },
  {
    "text": "update and behind-the-scenes the machinery in Sage maker updates the end",
    "start": "946370",
    "end": "951740"
  },
  {
    "text": "point and start saving traffic using the deployment schedule that we saw earlier on to the new end point now this all",
    "start": "951740",
    "end": "960680"
  },
  {
    "start": "959000",
    "end": "959000"
  },
  {
    "text": "works well if you're sure that you're sure that you're sure that your model",
    "start": "960680",
    "end": "965779"
  },
  {
    "text": "works sometimes you want to do something different sometimes you may want to have",
    "start": "965779",
    "end": "971230"
  },
  {
    "text": "multiple versions of the same model running at the same time and have the final control of what's going on you may",
    "start": "971230",
    "end": "979100"
  },
  {
    "text": "want to try different algorithms you may want to switch from extra boost",
    "start": "979100",
    "end": "984949"
  },
  {
    "text": "algorithm to a neural network and you want to test them side-by-side so",
    "start": "984949",
    "end": "991880"
  },
  {
    "text": "another way to do this is to have is to change the end point configuration so",
    "start": "991880",
    "end": "998389"
  },
  {
    "text": "that now we have both models present so",
    "start": "998389",
    "end": "1003639"
  },
  {
    "text": "what this blob of text says is that I want to create an endpoint configuration",
    "start": "1003639",
    "end": "1009040"
  },
  {
    "text": "that has both models one is more than one one is model two and they have these",
    "start": "1009040",
    "end": "1014500"
  },
  {
    "text": "two variant names and the first one takes 95% of the traffic and the second",
    "start": "1014500",
    "end": "1020980"
  },
  {
    "text": "one takes five percent of the traffic and they both start with two instances each so that traffic will be redirected",
    "start": "1020980",
    "end": "1027449"
  },
  {
    "text": "in a manner that meets that split that you specify there so now you have two",
    "start": "1027449",
    "end": "1034600"
  },
  {
    "text": "models running at the same time and again they could be on the same instance type they could be on different instance",
    "start": "1034600",
    "end": "1040000"
  },
  {
    "text": "type there could be completely from models that's completely up to you so",
    "start": "1040000",
    "end": "1046870"
  },
  {
    "text": "once you have this configuration you update right that's a companion to the",
    "start": "1046870",
    "end": "1052270"
  },
  {
    "text": "creation of an endpoint it's the updating of an endpoint and again your endpoint stays the same but",
    "start": "1052270",
    "end": "1057520"
  },
  {
    "text": "what now you doing is you are creating this configuration that has both systems",
    "start": "1057520",
    "end": "1063090"
  },
  {
    "text": "active at the same time once it happy",
    "start": "1063090",
    "end": "1072070"
  },
  {
    "text": "that model to meets your needs what you can do is you can say okay I'm",
    "start": "1072070",
    "end": "1078549"
  },
  {
    "text": "going to start turning down model 1 you can change the desire weight of model 1 from 95 to 5 so now the each model will",
    "start": "1078549",
    "end": "1086980"
  },
  {
    "text": "take 5/10 I 1/2 of the traffic and you have them both then you know if you're",
    "start": "1086980",
    "end": "1092289"
  },
  {
    "text": "happy over time you can say hey I'm gonna turn model 1 off completely or",
    "start": "1092289",
    "end": "1098590"
  },
  {
    "text": "maybe leave it running at very low capacity whatever your business needs are so now that we talked about models",
    "start": "1098590",
    "end": "1108760"
  },
  {
    "start": "1104000",
    "end": "1104000"
  },
  {
    "text": "and how to swap them and how to make them seamlessly integrate with each",
    "start": "1108760",
    "end": "1114130"
  },
  {
    "text": "other we're going to talk about scaling and how you can take this system that we",
    "start": "1114130",
    "end": "1119649"
  },
  {
    "text": "just described and make it meet your traffic into your traffic needs switch",
    "start": "1119649",
    "end": "1128500"
  },
  {
    "text": "maker has very rich vocabulary that",
    "start": "1128500",
    "end": "1134080"
  },
  {
    "text": "allows you to determine how if and when n points should be scaled up and down",
    "start": "1134080",
    "end": "1142630"
  },
  {
    "text": "and for the next few minutes we're going to go through a couple of scenarios that I think are interesting you can start on",
    "start": "1142630",
    "end": "1151360"
  },
  {
    "text": "the console that's very easy to use you can say hey I want to use these many instances between 2 & 5 if I can see",
    "start": "1151360",
    "end": "1159220"
  },
  {
    "text": "correctly and you can say I want to",
    "start": "1159220",
    "end": "1164289"
  },
  {
    "text": "achieve these many vocations per minute per instance per minute and if the",
    "start": "1164289",
    "end": "1170559"
  },
  {
    "text": "traffic goes up I want a number of instances to go up up to this maximum limit if your number goes down I want to",
    "start": "1170559",
    "end": "1177610"
  },
  {
    "text": "have a cool-down period so that I don't just drop immediately but maybe I let some some instances be alive for a few",
    "start": "1177610",
    "end": "1186789"
  },
  {
    "text": "seconds or a few minutes and then turn them off as my traffic decree",
    "start": "1186789",
    "end": "1192960"
  },
  {
    "text": "so why do you need this this is the reason why traffic follows patterns",
    "start": "1193700",
    "end": "1201750"
  },
  {
    "start": "1194000",
    "end": "1194000"
  },
  {
    "text": "right here you see a traffic that follows a daily pattern that's kind of high frequency but also a growth pattern",
    "start": "1201750",
    "end": "1208169"
  },
  {
    "text": "you see the the traffic seems to be increasing between September and October",
    "start": "1208169",
    "end": "1213259"
  },
  {
    "text": "this is just an example but I'm sure each one of you will have their own",
    "start": "1213259",
    "end": "1218399"
  },
  {
    "text": "needs in terms of how to manage increases in decreases in traffic",
    "start": "1218399",
    "end": "1223740"
  },
  {
    "text": "sometimes these patterns are known sometimes they are not assumed that for instance you are working on new on a new",
    "start": "1223740",
    "end": "1230970"
  },
  {
    "text": "site and some kind of breaking news happens and you want to react to that you cannot predict that that's just life",
    "start": "1230970",
    "end": "1237509"
  },
  {
    "text": "and the auto scaling Paul the automatic scaling policies of sage maker allow you",
    "start": "1237509",
    "end": "1243450"
  },
  {
    "text": "to react to that and we're going to go through some of those so this is what",
    "start": "1243450",
    "end": "1250019"
  },
  {
    "start": "1247000",
    "end": "1247000"
  },
  {
    "text": "automatic scaling looks like in action this is a graph that shows overtime traffic going up and down and the blue",
    "start": "1250019",
    "end": "1258629"
  },
  {
    "text": "line that you see is the total number of the invocations over a period of time for a particular service and at some",
    "start": "1258629",
    "end": "1266429"
  },
  {
    "text": "point auto scaling kicks in and a new set of instances is added to the fleet",
    "start": "1266429",
    "end": "1271980"
  },
  {
    "text": "and the load balancer that's in front of this is informed of these and he allows",
    "start": "1271980",
    "end": "1277049"
  },
  {
    "text": "the traffic per instance the invocations per instance to decrease to a value that you would that you would like",
    "start": "1277049",
    "end": "1284778"
  },
  {
    "start": "1287000",
    "end": "1287000"
  },
  {
    "text": "the number of invocations per per minute number of invocations per second is very",
    "start": "1287690",
    "end": "1292950"
  },
  {
    "text": "simple to think about criteria how many requests my saying that's very common",
    "start": "1292950",
    "end": "1300120"
  },
  {
    "text": "very useful but sometimes you want something else sometimes you want metrics that you can not quite that they",
    "start": "1300120",
    "end": "1308250"
  },
  {
    "text": "are not quite that sage maker allows you to tailor the autoscanning requirements",
    "start": "1308250",
    "end": "1316440"
  },
  {
    "text": "of your endpoint to your needs by using CloudWatch metrics you can use whatever",
    "start": "1316440",
    "end": "1322710"
  },
  {
    "text": "is a meter to CloudWatch metrics excuse me to trigger scaling up and down that's",
    "start": "1322710",
    "end": "1329970"
  },
  {
    "text": "a very simple operation that you can do from the city from the CLI oh and you",
    "start": "1329970",
    "end": "1336120"
  },
  {
    "text": "can create a whole bunch of metrics that are specific to you that will allow you",
    "start": "1336120",
    "end": "1341220"
  },
  {
    "text": "your instances and your endpoint to scale in a way that meets the need of",
    "start": "1341220",
    "end": "1346740"
  },
  {
    "text": "your businesses but doesn't waste resources because that's the ultimate goal of this of this whole technique so",
    "start": "1346740",
    "end": "1354900"
  },
  {
    "start": "1353000",
    "end": "1353000"
  },
  {
    "text": "you can create automatic scaling policies that start on the index in this",
    "start": "1354900",
    "end": "1364530"
  },
  {
    "text": "case on CPU utilization here we're saying I'm gonna register my endpoint",
    "start": "1364530",
    "end": "1371820"
  },
  {
    "text": "which is called endpoint which is part of sage maker with the application of",
    "start": "1371820",
    "end": "1377490"
  },
  {
    "text": "the scaling within AWS and I'm gonna say that the what I want to change is the",
    "start": "1377490",
    "end": "1383850"
  },
  {
    "text": "desire a desired instance count and he has to go between two and five but you",
    "start": "1383850",
    "end": "1390630"
  },
  {
    "text": "can also change you can also auto scale on CPU utilization and the letters in R",
    "start": "1390630",
    "end": "1397350"
  },
  {
    "text": "and say I want to increase my instance count when my CPU utilization per",
    "start": "1397350",
    "end": "1404810"
  },
  {
    "text": "instance grows to above 50% which is a number that you can pick and you know it",
    "start": "1404810",
    "end": "1410160"
  },
  {
    "text": "will be up to you and how hot you want to run your boxes and again we end up",
    "start": "1410160",
    "end": "1416790"
  },
  {
    "text": "with something that looks like this where traffic is increasing but the number of invocations per box as",
    "start": "1416790",
    "end": "1425480"
  },
  {
    "text": "per the orange line remains below a certain a certain level as triggered by",
    "start": "1425480",
    "end": "1432049"
  },
  {
    "text": "the CP utilization okay that was very",
    "start": "1432049",
    "end": "1439429"
  },
  {
    "text": "technical thank you for paying attention I am NOT going to invite you our guest",
    "start": "1439429",
    "end": "1445279"
  },
  {
    "text": "Michael Chi the director of next-gen starts at the National Football League take it away Michael",
    "start": "1445279",
    "end": "1451870"
  },
  {
    "text": "can everybody hear me can everybody hear okay all right so I'm Michael Chi",
    "start": "1453500",
    "end": "1460039"
  },
  {
    "text": "director of engineering at the National Football League where I work on next-gen stats I'm gonna start by talking about",
    "start": "1460039",
    "end": "1467570"
  },
  {
    "text": "who we are at the league what next-gen stats is and how we've come to use stage",
    "start": "1467570",
    "end": "1472970"
  },
  {
    "text": "maker as part of our platform for creating and delivering next-gen stats to our fans I'll talk about how we",
    "start": "1472970",
    "end": "1480950"
  },
  {
    "text": "approach creating stats and finally I'll talk about completion probability which",
    "start": "1480950",
    "end": "1486350"
  },
  {
    "text": "is a set that we've created this year using sage maker so the NFL is",
    "start": "1486350",
    "end": "1493220"
  },
  {
    "text": "internationally known as American football it's America's favorite sport it's comprised of 32 teams from around",
    "start": "1493220",
    "end": "1500600"
  },
  {
    "text": "the country and with about 330 games played each season each week millions of",
    "start": "1500600",
    "end": "1506539"
  },
  {
    "text": "fans tuned in to watch their favorite teams play the game if you pay attention",
    "start": "1506539",
    "end": "1511610"
  },
  {
    "text": "to TV rankings each week NFL games consistently make it into the top 10",
    "start": "1511610",
    "end": "1517820"
  },
  {
    "text": "most watched TV shows each week our Sunday Night Football broadcast on NBC",
    "start": "1517820",
    "end": "1524950"
  },
  {
    "text": "had over 20 million viewers tuned in to watch the game week 2 with so many",
    "start": "1524950",
    "end": "1532340"
  },
  {
    "text": "viewers and was such a large fan base it's our responsibility and mission as",
    "start": "1532340",
    "end": "1538220"
  },
  {
    "text": "those who work for the league to continuously find ways to enhance the game and make the experience better for",
    "start": "1538220",
    "end": "1544940"
  },
  {
    "text": "our fans on next-gen stats we do that with data",
    "start": "1544940",
    "end": "1550870"
  },
  {
    "start": "1550000",
    "end": "1550000"
  },
  {
    "text": "the next chance that's project is known internally as the player tracking initiative we put RFID tags in all of",
    "start": "1551220",
    "end": "1558990"
  },
  {
    "text": "our players and check their real-time location in all of the games every tenth",
    "start": "1558990",
    "end": "1564630"
  },
  {
    "text": "of a second weekend next y-coordinate for where the players are on the field and for all the players using this data",
    "start": "1564630",
    "end": "1572370"
  },
  {
    "text": "we create new metrics on every play we calculate things like what was the often",
    "start": "1572370",
    "end": "1578070"
  },
  {
    "text": "offensive formation on the play what personnel groupings were used both on offense on that defense where were",
    "start": "1578070",
    "end": "1585060"
  },
  {
    "text": "the receivers lined out over the past three years we've amassed over three",
    "start": "1585060",
    "end": "1590940"
  },
  {
    "text": "terabytes worth of data next-gen data that may not sound like a lot to some of",
    "start": "1590940",
    "end": "1596340"
  },
  {
    "text": "you who work with big data and data science but to the NFL that's a tremendous amount one week's worth of",
    "start": "1596340",
    "end": "1603570"
  },
  {
    "text": "next-gen data is greater in size than all the historical box score and play-by-play stats dating back to 1920",
    "start": "1603570",
    "end": "1612650"
  },
  {
    "text": "using this data we integrate with broadcasters so that they can put stats up on TV while the games are going on if",
    "start": "1612860",
    "end": "1621240"
  },
  {
    "text": "you were watching last night's Monday Night Football game before every play the SPE ESPN puts up which players are",
    "start": "1621240",
    "end": "1628710"
  },
  {
    "text": "on the field if you got up to one of the",
    "start": "1628710",
    "end": "1634230"
  },
  {
    "text": "games this season and went to the stadiums you might have noticed that on the scoreboards on the Jumbotrons",
    "start": "1634230",
    "end": "1640140"
  },
  {
    "text": "they're putting up graphics with next-gen data so the player tracking",
    "start": "1640140",
    "end": "1648990"
  },
  {
    "text": "initiative is a fairly new initiative for the league when we first started off",
    "start": "1648990",
    "end": "1658160"
  },
  {
    "text": "when I first started off we hired it our",
    "start": "1658160",
    "end": "1663750"
  },
  {
    "text": "team was pretty lean and",
    "start": "1663750",
    "end": "1668000"
  },
  {
    "text": "when I first started off our team was pretty lean we we hired a team of very",
    "start": "1671390",
    "end": "1678320"
  },
  {
    "text": "talented individuals but what we lacked was data science experience so when we",
    "start": "1678320",
    "end": "1688910"
  },
  {
    "text": "talked to our friends at AWS and they introduced stage maker to us we were really excited stage maker provided a",
    "start": "1688910",
    "end": "1697670"
  },
  {
    "text": "way for a team of engineers to start using the tools of data science here's a",
    "start": "1697670",
    "end": "1708740"
  },
  {
    "text": "diagram of how we deliver next-gen stats to our fans everything that we do is",
    "start": "1708740",
    "end": "1714380"
  },
  {
    "text": "deployed on AWS as inputs to our platform we have the tracking data",
    "start": "1714380",
    "end": "1720470"
  },
  {
    "text": "that's coming from the stadiums and we have the traditional stats the box going the play-by-play we run a DC OS cluster",
    "start": "1720470",
    "end": "1728450"
  },
  {
    "text": "on about 30 ec2 instances that are configured in an auto scale convicted",
    "start": "1728450",
    "end": "1734390"
  },
  {
    "text": "configuration and we use Kafka as our message broker we store data in various",
    "start": "1734390",
    "end": "1743750"
  },
  {
    "text": "in multiple data sources but we use MongoDB as our primary data source for",
    "start": "1743750",
    "end": "1748850"
  },
  {
    "text": "the tracking data once all the data comes through our platform we publish it",
    "start": "1748850",
    "end": "1753980"
  },
  {
    "text": "to Kafka and it's run through a pipeline of over a hundred processes that operate",
    "start": "1753980",
    "end": "1759890"
  },
  {
    "text": "and create metrics on every play this architecture is designed for speed so",
    "start": "1759890",
    "end": "1766850"
  },
  {
    "text": "once the play is over we're able to calculate all these metrics within a second of it of the play ending building",
    "start": "1766850",
    "end": "1775820"
  },
  {
    "text": "models and deploying on the stage maker we deploy them as API endpoints",
    "start": "1775820",
    "end": "1782679"
  },
  {
    "text": "and and we create a processor that and place it in the right place in the right",
    "start": "1784780",
    "end": "1791230"
  },
  {
    "text": "sequence in the pipeline to make the inference to the stage maker and point",
    "start": "1791230",
    "end": "1796450"
  },
  {
    "text": "and save save the next gen stat to our database and make it available to our",
    "start": "1796450",
    "end": "1801490"
  },
  {
    "text": "fans stage maker provides us a way to use machine learning and deployed models",
    "start": "1801490",
    "end": "1807700"
  },
  {
    "text": "and make those calls without changing much of our our architecture so at the",
    "start": "1807700",
    "end": "1819130"
  },
  {
    "start": "1816000",
    "end": "1816000"
  },
  {
    "text": "league there's two ways that we think about how we create stats derive metrics",
    "start": "1819130",
    "end": "1824920"
  },
  {
    "text": "and there's rule-based stats derive metrics are simple derivation from the",
    "start": "1824920",
    "end": "1831490"
  },
  {
    "text": "tracking data a stat like air yards which measures and quantifies how far a",
    "start": "1831490",
    "end": "1837490"
  },
  {
    "text": "quarterback throws the ball beyond the line of scrimmage if you have the tracking data and you",
    "start": "1837490",
    "end": "1842770"
  },
  {
    "text": "know where the receiver caught the ball and you know where the line of scrimmage it's a pretty trivial problem to solve",
    "start": "1842770",
    "end": "1848440"
  },
  {
    "text": "for rule based sets are ones that are a little bit difficult - or more",
    "start": "1848440",
    "end": "1854350"
  },
  {
    "text": "algorithmic and harder to solve for for us take who covered who for example it's",
    "start": "1854350",
    "end": "1860110"
  },
  {
    "text": "a coverage stat saying if I'm a receiver which defenders which defender covered",
    "start": "1860110",
    "end": "1865600"
  },
  {
    "text": "me on every play how would you approach solving that kind of a problem using",
    "start": "1865600",
    "end": "1871240"
  },
  {
    "text": "tracking data you might start off by saying from the receiver which defender",
    "start": "1871240",
    "end": "1876430"
  },
  {
    "text": "did I line up but lined up against me you might take it a step further and say",
    "start": "1876430",
    "end": "1881770"
  },
  {
    "text": "over the course of the play which which of the defenders had the shortest average distance to the receiver and",
    "start": "1881770",
    "end": "1889930"
  },
  {
    "text": "then you might say at at the time that the ball was thrown which defender was",
    "start": "1889930",
    "end": "1895480"
  },
  {
    "text": "closest to the receiver and if all three of those match you're pretty confident and in in the stat but what we've",
    "start": "1895480",
    "end": "1905980"
  },
  {
    "text": "learned from the tracking data and the game of football there are certain nuances where that doesn't always play",
    "start": "1905980",
    "end": "1911890"
  },
  {
    "text": "out the way the way it does there's what it like for example what if the",
    "start": "1911890",
    "end": "1919400"
  },
  {
    "text": "receiver is lined up in trips and bunched with on the left which means the",
    "start": "1919400",
    "end": "1925070"
  },
  {
    "text": "receiver has two other receipt there's three receivers all within one and a half yards of each other or what if the",
    "start": "1925070",
    "end": "1933790"
  },
  {
    "text": "defense is not playing man-to-man into playing zone you can start to see where",
    "start": "1933790",
    "end": "1938929"
  },
  {
    "text": "these rule based algorithms start to break down now that we're starting to",
    "start": "1938929",
    "end": "1946340"
  },
  {
    "text": "use machine learning and on stage maker we have a new tool and a new approach to",
    "start": "1946340",
    "end": "1952130"
  },
  {
    "text": "solving these dip more difficult problems if we're able to use the data and train a model to learn these nuances",
    "start": "1952130",
    "end": "1959600"
  },
  {
    "text": "in the tracking data that's we can we",
    "start": "1959600",
    "end": "1964670"
  },
  {
    "text": "can approach the problem differently and in a in a better way to solve for all these edge cases and write code for",
    "start": "1964670",
    "end": "1971510"
  },
  {
    "text": "every edge case that we come across it makes the code more complex every time",
    "start": "1971510",
    "end": "1976730"
  },
  {
    "text": "we add a case and then and then it just",
    "start": "1976730",
    "end": "1982970"
  },
  {
    "text": "becomes or not unmaintainable so a stage",
    "start": "1982970",
    "end": "1990200"
  },
  {
    "text": "maker and machine learning we also have a new type of stat that we can create we",
    "start": "1990200",
    "end": "1995600"
  },
  {
    "text": "can start using historical data we can start to predict what might happen on the next play take completion probe or",
    "start": "1995600",
    "end": "2004210"
  },
  {
    "text": "we can also quantify how difficult to pass is to complete take completion",
    "start": "2004210",
    "end": "2010300"
  },
  {
    "text": "probability for example this is a stat that we created this year the purpose of it is to do exactly that quantify given",
    "start": "2010300",
    "end": "2017830"
  },
  {
    "text": "different parameters that are happening on the passing play how difficult is a pass for the receiver to complete for",
    "start": "2017830",
    "end": "2025360"
  },
  {
    "text": "this we use the XG boost algorithm built into sage maker we split our data into",
    "start": "2025360",
    "end": "2031860"
  },
  {
    "text": "70-20-10 train validate and test sets and using sage makers automatic hyper",
    "start": "2031860",
    "end": "2039490"
  },
  {
    "text": "tuning parameters we're able a trained and validated a model and returned the best performing model",
    "start": "2039490",
    "end": "2047100"
  },
  {
    "text": "these are some of the features that go into completion probability and if you",
    "start": "2048730",
    "end": "2054919"
  },
  {
    "text": "look at them they make sense receiver separation how how close is the defender",
    "start": "2054919",
    "end": "2060740"
  },
  {
    "text": "from the receiver basically telling us is the receiver colored or not air yards",
    "start": "2060740",
    "end": "2067100"
  },
  {
    "text": "air distance if you're throwing a pass further down the field those are generally harder - harder to complete",
    "start": "2067100",
    "end": "2075340"
  },
  {
    "text": "we trained completion probability using 35,000 pass in place over two years we",
    "start": "2078760",
    "end": "2085970"
  },
  {
    "start": "2079000",
    "end": "2079000"
  },
  {
    "text": "ended up with eleven key features and what we found after we trained and",
    "start": "2085970",
    "end": "2091070"
  },
  {
    "text": "validated a model that you still have to",
    "start": "2091070",
    "end": "2096260"
  },
  {
    "text": "test that ten percent that is not that the model has not seen and you have to",
    "start": "2096260",
    "end": "2101720"
  },
  {
    "text": "validate and see if the model is performing to your needs and so with",
    "start": "2101720",
    "end": "2106790"
  },
  {
    "text": "completion probability that's quantifying how difficult to pass is and for us working at the NFL we get to",
    "start": "2106790",
    "end": "2112730"
  },
  {
    "text": "watch a lot of football and we're able to tell and we're able were able to train our eyes to see when when a pass",
    "start": "2112730",
    "end": "2121220"
  },
  {
    "text": "is made a 50-yard pass is made to get to the sideline and there's two receivers",
    "start": "2121220",
    "end": "2127580"
  },
  {
    "text": "on the on the under receiver it's pretty difficult pass and so up front you have",
    "start": "2127580",
    "end": "2133430"
  },
  {
    "text": "to just decide what your criteria for the acceptance of that model is so at",
    "start": "2133430",
    "end": "2144950"
  },
  {
    "text": "this time I'm going to show a video of completion probability that you might have seen on Sunday Night Football in",
    "start": "2144950",
    "end": "2151490"
  },
  {
    "text": "our partnership with AWS",
    "start": "2151490",
    "end": "2154720"
  },
  {
    "text": "Super Bowl 52 as time ran down in the first Nick Foles was about to complete",
    "start": "2156700",
    "end": "2162200"
  },
  {
    "text": "one of the most improbable plays of the game with each tick of the clock AI from Amazon Web Services processed thousands",
    "start": "2162200",
    "end": "2168830"
  },
  {
    "text": "of data points to generate real-time insights moving that a 19% chance was",
    "start": "2168830",
    "end": "2175160"
  },
  {
    "text": "all fools needed to change the course of history welcome to the next generation",
    "start": "2175160",
    "end": "2183380"
  },
  {
    "text": "of football so our international",
    "start": "2183380",
    "end": "2190820"
  },
  {
    "text": "approach with the completion probability wasn't really an ml based approach this",
    "start": "2190820",
    "end": "2195920"
  },
  {
    "text": "was before we even knew about sage maker and and and had a bet as a tool for",
    "start": "2195920",
    "end": "2201980"
  },
  {
    "text": "creating new stats we tried to build create a methyl function that would take",
    "start": "2201980",
    "end": "2208670"
  },
  {
    "text": "in different features of a play apply different weights and output a number but what we realized that that that's",
    "start": "2208670",
    "end": "2214640"
  },
  {
    "text": "very subjective and it's not using the data and it's not really trustworthy",
    "start": "2214640",
    "end": "2221260"
  },
  {
    "text": "some of the other early lessons before we use stage makers just that we since",
    "start": "2221260",
    "end": "2226670"
  },
  {
    "text": "we didn't have the expertise of setting up servers in a in a environment for",
    "start": "2226670",
    "end": "2232280"
  },
  {
    "text": "training the models we were doing these on our laptops and it was very inefficient and there wasn't a good way",
    "start": "2232280",
    "end": "2237590"
  },
  {
    "text": "to share the results of our model training from engine with with each other and so sage maker with the with",
    "start": "2237590",
    "end": "2245510"
  },
  {
    "text": "the notebook jupiter notebooks and being able to run those on on in in the cloud",
    "start": "2245510",
    "end": "2253160"
  },
  {
    "text": "makes it a lot easier to share and collaborate on different models so in my",
    "start": "2253160",
    "end": "2265550"
  },
  {
    "start": "2259000",
    "end": "2259000"
  },
  {
    "text": "opinion one of the best that one of the one of the takeaways from our story with",
    "start": "2265550",
    "end": "2271520"
  },
  {
    "text": "sage maker is that it really allows a team of engineers who are very smart and",
    "start": "2271520",
    "end": "2278810"
  },
  {
    "text": "understand their data very well to use the tools of of machine learning that",
    "start": "2278810",
    "end": "2285740"
  },
  {
    "text": "are more complex and and tackle problems in different ways it",
    "start": "2285740",
    "end": "2292000"
  },
  {
    "text": "also it also allows us to deploy our models in a in an environment that's",
    "start": "2292000",
    "end": "2298780"
  },
  {
    "text": "familiar to us being on e on AWS thank",
    "start": "2298780",
    "end": "2304240"
  },
  {
    "text": "you",
    "start": "2304240",
    "end": "2306420"
  },
  {
    "text": "thank you thank you Michael that was very interesting i earlier on on sunday",
    "start": "2312350",
    "end": "2318140"
  },
  {
    "text": "asked if you could make the 49ers win that that's that's next year is Roger",
    "start": "2318140",
    "end": "2324580"
  },
  {
    "text": "there yes Michael is one of the customers of stage maker that has found",
    "start": "2324580",
    "end": "2330920"
  },
  {
    "text": "the first star platform to build train and deploy and she learned models at skill and this the thing that's",
    "start": "2330920",
    "end": "2339440"
  },
  {
    "text": "interesting in his story is how a team",
    "start": "2339440",
    "end": "2344349"
  },
  {
    "text": "like Michaels was able to integrate this whole pipeline into a complete system",
    "start": "2345130",
    "end": "2351920"
  },
  {
    "text": "that was put into production without you know having the expertise of the data",
    "start": "2351920",
    "end": "2358880"
  },
  {
    "text": "scientists that that were you the Amazon used to put these extra boost models",
    "start": "2358880",
    "end": "2367490"
  },
  {
    "text": "together and you can try seismic for yourself there's a link you can try",
    "start": "2367490",
    "end": "2373970"
  },
  {
    "text": "building models there is sample notebooks that you can execute top to bottom everything is done for you feel",
    "start": "2373970",
    "end": "2380660"
  },
  {
    "text": "free to try it out thank you [Applause]",
    "start": "2380660",
    "end": "2387019"
  }
]
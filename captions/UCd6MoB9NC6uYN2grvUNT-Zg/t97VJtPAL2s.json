[
  {
    "start": "0",
    "end": "27000"
  },
  {
    "text": "[Music]",
    "start": "410",
    "end": "6519"
  },
  {
    "text": "[Music]",
    "start": "8630",
    "end": "11200"
  },
  {
    "text": "hi I'm Poonam a cloud Support Engineer",
    "start": "11200",
    "end": "14060"
  },
  {
    "text": "here at the AWS office in Sydney today I",
    "start": "14060",
    "end": "17300"
  },
  {
    "text": "will walk you through how to resolve the",
    "start": "17300",
    "end": "19400"
  },
  {
    "text": "error container kills by yon for",
    "start": "19400",
    "end": "22190"
  },
  {
    "text": "exceeding memory limit his park on",
    "start": "22190",
    "end": "24470"
  },
  {
    "text": "Amazon EMR so let's get started",
    "start": "24470",
    "end": "26930"
  },
  {
    "text": "here is a sample error the root cause",
    "start": "26930",
    "end": "30259"
  },
  {
    "start": "27000",
    "end": "62000"
  },
  {
    "text": "and the appropriate solution for this",
    "start": "30259",
    "end": "32119"
  },
  {
    "text": "error depends on your workload you might",
    "start": "32119",
    "end": "34760"
  },
  {
    "text": "have to try each of the following",
    "start": "34760",
    "end": "36320"
  },
  {
    "text": "methods in the following order until the",
    "start": "36320",
    "end": "39020"
  },
  {
    "text": "error is resolved before you continue to",
    "start": "39020",
    "end": "41540"
  },
  {
    "text": "another method reverse any changes that",
    "start": "41540",
    "end": "44060"
  },
  {
    "text": "you made to spark default dot cons in",
    "start": "44060",
    "end": "46940"
  },
  {
    "text": "preceding section use one of the",
    "start": "46940",
    "end": "49610"
  },
  {
    "text": "following methods to resolve this error",
    "start": "49610",
    "end": "51520"
  },
  {
    "text": "increase the memory overhead reduce the",
    "start": "51520",
    "end": "54830"
  },
  {
    "text": "number of executor course increase the",
    "start": "54830",
    "end": "57320"
  },
  {
    "text": "number of partitions increase the driver",
    "start": "57320",
    "end": "59600"
  },
  {
    "text": "and executor memory let's look at the",
    "start": "59600",
    "end": "62930"
  },
  {
    "start": "62000",
    "end": "117000"
  },
  {
    "text": "first option memory overhead is the",
    "start": "62930",
    "end": "65390"
  },
  {
    "text": "amount off of heap memory allocated to",
    "start": "65390",
    "end": "68299"
  },
  {
    "text": "each executor by default memory overhead",
    "start": "68299",
    "end": "71240"
  },
  {
    "text": "is set to either 10% of executors memory",
    "start": "71240",
    "end": "74600"
  },
  {
    "text": "or 384 MB or whichever is higher memory",
    "start": "74600",
    "end": "78649"
  },
  {
    "text": "overhead is used for Java NIU direct",
    "start": "78649",
    "end": "81469"
  },
  {
    "text": "buffers thread stacks shared native",
    "start": "81469",
    "end": "83869"
  },
  {
    "text": "libraries or memory mapped files",
    "start": "83869",
    "end": "85840"
  },
  {
    "text": "consider making gradual increases in",
    "start": "85840",
    "end": "88609"
  },
  {
    "text": "memory overhead up to 25% if the error",
    "start": "88609",
    "end": "91969"
  },
  {
    "text": "occurs only in driver container or",
    "start": "91969",
    "end": "94609"
  },
  {
    "text": "executor container then consider",
    "start": "94609",
    "end": "96829"
  },
  {
    "text": "increasing the memory overhead for that",
    "start": "96829",
    "end": "99020"
  },
  {
    "text": "container only you can increase memory",
    "start": "99020",
    "end": "101719"
  },
  {
    "text": "overhead while the cluster is running",
    "start": "101719",
    "end": "103670"
  },
  {
    "text": "when you launch a new cluster or when",
    "start": "103670",
    "end": "105770"
  },
  {
    "text": "you submit a job be sure that the",
    "start": "105770",
    "end": "108469"
  },
  {
    "text": "executors memory and the memory overhead",
    "start": "108469",
    "end": "110840"
  },
  {
    "text": "together should not be more than your",
    "start": "110840",
    "end": "113539"
  },
  {
    "text": "node manager resource memory MB now I'm",
    "start": "113539",
    "end": "117590"
  },
  {
    "start": "117000",
    "end": "182000"
  },
  {
    "text": "in the terminal I'm going to show you",
    "start": "117590",
    "end": "119240"
  },
  {
    "text": "how to make the memory overhead change",
    "start": "119240",
    "end": "123340"
  },
  {
    "text": "similarly I'm going to show you how to",
    "start": "132270",
    "end": "134760"
  },
  {
    "text": "do when you launch a new EMR cluster now",
    "start": "134760",
    "end": "137700"
  },
  {
    "text": "I have many of my console we can add our",
    "start": "137700",
    "end": "140040"
  },
  {
    "text": "memory overhead parameter by launching a",
    "start": "140040",
    "end": "142470"
  },
  {
    "text": "new cluster with the help of",
    "start": "142470",
    "end": "144120"
  },
  {
    "text": "configuration you can also use a spark",
    "start": "144120",
    "end": "147420"
  },
  {
    "text": "submit command to add the memory",
    "start": "147420",
    "end": "149550"
  },
  {
    "text": "overhead parameter per job or you can",
    "start": "149550",
    "end": "152400"
  },
  {
    "text": "use a spark submit command to specify",
    "start": "152400",
    "end": "154920"
  },
  {
    "text": "the memory overhead parameter with - -",
    "start": "154920",
    "end": "157650"
  },
  {
    "text": "cons if increasing memory overhead",
    "start": "157650",
    "end": "160050"
  },
  {
    "text": "doesn't solve the problem consider",
    "start": "160050",
    "end": "162300"
  },
  {
    "text": "reducing the number of executors course",
    "start": "162300",
    "end": "164460"
  },
  {
    "text": "this reduces the maximum number of tasks",
    "start": "164460",
    "end": "167580"
  },
  {
    "text": "that the executor can perform which",
    "start": "167580",
    "end": "169920"
  },
  {
    "text": "reduces the amount of memory required",
    "start": "169920",
    "end": "172190"
  },
  {
    "text": "depending on driver container throwing",
    "start": "172190",
    "end": "174780"
  },
  {
    "text": "this error or other executor container",
    "start": "174780",
    "end": "176880"
  },
  {
    "text": "getting this error consider decreasing",
    "start": "176880",
    "end": "178920"
  },
  {
    "text": "course for either driver or executor now",
    "start": "178920",
    "end": "182940"
  },
  {
    "start": "182000",
    "end": "268000"
  },
  {
    "text": "we are in terminal we can make the",
    "start": "182940",
    "end": "186240"
  },
  {
    "text": "executor code changes here and add spike",
    "start": "186240",
    "end": "191370"
  },
  {
    "text": "driver code 3 I am in Yama console now",
    "start": "191370",
    "end": "197790"
  },
  {
    "text": "when you're trying to launch a new",
    "start": "197790",
    "end": "199500"
  },
  {
    "text": "cluster you can add a executor cores and",
    "start": "199500",
    "end": "203130"
  },
  {
    "text": "Driver course parameter with the help of",
    "start": "203130",
    "end": "205110"
  },
  {
    "text": "configuration all change only for single",
    "start": "205110",
    "end": "209220"
  },
  {
    "text": "job submission with slack submit if you",
    "start": "209220",
    "end": "212220"
  },
  {
    "text": "increase number of partitions this",
    "start": "212220",
    "end": "214380"
  },
  {
    "text": "reduces the amount of memory required",
    "start": "214380",
    "end": "216600"
  },
  {
    "text": "per partition because spark heavily",
    "start": "216600",
    "end": "219090"
  },
  {
    "text": "utilizes cluster Ram as an effective way",
    "start": "219090",
    "end": "221640"
  },
  {
    "text": "to maximize speed it is important to",
    "start": "221640",
    "end": "224520"
  },
  {
    "text": "monitor memory usage with ganglia and",
    "start": "224520",
    "end": "227190"
  },
  {
    "text": "verify that your cluster settings and",
    "start": "227190",
    "end": "229350"
  },
  {
    "text": "partitioning strategy meet your growing",
    "start": "229350",
    "end": "231330"
  },
  {
    "text": "data needs if you still get the",
    "start": "231330",
    "end": "233070"
  },
  {
    "text": "container killed by yawn for exceeding",
    "start": "233070",
    "end": "235110"
  },
  {
    "text": "memory limits error message after",
    "start": "235110",
    "end": "237570"
  },
  {
    "text": "increasing the number of partitions",
    "start": "237570",
    "end": "238980"
  },
  {
    "text": "consider increasing driver and executor",
    "start": "238980",
    "end": "241980"
  },
  {
    "text": "memory depending on driver container",
    "start": "241980",
    "end": "244710"
  },
  {
    "text": "throwing this error or other executor",
    "start": "244710",
    "end": "246810"
  },
  {
    "text": "container throwing this error consider",
    "start": "246810",
    "end": "248850"
  },
  {
    "text": "increasing memory for either driver or",
    "start": "248850",
    "end": "251250"
  },
  {
    "text": "executor container as was mentioned",
    "start": "251250",
    "end": "253770"
  },
  {
    "text": "earlier make sure that spark driver or",
    "start": "253770",
    "end": "256620"
  },
  {
    "text": "executor memory + spark driver executors",
    "start": "256620",
    "end": "260280"
  },
  {
    "text": "memory overhead should be less than yarn",
    "start": "260280",
    "end": "262590"
  },
  {
    "text": "or manager resource memory MB depending",
    "start": "262590",
    "end": "265500"
  },
  {
    "text": "on",
    "start": "265500",
    "end": "265920"
  },
  {
    "text": "the ec2 instance type now I am back in",
    "start": "265920",
    "end": "268890"
  },
  {
    "text": "terminal I am going to modify spark",
    "start": "268890",
    "end": "271680"
  },
  {
    "text": "defaults Don Kahn's",
    "start": "271680",
    "end": "273120"
  },
  {
    "text": "to add executor memory and Driver memory",
    "start": "273120",
    "end": "275940"
  },
  {
    "text": "I am in M Arkansas now when you",
    "start": "275940",
    "end": "282300"
  },
  {
    "text": "launching a new Yama cluster you can",
    "start": "282300",
    "end": "284460"
  },
  {
    "text": "make the same changes for the executor",
    "start": "284460",
    "end": "286500"
  },
  {
    "text": "memory and Driver memory with the help",
    "start": "286500",
    "end": "288300"
  },
  {
    "text": "of configuration or change only for",
    "start": "288300",
    "end": "291420"
  },
  {
    "text": "single job submission with spark submit",
    "start": "291420",
    "end": "294060"
  },
  {
    "text": "if you still get error message try the",
    "start": "294060",
    "end": "296820"
  },
  {
    "text": "following benchmarking it's a best",
    "start": "296820",
    "end": "299430"
  },
  {
    "text": "practice to run your application against",
    "start": "299430",
    "end": "301740"
  },
  {
    "text": "the sample data set this can help you",
    "start": "301740",
    "end": "303870"
  },
  {
    "text": "spot slowdowns and secured partitions",
    "start": "303870",
    "end": "306270"
  },
  {
    "text": "which can lead to memory problems data",
    "start": "306270",
    "end": "308970"
  },
  {
    "text": "filtration be sure that you are",
    "start": "308970",
    "end": "311010"
  },
  {
    "text": "processing the minimum amount of data",
    "start": "311010",
    "end": "313410"
  },
  {
    "text": "if you don't filter your data or if you",
    "start": "313410",
    "end": "315960"
  },
  {
    "text": "filter late in the application run",
    "start": "315960",
    "end": "317850"
  },
  {
    "text": "excess data might slow down the",
    "start": "317850",
    "end": "319770"
  },
  {
    "text": "application and increase the chance of",
    "start": "319770",
    "end": "322170"
  },
  {
    "text": "memory exception data set size it's a",
    "start": "322170",
    "end": "325170"
  },
  {
    "text": "best practice to process the minimum",
    "start": "325170",
    "end": "327390"
  },
  {
    "text": "required data partition your data so",
    "start": "327390",
    "end": "329820"
  },
  {
    "text": "that only the required data is ingested",
    "start": "329820",
    "end": "332130"
  },
  {
    "text": "partitioning strategy consider using a",
    "start": "332130",
    "end": "335250"
  },
  {
    "text": "different partitioning strategy for",
    "start": "335250",
    "end": "337230"
  },
  {
    "text": "example partition on an alternate key to",
    "start": "337230",
    "end": "340470"
  },
  {
    "text": "avoid large partitions and skewed",
    "start": "340470",
    "end": "342720"
  },
  {
    "text": "partitions Amazon ec2 instance type it's",
    "start": "342720",
    "end": "346380"
  },
  {
    "text": "possible that your Amazon ec2 instance",
    "start": "346380",
    "end": "348930"
  },
  {
    "text": "doesn't have the memory resources",
    "start": "348930",
    "end": "350700"
  },
  {
    "text": "required for your workload switching to",
    "start": "350700",
    "end": "353310"
  },
  {
    "text": "a larger memory optimize instance type",
    "start": "353310",
    "end": "355590"
  },
  {
    "text": "might solve the problem if you still get",
    "start": "355590",
    "end": "357960"
  },
  {
    "text": "memory exceptions after changing",
    "start": "357960",
    "end": "360150"
  },
  {
    "text": "instance type try one of the methods",
    "start": "360150",
    "end": "362130"
  },
  {
    "text": "mentioned earlier in this video on the",
    "start": "362130",
    "end": "364890"
  },
  {
    "text": "new instance thanks for watching and",
    "start": "364890",
    "end": "367560"
  },
  {
    "text": "happy cloud computing from all of us",
    "start": "367560",
    "end": "370020"
  },
  {
    "text": "here at it",
    "start": "370020",
    "end": "370970"
  },
  {
    "text": "[Music]",
    "start": "370970",
    "end": "374190"
  },
  {
    "text": "you",
    "start": "374190",
    "end": "376250"
  },
  {
    "text": "[Music]",
    "start": "376520",
    "end": "378910"
  }
]
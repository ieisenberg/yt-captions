[
  {
    "start": "0",
    "end": "93000"
  },
  {
    "text": "thanks everyone for coming this is net 401 my name is Mike fir I'm an engineer",
    "start": "110",
    "end": "7379"
  },
  {
    "text": "with AWS in the ec2 organization and today we're going to be talking about network performance so as a quick",
    "start": "7379",
    "end": "14009"
  },
  {
    "text": "overview of what I'm we talking about today and what you can expect from this session is we're gonna do a little bit of a deep dive into TCP so TCP runs a",
    "start": "14009",
    "end": "21810"
  },
  {
    "text": "lot of our applications as we're gonna go through and this since this is a 400 level talk we're gonna go pretty deep",
    "start": "21810",
    "end": "27210"
  },
  {
    "text": "into the details of what makes TCP go of course I'll give a little bit of a refresher just to kind of get your minds refreshed about some of these concepts",
    "start": "27210",
    "end": "33540"
  },
  {
    "text": "but expect some details after I talk about TCP for a bit we're next gonna",
    "start": "33540",
    "end": "38910"
  },
  {
    "text": "talk about some tooling so TCP can be a pretty complicated protocol and so it helps to have the right tools to be able",
    "start": "38910",
    "end": "45329"
  },
  {
    "text": "to inspect and figure out what's going on within tcp itself after we talk about",
    "start": "45329",
    "end": "51239"
  },
  {
    "text": "some ways to kind of inspect things and make changes to your TCP stack we're gonna then look at some applications so",
    "start": "51239",
    "end": "58050"
  },
  {
    "text": "these applications I put together just for this talk they're toys they're examples and I'm hoping what you take",
    "start": "58050",
    "end": "63809"
  },
  {
    "text": "away from this talk is not that I get a particular change in behavior in these applications but rather than you've got",
    "start": "63809",
    "end": "69240"
  },
  {
    "text": "a new set of tools in your toolbox so that you can go and explore and experiment and change with your",
    "start": "69240",
    "end": "74820"
  },
  {
    "text": "particular applications and hopefully improve the performance of them network performance is is notoriously difficult",
    "start": "74820",
    "end": "81240"
  },
  {
    "text": "to get right and so any kind of general statements tend not to be helpful which is why I want to give you the tools to make the decisions yourself about how to",
    "start": "81240",
    "end": "88200"
  },
  {
    "text": "improve the performance of your particular application so I've been with",
    "start": "88200",
    "end": "93780"
  },
  {
    "start": "93000",
    "end": "183000"
  },
  {
    "text": "Amazon for about eight years now a little over that and I really loved working on the cloud and during that",
    "start": "93780",
    "end": "99900"
  },
  {
    "text": "pretty much entire period I've worked on ec2 and ec2 networking VPC and things like this and during that time of really",
    "start": "99900",
    "end": "105420"
  },
  {
    "text": "kind of low come below of tcp tcp is just a fascinating algorithm and it just runs so much of the internet and of",
    "start": "105420",
    "end": "113280"
  },
  {
    "text": "course everyone knows tcp is transmission control protocol and it runs on everything from if you're checking your mail on your phone to if",
    "start": "113280",
    "end": "119490"
  },
  {
    "text": "you're calling a web service API on your desktop and I think one of the reasons that TCP is so popular is the",
    "start": "119490",
    "end": "126840"
  },
  {
    "text": "abstractions it gives you so the two kind of most important features that I think drive this are one is that you",
    "start": "126840",
    "end": "133379"
  },
  {
    "text": "don't have to worry about the specific of network so a lot of our networks are based out of packets but TCB's model is a streaming model so",
    "start": "133379",
    "end": "140310"
  },
  {
    "text": "as an application if I want to have a TCP connection I open up a connection and then I start sending bytes and I",
    "start": "140310",
    "end": "146160"
  },
  {
    "text": "usually send bytes by writing them into a socket I don't have to care about how big of a right to do in terms of how the",
    "start": "146160",
    "end": "152490"
  },
  {
    "text": "bytes are gonna be split up on the network I just write some bytes and I know that they'll be delivered to the other side and it's TCPS job not mine to",
    "start": "152490",
    "end": "160890"
  },
  {
    "text": "make sure that for one all the packets do eventually get there that none of them are dropped that none of them are",
    "start": "160890",
    "end": "166830"
  },
  {
    "text": "reordered and that excuse me that the performance of the stream is as high as",
    "start": "166830",
    "end": "173790"
  },
  {
    "text": "it can be so one of the things that's that TCP does as well is a flow control and make sure it sends as many packets",
    "start": "173790",
    "end": "179550"
  },
  {
    "text": "as as can without overwhelming the receiver so let's talk a little bit at a high level how TCP works if I was",
    "start": "179550",
    "end": "186570"
  },
  {
    "start": "183000",
    "end": "478000"
  },
  {
    "text": "walking down the Vegas Strip and I was talked to a random person on the street and I said what do you know about TCP I",
    "start": "186570",
    "end": "192180"
  },
  {
    "text": "bet you they'd say three-way handshake I bet you the first things out of their mouth would be sin and AK so of course",
    "start": "192180",
    "end": "198960"
  },
  {
    "text": "the three-way handshake what that means is that when you do that you're establishing a connection so a",
    "start": "198960",
    "end": "204510"
  },
  {
    "text": "connection in TCP is a bi-directional connection between the sender and the receiver and in fact it's full duplex",
    "start": "204510",
    "end": "210780"
  },
  {
    "text": "rights the sender and receiver can send at the exact same time and again this is an abstraction it's helpful for",
    "start": "210780",
    "end": "216270"
  },
  {
    "text": "application programmers to think about TCP as this nice bi-directional pipe that we can just shove bytes into and",
    "start": "216270",
    "end": "222990"
  },
  {
    "text": "they'll pop out the other side as we start to dig into the details of what actually makes TCP go however it's",
    "start": "222990",
    "end": "229470"
  },
  {
    "text": "helpful to break this down and not as one bi-directional pipe but it's two separate unidirectional pipes and",
    "start": "229470",
    "end": "236010"
  },
  {
    "text": "there's a couple of reasons for this one is that the path that packets take to",
    "start": "236010",
    "end": "242250"
  },
  {
    "text": "get from one side of the connection to the other might be different than on the reverse path it might physically",
    "start": "242250",
    "end": "247770"
  },
  {
    "text": "Traverse different routers along the path or even if it did traverse the same routers in both directions the state of",
    "start": "247770",
    "end": "254700"
  },
  {
    "text": "that router might be different for the ingress in the egress bytes think about if I have a streaming delivery sir our",
    "start": "254700",
    "end": "259829"
  },
  {
    "text": "streaming video service it's going to have a very asymmetrical bandwidth utilization on those links the second",
    "start": "259830",
    "end": "266610"
  },
  {
    "text": "reason is really helpful to think about TCP as a pair of you know directional constraint channels is that the real power of TCP",
    "start": "266610",
    "end": "273700"
  },
  {
    "text": "the place where it gets to make all of its decisions is actually at the sender if I'm a receiver if someone sends me a",
    "start": "273700",
    "end": "279820"
  },
  {
    "text": "packet I don't have very much choice I either have room for it which case I'm gonna put it in a receive side buffer or",
    "start": "279820",
    "end": "286120"
  },
  {
    "text": "I'm gonna throw it away that's all I get to do there's a very little bit choice but as a sender I have a lot of control about how fast how many and all kinds of",
    "start": "286120",
    "end": "294100"
  },
  {
    "text": "different knobs and parameters about how to set up this urge how to best utilize this connection and so we really want to",
    "start": "294100",
    "end": "299740"
  },
  {
    "text": "talk about the sender on both sides to get the best performance out of any given TCP connection now as we dig into",
    "start": "299740",
    "end": "307180"
  },
  {
    "text": "the details of TCP you might remember some of these academic terms receive window congestion window these are the main knobs that kind of",
    "start": "307180",
    "end": "313000"
  },
  {
    "text": "control how TCP works and we're gonna go into a little bit of the details of those today so the receive window is",
    "start": "313000",
    "end": "319180"
  },
  {
    "text": "something that as its name suggests is maintained by the receiver and it's signaled back to the sender and the",
    "start": "319180",
    "end": "325320"
  },
  {
    "text": "purpose of the receive window is to tell the sender how much space I have in my",
    "start": "325320",
    "end": "330640"
  },
  {
    "text": "receive buffer so when you set up a TCP connection your kernel is gonna allocate a certain number of bytes in the kernel",
    "start": "330640",
    "end": "336880"
  },
  {
    "text": "to accept packets and it will queue them there and every so often your application will execute a read system",
    "start": "336880",
    "end": "342610"
  },
  {
    "text": "call reach down in the kernel and read a chunk of those ball bites out of the buffer so if the buffer is full if your",
    "start": "342610",
    "end": "349810"
  },
  {
    "text": "application isn't reading those bytes out of the buffer there's no point for the sender to send more data if Jack is",
    "start": "349810",
    "end": "355990"
  },
  {
    "text": "sending bytes to Jill and Jill's buffer pool she just says no thanks don't send me anymore there's no point in doing it they're just gonna be dropped on the",
    "start": "355990",
    "end": "362050"
  },
  {
    "text": "floor and so it's Jill's responsibility to tell Jack about the state of her receive",
    "start": "362050",
    "end": "367120"
  },
  {
    "text": "buffer now this has real consequences for the amount of bandwidth you can get in a connection now a lot of you may",
    "start": "367120",
    "end": "374080"
  },
  {
    "text": "have heard of the term bandwidth delay products bandwidth delay product is when you take the round-trip time of",
    "start": "374080",
    "end": "379360"
  },
  {
    "text": "connection and you multiply it by the bandwidth you have on that connection and what that tells you is how many",
    "start": "379360",
    "end": "385570"
  },
  {
    "text": "bytes you can actually place on the wire at once if I'm blasting full rate at the full bandwidth and I know my round-trip",
    "start": "385570",
    "end": "391870"
  },
  {
    "text": "time I can now compute how many bytes I can actually have in flight without dropping any now we're",
    "start": "391870",
    "end": "398169"
  },
  {
    "text": "the receipt window comes into this is it imposes an artificial cap on the number of bytes we can have on the wire",
    "start": "398169",
    "end": "403810"
  },
  {
    "text": "so what I've done in this slide here is I've actually solved for a different term in that equation in the bandwidth",
    "start": "403810",
    "end": "409180"
  },
  {
    "text": "delay product I say if I know my received window because it's capped let's say it's 100 kilobytes and I know",
    "start": "409180",
    "end": "415210"
  },
  {
    "text": "my round-trip time because unfortunately we haven't quite figured out how to change the speed of light that's pretty",
    "start": "415210",
    "end": "420219"
  },
  {
    "text": "much fixed so if I have a hundred kilobyte received window and a two millisecond round-trip time then my",
    "start": "420219",
    "end": "425979"
  },
  {
    "text": "effective bandwidth by the way of AB a little a product equation is 400 megabits so 400 megabits is pretty good",
    "start": "425979",
    "end": "433419"
  },
  {
    "text": "you'll get a lot of transfer out of that a lot of decent performance it's not great but it's pretty good now think",
    "start": "433419",
    "end": "438819"
  },
  {
    "text": "about what happens we take the same equation but instead of 2 milliseconds round-trip time let's say it's a hundred",
    "start": "438819",
    "end": "444129"
  },
  {
    "text": "milliseconds so 100 milliseconds isn't too high it's about the time it takes to go across the United States and back and",
    "start": "444129",
    "end": "451330"
  },
  {
    "text": "when we use this equation there we find we're only gonna be able to max out at 8 megabits now 8 megabits is not anything",
    "start": "451330",
    "end": "460180"
  },
  {
    "text": "related to the size of the fiber connection between the routers along the",
    "start": "460180",
    "end": "465460"
  },
  {
    "text": "network path it doesn't matter how many waves are on there doesn't matter what kind of network card it has this is purely being influenced by the",
    "start": "465460",
    "end": "472089"
  },
  {
    "text": "artificial restriction to the receive window places on the connection so how",
    "start": "472089",
    "end": "477189"
  },
  {
    "text": "do we change it well I'm gonna be talking a lot about examples today these are all going to be in Linux just to kind of keep the presentation concise",
    "start": "477189",
    "end": "483430"
  },
  {
    "start": "478000",
    "end": "522000"
  },
  {
    "text": "but a lot of these concepts work equally well in Windows so here's a linux command the sissie TL and what this is",
    "start": "483430",
    "end": "490060"
  },
  {
    "text": "gonna do is it's gonna update the number of the size of my receive window and",
    "start": "490060",
    "end": "495279"
  },
  {
    "text": "there's actually two commands to do it one is kind of for all IP protocols across the box and the other one is specific for TCP and the TCP one",
    "start": "495279",
    "end": "503259"
  },
  {
    "text": "actually has a three tuple of values it's a minimum default and a max and so the really important one there is the",
    "start": "503259",
    "end": "508990"
  },
  {
    "text": "max right if we don't allow our TCP connection to ramp up past that that",
    "start": "508990",
    "end": "514180"
  },
  {
    "text": "it's placing an artificial ceiling so if this maximum value is set to low then you're gonna be artificially capping",
    "start": "514180",
    "end": "519430"
  },
  {
    "text": "your bandwidth ok let's talk about the congestion window the congestion window",
    "start": "519430",
    "end": "525790"
  },
  {
    "start": "522000",
    "end": "541000"
  },
  {
    "text": "has a little bit of a different role than the receive window actually it's very different it's hard it's maintained by the sender",
    "start": "525790",
    "end": "532209"
  },
  {
    "text": "this is where all the magic happens and I'm going to talk about some lot more detail of this in a few minutes but let's talk let's kind of ramped in this",
    "start": "532209",
    "end": "538839"
  },
  {
    "text": "a little bit more generally so it's controlled by the sender and what it's trying to do is it's trying to figure",
    "start": "538839",
    "end": "544930"
  },
  {
    "start": "541000",
    "end": "661000"
  },
  {
    "text": "out what is the state in the middle of the network and it's controlled by",
    "start": "544930",
    "end": "550899"
  },
  {
    "text": "something called the congestion control algorithm there's not just one of these algorithms although there is a default that pretty much all installations of",
    "start": "550899",
    "end": "557319"
  },
  {
    "text": "Linux use it is configurable and we're gonna look at ways to configure in just a second and this algorithm actually",
    "start": "557319",
    "end": "564100"
  },
  {
    "text": "uses a few different heuristics to try to figure out what the state of the network is now what it's trying to do is",
    "start": "564100",
    "end": "570220"
  },
  {
    "text": "figure out if there's congestion on the network and I send more packets those",
    "start": "570220",
    "end": "575290"
  },
  {
    "text": "packets still might not arrive at my destination so I'm gonna make the situation in the middle of network worse",
    "start": "575290",
    "end": "581259"
  },
  {
    "text": "by sending packets too fast so I really want to be a good citizen here I want to send just enough packets to get my",
    "start": "581259",
    "end": "587199"
  },
  {
    "text": "maximum throughput but I don't wanna send too many because that'll make the problem worse for everybody and so the",
    "start": "587199",
    "end": "592990"
  },
  {
    "text": "common inputs you'll see to the congestion control algorithms are lost and this is the dominant one that's used",
    "start": "592990",
    "end": "599290"
  },
  {
    "text": "in a lot of algorithms today so just measuring if I don't get a acknowledgment back from a packet right",
    "start": "599290",
    "end": "604660"
  },
  {
    "text": "TCP is based on acknowledgments I sent a packet I wait for a response if I don't get the response either because my sent",
    "start": "604660",
    "end": "610600"
  },
  {
    "text": "packet didn't arrive or because the response didn't arrive which I can't really tell the difference if I don't",
    "start": "610600",
    "end": "615819"
  },
  {
    "text": "get the response back then I'm gonna do that there must be congestion on the network something's wrong so I'm gonna",
    "start": "615819",
    "end": "620829"
  },
  {
    "text": "slow down other congestion control algorithms use latency they'll actually try to time the amount of amount of time",
    "start": "620829",
    "end": "628240"
  },
  {
    "text": "it takes from when I send the response I send a request and get a response when I send out that packet and get the",
    "start": "628240",
    "end": "633399"
  },
  {
    "text": "acknowledgement back and then a third mechanisms that these algorithms use especially there's some new ones here",
    "start": "633399",
    "end": "639790"
  },
  {
    "text": "that use bandwidth estimation directly so trying to figure out probing the link and spitting out just how many packets",
    "start": "639790",
    "end": "645999"
  },
  {
    "text": "can I get through and trying to measure not indirectly but fairly directly by using kind of active probing how much",
    "start": "645999",
    "end": "652389"
  },
  {
    "text": "bandwidth do I have on this link regardless of whether or not there's loss so I mentioned that the congestion",
    "start": "652389",
    "end": "658209"
  },
  {
    "text": "control algorithm is has a tough job and the reason it's a tough job is because it's trying to make this",
    "start": "658209",
    "end": "663540"
  },
  {
    "start": "661000",
    "end": "773000"
  },
  {
    "text": "decision about global state from local information right it has no idea what's going on in the network and so when you",
    "start": "663540",
    "end": "669150"
  },
  {
    "text": "first establish a TCP connection the first thing it knows is nothing it knows",
    "start": "669150",
    "end": "674610"
  },
  {
    "text": "absolutely nothing about how far away the end point is it knows nothing about how much congestion there is on the",
    "start": "674610",
    "end": "680550"
  },
  {
    "text": "links and so what it does is it starts slow and this is what's called the initial congestion window now once upon",
    "start": "680550",
    "end": "687210"
  },
  {
    "text": "a time but before two 6:39 in linux the congestion initial congestion window was",
    "start": "687210",
    "end": "692310"
  },
  {
    "text": "set to three so this three is actually three packets and when we're counting a number of bytes from the applications",
    "start": "692310",
    "end": "698400"
  },
  {
    "text": "perspective it's actually three kind of maximum segment sizes so the number of payload bytes will actually fit without",
    "start": "698400",
    "end": "703590"
  },
  {
    "text": "all the headers on a packet so if you get three packets you're gonna have about 4,300 bytes of application payload",
    "start": "703590",
    "end": "709350"
  },
  {
    "text": "being sent out before TCP waits first first acknowledgment now this is just a",
    "start": "709350",
    "end": "715110"
  },
  {
    "text": "default and in fact it was figured out that this entry isn't a very good default so after two 6:39 it was actually bumped to ten in Linux but we",
    "start": "715110",
    "end": "722430"
  },
  {
    "text": "can go even higher if you wanted to so let's say we wanted to change the amount of Nashville congestion window for our",
    "start": "722430",
    "end": "728220"
  },
  {
    "text": "to speak stack you can do it with actually on a per route basis so by convention here on these slides is that",
    "start": "728220",
    "end": "734010"
  },
  {
    "text": "the commands I'm gonna be typing in those are in purple all the output is gonna be in black and if there's",
    "start": "734010",
    "end": "739170"
  },
  {
    "text": "something I want you to pay attention in the output that's colored orange so I'm a type IP grout change I'm going to",
    "start": "739170",
    "end": "744300"
  },
  {
    "text": "change this one particular route and the important thing there those last two terms the initial condition windows 16",
    "start": "744300",
    "end": "749520"
  },
  {
    "text": "so that means I'm updating the initial condition window for this route all new TCP connections that go out this route",
    "start": "749520",
    "end": "755130"
  },
  {
    "text": "will have an initial condition window of 16 and then if I list my routes again I now see this new value initial condition",
    "start": "755130",
    "end": "760890"
  },
  {
    "text": "window 16 showing up even though it didn't before if it didn't show up that basically means it's defaulting to the default inside the kernel now loss is",
    "start": "760890",
    "end": "770010"
  },
  {
    "text": "pretty is pretty important too many congestion control volumes and this is",
    "start": "770010",
    "end": "775320"
  },
  {
    "start": "773000",
    "end": "861000"
  },
  {
    "text": "what happens when you get lost on a network when you when you have loss and",
    "start": "775320",
    "end": "780750"
  },
  {
    "text": "a congestion control with algorithm is using that as a signal for how fast to send it will start backing off",
    "start": "780750",
    "end": "786720"
  },
  {
    "text": "immediately you know if you ask me a question and say kind of intuitively",
    "start": "786720",
    "end": "792020"
  },
  {
    "text": "1% of your packets are not reaching the destination put another way 99% of your packets are",
    "start": "792020",
    "end": "798920"
  },
  {
    "text": "reaching the destination how fast do you think your connection would run well I",
    "start": "798920",
    "end": "803930"
  },
  {
    "text": "did a little experiment so this is the graph the y axis here is kind of the percent of idealized throughput so at 0%",
    "start": "803930",
    "end": "810080"
  },
  {
    "text": "packet loss we get a hundred percent of our idealized throughput but as we start to add just a little bit of loss at one",
    "start": "810080",
    "end": "815630"
  },
  {
    "text": "percent I'm not at ninety five I'm not a 90 percent I'm like damn less than 50 percent on my throughput gone just from",
    "start": "815630",
    "end": "822440"
  },
  {
    "text": "1 percent of loss and the reason is because TCP is backing off very aggressively doesn't want to make the situation worse and it doesn't",
    "start": "822440",
    "end": "829640"
  },
  {
    "text": "necessarily know that the loss is because of congestion but it assumes so",
    "start": "829640",
    "end": "836440"
  },
  {
    "text": "so how do we figure out if there's loss oh I'm sorry there's one more thing I wanted to mention on this on this graph",
    "start": "836860",
    "end": "842180"
  },
  {
    "text": "and that is kind of the inverse if I have an application that has very good network performance and then suddenly",
    "start": "842180",
    "end": "849230"
  },
  {
    "text": "the performance drops precipitously what could be going on well one potential candidate is that I'm",
    "start": "849230",
    "end": "856040"
  },
  {
    "text": "seeing loss right if my throughput drops well this graph tells me that maybe I'm seeing loss so how do we figure that out",
    "start": "856040",
    "end": "861500"
  },
  {
    "start": "861000",
    "end": "945000"
  },
  {
    "text": "so the net stat tool is pretty widely known it's on pretty much every Linux box you'll find in the entire planet but",
    "start": "861500",
    "end": "868400"
  },
  {
    "text": "it's also very coarse grained and so what I'm doing here is I'm just prepping out for retransmissions so what's a retransmission the retransmission is",
    "start": "868400",
    "end": "874790"
  },
  {
    "text": "when a TCP connection sends a packet of data but never gets an acknowledgment",
    "start": "874790",
    "end": "880330"
  },
  {
    "text": "now the whatever calls that acknowledgement or packet to be dropped",
    "start": "880330",
    "end": "885380"
  },
  {
    "text": "is not going to tell us we're not gonna get some card in the mail that said by the way packet number 37 yeah it's dead",
    "start": "885380",
    "end": "890900"
  },
  {
    "text": "so we have to figure it out so then we have to at some point just give up and say alright I'm just gonna assume packet 37 never made it I'm gonna send it again",
    "start": "890900",
    "end": "896900"
  },
  {
    "text": "that's what a retransmission is so here I'm prepping out the retransmission statistics from @adam net stat and this",
    "start": "896900",
    "end": "902660"
  },
  {
    "text": "set is coarse-grained in that all of the connections and the Box influence these same counters so I don't know which",
    "start": "902660",
    "end": "907910"
  },
  {
    "text": "particular TCP connection is contributing to the retransmissions these are also initialized at the kernel",
    "start": "907910",
    "end": "914390"
  },
  {
    "text": "boot time so this particular box has about 58,000 retransmissions but I don't",
    "start": "914390",
    "end": "919400"
  },
  {
    "text": "know if that was from 10 seconds ago for 10 weeks ago but one of the things that's really helpful when you have",
    "start": "919400",
    "end": "925240"
  },
  {
    "text": "- like this is to pull it and not even just pull it but dump the results of polling into some kind of metric system",
    "start": "925240",
    "end": "931209"
  },
  {
    "text": "where you can graph it then you can say hey at my graphs I see a drop in my performance and hey in my graphs I see a",
    "start": "931209",
    "end": "938230"
  },
  {
    "text": "sudden surge in retransmissions maybe something is going on in the network layer let's find out if you want to go a",
    "start": "938230",
    "end": "945399"
  },
  {
    "start": "945000",
    "end": "1048000"
  },
  {
    "text": "little bit more fine-grained than then that's that you can use the stock it statistically and the socket statistic tool will give",
    "start": "945399",
    "end": "952540"
  },
  {
    "text": "you a huge wall of text about every single connection on your box so this is one line from SS when I ran",
    "start": "952540",
    "end": "958450"
  },
  {
    "text": "it lovely it has a lot of stuff there I'm not gonna talk about every single one of these but I'm gonna walk through a few of them so the first thing we're",
    "start": "958450",
    "end": "964029"
  },
  {
    "text": "gonna find here is the TCP States so this is an established TCP connection the next thing I'm gonna point out here",
    "start": "964029",
    "end": "969310"
  },
  {
    "text": "is the send Q so the send Q is the number of bytes that are pending in the",
    "start": "969310",
    "end": "974440"
  },
  {
    "text": "TCP stack to be sent over the network if this value is 0 that means your",
    "start": "974440",
    "end": "980830"
  },
  {
    "text": "application isn't sending any data stop looking at the network and go look at your application so you always want the",
    "start": "980830",
    "end": "987310"
  },
  {
    "text": "send queue if you're expecting good network performance if you're expecting you know things to be actually moving to be greater than 0 fairly obvious in hindsight okay what",
    "start": "987310",
    "end": "995380"
  },
  {
    "text": "about was word cubic it's kind of a funky word cubic is actually the name of the congestion control algorithm that's",
    "start": "995380",
    "end": "1001170"
  },
  {
    "text": "used by this TCP connection we'll get rid of that more in a second we've got a few more here RT oh that's the",
    "start": "1001170",
    "end": "1007380"
  },
  {
    "text": "retransmission timeout I said a minute ago that TCP is not going to get a notice that when packets are dropped so",
    "start": "1007380",
    "end": "1014670"
  },
  {
    "text": "it maintains what's called a retransmission timer that tells it after this amount of time just give up on it",
    "start": "1014670",
    "end": "1020100"
  },
  {
    "text": "assume it's dead even if it's not we also have the congestion control congestion window again this is in",
    "start": "1020100",
    "end": "1027630"
  },
  {
    "text": "packets not bytes so this is scaled up to 138 packets for this particular",
    "start": "1027630",
    "end": "1032880"
  },
  {
    "text": "connection and then down here we have the retransmissions for this one particular TCP flow so again you can",
    "start": "1032880",
    "end": "1039240"
  },
  {
    "text": "start scraping this output but it is only gonna give you a point in time right so you run this command it just",
    "start": "1039240",
    "end": "1044459"
  },
  {
    "text": "dumps all the output and exits if you want to go a little bit deeper there's a great set of tools by Brendan Gregg",
    "start": "1044459",
    "end": "1051000"
  },
  {
    "start": "1048000",
    "end": "1129000"
  },
  {
    "text": "Brendan's an engineer and Netflix it has an amazing performance blog which I really enjoy reading and he's written",
    "start": "1051000",
    "end": "1056970"
  },
  {
    "text": "some really great tools for inspecting all manner of components in your ec2 instance one of",
    "start": "1056970",
    "end": "1063409"
  },
  {
    "text": "which is a TCP stack so this tool the TCP rate retransmission tool is actually",
    "start": "1063409",
    "end": "1068509"
  },
  {
    "text": "directly measuring retransmissions the mechanism this tool uses is the Colonel",
    "start": "1068509",
    "end": "1073820"
  },
  {
    "text": "F trace mechanism which means it's actually instrumenting code inside the colonel and so when you run this command",
    "start": "1073820",
    "end": "1080720"
  },
  {
    "text": "it just it doesn't print out the current state of the connections in exit it actually sits there and waits for the",
    "start": "1080720",
    "end": "1086059"
  },
  {
    "text": "instrumentation to fire so every time you see a retransmission a new line will show up and the line in the line so you",
    "start": "1086059",
    "end": "1091580"
  },
  {
    "text": "can monitor this in real time if you're all like on a on an outage call if you're working on an issue live this",
    "start": "1091580",
    "end": "1097460"
  },
  {
    "text": "tool can be really helpful to figure out am i recovered my solving problems what's going on the other thing nice",
    "start": "1097460",
    "end": "1103669"
  },
  {
    "text": "about it is because it's instrumenting it's actually instrumenting the retransmission path in the kernel it's",
    "start": "1103669",
    "end": "1109340"
  },
  {
    "text": "pay-as-you-go if you're not sending any returns message excuse me not sending any retransmissions then the",
    "start": "1109340",
    "end": "1116119"
  },
  {
    "text": "instrumentation code will never get run which means you're not paying any kind of performance penalty for the inspiration kind of in the normal happy",
    "start": "1116119",
    "end": "1121759"
  },
  {
    "text": "case if you want to find out more about these tools there's a great github repo there definitely check it out okay let's",
    "start": "1121759",
    "end": "1129559"
  },
  {
    "start": "1129000",
    "end": "1244000"
  },
  {
    "text": "talk more about congestion control algorithms so like I said before these",
    "start": "1129559",
    "end": "1134840"
  },
  {
    "text": "things are magical and if you look at the history of congestion control especially within Linux it's a little",
    "start": "1134840",
    "end": "1141080"
  },
  {
    "text": "bit of a story tale so back before two six eight there was an implementation called New Reno then there was a brief",
    "start": "1141080",
    "end": "1148029"
  },
  {
    "text": "experiment with what was called BIC then moved to cubic at two 6:19 and that's",
    "start": "1148029",
    "end": "1153139"
  },
  {
    "text": "pretty much where we've been since then and now we actually have a pluggable architect or not now it's actually been",
    "start": "1153139",
    "end": "1159320"
  },
  {
    "text": "there for quite a while with but there is a pluggable architecture within Linux that allows you to swap these out and play with different ones and so when I",
    "start": "1159320",
    "end": "1165950"
  },
  {
    "text": "see a history of change in a fundamental component of my kernel kind of makes me wonder why why is that the case well one",
    "start": "1165950",
    "end": "1173539"
  },
  {
    "text": "possible answer is it's hard to get right and so we keep making improvements we coming up with new algorithms there's",
    "start": "1173539",
    "end": "1180080"
  },
  {
    "text": "the active body of research even say into what goes into a good congestion control algorithm and so we just keep",
    "start": "1180080",
    "end": "1185869"
  },
  {
    "text": "making improvements that's one answer the other answer is that the state of the world has",
    "start": "1185869",
    "end": "1190970"
  },
  {
    "text": "changed do you think about back when linux to 6/8 email man that was a while ago the state of the network was a very",
    "start": "1190970",
    "end": "1198559"
  },
  {
    "text": "different world and historically when a lot of the initial TCP congestion control algorithms came out the world",
    "start": "1198559",
    "end": "1204679"
  },
  {
    "text": "looks very different so you could think about dial-up it behaves very differently than broadband behaves very",
    "start": "1204679",
    "end": "1210710"
  },
  {
    "text": "differently than Wi-Fi behaves very differently than mobile but when you're congestion control algorithm is running",
    "start": "1210710",
    "end": "1217039"
  },
  {
    "text": "it has no idea what kinds of networks is traversing and all those networks didn't exist back then so the world has changed",
    "start": "1217039",
    "end": "1223880"
  },
  {
    "text": "so we iterate and we move forward now there's a bunch of other algorithms out there I just listed a few of them VBR",
    "start": "1223880",
    "end": "1231110"
  },
  {
    "text": "I'm gonna talk about in a second Vegas Illinois Illinois is pretty interesting one I'm also gonna mention that a little bit later this is not an exhaustive list",
    "start": "1231110",
    "end": "1237169"
  },
  {
    "text": "but these are ones that you can that are in the usual in the kernel tree that you can play around with if you like so",
    "start": "1237169",
    "end": "1244760"
  },
  {
    "start": "1244000",
    "end": "1337000"
  },
  {
    "text": "let's say we wanted to do that the TCP congestion control window are suppose to be the TCP congestion algorithm is not",
    "start": "1244760",
    "end": "1251090"
  },
  {
    "text": "actually a parameter you'll find on most applications if you're running the nginx",
    "start": "1251090",
    "end": "1256190"
  },
  {
    "text": "web server its config file does not have an entry for what is the condition control algorithm I should use for this",
    "start": "1256190",
    "end": "1261710"
  },
  {
    "text": "connection it's possible to set it but most applications won't expose that now and so if we want to play with different",
    "start": "1261710",
    "end": "1269090"
  },
  {
    "text": "congestion control algorithms what we can do is just change the default for the entire box so here's a sis CTL the",
    "start": "1269090",
    "end": "1274370"
  },
  {
    "text": "top one there is just listing out what congestion control algorithms are available in my running kernel here I",
    "start": "1274370",
    "end": "1280429"
  },
  {
    "text": "have cubic in Reno if I want to find out what other ones are currently in my internal build I can just use this find",
    "start": "1280429",
    "end": "1285890"
  },
  {
    "text": "command chances are if it starts with TCP underscore something it's probably a chest congestion control algorithm so",
    "start": "1285890",
    "end": "1292159"
  },
  {
    "text": "let's let's add illinois so i'm modprobe annoy if I do my assistive to yell again it now shows up in my list of potential",
    "start": "1292159",
    "end": "1298820"
  },
  {
    "text": "congestion control algorithms now again this doesn't actually change the behavior it's just now available for use if I want to change it so that this is",
    "start": "1298820",
    "end": "1304940"
  },
  {
    "text": "the default I can use this TL and what this means is that all future TCP",
    "start": "1304940",
    "end": "1309950"
  },
  {
    "text": "connections will use the illinois congestion control algorithm now the bad thing about CTL is of course is that you",
    "start": "1309950",
    "end": "1316400"
  },
  {
    "text": "lose them when your box reboots so if you want to persist it you can use the second command so that it is the",
    "start": "1316400",
    "end": "1321620"
  },
  {
    "text": "long term default and of course like I said all new connections so if you're",
    "start": "1321620",
    "end": "1328580"
  },
  {
    "text": "benchmarking your application and you change this default you're sure to bounce your processes to make sure all open sockets are opened with the new",
    "start": "1328580",
    "end": "1334970"
  },
  {
    "text": "settings I wanted to get a special call out actually to a newcomer in the congestion control algorithm world which",
    "start": "1334970",
    "end": "1341900"
  },
  {
    "start": "1337000",
    "end": "1430000"
  },
  {
    "text": "is BB r so BB R stands for a bottleneck bandwidth and round-trip time this was developed at Google and they actually",
    "start": "1341900",
    "end": "1348050"
  },
  {
    "text": "run it on a lot of their their high scale applications including YouTube BB r has been pushed upstream into Linux",
    "start": "1348050",
    "end": "1354530"
  },
  {
    "text": "for nine it's a part of Amazon Linux of 2020 1709 so if you got the last or last",
    "start": "1354530",
    "end": "1360890"
  },
  {
    "text": "two Amazon Linux releases you can get it if you're running your own kernels you make sure your own for nine or you can",
    "start": "1360890",
    "end": "1366740"
  },
  {
    "text": "also grab the drivers are available for older kernels as well but they're enabled by default and what's different",
    "start": "1366740",
    "end": "1373070"
  },
  {
    "text": "about BB R is it doesn't actually use loss at least not directly to measure the performance or the",
    "start": "1373070",
    "end": "1378920"
  },
  {
    "text": "congestion on a network it actually tries to measure the bandwidth delay products directly it tries to measure",
    "start": "1378920",
    "end": "1384530"
  },
  {
    "text": "the round-trip time and it tries to measure the bandwidth and the way it measures these is it does precise timing",
    "start": "1384530",
    "end": "1390500"
  },
  {
    "text": "about when it sends out packets and when it gets them back to implement that timing the initial implementation of VB",
    "start": "1390500",
    "end": "1396170"
  },
  {
    "text": "are actually used a queueing discipline in a Linux kernel so if you want to play with BB R and you're on Linux for nine",
    "start": "1396170",
    "end": "1402140"
  },
  {
    "text": "or greater you actually have to run two commands it's an modprobe this scheduler this fair queuing scheduler and then you",
    "start": "1402140",
    "end": "1408920"
  },
  {
    "text": "have to set those to the fault you get the turn on F Q as your scheduler and then you use BB are the good news is",
    "start": "1408920",
    "end": "1414260"
  },
  {
    "text": "that this second step is actually going to require as of 413 so if you're running bleeding-edge or you're willing",
    "start": "1414260",
    "end": "1419780"
  },
  {
    "text": "to wait a little bit you don't have to do this extra step and in fact if you're using a different queueing discipline already then you can still play around",
    "start": "1419780",
    "end": "1426710"
  },
  {
    "text": "with BB r and not have it take over that setting okay so I talked a little bit before about the retransmission timer",
    "start": "1426710",
    "end": "1433340"
  },
  {
    "start": "1430000",
    "end": "1549000"
  },
  {
    "text": "this is important setting to tune but tune carefully so the two that",
    "start": "1433340",
    "end": "1439490"
  },
  {
    "text": "retransmission timer on Linux defaults to 200 milliseconds let's say I'm on a",
    "start": "1439490",
    "end": "1445010"
  },
  {
    "text": "network where I have maybe a few milliseconds of round-trip time at least",
    "start": "1445010",
    "end": "1450650"
  },
  {
    "text": "usually now round-trip time can be influenced by the routers in the middle they can also be influenced by the load",
    "start": "1450650",
    "end": "1457280"
  },
  {
    "text": "of the end host as well the look the kind of the bandwidth consumed by their network cards and so all kinds of things",
    "start": "1457280",
    "end": "1463280"
  },
  {
    "text": "can happen even on a low bandwidth network so if I were to set the retransmission timer to something really",
    "start": "1463280",
    "end": "1468770"
  },
  {
    "text": "low like five milliseconds on all like a two two millisecond round-trip time if I get any kind of spurious increase in my",
    "start": "1468770",
    "end": "1477800"
  },
  {
    "text": "latency what that means is that the retransmission timer will fire and there",
    "start": "1477800",
    "end": "1482870"
  },
  {
    "text": "might be an acknowledgment on its way back so I send a packet I'm waiting five milliseconds it doesn't arrive yet but",
    "start": "1482870",
    "end": "1488510"
  },
  {
    "text": "it's on its way and I just assume it's gone and I send again and so it can be really dangerous to do this because you",
    "start": "1488510",
    "end": "1493550"
  },
  {
    "text": "can get into a kind of a death spiral where your network starts sending more and more traffic that are ultimately duplicates and potentially making what",
    "start": "1493550",
    "end": "1499760"
  },
  {
    "text": "was a spurious event into a long-running event and of course you wouldn't wanna set it too high either if you set it to a thousand milliseconds that means I'm",
    "start": "1499760",
    "end": "1506960"
  },
  {
    "text": "standing him sending out two milliseconds around time one packet gets dropped and I have to wait a thousand milliseconds until it shows back up so",
    "start": "1506960",
    "end": "1514100"
  },
  {
    "text": "too high is also bad so this is a setting that you want to play with with care but it can be an important one to",
    "start": "1514100",
    "end": "1520370"
  },
  {
    "text": "work it out some last few decimal points of high percentile latency numbers so if",
    "start": "1520370",
    "end": "1527000"
  },
  {
    "text": "we want to change it the RTO is again on the routes let's say I want to change it",
    "start": "1527000",
    "end": "1533930"
  },
  {
    "text": "on my local network so my broadcast main my you know my 8 my AZ subnet this one",
    "start": "1533930",
    "end": "1540260"
  },
  {
    "text": "right here and that's a link-local address so I'm like you know that the prior commands which I was using IP",
    "start": "1540260",
    "end": "1546320"
  },
  {
    "text": "route change to update the link local address I'm actually gonna use IP route excuse me I'm gonna use IP rail change",
    "start": "1546320",
    "end": "1553330"
  },
  {
    "start": "1549000",
    "end": "1618000"
  },
  {
    "text": "but I'm gonna use the scope link command and I'm gonna walk it to 50 milliseconds",
    "start": "1553330",
    "end": "1558640"
  },
  {
    "text": "50 milliseconds is probably a pretty good lower bound the reason is something",
    "start": "1558640",
    "end": "1563900"
  },
  {
    "text": "very special happens at 40 so you may have heard of Nagle algorithm which tries to coalesce packets on the sender",
    "start": "1563900",
    "end": "1570440"
  },
  {
    "text": "side to make sure that it's not sending you know fragments of of payload there's",
    "start": "1570440",
    "end": "1575660"
  },
  {
    "text": "something that happens on the receiver side as well which is delayed acknowledgments so if I send some packets from Jack to Jill Jill does not",
    "start": "1575660",
    "end": "1583340"
  },
  {
    "text": "have to immediately respond she can wait and if she gonna send some data back to me anyway",
    "start": "1583340",
    "end": "1588909"
  },
  {
    "text": "she can piggyback her acknowledgement on the date as she was gonna send so delayed acknowledgement allows Alice to",
    "start": "1588909",
    "end": "1594789"
  },
  {
    "text": "wait for a little while and if she's not gonna say anything then she'll just send the acknowledgement but an acknowledgment is basically pure header",
    "start": "1594789",
    "end": "1601059"
  },
  {
    "text": "there's no payload which is why this optimization is there but the delayed acknowledgment usually comes in in about forty milliseconds so if you set this",
    "start": "1601059",
    "end": "1607330"
  },
  {
    "text": "below 40 and you have a system that actually is executing delayed acknowledgments then again you can have",
    "start": "1607330",
    "end": "1612630"
  },
  {
    "text": "duplicate packets settle your packet which can cause other problems so what else causes around RTO timers to",
    "start": "1612630",
    "end": "1622030"
  },
  {
    "start": "1618000",
    "end": "1708000"
  },
  {
    "text": "fire one thing that we found out is it can be caused by queuing along the",
    "start": "1622030",
    "end": "1627100"
  },
  {
    "text": "network path and so when you send a packet from a sender to receiver what happens is that it traverses a set of",
    "start": "1627100",
    "end": "1633130"
  },
  {
    "text": "routers and each of those routers has an implant in network card that has",
    "start": "1633130",
    "end": "1638500"
  },
  {
    "text": "a buffer it has a data plane and the data planes job is to take packets off the incoming buffer as faculty as it can",
    "start": "1638500",
    "end": "1644950"
  },
  {
    "text": "do a roughtly lookup and then put them on the corresponding output buffer it's got a pair of buffers there and what can",
    "start": "1644950",
    "end": "1651309"
  },
  {
    "text": "happen in a high-speed network is you get microbursts on those buffers those",
    "start": "1651309",
    "end": "1656320"
  },
  {
    "text": "buffers can back up you can get a huge queue of packets waiting to get transferred from the incoming buffer an",
    "start": "1656320",
    "end": "1662470"
  },
  {
    "text": "incoming neck to the outgoing neck and what that means is that if you happen to get stuck in a long queue suddenly you",
    "start": "1662470",
    "end": "1669429"
  },
  {
    "text": "can get a whole bunch of latency that you weren't necessarily expecting especially if this happened on multiple",
    "start": "1669429",
    "end": "1675130"
  },
  {
    "text": "hops down your network path so what we can do is try to change the sender to",
    "start": "1675130",
    "end": "1681460"
  },
  {
    "text": "space things out a little bit if you think about how an application sends data to TCP see TCP it's usually doing a",
    "start": "1681460",
    "end": "1687610"
  },
  {
    "text": "write system call with a huge blob of data down on the kernel and then the kernels chunking it up and sending it",
    "start": "1687610",
    "end": "1692710"
  },
  {
    "text": "out in packets now I'm kernel has the option to send them all out of once or at least as fast as it can or can just",
    "start": "1692710",
    "end": "1698380"
  },
  {
    "text": "spend a little bit of delay in between them and it still gets approximately the same kind of end-to-end bandwidth but it",
    "start": "1698380",
    "end": "1704230"
  },
  {
    "text": "helps smooth out some of these interface buffers so if you want to play with this there's a command in Linux called TC",
    "start": "1704230",
    "end": "1710110"
  },
  {
    "start": "1708000",
    "end": "1742000"
  },
  {
    "text": "which is the traffic control command TC is one of these Linux commands that is you know it is incredibly powerful but",
    "start": "1710110",
    "end": "1717789"
  },
  {
    "text": "the power is actually rivaled by how goal is to figure out how it use and so",
    "start": "1717789",
    "end": "1722790"
  },
  {
    "text": "if you want to play around with TCP Google's your friend you're gonna go figure out what other people have done you're gonna find some examples after",
    "start": "1722790",
    "end": "1728460"
  },
  {
    "text": "you understand some examples then maybe you're gonna go read the man page and after you're the man page you're probably gonna read the little source",
    "start": "1728460",
    "end": "1733500"
  },
  {
    "text": "code it's really powerful but it's a little hard to use so what I would like",
    "start": "1733500",
    "end": "1739470"
  },
  {
    "text": "to be able to do is use TC and here's the command I'm gonna do CTC cutest list so what i'm doing here is listening my",
    "start": "1739470",
    "end": "1746010"
  },
  {
    "start": "1742000",
    "end": "1810000"
  },
  {
    "text": "cueing disciplines and queueing disciplines are basically a mechanism the linux kernel that all outbound",
    "start": "1746010",
    "end": "1751380"
  },
  {
    "text": "packets go through the initial setting for queueing discipline in linux is",
    "start": "1751380",
    "end": "1757380"
  },
  {
    "text": "what's called fast FIFO so basically every packet that comes in as soon as you can send it out on the network first-in first-out",
    "start": "1757380",
    "end": "1763070"
  },
  {
    "text": "so we can change the queuing discipline for all packets going outbound and here",
    "start": "1763070",
    "end": "1769050"
  },
  {
    "text": "what I'm gonna use is what's called the coddle algorithm Co DL coddle actually stands for controlled delay which is",
    "start": "1769050",
    "end": "1775050"
  },
  {
    "text": "exactly what it's doing it's just adding a little bit of spacing between all the packets is sending out to try to help",
    "start": "1775050",
    "end": "1782040"
  },
  {
    "text": "and make sure that we don't get latency spikes from these little micro bursts a buffer pileups if you want to learn more",
    "start": "1782040",
    "end": "1788880"
  },
  {
    "text": "about how coddle works there's this website here that has some great information it's actually a pretty algorithm it doesn't have a lot of",
    "start": "1788880",
    "end": "1794250"
  },
  {
    "text": "tunable zand that's by design it tries to be pretty smart excuse me in trying to adaptively control how much",
    "start": "1794250",
    "end": "1800730"
  },
  {
    "text": "spacing to put in between packets and so you can easily just turn it on and turn off and see the effects you don't have a",
    "start": "1800730",
    "end": "1805860"
  },
  {
    "text": "lot of knobs to play with now a lot of customers on on ec2 are doing things",
    "start": "1805860",
    "end": "1811320"
  },
  {
    "start": "1810000",
    "end": "1890000"
  },
  {
    "text": "with overlay networks if your architecture diagram if your network architecture diagram doesn't have the",
    "start": "1811320",
    "end": "1816750"
  },
  {
    "text": "word overlay in it and it doesn't have the word you know VPN tunnel in it you probably don't ever want to touch",
    "start": "1816750",
    "end": "1821970"
  },
  {
    "text": "your MTU it's just gonna cause pain but if you are doing fun things like overlay",
    "start": "1821970",
    "end": "1827730"
  },
  {
    "text": "networks or you're wrapping things up in some kind of a tunnel like a VPN tunnel then you want to pay attention to em to use all right MT users are important",
    "start": "1827730",
    "end": "1834090"
  },
  {
    "text": "because it tracks how many bytes of payload I can put for each byte of header and I want to include the slide",
    "start": "1834090",
    "end": "1840900"
  },
  {
    "text": "just for completeness because if you'd assume they're just going to default are being that 1500 which is a default and a",
    "start": "1840900",
    "end": "1845940"
  },
  {
    "text": "lot of commands you're gonna be wasting an awful lot of packet processing and at",
    "start": "1845940",
    "end": "1851160"
  },
  {
    "text": "high speed the ultimate limiting factor typically isn't the number of bytes in the payload it's actually packet per",
    "start": "1851160",
    "end": "1857370"
  },
  {
    "text": "second because every single packet has to be looked up in some routing table move to a queue and it's the packets per",
    "start": "1857370",
    "end": "1864240"
  },
  {
    "text": "second metric that a lot of times will get in your way so if you're constrained by packet per",
    "start": "1864240",
    "end": "1869640"
  },
  {
    "text": "second performance then you want to make sure that you're always using the maximum and to you available now within",
    "start": "1869640",
    "end": "1875640"
  },
  {
    "text": "a V PC within ec2 you have nine thousand one jumbo frames so you can all go all",
    "start": "1875640",
    "end": "1880860"
  },
  {
    "text": "the way up to nine thousand one if you're doing overlays you're gonna have to carve a little bit out of that do the math carefully get it right and then",
    "start": "1880860",
    "end": "1887940"
  },
  {
    "text": "you'll be get a little extra performance and actually to make this change we're gonna let's say we want to change it",
    "start": "1887940",
    "end": "1893610"
  },
  {
    "start": "1890000",
    "end": "1925000"
  },
  {
    "text": "here IP linked list and there it is MTU 9001 that's my link local address and",
    "start": "1893610",
    "end": "1901940"
  },
  {
    "text": "let's say I want to change this to maybe 1500 so I'm gonna add this default of",
    "start": "1901940",
    "end": "1908279"
  },
  {
    "text": "sorry I'm gonna add this new parameter of 1500 on my rat a lot of these changes were all Rob based so if I list my",
    "start": "1908279",
    "end": "1914580"
  },
  {
    "text": "routes again I am have a forced MTU of 1500 bytes usually you wanna go in the",
    "start": "1914580",
    "end": "1920010"
  },
  {
    "text": "other direction but sometimes want to bring it down as well then this is fun to experiment with okay no talk about network performance",
    "start": "1920010",
    "end": "1927270"
  },
  {
    "start": "1925000",
    "end": "1948000"
  },
  {
    "text": "would be complete without talking about enhanced networking so enhanced networking was released a few years ago",
    "start": "1927270",
    "end": "1932610"
  },
  {
    "text": "2014 and what it allows ec2 instances to",
    "start": "1932610",
    "end": "1937980"
  },
  {
    "text": "do is get more bang for their buck in terms of sending out packets now the way",
    "start": "1937980",
    "end": "1943140"
  },
  {
    "text": "this works and Peter DeSantis talked about this a little bit the other night and hinted that it is when you're",
    "start": "1943140",
    "end": "1948510"
  },
  {
    "text": "sending data out of a TCP connection it doesn't actually take that kind of idealized back and forth I talked about",
    "start": "1948510",
    "end": "1953700"
  },
  {
    "text": "it actually goes through a few different hops especially when you're on a cloud-based virtualization technology like Amazon ec2 so what's exposed to",
    "start": "1953700",
    "end": "1961740"
  },
  {
    "text": "your guest operating system is actually what's called a Zen para virtualized driver so every packet you send out goes",
    "start": "1961740",
    "end": "1968760"
  },
  {
    "text": "through the Zen PV driver it then passes through the virtualization layer which then sends it on down to the neck and",
    "start": "1968760",
    "end": "1974820"
  },
  {
    "text": "off on to the wire now these extra hops that your packets are taking are adding",
    "start": "1974820",
    "end": "1981120"
  },
  {
    "text": "latency but almost more problematically they're adding jitter some packets might be fast some packets might be slow",
    "start": "1981120",
    "end": "1987580"
  },
  {
    "text": "the virtualization layer might be busy doing something else at that exact moment so you're not actually when you think you're talking to your eth0",
    "start": "1987580",
    "end": "1993670"
  },
  {
    "text": "you're not actually talking the hardware you're talking about to this hardware abstraction layer which is adding latency to you",
    "start": "1993670",
    "end": "1999340"
  },
  {
    "text": "so what enhanced networking did as we said you know what we're gonna skip the virtualization layer we're gonna go directly to the neck and the first",
    "start": "1999340",
    "end": "2005910"
  },
  {
    "text": "version of enhanced networking used intel to nix there was a t25 nine nines and these allow ten gigabit throughput",
    "start": "2005910",
    "end": "2012920"
  },
  {
    "text": "and then much more importantly much less jitter so if you look at the metrics",
    "start": "2012920",
    "end": "2018090"
  },
  {
    "text": "that we posted back when we first launched this and really are impressive now the net tell Mick is a pretty neat",
    "start": "2018090",
    "end": "2023580"
  },
  {
    "text": "card but unfortunately a 10 gig card and as we've started to move to the nitro",
    "start": "2023580",
    "end": "2028860"
  },
  {
    "text": "system and move a lot of our networking components off onto our own Hardware we've we knew that we're gonna have a road map where this bandwidth of this",
    "start": "2028860",
    "end": "2035550"
  },
  {
    "text": "device was gonna start to increase so last year we introduced the elastic network adapter and the elastic network",
    "start": "2035550",
    "end": "2042150"
  },
  {
    "text": "adapter conceptually is very similar to the Intel card it's a box that exposes virtual functions up to the guests you",
    "start": "2042150",
    "end": "2048720"
  },
  {
    "text": "know the academic term for this is SR io v single rutile virtualization and these",
    "start": "2048720",
    "end": "2053730"
  },
  {
    "text": "virtual functions are what the guest operating you use to talk directly to the ene driver now when we first wants",
    "start": "2053730",
    "end": "2059399"
  },
  {
    "text": "ene we actually allow 20 gigabits streams and then a few months ago we actually bumped that number to 25 and",
    "start": "2059400",
    "end": "2064860"
  },
  {
    "text": "the great thing about that bump is you didn't have to do anything the twenty five gigabit came for free you get five extra gigabits no extra charge no hidden",
    "start": "2064860",
    "end": "2072149"
  },
  {
    "text": "fees so how do you know you're using ena well you can use the ETH tool to find",
    "start": "2072150",
    "end": "2078360"
  },
  {
    "start": "2076000",
    "end": "2167000"
  },
  {
    "text": "out what driver your kernel is using if it says if that means using this NPV driver that's fine does andrey pv driver",
    "start": "2078360",
    "end": "2084990"
  },
  {
    "text": "works great it's gonna be the only thing you have on older instance types if you're on enhanced networking",
    "start": "2084990",
    "end": "2090840"
  },
  {
    "text": "there's the Intel driver here and then on ene the drivers just called ena and",
    "start": "2090840",
    "end": "2096090"
  },
  {
    "text": "that wasn't and I'm in fact by design on our roadmap we're gonna be continuing to ramp up the bandwidth that is gonna be",
    "start": "2096090",
    "end": "2102990"
  },
  {
    "text": "available on these cards so today it's twenty five and the future might be 50 hundred and so on and so forth and every",
    "start": "2102990",
    "end": "2109380"
  },
  {
    "text": "time we did that we didn't want to make you guys have to change what driver your kernel was using so when we built this",
    "start": "2109380",
    "end": "2115920"
  },
  {
    "text": "ena driver this driver is meant to go up to four hundred gigabits no changes all new future hardware we'll just take",
    "start": "2115920",
    "end": "2123700"
  },
  {
    "text": "advantage of that as we go you know as the hardware's an evolved over time I've",
    "start": "2123700",
    "end": "2129160"
  },
  {
    "text": "tried to get a list of the different instance types you know we just launched c5 a week ago so c5 would be on the ene",
    "start": "2129160",
    "end": "2135190"
  },
  {
    "text": "ene list as well basically all new east two instances going forward are gonna be",
    "start": "2135190",
    "end": "2140290"
  },
  {
    "text": "a ena enabled if you want to get the drivers for the ene device you can",
    "start": "2140290",
    "end": "2146380"
  },
  {
    "text": "download it from their website we've actually pushed them upstream into Linux for nine so if you're running the latest",
    "start": "2146380",
    "end": "2151450"
  },
  {
    "text": "Amazon Linux ami for analytics latest kernel from other distributions you should be able to get it for free if you",
    "start": "2151450",
    "end": "2157900"
  },
  {
    "text": "want to do more exotic things if you're running DP DK there's also DP DK drivers at that address as well as FreeBSD",
    "start": "2157900",
    "end": "2163869"
  },
  {
    "text": "drivers okay lots of talk let's play",
    "start": "2163869",
    "end": "2168910"
  },
  {
    "start": "2167000",
    "end": "2198000"
  },
  {
    "text": "some let's play with some toys so I want to go through a few examples again these are toys they're made up but let's let's",
    "start": "2168910",
    "end": "2175960"
  },
  {
    "text": "see what changes we can enact and the changes I'm going to be making here are just to the Linux stack I'm not gonna",
    "start": "2175960",
    "end": "2183250"
  },
  {
    "text": "touch the application in any way I don't assume that I'm gonna have the source code I don't assume I'll even",
    "start": "2183250",
    "end": "2188980"
  },
  {
    "text": "necessarily know what decisions it's making but assuming a fixed kind of application what can I do just with the network stack so here's my",
    "start": "2188980",
    "end": "2197020"
  },
  {
    "text": "test setup I've got a pair of m416 excels these are my Jack and Jill I'm",
    "start": "2197020",
    "end": "2203650"
  },
  {
    "text": "gonna be running a recent Linux kernel I'm using the Amazon Linux from I think a point released ago when I first made",
    "start": "2203650",
    "end": "2209920"
  },
  {
    "text": "these using nginx my client is gonna be a patchy bench Apache bench is a little",
    "start": "2209920",
    "end": "2215710"
  },
  {
    "text": "bit older it's not the best of breed necessarily if you're looking to benchmark a brand new web server but it's pretty predictable I know it pretty",
    "start": "2215710",
    "end": "2221440"
  },
  {
    "text": "well so I'm gonna use it as my kind of client in his examples I'm using SSL you know for all these connections those are",
    "start": "2221440",
    "end": "2227980"
  },
  {
    "text": "the parameters I'm using in case you want to play along at home all the data I generated just catting dev dev random",
    "start": "2227980",
    "end": "2234420"
  },
  {
    "text": "they're served out of a temp FS directory so there's no IO whatsoever the client throws away the bits so",
    "start": "2234420",
    "end": "2240190"
  },
  {
    "text": "really what I'm trying to do in these experiments is focus exclusively on the network throwing out all the other",
    "start": "2240190",
    "end": "2245680"
  },
  {
    "text": "parameters of variability and just see what can I change about the network so the first application I'm going to go",
    "start": "2245680",
    "end": "2251770"
  },
  {
    "start": "2250000",
    "end": "2278000"
  },
  {
    "text": "through is this loss it's situation so I gave that really funky graph earlier when we just got a little",
    "start": "2251770",
    "end": "2257550"
  },
  {
    "text": "bit of loss and throughput really drops off so if you're in a situation where you have lost maybe you have a lot of",
    "start": "2257550",
    "end": "2263580"
  },
  {
    "text": "customers that are mobile users and loss is just going to be part of the day part",
    "start": "2263580",
    "end": "2269070"
  },
  {
    "text": "of a part of your work life maybe you just can't get around it or you want to make sure that just in case loss happens",
    "start": "2269070",
    "end": "2274349"
  },
  {
    "text": "your application is minimally impacted what can we do so here's my setup I'm",
    "start": "2274349",
    "end": "2280080"
  },
  {
    "start": "2278000",
    "end": "2311000"
  },
  {
    "text": "going to use that a pair of instances they're 80 milliseconds apart round-trip time I'm gonna be running this Apache",
    "start": "2280080",
    "end": "2285359"
  },
  {
    "text": "bench command and then I'm going to use this TC tool which is quite the Swiss Army knife to add half a percent of loss",
    "start": "2285359",
    "end": "2292890"
  },
  {
    "text": "the TC tool has a lot of parameters you can actually change like the probability distribution of this loss and make it",
    "start": "2292890",
    "end": "2298560"
  },
  {
    "text": "much more realistic this is gonna be a uniform distribution it's probably not terribly realistic but it's fun for a",
    "start": "2298560",
    "end": "2303960"
  },
  {
    "text": "demo okay so our goal here given 5 or 0.5% loss how fast can I go now what I",
    "start": "2303960",
    "end": "2311250"
  },
  {
    "text": "did in this experiments was I was running nginx and I just dumped the output of nginx into cloud watch and I",
    "start": "2311250",
    "end": "2318000"
  },
  {
    "text": "realized that these graphs you probably can't read the extra y axis the x-axis is time the y-axis is the milliseconds",
    "start": "2318000",
    "end": "2325349"
  },
  {
    "text": "for a request and the two lines here are the p50 and p99 for those requests so",
    "start": "2325349",
    "end": "2332880"
  },
  {
    "text": "what are P 50 and P 99 they're fancy words for percentiles so when a lot of times when people talk about performance",
    "start": "2332880",
    "end": "2338160"
  },
  {
    "text": "numbers they use average don't use average use median median means 50% of",
    "start": "2338160",
    "end": "2344430"
  },
  {
    "text": "your customers are getting this percent of this performance for better p99 means this is the 99th percentile 99% of your",
    "start": "2344430",
    "end": "2351750"
  },
  {
    "text": "customers are getting this or better sometimes you have no choice to use average but if you can you should always be looking at percentiles it gives you a",
    "start": "2351750",
    "end": "2357180"
  },
  {
    "text": "more complete picture of what's going on okay so in this experiment baseline I",
    "start": "2357180",
    "end": "2362430"
  },
  {
    "text": "don't haven't added my loss yet this is just kind of getting things started my p 99 99 % of all my requests ended in 37",
    "start": "2362430",
    "end": "2369780"
  },
  {
    "text": "37 seconds or less 50 percent of them were 23 seconds or less let's add our",
    "start": "2369780",
    "end": "2375030"
  },
  {
    "text": "loss okay everything else lower my P 99 is now 52 seconds my p 50 is now 42",
    "start": "2375030",
    "end": "2382260"
  },
  {
    "text": "seconds so what can we do well I was talking about congestion",
    "start": "2382260",
    "end": "2387520"
  },
  {
    "text": "control algorithms earlier and saying that a lot of them use loss as their primary indicator of congestion so why",
    "start": "2387520",
    "end": "2393490"
  },
  {
    "text": "don't we start playing with some congestion control algorithms so the first thing I'm going to play with is so",
    "start": "2393490",
    "end": "2399130"
  },
  {
    "text": "I'm going to put cubic here on my left that's the graph we just had just changing the title a little bit and I'm",
    "start": "2399130",
    "end": "2405310"
  },
  {
    "text": "gonna do is I'm gonna look at Illinois so Illinois is a congestion control algorithm that does not have quite the",
    "start": "2405310",
    "end": "2411100"
  },
  {
    "text": "sensitivity to loss that cubic does so I use Illinois boom right away my p50 is",
    "start": "2411100",
    "end": "2417910"
  },
  {
    "text": "dropped almost in half and my Pinay and has come down as well let's see what",
    "start": "2417910",
    "end": "2423370"
  },
  {
    "text": "else can we do what about bbr that was supposed to be do something interesting",
    "start": "2423370",
    "end": "2428550"
  },
  {
    "text": "even better IP 50 is down at 11 seconds so just from changing the congestion control",
    "start": "2428550",
    "end": "2433960"
  },
  {
    "text": "algorithm this experiment changing nothing else I've gotten a 74 percent decrease in my p 50 latency for these",
    "start": "2433960",
    "end": "2440950"
  },
  {
    "text": "requests now you might be wondering or if you're still awake",
    "start": "2440950",
    "end": "2446020"
  },
  {
    "text": "you think 11 seconds is not lower than what I had without any loss with cubic",
    "start": "2446020",
    "end": "2451690"
  },
  {
    "text": "and yes you'd be correct in fact bbr performs better with lost than cubic did",
    "start": "2451690",
    "end": "2458020"
  },
  {
    "text": "without loss is that true in every situation probably not it's a it's an artifact of these particular experiments",
    "start": "2458020",
    "end": "2464230"
  },
  {
    "text": "but I get to compare them side-by-side and see what am i trading off here and in fact if I remove loss from DBR it",
    "start": "2464230",
    "end": "2470530"
  },
  {
    "text": "gets even better right B be ours best-case scenario here is now 8 seconds at P 50 and 44 seconds at P 99 so is",
    "start": "2470530",
    "end": "2480070"
  },
  {
    "text": "this a talk to tell you that you should go play with bbr yes it's gonna solve all your problems no and is this gonna",
    "start": "2480070",
    "end": "2487030"
  },
  {
    "text": "represent what you're gonna see in your applications no let me show you one more paragraphs so this paragraph shows you",
    "start": "2487030",
    "end": "2492520"
  },
  {
    "text": "the cubic no loss versus the VBR no loss so as we can see the P 50 on the bbr is",
    "start": "2492520",
    "end": "2498550"
  },
  {
    "text": "much much better but the P 99 is actually more spiky is my application",
    "start": "2498550",
    "end": "2504400"
  },
  {
    "text": "really sensitive to jitter maybe VBR isn't the right solution for this particular benchmark now again this",
    "start": "2504400",
    "end": "2510550"
  },
  {
    "text": "might also be artifacts of this particular experiment so this is what you I want you guys to take away from",
    "start": "2510550",
    "end": "2516100"
  },
  {
    "text": "this presentation not that go use bbr start looking at what happens when I change these what happens at different",
    "start": "2516100",
    "end": "2522760"
  },
  {
    "text": "percentiles don't assume one number is gonna summarize everything about a performance benchmark okay so that was",
    "start": "2522760",
    "end": "2529840"
  },
  {
    "text": "an 80 millisecond link let's talk a little bit about a low RTT path about let's say 2 milliseconds or sorry one",
    "start": "2529840",
    "end": "2538510"
  },
  {
    "start": "2537000",
    "end": "2566000"
  },
  {
    "text": "millisecond man and for this one I'm gonna be transferring a pretty small object just 10 Meg's but over and over",
    "start": "2538510",
    "end": "2544960"
  },
  {
    "text": "and over never never never again and what I want to look at here is actually the retransmission timer when I add a",
    "start": "2544960",
    "end": "2550990"
  },
  {
    "text": "little bit loss so these instances are closer together I'm only going to use point 2 percent and this experiment the",
    "start": "2550990",
    "end": "2556900"
  },
  {
    "text": "last one was 0.5 same TC command I didn't put it up on the slide but you can extrapolate from the prior one just",
    "start": "2556900",
    "end": "2563290"
  },
  {
    "text": "at point two instead of point five so if I'm running this experiment and I graph my my data without any loss my p50 is",
    "start": "2563290",
    "end": "2573490"
  },
  {
    "text": "about to excuse me with loss this is with loss so if i graph my my latency",
    "start": "2573490",
    "end": "2578770"
  },
  {
    "text": "with loss 0.2 percent loss my p 50 is at two milliseconds pretty fast 10 makefile",
    "start": "2578770",
    "end": "2585490"
  },
  {
    "text": "two milliseconds yeah that's pretty fast what about a really high percentile p",
    "start": "2585490",
    "end": "2592420"
  },
  {
    "text": "ninety-nine point nine nine 200 milliseconds that's two orders of magnitude higher than my P 50 now these",
    "start": "2592420",
    "end": "2600400"
  },
  {
    "text": "Y axes are not to scale I had to use different scales because if I put them on the same y-axis you couldn't even see",
    "start": "2600400",
    "end": "2605560"
  },
  {
    "text": "the two milliseconds they'd be down on the floor so why do we care about such high percentiles like P 99.99 well that",
    "start": "2605560",
    "end": "2612940"
  },
  {
    "text": "means one out of every ten thousand of your customers are gonna experience this but it's actually probably worse than",
    "start": "2612940",
    "end": "2619420"
  },
  {
    "text": "that if you think about what happens today and a lot of our architectures there tend to be service-oriented",
    "start": "2619420",
    "end": "2624970"
  },
  {
    "text": "architectures you like micro-services we like to break things apart so if you think about the p 90999 even think about",
    "start": "2624970",
    "end": "2632170"
  },
  {
    "text": "all the hops it goes through to actually satisfy one customer request could be dozens of micro-services and when you",
    "start": "2632170",
    "end": "2639100"
  },
  {
    "text": "start adding up dozens and dozens and dozens of p99 minds the probabilities start to collapse right so now it might",
    "start": "2639100",
    "end": "2645520"
  },
  {
    "text": "be one and a hundred customers are experienced this for maybe 1,000 and you really want that customer have a good",
    "start": "2645520",
    "end": "2653390"
  },
  {
    "text": "so what can we do about this 200 milliseconds well what are we know about",
    "start": "2653390",
    "end": "2658470"
  },
  {
    "text": "200 milliseconds it's the default RTO for Linux let's try dropping so instead of 200",
    "start": "2658470",
    "end": "2665250"
  },
  {
    "text": "milliseconds for the default RTO let's drop it 250 and just making that one change on the IP route gets me half of",
    "start": "2665250",
    "end": "2672480"
  },
  {
    "text": "the latency back at this high percentile now why is it not P 50 well there's",
    "start": "2672480",
    "end": "2677610"
  },
  {
    "text": "probably other things going on at a really high percentile like P 9999 a lot of things just like one or a few packets",
    "start": "2677610",
    "end": "2684420"
  },
  {
    "text": "here and there have to have a bad day to cause this to go wrong well what I found here is that half of the problem was",
    "start": "2684420",
    "end": "2691680"
  },
  {
    "text": "just the RTO but dropping the Artyom in my really high percentile performance",
    "start": "2691680",
    "end": "2697110"
  },
  {
    "text": "gets better in fact twice as good which is pretty great for a one-line change",
    "start": "2697110",
    "end": "2703130"
  },
  {
    "text": "okay third application this one is going to be a high transaction service now",
    "start": "2703430",
    "end": "2710460"
  },
  {
    "start": "2705000",
    "end": "2779000"
  },
  {
    "text": "this one I'm actually going to use HTTP the previous examples were all HTTP with SSL and the reason is I'm going down to",
    "start": "2710460",
    "end": "2717840"
  },
  {
    "text": "looking at individual packets and what's going on there so I'm gonna do my",
    "start": "2717840",
    "end": "2722880"
  },
  {
    "text": "instances a little bit farther apart this time I'm gonna assume there's a 1500 byte MTU and I'm gonna make 200",
    "start": "2722880",
    "end": "2730650"
  },
  {
    "text": "thousand requests for a little tiny 10k object so what do we what do we expect",
    "start": "2730650",
    "end": "2735870"
  },
  {
    "text": "to be 10k not many things these days right well there's a few things webpages HTML",
    "start": "2735870",
    "end": "2740970"
  },
  {
    "text": "files thumbnails a lot of web requests fall into this category of short-lived",
    "start": "2740970",
    "end": "2746070"
  },
  {
    "text": "connections that transfer a relatively small amount of data now hopefully it's we're using that connection in the future but not always if you have a web",
    "start": "2746070",
    "end": "2752670"
  },
  {
    "text": "page which is relatively static relatively that's small you might get one teaspoon connection and you're done",
    "start": "2752670",
    "end": "2758910"
  },
  {
    "text": "similarly with API requests your API requests might only be transferring a little bit of data 10k is not unreasonable for an API request right if",
    "start": "2758910",
    "end": "2765240"
  },
  {
    "text": "you have a web service so let's look about what happens with a congestion control and specifically the initial",
    "start": "2765240",
    "end": "2772800"
  },
  {
    "text": "congestion control window what happens on these two servers that are 80 milliseconds apart so when I run this",
    "start": "2772800",
    "end": "2780120"
  },
  {
    "start": "2779000",
    "end": "2895000"
  },
  {
    "text": "test I'm gonna start out at three packets now as I mentioned before most modern Linux",
    "start": "2780120",
    "end": "2786190"
  },
  {
    "text": "distributions don't have this setting this low but I'm gonna start here we do have customers that run old kernels so",
    "start": "2786190",
    "end": "2792249"
  },
  {
    "text": "it is something to look out for if you are before to 6:39 but at three packets for my initial congestion window it",
    "start": "2792249",
    "end": "2799329"
  },
  {
    "text": "takes 321 milliseconds to transfer a 10k file what in the world is going on",
    "start": "2799329",
    "end": "2806819"
  },
  {
    "text": "so 321 or how about just 320 is an awfully suspicious multiplier of 80",
    "start": "2806819",
    "end": "2813940"
  },
  {
    "text": "all right it's about four times eighty and so what's really going on here is to transfer that 10k file we had to",
    "start": "2813940",
    "end": "2820569"
  },
  {
    "text": "do four round trips four times so let's try playing with this what happens we go",
    "start": "2820569",
    "end": "2825670"
  },
  {
    "text": "up to ten packets as our initial congestion window so what this means is I'm now sending ten packets and before",
    "start": "2825670",
    "end": "2832900"
  },
  {
    "text": "waiting for my first acknowledgment so I get all those out and what I've done by doing that is eliminated an entire round",
    "start": "2832900",
    "end": "2838809"
  },
  {
    "text": "trip from this request response so now my latency is dropped at P 52 to 41",
    "start": "2838809",
    "end": "2844619"
  },
  {
    "text": "let's keep going let's go to 16 packets now I'm down 161 milliseconds for my P",
    "start": "2844619",
    "end": "2850329"
  },
  {
    "text": "50 and as I'm doing this the actual effective bandwidth on my my neck is going up dramatically right I'm getting",
    "start": "2850329",
    "end": "2857109"
  },
  {
    "text": "a lot more utilization if I'm concerned about my optimizing my costs and how much how many requests I can handle on",
    "start": "2857109",
    "end": "2864009"
  },
  {
    "text": "an individual box this is starting to make a difference and so at a congestion window of 16 packets initial congestion",
    "start": "2864009",
    "end": "2870460"
  },
  {
    "text": "windows 15 packets I'm down to two round-trip times and that's probably about as good as you're gonna get",
    "start": "2870460",
    "end": "2875470"
  },
  {
    "text": "for initial brand-new TCP connection because you need one for our handshake of course and then one to actually",
    "start": "2875470",
    "end": "2882039"
  },
  {
    "text": "transfer the data and of course the bandwidth has now increased by 79",
    "start": "2882039",
    "end": "2887529"
  },
  {
    "text": "percent okay what do I hope you take away from this talk one is that the",
    "start": "2887529",
    "end": "2895900"
  },
  {
    "start": "2895000",
    "end": "3048000"
  },
  {
    "text": "network doesn't have to be a black box it can be pretty easy to blame a lot of",
    "start": "2895900",
    "end": "2901779"
  },
  {
    "text": "problems on the network o network problem transient resolved don't do that",
    "start": "2901779",
    "end": "2909890"
  },
  {
    "text": "take a look use tools figure out was it a network problem and where might it be",
    "start": "2909890",
    "end": "2915390"
  },
  {
    "text": "just because you're seeing packet loss does not necessarily mean that the middle of network caused it we can try",
    "start": "2915390",
    "end": "2921930"
  },
  {
    "text": "to track that down if you have middle boxes you want to try to figure out where you're you're introducing",
    "start": "2921930",
    "end": "2927000"
  },
  {
    "text": "retransmissions where you're losing packets and you want to figure out if I see sudden shifts in behavior in my in",
    "start": "2927000",
    "end": "2933150"
  },
  {
    "text": "my application is it even possible that it's networking that it's packet loss if you're not seeing any of retransmissions",
    "start": "2933150",
    "end": "2939920"
  },
  {
    "text": "chances are there's not any packet loss keep digging find the true recalls the second",
    "start": "2939920",
    "end": "2946800"
  },
  {
    "text": "takeaway is these tweaks are pretty simple and hopefully I'm gonna enable you to go from here and start playing",
    "start": "2946800",
    "end": "2952980"
  },
  {
    "text": "this isn't gonna take hours and hours you know I did these experiments fairly quickly and there are a lot of fun to",
    "start": "2952980",
    "end": "2959430"
  },
  {
    "text": "play around with now of course with any kind of performance tuning you want to",
    "start": "2959430",
    "end": "2964590"
  },
  {
    "text": "be very deliberate change one program at a time as close as you can test your",
    "start": "2964590",
    "end": "2969720"
  },
  {
    "text": "production use case if you can replicate if you have a production BBC can you create a test VPC that looks the same",
    "start": "2969720",
    "end": "2976109"
  },
  {
    "text": "where you can start playing around these try to use your exact data because a lot of performance troubleshooting is going",
    "start": "2976109",
    "end": "2982320"
  },
  {
    "text": "to be very very specific to the details that you're seeing in a production stack",
    "start": "2982320",
    "end": "2987710"
  },
  {
    "text": "and then finally understanding what your application needs from Network if it turns out that the send queue that the",
    "start": "2987710",
    "end": "2996000"
  },
  {
    "text": "sockets addictive tool is telling me is zero does that mean the network is a",
    "start": "2996000",
    "end": "3001730"
  },
  {
    "text": "problem no maybe my network has some global mutex and it's budding against",
    "start": "3001730",
    "end": "3006890"
  },
  {
    "text": "itself is it really blocked on the network maybe it's spending most of its time reading bytes from disk and then",
    "start": "3006890",
    "end": "3013460"
  },
  {
    "text": "sending the network and if you're not measuring those individually if you're measuring them together then you might say oh it's not my problem",
    "start": "3013460",
    "end": "3019310"
  },
  {
    "text": "but it might not be so make sure when you're benchmarking when you when you're benchmarking that as much as you can",
    "start": "3019310",
    "end": "3025790"
  },
  {
    "text": "isolate the networking effects to make sure that you can effectively kind of",
    "start": "3025790",
    "end": "3030980"
  },
  {
    "text": "triangulate where these problems are so thank you very much for coming I'm gonna",
    "start": "3030980",
    "end": "3036020"
  },
  {
    "text": "be up here in the front afterwards if you have a few questions please remember to fulfill your",
    "start": "3036020",
    "end": "3041300"
  },
  {
    "text": "evaluations tn Korea [Applause]",
    "start": "3041300",
    "end": "3049670"
  }
]
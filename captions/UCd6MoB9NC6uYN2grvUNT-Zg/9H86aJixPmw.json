[
  {
    "start": "0",
    "end": "149000"
  },
  {
    "text": "hi everyone my name is Florian and today",
    "start": "599",
    "end": "3360"
  },
  {
    "text": "I'm gonna show you how we built our",
    "start": "3360",
    "end": "5339"
  },
  {
    "text": "first Kafka connector and how we deploy",
    "start": "5339",
    "end": "8040"
  },
  {
    "text": "it to the cloud by using Amazon msk",
    "start": "8040",
    "end": "10440"
  },
  {
    "text": "connect",
    "start": "10440",
    "end": "12059"
  },
  {
    "text": "but first let us understand better what",
    "start": "12059",
    "end": "15120"
  },
  {
    "text": "Kafka connect and msk connect actually",
    "start": "15120",
    "end": "17279"
  },
  {
    "text": "is",
    "start": "17279",
    "end": "18660"
  },
  {
    "text": "Kafka connect is part of the open source",
    "start": "18660",
    "end": "21359"
  },
  {
    "text": "Apache Kafka project and allows us to",
    "start": "21359",
    "end": "24119"
  },
  {
    "text": "build data Integrations for a variety of",
    "start": "24119",
    "end": "26640"
  },
  {
    "text": "systems such as databases key value",
    "start": "26640",
    "end": "29340"
  },
  {
    "text": "stores or file systems",
    "start": "29340",
    "end": "32758"
  },
  {
    "text": "connectors come in two different flavors",
    "start": "32759",
    "end": "34860"
  },
  {
    "text": "they can either be a source connector",
    "start": "34860",
    "end": "36960"
  },
  {
    "text": "which allow us to read records from a",
    "start": "36960",
    "end": "39360"
  },
  {
    "text": "source like a database and store them",
    "start": "39360",
    "end": "41579"
  },
  {
    "text": "into the Kafka cluster or as a sync",
    "start": "41579",
    "end": "44579"
  },
  {
    "text": "connector which allows us to read",
    "start": "44579",
    "end": "46739"
  },
  {
    "text": "records from our Kafka cluster and store",
    "start": "46739",
    "end": "49200"
  },
  {
    "text": "them in the external system like a",
    "start": "49200",
    "end": "51360"
  },
  {
    "text": "search index or a file system",
    "start": "51360",
    "end": "54539"
  },
  {
    "text": "under the hood a battery Kafka connects",
    "start": "54539",
    "end": "57300"
  },
  {
    "text": "runs workers that can execute your",
    "start": "57300",
    "end": "60780"
  },
  {
    "text": "connectors",
    "start": "60780",
    "end": "62039"
  },
  {
    "text": "one connector consists of one or more",
    "start": "62039",
    "end": "65338"
  },
  {
    "text": "tasks that are executed by Kafka connect",
    "start": "65339",
    "end": "69119"
  },
  {
    "text": "so how many tasks do you actually need",
    "start": "69119",
    "end": "71340"
  },
  {
    "text": "for your connector this will depend on",
    "start": "71340",
    "end": "74820"
  },
  {
    "text": "your Source or sync let's say we are",
    "start": "74820",
    "end": "77939"
  },
  {
    "text": "building a sync connector and we are",
    "start": "77939",
    "end": "79799"
  },
  {
    "text": "sending records from our cluster to a",
    "start": "79799",
    "end": "82439"
  },
  {
    "text": "database we might want to have the same",
    "start": "82439",
    "end": "85619"
  },
  {
    "text": "number of tasks as the number of",
    "start": "85619",
    "end": "88080"
  },
  {
    "text": "partitions our topic has",
    "start": "88080",
    "end": "90600"
  },
  {
    "text": "why do we want to have that if we have",
    "start": "90600",
    "end": "93060"
  },
  {
    "text": "more tasks we are have we have idle",
    "start": "93060",
    "end": "96360"
  },
  {
    "text": "tasks that will not process any",
    "start": "96360",
    "end": "98340"
  },
  {
    "text": "partitions of the Kafka topic if you",
    "start": "98340",
    "end": "101520"
  },
  {
    "text": "have less this might be an option here",
    "start": "101520",
    "end": "103740"
  },
  {
    "text": "but if you have very high throughput the",
    "start": "103740",
    "end": "106560"
  },
  {
    "text": "consumer that is running in Kafka",
    "start": "106560",
    "end": "108600"
  },
  {
    "text": "connect our connector might not be able",
    "start": "108600",
    "end": "111060"
  },
  {
    "text": "to keep up with the interest of the data",
    "start": "111060",
    "end": "114360"
  },
  {
    "text": "so what does Amazon msk connect actually",
    "start": "114360",
    "end": "117299"
  },
  {
    "text": "does here msk connect is basically a",
    "start": "117299",
    "end": "121020"
  },
  {
    "text": "fully managed Kafka connector",
    "start": "121020",
    "end": "122939"
  },
  {
    "text": "environment it allows you to easily",
    "start": "122939",
    "end": "124920"
  },
  {
    "text": "deploy manage scale and monitor your",
    "start": "124920",
    "end": "129060"
  },
  {
    "text": "Kafka connectors on AWS",
    "start": "129060",
    "end": "132239"
  },
  {
    "text": "msk connect will handle Auto scaling for",
    "start": "132239",
    "end": "135420"
  },
  {
    "text": "you and will scale your connectors on a",
    "start": "135420",
    "end": "138060"
  },
  {
    "text": "predefined CPU usage",
    "start": "138060",
    "end": "141860"
  },
  {
    "text": "so let's get back to our own connector",
    "start": "142200",
    "end": "144959"
  },
  {
    "text": "what are we actually building in today's",
    "start": "144959",
    "end": "146819"
  },
  {
    "text": "session",
    "start": "146819",
    "end": "147840"
  },
  {
    "text": "we will build a sync connector that",
    "start": "147840",
    "end": "150360"
  },
  {
    "start": "149000",
    "end": "1418000"
  },
  {
    "text": "allows us to send records from Kafka to",
    "start": "150360",
    "end": "153180"
  },
  {
    "text": "Amazon event Bridge",
    "start": "153180",
    "end": "154800"
  },
  {
    "text": "Amazon event Bridge is a fully managed",
    "start": "154800",
    "end": "157080"
  },
  {
    "text": "event bus that can handle thousands of",
    "start": "157080",
    "end": "159660"
  },
  {
    "text": "Records per second and send them to",
    "start": "159660",
    "end": "162060"
  },
  {
    "text": "Downstream processes or applications",
    "start": "162060",
    "end": "165540"
  },
  {
    "text": "if you're building event-driven",
    "start": "165540",
    "end": "167099"
  },
  {
    "text": "architectures you might have used",
    "start": "167099",
    "end": "168959"
  },
  {
    "text": "already a budget Kafka or eventbridge",
    "start": "168959",
    "end": "172140"
  },
  {
    "text": "and with this connector you can use both",
    "start": "172140",
    "end": "174420"
  },
  {
    "text": "now together to integrate even more",
    "start": "174420",
    "end": "176519"
  },
  {
    "text": "systems in your landscape",
    "start": "176519",
    "end": "179940"
  },
  {
    "text": "for our connector we will have an ec2",
    "start": "179940",
    "end": "183239"
  },
  {
    "text": "instance that is interesting data into",
    "start": "183239",
    "end": "186300"
  },
  {
    "text": "our battery Kafka cluster it will also",
    "start": "186300",
    "end": "189060"
  },
  {
    "text": "use the glue schema registry provided by",
    "start": "189060",
    "end": "191700"
  },
  {
    "text": "AWS where we can score store our Avro",
    "start": "191700",
    "end": "195420"
  },
  {
    "text": "schemas",
    "start": "195420",
    "end": "197400"
  },
  {
    "text": "on the other hand we will have our Kafka",
    "start": "197400",
    "end": "200040"
  },
  {
    "text": "Connector running on msk connect which",
    "start": "200040",
    "end": "203459"
  },
  {
    "text": "reads the schema from AWS glue and then",
    "start": "203459",
    "end": "206099"
  },
  {
    "text": "sends the records Downstream to Amazon",
    "start": "206099",
    "end": "208379"
  },
  {
    "text": "event Bridge",
    "start": "208379",
    "end": "211099"
  },
  {
    "text": "enough of the slides let's get up our",
    "start": "211800",
    "end": "214260"
  },
  {
    "text": "IDE and look at the code that we need",
    "start": "214260",
    "end": "216360"
  },
  {
    "text": "for our Kafka connector",
    "start": "216360",
    "end": "218580"
  },
  {
    "text": "so here's my Java project for our Kafka",
    "start": "218580",
    "end": "221879"
  },
  {
    "text": "connector let's stick into the source",
    "start": "221879",
    "end": "223920"
  },
  {
    "text": "code on what we actually need to build",
    "start": "223920",
    "end": "225900"
  },
  {
    "text": "the connector",
    "start": "225900",
    "end": "227580"
  },
  {
    "text": "I'm going to open up my source here and",
    "start": "227580",
    "end": "230099"
  },
  {
    "text": "as you can see I have five Java classes",
    "start": "230099",
    "end": "232440"
  },
  {
    "text": "available",
    "start": "232440",
    "end": "234319"
  },
  {
    "text": "all those five are not mandatory for",
    "start": "234319",
    "end": "236819"
  },
  {
    "text": "building a connector but I will walk you",
    "start": "236819",
    "end": "239099"
  },
  {
    "text": "through all of them on how we build our",
    "start": "239099",
    "end": "241799"
  },
  {
    "text": "event Bridge connector",
    "start": "241799",
    "end": "244799"
  },
  {
    "text": "the main class is the eventbridge sync",
    "start": "244799",
    "end": "247019"
  },
  {
    "text": "connector",
    "start": "247019",
    "end": "249239"
  },
  {
    "text": "we have several methods that we need to",
    "start": "249239",
    "end": "251159"
  },
  {
    "text": "implement here",
    "start": "251159",
    "end": "252239"
  },
  {
    "text": "for example we have a start method that",
    "start": "252239",
    "end": "254819"
  },
  {
    "text": "we need this is everything that happens",
    "start": "254819",
    "end": "257699"
  },
  {
    "text": "during the startup of the connector in",
    "start": "257699",
    "end": "260040"
  },
  {
    "text": "our case we're just setting some",
    "start": "260040",
    "end": "262139"
  },
  {
    "text": "properties from our connector",
    "start": "262139",
    "end": "265440"
  },
  {
    "text": "I will come back to this later on where",
    "start": "265440",
    "end": "268080"
  },
  {
    "text": "these properties come from and what we",
    "start": "268080",
    "end": "269820"
  },
  {
    "text": "actually use here",
    "start": "269820",
    "end": "271979"
  },
  {
    "text": "we also need a task class method which",
    "start": "271979",
    "end": "275100"
  },
  {
    "text": "actually defines what kind of task is",
    "start": "275100",
    "end": "278220"
  },
  {
    "text": "executed by the connector",
    "start": "278220",
    "end": "280259"
  },
  {
    "text": "if you remember from before a connector",
    "start": "280259",
    "end": "282840"
  },
  {
    "text": "can has can have one or more tasks and",
    "start": "282840",
    "end": "286440"
  },
  {
    "text": "this method actually tells our connector",
    "start": "286440",
    "end": "288180"
  },
  {
    "text": "what kind of task we are spawning",
    "start": "288180",
    "end": "292680"
  },
  {
    "text": "each task can connect to a different",
    "start": "292680",
    "end": "295860"
  },
  {
    "text": "let's say topic",
    "start": "295860",
    "end": "298440"
  },
  {
    "text": "um or not actually not a topic but a",
    "start": "298440",
    "end": "300840"
  },
  {
    "text": "different part of a topic like a",
    "start": "300840",
    "end": "302759"
  },
  {
    "text": "partition or if you're building a source",
    "start": "302759",
    "end": "305699"
  },
  {
    "text": "connector each task might reach from a",
    "start": "305699",
    "end": "308520"
  },
  {
    "text": "different database table",
    "start": "308520",
    "end": "310500"
  },
  {
    "text": "so each task needs actually its own",
    "start": "310500",
    "end": "313139"
  },
  {
    "text": "config so it knows where to read the",
    "start": "313139",
    "end": "315120"
  },
  {
    "text": "data from or where to send it",
    "start": "315120",
    "end": "317759"
  },
  {
    "text": "so this is why we need to task configs",
    "start": "317759",
    "end": "320900"
  },
  {
    "text": "method and we just generate a number of",
    "start": "320900",
    "end": "324539"
  },
  {
    "text": "configurations here",
    "start": "324539",
    "end": "326880"
  },
  {
    "text": "this is more complicated if you're",
    "start": "326880",
    "end": "329100"
  },
  {
    "text": "building a source connector so you need",
    "start": "329100",
    "end": "331919"
  },
  {
    "text": "probably an external thread that is",
    "start": "331919",
    "end": "334139"
  },
  {
    "text": "monitoring The Source system let's say",
    "start": "334139",
    "end": "336660"
  },
  {
    "text": "for example we are having",
    "start": "336660",
    "end": "339120"
  },
  {
    "text": "a SQL database with five tables and",
    "start": "339120",
    "end": "342720"
  },
  {
    "text": "somebody creates a new table on this",
    "start": "342720",
    "end": "344759"
  },
  {
    "text": "database our connector will not",
    "start": "344759",
    "end": "347160"
  },
  {
    "text": "magically know that there's a new table",
    "start": "347160",
    "end": "348780"
  },
  {
    "text": "now there so we need to implement an",
    "start": "348780",
    "end": "351780"
  },
  {
    "text": "external monitoring thread that would",
    "start": "351780",
    "end": "353940"
  },
  {
    "text": "say hey there's a new table available",
    "start": "353940",
    "end": "356820"
  },
  {
    "text": "we need to add this configuration to our",
    "start": "356820",
    "end": "360360"
  },
  {
    "text": "connector",
    "start": "360360",
    "end": "361800"
  },
  {
    "text": "for a sync connector that we are",
    "start": "361800",
    "end": "363720"
  },
  {
    "text": "building here this is not much much",
    "start": "363720",
    "end": "365699"
  },
  {
    "text": "relevant because the battery Kafka",
    "start": "365699",
    "end": "367680"
  },
  {
    "text": "connect will just handle the number of",
    "start": "367680",
    "end": "370080"
  },
  {
    "text": "partitions that we have in a Kafka topic",
    "start": "370080",
    "end": "372419"
  },
  {
    "text": "itself so if we create a topic with 10",
    "start": "372419",
    "end": "375600"
  },
  {
    "text": "partitions",
    "start": "375600",
    "end": "377580"
  },
  {
    "text": "kapha connect will not spawn more than",
    "start": "377580",
    "end": "380820"
  },
  {
    "text": "10",
    "start": "380820",
    "end": "381660"
  },
  {
    "text": "tasks for this partition or for this",
    "start": "381660",
    "end": "384600"
  },
  {
    "text": "topic",
    "start": "384600",
    "end": "386900"
  },
  {
    "text": "we also have a config method",
    "start": "387060",
    "end": "389580"
  },
  {
    "text": "this returns our config for the",
    "start": "389580",
    "end": "392400"
  },
  {
    "text": "connector we also have a version method",
    "start": "392400",
    "end": "394800"
  },
  {
    "text": "implemented",
    "start": "394800",
    "end": "396479"
  },
  {
    "text": "it actually gives us right now the",
    "start": "396479",
    "end": "399720"
  },
  {
    "text": "Apache Kafka version but you can also",
    "start": "399720",
    "end": "402000"
  },
  {
    "text": "Implement our logic to have a",
    "start": "402000",
    "end": "404060"
  },
  {
    "text": "representation of a versioning from our",
    "start": "404060",
    "end": "407220"
  },
  {
    "text": "connector",
    "start": "407220",
    "end": "409440"
  },
  {
    "text": "we also have a stop method we don't need",
    "start": "409440",
    "end": "412259"
  },
  {
    "text": "any",
    "start": "412259",
    "end": "413720"
  },
  {
    "text": "implementation here but if you implement",
    "start": "413720",
    "end": "416639"
  },
  {
    "text": "this partition Checker or monitoring",
    "start": "416639",
    "end": "419699"
  },
  {
    "text": "threat I mentioned before you need to",
    "start": "419699",
    "end": "422100"
  },
  {
    "text": "stop this external thread here",
    "start": "422100",
    "end": "425539"
  },
  {
    "text": "so this is our basic connector class",
    "start": "425940",
    "end": "427919"
  },
  {
    "text": "let's look at the config in more detail",
    "start": "427919",
    "end": "430860"
  },
  {
    "text": "that we are providing",
    "start": "430860",
    "end": "433638"
  },
  {
    "text": "so we are defining actually to config",
    "start": "434639",
    "end": "437400"
  },
  {
    "text": "parameters one is for the event bus Arn",
    "start": "437400",
    "end": "440759"
  },
  {
    "text": "Arn stands for Amazon resource name so",
    "start": "440759",
    "end": "444360"
  },
  {
    "text": "this is a unique ID that I've identifies",
    "start": "444360",
    "end": "446580"
  },
  {
    "text": "your event bus",
    "start": "446580",
    "end": "448919"
  },
  {
    "text": "we will need this so we know where to",
    "start": "448919",
    "end": "451380"
  },
  {
    "text": "send our records to and we will also",
    "start": "451380",
    "end": "453840"
  },
  {
    "text": "need an AWS regions barometer so we know",
    "start": "453840",
    "end": "457380"
  },
  {
    "text": "which AWS region our event bus is in",
    "start": "457380",
    "end": "461460"
  },
  {
    "text": "those are currently the only two",
    "start": "461460",
    "end": "463199"
  },
  {
    "text": "parameters that we are using",
    "start": "463199",
    "end": "465479"
  },
  {
    "text": "so we are adding those to our",
    "start": "465479",
    "end": "467400"
  },
  {
    "text": "configuration",
    "start": "467400",
    "end": "469620"
  },
  {
    "text": "those are from type string we can also",
    "start": "469620",
    "end": "471960"
  },
  {
    "text": "use other types like integer or even",
    "start": "471960",
    "end": "474900"
  },
  {
    "text": "more complex data types like arrays",
    "start": "474900",
    "end": "478860"
  },
  {
    "text": "we can also provide a short description",
    "start": "478860",
    "end": "480960"
  },
  {
    "text": "on what this parameter means and also we",
    "start": "480960",
    "end": "484380"
  },
  {
    "text": "have an importance here which basically",
    "start": "484380",
    "end": "486660"
  },
  {
    "text": "helps us to structure our documentation",
    "start": "486660",
    "end": "489000"
  },
  {
    "text": "for",
    "start": "489000",
    "end": "490800"
  },
  {
    "text": "um our parameters this does not",
    "start": "490800",
    "end": "493199"
  },
  {
    "text": "necessarily mean that this parameter is",
    "start": "493199",
    "end": "496020"
  },
  {
    "text": "mandatory it just is",
    "start": "496020",
    "end": "498960"
  },
  {
    "text": "um yeah like a ranking system within the",
    "start": "498960",
    "end": "500819"
  },
  {
    "text": "documentation",
    "start": "500819",
    "end": "503360"
  },
  {
    "text": "so we already covered the connector and",
    "start": "503759",
    "end": "506940"
  },
  {
    "text": "the configuration",
    "start": "506940",
    "end": "508379"
  },
  {
    "text": "so let's see what our task is actually",
    "start": "508379",
    "end": "510539"
  },
  {
    "text": "doing which sends the records from",
    "start": "510539",
    "end": "514640"
  },
  {
    "text": "Kafka connect to our Amazon event Bridge",
    "start": "514640",
    "end": "520219"
  },
  {
    "text": "so during the startup we have a start",
    "start": "520260",
    "end": "522419"
  },
  {
    "text": "method which is doing all the stuff we",
    "start": "522419",
    "end": "524520"
  },
  {
    "text": "receive the configuration the task",
    "start": "524520",
    "end": "526680"
  },
  {
    "text": "configuration",
    "start": "526680",
    "end": "528839"
  },
  {
    "text": "and we instantiate a new class called",
    "start": "528839",
    "end": "532080"
  },
  {
    "text": "eventbridge writer as you can see we",
    "start": "532080",
    "end": "534779"
  },
  {
    "text": "have already on the left here so this is",
    "start": "534779",
    "end": "536880"
  },
  {
    "text": "a class that we wrote",
    "start": "536880",
    "end": "539459"
  },
  {
    "text": "which will then get instantiated",
    "start": "539459",
    "end": "543300"
  },
  {
    "text": "you also have a record reporter I will",
    "start": "543300",
    "end": "545640"
  },
  {
    "text": "come back to later what this actually",
    "start": "545640",
    "end": "547680"
  },
  {
    "text": "does",
    "start": "547680",
    "end": "550040"
  },
  {
    "text": "next we have the boot method this is",
    "start": "552660",
    "end": "555540"
  },
  {
    "text": "basically one of the most important",
    "start": "555540",
    "end": "557459"
  },
  {
    "text": "methods that we're implementing",
    "start": "557459",
    "end": "560279"
  },
  {
    "text": "right now all the records that are",
    "start": "560279",
    "end": "562980"
  },
  {
    "text": "received from Apache half car are",
    "start": "562980",
    "end": "564899"
  },
  {
    "text": "handled by Kafka connect and sent to",
    "start": "564899",
    "end": "567060"
  },
  {
    "text": "this boot method and this method",
    "start": "567060",
    "end": "569100"
  },
  {
    "text": "actually defines what happens to our",
    "start": "569100",
    "end": "572160"
  },
  {
    "text": "records and where and how do they end up",
    "start": "572160",
    "end": "574740"
  },
  {
    "text": "in our destination",
    "start": "574740",
    "end": "577880"
  },
  {
    "text": "so for",
    "start": "579240",
    "end": "580860"
  },
  {
    "text": "for this method we receive a collection",
    "start": "580860",
    "end": "583080"
  },
  {
    "text": "of sync records",
    "start": "583080",
    "end": "585540"
  },
  {
    "text": "and in our case we need to prepare them",
    "start": "585540",
    "end": "589800"
  },
  {
    "text": "before we can send them to our",
    "start": "589800",
    "end": "591120"
  },
  {
    "text": "destination system",
    "start": "591120",
    "end": "593220"
  },
  {
    "text": "so we mapped them to a different class",
    "start": "593220",
    "end": "595980"
  },
  {
    "text": "it's event Bridge writer record it's not",
    "start": "595980",
    "end": "598920"
  },
  {
    "text": "too much relevance what's in there it's",
    "start": "598920",
    "end": "600720"
  },
  {
    "text": "basically just a very small",
    "start": "600720",
    "end": "603060"
  },
  {
    "text": "um kind of a data class that says this",
    "start": "603060",
    "end": "605519"
  },
  {
    "text": "is the payload this is the record",
    "start": "605519",
    "end": "608399"
  },
  {
    "text": "um error codes and messaging so it's",
    "start": "608399",
    "end": "610680"
  },
  {
    "text": "just a wrapper around our Kafka records",
    "start": "610680",
    "end": "615680"
  },
  {
    "text": "after we have this list we will create",
    "start": "616380",
    "end": "620399"
  },
  {
    "text": "um",
    "start": "620399",
    "end": "621060"
  },
  {
    "text": "we will partition this or actually it's",
    "start": "621060",
    "end": "623279"
  },
  {
    "text": "a collection we will partition The",
    "start": "623279",
    "end": "624779"
  },
  {
    "text": "Collection which then creates a list we",
    "start": "624779",
    "end": "628200"
  },
  {
    "text": "will create lists with a length of 10 we",
    "start": "628200",
    "end": "630600"
  },
  {
    "text": "use this for batching so we send",
    "start": "630600",
    "end": "633240"
  },
  {
    "text": "batches of 10 records every time and not",
    "start": "633240",
    "end": "636300"
  },
  {
    "text": "every record once",
    "start": "636300",
    "end": "638940"
  },
  {
    "text": "this just reduces the overhead uh the",
    "start": "638940",
    "end": "641519"
  },
  {
    "text": "number of HTTP requests you're making",
    "start": "641519",
    "end": "643320"
  },
  {
    "text": "and so on so this increases our",
    "start": "643320",
    "end": "645600"
  },
  {
    "text": "throughput from our connector",
    "start": "645600",
    "end": "649160"
  },
  {
    "text": "all right so in this next step we are",
    "start": "651300",
    "end": "654240"
  },
  {
    "text": "actually",
    "start": "654240",
    "end": "655560"
  },
  {
    "text": "handling our records or actually sending",
    "start": "655560",
    "end": "659160"
  },
  {
    "text": "them to eventbridge",
    "start": "659160",
    "end": "662220"
  },
  {
    "text": "as you can see here we have our list and",
    "start": "662220",
    "end": "665160"
  },
  {
    "text": "we use a flat map operation so we",
    "start": "665160",
    "end": "668399"
  },
  {
    "text": "execute on each item our put items",
    "start": "668399",
    "end": "671820"
  },
  {
    "text": "method",
    "start": "671820",
    "end": "673920"
  },
  {
    "text": "so let's submit to our eventbridge",
    "start": "673920",
    "end": "676019"
  },
  {
    "text": "writer to see what this is going on here",
    "start": "676019",
    "end": "679800"
  },
  {
    "text": "we have a Constructor",
    "start": "679800",
    "end": "682500"
  },
  {
    "text": "put items",
    "start": "682500",
    "end": "684480"
  },
  {
    "text": "here we go",
    "start": "684480",
    "end": "686339"
  },
  {
    "text": "you see we are logging the size of our",
    "start": "686339",
    "end": "689339"
  },
  {
    "text": "list",
    "start": "689339",
    "end": "690959"
  },
  {
    "text": "this is usually 10 but if there is a",
    "start": "690959",
    "end": "693120"
  },
  {
    "text": "very low throughput we might have less",
    "start": "693120",
    "end": "695640"
  },
  {
    "text": "records",
    "start": "695640",
    "end": "697079"
  },
  {
    "text": "um maybe even one if it's very low",
    "start": "697079",
    "end": "699000"
  },
  {
    "text": "throughputs",
    "start": "699000",
    "end": "701160"
  },
  {
    "text": "so we are creating our records according",
    "start": "701160",
    "end": "703920"
  },
  {
    "text": "to the AWS Java SDK",
    "start": "703920",
    "end": "708240"
  },
  {
    "text": "and you can see here we are calling the",
    "start": "708240",
    "end": "710820"
  },
  {
    "text": "create put inventory uh put create put",
    "start": "710820",
    "end": "714000"
  },
  {
    "text": "events entry which basically creates",
    "start": "714000",
    "end": "717540"
  },
  {
    "text": "um",
    "start": "717540",
    "end": "718200"
  },
  {
    "text": "the Java type for our API call",
    "start": "718200",
    "end": "722700"
  },
  {
    "text": "as you can see we specify here our event",
    "start": "722700",
    "end": "725339"
  },
  {
    "text": "bus as a destination also it's just a",
    "start": "725339",
    "end": "728760"
  },
  {
    "text": "static name right now called Kafka",
    "start": "728760",
    "end": "731040"
  },
  {
    "text": "connect or detail type",
    "start": "731040",
    "end": "733500"
  },
  {
    "text": "which is a kind of a topic we have on",
    "start": "733500",
    "end": "736880"
  },
  {
    "text": "Amazon event Bridge",
    "start": "736880",
    "end": "739800"
  },
  {
    "text": "and we'll just use also a string and",
    "start": "739800",
    "end": "742980"
  },
  {
    "text": "detail is the actual payload of the",
    "start": "742980",
    "end": "745140"
  },
  {
    "text": "record",
    "start": "745140",
    "end": "745980"
  },
  {
    "text": "itself",
    "start": "745980",
    "end": "747180"
  },
  {
    "text": "so as you can see here we're using our",
    "start": "747180",
    "end": "749820"
  },
  {
    "text": "data class and just get our record from",
    "start": "749820",
    "end": "752519"
  },
  {
    "text": "there",
    "start": "752519",
    "end": "754700"
  },
  {
    "text": "we also have a little helper method here",
    "start": "756300",
    "end": "758040"
  },
  {
    "text": "which is called create Json payload",
    "start": "758040",
    "end": "760860"
  },
  {
    "text": "So within Kafka you can use several data",
    "start": "760860",
    "end": "763620"
  },
  {
    "text": "formats like Json even strings protobuf",
    "start": "763620",
    "end": "768240"
  },
  {
    "text": "afro and so on",
    "start": "768240",
    "end": "770339"
  },
  {
    "text": "but we don't want to get in all this",
    "start": "770339",
    "end": "772139"
  },
  {
    "text": "serialization and deservation stuff so",
    "start": "772139",
    "end": "775019"
  },
  {
    "text": "Kafka connect also handles this for us",
    "start": "775019",
    "end": "778680"
  },
  {
    "text": "this is why we have this",
    "start": "778680",
    "end": "781220"
  },
  {
    "text": "Kafka sync record type",
    "start": "781220",
    "end": "784079"
  },
  {
    "text": "as you can see here",
    "start": "784079",
    "end": "786240"
  },
  {
    "text": "we have a sync record type and this",
    "start": "786240",
    "end": "788339"
  },
  {
    "text": "actually gives us the record type",
    "start": "788339",
    "end": "789600"
  },
  {
    "text": "independent from the data format that we",
    "start": "789600",
    "end": "792300"
  },
  {
    "text": "are using",
    "start": "792300",
    "end": "793800"
  },
  {
    "text": "and from that data format from sync",
    "start": "793800",
    "end": "796019"
  },
  {
    "text": "record",
    "start": "796019",
    "end": "798200"
  },
  {
    "text": "we can actually create our Json payload",
    "start": "798899",
    "end": "801540"
  },
  {
    "text": "why is it Json",
    "start": "801540",
    "end": "804839"
  },
  {
    "text": "because eventbridge only speaks Json so",
    "start": "804839",
    "end": "807480"
  },
  {
    "text": "we need to convert our sync record to a",
    "start": "807480",
    "end": "810600"
  },
  {
    "text": "Json string this is what we're doing",
    "start": "810600",
    "end": "813120"
  },
  {
    "text": "here we are reading right now it's only",
    "start": "813120",
    "end": "816620"
  },
  {
    "text": "the value so we're just not propagating",
    "start": "816620",
    "end": "820139"
  },
  {
    "text": "any headers or keys right now but you",
    "start": "820139",
    "end": "823019"
  },
  {
    "text": "would also implement this here",
    "start": "823019",
    "end": "825660"
  },
  {
    "text": "so we are using this to send our records",
    "start": "825660",
    "end": "828300"
  },
  {
    "text": "or prepare our records in Json format",
    "start": "828300",
    "end": "832200"
  },
  {
    "text": "coming back to that our request entry is",
    "start": "832200",
    "end": "835260"
  },
  {
    "text": "built everything is ready",
    "start": "835260",
    "end": "839040"
  },
  {
    "text": "so we can build our request",
    "start": "839040",
    "end": "842519"
  },
  {
    "text": "um I'll put events we put events entries",
    "start": "842519",
    "end": "845639"
  },
  {
    "text": "this is usually a list or this is a list",
    "start": "845639",
    "end": "848459"
  },
  {
    "text": "with a size of 0 to 10. depending on how",
    "start": "848459",
    "end": "852959"
  },
  {
    "text": "many records we received",
    "start": "852959",
    "end": "854579"
  },
  {
    "text": "and then we actually call the put events",
    "start": "854579",
    "end": "857279"
  },
  {
    "text": "method on the eventbridge client to send",
    "start": "857279",
    "end": "859560"
  },
  {
    "text": "the records from the connector to",
    "start": "859560",
    "end": "861779"
  },
  {
    "text": "eventbridge",
    "start": "861779",
    "end": "864180"
  },
  {
    "text": "we will also do some error handling here",
    "start": "864180",
    "end": "865980"
  },
  {
    "text": "I don't want to go into much detail on",
    "start": "865980",
    "end": "868200"
  },
  {
    "text": "what we do here",
    "start": "868200",
    "end": "869579"
  },
  {
    "text": "but we will get a positive response from",
    "start": "869579",
    "end": "872279"
  },
  {
    "text": "eventbridge even though the records",
    "start": "872279",
    "end": "874680"
  },
  {
    "text": "failed so this is why we need to mark",
    "start": "874680",
    "end": "876660"
  },
  {
    "text": "them as failed and we can enter enter a",
    "start": "876660",
    "end": "880320"
  },
  {
    "text": "status into the record if it's failed or",
    "start": "880320",
    "end": "883079"
  },
  {
    "text": "not and retry later if you want to this",
    "start": "883079",
    "end": "885720"
  },
  {
    "text": "is a bit more advanced for your first",
    "start": "885720",
    "end": "887639"
  },
  {
    "text": "prototype you probably don't need that",
    "start": "887639",
    "end": "889800"
  },
  {
    "text": "but for a production ready connector you",
    "start": "889800",
    "end": "893339"
  },
  {
    "text": "would definitely want to implement",
    "start": "893339",
    "end": "894600"
  },
  {
    "text": "something like retrying",
    "start": "894600",
    "end": "896579"
  },
  {
    "text": "if an exponential back off or any kind",
    "start": "896579",
    "end": "899940"
  },
  {
    "text": "of other strategy to handle failed",
    "start": "899940",
    "end": "902160"
  },
  {
    "text": "records",
    "start": "902160",
    "end": "904019"
  },
  {
    "text": "in our case if an event fails several",
    "start": "904019",
    "end": "907320"
  },
  {
    "text": "times",
    "start": "907320",
    "end": "909240"
  },
  {
    "text": "we will handle this as well we will just",
    "start": "909240",
    "end": "912360"
  },
  {
    "text": "write them to our record reporter",
    "start": "912360",
    "end": "915720"
  },
  {
    "text": "so you're asking probably what is a",
    "start": "915720",
    "end": "917940"
  },
  {
    "text": "errand record reporter this is a logic",
    "start": "917940",
    "end": "920699"
  },
  {
    "text": "that Kafka connect provides us for",
    "start": "920699",
    "end": "923279"
  },
  {
    "text": "handling ever records",
    "start": "923279",
    "end": "925500"
  },
  {
    "text": "you're probably familiar with the",
    "start": "925500",
    "end": "927060"
  },
  {
    "text": "concept of a debt letter Q if you're",
    "start": "927060",
    "end": "929399"
  },
  {
    "text": "handling records in a streaming or",
    "start": "929399",
    "end": "931560"
  },
  {
    "text": "messaging system you usually send them",
    "start": "931560",
    "end": "933779"
  },
  {
    "text": "somewhere else for manual inspection or",
    "start": "933779",
    "end": "936720"
  },
  {
    "text": "for other processing systems",
    "start": "936720",
    "end": "939240"
  },
  {
    "text": "so in this case Kafka connect implements",
    "start": "939240",
    "end": "941579"
  },
  {
    "text": "the logic already for for us and we just",
    "start": "941579",
    "end": "945000"
  },
  {
    "text": "need to instruct Kafka connect to do it",
    "start": "945000",
    "end": "948720"
  },
  {
    "text": "so if we have a configuration available",
    "start": "948720",
    "end": "952019"
  },
  {
    "text": "where to send our records this is",
    "start": "952019",
    "end": "954420"
  },
  {
    "text": "usually a Kafka topic we will just add",
    "start": "954420",
    "end": "957000"
  },
  {
    "text": "our records and then report them",
    "start": "957000",
    "end": "961019"
  },
  {
    "text": "through this errand record report and",
    "start": "961019",
    "end": "964320"
  },
  {
    "text": "then kafa connect will automatically",
    "start": "964320",
    "end": "966000"
  },
  {
    "text": "handle to send those records into the",
    "start": "966000",
    "end": "969779"
  },
  {
    "text": "predefined Kafka error topic",
    "start": "969779",
    "end": "972839"
  },
  {
    "text": "of course we could also Implement some",
    "start": "972839",
    "end": "974639"
  },
  {
    "text": "other logic like send it to a queue or",
    "start": "974639",
    "end": "978060"
  },
  {
    "text": "to an excellent system like S3 but this",
    "start": "978060",
    "end": "981000"
  },
  {
    "text": "is the predefined method that we have",
    "start": "981000",
    "end": "982680"
  },
  {
    "text": "available in Kafka connect already",
    "start": "982680",
    "end": "986720"
  },
  {
    "text": "so that was a very quick run through to",
    "start": "988440",
    "end": "990779"
  },
  {
    "text": "the code let's actually start start",
    "start": "990779",
    "end": "993660"
  },
  {
    "text": "um trying it out let's see if everything",
    "start": "993660",
    "end": "995399"
  },
  {
    "text": "works",
    "start": "995399",
    "end": "997019"
  },
  {
    "text": "so we're using Maven here so as a first",
    "start": "997019",
    "end": "999540"
  },
  {
    "text": "step I can use the maven commands to",
    "start": "999540",
    "end": "1003019"
  },
  {
    "text": "build my jar file",
    "start": "1003019",
    "end": "1005660"
  },
  {
    "text": "this might take a few seconds",
    "start": "1005660",
    "end": "1007820"
  },
  {
    "text": "and for local testing we're actually",
    "start": "1007820",
    "end": "1011000"
  },
  {
    "text": "using Docker compose",
    "start": "1011000",
    "end": "1012800"
  },
  {
    "text": "the docker compose is basically",
    "start": "1012800",
    "end": "1016279"
  },
  {
    "text": "um yeah part of the docker CLI and",
    "start": "1016279",
    "end": "1019100"
  },
  {
    "text": "allows you to spin up several services",
    "start": "1019100",
    "end": "1021040"
  },
  {
    "text": "within one definition file",
    "start": "1021040",
    "end": "1024918"
  },
  {
    "text": "so we're spinning up a Kafka cluster",
    "start": "1024919",
    "end": "1027620"
  },
  {
    "text": "and we're also spinning up a connect",
    "start": "1027620",
    "end": "1030319"
  },
  {
    "text": "cluster",
    "start": "1030319",
    "end": "1032980"
  },
  {
    "text": "this will have some pretty fine configs",
    "start": "1034520",
    "end": "1036740"
  },
  {
    "text": "there and so on",
    "start": "1036740",
    "end": "1039140"
  },
  {
    "text": "all right our builds worked let's run",
    "start": "1039140",
    "end": "1043880"
  },
  {
    "text": "docker",
    "start": "1043880",
    "end": "1046880"
  },
  {
    "text": "container",
    "start": "1048580",
    "end": "1050540"
  },
  {
    "text": "prune first to clean everything that we",
    "start": "1050540",
    "end": "1052820"
  },
  {
    "text": "have available",
    "start": "1052820",
    "end": "1055179"
  },
  {
    "text": "all right this is done",
    "start": "1058100",
    "end": "1060320"
  },
  {
    "text": "so let's run",
    "start": "1060320",
    "end": "1062840"
  },
  {
    "text": "docker",
    "start": "1062840",
    "end": "1064340"
  },
  {
    "text": "combos up this will start our Kafka",
    "start": "1064340",
    "end": "1067460"
  },
  {
    "text": "cluster and also our connect cluster",
    "start": "1067460",
    "end": "1071120"
  },
  {
    "text": "so in this case our connect cluster will",
    "start": "1071120",
    "end": "1073580"
  },
  {
    "text": "only run as one Docker container but you",
    "start": "1073580",
    "end": "1076100"
  },
  {
    "text": "could run your connect cluster in a",
    "start": "1076100",
    "end": "1077960"
  },
  {
    "text": "distributed mode on several instances",
    "start": "1077960",
    "end": "1082240"
  },
  {
    "text": "for testing our",
    "start": "1083660",
    "end": "1085760"
  },
  {
    "text": "connect connector I also created a",
    "start": "1085760",
    "end": "1089840"
  },
  {
    "text": "producer which is sending records to our",
    "start": "1089840",
    "end": "1092720"
  },
  {
    "text": "Kafka cluster",
    "start": "1092720",
    "end": "1094640"
  },
  {
    "text": "so basically sends this kind of data",
    "start": "1094640",
    "end": "1098179"
  },
  {
    "text": "it's very simple payload there's an IDE",
    "start": "1098179",
    "end": "1100640"
  },
  {
    "text": "credit card first name last name and",
    "start": "1100640",
    "end": "1102799"
  },
  {
    "text": "street address",
    "start": "1102799",
    "end": "1104120"
  },
  {
    "text": "to our Kafka cluster in Avro format",
    "start": "1104120",
    "end": "1109340"
  },
  {
    "text": "so we have the every class automatically",
    "start": "1109340",
    "end": "1112039"
  },
  {
    "text": "generated",
    "start": "1112039",
    "end": "1114380"
  },
  {
    "text": "so this is what it looks like and we",
    "start": "1114380",
    "end": "1116360"
  },
  {
    "text": "will send this data to our Kafka cluster",
    "start": "1116360",
    "end": "1121299"
  },
  {
    "text": "as you can see our Kafka connect cluster",
    "start": "1123260",
    "end": "1126620"
  },
  {
    "text": "is already starting",
    "start": "1126620",
    "end": "1128059"
  },
  {
    "text": "let's give it another second",
    "start": "1128059",
    "end": "1130400"
  },
  {
    "text": "until it's available",
    "start": "1130400",
    "end": "1133419"
  },
  {
    "text": "you also see here that we are loading",
    "start": "1135080",
    "end": "1137419"
  },
  {
    "text": "plugins from this share here",
    "start": "1137419",
    "end": "1139760"
  },
  {
    "text": "user share Java my first Kafka connector",
    "start": "1139760",
    "end": "1142700"
  },
  {
    "text": "so how we actually or what we actually",
    "start": "1142700",
    "end": "1145760"
  },
  {
    "text": "do here is that we have our Char file",
    "start": "1145760",
    "end": "1148820"
  },
  {
    "text": "from the connector which is called",
    "start": "1148820",
    "end": "1151160"
  },
  {
    "text": "eventbridge sync and this is mounted",
    "start": "1151160",
    "end": "1154160"
  },
  {
    "text": "into the docker container on this share",
    "start": "1154160",
    "end": "1157220"
  },
  {
    "text": "so this is how we move the jar file from",
    "start": "1157220",
    "end": "1159919"
  },
  {
    "text": "our local computer to our Docker",
    "start": "1159919",
    "end": "1163280"
  },
  {
    "text": "container",
    "start": "1163280",
    "end": "1165320"
  },
  {
    "text": "all right",
    "start": "1165320",
    "end": "1168100"
  },
  {
    "text": "so we have our",
    "start": "1168500",
    "end": "1170600"
  },
  {
    "text": "Java classes loaded from from the file",
    "start": "1170600",
    "end": "1175160"
  },
  {
    "text": "share that we gave you the original file",
    "start": "1175160",
    "end": "1177200"
  },
  {
    "text": "share but the mounts that we have from",
    "start": "1177200",
    "end": "1178760"
  },
  {
    "text": "our local machine",
    "start": "1178760",
    "end": "1180799"
  },
  {
    "text": "so now you need to submit",
    "start": "1180799",
    "end": "1183320"
  },
  {
    "text": "um the connector to the cluster itself",
    "start": "1183320",
    "end": "1186200"
  },
  {
    "text": "to do that you usually submit some",
    "start": "1186200",
    "end": "1190039"
  },
  {
    "text": "configuration",
    "start": "1190039",
    "end": "1192260"
  },
  {
    "text": "to your classroom yeah the rest API of",
    "start": "1192260",
    "end": "1196580"
  },
  {
    "text": "Kafka connects",
    "start": "1196580",
    "end": "1198620"
  },
  {
    "text": "so what do we actually need here we need",
    "start": "1198620",
    "end": "1201020"
  },
  {
    "text": "a name file connector and we provide a",
    "start": "1201020",
    "end": "1203360"
  },
  {
    "text": "config",
    "start": "1203360",
    "end": "1204500"
  },
  {
    "text": "so the config there's a mandatory Fields",
    "start": "1204500",
    "end": "1207559"
  },
  {
    "text": "like the connector class gives just the",
    "start": "1207559",
    "end": "1210380"
  },
  {
    "text": "name of the connector that we built",
    "start": "1210380",
    "end": "1213260"
  },
  {
    "text": "the topics that we read from in our case",
    "start": "1213260",
    "end": "1215539"
  },
  {
    "text": "it's just one but we could process",
    "start": "1215539",
    "end": "1217220"
  },
  {
    "text": "multiple topics with the same connector",
    "start": "1217220",
    "end": "1220640"
  },
  {
    "text": "the previously defined event bus Iran",
    "start": "1220640",
    "end": "1224179"
  },
  {
    "text": "so our destination same here for the",
    "start": "1224179",
    "end": "1226760"
  },
  {
    "text": "region and we also provide a maximum",
    "start": "1226760",
    "end": "1229460"
  },
  {
    "text": "number of tasks that we want to run",
    "start": "1229460",
    "end": "1233140"
  },
  {
    "text": "we also provide some civilization here",
    "start": "1233179",
    "end": "1235940"
  },
  {
    "text": "so our keys are just serialize the",
    "start": "1235940",
    "end": "1239120"
  },
  {
    "text": "string we are not processing any further",
    "start": "1239120",
    "end": "1241160"
  },
  {
    "text": "but we can use pretty much any converter",
    "start": "1241160",
    "end": "1245059"
  },
  {
    "text": "that is available for Kafka",
    "start": "1245059",
    "end": "1247820"
  },
  {
    "text": "for our value converter we use actually",
    "start": "1247820",
    "end": "1250840"
  },
  {
    "text": "the AWS Kafka Avro converter which is",
    "start": "1250840",
    "end": "1254240"
  },
  {
    "text": "part of the schema registry the AWS glue",
    "start": "1254240",
    "end": "1256700"
  },
  {
    "text": "schema ancestry",
    "start": "1256700",
    "end": "1258380"
  },
  {
    "text": "so we are telling kafra connect use this",
    "start": "1258380",
    "end": "1261679"
  },
  {
    "text": "converter use AWS region usd-1",
    "start": "1261679",
    "end": "1265940"
  },
  {
    "text": "and the schema name payload GSR Avro so",
    "start": "1265940",
    "end": "1269840"
  },
  {
    "text": "this means we are using",
    "start": "1269840",
    "end": "1272240"
  },
  {
    "text": "um the schema that is available in the",
    "start": "1272240",
    "end": "1273860"
  },
  {
    "text": "AWS glue schema accessory to deserialize",
    "start": "1273860",
    "end": "1277360"
  },
  {
    "text": "our sync record",
    "start": "1277360",
    "end": "1280460"
  },
  {
    "text": "into something readable",
    "start": "1280460",
    "end": "1283520"
  },
  {
    "text": "so let's see if everything started",
    "start": "1283520",
    "end": "1286940"
  },
  {
    "text": "you can see here finished starting",
    "start": "1286940",
    "end": "1289159"
  },
  {
    "text": "connectors and tasks this is pretty fast",
    "start": "1289159",
    "end": "1291559"
  },
  {
    "text": "because there is no connectors running",
    "start": "1291559",
    "end": "1294020"
  },
  {
    "text": "yet so let's submit our configuration to",
    "start": "1294020",
    "end": "1297260"
  },
  {
    "text": "our Kafka connect cluster for this I",
    "start": "1297260",
    "end": "1300020"
  },
  {
    "text": "will just use Curl",
    "start": "1300020",
    "end": "1302860"
  },
  {
    "text": "so I'm using curl to submit the Json",
    "start": "1303020",
    "end": "1306440"
  },
  {
    "text": "file",
    "start": "1306440",
    "end": "1307600"
  },
  {
    "text": "which is our overall to our localhost",
    "start": "1307600",
    "end": "1311020"
  },
  {
    "text": "8083 so this is the board that Kafka",
    "start": "1311020",
    "end": "1313520"
  },
  {
    "text": "connects is exposing",
    "start": "1313520",
    "end": "1316659"
  },
  {
    "text": "and submit that",
    "start": "1316760",
    "end": "1318980"
  },
  {
    "text": "we get a response here",
    "start": "1318980",
    "end": "1322179"
  },
  {
    "text": "all right let's see what our",
    "start": "1323059",
    "end": "1328039"
  },
  {
    "text": "connect cluster is doing",
    "start": "1328039",
    "end": "1330140"
  },
  {
    "text": "nothing to do yet because there are no",
    "start": "1330140",
    "end": "1332600"
  },
  {
    "text": "records available so let's start our",
    "start": "1332600",
    "end": "1334460"
  },
  {
    "text": "producer application to send in some",
    "start": "1334460",
    "end": "1336140"
  },
  {
    "text": "records",
    "start": "1336140",
    "end": "1337940"
  },
  {
    "text": "I was started here within in Delhi",
    "start": "1337940",
    "end": "1341419"
  },
  {
    "text": "topic already exists start sending some",
    "start": "1341419",
    "end": "1343820"
  },
  {
    "text": "records awesome",
    "start": "1343820",
    "end": "1346779"
  },
  {
    "text": "so let's go what's going on here and now",
    "start": "1346940",
    "end": "1349220"
  },
  {
    "text": "we see",
    "start": "1349220",
    "end": "1350299"
  },
  {
    "text": "um the logs from our connector sending",
    "start": "1350299",
    "end": "1353179"
  },
  {
    "text": "that to eventbridge",
    "start": "1353179",
    "end": "1355940"
  },
  {
    "text": "so if we see one record sending the",
    "start": "1355940",
    "end": "1357980"
  },
  {
    "text": "event bridge and the next log we see",
    "start": "1357980",
    "end": "1359720"
  },
  {
    "text": "four so this is the batching",
    "start": "1359720",
    "end": "1362419"
  },
  {
    "text": "um that I mentioned before that we are",
    "start": "1362419",
    "end": "1363799"
  },
  {
    "text": "doing within our connectors to increase",
    "start": "1363799",
    "end": "1366020"
  },
  {
    "text": "the throughput of our application",
    "start": "1366020",
    "end": "1368360"
  },
  {
    "text": "but as you see usually we're only",
    "start": "1368360",
    "end": "1370100"
  },
  {
    "text": "writing one record because we have very",
    "start": "1370100",
    "end": "1372500"
  },
  {
    "text": "low throughput from our producer",
    "start": "1372500",
    "end": "1376419"
  },
  {
    "text": "great so we are sending records to",
    "start": "1376700",
    "end": "1379640"
  },
  {
    "text": "Amazon event bridge in our AWS account",
    "start": "1379640",
    "end": "1382760"
  },
  {
    "text": "so that's the next step let's deploy",
    "start": "1382760",
    "end": "1384919"
  },
  {
    "text": "this connector to AWS by using Amazon",
    "start": "1384919",
    "end": "1387980"
  },
  {
    "text": "msk connect",
    "start": "1387980",
    "end": "1390940"
  },
  {
    "text": "let me stop our producer",
    "start": "1392240",
    "end": "1395240"
  },
  {
    "text": "I will also stop our",
    "start": "1395240",
    "end": "1398900"
  },
  {
    "text": "Kafka",
    "start": "1398900",
    "end": "1400900"
  },
  {
    "text": "connector and our Kafka cluster create",
    "start": "1400900",
    "end": "1404600"
  },
  {
    "text": "everything stop so let's move to the AWS",
    "start": "1404600",
    "end": "1407240"
  },
  {
    "text": "console so we can start getting get",
    "start": "1407240",
    "end": "1409700"
  },
  {
    "text": "started with Amazon NSK connect",
    "start": "1409700",
    "end": "1414158"
  },
  {
    "start": "1418000",
    "end": "1654000"
  },
  {
    "text": "all right here's the AWS console I'm",
    "start": "1418100",
    "end": "1420860"
  },
  {
    "text": "already in my AWS account as a first",
    "start": "1420860",
    "end": "1423260"
  },
  {
    "text": "step we need to upload the connector",
    "start": "1423260",
    "end": "1425360"
  },
  {
    "text": "into Amazon S3",
    "start": "1425360",
    "end": "1429020"
  },
  {
    "text": "so I created the buckets already where I",
    "start": "1429020",
    "end": "1432140"
  },
  {
    "text": "can where I store all my connectors",
    "start": "1432140",
    "end": "1434600"
  },
  {
    "text": "so let's upload the connector that we",
    "start": "1434600",
    "end": "1438200"
  },
  {
    "text": "just built from our local machine",
    "start": "1438200",
    "end": "1440480"
  },
  {
    "text": "add files",
    "start": "1440480",
    "end": "1443559"
  },
  {
    "text": "Eventbrite sync let's use that",
    "start": "1444500",
    "end": "1448100"
  },
  {
    "text": "and the download",
    "start": "1448100",
    "end": "1451059"
  },
  {
    "text": "all right this might take a second",
    "start": "1451880",
    "end": "1456280"
  },
  {
    "text": "all right our connector is uploaded so",
    "start": "1456919",
    "end": "1459440"
  },
  {
    "text": "let's start creating our connector",
    "start": "1459440",
    "end": "1461600"
  },
  {
    "text": "within the Amazon msk service",
    "start": "1461600",
    "end": "1464900"
  },
  {
    "text": "so the first thing we need to create is",
    "start": "1464900",
    "end": "1467299"
  },
  {
    "text": "a plugin a plugin is basically a",
    "start": "1467299",
    "end": "1469700"
  },
  {
    "text": "container that holds all our codes that",
    "start": "1469700",
    "end": "1472640"
  },
  {
    "text": "is necessary to execute the connector so",
    "start": "1472640",
    "end": "1475520"
  },
  {
    "text": "let's create a customized plugin",
    "start": "1475520",
    "end": "1478880"
  },
  {
    "text": "let's choose our S3 object that we just",
    "start": "1478880",
    "end": "1482960"
  },
  {
    "text": "uploaded",
    "start": "1482960",
    "end": "1485620"
  },
  {
    "text": "all right let's go with our object that",
    "start": "1486140",
    "end": "1489860"
  },
  {
    "text": "we uploaded choose that one",
    "start": "1489860",
    "end": "1493340"
  },
  {
    "text": "I'm gonna name it event Bridge",
    "start": "1493340",
    "end": "1496340"
  },
  {
    "text": "sync plugin",
    "start": "1496340",
    "end": "1499779"
  },
  {
    "text": "and create a plugin so there's no",
    "start": "1500780",
    "end": "1503299"
  },
  {
    "text": "configuration that we need we just need",
    "start": "1503299",
    "end": "1505220"
  },
  {
    "text": "to specify the Char file that we",
    "start": "1505220",
    "end": "1507620"
  },
  {
    "text": "uploaded to S3",
    "start": "1507620",
    "end": "1510580"
  },
  {
    "text": "let's give it a second so it's",
    "start": "1510620",
    "end": "1514640"
  },
  {
    "text": "our plugin is now active so let's start",
    "start": "1514640",
    "end": "1517340"
  },
  {
    "text": "with the connector creation",
    "start": "1517340",
    "end": "1520720"
  },
  {
    "text": "as a first step create connector we",
    "start": "1520880",
    "end": "1524299"
  },
  {
    "text": "already created the plugin so let's use",
    "start": "1524299",
    "end": "1526460"
  },
  {
    "text": "our eventbridge sync plugin",
    "start": "1526460",
    "end": "1529279"
  },
  {
    "text": "hit next we're going to name it",
    "start": "1529279",
    "end": "1531260"
  },
  {
    "text": "eventbridge",
    "start": "1531260",
    "end": "1533659"
  },
  {
    "text": "sync",
    "start": "1533659",
    "end": "1535820"
  },
  {
    "text": "we have an msk cluster available in our",
    "start": "1535820",
    "end": "1538340"
  },
  {
    "text": "AWS account so we we don't using",
    "start": "1538340",
    "end": "1541400"
  },
  {
    "text": "self-managed Apache Kafka cluster but of",
    "start": "1541400",
    "end": "1544100"
  },
  {
    "text": "course you could also use that",
    "start": "1544100",
    "end": "1546440"
  },
  {
    "text": "just make sure you have the network",
    "start": "1546440",
    "end": "1549020"
  },
  {
    "text": "connectivity available",
    "start": "1549020",
    "end": "1551600"
  },
  {
    "text": "we're going to use our msk serverless",
    "start": "1551600",
    "end": "1553520"
  },
  {
    "text": "cluster using Amazon IM Authentication",
    "start": "1553520",
    "end": "1558380"
  },
  {
    "text": "and next we need to specify our",
    "start": "1558380",
    "end": "1560779"
  },
  {
    "text": "connector configuration",
    "start": "1560779",
    "end": "1562700"
  },
  {
    "text": "so this is the same configuration that",
    "start": "1562700",
    "end": "1564440"
  },
  {
    "text": "we previously from provided as a Json",
    "start": "1564440",
    "end": "1567159"
  },
  {
    "text": "here it's just a key value pair so let",
    "start": "1567159",
    "end": "1570500"
  },
  {
    "text": "me just use the same again",
    "start": "1570500",
    "end": "1574840"
  },
  {
    "text": "we can Define our capacity as a next",
    "start": "1574880",
    "end": "1577220"
  },
  {
    "text": "step we can either use all the scales or",
    "start": "1577220",
    "end": "1579679"
  },
  {
    "text": "provisioned so either msk connect will",
    "start": "1579679",
    "end": "1582620"
  },
  {
    "text": "scale your connector based on CPU usage",
    "start": "1582620",
    "end": "1584659"
  },
  {
    "text": "or we just use the predefined number of",
    "start": "1584659",
    "end": "1587539"
  },
  {
    "text": "CPU",
    "start": "1587539",
    "end": "1588919"
  },
  {
    "text": "for now I will go with Provisions I will",
    "start": "1588919",
    "end": "1591919"
  },
  {
    "text": "use two CPUs and one worker so we have",
    "start": "1591919",
    "end": "1595760"
  },
  {
    "text": "one instance that is having two CPUs but",
    "start": "1595760",
    "end": "1598700"
  },
  {
    "text": "of course we could also increase this",
    "start": "1598700",
    "end": "1600320"
  },
  {
    "text": "number if we need more throughputs",
    "start": "1600320",
    "end": "1603620"
  },
  {
    "text": "I already created a role for that so I'm",
    "start": "1603620",
    "end": "1607039"
  },
  {
    "text": "using our connector role which allows",
    "start": "1607039",
    "end": "1609140"
  },
  {
    "text": "access to our Kafka cluster allows",
    "start": "1609140",
    "end": "1612260"
  },
  {
    "text": "access to our glue schema registry and",
    "start": "1612260",
    "end": "1615140"
  },
  {
    "text": "also to sending events to cloudwatch for",
    "start": "1615140",
    "end": "1617480"
  },
  {
    "text": "logging and sending our events to",
    "start": "1617480",
    "end": "1619340"
  },
  {
    "text": "eventbridge for processing",
    "start": "1619340",
    "end": "1622220"
  },
  {
    "text": "so we hit next",
    "start": "1622220",
    "end": "1624559"
  },
  {
    "text": "no additional configuration here needed",
    "start": "1624559",
    "end": "1626779"
  },
  {
    "text": "we were gonna send our logs to",
    "start": "1626779",
    "end": "1629600"
  },
  {
    "text": "Amazon cloudwatch so let's specify",
    "start": "1629600",
    "end": "1634400"
  },
  {
    "text": "a lock group that we're going to use",
    "start": "1634400",
    "end": "1636100"
  },
  {
    "text": "let's use the log group that I created",
    "start": "1636100",
    "end": "1639200"
  },
  {
    "text": "already",
    "start": "1639200",
    "end": "1641500"
  },
  {
    "text": "hit next we have an overview of our",
    "start": "1643700",
    "end": "1646520"
  },
  {
    "text": "creation of our configuration",
    "start": "1646520",
    "end": "1649279"
  },
  {
    "text": "and then we can hit create connector",
    "start": "1649279",
    "end": "1653260"
  },
  {
    "text": "so our connectors are created let's see",
    "start": "1653539",
    "end": "1656500"
  },
  {
    "start": "1654000",
    "end": "1721000"
  },
  {
    "text": "at the locks what our connector is doing",
    "start": "1656500",
    "end": "1660440"
  },
  {
    "text": "and if everything works as expected",
    "start": "1660440",
    "end": "1663740"
  },
  {
    "text": "so open up our log group",
    "start": "1663740",
    "end": "1666799"
  },
  {
    "text": "and Cloud watch",
    "start": "1666799",
    "end": "1669740"
  },
  {
    "text": "and we should see the same log messages",
    "start": "1669740",
    "end": "1672140"
  },
  {
    "text": "that we saw before with the send records",
    "start": "1672140",
    "end": "1674659"
  },
  {
    "text": "to Amazon event Bridge",
    "start": "1674659",
    "end": "1677539"
  },
  {
    "text": "so let's open our",
    "start": "1677539",
    "end": "1680480"
  },
  {
    "text": "events and as we can see we're",
    "start": "1680480",
    "end": "1683480"
  },
  {
    "text": "interesting now a lot more events than",
    "start": "1683480",
    "end": "1685460"
  },
  {
    "text": "previously so we see always the writing",
    "start": "1685460",
    "end": "1688520"
  },
  {
    "text": "10 records event Bridge log messages",
    "start": "1688520",
    "end": "1691220"
  },
  {
    "text": "and with that we're already at the end",
    "start": "1691220",
    "end": "1693260"
  },
  {
    "text": "we created our first Amazon msk",
    "start": "1693260",
    "end": "1696200"
  },
  {
    "text": "connector and we build a sync connector",
    "start": "1696200",
    "end": "1699140"
  },
  {
    "text": "to send records from Amazon msk",
    "start": "1699140",
    "end": "1701900"
  },
  {
    "text": "serverless to Amazon event Bridge",
    "start": "1701900",
    "end": "1704419"
  },
  {
    "text": "if you follow this tutorial make sure to",
    "start": "1704419",
    "end": "1706760"
  },
  {
    "text": "clean up any resources in your AWS",
    "start": "1706760",
    "end": "1708919"
  },
  {
    "text": "account otherwise see you at the next",
    "start": "1708919",
    "end": "1711740"
  },
  {
    "text": "session my name is Florian and thanks",
    "start": "1711740",
    "end": "1713720"
  },
  {
    "text": "for tuning in",
    "start": "1713720",
    "end": "1716320"
  }
]
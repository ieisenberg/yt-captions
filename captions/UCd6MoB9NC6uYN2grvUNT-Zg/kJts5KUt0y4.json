[
  {
    "start": "0",
    "end": "45000"
  },
  {
    "text": "hello everyone thank you for joining",
    "start": "799",
    "end": "2919"
  },
  {
    "text": "this demo let's start with a bit of",
    "start": "2919",
    "end": "5440"
  },
  {
    "text": "History before we jump into generative",
    "start": "5440",
    "end": "7680"
  },
  {
    "text": "AI topic 10 to 15 years back data",
    "start": "7680",
    "end": "11240"
  },
  {
    "text": "warehouses are primarily for batch",
    "start": "11240",
    "end": "13679"
  },
  {
    "text": "analytics over a period of time they",
    "start": "13679",
    "end": "16118"
  },
  {
    "text": "evoled to support realtime streaming",
    "start": "16119",
    "end": "18600"
  },
  {
    "text": "analytics and machine learning workloads",
    "start": "18600",
    "end": "21320"
  },
  {
    "text": "now the evolution took one more giant",
    "start": "21320",
    "end": "23599"
  },
  {
    "text": "step that is generative AI analytics",
    "start": "23599",
    "end": "26880"
  },
  {
    "text": "generative AI technology already making",
    "start": "26880",
    "end": "29400"
  },
  {
    "text": "huge imp in businesses and it has",
    "start": "29400",
    "end": "31880"
  },
  {
    "text": "potential to scale much higher with an",
    "start": "31880",
    "end": "34280"
  },
  {
    "text": "anticipated revenue of 4.4 trillions",
    "start": "34280",
    "end": "37760"
  },
  {
    "text": "annually let's see how a cloud data",
    "start": "37760",
    "end": "40120"
  },
  {
    "text": "warehouse such as Amazon redshift is",
    "start": "40120",
    "end": "42640"
  },
  {
    "text": "adapting to this",
    "start": "42640",
    "end": "45000"
  },
  {
    "start": "45000",
    "end": "59000"
  },
  {
    "text": "technology myself Sati sonti senior",
    "start": "45000",
    "end": "47960"
  },
  {
    "text": "specialist solution architect at AWS in",
    "start": "47960",
    "end": "51039"
  },
  {
    "text": "this session I'll walk you through red",
    "start": "51039",
    "end": "53559"
  },
  {
    "text": "shift generative AA capabilities",
    "start": "53559",
    "end": "55399"
  },
  {
    "text": "particularly the integration with Amazon",
    "start": "55399",
    "end": "58280"
  },
  {
    "text": "bedrock in this slide you see various",
    "start": "58280",
    "end": "61039"
  },
  {
    "start": "59000",
    "end": "127000"
  },
  {
    "text": "red shift features ranging from",
    "start": "61039",
    "end": "62840"
  },
  {
    "text": "injection options data sharing",
    "start": "62840",
    "end": "64640"
  },
  {
    "text": "capabilities and consumption features we",
    "start": "64640",
    "end": "67960"
  },
  {
    "text": "not go in depth into each of these",
    "start": "67960",
    "end": "70200"
  },
  {
    "text": "features but the one which is of focus",
    "start": "70200",
    "end": "72600"
  },
  {
    "text": "for this session is red shift AI ml",
    "start": "72600",
    "end": "76119"
  },
  {
    "text": "integration capabilities we'll dive deep",
    "start": "76119",
    "end": "78920"
  },
  {
    "text": "into this in in this session with a",
    "start": "78920",
    "end": "82640"
  },
  {
    "text": "demo if we zoom into red shift",
    "start": "82640",
    "end": "85000"
  },
  {
    "text": "generative a capabilities there are",
    "start": "85000",
    "end": "87079"
  },
  {
    "text": "largely three integration patterns that",
    "start": "87079",
    "end": "88840"
  },
  {
    "text": "are currently supported",
    "start": "88840",
    "end": "90520"
  },
  {
    "text": "you can have llms in Amazon Bedrock",
    "start": "90520",
    "end": "93360"
  },
  {
    "text": "deployed in sagemaker jumpstart or in",
    "start": "93360",
    "end": "95799"
  },
  {
    "text": "Sage maker and use those llms with red",
    "start": "95799",
    "end": "99360"
  },
  {
    "text": "shift native integration with all these",
    "start": "99360",
    "end": "101280"
  },
  {
    "text": "three",
    "start": "101280",
    "end": "102560"
  },
  {
    "text": "services these three integration",
    "start": "102560",
    "end": "104680"
  },
  {
    "text": "patterns have varying degree of",
    "start": "104680",
    "end": "106320"
  },
  {
    "text": "customization and ease of use if you",
    "start": "106320",
    "end": "108920"
  },
  {
    "text": "take Amazon Bedrock which we going to",
    "start": "108920",
    "end": "110680"
  },
  {
    "text": "demo in this session the service is",
    "start": "110680",
    "end": "113880"
  },
  {
    "text": "fully managed uh you don't need to",
    "start": "113880",
    "end": "115680"
  },
  {
    "text": "manage the",
    "start": "115680",
    "end": "116759"
  },
  {
    "text": "infrastructure and you can access those",
    "start": "116759",
    "end": "119439"
  },
  {
    "text": "l just by enabling the access to the",
    "start": "119439",
    "end": "122200"
  },
  {
    "text": "users and start running the generative",
    "start": "122200",
    "end": "124719"
  },
  {
    "text": "AI",
    "start": "124719",
    "end": "126399"
  },
  {
    "text": "analytics let's see the demo of the",
    "start": "126399",
    "end": "128479"
  },
  {
    "start": "127000",
    "end": "187000"
  },
  {
    "text": "first integration pattern in this",
    "start": "128479",
    "end": "131319"
  },
  {
    "text": "session we take a healthcare industry",
    "start": "131319",
    "end": "133959"
  },
  {
    "text": "use case uh for this",
    "start": "133959",
    "end": "136200"
  },
  {
    "text": "demo as part of this demo we will",
    "start": "136200",
    "end": "138560"
  },
  {
    "text": "generate personalized diet plan for",
    "start": "138560",
    "end": "141120"
  },
  {
    "text": "patients based on their conditions and",
    "start": "141120",
    "end": "143319"
  },
  {
    "text": "the medications they are",
    "start": "143319",
    "end": "145280"
  },
  {
    "text": "taking it's a very straightforward",
    "start": "145280",
    "end": "147400"
  },
  {
    "text": "integration you have your data in Amazon",
    "start": "147400",
    "end": "149280"
  },
  {
    "text": "red shift and your model in Amazon",
    "start": "149280",
    "end": "152080"
  },
  {
    "text": "Bedrock as a first step you will enable",
    "start": "152080",
    "end": "155120"
  },
  {
    "text": "the llm model access in Amazon Bedrock",
    "start": "155120",
    "end": "158560"
  },
  {
    "text": "then the second step is to load sample",
    "start": "158560",
    "end": "160959"
  },
  {
    "text": "patients data into red shift and you",
    "start": "160959",
    "end": "163440"
  },
  {
    "text": "need to prepare the prompt to pass it on",
    "start": "163440",
    "end": "165879"
  },
  {
    "text": "to the U llm deployed in Bedrock so you",
    "start": "165879",
    "end": "170360"
  },
  {
    "text": "do little bit of prompt engineering then",
    "start": "170360",
    "end": "172640"
  },
  {
    "text": "you'll create a model referencing the",
    "start": "172640",
    "end": "174480"
  },
  {
    "text": "llm sitting in Bedrock then your initial",
    "start": "174480",
    "end": "177920"
  },
  {
    "text": "setup is done after that you will get a",
    "start": "177920",
    "end": "179879"
  },
  {
    "text": "a function which you keep using in your",
    "start": "179879",
    "end": "181599"
  },
  {
    "text": "SQL statements to generate the",
    "start": "181599",
    "end": "184200"
  },
  {
    "text": "personalized di plan for the patients",
    "start": "184200",
    "end": "187480"
  },
  {
    "start": "187000",
    "end": "241000"
  },
  {
    "text": "now we are in the first step that is to",
    "start": "187480",
    "end": "189319"
  },
  {
    "text": "enable the model access in Amazon",
    "start": "189319",
    "end": "191599"
  },
  {
    "text": "Bedrock uh you are seeing Amazon Bedrock",
    "start": "191599",
    "end": "194400"
  },
  {
    "text": "uh Management console if you scroll on",
    "start": "194400",
    "end": "197200"
  },
  {
    "text": "your left navigation pane you'll see",
    "start": "197200",
    "end": "199159"
  },
  {
    "text": "model",
    "start": "199159",
    "end": "200120"
  },
  {
    "text": "access and if you click on modify model",
    "start": "200120",
    "end": "202720"
  },
  {
    "text": "access you will see all the llms that",
    "start": "202720",
    "end": "204640"
  },
  {
    "text": "are available for use in Amazon Bedrock",
    "start": "204640",
    "end": "208439"
  },
  {
    "text": "for this demo I'm using anthropy Cloud",
    "start": "208439",
    "end": "210840"
  },
  {
    "text": "so I'll search for that I already",
    "start": "210840",
    "end": "213159"
  },
  {
    "text": "requested access so the access was",
    "start": "213159",
    "end": "214959"
  },
  {
    "text": "granted but if you need to get a request",
    "start": "214959",
    "end": "217920"
  },
  {
    "text": "access it's a very simple process select",
    "start": "217920",
    "end": "220920"
  },
  {
    "text": "model of your choice for example in this",
    "start": "220920",
    "end": "222720"
  },
  {
    "text": "I'm selecting Cloud 3.5 Sonet then click",
    "start": "222720",
    "end": "226159"
  },
  {
    "text": "on next and submit and your",
    "start": "226159",
    "end": "228760"
  },
  {
    "text": "administrator can grant access to that",
    "start": "228760",
    "end": "231200"
  },
  {
    "text": "model here I already requested the model",
    "start": "231200",
    "end": "234360"
  },
  {
    "text": "and got the access so I'll move on to",
    "start": "234360",
    "end": "236280"
  },
  {
    "text": "the second step in our demo that is to",
    "start": "236280",
    "end": "238599"
  },
  {
    "text": "load the data in Amazon red",
    "start": "238599",
    "end": "241280"
  },
  {
    "start": "241000",
    "end": "511000"
  },
  {
    "text": "shift now we are in red shift query",
    "start": "241280",
    "end": "243840"
  },
  {
    "text": "editor V2 let's create a patients table",
    "start": "243840",
    "end": "246640"
  },
  {
    "text": "and load samples patient data go ahead",
    "start": "246640",
    "end": "249799"
  },
  {
    "text": "and run this command to create the table",
    "start": "249799",
    "end": "252599"
  },
  {
    "text": "table is created and I'm loading some",
    "start": "252599",
    "end": "254799"
  },
  {
    "text": "sample data into",
    "start": "254799",
    "end": "257600"
  },
  {
    "text": "it okay uh you can look at the sample",
    "start": "257600",
    "end": "261359"
  },
  {
    "text": "data to get a feel of how the data",
    "start": "261359",
    "end": "264160"
  },
  {
    "text": "is yeah it has patient ID patient name",
    "start": "264160",
    "end": "267600"
  },
  {
    "text": "and their condition and the medication",
    "start": "267600",
    "end": "269440"
  },
  {
    "text": "they taking this we will pass it on to",
    "start": "269440",
    "end": "272280"
  },
  {
    "text": "the llm model to generate personalized",
    "start": "272280",
    "end": "276039"
  },
  {
    "text": "typ plan so prior to that we should do",
    "start": "276039",
    "end": "278880"
  },
  {
    "text": "little bit of uh prompt engineering so",
    "start": "278880",
    "end": "281320"
  },
  {
    "text": "if you look at it the patient names and",
    "start": "281320",
    "end": "283880"
  },
  {
    "text": "the conditions are in different rows we",
    "start": "283880",
    "end": "286000"
  },
  {
    "text": "should bring them into a single Row for",
    "start": "286000",
    "end": "288479"
  },
  {
    "text": "passing as a prompt so here I'm running",
    "start": "288479",
    "end": "291720"
  },
  {
    "text": "um aggregation functions uh to combine",
    "start": "291720",
    "end": "295639"
  },
  {
    "text": "the conditions and patients uh",
    "start": "295639",
    "end": "297440"
  },
  {
    "text": "medications per patient and we will",
    "start": "297440",
    "end": "300560"
  },
  {
    "text": "further group them down and create like",
    "start": "300560",
    "end": "303720"
  },
  {
    "text": "a prompt in the next",
    "start": "303720",
    "end": "305720"
  },
  {
    "text": "SQL yeah if you look at this you see a",
    "start": "305720",
    "end": "309280"
  },
  {
    "text": "nice prompt created like gen has viral",
    "start": "309280",
    "end": "311880"
  },
  {
    "text": "sinusitis bronchitis taking so and so",
    "start": "311880",
    "end": "314280"
  },
  {
    "text": "medicine and now this is ready to pass",
    "start": "314280",
    "end": "317039"
  },
  {
    "text": "as a prom to the llm",
    "start": "317039",
    "end": "319800"
  },
  {
    "text": "model um we can just pass this output",
    "start": "319800",
    "end": "323440"
  },
  {
    "text": "also to llm model or for better",
    "start": "323440",
    "end": "325759"
  },
  {
    "text": "readability we are creating a",
    "start": "325759",
    "end": "327240"
  },
  {
    "text": "materialized view using the same SQL",
    "start": "327240",
    "end": "329280"
  },
  {
    "text": "statement",
    "start": "329280",
    "end": "330280"
  },
  {
    "text": "we'll go ahead and create a material",
    "start": "330280",
    "end": "331840"
  },
  {
    "text": "view this is not necessary but just for",
    "start": "331840",
    "end": "334360"
  },
  {
    "text": "readability we are creating it let's",
    "start": "334360",
    "end": "336680"
  },
  {
    "text": "look at the output of materialize view",
    "start": "336680",
    "end": "339360"
  },
  {
    "text": "yeah it has the patient ID and the",
    "start": "339360",
    "end": "341360"
  },
  {
    "text": "prompt neatly uh",
    "start": "341360",
    "end": "344680"
  },
  {
    "text": "formatted now this is the step where we",
    "start": "344680",
    "end": "347720"
  },
  {
    "text": "will create the model um this model",
    "start": "347720",
    "end": "351440"
  },
  {
    "text": "references the anthropic Cloud V2 and we",
    "start": "351440",
    "end": "354960"
  },
  {
    "text": "have a prompt passing to the model this",
    "start": "354960",
    "end": "357080"
  },
  {
    "text": "is a static prompt um however we we have",
    "start": "357080",
    "end": "359880"
  },
  {
    "text": "other options which I will discuss",
    "start": "359880",
    "end": "361240"
  },
  {
    "text": "further down and um we will go ahead and",
    "start": "361240",
    "end": "365080"
  },
  {
    "text": "run it which will return a function",
    "start": "365080",
    "end": "367000"
  },
  {
    "text": "called patient recommendation functions",
    "start": "367000",
    "end": "369440"
  },
  {
    "text": "and that function we will use to uh run",
    "start": "369440",
    "end": "372360"
  },
  {
    "text": "the inferences so let me go ahead and",
    "start": "372360",
    "end": "374440"
  },
  {
    "text": "run",
    "start": "374440",
    "end": "375840"
  },
  {
    "text": "this so the model reference created and",
    "start": "375840",
    "end": "378720"
  },
  {
    "text": "we have a function created for us to use",
    "start": "378720",
    "end": "381160"
  },
  {
    "text": "uh to generate inferences so let me come",
    "start": "381160",
    "end": "384120"
  },
  {
    "text": "down and run this SQL to generate",
    "start": "384120",
    "end": "386919"
  },
  {
    "text": "inferences for two of the patients",
    "start": "386919",
    "end": "391440"
  },
  {
    "text": "so when we run this uh The Prompt is",
    "start": "391479",
    "end": "393680"
  },
  {
    "text": "passed on to the llm and llm generates",
    "start": "393680",
    "end": "396080"
  },
  {
    "text": "the D plan and send it back to Red shift",
    "start": "396080",
    "end": "399160"
  },
  {
    "text": "so you can copy the output and paste it",
    "start": "399160",
    "end": "402080"
  },
  {
    "text": "in a notepad for us to look at the",
    "start": "402080",
    "end": "404639"
  },
  {
    "text": "multi-line output so this is the",
    "start": "404639",
    "end": "408080"
  },
  {
    "text": "generated patient plan for Emma who has",
    "start": "408080",
    "end": "411840"
  },
  {
    "text": "hypertension and bronchitis and taking",
    "start": "411840",
    "end": "413919"
  },
  {
    "text": "this",
    "start": "413919",
    "end": "414639"
  },
  {
    "text": "medication and we also have personalized",
    "start": "414639",
    "end": "419639"
  },
  {
    "text": "di plan created for another patient",
    "start": "419639",
    "end": "421879"
  },
  {
    "text": "let's see what it has so this patient",
    "start": "421879",
    "end": "425080"
  },
  {
    "text": "has diabetes and sinusitis and taking",
    "start": "425080",
    "end": "428240"
  },
  {
    "text": "these medications and the generated diet",
    "start": "428240",
    "end": "430800"
  },
  {
    "text": "plan is particularly uh personalized for",
    "start": "430800",
    "end": "434759"
  },
  {
    "text": "devb who has these conditions so that",
    "start": "434759",
    "end": "437879"
  },
  {
    "text": "concludes the demo for a simple call to",
    "start": "437879",
    "end": "440319"
  },
  {
    "text": "llm and generate responses all with SQL",
    "start": "440319",
    "end": "443720"
  },
  {
    "text": "statements you don't need to learn any",
    "start": "443720",
    "end": "445400"
  },
  {
    "text": "other",
    "start": "445400",
    "end": "446240"
  },
  {
    "text": "skills now we'll see further options",
    "start": "446240",
    "end": "448800"
  },
  {
    "text": "that are available in this integration",
    "start": "448800",
    "end": "451240"
  },
  {
    "text": "let's say you would like to make a",
    "start": "451240",
    "end": "452800"
  },
  {
    "text": "simple call without making without",
    "start": "452800",
    "end": "454840"
  },
  {
    "text": "passing any data from your data",
    "start": "454840",
    "end": "456560"
  },
  {
    "text": "warehouse like a catalog function you",
    "start": "456560",
    "end": "459080"
  },
  {
    "text": "can run that um as a leader node only",
    "start": "459080",
    "end": "461800"
  },
  {
    "text": "function so if You observe this SQL we",
    "start": "461800",
    "end": "464599"
  },
  {
    "text": "are calling the function passing a",
    "start": "464599",
    "end": "466720"
  },
  {
    "text": "prompt but we are there is no from",
    "start": "466720",
    "end": "468520"
  },
  {
    "text": "Clause we are not passing any data from",
    "start": "468520",
    "end": "470199"
  },
  {
    "text": "data warehouse so you can make a simple",
    "start": "470199",
    "end": "471919"
  },
  {
    "text": "question to llm using an SQL call and",
    "start": "471919",
    "end": "475319"
  },
  {
    "text": "you will get the output and this is not",
    "start": "475319",
    "end": "477599"
  },
  {
    "text": "a personalized uh typ which I'm",
    "start": "477599",
    "end": "479919"
  },
  {
    "text": "generating here because I'm not passing",
    "start": "479919",
    "end": "481479"
  },
  {
    "text": "any specific patient information so all",
    "start": "481479",
    "end": "483840"
  },
  {
    "text": "we get is a very generic response um as",
    "start": "483840",
    "end": "486759"
  },
  {
    "text": "a simple call to LM so I just want to",
    "start": "486759",
    "end": "489400"
  },
  {
    "text": "demonstrate you can use this integration",
    "start": "489400",
    "end": "492039"
  },
  {
    "text": "as a um leader node only function too",
    "start": "492039",
    "end": "495120"
  },
  {
    "text": "let me copy paste this output to a",
    "start": "495120",
    "end": "497680"
  },
  {
    "text": "simple notepad so if you look at this",
    "start": "497680",
    "end": "500240"
  },
  {
    "text": "it's a 7day diet plan for somebody with",
    "start": "500240",
    "end": "504000"
  },
  {
    "text": "pre- diabetes and it's not specific to",
    "start": "504000",
    "end": "506280"
  },
  {
    "text": "any patient so you can use this",
    "start": "506280",
    "end": "508800"
  },
  {
    "text": "integration for for such a kind of use",
    "start": "508800",
    "end": "510800"
  },
  {
    "text": "cases too the next option is to set the",
    "start": "510800",
    "end": "514800"
  },
  {
    "start": "511000",
    "end": "653000"
  },
  {
    "text": "additional parameters uh while making a",
    "start": "514800",
    "end": "517760"
  },
  {
    "text": "call to llm if you look at here along",
    "start": "517760",
    "end": "520360"
  },
  {
    "text": "with the prompt I'm also passing",
    "start": "520360",
    "end": "522839"
  },
  {
    "text": "optional parameters like temperature",
    "start": "522839",
    "end": "524959"
  },
  {
    "text": "what temperature will do for this model",
    "start": "524959",
    "end": "526880"
  },
  {
    "text": "is it will increase the specificity uh",
    "start": "526880",
    "end": "529360"
  },
  {
    "text": "based on the value you set it ranges",
    "start": "529360",
    "end": "531240"
  },
  {
    "text": "from 0 to one uh in for this for the",
    "start": "531240",
    "end": "534040"
  },
  {
    "text": "first call I'm generating the",
    "start": "534040",
    "end": "535600"
  },
  {
    "text": "recommendations for patient ID 101",
    "start": "535600",
    "end": "538880"
  },
  {
    "text": "setting the temper temperature to 0.2",
    "start": "538880",
    "end": "542240"
  },
  {
    "text": "let's see the output and we will do the",
    "start": "542240",
    "end": "544600"
  },
  {
    "text": "same call for the same patient",
    "start": "544600",
    "end": "546440"
  },
  {
    "text": "increasing the temperature then the",
    "start": "546440",
    "end": "549320"
  },
  {
    "text": "specificity of the output changes",
    "start": "549320",
    "end": "551160"
  },
  {
    "text": "according to the parameters we are",
    "start": "551160",
    "end": "552800"
  },
  {
    "text": "passing so if I copy paste this output",
    "start": "552800",
    "end": "556200"
  },
  {
    "text": "into a uh notepad and look at",
    "start": "556200",
    "end": "560880"
  },
  {
    "text": "the output I'll just move it here for",
    "start": "560880",
    "end": "564200"
  },
  {
    "text": "you to quickly have a look at",
    "start": "564200",
    "end": "566880"
  },
  {
    "text": "it this is how the output for",
    "start": "566880",
    "end": "569920"
  },
  {
    "text": "um the call that we passed on with a 0.2",
    "start": "569920",
    "end": "573519"
  },
  {
    "text": "temperature I would like to focus on two",
    "start": "573519",
    "end": "577040"
  },
  {
    "text": "uh uh recommendations here to show you",
    "start": "577040",
    "end": "579360"
  },
  {
    "text": "the difference between 0.2 and",
    "start": "579360",
    "end": "582040"
  },
  {
    "text": "0.8 this is the output generated with",
    "start": "582040",
    "end": "584760"
  },
  {
    "text": "0.2 if you look at the um recommendation",
    "start": "584760",
    "end": "589120"
  },
  {
    "text": "stay hydrated drink plenty of fluids",
    "start": "589120",
    "end": "591200"
  },
  {
    "text": "like water herble tea and avoid DIY um",
    "start": "591200",
    "end": "594920"
  },
  {
    "text": "and so on so and similarly if you look",
    "start": "594920",
    "end": "596720"
  },
  {
    "text": "at one more line avoid so gluten process",
    "start": "596720",
    "end": "599519"
  },
  {
    "text": "Force this made this thyroid function in",
    "start": "599519",
    "end": "601600"
  },
  {
    "text": "some",
    "start": "601600",
    "end": "602720"
  },
  {
    "text": "people now what we will do is we will",
    "start": "602720",
    "end": "605399"
  },
  {
    "text": "generate output increasing the",
    "start": "605399",
    "end": "607760"
  },
  {
    "text": "specificity uh temperature to get more",
    "start": "607760",
    "end": "610680"
  },
  {
    "text": "specific recommendations let me go ahead",
    "start": "610680",
    "end": "612959"
  },
  {
    "text": "and run this now we will get a different",
    "start": "612959",
    "end": "616160"
  },
  {
    "text": "output with more specific",
    "start": "616160",
    "end": "618680"
  },
  {
    "text": "recommendations so if I look at the",
    "start": "618680",
    "end": "620720"
  },
  {
    "text": "output with markings yeah this is the",
    "start": "620720",
    "end": "623120"
  },
  {
    "text": "output for um the inference call",
    "start": "623120",
    "end": "626880"
  },
  {
    "text": "generated with 0.8 specific necessity if",
    "start": "626880",
    "end": "630360"
  },
  {
    "text": "you look at this same recommendation but",
    "start": "630360",
    "end": "632839"
  },
  {
    "text": "now it is much more specific it is",
    "start": "632839",
    "end": "634760"
  },
  {
    "text": "calling 8 to 10 glasses of water and in",
    "start": "634760",
    "end": "637639"
  },
  {
    "text": "the second recommendation it is saying",
    "start": "637639",
    "end": "639480"
  },
  {
    "text": "monitor TSH levels it's giving the",
    "start": "639480",
    "end": "642040"
  },
  {
    "text": "specific details and um what we are",
    "start": "642040",
    "end": "645360"
  },
  {
    "text": "trying to tell here is based on the",
    "start": "645360",
    "end": "647480"
  },
  {
    "text": "option you are passing uh the optional",
    "start": "647480",
    "end": "649440"
  },
  {
    "text": "parameters you are passing we can",
    "start": "649440",
    "end": "650880"
  },
  {
    "text": "influence the Model",
    "start": "650880",
    "end": "652760"
  },
  {
    "text": "Behavior now we will see how do we",
    "start": "652760",
    "end": "655680"
  },
  {
    "text": "create a model uh with request type",
    "start": "655680",
    "end": "658120"
  },
  {
    "text": "defined as Raw so what it means is we",
    "start": "658120",
    "end": "660320"
  },
  {
    "text": "are not uh defining any fixed prompt U",
    "start": "660320",
    "end": "663720"
  },
  {
    "text": "everything we will construct at the time",
    "start": "663720",
    "end": "665680"
  },
  {
    "text": "of",
    "start": "665680",
    "end": "666399"
  },
  {
    "text": "inference let me go ahead and run",
    "start": "666399",
    "end": "669160"
  },
  {
    "text": "this uh now for this demonstration I'm",
    "start": "669160",
    "end": "671800"
  },
  {
    "text": "using Amazon titon text Express V1 model",
    "start": "671800",
    "end": "674600"
  },
  {
    "text": "you can use any other model but",
    "start": "674600",
    "end": "675920"
  },
  {
    "text": "essentially I'm just trying to",
    "start": "675920",
    "end": "677200"
  },
  {
    "text": "demonstrate how you can create it with",
    "start": "677200",
    "end": "679920"
  },
  {
    "text": "request type defined as raw if you look",
    "start": "679920",
    "end": "682360"
  },
  {
    "text": "at the inference call everything I'm",
    "start": "682360",
    "end": "684920"
  },
  {
    "text": "constructing at the time of inference",
    "start": "684920",
    "end": "687000"
  },
  {
    "text": "and passing the patients data the prompt",
    "start": "687000",
    "end": "689320"
  },
  {
    "text": "and all the parameters um we just want",
    "start": "689320",
    "end": "691880"
  },
  {
    "text": "to demonstrate another way of uh making",
    "start": "691880",
    "end": "695440"
  },
  {
    "text": "this call and here is the output if you",
    "start": "695440",
    "end": "699120"
  },
  {
    "text": "copy the output into a notepad you will",
    "start": "699120",
    "end": "701600"
  },
  {
    "text": "see the output in Json",
    "start": "701600",
    "end": "703600"
  },
  {
    "text": "format now let's look at the final",
    "start": "703600",
    "end": "705920"
  },
  {
    "text": "option for this demo um if we need to",
    "start": "705920",
    "end": "708880"
  },
  {
    "text": "look at the Run metrics which are",
    "start": "708880",
    "end": "710480"
  },
  {
    "text": "critical to determine the cost of",
    "start": "710480",
    "end": "712160"
  },
  {
    "text": "running these inference functions like",
    "start": "712160",
    "end": "714120"
  },
  {
    "text": "the input tokens and output uh tokens uh",
    "start": "714120",
    "end": "717320"
  },
  {
    "text": "you can Define your model with response",
    "start": "717320",
    "end": "720480"
  },
  {
    "text": "type as super I will go ahead and run",
    "start": "720480",
    "end": "723079"
  },
  {
    "text": "this and when you run the inference call",
    "start": "723079",
    "end": "726600"
  },
  {
    "text": "with for this particular model you will",
    "start": "726600",
    "end": "729000"
  },
  {
    "text": "get additional run metrics and with that",
    "start": "729000",
    "end": "731720"
  },
  {
    "text": "you'll be able to assess the cost of",
    "start": "731720",
    "end": "734079"
  },
  {
    "text": "using the Bedrock llm model let me go",
    "start": "734079",
    "end": "737560"
  },
  {
    "text": "ahead and run this to generate the",
    "start": "737560",
    "end": "741000"
  },
  {
    "text": "inference here you got the output now we",
    "start": "741320",
    "end": "744120"
  },
  {
    "text": "will copy this output and paste it in a",
    "start": "744120",
    "end": "747959"
  },
  {
    "text": "notepad yeah if you look at the output",
    "start": "747959",
    "end": "750199"
  },
  {
    "text": "you see how many tokens passed how many",
    "start": "750199",
    "end": "752160"
  },
  {
    "text": "tokens returned and the latency these",
    "start": "752160",
    "end": "755040"
  },
  {
    "text": "metrics are critical for us to determine",
    "start": "755040",
    "end": "757360"
  },
  {
    "text": "the cost and also to look at the",
    "start": "757360",
    "end": "759560"
  },
  {
    "text": "response times we also published a Blog",
    "start": "759560",
    "end": "762800"
  },
  {
    "start": "760000",
    "end": "778000"
  },
  {
    "text": "to provide you stepbystep walkthrough of",
    "start": "762800",
    "end": "765519"
  },
  {
    "text": "the solution and this is the blog it has",
    "start": "765519",
    "end": "768480"
  },
  {
    "text": "a SQL notebook for you to download and",
    "start": "768480",
    "end": "771240"
  },
  {
    "text": "replay this demo thank you for watching",
    "start": "771240",
    "end": "776760"
  }
]
[
  {
    "start": "0",
    "end": "55000"
  },
  {
    "text": "thank you everybody for coming my name is Colin McCarthy I'm a principal engineer originally from dublin ireland",
    "start": "0",
    "end": "6569"
  },
  {
    "text": "but i live in CL now and i work on elastic load balancing so elastic load",
    "start": "6569",
    "end": "13650"
  },
  {
    "text": "bouncing does exactly what the name sounds we balance load we take your",
    "start": "13650",
    "end": "20539"
  },
  {
    "text": "incoming HTTP requests or TCP connections and we balance them across",
    "start": "20539",
    "end": "26300"
  },
  {
    "text": "ec2 instances I'm going to talk more about how elb works under the hood so to",
    "start": "26300",
    "end": "33600"
  },
  {
    "text": "speak today and just dive a little bit a little bit in more detail around what's",
    "start": "33600",
    "end": "39390"
  },
  {
    "text": "going on to help build applications on top of vlb and and and speak to its",
    "start": "39390",
    "end": "47670"
  },
  {
    "text": "trends okay so I'm going to talk about three different parts of ELB one second",
    "start": "47670",
    "end": "57410"
  },
  {
    "start": "55000",
    "end": "75000"
  },
  {
    "text": "security scalability and availability which we which we think of as the the",
    "start": "57410",
    "end": "63960"
  },
  {
    "text": "kind of the main features and the main reasons why customers using lb and and",
    "start": "63960",
    "end": "69990"
  },
  {
    "text": "we'll go into some depth on each one so we'll start with security so what I want",
    "start": "69990",
    "end": "78119"
  },
  {
    "text": "to emphasize in this in this section is if you imagine they'll be just like I",
    "start": "78119",
    "end": "83850"
  },
  {
    "text": "described something that you run in front of your applications so save",
    "start": "83850",
    "end": "89220"
  },
  {
    "text": "you've got a website or an API or some kind of service that you're running in the cloud typically you'll have an",
    "start": "89220",
    "end": "96930"
  },
  {
    "text": "elastic load balancer running in front of that it is doing things like",
    "start": "96930",
    "end": "103430"
  },
  {
    "text": "terminating your TLS ssl traffic or providing that first layer of Defense and what I what I want to emphasize is",
    "start": "103430",
    "end": "112950"
  },
  {
    "text": "that everything I'm going to talk about in the Security section is kind of independent of load balancing and yet",
    "start": "112950",
    "end": "118590"
  },
  {
    "text": "it's a big reason why we see people using our baby wheat we even have customers who put al bees in front of",
    "start": "118590",
    "end": "126540"
  },
  {
    "text": "just a single instance just just for the security features alone so the first",
    "start": "126540",
    "end": "132510"
  },
  {
    "text": "thing we do like I said exterminate ssl/tls right so",
    "start": "132510",
    "end": "139170"
  },
  {
    "start": "135000",
    "end": "254000"
  },
  {
    "text": "if you if you create an elastic load balancer and I you decide you decide you",
    "start": "139170",
    "end": "145109"
  },
  {
    "text": "want to terminate secure traffic on that we support that you can upload a certificate and a key or we can generate",
    "start": "145109",
    "end": "152730"
  },
  {
    "text": "them for you I'll talk a little bit more about that in a second and we handle",
    "start": "152730",
    "end": "158069"
  },
  {
    "text": "keeping all of the SSL and TLS implementation of the day and we try to",
    "start": "158069",
    "end": "163530"
  },
  {
    "text": "make it easy to keep the configurations as up-to-date as possible so examples of",
    "start": "163530",
    "end": "169379"
  },
  {
    "text": "some of the things we've we've managed on behalf of customers are things like the SSL vulnerabilities that have been",
    "start": "169379",
    "end": "177000"
  },
  {
    "text": "coming out over the last few years we typically mitigate those on the same day",
    "start": "177000",
    "end": "182040"
  },
  {
    "text": "or better some of them we we managed to",
    "start": "182040",
    "end": "187200"
  },
  {
    "text": "beat same day by having features disabled long before they're an issue so",
    "start": "187200",
    "end": "192480"
  },
  {
    "text": "poodle for example the vulnerability and how sslv3 can be used we'd send a",
    "start": "192480",
    "end": "200159"
  },
  {
    "text": "mitigation for that same day mitigation for log jam which is just to do with how diffie-hellman encryption is handled we",
    "start": "200159",
    "end": "207269"
  },
  {
    "text": "had same day mitigation for heartbleed and the rc4 encryption cipher was",
    "start": "207269",
    "end": "213269"
  },
  {
    "text": "removed long before that was considered",
    "start": "213269",
    "end": "218389"
  },
  {
    "text": "insecure and so the details of all those particular vulnerabilities so many matter but when I want to get across is",
    "start": "218389",
    "end": "226169"
  },
  {
    "text": "you know that TLS and SSL stack that we're managing at the front end we're",
    "start": "226169",
    "end": "231439"
  },
  {
    "text": "keeping all this stuff up to date when these issues come out if the most you",
    "start": "231439",
    "end": "238229"
  },
  {
    "text": "might have to do is log into the console and update to the latest dlb security policy and you're you're up to date with",
    "start": "238229",
    "end": "245430"
  },
  {
    "text": "the latest settings we we always try to have those for the same day the way",
    "start": "245430",
    "end": "251040"
  },
  {
    "text": "we're able to provide all that is this",
    "start": "251040",
    "end": "256109"
  },
  {
    "start": "254000",
    "end": "325000"
  },
  {
    "text": "is a space we are investing quite heavily in we're trying to be quite deep",
    "start": "256109",
    "end": "261449"
  },
  {
    "text": "when it comes to SSL and TLS processing both for security reasons and perform",
    "start": "261449",
    "end": "266650"
  },
  {
    "text": "reasons at a point where we have our own implementation of the ssl/tls protocols that's something that's open source you",
    "start": "266650",
    "end": "273250"
  },
  {
    "text": "can you can go view it on github goes to regular quite intensive security reviews and security audits but that's something",
    "start": "273250",
    "end": "280000"
  },
  {
    "text": "that's managed within the EOB team itself so we're working on that code we're constantly staying up-to-date",
    "start": "280000",
    "end": "286240"
  },
  {
    "text": "we're members of the ssl/tls community so when security issues come around we",
    "start": "286240",
    "end": "292750"
  },
  {
    "text": "know about them we're involved in mitigate them mitigating them and we can have all of those things prepared so",
    "start": "292750",
    "end": "300430"
  },
  {
    "text": "that's probably one of one of our biggest and simplest features it's just",
    "start": "300430",
    "end": "306010"
  },
  {
    "text": "that we terminate all that TLS ssl traffic handle all of this stuff acid e you don't have to and can terminate the",
    "start": "306010",
    "end": "313960"
  },
  {
    "text": "traffic in a secure up-to-date way without having to worry so much about",
    "start": "313960",
    "end": "319120"
  },
  {
    "text": "whether your own instances are are up to date with the latest vulnerability at the moment recently we added support for",
    "start": "319120",
    "end": "328050"
  },
  {
    "start": "325000",
    "end": "391000"
  },
  {
    "text": "the edge of west certificate manager to make this even easier so now you can you",
    "start": "328050",
    "end": "335260"
  },
  {
    "text": "can log into the console and and create certificates through AWS so you can go",
    "start": "335260",
    "end": "341800"
  },
  {
    "text": "to the ADA where certificate manager console you can go dbl be console or the cloud from console and there's API is",
    "start": "341800",
    "end": "347110"
  },
  {
    "text": "for all of this too and you can you can create certificates using your own domain name we'll send a verification",
    "start": "347110",
    "end": "353680"
  },
  {
    "text": "email to the owner of that domain once they verified that that certificates",
    "start": "353680",
    "end": "358960"
  },
  {
    "text": "okay you can associate it with your EOB and that's that's that they're there",
    "start": "358960",
    "end": "364389"
  },
  {
    "text": "they're free the cost for you as well so that's we're trying to make this as easy",
    "start": "364389",
    "end": "370060"
  },
  {
    "text": "as possible to be able to terminate secure traffic in terms of how we manage",
    "start": "370060",
    "end": "376780"
  },
  {
    "text": "the SSL and TLS traffic there's a few things going on under the hood it can be",
    "start": "376780",
    "end": "382510"
  },
  {
    "text": "quite confusing when you see the set of you know what's a cipher suite what what",
    "start": "382510",
    "end": "388419"
  },
  {
    "text": "are the policies meaning and the one very briefly what's what's going on",
    "start": "388419",
    "end": "394750"
  },
  {
    "start": "391000",
    "end": "525000"
  },
  {
    "text": "under the hood is well what we we try to present to you very very simple options you know you",
    "start": "394750",
    "end": "401509"
  },
  {
    "text": "can take the latest greatest security policy and just use the default but",
    "start": "401509",
    "end": "407270"
  },
  {
    "text": "those policies are set up to prefer certain things the first thing that we",
    "start": "407270",
    "end": "412400"
  },
  {
    "text": "always try to prefer is what's called perfect forward secrecy so that means",
    "start": "412400",
    "end": "417770"
  },
  {
    "text": "when traffic is terminated on us it goes to this extra algorithm called",
    "start": "417770",
    "end": "425840"
  },
  {
    "text": "diffie-hellman that means if the key were ever disclosed or compromised in some way someone wouldn't be able to use",
    "start": "425840",
    "end": "432020"
  },
  {
    "text": "that key to go back in time and decrypt a bunch of traffic that they had recorded so it's pretty awesome feature",
    "start": "432020",
    "end": "437240"
  },
  {
    "text": "we always try to use it in terms of encryption algorithms we always prefer",
    "start": "437240",
    "end": "442400"
  },
  {
    "text": "to use a yes that's kind of our standard encryption algorithm over three days",
    "start": "442400",
    "end": "448089"
  },
  {
    "text": "over or c4 if you have it enabled it's actually disabled by default there's",
    "start": "448089",
    "end": "453889"
  },
  {
    "text": "these things called authentication algorithms which are around how traffic can be made tamper proof we prefer the",
    "start": "453889",
    "end": "461750"
  },
  {
    "text": "GCM algorithm over the CBC and H Mecca H Mac algorithms and when we're",
    "start": "461750",
    "end": "468770"
  },
  {
    "text": "constructing these preferences what we do behind the scenes is we we construct this list of cipher Suites in that order",
    "start": "468770",
    "end": "475129"
  },
  {
    "text": "that we prefer and then we test it against billions of connections from real world clients well we actually have",
    "start": "475129",
    "end": "481939"
  },
  {
    "text": "is an experimental setup where we can send a very small amount of experimental Amazon traffic to these tests endpoints",
    "start": "481939",
    "end": "490360"
  },
  {
    "text": "where we will measure whether that cipher suite has any impact and sometimes we find interesting digs right",
    "start": "490360",
    "end": "497089"
  },
  {
    "text": "sometimes we find you know that cipher suite in that order might impact certain versions of Java or you know certain",
    "start": "497089",
    "end": "504529"
  },
  {
    "text": "embedded system clients and so on and so we're doing that kind of analysis on this list before we publish it to try to",
    "start": "504529",
    "end": "510710"
  },
  {
    "text": "make sure that you can stay secure but also available right to the one when we publish that update and you can choose",
    "start": "510710",
    "end": "515899"
  },
  {
    "text": "the the latest policy that is not going to drop or break a bunch of traffic and",
    "start": "515899",
    "end": "522349"
  },
  {
    "text": "that's been that's been working pretty well the we try to strike a balance with their",
    "start": "522349",
    "end": "529959"
  },
  {
    "start": "525000",
    "end": "595000"
  },
  {
    "text": "defaults right we're always going to try to make sure that there are that the",
    "start": "529959",
    "end": "535720"
  },
  {
    "text": "cipher suites are are secure right so the default cipher suite will we'll try never to include something that's known",
    "start": "535720",
    "end": "541930"
  },
  {
    "text": "to be insecure and will minimize any gap of any systems that that leaves unsupported that can occasionally result",
    "start": "541930",
    "end": "551110"
  },
  {
    "text": "in some systems some very legacy embedded systems typically that are so old or the software is not being updated",
    "start": "551110",
    "end": "557769"
  },
  {
    "text": "that maybe they only support insecure cipher Suites we have a small number of",
    "start": "557769",
    "end": "564550"
  },
  {
    "text": "customers who end up being impacted by this you know typically customers who",
    "start": "564550",
    "end": "570850"
  },
  {
    "text": "are targeting things like set-top boxes and TVs and systems that aren't great at keeping software up today and maybe they",
    "start": "570850",
    "end": "577990"
  },
  {
    "text": "got a version of software you know when it shipped from a factory five six years ago and it's never been updated in the",
    "start": "577990",
    "end": "583899"
  },
  {
    "text": "meantime so a feature we added recently to try to help people manage this is to",
    "start": "583899",
    "end": "590709"
  },
  {
    "text": "integrate all of this with our access logs so access logs are another security",
    "start": "590709",
    "end": "598690"
  },
  {
    "start": "595000",
    "end": "695000"
  },
  {
    "text": "feature that we have I actually didn't really think of them as as a security",
    "start": "598690",
    "end": "604690"
  },
  {
    "text": "feature until I heard it from a lot of customers explaining to me that the user access logs in that way but you can",
    "start": "604690",
    "end": "611589"
  },
  {
    "text": "enable logging on your lb and we will record the details of each request and",
    "start": "611589",
    "end": "617470"
  },
  {
    "text": "we'll send it to an s3 bucket for analysis and the reason that's a security feature is you know in the in",
    "start": "617470",
    "end": "625089"
  },
  {
    "text": "the ADA West shared security model we're we're responsible for the elb right we're responsible for the security of",
    "start": "625089",
    "end": "630730"
  },
  {
    "text": "the elb it goes to a lot of rigorous review we've got a lot of operational and security practices around elastic",
    "start": "630730",
    "end": "639130"
  },
  {
    "text": "load balancers make making sure that they're not vulnerable and so on and the",
    "start": "639130",
    "end": "644410"
  },
  {
    "text": "same for s3 you can also protect s3 buckets with policies and so on and so what you can do is if you know that ALB",
    "start": "644410",
    "end": "651970"
  },
  {
    "text": "is is securely and reliably logging every request well then if an attack",
    "start": "651970",
    "end": "656980"
  },
  {
    "text": "happens to get through to your instance and say compromises some software vulnerability",
    "start": "656980",
    "end": "662830"
  },
  {
    "text": "and your instance like a wordpress vulnerability or something like that you know typically a step an attacker might",
    "start": "662830",
    "end": "669340"
  },
  {
    "text": "take is to raise all of the logs that are on that system itself but if the elb",
    "start": "669340",
    "end": "674740"
  },
  {
    "text": "is logging and sending it off to s3 you've got this extra channel of log data that aren't as vulnerable to an",
    "start": "674740",
    "end": "682720"
  },
  {
    "text": "attack or simply amazing things on the system and so on but we have partners",
    "start": "682720",
    "end": "688030"
  },
  {
    "text": "that we integrate with if you want to do higher-level analytics on that logging data but going back to cipher Suites one",
    "start": "688030",
    "end": "696160"
  },
  {
    "start": "695000",
    "end": "808000"
  },
  {
    "text": "of the more interesting things is we we now log the actual cipher suite that was",
    "start": "696160",
    "end": "701470"
  },
  {
    "text": "negotiated when a when a HTTP request came in right so you can see this",
    "start": "701470",
    "end": "706510"
  },
  {
    "text": "request for example use that cipher suite over the TLS 1.2 protocol and that",
    "start": "706510",
    "end": "715240"
  },
  {
    "text": "might be useful if you are you know if you have a lot of legacy embedded system clients and you're worried about",
    "start": "715240",
    "end": "721870"
  },
  {
    "text": "upgrading to the latest settings is that going to break something well simple way is to go to the logs and see is anything",
    "start": "721870",
    "end": "727420"
  },
  {
    "text": "negotiating those so for example if you were if you're upgrading to lay this",
    "start": "727420",
    "end": "732640"
  },
  {
    "text": "policy and in the process disabling support for or C for which you really should do the rc4 encryption algorithm",
    "start": "732640",
    "end": "739360"
  },
  {
    "text": "is is definitely broken at this point a good exercise to do might be to just",
    "start": "739360",
    "end": "745330"
  },
  {
    "text": "enable logging go to the logs maybe a day or two's worth the logs see if anybody's still negotiating over c4 dig",
    "start": "745330",
    "end": "752470"
  },
  {
    "text": "into it and and see what's going on when we were turning our for c4 for amazon",
    "start": "752470",
    "end": "760300"
  },
  {
    "text": "com one of the interesting things I learned was what we went we went we did this exercise when true logs and we saw",
    "start": "760300",
    "end": "767230"
  },
  {
    "text": "who was still negotiating or c4 at the beginning we were kind of like well there's still some clients negotiating",
    "start": "767230",
    "end": "772660"
  },
  {
    "text": "or c4 how are we going to turn this off you know we don't want to break anybody in the process and we actually found out",
    "start": "772660",
    "end": "777700"
  },
  {
    "text": "a lot of the things still negotiating or c4 where you know robots and spam bots",
    "start": "777700",
    "end": "782830"
  },
  {
    "text": "and unwanted traffic in the beginning so it was actually a positive to turn it off which we only learned from scanning",
    "start": "782830",
    "end": "790420"
  },
  {
    "text": "the logs line by line which is which is pretty cool so that pattern of using a knee lb",
    "start": "790420",
    "end": "798360"
  },
  {
    "text": "in front of your instances as kind of this defense known defensive layer",
    "start": "798360",
    "end": "803930"
  },
  {
    "text": "that's kind of less typically less vulnerable is an example of",
    "start": "803930",
    "end": "809490"
  },
  {
    "start": "808000",
    "end": "938000"
  },
  {
    "text": "compartmentalization which is another security pattern we see a lot of customers apply where the launch eel",
    "start": "809490",
    "end": "818040"
  },
  {
    "text": "bees into public subnets using VPC that's a virtual private cloud for ec2",
    "start": "818040",
    "end": "823730"
  },
  {
    "text": "and they'll they'll lock that down with security groups and I am spall I am",
    "start": "823730",
    "end": "832470"
  },
  {
    "text": "policies and roll accounts and so on so that only trusted accounts with the",
    "start": "832470",
    "end": "837780"
  },
  {
    "text": "right permissions can launch elb ease into that public subnet that's the only",
    "start": "837780",
    "end": "843750"
  },
  {
    "text": "way to effectively open a public port on the Internet I'm on that lets them do",
    "start": "843750",
    "end": "851780"
  },
  {
    "text": "what that lets them do is is say well with some confidence okay the only",
    "start": "851780",
    "end": "857070"
  },
  {
    "text": "things that have traffic coming in from the internet have this at these managed",
    "start": "857070",
    "end": "863160"
  },
  {
    "text": "ssl/tls tax that are being kept up today they have the certificates being managed by AWS it can't simply be copied around",
    "start": "863160",
    "end": "870260"
  },
  {
    "text": "or exported easily and I've got logging",
    "start": "870260",
    "end": "875850"
  },
  {
    "text": "in place so that any requests that come in are known and that lets them open up and be a bit more free what happens in",
    "start": "875850",
    "end": "881880"
  },
  {
    "text": "the private submits because they they can launch instances more freely there be a bit more agile there but know that",
    "start": "881880",
    "end": "889080"
  },
  {
    "text": "it has to come true that that top layer that's been set up a bit more in",
    "start": "889080",
    "end": "894860"
  },
  {
    "text": "addition to to roll accounts you know we've full support for cloud try logging",
    "start": "894860",
    "end": "900120"
  },
  {
    "text": "in the ELP API so somebody's creating a lbs launching them into submits that's",
    "start": "900120",
    "end": "906990"
  },
  {
    "text": "something that's completely known and then we have access logging which I already mentioned in addition to all",
    "start": "906990",
    "end": "913950"
  },
  {
    "text": "that you can also enable VPC flow logging so we also support that which gives you additional logs that are",
    "start": "913950",
    "end": "921210"
  },
  {
    "text": "network level so you can see the actual you know sources and destinations of TCP traffic they're coming in and out of the",
    "start": "921210",
    "end": "928699"
  },
  {
    "text": "in and out of the lb so you get quite a quite a thorough detailed view of everything that's going on and keep",
    "start": "928699",
    "end": "934910"
  },
  {
    "text": "things nice and constrained and all of that kind of feeds into you know",
    "start": "934910",
    "end": "943820"
  },
  {
    "text": "standard trap models helps you protect against some pretty common security threats and so those are pretty popular",
    "start": "943820",
    "end": "953570"
  },
  {
    "text": "features and as I said we see them even being used in some cases even when",
    "start": "953570",
    "end": "958940"
  },
  {
    "text": "there's just one instance behind that he'll be even when it's not doing any low bouncing just for the benefit of all those extra monitoring and kind of",
    "start": "958940",
    "end": "967339"
  },
  {
    "text": "compliance features which is kind of neat ok but the real job of elb is",
    "start": "967339",
    "end": "972889"
  },
  {
    "text": "scaling right that's that's where things get a little more interesting you'll be",
    "start": "972889",
    "end": "978589"
  },
  {
    "start": "974000",
    "end": "1006000"
  },
  {
    "text": "at its root is a scalability feature we're about taking you know small or",
    "start": "978589",
    "end": "985190"
  },
  {
    "text": "huge amounts of load in whether it's from the internet or from you know other",
    "start": "985190",
    "end": "990279"
  },
  {
    "text": "ec2 instances and spreading that load in a fair way and in a way that optimizes",
    "start": "990279",
    "end": "996290"
  },
  {
    "text": "for your application saw an engineer actually you know write code and work on",
    "start": "996290",
    "end": "1002709"
  },
  {
    "text": "elb so I include an equation I couldn't couldn't resist and this equation is",
    "start": "1002709",
    "end": "1011410"
  },
  {
    "start": "1006000",
    "end": "1051000"
  },
  {
    "text": "what's called littles law which I think of is one of the the fundamental laws that applies to kind of balancing load",
    "start": "1011410",
    "end": "1019089"
  },
  {
    "text": "or building systems building distributed systems that handle many requests and",
    "start": "1019089",
    "end": "1024610"
  },
  {
    "text": "littles law is simpler it's pretty simple all it says is that the total",
    "start": "1024610",
    "end": "1029980"
  },
  {
    "text": "load or capacity of a system is this is equal to the rate of arrival so that's",
    "start": "1029980",
    "end": "1036010"
  },
  {
    "text": "lambda times the average wait time right so the total amount of requests a system",
    "start": "1036010",
    "end": "1043058"
  },
  {
    "text": "can sustain is just based on the rate they're coming in and how long it takes",
    "start": "1043059",
    "end": "1048370"
  },
  {
    "text": "to process each request we can flip that on its head and say well the wait time",
    "start": "1048370",
    "end": "1053590"
  },
  {
    "start": "1051000",
    "end": "1065000"
  },
  {
    "text": "is therefore equal to the pacity of the system like how many instances you have or how much work your",
    "start": "1053590",
    "end": "1061630"
  },
  {
    "text": "system could do divided by the rate of arrival we are in simpler words latency",
    "start": "1061630",
    "end": "1067560"
  },
  {
    "start": "1065000",
    "end": "1128000"
  },
  {
    "text": "is is equal to load / throughput right",
    "start": "1067560",
    "end": "1072910"
  },
  {
    "text": "so the more low do you have in general the more late in the system will be it'll slow down a little and the higher",
    "start": "1072910",
    "end": "1080710"
  },
  {
    "text": "your trooper the faster it'll get right so it's it's pretty intuitive it's not",
    "start": "1080710",
    "end": "1087460"
  },
  {
    "text": "it's not a surprising result but it has some interesting implications so what",
    "start": "1087460",
    "end": "1094780"
  },
  {
    "text": "drives the latency of modern systems you",
    "start": "1094780",
    "end": "1100240"
  },
  {
    "text": "know we always want to keep the latency low people want lots people want their api's to run quickly or the websites close fast people tend to notice things",
    "start": "1100240",
    "end": "1107680"
  },
  {
    "text": "even in you know timescales of 100 milliseconds can be noticed by people",
    "start": "1107680",
    "end": "1113220"
  },
  {
    "text": "but a real challenge is that the the kind of load or capacity of systems it",
    "start": "1113220",
    "end": "1118840"
  },
  {
    "text": "tends to be nonlinear right and there's a bunch of reasons why one of the one of",
    "start": "1118840",
    "end": "1125440"
  },
  {
    "text": "the most common reasons is that a lot of applications are use garbage collection",
    "start": "1125440",
    "end": "1134320"
  },
  {
    "start": "1128000",
    "end": "1195000"
  },
  {
    "text": "right so what happens is like if you start a back-end in a garbage collected",
    "start": "1134320",
    "end": "1140770"
  },
  {
    "text": "language likes a Java you know typically it'll just build up memory and memory",
    "start": "1140770",
    "end": "1146440"
  },
  {
    "text": "memory usage you know until it hits some maximum heap size and then the garbage collector will come in and it'll be busy",
    "start": "1146440",
    "end": "1154720"
  },
  {
    "text": "doing its garbage collection you know while it's doing garbage collection it won't be able to process requests and so",
    "start": "1154720",
    "end": "1160150"
  },
  {
    "text": "latency will go way up when that garbage collection is happening and some systems",
    "start": "1160150",
    "end": "1165850"
  },
  {
    "text": "you know you can see really big Delta's you know you can see a system go from like you know requests are taking one",
    "start": "1165850",
    "end": "1172210"
  },
  {
    "text": "millisecond to I've seen boxes take you know tens of seconds to do garbage collection because they had heap sizes",
    "start": "1172210",
    "end": "1178900"
  },
  {
    "text": "that were so large you know the JVM was trying to free 10 gigs of memory all at",
    "start": "1178900",
    "end": "1184510"
  },
  {
    "text": "once so this box can go from leading really quick to being really slow in an instant right so that's one common",
    "start": "1184510",
    "end": "1192310"
  },
  {
    "text": "source of of non-linearity another common source of non-linearity is",
    "start": "1192310",
    "end": "1198130"
  },
  {
    "start": "1195000",
    "end": "1301000"
  },
  {
    "text": "caching right so I bottom a lot of applications have caching at different",
    "start": "1198130",
    "end": "1203410"
  },
  {
    "text": "layers right the common variables are accessing the common users are accessing",
    "start": "1203410",
    "end": "1209170"
  },
  {
    "text": "or you know a shopping cart that Z being edited right now might be hot in some",
    "start": "1209170",
    "end": "1214210"
  },
  {
    "text": "cash and one that was edited a few hours ago might be cool in some cash right and so a request that happens to hit warm",
    "start": "1214210",
    "end": "1222490"
  },
  {
    "text": "entries in the cash will be really fast because maybe that data is right there on the server handling the request but",
    "start": "1222490",
    "end": "1229420"
  },
  {
    "text": "you hit a cold entry in the cache maybe it has to go to disk or some order box",
    "start": "1229420",
    "end": "1234940"
  },
  {
    "text": "that's remote and so you see the same kind of Delta and again did the difference can be huge right something",
    "start": "1234940",
    "end": "1243940"
  },
  {
    "text": "that's looking up local main memory can take microseconds something that's looking up you know a remote distributed",
    "start": "1243940",
    "end": "1249460"
  },
  {
    "text": "cache can take tens of milliseconds right so the several orders of magnitude difference so it's a lot going on and so",
    "start": "1249460",
    "end": "1258370"
  },
  {
    "text": "what this tends to result in is is kind of a very log normal distribution of",
    "start": "1258370",
    "end": "1266620"
  },
  {
    "text": "request processing times where you get you know most your requests you're doing",
    "start": "1266620",
    "end": "1271900"
  },
  {
    "text": "okay they've got like some smallish processing time but you get this tale of",
    "start": "1271900",
    "end": "1277660"
  },
  {
    "text": "requests that are in the kind of higher percentile of your distribution that take quite a long amount of time right",
    "start": "1277660",
    "end": "1284500"
  },
  {
    "text": "so you might have you know an average request time of say five milliseconds but then maybe your 99th percentile of",
    "start": "1284500",
    "end": "1293100"
  },
  {
    "text": "requests might might take like a second that's not even that unusual and so if",
    "start": "1293100",
    "end": "1302230"
  },
  {
    "start": "1301000",
    "end": "1359000"
  },
  {
    "text": "we think about this as in terms of a queuing system right so servers and",
    "start": "1302230",
    "end": "1308310"
  },
  {
    "text": "instances and even entire distributed systems can be modeled as cues that's",
    "start": "1308310",
    "end": "1314110"
  },
  {
    "text": "actually where littles law comes from is queuing theory it kind of looks like well you've got a queue with small",
    "start": "1314110",
    "end": "1321370"
  },
  {
    "text": "requests in it you've got Q's with big requests in it right and this itself can be a source of",
    "start": "1321370",
    "end": "1327630"
  },
  {
    "text": "variance and load right like you might have a lot of small requests that are just requesting the front page right",
    "start": "1327630",
    "end": "1333900"
  },
  {
    "text": "those are probably hot in a cache so probably easy to render they're probably just a few k right but then occasionally",
    "start": "1333900",
    "end": "1340230"
  },
  {
    "text": "there's a request floating around that's for you know a big data dump and the",
    "start": "1340230",
    "end": "1345540"
  },
  {
    "text": "code has to go you know dump a bunch of data from a database and process it and",
    "start": "1345540",
    "end": "1350640"
  },
  {
    "text": "pivot it and do a bunch of things with it just takes a longer amount of time right and that feeds into the same",
    "start": "1350640",
    "end": "1357630"
  },
  {
    "text": "pattern again where you know your median request time is probably quite good your",
    "start": "1357630",
    "end": "1365700"
  },
  {
    "start": "1359000",
    "end": "1398000"
  },
  {
    "text": "average request times not going to be not going to be great so like walk when",
    "start": "1365700",
    "end": "1373170"
  },
  {
    "text": "we're trying to balance load we got to ask yourselves like well what can we do about this right what can we what can we",
    "start": "1373170",
    "end": "1379860"
  },
  {
    "text": "do to improve things so the first thing we do is well we have more instances",
    "start": "1379860",
    "end": "1384990"
  },
  {
    "text": "right we kind of troll more capacity at the problem so instead of all of those requests contending on one instance and",
    "start": "1384990",
    "end": "1391650"
  },
  {
    "text": "having to queue up linearly and just get processed one after another we control several at it and that can improve",
    "start": "1391650",
    "end": "1401460"
  },
  {
    "start": "1398000",
    "end": "1439000"
  },
  {
    "text": "things right that can kind of smoothing out the tail if even all you do is kind of like choose a cheeser machine at",
    "start": "1401460",
    "end": "1408360"
  },
  {
    "text": "random it'll it'll tend to have some kind of smoothing effect where it'll kind of bring in the average because on",
    "start": "1408360",
    "end": "1415440"
  },
  {
    "text": "average you know bucks is probably free and it's not too busy but your tail kind",
    "start": "1415440",
    "end": "1420510"
  },
  {
    "text": "of stays where it is because occasionally you know bad request is still going to a big request or a cache",
    "start": "1420510",
    "end": "1425880"
  },
  {
    "text": "miss or a GC pause if that's what we call garbage collection pauses when they",
    "start": "1425880",
    "end": "1432840"
  },
  {
    "text": "slow the box down can still occur at the same rate and so the detail kind of stays where it is right so if we just",
    "start": "1432840",
    "end": "1441960"
  },
  {
    "start": "1439000",
    "end": "1475000"
  },
  {
    "text": "separate the requests and we we line them all up and we send them to different instances we we do get some",
    "start": "1441960",
    "end": "1450390"
  },
  {
    "text": "benefit right here I've got four instances splitting them up so that",
    "start": "1450390",
    "end": "1456090"
  },
  {
    "text": "cues are roughly equal in size this is an example of something called round",
    "start": "1456090",
    "end": "1464039"
  },
  {
    "text": "robin no bouncing where we just take take a request at random and say okay well you can go to this server you can",
    "start": "1464039",
    "end": "1469350"
  },
  {
    "text": "go this server and there's that will improve things quite a bit it pulls in",
    "start": "1469350",
    "end": "1477870"
  },
  {
    "start": "1475000",
    "end": "1487000"
  },
  {
    "text": "the tail like I mentioned but the the real piece of magic that elb does which",
    "start": "1477870",
    "end": "1483900"
  },
  {
    "text": "kind of blows my mind that it works so effectively is we do something a little different which is so the previous q",
    "start": "1483900",
    "end": "1491299"
  },
  {
    "start": "1487000",
    "end": "1584000"
  },
  {
    "text": "kind of reminds me of a lot of cues like it opposed office maybe where everyone lines up and in front of their own",
    "start": "1491299",
    "end": "1497159"
  },
  {
    "text": "server but we try to queue more like a bank where you know there's one line",
    "start": "1497159",
    "end": "1503250"
  },
  {
    "text": "that everybody gets in and then when a server is available you go to the next available server right and this has the",
    "start": "1503250",
    "end": "1512880"
  },
  {
    "text": "effect of saying well if you've got a box over here that's busy doing garbage",
    "start": "1512880",
    "end": "1518100"
  },
  {
    "text": "collection or it's got a cache miss or is processing a big request you know we're not going to send any new requests",
    "start": "1518100",
    "end": "1523950"
  },
  {
    "text": "to it while it's doing that we're going to try to send it to one of the other servers right this is called lease",
    "start": "1523950",
    "end": "1530520"
  },
  {
    "text": "connections loud bouncing our implementation of it is actually a little bit more refined than that we",
    "start": "1530520",
    "end": "1536340"
  },
  {
    "text": "implement least outstanding requests so what we do is we count the number of",
    "start": "1536340",
    "end": "1541500"
  },
  {
    "text": "requests that are outstanding to each of your instances and we'll send the next request to whichever is the lowest right",
    "start": "1541500",
    "end": "1548190"
  },
  {
    "text": "so if you've got capacity free in the system that's where the next request is going right it's a it's really really",
    "start": "1548190",
    "end": "1555929"
  },
  {
    "text": "cool it's amazingly effective kind of blows my mind how effective it is it's",
    "start": "1555929",
    "end": "1562110"
  },
  {
    "text": "particularly effective when you've got a you know a small number of slow",
    "start": "1562110",
    "end": "1568320"
  },
  {
    "text": "instances right so if you've got you've got a handful like 24 even ten instances",
    "start": "1568320",
    "end": "1575059"
  },
  {
    "text": "that are running a reasonably slow application this will smoothen out those",
    "start": "1575059",
    "end": "1582539"
  },
  {
    "text": "Peaks helped quite a bit it can it can really pull in the tail quite a lot",
    "start": "1582539",
    "end": "1588390"
  },
  {
    "start": "1584000",
    "end": "1618000"
  },
  {
    "text": "really flat flat load and you you're only ever going to see that tail when when in general you",
    "start": "1588390",
    "end": "1594540"
  },
  {
    "text": "know the whole system is out of capacity right as long as there's capacity available somewhere that's that's where",
    "start": "1594540",
    "end": "1600240"
  },
  {
    "text": "you'll be going to try to remove the request too surprisingly effective and",
    "start": "1600240",
    "end": "1606110"
  },
  {
    "text": "amazingly cool the one big downside of",
    "start": "1606110",
    "end": "1612030"
  },
  {
    "text": "this though this doesn't all come for free right there's a little bit of a gotcha is if you have a server that's",
    "start": "1612030",
    "end": "1620370"
  },
  {
    "start": "1618000",
    "end": "1721000"
  },
  {
    "text": "being particularly fast right but it's actually not doing anything useful like maybe it's just throwing 500 errors or",
    "start": "1620370",
    "end": "1628040"
  },
  {
    "text": "exceptions or you know PHP crashes that server is going to soak all the load",
    "start": "1628040",
    "end": "1634049"
  },
  {
    "text": "right you're going to blackhole traffic so it's kind of a double-edged sword",
    "start": "1634049",
    "end": "1639120"
  },
  {
    "text": "it's really awesome algorithm in general when everything's going well it's amazing it's smoothing out differences",
    "start": "1639120",
    "end": "1646049"
  },
  {
    "text": "in load there's a really really great job but if you've got a box that's kind",
    "start": "1646049",
    "end": "1651150"
  },
  {
    "text": "of poisonous and is in this kind of throwing errors quickly it will rapidly soak in everything so you know it's",
    "start": "1651150",
    "end": "1659669"
  },
  {
    "text": "pretty important to pay attention the boxes that are spinning like that and and take them out of service quickly but",
    "start": "1659669",
    "end": "1666330"
  },
  {
    "text": "one simple trick you can also do is if you do even it like an exception handler or some kind of code path that's",
    "start": "1666330",
    "end": "1672900"
  },
  {
    "text": "responsible for Charlie Milles 500s just put a sleep in there right just slow it down so that it can only respond with",
    "start": "1672900",
    "end": "1679650"
  },
  {
    "text": "500 errors say once every 200 milliseconds or something appropriately slow so that box isn't just going to",
    "start": "1679650",
    "end": "1686640"
  },
  {
    "text": "soak up traffic if you want a bit of defense in depth right so that's the",
    "start": "1686640",
    "end": "1694799"
  },
  {
    "text": "other side of all that now all this only works right if elb itself can actually",
    "start": "1694799",
    "end": "1700950"
  },
  {
    "text": "take all your requests in at a faster rate than you could write it has to take",
    "start": "1700950",
    "end": "1706950"
  },
  {
    "text": "the request in queue them up and nowhere to serve them with very low latency and without you know without throwing away",
    "start": "1706950",
    "end": "1713970"
  },
  {
    "text": "any of those requests so elb itself has to be able to scale quite large and",
    "start": "1713970",
    "end": "1719100"
  },
  {
    "text": "quite quickly so to give you an idea of the we have the kind of scales we run",
    "start": "1719100",
    "end": "1727249"
  },
  {
    "start": "1721000",
    "end": "1883000"
  },
  {
    "text": "you know we have e lbs today in production to run everything from like",
    "start": "1727249",
    "end": "1732779"
  },
  {
    "text": "literally you know I've seen yell bees that handle like literally one or two requests per day but it was a very",
    "start": "1732779",
    "end": "1739679"
  },
  {
    "text": "important workload and needed something in front of it just to trigger off a very important batch job and make sure",
    "start": "1739679",
    "end": "1745379"
  },
  {
    "text": "there was some availability and resilience in place all the way up to like millions of requests per second",
    "start": "1745379",
    "end": "1750919"
  },
  {
    "text": "right so we can go you know as high as your needs so far we've never hit any",
    "start": "1750919",
    "end": "1757169"
  },
  {
    "text": "ceiling or limit we were we weren't able to to scale up to our own scaling is a",
    "start": "1757169",
    "end": "1763139"
  },
  {
    "text": "mix of proactive scaling so what I mean by that is if you add back ends if you",
    "start": "1763139",
    "end": "1768869"
  },
  {
    "text": "add instances to your elb we scale up assuming you added those instances for",
    "start": "1768869",
    "end": "1774719"
  },
  {
    "text": "some reason right so when you when you go at a bunch of instances we will we will scale up to match that and both",
    "start": "1774719",
    "end": "1781889"
  },
  {
    "text": "then and in general we're always very aggressive to scale up so we scale up in",
    "start": "1781889",
    "end": "1787169"
  },
  {
    "text": "minutes or less you know and and we're very cautious to scale down so when you",
    "start": "1787169",
    "end": "1795809"
  },
  {
    "text": "add those instances will scale up and we'll stay scaled up for quite a long time like days even if we don't see",
    "start": "1795809",
    "end": "1802589"
  },
  {
    "text": "traffic and after that we go into our more reactive mode which is we pay",
    "start": "1802589",
    "end": "1811379"
  },
  {
    "text": "attention to the traffic patterns as we see them come in and and we scale ahead",
    "start": "1811379",
    "end": "1816389"
  },
  {
    "text": "of that right so that's a reactive scaling and there's a there's a few",
    "start": "1816389",
    "end": "1823080"
  },
  {
    "text": "things going on there to make sure that we're always at a higher scale then then",
    "start": "1823080",
    "end": "1829289"
  },
  {
    "text": "your own instance capacity the first I already mentioned it's quite quick so we scale up in minutes or less the second",
    "start": "1829289",
    "end": "1836309"
  },
  {
    "text": "I'll talk a little bit about when we get to availability is we're always preferred for the loss of a data center so every elb is kind of typically over",
    "start": "1836309",
    "end": "1844919"
  },
  {
    "text": "scaled by fifty percent or so so there's this kind of buffer that's in there that's actually for disaster recovery in",
    "start": "1844919",
    "end": "1851729"
  },
  {
    "text": "case of data center fails but also means you've got this you know huge margin you would have to run right through",
    "start": "1851729",
    "end": "1857430"
  },
  {
    "text": "you hit the before you hit the ceiling and then the other thing we do is it's its predictive load balancing so it's",
    "start": "1857430",
    "end": "1863580"
  },
  {
    "text": "actually look predictive scaling rather so we're looking at the load pattern and seeing where it's going to go and seeing",
    "start": "1863580",
    "end": "1869070"
  },
  {
    "text": "what we need to do before you need it so that's that's what we're doing for our",
    "start": "1869070",
    "end": "1874140"
  },
  {
    "text": "own scaling under the hood we provide a bunch of cloud web metrics I'll go",
    "start": "1874140",
    "end": "1881250"
  },
  {
    "text": "through them in detail in a bit but it's also common to see people you know use",
    "start": "1881250",
    "end": "1888840"
  },
  {
    "start": "1883000",
    "end": "1938000"
  },
  {
    "text": "their lab answer as a kind of convenient way to manage their own scaling so all",
    "start": "1888840",
    "end": "1895530"
  },
  {
    "text": "of the cloud watch metrics that we support can be used to trigger auto scaling events in your own instances",
    "start": "1895530",
    "end": "1901110"
  },
  {
    "text": "right and that's that's convenient because in you know we have metrics like how many HTTP requests you're getting",
    "start": "1901110",
    "end": "1908040"
  },
  {
    "text": "and often you'll want to scale your instances based on that but you know",
    "start": "1908040",
    "end": "1913230"
  },
  {
    "text": "maybe not go through all the effort of building your own metric of how many HTTP requests using on the backend you",
    "start": "1913230",
    "end": "1918480"
  },
  {
    "text": "can just get it conveniently from the elb so you can match the scaling right of both the elastic load balancer kind",
    "start": "1918480",
    "end": "1927150"
  },
  {
    "text": "of at the top or in front and your instances which are at the back and they can they can stay in harmony which is",
    "start": "1927150",
    "end": "1936270"
  },
  {
    "text": "pretty cool we provide 13 of those cloud",
    "start": "1936270",
    "end": "1942150"
  },
  {
    "start": "1938000",
    "end": "1989000"
  },
  {
    "text": "watch metrics each which can be used for scaling some up some of them don't make",
    "start": "1942150",
    "end": "1947340"
  },
  {
    "text": "sense to use for scaling like healthy host count and so on but but the but but",
    "start": "1947340",
    "end": "1954690"
  },
  {
    "text": "they're all possible to use for for that you can configure cloud watch alarms on",
    "start": "1954690",
    "end": "1961230"
  },
  {
    "text": "each of these metrics you can get notifications when they go with those lamb levels they're all provided at one",
    "start": "1961230",
    "end": "1966990"
  },
  {
    "text": "minute granularity and so on you can view them in the in the cloud watch consoles so having me will be in front",
    "start": "1966990",
    "end": "1974130"
  },
  {
    "text": "of your instances also gives you all that need visibility into you know your",
    "start": "1974130",
    "end": "1979530"
  },
  {
    "text": "your traffic patterns in pretty close to real time you know minutes would have",
    "start": "1979530",
    "end": "1986220"
  },
  {
    "text": "better minutes delay or so some of them are worth diving into the",
    "start": "1986220",
    "end": "1994450"
  },
  {
    "start": "1989000",
    "end": "2035000"
  },
  {
    "text": "healthy house call metric is that's where we expose you know this is kind of",
    "start": "1994450",
    "end": "2000370"
  },
  {
    "text": "eel B's view of your instance health so if you've got a number of instances registered behind the knee lb we give",
    "start": "2000370",
    "end": "2008770"
  },
  {
    "text": "you a metric that tells you how many we think are actually healthy and in service you can view it at an",
    "start": "2008770",
    "end": "2015130"
  },
  {
    "text": "availability zone level you can see how healthy we think your application is you",
    "start": "2015130",
    "end": "2020650"
  },
  {
    "text": "know l bees are constantly held checking your instances so that we don't send traffic to an instance that's down and",
    "start": "2020650",
    "end": "2026170"
  },
  {
    "text": "so you can use this metric to you know trigger an alarm replace that instance if you want to do all those kind of neat",
    "start": "2026170",
    "end": "2033400"
  },
  {
    "text": "things a few more if you're interested in measuring the performance we have",
    "start": "2033400",
    "end": "2038920"
  },
  {
    "start": "2035000",
    "end": "2064000"
  },
  {
    "text": "measurements for latency so what will expose the end M latency this is how",
    "start": "2038920",
    "end": "2044140"
  },
  {
    "text": "long the whole request took including the time it took lb to process it and the time it took your instance to",
    "start": "2044140",
    "end": "2051158"
  },
  {
    "text": "process it and so on and you can see if your overall system is getting slower or if there's any kind of problem going on",
    "start": "2051159",
    "end": "2057700"
  },
  {
    "text": "it'll often often often show up as a latency thing we have surged queue and",
    "start": "2057700",
    "end": "2066100"
  },
  {
    "start": "2064000",
    "end": "2180000"
  },
  {
    "text": "spillover metrics so Serge queues are",
    "start": "2066100",
    "end": "2072419"
  },
  {
    "text": "just these cues we keep on the lb of requests that you know your backends",
    "start": "2072419",
    "end": "2079330"
  },
  {
    "text": "can't accept yet so if your backends get clogged up and aren't accepting requests you'll see the search q start to fill up",
    "start": "2079330",
    "end": "2085898"
  },
  {
    "text": "that something you might want to scale up on something you might want to go to",
    "start": "2085899",
    "end": "2091960"
  },
  {
    "text": "nor optimize an application for or just you know add more instances if it's something you're you're managing",
    "start": "2091960",
    "end": "2098440"
  },
  {
    "text": "manually and so on we queue up to a just over a thousand requests after that you",
    "start": "2098440",
    "end": "2107230"
  },
  {
    "text": "know we found out to working with customers that it's better to start",
    "start": "2107230",
    "end": "2114970"
  },
  {
    "text": "returning errors and kind of cause traffic to go away rather than simply backing up requests",
    "start": "2114970",
    "end": "2120510"
  },
  {
    "text": "definitely because what happens is the clients tend to time out and so we're just you know queuing up all these",
    "start": "2120510",
    "end": "2126240"
  },
  {
    "text": "requests but there's no client interested in I mean anymore and in some kind of overload event it really harms",
    "start": "2126240",
    "end": "2132630"
  },
  {
    "text": "the applications ability to recover if it's you know it slows down and all that happens is these requests keep coming so",
    "start": "2132630",
    "end": "2139500"
  },
  {
    "text": "it's it's this queue size this is designed to balance you know giving you enough swash to kind of get around some",
    "start": "2139500",
    "end": "2146640"
  },
  {
    "text": "kind of temporary clog or just short-term issue where your instances maybe aren't keeping up it'll just help",
    "start": "2146640",
    "end": "2152700"
  },
  {
    "text": "you out for a few seconds but it's not going to queue things for so long that the system will recover because we just",
    "start": "2152700",
    "end": "2158340"
  },
  {
    "text": "keep hammering it with this stampede of requests it's quite interesting when",
    "start": "2158340",
    "end": "2163500"
  },
  {
    "text": "things when we do get to returning errors that's spilling over those are",
    "start": "2163500",
    "end": "2168960"
  },
  {
    "text": "spill overs and we have a metric for those too and so you can see if we get all the way to that state that's what's",
    "start": "2168960",
    "end": "2175500"
  },
  {
    "text": "going on ah in addition to the metrics we have the access logs as we saw",
    "start": "2175500",
    "end": "2181950"
  },
  {
    "start": "2180000",
    "end": "2225000"
  },
  {
    "text": "earlier apart from the SSL and TLS protocol version which we already went through on the Cyprus we we have all",
    "start": "2181950",
    "end": "2189060"
  },
  {
    "text": "these fields too so it's quite it's quite a detailed take on just what's",
    "start": "2189060",
    "end": "2197640"
  },
  {
    "text": "going just what's going through your load you know you've got all the different sizes the size of the request",
    "start": "2197640",
    "end": "2202980"
  },
  {
    "text": "the size of the response things like the user agent header which can be really good for figuring out row clients",
    "start": "2202980",
    "end": "2210440"
  },
  {
    "text": "timestamps and just a lot of fields that we found true experience tend to be useful it's a bit more verbose than your",
    "start": "2210440",
    "end": "2217320"
  },
  {
    "text": "typical like Apache log and that's just because we found cases where each of",
    "start": "2217320",
    "end": "2223170"
  },
  {
    "text": "these are useful in addition to all this",
    "start": "2223170",
    "end": "2228600"
  },
  {
    "start": "2225000",
    "end": "2335000"
  },
  {
    "text": "scalability which happens within a region we we also support global",
    "start": "2228600",
    "end": "2236220"
  },
  {
    "text": "scalability with Ram 53 so you can create a DNS domain name on route 53 and",
    "start": "2236220",
    "end": "2244230"
  },
  {
    "text": "you can route traffic using either latency based routing geo based routing",
    "start": "2244230",
    "end": "2249690"
  },
  {
    "text": "or traffic policies which recently launched that let you send traffic from all over the world two different",
    "start": "2249690",
    "end": "2256380"
  },
  {
    "text": "lbs in different AWS regions we have customers particularly in you know very",
    "start": "2256380",
    "end": "2263340"
  },
  {
    "text": "latency sensitive businesses like advertising that will generally run in",
    "start": "2263340",
    "end": "2268920"
  },
  {
    "text": "what's called active active modes where they'll always try to send requests to the closest region and we have required",
    "start": "2268920",
    "end": "2274680"
  },
  {
    "text": "and we have customers who use this for failover between regions so they'll have a primary stack in one region and a",
    "start": "2274680",
    "end": "2281940"
  },
  {
    "text": "secondary stack in in a whole separate region and they will be able to fail over between them using DNS and that's",
    "start": "2281940",
    "end": "2288900"
  },
  {
    "text": "all supported with elb integration route 53 knows about the same hell checks the",
    "start": "2288900",
    "end": "2295770"
  },
  {
    "text": "DL bees are making so not only does failover happen if there were some kind",
    "start": "2295770",
    "end": "2301350"
  },
  {
    "text": "of you know power issue or a data center failure or some major Internet traffic",
    "start": "2301350",
    "end": "2308040"
  },
  {
    "text": "event that meant traffic wasn't reaching a certain region so it'll certainly failover in those cases but it will also",
    "start": "2308040",
    "end": "2313770"
  },
  {
    "text": "fail over in the cases where you know your application in that region is the",
    "start": "2313770",
    "end": "2318810"
  },
  {
    "text": "problem right so maybe your application has fallen over it's failing at clb he'll checks you'll be will actually",
    "start": "2318810",
    "end": "2324390"
  },
  {
    "text": "tell route 53 and route 53 will be able to failover so we see some customers use",
    "start": "2324390",
    "end": "2330240"
  },
  {
    "text": "it to manage like blue green deployment patterns just like that and that's kind",
    "start": "2330240",
    "end": "2335880"
  },
  {
    "text": "of a good place to tee up our availability strategy and what's going on right how how do we keep elb highly",
    "start": "2335880",
    "end": "2342420"
  },
  {
    "text": "available and a lot of the patterns that we're doing here are things you can",
    "start": "2342420",
    "end": "2347520"
  },
  {
    "text": "replicate for yourself for your for your own instances directly to so the first",
    "start": "2347520",
    "end": "2355260"
  },
  {
    "text": "kind of availability feature that lb",
    "start": "2355260",
    "end": "2360930"
  },
  {
    "text": "offers is quite a simple one which is well when you've got an EOB in front of your workload right you can replace",
    "start": "2360930",
    "end": "2367200"
  },
  {
    "start": "2363000",
    "end": "2423000"
  },
  {
    "text": "instances seamlessly right you you call the elb api and you remove the instance",
    "start": "2367200",
    "end": "2373860"
  },
  {
    "text": "I you add anyone whichever or do you want as well and as long as there's instances that are up and running",
    "start": "2373860",
    "end": "2380190"
  },
  {
    "text": "available behind that elb you know we're not going to drop requests in fact you'll be will actually when you",
    "start": "2380190",
    "end": "2388200"
  },
  {
    "text": "associate an instance from an elastic load balancer will will stop sending new",
    "start": "2388200",
    "end": "2393329"
  },
  {
    "text": "requests to it you know straight away this first thing that happens but we can drain traffic to the existing instance",
    "start": "2393329",
    "end": "2399930"
  },
  {
    "text": "right so lb will keep those connections open it'll let that traffic drain and then when it's gone it's gone you can",
    "start": "2399930",
    "end": "2406349"
  },
  {
    "text": "you can turn off the incidence right so you don't have to worry about you know doing very basic DNS tricks or trick or",
    "start": "2406349",
    "end": "2414960"
  },
  {
    "text": "problems they might see what other load balancers we're in a second you take it out it kills a bunch of connections that",
    "start": "2414960",
    "end": "2420359"
  },
  {
    "text": "are in flight so that's the first thing that's going on right oh that's all",
    "start": "2420359",
    "end": "2426329"
  },
  {
    "start": "2423000",
    "end": "2475000"
  },
  {
    "text": "based on health checks so we're always actively help checking every single",
    "start": "2426329",
    "end": "2432599"
  },
  {
    "text": "instance since behind a TLB so another way to fail or another way to replace",
    "start": "2432599",
    "end": "2438660"
  },
  {
    "text": "instances is you can you could decide to fail its hell jack right so if an instance crashes and we're not gonna be",
    "start": "2438660",
    "end": "2444390"
  },
  {
    "text": "able to reach it anymore if your application crashes we're not gonna be able to i'll check it anymore be Marquez unhealthy will stop routing traffic",
    "start": "2444390",
    "end": "2450690"
  },
  {
    "text": "there we could also decide to do it intentionally it's just another way you can decide to take out instances",
    "start": "2450690",
    "end": "2456770"
  },
  {
    "text": "sometimes people prefer that pattern because they've got you know DevOps processes where they can conveniently",
    "start": "2456770",
    "end": "2462900"
  },
  {
    "text": "run code on that box and so if you can cause the hell check URL to fail will also stop sending that box near traffic",
    "start": "2462900",
    "end": "2469740"
  },
  {
    "text": "but I mean existing connections will that we're open we'll try to keep them going we support a bunch of hell checks",
    "start": "2469740",
    "end": "2477810"
  },
  {
    "start": "2475000",
    "end": "2550000"
  },
  {
    "text": "like that we do basic TCP ones and HTTP ones and h-e-bs ones I customize the",
    "start": "2477810",
    "end": "2484170"
  },
  {
    "text": "frequency and failure trash holes it's",
    "start": "2484170",
    "end": "2489800"
  },
  {
    "text": "something we're thinking about is you know how deep do you want that he'll check to go so we will he'll check a URL",
    "start": "2489800",
    "end": "2496440"
  },
  {
    "text": "of your choice right you tell us the URL that's what we'll try to hit behind that URL you can have a simple static",
    "start": "2496440",
    "end": "2501869"
  },
  {
    "text": "response that just returns 200 and basically says you know network connectivity to the instance works",
    "start": "2501869",
    "end": "2507770"
  },
  {
    "text": "that's a fine he'll check but you could also decide you know know when I get",
    "start": "2507770",
    "end": "2512790"
  },
  {
    "text": "that when i get that he'll check paying i'm going to check that my databases alive you know gonna try to do with sequel query and",
    "start": "2512790",
    "end": "2519529"
  },
  {
    "text": "only if I get a successful sequel query am I going to return 200 right so you can go as deep as you like and there's",
    "start": "2519529",
    "end": "2526789"
  },
  {
    "text": "trade-offs in that you know sometimes so if you go too deep maybe you're just exercising the whole system too much and",
    "start": "2526789",
    "end": "2533749"
  },
  {
    "text": "it's too costly and sometimes if you go too shallow you know if the dependency falls over and your application is down",
    "start": "2533749",
    "end": "2540019"
  },
  {
    "text": "but that health status is still 200 you're going to end a black hole in traffic which is an isn't optimal we",
    "start": "2540019",
    "end": "2551449"
  },
  {
    "start": "2550000",
    "end": "2667000"
  },
  {
    "text": "also support idle time outs so in general we try to keep connections alive",
    "start": "2551449",
    "end": "2556640"
  },
  {
    "text": "you know where we can just to save some latency we you can configure those you",
    "start": "2556640",
    "end": "2562909"
  },
  {
    "text": "can you can set up how long you'd like them to be they the default is a minute",
    "start": "2562909",
    "end": "2571459"
  },
  {
    "text": "right so we'll try to keep a connection over a minutes with your websites getting or your applications getting",
    "start": "2571459",
    "end": "2576469"
  },
  {
    "text": "more than one request two minute per you know back-end instance in general those connections will be kept open you can",
    "start": "2576469",
    "end": "2582619"
  },
  {
    "text": "you can extend that as you like but one thing to keep track of right one kind of",
    "start": "2582619",
    "end": "2589549"
  },
  {
    "text": "gotcha with those idle time outs an important kind of detail is as I said earlier with the queues there's no point",
    "start": "2589549",
    "end": "2595849"
  },
  {
    "text": "queuing up work when a client gives up on it right if the client has its own timeout value so let's say it's a",
    "start": "2595849",
    "end": "2602059"
  },
  {
    "text": "browser a typical browser timeout might be 30 seconds well there's really no point having more than 30 second idle",
    "start": "2602059",
    "end": "2608959"
  },
  {
    "text": "timeout on your low bouncer and if you've got a tree if you've got it like a tree of applications where you know",
    "start": "2608959",
    "end": "2616069"
  },
  {
    "text": "each one is calling another application and each application is behind it so now",
    "start": "2616069",
    "end": "2621229"
  },
  {
    "text": "bouncer you probably want those timeouts to decrease as you get deeper and deeper in the tree just to avoid doing work",
    "start": "2621229",
    "end": "2627559"
  },
  {
    "text": "kind of deep in that tree the edge of the system when you know clients have long ago given up about open it so",
    "start": "2627559",
    "end": "2635779"
  },
  {
    "text": "that's that can be pretty important for maintaining your own availability because otherwise what can happen is you know big workloads come along the system",
    "start": "2635779",
    "end": "2643339"
  },
  {
    "text": "gets a little slower because of littles law that we saw earlier requests start to time out",
    "start": "2643339",
    "end": "2648869"
  },
  {
    "text": "on the client side but you know the servers are still busy doing work because the idle time outs are too high",
    "start": "2648869",
    "end": "2655619"
  },
  {
    "text": "and it ends up making it harder for everything to recover so that's a",
    "start": "2655619",
    "end": "2661910"
  },
  {
    "text": "pattern worth applying if you can so I",
    "start": "2661910",
    "end": "2667589"
  },
  {
    "text": "hinted at earlier with our own availability but what we're doing right",
    "start": "2667589",
    "end": "2673170"
  },
  {
    "text": "for Al B's availability is that you know",
    "start": "2673170",
    "end": "2680039"
  },
  {
    "text": "an elastic cloud bouncer is provisioned in multiple availability zones just like",
    "start": "2680039",
    "end": "2685559"
  },
  {
    "text": "your instances are hopefully if you're running some kind of high availability set up and all that's happening all that",
    "start": "2685559",
    "end": "2692339"
  },
  {
    "text": "we're doing to make sure that your lb is up and available and in service at all times is we want amazon route 53 health",
    "start": "2692339",
    "end": "2700650"
  },
  {
    "text": "checks so every ELB is hosted on route 53 and there's a bunch of IP addresses",
    "start": "2700650",
    "end": "2705900"
  },
  {
    "text": "associated with that ELB sum over some of them are in you know zone a similar",
    "start": "2705900",
    "end": "2711690"
  },
  {
    "text": "vermin zombie or CMD and so on and if you do a DNS lookup on the lb you'll get",
    "start": "2711690",
    "end": "2717420"
  },
  {
    "text": "back an answer set that has a mix of ips from each availability zone that's up but we've pre-configured instead of",
    "start": "2717420",
    "end": "2724230"
  },
  {
    "text": "route 53 hell checks that are happening you know all the time from I think 16",
    "start": "2724230",
    "end": "2734160"
  },
  {
    "text": "locations all over the world that are constantly hell checking those lbs and",
    "start": "2734160",
    "end": "2740220"
  },
  {
    "text": "making sure that they're open available and if any of them are if any of those IPS are unreachable route 53 withdraws",
    "start": "2740220",
    "end": "2747089"
  },
  {
    "text": "them from dns and on the EOB side we we",
    "start": "2747089",
    "end": "2753210"
  },
  {
    "text": "we don't do anything else in general right we we let route 53 withdraw those nodes from service traffic will stop",
    "start": "2753210",
    "end": "2762180"
  },
  {
    "text": "coming into them and traffic will keep going to the ones that that are that are up and available and and if it's some",
    "start": "2762180",
    "end": "2770910"
  },
  {
    "text": "kind of power vent you know hopefully when power is restored everything's back to normal if it's some kind of network event you know like a big",
    "start": "2770910",
    "end": "2777910"
  },
  {
    "text": "kind of internet transit issue and so on when that's passed everything goes back to normal but there's not not a lot of",
    "start": "2777910",
    "end": "2784299"
  },
  {
    "text": "work going on behind the scenes and that's a kind of a key to our availability strategy where when we have",
    "start": "2784299",
    "end": "2791680"
  },
  {
    "text": "these large events you know when big things are happening we don't try to do more work right we don't try to have",
    "start": "2791680",
    "end": "2797950"
  },
  {
    "text": "api's and systems behind the scenes that are scrambling to you know remove this",
    "start": "2797950",
    "end": "2803170"
  },
  {
    "text": "ad this remove this ad this because what happens is that tends to make things worse right the system's already",
    "start": "2803170",
    "end": "2809770"
  },
  {
    "text": "overloaded so adding more change to the system can make things worse instead we",
    "start": "2809770",
    "end": "2815500"
  },
  {
    "text": "try to do a constant amount of work so those route 53 health checks they're just always happening all the time the",
    "start": "2815500",
    "end": "2821109"
  },
  {
    "text": "same rate when something's up when something's down all that really happens is something flips from healthy to",
    "start": "2821109",
    "end": "2826210"
  },
  {
    "text": "unhealthy and DNS is the in Iraq so it's kept extremely dumb extremely simple and",
    "start": "2826210",
    "end": "2833940"
  },
  {
    "text": "therefore very reliable in their experience this has weathered you know",
    "start": "2833940",
    "end": "2840819"
  },
  {
    "text": "several large you know internet transit events for example quite reliably and",
    "start": "2840819",
    "end": "2846309"
  },
  {
    "text": "one of the really nice properties of route 53 how checks is because they come from all over the world you know",
    "start": "2846309",
    "end": "2852910"
  },
  {
    "text": "sometimes you'll get a different view in one part of the world then you will other parts right because maybe the",
    "start": "2852910",
    "end": "2857950"
  },
  {
    "text": "network is is has a problem from that side but not others this all works",
    "start": "2857950",
    "end": "2863170"
  },
  {
    "text": "because we're in multiple availability zones to start with in if we always try",
    "start": "2863170",
    "end": "2872230"
  },
  {
    "text": "to match elastic load balancer so that our nodes are in the same availability zone as your nodes and we support cross",
    "start": "2872230",
    "end": "2883029"
  },
  {
    "text": "I'll now bouncing as well so when we match your when we match the zone that",
    "start": "2883029",
    "end": "2890079"
  },
  {
    "text": "your instances are in right traffic will come to the elb that's in a certain zone if we keep traffic in that zone what can",
    "start": "2890079",
    "end": "2898539"
  },
  {
    "text": "happen is there can be an imbalance in the traffic between the two zones",
    "start": "2898539",
    "end": "2903730"
  },
  {
    "text": "because the kinds of low bouncing the DNS can do which is how we route traffic to zones isn't as good as the kind of",
    "start": "2903730",
    "end": "2910750"
  },
  {
    "text": "low bouncing we saw the dl b can do one simple thing when one simple tip that we advise people on",
    "start": "2910750",
    "end": "2919180"
  },
  {
    "text": "is to use cross on now bouncing which is now the default put on some similar bouncers maybe may not be enabled now",
    "start": "2919180",
    "end": "2925570"
  },
  {
    "text": "smooth and all that out so what'll happen is elb will soak up any imbalance",
    "start": "2925570",
    "end": "2930610"
  },
  {
    "text": "that comes in between the two availability zones because of DNS load balancing and we'll just even it out",
    "start": "2930610",
    "end": "2935710"
  },
  {
    "text": "we'll just send the traffic to the least loaded instance like I said so for all",
    "start": "2935710",
    "end": "2944020"
  },
  {
    "start": "2940000",
    "end": "2980000"
  },
  {
    "text": "that to work you know when you create when you create your elastic load balancer if you're using VPC we ask you",
    "start": "2944020",
    "end": "2950020"
  },
  {
    "text": "to associate two or more subnets one in each availability zone with the elastic load balancer just so that we can",
    "start": "2950020",
    "end": "2955720"
  },
  {
    "text": "provision those nodes and hear those traffic and balances I was talking about right so if you've got a relatively",
    "start": "2955720",
    "end": "2962470"
  },
  {
    "text": "small amount allowed if you're in a large amount of requests things will just even out even DNS can even that out",
    "start": "2962470",
    "end": "2968380"
  },
  {
    "text": "because the laws of large numbers will take over you've got a relatively small number of requests then you know",
    "start": "2968380",
    "end": "2973810"
  },
  {
    "text": "occasionally DNS can send you know fifty percent more traffic to one sound and another that's in effect because of DNS",
    "start": "2973810",
    "end": "2983109"
  },
  {
    "text": "caching what happens is you know if all your customers are on you know a small",
    "start": "2983109",
    "end": "2988210"
  },
  {
    "text": "number of networks with a small number of DNS providers we see this with you know iphone apps for example because all",
    "start": "2988210",
    "end": "2995380"
  },
  {
    "text": "of the users are all on a few cellular networks and those cellular networks only have a handful of DNS servers that",
    "start": "2995380",
    "end": "3001170"
  },
  {
    "text": "means there's only a few DNS answers in play at any given time right so you know occasionally you know the dice can just",
    "start": "3001170",
    "end": "3008220"
  },
  {
    "text": "roll such that those DNS servers all send a bit more traffic to one availability zone than another we do",
    "start": "3008220",
    "end": "3014940"
  },
  {
    "text": "have a suggested workaround for this if you really want to get very even DNS low bouncing that's to create a wild-card",
    "start": "3014940",
    "end": "3022340"
  },
  {
    "text": "name that maps to your lb and in your application to make up you know annonce",
    "start": "3022340",
    "end": "3028800"
  },
  {
    "text": "or you it'd or some kind of fields that you're never going to reuse will always bust a cache will always get a unique",
    "start": "3028800",
    "end": "3035430"
  },
  {
    "text": "response and put that in your application and that will that'll even",
    "start": "3035430",
    "end": "3040920"
  },
  {
    "text": "things out but alternatively just an able cross L&L",
    "start": "3040920",
    "end": "3046780"
  },
  {
    "text": "bouncing and let you know he'll be figure it out right so that's the same",
    "start": "3046780",
    "end": "3052299"
  },
  {
    "text": "zone low bouncing that I mentioned that's the cross on I'll bouncing and we've got a graph evening it out sorry",
    "start": "3052299",
    "end": "3058720"
  },
  {
    "text": "about the slides not advancing so we're going a little out of order great so the",
    "start": "3058720",
    "end": "3067930"
  },
  {
    "start": "3065000",
    "end": "3124000"
  },
  {
    "text": "last thing I want to mention is that everything I've talked about here everything they've covered in the lb",
    "start": "3067930",
    "end": "3073690"
  },
  {
    "text": "it's all scriptable we've got a P is for everything we integrate with you know",
    "start": "3073690",
    "end": "3079660"
  },
  {
    "text": "all of the AWS kind of managed DevOps offerings and plenty of third parties or",
    "start": "3079660",
    "end": "3087460"
  },
  {
    "text": "using using it to increasingly we're seeing folks uz lbs as kind of",
    "start": "3087460",
    "end": "3094119"
  },
  {
    "text": "deployment aids where you know people will create a whole new stock for a new",
    "start": "3094119",
    "end": "3099220"
  },
  {
    "text": "deployment when a new lb in front of it you know test their workload jus those who the lb and then flip the load when",
    "start": "3099220",
    "end": "3106180"
  },
  {
    "text": "when when they're done so you're going to see us have features that really",
    "start": "3106180",
    "end": "3111190"
  },
  {
    "text": "enable a use case make things make things even easier for folks that are",
    "start": "3111190",
    "end": "3118089"
  },
  {
    "text": "doing those kind of work clothes but that's it that's everything I have thank",
    "start": "3118089",
    "end": "3124359"
  },
  {
    "text": "you all for coming if if you have any questions or any more detail I can fill you in on just feel free to ask me I'll",
    "start": "3124359",
    "end": "3130390"
  },
  {
    "text": "be right down here after the talk and then maybe outside if they kick is that thank you",
    "start": "3130390",
    "end": "3137130"
  }
]
[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": "good afternoon everyone hi my name is Ray Wong I'm a senior",
    "start": "2030",
    "end": "7350"
  },
  {
    "text": "product manager for on the alias batch and high performance computing team",
    "start": "7350",
    "end": "12559"
  },
  {
    "text": "today with me we have a micro repulsive he is the head of platform engineering",
    "start": "12559",
    "end": "20369"
  },
  {
    "text": "at AQR Capital so today I will be talking to you about a dispatch I'll",
    "start": "20369",
    "end": "27539"
  },
  {
    "start": "22000",
    "end": "53000"
  },
  {
    "text": "give you a little brief interview of batch and then move on to some of our",
    "start": "27539",
    "end": "33600"
  },
  {
    "text": "recent announcement that made in 2008 II now talk a little bit about my roadmap",
    "start": "33600",
    "end": "40620"
  },
  {
    "text": "for 2019 before handing it off to Michael to discuss AQR Capital is",
    "start": "40620",
    "end": "47610"
  },
  {
    "text": "leveraging a dispatch to identify new investment signals so in this batch is",
    "start": "47610",
    "end": "56629"
  },
  {
    "text": "our cloud native job scheduler it is a fully managed service which means that",
    "start": "56629",
    "end": "63750"
  },
  {
    "text": "you don't have to download any software and there is no servers to manage we really want you to focus on your job and",
    "start": "63750",
    "end": "71400"
  },
  {
    "text": "just tell us the requirements of your jobs what kind of application you'll",
    "start": "71400",
    "end": "77280"
  },
  {
    "text": "like us to run and it will figure out how to execute your jobs and how to",
    "start": "77280",
    "end": "83430"
  },
  {
    "text": "manage the underlying infrastructure so we want to take the undifferentiated",
    "start": "83430",
    "end": "88500"
  },
  {
    "text": "heavy lifting out of you guys this lives an a-list actress also natively",
    "start": "88500",
    "end": "95250"
  },
  {
    "text": "integrated with many other AWS services we we think there's a lot of valuing",
    "start": "95250",
    "end": "101009"
  },
  {
    "text": "those services such as auto scaling groups or Identity and Access Management",
    "start": "101009",
    "end": "106350"
  },
  {
    "text": "so we want to make it very easy for you to access those services through batch batch also offers a cost optimized",
    "start": "106350",
    "end": "114689"
  },
  {
    "text": "resource provisioning which means that you can use ec2 on-demand instances spot",
    "start": "114689",
    "end": "121890"
  },
  {
    "text": "instances with batch with no complexity at all and if you have already purchased",
    "start": "121890",
    "end": "128090"
  },
  {
    "text": "its reserved instances then you can use them with Bosch also of course there is no",
    "start": "128090",
    "end": "137069"
  },
  {
    "text": "additional charge to use a dispatch you only pay for the ATS resources that you",
    "start": "137069",
    "end": "144060"
  },
  {
    "text": "consume for example might be EBS volumes or ec2 instances but batch itself is",
    "start": "144060",
    "end": "151200"
  },
  {
    "text": "free so in 2080 we made several",
    "start": "151200",
    "end": "157220"
  },
  {
    "start": "152000",
    "end": "179000"
  },
  {
    "text": "announcements so first for a regional expansion we have expanded to five new",
    "start": "157220",
    "end": "162630"
  },
  {
    "text": "regions in 2018 including Mumbai so Paris and now a diverse batch is",
    "start": "162630",
    "end": "170100"
  },
  {
    "text": "available in 15 commercial regions and we don't plan to stop here we're",
    "start": "170100",
    "end": "175590"
  },
  {
    "text": "definitely going to continue to expand to new regions and in 2018 we also made",
    "start": "175590",
    "end": "183360"
  },
  {
    "start": "179000",
    "end": "299000"
  },
  {
    "text": "a number of features that enhances the performance and manageability of a",
    "start": "183360",
    "end": "190170"
  },
  {
    "text": "diverse batch we have integrated with Amazon CloudWatch",
    "start": "190170",
    "end": "195569"
  },
  {
    "text": "events and so batch now you can set that as a Amazon clout you been target what",
    "start": "195569",
    "end": "203190"
  },
  {
    "text": "that means is a best batch we can trigger the submission of a job to a to",
    "start": "203190",
    "end": "209519"
  },
  {
    "text": "s batch from any respond to any event patter or on any schedule for example",
    "start": "209519",
    "end": "215910"
  },
  {
    "text": "it's now very easy for you to submit a lot of jobs to back to batch every I am",
    "start": "215910",
    "end": "224310"
  },
  {
    "text": "on weekdays or you can submit a job to bash whenever you have an end user who",
    "start": "224310",
    "end": "231720"
  },
  {
    "text": "drops a file into a s 3 bucket another feature we launched this year is called",
    "start": "231720",
    "end": "238650"
  },
  {
    "text": "job execution timeout this is a feature designed to help you control your cost because for example if",
    "start": "238650",
    "end": "245310"
  },
  {
    "text": "your jobs they normally run for 10 minutes and use probably something wrong",
    "start": "245310",
    "end": "250560"
  },
  {
    "text": "something different job is running for 20 minutes then you can actually set a job execution timeout duration to be 20",
    "start": "250560",
    "end": "258120"
  },
  {
    "text": "minutes the batch will automatically terminate your job after 20 minutes is",
    "start": "258120",
    "end": "263400"
  },
  {
    "text": "up so this definitely will help you manage your cost a little bit better and if",
    "start": "263400",
    "end": "268590"
  },
  {
    "text": "your organization uses AWS a cocktail to for compliance reasons then batch is now",
    "start": "268590",
    "end": "277320"
  },
  {
    "text": "integrated with AWS cloud trail so you can audit your costs to Ada best batch",
    "start": "277320",
    "end": "282990"
  },
  {
    "text": "api's and last but not least we made a number of significant scheduling and",
    "start": "282990",
    "end": "289050"
  },
  {
    "text": "throughput enhancements so now batch schedules jobs fat it's it's getting faster and faster and we",
    "start": "289050",
    "end": "295830"
  },
  {
    "text": "can handle millions of jobs with ease so in addition to the performance he has",
    "start": "295830",
    "end": "303300"
  },
  {
    "start": "299000",
    "end": "368000"
  },
  {
    "text": "mints we also worked really hard to improve the manage compute environment experience for example you see that we",
    "start": "303300",
    "end": "312000"
  },
  {
    "text": "would just add a support for a lot of new instance types such as the z1b and the r5 d and we also about two weeks",
    "start": "312000",
    "end": "320910"
  },
  {
    "text": "ago made an announcement that will support easy to launch templates so a",
    "start": "320910",
    "end": "326700"
  },
  {
    "text": "launch templates is a very powerful and flexible way for you to template ice",
    "start": "326700",
    "end": "333930"
  },
  {
    "text": "your ec2 launch request and through launch templates you can do things like",
    "start": "333930",
    "end": "339960"
  },
  {
    "text": "you can increase the size of your container volume you can encrypt your container we also support customer user",
    "start": "339960",
    "end": "348060"
  },
  {
    "text": "data this is very powerful you can do things like you can mount an EFS an instance launch without the need to",
    "start": "348060",
    "end": "354960"
  },
  {
    "text": "create your own custom armies anymore so it's custom a user data is very powerful",
    "start": "354960",
    "end": "362160"
  },
  {
    "text": "and we encourage you to try it out and see what use cases you can come up with",
    "start": "362160",
    "end": "368750"
  },
  {
    "start": "368000",
    "end": "402000"
  },
  {
    "text": "so about two weeks ago we also made a very big announcement about this new feature called multi node parallel jobs",
    "start": "369770",
    "end": "376920"
  },
  {
    "text": "but before I talk about multi node parallel jobs I want to briefly review",
    "start": "376920",
    "end": "382710"
  },
  {
    "text": "how a database - handle store jobs so when you submit a single job to a to s -",
    "start": "382710",
    "end": "389730"
  },
  {
    "text": "but what is happening is that batch we'll take a look at York the jobs requirements and we'll all",
    "start": "389730",
    "end": "396870"
  },
  {
    "text": "scale up a appropriately-sized the instance to run our job so here's the",
    "start": "396870",
    "end": "403230"
  },
  {
    "start": "402000",
    "end": "446000"
  },
  {
    "text": "instance we'll create a container within that instance and we'll run your job inside of the container so if you submit",
    "start": "403230",
    "end": "410970"
  },
  {
    "text": "lots of jobs to 8 OS batch we'll take a look at the requirements of all those",
    "start": "410970",
    "end": "416520"
  },
  {
    "text": "jobs try to then pack them into a fewer container instance this is impossible",
    "start": "416520",
    "end": "424110"
  },
  {
    "text": "create all the create all the containers for each shop and run the jobs in there",
    "start": "424110",
    "end": "431880"
  },
  {
    "text": "but the thing to call out is the largest job you can run with batch prior to",
    "start": "431880",
    "end": "437670"
  },
  {
    "text": "multi amount parallel jobs it has to fit into a single container instance instance might be very big but it still",
    "start": "437670",
    "end": "444660"
  },
  {
    "text": "has to fit into one so with the support for multi node parallel jobs this all",
    "start": "444660",
    "end": "450450"
  },
  {
    "start": "446000",
    "end": "483000"
  },
  {
    "text": "changes so now you are able to submit a job to batch that spans across multiple",
    "start": "450450",
    "end": "456480"
  },
  {
    "text": "instances in this example we have 4 instances up for the single job what",
    "start": "456480",
    "end": "464400"
  },
  {
    "text": "batch will do is batch will created a container in each instance and then",
    "start": "464400",
    "end": "469740"
  },
  {
    "text": "we'll run the jobs in all the containers in all the containers a diverse batch",
    "start": "469740",
    "end": "476040"
  },
  {
    "text": "will also help you set up networking so the instances and containers can communicate with each other to run your",
    "start": "476040",
    "end": "482850"
  },
  {
    "text": "job this is perfect for distributed computing workloads for example if you",
    "start": "482850",
    "end": "490530"
  },
  {
    "start": "483000",
    "end": "521000"
  },
  {
    "text": "have a tightly coupled high performance computing workload such as weather",
    "start": "490530",
    "end": "495810"
  },
  {
    "text": "simulation or computational fluid dynamics workload that uses the MPI",
    "start": "495810",
    "end": "502590"
  },
  {
    "text": "framework the message passing interface is pretty more you can now run these MPI jobs on batch this is also very good for",
    "start": "502590",
    "end": "510740"
  },
  {
    "text": "distributed machine learning and deep learning so if you have a distributed",
    "start": "510740",
    "end": "516810"
  },
  {
    "text": "tensorflow workload this is also great so for",
    "start": "516810",
    "end": "524219"
  },
  {
    "start": "521000",
    "end": "604000"
  },
  {
    "text": "roadmap what expect in the next 12 months so first we",
    "start": "524220",
    "end": "530140"
  },
  {
    "text": "will soon announce the support for the elastic fabric a doctor so EFA is",
    "start": "530140",
    "end": "535839"
  },
  {
    "text": "something we just announced on Monday it is a new ec2 Network device that will",
    "start": "535839",
    "end": "541810"
  },
  {
    "text": "help enhance the performance of distributed high-performance computing workloads so if you have MPI jobs this",
    "start": "541810",
    "end": "549070"
  },
  {
    "text": "is perfect for that so you you can use spatch to submit your MPI drops process",
    "start": "549070",
    "end": "554560"
  },
  {
    "text": "your MPI drops and use EFA to increase the performance will also significantly",
    "start": "554560",
    "end": "562470"
  },
  {
    "text": "improve our batch console and also emit cow watch event metrics for monitoring",
    "start": "562470",
    "end": "569560"
  },
  {
    "text": "the status and health of your jobs for those of you who have gpu-accelerated",
    "start": "569560",
    "end": "576750"
  },
  {
    "text": "workloads we'll announce some better GPU support very soon of course we're going to",
    "start": "576750",
    "end": "582970"
  },
  {
    "text": "continue to make scheduling and performance improvements that includes",
    "start": "582970",
    "end": "587980"
  },
  {
    "text": "support new instance types as soon as they launch and also support any new",
    "start": "587980",
    "end": "593820"
  },
  {
    "text": "regions when they announce these are just some items that we have planned for",
    "start": "593820",
    "end": "599550"
  },
  {
    "text": "2019 I'll be happy to talk to you afterwards if you have more questions now I will hand the stage to Michael",
    "start": "599550",
    "end": "608160"
  },
  {
    "start": "604000",
    "end": "615000"
  },
  {
    "text": "thank you so I have a lot of content to cover so I'm just gonna dive right in",
    "start": "608160",
    "end": "615600"
  },
  {
    "start": "615000",
    "end": "664000"
  },
  {
    "text": "first the legal and compliance team at AQR says hello to everyone in Vegas you",
    "start": "615600",
    "end": "622120"
  },
  {
    "text": "can read these disclosures at your leisure so our agenda I'm going to talk",
    "start": "622120",
    "end": "627160"
  },
  {
    "text": "very briefly about aq are and what we do and spend a little bit more time on the",
    "start": "627160",
    "end": "632230"
  },
  {
    "text": "business problem that we face that'll sort of frame the discussion for the rest of the talk and then spend most of",
    "start": "632230",
    "end": "640480"
  },
  {
    "text": "my time on the actual solution the lessons learned and the takeaways if I have a goal for this talk it's for you",
    "start": "640480",
    "end": "647949"
  },
  {
    "text": "to walk out of this room learning from our mistakes so if you go ahead and build this a high",
    "start": "647949",
    "end": "655209"
  },
  {
    "text": "performance compute cluster on Amazon batch you've learned from our errors and can",
    "start": "655209",
    "end": "661240"
  },
  {
    "text": "move forward and build your own solution in a much faster manner so first a QR is",
    "start": "661240",
    "end": "667090"
  },
  {
    "start": "664000",
    "end": "688000"
  },
  {
    "text": "a quantitative asset management firm were based in Greenwich Connecticut we",
    "start": "667090",
    "end": "673390"
  },
  {
    "text": "have roughly a thousand employees close to 50% of those employees have advanced",
    "start": "673390",
    "end": "680590"
  },
  {
    "text": "degrees and as of September 30th we had 226 billion of assets under management",
    "start": "680590",
    "end": "689009"
  },
  {
    "start": "688000",
    "end": "739000"
  },
  {
    "text": "so background so where as I mentioned",
    "start": "689160",
    "end": "694330"
  },
  {
    "text": "we're a quantitative asset management firm and what that means is we make our investment decisions driven by numerical",
    "start": "694330",
    "end": "702010"
  },
  {
    "text": "models so we're a quant fund to coin a phrase researchers working for us",
    "start": "702010",
    "end": "710320"
  },
  {
    "text": "develop these models to describe various markets so they may develop a model the",
    "start": "710320",
    "end": "717070"
  },
  {
    "text": "to describe equity markets and then backtest those models going back several decades to validate those models and",
    "start": "717070",
    "end": "724350"
  },
  {
    "text": "then these same researchers have a never-ending appetite for more data so",
    "start": "724350",
    "end": "729430"
  },
  {
    "text": "as more data comes in they can use that data to add additional factors additional features to the models that",
    "start": "729430",
    "end": "735850"
  },
  {
    "text": "we have and hopefully fine tune performance so what does that workflow",
    "start": "735850",
    "end": "741760"
  },
  {
    "start": "739000",
    "end": "853000"
  },
  {
    "text": "will look like so here I'm gonna describe a workflow for a typical researcher it's purely illustrative it",
    "start": "741760",
    "end": "748330"
  },
  {
    "text": "doesn't describe exactly what AQR does I'm greatly simplifying it here for this",
    "start": "748330",
    "end": "753940"
  },
  {
    "text": "particular presentation so a researcher starts with an idea maybe his idea is earnings per share is",
    "start": "753940",
    "end": "761470"
  },
  {
    "text": "a good indicator for future performance of inequity so he goes to our databases",
    "start": "761470",
    "end": "767410"
  },
  {
    "text": "that we have he gathers up the data to describe earnings per share and equities and all of this historical data he fires",
    "start": "767410",
    "end": "775210"
  },
  {
    "text": "up his local development environment let's say in pycharm developing in",
    "start": "775210",
    "end": "780220"
  },
  {
    "text": "Python and builds a model to describe his idea so again maybe he's thinking",
    "start": "780220",
    "end": "786370"
  },
  {
    "text": "earnings per share is a good predictor he tests that model locally on his",
    "start": "786370",
    "end": "791710"
  },
  {
    "text": "in development environment to make sure it's syntactically correct it compiles it runs and then the next thing he wants",
    "start": "791710",
    "end": "798430"
  },
  {
    "text": "to do is validate that that model is actually a good idea so he back tests it so instead of just testing locally on",
    "start": "798430",
    "end": "804760"
  },
  {
    "text": "his machine he may want to test 20,000 equities going back 10 20 30 40 years",
    "start": "804760",
    "end": "811410"
  },
  {
    "text": "that's where the cluster comes into play so he wants to submit that job to a big",
    "start": "811410",
    "end": "816700"
  },
  {
    "text": "cluster on the back end what paralyzes that job across all the nodes that are available and then finally analyze the",
    "start": "816700",
    "end": "823779"
  },
  {
    "text": "results so the cluster finishes analyzing the back tests or the cluster finishes running the back test the",
    "start": "823779",
    "end": "830470"
  },
  {
    "text": "result is given to the researcher he analyzes it determines if there's any merit to that particular model and then",
    "start": "830470",
    "end": "837250"
  },
  {
    "text": "iterates on the process maybe earnings per share isn't a good predictor maybe if he adds market capitalization to the",
    "start": "837250",
    "end": "844600"
  },
  {
    "text": "model that would be a good predictor and again he goes through the process again of gathering the data building a model",
    "start": "844600",
    "end": "850690"
  },
  {
    "text": "back testing etc etc so the problem that we have on-premise compute grid can't",
    "start": "850690",
    "end": "858040"
  },
  {
    "start": "853000",
    "end": "917000"
  },
  {
    "text": "keep up so as we continue to grow as we add more researchers they're constantly",
    "start": "858040",
    "end": "864430"
  },
  {
    "text": "adding more back tests more compute resources to the grid and the grid can't",
    "start": "864430",
    "end": "870279"
  },
  {
    "text": "keep up capex ends up being locked into those grid resources so as researchers",
    "start": "870279",
    "end": "876550"
  },
  {
    "text": "go home for the weekends in the evening the grid basically sits idle and we have dollars now invested in that grid that",
    "start": "876550",
    "end": "883450"
  },
  {
    "text": "are effectively doing nothing researchers are waiting for grid resources so they were waiting in queue",
    "start": "883450",
    "end": "889029"
  },
  {
    "text": "no longer they wait in queue the longer it takes us to develop a new signal and",
    "start": "889029",
    "end": "894130"
  },
  {
    "text": "the longer this entire process takes of that feedback loop in the prior slide a",
    "start": "894130",
    "end": "900240"
  },
  {
    "text": "corollary to that is researchers need to get job results quickly and then finally",
    "start": "900240",
    "end": "905800"
  },
  {
    "text": "we have new experimental use cases especially around GPU that require a",
    "start": "905800",
    "end": "910930"
  },
  {
    "text": "significant upfront capital investment that we don't want to make that investment for just an experimental use",
    "start": "910930",
    "end": "917200"
  },
  {
    "start": "917000",
    "end": "999000"
  },
  {
    "text": "case so what were our design considerations we wanted the solution to",
    "start": "917200",
    "end": "922990"
  },
  {
    "text": "be scalable both in compute in memory and then along with that solution we wanted it to be fast without long queue",
    "start": "922990",
    "end": "930040"
  },
  {
    "text": "times so we wanted a researcher to be able to submit a job and not have to wait in line behind another researcher",
    "start": "930040",
    "end": "936040"
  },
  {
    "text": "in order to get his job into the running state we didn't want to manage a job",
    "start": "936040",
    "end": "941380"
  },
  {
    "text": "scheduler so there's a lot of high performance compute job schedulers out there like Condor slurm Sun Grid Engine",
    "start": "941380",
    "end": "948790"
  },
  {
    "text": "we found them extremely difficult to maintain and support the Condor manual",
    "start": "948790",
    "end": "954699"
  },
  {
    "text": "itself is over a thousand pages we didn't want to have to dedicate resources in order to support a job",
    "start": "954699",
    "end": "961690"
  },
  {
    "text": "scheduler we wanted to be very easy-to-use so we wanted researchers to",
    "start": "961690",
    "end": "967779"
  },
  {
    "text": "be able to develop their model locally on their workstation and then submit it to the grid in sort of a seamless manner",
    "start": "967779",
    "end": "973920"
  },
  {
    "text": "we didn't want to have to have them to go through and he saw the pre-processing step or pre-staging step of putting the",
    "start": "973920",
    "end": "980440"
  },
  {
    "text": "data or the code in a particular place in order for the job to run on the grid and then of course we're a financial",
    "start": "980440",
    "end": "987160"
  },
  {
    "text": "institution we wanted the solution to be secure and we wanted that security issue to be an issue for the cloud engineering",
    "start": "987160",
    "end": "994240"
  },
  {
    "text": "and the InfoSec team and not necessarily an issue for the researchers themselves",
    "start": "994240",
    "end": "999420"
  },
  {
    "start": "999000",
    "end": "1038000"
  },
  {
    "text": "so here we are reinvent it goes without saying that we",
    "start": "999420",
    "end": "1005069"
  },
  {
    "text": "built the solution on AWS we built it because AWS provides that burst ability",
    "start": "1005069",
    "end": "1010199"
  },
  {
    "text": "that we need it also we leveraged as many building block services that AWS",
    "start": "1010199",
    "end": "1015540"
  },
  {
    "text": "has provides in order to build this solution as quickly as possible so we leverage services like Amazon s3 and is",
    "start": "1015540",
    "end": "1023010"
  },
  {
    "text": "on batch ec2 ECS Kinesis etc and then we",
    "start": "1023010",
    "end": "1028798"
  },
  {
    "text": "also leverage spot and we'll get into how much it cost us to actually run on",
    "start": "1028799",
    "end": "1034319"
  },
  {
    "text": "spot but it's significantly less than running the on-premise grid we wanted a",
    "start": "1034319",
    "end": "1040980"
  },
  {
    "start": "1038000",
    "end": "1109000"
  },
  {
    "text": "seamless interface so we base that interface on Sun and grid engine if you're familiar with Sun grid engine you",
    "start": "1040980",
    "end": "1047010"
  },
  {
    "text": "may be familiar with commands like beast q sub and q s-- that we created similar",
    "start": "1047010",
    "end": "1052080"
  },
  {
    "text": "commands called B sub and B stat and we picked Sun grid engine because they do a",
    "start": "1052080",
    "end": "1057419"
  },
  {
    "text": "very good job and we wanted an interface that was familiar to researchers we created a submit jobs API",
    "start": "1057419",
    "end": "1063930"
  },
  {
    "text": "using the AWS command line that basically allowed them to submit jobs",
    "start": "1063930",
    "end": "1069210"
  },
  {
    "text": "via CLI or an API which gave them unlimited compute at their fingertips this for the researchers and then a",
    "start": "1069210",
    "end": "1076350"
  },
  {
    "text": "short feedback loop so jobs got to the start state as quickly as possible and then most importantly to me at least",
    "start": "1076350",
    "end": "1083550"
  },
  {
    "text": "having worked in IT for 20 years is we wanted the backend environment that the",
    "start": "1083550",
    "end": "1089160"
  },
  {
    "text": "researchers are running their jobs in to match their front-end workstation where they're developing their jobs it's very",
    "start": "1089160",
    "end": "1096270"
  },
  {
    "text": "frustrating to have a situation where a job runs in one environment ie your workstation but then as soon as you",
    "start": "1096270",
    "end": "1103020"
  },
  {
    "text": "submitted to the grid the job no longer works those are always difficult issues to",
    "start": "1103020",
    "end": "1108210"
  },
  {
    "text": "take care of or resolve we want it to be very fast we automated everything in the",
    "start": "1108210",
    "end": "1114090"
  },
  {
    "start": "1109000",
    "end": "1137000"
  },
  {
    "text": "environment we leveraged infrastructure as code to deploy our solution and also to manage it we basically gave in quotes",
    "start": "1114090",
    "end": "1121740"
  },
  {
    "text": "unlimited compute and we'll get to why that's unlimited in quotes in a few slides and we wanted very short start",
    "start": "1121740",
    "end": "1130020"
  },
  {
    "text": "times so we wanted a job to be submitted and to be running in the running state within minutes without long queues for",
    "start": "1130020",
    "end": "1136680"
  },
  {
    "text": "the researcher and then we wanted the solution to be secure we did encryption",
    "start": "1136680",
    "end": "1142170"
  },
  {
    "start": "1137000",
    "end": "1172000"
  },
  {
    "text": "everywhere which isn't the best of security controls but in the cloud AWS",
    "start": "1142170",
    "end": "1147480"
  },
  {
    "text": "makes it very easy to just sort of check the box and get encryption we leverage as many AWS security controls the tools",
    "start": "1147480",
    "end": "1154890"
  },
  {
    "text": "as possible so we use things like kms guard duty I am and then as I said",
    "start": "1154890",
    "end": "1161550"
  },
  {
    "text": "before we made security a cloud engineering issue and not a researcher issue who tried to make security as easy",
    "start": "1161550",
    "end": "1168300"
  },
  {
    "text": "as possible for the researchers to just natively work in their environment so",
    "start": "1168300",
    "end": "1173610"
  },
  {
    "start": "1172000",
    "end": "1214000"
  },
  {
    "text": "now let's get to the solution itself so we start here in the lower right hand",
    "start": "1173610",
    "end": "1178830"
  },
  {
    "text": "corner with little grey men those are the researchers they are remote desktop",
    "start": "1178830",
    "end": "1184170"
  },
  {
    "text": "being doing the RDP protocol into a Linux virtual desktop that's running on",
    "start": "1184170",
    "end": "1190230"
  },
  {
    "text": "ec2 that Desktop has an NFS mount point for the home directories along with a bunch of",
    "start": "1190230",
    "end": "1197309"
  },
  {
    "text": "temp shares and data shares that exists on EFS and they login to that",
    "start": "1197309",
    "end": "1202919"
  },
  {
    "text": "environment they get a full desktop they fire up PyCharm they start developing",
    "start": "1202919",
    "end": "1209009"
  },
  {
    "text": "their models they test them locally make sure that they work and then when they have a working model they submit it to",
    "start": "1209009",
    "end": "1216179"
  },
  {
    "start": "1214000",
    "end": "1244000"
  },
  {
    "text": "batch and we've written a very lightweight wrapper around Amazon batch that we call batch star that's used to",
    "start": "1216179",
    "end": "1223830"
  },
  {
    "text": "submit jobs so researchers are fairly non-technical users we don't want to expose the entire AWS API to them so",
    "start": "1223830",
    "end": "1232499"
  },
  {
    "text": "we've simplified that by delivering this simplified interface which we call batch star and that takes care of bundling up",
    "start": "1232499",
    "end": "1240600"
  },
  {
    "text": "the job and submitting it into batch and then after that batch does all the heavy",
    "start": "1240600",
    "end": "1245820"
  },
  {
    "text": "lifting so batch then fires up all of our ec2",
    "start": "1245820",
    "end": "1250830"
  },
  {
    "text": "instances across six different availability zones connects those",
    "start": "1250830",
    "end": "1256649"
  },
  {
    "text": "instances to ECS starts the containers and then starts running and executing",
    "start": "1256649",
    "end": "1263249"
  },
  {
    "text": "the jobs we store our container images in ECR and then we have a job state",
    "start": "1263249",
    "end": "1269489"
  },
  {
    "text": "engine that orchestrates the jobs across the cluster running in s3 what's",
    "start": "1269489",
    "end": "1276029"
  },
  {
    "text": "important to note here is that the jobs are executing in the same context that the user is running them in so if the",
    "start": "1276029",
    "end": "1283259"
  },
  {
    "text": "user is logged into VDI as Joe Schmoe when the jobs execute on the back-end",
    "start": "1283259",
    "end": "1288570"
  },
  {
    "text": "grid they're also executing as Joe Schmoe with the same user ID and GID",
    "start": "1288570",
    "end": "1294239"
  },
  {
    "text": "which means there's an NFS mount point and that container has the same access",
    "start": "1294239",
    "end": "1300690"
  },
  {
    "text": "to those files as the end-user does who submitted the job this is critical",
    "start": "1300690",
    "end": "1306149"
  },
  {
    "text": "because it allows the output of those jobs to go to that EFS endpoint and",
    "start": "1306149",
    "end": "1312149"
  },
  {
    "text": "still be accessible by the researcher when he wants to analyze the results so",
    "start": "1312149",
    "end": "1318389"
  },
  {
    "text": "what does this look like from the researchers perspective so this is the simple command that they need to run in",
    "start": "1318389",
    "end": "1323730"
  },
  {
    "text": "order to submit a job to the grid and you can see here it's written in bash there's a for loop there going from",
    "start": "1323730",
    "end": "1330239"
  },
  {
    "text": "1 to 25 they're executing a command Python test my model just sort of a",
    "start": "1330239",
    "end": "1336450"
  },
  {
    "text": "made-up command and they're piping that into this b sub command that we've",
    "start": "1336450",
    "end": "1341580"
  },
  {
    "text": "created and then once that command is executed B sub is gonna wrap up that",
    "start": "1341580",
    "end": "1348840"
  },
  {
    "text": "command itself and submit it to Amazon batch under the covers Amazon batch is",
    "start": "1348840",
    "end": "1354840"
  },
  {
    "text": "going to spin up 25 different containers and each one of those different containers is going to execute the",
    "start": "1354840",
    "end": "1361559"
  },
  {
    "text": "command Python test my model and the researcher could just as easily have",
    "start": "1361559",
    "end": "1366600"
  },
  {
    "text": "scaled this up instead of doing 25 containers it could have been twenty-five hundred twenty-five thousand",
    "start": "1366600",
    "end": "1372899"
  },
  {
    "text": "two hundred fifty thousand containers it doesn't really matter to us the researcher also has control of how big",
    "start": "1372899",
    "end": "1380159"
  },
  {
    "start": "1376000",
    "end": "1404000"
  },
  {
    "text": "he would like the container to be so instead of in the previous slide you can see he could scale it out laterally but",
    "start": "1380159",
    "end": "1387389"
  },
  {
    "text": "now we can also scale out the container vertically as well so he can set the number of CPU for each one of those",
    "start": "1387389",
    "end": "1393210"
  },
  {
    "text": "containers he can also set the memory so we can go CPU all the way up to 36 VC PU",
    "start": "1393210",
    "end": "1399600"
  },
  {
    "text": "and you can set the memory all the way up to 128 gigs of RAM once he submits",
    "start": "1399600",
    "end": "1406590"
  },
  {
    "start": "1404000",
    "end": "1424000"
  },
  {
    "text": "the job he gets a nice little interface like that basically shows him the status of the job each one of the lines and",
    "start": "1406590",
    "end": "1413279"
  },
  {
    "text": "that output is an individual container that's running the Python test my model it goes into the runnable state and then",
    "start": "1413279",
    "end": "1420989"
  },
  {
    "text": "when the job is done you can see that it's actually succeeded now some researchers are saying have said hey the",
    "start": "1420989",
    "end": "1428249"
  },
  {
    "start": "1424000",
    "end": "1478000"
  },
  {
    "text": "CLI is nice but I would like an API as well because I do all my development in",
    "start": "1428249",
    "end": "1433649"
  },
  {
    "text": "Python and I want to immediately as part of my pipeline go directly from",
    "start": "1433649",
    "end": "1439859"
  },
  {
    "text": "development into job submission and back tests and I don't want to have to now shell out to the CLI to submit my job so",
    "start": "1439859",
    "end": "1448109"
  },
  {
    "text": "we wrote an API that again wraps around the Amazon batch and the researcher",
    "start": "1448109",
    "end": "1454649"
  },
  {
    "text": "instantiates a cluster object specifying a CPU and memory for each one of the containers and then he has this function",
    "start": "1454649",
    "end": "1462140"
  },
  {
    "text": "called cloud map cloud map is exactly the same as the Python map function if",
    "start": "1462140",
    "end": "1468890"
  },
  {
    "text": "you're familiar with Python and that function it takes two arguments the first argument is a function in this",
    "start": "1468890",
    "end": "1476030"
  },
  {
    "text": "case it's this made-up function called foo and foo is just taking an input and",
    "start": "1476030",
    "end": "1481160"
  },
  {
    "text": "raising two to that power so 2 to the 0 2 to the 1 etc and then also arrange a",
    "start": "1481160",
    "end": "1487340"
  },
  {
    "text": "list in it or and in this case it's the numbers from 0 to 9 so map in this case",
    "start": "1487340",
    "end": "1494120"
  },
  {
    "text": "is going to call foo and it's going to raise 2 to the 0 power 2 to the 1 power 2 to the 2 2 to the 3 etc etc etc now",
    "start": "1494120",
    "end": "1502060"
  },
  {
    "text": "that if we use map the normal map that would just execute locally on the",
    "start": "1502060",
    "end": "1507650"
  },
  {
    "text": "workstation and then return the results to the cop-caller here we're using cloud",
    "start": "1507650",
    "end": "1512720"
  },
  {
    "text": "map and what that's doing is now bundling each one of those different calls and executing it in a container on",
    "start": "1512720",
    "end": "1519620"
  },
  {
    "text": "Amazon batch so all of this is now executing remotely now we wouldn't",
    "start": "1519620",
    "end": "1525560"
  },
  {
    "text": "necessarily do this to raise 2 to a power that's a bit silly you can imagine replacing foo with that test my model",
    "start": "1525560",
    "end": "1533300"
  },
  {
    "text": "and running a back test and instead of iterating between 0 and 9 you would",
    "start": "1533300",
    "end": "1538670"
  },
  {
    "text": "iterate across 20,000 different equities researchers also came to us and said hey",
    "start": "1538670",
    "end": "1545150"
  },
  {
    "start": "1544000",
    "end": "1567000"
  },
  {
    "text": "this is great but what I'd like to do is I like to submit a job and then have that job submit additional jobs so here",
    "start": "1545150",
    "end": "1552950"
  },
  {
    "text": "we have an API where we're calling a job within a job and then that function job",
    "start": "1552950",
    "end": "1558050"
  },
  {
    "text": "within a job instantiates as you can see there on line 29 its tan shi'ites yet",
    "start": "1558050",
    "end": "1563060"
  },
  {
    "text": "another job that is being submitted to the grid the benefit of this is now",
    "start": "1563060",
    "end": "1569330"
  },
  {
    "text": "we're able to create direct asic book grass so in this scenario you have a",
    "start": "1569330",
    "end": "1574970"
  },
  {
    "text": "researcher he says hey I would like to back test 20,000 equities going across",
    "start": "1574970",
    "end": "1580790"
  },
  {
    "text": "two decades so the first job that he submits is a job for each one of those",
    "start": "1580790",
    "end": "1586790"
  },
  {
    "text": "different equities so Apple Microsoft IBM HP and then each one of those",
    "start": "1586790",
    "end": "1592820"
  },
  {
    "text": "jobs calls a child job that then deals with each one of the different years",
    "start": "1592820",
    "end": "1598549"
  },
  {
    "text": "across all of those different decades decades the beauty here is now we have",
    "start": "1598549",
    "end": "1603830"
  },
  {
    "text": "this massive parallelism going on or basically executing 20,000 equities",
    "start": "1603830",
    "end": "1609620"
  },
  {
    "text": "times 20 years worth of data and that's creating an enormous number of jobs all",
    "start": "1609620",
    "end": "1616610"
  },
  {
    "text": "at once each one of these jobs is then executing then rolling back their results to their parent job and then",
    "start": "1616610",
    "end": "1623870"
  },
  {
    "text": "finally rolling back those results back to the calling client so the researcher can analyze the results all right so now",
    "start": "1623870",
    "end": "1631850"
  },
  {
    "start": "1630000",
    "end": "1686000"
  },
  {
    "text": "lessons learned the first set of lessons learned is basically AWS 101 you're",
    "start": "1631850",
    "end": "1638629"
  },
  {
    "text": "running a batch job used the spot fleet as much as possible for us the table to",
    "start": "1638629",
    "end": "1644210"
  },
  {
    "text": "drive down costs down to $15 an hour for 1000v cpu so basically $15 for 500",
    "start": "1644210",
    "end": "1654139"
  },
  {
    "text": "physical course it's an incredibly low price and something that we can't match on-premise use as many instance types as",
    "start": "1654139",
    "end": "1661220"
  },
  {
    "text": "you can so that spot fleet has as many options as possible to drive the lowest cost we happen to use c5s m5s and our",
    "start": "1661220",
    "end": "1669649"
  },
  {
    "text": "fives which is also all of the instances that work for us and are layered on top",
    "start": "1669649",
    "end": "1675649"
  },
  {
    "text": "of the nitro hypervisor which we've had a lot of success with working with and then also again to lower the cost as",
    "start": "1675649",
    "end": "1683000"
  },
  {
    "text": "much as possible use as many AZ's as you can log everything",
    "start": "1683000",
    "end": "1688820"
  },
  {
    "start": "1686000",
    "end": "1692000"
  },
  {
    "text": "ECS logs job output host logs etc and then also monitor everything so you if",
    "start": "1688820",
    "end": "1696350"
  },
  {
    "start": "1692000",
    "end": "1736000"
  },
  {
    "text": "you build a solution like this you're gonna end up building a lot of custom metrics that don't come out of the box",
    "start": "1696350",
    "end": "1702019"
  },
  {
    "text": "from Amazon so you're gonna want to track the job run time you're gonna want to track the job startup time so the",
    "start": "1702019",
    "end": "1708529"
  },
  {
    "text": "time that it goes from start time to the actual job in the running state you'll need the cha track job cost as well this",
    "start": "1708529",
    "end": "1716210"
  },
  {
    "text": "is something your management will always ask who's using the most resources on the grid who's charging or driving up",
    "start": "1716210",
    "end": "1722870"
  },
  {
    "text": "costs the most and then you'll also want to track high priority Hieu usage because there's always that",
    "start": "1722870",
    "end": "1728339"
  },
  {
    "text": "one guy in the group that feels he can cut the line and constantly use the high priority queue do you want to track for",
    "start": "1728339",
    "end": "1735149"
  },
  {
    "text": "that as well all of this monitoring can then you be used to develop cloud watch",
    "start": "1735149",
    "end": "1741599"
  },
  {
    "start": "1736000",
    "end": "1766000"
  },
  {
    "text": "dashboards we use cloud watch you could use Griffin and others tons of tools out there to visualize data we use cloud",
    "start": "1741599",
    "end": "1749070"
  },
  {
    "text": "watch just because it's very easy to publish data into cloud watch but also",
    "start": "1749070",
    "end": "1754129"
  },
  {
    "text": "publish data out of our logs into cloud watch as well so we monitor everything",
    "start": "1754129",
    "end": "1760589"
  },
  {
    "text": "the batch compute the desired level the CPU by user etc etc etc and the",
    "start": "1760589",
    "end": "1767099"
  },
  {
    "start": "1766000",
    "end": "1789000"
  },
  {
    "text": "dashboards really just continue our EFS percent IO limits job completion by",
    "start": "1767099",
    "end": "1772589"
  },
  {
    "text": "users all of this information is useful to all of your l1 and l2 operations",
    "start": "1772589",
    "end": "1779609"
  },
  {
    "text": "people that are going to be supporting the grid without these visualization trying to diagnose problems is extremely",
    "start": "1779609",
    "end": "1786719"
  },
  {
    "text": "difficult so more lessons learned as we added more",
    "start": "1786719",
    "end": "1793469"
  },
  {
    "start": "1789000",
    "end": "1829000"
  },
  {
    "text": "researchers we started getting into the dreaded too many requests exceptions if",
    "start": "1793469",
    "end": "1798629"
  },
  {
    "text": "you worked at Amazon or work for Amazon in any length of time you will run into",
    "start": "1798629",
    "end": "1803639"
  },
  {
    "text": "this particular issue and what was happening here is as we added more researchers they were calling this API",
    "start": "1803639",
    "end": "1810629"
  },
  {
    "text": "called describe jobs to get the status of their jobs is my job running is it stopped as it succeeded has it failed",
    "start": "1810629",
    "end": "1817229"
  },
  {
    "text": "and as we add on more researchers they're making more and more of these calls and we're getting these exceptions",
    "start": "1817229",
    "end": "1822629"
  },
  {
    "text": "the other issue that we're running into is governance guardrails so making sure that researchers are doing the right",
    "start": "1822629",
    "end": "1828209"
  },
  {
    "text": "thing the solution to that was to build an event-based pipeline so ray talked a",
    "start": "1828209",
    "end": "1833579"
  },
  {
    "start": "1829000",
    "end": "1853000"
  },
  {
    "text": "little bit about how Amazon batch emits events into cloud watch events as jobs",
    "start": "1833579",
    "end": "1839669"
  },
  {
    "text": "state changes so job goes to the pending state the starting state the finished of the succeeded state or the failed state",
    "start": "1839669",
    "end": "1846749"
  },
  {
    "text": "all of those events get fed into cloud watch events we then have a Kinesis",
    "start": "1846749",
    "end": "1851789"
  },
  {
    "text": "stream that listens to each one of those events and then a land a function that processes each of those events as",
    "start": "1851789",
    "end": "1857969"
  },
  {
    "start": "1853000",
    "end": "1872000"
  },
  {
    "text": "they're coming through and that lambda function is basically taking all of those events adding a little bit of metadata to them",
    "start": "1857969",
    "end": "1864600"
  },
  {
    "text": "and then sticking them into DynamoDB DynamoDB then has streams hanging off of",
    "start": "1864600",
    "end": "1871500"
  },
  {
    "text": "that and that allows us to now hook up a whole bunch of land of functions that do",
    "start": "1871500",
    "end": "1878010"
  },
  {
    "start": "1872000",
    "end": "1946000"
  },
  {
    "text": "a lot of useful things for us so the first lambda function a series of",
    "start": "1878010",
    "end": "1883050"
  },
  {
    "text": "lambda functions is the job policy enforcement so this is the this is the job engine that's watching for that user",
    "start": "1883050",
    "end": "1889980"
  },
  {
    "text": "who's submitting too many jobs to the high priority queue or a job that's been",
    "start": "1889980",
    "end": "1895170"
  },
  {
    "text": "running for too long or a job that's using the incorrect container and that lambda function is now if the policy",
    "start": "1895170",
    "end": "1903260"
  },
  {
    "text": "violation is bad enough going to terminate the job forcefully and or",
    "start": "1903260",
    "end": "1908280"
  },
  {
    "text": "email the end user that submitted it and then also we have this lambda function",
    "start": "1908280",
    "end": "1913440"
  },
  {
    "text": "that's collecting all these metrics so those metrics that you saw on the dashboard and now all being collected by",
    "start": "1913440",
    "end": "1918750"
  },
  {
    "text": "this lambda function some things like the cost of the job the running time of",
    "start": "1918750",
    "end": "1924210"
  },
  {
    "text": "the job all that good stuff is then being dumped into cloud watch and then finally the researchers are no longer",
    "start": "1924210",
    "end": "1931380"
  },
  {
    "text": "querying the described jobs API they can now query directly to DynamoDB and",
    "start": "1931380",
    "end": "1937910"
  },
  {
    "text": "DynamoDB allows us to sort of turn the dial and scale up as necessary without",
    "start": "1937910",
    "end": "1943140"
  },
  {
    "text": "having to run into any throttling limits second set of lessons learned as we",
    "start": "1943140",
    "end": "1949230"
  },
  {
    "text": "added more compute and scaled up the cluster from basically a thousand CPU all the way up to 50,000 CPU we're",
    "start": "1949230",
    "end": "1956309"
  },
  {
    "text": "running into now too many requests exceptions in the container itself we have some issues with job state we have",
    "start": "1956309",
    "end": "1962700"
  },
  {
    "text": "some issues with start time we issues with costs so the first one is I I love",
    "start": "1962700",
    "end": "1968250"
  },
  {
    "start": "1965000",
    "end": "2308000"
  },
  {
    "text": "this slide because this is AWS 101 this is what they tell you to do if you're",
    "start": "1968250",
    "end": "1973950"
  },
  {
    "text": "gonna run an e CS container and you want to get a secret into that container so if that ECS container needs to connect",
    "start": "1973950",
    "end": "1981660"
  },
  {
    "text": "to a database and you need to get a user's ID and a password and you store that into parameter store and then you",
    "start": "1981660",
    "end": "1988650"
  },
  {
    "text": "go get it so when you're scaling up a couple hundred e CS containers that's fine when you start scaling up",
    "start": "1988650",
    "end": "1995860"
  },
  {
    "text": "thousands 3,000 4,000 5,000 containers and you have this thundering herd",
    "start": "1995860",
    "end": "2001779"
  },
  {
    "text": "problem they're all starting at the same exact time parameter store tends to fail",
    "start": "2001779",
    "end": "2006909"
  },
  {
    "text": "fall over with too many requests exceptions and whether or not you'd want",
    "start": "2006909",
    "end": "2011980"
  },
  {
    "text": "to do exponential back-off or jitter or randomness to your retries it doesn't matter the gap between the",
    "start": "2011980",
    "end": "2019330"
  },
  {
    "text": "number of requests that you're making and what parameter store can support is just too broad so the solution here was",
    "start": "2019330",
    "end": "2027370"
  },
  {
    "text": "to use s3 so in our case we store our secrets on s3 which allows us to scale",
    "start": "2027370",
    "end": "2033159"
  },
  {
    "text": "up the level that we need to in order to support all of these containers starting",
    "start": "2033159",
    "end": "2038379"
  },
  {
    "text": "at once then we also have issues with job states so what does job State job",
    "start": "2038379",
    "end": "2044259"
  },
  {
    "text": "state is that shared memory that's used across containers and it's also handling job assignment so think of this you",
    "start": "2044259",
    "end": "2051040"
  },
  {
    "text": "you've submitted a job it's spinning up twenty thousand containers to analyze equities the first container starts up",
    "start": "2051040",
    "end": "2057550"
  },
  {
    "text": "and says what am I supposed to do the job state engine then responds and says you're working on Microsoft and here's",
    "start": "2057550",
    "end": "2064898"
  },
  {
    "text": "the data that you need in order to work on Microsoft next container starts up says the same thing to the job state",
    "start": "2064899",
    "end": "2071378"
  },
  {
    "text": "engine what am I supposed to work on you're working on Apple and here's the data that you need to work on Apple and",
    "start": "2071379",
    "end": "2076898"
  },
  {
    "text": "then it also deals with output and input so when the job finishes all of that",
    "start": "2076899",
    "end": "2082060"
  },
  {
    "text": "information is stored in the job state engine so that can be collected and returned to the caller so we started",
    "start": "2082060",
    "end": "2088599"
  },
  {
    "text": "this design using EFS as the job state storage that quickly fell over and it",
    "start": "2088599",
    "end": "2094960"
  },
  {
    "text": "fell over because EFS was running into percent IO limits and we were basically",
    "start": "2094960",
    "end": "2101170"
  },
  {
    "text": "pinning EFS in the cluster was no longer responding we switched to Redis and then",
    "start": "2101170",
    "end": "2106630"
  },
  {
    "text": "Redis fell over Redis fell over because researchers started submitting data into",
    "start": "2106630",
    "end": "2112180"
  },
  {
    "text": "the job state and we ran out of space within Redis itself you've ended up",
    "start": "2112180",
    "end": "2117310"
  },
  {
    "text": "finally settling on s3 this may look like oh you know we've moved from one",
    "start": "2117310",
    "end": "2123940"
  },
  {
    "text": "service to another and these services aren't our not good for you that's really not the case actually the point of this slide is",
    "start": "2123940",
    "end": "2130420"
  },
  {
    "text": "to show how easy it was to switch from one storage system to another with",
    "start": "2130420",
    "end": "2136990"
  },
  {
    "text": "relative ease so if I had to build this on premise and build out a scale out file system and by let's say Isilon and",
    "start": "2136990",
    "end": "2144580"
  },
  {
    "text": "deploy that and then find out oh that's not gonna work and now I need to switch to Redis and oh that's not gonna work",
    "start": "2144580",
    "end": "2149740"
  },
  {
    "text": "and switch to another it have been months of delay whereas here it was just a matter of days to switch from one to",
    "start": "2149740",
    "end": "2155740"
  },
  {
    "text": "the other next thing that you want to monitor is job start times so here is a",
    "start": "2155740",
    "end": "2162550"
  },
  {
    "text": "histogram of job start times you can see most of those jobs are starting within the first two minutes",
    "start": "2162550",
    "end": "2169420"
  },
  {
    "text": "I recommend that in order to reduce your jobs to start times you've baked your a.m. eyes with as much software as",
    "start": "2169420",
    "end": "2176770"
  },
  {
    "text": "possible and leave as little into the runtime of the image start as you can so",
    "start": "2176770",
    "end": "2183040"
  },
  {
    "text": "we use Packer from hashey Corp in order to bake our a.m. eyes and we have a launch time from the initial ec2 launch",
    "start": "2183040",
    "end": "2190360"
  },
  {
    "text": "to it now being able to access and run jobs of under 90 seconds and then I also",
    "start": "2190360",
    "end": "2196690"
  },
  {
    "text": "recommend that you give yourself an SLA for jobs so our SLA is that a job will start",
    "start": "2196690",
    "end": "2202060"
  },
  {
    "text": "within 10 minutes 75% of the time and 15 minutes 90% of the time and then as you",
    "start": "2202060",
    "end": "2209620"
  },
  {
    "text": "notice that we sort of have this long queue that saw it long tail to the start",
    "start": "2209620",
    "end": "2214960"
  },
  {
    "text": "times I'm going to get into why that's happening in the next slide so here we",
    "start": "2214960",
    "end": "2221620"
  },
  {
    "text": "have the compute environment you can see on the left hand side we have a number of V CPU that we're running and then",
    "start": "2221620",
    "end": "2228130"
  },
  {
    "text": "along the bottom there is a time scale you definitely want to set limits on",
    "start": "2228130",
    "end": "2233230"
  },
  {
    "text": "your cluster so don't do unlimited compute you want to set a limit for many",
    "start": "2233230",
    "end": "2239440"
  },
  {
    "text": "different reasons one and probably the biggest one is runaway cost so if you",
    "start": "2239440",
    "end": "2245410"
  },
  {
    "text": "allow your researchers to run basically at unlimited scale you'll quickly run into a scenario of someone leaving a job",
    "start": "2245410",
    "end": "2252220"
  },
  {
    "text": "running on a Friday evening and then it runs all weekend long at 50 or a hundred",
    "start": "2252220",
    "end": "2257710"
  },
  {
    "text": "thousand cores and then on Monday morning you come in with with that beautiful million dollar bill that's always difficult to defend",
    "start": "2257710",
    "end": "2265680"
  },
  {
    "text": "to the boss as to why you ran into that particular issue the other thing that",
    "start": "2265680",
    "end": "2271230"
  },
  {
    "text": "you may see if you start operating at scale is these little step functions going on here so what's happening there",
    "start": "2271230",
    "end": "2277920"
  },
  {
    "text": "is the someone has submitted a job that needs 50,000 CPU but batch doesn't",
    "start": "2277920",
    "end": "2284430"
  },
  {
    "text": "immediately scale you up to 50,000 instead it goes through steps this is",
    "start": "2284430",
    "end": "2290040"
  },
  {
    "text": "has some good and bad the the good part of it is it reduces that thundering herd",
    "start": "2290040",
    "end": "2295260"
  },
  {
    "text": "problem of everybody coming in at once the the downside of these step functions",
    "start": "2295260",
    "end": "2300690"
  },
  {
    "text": "is it adds to that tail of start time it leads to those longer starts of jobs all",
    "start": "2300690",
    "end": "2308520"
  },
  {
    "start": "2308000",
    "end": "2324000"
  },
  {
    "text": "right takeaways so follow Amazon best practices you spot multi a-z log",
    "start": "2308520",
    "end": "2316230"
  },
  {
    "text": "everything monitor everything so to what you'll hear from any solution architect or anybody from professional services",
    "start": "2316230",
    "end": "2322410"
  },
  {
    "text": "working with the Amazon team watch for scale issues so eliminate API calls in",
    "start": "2322410",
    "end": "2329790"
  },
  {
    "text": "your containers as much as you can only if you have to use an API call in a",
    "start": "2329790",
    "end": "2335910"
  },
  {
    "text": "container use only services that can scale things like DynamoDB s3 services",
    "start": "2335910",
    "end": "2343140"
  },
  {
    "text": "that you can turn a dial and make them go faster switch to event based versus",
    "start": "2343140",
    "end": "2349109"
  },
  {
    "text": "event and message based versus a polling based for status it's much easier to",
    "start": "2349109",
    "end": "2355500"
  },
  {
    "text": "design and deal with events as they're throwing through the flowing through a system than doing polls and then choose",
    "start": "2355500",
    "end": "2361890"
  },
  {
    "text": "your job state back-end with care I think we when we develop this we just sort of guesstimated that EFS would be",
    "start": "2361890",
    "end": "2369600"
  },
  {
    "text": "the right solution and I think we should we would have been better off if we had put more time into the upfront design",
    "start": "2369600",
    "end": "2376700"
  },
  {
    "start": "2376000",
    "end": "2410000"
  },
  {
    "text": "right a lightweight wrapper around the AWS batch API you're dealing with a lot",
    "start": "2376700",
    "end": "2382380"
  },
  {
    "text": "of non-technical people here they're not developers they're not engineers and",
    "start": "2382380",
    "end": "2388530"
  },
  {
    "text": "hence exposing the entire AWS SDK to them just doesn't make sense they should be have",
    "start": "2388530",
    "end": "2395350"
  },
  {
    "text": "that trim down to just the API as they need and then buried in there whether it's in lambda functions or as part of",
    "start": "2395350",
    "end": "2402280"
  },
  {
    "text": "that lightweight wrapper put in your governador function put in your your guardrails in place to make sure that",
    "start": "2402280",
    "end": "2408369"
  },
  {
    "text": "people do the right things reduce your start times so use things like Packer",
    "start": "2408369",
    "end": "2414960"
  },
  {
    "start": "2410000",
    "end": "2449000"
  },
  {
    "text": "Netflix as a tool to do this as well to pre-bake your a.m. eyes if you'd like",
    "start": "2414960",
    "end": "2421510"
  },
  {
    "text": "pre warm your cluster during active times a day it's another way to reduce the start times so you can say instead",
    "start": "2421510",
    "end": "2428440"
  },
  {
    "text": "of being at 0 at 8 a.m. say hey let's start at 1000 cores at 8 a.m. and then we'll scale up and down from there and",
    "start": "2428440",
    "end": "2435130"
  },
  {
    "text": "then at 6 p.m. scale it back down to 0 give yourself and your end users an SLA",
    "start": "2435130",
    "end": "2441369"
  },
  {
    "text": "for job start times this is how they'll be judging you based on your performance how quickly jobs get into the started",
    "start": "2441369",
    "end": "2448450"
  },
  {
    "text": "state and then last but not least have controls for a runaway costs so alarm",
    "start": "2448450",
    "end": "2455859"
  },
  {
    "start": "2449000",
    "end": "2494000"
  },
  {
    "text": "for long running jobs we mentioned previously that you can set a time out",
    "start": "2455859",
    "end": "2462580"
  },
  {
    "text": "on jobs that's great if you put that into your governador function to make sure that the time out is always the",
    "start": "2462580",
    "end": "2468580"
  },
  {
    "text": "hard time out that's available in batch you can do it that way you can also just monitor for it and alarm when there's a",
    "start": "2468580",
    "end": "2475150"
  },
  {
    "text": "job that's been running for too long or so too outside of your window of expectation for a job to run and then",
    "start": "2475150",
    "end": "2481690"
  },
  {
    "text": "finally set limits on your compute environment do not let it run in sort of an unlimited state make sure you set a",
    "start": "2481690",
    "end": "2488710"
  },
  {
    "text": "cap as a number of CPU that you can actually execute all right that's it QA",
    "start": "2488710",
    "end": "2498010"
  },
  {
    "start": "2494000",
    "end": "2805000"
  },
  {
    "text": "there's a microphone here if you'd like to walk up to that for people that don't",
    "start": "2498010",
    "end": "2503830"
  },
  {
    "text": "like to walk up to the microphone I'm one of them ray and I will be here after",
    "start": "2503830",
    "end": "2510369"
  },
  {
    "text": "the presentation outside if you'd like to talk to his one-on-one thanks the",
    "start": "2510369",
    "end": "2516760"
  },
  {
    "text": "question is with your child job within a job thing that you constructed I'm",
    "start": "2516760",
    "end": "2522280"
  },
  {
    "text": "assuming then that the parent job is waiting synchronously for the cherrylle jobs that's correct you have a",
    "start": "2522280",
    "end": "2529510"
  },
  {
    "text": "limit on how deep the child jobs can go no we don't I can go as deep as they'd like so a job forever a job could wait",
    "start": "2529510",
    "end": "2538240"
  },
  {
    "text": "forever but eventually that governador function that's basically in place to",
    "start": "2538240",
    "end": "2543340"
  },
  {
    "text": "make sure it doesn't wait forever would hop in and say kill this job thank you I",
    "start": "2543340",
    "end": "2550740"
  },
  {
    "text": "could pretty good good presentation thank you um thank you question about the data so you you you",
    "start": "2550740",
    "end": "2557440"
  },
  {
    "text": "deal with a lot of data financial data that goes into these containers that are split into many cores where do you store",
    "start": "2557440",
    "end": "2563500"
  },
  {
    "text": "that data so the data is sort of all over the place that a QR some of it is back on premise but for a latency",
    "start": "2563500",
    "end": "2570880"
  },
  {
    "text": "perspective we try to keep as much of the data in the cloud as as possible so our storage mechanisms are today they're",
    "start": "2570880",
    "end": "2578890"
  },
  {
    "text": "EFS and they're also s3 I see and the other thing about the you know you",
    "start": "2578890",
    "end": "2585010"
  },
  {
    "text": "talked about writing the lightweight wrapper and I think that's what you called batch star yes is that something that you would ever consider open source",
    "start": "2585010",
    "end": "2591369"
  },
  {
    "text": "so we are considering open sourcing it so just a fun fact here if you're familiar with the pandas library that",
    "start": "2591369",
    "end": "2598240"
  },
  {
    "text": "was built and published by a QR so we have a history of sort of open sourcing project we also have a history and",
    "start": "2598240",
    "end": "2604990"
  },
  {
    "text": "academia academia of publishing our results in papers and now we're also",
    "start": "2604990",
    "end": "2610720"
  },
  {
    "text": "getting into the sort of business of open sourcing more of our projects this is one of the top projects that were",
    "start": "2610720",
    "end": "2616570"
  },
  {
    "text": "considering open sourcing excellent thank you George I was just wondering",
    "start": "2616570",
    "end": "2622900"
  },
  {
    "text": "how you're handling a client feedback if you have a client crash or anything that is long-range AAB you're sending that",
    "start": "2622900",
    "end": "2629560"
  },
  {
    "text": "information back to the to the client in those cases sure so there's a couple commands that are available to them",
    "start": "2629560",
    "end": "2636849"
  },
  {
    "text": "this command beast at which is the equivalent the beast that is available for them to check the status of jobs",
    "start": "2636849",
    "end": "2643140"
  },
  {
    "text": "there's also a command that we call B log blog that you can then get your logs",
    "start": "2643140",
    "end": "2649060"
  },
  {
    "text": "out of the job itself and then last but not least we take we also take all of the the log output goes into cloud watch",
    "start": "2649060",
    "end": "2657040"
  },
  {
    "text": "logs and then we have a Kinesis connect - that that streams those logs down into",
    "start": "2657040",
    "end": "2663080"
  },
  {
    "text": "an on-premise Splunk so then researchers can go into Splunk and then you know parson and view the",
    "start": "2663080",
    "end": "2669590"
  },
  {
    "text": "logs from there thank you sure aw is",
    "start": "2669590",
    "end": "2675560"
  },
  {
    "text": "that have support for Windows at this point it's something that will be on our",
    "start": "2675560",
    "end": "2684530"
  },
  {
    "text": "roadmap for 2019 yes okay and generally in high-performance computing the",
    "start": "2684530",
    "end": "2690980"
  },
  {
    "text": "concept is of a job and a task the task",
    "start": "2690980",
    "end": "2700570"
  },
  {
    "text": "is that the smallest unit of first yes that's the smallest unit we also have a concept called a ray job which if you",
    "start": "2700570",
    "end": "2708290"
  },
  {
    "text": "submit a red job you can have thousands hundred thousands of child jobs that's a",
    "start": "2708290",
    "end": "2714800"
  },
  {
    "text": "single job unit our ray job is just a collection of a jobs that you can submit",
    "start": "2714800",
    "end": "2720140"
  },
  {
    "text": "all at once thank you thank you for",
    "start": "2720140",
    "end": "2726980"
  },
  {
    "text": "sharing your experience question is more like a compliance and security side when",
    "start": "2726980",
    "end": "2734450"
  },
  {
    "text": "you first had this idea to load your you know like a research environment in AWS",
    "start": "2734450",
    "end": "2740150"
  },
  {
    "text": "did you have to you know go through with a compliance oh of course how was that experience can you share",
    "start": "2740150",
    "end": "2746570"
  },
  {
    "text": "that it was good the security the infoe sect team that we have is very",
    "start": "2746570",
    "end": "2752180"
  },
  {
    "text": "understanding it's not it's not a team of just a flat-out no and then you have to sort of prove the yes that I've dealt",
    "start": "2752180",
    "end": "2758630"
  },
  {
    "text": "with before with other info SEC teams the very understanding of the business requirements so here",
    "start": "2758630",
    "end": "2764390"
  },
  {
    "text": "AWS makes sort of perfect sense for these types of workloads and then it was",
    "start": "2764390",
    "end": "2769610"
  },
  {
    "text": "just a matter of working with with InfoSec the AWS team and just convincing them that actually running in AWS is",
    "start": "2769610",
    "end": "2777170"
  },
  {
    "text": "just as secure as running in on-premise and then we have a bunch of controls",
    "start": "2777170",
    "end": "2783200"
  },
  {
    "text": "that I didn't get into in this presentation things like you can't launch an Internet gateway you have to",
    "start": "2783200",
    "end": "2789050"
  },
  {
    "text": "come on premise to get access to the Internet you have to go through a proxy still that's on",
    "start": "2789050",
    "end": "2794240"
  },
  {
    "text": "there's encryption at rest everywhere there's all these long series of controls that are in addition to the",
    "start": "2794240",
    "end": "2800450"
  },
  {
    "text": "controls that we have on-premise so it's it's actually more controls in place in the cloud than we do in on-premise data",
    "start": "2800450",
    "end": "2807680"
  },
  {
    "start": "2805000",
    "end": "3089000"
  },
  {
    "text": "centers thank you hi can you just",
    "start": "2807680",
    "end": "2814010"
  },
  {
    "text": "mention a little bit more about the jobs state that you were storing in s3 and what workflow engine you were using or",
    "start": "2814010",
    "end": "2821540"
  },
  {
    "text": "you wrote and how you dealt with that data sure so the workflow engine is",
    "start": "2821540",
    "end": "2826580"
  },
  {
    "text": "written by me so it it isn't very",
    "start": "2826580",
    "end": "2832070"
  },
  {
    "text": "complex so there's we basically serialized the job data and store it",
    "start": "2832070",
    "end": "2839980"
  },
  {
    "text": "persistently on s3 and then each one of the jobs when they start up they",
    "start": "2839980",
    "end": "2845720"
  },
  {
    "text": "understand how to deserialize that data and then determine where they are in the",
    "start": "2845720",
    "end": "2851420"
  },
  {
    "text": "process of processing the job itself so each one of the containers that execute",
    "start": "2851420",
    "end": "2858349"
  },
  {
    "text": "gets an index an index ID it's an environmental variable so when he",
    "start": "2858349",
    "end": "2864080"
  },
  {
    "text": "launches on the container launches he looks at his index he looks at his container the job state information was",
    "start": "2864080",
    "end": "2871760"
  },
  {
    "text": "just basically a giant map and matches his index to the hash in that map and",
    "start": "2871760",
    "end": "2877580"
  },
  {
    "text": "says oh that's what I need to work on that original sort of serialized object",
    "start": "2877580",
    "end": "2883790"
  },
  {
    "text": "is created when the researcher actually submits the job so when the researcher",
    "start": "2883790",
    "end": "2890000"
  },
  {
    "text": "submits the job that's when that job state is created and dumped onto s3 so",
    "start": "2890000",
    "end": "2896750"
  },
  {
    "text": "that's like the graph the dag graph is an s3 then right what's that the graph that is an s3 the compute graph the dad",
    "start": "2896750",
    "end": "2904280"
  },
  {
    "text": "graph is made by the code of the researcher himself so he's what he's the",
    "start": "2904280",
    "end": "2910070"
  },
  {
    "text": "guy who's describing how that dag could should be created and the dependencies that should exist and then all your",
    "start": "2910070",
    "end": "2916849"
  },
  {
    "text": "outputs are stored in a TFS and although what's the job outputs are in EFS so the researchers you can go back and see it",
    "start": "2916849",
    "end": "2923180"
  },
  {
    "text": "there that's correct Thanks sure question today morning",
    "start": "2923180",
    "end": "2929010"
  },
  {
    "text": "somebody unknown at the keynote they said there'll be luster the luster",
    "start": "2929010",
    "end": "2934380"
  },
  {
    "text": "filesystem HPC you went through your traumas of going from here first readers",
    "start": "2934380",
    "end": "2940590"
  },
  {
    "text": "and so on Luster's is something that we tend to use for HPC yes is there any",
    "start": "2940590",
    "end": "2947940"
  },
  {
    "text": "plans for integrating HP's HP a batch processing with lustre and potentially",
    "start": "2947940",
    "end": "2954900"
  },
  {
    "text": "doing some forms of checkpointing which luster gives you so that if you reach a certain guardrail you can then come back",
    "start": "2954900",
    "end": "2962450"
  },
  {
    "text": "stop the job come back any such features yeah yeah there's two great questions so",
    "start": "2962450",
    "end": "2969390"
  },
  {
    "text": "the first one on on EFS is you know fun fact right now the cluster is pinned at",
    "start": "2969390",
    "end": "2975840"
  },
  {
    "text": "100% utilization EFS is is hit its % io limit I happen to check before I got on",
    "start": "2975840",
    "end": "2982710"
  },
  {
    "text": "stage got the alert so EFS is having a problem for us right now",
    "start": "2982710",
    "end": "2988170"
  },
  {
    "text": "lustre may be the fix having experienced lustre in the past you have to load up",
    "start": "2988170",
    "end": "2995670"
  },
  {
    "text": "your own clients you the implementation that Amazon seems to have and this is",
    "start": "2995670",
    "end": "3000920"
  },
  {
    "text": "all brand-new you're getting my opinion on the fly here you have to copy the",
    "start": "3000920",
    "end": "3006290"
  },
  {
    "text": "data from s3 and then do some funky commands to persist the data back into",
    "start": "3006290",
    "end": "3012350"
  },
  {
    "text": "s3 with the the lustre connection and I'm not sure how that's going to get",
    "start": "3012350",
    "end": "3018980"
  },
  {
    "text": "exposed to research or a researcher is just looking at a file system he writes",
    "start": "3018980",
    "end": "3024470"
  },
  {
    "text": "he expects that file to exist when the lustre file system is rebuilt again and",
    "start": "3024470",
    "end": "3030110"
  },
  {
    "text": "I'm not sure how we would end up doing that so there are some issues there that",
    "start": "3030110",
    "end": "3035420"
  },
  {
    "text": "need to be resolved we are also exploring other file systems as well",
    "start": "3035420",
    "end": "3040580"
  },
  {
    "text": "beyond just EFS and lustre and there's a I'm not going to name any names but",
    "start": "3040580",
    "end": "3046160"
  },
  {
    "text": "there are a lot of them available in in the expo hall and then on your your",
    "start": "3046160",
    "end": "3051800"
  },
  {
    "text": "check point in question yeah yeah yeah that's it's such a difficult computer",
    "start": "3051800",
    "end": "3058340"
  },
  {
    "text": "song problem right I'd like to put those checkpoints in place and then to recover it's not something that we have built as",
    "start": "3058340",
    "end": "3065150"
  },
  {
    "text": "the cloud engineering team but it's possible that the research engineering team so we have researchers and then we",
    "start": "3065150",
    "end": "3071240"
  },
  {
    "text": "have research engineers that help those researchers it's possible that one of",
    "start": "3071240",
    "end": "3076400"
  },
  {
    "text": "them is in the audience looking at me right now it's possible that maybe one of those guys who build the",
    "start": "3076400",
    "end": "3081730"
  },
  {
    "text": "checkpointing as part of a job submission one thing about bluster fsx",
    "start": "3081730",
    "end": "3088310"
  },
  {
    "text": "for lustre so it will work out of box out of the box would batch right now if you use ec2 launch template use the",
    "start": "3088310",
    "end": "3097190"
  },
  {
    "start": "3089000",
    "end": "3154000"
  },
  {
    "text": "custom data use our data feature you can mount the lustre right now but eventually we might implement something",
    "start": "3097190",
    "end": "3105470"
  },
  {
    "text": "to make it easier for you to do it right maybe a checkbox saying I want to create a file system while I launch a computing",
    "start": "3105470",
    "end": "3113900"
  },
  {
    "text": "environment something like that yeah",
    "start": "3113900",
    "end": "3120140"
  },
  {
    "text": "those drivers will be built into the Ami's or you can install them on the run the kernel drivers so you mentioned when",
    "start": "3120140",
    "end": "3131390"
  },
  {
    "text": "the research is doing the historical analysis for back testing so the data is stored in some on-premise and some on",
    "start": "3131390",
    "end": "3137960"
  },
  {
    "text": "cloud and some on database file systems did you have any issues with searches",
    "start": "3137960",
    "end": "3145190"
  },
  {
    "text": "submit a job they face access issues connecting with different resources or",
    "start": "3145190",
    "end": "3150230"
  },
  {
    "text": "it was all like yeah so the the number one thing is we basically said to researchers look if you're going to use",
    "start": "3150230",
    "end": "3155930"
  },
  {
    "text": "this cluster in the cloud that data eventually needs to move in the cloud isn't less an access issue to a certain",
    "start": "3155930",
    "end": "3163460"
  },
  {
    "text": "extent the data sort of shared across the researchers it's sort of how they do their their business but it needed to",
    "start": "3163460",
    "end": "3171650"
  },
  {
    "text": "exist in the cloud and need to exist in scale we're first there's the latency",
    "start": "3171650",
    "end": "3177440"
  },
  {
    "text": "from going from where we are in Connecticut down to North Virginia just to get the data would be an issue but",
    "start": "3177440",
    "end": "3184640"
  },
  {
    "text": "the other issue would just be at fifty thousand cores or fifty thousand V CPU",
    "start": "3184640",
    "end": "3189830"
  },
  {
    "text": "25,000 cores most likely keel over anything that we had on-premise and that goes teen maybe",
    "start": "3189830",
    "end": "3197000"
  },
  {
    "text": "not related to this like what is that in our database or structure that you use on cloud which enables therefore the",
    "start": "3197000",
    "end": "3205190"
  },
  {
    "text": "uses to store the data there what do you mean so like on-premise so you cannot",
    "start": "3205190",
    "end": "3210680"
  },
  {
    "text": "connect it but due to the latency so what is like are they using somekind of Amazon redshift or like what are the",
    "start": "3210680",
    "end": "3217280"
  },
  {
    "text": "different data structures that they use oh that's something that I can't share but all I can say is it's stored a",
    "start": "3217280",
    "end": "3224930"
  },
  {
    "text": "combination of s3 and EFS in the cloud and another question so when the user submitted a job do you have any other",
    "start": "3224930",
    "end": "3232430"
  },
  {
    "text": "tools that to monitor like visually oh yeah this is running and are you just",
    "start": "3232430",
    "end": "3237920"
  },
  {
    "text": "using this batch there's the API that I showed to submit job also has an API",
    "start": "3237920",
    "end": "3245119"
  },
  {
    "text": "available to monitor jobs as well and there's also that command that I showed and quickly through one of the",
    "start": "3245119",
    "end": "3251329"
  },
  {
    "text": "screenshots their command called beast that we can actually monitor the status of your running job and then as well",
    "start": "3251329",
    "end": "3259190"
  },
  {
    "text": "there's logs they get outputted down to can be picked up by one of the commands",
    "start": "3259190",
    "end": "3264470"
  },
  {
    "text": "but also can be picked up through Splunk thank you sure thanks for the talk and I",
    "start": "3264470",
    "end": "3272359"
  },
  {
    "text": "just wondered do you treat your resources as a single cluster or do you implement any kind of segregation",
    "start": "3272359",
    "end": "3277480"
  },
  {
    "text": "between users that's a that's a great question so right now it's a single",
    "start": "3277480",
    "end": "3284779"
  },
  {
    "text": "cluster the goal was with the design that we could make the cluster big enough that no one would step on each",
    "start": "3284779",
    "end": "3291710"
  },
  {
    "text": "other what we're finding already is that people are stepping on each other so in",
    "start": "3291710",
    "end": "3297349"
  },
  {
    "text": "all likelihood will start to divvy things up by department since we deliver",
    "start": "3297349",
    "end": "3303799"
  },
  {
    "text": "everything is infrastructure as code it's relatively easy for us to just stamp out another high performance",
    "start": "3303799",
    "end": "3310190"
  },
  {
    "text": "compute cluster and then send a set of users one way and another set of users a different way that sounds familiar",
    "start": "3310190",
    "end": "3316220"
  },
  {
    "text": "okay and just one other question so I guess your actual framework from submitting jobs is quite opinionated in",
    "start": "3316220",
    "end": "3322160"
  },
  {
    "text": "terms of the researcher can run right so I guess they have to use that Python framework and you can't run like arbitrary you",
    "start": "3322160",
    "end": "3329619"
  },
  {
    "text": "know other like other languages or the you know ah yeah so so right now most of",
    "start": "3329619",
    "end": "3335259"
  },
  {
    "text": "them work in Python the the framework that you saw the batch line you know I did Python test my model that just as",
    "start": "3335259",
    "end": "3342279"
  },
  {
    "text": "easily could have been Java run my jar file or run this go program like it's",
    "start": "3342279",
    "end": "3347769"
  },
  {
    "text": "ubiquitous from that perspective the API itself though was written in Python",
    "start": "3347769",
    "end": "3353039"
  },
  {
    "text": "there isn't a plan yet to write it in any other programming language but it's",
    "start": "3353039",
    "end": "3358089"
  },
  {
    "text": "relatively easy to port to to someplace else if we needed to okay thanks very",
    "start": "3358089",
    "end": "3363249"
  },
  {
    "text": "much sure sorry any other questions all",
    "start": "3363249",
    "end": "3382569"
  },
  {
    "text": "right like I said ray and I will be around if you know anyone wants to come up and you know approach one-on-one I'll be happy",
    "start": "3382569",
    "end": "3389739"
  },
  {
    "text": "to answer anything you have [Applause]",
    "start": "3389739",
    "end": "3396530"
  }
]
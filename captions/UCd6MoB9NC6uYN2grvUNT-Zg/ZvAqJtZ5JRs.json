[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "in this session we're going to talk",
    "start": "510",
    "end": "1709"
  },
  {
    "text": "about data warehousing best practices",
    "start": "1709",
    "end": "4500"
  },
  {
    "text": "using Amazon redshift so quickly I want",
    "start": "4500",
    "end": "7500"
  },
  {
    "text": "to go over what Amazon redshift history",
    "start": "7500",
    "end": "10349"
  },
  {
    "text": "was and development get into cluster",
    "start": "10349",
    "end": "12960"
  },
  {
    "text": "architectures talk about some concepts",
    "start": "12960",
    "end": "15150"
  },
  {
    "text": "and terminologies do some storage deep",
    "start": "15150",
    "end": "17580"
  },
  {
    "text": "dive and then I want to talk about what",
    "start": "17580",
    "end": "19890"
  },
  {
    "text": "are the new features that we launched",
    "start": "19890",
    "end": "21900"
  },
  {
    "text": "over the last six months there were some",
    "start": "21900",
    "end": "24090"
  },
  {
    "text": "significant features that we launched",
    "start": "24090",
    "end": "25920"
  },
  {
    "text": "over the last six months and also what",
    "start": "25920",
    "end": "28080"
  },
  {
    "text": "is coming in the pipeline so the history",
    "start": "28080",
    "end": "32910"
  },
  {
    "text": "and development those of you are using",
    "start": "32910",
    "end": "35670"
  },
  {
    "text": "redshift today how many of you are using",
    "start": "35670",
    "end": "37170"
  },
  {
    "text": "redshift today okay not many so what we",
    "start": "37170",
    "end": "40829"
  },
  {
    "text": "did is we took a very familiar database",
    "start": "40829",
    "end": "43379"
  },
  {
    "text": "positive sequel and package that with",
    "start": "43379",
    "end": "46430"
  },
  {
    "text": "will app MPP and columnar added all the",
    "start": "46430",
    "end": "51510"
  },
  {
    "text": "dependent AWS services to it like km as",
    "start": "51510",
    "end": "54809"
  },
  {
    "text": "VP C's route 53 into it and give you a",
    "start": "54809",
    "end": "59010"
  },
  {
    "text": "package of redshift so Amazon redshift",
    "start": "59010",
    "end": "61920"
  },
  {
    "text": "is a collection of all these services",
    "start": "61920",
    "end": "64260"
  },
  {
    "text": "for you it is not post girls in itself",
    "start": "64260",
    "end": "66840"
  },
  {
    "text": "it exposes something like Postgres it's",
    "start": "66840",
    "end": "69570"
  },
  {
    "text": "MPP columnar all up as far since launch",
    "start": "69570",
    "end": "74640"
  },
  {
    "text": "we launched it in Valentine's Day 2013",
    "start": "74640",
    "end": "77420"
  },
  {
    "text": "since launch we have fallen in love with",
    "start": "77420",
    "end": "81000"
  },
  {
    "text": "it been one of our fastest growing",
    "start": "81000",
    "end": "83369"
  },
  {
    "text": "services in the AWS ecosystem we have",
    "start": "83369",
    "end": "86520"
  },
  {
    "text": "introduced under significant patches to",
    "start": "86520",
    "end": "88740"
  },
  {
    "text": "redshift and under and 50 significant",
    "start": "88740",
    "end": "91140"
  },
  {
    "text": "features since that time each of these",
    "start": "91140",
    "end": "94799"
  },
  {
    "text": "patches are automated you don't have to",
    "start": "94799",
    "end": "97619"
  },
  {
    "text": "take downtime for installing the patches",
    "start": "97619",
    "end": "99450"
  },
  {
    "text": "we automatically install the patches",
    "start": "99450",
    "end": "101130"
  },
  {
    "text": "during maintenance windows for you we",
    "start": "101130",
    "end": "103079"
  },
  {
    "text": "upgrade your cluster we keep putting in",
    "start": "103079",
    "end": "105090"
  },
  {
    "text": "smaller patches optimizer fixes as we go",
    "start": "105090",
    "end": "108299"
  },
  {
    "text": "about doing it so let us look at a",
    "start": "108299",
    "end": "111689"
  },
  {
    "text": "cluster architecture let us dive deep",
    "start": "111689",
    "end": "113790"
  },
  {
    "text": "into how the cluster works and what it",
    "start": "113790",
    "end": "116430"
  },
  {
    "start": "116000",
    "end": "116000"
  },
  {
    "text": "looks like the cluster is split into two",
    "start": "116430",
    "end": "119579"
  },
  {
    "text": "pieces one is the leader node and the",
    "start": "119579",
    "end": "121409"
  },
  {
    "text": "others are the compute nodes there are",
    "start": "121409",
    "end": "123570"
  },
  {
    "text": "one or more compute nodes attached to a",
    "start": "123570",
    "end": "126240"
  },
  {
    "text": "leader node the leader node is the",
    "start": "126240",
    "end": "128670"
  },
  {
    "text": "sequel endpoint so your tableau servers",
    "start": "128670",
    "end": "131039"
  },
  {
    "text": "your your your",
    "start": "131039",
    "end": "133860"
  },
  {
    "text": "our tenuity workbench all these guys",
    "start": "133860",
    "end": "136200"
  },
  {
    "text": "connected into the redshift leader node",
    "start": "136200",
    "end": "138270"
  },
  {
    "text": "and then the compute nodes where the all",
    "start": "138270",
    "end": "140610"
  },
  {
    "text": "your data is stored so going in with",
    "start": "140610",
    "end": "143460"
  },
  {
    "text": "more deeper into the components of the",
    "start": "143460",
    "end": "145740"
  },
  {
    "text": "leader and compute nodes your leader",
    "start": "145740",
    "end": "148200"
  },
  {
    "text": "node actually does parsing an execution",
    "start": "148200",
    "end": "151980"
  },
  {
    "text": "of your queries so as soon as the query",
    "start": "151980",
    "end": "153930"
  },
  {
    "text": "is submitted to your leader node the",
    "start": "153930",
    "end": "155880"
  },
  {
    "text": "leader node converts that into a C++",
    "start": "155880",
    "end": "157860"
  },
  {
    "text": "code and pushes it down to the compute",
    "start": "157860",
    "end": "159870"
  },
  {
    "text": "nodes for it to execute the leader node",
    "start": "159870",
    "end": "162510"
  },
  {
    "text": "also exposes pg catalog tables if you",
    "start": "162510",
    "end": "165150"
  },
  {
    "text": "are familiar with Postgres this would be",
    "start": "165150",
    "end": "167640"
  },
  {
    "text": "very familiar to you",
    "start": "167640",
    "end": "169040"
  },
  {
    "text": "poster sequel exposes PG catalog tables",
    "start": "169040",
    "end": "171930"
  },
  {
    "text": "to understand the inner workings of",
    "start": "171930",
    "end": "173640"
  },
  {
    "text": "Postgres and we do the same thing on the",
    "start": "173640",
    "end": "175890"
  },
  {
    "text": "leader node all the compute node there",
    "start": "175890",
    "end": "179640"
  },
  {
    "text": "is curry execution processing engine",
    "start": "179640",
    "end": "181380"
  },
  {
    "text": "happening you have backup and restore",
    "start": "181380",
    "end": "183960"
  },
  {
    "text": "process happening all backups happen",
    "start": "183960",
    "end": "186210"
  },
  {
    "text": "directly out into s3 we continuously",
    "start": "186210",
    "end": "189300"
  },
  {
    "text": "backup data into s3 for you there is a",
    "start": "189300",
    "end": "191970"
  },
  {
    "text": "replication process that happens between",
    "start": "191970",
    "end": "193590"
  },
  {
    "text": "the compute nodes I'll talk about it in",
    "start": "193590",
    "end": "195120"
  },
  {
    "text": "a bit we also have local storage",
    "start": "195120",
    "end": "198300"
  },
  {
    "text": "attached to the compute node which",
    "start": "198300",
    "end": "199950"
  },
  {
    "text": "contains your disks your slices tables",
    "start": "199950",
    "end": "203880"
  },
  {
    "text": "columns and blocks in this talk we're",
    "start": "203880",
    "end": "206820"
  },
  {
    "text": "going to go deep into these aspects so a",
    "start": "206820",
    "end": "212190"
  },
  {
    "text": "few concepts and terminologies before we",
    "start": "212190",
    "end": "214410"
  },
  {
    "text": "get into the storage nodes blocks slices",
    "start": "214410",
    "end": "217459"
  },
  {
    "text": "so redshift has been designed to reduce",
    "start": "217459",
    "end": "222150"
  },
  {
    "start": "218000",
    "end": "218000"
  },
  {
    "text": "are you are you in a database is your",
    "start": "222150",
    "end": "226560"
  },
  {
    "text": "biggest concern for performance if you",
    "start": "226560",
    "end": "228690"
  },
  {
    "text": "can reduce your are you you are more",
    "start": "228690",
    "end": "230550"
  },
  {
    "text": "performant for starters redshift is",
    "start": "230550",
    "end": "232980"
  },
  {
    "text": "columnar storage when you access your",
    "start": "232980",
    "end": "235500"
  },
  {
    "text": "data with row storage all the yellow",
    "start": "235500",
    "end": "237630"
  },
  {
    "text": "boxes are the data that you are storing",
    "start": "237630",
    "end": "239940"
  },
  {
    "text": "you need to access the entire row before",
    "start": "239940",
    "end": "243300"
  },
  {
    "text": "you can go to a particular column wasted",
    "start": "243300",
    "end": "245970"
  },
  {
    "text": "i/o means higher performance latencies",
    "start": "245970",
    "end": "249390"
  },
  {
    "text": "for you",
    "start": "249390",
    "end": "251180"
  },
  {
    "text": "columnar storage allows you to access",
    "start": "251180",
    "end": "254100"
  },
  {
    "text": "your data for that particular column",
    "start": "254100",
    "end": "256200"
  },
  {
    "text": "from that particular block alone you",
    "start": "256200",
    "end": "258540"
  },
  {
    "text": "only scan the blocks that are relevant",
    "start": "258540",
    "end": "260790"
  },
  {
    "text": "for the query you don't scan everything",
    "start": "260790",
    "end": "265590"
  },
  {
    "text": "compression compression reduces your are",
    "start": "265590",
    "end": "269140"
  },
  {
    "text": "you as well now your overhead if you",
    "start": "269140",
    "end": "271420"
  },
  {
    "text": "look at the these encode strings at the",
    "start": "271420",
    "end": "276880"
  },
  {
    "text": "end of the column definitions they are",
    "start": "276880",
    "end": "279100"
  },
  {
    "text": "basically saying what kind of encoding",
    "start": "279100",
    "end": "281140"
  },
  {
    "text": "or what kind of compression is redshift",
    "start": "281140",
    "end": "283780"
  },
  {
    "text": "doing for that column it reduces storage",
    "start": "283780",
    "end": "287320"
  },
  {
    "text": "requirements and reduces the i/o as well",
    "start": "287320",
    "end": "290080"
  },
  {
    "text": "each of the columns grow and shrink",
    "start": "290080",
    "end": "292270"
  },
  {
    "text": "independently they don't have to depend",
    "start": "292270",
    "end": "294310"
  },
  {
    "text": "on the other column so you can say I'll",
    "start": "294310",
    "end": "296350"
  },
  {
    "text": "start with run length encoding on it and",
    "start": "296350",
    "end": "300070"
  },
  {
    "text": "then mu2 is it STD or L is zero and we",
    "start": "300070",
    "end": "303670"
  },
  {
    "text": "will still do that for you because each",
    "start": "303670",
    "end": "305620"
  },
  {
    "text": "of these columns can compress",
    "start": "305620",
    "end": "306970"
  },
  {
    "text": "individually the third important thing",
    "start": "306970",
    "end": "311470"
  },
  {
    "text": "for our reduction is zone maps in zone",
    "start": "311470",
    "end": "315700"
  },
  {
    "text": "maps are in memory blocked metadata they",
    "start": "315700",
    "end": "318100"
  },
  {
    "text": "contain per block minimum and maximum",
    "start": "318100",
    "end": "320770"
  },
  {
    "text": "values so each of these elope",
    "start": "320770",
    "end": "325259"
  },
  {
    "text": "each of these lob oxes are blocks and in",
    "start": "326160",
    "end": "330010"
  },
  {
    "text": "each of those blocks we store the",
    "start": "330010",
    "end": "331810"
  },
  {
    "text": "minimum and maximum value for that",
    "start": "331810",
    "end": "334210"
  },
  {
    "text": "particular block so when a query runs",
    "start": "334210",
    "end": "336730"
  },
  {
    "text": "through the blocks it can skip blocks",
    "start": "336730",
    "end": "338740"
  },
  {
    "text": "which may not have the data that it is",
    "start": "338740",
    "end": "341380"
  },
  {
    "text": "interested in which reduces unnecessary",
    "start": "341380",
    "end": "343390"
  },
  {
    "text": "I here for you it's very important that",
    "start": "343390",
    "end": "346780"
  },
  {
    "text": "you define your table for encoding you",
    "start": "346780",
    "end": "351010"
  },
  {
    "text": "define short keys for your table which",
    "start": "351010",
    "end": "352960"
  },
  {
    "text": "is going to improve performance because",
    "start": "352960",
    "end": "354910"
  },
  {
    "text": "once your data is sorted your zone maps",
    "start": "354910",
    "end": "356860"
  },
  {
    "text": "work far better slice a slices of",
    "start": "356860",
    "end": "364440"
  },
  {
    "start": "360000",
    "end": "360000"
  },
  {
    "text": "virtual compute node think of it as a",
    "start": "364440",
    "end": "366670"
  },
  {
    "text": "virtual compute node each node has to 16",
    "start": "366670",
    "end": "371410"
  },
  {
    "text": "or 32 slices depending on the instance",
    "start": "371410",
    "end": "373750"
  },
  {
    "text": "style that we choose for that node so if",
    "start": "373750",
    "end": "376750"
  },
  {
    "text": "you have a two node cluster of a DC one",
    "start": "376750",
    "end": "378730"
  },
  {
    "text": "large you will have four slices on it",
    "start": "378730",
    "end": "382840"
  },
  {
    "text": "two per node a slice is where your data",
    "start": "382840",
    "end": "386830"
  },
  {
    "text": "is stored the slides only processes its",
    "start": "386830",
    "end": "390520"
  },
  {
    "text": "own data it doesn't borrow data from",
    "start": "390520",
    "end": "393310"
  },
  {
    "text": "another slice to process it",
    "start": "393310",
    "end": "396630"
  },
  {
    "text": "data distribution very important as",
    "start": "396630",
    "end": "399729"
  },
  {
    "start": "397000",
    "end": "397000"
  },
  {
    "text": "important as hot keys we have three ways",
    "start": "399729",
    "end": "403210"
  },
  {
    "text": "of distributing data in redshift",
    "start": "403210",
    "end": "405520"
  },
  {
    "text": "redshift is a massively parallel",
    "start": "405520",
    "end": "407080"
  },
  {
    "text": "processing system so we need to",
    "start": "407080",
    "end": "409300"
  },
  {
    "text": "distribute the data across the cluster",
    "start": "409300",
    "end": "411009"
  },
  {
    "text": "so we can distribute the data using keys",
    "start": "411009",
    "end": "413789"
  },
  {
    "text": "valued define a key that you want to",
    "start": "413789",
    "end": "416410"
  },
  {
    "text": "distribute the data across or you can",
    "start": "416410",
    "end": "418599"
  },
  {
    "text": "distribute the data into all the slices",
    "start": "418599",
    "end": "420520"
  },
  {
    "text": "in the cluster or ask us to evenly",
    "start": "420520",
    "end": "424750"
  },
  {
    "text": "distribute the data across the nodes for",
    "start": "424750",
    "end": "426940"
  },
  {
    "text": "you on the key side of things you need",
    "start": "426940",
    "end": "430389"
  },
  {
    "text": "to be ensured that your data is evenly",
    "start": "430389",
    "end": "432460"
  },
  {
    "text": "distributed your key is even is able to",
    "start": "432460",
    "end": "435190"
  },
  {
    "text": "evenly distribute the data if you have",
    "start": "435190",
    "end": "437110"
  },
  {
    "text": "lopsided distribution you will see that",
    "start": "437110",
    "end": "439509"
  },
  {
    "text": "your cluster doesn't perform optimally",
    "start": "439509",
    "end": "443970"
  },
  {
    "text": "discs each node contains a formal disks",
    "start": "446970",
    "end": "451780"
  },
  {
    "start": "447000",
    "end": "447000"
  },
  {
    "text": "we have 2.5 - 3 X the capacity that we",
    "start": "451780",
    "end": "455590"
  },
  {
    "text": "are to ties on the nodes so when we say",
    "start": "455590",
    "end": "458080"
  },
  {
    "text": "that the node capacity is 2 terabytes we",
    "start": "458080",
    "end": "461020"
  },
  {
    "text": "have close to 6 terabytes that we use",
    "start": "461020",
    "end": "463449"
  },
  {
    "text": "internally so what do we use it for we",
    "start": "463449",
    "end": "465880"
  },
  {
    "text": "use it for storing data from remote",
    "start": "465880",
    "end": "468610"
  },
  {
    "text": "nodes so each of these nodes are",
    "start": "468610",
    "end": "471070"
  },
  {
    "text": "ephemeral storage so we take the data",
    "start": "471070",
    "end": "473380"
  },
  {
    "text": "from that node a part of the data from",
    "start": "473380",
    "end": "475330"
  },
  {
    "text": "that node and store it duplicate it in",
    "start": "475330",
    "end": "477909"
  },
  {
    "text": "another node as well so we have local",
    "start": "477909",
    "end": "480580"
  },
  {
    "text": "data storage accessed by the local",
    "start": "480580",
    "end": "483130"
  },
  {
    "text": "compute nodes and remote data storage",
    "start": "483130",
    "end": "486009"
  },
  {
    "text": "accessed by the remote computer notes we",
    "start": "486009",
    "end": "489610"
  },
  {
    "text": "have internal views that exposes this",
    "start": "489610",
    "end": "491620"
  },
  {
    "text": "for you you can actually look at those",
    "start": "491620",
    "end": "493960"
  },
  {
    "text": "views to understand how much of the data",
    "start": "493960",
    "end": "496659"
  },
  {
    "text": "of the remote node is stored in your",
    "start": "496659",
    "end": "498340"
  },
  {
    "text": "local computer notes blocks are",
    "start": "498340",
    "end": "504099"
  },
  {
    "start": "503000",
    "end": "503000"
  },
  {
    "text": "immutable 1 MB blocks that we use in",
    "start": "504099",
    "end": "506710"
  },
  {
    "text": "redshift all data is stored on the block",
    "start": "506710",
    "end": "509380"
  },
  {
    "text": "the block has metadata information on it",
    "start": "509380",
    "end": "512110"
  },
  {
    "text": "on the zone map information it also",
    "start": "512110",
    "end": "515050"
  },
  {
    "text": "stores information regarding MVCC data",
    "start": "515050",
    "end": "518219"
  },
  {
    "text": "so your immutable blocks are always",
    "start": "518219",
    "end": "523300"
  },
  {
    "text": "formatted when you do an update we don't",
    "start": "523300",
    "end": "525640"
  },
  {
    "text": "go and change a record inside of",
    "start": "525640",
    "end": "528750"
  },
  {
    "text": "so your block has to be formatted a new",
    "start": "528750",
    "end": "531690"
  },
  {
    "text": "block has to be picked up when an update",
    "start": "531690",
    "end": "533070"
  },
  {
    "text": "is done so you need to be careful about",
    "start": "533070",
    "end": "536220"
  },
  {
    "text": "doing many updates on redshift because",
    "start": "536220",
    "end": "538290"
  },
  {
    "text": "you need to do a vacuum or a deep copy",
    "start": "538290",
    "end": "540570"
  },
  {
    "text": "right after an update if it has spans",
    "start": "540570",
    "end": "543060"
  },
  {
    "text": "many rows because you'll have ghost rows",
    "start": "543060",
    "end": "545130"
  },
  {
    "text": "inside the blocks a full block may",
    "start": "545130",
    "end": "548610"
  },
  {
    "text": "contain anywhere between 16 and 8.4",
    "start": "548610",
    "end": "551010"
  },
  {
    "text": "million values so if I'm able to extract",
    "start": "551010",
    "end": "554010"
  },
  {
    "text": "one single block of data into memory I",
    "start": "554010",
    "end": "556500"
  },
  {
    "text": "should be able to read a max of 8.4",
    "start": "556500",
    "end": "560370"
  },
  {
    "text": "million values for that table columns",
    "start": "560370",
    "end": "565160"
  },
  {
    "start": "564000",
    "end": "564000"
  },
  {
    "text": "logical structures accessible through",
    "start": "565160",
    "end": "567959"
  },
  {
    "text": "sequel the properties of a column",
    "start": "567959",
    "end": "571199"
  },
  {
    "text": "include the distribution keys sort keys",
    "start": "571199",
    "end": "573570"
  },
  {
    "text": "and compression algorithm that's being",
    "start": "573570",
    "end": "575220"
  },
  {
    "text": "used columns shrink and grow",
    "start": "575220",
    "end": "577829"
  },
  {
    "text": "independently they don't you don't need",
    "start": "577829",
    "end": "579899"
  },
  {
    "text": "to have you may have a run length",
    "start": "579899",
    "end": "582089"
  },
  {
    "text": "encoding on a column and these columns",
    "start": "582089",
    "end": "584459"
  },
  {
    "text": "may have a different encoding toward",
    "start": "584459",
    "end": "586260"
  },
  {
    "text": "another column or within the data itself",
    "start": "586260",
    "end": "588779"
  },
  {
    "text": "one column may show run length encoding",
    "start": "588779",
    "end": "591180"
  },
  {
    "text": "for hundred rows and then the next",
    "start": "591180",
    "end": "593579"
  },
  {
    "text": "hundred rows may not have run length",
    "start": "593579",
    "end": "595110"
  },
  {
    "text": "encoding on them the system columns",
    "start": "595110",
    "end": "598740"
  },
  {
    "text": "there are three system columns per table",
    "start": "598740",
    "end": "600870"
  },
  {
    "text": "per slice for MVCC so few of the new and",
    "start": "600870",
    "end": "607860"
  },
  {
    "text": "upcoming features on redshift how many",
    "start": "607860",
    "end": "612690"
  },
  {
    "start": "612000",
    "end": "612000"
  },
  {
    "text": "of you heard of a spectrum spectrum",
    "start": "612690",
    "end": "618290"
  },
  {
    "text": "anybody attended the earlier talk with",
    "start": "618290",
    "end": "620550"
  },
  {
    "text": "Adrienne Adrienne was mentioning that is",
    "start": "620550",
    "end": "622890"
  },
  {
    "text": "three is value keep all your data and",
    "start": "622890",
    "end": "625199"
  },
  {
    "text": "that is the philosophy that Amazon is",
    "start": "625199",
    "end": "628470"
  },
  {
    "text": "going with s3 is your data Lake you put",
    "start": "628470",
    "end": "630540"
  },
  {
    "text": "all your data in s3 and then query the",
    "start": "630540",
    "end": "633180"
  },
  {
    "text": "data using your redshift cluster query",
    "start": "633180",
    "end": "635760"
  },
  {
    "text": "the data using Athena query the data",
    "start": "635760",
    "end": "637470"
  },
  {
    "text": "using EMR spectrum allows you to query",
    "start": "637470",
    "end": "640560"
  },
  {
    "text": "your data stored in s3 without having to",
    "start": "640560",
    "end": "643110"
  },
  {
    "text": "load the data into the redshift cluster",
    "start": "643110",
    "end": "645329"
  },
  {
    "text": "it is fully sequel supported and C",
    "start": "645329",
    "end": "648480"
  },
  {
    "text": "sequel compliant it pushes the sequel",
    "start": "648480",
    "end": "651209"
  },
  {
    "text": "predicates into the spectrum layer so",
    "start": "651209",
    "end": "653190"
  },
  {
    "text": "that your cluster is not overburdened",
    "start": "653190",
    "end": "656010"
  },
  {
    "text": "with that work so it doesn't have to go",
    "start": "656010",
    "end": "658470"
  },
  {
    "text": "and pull like a terabyte of data in and",
    "start": "658470",
    "end": "660690"
  },
  {
    "text": "apply predicates to it",
    "start": "660690",
    "end": "662180"
  },
  {
    "text": "can push the predicates into the",
    "start": "662180",
    "end": "663470"
  },
  {
    "text": "spectrum cluster do all the predicate",
    "start": "663470",
    "end": "665750"
  },
  {
    "text": "processing there and only get the amount",
    "start": "665750",
    "end": "669140"
  },
  {
    "text": "of data that is needed for your query",
    "start": "669140",
    "end": "670820"
  },
  {
    "text": "you can join your redshift tables with",
    "start": "670820",
    "end": "675200"
  },
  {
    "text": "your spectrum tables which are external",
    "start": "675200",
    "end": "678290"
  },
  {
    "text": "tables which effectively means I can",
    "start": "678290",
    "end": "681050"
  },
  {
    "text": "start doing roll out from redshift for",
    "start": "681050",
    "end": "685190"
  },
  {
    "text": "data that is not access so frequently",
    "start": "685190",
    "end": "687529"
  },
  {
    "text": "and kept inside f3 I can have multiple",
    "start": "687529",
    "end": "691339"
  },
  {
    "text": "redshift clusters going and hitting the",
    "start": "691339",
    "end": "693080"
  },
  {
    "text": "data on a spectrum on s3",
    "start": "693080",
    "end": "695390"
  },
  {
    "text": "through the spectrum clusters that means",
    "start": "695390",
    "end": "697730"
  },
  {
    "text": "that I increase the concurrency for my",
    "start": "697730",
    "end": "701510"
  },
  {
    "text": "redshift muster because instead of going",
    "start": "701510",
    "end": "704000"
  },
  {
    "text": "with fifteen concurrency I can now say I",
    "start": "704000",
    "end": "706430"
  },
  {
    "text": "can have to redshift clusters looking at",
    "start": "706430",
    "end": "708260"
  },
  {
    "text": "the data and I have 30 people who can",
    "start": "708260",
    "end": "710779"
  },
  {
    "text": "run queries against it so the",
    "start": "710779",
    "end": "714890"
  },
  {
    "text": "architecture remains the same we still",
    "start": "714890",
    "end": "716570"
  },
  {
    "text": "have a leader node and a few compute",
    "start": "716570",
    "end": "719149"
  },
  {
    "text": "nodes out there so whenever you submit a",
    "start": "719149",
    "end": "722149"
  },
  {
    "text": "query which involves data from an",
    "start": "722149",
    "end": "725420"
  },
  {
    "text": "external store like s3 redshift pushes",
    "start": "725420",
    "end": "728900"
  },
  {
    "text": "the data to the spectrum nodes out there",
    "start": "728900",
    "end": "731800"
  },
  {
    "text": "they scale out based on a number of",
    "start": "731800",
    "end": "734720"
  },
  {
    "text": "nodes that you have on your redshift",
    "start": "734720",
    "end": "736850"
  },
  {
    "text": "roster they push the predicates as well",
    "start": "736850",
    "end": "739910"
  },
  {
    "text": "down to the spectrum nodes the spectrum",
    "start": "739910",
    "end": "742339"
  },
  {
    "text": "nodes gathers the data from s3 remember",
    "start": "742339",
    "end": "745250"
  },
  {
    "text": "it doesn't load the data into the",
    "start": "745250",
    "end": "746959"
  },
  {
    "text": "redshift cluster your cluster still",
    "start": "746959",
    "end": "748700"
  },
  {
    "text": "remains as a small agile cluster it",
    "start": "748700",
    "end": "752180"
  },
  {
    "text": "loads the data into this it looks at the",
    "start": "752180",
    "end": "754670"
  },
  {
    "text": "data on s3 doesn't load the data into",
    "start": "754670",
    "end": "756620"
  },
  {
    "text": "redshift the processes the data applies",
    "start": "756620",
    "end": "759440"
  },
  {
    "text": "the predicates and gives the results",
    "start": "759440",
    "end": "761240"
  },
  {
    "text": "back to your computer on your compute",
    "start": "761240",
    "end": "764660"
  },
  {
    "text": "nodes can further do processing on it by",
    "start": "764660",
    "end": "766880"
  },
  {
    "text": "joining the data to existing tables on",
    "start": "766880",
    "end": "769880"
  },
  {
    "text": "the redshift cluster and providing you",
    "start": "769880",
    "end": "772070"
  },
  {
    "text": "the results the data catalog for",
    "start": "772070",
    "end": "776329"
  },
  {
    "text": "spectrum is run from Apache hive",
    "start": "776329",
    "end": "779930"
  },
  {
    "text": "metaphor if you are using Apache high",
    "start": "779930",
    "end": "782450"
  },
  {
    "text": "meta store you can reuse the high Metis",
    "start": "782450",
    "end": "784459"
  },
  {
    "text": "or if you are using glue glue integrates",
    "start": "784459",
    "end": "787279"
  },
  {
    "text": "with a redshift spectrum as well there's",
    "start": "787279",
    "end": "792470"
  },
  {
    "start": "791000",
    "end": "791000"
  },
  {
    "text": "a paradigm shift enabled by Rachel",
    "start": "792470",
    "end": "794779"
  },
  {
    "text": "Spectrum earlier",
    "start": "794779",
    "end": "796579"
  },
  {
    "text": "was used to say I will only be able to",
    "start": "796579",
    "end": "798910"
  },
  {
    "text": "analyze or visualize a small subset of",
    "start": "798910",
    "end": "802610"
  },
  {
    "text": "data because my data warehouse cannot",
    "start": "802610",
    "end": "805040"
  },
  {
    "text": "handle all the data in that with",
    "start": "805040",
    "end": "807920"
  },
  {
    "text": "spectrum you can put all your data in s3",
    "start": "807920",
    "end": "810170"
  },
  {
    "text": "and query the data through your redshift",
    "start": "810170",
    "end": "813230"
  },
  {
    "text": "cluster using proper sequel statements a",
    "start": "813230",
    "end": "817748"
  },
  {
    "start": "818000",
    "end": "818000"
  },
  {
    "text": "few of the recently released features on",
    "start": "818739",
    "end": "824149"
  },
  {
    "text": "redshift",
    "start": "824149",
    "end": "824959"
  },
  {
    "text": "I'm not taking everything here",
    "start": "824959",
    "end": "827439"
  },
  {
    "text": "performance enhancements we have",
    "start": "827439",
    "end": "829939"
  },
  {
    "text": "increased our vacuum speeds 10x faster",
    "start": "829939",
    "end": "832279"
  },
  {
    "text": "now our snapshot and restores our 2x",
    "start": "832279",
    "end": "836569"
  },
  {
    "text": "faster our queries are up to 5x faster",
    "start": "836569",
    "end": "840459"
  },
  {
    "text": "we introduced a new service called query",
    "start": "840459",
    "end": "842989"
  },
  {
    "text": "monitoring rules on redshift recently",
    "start": "842989",
    "end": "845689"
  },
  {
    "text": "carry monitoring rules look at your",
    "start": "845689",
    "end": "848509"
  },
  {
    "text": "queries they monitor your queries",
    "start": "848509",
    "end": "850459"
  },
  {
    "text": "in-flight queries and then say is this",
    "start": "850459",
    "end": "853160"
  },
  {
    "text": "query taking too much memory is it",
    "start": "853160",
    "end": "854660"
  },
  {
    "text": "carrying taking too much CPU is it",
    "start": "854660",
    "end": "856999"
  },
  {
    "text": "returning more rows than needed and it",
    "start": "856999",
    "end": "859970"
  },
  {
    "text": "allows you to kill the query which",
    "start": "859970",
    "end": "862879"
  },
  {
    "text": "basically means your data scientists",
    "start": "862879",
    "end": "865699"
  },
  {
    "text": "cannot do runaway queries on the",
    "start": "865699",
    "end": "867259"
  },
  {
    "text": "redshift cluster so they can go and run",
    "start": "867259",
    "end": "871819"
  },
  {
    "text": "the query pull data out but they have to",
    "start": "871819",
    "end": "874639"
  },
  {
    "text": "be conscious of the fact that other",
    "start": "874639",
    "end": "876139"
  },
  {
    "text": "people are using the redshift duster as",
    "start": "876139",
    "end": "877730"
  },
  {
    "text": "well you define the rules we will",
    "start": "877730",
    "end": "880220"
  },
  {
    "text": "execute the rules behind the scenes for",
    "start": "880220",
    "end": "881839"
  },
  {
    "text": "you we have enhanced VPC routing so we",
    "start": "881839",
    "end": "886189"
  },
  {
    "text": "support the s3 buckets as a VPC endpoint",
    "start": "886189",
    "end": "888949"
  },
  {
    "text": "today so you can put access keys access",
    "start": "888949",
    "end": "892519"
  },
  {
    "text": "policies around those s3 buckets and",
    "start": "892519",
    "end": "896569"
  },
  {
    "text": "restrict who can of offload data from",
    "start": "896569",
    "end": "899959"
  },
  {
    "text": "redshift into the buckets or on load",
    "start": "899959",
    "end": "902209"
  },
  {
    "text": "data from Reggie from the s3 buckets",
    "start": "902209",
    "end": "904489"
  },
  {
    "text": "into redshift",
    "start": "904489",
    "end": "905360"
  },
  {
    "text": "I am authentication via law we pre",
    "start": "905360",
    "end": "912919"
  },
  {
    "start": "908000",
    "end": "908000"
  },
  {
    "text": "announced this last 3 in when we had a",
    "start": "912919",
    "end": "916429"
  },
  {
    "text": "few customers do private beta with us we",
    "start": "916429",
    "end": "919489"
  },
  {
    "text": "had partners come in and help us develop",
    "start": "919489",
    "end": "922579"
  },
  {
    "text": "the JDBC drivers for it so it uses a",
    "start": "922579",
    "end": "925910"
  },
  {
    "text": "custom JDBC ODBC driver that we provide",
    "start": "925910",
    "end": "928519"
  },
  {
    "text": "today for you",
    "start": "928519",
    "end": "929850"
  },
  {
    "text": "custom JDBC ODBC driver can actually",
    "start": "929850",
    "end": "932519"
  },
  {
    "text": "talk to your 80 federated logins and",
    "start": "932519",
    "end": "935509"
  },
  {
    "text": "create appropriate temporary logins",
    "start": "935509",
    "end": "939209"
  },
  {
    "text": "within redshift for you to access the",
    "start": "939209",
    "end": "941550"
  },
  {
    "text": "data if you're a redshift user using",
    "start": "941550",
    "end": "944430"
  },
  {
    "text": "tableau desktop tableau I've released",
    "start": "944430",
    "end": "946440"
  },
  {
    "text": "their own connector for this as well and",
    "start": "946440",
    "end": "949889"
  },
  {
    "text": "it works with tableau it's very easy to",
    "start": "949889",
    "end": "953639"
  },
  {
    "text": "set up we listed on GA two weeks back it",
    "start": "953639",
    "end": "959069"
  },
  {
    "text": "is if you are using any of the ad",
    "start": "959069",
    "end": "961470"
  },
  {
    "text": "Federation like octa ad FS or ping",
    "start": "961470",
    "end": "963810"
  },
  {
    "text": "federate it's very easy for you to set",
    "start": "963810",
    "end": "965819"
  },
  {
    "text": "it up and start using redshift on your",
    "start": "965819",
    "end": "969839"
  },
  {
    "text": "ad authenticated mode if you're",
    "start": "969839",
    "end": "973529"
  },
  {
    "text": "interested in doing this please reach",
    "start": "973529",
    "end": "974819"
  },
  {
    "text": "out to your account team we are more",
    "start": "974819",
    "end": "975959"
  },
  {
    "text": "than happy to come and explain the whole",
    "start": "975959",
    "end": "978750"
  },
  {
    "text": "thing how it works and help you",
    "start": "978750",
    "end": "980339"
  },
  {
    "text": "configure it for you as well lots of",
    "start": "980339",
    "end": "985380"
  },
  {
    "text": "things are coming these are the top",
    "start": "985380",
    "end": "988620"
  },
  {
    "text": "requested feature at this time automatic",
    "start": "988620",
    "end": "992790"
  },
  {
    "text": "and incremental vacuum today lot of",
    "start": "992790",
    "end": "995610"
  },
  {
    "text": "customers spend time doing vacuums the",
    "start": "995610",
    "end": "997949"
  },
  {
    "text": "vacuum is their biggest bottleneck on an",
    "start": "997949",
    "end": "1000949"
  },
  {
    "text": "ETL process because they update because",
    "start": "1000949",
    "end": "1003560"
  },
  {
    "text": "they delete records from the database",
    "start": "1003560",
    "end": "1005899"
  },
  {
    "text": "they want to do vacuum they want to also",
    "start": "1005899",
    "end": "1008240"
  },
  {
    "text": "sort the data that is being inserted",
    "start": "1008240",
    "end": "1010639"
  },
  {
    "text": "into the redshift custom they do vacuums",
    "start": "1010639",
    "end": "1013430"
  },
  {
    "text": "and a vacuums take lot of time when they",
    "start": "1013430",
    "end": "1016220"
  },
  {
    "text": "do continuous ETL where they don't have",
    "start": "1016220",
    "end": "1019939"
  },
  {
    "text": "a predefined window but they",
    "start": "1019939",
    "end": "1021199"
  },
  {
    "text": "continuously keep doing ETL",
    "start": "1021199",
    "end": "1022850"
  },
  {
    "text": "the vacuum process starts eating into",
    "start": "1022850",
    "end": "1025220"
  },
  {
    "text": "their ETL times and which affects your",
    "start": "1025220",
    "end": "1027530"
  },
  {
    "text": "business users we are we are working on",
    "start": "1027530",
    "end": "1030650"
  },
  {
    "text": "an automatic and incremental approach to",
    "start": "1030650",
    "end": "1032480"
  },
  {
    "text": "vacuum where we will vacuum it for you",
    "start": "1032480",
    "end": "1034339"
  },
  {
    "text": "you don't have to do anything leave it",
    "start": "1034339",
    "end": "1036319"
  },
  {
    "text": "with us and we will take care of it this",
    "start": "1036319",
    "end": "1039110"
  },
  {
    "text": "is very similar to the Postgres sequel",
    "start": "1039110",
    "end": "1040610"
  },
  {
    "text": "auto vacuum feature",
    "start": "1040610",
    "end": "1042428"
  },
  {
    "text": "post-classical doesn't have an",
    "start": "1042429",
    "end": "1044089"
  },
  {
    "text": "incremental vacuum incremental vacuum",
    "start": "1044089",
    "end": "1045860"
  },
  {
    "text": "basis this is something that we are",
    "start": "1045860",
    "end": "1047240"
  },
  {
    "text": "developing within redshirt short query",
    "start": "1047240",
    "end": "1050299"
  },
  {
    "text": "bias we can look at queries and say hey",
    "start": "1050299",
    "end": "1053570"
  },
  {
    "text": "this query may run faster than a then a",
    "start": "1053570",
    "end": "1055970"
  },
  {
    "text": "query that is ahead of the queue and we",
    "start": "1055970",
    "end": "1058580"
  },
  {
    "text": "may throw that queue that query into the",
    "start": "1058580",
    "end": "1060679"
  },
  {
    "text": "top of the queue",
    "start": "1060679",
    "end": "1062820"
  },
  {
    "text": "we keep monitoring the queries we know",
    "start": "1062820",
    "end": "1065070"
  },
  {
    "text": "the execution plants of these queries we",
    "start": "1065070",
    "end": "1067050"
  },
  {
    "text": "know how much time each of these queries",
    "start": "1067050",
    "end": "1068550"
  },
  {
    "text": "took and we would be able to take these",
    "start": "1068550",
    "end": "1070800"
  },
  {
    "text": "queries and put them up into the queue",
    "start": "1070800",
    "end": "1075570"
  },
  {
    "text": "so that they execute faster and your",
    "start": "1075570",
    "end": "1078150"
  },
  {
    "text": "users don't have to wait for those",
    "start": "1078150",
    "end": "1079590"
  },
  {
    "text": "queries",
    "start": "1079590",
    "end": "1080900"
  },
  {
    "text": "[Applause]",
    "start": "1080900",
    "end": "1085029"
  }
]
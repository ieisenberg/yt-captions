[
  {
    "start": "0",
    "end": "215000"
  },
  {
    "text": "okay hey so again hello everybody and thank you for joining me for this session",
    "start": "0",
    "end": "5600"
  },
  {
    "text": "about lumberjacking aws how to do log analysis on aws",
    "start": "5600",
    "end": "11280"
  },
  {
    "text": "my name is guy ernest i am part of the solution architecture team with a focus on big data analytics and",
    "start": "11280",
    "end": "18480"
  },
  {
    "text": "machine learning i got yesterday night in the restaurant at the chinese restaurant i got this",
    "start": "18480",
    "end": "25920"
  },
  {
    "text": "fortune cookie so in the future you will be able to",
    "start": "25920",
    "end": "31359"
  },
  {
    "text": "predict the future i wanted to share with you because i think this is also relevant for you not just because you are here",
    "start": "31359",
    "end": "38719"
  },
  {
    "text": "and we're going to talk about how we can actually do that but also because we see many of our customers are starting to do",
    "start": "38719",
    "end": "44879"
  },
  {
    "text": "log analysis how to crunch their log their history logs and how to predict and increase",
    "start": "44879",
    "end": "51680"
  },
  {
    "text": "their business success in the future so in the past it was quite hard to do a",
    "start": "51680",
    "end": "59760"
  },
  {
    "text": "log analysis only few companies were able to afford it",
    "start": "59760",
    "end": "65760"
  },
  {
    "text": "but if we look on those data points and this very significant",
    "start": "65760",
    "end": "71360"
  },
  {
    "text": "hocistic trends you can see that things are changing if we look for example on the storage",
    "start": "71360",
    "end": "77360"
  },
  {
    "text": "cost you can see that the it's increased decreased quite dramatically from",
    "start": "77360",
    "end": "83520"
  },
  {
    "text": "14 million dollars back in 1980 to uh less than 70 dollars uh in 2010 if you check the",
    "start": "83520",
    "end": "92000"
  },
  {
    "text": "cpu cost that is the one jackal flop of a cpu back in the days was more than",
    "start": "92000",
    "end": "98640"
  },
  {
    "text": "one billion dollars and now it's a less than half a dollar and the same with the number of hosts that are connected uh",
    "start": "98640",
    "end": "106399"
  },
  {
    "text": "that we can analyze those uh those host data and the bandwidth cost also is uh",
    "start": "106399",
    "end": "112000"
  },
  {
    "text": "decreasing dramatically but if we go deeper into the details of",
    "start": "112000",
    "end": "118399"
  },
  {
    "text": "those numbers we can see that the progress is not that even that is we see",
    "start": "118399",
    "end": "123520"
  },
  {
    "text": "that the disks are becoming cheaper they're becoming bigger they became",
    "start": "123520",
    "end": "128720"
  },
  {
    "text": "becoming faster but it's not in the same speed that the price can reduce by 450",
    "start": "128720",
    "end": "135280"
  },
  {
    "text": "000 since 1980 and the standard",
    "start": "135280",
    "end": "140879"
  },
  {
    "text": "disk size increased from 100 megabytes to three terabytes today it's an increase of about 30 000",
    "start": "140879",
    "end": "147840"
  },
  {
    "text": "but the speed of the disk is not increasing that much a factor of only 50",
    "start": "147840",
    "end": "153360"
  },
  {
    "text": "as since so this leads us to the need of",
    "start": "153360",
    "end": "159519"
  },
  {
    "text": "using doing things a bit differently using things in a parallel way so if you want to actually",
    "start": "159519",
    "end": "165360"
  },
  {
    "text": "enjoy the the reduction in the cost and the increase in all the other parameters",
    "start": "165360",
    "end": "171920"
  },
  {
    "text": "we need to start thinking of using more spindles using more parallel work so",
    "start": "171920",
    "end": "178480"
  },
  {
    "text": "more spindles is the way to go it's the wrong spindle uh i search for",
    "start": "178480",
    "end": "185200"
  },
  {
    "text": "spindles and i got this uh picture i shouldn't trust a search engine with my workload but i think it",
    "start": "185200",
    "end": "191599"
  },
  {
    "text": "gives the same meaning that we want to get is that basically we want to use our low-cost worker to work in a parallel",
    "start": "191599",
    "end": "199599"
  },
  {
    "text": "way on our data to make it run faster and more more effective way and we can",
    "start": "199599",
    "end": "206319"
  },
  {
    "text": "get more and more worker and get more work done in a parallel way",
    "start": "206319",
    "end": "212760"
  },
  {
    "text": "let's start with one company that's already doing local analysis and basically all the businesses based on log analysis",
    "start": "213120",
    "end": "220080"
  },
  {
    "start": "215000",
    "end": "215000"
  },
  {
    "text": "this is a foursquare i assume that most of you are familiar with this service it's having 40 million people around the",
    "start": "220080",
    "end": "227680"
  },
  {
    "text": "world from the early days of mobile and online check-in",
    "start": "227680",
    "end": "233280"
  },
  {
    "text": "until that today they are crunching more than 4.5 billion check-ins and they are",
    "start": "233280",
    "end": "238480"
  },
  {
    "text": "adding millions of check-ins every day uh to their crunching processes and so",
    "start": "238480",
    "end": "244080"
  },
  {
    "text": "this is the screenshot of my foursquare page uh when",
    "start": "244080",
    "end": "249439"
  },
  {
    "text": "i entered yesterday night i checked for davinci said area of the conference what",
    "start": "249439",
    "end": "255360"
  },
  {
    "text": "we can do in las vegas after we are finishing with all those fascinating technical sessions during the day we",
    "start": "255360",
    "end": "261280"
  },
  {
    "text": "want to have some fun in the evening time and i search for some art related",
    "start": "261280",
    "end": "267199"
  },
  {
    "text": "venues in the area and i got this list very nicely uh very good recommendation what",
    "start": "267199",
    "end": "273120"
  },
  {
    "text": "we can do after time but what if we could check what's going",
    "start": "273120",
    "end": "278560"
  },
  {
    "text": "on been behind the scene what's happening uh inside foursquare where they need to",
    "start": "278560",
    "end": "284960"
  },
  {
    "text": "analyze and create those recommendations and those analysis we can see that the challenge that they are reporting was",
    "start": "284960",
    "end": "291759"
  },
  {
    "text": "how can they stream hundreds and millions of application logs each day and since the company is relying on",
    "start": "291759",
    "end": "298880"
  },
  {
    "text": "analytics the application itself is completely free so they actually need to be able to do this daily reports on",
    "start": "298880",
    "end": "306240"
  },
  {
    "text": "their infrastructure and for their customers and they need to do it in a very efficient way so aws can give them the",
    "start": "306240",
    "end": "314560"
  },
  {
    "text": "infrastructure the tools to actually create this lock analysis process in a an affordable way and we're going to",
    "start": "314560",
    "end": "320880"
  },
  {
    "text": "talk about this today so what we're going to do we're basically going to build a system just like the one that",
    "start": "320880",
    "end": "327360"
  },
  {
    "text": "foursquare is having so if you go around your organization and ask for what do i need what do you",
    "start": "327360",
    "end": "334240"
  },
  {
    "start": "333000",
    "end": "333000"
  },
  {
    "text": "need for me i'm going to build an analytical project what kind of question can i can",
    "start": "334240",
    "end": "341039"
  },
  {
    "text": "i answer you and you go around your business units you will get different answers so in the past logs were only",
    "start": "341039",
    "end": "348800"
  },
  {
    "text": "part of the operation so basically the we checked for problems developers used",
    "start": "348800",
    "end": "354639"
  },
  {
    "text": "the logs to debug their code but now we are beginning to start getting a new",
    "start": "354639",
    "end": "360560"
  },
  {
    "text": "request our marketing team would like to optimize their marketing budget and they have questions",
    "start": "360560",
    "end": "367360"
  },
  {
    "text": "regarding this effectiveness we can see that the ceo team was asking how can we analyze our",
    "start": "367360",
    "end": "374720"
  },
  {
    "text": "cost how can we analyze our revenues how can we actually build a more viable business so as long",
    "start": "374720",
    "end": "381680"
  },
  {
    "text": "as our business is growing and we're getting more and more users to use our service we want to uh increase the ratio",
    "start": "381680",
    "end": "388240"
  },
  {
    "start": "388000",
    "end": "388000"
  },
  {
    "text": "between the cost of each of uh is our the serving of each of our users",
    "start": "388240",
    "end": "394479"
  },
  {
    "text": "and the revenue that we can generate from from those users so running those analysis those metrics can help us",
    "start": "394479",
    "end": "401360"
  },
  {
    "text": "increase and create our viable business so we got a list of metrics now we",
    "start": "401360",
    "end": "408479"
  },
  {
    "start": "407000",
    "end": "407000"
  },
  {
    "text": "can go and check which logs in our system what are the data sources we can use to actually answer those",
    "start": "408479",
    "end": "415280"
  },
  {
    "text": "metrics so we can see that we have a list of sources a cloud",
    "start": "415280",
    "end": "421840"
  },
  {
    "text": "cdn service of amazon can give us many of those answers some of the data is",
    "start": "421840",
    "end": "427599"
  },
  {
    "text": "hidden in the web server application server we can also join the data that we have in our",
    "start": "427599",
    "end": "433599"
  },
  {
    "text": "older databases or our user databases so we have a long list of data sources that",
    "start": "433599",
    "end": "439280"
  },
  {
    "text": "we can basically uh use to build our project so what",
    "start": "439280",
    "end": "445280"
  },
  {
    "text": "how is the right way to start so first we need to understand the data what is the format of the",
    "start": "445280",
    "end": "451840"
  },
  {
    "text": "of the files and let's check this cloudfront format so it's it's a nice",
    "start": "451840",
    "end": "458960"
  },
  {
    "text": "format it's a tsv file we have a nice header the header tells",
    "start": "458960",
    "end": "465039"
  },
  {
    "text": "us that we have the um the date the time the edge location that it's serving which on the files what was",
    "start": "465039",
    "end": "471680"
  },
  {
    "text": "the size of each of the the files that was served uh was it the ip that requested quite a lot",
    "start": "471680",
    "end": "478160"
  },
  {
    "text": "of data very nicely organized but it's not enough we need to know a bit more we want to know",
    "start": "478160",
    "end": "484000"
  },
  {
    "text": "what values do we have in the columns we want to know what is the cardinality how many values we have we want to know what",
    "start": "484000",
    "end": "490319"
  },
  {
    "text": "is distribution of those values it's very important for us before we are starting to join the data and put them",
    "start": "490319",
    "end": "497199"
  },
  {
    "text": "into other analysis tool so i think that the very easy way to start is to start",
    "start": "497199",
    "end": "502879"
  },
  {
    "text": "with the r r is a very powerful and popular tool among data scientists so",
    "start": "502879",
    "end": "509039"
  },
  {
    "text": "here you can see how i can in a few lines of our code load the data",
    "start": "509039",
    "end": "515039"
  },
  {
    "text": "i can remove the header i can see the data in a table view and then i can",
    "start": "515039",
    "end": "520719"
  },
  {
    "start": "520000",
    "end": "520000"
  },
  {
    "text": "create a plot of of one of the value of one of the um the columns and in this case i chose to",
    "start": "520719",
    "end": "528000"
  },
  {
    "text": "check the status of the request and you can see that most of maybe it's tiny",
    "start": "528000",
    "end": "534640"
  },
  {
    "text": "letters but the majority of the status code are 200 of course uh this is the log um",
    "start": "534640",
    "end": "541440"
  },
  {
    "text": "scale of the white is why it doesn't it doesn't look that big and also we have 304 404 so more or less we understand",
    "start": "541440",
    "end": "548800"
  },
  {
    "text": "what kind of value we can expect in this field and what is distribution of these values",
    "start": "548800",
    "end": "555440"
  },
  {
    "text": "but you should know that r is quite memory hungry and instead of",
    "start": "555440",
    "end": "561920"
  },
  {
    "start": "557000",
    "end": "557000"
  },
  {
    "text": "you trying to go to your i.t people and ask them i need to increase my memory in my",
    "start": "561920",
    "end": "567760"
  },
  {
    "text": "machine i think that you can also use one of the my favorite tricks is to actually run in the cloud so as you can",
    "start": "567760",
    "end": "574399"
  },
  {
    "text": "see this is this machine this r studio machine i can launch whenever i need to do this",
    "start": "574399",
    "end": "580080"
  },
  {
    "text": "kind of analysis this machine has a 64 gigabyte of data unlimited uh for my",
    "start": "580080",
    "end": "586800"
  },
  {
    "text": "use case and whenever i finish my",
    "start": "586800",
    "end": "591839"
  },
  {
    "text": "my my analysis my understanding of the data i can delete the cluster and continue",
    "start": "592320",
    "end": "597600"
  },
  {
    "text": "with my life if writing our code is a bit complex for",
    "start": "597600",
    "end": "602880"
  },
  {
    "text": "you and you feel that you want to have something easier to do you can also use the open refine",
    "start": "602880",
    "end": "610080"
  },
  {
    "text": "you can again run it on an ec2 instance and with a point and click you can create a",
    "start": "610080",
    "end": "616640"
  },
  {
    "text": "table view of your data this is the same data that you saw before",
    "start": "616640",
    "end": "621680"
  },
  {
    "text": "with r and on the left side you can see the facets that you can you can create",
    "start": "621680",
    "end": "627279"
  },
  {
    "text": "on those values and the same status code you can see that the majority are 200 and so on so it's easier maybe to do if",
    "start": "627279",
    "end": "634480"
  },
  {
    "text": "you are not familiar with writing our code okay so now basically we understand our",
    "start": "634480",
    "end": "640720"
  },
  {
    "text": "data of course we did the same analysis to other columns and we understand it much better and we can start planning on",
    "start": "640720",
    "end": "646720"
  },
  {
    "text": "actually creating our project usually this kind of project are in this",
    "start": "646720",
    "end": "653279"
  },
  {
    "text": "kind of a format it's called the etl the extract we're extracting our logs from",
    "start": "653279",
    "end": "658399"
  },
  {
    "text": "the various sources the t for transformation we are transforming the logs we are cleaning them we are",
    "start": "658399",
    "end": "665120"
  },
  {
    "text": "filtering them we are enriching them and then we can load them into our data warehouse so this is our etl process and",
    "start": "665120",
    "end": "673839"
  },
  {
    "text": "when we want to start doing that we want to use aws for that and this is what we uh",
    "start": "673839",
    "end": "679839"
  },
  {
    "text": "came up when we did the white boarding on the service so the plan is as follows",
    "start": "679839",
    "end": "686079"
  },
  {
    "text": "we're going to extract the data from our edge location we're going to run transformation using",
    "start": "686079",
    "end": "692560"
  },
  {
    "text": "emr which is a very good tool to run a transformation in scale",
    "start": "692560",
    "end": "698079"
  },
  {
    "text": "and we're going to load it into redshift as the data warehouse and we can also get",
    "start": "698079",
    "end": "703760"
  },
  {
    "text": "some data from rds remember the user tables or our order tables and we can",
    "start": "703760",
    "end": "710320"
  },
  {
    "text": "upload them into s3 and then to read shift so this is the plan let's start building our system",
    "start": "710320",
    "end": "716800"
  },
  {
    "text": "so here's our system here here are our users uh they are accessing our web servers they are accessing our",
    "start": "716800",
    "end": "724560"
  },
  {
    "text": "cdn network um and we want to get the logs from the many uh",
    "start": "724560",
    "end": "732800"
  },
  {
    "text": "edge location of cloudfront crowdfund is served from more than 40 edge location",
    "start": "732800",
    "end": "737839"
  },
  {
    "text": "but we can get the data from all of them with just defining uh enabling logging",
    "start": "737839",
    "end": "743680"
  },
  {
    "text": "in the management console as you can see here so you are enabling the the logging you",
    "start": "743680",
    "end": "749600"
  },
  {
    "text": "are defining to which bucket you want your logs to be sent and",
    "start": "749600",
    "end": "756079"
  },
  {
    "text": "basically you have already all the logs uh ready for your processing but if you want to have um logs from",
    "start": "756079",
    "end": "763920"
  },
  {
    "text": "your web servers if you want to have logs from your application servers basically you need to start doing what",
    "start": "763920",
    "end": "768959"
  },
  {
    "text": "is called log shipping so as you can see log shipping is is a hard work uh it",
    "start": "768959",
    "end": "775680"
  },
  {
    "text": "requires real men with very uh specific tools uh but let's try to make it a bit",
    "start": "775680",
    "end": "781440"
  },
  {
    "text": "easier what is the easiest way to actually create log shipping for your servers",
    "start": "781440",
    "end": "787360"
  },
  {
    "text": "so this is a personal note that it's very uh",
    "start": "787360",
    "end": "794800"
  },
  {
    "start": "788000",
    "end": "788000"
  },
  {
    "text": "enjoyable to be a solution architect the the one of the most enjoyable thing is basically meeting amazing customers and",
    "start": "794800",
    "end": "801440"
  },
  {
    "text": "this is a story of a customer that i met that when we talked about his analytic",
    "start": "801440",
    "end": "806959"
  },
  {
    "text": "system he told me that he has one he already is doing lock shipping and he",
    "start": "806959",
    "end": "812880"
  },
  {
    "text": "showed me this s3 bucket when i look at it i ask where is the",
    "start": "812880",
    "end": "818399"
  },
  {
    "text": "where is the shipment it's simply you have a small tiny object and a log",
    "start": "818399",
    "end": "824639"
  },
  {
    "text": "folder how do you do it then he pointed me to the documentation and",
    "start": "824639",
    "end": "830000"
  },
  {
    "text": "if you look at the commentation of the the server access log you can see that the request uri is part of the logo",
    "start": "830000",
    "end": "837920"
  },
  {
    "text": "so what you can do is just put in the uri all the data that you want and",
    "start": "837920",
    "end": "844480"
  },
  {
    "text": "s3 will ship all the logs for you without you needing to do anything else",
    "start": "844480",
    "end": "849760"
  },
  {
    "text": "and this is a way that you can embed your invisible pixel this is what you could poor men invisible pixel",
    "start": "849760",
    "end": "856880"
  },
  {
    "start": "850000",
    "end": "850000"
  },
  {
    "text": "so you're calling for your tiny object and you are putting all the other values the version user id campaign id and",
    "start": "856880",
    "end": "865440"
  },
  {
    "text": "you can implement that with this kind of a simple mechanism no cost other than",
    "start": "865440",
    "end": "870560"
  },
  {
    "text": "the cost of the storage of your s3 logs",
    "start": "870560",
    "end": "875920"
  },
  {
    "text": "so here is a system we have our code delivery logs",
    "start": "876639",
    "end": "882000"
  },
  {
    "text": "sent we have the invisible pixel logs sent but we might need to do something more than that not everything can be",
    "start": "882000",
    "end": "889199"
  },
  {
    "text": "embedded into the visible pixel uh what we need to do now is basically to do log shipping with other framework and for",
    "start": "889199",
    "end": "896160"
  },
  {
    "text": "that you can use a set of uh open source framework uh i like",
    "start": "896160",
    "end": "902160"
  },
  {
    "text": "specifically uh fluentd especially for the this retro ascii diagram that they have",
    "start": "902160",
    "end": "907839"
  },
  {
    "text": "that basically tells it all that all you need to do is basically define your input in this case it could be a web",
    "start": "907839",
    "end": "913839"
  },
  {
    "text": "server define the medium in this case it's a fluentd but it can be the others and you define the output in this case",
    "start": "913839",
    "end": "921279"
  },
  {
    "text": "s3 and you can gather your data from your web servers from",
    "start": "921279",
    "end": "926880"
  },
  {
    "text": "proxy servers from database servers and it's working very very nicely",
    "start": "926880",
    "end": "932639"
  },
  {
    "text": "again fluent is one option floom scribe chakra all of them are very powerful",
    "start": "932639",
    "end": "939839"
  },
  {
    "text": "very popular uh fluently has more than 100 different plugins so basically you can",
    "start": "939839",
    "end": "946720"
  },
  {
    "text": "actually get your data uh from everywhere and you can implement this architecture of log everything which",
    "start": "946720",
    "end": "953360"
  },
  {
    "text": "basically this is what we want for our project another option",
    "start": "953360",
    "end": "959519"
  },
  {
    "text": "that was announced yesterday you can use amazon kinesis",
    "start": "959519",
    "end": "965199"
  },
  {
    "start": "960000",
    "end": "960000"
  },
  {
    "text": "so this streaming service is helping you to",
    "start": "965199",
    "end": "970639"
  },
  {
    "text": "put all your logs from the many web servers application server wherever you have your code running into the stream",
    "start": "970639",
    "end": "978399"
  },
  {
    "text": "and then write this kinesis enable application that will take the logs from the stream",
    "start": "978399",
    "end": "985839"
  },
  {
    "text": "and put it into s3 if you download the the java the libraries that we put as",
    "start": "985839",
    "end": "993120"
  },
  {
    "text": "part of the service you can see a set of connectors already ready for you and one of the",
    "start": "993120",
    "end": "998320"
  },
  {
    "text": "connectors is 4s3 so actually writing this kind of kinesis application shouldn't be that much problem for you",
    "start": "998320",
    "end": "1006959"
  },
  {
    "text": "okay very good we did quite nice uh progress so what we managed to do is now",
    "start": "1008639",
    "end": "1014399"
  },
  {
    "text": "we have all our logs from all our sources into a one s3 bucket and we can start doing our",
    "start": "1014399",
    "end": "1021199"
  },
  {
    "text": "transformation so done with the extraction phase",
    "start": "1021199",
    "end": "1026160"
  },
  {
    "text": "the first step in the transformation is basically use the s3 distributed copy",
    "start": "1027039",
    "end": "1033918"
  },
  {
    "text": "why do we need to do that so if you remember we are talking about parallel processing and power processing prefers",
    "start": "1033919",
    "end": "1040240"
  },
  {
    "start": "1036000",
    "end": "1036000"
  },
  {
    "text": "to have large files to process um and it likes to have the",
    "start": "1040240",
    "end": "1045678"
  },
  {
    "text": "the files in an even size that if you have one big file and few small files what",
    "start": "1045679",
    "end": "1052960"
  },
  {
    "text": "you'll have is that one of your workers will work very very hard for very long time",
    "start": "1052960",
    "end": "1058320"
  },
  {
    "text": "while the others will be idle and wait for their work to to come so this kind of",
    "start": "1058320",
    "end": "1064840"
  },
  {
    "text": "underutilized cluster is something that we want to avoid another important thing that you would",
    "start": "1064840",
    "end": "1070000"
  },
  {
    "text": "like to have is to have the files compressed that is if you remember the files that are coming from cloudfront or",
    "start": "1070000",
    "end": "1076720"
  },
  {
    "text": "from s3 are already compressed but the files that you are generating from other sources might not be compressed and it's",
    "start": "1076720",
    "end": "1083440"
  },
  {
    "text": "going to be a lot of waste for you you will wait a long time for the files to for the logs to",
    "start": "1083440",
    "end": "1091280"
  },
  {
    "text": "to move because they are bigger you will pay more for the bandwidth you'll pay more for the storage and it's",
    "start": "1091280",
    "end": "1097280"
  },
  {
    "text": "better to avoid it and s3 distribute copy basically gives you all of that it will aggregate the data for you for",
    "start": "1097280",
    "end": "1104320"
  },
  {
    "text": "larger files it will also make sure that the files are more or less the same size not going to be",
    "start": "1104320",
    "end": "1109919"
  },
  {
    "text": "accurate but more or less the same size and they will be compressed and this is done by a single command so",
    "start": "1109919",
    "end": "1116720"
  },
  {
    "text": "this is an example of how you do distributed copy with emr so you are",
    "start": "1116720",
    "end": "1122480"
  },
  {
    "text": "specifying what is the source bucket that you want to do you specifying this destination what is the format of your",
    "start": "1122480",
    "end": "1129440"
  },
  {
    "text": "aggregation basically this is a date format uh what is the target size in",
    "start": "1129440",
    "end": "1134880"
  },
  {
    "text": "this case 128 megabyte and of course compress it with",
    "start": "1134880",
    "end": "1140880"
  },
  {
    "text": "lco and also uh at the end whenever i finish",
    "start": "1140880",
    "end": "1145919"
  },
  {
    "text": "copying a file to the new to the new destination i can delete it again",
    "start": "1145919",
    "end": "1151120"
  },
  {
    "text": "saving on our storage cost so with this a single command we can basically get uh",
    "start": "1151120",
    "end": "1157919"
  },
  {
    "text": "the files ready for our next step so uh the files are sent into the emr",
    "start": "1157919",
    "end": "1166400"
  },
  {
    "text": "the elastic map reduce which as the first phase did our distributed copy but",
    "start": "1166400",
    "end": "1171600"
  },
  {
    "text": "now we can actually run a set of steps uh that will uh help us we will make",
    "start": "1171600",
    "end": "1176720"
  },
  {
    "text": "this transformation the steps can be in java implementing the mapreduce interface",
    "start": "1176720",
    "end": "1183520"
  },
  {
    "text": "but it can also be in one of the high-level languages that are available",
    "start": "1183520",
    "end": "1188559"
  },
  {
    "text": "for emr for example a hive streaming cascading and many of",
    "start": "1188559",
    "end": "1194880"
  },
  {
    "text": "them that you're going to choose from let's see an example of of a pig script",
    "start": "1194880",
    "end": "1201520"
  },
  {
    "text": "this is a pig script that actually analyzed the invisible pixel example that we saw in the beginning",
    "start": "1201520",
    "end": "1209039"
  },
  {
    "start": "1203000",
    "end": "1203000"
  },
  {
    "text": "i like to call pig shelling scale why because whatever you can do with shell",
    "start": "1209039",
    "end": "1214400"
  },
  {
    "text": "on a small file now you can do in unlimited scale using pig let's see an example so the",
    "start": "1214400",
    "end": "1222640"
  },
  {
    "text": "first stage of the of the script we are basically loading the data",
    "start": "1222640",
    "end": "1228080"
  },
  {
    "text": "and filtering you which is exactly like what you would get if you run a cat or a grep a command",
    "start": "1228080",
    "end": "1235120"
  },
  {
    "text": "the sector and the second phase is to do this parsing that is what values do we have inside",
    "start": "1235120",
    "end": "1241919"
  },
  {
    "text": "you can see that we are getting the the user id the campaign id and this is a very similar to what you",
    "start": "1241919",
    "end": "1248080"
  },
  {
    "text": "would write if you are writing or okay command and at the end when we finish our",
    "start": "1248080",
    "end": "1253520"
  },
  {
    "text": "processing we just store the data back uh very similar to what you can do with shell so it's quite simple to write a",
    "start": "1253520",
    "end": "1261919"
  },
  {
    "text": "big script one note about a comparison between pig and hive because many people are asking",
    "start": "1261919",
    "end": "1268799"
  },
  {
    "text": "which language is better so of course it depends",
    "start": "1268799",
    "end": "1274240"
  },
  {
    "text": "so pig is more geared into etl stuff uh i see more developers or more people who",
    "start": "1274240",
    "end": "1280400"
  },
  {
    "start": "1276000",
    "end": "1276000"
  },
  {
    "text": "are used to you know system illustrators who are used uh to run a shell",
    "start": "1280400",
    "end": "1285520"
  },
  {
    "text": "using a pig while the analysts people are more used to writing",
    "start": "1285520",
    "end": "1291679"
  },
  {
    "text": "sql are using hives more frequently hive has this h",
    "start": "1291679",
    "end": "1297600"
  },
  {
    "text": "ql which is quite similar to sql so it's very easy for them to pick up but you don't need to decide because when you",
    "start": "1297600",
    "end": "1304480"
  },
  {
    "text": "are running your emr you can run various steps and in various languages",
    "start": "1304480",
    "end": "1311120"
  },
  {
    "text": "pig makes it very easy to to write a mapreduce code but",
    "start": "1312799",
    "end": "1318640"
  },
  {
    "start": "1314000",
    "end": "1314000"
  },
  {
    "text": "when it's too easy sometimes you're missing some of the optimization you can get and this is why i recommend also using",
    "start": "1318640",
    "end": "1326799"
  },
  {
    "text": "this specific tool i think it's it won one of the prizes yesterday netflix prize in",
    "start": "1326799",
    "end": "1332559"
  },
  {
    "text": "inverner uh a keynote uh so lipstick actually giving you an insight about what's going on",
    "start": "1332559",
    "end": "1339600"
  },
  {
    "text": "underneath the hood of your peak script so you're running open scripts and you can see what are the map and reduce the",
    "start": "1339600",
    "end": "1345840"
  },
  {
    "text": "steps that are happening and which one of them is taking longer so you can actually optimize your pig",
    "start": "1345840",
    "end": "1352640"
  },
  {
    "text": "to to run in a better way there is another tool ambrose that was",
    "start": "1352640",
    "end": "1357919"
  },
  {
    "start": "1356000",
    "end": "1356000"
  },
  {
    "text": "open sourced by twitter also giving you this kind of flow how",
    "start": "1357919",
    "end": "1363679"
  },
  {
    "text": "your job is going through the system what takes longer what is stuck",
    "start": "1363679",
    "end": "1370000"
  },
  {
    "text": "and this kind of insight into what's happening underneath will give you a",
    "start": "1370000",
    "end": "1375760"
  },
  {
    "text": "better understanding about how you can optimize and make your emr jobs run faster uh",
    "start": "1375760",
    "end": "1382400"
  },
  {
    "text": "actually how we like saying that that the pig will fly which it can",
    "start": "1382400",
    "end": "1390400"
  },
  {
    "text": "another thing that i think that it's important for you to know is that you should optimize your vmware cluster and",
    "start": "1391600",
    "end": "1396640"
  },
  {
    "text": "this is an exercise that one of my teammates did a few weeks back what he did is he",
    "start": "1396640",
    "end": "1403039"
  },
  {
    "text": "took a spreadsheet you put all the instances that can run in emr you put the price of the",
    "start": "1403039",
    "end": "1410799"
  },
  {
    "text": "hourly price for each of the machines and then you define the budget the budget was ten dollars",
    "start": "1410799",
    "end": "1416480"
  },
  {
    "text": "ten dollars an hour how many machine can i have in ten dollars an hour uh for",
    "start": "1416480",
    "end": "1421760"
  },
  {
    "text": "example if i choose m2 extra large i can have 21",
    "start": "1421760",
    "end": "1428080"
  },
  {
    "text": "machines so it's different layout bigger machine and fewer of them or smaller machine and more of them",
    "start": "1428080",
    "end": "1434559"
  },
  {
    "start": "1429000",
    "end": "1429000"
  },
  {
    "text": "then he calculated the accumulated cpu memory and storage they can get",
    "start": "1434559",
    "end": "1441440"
  },
  {
    "text": "from each one of those layers then he added another",
    "start": "1441440",
    "end": "1447520"
  },
  {
    "text": "dimension which is the network he estimated how much network he can get to the disk how much network he can get in",
    "start": "1447520",
    "end": "1454080"
  },
  {
    "text": "the cluster between the nodes and how much network he can get um to s3 again this is our estimation you",
    "start": "1454080",
    "end": "1460880"
  },
  {
    "text": "and you can calculate it and then you of course make the colors which one is better and",
    "start": "1460880",
    "end": "1467919"
  },
  {
    "text": "it gives you very easy way to understand that your layout will define what kind of workload you",
    "start": "1467919",
    "end": "1475200"
  },
  {
    "text": "can run with that so if you need more cpu maybe it's better to have the c1 extra large if you need more",
    "start": "1475200",
    "end": "1482960"
  },
  {
    "text": "memory it's better to run with the m2 extra large if you need more network uh",
    "start": "1482960",
    "end": "1488080"
  },
  {
    "text": "we have the the m1 large so in our case when we",
    "start": "1488080",
    "end": "1493919"
  },
  {
    "text": "analyze what we when we estimate or evaluate what you think will be the the bottleneck we estimate because we are",
    "start": "1493919",
    "end": "1500000"
  },
  {
    "text": "doing distributed copy which is basically copying the file from s3 and we are running pig which is quite simple",
    "start": "1500000",
    "end": "1506559"
  },
  {
    "text": "it doesn't like too much cpu and too much memory we will be network bound so this is kind of an uh theoretical",
    "start": "1506559",
    "end": "1513440"
  },
  {
    "text": "exercise that we can do to try to estimate what is the best way to lay out our cluster to maximize our",
    "start": "1513440",
    "end": "1520080"
  },
  {
    "text": "performance but you don't have to rely on theory you can also try it in a practical way so",
    "start": "1520080",
    "end": "1527520"
  },
  {
    "start": "1524000",
    "end": "1524000"
  },
  {
    "text": "you can monitor your cluster this is monitoring using ganglia",
    "start": "1527520",
    "end": "1534799"
  },
  {
    "text": "you can see that you can check the cpu of your instance you can check the memory of your cluster",
    "start": "1534799",
    "end": "1541200"
  },
  {
    "text": "you can check the network of your cluster and again it's showing us that the bottleneck of this",
    "start": "1541200",
    "end": "1547360"
  },
  {
    "text": "specific process that we are running is network and we can optimize it to define the right layout of our system it's",
    "start": "1547360",
    "end": "1553760"
  },
  {
    "text": "quite easy to install ganglia this is a single bootstrap action that you put as",
    "start": "1553760",
    "end": "1559840"
  },
  {
    "text": "part of your emr launch or you can also use it from the",
    "start": "1559840",
    "end": "1565200"
  },
  {
    "start": "1564000",
    "end": "1564000"
  },
  {
    "text": "management console when you are starting a console you can define that you want the ganglia to be",
    "start": "1565200",
    "end": "1571120"
  },
  {
    "text": "added to the cluster and then you can log to the server and check your uh your",
    "start": "1571120",
    "end": "1577440"
  },
  {
    "text": "metrics if this management console looks a bit different within but what you are used",
    "start": "1577440",
    "end": "1582880"
  },
  {
    "text": "to it because it's recently updated last week it was uh um",
    "start": "1582880",
    "end": "1588960"
  },
  {
    "text": "updated to this view so now you can have these options already uh it also",
    "start": "1588960",
    "end": "1594480"
  },
  {
    "text": "gathering the relevant cloud watch metrics from around the system into",
    "start": "1594480",
    "end": "1600880"
  },
  {
    "text": "the emr console so you can actually see it from here also the bottlenecks or the usage of your cluster the same network",
    "start": "1600880",
    "end": "1607600"
  },
  {
    "text": "memory and other resources that you're using and yeah you can also see the steps the failures",
    "start": "1607600",
    "end": "1614320"
  },
  {
    "text": "there are most of the resources we now need for emr are available through the management calls",
    "start": "1614320",
    "end": "1620240"
  },
  {
    "text": "or in an easy way another tool uh which i like uh is",
    "start": "1620240",
    "end": "1627279"
  },
  {
    "text": "something that was recently uh open sourced by high media uh this is another",
    "start": "1627279",
    "end": "1632720"
  },
  {
    "text": "clever implementation of how can i make",
    "start": "1632720",
    "end": "1638000"
  },
  {
    "text": "get more data more understanding about what's going on in my cluster so what they actually did they are querying",
    "start": "1638000",
    "end": "1644240"
  },
  {
    "text": "all the apis the ec2 api the s3 api of course the emr api they are checking the",
    "start": "1644240",
    "end": "1650320"
  },
  {
    "text": "job tracker from the hadoop they are also asking for the emr pricing",
    "start": "1650320",
    "end": "1655360"
  },
  {
    "text": "from the site they are gathering all this information and creating this textual console and this even visually",
    "start": "1655360",
    "end": "1661120"
  },
  {
    "text": "visualization that can help you understand what's going on uh this is an example of how a complete job can look",
    "start": "1661120",
    "end": "1668400"
  },
  {
    "text": "like so you have a lot of data to die dive into and get a better understanding",
    "start": "1668400",
    "end": "1674480"
  },
  {
    "text": "about what you can do better in your system",
    "start": "1674480",
    "end": "1679360"
  },
  {
    "text": "so what we managed to do is uh we gathered the logs into s3 we all ready to make most of the transformation uh",
    "start": "1680080",
    "end": "1687440"
  },
  {
    "text": "with emr we try to optimize as much as we could our cost but one of the most",
    "start": "1687440",
    "end": "1693679"
  },
  {
    "text": "powerful way of lowering the cost of our processing is using spot instances",
    "start": "1693679",
    "end": "1699200"
  },
  {
    "text": "so i guess that most of you already know about spot instances hopefully most of you are",
    "start": "1699200",
    "end": "1704399"
  },
  {
    "text": "already using that so i am not going to teach you what is spot instances but what i can do is basically i can share",
    "start": "1704399",
    "end": "1710880"
  },
  {
    "text": "with you some strategies that i see our customer actually doing when they are",
    "start": "1710880",
    "end": "1716799"
  },
  {
    "start": "1714000",
    "end": "1714000"
  },
  {
    "text": "running spot instances so this is the market price",
    "start": "1716799",
    "end": "1722720"
  },
  {
    "text": "the on demand price sorry the only one price for this c1 extra large uh about",
    "start": "1722720",
    "end": "1728720"
  },
  {
    "text": "64 cent so one strategy is most saving i will",
    "start": "1728720",
    "end": "1735120"
  },
  {
    "text": "pay 20 30 not more than that so uh if it's more",
    "start": "1735120",
    "end": "1740399"
  },
  {
    "text": "than that i don't want to to run my job i will wait until the price will go down and the price can go down and it's",
    "start": "1740399",
    "end": "1745600"
  },
  {
    "text": "usually around the 10 percent of the on demand it's a huge savings so if i want to do more saving i",
    "start": "1745600",
    "end": "1751520"
  },
  {
    "text": "will be very low some of them are saying i want to not pay money on demand",
    "start": "1751520",
    "end": "1758080"
  },
  {
    "text": "so they are bidding 80 90 percent of the on demand price and then they're getting",
    "start": "1758080",
    "end": "1763120"
  },
  {
    "text": "more time over off and they still paying less they will pay",
    "start": "1763120",
    "end": "1768480"
  },
  {
    "text": "with running the on-demand prices but we also find some customers that are",
    "start": "1768480",
    "end": "1774559"
  },
  {
    "text": "using more than their own demand they can ask for 150 or even 200",
    "start": "1774559",
    "end": "1780480"
  },
  {
    "text": "of the on demand price why did they do that and of course i explained them you're going to pay more",
    "start": "1780480",
    "end": "1785840"
  },
  {
    "text": "uh with spot then you're going to pay with on demand doesn't make sense so they said yes it makes a lot of sense",
    "start": "1785840",
    "end": "1791200"
  },
  {
    "text": "for me because then i get less interruptions i can run my jobs",
    "start": "1791200",
    "end": "1796399"
  },
  {
    "text": "faster i will get more time and even if for one hour two hours doing the",
    "start": "1796399",
    "end": "1802399"
  },
  {
    "text": "my two days of job i will pay a bit more than the on demand overall i will save a",
    "start": "1802399",
    "end": "1809200"
  },
  {
    "text": "lot because overall it will be 60 70 of the on demand on the the whole time",
    "start": "1809200",
    "end": "1814799"
  },
  {
    "text": "of running the job and my job will run faster i will get less interruption so it's really uh up to you to decide what",
    "start": "1814799",
    "end": "1821919"
  },
  {
    "text": "is the risk that you want to put on losing your instances and define and use that to define what is your bidding",
    "start": "1821919",
    "end": "1829279"
  },
  {
    "text": "strategy but i don't encourage you to put more than their own demand but basically",
    "start": "1829279",
    "end": "1834559"
  },
  {
    "text": "there are customers who are doing that and they are still saving a lot of money",
    "start": "1834559",
    "end": "1840158"
  },
  {
    "text": "so i i want to take you back to the early days of amazon.com",
    "start": "1841760",
    "end": "1847440"
  },
  {
    "text": "so this diagram was drawn by jeff bezos himself i don't know if it was a napkin",
    "start": "1847440",
    "end": "1853360"
  },
  {
    "text": "but it's a good story so we he draw that to explain how amazon.com can continue growing",
    "start": "1853360",
    "end": "1861679"
  },
  {
    "text": "so it all starts with the customer experience what customers are looking for is have",
    "start": "1861679",
    "end": "1866880"
  },
  {
    "text": "selection i want to find what they want to uh to buy and they want lower costs",
    "start": "1866880",
    "end": "1872240"
  },
  {
    "text": "once we have that we are generating traffic people are coming people are buying these attracts sellers when the",
    "start": "1872240",
    "end": "1879120"
  },
  {
    "text": "sellers are coming with more selection uh and when we are selling more we can",
    "start": "1879120",
    "end": "1884640"
  },
  {
    "text": "also invest in re lowering the cost of our structure and reducing the cost once",
    "start": "1884640",
    "end": "1889840"
  },
  {
    "text": "again and this creates the flywheel this is how we can start growing and growing",
    "start": "1889840",
    "end": "1895679"
  },
  {
    "text": "and growing because this is a very powerful flywheel of customers coming coming in sellers coming in",
    "start": "1895679",
    "end": "1903039"
  },
  {
    "text": "more selection lower cost and the business is growing this is how amazon.com is growing until today",
    "start": "1903039",
    "end": "1909519"
  },
  {
    "text": "let's try to use the same mechanism to grow our business analysis",
    "start": "1909519",
    "end": "1915840"
  },
  {
    "text": "project which we we started so what we're going to actually get is more data sources these are the sellers",
    "start": "1915840",
    "end": "1922480"
  },
  {
    "text": "we want to have more queries answered uh once we have the ability to serve more",
    "start": "1922480",
    "end": "1927760"
  },
  {
    "text": "queries again we'll have more customers this time their customers are internal users or maybe can",
    "start": "1927760",
    "end": "1934799"
  },
  {
    "text": "also get external people to buy our reports but still customers and",
    "start": "1934799",
    "end": "1941600"
  },
  {
    "text": "we can start growing again this flywheel of our our agile",
    "start": "1941600",
    "end": "1947600"
  },
  {
    "text": "data warehouse project what we now need is basically this kind of a lower cost structure and enter",
    "start": "1947600",
    "end": "1954240"
  },
  {
    "text": "amazon redshift but before we gonna jump into redchiff then the question can be why use redshift why not use the regular",
    "start": "1954240",
    "end": "1962000"
  },
  {
    "text": "databases there are other databases out there and redshift is uh might not be the best",
    "start": "1962000",
    "end": "1968000"
  },
  {
    "text": "solution uh so for that i uh i think that we should consider the the",
    "start": "1968000",
    "end": "1973440"
  },
  {
    "text": "following trends so basically when we are moving from the transactional uh processing to analytical one what we see",
    "start": "1973440",
    "end": "1980159"
  },
  {
    "text": "that the context has changed from transactional to global the focus from latency of this transaction we are",
    "start": "1980159",
    "end": "1986480"
  },
  {
    "text": "talking about throughput how many um records we can with processes it could be processed in in a second and we are",
    "start": "1986480",
    "end": "1993519"
  },
  {
    "text": "not using indexes anymore because we are doing a full table scan uh we are not doing random i o we are doing sequential",
    "start": "1993519",
    "end": "2000640"
  },
  {
    "text": "one and we want to optimize our disk not to for sick time but for a transfer so",
    "start": "2000640",
    "end": "2006640"
  },
  {
    "text": "basically what we actually need is a different hardware different uh type of database and this is why redshift is",
    "start": "2006640",
    "end": "2014240"
  },
  {
    "text": "running on this kind of optimized hardware for analytics so let's go back to our system we did",
    "start": "2014240",
    "end": "2021039"
  },
  {
    "text": "all the analysis all the transformation and now it's time to load it into a",
    "start": "2021039",
    "end": "2026799"
  },
  {
    "text": "redshift l in the etl how do you do that",
    "start": "2026799",
    "end": "2032880"
  },
  {
    "text": "basically it's a single command so the first command is to create a table this is the create table",
    "start": "2032880",
    "end": "2040000"
  },
  {
    "text": "that is loading the data from the original files from a cloud formation a from a",
    "start": "2040000",
    "end": "2046799"
  },
  {
    "text": "cloudfront sorry and with a single copy command i'm taking the bucket that i put the output",
    "start": "2046799",
    "end": "2053760"
  },
  {
    "text": "of my cloud for cloudfront i giving the credential of my s3 bucket",
    "start": "2053760",
    "end": "2059599"
  },
  {
    "text": "so redshift can read the data from there i'm ignoring the header you remember i had two lines of header uh in the log",
    "start": "2059599",
    "end": "2067520"
  },
  {
    "text": "and of course the data is gzip so it's important to put it in the command and putting the",
    "start": "2067520",
    "end": "2074240"
  },
  {
    "text": "date format so after this command all the log files and i'm talking about this",
    "start": "2074240",
    "end": "2079358"
  },
  {
    "text": "kind of parallel uh loading so if i have thousands of file in s3 there will be a",
    "start": "2079359",
    "end": "2086320"
  },
  {
    "text": "load into redshift in a parallel way in a very fast way so it's compressed and",
    "start": "2086320",
    "end": "2092000"
  },
  {
    "text": "run in parallel one note about optimizing redshift of course there's a",
    "start": "2092000",
    "end": "2098240"
  },
  {
    "text": "full session about how to make your redshift run faster but note that you can see in this slide is that it's",
    "start": "2098240",
    "end": "2104240"
  },
  {
    "text": "important to decide what is the format of your columns so don't load everything",
    "start": "2104240",
    "end": "2109520"
  },
  {
    "text": "a string which might be a temptation because it's the simplest way if you load data's date numbers and numbers and",
    "start": "2109520",
    "end": "2116240"
  },
  {
    "text": "so on you will get much better compression which will make your redshift queries",
    "start": "2116240",
    "end": "2121760"
  },
  {
    "text": "run much much faster if you want to schedule and create this",
    "start": "2121760",
    "end": "2129040"
  },
  {
    "start": "2128000",
    "end": "2128000"
  },
  {
    "text": "kind of automatic way of loading every hour every day your files",
    "start": "2129040",
    "end": "2136320"
  },
  {
    "text": "aws data pipeline is there and this is an example of how you can define loading",
    "start": "2136320",
    "end": "2142800"
  },
  {
    "text": "your data you can see that the top one is taking the data from s3 bucket in an",
    "start": "2142800",
    "end": "2148400"
  },
  {
    "text": "hourly upload into redshift and then the the second one the bottom one is taking",
    "start": "2148400",
    "end": "2153760"
  },
  {
    "text": "your data from your databases on a daily basis i want to do it on a daily basis",
    "start": "2153760",
    "end": "2158880"
  },
  {
    "text": "because i don't want to add load to my production service so once a day it's enough for me to to get",
    "start": "2158880",
    "end": "2165280"
  },
  {
    "text": "um the transaction there so using this kind of pipeline will give",
    "start": "2165280",
    "end": "2170800"
  },
  {
    "text": "me the data fresh all the time into my database into",
    "start": "2170800",
    "end": "2176560"
  },
  {
    "text": "my data warehouse in a very scheduled automatic way",
    "start": "2176560",
    "end": "2182240"
  },
  {
    "text": "so we've got our data in the database in the data warehouse now it's time to make some",
    "start": "2182880",
    "end": "2190079"
  },
  {
    "text": "knowledge to tell a story so time for data visualization so i'm not sure that you can create this kind of",
    "start": "2190079",
    "end": "2196079"
  },
  {
    "text": "visualization in redshift this is a very famous visualization from 150 years ago",
    "start": "2196079",
    "end": "2202079"
  },
  {
    "text": "what you can see here is this brown line this is the army of napoleon leaving france on its way to moscow on the top",
    "start": "2202079",
    "end": "2210160"
  },
  {
    "text": "right side and you can clearly see the path that they took and the decrease of their size as they are",
    "start": "2210160",
    "end": "2216560"
  },
  {
    "text": "fighting their way and to moscow and then you can see their retreat black line going from moscow",
    "start": "2216560",
    "end": "2223599"
  },
  {
    "text": "back the few that managed to start even their journey back to france and they even fear that got it all the way back",
    "start": "2223599",
    "end": "2230400"
  },
  {
    "text": "to france it's a it's a very powerful story a terrible one but it's a very powerful story that if you'll try to",
    "start": "2230400",
    "end": "2236079"
  },
  {
    "text": "make it in table and numbers it will be very very complex but one single image",
    "start": "2236079",
    "end": "2242160"
  },
  {
    "text": "can give you and tell you this story so what we want to do is actually tell the story of our data tell the story for our",
    "start": "2242160",
    "end": "2248160"
  },
  {
    "text": "customers so what kind of story can we tell with the data that we loaded so this is some kind of a",
    "start": "2248160",
    "end": "2255520"
  },
  {
    "text": "dashboard that i created on the the cloud front logs so you can see the",
    "start": "2255520",
    "end": "2261520"
  },
  {
    "text": "increase of number of users coming to the system it's a success of our marketing launch",
    "start": "2261520",
    "end": "2267359"
  },
  {
    "text": "you can see the distribution of the ages and the gender of our users because this is a gaming site so it's not a surprise",
    "start": "2267359",
    "end": "2274640"
  },
  {
    "text": "that most of our users are the age of 15 to 25 to further them are",
    "start": "2274640",
    "end": "2281119"
  },
  {
    "text": "are male it's a it's not a surprise that this is a distribution and also we can",
    "start": "2281119",
    "end": "2286960"
  },
  {
    "text": "see the top 25 games and which countries are",
    "start": "2286960",
    "end": "2293200"
  },
  {
    "text": "downloading and buying which game it's very very important for our business to start seeing the data as it is so how do",
    "start": "2293200",
    "end": "2300960"
  },
  {
    "text": "you do that basically you can choose your own favorite bi tool so there are many of",
    "start": "2300960",
    "end": "2306640"
  },
  {
    "text": "them in this case i use the tableau on a window instance my shop is a linux",
    "start": "2306640",
    "end": "2312720"
  },
  {
    "text": "show but if i need to run some bi tools that are only windows",
    "start": "2312720",
    "end": "2318000"
  },
  {
    "text": "based like a tableau and sysense and click view which are very",
    "start": "2318000",
    "end": "2324320"
  },
  {
    "text": "powerful and popular i can start them on a windows instance run my dashboard and",
    "start": "2324320",
    "end": "2331359"
  },
  {
    "text": "use that to publish to my internal and external customers there are also solutions that are more",
    "start": "2331359",
    "end": "2338800"
  },
  {
    "text": "open like jaspersoft and microstrategy that are also running on linux machine",
    "start": "2338800",
    "end": "2344880"
  },
  {
    "text": "but there are many of them and i can't even put all of them on one slide you can check them in the",
    "start": "2344880",
    "end": "2351599"
  },
  {
    "text": "aws marketplace another option if you remember this our machine are in the cloud that i had in",
    "start": "2351599",
    "end": "2357760"
  },
  {
    "text": "the beginning to analyze my code i can also use that to create some more interesting",
    "start": "2357760",
    "end": "2364079"
  },
  {
    "text": "or powerful visualization and this is a visualization that i created which",
    "start": "2364079",
    "end": "2370560"
  },
  {
    "text": "basically trying to show which games are downloaded with other games uh so this",
    "start": "2370560",
    "end": "2376800"
  },
  {
    "text": "is a kind of a heat map i've got the game on one side the same game on the other when you see which games are",
    "start": "2376800",
    "end": "2382560"
  },
  {
    "text": "working nicely together so one of the most popular game is a",
    "start": "2382560",
    "end": "2388400"
  },
  {
    "text": "network which is downloaded quite often and the most common game",
    "start": "2388400",
    "end": "2394000"
  },
  {
    "text": "that usually goes with it is this guy this game which um",
    "start": "2394000",
    "end": "2400000"
  },
  {
    "text": "tile world so having this kind of understanding and this kind of information can just be the",
    "start": "2400000",
    "end": "2406960"
  },
  {
    "text": "the first step into my recommendation engine i can use that to create my site",
    "start": "2406960",
    "end": "2413280"
  },
  {
    "text": "differently to allow this people who bought that also bought this and so on so this kind of a very",
    "start": "2413280",
    "end": "2420000"
  },
  {
    "text": "powerful way of getting the data to work for me to generate more revenues and getting more people to download more of",
    "start": "2420000",
    "end": "2426880"
  },
  {
    "text": "my games so we did a lot of work in this",
    "start": "2426880",
    "end": "2435119"
  },
  {
    "text": "less than an hour we managed to gather the logs process them transform them load them into redshift and even create",
    "start": "2435119",
    "end": "2440720"
  },
  {
    "text": "our visualization an important thing i wanted to uh to remind you that redshift is very low",
    "start": "2440720",
    "end": "2447200"
  },
  {
    "text": "cost but it's even lower cost when it's not running what do i mean by that it is",
    "start": "2447200",
    "end": "2452560"
  },
  {
    "text": "basically what you can do is you can snapshot your redshift and you can delete it when you",
    "start": "2452560",
    "end": "2458880"
  },
  {
    "text": "would like to do such a thing let's say that you're running your reports every month and it takes you two days to run",
    "start": "2458880",
    "end": "2464400"
  },
  {
    "text": "your reports but why do you need the cluster to up be up and running the other 28 days it doesn't make sense",
    "start": "2464400",
    "end": "2471440"
  },
  {
    "text": "so what you can do is basically delete the cluster of course snapshot your",
    "start": "2471440",
    "end": "2476960"
  },
  {
    "text": "cluster before you are deleted it so next month you can start your cluster with the from this same specific",
    "start": "2476960",
    "end": "2483920"
  },
  {
    "text": "snapshot and then you can load all the data that you gather during the last month and repeat",
    "start": "2483920",
    "end": "2490400"
  },
  {
    "text": "your log generation and kill it again and you can continue like that again and again and you don't have to kill your",
    "start": "2490400",
    "end": "2498079"
  },
  {
    "text": "cluster you can also uh just unload data that you don't use if most of your queries are running on the",
    "start": "2498079",
    "end": "2504240"
  },
  {
    "text": "last last week for example why do you need to have this history uh already all",
    "start": "2504240",
    "end": "2509520"
  },
  {
    "text": "the time in redshift when you only need it once a quarter once a year when you're",
    "start": "2509520",
    "end": "2514640"
  },
  {
    "text": "generating your yearly report so this is a simple way of unloading your data",
    "start": "2514640",
    "end": "2520640"
  },
  {
    "text": "and then you can reload it once you want to run uh this monthly quarterly or",
    "start": "2520640",
    "end": "2526079"
  },
  {
    "text": "yearly report and then you can also resize your cluster to hold more of the data so be very",
    "start": "2526079",
    "end": "2532480"
  },
  {
    "text": "conscious about the size of a cluster the amount of data you have there so your project",
    "start": "2532480",
    "end": "2539119"
  },
  {
    "text": "will be a cost effective for you so what we build here is the reference",
    "start": "2539119",
    "end": "2545520"
  },
  {
    "text": "architecture i believe that it makes sense how it's built why we build it but you might use it differently maybe you",
    "start": "2545520",
    "end": "2552079"
  },
  {
    "start": "2549000",
    "end": "2549000"
  },
  {
    "text": "don't need emr maybe you have another um etl tools that you want to use maybe",
    "start": "2552079",
    "end": "2557760"
  },
  {
    "text": "even you want to as a different data warehouse everything is possible but i think that it makes sense why it",
    "start": "2557760",
    "end": "2563520"
  },
  {
    "text": "looks like that if what we build here is a bit too complex and you want maybe to do it even",
    "start": "2563520",
    "end": "2569280"
  },
  {
    "text": "easier you can use many of our third-party tools like locally that you can find in",
    "start": "2569280",
    "end": "2576319"
  },
  {
    "text": "the aws marketplace uh that will help you generate and understand and and uh",
    "start": "2576319",
    "end": "2582240"
  },
  {
    "text": "go cut through your logs uh splunk is another powerful one a",
    "start": "2582240",
    "end": "2587359"
  },
  {
    "text": "logstash is also a powerful tool so using those can give you maybe even the taste should you move forward and should",
    "start": "2587359",
    "end": "2594240"
  },
  {
    "text": "you build your own log analysis tool",
    "start": "2594240",
    "end": "2599920"
  },
  {
    "text": "so now we are very good about log analysis we know how to build system we know how to uh to optimize it we are",
    "start": "2600000",
    "end": "2606480"
  },
  {
    "text": "doing a very very good job what else can we do with log log analysis so once we",
    "start": "2606480",
    "end": "2611599"
  },
  {
    "text": "are mastering this technique this framework what we can do is for example do a b testing",
    "start": "2611599",
    "end": "2618560"
  },
  {
    "text": "so a b testing gives you the ability to stop guessing currently when you want to",
    "start": "2618560",
    "end": "2623839"
  },
  {
    "text": "have a new version you have a new pricing model a new layout of them",
    "start": "2623839",
    "end": "2629760"
  },
  {
    "text": "of your home page this kind of decision can be run in parallel so you can run one",
    "start": "2629760",
    "end": "2636079"
  },
  {
    "text": "version when your application cost three dollars and one that when it cost less",
    "start": "2636079",
    "end": "2641839"
  },
  {
    "text": "and you can see how many clicks you can generate in each one of those models so running a b testing is quite",
    "start": "2641839",
    "end": "2648560"
  },
  {
    "text": "simple once we know how to do this log analysis because all we need to do is just run two versions",
    "start": "2648560",
    "end": "2655119"
  },
  {
    "text": "get the logs which we already did and analyze it again which we already did so",
    "start": "2655119",
    "end": "2660319"
  },
  {
    "text": "this kind of of powerful tools that now are for a disposal is something that",
    "start": "2660319",
    "end": "2666160"
  },
  {
    "text": "you should consider and it's going to be a good incentive for you to even start doing this journey into log analysis",
    "start": "2666160",
    "end": "2673760"
  },
  {
    "text": "but as you know but with the great powers come great responsibility",
    "start": "2674560",
    "end": "2680480"
  },
  {
    "start": "2679000",
    "end": "2679000"
  },
  {
    "text": "and it's very very easy to make mistakes when you have a lot of data when you're trying to build your system when you're",
    "start": "2680480",
    "end": "2687200"
  },
  {
    "text": "trying to define this crucial business decision uh",
    "start": "2687200",
    "end": "2692480"
  },
  {
    "text": "you might get it wrong and the story here is about abraham wilde he was a",
    "start": "2692480",
    "end": "2698079"
  },
  {
    "text": "mathematician a statistician from the second world war he worked with the air force and what he did basically was log",
    "start": "2698079",
    "end": "2704960"
  },
  {
    "text": "analysis what is log analysis for him he measured uh where",
    "start": "2704960",
    "end": "2710880"
  },
  {
    "text": "uh where where readily defined bullet holes uh in the planes that returned from",
    "start": "2710880",
    "end": "2718000"
  },
  {
    "text": "emissions to occupied europe um so we draw this kind of very",
    "start": "2718000",
    "end": "2723119"
  },
  {
    "text": "interesting uh um visualization on the planes that the place we're going to hit",
    "start": "2723119",
    "end": "2728160"
  },
  {
    "text": "and now we need to decide where to put extra armor of course you can't put extra armor",
    "start": "2728160",
    "end": "2734079"
  },
  {
    "text": "everywhere because then you might get heavy planes slower planes you need to find what is the best place to do it so",
    "start": "2734079",
    "end": "2742640"
  },
  {
    "text": "where would you put your uh your armor what's going to be a where you have the hits in the wings going to be b or maybe",
    "start": "2742640",
    "end": "2749839"
  },
  {
    "text": "it's going to be c so it's not an easy decision if you think of for a minute",
    "start": "2749839",
    "end": "2756720"
  },
  {
    "text": "you might come to the wrong conclusion because where he decided to put the extra armor is here",
    "start": "2756720",
    "end": "2763040"
  },
  {
    "text": "why did he do that because basically what he measured was the plane that did return from",
    "start": "2763040",
    "end": "2769760"
  },
  {
    "text": "mission to europe and not the plane that did not so",
    "start": "2769760",
    "end": "2774880"
  },
  {
    "text": "the period the planes that got hit in the other places simply couldn't make it",
    "start": "2774880",
    "end": "2780000"
  },
  {
    "text": "home so why it's relevant for you because remember that what you are measuring is basically",
    "start": "2780000",
    "end": "2786079"
  },
  {
    "text": "the people that did come to your site they did buys the data did buy your games and if you are",
    "start": "2786079",
    "end": "2794560"
  },
  {
    "text": "taking the wrong conclusion from this kind of of data you might miss the point",
    "start": "2794560",
    "end": "2800000"
  },
  {
    "text": "and it's very important for you to to remember that that remember what you are measuring remember",
    "start": "2800000",
    "end": "2805839"
  },
  {
    "text": "what kind of conclusion you can draw from that so this is a very very interesting",
    "start": "2805839",
    "end": "2813760"
  },
  {
    "text": "project we managed to build we managed to get our logs we managed to transform them and manage to load them into our",
    "start": "2813760",
    "end": "2820319"
  },
  {
    "text": "analysis and it was i believe quite simple i hope that when you look at that and you are trying to",
    "start": "2820319",
    "end": "2826240"
  },
  {
    "text": "go back home and try to implement what we talked here i think it will give you uh in a couple of days hopefully this",
    "start": "2826240",
    "end": "2833520"
  },
  {
    "text": "agile and iterative way uh the tools to create the flywheel that we",
    "start": "2833520",
    "end": "2839440"
  },
  {
    "text": "discussed the the business that you can start pushing inside the organization and make",
    "start": "2839440",
    "end": "2846000"
  },
  {
    "text": "yourself your company more data-driven and create new revenue opportunities",
    "start": "2846000",
    "end": "2852079"
  },
  {
    "text": "for you as a business and i also hope that i imagine i",
    "start": "2852079",
    "end": "2857280"
  },
  {
    "text": "managed to get you interested about more about architecture so here are some",
    "start": "2857280",
    "end": "2863359"
  },
  {
    "text": "interesting urls that you can find more architectural information technical articles and the blog that",
    "start": "2863359",
    "end": "2871040"
  },
  {
    "text": "giving a lot of hands-on experience with our services and also we have a few uh reinvent",
    "start": "2871040",
    "end": "2877920"
  },
  {
    "text": "session that you should check most of them maybe are over and you can check them on youtube later on but",
    "start": "2877920",
    "end": "2884079"
  },
  {
    "text": "they're also relevant for what we talked here so again thank you very much for your attention and i'll be happy to take more",
    "start": "2884079",
    "end": "2890480"
  },
  {
    "text": "of your questions down on the stage",
    "start": "2890480",
    "end": "2895359"
  }
]
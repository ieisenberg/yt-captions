[
  {
    "text": "- Hello everyone, I'm Jyothi Bodas,",
    "start": "570",
    "end": "3000"
  },
  {
    "text": "a Software Development Manager at AWS.",
    "start": "3000",
    "end": "4983"
  },
  {
    "text": "Today, I'm so thrilled to demonstrate",
    "start": "6240",
    "end": "8340"
  },
  {
    "text": "as how we have optimized\nour Data Ingestion process",
    "start": "8340",
    "end": "11500"
  },
  {
    "text": "within AWS Supply Chain\nusing Generative AI.",
    "start": "11500",
    "end": "15063"
  },
  {
    "text": "We all know the challenges that come",
    "start": "16050",
    "end": "17789"
  },
  {
    "text": "with integrating data from various sources",
    "start": "17790",
    "end": "20820"
  },
  {
    "text": "into a cohesive and\ncentralized data model.",
    "start": "20820",
    "end": "24119"
  },
  {
    "text": "It's often a complex puzzle,",
    "start": "24120",
    "end": "26310"
  },
  {
    "text": "with data scattered across\ndifferent platforms.",
    "start": "26310",
    "end": "29520"
  },
  {
    "text": "That's where our AWS Supply\nChain Data Ingestion pipeline",
    "start": "29520",
    "end": "33720"
  },
  {
    "text": "comes into picture, serving\nas a crucial component",
    "start": "33720",
    "end": "37172"
  },
  {
    "text": "in seamlessly unifying\nsuch fragmented data.",
    "start": "37172",
    "end": "41160"
  },
  {
    "text": "Please join me as we explore",
    "start": "41160",
    "end": "43050"
  },
  {
    "text": "the transformative power of Generative AI",
    "start": "43050",
    "end": "46200"
  },
  {
    "text": "in streamlining this essential\naspect of data management.",
    "start": "46200",
    "end": "50190"
  },
  {
    "text": "Let's dive in.",
    "start": "50190",
    "end": "51243"
  },
  {
    "text": "Today, AWS Supply Chain\nteam is excited to introduce",
    "start": "54150",
    "end": "57300"
  },
  {
    "text": "our new Generative AI powered\ndata onboarding agent,",
    "start": "57300",
    "end": "60930"
  },
  {
    "text": "which is now available\nfor all our customers.",
    "start": "60930",
    "end": "63810"
  },
  {
    "text": "With this release, we are\nintroducing a new concept",
    "start": "63810",
    "end": "66300"
  },
  {
    "text": "called flow that makes it\nincredibly easy for you",
    "start": "66300",
    "end": "69180"
  },
  {
    "text": "to upload customer native\ndata from any source system.",
    "start": "69180",
    "end": "73260"
  },
  {
    "text": "Our system then automatically\ntransforms your data",
    "start": "73260",
    "end": "76320"
  },
  {
    "text": "and associates to the AWS\nSupply Chain data model,",
    "start": "76320",
    "end": "79680"
  },
  {
    "text": "using Amazon Bedrock\nGenerative AI solution.",
    "start": "79680",
    "end": "83460"
  },
  {
    "text": "Let me walk you through the process,",
    "start": "83460",
    "end": "85830"
  },
  {
    "text": "which is essentially streamlined\ninto four simple steps",
    "start": "85830",
    "end": "89190"
  },
  {
    "text": "as displayed on the left side\nof the pattern in the screen.",
    "start": "89190",
    "end": "92730"
  },
  {
    "text": "Now, step one is to\nchoose your source system",
    "start": "92730",
    "end": "95790"
  },
  {
    "text": "where you extract the data.",
    "start": "95790",
    "end": "97950"
  },
  {
    "text": "Continue, step two then allows you",
    "start": "97950",
    "end": "101100"
  },
  {
    "text": "to select your AWS Supply\nChain modules of interest.",
    "start": "101100",
    "end": "104490"
  },
  {
    "text": "For this demo purposes, let's\nchoose Demand Planning module.",
    "start": "104490",
    "end": "107613"
  },
  {
    "text": "Below you'll see embedded documentation",
    "start": "109080",
    "end": "111210"
  },
  {
    "text": "detailing the data\nrequirements for the module.",
    "start": "111210",
    "end": "114210"
  },
  {
    "text": "For example, Demand\nPlanning requires product,",
    "start": "114210",
    "end": "116580"
  },
  {
    "text": "product alternate, outbound order line,",
    "start": "116580",
    "end": "119070"
  },
  {
    "text": "and Supplementary Time\nseries as an optional entity.",
    "start": "119070",
    "end": "122610"
  },
  {
    "text": "You can also give a custom name",
    "start": "122610",
    "end": "125310"
  },
  {
    "text": "identifying your source system,",
    "start": "125310",
    "end": "126960"
  },
  {
    "text": "I'm going to name it as Demand Plan,",
    "start": "126960",
    "end": "129060"
  },
  {
    "text": "and you can now simply drag\nand drop the related files.",
    "start": "129060",
    "end": "133680"
  },
  {
    "text": "So here I'm dropping outbound order line,",
    "start": "133680",
    "end": "137489"
  },
  {
    "text": "product alternate, and product records.",
    "start": "137490",
    "end": "141210"
  },
  {
    "text": "We have made it so easy for you",
    "start": "141210",
    "end": "142950"
  },
  {
    "text": "to upload the data directly\nwithin the web app,",
    "start": "142950",
    "end": "145709"
  },
  {
    "text": "mirroring Amazon S3 experience",
    "start": "145710",
    "end": "147840"
  },
  {
    "text": "without needing to navigate to S3 console.",
    "start": "147840",
    "end": "151443"
  },
  {
    "text": "There is also no need to\npre-transform your data",
    "start": "152850",
    "end": "155340"
  },
  {
    "text": "to match your data\nrequirements before you upload.",
    "start": "155340",
    "end": "157980"
  },
  {
    "text": "Here, I have successfully\nuploaded the data.",
    "start": "157980",
    "end": "161250"
  },
  {
    "text": "Now I'm going to click on Continue,",
    "start": "161250",
    "end": "163170"
  },
  {
    "text": "that takes us to the step three,",
    "start": "163170",
    "end": "165060"
  },
  {
    "text": "which is to confirm your source tables.",
    "start": "165060",
    "end": "167580"
  },
  {
    "text": "Here, you'll verify the\nschema for the uploaded files",
    "start": "167580",
    "end": "171030"
  },
  {
    "text": "and delete any unnecessary\nwritten and source tables.",
    "start": "171030",
    "end": "174480"
  },
  {
    "text": "Here I can see outbound order\nline, product alternate,",
    "start": "174480",
    "end": "178260"
  },
  {
    "text": "and product related schemas.",
    "start": "178260",
    "end": "181851"
  },
  {
    "text": "Now, I'm going to Accept all and continue,",
    "start": "181851",
    "end": "185250"
  },
  {
    "text": "which is where we create the source flows",
    "start": "185250",
    "end": "187560"
  },
  {
    "text": "that can now start accepting\nthe data in your source format,",
    "start": "187560",
    "end": "190980"
  },
  {
    "text": "including what you just uploaded.",
    "start": "190980",
    "end": "193083"
  },
  {
    "text": "Now that brings us to the step four.",
    "start": "194100",
    "end": "196500"
  },
  {
    "text": "This step involves\nassociating your source data",
    "start": "196500",
    "end": "199290"
  },
  {
    "text": "with the AWS Supply Chain\ndestination data model",
    "start": "199290",
    "end": "202469"
  },
  {
    "text": "using our destination flows.",
    "start": "202470",
    "end": "205020"
  },
  {
    "text": "Now here we scan the source tables",
    "start": "205020",
    "end": "207390"
  },
  {
    "text": "and column headers of your source data,",
    "start": "207390",
    "end": "210450"
  },
  {
    "text": "and automatically associate\nto our destination tables",
    "start": "210450",
    "end": "213989"
  },
  {
    "text": "and fields using Amazon Bedrock.",
    "start": "213990",
    "end": "216780"
  },
  {
    "text": "Now you'll see the successful association",
    "start": "216780",
    "end": "219480"
  },
  {
    "text": "of tables and fields, here we go.",
    "start": "219480",
    "end": "222420"
  },
  {
    "text": "Here is the table mapping",
    "start": "222420",
    "end": "225030"
  },
  {
    "text": "and here is the source to\ndestination column mapping",
    "start": "225030",
    "end": "228810"
  },
  {
    "text": "and we also generate the SQL query for it.",
    "start": "228810",
    "end": "231483"
  },
  {
    "text": "For any reason, if you\nwant to edit the mappings",
    "start": "232830",
    "end": "235590"
  },
  {
    "text": "and override them, you can\nalways simply drag and drop.",
    "start": "235590",
    "end": "239129"
  },
  {
    "text": "Here, I'm going to\noverride ID to Linkage ID",
    "start": "239130",
    "end": "242940"
  },
  {
    "text": "which then immediately changes your SQL.",
    "start": "242940",
    "end": "245313"
  },
  {
    "text": "And you can also in inverse change the SQL",
    "start": "246300",
    "end": "250360"
  },
  {
    "text": "to map to a different column,\nsay, Record Identifier as ID,",
    "start": "251790",
    "end": "256320"
  },
  {
    "text": "save your edits, now ID\nbecomes Record Identifier.",
    "start": "256320",
    "end": "261320"
  },
  {
    "text": "As you can see, the SQL and\nmapping are highly responsive.",
    "start": "262650",
    "end": "267600"
  },
  {
    "text": "You can also override the table mappings",
    "start": "267600",
    "end": "269910"
  },
  {
    "text": "by choosing a different\ntable, which will re-trigger",
    "start": "269910",
    "end": "272910"
  },
  {
    "text": "the auto association of the fields for it.",
    "start": "272910",
    "end": "275133"
  },
  {
    "text": "Now, once you are satisfied\nwith the mappings,",
    "start": "276330",
    "end": "279689"
  },
  {
    "text": "you can go ahead and submit,",
    "start": "279690",
    "end": "282030"
  },
  {
    "text": "like for the product destination flow,",
    "start": "282030",
    "end": "284550"
  },
  {
    "text": "I'm going to submit the product.",
    "start": "284550",
    "end": "286263"
  },
  {
    "text": "Next, I'm going to submit\nthe product alternate,",
    "start": "288690",
    "end": "291273"
  },
  {
    "text": "and I'm going to submit",
    "start": "293340",
    "end": "294690"
  },
  {
    "text": "the outbound order line destination flows.",
    "start": "294690",
    "end": "298113"
  },
  {
    "text": "Now here at this step, I'm\ngoing to complete my step four,",
    "start": "300090",
    "end": "305090"
  },
  {
    "text": "which takes me to a centralized dashboards",
    "start": "305100",
    "end": "308910"
  },
  {
    "text": "where you can view the status",
    "start": "308910",
    "end": "311550"
  },
  {
    "text": "of your source and destination flows.",
    "start": "311550",
    "end": "314400"
  },
  {
    "text": "Here you can see that\noutbound order line, product,",
    "start": "314400",
    "end": "318690"
  },
  {
    "text": "and product alternate source\nflows are in progress.",
    "start": "318690",
    "end": "322110"
  },
  {
    "text": "As soon as they are successful,",
    "start": "322110",
    "end": "324419"
  },
  {
    "text": "they will trigger the\ncorresponding destination flows",
    "start": "324420",
    "end": "327150"
  },
  {
    "text": "into the AWS Supply Chain Data Lake.",
    "start": "327150",
    "end": "330240"
  },
  {
    "text": "Looks like the source\nflows are all successful",
    "start": "330240",
    "end": "332940"
  },
  {
    "text": "and that should trigger the\ncorresponding destination flows,",
    "start": "332940",
    "end": "335790"
  },
  {
    "text": "which are successful as well for product,",
    "start": "335790",
    "end": "338130"
  },
  {
    "text": "product alternate, and\noutbound order line.",
    "start": "338130",
    "end": "340653"
  },
  {
    "text": "Now following these steps\nthrough one to four,",
    "start": "341490",
    "end": "344400"
  },
  {
    "text": "you're all set for the\ndata ingestion setup.",
    "start": "344400",
    "end": "347190"
  },
  {
    "text": "For subsequent data\nflows against your flows,",
    "start": "347190",
    "end": "350070"
  },
  {
    "text": "you can always go through this\none click upload experience",
    "start": "350070",
    "end": "354720"
  },
  {
    "text": "without having to go through\nsteps one through four again.",
    "start": "354720",
    "end": "358350"
  },
  {
    "text": "Or you can have your middleware\nconnector sync the data",
    "start": "358350",
    "end": "361770"
  },
  {
    "text": "to your AWS S3 prefix path\nas shown here on the screen.",
    "start": "361770",
    "end": "366770"
  },
  {
    "text": "For operational purposes,",
    "start": "367650",
    "end": "369030"
  },
  {
    "text": "you can always manage your\nsource flows by editing them",
    "start": "369030",
    "end": "373290"
  },
  {
    "text": "as well as delete them as needed.",
    "start": "373290",
    "end": "376440"
  },
  {
    "text": "The same goes with the destination flows,",
    "start": "376440",
    "end": "378360"
  },
  {
    "text": "you can manage or delete the mapping",
    "start": "378360",
    "end": "380610"
  },
  {
    "text": "and sequence wherever you need.",
    "start": "380610",
    "end": "382623"
  },
  {
    "text": "Now, that concludes our demo,",
    "start": "383490",
    "end": "385380"
  },
  {
    "text": "thank you so much for your time.",
    "start": "385380",
    "end": "387180"
  },
  {
    "text": "Happy data onboarding.",
    "start": "387180",
    "end": "388473"
  }
]
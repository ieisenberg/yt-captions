[
  {
    "start": "0",
    "end": "103000"
  },
  {
    "text": "all right ready to go okay",
    "start": "1580",
    "end": "10200"
  },
  {
    "text": "what's the energy guys come on bring it up bring it up okay yeah after party",
    "start": "10200",
    "end": "15480"
  },
  {
    "text": "well thanks a lot for everyone to everyone for making it to the",
    "start": "15480",
    "end": "21180"
  },
  {
    "text": "presentation on Friday morning my name is Dan Banga I do lead a team of business development managers at amazon",
    "start": "21180",
    "end": "27660"
  },
  {
    "text": "web services focusing on machine learning and deep learning platforms and services specifically sage maker and the",
    "start": "27660",
    "end": "34410"
  },
  {
    "text": "ecosystem of products that come around it it's my pleasure to present alongside",
    "start": "34410",
    "end": "40410"
  },
  {
    "text": "face book today my friend Jeff Smith from face book AI research and the goal",
    "start": "40410",
    "end": "46289"
  },
  {
    "text": "of today is to talk to you in in death and details about the pie tours the",
    "start": "46289",
    "end": "51690"
  },
  {
    "text": "experience of a developer as it as it comes to PI torch on on the cloud on",
    "start": "51690",
    "end": "57149"
  },
  {
    "text": "sage maker just for a little bit of housekeeping there will be code we will be showing",
    "start": "57149",
    "end": "63809"
  },
  {
    "text": "some code but don't worry about all the details because as a matter of fact the code are available the code is available",
    "start": "63809",
    "end": "69299"
  },
  {
    "text": "on github so just what we want to focus on today is the best practices some of",
    "start": "69299",
    "end": "76350"
  },
  {
    "text": "the insights that we can share right now so that you you at least get that you got this like that home and the details",
    "start": "76350",
    "end": "83729"
  },
  {
    "text": "are available online for you to read okay also this is a 400 level session we",
    "start": "83729",
    "end": "90659"
  },
  {
    "text": "won't be doing going through a lot of definitions but again everything is available to read online and the code is",
    "start": "90659",
    "end": "98430"
  },
  {
    "text": "heavily documented for for for your benefit okay so I'd like to get this",
    "start": "98430",
    "end": "105600"
  },
  {
    "start": "103000",
    "end": "211000"
  },
  {
    "text": "started by walking you through some of the ten top ten strategic trends in",
    "start": "105600",
    "end": "111390"
  },
  {
    "text": "technology for 2019 as you all know we're walking towards the world of autonomous things and immersive",
    "start": "111390",
    "end": "117329"
  },
  {
    "text": "experience in blockchain as you might have seen there are tons tons of these net new technologies that are coming in",
    "start": "117329",
    "end": "123719"
  },
  {
    "text": "impact in our world and I believe you're all here today because you understand the impact that AI has over the world",
    "start": "123719",
    "end": "131879"
  },
  {
    "text": "that we are all going being today tomorrow but particularly some of the things that caught my",
    "start": "131879",
    "end": "137680"
  },
  {
    "text": "attention when I was looking at these changes are things like digital ethics and privacy or smart spaces or AI driven",
    "start": "137680",
    "end": "145900"
  },
  {
    "text": "development and those are practical aspects of using deep learning and AI to",
    "start": "145900",
    "end": "153070"
  },
  {
    "text": "make essentially the experience better when it comes to AI driven development for developers and data scientists but",
    "start": "153070",
    "end": "159820"
  },
  {
    "text": "as well as the experience better when it comes to humanity in general so we're seeing all these trends coming up and",
    "start": "159820",
    "end": "166120"
  },
  {
    "text": "we're seeing AI involved in all of these and at AWS specifically we're seeing tens of thousands of developers actively",
    "start": "166120",
    "end": "172840"
  },
  {
    "text": "building machine learning models on the cloud today so much so that there's a",
    "start": "172840",
    "end": "178050"
  },
  {
    "text": "250% growth year over year and then this is mostly enabled by the the speed at",
    "start": "178050",
    "end": "186700"
  },
  {
    "text": "which these developers and their scientists can build trained and tuned machine learning models on the cloud so",
    "start": "186700",
    "end": "191800"
  },
  {
    "text": "part of what we do with sage maker and other products and services is to accelerate the process that someone has",
    "start": "191800",
    "end": "198820"
  },
  {
    "text": "to go through from ideation to realization as far as their project is concerned when it comes to machine",
    "start": "198820",
    "end": "204790"
  },
  {
    "text": "learning and eight out of ten of tensorflow workloads that were observing nowadays is running on AWS including the",
    "start": "204790",
    "end": "210459"
  },
  {
    "text": "benchmark now we're working with tons and tons of customers a lot of them you",
    "start": "210459",
    "end": "216610"
  },
  {
    "text": "might you might know if you're using ZocDoc to go to the doctor for example you're probably using tensorflow natal",
    "start": "216610",
    "end": "223000"
  },
  {
    "text": "you are using tensorflow on AWS in the backend DigitalGlobe is using say",
    "start": "223000",
    "end": "228820"
  },
  {
    "text": "shoemaker to analyze large images and and then provide those large images and",
    "start": "228820",
    "end": "235360"
  },
  {
    "text": "insights on those large images to their own customers as a service so we're seeing a heavy momentum going towards",
    "start": "235360",
    "end": "241890"
  },
  {
    "text": "leveraging machine learning on the cloud today and in sports analytics as well",
    "start": "241890",
    "end": "247320"
  },
  {
    "text": "some of the fun examples are folks like the NFL essentially interesting terabytes of data into the cloud and",
    "start": "247320",
    "end": "254310"
  },
  {
    "text": "leveraging Amazon Sage maker to transform the experience that some of",
    "start": "254310",
    "end": "259720"
  },
  {
    "text": "their customers have when it comes to the game we're saying similar dynamics in sports analytics with Formula One",
    "start": "259720",
    "end": "266590"
  },
  {
    "text": "essentially ingesting terabytes of data through the cars during race and then",
    "start": "266590",
    "end": "272230"
  },
  {
    "text": "using machine learning on sage maker to transform their experience of visual experience that folks that are watching",
    "start": "272230",
    "end": "278770"
  },
  {
    "text": "the races are having so our approach that it appears to enable all of these",
    "start": "278770",
    "end": "284199"
  },
  {
    "start": "281000",
    "end": "351000"
  },
  {
    "text": "capabilities and all these accelerations is to essentially start by being customer focused 90 to 95 percent of our",
    "start": "284199",
    "end": "291130"
  },
  {
    "text": "roadmap is driven by the feedback that we get from customers we are aggressive",
    "start": "291130",
    "end": "296770"
  },
  {
    "text": "at the pace at which we innovate if you observe the keynotes and all the launches that we announced lately you",
    "start": "296770",
    "end": "303010"
  },
  {
    "text": "you this might not be a surprise to you and we also focus on the breath and the",
    "start": "303010",
    "end": "308410"
  },
  {
    "text": "Deaf at the same time there's more AI and machine learning services in production at AWS and anywhere else and",
    "start": "308410",
    "end": "314800"
  },
  {
    "text": "because we're aggressively listening to what our customers are asking for we're essentially building anything that",
    "start": "314800",
    "end": "321130"
  },
  {
    "text": "they're asking for anything that is popular we support every framework or the most popular framework that exists",
    "start": "321130",
    "end": "326530"
  },
  {
    "text": "nowadays pythor stencil fluid makes night cafe you name it and then we package all of this with within a",
    "start": "326530",
    "end": "332590"
  },
  {
    "text": "secured environment and we embed research and development into everything that we do for example in sage maker",
    "start": "332590",
    "end": "338860"
  },
  {
    "text": "will provide algorithms that are coming from the research that we do at Amazon to come and we make them available for",
    "start": "338860",
    "end": "344680"
  },
  {
    "text": "our customers to consume so now let's jump into the developers experience today as a developer you're probably",
    "start": "344680",
    "end": "353020"
  },
  {
    "start": "351000",
    "end": "377000"
  },
  {
    "text": "working with I mean by developer I mean they're scientists and AI engineer developer you're probably partnering",
    "start": "353020",
    "end": "359349"
  },
  {
    "text": "with a DevOps engineer or someone that owns the infrastructure and you're working together to essentially put your",
    "start": "359349",
    "end": "366340"
  },
  {
    "text": "products in production right so you build your AI models using things like Jupiter notebook and then you have to",
    "start": "366340",
    "end": "373060"
  },
  {
    "text": "hand that over to the devil person to put that in production but I want to challenge all of us today to think about",
    "start": "373060",
    "end": "379630"
  },
  {
    "start": "377000",
    "end": "457000"
  },
  {
    "text": "is this concept of AI driven development where you're working on an integrated workflow an integrated AI application",
    "start": "379630",
    "end": "387039"
  },
  {
    "text": "development workflow that includes a few things one of them is the AI developers tool as a developer what kind of SDK",
    "start": "387039",
    "end": "394690"
  },
  {
    "text": "what kind of tool which you require in order to build AI models the second thing that comes in",
    "start": "394690",
    "end": "400420"
  },
  {
    "text": "in a picture is of course there are algorithms because you as an AI developer again you want to use the",
    "start": "400420",
    "end": "405970"
  },
  {
    "text": "tools that make your life easier but you also want to build some algorithms what if some of these algorithms were already",
    "start": "405970",
    "end": "412690"
  },
  {
    "text": "figured out by folks like us and made available to you in order for you to pick them up and then use that directly",
    "start": "412690",
    "end": "417730"
  },
  {
    "text": "or what if the same environment would be able to provide you the ability to bring your own algorithm in pi torch or",
    "start": "417730",
    "end": "424240"
  },
  {
    "text": "another framework language the third thing is an end to end machine learning",
    "start": "424240",
    "end": "429520"
  },
  {
    "text": "platforms that is fully integrated with the developer tools and then the algorithm and that's where CH mail comes",
    "start": "429520",
    "end": "435160"
  },
  {
    "text": "in the picture and the fourth thing is of course the model templates and packages and SDK and everything that we",
    "start": "435160",
    "end": "440800"
  },
  {
    "text": "can't empathize to make sure that the experience that you have is reproducible and repeatable and so that's where a",
    "start": "440800",
    "end": "447850"
  },
  {
    "text": "sage maker and PI thoughts are really nicely combined to essentially make sure that the developers experiences is as",
    "start": "447850",
    "end": "454600"
  },
  {
    "text": "easy as possible and we gotta jump into a details right now I believe who here is not familiar with sage maker pretty",
    "start": "454600",
    "end": "462490"
  },
  {
    "text": "much no one so we're going to go really rapidly through the details you've seen the AWS machine learning stack before we",
    "start": "462490",
    "end": "468970"
  },
  {
    "text": "support the GPU that are provided by Nvidia Volta v100 so the fastest GPU in",
    "start": "468970",
    "end": "475120"
  },
  {
    "text": "the world all the frameworks that are available and then as of a couple of days ago sage maker was up mented with",
    "start": "475120",
    "end": "481480"
  },
  {
    "text": "ground truth data labeling capabilities elastic inference reinforcement learning workflow and collaboration capabilities",
    "start": "481480",
    "end": "488140"
  },
  {
    "text": "so there's a lot that we make available there all of these is packaged behind an API that again enables AI driven",
    "start": "488140",
    "end": "496000"
  },
  {
    "text": "development and just to accelerate again on the capabilities of sage maker as a reminder you have a notebook instances",
    "start": "496000",
    "end": "502810"
  },
  {
    "text": "environment that enables you to build models to train in tune models as well as deploying models in production and",
    "start": "502810",
    "end": "509380"
  },
  {
    "text": "the key call-out here is that all of these are available within again the",
    "start": "509380",
    "end": "514450"
  },
  {
    "text": "framework and integrated framework of cloud data Lake solutions compliance and",
    "start": "514450",
    "end": "519610"
  },
  {
    "text": "other capabilities pay-as-you-go and all the things that you know now PI torch to",
    "start": "519610",
    "end": "525130"
  },
  {
    "text": "approach the PI torch experience or the experience of a pythons developer and sage maker I want to walk you through",
    "start": "525130",
    "end": "530650"
  },
  {
    "text": "the concept that I call the anatomy of a deep learning framework seance ash maker and the experience of a",
    "start": "530650",
    "end": "536589"
  },
  {
    "start": "535000",
    "end": "819000"
  },
  {
    "text": "Python Chevelle / or a developer in general usually starts with the developer working on either their laptop",
    "start": "536589",
    "end": "542769"
  },
  {
    "text": "or the Jupiter notebook and for that I'm actually going to switch to my laptop to",
    "start": "542769",
    "end": "548399"
  },
  {
    "text": "get to get the work load started okay",
    "start": "548399",
    "end": "554760"
  },
  {
    "text": "okay I'm gonna get back to the presentation and move back to sharing my screen when it's possible so as a",
    "start": "554760",
    "end": "562029"
  },
  {
    "text": "developer you get started with with your laptop or Jupiter notebook environment",
    "start": "562029",
    "end": "567040"
  },
  {
    "text": "and when the experience is a shoemaker starts like this well you you have",
    "start": "567040",
    "end": "572170"
  },
  {
    "text": "control over part of the infrastructure some of the infrastructure you can either kick off jupiter notebooks or",
    "start": "572170",
    "end": "577630"
  },
  {
    "text": "training environment or hosting environment and that control is augmented by capabilities like a stage",
    "start": "577630",
    "end": "585579"
  },
  {
    "text": "maker identity sorry it obvious identity and access management that would enable you to basically have access controls in",
    "start": "585579",
    "end": "592630"
  },
  {
    "text": "in their environment and then you would be able to encrypt data and in the EBS",
    "start": "592630",
    "end": "598540"
  },
  {
    "text": "drives and everything data at rest and in transit using the key management service of AWS now all that work",
    "start": "598540",
    "end": "605829"
  },
  {
    "text": "together with Amazon s3 to provide data in the model artifacts to to the model",
    "start": "605829",
    "end": "611380"
  },
  {
    "text": "the other piece of the equation is Amazon ECR that makes it possible for us",
    "start": "611380",
    "end": "616630"
  },
  {
    "text": "to package algorithms in different doctor containers for the workload that you have to run through one of them is",
    "start": "616630",
    "end": "622779"
  },
  {
    "text": "PI tours the other ones are tend to flow MX net trainer and it's also possible for you to bring your own algorithm",
    "start": "622779",
    "end": "628600"
  },
  {
    "text": "within this ecosystem now the other thing that is important is logs because we don't want the developers to have to",
    "start": "628600",
    "end": "636040"
  },
  {
    "text": "run machines all the time or after the workloads are done it's possible for us",
    "start": "636040",
    "end": "641199"
  },
  {
    "text": "to essentially externalize the logs back to carwash logs and make sure that we shut down their infrastructure after the",
    "start": "641199",
    "end": "647589"
  },
  {
    "text": "workload is done now I believe you're familiar with the Jupiter notebooks experience it's an easy to machine that",
    "start": "647589",
    "end": "653620"
  },
  {
    "text": "we spin up for you and then we put sample notebooks in there to practice and then for the training ecosystem we",
    "start": "653620",
    "end": "660490"
  },
  {
    "text": "spin up an ephemeral cluster that comes attached with an EBS volume and we fetch the data automatically from the cloud",
    "start": "660490",
    "end": "666640"
  },
  {
    "text": "storage in to that training environment with the possibility of streaming that data in directly bypassing the the EBS volume",
    "start": "666640",
    "end": "674780"
  },
  {
    "text": "there and work taking the data directly to to the instances for training now the other thing that are that is important",
    "start": "674780",
    "end": "681380"
  },
  {
    "text": "is the hosting experience so with a few clicks you can essentially host your",
    "start": "681380",
    "end": "686420"
  },
  {
    "text": "machine learning models behind the rest endpoint that is managed by Sage maker or behind the badge in France a batch",
    "start": "686420",
    "end": "693440"
  },
  {
    "text": "transformation endpoint that is also managed by Sage maker now what happens for when you want to consume your models",
    "start": "693440",
    "end": "700520"
  },
  {
    "text": "well it's possible again within a sage maker environment to using AWS lambda",
    "start": "700520",
    "end": "705980"
  },
  {
    "text": "and API gateway communicate with that rest endpoint that you've made available for for serving your models now let's",
    "start": "705980",
    "end": "713690"
  },
  {
    "text": "dig a little bit into the docker containers that we pull in in order to train your machine learning models if",
    "start": "713690",
    "end": "719840"
  },
  {
    "text": "you want to look at it from bottom up as far as the stack is concerned with in that container we have a data agent",
    "start": "719840",
    "end": "725660"
  },
  {
    "text": "which has a responsibility to essentially go fetch the data shard the data distribute the data to multiple",
    "start": "725660",
    "end": "731450"
  },
  {
    "text": "machines and bring that to the tooter cluster there is also a lock matrix agent which also has a responsibility to",
    "start": "731450",
    "end": "737660"
  },
  {
    "text": "collect the logs from every machines that are involved in the training process and then push those to the cloud wash logs metric and then when you go",
    "start": "737660",
    "end": "744230"
  },
  {
    "text": "slightly higher up the stack you get the possibility to distribute your training jobs depending on the frameworks that",
    "start": "744230",
    "end": "750680"
  },
  {
    "text": "that is that you're leveraging and also you have possibility to have CUDA",
    "start": "750680",
    "end": "755690"
  },
  {
    "text": "libraries in case you're using GPUs going slightly higher up the stack we get PI towards libraries install whether",
    "start": "755690",
    "end": "762590"
  },
  {
    "text": "you if you're using a PI torch container we get tensorflow installed if you're using a tensor flow container and so on and so forth and then going again",
    "start": "762590",
    "end": "769940"
  },
  {
    "text": "slightly higher up the stack we get the Amazon sage maker SDK which is the most powerful item on this entire slide the",
    "start": "769940",
    "end": "775940"
  },
  {
    "text": "sage Maker SDK is that thing that makes it possible for us to do everything here",
    "start": "775940",
    "end": "781100"
  },
  {
    "text": "fetch the data on your behalf log the data on your behalf you can summon sage",
    "start": "781100",
    "end": "786440"
  },
  {
    "text": "maker through the SDK and say I want four or five six machines and we will figure out how to do everything else on",
    "start": "786440",
    "end": "791900"
  },
  {
    "text": "your behalf and way higher up the stack we have your algorithm and again the",
    "start": "791900",
    "end": "797120"
  },
  {
    "text": "algorithm could be an Amazon provided algorithm or it could be you bring your own algorithm in tensorflow but for that for the for",
    "start": "797120",
    "end": "803630"
  },
  {
    "text": "the impetus for this specific case but for that scenario you wouldn't have to build all the distribution and",
    "start": "803630",
    "end": "810710"
  },
  {
    "text": "everything else that happens within the container because we bring all of these capabilities all you have to bring a",
    "start": "810710",
    "end": "816020"
  },
  {
    "text": "co-pilot or script and and we'll walk through an example now what happens when you do import sage maker when you",
    "start": "816020",
    "end": "822650"
  },
  {
    "start": "819000",
    "end": "1139000"
  },
  {
    "text": "essentially import the sdk within your working environment if you remember that stack that we just walk through the",
    "start": "822650",
    "end": "828950"
  },
  {
    "text": "Python that the Python SDK does a few things well first you you import sage maker for this specific case of pi torch",
    "start": "828950",
    "end": "835730"
  },
  {
    "text": "we provide sage maker the Python that has a couple of classes one is PI 2 and PI throws model who here is familiar",
    "start": "835730",
    "end": "841550"
  },
  {
    "text": "with scikit-learn ok quite a number of people so you can think about the Python",
    "start": "841550",
    "end": "847130"
  },
  {
    "text": "estimator in sage maker as an analogy to psychic learn where we packaged the context class that has the possibility",
    "start": "847130",
    "end": "854390"
  },
  {
    "text": "to talk to the infrastructure it has a possibility to fetch the Python container it has the possibility to hand",
    "start": "854390",
    "end": "861230"
  },
  {
    "text": "over happy parameters to your training job and so that's how the developer communicates with sage maker and",
    "start": "861230",
    "end": "867680"
  },
  {
    "text": "communicates with the PI college environment so that's essentially what happens here as I create a Python",
    "start": "867680",
    "end": "873170"
  },
  {
    "text": "estimator and within that estimator I pointed to my main function and then I'll say I want the MLP 3 to extra-large",
    "start": "873170",
    "end": "880310"
  },
  {
    "text": "which is a GPU machine and as I tell the version of pi thoughts that I want to use and the hyper parameters that I want",
    "start": "880310",
    "end": "887750"
  },
  {
    "text": "to leverage now the second thing is similar to scikit-learn when you want to start training the model you say pythons",
    "start": "887750",
    "end": "894500"
  },
  {
    "text": "estimator that fit essentially asking sage maker to go fetch the data using the data agent from s3 and you point it",
    "start": "894500",
    "end": "902120"
  },
  {
    "text": "to these channels so the content of this dictionary is actually in this case we have training which is the pointer to",
    "start": "902120",
    "end": "909500"
  },
  {
    "text": "the training data set on s3 and then we have test which is a pointer to the test data set on s3 so in this case a shoe",
    "start": "909500",
    "end": "915680"
  },
  {
    "text": "maker would know how to go fetch the data in these two buckets and it would",
    "start": "915680",
    "end": "921410"
  },
  {
    "text": "know that the trained one is for the purpose of training and a test one is for the purpose of testing so pretty straightforward and once you're done",
    "start": "921410",
    "end": "927770"
  },
  {
    "text": "training you probably want to host your model behind the endpoint and it's",
    "start": "927770",
    "end": "934310"
  },
  {
    "text": "extreme easy with sage maker to essentially host your model all you have to do is use the Python model class point stage may",
    "start": "934310",
    "end": "941630"
  },
  {
    "text": "appoint the Python model class to the location of the model itself on Amazon s3 and then give it some rows and all",
    "start": "941630",
    "end": "948350"
  },
  {
    "text": "that for Sage maker to be able to go fetch that data on your behalf and then",
    "start": "948350",
    "end": "954200"
  },
  {
    "text": "with six laters DEP LOI it's possible for Sage maker to spin up an instance in",
    "start": "954200",
    "end": "960470"
  },
  {
    "text": "this case three instances and then host your model on your behalf and expose that behind the rest API now in that",
    "start": "960470",
    "end": "967190"
  },
  {
    "text": "training example we had three machines involved in the training process and what does that look like specifically well when you have three machines that",
    "start": "967190",
    "end": "974240"
  },
  {
    "text": "station maker spins up on your behalf all of them have the same stack again that we walk through from the data",
    "start": "974240",
    "end": "979760"
  },
  {
    "text": "agents in the lock matrix and the first thing that happens is that the data agents in all these machines go to fetch",
    "start": "979760",
    "end": "985370"
  },
  {
    "text": "the data from the cloud storage again stage maker knows how to shot the data and distribute that to all the machines",
    "start": "985370",
    "end": "991940"
  },
  {
    "text": "so in this case one third of the data would go to one machine if that's what you decide or it's also possible for",
    "start": "991940",
    "end": "998150"
  },
  {
    "text": "Sage Maker to take the entire data set and hand that over to all the machines that are involved in the process",
    "start": "998150",
    "end": "1003670"
  },
  {
    "text": "now once the data are fetched by the data age and they're placed under these folders opt ml input data train and test",
    "start": "1003670",
    "end": "1010810"
  },
  {
    "text": "because again we pointed it to two training folders now what you have to do",
    "start": "1010810",
    "end": "1016060"
  },
  {
    "text": "as a BIOS developer is to know that from your code you have to go fetch the training data in these folders and so",
    "start": "1016060",
    "end": "1023080"
  },
  {
    "text": "our responsibility is to go get it from s3 put it here your responsibility is to get it from here and use it in your code",
    "start": "1023080",
    "end": "1030449"
  },
  {
    "text": "the next thing that happens is in this scenario specifically it's a distributed training exercise and because it's a",
    "start": "1030449",
    "end": "1037120"
  },
  {
    "text": "distributed training exercise our PI torch containers provide the distributed capabilities in pi torch distributed",
    "start": "1037120",
    "end": "1045010"
  },
  {
    "text": "backing capabilities in PI for which one of them is n wcl another one is glue with this TCP capability as well the",
    "start": "1045010",
    "end": "1051910"
  },
  {
    "text": "developers don't have to worry about that so the sage makeup I Tosh containers bring that and make it",
    "start": "1051910",
    "end": "1057610"
  },
  {
    "text": "possible for these machines to communicate during a distributed training process and once the model is",
    "start": "1057610",
    "end": "1063310"
  },
  {
    "text": "trained stage makeup puts the model in ops ml model out sorry ops mmm",
    "start": "1063310",
    "end": "1068620"
  },
  {
    "text": "and any with the name of the model in this case it's a table oh and after the",
    "start": "1068620",
    "end": "1073659"
  },
  {
    "text": "model is put there essentially what happens is a shoemaker fetches the model and then puts that in the model artifact",
    "start": "1073659",
    "end": "1080520"
  },
  {
    "text": "bucket now if you have some outputs like images or anything that is generated by",
    "start": "1080520",
    "end": "1086080"
  },
  {
    "text": "your model as you train it there's also an up ml output folder in which if you",
    "start": "1086080",
    "end": "1091659"
  },
  {
    "text": "put information so H maker is going to fetch and push back to the cloud storage so that's the responsibility of stage",
    "start": "1091659",
    "end": "1097120"
  },
  {
    "text": "maker in the process of training a distributed algorithm on a cloud and your responsibility is to know where",
    "start": "1097120",
    "end": "1104440"
  },
  {
    "text": "these things are and fetch them and use them now the lock metrics agent also as",
    "start": "1104440",
    "end": "1110470"
  },
  {
    "text": "you do train your model it goes around and then fetches all the logs from all the machines aggregates them and pushes",
    "start": "1110470",
    "end": "1116890"
  },
  {
    "text": "them back to the cloud storage so that you can to the cloud watch logs so that you can visualize your logs after the",
    "start": "1116890",
    "end": "1123130"
  },
  {
    "text": "execution of a training jar now to go higher up the stack and talk",
    "start": "1123130",
    "end": "1128470"
  },
  {
    "text": "specifically about pythons 1.0 what is the strategy there and what are the benefits that the developers have there",
    "start": "1128470",
    "end": "1134950"
  },
  {
    "text": "it's my pleasure to introduce you Jeff Smith from Facebook a I research hello",
    "start": "1134950",
    "end": "1145270"
  },
  {
    "start": "1139000",
    "end": "1263000"
  },
  {
    "text": "everyone my name is Jeff I'm here from Facebook a I research I'm really happy that Amazon gave us the chance to come and",
    "start": "1145270",
    "end": "1151029"
  },
  {
    "text": "tell a little bit of our story behind why we built pi torch and what we do with PI tour should Facebook so let me",
    "start": "1151029",
    "end": "1157480"
  },
  {
    "text": "dive into that so one of the most important things we do with a I at Facebook is to make our existing",
    "start": "1157480",
    "end": "1163419"
  },
  {
    "text": "products better and so these are things like social recommendations asking your",
    "start": "1163419",
    "end": "1168460"
  },
  {
    "text": "friends what exactly you know searching for a restaurant or something like that",
    "start": "1168460",
    "end": "1173529"
  },
  {
    "text": "I'm so you can see an example of something like that so that to be able to work with that sort of data set of",
    "start": "1173529",
    "end": "1178990"
  },
  {
    "text": "your friends there's other interesting applications one of them is I really like which I will point to later is",
    "start": "1178990",
    "end": "1185320"
  },
  {
    "text": "machine translation people all around the world use Facebook this is one that I use on a nearly daily basis we use",
    "start": "1185320",
    "end": "1193149"
  },
  {
    "text": "machine translation as a way of using deep learning models to be able to allow people to talk to each other who don't",
    "start": "1193149",
    "end": "1198429"
  },
  {
    "text": "speak the same language accessibility is another application which depending on your personal",
    "start": "1198429",
    "end": "1204580"
  },
  {
    "text": "background you may not have seen before but it's a really powerful use of deep learning to render all of this rich user",
    "start": "1204580",
    "end": "1210460"
  },
  {
    "text": "content that we have across things like Facebook and Instagram accessible to people who have different abilities and",
    "start": "1210460",
    "end": "1216370"
  },
  {
    "text": "we do this with with pi torch it's not just the good parts of applications",
    "start": "1216370",
    "end": "1223870"
  },
  {
    "text": "though that AI helps us with it's also the difficult stuff the protection of the community the integrity of your",
    "start": "1223870",
    "end": "1229990"
  },
  {
    "text": "experience as a Facebook Instagram user and so this is preventing things like share baiting as you see there and even",
    "start": "1229990",
    "end": "1237640"
  },
  {
    "text": "suicide prevention detection so these are really important applications that we're investing a lot in internally",
    "start": "1237640",
    "end": "1243220"
  },
  {
    "text": "across the board to be able to make sure that our platform is used in a way that really benefits you the users the most",
    "start": "1243220",
    "end": "1250299"
  },
  {
    "text": "as as much as possible and deep learning plays a really key role in that as powered by PI torch ok so there we go we",
    "start": "1250299",
    "end": "1264700"
  },
  {
    "start": "1263000",
    "end": "1292000"
  },
  {
    "text": "do this as an extraordinary scale today so pie charts today is our end and research production platform performing",
    "start": "1264700",
    "end": "1271900"
  },
  {
    "text": "300 trillion inference operations a day we also run",
    "start": "1271900",
    "end": "1278049"
  },
  {
    "text": "all of this code on mobile devices so the technology you're going to see today is actually deployed on over a billion",
    "start": "1278049",
    "end": "1283990"
  },
  {
    "text": "mobile devices and so there are a lot of unique challenges that come from operating of that scale on servers and",
    "start": "1283990",
    "end": "1290290"
  },
  {
    "text": "in mobile devices and so it takes a fairly unique approach to technology to develop the tool team that allows people",
    "start": "1290290",
    "end": "1296470"
  },
  {
    "start": "1292000",
    "end": "1403000"
  },
  {
    "text": "to be successful in doing things like that so our choice for this is pi torch I'm gonna be a little bit of background",
    "start": "1296470",
    "end": "1301540"
  },
  {
    "text": "on what is pi torch the first thing I want to point out is that pi torches has",
    "start": "1301540",
    "end": "1308230"
  },
  {
    "text": "gotten really popular here and so we've seen this big uptick and contributors on github we have now become the second",
    "start": "1308230",
    "end": "1315940"
  },
  {
    "text": "fastest growing project and all of open source on github which is really exciting to see so it's been this really",
    "start": "1315940",
    "end": "1322000"
  },
  {
    "text": "great community success story in which we've developed an open-source AI framework in collaboration with everyone",
    "start": "1322000",
    "end": "1329020"
  },
  {
    "text": "in the community if you're not familiar with it here are some of the places you might start to touch it if you as a user",
    "start": "1329020",
    "end": "1335440"
  },
  {
    "text": "these are just AP is that allow you to do various things like have like used",
    "start": "1335440",
    "end": "1340539"
  },
  {
    "text": "specific optimizers and this is just kind of a sampling of some of the utilities that come out of the box that",
    "start": "1340539",
    "end": "1345639"
  },
  {
    "text": "are really easy to use I'll show you them kind of in action when it makes it a little bit clearer okay so the the",
    "start": "1345639",
    "end": "1353049"
  },
  {
    "text": "first example here to be clear we have now two AP eyes across Python and C++",
    "start": "1353049",
    "end": "1359289"
  },
  {
    "text": "we're showing them both here just to show that they're they're very similar in their structure and so your use of them really just depends upon what suits",
    "start": "1359289",
    "end": "1366370"
  },
  {
    "text": "your application the best here we're showing an example of some of the the out-of-the-box functionality you get",
    "start": "1366370",
    "end": "1372129"
  },
  {
    "text": "module is our way of defining a neural network layer and then you and then I'm gonna show you a few more functions you",
    "start": "1372129",
    "end": "1377649"
  },
  {
    "text": "can get so you get things like drop out nonlinear functions right out of the box here's some example of a few more things",
    "start": "1377649",
    "end": "1383379"
  },
  {
    "text": "so we have we have like data loaders from from torch vision which allow us to",
    "start": "1383379",
    "end": "1389350"
  },
  {
    "text": "get example datasets and things like that and again the Python and C++ are very similar and they're they're very",
    "start": "1389350",
    "end": "1395049"
  },
  {
    "text": "idiomatic to both of their languages that we're trying to really work with you as a developer in the way that",
    "start": "1395049",
    "end": "1400330"
  },
  {
    "text": "you're going to program to begin with I want to talk about the journey of research to production because this is",
    "start": "1400330",
    "end": "1406419"
  },
  {
    "start": "1403000",
    "end": "1577000"
  },
  {
    "text": "really what makes or breaks AI technology today because AI is a very old topic but it's a fairly new topic",
    "start": "1406419",
    "end": "1412690"
  },
  {
    "text": "within production and this is an area that I personally spend a lot of time my career on and I'm really excited at the solutions we've been able to develop so",
    "start": "1412690",
    "end": "1420009"
  },
  {
    "text": "I'm gonna tell you the story of what is research to production at Facebook and so this is kind of a this is a snapshot",
    "start": "1420009",
    "end": "1425139"
  },
  {
    "text": "from maybe say the past year or so so we have these three different unique technologies that have their own",
    "start": "1425139",
    "end": "1431610"
  },
  {
    "text": "capabilities ok there we go okay alright",
    "start": "1431610",
    "end": "1442149"
  },
  {
    "text": "so high-torque historically was used for prototyping it grew out of facebook AI research and was really focused on the",
    "start": "1442149",
    "end": "1447970"
  },
  {
    "text": "experience of AI researchers trying to develop papers but not necessarily to deploy to production onyx is the open",
    "start": "1447970",
    "end": "1456700"
  },
  {
    "text": "neural network exchange format which we developed in collaboration with a number of large companies within the larger",
    "start": "1456700",
    "end": "1463600"
  },
  {
    "text": "tech industry to allow us to have inner operation between deep learning frameworks it's real focus is on being",
    "start": "1463600",
    "end": "1469179"
  },
  {
    "text": "able to transfer neural network models from this research mode into production and then finally historically we developed a",
    "start": "1469179",
    "end": "1475600"
  },
  {
    "text": "different deep learning framework called cafe 2 which is really optimized to be able to execute on that trillions of",
    "start": "1475600",
    "end": "1482590"
  },
  {
    "text": "inference operations a day mission that we have organizationally this is great",
    "start": "1482590",
    "end": "1488400"
  },
  {
    "text": "but we want to make it smoother we want to put less work and then we want to have this really smooth transition from",
    "start": "1488400",
    "end": "1495580"
  },
  {
    "text": "prototyping all the way out to deployment and that is what PI torch 1.0 is all about so what is PI torch 1.0",
    "start": "1495580",
    "end": "1503800"
  },
  {
    "text": "it's a seamless path from research to production we want to make sure that whatever you can do in research you can",
    "start": "1503800",
    "end": "1509740"
  },
  {
    "text": "deploy with the least friction possible and so we have a lot of tools for this part of this is is allowing you to",
    "start": "1509740",
    "end": "1516760"
  },
  {
    "text": "really opt in and decide when you want flexibility and when you want to be concerned with having the sort of static",
    "start": "1516760",
    "end": "1523990"
  },
  {
    "text": "assumptions that we have in a production mode but to be able to have a tool chain that doesn't require you to make substantial changes just because you've",
    "start": "1523990",
    "end": "1530620"
  },
  {
    "text": "decided ok this model is good I want to ship it we talk about production ization",
    "start": "1530620",
    "end": "1535870"
  },
  {
    "text": "this is really the area I think that of AI technology where people have really only recently started to develop very",
    "start": "1535870",
    "end": "1542800"
  },
  {
    "text": "powerful and useful solutions as an engineer and an engineering manager this",
    "start": "1542800",
    "end": "1548080"
  },
  {
    "text": "is one of the biggest rate limiters I have seen on a large number of teams I've been on so when we talk about",
    "start": "1548080",
    "end": "1553120"
  },
  {
    "text": "production ization there are things we need to do to be able to operate at Facebook scale you need to use your hardware really efficiently because we",
    "start": "1553120",
    "end": "1560050"
  },
  {
    "text": "we need to do so much inference operations who have training jobs they're enormous which means that we",
    "start": "1560050",
    "end": "1565090"
  },
  {
    "text": "also need to be able to do that quite scalable we need to be able to able to address large clusters of GPUs and we",
    "start": "1565090",
    "end": "1570340"
  },
  {
    "text": "nee able need to be able to go across a range of devices CPUs GPUs mobile",
    "start": "1570340",
    "end": "1575530"
  },
  {
    "text": "devices another thing that we want to be able to do is to be able to optimize our",
    "start": "1575530",
    "end": "1581320"
  },
  {
    "start": "1577000",
    "end": "1727000"
  },
  {
    "text": "code the solution within pi torch 1.0 is this really unique and powerful technology which we call the JIT the JIT",
    "start": "1581320",
    "end": "1588190"
  },
  {
    "text": "allows us to be able to take this flexible experimental mode and adapt it for production use cases either",
    "start": "1588190",
    "end": "1594070"
  },
  {
    "text": "incrementally or as a whole program what we're talking about is this difference",
    "start": "1594070",
    "end": "1599200"
  },
  {
    "text": "between eager and static mode within deep learning frameworks in general classic Pike torch has really focused on",
    "start": "1599200",
    "end": "1606100"
  },
  {
    "text": "this eager mode where depending on how you're running a program maybe you actually just want to see the result right now or maybe you want to be able",
    "start": "1606100",
    "end": "1611620"
  },
  {
    "text": "to export a graph and using onyx or something like that to be able to optimize it later static graph deep learning frameworks",
    "start": "1611620",
    "end": "1619060"
  },
  {
    "text": "like cafe to have this sort of assumption that you're going to run your program just to produce a graph and that",
    "start": "1619060",
    "end": "1624220"
  },
  {
    "text": "graph itself is going to be executed to produce your result intrinsic conflict",
    "start": "1624220",
    "end": "1629770"
  },
  {
    "text": "between these two there's some pros and cons obviously people like flexibility and research it allows them to pursue",
    "start": "1629770",
    "end": "1635500"
  },
  {
    "text": "the development of new ideas but it's really hard to ship because we can't do things like optimization to run it",
    "start": "1635500",
    "end": "1641020"
  },
  {
    "text": "efficiently on the static side of this chart of course this gives us the",
    "start": "1641020",
    "end": "1646630"
  },
  {
    "text": "ability to optimize to run efficiently but this gets in the way of your development workflow when you're really in that early research stage so what",
    "start": "1646630",
    "end": "1653530"
  },
  {
    "text": "we've done is we've taken classic PI torch that a lot of people know and love that is simple and debuggable and is",
    "start": "1653530",
    "end": "1659140"
  },
  {
    "text": "straight Python as you know it and we now call that the PI torch eager mode again its main negative is that it we",
    "start": "1659140",
    "end": "1666820"
  },
  {
    "text": "can't optimize it for production and for a lot of use cases some users can't deploy with up with a Python runtime",
    "start": "1666820",
    "end": "1673420"
  },
  {
    "text": "environment so that's eager mode we now have script mode what can you do a",
    "start": "1673420",
    "end": "1679180"
  },
  {
    "text": "script mode well script mode allows you to extract out what is the graph from your flexible PI torch program and be",
    "start": "1679180",
    "end": "1686710"
  },
  {
    "text": "able to optimize it for efficient execution using the JIT compiler there's",
    "start": "1686710",
    "end": "1691960"
  },
  {
    "text": "two ways to do this one is that you can do this in a tracing mode that allows you to perform an execution of your",
    "start": "1691960",
    "end": "1698350"
  },
  {
    "text": "program to get its structure so if you have no conditional logic within your",
    "start": "1698350",
    "end": "1703810"
  },
  {
    "text": "entire deep learning framework is there your entire deep learning program you can actually just run it through once and then you'll get this the static",
    "start": "1703810",
    "end": "1710110"
  },
  {
    "text": "representation that you can execute then in a way that can be highly optimized or",
    "start": "1710110",
    "end": "1715570"
  },
  {
    "text": "you can move incremental e taking things function by function giving you that sort of incremental adaptation of",
    "start": "1715570",
    "end": "1720970"
  },
  {
    "text": "research to production and all this is is opt in at the level of of simple annotations a way that you can dive into",
    "start": "1720970",
    "end": "1728650"
  },
  {
    "start": "1727000",
    "end": "1819000"
  },
  {
    "text": "precisely how we use technology like this today is to use our fair seek",
    "start": "1728650",
    "end": "1733780"
  },
  {
    "text": "implementation fair seek is the is the framework that we developed to perform the six",
    "start": "1733780",
    "end": "1739570"
  },
  {
    "text": "billion neural machine translations we perform on a daily basis it's really",
    "start": "1739570",
    "end": "1744790"
  },
  {
    "text": "leading research technology that is actually deployed at extraordinary scale today making people happy",
    "start": "1744790",
    "end": "1750940"
  },
  {
    "text": "all across Facebook and you can use it on a specially optimized version of the",
    "start": "1750940",
    "end": "1758140"
  },
  {
    "text": "project which you can find on this github project and you can get it and you can understand how you can use it on stage maker today and with that I'm",
    "start": "1758140",
    "end": "1765400"
  },
  {
    "text": "gonna pass back to Dan thanks thank you Jeff okay thanks",
    "start": "1765400",
    "end": "1773140"
  },
  {
    "text": "so to recap stage maker provides the",
    "start": "1773140",
    "end": "1778390"
  },
  {
    "text": "end-to-end machine learning platform capabilities it can dance at the same",
    "start": "1778390",
    "end": "1785679"
  },
  {
    "text": "rhythm as the developer to basically get to a a driven development and pìkô which",
    "start": "1785679",
    "end": "1793780"
  },
  {
    "text": "provides all the api's and all the capabilities from a deep learning standpoint that can take the developer",
    "start": "1793780",
    "end": "1801010"
  },
  {
    "text": "from research to production in a seamless manner and Facebook and Amazon",
    "start": "1801010",
    "end": "1806230"
  },
  {
    "text": "work together to implement phasic which is basically Facebook AI research",
    "start": "1806230",
    "end": "1811570"
  },
  {
    "text": "sequence the sequence library on top of AWS Amazon sage maker so it's possible",
    "start": "1811570",
    "end": "1817000"
  },
  {
    "text": "for you to play around with it right now now we're going to switch to the demo and essentially for the demo we will I",
    "start": "1817000",
    "end": "1823600"
  },
  {
    "start": "1819000",
    "end": "1947000"
  },
  {
    "text": "would walk you through a practical aspect of what Jeff just described for",
    "start": "1823600",
    "end": "1829030"
  },
  {
    "text": "all of us so we will who here is familiar with generative address here",
    "start": "1829030",
    "end": "1834309"
  },
  {
    "text": "networks a few people okay so ganz are essentially the generative adversarial",
    "start": "1834309",
    "end": "1841330"
  },
  {
    "text": "networks were invented by younggu fellow and it's a it's a mechanism through which you can basically train two",
    "start": "1841330",
    "end": "1848470"
  },
  {
    "text": "networks to neural networks to work against each other for good at end of the day in this specific example of DC",
    "start": "1848470",
    "end": "1855910"
  },
  {
    "text": "GaN what we are going to implement is a neural network that is striving to",
    "start": "1855910",
    "end": "1862750"
  },
  {
    "text": "generate fake images in a neural network that is striving to basically",
    "start": "1862750",
    "end": "1868179"
  },
  {
    "text": "discriminate and correct those fake images as the in finding out whether these images are",
    "start": "1868179",
    "end": "1873200"
  },
  {
    "text": "fake or real so the idea there and the intuition there is that you you want to be able at the end of the day to",
    "start": "1873200",
    "end": "1879289"
  },
  {
    "text": "generate net new images from random noise and as that generator generates",
    "start": "1879289",
    "end": "1885529"
  },
  {
    "text": "net new images you also have a trained discriminator that is trained that is basically classifying these images as",
    "start": "1885529",
    "end": "1892220"
  },
  {
    "text": "fake or real and you train them together and a benefit there is that a point of",
    "start": "1892220",
    "end": "1897559"
  },
  {
    "text": "equilibrium is where the discriminator is almost at the quaint point us as in",
    "start": "1897559",
    "end": "1903529"
  },
  {
    "text": "5050 where it's not certain whether an image is is is real or not because it",
    "start": "1903529",
    "end": "1908750"
  },
  {
    "text": "starts very high in confidence because it was trained on recognizing real images and it ends up as I'm not sure",
    "start": "1908750",
    "end": "1914210"
  },
  {
    "text": "anymore and by that time you basically train a generator to give you some images that as a dad are as real as",
    "start": "1914210",
    "end": "1920539"
  },
  {
    "text": "possible now in the images domain it's a pretty fun example and it's very visual",
    "start": "1920539",
    "end": "1925639"
  },
  {
    "text": "so that's why we selected that for the demo but you can extrapolate that concept and basically train threat",
    "start": "1925639",
    "end": "1932720"
  },
  {
    "text": "detection models with a threat detection discriminator and a detection generator you can train fraud detection models you",
    "start": "1932720",
    "end": "1940519"
  },
  {
    "text": "can train all sorts of different types of models with that type of mindset so that's what we selected that for for the",
    "start": "1940519",
    "end": "1946340"
  },
  {
    "text": "demo and now I'm going to switch to to my laptop to walk you through some more details so the first thing is the we",
    "start": "1946340",
    "end": "1954860"
  },
  {
    "start": "1947000",
    "end": "2062000"
  },
  {
    "text": "will walk through some code and the first thing that I want to call out is I'm using my own laptop to do stage",
    "start": "1954860",
    "end": "1960590"
  },
  {
    "text": "maker specific development right again that's all thanks to the stage maker Python SDK so the stage maker Python SDK",
    "start": "1960590",
    "end": "1967309"
  },
  {
    "text": "is pip installable you can have that on your own laptop and what that makes possible is for you to basically use",
    "start": "1967309",
    "end": "1973669"
  },
  {
    "text": "sage maker on your own laptop or usage maker on the Jupiter notebook instance on the cloud whichever one works for you",
    "start": "1973669",
    "end": "1980480"
  },
  {
    "text": "I guess we should start by the jupiter notebook so the sage maker console looks",
    "start": "1980480",
    "end": "1985549"
  },
  {
    "text": "like this and then if you go to notebook and as of a couple of days ago we have all of these other capabilities that are",
    "start": "1985549",
    "end": "1992419"
  },
  {
    "text": "available but if you do create a jupiter notebook instance it's very easy to just",
    "start": "1992419",
    "end": "1998389"
  },
  {
    "text": "open the notebook here and i've already done that and then i would land into my my own Jupiter notebook folder with",
    "start": "1998389",
    "end": "2005020"
  },
  {
    "text": "with massage maker DCA an example now the structure of this example and which",
    "start": "2005020",
    "end": "2010720"
  },
  {
    "text": "again is available in github is I have a notebook to basically walk through some",
    "start": "2010720",
    "end": "2016660"
  },
  {
    "text": "of in an exploratory manner to some of the the things that I want to play with",
    "start": "2016660",
    "end": "2021820"
  },
  {
    "text": "right so I'm showing you the notebook now because it helps me do some preview of the data I hope it helps me visualize",
    "start": "2021820",
    "end": "2028540"
  },
  {
    "text": "my data on a subsample data set in order for me to know that I'm working with the proper data set that I need but it's",
    "start": "2028540",
    "end": "2035890"
  },
  {
    "text": "very straightforward the idea here is to to load the date to get a subset of the",
    "start": "2035890",
    "end": "2041350"
  },
  {
    "text": "data locally and then use that to explore your data set at a very at a",
    "start": "2041350",
    "end": "2046390"
  },
  {
    "text": "very low skill level now so I just want to point out that the experience is",
    "start": "2046390",
    "end": "2051580"
  },
  {
    "text": "possible on Jupiter notebook instance or sage maker the next call-out that I have is when you do execute on Sage Maker you",
    "start": "2051580",
    "end": "2058840"
  },
  {
    "text": "have this concept called local mode now sage maker local mode makes it possible",
    "start": "2058840",
    "end": "2064179"
  },
  {
    "start": "2062000",
    "end": "2553000"
  },
  {
    "text": "for developers to essentially kick off a station maker job using the sage maker",
    "start": "2064180",
    "end": "2069850"
  },
  {
    "text": "SDK and the sage sage maker syntax but leveraging docker containers on their",
    "start": "2069850",
    "end": "2074889"
  },
  {
    "text": "local machines before testing so what that makes possible is you're using the",
    "start": "2074890",
    "end": "2080710"
  },
  {
    "text": "same syntax and semantics and you're kicking off a job locally you can clean up your code you can remove some errors",
    "start": "2080710",
    "end": "2087399"
  },
  {
    "text": "and all these things I can typically go through but by the time you're done with that it's very easy for you to",
    "start": "2087400",
    "end": "2093129"
  },
  {
    "text": "extrapolate and push the same piece of code to Sage Maker and train to a larger instance 10 instance 120 instances if",
    "start": "2093130",
    "end": "2099400"
  },
  {
    "text": "you want now I'll start by working you through the what you need to do to",
    "start": "2099400",
    "end": "2105370"
  },
  {
    "text": "execute as in you assuming you already have your neural network we'll get into that but assuming you already have that",
    "start": "2105370",
    "end": "2110530"
  },
  {
    "text": "and you want to kick off a job with a shoemaker this is what the code looks like it's very straightforward so essentially I do import sage maker and I",
    "start": "2110530",
    "end": "2117700"
  },
  {
    "text": "import some extra libraries so that can basically help me visualize my data this is the essence of sage make a local mode",
    "start": "2117700",
    "end": "2124270"
  },
  {
    "text": "this role is basically my sage make a role that enables a shoemaker to do things on it appears on my behalf I put",
    "start": "2124270",
    "end": "2129970"
  },
  {
    "text": "it in my environment variables because I'm sharing the code and github and I don't want you to run things in my",
    "start": "2129970",
    "end": "2135160"
  },
  {
    "text": "account so that's why it's there but you you will have your own role there and in",
    "start": "2135160",
    "end": "2141010"
  },
  {
    "text": "this instance type variable I'm keeping I'm keeping two versions of it whether I want to submit the job to Sage maker or",
    "start": "2141010",
    "end": "2147190"
  },
  {
    "text": "I want to submit the job locally so in the case I want to submit the job locally I say I want to use the local",
    "start": "2147190",
    "end": "2153760"
  },
  {
    "text": "mode and and a point a shoe maker to my input data said in this case I have the",
    "start": "2153760",
    "end": "2159130"
  },
  {
    "text": "the face data set in my in my s3 bucket and this is what we we went through",
    "start": "2159130",
    "end": "2165430"
  },
  {
    "text": "slightly earlier now you create this estimator object which again is like the",
    "start": "2165430",
    "end": "2171579"
  },
  {
    "text": "spark context in spark if you familiar with it or is the cyclic learn estimator and you point it to your entry point the",
    "start": "2171579",
    "end": "2178960"
  },
  {
    "text": "entry point is the main function is a function that you that is actually executing the training process of your",
    "start": "2178960",
    "end": "2184450"
  },
  {
    "text": "training job the other thing that the estimator object is expecting from you is the source directory now the sorcerer",
    "start": "2184450",
    "end": "2191650"
  },
  {
    "text": "actually is very important because sometimes your code has helper libraries has utility libraries has dependencies",
    "start": "2191650",
    "end": "2198310"
  },
  {
    "text": "so all of these dependencies you can put them in the source directory and then CH maker is going to fetch that and put",
    "start": "2198310",
    "end": "2203859"
  },
  {
    "text": "that on every container docket container as it spins up the job for you that next thing is a role and the framework",
    "start": "2203859",
    "end": "2210730"
  },
  {
    "text": "version now when you say I want the framework version 1.0.0 point one dev",
    "start": "2210730",
    "end": "2216369"
  },
  {
    "text": "because you're using the Python estimator stage maker knows to go get pythons 1.0 and make it available to you",
    "start": "2216369",
    "end": "2223540"
  },
  {
    "text": "if you said you wanted vers firmware version zero point four point zero as a shoe maker would create a container with",
    "start": "2223540",
    "end": "2230380"
  },
  {
    "text": "Python zero point 4.0 for you and in this case I say I want two instances and",
    "start": "2230380",
    "end": "2235960"
  },
  {
    "text": "then this is an instance type that I want now here the instance type is local what we're going to do is that we're",
    "start": "2235960",
    "end": "2241990"
  },
  {
    "text": "going to change that to MLP 3/16 extra-large which is a GPU based",
    "start": "2241990",
    "end": "2247720"
  },
  {
    "text": "instance running on on on on th maker now the next thing that I need to",
    "start": "2247720",
    "end": "2253359"
  },
  {
    "text": "specify is the hyper parameters here I say well because it's the demo I say I",
    "start": "2253359",
    "end": "2259150"
  },
  {
    "text": "want to run I already run it for a longer period of time but I say I want to run it for two epochs and this is a",
    "start": "2259150",
    "end": "2264550"
  },
  {
    "text": "distributed back-end that I want to use and for selecting a distribution back-end you can say you want glow you",
    "start": "2264550",
    "end": "2269920"
  },
  {
    "text": "want n CC L you want depending on how you want to distribute your workload but you don't have to",
    "start": "2269920",
    "end": "2275740"
  },
  {
    "text": "again install and configure it CH maker does it by default here I can change my back-end to glue an end of a CL and you",
    "start": "2275740",
    "end": "2282040"
  },
  {
    "text": "can you can compare performances there now this display after it's basically a",
    "start": "2282040",
    "end": "2287410"
  },
  {
    "text": "hyper parameter that I use in my code to display the pictures because again I'm generating pictures as part of this",
    "start": "2287410",
    "end": "2294010"
  },
  {
    "text": "exercise so I want to be able to see these pictures as I go through my my development and this specifically and",
    "start": "2294010",
    "end": "2302020"
  },
  {
    "text": "one of the reasons I selected this example is because again in some cases you might be training a deep neural",
    "start": "2302020",
    "end": "2307750"
  },
  {
    "text": "network and at the end of the training of a deep neural network you might want to have a conversation with your team",
    "start": "2307750",
    "end": "2313480"
  },
  {
    "text": "which your management and all these things so you my advice we use to think about displaying some of your results",
    "start": "2313480",
    "end": "2319930"
  },
  {
    "text": "creating new metrics and I'll show you some of the code to basically measure",
    "start": "2319930",
    "end": "2325060"
  },
  {
    "text": "the amount of time it takes for you to fetch the data out the amount of time it takes for an iteration the amount of time it takes with a batch all of these",
    "start": "2325060",
    "end": "2331540"
  },
  {
    "text": "things you can point them out to Sage Maker and then basically it will be able to from where you stored it in an output",
    "start": "2331540",
    "end": "2338589"
  },
  {
    "text": "folder pick that up and put it back on s3 for you so that you could review that later on now the number of workers is",
    "start": "2338589",
    "end": "2345730"
  },
  {
    "text": "basically it's taken by the training data loader that Jeff spoke about and it's a way to hyper thread the mechanism",
    "start": "2345730",
    "end": "2352960"
  },
  {
    "text": "through which you can fetch the data from the data loader and I specify my batch size and the base job name now the",
    "start": "2352960",
    "end": "2359830"
  },
  {
    "text": "cool thing about running sage maker kicking off a job with sage maker when I",
    "start": "2359830",
    "end": "2365410"
  },
  {
    "text": "do that estimator fit is that I have this weight parameter now if I say",
    "start": "2365410",
    "end": "2372460"
  },
  {
    "text": "weight is equal to true what is going to happen is that my laptop is going to ask sage maker to start a job go to s3 and",
    "start": "2372460",
    "end": "2379839"
  },
  {
    "text": "fetch that data give it that infrastructure and get the job started",
    "start": "2379839",
    "end": "2385089"
  },
  {
    "text": "but because I said weight is equal to true the log matrix agent is going to go and fetch logs from all of these",
    "start": "2385089",
    "end": "2390970"
  },
  {
    "text": "machines that are contributing in the job and then present them back to me on my client and my client could have been",
    "start": "2390970",
    "end": "2396640"
  },
  {
    "text": "it could have been my Drupal or notebook as well so we're going to get this started well and then I'm going to get into",
    "start": "2396640",
    "end": "2403089"
  },
  {
    "text": "describing the actual PI torch code now the job is starting can you see can",
    "start": "2403089",
    "end": "2410170"
  },
  {
    "text": "you see correctly yeah so CH maker is starting a training job the other important thing that I wanted",
    "start": "2410170",
    "end": "2416349"
  },
  {
    "text": "to call out some folks ask me so what about my own library what if I wanted to",
    "start": "2416349",
    "end": "2421900"
  },
  {
    "text": "install tangible in this specific case for example I'm using tensor board to present the metrics the custom metrics",
    "start": "2421900",
    "end": "2428170"
  },
  {
    "text": "that have generated as well as some of the images that I'm generating on the fly because I want to visualize those in",
    "start": "2428170",
    "end": "2434380"
  },
  {
    "text": "fake images that were created through time and so you can have these requirements this text file basically",
    "start": "2434380",
    "end": "2441730"
  },
  {
    "text": "part of your source directory in this case in my source directory I have these requirements or text file and in your",
    "start": "2441730",
    "end": "2448090"
  },
  {
    "text": "requirement or text file whatever library you put in there as long as it's pip installable sage maker will pick",
    "start": "2448090",
    "end": "2454180"
  },
  {
    "text": "that up and install it for you so this is very powerful in a sense that you can start a job with PI torch and sage maker",
    "start": "2454180",
    "end": "2460690"
  },
  {
    "text": "but if you have dependencies and extra libraries like an NLP library that you want to use or like like tend to board",
    "start": "2460690",
    "end": "2468430"
  },
  {
    "text": "or like anything else that you want to use that we don't provide by default just by putting that in the requirements",
    "start": "2468430",
    "end": "2474820"
  },
  {
    "text": "the text file station maker will be able to find that requirement the text file take the libraries install the libraries",
    "start": "2474820",
    "end": "2480730"
  },
  {
    "text": "in every container before it starts trading your job so again that's the relationship between you sage maker and",
    "start": "2480730",
    "end": "2486580"
  },
  {
    "text": "and the framework so while it's starting the instances I'm going to walk you",
    "start": "2486580",
    "end": "2491740"
  },
  {
    "text": "through the actual Gantt code for pi torch now we worked through the launch",
    "start": "2491740",
    "end": "2496869"
  },
  {
    "text": "code which is basically the execution code for for the main function the structure of my the structure of my",
    "start": "2496869",
    "end": "2505780"
  },
  {
    "text": "source directory is like this so I have my main function which basically runs the the training loop but before I get",
    "start": "2505780",
    "end": "2513130"
  },
  {
    "text": "there I want to start by the actual neural network function so I keep my neural network definitions in one file",
    "start": "2513130",
    "end": "2519099"
  },
  {
    "text": "and then I keep my main function in another file now the neural network definitions file is very straightforward",
    "start": "2519099",
    "end": "2525460"
  },
  {
    "text": "that's exactly what Jeff showed you earlier PI torch makes it very easy for",
    "start": "2525460",
    "end": "2531160"
  },
  {
    "text": "you to describe your neural network using the simple API is that that that",
    "start": "2531160",
    "end": "2536740"
  },
  {
    "text": "Jeff introduced you to now to create my generator I use a tenon",
    "start": "2536740",
    "end": "2542560"
  },
  {
    "text": "module class that not Jeff told told us about which basically makes it possible",
    "start": "2542560",
    "end": "2549070"
  },
  {
    "text": "for you to declare your neural network in it in a decorative way now it",
    "start": "2549070",
    "end": "2554230"
  },
  {
    "text": "provides simple api's to to create linear layers to create convolutional layers to create LCM layers and in a",
    "start": "2554230",
    "end": "2561520"
  },
  {
    "text": "parameterised way so that you don't have to do a lot of writing code now when you do create these layers with an end and a",
    "start": "2561520",
    "end": "2568150"
  },
  {
    "text": "module module it does other things in the backend other things like identifying what kind of parameters are",
    "start": "2568150",
    "end": "2574390"
  },
  {
    "text": "involved in those layers identifying whether these parameters need their gradients computer identifying whether",
    "start": "2574390",
    "end": "2580660"
  },
  {
    "text": "these weights are contributing to the last function that you want to optimize and then keeping track of these",
    "start": "2580660",
    "end": "2586390"
  },
  {
    "text": "gradients so that when you do your back propagation step it will be able to",
    "start": "2586390",
    "end": "2591550"
  },
  {
    "text": "update these gradients on your behalf so all of that is similar to the end user and PI torch makes it a lot easier for",
    "start": "2591550",
    "end": "2597550"
  },
  {
    "text": "you to just decoratively declare your neural network it also has this sequential class that basically",
    "start": "2597550",
    "end": "2605170"
  },
  {
    "start": "2603000",
    "end": "2703000"
  },
  {
    "text": "makes it possible for you to stack your decorations of a neural network in this case for my generator because the",
    "start": "2605170",
    "end": "2611470"
  },
  {
    "text": "generator starts with a vector of basically noise a hundred dimensional vector of nothing random noise and from",
    "start": "2611470",
    "end": "2619180"
  },
  {
    "text": "there it tries to create an image something in the shape of an image so it does transpose convolution in two",
    "start": "2619180",
    "end": "2626500"
  },
  {
    "text": "dimension two basics to go from a one-dimensional vector back to the shape",
    "start": "2626500",
    "end": "2631600"
  },
  {
    "text": "of an image and for that it uses the number of channels that you provide because we're using color images and and",
    "start": "2631600",
    "end": "2638140"
  },
  {
    "text": "and other parameters so that's what's going on here the code is available on github so you can you can read the",
    "start": "2638140",
    "end": "2643510"
  },
  {
    "text": "details and these part of the of the initialization class of the generator is",
    "start": "2643510",
    "end": "2651570"
  },
  {
    "text": "concerned with instantiating the the weight of that generator again there are",
    "start": "2651570",
    "end": "2656710"
  },
  {
    "text": "helpful libraries for you to either randomly instantiate the weights of that",
    "start": "2656710",
    "end": "2662170"
  },
  {
    "text": "neural network of that part of a neural network or instantiate the weights with a normal distribution centered at zero",
    "start": "2662170",
    "end": "2669220"
  },
  {
    "text": "in standard deviation of 0.2 for 0.02 for example right okay so the other important thing",
    "start": "2669220",
    "end": "2676820"
  },
  {
    "text": "when you're creating a newer network when you're declaring a newer network with with PI torch is the forward",
    "start": "2676820",
    "end": "2683510"
  },
  {
    "text": "function now the fourth function is designed to pass your data through the the through the neural network",
    "start": "2683510",
    "end": "2690829"
  },
  {
    "text": "architecture that you've created now this is important okay my trading job is actually starting already by the way so",
    "start": "2690829",
    "end": "2697280"
  },
  {
    "text": "this is going on I'll walk you through the logs in a minute so the fourth function is important in",
    "start": "2697280",
    "end": "2704869"
  },
  {
    "start": "2703000",
    "end": "2753000"
  },
  {
    "text": "the sense that it's what takes your your actual data and passes it through the",
    "start": "2704869",
    "end": "2709940"
  },
  {
    "text": "neural network now you might observe here that there is no backward function that you have to create the backward",
    "start": "2709940",
    "end": "2715670"
  },
  {
    "text": "function is responsible for after the data is passed through the neural network and then it gets to the end and",
    "start": "2715670",
    "end": "2721250"
  },
  {
    "text": "it's it's basically evaluated by the last function then you need to essentially penalize all the weights in",
    "start": "2721250",
    "end": "2727790"
  },
  {
    "text": "the neural network for their contribution on the on the last function so for that you use back propagation",
    "start": "2727790",
    "end": "2733280"
  },
  {
    "text": "which applies the chain rule all the way up from the last function back to every",
    "start": "2733280",
    "end": "2738650"
  },
  {
    "text": "single weight that contributed in that execution and so that back propagation is a lot of differential equations that",
    "start": "2738650",
    "end": "2744829"
  },
  {
    "text": "you typically have to do yourself you have to track all the weights and sum your networks can get very very very big",
    "start": "2744829",
    "end": "2750200"
  },
  {
    "text": "big all the way up until billions of parameters so PI torch seamlessly keep",
    "start": "2750200",
    "end": "2756290"
  },
  {
    "text": "these parameters and this tract relationship between all the weights that are contributing to the outcome and",
    "start": "2756290",
    "end": "2762020"
  },
  {
    "text": "when you when you use the backward function in your in in in pi torch it",
    "start": "2762020",
    "end": "2767869"
  },
  {
    "text": "does back propagation and try to wait for you automatically so backward for the backward function is provided by the",
    "start": "2767869",
    "end": "2773480"
  },
  {
    "text": "autograph package and pi towards you don't have to implement it yourself so",
    "start": "2773480",
    "end": "2778520"
  },
  {
    "text": "we've done the same for the discriminator which basically does the opposite of the generator the generator",
    "start": "2778520",
    "end": "2783560"
  },
  {
    "text": "does transport convolution to create an image the discriminator goat does normal",
    "start": "2783560",
    "end": "2788900"
  },
  {
    "text": "convolution to identify the objects in the image and classify that at the end with a sigmoid activation function which",
    "start": "2788900",
    "end": "2795859"
  },
  {
    "text": "is essentially a binary a binary logic function that says well if it computes",
    "start": "2795859",
    "end": "2804560"
  },
  {
    "text": "the probability between 0 and 1 that that says how much it believes that that image is real or fake right so this if",
    "start": "2804560",
    "end": "2812150"
  },
  {
    "text": "you're familiar with object detection and object classifications it's pretty much the same thing that's what a discriminator is doing and you could",
    "start": "2812150",
    "end": "2818569"
  },
  {
    "text": "also initialize that here and it has a forward function that's pretty much it so this is a structure of neural network",
    "start": "2818569",
    "end": "2824599"
  },
  {
    "text": "that does something as complex as as generator generative atmosphere networks",
    "start": "2824599",
    "end": "2830930"
  },
  {
    "text": "now the other thing that you that you have to do now is your main function so",
    "start": "2830930",
    "end": "2836029"
  },
  {
    "start": "2831000",
    "end": "2992000"
  },
  {
    "text": "you have declared your neural network you need now to use it to fetch the data to pass the data through your model to",
    "start": "2836029",
    "end": "2844099"
  },
  {
    "text": "train your mini-batches and to do everything else that you need to do now specifically the point I want to hit",
    "start": "2844099",
    "end": "2849619"
  },
  {
    "text": "here is the operational aspect of training neural network or training",
    "start": "2849619",
    "end": "2855319"
  },
  {
    "text": "models I spoke to you earlier about using tension board to log metrics now",
    "start": "2855319",
    "end": "2860569"
  },
  {
    "text": "besides importing all the other PI torch libraries it's very important - here we",
    "start": "2860569",
    "end": "2868760"
  },
  {
    "text": "go okay so this stencil board X library makes it possible for you to use 10 to",
    "start": "2868760",
    "end": "2875270"
  },
  {
    "text": "ward with my torch all right it was part of my requirements or text file installable so you would be familiar with everything",
    "start": "2875270",
    "end": "2881990"
  },
  {
    "text": "pi thoughts related up there because it's common already but I installed tensor board X to be able to write logs",
    "start": "2881990",
    "end": "2888829"
  },
  {
    "text": "of any kind that I want to tend to board during my execution so that's what I do",
    "start": "2888829",
    "end": "2893869"
  },
  {
    "text": "here I important about X it gives me access to this summary writer and I have",
    "start": "2893869",
    "end": "2898910"
  },
  {
    "text": "this tangible log directory that I put that I pass through summary writer to create a writer that I will use to write",
    "start": "2898910",
    "end": "2905779"
  },
  {
    "text": "images logs and everything else now the interesting thing that I want to call out here as it relates to sage make a",
    "start": "2905779",
    "end": "2911900"
  },
  {
    "text": "remember when I told you that sage maker knows where to put things for you you know you need to know what to put things",
    "start": "2911900",
    "end": "2917119"
  },
  {
    "text": "for say shoe maker this is one of these examples a sister SDK to the sage maker",
    "start": "2917119",
    "end": "2922670"
  },
  {
    "text": "SDK is called decision maker containers if you don't have it installed install it what is a shoe maker containers does",
    "start": "2922670",
    "end": "2929390"
  },
  {
    "text": "is it provides you with a lot of environment variables that are already available in Sage Maker one of these",
    "start": "2929390",
    "end": "2936500"
  },
  {
    "text": "environment variables is the output data there the output data there is essentially the",
    "start": "2936500",
    "end": "2942720"
  },
  {
    "text": "environment variable for where sage maker is expecting you to put some of your output that is going to fetch and",
    "start": "2942720",
    "end": "2949799"
  },
  {
    "text": "go prêt up put on on s3 on your behalf so that's what I've done here I'm",
    "start": "2949799",
    "end": "2954869"
  },
  {
    "text": "creating my summary writer and I'm pointing that to these output data directory and I'm naming my folder runs",
    "start": "2954869",
    "end": "2961440"
  },
  {
    "text": "and that's where I'm going to have my tensor board metrics now the rest of it",
    "start": "2961440",
    "end": "2966569"
  },
  {
    "text": "is well this is a helper function to load the to load the generator and",
    "start": "2966569",
    "end": "2972299"
  },
  {
    "text": "instantiate instantiate that to load the discriminator and instantiate that as well and there starts my training",
    "start": "2972299",
    "end": "2979710"
  },
  {
    "text": "function now I commented the training function so that you could read the code and github and get to the details we",
    "start": "2979710",
    "end": "2986010"
  },
  {
    "text": "don't have all the time to go through all of that but importing for the important point to to call us are how do",
    "start": "2986010",
    "end": "2992609"
  },
  {
    "start": "2992000",
    "end": "3223000"
  },
  {
    "text": "how do I know because or how do I create my scripts in such a way that I can use",
    "start": "2992609",
    "end": "2998309"
  },
  {
    "text": "it regardless of whether I'm using a CPU or GPU regardless of whether I have",
    "start": "2998309",
    "end": "3003770"
  },
  {
    "text": "multiple GPUs or not so I want to have my code to be agnostic to all of these",
    "start": "3003770",
    "end": "3008809"
  },
  {
    "text": "possible changes in infrastructure whenever I want to kick off a stage maker training job and that's basically",
    "start": "3008809",
    "end": "3015410"
  },
  {
    "text": "what is happening here so I'm checking part of the arguments that sage maker",
    "start": "3015410",
    "end": "3021650"
  },
  {
    "text": "provides to me are the number of hosts that I have again I don't need to figure that out because if I kick off a job",
    "start": "3021650",
    "end": "3027619"
  },
  {
    "text": "with two or three or four hosts sage maker is going to pass that to me as part of the argument to my main function",
    "start": "3027619",
    "end": "3033230"
  },
  {
    "text": "training job so I can use that information and say hey if the number of",
    "start": "3033230",
    "end": "3039319"
  },
  {
    "text": "the hosts that you've created for me is more than one and there is this",
    "start": "3039319",
    "end": "3045589"
  },
  {
    "text": "parameter for distributed back-end and it's not known well I believe I want to",
    "start": "3045589",
    "end": "3050990"
  },
  {
    "text": "dispute a training job and so if I have a disability training job do all of these things so this is if you're a",
    "start": "3050990",
    "end": "3057440"
  },
  {
    "text": "Python developer you probably familiar with this - this will be the training job in PI towards you you essentially",
    "start": "3057440",
    "end": "3063410"
  },
  {
    "text": "need to have a view of your world or your world sighs machines have different ranks within that world size and that's",
    "start": "3063410",
    "end": "3070039"
  },
  {
    "text": "how they can distribute the work among themselves distribute the data the logs and all this",
    "start": "3070039",
    "end": "3075430"
  },
  {
    "text": "so and that's what I'm doing here so I'm getting I'm grabbing the environment variables I'm grabbing the host rank of",
    "start": "3075430",
    "end": "3082490"
  },
  {
    "text": "my machine and I'm instantiating my my distributed Python she submitted from",
    "start": "3082490",
    "end": "3088520"
  },
  {
    "text": "class to with that back-end that was that was provided by me and with the",
    "start": "3088520",
    "end": "3094100"
  },
  {
    "text": "host Frank that is that that this machine has now this specific machine",
    "start": "3094100",
    "end": "3099470"
  },
  {
    "text": "because you have a copy of the script on multiple machines every single one of them has a rank in the in the world of",
    "start": "3099470",
    "end": "3107060"
  },
  {
    "text": "machines that you have and what's H Maker does is if it starts three or four or five machines it would basically give",
    "start": "3107060",
    "end": "3113720"
  },
  {
    "text": "them different ranks and if you read the rank from the environment variable then you will be each machine even though the",
    "start": "3113720",
    "end": "3120290"
  },
  {
    "text": "script is the same in all the machine each machine will be instantiated with its own host rank I hope it makes sense",
    "start": "3120290",
    "end": "3127970"
  },
  {
    "text": "so far if it makes sense say yes all right perfect I'm not talking to",
    "start": "3127970",
    "end": "3133940"
  },
  {
    "text": "myself okay so so then the next thing you know you've you've given stats you you you",
    "start": "3133940",
    "end": "3140750"
  },
  {
    "text": "loaded your model you've found out agnostic Allah if you are code is if",
    "start": "3140750",
    "end": "3147530"
  },
  {
    "text": "your workload is distributed or not if GPUs are supposed to be used or not and",
    "start": "3147530",
    "end": "3153370"
  },
  {
    "text": "the next thing to actually know this this is how you find out whatever you have GPUs are not so if pythons provide",
    "start": "3153370",
    "end": "3160130"
  },
  {
    "text": "this Porsche CUDA is available as as a feature and this torch CUDA is available",
    "start": "3160130",
    "end": "3166250"
  },
  {
    "text": "essentially gives you an output of true or false if you have GPUs available or not and so I can leverage that and",
    "start": "3166250",
    "end": "3172100"
  },
  {
    "text": "create this device variable that to which I'm going to push all my 10",
    "start": "3172100",
    "end": "3177500"
  },
  {
    "text": "servers and all my newer networks and everything else if you use fighters before before Pike just 1.0 to pass your",
    "start": "3177500",
    "end": "3185480"
  },
  {
    "text": "10 source to two GPUs was it was challenging so pathos 1.0 makes it a lot",
    "start": "3185480",
    "end": "3192110"
  },
  {
    "text": "easier to point all the tensors all the network structures and everything else to a specific device and you only set",
    "start": "3192110",
    "end": "3199730"
  },
  {
    "text": "that up once and you can you can use that for going on for it now the next thing I need to do is to load my data",
    "start": "3199730",
    "end": "3205340"
  },
  {
    "text": "and I have a helper function to send create my data loader you can read that in the utilities file and I load my",
    "start": "3205340",
    "end": "3213230"
  },
  {
    "text": "model which returns a generator and a discriminator which is what we are returning here in the load model",
    "start": "3213230",
    "end": "3221000"
  },
  {
    "text": "function and my torch also has",
    "start": "3221000",
    "end": "3227180"
  },
  {
    "start": "3223000",
    "end": "3333000"
  },
  {
    "text": "distortion cuda device count so Turku device count is essentially returning",
    "start": "3227180",
    "end": "3232550"
  },
  {
    "text": "the number of GPUs that exists on that machine so again you can use this",
    "start": "3232550",
    "end": "3237920"
  },
  {
    "text": "function to find out if you have more than one GPUs on your machine and if you",
    "start": "3237920",
    "end": "3243500"
  },
  {
    "text": "have more than one GPUs on the machine then you can use all of these GPUs that you have on the machine so yeah if you",
    "start": "3243500",
    "end": "3251330"
  },
  {
    "text": "have more than one GPUs on the machine patos provide the nn module has this data parallel class which is a wrapper",
    "start": "3251330",
    "end": "3257960"
  },
  {
    "text": "around your normal and in module class but now that it knows that you have",
    "start": "3257960",
    "end": "3263510"
  },
  {
    "text": "multiple GPUs in the machine it's going to paralyze the data to all these GPUs again something you don't have to worry",
    "start": "3263510",
    "end": "3269270"
  },
  {
    "text": "about the only thing you have to do is find out if you have more than one GPUs and push that to all these GPUs using",
    "start": "3269270",
    "end": "3275870"
  },
  {
    "text": "data parallel and the way you push all of these to the GPUs is by saying generator to device discriminator to",
    "start": "3275870",
    "end": "3282860"
  },
  {
    "text": "device and your device is true its GPU if you're using GPU CPU using CPU and",
    "start": "3282860",
    "end": "3288530"
  },
  {
    "text": "you find that agnostic lis using this function again the beauty of this is whether you're on CPU and GPU this will",
    "start": "3288530",
    "end": "3295490"
  },
  {
    "text": "work agnostic way the next the next thing to do is to create your your loss",
    "start": "3295490",
    "end": "3301400"
  },
  {
    "text": "function and pythons provide again with Eden module the multiple loss function",
    "start": "3301400",
    "end": "3307550"
  },
  {
    "text": "in the case of the of the generative adversarial Network we're using the brand new banner across the entropy loss",
    "start": "3307550",
    "end": "3313550"
  },
  {
    "text": "which is essentially computing a cross entropy across multiple valve different",
    "start": "3313550",
    "end": "3319520"
  },
  {
    "text": "values or different variables in this case we have two outputs that we care about fake are not fake so the BCE computes",
    "start": "3319520",
    "end": "3326840"
  },
  {
    "text": "the likelihood of something being fake or something not being faking gives you probability between 0 and 1 the next",
    "start": "3326840",
    "end": "3334460"
  },
  {
    "start": "3333000",
    "end": "3402000"
  },
  {
    "text": "thing is the optimizer and all of these I hope you can see how sequential programming with pi torch can be as",
    "start": "3334460",
    "end": "3340790"
  },
  {
    "text": "opposed to other frame work where you have to create a graph in something and then push that part or",
    "start": "3340790",
    "end": "3346250"
  },
  {
    "text": "makes it possible for you to in a sequential manner describe your new network your data loader and everything",
    "start": "3346250",
    "end": "3352760"
  },
  {
    "text": "step by step and the next thing you have to do here is instantiate an optimizer",
    "start": "3352760",
    "end": "3357980"
  },
  {
    "text": "and optimizer is also provided by the toss up team library and that mainly optimizers rmsprop and adam and all",
    "start": "3357980",
    "end": "3365420"
  },
  {
    "text": "these other guys now here we're using the atom optimizer I'm using an optimizer for each new piece of the",
    "start": "3365420",
    "end": "3372410"
  },
  {
    "text": "neural network the generator or the discriminator and the way it knows to work with that piece of a neural network",
    "start": "3372410",
    "end": "3377869"
  },
  {
    "text": "is because I'm passing the discriminator that parameters to the discriminator optimizer and the generator that",
    "start": "3377869",
    "end": "3384560"
  },
  {
    "text": "parameters to the generator optimizer now fast-forward there's some helper",
    "start": "3384560",
    "end": "3389630"
  },
  {
    "text": "libraries here to print the logs to average load the the average logs the average meter the average time it took",
    "start": "3389630",
    "end": "3395810"
  },
  {
    "text": "me to load the data to run through a batch and all these other things now the",
    "start": "3395810",
    "end": "3403070"
  },
  {
    "start": "3402000",
    "end": "3458000"
  },
  {
    "text": "other important thing here is a training loop the training loop is where you're actually training your data where you're",
    "start": "3403070",
    "end": "3408619"
  },
  {
    "text": "actually training your model and so with my training loop I'm essentially tracking the time it takes me to to",
    "start": "3408619",
    "end": "3416359"
  },
  {
    "text": "update I'm sorry tracking the time it takes me to load the data I can also",
    "start": "3416359",
    "end": "3421599"
  },
  {
    "text": "pass the real faces which is say a tensor with the actual real images to",
    "start": "3421599",
    "end": "3426680"
  },
  {
    "text": "the GPU I have to do that for every data set that I have because I'm using the GPU I said the the batch size to the",
    "start": "3426680",
    "end": "3433609"
  },
  {
    "text": "data is loaded in batches so I want to pick up the batch size and everything else that follows is to essentially pass",
    "start": "3433609",
    "end": "3441260"
  },
  {
    "text": "the data through the neural network do the forward propagation compute the loss",
    "start": "3441260",
    "end": "3446510"
  },
  {
    "text": "and then do the backward propagation and iterate through that over and over so you can read the the details there I",
    "start": "3446510",
    "end": "3452180"
  },
  {
    "text": "commented aim from the logic about the last function here so that you can read that later and scrolling down to the",
    "start": "3452180",
    "end": "3460670"
  },
  {
    "start": "3458000",
    "end": "3600000"
  },
  {
    "text": "next part that matters is writing the log so because I have that writer with",
    "start": "3460670",
    "end": "3468020"
  },
  {
    "text": "that writer that I created I can essentially write all these values that I care about and I encourage you to be",
    "start": "3468020",
    "end": "3474020"
  },
  {
    "text": "creative about what you want to right if you want to track anything you can put it here so I'm tracking average",
    "start": "3474020",
    "end": "3480890"
  },
  {
    "text": "time to load a batch average time to do this a number of other things now if my",
    "start": "3480890",
    "end": "3486350"
  },
  {
    "text": "display after if my if my display after parameter was set to 200 so after two",
    "start": "3486350",
    "end": "3493520"
  },
  {
    "text": "hundred iterations I want to see a new image that's essentially what I'm doing here so after two hundred iterations I",
    "start": "3493520",
    "end": "3499370"
  },
  {
    "text": "want to print the logs to to the to stand it out and when you print the",
    "start": "3499370",
    "end": "3504470"
  },
  {
    "text": "standardization make a pic setup and sends it to your logs and I also want to visualize some of these images and",
    "start": "3504470",
    "end": "3510890"
  },
  {
    "text": "that's what I use here with the vu chilled safe image and safe image and writer add image so save image will save",
    "start": "3510890",
    "end": "3516260"
  },
  {
    "text": "an image to a folder that I will that I upload for myself and right image it's going to write the images 210 to board",
    "start": "3516260",
    "end": "3523220"
  },
  {
    "text": "and that's pretty much it the rest of it is is to do some plotting and saving the",
    "start": "3523220",
    "end": "3529010"
  },
  {
    "text": "model which is pretty straightforward and I run the main function now let's look at the logs of running the main",
    "start": "3529010",
    "end": "3534170"
  },
  {
    "text": "function that we started earlier a Kotori earlier CH maker would install",
    "start": "3534170",
    "end": "3539870"
  },
  {
    "text": "the libraries on your behalf so that's what happened here it starts this",
    "start": "3539870",
    "end": "3547430"
  },
  {
    "text": "collecting tend to board decision maker finding tend to board in my requirements a text file and installing installing it",
    "start": "3547430",
    "end": "3553370"
  },
  {
    "text": "for me on different machines now it's kicking off the training job giving me",
    "start": "3553370",
    "end": "3559550"
  },
  {
    "text": "some of the parameters and I made it I",
    "start": "3559550",
    "end": "3564890"
  },
  {
    "text": "made it run for just two epochs so that we won't stare at the logs training for forever so and then it starts plotting I",
    "start": "3564890",
    "end": "3572510"
  },
  {
    "text": "mean it start reporting the logs and everything else that you probably familiar with if you train the new network before so that's pretty much the",
    "start": "3572510",
    "end": "3578360"
  },
  {
    "text": "experience there now going back to the console if I go back to stage maker training jobs I can",
    "start": "3578360",
    "end": "3583910"
  },
  {
    "text": "see the training job that we just executed this one and if I go to the details there's a shoe maker will give",
    "start": "3583910",
    "end": "3589790"
  },
  {
    "text": "me the metadata and will give me information about the output and if I go",
    "start": "3589790",
    "end": "3595130"
  },
  {
    "text": "to this output folder then it pushed my model there and it also pushed the",
    "start": "3595130",
    "end": "3600490"
  },
  {
    "text": "information all the information that I was that are stored in in those images",
    "start": "3600490",
    "end": "3606260"
  },
  {
    "text": "and everything else that is related the other interests thing that I wanted to show you is the logs that the log matrix has pushed to",
    "start": "3606260",
    "end": "3613670"
  },
  {
    "text": "to clash logs so here I can visualize GPU utilization CPU utilization I can",
    "start": "3613670",
    "end": "3619460"
  },
  {
    "text": "also the same logs in case I wanted to wait for the logs that were presenting to my presented to my laptop are also",
    "start": "3619460",
    "end": "3625640"
  },
  {
    "text": "sent to to Sage maker and these are the logs for multiple jobs that I've executed through time so forever you can",
    "start": "3625640",
    "end": "3631700"
  },
  {
    "text": "see your logs afterwards and tend to board all the metrics that are pushed to",
    "start": "3631700",
    "end": "3637490"
  },
  {
    "text": "tensile board are visible afterwards right so the average batch time that I was tracking the the loss for the",
    "start": "3637490",
    "end": "3644210"
  },
  {
    "text": "discriminator the loss for the generator all of these things are available for for you to visualize afterwards and the",
    "start": "3644210",
    "end": "3650630"
  },
  {
    "text": "images as well available so because I pushed the images after each iteration it's possible for me to visualize how",
    "start": "3650630",
    "end": "3657350"
  },
  {
    "text": "the network through time to generator through time has been trying to generate through yeah has been trying to generate",
    "start": "3657350",
    "end": "3664640"
  },
  {
    "text": "fake images like initially it's really really dirty and really random and as",
    "start": "3664640",
    "end": "3669860"
  },
  {
    "text": "you go forward it becomes clearer and clearer and I didn't wait enough for it to start generating images that look as",
    "start": "3669860",
    "end": "3675470"
  },
  {
    "text": "real as possible and then you can also plot that against the real images so that's that and the last thing before we",
    "start": "3675470",
    "end": "3682370"
  },
  {
    "text": "call it a day all the files that I was saving in the output data directory",
    "start": "3682370",
    "end": "3687410"
  },
  {
    "text": "after each epoch stage maker would fetch them up and then push them to the cloud storage so I've already downloaded that",
    "start": "3687410",
    "end": "3694580"
  },
  {
    "text": "from a previous execution so this is really good if you want to have a conversation with your team after these",
    "start": "3694580",
    "end": "3700700"
  },
  {
    "text": "are the image at epoch number 25 or whatever you can come and pick them up from here and you also have the real",
    "start": "3700700",
    "end": "3709220"
  },
  {
    "text": "know these are still the fake images and you also have the yeah",
    "start": "3709220",
    "end": "3714500"
  },
  {
    "text": "all of these fake images and you also have the the lost function that you can",
    "start": "3714500",
    "end": "3719960"
  },
  {
    "text": "plot after every epoch right and you can visualize that and have a conversation",
    "start": "3719960",
    "end": "3725420"
  },
  {
    "text": "around that afterwards the other interesting thing that's available there is a creator a Jif or",
    "start": "3725420",
    "end": "3733550"
  },
  {
    "text": "gif depending on how you pronounce that for for the loss of a generator and discriminator as part of the one of the",
    "start": "3733550",
    "end": "3739880"
  },
  {
    "text": "helper functions that's available there so again you can you and use that to do some plotting internally create some animation and",
    "start": "3739880",
    "end": "3747200"
  },
  {
    "text": "then after you push everything it's going to be available in this case you see the generator starts with a high",
    "start": "3747200",
    "end": "3752300"
  },
  {
    "text": "error but over time it's the error of generator starts going down and then if",
    "start": "3752300",
    "end": "3757400"
  },
  {
    "text": "I train for long enough you'll have seen the discriminated meeting the generator somewhere halfway through to a position",
    "start": "3757400",
    "end": "3763400"
  },
  {
    "text": "where to the equilibrium position that would indicate that the generator has gotten a lot better at generating images",
    "start": "3763400",
    "end": "3769550"
  },
  {
    "text": "and the discriminator as getting a lot worse at finding out whether these images are true or not and also created",
    "start": "3769550",
    "end": "3776869"
  },
  {
    "text": "an animation for for the results for you to be able to animate the epochs of everything through time now with that",
    "start": "3776869",
    "end": "3784460"
  },
  {
    "text": "I'm going to switch back to the slides and back to the the example code",
    "start": "3784460",
    "end": "3790069"
  },
  {
    "text": "hopefully you took it took a picture of that and thank you thanks again for your time",
    "start": "3790069",
    "end": "3795730"
  },
  {
    "text": "[Applause]",
    "start": "3795730",
    "end": "3798679"
  }
]
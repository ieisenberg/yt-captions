[
  {
    "text": "hi everyone i'm fabio nonato a principal",
    "start": "640",
    "end": "3280"
  },
  {
    "text": "solutions architect",
    "start": "3280",
    "end": "4480"
  },
  {
    "text": "at amazon web services in this video we",
    "start": "4480",
    "end": "7200"
  },
  {
    "text": "will explore how to leverage the new ec2",
    "start": "7200",
    "end": "9519"
  },
  {
    "text": "inf1 instances",
    "start": "9519",
    "end": "10719"
  },
  {
    "text": "based on the aws inferential chips to",
    "start": "10719",
    "end": "13040"
  },
  {
    "text": "run high performance",
    "start": "13040",
    "end": "14240"
  },
  {
    "text": "and cost effective machine learning",
    "start": "14240",
    "end": "15759"
  },
  {
    "text": "inference jobs through sagemaker neo",
    "start": "15759",
    "end": "18560"
  },
  {
    "text": "infund instances are based on aws",
    "start": "18560",
    "end": "20800"
  },
  {
    "text": "inferential chips",
    "start": "20800",
    "end": "21920"
  },
  {
    "text": "which are custom built by aws for",
    "start": "21920",
    "end": "23920"
  },
  {
    "text": "machine learning inference",
    "start": "23920",
    "end": "25519"
  },
  {
    "text": "the inferential chips are coupled with",
    "start": "25519",
    "end": "27439"
  },
  {
    "text": "the latest custom second generation",
    "start": "27439",
    "end": "29279"
  },
  {
    "text": "intel excusing scalable processors",
    "start": "29279",
    "end": "31519"
  },
  {
    "text": "and have up to 100 gigabits networking",
    "start": "31519",
    "end": "34000"
  },
  {
    "text": "to enable high throughput",
    "start": "34000",
    "end": "35280"
  },
  {
    "text": "inference this instances are based on",
    "start": "35280",
    "end": "37840"
  },
  {
    "text": "the aws nitro system",
    "start": "37840",
    "end": "39520"
  },
  {
    "text": "which is a combination of dedicated",
    "start": "39520",
    "end": "41120"
  },
  {
    "text": "hardware and lightweight hypervisor",
    "start": "41120",
    "end": "43040"
  },
  {
    "text": "that enables faster innovation and",
    "start": "43040",
    "end": "44879"
  },
  {
    "text": "enhanced security in amazon ec2",
    "start": "44879",
    "end": "47600"
  },
  {
    "text": "the ec2 info instances feature aws",
    "start": "47600",
    "end": "50239"
  },
  {
    "text": "neuron",
    "start": "50239",
    "end": "50960"
  },
  {
    "text": "an sdk that natively integrates with",
    "start": "50960",
    "end": "52960"
  },
  {
    "text": "popular machine learning frameworks such",
    "start": "52960",
    "end": "54559"
  },
  {
    "text": "as tensorflow",
    "start": "54559",
    "end": "55600"
  },
  {
    "text": "pytorch and mxnet and optimizes model",
    "start": "55600",
    "end": "58399"
  },
  {
    "text": "performance for the inferential chips",
    "start": "58399",
    "end": "60480"
  },
  {
    "text": "the neuron sdk is integrated into",
    "start": "60480",
    "end": "62559"
  },
  {
    "text": "sagemaker neo",
    "start": "62559",
    "end": "63760"
  },
  {
    "text": "to make it easy for developers to deploy",
    "start": "63760",
    "end": "65920"
  },
  {
    "text": "their ml models",
    "start": "65920",
    "end": "67119"
  },
  {
    "text": "to info one instances with this",
    "start": "67119",
    "end": "69600"
  },
  {
    "text": "combination",
    "start": "69600",
    "end": "70400"
  },
  {
    "text": "info instances provide high performance",
    "start": "70400",
    "end": "72560"
  },
  {
    "text": "and lower cost inference in the cloud",
    "start": "72560",
    "end": "74720"
  },
  {
    "text": "making it economically feasible to",
    "start": "74720",
    "end": "76400"
  },
  {
    "text": "deploy complex and large-scale machine",
    "start": "76400",
    "end": "78240"
  },
  {
    "text": "learning inference applications",
    "start": "78240",
    "end": "80000"
  },
  {
    "text": "such as image recognition speech",
    "start": "80000",
    "end": "81759"
  },
  {
    "text": "recognition natural language processing",
    "start": "81759",
    "end": "83840"
  },
  {
    "text": "and fraud detection with up to 16 aws",
    "start": "83840",
    "end": "87680"
  },
  {
    "text": "inferential chips",
    "start": "87680",
    "end": "88880"
  },
  {
    "text": "inf1 instances can scale in performance",
    "start": "88880",
    "end": "91200"
  },
  {
    "text": "to 2000 tara operations per second",
    "start": "91200",
    "end": "93840"
  },
  {
    "text": "and deliver extremely low latency for",
    "start": "93840",
    "end": "95920"
  },
  {
    "text": "real-time applications",
    "start": "95920",
    "end": "98400"
  },
  {
    "text": "the large on-chip memory of aws",
    "start": "98400",
    "end": "100560"
  },
  {
    "text": "inferentia",
    "start": "100560",
    "end": "101680"
  },
  {
    "text": "allows caching of machine learning",
    "start": "101680",
    "end": "103200"
  },
  {
    "text": "models directly on the chip",
    "start": "103200",
    "end": "104960"
  },
  {
    "text": "this eliminates the need to access",
    "start": "104960",
    "end": "106720"
  },
  {
    "text": "outside memory resources during",
    "start": "106720",
    "end": "108399"
  },
  {
    "text": "inference",
    "start": "108399",
    "end": "109200"
  },
  {
    "text": "enabling low latency without impacting",
    "start": "109200",
    "end": "111360"
  },
  {
    "text": "bandwidth",
    "start": "111360",
    "end": "113280"
  },
  {
    "text": "in today's example we will start by",
    "start": "113280",
    "end": "115439"
  },
  {
    "text": "setting up a sagemaker notebook",
    "start": "115439",
    "end": "117119"
  },
  {
    "text": "to train an image classification model",
    "start": "117119",
    "end": "118960"
  },
  {
    "text": "on eminence dataset using tensorflow",
    "start": "118960",
    "end": "121439"
  },
  {
    "text": "then we will compile it using amazon",
    "start": "121439",
    "end": "123600"
  },
  {
    "text": "stagemaker neo",
    "start": "123600",
    "end": "124799"
  },
  {
    "text": "and apply the model on a sagemaker",
    "start": "124799",
    "end": "126640"
  },
  {
    "text": "endpoint running on an info one instance",
    "start": "126640",
    "end": "129360"
  },
  {
    "text": "and use the new deep learning runtime to",
    "start": "129360",
    "end": "131680"
  },
  {
    "text": "make inferences in real time with low",
    "start": "131680",
    "end": "133840"
  },
  {
    "text": "latency",
    "start": "133840",
    "end": "134800"
  },
  {
    "text": "so let's get started",
    "start": "134800",
    "end": "137840"
  },
  {
    "text": "first from the management console we can",
    "start": "137840",
    "end": "140239"
  },
  {
    "text": "navigate to sagemaker",
    "start": "140239",
    "end": "143840"
  },
  {
    "text": "then we'll navigate to notebook",
    "start": "149120",
    "end": "150879"
  },
  {
    "text": "instances on the left hand side options",
    "start": "150879",
    "end": "153760"
  },
  {
    "text": "and create a new notebook",
    "start": "153760",
    "end": "157840"
  },
  {
    "text": "here we can give the notebook a name",
    "start": "158720",
    "end": "161800"
  },
  {
    "text": "info1-test",
    "start": "161800",
    "end": "164319"
  },
  {
    "text": "and pick an instance type a little bit",
    "start": "164319",
    "end": "166160"
  },
  {
    "text": "bigger than the default one",
    "start": "166160",
    "end": "170720"
  },
  {
    "text": "we can leave most of the default options",
    "start": "170720",
    "end": "172560"
  },
  {
    "text": "as is",
    "start": "172560",
    "end": "174319"
  },
  {
    "text": "but we will add a git repository",
    "start": "174319",
    "end": "178319"
  },
  {
    "text": "we can clone a public git repository",
    "start": "178319",
    "end": "180400"
  },
  {
    "text": "with the code from our project",
    "start": "180400",
    "end": "182560"
  },
  {
    "text": "here we're going to use the aws labs",
    "start": "182560",
    "end": "185920"
  },
  {
    "text": "sagemaker examples the url",
    "start": "185920",
    "end": "189680"
  },
  {
    "text": "is here on a qr code for you to copy",
    "start": "189680",
    "end": "192879"
  },
  {
    "text": "so we can just clone with https",
    "start": "192879",
    "end": "196640"
  },
  {
    "text": "and add the https url to the git",
    "start": "196640",
    "end": "199440"
  },
  {
    "text": "repository url field",
    "start": "199440",
    "end": "202640"
  },
  {
    "text": "we hit create new notebook instance",
    "start": "202640",
    "end": "206159"
  },
  {
    "text": "and that's it now sagemaker is",
    "start": "206159",
    "end": "208239"
  },
  {
    "text": "provisioning a new notebook instance",
    "start": "208239",
    "end": "210319"
  },
  {
    "text": "on an 5 x large ec2",
    "start": "210319",
    "end": "213840"
  },
  {
    "text": "this will take approximately 3 minutes",
    "start": "213840",
    "end": "216159"
  },
  {
    "text": "so hit pause on the recording and come",
    "start": "216159",
    "end": "217920"
  },
  {
    "text": "back when it's provisioned",
    "start": "217920",
    "end": "221040"
  },
  {
    "text": "now with the instance up we have a",
    "start": "221200",
    "end": "222959"
  },
  {
    "text": "couple of options",
    "start": "222959",
    "end": "224799"
  },
  {
    "text": "we are going to open a jupiter lab",
    "start": "224799",
    "end": "228000"
  },
  {
    "text": "which will get us a direct environment",
    "start": "228000",
    "end": "230720"
  },
  {
    "text": "in the machine",
    "start": "230720",
    "end": "232400"
  },
  {
    "text": "just provisioned the git repository that",
    "start": "232400",
    "end": "235680"
  },
  {
    "text": "we cloned",
    "start": "235680",
    "end": "237200"
  },
  {
    "text": "will be available directly at the root",
    "start": "237200",
    "end": "239360"
  },
  {
    "text": "of our working directory",
    "start": "239360",
    "end": "241280"
  },
  {
    "text": "here amazon stage maker examples",
    "start": "241280",
    "end": "245200"
  },
  {
    "text": "we can navigate to our jupiter notebook",
    "start": "245280",
    "end": "249760"
  },
  {
    "text": "so we can start our model training job",
    "start": "250319",
    "end": "254319"
  },
  {
    "text": "this notebook is based on the",
    "start": "254319",
    "end": "255680"
  },
  {
    "text": "distributed tensorflow training with",
    "start": "255680",
    "end": "257359"
  },
  {
    "text": "sagemaker example and it contains all",
    "start": "257359",
    "end": "259199"
  },
  {
    "text": "the steps we need to create a new model",
    "start": "259199",
    "end": "261359"
  },
  {
    "text": "and persist it",
    "start": "261359",
    "end": "262400"
  },
  {
    "text": "on an aws simple storage service s3 as",
    "start": "262400",
    "end": "265520"
  },
  {
    "text": "an object",
    "start": "265520",
    "end": "266320"
  },
  {
    "text": "that we can refer later to and deploy to",
    "start": "266320",
    "end": "268720"
  },
  {
    "text": "the info on type instance",
    "start": "268720",
    "end": "270880"
  },
  {
    "text": "let's start by setting up the",
    "start": "270880",
    "end": "272080"
  },
  {
    "text": "environment",
    "start": "272080",
    "end": "274560"
  },
  {
    "text": "this will create a sagemaker session",
    "start": "274560",
    "end": "276560"
  },
  {
    "text": "that we're going to use throughout the",
    "start": "276560",
    "end": "278080"
  },
  {
    "text": "whole notebook",
    "start": "278080",
    "end": "283199"
  },
  {
    "text": "as we're setting up the environment we",
    "start": "283199",
    "end": "285520"
  },
  {
    "text": "can notice that there are a few utility",
    "start": "285520",
    "end": "287280"
  },
  {
    "text": "functions that will help us with",
    "start": "287280",
    "end": "288479"
  },
  {
    "text": "downloading the mnist dataset",
    "start": "288479",
    "end": "290960"
  },
  {
    "text": "and converting it to tf record type",
    "start": "290960",
    "end": "293199"
  },
  {
    "text": "which is the data format we will use",
    "start": "293199",
    "end": "294880"
  },
  {
    "text": "during your sagemaker training job",
    "start": "294880",
    "end": "298560"
  },
  {
    "text": "this data will be placed on a data",
    "start": "306800",
    "end": "308400"
  },
  {
    "text": "folder right next to our notebook",
    "start": "308400",
    "end": "310960"
  },
  {
    "text": "by the convert to method on the utils",
    "start": "310960",
    "end": "315440"
  },
  {
    "text": "module",
    "start": "322840",
    "end": "324720"
  },
  {
    "text": "we can now reference this data and",
    "start": "324720",
    "end": "326639"
  },
  {
    "text": "upload it to our training session",
    "start": "326639",
    "end": "328720"
  },
  {
    "text": "using the sagemaker session upload data",
    "start": "328720",
    "end": "331120"
  },
  {
    "text": "function",
    "start": "331120",
    "end": "333520"
  },
  {
    "text": "our next step is to construct a script",
    "start": "336240",
    "end": "338400"
  },
  {
    "text": "to run the distributed training",
    "start": "338400",
    "end": "340000"
  },
  {
    "text": "using the sagemaker test and flow api",
    "start": "340000",
    "end": "343600"
  },
  {
    "text": "luckily we can use these implementation",
    "start": "343600",
    "end": "345600"
  },
  {
    "text": "of a convolutional neural network",
    "start": "345600",
    "end": "347440"
  },
  {
    "text": "available in the mns.pi module",
    "start": "347440",
    "end": "352320"
  },
  {
    "text": "this implementation is an adaptation of",
    "start": "352320",
    "end": "354160"
  },
  {
    "text": "the tensorflow mnist example and",
    "start": "354160",
    "end": "356000"
  },
  {
    "text": "provides",
    "start": "356000",
    "end": "356800"
  },
  {
    "text": "a model function method used for",
    "start": "356800",
    "end": "358880"
  },
  {
    "text": "training evaluation",
    "start": "358880",
    "end": "360560"
  },
  {
    "text": "and inference",
    "start": "360560",
    "end": "363360"
  },
  {
    "text": "at the end of the script we're going to",
    "start": "364639",
    "end": "366160"
  },
  {
    "text": "see a new process",
    "start": "366160",
    "end": "367759"
  },
  {
    "text": "and neopos process methods these methods",
    "start": "367759",
    "end": "371440"
  },
  {
    "text": "will interface with the compile model",
    "start": "371440",
    "end": "373280"
  },
  {
    "text": "and process the incoming requests and",
    "start": "373280",
    "end": "375199"
  },
  {
    "text": "outgoing inference results into the",
    "start": "375199",
    "end": "376880"
  },
  {
    "text": "correct format",
    "start": "376880",
    "end": "380080"
  },
  {
    "text": "to create our training job we will use a",
    "start": "380080",
    "end": "382479"
  },
  {
    "text": "sagemaker tensorflow estimator method",
    "start": "382479",
    "end": "385039"
  },
  {
    "text": "which takes as arguments the entry point",
    "start": "385039",
    "end": "386880"
  },
  {
    "text": "script image stopped by",
    "start": "386880",
    "end": "388560"
  },
  {
    "text": "the session role and training parameters",
    "start": "388560",
    "end": "390960"
  },
  {
    "text": "including the number of steps",
    "start": "390960",
    "end": "392800"
  },
  {
    "text": "the type of instance and the instance",
    "start": "392800",
    "end": "394639"
  },
  {
    "text": "count we will be using two",
    "start": "394639",
    "end": "396880"
  },
  {
    "text": "ml65x large instances for training",
    "start": "396880",
    "end": "401280"
  },
  {
    "text": "using the fit method we kick off the",
    "start": "401520",
    "end": "403919"
  },
  {
    "text": "training job and sagemaker will take",
    "start": "403919",
    "end": "405759"
  },
  {
    "text": "care of provisioning the instances",
    "start": "405759",
    "end": "408319"
  },
  {
    "text": "the log of each instance will be printed",
    "start": "408319",
    "end": "410400"
  },
  {
    "text": "on screen as training progresses",
    "start": "410400",
    "end": "412240"
  },
  {
    "text": "and in the end the training job will",
    "start": "412240",
    "end": "414160"
  },
  {
    "text": "generate a safe model",
    "start": "414160",
    "end": "415440"
  },
  {
    "text": "for compilation this training job will",
    "start": "415440",
    "end": "418319"
  },
  {
    "text": "take approximately 7 minutes to complete",
    "start": "418319",
    "end": "420880"
  },
  {
    "text": "so let's skip ahead until the point we",
    "start": "420880",
    "end": "422800"
  },
  {
    "text": "have it all completed",
    "start": "422800",
    "end": "425680"
  },
  {
    "text": "as we scroll through the logs we can see",
    "start": "425759",
    "end": "427919"
  },
  {
    "text": "the two training workers",
    "start": "427919",
    "end": "429759"
  },
  {
    "text": "the model evaluation and the number of",
    "start": "429759",
    "end": "432479"
  },
  {
    "text": "training steps",
    "start": "432479",
    "end": "437680"
  },
  {
    "text": "the last piece of information in this",
    "start": "437680",
    "end": "439280"
  },
  {
    "text": "log is the training time",
    "start": "439280",
    "end": "441840"
  },
  {
    "text": "which is just above seven minutes",
    "start": "441840",
    "end": "445919"
  },
  {
    "text": "now we're ready to deploy our model in",
    "start": "445919",
    "end": "448639"
  },
  {
    "text": "an if1",
    "start": "448639",
    "end": "449360"
  },
  {
    "text": "instance we start the compilation by",
    "start": "449360",
    "end": "452240"
  },
  {
    "text": "retrieving the output path",
    "start": "452240",
    "end": "453680"
  },
  {
    "text": "of the training job so we can reuse it",
    "start": "453680",
    "end": "456319"
  },
  {
    "text": "as an argument for the compile model",
    "start": "456319",
    "end": "458080"
  },
  {
    "text": "method",
    "start": "458080",
    "end": "459039"
  },
  {
    "text": "this sagemaker new method will optimize",
    "start": "459039",
    "end": "461680"
  },
  {
    "text": "our model",
    "start": "461680",
    "end": "462240"
  },
  {
    "text": "for our desired deployment target",
    "start": "462240",
    "end": "465440"
  },
  {
    "text": "we are targeting the ml underscore inf1",
    "start": "465440",
    "end": "468240"
  },
  {
    "text": "instance family for deployment",
    "start": "468240",
    "end": "471840"
  },
  {
    "text": "and we're using the same output pad",
    "start": "475680",
    "end": "479680"
  },
  {
    "text": "this compilation will again take some",
    "start": "482400",
    "end": "484160"
  },
  {
    "text": "minutes to complete",
    "start": "484160",
    "end": "485440"
  },
  {
    "text": "so let's skip ahead to the deployment",
    "start": "485440",
    "end": "487120"
  },
  {
    "text": "phase",
    "start": "487120",
    "end": "489360"
  },
  {
    "text": "deploying the recently compiled model to",
    "start": "490400",
    "end": "492479"
  },
  {
    "text": "a new info one instance",
    "start": "492479",
    "end": "494080"
  },
  {
    "text": "powered by the inferential chips is",
    "start": "494080",
    "end": "496000"
  },
  {
    "text": "quite straightforward",
    "start": "496000",
    "end": "497440"
  },
  {
    "text": "we will only require the sagemaker new",
    "start": "497440",
    "end": "499919"
  },
  {
    "text": "deploy method",
    "start": "499919",
    "end": "501440"
  },
  {
    "text": "and to define the instance type here",
    "start": "501440",
    "end": "504080"
  },
  {
    "text": "we'll",
    "start": "504080",
    "end": "504479"
  },
  {
    "text": "use an inf1x large type but depending on",
    "start": "504479",
    "end": "507199"
  },
  {
    "text": "the size of the compile model",
    "start": "507199",
    "end": "508800"
  },
  {
    "text": "we could easily switch it up to a bigger",
    "start": "508800",
    "end": "510560"
  },
  {
    "text": "machine such as 6x large",
    "start": "510560",
    "end": "512800"
  },
  {
    "text": "with 4 inferencer chips or 24x large",
    "start": "512800",
    "end": "516080"
  },
  {
    "text": "with 16 differential chips as the model",
    "start": "516080",
    "end": "519360"
  },
  {
    "text": "is being deployed",
    "start": "519360",
    "end": "520399"
  },
  {
    "text": "by sagemaker neo we will create a",
    "start": "520399",
    "end": "522800"
  },
  {
    "text": "serializer method",
    "start": "522800",
    "end": "524080"
  },
  {
    "text": "so we can call the endpoint directly",
    "start": "524080",
    "end": "525760"
  },
  {
    "text": "with the mnist images as numpy arrays",
    "start": "525760",
    "end": "528640"
  },
  {
    "text": "the predictor endpoint expects a bytes",
    "start": "528640",
    "end": "531040"
  },
  {
    "text": "sequence",
    "start": "531040",
    "end": "531680"
  },
  {
    "text": "for the data if the serializer is not",
    "start": "531680",
    "end": "534000"
  },
  {
    "text": "specified",
    "start": "534000",
    "end": "535760"
  },
  {
    "text": "as the endpoint becomes ready we can now",
    "start": "535760",
    "end": "537839"
  },
  {
    "text": "send requests and retrieve results in",
    "start": "537839",
    "end": "539920"
  },
  {
    "text": "real time",
    "start": "539920",
    "end": "540640"
  },
  {
    "text": "with low latency so we will load 10",
    "start": "540640",
    "end": "543920"
  },
  {
    "text": "mnist images",
    "start": "543920",
    "end": "544880"
  },
  {
    "text": "and fire them sequentially at the model",
    "start": "544880",
    "end": "547040"
  },
  {
    "text": "endpoint",
    "start": "547040",
    "end": "549839"
  },
  {
    "text": "as you can see we almost cannot keep up",
    "start": "551120",
    "end": "553279"
  },
  {
    "text": "with the responses",
    "start": "553279",
    "end": "554399"
  },
  {
    "text": "as they come back we also notice that",
    "start": "554399",
    "end": "556959"
  },
  {
    "text": "the model is correctly predicting",
    "start": "556959",
    "end": "558720"
  },
  {
    "text": "or test images proving that we",
    "start": "558720",
    "end": "561040"
  },
  {
    "text": "successfully trained",
    "start": "561040",
    "end": "562320"
  },
  {
    "text": "optimized and deployed this mnist image",
    "start": "562320",
    "end": "564399"
  },
  {
    "text": "classification model with sagemaker neo",
    "start": "564399",
    "end": "568399"
  },
  {
    "text": "now as you're done sagemaker also",
    "start": "568399",
    "end": "571120"
  },
  {
    "text": "provides a delete endpoint method",
    "start": "571120",
    "end": "573279"
  },
  {
    "text": "which you can use to spin down the info",
    "start": "573279",
    "end": "575600"
  },
  {
    "text": "instance",
    "start": "575600",
    "end": "576480"
  },
  {
    "text": "running our endpoint before deleting the",
    "start": "576480",
    "end": "579279"
  },
  {
    "text": "endpoint",
    "start": "579279",
    "end": "580240"
  },
  {
    "text": "i would like to show you where to find",
    "start": "580240",
    "end": "581839"
  },
  {
    "text": "more information on the status",
    "start": "581839",
    "end": "583680"
  },
  {
    "text": "and duration of your compilation and",
    "start": "583680",
    "end": "585440"
  },
  {
    "text": "training jobs as well as the endpoint",
    "start": "585440",
    "end": "587760"
  },
  {
    "text": "configuration itself",
    "start": "587760",
    "end": "590480"
  },
  {
    "text": "if we come back to the aws console and",
    "start": "590480",
    "end": "593440"
  },
  {
    "text": "reload my expired session",
    "start": "593440",
    "end": "595760"
  },
  {
    "text": "we will find the links to the training",
    "start": "595760",
    "end": "598399"
  },
  {
    "text": "jobs",
    "start": "598399",
    "end": "599040"
  },
  {
    "text": "compiled models and finally the endpoint",
    "start": "599040",
    "end": "601839"
  },
  {
    "text": "we are using",
    "start": "601839",
    "end": "602959"
  },
  {
    "text": "all on the left hand side menu options",
    "start": "602959",
    "end": "607279"
  },
  {
    "text": "i would like to invite you to explore",
    "start": "611279",
    "end": "612880"
  },
  {
    "text": "more about inferentia and other",
    "start": "612880",
    "end": "614560"
  },
  {
    "text": "tutorials and examples on the aws labs",
    "start": "614560",
    "end": "616880"
  },
  {
    "text": "github",
    "start": "616880",
    "end": "618240"
  },
  {
    "text": "i hope this walkthrough was fun thank",
    "start": "618240",
    "end": "620240"
  },
  {
    "text": "you for watching",
    "start": "620240",
    "end": "623600"
  }
]
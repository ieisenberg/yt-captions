[
  {
    "start": "0",
    "end": "61000"
  },
  {
    "text": "hi everyone thank you for joining us today uh you probably been walking all",
    "start": "840",
    "end": "6600"
  },
  {
    "text": "over Vegas and going to different sessions uh so please sit back and relax",
    "start": "6600",
    "end": "12000"
  },
  {
    "text": "as we go from zero to 100 million records per second um people there on",
    "start": "12000",
    "end": "17080"
  },
  {
    "text": "the back don't relax so much we don't want you to fall asleep um so today",
    "start": "17080",
    "end": "22600"
  },
  {
    "text": "instead of uh lecturing about how the miroring system works uh in AWS I have",
    "start": "22600",
    "end": "28359"
  },
  {
    "text": "an idea what we can do is something different we will build a data processing system together with",
    "start": "28359",
    "end": "36040"
  },
  {
    "text": "you my name is Diego macadar and I'm here with Michael Fort we are part of",
    "start": "36040",
    "end": "41320"
  },
  {
    "text": "the metering and build generation team uh within the Commerce platform in AWS uh the metering team basically collects",
    "start": "41320",
    "end": "48960"
  },
  {
    "text": "all the usage that you use uh daily in AWS through all the services and we",
    "start": "48960",
    "end": "54960"
  },
  {
    "text": "aggregate that information and start the building process from there",
    "start": "54960",
    "end": "61320"
  },
  {
    "start": "61000",
    "end": "61000"
  },
  {
    "text": "so many of you probably back in your um offices build and maintain data",
    "start": "61519",
    "end": "68200"
  },
  {
    "text": "processing systems and we know from our own experience that dealing with data",
    "start": "68200",
    "end": "73240"
  },
  {
    "text": "can be really difficult um especially when this data is growing all the",
    "start": "73240",
    "end": "78640"
  },
  {
    "text": "time so to build this architecture with you we will explore some tools and techniques to deal with exponential",
    "start": "78640",
    "end": "85520"
  },
  {
    "text": "growth of data we will go through this with you together",
    "start": "85520",
    "end": "91159"
  },
  {
    "text": "for this architecture today we will use a real example here for Las Vegas let's",
    "start": "91159",
    "end": "96640"
  },
  {
    "text": "Sol a real problem so as you can see there's many lights in Vegas all the hotels and",
    "start": "96640",
    "end": "103960"
  },
  {
    "text": "casinos and stadiums have uh uh lights all over from some research this there's",
    "start": "103960",
    "end": "111040"
  },
  {
    "text": "15,000 miles of neon lights in Vegas and only in Freeman Street you can find 12",
    "start": "111040",
    "end": "120079"
  },
  {
    "text": "12 million light bulbs so the problem that we want to solve today is by using",
    "start": "120079",
    "end": "125759"
  },
  {
    "text": "smart socket technology we want to gather the information of the lights and build a system to analyze what's going",
    "start": "125759",
    "end": "132879"
  },
  {
    "text": "on there and provide orders for those lights so th those get get provisioned",
    "start": "132879",
    "end": "138720"
  },
  {
    "text": "so the information will flow from the smart sockets into our system and will",
    "start": "138720",
    "end": "144480"
  },
  {
    "text": "generate aggregated information into the ordering systems so these will basically improve",
    "start": "144480",
    "end": "151080"
  },
  {
    "text": "the overall lighting experience in Vegas and also will reduce the cost and Logistics of",
    "start": "151080",
    "end": "157120"
  },
  {
    "text": "it one thing that we need to consider here is that there's many lights in Vegas and we need to make sure that",
    "start": "157120",
    "end": "164080"
  },
  {
    "text": "we're not over provisioning or underprovision these lights if we over provision the lights what happens is",
    "start": "164080",
    "end": "170640"
  },
  {
    "text": "that we will need to store those lights and really have a complex logistic model in order to send them to the right",
    "start": "170640",
    "end": "177640"
  },
  {
    "text": "places if we underprovision the lights all the the nice signs that you see all",
    "start": "177640",
    "end": "183560"
  },
  {
    "text": "over Vegas will have black spots in it so that takes me to the next thing which",
    "start": "183560",
    "end": "189120"
  },
  {
    "start": "189000",
    "end": "189000"
  },
  {
    "text": "is having three principles for this architecture the number one will be that",
    "start": "189120",
    "end": "194680"
  },
  {
    "text": "we need to be 100% accurate we don't want to remember to underprovision or",
    "start": "194680",
    "end": "200000"
  },
  {
    "text": "over provision lights and in order to do this we need to have once and only once",
    "start": "200000",
    "end": "205680"
  },
  {
    "text": "guarantee meaning that any message that we get from the light sockets will be processed only once it will not be",
    "start": "205680",
    "end": "212280"
  },
  {
    "text": "duplicat or dropped and another thing that we would want to accomplish in this architecture",
    "start": "212280",
    "end": "218319"
  },
  {
    "text": "is that we want item poent processing meaning that any message that we get from these light sockets will be",
    "start": "218319",
    "end": "224280"
  },
  {
    "text": "processed the same way anytime that we process the message another thing there's Al always",
    "start": "224280",
    "end": "231280"
  },
  {
    "text": "new casinos new hotels opening here so we want to be horizontally",
    "start": "231280",
    "end": "236599"
  },
  {
    "text": "scalable we want to have Loosely coupled components so can grow any of of these",
    "start": "236599",
    "end": "241680"
  },
  {
    "text": "components without having to impact the whole system and of course we want El",
    "start": "241680",
    "end": "246959"
  },
  {
    "text": "elasticity we don't want to actually be operating these systems and having to be",
    "start": "246959",
    "end": "252200"
  },
  {
    "text": "um operationally working on that so that takes me to the third part that is",
    "start": "252200",
    "end": "257680"
  },
  {
    "text": "basically that we want to focus on the business we want to focus on the business and not having to context",
    "start": "257680",
    "end": "263680"
  },
  {
    "text": "switch between operations and development we want to make sure that this business is",
    "start": "263680",
    "end": "268720"
  },
  {
    "text": "actually the one that we are focusing on so we want to be operationally excellent",
    "start": "268720",
    "end": "274560"
  },
  {
    "text": "in AWS we have an a culture of op operational excellence and we want to use manage Frameworks for this so",
    "start": "274560",
    "end": "281400"
  },
  {
    "text": "something that we will do today is we will explore these tools and techniques in detail on how to we can improve the",
    "start": "281400",
    "end": "288320"
  },
  {
    "text": "usage of that in order to to grow this data from zero to 100 million records",
    "start": "288320",
    "end": "293440"
  },
  {
    "text": "per second so now that we have the idea let's start to Define this architecture",
    "start": "293440",
    "end": "300479"
  },
  {
    "text": "and by defining this architecture I will basically show what components we will be working",
    "start": "300479",
    "end": "306160"
  },
  {
    "text": "with we will start collecting the information from the light bulbs uh into our",
    "start": "306160",
    "end": "312240"
  },
  {
    "text": "system then we will transform this information if you think about this this these uh uh smart sockets will be",
    "start": "312240",
    "end": "319080"
  },
  {
    "text": "basically metering the information that it's uh being sent through the lights and we need to transform that into a",
    "start": "319080",
    "end": "325240"
  },
  {
    "text": "more human readable um uh format for the analytics that we will do and also for",
    "start": "325240",
    "end": "331080"
  },
  {
    "text": "the aggregation we will need to process that information so we will be we will need to transform the information and we",
    "start": "331080",
    "end": "337400"
  },
  {
    "text": "will go more into detail uh later we will analyze the information that we have providing real time",
    "start": "337400",
    "end": "344600"
  },
  {
    "text": "analytics for our customers so everything that's happening on the system we want to make it visible for",
    "start": "344600",
    "end": "350639"
  },
  {
    "text": "external customers then we will aggregate this information and the reason for the",
    "start": "350639",
    "end": "356560"
  },
  {
    "text": "aggregation basically and again we will go into more into detail later is that we want to not to create very very small",
    "start": "356560",
    "end": "363680"
  },
  {
    "text": "orders all all the time but we actually want to have meaningful orders and for this architecture we will Define a daily",
    "start": "363680",
    "end": "371319"
  },
  {
    "text": "um order and then at the end of this PIP plan what we will do is deliver this",
    "start": "371319",
    "end": "377440"
  },
  {
    "text": "information into the systems or make it available for the systems to consume it some other things that we need to",
    "start": "377440",
    "end": "384560"
  },
  {
    "text": "consider on the architecture is one thing it's the global data and by global data I mean this data that will be",
    "start": "384560",
    "end": "390880"
  },
  {
    "text": "flowing through the system we will have data in each one of these components but we also need to consider this global",
    "start": "390880",
    "end": "397599"
  },
  {
    "text": "data on how to manage it and the other thing within this global data is that we",
    "start": "397599",
    "end": "404080"
  },
  {
    "text": "need to understand what's the state of this data and we spoke before about item potency and how I will know what's the",
    "start": "404080",
    "end": "411360"
  },
  {
    "text": "stage of this data so I can replay it if it fails and move it forward through the",
    "start": "411360",
    "end": "416680"
  },
  {
    "text": "pipeline and last but not least we said we want to be 100% accurate and to be",
    "start": "416680",
    "end": "422680"
  },
  {
    "text": "100% accurate we don't need to just architect the things around that but also we need to verify it by auditing",
    "start": "422680",
    "end": "429639"
  },
  {
    "text": "the information that we're uh coming with so we will have the streaming",
    "start": "429639",
    "end": "434800"
  },
  {
    "start": "433000",
    "end": "433000"
  },
  {
    "text": "components that are the system is Flowing the the the data from the smart sockets we collect it we transform it we",
    "start": "434800",
    "end": "442960"
  },
  {
    "text": "analyze it and then we stop there for a second we buffer the information for a",
    "start": "442960",
    "end": "448360"
  },
  {
    "text": "day and after buff offering this information we will move to the batch components which are aggregation and",
    "start": "448360",
    "end": "455520"
  },
  {
    "start": "453000",
    "end": "453000"
  },
  {
    "text": "delivery and of course audit so we spoke up to now about three",
    "start": "455520",
    "end": "462039"
  },
  {
    "start": "459000",
    "end": "459000"
  },
  {
    "text": "logical entities that we will go through the presentation data State and",
    "start": "462039",
    "end": "469919"
  },
  {
    "text": "compute so now that we have the problem defined let's start together building this architecture and we will start with",
    "start": "469919",
    "end": "476759"
  },
  {
    "text": "the data part and specifically let's start with global data here so Mike what options do",
    "start": "476759",
    "end": "483840"
  },
  {
    "text": "we have for managing global data in this system I think before we talk about",
    "start": "483840",
    "end": "490360"
  },
  {
    "text": "picking a solution for our global data or the data that's going to be shared across our systems we need to talk about",
    "start": "490360",
    "end": "497280"
  },
  {
    "text": "how we're going to manage that data and first of all all of our global data or all the data that's stored that's going",
    "start": "497280",
    "end": "502720"
  },
  {
    "text": "to be used across our systems must be immutable and the reason that we do this is for two primary reasons one",
    "start": "502720",
    "end": "510039"
  },
  {
    "text": "auditability so that we know what actions were performed at any given",
    "start": "510039",
    "end": "515599"
  },
  {
    "text": "processing and secondly for the replayability that Diego spoke about before if we need to retry any of our",
    "start": "515599",
    "end": "521719"
  },
  {
    "text": "logic we can just replay it through our system and we don't have to worry about cleaning up artifacts the second thing we need to",
    "start": "521719",
    "end": "528560"
  },
  {
    "text": "look at performance bottlenecks that we might get in any solution that we choose let's talk about Dynamo DB for instance",
    "start": "528560",
    "end": "535040"
  },
  {
    "text": "where we need to pick a partition and need to worry about the iops or for",
    "start": "535040",
    "end": "540480"
  },
  {
    "text": "Amazon's RDS or we might we have to worry about IO and so we want to monitor",
    "start": "540480",
    "end": "545880"
  },
  {
    "text": "these things typically with Amazon's cloud or excuse me Cloud watch and set up some alarming thresholds and the last",
    "start": "545880",
    "end": "553160"
  },
  {
    "text": "thing is of course uh security and everything we do it's a top priority at Amazon to make sure things are secure",
    "start": "553160",
    "end": "559519"
  },
  {
    "text": "and so we need to have encryption both at rest and in",
    "start": "559519",
    "end": "565120"
  },
  {
    "text": "transit so now when we're trying to talk about the options that we're going to choose we need to look at structured",
    "start": "565120",
    "end": "571000"
  },
  {
    "text": "versus unstructured data and I'm want to make sure that we don't confuse formatting with structuring so",
    "start": "571000",
    "end": "577360"
  },
  {
    "text": "formatting is the format that's coming from your Upstream systems like Json or",
    "start": "577360",
    "end": "583360"
  },
  {
    "text": "CSV some of these common formats that you might get from a file and that's not really what I'm",
    "start": "583360",
    "end": "589240"
  },
  {
    "text": "talking about here unstructured data would be that the data store understands the data that you're putting into the",
    "start": "589240",
    "end": "594640"
  },
  {
    "text": "store and so Amazon S3 you could put a file name and here's my file but S3 doesn't understand that data at all it",
    "start": "594640",
    "end": "601160"
  },
  {
    "text": "just knows that there's a file and it has some data enclosed within it the others would be structured data and",
    "start": "601160",
    "end": "608040"
  },
  {
    "text": "that's if I need to do queries on my data say hey I needed the statistic of a data or the state of a data that would",
    "start": "608040",
    "end": "613880"
  },
  {
    "text": "go in a structured data store like Amazon's Dynamo DB which is a key value store or into Amazon's RDS which if you",
    "start": "613880",
    "end": "621920"
  },
  {
    "text": "had relations between some of your data sets uh would be a relational store so Dio I think it's a time that we",
    "start": "621920",
    "end": "629000"
  },
  {
    "text": "look at the data that's coming from our smartsockets and make a decision on what kind of uh medium we want to use yeah",
    "start": "629000",
    "end": "635320"
  },
  {
    "start": "635000",
    "end": "635000"
  },
  {
    "text": "and that that's an important thing we are always in architecture making trade-offs of things uh and that's what",
    "start": "635320",
    "end": "640600"
  },
  {
    "text": "we will do uh during this session too so here's the data that we're uh getting presented by the smart sockets as you",
    "start": "640600",
    "end": "647519"
  },
  {
    "text": "can see it has a Json format uh we have client ID Tim stamp um the the socket",
    "start": "647519",
    "end": "653959"
  },
  {
    "text": "identifier light identifier um so all this information that is that is coming",
    "start": "653959",
    "end": "659399"
  },
  {
    "text": "uh it's coming actually in collections of Records so if you can think each one of the rooms of the hotels or each one",
    "start": "659399",
    "end": "665320"
  },
  {
    "text": "of the uh different signs will have a collection that will be able to send us this information through um so this is",
    "start": "665320",
    "end": "672880"
  },
  {
    "text": "how is it looks and from what you say this is actually formatted data right so",
    "start": "672880",
    "end": "679040"
  },
  {
    "text": "if this is formated data then we probably want to have it there in uh in",
    "start": "679040",
    "end": "684639"
  },
  {
    "text": "this unmut store that can be S3 in this case and one of the reasons why I would",
    "start": "684639",
    "end": "689959"
  },
  {
    "text": "pick S3 here it's because beyond that we don't actually need uh the the query",
    "start": "689959",
    "end": "696560"
  },
  {
    "text": "ability of this data we actually want to reduce the cost too and this will be a",
    "start": "696560",
    "end": "702839"
  },
  {
    "text": "lot of data if you think about any event that happens to any light in all Las",
    "start": "702839",
    "end": "708160"
  },
  {
    "text": "Vegas it will really create millions of Records per second so this is why we",
    "start": "708160",
    "end": "713440"
  },
  {
    "text": "want to store it in a place where it's cost effective and also effective from the speed uh uh perspective so let's",
    "start": "713440",
    "end": "721000"
  },
  {
    "text": "choose S3 here on the architecture and one thing that you said before and I will um get that and use it is that we",
    "start": "721000",
    "end": "729079"
  },
  {
    "text": "said that we want un mutable data and this data will go through different steps so one thing that we can do to is",
    "start": "729079",
    "end": "736199"
  },
  {
    "text": "create three different S3 brackets and with that we can store each one of the stages of this data do you think this is",
    "start": "736199",
    "end": "743120"
  },
  {
    "text": "a a good idea yeah I think you know it's time to look kind of at that local store",
    "start": "743120",
    "end": "748839"
  },
  {
    "text": "that we were talking about before yeah and and and you're right the local store it's important because you spoke about",
    "start": "748839",
    "end": "755160"
  },
  {
    "text": "the immutability and if we cannot mutate the records then how can we process them",
    "start": "755160",
    "end": "761120"
  },
  {
    "text": "uh so how would the local data look like here so we use local data again for the mutations of the data if we need to do",
    "start": "761120",
    "end": "767720"
  },
  {
    "text": "some processing we don't want to process it obviously in our local store or in our Global store we want to take that",
    "start": "767720",
    "end": "773440"
  },
  {
    "text": "down to the local store do our processing make our mutations and then move that back to the global store so",
    "start": "773440",
    "end": "778560"
  },
  {
    "text": "our scope of work is limited to the amount of objects that we process in that one run and so this is where we do",
    "start": "778560",
    "end": "784880"
  },
  {
    "text": "our mutations of data another reason we use a local stores really for caching data optimizations and so if you could",
    "start": "784880",
    "end": "791959"
  },
  {
    "text": "think about a map that we'd have to change our client identifier to something that's human readable as Diego",
    "start": "791959",
    "end": "797079"
  },
  {
    "text": "spoke about before we wouldn't want to continuously grab that map from a a",
    "start": "797079",
    "end": "802160"
  },
  {
    "text": "global store we'd want to pull that into a local store and then do some checking between some synchronization between the",
    "start": "802160",
    "end": "807880"
  },
  {
    "text": "local store and the the the global store to make sure that they're in sync but we got the optimization of only looking",
    "start": "807880",
    "end": "814800"
  },
  {
    "text": "locally and then again once we're done with that lifetime of the Persistence of of that object or doing our mutations",
    "start": "814800",
    "end": "821360"
  },
  {
    "text": "we'll then move it back to our Global store and we'll be done and it's immutable again so I think we should look at you",
    "start": "821360",
    "end": "828320"
  },
  {
    "text": "know how this local data is transformed in the system that we're designing okay so let let's see how this works uh we",
    "start": "828320",
    "end": "835560"
  },
  {
    "start": "833000",
    "end": "833000"
  },
  {
    "text": "will get the data and as we transform it for instance we will get the client ID that it's uh like formated on the own",
    "start": "835560",
    "end": "843600"
  },
  {
    "text": "iot um structure into the client ID and from this cach that you spoke about we",
    "start": "843600",
    "end": "849079"
  },
  {
    "text": "can actually grab the information and transform it through a map to best hotel",
    "start": "849079",
    "end": "854199"
  },
  {
    "text": "for instance which is the the name of this fictitious Hotel um we can also",
    "start": "854199",
    "end": "859519"
  },
  {
    "text": "transform we spoke about before about uh how to aggregate this data daily if we use the seconds that we're getting from",
    "start": "859519",
    "end": "866000"
  },
  {
    "text": "the iot we will get aggregation up to the second so we want to transform it to a date format also uh for the use of",
    "start": "866000",
    "end": "873519"
  },
  {
    "text": "that aggregation and then we have the light identifier that can be for instance the identifier for the ordering",
    "start": "873519",
    "end": "879680"
  },
  {
    "text": "system to make it easier for for the for the ordering system to process these orders so one of the things that I want",
    "start": "879680",
    "end": "886839"
  },
  {
    "text": "to point out here and it's interesting is that you mentioned the caching uh technique and using that caching",
    "start": "886839",
    "end": "893920"
  },
  {
    "text": "actually gives us two more things one it's reduction in cost we're not querying the data store all the time and",
    "start": "893920",
    "end": "900839"
  },
  {
    "text": "the second thing that it gives us is also resiliency and against any connection connectivity issues that we",
    "start": "900839",
    "end": "906480"
  },
  {
    "text": "can have to that uh uh database so I think that's that's good",
    "start": "906480",
    "end": "911839"
  },
  {
    "text": "with data and let's move to the state stage so how do we deal with the the",
    "start": "911839",
    "end": "917240"
  },
  {
    "text": "global State and by global State I mean how we are tracking the information that",
    "start": "917240",
    "end": "922320"
  },
  {
    "text": "is flowing through the system again we're talking about stores",
    "start": "922320",
    "end": "928360"
  },
  {
    "text": "and you'll see the same stores that we talked about before and they have you know have the same behaviors so we have",
    "start": "928360",
    "end": "934399"
  },
  {
    "text": "a key value store if you need to look something up by a key and get some State associated with that key or if you have",
    "start": "934399",
    "end": "940279"
  },
  {
    "text": "a relational store where you say okay there's States you could derive a state from two different there's a relationship between those pieces of",
    "start": "940279",
    "end": "947040"
  },
  {
    "text": "state and then if you just have a blob of state so I need to grab some file down from S3 and then it has a bunch of",
    "start": "947040",
    "end": "953920"
  },
  {
    "text": "state within that file and then I would move that file as the state changes and so it really depends on the state that",
    "start": "953920",
    "end": "959199"
  },
  {
    "text": "we're looking at and and how our system is going to work so these are the trade-offs or things that we would look at uh when we're dealing with State and",
    "start": "959199",
    "end": "967519"
  },
  {
    "text": "I think it's important though when you're talking about state to really understand the transitions of your state you know are are you making the state",
    "start": "967519",
    "end": "973800"
  },
  {
    "text": "machine that's overly complicated because you're going to have to deal with all of these State Transitions and",
    "start": "973800",
    "end": "979000"
  },
  {
    "text": "really making a a map of what of those transitions are is very very critical when you're dealing with State and so I",
    "start": "979000",
    "end": "984920"
  },
  {
    "text": "think it's a good idea if we we take a look at the state machine that we're going to build uh for this system so in this system we will use a",
    "start": "984920",
    "end": "992600"
  },
  {
    "start": "990000",
    "end": "990000"
  },
  {
    "text": "simple State machine when we receive the information from the smart sockets remember we receive it in batches of",
    "start": "992600",
    "end": "999000"
  },
  {
    "text": "information we will set it as created we start the process there and we know that",
    "start": "999000",
    "end": "1004160"
  },
  {
    "text": "we received it um and remember that we the next stage that we have is transforming this information so when we",
    "start": "1004160",
    "end": "1010480"
  },
  {
    "text": "are doing the transformation things can fail especially in distributed systems and with these amounts of data we can",
    "start": "1010480",
    "end": "1017000"
  },
  {
    "text": "actually have a fail state but if beauty of doing this uh in a item poent way is",
    "start": "1017000",
    "end": "1022480"
  },
  {
    "text": "that we can in any time replay the same message and actually get to the transform stage again and from that",
    "start": "1022480",
    "end": "1029600"
  },
  {
    "text": "transform stage we will analyze it aggregate it and set it as complete so",
    "start": "1029600",
    "end": "1035000"
  },
  {
    "text": "this will be the state machine that we will be using and based of the options that you gave uh regarding the different",
    "start": "1035000",
    "end": "1041400"
  },
  {
    "text": "stores that we have and considering that we have a batch name and a specific uh",
    "start": "1041400",
    "end": "1047000"
  },
  {
    "text": "state that we want to track a ke Val store seems to be like the best option here um what do you think about that I",
    "start": "1047000",
    "end": "1054120"
  },
  {
    "text": "think it's right I mean you're just tracking state of that batch as it moves through your system so it's really easy to just say hey this is my batch name as",
    "start": "1054120",
    "end": "1060760"
  },
  {
    "text": "long as you are keeping to those best practices of Dynamo and making sure that you you are partitioning properly okay",
    "start": "1060760",
    "end": "1067280"
  },
  {
    "text": "so if everyone agrees we will set Dynamo DB as the uh State machine holder where",
    "start": "1067280",
    "end": "1073960"
  },
  {
    "text": "we will be able to track the local state uh sorry the global state but then one",
    "start": "1073960",
    "end": "1079400"
  },
  {
    "text": "thing that I'm I also had a question around is that once we have this state there how does the next component know",
    "start": "1079400",
    "end": "1086039"
  },
  {
    "text": "that it has to pick it up yeah so I mean especially if we're going to use Dynam DB here we could do large table scans",
    "start": "1086039",
    "end": "1092559"
  },
  {
    "text": "and if you can imagine the amount of volume that we'd get from all these lights it's not really going to be",
    "start": "1092559",
    "end": "1097880"
  },
  {
    "text": "scalable we'd have to do huge scans and look for filtering on on failed State we wouldn't want to do that we want to be",
    "start": "1097880",
    "end": "1104000"
  },
  {
    "text": "very explicit in the amount of work that we're going to be doing from our Downstream systems so typically we could",
    "start": "1104000",
    "end": "1111120"
  },
  {
    "text": "send that data directly to uh the downstream system but again if we talk",
    "start": "1111120",
    "end": "1116480"
  },
  {
    "text": "directly to those Downstream systems we couple those systems together and typically in the behavior of two",
    "start": "1116480",
    "end": "1122640"
  },
  {
    "text": "independent systems is they scale differently and so you've then caused this dependency between the downstream",
    "start": "1122640",
    "end": "1128200"
  },
  {
    "text": "systems and the Upstream systems and you have to protect yourself and so you'll have some buffer and you have buffer",
    "start": "1128200",
    "end": "1133559"
  },
  {
    "text": "overrun problems and so we don't couple systems like that typically we'll take a channel that is in between that can grow",
    "start": "1133559",
    "end": "1140039"
  },
  {
    "text": "elastically uh you know typically with a queuing system that you could directly share that state and it has its own uh",
    "start": "1140039",
    "end": "1147240"
  },
  {
    "text": "explicit amount of work that it needs to get done okay so for queing systems uh",
    "start": "1147240",
    "end": "1152280"
  },
  {
    "text": "in AWS we have uh Amazon sqs uh used um or or we also have Amazon Kinesis so",
    "start": "1152280",
    "end": "1159760"
  },
  {
    "text": "what are the trade-offs between those two here yeah I think we've been going through a lot of trade-offs and it's",
    "start": "1159760",
    "end": "1165360"
  },
  {
    "start": "1162000",
    "end": "1162000"
  },
  {
    "text": "really about picking attributes that you need need to make make trade-offs in and in this system we've picked three here",
    "start": "1165360",
    "end": "1171799"
  },
  {
    "text": "ordering locality and delivery and by ordering I mean I'm I going to get those",
    "start": "1171799",
    "end": "1177080"
  },
  {
    "text": "messages in the same order every single time for locality is the same logical consumer going to get that message and",
    "start": "1177080",
    "end": "1183799"
  },
  {
    "text": "for delivery is there possibilities that I get that same message twice and so for Amazon's sqs we are not ordered it is",
    "start": "1183799",
    "end": "1192120"
  },
  {
    "text": "not localized and it's at least once delivery which is very common with a queuing system a distributed queuing",
    "start": "1192120",
    "end": "1197760"
  },
  {
    "text": "system and then in Amazon skines it's it's strictly ordered and it has locality so the same logical consumer",
    "start": "1197760",
    "end": "1204280"
  },
  {
    "text": "will get that same message and it's again at least once processing okay so we we spoke before on the three",
    "start": "1204280",
    "end": "1210679"
  },
  {
    "text": "principles for this architecture about item potency and the so then it looks",
    "start": "1210679",
    "end": "1215840"
  },
  {
    "text": "like Kinesis gives us that ability to localize the things and send them through uh the same set of host if it",
    "start": "1215840",
    "end": "1223200"
  },
  {
    "text": "fails we can replay the same message and it will end up in the same place but one thing that I'm worried about is that",
    "start": "1223200",
    "end": "1229240"
  },
  {
    "text": "you're mentioning here that both of these options have at least one processing meaning that if I have a",
    "start": "1229240",
    "end": "1235679"
  },
  {
    "text": "record I know that I will get it but I might get it duplicated so how can we deal with that uh in this case typically",
    "start": "1235679",
    "end": "1243400"
  },
  {
    "text": "You' build your own D duplication strategy if if they're not guaranteeing uh once and only once processing you",
    "start": "1243400",
    "end": "1249400"
  },
  {
    "text": "have to have some way to duplicate those messages and typically you pick a a key that you can say if has seen this key",
    "start": "1249400",
    "end": "1256159"
  },
  {
    "text": "before if I have then I can duplicate that particular message out and if I haven't then I'll accept that message as",
    "start": "1256159",
    "end": "1262520"
  },
  {
    "text": "as valid work and the nice thing about having locality is we can change the scope of data that we're looking at J",
    "start": "1262520",
    "end": "1269840"
  },
  {
    "text": "down to the consumer that's getting that message and so we don't have to have it across our entire distributed set of",
    "start": "1269840",
    "end": "1275400"
  },
  {
    "text": "workers we have it just to the consumer that's consuming that queue so it gains uh some optimizations there as well okay",
    "start": "1275400",
    "end": "1282320"
  },
  {
    "text": "so that looks like a good idea let's use Kinesis and let me see if I'm understanding correctly what will happen",
    "start": "1282320",
    "end": "1288039"
  },
  {
    "start": "1285000",
    "end": "1285000"
  },
  {
    "text": "with Kines is that every hotel that is sending me the lights will go to a different partition so as we get the",
    "start": "1288039",
    "end": "1295480"
  },
  {
    "text": "information from the light sockets we will move it through the transform and then it will end up going through this",
    "start": "1295480",
    "end": "1301080"
  },
  {
    "text": "channel for uh the next stage uh which will be the the analysis here but one",
    "start": "1301080",
    "end": "1306640"
  },
  {
    "text": "thing I'm noticing here uh on this graph is that we probably have hotels that are",
    "start": "1306640",
    "end": "1312080"
  },
  {
    "text": "way larger than others so how can we actually make the best use of the resources that we have instead of having",
    "start": "1312080",
    "end": "1318799"
  },
  {
    "text": "the hotel one going all to one partition and the hotel two with few messages for partition number",
    "start": "1318799",
    "end": "1325440"
  },
  {
    "text": "two I think it's first of all we should mention the fact that Kinesis utilizes charge which are groups of partitions so",
    "start": "1325440",
    "end": "1332640"
  },
  {
    "text": "if you think that a partition gets hot they have no way to distribute that load so you need to be very careful in how uh",
    "start": "1332640",
    "end": "1338679"
  },
  {
    "text": "many partitions that you're going to choose and you can do this by adding entropy to the partition uh that you're",
    "start": "1338679",
    "end": "1345480"
  },
  {
    "text": "you're selecting your partition key and so You' pick a an an attribute like Hotel identifier as a partition key and",
    "start": "1345480",
    "end": "1351520"
  },
  {
    "text": "then to add that entropy you take a hashing function on the entity of work that you're doing and then modulus the",
    "start": "1351520",
    "end": "1358679"
  },
  {
    "text": "partition key size that you've selected and you can select the partition key size based off of the amount of data",
    "start": "1358679",
    "end": "1363960"
  },
  {
    "text": "that you're getting from that hotel and it's important that we think about how that's going to change over time because",
    "start": "1363960",
    "end": "1370320"
  },
  {
    "text": "hotels are going to get larger some will shut down and so we want to CH be able to change those partition key sizes and",
    "start": "1370320",
    "end": "1376520"
  },
  {
    "text": "so the way that we could do that is by a time versioning on that partition key",
    "start": "1376520",
    "end": "1382679"
  },
  {
    "text": "where we say at this particular time based off of a time that's as part of that entity so if you look at back at",
    "start": "1382679",
    "end": "1388799"
  },
  {
    "text": "the batches that came with a time stamp we could use that Tim stamp to decide which partition key size we're going to",
    "start": "1388799",
    "end": "1394640"
  },
  {
    "text": "use over time and this really helps us uh partition our data better okay so",
    "start": "1394640",
    "end": "1400559"
  },
  {
    "text": "that was a little bit complex so let me see if I understand it correctly what happens here is that I'm basically",
    "start": "1400559",
    "end": "1406279"
  },
  {
    "text": "adding uh what you called entropy I'm adding an extra value to distribute the load between the different partitions",
    "start": "1406279",
    "end": "1413120"
  },
  {
    "text": "here so that way I can have even partitions but now we spoke about being scalable and being horizontally scalable",
    "start": "1413120",
    "end": "1420400"
  },
  {
    "text": "and elastic so if I think about Kinesis I think about this uh stream of charts",
    "start": "1420400",
    "end": "1427039"
  },
  {
    "text": "that I have and then how can I actually scale up or down based off the needs that I",
    "start": "1427039",
    "end": "1432919"
  },
  {
    "text": "have so typically we do this with like hotspot manager something that can understand the data that's coming in and",
    "start": "1432919",
    "end": "1439760"
  },
  {
    "start": "1434000",
    "end": "1434000"
  },
  {
    "text": "then make changes dynamically and so we can capture all the io statistics coming from our producer send that to a data",
    "start": "1439760",
    "end": "1446080"
  },
  {
    "text": "store and then have our hotspot manager read that data make various changes on the partition keys and then update that",
    "start": "1446080",
    "end": "1453720"
  },
  {
    "text": "partition key back to the store and then that gets synced back to the producer and you do this again with a Time",
    "start": "1453720",
    "end": "1459360"
  },
  {
    "text": "versioning the other thing is I think you mentioned on The Shard side you need to be able to scale up and down your",
    "start": "1459360",
    "end": "1464559"
  },
  {
    "text": "shards and so the hotspot manager can do that as well it looks at what the volume cross your shards are and make",
    "start": "1464559",
    "end": "1469679"
  },
  {
    "text": "determinations if you need to shrink the amount of shards that you have or grow the amount of shards that you have okay that that uh actually sounds",
    "start": "1469679",
    "end": "1477559"
  },
  {
    "text": "good so let's use Kinesis for this but one thing that I want to um reiterate here is that we spoke about some of the",
    "start": "1477559",
    "end": "1484600"
  },
  {
    "text": "techniques for local data to use caching within each one of these components and",
    "start": "1484600",
    "end": "1490120"
  },
  {
    "text": "to put Kinesis here we actually need to add these other two things which are the D duplication Logic on each one of the",
    "start": "1490120",
    "end": "1497080"
  },
  {
    "text": "consumers and also Al the hotspot management to make sure that we can grow elastically and Shrink",
    "start": "1497080",
    "end": "1502760"
  },
  {
    "text": "elastically so let's go um now to the next stage which is the local state how",
    "start": "1502760",
    "end": "1508320"
  },
  {
    "start": "1506000",
    "end": "1506000"
  },
  {
    "text": "do we manage local state yeah so a local state is Mike give me a second I think",
    "start": "1508320",
    "end": "1514159"
  },
  {
    "text": "you copied the same slide from data uh I did I was optimizing cost okay but um in",
    "start": "1514159",
    "end": "1522120"
  },
  {
    "text": "reality they're it's very similar right you're using data stores key value stores depending on the the use of your",
    "start": "1522120",
    "end": "1527600"
  },
  {
    "text": "data and and so if you take D duplication state for instance where you're saying a single consumer can grab",
    "start": "1527600",
    "end": "1533840"
  },
  {
    "text": "that data and look up local state have I processed this or have I not processed this it has that characteristic of what",
    "start": "1533840",
    "end": "1540200"
  },
  {
    "text": "we call worm write once read many I write to my my local store that I've processed this data and I'm consistently",
    "start": "1540200",
    "end": "1546600"
  },
  {
    "text": "reading to say hey have I seen this have I seen this and then once we're done with our checkpoint if you think of Kinesis or KCl where you can say I've",
    "start": "1546600",
    "end": "1553159"
  },
  {
    "text": "done some scope of work 10 minutes of work I can then move that store or move that DD ation State back up into my uh",
    "start": "1553159",
    "end": "1560840"
  },
  {
    "text": "Global store or Global state store and then if my consumer dies it can move to a different host and I can grab that D",
    "start": "1560840",
    "end": "1567520"
  },
  {
    "text": "duplication State back into that consumer so we have a nice uh elastic",
    "start": "1567520",
    "end": "1572600"
  },
  {
    "text": "model and we have fall tolerance as well okay so let's review the",
    "start": "1572600",
    "end": "1578399"
  },
  {
    "text": "architecture uh for a second we have S3 for the global data we can store a lot",
    "start": "1578399",
    "end": "1583640"
  },
  {
    "text": "of data at a low cost uh we will make that data immutable we will just change",
    "start": "1583640",
    "end": "1588960"
  },
  {
    "text": "it on this caching on each one of the components uh then we will have the tracking of the state through dynamodb",
    "start": "1588960",
    "end": "1596159"
  },
  {
    "text": "and uh then we will have uh the Kinesis stream sending the information between",
    "start": "1596159",
    "end": "1601440"
  },
  {
    "text": "uh the transform and the analyze uh components so let's go now that we have data and State uh uh there let's go to",
    "start": "1601440",
    "end": "1609200"
  },
  {
    "text": "the compute and tell me Mike for the compute what options do we have here well we have the new hotness that",
    "start": "1609200",
    "end": "1616960"
  },
  {
    "start": "1611000",
    "end": "1611000"
  },
  {
    "text": "is uh server L compute so Ser lless compute I'm not going to go into details there's a lot of details in this",
    "start": "1616960",
    "end": "1622880"
  },
  {
    "text": "conference uh but basically we've abstracted away server management so if you don't want to deal with the server",
    "start": "1622880",
    "end": "1628399"
  },
  {
    "text": "itself you get out of the box scaling and metrics and logging and so there's a lot of benefits to moving to a",
    "start": "1628399",
    "end": "1634399"
  },
  {
    "text": "serverless compute on the other hand we have the more traditional model which is f has Fine gr controls where we can",
    "start": "1634399",
    "end": "1640760"
  },
  {
    "text": "tweak things depending on our use case uh we it's time sensitive if you have very time sensitive critical",
    "start": "1640760",
    "end": "1647159"
  },
  {
    "text": "applications that you care about nanc of time of course you're going to want to use something more in the traditional model and then collocation of resources",
    "start": "1647159",
    "end": "1654880"
  },
  {
    "text": "where if you're using a hybrid approach and you say okay I have some set of entities that I I know I need to execute",
    "start": "1654880",
    "end": "1661279"
  },
  {
    "text": "on and I want to execute it seamlessly between the cloud you'll typically use something like ec2 uh also for for",
    "start": "1661279",
    "end": "1668080"
  },
  {
    "text": "clustering as we mentioned here as well if you have some custom clustering that you're using you need to know how many specific nodes that you're going to have",
    "start": "1668080",
    "end": "1674919"
  },
  {
    "text": "and you need to have deterministic Behavior there uh then the server based comput is going to be the choice okay so",
    "start": "1674919",
    "end": "1681320"
  },
  {
    "text": "it sounds like for the transform stage when we are getting all the information we can use Lambda uh as you said it's",
    "start": "1681320",
    "end": "1687679"
  },
  {
    "text": "the new hotness I really like things that are easy to manage and I like things that are trendy so let's use",
    "start": "1687679",
    "end": "1693640"
  },
  {
    "text": "Lambda there uh but then after we are uh using Kinesis we spoke about the duplication and about analyzing",
    "start": "1693640",
    "end": "1700440"
  },
  {
    "text": "information we will need to do more complex operations that are actually merging uh those different um me",
    "start": "1700440",
    "end": "1708120"
  },
  {
    "text": "messages that we are getting so let's use ec2 there um do you think this this this is a good idea yeah I think it's a",
    "start": "1708120",
    "end": "1715480"
  },
  {
    "text": "great idea okay so one thing um if we put uh Lambda there it will easily scale",
    "start": "1715480",
    "end": "1721679"
  },
  {
    "text": "but then the question that I have with ec2 is that we're here in Vegas and there's all the time new projects coming",
    "start": "1721679",
    "end": "1727840"
  },
  {
    "text": "in new hotels new stadiums being built uh uh all the time so how do we scale",
    "start": "1727840",
    "end": "1733840"
  },
  {
    "text": "those ec2 boxes there's a very known well behaved",
    "start": "1733840",
    "end": "1739679"
  },
  {
    "start": "1738000",
    "end": "1738000"
  },
  {
    "text": "system that we have Amazon's ec2 autoscaling where we determine what the",
    "start": "1739679",
    "end": "1745039"
  },
  {
    "text": "uh bottleneck is in our system say this is let's say we're Bound by memory in",
    "start": "1745039",
    "end": "1750159"
  },
  {
    "text": "this use case because we're keeping that D duplication State and we have multiple consumers on potentially one ec2 node we",
    "start": "1750159",
    "end": "1757320"
  },
  {
    "text": "know we're going to be bound by memory and so we'll set up some alarms that say Hey we've crossed some threshold 70% or",
    "start": "1757320",
    "end": "1763360"
  },
  {
    "text": "whatever threshold is determined and once that alarm goes off uh it's being",
    "start": "1763360",
    "end": "1768720"
  },
  {
    "text": "monitored by autoscaling and then it'll scale up or scale down your system okay that's a a good idea so let let's add",
    "start": "1768720",
    "end": "1775279"
  },
  {
    "text": "this Auto scaling there uh with uh cloudwatch where we can monitor our resources and scale up or down so we",
    "start": "1775279",
    "end": "1782240"
  },
  {
    "text": "have the costs under control there too um so let me reiterate we're getting the",
    "start": "1782240",
    "end": "1787840"
  },
  {
    "text": "information uh through Lambda if you can think about the the event that is trigger that transforms directly the",
    "start": "1787840",
    "end": "1793880"
  },
  {
    "text": "information there uh it senses through the Kinesis stream we have the D duplic a and we also spoke about the hotspot",
    "start": "1793880",
    "end": "1800679"
  },
  {
    "text": "management there and we move it to this uh set of hosts that will basically analyze the information and provide",
    "start": "1800679",
    "end": "1806640"
  },
  {
    "text": "visibility uh to the customers so how do we do this aggregation we spoke about",
    "start": "1806640",
    "end": "1812760"
  },
  {
    "text": "batching the information uh here in this stage so what do we need to do to aggregate the information here typically",
    "start": "1812760",
    "end": "1819279"
  },
  {
    "start": "1819000",
    "end": "1819000"
  },
  {
    "text": "when you have long running jobs you're going to utilize something like map reduce it's very common uh and we have a",
    "start": "1819279",
    "end": "1825279"
  },
  {
    "text": "thing called manifest let's the Manifest here and the idea of a manifest is you want to reduce cost when you're talking",
    "start": "1825279",
    "end": "1832279"
  },
  {
    "text": "to one of your stores and so you would group together work into a manifest and you'll pull that manifest down and it'll",
    "start": "1832279",
    "end": "1838399"
  },
  {
    "text": "let you know the amount of work that you need to do and so you've really reduced the amount of iops hitting each of your",
    "start": "1838399",
    "end": "1844000"
  },
  {
    "text": "stores and then you from that manifest you'll get a list of batches or a list of work that we said you need to execute",
    "start": "1844000",
    "end": "1849519"
  },
  {
    "text": "on and then from that you can then map those records down into a sub subset of records that you would need for ordering",
    "start": "1849519",
    "end": "1856440"
  },
  {
    "text": "uh with a single record and a single sing value okay so the the option in uh AWS for aggregating records probably",
    "start": "1856440",
    "end": "1863880"
  },
  {
    "text": "it's EMR uh so we can pick EMR we can use it with Hadoop with spark or or any",
    "start": "1863880",
    "end": "1869159"
  },
  {
    "text": "flavor that we want to use here um so let's put this and as we get the things",
    "start": "1869159",
    "end": "1874480"
  },
  {
    "text": "uh from from ec2 we can use Lambda to push them uh through uh EMR actually we",
    "start": "1874480",
    "end": "1880200"
  },
  {
    "text": "can use Lambda to schedule uh this daily job or we can actually do it on any Pace",
    "start": "1880200",
    "end": "1885440"
  },
  {
    "text": "that we want we don't need to be constrained up to the uh that because we have things buffered there so we can",
    "start": "1885440",
    "end": "1891120"
  },
  {
    "text": "take them as as we want and um we're moving it to EMR and we can set up this",
    "start": "1891120",
    "end": "1896360"
  },
  {
    "text": "EMR cluster and as I can imagine Mike here we're in Vegas we spoke about these",
    "start": "1896360",
    "end": "1901639"
  },
  {
    "text": "trillions of lights all over the miles of neon all over so we'll probably need",
    "start": "1901639",
    "end": "1907000"
  },
  {
    "text": "a huge EMR stack that is standing there waiting for uh anything that we want to",
    "start": "1907000",
    "end": "1912279"
  },
  {
    "text": "process we don't have problems of of scale um do you think that will work",
    "start": "1912279",
    "end": "1918360"
  },
  {
    "text": "I really hope we don't Design Systems like that uh we can it'll work uh but we're really underutilizing these huge",
    "start": "1918360",
    "end": "1924720"
  },
  {
    "text": "clusters because we have periodic jobs hotels are not the same size and if if we're using just the hotel to this is",
    "start": "1924720",
    "end": "1930880"
  },
  {
    "text": "the data that we need to utilize we're going to have way more nodes that we need way more map reduce tasks so we",
    "start": "1930880",
    "end": "1938159"
  },
  {
    "text": "want to really optimize that and we can do that by by knowing the amount of backlog that we have or the amount of",
    "start": "1938159",
    "end": "1944760"
  },
  {
    "text": "data that we have and then making Intelligent Decisions on managing those clusters and so if you can imagine a",
    "start": "1944760",
    "end": "1950960"
  },
  {
    "start": "1945000",
    "end": "1945000"
  },
  {
    "text": "cluster manager that knows the amount of work that's going to be executed the node times that they're going to be executed it could stand up and tear down",
    "start": "1950960",
    "end": "1957880"
  },
  {
    "text": "clusters for you before that job execution happens and so you have this cluster manager that's consistently",
    "start": "1957880",
    "end": "1964279"
  },
  {
    "text": "reading the backlog of work that's going to be executed on and then it'll stand up clusters so the bootstrap time you",
    "start": "1964279",
    "end": "1970360"
  },
  {
    "text": "don't have to pay for that bootstrap time when you're trying to execute your jobs and then when your jobs actually",
    "start": "1970360",
    "end": "1975519"
  },
  {
    "text": "start they look at the Clusters that are available say oh I can lease this cluster now",
    "start": "1975519",
    "end": "1980880"
  },
  {
    "text": "utilize an exercise on that cluster release that cluster and then it's available for another worker and because",
    "start": "1980880",
    "end": "1986600"
  },
  {
    "text": "you have the cluster manager consistently looking at the backlog of work you can also scale up and scale down those clusters so if you're no",
    "start": "1986600",
    "end": "1992360"
  },
  {
    "text": "longer going to have executions on them tear them down we don't need them anymore because we really think of them like ec2 nodes where we have some work",
    "start": "1992360",
    "end": "1999679"
  },
  {
    "text": "we need to do some work and then we're done with it we don't want to pay the cost of running these clusters for a long period of",
    "start": "1999679",
    "end": "2005559"
  },
  {
    "text": "time okay so uh for now how this looks is we get the information from the",
    "start": "2005559",
    "end": "2011080"
  },
  {
    "text": "sockets on all these hotels uh we get it through Lambda we put it also in a",
    "start": "2011080",
    "end": "2016679"
  },
  {
    "text": "streer uh we transform it and we pass it through Kinesis uh when we pass it",
    "start": "2016679",
    "end": "2022559"
  },
  {
    "text": "through Kinesis I want to reiterate the the the the tools that or the techniques that we are using here which are the D",
    "start": "2022559",
    "end": "2029240"
  },
  {
    "text": "duplication and the hotspot management uh we send it through ec2 with AOS scaling that it's already built in then",
    "start": "2029240",
    "end": "2036440"
  },
  {
    "text": "there and when we are using EMR we're adding this component of cluster management where we can smartly use this",
    "start": "2036440",
    "end": "2043440"
  },
  {
    "text": "uh as disposable resources the same thing as you said we use for ec2 where we don't care about having that stand up",
    "start": "2043440",
    "end": "2050280"
  },
  {
    "text": "all the time we can use it and then we can throw it away and spein up another one whenever we need it so that gives us",
    "start": "2050280",
    "end": "2057760"
  },
  {
    "text": "a a full picture of our processing Pipeline and now we need to actually communicate with the exterior we need to",
    "start": "2057760",
    "end": "2064320"
  },
  {
    "text": "communicate with the hotels and with the ordering systems that we might have so what options do we have there for",
    "start": "2064320",
    "end": "2070560"
  },
  {
    "text": "communicating with the external systems we deal with externally facing",
    "start": "2070560",
    "end": "2076839"
  },
  {
    "start": "2074000",
    "end": "2074000"
  },
  {
    "text": "uh entities whether it's another team or it's a different company or your",
    "start": "2076839",
    "end": "2082520"
  },
  {
    "text": "customers typically we do this in API format it's language agnostic and we can just gather that information and then",
    "start": "2082520",
    "end": "2088560"
  },
  {
    "text": "have execute some functions on that and you want to think about authorization authentication super important because",
    "start": "2088560",
    "end": "2095158"
  },
  {
    "text": "it's not behind your fence anymore uh you you need to make sure that the clients that are talking to you are your",
    "start": "2095159",
    "end": "2100640"
  },
  {
    "text": "actual light sockets and not some fictitious person ordering 5 million lights for some Customer because that",
    "start": "2100640",
    "end": "2105720"
  },
  {
    "text": "would be a terrible experience uh so security is obviously a top priority the",
    "start": "2105720",
    "end": "2111560"
  },
  {
    "text": "second thing we really want to talk about is scaling right scaling up the amount of nodes that you would need in your back end to handle all these",
    "start": "2111560",
    "end": "2118119"
  },
  {
    "text": "requests and then optimizations like caching uh where if you have somebody across the world they make the same",
    "start": "2118119",
    "end": "2124560"
  },
  {
    "text": "request over and over has to travel all the way across the world to get a Quest EST you want to cach as close to that uh",
    "start": "2124560",
    "end": "2130680"
  },
  {
    "text": "point of presence and then the last thing is protection right like now that you've coupled systems together because",
    "start": "2130680",
    "end": "2136720"
  },
  {
    "text": "they're talking to you directly you have to protect yourself against brownouts and so you do that typically with a",
    "start": "2136720",
    "end": "2142119"
  },
  {
    "text": "throttling mechanism and DS protection and so there's various tools and we're not there's an extensive list of how to",
    "start": "2142119",
    "end": "2148800"
  },
  {
    "text": "do each of these uh and you can piece this all together you can use a managed framework like Amazon's API Gateway and",
    "start": "2148800",
    "end": "2156720"
  },
  {
    "text": "it manages a lot of those solutions for you okay so um to me I like simplified",
    "start": "2156720",
    "end": "2162520"
  },
  {
    "text": "Solutions since we spoke about operationally Excellence being operationally excellent so we basically",
    "start": "2162520",
    "end": "2168119"
  },
  {
    "text": "want to do simple things uh it looks like Amazon API Gateway gives us all",
    "start": "2168119",
    "end": "2173400"
  },
  {
    "text": "what we need uh there in compound with Lambda to actually execute the functions",
    "start": "2173400",
    "end": "2178520"
  },
  {
    "text": "that we have there so that that gives us a a very good um contract there we will",
    "start": "2178520",
    "end": "2183920"
  },
  {
    "text": "have good contracts with the exterior good good good contract with the down TR",
    "start": "2183920",
    "end": "2189079"
  },
  {
    "text": "systems and then with these good contracts we can actually uh scale up or down internally in our our Pipeline and",
    "start": "2189079",
    "end": "2196240"
  },
  {
    "text": "it will be uh something that will feel completely smooth for for uh these external",
    "start": "2196240",
    "end": "2202280"
  },
  {
    "text": "systems so now uh we I think we have a good idea of how to get the information through the pipeline up to the ordering",
    "start": "2202280",
    "end": "2209280"
  },
  {
    "text": "system and we want to do the Audits and to validate that so one thing that we can do for auditing it's actually",
    "start": "2209280",
    "end": "2216599"
  },
  {
    "text": "replicating exactly the same pipeline that we have here and then compare the results at the end so we do do a line by",
    "start": "2216599",
    "end": "2223520"
  },
  {
    "text": "line comparison and what happen there is that if I push a a code bag or or if any",
    "start": "2223520",
    "end": "2229680"
  },
  {
    "text": "uh host goes bad and it corrupts the data I will be able to catch that at the end of the",
    "start": "2229680",
    "end": "2236079"
  },
  {
    "text": "pipeline now the question that I have here uh Mike it's can we simplify that",
    "start": "2236079",
    "end": "2242560"
  },
  {
    "text": "uh in some way where we don't know the ne we we spoke about the next day right so I will just know this on the next day",
    "start": "2242560",
    "end": "2249640"
  },
  {
    "text": "if I do that can I know this faster yeah failing fast is critical",
    "start": "2249640",
    "end": "2255960"
  },
  {
    "text": "right when you're dealing with especially High volumes you want to fail as fast as possible there's possibilities as you said there's",
    "start": "2255960",
    "end": "2261880"
  },
  {
    "text": "corruption in your data and so you don't want that to propagate until the all the way at the end when you're you know",
    "start": "2261880",
    "end": "2267960"
  },
  {
    "text": "getting these results for your bilding system you want to see it before the analytics happen because your customers are seeing some anomalous data and",
    "start": "2267960",
    "end": "2274680"
  },
  {
    "text": "they're what's happening and you're having to do a lot of scrambling to find out what the problem was and so if you",
    "start": "2274680",
    "end": "2281079"
  },
  {
    "text": "have to wait all the way till the end of the day that's a terrible experience so we can do this with incremental auditing",
    "start": "2281079",
    "end": "2287599"
  },
  {
    "start": "2287000",
    "end": "2287000"
  },
  {
    "text": "right where we say we have let's say a function that says color take these boxes and color them and then we can do",
    "start": "2287599",
    "end": "2294119"
  },
  {
    "text": "as you said a line by line comparison of did I color these things properly yes great our audit passes we can move on",
    "start": "2294119",
    "end": "2301160"
  },
  {
    "text": "and then maybe we have a uniqueness function and it just gets the unique colors and again we can do a line by",
    "start": "2301160",
    "end": "2307079"
  },
  {
    "text": "line compar do we get the right results yes great move on and because of that transitive property of equality we can",
    "start": "2307079",
    "end": "2313480"
  },
  {
    "text": "say a a equal B and B equal to therefore the whole pipeline is fine okay so",
    "start": "2313480",
    "end": "2318760"
  },
  {
    "text": "basically what you're saying is that when we um do each one of these steps we can actually do line by line comparison",
    "start": "2318760",
    "end": "2325680"
  },
  {
    "text": "of what we are getting and uh get a result and see if we failed we can fail fast so for instance if I push a code",
    "start": "2325680",
    "end": "2332599"
  },
  {
    "text": "back I can athor roll back and I don't need to wait till the next day because I will know right away that some something",
    "start": "2332599",
    "end": "2338000"
  },
  {
    "text": "it's wrong there um and that is great but we spoke about going from zero to 100 million records per second we will",
    "start": "2338000",
    "end": "2344680"
  },
  {
    "text": "have many many lights here is there any way to avoid the costly operation of comparing line by line because actually",
    "start": "2344680",
    "end": "2351760"
  },
  {
    "text": "we don't need that information the first thing I need to know before anything is",
    "start": "2351760",
    "end": "2357079"
  },
  {
    "text": "if I am right or if I'm wrong yeah line by line comparisons are extremely",
    "start": "2357079",
    "end": "2362440"
  },
  {
    "text": "expensive you're talking about having to sort and Shuffle data and do those comparisons a lot like would do a map",
    "start": "2362440",
    "end": "2368040"
  },
  {
    "text": "reduce uh type operation and so this is where really check summing comes in",
    "start": "2368040",
    "end": "2373680"
  },
  {
    "start": "2371000",
    "end": "2371000"
  },
  {
    "text": "right it's a digital identity for a record and you have to if you look at the source data and the result data",
    "start": "2373680",
    "end": "2379160"
  },
  {
    "text": "they're different it's hard to compare these two results and so we need to get them into a format that we can do",
    "start": "2379160",
    "end": "2384800"
  },
  {
    "text": "comparisons and so what we'll do to get a check sum is take a hashing function of our fixed and our transformed",
    "start": "2384800",
    "end": "2391640"
  },
  {
    "text": "values and then we'll times that by the aggregating value if we're going to do aggregation and so if you looked at here",
    "start": "2391640",
    "end": "2397560"
  },
  {
    "text": "when we talk about fixed values that's values that are change or static through the entire process and so as an example",
    "start": "2397560",
    "end": "2404800"
  },
  {
    "text": "you can see event type it's outage both on the source set and on the result set",
    "start": "2404800",
    "end": "2410280"
  },
  {
    "text": "and so these are fixed then if we look at transformed Fields those are fields that have",
    "start": "2410280",
    "end": "2416520"
  },
  {
    "text": "changed through the lifetime of the process so on our source side we see that client ID has been changed to best",
    "start": "2416520",
    "end": "2422319"
  },
  {
    "text": "hotel again that's the human readable time stamp has been changed and light identifer has has changed so we need to",
    "start": "2422319",
    "end": "2428960"
  },
  {
    "text": "these are our transformed Fields the next thing that we need to do is actually do the",
    "start": "2428960",
    "end": "2434240"
  },
  {
    "text": "Transformations and remove anything that is not in our result set because these were you know as we did some we didn't",
    "start": "2434240",
    "end": "2440560"
  },
  {
    "text": "need that socket identifier for our order we don't care about that necessarily for the ordering system but",
    "start": "2440560",
    "end": "2445880"
  },
  {
    "text": "we might care about it when we deliver it so we know which light to replace and so we do the filtering we do the",
    "start": "2445880",
    "end": "2452280"
  },
  {
    "text": "Transformations and now our source starts to look a little bit like our result set",
    "start": "2452280",
    "end": "2457800"
  },
  {
    "text": "and now we need to run our hashing function over both the fixed and transformed fields on both the source",
    "start": "2457800",
    "end": "2463240"
  },
  {
    "text": "and the result set so you can see here we picked md5 uh it's a 1 AE Etc trust",
    "start": "2463240",
    "end": "2469640"
  },
  {
    "text": "me this is correct uh I hope you trust me and so now we've got an identity for",
    "start": "2469640",
    "end": "2476319"
  },
  {
    "text": "the key if you will that we've done in our map reduce now if we actually move forward",
    "start": "2476319",
    "end": "2484560"
  },
  {
    "text": "we need to find our aggregating value and this is the value that in our map reduce we said this is our our value of",
    "start": "2484560",
    "end": "2490720"
  },
  {
    "text": "our key and this is how we're going to do our aggregations and then we actually need to perform the multiplication of hey we",
    "start": "2490720",
    "end": "2498560"
  },
  {
    "text": "have our hashing identity times it by the value and so then we'll get an actual identity for that record and so",
    "start": "2498560",
    "end": "2505160"
  },
  {
    "text": "uh if you see here we have an identity for the source set which is 1 AE again",
    "start": "2505160",
    "end": "2511520"
  },
  {
    "text": "your timing going up by one so it's an identity operation uh and then on the result set you time to that Identity or",
    "start": "2511520",
    "end": "2516880"
  },
  {
    "text": "that identity for the The Key by two and you get a different result and you can imagine we we tried to limit the scale",
    "start": "2516880",
    "end": "2523200"
  },
  {
    "text": "here but millions of Records right with all of these different identities so let me let me see if I'm understanding",
    "start": "2523200",
    "end": "2529520"
  },
  {
    "text": "correctly uh what you're saying basically is since we generated this digital identity through the md5 or it",
    "start": "2529520",
    "end": "2536160"
  },
  {
    "text": "can be any hashing method uh we created a unique uh way of identifying the",
    "start": "2536160",
    "end": "2541240"
  },
  {
    "text": "record and if we time it by the value that we are aggregating in reality adding up these two values uh it's the",
    "start": "2541240",
    "end": "2548480"
  },
  {
    "text": "same as multiplying the other uh value by two is that correct yeah so if you",
    "start": "2548480",
    "end": "2553800"
  },
  {
    "text": "look at the the the assertion that we make when we do our audit result we assert that the sum of the source",
    "start": "2553800",
    "end": "2560559"
  },
  {
    "text": "records are going to be that of the the sum of the result set and then we don't have to do line by line comparisons",
    "start": "2560559",
    "end": "2566880"
  },
  {
    "text": "anymore we can do this rolling aggregation or rolling check sum and we don't have to sort and Shuffle data anymore we just do an easy computation",
    "start": "2566880",
    "end": "2573920"
  },
  {
    "text": "of a sum okay that that makes sense and and let me ask you another question about",
    "start": "2573920",
    "end": "2579200"
  },
  {
    "text": "this um I I really we are trying to build an architecture that it's simple",
    "start": "2579200",
    "end": "2584800"
  },
  {
    "text": "uh enough to is there a way we can minimize this component and not to to create yet another component for this",
    "start": "2584800",
    "end": "2592359"
  },
  {
    "text": "yeah we can definitely do these in line so typically we'd perform whatever operations and if you think of them as",
    "start": "2592359",
    "end": "2598400"
  },
  {
    "text": "metadata identifiers for that record you could carry that through your system and",
    "start": "2598400",
    "end": "2603440"
  },
  {
    "text": "just consistently check hey did I do the right thing did I do the right thing did I do the right thing thing and you're consistently auditing your data as",
    "start": "2603440",
    "end": "2609880"
  },
  {
    "text": "you're processing it and so you get a nice quick failure if something was to go wrong or an intern at 3:00 am.",
    "start": "2609880",
    "end": "2616319"
  },
  {
    "text": "decided to push a code change and you're like oh my God you know you're not struggling to to find out what happened",
    "start": "2616319",
    "end": "2622040"
  },
  {
    "text": "it just fails and and then we can recover from there or roll back okay that that sounds like a good uh story",
    "start": "2622040",
    "end": "2628680"
  },
  {
    "start": "2627000",
    "end": "2627000"
  },
  {
    "text": "for auditing let me um review this architecture uh together so uh we will",
    "start": "2628680",
    "end": "2634720"
  },
  {
    "text": "get information from the smart sockets we can get as many information as we want uh through this uh contract that we",
    "start": "2634720",
    "end": "2641559"
  },
  {
    "text": "defined with the smart sockets um we will get it through API Gateway we will have their authentication authorization",
    "start": "2641559",
    "end": "2648680"
  },
  {
    "text": "uh dos control anything protecting us from the exterior uh and also caching of",
    "start": "2648680",
    "end": "2654040"
  },
  {
    "text": "the information uh with Lambda we will be able to actually get these events and",
    "start": "2654040",
    "end": "2660440"
  },
  {
    "text": "transform them as we need uh and we spoke about here about uh the human breedable and things for for the aggreg",
    "start": "2660440",
    "end": "2667480"
  },
  {
    "text": "but basically we can uh do any type of transformation of that individual record",
    "start": "2667480",
    "end": "2673240"
  },
  {
    "text": "um we're persisting this in S3 and as we go along the pipeline we will do these incremental auditing that are built in",
    "start": "2673240",
    "end": "2680680"
  },
  {
    "text": "line with our processes and we will use Kinesis as the transport layer with uh",
    "start": "2680680",
    "end": "2685880"
  },
  {
    "text": "these two techniques that uh everyone can take home which is D duplicating the information if we want to make sure that",
    "start": "2685880",
    "end": "2692119"
  },
  {
    "text": "we are doing once and only once processing um and also the spot",
    "start": "2692119",
    "end": "2697440"
  },
  {
    "text": "management or hotspot management where we can actually uh see what's going on on the charts see what's going on on the",
    "start": "2697440",
    "end": "2703480"
  },
  {
    "text": "partitions and we can scale up or down the KY stream based of that um then from",
    "start": "2703480",
    "end": "2709480"
  },
  {
    "text": "there we will uh get with Lambda to EMR where we will use here the growth",
    "start": "2709480",
    "end": "2714720"
  },
  {
    "text": "manager as we uh use the growth manager we will be able to elastically scale uh",
    "start": "2714720",
    "end": "2720520"
  },
  {
    "text": "up or down uh also the EMR clusters and uh then we will move this information uh",
    "start": "2720520",
    "end": "2726480"
  },
  {
    "text": "to the delivery uh part always keeping the global track of what's going on and with the capacity of replaying if we",
    "start": "2726480",
    "end": "2733440"
  },
  {
    "text": "need it uh so if we see that anything failed we can replay it again and it will go through the same process and uh",
    "start": "2733440",
    "end": "2740960"
  },
  {
    "text": "another interesting thing there is that we don't have even possibility of duplicates because if we replay through",
    "start": "2740960",
    "end": "2747000"
  },
  {
    "text": "that the duplication and since this is item poent we are again D duplicating",
    "start": "2747000",
    "end": "2752359"
  },
  {
    "text": "that information so any possible fail we're reducing it to",
    "start": "2752359",
    "end": "2757559"
  },
  {
    "text": "uh basically doing it on the right way uh does that make sense yeah I mean",
    "start": "2757559",
    "end": "2763400"
  },
  {
    "text": "we've really reduced our operational footprint here where at any point in time if there's a failure we're safe to",
    "start": "2763400",
    "end": "2769520"
  },
  {
    "text": "rerun and we don't have to have these really long Sops about you know configure this this way or drop this",
    "start": "2769520",
    "end": "2776319"
  },
  {
    "text": "table which I hope never happens um and so it's it's really easy for the operator to hit rerun and and and we're",
    "start": "2776319",
    "end": "2782160"
  },
  {
    "text": "good to go and we don't have to focus on operations all the time we can focus on the development or the new new ideas",
    "start": "2782160",
    "end": "2787400"
  },
  {
    "text": "that we have and again there's a lot of implementation details that obviously we didn't cover for we only have an hour",
    "start": "2787400",
    "end": "2794559"
  },
  {
    "text": "but you know it's it's very crucial that we we look at our pipelines and we have these uh best practices if you will on",
    "start": "2794559",
    "end": "2801760"
  },
  {
    "text": "both our data our compute and and then our our state and in in our team",
    "start": "2801760",
    "end": "2807160"
  },
  {
    "text": "specifically these uh techniques and these tools and also the fact that we started moving to manage Frameworks that",
    "start": "2807160",
    "end": "2814040"
  },
  {
    "text": "we we don't have to be heavily operational when we grow it allowed us to really focus on the business and that",
    "start": "2814040",
    "end": "2820440"
  },
  {
    "text": "is something that we all want to achieve in our own companies we want to focus on the business and not be operating the",
    "start": "2820440",
    "end": "2827079"
  },
  {
    "text": "systems all the time so I think we did it thank you very much everyone um we will be here for any",
    "start": "2827079",
    "end": "2835119"
  },
  {
    "text": "questions that you might have um uh down the stage so so uh please spend uh",
    "start": "2835119",
    "end": "2841240"
  },
  {
    "text": "anytime that you want with us to to respond a question Mike can can answer questions and thank you especially here",
    "start": "2841240",
    "end": "2847000"
  },
  {
    "text": "to anet uh he's part of our team and he also helped a lot with the presentation here so uh he's also available if if you",
    "start": "2847000",
    "end": "2854400"
  },
  {
    "text": "have any any other questions so thank you very much and uh please don't forget to complete your evaluations",
    "start": "2854400",
    "end": "2860850"
  },
  {
    "text": "[Applause]",
    "start": "2860850",
    "end": "2866480"
  }
]
[
  {
    "start": "0",
    "end": "25000"
  },
  {
    "text": "all right welcome everybody for our",
    "start": "180",
    "end": "3000"
  },
  {
    "text": "afternoon session glad to have you here",
    "start": "3000",
    "end": "4680"
  },
  {
    "text": "and anyone would like to join us come on",
    "start": "4680",
    "end": "6090"
  },
  {
    "text": "in we're about to do a live AWS demo",
    "start": "6090",
    "end": "8339"
  },
  {
    "text": "please welcome to the stage Sunil",
    "start": "8339",
    "end": "11249"
  },
  {
    "text": "Malia Thank You thanks thank you guys",
    "start": "11249",
    "end": "14490"
  },
  {
    "text": "for joining so today I'll describe how",
    "start": "14490",
    "end": "18119"
  },
  {
    "text": "you can train your models",
    "start": "18119",
    "end": "20820"
  },
  {
    "text": "once you've change the models deploy it",
    "start": "20820",
    "end": "22380"
  },
  {
    "text": "on servlets and create an endpoint so if",
    "start": "22380",
    "end": "26490"
  },
  {
    "start": "25000",
    "end": "80000"
  },
  {
    "text": "you look at the traditional pipeline",
    "start": "26490",
    "end": "28890"
  },
  {
    "text": "that you have at machine learning",
    "start": "28890",
    "end": "30150"
  },
  {
    "text": "whether you go from data the pre process",
    "start": "30150",
    "end": "32369"
  },
  {
    "text": "your data and then you when you create",
    "start": "32369",
    "end": "35250"
  },
  {
    "text": "your models but once that's done you're",
    "start": "35250",
    "end": "37710"
  },
  {
    "text": "looking at ok how do I get a prediction",
    "start": "37710",
    "end": "40470"
  },
  {
    "text": "API and deploy it so Amazon sage maker",
    "start": "40470",
    "end": "45360"
  },
  {
    "text": "which was announced today makes this",
    "start": "45360",
    "end": "47490"
  },
  {
    "text": "very easy where your modular from a",
    "start": "47490",
    "end": "49920"
  },
  {
    "text": "training aspect you can train your",
    "start": "49920",
    "end": "51690"
  },
  {
    "text": "scaling scale your cluster training",
    "start": "51690",
    "end": "54660"
  },
  {
    "text": "models it also has an independent",
    "start": "54660",
    "end": "56310"
  },
  {
    "text": "deployment component as well but as you",
    "start": "56310",
    "end": "60420"
  },
  {
    "text": "might have seen with serverless where",
    "start": "60420",
    "end": "62870"
  },
  {
    "text": "it's often beneficial where you might",
    "start": "62870",
    "end": "65550"
  },
  {
    "text": "not have you might just want to be",
    "start": "65550",
    "end": "67410"
  },
  {
    "text": "testing right trading really quickly on",
    "start": "67410",
    "end": "69920"
  },
  {
    "text": "certain endpoints but also you don't",
    "start": "69920",
    "end": "73710"
  },
  {
    "text": "want a dedicated infrastructure you want",
    "start": "73710",
    "end": "76530"
  },
  {
    "text": "that heavy lifting to be done by AWS so",
    "start": "76530",
    "end": "80310"
  },
  {
    "start": "80000",
    "end": "150000"
  },
  {
    "text": "from a cost perspective and also also",
    "start": "80310",
    "end": "85950"
  },
  {
    "text": "just to be able to spin up an endpoint",
    "start": "85950",
    "end": "88350"
  },
  {
    "text": "this seamlessly I've created a repo with",
    "start": "88350",
    "end": "92520"
  },
  {
    "text": "MX net all the necessary bundles but not",
    "start": "92520",
    "end": "96120"
  },
  {
    "text": "the knowledge that I created",
    "start": "96120",
    "end": "98370"
  },
  {
    "text": "Jupiter notebook which integrates with s",
    "start": "98370",
    "end": "101700"
  },
  {
    "text": "Sam which is service application Marvel",
    "start": "101700",
    "end": "105420"
  },
  {
    "text": "to be able to deploy the lambda function",
    "start": "105420",
    "end": "111330"
  },
  {
    "text": "and API gateway pretty easily so let's",
    "start": "111330",
    "end": "114690"
  },
  {
    "text": "look a little bit about the code so it",
    "start": "114690",
    "end": "118350"
  },
  {
    "text": "looks similar to any lambda function",
    "start": "118350",
    "end": "121590"
  },
  {
    "text": "where",
    "start": "121590",
    "end": "122100"
  },
  {
    "text": "of the lambda handler you get the URL in",
    "start": "122100",
    "end": "126030"
  },
  {
    "text": "this case I'm calling a predict function",
    "start": "126030",
    "end": "127799"
  },
  {
    "text": "that does the job now what's happening",
    "start": "127799",
    "end": "132150"
  },
  {
    "text": "is most of the machine learning models",
    "start": "132150",
    "end": "135360"
  },
  {
    "text": "let's say you are tend to develop may be",
    "start": "135360",
    "end": "138780"
  },
  {
    "text": "larger than the lambda deployment so the",
    "start": "138780",
    "end": "141630"
  },
  {
    "text": "lambda currently has a limit of 15 Meg's",
    "start": "141630",
    "end": "144030"
  },
  {
    "text": "zip limit so it's hard to package",
    "start": "144030",
    "end": "147510"
  },
  {
    "text": "everything so well what I did was from",
    "start": "147510",
    "end": "151770"
  },
  {
    "start": "150000",
    "end": "230000"
  },
  {
    "text": "an architecture point of view download",
    "start": "151770",
    "end": "154410"
  },
  {
    "text": "the model and keep it in memory so that",
    "start": "154410",
    "end": "156510"
  },
  {
    "text": "we can reuse so the way we can do this",
    "start": "156510",
    "end": "158940"
  },
  {
    "text": "is anything outside the lambda context",
    "start": "158940",
    "end": "162209"
  },
  {
    "text": "handler that we saw is kind of treated",
    "start": "162209",
    "end": "166050"
  },
  {
    "text": "as a global variable so or a global",
    "start": "166050",
    "end": "169470"
  },
  {
    "text": "static variable so this is not loaded or",
    "start": "169470",
    "end": "172920"
  },
  {
    "text": "initialize every time you have a request",
    "start": "172920",
    "end": "175830"
  },
  {
    "text": "it is almost cached in memory so if we",
    "start": "175830",
    "end": "178739"
  },
  {
    "text": "download the model and keep keep the",
    "start": "178739",
    "end": "181230"
  },
  {
    "text": "object outside of the context handler it",
    "start": "181230",
    "end": "183870"
  },
  {
    "text": "is persisted across request so we don't",
    "start": "183870",
    "end": "186600"
  },
  {
    "text": "pay the penalty of downloading and",
    "start": "186600",
    "end": "189030"
  },
  {
    "text": "initializing the model every time so so",
    "start": "189030",
    "end": "192209"
  },
  {
    "text": "that way you actually get the benefit of",
    "start": "192209",
    "end": "197570"
  },
  {
    "text": "you only pay the penalty once but once",
    "start": "197570",
    "end": "201329"
  },
  {
    "text": "the lambda function is being warmed up",
    "start": "201329",
    "end": "203670"
  },
  {
    "text": "you get to use it so just quickly",
    "start": "203670",
    "end": "208380"
  },
  {
    "text": "looking at the code here I'm using MX",
    "start": "208380",
    "end": "212940"
  },
  {
    "text": "net so Apache MX and I've provided all",
    "start": "212940",
    "end": "216780"
  },
  {
    "text": "the necessary libraries to be running",
    "start": "216780",
    "end": "219239"
  },
  {
    "text": "this so the model files so we specify",
    "start": "219239",
    "end": "223109"
  },
  {
    "text": "the model files one is the binary model",
    "start": "223109",
    "end": "225480"
  },
  {
    "text": "file the other one's a JSON that",
    "start": "225480",
    "end": "226890"
  },
  {
    "text": "describes the model structure and then I",
    "start": "226890",
    "end": "230760"
  },
  {
    "start": "230000",
    "end": "335000"
  },
  {
    "text": "have a function here where we do OK we",
    "start": "230760",
    "end": "234570"
  },
  {
    "text": "reload the model and this model in",
    "start": "234570",
    "end": "239040"
  },
  {
    "text": "particular we're using is a geo geo",
    "start": "239040",
    "end": "242280"
  },
  {
    "text": "lookup our geo prediction model what",
    "start": "242280",
    "end": "246150"
  },
  {
    "text": "this does is given a",
    "start": "246150",
    "end": "248700"
  },
  {
    "text": "it's going to tell you where the image",
    "start": "248700",
    "end": "251010"
  },
  {
    "text": "was taken",
    "start": "251010",
    "end": "251819"
  },
  {
    "text": "it doesn't use like the XF data has",
    "start": "251819",
    "end": "254099"
  },
  {
    "text": "actually trained on a bunch of images",
    "start": "254099",
    "end": "257549"
  },
  {
    "text": "that were taken for a particular",
    "start": "257549",
    "end": "259289"
  },
  {
    "text": "location and so this was this was built",
    "start": "259289",
    "end": "262860"
  },
  {
    "text": "using the multimedia commons data set",
    "start": "262860",
    "end": "266039"
  },
  {
    "text": "which had like the geo coordinates and",
    "start": "266039",
    "end": "269880"
  },
  {
    "text": "it was restrained using that so roughly",
    "start": "269880",
    "end": "272880"
  },
  {
    "text": "around five hundred thousand images that",
    "start": "272880",
    "end": "276240"
  },
  {
    "text": "the model was trained on so the model",
    "start": "276240",
    "end": "278280"
  },
  {
    "text": "outputs is given an image it gives you",
    "start": "278280",
    "end": "280860"
  },
  {
    "text": "the latitude and longitude and what I've",
    "start": "280860",
    "end": "283259"
  },
  {
    "text": "done is I use on a Geo pie library here",
    "start": "283259",
    "end": "286110"
  },
  {
    "text": "to do a reverse lookup",
    "start": "286110",
    "end": "289638"
  },
  {
    "text": "so it's the GOP library",
    "start": "294990",
    "end": "299930"
  },
  {
    "text": "it doesn't do reverse lookups are given",
    "start": "303000",
    "end": "304979"
  },
  {
    "text": "a lap long it gives you the the city and",
    "start": "304979",
    "end": "309000"
  },
  {
    "text": "the address of very things that images",
    "start": "309000",
    "end": "311479"
  },
  {
    "text": "so once we have done cure what we can do",
    "start": "311479",
    "end": "315870"
  },
  {
    "text": "is we write the file so it's it's easy",
    "start": "315870",
    "end": "320610"
  },
  {
    "text": "to edit the lambda code in the Jupiter",
    "start": "320610",
    "end": "322830"
  },
  {
    "text": "notebook you can execute the cell it",
    "start": "322830",
    "end": "324810"
  },
  {
    "text": "creates a lambda function file and the",
    "start": "324810",
    "end": "327960"
  },
  {
    "text": "next thing is we can actually we need to",
    "start": "327960",
    "end": "331530"
  },
  {
    "text": "zip the file so all that is provided",
    "start": "331530",
    "end": "333599"
  },
  {
    "text": "here and here's a handy function to just",
    "start": "333599",
    "end": "338039"
  },
  {
    "text": "update the coders to the case so several",
    "start": "338039",
    "end": "341550"
  },
  {
    "text": "occasion model uses two files so it uses",
    "start": "341550",
    "end": "345090"
  },
  {
    "text": "a two llamo files template um oh the",
    "start": "345090",
    "end": "348210"
  },
  {
    "text": "Stryker file to define the prediction",
    "start": "348210",
    "end": "350460"
  },
  {
    "text": "define the API a gateway endpoints so",
    "start": "350460",
    "end": "352740"
  },
  {
    "text": "all you need to do is substitute your",
    "start": "352740",
    "end": "354900"
  },
  {
    "text": "account ID and the helper code here",
    "start": "354900",
    "end": "359039"
  },
  {
    "text": "writes that for you and then it uploads",
    "start": "359039",
    "end": "362550"
  },
  {
    "text": "that to a your s3 bucket and your lambda",
    "start": "362550",
    "end": "366570"
  },
  {
    "text": "function zip file as well then the next",
    "start": "366570",
    "end": "369810"
  },
  {
    "text": "thing is you use the AWS CloudFormation",
    "start": "369810",
    "end": "373759"
  },
  {
    "text": "template to create the confirmation",
    "start": "373759",
    "end": "376440"
  },
  {
    "text": "stack and once you package you first",
    "start": "376440",
    "end": "381180"
  },
  {
    "text": "package it once then you create the",
    "start": "381180",
    "end": "382919"
  },
  {
    "text": "create the actual file and once you have",
    "start": "382919",
    "end": "387030"
  },
  {
    "text": "done that it actually gives you an API",
    "start": "387030",
    "end": "389759"
  },
  {
    "text": "endpoint and all that is automated so",
    "start": "389759",
    "end": "391979"
  },
  {
    "text": "you just literally need to just",
    "start": "391979",
    "end": "393780"
  },
  {
    "text": "substitute with your account ID the rest",
    "start": "393780",
    "end": "395969"
  },
  {
    "text": "of the deployment is automated so let's",
    "start": "395969",
    "end": "400590"
  },
  {
    "text": "let's take a look at you know how the",
    "start": "400590",
    "end": "402419"
  },
  {
    "text": "model I've already in interest of time",
    "start": "402419",
    "end": "404039"
  },
  {
    "text": "already deployed the model so let's",
    "start": "404039",
    "end": "406560"
  },
  {
    "start": "405000",
    "end": "525000"
  },
  {
    "text": "actually look at this",
    "start": "406560",
    "end": "409299"
  },
  {
    "text": "any guesses as to where this is the",
    "start": "409299",
    "end": "415099"
  },
  {
    "text": "Statue of Liberty in New York right so",
    "start": "415099",
    "end": "418519"
  },
  {
    "text": "let's actually execute and see again",
    "start": "418519",
    "end": "423339"
  },
  {
    "text": "sorry",
    "start": "423339",
    "end": "426339"
  },
  {
    "text": "let me get again",
    "start": "429650",
    "end": "432470"
  },
  {
    "text": "that says it's not happen community",
    "start": "432470",
    "end": "434660"
  },
  {
    "text": "board number one so Statue of Liberty",
    "start": "434660",
    "end": "436670"
  },
  {
    "text": "Liberty Island so it'll actually guessed",
    "start": "436670",
    "end": "439790"
  },
  {
    "text": "the image correctly so maybe we'll do",
    "start": "439790",
    "end": "444230"
  },
  {
    "text": "we'll have more fun right like how many",
    "start": "444230",
    "end": "446420"
  },
  {
    "text": "of you how many other Statue of",
    "start": "446420",
    "end": "448310"
  },
  {
    "text": "Liberty's or replicas do you think there",
    "start": "448310",
    "end": "450500"
  },
  {
    "text": "are there's one right here in Vegas so",
    "start": "450500",
    "end": "455300"
  },
  {
    "text": "that's actually so I I have an image",
    "start": "455300",
    "end": "460730"
  },
  {
    "text": "here",
    "start": "460730",
    "end": "463420"
  },
  {
    "text": "sorry that's not the one",
    "start": "466100",
    "end": "469600"
  },
  {
    "text": "we can try that like we can try the",
    "start": "485539",
    "end": "487599"
  },
  {
    "text": "Eiffel Tower so this is the Eiffel Tower",
    "start": "487599",
    "end": "494379"
  },
  {
    "text": "in Paris so",
    "start": "494379",
    "end": "498939"
  },
  {
    "text": "it does detect it in Paris I just wanted",
    "start": "503170",
    "end": "506980"
  },
  {
    "text": "to give it a little fun one right like",
    "start": "506980",
    "end": "509760"
  },
  {
    "text": "so this is actually the Statute of",
    "start": "509760",
    "end": "511930"
  },
  {
    "text": "Liberty if you didn't know this is",
    "start": "511930",
    "end": "513340"
  },
  {
    "text": "actually Statue of Liberty in Paris",
    "start": "513340",
    "end": "514960"
  },
  {
    "text": "that's the other one that the French",
    "start": "514960",
    "end": "517510"
  },
  {
    "text": "could give the Americans so let's see if",
    "start": "517510",
    "end": "521469"
  },
  {
    "text": "I can detect so it was able to detect",
    "start": "521470",
    "end": "526090"
  },
  {
    "text": "that it was actually friends so it's a",
    "start": "526090",
    "end": "528790"
  },
  {
    "text": "pretty good model but as you can see",
    "start": "528790",
    "end": "530290"
  },
  {
    "text": "more importantly as you see it was so",
    "start": "530290",
    "end": "532270"
  },
  {
    "text": "easy to deploy a model and the response",
    "start": "532270",
    "end": "535330"
  },
  {
    "text": "times have been pretty fast when you",
    "start": "535330",
    "end": "537100"
  },
  {
    "text": "think about the model has to download",
    "start": "537100",
    "end": "538690"
  },
  {
    "text": "the image and go to the process and the",
    "start": "538690",
    "end": "541060"
  },
  {
    "text": "model here is about 400 Meg's",
    "start": "541060",
    "end": "543310"
  },
  {
    "text": "so it's a pretty pretty heavy model so",
    "start": "543310",
    "end": "548350"
  },
  {
    "text": "what I what I've done was actually",
    "start": "548350",
    "end": "550060"
  },
  {
    "text": "benchmark",
    "start": "550060",
    "end": "551160"
  },
  {
    "text": "the model to see hey what is the latency",
    "start": "551160",
    "end": "555850"
  },
  {
    "text": "that we see when we do something as",
    "start": "555850",
    "end": "558610"
  },
  {
    "text": "heavy as that and we get about a average",
    "start": "558610",
    "end": "562330"
  },
  {
    "text": "latency of 1.2 seconds from San",
    "start": "562330",
    "end": "565870"
  },
  {
    "text": "Francisco to us yeah West - that is",
    "start": "565870",
    "end": "569410"
  },
  {
    "text": "Oregon but also his kind of a benchmark",
    "start": "569410",
    "end": "573520"
  },
  {
    "text": "all over the world as you can see",
    "start": "573520",
    "end": "576090"
  },
  {
    "text": "everything under about a second and a",
    "start": "576090",
    "end": "579340"
  },
  {
    "text": "half so it's near real-time you can",
    "start": "579340",
    "end": "582520"
  },
  {
    "text": "achieve their real-time predictions for",
    "start": "582520",
    "end": "584830"
  },
  {
    "text": "really heavy models using Apache MX net",
    "start": "584830",
    "end": "589570"
  },
  {
    "text": "or lambda which makes it a pretty viable",
    "start": "589570",
    "end": "591610"
  },
  {
    "text": "option for you to use this to deploy and",
    "start": "591610",
    "end": "595660"
  },
  {
    "text": "build your inference on lambda so it's",
    "start": "595660",
    "end": "600310"
  },
  {
    "text": "not just restricted to so the code is",
    "start": "600310",
    "end": "603760"
  },
  {
    "text": "actually available if you go to AWS lab",
    "start": "603760",
    "end": "606430"
  },
  {
    "text": "slash an excellent lambda the code is",
    "start": "606430",
    "end": "610030"
  },
  {
    "text": "available here and open sourced but",
    "start": "610030",
    "end": "613000"
  },
  {
    "text": "there's also",
    "start": "613000",
    "end": "615570"
  },
  {
    "text": "so Kenner's which is another very",
    "start": "616779",
    "end": "619660"
  },
  {
    "text": "popular deep learning framework I've",
    "start": "619660",
    "end": "623769"
  },
  {
    "text": "made that available as well in the",
    "start": "623769",
    "end": "629740"
  },
  {
    "text": "github repo is a Karass package where",
    "start": "629740",
    "end": "632170"
  },
  {
    "text": "instead of using MX and you can use",
    "start": "632170",
    "end": "634240"
  },
  {
    "text": "cameras with the tensorflow back-end and",
    "start": "634240",
    "end": "636910"
  },
  {
    "text": "deployed similar in a similar fashion to",
    "start": "636910",
    "end": "640660"
  },
  {
    "text": "what we saw with MX now",
    "start": "640660",
    "end": "644610"
  },
  {
    "text": "so I just wanted to show one other image",
    "start": "646210",
    "end": "650290"
  },
  {
    "text": "right like we we looked at all the",
    "start": "650290",
    "end": "652120"
  },
  {
    "text": "popular ones so wanted to kind of get",
    "start": "652120",
    "end": "655660"
  },
  {
    "text": "this image which is",
    "start": "655660",
    "end": "659790"
  },
  {
    "text": "this is actually small bird which is one",
    "start": "663750",
    "end": "666900"
  },
  {
    "text": "of the remotest inhabited regions in",
    "start": "666900",
    "end": "671460"
  },
  {
    "text": "Norway",
    "start": "671460",
    "end": "672690"
  },
  {
    "text": "so let's actually try and see if we can",
    "start": "672690",
    "end": "676560"
  },
  {
    "text": "detect that I was able to get it was in",
    "start": "676560",
    "end": "680130"
  },
  {
    "text": "small bar Norway so that's what I had an",
    "start": "680130",
    "end": "684630"
  },
  {
    "text": "in-store today for a demo so with with",
    "start": "684630",
    "end": "688890"
  },
  {
    "text": "the benchmarks that we've seen it's a",
    "start": "688890",
    "end": "690300"
  },
  {
    "text": "pretty wild option to be using lambda",
    "start": "690300",
    "end": "693360"
  },
  {
    "text": "and you can expect more enhancements in",
    "start": "693360",
    "end": "696510"
  },
  {
    "text": "terms of a bit of contributed like an",
    "start": "696510",
    "end": "699540"
  },
  {
    "text": "a/b testing module and so on where you",
    "start": "699540",
    "end": "703260"
  },
  {
    "text": "can have multiple models and track which",
    "start": "703260",
    "end": "706110"
  },
  {
    "text": "one is doing better so thanks for",
    "start": "706110",
    "end": "708810"
  },
  {
    "text": "listening in and I'll be here for a",
    "start": "708810",
    "end": "711090"
  },
  {
    "text": "question thank you thank you Sunil",
    "start": "711090",
    "end": "715760"
  }
]
[
  {
    "text": "Hi, and welcome to 'This is My Architecture.'",
    "start": "7008",
    "end": "9825"
  },
  {
    "text": "Today, I'm with Andreas from 1plusX.",
    "start": "9825",
    "end": "12787"
  },
  {
    "text": "- Hi, Andreas.\n- Hi, Ross.",
    "start": "12787",
    "end": "14497"
  },
  {
    "text": "What can you tell us about 1plusX?",
    "start": "14497",
    "end": "16617"
  },
  {
    "text": "1plusX is a Swiss company\nwho has a software-as-a-service product",
    "start": "16617",
    "end": "20431"
  },
  {
    "text": "which is a data management platform.",
    "start": "20431",
    "end": "22602"
  },
  {
    "text": "And this is a software or product\nthat media companies, publishers, and marketers",
    "start": "22602",
    "end": "27810"
  },
  {
    "text": "can use to ingest, process, enrich, \nand activate the user data.",
    "start": "27811",
    "end": "32264"
  },
  {
    "text": "All right, and what part of 1plusX\nare we going to be talking about today?",
    "start": "32264",
    "end": "36035"
  },
  {
    "text": "So we're actually going to talk about \nthe core of the data management platform",
    "start": "36035",
    "end": "40091"
  },
  {
    "text": "where we go from events data\nto user profiles.",
    "start": "40091",
    "end": "43905"
  },
  {
    "text": "All right, I'm looking forward to it.",
    "start": "43905",
    "end": "44975"
  },
  {
    "text": "Why don't you start taking us through\nwhat we see on the board here?",
    "start": "44976",
    "end": "47336"
  },
  {
    "text": "Yes, so we can try to follow an event\nas it flows through the system,",
    "start": "47336",
    "end": "51708"
  },
  {
    "text": "so it's a streaming based system\nthat has Kafka as a backbone.",
    "start": "51708",
    "end": "55289"
  },
  {
    "text": "So when we start with an event,",
    "start": "55289",
    "end": "58290"
  },
  {
    "text": "where a user visits a website \nof our customers,",
    "start": "58290",
    "end": "60918"
  },
  {
    "text": "say the user reads an article\nabout the Olympics,",
    "start": "60918",
    "end": "63659"
  },
  {
    "text": "then the event will come in here\ninto our ingestion component",
    "start": "63659",
    "end": "67491"
  },
  {
    "text": "which runs on ECS.",
    "start": "67491",
    "end": "68875"
  },
  {
    "text": "Here, it will be cleaned, processed,\nand prepared for the internal processing.",
    "start": "68875",
    "end": "74168"
  },
  {
    "text": "And it will go here to Kafka\nand will also go to S3.",
    "start": "74168",
    "end": "80896"
  },
  {
    "text": "Then in the next step, we go to the aggregation\nand machine learning step.",
    "start": "82625",
    "end": "85723"
  },
  {
    "text": "So here we actually go from event-level data,",
    "start": "85723",
    "end": "89060"
  },
  {
    "text": "so data that says\na user did something at a certain point in time,",
    "start": "89060",
    "end": "92282"
  },
  {
    "text": "to attributes for users,\nso making statements about users.",
    "start": "92282",
    "end": "96076"
  },
  {
    "text": "A simple attribute could be\nwhat is the total number of events",
    "start": "96076",
    "end": "99040"
  },
  {
    "text": "that this user had in the past,",
    "start": "99041",
    "end": "100783"
  },
  {
    "text": "but there are also more complicated attributes",
    "start": "100783",
    "end": "102584"
  },
  {
    "text": "and that's why I put the machine learning here.",
    "start": "102584",
    "end": "104625"
  },
  {
    "text": "For example, to predict the gender\nof the user based on their past behavior.",
    "start": "104625",
    "end": "109322"
  },
  {
    "text": "This is happening in this step.",
    "start": "109322",
    "end": "111680"
  },
  {
    "text": "After that, we have the data again in Kafka",
    "start": "112451",
    "end": "117113"
  },
  {
    "text": "so the outputs here are the user attributes.",
    "start": "117113",
    "end": "119014"
  },
  {
    "text": "We go to the next step,\nthe profile step.",
    "start": "119014",
    "end": "121215"
  },
  {
    "text": "So, again, here we have a connection.",
    "start": "121215",
    "end": "123173"
  },
  {
    "text": "So here we basically combine\nall the user attribute data",
    "start": "123173",
    "end": "128423"
  },
  {
    "text": "that we have computed in this previous step.",
    "start": "128424",
    "end": "130838"
  },
  {
    "text": "Since we had, in the previous step,\ndifferent components",
    "start": "130839",
    "end": "133479"
  },
  {
    "text": "that we're computing user attributes here,\nwe combine them in that profile step.",
    "start": "133479",
    "end": "137891"
  },
  {
    "text": "And we actually also have a storage here,\na Couchbase database",
    "start": "137891",
    "end": "142133"
  },
  {
    "text": "and also an Elasticsearch\nto represent the data.",
    "start": "142133",
    "end": "145336"
  },
  {
    "text": "What we also do here is\nwe compute so-called audiences.",
    "start": "146678",
    "end": "150721"
  },
  {
    "text": "Audiences are groups of users\nthat are customer-defined.",
    "start": "150721",
    "end": "153907"
  },
  {
    "text": "For example, the customer could define,\n\"I want everybody who's interested in the Olympics.\"",
    "start": "153907",
    "end": "158099"
  },
  {
    "text": "And since our user that you are following\nthrough the system",
    "start": "158099",
    "end": "160797"
  },
  {
    "text": "here has now shown that they're interested\nin the Olympics,",
    "start": "160797",
    "end": "163273"
  },
  {
    "text": "this user will be part of that audience.",
    "start": "163273",
    "end": "165517"
  },
  {
    "text": "This information goes back to Kafka\nand then goes into the serving part of the system",
    "start": "165518",
    "end": "171799"
  },
  {
    "text": "which is again an ECS service with a Couchbase database.",
    "start": "171799",
    "end": "174851"
  },
  {
    "text": "And here the data, this audience membership data,",
    "start": "174852",
    "end": "177403"
  },
  {
    "text": "is indexed such that it can be accessed\nwhen the customer clears it.",
    "start": "177403",
    "end": "181863"
  },
  {
    "text": "Okay, so that provides some level\nof separation",
    "start": "181863",
    "end": "184630"
  },
  {
    "text": "between, we have, real-time streaming, essentially, here\ncoming through Kafka",
    "start": "184630",
    "end": "188240"
  },
  {
    "text": "and you storing some sort of view of that data here.",
    "start": "188240",
    "end": "192983"
  },
  {
    "text": "How does that affect the design of the system?",
    "start": "192983",
    "end": "196619"
  },
  {
    "text": "What happens if your real-time streaming goes down?",
    "start": "196619",
    "end": "198560"
  },
  {
    "text": "What is the effect on how your users\nare able to continue using your system?",
    "start": "198560",
    "end": "203172"
  },
  {
    "text": "Yes, so in general we want, of course,\nbe fault tolerant, we want to be highly available,",
    "start": "203172",
    "end": "206644"
  },
  {
    "text": "but we're also dealing with massive volumes of data.",
    "start": "206644",
    "end": "208987"
  },
  {
    "text": "So a typical customer would have\nmultiple billions of events per month",
    "start": "208988",
    "end": "212798"
  },
  {
    "text": "and tens of millions of profiles.",
    "start": "212798",
    "end": "214878"
  },
  {
    "text": "And we want to do this whole thing\ncost-effectively.",
    "start": "214878",
    "end": "216958"
  },
  {
    "text": "So the solution that we came up with\nfor this",
    "start": "216958",
    "end": "219284"
  },
  {
    "text": "is that we have two different\nfault-tolerant strategies",
    "start": "219284",
    "end": "222300"
  },
  {
    "text": "for the periphery of the system ingestion\nand serving part and the core.",
    "start": "222300",
    "end": "226011"
  },
  {
    "text": "So for the periphery\nwhere we have the interfaces to the customer,",
    "start": "226011",
    "end": "229617"
  },
  {
    "text": "we have distribution to multiple availability zones.",
    "start": "229617",
    "end": "233519"
  },
  {
    "text": "We have autoscaling, load balancers, everything.",
    "start": "233519",
    "end": "236726"
  },
  {
    "text": "We have replication in the database and so on,",
    "start": "236727",
    "end": "239102"
  },
  {
    "text": "so we try to keep this\nworking at all times.",
    "start": "239102",
    "end": "241013"
  },
  {
    "text": "In the core, we actually embrace failure\ninstead of trying to avoid failure.",
    "start": "241013",
    "end": "245771"
  },
  {
    "text": "So we have this Kafka, we have these services,\nand these databases",
    "start": "245771",
    "end": "249431"
  },
  {
    "text": "only in one availability zone.",
    "start": "249431",
    "end": "250599"
  },
  {
    "text": "So some of those databases\nare even not replicated.",
    "start": "250599",
    "end": "253964"
  },
  {
    "text": "You can say, \"Okay, how can you do that?\"",
    "start": "253964",
    "end": "255799"
  },
  {
    "text": "So the thing is we have mechanisms",
    "start": "255799",
    "end": "257988"
  },
  {
    "text": "to recover the data\nwhenever we have corrupt data anywhere",
    "start": "257989",
    "end": "261491"
  },
  {
    "text": "that we can employ within minutes\nto hours.",
    "start": "261491",
    "end": "264548"
  },
  {
    "text": "Basically, recreate any state here\nin any part of the system.",
    "start": "264548",
    "end": "268243"
  },
  {
    "text": "Okay, I want to go back to a number\nyou dropped there when you were describing that,",
    "start": "268243",
    "end": "273143"
  },
  {
    "text": "when you spoke about billions of events\nfor a user.",
    "start": "273143",
    "end": "276191"
  },
  {
    "text": "What affect does that have \non scaling the infrastructure that we see?",
    "start": "276191",
    "end": "279639"
  },
  {
    "text": "Yeah, so all the components\nthat we use have to be inherently scalable.",
    "start": "279639",
    "end": "283559"
  },
  {
    "text": "So we use ECS Fargate.",
    "start": "283559",
    "end": "285477"
  },
  {
    "text": "We don't run our own clusters.",
    "start": "285477",
    "end": "286827"
  },
  {
    "text": "We think it's great that we can just run services \nas containers, basically,",
    "start": "286827",
    "end": "290816"
  },
  {
    "text": "and don't think of clusters,",
    "start": "290816",
    "end": "292056"
  },
  {
    "text": "but then we can use autoscaling\nalso here to adjust to changing load.",
    "start": "292056",
    "end": "295825"
  },
  {
    "text": "For example, at night, of course,\nwe have less load,",
    "start": "295825",
    "end": "297549"
  },
  {
    "text": "less traffic on websites\nthan during the day.",
    "start": "297549",
    "end": "299929"
  },
  {
    "text": "We have EMR here\nwhich we use in combination with S3 actually.",
    "start": "299929",
    "end": "305746"
  },
  {
    "text": "So we don't have an HDFS.",
    "start": "305747",
    "end": "308271"
  },
  {
    "text": "We don't have one single EMR cluster.",
    "start": "308271",
    "end": "310692"
  },
  {
    "text": "We have the data in S3\nand we dynamically spawn EMR clusters",
    "start": "310692",
    "end": "315936"
  },
  {
    "text": "based on the demand that we currently have.",
    "start": "315937",
    "end": "318277"
  },
  {
    "text": "And we can run hundreds of nodes\nif we need to for a big job",
    "start": "318277",
    "end": "321502"
  },
  {
    "text": "or just five nodes\nfor some small experiment.",
    "start": "321502",
    "end": "324187"
  },
  {
    "text": "Okay, and then one other thing,",
    "start": "324187",
    "end": "326377"
  },
  {
    "text": "seeing you're a Swiss company,\nyou have a lot of customers within Europe,",
    "start": "326377",
    "end": "329611"
  },
  {
    "text": "GDPR always comes up in these discussions.",
    "start": "329611",
    "end": "331841"
  },
  {
    "text": "How does that affect \nwhat you have?",
    "start": "331842",
    "end": "333889"
  },
  {
    "text": "Yes, that's a challenge.\nSo under GDPR,",
    "start": "333889",
    "end": "336281"
  },
  {
    "text": "users have the right\nto delete their data at any point.",
    "start": "336281",
    "end": "339408"
  },
  {
    "text": "So when a user requests the deletion,",
    "start": "339408",
    "end": "341222"
  },
  {
    "text": "we have to make sure that it's gone\nfrom all these databases",
    "start": "341222",
    "end": "343826"
  },
  {
    "text": "within a reasonable amount of time.",
    "start": "343826",
    "end": "345749"
  },
  {
    "text": "So this conflicts with a typical pattern\naround Kafka here",
    "start": "345749",
    "end": "349930"
  },
  {
    "text": "like this event sourcing pattern\nwhere you would typically keep your event data for very long.",
    "start": "349930",
    "end": "354108"
  },
  {
    "text": "Such and in case of a failure\nor some kind of need to restore a system state.",
    "start": "354109",
    "end": "359875"
  },
  {
    "text": "You can go back, you can basically rewind\nand just replay everything.",
    "start": "359875",
    "end": "363461"
  },
  {
    "text": "Now, if this data is user data\nand this user has requested the deletion of their data,",
    "start": "363461",
    "end": "369381"
  },
  {
    "text": "you cannot do that.\nThat's problematic.",
    "start": "369381",
    "end": "372134"
  },
  {
    "text": "In Kafka, you cannot really delete\nrecords by key.",
    "start": "372134",
    "end": "375721"
  },
  {
    "text": "So what we came up with here\nis mainly in these components,",
    "start": "375721",
    "end": "380803"
  },
  {
    "text": "so actually when we go from events\nto user level data,",
    "start": "380803",
    "end": "385010"
  },
  {
    "text": "we use a combination of batch\nand stream processing.",
    "start": "385010",
    "end": "389557"
  },
  {
    "text": "And we only keep a short history\nof events in Kafka",
    "start": "389557",
    "end": "392922"
  },
  {
    "text": "that automatically expire,\nso the user deletion is granted.",
    "start": "392922",
    "end": "396560"
  },
  {
    "text": "And we keep files for historical data\nin S3 where we run deletion jobs.",
    "start": "396560",
    "end": "401514"
  },
  {
    "text": "And we compute the result of the whole component\nof the whole aggregation,",
    "start": "401515",
    "end": "405593"
  },
  {
    "text": "maybe the event count that I mentioned before\nor the gender probability",
    "start": "405593",
    "end": "408770"
  },
  {
    "text": "as a combination of results\nof a batch job running on EMR.",
    "start": "408770",
    "end": "412358"
  },
  {
    "text": "And the computation that runs on ECS\non the newest events.",
    "start": "412358",
    "end": "416172"
  },
  {
    "text": "That is great to hear.",
    "start": "416172",
    "end": "417552"
  },
  {
    "text": "It's always a challenge for customers\nto implement GDPR correctly.",
    "start": "417552",
    "end": "421256"
  },
  {
    "text": "Andreas, so I got to say\nthank you for joining us today",
    "start": "421256",
    "end": "424163"
  },
  {
    "text": "and sharing the architecture\nof 1plusX.",
    "start": "424163",
    "end": "426733"
  },
  {
    "text": "Thanks for having me.",
    "start": "426733",
    "end": "428489"
  },
  {
    "text": "And thank you for watching 'This is My Architecture.'",
    "start": "428489",
    "end": "430267"
  }
]
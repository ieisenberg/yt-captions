[
  {
    "start": "0",
    "end": "82000"
  },
  {
    "text": "my name is Darren brisk wind I am from Amazon Web Services I as I",
    "start": "1460",
    "end": "6960"
  },
  {
    "text": "like to tell people have the easiest job at AWS as I I'm a Technical Evangelist",
    "start": "6960",
    "end": "12809"
  },
  {
    "text": "for databases so my job is it getting nerds excited about data this is not",
    "start": "12809",
    "end": "18720"
  },
  {
    "text": "hard so if you're a nerd who thinks day's exciting this is the right room for you because today we're going to",
    "start": "18720",
    "end": "25590"
  },
  {
    "text": "talk about if the two of the tea's are silent you have to decide which two of",
    "start": "25590",
    "end": "31410"
  },
  {
    "text": "the tea's are silent but if twitch comes from if this then that is a organization",
    "start": "31410",
    "end": "38640"
  },
  {
    "text": "that does these amazing mashups of apps and you're going to hear today from",
    "start": "38640",
    "end": "44940"
  },
  {
    "text": "Nicolas Silva who will give in detail about both what if does and how it works",
    "start": "44940",
    "end": "50820"
  },
  {
    "text": "with ElastiCache and Redis so I think of Nicolas as one of the code ninjas that",
    "start": "50820",
    "end": "57690"
  },
  {
    "text": "these little guys are supposed to represent because you know if you've ever watched a movie you know that one",
    "start": "57690",
    "end": "63930"
  },
  {
    "text": "ninja is an undefeatable ultimate force and two or more ninjas always lose so",
    "start": "63930",
    "end": "70619"
  },
  {
    "text": "that's why you have Nicolas here alone because if you're a ninja you have to avoid your co-workers but he's going to",
    "start": "70619",
    "end": "77369"
  },
  {
    "text": "tell us a lot about how it works and how it uses ElastiCache but first I get to tell you a little bit about ElastiCache",
    "start": "77369",
    "end": "83189"
  },
  {
    "start": "82000",
    "end": "336000"
  },
  {
    "text": "so how many people here have used ElastiCache and you're all on one side",
    "start": "83189",
    "end": "91049"
  },
  {
    "text": "of the room that's an interesting spread okay well ElastiCache for those not familiar with",
    "start": "91049",
    "end": "97049"
  },
  {
    "text": "or even those who are is a service that's been part of AWS for a very long time and it started with memcache D and",
    "start": "97049",
    "end": "103950"
  },
  {
    "text": "memcache D is a terrific caching technology it's still great but it hasn't really changed much in many years",
    "start": "103950",
    "end": "109259"
  },
  {
    "text": "because it's one of those kind of traditional UNIX tools that does one thing which is caching and does it really well in 2009 a team in Italy",
    "start": "109259",
    "end": "118530"
  },
  {
    "text": "created a product called Redis that was designed to address some of the deficiencies of memcache and add a lot",
    "start": "118530",
    "end": "125040"
  },
  {
    "text": "more functionality and we're seeing memcache as by far the most common and popular engine within Amazon ElastiCache",
    "start": "125040",
    "end": "131459"
  },
  {
    "text": "and it does a lot more than cat I'll talk about that a bit but I want to say a few words about what makes Redis",
    "start": "131459",
    "end": "137640"
  },
  {
    "text": "and Amazon ElastiCache different than getting open-source Redis off of github and running it on a c2 which you can do",
    "start": "137640",
    "end": "143850"
  },
  {
    "text": "and that's great but we do a few things that are different so like any other Redis it's a in-memory key value store",
    "start": "143850",
    "end": "151560"
  },
  {
    "text": "that's very high performance okay what does that actually mean the average get or set time for a 4k",
    "start": "151560",
    "end": "158310"
  },
  {
    "text": "object just are roughly our average object size it's about 400 to 450",
    "start": "158310",
    "end": "164239"
  },
  {
    "text": "microseconds right less than half a millisecond now very rarely do people",
    "start": "164239",
    "end": "170670"
  },
  {
    "text": "really care about the difference between half a millisecond in one millisecond what makes that speed interesting is that how much throughput you can get",
    "start": "170670",
    "end": "177050"
  },
  {
    "text": "with ElastiCache today we have customers that have achieved over 4.5 million",
    "start": "177050",
    "end": "183030"
  },
  {
    "text": "writes per second and 20 million reads per second on ElastiCache cluster so",
    "start": "183030",
    "end": "188850"
  },
  {
    "text": "we're able to scale to very high throughput and we can do that cus it's in memory now the downside of being in",
    "start": "188850",
    "end": "196170"
  },
  {
    "text": "memory is it's all in memory so your storage is limited to the memory ElastiCache today that means you could",
    "start": "196170",
    "end": "201989"
  },
  {
    "text": "have up to 3.5 terabytes in our largest cluster but it runs anywhere from a t2 micro that will hold about 500 megabytes",
    "start": "201989",
    "end": "209220"
  },
  {
    "text": "up to a cluster with 15 shards of our through our 3/8 extra-large that's how",
    "start": "209220",
    "end": "215970"
  },
  {
    "text": "you get to 53 and a half terabytes it gives us a wide range and of course it's",
    "start": "215970",
    "end": "221010"
  },
  {
    "text": "a fully managed environment with no administration now those of you have ever run your own Redis environment it's not hard to install Redis it's not hard",
    "start": "221010",
    "end": "227370"
  },
  {
    "text": "to run Redis it's hard to do is run high availability successfully and why is",
    "start": "227370",
    "end": "233070"
  },
  {
    "text": "that it's like any other data I have environment there's a thousand little details and if you get 999 right that's",
    "start": "233070",
    "end": "239070"
  },
  {
    "text": "not good enough because it won't work when you have the emergency when you use managed environment we take care of that",
    "start": "239070",
    "end": "245579"
  },
  {
    "text": "and by the way it's less expensive to do high availability and ElastiCache than",
    "start": "245579",
    "end": "251040"
  },
  {
    "text": "open source because there's no cross AZ data transfer costs so when I put my",
    "start": "251040",
    "end": "256079"
  },
  {
    "text": "replicas in different availability zones with elastic cache it cost you nothing to copy that data if you're using open",
    "start": "256079",
    "end": "261900"
  },
  {
    "text": "source you're gonna have to pay the data transfer it's not a huge cost difference but be significant we've also done some work",
    "start": "261900",
    "end": "269020"
  },
  {
    "text": "to harden this under the hood so our interface is 100% open standards",
    "start": "269020",
    "end": "274270"
  },
  {
    "text": "open-source Redis any Redis code you have will work with ElastiCache will work with open source will work with",
    "start": "274270",
    "end": "280509"
  },
  {
    "text": "other organizations like say Redis labs and their Enterprise Redis these will all work just fine but underneath we've",
    "start": "280509",
    "end": "286720"
  },
  {
    "text": "done some things to make it work better because we can cheat why don't you why we can cheat open source Redis has to",
    "start": "286720",
    "end": "292900"
  },
  {
    "text": "run on every platform ever made right it has to run on laptops and different servers and different architectures we",
    "start": "292900",
    "end": "299650"
  },
  {
    "text": "only have to make it run on ec2 we know how ec2 works so we can optimize it free",
    "start": "299650",
    "end": "304660"
  },
  {
    "text": "c2 so if you're familiar with Aurora and our RDS where we've optimized the engine but it's a my sequel or not what",
    "start": "304660",
    "end": "310449"
  },
  {
    "text": "Postgres interface same thing here we've optimized the engine so for example we can do failover faster and smoother",
    "start": "310449",
    "end": "317110"
  },
  {
    "text": "because we do direct memory transfer instead of having to go through dis storage when we do replicas similarly we",
    "start": "317110",
    "end": "324370"
  },
  {
    "text": "can do snapshots even though you're using almost all the memory because we can take advantage of the of the ec2",
    "start": "324370",
    "end": "330610"
  },
  {
    "text": "capabilities so there's a lot of things we're able to do that you just can't quite do an open source so to drill into",
    "start": "330610",
    "end": "337330"
  },
  {
    "start": "336000",
    "end": "397000"
  },
  {
    "text": "that a bit if you look at the things in Redis you know it is ridiculously fast and that's actually in the documentation",
    "start": "337330",
    "end": "342580"
  },
  {
    "text": "that it says it's ridiculously fast so I can put that up on the board as we said less than 500 microseconds for most",
    "start": "342580",
    "end": "350229"
  },
  {
    "text": "operations now that's assuming you're moving a kilobyte to four kilobytes obviously if I'm moving 500 megabytes it",
    "start": "350229",
    "end": "356530"
  },
  {
    "text": "will take more than a millisecond but we it's still the fastest data technology out there we do have the persistence",
    "start": "356530",
    "end": "364500"
  },
  {
    "text": "capability that's so that I can take backups and other pieces this is one of the things that memcache D just doesn't",
    "start": "364500",
    "end": "371110"
  },
  {
    "text": "do but I can do in Redis as well as have high availability through replication so",
    "start": "371110",
    "end": "376150"
  },
  {
    "text": "we support up to five replicas you really don't need more than one or two for availability the reason I have more",
    "start": "376150",
    "end": "383020"
  },
  {
    "text": "than two is if you have a really high read rate I need to get millions of reads we can do that there's all sorts",
    "start": "383020",
    "end": "388599"
  },
  {
    "text": "of cool stuff like atomic operations and about 200 commands and Lua scripting but I want to spend just a moment on the",
    "start": "388599",
    "end": "395349"
  },
  {
    "text": "data structures that's a lot of what if does really depends on you saying the data structures and Redis so",
    "start": "395349",
    "end": "401300"
  },
  {
    "start": "397000",
    "end": "684000"
  },
  {
    "text": "pardon me if I get a bit nerdy here but I love this stuff because you know this is the code so in Redis everything's a",
    "start": "401300",
    "end": "408740"
  },
  {
    "text": "string it's a key value store so the basic Retta structure is a key that's a string and a value that's a",
    "start": "408740",
    "end": "414650"
  },
  {
    "text": "string each of those can be up to 512 megabytes yes you can have a 500",
    "start": "414650",
    "end": "420560"
  },
  {
    "text": "megabyte key don't do that because it makes a little hard to use the key but",
    "start": "420560",
    "end": "425990"
  },
  {
    "text": "people commonly do keys that are a couple of hundred or a couple of thousand characters because I've seen",
    "start": "425990",
    "end": "431659"
  },
  {
    "text": "people do things like you know put an s h1 hash in as the key it's not human readable but it's great for code",
    "start": "431659",
    "end": "436669"
  },
  {
    "text": "connection and other things or do compound keys like user : something",
    "start": "436669",
    "end": "442009"
  },
  {
    "text": "session : something and be able to do these complexities and then what's cool",
    "start": "442009",
    "end": "447050"
  },
  {
    "text": "about red is it's not typed everything's a string but rightis is smart enough to figure that out so rightist can look at a string that's",
    "start": "447050",
    "end": "453860"
  },
  {
    "text": "7 6 3 9 I go oh I know that's an integer and that will increment or decrement it or do other math operations and it's a",
    "start": "453860",
    "end": "461629"
  },
  {
    "text": "binary safe string so that string could be an image it could be a JPEG file or a PNG file or something else or a movie",
    "start": "461629",
    "end": "469250"
  },
  {
    "text": "file the only limit is 512 gig but it was sorry 512 Meg but if you have something in the gigabytes phase you can",
    "start": "469250",
    "end": "475520"
  },
  {
    "text": "chop it into pieces a lot of people do that another data type is a hash so a hash instead of key and value you have a",
    "start": "475520",
    "end": "482000"
  },
  {
    "text": "key and a hash table and the hash table consists of a bunch of keys and values so I can keep a lot of nested",
    "start": "482000",
    "end": "487879"
  },
  {
    "text": "information that way or we can put those strings together in a list and then pop and push from each end of the list or",
    "start": "487879",
    "end": "494330"
  },
  {
    "text": "put it together in a set so the difference between a set and a list is the set is unique so you might notice on",
    "start": "494330",
    "end": "499580"
  },
  {
    "text": "here the list I have a CBC so C can go in there twice and a set I can only have",
    "start": "499580",
    "end": "505639"
  },
  {
    "text": "each of them once set sorriness are ordered in the way you put them in a sorted set is really useful and if we'll",
    "start": "505639",
    "end": "512060"
  },
  {
    "text": "talk a bit about how they're using that because the sorted set each of the items in the set has a score and it's always",
    "start": "512060",
    "end": "519919"
  },
  {
    "text": "kept in the order of the score so let's say you're running a game and you want to know who are the top ten players well",
    "start": "519919",
    "end": "526640"
  },
  {
    "text": "if I'm keeping player names and scores it's a hundred microseconds to pull out those top ten players",
    "start": "526640",
    "end": "531740"
  },
  {
    "text": "or if you're a lousy player like me but I want to know so I'm probably you know player 1 million 370 in the ranking but",
    "start": "531740",
    "end": "538490"
  },
  {
    "text": "I want to know whose 1 million 369 so I can knock them off also one call to find",
    "start": "538490",
    "end": "544040"
  },
  {
    "text": "my rank and another call to spy and say the five ahead of me and the fight behind me so really easy that's more",
    "start": "544040",
    "end": "549110"
  },
  {
    "text": "than gaming ecommerce will use this what are my top selling products today combine it with a hash what are the top",
    "start": "549110",
    "end": "555500"
  },
  {
    "text": "selling products with each of these products and then have and then link those up so I can use these data types a",
    "start": "555500",
    "end": "561710"
  },
  {
    "text": "lot of interesting ways geospatial index is a special sorted set but you have two scores allotted to Dan along longitude",
    "start": "561710",
    "end": "568340"
  },
  {
    "text": "and then reddit says all these cool commands to what's the distance between these two points or here's a point in",
    "start": "568340",
    "end": "573710"
  },
  {
    "text": "radius as this other point inside that radius lots of uses to be able to in microseconds figure out geographic",
    "start": "573710",
    "end": "579770"
  },
  {
    "text": "information and the last one's kind of cool I don't know use Hyper log log okay this is a weird one hyper log log is a",
    "start": "579770",
    "end": "586280"
  },
  {
    "text": "mathematical trick that if you have a very large set to guess the cardinality",
    "start": "586280",
    "end": "591310"
  },
  {
    "text": "so in other words let's say I've got a table with a billion items in it we get",
    "start": "591310",
    "end": "599120"
  },
  {
    "text": "that sometimes if you want to count the number of items doing a scan or even doing a select count Splatt is",
    "start": "599120",
    "end": "605810"
  },
  {
    "text": "computationally expensive and a table that big it probably changes by the time it's done counting a hyper log log is",
    "start": "605810",
    "end": "612730"
  },
  {
    "text": "doing a mathematical trick by taking a hash of the table definition and looking",
    "start": "612730",
    "end": "619280"
  },
  {
    "text": "for the number of matching digits to guess the size of the number of items in that table or that set doesn't have to",
    "start": "619280",
    "end": "625670"
  },
  {
    "text": "be a table and it's always within three percent usually within a half a percent but the hyper log never takes up more",
    "start": "625670",
    "end": "631460"
  },
  {
    "text": "than twelve K so if I have something that has millions or hundreds of millions or billions and I want to know",
    "start": "631460",
    "end": "637040"
  },
  {
    "text": "the count I can figure that out within three percent and 100 microsecond operation this is really useful there's",
    "start": "637040",
    "end": "644720"
  },
  {
    "text": "certain ecommerce sites that you may have heard of that use this at the top of their page to tell you how many items",
    "start": "644720",
    "end": "649910"
  },
  {
    "text": "are in the catalogue now Redis was originally written by a team in Italy as",
    "start": "649910",
    "end": "656570"
  },
  {
    "text": "I mentioned the head of that team who still contributes the project Salvatore's and flipy Sanfilippo who",
    "start": "656570",
    "end": "662540"
  },
  {
    "text": "online goes by ante res has the great phrase that learning Redis is the best",
    "start": "662540",
    "end": "667730"
  },
  {
    "text": "half-hour you can spend in your career as a developer I guess that's a bit of an exaggeration but I'll tell you if you",
    "start": "667730",
    "end": "673760"
  },
  {
    "text": "haven't done stuff with Redis if you can code in any language and you've used any database you can pick this up in a day",
    "start": "673760",
    "end": "679060"
  },
  {
    "text": "and it's great stuff to use so have been giving that little overview I'd like to",
    "start": "679060",
    "end": "684530"
  },
  {
    "start": "684000",
    "end": "815000"
  },
  {
    "text": "mention just a few examples and then we'll bring Nicolas up to talk about reality just show a few ways these are",
    "start": "684530",
    "end": "690710"
  },
  {
    "text": "use so they're up there as an example of one of those compound keys page : index at HTML you don't have to use a colon",
    "start": "690710",
    "end": "696740"
  },
  {
    "text": "that's just a common convention but you might notice what we're storing there in this case is a web page so this is",
    "start": "696740",
    "end": "703580"
  },
  {
    "text": "commonly used then for session caching or ways to keep web or other information that I want to be able to pull back",
    "start": "703580",
    "end": "709010"
  },
  {
    "text": "quickly there's another example there of in this case an integer so it's smart",
    "start": "709010",
    "end": "714290"
  },
  {
    "text": "enough to say hey it's stored as a string but I know that's an integer figure it out on its own one of the other things you can do with strings",
    "start": "714290",
    "end": "720500"
  },
  {
    "text": "that's unique to Redis is not pull back the whole string but only get or set",
    "start": "720500",
    "end": "725690"
  },
  {
    "text": "just a number of bits and arbitrary set of bits so if I'm using something like protocol buff protobuf for protocol",
    "start": "725690",
    "end": "732320"
  },
  {
    "text": "buffers or mini fie and I don't want to pull out and deserialize the whole thing if I know the structure I know I want to",
    "start": "732320",
    "end": "738410"
  },
  {
    "text": "get bits 107 through 119 you can do that you can't do that with other databases it's a really cool feature to be able to",
    "start": "738410",
    "end": "745190"
  },
  {
    "text": "deal with compress data there's a set of who logged in today so say user 3 logs",
    "start": "745190",
    "end": "750410"
  },
  {
    "text": "and again it's a set they're unique so it doesn't come in again on the other hand below it is the post ideas these are the IDs of people who have done",
    "start": "750410",
    "end": "756740"
  },
  {
    "text": "posting so for that one that's a list goes to somebody pose three times I want them to show up three times there's ways",
    "start": "756740",
    "end": "762530"
  },
  {
    "text": "to keep the data there below is an example of a hash so I'm keeping session in this case my hash my key values are",
    "start": "762530",
    "end": "768860"
  },
  {
    "text": "time and a time value on a username and a username value time values my Redis are normally done in UNIX epoch time but",
    "start": "768860",
    "end": "776930"
  },
  {
    "text": "anyway no Python Java Ruby node C whatever that you're going to use have",
    "start": "776930",
    "end": "782720"
  },
  {
    "text": "the tools you need to convert between UNIX epoch time and standard time stamps and then finally there's an example",
    "start": "782720",
    "end": "788240"
  },
  {
    "text": "there of a scourge set sorted set where you might notice that there is a score next to Joe and Bert and Fred and Chris",
    "start": "788240",
    "end": "794660"
  },
  {
    "text": "inside the users and scores set and it's always kept in that",
    "start": "794660",
    "end": "799670"
  },
  {
    "text": "so if I put in a new entry it wouldn't go at the end it would go where the score fit in so that's always kept in",
    "start": "799670",
    "end": "806900"
  },
  {
    "text": "order that's how I can pull it back so quickly all right so I've got these tools how do you use them to do",
    "start": "806900",
    "end": "813200"
  },
  {
    "text": "something really cool Nicolette's come on up here Thank You Darren that was",
    "start": "813200",
    "end": "826070"
  },
  {
    "start": "815000",
    "end": "966000"
  },
  {
    "text": "that was really interesting I actually my brain was going I feel like there are some things that we could actually",
    "start": "826070",
    "end": "831140"
  },
  {
    "text": "improve about our systems with with some of those things so if you're not familiar with it if our tagline right",
    "start": "831140",
    "end": "838250"
  },
  {
    "text": "now is one connection countless possibilities we allow users and developers to create what we call",
    "start": "838250",
    "end": "845360"
  },
  {
    "text": "applets oracle has given up the word Firefox is deprecating Java applets in",
    "start": "845360",
    "end": "851510"
  },
  {
    "text": "the browser I think in February so we snatched it here are some examples you",
    "start": "851510",
    "end": "858680"
  },
  {
    "text": "can connect your hue lights to your location your Facebook photos to an iOS",
    "start": "858680",
    "end": "866960"
  },
  {
    "text": "photo album or a box account and pretty much anything that you can think of developers can also write even more",
    "start": "866960",
    "end": "874790"
  },
  {
    "text": "complex functionality and we just released what we're calling a maker tier",
    "start": "874790",
    "end": "880790"
  },
  {
    "text": "where you can build access to this functionality yourself I've prepared a",
    "start": "880790",
    "end": "886160"
  },
  {
    "text": "little bit of a demo we're gonna try and see if it works because conference Wi-Fi this has been",
    "start": "886160",
    "end": "891950"
  },
  {
    "text": "pretty great but you never know every attendee got an echo dot and Alexa the",
    "start": "891950",
    "end": "899770"
  },
  {
    "text": "the Alexa service is one of our partners and we enable a lot of skills that are",
    "start": "899770",
    "end": "911930"
  },
  {
    "text": "not actually native so just by connecting to it you can enable pretty",
    "start": "911930",
    "end": "917150"
  },
  {
    "text": "much anything that you can dream of with our 360 partners so okay let's try it",
    "start": "917150",
    "end": "922760"
  },
  {
    "text": "Alexa find my phone Oh [Music]",
    "start": "922760",
    "end": "929980"
  },
  {
    "text": "okay Alexa stop Alexa trigger find my",
    "start": "931280",
    "end": "939360"
  },
  {
    "text": "phone it was the word trigger that I had",
    "start": "939360",
    "end": "944580"
  },
  {
    "text": "forgotten and so that's not a native skill that oxo has and it's actually",
    "start": "944580",
    "end": "951060"
  },
  {
    "text": "calling my phone and will leave a voicemail that I can customize so you can actually if you've lost your phone",
    "start": "951060",
    "end": "957660"
  },
  {
    "text": "somewhere else you can actually have the voicemail say something to the person that theoretically finds your phone",
    "start": "957660",
    "end": "964080"
  },
  {
    "text": "really neat we have over 43 million applets that have been created over nine million",
    "start": "964080",
    "end": "970710"
  },
  {
    "start": "966000",
    "end": "1005000"
  },
  {
    "text": "users on our platform 360 services as I mentioned we run applets over a billion",
    "start": "970710",
    "end": "977100"
  },
  {
    "text": "times per month and that doesn't even include times that applets didn't have fresh data or aired out because of",
    "start": "977100",
    "end": "984750"
  },
  {
    "text": "authentication information or something like that so those are just active applet runs and we have over 80 million",
    "start": "984750",
    "end": "990990"
  },
  {
    "text": "service activations essentially ooofff login information for people's connected",
    "start": "990990",
    "end": "997830"
  },
  {
    "text": "services or if it doesn't require authentication just a nun often an",
    "start": "997830",
    "end": "1003050"
  },
  {
    "text": "unauthenticated connection we run in one region for availability zones over 300",
    "start": "1003050",
    "end": "1010940"
  },
  {
    "text": "spot instances that run all the recipes I talked about that yesterday in a",
    "start": "1010940",
    "end": "1016220"
  },
  {
    "text": "different session over 60 ElastiCache nodes and one DevOps engineer hi guys",
    "start": "1016220",
    "end": "1025060"
  },
  {
    "text": "we're going to talk about two different ways in which we use ElastiCache today one",
    "start": "1025060",
    "end": "1030650"
  },
  {
    "text": "I'm calling applet optimization you saw the slide I leaked it a little bit and",
    "start": "1030650",
    "end": "1038329"
  },
  {
    "text": "then also the way that we store our applet logs so digging right into it",
    "start": "1038329",
    "end": "1043670"
  },
  {
    "text": "applet optimization applets consists primarily of triggers and actions and if",
    "start": "1043670",
    "end": "1049220"
  },
  {
    "start": "1045000",
    "end": "1077000"
  },
  {
    "text": "you're familiar with if from the last six years it was one trigger to one action if this then that and now we're starting",
    "start": "1049220",
    "end": "1058070"
  },
  {
    "text": "to get more complex triggers and actions but for now just thinking about it simply",
    "start": "1058070",
    "end": "1063290"
  },
  {
    "text": "that way instant triggers are when one of our partners calls in to us we but",
    "start": "1063290",
    "end": "1070160"
  },
  {
    "text": "not every partner support set so we strive for as little delay as possible",
    "start": "1070160",
    "end": "1075280"
  },
  {
    "text": "but you what have to resort to pulling in a lot of cases even with instant",
    "start": "1075280",
    "end": "1082310"
  },
  {
    "start": "1077000",
    "end": "1093000"
  },
  {
    "text": "triggers you have to resort to polling in case you missed one of the notifications from the partner you still",
    "start": "1082310",
    "end": "1088940"
  },
  {
    "text": "want to be able to make sure that you can check that new data was there going",
    "start": "1088940",
    "end": "1094520"
  },
  {
    "start": "1093000",
    "end": "1110000"
  },
  {
    "text": "back to this this is actually one of my applets that I have activated on my account I get little updates from the",
    "start": "1094520",
    "end": "1101900"
  },
  {
    "text": "reddit LEGO Group in in slack pretty much all day a couple times a day really",
    "start": "1101900",
    "end": "1108230"
  },
  {
    "text": "fun one so we started building a system",
    "start": "1108230",
    "end": "1113690"
  },
  {
    "start": "1110000",
    "end": "1157000"
  },
  {
    "text": "that we could predict when someone's applet would run we needed to be able to",
    "start": "1113690",
    "end": "1120770"
  },
  {
    "text": "store that data somewhere we wanted that storage system to be fast harkening back to Darren's time section",
    "start": "1120770",
    "end": "1128840"
  },
  {
    "text": "we at but we needed some native complex data types like sets and bitmaps and that'll become clear why in a few",
    "start": "1128840",
    "end": "1136430"
  },
  {
    "text": "minutes we also needed to be able to do atomic track transactions across multiple keys also I'll explain why",
    "start": "1136430",
    "end": "1143380"
  },
  {
    "text": "shortly and really Redis was the the",
    "start": "1143380",
    "end": "1148820"
  },
  {
    "text": "clear choice for that we do not like to run things ourselves so manage ElastiCache was was was",
    "start": "1148820",
    "end": "1155480"
  },
  {
    "text": "perfect we the way that we do this is anytime an applet runs we publish that",
    "start": "1155480",
    "end": "1161330"
  },
  {
    "start": "1157000",
    "end": "1196000"
  },
  {
    "text": "data to Kinesis and we wrote a Kinesis consumer I think just based off of one",
    "start": "1161330",
    "end": "1167210"
  },
  {
    "text": "of the the Kinesis consumer templates that rights to our predictor elastic",
    "start": "1167210",
    "end": "1174170"
  },
  {
    "text": "hash data store and rights to a bitmap we have a a bit for every minute of the",
    "start": "1174170",
    "end": "1179900"
  },
  {
    "text": "day on a key that is the users ID our sorry the applet ID and the day so it's",
    "start": "1179900",
    "end": "1188960"
  },
  {
    "text": "a very very concise data type this particular consumer only cares about when it ran a",
    "start": "1188960",
    "end": "1195360"
  },
  {
    "text": "ran at at 1:00 a.m. we would write set",
    "start": "1195360",
    "end": "1200490"
  },
  {
    "start": "1196000",
    "end": "1236000"
  },
  {
    "text": "bit key 61 if it ran at 101 a.m. it would be key 61 we sorry have enough so",
    "start": "1200490",
    "end": "1212840"
  },
  {
    "text": "it's very concise structure we can fit all this data into a single node and",
    "start": "1212840",
    "end": "1219299"
  },
  {
    "text": "then use replication to keep it highly available and then our data science team",
    "start": "1219299",
    "end": "1227190"
  },
  {
    "text": "wrote a machine learning algorithm to actually use all that data and return a",
    "start": "1227190",
    "end": "1232830"
  },
  {
    "text": "predicted schedule for when an applet ran so here's kind of example this is",
    "start": "1232830",
    "end": "1239040"
  },
  {
    "start": "1236000",
    "end": "1312000"
  },
  {
    "text": "what what we used to be doing the polling frequency is when we would we",
    "start": "1239040",
    "end": "1244049"
  },
  {
    "text": "would just check essentially as often as we could for a particular applet asking do you have new data do you have new",
    "start": "1244049",
    "end": "1250230"
  },
  {
    "text": "data do you have new data but if you look at the actual events scheduled over like let's say this is a 24-hour period",
    "start": "1250230",
    "end": "1255900"
  },
  {
    "text": "that person's applet only ran three times during that period so we don't",
    "start": "1255900",
    "end": "1261240"
  },
  {
    "text": "actually need to be checking for the rest of the time and we can use that",
    "start": "1261240",
    "end": "1267360"
  },
  {
    "text": "information over like a historical period like seven days to be able to predict when to check so then we can",
    "start": "1267360",
    "end": "1275700"
  },
  {
    "text": "construct a predicted applet scheduled like the the bottom example that sure we",
    "start": "1275700",
    "end": "1281160"
  },
  {
    "text": "check a couple extra times when there we there wouldn't be we don't think that",
    "start": "1281160",
    "end": "1286620"
  },
  {
    "text": "there would be an applet run at that time but around the times that we are pretty sure that there's going to be an",
    "start": "1286620",
    "end": "1292440"
  },
  {
    "text": "applet run we check even more frequently but and this example doesn't really",
    "start": "1292440",
    "end": "1298290"
  },
  {
    "text": "highlight this very well because it's it's like seven little marks on a on a line over the course of seven days we",
    "start": "1298290",
    "end": "1305790"
  },
  {
    "text": "that we by doing this we were actually able to reduce our total number of trigger checks very significantly so the",
    "start": "1305790",
    "end": "1314040"
  },
  {
    "start": "1312000",
    "end": "1430000"
  },
  {
    "text": "prediction algorithm uses historical data to return a daily schedule for each applet that schedule is then transformed",
    "start": "1314040",
    "end": "1320220"
  },
  {
    "text": "into a key for each minute of the day with a list of the applets to check so",
    "start": "1320220",
    "end": "1326070"
  },
  {
    "text": "what I mean by that is we actually have the a crawler that crawls through our",
    "start": "1326070",
    "end": "1331950"
  },
  {
    "text": "entire list of athletes all however million of them that there were fetches",
    "start": "1331950",
    "end": "1336990"
  },
  {
    "text": "the schedule and then rien Q's or rewrites that to a different Redis data",
    "start": "1336990",
    "end": "1342600"
  },
  {
    "text": "structure just a set and then we we keep",
    "start": "1342600",
    "end": "1347789"
  },
  {
    "text": "like a master schedule for the entire day with one set for each minute with a",
    "start": "1347789",
    "end": "1353850"
  },
  {
    "text": "list of the applet IDs that we think that we need to check on that minute then our applet applet check in cure a",
    "start": "1353850",
    "end": "1361950"
  },
  {
    "text": "lot of jargon just gets to read the entire schedule for that minute and in",
    "start": "1361950",
    "end": "1368700"
  },
  {
    "text": "queue those applets to be checked and it's goes on to the next one at the next",
    "start": "1368700",
    "end": "1374640"
  },
  {
    "text": "minute so we don't have to go through our database all the time checking to see which applets need to be run it's",
    "start": "1374640",
    "end": "1381390"
  },
  {
    "text": "really simplified ever our our system some of this already talked about but",
    "start": "1381390",
    "end": "1387360"
  },
  {
    "text": "the service crawls all applets and writes essentially a pivot table back to Redis and it does it with a pretty",
    "start": "1387360",
    "end": "1394049"
  },
  {
    "text": "complex lua script or actually not a complex lua script a pretty simple Lua script that just checks if it's in the",
    "start": "1394049",
    "end": "1401279"
  },
  {
    "text": "set for for convenience and we also do a little bit of logging around that and",
    "start": "1401279",
    "end": "1406740"
  },
  {
    "text": "then either adds it or removes it based on whether we think it should run at that time and this is kind of just",
    "start": "1406740",
    "end": "1413010"
  },
  {
    "text": "always crawling through our database and updating the schedule going forward the",
    "start": "1413010",
    "end": "1418080"
  },
  {
    "text": "and as I said instead of having a bitmap of the day with 1440 bits we have 1440",
    "start": "1418080",
    "end": "1425730"
  },
  {
    "text": "sets for the day one with each minute so",
    "start": "1425730",
    "end": "1430919"
  },
  {
    "text": "over this we've seen a significant reduction in our average polling frequency and a significant reduction in",
    "start": "1430919",
    "end": "1437429"
  },
  {
    "text": "the average delay between when data occurs on a new service or an event",
    "start": "1437429",
    "end": "1442830"
  },
  {
    "text": "occurs on a new server are on one of the services and when that applet runs we",
    "start": "1442830",
    "end": "1448919"
  },
  {
    "text": "also really smoothed out our workload we had kind of workload that was really spiky in the morning there would be a",
    "start": "1448919",
    "end": "1455370"
  },
  {
    "text": "lot of applet runs and we would kind of like get backed up a little bit now it's just very very smooth",
    "start": "1455370",
    "end": "1461720"
  },
  {
    "text": "and has really let us optimize our our workers handling the workload and",
    "start": "1461720",
    "end": "1468220"
  },
  {
    "text": "realistically ElastiCache turned out to be a flexible data storage service that",
    "start": "1468220",
    "end": "1475010"
  },
  {
    "text": "exceeded our requirements so it's way faster than we even needed it to be and more scalable in that we're at this",
    "start": "1475010",
    "end": "1482330"
  },
  {
    "text": "point only using a fraction of our of our node and we can if we need to or",
    "start": "1482330",
    "end": "1490400"
  },
  {
    "text": "when we need to we can scale out to more or go across region it's very very easy to do that so the next thing that I",
    "start": "1490400",
    "end": "1497900"
  },
  {
    "start": "1496000",
    "end": "1502000"
  },
  {
    "text": "mentioned that we'd be talking about is our applet log system every applet",
    "start": "1497900",
    "end": "1503060"
  },
  {
    "start": "1502000",
    "end": "1542000"
  },
  {
    "text": "transaction is logged whether or not it actually fired if there was an error if",
    "start": "1503060",
    "end": "1509720"
  },
  {
    "text": "the applet was deactivated when it was created we log a little bit of data so",
    "start": "1509720",
    "end": "1514940"
  },
  {
    "text": "that we can then fire notifications and give give the user some context about",
    "start": "1514940",
    "end": "1521030"
  },
  {
    "text": "what actually happened but it like we don't go too deep into the logging its it's really just kind of a snapshot all",
    "start": "1521030",
    "end": "1529490"
  },
  {
    "text": "those applet logs are accessible by users so we need those to be indexed by",
    "start": "1529490",
    "end": "1534950"
  },
  {
    "text": "user applet and service so when coming up with the design for the system we",
    "start": "1534950",
    "end": "1541400"
  },
  {
    "text": "have some pretty strict requirements we needed it to be affordable and scalable horizontally so we we didn't want to run",
    "start": "1541400",
    "end": "1548570"
  },
  {
    "start": "1542000",
    "end": "1601000"
  },
  {
    "text": "into any sort of scaling issues we actually had a previous system that we did run into scaling issues so couldn't",
    "start": "1548570",
    "end": "1554000"
  },
  {
    "text": "do that we wanted a good user experience when displaying those logs and what I mean is that we wanted them to show up",
    "start": "1554000",
    "end": "1560030"
  },
  {
    "text": "quickly and if someone's navigating around their account that it they wouldn't see long page load times or",
    "start": "1560030",
    "end": "1566150"
  },
  {
    "text": "anything like that we wanted the system to be resilient to adding additional indexes in the future so let's say we",
    "start": "1566150",
    "end": "1573470"
  },
  {
    "text": "introduce some new kind of like core concept we want to be able to add that index to logs going forward as well as",
    "start": "1573470",
    "end": "1582410"
  },
  {
    "text": "long as going backward I don't say future proof because we know that it's",
    "start": "1582410",
    "end": "1587540"
  },
  {
    "text": "going to take some work to do something like that so I came up with a future resilient going forward is really easy",
    "start": "1587540",
    "end": "1594500"
  },
  {
    "text": "to add an index the system that we developed but we know that it would take work to kind of like it go back and and reindex so again",
    "start": "1594500",
    "end": "1602510"
  },
  {
    "start": "1601000",
    "end": "1651000"
  },
  {
    "text": "theme Kinesis we publish all of the data to Kinesis and since we're doing just",
    "start": "1602510",
    "end": "1608270"
  },
  {
    "text": "one publish the consumer for Apple optimization consumes the same data",
    "start": "1608270",
    "end": "1613490"
  },
  {
    "text": "stream as the the consumer for applet logs that Kinesis consumer",
    "start": "1613490",
    "end": "1618640"
  },
  {
    "text": "simultaneously writes chunks of data to s3 so it'll actually batch up a",
    "start": "1618640",
    "end": "1623770"
  },
  {
    "text": "customizable batch size of log items and then write it as a chunk so that we're not doing like tens of millions of puts",
    "start": "1623770",
    "end": "1630950"
  },
  {
    "text": "to s3 which would be pretty cost ineffective and then also writes indexes",
    "start": "1630950",
    "end": "1639230"
  },
  {
    "text": "to elastic cache so as I said we can add indexes going forward and then it will just continue to work and then we can",
    "start": "1639230",
    "end": "1644960"
  },
  {
    "text": "reenacts going backward with an elastic MapReduce job or something that we haven't written yet so when we want to",
    "start": "1644960",
    "end": "1652429"
  },
  {
    "start": "1651000",
    "end": "1759000"
  },
  {
    "text": "read those logs all we have to do is look up the index in the elastic cache say on the app what ID fetch the chunk",
    "start": "1652429",
    "end": "1659420"
  },
  {
    "text": "locations on s3 and then read data from s3 in and then create kind of like the",
    "start": "1659420",
    "end": "1666050"
  },
  {
    "text": "last ten entries or the last hundred entries or however that however far you want to go back the it reading from s3",
    "start": "1666050",
    "end": "1675020"
  },
  {
    "text": "can be slow sometimes even if you're reading entries in parallel across different chunks we're also parsing parsing like however",
    "start": "1675020",
    "end": "1684290"
  },
  {
    "text": "big the chunk size is like it can get pretty pretty time-consuming and when I",
    "start": "1684290",
    "end": "1689960"
  },
  {
    "text": "say time-consuming I mean I'm talking about like milliseconds it's it's still",
    "start": "1689960",
    "end": "1695240"
  },
  {
    "text": "really fast but if someone is navigating around the site we don't want them waiting hundreds of milliseconds to reef",
    "start": "1695240",
    "end": "1701059"
  },
  {
    "text": "or service to read a whole bunch of stuff off of different locations on s3 so we actually cache recent reads into",
    "start": "1701059",
    "end": "1708350"
  },
  {
    "text": "back into ElastiCache that just as kind of like a simple key value store the",
    "start": "1708350",
    "end": "1713720"
  },
  {
    "text": "indexes keep at keep most the most recent X items so if we're looking at at",
    "start": "1713720",
    "end": "1720170"
  },
  {
    "text": "our index as being a hundred items that X would be a hundred and when an index gets too large we actually truncate the",
    "start": "1720170",
    "end": "1726679"
  },
  {
    "text": "index with luluwa and then store the index back to s3 so that at any point if",
    "start": "1726679",
    "end": "1732260"
  },
  {
    "text": "someone is kind of like navigating really far back in their in their applet",
    "start": "1732260",
    "end": "1737480"
  },
  {
    "text": "logs we can fetch the chunks for the index load the index again into kind of",
    "start": "1737480",
    "end": "1744080"
  },
  {
    "text": "like a temporary key and then restart the whole process over again so it seems",
    "start": "1744080",
    "end": "1750620"
  },
  {
    "text": "kind of kind of clunky but it really is just the same process for fetching logs and we just reused that for fetching",
    "start": "1750620",
    "end": "1756770"
  },
  {
    "text": "archived in indices so to recap s3 is",
    "start": "1756770",
    "end": "1762410"
  },
  {
    "start": "1759000",
    "end": "1865000"
  },
  {
    "text": "our cold storage for long-term archiving ElastiCache Redis has the hot data and",
    "start": "1762410",
    "end": "1768290"
  },
  {
    "text": "hot indexes we it's fast loading for users while still being affordable and",
    "start": "1768290",
    "end": "1773840"
  },
  {
    "text": "scalable and the cost scale with a number of users instead of growing out of hand and that was the key thing is",
    "start": "1773840",
    "end": "1779390"
  },
  {
    "text": "that we know and it actually scales with a number of applets but we we know that",
    "start": "1779390",
    "end": "1786470"
  },
  {
    "text": "if we're dumping stuff to s3 that we it",
    "start": "1786470",
    "end": "1791900"
  },
  {
    "text": "can just grow and grow and grow and grow and then you're spending tens of thousands of dollars in s3 with this system using ElastiCache as the index",
    "start": "1791900",
    "end": "1801530"
  },
  {
    "text": "and being able to limit it to the number of users because things are indexed by",
    "start": "1801530",
    "end": "1807020"
  },
  {
    "text": "user that a certain ElastiCache node will be able to handle a certain number",
    "start": "1807020",
    "end": "1812090"
  },
  {
    "text": "of users and rather than like paying a bunch of throughput prices on dynamo",
    "start": "1812090",
    "end": "1820010"
  },
  {
    "text": "this allows us to scale and keep just the kind of like hot data in ElastiCache",
    "start": "1820010",
    "end": "1826430"
  },
  {
    "text": "and we can estimate exactly how many kilobytes of data one particular applet index will use and and so on so we can",
    "start": "1826430",
    "end": "1835030"
  },
  {
    "text": "use elastic MapReduce or something like that to read X an entire account if someone wants all of their data or their",
    "start": "1835030",
    "end": "1841400"
  },
  {
    "text": "they're concerned about a particular particular app what running and then we can add indexes without hassle going",
    "start": "1841400",
    "end": "1848870"
  },
  {
    "text": "forward and with a little bit of hassle going backwards it really has a has kind",
    "start": "1848870",
    "end": "1853880"
  },
  {
    "text": "of like saved us a lot in terms of what we were doing before what we know that we're going to have to",
    "start": "1853880",
    "end": "1859430"
  },
  {
    "text": "do going forward and yeah that's that's a pretty much it for",
    "start": "1859430",
    "end": "1864649"
  },
  {
    "text": "our applet logs so I'm gonna hand it back to Darren and you can wrap up well",
    "start": "1864649",
    "end": "1874009"
  },
  {
    "start": "1865000",
    "end": "1897000"
  },
  {
    "text": "first is the thing that we need to ask you which is very important at every",
    "start": "1874009",
    "end": "1879019"
  },
  {
    "text": "session at reinvent so please fill out your evaluations because if you haven't",
    "start": "1879019",
    "end": "1884570"
  },
  {
    "text": "figured this out yet after you've filled out evaluations it unlocks the SWAC so you can go by the swag counter and get stuff other than",
    "start": "1884570",
    "end": "1891950"
  },
  {
    "text": "that does anyone have any questions if so please go to one of our microphones and let us know what you like to know",
    "start": "1891950",
    "end": "1898870"
  }
]
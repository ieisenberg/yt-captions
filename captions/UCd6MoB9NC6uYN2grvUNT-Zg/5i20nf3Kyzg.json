[
  {
    "text": "now we're going to use Hive to process",
    "start": "320",
    "end": "2080"
  },
  {
    "text": "some Wikipedia data via a",
    "start": "2080",
    "end": "5080"
  },
  {
    "text": "lab what this lab covers is the same",
    "start": "5080",
    "end": "7480"
  },
  {
    "text": "things we're talking about in the",
    "start": "7480",
    "end": "8400"
  },
  {
    "text": "previous module which is how do you",
    "start": "8400",
    "end": "9880"
  },
  {
    "text": "actually use a hive job flow uh in",
    "start": "9880",
    "end": "13240"
  },
  {
    "text": "elastic map produce to process data so",
    "start": "13240",
    "end": "16080"
  },
  {
    "text": "in this lab we're using the same data",
    "start": "16080",
    "end": "17760"
  },
  {
    "text": "sets that we used in the Hadoop lab",
    "start": "17760",
    "end": "19760"
  },
  {
    "text": "which uh consist of a set of files that",
    "start": "19760",
    "end": "23400"
  },
  {
    "text": "contain Wikipedia XML records uh each",
    "start": "23400",
    "end": "26279"
  },
  {
    "text": "XML record is a single page from",
    "start": "26279",
    "end": "28160"
  },
  {
    "text": "Wikipedia it occupies one line of text",
    "start": "28160",
    "end": "31080"
  },
  {
    "text": "from that record we can extract",
    "start": "31080",
    "end": "32480"
  },
  {
    "text": "information like uh the contributors",
    "start": "32480",
    "end": "35480"
  },
  {
    "text": "which is basically the username for",
    "start": "35480",
    "end": "37440"
  },
  {
    "text": "whoever last edited the page and also",
    "start": "37440",
    "end": "39800"
  },
  {
    "text": "when that page was edited so an edit",
    "start": "39800",
    "end": "41760"
  },
  {
    "text": "date once we have that data then we can",
    "start": "41760",
    "end": "44399"
  },
  {
    "text": "do things like say okay who um are the",
    "start": "44399",
    "end": "47079"
  },
  {
    "text": "contributors that have done the most",
    "start": "47079",
    "end": "49199"
  },
  {
    "text": "edits on all these Pages recently and",
    "start": "49199",
    "end": "52280"
  },
  {
    "text": "because we have timestamps then we can",
    "start": "52280",
    "end": "53760"
  },
  {
    "text": "say when do most the edits",
    "start": "53760",
    "end": "57000"
  },
  {
    "text": "happen before you can actually do the",
    "start": "57000",
    "end": "58920"
  },
  {
    "text": "lab you need to set up so you I'm",
    "start": "58920",
    "end": "61640"
  },
  {
    "text": "assuming that you've already got your",
    "start": "61640",
    "end": "62600"
  },
  {
    "text": "adabs account uh and that you've created",
    "start": "62600",
    "end": "66119"
  },
  {
    "text": "a uh public private key pair and you've",
    "start": "66119",
    "end": "68880"
  },
  {
    "text": "downloaded that private key that you've",
    "start": "68880",
    "end": "71040"
  },
  {
    "text": "got the hive lab and that Hive lab's",
    "start": "71040",
    "end": "73080"
  },
  {
    "text": "available uh via S3 so you should just",
    "start": "73080",
    "end": "76040"
  },
  {
    "text": "be able to download and expand it once",
    "start": "76040",
    "end": "78320"
  },
  {
    "text": "you've downloaded it and expanded it um",
    "start": "78320",
    "end": "80200"
  },
  {
    "text": "you'll be in a directory that'll have",
    "start": "80200",
    "end": "81759"
  },
  {
    "text": "two files in it the key one is a readme",
    "start": "81759",
    "end": "83520"
  },
  {
    "text": "file and that contains all the",
    "start": "83520",
    "end": "85320"
  },
  {
    "text": "instructions for running this lab so",
    "start": "85320",
    "end": "87640"
  },
  {
    "text": "let's go take a look at that so you can",
    "start": "87640",
    "end": "89600"
  },
  {
    "text": "see here uh in the directory there's two",
    "start": "89600",
    "end": "91400"
  },
  {
    "text": "files one's called readme and one's",
    "start": "91400",
    "end": "93159"
  },
  {
    "text": "called hi- la. hql the hi- la. hql file",
    "start": "93159",
    "end": "97799"
  },
  {
    "text": "contains the hive query language",
    "start": "97799",
    "end": "100759"
  },
  {
    "text": "commands that uh we use as part of the",
    "start": "100759",
    "end": "103520"
  },
  {
    "text": "batch processing uh that I demonstrated",
    "start": "103520",
    "end": "105640"
  },
  {
    "text": "in the previous module the readme file",
    "start": "105640",
    "end": "108399"
  },
  {
    "text": "is something we can look at now contains",
    "start": "108399",
    "end": "110719"
  },
  {
    "text": "step-by-step requirements uh or",
    "start": "110719",
    "end": "112680"
  },
  {
    "text": "prerequisites here as well as what you",
    "start": "112680",
    "end": "115200"
  },
  {
    "text": "need to do to actually run the job the",
    "start": "115200",
    "end": "117680"
  },
  {
    "text": "sequence is the same as what we went",
    "start": "117680",
    "end": "119200"
  },
  {
    "text": "through in the previous month module in",
    "start": "119200",
    "end": "120200"
  },
  {
    "text": "other words you first got to set up a",
    "start": "120200",
    "end": "122079"
  },
  {
    "text": "bucket in",
    "start": "122079",
    "end": "123039"
  },
  {
    "text": "S3 uh then you can define a hive job",
    "start": "123039",
    "end": "126479"
  },
  {
    "text": "flow using the AWS console so in your",
    "start": "126479",
    "end": "129039"
  },
  {
    "text": "browser go through this",
    "start": "129039",
    "end": "131840"
  },
  {
    "text": "process and then once that's running",
    "start": "131840",
    "end": "134200"
  },
  {
    "text": "it's running a batch job and you can",
    "start": "134200",
    "end": "135800"
  },
  {
    "text": "monitor that job you can also do an",
    "start": "135800",
    "end": "138160"
  },
  {
    "text": "interactive Hive job flow and that and",
    "start": "138160",
    "end": "141280"
  },
  {
    "text": "that's this step number four here where",
    "start": "141280",
    "end": "143840"
  },
  {
    "text": "you essentially are doing uh the same",
    "start": "143840",
    "end": "145879"
  },
  {
    "text": "kind of steps for setting up a hive job",
    "start": "145879",
    "end": "147840"
  },
  {
    "text": "flow but you're saying I wanted to be an",
    "start": "147840",
    "end": "149360"
  },
  {
    "text": "Interactive session versus providing the",
    "start": "149360",
    "end": "152239"
  },
  {
    "text": "script that you want to run and the",
    "start": "152239",
    "end": "153400"
  },
  {
    "text": "input and output directories uh and this",
    "start": "153400",
    "end": "155800"
  },
  {
    "text": "lets you then interactively build up",
    "start": "155800",
    "end": "157599"
  },
  {
    "text": "your hive scripts as we've talked about",
    "start": "157599",
    "end": "159879"
  },
  {
    "text": "previously the commands that are in that",
    "start": "159879",
    "end": "162480"
  },
  {
    "text": "hi- lab. hql file are the same ones that",
    "start": "162480",
    "end": "166120"
  },
  {
    "text": "you'll see down",
    "start": "166120",
    "end": "168800"
  },
  {
    "text": "here talking about being entered when",
    "start": "168800",
    "end": "172400"
  },
  {
    "text": "you're in the hive interpreter uh so if",
    "start": "172400",
    "end": "175000"
  },
  {
    "text": "you need to you can just open that file",
    "start": "175000",
    "end": "176519"
  },
  {
    "text": "up and copy the specific commands and",
    "start": "176519",
    "end": "178440"
  },
  {
    "text": "paste them if you're having trouble",
    "start": "178440",
    "end": "179440"
  },
  {
    "text": "following the steps that are here we",
    "start": "179440",
    "end": "181480"
  },
  {
    "text": "also talk about down here in an advanced",
    "start": "181480",
    "end": "183519"
  },
  {
    "text": "section again how you can use uh a",
    "start": "183519",
    "end": "186480"
  },
  {
    "text": "proxying server to be able to view the",
    "start": "186480",
    "end": "188879"
  },
  {
    "text": "actual Hadoop jobs using the Hadoop uh",
    "start": "188879",
    "end": "191799"
  },
  {
    "text": "guey which lets you view individual jobs",
    "start": "191799",
    "end": "194480"
  },
  {
    "text": "and get statistics about those",
    "start": "194480",
    "end": "196480"
  },
  {
    "text": "jobs so good luck on the lab and if you",
    "start": "196480",
    "end": "199599"
  },
  {
    "text": "get stuck you can go back and look at",
    "start": "199599",
    "end": "201799"
  },
  {
    "text": "the previous Hive and pig module and in",
    "start": "201799",
    "end": "204560"
  },
  {
    "text": "that video you'll see me doing the same",
    "start": "204560",
    "end": "206760"
  },
  {
    "text": "things that you'll be doing with this",
    "start": "206760",
    "end": "207959"
  },
  {
    "text": "lab",
    "start": "207959",
    "end": "210799"
  }
]
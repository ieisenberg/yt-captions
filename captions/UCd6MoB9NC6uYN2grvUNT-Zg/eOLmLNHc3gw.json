[
  {
    "text": "good morning everyone thanks so much for joining us today happy Thursday today we are going to talk about pi torch in our",
    "start": "2870",
    "end": "10169"
  },
  {
    "text": "webinar my name is sue awake and I'm the AWS global partner marketing manager for AI and machine learning our presenter",
    "start": "10169",
    "end": "16530"
  },
  {
    "text": "today is Chris Greenock and you guys know Chris he's the global machine learning segment lead for the AWS",
    "start": "16530",
    "end": "21660"
  },
  {
    "text": "partner network today he's going to walk you through model building training and deployment with Python also on the call",
    "start": "21660",
    "end": "28560"
  },
  {
    "text": "today we have Chris burns he's a senior AWS partner solution architect with an AI ml specialty Chris is going to help",
    "start": "28560",
    "end": "34920"
  },
  {
    "text": "answer your questions in the question and answer pane which is at the bottom of the control panel for GoToWebinar so",
    "start": "34920",
    "end": "40649"
  },
  {
    "text": "as you think of questions today just pop them in there and we'll do our best to answer them during the call and that is",
    "start": "40649",
    "end": "46079"
  },
  {
    "text": "my very short intro and I'm going to toss it over to Chris to get things started all right thank you sue yeah so",
    "start": "46079",
    "end": "54570"
  },
  {
    "text": "today we're going to take a look at PI torch and in particular it's adoption in the enterprise so PI torch of course is",
    "start": "54570",
    "end": "63059"
  },
  {
    "text": "a very popular framework for developing machine learning models in fact if you",
    "start": "63059",
    "end": "70560"
  },
  {
    "text": "well share my philosophy which is that the real innovation in machine learning is deep learning and that deep learning",
    "start": "70560",
    "end": "78150"
  },
  {
    "text": "is evolving very quickly in this is mostly experienced through papers in",
    "start": "78150",
    "end": "84240"
  },
  {
    "text": "archive.org and various breakthroughs that we're seeing throughout research",
    "start": "84240",
    "end": "90600"
  },
  {
    "text": "almost all the papers that are coming out now are in PI torch so I guess it's",
    "start": "90600",
    "end": "96329"
  },
  {
    "text": "the cool kids framework and the adoption and Enterprise has been lagging but",
    "start": "96329",
    "end": "104670"
  },
  {
    "text": "things are changing quickly in fact I encourage every machine learning practitioner not to get too attached to",
    "start": "104670",
    "end": "112140"
  },
  {
    "text": "anything I've been doing machine learning literally since the eighties convolutional neural networks existed",
    "start": "112140",
    "end": "119579"
  },
  {
    "text": "back then believe it or not we ran among sparcstation twos then we had the AI winter and now sort of everything that",
    "start": "119579",
    "end": "126719"
  },
  {
    "text": "is old is new again where I'm really seeing innovation is in models like Bert",
    "start": "126719",
    "end": "131940"
  },
  {
    "text": "and Elmo and whenever you take a look when you download stuff or",
    "start": "131940",
    "end": "137920"
  },
  {
    "text": "get it off a github and or look at the papers you'll notice PI torch is without",
    "start": "137920",
    "end": "143110"
  },
  {
    "text": "question the language of choice Facebook sort of came up with PI torch it was",
    "start": "143110",
    "end": "152500"
  },
  {
    "text": "originally released about two years ago in 2006 the current version is version",
    "start": "152500",
    "end": "158500"
  },
  {
    "text": "1.1 that was released about three months ago and it has a few key key features",
    "start": "158500",
    "end": "164470"
  },
  {
    "text": "which I'm going to point out but this is not a PI torch tutorial I do I'm going",
    "start": "164470",
    "end": "170740"
  },
  {
    "text": "to provide a lot of resources for really learning the language this is simply how I'm seeing at AWS partners and customers",
    "start": "170740",
    "end": "178540"
  },
  {
    "text": "are beginning to use it in the enterprise and hopefully point to a few best practices that you can adopt so",
    "start": "178540",
    "end": "187090"
  },
  {
    "text": "before I do just want to always start with the whole Amazon machine learning",
    "start": "187090",
    "end": "193150"
  },
  {
    "text": "stack we divide it into this layered cake where the top layer that cake are",
    "start": "193150",
    "end": "199750"
  },
  {
    "text": "the AI services these are deep learning fully managed services that you really",
    "start": "199750",
    "end": "206890"
  },
  {
    "text": "just don't have to know any PI torch or any deep learning framework whatsoever to use so our vision services",
    "start": "206890",
    "end": "213990"
  },
  {
    "text": "recognition and now to extract speech we have Pali and transcribed languages",
    "start": "213990",
    "end": "219190"
  },
  {
    "text": "translate comprehend chatbots with Lex we have two new really amazing services",
    "start": "219190",
    "end": "226360"
  },
  {
    "text": "one is forecast for time series data and recommendations where you can build",
    "start": "226360",
    "end": "231420"
  },
  {
    "text": "recommendation engine at scale with the exact same tools we use here at Amazon and there's no deep learning experience",
    "start": "231420",
    "end": "239560"
  },
  {
    "text": "required you do need data for a lot of these algorithms but these are ready to",
    "start": "239560",
    "end": "247090"
  },
  {
    "text": "go if you'd know how to use a restful interface next up a sage maker so if you're on this call you've seen sage",
    "start": "247090",
    "end": "253510"
  },
  {
    "text": "maker before we're going to use it here today it is the most comprehensive end-to-end tool for conceiving developing and",
    "start": "253510",
    "end": "261910"
  },
  {
    "text": "deploying machine learning models at scale we've recently introduced a",
    "start": "261910",
    "end": "267640"
  },
  {
    "text": "labeling service called Graham true and of course we'll be using sage maker in our demonstration today the base the",
    "start": "267640",
    "end": "276990"
  },
  {
    "text": "foundation of everything that preceded this is our frameworks an infrastructure",
    "start": "276990",
    "end": "282419"
  },
  {
    "text": "layer here we have of course tensorflow and MX net and we take a non",
    "start": "282419",
    "end": "288419"
  },
  {
    "text": "prescriptive approach to everything we if you're a tensor flow fan you we know already that AWS is the best",
    "start": "288419",
    "end": "296120"
  },
  {
    "text": "infrastructure on which you can develop tensor flow and more than 80% of all",
    "start": "296120",
    "end": "301289"
  },
  {
    "text": "tensor flow deployments do take place on AWS importantly we have our compute and",
    "start": "301289",
    "end": "306300"
  },
  {
    "text": "GPU infrastructure with the p3 class ec2",
    "start": "306300",
    "end": "311370"
  },
  {
    "text": "g4 and g5 s for doing compute intensive tasks field programmable gate arrays",
    "start": "311370",
    "end": "318259"
  },
  {
    "text": "Greengrass for developing distributing and protecting securing IOT models at",
    "start": "318259",
    "end": "325289"
  },
  {
    "text": "scale elastic inference which is a pretty exciting new option where you can",
    "start": "325289",
    "end": "331439"
  },
  {
    "text": "take any compute instance on AWS and just add a GPU it's like throwing a GPU",
    "start": "331439",
    "end": "338339"
  },
  {
    "text": "into your machine in the physical world but here of course you're just doing it with software we're gonna put our",
    "start": "338339",
    "end": "345870"
  },
  {
    "text": "attention today on PI torch which is this framework so let's do that oh I guess there's one more step",
    "start": "345870",
    "end": "351689"
  },
  {
    "text": "you know I've introduced this new concept in my all of my decks because",
    "start": "351689",
    "end": "358439"
  },
  {
    "text": "like I said it's really important not to get too attached to things in this fast-moving field there are so many",
    "start": "358439",
    "end": "364610"
  },
  {
    "text": "applications now in deep learning that operate just like our managed services",
    "start": "364610",
    "end": "370020"
  },
  {
    "text": "or algorithms that you can use readily and there's two things here number one",
    "start": "370020",
    "end": "375839"
  },
  {
    "text": "you don't want to waste any money developing something that's already been developed number two there's a lot of",
    "start": "375839",
    "end": "381839"
  },
  {
    "text": "reputation risk I believe at this point in machine learning because there's so",
    "start": "381839",
    "end": "388050"
  },
  {
    "text": "much out there either in the model zoos or as commercial products that that I",
    "start": "388050",
    "end": "393449"
  },
  {
    "text": "always like to emphasize make sure you're not reinventing the wheel we tend",
    "start": "393449",
    "end": "399000"
  },
  {
    "text": "to get lost in this stuff right so it all begins with defining a business problem that you intend solve as a machine-learning process then",
    "start": "399000",
    "end": "406009"
  },
  {
    "text": "you need to shapes frame that problem as a machine learning problem which means",
    "start": "406009",
    "end": "411679"
  },
  {
    "text": "it's a prediction problem because predictions are the basis of machine learning if you're able to do that and",
    "start": "411679",
    "end": "417799"
  },
  {
    "text": "if by the way if you're not then you have a heuristic problem you just solve it the old-fashioned way the way you",
    "start": "417799",
    "end": "423199"
  },
  {
    "text": "were taught in school but if you are if you do end up with a prediction problem the first place to look for a solution",
    "start": "423199",
    "end": "429949"
  },
  {
    "text": "is the sage maker marketplace there are hundreds of ready-made models that are",
    "start": "429949",
    "end": "435649"
  },
  {
    "text": "immediately deployable using sage maker so you can make commercial endpoints at scale by just browsing the sage maker",
    "start": "435649",
    "end": "443509"
  },
  {
    "text": "marketplace if it solves your problem launch it of course it's made by a vendor so there",
    "start": "443509",
    "end": "448579"
  },
  {
    "text": "will be a fee in those fees very you can but you can try before you buy many of the models in the sage maker marketplace",
    "start": "448579",
    "end": "455119"
  },
  {
    "text": "are free so I encourage everyone if you're taking notes the first note here",
    "start": "455119",
    "end": "461239"
  },
  {
    "text": "is to go to the sage maker marketplace today perhaps right after this webinar and try launching a model launch a free",
    "start": "461239",
    "end": "468169"
  },
  {
    "text": "model see what it's like and I think you'll see that it's the easiest way to launch a model globally at scale if it",
    "start": "468169",
    "end": "475819"
  },
  {
    "text": "solves your problem next up we have of course the managed services now those are interchangeable they could have said",
    "start": "475819",
    "end": "481879"
  },
  {
    "text": "the lex pali recognition managed services first however you're part of",
    "start": "481879",
    "end": "486919"
  },
  {
    "text": "the partner network and you should know we're always looking out for your interests I always promote my partner's",
    "start": "486919",
    "end": "491959"
  },
  {
    "text": "products and solutions first now the good thing here is you don't need training data and training data in order",
    "start": "491959",
    "end": "498349"
  },
  {
    "text": "to launch your model right these are pre-trained models and that eliminates",
    "start": "498349",
    "end": "503360"
  },
  {
    "text": "maybe up to 90% of the heavy lifting so that is an enormous blessing time-saver",
    "start": "503360",
    "end": "510139"
  },
  {
    "text": "money saver everything now it's possible that those solutions both our managed",
    "start": "510139",
    "end": "518120"
  },
  {
    "text": "services and the stage maker marketplace partner solutions don't solve your problem so then what do you do well",
    "start": "518120",
    "end": "524059"
  },
  {
    "text": "number one you're going to need data so make sure you have data make sure you have the data that's relevant to the",
    "start": "524059",
    "end": "529790"
  },
  {
    "text": "task at hand and then first choice should be using the sage maker built-in algorithms now the sage maker built-in",
    "start": "529790",
    "end": "536720"
  },
  {
    "text": "algorithms sar highly robust we can handle vision and language of course in deep learning",
    "start": "536720",
    "end": "542290"
  },
  {
    "text": "also all the ordinary predictive models such as XG boost linear regression",
    "start": "542290",
    "end": "549019"
  },
  {
    "text": "logistic regression classification what's beautiful and it really is",
    "start": "549019",
    "end": "554149"
  },
  {
    "text": "beautiful I was gonna say something else but it what's beautiful about using the built-in algorithms is we do an enormous",
    "start": "554149",
    "end": "561589"
  },
  {
    "text": "amount of heavy lifting for you number one we can automatically batch your data and feed it so that you never run out of",
    "start": "561589",
    "end": "568009"
  },
  {
    "text": "memory in your GPU you can grow out of an individual GPU into multiple GPUs you",
    "start": "568009",
    "end": "574639"
  },
  {
    "text": "can grow out of a single instance and into a cluster of the most powerful GPU",
    "start": "574639",
    "end": "580910"
  },
  {
    "text": "instances that are made today our p3 class now it's also possible that you",
    "start": "580910",
    "end": "586699"
  },
  {
    "text": "might have to write a custom model from scratch and that's what we're going to talk about the rest of this session but",
    "start": "586699",
    "end": "591829"
  },
  {
    "text": "I do want to emphasize that you've got to go through this process to get to the point where you're going to use",
    "start": "591829",
    "end": "597109"
  },
  {
    "text": "tensorflow MX net or PI torch so why use PI torch",
    "start": "597109",
    "end": "603309"
  },
  {
    "text": "probably the number one thing people point to is that you can create a dynamic neural network in other words as",
    "start": "603309",
    "end": "611149"
  },
  {
    "text": "opposed to a symbolic approach which is common in other frameworks pi torch is",
    "start": "611149",
    "end": "617269"
  },
  {
    "text": "almost it is exclusively operating where you're have a dynamic graph so each",
    "start": "617269",
    "end": "625040"
  },
  {
    "text": "command within pi torch as it executes has the option of redefining the",
    "start": "625040",
    "end": "631610"
  },
  {
    "text": "computational graph and tensor flow you have to define the entire computational graph of model then run it but in pi",
    "start": "631610",
    "end": "638959"
  },
  {
    "text": "torch you can define and manipulate the graph on the go now of course there's",
    "start": "638959",
    "end": "644149"
  },
  {
    "text": "tensor flow eager and I'll just express my personal opinion here I've been using",
    "start": "644149",
    "end": "649639"
  },
  {
    "text": "tensor flow for five years now you know it was invented at a time where people",
    "start": "649639",
    "end": "654709"
  },
  {
    "text": "didn't really know where machine learning is going to go and you know they do a great job of open of improving",
    "start": "654709",
    "end": "660829"
  },
  {
    "text": "it it's an open source project the beauty of Pi torch is that its",
    "start": "660829",
    "end": "666459"
  },
  {
    "text": "origins are more modern we kind of had this eye dia that Python was going to be the",
    "start": "666459",
    "end": "672990"
  },
  {
    "text": "lingua franca of machine learning so it just takes this different approach that",
    "start": "672990",
    "end": "678899"
  },
  {
    "text": "I think is much more appropriate to the tasks especially of deep learning and",
    "start": "678899",
    "end": "683940"
  },
  {
    "text": "that is reflected in the fact that just about every paper coming out now is done in PI George Wright just about I'm not",
    "start": "683940",
    "end": "690600"
  },
  {
    "text": "going to percentage eyes that but many or most are coming out in PI torch PI",
    "start": "690600",
    "end": "695640"
  },
  {
    "text": "torches designed to leverage math processing power and accelerate the GPU this is another more modern approach",
    "start": "695640",
    "end": "703130"
  },
  {
    "text": "memory opt is it optimization is built-in and I've already mentioned you know PI torches Python centric so it's",
    "start": "703130",
    "end": "710250"
  },
  {
    "text": "really designed so that it looks and feels like Python it's easier to learn",
    "start": "710250",
    "end": "718230"
  },
  {
    "text": "and because it's easier to learn because it's just Python you don't have to learn the built-in mechanics of the",
    "start": "718230",
    "end": "724320"
  },
  {
    "text": "computational graph or symbolic language it feels natural and it's just easier to",
    "start": "724320",
    "end": "730019"
  },
  {
    "text": "build complicated and and retaining your mind complicated architectures so it",
    "start": "730019",
    "end": "737579"
  },
  {
    "text": "just really inherits all those benefits of natural Python tensorflow is known",
    "start": "737579",
    "end": "743940"
  },
  {
    "text": "for having a very steep learning curve and I think this is why we're starting",
    "start": "743940",
    "end": "748980"
  },
  {
    "text": "to see a lot of this adoption now there there are some negatives I let me just",
    "start": "748980",
    "end": "753990"
  },
  {
    "text": "touch on this briefly so especially if you look at MX net MX net supports two",
    "start": "753990",
    "end": "759360"
  },
  {
    "text": "styles of programming imperative and symbolic so when you're using MX net you",
    "start": "759360",
    "end": "766260"
  },
  {
    "text": "have the option of locking in and you know you're not going to change your computational graph right so you have",
    "start": "766260",
    "end": "771810"
  },
  {
    "text": "this option of using the symbol API and getting all those benefits of a",
    "start": "771810",
    "end": "777449"
  },
  {
    "text": "pre-trained app reconstructed computational graph for training and hyper parameter",
    "start": "777449",
    "end": "782940"
  },
  {
    "text": "optimization and deployment also you know there's no tensor board in pi torch",
    "start": "782940",
    "end": "789860"
  },
  {
    "text": "you know obviously you can sort of get it to work and there's there's options for this but PI torches once again just",
    "start": "789860",
    "end": "796769"
  },
  {
    "text": "kind of a basic tool in it and if you haven't used either of these tensor",
    "start": "796769",
    "end": "801870"
  },
  {
    "text": "board is a tool that enables you to visualize your model store in a browser you could use matplotlib",
    "start": "801870",
    "end": "808850"
  },
  {
    "text": "and that's what most people do pi torture these things but it's it's a bit of a drawback now I think to date it's",
    "start": "808850",
    "end": "818480"
  },
  {
    "text": "pretty much well acknowledged that tensorflow and MX net are better for production models and scalability and",
    "start": "818480",
    "end": "824360"
  },
  {
    "text": "I'm certainly not going to take anything away from that I think at the state-of-the-art in PI torch for",
    "start": "824360",
    "end": "830239"
  },
  {
    "text": "production for enterprises evolving but that's why I wanted to have this webinar today because it is evolving it's not",
    "start": "830239",
    "end": "837259"
  },
  {
    "text": "stuck and I think there's a few elements within sage maker that in particular",
    "start": "837259",
    "end": "843379"
  },
  {
    "text": "that make it really easy to adopt last but not least PI torch supports only",
    "start": "843379",
    "end": "849170"
  },
  {
    "text": "Python and C plus plus MX net supports Java Scala closure and R in addition to",
    "start": "849170",
    "end": "856309"
  },
  {
    "text": "Python and C++ this can be really important of course if you're on one of",
    "start": "856309",
    "end": "862129"
  },
  {
    "text": "those architectures right so or programming languages in particular are Java and Scala so there's a lot of",
    "start": "862129",
    "end": "870019"
  },
  {
    "text": "positives handful of negatives oops this one's out of order but oh I think I do",
    "start": "870019",
    "end": "878089"
  },
  {
    "text": "why I put this here okay so why is PI torch popular right now well I think you",
    "start": "878089",
    "end": "885170"
  },
  {
    "text": "can almost single-handedly give credit to fast AI feste AI is a massive online",
    "start": "885170",
    "end": "892999"
  },
  {
    "text": "open massively open online course free that's given out of us University of San",
    "start": "892999",
    "end": "901999"
  },
  {
    "text": "Francisco by Jeremy Howard and Rachel Thomas who are simply the thought",
    "start": "901999",
    "end": "907790"
  },
  {
    "text": "leaders in this field they're the best they're easy to work with I just have to",
    "start": "907790",
    "end": "913730"
  },
  {
    "text": "say I think they as a group they single-handedly really brought pi torch",
    "start": "913730",
    "end": "918860"
  },
  {
    "text": "to the masses through this course if you haven't taken the course it's free I could not encourage you more to do",
    "start": "918860",
    "end": "925610"
  },
  {
    "text": "this next I just want to give you one quick sample of the fast AI interface",
    "start": "925610",
    "end": "931069"
  },
  {
    "text": "now fast AI is a module it's a Python module you just do a pip install fast AI or a Conda install",
    "start": "931069",
    "end": "937900"
  },
  {
    "text": "and you get all the benefits of this language the language higher level features but this is the thing it's not",
    "start": "937900",
    "end": "943480"
  },
  {
    "text": "really higher level so it's approximately like care us but kerasys",
    "start": "943480",
    "end": "948970"
  },
  {
    "text": "genuinely higher level you lose performance and flexibility when you use care us you don't have that experience",
    "start": "948970",
    "end": "956530"
  },
  {
    "text": "in fast AI and I think that's why they gave it this name typical pipeline is",
    "start": "956530",
    "end": "962590"
  },
  {
    "text": "shown in this very short method here called get data where you're taking your",
    "start": "962590",
    "end": "968590"
  },
  {
    "text": "data and you're doing an immediate transform and data bunch which is a",
    "start": "968590",
    "end": "976270"
  },
  {
    "text": "combination of data loading and and preparing your data set and loading that",
    "start": "976270",
    "end": "982330"
  },
  {
    "text": "data set in a very simple command that's in Python syntax also accessing models",
    "start": "982330",
    "end": "990970"
  },
  {
    "text": "such as convolutional neural networks is simple is as simple as saying here",
    "start": "990970",
    "end": "996400"
  },
  {
    "text": "CNN underbar learner so these are two separate and distinct examples of how I",
    "start": "996400",
    "end": "1001830"
  },
  {
    "text": "use the API pretty much everyone who's used fast AI is pretty familiar with that",
    "start": "1001830",
    "end": "1008130"
  },
  {
    "text": "architecture so if this is new to you once again I simply encourage you to take a look so what is the adoption well",
    "start": "1008130",
    "end": "1015470"
  },
  {
    "text": "this these are statistics from April and",
    "start": "1015470",
    "end": "1020670"
  },
  {
    "text": "we could see without question were you to list popularity based on job listings",
    "start": "1020670",
    "end": "1026720"
  },
  {
    "text": "tensorflow is still the leader but look at pi torch I mean it's just sort of an elbow away",
    "start": "1026720",
    "end": "1033089"
  },
  {
    "text": "caris is listed third but of course caris runs on Amex net and tensorflow",
    "start": "1033089",
    "end": "1039079"
  },
  {
    "text": "fast day is showing up as a job requirement but obviously negligible on",
    "start": "1039080",
    "end": "1044699"
  },
  {
    "text": "this particular search but here's where the rubber hits the road I mean it's",
    "start": "1044700",
    "end": "1050490"
  },
  {
    "text": "just undeniable that the Sun of setting a little bit on tensorflow and that pi torches is popping up right and if you",
    "start": "1050490",
    "end": "1057750"
  },
  {
    "text": "take a look at this chart here which is just showing Google search trends there",
    "start": "1057750",
    "end": "1064410"
  },
  {
    "text": "PI torch n tensorflow are clearly converging so this is an important",
    "start": "1064410",
    "end": "1070500"
  },
  {
    "text": "framework in I like to show these statistics here just to underline the fact that pie",
    "start": "1070500",
    "end": "1076510"
  },
  {
    "text": "chart is worth paying attention to if you're not using it today you know where to go in the wild",
    "start": "1076510",
    "end": "1083020"
  },
  {
    "text": "recently at Facebook's f8 developer conference a couple of good sessions on",
    "start": "1083020",
    "end": "1088600"
  },
  {
    "text": "how Facebook is using pi torch it's obviously in the phone on all platforms",
    "start": "1088600",
    "end": "1096539"
  },
  {
    "text": "it's going to be in the cloud they're using it for vision for language",
    "start": "1096539",
    "end": "1101860"
  },
  {
    "text": "processing so you know this is kind of Facebook's baby so it makes sense that they have an enormous number of",
    "start": "1101860",
    "end": "1107679"
  },
  {
    "text": "production instances we support quite a bit of Pi torch and I do in my",
    "start": "1107679",
    "end": "1113950"
  },
  {
    "text": "day-to-day job here as a Solutions Architect one of those incidences is at",
    "start": "1113950",
    "end": "1119260"
  },
  {
    "text": "Airbnb where they're using PI torch as a dialog assistant for customer service",
    "start": "1119260",
    "end": "1126029"
  },
  {
    "text": "Genentech is doing drug discovery in cancer therapy and personalized cancer",
    "start": "1126029",
    "end": "1131169"
  },
  {
    "text": "medicine principally in pi torch and Toyota research is using it for odd",
    "start": "1131169",
    "end": "1137130"
  },
  {
    "text": "autonomous driving now those are for sure production examples one of the",
    "start": "1137130",
    "end": "1142840"
  },
  {
    "text": "things that we know about PI torch in general is that it's been popular because it's a great research tool so",
    "start": "1142840",
    "end": "1149740"
  },
  {
    "text": "what's the difference here well research has a training focus and what I mean by training is that you're coming up with",
    "start": "1149740",
    "end": "1157299"
  },
  {
    "text": "new models you're experimenting with new architectures and then you're training against your data and it's flexibility",
    "start": "1157299",
    "end": "1164529"
  },
  {
    "text": "in particular that ability to modify your graph while you're training is is",
    "start": "1164529",
    "end": "1170890"
  },
  {
    "text": "really what has driven this popularity enterprise is different of course getting into production can be tough",
    "start": "1170890",
    "end": "1179220"
  },
  {
    "text": "machine learning principally produces features not solutions and what I mean by that is you're you may be creating a",
    "start": "1179220",
    "end": "1187870"
  },
  {
    "text": "feature that say two-factor authentication through computer vision",
    "start": "1187870",
    "end": "1193090"
  },
  {
    "text": "perhaps counting with computer vision maybe language processing in a customer",
    "start": "1193090",
    "end": "1199840"
  },
  {
    "text": "service environment and these are critical features but sitting within solutions that maybe have",
    "start": "1199840",
    "end": "1208110"
  },
  {
    "text": "you know 20 or 30 or 200 or 300 other features so when you get out of the data",
    "start": "1208110",
    "end": "1215970"
  },
  {
    "text": "scientist role and you have your model that works you go into your developer",
    "start": "1215970",
    "end": "1222149"
  },
  {
    "text": "and dev ops role in security roles all of which have a much different focus so",
    "start": "1222149",
    "end": "1227610"
  },
  {
    "text": "your focus goes from accuracy reliability getting good prediction numbers to all of the sudden is it",
    "start": "1227610",
    "end": "1234480"
  },
  {
    "text": "robust does this feature when it fails does it kill the rest of my pipeline is",
    "start": "1234480",
    "end": "1242970"
  },
  {
    "text": "it is it possible for me to use this in a decision support system and provide",
    "start": "1242970",
    "end": "1248879"
  },
  {
    "text": "explain ability is it possible to put it into C ICD for continuous integration and deployment without breaking",
    "start": "1248879",
    "end": "1255779"
  },
  {
    "text": "everything else absolutely important across the globe right now is privacy",
    "start": "1255779",
    "end": "1261779"
  },
  {
    "text": "and security so GDP our PCI HIPAA the California",
    "start": "1261779",
    "end": "1268080"
  },
  {
    "text": "Consumer Protection Act are all issues where we're now discovering that people",
    "start": "1268080",
    "end": "1274440"
  },
  {
    "text": "know how to mess with especially computer vision models you know there's",
    "start": "1274440",
    "end": "1279990"
  },
  {
    "text": "such a thing as hacking computer vision models announce in the news and also you",
    "start": "1279990",
    "end": "1285389"
  },
  {
    "text": "know delete ability can if someone got a hold of the model can they pull out private information well guess what the",
    "start": "1285389",
    "end": "1291509"
  },
  {
    "text": "answer is yes so there's a lot of issues around making",
    "start": "1291509",
    "end": "1296549"
  },
  {
    "text": "sure that your apps are compliant finally there's monitoring and analytics obviously we need to monitor our apps",
    "start": "1296549",
    "end": "1303240"
  },
  {
    "text": "not only to make sure they're up and satisfying our customers but also we want to know where's the growth and so",
    "start": "1303240",
    "end": "1310200"
  },
  {
    "text": "how do we take our pike-perch models and put them into the same production framework as as our other apps so first",
    "start": "1310200",
    "end": "1317759"
  },
  {
    "text": "up I'm going to bring up my browser now and let's take a look here at the",
    "start": "1317759",
    "end": "1324840"
  },
  {
    "text": "features that are within Sage maker let me just do a little housekeeping here so",
    "start": "1324840",
    "end": "1331230"
  },
  {
    "text": "well not sage maker I'm sorry I said CH maker but the first thing we're gonna do is look at the deep learning",
    "start": "1331230",
    "end": "1337850"
  },
  {
    "text": "me so if you're not familiar with the deep learning ah me I'm gonna make you familiar get you familiar with it right",
    "start": "1337850",
    "end": "1343309"
  },
  {
    "text": "now so at the stage maker F stage at the AWS console obviously one of our most",
    "start": "1343309",
    "end": "1349910"
  },
  {
    "text": "popular services is ec2 and here you can launch an instance of any type and",
    "start": "1349910",
    "end": "1358100"
  },
  {
    "text": "before you begin to do anything you have an option to choose an Amazon machine image or AMI",
    "start": "1358100",
    "end": "1364010"
  },
  {
    "text": "if you go to the AWS marketplace and just type deep learning I'll make this a",
    "start": "1364010",
    "end": "1370190"
  },
  {
    "text": "little bigger for everybody and hit return you'll see that AWS provides a",
    "start": "1370190",
    "end": "1375830"
  },
  {
    "text": "number of the deep learning Ami's and we can run on a boon - for example let's",
    "start": "1375830",
    "end": "1382760"
  },
  {
    "text": "click on more info here and oops I guess",
    "start": "1382760",
    "end": "1388250"
  },
  {
    "text": "we don't want to choose that one let's do this one okay cool but what is going",
    "start": "1388250",
    "end": "1393770"
  },
  {
    "text": "on here hey this happens to be all the time and you know yes what boy all right",
    "start": "1393770",
    "end": "1403460"
  },
  {
    "text": "this is new sorry forgive me and let me just go to this link and make sure that I have oh this makes sense",
    "start": "1403460",
    "end": "1410419"
  },
  {
    "text": "oh they put the they put the army in the marketplace okay so one of the things Oh",
    "start": "1410419",
    "end": "1415900"
  },
  {
    "text": "emphasize about deep learning is don't get attached to anything as you can see",
    "start": "1415900",
    "end": "1421789"
  },
  {
    "text": "even I who work on this stuff every day discover new features on AWS so let me",
    "start": "1421789",
    "end": "1428929"
  },
  {
    "text": "blow this up a little bit because the concept obviously is all still the same so the deep learning ami is a",
    "start": "1428929",
    "end": "1436640"
  },
  {
    "text": "pre-configured ami that includes all the popular machine learning frameworks and it's built on a bedrock that takes",
    "start": "1436640",
    "end": "1443960"
  },
  {
    "text": "advantage of our NVIDIA GPUs right so we have CUDA si UD n n n CCL we have of",
    "start": "1443960",
    "end": "1452659"
  },
  {
    "text": "course MX net with gluon tensorflow cafe and pi torch trainer etcetera",
    "start": "1452659",
    "end": "1460610"
  },
  {
    "text": "so when you law when you log on when you load up a an ec2 instance with this ami",
    "start": "1460610",
    "end": "1468890"
  },
  {
    "text": "you're going to have pre-built in it everything that you need to get running right away and of course we charge by",
    "start": "1468890",
    "end": "1475249"
  },
  {
    "text": "the second on everything so it's a really great way if you just want metal and you want an environment to do",
    "start": "1475249",
    "end": "1482210"
  },
  {
    "text": "machine learning development you can launch this in in less than five minutes on almost any ec2 instance and I'll just",
    "start": "1482210",
    "end": "1491090"
  },
  {
    "text": "do this for sport here and let's pick a p3 I'm just scrolling down through the",
    "start": "1491090",
    "end": "1500749"
  },
  {
    "text": "various instance types why not choose a GPU instance with a p3 16x large right",
    "start": "1500749",
    "end": "1506830"
  },
  {
    "text": "so when we go to configure that instance we will see that now if I had brought up",
    "start": "1506830",
    "end": "1514999"
  },
  {
    "text": "a c5 or something you can see this option here this is a new option to add",
    "start": "1514999",
    "end": "1521840"
  },
  {
    "text": "an elastic elastic inference accelerator",
    "start": "1521840",
    "end": "1527029"
  },
  {
    "text": "so this is this software GPU add-on so",
    "start": "1527029",
    "end": "1532090"
  },
  {
    "text": "take note of that whenever you're launching any ec2 instance now that you can add additional GPUs just by clicking",
    "start": "1532090",
    "end": "1539840"
  },
  {
    "text": "that switch all right there might be questions about that later and I'm sorry that was a little confusing because I",
    "start": "1539840",
    "end": "1545480"
  },
  {
    "text": "had failed to see that we moved the deep-learning ami but that's all part of",
    "start": "1545480",
    "end": "1552110"
  },
  {
    "text": "live webinars all right so let's go to sage maker a few things about sage maker",
    "start": "1552110",
    "end": "1558559"
  },
  {
    "text": "if you've never seen sage maker before I describe it as a fabric and a fabric a",
    "start": "1558559",
    "end": "1564110"
  },
  {
    "text": "software fabric is where you take a number of independent modules software components that can be used completely",
    "start": "1564110",
    "end": "1570649"
  },
  {
    "text": "on their own but then when put together look like a single product and so what are those",
    "start": "1570649",
    "end": "1576889"
  },
  {
    "text": "four components for Sage maker well there's ground truth for labeling then notebook instance is Jupiter notebooks",
    "start": "1576889",
    "end": "1582379"
  },
  {
    "text": "which we're gonna launch in a moment here a training module where you can",
    "start": "1582379",
    "end": "1587419"
  },
  {
    "text": "submit training jobs that will - that will train in the background highly optimizing",
    "start": "1587419",
    "end": "1593179"
  },
  {
    "text": "affordability of developing machine learning models and then inference right inferences in production in the cloud",
    "start": "1593179",
    "end": "1600080"
  },
  {
    "text": "now we're in the Oregon we're in the Oregon",
    "start": "1600080",
    "end": "1605420"
  },
  {
    "text": "right now I'm actually gonna switch here to Ohio because I have a few things that",
    "start": "1605420",
    "end": "1612020"
  },
  {
    "text": "I pre ran here to just for a demonstration here today I have one",
    "start": "1612020",
    "end": "1617060"
  },
  {
    "text": "notebook and service but before I start that when you want to start a notebook here you go to notebook instances create",
    "start": "1617060",
    "end": "1624680"
  },
  {
    "text": "notebook instance you give it a name I",
    "start": "1624680",
    "end": "1629500"
  },
  {
    "text": "think that needs to be connected so I'll just do this and I choose your instance",
    "start": "1630580",
    "end": "1637430"
  },
  {
    "text": "type we just went through that whole list over there I discourage you from choosing any of the expensive machines",
    "start": "1637430",
    "end": "1646610"
  },
  {
    "text": "just to run a Jupiter notebook you can easily run on this t2 instance which is",
    "start": "1646610",
    "end": "1651830"
  },
  {
    "text": "less than you know a diamond hour but then do your training in the cloud on the heavier metal and you can add GPUs",
    "start": "1651830",
    "end": "1658280"
  },
  {
    "text": "to Sage maker as well through that elastic inference so that's how easy it",
    "start": "1658280",
    "end": "1663350"
  },
  {
    "text": "is you can start up with a git repository by just listing it right here and you're off to the races I'm not",
    "start": "1663350",
    "end": "1669740"
  },
  {
    "text": "going to do that because I already have one running that's pre baked you have the option of using Jupiter lab I'm just",
    "start": "1669740",
    "end": "1675800"
  },
  {
    "text": "gonna open Jupiter itself hope I'm not going too fast but here we are so once",
    "start": "1675800",
    "end": "1682820"
  },
  {
    "text": "you go into Sage maker Jupiter notebooks you'll see this interface and it's if",
    "start": "1682820",
    "end": "1688580"
  },
  {
    "text": "you've used Jupiter before it should be fairly familiar I have one notebook that happens to be running here but the",
    "start": "1688580",
    "end": "1695720"
  },
  {
    "text": "feature I want to point out is our sage maker examples so we have an accordion list here of more than a hundred might",
    "start": "1695720",
    "end": "1702500"
  },
  {
    "text": "be more than 200 samples of deep learning principally deep learning",
    "start": "1702500",
    "end": "1708970"
  },
  {
    "text": "notebooks ready to use and ready to use for copy and paste so we have the",
    "start": "1708970",
    "end": "1715760"
  },
  {
    "text": "introduction Amazon algorithms and applying machine learning advanced functionality yadda yadda but you'll see",
    "start": "1715760",
    "end": "1721430"
  },
  {
    "text": "you down here we have some very specific PI torch examples first of all we have",
    "start": "1721430",
    "end": "1728480"
  },
  {
    "text": "the entire oops we have the entire fast",
    "start": "1728480",
    "end": "1733490"
  },
  {
    "text": "AI course version three so you could take fast AI course and run the entire course",
    "start": "1733490",
    "end": "1742260"
  },
  {
    "text": "on sage maker and it's a good idea to do that",
    "start": "1742260",
    "end": "1747720"
  },
  {
    "text": "in fact I took one I took the cam vid",
    "start": "1747720",
    "end": "1752840"
  },
  {
    "text": "lesson and I'm just gonna pop over here to Oregon it's just trying to keep this",
    "start": "1753050",
    "end": "1759120"
  },
  {
    "text": "stuff separate and I just ran one of them I just want to show you what that experience looks like and I don't want",
    "start": "1759120",
    "end": "1768300"
  },
  {
    "text": "to take a look at my existing instances here we go we'll open Jupiter yeah there",
    "start": "1768300",
    "end": "1775770"
  },
  {
    "text": "we go so here we go oh well I took the",
    "start": "1775770",
    "end": "1787050"
  },
  {
    "text": "distributed training model and no I'm not seeing it and that's too bad all",
    "start": "1787050",
    "end": "1795240"
  },
  {
    "text": "right well I ran this model is gonna show it to you all executed oh it is run not a second okay I did run this okay so",
    "start": "1795240",
    "end": "1802320"
  },
  {
    "text": "this is a popular computer vision problem using segmentation so this is I",
    "start": "1802320",
    "end": "1810420"
  },
  {
    "text": "think in lesson three of the fast AI which the fact that this is in lesson",
    "start": "1810420",
    "end": "1816120"
  },
  {
    "text": "three should indicate how fast fast AI is that you can come in and begin to do",
    "start": "1816120",
    "end": "1823230"
  },
  {
    "text": "a autonomous driving computer vision model using a photograph such as this",
    "start": "1823230",
    "end": "1828900"
  },
  {
    "text": "with a pre labeled segmentation set like this and do a highly accurate I'll just grunt to skip to the chase",
    "start": "1828900",
    "end": "1835970"
  },
  {
    "text": "predictive model at the end so this is one of the built-in built-in lessons for",
    "start": "1835970",
    "end": "1843840"
  },
  {
    "text": "fast AI along the way Jeremy does a couple of things one thing that's really",
    "start": "1843840",
    "end": "1850380"
  },
  {
    "text": "sort of unique to his approach is finding the correct learning rate to use",
    "start": "1850380",
    "end": "1855780"
  },
  {
    "text": "and he also does what's called an eel annealing learning rate where your",
    "start": "1855780",
    "end": "1861060"
  },
  {
    "text": "learning rate actually starts off incremental II larger and then once you",
    "start": "1861060",
    "end": "1866280"
  },
  {
    "text": "hit sort of a turnaround point gets incremental II smaller which dramatic",
    "start": "1866280",
    "end": "1871559"
  },
  {
    "text": "Clee reduces your training time and expense in training so just a couple of",
    "start": "1871559",
    "end": "1877529"
  },
  {
    "text": "features there I wanted to point out so I'm gonna close this so in addition to",
    "start": "1877529",
    "end": "1885049"
  },
  {
    "text": "the whole fast AI library being up there in Sage Maker examples we have all of",
    "start": "1885049",
    "end": "1891450"
  },
  {
    "text": "the PI torch tutorials so these PI torch tutorials are the ones that you'll see if you go to PI torch org in the",
    "start": "1891450",
    "end": "1898789"
  },
  {
    "text": "tutorial section and I'll just take a look at a this classification tutorial",
    "start": "1898789",
    "end": "1906210"
  },
  {
    "text": "you'll notice if you're not familiar with sage maker on the right hand side here you have two options now if I know",
    "start": "1906210",
    "end": "1911730"
  },
  {
    "text": "this tutorial and I know that there's an RNN in there that I want to copy and paste I don't need to actually run that",
    "start": "1911730",
    "end": "1919080"
  },
  {
    "text": "or set up a whole permanent notebook to take a look at this code if you just",
    "start": "1919080",
    "end": "1924119"
  },
  {
    "text": "click on preview you'll go into the code and this is exactly the way you'll find",
    "start": "1924119",
    "end": "1931080"
  },
  {
    "text": "it in github so it's really just here as a convenience if you're coming down here",
    "start": "1931080",
    "end": "1936629"
  },
  {
    "text": "you take a look at the network you're like this is what I was looking for right so you could just copy and paste",
    "start": "1936629",
    "end": "1942360"
  },
  {
    "text": "that out and use it in your own code so that's what it's here for it's here to accelerate your development now we did",
    "start": "1942360",
    "end": "1948749"
  },
  {
    "text": "not we're not running a notebook so I can just kill that tab and I it's very very little expense for going in there",
    "start": "1948749",
    "end": "1955950"
  },
  {
    "text": "and modifying modifying your work so that's a quick overview of what's",
    "start": "1955950",
    "end": "1962580"
  },
  {
    "text": "available in the example in the sample notebooks and it popped back over to",
    "start": "1962580",
    "end": "1967679"
  },
  {
    "text": "Ohio here and I want to take a look at one or two more one or two more",
    "start": "1967679",
    "end": "1973740"
  },
  {
    "text": "interesting features that we have for Python in sage maker let's let's do this",
    "start": "1973740",
    "end": "1980820"
  },
  {
    "text": "this way there you go back to the Presto",
    "start": "1980820",
    "end": "1987440"
  },
  {
    "text": "alright alright good so there's the sage maker notebooks um oh here's something",
    "start": "1987440",
    "end": "1995129"
  },
  {
    "text": "interesting I don't like notebooks and I know that",
    "start": "1995129",
    "end": "2001009"
  },
  {
    "text": "I'm not the only one you know there are dozens that don't like",
    "start": "2001009",
    "end": "2006649"
  },
  {
    "text": "notebooks okay so that's principally because you know I come from a developer",
    "start": "2006649",
    "end": "2013070"
  },
  {
    "text": "background maybe not necessarily data science background but I want to use all",
    "start": "2013070",
    "end": "2018080"
  },
  {
    "text": "these - all of these frameworks in my tools of choice so my particular tool of",
    "start": "2018080",
    "end": "2024620"
  },
  {
    "text": "choice Cho it blat tool of choice at the moment happens to be Visual Studio code",
    "start": "2024620",
    "end": "2030130"
  },
  {
    "text": "so that's what I'm typically using when I want to well work on almost anything",
    "start": "2030130",
    "end": "2036890"
  },
  {
    "text": "and I have a few examples here that I'd like to show you and and just by way of",
    "start": "2036890",
    "end": "2044710"
  },
  {
    "text": "demonstration just to open up this folder here so if you're familiar with",
    "start": "2044710",
    "end": "2051310"
  },
  {
    "text": "Visual Studio code then everything here will look familiar to you I know there's",
    "start": "2051310",
    "end": "2057320"
  },
  {
    "text": "PyCharm there's a lot of tools out there this is a particular CNN that I like to",
    "start": "2057320",
    "end": "2064669"
  },
  {
    "text": "use to describe some of the features of fast AI actually not fast eh I bet PI",
    "start": "2064669",
    "end": "2072500"
  },
  {
    "text": "torch so some of the more important features in and this is just a simple CNN from Amnesty so you could see here",
    "start": "2072500",
    "end": "2080300"
  },
  {
    "text": "at the bottom here's the actual CNN it's very simple we do convolutional 2d",
    "start": "2080300",
    "end": "2087888"
  },
  {
    "text": "networks that average out too cool I'll show you the lambda function in a moment here but what's nice about",
    "start": "2087889",
    "end": "2094520"
  },
  {
    "text": "this is it's you know 144 lines and then",
    "start": "2094520",
    "end": "2099800"
  },
  {
    "text": "the process you can pretty much get most of what most of the the simple and basic",
    "start": "2099800",
    "end": "2106220"
  },
  {
    "text": "features that you're going to be using in pi torch all the time so there's a",
    "start": "2106220",
    "end": "2111680"
  },
  {
    "text": "few modules the neural network module which is not to be mistaken with a PI",
    "start": "2111680",
    "end": "2118790"
  },
  {
    "text": "torch module which is lower case M is basically used to hold your weights and bias I don't know if I mentioned in the",
    "start": "2118790",
    "end": "2127130"
  },
  {
    "text": "beginning the auto grad or Auto gradient back propagation feature that's in PI",
    "start": "2127130",
    "end": "2132980"
  },
  {
    "text": "torch that - is a really key feature of Pi torch",
    "start": "2132980",
    "end": "2139279"
  },
  {
    "text": "so obviously we're creating a deeper neural network we want to be able to have a forward pass where we take a good",
    "start": "2139279",
    "end": "2145880"
  },
  {
    "text": "guess at what our weights and biases should be then we want to back propagate so the auto grad feature within within",
    "start": "2145880",
    "end": "2157359"
  },
  {
    "text": "pi torch will do that for us here we were setting up for our initial weights",
    "start": "2157359",
    "end": "2164059"
  },
  {
    "text": "and bias a simple linear linear regressor and we have the the shape of",
    "start": "2164059",
    "end": "2172910"
  },
  {
    "text": "the am-ness data set which is of course 780 and we've got ten digits in there so",
    "start": "2172910",
    "end": "2178160"
  },
  {
    "text": "with this single function here we have completely initialized our neural",
    "start": "2178160",
    "end": "2184700"
  },
  {
    "text": "network to begin training as we move down just a little bit there's two",
    "start": "2184700",
    "end": "2190609"
  },
  {
    "text": "features one is I actually have to have come down here a little bit we're going to load up our data set we're just going",
    "start": "2190609",
    "end": "2196969"
  },
  {
    "text": "to copy it off of deep learning net will download it we unpick live I don't know",
    "start": "2196969",
    "end": "2203359"
  },
  {
    "text": "if that's an expression or not we need to map it because it doesn't come in a way that's immediately useful and then",
    "start": "2203359",
    "end": "2209630"
  },
  {
    "text": "we have these two calls right so here we're taking our training and validation sets and adding them using something",
    "start": "2209630",
    "end": "2217430"
  },
  {
    "text": "called a tensor data set so tensor data set is going to help us batch our load",
    "start": "2217430",
    "end": "2226130"
  },
  {
    "text": "up our data batch our data and then the data loader is going to help us batch it",
    "start": "2226130",
    "end": "2231229"
  },
  {
    "text": "so these few modules n n modules has you",
    "start": "2231229",
    "end": "2237499"
  },
  {
    "text": "know a little bit more I think it's got about a dozen ready-made models for you",
    "start": "2237499",
    "end": "2243529"
  },
  {
    "text": "to initialize your architecture data set will automatically pre process and put",
    "start": "2243529",
    "end": "2250940"
  },
  {
    "text": "features around the data set itself and then data loader is going to help you do",
    "start": "2250940",
    "end": "2258469"
  },
  {
    "text": "mini batches and and iterate through your data set in your epics those are",
    "start": "2258469",
    "end": "2263630"
  },
  {
    "text": "really useful and that's it so when we actually come to fit our model it turns",
    "start": "2263630",
    "end": "2268729"
  },
  {
    "text": "out to be a pretty simple and I think what is about a dozen lines pretty simple and",
    "start": "2268729",
    "end": "2275839"
  },
  {
    "text": "readily easy really easy to read model so we come down here and you'll see at",
    "start": "2275839",
    "end": "2283579"
  },
  {
    "text": "the end here we actually run our well here's another thing too this is how you",
    "start": "2283579",
    "end": "2289880"
  },
  {
    "text": "determine whether or not you have a GPU available so it's a real simple call",
    "start": "2289880",
    "end": "2295249"
  },
  {
    "text": "torch device if CUDA exists you use that otherwise uses CPU and now this model is running",
    "start": "2295249",
    "end": "2302539"
  },
  {
    "text": "on the appropriate machine you just say model - that's it that's all you have to do to switch dynamically let's say you",
    "start": "2302539",
    "end": "2310160"
  },
  {
    "text": "have a an apple laptop right it's not going to have an NVIDIA GPU in it so you",
    "start": "2310160",
    "end": "2315650"
  },
  {
    "text": "can develop your models here it takes a little longer baby you've police bug check syntax check etcetera and I've",
    "start": "2315650",
    "end": "2322670"
  },
  {
    "text": "only touched the beginning of the features that's why I said I I can't do justice to Pi torch in in an hour and a",
    "start": "2322670",
    "end": "2328759"
  },
  {
    "text": "half I think Jeremy does it best but with these three lines here we move",
    "start": "2328759",
    "end": "2334430"
  },
  {
    "text": "the model to the GPU we said our optimizer - stochastic gradient descent and then we fit the model and I have a",
    "start": "2334430",
    "end": "2342019"
  },
  {
    "text": "keyboard shortcut that just will go ahead and actually run this in Python it",
    "start": "2342019",
    "end": "2351319"
  },
  {
    "text": "should be running there we go GPU available is true so that means I'm",
    "start": "2351319",
    "end": "2356569"
  },
  {
    "text": "running on my GPUs I have to have a surface book - which has Nvidia 1060 GPU",
    "start": "2356569",
    "end": "2363529"
  },
  {
    "text": "in it which I'm very fond of we'll just give it a moment we should start seeing our our loss and I'll just let that run",
    "start": "2363529",
    "end": "2376660"
  },
  {
    "text": "it only takes another two minutes but time is valuable in a webinar so another",
    "start": "2376660",
    "end": "2383599"
  },
  {
    "text": "feature that I'd like to talk about is sage maker local so what a stage maker",
    "start": "2383599",
    "end": "2389749"
  },
  {
    "text": "local I wish I didn't have to do this every time okay so your maker local is a",
    "start": "2389749",
    "end": "2396349"
  },
  {
    "text": "feature in stage maker where you can set up a Python environment and download the",
    "start": "2396349",
    "end": "2402920"
  },
  {
    "text": "containers on which we run all of our stuff and sage maker so",
    "start": "2402920",
    "end": "2408980"
  },
  {
    "text": "this is an MX in that example there's a PI torch example as well but literally",
    "start": "2408980",
    "end": "2414200"
  },
  {
    "text": "all you have to do to run locally after you do your setup and the setups easy",
    "start": "2414200",
    "end": "2420109"
  },
  {
    "text": "you just you just do a pip install sage maker I believe I'll look that up it's",
    "start": "2420109",
    "end": "2427520"
  },
  {
    "text": "it's easy to search for you simply change the train instance type from what",
    "start": "2427520",
    "end": "2435920"
  },
  {
    "text": "ordinarily would be there which is a ec2 instance like ml p 2x large you simply",
    "start": "2435920",
    "end": "2442490"
  },
  {
    "text": "change that to local GPU and it will run on your local GPU on your laptop and",
    "start": "2442490",
    "end": "2449599"
  },
  {
    "text": "it's the exact same thing for deploy so we you can actually do all of this work",
    "start": "2449599",
    "end": "2455780"
  },
  {
    "text": "that I'm describing right now is this hung up here live demos is the way this",
    "start": "2455780",
    "end": "2463520"
  },
  {
    "text": "always works at any rate I don't know why that isn't going to the end it shouldn't take that long usually it just",
    "start": "2463520",
    "end": "2469339"
  },
  {
    "text": "pops out but that's what happens with live demos so that's how sage maker",
    "start": "2469339",
    "end": "2478960"
  },
  {
    "text": "local works you can work in your own environment and there's many reasons well I have many reasons for not using",
    "start": "2478960",
    "end": "2485240"
  },
  {
    "text": "notebooks when I'm massaging data I want to be able to you know take the ability",
    "start": "2485240",
    "end": "2490790"
  },
  {
    "text": "to have multiple cursors and move things around process the data you know the way",
    "start": "2490790",
    "end": "2496579"
  },
  {
    "text": "that I like you know like this so you know there's a lot of reasons that I have for not using a notebook in stage",
    "start": "2496579",
    "end": "2503690"
  },
  {
    "text": "maker local makes it really easy for me to operate on my on my laptop alright so",
    "start": "2503690",
    "end": "2512030"
  },
  {
    "text": "I mentioned containers briefly a really important principle of sage maker is",
    "start": "2512030",
    "end": "2519020"
  },
  {
    "text": "that it's built on this really this fundamental architecture of the docker",
    "start": "2519020",
    "end": "2525920"
  },
  {
    "text": "containers so there's a lot of flexibility there like I said that's what makes sage maker local possible",
    "start": "2525920",
    "end": "2532869"
  },
  {
    "text": "whenever we deploy in the cloud we're doing it through inference images and I'll just pop back to the sage maker",
    "start": "2532869",
    "end": "2539930"
  },
  {
    "text": "because I want to show you how to do that where's mine there we go",
    "start": "2539930",
    "end": "2547760"
  },
  {
    "text": "so when sage maker examples if you go to advanced functionality we have a number",
    "start": "2547760",
    "end": "2555200"
  },
  {
    "text": "of notebooks that will show you how to make your own containers from scratch",
    "start": "2555200",
    "end": "2561440"
  },
  {
    "text": "right so the one I like to point to is scikit-learn I still use I get learned",
    "start": "2561440",
    "end": "2566570"
  },
  {
    "text": "quite a bit you know I like it I love it I use it for a glommit agglomerative clustering it's not dead for sure but if",
    "start": "2566570",
    "end": "2575210"
  },
  {
    "text": "you go into this notebook you'll see it's very well documented describes you know when should use your own container",
    "start": "2575210",
    "end": "2582310"
  },
  {
    "text": "you know how do you package up something for training tells you your exact file",
    "start": "2582310",
    "end": "2588140"
  },
  {
    "text": "formats to expect for inference tells you what the defaults are which is you",
    "start": "2588140",
    "end": "2593960"
  },
  {
    "text": "know flask essentially but I've seen people use all kinds of web modules up",
    "start": "2593960",
    "end": "2603440"
  },
  {
    "text": "there including a HTTP which is a node module so you're not limited to that but",
    "start": "2603440",
    "end": "2609560"
  },
  {
    "text": "here's the important thing right we actually include the docker file as well so I'll just cut that out and here you",
    "start": "2609560",
    "end": "2616490"
  },
  {
    "text": "pretty much have everything you need to do what was just described above so we give you the docker container and then",
    "start": "2616490",
    "end": "2623180"
  },
  {
    "text": "we give you all the shell commands that create the image so it's really nice and it loads that up in ECR so that's our",
    "start": "2623180",
    "end": "2630640"
  },
  {
    "text": "AWS is version of you know docker hub",
    "start": "2630640",
    "end": "2636710"
  },
  {
    "text": "essentially so everything you need is is really in this this notebook but I think",
    "start": "2636710",
    "end": "2643160"
  },
  {
    "text": "showing you is is better than telling you so I'm just gonna take a command prompt here put it in my window here and",
    "start": "2643160",
    "end": "2651730"
  },
  {
    "text": "I have something that one of my colleagues here binoy the noid daus created a few days ago and he didn't do",
    "start": "2651730",
    "end": "2660110"
  },
  {
    "text": "it for this purpose but I thought this is particularly applicable for this",
    "start": "2660110",
    "end": "2666880"
  },
  {
    "text": "hackathon hackathon I'm sorry for this webinar webinar hackathon that's all",
    "start": "2666880",
    "end": "2674190"
  },
  {
    "text": "okay so I'm gonna start up at Jupiter notebook as you can tell I'm in a DOS command shell just on my local machine",
    "start": "2674190",
    "end": "2686300"
  },
  {
    "text": "so this is not sage maker right this is my local machine Jupiter notebook here",
    "start": "2691910",
    "end": "2697200"
  },
  {
    "text": "you can see the interface is different I don't have sage maker examples and the way he did this is nice right",
    "start": "2697200",
    "end": "2703590"
  },
  {
    "text": "he's got three notebooks here and I'll go into the first and what he's doing in",
    "start": "2703590",
    "end": "2708720"
  },
  {
    "text": "this particular notebook I'll just run every oh well I guess it was already run I'll just run it again anyway because no",
    "start": "2708720",
    "end": "2714180"
  },
  {
    "text": "harm so what he does in this notebook is he puts together what we using the iris",
    "start": "2714180",
    "end": "2721530"
  },
  {
    "text": "dataset here time teensy-tiny dataset wraps it up and loads it up to s3 so why",
    "start": "2721530",
    "end": "2729750"
  },
  {
    "text": "is he doing this the reason he's loading up to s3 is if you want to use the",
    "start": "2729750",
    "end": "2736260"
  },
  {
    "text": "training subset the the training component of sage maker to really get",
    "start": "2736260",
    "end": "2743130"
  },
  {
    "text": "that financial efficiency then you have to load your data at some point up to s3",
    "start": "2743130",
    "end": "2748920"
  },
  {
    "text": "because when you're training your data you're going to be doing it on s3 so I'll close this notebook because that",
    "start": "2748920",
    "end": "2756060"
  },
  {
    "text": "was a simple task that had to be done leave that page then we'll come and",
    "start": "2756060",
    "end": "2761730"
  },
  {
    "text": "we'll just create the model so if we create the model here and once again I'm",
    "start": "2761730",
    "end": "2769260"
  },
  {
    "text": "just gonna clear all that output now restart by the way if you start this up on if you start up any notebook that you",
    "start": "2769260",
    "end": "2776940"
  },
  {
    "text": "got from github or something like this in sage maker it's really easy to change your kernel you just go change the",
    "start": "2776940",
    "end": "2784770"
  },
  {
    "text": "kernel well this is on my laptop so I only have a Python 3 but you basically just go kernel change kernel and you go",
    "start": "2784770",
    "end": "2790350"
  },
  {
    "text": "to the kernel that you want I'll go back to sage maker to show you that a moment so I'm just gonna run all these cells",
    "start": "2790350",
    "end": "2796380"
  },
  {
    "text": "let's let it run and so here he's actually running and creating the data",
    "start": "2796380",
    "end": "2804000"
  },
  {
    "text": "set model so I've run this a little bit earlier and I'm not going to wait for that to train what I'm going to do is go now to",
    "start": "2804000",
    "end": "2811830"
  },
  {
    "text": "this notebook and this is really the gist this is the one that I had to do",
    "start": "2811830",
    "end": "2817680"
  },
  {
    "text": "the two others to get here but we've got our model we've created our model now we",
    "start": "2817680",
    "end": "2823680"
  },
  {
    "text": "want to train it in the cloud so we do need to know what our execution role is",
    "start": "2823680",
    "end": "2829770"
  },
  {
    "text": "those are created in sage maker easily through the graphic user interface and here we're using a PI torch wrapper to",
    "start": "2829770",
    "end": "2837360"
  },
  {
    "text": "create our estimator and then we fit it in the cloud so what does that look like",
    "start": "2837360",
    "end": "2843030"
  },
  {
    "text": "well let's see let's do it this way I'll just run all the cells up to this point run all above and then I'll get my sage",
    "start": "2843030",
    "end": "2853470"
  },
  {
    "text": "maker home screen open in one of these windows maybe it's right here I've got",
    "start": "2853470",
    "end": "2858720"
  },
  {
    "text": "to make sure we're in Ohio we are and we'll go over to training jobs all right so it's looks like the last one I ran",
    "start": "2858720",
    "end": "2865830"
  },
  {
    "text": "failed no big deal but these are all the jobs that I've run and you can see there's nothing in process right now so",
    "start": "2865830",
    "end": "2873270"
  },
  {
    "text": "if I go back to my training notebook that's going to actually run the the",
    "start": "2873270",
    "end": "2880490"
  },
  {
    "text": "training job in the cloud it's used that we've used everything that we needed on",
    "start": "2880490",
    "end": "2887580"
  },
  {
    "text": "our notebook to create the model we're gonna launch this training job now though in the cloud and you notice I'm",
    "start": "2887580",
    "end": "2893490"
  },
  {
    "text": "not using stage maker local because I'm specifying a machine in the cloud that's all you have to do now the estimator is",
    "start": "2893490",
    "end": "2899190"
  },
  {
    "text": "just a wrapper so that happens quickly and then when we execute this it says",
    "start": "2899190",
    "end": "2904260"
  },
  {
    "text": "starting the training job well let's take a look and see if that's actually true so I'll refresh this screen and",
    "start": "2904260",
    "end": "2914130"
  },
  {
    "text": "there we go so our job was launched locally I did all my editing locally on",
    "start": "2914130",
    "end": "2919410"
  },
  {
    "text": "my local machine with PI torch but it's training in the cloud so Bravo and as",
    "start": "2919410",
    "end": "2926010"
  },
  {
    "text": "once again I can train this on any instance type so if I'm using the absolutely cheapest instance type or",
    "start": "2926010",
    "end": "2933030"
  },
  {
    "text": "using no instance type at all to do my Jupiter notebooks on my machine I can launch in the cloud and just for",
    "start": "2933030",
    "end": "2939780"
  },
  {
    "text": "training and just pay by the second so let me just finish off this notebook by pointing out that the same is true for",
    "start": "2939780",
    "end": "2947580"
  },
  {
    "text": "deploying in the cloud so this is all on my laptop I just download CH maker and state deploy and we're using the PI",
    "start": "2947580",
    "end": "2955830"
  },
  {
    "text": "torch containers to train and deploying the cloud and it did this all from my",
    "start": "2955830",
    "end": "2962190"
  },
  {
    "text": "laptop that to me is a enterprise workflow it's you know it's more what",
    "start": "2962190",
    "end": "2969780"
  },
  {
    "text": "I'm used to when I'm working in you know major companies you know folks like",
    "start": "2969780",
    "end": "2975900"
  },
  {
    "text": "using their own laptop having their own IDs that could be PyCharm and not say Visual Studio code things like that but",
    "start": "2975900",
    "end": "2983370"
  },
  {
    "text": "it's it's a really nice quick acceleration with some depth right because you can always go back to the",
    "start": "2983370",
    "end": "2990620"
  },
  {
    "text": "that fairly large set of documentation including the documentation that sage",
    "start": "2990620",
    "end": "2997260"
  },
  {
    "text": "maker provides itself I hope I hope that was all pretty clear so containers are",
    "start": "2997260",
    "end": "3003500"
  },
  {
    "text": "key our containers for tensorflow PI torch and MX net are all open source",
    "start": "3003500",
    "end": "3009590"
  },
  {
    "text": "they're all up on github you can download them and put them on your machine set up your local laptop to just",
    "start": "3009590",
    "end": "3015710"
  },
  {
    "text": "rent all right let's talk about DevOps well this is the essence of enterprise right because you can create an amazing",
    "start": "3015710",
    "end": "3023960"
  },
  {
    "text": "model cancer therapies automated driving customer service dialogue enhancement",
    "start": "3023960",
    "end": "3031900"
  },
  {
    "text": "transcription all kinds of these things but if you're not controlling your data",
    "start": "3031900",
    "end": "3037960"
  },
  {
    "text": "in production your your data models in production then you know you're not",
    "start": "3037960",
    "end": "3043490"
  },
  {
    "text": "going to go anywhere and if you're deploying at scale you have say tens of thousands or perhaps even millions of",
    "start": "3043490",
    "end": "3048740"
  },
  {
    "text": "customers you need good controls first and foremost clearly is our our",
    "start": "3048740",
    "end": "3056480"
  },
  {
    "text": "competency partner Domino data labs Domino data labs and I'll encourage you",
    "start": "3056480",
    "end": "3062480"
  },
  {
    "text": "to well actually why don't I just do this again no harm here Domino data labs",
    "start": "3062480",
    "end": "3070630"
  },
  {
    "text": "there we go is a comprehensive environment for CI CD for controlling",
    "start": "3070720",
    "end": "3077029"
  },
  {
    "text": "your your data so that when you're testing",
    "start": "3077029",
    "end": "3082190"
  },
  {
    "text": "you're not only testing on data that you've set up but you conversion that",
    "start": "3082190",
    "end": "3088369"
  },
  {
    "text": "data you can go back and pull things out you can upgrade downgrade in a very very",
    "start": "3088369",
    "end": "3094940"
  },
  {
    "text": "controlled manner so Domino data Labs is one of our competency partners and for production if you don't mind paying it",
    "start": "3094940",
    "end": "3102739"
  },
  {
    "text": "is the best of class for developing and",
    "start": "3102739",
    "end": "3107839"
  },
  {
    "text": "deploying in the enterprise um let's say you don't want to pay anything well there's some open source options here",
    "start": "3107839",
    "end": "3113630"
  },
  {
    "text": "first of all would be sage build so what a sage build well if you just search for sage maker build you'll see some code",
    "start": "3113630",
    "end": "3122660"
  },
  {
    "text": "that was started by my good friend John Calhoun and what sage maker build is is",
    "start": "3122660",
    "end": "3127869"
  },
  {
    "text": "it uses Amazon step functions to automatically reload and and redeploy a",
    "start": "3127869",
    "end": "3136400"
  },
  {
    "text": "model based on whether the data or the model itself has changed right so John",
    "start": "3136400",
    "end": "3145099"
  },
  {
    "text": "does a great job of describing this process right where you actually do build to build training you train your",
    "start": "3145099",
    "end": "3151039"
  },
  {
    "text": "model create the model put it in the cloud and then as your code is changing",
    "start": "3151039",
    "end": "3157339"
  },
  {
    "text": "over time you want to retrain that image and once again using step functions",
    "start": "3157339",
    "end": "3164019"
  },
  {
    "text": "redeploy at that CH maker endpoint if you're not familiar with this the sage",
    "start": "3164019",
    "end": "3169279"
  },
  {
    "text": "maker endpoints don't change we have something called production variants",
    "start": "3169279",
    "end": "3174380"
  },
  {
    "text": "that change underneath the endpoint so your developers don't have to go hunting around for a new endpoint we take care",
    "start": "3174380",
    "end": "3181039"
  },
  {
    "text": "of all of that under the hood for you using production variants in sage maker",
    "start": "3181039",
    "end": "3187269"
  },
  {
    "text": "then there's ml flow not going to go into that in too much depth but we will",
    "start": "3187269",
    "end": "3192980"
  },
  {
    "text": "probably be doing a a session on ml flow",
    "start": "3192980",
    "end": "3198380"
  },
  {
    "text": "and actually all four of these tools in an upcoming webinar that we do here bi-weekly",
    "start": "3198380",
    "end": "3204590"
  },
  {
    "text": "and then finally there's onyx so what is onyx onyx is the open network exchange",
    "start": "3204590",
    "end": "3210080"
  },
  {
    "text": "model and it's a collaboration between",
    "start": "3210080",
    "end": "3214960"
  },
  {
    "text": "Facebook of course Microsoft Amazon and about a dozen other partners to have a",
    "start": "3216100",
    "end": "3222890"
  },
  {
    "text": "means for exchanging your models between",
    "start": "3222890",
    "end": "3228710"
  },
  {
    "text": "various inference engines so and I believe I have an example no that's the",
    "start": "3228710",
    "end": "3234950"
  },
  {
    "text": "distributed example again I thought this is where I did the onyx that well if I",
    "start": "3234950",
    "end": "3241940"
  },
  {
    "text": "go back to sage maker examples let me just do a quick onyx search here that's",
    "start": "3241940",
    "end": "3252260"
  },
  {
    "text": "not it anyway we do have onyx templates in here that are just cut and paste and",
    "start": "3252260",
    "end": "3258350"
  },
  {
    "text": "ready to go I thought is in this one but no worries alright Tunde ok so that's",
    "start": "3258350",
    "end": "3266720"
  },
  {
    "text": "onyx I would probably remiss too if I didn't mention neo neo is the it's a and",
    "start": "3266720",
    "end": "3277820"
  },
  {
    "text": "an AWS specific feature that takes your model and will apply it to various",
    "start": "3277820",
    "end": "3285070"
  },
  {
    "text": "architectures so whether you're running on arm or in the cloud or on a Raspberry",
    "start": "3285070",
    "end": "3290750"
  },
  {
    "text": "Pi neo will actually take your model and enable it to run on any architecture",
    "start": "3290750",
    "end": "3296320"
  },
  {
    "text": "alright so that's the that's the overview today we'd get ready for",
    "start": "3296320",
    "end": "3302450"
  },
  {
    "text": "questions and before we do just a few",
    "start": "3302450",
    "end": "3307870"
  },
  {
    "text": "resources here first of all PI torch org is where you'll find all of the",
    "start": "3307870",
    "end": "3313820"
  },
  {
    "text": "resources video tutorials the f8 conference just happen Developers",
    "start": "3313820",
    "end": "3319790"
  },
  {
    "text": "Conference so there's a lot of fresh instructional videos and notebooks up there that will give you an enormous",
    "start": "3319790",
    "end": "3326630"
  },
  {
    "text": "amount of guidance to get started in PI torch or to answer almost any question that you have if you're completely new",
    "start": "3326630",
    "end": "3334100"
  },
  {
    "text": "to deep learning I could not recommend hire the fast AI course it's",
    "start": "3334100",
    "end": "3341180"
  },
  {
    "text": "just the pest finally I had mentioned that the PI torch containers are open-source they are and here's the URL",
    "start": "3341180",
    "end": "3348140"
  },
  {
    "text": "pretty simple at github sage maker PI torch container so with that I wonder if",
    "start": "3348140",
    "end": "3355910"
  },
  {
    "text": "we have any questions",
    "start": "3355910",
    "end": "3358390"
  },
  {
    "text": "hey Chris you know we're not getting a ton of questions in the in the chat but",
    "start": "3361780",
    "end": "3366980"
  },
  {
    "text": "Chris Burns maybe you've got a few a couple that you've taken give it a little time yeah one second I'm going",
    "start": "3366980",
    "end": "3378589"
  },
  {
    "text": "back to the to the questions here and yeah so none yet from the participants",
    "start": "3378589",
    "end": "3384700"
  },
  {
    "text": "also here's one",
    "start": "3384700",
    "end": "3389170"
  },
  {
    "text": "actually it's not a real question it was a it was a heckle from Bob all right",
    "start": "3392400",
    "end": "3401729"
  },
  {
    "text": "maybe all right so so Chris we talked about you did mention it fast AI which",
    "start": "3401729",
    "end": "3408180"
  },
  {
    "text": "is the obvious choice for somebody that wants to get into PI torch or somebody that is new to deep learning completely",
    "start": "3408180",
    "end": "3415489"
  },
  {
    "text": "but all the fast di courses are available in the sage maker examples is that correct",
    "start": "3415489",
    "end": "3421759"
  },
  {
    "text": "there we go yeah I know there's a lot of background noise I'm in New York City so have to mute between questions and I",
    "start": "3422950",
    "end": "3430359"
  },
  {
    "text": "hope that wasn't too distracting through the presentation but short answer is yeah it's it's not just a course of",
    "start": "3430359",
    "end": "3437950"
  },
  {
    "text": "course it's this kind of chaos high-level interface for pi torch so you",
    "start": "3437950",
    "end": "3444640"
  },
  {
    "text": "know it's kind of a one-two punch the jab is the course itself where you do",
    "start": "3444640",
    "end": "3449770"
  },
  {
    "text": "everything from doing computer vision discriminating between various dog types",
    "start": "3449770",
    "end": "3455200"
  },
  {
    "text": "for example I'm doing collaborative filtering matrix factorization almost",
    "start": "3455200",
    "end": "3462730"
  },
  {
    "text": "every deep learning technique for NLP natural language processing and some",
    "start": "3462730",
    "end": "3467890"
  },
  {
    "text": "that I guess Jeremy just likes himself but then it's just this module that you",
    "start": "3467890",
    "end": "3473770"
  },
  {
    "text": "import and it has all those convenience functions that very easily pipeline I think it's that ability to you know dot",
    "start": "3473770",
    "end": "3482040"
  },
  {
    "text": "transform dot date a bunch that you know just eliminates a lot of the heavy",
    "start": "3482040",
    "end": "3488140"
  },
  {
    "text": "lifting in setting up to Train ok thanks",
    "start": "3488140",
    "end": "3494109"
  },
  {
    "text": "Kristen and also if I'm not mistaken PI torch is a first-class citizen I'll use",
    "start": "3494109",
    "end": "3500260"
  },
  {
    "text": "that phrase for lack of a better with sage makers so that if you want to bring a custom model we have a PI torch",
    "start": "3500260",
    "end": "3506530"
  },
  {
    "text": "container that will plug into stage maker for training and hosting is that correct yeah it is but you know we",
    "start": "3506530",
    "end": "3513910"
  },
  {
    "text": "should probably mention another one of our partners here we do do hyper",
    "start": "3513910",
    "end": "3519010"
  },
  {
    "text": "parameter hyper parameter tuning on AWS and we have the API for hyper parameter",
    "start": "3519010",
    "end": "3525880"
  },
  {
    "text": "tuning fully exposed I tend to favor sigit when I'm doing hyper parameter",
    "start": "3525880",
    "end": "3532599"
  },
  {
    "text": "optimization on pi torch sig opt another one of our competency partners really",
    "start": "3532599",
    "end": "3538869"
  },
  {
    "text": "has a robust tool set that just seems to work it there's just a little bit more",
    "start": "3538869",
    "end": "3544510"
  },
  {
    "text": "punch depending on what you're what you're trying to do so definitely try",
    "start": "3544510",
    "end": "3550420"
  },
  {
    "text": "our API for hyper parameter optimization and we have a bunch of built-ins",
    "start": "3550420",
    "end": "3556540"
  },
  {
    "text": "examples in sage maker that demonstrate how to do that but for pi torch in",
    "start": "3556540",
    "end": "3561700"
  },
  {
    "text": "particular you know because we do tend to have a tensorflow MX net really MX net bias in a lot of how our stuff goes",
    "start": "3561700",
    "end": "3570490"
  },
  {
    "text": "into production here the sig opt stuff really sort of nailed pi torch early and",
    "start": "3570490",
    "end": "3576270"
  },
  {
    "text": "it's it's just a great alternative all",
    "start": "3576270",
    "end": "3583630"
  },
  {
    "text": "right great thanks Chris I don't see I don't see any other questions some are questions that we may be able to give three or four",
    "start": "3583630",
    "end": "3590470"
  },
  {
    "text": "minutes back sounds good all right guys thanks so much for this presentation",
    "start": "3590470",
    "end": "3595960"
  },
  {
    "text": "today Chris it was fantastic and Chris Burns for hanging in there and keeping track of questions our next webinar on",
    "start": "3595960",
    "end": "3602950"
  },
  {
    "text": "machine learning topics is on May 3rd so May 3rd good lord May 30th so in two weeks hopefully you",
    "start": "3602950",
    "end": "3610090"
  },
  {
    "text": "can join us the topic is building integrations with Amazon sage maker ground truth so hopefully everybody is",
    "start": "3610090",
    "end": "3617410"
  },
  {
    "text": "getting registered for that when you get the email to follow as a follow-up email from this webinar which will have the",
    "start": "3617410",
    "end": "3623770"
  },
  {
    "text": "link to the recording it will have a quick three question survey which would be super great if you could fill it out and it'll also have a link to register",
    "start": "3623770",
    "end": "3630910"
  },
  {
    "text": "for the next webinar on the 30th so thanks for joining us today hope everybody has a fantastic day",
    "start": "3630910",
    "end": "3638670"
  }
]
[
  {
    "start": "0",
    "end": "17000"
  },
  {
    "text": "Hello and welcome to this episode\nof 'This is My Architecture'.",
    "start": "7803",
    "end": "11177"
  },
  {
    "text": "I'm Kapil, and with me I have\nGireesh from Eyeota.",
    "start": "11177",
    "end": "14735"
  },
  {
    "text": "Gireesh, welcome to the show.",
    "start": "14735",
    "end": "16242"
  },
  {
    "text": "Thanks, Kapil. It's good to be here.",
    "start": "16242",
    "end": "17920"
  },
  {
    "start": "17000",
    "end": "34000"
  },
  {
    "text": "Glad to have you.",
    "start": "17920",
    "end": "19101"
  },
  {
    "text": "And, Gireesh, can you tell us\na little bit about Eyeota?",
    "start": "19101",
    "end": "21705"
  },
  {
    "text": "Eyeota is an audience data marketplace\nwith a global footprint.",
    "start": "21705",
    "end": "24757"
  },
  {
    "text": "We provide a privacy compliant way\nfor advertisers",
    "start": "24757",
    "end": "27536"
  },
  {
    "text": "to reach their target audiences\nwith precision",
    "start": "27536",
    "end": "29977"
  },
  {
    "text": "and for data providers\nto monetize the data with transparency.",
    "start": "29978",
    "end": "34653"
  },
  {
    "start": "34000",
    "end": "77000"
  },
  {
    "text": "And, Gireesh,\nyou've built a new data platform on AWS,",
    "start": "34653",
    "end": "37517"
  },
  {
    "text": "can you tell us what were the challenges\nyou were trying to solve?",
    "start": "37517",
    "end": "40108"
  },
  {
    "text": "The primary business problem\nwe are trying to address is data quality.",
    "start": "40109",
    "end": "43124"
  },
  {
    "text": "We are certified by both the IAB Tech Lab\nand by Neutronian the gold standards",
    "start": "43124",
    "end": "47099"
  },
  {
    "text": "in ad tech data quality certification.",
    "start": "47099",
    "end": "49495"
  },
  {
    "text": "The way we achieve this quality\nis by using our machine learning algorithms,",
    "start": "49495",
    "end": "53988"
  },
  {
    "text": "which are designed to optimize\nthe trade-off between scale and data quality.",
    "start": "53988",
    "end": "57966"
  },
  {
    "text": "In technical terms it translates\ninto a few different requirements,",
    "start": "57966",
    "end": "61149"
  },
  {
    "text": "one is scalability,\ngiven the volumes of data we process,",
    "start": "61149",
    "end": "64698"
  },
  {
    "text": "flexibility for our development teams,",
    "start": "64699",
    "end": "69065"
  },
  {
    "text": "extraction from the infrastructure layer",
    "start": "69066",
    "end": "71495"
  },
  {
    "text": "and transparency on unit cost economics,",
    "start": "71495",
    "end": "74164"
  },
  {
    "text": "so that all of this comes together\nto increase delivery velocity.",
    "start": "74164",
    "end": "76379"
  },
  {
    "text": "Great.",
    "start": "76379",
    "end": "77442"
  },
  {
    "start": "77000",
    "end": "211000"
  },
  {
    "text": "And could you walk us through the diagram?",
    "start": "77442",
    "end": "78941"
  },
  {
    "text": "I see a lot of moving parts here.",
    "start": "78941",
    "end": "80759"
  },
  {
    "text": "Sure.",
    "start": "80759",
    "end": "81779"
  },
  {
    "text": "So this is really, you can think about it\nas a model lifecycle,",
    "start": "81779",
    "end": "85315"
  },
  {
    "text": "and we articulate that in code...",
    "start": "85315",
    "end": "87365"
  },
  {
    "text": "In the form of Airflow DAGs,",
    "start": "88691",
    "end": "92064"
  },
  {
    "text": "PySpark scripts, and SageMaker notebooks.",
    "start": "92064",
    "end": "95491"
  },
  {
    "text": "We also have our raw data,",
    "start": "95491",
    "end": "98407"
  },
  {
    "text": "which comes to us\nfrom our supply side partners.",
    "start": "98407",
    "end": "101481"
  },
  {
    "text": "And both of these, we stored in S3.",
    "start": "101482",
    "end": "106339"
  },
  {
    "text": "From S3 we use Airflow to pick up...",
    "start": "106339",
    "end": "110773"
  },
  {
    "text": "To orchestrate our date pipelines.",
    "start": "112324",
    "end": "115061"
  },
  {
    "text": "So this then it goes into the top over here,",
    "start": "115061",
    "end": "118340"
  },
  {
    "text": "essentially what's going on\nis we're using Glue",
    "start": "118341",
    "end": "120911"
  },
  {
    "text": "for pre-processing and feature selection.",
    "start": "120911",
    "end": "123731"
  },
  {
    "text": "That's where the PySpark scripts come in.",
    "start": "123731",
    "end": "125761"
  },
  {
    "text": "From there the data flows into SageMaker",
    "start": "125761",
    "end": "129091"
  },
  {
    "text": "from model training and tuning,",
    "start": "129092",
    "end": "131127"
  },
  {
    "text": "and also from here data flows\ninto SageMaker batch inference,",
    "start": "131127",
    "end": "136406"
  },
  {
    "text": "which is where we run...",
    "start": "136406",
    "end": "138235"
  },
  {
    "text": "Which we run on our held out data sets.",
    "start": "138235",
    "end": "139647"
  },
  {
    "text": "Right.",
    "start": "139647",
    "end": "140724"
  },
  {
    "text": "Down here on the inference side, again,",
    "start": "140724",
    "end": "143327"
  },
  {
    "text": "Airflow is triggering a pipeline\nwith Glue doing pre-processing.",
    "start": "143327",
    "end": "147612"
  },
  {
    "text": "And from there\nthe data is going into SageMaker",
    "start": "147612",
    "end": "149713"
  },
  {
    "text": "for batch inference.",
    "start": "149713",
    "end": "150846"
  },
  {
    "text": "Remember, this is unlabeled data,",
    "start": "150846",
    "end": "153353"
  },
  {
    "text": "so the generated labels\nare then stored in S3,",
    "start": "153353",
    "end": "157123"
  },
  {
    "text": "from there it is distributed downstream\nto the rest of our pipeline.",
    "start": "157123",
    "end": "160965"
  },
  {
    "text": "And in the middle over here\nwe have model selection",
    "start": "160965",
    "end": "163064"
  },
  {
    "text": "and pipeline optimization,",
    "start": "163064",
    "end": "164543"
  },
  {
    "text": "so both of these pipelines\nthey push their performance",
    "start": "164544",
    "end": "168733"
  },
  {
    "text": "and operational metrics into CloudWatch",
    "start": "168733",
    "end": "172416"
  },
  {
    "text": "from there we have\nan internal metrics visualization tool",
    "start": "172416",
    "end": "175607"
  },
  {
    "text": "which we run on EC2.",
    "start": "175607",
    "end": "177491"
  },
  {
    "text": "That helps our data science teams\nfigure out what is the right model",
    "start": "177491",
    "end": "181784"
  },
  {
    "text": "to push into production for each use case.",
    "start": "181784",
    "end": "184213"
  },
  {
    "text": "The selected models are pushed into S3,",
    "start": "184214",
    "end": "186730"
  },
  {
    "text": "and that's what is used\nby the batch inference job",
    "start": "186730",
    "end": "191271"
  },
  {
    "text": "to run on the production workload.",
    "start": "191271",
    "end": "193530"
  },
  {
    "text": "Our data science team\nalso uses visualization",
    "start": "193531",
    "end": "196073"
  },
  {
    "text": "to monitor the production pipelines\nfor things like model drift,",
    "start": "196073",
    "end": "200739"
  },
  {
    "text": "at the same time our data engineering\nand infrastructure teams",
    "start": "200740",
    "end": "203944"
  },
  {
    "text": "they also use the metrics over here",
    "start": "203944",
    "end": "206439"
  },
  {
    "text": "to ensure pipeline uptime",
    "start": "206439",
    "end": "208361"
  },
  {
    "text": "and also look for optimization opportunities.",
    "start": "208361",
    "end": "210472"
  },
  {
    "text": "Right.",
    "start": "210473",
    "end": "211496"
  },
  {
    "start": "211000",
    "end": "248000"
  },
  {
    "text": "And I can see there are clearly\ntwo different types of pipelines here.",
    "start": "211496",
    "end": "215260"
  },
  {
    "text": "Can you tell us what's the typical scale\nof data processes by these pipelines?",
    "start": "215260",
    "end": "219562"
  },
  {
    "text": "So up here from model training and tuning,",
    "start": "219563",
    "end": "221617"
  },
  {
    "text": "we run a few hundreds of training jobs,",
    "start": "221617",
    "end": "223771"
  },
  {
    "text": "each of which is processing",
    "start": "223771",
    "end": "225030"
  },
  {
    "text": "anywhere from a few hundred megs of data",
    "start": "225031",
    "end": "227451"
  },
  {
    "text": "to a few hundred gigs of data.",
    "start": "227451",
    "end": "229130"
  },
  {
    "text": "Down here on inference\nwe run a few hundred inference jobs",
    "start": "229130",
    "end": "234981"
  },
  {
    "text": "each of which is processing\nterabyte scale data.",
    "start": "234981",
    "end": "237465"
  },
  {
    "text": "Ultimately we are processing like",
    "start": "237465",
    "end": "239026"
  },
  {
    "text": "six or seven billion\nunique advertising ID's a month",
    "start": "239026",
    "end": "241679"
  },
  {
    "text": "and mapping these\ninto 70,000 different attributes.",
    "start": "241679",
    "end": "244459"
  },
  {
    "text": "So all of this is running\non a ginormous distributed sparce matrix.",
    "start": "244459",
    "end": "247740"
  },
  {
    "text": "Fantastic.",
    "start": "247740",
    "end": "248773"
  },
  {
    "text": "And you are doing all of this orchestration\nfrom Apache Airflow.",
    "start": "248773",
    "end": "251834"
  },
  {
    "text": "Can you tell us why Airflow?",
    "start": "251834",
    "end": "253859"
  },
  {
    "text": "Primarily, it gives us a lot of flexibility",
    "start": "253859",
    "end": "255620"
  },
  {
    "text": "for both our data science\nand data engineering teams.",
    "start": "255621",
    "end": "257978"
  },
  {
    "text": "So typically a data science team\nneeds to work",
    "start": "257978",
    "end": "260389"
  },
  {
    "text": "on very experimental features\nand they can do that on Airflow,",
    "start": "260390",
    "end": "263701"
  },
  {
    "text": "but the data engineering team\nis optimizing production,",
    "start": "263701",
    "end": "265792"
  },
  {
    "text": "scale, performance,\nso they can do that as well on Airflow,",
    "start": "265792",
    "end": "268153"
  },
  {
    "text": "so it's a single platform\nthat both of them can use",
    "start": "268153",
    "end": "270736"
  },
  {
    "text": "and it's great for our velocity.",
    "start": "270736",
    "end": "272289"
  },
  {
    "start": "272000",
    "end": "301000"
  },
  {
    "text": "And what was your experience like\nintegrating from Airflow with AWS services?",
    "start": "272290",
    "end": "278061"
  },
  {
    "text": "It was quite straight forward\nto orchestrate the services.",
    "start": "278061",
    "end": "280815"
  },
  {
    "text": "It was mostly a question\nof following the dots,",
    "start": "280815",
    "end": "282956"
  },
  {
    "text": "but then when we got\ninto final-grained configuration,",
    "start": "282956",
    "end": "285138"
  },
  {
    "text": "we faced a bit of a learning curve,",
    "start": "285138",
    "end": "286724"
  },
  {
    "text": "for example, we needed to figure out\nthe right metrics to monitor here",
    "start": "286724",
    "end": "290069"
  },
  {
    "text": "so that we could figure out\nhow many DPUs to process for Glue,",
    "start": "290069",
    "end": "292935"
  },
  {
    "text": "to configure for Glue,",
    "start": "292935",
    "end": "294561"
  },
  {
    "text": "for SageMaker we needed to play around a bit",
    "start": "294561",
    "end": "296529"
  },
  {
    "text": "with distributed learning and model averaging\nto get it to scale to our sizes of data.",
    "start": "296529",
    "end": "300591"
  },
  {
    "text": "Right.",
    "start": "300591",
    "end": "301651"
  },
  {
    "start": "301000",
    "end": "326000"
  },
  {
    "text": "That's a lot of fantastic work\ndone by your team.",
    "start": "301651",
    "end": "304739"
  },
  {
    "text": "What would you say\nare the key outcomes of this project?",
    "start": "304739",
    "end": "307409"
  },
  {
    "text": "Team efficiency.",
    "start": "307409",
    "end": "308456"
  },
  {
    "text": "I mean, right now\nwe get most training pipelines",
    "start": "308456",
    "end": "313866"
  },
  {
    "text": "configured within three to five working days,",
    "start": "313866",
    "end": "315687"
  },
  {
    "text": "which is half of what we used to do earlier.",
    "start": "315687",
    "end": "318192"
  },
  {
    "text": "And we get this with a lot more transparency\non model performance",
    "start": "318192",
    "end": "322158"
  },
  {
    "text": "and also a lot more configurability\nacross the board,",
    "start": "322158",
    "end": "324451"
  },
  {
    "text": "so it's a huge win for the team.",
    "start": "324451",
    "end": "326436"
  },
  {
    "start": "326000",
    "end": "342000"
  },
  {
    "text": "That's fantastic.",
    "start": "326437",
    "end": "327779"
  },
  {
    "text": "Gireesh, thanks a lot for sharing\nall these insights with our viewers.",
    "start": "327779",
    "end": "331285"
  },
  {
    "text": "And thank you for watching this episode\nof 'This is My Architecture'.",
    "start": "331285",
    "end": "334934"
  }
]
[
  {
    "text": "hello everyone welcome my name is chris and this is colin and we are two members of the",
    "start": "2480",
    "end": "9040"
  },
  {
    "text": "live service team responsible for developing and operating the simpsons tapped out mobile game we're",
    "start": "9040",
    "end": "15759"
  },
  {
    "text": "glad you guys could be here with us today",
    "start": "15759",
    "end": "19279"
  },
  {
    "text": "so we put this quote up first to try and get a cheap laugh but on another level",
    "start": "24400",
    "end": "32160"
  },
  {
    "text": "it kind of sums up our experiences with aws quite nicely colin and i we're not dbas",
    "start": "32160",
    "end": "40320"
  },
  {
    "text": "we're not network engineers we're a couple of software engineers and at one time we accounted for two-thirds",
    "start": "40320",
    "end": "48320"
  },
  {
    "text": "of the team responsible for developing and operating a service hit by millions of",
    "start": "48320",
    "end": "53760"
  },
  {
    "text": "people every day a situation would not be a situation like this would not be possible without",
    "start": "53760",
    "end": "59520"
  },
  {
    "text": "the help of aws during the two and a half year run of simpsons tapped out our service has",
    "start": "59520",
    "end": "64720"
  },
  {
    "text": "evolved in many ways reasons for this include performance improvements reducing costs an easing operation",
    "start": "64720",
    "end": "73119"
  },
  {
    "text": "our presentation today is going to cover a few examples of this evolution and show that solutions",
    "start": "73119",
    "end": "78400"
  },
  {
    "text": "involving aws technology not only provide great solutions",
    "start": "78400",
    "end": "84000"
  },
  {
    "text": "but they're almost always easier than doing it yourself",
    "start": "84000",
    "end": "90000"
  },
  {
    "text": "before we get into the technology side of things just a bit of a summary of the game for anybody that's not familiar with it",
    "start": "90960",
    "end": "96560"
  },
  {
    "text": "so it's your typical mobile town builder we originally released on ios later",
    "start": "96560",
    "end": "102640"
  },
  {
    "text": "added android and kindle releases the premise is pretty simple",
    "start": "102640",
    "end": "108479"
  },
  {
    "text": "homer has exploded the nuclear power plant and as a result springfield has been",
    "start": "108799",
    "end": "115439"
  },
  {
    "text": "destroyed and you are tasked with the responsibility of rebuilding it along the way you discover new buildings",
    "start": "115439",
    "end": "122240"
  },
  {
    "text": "new characters as you complete quests level up all those all those usual things the game designers",
    "start": "122240",
    "end": "128399"
  },
  {
    "text": "and the licensers were were very adamant about making the characters and the story be the star",
    "start": "128399",
    "end": "135120"
  },
  {
    "text": "as opposed to any kind of complex game mechanics and so as a result your basic session involves you know",
    "start": "135120",
    "end": "141920"
  },
  {
    "text": "logging in collecting money from buildings and characters advancing any quests activating new",
    "start": "141920",
    "end": "149840"
  },
  {
    "text": "activating new jobs for your characters and then paying a visit to your friends springfield",
    "start": "149840",
    "end": "157760"
  },
  {
    "text": "in terms of our release cycles we have new server deployments roughly every two weeks",
    "start": "157760",
    "end": "163120"
  },
  {
    "text": "we have new client content roughly every two weeks this comes in two forms the first is new client",
    "start": "163120",
    "end": "169920"
  },
  {
    "text": "releases these are these are the major ones that involve new gameplay mechanics",
    "start": "169920",
    "end": "175680"
  },
  {
    "text": "um possibly themed content in between we have just dlc releases which",
    "start": "175680",
    "end": "181519"
  },
  {
    "text": "often have new buildings new characters new quests uh things like that we have holiday",
    "start": "181519",
    "end": "188400"
  },
  {
    "text": "themed clients throughout the year the biggest ones being the halloween and the christmas clients we just completed",
    "start": "188400",
    "end": "193920"
  },
  {
    "text": "the treehouse of horror release for this year um springfield was being invaded by aliens",
    "start": "193920",
    "end": "199760"
  },
  {
    "text": "and you had to squish them in order to save springfield the christmas events",
    "start": "199760",
    "end": "205120"
  },
  {
    "text": "starting up in a couple of weeks not sure all the different gameplay mechanics but i do know that the assets get a winter treatment so everything's",
    "start": "205120",
    "end": "211680"
  },
  {
    "text": "covered in snow and the houses have christmas decorations for you too for",
    "start": "211680",
    "end": "217519"
  },
  {
    "text": "you to activate we also have other events for things like valentine's day and easter throughout the year on top of this",
    "start": "217519",
    "end": "225280"
  },
  {
    "text": "during the simpsons television season it's not uncommon for us to have episode tie-ins so",
    "start": "225280",
    "end": "230560"
  },
  {
    "text": "five or six days before an episode is an episode airs we'll release some dlc",
    "start": "230560",
    "end": "236319"
  },
  {
    "text": "content that ties in with the episode so a lot of the times it has some",
    "start": "236319",
    "end": "241439"
  },
  {
    "text": "back story an advert for the upcoming episode we just completed one last week for the",
    "start": "241439",
    "end": "248239"
  },
  {
    "text": "futurama crossover episode for anybody that saw that",
    "start": "248239",
    "end": "252720"
  },
  {
    "text": "so what you see here is a cloud watch graph of our request count for a 10-day period at the beginning",
    "start": "253439",
    "end": "258880"
  },
  {
    "text": "of october of this year we kind of like this graph because in a span of 10 days it it covers a few",
    "start": "258880",
    "end": "266160"
  },
  {
    "text": "events that we see commonly throughout the year so i'll walk you through a few of those things",
    "start": "266160",
    "end": "271280"
  },
  {
    "text": "so what you see in the first three days is the typical usage pattern when a client has either",
    "start": "271280",
    "end": "277759"
  },
  {
    "text": "been out for a while and players have exhausted the content or grown tired of",
    "start": "277759",
    "end": "283440"
  },
  {
    "text": "of the existing client something like that you see this day over day player decline",
    "start": "283440",
    "end": "289600"
  },
  {
    "text": "this spot here the marketing team sent out a series of push notifications to try and re-engage some players so we get",
    "start": "290639",
    "end": "297199"
  },
  {
    "text": "a bit of an uptick in our request counts at that time a few days later this is when we",
    "start": "297199",
    "end": "303280"
  },
  {
    "text": "released the treehouse of horror client and as usual whenever we release a client there's",
    "start": "303280",
    "end": "308400"
  },
  {
    "text": "an uptick in in traffic but a day day and a half later you see a",
    "start": "308400",
    "end": "314560"
  },
  {
    "text": "bit of a dip a brief dip in our request count that was when we activated our forced update mechanic and what that does is after",
    "start": "314560",
    "end": "321759"
  },
  {
    "text": "about a after about a day day and a half anybody who hasn't voluntarily updated the client is sort of forced to",
    "start": "321759",
    "end": "328720"
  },
  {
    "text": "do so before continuing with the game the reason for this is a lot of the times when we release new",
    "start": "328720",
    "end": "333919"
  },
  {
    "text": "clients there's some gameplay mechanic that can only be done with your friends and it only",
    "start": "333919",
    "end": "340160"
  },
  {
    "text": "really works if both you and your friend have the most recent client in the most recent dlc",
    "start": "340160",
    "end": "345680"
  },
  {
    "text": "and what you see at the end is we follow a blue green deployment strategy which we'll talk a little bit more about later",
    "start": "345680",
    "end": "352080"
  },
  {
    "text": "and at this point we did a server deployment and all of the traffic was then moved to a",
    "start": "352080",
    "end": "357360"
  },
  {
    "text": "new server environment so some interesting usage stats our",
    "start": "357360",
    "end": "363759"
  },
  {
    "text": "highest daily active user count has been recorded around 7.2 million",
    "start": "363759",
    "end": "370560"
  },
  {
    "text": "our highest peak concurrent user count has been roughly 500 000.",
    "start": "370560",
    "end": "375680"
  },
  {
    "text": "we've had request rates exceeding 20 000 per second and as you saw in that request count",
    "start": "375680",
    "end": "381600"
  },
  {
    "text": "graph previously our player count follows a similar pattern there's about a 2x player count difference between high",
    "start": "381600",
    "end": "387600"
  },
  {
    "text": "peak and low peak traffic just a note there those stats were taken from triage of",
    "start": "387600",
    "end": "394800"
  },
  {
    "text": "horror last year where our game is it was generally considered to be the most popular time for our game the the",
    "start": "394800",
    "end": "400639"
  },
  {
    "text": "numbers have dipped a little bit this year but it's still it's still common to see dow",
    "start": "400639",
    "end": "406319"
  },
  {
    "text": "of five to six million uh whenever we release new clients and request rates around thirteen thousand per second",
    "start": "406319",
    "end": "413759"
  },
  {
    "text": "some interesting aws stats so we have over five thousand read and twenty five",
    "start": "413759",
    "end": "419599"
  },
  {
    "text": "hundred right dynamo db units average about 80 000",
    "start": "419599",
    "end": "424639"
  },
  {
    "text": "ec2 instance hours per month and anywhere between 70 and 150 instances",
    "start": "424639",
    "end": "429680"
  },
  {
    "text": "running throughout the day we have four million new s3 objects",
    "start": "429680",
    "end": "434960"
  },
  {
    "text": "written per day with 30 million reads and 30 million writes per day so just some context here we store",
    "start": "434960",
    "end": "442240"
  },
  {
    "text": "things like the players session data friend event data",
    "start": "442240",
    "end": "449120"
  },
  {
    "text": "premium currency balance in dynamodb and we store the player's springfield data",
    "start": "449120",
    "end": "454560"
  },
  {
    "text": "in s3 every 24 hours a backup job runs and finds all of the lands that have been",
    "start": "454560",
    "end": "460400"
  },
  {
    "text": "modified in that previous 24 hours and will make a backup which is where the majority of those four million new",
    "start": "460400",
    "end": "465520"
  },
  {
    "text": "objects per day come from and i'll hand it over to colin for history lesson okay thanks chris",
    "start": "465520",
    "end": "472639"
  },
  {
    "text": "um i'm gonna go over the game's launch history because it's pretty interesting and i'll go over some of the few key",
    "start": "472639",
    "end": "479199"
  },
  {
    "text": "events so the game was originally developed by an outsourcing company",
    "start": "479199",
    "end": "484720"
  },
  {
    "text": "chris and i weren't part of the team we joined it afterward there was a predicted massive player",
    "start": "484720",
    "end": "490720"
  },
  {
    "text": "engagement of over 10 million dau however the game suffered from a variety",
    "start": "490720",
    "end": "496479"
  },
  {
    "text": "of serious issues despite planning for a large user base the system performed very poorly and as",
    "start": "496479",
    "end": "502160"
  },
  {
    "text": "a result it had poor availability there are many different problems and",
    "start": "502160",
    "end": "507680"
  },
  {
    "text": "i'll give you one concrete example the database cluster had 40 shards and so in order to update a row",
    "start": "507680",
    "end": "514080"
  },
  {
    "text": "the application first had to find the correct shard but due to a misconfiguration instead of",
    "start": "514080",
    "end": "519839"
  },
  {
    "text": "using a hashing algorithm or some sort of index it would actually query each shard one",
    "start": "519839",
    "end": "524959"
  },
  {
    "text": "by one until it found the correct one",
    "start": "524959",
    "end": "528959"
  },
  {
    "text": "there were data integrity issues the game logic didn't properly handle concurrent updates so it suffered from the very basic",
    "start": "531839",
    "end": "538720"
  },
  {
    "text": "problem of two users simultaneously reading the same data making independent modifications and",
    "start": "538720",
    "end": "544720"
  },
  {
    "text": "then trying to write them back this obviously results in lost updates but since the game state was being",
    "start": "544720",
    "end": "551120"
  },
  {
    "text": "stored as individual data objects with interdependencies this sometimes resulted in",
    "start": "551120",
    "end": "556880"
  },
  {
    "text": "inconsistencies that rendered the data unusable and so to just give you an idea of the",
    "start": "556880",
    "end": "562160"
  },
  {
    "text": "rate of data corruption it was roughly two percent of the user base per day so",
    "start": "562160",
    "end": "567200"
  },
  {
    "text": "it was very significant there was no operational telemetry there",
    "start": "567200",
    "end": "574800"
  },
  {
    "text": "was no visibility into the health of the service beyond cpu and network i o and then lastly the",
    "start": "574800",
    "end": "581360"
  },
  {
    "text": "deployments were very complicated it required members from the it group the database group",
    "start": "581360",
    "end": "587600"
  },
  {
    "text": "the live monitoring team the game team and there were paperwork requirements before",
    "start": "587600",
    "end": "593040"
  },
  {
    "text": "receiving assistance from any of these teams was received and we had a minimum of about 20 minutes of downtime",
    "start": "593040",
    "end": "599600"
  },
  {
    "text": "for any deployment it was starting to look like lisa would be mortified",
    "start": "599600",
    "end": "605839"
  },
  {
    "text": "as a result of the technical problems the game was delisted from the app store while solutions were being developed",
    "start": "609440",
    "end": "615279"
  },
  {
    "text": "this put great strain on our relationship with the licensor and drew some unwanted attention from our ceo",
    "start": "615279",
    "end": "621760"
  },
  {
    "text": "at this point development was moved to our studio in kitchener ontario",
    "start": "621760",
    "end": "626880"
  },
  {
    "text": "the studio had a proven track record of launching and maintaining live services and the hope was that the new team could",
    "start": "626880",
    "end": "632480"
  },
  {
    "text": "turn it around after all of the critical issues had been addressed the game relaunched in",
    "start": "632480",
    "end": "637920"
  },
  {
    "text": "august 2012. so there was a lot of things that happened in that four months i'm not going to really talk about any of them",
    "start": "637920",
    "end": "644079"
  },
  {
    "text": "everything that i'm going to talk about is from that point to now",
    "start": "644079",
    "end": "650000"
  },
  {
    "text": "so the system was still in pretty bad shape it was very complicated unreliable and",
    "start": "651440",
    "end": "658079"
  },
  {
    "text": "difficult to operate so all of our subsequent topics will be about how we use various aws products and features to transform the",
    "start": "658079",
    "end": "664959"
  },
  {
    "text": "system into something that is more manageable by a small team the first topic is about",
    "start": "664959",
    "end": "670800"
  },
  {
    "text": "trying to reduce the service downtime as much as possible these changes took place at different",
    "start": "670800",
    "end": "676320"
  },
  {
    "text": "times over the last two years the second topic is about how we replaced our expensive and complicated",
    "start": "676320",
    "end": "682880"
  },
  {
    "text": "mysql cluster with dynamodb and the final topic will be about moving the game server to elastic bean",
    "start": "682880",
    "end": "689360"
  },
  {
    "text": "stock to simplify deployments auto scaling and failover",
    "start": "689360",
    "end": "694800"
  },
  {
    "text": "okay this is the system architecture when the game was relaunched even though this is the second iteration of the system we can consider it to be",
    "start": "696560",
    "end": "703440"
  },
  {
    "text": "our starting point since this is where we were able to start thinking about making optimization rather than just trying to get something",
    "start": "703440",
    "end": "709519"
  },
  {
    "text": "that works so just going over this real quick on the top right we have the mobile devices on",
    "start": "709519",
    "end": "715680"
  },
  {
    "text": "which the game client runs underneath it we have origin which is the ea identity service",
    "start": "715680",
    "end": "722480"
  },
  {
    "text": "so you can use the same user account to play multiple ea games and then everything else is pretty",
    "start": "722480",
    "end": "728079"
  },
  {
    "text": "standard we have an elastic load balancer we have a cluster of h a proxy instances which chris will talk about a bit later",
    "start": "728079",
    "end": "735120"
  },
  {
    "text": "we have the game servers which were running on an ec2 cluster a memcache cluster a mysql cluster",
    "start": "735120",
    "end": "743360"
  },
  {
    "text": "and then we were using s3 for some of the uh larger game objects and so it's worth",
    "start": "743360",
    "end": "749600"
  },
  {
    "text": "noting that the mysql cluster the memcache cluster the game servers and actually also the",
    "start": "749600",
    "end": "755120"
  },
  {
    "text": "aha proxy instances were all running an ec2 on manually managed and manually configured",
    "start": "755120",
    "end": "762160"
  },
  {
    "text": "instances so we had a few goals from this point",
    "start": "762160",
    "end": "769920"
  },
  {
    "text": "forward the first one was the first problem was that the uh deployments were very complicated and",
    "start": "769920",
    "end": "776160"
  },
  {
    "text": "so we needed to simplify the process as well as eliminate the deployment downtime",
    "start": "776160",
    "end": "782160"
  },
  {
    "text": "the second goal was to improve scalability and availability neither the game servers nor the",
    "start": "782160",
    "end": "787519"
  },
  {
    "text": "database scaled automatically nor did they have failover mechanisms the database cluster",
    "start": "787519",
    "end": "792800"
  },
  {
    "text": "was comprised of 120 ec2 instances and it would have been very difficult to scale out",
    "start": "792800",
    "end": "797839"
  },
  {
    "text": "since we would have needed to reshare them all and then the third goal was to reduce",
    "start": "797839",
    "end": "802880"
  },
  {
    "text": "costs the database cluster was costing nearly a million dollars a year despite no longer storing the main game data",
    "start": "802880",
    "end": "811120"
  },
  {
    "text": "for most of the last two years our team had only three to four engineers to handle all of the development and operations",
    "start": "813600",
    "end": "820480"
  },
  {
    "text": "this includes code changes quality assurance deployments and being first level incident responders",
    "start": "820480",
    "end": "827440"
  },
  {
    "text": "since we were low on manpower we needed solutions that used our manpower as efficiently as possible",
    "start": "827440",
    "end": "833360"
  },
  {
    "text": "we accomplished this by adopting various aws aws products and features which will be our main topic for this",
    "start": "833360",
    "end": "839440"
  },
  {
    "text": "presentation i can turn it back over to chris for the first topic",
    "start": "839440",
    "end": "844720"
  },
  {
    "text": "okay so one of the things colin mentioned there was our service stability so our quest for",
    "start": "844720",
    "end": "851120"
  },
  {
    "text": "zero downtime just to give you an indication this is",
    "start": "851120",
    "end": "856480"
  },
  {
    "text": "the same uh same diagram that colin just walked you through so we'll be focusing on these components",
    "start": "856480",
    "end": "862320"
  },
  {
    "text": "here it's sort of broken up into two sections the first one will be about the game servers in the aj proxy",
    "start": "862320",
    "end": "868160"
  },
  {
    "text": "configuration and then the second half will will be about the origin uh integration",
    "start": "868160",
    "end": "875040"
  },
  {
    "text": "so problem one stateful servers at the time of the relaunch all of the all of a player's game state",
    "start": "875440",
    "end": "882320"
  },
  {
    "text": "was being cashed locally on an individual server so as a result",
    "start": "882320",
    "end": "887680"
  },
  {
    "text": "players needed to be sticky to that server at all times we had aj proxy instances behind the",
    "start": "887680",
    "end": "894720"
  },
  {
    "text": "load balancer in order to make sure that in order to dictate the player distribution",
    "start": "894720",
    "end": "901440"
  },
  {
    "text": "the h.a proxy config would hash a player's game id",
    "start": "901440",
    "end": "906880"
  },
  {
    "text": "and be able to direct their traffic to the appropriate to the appropriate server so that even on subsequent sessions they",
    "start": "906880",
    "end": "913120"
  },
  {
    "text": "would always find that find that same server as the set of instances changed the aha",
    "start": "913120",
    "end": "918720"
  },
  {
    "text": "proxy config needed to be updated and this would alter the hashing schemes causing some players to switch servers",
    "start": "918720",
    "end": "926320"
  },
  {
    "text": "the additional removal of instances would would cause some players to then switch servers and if they happen to be",
    "start": "926320",
    "end": "931920"
  },
  {
    "text": "playing at the time this is what they'd see so",
    "start": "931920",
    "end": "937600"
  },
  {
    "text": "this is the dreaded bart screen if you google bart screen this is what you will see anytime there",
    "start": "937600",
    "end": "944880"
  },
  {
    "text": "is an issue with client server communication in the game this is most likely what you are going to see",
    "start": "944880",
    "end": "950639"
  },
  {
    "text": "it's it's so popular that last season the simpsons television show even did a parody of it",
    "start": "950639",
    "end": "957519"
  },
  {
    "text": "um so anyway having to uh having to re-authent uh",
    "start": "957519",
    "end": "963600"
  },
  {
    "text": "re-authenticate in the middle of your session is is kind of a bad thing",
    "start": "963600",
    "end": "969839"
  },
  {
    "text": "so deployments at that time were sort of an extreme version of this case so it would force",
    "start": "970079",
    "end": "976800"
  },
  {
    "text": "all active players to have to re-authenticate causing a 10 to 20 minute interruption in game play",
    "start": "976800",
    "end": "982160"
  },
  {
    "text": "the graph you see here now the data is about a year and a half old so it's been aggregated on an hourly level",
    "start": "982160",
    "end": "987920"
  },
  {
    "text": "but in actuality sort of the player count drop was much more severe",
    "start": "987920",
    "end": "993519"
  },
  {
    "text": "but it only lasted maybe you know 15-20 minutes as opposed to the what looks like to be two hours",
    "start": "993519",
    "end": "999600"
  },
  {
    "text": "in this graph as a result of this re-authentication problem we",
    "start": "999600",
    "end": "1006880"
  },
  {
    "text": "needed to take great care to make sure that we only did server deployments at low peak times",
    "start": "1006880",
    "end": "1012079"
  },
  {
    "text": "and we avoided things like client releases dlc releases any marketing promotions we pretty much",
    "start": "1012079",
    "end": "1018560"
  },
  {
    "text": "had to keep in close contact with those teams to make sure we didn't step on anybody's toes",
    "start": "1018560",
    "end": "1025360"
  },
  {
    "text": "so obviously we needed to we needed to make a change here and we needed to remove that that local caching so",
    "start": "1025360",
    "end": "1031280"
  },
  {
    "text": "the the solution for this was obvious we had to take had to make use of elastic hash we had",
    "start": "1031280",
    "end": "1036798"
  },
  {
    "text": "to move all of that locally cached data into elastic make it available for any server so that any",
    "start": "1036799",
    "end": "1043199"
  },
  {
    "text": "client request could go to any server at any given time we ended up setting up two elastic cache clusters one for",
    "start": "1043199",
    "end": "1049600"
  },
  {
    "text": "the springfield data for a given player and then another cluster for all of the other",
    "start": "1049600",
    "end": "1055120"
  },
  {
    "text": "players data as a bonus by doing this we were also",
    "start": "1055120",
    "end": "1060320"
  },
  {
    "text": "able to entirely remove the aha proxy instances since we didn't need to keep players sticky",
    "start": "1060320",
    "end": "1066000"
  },
  {
    "text": "anymore so this rendered the game servers completely stateless and",
    "start": "1066000",
    "end": "1071760"
  },
  {
    "text": "as a result we could freely add and remove ec2 instances without affecting the player",
    "start": "1071760",
    "end": "1077600"
  },
  {
    "text": "so problem number two was our auth stability so as colin mentioned earlier we integrate with",
    "start": "1077600",
    "end": "1084400"
  },
  {
    "text": "origin our internal our ea ea developed authentication service and when we first",
    "start": "1084400",
    "end": "1091840"
  },
  {
    "text": "relaunched whenever origin was down we were down",
    "start": "1091840",
    "end": "1099039"
  },
  {
    "text": "close enough nucleus fine",
    "start": "1101440",
    "end": "1106720"
  },
  {
    "text": "just to give the data's a little bit old but you can see here this was the the minutes of downtime we experienced",
    "start": "1106880",
    "end": "1113440"
  },
  {
    "text": "quarter over quarter uh whenever the authentication service was down so we needed to make a change here",
    "start": "1113440",
    "end": "1122240"
  },
  {
    "text": "so what we wanted to do was put in a mechanism to automatically detect failures",
    "start": "1122240",
    "end": "1127280"
  },
  {
    "text": "and to bypass to some backup functionality whenever those errors were detected",
    "start": "1127280",
    "end": "1134399"
  },
  {
    "text": "so i'll walk you through sort of what the what the authentication procedure was so we'd send our credentials to nucleus",
    "start": "1135760",
    "end": "1144400"
  },
  {
    "text": "you get an access code back the credentials were good you would then use that access code to",
    "start": "1144400",
    "end": "1149919"
  },
  {
    "text": "authenticate against the game servers that access code would then be validated",
    "start": "1149919",
    "end": "1156240"
  },
  {
    "text": "if the access code was good the game server would respond with a game session now the key point here is if",
    "start": "1156240",
    "end": "1164559"
  },
  {
    "text": "the authentication was good both the client and the server would cache that access code the game",
    "start": "1164559",
    "end": "1171840"
  },
  {
    "text": "server would cache it in elastic cache and the client would save it on the device and this was important",
    "start": "1171840",
    "end": "1178000"
  },
  {
    "text": "for the failure case where username and password would get sent and",
    "start": "1178000",
    "end": "1184080"
  },
  {
    "text": "who knows what would happen the request could time out we could get some unknown error either way we don't get a valid",
    "start": "1184080",
    "end": "1189520"
  },
  {
    "text": "access code what happens in this case we use the saved access code and make",
    "start": "1189520",
    "end": "1196640"
  },
  {
    "text": "the authentication request against the game server again the game server is unaware of anything",
    "start": "1196640",
    "end": "1202640"
  },
  {
    "text": "any problems so it'll try and validate the access code and again who knows what will happen with no",
    "start": "1202640",
    "end": "1210159"
  },
  {
    "text": "validation response coming back the game server will then go and check for any cash access code that",
    "start": "1210159",
    "end": "1216480"
  },
  {
    "text": "it has for this player if that access code matches the access code that was passed in",
    "start": "1216480",
    "end": "1224320"
  },
  {
    "text": "you will still get a valid game session so just a note here in order to kind of",
    "start": "1224880",
    "end": "1230480"
  },
  {
    "text": "balance stability with security we only cache those access codes for",
    "start": "1230480",
    "end": "1236240"
  },
  {
    "text": "seven days on the game server we don't want two-month-old access codes being used to get into the game",
    "start": "1236240",
    "end": "1243840"
  },
  {
    "text": "so how did we do ec2 instance changes have zero impact to the player deployments have",
    "start": "1244240",
    "end": "1250480"
  },
  {
    "text": "zero impact to the player cash changes have near zero impact if we",
    "start": "1250480",
    "end": "1255919"
  },
  {
    "text": "end up having to to change the cl the cash clusters at all then",
    "start": "1255919",
    "end": "1261200"
  },
  {
    "text": "you know there'll be a little a little bit of time where you'll have some cash misses and some",
    "start": "1261200",
    "end": "1267039"
  },
  {
    "text": "longer response times but the player will still be able to play",
    "start": "1267039",
    "end": "1272320"
  },
  {
    "text": "and off time has near zero impact if you're an active player you would have no problems getting into",
    "start": "1272400",
    "end": "1278720"
  },
  {
    "text": "the game only people that sort of played in frequently or new users would",
    "start": "1278720",
    "end": "1283760"
  },
  {
    "text": "unfortunately still be impacted i'll hand it over to colin for the next topic",
    "start": "1283760",
    "end": "1289600"
  },
  {
    "text": "okay um converting the mysql cluster to use dynamodb was one of our most",
    "start": "1289600",
    "end": "1294640"
  },
  {
    "text": "time-consuming but rewarding endeavors let me walk you through how we did this",
    "start": "1294640",
    "end": "1300480"
  },
  {
    "text": "tst tsto initially launched with a cluster of 120 extra large ec2 instances",
    "start": "1301120",
    "end": "1306880"
  },
  {
    "text": "running mysql it had a 40 master 40 read slave and 40 cold backup",
    "start": "1306880",
    "end": "1312400"
  },
  {
    "text": "configuration the cluster was operated by a separate",
    "start": "1312400",
    "end": "1317919"
  },
  {
    "text": "team within ea deployments which altered the mysql cluster required coordination with the",
    "start": "1317919",
    "end": "1323440"
  },
  {
    "text": "database team often requiring time-consuming paperwork and meetings and it was impossible to change the",
    "start": "1323440",
    "end": "1329840"
  },
  {
    "text": "schema without downtime we encountered recurring performance issues since no one on the team",
    "start": "1329840",
    "end": "1336480"
  },
  {
    "text": "had more than basic knowledge of relational databases we were unable to effectively troubleshoot these problems",
    "start": "1336480",
    "end": "1342640"
  },
  {
    "text": "therefore we had to rely on the database team to troubleshoot issues which first required",
    "start": "1342640",
    "end": "1348720"
  },
  {
    "text": "convincing them of the problem's existence and then working with them to develop and deploy a solution the end result being that too many",
    "start": "1348720",
    "end": "1355679"
  },
  {
    "text": "dollars and too many hours were wasted",
    "start": "1355679",
    "end": "1361120"
  },
  {
    "text": "so this is the components that need changing in this section will be the mysql",
    "start": "1361120",
    "end": "1366480"
  },
  {
    "text": "cluster and its interaction with the game server",
    "start": "1366480",
    "end": "1370480"
  },
  {
    "text": "luckily the existing data model fit well with the nosql model and for the most part it was",
    "start": "1372000",
    "end": "1377840"
  },
  {
    "text": "simply a matter of remapping various scrud operations to use the dynamodb api the one exception of",
    "start": "1377840",
    "end": "1384240"
  },
  {
    "text": "this was that at the time there was no support for global secondary indexes so we had to implement the index using a",
    "start": "1384240",
    "end": "1391360"
  },
  {
    "text": "duplicate table that had a different key schema similar to how dynamodb supports this",
    "start": "1391360",
    "end": "1396640"
  },
  {
    "text": "feature today transparently the difficult part of the migration was moving the vast amount of data in our",
    "start": "1396640",
    "end": "1402559"
  },
  {
    "text": "existing mysql cluster in a manner that required no downtime",
    "start": "1402559",
    "end": "1408159"
  },
  {
    "text": "so this was done in several steps the first was to add application logic that would write to dynamodb",
    "start": "1408159",
    "end": "1414480"
  },
  {
    "text": "in addition to writing to the existing data store the result is that the two data stores are now in sync for all",
    "start": "1414480",
    "end": "1420240"
  },
  {
    "text": "active users we did this for one or two tables at a time over the course of several releases",
    "start": "1420240",
    "end": "1427519"
  },
  {
    "text": "however we still needed to retain the data for inactive users so the second step was to iterate through every row in every table on every my",
    "start": "1428400",
    "end": "1436480"
  },
  {
    "text": "my sql shard and copy that road to copy that row to dynamodb if it didn't",
    "start": "1436480",
    "end": "1441919"
  },
  {
    "text": "already exist the last step was simply to verify that",
    "start": "1441919",
    "end": "1446960"
  },
  {
    "text": "everything had made it into dynamodb and to remove the code that writes to mysql",
    "start": "1446960",
    "end": "1453919"
  },
  {
    "text": "the conversion process took about three months this includes the time it took to change and test the code",
    "start": "1455279",
    "end": "1460799"
  },
  {
    "text": "deploy new versions of the software perform the offline migration and verify the data however we now had",
    "start": "1460799",
    "end": "1467840"
  },
  {
    "text": "a database replacement that was owned and operated entirely by the game team",
    "start": "1467840",
    "end": "1473840"
  },
  {
    "text": "quickly going over some of the benefits very easy to operate scale and maintain this new cluster",
    "start": "1475360",
    "end": "1483279"
  },
  {
    "text": "it no longer required cooperation with an external team no no sql is a much better fit for the",
    "start": "1483279",
    "end": "1489360"
  },
  {
    "text": "type of data we were reading in writing we had consistent performance not just",
    "start": "1489360",
    "end": "1494480"
  },
  {
    "text": "consistent but consistently excellent performance coupled with aws data pipeline and",
    "start": "1494480",
    "end": "1501200"
  },
  {
    "text": "redshift services we have the potential for a powerful data analytics",
    "start": "1501200",
    "end": "1506559"
  },
  {
    "text": "and most importantly our total dynamo dynamodb bill is 90 cheaper than running the mysql",
    "start": "1506559",
    "end": "1513200"
  },
  {
    "text": "cluster was in ec2 okay chris we'll talk about the next",
    "start": "1513200",
    "end": "1518960"
  },
  {
    "text": "topic okay so the last case study we're going to have a look at was our addition of auto scaling and elastic beanstalk",
    "start": "1518960",
    "end": "1529840"
  },
  {
    "text": "so for this uh for this portion we'll be looking at the game servers and the load balancer",
    "start": "1530080",
    "end": "1536480"
  },
  {
    "text": "so there were two problems here that we were really looking to address so the first you know before auto scaling we would",
    "start": "1536720",
    "end": "1543120"
  },
  {
    "text": "have to manually provision the number of ec2 instances and we would have to make educated",
    "start": "1543120",
    "end": "1550799"
  },
  {
    "text": "guesses sort of based on past experiences and often",
    "start": "1550799",
    "end": "1556880"
  },
  {
    "text": "some form of product management estimate we don't know where they came from but",
    "start": "1556880",
    "end": "1563440"
  },
  {
    "text": "on top of this we would have to closely track client releases dlc releases marketing events things",
    "start": "1563600",
    "end": "1570240"
  },
  {
    "text": "like that to make sure we were properly provisioned before any of these things happened",
    "start": "1570240",
    "end": "1576400"
  },
  {
    "text": "for major releases like trio support even after the client was released we",
    "start": "1576400",
    "end": "1582559"
  },
  {
    "text": "would spend the first few days really keeping an eye on our dashboards to make sure that you know we were properly provisioned",
    "start": "1582559",
    "end": "1588880"
  },
  {
    "text": "that everything was healthy and that we didn't have to adjust the number of instances",
    "start": "1588880",
    "end": "1594000"
  },
  {
    "text": "and as you saw earlier in the request count graph",
    "start": "1594000",
    "end": "1599600"
  },
  {
    "text": "it has a very sine wave very rhythmic pattern to it and with manual scaling we had to be",
    "start": "1599600",
    "end": "1606159"
  },
  {
    "text": "provisioned at all times for peak usage and so there was a lot of wastage going on during the low peak times",
    "start": "1606159",
    "end": "1614080"
  },
  {
    "text": "the other problem we were looking at was complex server deployment so at the time of the relaunch our",
    "start": "1614080",
    "end": "1619840"
  },
  {
    "text": "deployments were done by manually executing some scripts that would launch new instances deploy",
    "start": "1619840",
    "end": "1626080"
  },
  {
    "text": "artifacts update our aha proxy instances to redirect traffic to the new deployment this",
    "start": "1626080",
    "end": "1631679"
  },
  {
    "text": "introduced many opportunities for failure human error when executing the scripts",
    "start": "1631679",
    "end": "1636960"
  },
  {
    "text": "we wouldn't get all the instances we tried to launch we'd ask for 90 we'd get 87. and then rollbacks",
    "start": "1636960",
    "end": "1644240"
  },
  {
    "text": "rollbacks were tricky because we'd have to keep the old deployment fully scaled until we were",
    "start": "1644240",
    "end": "1650880"
  },
  {
    "text": "very confident that the new deployment was working properly and only then could we could we manually",
    "start": "1650880",
    "end": "1656159"
  },
  {
    "text": "tear it down so before we could turn on auto scaling there's a few things we needed to take",
    "start": "1656159",
    "end": "1661520"
  },
  {
    "text": "care of so implement a fully stateless game service we took care of that earlier on shutdown any interesting logs we",
    "start": "1661520",
    "end": "1669039"
  },
  {
    "text": "wanted to keep telemetry game state anything that was still on the uh the ec2 instance we needed to",
    "start": "1669039",
    "end": "1675279"
  },
  {
    "text": "make sure that that was automatically persisted on shutdown when we were manually",
    "start": "1675279",
    "end": "1681919"
  },
  {
    "text": "scaling we could make sure that was taken care of manually before tearing down instances we needed to make sure it was",
    "start": "1681919",
    "end": "1687919"
  },
  {
    "text": "now automatic and we needed to determine our auto scaling criteria we did",
    "start": "1687919",
    "end": "1693200"
  },
  {
    "text": "a number of load tests we had to tweak it a couple of times in our first few deployments but we ultimately settled on",
    "start": "1693200",
    "end": "1699039"
  },
  {
    "text": "a policy based on cpu utilization that was aggressive enough to rise and fall with the natural player",
    "start": "1699039",
    "end": "1705760"
  },
  {
    "text": "count but there was still some manual intervention required if there was some big",
    "start": "1705760",
    "end": "1711520"
  },
  {
    "text": "abnormality in our player count so what you see here is our healthy host",
    "start": "1711520",
    "end": "1717360"
  },
  {
    "text": "count over that same 10-day period that we were looking at earlier for the request count now we're in three",
    "start": "1717360",
    "end": "1723919"
  },
  {
    "text": "availability zones so the actual number of instances running is three times the number you see here",
    "start": "1723919",
    "end": "1729440"
  },
  {
    "text": "so at this time we actually we have auto scaling in place so you can see our number of instances rising and falling in that same rhythmic pattern if",
    "start": "1729440",
    "end": "1736320"
  },
  {
    "text": "we didn't have it this would be the an example of",
    "start": "1736320",
    "end": "1741360"
  },
  {
    "text": "what the provisioning might have been set at and so you can end up you can see the the big gaps there the big white",
    "start": "1741360",
    "end": "1747279"
  },
  {
    "text": "areas where we would be wasting uh wasting ec2 instance hours by having to manually provision it this",
    "start": "1747279",
    "end": "1754720"
  },
  {
    "text": "way the other thing i wanted to highlight was so this was the marketing activity we talked about earlier",
    "start": "1754720",
    "end": "1761039"
  },
  {
    "text": "the auto scaling policy was actually able to keep up with that aggressive increase so we were",
    "start": "1761039",
    "end": "1768000"
  },
  {
    "text": "good this time cohen's going to share something later where we weren't so lucky",
    "start": "1768000",
    "end": "1774000"
  },
  {
    "text": "so having auto scaling integrated certainly made the lives of the server",
    "start": "1774320",
    "end": "1779360"
  },
  {
    "text": "team much easier but on top of that it also saved us some money so you can see here these are the this is",
    "start": "1779360",
    "end": "1785039"
  },
  {
    "text": "month over month our ec2 instance hours and you can tell where we added auto",
    "start": "1785039",
    "end": "1791279"
  },
  {
    "text": "scaling we had a drop in 30 drop uh of 30 percent in the number of instance hours",
    "start": "1791279",
    "end": "1797120"
  },
  {
    "text": "used per month so the other half of this was the complex deployments and for that we",
    "start": "1797120",
    "end": "1802640"
  },
  {
    "text": "turned to elastic bean stock so as i was mentioning before we like the idea of the blue green deployment strategy we have",
    "start": "1802640",
    "end": "1808799"
  },
  {
    "text": "you know we have we keep a fully scaled production environment i'm in a minimally scaled pre-production",
    "start": "1808799",
    "end": "1813919"
  },
  {
    "text": "environment and the elbs are both are fully warmed in both environments and",
    "start": "1813919",
    "end": "1819360"
  },
  {
    "text": "uh the reason we like this is because if it facilitates testing really nicely we can put the new server code on the",
    "start": "1819360",
    "end": "1825520"
  },
  {
    "text": "pre-production environment have qa test it out before we fully scale it up",
    "start": "1825520",
    "end": "1831360"
  },
  {
    "text": "and then complete the swap it also facilitates an easy rollback you just redirect the traffic back to the other",
    "start": "1831360",
    "end": "1837760"
  },
  {
    "text": "deployment so yeah three basic steps now to our server deployments we upload the",
    "start": "1837760",
    "end": "1843440"
  },
  {
    "text": "artifacts we scale up the pre-production environment and then perform elastic being stock's url swap to",
    "start": "1843440",
    "end": "1849600"
  },
  {
    "text": "cut over to the new deployment and as i mentioned rollbacks are as simple",
    "start": "1849600",
    "end": "1855440"
  },
  {
    "text": "as just doing that url swap back to the previous environment if it's been a while since traffic was hitting the old",
    "start": "1855440",
    "end": "1862159"
  },
  {
    "text": "deployment we might have lost a number of instances due to auto scaling so we might just have to top it up but otherwise",
    "start": "1862159",
    "end": "1868480"
  },
  {
    "text": "it's just that easy so the benefits if it isn't already",
    "start": "1868480",
    "end": "1873600"
  },
  {
    "text": "obvious it's greatly simplified our deployments they can now be done entirely within the game server team and often by just a",
    "start": "1873600",
    "end": "1881039"
  },
  {
    "text": "single person uh it's the opportunity for human error",
    "start": "1881039",
    "end": "1888399"
  },
  {
    "text": "is uh much uh is greatly reduced because elastic beanstalk is doing a lot of the",
    "start": "1888399",
    "end": "1894080"
  },
  {
    "text": "heavy lifting for us uh and deployments can now often be completed and verified",
    "start": "1894080",
    "end": "1899120"
  },
  {
    "text": "in you know under 20 20 minutes or so the other the other benefit is the",
    "start": "1899120",
    "end": "1906320"
  },
  {
    "text": "dashboards that beanstalk provides you so it's got a nice monitoring dashboard coupled with our own custom dashboards",
    "start": "1906320",
    "end": "1911600"
  },
  {
    "text": "we have unprecedented visibility into our service we're always the first to know of any",
    "start": "1911600",
    "end": "1918320"
  },
  {
    "text": "issue with our service and we are always the first to respond to uh to any uh issues with a service",
    "start": "1918320",
    "end": "1926159"
  },
  {
    "text": "and so now colin will tell us some stories running a live service is often very",
    "start": "1926159",
    "end": "1932960"
  },
  {
    "text": "exciting when things don't go according to plan i'm going to share a couple funny stories about problems that arose",
    "start": "1932960",
    "end": "1939120"
  },
  {
    "text": "unexpectedly and how we were able to solve them quickly",
    "start": "1939120",
    "end": "1944000"
  },
  {
    "text": "whacking day was a major content release in spring 2013. the goal was unsurprisingly to whack",
    "start": "1945519",
    "end": "1952240"
  },
  {
    "text": "snakes but before i talk about this event i first have to review the existing system mechanics",
    "start": "1952240",
    "end": "1958000"
  },
  {
    "text": "in tsto you can visit a friend's town and perform actions these actions generate events",
    "start": "1958000",
    "end": "1964080"
  },
  {
    "text": "which your friends can see and acknowledge for every event generated in this manner we have one database right",
    "start": "1964080",
    "end": "1971360"
  },
  {
    "text": "when your friend acknowledges the event there is one database delete",
    "start": "1971360",
    "end": "1976559"
  },
  {
    "text": "there's a limit of three events per friend per day and uh throughout the entire system we",
    "start": "1976559",
    "end": "1983760"
  },
  {
    "text": "had pretty low dynamodb read and write throughput on this table of about 100 read and write",
    "start": "1983760",
    "end": "1988799"
  },
  {
    "text": "units respectively for whacking day the user's goal was to",
    "start": "1988799",
    "end": "1995200"
  },
  {
    "text": "collect eggs they could collect over 100 per day they",
    "start": "1995200",
    "end": "2000880"
  },
  {
    "text": "could place any number of eggs in a friend's town",
    "start": "2000880",
    "end": "2005840"
  },
  {
    "text": "and each egg placement generated an event okay as you can see on the bottom left",
    "start": "2006640",
    "end": "2012000"
  },
  {
    "text": "this is a pretty typical example of what a user would do at any given time",
    "start": "2012000",
    "end": "2019200"
  },
  {
    "text": "okay and because of this the consumed throughput grew by an order of magnitude",
    "start": "2019200",
    "end": "2024640"
  },
  {
    "text": "fortunately we were able to detect this increase in time due to cloud watch alarms and we're able to increase the provisioning in time to prevent user",
    "start": "2024640",
    "end": "2031200"
  },
  {
    "text": "impact this underlines the importance of having dynamo to be auto scaling so we made",
    "start": "2031200",
    "end": "2037600"
  },
  {
    "text": "sure to put that in place there's some open source tools that you can use now but at the time we had to",
    "start": "2037600",
    "end": "2043200"
  },
  {
    "text": "write our own auto scaler and then the more important action item was um to be more involved in the",
    "start": "2043200",
    "end": "2050638"
  },
  {
    "text": "content design process so that we could give other project members greater insight into how game features",
    "start": "2050639",
    "end": "2056240"
  },
  {
    "text": "affected the service okay the next story occasionally",
    "start": "2056240",
    "end": "2062560"
  },
  {
    "text": "marketing will send push notifications to all users and it's designed to inform them of a key event such as a content update or",
    "start": "2062560",
    "end": "2069358"
  },
  {
    "text": "an item sale this is usually done by dividing the entire player base into 24 segments",
    "start": "2069359",
    "end": "2075280"
  },
  {
    "text": "sending notifications to one segment per hour it's done this way in order to avoid large spikes in traffic",
    "start": "2075280",
    "end": "2083040"
  },
  {
    "text": "in one of our recent updates a client was released which contained unbeknownst to us a built-in",
    "start": "2083040",
    "end": "2088878"
  },
  {
    "text": "notification schedule which was independent from the usual marketing process",
    "start": "2088879",
    "end": "2094079"
  },
  {
    "text": "the first notification awarded players with donuts and urged them to come into the game and claim their prize",
    "start": "2094079",
    "end": "2101040"
  },
  {
    "text": "the notification was extremely effective the problem was that it went to every single player in the",
    "start": "2101040",
    "end": "2106480"
  },
  {
    "text": "world at the exact same time this led to what was effectively a ddos",
    "start": "2106480",
    "end": "2111760"
  },
  {
    "text": "as you can see the system couldn't handle the strain and the player account dropped to almost zero it can't really be seen in this graph",
    "start": "2111760",
    "end": "2118640"
  },
  {
    "text": "the one on the top left because each data point is in five minute intervals but it turns out that",
    "start": "2118640",
    "end": "2123680"
  },
  {
    "text": "the player count had doubled in under five minutes for the graph on the",
    "start": "2123680",
    "end": "2128720"
  },
  {
    "text": "right you can see that we lost about 30 instances you can see uh ec2 auto scaling trying",
    "start": "2128720",
    "end": "2134800"
  },
  {
    "text": "to kick in that's the little uh bump after the drop but it couldn't keep up with",
    "start": "2134800",
    "end": "2140480"
  },
  {
    "text": "the uh increasing traffic and so when we when we realized what was happening we had to manually double the instance",
    "start": "2140480",
    "end": "2146800"
  },
  {
    "text": "count which is what you see uh on the far right with the large spike in instance counts um",
    "start": "2146800",
    "end": "2154560"
  },
  {
    "text": "so i forgot something uh there's an obvious less er there's an",
    "start": "2154560",
    "end": "2160000"
  },
  {
    "text": "obvious lesson here which is to avoid telling all your users to log in at the same time but there's a more widely applicable",
    "start": "2160000",
    "end": "2165599"
  },
  {
    "text": "lesson in that you should always think about you should always think carefully about how marketing activities can impact",
    "start": "2165599",
    "end": "2171599"
  },
  {
    "text": "your service and to make sure that it's done in a safe manner",
    "start": "2171599",
    "end": "2176640"
  },
  {
    "text": "so i'm just going to review the changes from the relaunch to the present day in",
    "start": "2178240",
    "end": "2183760"
  },
  {
    "text": "the architectural diagram so we didn't talk too much about it but one of the first things we did was",
    "start": "2183760",
    "end": "2189280"
  },
  {
    "text": "move the manually managed memcache cluster to elasticash that was pretty easy as chris talked",
    "start": "2189280",
    "end": "2196720"
  },
  {
    "text": "about we made the game server stateless and so we were able to remove the ha proxy cluster",
    "start": "2196720",
    "end": "2204160"
  },
  {
    "text": "we changed the mysql cluster to use dynamodb instead and then we added elastic beanstalk",
    "start": "2205200",
    "end": "2215838"
  },
  {
    "text": "regarding the original problems we wanted to solve for complex deployments they're now extremely easy using",
    "start": "2216160",
    "end": "2221760"
  },
  {
    "text": "beanstalk for the auto scaling and failover we now have auto scaling and automatic failover",
    "start": "2221760",
    "end": "2229119"
  },
  {
    "text": "on every component and then for the expensive database",
    "start": "2229119",
    "end": "2234400"
  },
  {
    "text": "cluster we were able to replace it with a very cost effective solution",
    "start": "2234400",
    "end": "2239680"
  },
  {
    "text": "aws allows our team to be autonomous and efficient if there's ever a problem with the system we're able to single-handedly",
    "start": "2240960",
    "end": "2248000"
  },
  {
    "text": "troubleshoot develop and test and deploy a solution all within a few hours",
    "start": "2248000",
    "end": "2254800"
  },
  {
    "text": "whether it's by developing new products or features or reducing the cost of existing features",
    "start": "2254800",
    "end": "2260079"
  },
  {
    "text": "aws keeps getting better we're always on the lookout for new features to improve our service",
    "start": "2260079",
    "end": "2266400"
  },
  {
    "text": "like chris said at the beginning we're not dbas and we're not network engineers we're a team of",
    "start": "2266400",
    "end": "2271680"
  },
  {
    "text": "generalists running the live service for a game played by six million people per day and it would be impossible without aws",
    "start": "2271680",
    "end": "2280079"
  },
  {
    "text": "thank you everyone for attending you can give us your feedback this is gam302",
    "start": "2280960",
    "end": "2288559"
  },
  {
    "text": "and thanks for attending",
    "start": "2289520",
    "end": "2299680"
  },
  {
    "text": "you",
    "start": "2299680",
    "end": "2301760"
  }
]
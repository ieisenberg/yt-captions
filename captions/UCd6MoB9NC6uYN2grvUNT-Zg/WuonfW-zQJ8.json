[
  {
    "start": "0",
    "end": "56000"
  },
  {
    "text": "welcome everyone to today's webinar the speaker for today's webinar is John",
    "start": "16760",
    "end": "22320"
  },
  {
    "text": "handler he's the principal solution architect with EWS",
    "start": "22320",
    "end": "27329"
  },
  {
    "text": "let me handle weather control - John what do you John good morning everybody",
    "start": "27329",
    "end": "35090"
  },
  {
    "text": "thanks for coming out this morning appreciate your time and attention my name is John handler I'm principal",
    "start": "35090",
    "end": "40860"
  },
  {
    "text": "Solutions Architect with Amazon Web Services and I work with our search",
    "start": "40860",
    "end": "46019"
  },
  {
    "text": "services principally elastic search service but also with amazon cloudsearch",
    "start": "46019",
    "end": "52399"
  },
  {
    "text": "and this morning we are going to be focusing on Amazon elastic search",
    "start": "52399",
    "end": "58620"
  },
  {
    "start": "56000",
    "end": "56000"
  },
  {
    "text": "service for the webinar so I usually",
    "start": "58620",
    "end": "64408"
  },
  {
    "text": "like to start my presentations by asking for a show of hands for who has anything that produces logs",
    "start": "64409",
    "end": "71909"
  },
  {
    "text": "and of course everybody has things that produce logs because we all have",
    "start": "71909",
    "end": "79170"
  },
  {
    "text": "applications we have servers we have mobile applications we have web applications we do metering we have IOT",
    "start": "79170",
    "end": "87240"
  },
  {
    "text": "all of these things produce data in the form of logs among other things and the",
    "start": "87240",
    "end": "97680"
  },
  {
    "start": "93000",
    "end": "93000"
  },
  {
    "text": "problem is if I take one of those logs and it is a text file now I could",
    "start": "97680",
    "end": "106200"
  },
  {
    "text": "actually read all of this so this is an example here on the screen of an Apache",
    "start": "106200",
    "end": "111750"
  },
  {
    "text": "web log and this Apache web log is showing you know all of the access to my",
    "start": "111750",
    "end": "117200"
  },
  {
    "text": "web server if the phone goes off at 3:00 in the morning and I have to figure out",
    "start": "117200",
    "end": "123210"
  },
  {
    "text": "what's going on with the website because I'm having a problem and if I have thousands of servers and terabytes of",
    "start": "123210",
    "end": "130590"
  },
  {
    "text": "data there's no way that I can look at that in in this format and figure out",
    "start": "130590",
    "end": "136769"
  },
  {
    "text": "what's going on and similarly for all of the data that we produce that actually",
    "start": "136769",
    "end": "142650"
  },
  {
    "text": "machines we have all of this data but we don't have an easy way to get at it in a text",
    "start": "142650",
    "end": "151890"
  },
  {
    "start": "148000",
    "end": "148000"
  },
  {
    "text": "format now we have a tool though called",
    "start": "151890",
    "end": "158040"
  },
  {
    "text": "elasticsearch which allows us to flow that log data into elasticsearch which",
    "start": "158040",
    "end": "165060"
  },
  {
    "text": "is a search engine and elasticsearch holds it and then provides a UI called",
    "start": "165060",
    "end": "171660"
  },
  {
    "text": "cabana that allows us to visualize the data that's actually in our log files in a",
    "start": "171660",
    "end": "177150"
  },
  {
    "text": "useful way so for instance I can get some metrics like counts unique counts of people who",
    "start": "177150",
    "end": "184319"
  },
  {
    "text": "are hitting my website I can look at different places that are generating",
    "start": "184319",
    "end": "189750"
  },
  {
    "start": "186000",
    "end": "186000"
  },
  {
    "text": "that traffic etc so elasticsearch is a",
    "start": "189750",
    "end": "194850"
  },
  {
    "text": "technology again elasticsearch is a search engine in much the same way that",
    "start": "194850",
    "end": "199950"
  },
  {
    "text": "you would use Google to search over web pages you use elastic search to search",
    "start": "199950",
    "end": "206370"
  },
  {
    "text": "over data that you have put into the search engine elastic search came out in about 2009 and initially as a full text",
    "start": "206370",
    "end": "216320"
  },
  {
    "text": "distributed search engine that a plot that allowed people to search through",
    "start": "216320",
    "end": "221430"
  },
  {
    "text": "their text documents and provided you know normal search like experience then",
    "start": "221430",
    "end": "229079"
  },
  {
    "text": "a technology called log stash came along log stash is a streaming ETL over-over",
    "start": "229079",
    "end": "236609"
  },
  {
    "text": "streaming data that allows you to transform data as it comes through the pipeline and deliver that data",
    "start": "236609",
    "end": "243359"
  },
  {
    "text": "principally to elasticsearch Cabana again web UI that allows you to visualize the data that's in your logs",
    "start": "243359",
    "end": "250260"
  },
  {
    "text": "so the three of those became paired together and called the elks stack and",
    "start": "250260",
    "end": "255269"
  },
  {
    "text": "this allowed people to start flowing their log data in and start visualizing",
    "start": "255269",
    "end": "260639"
  },
  {
    "text": "it and and making it more useful now the issue with the ELQ stack is it's",
    "start": "260639",
    "end": "268440"
  },
  {
    "text": "tremendously easy to get started it's very easy to spin up a search cluster an",
    "start": "268440",
    "end": "274110"
  },
  {
    "text": "elastic search cluster very easy to flow data in there logstash but as you try to grow and as",
    "start": "274110",
    "end": "281220"
  },
  {
    "text": "the data size grows grows as the amount of logs that you have grows elastics elk",
    "start": "281220",
    "end": "287190"
  },
  {
    "text": "can be very difficult to scale and we find this across the board for people",
    "start": "287190",
    "end": "292800"
  },
  {
    "text": "that we talk to that managing elk is difficult so in 2015 we came out with",
    "start": "292800",
    "end": "300780"
  },
  {
    "text": "Amazon Elastic search service that provides a managed experience that makes",
    "start": "300780",
    "end": "306330"
  },
  {
    "text": "it easier to deploy and operate elasticsearch in the AWS cloud we",
    "start": "306330",
    "end": "314760"
  },
  {
    "start": "308000",
    "end": "308000"
  },
  {
    "text": "primarily wanted to make sure that it was easy to use elastic search and that",
    "start": "314760",
    "end": "320610"
  },
  {
    "text": "we added a few features and benefits that make it a great experience to run",
    "start": "320610",
    "end": "326340"
  },
  {
    "text": "elastic search on AWS first of those is we provide easy api's to create elastic",
    "start": "326340",
    "end": "333780"
  },
  {
    "text": "search clusters so with a single API call you can have a cluster deployed and",
    "start": "333780",
    "end": "339570"
  },
  {
    "text": "ready for use in a matter of minutes the second of all we wanted to make sure",
    "start": "339570",
    "end": "345030"
  },
  {
    "text": "that we provided an open source experience so Amazon elastic search service provides you direct access to",
    "start": "345030",
    "end": "351690"
  },
  {
    "text": "the elect elastic search API and supports the Elex tax so that you can",
    "start": "351690",
    "end": "357599"
  },
  {
    "text": "use an elastic search service version of elastic search as a drop-in replacement",
    "start": "357599",
    "end": "363570"
  },
  {
    "text": "for an existing elastic search cluster that you have some of the features that we added we added security in the form",
    "start": "363570",
    "end": "371580"
  },
  {
    "text": "of AWS Identity and Access Management or I am you secure your elastic search",
    "start": "371580",
    "end": "377460"
  },
  {
    "text": "clusters with an iam policy that allows you to control who has access to read",
    "start": "377460",
    "end": "383729"
  },
  {
    "text": "and write from that cluster and down to an index level of granularity we have a",
    "start": "383729",
    "end": "389940"
  },
  {
    "text": "feature that makes elastic search service clusters highly available with our zone awareness feature you can split",
    "start": "389940",
    "end": "398550"
  },
  {
    "text": "your cluster into two different AWS availability zones and this gives you replication of data across those zones",
    "start": "398550",
    "end": "406219"
  },
  {
    "text": "we provide a number of integrations with other AWS services to",
    "start": "406219",
    "end": "411330"
  },
  {
    "text": "make it easier to get data into your elasticsearch Service domain in particular we integrate with Amazon",
    "start": "411330",
    "end": "416939"
  },
  {
    "text": "Kinesis firehose a IOT and cloud watch logs at a console level to make it very",
    "start": "416939",
    "end": "423659"
  },
  {
    "text": "simple to get your data into the service finally we make the service easily",
    "start": "423659",
    "end": "429479"
  },
  {
    "text": "scalable so we have an API that allows you to deploy a cluster additionally we",
    "start": "429479",
    "end": "435360"
  },
  {
    "text": "have an API that allows you to change a cluster configuration if you're running a particular set of instance types and",
    "start": "435360",
    "end": "442560"
  },
  {
    "text": "you want to change to different instance types you can do this with a single call we seamlessly bring in new instances in",
    "start": "442560",
    "end": "449490"
  },
  {
    "text": "the backend and cut the data across between the two sets of instances and",
    "start": "449490",
    "end": "455900"
  },
  {
    "text": "you're then on the new configuration again seamlessly while it runs and you",
    "start": "455900",
    "end": "463500"
  },
  {
    "start": "460000",
    "end": "460000"
  },
  {
    "text": "have full access we see two main use cases where elasticsearch service is",
    "start": "463500",
    "end": "471990"
  },
  {
    "text": "used the first of those is falls under the rubric of log analytics now this is",
    "start": "471990",
    "end": "478169"
  },
  {
    "text": "more broadly any kind of streaming data that you would send into the elastic search service what we see customers",
    "start": "478169",
    "end": "485430"
  },
  {
    "text": "doing here we see many customers who are monitoring their infrastructure simply",
    "start": "485430",
    "end": "490529"
  },
  {
    "text": "to use Cabana to visualize server uptime server loads problems that are going on",
    "start": "490529",
    "end": "498479"
  },
  {
    "text": "in terms of the error codes that they're receiving etc as we get higher up in the",
    "start": "498479",
    "end": "504690"
  },
  {
    "text": "abstraction layer we talk about application logs we'll go into a couple of examples in a second but customers do",
    "start": "504690",
    "end": "510900"
  },
  {
    "text": "various things to make sure that their applications are functioning right and indeed to even get analytical kind of",
    "start": "510900",
    "end": "517110"
  },
  {
    "text": "information as their users interact with their software the second use case is a",
    "start": "517110",
    "end": "523620"
  },
  {
    "text": "full-text search use case and again elastic search is a full text search engine that provides you the ability to",
    "start": "523620",
    "end": "530730"
  },
  {
    "text": "match free text as well as to perform structured and other kinds of expression",
    "start": "530730",
    "end": "536100"
  },
  {
    "text": "based searching with adjustable relevance faceting filtering etc so it's",
    "start": "536100",
    "end": "543209"
  },
  {
    "text": "a full text search engine we do see maybe 30 40 percent of our customers using elasticsearch service for",
    "start": "543209",
    "end": "549649"
  },
  {
    "start": "546000",
    "end": "546000"
  },
  {
    "text": "full-text search some of our customers that are using elasticsearch service at",
    "start": "549649",
    "end": "556820"
  },
  {
    "text": "various levels of scale the point I like to make about this slide is yes we have",
    "start": "556820",
    "end": "562010"
  },
  {
    "text": "a broad range of customers across many different verticals and this really speaks to elastic searches popularity",
    "start": "562010",
    "end": "569540"
  },
  {
    "text": "and use as a monitoring tool you know in all of these cases we see though these",
    "start": "569540",
    "end": "576290"
  },
  {
    "text": "companies using elastic search to monitor their infrastructure and do the kind of log analytics that I was talking",
    "start": "576290",
    "end": "582110"
  },
  {
    "start": "579000",
    "end": "579000"
  },
  {
    "text": "about a couple of examples first of all",
    "start": "582110",
    "end": "587480"
  },
  {
    "text": "we have the Adobe developer platform they are taking logs from their API",
    "start": "587480",
    "end": "592880"
  },
  {
    "text": "servers so as their customers are interacting with the Adobe API servers",
    "start": "592880",
    "end": "598550"
  },
  {
    "text": "they're shipping all of those logs now they're a very high volume use case so",
    "start": "598550",
    "end": "604130"
  },
  {
    "text": "they're using Amazon Kinesis streams to handle the influx of data from all of",
    "start": "604130",
    "end": "609649"
  },
  {
    "text": "those servers they then pass it through spark streaming and they do a little bit of a modification on the data they roll",
    "start": "609649",
    "end": "615890"
  },
  {
    "text": "it up into 1-minute windows to make it you know somewhat lower volume before",
    "start": "615890",
    "end": "621529"
  },
  {
    "text": "sending it off to elasticsearch service they found this was a you know a really",
    "start": "621529",
    "end": "626779"
  },
  {
    "text": "effective solution for them they're sending over 200,000 API calls per second at peak and all of that data is",
    "start": "626779",
    "end": "635209"
  },
  {
    "text": "going to last 6 search service as they were doing the development they really had a nice benefit of being able to",
    "start": "635209",
    "end": "642339"
  },
  {
    "text": "switch around their deployment and instance types and they were able to take advantage of that to make sure that",
    "start": "642339",
    "end": "648529"
  },
  {
    "text": "they dialed in their their deployment exactly to the resource needs that they",
    "start": "648529",
    "end": "655430"
  },
  {
    "start": "651000",
    "end": "651000"
  },
  {
    "text": "had a second example of streaming data is mcgraw-hill education mcgraw-hill",
    "start": "655430",
    "end": "662810"
  },
  {
    "text": "education is an online learning software they have a catalog of classes students",
    "start": "662810",
    "end": "669949"
  },
  {
    "text": "sign up for those classes and teachers deliver them they wanted to use elasticsearch to analyze the performance",
    "start": "669949",
    "end": "677390"
  },
  {
    "text": "of not only their software but also of the students and teachers who are using that software",
    "start": "677390",
    "end": "683150"
  },
  {
    "text": "so they flow in all of the data as students and teachers interact with their website into elasticsearch service",
    "start": "683150",
    "end": "690290"
  },
  {
    "text": "and then they don't use Cabana they use actually elasticsearch query language to",
    "start": "690290",
    "end": "696020"
  },
  {
    "text": "send queries and figure out things like what was the class average and how",
    "start": "696020",
    "end": "702170"
  },
  {
    "text": "engaged was this teacher with their students and you know how much did the",
    "start": "702170",
    "end": "707510"
  },
  {
    "text": "students learn in this class versus that class so they had a real analytics kind of solution and problem and for them the",
    "start": "707510",
    "end": "714850"
  },
  {
    "text": "scalability of elasticsearch service was really a big benefit they start the school year with no data whatsoever and",
    "start": "714850",
    "end": "721880"
  },
  {
    "text": "as it goes on across the nine months of the school year they grow out to be 32 terabytes of data",
    "start": "721880",
    "end": "727790"
  },
  {
    "text": "with elasticsearch service they were able to deploy us they will really use a small deployment to start out with and",
    "start": "727790",
    "end": "734780"
  },
  {
    "text": "then grow that deployment as their data grew along with it so we'll talk a",
    "start": "734780",
    "end": "741320"
  },
  {
    "text": "little bit about elasticsearch service now and walk through some of the basics",
    "start": "741320",
    "end": "746840"
  },
  {
    "text": "of how to think about deploying a cluster of elasticsearch and what does that mean and how does it operate when",
    "start": "746840",
    "end": "755810"
  },
  {
    "start": "748000",
    "end": "748000"
  },
  {
    "text": "you use elasticsearch service you create what we call a domain an elastic search",
    "start": "755810",
    "end": "760970"
  },
  {
    "text": "service domain wraps all of the software and hardware that is used to run elastic",
    "start": "760970",
    "end": "766280"
  },
  {
    "text": "search in the AWS cloud along with the additional security and monitoring and other features that we provide with the",
    "start": "766280",
    "end": "772880"
  },
  {
    "text": "service so domain is just a group name you use the SDK the CLI the console",
    "start": "772880",
    "end": "779390"
  },
  {
    "text": "cloud formation to deploy an elastic search service cluster and again elastic",
    "start": "779390",
    "end": "785210"
  },
  {
    "text": "search is a clustered technology so we have a collection of nodes first we have",
    "start": "785210",
    "end": "792410"
  },
  {
    "text": "data nodes the data nodes hold the data and respond to queries and updates then",
    "start": "792410",
    "end": "798770"
  },
  {
    "text": "we have master nodes master nodes or orchestrators they manage the data nodes",
    "start": "798770",
    "end": "803830"
  },
  {
    "text": "all of those nodes exist in a cluster and all of them perform the tasks of",
    "start": "803830",
    "end": "809180"
  },
  {
    "text": "elasticsearch together in front of the cluster we put elastic load balancing just to spread the load",
    "start": "809180",
    "end": "815780"
  },
  {
    "text": "across the nodes in the cluster in front run of that we have Identity and Access Management AWS I am to provide security",
    "start": "815780",
    "end": "823160"
  },
  {
    "text": "for the cluster and then we send monitoring information to cloud trail and to cloud watch so that you can",
    "start": "823160",
    "end": "830600"
  },
  {
    "text": "monitor the performance of your cluster and make sure that everything is going",
    "start": "830600",
    "end": "836330"
  },
  {
    "text": "well when you're creating a domain the first thing that you have to think about",
    "start": "836330",
    "end": "842630"
  },
  {
    "text": "is how many instances do I need to have in that domains to support my problem so",
    "start": "842630",
    "end": "848810"
  },
  {
    "text": "there's a little bit of a kind of joint question here and at a very simple level",
    "start": "848810",
    "end": "854180"
  },
  {
    "text": "we can take this as a question of storage so I want to look at the number",
    "start": "854180",
    "end": "860420"
  },
  {
    "text": "of instances and I want to look at the storage type to figure out how many instances I need to support my workload",
    "start": "860420",
    "end": "869410"
  },
  {
    "start": "864000",
    "end": "864000"
  },
  {
    "text": "but before we can talk about that we have to go a little bit into how is that",
    "start": "869410",
    "end": "874430"
  },
  {
    "text": "that elasticsearch stores data and how is that data organized within the cluster for long analytics use cases we",
    "start": "874430",
    "end": "882500"
  },
  {
    "text": "typically see customers streaming across a number of different indexes essentially this is a write-once",
    "start": "882500",
    "end": "889780"
  },
  {
    "text": "scenario so customers will create an index for each day and many of the tools",
    "start": "889780",
    "end": "896300"
  },
  {
    "text": "already do this automatically for you that index is consists of the set of all",
    "start": "896300",
    "end": "902690"
  },
  {
    "text": "of the documents that are in that in that search index indexes are divided",
    "start": "902690",
    "end": "908120"
  },
  {
    "text": "into shards each shard is a subset of all of the documents that are in the",
    "start": "908120",
    "end": "914060"
  },
  {
    "text": "index and shards are non-overlapping they're all distinct indexes can have",
    "start": "914060",
    "end": "919730"
  },
  {
    "text": "one to many shards the shards contain documents the documents themselves are",
    "start": "919730",
    "end": "925790"
  },
  {
    "text": "not what we think of as a kind of office document they're not Word documents or",
    "start": "925790",
    "end": "931070"
  },
  {
    "text": "PDFs or whatever for long analytics each log line corresponds to a single search",
    "start": "931070",
    "end": "937130"
  },
  {
    "text": "document documents are what you put into a search engine documents are what you get out of the search engine the document is come",
    "start": "937130",
    "end": "945020"
  },
  {
    "text": "host of a set of fields and values so if we think about Apache web logs we have a",
    "start": "945020",
    "end": "950570"
  },
  {
    "text": "host we have an identity an off field we have a time stamp we have a request a",
    "start": "950570",
    "end": "956090"
  },
  {
    "text": "verb that was given with that with that request as well so this is a little",
    "start": "956090",
    "end": "962090"
  },
  {
    "start": "959000",
    "end": "959000"
  },
  {
    "text": "logical structure of the data within elastic search elastic search is partly",
    "start": "962090",
    "end": "968390"
  },
  {
    "text": "called elastic search because it takes that data and it deploys it elastically on to a cluster of instances so in this",
    "start": "968390",
    "end": "976670"
  },
  {
    "text": "case and how it does that is it deploys the shards themselves the shards are the",
    "start": "976670",
    "end": "981730"
  },
  {
    "text": "storage and computational pieces of elastic search in fact they're an instance of something called Apache",
    "start": "981730",
    "end": "988970"
  },
  {
    "text": "leucine which is a Java library that provides reading and writing o search indexes so each shard holding some set",
    "start": "988970",
    "end": "997070"
  },
  {
    "text": "of documents is deployed onto a particular instance in an Amazon elastic search service cluster in this example",
    "start": "997070",
    "end": "1003610"
  },
  {
    "text": "we have two indexes and each of them has three shards shards come in two flavors",
    "start": "1003610",
    "end": "1009010"
  },
  {
    "text": "there's a primary shard that's the first shard for each one in addition you have",
    "start": "1009010",
    "end": "1015160"
  },
  {
    "text": "a set of replica shards which you can dynamically set from 1 to n in this",
    "start": "1015160",
    "end": "1020860"
  },
  {
    "text": "example we have a single primary shard and a single replica shard for each of",
    "start": "1020860",
    "end": "1025870"
  },
  {
    "text": "our shards you'll notice that those are then deployed onto the instances in the",
    "start": "1025870",
    "end": "1031660"
  },
  {
    "text": "cluster in such a way that no primary or replica sits on the same instance this",
    "start": "1031660",
    "end": "1037689"
  },
  {
    "text": "gives elasticsearch some some resiliency to individual instance failure if an",
    "start": "1037690",
    "end": "1044589"
  },
  {
    "text": "instance goes out I still retain one copy of that data somewhere else in the",
    "start": "1044589",
    "end": "1049810"
  },
  {
    "text": "cluster if I bring in a new instance elasticsearch is able to then recreate that that set of data on the new",
    "start": "1049810",
    "end": "1058420"
  },
  {
    "start": "1057000",
    "end": "1057000"
  },
  {
    "text": "instance and recover from that failure so if we think about how many instances",
    "start": "1058420",
    "end": "1064900"
  },
  {
    "text": "we want again we have a number of shards that are deployed roughly evenly onto a set of instances well again we can look",
    "start": "1064900",
    "end": "1072310"
  },
  {
    "text": "at it as a sizing problem or from the size perspective so we'll say let's have",
    "start": "1072310",
    "end": "1078040"
  },
  {
    "text": "say we have a two-terabyte corpus now when I send in two terabytes of log lines elasticsearch creates an index out of",
    "start": "1078040",
    "end": "1085179"
  },
  {
    "text": "those log lines which is not exactly the same size as the source data was in fact",
    "start": "1085179",
    "end": "1091269"
  },
  {
    "text": "it it ranges from smaller than to larger than the source data but in typical",
    "start": "1091269",
    "end": "1098289"
  },
  {
    "text": "cases the index size is about the same as the source corpus of documents",
    "start": "1098289",
    "end": "1103919"
  },
  {
    "text": "usually one to one point one for each replica that we deploy we have to add an",
    "start": "1103919",
    "end": "1110740"
  },
  {
    "text": "additional an additional set of storage right so if I start with my two terabyte",
    "start": "1110740",
    "end": "1116080"
  },
  {
    "text": "corpus and I end up with a two terabyte index and then I add a replica I'll need",
    "start": "1116080",
    "end": "1121840"
  },
  {
    "text": "four terabytes of storage to store that index we can then size based on storage",
    "start": "1121840",
    "end": "1127870"
  },
  {
    "text": "requirements we can use local storage or EBS storage and for EBS storage we can",
    "start": "1127870",
    "end": "1134440"
  },
  {
    "text": "get as large as one-and-a-half terabytes per instance taking all that we can",
    "start": "1134440",
    "end": "1139659"
  },
  {
    "text": "simply divide we can say okay I have a two terabyte corpus with my replicas that's 4 terabytes of of index I need to",
    "start": "1139659",
    "end": "1148179"
  },
  {
    "text": "store so that will require four instances if I have a one and a half",
    "start": "1148179",
    "end": "1153549"
  },
  {
    "text": "terabytes per instance it gives a six terabytes total of storage we divide that we have a little overhead in there",
    "start": "1153549",
    "end": "1160539"
  },
  {
    "text": "that's good because again the index will be a little bit larger so this is the right sizing for this two terabyte",
    "start": "1160539",
    "end": "1167139"
  },
  {
    "start": "1163000",
    "end": "1163000"
  },
  {
    "text": "corpus when you create your elasticsearch index you set the number",
    "start": "1167139",
    "end": "1173559"
  },
  {
    "text": "of primary shards it's very important to get the number of primary shards correct",
    "start": "1173559",
    "end": "1178870"
  },
  {
    "text": "so that they're not too big and they're not too small there's a lot of",
    "start": "1178870",
    "end": "1183880"
  },
  {
    "text": "information out there about how to size shards but again at a very simple level we can take this as a problem of storage",
    "start": "1183880",
    "end": "1191500"
  },
  {
    "text": "so as a best practice set the primary shard count so that the shards are less",
    "start": "1191500",
    "end": "1198010"
  },
  {
    "text": "than 50 gigabytes to do this you can divide your index size by about 40",
    "start": "1198010",
    "end": "1203500"
  },
  {
    "text": "gigabytes you can shade it up or down to get an initial shard count so if we look",
    "start": "1203500",
    "end": "1208750"
  },
  {
    "text": "at our example here again two terabyte corpus will 50 shards taking two thousand gigabytes",
    "start": "1208750",
    "end": "1214890"
  },
  {
    "text": "dividing by 40 by 40 gigabytes per shard we should use about 50 shards for that",
    "start": "1214890",
    "end": "1220530"
  },
  {
    "text": "and we use 40 gigabytes as a target because that gives a little overhead as",
    "start": "1220530",
    "end": "1226440"
  },
  {
    "text": "your indexes roll forward day to day you won't have to adjust anything quite as often",
    "start": "1226440",
    "end": "1232880"
  },
  {
    "text": "then comes the tricky bit because we've so far sized based only on storage the",
    "start": "1232880",
    "end": "1239910"
  },
  {
    "text": "next thing we have to do is adjust for workload there are some general rules",
    "start": "1239910",
    "end": "1245100"
  },
  {
    "text": "here but mostly what you do is you try it out run your workload against it and",
    "start": "1245100",
    "end": "1251640"
  },
  {
    "text": "see how it comes out whether you're over or under scaled just two little tips the",
    "start": "1251640",
    "end": "1259140"
  },
  {
    "text": "more shards you have you end up parallelizing your writes better so for",
    "start": "1259140",
    "end": "1264270"
  },
  {
    "text": "higher right capacity and then this is usually the case with log analytics for higher write capacity you want to shade",
    "start": "1264270",
    "end": "1271170"
  },
  {
    "text": "up in the shard count now the more shards you have though the more your",
    "start": "1271170",
    "end": "1277410"
  },
  {
    "text": "query gets distributed and the more individual shards have to respond for",
    "start": "1277410",
    "end": "1282540"
  },
  {
    "text": "queries so for queries you tend to want fewer shards generally again log",
    "start": "1282540",
    "end": "1288960"
  },
  {
    "text": "analytics we're dealing with writes not reads so generally for log analytics you",
    "start": "1288960",
    "end": "1294690"
  },
  {
    "text": "want more shards for query or full text use cases that's where you'd see perhaps",
    "start": "1294690",
    "end": "1300390"
  },
  {
    "text": "you'd need fewer shards then as we're as we're sizing it out we also want to look",
    "start": "1300390",
    "end": "1307530"
  },
  {
    "text": "at how many shards are going to be active on each of the instances and as a",
    "start": "1307530",
    "end": "1312930"
  },
  {
    "text": "general guideline the active shards per instance should roughly be the same as",
    "start": "1312930",
    "end": "1317970"
  },
  {
    "text": "the number of CPUs on that instance so if I'm thinking about",
    "start": "1317970",
    "end": "1323130"
  },
  {
    "text": "and when I say active shards what I mean is elasticsearch for log analytics is a",
    "start": "1323130",
    "end": "1328800"
  },
  {
    "text": "write only kind of use case so I'm writing to one index at a time and all",
    "start": "1328800",
    "end": "1335820"
  },
  {
    "text": "of the other indexes are there and they're responding to some queries but mostly what I'm doing is writing so in",
    "start": "1335820",
    "end": "1341850"
  },
  {
    "text": "that case I can essentially ignore the old indexes and just look at it as a single index and say",
    "start": "1341850",
    "end": "1348320"
  },
  {
    "text": "okay if this index is spread across all the instances in my cluster",
    "start": "1348320",
    "end": "1353390"
  },
  {
    "text": "how many shards active would how many shards would I have per instance that should roughly equal the cpu's that you",
    "start": "1353390",
    "end": "1359600"
  },
  {
    "text": "have on the instance type that you select last point always use at least",
    "start": "1359600",
    "end": "1365900"
  },
  {
    "text": "one replica for production use cases as we saw in the previous slide the first",
    "start": "1365900",
    "end": "1372950"
  },
  {
    "text": "replica provides you a second copy of your data within your cluster so one",
    "start": "1372950",
    "end": "1378110"
  },
  {
    "text": "replica provides you with redundancy and the resiliency in the case of a single",
    "start": "1378110",
    "end": "1383360"
  },
  {
    "text": "instance failing further replicas are usually used to add additional query",
    "start": "1383360",
    "end": "1390020"
  },
  {
    "text": "capacity so for full-text search use cases you sometimes see multiple",
    "start": "1390020",
    "end": "1395210"
  },
  {
    "text": "replicas spread evenly across additional instances but the point I want to make",
    "start": "1395210",
    "end": "1400970"
  },
  {
    "text": "here you should use one replica for all production use cases so let's talk a",
    "start": "1400970",
    "end": "1410240"
  },
  {
    "text": "little bit about instance type and how do you pick an instance type for your elasticsearch use case you can see here",
    "start": "1410240",
    "end": "1419540"
  },
  {
    "start": "1419000",
    "end": "1419000"
  },
  {
    "text": "on our console you have this the choice to choose among the supported instance types and the instance types that we",
    "start": "1419540",
    "end": "1426860"
  },
  {
    "text": "support are the tee class the m-class the our class the c class in the AI class for the tee class of instances",
    "start": "1426860",
    "end": "1434810"
  },
  {
    "text": "these are really an entry point they're really only good for Devon tests they're",
    "start": "1434810",
    "end": "1440570"
  },
  {
    "text": "not for production use cases so put those aside the EM class instances have",
    "start": "1440570",
    "end": "1446480"
  },
  {
    "text": "a balance between the CPU and the RAM that they provide and so they're a good",
    "start": "1446480",
    "end": "1451970"
  },
  {
    "text": "starting point for almost all use cases there again very balanced and are good",
    "start": "1451970",
    "end": "1459410"
  },
  {
    "text": "in those cases the our class instances have additional RAM which helps",
    "start": "1459410",
    "end": "1465710"
  },
  {
    "text": "elasticsearch in queries especially but also helps for writes so we see heavier",
    "start": "1465710",
    "end": "1472430"
  },
  {
    "text": "workloads or read heavy workloads migrating to the our class of instances",
    "start": "1472430",
    "end": "1477820"
  },
  {
    "text": "when the M class runs out for them the C class of instances with more CPUs supports more",
    "start": "1477820",
    "end": "1486230"
  },
  {
    "text": "concurrency so if you have a very high connectivity that you're trying to support you'd want to head towards the C",
    "start": "1486230",
    "end": "1492380"
  },
  {
    "text": "class and then finally the AI class of instance is hat with 1.6 terabytes of",
    "start": "1492380",
    "end": "1498380"
  },
  {
    "text": "SSD local storage has the largest attached disks of any instance type that",
    "start": "1498380",
    "end": "1505070"
  },
  {
    "text": "we support we do find that the instance storage is slightly more slightly",
    "start": "1505070",
    "end": "1511940"
  },
  {
    "text": "quicker than the EBS storage in most situations it doesn't matter especially for log analytics we do recommend EBS",
    "start": "1511940",
    "end": "1519650"
  },
  {
    "text": "volumes and we do recommend the GP to general-purpose EBS volumes as the right",
    "start": "1519650",
    "end": "1525890"
  },
  {
    "text": "choice however instant storage will give you up",
    "start": "1525890",
    "end": "1531020"
  },
  {
    "text": "to a 10 to the 15 percent performance improvement which usually matters for",
    "start": "1531020",
    "end": "1536450"
  },
  {
    "text": "again full-text workloads not so much for a lot for log analytics workloads",
    "start": "1536450",
    "end": "1544300"
  },
  {
    "start": "1538000",
    "end": "1538000"
  },
  {
    "text": "when we think about instance sizing and I just wanted to give some example or",
    "start": "1544300",
    "end": "1549590"
  },
  {
    "text": "some feel for what are the incident sizes that would be appropriate for different workloads starting out at the",
    "start": "1549590",
    "end": "1555920"
  },
  {
    "text": "small end we do see a lot of customers who have application instances with lob",
    "start": "1555920",
    "end": "1561920"
  },
  {
    "text": "stash or the newer beats co-located on the application instance tailing the log",
    "start": "1561920",
    "end": "1567710"
  },
  {
    "text": "lines and sending those to elasticsearch directly in this case you know we have",
    "start": "1567710",
    "end": "1574820"
  },
  {
    "text": "the m4 class and for large as our entry point default instance type up to 200",
    "start": "1574820",
    "end": "1580700"
  },
  {
    "text": "gigabytes a day with hundred BBS 100 gigabyte EBS volumes or larger depending",
    "start": "1580700",
    "end": "1587360"
  },
  {
    "text": "on how much data you're storing is a good choice we do also recommend masternodes we'll get to those in this",
    "start": "1587360",
    "end": "1594620"
  },
  {
    "start": "1591000",
    "end": "1591000"
  },
  {
    "text": "in a second for larger use cases a",
    "start": "1594620",
    "end": "1599630"
  },
  {
    "text": "couple of points to make when you have a large set of instances and you outgrow",
    "start": "1599630",
    "end": "1605750"
  },
  {
    "text": "the number of CPUs that you can support with connectivity then you need some kind of buffering solution",
    "start": "1605750",
    "end": "1612840"
  },
  {
    "text": "this case we recommend Amazon Kinesis fire hose to take your data transform",
    "start": "1612840",
    "end": "1618090"
  },
  {
    "text": "and deliver to elasticsearch service and here we're seeing up to a terabyte of data a day something like on the r4 2x",
    "start": "1618090",
    "end": "1626700"
  },
  {
    "text": "larges with one terabyte volumes and again 3m for large master nodes is the",
    "start": "1626700",
    "end": "1632820"
  },
  {
    "start": "1629000",
    "end": "1629000"
  },
  {
    "text": "recommendation finally at the high end and again this is thinking about the",
    "start": "1632820",
    "end": "1639600"
  },
  {
    "text": "Adobe use case what we see is we have many many data producers and we need",
    "start": "1639600",
    "end": "1646500"
  },
  {
    "text": "some really large scale way of handling all of that data well many customers use Amazon Kinesis",
    "start": "1646500",
    "end": "1652830"
  },
  {
    "text": "streams or they use SPARC along with that or they use EMR and this is again",
    "start": "1652830",
    "end": "1659429"
  },
  {
    "text": "one terabyte plus per day we're then looking at kind of getting into the larger instance sizes like the 8x large",
    "start": "1659429",
    "end": "1666750"
  },
  {
    "text": "for the our fours as the number of data instances grows the number of master",
    "start": "1666750",
    "end": "1673020"
  },
  {
    "text": "nodes is going to grow in size and complexity is C for 2x large for an XL",
    "start": "1673020",
    "end": "1678690"
  },
  {
    "text": "use case is a good a good place to start for this I want to touch on a couple of",
    "start": "1678690",
    "end": "1687929"
  },
  {
    "text": "the features that we have that we provide through Amazon Elastic search service the first of those is dedicated",
    "start": "1687929",
    "end": "1695520"
  },
  {
    "text": "masters you'll see in our console you can choose to enable dedicated masters if you click the check box you'll have a",
    "start": "1695520",
    "end": "1703289"
  },
  {
    "text": "drop-down that lets you set an instance type in an instance count for the dedicated master notes so what are",
    "start": "1703289",
    "end": "1709529"
  },
  {
    "start": "1705000",
    "end": "1705000"
  },
  {
    "text": "dedicated masters and should you use them well every elasticsearch cluster",
    "start": "1709529",
    "end": "1715190"
  },
  {
    "text": "has a master instance that master instance is responsible to know what are",
    "start": "1715190",
    "end": "1722850"
  },
  {
    "text": "the indexes what are the schemas for those indexes what are the shards",
    "start": "1722850",
    "end": "1727890"
  },
  {
    "text": "where are the shards located which are the nodes in the cluster and where are",
    "start": "1727890",
    "end": "1733020"
  },
  {
    "text": "they so essentially it's keeping track of cluster state so the problem is if I",
    "start": "1733020",
    "end": "1739679"
  },
  {
    "text": "have my master instance which is tracking my cluster state",
    "start": "1739679",
    "end": "1745290"
  },
  {
    "text": "colocation and doing the same functions as the data instance which is weeding",
    "start": "1745290",
    "end": "1751370"
  },
  {
    "text": "which is handling updates and responding to queries then my query or or update",
    "start": "1751370",
    "end": "1759150"
  },
  {
    "text": "volume can actually overload that node and all of a sudden my coordinator goes away and my cluster dissolves so it's",
    "start": "1759150",
    "end": "1766860"
  },
  {
    "text": "not a great idea to keep the master function on the same instance as the",
    "start": "1766860",
    "end": "1772020"
  },
  {
    "text": "data the data instances when I employ",
    "start": "1772020",
    "end": "1777150"
  },
  {
    "text": "dedicated masters what I do is I take that master function and I push it on to",
    "start": "1777150",
    "end": "1782730"
  },
  {
    "text": "a node that's not a data node so dedicated master nodes are nodes that do",
    "start": "1782730",
    "end": "1787799"
  },
  {
    "text": "nothing but provide the the master function or provide a way to do the",
    "start": "1787799",
    "end": "1793919"
  },
  {
    "text": "master function now the master instance in a cluster is elected based on the",
    "start": "1793919",
    "end": "1802280"
  },
  {
    "text": "majority of the instances that are eligible to be masters so if I have an",
    "start": "1802280",
    "end": "1810480"
  },
  {
    "text": "even number of instances eligible then and I have a split and network split",
    "start": "1810480",
    "end": "1817200"
  },
  {
    "text": "then each half could get enough to elect",
    "start": "1817200",
    "end": "1822630"
  },
  {
    "text": "a master in that case my cluster will turn into two clusters and that's not a good thing so an even number of",
    "start": "1822630",
    "end": "1830130"
  },
  {
    "text": "dedicated masters is not a good thing you always want to use an odd number of",
    "start": "1830130",
    "end": "1835200"
  },
  {
    "text": "dedicated masters and one dedicated master is really not enough if that",
    "start": "1835200",
    "end": "1840900"
  },
  {
    "text": "dedicated if that master goes away again you don't have a backup so you want to",
    "start": "1840900",
    "end": "1846390"
  },
  {
    "text": "use three dedicated masters in all cases where you want to use masters at least",
    "start": "1846390",
    "end": "1851820"
  },
  {
    "text": "five or seven perhaps in very large clusters we do we recommend that you use",
    "start": "1851820",
    "end": "1858090"
  },
  {
    "text": "three dedicated masters for all production workloads in some cases if it's Devon test you don't care so much",
    "start": "1858090",
    "end": "1864240"
  },
  {
    "text": "if you if your cluster goes away you can rebuild it easily but in production we recommend that you use three dedicated",
    "start": "1864240",
    "end": "1870720"
  },
  {
    "start": "1866000",
    "end": "1866000"
  },
  {
    "text": "master nodes terms of the masternodes themselves",
    "start": "1870720",
    "end": "1875820"
  },
  {
    "text": "because they're doing a lot less than what the data nodes are doing so you you",
    "start": "1875820",
    "end": "1881340"
  },
  {
    "text": "can use much smaller instance types and you can use again only three of them for",
    "start": "1881340",
    "end": "1887100"
  },
  {
    "text": "to manage really large clusters so if we look at the number of data nodes that",
    "start": "1887100",
    "end": "1892140"
  },
  {
    "text": "are in your cluster we can recommend master instances based on that for up to",
    "start": "1892140",
    "end": "1897630"
  },
  {
    "text": "ten the m3 medium is the lowest cost option for master notes up to 20 we",
    "start": "1897630",
    "end": "1904290"
  },
  {
    "text": "would like to see you go to a large instance type 50 we'd like an extra-large and up to a hundred we'd",
    "start": "1904290",
    "end": "1910380"
  },
  {
    "text": "like a 2x large again we've we've chosen m3 m4 and c4 your mileage may vary and",
    "start": "1910380",
    "end": "1917929"
  },
  {
    "text": "with all things scale for elasticsearch it depends on testing so try it out but",
    "start": "1917929",
    "end": "1924390"
  },
  {
    "text": "these are a good place to start the next",
    "start": "1924390",
    "end": "1929429"
  },
  {
    "start": "1929000",
    "end": "1929000"
  },
  {
    "text": "feature I want to talk about is zone awareness so with zone awareness again we split the instances in the cluster",
    "start": "1929429",
    "end": "1937020"
  },
  {
    "text": "into two different availability zones and then we make sure that the primary",
    "start": "1937020",
    "end": "1942600"
  },
  {
    "text": "and replica shards are separated into different zones in this in this way you",
    "start": "1942600",
    "end": "1948720"
  },
  {
    "text": "have redundancy where a hundred percent of your data resides in each of the availability zones",
    "start": "1948720",
    "end": "1954179"
  },
  {
    "text": "if one zone should become unavailable you retain a hundred percent of data online so you haven't lost any data out",
    "start": "1954179",
    "end": "1961380"
  },
  {
    "text": "of the cluster we do recommend zone awareness again for production use cases where the data itself is important to",
    "start": "1961380",
    "end": "1969900"
  },
  {
    "start": "1969000",
    "end": "1969000"
  },
  {
    "text": "maintain online it's it's important to add that high availability in terms of",
    "start": "1969900",
    "end": "1977640"
  },
  {
    "text": "the cost of elasticsearch service we charge based on three dimensions two of",
    "start": "1977640",
    "end": "1982770"
  },
  {
    "text": "them primarily with elasticsearch service you pay for the instances in the",
    "start": "1982770",
    "end": "1987929"
  },
  {
    "text": "cluster I pay hourly and then if you choose EBS as your storage option then you also pay",
    "start": "1987929",
    "end": "1996450"
  },
  {
    "text": "for the EBS volumes the third dimension we also charges AWS data transfer this",
    "start": "1996450",
    "end": "2002720"
  },
  {
    "text": "is the standard data transfer charge that that you would occur across AWS",
    "start": "2002720",
    "end": "2007790"
  },
  {
    "text": "we do qualify for free tier so if you are free tier qualifying you can use a",
    "start": "2007790",
    "end": "2015320"
  },
  {
    "text": "single tee too small to try out the service see how it goes get a feel for it",
    "start": "2015320",
    "end": "2020810"
  },
  {
    "text": "and use it for free so I just want to sum up that was a lot of information on",
    "start": "2020810",
    "end": "2028150"
  },
  {
    "text": "scaling and features of the service so some of the things we covered the data",
    "start": "2028150",
    "end": "2035000"
  },
  {
    "text": "nodes you need you should size initially based on the storage so you take the",
    "start": "2035000",
    "end": "2040400"
  },
  {
    "text": "storage needed divided by the storage per node that tells you how many data notes you need we do recommend again the",
    "start": "2040400",
    "end": "2047000"
  },
  {
    "text": "GP to EBS volumes for the log analytics use case three dedicated master nodes",
    "start": "2047000",
    "end": "2052129"
  },
  {
    "text": "for production and zone awareness the last one we didn't cover I'm gonna skip it so once we understand how to deploy",
    "start": "2052130",
    "end": "2062600"
  },
  {
    "text": "an elastic search service cluster and how it operates the next question that comes fairly urgently is well how do I",
    "start": "2062600",
    "end": "2068990"
  },
  {
    "start": "2065000",
    "end": "2065000"
  },
  {
    "text": "get data into it so we have a number of different ways of getting data into",
    "start": "2068990",
    "end": "2075800"
  },
  {
    "text": "elastic search corresponding to a number of different technologies that you might use for we have on the Left a set of",
    "start": "2075800",
    "end": "2084290"
  },
  {
    "text": "data producers those are generating log data streaming data all of that we would",
    "start": "2084290",
    "end": "2089750"
  },
  {
    "text": "send that again through Kinesis firehose will be our recommendation will go into depth on that cloud watch logs if you're",
    "start": "2089750",
    "end": "2097190"
  },
  {
    "text": "already sending log data to cloud watch logs it's very easy to forward that data to elastic search service you can do it",
    "start": "2097190",
    "end": "2105020"
  },
  {
    "text": "in the console it's just a few clicks send it off to elastic search and then you can use gabbana on top of that for",
    "start": "2105020",
    "end": "2112070"
  },
  {
    "text": "IOT again IOT can integrate directly with elastic search so if you're sending",
    "start": "2112070",
    "end": "2117230"
  },
  {
    "text": "data through IOT you can get it to elastic search and again if you're using",
    "start": "2117230",
    "end": "2122240"
  },
  {
    "start": "2121000",
    "end": "2121000"
  },
  {
    "text": "log stash that's another way to get data into elastic search lamda is kind of the",
    "start": "2122240",
    "end": "2129770"
  },
  {
    "text": "all-purpose tool across AWS and it's true as well for elastic search service",
    "start": "2129770",
    "end": "2135160"
  },
  {
    "text": "with with lambda you can take records and transform them and send them into",
    "start": "2135160",
    "end": "2140840"
  },
  {
    "text": "elastic search sir some of the use cases that we see if we have a data lake kind of scenario where",
    "start": "2140840",
    "end": "2147380"
  },
  {
    "text": "we're sending a number of files into a data lake somewhere you can trigger a",
    "start": "2147380",
    "end": "2153220"
  },
  {
    "text": "lambda function on the s3 create event pull the metadata for that object that",
    "start": "2153220",
    "end": "2160490"
  },
  {
    "text": "landed in s3 and then push that into elastic search to make elastic search your catalog for searching what's in",
    "start": "2160490",
    "end": "2167690"
  },
  {
    "text": "your data lake you could also pull the data out of the object itself and use",
    "start": "2167690",
    "end": "2173480"
  },
  {
    "text": "that and send it to elastic search some customers are sending their log data in bulk blocks into s3 then reading that",
    "start": "2173480",
    "end": "2181100"
  },
  {
    "text": "out of s3 with their lambda and pushing it into elastic search service similarly",
    "start": "2181100",
    "end": "2186890"
  },
  {
    "text": "if I'm using Amazon DynamoDB and I'm sending data to a table I can",
    "start": "2186890",
    "end": "2192740"
  },
  {
    "text": "trigger a lambda function off the dynamo stream and push that data into elastic",
    "start": "2192740",
    "end": "2198020"
  },
  {
    "text": "search and then finally Amazon Kinesis streams provides provides the ability to",
    "start": "2198020",
    "end": "2204560"
  },
  {
    "text": "trigger lambda on events so if I'm streaming data through Kinesis streams I can easily move that data into elastic",
    "start": "2204560",
    "end": "2211220"
  },
  {
    "start": "2208000",
    "end": "2208000"
  },
  {
    "text": "search via a lambda function I'm going to talk a little bit in depth about",
    "start": "2211220",
    "end": "2216560"
  },
  {
    "text": "Kinesis firehose because I think it's a really nice method for getting data into",
    "start": "2216560",
    "end": "2222800"
  },
  {
    "text": "elasticsearch firehose provides a delivery stream which is the underlying",
    "start": "2222800",
    "end": "2228670"
  },
  {
    "text": "mechanism it can send to s sorry s3",
    "start": "2228670",
    "end": "2233990"
  },
  {
    "text": "redshift and elastic search service and it provides a simple HTTP rest endpoint",
    "start": "2233990",
    "end": "2241580"
  },
  {
    "text": "where you simply push records into the stream to deliver it to your destination ship firehose has a number of features",
    "start": "2241580",
    "end": "2250790"
  },
  {
    "start": "2242000",
    "end": "2242000"
  },
  {
    "text": "that make it a really nice delivery architecture so we have our data sources they're pushing source records into the",
    "start": "2250790",
    "end": "2257359"
  },
  {
    "text": "delivery stream which by the way also can happen with the Kinesis agent that",
    "start": "2257359",
    "end": "2263900"
  },
  {
    "text": "can tail your log files and push those into into fire hose as well fire hose",
    "start": "2263900",
    "end": "2269570"
  },
  {
    "text": "then will call out to a lambda to allow you to transform that data while it's in",
    "start": "2269570",
    "end": "2275330"
  },
  {
    "text": "flight so fire hose delivers batches of data to lambda you can transform that data in",
    "start": "2275330",
    "end": "2280640"
  },
  {
    "text": "Landa and send it back to fire hose and fire hose will then deliver that data to elasticsearch service fire hose handles",
    "start": "2280640",
    "end": "2288950"
  },
  {
    "text": "failures and retries in a really elegant way as you're sending data in you can",
    "start": "2288950",
    "end": "2294530"
  },
  {
    "text": "set a buffer size so that your buffering your data and sending it in bulk to elasticsearch it deals with delivery",
    "start": "2294530",
    "end": "2302150"
  },
  {
    "text": "failures so if records are not delivered correctly they're pushed off to s3 it",
    "start": "2302150",
    "end": "2308420"
  },
  {
    "text": "deals with retry so you can set a window that says retry my we try my batches for",
    "start": "2308420",
    "end": "2315050"
  },
  {
    "text": "up to this amount of time and you don't have to worry about writing that at lambda or dead letter queues or anything",
    "start": "2315050",
    "end": "2321290"
  },
  {
    "text": "else fire hose does all of that for you in addition fire hose can send all of your source records to s3 so this is a",
    "start": "2321290",
    "end": "2328790"
  },
  {
    "text": "nice way to maintain a backup set of your log data in s3 and also send that",
    "start": "2328790",
    "end": "2335420"
  },
  {
    "start": "2333000",
    "end": "2333000"
  },
  {
    "text": "data simultaneously to elasticsearch and",
    "start": "2335420",
    "end": "2340490"
  },
  {
    "text": "just to make the point what are you doing in terms of the transformation elasticsearch works with structure Jason",
    "start": "2340490",
    "end": "2346910"
  },
  {
    "text": "so what you send into elasticsearch is not what we have at the top here which",
    "start": "2346910",
    "end": "2352940"
  },
  {
    "text": "is the original apache web log line in fact you have to transform that into",
    "start": "2352940",
    "end": "2358700"
  },
  {
    "text": "Jason as below here so I have the verb the ident abides timestamp requests etc",
    "start": "2358700",
    "end": "2365319"
  },
  {
    "text": "all of that is filled and value pairs those fields provide the bassists for",
    "start": "2365319",
    "end": "2372500"
  },
  {
    "text": "elastic search to search with and also these are the things that you can visualize with Cabana",
    "start": "2372500",
    "end": "2377839"
  },
  {
    "text": "so documents again contain these field value pairs fields can be nested so you",
    "start": "2377839",
    "end": "2384619"
  },
  {
    "text": "can have a field within a field and elastic search natively handles that nested Jason providing you dot path",
    "start": "2384619",
    "end": "2392270"
  },
  {
    "text": "access to the eventual values there are all kinds of different value types",
    "start": "2392270",
    "end": "2397869"
  },
  {
    "text": "including text dates geo objects and more values can be single or arrays so",
    "start": "2397869",
    "end": "2406520"
  },
  {
    "text": "you can send in a single value as I'm doing or I can send it an area values if I",
    "start": "2406520",
    "end": "2412120"
  },
  {
    "text": "have multiples for a particular field elasticsearch again should receive Jason",
    "start": "2412120",
    "end": "2421080"
  },
  {
    "start": "2421000",
    "end": "2421000"
  },
  {
    "text": "within fire hose we do provide lambda blueprints for some common use cases so in particular if",
    "start": "2421680",
    "end": "2428950"
  },
  {
    "text": "you're sending Apache web logs to elasticsearch service if you send them via fire hose we have an Apache log -",
    "start": "2428950",
    "end": "2436630"
  },
  {
    "text": "Jason transform you can simply click and use that one within fire hose to",
    "start": "2436630",
    "end": "2441910"
  },
  {
    "text": "automatically transform your data into that Jason we also have a syslog to JSON format that works with elasticsearch",
    "start": "2441910",
    "end": "2449290"
  },
  {
    "start": "2445000",
    "end": "2445000"
  },
  {
    "text": "service so again some of the features that fire hose has that make it great",
    "start": "2449290",
    "end": "2456460"
  },
  {
    "text": "for ingest serverless Gale didn't mention it but you know with Kinesis you",
    "start": "2456460",
    "end": "2462640"
  },
  {
    "text": "know it's serverless it scales automatically and it provides you with almost limitless capacity to scale out",
    "start": "2462640",
    "end": "2469980"
  },
  {
    "text": "the error handling is great the retries the buffering windows and then the s3",
    "start": "2469980",
    "end": "2477280"
  },
  {
    "text": "bucket where your failures land up provide you a means of going back and looking at that that data that failed",
    "start": "2477280",
    "end": "2484090"
  },
  {
    "start": "2479000",
    "end": "2479000"
  },
  {
    "text": "and retrying it we didn't cover any of these best practices I'm going to skip",
    "start": "2484090",
    "end": "2489850"
  },
  {
    "text": "over these actually I'll just say a couple of things with fire hose again",
    "start": "2489850",
    "end": "2496390"
  },
  {
    "text": "you set a buffer and that's based on the amount of time you want to wait and also",
    "start": "2496390",
    "end": "2502450"
  },
  {
    "text": "the size of data that's going through so use smaller buffer sizes to increase",
    "start": "2502450",
    "end": "2508570"
  },
  {
    "text": "your throughput and decrease your latency to searchability but you have to",
    "start": "2508570",
    "end": "2513760"
  },
  {
    "text": "be a little bit careful that you don't overwhelm your Klepfer your cluster with too many right requests firehose does",
    "start": "2513760",
    "end": "2523750"
  },
  {
    "text": "Allah does rotate your index for you you can choose daily weekly monthly or",
    "start": "2523750",
    "end": "2531010"
  },
  {
    "text": "hourly and daily is correct for most use cases out to about a terabyte hourly",
    "start": "2531010",
    "end": "2537700"
  },
  {
    "text": "would be multiple terabytes per day and larger than that weekly",
    "start": "2537700",
    "end": "2543340"
  },
  {
    "text": "monthly you could use for you know 250 gigabytes 200 gigabytes to one terabyte",
    "start": "2543340",
    "end": "2549550"
  },
  {
    "text": "over that time period so I'm going to",
    "start": "2549550",
    "end": "2554920"
  },
  {
    "text": "talk a little bit about Cabana and what Cabana does and how elasticsearch supports log analysis and the feature",
    "start": "2554920",
    "end": "2563890"
  },
  {
    "text": "that elasticsearch has is called aggregations so if we look at an",
    "start": "2563890",
    "end": "2569230"
  },
  {
    "text": "aggregation what an aggregation does is it takes the values for a particular field and splits them into buckets and",
    "start": "2569230",
    "end": "2577120"
  },
  {
    "text": "then counts or does other math on the contents of those buckets so here's an",
    "start": "2577120",
    "end": "2583450"
  },
  {
    "text": "example if I have an Apache web log and I want to look at all the traffic from a particular host with some and figure out",
    "start": "2583450",
    "end": "2590410"
  },
  {
    "text": "what are the verbs that that HTTP verbs that that host is sending I lookup",
    "start": "2590410",
    "end": "2595980"
  },
  {
    "text": "elasticsearch looks up in its index that host name it finds there the list of all",
    "start": "2595980",
    "end": "2601870"
  },
  {
    "text": "of the documents that contained that host name in other words this is a straight-up list of all of the weblog",
    "start": "2601870",
    "end": "2608890"
  },
  {
    "text": "lines that came from that host it then looks at the verb field and gets the",
    "start": "2608890",
    "end": "2614410"
  },
  {
    "text": "data that is attached to each of those documents in this case we have a couple of gets opposed to another CAD put et",
    "start": "2614410",
    "end": "2621220"
  },
  {
    "text": "cetera it creates buckets out of the different values of that field data and then it",
    "start": "2621220",
    "end": "2626710"
  },
  {
    "start": "2626000",
    "end": "2626000"
  },
  {
    "text": "simply counts how many times did each of those values occur so aggregation is",
    "start": "2626710",
    "end": "2633790"
  },
  {
    "text": "then generalize this concept of buckets and metrics so a bucket is some",
    "start": "2633790",
    "end": "2639370"
  },
  {
    "text": "collection of documents meeting some criterion and a metric is a calculation on the contents of that bucket so in",
    "start": "2639370",
    "end": "2646330"
  },
  {
    "text": "particular a very common aggregation is to go across the x-axis and bucket by",
    "start": "2646330",
    "end": "2652570"
  },
  {
    "text": "time and then count how many objects fell within that time window this is a",
    "start": "2652570",
    "end": "2658690"
  },
  {
    "text": "graph for instance of all of the traffic in to my website so I can take all of my",
    "start": "2658690",
    "end": "2664720"
  },
  {
    "text": "web log lines I can put them into buckets based on their timestamp and then I can count how many objects fall",
    "start": "2664720",
    "end": "2670630"
  },
  {
    "start": "2670000",
    "end": "2670000"
  },
  {
    "text": "into each of those buckets to provide me a histogram of the traffic over time but",
    "start": "2670630",
    "end": "2676990"
  },
  {
    "text": "aggregation is get much more complicated than that I can take buckets and sub bucket so this is a pie chart of some of",
    "start": "2676990",
    "end": "2686350"
  },
  {
    "text": "my cloud trail logs I'm looking at the AR n of the of the sender of those",
    "start": "2686350",
    "end": "2695170"
  },
  {
    "text": "requests and then I'm bucketing within that by the region that that request was issued in and then I'm further bucketing",
    "start": "2695170",
    "end": "2702340"
  },
  {
    "text": "by the event name or what was what was called and then I'm counting so I can see I have a major major caller over",
    "start": "2702340",
    "end": "2711520"
  },
  {
    "text": "here I have a smaller caller my regions breakdown etc I can use this to track what's happening in real time some of",
    "start": "2711520",
    "end": "2721150"
  },
  {
    "start": "2715000",
    "end": "2715000"
  },
  {
    "text": "the other things that you can do with gabbana we have metrics that again allow",
    "start": "2721150",
    "end": "2726700"
  },
  {
    "text": "me to just count things so here's for web log lines this is the total events",
    "start": "2726700",
    "end": "2731890"
  },
  {
    "text": "in the time period I'm looking at this is the requests I've said I've received this is the different host that unique",
    "start": "2731890",
    "end": "2738760"
  },
  {
    "start": "2735000",
    "end": "2735000"
  },
  {
    "text": "no hosts that have sent me those requests I can have line charts this is",
    "start": "2738760",
    "end": "2744340"
  },
  {
    "text": "a line chart that's graphing the size of the data that I'm sending out so I'm pocketing again by time on the bottom",
    "start": "2744340",
    "end": "2751270"
  },
  {
    "text": "and then at the top I'm looking at how much data is flowing out of my website I",
    "start": "2751270",
    "end": "2756930"
  },
  {
    "text": "can break it out in more complicated ways by looking at different hosts and",
    "start": "2756930",
    "end": "2762340"
  },
  {
    "text": "how how many requests those are sending I can again get a pie chart again this",
    "start": "2762340",
    "end": "2768070"
  },
  {
    "start": "2767000",
    "end": "2767000"
  },
  {
    "text": "is host and request and I can even have a heat map that lets me find hot spots",
    "start": "2768070",
    "end": "2774369"
  },
  {
    "text": "in my requests data this is again looking at the URLs that I'm receiving",
    "start": "2774369",
    "end": "2779890"
  },
  {
    "text": "for my weblog and finding where I have the hot spots during different times of",
    "start": "2779890",
    "end": "2785230"
  },
  {
    "start": "2782000",
    "end": "2782000"
  },
  {
    "text": "day or different days and then finally I can visualize some stacked bars if I",
    "start": "2785230",
    "end": "2792520"
  },
  {
    "text": "want to look at you know totals and the breakdown of items within the totals so",
    "start": "2792520",
    "end": "2798760"
  },
  {
    "text": "the that takeaways in terms of kibana are that elasticsearch itself works on",
    "start": "2798760",
    "end": "2805859"
  },
  {
    "text": "statistical data looking at counts and psalms and mins and averages across buckets that are defined",
    "start": "2805859",
    "end": "2815440"
  },
  {
    "text": "by a query the visualizations themselves are buckets and metrics and frequently",
    "start": "2815440",
    "end": "2822550"
  },
  {
    "text": "you want to use a histogram of time on the x-axis and then sub aggregate to get",
    "start": "2822550",
    "end": "2828580"
  },
  {
    "text": "your y-axis so in summary elastic search",
    "start": "2828580",
    "end": "2834820"
  },
  {
    "text": "service provides you an easy way to run elastic search in the AWS cloud firehose",
    "start": "2834820",
    "end": "2840070"
  },
  {
    "text": "is a great tool for ingesting data and with Cabana you can you can real-time in",
    "start": "2840070",
    "end": "2846040"
  },
  {
    "text": "you can monitor your infrastructure in real time dig in and find problems and",
    "start": "2846040",
    "end": "2851860"
  },
  {
    "text": "make sure everything's running well so thank you very much I am going to switch over to the",
    "start": "2851860",
    "end": "2859120"
  },
  {
    "text": "questions now okay so one question is",
    "start": "2859120",
    "end": "2875050"
  },
  {
    "text": "elastic search only for searching log files so as we talked about there are two main use cases for elastic search",
    "start": "2875050",
    "end": "2881920"
  },
  {
    "text": "service the first of those is logs but also streaming data web application data",
    "start": "2881920",
    "end": "2888460"
  },
  {
    "text": "as we heard about with McGraw Hill etc the second use case is full text use",
    "start": "2888460",
    "end": "2894760"
  },
  {
    "text": "case we do see a number of different customers who are using elastic search service to support their web",
    "start": "2894760",
    "end": "2900790"
  },
  {
    "text": "applications for things like e-commerce and application search across whatever",
    "start": "2900790",
    "end": "2906790"
  },
  {
    "text": "the data the application is providing as well",
    "start": "2906790",
    "end": "2912840"
  },
  {
    "text": "so here a long age question we're using a spring",
    "start": "2926090",
    "end": "2933810"
  },
  {
    "text": "boot java application and essentially the log lines in our the the Java errors",
    "start": "2933810",
    "end": "2940140"
  },
  {
    "text": "are multi-line and so how should we handle that there are a couple of different ways if you happen to be using",
    "start": "2940140",
    "end": "2947100"
  },
  {
    "text": "log stash log stash does have a way of condensing multiple lines into a single",
    "start": "2947100",
    "end": "2952500"
  },
  {
    "text": "line I don't remember the syntax off the top of my head but one of the filters",
    "start": "2952500",
    "end": "2957690"
  },
  {
    "text": "does allow you to to condense multiple",
    "start": "2957690",
    "end": "2963180"
  },
  {
    "text": "lines into single lines if you're not using log stash if you're using something like firehose or otherwise",
    "start": "2963180",
    "end": "2969300"
  },
  {
    "text": "using lamda that's the place where you really have to do that data transformation to take those multiple",
    "start": "2969300",
    "end": "2975930"
  },
  {
    "text": "lines and condense them into a single line so that they go into elasticsearch as a single document an alternate that",
    "start": "2975930",
    "end": "2982920"
  },
  {
    "text": "you could do is you could send them as a multivalued field so that each line was",
    "start": "2982920",
    "end": "2988410"
  },
  {
    "text": "part of a message field or you know some multi-line field that you were using to",
    "start": "2988410",
    "end": "2994770"
  },
  {
    "text": "search with an elastic search so here's",
    "start": "2994770",
    "end": "3007640"
  },
  {
    "text": "a question it's the difference between cloud trail and elasticsearch service cloud trail is",
    "start": "3007640",
    "end": "3014160"
  },
  {
    "text": "a service that receives logs from other AWS services so when I interact with the",
    "start": "3014160",
    "end": "3021270"
  },
  {
    "text": "ec2 console or the s3 console or I send I sent data or I create a Kinesis stream",
    "start": "3021270",
    "end": "3028760"
  },
  {
    "text": "those AWS services ec2 s3 Kinesis send",
    "start": "3028760",
    "end": "3034290"
  },
  {
    "text": "logs to cloud trail cloud trail provides you some basic capabilities to search",
    "start": "3034290",
    "end": "3040530"
  },
  {
    "text": "and display your log lines similarly cloud watch logs does provide you with some basic capabilities for",
    "start": "3040530",
    "end": "3047460"
  },
  {
    "text": "searching and displaying your log lines the difference is that elastic search",
    "start": "3047460",
    "end": "3052950"
  },
  {
    "text": "service number one is real-time so with elastic search service I'm setting my logs in in real time and I'm able to",
    "start": "3052950",
    "end": "3061110"
  },
  {
    "text": "visualize in real time what's happening right now and the second of all elastic",
    "start": "3061110",
    "end": "3067080"
  },
  {
    "text": "search has a much broader capability to provide you with the ability to search your data so Cloud trail Cloud watch",
    "start": "3067080",
    "end": "3075450"
  },
  {
    "text": "logs they're not they're not fundamentally search engines search engines are good at natural language",
    "start": "3075450",
    "end": "3081450"
  },
  {
    "text": "they know how to decompose and make things searchable easily",
    "start": "3081450",
    "end": "3087560"
  },
  {
    "text": "okay is it compulsory to use lambda to push data from cloud watch to",
    "start": "3097800",
    "end": "3103359"
  },
  {
    "text": "elasticsearch can't we directly send data from cloud watched elasticsearch cloud watch provides the integration via",
    "start": "3103359",
    "end": "3113410"
  },
  {
    "text": "lambda and other than triggering off a",
    "start": "3113410",
    "end": "3118839"
  },
  {
    "text": "cloud watch event there's really no way to send data directly from cloud watch",
    "start": "3118839",
    "end": "3124780"
  },
  {
    "text": "to elastics or service without having lambda involved in some way shape or form you could use lambda to send to",
    "start": "3124780",
    "end": "3131859"
  },
  {
    "text": "Kinesis Kinesis streams or Kinesis firehose from out of cloud watch but",
    "start": "3131859",
    "end": "3138300"
  },
  {
    "text": "there's no direct way to get that data across",
    "start": "3138300",
    "end": "3143700"
  },
  {
    "text": "so rolling down the questions here I'm trying to get to them all so",
    "start": "3154380",
    "end": "3167869"
  },
  {
    "text": "can it handle logs from mainframe systems as well do you have any examples I don't have any examples of mainframe",
    "start": "3167869",
    "end": "3175730"
  },
  {
    "text": "systems sending logs and the creel",
    "start": "3175730",
    "end": "3181609"
  },
  {
    "text": "question to me would be how to get those logs off of that mainframe if if you're",
    "start": "3181609",
    "end": "3187190"
  },
  {
    "text": "able to stream that data into the cloud in some way shape or form generally s3 I",
    "start": "3187190",
    "end": "3193549"
  },
  {
    "text": "would think would be the right destination and then using lambda to transfer from s3 potentially translate",
    "start": "3193549",
    "end": "3202220"
  },
  {
    "text": "in lambda and send off to elastic search service I think the real question is how",
    "start": "3202220",
    "end": "3208670"
  },
  {
    "text": "to get that data into AWS and I'm not sure of the answer it's obviously going",
    "start": "3208670",
    "end": "3214670"
  },
  {
    "text": "to depend on the mainframe and your means of connecting to AWS how can we",
    "start": "3214670",
    "end": "3222349"
  },
  {
    "text": "use media files with elasticsearch for streaming so elasticsearch well one",
    "start": "3222349",
    "end": "3229339"
  },
  {
    "text": "thing to say elastic search is not actually streaming any files so generally with media what we would see",
    "start": "3229339",
    "end": "3236509"
  },
  {
    "text": "is that elastic search would provide you with a catalogue of the media files that",
    "start": "3236509",
    "end": "3241730"
  },
  {
    "text": "you have and potentially you know if you're building an application that is taking media in and providing the",
    "start": "3241730",
    "end": "3249410"
  },
  {
    "text": "ability for customers to find that media and to watch it elastic search would play a role as the catalog that would",
    "start": "3249410",
    "end": "3256730"
  },
  {
    "text": "support customers searching the different media that you have for for",
    "start": "3256730",
    "end": "3262220"
  },
  {
    "text": "them to find and watch it so does",
    "start": "3262220",
    "end": "3273400"
  },
  {
    "text": "to provide cloud watch metrics and similar dashboards like Cabana",
    "start": "3273400",
    "end": "3278910"
  },
  {
    "text": "so elasticsearch does support you know getting metrics out of your log data",
    "start": "3278910",
    "end": "3287700"
  },
  {
    "text": "it's not so we do also provide metrics to cloud watch so your elastic search",
    "start": "3287700",
    "end": "3294280"
  },
  {
    "text": "service domain we publish about about 20 metrics that cover things like the JVM",
    "start": "3294280",
    "end": "3301540"
  },
  {
    "text": "memory pressure for your Java JVM the CPU utilization on your instances the",
    "start": "3301540",
    "end": "3309280"
  },
  {
    "text": "free storage space in your cluster we have a host of EBS metrics that we",
    "start": "3309280",
    "end": "3314380"
  },
  {
    "text": "publish around the read and write Layton sees cue depths other other things like",
    "start": "3314380",
    "end": "3320170"
  },
  {
    "text": "that so please explain what is full-text",
    "start": "3320170",
    "end": "3330760"
  },
  {
    "text": "search so full-text search is what what",
    "start": "3330760",
    "end": "3336730"
  },
  {
    "text": "an example of full-text search is Google so what Google does is Google goes and",
    "start": "3336730",
    "end": "3343120"
  },
  {
    "text": "it takes web pages and it indexes them in a search engine a web page is a",
    "start": "3343120",
    "end": "3349330"
  },
  {
    "text": "search document in Google and with Google you get a few you get a box where",
    "start": "3349330",
    "end": "3355480"
  },
  {
    "text": "you can type a few words then Google the search engine takes those words matches",
    "start": "3355480",
    "end": "3361690"
  },
  {
    "text": "them against text that it's found on the web pages to retrieve for you",
    "start": "3361690",
    "end": "3367540"
  },
  {
    "text": "matches for the text that you've typed now there's a language processing",
    "start": "3367540",
    "end": "3373780"
  },
  {
    "text": "component of that there's a search component of that Google you know is matching your words the words it finds",
    "start": "3373780",
    "end": "3380020"
  },
  {
    "text": "and there's a relevance component of that it doesn't retrieve everything for",
    "start": "3380020",
    "end": "3386020"
  },
  {
    "text": "you it retrieves the best matches for what you've typed and all of those are",
    "start": "3386020",
    "end": "3391090"
  },
  {
    "text": "sort of core components of what we think of as full-text search",
    "start": "3391090",
    "end": "3397380"
  },
  {
    "text": "is it like a bi tool yes it's like a bi tool but there's a there's a difference",
    "start": "3399470",
    "end": "3405890"
  },
  {
    "text": "in emphasis when I think about traditional bi it tends to be analytical and tends to",
    "start": "3405890",
    "end": "3412580"
  },
  {
    "text": "be sort of predictive and it tends to be over a longer time frame so a bi tool",
    "start": "3412580",
    "end": "3419720"
  },
  {
    "text": "should look at you know sales data and number one breakdown for me you know",
    "start": "3419720",
    "end": "3425840"
  },
  {
    "text": "which regions were selling the most widgets and which salespeople were selling the most widgets and what was my",
    "start": "3425840",
    "end": "3431720"
  },
  {
    "text": "revenue by region all of that stuff elasticsearch can do that portion but",
    "start": "3431720",
    "end": "3437000"
  },
  {
    "text": "then bi tools also frequently are predictive in that they say okay so if I add three more sales people to this",
    "start": "3437000",
    "end": "3443570"
  },
  {
    "text": "region how should my sales change right elasticsearch is much more real-time",
    "start": "3443570",
    "end": "3449450"
  },
  {
    "text": "focused with elasticsearch we're monitoring some set of infrastructure or hardware and we're looking to find",
    "start": "3449450",
    "end": "3456970"
  },
  {
    "text": "trends and patterns in the data as it's coming through in real time",
    "start": "3456970",
    "end": "3463570"
  },
  {
    "text": "so a lot of questions on sort of other technologies and how it compares how",
    "start": "3474260",
    "end": "3482010"
  },
  {
    "text": "does it compare to memcache just Splunk to Hadoop you know what I would say is",
    "start": "3482010",
    "end": "3487970"
  },
  {
    "text": "all right well let's start start with memcache so you know memcache as a",
    "start": "3487970",
    "end": "3493020"
  },
  {
    "text": "caching solution is essentially a storage solution we don't think of",
    "start": "3493020",
    "end": "3498059"
  },
  {
    "text": "elasticsearch or search engines typically as storage solutions it's really meant to be something that",
    "start": "3498059",
    "end": "3505050"
  },
  {
    "text": "provides you the ability to stream in data visualize that data and react to",
    "start": "3505050",
    "end": "3510089"
  },
  {
    "text": "what's going on in real time memcache is a little bit more permanent a little bit",
    "start": "3510089",
    "end": "3516059"
  },
  {
    "text": "more solid as a storage medium when we",
    "start": "3516059",
    "end": "3521609"
  },
  {
    "text": "think about Splunk Splunk is really a full-blown application that has not only",
    "start": "3521609",
    "end": "3528510"
  },
  {
    "text": "the ability to take in log data but also to view that log data in in you know a",
    "start": "3528510",
    "end": "3535440"
  },
  {
    "text": "fully built out way elasticsearch is more like a toolbox it allows you to",
    "start": "3535440",
    "end": "3540630"
  },
  {
    "text": "take in your data but you'll have to build some visualizations you'll have to put some work into it to get the",
    "start": "3540630",
    "end": "3546000"
  },
  {
    "text": "information out of those of course as a",
    "start": "3546000",
    "end": "3551430"
  },
  {
    "text": "toolkit it tends to be less expensive than Splunk so there's a kind of",
    "start": "3551430",
    "end": "3556559"
  },
  {
    "text": "breaking point where you say okay we're really getting the value for from Splunk for this set of use cases so we should",
    "start": "3556559",
    "end": "3563220"
  },
  {
    "text": "use spunk for that and these use cases we really don't have such a high need",
    "start": "3563220",
    "end": "3568230"
  },
  {
    "text": "for the analysis that we want to do we want to build something that's a less",
    "start": "3568230",
    "end": "3573240"
  },
  {
    "text": "costly and we'll give you essentially the same results but you'll have to put",
    "start": "3573240",
    "end": "3578880"
  },
  {
    "text": "a little bit more work into it how is it different from Hadoop Hadoop is a",
    "start": "3578880",
    "end": "3585329"
  },
  {
    "text": "general framework for performing distributed calculation elasticsearch is",
    "start": "3585329",
    "end": "3591000"
  },
  {
    "text": "a distributed framework but it only performs search engine calculation",
    "start": "3591000",
    "end": "3597890"
  },
  {
    "text": "sorry I'm still I'll take one last one and then then we will wrap up I don't",
    "start": "3609160",
    "end": "3622700"
  },
  {
    "text": "find the health of index or shards so I mentioned we do support a number of",
    "start": "3622700",
    "end": "3629210"
  },
  {
    "text": "different cloud watch metrics around your cluster most of those are again at",
    "start": "3629210",
    "end": "3635150"
  },
  {
    "text": "a full cluster level if you want to dig in to find out the health at an index or",
    "start": "3635150",
    "end": "3641150"
  },
  {
    "text": "a shard level we expose several api's from elasticsearch that allow you to do",
    "start": "3641150",
    "end": "3647480"
  },
  {
    "text": "this so in particular we have an API underscore cat CIT that provides you",
    "start": "3647480",
    "end": "3654530"
  },
  {
    "text": "information about indices so you can do underscore cat slash indices underscore",
    "start": "3654530",
    "end": "3660590"
  },
  {
    "text": "cat slash shards to get information on those in addition there's a number of",
    "start": "3660590",
    "end": "3666680"
  },
  {
    "text": "different stats api's so there's an underscore stats which gives you overall",
    "start": "3666680",
    "end": "3672470"
  },
  {
    "text": "index statistics there's a nodes stats that gives you individual node",
    "start": "3672470",
    "end": "3679990"
  },
  {
    "text": "statistics including operating system JVM all sorts of low level information",
    "start": "3679990",
    "end": "3685340"
  },
  {
    "text": "that you can pull out of the elasticsearch api's so I'm aware that we",
    "start": "3685340",
    "end": "3691640"
  },
  {
    "text": "are running out of time I want to thank you again for your time and attention and look forward to having you try out",
    "start": "3691640",
    "end": "3700130"
  },
  {
    "text": "the service",
    "start": "3700130",
    "end": "3702640"
  },
  {
    "text": "you",
    "start": "3720430",
    "end": "3722490"
  }
]
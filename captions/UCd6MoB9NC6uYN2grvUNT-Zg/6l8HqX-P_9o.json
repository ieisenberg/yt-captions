[
  {
    "text": "Welcome to 'Back to Basics.'",
    "start": "5224",
    "end": "6902"
  },
  {
    "text": "I'm Orit Alul and today we're going to talk about data.",
    "start": "6902",
    "end": "10426"
  },
  {
    "text": "The amount of data\ngenerated by IoT, smart devices,",
    "start": "10426",
    "end": "14209"
  },
  {
    "text": "cloud applications, and social\nis growing exponentially.",
    "start": "14209",
    "end": "17727"
  },
  {
    "text": "You need ways to easily and cost-effectively \nanalyze all of this data",
    "start": "17727",
    "end": "22041"
  },
  {
    "text": "within minimal time-to-insight, \nregardless of the data source.",
    "start": "22041",
    "end": "25829"
  },
  {
    "text": "Therefore, I'd like to talk to you about the basics of data lake \nand lake house patterns.",
    "start": "26527",
    "end": "31377"
  },
  {
    "text": "You're probably familiar with the data lake pattern,\nbut what is the lake house approach?",
    "start": "31377",
    "end": "36788"
  },
  {
    "text": "The lake house approach is about connecting your data lake, \nyour data warehouse,",
    "start": "36788",
    "end": "41239"
  },
  {
    "text": "and all your other purpose-built analytic services.",
    "start": "41240",
    "end": "45188"
  },
  {
    "text": "Let's start with the source of the data, \nthe data ingest.",
    "start": "46117",
    "end": "49583"
  },
  {
    "text": "Your data is valuable, \nand you'd like to put it in a persistent safe place,",
    "start": "49583",
    "end": "54918"
  },
  {
    "text": "such as Amazon S3, as quickly as possible\nand as simply as possible.",
    "start": "54918",
    "end": "60042"
  },
  {
    "text": "What you don't want to do,\nis you don't want your application to gather the data in files",
    "start": "61074",
    "end": "65976"
  },
  {
    "text": "and copy these files to S3.",
    "start": "65976",
    "end": "68263"
  },
  {
    "text": "This will require your application\nto buffer the data in memory or on a local disk,",
    "start": "68527",
    "end": "74106"
  },
  {
    "text": "which can result in failure and data loss.",
    "start": "74106",
    "end": "77361"
  },
  {
    "text": "Therefore, you should use a stream,\nsuch as Amazon Kinesis Data Firehose.",
    "start": "78378",
    "end": "83146"
  },
  {
    "text": "With Firehose,\nit is simple to reliably load your data into the data lake.",
    "start": "83147",
    "end": "88445"
  },
  {
    "text": "Your application can write the data it collects\nstraight to the stream,",
    "start": "88445",
    "end": "93048"
  },
  {
    "text": "and Firehose will deliver the data to S3 \nas quickly as you choose.",
    "start": "93049",
    "end": "97484"
  },
  {
    "text": "When you use a data streaming mechanism,",
    "start": "98617",
    "end": "100735"
  },
  {
    "text": "your application can write even small amount of data as it arrives,\ndirectly to the stream.",
    "start": "100735",
    "end": "106449"
  },
  {
    "text": "This will keep your application lean and simple.",
    "start": "106449",
    "end": "109230"
  },
  {
    "text": "You can configure Kinesis Data Firehose",
    "start": "110713",
    "end": "113200"
  },
  {
    "text": "to persist the data \naccording to a time interval between one to 15 minutes,",
    "start": "113200",
    "end": "117683"
  },
  {
    "text": "or as data is accumulated \nbetween one to 128 megabytes.",
    "start": "117683",
    "end": "122278"
  },
  {
    "text": "This is your raw data.",
    "start": "122714",
    "end": "125192"
  },
  {
    "text": "Now that you've ingested your data to S3, \nyou'll probably like to start querying the data.",
    "start": "126903",
    "end": "132072"
  },
  {
    "text": "But before doing that,",
    "start": "132072",
    "end": "133924"
  },
  {
    "text": "there are three things\nthat will make your reads or queries, more efficient;",
    "start": "133924",
    "end": "139303"
  },
  {
    "text": "the data format, partitioning, \nand the size of the files.",
    "start": "139721",
    "end": "144418"
  },
  {
    "text": "Now let's look at each one of these topics.",
    "start": "144419",
    "end": "147237"
  },
  {
    "text": "Let's start with the first, data format.",
    "start": "147796",
    "end": "150776"
  },
  {
    "text": "In most of the cases,\nyour application will write data in a textual format,",
    "start": "150776",
    "end": "156168"
  },
  {
    "text": "such as JSON.",
    "start": "156168",
    "end": "157520"
  },
  {
    "text": "This is a nice, human-readable format,",
    "start": "157520",
    "end": "159763"
  },
  {
    "text": "but it is wasteful \nin terms of data size and processing.",
    "start": "159763",
    "end": "164041"
  },
  {
    "text": "Since most of your reads\nare going to be analytical queries,",
    "start": "164041",
    "end": "167809"
  },
  {
    "text": "it can be beneficial \nto transform the data to a columnar format,",
    "start": "167809",
    "end": "172044"
  },
  {
    "text": "such as parquet, or ORC.",
    "start": "172044",
    "end": "175046"
  },
  {
    "text": "The columnar format \nenables better compression of the data,",
    "start": "176094",
    "end": "179398"
  },
  {
    "text": "and the ability to access only specific columns,",
    "start": "179398",
    "end": "182653"
  },
  {
    "text": "which reduces the amount of data scanned\nduring query time.",
    "start": "182654",
    "end": "186485"
  },
  {
    "text": "Let's talk about the second topic, \ndata partitioning.",
    "start": "186837",
    "end": "190226"
  },
  {
    "text": "Data partitioning is about the ability\nto search for the answer in the right place.",
    "start": "190226",
    "end": "194956"
  },
  {
    "text": "When you run a query, \nyou'd like to scan as little data as possible",
    "start": "195629",
    "end": "200027"
  },
  {
    "text": "in order to get results.",
    "start": "200027",
    "end": "201907"
  },
  {
    "text": "Data partitions will navigate the query engine\nto the right place or places",
    "start": "201908",
    "end": "207682"
  },
  {
    "text": "in which the data resides.",
    "start": "207682",
    "end": "209924"
  },
  {
    "text": "For example, if I'd like to run a query \non the last three days of data,",
    "start": "209924",
    "end": "215056"
  },
  {
    "text": "then if I partition the data in days,",
    "start": "215057",
    "end": "217713"
  },
  {
    "text": "I can scan only the data of the last three days.",
    "start": "217713",
    "end": "220948"
  },
  {
    "text": "But if I'll partition the data in months,",
    "start": "220948",
    "end": "223527"
  },
  {
    "text": "then I have to scan data of the entire month\nand filter only the relevant three days.",
    "start": "223527",
    "end": "228900"
  },
  {
    "text": "What if you have really fast velocity data \nand partition data in hours or minutes?",
    "start": "229656",
    "end": "234553"
  },
  {
    "text": "Would that be a good approach?\nProbably not.",
    "start": "234553",
    "end": "238220"
  },
  {
    "text": "Which leads me to the third point,\ndata compaction.",
    "start": "238220",
    "end": "242378"
  },
  {
    "text": "If you write data too frequent, \nor partition the data to small files,",
    "start": "243365",
    "end": "248406"
  },
  {
    "text": "you might end up with large number of small files.",
    "start": "248406",
    "end": "252203"
  },
  {
    "text": "Large number of small files\nwill also lead to inefficiency during query time ",
    "start": "252203",
    "end": "257221"
  },
  {
    "text": "due to overheads.",
    "start": "257222",
    "end": "259044"
  },
  {
    "text": "The general rule when using S3 as a storage layer",
    "start": "259045",
    "end": "263000"
  },
  {
    "text": "is to generate files\nin the size of 128 megabytes or larger.",
    "start": "263000",
    "end": "267779"
  },
  {
    "text": "As always, we have to consider trade-offs,",
    "start": "269092",
    "end": "271446"
  },
  {
    "text": "between partitioning the data \nand the file size within the partition.",
    "start": "271446",
    "end": "276236"
  },
  {
    "text": "You can use AWS Glue jobs\nto create scheduled jobs",
    "start": "277441",
    "end": "280221"
  },
  {
    "text": "that will transform the raw data \nto a columnar format,",
    "start": "280221",
    "end": "284469"
  },
  {
    "text": "compact the data to large files, \nand write the transform data to the relevant partition.",
    "start": "284469",
    "end": "289574"
  },
  {
    "text": "You can leverage Glue Studio\nto build this job in a visual way.",
    "start": "290382",
    "end": "295913"
  },
  {
    "text": "One more thing that we need to do, \nis we need to update the data lakes catalog",
    "start": "297476",
    "end": "302182"
  },
  {
    "text": "with a schema of the data and the partitions we created.",
    "start": "302182",
    "end": "305987"
  },
  {
    "text": "This is where AWS Glue Crawler comes in handy.",
    "start": "306714",
    "end": "311005"
  },
  {
    "text": "We can use the Crawler \nto populate the Glue Data Catalog automatically.",
    "start": "311642",
    "end": "316026"
  },
  {
    "text": "Now we are ready \nto start querying the data.",
    "start": "317177",
    "end": "319805"
  },
  {
    "text": "You can use Amazon Athena\nto run standard SQL ad hoc queries",
    "start": "319805",
    "end": "324586"
  },
  {
    "text": "straight on the data lake on S3.",
    "start": "324586",
    "end": "327036"
  },
  {
    "text": "Athena is serverless,\nso there is no infrastructure to set up or manage,",
    "start": "327036",
    "end": "332000"
  },
  {
    "text": "and you pay only for the queries you run,\nbased on the amount of data that was scanned.",
    "start": "332000",
    "end": "337402"
  },
  {
    "text": "Amazon Athena is really popular \nwith data engineers and developers",
    "start": "337402",
    "end": "341906"
  },
  {
    "text": "due to the ease of use and cost efficiency.",
    "start": "341906",
    "end": "345217"
  },
  {
    "text": "If you prefer to analyze your data \nin a more visual way, or produce reports,",
    "start": "346677",
    "end": "351676"
  },
  {
    "text": "you can leverage Amazon QuickSight.",
    "start": "351676",
    "end": "354111"
  },
  {
    "text": "Amazon QuickSight is integrated with many data sources, \nincluding Amazon Athena,",
    "start": "354111",
    "end": "359677"
  },
  {
    "text": "so you can analyze the data in your data lake,",
    "start": "359677",
    "end": "362610"
  },
  {
    "text": "and also join other data sources,",
    "start": "362610",
    "end": "364729"
  },
  {
    "text": "such as relational databases, \nAmazon Elasticsearch, Apache Spark, and more.",
    "start": "364730",
    "end": "370144"
  },
  {
    "text": "If you are a BI engineer,\nyou'd probably like to run some complex and sophisticated queries.",
    "start": "371191",
    "end": "376371"
  },
  {
    "text": "You'd probably like to use a data warehouse,\nsuch as Amazon Redshift,",
    "start": "376371",
    "end": "381435"
  },
  {
    "text": "to run your queries on large amount of data\nand get quick results.",
    "start": "381435",
    "end": "386296"
  },
  {
    "text": "Amazon Redshift is a fully managed,\npetabyte scale data warehouse service.",
    "start": "386296",
    "end": "392060"
  },
  {
    "text": "This leads me to talk about the lake house approach.",
    "start": "392060",
    "end": "395319"
  },
  {
    "text": "The lake house approach \ncombines the things that we discussed so far.",
    "start": "395319",
    "end": "399766"
  },
  {
    "text": "The data lake allows you to have a single place",
    "start": "399766",
    "end": "403250"
  },
  {
    "text": "where you can run analytics \nacross most of your data.",
    "start": "403251",
    "end": "406656"
  },
  {
    "text": "While the purpose build analytics services",
    "start": "406656",
    "end": "408803"
  },
  {
    "text": "provide you the speed you need \nfor specific use cases",
    "start": "408803",
    "end": "411836"
  },
  {
    "text": "like real time dashboards and log analytics.",
    "start": "411836",
    "end": "414707"
  },
  {
    "text": "The lake house architecture \nenables you to use the right tool for the right job.",
    "start": "415415",
    "end": "420785"
  },
  {
    "text": "You get the flexibility to evolve your lake house\nto meet current and future needs",
    "start": "420785",
    "end": "426216"
  },
  {
    "text": "as you add new data sources,\ndiscover new use cases,",
    "start": "426216",
    "end": "429769"
  },
  {
    "text": "and develop newer analytics methods.",
    "start": "429769",
    "end": "432542"
  },
  {
    "text": "Check out the resources below for more details,\nand see you next time.",
    "start": "433512",
    "end": "438403"
  }
]
[
  {
    "start": "0",
    "end": "102000"
  },
  {
    "text": "- Hello everyone. My name Arabinda Pani and I'm a Principal Database\nSpecialist Solution Architect",
    "start": "810",
    "end": "6450"
  },
  {
    "text": "here at AWS. In this demo, we'll\ntake a top down approach and drill down on some of\nthe Aurora cost components",
    "start": "6450",
    "end": "13780"
  },
  {
    "text": "starting from AWS monthly\nbilling statements and using various AWS\nservices and features",
    "start": "13780",
    "end": "20250"
  },
  {
    "text": "like AWS Cost Explorer,\nAWS Cost and Usage Reports, Amazon Athena, Amazon CloudWatch",
    "start": "20250",
    "end": "27330"
  },
  {
    "text": "and RDS performance insights\nto find which Aurora clusters or queries running in a particular cluster",
    "start": "27330",
    "end": "34329"
  },
  {
    "text": "might be contributing to\nyour overall Aurora spend. Typically, we will take this approach",
    "start": "34330",
    "end": "39360"
  },
  {
    "text": "while doing investigation to understand and manage your Aurora cost over time.",
    "start": "39360",
    "end": "44900"
  },
  {
    "text": "So let's dive in. The agenda for today's session\nis we will briefly go through",
    "start": "44900",
    "end": "51850"
  },
  {
    "text": "the various Aurora cost components. Then we will specifically\nreview how Aurora I/O cost",
    "start": "51850",
    "end": "57980"
  },
  {
    "text": "is calculated and how to monitor it. After that, we will spend most of the time",
    "start": "57980",
    "end": "63790"
  },
  {
    "text": "going to the demo. And finally, we will discuss\nsome of the best practices to optimize Aurora I/O cost.",
    "start": "63790",
    "end": "70740"
  },
  {
    "text": "So let's get started. Amazon Aurora is a database we built ground up for the cloud.",
    "start": "70740",
    "end": "76130"
  },
  {
    "text": "It offers the speed and\navailability of commercial databases with the simplicity and cost effectiveness",
    "start": "76130",
    "end": "82140"
  },
  {
    "text": "of open source databases. Aurora is offered as a managed service and it's drop-in compatible\nwith MySQL and PostgreSQL.",
    "start": "82140",
    "end": "89043"
  },
  {
    "text": "This means the code you wrote for either of these database engines will continue to work with Aurora.",
    "start": "89890",
    "end": "96310"
  },
  {
    "text": "There is no licensing costs\nto worry about with Aurora and it's offered with a simple\npay-as-you-go pricing model.",
    "start": "96310",
    "end": "103149"
  },
  {
    "start": "102000",
    "end": "159000"
  },
  {
    "text": "Okay, now let's quickly take a look at different Aurora cost components. For every Aurora cluster,\ncompute, storage and I/O costs",
    "start": "103150",
    "end": "111479"
  },
  {
    "text": "are charged. Typically, Aurora compute and storage are the primary drivers of cost.",
    "start": "111480",
    "end": "116829"
  },
  {
    "text": "You don't pre-provision\nstorage and IOPS in Aurora. Aurora offers an elastic storage volume",
    "start": "116830",
    "end": "122740"
  },
  {
    "text": "which automatically\ngrows based on your usage and shrinks when you remove\nlarge chunks of data.",
    "start": "122740",
    "end": "128390"
  },
  {
    "text": "Additionally, there is a\nseparate cost for backups and data transfers based on your usage",
    "start": "128390",
    "end": "134159"
  },
  {
    "text": "but backup storage is only\ncharged beyond the free limit which is equal to the size of\nyour Aurora storage volume.",
    "start": "134160",
    "end": "141240"
  },
  {
    "text": "Finally, you have the ability to use all the innovative features\nthat Amazon Aurora offers",
    "start": "141240",
    "end": "146920"
  },
  {
    "text": "out of the box. You don't pay anything\nto turn on a feature. You are just charged for\nadditional resource consumption",
    "start": "146920",
    "end": "153290"
  },
  {
    "text": "and usage of other AWS services for example storage, I/O\nand data transfer cost.",
    "start": "153290",
    "end": "159340"
  },
  {
    "start": "159000",
    "end": "353000"
  },
  {
    "text": "Let's jump to Aurora I/O cost next and understand how it works. In a relational database engine,",
    "start": "159340",
    "end": "165740"
  },
  {
    "text": "the minimum unit for read operation is a database block or page even if you want to read a single row.",
    "start": "165740",
    "end": "172080"
  },
  {
    "text": "When you run a select query, the engine first attempts\nto fulfill the query using pages already in\nthe buffer pool or cache.",
    "start": "172080",
    "end": "180489"
  },
  {
    "text": "In this case, there is no read I/O cost. But if a database page\nrequested by a query",
    "start": "180490",
    "end": "186910"
  },
  {
    "text": "doesn't exist in the buffer cache, the DP engine reads it from\nthe storage to the buffer cache",
    "start": "186910",
    "end": "193160"
  },
  {
    "text": "before returning the\nresults back to the client. This is when you incur\nRead I/O cost in Aurora",
    "start": "193160",
    "end": "198970"
  },
  {
    "text": "and each page read from the storage volume is counted as one read I/O. Both explicit and implicit read operations",
    "start": "198970",
    "end": "205880"
  },
  {
    "text": "from the storage are charged. Example of an implicit read operation is when a query reads an index on a table",
    "start": "205880",
    "end": "212620"
  },
  {
    "text": "to fetch the actual data pages or when you create an index on a table and it implicitly scans the entire table.",
    "start": "212620",
    "end": "220200"
  },
  {
    "text": "The amount of Aurora Read\nI/Os depend on several factors such as the DB Cache size",
    "start": "220200",
    "end": "226220"
  },
  {
    "text": "which is set based on the memory located to a database instance. The larger the DB Cache,",
    "start": "226220",
    "end": "231850"
  },
  {
    "text": "the higher is the possibility\nthat the data and index pages which a query needs to access",
    "start": "231850",
    "end": "237110"
  },
  {
    "text": "will be found and served from the DB Cache resulting in less number\nof Aurora Read I/Os.",
    "start": "237110",
    "end": "243161"
  },
  {
    "text": "Read I/O is also driven\nby data access pattern. That is accessing data with or\nwithout indexes for example.",
    "start": "243161",
    "end": "250130"
  },
  {
    "text": "An unoptimized SQL query\ncan incur higher I/Os as compared to an optimized query",
    "start": "250130",
    "end": "256650"
  },
  {
    "text": "because it needs to scan a lot of pages to get to the final query result. Typically, this is the most common cause",
    "start": "256650",
    "end": "263010"
  },
  {
    "text": "for higher Aurora I/Os. Finally, where rows are stored physically also impacts Aurora Read I/Os.",
    "start": "263010",
    "end": "270450"
  },
  {
    "text": "For example, if a select\nquery needs to fetch five rows from the Aurora storage, these rows can be in one database block",
    "start": "270450",
    "end": "277640"
  },
  {
    "text": "or scattered around multiple blocks. The latter could increase the\nnumber of Aurora Read I/Os.",
    "start": "277640",
    "end": "283710"
  },
  {
    "text": "Next, let's see how Write\nI/Os are charged in Aurora. For starters, Aurora\ndoesn't write database pages",
    "start": "283710",
    "end": "290610"
  },
  {
    "text": "to the storage. It only writes log records\nand to six different copies across three availability zones.",
    "start": "290610",
    "end": "297030"
  },
  {
    "text": "The database pages are\nmaterialized in the storage. Aurora also asynchronously\nreplicates the log records",
    "start": "297030",
    "end": "304070"
  },
  {
    "text": "to all the replicas set up in the cluster to keep their cache\ndatabase pages up-to-date.",
    "start": "304070",
    "end": "309940"
  },
  {
    "text": "We don't charge any Write\nI/Os for sending log records to the replicas in the\nsame Aurora cluster.",
    "start": "309940",
    "end": "315870"
  },
  {
    "text": "Although we are writing\nto six different copies in the storage, we charge only for one write operation.",
    "start": "315870",
    "end": "322550"
  },
  {
    "text": "Both explicit and\nimplicit write operations to the Aurora storage are charged. Example of an implicit write operation is",
    "start": "322550",
    "end": "330050"
  },
  {
    "text": "when you insert data to\na table with indexes, then the index pages are also updated.",
    "start": "330050",
    "end": "335720"
  },
  {
    "text": "Or for example, when PostgreSQL's\nauto vacuum process runs, it implicitly reads pages to be vacuumed",
    "start": "335720",
    "end": "342889"
  },
  {
    "text": "from the Aurora storage which are not already in the buffer cache. And then it needs to write\nlog records for the update",
    "start": "342890",
    "end": "350180"
  },
  {
    "text": "to those pages back to the storage. Next, let's see how you can monitor",
    "start": "350180",
    "end": "355540"
  },
  {
    "start": "353000",
    "end": "444000"
  },
  {
    "text": "Aurora read and write I/Os. As we discussed, Aurora\nRead I/O is charged",
    "start": "355540",
    "end": "360860"
  },
  {
    "text": "based on the number of\nphysical page routes from the a storage. Read I/O is charged based\non one million requests.",
    "start": "360860",
    "end": "367910"
  },
  {
    "text": "For example, in U.S. East I region, the cost is 20 cents per\none million read operations.",
    "start": "367910",
    "end": "374180"
  },
  {
    "text": "To monitor the Read I/Os, you can use the CloudWatch metrics called Build Volume Read I/Os.",
    "start": "374180",
    "end": "380300"
  },
  {
    "text": "Build read operations are calculated at the cluster volume level by aggregating Read\nI/Os from all instances",
    "start": "380300",
    "end": "387650"
  },
  {
    "text": "in the Aurora DB cluster\nover a five minute period and then reported at\nfive minute intervals.",
    "start": "387650",
    "end": "393560"
  },
  {
    "text": "So to determine the amount\nof build read operations per second, divide the value of the volume\nRead IOPS CloudWatch metric",
    "start": "393560",
    "end": "401360"
  },
  {
    "text": "by 300 seconds. Aurora Write I/Os are\ncounted in four KB units.",
    "start": "401360",
    "end": "406380"
  },
  {
    "text": "For example, a log\nrecord that is 1024 bytes will count as one Write I/O operation.",
    "start": "406380",
    "end": "413000"
  },
  {
    "text": "However, if the log record\nis larger than four KB, more than Write I/O operation\nwill be needed to persist it.",
    "start": "413000",
    "end": "420870"
  },
  {
    "text": "To optimize I/O consumption, concurrent write operations whose log records are less than four KB",
    "start": "420870",
    "end": "427010"
  },
  {
    "text": "maybe batched together by\nthe Aurora database engine if they are persisted on the\nsame storage protection groups.",
    "start": "427010",
    "end": "433509"
  },
  {
    "text": "Similar to Read I/O, Write I/O it charged per one million request. To monitor Write I/O,",
    "start": "433510",
    "end": "440130"
  },
  {
    "text": "you can use the CloudWatch metrics called Build Volume Write IOPS. With that, let's jump to the demo.",
    "start": "440130",
    "end": "446873"
  },
  {
    "start": "447000",
    "end": "496000"
  },
  {
    "text": "All right, so the first\nplace you will go to see your AWS monthly spend is the AWS billing dashboard.",
    "start": "448050",
    "end": "455250"
  },
  {
    "text": "So let's search for billing and head to the billing dashboard.",
    "start": "455250",
    "end": "459653"
  },
  {
    "text": "Next, let's click the bills\nto see our AWS monthly spend.",
    "start": "461500",
    "end": "466500"
  },
  {
    "text": "As you can see, I'm spending the most for\nrelational database service in USA's North Virginia.",
    "start": "466820",
    "end": "473950"
  },
  {
    "text": "So let's drill down further and see the various cost components related to RDS and Aurora.",
    "start": "473950",
    "end": "480010"
  },
  {
    "text": "The Aurora storage and I/O\ncost are grouped together and shown here. Similarly, the backup\ncost for Aurora MySQL",
    "start": "480010",
    "end": "487860"
  },
  {
    "text": "is grouped together and\nshown in this line item here. And there is a separate line item",
    "start": "487860",
    "end": "493420"
  },
  {
    "text": "for Aurora PostgreSQL backup cost. So next, if you want to find\nout which Aurora cluster",
    "start": "493420",
    "end": "500669"
  },
  {
    "start": "496000",
    "end": "610000"
  },
  {
    "text": "is contributing to the highest cost, we'll have to go to AWS\nCost Exploder for that.",
    "start": "500670",
    "end": "506043"
  },
  {
    "text": "So let's search AWS Cost Explorer",
    "start": "507070",
    "end": "510120"
  },
  {
    "text": "and go to the console. Select Cost Explorer from\nthe left navigation bar.",
    "start": "512120",
    "end": "520060"
  },
  {
    "text": "AWS Cost Explorer helps\nus to monitor, understand and manage our AWS cost.",
    "start": "520060",
    "end": "527510"
  },
  {
    "text": "This is where you can slice and dice the various AWS cost components. So as you can see,",
    "start": "527510",
    "end": "533940"
  },
  {
    "text": "I'm spending the most for\nrelational database service for the last six months. Next, let's see which\nspecific cost components",
    "start": "533940",
    "end": "542500"
  },
  {
    "text": "within relational database\nservice I'm spending the most. So for that, I will select\nrelational database service",
    "start": "542500",
    "end": "549570"
  },
  {
    "text": "in the filter here. Next, let's remove the forecast",
    "start": "549570",
    "end": "556000"
  },
  {
    "text": "and let's focus our effort\nfor the current month. So select current month from\nthe filter here and hit Apply.",
    "start": "556970",
    "end": "564140"
  },
  {
    "text": "Let's group the cost by each day and let's group the cost\nagain by usage type.",
    "start": "564140",
    "end": "570883"
  },
  {
    "text": "Select bar chart here. So this view is showing me the cost for relational database service",
    "start": "571890",
    "end": "578780"
  },
  {
    "text": "for the current month for\nthe various usage types. As we can see, the instance cost",
    "start": "578780",
    "end": "584930"
  },
  {
    "text": "was contributing to the\nhighest for last several days. But recently, the Aurora I/O",
    "start": "584930",
    "end": "590540"
  },
  {
    "text": "is contributing to the highest\ncost as we can see here. Next, let's drill down\non the Aurora I/O cost.",
    "start": "590540",
    "end": "598300"
  },
  {
    "text": "So for that, we will\nadd Aurora storage I/O to the filter here",
    "start": "598300",
    "end": "602230"
  },
  {
    "text": "and let's select this\nparticular line item. The next step is to find\nout which Aurora cluster",
    "start": "605860",
    "end": "613570"
  },
  {
    "start": "610000",
    "end": "769000"
  },
  {
    "text": "or clusters might have\ncontributed to this I/O cost. So this is where the cost\nallocation tags come handy.",
    "start": "613570",
    "end": "620550"
  },
  {
    "text": "As you see here, I have two specific tags: one is environment and the second is name.",
    "start": "620550",
    "end": "625720"
  },
  {
    "text": "But let's see how I have added\nthese to my Aurora clusters. So let's head to the RDS console next,",
    "start": "625720",
    "end": "632370"
  },
  {
    "text": "select databases in the\nleft navigation bar here and let's go to one of my Aurora clusters.",
    "start": "632370",
    "end": "640283"
  },
  {
    "text": "As you can see, I have added two tags\nto my Aurora cluster. One is environment and the second is name.",
    "start": "641760",
    "end": "648030"
  },
  {
    "text": "The same thing I have done\nwith other Aurora clusters in my AWS account. Next, you'll have to enable this tags",
    "start": "648030",
    "end": "655350"
  },
  {
    "text": "in the cost allocation tag\nsection of the billing dashboard. So let's head to the\nbilling dashboard next",
    "start": "655350",
    "end": "662000"
  },
  {
    "text": "and go to cost allocation tags. I have activated the name\nin the environment tag",
    "start": "662000",
    "end": "668550"
  },
  {
    "text": "by selecting these and\nthen clicking on activate. As you can see, the\nstatus for these two tags",
    "start": "668550",
    "end": "674750"
  },
  {
    "text": "are active right now. With this, the tagging information will start flowing to the billing items",
    "start": "674750",
    "end": "680920"
  },
  {
    "text": "and then AWS Cost Explorer and there is one more feature called AWS Cost and Usage Reports",
    "start": "680920",
    "end": "687460"
  },
  {
    "text": "which we'll talk about next will have those tagging information. Let's go back to the AWS Cost Explorer",
    "start": "687460",
    "end": "694149"
  },
  {
    "text": "and select one of these\ntags to group the cost by these tags.",
    "start": "694150",
    "end": "699103"
  },
  {
    "text": "Let's select the environment tag here and we can see that the broad environments",
    "start": "702450",
    "end": "707610"
  },
  {
    "text": "are contributing to the highest cost here. Also, there are some\nenvironments which are not tagged",
    "start": "707610",
    "end": "713050"
  },
  {
    "text": "for which the cost is grouped\ntogether and shown here. Next, let's select the name tag.",
    "start": "713050",
    "end": "718532"
  },
  {
    "text": "This view is showing me\nexactly which Aurora cluster is contributing to the highest\nAurora storage I/O cost,",
    "start": "720480",
    "end": "727060"
  },
  {
    "text": "which is APG cod in my case. So this is the benefit of\nadding tags to your RDS",
    "start": "727060",
    "end": "733010"
  },
  {
    "text": "and Aurora clusters and enabling them for billing purpose because this allows us to\ndissect the AWS cost further",
    "start": "733010",
    "end": "741410"
  },
  {
    "text": "by a specific tag. If you want to see your AWS\ncost on an hour by hour basis,",
    "start": "741410",
    "end": "747470"
  },
  {
    "text": "AWS Cost Explorer also\nallows us to do that. So for that, let's select\nhourly in the dropdown here",
    "start": "747470",
    "end": "755230"
  },
  {
    "text": "and this will limit our\nanalysis to the last seven days which is fine.",
    "start": "755230",
    "end": "759483"
  },
  {
    "text": "Using this view, I can\nnow see hour by hour cost for APG cod cluster",
    "start": "761010",
    "end": "766710"
  },
  {
    "text": "specific to storage I/O usage. So if you are a fan of\nSQL, you can also use",
    "start": "766710",
    "end": "772390"
  },
  {
    "start": "769000",
    "end": "974000"
  },
  {
    "text": "AWS Cost and Usage Reports along with Amazon Athena\nto do your analysis.",
    "start": "772390",
    "end": "777980"
  },
  {
    "text": "So let's go to the billing dashboard again and select cost and usage reports",
    "start": "777980",
    "end": "783380"
  },
  {
    "text": "in the left navigation bar. The AWS Cost and Usage\nReports contains the most",
    "start": "783380",
    "end": "788930"
  },
  {
    "text": "comprehensive set of cost\nand usage data available. You can use cost and usage reports",
    "start": "788930",
    "end": "794420"
  },
  {
    "text": "to publish your AWS billing reports that break down your cost\nby the hour, day or month,",
    "start": "794420",
    "end": "800380"
  },
  {
    "text": "by product or product resource\nto an Amazon S3 bucket that you own. I have created a cost and usage report",
    "start": "800380",
    "end": "807260"
  },
  {
    "text": "by selecting this create\nreport button here and then you specify a\nname for your report.",
    "start": "807260",
    "end": "812653"
  },
  {
    "text": "And then you can select if you want to add the\nresource IDs to the report. If you select this option,",
    "start": "815300",
    "end": "821570"
  },
  {
    "text": "your report sizes can\nincrease significantly so select this based on your need.",
    "start": "821570",
    "end": "826930"
  },
  {
    "text": "For this demo, I have selected it. Also, I have selected the\ndata refresh setting here",
    "start": "826930",
    "end": "832450"
  },
  {
    "text": "and then we click Next. On the is screen, you\ncan specify the S3 bucket",
    "start": "832450",
    "end": "838070"
  },
  {
    "text": "where you want to store all\nthe AWS billing reports. You can specify S3 path prefix here.",
    "start": "838070",
    "end": "844480"
  },
  {
    "text": "You can specify the granularity,\nhourly daily or monthly. For this demo, I have selected hourly",
    "start": "844480",
    "end": "850949"
  },
  {
    "text": "and you can also specify the\nreport versioning option here. For this demo, I have selected\nthe second option here",
    "start": "850950",
    "end": "858900"
  },
  {
    "text": "which overrides the existing reports. And then we have a choice\nof integrating the reports",
    "start": "858900",
    "end": "864730"
  },
  {
    "text": "with three different AWS services: Amazon Athena, Amazon Redshift\nand Amazon QuickSight.",
    "start": "864730",
    "end": "870589"
  },
  {
    "text": "For this demo, I have\nselected Amazon Athena. So what happens behind the scene is",
    "start": "870590",
    "end": "876270"
  },
  {
    "text": "we will generate the billing\nreports in the parquet format and we will store them in the\nS3 bucket you have specified.",
    "start": "876270",
    "end": "882550"
  },
  {
    "text": "There are some additional\nsteps to integrate AWS Cost and Usage\nReports with Amazon Athena",
    "start": "882550",
    "end": "888540"
  },
  {
    "text": "which we will see next. So here you will click\nNext to create the cost and usage reports.",
    "start": "888540",
    "end": "893579"
  },
  {
    "text": "I already have created one for this demo so I will just cancel here. And this is my cost and usage reports.",
    "start": "893580",
    "end": "900350"
  },
  {
    "text": "So once you have created\nthe cost and usage reports and you have selected\nthe option to integrate",
    "start": "900350",
    "end": "905550"
  },
  {
    "text": "with Amazon Athena, you will be shown a documentation link which you'll have to further follow",
    "start": "905550",
    "end": "911410"
  },
  {
    "text": "to integrate Amazon Athena\nwith cost and uses reports. And this is the documentation\nlink that will be shown.",
    "start": "911410",
    "end": "918360"
  },
  {
    "text": "This documentation shows us how to install a AWS provided\ncloud formation template",
    "start": "918360",
    "end": "924310"
  },
  {
    "text": "to integrate Amazon Athena with\nAWS Cost and Usage Reports. It is recommended to\ncreate a new S3 bucket",
    "start": "924310",
    "end": "931300"
  },
  {
    "text": "for your AWS Cost and Usage Reports. Because when you install this\ncloud formation template,",
    "start": "931300",
    "end": "936610"
  },
  {
    "text": "it will remove any S3 event that your bucket might already have. After you have enabled\nthe Athena integration,",
    "start": "936610",
    "end": "944080"
  },
  {
    "text": "you'll have to wait 24 hours before the first report is\ncreated in your S3 bucket.",
    "start": "944080",
    "end": "949980"
  },
  {
    "text": "After that, go to the S3\nbucket which you had specified and go to the path prefix",
    "start": "949980",
    "end": "955920"
  },
  {
    "text": "and there will be a YAML file\nwhich we need to download and then install in your AWS account.",
    "start": "955920",
    "end": "962500"
  },
  {
    "text": "The cloud formation stack\ncreates several resources including glue crawler and a glue database",
    "start": "962500",
    "end": "968830"
  },
  {
    "text": "which we will query using Amazon Athena to analyze our billing data.",
    "start": "968830",
    "end": "974220"
  },
  {
    "start": "974000",
    "end": "1104000"
  },
  {
    "text": "Once your cloud formation\nstart creation is complete, We'll go to Amazon Athena\nconsole to query the billing data",
    "start": "974220",
    "end": "981400"
  },
  {
    "text": "which is stored in Amazon S3. Let's go to the Athena console next. If you're not familiar with Amazon Athena,",
    "start": "981400",
    "end": "988890"
  },
  {
    "text": "it's an interactive query\nservice that makes it easy to analyze data in Amazon\nS3 using standard SQL.",
    "start": "988890",
    "end": "996089"
  },
  {
    "text": "Athena is serverless so there is no infrastructure to manage and you only pay for the\nqueries that you run.",
    "start": "996090",
    "end": "1003130"
  },
  {
    "text": "The cloud formation\ntemplate that we deployed created a glue database for us.",
    "start": "1003130",
    "end": "1008180"
  },
  {
    "text": "So this is the database that it created. Also, the glue crawler that got deployed",
    "start": "1008180",
    "end": "1013400"
  },
  {
    "text": "has created a partition table for us. And the partition table name is called.",
    "start": "1013400",
    "end": "1018820"
  },
  {
    "text": "There is one more cable called\ncost and uses data status which shows us if the\ncost and usage reports",
    "start": "1018820",
    "end": "1026400"
  },
  {
    "text": "are actually ready to be\nqueried by Amazon Athena. So let's select start\nfrom this table next.",
    "start": "1026400",
    "end": "1032592"
  },
  {
    "text": "As we can see here, the\nstatus source is ready. So that means that we can now query the cost and usage reports\nusing Amazon Athena.",
    "start": "1035400",
    "end": "1044110"
  },
  {
    "text": "I have a query here where I'm\nselecting from the cod table And what I have done\nis that I have selected",
    "start": "1044110",
    "end": "1049760"
  },
  {
    "text": "some filters here and I have glued by some of the columns. As you can see, I'm\nfiltering by the line item",
    "start": "1049760",
    "end": "1056300"
  },
  {
    "text": "usage start date and I have specified the dates\nfor which I want to analyze the billing data.",
    "start": "1056300",
    "end": "1061990"
  },
  {
    "text": "Also, I have specified\nthe name tag to APG cod which I had created earlier.",
    "start": "1061990",
    "end": "1067970"
  },
  {
    "text": "And I'm filtering by the usage type and I've specified\nAurora storage I/O usage.",
    "start": "1067970",
    "end": "1074140"
  },
  {
    "text": "So with these filters and\nthe group by conditions, let's run the query next and\nsee what kind of data we see.",
    "start": "1074140",
    "end": "1082169"
  },
  {
    "text": "We can see the hourly\nstorage I/O usage charges for APG cod cluster",
    "start": "1082170",
    "end": "1087610"
  },
  {
    "text": "like we saw earlier\nusing AWS Cost Explorer. So in summary, AWS Cost Explorer",
    "start": "1087610",
    "end": "1093843"
  },
  {
    "text": "and AWS Cost and Usage\nReports can help you to slice and dice your AWS cost.",
    "start": "1094878",
    "end": "1100660"
  },
  {
    "text": "So you know where to focus your effort for your cost analysis. The next step is to drill\ndown on APG cod cluster",
    "start": "1100660",
    "end": "1108290"
  },
  {
    "start": "1104000",
    "end": "1159000"
  },
  {
    "text": "and to find out if these\nstorage I/O usage charges were related to reads or writes.",
    "start": "1108290",
    "end": "1114770"
  },
  {
    "text": "Also, we need to find out\nwhich specific queries might have contributed to this I/O charge.",
    "start": "1114770",
    "end": "1120610"
  },
  {
    "text": "So let's head back to the RDS console and for APG cod cluster,",
    "start": "1120610",
    "end": "1125630"
  },
  {
    "text": "let's go to the monitoring tab now. Here, let's search for some\nof the billing related metrics",
    "start": "1125630",
    "end": "1131710"
  },
  {
    "text": "and let's select the time\nduration for last seven days. Using these CloudWatch metrics,",
    "start": "1132960",
    "end": "1139280"
  },
  {
    "text": "We can see that for APG cod cluster, The volume write IOPS was\nconsistently less than 250K",
    "start": "1139280",
    "end": "1146890"
  },
  {
    "text": "but the volume read IOPS\nwas more than 1.5 million for the last several days.",
    "start": "1146950",
    "end": "1152570"
  },
  {
    "text": "So this is telling us that\nthere might be some queries running in this cluster which is reading a lot of\ndata from the Aurora storage.",
    "start": "1152570",
    "end": "1159460"
  },
  {
    "start": "1159000",
    "end": "1748000"
  },
  {
    "text": "To analyze the database\nactivity of this cluster and to see the queries\nrunning on this cluster,",
    "start": "1159460",
    "end": "1164990"
  },
  {
    "text": "let's go to RDS performance insights next. RDS performance insight collects",
    "start": "1164990",
    "end": "1170880"
  },
  {
    "text": "detailed database performance data and presents it in a graphical interface to help you quickly assess performance",
    "start": "1170880",
    "end": "1177930"
  },
  {
    "text": "of your database workloads. Let's select the right\ninstance of APG cod cluster",
    "start": "1177930",
    "end": "1183690"
  },
  {
    "text": "which is APG-cod-instance-1 and view its database activity.",
    "start": "1183690",
    "end": "1189419"
  },
  {
    "text": "Performance insights\nhas three main sections. On the top, we have the counter metrics.",
    "start": "1189420",
    "end": "1194910"
  },
  {
    "text": "In the middle, we have the database load and at the bottom, we\nhave the top activity.",
    "start": "1194910",
    "end": "1201170"
  },
  {
    "text": "You can also select various time duration by selecting one of the\noptions here at the top.",
    "start": "1201170",
    "end": "1207460"
  },
  {
    "text": "Counter metrics section\nshows us the various OS and database related metrics.",
    "start": "1207460",
    "end": "1213250"
  },
  {
    "text": "You can customize this view by selecting the managed metrics button here. In the OS metrics section,",
    "start": "1213250",
    "end": "1219860"
  },
  {
    "text": "you can specify various\nCPU related metrics, various storage, disc I/O related metrics",
    "start": "1219860",
    "end": "1225550"
  },
  {
    "text": "and various memory related metrics. Similarly, in the\ndatabase metrics section, you can specify various\ndatabase internal metrics.",
    "start": "1225550",
    "end": "1234603"
  },
  {
    "text": "The database load section in the middle allows us to slice the\ndata by various dimensions",
    "start": "1235460",
    "end": "1241360"
  },
  {
    "text": "such as user, weights, SQL and host. Here, you can hover your mouse",
    "start": "1241360",
    "end": "1247070"
  },
  {
    "text": "over a particular weight\nevents to learn more about it. We can scroll to the\nbottom to see the top SQLs",
    "start": "1247070",
    "end": "1253100"
  },
  {
    "text": "in the APG cod cluster. Since the APG cod cluster\nwas more real heavy,",
    "start": "1253100",
    "end": "1258240"
  },
  {
    "text": "I'm specifically interested\nto see the queries which contributed to it. So let me go ahead and\nselect the I/O data file",
    "start": "1258240",
    "end": "1265649"
  },
  {
    "text": "read weight here. And if you scroll to the bottom now, we can see that there is\na update query happening",
    "start": "1265650",
    "end": "1273270"
  },
  {
    "text": "on pgbench accounts that is contributing to the most for this weight event.",
    "start": "1273270",
    "end": "1278419"
  },
  {
    "text": "Also, there is a select\nquery on the pgbench accounts which has the same weight event.",
    "start": "1278420",
    "end": "1283800"
  },
  {
    "text": "Next, I will select another weight event which is also related to the reads",
    "start": "1283800",
    "end": "1288860"
  },
  {
    "text": "which is I/O data file pre-fetch. We can see that the same select statement on pgbench account",
    "start": "1288860",
    "end": "1295350"
  },
  {
    "text": "is also seeing this weight event. We can also slice the database load by SQL",
    "start": "1295350",
    "end": "1301850"
  },
  {
    "text": "instead of the weights. If you hover our mouse over\na particular bar chart here,",
    "start": "1301850",
    "end": "1307950"
  },
  {
    "text": "we can see that the select\nstatement on pgbench's accounts is contributing to 42% of\nthe average active sessions",
    "start": "1307950",
    "end": "1315820"
  },
  {
    "text": "followed by the update\nstatement on pgbench's accounts which is contributing to 27%.",
    "start": "1315820",
    "end": "1321100"
  },
  {
    "text": "Next, let's select the select statement on the pgbench accounts here.",
    "start": "1321100",
    "end": "1325723"
  },
  {
    "text": "And we can see the weight events\nthat this particular query saw at the bottom. Also, using this view,",
    "start": "1327190",
    "end": "1333600"
  },
  {
    "text": "we can see that this query is\nrunning every 30 minutes or so",
    "start": "1333600",
    "end": "1337809"
  },
  {
    "text": "Now, if you scroll back\nto the counter metrics, we can also see that some of the metrics are also spiking up every 30 minutes.",
    "start": "1339120",
    "end": "1346233"
  },
  {
    "text": "The topple's return metric here shows us how many couples\nPostgreSQL actually scanned",
    "start": "1348270",
    "end": "1354580"
  },
  {
    "text": "to get to the final output. And the topple's fetched metrics shows us how many rows\nor topples PostgreSQL",
    "start": "1354580",
    "end": "1361900"
  },
  {
    "text": "actually return back to the client. So these metrics are telling\nus some of the queries are actually scanning lot of rows",
    "start": "1361900",
    "end": "1368300"
  },
  {
    "text": "for returning very few\nrows back to the client. And this might be because\nthose queries are running",
    "start": "1368300",
    "end": "1373590"
  },
  {
    "text": "with an unoptimized plan. Next, I ran an explained\nplan on a particular instance",
    "start": "1373590",
    "end": "1379340"
  },
  {
    "text": "of that query. So I scrolled down to\nthe bottom here again and I selected Top SQL.",
    "start": "1379340",
    "end": "1384730"
  },
  {
    "text": "And by expanding this node, you can see the various instances\nof this particular query,",
    "start": "1384730",
    "end": "1390980"
  },
  {
    "text": "which shows us the bind variables too. And I copied one of the SQL text here and then I ran a explain plan\nusing the PSQL command line.",
    "start": "1390980",
    "end": "1399490"
  },
  {
    "text": "PostgreSQL has extension\ncalled PG start statements which is very helpful in\ntracking the execution statistics",
    "start": "1399490",
    "end": "1406650"
  },
  {
    "text": "of queries over a period of time. So I ran a query on the\nPG start statements view",
    "start": "1406650",
    "end": "1412000"
  },
  {
    "text": "and ordered the queries\nby shared blocks read to confirm what RDS\nperformance insight showed me",
    "start": "1412000",
    "end": "1419280"
  },
  {
    "text": "as the top contributor\nfor the I/O charges. So as we can see here, the select statements\non pgbench's accounts",
    "start": "1419280",
    "end": "1427130"
  },
  {
    "text": "is the top SQL with the\nhighest shared block recount. I also ran another query\non PG start statements",
    "start": "1427130",
    "end": "1434740"
  },
  {
    "text": "and ordered the queries\nby mean execution time. And the same select statement is also here",
    "start": "1434740",
    "end": "1440610"
  },
  {
    "text": "which tells me that this is a slow query. Then I explained the query plan with some of the other\noptions that you can see here",
    "start": "1440610",
    "end": "1447840"
  },
  {
    "text": "such as analyze verbose\nbuffers and settings. Analyze actually runs\nthe query and shows me",
    "start": "1447840",
    "end": "1454170"
  },
  {
    "text": "the actual run time and\nvarious other statistics for the plan notes.",
    "start": "1454170",
    "end": "1459370"
  },
  {
    "text": "Next, I copied the query plan and then pasted it into\na tool called the page.",
    "start": "1459370",
    "end": "1464430"
  },
  {
    "text": "As long as you don't mind\nposting the query plan, this tool can be used\nand the import and things",
    "start": "1464430",
    "end": "1470060"
  },
  {
    "text": "jump right at you. It immediately focuses your\nattention from the blur of all the text",
    "start": "1470060",
    "end": "1475429"
  },
  {
    "text": "to the problems in the query plan. We can see that the query is doing a parallel sequential scan",
    "start": "1475430",
    "end": "1481300"
  },
  {
    "text": "on the pgbench account's table and there are two workers\nthe query is running with.",
    "start": "1481300",
    "end": "1487160"
  },
  {
    "text": "The total execution time\nwas about 444 seconds and this particular node took 444 seconds.",
    "start": "1487160",
    "end": "1495429"
  },
  {
    "text": "So most of the time is spent doing the parallel sequential scan on the table.",
    "start": "1495430",
    "end": "1500789"
  },
  {
    "text": "Also, we see that this particular node queried about 42 GBF data\nfrom the Aurora storage.",
    "start": "1500790",
    "end": "1507760"
  },
  {
    "text": "And in total, the query\nread about 84 GBF data from the Aurora storage.",
    "start": "1507760",
    "end": "1513320"
  },
  {
    "text": "The APG cod cluster is set up on a DBR6G large instance class",
    "start": "1513320",
    "end": "1519399"
  },
  {
    "text": "which has about 16 GBF memory. So each time the query runs\nwith this particular plan,",
    "start": "1519400",
    "end": "1526600"
  },
  {
    "text": "it is fetching about 84 GB amount of data from Aurora storage. Because we are not able\nto cache the hard data",
    "start": "1526600",
    "end": "1534100"
  },
  {
    "text": "in the small buffer\npool of APG cod cluster. We see that the query has a\nfilter on the branch ID column",
    "start": "1534100",
    "end": "1540850"
  },
  {
    "text": "of pgbench accounts. And it turns out we don't\nhave a index on this column.",
    "start": "1540850",
    "end": "1546330"
  },
  {
    "text": "So, the query ends up doing\na parallel sequential scan on this huge table.",
    "start": "1546330",
    "end": "1551610"
  },
  {
    "text": "To optimize this query, I created a index on the branch ID column and here is the optimized plan.",
    "start": "1551610",
    "end": "1558710"
  },
  {
    "text": "Now we see that the query\nis doing a index scan on the new index I created",
    "start": "1558710",
    "end": "1564250"
  },
  {
    "text": "and it's only reading 13 MB of\ndata from the Aurora storage. And the execution time\ndropped from 444 seconds",
    "start": "1564250",
    "end": "1573080"
  },
  {
    "text": "to only 223 milliseconds now. So this is how you use\nquery plan to understand",
    "start": "1573080",
    "end": "1579000"
  },
  {
    "text": "the bottleneck and then use\nvarious query optimizers and techniques to tune a query.",
    "start": "1579000",
    "end": "1584445"
  },
  {
    "text": "To see if your buffer\ncache is sized properly, You can use the CloudWatch metrics called Buffer Cache Hit Ratio.",
    "start": "1584445",
    "end": "1591323"
  },
  {
    "text": "Typically for a LTP workload, the buffer cache hit ratios\nshould stay very close to a 100%.",
    "start": "1592550",
    "end": "1598610"
  },
  {
    "text": "But as we can see for APG cod cluster, it's around 96% or so.",
    "start": "1598610",
    "end": "1603800"
  },
  {
    "text": "And we see that the buffer cache hit ratio are dropping to almost\n7% every 30 minutes.",
    "start": "1603800",
    "end": "1610280"
  },
  {
    "text": "This is when that large query was running and it was flooding the buffer pool with all those data pages.",
    "start": "1610280",
    "end": "1616740"
  },
  {
    "text": "Even after tuning the expensive queries, If you see the buffer cache\nhit ratio not improving,",
    "start": "1616740",
    "end": "1622210"
  },
  {
    "text": "your buffer pool might be\nvery small for your workload. In that case, you can consider\nscaling up your instance",
    "start": "1622210",
    "end": "1629100"
  },
  {
    "text": "to the next instance class. So this is how you drill\ndown on Aurora I/O cost",
    "start": "1629100",
    "end": "1634120"
  },
  {
    "text": "starting from the AWS billing statement and then actually finding\nout which Aurora cluster",
    "start": "1634120",
    "end": "1639220"
  },
  {
    "text": "or queries running in\nthat particular cluster might have contributed to that I/O cost. We can apply the same methodology\nto drill down on I/O cost",
    "start": "1639220",
    "end": "1648240"
  },
  {
    "text": "for Aurora MySQL. Let me select the writer instance\nof an Aurora MySQL cluster",
    "start": "1648240",
    "end": "1653870"
  },
  {
    "text": "and see what kind of analysis we can do using RDS performance insights.",
    "start": "1653870",
    "end": "1660080"
  },
  {
    "text": "Let's select the last 24 hours of data and scroll down to the bottom\nto see the top activity.",
    "start": "1660080",
    "end": "1666490"
  },
  {
    "text": "You can click on the gear icon here and add various SQL level\nmetrics which you want to see.",
    "start": "1666490",
    "end": "1673170"
  },
  {
    "text": "I have added two metrics\ncalled rows examined per second and the rows sent per second.",
    "start": "1673170",
    "end": "1680350"
  },
  {
    "text": "The rows examined per second\ntells us how many rows MySQL had to scan to get\nto the final query result.",
    "start": "1680350",
    "end": "1688190"
  },
  {
    "text": "And the rows sent per second tells us how many rows were actually\nsent back to the client.",
    "start": "1688190",
    "end": "1694309"
  },
  {
    "text": "So I'm particularly\ninterested to see the queries where the rows examined\nper second is very high",
    "start": "1694310",
    "end": "1700129"
  },
  {
    "text": "compared to the rows sent per second. So that means these\nqueries might be running with an unoptimized plan",
    "start": "1700130",
    "end": "1706610"
  },
  {
    "text": "where there is further\nopportunity for tuning. We can see that these three\nqueries have a large difference",
    "start": "1706610",
    "end": "1713270"
  },
  {
    "text": "between the rows examine per second and the rows sent per second.",
    "start": "1713270",
    "end": "1718580"
  },
  {
    "text": "We can apply similar\noptimization technique like we did earlier to tune these queries.",
    "start": "1718580",
    "end": "1724040"
  },
  {
    "text": "In MySQL, you can use slow query log to find out the queries\nwhich are taking long time",
    "start": "1724040",
    "end": "1729240"
  },
  {
    "text": "to execute and are therefore\ncandidates for optimization. Once you find the slow queries,",
    "start": "1729240",
    "end": "1735200"
  },
  {
    "text": "you can analyze them by\nrunning explain plan on them. And then you can further\ndo query profiling",
    "start": "1735200",
    "end": "1741340"
  },
  {
    "text": "using MySQL performance schema to determine which part\nof the query execution",
    "start": "1741340",
    "end": "1746820"
  },
  {
    "text": "is causing the most latency. Now that we saw a demo for how\nto optimize Aurora I/O cost,",
    "start": "1746820",
    "end": "1753240"
  },
  {
    "start": "1748000",
    "end": "1939000"
  },
  {
    "text": "let's discuss some of the best practices when it comes to Aurora\nI/O cost optimization.",
    "start": "1753240",
    "end": "1759200"
  },
  {
    "text": "To optimize Read I/O, tune your SQL queries using\nsome of the query optimizers",
    "start": "1759200",
    "end": "1764387"
  },
  {
    "text": "and techniques so that it only scans the\nminimal number of data and index pages to return the query result",
    "start": "1764387",
    "end": "1771050"
  },
  {
    "text": "and every full table scans\nfor large tables at all cost. Typically, this is the most common cause",
    "start": "1771050",
    "end": "1777200"
  },
  {
    "text": "when it comes to higher Aurora Read I/O. Like we discussed in the demo, monitor buffer cache hit\nratio CloudWatch metrics",
    "start": "1777200",
    "end": "1784809"
  },
  {
    "text": "and scale up the instance when needed to reduce reads from storage. For Aurora PostgreSQL,\nblotted tables and indexes",
    "start": "1784810",
    "end": "1792980"
  },
  {
    "text": "can cause additional reads\nfor tables with high DMLs. So makes sure auto hacking\nis tuned for your workload.",
    "start": "1792980",
    "end": "1799850"
  },
  {
    "text": "Aurora provides managed backup capability but you also have the ability to use",
    "start": "1799850",
    "end": "1805290"
  },
  {
    "text": "logical backup utilities\nlike MySQL dump for MySQL and PG dump for PostgreSQL.",
    "start": "1805290",
    "end": "1811490"
  },
  {
    "text": "These utilities will\ngenerate a lot of Read I/Os. So unless absolutely required,",
    "start": "1811490",
    "end": "1817010"
  },
  {
    "text": "stick to Aurora native backup capability. Same true for logical replication.",
    "start": "1817010",
    "end": "1823150"
  },
  {
    "text": "Try to use Aurora replicas and use bin log or while based read replicas",
    "start": "1823150",
    "end": "1828470"
  },
  {
    "text": "as an exception for specific needs. When it comes to optimizing Write I/O,",
    "start": "1828470",
    "end": "1834559"
  },
  {
    "text": "make sure that database only\ncontains the required indexes to support your workload. Remove all unused and duplicate indexes",
    "start": "1834560",
    "end": "1842460"
  },
  {
    "text": "to reduce Write I/O. For PostgreSQL, adjust\nthe table fill factor",
    "start": "1842460",
    "end": "1847640"
  },
  {
    "text": "based on your workload so that HOT or heap only\ntype of update can be used. This reduces unnecessary index updates",
    "start": "1847640",
    "end": "1855290"
  },
  {
    "text": "and helps with single-pay vacuuming also called as defragmentation\nfurther reducing Write I/Os.",
    "start": "1855290",
    "end": "1862210"
  },
  {
    "text": "Another I/O optimization\ntechnique is to utilize table partitioning. This can help with partition\npruning during reads",
    "start": "1862210",
    "end": "1869900"
  },
  {
    "text": "by avoiding scans and partitions which don't satisfy a\nqueries where clause.",
    "start": "1869900",
    "end": "1875210"
  },
  {
    "text": "You can also drop unrequired partitions instead of deleting large number of rows which will help with\nreducing Write I/O cost.",
    "start": "1875210",
    "end": "1883190"
  },
  {
    "text": "Logical replication\nusing bin log for MySQL and write ahead log for PostgreSQL",
    "start": "1883190",
    "end": "1889140"
  },
  {
    "text": "also causes additional writes. So use them only when needed.",
    "start": "1889140",
    "end": "1893373"
  },
  {
    "text": "So that concludes the demo\nI wanted to show you today. We saw how cost allocation\ntag can be beneficial",
    "start": "1894270",
    "end": "1900920"
  },
  {
    "text": "while investigating which\nAurora clusters or environments might be contributing to\nyour overall Aurora spend.",
    "start": "1900920",
    "end": "1907310"
  },
  {
    "text": "By using various AWS services and features like AWS Cost Explorer,\nAWS Cost and Usage Reports,",
    "start": "1907310",
    "end": "1915260"
  },
  {
    "text": "Amazon Athena, Amazon CloudWatch and RDS performance insights. I hope this demo was useful\nand I hope this will help you",
    "start": "1915260",
    "end": "1923730"
  },
  {
    "text": "in investigating your Aurora\nbill in a systematic way. Thank you so much for taking\nthe time to go through",
    "start": "1923730",
    "end": "1929960"
  },
  {
    "text": "this demo today. And I wish you happy cloud\ncomputing from all of us here at AWS.",
    "start": "1929960",
    "end": "1935137"
  }
]
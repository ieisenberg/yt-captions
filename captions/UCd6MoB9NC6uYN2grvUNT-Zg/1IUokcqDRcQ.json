[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": "in this module we're going to be talking",
    "start": "1120",
    "end": "2480"
  },
  {
    "text": "about how you can use Amazon's elastic",
    "start": "2480",
    "end": "4480"
  },
  {
    "text": "map ruce to run Hive and pig jobs in",
    "start": "4480",
    "end": "7240"
  },
  {
    "text": "previous sections we've been focusing on",
    "start": "7240",
    "end": "9000"
  },
  {
    "text": "running custom Java code custom Hadoop",
    "start": "9000",
    "end": "11599"
  },
  {
    "text": "jobs um but in this case we're talking",
    "start": "11599",
    "end": "14000"
  },
  {
    "text": "about how you can execute Hive and pig",
    "start": "14000",
    "end": "16680"
  },
  {
    "text": "scripts using Amazon's elastic map",
    "start": "16680",
    "end": "19000"
  },
  {
    "text": "produce",
    "start": "19000",
    "end": "20400"
  },
  {
    "start": "20000",
    "end": "102000"
  },
  {
    "text": "support now this module assumes that you",
    "start": "20400",
    "end": "22720"
  },
  {
    "text": "already know about either Hive or Pig so",
    "start": "22720",
    "end": "24800"
  },
  {
    "text": "what we're going to talk about is the",
    "start": "24800",
    "end": "26000"
  },
  {
    "text": "specific things that you need to know in",
    "start": "26000",
    "end": "28119"
  },
  {
    "text": "order to use Hive or Pig with elastic",
    "start": "28119",
    "end": "30599"
  },
  {
    "text": "map produce why would you actually want",
    "start": "30599",
    "end": "32640"
  },
  {
    "text": "to use elastic map produce when running",
    "start": "32640",
    "end": "34320"
  },
  {
    "text": "your hype jobs there's a couple things",
    "start": "34320",
    "end": "36399"
  },
  {
    "text": "one is it's simplifies the setup so when",
    "start": "36399",
    "end": "39600"
  },
  {
    "text": "you ask Amazon to create a Hadoop",
    "start": "39600",
    "end": "42000"
  },
  {
    "text": "cluster for you in elastic map reduce",
    "start": "42000",
    "end": "44360"
  },
  {
    "text": "you can tell it to automatically set up",
    "start": "44360",
    "end": "46079"
  },
  {
    "text": "Hive or Pig so you don't have to do",
    "start": "46079",
    "end": "48120"
  },
  {
    "text": "anything extra in order to run your hive",
    "start": "48120",
    "end": "50199"
  },
  {
    "text": "jobs uh you already have a database",
    "start": "50199",
    "end": "52320"
  },
  {
    "text": "running that you can use to store your",
    "start": "52320",
    "end": "54320"
  },
  {
    "text": "hive schemas you have a very simple way",
    "start": "54320",
    "end": "57359"
  },
  {
    "text": "of both running monitoring and then also",
    "start": "57359",
    "end": "59960"
  },
  {
    "text": "so terminating your hive jobs because",
    "start": "59960",
    "end": "62600"
  },
  {
    "text": "you've got the Amazon Management console",
    "start": "62600",
    "end": "64360"
  },
  {
    "text": "and also the command line tools let you",
    "start": "64360",
    "end": "65840"
  },
  {
    "text": "interact with Hive there's some things",
    "start": "65840",
    "end": "68560"
  },
  {
    "text": "that Amazon's uh done to extend and",
    "start": "68560",
    "end": "71560"
  },
  {
    "text": "improve Hive so for example there's a",
    "start": "71560",
    "end": "73920"
  },
  {
    "text": "Json CI that lets you uh read and write",
    "start": "73920",
    "end": "76920"
  },
  {
    "text": "data in Json format and there are a",
    "start": "76920",
    "end": "80479"
  },
  {
    "text": "bunch of patches that they've applied to",
    "start": "80479",
    "end": "82439"
  },
  {
    "text": "Hive to improve how it runs inside of an",
    "start": "82439",
    "end": "85880"
  },
  {
    "text": "elastic map reduce cluster for example",
    "start": "85880",
    "end": "88479"
  },
  {
    "text": "there's various things that you can do",
    "start": "88479",
    "end": "89920"
  },
  {
    "text": "with Hive uh in EMR like reading and",
    "start": "89920",
    "end": "93040"
  },
  {
    "text": "writing tables uh to and from S3 that",
    "start": "93040",
    "end": "95479"
  },
  {
    "text": "you couldn't do with a regular version",
    "start": "95479",
    "end": "96759"
  },
  {
    "text": "of Hive and there's a full list of them",
    "start": "96759",
    "end": "98560"
  },
  {
    "text": "on um the Amazon website the link you",
    "start": "98560",
    "end": "101159"
  },
  {
    "text": "see",
    "start": "101159",
    "end": "102240"
  },
  {
    "start": "102000",
    "end": "133000"
  },
  {
    "text": "here so how do you actually go about",
    "start": "102240",
    "end": "104159"
  },
  {
    "text": "running a hive job well you create a",
    "start": "104159",
    "end": "105880"
  },
  {
    "text": "hive job flow uh the sequence is very",
    "start": "105880",
    "end": "109079"
  },
  {
    "text": "similar to running uh a regular Hadoop",
    "start": "109079",
    "end": "112280"
  },
  {
    "text": "job in that the first thing you do is",
    "start": "112280",
    "end": "114560"
  },
  {
    "text": "you've got to you know upload your hive",
    "start": "114560",
    "end": "116719"
  },
  {
    "text": "script you've got to say you know where",
    "start": "116719",
    "end": "118920"
  },
  {
    "text": "your data is coming from you do this",
    "start": "118920",
    "end": "120799"
  },
  {
    "text": "process of configuring a hive job flow",
    "start": "120799",
    "end": "123479"
  },
  {
    "text": "uh then once it's all ready to go you",
    "start": "123479",
    "end": "125280"
  },
  {
    "text": "say run uh Amazon takes care of setting",
    "start": "125280",
    "end": "127880"
  },
  {
    "text": "up the cluster for you executing your",
    "start": "127880",
    "end": "129840"
  },
  {
    "text": "hive script and then terminating things",
    "start": "129840",
    "end": "131760"
  },
  {
    "text": "when it's",
    "start": "131760",
    "end": "133840"
  },
  {
    "start": "133000",
    "end": "181000"
  },
  {
    "text": "done so what's the difference between",
    "start": "133840",
    "end": "135800"
  },
  {
    "text": "using a hive flow and a custom jar I",
    "start": "135800",
    "end": "138000"
  },
  {
    "text": "mean both you can do um you can set up",
    "start": "138000",
    "end": "140760"
  },
  {
    "text": "the job flows using the AWS Management",
    "start": "140760",
    "end": "143959"
  },
  {
    "text": "console or the command line tools when",
    "start": "143959",
    "end": "146319"
  },
  {
    "text": "you're running a custom jar you've got",
    "start": "146319",
    "end": "148480"
  },
  {
    "text": "code that you've uploaded as a Hadoop",
    "start": "148480",
    "end": "150599"
  },
  {
    "text": "job jar into S3 versus with Hive job",
    "start": "150599",
    "end": "153920"
  },
  {
    "text": "flows you have typically a hive script",
    "start": "153920",
    "end": "156120"
  },
  {
    "text": "that you've put somewhere in S3 um the",
    "start": "156120",
    "end": "159040"
  },
  {
    "text": "data in both cases often comes out of S3",
    "start": "159040",
    "end": "162959"
  },
  {
    "text": "uh though it doesn't have to and the",
    "start": "162959",
    "end": "164480"
  },
  {
    "text": "results typically wind up again in S3",
    "start": "164480",
    "end": "167519"
  },
  {
    "text": "though if you look for example at the um",
    "start": "167519",
    "end": "171560"
  },
  {
    "text": "you know running a data warehouse using",
    "start": "171560",
    "end": "174000"
  },
  {
    "text": "Hive tutorial that's available online in",
    "start": "174000",
    "end": "175840"
  },
  {
    "text": "that case I believe it's actually",
    "start": "175840",
    "end": "177360"
  },
  {
    "text": "writing results into simple DB versus",
    "start": "177360",
    "end": "179480"
  },
  {
    "text": "say giving them an",
    "start": "179480",
    "end": "182120"
  },
  {
    "start": "181000",
    "end": "351000"
  },
  {
    "text": "S3 so what's the first thing that you",
    "start": "183280",
    "end": "185319"
  },
  {
    "text": "need to do when you're running a hive",
    "start": "185319",
    "end": "187360"
  },
  {
    "text": "job flow well you need to set up a",
    "start": "187360",
    "end": "189319"
  },
  {
    "text": "bucket in S3 and in here typically then",
    "start": "189319",
    "end": "192680"
  },
  {
    "text": "you've got your hive script uh you've",
    "start": "192680",
    "end": "195280"
  },
  {
    "text": "got you know where your data is coming",
    "start": "195280",
    "end": "196599"
  },
  {
    "text": "from you've got where you want your",
    "start": "196599",
    "end": "197959"
  },
  {
    "text": "results to go to and you've got where",
    "start": "197959",
    "end": "200000"
  },
  {
    "text": "you want Amazon to save the logs from",
    "start": "200000",
    "end": "202599"
  },
  {
    "text": "the job and all of this can be done",
    "start": "202599",
    "end": "205239"
  },
  {
    "text": "using the AWS console uh in terms of",
    "start": "205239",
    "end": "207959"
  },
  {
    "text": "setting up the bucket in these",
    "start": "207959",
    "end": "208879"
  },
  {
    "text": "directories and also uploading files so",
    "start": "208879",
    "end": "211120"
  },
  {
    "text": "we're going to go um set up that bucket",
    "start": "211120",
    "end": "212920"
  },
  {
    "text": "right",
    "start": "212920",
    "end": "215080"
  },
  {
    "text": "now so here I am I have logged into the",
    "start": "215439",
    "end": "219519"
  },
  {
    "text": "AWS Management console and I'm sitting",
    "start": "219519",
    "end": "221319"
  },
  {
    "text": "here in the S3 bucket Explorer and at",
    "start": "221319",
    "end": "224400"
  },
  {
    "text": "this point I can create a new bucket for",
    "start": "224400",
    "end": "226720"
  },
  {
    "text": "example let's call this bucket AWS test",
    "start": "226720",
    "end": "230720"
  },
  {
    "text": "uh",
    "start": "230720",
    "end": "232959"
  },
  {
    "text": "KK and once I've got this bucket I can",
    "start": "233239",
    "end": "235680"
  },
  {
    "text": "create some folders in here so I know I",
    "start": "235680",
    "end": "237879"
  },
  {
    "text": "want to have a folder called Scripts",
    "start": "237879",
    "end": "240720"
  },
  {
    "text": "uh I know I'm going to want to have a",
    "start": "240720",
    "end": "242720"
  },
  {
    "text": "folder called",
    "start": "242720",
    "end": "244640"
  },
  {
    "text": "Data uh I need to have one called logs",
    "start": "244640",
    "end": "247439"
  },
  {
    "text": "for my logs file go to and uh I'm going",
    "start": "247439",
    "end": "250400"
  },
  {
    "text": "to call create a folder called Hive",
    "start": "250400",
    "end": "252280"
  },
  {
    "text": "results where my results are going to go",
    "start": "252280",
    "end": "254200"
  },
  {
    "text": "to now at this point I have some things",
    "start": "254200",
    "end": "255879"
  },
  {
    "text": "I need to upload in here so for example",
    "start": "255879",
    "end": "257639"
  },
  {
    "text": "into",
    "start": "257639",
    "end": "260079"
  },
  {
    "text": "scripts I am going to upload my hql file",
    "start": "260160",
    "end": "265520"
  },
  {
    "text": "my hive query language",
    "start": "265520",
    "end": "268280"
  },
  {
    "text": "file and that one is",
    "start": "268280",
    "end": "271560"
  },
  {
    "text": "located right",
    "start": "271560",
    "end": "274800"
  },
  {
    "text": "here and this is pretty small so it",
    "start": "274919",
    "end": "277000"
  },
  {
    "text": "shouldn't take very long to",
    "start": "277000",
    "end": "278440"
  },
  {
    "text": "upload then I'm going to go back here",
    "start": "278440",
    "end": "280440"
  },
  {
    "text": "and I'm going to upload some data that I",
    "start": "280440",
    "end": "281960"
  },
  {
    "text": "want to process and this is going to",
    "start": "281960",
    "end": "283960"
  },
  {
    "text": "take a little bit longer now when you're",
    "start": "283960",
    "end": "286080"
  },
  {
    "text": "doing your lab you won't have to do this",
    "start": "286080",
    "end": "287720"
  },
  {
    "text": "because this data is already uploaded",
    "start": "287720",
    "end": "289000"
  },
  {
    "text": "and available for you in this case",
    "start": "289000",
    "end": "291120"
  },
  {
    "text": "inside of data I've got a sample of the",
    "start": "291120",
    "end": "293880"
  },
  {
    "text": "Wikipedia data and this is",
    "start": "293880",
    "end": "297400"
  },
  {
    "text": "the uh XML files that were generated",
    "start": "297400",
    "end": "300720"
  },
  {
    "text": "from a dump of Wikipedia that are also",
    "start": "300720",
    "end": "302960"
  },
  {
    "text": "used for the Wikipedia ingrams lab for",
    "start": "302960",
    "end": "305320"
  },
  {
    "text": "writing custom Hadoop",
    "start": "305320",
    "end": "307280"
  },
  {
    "text": "jobs so it has a bunch of lines of text",
    "start": "307280",
    "end": "311080"
  },
  {
    "text": "where each line has a single page in it",
    "start": "311080",
    "end": "314560"
  },
  {
    "text": "if we take a look at what that data",
    "start": "314560",
    "end": "315919"
  },
  {
    "text": "actually looks",
    "start": "315919",
    "end": "317199"
  },
  {
    "text": "like while this thing is uploading you",
    "start": "317199",
    "end": "319400"
  },
  {
    "text": "can see it looks like this right so you",
    "start": "319400",
    "end": "321800"
  },
  {
    "text": "have these lines of XML where you've got",
    "start": "321800",
    "end": "324639"
  },
  {
    "text": "a page tag and inside of it's a title",
    "start": "324639",
    "end": "326720"
  },
  {
    "text": "and here's the title for the article and",
    "start": "326720",
    "end": "329080"
  },
  {
    "text": "eventually you'll get things like um a",
    "start": "329080",
    "end": "332520"
  },
  {
    "text": "revision timestamp and a contributor's",
    "start": "332520",
    "end": "335080"
  },
  {
    "text": "username and we're going to take",
    "start": "335080",
    "end": "336120"
  },
  {
    "text": "advantage of those in the actual lab and",
    "start": "336120",
    "end": "338639"
  },
  {
    "text": "we're running that same lab code here so",
    "start": "338639",
    "end": "341520"
  },
  {
    "text": "once this is uploaded now I'm actually",
    "start": "341520",
    "end": "343840"
  },
  {
    "text": "ready to go and start running the uh",
    "start": "343840",
    "end": "347000"
  },
  {
    "text": "start defining the hive job flow when",
    "start": "347000",
    "end": "351800"
  },
  {
    "start": "351000",
    "end": "533000"
  },
  {
    "text": "you set up a job flow you have a whole",
    "start": "351800",
    "end": "353240"
  },
  {
    "text": "bunch of settings that you can specify",
    "start": "353240",
    "end": "354720"
  },
  {
    "text": "using the AWS Management console or the",
    "start": "354720",
    "end": "357000"
  },
  {
    "text": "command line interface so for example",
    "start": "357000",
    "end": "359120"
  },
  {
    "text": "when you're set setting this up you need",
    "start": "359120",
    "end": "360160"
  },
  {
    "text": "to give it a name you need to say how",
    "start": "360160",
    "end": "361520"
  },
  {
    "text": "big your cluster is uh you know where",
    "start": "361520",
    "end": "363600"
  },
  {
    "text": "you want to put the log files Etc so",
    "start": "363600",
    "end": "366960"
  },
  {
    "text": "this process is pretty straightforward",
    "start": "366960",
    "end": "368639"
  },
  {
    "text": "I'm going to come back over here to the",
    "start": "368639",
    "end": "370319"
  },
  {
    "text": "AWS Management console I'll click on the",
    "start": "370319",
    "end": "372960"
  },
  {
    "text": "elastic map ruce",
    "start": "372960",
    "end": "374680"
  },
  {
    "text": "Tab and here I say I'm going to want to",
    "start": "374680",
    "end": "376639"
  },
  {
    "text": "create a new job flow so I'm going to",
    "start": "376639",
    "end": "378759"
  },
  {
    "text": "give it a name in this case it's I don't",
    "start": "378759",
    "end": "380840"
  },
  {
    "text": "know",
    "start": "380840",
    "end": "382440"
  },
  {
    "text": "Wikipedia",
    "start": "382440",
    "end": "384199"
  },
  {
    "text": "contributors and the job type here is",
    "start": "384199",
    "end": "387080"
  },
  {
    "text": "going to be a hive",
    "start": "387080",
    "end": "388400"
  },
  {
    "text": "program now I have to tell it where this",
    "start": "388400",
    "end": "392000"
  },
  {
    "text": "actual script is located in S3 so it's",
    "start": "392000",
    "end": "394160"
  },
  {
    "text": "AWS test KK scripts hi.",
    "start": "394160",
    "end": "399680"
  },
  {
    "text": "hql um and then you can set up input and",
    "start": "399680",
    "end": "402520"
  },
  {
    "text": "output locations and these it's a little",
    "start": "402520",
    "end": "404199"
  },
  {
    "text": "bit confusing because really what's",
    "start": "404199",
    "end": "405440"
  },
  {
    "text": "Happening Here is whatever you put in",
    "start": "405440",
    "end": "407240"
  },
  {
    "text": "here for the input location and the",
    "start": "407240",
    "end": "408520"
  },
  {
    "text": "output location Hive just defines these",
    "start": "408520",
    "end": "411240"
  },
  {
    "text": "as variables that you can use in your",
    "start": "411240",
    "end": "413160"
  },
  {
    "text": "scripts they don't mean anything else",
    "start": "413160",
    "end": "415280"
  },
  {
    "text": "other than in your script you can",
    "start": "415280",
    "end": "416639"
  },
  {
    "text": "reference a variable called input and it",
    "start": "416639",
    "end": "419199"
  },
  {
    "text": "will will have whatever you enter here",
    "start": "419199",
    "end": "420759"
  },
  {
    "text": "and you can also reference a variable",
    "start": "420759",
    "end": "422160"
  },
  {
    "text": "called output all uppercase and it has",
    "start": "422160",
    "end": "423960"
  },
  {
    "text": "whatever you put in here so in this case",
    "start": "423960",
    "end": "426400"
  },
  {
    "text": "the input I want to say comes from S3",
    "start": "426400",
    "end": "430360"
  },
  {
    "text": "and it's AWS test KK data that's the",
    "start": "430360",
    "end": "434080"
  },
  {
    "text": "directory that has the files in it and",
    "start": "434080",
    "end": "436360"
  },
  {
    "text": "the output location I'm saying I want to",
    "start": "436360",
    "end": "439759"
  },
  {
    "text": "go into the AWS test KK bucket and here",
    "start": "439759",
    "end": "443639"
  },
  {
    "text": "I wanted to put it in Hive",
    "start": "443639",
    "end": "447879"
  },
  {
    "text": "results now notice here and we'll talk",
    "start": "447879",
    "end": "450080"
  },
  {
    "text": "about this in a little bit um I have an",
    "start": "450080",
    "end": "451720"
  },
  {
    "text": "option of starting an interactive Hive",
    "start": "451720",
    "end": "453199"
  },
  {
    "text": "session where I'm not actually executing",
    "start": "453199",
    "end": "455400"
  },
  {
    "text": "a pre-created hive script I'm just",
    "start": "455400",
    "end": "457400"
  },
  {
    "text": "setting up to be able to work with the",
    "start": "457400",
    "end": "458919"
  },
  {
    "text": "hive interpreter to Define what goes",
    "start": "458919",
    "end": "461560"
  },
  {
    "text": "into a",
    "start": "461560",
    "end": "463080"
  },
  {
    "text": "script at this point I can set up the",
    "start": "463080",
    "end": "465479"
  },
  {
    "text": "size of my cluster I want it to be a",
    "start": "465479",
    "end": "467319"
  },
  {
    "text": "very small cluster so I'm only going to",
    "start": "467319",
    "end": "469000"
  },
  {
    "text": "have um a single slave uh which is an M1",
    "start": "469000",
    "end": "471720"
  },
  {
    "text": "small and my master is also an M1 small",
    "start": "471720",
    "end": "475840"
  },
  {
    "text": "no spot instances and no um task",
    "start": "475840",
    "end": "478960"
  },
  {
    "text": "instances",
    "start": "478960",
    "end": "481319"
  },
  {
    "text": "at this point just in case I wanted to",
    "start": "481440",
    "end": "483000"
  },
  {
    "text": "I'm going to set up uh an ec2 key pair",
    "start": "483000",
    "end": "485639"
  },
  {
    "text": "with a previously created key AWS test",
    "start": "485639",
    "end": "488280"
  },
  {
    "text": "which would let me log into the master",
    "start": "488280",
    "end": "490000"
  },
  {
    "text": "if I wanted to and right here I have to",
    "start": "490000",
    "end": "492639"
  },
  {
    "text": "specify where the logs are going to get",
    "start": "492639",
    "end": "494800"
  },
  {
    "text": "written",
    "start": "494800",
    "end": "495919"
  },
  {
    "text": "to I don't care about additional",
    "start": "495919",
    "end": "498080"
  },
  {
    "text": "debugging and I don't want the cluster",
    "start": "498080",
    "end": "499560"
  },
  {
    "text": "to stay alive when I'm",
    "start": "499560",
    "end": "501680"
  },
  {
    "text": "done I don't need any special bootstrap",
    "start": "501680",
    "end": "504240"
  },
  {
    "text": "actions for adjusting the configuration",
    "start": "504240",
    "end": "506479"
  },
  {
    "text": "of my",
    "start": "506479",
    "end": "508000"
  },
  {
    "text": "cluster now I can take a look at all",
    "start": "508000",
    "end": "510159"
  },
  {
    "text": "these settings here and make sure",
    "start": "510159",
    "end": "511319"
  },
  {
    "text": "they're right and once I'm pretty sure",
    "start": "511319",
    "end": "512719"
  },
  {
    "text": "they're right I'm going to create the",
    "start": "512719",
    "end": "514479"
  },
  {
    "text": "job",
    "start": "514479",
    "end": "516000"
  },
  {
    "text": "flow and what's going to happen here if",
    "start": "516000",
    "end": "519240"
  },
  {
    "text": "we view just the running ones this one",
    "start": "519240",
    "end": "521039"
  },
  {
    "text": "is going to start up and then it'll",
    "start": "521039",
    "end": "523159"
  },
  {
    "text": "switch from starting to running and",
    "start": "523159",
    "end": "526080"
  },
  {
    "text": "it'll start processing the data and then",
    "start": "526080",
    "end": "528399"
  },
  {
    "text": "when it's finished running that script",
    "start": "528399",
    "end": "530440"
  },
  {
    "text": "its status will change to um completed",
    "start": "530440",
    "end": "533839"
  },
  {
    "start": "533000",
    "end": "776000"
  },
  {
    "text": "now at this point I can monitor my job",
    "start": "533839",
    "end": "536360"
  },
  {
    "text": "we were looking there at the ads",
    "start": "536360",
    "end": "537600"
  },
  {
    "text": "Management console to see the state of",
    "start": "537600",
    "end": "539000"
  },
  {
    "text": "the job whether it was starting or",
    "start": "539000",
    "end": "540279"
  },
  {
    "text": "running or shutting down and how long it",
    "start": "540279",
    "end": "541880"
  },
  {
    "text": "had taken and the normalized instance",
    "start": "541880",
    "end": "544399"
  },
  {
    "text": "hours which gives me a sense of the cost",
    "start": "544399",
    "end": "546760"
  },
  {
    "text": "um I can terminate that job and I'm",
    "start": "546760",
    "end": "548920"
  },
  {
    "text": "going to show you something that we",
    "start": "548920",
    "end": "550240"
  },
  {
    "text": "covered in another module which is you",
    "start": "550240",
    "end": "551959"
  },
  {
    "text": "know how do I go about",
    "start": "551959",
    "end": "553680"
  },
  {
    "text": "actually watching the real Hadoop jobs",
    "start": "553680",
    "end": "557279"
  },
  {
    "text": "run which is sometimes a useful thing to",
    "start": "557279",
    "end": "558880"
  },
  {
    "text": "do in terms of",
    "start": "558880",
    "end": "561680"
  },
  {
    "text": "progress so we're back here we're still",
    "start": "562640",
    "end": "564560"
  },
  {
    "text": "starting up and if I click on this then",
    "start": "564560",
    "end": "567839"
  },
  {
    "text": "the key thing for me in the description",
    "start": "567839",
    "end": "569399"
  },
  {
    "text": "tab down here is whether I have a master",
    "start": "569399",
    "end": "571680"
  },
  {
    "text": "public DNS name once this gets set up",
    "start": "571680",
    "end": "574200"
  },
  {
    "text": "then I have the ability to actually set",
    "start": "574200",
    "end": "577240"
  },
  {
    "text": "up a proxy server so I can look at the",
    "start": "577240",
    "end": "579720"
  },
  {
    "text": "Hadoop GUI and uh get a better sense of",
    "start": "579720",
    "end": "582680"
  },
  {
    "text": "where my job is until it has a master",
    "start": "582680",
    "end": "585160"
  },
  {
    "text": "DNS name there's not a whole lot I can",
    "start": "585160",
    "end": "586519"
  },
  {
    "text": "do other than sort of watch it here and",
    "start": "586519",
    "end": "589959"
  },
  {
    "text": "the status here is still it's starting",
    "start": "589959",
    "end": "591760"
  },
  {
    "text": "up all the instances which is why I",
    "start": "591760",
    "end": "593800"
  },
  {
    "text": "don't yet have that Master DNS name that",
    "start": "593800",
    "end": "596040"
  },
  {
    "text": "I can use now at this point our job is",
    "start": "596040",
    "end": "598640"
  },
  {
    "text": "finally actually running if we select",
    "start": "598640",
    "end": "601720"
  },
  {
    "text": "the job flow here and we look down we'll",
    "start": "601720",
    "end": "603920"
  },
  {
    "text": "see that it's got this master public DNS",
    "start": "603920",
    "end": "605760"
  },
  {
    "text": "name that we",
    "start": "605760",
    "end": "607079"
  },
  {
    "text": "need if I copy this name and then I",
    "start": "607079",
    "end": "611040"
  },
  {
    "text": "switch over to a terminal window and in",
    "start": "611040",
    "end": "613720"
  },
  {
    "text": "here I say",
    "start": "613720",
    "end": "616440"
  },
  {
    "text": "SSH and I'm going to use the private key",
    "start": "616440",
    "end": "621160"
  },
  {
    "text": "pair from the key pair that I the",
    "start": "621160",
    "end": "623800"
  },
  {
    "text": "private key portion of the keyar that I",
    "start": "623800",
    "end": "625600"
  },
  {
    "text": "previously generated using the OS",
    "start": "625600",
    "end": "627279"
  },
  {
    "text": "Management console and then I do a",
    "start": "627279",
    "end": "630640"
  },
  {
    "text": "little uh special magic to set this",
    "start": "630640",
    "end": "634320"
  },
  {
    "text": "thing up to be a proxy and it's proxying",
    "start": "634320",
    "end": "637160"
  },
  {
    "text": "through Port",
    "start": "637160",
    "end": "638839"
  },
  {
    "text": "6666 and I always need to use the Hadoop",
    "start": "638839",
    "end": "641440"
  },
  {
    "text": "server here and that same Master public",
    "start": "641440",
    "end": "644240"
  },
  {
    "text": "DNS name and it'll ask me do I want to",
    "start": "644240",
    "end": "646959"
  },
  {
    "text": "add this to my list of known hosts I say",
    "start": "646959",
    "end": "648560"
  },
  {
    "text": "yes and at this point I'm proxying what",
    "start": "648560",
    "end": "651000"
  },
  {
    "text": "that means is back over here in the",
    "start": "651000",
    "end": "653560"
  },
  {
    "text": "browser because I've configured my",
    "start": "653560",
    "end": "655519"
  },
  {
    "text": "browser with foxy proxy to uh know about",
    "start": "655519",
    "end": "658800"
  },
  {
    "text": "Pro boxing through Port",
    "start": "658800",
    "end": "661760"
  },
  {
    "text": "6666 I actually have access to the H",
    "start": "661760",
    "end": "663920"
  },
  {
    "text": "doop",
    "start": "663920",
    "end": "664720"
  },
  {
    "text": "console and at this point right here",
    "start": "664720",
    "end": "666560"
  },
  {
    "text": "it's not yet running any jobs because",
    "start": "666560",
    "end": "668240"
  },
  {
    "text": "it's still figuring out which job or",
    "start": "668240",
    "end": "670600"
  },
  {
    "text": "jobs it needs to run so the hive is busy",
    "start": "670600",
    "end": "673320"
  },
  {
    "text": "doing that right now if I switch back",
    "start": "673320",
    "end": "675839"
  },
  {
    "text": "over here you can see it's only been",
    "start": "675839",
    "end": "677440"
  },
  {
    "text": "running for um two minutes but pretty",
    "start": "677440",
    "end": "680399"
  },
  {
    "text": "soon now it'll start actually running",
    "start": "680399",
    "end": "682519"
  },
  {
    "text": "jobs so it started running my first job",
    "start": "682519",
    "end": "685240"
  },
  {
    "text": "down here I'm again using the Hadoop go",
    "start": "685240",
    "end": "689240"
  },
  {
    "text": "to take a look at what's really going on",
    "start": "689240",
    "end": "690680"
  },
  {
    "text": "under the hood here when Hive has turned",
    "start": "690680",
    "end": "693399"
  },
  {
    "text": "my query into three map reduce jobs this",
    "start": "693399",
    "end": "697639"
  },
  {
    "text": "first job right here has just started so",
    "start": "697639",
    "end": "700920"
  },
  {
    "text": "it's busy reading from S3 so you can see",
    "start": "700920",
    "end": "703279"
  },
  {
    "text": "it's read about four Megs worth of S3",
    "start": "703279",
    "end": "706079"
  },
  {
    "text": "data if I refresh you can see that it",
    "start": "706079",
    "end": "708360"
  },
  {
    "text": "read all of the S3 data all 12 megabytes",
    "start": "708360",
    "end": "711440"
  },
  {
    "text": "of it the map is complete the reduce",
    "start": "711440",
    "end": "714639"
  },
  {
    "text": "hasn't quite uh started running yet see",
    "start": "714639",
    "end": "717519"
  },
  {
    "text": "that I have roughly 10,000 lines of",
    "start": "717519",
    "end": "719600"
  },
  {
    "text": "input data that's essentially that size",
    "start": "719600",
    "end": "721800"
  },
  {
    "text": "of that Wikipedia sample. XML",
    "start": "721800",
    "end": "724680"
  },
  {
    "text": "file if I refresh again you can see the",
    "start": "724680",
    "end": "727720"
  },
  {
    "text": "reduce is completed if I go back over to",
    "start": "727720",
    "end": "730399"
  },
  {
    "text": "main",
    "start": "730399",
    "end": "732160"
  },
  {
    "text": "view first job is",
    "start": "732160",
    "end": "734399"
  },
  {
    "text": "finished and it's setting up to run the",
    "start": "734399",
    "end": "736440"
  },
  {
    "text": "second",
    "start": "736440",
    "end": "737440"
  },
  {
    "text": "job if you go back over to the AWS",
    "start": "737440",
    "end": "739560"
  },
  {
    "text": "Management console you can see that",
    "start": "739560",
    "end": "740680"
  },
  {
    "text": "we're about four minutes in here total",
    "start": "740680",
    "end": "742680"
  },
  {
    "text": "time would be about I think 7",
    "start": "742680",
    "end": "744880"
  },
  {
    "text": "minutes at this point now we're done",
    "start": "744880",
    "end": "747199"
  },
  {
    "text": "running all three of the jobs the dupe",
    "start": "747199",
    "end": "749199"
  },
  {
    "text": "jobs that Hive had created in order to",
    "start": "749199",
    "end": "752680"
  },
  {
    "text": "fulfill the request I'd made the query",
    "start": "752680",
    "end": "755040"
  },
  {
    "text": "i' I'd given it and the hive lab. hql",
    "start": "755040",
    "end": "758240"
  },
  {
    "text": "file if we go back over to the AWS",
    "start": "758240",
    "end": "761079"
  },
  {
    "text": "Management console it says that the",
    "start": "761079",
    "end": "763079"
  },
  {
    "text": "status is still running the job itself",
    "start": "763079",
    "end": "765040"
  },
  {
    "text": "is finished but what it's doing is it's",
    "start": "765040",
    "end": "767199"
  },
  {
    "text": "copying logs over into S3 and then you",
    "start": "767199",
    "end": "770720"
  },
  {
    "text": "just saw it switched the state to",
    "start": "770720",
    "end": "773000"
  },
  {
    "text": "shutting down so now it's terminating",
    "start": "773000",
    "end": "774480"
  },
  {
    "text": "the",
    "start": "774480",
    "end": "776040"
  },
  {
    "text": "cluster similar to when you're running",
    "start": "776040",
    "end": "778959"
  },
  {
    "text": "regular Java code regular Hadoop jobs at",
    "start": "778959",
    "end": "782000"
  },
  {
    "text": "the end of a hive job flow the cluster",
    "start": "782000",
    "end": "784680"
  },
  {
    "text": "goes away unless you say that you want",
    "start": "784680",
    "end": "785959"
  },
  {
    "text": "to keep it running so that means uh",
    "start": "785959",
    "end": "788480"
  },
  {
    "text": "anything that you've created any tables",
    "start": "788480",
    "end": "790399"
  },
  {
    "text": "you've created in Hive that by default",
    "start": "790399",
    "end": "792120"
  },
  {
    "text": "have gone into hdfs get tossed so that",
    "start": "792120",
    "end": "794480"
  },
  {
    "text": "means you need to wind up putting the",
    "start": "794480",
    "end": "796839"
  },
  {
    "text": "end results somewhere in S3 or some",
    "start": "796839",
    "end": "799680"
  },
  {
    "text": "other place that's going to",
    "start": "799680",
    "end": "801440"
  },
  {
    "text": "persist the other thing is that the",
    "start": "801440",
    "end": "803760"
  },
  {
    "text": "Hadoop log files have automatically been",
    "start": "803760",
    "end": "805760"
  },
  {
    "text": "copied for me by elastic map ruce into",
    "start": "805760",
    "end": "808360"
  },
  {
    "text": "S3 into that location that I specified",
    "start": "808360",
    "end": "810839"
  },
  {
    "text": "when I was defining the high of job flow",
    "start": "810839",
    "end": "813120"
  },
  {
    "text": "so we can go take a look at that",
    "start": "813120",
    "end": "814880"
  },
  {
    "text": "now so over here if I go over to",
    "start": "814880",
    "end": "819040"
  },
  {
    "text": "S3 and I see my list of buckets down the",
    "start": "819920",
    "end": "822440"
  },
  {
    "text": "left side the one we've been using is aw",
    "start": "822440",
    "end": "825240"
  },
  {
    "text": "test AWS test KK in here I've got my",
    "start": "825240",
    "end": "829560"
  },
  {
    "text": "hive results and there's a file here",
    "start": "829560",
    "end": "831759"
  },
  {
    "text": "with six zeros in its name this is the",
    "start": "831759",
    "end": "833759"
  },
  {
    "text": "actual table that I created as a result",
    "start": "833759",
    "end": "835839"
  },
  {
    "text": "of my hive query and if I open this up",
    "start": "835839",
    "end": "840320"
  },
  {
    "text": "it's going to display it uh since it's",
    "start": "840320",
    "end": "843199"
  },
  {
    "text": "uh an unknown format I'll I'll open it",
    "start": "843199",
    "end": "845880"
  },
  {
    "text": "up using BB edit and what it has here is",
    "start": "845880",
    "end": "848360"
  },
  {
    "text": "a",
    "start": "848360",
    "end": "849160"
  },
  {
    "text": "list of the top contributors to",
    "start": "849160",
    "end": "852000"
  },
  {
    "text": "Wikipedia at least the the most recent",
    "start": "852000",
    "end": "854160"
  },
  {
    "text": "edits for files and their counts and",
    "start": "854160",
    "end": "856399"
  },
  {
    "text": "many of these are Bots which means",
    "start": "856399",
    "end": "858480"
  },
  {
    "text": "they're automatically doing things but",
    "start": "858480",
    "end": "859800"
  },
  {
    "text": "you can see there are some um actual",
    "start": "859800",
    "end": "861600"
  },
  {
    "text": "users who have made a lot of changes and",
    "start": "861600",
    "end": "865279"
  },
  {
    "text": "some of these users have very",
    "start": "865279",
    "end": "866399"
  },
  {
    "text": "interesting names the other I can look",
    "start": "866399",
    "end": "869240"
  },
  {
    "text": "at is the logs for the for for the jobs",
    "start": "869240",
    "end": "872680"
  },
  {
    "text": "that I did so if I look here in the logs",
    "start": "872680",
    "end": "875560"
  },
  {
    "text": "directory um inside of here each one of",
    "start": "875560",
    "end": "878440"
  },
  {
    "text": "these is from a different run that I did",
    "start": "878440",
    "end": "880160"
  },
  {
    "text": "a different job flow the job flow we",
    "start": "880160",
    "end": "882000"
  },
  {
    "text": "just ran had a job ID of j-v I blah blah",
    "start": "882000",
    "end": "885680"
  },
  {
    "text": "blah if I open this up most interesting",
    "start": "885680",
    "end": "888639"
  },
  {
    "text": "is inside of this steps directory I look",
    "start": "888639",
    "end": "891120"
  },
  {
    "text": "in the steps directory step one was a",
    "start": "891120",
    "end": "892920"
  },
  {
    "text": "step of setting up Hive step two is my",
    "start": "892920",
    "end": "895800"
  },
  {
    "text": "actual uh sort of flow that ran",
    "start": "895800",
    "end": "899800"
  },
  {
    "text": "in here Hive actually puts a lot of its",
    "start": "899800",
    "end": "902160"
  },
  {
    "text": "information into standard error so if I",
    "start": "902160",
    "end": "903880"
  },
  {
    "text": "open up standard error and I take a look",
    "start": "903880",
    "end": "906360"
  },
  {
    "text": "at",
    "start": "906360",
    "end": "908040"
  },
  {
    "text": "this you'll see here that it's a bunch",
    "start": "908040",
    "end": "910240"
  },
  {
    "text": "of output from hive and remember how",
    "start": "910240",
    "end": "912639"
  },
  {
    "text": "when we're looking at the job using the",
    "start": "912639",
    "end": "915120"
  },
  {
    "text": "Hadoop GUI we see there actually were",
    "start": "915120",
    "end": "916680"
  },
  {
    "text": "three jobs so here's the first job",
    "start": "916680",
    "end": "920040"
  },
  {
    "text": "here's the second job and there's the",
    "start": "920040",
    "end": "922240"
  },
  {
    "text": "third",
    "start": "922240",
    "end": "924519"
  },
  {
    "text": "job now the kind of job we ran there is",
    "start": "925639",
    "end": "928399"
  },
  {
    "start": "926000",
    "end": "981000"
  },
  {
    "text": "one where we already have a fully",
    "start": "928399",
    "end": "930240"
  },
  {
    "text": "debugged Hive script that HIV lab. hql",
    "start": "930240",
    "end": "934639"
  },
  {
    "text": "file and that's great for when you've",
    "start": "934639",
    "end": "937160"
  },
  {
    "text": "got something that's in production right",
    "start": "937160",
    "end": "939160"
  },
  {
    "text": "so you're doing batch processing using",
    "start": "939160",
    "end": "940639"
  },
  {
    "text": "Hive but the act of developing Hive",
    "start": "940639",
    "end": "943560"
  },
  {
    "text": "scripts as anybody who actually has done",
    "start": "943560",
    "end": "945399"
  },
  {
    "text": "it knows has a lot of trial and errors",
    "start": "945399",
    "end": "947240"
  },
  {
    "text": "you're trying to get the query right and",
    "start": "947240",
    "end": "948560"
  },
  {
    "text": "you're trying to get all your parameters",
    "start": "948560",
    "end": "949680"
  },
  {
    "text": "set up properly and the issue is if",
    "start": "949680",
    "end": "952519"
  },
  {
    "text": "you're trying to use the uh approach of",
    "start": "952519",
    "end": "957000"
  },
  {
    "text": "taking uh hive job flows and giving it a",
    "start": "957000",
    "end": "960759"
  },
  {
    "text": "script and running it is that when your",
    "start": "960759",
    "end": "962160"
  },
  {
    "text": "script has an error your cluster finally",
    "start": "962160",
    "end": "965120"
  },
  {
    "text": "fires up after a couple minutes and then",
    "start": "965120",
    "end": "967600"
  },
  {
    "text": "boom immediately has a problem and it",
    "start": "967600",
    "end": "969880"
  },
  {
    "text": "fails and you've paid for the time that",
    "start": "969880",
    "end": "972959"
  },
  {
    "text": "your cluster has spent uh in one hour",
    "start": "972959",
    "end": "975560"
  },
  {
    "text": "increments so you pay this it's called",
    "start": "975560",
    "end": "977560"
  },
  {
    "text": "the 10-second",
    "start": "977560",
    "end": "979040"
  },
  {
    "text": "penalty you pay for a full hour no",
    "start": "979040",
    "end": "981120"
  },
  {
    "start": "981000",
    "end": "1263000"
  },
  {
    "text": "matter what so in that case the solution",
    "start": "981120",
    "end": "983519"
  },
  {
    "text": "is you start up an interactive session",
    "start": "983519",
    "end": "986680"
  },
  {
    "text": "and then you fire up the hive and",
    "start": "986680",
    "end": "988759"
  },
  {
    "text": "interpreter uh via the command line tool",
    "start": "988759",
    "end": "991880"
  },
  {
    "text": "and this then lets you try out scripts",
    "start": "991880",
    "end": "996199"
  },
  {
    "text": "interactively so what you need to do is",
    "start": "996199",
    "end": "999160"
  },
  {
    "text": "you start up your EMR cluster your",
    "start": "999160",
    "end": "1000959"
  },
  {
    "text": "elastic map produce Hive cluster um in a",
    "start": "1000959",
    "end": "1004639"
  },
  {
    "text": "sort of Stay Alive mode and you don't",
    "start": "1004639",
    "end": "1007000"
  },
  {
    "text": "actually run a script after it's done",
    "start": "1007000",
    "end": "1009279"
  },
  {
    "text": "that then you SSH into the master which",
    "start": "1009279",
    "end": "1012160"
  },
  {
    "text": "means that when you set this job flow up",
    "start": "1012160",
    "end": "1014680"
  },
  {
    "text": "you must specify a key pair so that you",
    "start": "1014680",
    "end": "1017000"
  },
  {
    "text": "can use that private key to SSH into the",
    "start": "1017000",
    "end": "1019240"
  },
  {
    "text": "master and then when you're in there you",
    "start": "1019240",
    "end": "1021240"
  },
  {
    "text": "start running the hive interpreter and",
    "start": "1021240",
    "end": "1023079"
  },
  {
    "text": "then when you're done you have to",
    "start": "1023079",
    "end": "1023920"
  },
  {
    "text": "remember of course to terminate this job",
    "start": "1023920",
    "end": "1025918"
  },
  {
    "text": "flow so we're going to go give that a",
    "start": "1025919",
    "end": "1027640"
  },
  {
    "text": "try",
    "start": "1027640",
    "end": "1029880"
  },
  {
    "text": "now so I'm going to switch back over to",
    "start": "1031640",
    "end": "1033760"
  },
  {
    "text": "the elastic map produce Tab and I'm",
    "start": "1033760",
    "end": "1036079"
  },
  {
    "text": "going to create a new job flow in this",
    "start": "1036079",
    "end": "1038520"
  },
  {
    "text": "case I'm going to call it Hive",
    "start": "1038520",
    "end": "1043438"
  },
  {
    "text": "development and I still set the type to",
    "start": "1043439",
    "end": "1045760"
  },
  {
    "text": "be a hive program but in the very next",
    "start": "1045760",
    "end": "1048720"
  },
  {
    "text": "screen here instead of executing a hive",
    "start": "1048720",
    "end": "1051039"
  },
  {
    "text": "script I say I want to run an",
    "start": "1051039",
    "end": "1052960"
  },
  {
    "text": "interactive Hive",
    "start": "1052960",
    "end": "1054679"
  },
  {
    "text": "session now I still get to specify the",
    "start": "1054679",
    "end": "1056880"
  },
  {
    "text": "size of my cluster so I'm going to make",
    "start": "1056880",
    "end": "1058080"
  },
  {
    "text": "it really",
    "start": "1058080",
    "end": "1059640"
  },
  {
    "text": "small and of course I better set up an",
    "start": "1059640",
    "end": "1062400"
  },
  {
    "text": "ec2 key pair so I can actually log into",
    "start": "1062400",
    "end": "1064559"
  },
  {
    "text": "the",
    "start": "1064559",
    "end": "1065440"
  },
  {
    "text": "master uh here I don't need any",
    "start": "1065440",
    "end": "1067679"
  },
  {
    "text": "additional debugging I don't really care",
    "start": "1067679",
    "end": "1069360"
  },
  {
    "text": "where the logs",
    "start": "1069360",
    "end": "1070960"
  },
  {
    "text": "go I don't need any special bootstrap",
    "start": "1070960",
    "end": "1073760"
  },
  {
    "text": "actions I can check my things here and I",
    "start": "1073760",
    "end": "1076159"
  },
  {
    "text": "can create that job flow and and it'll",
    "start": "1076159",
    "end": "1080880"
  },
  {
    "text": "take couple minutes for it to set up the",
    "start": "1081080",
    "end": "1083799"
  },
  {
    "text": "cluster and configure Hive and at that",
    "start": "1083799",
    "end": "1085520"
  },
  {
    "text": "point then once again I have a",
    "start": "1085520",
    "end": "1090000"
  },
  {
    "text": "master uh public DNS name down here then",
    "start": "1090000",
    "end": "1093000"
  },
  {
    "text": "I can use that along with my private key",
    "start": "1093000",
    "end": "1095280"
  },
  {
    "text": "to log into the master and start running",
    "start": "1095280",
    "end": "1097360"
  },
  {
    "text": "the hive",
    "start": "1097360",
    "end": "1098960"
  },
  {
    "text": "interpreter and you'll see that the",
    "start": "1098960",
    "end": "1100760"
  },
  {
    "text": "state changed to running even though I",
    "start": "1100760",
    "end": "1103400"
  },
  {
    "text": "didn't actually give it a script to run",
    "start": "1103400",
    "end": "1105159"
  },
  {
    "text": "the issue is it's running the first step",
    "start": "1105159",
    "end": "1106880"
  },
  {
    "text": "which is the step that is configured",
    "start": "1106880",
    "end": "1108360"
  },
  {
    "text": "heing Hive once it's finished that first",
    "start": "1108360",
    "end": "1110600"
  },
  {
    "text": "step then the state will change to",
    "start": "1110600",
    "end": "1112799"
  },
  {
    "text": "waiting and at that point it's ready for",
    "start": "1112799",
    "end": "1115400"
  },
  {
    "text": "me to start interacting with the hive",
    "start": "1115400",
    "end": "1117679"
  },
  {
    "text": "interpreter we're finally ready status",
    "start": "1117679",
    "end": "1120120"
  },
  {
    "text": "changed the waiting down here you can",
    "start": "1120120",
    "end": "1122159"
  },
  {
    "text": "see that I have that Master public DNS",
    "start": "1122159",
    "end": "1124520"
  },
  {
    "text": "name so I'm going to copy",
    "start": "1124520",
    "end": "1127200"
  },
  {
    "text": "that and now I'm going to switch over to",
    "start": "1127200",
    "end": "1129600"
  },
  {
    "text": "the terminal and",
    "start": "1129600",
    "end": "1131919"
  },
  {
    "text": "here same as before I'm going to sh ssh",
    "start": "1131919",
    "end": "1135000"
  },
  {
    "text": "in using the private key that I",
    "start": "1135000",
    "end": "1138320"
  },
  {
    "text": "previously downloaded when I defined a",
    "start": "1138320",
    "end": "1139880"
  },
  {
    "text": "public private key pair and using the",
    "start": "1139880",
    "end": "1143000"
  },
  {
    "text": "AWS Management console and then I log in",
    "start": "1143000",
    "end": "1145320"
  },
  {
    "text": "as the Hadoop user to that same",
    "start": "1145320",
    "end": "1149880"
  },
  {
    "text": "server at this point you can see I'm",
    "start": "1151080",
    "end": "1153039"
  },
  {
    "text": "logged",
    "start": "1153039",
    "end": "1153919"
  },
  {
    "text": "in and now I can start running",
    "start": "1153919",
    "end": "1157960"
  },
  {
    "text": "hive",
    "start": "1167240",
    "end": "1168840"
  },
  {
    "text": "so it's a regular Hive interpreter I can",
    "start": "1168840",
    "end": "1170320"
  },
  {
    "text": "do things like say show me the tables",
    "start": "1170320",
    "end": "1173159"
  },
  {
    "text": "that I've currently got",
    "start": "1173159",
    "end": "1175880"
  },
  {
    "text": "defined and I see that I've got no",
    "start": "1176000",
    "end": "1178840"
  },
  {
    "text": "tables from here I can do things like I",
    "start": "1178840",
    "end": "1181320"
  },
  {
    "text": "can Source",
    "start": "1181320",
    "end": "1182640"
  },
  {
    "text": "scripts I can do uh all the usual Hive",
    "start": "1182640",
    "end": "1185760"
  },
  {
    "text": "commands for example I could create a",
    "start": "1185760",
    "end": "1189039"
  },
  {
    "text": "table I could type called um I don't",
    "start": "1189039",
    "end": "1193360"
  },
  {
    "text": "know test and it's got a field name of",
    "start": "1193360",
    "end": "1196960"
  },
  {
    "text": "type string and age of type",
    "start": "1196960",
    "end": "1201480"
  },
  {
    "text": "int great I've defined a table so now if",
    "start": "1201480",
    "end": "1203760"
  },
  {
    "text": "I do show",
    "start": "1203760",
    "end": "1205880"
  },
  {
    "text": "tables it shows that I've got a table",
    "start": "1205880",
    "end": "1207840"
  },
  {
    "text": "called test I could insert data into",
    "start": "1207840",
    "end": "1210039"
  },
  {
    "text": "that table um I can start executing",
    "start": "1210039",
    "end": "1212960"
  },
  {
    "text": "commands to Define new tables based on",
    "start": "1212960",
    "end": "1215600"
  },
  {
    "text": "the results of queries against that",
    "start": "1215600",
    "end": "1217520"
  },
  {
    "text": "table I can source and then here for",
    "start": "1217520",
    "end": "1220480"
  },
  {
    "text": "example I could put in uh a path uh into",
    "start": "1220480",
    "end": "1224360"
  },
  {
    "text": "S3 of a script and what it would do then",
    "start": "1224360",
    "end": "1227360"
  },
  {
    "text": "it was a it would um essentially execute",
    "start": "1227360",
    "end": "1230200"
  },
  {
    "text": "that Hive script for me and when I'm",
    "start": "1230200",
    "end": "1233760"
  },
  {
    "text": "done I can say exit and I'm back now uh",
    "start": "1233760",
    "end": "1240159"
  },
  {
    "text": "at the command line prompt on the master",
    "start": "1240159",
    "end": "1243559"
  },
  {
    "text": "server that I logged into so I need to",
    "start": "1243559",
    "end": "1245919"
  },
  {
    "text": "exit out of here to really get back all",
    "start": "1245919",
    "end": "1248440"
  },
  {
    "text": "the way out and then once I'm done using",
    "start": "1248440",
    "end": "1252799"
  },
  {
    "text": "Hive um I of course want to terminate",
    "start": "1252799",
    "end": "1255240"
  },
  {
    "text": "this cluster so if I select it then I",
    "start": "1255240",
    "end": "1257679"
  },
  {
    "text": "can click up up here terminate it'll say",
    "start": "1257679",
    "end": "1259159"
  },
  {
    "text": "do I really want to terminate I say yes",
    "start": "1259159",
    "end": "1260960"
  },
  {
    "text": "and the state changes to shutting down",
    "start": "1260960",
    "end": "1263720"
  },
  {
    "start": "1263000",
    "end": "1300000"
  },
  {
    "text": "all the stuff we've been talking about",
    "start": "1263720",
    "end": "1264960"
  },
  {
    "text": "pretty much has had to do with Hive pig",
    "start": "1264960",
    "end": "1267120"
  },
  {
    "text": "is very similar uh when you create your",
    "start": "1267120",
    "end": "1269919"
  },
  {
    "text": "job flow you have the option of saying",
    "start": "1269919",
    "end": "1272000"
  },
  {
    "text": "this is Pig instead of Hive you have an",
    "start": "1272000",
    "end": "1275360"
  },
  {
    "text": "interactive mode similar to Hive where",
    "start": "1275360",
    "end": "1277360"
  },
  {
    "text": "you can work on developing your pig",
    "start": "1277360",
    "end": "1279360"
  },
  {
    "text": "scripts um you know just is some obvious",
    "start": "1279360",
    "end": "1282520"
  },
  {
    "text": "differences like if you're executing a",
    "start": "1282520",
    "end": "1284240"
  },
  {
    "text": "script file then it's going to be Pig",
    "start": "1284240",
    "end": "1286080"
  },
  {
    "text": "Latin uh in there not high ql and uh",
    "start": "1286080",
    "end": "1290440"
  },
  {
    "text": "there's an example of parsing log files",
    "start": "1290440",
    "end": "1292720"
  },
  {
    "text": "using Pig for those of you who want to",
    "start": "1292720",
    "end": "1294080"
  },
  {
    "text": "try out Pig and uh elastic map reduce",
    "start": "1294080",
    "end": "1296720"
  },
  {
    "text": "and the URL to it is there at the bottom",
    "start": "1296720",
    "end": "1299360"
  },
  {
    "text": "of the slide",
    "start": "1299360",
    "end": "1302960"
  }
]
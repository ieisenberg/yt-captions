[
  {
    "text": "hello everybody thank you for joining us tonight my name is Jamie Kinney I'm the principal project manager for a batch",
    "start": "120",
    "end": "5549"
  },
  {
    "text": "and high-performance computing at Amazon and like to thank you for attending our talk today we're gonna be joined by",
    "start": "5549",
    "end": "11670"
  },
  {
    "text": "several people a few of whom are on the stage today so we'll have three of our of our customers presenting on their",
    "start": "11670",
    "end": "17820"
  },
  {
    "text": "usage of eight of us batch we're going to from Admiral have Miko Yola in the",
    "start": "17820",
    "end": "24150"
  },
  {
    "text": "red shirt over here Oleg's in the front row over there he'll be joining us for Q&A at the end",
    "start": "24150",
    "end": "29400"
  },
  {
    "text": "from base to genomics Ryan's gonna be presenting and also joined by Aaron",
    "start": "29400",
    "end": "35550"
  },
  {
    "text": "Quinlan and Brent Peterson also sitting in the front desk all three co-founders base-2 and then Dino from from Autodesk",
    "start": "35550",
    "end": "43489"
  },
  {
    "text": "so thank you for for joining us today so for today's talk I wanted to just start",
    "start": "43489",
    "end": "51480"
  },
  {
    "text": "off with a quick recap of some of the features that we've launched with AWS patch over the past year bring you up to",
    "start": "51480",
    "end": "56670"
  },
  {
    "text": "speed on what's new in the 12 months since we launched the service at last year's reinvent before going into a",
    "start": "56670",
    "end": "63629"
  },
  {
    "text": "glimpse of our roadmap talking about it in depth about a feature that we've actually just launched in the past 30",
    "start": "63629",
    "end": "69180"
  },
  {
    "text": "minutes and then go into into detail and how our actual customers are using the service and give them the majority of",
    "start": "69180",
    "end": "74790"
  },
  {
    "text": "the time today before that course saving some time for it for Q&A so just a quick",
    "start": "74790",
    "end": "80189"
  },
  {
    "text": "reminder and talking about what led us to build the a DBS batch service we're",
    "start": "80189",
    "end": "85350"
  },
  {
    "text": "we switch I'll do it sorry AWS patch as you probably know",
    "start": "85350",
    "end": "91860"
  },
  {
    "text": "given your interest in the session is the service that we launched last year with a goal of of helping you greatly",
    "start": "91860",
    "end": "99060"
  },
  {
    "text": "simplify batch processing in the cloud if you had wanted to run batch processing workloads on Amazon before we",
    "start": "99060",
    "end": "107040"
  },
  {
    "text": "launched the DBS batch service and you worked with us we would likely have been start to do on how to combine about a dozen different services and we",
    "start": "107040",
    "end": "113490"
  },
  {
    "text": "recognized after helping tens of hundreds of customers implement very similar solutions that we really needed",
    "start": "113490",
    "end": "119729"
  },
  {
    "text": "to help by offering higher level primitives and so the goal of a DBS batch is to provide a fully managed",
    "start": "119729",
    "end": "125670"
  },
  {
    "text": "platform that helps you reduce costs by making it easy to take advantage of low cost easy to spot instances by",
    "start": "125670",
    "end": "132360"
  },
  {
    "text": "automatically up and down resources taking advantage of things like per second billing which",
    "start": "132360",
    "end": "137560"
  },
  {
    "text": "which we launched in the past year and also making it very easy for your jobs to securely and easily authenticate and",
    "start": "137560",
    "end": "144310"
  },
  {
    "text": "leverage other services offered by Amazon things like Amazon DynamoDB or recognition and so now getting into the",
    "start": "144310",
    "end": "151570"
  },
  {
    "text": "the summary of the launches for the past year when we launched batch this time last year we launched in the u.s. East",
    "start": "151570",
    "end": "157090"
  },
  {
    "text": "one Northern Virginia region we're now in nine regions in total and you can",
    "start": "157090",
    "end": "162640"
  },
  {
    "text": "expect that will will continue that regional expansion getting into the remainder of AWS regions early in 2018",
    "start": "162640",
    "end": "169950"
  },
  {
    "text": "we had a big focus very early on to to make manage compute environments work better in batch for many of you we heard",
    "start": "169950",
    "end": "177370"
  },
  {
    "text": "that it was important that not only do we support the ECS optimized Amazon machine image but then we also give you",
    "start": "177370",
    "end": "183610"
  },
  {
    "text": "the freedom to be able to provide your own machine image and manage compute environments and in doing so we give you",
    "start": "183610",
    "end": "189280"
  },
  {
    "text": "the ability to do things like automatically mount elastic file systems to be able to configure encryption in in",
    "start": "189280",
    "end": "195670"
  },
  {
    "text": "the way that you prefer to be able to use the operating system of your choice to be able to use more faster bigger",
    "start": "195670",
    "end": "201400"
  },
  {
    "text": "different types of EBS volumes as well as if you want to run GPU or FPGA",
    "start": "201400",
    "end": "206680"
  },
  {
    "text": "accelerated workloads so very important capability so that was at it back in March and then over the course of the",
    "start": "206680",
    "end": "211990"
  },
  {
    "text": "year and up to even today we've worked to support additional instance types as",
    "start": "211990",
    "end": "217690"
  },
  {
    "text": "they've as they become available so as of today you can also now of course launch the c5 instances in your managed",
    "start": "217690",
    "end": "223959"
  },
  {
    "text": "compute environments and then a major area that we focused on is the way that",
    "start": "223959",
    "end": "230440"
  },
  {
    "text": "scheduling and resource provisioning works with a native us batch when we first envisioned the service our target",
    "start": "230440",
    "end": "236680"
  },
  {
    "text": "was to support jobs that lasted for 15 minutes or longer and on day one",
    "start": "236680",
    "end": "242170"
  },
  {
    "text": "probably a few people in the room started submitting jobs that lasted only a fraction of a second and wondered why",
    "start": "242170",
    "end": "247570"
  },
  {
    "text": "we weren't very efficient at utilizing the resources that we were scaling up and so we we focused pretty pretty",
    "start": "247570",
    "end": "254410"
  },
  {
    "text": "heavily over the course of the past year to support shorter duration jobs and so now with jobs that last as short as just",
    "start": "254410",
    "end": "260169"
  },
  {
    "text": "a couple of seconds we can easily obtain about 90% utilization of the computer",
    "start": "260169",
    "end": "265540"
  },
  {
    "text": "is that we provision for you so batch is now a platform that can handle jobs lasting just a couple of seconds to two",
    "start": "265540",
    "end": "270790"
  },
  {
    "text": "months if you like and then finally additional capabilities around tagging",
    "start": "270790",
    "end": "277000"
  },
  {
    "text": "both Neos pod and non spot resources on the manageability side we added the",
    "start": "277000",
    "end": "282580"
  },
  {
    "text": "ability to automatically retry jobs so if your job fails due to a spot termination or if you have an application error you can with your job",
    "start": "282580",
    "end": "290440"
  },
  {
    "text": "submission specify a number of times you'd like us to retry your job if it fails we'll move it back to the head of the queue and then added support within",
    "start": "290440",
    "end": "298270"
  },
  {
    "text": "a TBS cloud formation terraform also supports AWS patch and a big launch was",
    "start": "298270",
    "end": "304210"
  },
  {
    "text": "the ability to use event-driven models with a DBS patch so and that means two",
    "start": "304210",
    "end": "309550"
  },
  {
    "text": "things on one side it's being able to receive events as your jobs transition from one state to another so when your",
    "start": "309550",
    "end": "315970"
  },
  {
    "text": "job goes from runnable to starting to running at each of those state transitions will emit an event telling",
    "start": "315970",
    "end": "321700"
  },
  {
    "text": "you the time that occurred the new state of your job and the payload will include the output of the describe jobs API",
    "start": "321700",
    "end": "328090"
  },
  {
    "text": "response and that means you can then set up filters that say tell me about any job that failed with this particular",
    "start": "328090",
    "end": "334470"
  },
  {
    "text": "failure code and and maybe send this to an SNS queue so that I can do manual",
    "start": "334470",
    "end": "340030"
  },
  {
    "text": "investigation of this or if I have a job that matches a particular job definition and it succeeds send me an event so that",
    "start": "340030",
    "end": "346360"
  },
  {
    "text": "I can then trigger a step functions flow to perform additional operations so",
    "start": "346360",
    "end": "351970"
  },
  {
    "text": "that's one side of the event-driven architecture talked a little bit as we get into the roadmap about future",
    "start": "351970",
    "end": "358060"
  },
  {
    "text": "capabilities that allow batch to be used and in response to events that are being generated and then on the the regulatory",
    "start": "358060",
    "end": "366340"
  },
  {
    "text": "and compliance front we focused very early on in the service to ensure the batch is covered as part of the the",
    "start": "366340",
    "end": "372100"
  },
  {
    "text": "HIPAA business associates agreement we're working on additional certifications and additional auditing",
    "start": "372100",
    "end": "378100"
  },
  {
    "text": "and compliance capabilities for batch very important as you'll hear from base to genomics in just a bit and then",
    "start": "378100",
    "end": "385150"
  },
  {
    "text": "getting back to the original design of batch when we were talking to a number of early beta customers of 80s batch we",
    "start": "385150",
    "end": "392460"
  },
  {
    "text": "wondered if we should have an API for submitting workflows or DAGs in addition to the submit job API that we have",
    "start": "392460",
    "end": "398920"
  },
  {
    "text": "today and in those conversations it became pretty clear that we probably shouldn't be too opinionated about how",
    "start": "398920",
    "end": "405340"
  },
  {
    "text": "workflows are executed that that would be executed by a dispatch and so we focused on a model that lets you express",
    "start": "405340",
    "end": "411880"
  },
  {
    "text": "interdependencies between jobs so submit jobs one two and three telling us that three depends on two and two depends on",
    "start": "411880",
    "end": "417910"
  },
  {
    "text": "one so if you have a very deterministic workflow you can you can manage that fully with an AWS batch if on the other",
    "start": "417910",
    "end": "425170"
  },
  {
    "text": "hand you're you have a more complex workflow or non-deterministic workflow that's where integration with step",
    "start": "425170",
    "end": "431440"
  },
  {
    "text": "functions comes into play and so we had a very popular compute blog post with a corresponding github repo that shows you",
    "start": "431440",
    "end": "438520"
  },
  {
    "text": "exactly how to integrate a TBS step functions or the workflow engine of your choice with AWS batch in this time using",
    "start": "438520",
    "end": "445320"
  },
  {
    "text": "lambda as the intermediary between step functions and AWS batch so you have as",
    "start": "445320",
    "end": "452290"
  },
  {
    "text": "you proceed from from state to state within your step functions workflow lambda functions are invoked which we'll",
    "start": "452290",
    "end": "458830"
  },
  {
    "text": "call the submit job API for AWS batch we have a pattern or a blueprint in the",
    "start": "458830",
    "end": "464290"
  },
  {
    "text": "lambic console that makes it easy for you to both submit jobs and query the the status of your jobs now that we've",
    "start": "464290",
    "end": "470140"
  },
  {
    "text": "moved to an event-driven model instead of having to pull every 30 second say for the status of your jobs you can",
    "start": "470140",
    "end": "475300"
  },
  {
    "text": "simply have step functions listen for the event that we emit when your job either succeeds or fails now that that's",
    "start": "475300",
    "end": "482680"
  },
  {
    "text": "really helpful but we have a lot of customers that are running thousands and tens of thousands of jobs on a DBS batch",
    "start": "482680",
    "end": "489160"
  },
  {
    "text": "on a daily basis and we thought that there was a way that we could we could simplify this as well and so we hinted about this a little bit when we",
    "start": "489160",
    "end": "495250"
  },
  {
    "text": "announced the service but but happy to announce that today we have a new feature for batch called array jobs so",
    "start": "495250",
    "end": "501700"
  },
  {
    "text": "array jobs is a way for you to very easily with a single submit job API call submit 10,000 copies of a job so every",
    "start": "501700",
    "end": "509980"
  },
  {
    "text": "job is identical in terms of the the command that it executes the CPU and memory the environment variables the",
    "start": "509980",
    "end": "515650"
  },
  {
    "text": "parameters everything else associated with the job except that will create as",
    "start": "515650",
    "end": "520690"
  },
  {
    "text": "many copies as we've specified up to 10,000 initially and then every job will get an extra environment variable that",
    "start": "520690",
    "end": "526870"
  },
  {
    "text": "tells you the index within the array and so you can use that index environment variable to be",
    "start": "526870",
    "end": "531930"
  },
  {
    "text": "a hashing algorithm to get copy specific behavior or use that as a key to look up",
    "start": "531930",
    "end": "536940"
  },
  {
    "text": "a copy of specific behavior from dynamodb or from a CSV file that you're storing an s3 that's one of the",
    "start": "536940",
    "end": "542370"
  },
  {
    "text": "parameters for your job and so what this means that if you submit a job that has you have job B is the name and it has a",
    "start": "542370",
    "end": "549089"
  },
  {
    "text": "job ID with a string of digits and some hyphens on it will create with ten copies you'll have elements you'll have",
    "start": "549089",
    "end": "557010"
  },
  {
    "text": "ten jobs in your queue with that same job ID but : 0 : 1 : 2 through 9 and you",
    "start": "557010",
    "end": "565709"
  },
  {
    "text": "can of course submit these jobs using the the ADB OS batch console here's where you would specify the the array",
    "start": "565709",
    "end": "571980"
  },
  {
    "text": "size but you'll notice oh we also have some updates to the dependency model with with batch with array job",
    "start": "571980",
    "end": "579720"
  },
  {
    "text": "submissions so I'd like to talk about those in a little bit more detail now so here's a very simple array job",
    "start": "579720",
    "end": "586320"
  },
  {
    "text": "submission the the interesting bits are happening right here where you specify the array properties and the the number",
    "start": "586320",
    "end": "593130"
  },
  {
    "text": "of copies you'd like to have in your array job and but you can also express",
    "start": "593130",
    "end": "599310"
  },
  {
    "text": "dependencies so you in this example you can have an array job that has 100 elements in this example being submitted",
    "start": "599310",
    "end": "606089"
  },
  {
    "text": "by you know with a name of job a and then you can have an on or a job at a single copy job that will only begin to",
    "start": "606089",
    "end": "613260"
  },
  {
    "text": "execute once all elements have completed within the initial array job you can invert this and have an array job of",
    "start": "613260",
    "end": "619500"
  },
  {
    "text": "course that only starts one set a preceding non array job has completed relatively straightforward here's where",
    "start": "619500",
    "end": "625380"
  },
  {
    "text": "the fun starts though we have a dependency model called n2 n and so if you have a three-step pipeline that you",
    "start": "625380",
    "end": "632610"
  },
  {
    "text": "want to run across 10,000 elements maybe it's 10,000 objects in an s3 bucket or maybe it's 10,000 genomes that you want",
    "start": "632610",
    "end": "638520"
  },
  {
    "text": "to process we need to perform three operations on every one of those those elements or those objects you could do",
    "start": "638520",
    "end": "644910"
  },
  {
    "text": "that with three jobs to mission api's one for the first step one for the second step one for the third step and",
    "start": "644910",
    "end": "651060"
  },
  {
    "text": "in the end-to-end dependency model what we'll do is we'll create an implicit intra dependency between the elements",
    "start": "651060",
    "end": "657510"
  },
  {
    "text": "such that when element 42 of job a completes will then proceed to what will",
    "start": "657510",
    "end": "663360"
  },
  {
    "text": "cause element 42 of job B to become runnable and be scheduled as soon as there's a resource available this is regardless of",
    "start": "663360",
    "end": "669480"
  },
  {
    "text": "whether other elements in job a have completed or not we also have a model",
    "start": "669480",
    "end": "674580"
  },
  {
    "text": "where you can specify a dependency within a single job so if you want to give us a job that has 20 steps and tell",
    "start": "674580",
    "end": "680580"
  },
  {
    "text": "us that the job depends on itself we will set up interdependencies civil Ren state element 0 then 1 then 2 then 3",
    "start": "680580",
    "end": "687180"
  },
  {
    "text": "sequentially and you can also combine some of these dependency models so in",
    "start": "687180",
    "end": "692820"
  },
  {
    "text": "this case we have two jobs a and B that are non array and only once both of those are completed will we then begin",
    "start": "692820",
    "end": "698790"
  },
  {
    "text": "to run job C but as individual elements and jobs C if completed then the",
    "start": "698790",
    "end": "703920"
  },
  {
    "text": "corresponding elements in job D can begin you can also express dependencies on specific elements of your job and a",
    "start": "703920",
    "end": "710460"
  },
  {
    "text": "dependency that's expressed on a 10,000 element array job for example would only count as one of the dependency limits",
    "start": "710460",
    "end": "717420"
  },
  {
    "text": "for your for your jobs so at the moment we have a constraint of 20 dependencies for any given job that that array job",
    "start": "717420",
    "end": "724290"
  },
  {
    "text": "would only count for one of those and so this is really helpful if you want to have a deterministic workflow",
    "start": "724290",
    "end": "729870"
  },
  {
    "text": "potentially with lots of fan-out and fan back in operations where each stage might have different resource",
    "start": "729870",
    "end": "735600"
  },
  {
    "text": "requirements you combine this with per second billing and you can have a 10 second operation that's performing a",
    "start": "735600",
    "end": "740760"
  },
  {
    "text": "heavy Network IO stage followed by a CPU and then a memory intensive stage then maybe a GPU intensive phase to wrap",
    "start": "740760",
    "end": "747690"
  },
  {
    "text": "things up so now getting into the the roadmap for AWS batch just quickly",
    "start": "747690",
    "end": "753330"
  },
  {
    "text": "summarizing what you can expect in 2018 first we've heard loud and clear that we",
    "start": "753330",
    "end": "758820"
  },
  {
    "text": "need to improve the AWS batch console we've increased the size of the of the web development team supporting the AWS",
    "start": "758820",
    "end": "764610"
  },
  {
    "text": "batch console and we're looking forward to making it far easier for you to use not just keeping up with the the",
    "start": "764610",
    "end": "770460"
  },
  {
    "text": "capabilities that we're adding but but starting to add more telemetry and monitoring capabilities allowing you to very quickly be able to hone in on the",
    "start": "770460",
    "end": "776460"
  },
  {
    "text": "status of the a TBS batch jobs that you care about we'll also be making it",
    "start": "776460",
    "end": "782550"
  },
  {
    "text": "easier for you to submit jobs in response to events so in the in the coming weeks very soon actually you'll",
    "start": "782550",
    "end": "788730"
  },
  {
    "text": "be able to have particular job definitions that will be used to submit",
    "start": "788730",
    "end": "794910"
  },
  {
    "text": "a job to an AWS batch job queue when events that match a particular filter occur so if an object arrives in s3",
    "start": "794910",
    "end": "801690"
  },
  {
    "text": "maybe it's a video file that needs to be transcoded is written to a particular bucket that event signaling that that",
    "start": "801690",
    "end": "808020"
  },
  {
    "text": "objects now existing in s3 could be used to automatically trigger a transcoding job with an ADB OS batch as one example",
    "start": "808020",
    "end": "814470"
  },
  {
    "text": "I will also be adding a support for cloud trail auditing we already support",
    "start": "814470",
    "end": "820260"
  },
  {
    "text": "cloud trail auditing of the underlying services that we operate on on your behalf but this will this will add",
    "start": "820260",
    "end": "826050"
  },
  {
    "text": "support to the AWS batch API calls themselves so you can tell who's submitting jobs you can keep track of",
    "start": "826050",
    "end": "831330"
  },
  {
    "text": "who cancelled jobs or terminated jobs an important capability that we've heard",
    "start": "831330",
    "end": "836340"
  },
  {
    "text": "from a number of our customers that are using adb OS batch to run jobs that leverage license software is one example",
    "start": "836340",
    "end": "842280"
  },
  {
    "text": "is the need to be able to schedule not just based on on compute requirements of the job the CPU in the memory needs of a",
    "start": "842280",
    "end": "848280"
  },
  {
    "text": "job but also based on availability of licenses within a pool and so we'll be adding a feature to batch called",
    "start": "848280",
    "end": "854460"
  },
  {
    "text": "consumable resources where you'll be able to define an integer that corresponds to a limited resource that",
    "start": "854460",
    "end": "860790"
  },
  {
    "text": "you have at your disposal and if your job has a dependency on that may be in",
    "start": "860790",
    "end": "865890"
  },
  {
    "text": "addition to dependencies and other jobs will actually only begin to run your job or transition to run a bowl when we have",
    "start": "865890",
    "end": "872160"
  },
  {
    "text": "both available compute resources and also when that consumable resource is",
    "start": "872160",
    "end": "877260"
  },
  {
    "text": "greater than zero when the job starts will decrement from that compute that consumable resource and when the job",
    "start": "877260",
    "end": "882630"
  },
  {
    "text": "completes we'll increment that expect additional job types for a BBS batch including the ability to run jobs that",
    "start": "882630",
    "end": "890400"
  },
  {
    "text": "span more than one ec2 instance and finally we'll be expanding into a number of other regions so with with the time",
    "start": "890400",
    "end": "898230"
  },
  {
    "text": "that we have remaining I don't like to hand it over to Tamika Yola from Admiral to talk about Admirals experiences using",
    "start": "898230",
    "end": "905130"
  },
  {
    "text": "batch thank you thank you [Applause]",
    "start": "905130",
    "end": "911289"
  },
  {
    "text": "okay hello everyone my name is Mick koala I'm going to hear deliver a trolls",
    "start": "911489",
    "end": "917079"
  },
  {
    "text": "customer story on AWS patch so the first thing what I'm going to talk about a bit is why a troll likes a SS patch and",
    "start": "917079",
    "end": "924309"
  },
  {
    "text": "after that I'll go a bit on the technical side of stuff what kind of tooling have we built on a table ice",
    "start": "924309",
    "end": "929679"
  },
  {
    "text": "patch and the problems that we face and so on so let's begin",
    "start": "929679",
    "end": "935649"
  },
  {
    "text": "yeah so here are some numbers about adoption rates of a SS badge and a troll",
    "start": "935649",
    "end": "942669"
  },
  {
    "text": "so we started using it around six months ago in June not long after a SS batch",
    "start": "942669",
    "end": "947709"
  },
  {
    "text": "itself became available in us was - and as of today I'm starting from left we have two themes at that role who are",
    "start": "947709",
    "end": "954339"
  },
  {
    "text": "using a double dispatch in production and one of the themes is attribution to main user which I am part of the",
    "start": "954339",
    "end": "961359"
  },
  {
    "text": "attribution teams responsibly that a troll is to look at like a troll is an advertising company we show display",
    "start": "961359",
    "end": "967719"
  },
  {
    "text": "advertising on the Internet we code through previous tastes of all the data and we come up with numbers",
    "start": "967719",
    "end": "973149"
  },
  {
    "text": "like how well this advertising campaign perform and we put them on a dashboard for the customer to see so we kind of",
    "start": "973149",
    "end": "979509"
  },
  {
    "text": "report on the bottom line of advertising performance in the eyes of the customer which is which is important work so",
    "start": "979509",
    "end": "988539"
  },
  {
    "text": "moving on so far we have submitted 1.2 million jobs as of today we submit",
    "start": "988539",
    "end": "994119"
  },
  {
    "text": "around 5,000 jobs per day so we're a heavy use of a SS batch we have churned",
    "start": "994119",
    "end": "999759"
  },
  {
    "text": "about 300,000 instances so far if you do some mathematics you can maybe figure that one instance on average runs about",
    "start": "999759",
    "end": "1006299"
  },
  {
    "text": "four jobs in our use and finally this is an estimation we have spent 600 CPU",
    "start": "1006299",
    "end": "1013889"
  },
  {
    "text": "years on a SS patch and the key word really here is spent we have paid money for 600 CPU years so not everything is",
    "start": "1013889",
    "end": "1021419"
  },
  {
    "text": "100% efficient but it's a it's still pretty good my opinion so then why does",
    "start": "1021419",
    "end": "1028949"
  },
  {
    "text": "a draw like a dispatch so my first point may be obvious to you if you're like a doctor enthusiast it's the the doctor is",
    "start": "1028949",
    "end": "1035788"
  },
  {
    "text": "very flexible I can pick up any code I can put it inside the doctor container and when I submit that job to the system",
    "start": "1035789",
    "end": "1042900"
  },
  {
    "text": "I can be pretty sure it will actually work in justing attribution team at AdRoll we have a pretty diverse set of",
    "start": "1042900",
    "end": "1048930"
  },
  {
    "text": "technologies we have C code we have Python code we have go code we have some",
    "start": "1048930",
    "end": "1054660"
  },
  {
    "text": "rust code and then we have my personal favorite we have some Haskell code and we run all of that on a daily basis on a",
    "start": "1054660",
    "end": "1061410"
  },
  {
    "text": "SS patch and it works really well and my second point is that edible is patched",
    "start": "1061410",
    "end": "1067110"
  },
  {
    "text": "the conceptual model is pretty simple I put my stuff in the docker image and I submitted the way and a double dispatch",
    "start": "1067110",
    "end": "1073140"
  },
  {
    "text": "will figure out how to scale up and down and so on and the reason this is beneficial is that when I'm trying to",
    "start": "1073140",
    "end": "1078840"
  },
  {
    "text": "teach the system to a new engineer or someone maybe some other team at that role wants to take use of it they can be",
    "start": "1078840",
    "end": "1085050"
  },
  {
    "text": "productive on day one since they don't really have to understand much how this actually works they don't have to care",
    "start": "1085050",
    "end": "1090330"
  },
  {
    "text": "about scaling or anything so it really saves time when I'm trying to unboard new people that this stuff and as we",
    "start": "1090330",
    "end": "1096060"
  },
  {
    "text": "know time is money so we're saving money on that as well and then we have this is",
    "start": "1096060",
    "end": "1103650"
  },
  {
    "text": "what I like we have a lot of control over how edible dispatch the workers actually run like we can specify our",
    "start": "1103650",
    "end": "1109830"
  },
  {
    "text": "custom MEI which we do we install some custom software on it we change some settings and so on so we're kind of like",
    "start": "1109830",
    "end": "1116700"
  },
  {
    "text": "control freaks and we like that that it gives us the flexibility like then and finally the cost efficiency especially",
    "start": "1116700",
    "end": "1124410"
  },
  {
    "text": "now if you've been paying attention ec2 now has per second billing so when I submit some jobs to the system and then",
    "start": "1124410",
    "end": "1131430"
  },
  {
    "text": "the jobs finish edible dispatch kills the instances very quickly after did idle so we don't pay for anything extra",
    "start": "1131430",
    "end": "1138090"
  },
  {
    "text": "we just really cost-efficient AdRoll uses part instances exclusively the",
    "start": "1138090",
    "end": "1143580"
  },
  {
    "text": "instance types were interested in they're almost always available on the spot market and I think for batch jobs",
    "start": "1143580",
    "end": "1149280"
  },
  {
    "text": "in particular the spot instances are pretty great so that's a good stuff so",
    "start": "1149280",
    "end": "1155790"
  },
  {
    "text": "that's about why we're using this thing so next up I'm going to go in some technical stuff like what kind of",
    "start": "1155790",
    "end": "1162150"
  },
  {
    "text": "tooling we built on this thing since there are some pain points in there that we addressed and my first the biggest",
    "start": "1162150",
    "end": "1168540"
  },
  {
    "text": "thing that we had was monitoring capabilities of bad jobs so when we're running a few",
    "start": "1168540",
    "end": "1174280"
  },
  {
    "text": "thousand jobs per day like I said we run about five thousand as of today and when",
    "start": "1174280",
    "end": "1179440"
  },
  {
    "text": "I come to work tomorrow in my phone I might have like an automated email alerts that hey this Esther e-file did",
    "start": "1179440",
    "end": "1185860"
  },
  {
    "text": "not come into existence last night for some reason or these numbers will not insert it into the database that's when",
    "start": "1185860",
    "end": "1192490"
  },
  {
    "text": "I want to go back to my batch jobs and find out which job failed or which job",
    "start": "1192490",
    "end": "1198580"
  },
  {
    "text": "misbehaved and something so technically I can go to the edibles management console on the edible dispatch tab and",
    "start": "1198580",
    "end": "1204610"
  },
  {
    "text": "all the information will be there but right now the search is not so good as we would hope it to be it's difficult to",
    "start": "1204610",
    "end": "1211660"
  },
  {
    "text": "find your job out of all those thousands of jobs and in attribution we have a pretty diverse set of jobs anyway so it",
    "start": "1211660",
    "end": "1218770"
  },
  {
    "text": "really gets mixed up so the solution that we came up with is that we built a",
    "start": "1218770",
    "end": "1223870"
  },
  {
    "text": "monitoring tool which is called the battery patchy so yeah it's an internal",
    "start": "1223870",
    "end": "1230410"
  },
  {
    "text": "tool we could come up with any kind of name we wanted so we call it the battery country so the responsive things",
    "start": "1230410",
    "end": "1236620"
  },
  {
    "text": "happening here in this UI and I wanted to highlight some of the important parts in here some on top right we have a",
    "start": "1236620",
    "end": "1243700"
  },
  {
    "text": "search box right now I wrote for DB in that search box and it automatically",
    "start": "1243700",
    "end": "1248740"
  },
  {
    "text": "very quickly shows me all the jobs that match the keywords in this search and this search we spend a lot of time",
    "start": "1248740",
    "end": "1254530"
  },
  {
    "text": "making it really good as in it's very fast all the results will come in less than one second even though we have 1.2",
    "start": "1254530",
    "end": "1261130"
  },
  {
    "text": "million jobs in the database and I can also put things like s3 URL in the",
    "start": "1261130",
    "end": "1266590"
  },
  {
    "text": "search and it will also find jobs that somewhere in their command line refer to this s3 path so if some file is missing",
    "start": "1266590",
    "end": "1272950"
  },
  {
    "text": "I can very quickly find it this way at least mostly it's not always easy anyway",
    "start": "1272950",
    "end": "1278490"
  },
  {
    "text": "finally we have this job queue over here so if you have a right now it's selected to I don't know if you can read it",
    "start": "1278490",
    "end": "1284740"
  },
  {
    "text": "attribution managed spot staging which means it's attribution job queue using",
    "start": "1284740",
    "end": "1289990"
  },
  {
    "text": "jobs bar instances and it's managed as of today all of our computer moments are",
    "start": "1289990",
    "end": "1296650"
  },
  {
    "text": "managed so different teams have their own job queues and this can select it and they don't get mixed up with",
    "start": "1296650",
    "end": "1302380"
  },
  {
    "text": "attribution jobs and so on so like everyone can use the same tool and they don't have to maintain their own",
    "start": "1302380",
    "end": "1309279"
  },
  {
    "text": "copies which is nice for saving more resources in finally there's the status we have the all the jobs on the same",
    "start": "1309279",
    "end": "1315849"
  },
  {
    "text": "listing you succeeded failed running what server and the reason this is notable is because in the actual",
    "start": "1315849",
    "end": "1322419"
  },
  {
    "text": "management tool the jobs are broken down by different tabs which sometimes makes",
    "start": "1322419",
    "end": "1327519"
  },
  {
    "text": "things a little difficult it's difficult to glance what's going on with the system especially if you have like a row",
    "start": "1327519",
    "end": "1332589"
  },
  {
    "text": "large number of jobs going on all the time and also the search here is not that great although if you were paying",
    "start": "1332589",
    "end": "1339549"
  },
  {
    "text": "attention this thing is going to get better in 2018 and after that maybe this tool will not be as necessary back then",
    "start": "1339549",
    "end": "1348809"
  },
  {
    "text": "so going on we have a we brought the Python library to make the submitting",
    "start": "1348809",
    "end": "1354879"
  },
  {
    "text": "the jobs as easy as possible so there's a lot of things to continue in a dispatch change all kinds of settings",
    "start": "1354879",
    "end": "1360279"
  },
  {
    "text": "and so on but on an organizational level at that role most of those things will be the same so we kind of hid away as",
    "start": "1360279",
    "end": "1366879"
  },
  {
    "text": "much complexity as we could and just expose the things that people will actually change here we have an image",
    "start": "1366879",
    "end": "1373269"
  },
  {
    "text": "name which is ubuntu 16.04 here we have the name of the job it'll show up in bad sheep a tree and the job queue I want to",
    "start": "1373269",
    "end": "1380409"
  },
  {
    "text": "submit the job I have the command line and I have a timeout which is it - one hour if the job doesn't finish in one",
    "start": "1380409",
    "end": "1387609"
  },
  {
    "text": "hour we have a script that kill said it's a pretty good feature and it has",
    "start": "1387609",
    "end": "1392949"
  },
  {
    "text": "its own slide so there is no building support for timeouts in a table is patched right now but as I mentioned",
    "start": "1392949",
    "end": "1399039"
  },
  {
    "text": "when we run a large number of jobs in event eventually you will have some that gets stuck for whatever reason maybe",
    "start": "1399039",
    "end": "1405669"
  },
  {
    "text": "there's crappy code in there we have a lot of different diverse set of jobs some of them will fail in a way that",
    "start": "1405669",
    "end": "1411639"
  },
  {
    "text": "doesn't actually kill the job it just gets stuck and this is a problem the instance will stay alive forever until",
    "start": "1411639",
    "end": "1418449"
  },
  {
    "text": "we manually kill it so we spent money on that and maybe worse is that other jobs may wait on that job so it'll be just",
    "start": "1418449",
    "end": "1425889"
  },
  {
    "text": "there until something actually done something about the job so the solution we did at job submit time we put an",
    "start": "1425889",
    "end": "1433629"
  },
  {
    "text": "environment variable on the job dispatch timeout it has the timestamp when the job should die and",
    "start": "1433629",
    "end": "1440080"
  },
  {
    "text": "then we have a script once every one minute it checks all the jobs that have defined this batch timeout and if it's",
    "start": "1440080",
    "end": "1447150"
  },
  {
    "text": "later than if it's expired then we just that job is going to die which is this",
    "start": "1447150",
    "end": "1453760"
  },
  {
    "text": "is a really useful feature like I think this becomes relevant when you have very",
    "start": "1453760",
    "end": "1459130"
  },
  {
    "text": "large number of jobs and we're much more job that you can handle so you want some automatic way to actually kill those",
    "start": "1459130",
    "end": "1465760"
  },
  {
    "text": "that get stuck and so on it's kind of fault tolerance type of feature finally",
    "start": "1465760",
    "end": "1471549"
  },
  {
    "text": "I have some other tricks that we do but I don't think are as important as I mentioned we customized the workers we",
    "start": "1471549",
    "end": "1477760"
  },
  {
    "text": "have a custom ami I've installed some custom software in there we make great use of instance store especially on i3",
    "start": "1477760",
    "end": "1484059"
  },
  {
    "text": "instances they have really fast SSD drives we use it as a scratch space it's very good and then we have production",
    "start": "1484059",
    "end": "1492040"
  },
  {
    "text": "and staging environments completely separated I think it's a good idea to have production at least separated from",
    "start": "1492040",
    "end": "1497740"
  },
  {
    "text": "staging and testing so there is no chance of them interfering with each other although it's a bit more expensive",
    "start": "1497740",
    "end": "1503140"
  },
  {
    "text": "since they're not sharing any instances and so on but it's like you get more if",
    "start": "1503140",
    "end": "1508630"
  },
  {
    "text": "you pay more then you get more reliability as well oh yeah and then ALW",
    "start": "1508630",
    "end": "1514990"
  },
  {
    "text": "spatch can give you like an optimal type of instance but the way we have set it up is that we have one job queue for a",
    "start": "1514990",
    "end": "1521590"
  },
  {
    "text": "very specific type of instance so when I submit a job I know exactly what kind of instance I'm going to get which is",
    "start": "1521590",
    "end": "1527860"
  },
  {
    "text": "relevant for the disks of mostly but that's like how we like to do things",
    "start": "1527860",
    "end": "1533490"
  },
  {
    "text": "this is my last slide so I talked about the monitoring tools and the timeouts",
    "start": "1533490",
    "end": "1538960"
  },
  {
    "text": "and so on it may seem like you need to have all kinds of complicated stuff in here but that's not exactly true when we",
    "start": "1538960",
    "end": "1545049"
  },
  {
    "text": "start at a draw we just went to the console and click hey let's create compute environment and job queues and",
    "start": "1545049",
    "end": "1550299"
  },
  {
    "text": "submit jobs using both who and so on and it worked just fine when we grew up our",
    "start": "1550299",
    "end": "1555940"
  },
  {
    "text": "use of edible dispatch then we started to see all the needs for these timeouts and monitoring and stuff and I think the",
    "start": "1555940",
    "end": "1563320"
  },
  {
    "text": "monitoring is the one thing if you're going to scale up your use of a double dispatch you may want to think about you're going to monitor them in the use",
    "start": "1563320",
    "end": "1570580"
  },
  {
    "text": "case that I described so it doesn't have to be a UI like I showed it could be like a CSV file of all the jobs that",
    "start": "1570580",
    "end": "1577480"
  },
  {
    "text": "have failed you have some script that tells them what they are or you can wait until the edibles Management Council",
    "start": "1577480",
    "end": "1583090"
  },
  {
    "text": "gets better in this regard and finally I wanted to stress this because this is",
    "start": "1583090",
    "end": "1589119"
  },
  {
    "text": "really useful cash saving feature use the spot instances unless you have very",
    "start": "1589119",
    "end": "1594490"
  },
  {
    "text": "specific needs I think you almost always can use bar instances or batch jobs the really good in biggest batch jobs or are",
    "start": "1594490",
    "end": "1602200"
  },
  {
    "text": "already kind of like FML they will die very quickly anyway so you don't usually need the kind of reliability you need",
    "start": "1602200",
    "end": "1608019"
  },
  {
    "text": "from services that run web servers that run all the time and so on spot instances they're great and I think",
    "start": "1608019",
    "end": "1617230"
  },
  {
    "text": "that's all I have to say thank you for listening I will hand [Applause]",
    "start": "1617230",
    "end": "1625630"
  },
  {
    "text": "all right so I'm my name is Ryan layer with base-2 genomics so we're a small",
    "start": "1631150",
    "end": "1636590"
  },
  {
    "text": "startup that we spun out of the University of Utah human genetics department so that we could",
    "start": "1636590",
    "end": "1641960"
  },
  {
    "text": "commercialize the software that we developed and optimized in our academic lab so we by putting on this other hat",
    "start": "1641960",
    "end": "1650120"
  },
  {
    "text": "allows us to focus on cost and scale which are improvements that really",
    "start": "1650120",
    "end": "1655460"
  },
  {
    "text": "wouldn't have led to new publications and new papers but are very important to hospitals pharmaceutical companies and",
    "start": "1655460",
    "end": "1662270"
  },
  {
    "text": "genetic testing labs and these are exactly the partners that we need if we",
    "start": "1662270",
    "end": "1667370"
  },
  {
    "text": "want our software helping patients so the excitement of whole genome",
    "start": "1667370",
    "end": "1674480"
  },
  {
    "text": "sequencing is that it represents the ultimate genetic test once we extract DNA from a patient and we sequence it",
    "start": "1674480",
    "end": "1681350"
  },
  {
    "text": "we're left with about a hundred million short sequences that completely characterize the patient's genetic code",
    "start": "1681350",
    "end": "1688400"
  },
  {
    "text": "and our software minds this data looking for signals of genetic disorders cost",
    "start": "1688400",
    "end": "1696710"
  },
  {
    "text": "and scale are very important here because as sequencing gets cheaper we're looking at not one patient at a time",
    "start": "1696710",
    "end": "1703040"
  },
  {
    "text": "but thousands of patients so there are other people operating in this space but",
    "start": "1703040",
    "end": "1710210"
  },
  {
    "text": "they by and large are focused on just one type of mutations these are the ones",
    "start": "1710210",
    "end": "1715310"
  },
  {
    "text": "that affect just one or a few of the three billion bases in your genome and",
    "start": "1715310",
    "end": "1720650"
  },
  {
    "text": "they largely ignore big forms of variations like duplications and deletions that can affect millions of",
    "start": "1720650",
    "end": "1728630"
  },
  {
    "text": "bases and are hallmarks of many genetic disorders most notably cancer so our",
    "start": "1728630",
    "end": "1735200"
  },
  {
    "text": "opinion is why go through the trouble of sequencing an entire genome if you're just going to shine a light on one type",
    "start": "1735200",
    "end": "1740960"
  },
  {
    "text": "of variation at base to genomics we want to illuminate the entire space and give",
    "start": "1740960",
    "end": "1746180"
  },
  {
    "text": "doctors access to the full spectrum of genetic variation that may exist in their patients so to do this we use a",
    "start": "1746180",
    "end": "1754640"
  },
  {
    "text": "really simple architecture this is like the batch to smiley face we store all of our files on s3 and we",
    "start": "1754640",
    "end": "1762380"
  },
  {
    "text": "process them in batch and we write the results back to s3 that's because we have very large files and our pipeline",
    "start": "1762380",
    "end": "1769430"
  },
  {
    "text": "is heterogeneous and I mean that in a very broad sense we have a mixture of open source commercial and our own",
    "start": "1769430",
    "end": "1776840"
  },
  {
    "text": "proprietary software all of these have different CPU and memory requirements and at different stages in the pipeline",
    "start": "1776840",
    "end": "1783200"
  },
  {
    "text": "we have different types of both tasks and data parallelism and we're able to",
    "start": "1783200",
    "end": "1788350"
  },
  {
    "text": "to accomplish all of this because of all of the services that AWS provides",
    "start": "1788350",
    "end": "1793700"
  },
  {
    "text": "through batch all right so that to kind of dive into our pipeline I'm gonna go",
    "start": "1793700",
    "end": "1800630"
  },
  {
    "text": "through one specific example where we looked at a UN sarcoma study so this is a form of a fairly rare childhood cancer",
    "start": "1800630",
    "end": "1807140"
  },
  {
    "text": "and as I move along I'm gonna pay particular attention to how we parallelized our analysis so we can get",
    "start": "1807140",
    "end": "1813770"
  },
  {
    "text": "this done cheaply and quickly I also have this little ticker in the corner so you can idea of the scale of just one",
    "start": "1813770",
    "end": "1820400"
  },
  {
    "text": "experiment we're gonna look at both how much data are we pulling and pushing to s3 and how many CPU hours we spend",
    "start": "1820400",
    "end": "1826670"
  },
  {
    "text": "operating on that data alright so we start with raw sequencing data in this",
    "start": "1826670",
    "end": "1832730"
  },
  {
    "text": "case we had 1,000 49 samples so that's 50 terabytes of raw data the first step",
    "start": "1832730",
    "end": "1839450"
  },
  {
    "text": "in this is called it's called alignment where you take each one of those sequences and you have a hundred million",
    "start": "1839450",
    "end": "1845240"
  },
  {
    "text": "per sample and we take that short sequence and we look up where that exists in the human reference genome so",
    "start": "1845240",
    "end": "1852260"
  },
  {
    "text": "this is a like a string search problem and we do that so we can look at one",
    "start": "1852260",
    "end": "1857300"
  },
  {
    "text": "spot in the genome across all of our samples looking for mutations in that area so we do this to every sample so we",
    "start": "1857300",
    "end": "1865070"
  },
  {
    "text": "call this sample parallel so we take all of our samples and we're gonna look at just one of them maybe yeah",
    "start": "1865070",
    "end": "1873560"
  },
  {
    "text": "we're going to look at just one sample but this is data parallel so we're doing this to all samples so we take the 50",
    "start": "1873560",
    "end": "1879950"
  },
  {
    "text": "gigabytes of raw data for this sample and we send the alignment job to batch",
    "start": "1879950",
    "end": "1886510"
  },
  {
    "text": "to make this job submission step a little bit easier much like the last",
    "start": "1886510",
    "end": "1891590"
  },
  {
    "text": "speaker we have now open-source tool we call batch it and this makes job submission to batch",
    "start": "1891590",
    "end": "1898159"
  },
  {
    "text": "look a lot like job submission to a something like slurm a queuing system on",
    "start": "1898159",
    "end": "1903979"
  },
  {
    "text": "a cluster which is something that we're very familiar with so if you if you're interested in batch",
    "start": "1903979",
    "end": "1909019"
  },
  {
    "text": "please check out our github page so the way the way it works is you start by defining a generic shell script where",
    "start": "1909019",
    "end": "1917059"
  },
  {
    "text": "you've replaced all of the command line parameters and options with variables and then you submit that shell script to",
    "start": "1917059",
    "end": "1923210"
  },
  {
    "text": "batch using a pretty simple batch --it submit operation where you define things",
    "start": "1923210",
    "end": "1928580"
  },
  {
    "text": "like the docker image the the roles the queues the environmental variables but",
    "start": "1928580",
    "end": "1934460"
  },
  {
    "text": "one of the really interesting things that we added was something that gets around this disk space issue that's in",
    "start": "1934460",
    "end": "1941840"
  },
  {
    "text": "batch so the default ami is basically have no storage you can do a custom ami",
    "start": "1941840",
    "end": "1947690"
  },
  {
    "text": "and my other local storage or attach an EBS volume but you're stuck with that",
    "start": "1947690",
    "end": "1953570"
  },
  {
    "text": "mount for the entirety of the instance and if you're running multiple jobs on",
    "start": "1953570",
    "end": "1959210"
  },
  {
    "text": "an instance then you're gonna have a lot of multi-tenancy issues the most",
    "start": "1959210",
    "end": "1964999"
  },
  {
    "text": "troubling of those issues is how big should this mount be so you need to estimate you know how much disk space is",
    "start": "1964999",
    "end": "1972529"
  },
  {
    "text": "the maximum for all of my jobs times the number of jobs I'm going to be running on each instance and if you have a",
    "start": "1972529",
    "end": "1979249"
  },
  {
    "text": "heterogeneous pipeline like us you're gonna that estimation is probably going to be much larger than your actual usage",
    "start": "1979249",
    "end": "1986029"
  },
  {
    "text": "so you're wasting a lot of money on space that you're not going to use so",
    "start": "1986029",
    "end": "1991460"
  },
  {
    "text": "what we figured out is a way to dynamically attach EBS volumes directly to your jobs we mount them and then when",
    "start": "1991460",
    "end": "1998629"
  },
  {
    "text": "the job's over we unmount them delete them and detach them so with the per second billing with EBS now you were",
    "start": "1998629",
    "end": "2007659"
  },
  {
    "text": "able to save a lot of money and this is really important to us because our EBS costs are a large fraction of our total",
    "start": "2007659",
    "end": "2015159"
  },
  {
    "text": "costs and I'll get into exactly how we do that in a couple slides so batch uses",
    "start": "2015159",
    "end": "2021460"
  },
  {
    "text": "the go API to transform these command line parameters to this this JSON we submit that to the the",
    "start": "2021460",
    "end": "2029049"
  },
  {
    "text": "submit jobs API and it yeah so and it gives us this result so the interesting",
    "start": "2029049",
    "end": "2036549"
  },
  {
    "text": "interesting bits here are where we submit the we set the command-line variables we encode the job and then we",
    "start": "2036549",
    "end": "2044149"
  },
  {
    "text": "set the stage for mounting the EBS alright to do the Mount EBS we wrap a",
    "start": "2044149",
    "end": "2049700"
  },
  {
    "text": "little bit of bash around the main execution we first have this initial",
    "start": "2049700",
    "end": "2056059"
  },
  {
    "text": "batch 't command where we do our EBS mount you can set things like the properties of the EBS the file format",
    "start": "2056059",
    "end": "2062929"
  },
  {
    "text": "all sorts of interesting parameters there and then to unmount we have a trap and in that trap we unmount and then we",
    "start": "2062929",
    "end": "2069500"
  },
  {
    "text": "have another batch of command that makes sure to delete and detach that EBS volume all right so the plumbing that",
    "start": "2069500",
    "end": "2078138"
  },
  {
    "text": "makes all of this possible was actually inspired by Andres ogia tool suite and",
    "start": "2078139",
    "end": "2083240"
  },
  {
    "text": "what you do is you just you map the instance dev to the container dev",
    "start": "2083240",
    "end": "2091089"
  },
  {
    "text": "alright so once you run that batch returns your job ID and you can use that to set up your dependencies alright so",
    "start": "2091089",
    "end": "2098660"
  },
  {
    "text": "we run all of our all of our jobs on compute environments that have a pretty",
    "start": "2098660",
    "end": "2104539"
  },
  {
    "text": "diverse set of instances in them we started looking we know like the",
    "start": "2104539",
    "end": "2109849"
  },
  {
    "text": "previous speaker we really like the i3 because it had all of that local storage we thought we could save a lot of money",
    "start": "2109849",
    "end": "2115240"
  },
  {
    "text": "but the pricing of this is just way too unstable for us we we could never really",
    "start": "2115240",
    "end": "2120619"
  },
  {
    "text": "get good spot prices very consistently so we had to switch our our architecture",
    "start": "2120619",
    "end": "2125779"
  },
  {
    "text": "to use jobs that had a profile like this things that were much more stable and we can get predictable pricing over time",
    "start": "2125779",
    "end": "2132609"
  },
  {
    "text": "alright so with this you know with batching with this diverse set of instances we can align a full genome",
    "start": "2132609",
    "end": "2140770"
  },
  {
    "text": "excuse me for one individual it's about a hundred gigabytes of data we do that",
    "start": "2140770",
    "end": "2146059"
  },
  {
    "text": "in about seven compute days you do that across a thousand forty nine instant",
    "start": "2146059",
    "end": "2151220"
  },
  {
    "text": "samples were now up to a hundred terabytes of data and about twenty CPU",
    "start": "2151220",
    "end": "2157339"
  },
  {
    "text": "years so that's just the first step in the pipe now we have this aligned genome so we",
    "start": "2157339",
    "end": "2162530"
  },
  {
    "text": "know where all of those 100 million sequences originated from for every sample we now go through and analyze",
    "start": "2162530",
    "end": "2168500"
  },
  {
    "text": "that data looking for these mutations so we stay with the idea of sample parallel",
    "start": "2168500",
    "end": "2174200"
  },
  {
    "text": "here and this step is we call variant calling so you have your sample and",
    "start": "2174200",
    "end": "2179240"
  },
  {
    "text": "there are kind of two stages here I talked about the the two different forms of variation so there's the small",
    "start": "2179240",
    "end": "2185480"
  },
  {
    "text": "variants which most people look at and then you also here you have some task parallelism along with your data",
    "start": "2185480",
    "end": "2191060"
  },
  {
    "text": "parallelism parallelism so in parallel we do this large variant calling which is really the specialty of our academic",
    "start": "2191060",
    "end": "2198200"
  },
  {
    "text": "lab and is now the specialty of base two if you look at the CPU requirements it",
    "start": "2198200",
    "end": "2203540"
  },
  {
    "text": "is drastically cheaper to call these large variants so you so for just a little bit of extra money and given the",
    "start": "2203540",
    "end": "2209930"
  },
  {
    "text": "parallelism no extra time you're able to get the full spectrum of a variation",
    "start": "2209930",
    "end": "2215080"
  },
  {
    "text": "across all of your samples so you do that for all of the samples we're now up",
    "start": "2215080",
    "end": "2221480"
  },
  {
    "text": "to 287 terabytes of data and 35 compute years and at this point you have all of",
    "start": "2221480",
    "end": "2228500"
  },
  {
    "text": "the genetic variants all of the mutations for all of your samples now we",
    "start": "2228500",
    "end": "2234200"
  },
  {
    "text": "need to do something we call joint calling where you take all of that data and you put it into one central location",
    "start": "2234200",
    "end": "2240260"
  },
  {
    "text": "so you can really start to dig in and look for you know what makes the people sick what makes some people well so we",
    "start": "2240260",
    "end": "2246109"
  },
  {
    "text": "call that joint calling and we switch gears here to something called region parallel so it's no longer sample",
    "start": "2246109",
    "end": "2251839"
  },
  {
    "text": "parallel so what I mean by that is we take a genome we divided up into individual regions and then for each",
    "start": "2251839",
    "end": "2258650"
  },
  {
    "text": "region we pull all of the mutations we identified in the prior step for all of",
    "start": "2258650",
    "end": "2264290"
  },
  {
    "text": "our samples and we join them we joint call all of those variants into a single",
    "start": "2264290",
    "end": "2270920"
  },
  {
    "text": "unified of you know single unified file",
    "start": "2270920",
    "end": "2276040"
  },
  {
    "text": "so to do this we have about 80 regions across the human genome we do we have",
    "start": "2276040",
    "end": "2281930"
  },
  {
    "text": "and the final tally here is about 300 terabytes of data and 35 CPU years for",
    "start": "2281930",
    "end": "2288530"
  },
  {
    "text": "this for this one experiment but the really nice thing about batch is given the resources that are available there we",
    "start": "2288530",
    "end": "2294789"
  },
  {
    "text": "actually did this in just over three days and we could have doubled the number of number of CPUs in our in our",
    "start": "2294789",
    "end": "2302980"
  },
  {
    "text": "compute environments that done this in less than two days and I think it's really exciting because in just a few",
    "start": "2302980",
    "end": "2308319"
  },
  {
    "text": "days we we produce all of this data and then we actually our collaborators in",
    "start": "2308319",
    "end": "2313690"
  },
  {
    "text": "this project are writing new papers and finding new reasons why one population",
    "start": "2313690",
    "end": "2319690"
  },
  {
    "text": "of people might be more prone to this form of childhood cancer than other populations is actually a really",
    "start": "2319690",
    "end": "2324700"
  },
  {
    "text": "exciting results we have here so there's a lot of challenges that we have to face",
    "start": "2324700",
    "end": "2331299"
  },
  {
    "text": "the the most striking is is using academic software so academic software",
    "start": "2331299",
    "end": "2336760"
  },
  {
    "text": "is the cutting edge of statistical models and and algorithms but it's not",
    "start": "2336760",
    "end": "2342069"
  },
  {
    "text": "always written in a way that is is easily digestible by batch and in",
    "start": "2342069",
    "end": "2347410"
  },
  {
    "text": "particular exit codes are not faithfully reported in this software so we have we",
    "start": "2347410",
    "end": "2352960"
  },
  {
    "text": "have many instances where we have some catastrophic error and all of the output is truncated but you check exit code",
    "start": "2352960",
    "end": "2359349"
  },
  {
    "text": "zero so bash is no way batch has no way of knowing that it should report or maybe even retry so what we had to do is",
    "start": "2359349",
    "end": "2366400"
  },
  {
    "text": "we have to develop this infrastructure where after every result we go through",
    "start": "2366400",
    "end": "2371500"
  },
  {
    "text": "and we validate the output and we create a Sentinel file on s3 if that file is",
    "start": "2371500",
    "end": "2377920"
  },
  {
    "text": "valid what these sentinels do is allow us to move from event dependencies that",
    "start": "2377920",
    "end": "2383740"
  },
  {
    "text": "batch provides to data dependent infrastructure or data dependent you",
    "start": "2383740",
    "end": "2389440"
  },
  {
    "text": "know job planning and we do that with a software that we developed called base to Mon so for basically Mon a little",
    "start": "2389440",
    "end": "2396430"
  },
  {
    "text": "simple example you give it a set of input files and you get a set of operations and from that it knows all",
    "start": "2396430",
    "end": "2402400"
  },
  {
    "text": "the dependencies and all the parallelism that might exist in these operations and it can completely orchestrate a data",
    "start": "2402400",
    "end": "2409089"
  },
  {
    "text": "dependent pipeline where it knows all of the synchronization points and knows all of the all of the parallelism tasks and",
    "start": "2409089",
    "end": "2415690"
  },
  {
    "text": "data and and it runs pretty easily it's a very small service that runs on a",
    "start": "2415690",
    "end": "2420789"
  },
  {
    "text": "teaching micro and it takes all these inputs it wants the sentinels exist",
    "start": "2420789",
    "end": "2426160"
  },
  {
    "text": "three it submits new jobs to batch and the whole time it actually monitors all of those instances and what this gives",
    "start": "2426160",
    "end": "2432790"
  },
  {
    "text": "us is this you know a data dependent pipeline you can basically tear down every job you have and restart for",
    "start": "2432790",
    "end": "2439450"
  },
  {
    "text": "almost free so recovery and restart are a given we also use this to mod relies a",
    "start": "2439450",
    "end": "2446170"
  },
  {
    "text": "lot of that third-party software that we're using and a really nice piece here is because we're monitoring these jobs",
    "start": "2446170",
    "end": "2452890"
  },
  {
    "text": "when they fail we can look for characteristic memory errors and we resubmit we can actually change the",
    "start": "2452890",
    "end": "2459520"
  },
  {
    "text": "parameters give it more memory so it's unlikely to fail again and the the",
    "start": "2459520",
    "end": "2464920"
  },
  {
    "text": "real-time instance monitoring gives us a good idea of how much time and how much cost were incurring alright so that",
    "start": "2464920",
    "end": "2471910"
  },
  {
    "text": "that's all I have please visit our website or or tweet at us if you're",
    "start": "2471910",
    "end": "2476980"
  },
  {
    "text": "interested in knowing more about batch or a batch it it's on our github site or",
    "start": "2476980",
    "end": "2482350"
  },
  {
    "text": "you know more of how we're using batch so thank you very much hey everybody how",
    "start": "2482350",
    "end": "2500080"
  },
  {
    "text": "are you guys doing you're tired well imagine you have to do a",
    "start": "2500080",
    "end": "2505600"
  },
  {
    "text": "presentation up here okay so I work for",
    "start": "2505600",
    "end": "2513700"
  },
  {
    "text": "Autodesk in Autodesk we do many things but our core business is CAD software cab stands for computer aided design and",
    "start": "2513700",
    "end": "2521050"
  },
  {
    "text": "is extensively used in various industries such as automotive aerospace shipbuilding industrial and",
    "start": "2521050",
    "end": "2528220"
  },
  {
    "text": "architectural designs a prosthetics and a bunch more we're always looking to improve the way our customers design",
    "start": "2528220",
    "end": "2536830"
  },
  {
    "text": "things and this talk is about one such new way in general terms the goal of any",
    "start": "2536830",
    "end": "2545770"
  },
  {
    "text": "engineering activity is to strike a balance between the performance of what",
    "start": "2545770",
    "end": "2551470"
  },
  {
    "text": "you're trying to do and cost of making that specific thing for simplicity sake",
    "start": "2551470",
    "end": "2557590"
  },
  {
    "text": "consider you have to come up with a mechanical part such as you see here on your screen that this will eventually",
    "start": "2557590",
    "end": "2563770"
  },
  {
    "text": "need to be manufactured and the challenge is basically how would you",
    "start": "2563770",
    "end": "2569320"
  },
  {
    "text": "approach this this this problem one way",
    "start": "2569320",
    "end": "2578530"
  },
  {
    "text": "to do design is basically what General Electric did in 2013 they created a",
    "start": "2578530",
    "end": "2586570"
  },
  {
    "text": "crowdsource design challenge for a jet engine bracket you see it on your screen they ask the public to come up with a",
    "start": "2586570",
    "end": "2593340"
  },
  {
    "text": "optimal design for a mechanical part according to certain specifications they published and you know such a strength",
    "start": "2593340",
    "end": "2600430"
  },
  {
    "text": "weight and so on for this challenge there are about 700 designs submitted",
    "start": "2600430",
    "end": "2606870"
  },
  {
    "text": "from by people across 53 different countries and it took about two months",
    "start": "2606870",
    "end": "2612370"
  },
  {
    "text": "in total most of these satisfy the requirements that we asked for",
    "start": "2612370",
    "end": "2618210"
  },
  {
    "text": "imagine how many of these could have been created by a single designer or a",
    "start": "2625350",
    "end": "2631120"
  },
  {
    "text": "design team with limited amount of time",
    "start": "2631120",
    "end": "2636030"
  },
  {
    "text": "you might have noticed from the previous slide that the design phase doesn't actually deal just with shapes but also",
    "start": "2637080",
    "end": "2643300"
  },
  {
    "text": "needs to take into consideration things like the processes that you're going to use to actually make your thing",
    "start": "2643300",
    "end": "2648930"
  },
  {
    "text": "materials that are gonna have and the cost for it all so how are we moving",
    "start": "2648930",
    "end": "2657370"
  },
  {
    "text": "away from the old ways of designing producing designs by hand and into you",
    "start": "2657370",
    "end": "2662860"
  },
  {
    "text": "know new and automated ways such as the generative design the old way",
    "start": "2662860",
    "end": "2671860"
  },
  {
    "text": "also known as converging design its engineers are limited in time and energy",
    "start": "2671860",
    "end": "2676990"
  },
  {
    "text": "that they can spend on any number of designs that they can produce so they can't explore fully the design space the",
    "start": "2676990",
    "end": "2683440"
  },
  {
    "text": "results are limited design options enter generative design so generative design",
    "start": "2683440",
    "end": "2690160"
  },
  {
    "text": "is a good unit of design software you input your design goals such as the",
    "start": "2690160",
    "end": "2695530"
  },
  {
    "text": "materials manufacturing methods on the costs into our software then using cloud",
    "start": "2695530",
    "end": "2701410"
  },
  {
    "text": "computing the system generates multiple designs for you basically the computer",
    "start": "2701410",
    "end": "2706810"
  },
  {
    "text": "creates the designs and in instead of view punitive design is also known as a",
    "start": "2706810",
    "end": "2716290"
  },
  {
    "text": "divergent divergent design there is no single solution instead you potentially",
    "start": "2716290",
    "end": "2722770"
  },
  {
    "text": "get thousands of great solutions and it's like having your own crowdsource challenge the way",
    "start": "2722770",
    "end": "2729370"
  },
  {
    "text": "General Electric did with their design challenge but much quicker you don't have to wait for months and months in",
    "start": "2729370",
    "end": "2735599"
  },
  {
    "text": "hundreds of people to do it for you once you get the potential designs from our",
    "start": "2735599",
    "end": "2743380"
  },
  {
    "text": "system it's up to you to select the ones that fits your need best along that price performance curve this is the",
    "start": "2743380",
    "end": "2755950"
  },
  {
    "text": "workflow for our software doing the genitive design and basically deals with the first three steps here the second",
    "start": "2755950",
    "end": "2765310"
  },
  {
    "text": "the fourth six steps are what you would do to eventually produce but we're going",
    "start": "2765310",
    "end": "2770800"
  },
  {
    "text": "to focus on the first three here so the way it works is you define an input your",
    "start": "2770800",
    "end": "2775990"
  },
  {
    "text": "project requirements into our software then our software generates a number of",
    "start": "2775990",
    "end": "2781359"
  },
  {
    "text": "variants for each project you can think of it in terms of the part that I showed",
    "start": "2781359",
    "end": "2787330"
  },
  {
    "text": "earlier if you had to make that the variant would be different material",
    "start": "2787330",
    "end": "2793060"
  },
  {
    "text": "types so let's say you know one is going to be steel another one is going to be aluminum and a third one would be wood",
    "start": "2793060",
    "end": "2800819"
  },
  {
    "text": "these three variants then get solved what we call solved as in the geometry",
    "start": "2801000",
    "end": "2807700"
  },
  {
    "text": "for the actual part gets generated and is done in parallel so you can imagine",
    "start": "2807700",
    "end": "2815650"
  },
  {
    "text": "if you have stronger materials you can have thinner diameters for pieces of",
    "start": "2815650",
    "end": "2820690"
  },
  {
    "text": "your parts versus the other way around if you have something like wood then in",
    "start": "2820690",
    "end": "2827320"
  },
  {
    "text": "the third step you explore all the solutions that you got all the designs and you can choose the one that fits",
    "start": "2827320",
    "end": "2833200"
  },
  {
    "text": "your best against again along that price performance curve so how do we how do we",
    "start": "2833200",
    "end": "2840400"
  },
  {
    "text": "implement this on AWS we basically used these three services and I'm these are",
    "start": "2840400",
    "end": "2847089"
  },
  {
    "text": "the ones that I'm going to focus most of course we use the bunch of other ones that are less important so we use DCs",
    "start": "2847089",
    "end": "2853119"
  },
  {
    "text": "we use simple workflow and we use batch in case you guys are not familiar with",
    "start": "2853119",
    "end": "2859869"
  },
  {
    "text": "simple workflow it's a state machine it was it was a great fit for what we",
    "start": "2859869",
    "end": "2865420"
  },
  {
    "text": "needed to coordinate our jobs on batch and it saved us from",
    "start": "2865420",
    "end": "2871180"
  },
  {
    "text": "having to write our own this is the",
    "start": "2871180",
    "end": "2876340"
  },
  {
    "text": "architecture that we use for our generative design software a project",
    "start": "2876340",
    "end": "2885640"
  },
  {
    "text": "gets submitted to the API service running on on ECS which triggers a",
    "start": "2885640",
    "end": "2891220"
  },
  {
    "text": "workflow in SWF so we have basically I want to one matching between a project",
    "start": "2891220",
    "end": "2896560"
  },
  {
    "text": "and a workflow and as in Swift the",
    "start": "2896560",
    "end": "2906060"
  },
  {
    "text": "generate step from the workflow I showed you guys earlier the second step",
    "start": "2906060",
    "end": "2912310"
  },
  {
    "text": "basically consists of two phases one is generating the variance what I was",
    "start": "2912310",
    "end": "2917530"
  },
  {
    "text": "mentioning earlier about you know for example material types and then the second so this first phase happens in just one",
    "start": "2917530",
    "end": "2925360"
  },
  {
    "text": "container so one container gets been up in a batch job with one can dare get spin up and creates the older variants",
    "start": "2925360",
    "end": "2933360"
  },
  {
    "text": "and the second phase is solving each of those variants and it happens in",
    "start": "2933360",
    "end": "2940330"
  },
  {
    "text": "parallel so another batch job gets submitted and you know be that three or a hundred or a thousand variants they",
    "start": "2940330",
    "end": "2948910"
  },
  {
    "text": "all get to happen in parallel we have to manage computer environments in batch",
    "start": "2948910",
    "end": "2955710"
  },
  {
    "text": "for first phase we use a CPU cluster for generating the variants and we use an",
    "start": "2955710",
    "end": "2960880"
  },
  {
    "text": "optimal instance type we don't really care what that picks for us the second cluster the second phase is GPU cluster",
    "start": "2960880",
    "end": "2967810"
  },
  {
    "text": "for solving variants we found we started with CPU clusters but then did some",
    "start": "2967810",
    "end": "2975220"
  },
  {
    "text": "benchmarks and found out the DP cluster is actually a better fit for us we had to create a custom AMI and we had to",
    "start": "2975220",
    "end": "2980680"
  },
  {
    "text": "restrict our instance types that we use in batch to p2 we have these two job",
    "start": "2980680",
    "end": "2986470"
  },
  {
    "text": "queues corresponding to both of these clusters so it's really simple here's",
    "start": "2986470",
    "end": "2992050"
  },
  {
    "text": "how our job definition for the solver piece for the solfege job looks like you",
    "start": "2992050",
    "end": "2998470"
  },
  {
    "text": "can see that it's really simple and stuff in bold is basically what you",
    "start": "2998470",
    "end": "3003789"
  },
  {
    "text": "would need as a minimum job definition the other stuff is since this is a ma",
    "start": "3003789",
    "end": "3010299"
  },
  {
    "text": "this is a job definition for a GPU job basically deals with setting up the",
    "start": "3010299",
    "end": "3016599"
  },
  {
    "text": "Nvidia drivers and all this other stuff our code uses go so this is a simple",
    "start": "3016599",
    "end": "3023680"
  },
  {
    "text": "sample on how we actually submit a job it's very again very it's trivial",
    "start": "3023680",
    "end": "3029289"
  },
  {
    "text": "honestly just need to give it the job definition the job name and the job queue you can",
    "start": "3029289",
    "end": "3036460"
  },
  {
    "text": "do some overrides as well if you need to but that's all you need with the AWS SDK for go",
    "start": "3036460",
    "end": "3044549"
  },
  {
    "text": "so I have a little demo if you're not",
    "start": "3050230",
    "end": "3061599"
  },
  {
    "text": "quite sure how to play",
    "start": "3061599",
    "end": "3064440"
  },
  {
    "text": "do you know how we start the video yes II was showing up here so people really click there we go oh I see",
    "start": "3068420",
    "end": "3080500"
  },
  {
    "text": "okay so this is how it looks in action like assume you have to do a part that would connect the three green dots but",
    "start": "3081620",
    "end": "3087740"
  },
  {
    "text": "then keep the space that you just saw in red empty our software would generate",
    "start": "3087740",
    "end": "3094760"
  },
  {
    "text": "the variance so these are all the variance and then fill the geometry for each of them then you can explore it and",
    "start": "3094760",
    "end": "3101080"
  },
  {
    "text": "look at them and choose the one that fits best for your project you can sort",
    "start": "3101080",
    "end": "3106550"
  },
  {
    "text": "by various characteristics you can you",
    "start": "3106550",
    "end": "3115520"
  },
  {
    "text": "can see the basically you know look around and finally you can explore it",
    "start": "3115520",
    "end": "3120830"
  },
  {
    "text": "you know on that price performance curve not necessarily price and performance",
    "start": "3120830",
    "end": "3126110"
  },
  {
    "text": "you can also sort you know have the curve based on strength of the part or the material that it's used so you can",
    "start": "3126110",
    "end": "3136100"
  },
  {
    "text": "easily get you know hundreds of designs for a solution so hundreds of designs",
    "start": "3136100",
    "end": "3141260"
  },
  {
    "text": "for a problem that would you know take humans much much longer to make on their",
    "start": "3141260",
    "end": "3146510"
  },
  {
    "text": "own on their own with a generative",
    "start": "3146510",
    "end": "3152180"
  },
  {
    "text": "design so far we started using this about six months ago more seriously and",
    "start": "3152180",
    "end": "3158990"
  },
  {
    "text": "we've created twenty two hundred studies about ten times more design options were",
    "start": "3158990",
    "end": "3169670"
  },
  {
    "text": "computed this is just an example of what",
    "start": "3169670",
    "end": "3175340"
  },
  {
    "text": "you can get you know if you input if your problem is to create a bike frame",
    "start": "3175340",
    "end": "3182350"
  },
  {
    "text": "and lastly we actually used our genitive",
    "start": "3183580",
    "end": "3190100"
  },
  {
    "text": "design software to generate the floor plan for our Toronto office and we",
    "start": "3190100",
    "end": "3198230"
  },
  {
    "text": "inputted things like you know how the number of desk we needed the the width of the corridor the space between them",
    "start": "3198230",
    "end": "3203780"
  },
  {
    "text": "and so on and you know got a bunch of options which we finally converged on",
    "start": "3203780",
    "end": "3210830"
  },
  {
    "text": "and they built from one of those who actually built our our new office that way that's it thank",
    "start": "3210830",
    "end": "3220150"
  },
  {
    "text": "you mister thanks Tina that's really",
    "start": "3220150",
    "end": "3228160"
  },
  {
    "text": "exciting I had a chance to visit Autodesk's office in San Francisco and they had actually a number of quadcopter",
    "start": "3228160",
    "end": "3234369"
  },
  {
    "text": "designs that were generated using the this generative design technique and somebody likes to fly quad copters was",
    "start": "3234369",
    "end": "3239530"
  },
  {
    "text": "amazing to see all the different variations that are created by this and how each were optimized for cost or for",
    "start": "3239530",
    "end": "3245859"
  },
  {
    "text": "longevity of flight or other attributes really complication of the service so",
    "start": "3245859",
    "end": "3251050"
  },
  {
    "text": "just to summarize I wanted to you know close out with before we go to questions with a few links that all of our slides",
    "start": "3251050",
    "end": "3258310"
  },
  {
    "text": "will be posted you can find them on SlideShare and on YouTube within a couple of days of today's talk just some",
    "start": "3258310",
    "end": "3263980"
  },
  {
    "text": "links to the to the sample code for for the batch and the step functions integration will also be tweeting and",
    "start": "3263980",
    "end": "3270790"
  },
  {
    "text": "finding other ways to get out links to to batch it and some of the other tools that our presenters that have have open",
    "start": "3270790",
    "end": "3276160"
  },
  {
    "text": "sourced and a few other open-source projects that have emerged trendy to be us batch in the past month or so and so",
    "start": "3276160",
    "end": "3281380"
  },
  {
    "text": "if I'd like to thank everybody for your time and with the remaining five or seven minutes I'd like to take any",
    "start": "3281380",
    "end": "3286720"
  },
  {
    "text": "questions that you have there's a microphone over here and also we have a",
    "start": "3286720",
    "end": "3292000"
  },
  {
    "text": "few other folks who weren't able to join us on stage for the presentation but they're available to answer questions Erin and Brenton and Oleg so any",
    "start": "3292000",
    "end": "3300010"
  },
  {
    "text": "questions sure yeah sorry - does it pass",
    "start": "3300010",
    "end": "3306640"
  },
  {
    "text": "that yeah you have a question so yeah question is is there any time",
    "start": "3306640",
    "end": "3314070"
  },
  {
    "text": "any timeframe for Windows support so we already support windows in unmanaged",
    "start": "3314070",
    "end": "3319440"
  },
  {
    "text": "compute environments today so if you have a containerized Windows application that you'd like to run on on AWS batch",
    "start": "3319440",
    "end": "3325430"
  },
  {
    "text": "you create a compute environment using the windows ECS optimized ami and then you can submit jobs just as you would if",
    "start": "3325430",
    "end": "3332579"
  },
  {
    "text": "those are running Linux applications as the the support for Windows transitions",
    "start": "3332579",
    "end": "3338849"
  },
  {
    "text": "from from beta to GA within the ec2 container service you can expect that will quickly follow suit and support",
    "start": "3338849",
    "end": "3344220"
  },
  {
    "text": "Windows workloads an AWS patch as a first-class citizen yeah yeah the only",
    "start": "3344220",
    "end": "3350700"
  },
  {
    "text": "thing that we don't do right now is is a provisioning of your your Windows ec2 instances but that's something that we",
    "start": "3350700",
    "end": "3356940"
  },
  {
    "text": "would be doing as a follow-up to BCS supporting Windows containers as a ga at",
    "start": "3356940",
    "end": "3366630"
  },
  {
    "text": "the moment yes at the moment yes yes I'm",
    "start": "3366630",
    "end": "3373440"
  },
  {
    "text": "sorry yes yeah the question is will there be",
    "start": "3373440",
    "end": "3378850"
  },
  {
    "text": "support for a gov cloud in the future absolutely so as you saw on our road map slide regional expansion kind of",
    "start": "3378850",
    "end": "3384400"
  },
  {
    "text": "continuing from one region last year this time to nine today we're gonna round out the the remaining regions and",
    "start": "3384400",
    "end": "3390280"
  },
  {
    "text": "we don't yet support very early in 2018 so gov cloud my time at Amazon I've had",
    "start": "3390280",
    "end": "3395530"
  },
  {
    "text": "the opportunity to work with customers like NASA Jet Propulsion Laboratory who helped us to find the requirements for",
    "start": "3395530",
    "end": "3400840"
  },
  {
    "text": "the for the Gov cob region it's very high on our priority list to be able to support HR sensitive workloads yep great",
    "start": "3400840",
    "end": "3410140"
  },
  {
    "text": "any other questions yes okay question is do we have any",
    "start": "3410140",
    "end": "3421090"
  },
  {
    "text": "plans to support you know things that you can run in an EMR cluster elastic MapReduce cluster like spark jobs so we",
    "start": "3421090",
    "end": "3426970"
  },
  {
    "text": "actually have a number of customers that are running spark jobs within a TBS patch today they're running single node spark and so you can get quite a few V",
    "start": "3426970",
    "end": "3433990"
  },
  {
    "text": "CPUs on an ec2 instance today but we actually with the the support for jobs",
    "start": "3433990",
    "end": "3440410"
  },
  {
    "text": "that can span multiple instances we expect that to be one of the workloads that would be possible on batch also",
    "start": "3440410",
    "end": "3446410"
  },
  {
    "text": "looking at EDD workloads like MPI or other tightly coupled applications is",
    "start": "3446410",
    "end": "3451630"
  },
  {
    "text": "there another question over here - okay you're helping find it thank you any other questions",
    "start": "3451630",
    "end": "3459600"
  },
  {
    "text": "okay yeah great great question so asking if we have plans to support time based",
    "start": "3466950",
    "end": "3473230"
  },
  {
    "text": "scheduling so instead of scheduling based on compute resources Calendar and and and wall clock scheduling so today",
    "start": "3473230",
    "end": "3479650"
  },
  {
    "text": "the the way that you do that is setting up a cloud watch scheduled event which supports crown cron syntax that triggers",
    "start": "3479650",
    "end": "3485859"
  },
  {
    "text": "a lambda function which then submits the job database match so one of the features on our near-term roadmap is the",
    "start": "3485859",
    "end": "3491980"
  },
  {
    "text": "ability to have an event automatically trigger the submission of a native grass batch job that would be that would you",
    "start": "3491980",
    "end": "3498550"
  },
  {
    "text": "know eliminate one of the services from that picture we want to simplify that much like lambda has scheduled lambda",
    "start": "3498550",
    "end": "3504490"
  },
  {
    "text": "function execution they use cloud much scheduled events behind the scenes for that we'll be doing something very",
    "start": "3504490",
    "end": "3510339"
  },
  {
    "text": "similar with the theaetetus batch console we'll also be looking at other scheduling algorithms scheduling in",
    "start": "3510339",
    "end": "3516310"
  },
  {
    "text": "terms of expressing things like the the resource requirements the the the",
    "start": "3516310",
    "end": "3521500"
  },
  {
    "text": "maximum or estimated duration for your job in the budget so that we can pick the most cost-effective time to run your",
    "start": "3521500",
    "end": "3526869"
  },
  {
    "text": "workload so deadlines scheduling and other scheduling algorithms great well",
    "start": "3526869",
    "end": "3536109"
  },
  {
    "text": "with no more questions liked it round of applause again for all of our fantastic presenters thank you [Applause]",
    "start": "3536109",
    "end": "3544090"
  }
]
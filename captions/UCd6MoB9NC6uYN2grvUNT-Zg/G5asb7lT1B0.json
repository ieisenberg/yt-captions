[
  {
    "start": "0",
    "end": "94000"
  },
  {
    "text": "good afternoon everyone a very warm welcome to the very last session of the",
    "start": "2520",
    "end": "8800"
  },
  {
    "text": "day I'm here to give you the good news and the bad news about big data which do",
    "start": "8800",
    "end": "14120"
  },
  {
    "text": "you want first do you want the bad news first or the good news first I knew you going to say that I'll",
    "start": "14120",
    "end": "19680"
  },
  {
    "text": "give you the good news first the good news is there has never been a more exciting time to be in the big data or",
    "start": "19680",
    "end": "26000"
  },
  {
    "text": "the analytic space there is so much good stuff going on so much is available to",
    "start": "26000",
    "end": "31279"
  },
  {
    "text": "us to really Drive some fantastic analysis this challenge is of course the",
    "start": "31279",
    "end": "37360"
  },
  {
    "text": "volume of data is growing the variety of data is growing the velocity of data is growing all the 3vs that we always hear",
    "start": "37360",
    "end": "43200"
  },
  {
    "text": "about but as the saying goes necessity is the mother of invention and there has",
    "start": "43200",
    "end": "48239"
  },
  {
    "text": "been some incredible inventing going on in the last 5 10 years you marry that",
    "start": "48239",
    "end": "55320"
  },
  {
    "text": "invention with the power and the scale of the cloud and you've got some f fantastic Technologies and tools to work",
    "start": "55320",
    "end": "62920"
  },
  {
    "text": "with that's the good news the bad news is how do you keep up how do you",
    "start": "62920",
    "end": "68960"
  },
  {
    "text": "possibly keep up with all the Innovation whenever you wake up in the morning and you check your news your feeds wherever",
    "start": "68960",
    "end": "75240"
  },
  {
    "text": "you get your info from there's a new open source project that's been released there's a new release from one of the vendors Amazon's come out with a new",
    "start": "75240",
    "end": "81720"
  },
  {
    "text": "service Amazon's changed the service how do you possibly keep up with that and customers often say to me you know",
    "start": "81720",
    "end": "87000"
  },
  {
    "text": "what's what's the best particular project or service for my use case so",
    "start": "87000",
    "end": "94200"
  },
  {
    "start": "94000",
    "end": "286000"
  },
  {
    "text": "the good news is this presentation will make it all crystal clear in one hour we we'll have it all absolutely sorted",
    "start": "94200",
    "end": "101399"
  },
  {
    "text": "that's that's the good news so what we're going to do as an agenda is we're going to look at an endtoend framework",
    "start": "101399",
    "end": "108680"
  },
  {
    "text": "for some of the Big Data Technologies I'm going to step you through how you might use the AWS cloud from end to end",
    "start": "108680",
    "end": "117039"
  },
  {
    "text": "to start doing some some analytics in an agile way once we've done that we're going to layer on top of that some use cases some",
    "start": "117039",
    "end": "123920"
  },
  {
    "text": "some common use cases that we see on top of those building blocks so you can kind of see how they're used in",
    "start": "123920",
    "end": "129759"
  },
  {
    "text": "practice uh and then at the end there if the if the gods smile on us we'll do uh we'll do a little demonstration as",
    "start": "129759",
    "end": "136400"
  },
  {
    "text": "well so that's our main agenda I also want to sprinkle a couple of other items in there as well I want to talk about",
    "start": "136400",
    "end": "142680"
  },
  {
    "text": "the greater good that big data can do for us I want to talk about religion yes",
    "start": "142680",
    "end": "148360"
  },
  {
    "text": "we're going to go there and I want to talk about fomo I want to talk about the fear of missing out uh and we'll cover",
    "start": "148360",
    "end": "154319"
  },
  {
    "text": "that off as well so let's first talk about the greater good so when we look at Big Data",
    "start": "154319",
    "end": "159519"
  },
  {
    "text": "Technologies and all the analytics great stuff that's out there we always look at what that can do for us and look at what",
    "start": "159519",
    "end": "164720"
  },
  {
    "text": "that can do for our organizations and that's fantastic but I think sometimes it's nice to take a step back and think",
    "start": "164720",
    "end": "170480"
  },
  {
    "text": "about what can Big Data do for the greater good what can it do for the for for Humanity as a whole and there are a",
    "start": "170480",
    "end": "176480"
  },
  {
    "text": "lot of men and women working in this field to really benefit all of us and there's one particular project which is",
    "start": "176480",
    "end": "182840"
  },
  {
    "text": "quite near and dear to my heart I've had friends affected by this and I'm sure you have as well and it's the project",
    "start": "182840",
    "end": "189200"
  },
  {
    "text": "that deals with people posting to social media when they've had too much to drink it's a big problem we've all done",
    "start": "189200",
    "end": "196120"
  },
  {
    "text": "it we've all been out late at night and we've pressed send on that text message that shouldn't have gone or we've",
    "start": "196120",
    "end": "202000"
  },
  {
    "text": "uploaded to Facebook a picture that maybe we shouldn't have and there are different ways of dealing with this so",
    "start": "202000",
    "end": "207239"
  },
  {
    "text": "there's applications you can get on your phone which will hide your contact list from you for example for for 5 or 6",
    "start": "207239",
    "end": "213599"
  },
  {
    "text": "hours that kind of works to some extent or there's other apps that go a step further where they'll actually analyze",
    "start": "213599",
    "end": "219640"
  },
  {
    "text": "your text message if there's too many spelling mistakes it won't send the message if there's too much of a gap",
    "start": "219640",
    "end": "226120"
  },
  {
    "text": "between the last word and when you hit send won't send the message assuming that you're fumbling for the send button",
    "start": "226120",
    "end": "232599"
  },
  {
    "text": "thinks you're probably not in a fit state to send it that's great but I think the power of",
    "start": "232599",
    "end": "238000"
  },
  {
    "text": "Big Data if you look at what Facebook are doing now they're actually looking at using some deep learning techniques",
    "start": "238000",
    "end": "243159"
  },
  {
    "text": "to actually analyze your photos on the fly in real time to decide whether they",
    "start": "243159",
    "end": "249640"
  },
  {
    "text": "think that's something you're going to be embarrassed about the next day so this is the project that they've got going they announced it last",
    "start": "249640",
    "end": "256600"
  },
  {
    "text": "November deep learning techniques so what they'll do is they'll actually train this machine learning algorithm on",
    "start": "256600",
    "end": "262320"
  },
  {
    "text": "appropriate pictures and non-appropriate pictures and then if it's inappropriate then they won't send it for you thought",
    "start": "262320",
    "end": "268919"
  },
  {
    "text": "that was a fantastic use of the technology that benefits all of us that benefits the human race in a very",
    "start": "268919",
    "end": "274840"
  },
  {
    "text": "meaningful way um that cow by the way is actually part of a different story when I crop this that's not actually supposed",
    "start": "274840",
    "end": "280919"
  },
  {
    "text": "to be someone's embarrassing picture um so I don't get the wrong idea about that so let's start talking about this",
    "start": "280919",
    "end": "288320"
  },
  {
    "start": "286000",
    "end": "526000"
  },
  {
    "text": "this big data end to- end framework and the first thing I want to do is just",
    "start": "288320",
    "end": "294880"
  },
  {
    "text": "cover off on the Amazon services in this space so a lot of you are very familiar with these I know but just on the same p page let me just go round the clock and",
    "start": "294880",
    "end": "302080"
  },
  {
    "text": "quickly just cover off what Amazon's got in this space and then we'll see how it all fits together so in the middle we've got Amazon",
    "start": "302080",
    "end": "308600"
  },
  {
    "text": "S3 simple storage service great place to store objects and files Etc very",
    "start": "308600",
    "end": "313680"
  },
  {
    "text": "scalable very durable at 6:00 we've got Amazon Glacier same as S3 but a lot",
    "start": "313680",
    "end": "321039"
  },
  {
    "text": "colder that's basically our long-term storage archive so it's much cheaper to store data in glacia than it is in S3",
    "start": "321039",
    "end": "326960"
  },
  {
    "text": "but it takes longer to retrieve it going clockwise we've got Amazon RDS that's",
    "start": "326960",
    "end": "332120"
  },
  {
    "text": "our relational database service so that's a managed database service so what that means is we'll manage the",
    "start": "332120",
    "end": "337919"
  },
  {
    "text": "infrastructure underneath for you we'll patch it we'll back it up we'll install the software and then you just get to",
    "start": "337919",
    "end": "343960"
  },
  {
    "text": "use that database as you would normally that comes in four flavors MySQL postest oricon SQL server and it is your",
    "start": "343960",
    "end": "350600"
  },
  {
    "text": "traditional relational database as you know it and love it today up at 10:00 we've got Amazon",
    "start": "350600",
    "end": "356560"
  },
  {
    "text": "redshift also a relational database a managed relational database but this is targeted at analytical workloads as",
    "start": "356560",
    "end": "364280"
  },
  {
    "text": "opposed to more of a transactional workload that you would get with RDS and we'll look at that in a bit more detail as we go through at 12:00 we've got",
    "start": "364280",
    "end": "371759"
  },
  {
    "text": "Amazon Kinesis very exciting new service that's designed for Real Time analytics so the ability to ingest data in real",
    "start": "371759",
    "end": "378800"
  },
  {
    "text": "time and then analyze it do something with it we'll have a bit of a look at that Amazon Dynamo DB is our nosql",
    "start": "378800",
    "end": "386479"
  },
  {
    "text": "database now we're not going to talk a lot about nosql today not because it's not awesome but just because it doesn't",
    "start": "386479",
    "end": "392199"
  },
  {
    "text": "quite fit into the processing framework that that we're going to be talking about we don't really have time to cover it off but no sequel for certain use",
    "start": "392199",
    "end": "398800"
  },
  {
    "text": "cases is is phenomenal at 3:00 we've got Amazon machine learning this is a brand new",
    "start": "398800",
    "end": "404680"
  },
  {
    "text": "service hot off the press which again we won't cover in any great detail but is a great way to get into the machine",
    "start": "404680",
    "end": "409960"
  },
  {
    "text": "learning space and then we've got Amazon EMR so that's our elastic map produce service",
    "start": "409960",
    "end": "416440"
  },
  {
    "text": "and again it's a managed service that gives you a Hadoop cluster so we'll spin",
    "start": "416440",
    "end": "421919"
  },
  {
    "text": "up the ec2 machines we'll install Hadoop we'll make sure that all the nodes are",
    "start": "421919",
    "end": "427560"
  },
  {
    "text": "talking to each other make sure it's all up to date and then we tie a nice big red bow around it and we hand it to you",
    "start": "427560",
    "end": "433080"
  },
  {
    "text": "when you can start using it as you'll see the theme as we go around here is all about manage services it's all about",
    "start": "433080",
    "end": "439639"
  },
  {
    "text": "removing the undifferentiated heavy lifting from you guys so that you can start to use and analyze and do the fun",
    "start": "439639",
    "end": "445759"
  },
  {
    "text": "stuff much more quickly now so this is this is the the Amazon offering in the Big Data space",
    "start": "445759",
    "end": "452000"
  },
  {
    "text": "But even just with our own Services there's overlap with the different services and hence questions about what",
    "start": "452000",
    "end": "457479"
  },
  {
    "text": "I should use and when I should use it so for example a lot of questions around okay RDS is a relational database red",
    "start": "457479",
    "end": "463800"
  },
  {
    "text": "shift is a relational database when should I use which one that's a valid",
    "start": "463800",
    "end": "469240"
  },
  {
    "text": "question which we'll cover off later on also red shift and EMR they're both designed to deal with large data sets",
    "start": "469240",
    "end": "474879"
  },
  {
    "text": "and process those data sets when do I use EMR when do I use redshift so so you can see even even in this set of",
    "start": "474879",
    "end": "481919"
  },
  {
    "text": "services there's questions around which which service to use now you layer on top of our services our partner Services thirdparty",
    "start": "481919",
    "end": "489840"
  },
  {
    "text": "software open- Source projects this is obviously just a very small slice you can start to see it becomes very",
    "start": "489840",
    "end": "495800"
  },
  {
    "text": "confusing and it's not immediately obvious what's the best service and what's the best Technologies to use for",
    "start": "495800",
    "end": "501720"
  },
  {
    "text": "my particular use case so that's what I want to try and do is put some put some structure around some of these uh and",
    "start": "501720",
    "end": "507479"
  },
  {
    "text": "give you give you a framework to use now one of the other things I want to I want to cover off on on this and I saw a",
    "start": "507479",
    "end": "514800"
  },
  {
    "text": "quote the other day that perfectly summed up what I was actually trying to say here and it was basically this",
    "start": "514800",
    "end": "521200"
  },
  {
    "text": "quote so this is true across all of it right we always have these religious debates about which is better and you",
    "start": "526839",
    "end": "532920"
  },
  {
    "text": "kind of expect that but normally you expect it in a certain category so my relational database is better than your",
    "start": "532920",
    "end": "539040"
  },
  {
    "text": "relational database that kind of thing but in the Big Data space we seem to have taken it to a whole new level now",
    "start": "539040",
    "end": "544839"
  },
  {
    "text": "where whole categories are trying to deliver a knockout blow to other categories so the Hadoop Camp saying",
    "start": "544839",
    "end": "550720"
  },
  {
    "text": "hadoop's the future relational databases are dead the nosql guys are saying hey",
    "start": "550720",
    "end": "556240"
  },
  {
    "text": "no sequels the future relational databases are dead and the relational database guys are saying why are you",
    "start": "556240",
    "end": "561720"
  },
  {
    "text": "picking on us you know we' we've been good friends to you for very many years why are you why are you pronouncing us",
    "start": "561720",
    "end": "567120"
  },
  {
    "text": "dead but the key Point here is that it really doesn't matter certainly our view on this is that it's not a one- siiz",
    "start": "567120",
    "end": "573920"
  },
  {
    "text": "fits-all type of approach every bit of software every technology every service",
    "start": "573920",
    "end": "579120"
  },
  {
    "text": "has got its good points and its bad points you use what is best for your use case and as we see as we go through",
    "start": "579120",
    "end": "584839"
  },
  {
    "text": "sometimes that might be an Amazon service sometimes it might not be for us it's all about what's best for your particular use",
    "start": "584839",
    "end": "591440"
  },
  {
    "text": "case so we're going to as a framework going to use this this long tube this is a magic tube where you put data in one",
    "start": "591440",
    "end": "597720"
  },
  {
    "text": "end and your answers magically out the other end but basically the process is this we're going to look at how you",
    "start": "597720",
    "end": "603480"
  },
  {
    "text": "ingest data into the cloud where do you store it how do you process it and then",
    "start": "603480",
    "end": "609040"
  },
  {
    "text": "what do you use to analyze it so let's have a look at ingest first",
    "start": "609040",
    "end": "616200"
  },
  {
    "text": "now the way I like to split up inest is depending on the different types of data that you have it's is going to depend",
    "start": "616200",
    "end": "621680"
  },
  {
    "text": "how you get it in there so databases is probably the most common type of data",
    "start": "621680",
    "end": "628600"
  },
  {
    "text": "everyone's got a dat database in their environment and the typical use case here is I have a database it's probably",
    "start": "628600",
    "end": "634760"
  },
  {
    "text": "a transaction processing database supporting some kind of application I want to do some reporting some analysis",
    "start": "634760",
    "end": "640480"
  },
  {
    "text": "on it but it's too slow I'm not getting results fast enough I want to look at more history I want to look at more",
    "start": "640480",
    "end": "646959"
  },
  {
    "text": "detail and the database is simply just running out of puff it's just not giving me what I need so I want to move it to",
    "start": "646959",
    "end": "652200"
  },
  {
    "text": "something that's a bit more um bit more performant so we'll look at where that goes and the types of data we're talking",
    "start": "652200",
    "end": "658320"
  },
  {
    "text": "about sales Data customer data you know the types of stuff Erp CRM all sorts of",
    "start": "658320",
    "end": "664000"
  },
  {
    "text": "stuff then we've got what I'm calling file data now file data is typically",
    "start": "664000",
    "end": "669639"
  },
  {
    "text": "event data so it's transactions it's events that have happened on some kind of um processing engine but they come at",
    "start": "669639",
    "end": "676200"
  },
  {
    "text": "you in in chunks big chunks it might be a daily chunk it might be an hourly chunk full of a thousand or a million",
    "start": "676200",
    "end": "683120"
  },
  {
    "text": "different events and you can see some of the processing Frameworks there so log forj is a logging framework Flume and",
    "start": "683120",
    "end": "690120"
  },
  {
    "text": "fluent D um are aggregation log aggregation services that can take logs",
    "start": "690120",
    "end": "695160"
  },
  {
    "text": "off different machines and push them into one central place um so file data is another type of data you need to deal",
    "start": "695160",
    "end": "701639"
  },
  {
    "text": "with and it's things like web logs server logs that kind of machine to",
    "start": "701639",
    "end": "706680"
  },
  {
    "text": "machine type stuff and then we've got streaming data so streaming data similar to file data",
    "start": "706680",
    "end": "713720"
  },
  {
    "text": "can be events so it's often an event or transaction that's happened the difference is that instead of coming at",
    "start": "713720",
    "end": "719040"
  },
  {
    "text": "you in a big chunk it's fired at you as it happens so you're getting thousands",
    "start": "719040",
    "end": "724279"
  },
  {
    "text": "or millions of tiny little events happening all the time that kind of realtime streaming scenario so it might",
    "start": "724279",
    "end": "730320"
  },
  {
    "text": "be clickstream data it might be sensor data so you might have a network of sensors that are sending information",
    "start": "730320",
    "end": "736800"
  },
  {
    "text": "about um about readings that they're experiencing you want to capture those and do something with them and we'll",
    "start": "736800",
    "end": "742199"
  },
  {
    "text": "spend a bit ofit time talking about that because it's a really interesting area at the moment so there are three types of",
    "start": "742199",
    "end": "748360"
  },
  {
    "text": "injest so let's look at storage so profoundly database data",
    "start": "748360",
    "end": "753600"
  },
  {
    "text": "typically goes into another database now it doesn't have to it can go into other",
    "start": "753600",
    "end": "759920"
  },
  {
    "text": "places but the common use case that we see is it goes into another database and the reasons for this are pretty simple",
    "start": "759920",
    "end": "765680"
  },
  {
    "text": "firstly it's the data is highly structured already so it's in a database it's got that structure so you may as",
    "start": "765680",
    "end": "772279"
  },
  {
    "text": "well keep it in a structured format the data might have relations between tables that's all been set up",
    "start": "772279",
    "end": "778720"
  },
  {
    "text": "see as will reuse that plus you've obviously got SQL skills and database",
    "start": "778720",
    "end": "783800"
  },
  {
    "text": "skills in your organization because you've got that original database so you want to also utilize those skills when",
    "start": "783800",
    "end": "789040"
  },
  {
    "text": "you move to your analytical database as well now there's a couple of",
    "start": "789040",
    "end": "794279"
  },
  {
    "text": "different database options I'm going to look at Amazon red shift and Amazon IDs",
    "start": "794279",
    "end": "800320"
  },
  {
    "text": "but when I do that I want you to think about not just these two services but the fact they represent their tribe if",
    "start": "800320",
    "end": "806639"
  },
  {
    "text": "you like so Amazon RDS representing the tribe of traditional relational databases MySQL postr SQL Server Etc and",
    "start": "806639",
    "end": "814839"
  },
  {
    "text": "Amazon red shift representing the newer breed of analytical MPP massively parallel databases and we'll look at",
    "start": "814839",
    "end": "822000"
  },
  {
    "text": "that as we go through now getting data out of a database can be a little bit tricky if",
    "start": "822000",
    "end": "828279"
  },
  {
    "text": "you want to do it in a in an ongoing change data capture kind of way if you want to capture the changes so often",
    "start": "828279",
    "end": "833839"
  },
  {
    "text": "we'll work with Partners in that area so there's a couple of really good ETL tools that we work with so ETL standing",
    "start": "833839",
    "end": "839399"
  },
  {
    "text": "for extract transform and load I've just put two up here there's quite a long list that that support Amazon really",
    "start": "839399",
    "end": "846440"
  },
  {
    "text": "well this is just two of the ones that we work with quite a lot and they will help you to get data out of those databases uh and push them into into the",
    "start": "846440",
    "end": "855800"
  },
  {
    "text": "cloud so let's just have a little chat about um Swiss Army",
    "start": "855880",
    "end": "861440"
  },
  {
    "start": "856000",
    "end": "1226000"
  },
  {
    "text": "knives the traditional relational database part of the reason that it's kind of been um been knocked so much",
    "start": "861440",
    "end": "867759"
  },
  {
    "text": "recently is that over the years it's been asked to do a lot it's become the Swiss army knife of of processing have a",
    "start": "867759",
    "end": "874560"
  },
  {
    "text": "processing problem put it in the put it in the database um and the problem is that over",
    "start": "874560",
    "end": "881959"
  },
  {
    "text": "the years we've developed fairly specific types of applications so we've been asking the database to support web",
    "start": "881959",
    "end": "888240"
  },
  {
    "text": "transactions so potentially thousands or tens of thousands of transactions a second we've asked it to do search we've",
    "start": "888240",
    "end": "894240"
  },
  {
    "text": "asked it to do complex transactions hot res logs analytics we've said do it all",
    "start": "894240",
    "end": "901240"
  },
  {
    "text": "that's why that's why it's been struggling so what's happened in the last few years is we said let's break out that those specific tasks into best",
    "start": "901240",
    "end": "909360"
  },
  {
    "text": "of breed specialized engines so that's why you've seen the rise of no SQL databases because people were frustrated",
    "start": "909360",
    "end": "916360"
  },
  {
    "text": "with the ability for a relational database to support webscale transactions that was kind of the reason for being for the nosql databases and so",
    "start": "916360",
    "end": "924399"
  },
  {
    "text": "they support that that use case really well search obviously goes into a dedicated search engine there's",
    "start": "924399",
    "end": "930720"
  },
  {
    "text": "dedicated cases for those hot reads logs can go into an object store the data warehouse is where you do your analytics",
    "start": "930720",
    "end": "937720"
  },
  {
    "text": "and so I believe that the traditional relational database is actually stronger than ever because it's now being allowed",
    "start": "937720",
    "end": "943959"
  },
  {
    "text": "to focus on what it's good at which is complex queries and transactions everybody uses a relational database in",
    "start": "943959",
    "end": "950720"
  },
  {
    "text": "their environment to do transactional workloads which is what they're good at and so I think you'll see the relational",
    "start": "950720",
    "end": "956560"
  },
  {
    "text": "databases go from strength to strength because they've offloaded a lot of this this other processing now Amazon does have services",
    "start": "956560",
    "end": "964199"
  },
  {
    "text": "in each of those categories I'm not going to go through those I'm just going to focus on those bottom two on the right there Amazon RS uh and red shift",
    "start": "964199",
    "end": "971800"
  },
  {
    "text": "and we're going to put them head-to-head we're going to put them in a in the ring together to fight it",
    "start": "971800",
    "end": "976959"
  },
  {
    "text": "out and we're going to look at it along these lines now remember these are representing their kind so RDS",
    "start": "976959",
    "end": "983639"
  },
  {
    "text": "traditional relational Amazon red shift um MPP",
    "start": "983639",
    "end": "989680"
  },
  {
    "text": "database so firstly this is important the types of databases that they are is the same so they both support an",
    "start": "989680",
    "end": "996600"
  },
  {
    "text": "standard SQL and they're both fully relational now that's important because some people think that when you move to an MPP database you don't have joins you",
    "start": "996600",
    "end": "1004560"
  },
  {
    "text": "don't have relations it's not really SQL um that's not the case full an standard SQL full relations so you could pick up",
    "start": "1004560",
    "end": "1010800"
  },
  {
    "text": "your data model with all its joins and relations and put that into an MPP database and then query it as you would",
    "start": "1010800",
    "end": "1016920"
  },
  {
    "text": "normally and it be very happy but here's where they differ in the architecture so a",
    "start": "1016920",
    "end": "1023800"
  },
  {
    "text": "traditional relational database is based on an SNP architecture now s SMP is a bit of a '90s",
    "start": "1023800",
    "end": "1029438"
  },
  {
    "text": "acronym that you don't hear much anymore that stands for symmetric multiprocessing and really what it means",
    "start": "1029439",
    "end": "1035079"
  },
  {
    "text": "is that those machines are really good at sharing resources in a single machine",
    "start": "1035079",
    "end": "1040480"
  },
  {
    "text": "or a small cluster of machines and that's why they get such great performance for transactional",
    "start": "1040480",
    "end": "1046880"
  },
  {
    "text": "workloads so I like to think of the spp databases is a bit like my 7-year-old",
    "start": "1046880",
    "end": "1052400"
  },
  {
    "text": "daughter she loves to share great at sharing sharing with a family sharing with a friends the mppb databases are my",
    "start": "1052400",
    "end": "1060320"
  },
  {
    "text": "four-year-old hates to share doesn't want to share anything now that's normally bad I'm",
    "start": "1060320",
    "end": "1065799"
  },
  {
    "text": "always telling it to share but in in the database world if you're trying to scale you want your nodes to be selfish you",
    "start": "1065799",
    "end": "1073120"
  },
  {
    "text": "want selfish nodes that keep to themselves and don't share resources because that's how you scale",
    "start": "1073120",
    "end": "1080000"
  },
  {
    "text": "so when you add a node to an MPP database it's got its own dis it's got its own memory it's got its own CPU it",
    "start": "1080000",
    "end": "1087240"
  },
  {
    "text": "doesn't need anything from anyone else so there's no contention for resource so that's why when you look at",
    "start": "1087240",
    "end": "1092919"
  },
  {
    "text": "scaling the traditional relational databases scale vertically so if you want to make it go faster you got to get",
    "start": "1092919",
    "end": "1098320"
  },
  {
    "text": "a bigger box but the MPP databases you scale them horizontally you as add more nodes and",
    "start": "1098320",
    "end": "1105280"
  },
  {
    "text": "you'll get returns in terms of performance so if you double number of nodes you should have the response time",
    "start": "1105280",
    "end": "1111080"
  },
  {
    "text": "for a query should be nice and linear uh and that's fantastic storage",
    "start": "1111080",
    "end": "1116760"
  },
  {
    "text": "is also interesting so the the relational databas is the traditional relational database is store by row which is fantastic for transactional",
    "start": "1116760",
    "end": "1123280"
  },
  {
    "text": "workloads because you're reading a row at a time or you're writing a row at a time not so good for analytics because",
    "start": "1123280",
    "end": "1128720"
  },
  {
    "text": "you only want to read maybe a couple of columns but you want to read a lot of rows if the if the data is stored in",
    "start": "1128720",
    "end": "1135360"
  },
  {
    "text": "rows you got to read a lot of redundant data and IO is the enemy of good performance when",
    "start": "1135360",
    "end": "1141440"
  },
  {
    "text": "you're doing analytics so if you look at Red shift is a column the database stores the data in columns and that",
    "start": "1141440",
    "end": "1147480"
  },
  {
    "text": "basically means that when you go to run a query where you're looking at a few columns but lots of rows the system can",
    "start": "1147480",
    "end": "1153440"
  },
  {
    "text": "just suck those off the dis really quickly and you're not reading redundant redundant",
    "start": "1153440",
    "end": "1158880"
  },
  {
    "text": "data which leads us to the workload traditional relational databases fantastic for transactional",
    "start": "1158880",
    "end": "1165880"
  },
  {
    "text": "workloads MPP databases like red shift fantastic for analytical workloads now the question then becomes",
    "start": "1165880",
    "end": "1173320"
  },
  {
    "text": "at what point does it make sense to move to an MPP database how much data do you need to have to make it worthwhile now",
    "start": "1173320",
    "end": "1180159"
  },
  {
    "text": "there's no hard and fast rule here but my rule of thumb generally tends to be",
    "start": "1180159",
    "end": "1185799"
  },
  {
    "text": "between 50 and 100 Gig is kind of where it makes sense to to move across I've",
    "start": "1185799",
    "end": "1191240"
  },
  {
    "text": "got some customers who've got 10 GB and they love the performance that they get from Red shift depends on the type of",
    "start": "1191240",
    "end": "1197480"
  },
  {
    "text": "processing you're doing but probably around that 50 to 100 Gig Mark is where you'd probably start to start to",
    "start": "1197480",
    "end": "1204279"
  },
  {
    "text": "look uh quick customer example Financial Times in the UK they moved from an on premise traditional relational database",
    "start": "1204600",
    "end": "1210720"
  },
  {
    "text": "to Red shift um they talked about some of their queries running 98%",
    "start": "1210720",
    "end": "1218120"
  },
  {
    "text": "faster I'm not actually quite sure how you calculate that in terms of time our math isn't as good good enough for that",
    "start": "1218120",
    "end": "1223520"
  },
  {
    "text": "but basically it's pretty quick so let's look at where the file",
    "start": "1223520",
    "end": "1229559"
  },
  {
    "start": "1226000",
    "end": "1555000"
  },
  {
    "text": "data goes now you got a couple of options here your file data can go into a specific application or it can go into",
    "start": "1229559",
    "end": "1235480"
  },
  {
    "text": "more generic storage so the specific applications I'm thinking about are things like Splunk and Sumo logic which",
    "start": "1235480",
    "end": "1241080"
  },
  {
    "text": "you might be familiar with these are dedicated software packages that give",
    "start": "1241080",
    "end": "1246120"
  },
  {
    "text": "you outof thebox functionality for reading machino machine data making sense of it analyzing it looking for",
    "start": "1246120",
    "end": "1252000"
  },
  {
    "text": "security issues that kind of thing great tools um if you want a slightly more",
    "start": "1252000",
    "end": "1257600"
  },
  {
    "text": "generic solution you might want want to put it into some kind of storage system the two we're going to look at are hdfs",
    "start": "1257600",
    "end": "1263799"
  },
  {
    "text": "which is hadoop's file system and S3 which is Amazon's Object Store so",
    "start": "1263799",
    "end": "1269039"
  },
  {
    "text": "looking at hdfs first hdfs is the file system embedded",
    "start": "1269039",
    "end": "1275200"
  },
  {
    "text": "in a Hadoop cluster so Hadoop sits on top of hdfs and uses that to distribute",
    "start": "1275200",
    "end": "1280520"
  },
  {
    "text": "data in the cluster now the key point about hdfs is it's got to have running",
    "start": "1280520",
    "end": "1285600"
  },
  {
    "text": "compute underneath it you got to have running machine for hdfs to to sit across because it",
    "start": "1285600",
    "end": "1291159"
  },
  {
    "text": "uses the storage on those machines now in the Amazon world you can either run this cluster yourself so you",
    "start": "1291159",
    "end": "1298159"
  },
  {
    "text": "can th those compute machines can be ec2 machines you can spin them up you can install Hadoop HDs will come with that",
    "start": "1298159",
    "end": "1305720"
  },
  {
    "text": "um and you're ready to go or you can use Amazon elastic map produce and so what",
    "start": "1305720",
    "end": "1312159"
  },
  {
    "text": "elastic map produce will do is it will do the management of those three rectangles for you it will spin up the",
    "start": "1312159",
    "end": "1318559"
  },
  {
    "text": "C2 machines it will still install Hadoop it will make sure they're all talking to each other um and basically you're ready",
    "start": "1318559",
    "end": "1324799"
  },
  {
    "text": "to go either way you've got a running Hadoop cluster that then allows you to",
    "start": "1324799",
    "end": "1330080"
  },
  {
    "text": "take advantage of the massive Hadoop ecosystem of tools out there so this is",
    "start": "1330080",
    "end": "1335240"
  },
  {
    "text": "this is just six of them but there's hundreds um they all plug into hero and so if",
    "start": "1335240",
    "end": "1341880"
  },
  {
    "text": "you've got your data sitting in htfs you can use those tools to then start to do analysis Transformations you name it",
    "start": "1341880",
    "end": "1350520"
  },
  {
    "text": "now contrast that with S3 so S3 there's no compute underneath it's just storage",
    "start": "1351120",
    "end": "1358080"
  },
  {
    "text": "and the idea is that if you sit in S3 you've then got the ability to to move into different other um processing",
    "start": "1358080",
    "end": "1364520"
  },
  {
    "text": "options so yes you can push it into EMR you can push it into red shift machine learning no SQL or of course any other",
    "start": "1364520",
    "end": "1371880"
  },
  {
    "text": "non- Amazon application as well so S3 potentially gives you a bit more flexibility in where that data goes",
    "start": "1371880",
    "end": "1379640"
  },
  {
    "text": "and of course you can um archive it off to Glacier as well if you wish so let's",
    "start": "1379640",
    "end": "1384880"
  },
  {
    "text": "do another uh another head to head so htfs and S3 in terms of",
    "start": "1384880",
    "end": "1390600"
  },
  {
    "text": "durability htfs has got a configurable option so it'll write data by default three times",
    "start": "1390600",
    "end": "1397400"
  },
  {
    "text": "to different places within the cluster every object with S3 obviously that that is built in so we'll automatically write",
    "start": "1397400",
    "end": "1404320"
  },
  {
    "text": "every object to three different physical locations for you in terms of the cost",
    "start": "1404320",
    "end": "1409600"
  },
  {
    "text": "hdfs tends to be higher because you've got to have running compute underneath whereas with S3 there's no",
    "start": "1409600",
    "end": "1416200"
  },
  {
    "text": "running compute it's just storage so it tends to be a little bit cheaper in terms of scaling it if you want more space in htfs you got to add",
    "start": "1416200",
    "end": "1423240"
  },
  {
    "text": "more nodes to your cluster with S3 obviously it's just automatic you just load up more data now it might seem that",
    "start": "1423240",
    "end": "1429799"
  },
  {
    "text": "I'm deliberately skewing this towards S3 but have a look at this last point which",
    "start": "1429799",
    "end": "1435799"
  },
  {
    "text": "is that hdfs tends to be a little bit faster and the reason for that is because if you've loaded your data into",
    "start": "1435799",
    "end": "1441600"
  },
  {
    "text": "hdfs the cluster is already running because it has to be and obviously your",
    "start": "1441600",
    "end": "1446919"
  },
  {
    "text": "data is already local it's already there whereas with S3 you got to move it to wherever you're going so again as I said",
    "start": "1446919",
    "end": "1452440"
  },
  {
    "text": "earlier it depends on your use case if your use case is that you get maybe a chunk of file twice a day then maybe you",
    "start": "1452440",
    "end": "1460360"
  },
  {
    "text": "don't want to running cluster all the time you don't want to pay for a constantly running cluster so you put that file in S3 you spin up a Hadoop",
    "start": "1460360",
    "end": "1466440"
  },
  {
    "text": "cluster you suck the data in you do your processing you shut the cluster down stop paying",
    "start": "1466440",
    "end": "1471559"
  },
  {
    "text": "for it or your use case might be you're getting chunks of data every 5 minutes",
    "start": "1471559",
    "end": "1477200"
  },
  {
    "text": "then it makes sense to have a running cluster you might as well have that in hdfs so again depends on your use case",
    "start": "1477200",
    "end": "1483039"
  },
  {
    "text": "and there's hybrid options of of course as well so you can use both uh good example of that was finra",
    "start": "1483039",
    "end": "1488799"
  },
  {
    "text": "the financial industry regulator regulatory Authority in the US these guys are tasked with looking at 30",
    "start": "1488799",
    "end": "1495520"
  },
  {
    "text": "billion trades a day that happen on the US Stock Exchange changes and looking for fraud obviously they want to do that",
    "start": "1495520",
    "end": "1501080"
  },
  {
    "text": "in a fairly timely fashion as you would what they do is they suck that in to S3",
    "start": "1501080",
    "end": "1506360"
  },
  {
    "text": "then they spin up bigo clusters and they push that processing through those clusters uh when they talk about the",
    "start": "1506360",
    "end": "1512320"
  },
  {
    "text": "benefits that they got they talk about agility they talk about performance and they talk about cost but the other interesting thing they talk about is",
    "start": "1512320",
    "end": "1518640"
  },
  {
    "text": "they talk about avoiding vendor lockin which I thought was quite interesting and the comment that he made was that",
    "start": "1518640",
    "end": "1525600"
  },
  {
    "text": "because the Big Data world is moving so quickly and Technologies are coming and going and changing he didn't want to get",
    "start": "1525600",
    "end": "1531799"
  },
  {
    "text": "locked into a particular proprietary technology he wanted to stay agnostic and he felt that doing that on Amazon",
    "start": "1531799",
    "end": "1537080"
  },
  {
    "text": "was the best way to do that let's move to streaming data so",
    "start": "1537080",
    "end": "1543640"
  },
  {
    "text": "streaming data typically goes into some kind of stream processor and a couple of",
    "start": "1543640",
    "end": "1549080"
  },
  {
    "text": "options we're going to look at we're going to look at Amazon Kinesis and we're going to look at Apache",
    "start": "1549080",
    "end": "1555120"
  },
  {
    "text": "Kafka now the first question is why do you need stream storage at all why don't you just spin up some orange boxes which",
    "start": "1555200",
    "end": "1562360"
  },
  {
    "text": "represent ec2 machines and then just fire all of the data at them and then",
    "start": "1562360",
    "end": "1568039"
  },
  {
    "text": "just collate it that way so let's assume that the data we're trying to collect is from sensors so this is a real world",
    "start": "1568039",
    "end": "1573240"
  },
  {
    "text": "example from one of our customers who deploy sensors throughout buildings and they're looking for things like",
    "start": "1573240",
    "end": "1578440"
  },
  {
    "text": "temperature humidity vibration all of that kind of stuff and Those sensors send information every 10",
    "start": "1578440",
    "end": "1584799"
  },
  {
    "text": "seconds now you could do this you could just spin up a lot of ec2 machine and ingest the data that way but what",
    "start": "1584799",
    "end": "1591399"
  },
  {
    "text": "you lose is you lose the ability to analyze data from a single device in a",
    "start": "1591399",
    "end": "1597000"
  },
  {
    "text": "meaningful way so what I mean by that is if we if we color code these arrows so",
    "start": "1597000",
    "end": "1602240"
  },
  {
    "text": "if you think of the color of an arrow representing a single device so with the Red Arrows say that's coming from a",
    "start": "1602240",
    "end": "1608679"
  },
  {
    "text": "single device so some of their messages are going to the top node some of their messages are going to the bottom node so",
    "start": "1608679",
    "end": "1615320"
  },
  {
    "text": "we can do things like we can have alerts that say if the temperature hits it's a certain or is is is out of band then",
    "start": "1615320",
    "end": "1622080"
  },
  {
    "text": "send an alert do something about it but we want to do something more meaningful we want to know is this temperature",
    "start": "1622080",
    "end": "1627760"
  },
  {
    "text": "trending up is it trending down how fast is it trending well you can't do that if you don't have access to all the",
    "start": "1627760",
    "end": "1633279"
  },
  {
    "text": "information from that device so what you need to do is to group you need to group those messages in some way so this is",
    "start": "1633279",
    "end": "1639080"
  },
  {
    "text": "why we have the stream processing engine which basically captures the",
    "start": "1639080",
    "end": "1644279"
  },
  {
    "text": "messages then groups them in a way that you specify before it then gets processed so now you can see all the Red",
    "start": "1644279",
    "end": "1652120"
  },
  {
    "text": "Arrows have been grouped together so they all get processed by the same worker so that worker can then look at",
    "start": "1652120",
    "end": "1659799"
  },
  {
    "text": "is this trending up down how fast whatever because it's got access to all of the information from that device okay",
    "start": "1659799",
    "end": "1665600"
  },
  {
    "text": "and that's key and that's obviously where the Amazon Kinesis or C or cfus sit in there",
    "start": "1665600",
    "end": "1672000"
  },
  {
    "text": "so looking at this in a bit more detail we'll look at Kinesis but CFA is very similar Kinesis sits AC Ross three",
    "start": "1672000",
    "end": "1678880"
  },
  {
    "text": "availability zones so an availability Zone you can think of as a separate physical data center so every message we",
    "start": "1678880",
    "end": "1685080"
  },
  {
    "text": "we receive we'll write it three times you create a stream that gives you an endpoint that you can then tell your",
    "start": "1685080",
    "end": "1691080"
  },
  {
    "text": "devices to write to they push all their messages into Kinesis and then at the",
    "start": "1691080",
    "end": "1696120"
  },
  {
    "text": "back end you've then got your applications that are consuming this data and so the the typical pattern here",
    "start": "1696120",
    "end": "1702279"
  },
  {
    "text": "is that you have multiple applications that are doing different things with the same data so so classic one is okay I",
    "start": "1702279",
    "end": "1709640"
  },
  {
    "text": "want a log of everything that's happened I just want an audit log all the raw data I need to keep it I need to know what happened at any time so that will",
    "start": "1709640",
    "end": "1715799"
  },
  {
    "text": "probably just be written to S3 but I also want to pull out some metrics so I want to see a real-time",
    "start": "1715799",
    "end": "1722760"
  },
  {
    "text": "dashboard I want to know you know are these buildings all right you know what's what's the temperature trending so I might push some metrics I'll pull",
    "start": "1722760",
    "end": "1729760"
  },
  {
    "text": "some metrics out of the data stream and push that into a nosql database like Dynamo put a dashboard over the top and",
    "start": "1729760",
    "end": "1736919"
  },
  {
    "text": "off we go but then I might want to do deeper analytics I might want to do year on",
    "start": "1736919",
    "end": "1742679"
  },
  {
    "text": "year or season on season so maybe I want to push some data into red shift so I can look at the Historical information",
    "start": "1742679",
    "end": "1748640"
  },
  {
    "text": "as well as the new information or I might even want to do something even more interesting I might want to push it",
    "start": "1748640",
    "end": "1753720"
  },
  {
    "text": "into something like Apache storm which is a um a complex event processing engine a distributed",
    "start": "1753720",
    "end": "1760720"
  },
  {
    "text": "one now the key thing here is that you can do all of that cuz each of these applications do not interfere with one",
    "start": "1760720",
    "end": "1766960"
  },
  {
    "text": "another they all into the stream at potentially different times but they got their own checkpoints so they're not",
    "start": "1766960",
    "end": "1773440"
  },
  {
    "text": "they're not going to interfere so that's one of the great things about again about using a stream processing engine is that ability to use",
    "start": "1773440",
    "end": "1780120"
  },
  {
    "text": "different uh different um",
    "start": "1780120",
    "end": "1785440"
  },
  {
    "text": "applications let's put Kinesis and Kafka head-to-head in terms of latency it's supposed to be realtime streaming so the",
    "start": "1785440",
    "end": "1790919"
  },
  {
    "text": "latency it better be low we're talking about potentially opening this up to the Internet so the",
    "start": "1790919",
    "end": "1796200"
  },
  {
    "text": "scaling had better be high they both respect the ordering that messages come in that can be important",
    "start": "1796200",
    "end": "1802799"
  },
  {
    "text": "but this is where they differ Kinesis will hold a message for 24 hours CFA that's configurable customers",
    "start": "1802799",
    "end": "1810799"
  },
  {
    "text": "tell us 24 hours for most use cases is okay but obviously if your application sits outside of that then maybe you want",
    "start": "1810799",
    "end": "1817320"
  },
  {
    "text": "to look at CFA again the size of the payload the size of the message 50k in Kinesis currently",
    "start": "1817320",
    "end": "1825440"
  },
  {
    "text": "configurable in Kafka again most customer to say 50k is enough sometimes it's not and again not to harp on about",
    "start": "1825440",
    "end": "1833279"
  },
  {
    "text": "the managed service thing too much but Kinesis is a fully managed",
    "start": "1833279",
    "end": "1838840"
  },
  {
    "text": "service CF you got to do that yourself uh a fantastic use case is uh",
    "start": "1838840",
    "end": "1846640"
  },
  {
    "text": "one of our gaming customers uh supercell and they use Kinesis to capture ingame",
    "start": "1846640",
    "end": "1852480"
  },
  {
    "text": "analytics in-game messages where are where are their users up to is somebody having an",
    "start": "1852480",
    "end": "1859000"
  },
  {
    "text": "issue playing this particular level and they capture that information and it gives them a much richer and realtime",
    "start": "1859000",
    "end": "1865480"
  },
  {
    "text": "view on what's going on in their in their gaming World um and they talk about the world of gaming never",
    "start": "1865480",
    "end": "1871799"
  },
  {
    "text": "sleeps uh I got some friends who are Gamers who never sleep uh and they talk about owing every",
    "start": "1871799",
    "end": "1878600"
  },
  {
    "text": "player a great experience and they basically use AWS to make that",
    "start": "1878600",
    "end": "1883440"
  },
  {
    "start": "1884000",
    "end": "1995000"
  },
  {
    "text": "happen so that's so we've looked at uh ingest and store let's have a look at process now process I'm going to look at",
    "start": "1884159",
    "end": "1890960"
  },
  {
    "text": "from three angles one is interactive so my definition of interactive is that you've got a human who's actually",
    "start": "1890960",
    "end": "1897000"
  },
  {
    "text": "sitting there waiting for something to finish so it had better finish quickly um because you want it to be interactive",
    "start": "1897000",
    "end": "1903919"
  },
  {
    "text": "batch so my definition of batch is you hope there's not a human sitting there waiting for it to finish because it's",
    "start": "1903919",
    "end": "1909080"
  },
  {
    "text": "going to take a long time and then obviously that you got to do something with the streaming data as",
    "start": "1909080",
    "end": "1914120"
  },
  {
    "text": "well so red shift sits squarely into the interactive Camp designed to be",
    "start": "1914120",
    "end": "1919200"
  },
  {
    "text": "interactive designed to have people using it designed to allow you to ask questions at the speed of thought get a",
    "start": "1919200",
    "end": "1925360"
  },
  {
    "text": "get an answer back ask another question kind of drool down through the data but there are other options as well so",
    "start": "1925360",
    "end": "1931039"
  },
  {
    "text": "there's open source options like Presto which came out of Facebook um in",
    "start": "1931039",
    "end": "1936919"
  },
  {
    "text": "paraa and they sit on top of Hadoop or or EMR so looking at those",
    "start": "1936919",
    "end": "1945840"
  },
  {
    "text": "three head to again latency is low so you want you want quick response durability is high they all scale up to",
    "start": "1946480",
    "end": "1954039"
  },
  {
    "text": "pretty high volumes the storage of red shift is native so that the storage is",
    "start": "1954039",
    "end": "1959399"
  },
  {
    "text": "direct attached within paror and Presto they're either talking to hdfs or in Presto case they can also talk to S3 so",
    "start": "1959399",
    "end": "1967600"
  },
  {
    "text": "that hybrid case I talked about where you might have some data in S3 and some in hdfs Presto is great for that bi",
    "start": "1967600",
    "end": "1973840"
  },
  {
    "text": "tools typically red Chi's got a few more just because it's been around longer and again Rift is a fully managed service in",
    "start": "1973840",
    "end": "1980760"
  },
  {
    "text": "paror and Presto I've said they're semi-managed because if you're using EMR then the Hadoop bits managed the top",
    "start": "1980760",
    "end": "1986600"
  },
  {
    "text": "bits not the presso bits not um if you're managing the whole Hado cluster then obviously it's it's completely",
    "start": "1986600",
    "end": "1992080"
  },
  {
    "text": "managed by you guys moving on to",
    "start": "1992080",
    "end": "1998039"
  },
  {
    "start": "1995000",
    "end": "2239000"
  },
  {
    "text": "batch there's lots of different options here I just wanted to cover off on three so spark is kind of the new kid on the",
    "start": "1998039",
    "end": "2005720"
  },
  {
    "text": "Block in terms of processing so of the you hear Hadoop and map produce talked about in the same sentence map produce",
    "start": "2005720",
    "end": "2011120"
  },
  {
    "text": "has been the processing engine for Hadoop for a long time a lot of people don't like it because they think it's too slow too batch oriented they've",
    "start": "2011120",
    "end": "2017600"
  },
  {
    "text": "moved more towards spark which gives you the option to do batch but also potentially interactive as well so",
    "start": "2017600",
    "end": "2023360"
  },
  {
    "text": "you'll hear a lot more about spark in the coming coming months and years Hive was kind of the original sequel on",
    "start": "2023360",
    "end": "2029440"
  },
  {
    "text": "Hadoop interface so people wanted more of a SQL interface into hop Hive was the first one again gets pinged for being",
    "start": "2029440",
    "end": "2035679"
  },
  {
    "text": "very slow um but it's it's a bit of a Workhorse it's pretty uh it's pretty",
    "start": "2035679",
    "end": "2040960"
  },
  {
    "text": "ubiquitous my favorite is pig pig eats everything that's why it's called Pig uh",
    "start": "2040960",
    "end": "2047720"
  },
  {
    "text": "it's a transformational engine so basically you feed it um messy data semi-structured",
    "start": "2047720",
    "end": "2054000"
  },
  {
    "text": "unstructured uh and then you can use it to basically put some structure around it um again um the the fun stuff with",
    "start": "2054000",
    "end": "2061560"
  },
  {
    "text": "had is the names of things like Pig's funny but when you put Pig on top of spark you get",
    "start": "2061560",
    "end": "2068599"
  },
  {
    "text": "Spork which is even funnier than",
    "start": "2068599",
    "end": "2073200"
  },
  {
    "text": "Pig uh sorry it's a bit late in the day to be showing you graphs but just a quick one um now I'm not showing you",
    "start": "2073919",
    "end": "2080679"
  },
  {
    "text": "this because red shift does particularly well on this um I'm showing it to you for a couple of reasons one is it it shows you the um the kind of the hive",
    "start": "2080679",
    "end": "2089240"
  },
  {
    "text": "batch versus some of the more interactive stuff so so lower numbers are better here so this is query",
    "start": "2089240",
    "end": "2095240"
  },
  {
    "text": "response time so if you look at hive big long bars takes a long time to do anything but you look at Red shift imp",
    "start": "2095240",
    "end": "2101160"
  },
  {
    "text": "paror um nice nice short bars um interactive speed you can ask a query",
    "start": "2101160",
    "end": "2106480"
  },
  {
    "text": "get a response back the other thing worth pointing out on this is this was done about a year ago by amp laabs and",
    "start": "2106480",
    "end": "2113320"
  },
  {
    "text": "it's already um at a date so you'll see shark up there so shark is Hive on",
    "start": "2113320",
    "end": "2119839"
  },
  {
    "text": "spark um unfortunately quite a good name but um has now been deprecated um in",
    "start": "2119839",
    "end": "2125200"
  },
  {
    "text": "favor of something else so even in the world of um Big Data things move fast so",
    "start": "2125200",
    "end": "2131040"
  },
  {
    "text": "shark's gone and all of those numbers if they ran that Benchmark today all of the numbers of those technologies will be a",
    "start": "2131040",
    "end": "2136280"
  },
  {
    "text": "lot lower there's been advances across the board in in in all of those different areas so um as I said things",
    "start": "2136280",
    "end": "2142400"
  },
  {
    "text": "change but things get faster and better all the time uh moving on let's do so streaming",
    "start": "2142400",
    "end": "2150000"
  },
  {
    "text": "so we've had a look at this already so basically uh spark has got its own streaming engine Kinesis consumers which",
    "start": "2150000",
    "end": "2155839"
  },
  {
    "text": "we've looked at uh will consume assume the data coming out of Kinesis and do something with it Apache storm is",
    "start": "2155839",
    "end": "2161079"
  },
  {
    "text": "another complex event processing engine um I wouldn't see Apache storm and Kinesis is competitive normally um",
    "start": "2161079",
    "end": "2167520"
  },
  {
    "text": "they're used together so there's actually a a connector for Kinesis that will go into storm so that's kind of the the process",
    "start": "2167520",
    "end": "2174839"
  },
  {
    "text": "side now on top of that you then want to start to analyze the data and I've broken this into three main areas the",
    "start": "2174839",
    "end": "2180680"
  },
  {
    "text": "first is your traditional business intelligence types of tools so things like Tableau jaspersoft business objects",
    "start": "2180680",
    "end": "2187200"
  },
  {
    "text": "microsof strategy cognos you know the ones um fantastic for that kind of business intelligence type of um type of",
    "start": "2187200",
    "end": "2194440"
  },
  {
    "text": "uh reports and anal analysis but then you might want to get into more statistical type of analysis so things",
    "start": "2194440",
    "end": "2200480"
  },
  {
    "text": "like SAS RS becoming very popular you can plug those in as well and then you got machine learning",
    "start": "2200480",
    "end": "2206960"
  },
  {
    "text": "so as I said Amazon machine learning has just come out but there's other fantastic open source options as well",
    "start": "2206960",
    "end": "2212359"
  },
  {
    "text": "like mahot for example which again sits on um Hadoop so that's the framework",
    "start": "2212359",
    "end": "2217800"
  },
  {
    "text": "that I wanted to build up for you now that's just some of the common ones that we see obviously there's plenty of",
    "start": "2217800",
    "end": "2223079"
  },
  {
    "text": "Technologies we haven't covered here not because they're not fantastic and and applicable in a lot of use cases um but",
    "start": "2223079",
    "end": "2229319"
  },
  {
    "text": "simply because we just wanted oh pardon me just wanted to cover off on um on just the main ones that we see so let me",
    "start": "2229319",
    "end": "2236000"
  },
  {
    "text": "layer some use cases on top of this and let's talk about fear of missing out so one of the things I hear",
    "start": "2236000",
    "end": "2242800"
  },
  {
    "start": "2239000",
    "end": "2438000"
  },
  {
    "text": "sometimes is wow look at all those fantastic Technologies there's all these amazing things out there if we're not",
    "start": "2242800",
    "end": "2247839"
  },
  {
    "text": "using them we're missing out and people have this this fear that they're somehow missing out on all this great stuff but",
    "start": "2247839",
    "end": "2254079"
  },
  {
    "text": "the thing is some of these technologies will give you what you need without necessarily having to get into some of",
    "start": "2254079",
    "end": "2260680"
  },
  {
    "text": "the more complex stuff so good example of this is is sequel analytics so you look at SQL analytics",
    "start": "2260680",
    "end": "2266880"
  },
  {
    "text": "where you want to be able to to get deeper into your data look at more detailed data look at more history have",
    "start": "2266880",
    "end": "2272520"
  },
  {
    "text": "it come back faster you could simply just take your database data",
    "start": "2272520",
    "end": "2278119"
  },
  {
    "text": "put it into red shift lay a tableau off the top of that and you're done red shift gives you the the",
    "start": "2278119",
    "end": "2285760"
  },
  {
    "text": "scalability and the speed to run those queries and get deep into the data and Tableau gives you that rich visual",
    "start": "2285760",
    "end": "2291599"
  },
  {
    "text": "environment in order to drill down into it you don't necessarily need to get into Hadoop and Spark and Spork and pig",
    "start": "2291599",
    "end": "2299839"
  },
  {
    "text": "you can stick with a database technology that you already know how to drive so my point there is don't necessarily feel",
    "start": "2299839",
    "end": "2306520"
  },
  {
    "text": "that if you're not using you're missing out it could be that just that your use case you're getting what you need out of other",
    "start": "2306520",
    "end": "2313440"
  },
  {
    "text": "Technologies another common use case is clickstream analysis A lot of people do this in batch so they'll use something",
    "start": "2314680",
    "end": "2320160"
  },
  {
    "text": "like log 4J which will do their um their logging for them push that event data maybe they push that straight into hdfs",
    "start": "2320160",
    "end": "2327359"
  },
  {
    "text": "that might be running on EMR or dup they spin up some of the some of the tooling and then they run some some uh",
    "start": "2327359",
    "end": "2334960"
  },
  {
    "text": "analysis tools over the top of that you can also do that in real",
    "start": "2334960",
    "end": "2340119"
  },
  {
    "text": "time so you might have an event producer that's actually firing every time someone makes a click that might go into",
    "start": "2340119",
    "end": "2346359"
  },
  {
    "text": "maybe that goes into Kinesis the Kinesis consumers will then write that into S3 for an audit log",
    "start": "2346359",
    "end": "2353400"
  },
  {
    "text": "they'll also write it into Amazon red shift for people to analyze that might be with Tableau for example and then",
    "start": "2353400",
    "end": "2358440"
  },
  {
    "text": "they might push some into into machine learning as",
    "start": "2358440",
    "end": "2362960"
  },
  {
    "text": "well the last one to look at is the data Lake now the data lake is a term that a",
    "start": "2364280",
    "end": "2369560"
  },
  {
    "text": "lot of people don't like because it's been a little bit overused which I agree with but the the the key message behind",
    "start": "2369560",
    "end": "2376240"
  },
  {
    "text": "the data L is actually quite interesting and a lot of it's to do with self-service analysis and it's basically",
    "start": "2376240",
    "end": "2381280"
  },
  {
    "text": "put the data in a place where your users can then selfs serve where they can spin up the technology that they want to use",
    "start": "2381280",
    "end": "2387680"
  },
  {
    "text": "and consume the data so for example you might have database data event data",
    "start": "2387680",
    "end": "2393400"
  },
  {
    "text": "streaming data you put that in S3 free Kafka takes",
    "start": "2393400",
    "end": "2398800"
  },
  {
    "text": "the streaming stuff and then people can spin up the tools that they want so if",
    "start": "2398800",
    "end": "2404920"
  },
  {
    "text": "they're familiar with Hadoop they might spin up a dup cluster use that to analyze the data if they're more",
    "start": "2404920",
    "end": "2410200"
  },
  {
    "text": "database people they might spin up red shift and then they can use the tools that they want to do",
    "start": "2410200",
    "end": "2416760"
  },
  {
    "text": "that and the key here is that you're not necessarily paying for all this processing 24x7 people spin stuff up do",
    "start": "2416760",
    "end": "2423880"
  },
  {
    "text": "the processing they need and then they shut that that processing engine down again so that's becoming an interesting",
    "start": "2423880",
    "end": "2430280"
  },
  {
    "text": "conversation that I'm having with a lot of customers is that kind of data like data Lake Enterprise Hub type of uh type",
    "start": "2430280",
    "end": "2436400"
  },
  {
    "text": "of approach right now what I wanted to do now is just jump",
    "start": "2436400",
    "end": "2442760"
  },
  {
    "start": "2438000",
    "end": "2584000"
  },
  {
    "text": "into a little bit of a demo just to finish off uh and do that with machine learning um so hopefully the uh the demo",
    "start": "2442760",
    "end": "2451760"
  },
  {
    "text": "Gods will smile on us",
    "start": "2451760",
    "end": "2455599"
  },
  {
    "text": "so machine learning for those of you who who are not familiar with it is basically the tenant is that machines",
    "start": "2463520",
    "end": "2471040"
  },
  {
    "text": "are better and more efficient at spotting patterns in data than humans are typically not always but for a lot",
    "start": "2471040",
    "end": "2478599"
  },
  {
    "text": "of use cases they're much better at it and so what you do with machine learning",
    "start": "2478599",
    "end": "2483720"
  },
  {
    "text": "is you first of all have to train the machine into what you're actually looking for so what you typically do is",
    "start": "2483720",
    "end": "2490800"
  },
  {
    "text": "you feed it a training set of data which has got all the information in it plus",
    "start": "2490800",
    "end": "2496839"
  },
  {
    "text": "the answers that you're looking for and it then will learn what patterns in the",
    "start": "2496839",
    "end": "2501960"
  },
  {
    "text": "original data led to the outcome so an example might be that you're looking for fraudulent credit card transactions so",
    "start": "2501960",
    "end": "2508760"
  },
  {
    "text": "when you're training it you feed it a set of data that's got the credit card transaction so the time stamp the user",
    "start": "2508760",
    "end": "2515160"
  },
  {
    "text": "the amount the merchant the location all that stuff plus you tell it the answer so you say this was a fraudulent",
    "start": "2515160",
    "end": "2521560"
  },
  {
    "text": "transaction or no it wasn't and the Machine will then look for pattern in the data to work out what actually leads",
    "start": "2521560",
    "end": "2528599"
  },
  {
    "text": "to that outcome what leads to it being a fraudulent transaction or not so what we do with Amazon machine",
    "start": "2528599",
    "end": "2534560"
  },
  {
    "text": "learning is that when you fired up which I'll show you you feed it a training set and what it then does with that",
    "start": "2534560",
    "end": "2541760"
  },
  {
    "text": "training set is uses 70% of the data to create the model and then holds back 30% to then",
    "start": "2541760",
    "end": "2549000"
  },
  {
    "text": "test itself so once it's created the model with the 70% it then uses that",
    "start": "2549000",
    "end": "2554200"
  },
  {
    "text": "remaining 30% makes predictions about what it thinks the answer should be and then",
    "start": "2554200",
    "end": "2559960"
  },
  {
    "text": "checks against the answers because remember that 30% still got the answer in there and so it checks does those",
    "start": "2559960",
    "end": "2566079"
  },
  {
    "text": "checks and then gives you an evaluation so basically says this is how I went on that 30% do you think this is okay or",
    "start": "2566079",
    "end": "2573480"
  },
  {
    "text": "not and if you're happy with it then you can then put that model into production um and then start feeding it raw data",
    "start": "2573480",
    "end": "2578720"
  },
  {
    "text": "that doesn't have the answers in it and it will then start to make those predictions for you so let's let's uh",
    "start": "2578720",
    "end": "2584920"
  },
  {
    "start": "2584000",
    "end": "2964000"
  },
  {
    "text": "just use a simple case so what we're going to use is a data set that came out of kaggle a lot of you you might be",
    "start": "2584920",
    "end": "2591240"
  },
  {
    "text": "familiar with kaggle so it's basically a site where they'll set up a competition a data sciency type of competition and",
    "start": "2591240",
    "end": "2598040"
  },
  {
    "text": "they'll say here's the data set this is the outcome that we want go and produce an algorithm that that leads to an",
    "start": "2598040",
    "end": "2603920"
  },
  {
    "text": "outcome and so the data set that they had was basically basically a lot of",
    "start": "2603920",
    "end": "2609319"
  },
  {
    "text": "cities now around the world are providing bikes to their citizens to say if you need to ride home here's a bike",
    "start": "2609319",
    "end": "2615599"
  },
  {
    "text": "that you can will lend you and you can ride home and then leave it somewhere uh and the trick there is",
    "start": "2615599",
    "end": "2621559"
  },
  {
    "text": "obviously knowing how many bikes you need on a given day based on the weather the time of day the season etc etc so",
    "start": "2621559",
    "end": "2630559"
  },
  {
    "text": "the data set has actually got by hour the number of bikes that were used the",
    "start": "2630559",
    "end": "2636720"
  },
  {
    "text": "weather the season all that information and so what we want to do is we want to feed that into the machine learning algorithm",
    "start": "2636720",
    "end": "2643480"
  },
  {
    "text": "for it to then learn basically how and predict how many bikes are going to be needed on a given",
    "start": "2643480",
    "end": "2651359"
  },
  {
    "text": "day now as we go through you'll notice I've created a few objects already and this basically just allows us to kind of",
    "start": "2653800",
    "end": "2659640"
  },
  {
    "text": "skip ahead uh so we're not sitting around waiting for things to happen so it's going to be a bit like a cooking show where we're going to pull one out",
    "start": "2659640",
    "end": "2665200"
  },
  {
    "text": "of the oven that we've prepared earlier just so that uh you're not sitting there watching me uh wait for stuff to happen",
    "start": "2665200",
    "end": "2672000"
  },
  {
    "text": "so the first thing we're going to do is create a data source now what this will do this will this will allow machine",
    "start": "2672000",
    "end": "2677079"
  },
  {
    "text": "learning to pull data either out of S3 or red shift and this is going to be our",
    "start": "2677079",
    "end": "2683319"
  },
  {
    "text": "training set of data so it's looking at my buckets and we're going to use this data",
    "start": "2683319",
    "end": "2689880"
  },
  {
    "text": "set here which is my training set okay I'm just going to call",
    "start": "2689880",
    "end": "2695119"
  },
  {
    "text": "this demo train okay we'll verify",
    "start": "2695119",
    "end": "2702119"
  },
  {
    "text": "that what it's going to do now is it pulls out of the so basically that's",
    "start": "2703079",
    "end": "2708960"
  },
  {
    "text": "just a CSV right it's just a comma Del limited file it pulls the schema out for me to have a look at to make sure I'm",
    "start": "2708960",
    "end": "2714000"
  },
  {
    "text": "happy with it and the first question it ask me is does the first line of the CSV actually have the header in it now in",
    "start": "2714000",
    "end": "2720640"
  },
  {
    "text": "this case it does which makes things a little bit easier because we know what we're looking at so I'll choose yes",
    "start": "2720640",
    "end": "2726480"
  },
  {
    "text": "there so you can see now on the left hand side I've got all the names of the columns and it's made a guess as to what kind of",
    "start": "2726480",
    "end": "2733359"
  },
  {
    "text": "data type each of these rows is and there's basically four options it's either a numeric a binary so two one or",
    "start": "2733359",
    "end": "2740280"
  },
  {
    "text": "two values um categorical so multivalue um or it's numeric or it's text and this",
    "start": "2740280",
    "end": "2747720"
  },
  {
    "text": "just helps it to um when it's doing its its algorithms so most of these I'm happy with the one I'm going to change",
    "start": "2747720",
    "end": "2753520"
  },
  {
    "text": "is weather so it thinks weather's a numeric because basically it's got a number between one and four but those",
    "start": "2753520",
    "end": "2759880"
  },
  {
    "text": "numbers actually represent how the weather was on that day so you know one is sunny two is cloudy three is windy",
    "start": "2759880",
    "end": "2764960"
  },
  {
    "text": "four is torrential rain uh so I'm actually going to make that categorical which will actually make the the",
    "start": "2764960",
    "end": "2771839"
  },
  {
    "text": "algorithm a bit smarter now the next thing it's asking",
    "start": "2771839",
    "end": "2777720"
  },
  {
    "text": "for here is what's the target so the target is the actual column that you want it to",
    "start": "2777720",
    "end": "2785000"
  },
  {
    "text": "predict what does it actually what are you actually asking it to to to try and work out so in our case it's the numbers",
    "start": "2785000",
    "end": "2793960"
  },
  {
    "text": "of bikes that were actually used on that day that's what we're trying to determine how many bikes were used in",
    "start": "2793960",
    "end": "2799559"
  },
  {
    "text": "the training set and then later obviously when we feed it raw data we want to know how many bikes do you think Mr machine learning algorithm we're",
    "start": "2799559",
    "end": "2806240"
  },
  {
    "text": "going to need for a given day so that's our that's our Target so it knows what it's aiming",
    "start": "2806240",
    "end": "2813160"
  },
  {
    "text": "at okay just take the defaults there",
    "start": "2813160",
    "end": "2818440"
  },
  {
    "text": "okay so that's going to go and do that so where we're up to in our model",
    "start": "2820760",
    "end": "2826800"
  },
  {
    "text": "here is that we've basically pointed the machine learning service at the training",
    "start": "2826800",
    "end": "2833280"
  },
  {
    "text": "data set so that's currently pulling that in doing some analysis on it now instead of waiting around for that I'm",
    "start": "2833280",
    "end": "2839520"
  },
  {
    "text": "going to jump to a data source that I prepared earlier so this",
    "start": "2839520",
    "end": "2846559"
  },
  {
    "text": "is basically one that I went through the same process that I just went through with that one and what we're going to do",
    "start": "2846559",
    "end": "2852480"
  },
  {
    "text": "is then we're going to ask it to create a model for",
    "start": "2852480",
    "end": "2860040"
  },
  {
    "text": "us okay so we'll give that uh we'll give that a name",
    "start": "2864720",
    "end": "2872359"
  },
  {
    "text": "now I'm taking the defaults as we go through here there's several stages where you can tweak the algorithm as you",
    "start": "2879240",
    "end": "2884559"
  },
  {
    "text": "go along but um I'll leave that for you for uh for some homework to do to go and read up on documentation and uh work out",
    "start": "2884559",
    "end": "2891839"
  },
  {
    "text": "how that all works so what it's doing now is it's now building that model based on that data set so if we go back",
    "start": "2891839",
    "end": "2898599"
  },
  {
    "text": "to our pipeline it's now doing this 70% 30% split so it's now taken 70% it's",
    "start": "2898599",
    "end": "2904280"
  },
  {
    "text": "running that through the model kind of creating the model it's learning about the data set and then after that it's going to push the 30% through and then",
    "start": "2904280",
    "end": "2910680"
  },
  {
    "text": "it's going to push out an evaluation so again let's let's jump",
    "start": "2910680",
    "end": "2917599"
  },
  {
    "text": "ahead so here's an evaluation of one that we did",
    "start": "2918559",
    "end": "2924960"
  },
  {
    "text": "earlier and you can see in green here it's basically giving us a summary as to how well it went when it tested itself",
    "start": "2926119",
    "end": "2933000"
  },
  {
    "text": "on that 30% and it uses something called uh rmsse which is basically the root",
    "start": "2933000",
    "end": "2939319"
  },
  {
    "text": "mean square error H and I've got no idea what that means but what I do know is",
    "start": "2939319",
    "end": "2946480"
  },
  {
    "text": "that lower numbers are better so you can see that that our value was 42 the",
    "start": "2946480",
    "end": "2951720"
  },
  {
    "text": "Baseline is 61 so so it's basically saying look we think the model is pretty",
    "start": "2951720",
    "end": "2957480"
  },
  {
    "text": "accurate we can actually delve into that a little bit further if we go into",
    "start": "2957480",
    "end": "2963920"
  },
  {
    "text": "the into here now what what this graph is showing us is that",
    "start": "2963920",
    "end": "2970000"
  },
  {
    "start": "2964000",
    "end": "3151000"
  },
  {
    "text": "dotted line in the middle that dash line in the middle is the actual number of bikes that were used for each row and",
    "start": "2970000",
    "end": "2977119"
  },
  {
    "text": "the bars on either side are the prediction that the algorithm made so the further away it gets from the dash",
    "start": "2977119",
    "end": "2983720"
  },
  {
    "text": "line the worse the the prediction was now the key thing you're looking for",
    "start": "2983720",
    "end": "2988839"
  },
  {
    "text": "here is that the mistakes that it made kind of fall evenly on either side of",
    "start": "2988839",
    "end": "2994319"
  },
  {
    "text": "the dash line so you know it's going to make mistakes right cuz it's it's just a model but you want it to be balanced so",
    "start": "2994319",
    "end": "2999520"
  },
  {
    "text": "the ones to the right of the dash line is where it overestimated how many bikes",
    "start": "2999520",
    "end": "3004680"
  },
  {
    "text": "we're going to be on that day and to the left it underestimated how many but if it if the if the graph looks like that",
    "start": "3004680",
    "end": "3011839"
  },
  {
    "text": "then that's kind of okay cuz sometimes it it's over sometimes it's under if it's all to one side of the dash line",
    "start": "3011839",
    "end": "3017799"
  },
  {
    "text": "then you've got a problem because if it's if all of those bars are to the left it's always underestimating how",
    "start": "3017799",
    "end": "3023280"
  },
  {
    "text": "many bikes are supposed to be there okay and you don't want that so there's there's something flawed in the model or",
    "start": "3023280",
    "end": "3029079"
  },
  {
    "text": "in the training set that you gave it but that I'm pretty happy with so what that means is then then",
    "start": "3029079",
    "end": "3034880"
  },
  {
    "text": "we've got this this model that we're happy with and then we can use that in a couple of ways",
    "start": "3034880",
    "end": "3041839"
  },
  {
    "text": "so one way is in batch so we've got our model sitting there we can then feed it",
    "start": "3041839",
    "end": "3047839"
  },
  {
    "text": "a batch of data so a CSV file with a whole bunch of um entries in it and it",
    "start": "3047839",
    "end": "3053359"
  },
  {
    "text": "will then give us a batch prediction so we give it a file and it'll give us a file back and that file that it gives us",
    "start": "3053359",
    "end": "3059119"
  },
  {
    "text": "will basically contain all the predictions so for every line it'll give us how the number of bikes it predicts",
    "start": "3059119",
    "end": "3065760"
  },
  {
    "text": "for each given time period that we give it the other",
    "start": "3065760",
    "end": "3072359"
  },
  {
    "text": "option and this is the interesting one is to do it in real time same",
    "start": "3072359",
    "end": "3079720"
  },
  {
    "text": "model but this time you're feeding it real-time data so that's that funny looking thing on the left there that's",
    "start": "3079720",
    "end": "3085240"
  },
  {
    "text": "the Kinesis uh symbol but it doesn't have to be Kinesis could be anything basically you're",
    "start": "3085240",
    "end": "3090480"
  },
  {
    "text": "firing a message at a time into the model and saying and obviously for the",
    "start": "3090480",
    "end": "3095559"
  },
  {
    "text": "credit card fraud transaction you'd want to be doing it in real time so you want to say is this fraudulent so you send in",
    "start": "3095559",
    "end": "3101880"
  },
  {
    "text": "the transaction all the information's in there in 100 milliseconds it'll make a decision and it'll give you a real- time",
    "start": "3101880",
    "end": "3108799"
  },
  {
    "text": "prediction yes this is fraudulent no it's not and then you take that and obviously put that into a nosql database",
    "start": "3108799",
    "end": "3115960"
  },
  {
    "text": "or something like that um to basically then use that in your application",
    "start": "3115960",
    "end": "3122040"
  },
  {
    "text": "the the uh the applications of machine loarn learning are extremely broad um you can use it in all sorts of different",
    "start": "3122040",
    "end": "3129119"
  },
  {
    "text": "applications um we obviously just scratched the surface here as I said if it's of interest um have a look on the",
    "start": "3129119",
    "end": "3134559"
  },
  {
    "text": "website there's plenty of info plenty of tutorials you can do um etc etc thank",
    "start": "3134559",
    "end": "3139760"
  },
  {
    "text": "you very much guys for staying around being with us all day we really appreciate it I think we're doing um the",
    "start": "3139760",
    "end": "3144839"
  },
  {
    "text": "wrap up next door thank you very much",
    "start": "3144839",
    "end": "3148520"
  }
]
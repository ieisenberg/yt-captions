[
  {
    "start": "0",
    "end": "61000"
  },
  {
    "text": "welcome we are hoping that you're having a great time at reinvent Anne's Monday",
    "start": "30",
    "end": "5700"
  },
  {
    "text": "so this is the first days and there's a lot more to go today we're going to talk",
    "start": "5700",
    "end": "11250"
  },
  {
    "text": "about two important things the first is health care patient data which is the",
    "start": "11250",
    "end": "20789"
  },
  {
    "text": "central theme of all that we do when we talk about health care analysis and bi",
    "start": "20789",
    "end": "25830"
  },
  {
    "text": "and the second thing is that what it takes us to create a process or a system",
    "start": "25830",
    "end": "32509"
  },
  {
    "text": "where you can easily create analytics where you can easily ride machine",
    "start": "32510",
    "end": "37710"
  },
  {
    "text": "learning models where you can easily write data descriptive predictive prescriptive you name it any kind of",
    "start": "37710",
    "end": "43890"
  },
  {
    "text": "analysis what it takes to create a system that can drive interventions what",
    "start": "43890",
    "end": "50460"
  },
  {
    "text": "it takes to create a system that helps empowers the end user to create a system",
    "start": "50460",
    "end": "56280"
  },
  {
    "text": "which can then be utilized to create models for data intervention so before",
    "start": "56280",
    "end": "65460"
  },
  {
    "start": "61000",
    "end": "179000"
  },
  {
    "text": "we dive into you know the creation of this process or or or the services or",
    "start": "65460",
    "end": "72119"
  },
  {
    "text": "anything like that let me highlight a few points and I'm sure you all are expert here in this room and and this is",
    "start": "72119",
    "end": "78659"
  },
  {
    "text": "maybe something which is redundant but I just want to take a quick moment to talk about the power of health care bi",
    "start": "78659",
    "end": "85610"
  },
  {
    "text": "forecasting a chronic condition okay you have a set of people who have diabetes",
    "start": "85610",
    "end": "90930"
  },
  {
    "text": "you want to predict their kidney failures you want to predict congestive heart failure on patients descriptive",
    "start": "90930",
    "end": "96600"
  },
  {
    "text": "analytics this is what we do basic average min max some standard deviations and other things deep learning using",
    "start": "96600",
    "end": "103770"
  },
  {
    "text": "medical images this is something that you know getting more and more important",
    "start": "103770",
    "end": "108780"
  },
  {
    "text": "some some but he told me the other day that hey you know I want to take a picture of your heart but not from",
    "start": "108780",
    "end": "114299"
  },
  {
    "text": "outside inside x-ray that is and and want to run some deep learning models to",
    "start": "114299",
    "end": "119880"
  },
  {
    "text": "extract the features and what does it mean it means that I want to study the images of your heart to find out what is",
    "start": "119880",
    "end": "125700"
  },
  {
    "text": "the best treatment for you if you are suffering from a chronic condition okay so again part of analysis optimization",
    "start": "125700",
    "end": "132300"
  },
  {
    "text": "of an EMR workflow and you know you know and EMR this is not Amazon EMR this is electronic",
    "start": "132300",
    "end": "138030"
  },
  {
    "text": "medical record system or EHR you know in hospitals we use this EMR system for",
    "start": "138030",
    "end": "145980"
  },
  {
    "text": "labs for medications for encounters right and in our clinicians and our physicians and nurses and all that staff",
    "start": "145980",
    "end": "152480"
  },
  {
    "text": "they use the system EMR systems for majority part of the day when they're",
    "start": "152480",
    "end": "157530"
  },
  {
    "text": "not treating patients okay so how to optimize this is also part of analysis and then interventions it has a",
    "start": "157530",
    "end": "163500"
  },
  {
    "text": "continuous cycle right so so so we start with with finding out the patients who",
    "start": "163500",
    "end": "169140"
  },
  {
    "text": "needs a treatment or or we want to forecast certain diseases well once you",
    "start": "169140",
    "end": "174150"
  },
  {
    "text": "find that out what do you do next you know you provide interventions so what are the main",
    "start": "174150",
    "end": "180360"
  },
  {
    "start": "179000",
    "end": "258000"
  },
  {
    "text": "challenges that that one sees when you creating a system a healthcare bi",
    "start": "180360",
    "end": "186150"
  },
  {
    "text": "solution the first one is the infrastructure right so I have a 60 terabyte database or I have 55 terabyte",
    "start": "186150",
    "end": "193049"
  },
  {
    "text": "database or I may have even 100 gigabyte of database sometimes and most of the times actually it is not an easy process",
    "start": "193049",
    "end": "200160"
  },
  {
    "text": "for me to procure this set of hardware which can actually scale with my needs",
    "start": "200160",
    "end": "205320"
  },
  {
    "text": "so today I may have 200 patients tomorrow I may have 20 million patients okay the infrastructure has to scale",
    "start": "205320",
    "end": "212609"
  },
  {
    "text": "with the need the second challenge that we have in healthcare bi is complex and noisy data so it hasn't always not",
    "start": "212609",
    "end": "219720"
  },
  {
    "text": "friendly you know it comes from I mentioned from the EMR systems it may come from a glucometer it may come from",
    "start": "219720",
    "end": "225420"
  },
  {
    "text": "a vein scale it may come from any other sensory devices that you have it in your home and the third thing is usability",
    "start": "225420",
    "end": "230910"
  },
  {
    "text": "and adoption now why do I put it out here is because if I'm a data scientist or if I'm at if I'm someone who is doing",
    "start": "230910",
    "end": "238859"
  },
  {
    "text": "the data analysis if you give me in infrastructure great if you solve my data problems perfect but you still need",
    "start": "238859",
    "end": "245730"
  },
  {
    "text": "to give me a system where I can go and easily create my models I can easily",
    "start": "245730",
    "end": "250769"
  },
  {
    "text": "share my model remember that we talked about interventions before something that we can drive something that help",
    "start": "250769",
    "end": "256799"
  },
  {
    "text": "help us drive the intervention so the first challenge the infrastructure we have multiple data sources we have data",
    "start": "256799",
    "end": "264030"
  },
  {
    "start": "258000",
    "end": "321000"
  },
  {
    "text": "from EMR we have data from labs in medication and counters you name it various data",
    "start": "264030",
    "end": "269699"
  },
  {
    "text": "models coming from various sources you may end up having different data models as simple as you take a blood sample",
    "start": "269699",
    "end": "275460"
  },
  {
    "text": "from a glucometer device the data the streams that back to the data source is obviously different than an encounter",
    "start": "275460",
    "end": "282629"
  },
  {
    "text": "information that we have data transfer rate now if I'm a data scientist you",
    "start": "282629",
    "end": "287729"
  },
  {
    "text": "know data analyst or somebody like that you know for me to log into your database and run queries and get the",
    "start": "287729",
    "end": "293639"
  },
  {
    "text": "data out of that and then put that in a machine learning you know system you call it spark or or Hadoop or anything",
    "start": "293639",
    "end": "300750"
  },
  {
    "text": "for that matter you need to transfer the data back and forth between these systems elasticity with my needs with",
    "start": "300750",
    "end": "308069"
  },
  {
    "text": "the number of patients with that with an epidemic or with anything that requires for me to scale out or to scale back in",
    "start": "308069",
    "end": "315349"
  },
  {
    "text": "something that is also a challenge so these are first of the three challenges we talked about the second one is the",
    "start": "315349",
    "end": "321990"
  },
  {
    "text": "complex and and noisy data which I touched upon upon briefly and the third is third is a usability and adoption",
    "start": "321990",
    "end": "328680"
  },
  {
    "text": "challenge you know I want to make sure that we all in this room understand what",
    "start": "328680",
    "end": "334110"
  },
  {
    "text": "we mean by usability and adoption when we talk about that first of all you gave me a system and infrastructure where I",
    "start": "334110",
    "end": "340949"
  },
  {
    "text": "can connect so that's good okay what are my permissions what what are the drivers I'm supposed to be using what am i",
    "start": "340949",
    "end": "346949"
  },
  {
    "text": "networking how am i encrypting this data the second is that how do I share so I",
    "start": "346949",
    "end": "352050"
  },
  {
    "text": "built a cool model on sepsis or congestive heart failure or anything for them that matter but once they're done",
    "start": "352050",
    "end": "358080"
  },
  {
    "text": "with my model how do I share my work with others in my organization or even better to the intervention team which is",
    "start": "358080",
    "end": "364349"
  },
  {
    "text": "actually going to drive this intubation take it forward how do I reuse my research so you spend close to six",
    "start": "364349",
    "end": "370740"
  },
  {
    "text": "months in in in generating a model feature exploration and all that you want that work to just get wasted you",
    "start": "370740",
    "end": "376589"
  },
  {
    "text": "want to reuse that work over and over again how do I find new packages now if you",
    "start": "376589",
    "end": "381599"
  },
  {
    "text": "have work with you know any Jupiter notebook like packaged or any machine learning you will recognize this that as",
    "start": "381599",
    "end": "388169"
  },
  {
    "text": "and when I use new research I you know escalate my my findings I need to I need",
    "start": "388169",
    "end": "394349"
  },
  {
    "text": "to get two new packages and and we will talk about that in detail when we have our",
    "start": "394349",
    "end": "400420"
  },
  {
    "text": "speaker how do i package now my work is done I want to package my work so that others",
    "start": "400420",
    "end": "406000"
  },
  {
    "text": "can use it so so starting from finding the data to resolving the infrastructure",
    "start": "406000",
    "end": "411670"
  },
  {
    "text": "to creating a system that can actually be leveraged you know to for better",
    "start": "411670",
    "end": "420250"
  },
  {
    "text": "patient care because that's the central theme that we are all working towards okay now the first aspect is",
    "start": "420250",
    "end": "427300"
  },
  {
    "text": "infrastructure and the data right so one thing that we can that we can do and that one thing you won't emphasize in",
    "start": "427300",
    "end": "433750"
  },
  {
    "text": "our today's discussion is using Amazon s3 as a derelict now what is the data like right so data like is something",
    "start": "433750",
    "end": "439030"
  },
  {
    "text": "that we you collect data from multiple sources you create a system where your analysis can sit on top of it as opposed",
    "start": "439030",
    "end": "444130"
  },
  {
    "text": "to going through multiple data sources and connecting them from your application so something as an example",
    "start": "444130",
    "end": "450820"
  },
  {
    "text": "here is trading on premises s DF s for durability and scalability with Amazon",
    "start": "450820",
    "end": "455860"
  },
  {
    "text": "s3 in the cloud and these slides right now that I am presenting are at a high",
    "start": "455860",
    "end": "461740"
  },
  {
    "text": "level we're gonna have our speaker who's going to go much in detail on all of these options including Amazon s3 as a",
    "start": "461740",
    "end": "468250"
  },
  {
    "text": "data like so now I have my data consolidated I have my data from different sources",
    "start": "468250",
    "end": "473500"
  },
  {
    "text": "I created a data Lake why do I need Amazon s3 well if you look at this picture on the left hand side you have",
    "start": "473500",
    "end": "479530"
  },
  {
    "start": "475000",
    "end": "529000"
  },
  {
    "text": "data from different ERP system web blocks connected devices social media EMR systems glucometer sensory devices",
    "start": "479530",
    "end": "487030"
  },
  {
    "text": "IOT and whatnot and then you scale it you put the data in in one place Amazon",
    "start": "487030",
    "end": "492250"
  },
  {
    "text": "s3 in just that and then from there you either you can direct query the data using Amazon Athena which is our query",
    "start": "492250",
    "end": "498700"
  },
  {
    "text": "engine which you can directly use it against s3 or you can scale it you can",
    "start": "498700",
    "end": "504340"
  },
  {
    "text": "use Amazon EMR it is the use case we're going to talk about today but Amazon EMR is is a Hadoop framework where you can",
    "start": "504340",
    "end": "512110"
  },
  {
    "text": "run on Amazon where you can run spark jobs for for advanced data analysis so you can see in this picture that how can",
    "start": "512110",
    "end": "519010"
  },
  {
    "text": "I take data from multiple sources ingest into s3 and actually utilize that and",
    "start": "519010",
    "end": "524680"
  },
  {
    "text": "and leverage that information you know across multiple multiple channels EMR so",
    "start": "524680",
    "end": "530950"
  },
  {
    "start": "529000",
    "end": "557000"
  },
  {
    "text": "em are like I said is a managed Hadoop framework makes it easy fast and cost-effective process to process vast amounts of data",
    "start": "530950",
    "end": "538960"
  },
  {
    "text": "so you know if you work with Hadoop framework before this is a framework which is fully managed by Amazon on on a",
    "start": "538960",
    "end": "545950"
  },
  {
    "text": "cloud as you can see in this diagram we have an Amazon EMR sitting on top of",
    "start": "545950",
    "end": "551320"
  },
  {
    "text": "multiple sources Amazon s3 is this is one of them and that is where we just built our data like now with the data",
    "start": "551320",
    "end": "559600"
  },
  {
    "start": "557000",
    "end": "608000"
  },
  {
    "text": "now we have the data we have the we have the you know an engine that can process it at a big data scale the next thing",
    "start": "559600",
    "end": "566770"
  },
  {
    "text": "comes encryption so Amazon s3 provides data at rest encryption you can directly encrypt your your data in is 3 then",
    "start": "566770",
    "end": "574180"
  },
  {
    "text": "Hadoop I mentioned that HDFS data transfer protocol so data in rest as",
    "start": "574180",
    "end": "579190"
  },
  {
    "text": "well as data in transit both of these encryption can be achieved by the manner services that we have MapReduce SSL for encrypted shuffle and",
    "start": "579190",
    "end": "586660"
  },
  {
    "text": "finally spark in case you're using spark and and that's one of the examples we have today we can use SSL for block",
    "start": "586660",
    "end": "593620"
  },
  {
    "text": "transfer service in among among the others so the encryption is done data is in the data Lake we have used big data",
    "start": "593620",
    "end": "601300"
  },
  {
    "text": "analysis platform like Amazon EMR to perform analysis so some part of our of our problem is kind of resolved the next",
    "start": "601300",
    "end": "609220"
  },
  {
    "start": "608000",
    "end": "640000"
  },
  {
    "text": "thing is the monitoring ok so how do I know who's accessing my data in in s3 so for that we have bucket access logs in",
    "start": "609220",
    "end": "615520"
  },
  {
    "text": "EMR you know you can archive various log files that gave that eventually go to cloud watch and and generate metrics",
    "start": "615520",
    "end": "623080"
  },
  {
    "text": "every five minutes so so now we have a cycle which is connected from the source system all the way to the 2d monitoring",
    "start": "623080",
    "end": "631150"
  },
  {
    "text": "now remember I also talked about complex and noisy data I also talked about the",
    "start": "631150",
    "end": "636610"
  },
  {
    "text": "usability and adoption ok so to go deeper into that I would like to call",
    "start": "636610",
    "end": "642100"
  },
  {
    "start": "640000",
    "end": "703000"
  },
  {
    "text": "upon the speaker from Cerner",
    "start": "642100",
    "end": "647639"
  },
  {
    "text": "so Cerner is is one organization that I have seen as the continuously building",
    "start": "647760",
    "end": "653890"
  },
  {
    "text": "on the foundation of intelligent solutions its technologies connect people and services more than 27,000",
    "start": "653890",
    "end": "661480"
  },
  {
    "text": "facilities worldwide Cerner is creating a future where healthcare systems works",
    "start": "661480",
    "end": "667030"
  },
  {
    "text": "to improve for the well-being of patient they're always on the cutting edge and from Cerner I would like to invite Ryan brush",
    "start": "667030",
    "end": "672820"
  },
  {
    "text": "who is a principal architect at Cerner he traded Clara and open-source engine for rules he is deeply involved with",
    "start": "672820",
    "end": "679630"
  },
  {
    "text": "data engineering analysis in the application at a very large scale and I'm working with with Ryan for for number of months now and I've learned so",
    "start": "679630",
    "end": "685540"
  },
  {
    "text": "much from him in all these months you know that that I couldn't even think about it before he's a renowned speaker",
    "start": "685540",
    "end": "692649"
  },
  {
    "text": "he spoke at multiple conferences and he co-authored some chapters in those books 97 things every programmer should know",
    "start": "692649",
    "end": "698019"
  },
  {
    "text": "and Hadoop the definite guide so with that I would like to call upon Ryan brush from Cerner thanks Daphne I think",
    "start": "698019",
    "end": "711940"
  },
  {
    "start": "703000",
    "end": "796000"
  },
  {
    "text": "you were trying to make me blush a little bit there for that overview but I appreciate it all right so we're gonna",
    "start": "711940",
    "end": "719529"
  },
  {
    "text": "start with take a quick look at the story so far and if we could fit everything that we're doing in all of",
    "start": "719529",
    "end": "725769"
  },
  {
    "text": "our healthy and ten efforts onto one slide it might look something like this and that we're bringing together a broad",
    "start": "725769",
    "end": "731829"
  },
  {
    "text": "set of almost anything that is relevant in healthcare where we're doing going through a number of steps to normalize",
    "start": "731829",
    "end": "737860"
  },
  {
    "text": "it and put it into some standard structures that we can use once we have it no standard structures we're applying",
    "start": "737860",
    "end": "744040"
  },
  {
    "text": "a variety of analytics a variety of intelligence to that system and then",
    "start": "744040",
    "end": "750899"
  },
  {
    "text": "we're driving that back into the point of care back where the clinicians back where the health coaches back where",
    "start": "750899",
    "end": "756550"
  },
  {
    "text": "administrators of hospitals can be can apply this value and a lot of this is happening today on our own data centers",
    "start": "756550",
    "end": "762490"
  },
  {
    "text": "but we're gonna talk about how we're continuing to make it better with doing some of the things with AWS as well and",
    "start": "762490",
    "end": "769120"
  },
  {
    "text": "this is a big complicated system so we're have hundreds of connections of two disparate data sources we have more",
    "start": "769120",
    "end": "775420"
  },
  {
    "text": "than a hundred million unique person lives in this system we have several petabytes of data and these numbers are",
    "start": "775420",
    "end": "780550"
  },
  {
    "text": "always going up we have many different measures and a whole bunch of deep",
    "start": "780550",
    "end": "786610"
  },
  {
    "text": "ontology is to work with this healthcare data and of course all this is built upon you know security which in an area",
    "start": "786610",
    "end": "792790"
  },
  {
    "text": "in which we can make zero compromises so this is where we're doing today but in the purpose of this talk we're going to",
    "start": "792790",
    "end": "799480"
  },
  {
    "start": "796000",
    "end": "848000"
  },
  {
    "text": "zoom in on us piece of this and then how do we make these efforts how do we make them smarter how do we make them better and",
    "start": "799480",
    "end": "805810"
  },
  {
    "text": "how do we continuously improve them so we'll zoom in on one piece so we'll take",
    "start": "805810",
    "end": "810940"
  },
  {
    "text": "everything that we have in terms of this healthcare data its enormous ly vast complex set of data that we're working",
    "start": "810940",
    "end": "816070"
  },
  {
    "text": "with we're bringing it through this longitudinal record of everything and to",
    "start": "816070",
    "end": "821770"
  },
  {
    "text": "a environment that data scientists want to you is we want to create we want to create something that people want to go",
    "start": "821770",
    "end": "827500"
  },
  {
    "text": "to in order to make these things to make these things smarter we want to take",
    "start": "827500",
    "end": "832600"
  },
  {
    "text": "that new knowledge and push it into a content management system so as we have new algorithms that we want to apply we",
    "start": "832600",
    "end": "838990"
  },
  {
    "text": "need to be able to management and we need to be able to bring in third-party content as well and then finally of",
    "start": "838990",
    "end": "844270"
  },
  {
    "text": "course we need to be able to push that back into the original healthcare system that we started with so I am an engineer",
    "start": "844270",
    "end": "851020"
  },
  {
    "text": "by background I mean I and so my initial impulse is to take everything we've done and just dive deep into all the",
    "start": "851020",
    "end": "856360"
  },
  {
    "text": "technical details of all the complexity that we're dealing with to build this type of system but really the purpose of",
    "start": "856360",
    "end": "862660"
  },
  {
    "text": "this is not to dive deep into the technical details of it although we will touch on that as we go but really the",
    "start": "862660",
    "end": "868390"
  },
  {
    "text": "end goal is for our users we really want to make the technology disappear and when we think about when we talk to our",
    "start": "868390",
    "end": "874839"
  },
  {
    "start": "872000",
    "end": "1001000"
  },
  {
    "text": "users we talked to you know people that you might consider a data scientist or an analyst and think about the environment that we want to bring to",
    "start": "874839",
    "end": "880750"
  },
  {
    "text": "them instead of technology we want to bring them an SQL view of the data it's",
    "start": "880750",
    "end": "885820"
  },
  {
    "text": "accessible has a very large audience it's easy to use it's like bring the data through and a familiar SQL",
    "start": "885820",
    "end": "891130"
  },
  {
    "text": "interface you want to be able to do deep descriptive and predictive statistics",
    "start": "891130",
    "end": "896410"
  },
  {
    "text": "across that data set and then we want to be able to be at write pieces of code to sort of glue these things together to",
    "start": "896410",
    "end": "902260"
  },
  {
    "text": "orchestrate them to make it happen I mean this is the world that we want our data scientists to be to view rather",
    "start": "902260",
    "end": "908260"
  },
  {
    "text": "than all the complexity underneath them and so we give them an interface so and so here we have a Jupiter notebook",
    "start": "908260",
    "end": "914560"
  },
  {
    "text": "interface where you can explore and manipulate the data and while they work with this and our challenge that that we",
    "start": "914560",
    "end": "920440"
  },
  {
    "text": "have from a technology perspective is satisfying all the complexity we talked about earlier so things like we're",
    "start": "920440",
    "end": "926410"
  },
  {
    "text": "working at many petabytes of data at a time we're working with a number of",
    "start": "926410",
    "end": "931959"
  },
  {
    "text": "standard healthcare models we wanted oliday to be catalog so it's just discoverable if I have to go and",
    "start": "931959",
    "end": "938260"
  },
  {
    "text": "track down what data is there and what data isn't there or if I'd to go call a pick up the phone say hey where do I get this data set that takes us out of this",
    "start": "938260",
    "end": "945130"
  },
  {
    "text": "sort of innovative loop that we want to be into I mean everything that we have rights to should be securely available",
    "start": "945130",
    "end": "950410"
  },
  {
    "text": "and should just be there and then similarly when we produce new outputs from these either new new machine",
    "start": "950410",
    "end": "957040"
  },
  {
    "text": "learning models or new views of the data for analysis we want it to be collaborative so we can publish it back",
    "start": "957040",
    "end": "962530"
  },
  {
    "text": "into our data catalog so others continue to use it we need a rich ontology supports and so",
    "start": "962530",
    "end": "969160"
  },
  {
    "text": "if you've worked in healthcare you know there's so many different ontology --zz that all have a variety of needs and variety of use cases we want to make",
    "start": "969160",
    "end": "975820"
  },
  {
    "text": "that as easy as we can and make it as sort of a native feature in terms of our deep data science environment and we",
    "start": "975820",
    "end": "981850"
  },
  {
    "text": "want to make it extensible so have the navneet mentioned bringing in new packages bringing in new new modules to",
    "start": "981850",
    "end": "988210"
  },
  {
    "text": "work with it we want people to bring in their own approaches to do deep learning to do analysis of these systems and of",
    "start": "988210",
    "end": "995050"
  },
  {
    "text": "course it needs to be secure and which is a theme that will come back to a few times so how do we go about building",
    "start": "995050",
    "end": "1003450"
  },
  {
    "start": "1001000",
    "end": "1035000"
  },
  {
    "text": "this type of system imagine like we have this blank page and how can we go about doing him but one approach that that I",
    "start": "1003450",
    "end": "1011010"
  },
  {
    "text": "think that we took early on in this is we went back to one of the classics of software engineering and Fred Brooks no",
    "start": "1011010",
    "end": "1017850"
  },
  {
    "text": "silver bullet and which Brooks described there's the essential problem these are things our real users really care about",
    "start": "1017850",
    "end": "1023610"
  },
  {
    "text": "what's inherent in the problem we're trying to solve and then there's the accidental problem so we talked about",
    "start": "1023610",
    "end": "1028650"
  },
  {
    "text": "the essence before right we want to have this rich catalog of data set where everything is just there where they can just work with it but we have a lot of",
    "start": "1028650",
    "end": "1035640"
  },
  {
    "start": "1035000",
    "end": "1128000"
  },
  {
    "text": "accidents in this type of system accidents in the sense of what Brooks means it's like anything that's not",
    "start": "1035640",
    "end": "1041459"
  },
  {
    "text": "essential to the problem so things like hey we want to work with the work with our spark cluster we have a huge amount",
    "start": "1041459",
    "end": "1047100"
  },
  {
    "text": "of metadata we have provisioning and storage and connectivity and auditing and security and this list goes on and on and all of these are important if any",
    "start": "1047100",
    "end": "1054870"
  },
  {
    "text": "one of these doesn't work then our system doesn't work so we need to",
    "start": "1054870",
    "end": "1060240"
  },
  {
    "text": "approach this and maybe we do this I mean the way that we might have done this historically is like how do we go",
    "start": "1060240",
    "end": "1066060"
  },
  {
    "text": "about and solve these problems what I do is we'd go and and I'd go and I'd put on hey I put on my Software Architect hat right I'm gonna go yeah",
    "start": "1066060",
    "end": "1073180"
  },
  {
    "text": "alright I'm gonna go through and I'm gonna figure out the architecture to solve all these problems I'm gonna do it up front I'm gonna write a glorious",
    "start": "1073180",
    "end": "1079690"
  },
  {
    "text": "white paper gonna hand it off to engineers and yeah and I'm gonna yeah so that I mean that that maybe what we've",
    "start": "1079690",
    "end": "1085840"
  },
  {
    "text": "done historically and this approach we can take in an AWS style environment because there are so many great building",
    "start": "1085840",
    "end": "1092890"
  },
  {
    "text": "blocks in order to assemble the architecture for these things and that we can glue together how we can declare",
    "start": "1092890",
    "end": "1098980"
  },
  {
    "text": "hey we need this and bring it in part of our system but I think that this type of",
    "start": "1098980",
    "end": "1104230"
  },
  {
    "text": "we have an opportunity you know working through this type of system to do something better than we might have done",
    "start": "1104230",
    "end": "1109570"
  },
  {
    "text": "historically I mean it's typically we think of software architecture is something that we do upfront we get it nailed down my favorite definition of",
    "start": "1109570",
    "end": "1117040"
  },
  {
    "text": "software architecture is it's the things that are hard to change in the system which as Martin Fowler points out like",
    "start": "1117040",
    "end": "1123910"
  },
  {
    "text": "why are we making things in the system that are hard to change and in fact",
    "start": "1123910",
    "end": "1129580"
  },
  {
    "text": "there's no theoretical reason why anything in software has to be taught hard to change that so can we do better as opposed to you know a upright",
    "start": "1129580",
    "end": "1136150"
  },
  {
    "text": "architecture approach can we do something that it then adapted much more quickly so we went about this rather",
    "start": "1136150",
    "end": "1142300"
  },
  {
    "start": "1140000",
    "end": "1231000"
  },
  {
    "text": "than doing this massive big upfront let's figure everything out let's figure out the constraints let's figure out the",
    "start": "1142300",
    "end": "1148720"
  },
  {
    "text": "things that we really care about when building our data driven our data centric system we got to get those nail",
    "start": "1148720",
    "end": "1154270"
  },
  {
    "text": "down because there's certain things that are immutable that we cannot change but once we have defined those hard constraints what are the things that are",
    "start": "1154270",
    "end": "1159760"
  },
  {
    "text": "really important to us we want to optimize for fast iteration so we're continuously improving the system",
    "start": "1159760",
    "end": "1165550"
  },
  {
    "text": "continuously making it better so what are the hard constraints that we talked",
    "start": "1165550",
    "end": "1171280"
  },
  {
    "text": "to that that were that would here and we'll talk about what they are and how we can satisfy them using this sort of",
    "start": "1171280",
    "end": "1176500"
  },
  {
    "text": "cloud-based stack well the first one security and not me mention a few of",
    "start": "1176500",
    "end": "1181960"
  },
  {
    "text": "these things everything is encrypted in flight and at rest everything is that using a HIPAA compliant system we have a",
    "start": "1181960",
    "end": "1187780"
  },
  {
    "text": "auditing that goes through and make sure that everything is compliant with our with our processes in our policies so",
    "start": "1187780",
    "end": "1193270"
  },
  {
    "text": "security is absolutely does not move that's the one things that we really care about we also care about the user",
    "start": "1193270",
    "end": "1199960"
  },
  {
    "text": "experience we want that sort of match environment in which F I'm a data scientist everything that I want to meet",
    "start": "1199960",
    "end": "1205940"
  },
  {
    "text": "do my job is just there without having to pick up the phone and color the thing and I don't have to go requisition new clusters anything like",
    "start": "1205940",
    "end": "1211580"
  },
  {
    "text": "that everything I want is there for that needs and then I think the third one maybe stands out a little bit though",
    "start": "1211580",
    "end": "1217850"
  },
  {
    "text": "that's a little bit different than the other ones it's a reproducibility so let's focus on that just because yeah",
    "start": "1217850",
    "end": "1223100"
  },
  {
    "text": "maybe this one seems a little bit different but I think this is an as important to property as anything that",
    "start": "1223100",
    "end": "1228770"
  },
  {
    "text": "we have in this system and by reproducibility it's really a simple idea and that's really that the same",
    "start": "1228770",
    "end": "1234500"
  },
  {
    "start": "1231000",
    "end": "1283000"
  },
  {
    "text": "input produces the same output every single time and so whether you're if I'm",
    "start": "1234500",
    "end": "1241160"
  },
  {
    "text": "doing a machine learning use case the same query I need to build to recreate that every time I do it in order to my",
    "start": "1241160",
    "end": "1247130"
  },
  {
    "text": "models or reproduce previous results to make sure that they're valid this is important from user experience use case",
    "start": "1247130",
    "end": "1252740"
  },
  {
    "text": "it's exploring important from a data engineering use case in which whether using literal Amazon AWS lambda",
    "start": "1252740",
    "end": "1260330"
  },
  {
    "text": "functions or we are they're using a computer science lambda functions to transform data in the more abstract",
    "start": "1260330",
    "end": "1265520"
  },
  {
    "text": "sense the same input should produce the same output every time and by doing that",
    "start": "1265520",
    "end": "1271850"
  },
  {
    "text": "this kind of gets us in a nice feedback loop in which we can kind of continuously being proving the system making little tweaks and then changing",
    "start": "1271850",
    "end": "1278510"
  },
  {
    "text": "it as we go so and we'll come back to that reproducibility theme so we're",
    "start": "1278510",
    "end": "1284420"
  },
  {
    "start": "1283000",
    "end": "1338000"
  },
  {
    "text": "these things that we important let's let's go through our architecture so a lot of times you'll see architecture",
    "start": "1284420",
    "end": "1290780"
  },
  {
    "text": "diagrams sort of grow from the bottom up but again I think that this sort of takes away from that that way that we think about the system",
    "start": "1290780",
    "end": "1296930"
  },
  {
    "text": "we wanted to start with what's the experience that our users wanted we want to create that system and then let's",
    "start": "1296930",
    "end": "1302300"
  },
  {
    "text": "figure out what the architecture is to support that as opposed to describing the architecture from the bottom up and the user is something that sits at the",
    "start": "1302300",
    "end": "1308330"
  },
  {
    "text": "end so we start with that user experience at forefront of mine we know that we also need a way to process we",
    "start": "1308330",
    "end": "1314810"
  },
  {
    "text": "need some sort of processing engine to do this machine learning to do these heavy analytics that we're working within the system and of course we",
    "start": "1314810",
    "end": "1320750"
  },
  {
    "text": "needed a way to store the data and we need metadata associated with it and so this is I mean in a way this this this",
    "start": "1320750",
    "end": "1327470"
  },
  {
    "text": "architecture somewhat designed itself because I mean we obviously need these things now our challenge is how do we map them around a LAN to the best",
    "start": "1327470",
    "end": "1334250"
  },
  {
    "text": "available to and then iterate quickly to improve the system as we go so again we'll start at",
    "start": "1334250",
    "end": "1339679"
  },
  {
    "start": "1338000",
    "end": "1522000"
  },
  {
    "text": "the top where our users are is Jupiter notebook so if you've if you've done data science work or work with data",
    "start": "1339679",
    "end": "1346340"
  },
  {
    "text": "scientists this is a pretty popular tool in which they can interactively run code and do analytics we'll show some",
    "start": "1346340",
    "end": "1351860"
  },
  {
    "text": "examples of that so this is where our users wanted to be in terms of the",
    "start": "1351860",
    "end": "1356870"
  },
  {
    "text": "processing engine apache spark construe li has a pretty strong mind share when it comes to data engineering at scale it",
    "start": "1356870",
    "end": "1364580"
  },
  {
    "text": "has a number of the advantages of a MapReduce type framework in terms that can handle really sophisticated workloads but it also has a fairly easy",
    "start": "1364580",
    "end": "1372110"
  },
  {
    "text": "to use interface and they you can work with it with an SQL interface similar to lea but we've had shown in the earlier",
    "start": "1372110",
    "end": "1377960"
  },
  {
    "text": "slides and then the storage pretty clear if we're running in in Amazon and then",
    "start": "1377960",
    "end": "1383870"
  },
  {
    "text": "we're storing things in s3 and with the one exception of some additional metadata for thing workloads that don't",
    "start": "1383870",
    "end": "1390200"
  },
  {
    "text": "map directly to the s3 operations we'd store things in a data catalog that is just in our DBMS instance so that's our",
    "start": "1390200",
    "end": "1397850"
  },
  {
    "text": "first pasture that architecture but everything we do was iterative right so our next pass so we're using Jupiter hub",
    "start": "1397850",
    "end": "1403340"
  },
  {
    "text": "running on easy Amazon ec2 and we're spawning sessions as dock responders",
    "start": "1403340",
    "end": "1409250"
  },
  {
    "text": "which has some nice properties because since every interactive data sign session runs in its own docker container",
    "start": "1409250",
    "end": "1414770"
  },
  {
    "text": "we can bring their own libraries so they're isolated from the rest of it so if I have some specialized machine",
    "start": "1414770",
    "end": "1419840"
  },
  {
    "text": "learning need I can import that library into my container and not affect others and then everything that we do in here",
    "start": "1419840",
    "end": "1427280"
  },
  {
    "text": "we store it all hour long and live content back into s3 and we'll go into some reasons why and a couple slides for",
    "start": "1427280",
    "end": "1434929"
  },
  {
    "text": "our processing clusters we're using elastic MapReduce pretty clear choice and the nice the other nice thing is",
    "start": "1434929",
    "end": "1441110"
  },
  {
    "text": "that we tend to use a very transient workload I mean based on the on these deep analytic needs it's very its uneven",
    "start": "1441110",
    "end": "1447350"
  },
  {
    "text": "and that me a most data scientists will work during the day and not work much less at night so we actually have a",
    "start": "1447350",
    "end": "1453350"
  },
  {
    "text": "pattern in which we'll spin up you know a few dozen nodes like during the day or more depending on the workload and then",
    "start": "1453350",
    "end": "1458929"
  },
  {
    "text": "at the end of the day we'll turn them give them back basically turn the shutdown the cluster to give them back in and this is actually a really cost",
    "start": "1458929",
    "end": "1465710"
  },
  {
    "text": "effective way to do things if you have very transient workloads and that at the bottom there's like",
    "start": "1465710",
    "end": "1471019"
  },
  {
    "text": "everything that we store an s3 in terms of we we use Parque based data all of",
    "start": "1471019",
    "end": "1476870"
  },
  {
    "text": "our user folders are Laura logs anything that lives a long time is stored in s3 or in this catalog which is",
    "start": "1476870",
    "end": "1483289"
  },
  {
    "text": "just a hide meta store if you're familiar with the SPARC stack so this is our stack this is some of you of our",
    "start": "1483289",
    "end": "1490279"
  },
  {
    "text": "architecture but I think that there's one other interesting property that we see you know as we go go through these",
    "start": "1490279",
    "end": "1496009"
  },
  {
    "text": "things and that in the stack with there's a difference between everything above that chequered line and everything",
    "start": "1496009",
    "end": "1501950"
  },
  {
    "text": "below it and above that the line we think thing is that everything is stateless beyond a user session and",
    "start": "1501950",
    "end": "1508299"
  },
  {
    "text": "everything below that line has some long-lived state that goes in it and so",
    "start": "1508299",
    "end": "1514309"
  },
  {
    "text": "we found ourselves our architecture kind of naturally evolved into this area where there's these two distinct worlds we have our stateful system and we have",
    "start": "1514309",
    "end": "1521090"
  },
  {
    "text": "our state list system which kind of led to some really interesting things that we could do to continuously improve the",
    "start": "1521090",
    "end": "1526249"
  },
  {
    "start": "1522000",
    "end": "1626000"
  },
  {
    "text": "system so one of which is for state anything that lasts longer than a session we consider stateful but",
    "start": "1526249",
    "end": "1532700"
  },
  {
    "text": "stateless we can discard them the upgrade it was kind of neat right so if I want to upgrade anything our stateless stack I don't have to worry about doing",
    "start": "1532700",
    "end": "1539210"
  },
  {
    "text": "change that's or anything like that even though we could but it's easier just to throw the thing away just reproduce the",
    "start": "1539210",
    "end": "1544549"
  },
  {
    "text": "entire thing from the initial State because it is stateless we have to consider the staple data we have to",
    "start": "1544549",
    "end": "1550940"
  },
  {
    "text": "consider all system data in a state will change but in this we don't care because we're can we fully reproducible",
    "start": "1550940",
    "end": "1556240"
  },
  {
    "text": "interestingly the stateful parts of our stack tend to up wait up update much less frequently than the stateless",
    "start": "1556240",
    "end": "1562820"
  },
  {
    "text": "versions that the state I mean and stateful we're talking about our catalog we're talking about our data itself but",
    "start": "1562820",
    "end": "1567950"
  },
  {
    "text": "how we store it and how we format it doesn't change that often so we don't actually update it very frequently whereas this state list part of our",
    "start": "1567950",
    "end": "1574940"
  },
  {
    "text": "stack in our terms of our processing cluster and in terms of our interactive notebooks we upgrade all the time because we want to continuously deliver",
    "start": "1574940",
    "end": "1581210"
  },
  {
    "text": "that great user experience for them and then really everything and stateless",
    "start": "1581210",
    "end": "1586429"
  },
  {
    "text": "like its s3 its security groups its these things that don't tend to change and then first eight lists it's everything else that does this and I",
    "start": "1586429",
    "end": "1593539"
  },
  {
    "text": "really encourage like when designing in architecture whether it's a data-driven system like the one we describe here or",
    "start": "1593539",
    "end": "1598669"
  },
  {
    "text": "just system to general to kind of think about cake how can we separate state full and statelessness because it makes",
    "start": "1598669",
    "end": "1604070"
  },
  {
    "text": "it so much easier to quickly of all the portion of the system that you can live in this stateless stack so that the some",
    "start": "1604070",
    "end": "1609830"
  },
  {
    "text": "of the things that we did is like so we run Jupiter hub on ec2 but all of the user folders all of the user notebooks",
    "start": "1609830",
    "end": "1615470"
  },
  {
    "text": "are actually stored in s3 we map that s3 drive to that Jupiter hub instance that way it keeps things stateless that clean",
    "start": "1615470",
    "end": "1622580"
  },
  {
    "text": "separation lets us go really quickly lets its evolve really quickly and we're making extensive use of Amazon's AWS",
    "start": "1622580",
    "end": "1629870"
  },
  {
    "start": "1626000",
    "end": "1690000"
  },
  {
    "text": "cloud formation in order to do this which is think of really remarkable I",
    "start": "1629870",
    "end": "1635060"
  },
  {
    "text": "think this that represents a nice approach for building these types of systems and that rather it's typically",
    "start": "1635060",
    "end": "1641060"
  },
  {
    "text": "we might deploy something when you think about deployment might think about hey let's write a script and coordinator I run all our deployments you know run the",
    "start": "1641060",
    "end": "1647210"
  },
  {
    "text": "script end to end and our system would stand up but we found it best to think about cloud formation is more of its",
    "start": "1647210",
    "end": "1653030"
  },
  {
    "text": "you're not building deployment scripts you're building deployment ap is where you have a template which is essentially",
    "start": "1653030",
    "end": "1658220"
  },
  {
    "text": "an API for your system in our case we have a clear distinction between our staple template and our state list",
    "start": "1658220",
    "end": "1663440"
  },
  {
    "text": "template and because that's an API we can automate its deployment through it just like you would any other API you",
    "start": "1663440",
    "end": "1669530"
  },
  {
    "text": "can plug-in it to life cycle or tooling just like you could any other API and this is like I think a new and but",
    "start": "1669530",
    "end": "1674990"
  },
  {
    "text": "important shift and how we build software is I mean obviously there's a broad shift API is in general but I",
    "start": "1674990",
    "end": "1680870"
  },
  {
    "text": "think it's interesting that those same advantages those same patterns the same properties apply to how we can",
    "start": "1680870",
    "end": "1686090"
  },
  {
    "text": "effectively put deploy system by building api's do them now let's take a",
    "start": "1686090",
    "end": "1692570"
  },
  {
    "start": "1690000",
    "end": "1789000"
  },
  {
    "text": "look at how we get data into the system we talked about how we put it all together and really it's pretty simple",
    "start": "1692570",
    "end": "1700790"
  },
  {
    "text": "as we could so as we talked about earlier our healthy intents now the bulk the vast majority of Ed's running you",
    "start": "1700790",
    "end": "1706100"
  },
  {
    "text": "know in Cerner's data center that we've operated for some number of years now for data that we want to move into AWS",
    "start": "1706100",
    "end": "1712160"
  },
  {
    "text": "for basically doing a Hadoop distributed copy it's basically like a MapReduce job that spins up and does a move things",
    "start": "1712160",
    "end": "1717950"
  },
  {
    "text": "over into our s3 buckets after we copied over there we load everything into this",
    "start": "1717950",
    "end": "1723410"
  },
  {
    "text": "data this catalog of data so we can our users can easily find it and then we",
    "start": "1723410",
    "end": "1728870"
  },
  {
    "text": "actually have another use case that I think is interesting and to make the system collaborative is that we'll",
    "start": "1728870",
    "end": "1734660"
  },
  {
    "text": "actually so actively syndicate datasets to organizations to our clients with whom",
    "start": "1734660",
    "end": "1739980"
  },
  {
    "text": "we're working so our clients may have may want to do their own deep data analysis from this and in this they",
    "start": "1739980",
    "end": "1746250"
  },
  {
    "text": "actually can run and they're separate into the distinct AWS accounts and will essentially s3 sync things over into",
    "start": "1746250",
    "end": "1753330"
  },
  {
    "text": "their accounts we actually build again using an API centric approach building this data syndication service that",
    "start": "1753330",
    "end": "1759120"
  },
  {
    "text": "tracks with what can be shared with whom and tracks all the security and the traceability policies behind that but",
    "start": "1759120",
    "end": "1764970"
  },
  {
    "text": "the mechanism is essentially a succinct between accounts and that way when our users want to spin up their own system",
    "start": "1764970",
    "end": "1770430"
  },
  {
    "text": "which can include arbitrary code or arbitrary libraries so it needs to be strongly isolated they can do so you",
    "start": "1770430",
    "end": "1776400"
  },
  {
    "text": "know with the right data but do so safely but for the purposes of this talk",
    "start": "1776400",
    "end": "1781770"
  },
  {
    "text": "for the purpose of this presentation we're going to zoom in a little bit on the core system of what we're working",
    "start": "1781770",
    "end": "1787110"
  },
  {
    "text": "where we're working with the data and really the DCP like we said we starts",
    "start": "1787110",
    "end": "1793320"
  },
  {
    "start": "1789000",
    "end": "1911000"
  },
  {
    "text": "with a move to Amazon s3 and then we trigger a data pipeline which if you're",
    "start": "1793320",
    "end": "1799350"
  },
  {
    "text": "used to do for very long it's a little kind of thick maybe a little bit of like an oozy as a service there's a lot of",
    "start": "1799350",
    "end": "1805770"
  },
  {
    "text": "differences there but it can look for events new data landing in and then trigger some processing engine that",
    "start": "1805770",
    "end": "1810960"
  },
  {
    "text": "writes out to some end state that's what we do we are our ingestion is also written in Apache spark running on the",
    "start": "1810960",
    "end": "1817920"
  },
  {
    "text": "elastic MapReduce cluster and then the job simply converts data into Park a park a file format that lives in s3 and",
    "start": "1817920",
    "end": "1825360"
  },
  {
    "text": "then registers that was Park a files with the catalog now our users never",
    "start": "1825360",
    "end": "1831300"
  },
  {
    "text": "actually know that data is written in Park a that's that's entirely an implementation detail they work with this catalog which is really just like a",
    "start": "1831300",
    "end": "1837840"
  },
  {
    "text": "data dictionary I know a lot of people like to joke that all good ideas come from the 1970s right so it's really like",
    "start": "1837840",
    "end": "1843750"
  },
  {
    "text": "this new view of a data dictionary that has better scalability properties we use the park' format because it offered it's",
    "start": "1843750",
    "end": "1851670"
  },
  {
    "text": "a column based format so a lot of our query operations are very efficient because they scan entire columns versus",
    "start": "1851670",
    "end": "1857670"
  },
  {
    "text": "a row wise format which we have to like go row by row by row for every query that we do so park' is actually an",
    "start": "1857670",
    "end": "1863100"
  },
  {
    "text": "excellent format and apache spark it was like natively optimized to speak park' so well this isn't the only",
    "start": "1863100",
    "end": "1869610"
  },
  {
    "text": "for a data format for the sort of deep analytics use case it's kind of the kind of the incumbent just because of the",
    "start": "1869610",
    "end": "1875880"
  },
  {
    "text": "deep spark integration with it and also the integration with libraries like Athena our toolkits like Amazon Athena",
    "start": "1875880",
    "end": "1882000"
  },
  {
    "text": "and others that's right we got our data and we got in the catalog and so we kind",
    "start": "1882000",
    "end": "1887429"
  },
  {
    "text": "of got that through this architecture piece and now we face that our next set of challenges as we go and that is",
    "start": "1887429",
    "end": "1893340"
  },
  {
    "text": "dealing with the sheer complement complexity of healthcare data we talk about the hundreds of distinct sources",
    "start": "1893340",
    "end": "1899790"
  },
  {
    "text": "and all the ontology that all ideal and complexity that we're dealing with and this is perhaps our biggest essential",
    "start": "1899790",
    "end": "1905160"
  },
  {
    "text": "problem because complex healthcare data isn't going away this complexity is here to stay so how do we deal with this and",
    "start": "1905160",
    "end": "1912530"
  },
  {
    "text": "to illustrate it we're tailing thousands of different code values from different",
    "start": "1912530",
    "end": "1917820"
  },
  {
    "text": "systems oftentimes they'll be incomplete or conflicting data this is a United States of course we don't have a common person identifier so we have to write",
    "start": "1917820",
    "end": "1924059"
  },
  {
    "text": "logic to match people make sure that two records are actually for the same person even when we have standard standard data",
    "start": "1924059",
    "end": "1930600"
  },
  {
    "text": "models to bring into the system they're in consistently interpreted like maybe you can create a great spec but there's always some room for interpretation in a",
    "start": "1930600",
    "end": "1938130"
  },
  {
    "text": "spec and at your data system scales big enough you will run into every possible interpretation of that spec as we go and",
    "start": "1938130",
    "end": "1946580"
  },
  {
    "text": "that results in the way have different meanings different things mean different things to different contexts",
    "start": "1946580",
    "end": "1952710"
  },
  {
    "text": "they have to be reconciled across horses and of course human working memories you",
    "start": "1952710",
    "end": "1957750"
  },
  {
    "text": "know five to nine items so not very good right and there's just no way around this this isn't something you know we",
    "start": "1957750",
    "end": "1963890"
  },
  {
    "text": "land in architecture and high-five each other is like yeah we've nailed the data complexity problem this is like a",
    "start": "1963890",
    "end": "1969390"
  },
  {
    "text": "systematic approach that we have to work through so the first thing we've done is",
    "start": "1969390",
    "end": "1974700"
  },
  {
    "start": "1972000",
    "end": "2109000"
  },
  {
    "text": "taken all of our these data sets that we bring in and put it in this data dictionary this data catalogue that has",
    "start": "1974700",
    "end": "1979950"
  },
  {
    "text": "well-defined columns as well defined schemas I mean a lot of times if you've been in the big data quote-unquote space",
    "start": "1979950",
    "end": "1985710"
  },
  {
    "text": "you may have heard like schema on read is like hyped up as this really great thing and schema on read is a good thing",
    "start": "1985710",
    "end": "1992070"
  },
  {
    "text": "if you don't have a schema right if if I need to analyze data and there's not a defined schema for my input sources then",
    "start": "1992070",
    "end": "1997890"
  },
  {
    "text": "yeah let's use schema and read because at least I can do it so that that's the value there but given the choice but",
    "start": "1997890",
    "end": "2003410"
  },
  {
    "text": "not having a schema and having the schema you want a schema right I mean so so much tongue-in-cheek I kind of joked",
    "start": "2003410",
    "end": "2010160"
  },
  {
    "text": "that schema and read is a bug and not a feature and sometimes it's the necessary bug but but that's not where we want to",
    "start": "2010160",
    "end": "2015980"
  },
  {
    "text": "be so once we have a catalog then we can start looking at how do we make sense of this complex data itself and our",
    "start": "2015980",
    "end": "2023780"
  },
  {
    "text": "challenge here is that it becomes the data if this balance between a purely",
    "start": "2023780",
    "end": "2029420"
  },
  {
    "text": "highly faithful representation of a very complex data set and something that can be actually easily used by a user so a",
    "start": "2029420",
    "end": "2037010"
  },
  {
    "text": "lot of our analysis is actually done on data models that are based on the fire standard and so here this is one this is",
    "start": "2037010",
    "end": "2043850"
  },
  {
    "text": "actually the fire condition model that we've taken the fires the schema and it fully expanded it so here's the full",
    "start": "2043850",
    "end": "2049520"
  },
  {
    "text": "definition of the fire condition model and it keeps going and it keeps going",
    "start": "2049520",
    "end": "2054770"
  },
  {
    "text": "and the crazy thing is is that these fire based models I mean they're designed to hit that like 80 percent",
    "start": "2054770",
    "end": "2060800"
  },
  {
    "text": "case they're actually simplified versions as opposed to other healthcare models in which they pay that let's get",
    "start": "2060800",
    "end": "2067520"
  },
  {
    "text": "the things that are needed most often but you know maybe sometimes you know we don't but for the long tail things for",
    "start": "2067520",
    "end": "2073128"
  },
  {
    "text": "something that I only need a couple percent of the time it's not in this data model so there's already fairly well curated and that's actually one of",
    "start": "2073129",
    "end": "2079128"
  },
  {
    "text": "the reasons we use the fire based data model for a lot of our deep analysis because they've made there's been so",
    "start": "2079129",
    "end": "2084770"
  },
  {
    "text": "much curation in so much effort into finding what as the important data sets for this now for the board and data elements what should they look like and",
    "start": "2084770",
    "end": "2091429"
  },
  {
    "text": "how do we work with it but because of this expressive the all this",
    "start": "2091429",
    "end": "2097310"
  },
  {
    "text": "expressiveness comes with the cost of this complex data model that we see you know working walking through this schema",
    "start": "2097310",
    "end": "2103360"
  },
  {
    "text": "so how do we go through this take this complex data model and make it easier to use easier to work with and the pattern",
    "start": "2103360",
    "end": "2110990"
  },
  {
    "start": "2109000",
    "end": "2210000"
  },
  {
    "text": "that we found that works really well is we can take a really complex data set and we'll just project it onto something much simpler so when we say a sno-med",
    "start": "2110990",
    "end": "2117470"
  },
  {
    "text": "code they might meet hypertension medications this made me to condition and then we can project that onto hey",
    "start": "2117470",
    "end": "2123110"
  },
  {
    "text": "this person is hypertensive and what's interesting here is that like these projections are lossy right there is",
    "start": "2123110",
    "end": "2129770"
  },
  {
    "text": "less information is is hypertensive then there is towards the bottom of that but",
    "start": "2129770",
    "end": "2134840"
  },
  {
    "text": "depending on your use case after times a lossy projection is fine in fact it's actually what you want if I'm doing",
    "start": "2134840",
    "end": "2141710"
  },
  {
    "text": "some deep analytics of a system I just want to see hey is this person x4 tense if I don't need all this underlying complexity and so what we found is like",
    "start": "2141710",
    "end": "2149330"
  },
  {
    "text": "the ability to take these very large data sets and using this elastic environment in which we're working be",
    "start": "2149330",
    "end": "2154760"
  },
  {
    "text": "able to create many projections of the data that are much simpler to work with so for any problem at hand I can create",
    "start": "2154760",
    "end": "2160310"
  },
  {
    "text": "the projection that I want I can work with that much simplified data set and and do my analysis there and maybe I can",
    "start": "2160310",
    "end": "2166700"
  },
  {
    "text": "reuse that projection for similar problems if I can't and I just create another one and do it which is another",
    "start": "2166700",
    "end": "2171830"
  },
  {
    "text": "advantage looks another quite quiet advantage of some of these a lot of these lactic varmints the ability to have a scalable data collect catalog",
    "start": "2171830",
    "end": "2178010"
  },
  {
    "text": "that I can contribute new things to without having to pick up the phone and request you know hey we need some more hardware running this system and so once",
    "start": "2178010",
    "end": "2185960"
  },
  {
    "text": "we have these projections I mean of course what's interesting is like as we have these simplified projections they almost always end up looking like",
    "start": "2185960",
    "end": "2192410"
  },
  {
    "text": "spreadsheets I mean everyone just wants spreadsheets there they plug directly into like every machine learning tool",
    "start": "2192410",
    "end": "2198920"
  },
  {
    "text": "that exists I mean they plug into every analytic tool they can export database is like a everyone wants just giant",
    "start": "2198920",
    "end": "2204260"
  },
  {
    "text": "spreadsheets and just just assume all your users want giant spreadsheets and you'll be in a much better place so how",
    "start": "2204260",
    "end": "2211700"
  },
  {
    "start": "2210000",
    "end": "2251000"
  },
  {
    "text": "do we create this we turn things into giant spreadsheets we found a few patterns that work depending on the use case one is a rule-based approach for",
    "start": "2211700",
    "end": "2219020"
  },
  {
    "text": "projecting complex data into this giant spreadsheet and so a rule engine is",
    "start": "2219020",
    "end": "2224030"
  },
  {
    "text": "actually a pretty good way to do it because one often times they're very they're very expressive and you can be",
    "start": "2224030",
    "end": "2229760"
  },
  {
    "text": "their turing-complete you can put arbitrary code in there and also rules tend to not rules tend to avoid",
    "start": "2229760",
    "end": "2236750"
  },
  {
    "text": "spaghetti code and that they don't get quickly twisted up in one another and and deal with that sort of thing so a",
    "start": "2236750",
    "end": "2242780"
  },
  {
    "text": "rule engine is a nice approach but it requires a pretty savvy user it's usually a developer that's having to offer these rules at a low scale at a",
    "start": "2242780",
    "end": "2249800"
  },
  {
    "text": "granular level another one to solve a similar problem is this emerging spec in",
    "start": "2249800",
    "end": "2255260"
  },
  {
    "start": "2251000",
    "end": "2300000"
  },
  {
    "text": "healthcare the clinical quality language specification and and that it's similar",
    "start": "2255260",
    "end": "2260630"
  },
  {
    "text": "to a rural approach but it's a more constrained model so it's not as expressive as you might have from you",
    "start": "2260630",
    "end": "2265910"
  },
  {
    "text": "know a full rural engine but it can hit the most most of you to use cases most of the time and it",
    "start": "2265910",
    "end": "2272049"
  },
  {
    "text": "also benefits from the fact that there's been a lot of work in sort of curating and defining this quality this sort of",
    "start": "2272049",
    "end": "2278559"
  },
  {
    "text": "query language in a way that that it's it's easier to use and also interestingly the the quality language",
    "start": "2278559",
    "end": "2284829"
  },
  {
    "text": "is sort of migrating towards using fire as it's actually core data model so when it's a medication statement or hyper",
    "start": "2284829",
    "end": "2291670"
  },
  {
    "text": "hypertension or clinical condition or that sort of thing these are the fire resources so they're really well defined",
    "start": "2291670",
    "end": "2297700"
  },
  {
    "text": "and well documented what they're working with and then the next one to create these simplified projections of data is",
    "start": "2297700",
    "end": "2304029"
  },
  {
    "start": "2300000",
    "end": "2355000"
  },
  {
    "text": "something that's much more familiar to a much broader audience and that's just SQL maybe not as expressive but a lot",
    "start": "2304029",
    "end": "2310270"
  },
  {
    "text": "easier to get into so this same query that we just saw find hypertensive patients in the previous one so might",
    "start": "2310270",
    "end": "2316270"
  },
  {
    "text": "write some SQL where we'll query for everyone from our conditions for hypertension conditions and we'll union",
    "start": "2316270",
    "end": "2322299"
  },
  {
    "text": "that with some medication statements would that imply a standard meds and the",
    "start": "2322299",
    "end": "2328990"
  },
  {
    "text": "nice thing is that as we write SQL it's very simple that we can just wrap that and turn it to spark SQL so then it runs",
    "start": "2328990",
    "end": "2335470"
  },
  {
    "text": "directly into our spark cluster this is actually a valid query that runs in our system today and everything in here is",
    "start": "2335470",
    "end": "2342039"
  },
  {
    "text": "really standard SQL do one exception is something that will zoom in on you'll see some helpful user-defined functions",
    "start": "2342039",
    "end": "2347529"
  },
  {
    "text": "like in value set here that kind of makes it easier to kind of eliminate some of the complexity of this SQL and",
    "start": "2347529",
    "end": "2356349"
  },
  {
    "text": "once we have these things we can write once we turn these things to giant spreadsheets but we can do things that are really easy like let's just count",
    "start": "2356349",
    "end": "2362289"
  },
  {
    "text": "our hypertensive patients there you go it's a couple lines of code to find all up from our spreadsheet view of the",
    "start": "2362289",
    "end": "2367630"
  },
  {
    "text": "system or if I want to take that and I want to join it to the if I want to join",
    "start": "2367630",
    "end": "2373000"
  },
  {
    "text": "two diabetics for instance we can join that and hypertensive patients who are also diabetics you know there's there it",
    "start": "2373000",
    "end": "2378700"
  },
  {
    "text": "is right there again a few lines of code if we other things if I want to look at observation data instead we can go grab",
    "start": "2378700",
    "end": "2385960"
  },
  {
    "text": "that in this query you know here's our giant spreadsheet and then we can look at different views of that so we can",
    "start": "2385960",
    "end": "2391869"
  },
  {
    "text": "compute summary statistics of this sort of thing I mean all this is following that same pattern it's like create these",
    "start": "2391869",
    "end": "2397240"
  },
  {
    "text": "projections for a use case and then manipulate them interactively and of course you know this is just a simple",
    "start": "2397240",
    "end": "2403000"
  },
  {
    "text": "summary to but I can take that same and spreadsheet and there's a view of our distribution",
    "start": "2403000",
    "end": "2409090"
  },
  {
    "text": "of our data and if you probably can't see they have it of you look this let's see on the screen you might see like",
    "start": "2409090",
    "end": "2414410"
  },
  {
    "text": "some outlier or it's not living under sort of thing so you can get kind of quick immediate impression of and what",
    "start": "2414410",
    "end": "2419870"
  },
  {
    "text": "does our data look like and something that we need to analyze and if there is if there are outliers in this well then",
    "start": "2419870",
    "end": "2425480"
  },
  {
    "text": "we can just go back to our SQL and zoom in and figure out what's going on there trace it back to the data sources that we're working with and all this is kind",
    "start": "2425480",
    "end": "2433760"
  },
  {
    "text": "of built on these sort of use you see we'll see like little helper functions like this that are in value said that",
    "start": "2433760",
    "end": "2439040"
  },
  {
    "text": "are embedded into in our SQL and all this is is it's it's it's just a user-defined function that just looks",
    "start": "2439040",
    "end": "2445160"
  },
  {
    "text": "hey is this code value match one of these hypertension value sets so I have a collection of codes that I believe",
    "start": "2445160",
    "end": "2451670"
  },
  {
    "text": "identify hypertension is the code value in this column in MySQL query that's one of them and then it will match you to",
    "start": "2451670",
    "end": "2458540"
  },
  {
    "text": "use it there and we see this pattern popping up again where will fuse spark SQL Lee is a collection of user-defined",
    "start": "2458540",
    "end": "2466010"
  },
  {
    "start": "2459000",
    "end": "2498000"
  },
  {
    "text": "functions to work across these data sets that's like a value set and then we can",
    "start": "2466010",
    "end": "2471410"
  },
  {
    "text": "broadcast reference data to this cluster it creates a pretty neat experience when working working with it it's sort of",
    "start": "2471410",
    "end": "2480170"
  },
  {
    "text": "illustrate that I mean here's just pushing a value set so we'll create here's the set of value sets that we",
    "start": "2480170",
    "end": "2485270"
  },
  {
    "text": "believe an identify you know these particular medications we'll push them to a cluster in a real example we'll probably load them from some external",
    "start": "2485270",
    "end": "2491510"
  },
  {
    "text": "publication from some I confirm the value set Authority Center if you're familiar with that for instance and then",
    "start": "2491510",
    "end": "2496730"
  },
  {
    "text": "we could run the SQL in there and we find ourselves creating many of these we SQL as our interface into this in this",
    "start": "2496730",
    "end": "2504200"
  },
  {
    "start": "2498000",
    "end": "2585000"
  },
  {
    "text": "analysis problem but anything that can't be expressed in SQL we pushed in the user defined function so in values that",
    "start": "2504200",
    "end": "2509960"
  },
  {
    "text": "is our simplest example but extract terms right inside of our spark spark",
    "start": "2509960",
    "end": "2515000"
  },
  {
    "text": "job our instructor our processing cluster we can do a natural language processing step in which we extract",
    "start": "2515000",
    "end": "2520310"
  },
  {
    "text": "terminologies right out of the document in that spark cluster for instance and or we could even invoke rules if there's",
    "start": "2520310",
    "end": "2527540"
  },
  {
    "text": "logic that can't be expressed in SQL directly we could invoke a rule engine right in our processing job and this is",
    "start": "2527540",
    "end": "2533750"
  },
  {
    "text": "kind of one of the things that I think makes spark somewhat unique into I mean there's other ways to do it but",
    "start": "2533750",
    "end": "2539310"
  },
  {
    "text": "one of the compelling advantages of it and that all these functions it's just Java code so I have an SQL interface to",
    "start": "2539310",
    "end": "2545190"
  },
  {
    "text": "keep things simple it's like Alan Kay like to say like simple things should be simple well they are they're SQL but complex things",
    "start": "2545190",
    "end": "2551490"
  },
  {
    "text": "should be possible well they are because we can write these functions that go and do more sophisticated things written in",
    "start": "2551490",
    "end": "2558000"
  },
  {
    "text": "any language that could run on the JVM so and it's fast so here's our simple",
    "start": "2558000",
    "end": "2565350"
  },
  {
    "text": "query here an internal cluster we're working have internal types cluster with 300 million encounters running just",
    "start": "2565350",
    "end": "2571680"
  },
  {
    "text": "eight nodes which is much smaller many most of our clusters will be bigger than that for their analysis and this query",
    "start": "2571680",
    "end": "2576930"
  },
  {
    "text": "will come back and about four seconds running it so we and it takes advantage of that efficient Park a column or",
    "start": "2576930",
    "end": "2583200"
  },
  {
    "text": "format that we're working with so we talked about the toolkits and talk about",
    "start": "2583200",
    "end": "2588540"
  },
  {
    "start": "2585000",
    "end": "2752000"
  },
  {
    "text": "these patterns of creating giant spreadsheets combining together and doing analysis now we're gonna look at",
    "start": "2588540",
    "end": "2594330"
  },
  {
    "text": "applying that to some to actually do and some apply machine learning tasks and so",
    "start": "2594330",
    "end": "2600750"
  },
  {
    "text": "if we want to do something like build a predictive model do something like that well we'll just start let's just put together these spreadsheets that we want",
    "start": "2600750",
    "end": "2606780"
  },
  {
    "text": "so first one is is that we'll grab some information information put that in our patient spreadsheet we'll grab some",
    "start": "2606780",
    "end": "2613080"
  },
  {
    "text": "observation information and put that in a spreadsheet and I'm gonna zoom in on part of this query just briefly because",
    "start": "2613080",
    "end": "2620070"
  },
  {
    "text": "I think this shows like some of the about some of the the capabilities of doing data engineering at this scale and that this looks complex but it's really",
    "start": "2620070",
    "end": "2627360"
  },
  {
    "text": "just standard SQL once again it's easier it's not I think its most easiest easily read from the inside out so if the query",
    "start": "2627360",
    "end": "2635490"
  },
  {
    "text": "is if the code is in this value set for glucose level we included in our average otherwise we'd return null which simply",
    "start": "2635490",
    "end": "2641970"
  },
  {
    "text": "isn't included in the average and then that a little bit color code computes the average glucose level for that",
    "start": "2641970",
    "end": "2647880"
  },
  {
    "text": "person of course this query as it stands you know looks for their average Hall of history it probably isn't what we want",
    "start": "2647880",
    "end": "2653520"
  },
  {
    "text": "so we'll add to our group by clause will include month and year and or whatever",
    "start": "2653520",
    "end": "2658530"
  },
  {
    "text": "arbitrary date that we're working with and then we want to include that in our bees in a results table and we could do",
    "start": "2658530",
    "end": "2664560"
  },
  {
    "text": "that with a bunch of other things as well so again we've gone here from that complex but complete firebase data sets",
    "start": "2664560",
    "end": "2670650"
  },
  {
    "text": "and we convert it into a much simpler data model of how we can interactively explore and it's not and we do with",
    "start": "2670650",
    "end": "2676080"
  },
  {
    "text": "almost anything so here's the something similar for our conditions same exact pattern where we're getting like the",
    "start": "2676080",
    "end": "2682140"
  },
  {
    "text": "onset for these conditions that are used for our data analysis there then we can",
    "start": "2682140",
    "end": "2687240"
  },
  {
    "text": "join these tables together and we land in getting this view that we can feed",
    "start": "2687240",
    "end": "2692700"
  },
  {
    "text": "directly into our into our machine learning use case models or other use cases and back to the collaborative",
    "start": "2692700",
    "end": "2700080"
  },
  {
    "text": "space well we can take our time series we can write we can save it as a table of all our patient history information",
    "start": "2700080",
    "end": "2706050"
  },
  {
    "text": "and then we can pick it up from there so here we have whether we use sparks built",
    "start": "2706050",
    "end": "2712140"
  },
  {
    "text": "in machine learning capabilities or other systems other machine learning capabilities by having in this this sort",
    "start": "2712140",
    "end": "2718020"
  },
  {
    "text": "of tabular form you can tap into it here's a little bit of code that actually if you're familiar with like scikit-learn or other toolkits in the",
    "start": "2718020",
    "end": "2724770"
  },
  {
    "text": "python space should look very familiar we can take our high quality data put it into this pipeline and build a machine",
    "start": "2724770",
    "end": "2730890"
  },
  {
    "text": "learning model and this is where we kind of maybe draw the distinction of we talked about data engineering this was",
    "start": "2730890",
    "end": "2737130"
  },
  {
    "text": "everything that we've done like I said putting everything into giant spreadsheets and the machine learning youth cases which is picking it up from",
    "start": "2737130",
    "end": "2742710"
  },
  {
    "text": "there and these lines this lines a little bit blurry so you can debate where exactly it is but we kind of use",
    "start": "2742710",
    "end": "2748380"
  },
  {
    "text": "this definition for the purposes of our efforts and we actually are excited",
    "start": "2748380",
    "end": "2754740"
  },
  {
    "start": "2752000",
    "end": "2803000"
  },
  {
    "text": "there so actually something that we're sharing we're actually open sourcing a library today and to take all of fire",
    "start": "2754740",
    "end": "2761220"
  },
  {
    "text": "data and natively represented in the apache spark project so if you've the advantages of fire being all the",
    "start": "2761220",
    "end": "2767430"
  },
  {
    "text": "curation and efforts that exists in there today and be able to put that and directly query it with the exact same",
    "start": "2767430",
    "end": "2774210"
  },
  {
    "text": "SQL that we saw there today is kind of getting the advantages of spark data model I'm sorry about the fire data",
    "start": "2774210",
    "end": "2780300"
  },
  {
    "text": "model and with native support built in for spark so if you it's up on if you just go to engineering that Cerner comm",
    "start": "2780300",
    "end": "2786660"
  },
  {
    "text": "it'll be the top blog post right now and that's actually a link to the project itself it's apache license and it's up on",
    "start": "2786660",
    "end": "2792510"
  },
  {
    "text": "github you can find it all all of that sort of thing and I think this could really help our data engineering use",
    "start": "2792510",
    "end": "2798240"
  },
  {
    "text": "cases for this for for working with these firebase datasets so that's our",
    "start": "2798240",
    "end": "2804180"
  },
  {
    "start": "2803000",
    "end": "2932000"
  },
  {
    "text": "data engineering piece and and I think that we also want to make the major we wanted to look at how this plugs into our machine learning use",
    "start": "2804180",
    "end": "2810610"
  },
  {
    "text": "cases and and you know we you know when I just talked about turning the world a giant spreadsheets making well does that",
    "start": "2810610",
    "end": "2815980"
  },
  {
    "text": "have to do with machine learning but what's interesting is like every machine learning job I mean every machine learnt",
    "start": "2815980",
    "end": "2822010"
  },
  {
    "text": "as follows the same basic pattern whether it's logistic regression or whether it's a neural network they all",
    "start": "2822010",
    "end": "2828520"
  },
  {
    "text": "hold the same patterns that the machine learning algorithm has a set of parameters that you give it give to it and then it goes through and it finds",
    "start": "2828520",
    "end": "2835090"
  },
  {
    "text": "the optimal combination of those parameters so the machine learning the algorithm that's produced minimizes the",
    "start": "2835090",
    "end": "2841750"
  },
  {
    "text": "difference between what your test data says and what your your your predictions are they all follow that same pattern",
    "start": "2841750",
    "end": "2846880"
  },
  {
    "text": "and they're just walking down this slope to find this optimal combination and by going through these data engineering",
    "start": "2846880",
    "end": "2853120"
  },
  {
    "text": "exercises by providing these really high quality inputs to our machine learning model one it makes it'll it'll make the",
    "start": "2853120",
    "end": "2858790"
  },
  {
    "text": "machine learning model easier which means it will run much faster your models will converge much more quickly and to you'll get better outcomes",
    "start": "2858790",
    "end": "2865780"
  },
  {
    "text": "because you're taking advantage of some of this human knowledge that we have there's so much human knowledge in terms",
    "start": "2865780",
    "end": "2871000"
  },
  {
    "text": "of these coding systems and these data models and these data structures and by taking that we make machine learning",
    "start": "2871000",
    "end": "2876100"
  },
  {
    "text": "much more effective by giving it these high quality inputs that they're working with and as an engineer I kind of think",
    "start": "2876100",
    "end": "2882880"
  },
  {
    "text": "of all this is like really it's like we're just approximating functions in a way and we're just basically there's",
    "start": "2882880",
    "end": "2889480"
  },
  {
    "text": "certain functions that I know how to write so I can easily write a lab you mean level greater than some range I don't need machine money for that I",
    "start": "2889480",
    "end": "2895420"
  },
  {
    "text": "can write that function I don't know how to write this function to say hey is there something abnormal in this image",
    "start": "2895420",
    "end": "2901060"
  },
  {
    "text": "or it doesn't have to be images I mean is there something in this data that predicts some outcome that we wouldn't",
    "start": "2901060",
    "end": "2907420"
  },
  {
    "text": "expect and this is so much above what we do is in terms of as I view it from a",
    "start": "2907420",
    "end": "2912850"
  },
  {
    "text": "software engineering perspective is that hey we their functions we know how to write their functions we don't know how to write let's create an environment to",
    "start": "2912850",
    "end": "2919510"
  },
  {
    "text": "create these approximations of functions and continuously approve them and then integrating them back into our system",
    "start": "2919510",
    "end": "2924880"
  },
  {
    "text": "just like we would any other function that we work with and it's nice just to have this rich variety of toolkits that",
    "start": "2924880",
    "end": "2930550"
  },
  {
    "text": "can do this sort of thing of course we talked about because this deep complexity dealing with all these sorts",
    "start": "2930550",
    "end": "2936880"
  },
  {
    "start": "2932000",
    "end": "2986000"
  },
  {
    "text": "of things it's all the technology with it the deep complexity of all the data working with the sort of things but the sort of",
    "start": "2936880",
    "end": "2942640"
  },
  {
    "text": "that's theme to go to these simplified use of this data is reproducibility this ability to go from nothing from a system",
    "start": "2942640",
    "end": "2949869"
  },
  {
    "text": "that doesn't this to just data to be able to land an entire architecture be able to reproduce an entire data engineering pipeline to create these",
    "start": "2949869",
    "end": "2956470"
  },
  {
    "text": "projections for the purpose and to apply machine learning model that mitigates all this deep complexity that we're",
    "start": "2956470",
    "end": "2961930"
  },
  {
    "text": "dealing with so if we do one thing once we have these constraints that we really care about we have our security we have",
    "start": "2961930",
    "end": "2967000"
  },
  {
    "text": "our user experience dance that we cannot budge on but in addition to that I mean this rebuilding to reproduce the systems",
    "start": "2967000",
    "end": "2974260"
  },
  {
    "text": "and Inter it quickly on it are really what gets us to these sort of high level views that plug cleanly into a huge",
    "start": "2974260",
    "end": "2980829"
  },
  {
    "text": "number of analytic tools and machine learning tools and do so really effectively and this kind of gets us to",
    "start": "2980829",
    "end": "2988030"
  },
  {
    "start": "2986000",
    "end": "3070000"
  },
  {
    "text": "another for the positive space another positive loop that we can work through and that we have a new question we have",
    "start": "2988030",
    "end": "2995950"
  },
  {
    "text": "some new that we want to solve and by using these patterns we can model the data for the question at hand so we can",
    "start": "2995950",
    "end": "3003150"
  },
  {
    "text": "create this projection that meets these needs so I can do this analysis as necessary we can simulate we can refine",
    "start": "3003150",
    "end": "3008849"
  },
  {
    "text": "we can build the model we can test it we can validate it we can analyze the results in that model and we can feed it",
    "start": "3008849",
    "end": "3014670"
  },
  {
    "text": "back in so now that we'd better understand the question maybe we have another one or maybe we have we tweaked the parameters of the question and",
    "start": "3014670",
    "end": "3020369"
  },
  {
    "text": "adjust it and then of course through all of this I mean we're creating these new data sets that have each one of our",
    "start": "3020369",
    "end": "3025650"
  },
  {
    "text": "transformations ever each one of our functions each one of our data sets has value and we need to push them back in to this catalog so others can discover",
    "start": "3025650",
    "end": "3032609"
  },
  {
    "text": "them so they can leverage them so you can take advantage of them for new needs that emerge and what's exciting about",
    "start": "3032609",
    "end": "3038760"
  },
  {
    "text": "this this cycle is that we can do it on demand we can do it at scale and by Goong we can go through the cycle really",
    "start": "3038760",
    "end": "3045450"
  },
  {
    "text": "fast without even having to sort of leave that mental zone of where we're doing this analysis or if I don't have",
    "start": "3045450",
    "end": "3051240"
  },
  {
    "text": "to go and wander off because my job is gonna run for the next five hours if I can stay in that environment it",
    "start": "3051240",
    "end": "3056309"
  },
  {
    "text": "interactively do this analysis we can go much more quickly and by going much more quickly I mean really that just boils",
    "start": "3056309",
    "end": "3062190"
  },
  {
    "text": "down to the fact that we can innovate more quickly than we could have before and I think that's probably the most",
    "start": "3062190",
    "end": "3067470"
  },
  {
    "text": "exciting thing about all these patterns that we're working with so with that I've thank you everyone and I well I do",
    "start": "3067470",
    "end": "3074940"
  },
  {
    "start": "3070000",
    "end": "3536000"
  },
  {
    "text": "have some minute a little bit time for questions so I I think there's some",
    "start": "3074940",
    "end": "3083850"
  },
  {
    "text": "logistics around the questions that we're gonna line up guess we can there",
    "start": "3083850",
    "end": "3094430"
  },
  {
    "text": "okay well good I'll repeat the question once you go ahead and yeah okay so the",
    "start": "3095150",
    "end": "3125430"
  },
  {
    "text": "questions so given the and predicated on this data model is there a reason to use spark over something like redshift yeah",
    "start": "3125430",
    "end": "3131460"
  },
  {
    "text": "yeah so so I think that our approach is like it depends on the use case a part",
    "start": "3131460",
    "end": "3137610"
  },
  {
    "text": "of this environment is we want to be able to apply whatever tool fits best for the problem at hand",
    "start": "3137610",
    "end": "3142950"
  },
  {
    "text": "so if you have a variety of analytics that works really well in a redshift model or an Athena model absolutely use",
    "start": "3142950",
    "end": "3148440"
  },
  {
    "text": "those we used spark because some of our workloads worked better for one it's",
    "start": "3148440",
    "end": "3153990"
  },
  {
    "text": "like we we have a variety of pretty rich and complex user defined functions written in Java that work really well in",
    "start": "3153990",
    "end": "3159810"
  },
  {
    "text": "a spark cluster so we could isolate that so it's a bit of a better use case for our problem at hand and then in spark",
    "start": "3159810",
    "end": "3164970"
  },
  {
    "text": "also works really well with a lot more deeply nested structure datasets which is doable in some of these other",
    "start": "3164970",
    "end": "3171120"
  },
  {
    "text": "platforms as well but I have a spark support as solid for it but like I said I mean I think that that part of it's",
    "start": "3171120",
    "end": "3178290"
  },
  {
    "text": "like maybe the destruction that I draw is like for things like redshift if you have like the same style of queries that",
    "start": "3178290",
    "end": "3184470"
  },
  {
    "text": "you tend to run or same sort of analysis something like an MPP style database like a redshift is probably going to",
    "start": "3184470",
    "end": "3190110"
  },
  {
    "text": "beat a spark because it can be strongly optimized with that that schema that you defined if you want to create some crazy",
    "start": "3190110",
    "end": "3196080"
  },
  {
    "text": "new view based off of you know a couple of you know several a few hundred terabytes of data interactively SPARC",
    "start": "3196080",
    "end": "3202050"
  },
  {
    "text": "tends to do better that workload if you don't really know what your view of data wants to be but anyway I'd suggest try",
    "start": "3202050",
    "end": "3207690"
  },
  {
    "text": "them both and would do whatever works for you see a hand back to your thing I see a hand back there yeah right right",
    "start": "3207690",
    "end": "3225170"
  },
  {
    "text": "yeah yeah yeah so so the question is it's like we have to delete data from",
    "start": "3225170",
    "end": "3231660"
  },
  {
    "text": "our our database and and but a park' does you can't delete from a park a file you and and and I think that the the",
    "start": "3231660",
    "end": "3239790"
  },
  {
    "text": "thing is there's like every so every data set that we have in this is something that we can reproduce from the",
    "start": "3239790",
    "end": "3246270"
  },
  {
    "text": "initial raw data source so what we do is we don't attempt to delete remove from part Fayetteville just delete the parque",
    "start": "3246270",
    "end": "3251910"
  },
  {
    "text": "file and then we'll recreate it from well we'll deal with B Park a file will go back to the raw data format that",
    "start": "3251910",
    "end": "3258240"
  },
  {
    "text": "comes in which could be anything ranging from a CSV to whatever import you know whatever import we got from the system",
    "start": "3258240",
    "end": "3263700"
  },
  {
    "text": "and so we'll actually recreate our entire data set from scratch quote-unquote based without that data",
    "start": "3263700",
    "end": "3269610"
  },
  {
    "text": "but but yeah it's it's it's a it's a big challenge in this type of system so you have to be real but this is another place where like strong reproducibility",
    "start": "3269610",
    "end": "3276150"
  },
  {
    "text": "of your data sets is really really important that's a good question I saw one go up there then we'll get you",
    "start": "3276150",
    "end": "3282660"
  },
  {
    "text": "faster yeah it's good",
    "start": "3282660",
    "end": "3285799"
  },
  {
    "text": "yeah yeah so the question is data pipeline the fact that data pipeline isn't hip it eligible so we this data",
    "start": "3294530",
    "end": "3301110"
  },
  {
    "text": "pipeline in a very narrow sense in such a way that it never sees any actual data",
    "start": "3301110",
    "end": "3306330"
  },
  {
    "text": "and and so basically and this is trust this was a good length of conversation we have with our colleagues at Amazon as",
    "start": "3306330",
    "end": "3312330"
  },
  {
    "text": "well to make sure that that we were well covered in this case but the way we use data put it a WSB a pipeline is that it",
    "start": "3312330",
    "end": "3319740"
  },
  {
    "text": "basically looks for the the presence of a success files like hey there's some data ready to process and then and then",
    "start": "3319740",
    "end": "3325050"
  },
  {
    "text": "it goes and launches a spark job running an EMR that does all the workload so the",
    "start": "3325050",
    "end": "3330300"
  },
  {
    "text": "EMR cluster is is HIPAA compliant so yeah basically we use it as basically a way to trigger jobs that run in a HIPAA",
    "start": "3330300",
    "end": "3336840"
  },
  {
    "text": "compliant environment yeah yeah that one was yeah if we worked through that one but yeah we made sure that we were",
    "start": "3336840",
    "end": "3342090"
  },
  {
    "text": "covered there and I saw appears",
    "start": "3342090",
    "end": "3346280"
  },
  {
    "text": "yeah so they take out the data into an Excel spread and do some other manipulation there yeah so we actually",
    "start": "3356830",
    "end": "3364700"
  },
  {
    "text": "have a number of use cases in which will convert some summaries data into an",
    "start": "3364700",
    "end": "3369770"
  },
  {
    "text": "Excel and then can do some manipulation there and then push that in back in for reporting I mean the ones that we use",
    "start": "3369770",
    "end": "3375340"
  },
  {
    "text": "largely now are I mean just like some summary statistics and atha or sort of",
    "start": "3375340",
    "end": "3380840"
  },
  {
    "text": "things sorry our data sets tend to be much bigger than you can practically fit into Excel so but when we do it it tends",
    "start": "3380840",
    "end": "3387020"
  },
  {
    "text": "to be just like general broad population counts and that sort of thing then we do",
    "start": "3387020",
    "end": "3392810"
  },
  {
    "text": "that with so if you have a little more flexibility there since there's no pH I or PII and those spreadsheets that we're",
    "start": "3392810",
    "end": "3398360"
  },
  {
    "text": "dealing with all right so I've got it yeah got a few more got a few more minutes yes sir",
    "start": "3398360",
    "end": "3407110"
  },
  {
    "text": "Yeah right right so if question is how do you agree on the logic of those",
    "start": "3412030",
    "end": "3418390"
  },
  {
    "text": "productions what they should look like yeah and honestly I think that attempt",
    "start": "3418390",
    "end": "3423550"
  },
  {
    "text": "to the way the system of all they think of all was because of challenges in that",
    "start": "3423550",
    "end": "3429160"
  },
  {
    "text": "very question like it was different building any projection that suitable",
    "start": "3429160",
    "end": "3434260"
  },
  {
    "text": "for one use case is probably not suitable for another so what we've kind of done here is as we've let our data",
    "start": "3434260",
    "end": "3441370"
  },
  {
    "text": "scientists like create their own custom projections very frequently and then share projections with one another",
    "start": "3441370",
    "end": "3446520"
  },
  {
    "text": "whenever it makes sense to do so so it's sort of like sort of a collaborative approach where the in the in sharing is",
    "start": "3446520",
    "end": "3452260"
  },
  {
    "text": "often in terms of just hey here's my SQL query or maybe I write probably projection back to the database back to",
    "start": "3452260",
    "end": "3458860"
  },
  {
    "text": "the data catalog and you can pick it up from there but but there I think the so",
    "start": "3458860",
    "end": "3464770"
  },
  {
    "text": "I'm in a way I'm kind of like going at doing an end-around of your question by saying hey we don't have a ton of shared",
    "start": "3464770",
    "end": "3470590"
  },
  {
    "text": "projections but we kind of let people create their own ad hoc and customize it I will say that as we're evolving this",
    "start": "3470590",
    "end": "3476530"
  },
  {
    "text": "system we are seeing some commonality that tends to show up again and again and again and again in these projections",
    "start": "3476530",
    "end": "3482100"
  },
  {
    "text": "so we're actually working on taking that commonality and refactoring it it's having a small number of like sort of",
    "start": "3482100",
    "end": "3488920"
  },
  {
    "text": "common projections that a lot of people can use kind of similarly to like how fire shows like here's the data elements",
    "start": "3488920",
    "end": "3495220"
  },
  {
    "text": "to include and exclude so we want to find like some common projections that'll meet the 80% case but that's just that's a very iterative like",
    "start": "3495220",
    "end": "3501580"
  },
  {
    "text": "constantly getting feedback when do we need things sort of thing there's I just I don't know of a good shortcut to finding good common projections other",
    "start": "3501580",
    "end": "3508060"
  },
  {
    "text": "than other than just make it easy for people to create and make it easy for people to iterate on it's a real",
    "start": "3508060",
    "end": "3513820"
  },
  {
    "text": "challenge alright so maybe one more question you know okay last question yes",
    "start": "3513820",
    "end": "3520300"
  },
  {
    "text": "sir sorry I couldn't see over there",
    "start": "3520300",
    "end": "3523320"
  },
  {
    "text": "you know right yeah yeah yeah so okay so",
    "start": "3526200",
    "end": "3539650"
  },
  {
    "text": "a couple bit so the questions spreadsheets are great but there's a lot of stuff it doesn't spin into spreadsheets right so and so one is like",
    "start": "3539650",
    "end": "3548230"
  },
  {
    "text": "I'm being a little bit tongue-in-cheek when I say spreadsheet so I call it like anything that could fit in the tabular",
    "start": "3548230",
    "end": "3554320"
  },
  {
    "text": "form works really well so that hits part of what you're hitting there but obviously not all of it so like a EKG",
    "start": "3554320",
    "end": "3560140"
  },
  {
    "text": "date or a time series data can fit in a tabular form and that works we actually do time series data extensively using",
    "start": "3560140",
    "end": "3565900"
  },
  {
    "text": "this model so for unstructured data that can has a lot more challenging so a lot",
    "start": "3565900",
    "end": "3571570"
  },
  {
    "text": "of times that what we'll do for unstructured data so if you have images or something that I'm intending on the size of it I mean you can behind a sort",
    "start": "3571570",
    "end": "3578320"
  },
  {
    "text": "of I could have maybe like what you consider like it sort of a degenerative form of a table where you just have one",
    "start": "3578320",
    "end": "3583540"
  },
  {
    "text": "column and it's just the unstructured data then you have to write very customized code to deal with that so",
    "start": "3583540",
    "end": "3589090"
  },
  {
    "text": "yeah so there's it doesn't I mean that the system that were this patterns that we're describing here doesn't solve the",
    "start": "3589090",
    "end": "3596080"
  },
  {
    "text": "the unstructured data use cases I mean we it basically lets us hit the simplex",
    "start": "3596080",
    "end": "3602260"
  },
  {
    "text": "that working with simple data is simple the one piece that we do do quite a bit",
    "start": "3602260",
    "end": "3607480"
  },
  {
    "text": "of is that when dealing with unstructured data a lot of times you'll run through like some very complex like",
    "start": "3607480",
    "end": "3612580"
  },
  {
    "text": "feature extraction algorithm against whatever clinical note and then once you have run that feature extraction",
    "start": "3612580",
    "end": "3618340"
  },
  {
    "text": "algorithm then you could put that in a spreadsheet you can like have a you know a list of vectors again I'm being a",
    "start": "3618340",
    "end": "3623980"
  },
  {
    "text": "little bit tongue-in-cheek about the definition Fred sheet but but yeah there's there's a ton of problems that",
    "start": "3623980",
    "end": "3629109"
  },
  {
    "text": "aren't fitting this pattern but what we found that we do is like we write complex logic when you need to and then",
    "start": "3629109",
    "end": "3635109"
  },
  {
    "text": "when it makes sense project that onto the simpler form which may just be just feature vectors or term vectors or",
    "start": "3635109",
    "end": "3640690"
  },
  {
    "text": "engrams or sort of thing if you're grabbing stuff out of out of unstructured content and of course that the right answer that's going to vary",
    "start": "3640690",
    "end": "3646780"
  },
  {
    "text": "tremendously depending on the on the domain space so I've been kind of being kicked off the stage so hey thanks again",
    "start": "3646780",
    "end": "3652660"
  },
  {
    "text": "everyone I appreciate it [Applause]",
    "start": "3652660",
    "end": "3658550"
  }
]
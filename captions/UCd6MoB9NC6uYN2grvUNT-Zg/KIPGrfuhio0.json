[
  {
    "start": "0",
    "end": "37000"
  },
  {
    "text": "good afternoon everyone my name is elias haddad I'm a product manager at spunk responsible for data collection a little",
    "start": "60",
    "end": "8429"
  },
  {
    "text": "bit about me I joined Splunk over actually a little bit less than four years ago and I fell in love with this",
    "start": "8429",
    "end": "15420"
  },
  {
    "text": "piece of software since I first put my hands onto it the topic of our conversation today is",
    "start": "15420",
    "end": "21240"
  },
  {
    "text": "plunk obviously but also an exciting new announcement around Splunk I'm not gonna",
    "start": "21240",
    "end": "27000"
  },
  {
    "text": "spoil the surprise but I'll give you a hint just to whet your appetite it's about Kinesis and Splunk so this is the",
    "start": "27000",
    "end": "38940"
  },
  {
    "start": "37000",
    "end": "115000"
  },
  {
    "text": "agenda where for those of us who are not familiar with Blanc I'll go over what Splunk is I'll I promise I won't be too",
    "start": "38940",
    "end": "45059"
  },
  {
    "text": "long on that front just for us to focus on the the announcement and then we'll",
    "start": "45059",
    "end": "53399"
  },
  {
    "text": "talk about the ingestion landscape it's plunk some of the challenges that we have and how we're gonna plan or how",
    "start": "53399",
    "end": "59520"
  },
  {
    "text": "we're planning on addressing these challenges by leveraging that new ingestion mechanism that we have with",
    "start": "59520",
    "end": "66689"
  },
  {
    "text": "AWS and then at the very end we have Steven here from Cox auto he's gonna",
    "start": "66689",
    "end": "71729"
  },
  {
    "text": "talk about some exciting use cases that Cox auto has built around Splunk in AWS",
    "start": "71729",
    "end": "80060"
  },
  {
    "text": "for any questions that you might have please leave it to the very end so so",
    "start": "80060",
    "end": "86130"
  },
  {
    "text": "that we have will dedicate around 10 minutes or 15 minutes for that so over",
    "start": "86130",
    "end": "93060"
  },
  {
    "text": "the course of this session I have to go through this we have we're gonna make forward-looking statements these are",
    "start": "93060",
    "end": "99930"
  },
  {
    "text": "based on current facts and current events would like to caution you that some of these facts might be different",
    "start": "99930",
    "end": "106890"
  },
  {
    "text": "in the future so things might be things might change when things happen in the",
    "start": "106890",
    "end": "113040"
  },
  {
    "text": "future so just a quick question show of hand how many of you are familiar with what",
    "start": "113040",
    "end": "119570"
  },
  {
    "start": "115000",
    "end": "127000"
  },
  {
    "text": "Splunk is or our current Wow maybe I can skip all the slides then so just I'll",
    "start": "119570",
    "end": "128119"
  },
  {
    "start": "127000",
    "end": "215000"
  },
  {
    "text": "skip through it real real quick just to",
    "start": "128119",
    "end": "133430"
  },
  {
    "text": "introduce what Splunk is so for us to understand what Splunk is we need to understand what machine data is and",
    "start": "133430",
    "end": "138590"
  },
  {
    "text": "machine data is is any type of digital exhaust that gets generated by whatever",
    "start": "138590",
    "end": "144980"
  },
  {
    "text": "powers your organization and that can be very broad in nature machine data is",
    "start": "144980",
    "end": "150049"
  },
  {
    "text": "growing fast and which adds to the complexity of getting insight into machine data so as you see here on the",
    "start": "150049",
    "end": "158420"
  },
  {
    "text": "slide machine data can be broad broad range of things broad range of data sources what",
    "start": "158420",
    "end": "165380"
  },
  {
    "text": "you see here is just a small subset of what you can get into Splunk for example",
    "start": "165380",
    "end": "171200"
  },
  {
    "text": "if you're an airplane company airline company this could mean machine data",
    "start": "171200",
    "end": "176720"
  },
  {
    "text": "generated by application logs by events and metrics coming from your application could be events coming from the",
    "start": "176720",
    "end": "183650"
  },
  {
    "text": "infrastructure that's hosting these application could be security data coming from firewall network devices and",
    "start": "183650",
    "end": "189859"
  },
  {
    "text": "so forth also it could be way beyond this any Twitter feed any social media",
    "start": "189859",
    "end": "195530"
  },
  {
    "text": "interaction for you to get insight into how well your customers are are",
    "start": "195530",
    "end": "202030"
  },
  {
    "text": "interacting with your application also beyond that it could be in the Internet",
    "start": "202030",
    "end": "208160"
  },
  {
    "text": "of Things world it could be sensors whether it's airplane or train and so forth so with machine data there's",
    "start": "208160",
    "end": "218540"
  },
  {
    "start": "215000",
    "end": "267000"
  },
  {
    "text": "there's a lot of complexity so we believe that machine data has a lot of value and I'm sure you guys believe the",
    "start": "218540",
    "end": "224389"
  },
  {
    "text": "same way but also it's very messy unpredictable it's very hard to extract and harness that value from machine data",
    "start": "224389",
    "end": "231130"
  },
  {
    "text": "it's also for you to get inside you need to Swift through massive amounts of data",
    "start": "231130",
    "end": "236420"
  },
  {
    "text": "which makes it even more complex so we need something that scales to the volume and to your high number of devices that",
    "start": "236420",
    "end": "243920"
  },
  {
    "text": "generating these machine data and most importantly you don't",
    "start": "243920",
    "end": "249250"
  },
  {
    "text": "Celie no the question that you want to ask this data up front so it's plunk you",
    "start": "249250",
    "end": "254710"
  },
  {
    "text": "have the ability to ingest all that data regardless of the format regardless of the of where they reside and then you",
    "start": "254710",
    "end": "261940"
  },
  {
    "text": "can ask the question based on your needs",
    "start": "261940",
    "end": "265740"
  },
  {
    "text": "so what is plunk which brings me back to what Splunk a is it's a single piece of software it's one platform it allows you",
    "start": "267330",
    "end": "275350"
  },
  {
    "text": "to ingest analyze and visualize machine data in real time that's pretty much in",
    "start": "275350",
    "end": "281410"
  },
  {
    "text": "a nutshell it has the ability to analyze that data at scale and reliably and in",
    "start": "281410",
    "end": "288100"
  },
  {
    "text": "near real-time it's an open air ecosystem meaning that as a platform you'll have the ability to build your",
    "start": "288100",
    "end": "293950"
  },
  {
    "text": "own data ingestion but also build your own visualization do your own customization to get insight into that",
    "start": "293950",
    "end": "300490"
  },
  {
    "text": "data it's a very open ecosystem we have a broad range of apps on our App Store",
    "start": "300490",
    "end": "306640"
  },
  {
    "text": "so it's a very vibrant ecosystem in app and Splunk is nothing more than canned visualization that targets specific use",
    "start": "306640",
    "end": "314260"
  },
  {
    "text": "cases or specific technology just like AWS for example one of our more popular apps spunk app for AWS so we have",
    "start": "314260",
    "end": "322390"
  },
  {
    "text": "various apps that are you you can download from our App Store but also you can build your own it's very extensible",
    "start": "322390",
    "end": "327910"
  },
  {
    "text": "platform one thing worth mentioning that is that Splunk is is hybrid meaning that",
    "start": "327910",
    "end": "334150"
  },
  {
    "text": "you have ability to ingest data from on-prem cloud and various cloud vendors",
    "start": "334150",
    "end": "340120"
  },
  {
    "text": "as well it's a machine-learning powered platform which means not only you have",
    "start": "340120",
    "end": "345310"
  },
  {
    "text": "the ability to get insight into that data but also you you'll be able to apply machine learning to be more",
    "start": "345310",
    "end": "351340"
  },
  {
    "text": "proactive in to how you would look into that data on how you analyze the data and how you would detect anomalies",
    "start": "351340",
    "end": "358240"
  },
  {
    "text": "whenever something deviates from the norm that's our mission statement make",
    "start": "358240",
    "end": "365860"
  },
  {
    "start": "363000",
    "end": "379000"
  },
  {
    "text": "machine data accessible usable vital to everyone we have a high number of",
    "start": "365860",
    "end": "372520"
  },
  {
    "text": "customers over 13,000 today worldwide highly mature piece of software so let's",
    "start": "372520",
    "end": "380680"
  },
  {
    "start": "379000",
    "end": "478000"
  },
  {
    "text": "talk about Splunk in AWS so we have over the past year since I",
    "start": "380680",
    "end": "386650"
  },
  {
    "text": "joined spying there's various points of synergy between the two companies between Splunk and AWS and this can",
    "start": "386650",
    "end": "392979"
  },
  {
    "text": "summarize a little bit our point of synergy so today you have the ability to use plunk Enterprise which is the piece",
    "start": "392979",
    "end": "399879"
  },
  {
    "text": "of software that you can download and deploy it on your laptop but also it's available for you as an army to request",
    "start": "399879",
    "end": "405969"
  },
  {
    "text": "it from AWS marketplace also you have the ability to use spun cloud as a",
    "start": "405969",
    "end": "410979"
  },
  {
    "text": "surface which is the spawn Enterprise as a service also we have two apps that are",
    "start": "410979",
    "end": "416590"
  },
  {
    "text": "available for you one is this monk app for AWS that gives you quick insight and quick",
    "start": "416590",
    "end": "421900"
  },
  {
    "text": "visualization against various use cases with AWS whether its billing managing",
    "start": "421900",
    "end": "428020"
  },
  {
    "text": "your billing and cost whether it's security use cases around visualizing",
    "start": "428020",
    "end": "433060"
  },
  {
    "text": "all the activities around your AWS services or whether it's IT operation",
    "start": "433060",
    "end": "438250"
  },
  {
    "text": "related type of use cases measuring performance and various infrastructure",
    "start": "438250",
    "end": "445210"
  },
  {
    "text": "management type of use cases and also we have a broad range of integration and this is pretty much the focus of our",
    "start": "445210",
    "end": "451089"
  },
  {
    "text": "topic today is to to cover the data ingestion part so we have this monkey",
    "start": "451089",
    "end": "456159"
  },
  {
    "text": "add-on for AWS we'll talk about that in more details later on we also have",
    "start": "456159",
    "end": "461770"
  },
  {
    "text": "lambda blueprint all of this has a very broad range of support against all",
    "start": "461770",
    "end": "468129"
  },
  {
    "text": "pretty much all the AWS services so you have the ability to ingest pretty much any data from any service in AWS",
    "start": "468129",
    "end": "476339"
  },
  {
    "start": "478000",
    "end": "495000"
  },
  {
    "text": "the culmination of our partnership is one cloud which runs on AWS so if you're",
    "start": "479059",
    "end": "484939"
  },
  {
    "text": "not a customer today you have the ability to request it to request one cloud from your from the region that you",
    "start": "484939",
    "end": "492979"
  },
  {
    "text": "would like to have with that this brings us to the main topic of our conversation",
    "start": "492979",
    "end": "500809"
  },
  {
    "start": "495000",
    "end": "630000"
  },
  {
    "text": "today which is the data ingestion landscape from AWS this is one of my favorite slide on this deck the guy who",
    "start": "500809",
    "end": "508789"
  },
  {
    "text": "built it is probably not here but this this summarizes pretty much everything",
    "start": "508789",
    "end": "514849"
  },
  {
    "text": "you can ingest from AWS as you can see at the top of the slide you have all the",
    "start": "514849",
    "end": "520490"
  },
  {
    "text": "AWS services whether it is cloud Watch config cloud watch events koala wash",
    "start": "520490",
    "end": "526639"
  },
  {
    "text": "logs IOT Kinesis and so forth a very broad range of support that we have",
    "start": "526639",
    "end": "533360"
  },
  {
    "text": "today and this summer this summarizes as well the mechanism that you have today",
    "start": "533360",
    "end": "539779"
  },
  {
    "text": "to ingest that data from into Splunk so one mechanism is DB connect any anyone",
    "start": "539779",
    "end": "549050"
  },
  {
    "text": "of you familiar with DB connect ok so DB connect gives you that ability to query",
    "start": "549050",
    "end": "554720"
  },
  {
    "text": "databases directly ingest the data or query query the data directly from that database so whether you have redshift or",
    "start": "554720",
    "end": "562129"
  },
  {
    "text": "any other database RDS running in AWS you have the ability to ingest that data the spunk addon for AWS which is the",
    "start": "562129",
    "end": "570709"
  },
  {
    "text": "more popular type of data ingestion mechanism the way it works is it's a pole based data ingestion meaning you",
    "start": "570709",
    "end": "577189"
  },
  {
    "text": "have a script that runs on the spawn side that periodically queries the api's",
    "start": "577189",
    "end": "582949"
  },
  {
    "text": "from the various AWS services and this script keeps squaring and ingesting the",
    "start": "582949",
    "end": "588559"
  },
  {
    "text": "data and keep track of where it last left so this is this has a very broad",
    "start": "588559",
    "end": "595279"
  },
  {
    "text": "support as well and then also if you want to push the data into Splunk versus the pull of the AWS addon you can use",
    "start": "595279",
    "end": "602360"
  },
  {
    "text": "lambda today we have various blueprints that support a wide range of services as",
    "start": "602360",
    "end": "607370"
  },
  {
    "text": "well so we have portion pool and query from a database but",
    "start": "607370",
    "end": "612420"
  },
  {
    "text": "main point behind the slide is that we it is a little bit complex so we have good support but however it becomes a",
    "start": "612420",
    "end": "619589"
  },
  {
    "text": "little bit complex for for you as to what type of mechanism would you use to ingest the data and this is one of the",
    "start": "619589",
    "end": "626910"
  },
  {
    "text": "challenges that I see today but there's more than that so we have some of the",
    "start": "626910",
    "end": "633329"
  },
  {
    "start": "630000",
    "end": "727000"
  },
  {
    "text": "reliability scalability issues managing the data collection nodes it is doable",
    "start": "633329",
    "end": "638339"
  },
  {
    "text": "to be reliable it is possible to be reliable and scalable today but it's not easy to manage and that's one of the",
    "start": "638339",
    "end": "645829"
  },
  {
    "text": "challenges that I'm highlighting here the other part is managing data collection fleet or what we call in the",
    "start": "645829",
    "end": "652740"
  },
  {
    "text": "spunk word modular input which typically comes with the add-on there's there's a",
    "start": "652740",
    "end": "658380"
  },
  {
    "text": "management overhead there's some complexity behind that to to scale out and manage all those data collection",
    "start": "658380",
    "end": "664920"
  },
  {
    "text": "nodes something that's not necessarily related to the the add-on itself or the",
    "start": "664920",
    "end": "670410"
  },
  {
    "text": "data collection itself there's delayed event and this is very common we've seen not necessarily with AWS but also with other third party API",
    "start": "670410",
    "end": "678300"
  },
  {
    "text": "is that we integrate with whenever you do pull this ingestion the events are delayed and we know and understand that",
    "start": "678300",
    "end": "685790"
  },
  {
    "text": "everybody wants real-time the latest events are not ideal in many of the",
    "start": "685790",
    "end": "691680"
  },
  {
    "text": "security use cases and IT operation use cases very common very problematic also",
    "start": "691680",
    "end": "697560"
  },
  {
    "text": "is the API throttling there's I don't know how many of you are using the AWS",
    "start": "697560",
    "end": "702930"
  },
  {
    "text": "add-on but this is there is limit on the AWS api's and we constantly hear from",
    "start": "702930",
    "end": "708000"
  },
  {
    "text": "customers who use it that they're hitting those api's and they keep pumping up that limit it's nothing we",
    "start": "708000",
    "end": "715079"
  },
  {
    "text": "can control but it's pretty much on the AWS side that that we constantly hit",
    "start": "715079",
    "end": "720209"
  },
  {
    "text": "which results in a lot of data loss and and frustration also from the customer",
    "start": "720209",
    "end": "725610"
  },
  {
    "text": "side so with that we need a new solution",
    "start": "725610",
    "end": "732170"
  },
  {
    "start": "727000",
    "end": "771000"
  },
  {
    "text": "and today what we're gonna announce is a new solution that both Splunk in AWS",
    "start": "732170",
    "end": "737850"
  },
  {
    "text": "very happy very excited to announce and that's why we have Rae it's a solution",
    "start": "737850",
    "end": "743970"
  },
  {
    "text": "that both teams have worked on called rated on a lot of efforts spend in there and then rate I'll I'll let you take",
    "start": "743970",
    "end": "751949"
  },
  {
    "text": "over",
    "start": "751949",
    "end": "754069"
  },
  {
    "text": "my name is way I do product management for Amazon I'm the guy that brings in the new solution for you and today so I",
    "start": "765290",
    "end": "772980"
  },
  {
    "start": "771000",
    "end": "992000"
  },
  {
    "text": "work for Amazon Kinesis Amazon Kinesis is real-time streaming data service platform at ABS so before I kick off can",
    "start": "772980",
    "end": "780930"
  },
  {
    "text": "I have a quick show of hands how many of guys have heard of Kinesis before great awesome every almost every one of you",
    "start": "780930",
    "end": "787500"
  },
  {
    "text": "guys how many of you guys use Kinesis today good hand for great awesome so today we have three services under the",
    "start": "787500",
    "end": "794639"
  },
  {
    "text": "Amazon Kinesis Brent on the very right right hand side that's the first service we shipped about three and a half years",
    "start": "794639",
    "end": "800519"
  },
  {
    "text": "ago it's called Kinesis streams it stores the data in real time and stores",
    "start": "800519",
    "end": "805709"
  },
  {
    "text": "adding replayable of streaming manner to enable you to ryan own applications the early motivation for this service action",
    "start": "805709",
    "end": "811860"
  },
  {
    "text": "found an internal demand for an AWS you guys are at abyss customers you guys use ec2 instances s3 redshift database and",
    "start": "811860",
    "end": "820199"
  },
  {
    "text": "most of these services have pay-as-you-go pricing model which means for every second every minute when all",
    "start": "820199",
    "end": "826290"
  },
  {
    "text": "these millions of Erebus customers using these services all these services are running metering data to meet or how",
    "start": "826290",
    "end": "831839"
  },
  {
    "text": "many usage of the particular service you have been using and it's a huge problem to solve because number one it needs to",
    "start": "831839",
    "end": "838079"
  },
  {
    "text": "be in real time so that you can see your estimated bill sooner than later number two it has to be able to be highly",
    "start": "838079",
    "end": "844470"
  },
  {
    "text": "available reliable and scalable because all these attributes services in instances and servers are talking to the",
    "start": "844470",
    "end": "850500"
  },
  {
    "text": "service that's when we invented Kinesis cream so today the entire Erebus metering and billing pipeline runs on",
    "start": "850500",
    "end": "857040"
  },
  {
    "text": "Kinesis streams so since we shipped the service we see a lot of creative real-time use cases coming out from our",
    "start": "857040",
    "end": "863250"
  },
  {
    "text": "customers and one of the top use cases actually customer would like to use the tools and analytical solutions they've",
    "start": "863250",
    "end": "870600"
  },
  {
    "text": "been using for things like hive press though a data warehouse a visualization bi tool or a search engine or Splunk so",
    "start": "870600",
    "end": "879180"
  },
  {
    "text": "they actually build these applications in just these real-time data from Kinesis into these different places then we figured actually maybe we",
    "start": "879180",
    "end": "886500"
  },
  {
    "text": "can do something to make these use cases they look a little bit easier which is when we ship Kinesis firehose it's an",
    "start": "886500",
    "end": "892740"
  },
  {
    "text": "abstraction layer built on top of Kinesis streams where it does manage data delivery into these different",
    "start": "892740",
    "end": "898740"
  },
  {
    "text": "destinations including storage and analysis destinations we support s3r a",
    "start": "898740",
    "end": "904530"
  },
  {
    "text": "shift at the initial launch and later on we added a task search this service is service which means you do not you need",
    "start": "904530",
    "end": "910830"
  },
  {
    "text": "to manage any server is skills elastically you just keep pushing the data into the service scale up and scale",
    "start": "910830",
    "end": "917040"
  },
  {
    "text": "down you do not need to worry about it has a pretty elastic pricing model you only pay for the data volume gets",
    "start": "917040",
    "end": "922920"
  },
  {
    "text": "transferred through the service so you don't pay anything if the volume is not there and you pay low volume when you",
    "start": "922920",
    "end": "928800"
  },
  {
    "text": "have low traffic vol and you pay PI warning when you add a peak so that's the Kinesis firehose service loading",
    "start": "928800",
    "end": "934980"
  },
  {
    "text": "data into different data storage and analytical destinations then we ship the third service called Kinesis analytics",
    "start": "934980",
    "end": "941430"
  },
  {
    "text": "it's a sequel engine that allows you to using sequel skill to query and analyze the data against the real-time data",
    "start": "941430",
    "end": "947460"
  },
  {
    "text": "streams so once we ship these you know Kinesis streams and firehose service we",
    "start": "947460",
    "end": "952680"
  },
  {
    "text": "see a lot of demand customer wants to run real-time analytics data analytics and applications however you know",
    "start": "952680",
    "end": "959310"
  },
  {
    "text": "writing a distributed system dealing with real-time isn't super easy and not a lot of customers have nesco said yes",
    "start": "959310",
    "end": "966180"
  },
  {
    "text": "so we ship this service to let customers using standard sequel which is a skill",
    "start": "966180",
    "end": "971340"
  },
  {
    "text": "set vast majority of the technical professionals has today so anybody who can write a standard a sequel now you",
    "start": "971340",
    "end": "977310"
  },
  {
    "text": "can using sequel to query against live stream to get insights from our real-time dashboard out of your data",
    "start": "977310",
    "end": "983520"
  },
  {
    "text": "with minutes or even seconds latency and today you probably have guessed the main",
    "start": "983520",
    "end": "989100"
  },
  {
    "text": "service I'm going to talk about is the Kinesis firehose service real-time ingestion service so this is how can he",
    "start": "989100",
    "end": "995820"
  },
  {
    "start": "992000",
    "end": "1243000"
  },
  {
    "text": "says firehose looked like before and it has three major components number one is stating ingestion you gotta have to get",
    "start": "995820",
    "end": "1002240"
  },
  {
    "text": "the data into the service continuously pushing data into that in real time so",
    "start": "1002240",
    "end": "1007280"
  },
  {
    "text": "there are a few mechanisms for you to get data into the service we offer two restful api so virtually any",
    "start": "1007280",
    "end": "1013500"
  },
  {
    "text": "any device or servers can put AWS SDK on it you can use the API to get data into",
    "start": "1013500",
    "end": "1018870"
  },
  {
    "text": "the service we also offer a Kinesis agent it's a java application for you to install on linux instances or servers in",
    "start": "1018870",
    "end": "1026400"
  },
  {
    "text": "Mon is a local log file as new data gets written into the log file it'll pick up and forward that into the file host",
    "start": "1026400",
    "end": "1032970"
  },
  {
    "text": "service it also has native integrations with a bunch of areas native services for",
    "start": "1032970",
    "end": "1038339"
  },
  {
    "text": "example claw wash locks which means you can hook up a file host a river stream with car wash logs to pipe your V PC",
    "start": "1038339",
    "end": "1044970"
  },
  {
    "text": "flow log it abbis lambda log or any of the log that we ingest in the carwash log in real time into the service we",
    "start": "1044970",
    "end": "1052500"
  },
  {
    "text": "have integration with cloud watch events and a dance service has a lot of interesting changing events generated by",
    "start": "1052500",
    "end": "1058650"
  },
  {
    "text": "a river service including cloud trail easy to change events s3 events you can also hook up a cloud watch event topic",
    "start": "1058650",
    "end": "1065820"
  },
  {
    "text": "with the fire hose from the console with a few clicks you can stream these cloud trail data for example into fire hose in",
    "start": "1065820",
    "end": "1072600"
  },
  {
    "text": "real time we also have integration with Erebus IOT for those of you guys have",
    "start": "1072600",
    "end": "1077910"
  },
  {
    "text": "out to use case it abyss out is integrated with Kinesis fire hose directly so you can have your out a",
    "start": "1077910",
    "end": "1083460"
  },
  {
    "text": "device using MQTT protocol super efficient for low compute devices to",
    "start": "1083460",
    "end": "1088500"
  },
  {
    "text": "talk to the alw service a double tees service to get data off your IOT device",
    "start": "1088500",
    "end": "1093690"
  },
  {
    "text": "in real time push that into Kinesis fire hose and i believe last week database LT",
    "start": "1093690",
    "end": "1100470"
  },
  {
    "text": "just announced the new pricing model so in the case when you just use MQTT protocol to push data for IOT - Kinesis",
    "start": "1100470",
    "end": "1107610"
  },
  {
    "text": "fire hose you pay a much lower cost than you used to do so super exciting the",
    "start": "1107610",
    "end": "1112890"
  },
  {
    "text": "middle level it's a transformation feature so a lot of the time the data is generating a raw format it's not",
    "start": "1112890",
    "end": "1118710"
  },
  {
    "text": "suitable for analysis out of box but people don't want to have a multiple stage layer for you to get the data into",
    "start": "1118710",
    "end": "1125430"
  },
  {
    "text": "the system have another system to do transformation and another system to the analysis so fire hose is integrated with",
    "start": "1125430",
    "end": "1132600"
  },
  {
    "text": "AWS lambda for you to specify a custom function to the data transformation on",
    "start": "1132600",
    "end": "1138750"
  },
  {
    "text": "the fly as the data is transferred through the fire hose service so you have a surveillance pipeline to the",
    "start": "1138750",
    "end": "1144900"
  },
  {
    "text": "ingestion transformation and and deliveries last piece as I mentioned",
    "start": "1144900",
    "end": "1150250"
  },
  {
    "text": "we star the service with s3 and redshift as the supported destination we added",
    "start": "1150250",
    "end": "1156130"
  },
  {
    "text": "last search later on and you probably have guessed and today we are I'm super excited to announce that actually Splunk",
    "start": "1156130",
    "end": "1164500"
  },
  {
    "text": "is going to be added as an addition to this graph so we heard a lot from our",
    "start": "1164500",
    "end": "1170440"
  },
  {
    "text": "customers since we shipped the firehose service they would like to use Splunk because spelunk is super popular and",
    "start": "1170440",
    "end": "1176410"
  },
  {
    "text": "super easy to use tor free to analyze a lot of the machine generated data so we heard from our customers saying we want",
    "start": "1176410",
    "end": "1183070"
  },
  {
    "text": "to use this blanc can you guys supports Blanc as a delivery destination we also want to take advantage of the real-time",
    "start": "1183070",
    "end": "1188440"
  },
  {
    "text": "ingestion capability from fire hose so we started a conversation with Team",
    "start": "1188440",
    "end": "1193960"
  },
  {
    "text": "Splunk and they also heard a lot of feedback from their customers because we have a lot of the shared customer base",
    "start": "1193960",
    "end": "1199660"
  },
  {
    "text": "they're looking for a reliable ingestion solution to get their into sprung so we thought it made a lot of sense for us to",
    "start": "1199660",
    "end": "1206380"
  },
  {
    "text": "do a solution to do an integration between fire hose and Splunk service so we started working on this project and a",
    "start": "1206380",
    "end": "1212500"
  },
  {
    "text": "few month back we announced a better program for this integration as spunks Blanc's comm conference and it was super",
    "start": "1212500",
    "end": "1219610"
  },
  {
    "text": "well-received we got a lot of better customers sign up helped us testing and a database ring then this week this",
    "start": "1219610",
    "end": "1225850"
  },
  {
    "text": "featuresnow general available so if you go to Erebus console go to the Kinesis firehose service console now you can see",
    "start": "1225850",
    "end": "1232120"
  },
  {
    "text": "a drop down with Splunk as an addition and to get data from firehose in Chris Blanc in real time so why is this",
    "start": "1232120",
    "end": "1239410"
  },
  {
    "text": "important and how does that solve the problem Ellis just mentioned previously",
    "start": "1239410",
    "end": "1245580"
  },
  {
    "start": "1243000",
    "end": "1413000"
  },
  {
    "text": "reliability scalability and fault-tolerance as I mentioned the entire idea of Kinesis service including",
    "start": "1245580",
    "end": "1252400"
  },
  {
    "text": "fire hose is built based on the need of Erebus metering so it has to be highly available reliable and scalable to",
    "start": "1252400",
    "end": "1260170"
  },
  {
    "text": "handle all these mission-critical data to run the entire AWS cloud so fire hose",
    "start": "1260170",
    "end": "1265840"
  },
  {
    "text": "has that capability for all the data we receive from you whatever data source or",
    "start": "1265840",
    "end": "1271060"
  },
  {
    "text": "your service or mobile devices we automatically backup your data across three different AZ's data centers and we",
    "start": "1271060",
    "end": "1277990"
  },
  {
    "text": "very simple we just don't lose any custom data and since we started service from",
    "start": "1277990",
    "end": "1283390"
  },
  {
    "text": "three and a half years ago since I joined the company we did not lose a single part of customer data so once we",
    "start": "1283390",
    "end": "1288970"
  },
  {
    "text": "send the data into the Kinesis service we don't lose it we terribly store that SiC and its management overhead for data",
    "start": "1288970",
    "end": "1296110"
  },
  {
    "text": "collection notes like oftentimes gotta have to run an ingestion fleet to handle data warning from different places as",
    "start": "1296110",
    "end": "1301659"
  },
  {
    "text": "you skill that you have to figure out a way to add instance at a storage nodes add memory it's super painful not",
    "start": "1301659",
    "end": "1308289"
  },
  {
    "text": "cost-effective because you have to plan for the peak and over-provisioning for structure but again as I mention I",
    "start": "1308289",
    "end": "1314140"
  },
  {
    "text": "mentioned a file is completed survey list and you do not need to think about any resource and the pricing model is",
    "start": "1314140",
    "end": "1319840"
  },
  {
    "text": "completely elastic so you will not overpay because you need to provision for the peak there's nothing like that",
    "start": "1319840",
    "end": "1326429"
  },
  {
    "text": "also delayed event delivery due to probe a suggestion so from firehose we use a",
    "start": "1326429",
    "end": "1332020"
  },
  {
    "text": "push mechanism leveraging Splunk HTTP event collector so we actually use in pushing based mechanism to get data into",
    "start": "1332020",
    "end": "1339250"
  },
  {
    "text": "Splunk and we also have a data backup feature so for any case when the network",
    "start": "1339250",
    "end": "1344260"
  },
  {
    "text": "has a disruption or you are doing maintenance on a splint cluster or you're resizing a splint cluster we can",
    "start": "1344260",
    "end": "1350710"
  },
  {
    "text": "durably backup the data into an s3 bucket at your own so that later on you can backfill again that's for high",
    "start": "1350710",
    "end": "1357700"
  },
  {
    "text": "availability and data durability and also if you are throttling the reasons",
    "start": "1357700",
    "end": "1362860"
  },
  {
    "text": "because you know using Poe based mechanism with Splunk add-on to get data from aw services into the sprung cluster",
    "start": "1362860",
    "end": "1370240"
  },
  {
    "text": "a lot of time you have thought on a limit to get it out of these service in the case of firehose we use a push based",
    "start": "1370240",
    "end": "1376870"
  },
  {
    "text": "Mechelen so you no longer need to worry about that because we deal with these throttling mechanisms by direct",
    "start": "1376870",
    "end": "1382299"
  },
  {
    "text": "integration between firehose and all these other AWS services and down the road you should expect to see a lot more",
    "start": "1382299",
    "end": "1388210"
  },
  {
    "text": "direct integration of various service laws including any other data with Kinesis firehose out of the box so you",
    "start": "1388210",
    "end": "1395230"
  },
  {
    "text": "can just wire in a database log data or server event data you want to analyze including metric data you want to",
    "start": "1395230",
    "end": "1402490"
  },
  {
    "text": "analyze using Splunk you can just go to file is console and hook them up it'll probably take like a few minutes then",
    "start": "1402490",
    "end": "1408190"
  },
  {
    "text": "you have the real-time pipeline running so that given said I'm super excited",
    "start": "1408190",
    "end": "1415179"
  },
  {
    "start": "1413000",
    "end": "1462000"
  },
  {
    "text": "about it and since you guys you know most of you guys have heard of Kinesis highly encourage you guys you know after",
    "start": "1415179",
    "end": "1421179"
  },
  {
    "text": "this talk when you get a chance go ahead and log on to the and Kinesis files console in heck token is plant cluster",
    "start": "1421179",
    "end": "1428200"
  },
  {
    "text": "try to ingest a few events from the delivery stream from fire hose into spunk and see these data in motion",
    "start": "1428200",
    "end": "1435279"
  },
  {
    "text": "leveraging splints real-time dashboard and search capability leveraging Kinesis firehose real-time ingestion capability",
    "start": "1435279",
    "end": "1442990"
  },
  {
    "text": "with fault tolerance and reliability to see like what are the powerful tools and capabilities these two services can",
    "start": "1442990",
    "end": "1449679"
  },
  {
    "text": "bring turn to you guys together so given that I'll hand it back to alias to talk",
    "start": "1449679",
    "end": "1454809"
  },
  {
    "text": "a little bit about the advantage for using Kinesis firehose so in summary why",
    "start": "1454809",
    "end": "1471039"
  },
  {
    "start": "1462000",
    "end": "1571000"
  },
  {
    "text": "use Kinesis fire hose with Splunk it's fully managed so you don't have to manage your data collection fleet you",
    "start": "1471039",
    "end": "1476409"
  },
  {
    "text": "don't have to manage your data collection node one cool thing about this integration is that it bypasses it",
    "start": "1476409",
    "end": "1482139"
  },
  {
    "text": "simplifies the architecture basically it bypasses the need to have heavyweight forward here in the middle so that's",
    "start": "1482139",
    "end": "1488620"
  },
  {
    "text": "that's still an option for you if you for various architectural consideration however this is not really required",
    "start": "1488620",
    "end": "1495120"
  },
  {
    "text": "anymore so you can stream the data directly from the AWS console straight",
    "start": "1495120",
    "end": "1500379"
  },
  {
    "text": "into your Splunk indexer it has greater reliability Glitter greater scalability",
    "start": "1500379",
    "end": "1507399"
  },
  {
    "text": "as well of course just like we mentioned early on it's well integrated with various native AWS sources whether it's",
    "start": "1507399",
    "end": "1514269"
  },
  {
    "text": "cloud watch event cloud watch logs VPC flow logs and Kinesis an AWS iot so",
    "start": "1514269",
    "end": "1521259"
  },
  {
    "text": "these are native pretty much integrations you don't need to do any",
    "start": "1521259",
    "end": "1526960"
  },
  {
    "text": "programming and write any code it's pretty it's pretty much out of the box all you have to do is take the HP event",
    "start": "1526960",
    "end": "1533889"
  },
  {
    "text": "collector IP address and the token paste it on the AWS console pretty straightforward and off you go",
    "start": "1533889",
    "end": "1540129"
  },
  {
    "text": "with streaming the data directly to Splunk it also has the ability to extend",
    "start": "1540129",
    "end": "1546259"
  },
  {
    "text": "and transform the data so you can invoke lamda on any data that you're streaming",
    "start": "1546259",
    "end": "1552409"
  },
  {
    "text": "to Splunk a good use case for this if you want to normalize the data before you index it that's one option that you",
    "start": "1552409",
    "end": "1558200"
  },
  {
    "text": "have for you it's relatively low cost this is what you see on the screen is I",
    "start": "1558200",
    "end": "1563360"
  },
  {
    "text": "think the higher tier there's different tiers but in general is it's low cost for ingesting that data into Splunk so",
    "start": "1563360",
    "end": "1571940"
  },
  {
    "start": "1571000",
    "end": "1698000"
  },
  {
    "text": "let's talk a little bit more about the architecture how does it work so under on the left hand side you have",
    "start": "1571940",
    "end": "1578480"
  },
  {
    "text": "the AWS side you have the middle the AWS console Canisius firehose has native",
    "start": "1578480",
    "end": "1583519"
  },
  {
    "text": "integration with cloud watch logs cloud watch a fence and aw yes IOT as of today there could be more in the future",
    "start": "1583519",
    "end": "1589759"
  },
  {
    "text": "something rake in covering if you have any questions however this architecture is scalable it",
    "start": "1589759",
    "end": "1595759"
  },
  {
    "text": "does load balance the data typically you would want to put a load balance in the middle between your AWS environment and",
    "start": "1595759",
    "end": "1603559"
  },
  {
    "text": "Splunk basically you put a load balancer right in front of your indexer as I mentioned early on this is a simplified",
    "start": "1603559",
    "end": "1610159"
  },
  {
    "text": "architecture doesn't mean that this is the only architecture that we support so you would load balanced the data to your",
    "start": "1610159",
    "end": "1616309"
  },
  {
    "text": "index or tier directly one powerful thing about this architecture is that it",
    "start": "1616309",
    "end": "1622429"
  },
  {
    "text": "leverages HTTP Event collector index or acknowledgement so for those of you who are not familiar with HP event collector",
    "start": "1622429",
    "end": "1629080"
  },
  {
    "text": "it's an HTTP listener that Splunk provides you it's highly scalable highly",
    "start": "1629080",
    "end": "1634340"
  },
  {
    "text": "available it's basically listening on HTTP port waiting for events to come in",
    "start": "1634340",
    "end": "1639940"
  },
  {
    "text": "AWS fire hose directly stream to your HP event collector if you want to scale out you can add as many HP Event collector",
    "start": "1639940",
    "end": "1646639"
  },
  {
    "text": "nodes as you need as long as you put that load balancer in front one thing",
    "start": "1646639",
    "end": "1652039"
  },
  {
    "text": "also worth mentioning HP event collector has index or acknowledgment what this means is that within firehose when you",
    "start": "1652039",
    "end": "1660379"
  },
  {
    "text": "send the data if let's say let's say the data didn't get indexed firehose checks",
    "start": "1660379",
    "end": "1667309"
  },
  {
    "text": "that the data is indexed and if it didn't get indexed it can write it to s3 bucket and we'll talk a little bit more about that but basically you're doing",
    "start": "1667309",
    "end": "1673690"
  },
  {
    "text": "guaranteed delivery by leveraging that integration and leveraging the indexer",
    "start": "1673690",
    "end": "1679440"
  },
  {
    "text": "acknowledgement so this is if you want",
    "start": "1679440",
    "end": "1687779"
  },
  {
    "text": "to scale out how you do it you add as many indexer and as many cheap and collector nodes and you put a load",
    "start": "1687779",
    "end": "1694830"
  },
  {
    "text": "balancer in the middle how do you achieve reliability like I said the once",
    "start": "1694830",
    "end": "1704429"
  },
  {
    "start": "1698000",
    "end": "1825000"
  },
  {
    "text": "if let's say it's fire hose streaming the data you have some network outage or you have slunk is not reachable for one",
    "start": "1704429",
    "end": "1710730"
  },
  {
    "text": "reason or the other fire hose buffers the data for a certain amount of time until eventually if the ifs Punk is",
    "start": "1710730",
    "end": "1717960"
  },
  {
    "text": "still not reachable you can persist the data on to s3 so it has back pressure relief to start",
    "start": "1717960",
    "end": "1725429"
  },
  {
    "text": "persisting the data into an s3 bucket that you can configure as part of your configuration process now once there is",
    "start": "1725429",
    "end": "1732840"
  },
  {
    "text": "an s3 you have various mechanism to get it back into Splunk one mechanism is to",
    "start": "1732840",
    "end": "1739230"
  },
  {
    "text": "use a hybrid portion pool mechanism so what this means is that you can use the",
    "start": "1739230",
    "end": "1745529"
  },
  {
    "text": "AWS add-on to ingest that data directly back from s3 from that bucket that you configured for the failed event so that",
    "start": "1745529",
    "end": "1752399"
  },
  {
    "text": "means you have hybrid architecture and it is less prone for failure because now",
    "start": "1752399",
    "end": "1759630"
  },
  {
    "text": "you're having hybrid push and pull the",
    "start": "1759630",
    "end": "1765600"
  },
  {
    "text": "other alternative to this is once the data entry you can use a purely server",
    "start": "1765600",
    "end": "1771059"
  },
  {
    "text": "less architecture as opposed to using the add-on to ingest or pull the data from the s3 bucket you can leverage",
    "start": "1771059",
    "end": "1777330"
  },
  {
    "text": "lambda to stream the data directly from s3 as soon as the risk as soon as s3",
    "start": "1777330",
    "end": "1783149"
  },
  {
    "text": "receives those event into a cheap event collector obviously because you have basically",
    "start": "1783149",
    "end": "1788880"
  },
  {
    "text": "both push mechanism directly from firehose and s3 you might want to",
    "start": "1788880",
    "end": "1794309"
  },
  {
    "text": "configure your lambda to stream the data into ibaka backup spunky environment because you",
    "start": "1794309",
    "end": "1800820"
  },
  {
    "text": "don't want to overload your spunky environment if there's a failure or there's a network outage so it makes",
    "start": "1800820",
    "end": "1806940"
  },
  {
    "text": "sense to get the data from s3 into a separate Splunk cluster but in this architecture is purely",
    "start": "1806940",
    "end": "1814120"
  },
  {
    "text": "serverless you don't need to have heavyweight folder in the middle so that's an option that's a consideration that you can have based on your",
    "start": "1814120",
    "end": "1820750"
  },
  {
    "text": "requirement very popular we've had what",
    "start": "1820750",
    "end": "1829180"
  },
  {
    "start": "1825000",
    "end": "1959000"
  },
  {
    "text": "a decent amount of customers who were part of our beta program and this is pretty much a request that we get we got",
    "start": "1829180",
    "end": "1836230"
  },
  {
    "text": "from everyone and we get every day from a data ingestion perspective into Splunk",
    "start": "1836230",
    "end": "1841960"
  },
  {
    "text": "a very popular request a lot of you a lot of customers want to ingest data",
    "start": "1841960",
    "end": "1847840"
  },
  {
    "text": "from from multiple AWS accounts and this is this is basically the power of Splunk",
    "start": "1847840",
    "end": "1854230"
  },
  {
    "text": "the ability to get inside into data sources across broad range of AWS",
    "start": "1854230",
    "end": "1860080"
  },
  {
    "text": "account so in this slide here you have EPC flow logs as an example what doesn't",
    "start": "1860080",
    "end": "1865750"
  },
  {
    "text": "have to apply for VPC flow logs it can apply to cloud watch events and others but the idea here is that you want to",
    "start": "1865750",
    "end": "1872200"
  },
  {
    "text": "ingest from multiple AWS account but you don't want to necessarily configure firehose from each individual one you",
    "start": "1872200",
    "end": "1877990"
  },
  {
    "text": "don't want to go through the management overhead of configure a firehose on each individual individual account so in this",
    "start": "1877990",
    "end": "1886150"
  },
  {
    "text": "case you cloud watch logs natively has the ability to consolidate into one",
    "start": "1886150",
    "end": "1891220"
  },
  {
    "text": "account so you stream the data from cloud wash logs into one single account",
    "start": "1891220",
    "end": "1896620"
  },
  {
    "text": "and then from there you want to get the data into spunk using one Kinichi stream but here lies the challenge is that most",
    "start": "1896620",
    "end": "1902860"
  },
  {
    "text": "of the use cases that we've seen with customers rely on the fact that you want to control access you want to have",
    "start": "1902860",
    "end": "1909880"
  },
  {
    "text": "access control over the data you don't want to give access to account Bay a if",
    "start": "1909880",
    "end": "1916660"
  },
  {
    "text": "there is coming from account a you don't want to give access to that data to the users for account B so obviously here",
    "start": "1916660",
    "end": "1923530"
  },
  {
    "text": "you want to resell get the data in Splunk typically the way you do it in Splunk is segregate the data based on",
    "start": "1923530",
    "end": "1928750"
  },
  {
    "text": "index and this is where you can leverage the power of lambda transformation where",
    "start": "1928750",
    "end": "1934330"
  },
  {
    "text": "you can put conditions to override the index before you send it to Splunk so in",
    "start": "1934330",
    "end": "1939670"
  },
  {
    "text": "this case every account data would get segregated and go in two separate index and then from",
    "start": "1939670",
    "end": "1946149"
  },
  {
    "text": "there you can do the access control and you can build your data retention",
    "start": "1946149",
    "end": "1951760"
  },
  {
    "text": "policies based on the various indexes that you have so in summary this is our",
    "start": "1951760",
    "end": "1961450"
  },
  {
    "start": "1959000",
    "end": "2000000"
  },
  {
    "text": "new landscape you still have the various mechanism we've enriched it with Kinesis firehose you still have you can still",
    "start": "1961450",
    "end": "1969490"
  },
  {
    "text": "use the AWS add-on for ingesting data from s3 and the soup and the the AWS",
    "start": "1969490",
    "end": "1974590"
  },
  {
    "text": "services that are not supported by a firehose you still have the option to go push and pull we give you that",
    "start": "1974590",
    "end": "1979690"
  },
  {
    "text": "flexibility to architect your Splunk deployment and your data ingestion based on your needs and your own requirements",
    "start": "1979690",
    "end": "1986159"
  },
  {
    "text": "but we we have a very broad and rich data ingestion mechanism today and with",
    "start": "1986159",
    "end": "1992169"
  },
  {
    "text": "firehose you have very powerful scalable capabilities as well before I hand it",
    "start": "1992169",
    "end": "2002039"
  },
  {
    "start": "2000000",
    "end": "2039000"
  },
  {
    "text": "over to Steven worth mentioning today if you want to this is generally available so feel free to try it out it's",
    "start": "2002039",
    "end": "2009000"
  },
  {
    "text": "available on the AWS console on the Splunk site it is available for spun cloud and small enterprise everything is",
    "start": "2009000",
    "end": "2015529"
  },
  {
    "text": "available you can also download the Splunk add-on for Canisius firehose to apply knowledge on the data that you",
    "start": "2015529",
    "end": "2022169"
  },
  {
    "text": "ingest from Canisius firehose feel free to download it from spawn base as well",
    "start": "2022169",
    "end": "2027179"
  },
  {
    "text": "so and we have a demo booth if you want to check us out so with that I'll hand it over to Steven to talk about some",
    "start": "2027179",
    "end": "2033419"
  },
  {
    "text": "exciting use cases",
    "start": "2033419",
    "end": "2036259"
  },
  {
    "start": "2039000",
    "end": "2064000"
  },
  {
    "text": "good afternoon all right how you doing my name is Stephen hatch I'm from Cox automotive",
    "start": "2041150",
    "end": "2047220"
  },
  {
    "text": "based out of Atlanta Georgia I see a lot of folks here from my COTS automotive folks from EarthLink from 12 years ago",
    "start": "2047220",
    "end": "2054840"
  },
  {
    "text": "I see I'm very honored to be here today to speak at the a Jeb us reinvent",
    "start": "2054840",
    "end": "2061230"
  },
  {
    "text": "conference of 2017 I would like to thank",
    "start": "2061230",
    "end": "2067230"
  },
  {
    "start": "2064000",
    "end": "2132000"
  },
  {
    "text": "Splunk for this big picture of my dome there there's a there's a there's some",
    "start": "2067230",
    "end": "2074310"
  },
  {
    "text": "context to this picture my boss is also in the crowd we it was my idea actually to get a video success",
    "start": "2074310",
    "end": "2080760"
  },
  {
    "text": "story on a use case of Splunk what I didn't realize is the cameras that Splunk brought also how the 4k cameras",
    "start": "2080760",
    "end": "2089460"
  },
  {
    "text": "would pick up every little subtle sound so unfortunately in the middle of June",
    "start": "2089460",
    "end": "2094620"
  },
  {
    "text": "in Hotlanta it was 96 degrees and we had to turn air conditioners off because they were too loud so what you don't see",
    "start": "2094620",
    "end": "2101070"
  },
  {
    "text": "unless you zoom in there's a bead to sweat the top of that dome there and just to let you know and course that",
    "start": "2101070",
    "end": "2107340"
  },
  {
    "text": "blue long-sleeve fleece that I decided to wear it could someone told me that it pops when you're taking a video or",
    "start": "2107340",
    "end": "2114630"
  },
  {
    "text": "pictures but that's just to give you some context there so that smile you'll see that's really please let's get this",
    "start": "2114630",
    "end": "2120780"
  },
  {
    "text": "right alright so as you see there 20 years of IT experience I am the manager",
    "start": "2120780",
    "end": "2126900"
  },
  {
    "text": "of the enterprise logging services group at Cox Automotive the metrics you see",
    "start": "2126900",
    "end": "2134220"
  },
  {
    "start": "2132000",
    "end": "2162000"
  },
  {
    "text": "there on the bottom cuts out a mode of 24,000 employees worldwide they are not",
    "start": "2134220",
    "end": "2139740"
  },
  {
    "text": "all here today you see the 40,000 sales and all the way across but the biggest",
    "start": "2139740",
    "end": "2145500"
  },
  {
    "text": "number there is the far right is that 67% of all car buyers so basically",
    "start": "2145500",
    "end": "2150870"
  },
  {
    "text": "you've seen the commercials for all eternity Auto Trader in Kelly Blue Book so for any cars that are pretty much",
    "start": "2150870",
    "end": "2156360"
  },
  {
    "text": "bought 2/3 leverage our services it's an impressive number and the vision of Cox",
    "start": "2156360",
    "end": "2163830"
  },
  {
    "start": "2162000",
    "end": "2172000"
  },
  {
    "text": "automotive is to transform the way the world buys sells and old cars all right",
    "start": "2163830",
    "end": "2169680"
  },
  {
    "text": "here we go so this slide here it represents the",
    "start": "2169680",
    "end": "2175340"
  },
  {
    "start": "2172000",
    "end": "2215000"
  },
  {
    "text": "lifecycle of a car as the manufacturers our domestic and international produce",
    "start": "2175340",
    "end": "2180680"
  },
  {
    "text": "the cars they're then distributed to the dealers to be sold Cox automotive had a",
    "start": "2180680",
    "end": "2186590"
  },
  {
    "text": "vision that vision is well why not own the entire lifecycle well how do we do",
    "start": "2186590",
    "end": "2191600"
  },
  {
    "text": "that well let's go ahead and find the services either by way of homegrown or",
    "start": "2191600",
    "end": "2196820"
  },
  {
    "text": "acquisition or merger we teamed it with all these different companies to produce",
    "start": "2196820",
    "end": "2202100"
  },
  {
    "text": "his entire lifecycle so whether you're on the right hemisphere there with the dealers or the left hemisphere the",
    "start": "2202100",
    "end": "2207950"
  },
  {
    "text": "consumers we pretty much have a service for every facet of this lifecycle so as",
    "start": "2207950",
    "end": "2217790"
  },
  {
    "start": "2215000",
    "end": "2263000"
  },
  {
    "text": "part of this use case I want to talk to you about Mannheim specifically Mannheim is the auto auction company across the",
    "start": "2217790",
    "end": "2225170"
  },
  {
    "text": "United States 84 plus locations that facilitates the cells of dealer to",
    "start": "2225170",
    "end": "2230240"
  },
  {
    "text": "dealer auctions it's a little different than a consumer type that we can go to this is again dealer to dealer so this",
    "start": "2230240",
    "end": "2237680"
  },
  {
    "text": "is the arm auction in the bay area off of 884 it those that are aware eight",
    "start": "2237680",
    "end": "2243740"
  },
  {
    "text": "lanes that are basically going in parallel all makes all models people are",
    "start": "2243740",
    "end": "2249350"
  },
  {
    "text": "there to physically kick and touch the tires make sure that's exactly the car they want to fulfill their demands some",
    "start": "2249350",
    "end": "2255980"
  },
  {
    "text": "have a surplus of this and a lack of that so there that's why they're there they're here to trade their inventories",
    "start": "2255980",
    "end": "2263110"
  },
  {
    "start": "2263000",
    "end": "2300000"
  },
  {
    "text": "as we go into the lanes you'll see there are people in action and if I slip to the next one there it is this is the",
    "start": "2263110",
    "end": "2269900"
  },
  {
    "text": "inside view of again one of many auctions we have some as many as 32 lanes to happen in parallel so again",
    "start": "2269900",
    "end": "2278990"
  },
  {
    "text": "they're guys they're now armed in the lanes you see the silver card on the left the hood is actually ajar if you",
    "start": "2278990",
    "end": "2285020"
  },
  {
    "text": "will because some people actually go up there lift the hood to actually look to see if there's any oil league's transmission league's power steering all",
    "start": "2285020",
    "end": "2291290"
  },
  {
    "text": "that kind of stuff they're pretty thorough well what I want you to pay attention to is what's on that wall",
    "start": "2291290",
    "end": "2297560"
  },
  {
    "text": "there that TV screen that TV screen depicts the actual car that's in lane",
    "start": "2297560",
    "end": "2305030"
  },
  {
    "start": "2300000",
    "end": "2364000"
  },
  {
    "text": "right now being off and off and all the different makes models the year the van all I could",
    "start": "2305030",
    "end": "2310230"
  },
  {
    "text": "stuff but there's a key metric on this slide that makes this thing really",
    "start": "2310230",
    "end": "2316670"
  },
  {
    "text": "exciting is the number of online bidders that means for this particular Lane this",
    "start": "2316670",
    "end": "2323760"
  },
  {
    "text": "particular auction for this particular car there are 12 people somewhere on the",
    "start": "2323760",
    "end": "2329550"
  },
  {
    "text": "internet also bidding in real time for this particular Volvo all right so you",
    "start": "2329550",
    "end": "2336119"
  },
  {
    "text": "see the three guys there on the bottom the guy on the left that is what we call the clerk he's a guy that ups the price",
    "start": "2336119",
    "end": "2342750"
  },
  {
    "text": "every time the oxygenator goes to his audible the auctioneers in the middle the guy will be the dome that's the",
    "start": "2342750",
    "end": "2350609"
  },
  {
    "text": "actual dealer or the representative a dealer with the pink slips in hand so that's why he has most concerned look",
    "start": "2350609",
    "end": "2356609"
  },
  {
    "text": "because he want to make sure not only do all his car sell but for the price that he wants right because he has to make",
    "start": "2356609",
    "end": "2361829"
  },
  {
    "text": "his money so to make that happen there are gentlemen in this room that",
    "start": "2361829",
    "end": "2368430"
  },
  {
    "start": "2364000",
    "end": "2392000"
  },
  {
    "text": "helped set up this infrastructure we have high-definition cameras for every lane across all of our auctions so",
    "start": "2368430",
    "end": "2375119"
  },
  {
    "text": "basically we throw back all the way to our data centers and mirror that up with the data that we had those metrics so",
    "start": "2375119",
    "end": "2382410"
  },
  {
    "text": "that the users by way their cell phone their smart devices the laptops and desktops can bid against the people in",
    "start": "2382410",
    "end": "2388290"
  },
  {
    "text": "real-time for these cars all right so now with all that being said I want you",
    "start": "2388290",
    "end": "2395099"
  },
  {
    "start": "2392000",
    "end": "2489000"
  },
  {
    "text": "to pretend this is a AWS lab real quick I need you put your scripting hats on",
    "start": "2395099",
    "end": "2401480"
  },
  {
    "text": "audio video network gear and monitoring you're now being tasked to monitor the",
    "start": "2401480",
    "end": "2409650"
  },
  {
    "text": "health and wellness of this system so let's start off small let's just talk about one lane so first the component is",
    "start": "2409650",
    "end": "2417060"
  },
  {
    "text": "the users that want to connect by way the internet to connect to the stream that string could be a data center or",
    "start": "2417060",
    "end": "2423930"
  },
  {
    "text": "can be an AWS other other hand again it's that single lane we have to keep in",
    "start": "2423930",
    "end": "2429780"
  },
  {
    "text": "mind and taking consideration the audio and video the metrics that are coming",
    "start": "2429780",
    "end": "2435119"
  },
  {
    "text": "back and forth when the oxygenator is up ending in crimp incrementing the price all right",
    "start": "2435119",
    "end": "2440670"
  },
  {
    "text": "all that get smeared up in real time for the people to leverage and make a sound decision on buying that car we need to",
    "start": "2440670",
    "end": "2447299"
  },
  {
    "text": "protect that so I need you to write a script whatever tool whatever language whatever service to make sure that that",
    "start": "2447299",
    "end": "2454530"
  },
  {
    "text": "system right there stays up is that too big of a deal for some of you is it",
    "start": "2454530",
    "end": "2460230"
  },
  {
    "text": "probably there's rules simple simple script what if I ask you to expand that",
    "start": "2460230",
    "end": "2465540"
  },
  {
    "text": "to three lanes all right for loop array whatever case right not a big deal but remember I need you to own this for a",
    "start": "2465540",
    "end": "2471750"
  },
  {
    "text": "little while as a as a prototype to see if this thing works we just go by ideas go by it works out pretty well the way",
    "start": "2471750",
    "end": "2480119"
  },
  {
    "text": "things work people say you know what I heard this guy wrote the script and he's protecting three of your lanes I want",
    "start": "2480119",
    "end": "2485460"
  },
  {
    "text": "the same thing because remember I have 84 options to consider so now let's say",
    "start": "2485460",
    "end": "2493200"
  },
  {
    "start": "2489000",
    "end": "2556000"
  },
  {
    "text": "you're based in Atlanta Georgia your script is getting more and more press not only is it now monitoring all the",
    "start": "2493200",
    "end": "2499859"
  },
  {
    "text": "lanes at a particular auction the whole East Coast wants it alright you expanding your script some more you get",
    "start": "2499859",
    "end": "2506069"
  },
  {
    "text": "some more resilience to get in there a little bit more efficient and it's working great remember you need to own",
    "start": "2506069",
    "end": "2511859"
  },
  {
    "text": "this 9 to 5 sales you know starting close I need you to be aware of it well",
    "start": "2511859",
    "end": "2518790"
  },
  {
    "text": "guess what the folks in the Midwest hear about it the folks on the west coast hear about it so remember I need you to",
    "start": "2518790",
    "end": "2526770"
  },
  {
    "text": "own it 9:00 to 5:00 and the west coast is what time on the East Coast 8:00 p.m.",
    "start": "2526770",
    "end": "2533069"
  },
  {
    "text": "I need your onus all you can stay around to 8:00 p.m. every day five days a week for every oxygen for every Lane maybe",
    "start": "2533069",
    "end": "2541049"
  },
  {
    "text": "four oxygens they say eight lanes per that's a lot for you to be responsible for so I'm thinking you're gonna be",
    "start": "2541049",
    "end": "2547260"
  },
  {
    "text": "smart you want to leverage an application of some sort to do all this automation for you and so maybe by some",
    "start": "2547260",
    "end": "2553559"
  },
  {
    "text": "third-party app and it worked out okay so whatever the the visualization is",
    "start": "2553559",
    "end": "2558990"
  },
  {
    "text": "that this third-party I provided you leverage for a while but over time it still became too overwhelming so then",
    "start": "2558990",
    "end": "2567240"
  },
  {
    "start": "2566000",
    "end": "2681000"
  },
  {
    "text": "you know what because this app maybe it did work but I need someone to",
    "start": "2567240",
    "end": "2572390"
  },
  {
    "text": "handle all the influxes coming my way because remember I got to protect cameras I got to protect microphone",
    "start": "2572390",
    "end": "2579559"
  },
  {
    "text": "audio I got to protect a specific switch for a specific auction that represents a",
    "start": "2579559",
    "end": "2584930"
  },
  {
    "text": "specific lane and then at the same time I'll need to give specific ammunition to",
    "start": "2584930",
    "end": "2590269"
  },
  {
    "text": "a network operation center exactly what the problem is I can't just simply say simulcast is down I need more",
    "start": "2590269",
    "end": "2598309"
  },
  {
    "text": "information than that which auction which lane which component what is down",
    "start": "2598309",
    "end": "2604099"
  },
  {
    "text": "talk to me describe use your words right well because of the app that you did",
    "start": "2604099",
    "end": "2611240"
  },
  {
    "text": "maybe it is giving you this information but it's given me too much at the same time so if say Pennsylvania goes down",
    "start": "2611240",
    "end": "2619640"
  },
  {
    "text": "because their internet pipe went down does that mean the cameras down is the lane down no the internet pipe that",
    "start": "2619640",
    "end": "2626900"
  },
  {
    "text": "allows the traffic come all back and mirror up the data that's been broken so the people on side they don't know it",
    "start": "2626900",
    "end": "2633200"
  },
  {
    "text": "and frankly they don't care especially the guys there in lane because that's less competition we got to worry about for that period of time whoever gets cut",
    "start": "2633200",
    "end": "2640700"
  },
  {
    "text": "off on the internet yes we don't make the money we want but the guys that the oxen are actually kind of happy about for a period of time so all this needs",
    "start": "2640700",
    "end": "2648500"
  },
  {
    "text": "to be protected monitored and accurately if you will demonstrate it to the not to",
    "start": "2648500",
    "end": "2656329"
  },
  {
    "text": "say you little I need to know exact what's going on so that way I'm getting the right people engaged if I tell the",
    "start": "2656329",
    "end": "2661369"
  },
  {
    "text": "guy to run up and down 32 lanes to check his cameras and it's just one lane that's down that's not efficient if all",
    "start": "2661369",
    "end": "2668180"
  },
  {
    "text": "the lanes are up but it's the internet pipe I need to tell him to call or the network team to call the service provider not to have my god running up",
    "start": "2668180",
    "end": "2674269"
  },
  {
    "text": "and down the lanes trying to fix things pulling out plugs to fix one lane now he affected another option lane so we then",
    "start": "2674269",
    "end": "2683930"
  },
  {
    "start": "2681000",
    "end": "2834000"
  },
  {
    "text": "graduate and went to Splunk because you know what let's get all this david Splunk loud let's get some more",
    "start": "2683930",
    "end": "2689170"
  },
  {
    "text": "intuitive 'no slit some more proactiveness and leverage the components of Spawn cloud as far as",
    "start": "2689170",
    "end": "2694940"
  },
  {
    "text": "ingesting all that data correlate the events making sure that I could say you know what if this a B and C happens then",
    "start": "2694940",
    "end": "2701539"
  },
  {
    "text": "I call this person if it's only B and C that I want to call this person but I'm not going to everybody for every Lane and they maybe",
    "start": "2701539",
    "end": "2708349"
  },
  {
    "text": "over time I could take advantage of the fact that I have the schedule in a database so if the auction component",
    "start": "2708349",
    "end": "2717289"
  },
  {
    "text": "goes down on the west coast and it's a Saturday am I gonna give it the same urgency if there's no sales going on or",
    "start": "2717289",
    "end": "2723859"
  },
  {
    "text": "if an auction is already concluded yes I'll notify someone but I don't need to raise as much gain until it gets closer",
    "start": "2723859",
    "end": "2730789"
  },
  {
    "text": "to that schedule and I can actually leverage time to say you know what an hour before let's get a little bit more",
    "start": "2730789",
    "end": "2736609"
  },
  {
    "text": "intent list intensify the notifications so correlation gives me those abilities and again alert routing give it to the",
    "start": "2736609",
    "end": "2743779"
  },
  {
    "text": "right person and then but when it comes down to this Splunk cloud alone or Splunk Enterprise",
    "start": "2743779",
    "end": "2750710"
  },
  {
    "text": "can't give me that type of anomaly detection that I want to look at the",
    "start": "2750710",
    "end": "2755989"
  },
  {
    "text": "data as a whole maybe there's no problems going on but there's something in the data that has changed but it has",
    "start": "2755989",
    "end": "2763519"
  },
  {
    "text": "impacted the service yet it might be right there at the threshold waiting to",
    "start": "2763519",
    "end": "2769489"
  },
  {
    "text": "raise its ugly head probably on a Wednesday at the prime time of our biggest sales and that's when we exceed",
    "start": "2769489",
    "end": "2776420"
  },
  {
    "text": "the bandwidth so that's why I'm nominally detection would be a good thing and that's why I to size the next",
    "start": "2776420",
    "end": "2782359"
  },
  {
    "text": "step the metrics that we have in here",
    "start": "2782359",
    "end": "2787549"
  },
  {
    "text": "and as you see there on the left-hand side these are the actual KPIs that we measure for the traffic that gets sent",
    "start": "2787549",
    "end": "2794599"
  },
  {
    "text": "back and so the top is your service health score and you get whether it's packet loss what you sees all over the",
    "start": "2794599",
    "end": "2801140"
  },
  {
    "text": "place a little bit jitter Audio silence flapping packet ordering all of these are metrics that represent the overall",
    "start": "2801140",
    "end": "2807440"
  },
  {
    "text": "health score so any one of these are out of norm by way of itsí and it's machine",
    "start": "2807440",
    "end": "2813619"
  },
  {
    "text": "learning and anomaly detection it can let us know that hey I'm not going to tell you which line of coal or what",
    "start": "2813619",
    "end": "2819229"
  },
  {
    "text": "exactly is wrong but I'm telling you something has changed and I can go back in time to look at all there was a",
    "start": "2819229",
    "end": "2824390"
  },
  {
    "text": "release on this time or there was a maintenance by Sprint or Centrelink of someone else let's go back and",
    "start": "2824390",
    "end": "2829549"
  },
  {
    "text": "investigate what actually changed instead of waiting for it to impact us and then again by way of the the default",
    "start": "2829549",
    "end": "2837680"
  },
  {
    "start": "2834000",
    "end": "2855000"
  },
  {
    "text": "service analyzer you can get that kind of you in that way people can see this thing all across the room understand",
    "start": "2837680",
    "end": "2843269"
  },
  {
    "text": "that red is bad and green is good and when that specific KPI is satisfied then",
    "start": "2843269",
    "end": "2850259"
  },
  {
    "text": "everything will render green and we're back to where we need to be I want to",
    "start": "2850259",
    "end": "2857339"
  },
  {
    "start": "2855000",
    "end": "2908000"
  },
  {
    "text": "pivot real quick and talk about our expansion of social service at Cox Automotive where we basically have allow",
    "start": "2857339",
    "end": "2863009"
  },
  {
    "text": "a lot of our DevOps teams to leverage Splunk small cloud specifically to help",
    "start": "2863009",
    "end": "2868799"
  },
  {
    "text": "accelerate their continuous delivery in their pipelines of getting data out so",
    "start": "2868799",
    "end": "2874289"
  },
  {
    "text": "we try to extend our service by way of github and getting a lot of our binaries",
    "start": "2874289",
    "end": "2879599"
  },
  {
    "text": "and configs out there where they can come ingest them and leverage them by way of automation and not have to worry",
    "start": "2879599",
    "end": "2885359"
  },
  {
    "text": "about submitting requests or emails and stuff like that so whatever automation they want to leverage that's their",
    "start": "2885359",
    "end": "2890519"
  },
  {
    "text": "choice by by way of revision control leveraging the deployment server or not that's their choice so however way they",
    "start": "2890519",
    "end": "2897239"
  },
  {
    "text": "want to cook their meat whatever they want to leverage a smoker of you know",
    "start": "2897239",
    "end": "2902609"
  },
  {
    "text": "the grilled charcoal would have it I can care less if they're happy I'm happy",
    "start": "2902609",
    "end": "2909170"
  },
  {
    "start": "2908000",
    "end": "3056000"
  },
  {
    "text": "I'm sooner of excellence one thing going on two and a half years now of managing",
    "start": "2909380",
    "end": "2914489"
  },
  {
    "text": "the service the one thing I would put out there for anyone that's leveraging or managing Splunk is to make sure you",
    "start": "2914489",
    "end": "2920219"
  },
  {
    "text": "build your relationships especially on an enterprise side where you don't own the storage or the virtualization you",
    "start": "2920219",
    "end": "2927299"
  },
  {
    "text": "don't own the network gear you may have different partners or business units you",
    "start": "2927299",
    "end": "2932459"
  },
  {
    "text": "may have to consider and talk to there's a lot of talking there's a lot of establishment of standards which is",
    "start": "2932459",
    "end": "2938099"
  },
  {
    "text": "basically the second bullet point you have to make sure you have something consistent out there so you can support",
    "start": "2938099",
    "end": "2943709"
  },
  {
    "text": "it if everyone runs on their own different versions and want to leverage of the deployment server in a certain",
    "start": "2943709",
    "end": "2949829"
  },
  {
    "text": "manner or want access to your deployment server you can have problems again",
    "start": "2949829",
    "end": "2954869"
  },
  {
    "text": "standardize on infrastructure one thing I love to talk about is empowering mint",
    "start": "2954869",
    "end": "2961259"
  },
  {
    "text": "by empowering my users who are my most important resource by empowering them I",
    "start": "2961259",
    "end": "2967349"
  },
  {
    "text": "get that by way of education the more I dedicate them the more they",
    "start": "2967349",
    "end": "2972450"
  },
  {
    "text": "they can be delegated to as far as knowledge managers to help my team to",
    "start": "2972450",
    "end": "2978720"
  },
  {
    "text": "get more done so the more their skill the more they're educated on proper SPO best practices tags and whatnot the",
    "start": "2978720",
    "end": "2986730"
  },
  {
    "text": "better experience it is for everybody evangelizing like I'm doing right now is to get out there and spread the word on",
    "start": "2986730",
    "end": "2993780"
  },
  {
    "text": "best practices and reiterate some of the things as far as technical debt and stuff like that to make sure people",
    "start": "2993780",
    "end": "3000079"
  },
  {
    "text": "understand that we have to protect the platform and make sure that we're all good stewards of this powerful search",
    "start": "3000079",
    "end": "3005720"
  },
  {
    "text": "tool bill for scale obviously things change and you have to make sure you're always looking over the horizon to make",
    "start": "3005720",
    "end": "3012440"
  },
  {
    "text": "sure that whatever you thought was good last year may not be good this year always go back revisit do your retro",
    "start": "3012440",
    "end": "3017810"
  },
  {
    "text": "look at everything that you set up look at your documentation how data is it and as far as your partnerships with your",
    "start": "3017810",
    "end": "3024970"
  },
  {
    "text": "resources again your virtualization team with storage teams let them know behave we forecast this so I may be a specific",
    "start": "3024970",
    "end": "3032510"
  },
  {
    "text": "number of VMs or memory or resources or storage what-have-you don't put them in the dark and then at",
    "start": "3032510",
    "end": "3037790"
  },
  {
    "text": "the same at the last minute request something and then they don't have the budget to support you and then",
    "start": "3037790",
    "end": "3043400"
  },
  {
    "text": "part of that it's just growing your business grow it market it evangelize teach be available a lot of things that",
    "start": "3043400",
    "end": "3051680"
  },
  {
    "text": "to reduce the support Splunk other than SPO so before I conclude I would like to",
    "start": "3051680",
    "end": "3060410"
  },
  {
    "start": "3056000",
    "end": "3533000"
  },
  {
    "text": "kind of talk about very briefly as far as the announcement of a Kinesis firehose we are in their beta mode right",
    "start": "3060410",
    "end": "3068060"
  },
  {
    "text": "now at Cox automotive so we have not committed to anything however in my case",
    "start": "3068060",
    "end": "3073490"
  },
  {
    "text": "probably one thing I could think of that might be a good use case of it is the devices themselves for simulcast that",
    "start": "3073490",
    "end": "3079670"
  },
  {
    "text": "might be a nice way to go directly into firehose opposer going all the way to his web server the web server rights to",
    "start": "3079670",
    "end": "3086329"
  },
  {
    "text": "the law of the universe aboard sit up since it's a sprung cloud think it's indexed and gets way to be or think ways",
    "start": "3086329",
    "end": "3092480"
  },
  {
    "text": "to be ingested maybe that might be something that we could leverage in the future again its beta and again we're",
    "start": "3092480",
    "end": "3099980"
  },
  {
    "text": "not committing but that's something that we're we may consider thank you very much",
    "start": "3099980",
    "end": "3106539"
  },
  {
    "text": "any questions",
    "start": "3110720",
    "end": "3114140"
  },
  {
    "text": "yeah it pretty much work for so repeat a question first",
    "start": "3122520",
    "end": "3127530"
  },
  {
    "text": "yeah the question is does the firehose equation with Splunk only supports a",
    "start": "3127530",
    "end": "3133380"
  },
  {
    "text": "diverse you know based sprung cloud or any other so in this case it supports any Splunk version as long as you can",
    "start": "3133380",
    "end": "3140580"
  },
  {
    "text": "enable HCC token on it so it could be spunk enterprise run on ec2 instances it",
    "start": "3140580",
    "end": "3145980"
  },
  {
    "text": "could be Splunk cloud it could be using a Splunk enterprise running on Prem servers as long as it's the right",
    "start": "3145980",
    "end": "3152910"
  },
  {
    "text": "version which is six five and above say",
    "start": "3152910",
    "end": "3163920"
  },
  {
    "text": "that again the question is is this plumb",
    "start": "3163920",
    "end": "3174660"
  },
  {
    "text": "for gonna be kept around for now it is and in the case of your AWS one way of",
    "start": "3174660",
    "end": "3181200"
  },
  {
    "text": "ingesting the data is using firehose you still need the universal 400 the",
    "start": "3181200",
    "end": "3186390"
  },
  {
    "text": "heavyweight for for other use cases whether it's ingesting data from your on-prem devices or whether running",
    "start": "3186390",
    "end": "3191700"
  },
  {
    "text": "add-on because there's a lot of other API that you might want to ingest data from so in this case it's still around",
    "start": "3191700",
    "end": "3199850"
  },
  {
    "text": "yes sir so the question is if we want to pull OS performance metrics suppose",
    "start": "3209009",
    "end": "3215049"
  },
  {
    "text": "funny sting senses a nice blank analyze can I use fire hose so the short answer is yes",
    "start": "3215049",
    "end": "3220839"
  },
  {
    "text": "so all these metrics you can emit into cloud watch metrics then probably use a forwarding mechanism like lambda",
    "start": "3220839",
    "end": "3226329"
  },
  {
    "text": "function to pull these metrics out of cloud wash metrics forward that into firehose and we can ingest into Splunk",
    "start": "3226329",
    "end": "3232509"
  },
  {
    "text": "you probably know from the dot-com Phyllis can talk more Splunk just added some very amazing capability for metric",
    "start": "3232509",
    "end": "3238539"
  },
  {
    "text": "analysis so but as I mentioned down the road we kind of want to make this integration really easy so we've heard",
    "start": "3238539",
    "end": "3244180"
  },
  {
    "text": "repeatedly from the customers who want to use plunk to analyze metric data so we do have something on the roadmap can",
    "start": "3244180",
    "end": "3252130"
  },
  {
    "text": "share about timelines you have a direct integration between cloud watch metrics and firehose so you can basically have",
    "start": "3252130",
    "end": "3257980"
  },
  {
    "text": "your OS metric data or any metric data from a ec2 instances gets written into cloud watch metrics it all streamed into",
    "start": "3257980",
    "end": "3264910"
  },
  {
    "text": "files directly but today you gotta have to use a function or instance to do the forwarding dip so the question is do you",
    "start": "3264910",
    "end": "3277119"
  },
  {
    "text": "still have the need to use deployment for deployment server in the cloud it depends on what you're ingesting so",
    "start": "3277119",
    "end": "3283210"
  },
  {
    "text": "today what firehose gives you is let's say you move to firehose it gives you that native capability for data",
    "start": "3283210",
    "end": "3288789"
  },
  {
    "text": "ingestion of cloud watch logs cloud watch events and AWS a iot however you",
    "start": "3288789",
    "end": "3296380"
  },
  {
    "text": "would still if four data sources that live outside of these services you might want to realize that you would need the",
    "start": "3296380",
    "end": "3303190"
  },
  {
    "text": "folder and you would still need the deployment server to manage those for order yeah",
    "start": "3303190",
    "end": "3309660"
  },
  {
    "text": "yes so but I'm not sure I follow you're talking about deployment service yeah",
    "start": "3318410",
    "end": "3328310"
  },
  {
    "text": "yeah for now it is not the case but I think that that's something that we",
    "start": "3337880",
    "end": "3343200"
  },
  {
    "text": "could look into and I'm actually we can take this offline because we probably have the the right person for this roadmap question yeah you I guess right",
    "start": "3343200",
    "end": "3351170"
  },
  {
    "text": "yeah go ahead so the question is is this",
    "start": "3351170",
    "end": "3357810"
  },
  {
    "text": "new feature available gov power the short answer is no today today Kinesis file is available in six regions us one",
    "start": "3357810",
    "end": "3365100"
  },
  {
    "text": "is West to and Frankfurt and Tokyo and",
    "start": "3365100",
    "end": "3371120"
  },
  {
    "text": "Ohio but we do have plan to expand it to all database regions next year so we",
    "start": "3371120",
    "end": "3376650"
  },
  {
    "text": "should be available 30 soon",
    "start": "3376650",
    "end": "3379789"
  },
  {
    "text": "so the question is about what about the AWS ta and I think we had one similar",
    "start": "3397939",
    "end": "3404039"
  },
  {
    "text": "slide to address your question for some reason we removed it from the deck but short answer they the TA is still there you still need it for the services that",
    "start": "3404039",
    "end": "3411869"
  },
  {
    "text": "are not necessarily supported out of the box today by firehose so one good example of this is s3 so today for you",
    "start": "3411869",
    "end": "3419279"
  },
  {
    "text": "to ingest the data from s3 you could use the the AWS to a and also there are",
    "start": "3419279",
    "end": "3425670"
  },
  {
    "text": "other AWS api's that we integrate with that the TA has the native capability to",
    "start": "3425670",
    "end": "3433049"
  },
  {
    "text": "ingest the data from these API so you still need this the TA for those API and",
    "start": "3433049",
    "end": "3438150"
  },
  {
    "text": "also if you're talking reliability if you remember one of the slide I have is when fire hose streams the data and",
    "start": "3438150",
    "end": "3445199"
  },
  {
    "text": "persisted to s3 in case bunk is not reachable you might want to ingest that data back from s3 using the TI so that's",
    "start": "3445199",
    "end": "3451949"
  },
  {
    "text": "one option also to have a push-pull type of architecture",
    "start": "3451949",
    "end": "3457160"
  },
  {
    "text": "so the question is do I need one fire hose for each of the index so as I",
    "start": "3463180",
    "end": "3469970"
  },
  {
    "text": "mentioned fire hose use splats HTC token to ingest data and we enable the token",
    "start": "3469970",
    "end": "3476540"
  },
  {
    "text": "you you can specify default index along with the token so all the data coming into that into that token will be",
    "start": "3476540",
    "end": "3483680"
  },
  {
    "text": "indexed into particular index however you can actually use fire host lambda transformation feature to override the",
    "start": "3483680",
    "end": "3490280"
  },
  {
    "text": "index metadata of the each of the each of of the record so you can actually",
    "start": "3490280",
    "end": "3495349"
  },
  {
    "text": "enable routing feature that way so within fire hose depending on the type of event you have you can actually",
    "start": "3495349",
    "end": "3500869"
  },
  {
    "text": "assign a metadata called index equals to a if this is the this type of event and index P if it's type B of event so when",
    "start": "3500869",
    "end": "3508220"
  },
  {
    "text": "the htc token receives that metadata in a particular JSON format it'll parse and about it in two different index so you",
    "start": "3508220",
    "end": "3514970"
  },
  {
    "text": "can actually achieve that reason if I single fire hose delivery stream getting to multiple indexing Splunk and same",
    "start": "3514970",
    "end": "3520760"
  },
  {
    "text": "thing applies to any metadata on this function whether the source type source and index included other questions",
    "start": "3520760",
    "end": "3532240"
  }
]
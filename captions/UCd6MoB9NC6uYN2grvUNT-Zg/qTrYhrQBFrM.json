[
  {
    "text": "Hello everyone.",
    "start": "240",
    "end": "1073"
  },
  {
    "text": "My name is Young Jung,\nprincipal solutions architect,",
    "start": "1073",
    "end": "2940"
  },
  {
    "text": "AWS Welcome to the booth.",
    "start": "2940",
    "end": "4800"
  },
  {
    "text": "And this is the demo",
    "start": "4800",
    "end": "6060"
  },
  {
    "text": "for smart scaling LG\nplus smart scaling four",
    "start": "6060",
    "end": "9090"
  },
  {
    "text": "five Z core network.",
    "start": "9090",
    "end": "11070"
  },
  {
    "text": "And today we want to demonstrate\nthe scaling capability",
    "start": "11070",
    "end": "15539"
  },
  {
    "text": "of the network functions\nrunning on the AWS with powered",
    "start": "15540",
    "end": "18900"
  },
  {
    "text": "by AWS AI ML service.",
    "start": "18900",
    "end": "21270"
  },
  {
    "text": "The key objective of this demo is to show",
    "start": "21270",
    "end": "24780"
  },
  {
    "text": "how much we can improve\nthis scaling capability",
    "start": "24780",
    "end": "28230"
  },
  {
    "text": "with the AI ML service of AWS",
    "start": "28230",
    "end": "30990"
  },
  {
    "text": "and with the automation\ntools of AWS service as well.",
    "start": "30990",
    "end": "34410"
  },
  {
    "text": "If we use AWS to host network functions",
    "start": "34410",
    "end": "38610"
  },
  {
    "text": "and comparing to the traditional\ndays of the data centers",
    "start": "38610",
    "end": "42540"
  },
  {
    "text": "in the traditional days, we\nhad to equip a lot of hardwares",
    "start": "42540",
    "end": "47160"
  },
  {
    "text": "and the kind of network\ncapacity more than we need.",
    "start": "47160",
    "end": "50220"
  },
  {
    "text": "So, but we want to really\nchange this mindset to the,",
    "start": "50220",
    "end": "54240"
  },
  {
    "text": "this industry.",
    "start": "54240",
    "end": "55350"
  },
  {
    "text": "If we use AWS cloud for\nhosting those network function,",
    "start": "55350",
    "end": "59219"
  },
  {
    "text": "we don't have to prepare this\nover overbooked resources.",
    "start": "59220",
    "end": "63000"
  },
  {
    "text": "We can just use right\nresources right in time",
    "start": "63000",
    "end": "66090"
  },
  {
    "text": "and then we can scale whenever\nwe need more resource.",
    "start": "66090",
    "end": "69299"
  },
  {
    "text": "That's the key benefit\nof the AWS services.",
    "start": "69300",
    "end": "71970"
  },
  {
    "text": "And then we want to bring AI ML power",
    "start": "71970",
    "end": "75060"
  },
  {
    "text": "to automate that process.",
    "start": "75060",
    "end": "76710"
  },
  {
    "text": "Predictively do this actually",
    "start": "76710",
    "end": "79740"
  },
  {
    "text": "before the traffic surge comes in.",
    "start": "79740",
    "end": "82020"
  },
  {
    "text": "That's the key objective of this demo.",
    "start": "82020",
    "end": "84119"
  },
  {
    "text": "Okay, so what we have here is",
    "start": "85830",
    "end": "88410"
  },
  {
    "text": "data variables coming\nfrom UPF network function,",
    "start": "89670",
    "end": "94350"
  },
  {
    "text": "and we are looking at peak user throughput",
    "start": "94350",
    "end": "97619"
  },
  {
    "text": "and number of sessions\nthat are established.",
    "start": "97620",
    "end": "100020"
  },
  {
    "text": "So the, what we do is we\nlook at the, the patterns",
    "start": "100020",
    "end": "103799"
  },
  {
    "text": "of traffic and we try to do three things.",
    "start": "103800",
    "end": "107670"
  },
  {
    "text": "One is we look at forecast\nsystem, trying to predict",
    "start": "107670",
    "end": "112140"
  },
  {
    "text": "how the traffic patterns",
    "start": "112140",
    "end": "113340"
  },
  {
    "text": "and the sessions are going\nto be in the next 12 hours.",
    "start": "113340",
    "end": "116399"
  },
  {
    "text": "And then we do the diagnostic\nsystem where we are trying",
    "start": "116400",
    "end": "119460"
  },
  {
    "text": "to pick up of anomalies.",
    "start": "119460",
    "end": "121710"
  },
  {
    "text": "Now, what happens is\nwith the forecast system,",
    "start": "121710",
    "end": "124500"
  },
  {
    "text": "when we are predicting there's a chance",
    "start": "124500",
    "end": "126570"
  },
  {
    "text": "that the predictions\nare can be error prone.",
    "start": "126570",
    "end": "131130"
  },
  {
    "text": "So as a contingency we\nhave a diagnostic system",
    "start": "131130",
    "end": "134790"
  },
  {
    "text": "whenever there is a, a peak demand",
    "start": "134790",
    "end": "137400"
  },
  {
    "text": "and something that we are not picking up",
    "start": "137400",
    "end": "139590"
  },
  {
    "text": "by the forecast system, that's picked up",
    "start": "139590",
    "end": "141690"
  },
  {
    "text": "by the diagnostic system as an anomaly.",
    "start": "141690",
    "end": "144390"
  },
  {
    "text": "So in this particular\ndemo, what we are doing is",
    "start": "144390",
    "end": "147690"
  },
  {
    "text": "we are taking the real traffic\ndata from, from the core",
    "start": "147690",
    "end": "152400"
  },
  {
    "text": "and we are streaming it to\nsimulate the real time systems",
    "start": "152400",
    "end": "156390"
  },
  {
    "text": "and using that and using\nthat to do forecast.",
    "start": "156390",
    "end": "160205"
  },
  {
    "text": "And also we have developed\nan anomaly detection model on",
    "start": "160205",
    "end": "163950"
  },
  {
    "text": "Amazon SageMaker",
    "start": "163950",
    "end": "165480"
  },
  {
    "text": "and the streaming data\nis hitting an endpoint",
    "start": "165480",
    "end": "168690"
  },
  {
    "text": "that has been deployed",
    "start": "168690",
    "end": "170190"
  },
  {
    "text": "and we are getting real\ntimes anomaly scores",
    "start": "170190",
    "end": "174300"
  },
  {
    "text": "of the, of the traffic",
    "start": "174300",
    "end": "176880"
  },
  {
    "text": "- Before moving on, I want\nto remark the partners,",
    "start": "176880",
    "end": "180160"
  },
  {
    "text": "we together worked with\nthe, for this demo,",
    "start": "180160",
    "end": "182800"
  },
  {
    "text": "EL plus is our customer,",
    "start": "182800",
    "end": "184900"
  },
  {
    "text": "and we worked with LG\ncustomer, el plus customer",
    "start": "184900",
    "end": "188650"
  },
  {
    "text": "to develop the algorithm for the scaling.",
    "start": "188650",
    "end": "191439"
  },
  {
    "text": "And also we worked with\nthe Samsung electronics",
    "start": "191440",
    "end": "194800"
  },
  {
    "text": "who is providing cloud native\n5G core network for this demo.",
    "start": "194800",
    "end": "198520"
  },
  {
    "text": "- Okay, so now let's look\nat the demo in action.",
    "start": "199420",
    "end": "203020"
  },
  {
    "text": "Let's first look at the peak user data.",
    "start": "203020",
    "end": "205630"
  },
  {
    "text": "What you see here is the,",
    "start": "205630",
    "end": "207400"
  },
  {
    "text": "the line in blue is the actual\ntraffic, the other lines",
    "start": "207400",
    "end": "211150"
  },
  {
    "text": "that are in color, those are\nthe predicted forecast in three",
    "start": "211150",
    "end": "214810"
  },
  {
    "text": "different confidence\nintervals, which is, we call it",
    "start": "214810",
    "end": "217300"
  },
  {
    "text": "as P 10, P 50, and P 90.",
    "start": "217300",
    "end": "219700"
  },
  {
    "text": "What that means is we expect the traffic",
    "start": "219700",
    "end": "222489"
  },
  {
    "text": "to be within these confidence interval.",
    "start": "222490",
    "end": "224680"
  },
  {
    "text": "Now you'll notice that we are\nassimilating the data at the",
    "start": "224680",
    "end": "228159"
  },
  {
    "text": "time of New Year",
    "start": "228160",
    "end": "229840"
  },
  {
    "text": "because this has been the\nanomalous behavior that we know",
    "start": "229840",
    "end": "232875"
  },
  {
    "text": "that this is spike in traffic",
    "start": "232875",
    "end": "235120"
  },
  {
    "text": "during the new year's time when\neveryone is either messaging",
    "start": "235120",
    "end": "238959"
  },
  {
    "text": "or making calls.",
    "start": "238960",
    "end": "239980"
  },
  {
    "text": "And we know that there's a\ndemand on the, the core network.",
    "start": "239980",
    "end": "244269"
  },
  {
    "text": "And you'll see that in, in general,",
    "start": "244270",
    "end": "246280"
  },
  {
    "text": "apart from the peak load timeframe,",
    "start": "246280",
    "end": "249520"
  },
  {
    "text": "we have the forecast\nsystem predicting the load.",
    "start": "249520",
    "end": "252730"
  },
  {
    "text": "And during the times of new\nyear when the demand is high,",
    "start": "252730",
    "end": "256329"
  },
  {
    "text": "that is being picked up as an anomaly",
    "start": "256330",
    "end": "258074"
  },
  {
    "text": "by the diagnostic system.",
    "start": "258075",
    "end": "259420"
  },
  {
    "text": "And these two data are\nused to do the scaling,",
    "start": "260470",
    "end": "264190"
  },
  {
    "text": "whether it is scaling",
    "start": "264190",
    "end": "265515"
  },
  {
    "text": "or scale out based on\neither it is an anomaly",
    "start": "265515",
    "end": "268120"
  },
  {
    "text": "or forecast that we are picking up on.",
    "start": "268120",
    "end": "272229"
  },
  {
    "text": "Let's start with the, the demo here.",
    "start": "273220",
    "end": "276520"
  },
  {
    "text": "What you see here is the\nCloudWatch dashboard.",
    "start": "276520",
    "end": "279550"
  },
  {
    "text": "Let me first explain the,\nyou know, what's happening,",
    "start": "279550",
    "end": "283750"
  },
  {
    "text": "all the functional components\nof this architecture.",
    "start": "284800",
    "end": "287985"
  },
  {
    "text": "We are, we are streaming data",
    "start": "287985",
    "end": "290560"
  },
  {
    "text": "through Amazon Kinesis data streams,",
    "start": "292210",
    "end": "295600"
  },
  {
    "text": "and then we pump that data\nthrough Amazon data fire hose",
    "start": "295600",
    "end": "300430"
  },
  {
    "text": "and send that to a lambda function.",
    "start": "300430",
    "end": "303580"
  },
  {
    "text": "That lambda function is then calling the",
    "start": "303580",
    "end": "306669"
  },
  {
    "text": "realtime SageMaker endpoints to,",
    "start": "306670",
    "end": "309370"
  },
  {
    "text": "to get the inference on the anomaly score.",
    "start": "309370",
    "end": "312460"
  },
  {
    "text": "You know, we are doing that\nthrough the lambda function.",
    "start": "312460",
    "end": "315009"
  },
  {
    "text": "And let me also show you the forecast.",
    "start": "315010",
    "end": "317110"
  },
  {
    "text": "This is how the forecast looks like",
    "start": "317110",
    "end": "318759"
  },
  {
    "text": "with the three different\nconfidence intervals.",
    "start": "318760",
    "end": "320590"
  },
  {
    "text": "And we see that in, in general,",
    "start": "321550",
    "end": "324069"
  },
  {
    "text": "the traffic pattern has been\npredicted, which is quite close",
    "start": "324070",
    "end": "327640"
  },
  {
    "text": "to the original traffic with\nthe exception of the anomalies",
    "start": "327640",
    "end": "332230"
  },
  {
    "text": "that are occurring at\nthe New Year's timeframe.",
    "start": "332230",
    "end": "335710"
  },
  {
    "text": "I want to chime in to make a remark here",
    "start": "335710",
    "end": "338020"
  },
  {
    "text": "because this is captured as an anomaly.",
    "start": "338020",
    "end": "341080"
  },
  {
    "text": "That is because we only\nuse two months is of data.",
    "start": "341080",
    "end": "344169"
  },
  {
    "text": "If we accumulate, if we\nwere able to accumulate",
    "start": "344170",
    "end": "347890"
  },
  {
    "text": "the dataset more than two years,",
    "start": "347890",
    "end": "349870"
  },
  {
    "text": "then this will be no more\nnormally anymore in the system.",
    "start": "349870",
    "end": "353475"
  },
  {
    "text": "But right now we are using two months",
    "start": "353475",
    "end": "355810"
  },
  {
    "text": "of data comparing the\nprevious November data.",
    "start": "355810",
    "end": "359180"
  },
  {
    "text": "Certainly this is on anomaly,",
    "start": "359180",
    "end": "360710"
  },
  {
    "text": "but if we had the last\nyears' data and the the",
    "start": "360710",
    "end": "363410"
  },
  {
    "text": "before the other years' data,",
    "start": "363410",
    "end": "364970"
  },
  {
    "text": "then it can be seasonal,\nkind of normal data.",
    "start": "364970",
    "end": "367280"
  },
  {
    "text": "But at this demo, I just want\nto make sure this is captured",
    "start": "367280",
    "end": "370970"
  },
  {
    "text": "as anomaly because we\nare using some limited",
    "start": "370970",
    "end": "373400"
  },
  {
    "text": "number of the data sets.",
    "start": "373400",
    "end": "375035"
  },
  {
    "text": "Okay, now let's look at what\nis happening under the hood",
    "start": "375035",
    "end": "378440"
  },
  {
    "text": "inside of Amazon SageMaker.",
    "start": "378440",
    "end": "380510"
  },
  {
    "text": "As you can see here,",
    "start": "380510",
    "end": "381560"
  },
  {
    "text": "we are developing the\nanomaly detection model.",
    "start": "382400",
    "end": "385160"
  },
  {
    "text": "One for number of sessions\nthat are established",
    "start": "385160",
    "end": "387950"
  },
  {
    "text": "and also for the throughput,\nwhich is the RX total,",
    "start": "387950",
    "end": "391580"
  },
  {
    "text": "which is the peak user data.",
    "start": "391580",
    "end": "393620"
  },
  {
    "text": "We go through the process\nof SageMaker model building",
    "start": "393620",
    "end": "398620"
  },
  {
    "text": "and, and using these\ndata sets, we look at the",
    "start": "398720",
    "end": "403720"
  },
  {
    "text": "data analysis of how the\noriginal, the times, the,",
    "start": "404120",
    "end": "408895"
  },
  {
    "text": "the original raw signal looks like.",
    "start": "408895",
    "end": "411169"
  },
  {
    "text": "And we use that to run a forecast,",
    "start": "411170",
    "end": "414050"
  },
  {
    "text": "to run an anomaly detection model",
    "start": "414050",
    "end": "415699"
  },
  {
    "text": "and deploy that to a SageMaker instance.",
    "start": "416870",
    "end": "420199"
  },
  {
    "text": "So once the training is completed,\nthe model is now deployed",
    "start": "422990",
    "end": "426440"
  },
  {
    "text": "to an instance and we have\nstreaming data hitting an",
    "start": "426440",
    "end": "430040"
  },
  {
    "text": "endpoint, getting the inference out.",
    "start": "430040",
    "end": "433220"
  },
  {
    "text": "So that inference goes to Amazon S3",
    "start": "433220",
    "end": "437960"
  },
  {
    "text": "and, and we have the anomaly data coming",
    "start": "437960",
    "end": "442639"
  },
  {
    "text": "in once every five minutes for\nthe throughput information.",
    "start": "442640",
    "end": "447640"
  },
  {
    "text": "And this is refreshed every five minutes.",
    "start": "447650",
    "end": "449690"
  },
  {
    "text": "And so normally data is\nunloaded to the accessory bucket",
    "start": "450800",
    "end": "454520"
  },
  {
    "text": "and actually, and then event\nbreach is pulling the data",
    "start": "454520",
    "end": "458330"
  },
  {
    "text": "to the lambda, another lambda\nto take a poster processing.",
    "start": "458330",
    "end": "461780"
  },
  {
    "text": "In the poster processing process,",
    "start": "461780",
    "end": "464030"
  },
  {
    "text": "it is looking the forecast number",
    "start": "464030",
    "end": "466250"
  },
  {
    "text": "and the normally data score.",
    "start": "466250",
    "end": "468530"
  },
  {
    "text": "And if anomaly score is\nhigher than certain number",
    "start": "468530",
    "end": "471980"
  },
  {
    "text": "and then it is, we make a decision",
    "start": "471980",
    "end": "474110"
  },
  {
    "text": "to make a scaling in or scaling out.",
    "start": "474110",
    "end": "477199"
  },
  {
    "text": "And that is implemented\nwith the lambda functions.",
    "start": "477200",
    "end": "480950"
  },
  {
    "text": "Here, here.",
    "start": "480950",
    "end": "482300"
  },
  {
    "text": "And after this lambda function\nis processing the scaling",
    "start": "482300",
    "end": "485509"
  },
  {
    "text": "decision, then it is\ncooling the a p, another API",
    "start": "485510",
    "end": "489050"
  },
  {
    "text": "to reduce down the size of\nthe worker, no of the EKS",
    "start": "489050",
    "end": "493009"
  },
  {
    "text": "or increase the size of the\nworker node of the EKS that goes",
    "start": "493010",
    "end": "497030"
  },
  {
    "text": "to the OR scaling group.",
    "start": "497030",
    "end": "498860"
  },
  {
    "text": "And we can see that the,\nbased on the network demand,",
    "start": "498860",
    "end": "502250"
  },
  {
    "text": "on the change of the\nnetwork traffic, we can see",
    "start": "502250",
    "end": "504830"
  },
  {
    "text": "that the size of the instance\nis being bearing based on the",
    "start": "504830",
    "end": "509814"
  },
  {
    "text": "network capacity of the requirement.",
    "start": "509815",
    "end": "512180"
  },
  {
    "text": "So this outcome of the demo\nis shown in a dashboard",
    "start": "513170",
    "end": "516709"
  },
  {
    "text": "and if we, you can see\nthe timeline and then",
    "start": "516710",
    "end": "519830"
  },
  {
    "text": "because we are running\nsome intentional spike data",
    "start": "519830",
    "end": "523010"
  },
  {
    "text": "and based on the spike data,",
    "start": "523010",
    "end": "524780"
  },
  {
    "text": "net capacity is getting increased.",
    "start": "524780",
    "end": "526910"
  },
  {
    "text": "And then if there's a kind of\nnormal usage of the network,",
    "start": "526910",
    "end": "530394"
  },
  {
    "text": "then it goes down to\nthe normal net capacity",
    "start": "530395",
    "end": "533750"
  },
  {
    "text": "and if there comes another spike,",
    "start": "533750",
    "end": "535410"
  },
  {
    "text": "and then based on",
    "start": "535410",
    "end": "536639"
  },
  {
    "text": "that spike network capacity\nis getting increased",
    "start": "536640",
    "end": "539040"
  },
  {
    "text": "automatically, everything is\ndone by automatically nothing",
    "start": "539040",
    "end": "542670"
  },
  {
    "text": "of the human intervention.",
    "start": "542670",
    "end": "543779"
  },
  {
    "text": "That's the key of another, another aspect",
    "start": "543780",
    "end": "545790"
  },
  {
    "text": "of this, this demo.",
    "start": "545790",
    "end": "547470"
  },
  {
    "text": "Okay, as a conclusion,",
    "start": "547470",
    "end": "549120"
  },
  {
    "text": "this demo demo demonstrated\nAI ML power the scaling",
    "start": "549120",
    "end": "552600"
  },
  {
    "text": "capability of the five in the\ntop function when it is built",
    "start": "552600",
    "end": "555930"
  },
  {
    "text": "on AWS with AWS services, ai, ML services",
    "start": "555930",
    "end": "560399"
  },
  {
    "text": "and Amazon EKS and AWS Autoscaling group.",
    "start": "560400",
    "end": "564300"
  },
  {
    "text": "All those building blocks available",
    "start": "564300",
    "end": "566105"
  },
  {
    "text": "to compose this whole entire service set.",
    "start": "566105",
    "end": "569040"
  },
  {
    "text": "As the outcome of this service, we can see",
    "start": "569040",
    "end": "571649"
  },
  {
    "text": "that we can achieve the\noperational PCC, it'll be better",
    "start": "571650",
    "end": "576150"
  },
  {
    "text": "and also as well the\ncost reduction as well.",
    "start": "576150",
    "end": "579210"
  },
  {
    "text": "If we reserve all the instances\nmore than the bandwidth we",
    "start": "579210",
    "end": "582360"
  },
  {
    "text": "need then comparing to the, to",
    "start": "582360",
    "end": "584370"
  },
  {
    "text": "that if we use this architecture,",
    "start": "584370",
    "end": "586860"
  },
  {
    "text": "then in instance cost will\nbe reduced down in our lab",
    "start": "586860",
    "end": "590700"
  },
  {
    "text": "calculation, 30% of the\nreduction we can estimate.",
    "start": "590700",
    "end": "594360"
  },
  {
    "text": "So likewise,",
    "start": "594360",
    "end": "595529"
  },
  {
    "text": "it can be dependent on the\nnetwork size and the scale.",
    "start": "595530",
    "end": "598890"
  },
  {
    "text": "And if we do apply this demo\nto the other network functions,",
    "start": "598890",
    "end": "602820"
  },
  {
    "text": "we can have more kind of\nefficiency of the cost.",
    "start": "602820",
    "end": "606000"
  },
  {
    "text": "The operation this demo wanted",
    "start": "606000",
    "end": "607980"
  },
  {
    "text": "to deliver this key messaging.",
    "start": "607980",
    "end": "609480"
  },
  {
    "text": "AI ML can bring the power\nto automate the process",
    "start": "609480",
    "end": "613230"
  },
  {
    "text": "and also predict the KPIs to\ncontrol the network capacity.",
    "start": "613230",
    "end": "618230"
  },
  {
    "text": "Thank you for watching this video.",
    "start": "618300",
    "end": "619740"
  }
]
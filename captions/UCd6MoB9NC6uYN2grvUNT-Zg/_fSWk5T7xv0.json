[
  {
    "text": "So what we are here today\nto look at is the Ericsson",
    "start": "60",
    "end": "4830"
  },
  {
    "text": "Telco LLMs built on Eli,",
    "start": "4830",
    "end": "7950"
  },
  {
    "text": "the Ericsson Language\nIntelligence platform.",
    "start": "7950",
    "end": "10530"
  },
  {
    "text": "This is a collaboration\nbetween Ericsson and AWS.",
    "start": "10530",
    "end": "14040"
  },
  {
    "text": "Ericsson has been working on\ncreating telco specific l LMS",
    "start": "14040",
    "end": "18510"
  },
  {
    "text": "since roughly 2020.",
    "start": "18510",
    "end": "21240"
  },
  {
    "text": "They've been developing\nmost of this on-Prem",
    "start": "21240",
    "end": "23550"
  },
  {
    "text": "and have now this year started\nmoving this stuff to AWS.",
    "start": "23550",
    "end": "27779"
  },
  {
    "text": "They started this on,\non Kubernetes, on-Prem,",
    "start": "27780",
    "end": "30090"
  },
  {
    "text": "and now we have this\nrunning on Amazon EKS.",
    "start": "30090",
    "end": "34020"
  },
  {
    "text": "On top of that, we're utilizing our,",
    "start": "34020",
    "end": "37410"
  },
  {
    "text": "our machine learning\nservice like SageMaker,",
    "start": "37410",
    "end": "39570"
  },
  {
    "text": "Amazon SageMaker for training jobs",
    "start": "39570",
    "end": "41670"
  },
  {
    "text": "and evaluation of the, of, of\nthe models as well as bedrock",
    "start": "41670",
    "end": "45570"
  },
  {
    "text": "to provide LLMs generic LMS\nto support the Ericsson LLMs.",
    "start": "45570",
    "end": "50250"
  },
  {
    "text": "The benefits of a telco specific LLM",
    "start": "50250",
    "end": "53580"
  },
  {
    "text": "or a domain specific\nindustry specific LLMR,",
    "start": "53580",
    "end": "56700"
  },
  {
    "text": "that they can be actually much\nsmaller than the very large",
    "start": "56700",
    "end": "59760"
  },
  {
    "text": "language models that we see.",
    "start": "59760",
    "end": "61260"
  },
  {
    "text": "And with that, they get faster.",
    "start": "61260",
    "end": "63210"
  },
  {
    "text": "They cost a lot less to train them",
    "start": "63210",
    "end": "65045"
  },
  {
    "text": "'cause you need less time to train them.",
    "start": "65045",
    "end": "66450"
  },
  {
    "text": "You need less data to train them",
    "start": "66450",
    "end": "68159"
  },
  {
    "text": "because you need less, less,\nless time for that, less energy",
    "start": "68160",
    "end": "71160"
  },
  {
    "text": "for that as well as less time\nduring, during the inference.",
    "start": "71160",
    "end": "75330"
  },
  {
    "text": "Next we can see an,",
    "start": "75330",
    "end": "76770"
  },
  {
    "text": "an architecture diagram of how this looks.",
    "start": "76770",
    "end": "78750"
  },
  {
    "text": "I described this a little bit already.",
    "start": "78750",
    "end": "80550"
  },
  {
    "text": "We're having most of the\ninfrastructure deployed",
    "start": "80550",
    "end": "82590"
  },
  {
    "text": "on Amazon EKS.",
    "start": "82590",
    "end": "83700"
  },
  {
    "text": "That's where they originally\ncame from, from Kubernetes.",
    "start": "83700",
    "end": "86189"
  },
  {
    "text": "And now we have added other\nparts like for example, the",
    "start": "86190",
    "end": "89340"
  },
  {
    "text": "as Amazon SageMaker product\nsuite on top of that bedrock,",
    "start": "89340",
    "end": "93600"
  },
  {
    "text": "as I talked about before,",
    "start": "93600",
    "end": "95010"
  },
  {
    "text": "when you look at LLMs in\nlittle bit more detail,",
    "start": "95010",
    "end": "98550"
  },
  {
    "text": "it's not really just the LLM",
    "start": "98550",
    "end": "100260"
  },
  {
    "text": "that generates the tax is important.",
    "start": "100260",
    "end": "102360"
  },
  {
    "text": "The other part is very important is",
    "start": "102360",
    "end": "104580"
  },
  {
    "text": "to get the right context.",
    "start": "104580",
    "end": "105815"
  },
  {
    "text": "When you prove, when you\nask an LLM to generate text,",
    "start": "105815",
    "end": "109110"
  },
  {
    "text": "and this is something that\nEricsson perfected here",
    "start": "109110",
    "end": "111060"
  },
  {
    "text": "with their customer embedding models",
    "start": "111060",
    "end": "112680"
  },
  {
    "text": "that custom retrievers and reran us.",
    "start": "112680",
    "end": "114750"
  },
  {
    "text": "And if you pair that",
    "start": "114750",
    "end": "115770"
  },
  {
    "text": "and with an Amazon state-of-the\nart LLM like cloud,",
    "start": "115770",
    "end": "119820"
  },
  {
    "text": "cloud two we are using in this case,",
    "start": "119820",
    "end": "121530"
  },
  {
    "text": "then you get a really,\nreally good experience.",
    "start": "121530",
    "end": "123150"
  },
  {
    "text": "So what we have here is a demo where we,",
    "start": "124140",
    "end": "127350"
  },
  {
    "text": "it's a quite typical\nsetup in the beginning.",
    "start": "127350",
    "end": "129030"
  },
  {
    "text": "We have a chat bot, what\nwe can talk with the telco,",
    "start": "129030",
    "end": "132540"
  },
  {
    "text": "LLM about some issue that there,",
    "start": "132540",
    "end": "135420"
  },
  {
    "text": "that somebody is having\nwith a, with a network.",
    "start": "135420",
    "end": "137280"
  },
  {
    "text": "In this case we're talking about devices",
    "start": "137280",
    "end": "139895"
  },
  {
    "text": "that take too much energy.",
    "start": "139895",
    "end": "141360"
  },
  {
    "text": "In this case, somebody that\nworks in a knock will be able",
    "start": "141360",
    "end": "145200"
  },
  {
    "text": "to talk to the LLM.",
    "start": "145200",
    "end": "147060"
  },
  {
    "text": "So what they will be able\nto do, they will, they will,",
    "start": "147060",
    "end": "149310"
  },
  {
    "text": "in a conversation, I'll\nbe able to find out",
    "start": "149310",
    "end": "151175"
  },
  {
    "text": "what is the actual problem,\nwhat could be the problem.",
    "start": "151175",
    "end": "153750"
  },
  {
    "text": "We'll classify that in a second.",
    "start": "153750",
    "end": "155610"
  },
  {
    "text": "The great thing about this is",
    "start": "155610",
    "end": "156725"
  },
  {
    "text": "that you get really\naccurate responses here.",
    "start": "156725",
    "end": "159570"
  },
  {
    "text": "We get fast responses",
    "start": "159570",
    "end": "160830"
  },
  {
    "text": "and you can always find\nout, okay, what is the,",
    "start": "160830",
    "end": "163050"
  },
  {
    "text": "what is the sort of truth for this?",
    "start": "163050",
    "end": "164640"
  },
  {
    "text": "What what we can see here now is",
    "start": "164640",
    "end": "165810"
  },
  {
    "text": "that we get the right results here.",
    "start": "165810",
    "end": "167430"
  },
  {
    "text": "We can jump into, into this.",
    "start": "167430",
    "end": "168959"
  },
  {
    "text": "We see exactly what,\nwhere, where, what kind",
    "start": "168960",
    "end": "170880"
  },
  {
    "text": "of libraries we're talking about.",
    "start": "170880",
    "end": "172500"
  },
  {
    "text": "Where does this data come from.",
    "start": "172500",
    "end": "174120"
  },
  {
    "text": "We can then jump directly\ninto the, into the CPI,",
    "start": "174120",
    "end": "177810"
  },
  {
    "text": "the the customer product where we can see,",
    "start": "177810",
    "end": "181120"
  },
  {
    "text": "we can see exactly why we\ngot the answer that we have",
    "start": "181120",
    "end": "184360"
  },
  {
    "text": "to just to check, check\nfor tooth for, for this,",
    "start": "184360",
    "end": "186970"
  },
  {
    "text": "the integration is important.",
    "start": "186970",
    "end": "188710"
  },
  {
    "text": "So once we've done that, we\ncan have this interaction",
    "start": "188710",
    "end": "191230"
  },
  {
    "text": "with the chat, but to find\nout what is the actual problem",
    "start": "191230",
    "end": "193720"
  },
  {
    "text": "that we're having, we can then,",
    "start": "193720",
    "end": "196870"
  },
  {
    "text": "after we've had this conversation",
    "start": "196870",
    "end": "198549"
  },
  {
    "text": "and here we're asking,\nwe're asking the question",
    "start": "199510",
    "end": "201730"
  },
  {
    "text": "that I said earlier, what\nabout the, the devices",
    "start": "201730",
    "end": "203950"
  },
  {
    "text": "that drain energy really quickly.",
    "start": "203950",
    "end": "205720"
  },
  {
    "text": "So once we get, get to\nthe results of this,",
    "start": "205720",
    "end": "209740"
  },
  {
    "text": "We'll see for example here that hey,",
    "start": "216430",
    "end": "217989"
  },
  {
    "text": "maybe there is a problem with DRX.",
    "start": "217990",
    "end": "220570"
  },
  {
    "text": "We can, DRX is a way",
    "start": "220570",
    "end": "223540"
  },
  {
    "text": "to optimize the battery\nlifetime of devices",
    "start": "223540",
    "end": "226360"
  },
  {
    "text": "by not making them to connect",
    "start": "226360",
    "end": "228610"
  },
  {
    "text": "and get data all the\ntime from the network.",
    "start": "228610",
    "end": "231430"
  },
  {
    "text": "So we're asking a bunch\nof follow follow ups",
    "start": "231430",
    "end": "233680"
  },
  {
    "text": "about a specific topic.",
    "start": "233680",
    "end": "234819"
  },
  {
    "text": "Now that seems to be the,\nseems to be a possible solution",
    "start": "234820",
    "end": "238750"
  },
  {
    "text": "can also, based on our\nconversation, we can find out",
    "start": "238750",
    "end": "241270"
  },
  {
    "text": "what the product is that we have involved.",
    "start": "241270",
    "end": "242800"
  },
  {
    "text": "We can also see what kind\nof issue we have classified.",
    "start": "242800",
    "end": "246070"
  },
  {
    "text": "In this case, as we talked\nabout earlier, we have, we,",
    "start": "246070",
    "end": "248385"
  },
  {
    "text": "we can, we can optimize\nthe DRX configuration of,",
    "start": "248385",
    "end": "250965"
  },
  {
    "text": "we can send to the, to the user devices.",
    "start": "250965",
    "end": "253690"
  },
  {
    "text": "That's the first thing. Second thing",
    "start": "253690",
    "end": "255520"
  },
  {
    "text": "that we can do here is this\nis, this is the extension",
    "start": "255520",
    "end": "257859"
  },
  {
    "text": "of there, there's a part of\nthis here where the telco LLMs",
    "start": "257860",
    "end": "261069"
  },
  {
    "text": "the telecom LLMs that Ericsson\nprovides is really good.",
    "start": "261070",
    "end": "263590"
  },
  {
    "text": "And then we can combine them\nwith the state of the art LLMs",
    "start": "263590",
    "end": "267699"
  },
  {
    "text": "that you can access through bedrock.",
    "start": "267700",
    "end": "269260"
  },
  {
    "text": "So in this case, we're\ndoing something well,",
    "start": "269260",
    "end": "271360"
  },
  {
    "text": "this is is great, the steer x.",
    "start": "271360",
    "end": "272680"
  },
  {
    "text": "Now we need to find out a\nlittle bit more about the",
    "start": "272680",
    "end": "274690"
  },
  {
    "text": "usage of these devices.",
    "start": "274690",
    "end": "276160"
  },
  {
    "text": "So we, we need to query traffic data.",
    "start": "276160",
    "end": "278380"
  },
  {
    "text": "In this case we have natural language",
    "start": "278380",
    "end": "280120"
  },
  {
    "text": "that will then directly integrate\nwith the, with the traffic",
    "start": "280120",
    "end": "283600"
  },
  {
    "text": "data databases.",
    "start": "284620",
    "end": "286240"
  },
  {
    "text": "So we can query that data on top of that.",
    "start": "286240",
    "end": "288970"
  },
  {
    "text": "We can also visualize this data.",
    "start": "288970",
    "end": "290650"
  },
  {
    "text": "So in natural language you\ncan describe then what kind",
    "start": "290650",
    "end": "293410"
  },
  {
    "text": "of information do you\nwant to get In this case,",
    "start": "293410",
    "end": "295605"
  },
  {
    "text": "the important thing for us, we want",
    "start": "295605",
    "end": "296920"
  },
  {
    "text": "to find out if there are\nclusters, bursts",
    "start": "296920",
    "end": "300170"
  },
  {
    "text": "of connectivity or\nwhere the device is active.",
    "start": "300170",
    "end": "303345"
  },
  {
    "text": "And in getting data, we do get that.",
    "start": "303345",
    "end": "306310"
  },
  {
    "text": "What we want to do next\nthen is we want to find out",
    "start": "306310",
    "end": "308919"
  },
  {
    "text": "how long are these clusters.",
    "start": "308920",
    "end": "310480"
  },
  {
    "text": "And for that we need some pre-processing.",
    "start": "310480",
    "end": "311950"
  },
  {
    "text": "And again, we can process,",
    "start": "311950",
    "end": "313300"
  },
  {
    "text": "we can analyze this data\nin natural language.",
    "start": "313300",
    "end": "315580"
  },
  {
    "text": "As soon as we've done\nthat, we now have,",
    "start": "315580",
    "end": "317860"
  },
  {
    "text": "with this processing instruction,\nwe have now created the,",
    "start": "317860",
    "end": "321555"
  },
  {
    "text": "the, we have now applied a\ncluster categorization for each",
    "start": "321555",
    "end": "324729"
  },
  {
    "text": "and every request that we have in there.",
    "start": "324730",
    "end": "326350"
  },
  {
    "text": "So we just assigned a cluster to that.",
    "start": "326350",
    "end": "328330"
  },
  {
    "text": "And once we have that, we can find out",
    "start": "328330",
    "end": "329979"
  },
  {
    "text": "how long does this cluster last?",
    "start": "329980",
    "end": "331630"
  },
  {
    "text": "So how our burst histogram.",
    "start": "331630",
    "end": "333340"
  },
  {
    "text": "Once we have that, we\ncan then also plot that",
    "start": "333340",
    "end": "335500"
  },
  {
    "text": "and that gives us information on",
    "start": "336520",
    "end": "339759"
  },
  {
    "text": "how long these clusters\nlast, the visualization",
    "start": "339760",
    "end": "342670"
  },
  {
    "text": "that we get out of the box here, well,",
    "start": "342670",
    "end": "344950"
  },
  {
    "text": "we can always adjust this and\nthis is what we're doing next",
    "start": "344950",
    "end": "347050"
  },
  {
    "text": "'cause this is fantastic,",
    "start": "347050",
    "end": "348400"
  },
  {
    "text": "but we need to kind of zoom in closer.",
    "start": "348400",
    "end": "350290"
  },
  {
    "text": "So one, one of the examples",
    "start": "350290",
    "end": "351400"
  },
  {
    "text": "that we show here now is we just,",
    "start": "351400",
    "end": "352690"
  },
  {
    "text": "we just adjust in natural\nlanguage that we want",
    "start": "352690",
    "end": "354790"
  },
  {
    "text": "to see from a hundred milliseconds",
    "start": "354790",
    "end": "356565"
  },
  {
    "text": "to 200 milliseconds range.",
    "start": "356565",
    "end": "358970"
  },
  {
    "text": "Once we do that and\nplot that again, we, in,",
    "start": "358970",
    "end": "361640"
  },
  {
    "text": "in the background, we write\ncode, we execute that code",
    "start": "361640",
    "end": "364340"
  },
  {
    "text": "and we then have a new visualization here.",
    "start": "364340",
    "end": "367310"
  },
  {
    "text": "And in this case we can see\nthat here we have roughly the,",
    "start": "367310",
    "end": "370580"
  },
  {
    "text": "the bursts are roughly between 110, 150.",
    "start": "370580",
    "end": "374659"
  },
  {
    "text": "With this information, we can\nreally run arbitrary different",
    "start": "374660",
    "end": "377750"
  },
  {
    "text": "visualizations against our\ndata that we have here.",
    "start": "378620",
    "end": "381350"
  },
  {
    "text": "This one, is it really useful\nfor this particular DRX case?",
    "start": "381350",
    "end": "384530"
  },
  {
    "text": "No, but it's interesting that\nyou can do whatever you want",
    "start": "384530",
    "end": "386780"
  },
  {
    "text": "to, whatever kind of\nvisualization you want to have.",
    "start": "386780",
    "end": "389480"
  },
  {
    "text": "After that, we can take all of this data",
    "start": "389480",
    "end": "391730"
  },
  {
    "text": "and send it to a neural network to find,",
    "start": "391730",
    "end": "394130"
  },
  {
    "text": "to get the optimization or\nthe opt optimal configuration.",
    "start": "394130",
    "end": "398660"
  },
  {
    "text": "For this one, we get that, we feed",
    "start": "398660",
    "end": "400820"
  },
  {
    "text": "that back into the telco LLM",
    "start": "400820",
    "end": "402620"
  },
  {
    "text": "and then we have that we,",
    "start": "402620",
    "end": "403790"
  },
  {
    "text": "we can then again have\na conversation about the",
    "start": "403790",
    "end": "406190"
  },
  {
    "text": "result that we've gotten here.",
    "start": "406190",
    "end": "407510"
  },
  {
    "text": "So what's interesting about this is",
    "start": "407510",
    "end": "409220"
  },
  {
    "text": "that we're mixing different\ntypes of models here.",
    "start": "409220",
    "end": "411500"
  },
  {
    "text": "We're mixing the telco LLMs,\nwe we're mixing that with,",
    "start": "411500",
    "end": "414680"
  },
  {
    "text": "for example, Amazon Bedrock Cloud,",
    "start": "414680",
    "end": "417050"
  },
  {
    "text": "and we mix that together",
    "start": "417050",
    "end": "418190"
  },
  {
    "text": "with more traditional AI\nmodels like the neural network",
    "start": "418190",
    "end": "421820"
  },
  {
    "text": "that Ericsson has to optimize D Rx.",
    "start": "421820",
    "end": "424700"
  },
  {
    "text": "And in the end, the user\ncan provide feedback.",
    "start": "424700",
    "end": "427220"
  },
  {
    "text": "And this is the demo",
    "start": "427220",
    "end": "428240"
  },
  {
    "text": "for the Ericsson language\nintelligence platform providing",
    "start": "428240",
    "end": "431509"
  },
  {
    "text": "telcos on AWS.",
    "start": "431510",
    "end": "433220"
  },
  {
    "text": "Thank you.",
    "start": "433220",
    "end": "434053"
  }
]
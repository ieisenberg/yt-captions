[
  {
    "text": "good morning everyone uh good morning everyone um my",
    "start": "359",
    "end": "7720"
  },
  {
    "text": "name is AK uh I manag the Dropbox infrastructure uh and I wanted to thank",
    "start": "7720",
    "end": "13040"
  },
  {
    "text": "you for coming to this session um I'm extremely excited to be in front of you to talk about how Dropbox leverages AWS",
    "start": "13040",
    "end": "19720"
  },
  {
    "text": "and sqs to run massive workloads and at the end of this talk I would like to",
    "start": "19720",
    "end": "25199"
  },
  {
    "text": "make sure that you not only get a sense of um the operations and how we solve this particular problem but also get a",
    "start": "25199",
    "end": "32119"
  },
  {
    "text": "few takeaways which you can take back and see if they apply to the problems you might be trying to solve in your",
    "start": "32119",
    "end": "37280"
  },
  {
    "text": "companies and in your infrastructure hopefully most of you are aware of what Dropbox does uh we are the",
    "start": "37280",
    "end": "44399"
  },
  {
    "text": "world's largest cloud storage and syncing company in the world with over 300 million users syncing more than a",
    "start": "44399",
    "end": "51640"
  },
  {
    "text": "billion files every day just to give you a sense of how big we are we believe we",
    "start": "51640",
    "end": "57239"
  },
  {
    "text": "are the largest repository of office documents in the world with more than 35 billion documents in Dropbox right now",
    "start": "57239",
    "end": "64280"
  },
  {
    "text": "that's five documents for every living human being on the planet right now so that's a huge amount of scale this adds",
    "start": "64280",
    "end": "70680"
  },
  {
    "text": "up to hundreds and hundreds of paby of data which we have to store and synchronized across hundreds of millions",
    "start": "70680",
    "end": "77640"
  },
  {
    "text": "of devices every single day and the way we achieve this scale is by leveraging a",
    "start": "77640",
    "end": "85280"
  },
  {
    "text": "hybrid architecture where we use the power of Amazon and various services is that it offers uh things like ec2 S3 um",
    "start": "85280",
    "end": "95399"
  },
  {
    "text": "elb Route 53 sqs as well as our own servers in the data centers which we own",
    "start": "95399",
    "end": "101720"
  },
  {
    "text": "and operate our data centers are spread across us uh between East Coast and West",
    "start": "101720",
    "end": "108280"
  },
  {
    "text": "Coast and are Prim primarily used to store metadata about the users the files they have the revisions and other",
    "start": "108280",
    "end": "115560"
  },
  {
    "text": "business logic which we use to synchronize the data whereas we leverage Amazon to provide us with this almost",
    "start": "115560",
    "end": "121960"
  },
  {
    "text": "infinite and flexible resource where we can keep growing without or very little operation support and actually use",
    "start": "121960",
    "end": "128879"
  },
  {
    "text": "things like S3 to store our file content in order to understand this",
    "start": "128879",
    "end": "134319"
  },
  {
    "text": "better and see how this actually allows us to do uh synchronization across millions of users and hundreds of ped of",
    "start": "134319",
    "end": "140480"
  },
  {
    "text": "data let's walk through a extremely simplified version of how syncing",
    "start": "140480",
    "end": "147120"
  },
  {
    "text": "Works imagine you have a a client could be an iPad a phone or a desktop client",
    "start": "147120",
    "end": "153599"
  },
  {
    "text": "and there's a document in your Dropbox that the client has to upload to the",
    "start": "153599",
    "end": "158800"
  },
  {
    "text": "cloud the first thing that it does is it takes the document and separates it out",
    "start": "158800",
    "end": "164239"
  },
  {
    "text": "into two parts the first part is chunks of 4 megabyte blocks which is the actual",
    "start": "164239",
    "end": "170840"
  },
  {
    "text": "content the bytes in your file and the second part is what we call the metadata about the file uh the file name the path",
    "start": "170840",
    "end": "178120"
  },
  {
    "text": "on your computer where the file is located the revision number the actual list of blocks keyed by the hash of the block",
    "start": "178120",
    "end": "184959"
  },
  {
    "text": "which constitute that file and several other attributes which we use to provide a richer experience and use it to make",
    "start": "184959",
    "end": "191280"
  },
  {
    "text": "sure the syncing is done correctly once this is done the client takes the",
    "start": "191280",
    "end": "197879"
  },
  {
    "text": "metadata of the file and sends it to our servers and our data centers asking to",
    "start": "197879",
    "end": "203120"
  },
  {
    "text": "say hey can you commit a new revision of a file so if it's a new file this will be revision one on getting this request",
    "start": "203120",
    "end": "211280"
  },
  {
    "text": "the first thing that the servers do is check whether we have the blocks before we commit a new version obviously if we",
    "start": "211280",
    "end": "217599"
  },
  {
    "text": "commit a new version and we don't have the block that's a bad thing so if it's a new file as in this case we'll end up",
    "start": "217599",
    "end": "222799"
  },
  {
    "text": "saying no we don't have the blocks we have never seen this file before and tell the client that you need to upload",
    "start": "222799",
    "end": "228959"
  },
  {
    "text": "the blocks before we can commit a new file on receiving this message the client knows that now it has to upload",
    "start": "228959",
    "end": "235480"
  },
  {
    "text": "the uh the blocks so it takes these blocks sends us sends them to our server was running in AWS and ask us to put",
    "start": "235480",
    "end": "242560"
  },
  {
    "text": "them in S3 and this is where we actually store the content of your files in S3 in 4 megabyte blocks once that is done the",
    "start": "242560",
    "end": "250799"
  },
  {
    "text": "servers then notify both the client hey the blocks have successfully uploaded but also our servers and Dropbox data",
    "start": "250799",
    "end": "257560"
  },
  {
    "text": "centers to make sure that we record the fact that we have these three or four new blocks in our",
    "start": "257560",
    "end": "263520"
  },
  {
    "text": "repository once this is done the client again then goes back to our service and saying look you told me to upload the",
    "start": "263520",
    "end": "268560"
  },
  {
    "text": "blocks I did that can you now commit a new revision of a file and again our",
    "start": "268560",
    "end": "273800"
  },
  {
    "text": "servers do the same thing they check whether we have the blocks or not but since we had already updated the information that we did upload this",
    "start": "273800",
    "end": "280160"
  },
  {
    "text": "blocks this time the servers will find that we do have the blocks and",
    "start": "280160",
    "end": "285680"
  },
  {
    "text": "essentially tell the uh tell our clients that the commit is done and this is when essentially a file is",
    "start": "285680",
    "end": "292880"
  },
  {
    "text": "synced obviously this is an extremely simplified uh version of housing King works we have to in reality take a",
    "start": "292880",
    "end": "299240"
  },
  {
    "text": "handle lot of edge cases across different platforms uh there are bugs or features depending on what you want to",
    "start": "299240",
    "end": "305120"
  },
  {
    "text": "call them on each of these operating systems which we have to take care of uh we have to handle things like people",
    "start": "305120",
    "end": "310360"
  },
  {
    "text": "going offline or shutting down their laptops while the syncing is happening as well as multiple clients trying to",
    "start": "310360",
    "end": "316120"
  },
  {
    "text": "update the same file but hopefully this gives you a a very broad General sense of how our",
    "start": "316120",
    "end": "323280"
  },
  {
    "text": "infrastructure is able to do what is the core functionality of our product which is to synchronize data from your devices",
    "start": "323280",
    "end": "328840"
  },
  {
    "text": "onto the cloud what might be a surprise for a lot of you guys is that while syncing is an",
    "start": "328840",
    "end": "335120"
  },
  {
    "text": "extremely important and one of the reasons drbox became so popular it is actually a very very small part of what",
    "start": "335120",
    "end": "341360"
  },
  {
    "text": "we do what we find is users who are using Dropbox heavily are not using it to",
    "start": "341360",
    "end": "348840"
  },
  {
    "text": "synchronize and back up their data they are actually using it to share their files with each other there are people",
    "start": "348840",
    "end": "355160"
  },
  {
    "text": "who come from wedding trips or vacations they upload all their thousands of photographs and then share it with their",
    "start": "355160",
    "end": "360280"
  },
  {
    "text": "friends uh parents are using Dropbox to share videos of their kids' birthday with the grandparents uh people at work",
    "start": "360280",
    "end": "367319"
  },
  {
    "text": "use Dropbox to collaborate on documents to be able to work on an Excel sheet or an Office document remember as I",
    "start": "367319",
    "end": "373639"
  },
  {
    "text": "mentioned we are probably the one of the largest repository in the in the world for office documents and in a lot of",
    "start": "373639",
    "end": "379400"
  },
  {
    "text": "ways improve their productivity and in all these use cases it is simply not enough for us to be",
    "start": "379400",
    "end": "385639"
  },
  {
    "text": "able to just synchronize the bits of a file across different devices and make sure we you you never lose them we",
    "start": "385639",
    "end": "391440"
  },
  {
    "text": "actually have to add value on top of the data uh we have to make sure that when you're using Dropbox you're not only",
    "start": "391440",
    "end": "397039"
  },
  {
    "text": "getting the access to the data but are also able to improve your productivity or make the workflows about sharing and",
    "start": "397039",
    "end": "402479"
  },
  {
    "text": "collaboration better and we call this essentially bringing your data to life",
    "start": "402479",
    "end": "408039"
  },
  {
    "text": "uh for example we would like to be able to generate thumbnails when you upload photos from your fancy SLR camera so",
    "start": "408039",
    "end": "414280"
  },
  {
    "text": "that when you share your photos with someone who has an Android phone they can view the photos immediately on the",
    "start": "414280",
    "end": "419720"
  },
  {
    "text": "phone we want to be able to generate previews for your Microsoft Office documents uh so that when I'm working on",
    "start": "419720",
    "end": "425599"
  },
  {
    "text": "a on a presentation like this and I want to send it to my colleagues to get some comments they can quickly look at the",
    "start": "425599",
    "end": "431599"
  },
  {
    "text": "presentation on a web view as opposed to opening it on a native application another very good example of",
    "start": "431599",
    "end": "437879"
  },
  {
    "text": "how we can leverage uh our infrastructure to bring data to life is something we recently launched for",
    "start": "437879",
    "end": "443759"
  },
  {
    "text": "Dropbox or business which is a full teex search across all the documents remember",
    "start": "443759",
    "end": "448800"
  },
  {
    "text": "the the scale we're talking about is again more than 35 billion office documents and allowing people to access",
    "start": "448800",
    "end": "455120"
  },
  {
    "text": "their Dropbox and be able to search through the content of the document was one of the biggest and most frequently",
    "start": "455120",
    "end": "460680"
  },
  {
    "text": "Asked feature from our customers and what people would end up doing is they would have a large Dropbox where they're",
    "start": "460680",
    "end": "467400"
  },
  {
    "text": "literally working out of it but they cannot synchronize all their content into their native uh desktop or PCS and",
    "start": "467400",
    "end": "473680"
  },
  {
    "text": "they would want to be able to search the content to know what files they were working on and there a lot more examples",
    "start": "473680",
    "end": "479960"
  },
  {
    "text": "like this uh example another example could be video transcoding uh we videos is something which is extremely personal",
    "start": "479960",
    "end": "485560"
  },
  {
    "text": "for people they don't want to lose it but they also want to be able to view the videos across multiple platforms which means we have to transport these",
    "start": "485560",
    "end": "491400"
  },
  {
    "text": "videos in infrastructure so a common theme uh which hopefully you guys are getting a",
    "start": "491400",
    "end": "497479"
  },
  {
    "text": "sense is that a big part of our infrastructure is bringing data to life",
    "start": "497479",
    "end": "503080"
  },
  {
    "text": "and in order to do that what we need to do is run extremely large workloads",
    "start": "503080",
    "end": "510080"
  },
  {
    "text": "to process the files as they're being updated or uploaded to Dropbox and if you may notice these",
    "start": "510080",
    "end": "516680"
  },
  {
    "text": "workloads essentially can generate either metadata um examples could be exf",
    "start": "516680",
    "end": "522159"
  },
  {
    "text": "data from um photos which allows us to sort your photos based on an attribute",
    "start": "522159",
    "end": "527560"
  },
  {
    "text": "or actually generate files like thumbnails of different sizes so that you can view them on your iPad your",
    "start": "527560",
    "end": "533519"
  },
  {
    "text": "Kindle Fire on your phones as well on on web the challenge for us though is",
    "start": "533519",
    "end": "540320"
  },
  {
    "text": "unlike a lot of these large massive workloads which people want to run uh in a batch uh in a batch mode these",
    "start": "540320",
    "end": "547399"
  },
  {
    "text": "workloads require us to be extremely low latency and the underlying need for this",
    "start": "547399",
    "end": "554920"
  },
  {
    "text": "is the fact that people are now collaborating and sharing in almost Real Time Imagine uh a person uh called Sam",
    "start": "554920",
    "end": "563440"
  },
  {
    "text": "who is working late in the night trying furiously to finish up a report that's due in a couple of days and he feels",
    "start": "563440",
    "end": "569880"
  },
  {
    "text": "that he has something which he would love Alice to take a look at so he uses Dropbox he sends a link from Dropbox to",
    "start": "569880",
    "end": "577360"
  },
  {
    "text": "his colleague Alice and says hey check out the new updated dog now in the old days without the world which is now hard",
    "start": "577360",
    "end": "584079"
  },
  {
    "text": "to imagine but when we did not have our smartphones or our tablets it probably was reasonable to expect that Alice",
    "start": "584079",
    "end": "589959"
  },
  {
    "text": "would probably get to checking her email in the morning she would probably get to reading this document in like maybe four",
    "start": "589959",
    "end": "596399"
  },
  {
    "text": "hours maybe a day uh but if she's anything like anyone of us in this room she probably has a phone which is she's",
    "start": "596399",
    "end": "602920"
  },
  {
    "text": "constantly checking her email so what will happen is she will check her email look at the link and immediately want to",
    "start": "602920",
    "end": "608560"
  },
  {
    "text": "see the preview of this document and if Dropbox is not able to",
    "start": "608560",
    "end": "613760"
  },
  {
    "text": "generate a preview of this document this extremely short time span the product",
    "start": "613760",
    "end": "619560"
  },
  {
    "text": "looks extremely broken people will not understand that this is a hard problem people will not understand it takes time",
    "start": "619560",
    "end": "625320"
  },
  {
    "text": "they will say Dropbox doesn't work and that simply goes against what we believe in that Dropbox should just make things",
    "start": "625320",
    "end": "631680"
  },
  {
    "text": "happen magically so that's the number one challenge we have to run this massive",
    "start": "631680",
    "end": "637079"
  },
  {
    "text": "worklow but they need to be as fast as possible um at our scale we have another",
    "start": "637079",
    "end": "642279"
  },
  {
    "text": "unique challenge uh we also have to make sure these things run at a very high high throughput um to give you a sense",
    "start": "642279",
    "end": "648680"
  },
  {
    "text": "of the scale we're talking about uh what we typically see is tens of thousands of files need to be processed every second",
    "start": "648680",
    "end": "655519"
  },
  {
    "text": "and each of this file by the way generates more than one workload because you can imagine a file has to be processed by multiple systems to",
    "start": "655519",
    "end": "662680"
  },
  {
    "text": "generate thumbnails to extract exf data of in case of a document we need to process it to index it for search as",
    "start": "662680",
    "end": "669720"
  },
  {
    "text": "well as generate previews as if that was not enough uh we",
    "start": "669720",
    "end": "675320"
  },
  {
    "text": "are in the business of storing users content and users content can vary from small photos to extremely high",
    "start": "675320",
    "end": "682000"
  },
  {
    "text": "resolution photographs taken by SLR cameras or documents which are onepage to 50-page Legal contracts um so there's",
    "start": "682000",
    "end": "689800"
  },
  {
    "text": "a huge amount of variability in terms of workloads we have to do on the content moreover the actual workload also",
    "start": "689800",
    "end": "695800"
  },
  {
    "text": "changes a lot so transcoding a video can take tens of seconds whereas some other",
    "start": "695800",
    "end": "701200"
  },
  {
    "text": "operations can take a few milliseconds and if folks have designed systems uh handling variability in your input is",
    "start": "701200",
    "end": "707600"
  },
  {
    "text": "actually one of the most challenging tasks when you come when it comes to performance last but not the least uh",
    "start": "707600",
    "end": "715560"
  },
  {
    "text": "all of us live in a world where Innovation is the key to survival and one of the things which we found uh and",
    "start": "715560",
    "end": "721720"
  },
  {
    "text": "we firmly believe is that not only we have to build an infrastructure which allows us to do this we also have it",
    "start": "721720",
    "end": "727800"
  },
  {
    "text": "have to make it very easy for developers to add new kind of processing to the system so they shouldn't have to go",
    "start": "727800",
    "end": "734079"
  },
  {
    "text": "through this lengthy cycle of testing or making significant changes to the framework to add just another",
    "start": "734079",
    "end": "740279"
  },
  {
    "text": "workload so to recap the challenge we are facing is we have to have a system",
    "start": "740279",
    "end": "746560"
  },
  {
    "text": "which lets us run massive workloads with very low latency with a high throughput",
    "start": "746560",
    "end": "752160"
  },
  {
    "text": "um can handle variable workload which can range from tens of seconds of processing to a few milliseconds uh as",
    "start": "752160",
    "end": "758240"
  },
  {
    "text": "well as flexible architecture which allows developers to be able to dynamically change what gets processed",
    "start": "758240",
    "end": "764120"
  },
  {
    "text": "and how it gets processed if you had to take a step back",
    "start": "764120",
    "end": "769399"
  },
  {
    "text": "and think about how we would solve this in a extremely knif way uh going back to how I described the syncing one can",
    "start": "769399",
    "end": "776040"
  },
  {
    "text": "imagine that the first thing you might do is you know the moment you a new revision you know that you have a new",
    "start": "776040",
    "end": "781279"
  },
  {
    "text": "file that you need to process so why don't we actually go to Amazon get the",
    "start": "781279",
    "end": "786440"
  },
  {
    "text": "file and start processing uh it would work uh and once",
    "start": "786440",
    "end": "793120"
  },
  {
    "text": "the processing is done we store the we store the generated files back on hisory",
    "start": "793120",
    "end": "799040"
  },
  {
    "text": "as well as metadata in our databases uh this would work but I'm pretty sure some of you already noticing",
    "start": "799040",
    "end": "805120"
  },
  {
    "text": "that this has a few issues the first one is extremely highlen remember that we talked about what we need to do is we",
    "start": "805120",
    "end": "811920"
  },
  {
    "text": "want to make sure this entire processing happens as quickly as possible in this particular implementation we are shipping a lot of data potentially tens",
    "start": "811920",
    "end": "819079"
  },
  {
    "text": "of megabytes of data of a file in case of videos it can be easily a gigabyte of uh a video which people upload uh across",
    "start": "819079",
    "end": "826639"
  },
  {
    "text": "data centers uh it also has a huge cost to network bandwidth and for something",
    "start": "826639",
    "end": "832639"
  },
  {
    "text": "like us where the scale is huge we're talking about hundreds of gig gigabits of bandwidth this is an expensive",
    "start": "832639",
    "end": "840000"
  },
  {
    "text": "currency to pay just to do this processing so obviously we would like to avoid that you might you might think that you",
    "start": "840000",
    "end": "847600"
  },
  {
    "text": "know this this is an easy problem to solve so instead of shipping the data all the way from Amazon to our data centers to process it why don't we do",
    "start": "847600",
    "end": "854040"
  },
  {
    "text": "the opposite why don't we actually have our data centers send an RPC with some",
    "start": "854040",
    "end": "859279"
  },
  {
    "text": "relevant information about the file and say hey a server in ec2 can you actually process this file and I'll wait for the",
    "start": "859279",
    "end": "865880"
  },
  {
    "text": "metadata on receiving this request the servers can proc process the file they can actually uh do transcoding thumbnail",
    "start": "865880",
    "end": "872800"
  },
  {
    "text": "generation extracting um exf data from photos generating previews and once",
    "start": "872800",
    "end": "878040"
  },
  {
    "text": "that's done it stores the large files on S3 which is cheap because it's within Amazon and then ships the metadata back",
    "start": "878040",
    "end": "884880"
  },
  {
    "text": "to our data center to store it in our databases now this solves the latency",
    "start": "884880",
    "end": "892120"
  },
  {
    "text": "problem and the network problem to a large extent we are no longer shipping potentially tens of megabits or even a",
    "start": "892120",
    "end": "897560"
  },
  {
    "text": "gigabit of data between our data centers the latency should be low uh but uh this",
    "start": "897560",
    "end": "903720"
  },
  {
    "text": "is where the fact that we store user content bites us it's still does not handle the problem of variable workload",
    "start": "903720",
    "end": "909759"
  },
  {
    "text": "gracefully since our servers are making rpcs which can result in workloads which",
    "start": "909759",
    "end": "915560"
  },
  {
    "text": "can last up to tens of seconds we see issues we can easily see issues where rpcs either time out due to network",
    "start": "915560",
    "end": "921600"
  },
  {
    "text": "issues resulting in a higher failure or we'll run into load balancing issues uh",
    "start": "921600",
    "end": "927320"
  },
  {
    "text": "because some jobs will finish quickly and it's very hard to be able to make sure all servers get equal amount of",
    "start": "927320",
    "end": "932920"
  },
  {
    "text": "load this system is also going to be extremely susceptible to backlogs because you essentially have a monic",
    "start": "932920",
    "end": "938920"
  },
  {
    "text": "system which is saying for every file I'm going to start making RPC you can easily imagine that a particular kind of",
    "start": "938920",
    "end": "946000"
  },
  {
    "text": "file can slow down the entire pipeline so if tomorrow Apple decides to launch a new iPhone which has a fancy new video",
    "start": "946000",
    "end": "953160"
  },
  {
    "text": "format and the one of the first things a lot of people do when they buy their new iPhone is download Dropbox we might",
    "start": "953160",
    "end": "959000"
  },
  {
    "text": "finally see a surge in uh videos being uploaded which take longer for us to",
    "start": "959000",
    "end": "964319"
  },
  {
    "text": "transcode that will not only impact videos in this case it will also impact",
    "start": "964319",
    "end": "969399"
  },
  {
    "text": "all other processing of all the documents Your Word documents will not get processed your photos will not get",
    "start": "969399",
    "end": "974560"
  },
  {
    "text": "processed which is not a good user experience the last but not the least is",
    "start": "974560",
    "end": "980680"
  },
  {
    "text": "uh it's actually very hard to change or add new dat workloads because the moment you're doing this it changes your",
    "start": "980680",
    "end": "986880"
  },
  {
    "text": "network pattern you have to modify both was on our data centers as well as AWS",
    "start": "986880",
    "end": "992399"
  },
  {
    "text": "uh and any change this system has to be caned and tested very carefully which goes against what our original goal was",
    "start": "992399",
    "end": "999199"
  },
  {
    "text": "we want to build a flexible architecture",
    "start": "999199",
    "end": "1004319"
  },
  {
    "text": "so how did we solve this in Dropbox um in Dropbox we we took a first",
    "start": "1004319",
    "end": "1011000"
  },
  {
    "text": "principle approach and I built this in-house system which we call Life uh which is a highly scalable and",
    "start": "1011000",
    "end": "1018079"
  },
  {
    "text": "configurable system system which allows us to run various kinds of workloads uh workloads which can span seconds to",
    "start": "1018079",
    "end": "1025079"
  },
  {
    "text": "milliseconds uh in a graceful manner on files as they're updated in Dropbox in real time this system has a lot of",
    "start": "1025079",
    "end": "1033558"
  },
  {
    "text": "interesting properties uh it uses sqs as a control",
    "start": "1033559",
    "end": "1038959"
  },
  {
    "text": "panel to be able to manage uh how to coordinate and distribute the processing of files it is not only highly scalable",
    "start": "1038959",
    "end": "1046600"
  },
  {
    "text": "and reliable it also handles the aable workloads extremely gracefully and the best thing of all it is very very",
    "start": "1046600",
    "end": "1053679"
  },
  {
    "text": "trivial to add new workload to the system as I'll show you in a few slides but before we get into the",
    "start": "1053679",
    "end": "1059840"
  },
  {
    "text": "details of how life will works uh and how we were able to scale it up um I",
    "start": "1059840",
    "end": "1066000"
  },
  {
    "text": "want to walk through a few Concepts on which life Phill is based on so one of the key insights which we had which we",
    "start": "1066000",
    "end": "1072760"
  },
  {
    "text": "used to build life was that all of these workloads or jobs which we run or we",
    "start": "1072760",
    "end": "1078520"
  },
  {
    "text": "want to run on our files can be modeled as series of handlers think of handlers as modules or",
    "start": "1078520",
    "end": "1086360"
  },
  {
    "text": "classes which take an input or a function uh which take an input of a certain kind uh it could be a file of a",
    "start": "1086360",
    "end": "1093240"
  },
  {
    "text": "certain type or it could be binary blob in a format say protocol buffers and outputs uh outputs data of a certain",
    "start": "1093240",
    "end": "1101919"
  },
  {
    "text": "kind as well which again could be a file or it could be a binary blob and these handlers can consume output from each",
    "start": "1101919",
    "end": "1108799"
  },
  {
    "text": "each other um and can and use message cues to communicate with each other now",
    "start": "1108799",
    "end": "1114440"
  },
  {
    "text": "with this abstraction suddenly you can start thinking of stitching together these series of handlers to create what effectively is a data pipeline or",
    "start": "1114440",
    "end": "1121600"
  },
  {
    "text": "something which can handle a particular workload so you can imagine that you can define a data pipeline which says uh I",
    "start": "1121600",
    "end": "1127240"
  },
  {
    "text": "will take a photo and run these handlers in this order and in the end generate the output we need to",
    "start": "1127240",
    "end": "1132720"
  },
  {
    "text": "have we also introduced a notion of virtual clusters and this was actually extremely important for us to uh make a",
    "start": "1132720",
    "end": "1139919"
  },
  {
    "text": "performance system which I'll talk in a little bit but the idea here there was that instead of having this huge large",
    "start": "1139919",
    "end": "1146400"
  },
  {
    "text": "homogeneous set of servers which can run any kind of Handler we wanted to partition these servers uh into smaller",
    "start": "1146400",
    "end": "1153559"
  },
  {
    "text": "set of clusters which are configured to run only a specific set of handlers and",
    "start": "1153559",
    "end": "1159240"
  },
  {
    "text": "each of these clusters was associated with the sqsq which was one was an inbound one was an outbound and these",
    "start": "1159240",
    "end": "1166039"
  },
  {
    "text": "clusters were completely isolated from each other and with this components uh lill system",
    "start": "1166039",
    "end": "1173400"
  },
  {
    "text": "actually looks pretty simple uh at a very high level it's essentially a cluster a series of virtual clusters",
    "start": "1173400",
    "end": "1180000"
  },
  {
    "text": "remember each cluster can generate can run specific set of handlers each of these virtual clusters have a queue",
    "start": "1180000",
    "end": "1185840"
  },
  {
    "text": "attached to them and this is how they communicate with the rest of the infrastructure Dropbox and they have",
    "start": "1185840",
    "end": "1190919"
  },
  {
    "text": "access to our data and hisory so that they can read and write files back to it uh in order to make it extremely",
    "start": "1190919",
    "end": "1198840"
  },
  {
    "text": "flexible uh this entire system is configured and managed by a single yaml",
    "start": "1198840",
    "end": "1203880"
  },
  {
    "text": "file uh this file defines the system configuration it lets us know what kind",
    "start": "1203880",
    "end": "1210720"
  },
  {
    "text": "of virtual clusters are we running uh how many instances do we have in these clusters uh what handlers uh do are",
    "start": "1210720",
    "end": "1219679"
  },
  {
    "text": "allowed to run on each of these cluster and it also provides us with a configuration for each Handler which is",
    "start": "1219679",
    "end": "1225600"
  },
  {
    "text": "essentially what kind of code do you want to run for this Handler which gives us a very easy way to modify um or add",
    "start": "1225600",
    "end": "1232840"
  },
  {
    "text": "or delete handlers uh it also has a specific details about what kind of",
    "start": "1232840",
    "end": "1238120"
  },
  {
    "text": "input and output this Handler is expected to consume and output as an example uh this is a",
    "start": "1238120",
    "end": "1245960"
  },
  {
    "text": "snippet from the actual configuration which we use in Dropbox uh and I've",
    "start": "1245960",
    "end": "1251400"
  },
  {
    "text": "removed a few details to make it more readable but you can see that uh the first three lines essentially talk about",
    "start": "1251400",
    "end": "1257280"
  },
  {
    "text": "we have two virtual clusters one is uh as a name suggest for Microsoft Office",
    "start": "1257280",
    "end": "1262480"
  },
  {
    "text": "the other one is for video transcoding and then we have a essentially a description of what is a data pipeline",
    "start": "1262480",
    "end": "1271200"
  },
  {
    "text": "constitutes of in this case this data pipeline is for Microsoft Office it has two handlers uh one of them takes input",
    "start": "1271200",
    "end": "1279039"
  },
  {
    "text": "in forms of files of Excel and outputs a binary blob we use protocol buffers in our infrastructure so this essentially a",
    "start": "1279039",
    "end": "1285760"
  },
  {
    "text": "protocol buffer and then there's another Handler which consumes the output of this Handler and is able to Output a",
    "start": "1285760",
    "end": "1291880"
  },
  {
    "text": "file which is essentially an HTML version of your Excel files which we can show when someone request it on on the",
    "start": "1291880",
    "end": "1298279"
  },
  {
    "text": "web and using this configuration file is extremely powerful because in order to",
    "start": "1298279",
    "end": "1303320"
  },
  {
    "text": "add clusters or remove handlers or modify the handlers or even changing the code which uh these handlers run you",
    "start": "1303320",
    "end": "1310320"
  },
  {
    "text": "essentially have to modify this config file which gets then automatically pushed to all our servers and the the",
    "start": "1310320",
    "end": "1316840"
  },
  {
    "text": "system keeps running so in this new architecture uh let's go",
    "start": "1316840",
    "end": "1323000"
  },
  {
    "text": "back and try to figure out how how we can actually run massive workloads so the first thing that changes is instead",
    "start": "1323000",
    "end": "1330679"
  },
  {
    "text": "of making an RPC uh from our data centers uh to life Phill uh we",
    "start": "1330679",
    "end": "1336799"
  },
  {
    "text": "essentially send now a message an sqs message to the cues which are listening to um from our which are tied to the",
    "start": "1336799",
    "end": "1344360"
  },
  {
    "text": "Clusters I just talked about once this message is received each",
    "start": "1344360",
    "end": "1350360"
  },
  {
    "text": "of these virtual clusters servers are constantly pulling the the queue to pick new messages and the message gets picked",
    "start": "1350360",
    "end": "1357360"
  },
  {
    "text": "by one of the servers um and based on the configuration which I just showed you it knows that for a particular file",
    "start": "1357360",
    "end": "1365240"
  },
  {
    "text": "type what handlers do we need to run so very likely the first Handler which uh",
    "start": "1365240",
    "end": "1371640"
  },
  {
    "text": "gets executed for a particular file type will fetch the file from the file execute the code which was defined in",
    "start": "1371640",
    "end": "1378200"
  },
  {
    "text": "the configuration file and then uh again using the configuration file we talked",
    "start": "1378200",
    "end": "1384080"
  },
  {
    "text": "about is essentially going to pipeline these data across series of handlers",
    "start": "1384080",
    "end": "1389360"
  },
  {
    "text": "using message Q as an intermediat to be able to uh process the file and generate",
    "start": "1389360",
    "end": "1394799"
  },
  {
    "text": "various outputs in the end what we expect is the system will generate",
    "start": "1394799",
    "end": "1399960"
  },
  {
    "text": "either some files remember that what we discussed earlier the workflows typically end up generating either files",
    "start": "1399960",
    "end": "1406120"
  },
  {
    "text": "or metadata so we can store the Met back into S3 bucket or if there's some",
    "start": "1406120",
    "end": "1411679"
  },
  {
    "text": "metadata which we have to store we push it out to the outq which then gets sent",
    "start": "1411679",
    "end": "1416880"
  },
  {
    "text": "back to our servers uh in our data centers to be written to the",
    "start": "1416880",
    "end": "1422799"
  },
  {
    "text": "databases uh and while designing the system we heavily leveraged Amazon and",
    "start": "1422799",
    "end": "1428279"
  },
  {
    "text": "sqs uh sqs was able to give us an extremely",
    "start": "1428279",
    "end": "1434600"
  },
  {
    "text": "reliable delivery of messages uh we not only could remove the complexity in",
    "start": "1434600",
    "end": "1440000"
  },
  {
    "text": "terms of dealing with failures dealing with RPC time outs or durability of uh a",
    "start": "1440000",
    "end": "1445600"
  },
  {
    "text": "particular message getting lost in the distributed system we also had no operational overhead of maintaining this",
    "start": "1445600",
    "end": "1452240"
  },
  {
    "text": "system so at a very Tech very basic level you could imagine that we could",
    "start": "1452240",
    "end": "1457520"
  },
  {
    "text": "use something like redis or rabbit mq instead of sqs but in both these systems we would have had to put in a lot of",
    "start": "1457520",
    "end": "1463679"
  },
  {
    "text": "operational work to make things as reliable as sqs gave it for free and and as we will talk in a bit it",
    "start": "1463679",
    "end": "1471279"
  },
  {
    "text": "also scales to an extremely large number of requests even at our scale we have",
    "start": "1471279",
    "end": "1476440"
  },
  {
    "text": "manage to make sure sqs uh keeps growing as we are our uh user content and the",
    "start": "1476440",
    "end": "1482720"
  },
  {
    "text": "the usage of system grows on the other side since we are actually processing our files in ec2 uh",
    "start": "1482720",
    "end": "1490880"
  },
  {
    "text": "it gives us the benefit to scale our workers very easily within seconds depending on the",
    "start": "1490880",
    "end": "1496960"
  },
  {
    "text": "workload while we don't do this right now you can easily imagine that we can uh stitch up the autoscaling feature",
    "start": "1496960",
    "end": "1503840"
  },
  {
    "text": "which Amazon provides to be able to shrink or grow these clusters as the load changes and this is something which",
    "start": "1503840",
    "end": "1510159"
  },
  {
    "text": "is extremely valuable when you are again dealing with user content where you have very little control on what gets into",
    "start": "1510159",
    "end": "1516399"
  },
  {
    "text": "your system thanks to this and a bunch of other things which Amazon provided us",
    "start": "1516399",
    "end": "1521760"
  },
  {
    "text": "we're able to build and maintain this extremely large system with a team of just two Engineers uh something I don't",
    "start": "1521760",
    "end": "1529440"
  },
  {
    "text": "think would have been possible if uh we had tried to do this completely on our",
    "start": "1529440",
    "end": "1535559"
  },
  {
    "text": "own at the same time uh while sqs and Amazon provided an extremely strong",
    "start": "1535559",
    "end": "1542120"
  },
  {
    "text": "foundation for us to build this system on uh there were a lot of things which we had to do to make it work and scale",
    "start": "1542120",
    "end": "1549240"
  },
  {
    "text": "to our level of QPS and throughput I wish I could tell you that no we designed the system we wrote up the code",
    "start": "1549240",
    "end": "1555279"
  },
  {
    "text": "and it boom it started working from day one uh it didn't um it really does there were lot of mistakes we made there were",
    "start": "1555279",
    "end": "1561960"
  },
  {
    "text": "a lot of lessons we learned both about how to use Amazon better as well as things we should think about when",
    "start": "1561960",
    "end": "1567000"
  },
  {
    "text": "designing these kind of systems and I want to share a couple of lessons we learned and hopefully that will give you",
    "start": "1567000",
    "end": "1572159"
  },
  {
    "text": "some kind of things which are useful even for the things you you're working in your own companies so one of the",
    "start": "1572159",
    "end": "1577440"
  },
  {
    "text": "first earliest lesson we learned was use batch API so when we started building",
    "start": "1577440",
    "end": "1583760"
  },
  {
    "text": "the system and we writing this code uh we essentially said oh let's just send one message per RPC uh and at the rate",
    "start": "1583760",
    "end": "1590799"
  },
  {
    "text": "at which we were sending this QPS it became very clear that that's not going to scale very well uh luckily for us sqs",
    "start": "1590799",
    "end": "1598480"
  },
  {
    "text": "exposes a batched API called send messages badge which allows you to take",
    "start": "1598480",
    "end": "1603720"
  },
  {
    "text": "10 messages at the same time and send them in one RPC call instead of one message at a time and by doing that we",
    "start": "1603720",
    "end": "1611080"
  },
  {
    "text": "were we found that we could scale much much better than uh uh what we were doing by just using uh a single API",
    "start": "1611080",
    "end": "1620240"
  },
  {
    "text": "the second interesting uh lesson we learned this was somewhere in the middle of Designing the system and I call it",
    "start": "1620440",
    "end": "1626760"
  },
  {
    "text": "simply as uh let's not try to be too clever and let let's let sqs do all the",
    "start": "1626760",
    "end": "1631840"
  },
  {
    "text": "heavy lifting um so one of the the ideas we had which was to improve the",
    "start": "1631840",
    "end": "1637159"
  },
  {
    "text": "performance of our system was that whenever a Handler has free Cycles free",
    "start": "1637159",
    "end": "1642559"
  },
  {
    "text": "CPU Cycles to process a message instead of it then going to sqs which is an RPC",
    "start": "1642559",
    "end": "1647679"
  },
  {
    "text": "call fetching the message and starting to process can we actually aggressively",
    "start": "1647679",
    "end": "1652960"
  },
  {
    "text": "prefetch these messages and store them in memory for the Handler and the idea",
    "start": "1652960",
    "end": "1658279"
  },
  {
    "text": "being that uh this will allow a Handler to essentially quickly when it finishes",
    "start": "1658279",
    "end": "1663399"
  },
  {
    "text": "up with a particular processing of a particular message it can quickly look up in its memory and start processing the next message seemed simple it should",
    "start": "1663399",
    "end": "1670919"
  },
  {
    "text": "theoretically cut down the round trip time you're making for every uh new message but as it turned out it was a",
    "start": "1670919",
    "end": "1678559"
  },
  {
    "text": "pretty bad idea uh and particularly for our use case where the workloads were",
    "start": "1678559",
    "end": "1683679"
  },
  {
    "text": "extremely variable uh what we noticed was what would happen is a server since",
    "start": "1683679",
    "end": "1690600"
  },
  {
    "text": "remember there are like multiple servers doing this in a virtual cluster one server would aggressively prefetch a lot",
    "start": "1690600",
    "end": "1696840"
  },
  {
    "text": "of messages and store them in memory but then all these messages would get backlogged behind a specific message uh",
    "start": "1696840",
    "end": "1704600"
  },
  {
    "text": "or workload that say is taking tens of seconds it could be be transcoding a video which is very long and at the same",
    "start": "1704600",
    "end": "1712240"
  },
  {
    "text": "time we had other servers which were ideal which could have actually handle these messages but since the message was",
    "start": "1712240",
    "end": "1718399"
  },
  {
    "text": "already claimed by the server our through put reduced so we would see these unevenness in terms of some",
    "start": "1718399",
    "end": "1725600"
  },
  {
    "text": "servers being extremely idle some servers actually processing at their full capacity but our overall throughput",
    "start": "1725600",
    "end": "1732120"
  },
  {
    "text": "would not scale as much as we would like so we changed it back where we said prefetching of these messages does does",
    "start": "1732120",
    "end": "1738279"
  },
  {
    "text": "not work and wanted to uh and let handlers fetch the message",
    "start": "1738279",
    "end": "1743880"
  },
  {
    "text": "as they're able to process them uh the third lesson which we still",
    "start": "1743880",
    "end": "1750519"
  },
  {
    "text": "follow is almost an axium which is we have to make sure the the the pending messages Quee on sqs is almost always",
    "start": "1750519",
    "end": "1759039"
  },
  {
    "text": "always near zero this is essentially the the biggest signal you will have in",
    "start": "1759039",
    "end": "1764279"
  },
  {
    "text": "terms of whether your capacity to process incoming uh load is higher than",
    "start": "1764279",
    "end": "1769600"
  },
  {
    "text": "what you are seeing from your clients uh you can consider using Autos",
    "start": "1769600",
    "end": "1774760"
  },
  {
    "text": "scaling as I mentioned before to scale up your workers uh if the load increases but watching this and making sure that",
    "start": "1774760",
    "end": "1781720"
  },
  {
    "text": "we react to this is extremely important part of this design uh if things start backing up bad things will happen",
    "start": "1781720",
    "end": "1789600"
  },
  {
    "text": "however no matter how well you do capacity planning you can use autoscaling you can build and have good",
    "start": "1789600",
    "end": "1795120"
  },
  {
    "text": "quality control in a system all of us know bad things can happen uh in this",
    "start": "1795120",
    "end": "1800600"
  },
  {
    "text": "case it could be because of an increased workload as I mentioned uh we don't control the content users are uploading",
    "start": "1800600",
    "end": "1806919"
  },
  {
    "text": "to Dropbox something might change on their devices something might happen where Google or Apple launches a new",
    "start": "1806919",
    "end": "1813679"
  },
  {
    "text": "phone and suddenly we see a far higher resolution photos than what we were seeing earlier and there could be bugs",
    "start": "1813679",
    "end": "1819799"
  },
  {
    "text": "we have actually shot ourselves in the foot a lot of more times than what I would like to admit here where we have",
    "start": "1819799",
    "end": "1825320"
  },
  {
    "text": "introduced delays in our processing and made things slower or network issues uh things like fetching files from S3 could",
    "start": "1825320",
    "end": "1832720"
  },
  {
    "text": "become very slow which can cause uh issues in the system but all of these uh",
    "start": "1832720",
    "end": "1838760"
  },
  {
    "text": "causes often result in a in a common symptom which is backlog what you end up starting seeing is that the messages",
    "start": "1838760",
    "end": "1845279"
  },
  {
    "text": "which are being built up the number of pending messages in sqs is growing yeah and it doesn't seem to be uh decreasing",
    "start": "1845279",
    "end": "1852720"
  },
  {
    "text": "with time and in this state it is actually very very easy to enter a state",
    "start": "1852720",
    "end": "1858480"
  },
  {
    "text": "where system will not recover unless you start aggressively shutting down the input traffic coming to the system which",
    "start": "1858480",
    "end": "1864760"
  },
  {
    "text": "is an extremely bad experience for our users so the key here is while making",
    "start": "1864760",
    "end": "1869840"
  },
  {
    "text": "sure that in steady state things work but also building enough logic and and smartness in your system that graceful",
    "start": "1869840",
    "end": "1876559"
  },
  {
    "text": "degradation and automatic recovery is a first class Citizen and that's what we spent a lot of time actually building in",
    "start": "1876559",
    "end": "1883120"
  },
  {
    "text": "our system uh to make sure whenever any of the issues like bugs or happen it",
    "start": "1883120",
    "end": "1889120"
  },
  {
    "text": "does degrade the service but it does it in an extremely graceful manner minimizing the impact to the least",
    "start": "1889120",
    "end": "1894159"
  },
  {
    "text": "number of users as opposed to the entire system falling over so the first step there uh which uh was again a very good",
    "start": "1894159",
    "end": "1903120"
  },
  {
    "text": "learning experience for us was building deep insight into our system in",
    "start": "1903120",
    "end": "1909000"
  },
  {
    "text": "extremely complicated data pip planning system it is extremely hard to know what is causing a backlog as I explained uh",
    "start": "1909000",
    "end": "1916799"
  },
  {
    "text": "the causes could be anything it could be network issues it could be bug it could be new code it could be new content um",
    "start": "1916799",
    "end": "1923080"
  },
  {
    "text": "but all you see is a backlog so being able to dig deep into the system and see where the issues are happening required",
    "start": "1923080",
    "end": "1930120"
  },
  {
    "text": "us to invest in building extremely powerful profilers of this entire pipeline we instrumented the code and",
    "start": "1930120",
    "end": "1936679"
  },
  {
    "text": "built tooling so that we could exactly know which part of the system is slowing down and why is it slowing down is it",
    "start": "1936679",
    "end": "1941760"
  },
  {
    "text": "because of the code or the data or some other physical infrastructure issues and whenever we thought that we had an",
    "start": "1941760",
    "end": "1947960"
  },
  {
    "text": "instrumentation something would happen and we would have to go back and add more stuff so this is something which I wish again I could say I think we are",
    "start": "1947960",
    "end": "1954760"
  },
  {
    "text": "done but as we are scaling the system we find that there is no such thing as enough monitoring we we want to keep",
    "start": "1954760",
    "end": "1960320"
  },
  {
    "text": "adding more and more once we had this inside uh we also wanted to make sure",
    "start": "1960320",
    "end": "1965639"
  },
  {
    "text": "that we are able to uh recover gracefully and not recover human Intervention when something goes wrong",
    "start": "1965639",
    "end": "1972200"
  },
  {
    "text": "uh so we built inbuilt careful regation",
    "start": "1972200",
    "end": "1977519"
  },
  {
    "text": "where we built libraries where every publisher of a message was constantly looking at the Q length as I mentioned",
    "start": "1977519",
    "end": "1984519"
  },
  {
    "text": "the Q length of pending message in sqs is the best um signal you get about something being wrong in the system uh",
    "start": "1984519",
    "end": "1991279"
  },
  {
    "text": "so we built sophisticated logic around making sure whenever you try to publish a message you would look at the Q length",
    "start": "1991279",
    "end": "1998279"
  },
  {
    "text": "and stop publishing uh when the backlog is high this eases up the pressure on",
    "start": "1998279",
    "end": "2003519"
  },
  {
    "text": "the system and allows it to recover at the same time we also had to make sure",
    "start": "2003519",
    "end": "2008919"
  },
  {
    "text": "that we don't drop messages because remember these things are actually what people rely on to consume data at Dropbox so we had a separate system",
    "start": "2008919",
    "end": "2015880"
  },
  {
    "text": "which we built which would keep picking up these messages and put them in the queue at a much much slower Pace at the",
    "start": "2015880",
    "end": "2022159"
  },
  {
    "text": "same time making sure the system is not falling over but making sure that uh the",
    "start": "2022159",
    "end": "2027399"
  },
  {
    "text": "end result of something happening to a system is that for some users these updates become slower but we don't",
    "start": "2027399",
    "end": "2034000"
  },
  {
    "text": "forget about them but the majority of our users are still able to to get the experience they expect from",
    "start": "2034000",
    "end": "2040440"
  },
  {
    "text": "us so it it this entire system took us about 6 months to build with it as I",
    "start": "2040440",
    "end": "2045559"
  },
  {
    "text": "mention with the team of uh two team and thanks to the work we did and a bunch of",
    "start": "2045559",
    "end": "2050599"
  },
  {
    "text": "help we got from Amazon we are able to run the system at extremely high scale uh to give you some numbers uh at this",
    "start": "2050599",
    "end": "2058118"
  },
  {
    "text": "point we are running the system over 20 almost 25,000 cores uh spread across",
    "start": "2058119",
    "end": "2064398"
  },
  {
    "text": "five different virtual clusters uh we running as many as 23 handlers each",
    "start": "2064399",
    "end": "2069520"
  },
  {
    "text": "Handler is trying to take some kind of input and process it and output something uh we on a normal day send",
    "start": "2069520",
    "end": "2076200"
  },
  {
    "text": "about 20,000 QPS uh to sqs um but we easily burst up to as much as 300K and",
    "start": "2076200",
    "end": "2084398"
  },
  {
    "text": "this is where the power rescu comes into the play where they're able to scale themselves without us having to do",
    "start": "2084399",
    "end": "2091040"
  },
  {
    "text": "anything and uh at the current rate we are processing almost half a million",
    "start": "2091040",
    "end": "2097000"
  },
  {
    "text": "jobs per second some of these jobs are extremely timec consuming like video transport some of them take a few",
    "start": "2097000",
    "end": "2102119"
  },
  {
    "text": "milliseconds but the number of jobs we are doing with using this framework is almost half a",
    "start": "2102119",
    "end": "2107480"
  },
  {
    "text": "million but we're not done yet uh we continuing to see extremely high growth",
    "start": "2107480",
    "end": "2113480"
  },
  {
    "text": "which means the systems have to scale uh so scaling is obviously going to be a big Challenge and we're very happy to",
    "start": "2113480",
    "end": "2119839"
  },
  {
    "text": "see that Amazon and SQ is going to be an extremely important partner as well as someone who just almost makes us feel",
    "start": "2119839",
    "end": "2125320"
  },
  {
    "text": "that they are infinite resources um we also want to build automatic Regional failovers where we want to be able to",
    "start": "2125320",
    "end": "2131720"
  },
  {
    "text": "shift this traffic from one region to another region without any loss of experience for our users um we're",
    "start": "2131720",
    "end": "2137880"
  },
  {
    "text": "considering adding support for more languages right now these handlers have to be written in Python uh but we are",
    "start": "2137880",
    "end": "2144079"
  },
  {
    "text": "actively considering supporting languages like go uh as well as introducing containers to allow handlers",
    "start": "2144079",
    "end": "2149839"
  },
  {
    "text": "to uh get better isolation from each other both from a security perspective as well as making sure you're not",
    "start": "2149839",
    "end": "2155960"
  },
  {
    "text": "impacting other handlers performance um so what we talked about is is a very",
    "start": "2155960",
    "end": "2162920"
  },
  {
    "text": "specific system uh that we use to that we built to solve a problem which we had",
    "start": "2162920",
    "end": "2168680"
  },
  {
    "text": "but as I mentioned one of the goals which I had for this talk was that hopefully you guys will also get some",
    "start": "2168680",
    "end": "2174040"
  },
  {
    "text": "key takeaways from this talk I believe uh even driven computation where the",
    "start": "2174040",
    "end": "2179400"
  },
  {
    "text": "need to do some kind of processing where some file has when some event has happened maybe like a file upload or a",
    "start": "2179400",
    "end": "2185400"
  },
  {
    "text": "file update is an extremely common pattern uh and hopefully a lot of you guys already have this thing running",
    "start": "2185400",
    "end": "2191480"
  },
  {
    "text": "somewhere in your infrastructure where you need to solve this problem uh in this case we highly recommend sqs as an",
    "start": "2191480",
    "end": "2198280"
  },
  {
    "text": "extremely powerful toolkit or a framework to solve this problem uh it provides extremely high reliable",
    "start": "2198280",
    "end": "2204720"
  },
  {
    "text": "messaging queue system which as you saw we use to uh manage variable workloads",
    "start": "2204720",
    "end": "2210319"
  },
  {
    "text": "um at the same time leveraging Amazon and the elasticity which it provides to be able to handle variable workloads",
    "start": "2210319",
    "end": "2217119"
  },
  {
    "text": "where if you you are in a situation where you cannot control or anticipate the the workload you may have or you may",
    "start": "2217119",
    "end": "2223319"
  },
  {
    "text": "see from your users uh leveraging ec2 and Autos scaling is an extremely important uh thing to keep in mind and",
    "start": "2223319",
    "end": "2230560"
  },
  {
    "text": "the last but not the least uh it is very very important for systems which run",
    "start": "2230560",
    "end": "2237440"
  },
  {
    "text": "massive workloads and have high requirements on latencies and throughput to build techniques and logic to detect",
    "start": "2237440",
    "end": "2245720"
  },
  {
    "text": "and handle backlog it will happen happen in spite of all the scaling all the work which anyone does you will see issues",
    "start": "2245720",
    "end": "2252800"
  },
  {
    "text": "which will result in a backlog and while sqs and the building blocks which Amazon",
    "start": "2252800",
    "end": "2258839"
  },
  {
    "text": "uh provides are very powerful they themselves will not be able to prevent this from happening so you when you",
    "start": "2258839",
    "end": "2264920"
  },
  {
    "text": "develop your applications on top of it make sure that you actually take the time to understand where the issues can",
    "start": "2264920",
    "end": "2270960"
  },
  {
    "text": "happen and how can we gracefully degrade which is a more of an application specific um question and and this is",
    "start": "2270960",
    "end": "2278240"
  },
  {
    "text": "pretty much what I had uh for this talk as hopefully you guys found it very useful um we also have a booth uh in the",
    "start": "2278240",
    "end": "2286119"
  },
  {
    "text": "exhibition Hall if you have questions about Dropbox the scale or the problems we typically solve please come and talk",
    "start": "2286119",
    "end": "2292319"
  },
  {
    "text": "uh if you any questions I'm very happy to answer them right",
    "start": "2292319",
    "end": "2297440"
  },
  {
    "text": "now sorry can you repe how youil system",
    "start": "2301599",
    "end": "2309440"
  },
  {
    "text": "uh so the question was how did we determine the the visibility timeouts for different files and uh um different",
    "start": "2310000",
    "end": "2317400"
  },
  {
    "text": "kind of handlers which we have we used a very high visibility timeout we tried not to be too clever about uh trying to",
    "start": "2317400",
    "end": "2325200"
  },
  {
    "text": "say this um some visibility could be lower we just have a very high time out for all our",
    "start": "2325200",
    "end": "2331319"
  },
  {
    "text": "messages yes hand",
    "start": "2331319",
    "end": "2337480"
  },
  {
    "text": "user yeah so the question was can can I talk a little bit about error handling um so that that two kinds of error",
    "start": "2339599",
    "end": "2346319"
  },
  {
    "text": "handling we see uh since we deal with user content sometimes um the data is corrupted so the Handler will not be",
    "start": "2346319",
    "end": "2353440"
  },
  {
    "text": "able to uh just process or even say generate a thumbnail because the photo was a corrupted photo uh those errors",
    "start": "2353440",
    "end": "2360520"
  },
  {
    "text": "actually we have a retry mechanism where when the Handler says something went wrong we retried couple of times but if",
    "start": "2360520",
    "end": "2366480"
  },
  {
    "text": "it actually doesn't work we then put it in what we call a purgatory and we essentially say this is not going to get",
    "start": "2366480",
    "end": "2372560"
  },
  {
    "text": "fixed by itself and just we we make sure that level of errors are very low because we don't expect too much of data",
    "start": "2372560",
    "end": "2378040"
  },
  {
    "text": "being corrupt there's other kind of Errors which are more transient which might happen because of the issues which we talked about and there we essentially",
    "start": "2378040",
    "end": "2384680"
  },
  {
    "text": "hoping that R trying maybe four or five times and the the refresh the recovery process I talked about the automatic",
    "start": "2384680",
    "end": "2390760"
  },
  {
    "text": "recovery which is continuously running and picking up these messages which we failed to process covers that uh but we",
    "start": "2390760",
    "end": "2398319"
  },
  {
    "text": "do see some errors which we can't fix because the data is just",
    "start": "2398319",
    "end": "2404440"
  },
  {
    "text": "bad yeah so we we so we put the out cu and then we mark them in the databases saying these things are we code and code",
    "start": "2404720",
    "end": "2411079"
  },
  {
    "text": "giving up on these files because we can't do anything about them",
    "start": "2411079",
    "end": "2417480"
  },
  {
    "text": "yeah uh the question was any particular reason that we don't use autoscaling uh so the real honest answer",
    "start": "2418760",
    "end": "2426800"
  },
  {
    "text": "is it hasn't come up in the list of priorities for us to do um so the way I",
    "start": "2426800",
    "end": "2433119"
  },
  {
    "text": "think about Autos scaling is there are two benefits one is um it helps you save costs because then you can shrink your",
    "start": "2433119",
    "end": "2439560"
  },
  {
    "text": "clusters if you don't need them uh for us that has not been a big concern uh the other thing is it allows you to be",
    "start": "2439560",
    "end": "2447280"
  },
  {
    "text": "able to spike handle spikes which we don't anticipate in our use case what we find is spikes tend to be more where",
    "start": "2447280",
    "end": "2454599"
  },
  {
    "text": "Auto scaling will have to grow very rapidly and that doesn't very work very well for us so but definitely something",
    "start": "2454599",
    "end": "2462319"
  },
  {
    "text": "which the system allows and we may get to it when one of these things become more important yeah I three questions how do",
    "start": "2462319",
    "end": "2470560"
  },
  {
    "text": "you prevent sorry can you how do you prevent Loops okay and the other question is you mentioned that your",
    "start": "2470560",
    "end": "2476800"
  },
  {
    "text": "producers stop publishing at some point in time how do you prevent that",
    "start": "2476800",
    "end": "2482520"
  },
  {
    "text": "creating uh so the there are two questions one question was how do we prevent loops I'm presuming in the",
    "start": "2482560",
    "end": "2487920"
  },
  {
    "text": "config file uh so in the config F when people are editing the file we essentially do some very simplistic ways",
    "start": "2487920",
    "end": "2493200"
  },
  {
    "text": "to detect Loops it's not very sophisticated so technically you can create a very complicated graph uh so",
    "start": "2493200",
    "end": "2498720"
  },
  {
    "text": "while we have 23 handlers the graph which we have is still manageable where",
    "start": "2498720",
    "end": "2504160"
  },
  {
    "text": "people are not creating Loops so at some point that may become an issue but right now we have not solved it um the second",
    "start": "2504160",
    "end": "2509680"
  },
  {
    "text": "question was if the publisher stopping Q messages uh how does it impact users and",
    "start": "2509680",
    "end": "2515760"
  },
  {
    "text": "what do we do about it so when the system does go into a backlog mode we're absolutely impacting the users and in",
    "start": "2515760",
    "end": "2522119"
  },
  {
    "text": "the worst case you can imagine what happens is we are dropping say majority of the messages coming in and the",
    "start": "2522119",
    "end": "2527960"
  },
  {
    "text": "automatic recovery process then kicks in and starts putting them back in the queue at a much slower rate so in terms",
    "start": "2527960",
    "end": "2535160"
  },
  {
    "text": "of degradation it's much better than the system just kneeling over because the automatic R is saying I cannot handle",
    "start": "2535160",
    "end": "2540880"
  },
  {
    "text": "say 450,000 jobs every second but I can handle 100,000 jobs so we are able to at",
    "start": "2540880",
    "end": "2546559"
  },
  {
    "text": "least serve 20 % of our users and the system autocorrects itself as things resolve and we obviously get paged so",
    "start": "2546559",
    "end": "2553079"
  },
  {
    "text": "someone is actually using the monitoring we buil to figure out the root cause and fix that issue so that the backlog",
    "start": "2553079",
    "end": "2558839"
  },
  {
    "text": "clears up yeah",
    "start": "2558839",
    "end": "2564079"
  },
  {
    "text": "scenario uh we see a scenario where we don't see um so I think the the answer",
    "start": "2565280",
    "end": "2570839"
  },
  {
    "text": "to the question is there's a lot of Legacy infrastructure things we have built over the last seven years so when",
    "start": "2570839",
    "end": "2575960"
  },
  {
    "text": "Dropbox started uh Amazon I believe just had ec2 and S3 um so we have so much things we have",
    "start": "2575960",
    "end": "2584240"
  },
  {
    "text": "built which Amazon has now built to support other people that we already had to build internally that it's going to",
    "start": "2584240",
    "end": "2590760"
  },
  {
    "text": "be a very hard migration and it's not very obvious what it will buy us because we essentially going to be replacing",
    "start": "2590760",
    "end": "2597319"
  },
  {
    "text": "something with parity uh so it's more of a timing question but do I see if there was a",
    "start": "2597319",
    "end": "2602520"
  },
  {
    "text": "Dropbox today then I think it probably will be on AWS completely but we started 7 years back so kind of uh timing",
    "start": "2602520",
    "end": "2611640"
  },
  {
    "text": "issue",
    "start": "2611640",
    "end": "2614640"
  },
  {
    "text": "yeah so uh no so we we essentially so when we",
    "start": "2619760",
    "end": "2625720"
  },
  {
    "text": "we use pre-warming in a sense that we just spin up decent number of instances and that should technically take care of",
    "start": "2625720",
    "end": "2631920"
  },
  {
    "text": "what we think the load should be uh we don't use Auto scaling so it's not something where people can uh the system",
    "start": "2631920",
    "end": "2637839"
  },
  {
    "text": "will grow by itself but if the backlog starts increasing we essentially add enough machines to make sure that in",
    "start": "2637839",
    "end": "2643800"
  },
  {
    "text": "steady state the qes are near zero yeah it's man",
    "start": "2643800",
    "end": "2650040"
  },
  {
    "text": "right yeah soorry can",
    "start": "2650040",
    "end": "2657720"
  },
  {
    "text": "you yes that's a good question uh the question was that um sqs doesn't",
    "start": "2658359",
    "end": "2664000"
  },
  {
    "text": "guarantee once only delivery how do you manage that uh so I kind of cheated a bit so that particular",
    "start": "2664000",
    "end": "2669640"
  },
  {
    "text": "thing is handled by the metadata so remember that for every sqs we are updating both the files and the metadata",
    "start": "2669640",
    "end": "2675680"
  },
  {
    "text": "so at the end what handlers do is they make sure that when they're updating the metadata so storing another copy of the",
    "start": "2675680",
    "end": "2683160"
  },
  {
    "text": "file on his3 which is what the end result is is not that a big is not an issue from a user's perspective but it",
    "start": "2683160",
    "end": "2688839"
  },
  {
    "text": "is actually very wrong if we start updating the metadata so when we actually update the metadata we have a",
    "start": "2688839",
    "end": "2694559"
  },
  {
    "text": "kind of locking scheme which ensures that we only process processing a file once not twice but that's done in our",
    "start": "2694559",
    "end": "2700800"
  },
  {
    "text": "data centers uh on S3 we kind of just say it's okay for us to sometimes store",
    "start": "2700800",
    "end": "2706680"
  },
  {
    "text": "two copies of a block which kind gets vacuumed asynchronously",
    "start": "2706680",
    "end": "2714400"
  },
  {
    "text": "yeah uh so the question was have we considered in terms of reducing the compute cost having clients generate",
    "start": "2723480",
    "end": "2728839"
  },
  {
    "text": "compute cost um I think the in the world which everyone is moving towards which",
    "start": "2728839",
    "end": "2733960"
  },
  {
    "text": "is mobile and web based so web there's no client so people upload and they actually use a website a lot and on",
    "start": "2733960",
    "end": "2740400"
  },
  {
    "text": "phones it's obviously not going to at least in the current it's not feasible for asking phones to generate thumbnails",
    "start": "2740400",
    "end": "2745720"
  },
  {
    "text": "so we definitely don't think right now but maybe if the advances happen very quickly maybe um just doing if a desktop",
    "start": "2745720",
    "end": "2752400"
  },
  {
    "text": "PC doesn't seem valuable enough given that a lot of our users are non mobile on",
    "start": "2752400",
    "end": "2758079"
  },
  {
    "text": "and photos typically also happen through phones I mean I'm sure all of us know that so yeah I have a mic so I can be heard",
    "start": "2758079",
    "end": "2765119"
  },
  {
    "text": "very well uh do you guys use the standard a AWS Management console or do you have some internal solution or way",
    "start": "2765119",
    "end": "2772640"
  },
  {
    "text": "that you guys worked with Amazon to manage that better uh we we have to use internal tooling uh I I do believe the",
    "start": "2772640",
    "end": "2778440"
  },
  {
    "text": "console has improved a lot in the last year um but given the amount of instances we're talking about like",
    "start": "2778440",
    "end": "2783960"
  },
  {
    "text": "thousands and thousands of machines running hundreds of like the scale we have console becomes extremely high it",
    "start": "2783960",
    "end": "2791359"
  },
  {
    "text": "doesn't allow us to do things in massive so updating machines using the console doesn't work out very well so we we have",
    "start": "2791359",
    "end": "2797920"
  },
  {
    "text": "our internal tooling which is command based we don't have a",
    "start": "2797920",
    "end": "2802759"
  },
  {
    "text": "GUI",
    "start": "2803440",
    "end": "2806440"
  },
  {
    "text": "[Laughter] yeah you can join Dropbox and you'll find out",
    "start": "2811540",
    "end": "2817680"
  },
  {
    "text": "I was expecting answer but I still no no it's a good question as I said join",
    "start": "2817680",
    "end": "2822839"
  },
  {
    "text": "Dropbox and you will know oh sorry uh the question was how much do we pay Amazon every",
    "start": "2822839",
    "end": "2831680"
  },
  {
    "text": "month it's more than",
    "start": "2832920",
    "end": "2836280"
  },
  {
    "text": "$1 but but we we do believe we have one of the most important and and our relationship has been extremely good so",
    "start": "2841319",
    "end": "2846480"
  },
  {
    "text": "we have been working with Amazon for last 7 years it's it's obviously uh they have helped us skill a",
    "start": "2846480",
    "end": "2853240"
  },
  {
    "text": "lot any other questions",
    "start": "2853280",
    "end": "2858400"
  },
  {
    "text": "yeah yeah so we don't use the transcoding service which Amazon I think launched about two years maybe a year",
    "start": "2860880",
    "end": "2866880"
  },
  {
    "text": "and a half back and again this goes back to what I was mentioning earlier we build our own transporting service about 2 and a half years",
    "start": "2866880",
    "end": "2873400"
  },
  {
    "text": "back and so now we had it and at some point we may want to move but it's like",
    "start": "2873400",
    "end": "2878559"
  },
  {
    "text": "we have something that works so but yeah so we it's an in-house thing yeah I spotted what looked like",
    "start": "2878559",
    "end": "2885960"
  },
  {
    "text": "python class names in your yamamo file I was wondering what languages you use with sqs and also whether you're open",
    "start": "2885960",
    "end": "2891720"
  },
  {
    "text": "sourcing any of the what you presented today uh so the language the whole life system right now is python based uh so",
    "start": "2891720",
    "end": "2898079"
  },
  {
    "text": "we're using python for uh the entire infrastructure in terms of open sourcing we can definitely want to open sour",
    "start": "2898079",
    "end": "2904359"
  },
  {
    "text": "parts of it some of it becomes extremely specific specific to our use case uh so we may have to like re think about how",
    "start": "2904359",
    "end": "2910200"
  },
  {
    "text": "to make it more generic and useful for the entire Community uh like the handlers which we have are extremely",
    "start": "2910200",
    "end": "2915920"
  },
  {
    "text": "specific to Dropbox use case but the framework definitely can be separated out an open source which we have to",
    "start": "2915920",
    "end": "2922240"
  },
  {
    "text": "refactor code so um Dropbox use AWS uh for",
    "start": "2922240",
    "end": "2929079"
  },
  {
    "text": "provide those and other service and the Box they build their own data center how",
    "start": "2929079",
    "end": "2934440"
  },
  {
    "text": "do you compare the two different strategies so we we I think so our is both it's not",
    "start": "2934440",
    "end": "2940440"
  },
  {
    "text": "as if we just doing leveraging uh Amazon uh only we have our own data",
    "start": "2940440",
    "end": "2946880"
  },
  {
    "text": "centers as well in terms of comparison I think what our use case and our consumer",
    "start": "2946880",
    "end": "2951920"
  },
  {
    "text": "base is much wider much bigger and the growth we are seeing is is an order of magnitude different from boxes both in",
    "start": "2951920",
    "end": "2957960"
  },
  {
    "text": "terms of the data we have as well as the number of quote unquote pedabytes we upload every day so I think Amazon in",
    "start": "2957960",
    "end": "2964880"
  },
  {
    "text": "that sense has been extremely valuable for us to to be able to scale uh for box I would imagine they decid that doing",
    "start": "2964880",
    "end": "2971319"
  },
  {
    "text": "in-house makes more sense I don't know what choices they had to do but for me I",
    "start": "2971319",
    "end": "2976559"
  },
  {
    "text": "think it's a question of do you want to invest a lot in operational overhead or focus on building value on top of Amazon",
    "start": "2976559",
    "end": "2982760"
  },
  {
    "text": "which is what we would like to do so we do have our own data centers but we're very happy picking up things from Amazon",
    "start": "2982760",
    "end": "2988960"
  },
  {
    "text": "if they're ready for us to use like sqs is a good example we used sqs instead of using rabbit mq or RIS which also could",
    "start": "2988960",
    "end": "2996760"
  },
  {
    "text": "given us the same kind of",
    "start": "2996760",
    "end": "2999720"
  },
  {
    "text": "functionality all thank you guys uh hopefully you guys found the session very useful",
    "start": "3003920",
    "end": "3010200"
  }
]
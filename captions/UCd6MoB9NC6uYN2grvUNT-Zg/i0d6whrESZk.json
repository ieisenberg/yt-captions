[
  {
    "start": "0",
    "end": "120000"
  },
  {
    "text": "good morning everyone welcome to the first AWS big data Minicon",
    "start": "0",
    "end": "7040"
  },
  {
    "text": "you know I've spent most of my day yesterday talking with customers about",
    "start": "7040",
    "end": "13950"
  },
  {
    "text": "the problems they're working on how they're using our technology it's actually one of the highlights about",
    "start": "13950",
    "end": "19380"
  },
  {
    "text": "visiting it reinvent I always learn something new I'm always very impressed at what our customers are doing on top",
    "start": "19380",
    "end": "24810"
  },
  {
    "text": "of AWS but I'm also struck with the realization that for big data it really",
    "start": "24810",
    "end": "30570"
  },
  {
    "text": "is still day one for most companies in particular mainstream enterprises and I",
    "start": "30570",
    "end": "35880"
  },
  {
    "text": "suspect that's why many of you are here today is to learn more about Big Data so",
    "start": "35880",
    "end": "40980"
  },
  {
    "text": "we have an exciting date planned for you today we're going to start today however by level setting knowing that many of",
    "start": "40980",
    "end": "47489"
  },
  {
    "text": "you are learning coming here to learn about Big Data learn about what AWS offers in Big Data so we're going to",
    "start": "47489",
    "end": "53699"
  },
  {
    "text": "spend some time sharing with you how we think about Big Data the key services",
    "start": "53699",
    "end": "59160"
  },
  {
    "text": "that we build and operate for big data and what their trajectory are we're going to talk about some common",
    "start": "59160",
    "end": "65309"
  },
  {
    "text": "use cases and questions that come up and kind of diffuse those and share with you how we think and what we see is patterns",
    "start": "65309",
    "end": "71880"
  },
  {
    "text": "that customers are doctoring for dealing with big data and some of the change in their thinking then we're going to",
    "start": "71880",
    "end": "77280"
  },
  {
    "text": "include some new stuff as well an announcement a demonstration and I've got a guest speaker who's going to join",
    "start": "77280",
    "end": "82740"
  },
  {
    "text": "me Richard Freeman who's going to talk about how his company and he have actually used our services to actually",
    "start": "82740",
    "end": "88560"
  },
  {
    "text": "build a big data solution on top of AWS now after this morning talk there are",
    "start": "88560",
    "end": "94170"
  },
  {
    "text": "four parallel sessions three of which are technical presentations for our long talks that dive deep into many of the",
    "start": "94170",
    "end": "101189"
  },
  {
    "text": "many of the services and many of the techniques that I'll be discussing my opening talk I'll actually make some",
    "start": "101189",
    "end": "106200"
  },
  {
    "text": "call outs for those but each one of them has been selected to go deeper into these topics and in addition there's a",
    "start": "106200",
    "end": "111509"
  },
  {
    "text": "fourth parallel session which is a workshop as well so you have many choices to fill at your day to day and",
    "start": "111509",
    "end": "117420"
  },
  {
    "text": "i'm looking forward to many of these talks myself now i'm going to avoid introducing yet another definition for",
    "start": "117420",
    "end": "124350"
  },
  {
    "start": "120000",
    "end": "160000"
  },
  {
    "text": "big data a fifth or fourth to be but instead talk about what it really means to you and big data because of the",
    "start": "124350",
    "end": "131009"
  },
  {
    "text": "volume because of the variety of data it really forces you to innovate and make changes in how you collect how you store",
    "start": "131009",
    "end": "139190"
  },
  {
    "text": "process and analyze and share data simply put the old method simply no",
    "start": "139190",
    "end": "144350"
  },
  {
    "text": "longer work they don't scale at AWS we're innovating to try to",
    "start": "144350",
    "end": "150080"
  },
  {
    "text": "provide you with the tools the techniques the technologies that will",
    "start": "150080",
    "end": "155180"
  },
  {
    "text": "enable you to productively work with data at any scale",
    "start": "155180",
    "end": "160810"
  },
  {
    "start": "160000",
    "end": "285000"
  },
  {
    "text": "here's a sample of select services in Big Data that AWS offers and we'll move",
    "start": "160810",
    "end": "168230"
  },
  {
    "text": "through these left for left to right we have a double us Direct Connect which allows you to connect a one gigabit in a",
    "start": "168230",
    "end": "174800"
  },
  {
    "text": "10 gigabit ethernet from your company to AWS so that you can move data you can",
    "start": "174800",
    "end": "180590"
  },
  {
    "text": "take advantage of compute we have AWS import export to can move massive volumes of data into AWS as long as amaz",
    "start": "180590",
    "end": "188690"
  },
  {
    "text": "as well as amazon kinesis that allows you to move streaming data from continually generated devices and",
    "start": "188690",
    "end": "194120"
  },
  {
    "text": "sensors in database where you can store it in an array of storage services such as Amazon s3",
    "start": "194120",
    "end": "199900"
  },
  {
    "text": "DynamoDB you can move it into analytic services such as Amazon EMR Amazon",
    "start": "199900",
    "end": "205880"
  },
  {
    "text": "redshift should you want to backup your data you can back it up into glacier for less than a penny per gigabyte per month",
    "start": "205880",
    "end": "212540"
  },
  {
    "text": "for archival purposes should you want to move your databases from on Prem either one time or",
    "start": "212540",
    "end": "218240"
  },
  {
    "text": "continuously replicating it you can use AWS data migration service to move your",
    "start": "218240",
    "end": "223340"
  },
  {
    "text": "data to Aurora or to Amazon RDS as well and you can set up AWS data pipeline to",
    "start": "223340",
    "end": "229370"
  },
  {
    "text": "automate and schedule your big data processing workloads simply put as files land in AWS every day a pipeline could",
    "start": "229370",
    "end": "236480"
  },
  {
    "text": "kick off to process them and load your analytic server so when you come in at nine in the morning the reports are ready for you to look at",
    "start": "236480",
    "end": "243880"
  },
  {
    "text": "in 2016 alone we introduced 1000 new service features new service",
    "start": "243880",
    "end": "250970"
  },
  {
    "text": "improvements and new services the pace of innovation in AWS is blistering and in fact two of the server's services",
    "start": "250970",
    "end": "258079"
  },
  {
    "text": "listed up on that chart we're just introduced in the last few months amazon quick site amazon kinesis analytics and",
    "start": "258080",
    "end": "264680"
  },
  {
    "text": "i can guarantee you that after the keynotes tomorrow and on Thursday will be completely reworking",
    "start": "264680",
    "end": "270400"
  },
  {
    "text": "these slides because the family of big data services is in fact growing and all of these services are available to you",
    "start": "270400",
    "end": "275860"
  },
  {
    "text": "with a few mouse clicks so let's go ahead and look at a few select ones that I want to make sure you",
    "start": "275860",
    "end": "281380"
  },
  {
    "text": "understand how we feel perceive their role arguably the foundation for big data on",
    "start": "281380",
    "end": "288220"
  },
  {
    "start": "285000",
    "end": "433000"
  },
  {
    "text": "AWS is s3 it is an object store where you can store virtually any kind of data",
    "start": "288220",
    "end": "294010"
  },
  {
    "text": "on AWS from ordinary flat files to binary objects ranging from video images",
    "start": "294010",
    "end": "300930"
  },
  {
    "text": "seismograms you name it you can store it on AWS s3 and it's extremely low cost 25",
    "start": "300930",
    "end": "307810"
  },
  {
    "text": "cents per gigabyte per month and it's from the customer point of view it is effectively effectively infinitely",
    "start": "307810",
    "end": "314320"
  },
  {
    "text": "scalable there's no limit to what you can store into into s3 we're going to come back onto this later because",
    "start": "314320",
    "end": "319450"
  },
  {
    "text": "because it is a key point and more importantly once data has been put into s3 it's accessible by virtually every",
    "start": "319450",
    "end": "326730"
  },
  {
    "text": "single service on AWS has access to that data and again we're going to come back to that as an architectural best",
    "start": "326730",
    "end": "332830"
  },
  {
    "text": "practice for actually building big data on AWS we launched s3 back in two",
    "start": "332830",
    "end": "338380"
  },
  {
    "text": "thousand six at the time it was an innovative pay-as-you-go model the first of its kind charging 15 cents per",
    "start": "338380",
    "end": "345250"
  },
  {
    "text": "gigabyte per month over the last ten years we have made a series of price reductions in the most recent was just a",
    "start": "345250",
    "end": "350770"
  },
  {
    "text": "couple of weeks ago we've effectively brought the price of this storage down by eighty percent and at the same time",
    "start": "350770",
    "end": "357940"
  },
  {
    "text": "the team's been introducing a number of customer driven features such as V PCE support ipv6 web site hosting cross",
    "start": "357940",
    "end": "365980"
  },
  {
    "text": "region replication the team also observed the bar business observed customers really in many cases were",
    "start": "365980",
    "end": "372730"
  },
  {
    "text": "using s3 to store backup data they didn't want to lose the date of something happened on Prem so we've",
    "start": "372730",
    "end": "378070"
  },
  {
    "text": "released a new storage service called glacier which allows you to backup your data for indefinitely almost all the",
    "start": "378070",
    "end": "384760"
  },
  {
    "text": "data you could ever imagine can be backed up for less than a penny per gigabyte per month and just last year",
    "start": "384760",
    "end": "390370"
  },
  {
    "text": "the team released also that there's an interesting use case customers wanted the same durability guarantees that you",
    "start": "390370",
    "end": "397180"
  },
  {
    "text": "can get and reliability guarantees can get with s3 but that data doesn't get touched very often so they introduced",
    "start": "397180",
    "end": "402460"
  },
  {
    "text": "infrequently access is another new starched here and you can write lifecycle policy rules that will migrate",
    "start": "402460",
    "end": "408670"
  },
  {
    "text": "your data from hot actively used in s3 you notice that it's not being used you can migrate it too infrequently accessed",
    "start": "408670",
    "end": "415180"
  },
  {
    "text": "it hasn't been touched for several weeks go ahead and move it off to glacier and back and forth so it gives you a lot of",
    "start": "415180",
    "end": "420460"
  },
  {
    "text": "flexibility and it's that last number 11 9s of durability we'll come back to why",
    "start": "420460",
    "end": "425860"
  },
  {
    "text": "that's important in terms of allowing you to attach multiple applications to it but this is the foundation will talk",
    "start": "425860",
    "end": "431320"
  },
  {
    "text": "about the role that plays architectural e well we also heard from our customers we",
    "start": "431320",
    "end": "436750"
  },
  {
    "start": "433000",
    "end": "544000"
  },
  {
    "text": "love s3 we started using s3 but we have hundreds of terabytes petabytes of data",
    "start": "436750",
    "end": "442960"
  },
  {
    "text": "that we want to move to AWS last year we released AWS import/export snowball I",
    "start": "442960",
    "end": "449800"
  },
  {
    "text": "just call it snowball it's a petabyte scale transfer service that uses our hardware our network attracts attached",
    "start": "449800",
    "end": "456220"
  },
  {
    "text": "storage device and this just isn't any network attached storage storage device this thing can withstand 30 G's of",
    "start": "456220",
    "end": "462580"
  },
  {
    "text": "impact I don't care how rough your your um transport of your carrier is I'm your",
    "start": "462580",
    "end": "467890"
  },
  {
    "text": "snowball is going to make it just fine when it gets into us when you go to the AWS console to actually request a",
    "start": "467890",
    "end": "473290"
  },
  {
    "text": "snowball an e link label e ink label on the snowball gets generated with your",
    "start": "473290",
    "end": "479290"
  },
  {
    "text": "address once it arrives as 50 and 80 terabyte capacity you can order multiple",
    "start": "479290",
    "end": "485290"
  },
  {
    "text": "ease and have them ship to your facility it comes with the 10 gigabit per second network interface and a cable to plug",
    "start": "485290",
    "end": "491200"
  },
  {
    "text": "into your storage on Prem as soon as it's full the e-link label each label",
    "start": "491200",
    "end": "496930"
  },
  {
    "text": "changes back to the region to the address for the region in which you want your data to be uploaded and it can be",
    "start": "496930",
    "end": "502900"
  },
  {
    "text": "picked up by the carrier sent back to AWS and within a day we'll have it uploaded and accessible for you on AWS",
    "start": "502900",
    "end": "509800"
  },
  {
    "text": "and this is how we're allowing large companies to go ahead and move on to the cloud and that data encrypted with 256",
    "start": "509800",
    "end": "517000"
  },
  {
    "text": "bit encryption nothing is going to happen to it even if it got misdirected stolen or whatever bad things you might",
    "start": "517000",
    "end": "522130"
  },
  {
    "text": "think it happened to it your data is simply secure nothing's going to happen by the way we have a number of customers",
    "start": "522130",
    "end": "528640"
  },
  {
    "text": "doing so many interesting use cases they're taking these out on ships their take these out and oil drilling rigs",
    "start": "528640",
    "end": "533720"
  },
  {
    "text": "where they have no network connectivity capturing all the data that they need and sending it back for uploading analysis so it really opens up a wide",
    "start": "533720",
    "end": "539839"
  },
  {
    "text": "variety of use cases it's okay we've got our data up on AWS you know if you're",
    "start": "539839",
    "end": "545899"
  },
  {
    "start": "544000",
    "end": "596000"
  },
  {
    "text": "doing structured data processing Amazon redshift is a petabyte scale data",
    "start": "545899",
    "end": "551660"
  },
  {
    "text": "warehouse it's simple it's cost effective no upfront commitment you can actually start for as little as 25 cents",
    "start": "551660",
    "end": "558170"
  },
  {
    "text": "an hour going up to basically a thousand dollars per terabyte per year and again capacity up to one full petabyte fully",
    "start": "558170",
    "end": "565310"
  },
  {
    "text": "managed it's highly integrated with a number of services and app and products such as tableau for visualizing data",
    "start": "565310",
    "end": "571639"
  },
  {
    "text": "such as machine learning tool kits for learning over the data fishes are for data scientists to",
    "start": "571639",
    "end": "577639"
  },
  {
    "text": "explore so we go in a best practice we can hit on this a couple times is to",
    "start": "577639",
    "end": "583009"
  },
  {
    "text": "store the raw data into s3 if you want to actually do some analysis pull it up into a redshift and then you have your",
    "start": "583009",
    "end": "588709"
  },
  {
    "text": "familiar tools already used to using to actually look at the data slice and dice it and then drop it out out of out of",
    "start": "588709",
    "end": "594529"
  },
  {
    "text": "redshift going a little bit further Amazon Elastic MapReduce it is Hadoop as a",
    "start": "594529",
    "end": "601579"
  },
  {
    "start": "596000",
    "end": "707000"
  },
  {
    "text": "service you have the full Apache ecosystem available to you within 30",
    "start": "601579",
    "end": "606589"
  },
  {
    "text": "days of the time that the community makes a new drop that is available in EMR",
    "start": "606589",
    "end": "612250"
  },
  {
    "text": "another interesting thing is that its uses s3 as a data store for HBase H",
    "start": "612250",
    "end": "618050"
  },
  {
    "text": "space is open source software it basically has very good performance for for random access reads and writes over",
    "start": "618050",
    "end": "625040"
  },
  {
    "text": "very large distributed data sets and what this effectively does and it's kind of subtle if you haven't looked at this",
    "start": "625040",
    "end": "630620"
  },
  {
    "text": "it decouples your compute from your storage in typical Hadoop distributions",
    "start": "630620",
    "end": "636319"
  },
  {
    "text": "you buy a Hadoop cluster should you need to have multiple terabytes hundreds of",
    "start": "636319",
    "end": "641689"
  },
  {
    "text": "terabytes you have to buy the corresponding cluster size so you get the compute that comes with it even though you may not want it by decoupling",
    "start": "641689",
    "end": "648649"
  },
  {
    "text": "it like this you can actually have your Hadoop cluster just the right size for the analytics that you want to process",
    "start": "648649",
    "end": "654350"
  },
  {
    "text": "whereas you may have a huge datastore on s3 you get to pick and choose what you",
    "start": "654350",
    "end": "659720"
  },
  {
    "text": "want to analyze with EMR it in any given point in time so this decoupling is for the customer advantage of allowing you",
    "start": "659720",
    "end": "665980"
  },
  {
    "text": "to pick and choose for all the data that you have it in s3 exactly what you want to apply EMR for again going back to",
    "start": "665980",
    "end": "673179"
  },
  {
    "text": "best practices and how these services work well together it's a very common pattern",
    "start": "673179",
    "end": "678269"
  },
  {
    "text": "because we'd have no schema apply to the data it's an object store in s3 customers will use EMR when they have an",
    "start": "678269",
    "end": "684970"
  },
  {
    "text": "analysis question they want to ask to run large MapReduce jobs reading data from s3 applying the transforming and",
    "start": "684970",
    "end": "691990"
  },
  {
    "text": "format loading it to red shift within a few minutes they can be analyzing with bi tooling and redshift and again just",
    "start": "691990",
    "end": "698079"
  },
  {
    "text": "drop it so again using our services for what they're best for their intended to",
    "start": "698079",
    "end": "703119"
  },
  {
    "text": "be composed together like lego blocks okay",
    "start": "703119",
    "end": "709079"
  },
  {
    "start": "707000",
    "end": "774000"
  },
  {
    "text": "what if we want log data what if you're capturing log data from application",
    "start": "709079",
    "end": "714100"
  },
  {
    "text": "servers for customer interactions what if you're putting documents you want to actually analyze what instantly log",
    "start": "714100",
    "end": "720249"
  },
  {
    "text": "records from app servers feedback from York from your customers this is where Amazon Elastic search comes in it's a",
    "start": "720249",
    "end": "727660"
  },
  {
    "text": "distributed search engine and analytics engine and you can go from raw data to actionable insights within minutes it's",
    "start": "727660",
    "end": "734319"
  },
  {
    "text": "highly available highly reliable there's zero admin for our customers once the data is loaded it's a fully managed",
    "start": "734319",
    "end": "739839"
  },
  {
    "text": "elasticsearch it actually is tightly integrated with other AWS services such as Kinesis such as lambda as well as",
    "start": "739839",
    "end": "747459"
  },
  {
    "text": "third parties such as elastic search and Cabana to go end-to-end from law raw log records into a loaded elasticsearch",
    "start": "747459",
    "end": "754929"
  },
  {
    "text": "cluster and again it has reverse indexing so if you wanted to find all the documents in your collection that had certain keywords it's been indexed",
    "start": "754929",
    "end": "761889"
  },
  {
    "text": "reverse index immediately once it's loaded as you can immediately find all documents that have certain keywords in",
    "start": "761889",
    "end": "766899"
  },
  {
    "text": "it so again for these semi structured use cases and unstructured this service plays a very valuable role for big data",
    "start": "766899",
    "end": "774809"
  },
  {
    "text": "server 'less lambda this has actually really turned things upside down because",
    "start": "774809",
    "end": "780339"
  },
  {
    "text": "what if you actually just want to have your code executed in response to an event and you don't want to manage ec2",
    "start": "780339",
    "end": "786790"
  },
  {
    "text": "instances you don't want to manage servers you can actually give the code in Python Java and JavaScript to lamb",
    "start": "786790",
    "end": "794230"
  },
  {
    "text": "and we'll do the management and execution for it and you're only charged for the time your code is actually",
    "start": "794230",
    "end": "800380"
  },
  {
    "text": "executed by a customer in response to some event at a granularity of a hundred milliseconds nobody's calling your code",
    "start": "800380",
    "end": "807340"
  },
  {
    "text": "zero bill it just qui SS and goes quiet you get slashed on it or somebody puts",
    "start": "807340",
    "end": "812410"
  },
  {
    "text": "out an article and gets highly popular we scale it on your behalf to ensure that the requesters are handled and we",
    "start": "812410",
    "end": "818800"
  },
  {
    "text": "do fault tolerance to failover as well in case one of the instances behind the scenes has issues so again if you want",
    "start": "818800",
    "end": "824800"
  },
  {
    "text": "to do you roll your own analytics and roll your own code but not manage servers AWS lambda is an incredibly",
    "start": "824800",
    "end": "830800"
  },
  {
    "text": "powerful service and it actually allows us to extend each one of our AWS services and I'll talk about that in a",
    "start": "830800",
    "end": "836380"
  },
  {
    "text": "second then there's a monk amazon kinesis what if your data is continuously generated",
    "start": "836380",
    "end": "842350"
  },
  {
    "start": "837000",
    "end": "1066000"
  },
  {
    "text": "off of devices off of sensors and you want to have real-time insights into that data this is where Kinesis comes",
    "start": "842350",
    "end": "848620"
  },
  {
    "text": "into play conesus is amazon's data streaming platform there's actually three services today which make up",
    "start": "848620",
    "end": "855220"
  },
  {
    "text": "Kinesis the first launched in 2013 allows you to stream hundreds of",
    "start": "855220",
    "end": "860290"
  },
  {
    "text": "terabytes per hour to AWS into a stream we provide a Kinesis client library that",
    "start": "860290",
    "end": "866980"
  },
  {
    "text": "you can actually use in java and python and go and actually write a distributed application to process this data and",
    "start": "866980",
    "end": "873640"
  },
  {
    "text": "build your own custom applications if you want to use something like redshift or lambda or storm spark streaming we",
    "start": "873640",
    "end": "881320"
  },
  {
    "text": "have connectors to those as well so you can actually do your processing of your streaming of the data coming in through",
    "start": "881320",
    "end": "886420"
  },
  {
    "text": "a Kinesis stream but we noticed after 2013 most of our customers were actually",
    "start": "886420",
    "end": "892270"
  },
  {
    "text": "taking advantage of existing services like redshift and looking at the data and tableau they were where they were",
    "start": "892270",
    "end": "898240"
  },
  {
    "text": "trying to load it into into elasticsearch they were trying to load it into s3 for all the good reasons we've talked about so in 2015 we",
    "start": "898240",
    "end": "905770"
  },
  {
    "text": "released Kinesis fire hose again it's serverless you don't have to provision anything you create a delivery stream",
    "start": "905770",
    "end": "912040"
  },
  {
    "text": "you don't have to worry about how to scale it you tell us the destination you want the data to appear in and how many",
    "start": "912040",
    "end": "918160"
  },
  {
    "text": "seconds or how many minutes should it be encrypted compressed you install agents on prem where your servers are",
    "start": "918160",
    "end": "924880"
  },
  {
    "text": "generating the data and we in minutes that data is streamed up into these destinations that you've selected with",
    "start": "924880",
    "end": "931259"
  },
  {
    "text": "this service I'm going to get for users who don't want to write their own custom event processing or stream processing",
    "start": "931259",
    "end": "937290"
  },
  {
    "text": "they can take advantage of fire hose and use the servers that they have already used but guess what they have moved into",
    "start": "937290",
    "end": "943259"
  },
  {
    "text": "the real-time world we've got some wonderful success stories that are coming out documented customer use cases of customers only got to see their sales",
    "start": "943259",
    "end": "950220"
  },
  {
    "text": "data at the end of the anniversary cell or every week and now they're getting it hourly because they're using fire hose",
    "start": "950220",
    "end": "956370"
  },
  {
    "text": "to load the servers services that they were already using for AWS what we released earlier this year was",
    "start": "956370",
    "end": "963269"
  },
  {
    "text": "Kinesis analytics because the next request we heard from customers is wow I'd really like to actually not write an",
    "start": "963269",
    "end": "970379"
  },
  {
    "text": "app to manage or process my streaming data I'd actually like to give you my code in particular like to give you",
    "start": "970379",
    "end": "976050"
  },
  {
    "text": "sequel and have you run sequel over the streaming data and actually produce the output kinesis analytics is a fully",
    "start": "976050",
    "end": "983430"
  },
  {
    "text": "managed service that takes ansi standard sequel and as your data streaming by it",
    "start": "983430",
    "end": "988589"
  },
  {
    "text": "executes these queries continuously with low latency to produce an output stream of the process data nothing to manage",
    "start": "988589",
    "end": "995850"
  },
  {
    "text": "its pay-as-you-go we fully scale it depending on the demand of the data coming in or the number of queries",
    "start": "995850",
    "end": "1001250"
  },
  {
    "text": "you're trying to process no data no queries week we a sit down to nothing and so again pay-as-you-go we manage the",
    "start": "1001250",
    "end": "1007970"
  },
  {
    "text": "variability and the scaling of this we've also been hearing recently from",
    "start": "1007970",
    "end": "1013069"
  },
  {
    "text": "customers that we're using fire hose you know I love fire hose I'm trying to put the data into elasticsearch or two",
    "start": "1013069",
    "end": "1019309"
  },
  {
    "text": "redshift I'm reading it from s3 or I'm reading it off of a device and I need to format it I need to enrich it I need to",
    "start": "1019309",
    "end": "1025668"
  },
  {
    "text": "clean it before I load it into these destination services so I'm extremely pleased to pre-announce it in the next",
    "start": "1025669",
    "end": "1032270"
  },
  {
    "text": "couple of weeks we're releasing in line processing into Kinesis fire hose where",
    "start": "1032270",
    "end": "1038959"
  },
  {
    "text": "you can write any arbitrary lambda function as every record of streaming by through the fire hose we're going to",
    "start": "1038959",
    "end": "1044360"
  },
  {
    "text": "apply the lambda function shape clean it format it and deliver it on to its destination in addition we're going to",
    "start": "1044360",
    "end": "1051200"
  },
  {
    "text": "provide a library of ready to use templates for the common data transformations we see our customers",
    "start": "1051200",
    "end": "1056390"
  },
  {
    "text": "using and will continue to build that out so now you can go end and from raw data to loading into elasticsearch or",
    "start": "1056390",
    "end": "1062179"
  },
  {
    "text": "the redshift and all your logic of cleaning up in shape you can take place there and then finally another another new",
    "start": "1062179",
    "end": "1069470"
  },
  {
    "start": "1066000",
    "end": "1108000"
  },
  {
    "text": "service that was released this year is quick site it is for your business analyst who want to slice and dice the",
    "start": "1069470",
    "end": "1074929"
  },
  {
    "text": "data go data mining and exploring share it with anybody in the company share it",
    "start": "1074929",
    "end": "1080090"
  },
  {
    "text": "on the web shared in mobile at one-tenth the cost of traditional BI solutions and if you look at the connectivity it's",
    "start": "1080090",
    "end": "1086960"
  },
  {
    "text": "pretty much where you're going to find most of your business data from Excel of course amazon accessory redshift my",
    "start": "1086960",
    "end": "1093140"
  },
  {
    "text": "sequel oracle rd s salesforce etc so if you have data in these sources you'll be",
    "start": "1093140",
    "end": "1099530"
  },
  {
    "text": "able to connect with quick site and in a few minutes have your bi professional slicing and dicing and actually getting",
    "start": "1099530",
    "end": "1105169"
  },
  {
    "text": "insights into the data and then being able to share that okay now let's talk about let's start",
    "start": "1105169",
    "end": "1111470"
  },
  {
    "start": "1108000",
    "end": "1124000"
  },
  {
    "text": "putting these together I think these are some building blocks and I want to make sure you're aware of and I hope you'll dive deeper in each one of them now I",
    "start": "1111470",
    "end": "1117260"
  },
  {
    "text": "want to talk about some conversations that we tend to have with customers one of the first ones that comes up is scale",
    "start": "1117260",
    "end": "1122600"
  },
  {
    "text": "and it's actually not just a single question it's actually a myriad of questions ranging from how can I scale",
    "start": "1122600",
    "end": "1128179"
  },
  {
    "start": "1124000",
    "end": "1167000"
  },
  {
    "text": "up with the volume of data being generated am I going to make a bad choice how can I collect data quickly",
    "start": "1128179",
    "end": "1133429"
  },
  {
    "text": "from various sources one of their woes is currently in enterprises are looking at silos they have five six seven",
    "start": "1133429",
    "end": "1139640"
  },
  {
    "text": "different data sources where data is in and if you need to move it from one to the other it becomes an arduous task",
    "start": "1139640",
    "end": "1145419"
  },
  {
    "text": "another question we see is ok now I've got it into the cloud how can I ensure my entire company can actually run",
    "start": "1145419",
    "end": "1152480"
  },
  {
    "text": "concurrently analytics against it and indeed i was talking to an enterprise customer yes sir and they're explaining",
    "start": "1152480",
    "end": "1157580"
  },
  {
    "text": "about how they do it on prem where they will replicate the data when they know two or three people are going to run the same kind of analysis against it because",
    "start": "1157580",
    "end": "1164720"
  },
  {
    "text": "they're worried about contention want to hit that point there is a pattern that is emerging",
    "start": "1164720",
    "end": "1170660"
  },
  {
    "start": "1167000",
    "end": "1248000"
  },
  {
    "text": "that's resonating with the community that's working for people and that is to treat s3 is your data lake it's",
    "start": "1170660",
    "end": "1177320"
  },
  {
    "text": "infinitely scalable it can handle future data growth you will never have to worry about amazon's scale ever becoming an",
    "start": "1177320",
    "end": "1184040"
  },
  {
    "text": "impedance it's incredibly flexible in all of the tools as i mentioned earlier all AWS services at to s3 so any tool",
    "start": "1184040",
    "end": "1192920"
  },
  {
    "text": "can immediately access it you can store anything and everything in one place necessary at extremely low cost at the",
    "start": "1192920",
    "end": "1201740"
  },
  {
    "text": "beginning of that slide you saw s3 and all the eleven nines of data durability anybody who's thought a worked in",
    "start": "1201740",
    "end": "1207950"
  },
  {
    "text": "databases realize you get that kind of high data durability by having multiple copies and a bunch of other techniques",
    "start": "1207950",
    "end": "1214490"
  },
  {
    "text": "working behind the scenes to ensure that we can give you that data durability amazon s3 uses this intelligently such",
    "start": "1214490",
    "end": "1220490"
  },
  {
    "text": "as if you have multiple applications trying to simultaneously read from the same data set we will do we will",
    "start": "1220490",
    "end": "1227060"
  },
  {
    "text": "distribute those reads across all of these multiple copies this is a real mind change for people they realize I",
    "start": "1227060",
    "end": "1233180"
  },
  {
    "text": "don't have to worry about contention and I don't have any people to have to research schedule we can instead have multiple applications actually pointing",
    "start": "1233180",
    "end": "1239810"
  },
  {
    "text": "desaree and reading from it and this is really also about schema comes on read",
    "start": "1239810",
    "end": "1245300"
  },
  {
    "text": "when you write the data you write at law raw this is actually a diagram I like to",
    "start": "1245300",
    "end": "1250400"
  },
  {
    "start": "1248000",
    "end": "1334000"
  },
  {
    "text": "share because for those of us who have been building data management systems in the past this is a little striking in",
    "start": "1250400",
    "end": "1256190"
  },
  {
    "text": "the center is s3 this is the raw unformatted data on the left you see all",
    "start": "1256190",
    "end": "1263570"
  },
  {
    "text": "the data ingress ingest services we've talked about on the right you see various services that can attach",
    "start": "1263570",
    "end": "1269230"
  },
  {
    "text": "analyzed as well at the top we have catalogs we have access and user interfaces this is the mental model that",
    "start": "1269230",
    "end": "1276200"
  },
  {
    "text": "most major companies that have been working with big data are snapping to that s 3 is the data lake put all of",
    "start": "1276200",
    "end": "1282140"
  },
  {
    "text": "your data into it any one of your customers in your enterprise can choose the application that they're most",
    "start": "1282140",
    "end": "1287990"
  },
  {
    "text": "comfortable with and they can go in and read from the data lake and this also represents one of the more interesting",
    "start": "1287990",
    "end": "1293960"
  },
  {
    "text": "mind shifts that's happened in Big Data in five seven ten years ago we operated",
    "start": "1293960",
    "end": "1300020"
  },
  {
    "text": "in an era of scarcity we always thought about what kind of analysis we need to do what kind of schemas should we do how",
    "start": "1300020",
    "end": "1306860"
  },
  {
    "text": "do we format the data how to build the ETL pipeline we live in a world of abundance where we can literally store",
    "start": "1306860",
    "end": "1313550"
  },
  {
    "text": "everything at incredibly low cost on s3 and of course we can tear the storage because of the sole belief that there",
    "start": "1313550",
    "end": "1320660"
  },
  {
    "text": "may be latent value in our data we might be able to extract two or three years later so don't touch it put it in s3",
    "start": "1320660",
    "end": "1327240"
  },
  {
    "text": "lifecycle policies to move it out into other tiered storage but you never want to be without that raw data because you",
    "start": "1327240",
    "end": "1332980"
  },
  {
    "text": "might be something valuable in it another aspect of scale and agility",
    "start": "1332980",
    "end": "1339400"
  },
  {
    "text": "which I love to share with people is how fast can you actually scale your analytics well you can get a new bi",
    "start": "1339400",
    "end": "1346240"
  },
  {
    "text": "server from the Amazon console basically within 20 minutes and have it loaded with data you can add 50 terabytes of",
    "start": "1346240",
    "end": "1352690"
  },
  {
    "text": "storage to your reg ship with instantly whereas that would take an enterprise IT department about two months you can grow",
    "start": "1352690",
    "end": "1359410"
  },
  {
    "text": "your data warehouse cluster from 8 gigabytes to 1 petabyte in an hour you can build it at 1024 note Hadoop cluster",
    "start": "1359410",
    "end": "1366970"
  },
  {
    "text": "in about 30 minutes on EMR you can only imagine what it would take our traditional IT company to order the",
    "start": "1366970",
    "end": "1372250"
  },
  {
    "text": "necessary hardware to rack and stack and get that thing tuned and should you should your business explode and you",
    "start": "1372250",
    "end": "1377440"
  },
  {
    "text": "want to go multi-regional you can do that in a few hours and basically deploy your services around the world and all",
    "start": "1377440",
    "end": "1383830"
  },
  {
    "text": "of the regions in which AWS operates that's also part of the value prop of scale now Netflix needs no introduction",
    "start": "1383830",
    "end": "1391450"
  },
  {
    "start": "1388000",
    "end": "1416000"
  },
  {
    "text": "into their clever use of data their innovative practices and how they have run their business and made the most out",
    "start": "1391450",
    "end": "1397660"
  },
  {
    "text": "of data I would strongly encourage you they're presenting Netflix using Amazon s3 is the fabric of our big data",
    "start": "1397660",
    "end": "1404110"
  },
  {
    "text": "ecosystem talking about much of what I've just shared with you they'll be going deeper their talks today at five thirty and Mirage this building st.",
    "start": "1404110",
    "end": "1411220"
  },
  {
    "text": "Croix be they'll take you on a deeper dive on this story and if you're interested in this idea strongly encourage you to attend let's talk about",
    "start": "1411220",
    "end": "1417850"
  },
  {
    "start": "1416000",
    "end": "1421000"
  },
  {
    "text": "cost briefly also because that's another thing to people question about let's use an example example what if we wanted to",
    "start": "1417850",
    "end": "1424780"
  },
  {
    "start": "1421000",
    "end": "1536000"
  },
  {
    "text": "process the entire Twitter fire hose maybe do sentiment analytics",
    "start": "1424780",
    "end": "1430530"
  },
  {
    "text": "monitor politicians do a number of things there's a number of my customers who do this they actually track their",
    "start": "1430530",
    "end": "1436809"
  },
  {
    "text": "brands they track sentiment they actually track how things are trending and so let's imagine we wanted to put a",
    "start": "1436809",
    "end": "1442179"
  },
  {
    "text": "service together that would actually ingest the entire Twitter Phi rose into Kinesis we'd write some Kinesis enabled",
    "start": "1442179",
    "end": "1448360"
  },
  {
    "text": "applications on a c2 we'd archive our data in s3 which then we could load into",
    "start": "1448360",
    "end": "1453640"
  },
  {
    "text": "redshift and put a tableau or any other interface front of it so we could actually watch trending topics and see what are the hot tweets we might even",
    "start": "1453640",
    "end": "1460840"
  },
  {
    "text": "want to archive that to glacier if you put some prices on it the first thing you notice is that we're looking about everything in the pennies per hour to do",
    "start": "1460840",
    "end": "1469420"
  },
  {
    "text": "this end-to-end well what if we actually wanted to process the full Twitter files and track what's going on out on the",
    "start": "1469420",
    "end": "1475870"
  },
  {
    "text": "world let's look at the numbers Twitter firehose about a half a billion tweets per day that's about 5,800 tweets per",
    "start": "1475870",
    "end": "1483490"
  },
  {
    "text": "second these tweets are about 2k so that's about 12 megabytes per second I'll total you're going to ingest a",
    "start": "1483490",
    "end": "1489640"
  },
  {
    "text": "terabyte a day in Kinesis speak you're going to need a 12 shard stream we'll throw in a couple more 14 just to make",
    "start": "1489640",
    "end": "1496270"
  },
  {
    "text": "it safe for growth and so it's a penny and a half per hour to reserve a shard",
    "start": "1496270",
    "end": "1503050"
  },
  {
    "text": "in a stream and about a penny 1.4 pennies per million puts into your",
    "start": "1503050",
    "end": "1508240"
  },
  {
    "text": "stream so your whole amazon kinesis cost per hours forty-seven cents putting it",
    "start": "1508240",
    "end": "1514510"
  },
  {
    "text": "into REM Amazon redshift so we can then display it and look at it is 85 cents an hour assuming we're going to maintain",
    "start": "1514510",
    "end": "1520570"
  },
  {
    "text": "about two terabytes of historical data the s3 costs for I Carville purposes a dollar to an hour the total cost for",
    "start": "1520570",
    "end": "1527830"
  },
  {
    "text": "running an application like this ingesting and processing the whole twitter fire roses on two dollars and 34",
    "start": "1527830",
    "end": "1533530"
  },
  {
    "text": "cents an hour this is the beauty about being able to use only the services you need you scale only the services you",
    "start": "1533530",
    "end": "1540940"
  },
  {
    "text": "need you pay for what you use and what I've shown you are just the flat rate you can actually get discounts through",
    "start": "1540940",
    "end": "1546880"
  },
  {
    "text": "reserved instances spot instances and upfront commitments so cost here just",
    "start": "1546880",
    "end": "1552040"
  },
  {
    "text": "simply doesn't become a factor for many of these jobs what about scale and security this is",
    "start": "1552040",
    "end": "1557680"
  },
  {
    "start": "1554000",
    "end": "1568000"
  },
  {
    "text": "also another concern customers come up and talk and they say hey we love the services we've written some prototypes",
    "start": "1557680",
    "end": "1562750"
  },
  {
    "text": "we work in highly regulated industries our data is very valuable to us or a little bit concerned about what we",
    "start": "1562750",
    "end": "1568030"
  },
  {
    "start": "1568000",
    "end": "1611000"
  },
  {
    "text": "should do FINRA FINRA has been doing big data before many of us even were using that",
    "start": "1568030",
    "end": "1573550"
  },
  {
    "text": "word on a regular basis FINRA monitors all of the financial transactions at",
    "start": "1573550",
    "end": "1578590"
  },
  {
    "text": "present that's 75 billion market events per day for nasdaq New York Stock Exchange and what they're doing is",
    "start": "1578590",
    "end": "1585280"
  },
  {
    "text": "they're trying to determine this duct by enforcing rules they have to detect wrongdoing they have to discipline those",
    "start": "1585280",
    "end": "1591960"
  },
  {
    "text": "who break rules and this is a highly secure service or an environment to operate in highly regulated highly",
    "start": "1591960",
    "end": "1598890"
  },
  {
    "text": "adversarial and it's constantly evolving not only are the threats changing but the rules on which they might they have",
    "start": "1598890",
    "end": "1604410"
  },
  {
    "text": "to operate are changing the exchanges are changing so they have to have a highly fluid environment again yet be",
    "start": "1604410",
    "end": "1610290"
  },
  {
    "text": "highly secure a little illustration they will be giving a talk later today on the",
    "start": "1610290",
    "end": "1615600"
  },
  {
    "text": "left they're treating s3 is there data lake for all new york stock exchange data on nasdaq i'll direct exchange go",
    "start": "1615600",
    "end": "1623280"
  },
  {
    "text": "into amazon s3 as their data lake they have on they ingest petabytes leave it",
    "start": "1623280",
    "end": "1628800"
  },
  {
    "text": "at that of data from on-prem and bring it into a WS every day thousands of",
    "start": "1628800",
    "end": "1634410"
  },
  {
    "text": "analytical queries they actually have 400 analytical packages which are running on amazon redshift and EMR",
    "start": "1634410",
    "end": "1641220"
  },
  {
    "text": "analyzing all the transactions that are going through each and every day this is incredible skill and they have",
    "start": "1641220",
    "end": "1646620"
  },
  {
    "text": "incredibly stringent requirements they're leveraging V pce they have flow",
    "start": "1646620",
    "end": "1652350"
  },
  {
    "text": "logs that show them each and every transaction that has gone through they use encryption at rest for all of their",
    "start": "1652350",
    "end": "1657660"
  },
  {
    "text": "data AWS cloud trail and database auditing can show them exactly who has given them",
    "start": "1657660",
    "end": "1662940"
  },
  {
    "text": "access to everything so they can meet all the street all the security requirements we have a number of such",
    "start": "1662940",
    "end": "1668190"
  },
  {
    "text": "customers that work in these industries and I'll talk about that a little bit later just just by naming a few what I would like to give a shout-out offender",
    "start": "1668190",
    "end": "1675270"
  },
  {
    "text": "is giving a talk later today four o'clock here in this building again st. Croix be but they're able to talk about",
    "start": "1675270",
    "end": "1681059"
  },
  {
    "text": "how they store exabytes of data or more in s3 analyze gigabytes to petabytes every day using standard services",
    "start": "1681059",
    "end": "1687390"
  },
  {
    "text": "they're doing encryption they have audibility of all of their AP is and they can control egress and ingress",
    "start": "1687390",
    "end": "1693809"
  },
  {
    "text": "points using VPC to ensure exactly who has access to the service",
    "start": "1693809",
    "end": "1698960"
  },
  {
    "text": "but what about agility and actionable insights we're talking real time here because as you're starting to become",
    "start": "1698960",
    "end": "1705210"
  },
  {
    "start": "1699000",
    "end": "1712000"
  },
  {
    "text": "aware of maybe reading more data is continuously generated how could we actually turn that into actionable",
    "start": "1705210",
    "end": "1711000"
  },
  {
    "text": "insights I want to do something a little fun here for those of you with mobile",
    "start": "1711000",
    "end": "1716280"
  },
  {
    "start": "1712000",
    "end": "1768000"
  },
  {
    "text": "phones Android or iPhone I would like to ask that you point your Chrome or",
    "start": "1716280",
    "end": "1722190"
  },
  {
    "text": "browser or whatever at this URL you won't be installing anything on your phone and what you're going to see here",
    "start": "1722190",
    "end": "1728220"
  },
  {
    "text": "are those four images that I'm displaying there once you hit",
    "start": "1728220",
    "end": "1733230"
  },
  {
    "text": "that URL HTTP Amazon AMZN t 0 / big data",
    "start": "1733230",
    "end": "1741740"
  },
  {
    "text": "there's actually four quadrants and what they represent in the upper left-hand quarter quadrant it's new Amazon Web",
    "start": "1741740",
    "end": "1748559"
  },
  {
    "text": "Services on the right-hand side it's the blackjack game that's coming up left",
    "start": "1748559",
    "end": "1753899"
  },
  {
    "text": "time left hand corner lower left networking with your peers and lower right the replay party and you can",
    "start": "1753899",
    "end": "1760980"
  },
  {
    "text": "actually use your accelerometer to actually roll your phone around a little bit let's go ahead and actually go over",
    "start": "1760980",
    "end": "1766320"
  },
  {
    "text": "to the other screen please other computer there we go so what you're seeing here guys is",
    "start": "1766320",
    "end": "1774769"
  },
  {
    "start": "1768000",
    "end": "1873000"
  },
  {
    "text": "what we've jumped up we've got about 300 people playing along we're actually sending these events up to the cloud up",
    "start": "1774860",
    "end": "1782460"
  },
  {
    "text": "to Kinesis and actually doing real-time analytics up to 400 we see that we've",
    "start": "1782460",
    "end": "1787679"
  },
  {
    "text": "got predominantly I oh I phones here a few androids a few other and the numbers",
    "start": "1787679",
    "end": "1793620"
  },
  {
    "text": "going now let me ask you a question first question I want to ask is to get",
    "start": "1793620",
    "end": "1798659"
  },
  {
    "text": "my notes up what item most interests you this week go ahead and hover the ball over what most interests you to see what",
    "start": "1798659",
    "end": "1804960"
  },
  {
    "text": "are you most interested in learning about this week go I just let that ball hover over there for a few minutes",
    "start": "1804960",
    "end": "1811220"
  },
  {
    "text": "new services and you see the shift taking place very cool",
    "start": "1811220",
    "end": "1817700"
  },
  {
    "text": "with this within a second okay what were your colleagues be most interested in hearing about when you return next week",
    "start": "1817700",
    "end": "1826009"
  },
  {
    "text": "the Blackjacks picking up the party services are holding their own though",
    "start": "1831240",
    "end": "1837960"
  },
  {
    "text": "you know it's going to be a fun party come on there we go I",
    "start": "1837960",
    "end": "1843060"
  },
  {
    "text": "look forward to seeing you at blackjack last little question just interact here what would give you the biggest headache",
    "start": "1843060",
    "end": "1848560"
  },
  {
    "text": "this week what do you anticipate going to give you the biggest headache",
    "start": "1848560",
    "end": "1853860"
  },
  {
    "text": "yeah if history proves correct I'm with you guys and",
    "start": "1858390",
    "end": "1864050"
  },
  {
    "text": "again we can actually see participation dropped off spike back up all right",
    "start": "1864050",
    "end": "1871350"
  },
  {
    "text": "thank you let's go back over to the other monitor please you know the thing about this is you were just actually",
    "start": "1871350",
    "end": "1877380"
  },
  {
    "start": "1873000",
    "end": "1898000"
  },
  {
    "text": "hitting a webpage but imagine if that was embedded in device in a vehicle that you were monitoring what if it was in a",
    "start": "1877380",
    "end": "1882990"
  },
  {
    "text": "service that you're monitoring and you had hundreds of thousands of services what if this is actually a customer",
    "start": "1882990",
    "end": "1888060"
  },
  {
    "text": "engagement that you're tracking you have this ability to have real-time insights into your customer into your business",
    "start": "1888060",
    "end": "1893700"
  },
  {
    "text": "and if you can actually monitor it you can own it and you can react in real time that demo architecture guys we're",
    "start": "1893700",
    "end": "1900090"
  },
  {
    "start": "1898000",
    "end": "1928000"
  },
  {
    "text": "using Amazon cognito to give you a unique identifier for the session that",
    "start": "1900090",
    "end": "1905310"
  },
  {
    "text": "data that you're from there from your from your app was going into the Kinesis ingestion stream kinesis analytics a",
    "start": "1905310",
    "end": "1911730"
  },
  {
    "text": "simple sequel query I'll actually show you the whole code buying this thing the output of that Kinesis analytics feta",
    "start": "1911730",
    "end": "1917250"
  },
  {
    "text": "Kinesis aggregate stream a lambda function cleaned it and shaped it for us we loaded dynamo we uploaded the icons",
    "start": "1917250",
    "end": "1924390"
  },
  {
    "text": "from s3 and we built that little dashboard the demo was built all about that much code there's the",
    "start": "1924390",
    "end": "1930810"
  },
  {
    "text": "entire sequel and that entire app was serverless I did not provision a single instance ec2 instance and if we'd have",
    "start": "1930810",
    "end": "1937410"
  },
  {
    "text": "actually opened this up to several more rooms of service would have simply scaled with it as well you have the",
    "start": "1937410",
    "end": "1942720"
  },
  {
    "text": "ability to monitor hundreds of thousands of devices so big data does not have to",
    "start": "1942720",
    "end": "1948090"
  },
  {
    "start": "1946000",
    "end": "1965000"
  },
  {
    "text": "mean just batch it can be streamed in processed in real time and you can respond to requests in actionable",
    "start": "1948090",
    "end": "1953880"
  },
  {
    "text": "insights to generate business value and you can mitts mix and match you could have used any lambda or KCl and a",
    "start": "1953880",
    "end": "1960150"
  },
  {
    "text": "written your own app to do all this analytics it doesn't just have to be our services but this is what it offers you",
    "start": "1960150",
    "end": "1965630"
  },
  {
    "start": "1965000",
    "end": "1972000"
  },
  {
    "text": "let me just close on this about choice and selection because I've talked a lot about AWS services but the reality is we",
    "start": "1965630",
    "end": "1973560"
  },
  {
    "start": "1972000",
    "end": "2020000"
  },
  {
    "text": "have over 2000 product listings in the AWS marketplace all of these are",
    "start": "1973560",
    "end": "1979500"
  },
  {
    "text": "provisioned within a few mouse clicks same business model pay as you go no",
    "start": "1979500",
    "end": "1984750"
  },
  {
    "text": "commitments whatsoever over 290 of the offerings in the marketplace",
    "start": "1984750",
    "end": "1990150"
  },
  {
    "text": "specific to Big Data a success story that I like to share a",
    "start": "1990150",
    "end": "1995340"
  },
  {
    "text": "data scientist working at phillips had a business question he had over thirty six thousand million rosietta analyzed he",
    "start": "1995340",
    "end": "2002180"
  },
  {
    "text": "got an estimate from his team that it was going to take three months to actually implement the",
    "start": "2002180",
    "end": "2009050"
  },
  {
    "text": "solution on a saturday evening he found an application in the market place within one hour his job was done and",
    "start": "2009050",
    "end": "2015860"
  },
  {
    "text": "this is the opportunity to have it's not just our services it's any service it's available in the marketplace we actually",
    "start": "2015860",
    "end": "2021980"
  },
  {
    "start": "2020000",
    "end": "2031000"
  },
  {
    "text": "have one of the largest ecosystems of ISVs and integrators as well of any cloud offering tens of thousands of",
    "start": "2021980",
    "end": "2028250"
  },
  {
    "text": "companies that offer a wide range of products and services because really we",
    "start": "2028250",
    "end": "2033410"
  },
  {
    "text": "have a retail mindset we build what we think our customers need we welcome others to come in and put their two",
    "start": "2033410",
    "end": "2039470"
  },
  {
    "text": "offerings in the marketplace you can use ours you can build your own you can access thousands in the marketplace",
    "start": "2039470",
    "end": "2045880"
  },
  {
    "text": "customers decide for themselves so at this point I would like to invite dr.",
    "start": "2045880",
    "end": "2051800"
  },
  {
    "text": "Richard Freeman his lead data engineer and solution architect out working out of London for the tech for good company",
    "start": "2051800",
    "end": "2058460"
  },
  {
    "text": "Just Giving yep [Applause] [Music]",
    "start": "2058460",
    "end": "2065149"
  },
  {
    "start": "2060000",
    "end": "2081000"
  },
  {
    "text": "hello everybody so it's great today to be here especially of it as it's giving",
    "start": "2065870",
    "end": "2071610"
  },
  {
    "text": "Tuesday so we had the Black Friday on Friday that's a giving Tuesday where a lot of people actually donating their",
    "start": "2071610",
    "end": "2077790"
  },
  {
    "text": "time or money for good causes so today I'm going to be talking about",
    "start": "2077790",
    "end": "2084210"
  },
  {
    "text": "our big data platform at just giving just a bit background on the company so",
    "start": "2084210",
    "end": "2089520"
  },
  {
    "text": "we are a tech for good company we work in the charity sector as well as",
    "start": "2089520",
    "end": "2094560"
  },
  {
    "text": "crowdfunding projects were good and special charities also",
    "start": "2094560",
    "end": "2101090"
  },
  {
    "text": "we are the number one platform for online so forgiving in the world and",
    "start": "2101090",
    "end": "2106530"
  },
  {
    "text": "this is based on our 28.5 million users who have transacted on the",
    "start": "2106530",
    "end": "2112560"
  },
  {
    "text": "platform as well as our presence in 196 countries and",
    "start": "2112560",
    "end": "2118640"
  },
  {
    "text": "having a total set of 27,000 charities as well as crowdfunding projects for",
    "start": "2118640",
    "end": "2125910"
  },
  {
    "text": "good so we're number one and we've actually raised 4.2 billion in donations since",
    "start": "2125910",
    "end": "2133950"
  },
  {
    "text": "the creation of the company so yeah that's a huge amount of money if you think about it 4.2 billion dollars going",
    "start": "2133950",
    "end": "2139710"
  },
  {
    "text": "towards good causes and how we like to deal with it is to ensure that no good",
    "start": "2139710",
    "end": "2145590"
  },
  {
    "text": "cause goes unfunded in order to do that we actually try and understand I users",
    "start": "2145590",
    "end": "2151200"
  },
  {
    "text": "better and to actually understand them better we",
    "start": "2151200",
    "end": "2156450"
  },
  {
    "text": "found that we need to provide engaging content so this is content that they are very interested in",
    "start": "2156450",
    "end": "2162260"
  },
  {
    "text": "so this could be vile mail or it could be viral our feed product and we found that actually to understand",
    "start": "2162260",
    "end": "2170010"
  },
  {
    "text": "why someone donates time why someone runs for a marathon to raise for charity there are lots of different",
    "start": "2170010",
    "end": "2177690"
  },
  {
    "text": "reasons we found that understanding the relationship between the users and the charity is really",
    "start": "2177690",
    "end": "2184830"
  },
  {
    "text": "important the best way we have found to do that is actually to create a graph representation of all of that we called",
    "start": "2184830",
    "end": "2192360"
  },
  {
    "text": "it the gift graph and it contains half a billion nodes so I have been in",
    "start": "2192360",
    "end": "2198180"
  },
  {
    "text": "relationships and 100 million nodes so you could think of a node as even an",
    "start": "2198180",
    "end": "2203220"
  },
  {
    "text": "individual a colleague who responds with that individual a crowdfunding page for",
    "start": "2203220",
    "end": "2209250"
  },
  {
    "text": "good causes a specific charity if it's a charity you can action decompose those into a type of charity for dumplings",
    "start": "2209250",
    "end": "2216210"
  },
  {
    "text": "enamel charity you can break it down into dog charities in a specific",
    "start": "2216210",
    "end": "2221250"
  },
  {
    "text": "location for example in Las Vegas and we create that huge graph and this is",
    "start": "2221250",
    "end": "2226830"
  },
  {
    "text": "actually one of the biggest world giving graphs that exists we also take some of",
    "start": "2226830",
    "end": "2233910"
  },
  {
    "text": "the connections amongst Facebook for that graph we've also been using AWS in production",
    "start": "2233910",
    "end": "2241860"
  },
  {
    "text": "for a number of years and it helps us scale out very easily in terms of Peaks traffic's so think about in the past the",
    "start": "2241860",
    "end": "2250710"
  },
  {
    "text": "ice bucket challenge where many people in order to raise money put a nice bucket on the head",
    "start": "2250710",
    "end": "2256300"
  },
  {
    "text": "[Music] and that led to lots of spikes in our",
    "start": "2256300",
    "end": "2261510"
  },
  {
    "text": "website and mobile app so we used a double us to gain scale out very quickly and have that working",
    "start": "2261510",
    "end": "2269630"
  },
  {
    "start": "2269000",
    "end": "2399000"
  },
  {
    "text": "so this is one of our products this is a fundraising page just to give you a bit more context around the data capture",
    "start": "2269630",
    "end": "2276830"
  },
  {
    "text": "so this is actually you can see at the top this is for a half run running marathon and",
    "start": "2276830",
    "end": "2285320"
  },
  {
    "text": "how it works is a person wants to raise money for a charity they create a",
    "start": "2285320",
    "end": "2291480"
  },
  {
    "text": "fundraising page they set a specific target based on the amount they think they can raise and then they would send",
    "start": "2291480",
    "end": "2298860"
  },
  {
    "text": "out an email address an email to their colleagues to their friends and family in order to raise try and raise that",
    "start": "2298860",
    "end": "2306180"
  },
  {
    "text": "amount there's also the integration with Facebook and Twitter the social feed and use also provides",
    "start": "2306180",
    "end": "2314370"
  },
  {
    "text": "updates so depending on so if it's a half marathon for example Sophie will be in this case practicing running in",
    "start": "2314370",
    "end": "2322440"
  },
  {
    "text": "advance and provide updates on how things going under the hood we have a lot of product",
    "start": "2322440",
    "end": "2328940"
  },
  {
    "text": "that actually supports this fundraising page so for example the fundraising page",
    "start": "2328940",
    "end": "2334170"
  },
  {
    "text": "target we're actually using all the data we know about Sophie her past transactions I'm just giving how she",
    "start": "2334170",
    "end": "2340590"
  },
  {
    "text": "interacts with the website to actually make a recommendation on how much we think she can actually raise we also use",
    "start": "2340590",
    "end": "2346410"
  },
  {
    "text": "data science to actually provide insight into how Sophie you can actually raise more money in creating a perfect page",
    "start": "2346410",
    "end": "2355370"
  },
  {
    "text": "at the same time we're capturing a lot of the data so this is the clickstream data how users actually view the page",
    "start": "2355370",
    "end": "2362280"
  },
  {
    "text": "how users actually click on share for example on Facebook and that helps us",
    "start": "2362280",
    "end": "2369360"
  },
  {
    "text": "understand the actual behavior of the user so there's also a set of updates and",
    "start": "2369360",
    "end": "2375450"
  },
  {
    "text": "messages so you can actually respond so it's a very social interaction giving is very personal it is a network of",
    "start": "2375450",
    "end": "2382740"
  },
  {
    "text": "relationships so it could be colleagues friends family or some specific",
    "start": "2382740",
    "end": "2387830"
  },
  {
    "text": "crowdfunding project so something you're raising for example if one of your",
    "start": "2387830",
    "end": "2393630"
  },
  {
    "text": "colleagues has some issues you want to raise money for them specifically",
    "start": "2393630",
    "end": "2399589"
  },
  {
    "start": "2399000",
    "end": "2574000"
  },
  {
    "text": "so about four years ago we introduced data science almost into just giving and",
    "start": "2399710",
    "end": "2408840"
  },
  {
    "text": "we found that our existing data warehouse wasn't able to cope with the complexity of the queries we're also",
    "start": "2408840",
    "end": "2414030"
  },
  {
    "text": "bringing in more and more data so our sequel server just wasn't able to cope and in fact what happened is our data",
    "start": "2414030",
    "end": "2421620"
  },
  {
    "text": "science queries were so long they took tens of hours and they used to get canceled by the database teams",
    "start": "2421620",
    "end": "2428780"
  },
  {
    "text": "so we had to sneak sneak Lee put them in at 6pm after they went home",
    "start": "2428780",
    "end": "2435500"
  },
  {
    "text": "so think about long running queries and complex queries that are running in terms of data science in terms of",
    "start": "2435500",
    "end": "2441210"
  },
  {
    "text": "machine learning it does with graph analytics that was one of the key requirements that we had in addition to new data",
    "start": "2441210",
    "end": "2448230"
  },
  {
    "text": "sources so I've talked about the clickstream data and use a behavioral data there's other data sources that",
    "start": "2448230",
    "end": "2454500"
  },
  {
    "text": "we're very interested such as the Twitter data feed as well as ExactTarget which",
    "start": "2454500",
    "end": "2461280"
  },
  {
    "text": "is our mailer so how we send email and other integration like SurveyMonkey or",
    "start": "2461280",
    "end": "2466390"
  },
  {
    "text": "news feeds in addition we have a requirement for log data so think about",
    "start": "2466390",
    "end": "2472060"
  },
  {
    "text": "the web analytics data that comes in by the logs the server logs",
    "start": "2472060",
    "end": "2479100"
  },
  {
    "text": "so that's a lot more data coming in so the data warehouse definitely couldn't",
    "start": "2479100",
    "end": "2484150"
  },
  {
    "text": "cope with that we also wanted an easy way to actually add new data sources so all these data sources we wanted a very",
    "start": "2484150",
    "end": "2489760"
  },
  {
    "text": "quick way where we could release an integration ingest the data process it",
    "start": "2489760",
    "end": "2495010"
  },
  {
    "text": "through a pipeline at the bottom you can see a simplified version of automated pipeline",
    "start": "2495010",
    "end": "2501060"
  },
  {
    "text": "it takes in data we load the data always ends up in s3 we prepare the data we",
    "start": "2501060",
    "end": "2508300"
  },
  {
    "text": "transform it make it available and then we run our machine learning graph processing natural language processing and",
    "start": "2508300",
    "end": "2514990"
  },
  {
    "text": "streaming analytics processes I'll show you in the next slide a bit more detail around that to suicide of our",
    "start": "2514990",
    "end": "2521410"
  },
  {
    "text": "requirements at the end from a business point of view a consumer of the data we",
    "start": "2521410",
    "end": "2527740"
  },
  {
    "text": "want to gain and measure in a data-driven way all of this data and try",
    "start": "2527740",
    "end": "2534370"
  },
  {
    "text": "and understand to gain insight from the data as well as predict exactly the",
    "start": "2534370",
    "end": "2541750"
  },
  {
    "text": "success for example we talked about the fundraising project page earlier so we",
    "start": "2541750",
    "end": "2547840"
  },
  {
    "text": "want to understand if it released a new future for example the set of updates then we want to understand if that is",
    "start": "2547840",
    "end": "2553570"
  },
  {
    "text": "working so this allows us to do a be testing for example as well as predict the success when your future in addition",
    "start": "2553570",
    "end": "2559750"
  },
  {
    "text": "we make recommendations to the user so we talked about the recommended target value for the fundraising page there's a",
    "start": "2559750",
    "end": "2565120"
  },
  {
    "text": "lot of other recommendations we could recommend also people you may know a bit like you see on linkedin you see level",
    "start": "2565120",
    "end": "2571090"
  },
  {
    "text": "one two three four we can do that also and so just going to briefly talk about",
    "start": "2571090",
    "end": "2577360"
  },
  {
    "start": "2574000",
    "end": "2696000"
  },
  {
    "text": "the Raven platform which stands for reporting analytics visualization experimental networks so this is a",
    "start": "2577360",
    "end": "2584500"
  },
  {
    "text": "platform that we've built in-house using the AWS managed services and it is using",
    "start": "2584500",
    "end": "2591250"
  },
  {
    "text": "event-driven architecture and service pipelines so Roger talked about a bit",
    "start": "2591250",
    "end": "2596800"
  },
  {
    "text": "more the service concepts so will briefly cover that in this session",
    "start": "2596800",
    "end": "2601830"
  },
  {
    "text": "event-driven if you think about it maybe some of you amongst the the crowds are",
    "start": "2601830",
    "end": "2606900"
  },
  {
    "text": "familiar with Enterprise Service buses queuing measures messaging technologies",
    "start": "2606900",
    "end": "2615270"
  },
  {
    "text": "publish-subscribe mechanisms so these are typical patterns that you would use as a developer or as an architect",
    "start": "2615270",
    "end": "2621930"
  },
  {
    "text": "traditionally big data has been more about using workflows ETL processes directed acyclic graphs",
    "start": "2621930",
    "end": "2629290"
  },
  {
    "text": "which is tags there but how we've approached the platform is actually event-driven so actually",
    "start": "2629290",
    "end": "2634930"
  },
  {
    "text": "sending events as a data arrives we load it process it and make it available to the rest rather than draw up big",
    "start": "2634930",
    "end": "2641440"
  },
  {
    "text": "workflows where any changes need to be propagated through and it changes in tables on the input will need to be",
    "start": "2641440",
    "end": "2647230"
  },
  {
    "text": "changed we just load the events as they arrive we process them very fast and the data simply available",
    "start": "2647230",
    "end": "2653670"
  },
  {
    "text": "it supports et al elt at scale machine learning natural language processing and",
    "start": "2653670",
    "end": "2660340"
  },
  {
    "text": "graph processing this is done using EMR and spark as well as the land of functions which will cover very briefly",
    "start": "2660340",
    "end": "2666880"
  },
  {
    "text": "in the session again the idea at the end of the results all of this is is done using a raven",
    "start": "2666880",
    "end": "2672760"
  },
  {
    "text": "platform and the data the raw data is available data blocks are available which allows you to consume for example",
    "start": "2672760",
    "end": "2680110"
  },
  {
    "text": "unified view of the whole clickstream transactional data a lot of data I've got a diagram next which illustrates",
    "start": "2680110",
    "end": "2686020"
  },
  {
    "text": "some of that and at the same time we're running analytics on metrics in near",
    "start": "2686020",
    "end": "2691780"
  },
  {
    "text": "real time so we actually know know what's happening so this is an overview of the Raven",
    "start": "2691780",
    "end": "2700390"
  },
  {
    "start": "2696000",
    "end": "2945000"
  },
  {
    "text": "platform at just giving so you can see at the top left we have kissmetrics",
    "start": "2700390",
    "end": "2706080"
  },
  {
    "text": "kissmetrics is essentially a client-side web analytics think of it as a google",
    "start": "2706080",
    "end": "2712510"
  },
  {
    "text": "analytics but more user level so you actually understanding what the user clicks on whereas google is typically",
    "start": "2712510",
    "end": "2719290"
  },
  {
    "text": "used more as an aggregate so you'd see page views but you don't necessarily know who actually did that",
    "start": "2719290",
    "end": "2724980"
  },
  {
    "text": "we also make use of Kinesis streams so this is on server-side analytics so we",
    "start": "2724980",
    "end": "2732130"
  },
  {
    "text": "have micro services and micro sites that actually send events in real time into",
    "start": "2732130",
    "end": "2737680"
  },
  {
    "text": "there we also have log stash so this is for the app logs and the web logs and",
    "start": "2737680",
    "end": "2743769"
  },
  {
    "text": "we're ingesting that also we also use qualary which is a like a mini survey",
    "start": "2743769",
    "end": "2749529"
  },
  {
    "text": "which pops up and see tries to understand almost what you're doing within the context of the actions you're",
    "start": "2749529",
    "end": "2756099"
  },
  {
    "text": "taking on the site or the mobile app you can see on the middle left side we have",
    "start": "2756099",
    "end": "2761980"
  },
  {
    "text": "api integration so this is just a subset of what we have so we have SurveyMonkey",
    "start": "2761980",
    "end": "2767349"
  },
  {
    "text": "for the largest surveys which are triggered automatically so we're bringing in the results of the survey ExactTarget which is the mailing so we",
    "start": "2767349",
    "end": "2774400"
  },
  {
    "text": "send out specific mail shots by email to specific users based on some",
    "start": "2774400",
    "end": "2779650"
  },
  {
    "text": "events we also bring in Twitter data as well as the news feed data and other open source data data sets you can see",
    "start": "2779650",
    "end": "2787510"
  },
  {
    "text": "at the bottom on the left we have facts and dimensions from our data warehouse that we also in jest as well as the oltp",
    "start": "2787510",
    "end": "2796119"
  },
  {
    "text": "files on the middle you see we've got the ingestion layer the integration",
    "start": "2796119",
    "end": "2801910"
  },
  {
    "text": "between all the services and this is where all the magic happens that some of the machine learning some of the ETL",
    "start": "2801910",
    "end": "2808359"
  },
  {
    "text": "process is actually done there again using an event-driven architecture for that",
    "start": "2808359",
    "end": "2814650"
  },
  {
    "text": "in the middle you see we've got data so Roger talks about data lake concepts so",
    "start": "2814650",
    "end": "2820420"
  },
  {
    "text": "this is something i really like I'm quite passionate about so we actually loading all the data everything ends up",
    "start": "2820420",
    "end": "2825819"
  },
  {
    "text": "in s3 and then gets loaded into red shift or into an EMR which stands for elastic",
    "start": "2825819",
    "end": "2832990"
  },
  {
    "text": "MapReduce cluster to actually query data from s3 the beauty and how we see it is",
    "start": "2832990",
    "end": "2838569"
  },
  {
    "text": "that the clusters are disposable so if we if we need another cluster we can",
    "start": "2838569",
    "end": "2846039"
  },
  {
    "text": "spin up a register for class two very easy at just giving and then reload all the data we process all the ETL",
    "start": "2846039",
    "end": "2851339"
  },
  {
    "text": "the master data almost is in s3 and on the right so we have different",
    "start": "2851339",
    "end": "2859839"
  },
  {
    "text": "tools to actually consume the data almost so because redshift is really open you can connect",
    "start": "2859839",
    "end": "2866260"
  },
  {
    "text": "by JDBC odbc postgres connections it's you can actually use data science tools",
    "start": "2866260",
    "end": "2872950"
  },
  {
    "text": "such as Python or are very easy spss to",
    "start": "2872950",
    "end": "2878170"
  },
  {
    "text": "actually connect there and actually i have the clean data set almost full consumption and if you think about everything that we have on the left is",
    "start": "2878170",
    "end": "2885360"
  },
  {
    "text": "effectively available so you can actually join the web analytics data",
    "start": "2885360",
    "end": "2890850"
  },
  {
    "text": "server side client side or the logs with all the API data that we know about the",
    "start": "2890850",
    "end": "2896380"
  },
  {
    "text": "users in turn externally as well as the data warehouse the transactional data and so transactional data will be the",
    "start": "2896380",
    "end": "2903730"
  },
  {
    "text": "fact that someone's donated at specific time and the charity transactions and if you think about joining all that data",
    "start": "2903730",
    "end": "2909250"
  },
  {
    "text": "together that's what we can do using this platform which is really powerful which gives you a full view of",
    "start": "2909250",
    "end": "2914820"
  },
  {
    "text": "the actual user again to help us provide them with more",
    "start": "2914820",
    "end": "2920380"
  },
  {
    "text": "engaging content on the right again if we just continue so we can connect using other tools so",
    "start": "2920380",
    "end": "2928270"
  },
  {
    "text": "for real time analytics we're using lambda to actually consume the data straight from Kinesis dreams",
    "start": "2928270",
    "end": "2933420"
  },
  {
    "text": "i'll show you next a brief peak on some of that we also use sparks to actually",
    "start": "2933420",
    "end": "2940450"
  },
  {
    "text": "consume and to run some of the further machine learning on on the platform",
    "start": "2940450",
    "end": "2946290"
  },
  {
    "start": "2945000",
    "end": "3068000"
  },
  {
    "text": "so this is a sneak peak i'm running a talk later on this afternoon at two-thirty and also because that's for",
    "start": "2946290",
    "end": "2953350"
  },
  {
    "text": "i'm running another one tomorrow I've got the details afterwards this is a pattern that we came up to create a",
    "start": "2953350",
    "end": "2959590"
  },
  {
    "text": "server lyst streaming analytics pattern and a way of actually persisting those",
    "start": "2959590",
    "end": "2965230"
  },
  {
    "text": "results permanently into s3 and loading it into subsequent systems so you can see on the left we talked about web",
    "start": "2965230",
    "end": "2971200"
  },
  {
    "text": "analytics for example so imagine that your web analytics is getting loaded into Kinesis onto dynamo streams that",
    "start": "2971200",
    "end": "2978670"
  },
  {
    "text": "data gets past using micro batches into a lander function lambda function then",
    "start": "2978670",
    "end": "2984820"
  },
  {
    "text": "runs a set of counts so imagine it's a fundraising page we want to analyze a specific page views for example for that",
    "start": "2984820",
    "end": "2991510"
  },
  {
    "text": "specific page so we can do a set of counting we can count impressions clicks maybe shares on Facebook that data can",
    "start": "2991510",
    "end": "2998640"
  },
  {
    "text": "get passed into cloud watch metrics which is an Amazon service which is",
    "start": "2998640",
    "end": "3004160"
  },
  {
    "text": "accessible on the console so there's nothing to create from there you've got a real-time platform that actually you",
    "start": "3004160",
    "end": "3011390"
  },
  {
    "text": "can see exactly the page views the alternative which is similar to Roger talked about is to actually also write",
    "start": "3011390",
    "end": "3018140"
  },
  {
    "text": "those results right all the counters into dynamo DD and then what I've",
    "start": "3018140",
    "end": "3023330"
  },
  {
    "text": "written is a tranche j/s using node and JavaScript to actually",
    "start": "3023330",
    "end": "3028910"
  },
  {
    "text": "read that data almost read those pages in real-time chat them over time and allow for real-time updates",
    "start": "3028910",
    "end": "3035140"
  },
  {
    "text": "equally you can have that displayed as a table so you can see actual page views and that allows us to almost in a",
    "start": "3035140",
    "end": "3040580"
  },
  {
    "text": "service way present the data results at the bottom so we've got the new",
    "start": "3040580",
    "end": "3046670"
  },
  {
    "text": "product which is Kinesis analytics which allows you to write SQL on top of the",
    "start": "3046670",
    "end": "3051830"
  },
  {
    "text": "stream of data so this could do the Patriots again push them to the fire hose the fire hose will then push those",
    "start": "3051830",
    "end": "3059300"
  },
  {
    "text": "results in 2's free for actual loading into the subsequent",
    "start": "3059300",
    "end": "3065530"
  },
  {
    "text": "redshift or spark the outcome",
    "start": "3065530",
    "end": "3072160"
  },
  {
    "text": "so amazon kinesis has allowed us to ingest our full click",
    "start": "3072160",
    "end": "3077660"
  },
  {
    "text": "stream so from the whole site in real time into our platform and allows us to",
    "start": "3077660",
    "end": "3083660"
  },
  {
    "text": "actually run real time analytics queries so we can actually understand down to the second almost what users are",
    "start": "3083660",
    "end": "3091550"
  },
  {
    "text": "actually doing on the platform and we've also talked about a pattern for actually persisting that which is useful",
    "start": "3091550",
    "end": "3098930"
  },
  {
    "text": "for persisting in long-term store in red shift so raven platform has allowed us to in",
    "start": "3098930",
    "end": "3107240"
  },
  {
    "text": "an event-driven way load data and process it in near real-time as a data arrives we actually process it and this",
    "start": "3107240",
    "end": "3113840"
  },
  {
    "text": "is thanks to using the managed services in AWS where we actually process where",
    "start": "3113840",
    "end": "3119840"
  },
  {
    "text": "there's actually not much to support as a managed service yeah there's not much to do for redshift",
    "start": "3119840",
    "end": "3126500"
  },
  {
    "text": "I'd say you can resize it very easily you can add more knows you can downsize",
    "start": "3126500",
    "end": "3131990"
  },
  {
    "text": "it it gets upgraded automatically it's a great service we also as we talked about",
    "start": "3131990",
    "end": "3139760"
  },
  {
    "text": "the event-driven side so we're using event-driven architecture as well as a service patterns so this is something i",
    "start": "3139760",
    "end": "3146270"
  },
  {
    "text": "recommend you should think about your organization also there's lots of benefits in not having a server running",
    "start": "3146270",
    "end": "3152569"
  },
  {
    "text": "so there's no box to remote onto to fix to apply a patch so you don't need to maintain the operating system or even",
    "start": "3152569",
    "end": "3159289"
  },
  {
    "text": "have a pipeline for maintaining containers so service is is a way you should really",
    "start": "3159289",
    "end": "3166640"
  },
  {
    "text": "definitely look into also and this is what we've been using extensively at just giving",
    "start": "3166640",
    "end": "3172000"
  },
  {
    "text": "using a managed services again we able to automatically run at scale so scale",
    "start": "3172000",
    "end": "3180680"
  },
  {
    "text": "out the number of queries as well as compute really complex queries again in near real time or as part of the batch",
    "start": "3180680",
    "end": "3187309"
  },
  {
    "text": "processes that we're running in red shift overall it's improve the productivity",
    "start": "3187309",
    "end": "3193190"
  },
  {
    "text": "considerably at just giving so we allow data scientists rather than reinventing the wheel cleansing all the dates of",
    "start": "3193190",
    "end": "3199490"
  },
  {
    "text": "doing a massive drawing every time we actually have that ready available for experimentation they can take that data",
    "start": "3199490",
    "end": "3204829"
  },
  {
    "text": "run the a/b tests directly run the machine learning models try and understand the user's query are give",
    "start": "3204829",
    "end": "3211220"
  },
  {
    "text": "graph directly so this saves considerable map time and it's something that often people talk about data",
    "start": "3211220",
    "end": "3216319"
  },
  {
    "text": "science they don't realize that maybe eighty percent of that it's actually data preparation preparing the data",
    "start": "3216319",
    "end": "3221539"
  },
  {
    "text": "frames ready for querying cleansing the data enriching the data we've actually done that already so are they scientists",
    "start": "3221539",
    "end": "3228260"
  },
  {
    "text": "love it and that's that's a really valuable thing in terms of resourcing again the",
    "start": "3228260",
    "end": "3235970"
  },
  {
    "text": "ultimate aim for the business is to provide more insight to what's happening on the site provide insight to the actual users",
    "start": "3235970",
    "end": "3242109"
  },
  {
    "text": "measure the success of a product and how we release those features as well as",
    "start": "3242109",
    "end": "3247220"
  },
  {
    "text": "predict what are the new features we should release what products also as well as we talked about recommending for",
    "start": "3247220",
    "end": "3254240"
  },
  {
    "text": "example recommending what is a perfect fundraising page how can you achieve the perfect planning page to actually",
    "start": "3254240",
    "end": "3261470"
  },
  {
    "text": "raise money for the was that you really care about",
    "start": "3261470",
    "end": "3266090"
  },
  {
    "start": "3266000",
    "end": "3310000"
  },
  {
    "text": "so thank you very much the attention and I like to say that if you want to get more details I'm going to drill into a",
    "start": "3266480",
    "end": "3272070"
  },
  {
    "text": "lot more of this in terms of the service data pipelines the event-driven etl and",
    "start": "3272070",
    "end": "3277349"
  },
  {
    "text": "the stream processing so there's a session later on this afternoon as well",
    "start": "3277349",
    "end": "3282690"
  },
  {
    "text": "as tomorrow which is a repeat session so thank you for your attention and how to",
    "start": "3282690",
    "end": "3288900"
  },
  {
    "text": "think about how you can use tech for good or so thank you",
    "start": "3288900",
    "end": "3293030"
  },
  {
    "text": "thank you thank you Richard I was actually extremely",
    "start": "3295670",
    "end": "3300930"
  },
  {
    "text": "pleased from Richard agreed to talk not only is it service incredibly interesting but i love the application",
    "start": "3300930",
    "end": "3307440"
  },
  {
    "text": "it's a beautiful application of technology ok that was one example i",
    "start": "3307440",
    "end": "3312930"
  },
  {
    "start": "3310000",
    "end": "3346000"
  },
  {
    "text": "just simply want to share with you we have over 170 unique customer references",
    "start": "3312930",
    "end": "3318090"
  },
  {
    "text": "for big data and analytics we have some of the largest enterprise customers such as GE Johnson & Johnson and Phillips we",
    "start": "3318090",
    "end": "3325740"
  },
  {
    "text": "have some of the most successful tech startups such as Airbnb and Pinterest largest media companies such as Hearst",
    "start": "3325740",
    "end": "3332220"
  },
  {
    "text": "and netflix using AWS as well as highly regulated organizations and agencies",
    "start": "3332220",
    "end": "3337339"
  },
  {
    "text": "FINRA nazdik NASA so again a lot of companies are making big bets but it's",
    "start": "3337339",
    "end": "3343260"
  },
  {
    "text": "still very early days on Big Data folks i hope you enjoy the rest of the day here in AWS big data conn these are",
    "start": "3343260",
    "end": "3351900"
  },
  {
    "start": "3346000",
    "end": "3362000"
  },
  {
    "text": "the talks that will be held here in this building throughout the rest of the day if something is piqued your interest please look at the agenda i think you'll",
    "start": "3351900",
    "end": "3358140"
  },
  {
    "text": "find a talk that will take you on a deeper dive of many of the stuff that we've just talked about we also lose",
    "start": "3358140",
    "end": "3363900"
  },
  {
    "start": "3362000",
    "end": "3381000"
  },
  {
    "text": "your slides will be available we have resources should you want to actually get started on your own journey that are",
    "start": "3363900",
    "end": "3369390"
  },
  {
    "text": "available I'll leave this up and simply thank you and actually encourage you to do the give us take the survey give us",
    "start": "3369390",
    "end": "3375900"
  },
  {
    "text": "some feedback and enjoy the rest of reinvent in the Big Data con thank you",
    "start": "3375900",
    "end": "3383299"
  }
]
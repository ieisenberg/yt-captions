[
  {
    "text": "right yes yes yes perfect hi uh my name's uh AI Krishan and I'm the product",
    "start": "240",
    "end": "6480"
  },
  {
    "text": "manager on Amazon Kinesis uh thank you very very much uh for joining us today",
    "start": "6480",
    "end": "12120"
  },
  {
    "text": "this afternoon gosh it was uh a year ago right here that we launched uh Amazon",
    "start": "12120",
    "end": "17840"
  },
  {
    "text": "Kinesis uh fully managed service streaming data ingestion that enables continuous processing and it's uh",
    "start": "17840",
    "end": "23279"
  },
  {
    "text": "amazing that we can still have all of you here with us uh looking to learn a bit more about the",
    "start": "23279",
    "end": "28960"
  },
  {
    "text": "service there's a lot there's a lot of content here today for us to walk through so I'll keep it snappy uh keep it moving",
    "start": "28960",
    "end": "36399"
  },
  {
    "text": "and uh you know it's a full 45 minutes of content and we'll spend time any questions take it afterwards or of",
    "start": "36399",
    "end": "42719"
  },
  {
    "text": "course you can always uh reach out to any number of us on the team uh but a quick show of hands how many of you are",
    "start": "42719",
    "end": "49399"
  },
  {
    "text": "current Kinesis users okay I would say that's about 15",
    "start": "49399",
    "end": "55399"
  },
  {
    "text": "20% how many of you are here uh sort of know something about Kinesis but really",
    "start": "55399",
    "end": "61160"
  },
  {
    "text": "would appreciate a little bit more of a 200 level okay perfect okay um that so",
    "start": "61160",
    "end": "68479"
  },
  {
    "text": "so this session is a deep dive it is a 400 level session which means that there is some amount of uh knowledge that we",
    "start": "68479",
    "end": "75080"
  },
  {
    "text": "assume going in but but given where you you guys are and uh given our kind of customer feedback driven nature I might",
    "start": "75080",
    "end": "82040"
  },
  {
    "text": "end up spending some more time on kind of the the basics but we'll definitely run through some of the more interesting",
    "start": "82040",
    "end": "88320"
  },
  {
    "text": "concepts of things that you must know or things uh uh that we wish we told you",
    "start": "88320",
    "end": "94119"
  },
  {
    "text": "a year ago right when you started building the applications with",
    "start": "94119",
    "end": "99719"
  },
  {
    "text": "kis so just just a quick note first on on actual scenarios that we've seen in",
    "start": "100360",
    "end": "107200"
  },
  {
    "text": "the last year pop up now streaming data is all said and done cool sexy topic for",
    "start": "107200",
    "end": "114000"
  },
  {
    "text": "us to talk about but it's still in its infancy which means that what we notice is use cases going through this uh",
    "start": "114000",
    "end": "121719"
  },
  {
    "text": "progression as as as users discover what streaming data can do for them and indeed the the most prominent use case",
    "start": "121719",
    "end": "129200"
  },
  {
    "text": "which is kind of the the scenario number one in there is really just continuous ingestion of data to deposit it into",
    "start": "129200",
    "end": "136400"
  },
  {
    "text": "some store like S3 or red shift or or some other",
    "start": "136400",
    "end": "141480"
  },
  {
    "text": "database so it's not fancy realtime analytics it's really just movement of",
    "start": "141480",
    "end": "147440"
  },
  {
    "text": "small fast moving data data that's coming from your log servers application servers clickstream data data coming",
    "start": "147440",
    "end": "154040"
  },
  {
    "text": "from your sensors uh your mobile apps what have you but just simply that kind of small fast moving data that's being",
    "start": "154040",
    "end": "160920"
  },
  {
    "text": "produced and generated continuously to capture that in a durable uh reliable",
    "start": "160920",
    "end": "167159"
  },
  {
    "text": "form and then move that after some set of light Transformations light reshaping",
    "start": "167159",
    "end": "173200"
  },
  {
    "text": "into some uh a versatile store like S3 after which you can do something",
    "start": "173200",
    "end": "178480"
  },
  {
    "text": "meaningful with it so so that's kind of use case number one and regardless of what vertical you're in there is some",
    "start": "178480",
    "end": "184040"
  },
  {
    "text": "flavor of accelerated data ingestion that is happening now as soon as we see",
    "start": "184040",
    "end": "189480"
  },
  {
    "text": "customers do that there is always this innate desire to say well what if I can now generate kpis metrics of that",
    "start": "189480",
    "end": "196640"
  },
  {
    "text": "streaming data I might want to display that on a dashboard uh create some sort of a live site metric a number of these",
    "start": "196640",
    "end": "203440"
  },
  {
    "text": "other use cases normally related to uh visualization I'm not necessarily",
    "start": "203440",
    "end": "209000"
  },
  {
    "text": "talking about D Rich visualization but this is mostly time series data uh",
    "start": "209000",
    "end": "214159"
  },
  {
    "text": "window analytics count sums averages uh you know weighted averages Ballinger",
    "start": "214159",
    "end": "219720"
  },
  {
    "text": "bands stuff that is bread and butter uh but has enormous applicability across",
    "start": "219720",
    "end": "226480"
  },
  {
    "text": "different verticals and different use cases because the math is the same the output feels a little different but",
    "start": "226480",
    "end": "231959"
  },
  {
    "text": "that's where we find kind of the stage two and where we seeing now uh some",
    "start": "231959",
    "end": "237319"
  },
  {
    "text": "customers move into is this notion of responsib data analytics where where this streaming fresh data is now part of",
    "start": "237319",
    "end": "244879"
  },
  {
    "text": "some other richer feedback loop so nearline recommendation systems how do we optimize and enrich what we know",
    "start": "244879",
    "end": "252200"
  },
  {
    "text": "about a given customer who's on the website right now given their past uh",
    "start": "252200",
    "end": "257799"
  },
  {
    "text": "past visitor or buying history it it it comes at uh comes into play in in",
    "start": "257799",
    "end": "263240"
  },
  {
    "text": "auditing use cases well what happened in the past when I saw similar data so now that fresh stream data is looking into",
    "start": "263240",
    "end": "270000"
  },
  {
    "text": "another data store stuff is getting enriched so these are definitely more full-blown applications and and we see",
    "start": "270000",
    "end": "276600"
  },
  {
    "text": "customers move in into that that kind of level so you know it's easy to remember things in three and and as you think",
    "start": "276600",
    "end": "282800"
  },
  {
    "text": "about your journey with streaming data it's possibly going to be uh helpful to say well where am I where where would I",
    "start": "282800",
    "end": "288479"
  },
  {
    "text": "like to be at step one and step two okay so quick overview uh for some",
    "start": "288479",
    "end": "296080"
  },
  {
    "text": "of you this is old hat for for the rest of you probably the first little cartoon diagram about what Amazon Kinesis is so",
    "start": "296080",
    "end": "303520"
  },
  {
    "text": "manage service streaming data ingestion continuous processing so three things that I'd like for you to remember the",
    "start": "303520",
    "end": "310360"
  },
  {
    "text": "actual data source can be any any producer that can do uh an HTTP call",
    "start": "310360",
    "end": "317520"
  },
  {
    "text": "right uh at the end of the day you put data log servers application servers uh",
    "start": "317520",
    "end": "322880"
  },
  {
    "text": "mobile phone apps as I as I mentioned earlier you put data into into Amazon",
    "start": "322880",
    "end": "328639"
  },
  {
    "text": "kinesis aw style authentication authorization happens on the front ends",
    "start": "328639",
    "end": "334400"
  },
  {
    "text": "and this small fast moving data lands into a stream The Entity that you own",
    "start": "334400",
    "end": "339600"
  },
  {
    "text": "and operate all data gets three-way replicated across availability zones so",
    "start": "339600",
    "end": "344639"
  },
  {
    "text": "this is durability uh that you just get with the service no special knobs no",
    "start": "344639",
    "end": "350639"
  },
  {
    "text": "special levers no config changes that you need to make this is durable this is",
    "start": "350639",
    "end": "356360"
  },
  {
    "text": "a highly consistent way of storing data and the reason that is important in the",
    "start": "356360",
    "end": "361919"
  },
  {
    "text": "Kinesis world and the streaming data world is that as soon as the data hits the service you want the ability to",
    "start": "361919",
    "end": "368520"
  },
  {
    "text": "consume that data and you want to consume that data in multiple concurrent forms this is the second facet of stream",
    "start": "368520",
    "end": "376880"
  },
  {
    "text": "processing which is small fast moving data that you capture quickly and then",
    "start": "376880",
    "end": "381960"
  },
  {
    "text": "invariably what you want to do is drive multiple different consumers that are",
    "start": "381960",
    "end": "387599"
  },
  {
    "text": "independently but concurrently processing the same stream but for different use cases so in in the little",
    "start": "387599",
    "end": "394479"
  },
  {
    "text": "cartoons that you see on on the on the right hand side you might have an application that is consuming that",
    "start": "394479",
    "end": "401000"
  },
  {
    "text": "streaming data applying some some business specific Aggregate and then emitting that data into S3 that's his",
    "start": "401000",
    "end": "408520"
  },
  {
    "text": "job in life you could have another application that's concurrently perhaps",
    "start": "408520",
    "end": "413759"
  },
  {
    "text": "trailing 15 minutes behind the first one has its own independent cursor on the Stream and is reshaping the data and",
    "start": "413759",
    "end": "421800"
  },
  {
    "text": "then emitting that into red shift so now you've got fresh data that you've captured via Kinesis transformed loaded",
    "start": "421800",
    "end": "429680"
  },
  {
    "text": "up into your data warehouse in 15 minutes or less for instance it could be shorter but let's just pick that number",
    "start": "429680",
    "end": "435560"
  },
  {
    "text": "because it's way better than end of day it is way better than hourly uh and it's",
    "start": "435560",
    "end": "440720"
  },
  {
    "text": "really powerful because now all of your data sits in a place like red shift it could be another data warehouse but now",
    "start": "440720",
    "end": "447319"
  },
  {
    "text": "the rest of your organization has access to that that freshest data you could have another application that's",
    "start": "447319",
    "end": "452759"
  },
  {
    "text": "generating realtime kpis and dashboards and all of these applications are concurrently consuming from the same",
    "start": "452759",
    "end": "459560"
  },
  {
    "text": "data and this is at the end of the day the power of streaming data that you can collect all of your data collect it",
    "start": "459560",
    "end": "466720"
  },
  {
    "text": "continuously and expose that data to multiple different stakeholders by way of those specific",
    "start": "466720",
    "end": "474800"
  },
  {
    "text": "applications let's get a little bit more concrete in",
    "start": "475919",
    "end": "481120"
  },
  {
    "text": "Kinesis you're looking at two two components if you will the first",
    "start": "481120",
    "end": "487199"
  },
  {
    "text": "component is manage real time data ingestion so capture and storage of data",
    "start": "487199",
    "end": "494240"
  },
  {
    "text": "at scale and when you're building such a system you need to have certain properties we care a lot about scale you",
    "start": "494240",
    "end": "499960"
  },
  {
    "text": "might be at you know a few megabytes per hour today but your infrastructure might sending you might you might end up",
    "start": "499960",
    "end": "505840"
  },
  {
    "text": "sending a few gigabytes a few terabytes um and we seeing that growth happen so",
    "start": "505840",
    "end": "512518"
  },
  {
    "text": "one thing is to not necessarily get turned off by the notion of oh this is really about",
    "start": "512519",
    "end": "517760"
  },
  {
    "text": "scale it is but it's really about capturing your data as quickly as it's generated so that you can do something",
    "start": "517760",
    "end": "523800"
  },
  {
    "text": "meaningful with it it has to be durable because this is this is your data that's being captured your customers",
    "start": "523800",
    "end": "529800"
  },
  {
    "text": "interactions your billing data your metered data and you don't want to lose it cuz in many cases we've seen losing",
    "start": "529800",
    "end": "536399"
  },
  {
    "text": "data literally is losing money because the bill that You' have computed from that data is now cannot be done so it",
    "start": "536399",
    "end": "543600"
  },
  {
    "text": "has to be elastic there's a hit application that you create and suddenly you drive 5 million new users you want",
    "start": "543600",
    "end": "551200"
  },
  {
    "text": "your data ingestion engine to be able to scale elastically to consume that data",
    "start": "551200",
    "end": "556279"
  },
  {
    "text": "and last but not the least uh something that's unique to to streaming data system is that you want to have this",
    "start": "556279",
    "end": "561839"
  },
  {
    "text": "notion of a replayable read right CU you have multiple applications Each of which can be at different points in the Stream",
    "start": "561839",
    "end": "568640"
  },
  {
    "text": "one is right now right here one is 15 minutes behind and maybe you have a slow coach application that is coming along 2",
    "start": "568640",
    "end": "576160"
  },
  {
    "text": "hours behind wall clock time one of these applications any of these applications all of these applications",
    "start": "576160",
    "end": "582040"
  },
  {
    "text": "might fail when these applications come back up they only resume processing from",
    "start": "582040",
    "end": "587079"
  },
  {
    "text": "the pointer where they left off at so that's a notion of a replayable data so that's kind of the core realtime",
    "start": "587079",
    "end": "594959"
  },
  {
    "text": "ingestion component then there is a notion of continuous real-time prod processing okay the data is stored and",
    "start": "594959",
    "end": "601320"
  },
  {
    "text": "captured it's it's it exists as an ordered event stream that you can Now",
    "start": "601320",
    "end": "607000"
  },
  {
    "text": "consume it from but how does one go about authoring a stream processing application and that sort of an",
    "start": "607000",
    "end": "614040"
  },
  {
    "text": "application too has certain characteristics it's elastic you can go from 10 Megs per second to 100 Megs per",
    "start": "614040",
    "end": "620399"
  },
  {
    "text": "second and how does your application react to that new incoming data the application needs to have the",
    "start": "620399",
    "end": "626839"
  },
  {
    "text": "ability to load balance the incoming data across all the available instances on which it's running you do care about",
    "start": "626839",
    "end": "634560"
  },
  {
    "text": "fall tolerance you want the ability to easily checkpoint the data to replay the data in in in accord with the ingestion",
    "start": "634560",
    "end": "643760"
  },
  {
    "text": "Pipeline and last but not the least as I mentioned earlier you won't have multiple numbers of these applications",
    "start": "643760",
    "end": "650480"
  },
  {
    "text": "because once you start streaming data there's always this desire to have plug in that next application to see what",
    "start": "650480",
    "end": "656399"
  },
  {
    "text": "else you can do in the business and you want to do all of this in as manager form as possible so that",
    "start": "656399",
    "end": "661920"
  },
  {
    "text": "you can get on with business uh the endtoend latency has to be as low as possible because remember we looking at",
    "start": "661920",
    "end": "668600"
  },
  {
    "text": "a transition from a batch oriented view where you used to collect all the data in your ingestor tier spool it to disk",
    "start": "668600",
    "end": "676079"
  },
  {
    "text": "after a few hours maybe end of day snapshot that data into something like S3 run a",
    "start": "676079",
    "end": "683320"
  },
  {
    "text": "massive hadoo job that etls the data out and then loads it into some processing",
    "start": "683320",
    "end": "688760"
  },
  {
    "text": "engine we've all done it uh we still do it in fact I would be interested in a show of fans of how many of you have",
    "start": "688760",
    "end": "695000"
  },
  {
    "text": "this batch oriented way of collecting your own data and then ultimately getting into some persistent",
    "start": "695000",
    "end": "701240"
  },
  {
    "text": "store that's great the rest of you are lying um and then last but not the least one",
    "start": "701240",
    "end": "708079"
  },
  {
    "text": "of our our goals was not to create yet another trap or Silo for data right you",
    "start": "708079",
    "end": "713320"
  },
  {
    "text": "want to be able to move the data into multiple different processing engines data stores many of which a lot of",
    "start": "713320",
    "end": "720160"
  },
  {
    "text": "options exist uh including options we announced today and we want to be able to move the data into all those",
    "start": "720160",
    "end": "725760"
  },
  {
    "text": "different stores so that you can apply the right tool set for the right",
    "start": "725760",
    "end": "730880"
  },
  {
    "text": "job okay so some more Concepts uh a stream is a manage entity that you",
    "start": "732360",
    "end": "738720"
  },
  {
    "text": "create it takes three clicks on the console to create a stream as part of the stream creation process you say how",
    "start": "738720",
    "end": "744800"
  },
  {
    "text": "many shards you'd like a Shard is a unit of scale and a unit of parallelism each Shard can do a megabyte per second",
    "start": "744800",
    "end": "751920"
  },
  {
    "text": "in 2 Megs per second out which means let's say you're generating 100 megabytes per second across your",
    "start": "751920",
    "end": "757800"
  },
  {
    "text": "infrastructure logging tier you'd say Kinesis give me a stream with 100 shards and in 10 or 12 seconds you get a fully",
    "start": "757800",
    "end": "764920"
  },
  {
    "text": "manage capability to durably capture reliably store elastically scale all of",
    "start": "764920",
    "end": "770079"
  },
  {
    "text": "this 100 megabytes per second of data as quickly as you can throw it inside of",
    "start": "770079",
    "end": "775680"
  },
  {
    "text": "Kinesis Kinesis is a moving time window buffer on that data all data by default",
    "start": "775680",
    "end": "782399"
  },
  {
    "text": "is retained for a period of 24 hours and the oldest data is expired out of the system so good news bad news good news",
    "start": "782399",
    "end": "789399"
  },
  {
    "text": "is all data is stored for 24 hours which means that your consumers have at least that much time to pull the data off the",
    "start": "789399",
    "end": "796320"
  },
  {
    "text": "stream and do something meaningful with it on the downside you have 24 hours so",
    "start": "796320",
    "end": "801800"
  },
  {
    "text": "you would want to read that data as quickly as possible uh in your use cases",
    "start": "801800",
    "end": "807519"
  },
  {
    "text": "you're not locked into the capacity that you set at time of creation at any point",
    "start": "807519",
    "end": "812720"
  },
  {
    "text": "during operation you can say split that Shard which means there will be two where there was one which means you",
    "start": "812720",
    "end": "818720"
  },
  {
    "text": "effectively double the capacity of that Shard at any point during operation you can say merge the shards you can take",
    "start": "818720",
    "end": "824440"
  },
  {
    "text": "two adjacent shards of capacity and fuse them into one so these are all online operations I.E you can put data consume",
    "start": "824440",
    "end": "832399"
  },
  {
    "text": "data but the stream Still Remains an operation while it's being scaled up or scaled down these are operations that",
    "start": "832399",
    "end": "839360"
  },
  {
    "text": "you explicitly invoke and we'll talk a little bit about practices around that so how do you put data into Kinesis",
    "start": "839360",
    "end": "847079"
  },
  {
    "text": "you put data into Kinesis using the put record API which has your stream name that you've created the actual data blob",
    "start": "847079",
    "end": "854160"
  },
  {
    "text": "the log line the sensor data the clickstream data as the case might be and this thing called a partition key",
    "start": "854160",
    "end": "860440"
  },
  {
    "text": "you own your partition key strategy it is a way to distribute the data across",
    "start": "860440",
    "end": "866320"
  },
  {
    "text": "all the shards in your stream when you put data with a given partition key we",
    "start": "866320",
    "end": "871839"
  },
  {
    "text": "generate an nd5 hash of that partition key which falls on a certain hash key",
    "start": "871839",
    "end": "876880"
  },
  {
    "text": "value which will always be inside of a hash key range of Any Given Shard this",
    "start": "876880",
    "end": "882320"
  },
  {
    "text": "is interesting because every time you put data in that in that stream with that partition key it always gets routed",
    "start": "882320",
    "end": "889440"
  },
  {
    "text": "into that specific Shard and as we'll discuss later there are a couple of mindsets around this you can think about",
    "start": "889440",
    "end": "895839"
  },
  {
    "text": "Kinesis as just a way to capture all of your data right so just buffer my data",
    "start": "895839",
    "end": "901519"
  },
  {
    "text": "across all the shs in my stream it doesn't matter uh where they exactly",
    "start": "901519",
    "end": "906680"
  },
  {
    "text": "land because you just want to capture your data the other mental model is to say wait a minute I have a streaming map",
    "start": "906680",
    "end": "913440"
  },
  {
    "text": "ruce capability because each time I put data on a partition key it always lands on a given Shard which means on the",
    "start": "913440",
    "end": "920199"
  },
  {
    "text": "other end when the consumer is picking data from the stream from that Shard it will always see all the data that landed",
    "start": "920199",
    "end": "927279"
  },
  {
    "text": "on that Shard so that's the streaming mapper concept and U and in our experience and best practice as",
    "start": "927279",
    "end": "933120"
  },
  {
    "text": "customers see it they fall in one of these two camps mostly customers fall in the camp of I just want to get all my",
    "start": "933120",
    "end": "939839"
  },
  {
    "text": "data in I'll Generate random partition keys and let them land wherever they land but I just want it all captured as",
    "start": "939839",
    "end": "946199"
  },
  {
    "text": "quickly as possible every successful put is acknowledged with a monotonically",
    "start": "946199",
    "end": "951560"
  },
  {
    "text": "increasing sequence number per record that's put in the Stream So as you were discussing",
    "start": "951560",
    "end": "959000"
  },
  {
    "text": "determine your partition key strategy right you decide whether you're manage buffer or you're streaming map",
    "start": "959000",
    "end": "964480"
  },
  {
    "text": "reduce if you're going to go down the route of a managed buffer uh choose a",
    "start": "964480",
    "end": "969639"
  },
  {
    "text": "high cardinality of partition keys with respect to number of shards you want to",
    "start": "969639",
    "end": "974759"
  },
  {
    "text": "do that because you don't want to get into a hot Shard or a hot partition key problem what will happen then is you",
    "start": "974759",
    "end": "980880"
  },
  {
    "text": "will get a provision through PR exceeded error from Kinesis documented API response syntax and and what you're",
    "start": "980880",
    "end": "987800"
  },
  {
    "text": "going to face potentially is oh can I not get any more data in and while the rest of your shards might be running",
    "start": "987800",
    "end": "993920"
  },
  {
    "text": "cold might be running mostly empty and you might want to make sure that you generate enough partition Keys such that",
    "start": "993920",
    "end": "1000120"
  },
  {
    "text": "the data is uniformly distributed across uh most of the shards in your system the second one as we discussed",
    "start": "1000120",
    "end": "1006959"
  },
  {
    "text": "was the the streaming mapper concept this is useful we do some of this internally ourselves we think about",
    "start": "1006959",
    "end": "1013399"
  },
  {
    "text": "using partition Keys um on on device types we think about using partition ke",
    "start": "1013399",
    "end": "1018959"
  },
  {
    "text": "Keys as a certain application version and so all data related to that application version lands on this family",
    "start": "1018959",
    "end": "1026079"
  },
  {
    "text": "or this set of partition Keys that's useful CU then our application that's consuming that data can do something",
    "start": "1026079",
    "end": "1032079"
  },
  {
    "text": "meaningful with it provision adequate shorts now this is",
    "start": "1032079",
    "end": "1038079"
  },
  {
    "text": "kind of a a a no-brainer but it is a provision model at the end of the day",
    "start": "1038079",
    "end": "1043199"
  },
  {
    "text": "which means that there is this implicit contract between the Kinesis service and you as a user to say you will tell us",
    "start": "1043199",
    "end": "1049360"
  },
  {
    "text": "beforehand how many shards you want in your capacity you want to provision adequate",
    "start": "1049360",
    "end": "1054480"
  },
  {
    "text": "shards obviously for your Ingress if you're sending 10 Megs per second you want to have at least 10 10 shards in",
    "start": "1054480",
    "end": "1060080"
  },
  {
    "text": "your stream but you want to do a little bit more you want always want to have some Headroom um and we've seen",
    "start": "1060080",
    "end": "1065679"
  },
  {
    "text": "customers have up to 20 30 40% Headroom for the event of spiky in the case of spiky events mostly it's okay because",
    "start": "1065679",
    "end": "1073760"
  },
  {
    "text": "Kinesis shards happen to be uh remarkably cost effective but you also",
    "start": "1073760",
    "end": "1078840"
  },
  {
    "text": "also need to provision adequate shards for your egress needs remember you might have multiple applications consuming",
    "start": "1078840",
    "end": "1085720"
  },
  {
    "text": "from the same Shard and A Shard can do 2 Megs per second egress right so what if now you",
    "start": "1085720",
    "end": "1092200"
  },
  {
    "text": "have three shards uh what if you have three applications or four now you're running into a world where what",
    "start": "1092200",
    "end": "1098440"
  },
  {
    "text": "dominates your sizing and your capacity is the number of hungry applications you",
    "start": "1098440",
    "end": "1103600"
  },
  {
    "text": "want to feed more so than even the data you're going to put in so you should bear that in mind",
    "start": "1103600",
    "end": "1109280"
  },
  {
    "text": "also includes some Headroom for the catchup scenario an application might fail it might fail for 4 hours it comes",
    "start": "1109280",
    "end": "1116120"
  },
  {
    "text": "back up is going to request all the data it's going to be super hungry you got to feed that guy which means that it might",
    "start": "1116120",
    "end": "1122000"
  },
  {
    "text": "end up consuming all of your Shard egis band withd So for those catchup style scenarios you might want to think a",
    "start": "1122000",
    "end": "1128280"
  },
  {
    "text": "little bit more about depending on the application U the criticality of the",
    "start": "1128280",
    "end": "1133520"
  },
  {
    "text": "application uh if you should have certain more Shard capacity allocated in",
    "start": "1133520",
    "end": "1138799"
  },
  {
    "text": "into your Stream So provision adequate shards next best practice for putting",
    "start": "1138799",
    "end": "1144320"
  },
  {
    "text": "data sometimes it's not a terrible idea to do kind of a micro batch before you",
    "start": "1144320",
    "end": "1150360"
  },
  {
    "text": "do a put in many use cases we've seen that the individual data record is a few",
    "start": "1150360",
    "end": "1156120"
  },
  {
    "text": "hundred bytes that's it a single Kinesis payload can be as big as 50 kilobytes so",
    "start": "1156120",
    "end": "1162400"
  },
  {
    "text": "there is some wisdom in saying I'm going to help uh aggregate 50 or 100 of these",
    "start": "1162400",
    "end": "1168760"
  },
  {
    "text": "individual few hundred byte records and then execute a put record call https put",
    "start": "1168760",
    "end": "1175159"
  },
  {
    "text": "record calls put calls cost some they cost some efficiency they cost some CPU Cycles you want want to make sure that",
    "start": "1175159",
    "end": "1181440"
  },
  {
    "text": "you optimize for those for those kinds of put record calls and to enable you to",
    "start": "1181440",
    "end": "1186799"
  },
  {
    "text": "do that there are options uh you could use uh some of the great open-source uh",
    "start": "1186799",
    "end": "1192720"
  },
  {
    "text": "collectors and agents like fluent D or Flume in fact if you use use fluent D it",
    "start": "1192720",
    "end": "1198720"
  },
  {
    "text": "will generate uh as as a as a collector let's say running on your log server it can it can Generate random partition",
    "start": "1198720",
    "end": "1205400"
  },
  {
    "text": "Keys you can set a certain number of threads so it can buffer data locally on your producer in case there in case U",
    "start": "1205400",
    "end": "1212799"
  },
  {
    "text": "there's a network issue or it's unable to reach the service and then it can retry on your behalf so this is stuff",
    "start": "1212799",
    "end": "1218960"
  },
  {
    "text": "that you can just leverage using something like flu and do your Flume um uh the GitHub where it's available is",
    "start": "1218960",
    "end": "1225440"
  },
  {
    "text": "right there on on the slide itself you may not want to do that however you might say no I'm going to just use the",
    "start": "1225440",
    "end": "1231360"
  },
  {
    "text": "AWS SDK in which case what we've noticed is that using the async producer which",
    "start": "1231360",
    "end": "1236960"
  },
  {
    "text": "surprisingly uh lots of people discover for the first time when we talk through high through with data ingestion uh is",
    "start": "1236960",
    "end": "1243120"
  },
  {
    "text": "is a good idea now the there's a default thread pool executor within the AWS STK",
    "start": "1243120",
    "end": "1249480"
  },
  {
    "text": "in in all the languages available that can buffer up to can that can run up to 50 threads in tandem so you can get to a",
    "start": "1249480",
    "end": "1256000"
  },
  {
    "text": "reasonable throughput efficiency because if your server your log server for instance is producing a th000 records",
    "start": "1256000",
    "end": "1263120"
  },
  {
    "text": "per second you might have to do something special in there to get the data onto Kinesis so using something",
    "start": "1263120",
    "end": "1270000"
  },
  {
    "text": "like the async producer is a good idea you might you might also face a a choice",
    "start": "1270000",
    "end": "1275840"
  },
  {
    "text": "about well what if I run out of 50 threads right you might have to now think about some local queuing strategy",
    "start": "1275840",
    "end": "1282679"
  },
  {
    "text": "so using some of these options like either a synchronous queue or an array blocking queue available as part of the",
    "start": "1282679",
    "end": "1289360"
  },
  {
    "text": "the async producer are good options to work through in your specific use cases",
    "start": "1289360",
    "end": "1294559"
  },
  {
    "text": "because the goal here is to do some pre- batching to get to a higher efficiency throughput inside of your Kinesis",
    "start": "1294559",
    "end": "1302080"
  },
  {
    "text": "stream you can do other things you could use something like lock for j u",
    "start": "1302080",
    "end": "1307240"
  },
  {
    "text": "obviously it's not a traditional collector or agent in the traditional sense of the word uh but as part of your",
    "start": "1307240",
    "end": "1312360"
  },
  {
    "text": "application you can use lock for also available uh for putting data in into",
    "start": "1312360",
    "end": "1317919"
  },
  {
    "text": "kinesis um you can do a number of different things you can set max retries you can set the buffer size you can set thread",
    "start": "1317919",
    "end": "1324760"
  },
  {
    "text": "count so on so forth uh but this is again just available for you to pick up so that you can get to putting data uh",
    "start": "1324760",
    "end": "1331640"
  },
  {
    "text": "most effectively",
    "start": "1331640",
    "end": "1337600"
  },
  {
    "text": "so it is a provision model however and what happens when you start getting",
    "start": "1337600",
    "end": "1343039"
  },
  {
    "text": "provision throughput exceeded errors now you will get a provision throughput exceeded exception when either you're",
    "start": "1343039",
    "end": "1350360"
  },
  {
    "text": "sending in uh more data that you've provisioned for and this can happen",
    "start": "1350360",
    "end": "1355400"
  },
  {
    "text": "either by exceeding the megabytes per second on any given Shard or by exceeding the TPS rate on",
    "start": "1355400",
    "end": "1362080"
  },
  {
    "text": "any given Shard so let's say that one Shard can do a megabyte per second and you try and send 1.1 megabyte per second",
    "start": "1362080",
    "end": "1370240"
  },
  {
    "text": "you'll get a through put exceeded error it happens so what what do we do in those",
    "start": "1370240",
    "end": "1377320"
  },
  {
    "text": "circumstances is not good to go in with that knowledge for the first set is well you",
    "start": "1377320",
    "end": "1384320"
  },
  {
    "text": "got to retry it's always a good idea and you'll probably do that retry logic even if you use the core AWS STK um the next",
    "start": "1384320",
    "end": "1392120"
  },
  {
    "text": "action will be to say okay I'm going to rehard right so looks like I don't have enough shards or I've come across this",
    "start": "1392120",
    "end": "1398919"
  },
  {
    "text": "hot Shard that is giving me this provision through put exceeded error and what I need to do is split that Shard to",
    "start": "1398919",
    "end": "1404960"
  },
  {
    "text": "get into more shards so the way you would want to do",
    "start": "1404960",
    "end": "1410000"
  },
  {
    "text": "that is first and foremost track track the core metrics like put",
    "start": "1410000",
    "end": "1416480"
  },
  {
    "text": "record bytes put record latency and the success count that are all emitted on a",
    "start": "1416480",
    "end": "1421520"
  },
  {
    "text": "per stream basis uh one of the important parts about making something like Kinesis a backbone for your logging data",
    "start": "1421520",
    "end": "1430360"
  },
  {
    "text": "U is to make sure that you're paying attention to these metrics for instance you provisioned 100 shards in your",
    "start": "1430360",
    "end": "1436400"
  },
  {
    "text": "stream you know it cuz you provisioned it which which means that you cannot in theory get greater than 100 Megs per",
    "start": "1436400",
    "end": "1441440"
  },
  {
    "text": "second if you put record request bytes crosses that threshold or if you're",
    "start": "1441440",
    "end": "1446640"
  },
  {
    "text": "wiser you would probably say 70% or 60% of provision threshold it's normally a",
    "start": "1446640",
    "end": "1451880"
  },
  {
    "text": "good indicator back to you to say okay I think something is up I must initiate a splitshot API command now I realized",
    "start": "1451880",
    "end": "1459080"
  },
  {
    "text": "that I haven't talked through the splitshot API um you know on account of",
    "start": "1459080",
    "end": "1464600"
  },
  {
    "text": "uh the Deep dive nature of the session it was an assumption probably an incorrect one the splitshot API is",
    "start": "1464600",
    "end": "1470760"
  },
  {
    "text": "documented in our API reference guide so for those of you who are online you should probably check it out it it has",
    "start": "1470760",
    "end": "1475880"
  },
  {
    "text": "its own kind of the the sister version which is the merge Shard which will take two shards and combine them into one",
    "start": "1475880",
    "end": "1481399"
  },
  {
    "text": "documented apis please have a look at split shot and merge Shard so but sometimes that stuff is not",
    "start": "1481399",
    "end": "1489240"
  },
  {
    "text": "enough right you might say I actually want on a p short level understanding of how is my data doing not at a stream",
    "start": "1489240",
    "end": "1496679"
  },
  {
    "text": "wide level so to do that there are you have a couple of",
    "start": "1496679",
    "end": "1502279"
  },
  {
    "text": "options the partition key that you use as you know is put nv5 hash a hash key",
    "start": "1502279",
    "end": "1508039"
  },
  {
    "text": "is generated so the first thing would be to keep track of the hash key values of",
    "start": "1508039",
    "end": "1513559"
  },
  {
    "text": "the records that you putting in you can do that because the partition",
    "start": "1513559",
    "end": "1518640"
  },
  {
    "text": "key that you send you can derive an md5 hash from that the second one is to keep",
    "start": "1518640",
    "end": "1524720"
  },
  {
    "text": "track of The Shard IDs themselves The Shard IDs are returned uh there's a",
    "start": "1524720",
    "end": "1530480"
  },
  {
    "text": "method called get Shard ID as part of the put record result object that you can invoke to get back to an idea of",
    "start": "1530480",
    "end": "1536679"
  },
  {
    "text": "which Shard did the data land into and you can maintain on the side for a per",
    "start": "1536679",
    "end": "1543080"
  },
  {
    "text": "Shard ID basis what are how many times have the hash key values hit I.E how",
    "start": "1543080",
    "end": "1548840"
  },
  {
    "text": "full is my Shard and that information can normally be used as a best practice",
    "start": "1548840",
    "end": "1554120"
  },
  {
    "text": "to say I think Shard ID 00003 is is the one that's going to get",
    "start": "1554120",
    "end": "1559399"
  },
  {
    "text": "filled or is is likely going to be a hot Shard that Shard ID then can be passed",
    "start": "1559399",
    "end": "1565240"
  },
  {
    "text": "as a split Shard API command reference and you can just say split down this",
    "start": "1565240",
    "end": "1570279"
  },
  {
    "text": "hash key and you'll get two shards where instead there was just one and this is again an online operation so this is",
    "start": "1570279",
    "end": "1576880"
  },
  {
    "text": "normally a good best practice when you're sending in a fair bit of data I I'll have to say this though for a lot",
    "start": "1576880",
    "end": "1582720"
  },
  {
    "text": "of customers because of Kinesis cost Effectiveness you just run with more shards and you can forget about",
    "start": "1582720",
    "end": "1589360"
  },
  {
    "text": "everything I just told you you provisioned enough and life is",
    "start": "1589360",
    "end": "1594000"
  },
  {
    "text": "good yeah what is that uh but we can do something better",
    "start": "1594799",
    "end": "1600399"
  },
  {
    "text": "so how do we get to this uh scaling of Kinesis shards thing now the good news is that there is another utility that",
    "start": "1600399",
    "end": "1606960"
  },
  {
    "text": "one of our uh fantastic solution Architects wrote and this is kind of the the sh scaling utility and that's what",
    "start": "1606960",
    "end": "1614080"
  },
  {
    "text": "it looks like it takes your stream name and obviously the region in which you run the stream itself um you you say if you wanted to scale up",
    "start": "1614080",
    "end": "1621440"
  },
  {
    "text": "or scale down uh you can either give it a count I I want to scale up by 10 more",
    "start": "1621440",
    "end": "1627520"
  },
  {
    "text": "shards or you can give it a percent scale up by 10% more so which is",
    "start": "1627520",
    "end": "1633559"
  },
  {
    "text": "normally maybe a little better strategy than saying when I start getting a provision through prot exceeded error",
    "start": "1633559",
    "end": "1638720"
  },
  {
    "text": "I'll just double the number of shards which I've seen many people do it is a peace of mind simpler approach but",
    "start": "1638720",
    "end": "1645520"
  },
  {
    "text": "perhaps if you're looking for the next level of optimization then you might want to do something like this of course you can you know use your",
    "start": "1645520",
    "end": "1652760"
  },
  {
    "text": "own as complex as you want it to be short scaling uh um strategy as well but",
    "start": "1652760",
    "end": "1659399"
  },
  {
    "text": "this is is a neat way to just get started um and not end up highly",
    "start": "1659399",
    "end": "1664799"
  },
  {
    "text": "over-provisioned but be somewhat rightly over-provisioned okay so this is a a",
    "start": "1664799",
    "end": "1671039"
  },
  {
    "text": "good place to checkpoint real quick because we're talking about uh sending data into Kinesis variety of different",
    "start": "1671039",
    "end": "1676720"
  },
  {
    "text": "ways um AWS SDK also available in the mobile SDK there's this thing called",
    "start": "1676720",
    "end": "1682679"
  },
  {
    "text": "Kinesis recorder inside of it so in case that's part of your mobile apps you can",
    "start": "1682679",
    "end": "1687720"
  },
  {
    "text": "put data in Kinesis if you have the mobile SDK compiled in we talked about log for J Flume and fluent D let's pivot",
    "start": "1687720",
    "end": "1695080"
  },
  {
    "text": "let's pivot into consuming data so this was part one right so we have ingested",
    "start": "1695080",
    "end": "1700200"
  },
  {
    "text": "data done so hopefully with a few best practices partition keying uh",
    "start": "1700200",
    "end": "1705360"
  },
  {
    "text": "provisioning adequate shots for Ingress and egress um as well as thinking through scaling and what the right model",
    "start": "1705360",
    "end": "1711120"
  },
  {
    "text": "could be this is part B how do you build applications so let's talk through some",
    "start": "1711120",
    "end": "1716960"
  },
  {
    "text": "more theory about the Kinesis client Library this is an open-source Library",
    "start": "1716960",
    "end": "1722600"
  },
  {
    "text": "available in Java and also in Python for all developers a source available on GitHub and it is one way one way to",
    "start": "1722600",
    "end": "1729320"
  },
  {
    "text": "start building stream processing applications using Amazon Kinesis the application you build is deployed um",
    "start": "1729320",
    "end": "1736720"
  },
  {
    "text": "onto your set of E two instances so remember assembly is required this is a",
    "start": "1736720",
    "end": "1742519"
  },
  {
    "text": "developer oriented offering the application itself could be as simple as aggregate move data to S3 or it could be",
    "start": "1742519",
    "end": "1749159"
  },
  {
    "text": "the most wonderful online Machining machine learning algorithm that you're writing it is an application that has to",
    "start": "1749159",
    "end": "1754679"
  },
  {
    "text": "be written the application is written uh using the client Library you can deploy it onto your set of ec2 instances and",
    "start": "1754679",
    "end": "1762519"
  },
  {
    "text": "here are a few components that you you'll become quickly aware of if not already uh there is a notion of a work",
    "start": "1762519",
    "end": "1770000"
  },
  {
    "text": "that is something that the Kinesis client library that have abbreviated as KCl will manage on a per ec2 instance",
    "start": "1770000",
    "end": "1777279"
  },
  {
    "text": "basis for your application there is a record processor Factory that will create your piece of",
    "start": "1777279",
    "end": "1784240"
  },
  {
    "text": "business logic that you've already authored into it and spin it up as a process the record processor is that",
    "start": "1784240",
    "end": "1791919"
  },
  {
    "text": "becomes then that processing unit that consumes data from A Shard and actually",
    "start": "1791919",
    "end": "1797120"
  },
  {
    "text": "does your processing that's the icord processor the Kinesis",
    "start": "1797120",
    "end": "1803120"
  },
  {
    "text": "client Library uses the iord processor interface to communicate with your application so let's say your",
    "start": "1803120",
    "end": "1809559"
  },
  {
    "text": "application is I read the data that's being popped into me all I do is that I",
    "start": "1809559",
    "end": "1815240"
  },
  {
    "text": "wait for a th records I run a gzip and then I flush it",
    "start": "1815240",
    "end": "1820279"
  },
  {
    "text": "to S3 let's say that's the reason of existence for your application that logic would be implemented as part of",
    "start": "1820279",
    "end": "1827000"
  },
  {
    "text": "the ORD processor that's where your logic will live there's a whole bunch of housekeeping stuff startup shutdown",
    "start": "1827000",
    "end": "1833120"
  },
  {
    "text": "stuff the KCl takes care of you but really where you focus is in that iord processor",
    "start": "1833120",
    "end": "1838720"
  },
  {
    "text": "interface so what the KCl is going to do then for you is that it's going to spin",
    "start": "1838720",
    "end": "1844080"
  },
  {
    "text": "up a record processor per Shard so if you have a two Shard stream KCl on your",
    "start": "1844080",
    "end": "1850200"
  },
  {
    "text": "application's behalf is going to spin up two record processors as an application developer you don't worry about how many",
    "start": "1850200",
    "end": "1857039"
  },
  {
    "text": "shards are there in a stream at any point in time CU that is something that will change something that you will",
    "start": "1857039",
    "end": "1863200"
  },
  {
    "text": "change in fact and what you want to be focused on is in the core application logic and what the KCl is going to do is",
    "start": "1863200",
    "end": "1869840"
  },
  {
    "text": "is that it's going to first spin up uh a worker per ec2 instance because you could have many instances in your",
    "start": "1869840",
    "end": "1876039"
  },
  {
    "text": "application it's going then going to spin up a record processor per Shard is going to create a Shard",
    "start": "1876039",
    "end": "1883559"
  },
  {
    "text": "management table on your application's behalf inside of it is going to write",
    "start": "1883559",
    "end": "1889039"
  },
  {
    "text": "write down how many shards there are in the Stream the ID of that Shard the",
    "start": "1889039",
    "end": "1894120"
  },
  {
    "text": "beginning ending hash key of that Shard is going to allocate a record processor per Shard and it's going to enable you",
    "start": "1894120",
    "end": "1901600"
  },
  {
    "text": "to drive checkpoints you can say checkpoint after each record processor sees 100 records so on so",
    "start": "1901600",
    "end": "1909159"
  },
  {
    "text": "forth it will balance the shards uh the shards and the record processors as your",
    "start": "1909159",
    "end": "1915559"
  },
  {
    "text": "ec2 instances grow or Shrink it will balance uh shards and workers as",
    "start": "1915559",
    "end": "1921600"
  },
  {
    "text": "your shards merge and split so again as an application developer all of your focus is in the iord proster logic um",
    "start": "1921600",
    "end": "1929519"
  },
  {
    "text": "and the Kinesis client Library manages all of that state and for those of you who who've Wrestled a zookeeper to the",
    "start": "1929519",
    "end": "1936559"
  },
  {
    "text": "ground know how that can be a challenging timec consuming task and think of this as kind of a lightweight",
    "start": "1936559",
    "end": "1942960"
  },
  {
    "text": "distributed coordination capability for your streaming application something that you would have had to otherwise",
    "start": "1942960",
    "end": "1948760"
  },
  {
    "text": "managed by herself or through some other uh some other rich but complex",
    "start": "1948760",
    "end": "1955240"
  },
  {
    "text": "framework that was core KCl let's talk about this companion library that not many people know of again uh that",
    "start": "1957679",
    "end": "1965600"
  },
  {
    "text": "customers over time have picked up and has come up as a best practice which is that one of the biggest use cases as I",
    "start": "1965600",
    "end": "1971960"
  },
  {
    "text": "said earlier was moving that data into S3 red shift the Kinesis connector like library",
    "start": "1971960",
    "end": "1978279"
  },
  {
    "text": "is built on the Kinesis client Library as a name suggests it's a library again it's also open source and available for",
    "start": "1978279",
    "end": "1984840"
  },
  {
    "text": "all developers and it defines this pipeline inside of it the pipeline itself has a transform",
    "start": "1984840",
    "end": "1991880"
  },
  {
    "text": "filter buffer emit set of interfaces that you can then override and we'll go",
    "start": "1991880",
    "end": "1997720"
  },
  {
    "text": "into these in successive levels of detail but the KE key but the key key thing here is uh connect there's a",
    "start": "1997720",
    "end": "2004679"
  },
  {
    "text": "client library that helps you get up and running and a Connect library that allows you to then Cobble together your",
    "start": "2004679",
    "end": "2010840"
  },
  {
    "text": "streaming data with these destinations like S3 red shift Dynamo uh we also have",
    "start": "2010840",
    "end": "2016559"
  },
  {
    "text": "this for elastic search so if you want to pump all the streaming data into your elastic search cluster that too is",
    "start": "2016559",
    "end": "2022720"
  },
  {
    "text": "possible because the connector library has been extended to support elastic search as well so in the guts the the",
    "start": "2022720",
    "end": "2030240"
  },
  {
    "text": "record processor um the the Kinesis connector record",
    "start": "2030240",
    "end": "2037200"
  },
  {
    "text": "processor is the base class um you know it implements the record processor interface of the Kinesis client library",
    "start": "2037200",
    "end": "2043399"
  },
  {
    "text": "that we saw earlier um and it contains a few key classes uh the Transformer",
    "start": "2043399",
    "end": "2050480"
  },
  {
    "text": "filter buffer and emiter as we mentioned earlier and let's dig into these in in",
    "start": "2050480",
    "end": "2056398"
  },
  {
    "text": "subsequent uh levels of detail so the first one is a Transformer class uh you",
    "start": "2056399",
    "end": "2062599"
  },
  {
    "text": "want that because your data might be coming through in any format that you've put in and you might want to trans",
    "start": "2062599",
    "end": "2067720"
  },
  {
    "text": "transform it per some business specific use case um so for instance you have uh",
    "start": "2067720",
    "end": "2074158"
  },
  {
    "text": "you know you raw Jon style data and you want to convert that into some CSV style",
    "start": "2074159",
    "end": "2080480"
  },
  {
    "text": "data for your that is time stamp and by event type a billable event a new new",
    "start": "2080480",
    "end": "2087760"
  },
  {
    "text": "customer a new customer install event as the case might be so transforming is the most foundational step typically as you",
    "start": "2087760",
    "end": "2094358"
  },
  {
    "text": "consume the Kinesis record from the stream and then use a transform Library here to Define this custom serializer",
    "start": "2094359",
    "end": "2101720"
  },
  {
    "text": "deserializer uh there are a couple of uh and need to send this because it's a",
    "start": "2101720",
    "end": "2107480"
  },
  {
    "text": "pipeline the transformed uh the output of the transformed stage should be in a form that the I emitter class in the",
    "start": "2107480",
    "end": "2114839"
  },
  {
    "text": "next stage would be willing to accept you have a string to string Transformer you have a basic Json Transformer uh",
    "start": "2114839",
    "end": "2121160"
  },
  {
    "text": "that that's available right now in within the within the",
    "start": "2121160",
    "end": "2126200"
  },
  {
    "text": "library the filter method very frequently even though you capture all your data you",
    "start": "2126640",
    "end": "2132040"
  },
  {
    "text": "want to reshape and recope a lot of it out um and and that's kind of the the ey",
    "start": "2132040",
    "end": "2137400"
  },
  {
    "text": "filter method U really there's a keep record and an all pass you want to keep all your data or you want to filter a",
    "start": "2137400",
    "end": "2143320"
  },
  {
    "text": "bunch of it out quite simple uh but uh in many times PE customers have not",
    "start": "2143320",
    "end": "2149280"
  },
  {
    "text": "discovered this so it's use it's a useful useful uh method to undergo in your umu in your",
    "start": "2149280",
    "end": "2156640"
  },
  {
    "text": "applications then you have the buffer uh the I buffer",
    "start": "2156640",
    "end": "2163440"
  },
  {
    "text": "defines a system for uh batching all the data portions of the data that you've",
    "start": "2163440",
    "end": "2169000"
  },
  {
    "text": "received via the the Kinesis stream before you send it along its way normally a good idea to do some level of",
    "start": "2169000",
    "end": "2176359"
  },
  {
    "text": "buffering uh or micro batching as some people might call it before you send the data along its way for instance if",
    "start": "2176359",
    "end": "2182560"
  },
  {
    "text": "you're putting data into S3 normally a good idea to buffer it up to you know a few meab and size to make that an",
    "start": "2182560",
    "end": "2189359"
  },
  {
    "text": "efficient Rite if you're going to send that data along to Red shift also good idea uh to do some buffering if you're",
    "start": "2189359",
    "end": "2195800"
  },
  {
    "text": "going to send that data into Dynamo DB maybe you do want to do batch puts but",
    "start": "2195800",
    "end": "2201079"
  },
  {
    "text": "always good to have that option as you're thinking about how do you buffer the data before we send it on to the",
    "start": "2201079",
    "end": "2206599"
  },
  {
    "text": "next",
    "start": "2206599",
    "end": "2208800"
  },
  {
    "text": "stage so the connectors then that you need to be aware of uh the S3 connector for batch writing files uh for",
    "start": "2213040",
    "end": "2219960"
  },
  {
    "text": "ultimately storage in S3 and it'll use uh by default a sequence-based file",
    "start": "2219960",
    "end": "2225880"
  },
  {
    "text": "naming scheme your mileage may vary you might want to affect certain date time uh event type and so on so forth to",
    "start": "2225880",
    "end": "2232599"
  },
  {
    "text": "prefix those files before they land into S3 uh but that is that is also possible in as much as it's um as it's available",
    "start": "2232599",
    "end": "2239920"
  },
  {
    "text": "as Source the red shift connector which we'll talk about in some more detail is more interesting uh because it actually",
    "start": "2239920",
    "end": "2246839"
  },
  {
    "text": "leverages their S3 connector there isn't yet a magical way to get the data into red shift S3 is still continues to be a",
    "start": "2246839",
    "end": "2254800"
  },
  {
    "text": "great way to load data into red shift uh but the interesting thing is that it provides manifest support so you can put",
    "start": "2254800",
    "end": "2261000"
  },
  {
    "text": "the data into S3 create a manifest stream and it'll execute the red shift load from within S3 on your",
    "start": "2261000",
    "end": "2269000"
  },
  {
    "text": "behalf so let's let's look at some best practices as it pertains to processing",
    "start": "2269000",
    "end": "2275440"
  },
  {
    "text": "data from Kinesis the first one is is don't run an application on a single E2",
    "start": "2275440",
    "end": "2280480"
  },
  {
    "text": "instance stand alone put it in an autoscaling group even if you're not looking at scale putting it in an",
    "start": "2280480",
    "end": "2286920"
  },
  {
    "text": "autoscaling group just for the notion of uh High availability such that at least one instance is always up consuming the",
    "start": "2286920",
    "end": "2294200"
  },
  {
    "text": "data is a good idea so basically a scaling group of one uh it's all but in general it's a",
    "start": "2294200",
    "end": "2301160"
  },
  {
    "text": "good idea because your incoming data might be spiky right there might be uh legitimate cases where you're sending",
    "start": "2301160",
    "end": "2307200"
  },
  {
    "text": "aot more data and you want to make sure that this consuming application as simple or as complex as it might be",
    "start": "2307200",
    "end": "2313359"
  },
  {
    "text": "running on ec2 instances has the ability to respond and the KCl interoperates",
    "start": "2313359",
    "end": "2319680"
  },
  {
    "text": "with the autoscaling group so all the shards the workers the record processes that we spoke about automatically get",
    "start": "2319680",
    "end": "2325880"
  },
  {
    "text": "load balanced uh in response to these incoming uh uh with response to this",
    "start": "2325880",
    "end": "2330960"
  },
  {
    "text": "increased load on the system you can use any set of scaling metrics you can use the metrics you know and love that are",
    "start": "2330960",
    "end": "2337000"
  },
  {
    "text": "instan base CPU base so on so forth you can also use Kinesis metrics so scale",
    "start": "2337000",
    "end": "2342359"
  },
  {
    "text": "kick off or trigger the autoscaling group when the incoming data uh hits you know greater than n megabytes per second",
    "start": "2342359",
    "end": "2349760"
  },
  {
    "text": "as captured by put record bytes metric so as you're writing this",
    "start": "2349760",
    "end": "2355880"
  },
  {
    "text": "application you'll sometimes run into this issue of saying why is my consumer",
    "start": "2355880",
    "end": "2361280"
  },
  {
    "text": "slow I.E I know I put this data but is my consumer fall",
    "start": "2361280",
    "end": "2368040"
  },
  {
    "text": "behind why how will I how how do I get to know that it's going to catch",
    "start": "2368040",
    "end": "2373920"
  },
  {
    "text": "up metrics again are normally a good idea to as a first instance detect why",
    "start": "2374000",
    "end": "2380560"
  },
  {
    "text": "is my consumer slow and in that journey of figuring out why is your consumer slow why is your stream processing",
    "start": "2380560",
    "end": "2386160"
  },
  {
    "text": "application not running uh with the freshest data that's into it you your",
    "start": "2386160",
    "end": "2392000"
  },
  {
    "text": "best friends are get records iterator age and get records latency specifically",
    "start": "2392000",
    "end": "2397599"
  },
  {
    "text": "get record iterator Age Now the iterator is that cursor that any application",
    "start": "2397599",
    "end": "2404400"
  },
  {
    "text": "grabs onto the stream itself so if that iterator age is old what that means is",
    "start": "2404400",
    "end": "2411520"
  },
  {
    "text": "that your consumer has is seeing older and older data in the streaming World",
    "start": "2411520",
    "end": "2417040"
  },
  {
    "text": "older data means it was put a longer time ago than data that is quote unquote",
    "start": "2417040",
    "end": "2422920"
  },
  {
    "text": "now so you might want to watch out for get records or iterator age to say and maybe even set an alert against it to",
    "start": "2422920",
    "end": "2429200"
  },
  {
    "text": "say well I was really expecting my record processor and my consumer to be running under this millisecond threshold",
    "start": "2429200",
    "end": "2435760"
  },
  {
    "text": "remember it's in milliseconds not seconds minutes or hours so there'll be many many zeros and make sure you divide",
    "start": "2435760",
    "end": "2441240"
  },
  {
    "text": "by 100 as appropriate um and it's normally a good idea to pay attention",
    "start": "2441240",
    "end": "2446839"
  },
  {
    "text": "then to the get records iterator metric there are a bunch of other metrics that are also useful to get a sense for how",
    "start": "2446839",
    "end": "2453560"
  },
  {
    "text": "is my processing application doing but that's your best friend",
    "start": "2453560",
    "end": "2459240"
  },
  {
    "text": "it's it's a little unusual to call this a best practice uh because in many cases that is the scenario but build a put to",
    "start": "2460079",
    "end": "2468720"
  },
  {
    "text": "S3 an archive to S3 or a flush to S3 consumer application always a good idea",
    "start": "2468720",
    "end": "2473839"
  },
  {
    "text": "to capture all of your data and keep it in S3 because not only might you legitimately need it to extract out via",
    "start": "2473839",
    "end": "2480680"
  },
  {
    "text": "EMR or run whatever other process on it including move it to Red shift uh but also in the case something happens",
    "start": "2480680",
    "end": "2487319"
  },
  {
    "text": "applications is down um uh your Downstream applications down you have a source of Truth where all of your data",
    "start": "2487319",
    "end": "2494200"
  },
  {
    "text": "has been captured um as we talked about in the uh in the I",
    "start": "2494200",
    "end": "2500160"
  },
  {
    "text": "buffer case you can trigger the buffer flush based on number of counts amount of data and time since last flush your",
    "start": "2500160",
    "end": "2506920"
  },
  {
    "text": "mileage may vary depending on how you want to invoke the flush of data into S3",
    "start": "2506920",
    "end": "2513040"
  },
  {
    "text": "but these are your three big options for you to kind of uh work through when it comes to I have gathered my data I've",
    "start": "2513040",
    "end": "2519480"
  },
  {
    "text": "transformed it potentially filtered it and now is when I'm going to actually flush it after buffering so normally a",
    "start": "2519480",
    "end": "2526040"
  },
  {
    "text": "good idea to keep that in mind one thing that will come up time",
    "start": "2526040",
    "end": "2532280"
  },
  {
    "text": "and time again in several use cases is okay we're talking about a stream processing system with varying amounts",
    "start": "2532280",
    "end": "2538800"
  },
  {
    "text": "of load in it and there is the notion of duplicates",
    "start": "2538800",
    "end": "2544040"
  },
  {
    "text": "right there is the notion of my application failed it came back up it used the checkpoints that was great but",
    "start": "2544040",
    "end": "2550839"
  },
  {
    "text": "it ended up reprocessing data so it important processing or at least more",
    "start": "2550839",
    "end": "2555960"
  },
  {
    "text": "generally speaking getting to this at Le uh uh it says at least once a year it",
    "start": "2555960",
    "end": "2562319"
  },
  {
    "text": "really should read uh exactly once is a much much higher bar and and that",
    "start": "2562319",
    "end": "2568480"
  },
  {
    "text": "typically takes a lot more work from a developer and Architects perspective to put together now there are a few general",
    "start": "2568480",
    "end": "2575440"
  },
  {
    "text": "purpose techniques that we uh over time discovered as being things that that derive that give you maximum",
    "start": "2575440",
    "end": "2582119"
  },
  {
    "text": "Roi right for for the effort that you put in uh the first one is um any",
    "start": "2582119",
    "end": "2587160"
  },
  {
    "text": "checkpointing that you write using the KCl that you can configure do so after you've persisted the data so in the S3",
    "start": "2587160",
    "end": "2594520"
  },
  {
    "text": "case as we saw earlier you know flush to S3 then then do the checkpoint that's normally a good idea",
    "start": "2594520",
    "end": "2601839"
  },
  {
    "text": "the second is a notion of duplicate processing duplicates can be introduced anywhere in the process",
    "start": "2601839",
    "end": "2607760"
  },
  {
    "text": "the core Kinesis service won't introduce one but it can happen for instance your producer is putting data in and uh it",
    "start": "2607760",
    "end": "2615480"
  },
  {
    "text": "gets the ACT except the ACT doesn't reach it and it ends up retrying so now the producer has put data twice and the",
    "start": "2615480",
    "end": "2622559"
  },
  {
    "text": "same data has landed on your stream twice there is no inbuilt dupli dup",
    "start": "2622559",
    "end": "2628400"
  },
  {
    "text": "method inside of cor Kinesis and that will be a problem that'll have to be tackled at the consuming application",
    "start": "2628400",
    "end": "2634240"
  },
  {
    "text": "layer uh and it normally helps to have the the authoritative data repository could be Dynamo DB could be some other",
    "start": "2634240",
    "end": "2641160"
  },
  {
    "text": "key value store could be redis could be S3 but you want to make sure that that",
    "start": "2641160",
    "end": "2646559"
  },
  {
    "text": "place is where you deal with",
    "start": "2646559",
    "end": "2649920"
  },
  {
    "text": "duplicates moving data into red shift can also be accomplished using the",
    "start": "2652280",
    "end": "2657640"
  },
  {
    "text": "Kinesis connector Library so we so as we talked through earlier transform filter buffer",
    "start": "2657640",
    "end": "2664079"
  },
  {
    "text": "EMT and as we said it uses the S3 uh uses S3 underneath to move the data into",
    "start": "2664079",
    "end": "2672200"
  },
  {
    "text": "red shift there isn't a direct mechanism yet a good way to do it is to use the",
    "start": "2672200",
    "end": "2678400"
  },
  {
    "text": "red shift manifest emiter so how it's going to work is you have incoming kesa",
    "start": "2678400",
    "end": "2683559"
  },
  {
    "text": "stream you define your S3 manifest pipeline using the connector",
    "start": "2683559",
    "end": "2689240"
  },
  {
    "text": "um you write the data with with the connector into your S3 files you use the",
    "start": "2689240",
    "end": "2696160"
  },
  {
    "text": "you use the red shift manifest emitor to create a new oneshot stream the data in",
    "start": "2696160",
    "end": "2703040"
  },
  {
    "text": "that oneshot stream is simply going to be the names of the S3 files so that's your",
    "start": "2703040",
    "end": "2709480"
  },
  {
    "text": "manifest what what the what the what the application can do for you then is invoke a red shift manifest copy command",
    "start": "2709480",
    "end": "2717200"
  },
  {
    "text": "on your behalf using the Manifest stream that was generated and the file names within it so this way you'll get to uh a",
    "start": "2717200",
    "end": "2723359"
  },
  {
    "text": "little bit more of a reliable uh way to load data into red shift via Kinesis and",
    "start": "2723359",
    "end": "2729880"
  },
  {
    "text": "run the risk of of of faulty loads less or so of course as part of this journey you",
    "start": "2729880",
    "end": "2736800"
  },
  {
    "text": "want to fine tune your application a little bit you should think about what a checkpoint frequency should be how big",
    "start": "2736800",
    "end": "2742720"
  },
  {
    "text": "you want the connector buffer should be U whether you should be using an all pass filter or do you want to remove a a",
    "start": "2742720",
    "end": "2749680"
  },
  {
    "text": "bunch of data that's already been consumed in the Stream itself but by using the Manifest connector you'll get into this better data load into red",
    "start": "2749680",
    "end": "2756680"
  },
  {
    "text": "shift and customers who have done this have have gotten to a much more reliable uh 10 to 15 minute load of data into red",
    "start": "2756680",
    "end": "2764680"
  },
  {
    "text": "shift which is U as I mentioned earlier a big win from getting to a daily or a",
    "start": "2764680",
    "end": "2771000"
  },
  {
    "text": "eight hourly or even an hourly data load uh into something like red shift it doesn't have to be red shift it could be",
    "start": "2771000",
    "end": "2776920"
  },
  {
    "text": "other things so I'll just leave you with with",
    "start": "2776920",
    "end": "2782160"
  },
  {
    "text": "a few things U customers are using Amazon Kinesis using some of these best practices to first get to a cost",
    "start": "2782160",
    "end": "2790040"
  },
  {
    "text": "effective reliable scalable way to collect all data of Interest the multiple consumer model means that uh",
    "start": "2790040",
    "end": "2796640"
  },
  {
    "text": "you can decide at any point in time to introduce new or different applications that are also processing data from the",
    "start": "2796640",
    "end": "2803040"
  },
  {
    "text": "same kesa stream without disrupting the other application it's a fully managed service",
    "start": "2803040",
    "end": "2809200"
  },
  {
    "text": "getting to a managed stream takes three clicks and yes you do invest some energy in building out an",
    "start": "2809200",
    "end": "2815480"
  },
  {
    "text": "application but ultimately using things like the client library and the connector Library you get a little bit",
    "start": "2815480",
    "end": "2821200"
  },
  {
    "text": "more productivity out of getting that code up and running quickly especially if you're Java and python",
    "start": "2821200",
    "end": "2828160"
  },
  {
    "text": "programmers and last but not the least moving data into all of these multiple",
    "start": "2828160",
    "end": "2833359"
  },
  {
    "text": "different data stores the same fresh data that is transformed or morphed in",
    "start": "2833359",
    "end": "2839119"
  },
  {
    "text": "aggregated in specific ways into these data stores means that it's not just for developers it's not just for devops now",
    "start": "2839119",
    "end": "2846200"
  },
  {
    "text": "marketing for folks can get data into red shift your uh your sales folks can get data other other portions of your",
    "start": "2846200",
    "end": "2853319"
  },
  {
    "text": "organization can all get access that same data and that at the end of the day is the most powerful uh fundamental",
    "start": "2853319",
    "end": "2860280"
  },
  {
    "text": "shift that the streaming data model introduces I know this was rush but you guys have been great uh I'm around for",
    "start": "2860280",
    "end": "2866800"
  },
  {
    "text": "more questions uh if you'd like to chat with me um but hopefully you got through a quick flavor of Amazon Kinesis and",
    "start": "2866800",
    "end": "2873520"
  },
  {
    "text": "what we've learned in terms of best practices on putting data and processing data with the Kinesis",
    "start": "2873520",
    "end": "2879359"
  },
  {
    "text": "client library and connected Library thank you very [Applause] [Music]",
    "start": "2879359",
    "end": "2887469"
  },
  {
    "text": "much",
    "start": "2887640",
    "end": "2890640"
  }
]
[
  {
    "text": "hello everyone hope you had a great day so far I know it's kind of the you know",
    "start": "30",
    "end": "6180"
  },
  {
    "text": "later half of the day but I'm sure we're gonna make this quite enriching sar you all ready for this awesome that's the",
    "start": "6180",
    "end": "14070"
  },
  {
    "text": "spirit my name is pronounced num BR I'm a senior manager on AWS I also have with",
    "start": "14070",
    "end": "20789"
  },
  {
    "text": "me Phillip Clegg who is the CTO of mayor of it together we're going to talk to you about search and building high scale",
    "start": "20789",
    "end": "28019"
  },
  {
    "text": "search architecture using Amazon Elastic search service so we're going to do the",
    "start": "28019",
    "end": "34920"
  },
  {
    "text": "section into two parts first of all I'll cover an introduction to search give you a peek into the various capabilities",
    "start": "34920",
    "end": "41190"
  },
  {
    "text": "that elasticsearch offers I want to talk about the benefits of using Amazon Elastic search service and then Phil is",
    "start": "41190",
    "end": "48030"
  },
  {
    "text": "going to come over and tell you about the mirror web story how they went about building some cool architecture for",
    "start": "48030",
    "end": "53850"
  },
  {
    "text": "their search a really good scale so with that let's get started since the session",
    "start": "53850",
    "end": "60809"
  },
  {
    "text": "is primarily about full-text search I thought why not start with the definition of full-text search you know",
    "start": "60809",
    "end": "67290"
  },
  {
    "text": "Wikipedia puts it as a collection of techniques to search through fields in a",
    "start": "67290",
    "end": "72299"
  },
  {
    "text": "document or a collection of documents against the search criteria so on that note how many of you have used full-text",
    "start": "72299",
    "end": "79860"
  },
  {
    "text": "search to show a show of hands okay pretty much all of you well search is pretty much everywhere",
    "start": "79860",
    "end": "86549"
  },
  {
    "text": "you know use full-text search when you use Google search or it in Liza's your",
    "start": "86549",
    "end": "91829"
  },
  {
    "text": "text tries to give you search results based on relevance you use full text search when you search on Amazon you",
    "start": "91829",
    "end": "98460"
  },
  {
    "text": "know it gives you the list of products it allows you to sort by relevance it even gives you facets on the side by",
    "start": "98460",
    "end": "104310"
  },
  {
    "text": "which you can drill deeper and refine your search you even use full text search when you search on social media",
    "start": "104310",
    "end": "110189"
  },
  {
    "text": "you know you search for tweets search by hashtags and so on search is pretty much everywhere and that's why the search",
    "start": "110189",
    "end": "117060"
  },
  {
    "text": "architecture becomes that much more critical but for us to understand you",
    "start": "117060",
    "end": "122219"
  },
  {
    "text": "know how to actually build an architecture that can stand the test of times we should get a better sense of",
    "start": "122219",
    "end": "128160"
  },
  {
    "text": "this so it stands today so you understand that how they look quickly at the evolution of",
    "start": "128160",
    "end": "135140"
  },
  {
    "text": "search so if you go back in time a few decades in time you know your primary",
    "start": "135140",
    "end": "142400"
  },
  {
    "text": "source of data was your database your traditional relational database at that",
    "start": "142400",
    "end": "147560"
  },
  {
    "text": "time if you had to do a search it would be a select star from there like you",
    "start": "147560",
    "end": "153290"
  },
  {
    "text": "know query if you had to try out different permutation combinations of your search term you have to add it your",
    "start": "153290",
    "end": "160940"
  },
  {
    "text": "you know select class and you know try out queries so what it did was it would",
    "start": "160940",
    "end": "166820"
  },
  {
    "text": "return to you a fixed set of results that match exactly to your terms it",
    "start": "166820",
    "end": "172040"
  },
  {
    "text": "operated on a smaller data volume but soon the world will vault you know you",
    "start": "172040",
    "end": "177080"
  },
  {
    "text": "got a lot different kinds of data you got the web content you got document you got emails and all this gave birth",
    "start": "177080",
    "end": "183770"
  },
  {
    "text": "to the initial generation of search engines these search engines bought a",
    "start": "183770",
    "end": "189740"
  },
  {
    "text": "sense of relevance to search so now it is not just about getting all matches it's about getting the best possible",
    "start": "189740",
    "end": "196160"
  },
  {
    "text": "match but that was not enough you know as the world evolved if you fast forward",
    "start": "196160",
    "end": "202520"
  },
  {
    "text": "to the current day look at all kinds of data they got some web contents to",
    "start": "202520",
    "end": "208160"
  },
  {
    "text": "weather content products catalogs and whatnot and the modern these search engines have also evolved you know",
    "start": "208160",
    "end": "215570"
  },
  {
    "text": "they've got much better mechanisms to rank your search providing a better relevance be able to handle a lot more",
    "start": "215570",
    "end": "223550"
  },
  {
    "text": "data volumes the author of you interesting search features like faceting suggestions and also they have",
    "start": "223550",
    "end": "230480"
  },
  {
    "text": "better you know language processing capabilities so for us to look at search architecture let's for a second ignore",
    "start": "230480",
    "end": "237290"
  },
  {
    "text": "all the technology elements here and just look at the trends that we are seeing over the years first of all this",
    "start": "237290",
    "end": "245060"
  },
  {
    "text": "is a no-brainer search has pretty much become an integral part of almost every product or service that you're building",
    "start": "245060",
    "end": "250370"
  },
  {
    "text": "you're building a mobile app you need search you're building any kind of you know ecommerce service you need search",
    "start": "250370",
    "end": "255590"
  },
  {
    "text": "almost everywhere you're looking you need search either externally facing or maybe even internal for your own",
    "start": "255590",
    "end": "261410"
  },
  {
    "text": "consumption the other key trend is structured data it's now giving",
    "start": "261410",
    "end": "267050"
  },
  {
    "text": "to unstructured or semi-structured data gone are the days where you had everything in a tabular you know",
    "start": "267050",
    "end": "272930"
  },
  {
    "text": "relational database format now you got different more flexible formats but that's not it you know data volume is",
    "start": "272930",
    "end": "280430"
  },
  {
    "text": "increasing your performance requirements are increasing also the need to analyze",
    "start": "280430",
    "end": "286220"
  },
  {
    "text": "text in a smart way you know language of airway is also increasing so now given",
    "start": "286220",
    "end": "293030"
  },
  {
    "text": "that you're all part of the session I'm sure you all agree with the first point but now when you are building a search architecture you need to make sure that",
    "start": "293030",
    "end": "300020"
  },
  {
    "text": "it can cater to all the other points because that's where the world is heading so in response to all this the",
    "start": "300020",
    "end": "307419"
  },
  {
    "text": "several search engines available in the market today sure you know according to",
    "start": "307419",
    "end": "313789"
  },
  {
    "text": "DB engines these are the top five search engines of which we're gonna look at the",
    "start": "313789",
    "end": "319729"
  },
  {
    "text": "first one lastik such lastik search is one of the more popular search engines",
    "start": "319729",
    "end": "325669"
  },
  {
    "text": "out there it's open source easy to onboard can't handle high performance",
    "start": "325669",
    "end": "331969"
  },
  {
    "text": "and high scale really well because it's distributed system it also offers you a lot of extensibility mechanism it",
    "start": "331969",
    "end": "338840"
  },
  {
    "text": "enables you to ingest data and process data very well and visualize them well it's also what capable can be used even",
    "start": "338840",
    "end": "345500"
  },
  {
    "text": "for analytics and search but now the key part here is it is a distributed system",
    "start": "345500",
    "end": "351800"
  },
  {
    "text": "and so you still have to deal with managing one or more clusters of nodes and then handling the patching the",
    "start": "351800",
    "end": "358610"
  },
  {
    "text": "maintenance the availability and so on that's where Amazon Elastic search",
    "start": "358610",
    "end": "364219"
  },
  {
    "text": "service comes in so Amazon Elastic search service gives you a manager interface for lasting search so",
    "start": "364219",
    "end": "371719"
  },
  {
    "text": "literally what it does is it takes away the hassle of managing your instances setting up deploying and scaling and all",
    "start": "371719",
    "end": "378199"
  },
  {
    "text": "that so essentially you know if you were to look at it in terms of benefits what it",
    "start": "378199",
    "end": "383629"
  },
  {
    "text": "does is first of all it's fully compatible throughout this elastic search it's open source API so you can easily just migrate and replace elastic",
    "start": "383629",
    "end": "390379"
  },
  {
    "text": "search with Amazon elastic search also it's highly easy to use because it makes",
    "start": "390379",
    "end": "395539"
  },
  {
    "text": "it very simple for you by taking away all the overhead of management it's got",
    "start": "395539",
    "end": "400580"
  },
  {
    "text": "a lot of you know options for you to select different instances very easily scalable highly available and secure and of",
    "start": "400580",
    "end": "407720"
  },
  {
    "text": "course it's also well integrated with AWS so if your data is in aw yes it's",
    "start": "407720",
    "end": "412729"
  },
  {
    "text": "much easy for you to bring it in to Amazon Elastic search service and actually process it either for in analytics or for search let me give you",
    "start": "412729",
    "end": "420470"
  },
  {
    "text": "an example let me just walk you through with an example so let's say you want to build a catalog for books so what do you",
    "start": "420470",
    "end": "426590"
  },
  {
    "text": "do you go to the Amazon Elastic search service you just either use the console or the api's you know just with a few",
    "start": "426590",
    "end": "431960"
  },
  {
    "text": "clicks you can set up your cluster you can think the kind of instances that you want and that's it Amazon Elastic search",
    "start": "431960",
    "end": "437150"
  },
  {
    "text": "service does the rest now you can ingest data to it set up your indices and get going now the part here is that this is",
    "start": "437150",
    "end": "444530"
  },
  {
    "text": "not a typical you know your direct match of strings it's a best possible match it gives you a sense of relevance and I'll",
    "start": "444530",
    "end": "450860"
  },
  {
    "text": "tell you how we can configure that the multiple aspect that you can extend here so for example if you need to search for",
    "start": "450860",
    "end": "457400"
  },
  {
    "text": "elasticsearch guide it would return to you the perfect match lastic search guide completely matching you could also",
    "start": "457400",
    "end": "463849"
  },
  {
    "text": "return to you lastic search getting started guide or becoming an elastic search expert these are also you know",
    "start": "463849",
    "end": "469550"
  },
  {
    "text": "results that could match though they don't match exactly to your string so that's that's kind of an example of how",
    "start": "469550",
    "end": "475880"
  },
  {
    "text": "actually search can be smarter and much more applicable to your modern day you know repellents now I'm sure you might",
    "start": "475880",
    "end": "483080"
  },
  {
    "text": "all be wondering okay so how do we go about actually building the search architecture so let's dive right in so",
    "start": "483080",
    "end": "491360"
  },
  {
    "text": "this is the simplest form of a search architecture essentially what you do is you in just documents to the search",
    "start": "491360",
    "end": "498590"
  },
  {
    "text": "engine and then you make queries to the search engine to get results inside the search engine is where the magic happens",
    "start": "498590",
    "end": "505810"
  },
  {
    "text": "first of all the search engine takes the documents that you offer processes then",
    "start": "505810",
    "end": "511250"
  },
  {
    "text": "something takes it through a process called analysis and then extracts the key terms that it needs to actually",
    "start": "511250",
    "end": "517130"
  },
  {
    "text": "index for you subsequently when you do a query it figures out what are the key terms in your query that it needs to",
    "start": "517130",
    "end": "523310"
  },
  {
    "text": "actually search against goes into the index and pulls out the necessary documents sorts them based on relevance",
    "start": "523310",
    "end": "529250"
  },
  {
    "text": "and returns it to you now I know it's all easier said than done so let's dive",
    "start": "529250",
    "end": "535130"
  },
  {
    "text": "into each of these bit by bit the three phases here indexing text analysis and",
    "start": "535130",
    "end": "540500"
  },
  {
    "text": "query let's look at each of them one step deeper to help with that let me use",
    "start": "540500",
    "end": "548779"
  },
  {
    "text": "a data set to help illustrate the concept so data set here that I'm using is the IMDB database",
    "start": "548779",
    "end": "556040"
  },
  {
    "text": "you know consists of around 5,000 movies and each each document here captures the",
    "start": "556040",
    "end": "562160"
  },
  {
    "text": "various fields within a movie so for example here for the Ironman movie there's full text fields like title and",
    "start": "562160",
    "end": "568459"
  },
  {
    "text": "plot they're also non text fields like ratings and release-date and so on so",
    "start": "568459",
    "end": "575150"
  },
  {
    "text": "let's dive into the first stage of indexing indexing is common even in",
    "start": "575150",
    "end": "580699"
  },
  {
    "text": "databases you know we all have you know encounter the term indexing simply put",
    "start": "580699",
    "end": "586130"
  },
  {
    "text": "indexing is just a process of organizing a data for faster retrieval databases",
    "start": "586130",
    "end": "591470"
  },
  {
    "text": "use you know data structures like b-trees elastic search uses what we call inverted indices I'll tell you about it",
    "start": "591470",
    "end": "598600"
  },
  {
    "text": "so you have your documents sent to elastic search they're pretty much an",
    "start": "598600",
    "end": "604610"
  },
  {
    "text": "JSON document essentially they are like name value pairs I'll show you an example shortly and then what it does is",
    "start": "604610",
    "end": "611690"
  },
  {
    "text": "it subjects it through a process called analysis from the analysis it's going to look at each of your text fields and",
    "start": "611690",
    "end": "618500"
  },
  {
    "text": "extract the various terms that it needs to index so for each of these terms it's",
    "start": "618500",
    "end": "623720"
  },
  {
    "text": "going to build a list of documents that match those terms so in a typical database world you have documents and",
    "start": "623720",
    "end": "630410"
  },
  {
    "text": "then the terms that are there within it are the columns and fields sure it's inverted in the sense that it tracks the",
    "start": "630410",
    "end": "635510"
  },
  {
    "text": "terms and then mats it matches it to the documents because when you query it can easily get to the documents fast so for",
    "start": "635510",
    "end": "643040"
  },
  {
    "text": "example in the case of the Iron Man movie and you know I'm just in the",
    "start": "643040",
    "end": "648980"
  },
  {
    "text": "interesting one document which is a JSON document of the Iron Man movie I've got an index called movies I created a",
    "start": "648980",
    "end": "655250"
  },
  {
    "text": "document ID one two three four five and I'm writing this in it's got multiple fields title plot and so on some text",
    "start": "655250",
    "end": "662630"
  },
  {
    "text": "fields you know rank release date and so on non text fields and what elasticsearch does is it takes",
    "start": "662630",
    "end": "669160"
  },
  {
    "text": "in processes this analyzes this and indexes it all underneath it without me",
    "start": "669160",
    "end": "674199"
  },
  {
    "text": "having to know actually what what all is happening now the key part here is the",
    "start": "674199",
    "end": "679209"
  },
  {
    "text": "analysis part and let me just elaborate on that because that's very critical to control how research behaves so analysis",
    "start": "679209",
    "end": "687069"
  },
  {
    "text": "is the process of taking your text and extracting the key terms out of it to build your index",
    "start": "687069",
    "end": "692769"
  },
  {
    "text": "so essentially you provide you input text to the analysis phase it consists of different analyzers you could change",
    "start": "692769",
    "end": "698559"
  },
  {
    "text": "those different analyzes together it could be built-in analyzers or custom analyzers and then you get the output",
    "start": "698559",
    "end": "704170"
  },
  {
    "text": "terms that actually form your index let me let's treat this you know with",
    "start": "704170",
    "end": "710350"
  },
  {
    "text": "specific examples and I'll take the example of the Iron Man movie that we just saw so essentially what I'm doing",
    "start": "710350",
    "end": "716230"
  },
  {
    "text": "is we'll analyze you know the plot field here which is like a full text tossed",
    "start": "716230",
    "end": "721269"
  },
  {
    "text": "off string here and we'll see how analysis can actually work on it so",
    "start": "721269",
    "end": "726879"
  },
  {
    "text": "analysis generally has two phases the first phase is called tokenization and the second phase is called normalization",
    "start": "726879",
    "end": "732790"
  },
  {
    "text": "so first of all in the first phase you take the string and convert it into tokens and in this case I've actually",
    "start": "732790",
    "end": "739209"
  },
  {
    "text": "taken the example of a whitespace tokenizer or there's an inbuilt tokenizer that elasticsearch offers and",
    "start": "739209",
    "end": "745329"
  },
  {
    "text": "what it does is it just takes a txt converts it into the various tokens or in this case will be the various words",
    "start": "745329",
    "end": "751089"
  },
  {
    "text": "in the string do note that it also tracks the offset of the word and you",
    "start": "751089",
    "end": "756129"
  },
  {
    "text": "know the position of it in the dark etc so it can actually retrieve it fast in",
    "start": "756129",
    "end": "761290"
  },
  {
    "text": "case you're searching against it now well okay it's distributing the tokens",
    "start": "761290",
    "end": "766660"
  },
  {
    "text": "but when you search you typically want it to be case insensitive so let's",
    "start": "766660",
    "end": "772029"
  },
  {
    "text": "normalize it so let's add a filter called lowercase so does again a built",
    "start": "772029",
    "end": "777759"
  },
  {
    "text": "in one you know you just specify lowercase and while I translate it transverse and translates your string",
    "start": "777759",
    "end": "783610"
  },
  {
    "text": "into a lowercase string and so all tokens are converting to lower case but",
    "start": "783610",
    "end": "789490"
  },
  {
    "text": "now if you look at the plot string that you have there the many words in it that don't necessarily add much you know to",
    "start": "789490",
    "end": "795819"
  },
  {
    "text": "relevance for search for example you have got a and easter and a few such",
    "start": "795819",
    "end": "800890"
  },
  {
    "text": "woods so what we do is we subject it to a stop word filter and here I have taken",
    "start": "800890",
    "end": "806710"
  },
  {
    "text": "example where I am specifying the stop words that I want removed from my text",
    "start": "806710",
    "end": "812130"
  },
  {
    "text": "so here I'm customizing it a bit the multiple ways you can do it you can you specify a file which contains two stop",
    "start": "812130",
    "end": "818350"
  },
  {
    "text": "words you could even use certain you know stop word analyzers which actually do it all for you but here I'm just",
    "start": "818350",
    "end": "824440"
  },
  {
    "text": "showing an example where you customize it so essentially what elasticsearch does is it's going to strip off all these",
    "start": "824440",
    "end": "829570"
  },
  {
    "text": "stop words but now that's not it so for example if we take the word welding here if I were to search by where the term",
    "start": "829570",
    "end": "836440"
  },
  {
    "text": "veldt you still want it to match to the string welding if I may be searched by",
    "start": "836440",
    "end": "841690"
  },
  {
    "text": "welder you still want it to match to it so in other words you would like to actually normalize it into some native",
    "start": "841690",
    "end": "847600"
  },
  {
    "text": "form so that's the process called stemming and I could add a stemming filter as well so look at it the way",
    "start": "847600",
    "end": "854290"
  },
  {
    "text": "I've chained all this you have a lot of flexibility here in terms of how we chained it I've added an algorithmic",
    "start": "854290",
    "end": "859750"
  },
  {
    "text": "stemmer here called Lovins and what it does is it translates most of the words into its root form if it's not already",
    "start": "859750",
    "end": "866800"
  },
  {
    "text": "in that form so well D for example became whelp so later on if I search by wealthy or wealthiest it's still gonna",
    "start": "866800",
    "end": "873070"
  },
  {
    "text": "be able to actually map it to this kind of a string because it always converts it into its root form so with that you",
    "start": "873070",
    "end": "880210"
  },
  {
    "text": "know that's at a high level different forms of analysis now let's say we have analyzed it it's bit separated into",
    "start": "880210",
    "end": "886780"
  },
  {
    "text": "terms it's interesting it's in its normalized form now let's go into querying so when you actually start",
    "start": "886780",
    "end": "894730"
  },
  {
    "text": "querying you're actually specifying terms or you know that you want to match against so what lastik search does is it",
    "start": "894730",
    "end": "902320"
  },
  {
    "text": "first analyzes your query so for example you search by the term well B it",
    "start": "902320",
    "end": "908230"
  },
  {
    "text": "transfers that also into its normalized form wealth and then it looks for all documents that match those terms so you",
    "start": "908230",
    "end": "915880"
  },
  {
    "text": "have multiple terms in your query it's going to look for all documents that match both terms subsequently it's gone",
    "start": "915880",
    "end": "921250"
  },
  {
    "text": "of rank these based on a scoring algorithm and we'll talk about that shortly and then subsequently return",
    "start": "921250",
    "end": "927400"
  },
  {
    "text": "back to you the you know sorted result let's look at it with some examples",
    "start": "927400",
    "end": "934450"
  },
  {
    "text": "let's say you want to search for Ironman well simple you just say query title",
    "start": "934450",
    "end": "940640"
  },
  {
    "text": "Ironman and I got you know I tried this on the IMDB dataset and I got 77 hits",
    "start": "940640",
    "end": "945940"
  },
  {
    "text": "you can look at the whole column which is kind of the scoring that elasticsearch does the first three",
    "start": "945940",
    "end": "951950"
  },
  {
    "text": "results are scold higher because they're kind of the exact match you know the three Iron Man movies I also have you",
    "start": "951950",
    "end": "957890"
  },
  {
    "text": "know the results like the Iron Lady because it matched at least one of the terms now you might say hey you know I",
    "start": "957890",
    "end": "963589"
  },
  {
    "text": "don't want this I actually wanted to have an exact match simple you just say",
    "start": "963589",
    "end": "968660"
  },
  {
    "text": "match the whole phrase Ironman and only returns to you three hits the you know the three Iron Man movies now let's say",
    "start": "968660",
    "end": "975709"
  },
  {
    "text": "you know you want to actually have some of complex queries let's make it a bit more complicated let's say you want to",
    "start": "975709",
    "end": "980930"
  },
  {
    "text": "match all Iron Man movies and you want to return only those that are rated more",
    "start": "980930",
    "end": "986209"
  },
  {
    "text": "than seven so here's what you do say match title Iron Man and you say rating",
    "start": "986209",
    "end": "992120"
  },
  {
    "text": "greater than or equal to seven and it returns to you 33 hits instead of the 77 heads that we just saw now here all of",
    "start": "992120",
    "end": "999140"
  },
  {
    "text": "them are rated higher than seven or more now let's say you want to add some faceting to this let's say you want to",
    "start": "999140",
    "end": "1005920"
  },
  {
    "text": "actually split this into buckets based on rating if you say okay I want up one",
    "start": "1005920",
    "end": "1011440"
  },
  {
    "text": "bucket to be rated between seven and eight and another bucket to be grated greater than eight so here's how it look",
    "start": "1011440",
    "end": "1017380"
  },
  {
    "text": "you know you specify your facets then you are saying okay return to me those you know that match these different",
    "start": "1017380",
    "end": "1023560"
  },
  {
    "text": "buckets and organize them and it returns back and say it's the 27 movies between 7 and 8 or in gratings and there are six",
    "start": "1023560",
    "end": "1030730"
  },
  {
    "text": "movies higher than eight in fact I found is pretty interesting what I did was you",
    "start": "1030730",
    "end": "1035890"
  },
  {
    "text": "know essentially the 33 movies out of 77 or that are rated more than seven that",
    "start": "1035890",
    "end": "1042339"
  },
  {
    "text": "match Ironman cells curious actually searched for different other terms I searched for love I searched for action",
    "start": "1042339",
    "end": "1047949"
  },
  {
    "text": "and so on and I found that not many of those come even closer their success",
    "start": "1047949",
    "end": "1053049"
  },
  {
    "text": "rate you know criteria with these ratings was much lower like even with Lao it was like 20% of the results had",
    "start": "1053049",
    "end": "1058210"
  },
  {
    "text": "higher than seven ratings so Ironman seems to be a good formula you know to have a successful movie at least so in",
    "start": "1058210",
    "end": "1064510"
  },
  {
    "text": "case you know you're looking to build any movies something to think about but in me I",
    "start": "1064510",
    "end": "1069999"
  },
  {
    "text": "guess you get the point the different ways by which you can slice and dice this there's a lot of capabilities that",
    "start": "1069999",
    "end": "1075519"
  },
  {
    "text": "elastic search offers there's one other key point that I actually want to cover here that's about scoring and ranking so",
    "start": "1075519",
    "end": "1084159"
  },
  {
    "text": "elastic search by default does its own you know scoring of your results you already saw that in the table that I",
    "start": "1084159",
    "end": "1089950"
  },
  {
    "text": "showed you that it scored your results the default of Gotham actually has you know three key aspects that it actually",
    "start": "1089950",
    "end": "1095320"
  },
  {
    "text": "evaluates you based on the first one is of course the term frequency have frequently a term occurs the second one",
    "start": "1095320",
    "end": "1100869"
  },
  {
    "text": "is what we call inverse document frequency basically if a term of course too many times hidden within a document",
    "start": "1100869",
    "end": "1106629"
  },
  {
    "text": "elastic search fields here yeah maybe it's not as relevant that document may not be as relevant to the search and so",
    "start": "1106629",
    "end": "1111669"
  },
  {
    "text": "it dings it's likely in the score the next one is field length so for example if a term matches a field with smaller",
    "start": "1111669",
    "end": "1118749"
  },
  {
    "text": "length most likely it's more relevant for example if a term matches the",
    "start": "1118749",
    "end": "1123759"
  },
  {
    "text": "subject of an email it might be a better match then it matching just the body of",
    "start": "1123759",
    "end": "1128799"
  },
  {
    "text": "the email right because subjects are generally smaller in length so it has some you know mechanisms to actually build some",
    "start": "1128799",
    "end": "1135309"
  },
  {
    "text": "kind of scoring around it but you have the flexibility to changes around you have the flexibility to actually tweak",
    "start": "1135309",
    "end": "1141309"
  },
  {
    "text": "it or you know to define either based on the values within a field you can even have a scripting function to actually",
    "start": "1141309",
    "end": "1147249"
  },
  {
    "text": "change it and define how this coding needs to be calculated let me illustrate it with a small example",
    "start": "1147249",
    "end": "1153009"
  },
  {
    "text": "so I search for the term James Bond you know and I ask you to match against",
    "start": "1153009",
    "end": "1158200"
  },
  {
    "text": "title and plot and it returned to me results and the first result was Casino Royale with a really good score and that",
    "start": "1158200",
    "end": "1166299"
  },
  {
    "text": "was a very first result well make sense it's a James Bond movie but I you know I",
    "start": "1166299",
    "end": "1171639"
  },
  {
    "text": "said well I actually want to give title a lot more waited in the scoring mechanism so actually increase the",
    "start": "1171639",
    "end": "1178690"
  },
  {
    "text": "weight edge of title and tried the query again and this time these the search the",
    "start": "1178690",
    "end": "1184659"
  },
  {
    "text": "result are is on top was the movie born twenty four and the score went up it was like thirty two point six three because",
    "start": "1184659",
    "end": "1190450"
  },
  {
    "text": "I bumped up the title score by you know a factor of five so overall you know",
    "start": "1190450",
    "end": "1196090"
  },
  {
    "text": "what it illustrates is you have a lot of mechanisms to actually",
    "start": "1196090",
    "end": "1201400"
  },
  {
    "text": "in your search scoring system based on your requirements to actually get the desired behavior that will add lend to a",
    "start": "1201400",
    "end": "1208720"
  },
  {
    "text": "good customer experience there's a lot more you know you've just from the scoring aspect the many different",
    "start": "1208720",
    "end": "1214690"
  },
  {
    "text": "scoring models as well but in the interest of time I'm not getting into all those but overall you know the key",
    "start": "1214690",
    "end": "1220930"
  },
  {
    "text": "point here is the many many aspects here that you can actually find tune as you",
    "start": "1220930",
    "end": "1226360"
  },
  {
    "text": "build a search architecture to actually provide you the right kind of experience for the customer so all in all you know",
    "start": "1226360",
    "end": "1232660"
  },
  {
    "text": "to quickly summarize this plastic search is a great technology for full-text search offers you a number of",
    "start": "1232660",
    "end": "1238930"
  },
  {
    "text": "capabilities you know we saw a faceting it's a distributed system so it's fairly fast and performant can handle loads of",
    "start": "1238930",
    "end": "1246370"
  },
  {
    "text": "data and with Amazon elastic search you actually make it a lot more simpler because you don't have to deal with the",
    "start": "1246370",
    "end": "1253000"
  },
  {
    "text": "whole management hassles of the clusters etc because it takes care of that for you and of course if you have your data",
    "start": "1253000",
    "end": "1258910"
  },
  {
    "text": "with an AWS let's say s3 or so on it makes it much easier for you to integrate with it and get the data in",
    "start": "1258910",
    "end": "1265060"
  },
  {
    "text": "and search on top of it so let me stop there and you know hand over the stage",
    "start": "1265060",
    "end": "1271060"
  },
  {
    "text": "to Phil who's actually gonna walk you through the mirror web story he's gonna tell you about how they went about",
    "start": "1271060",
    "end": "1277210"
  },
  {
    "text": "building the search architecture and you know for what are the lessons and insights are they gained over to you",
    "start": "1277210",
    "end": "1283120"
  },
  {
    "text": "Phil right so you've probably never",
    "start": "1283120",
    "end": "1291790"
  },
  {
    "text": "heard of more web so I'll tell you a little bit about what we do we provide web and social media archiving and to",
    "start": "1291790",
    "end": "1297910"
  },
  {
    "text": "public sectors and to regulated industries so the financial sector and",
    "start": "1297910",
    "end": "1303160"
  },
  {
    "text": "FINRA regulated industries and in the UK we've got similar regulations what were",
    "start": "1303160",
    "end": "1310660"
  },
  {
    "text": "going to talk about today is the public archive that we've the web archive that we've done for the UK and National",
    "start": "1310660",
    "end": "1316120"
  },
  {
    "text": "Archives and this is a publicly viewable archive available online we also run the",
    "start": "1316120",
    "end": "1322420"
  },
  {
    "text": "UK Parliament web archive which is using similar technologies but what we're going to talk about is is the actual job",
    "start": "1322420",
    "end": "1328630"
  },
  {
    "text": "we did to ingest all of the data way back home so a quick rundown of what",
    "start": "1328630",
    "end": "1334479"
  },
  {
    "text": "web archives are I don't know if many of you familiar with the Internet Archive and the Wayback Machine well that's",
    "start": "1334479",
    "end": "1339580"
  },
  {
    "text": "essentially what this is website data is stored in an ISO standard walk format",
    "start": "1339580",
    "end": "1345429"
  },
  {
    "text": "file and it needs to be indexed to be to",
    "start": "1345429",
    "end": "1350499"
  },
  {
    "text": "be covered to play boat and I'm not going to go into details about what CDX",
    "start": "1350499",
    "end": "1355779"
  },
  {
    "text": "Injection is but the reason I need to talk about it is to explain how we did the indexing later and so what a CD X",
    "start": "1355779",
    "end": "1362409"
  },
  {
    "text": "index is is a list of all of the detail all of the assets within the web archive which would be HTML data PDFs and",
    "start": "1362409",
    "end": "1371320"
  },
  {
    "text": "anything that was on that particular website so we create an index and that creates a full text index our of every",
    "start": "1371320",
    "end": "1383499"
  },
  {
    "text": "year asset in the file so what is the UK government web archive well there's 20 years of historic archives it's a",
    "start": "1383499",
    "end": "1390700"
  },
  {
    "text": "hundred and 20 terabytes of data and we've got over 4,800 sites archived a",
    "start": "1390700",
    "end": "1396340"
  },
  {
    "text": "lot of these sites have been shut down and no longer on the public web but they are in our archive and we also archive",
    "start": "1396340",
    "end": "1403840"
  },
  {
    "text": "UK government Twitter accounts and YouTube videos so the UK web archive",
    "start": "1403840",
    "end": "1410019"
  },
  {
    "text": "project we won the tender last November to take this to move this archive from its previous supplier which was stored",
    "start": "1410019",
    "end": "1417460"
  },
  {
    "text": "in it in data centers in Paris and we needed to collect the the data and move",
    "start": "1417460",
    "end": "1424509"
  },
  {
    "text": "it into Amazon and we were lucky that the data had already moved to the",
    "start": "1424509",
    "end": "1429820"
  },
  {
    "text": "National Archives but it was stored on 72 2 terabyte hard drives and I had to go there with two snowballs and two",
    "start": "1429820",
    "end": "1439239"
  },
  {
    "text": "machines that I built that we were able to connect 8 drives at once and ingest the data as fast as we possibly could",
    "start": "1439239",
    "end": "1444700"
  },
  {
    "text": "onto the two snowballs but it still took two weeks the next phase of the project we had to develop a public facing",
    "start": "1444700",
    "end": "1450970"
  },
  {
    "text": "website that was capable of serving over 75 million visitors a month we had to",
    "start": "1450970",
    "end": "1459639"
  },
  {
    "text": "provide full replay of all the archives like the wayback machine and then we had to do full-text search",
    "start": "1459639",
    "end": "1465350"
  },
  {
    "text": "across the entire archive the first three bits we were quite familiar with with all of our public or all of our",
    "start": "1465350",
    "end": "1471530"
  },
  {
    "text": "financial clients but we didn't provide at that time full-text search and so we",
    "start": "1471530",
    "end": "1476840"
  },
  {
    "text": "had a bit of learning to do so indexing a hundred and twenty terabytes of web",
    "start": "1476840",
    "end": "1482990"
  },
  {
    "text": "archives we had the web archives of all stored in one hundred megabyte files so",
    "start": "1482990",
    "end": "1489850"
  },
  {
    "text": "then they were all stored in s3 we had to filter down the content so",
    "start": "1489850",
    "end": "1495679"
  },
  {
    "text": "that the search only provided results for government domains web crawlers",
    "start": "1495679",
    "end": "1500960"
  },
  {
    "text": "traditionally kind of can spread off onto the internet and an archive and pull down lots of stuff we didn't want those but",
    "start": "1500960",
    "end": "1507400"
  },
  {
    "text": "returning in the search results only certain mime types were in scope so we",
    "start": "1507400",
    "end": "1512900"
  },
  {
    "text": "only indexed text content documents we didn't index any video we didn't index any images at this stage the data set",
    "start": "1512900",
    "end": "1521299"
  },
  {
    "text": "also contained many many duplicate pages and we had a requirement that we were not to provide any duplicate results so",
    "start": "1521299",
    "end": "1530090"
  },
  {
    "text": "choosing the search technology there was two choices that we looked at that were popular at the time solar and elastic",
    "start": "1530090",
    "end": "1536600"
  },
  {
    "text": "search elastic search was that was the winner as we've seen from the slides previously it's very popular at the",
    "start": "1536600",
    "end": "1543049"
  },
  {
    "text": "moment but also Amazon offered as a elastic search service and we were a small team and we didn't have a lot of",
    "start": "1543049",
    "end": "1549919"
  },
  {
    "text": "search experience so it made sense to have a look running it on Amazon the we",
    "start": "1549919",
    "end": "1559460"
  },
  {
    "text": "chose the elastic search service for a number of reasons being out to scale was incredibly important as you'll see later",
    "start": "1559460",
    "end": "1564500"
  },
  {
    "text": "we we we spun up a very large cluster to do the initial interest and then scaled it back down it's an affordable level",
    "start": "1564500",
    "end": "1570679"
  },
  {
    "text": "when we went live by using their services where we meant I didn't have to",
    "start": "1570679",
    "end": "1576080"
  },
  {
    "text": "employ lots of elastic search experts to an elastic search cluster which did help",
    "start": "1576080",
    "end": "1582490"
  },
  {
    "text": "manage any access rights access rights to elastic search could be managed right I am and that that's integrated into the",
    "start": "1582490",
    "end": "1590870"
  },
  {
    "text": "Amazon environment mostly we also we monitor it with cloud watch and provide alerting along with all of our other",
    "start": "1590870",
    "end": "1597460"
  },
  {
    "text": "and finally failed nodes replaced automatically I don't have to worry as much about it as I would if we were",
    "start": "1597460",
    "end": "1603920"
  },
  {
    "text": "running it ourselves so traditional tools for indexing we've got Hadoop and spark now there are",
    "start": "1603920",
    "end": "1610340"
  },
  {
    "text": "a number of open source projects on the internet for indexing web archives but none of them actually pushed into",
    "start": "1610340",
    "end": "1615500"
  },
  {
    "text": "elasticsearch so we were forced to look at writing her own and the benchmark was",
    "start": "1615500",
    "end": "1621950"
  },
  {
    "text": "set by the British Library they run the UK web archive and the UK web archive is UK domains but not the",
    "start": "1621950",
    "end": "1629150"
  },
  {
    "text": "government ones so they set a record just around the time we were writing my software of indexed in ingesting 10",
    "start": "1629150",
    "end": "1637490"
  },
  {
    "text": "million records per hour so we set that as our benchmark now what I wanted to do",
    "start": "1637490",
    "end": "1642950"
  },
  {
    "text": "with the ingest job was to take the data stored in s3 process it with EMR through",
    "start": "1642950",
    "end": "1649250"
  },
  {
    "text": "a filter stage then do an extract stage where we then extract you the full-text",
    "start": "1649250",
    "end": "1654770"
  },
  {
    "text": "search from the documents that were in scope and then we push that into the elastic search we didn't have experience",
    "start": "1654770",
    "end": "1662840"
  },
  {
    "text": "with Hadoop so we have hired a hadoop contractor and they quoted us for one to two weeks of work to move this data into",
    "start": "1662840",
    "end": "1669050"
  },
  {
    "text": "elastic search however two weeks later they told is going to take six to eight",
    "start": "1669050",
    "end": "1674480"
  },
  {
    "text": "weeks why is this and it turned out they wanted we didn't realize that well heard",
    "start": "1674480",
    "end": "1680810"
  },
  {
    "text": "it was great for batch data processing on small amounts of small amounts of",
    "start": "1680810",
    "end": "1686570"
  },
  {
    "text": "large files this is a small file problem we had 1.2 million 100 megabyte files",
    "start": "1686570",
    "end": "1692150"
  },
  {
    "text": "and not only that they were gzip chunks for files so we had to move the whole",
    "start": "1692150",
    "end": "1698060"
  },
  {
    "text": "dataset from s3 into the HDFS to process it we couldn't read directly from s3 just",
    "start": "1698060",
    "end": "1703520"
  },
  {
    "text": "through the nature of each file had to be uncompressed and with a walk we only want certain parts of it to to be",
    "start": "1703520",
    "end": "1710300"
  },
  {
    "text": "extracted we don't need the whole file Oliver was filtered example so we decided to think outside the box and",
    "start": "1710300",
    "end": "1716500"
  },
  {
    "text": "some smart members of our dev team came up with what we call wild pipe which was in a way a rewrite of a dupe for the",
    "start": "1716500",
    "end": "1724310"
  },
  {
    "text": "cloud so what what is well pipe it what did it allow us to do it allowed us to",
    "start": "1724310",
    "end": "1729650"
  },
  {
    "text": "run in credibly quickly and do the ingest speeds that are unheard of",
    "start": "1729650",
    "end": "1735550"
  },
  {
    "text": "each worker in the in what pipe was was able to access the data directly from s3",
    "start": "1735550",
    "end": "1742160"
  },
  {
    "text": "for the filter stage and then was able to we didn't have to move the data so it",
    "start": "1742160",
    "end": "1747710"
  },
  {
    "text": "each worker had direct access to s3 and we were able to go and we were able to scale the cluster on the fliers work",
    "start": "1747710",
    "end": "1754190"
  },
  {
    "text": "as well so what do we actually do with wealth while pipe the data was stored in",
    "start": "1754190",
    "end": "1759559"
  },
  {
    "text": "s3 we used 350 Amazon ec2 instances to do the filtering stage and we were able",
    "start": "1759559",
    "end": "1765860"
  },
  {
    "text": "to filter their files without reading the actual what the works we did it with the CD x-files the CD x-files contained",
    "start": "1765860",
    "end": "1772309"
  },
  {
    "text": "a list of everything every asset in the file he just didn't contain the actual full text data so we knew the mime type we",
    "start": "1772309",
    "end": "1778429"
  },
  {
    "text": "need a location so we filtered down on the CD X Files then the next stage we had 650 Amazon",
    "start": "1778429",
    "end": "1785020"
  },
  {
    "text": "ec2 spot instances that were doing the",
    "start": "1785020",
    "end": "1790040"
  },
  {
    "text": "extract and they could then take a G a chunk of the actual work data directly",
    "start": "1790040",
    "end": "1795380"
  },
  {
    "text": "from s3 without was having to move the whole file and then we pushed into an with elastic search running that many",
    "start": "1795380",
    "end": "1803059"
  },
  {
    "text": "boxes though did present some difficulties and we managed to kill the elastic search many times until we got",
    "start": "1803059",
    "end": "1808640"
  },
  {
    "text": "the scale right so how do we optimize it I ran a 9 node es cluster with our for",
    "start": "1808640",
    "end": "1816380"
  },
  {
    "text": "4x large instances giving us one hundred and forty four cores across the cluster I set the sharding to be one shard per",
    "start": "1816380",
    "end": "1824990"
  },
  {
    "text": "CPU to be honest it was a bit of a guess and it worked but the first few times we took it out when we have smaller and we",
    "start": "1824990",
    "end": "1832250"
  },
  {
    "text": "had less shards I had no replica shards for the in just for the injustice because that slows",
    "start": "1832250",
    "end": "1838970"
  },
  {
    "text": "things down and then we use the bulk ingest API of I elastic search to chunk",
    "start": "1838970",
    "end": "1845230"
  },
  {
    "text": "the data in I think we we we chunked it in at 2 Meg chunks so once the worker",
    "start": "1845230",
    "end": "1852230"
  },
  {
    "text": "extract workers have up to 10 Meg's we push that interval a stick search",
    "start": "1852230",
    "end": "1857200"
  },
  {
    "text": "so what was the result it was fast very very fast we managed to index 1.4",
    "start": "1857830",
    "end": "1866289"
  },
  {
    "text": "billion documents in ten hours and that was averaging the 146 million documents an hour it actually went quicker at",
    "start": "1866289",
    "end": "1873220"
  },
  {
    "text": "times is that that was the average removing the time we did it and that",
    "start": "1873220",
    "end": "1878980"
  },
  {
    "text": "meant that we didn't have to spend too much on the ec2 instances and the elasticsearch cluster that was quite",
    "start": "1878980",
    "end": "1883990"
  },
  {
    "text": "large wasn't too expensive because we only ran it before that the ten hours we",
    "start": "1883990",
    "end": "1890679"
  },
  {
    "text": "also had this requirement to deduplicate and we achieved you duplication by",
    "start": "1890679",
    "end": "1897120"
  },
  {
    "text": "creating the elasticsearch ID as an md5 char of this string here which every",
    "start": "1897120",
    "end": "1905080"
  },
  {
    "text": "single asset in a walk file has an md5 digest generated but it doesn't conclude",
    "start": "1905080",
    "end": "1910779"
  },
  {
    "text": "the URL so you might have a document that's in many different locations on different URLs they all still have the same digest so we recreate a unique",
    "start": "1910779",
    "end": "1917980"
  },
  {
    "text": "digest and set that as the elasticsearch ID and what we did is we actually did",
    "start": "1917980",
    "end": "1925480"
  },
  {
    "text": "push 1.4 billion documents into elasticsearch but we overrode them it",
    "start": "1925480",
    "end": "1931120"
  },
  {
    "text": "was a very quick and crude way that actually worked very efficiently so we index 1.4 billion documents and then",
    "start": "1931120",
    "end": "1937360"
  },
  {
    "text": "with this do duplication winded up with 333 million unique documents in elastic search it worked quite well so this had",
    "start": "1937360",
    "end": "1945549"
  },
  {
    "text": "an effect of reducing the index size from an expected about 8 terabytes we are inherited the previous and",
    "start": "1945549",
    "end": "1952539"
  },
  {
    "text": "suppliers index and that was 8 terabytes Oviatt that was in leasing and we got it",
    "start": "1952539",
    "end": "1958419"
  },
  {
    "text": "down to 2.9 terabytes and that's quite important because running such as large",
    "start": "1958419",
    "end": "1963580"
  },
  {
    "text": "elasticsearch cluster the cost Divo up as you'd that and you have to what was I",
    "start": "1963580",
    "end": "1970750"
  },
  {
    "text": "think the maximum drive size that we could get was 1 point 5 terabytes so our current cluster is running 1.5 terabytes",
    "start": "1970750",
    "end": "1977649"
  },
  {
    "text": "per per node so running at 144 shards",
    "start": "1977649",
    "end": "1983139"
  },
  {
    "text": "wasn't something I wanted to do in production and so we had to use the at the ES shrink index API to reduce the",
    "start": "1983139",
    "end": "1990190"
  },
  {
    "text": "shards down from 144 down to 12 and that creates a copy of the index with the smaller sides",
    "start": "1990190",
    "end": "1996390"
  },
  {
    "text": "and then you remove and then we downgraded the cluster this was the one",
    "start": "1996390",
    "end": "2001910"
  },
  {
    "text": "of the features of Elmer's elasticsearch we were able to shrink the cluster down and it managed it all down to 6r 4x",
    "start": "2001910",
    "end": "2008600"
  },
  {
    "text": "large instances and then we have 3 m3 large instant master nodes and then",
    "start": "2008600",
    "end": "2015710"
  },
  {
    "text": "finally we added their replicas index to improve speed and redundancy what was the cost well 10 hours of our 4x large a",
    "start": "2015710",
    "end": "2025720"
  },
  {
    "text": "thousand of them would have cost around 2009 or $60 as it was we didn't use a",
    "start": "2025720",
    "end": "2031550"
  },
  {
    "text": "thousand for the entire time because once the filter stage had completed we were able to shut those down where I",
    "start": "2031550",
    "end": "2037730"
  },
  {
    "text": "ended up with a spot purchase price of one hundred and eighty-seven dollars phenomenal reduction and then the large",
    "start": "2037730",
    "end": "2044840"
  },
  {
    "text": "elasticsearch cluster that we ran looking back for our bill we used it for 136 hours and cost us two hundred and",
    "start": "2044840",
    "end": "2051290"
  },
  {
    "text": "thirty seven dollars which all-in-all was pretty cheap so what did we learn",
    "start": "2051290",
    "end": "2058750"
  },
  {
    "text": "well I learned you can take down the elastics so it's very easily with a thousand service hitting it and I think",
    "start": "2058750",
    "end": "2064190"
  },
  {
    "text": "we'd three attempts before we got it right and obviously tuning the index for",
    "start": "2064190",
    "end": "2069620"
  },
  {
    "text": "ingest is indexing is really important and one interesting thing you might not",
    "start": "2069620",
    "end": "2075110"
  },
  {
    "text": "have realized there is a 40 terabyte limit on EBS volumes and we were running",
    "start": "2075110",
    "end": "2080600"
  },
  {
    "text": "quite large volumes on all of these notes and we couldn't work out why we were booting not always spot purchases",
    "start": "2080600",
    "end": "2086060"
  },
  {
    "text": "they were arriving on they were showing this booting up and then immediately closing down again and it turned out",
    "start": "2086060",
    "end": "2092419"
  },
  {
    "text": "that we'd hit this limit so that's have you ever doing anything at that scale make sure you get your Amazon limits increased and then you",
    "start": "2092420",
    "end": "2100610"
  },
  {
    "text": "have spot purchase you can save those our money so completely statistics what did we end up with we ended up with 93",
    "start": "2100610",
    "end": "2109160"
  },
  {
    "text": "percent faster than the UK while the UK web archives a Hadoop cluster obviously we've got a 70 percent",
    "start": "2109160",
    "end": "2115730"
  },
  {
    "text": "reduction in cost with use of spot purchases and 60 percent reduction in",
    "start": "2115730",
    "end": "2120830"
  },
  {
    "text": "the index size duty to duplicating and that saved us a lot of money duplication because if we had to run an",
    "start": "2120830",
    "end": "2126420"
  },
  {
    "text": "a terabyte cluster with one GG they would have be very expensive so I think",
    "start": "2126420",
    "end": "2132540"
  },
  {
    "text": "I've gone a bit faster I do apologize it's my first real benefit but I'm sure we can do some Q&A yeah sure",
    "start": "2132540",
    "end": "2140240"
  },
  {
    "text": "some old things fell I think last bit some clothes and carts so as you've seen",
    "start": "2140240",
    "end": "2150510"
  },
  {
    "text": "you know there's a lot of flexibility that elasticsearch offers and phil has already shared some cool insights in",
    "start": "2150510",
    "end": "2156210"
  },
  {
    "text": "terms of how he has optimized it especially with spot instances and how he's handled ingestion of smarter way",
    "start": "2156210",
    "end": "2162660"
  },
  {
    "text": "and also with elastic search how he gained a lot of new insights as he actually went about doing it especially",
    "start": "2162660",
    "end": "2168180"
  },
  {
    "text": "with shrinking the indexes and actually saving money on that hopefully this session was super you know enriching to",
    "start": "2168180",
    "end": "2174359"
  },
  {
    "text": "all of you and I think will be around here anyway for Q&A so stick around you",
    "start": "2174359",
    "end": "2179579"
  },
  {
    "text": "know if you can actually take all the questions offline more than happy to answer them for you thank you so much",
    "start": "2179579",
    "end": "2186020"
  },
  {
    "text": "thank you [Applause]",
    "start": "2186020",
    "end": "2193449"
  }
]
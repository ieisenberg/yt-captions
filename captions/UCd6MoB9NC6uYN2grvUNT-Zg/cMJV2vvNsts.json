[
  {
    "start": "0",
    "end": "123000"
  },
  {
    "text": "welcome everybody this is uh the short time during this conference that I could put in my my day job hat on for for an",
    "start": "30",
    "end": "8340"
  },
  {
    "text": "hour and talk about AWS most of this conference I put my community hat on and",
    "start": "8340",
    "end": "14070"
  },
  {
    "text": "try to help arrange this thing so you'll see me running around a lot and I'll",
    "start": "14070",
    "end": "19949"
  },
  {
    "text": "take off my my nice shirt put on a t-shirt as I move around boxes the rest of the week but I'm Gemmell Jen ski I'm",
    "start": "19949",
    "end": "28349"
  },
  {
    "text": "a database engineer part of the Aurora RDS post quest teams and we'll talk a",
    "start": "28349",
    "end": "35100"
  },
  {
    "text": "little bit about Aurora go deep a little deeper than what Kevin just did and then",
    "start": "35100",
    "end": "40730"
  },
  {
    "text": "end it off with some stuff some brief stuff about performance but we'll let Jim Finnerty after me go a lot deeper on",
    "start": "40730",
    "end": "48570"
  },
  {
    "text": "the performance aspect of it but we'll just try to build on it throughout the course of the day that's kind of what",
    "start": "48570",
    "end": "53879"
  },
  {
    "text": "we're trying to do today is educate everybody about Postgres in the AWS",
    "start": "53879",
    "end": "60120"
  },
  {
    "text": "world leading up to this afternoon of how people are using it so one of the",
    "start": "60120",
    "end": "67619"
  },
  {
    "text": "things that I know at least I do is from the vernacular standpoint I talk about",
    "start": "67619",
    "end": "72689"
  },
  {
    "text": "Aurora and RDS right it's really Aurora is part of RDS it's one of one of the",
    "start": "72689",
    "end": "80159"
  },
  {
    "text": "main engines of of RDS it's part of the same platform but just in order to",
    "start": "80159",
    "end": "86850"
  },
  {
    "text": "distinguish between RDS Postgres and rora Postgres i end up calling it RDS",
    "start": "86850",
    "end": "92100"
  },
  {
    "text": "and rora a lot of folks at AWS do the same thing and it's kind of just in the vernacular of everybody but Aurora is",
    "start": "92100",
    "end": "98970"
  },
  {
    "text": "part of RDS so all the same tools apply your your same console and everything works but it's just part of the same",
    "start": "98970",
    "end": "107040"
  },
  {
    "text": "family that's there but will will intermix the terms a bit and throughout",
    "start": "107040",
    "end": "112079"
  },
  {
    "text": "the course of today you'll hear say RDS and that means already has Postgres which is a lot closer to the community",
    "start": "112079",
    "end": "118070"
  },
  {
    "text": "versus Aurora Postgres which has the Aurora storage underneath it so one of",
    "start": "118070",
    "end": "124110"
  },
  {
    "start": "123000",
    "end": "123000"
  },
  {
    "text": "the questions that get asked at the end of Kevin's presentation is what's the difference what you know talked briefly",
    "start": "124110",
    "end": "131400"
  },
  {
    "text": "about some of them but when you're making the decision you have RDS Postgres sitting",
    "start": "131400",
    "end": "138120"
  },
  {
    "text": "on top of EB s volumes we're a Postgres sitting on top of or storage but from",
    "start": "138120",
    "end": "146460"
  },
  {
    "text": "your application they're going to look the same right you're going to connect with the same JDBC drivers ODBC drivers",
    "start": "146460",
    "end": "153020"
  },
  {
    "text": "P sequel it's going to look like a regular Postgres database it's going to",
    "start": "153020",
    "end": "158910"
  },
  {
    "text": "give you the same backup and restore capabilities point in time recovery even though Aurora Postgres will do it in a",
    "start": "158910",
    "end": "164460"
  },
  {
    "text": "different manner you have that same capabilities same thing with high durability and high availability Aurora",
    "start": "164460",
    "end": "170970"
  },
  {
    "text": "is built to give you higher availability and higher durability but you're able to get it in both of them from security",
    "start": "170970",
    "end": "177720"
  },
  {
    "text": "from doing things like I am a thon tent ocation so if you have higher security",
    "start": "177720",
    "end": "182910"
  },
  {
    "text": "environments allows you to be able to log in without passwords by getting a token that's only alive for 15 minutes",
    "start": "182910",
    "end": "190110"
  },
  {
    "text": "same thing we read replicas you know cross region snapshots and scaling out",
    "start": "190110",
    "end": "196640"
  },
  {
    "text": "one of the things two of the things that aren't there in a rural post quest yet is cross region replication and outbound",
    "start": "196640",
    "end": "204270"
  },
  {
    "text": "logical replication so if you want to be able to replicate your database from east coast to the west coast it's not",
    "start": "204270",
    "end": "212790"
  },
  {
    "text": "there yet in Aurora Postgres it's on its way same thing with outbound logical",
    "start": "212790",
    "end": "217800"
  },
  {
    "text": "replication as Kevin talked about in his presentation of being able to have replication outside of Aurora that's",
    "start": "217800",
    "end": "224970"
  },
  {
    "text": "also not quite there yet but it's also on its way but those are a couple of the the differences between the two today",
    "start": "224970",
    "end": "230810"
  },
  {
    "text": "right and the idea is to have them in parity we have Postgres 10 and Postgres",
    "start": "230810",
    "end": "238410"
  },
  {
    "text": "11 as kevin has just got announced last week got released last week so you have",
    "start": "238410",
    "end": "244740"
  },
  {
    "text": "post-course 11 not one available and RDS Postgres so it's no longer in preview it's in GA so our storage is log base",
    "start": "244740",
    "end": "253290"
  },
  {
    "text": "storage what that means is as you're making your rights you're just sending",
    "start": "253290",
    "end": "258810"
  },
  {
    "text": "your transaction locks right that gives us a lot of advantages",
    "start": "258810",
    "end": "264699"
  },
  {
    "text": "one of it when you have a traditional database when you're talking about Postgres other databases have you as you",
    "start": "264699",
    "end": "270789"
  },
  {
    "text": "have a bunch of work to do it goes into a queue goes into a log buffer and that",
    "start": "270789",
    "end": "275949"
  },
  {
    "text": "log buffer has to flush out the disk you have to f synch it in order to be durable right so when you have water so",
    "start": "275949",
    "end": "281529"
  },
  {
    "text": "as you're having more and more data flowing in more and more transactions in a group commit some scenario where you",
    "start": "281529",
    "end": "287020"
  },
  {
    "text": "have a lot of concurrent transactions going on what happens is that log buffer gets full and you have to wait in order",
    "start": "287020",
    "end": "294340"
  },
  {
    "text": "to flush it out to disk in order to be able to go to do the next amount of work so it has to flush out be able to F sync",
    "start": "294340",
    "end": "301210"
  },
  {
    "text": "and then come back and do more work one of the advantages of the architecture or",
    "start": "301210",
    "end": "306610"
  },
  {
    "text": "our storage we don't have that same bottleneck right what it is is you have",
    "start": "306610",
    "end": "312189"
  },
  {
    "text": "a a each each one of the transactions what it's going to do as it's ready it's",
    "start": "312189",
    "end": "317949"
  },
  {
    "text": "just gonna flush things out the storage right so this way you have multiple things you have five different",
    "start": "317949",
    "end": "323020"
  },
  {
    "text": "transactions all as they're ready flushing everything out the storage but we're keeping track of the durability as",
    "start": "323020",
    "end": "329379"
  },
  {
    "text": "Kevin mentioned in his talk we need four of six quorum for durability so when",
    "start": "329379",
    "end": "335050"
  },
  {
    "text": "four of the six storage nodes come back and say that this is durable it's going",
    "start": "335050",
    "end": "340539"
  },
  {
    "text": "to be able to acknowledge the commits back to the client and we're going to go a little bit deeper about storage nodes and how that works but at first nobody",
    "start": "340539",
    "end": "348520"
  },
  {
    "text": "came back and said we're durable yet we just flushed out those five transactions but after you wait a little bit you know",
    "start": "348520",
    "end": "354879"
  },
  {
    "text": "you know fractions of a millisecond two of the six came back on for a transaction to a and B so it's almost",
    "start": "354879",
    "end": "363039"
  },
  {
    "text": "there it's halfway done then you wait a little bit longer transaction a hits",
    "start": "363039",
    "end": "368589"
  },
  {
    "text": "four it's good it's durable it's across four of the six but if you notice C also",
    "start": "368589",
    "end": "375969"
  },
  {
    "text": "as it for but we haven't acknowledged that back to the client Postgres is a acid compliant relational",
    "start": "375969",
    "end": "383259"
  },
  {
    "text": "database everything has to happen in a specific order so we can't acknowledge it until B has been at all so there so",
    "start": "383259",
    "end": "389830"
  },
  {
    "text": "it has to go in order right so it's going to wait in order an acknowledge C has gotten back to the client until B is",
    "start": "389830",
    "end": "395889"
  },
  {
    "text": "also done so if you wait a little longer then you're going to see that B and C e also getting acknowledged",
    "start": "395889",
    "end": "402460"
  },
  {
    "text": "they're durable they hit their 406 quorum and also a is also at 5:00 but we also have to wait there because D isn't",
    "start": "402460",
    "end": "410289"
  },
  {
    "text": "quite at the four of six yet so this way each day each transaction as its ready to flush out the storage it just goes",
    "start": "410289",
    "end": "416860"
  },
  {
    "text": "ahead and does that there's no waiting for the log buffers waiting for everybody to F sync on that same transaction log volume one of the other",
    "start": "416860",
    "end": "426909"
  },
  {
    "start": "425000",
    "end": "425000"
  },
  {
    "text": "big advantages of Arora Postgres is we write a lot less so in a traditional database you have to do things called",
    "start": "426909",
    "end": "433930"
  },
  {
    "text": "checkpointing and what a check point is is making sure that all your changes",
    "start": "433930",
    "end": "439180"
  },
  {
    "text": "that are that you've made recently in your database that you've written out to your transaction log are flushed out to",
    "start": "439180",
    "end": "446139"
  },
  {
    "text": "the main data files themselves otherwise you're gonna have a really long time there for recovery trying to replay all",
    "start": "446139",
    "end": "452110"
  },
  {
    "text": "your transaction logs so periodically you have to do that and in Postgres you have to you end up doing extra work when",
    "start": "452110",
    "end": "459039"
  },
  {
    "text": "you're doing that called full paid writes and we'll get into that so if you're writing something in Postgres you're gonna do an update and one of the",
    "start": "459039",
    "end": "466930"
  },
  {
    "text": "things about Postgres with multi-version concurrency control so different transactions gets are not waiting on",
    "start": "466930",
    "end": "472449"
  },
  {
    "text": "each other though where you have locking an update and Postgres is it a logical",
    "start": "472449",
    "end": "477699"
  },
  {
    "text": "deletion of the old version or inserting a new one so every update really is",
    "start": "477699",
    "end": "482709"
  },
  {
    "text": "affecting two different rows right that's written a transaction log and",
    "start": "482709",
    "end": "488019"
  },
  {
    "text": "we're getting that full page after a transaction after a checkpoint Postgres",
    "start": "488019",
    "end": "493389"
  },
  {
    "text": "has to write out the full page out to the transaction log and we'll get into that in a second why why we need to do",
    "start": "493389",
    "end": "501249"
  },
  {
    "text": "that but then after that we insert a new row that gets written out their transaction log right and then we do our",
    "start": "501249",
    "end": "508659"
  },
  {
    "text": "checkpoint flushing out to the data file so we want to be able to rewrite that and write that page actually down to the",
    "start": "508659",
    "end": "515349"
  },
  {
    "text": "data file itself on the storage right also what we want to be able to archive",
    "start": "515349",
    "end": "521620"
  },
  {
    "text": "that log being able to push that out so that in the event for point and time recovery we want to be able to get that",
    "start": "521620",
    "end": "527620"
  },
  {
    "text": "log file back we could roll forward to any point in time so or backups and that's pushed out to s3",
    "start": "527620",
    "end": "536030"
  },
  {
    "text": "but one of the things that o of why we need that full page rank is just the",
    "start": "536030",
    "end": "542460"
  },
  {
    "text": "mismatch between linux and Postgres Postgres writes everything in 8k pages",
    "start": "542460",
    "end": "547880"
  },
  {
    "text": "Linux writes everything in 4k pages in the event that there's an error or a",
    "start": "547880",
    "end": "553200"
  },
  {
    "text": "crash in the middle of flushing out that page you get what's called a torn page four of that 8k might have been written",
    "start": "553200",
    "end": "560010"
  },
  {
    "text": "out to disk so this way you're in that event your database would be corrupted",
    "start": "560010",
    "end": "565260"
  },
  {
    "text": "or at least that page would be corrupted so what Postgres does in the event of a recovery it takes that full page that's",
    "start": "565260",
    "end": "571710"
  },
  {
    "text": "written to the transaction log and overwrites that entire page in a recovery scenario so this way you don't",
    "start": "571710",
    "end": "577380"
  },
  {
    "text": "get any torn page scenarios right in",
    "start": "577380",
    "end": "583080"
  },
  {
    "text": "Aurora we up that update that row we need to get those two versions of the row just like any update Postgres works",
    "start": "583080",
    "end": "589380"
  },
  {
    "text": "the rural post cards works the same as Postgres in that effect with multi-version concurrency control and",
    "start": "589380",
    "end": "595140"
  },
  {
    "text": "that's going to be important when we talk about vacuum in a little while and that's flushed out to Aurora storage you",
    "start": "595140",
    "end": "602010"
  },
  {
    "text": "don't need that full page right because Aurora doesn't do any checkpoints all that work is pushed down into the",
    "start": "602010",
    "end": "608760"
  },
  {
    "text": "storage nodes themselves right and then we just happily go along add that next row will flush out Aurora our storage",
    "start": "608760",
    "end": "615750"
  },
  {
    "text": "out to s3 for backups but there's no there's no checkpoints and because of no",
    "start": "615750",
    "end": "621480"
  },
  {
    "text": "checkpoints we don't need to do full-page writes it's one of the ways that we get higher throughput as we're",
    "start": "621480",
    "end": "627890"
  },
  {
    "text": "as your application is running you're just writing a lot less the storage with Aurora as opposed to what you're doing",
    "start": "627890",
    "end": "634230"
  },
  {
    "text": "with RDS Postgres or community Postgres so what happens inside the storage notes",
    "start": "634230",
    "end": "640650"
  },
  {
    "start": "638000",
    "end": "638000"
  },
  {
    "text": "so we we talked about that Rory you have four or six quorum so on a very small",
    "start": "640650",
    "end": "645990"
  },
  {
    "text": "database you might be across six different storage nodes big databases you might have to be across hundreds or",
    "start": "645990",
    "end": "652770"
  },
  {
    "text": "even potentially thousands of different storage nodes this is what happens inside one of those right so when our",
    "start": "652770",
    "end": "660570"
  },
  {
    "text": "aurora read/write node goes and makes a change right it flows into an",
    "start": "660570",
    "end": "665790"
  },
  {
    "text": "thank you that's in memory it then goes into the update queue where it's",
    "start": "665790",
    "end": "672330"
  },
  {
    "text": "persistent to storage right at that point it's durable and it could acknowledge back so that's the entire",
    "start": "672330",
    "end": "679530"
  },
  {
    "text": "aspect that's synchronous waiting for that acknowledgement back from the individual storage notes when you're",
    "start": "679530",
    "end": "685200"
  },
  {
    "text": "waiting for that 4 or 6 quorum it's coming into that queue flushing it out to the update queue so it's persistent",
    "start": "685200",
    "end": "691080"
  },
  {
    "text": "on storage and then you get the acknowledgement back you are persistent in disk at that point and behind the",
    "start": "691080",
    "end": "697050"
  },
  {
    "text": "scenes that update queue goes and does some extra work asynchronously that you",
    "start": "697050",
    "end": "702600"
  },
  {
    "text": "don't have to wait for it's just going to be doing things behind it because it's intelligent it understands the wall format is doing things it's writing out",
    "start": "702600",
    "end": "709190"
  },
  {
    "text": "that update to the data blocks because when you need to do a read its you need",
    "start": "709190",
    "end": "714780"
  },
  {
    "text": "to return back those data blocks all right so you get it's going to coalesce those those changes into the individual",
    "start": "714780",
    "end": "720330"
  },
  {
    "text": "data blocks right it's also going out to the hot lock were their most recent",
    "start": "720330",
    "end": "725340"
  },
  {
    "text": "changes one of the advantage to the Aurora storage is with that 4 or 6 quorum the the different storage nodes",
    "start": "725340",
    "end": "732960"
  },
  {
    "text": "use peer-to-peer gossip in order to be able to fix one another so the event that you don't have to coordinate that",
    "start": "732960",
    "end": "739860"
  },
  {
    "text": "from the main Postgres engine the individual storage nodes fix themselves in the event of any sort of errors and",
    "start": "739860",
    "end": "746220"
  },
  {
    "text": "that hot log pushes stuff out into into the individual pieces right and all of",
    "start": "746220",
    "end": "751860"
  },
  {
    "text": "that is pushed out to s3 for storage all the time so you don't have to create a backup window or anything like that",
    "start": "751860",
    "end": "758190"
  },
  {
    "text": "all of everything's being backed up automatically for you behind the scenes into s3 one of the differences between",
    "start": "758190",
    "end": "764990"
  },
  {
    "text": "Aurora or Postgres and RDS Postgres RDS Postgres you have to give it a baton it's a backup window",
    "start": "764990",
    "end": "770940"
  },
  {
    "text": "Aurora Postgres it's always backing up so this way when you're when you do an",
    "start": "770940",
    "end": "778230"
  },
  {
    "text": "individual read request it's pulling it back that data block which has been coalesced from from the changes that's",
    "start": "778230",
    "end": "783870"
  },
  {
    "text": "been pushed in there she's just the show some of the differences here of that and",
    "start": "783870",
    "end": "791760"
  },
  {
    "text": "how you get additional throughput we created a test table that has a bunch of different type of data in there nine",
    "start": "791760",
    "end": "798180"
  },
  {
    "text": "nine different columns right we just random things that are in there we indexed every column right that",
    "start": "798180",
    "end": "806310"
  },
  {
    "text": "might be not something that you would ordinarily do but you might have 50 or 75 columns in there and you might have",
    "start": "806310",
    "end": "813750"
  },
  {
    "text": "nine indexes on there right you might have thirty indexes on there not not uncommon to see many indexes on on wider",
    "start": "813750",
    "end": "820709"
  },
  {
    "text": "tables but just creating a large number of indexes on a fairly straightforward",
    "start": "820709",
    "end": "826649"
  },
  {
    "text": "table what we did is we did an insert workload test",
    "start": "826649",
    "end": "832910"
  },
  {
    "text": "and across the the the y-axis is the insert per second and it's just time",
    "start": "832910",
    "end": "840540"
  },
  {
    "text": "across the the x-axis and what you see with Postgres with base Postgres it",
    "start": "840540",
    "end": "847410"
  },
  {
    "text": "starts out running pretty fast at around 25,000 inserts per second pretty fast",
    "start": "847410",
    "end": "852690"
  },
  {
    "text": "but it drops off radically very quickly it's a very steep drop and what's",
    "start": "852690",
    "end": "859260"
  },
  {
    "text": "happening there is as your indexes are getting bigger and bigger you're doing more full page rights as thing is your",
    "start": "859260",
    "end": "865500"
  },
  {
    "text": "check pointing you're gonna have to do more and more work in order to be able to maintain that right so it drops off",
    "start": "865500",
    "end": "871650"
  },
  {
    "text": "radically as you have to do all those full page rights because you have to do that not just for the main table you",
    "start": "871650",
    "end": "876720"
  },
  {
    "text": "have to do that for every index that you're maintaining so one of the things",
    "start": "876720",
    "end": "881970"
  },
  {
    "text": "that DBAs typically do when they have to go through a lot of transit going through a lot of transaction locks they",
    "start": "881970",
    "end": "887790"
  },
  {
    "text": "increase the size of their transaction locks so this way you spread out those checkpoints more so increasing your your",
    "start": "887790",
    "end": "894270"
  },
  {
    "text": "transaction log size your wall size the right a headlock out to 16 gigabytes from the the default of two it chugged",
    "start": "894270",
    "end": "902160"
  },
  {
    "text": "along fine for about 20 minutes right around 25,000 TPS and then you saw",
    "start": "902160",
    "end": "907829"
  },
  {
    "text": "that drop-off again he started getting that same sort of effect but Aurora is",
    "start": "907829",
    "end": "913620"
  },
  {
    "text": "across the top it was a little bit more than it's about 27,000 TPS or so but it",
    "start": "913620",
    "end": "919920"
  },
  {
    "text": "was consistent you're not doing those full page rights right so you this way you're not getting that jitter or that",
    "start": "919920",
    "end": "926640"
  },
  {
    "text": "massive drop-off of having to be able to write that that additional work out to storage because Aurora doesn't need to",
    "start": "926640",
    "end": "934980"
  },
  {
    "text": "and looking at it for the same thing of updating right so if you're updating two columns you get it you see that standard",
    "start": "934980",
    "end": "943360"
  },
  {
    "text": "Postgres or RDS Postgres at 3700 TPS whereas an R or Postgres at 17,000 you",
    "start": "943360",
    "end": "950230"
  },
  {
    "text": "see that the same effect in updates as well because an update again is a logical deletion and an inserting and a",
    "start": "950230",
    "end": "956860"
  },
  {
    "text": "new version of the row in Postgres do you get that same effect that every time you do an update it has to be able to",
    "start": "956860",
    "end": "962740"
  },
  {
    "text": "insert new things into an index but what like I mentioned one of the standard",
    "start": "962740",
    "end": "969579"
  },
  {
    "text": "things at DBA Zoo in order to get higher throughput is to increase your transaction log size in order to be able",
    "start": "969579",
    "end": "976000"
  },
  {
    "text": "to spread out those checkpoints right but that comes as a a trade off whenever",
    "start": "976000",
    "end": "983079"
  },
  {
    "text": "you're going to increase that transaction log size ya have the expense of recovery time",
    "start": "983079",
    "end": "988180"
  },
  {
    "text": "so the in the event that server crashes for whatever reason or if you even",
    "start": "988180",
    "end": "993220"
  },
  {
    "text": "simply do a restart of the server because you want to change some parameters that require a restart you",
    "start": "993220",
    "end": "998770"
  },
  {
    "text": "have you have to be able to shut everything down checkpoint everything out and the longer",
    "start": "998770",
    "end": "1003779"
  },
  {
    "text": "there is that longer it takes to be able to do that so for doing a a simple test here where we have three gigabyte a redo",
    "start": "1003779",
    "end": "1010950"
  },
  {
    "text": "or wall it'll go through with a about twenty eighteen thousand rights per",
    "start": "1010950",
    "end": "1016500"
  },
  {
    "text": "second which is along the x-axis here and it'll have a recovery time of",
    "start": "1016500",
    "end": "1021839"
  },
  {
    "text": "nineteen seconds so if your SLE lays for getting that up after some sort of crash it's really low great but if you're",
    "start": "1021839",
    "end": "1030839"
  },
  {
    "text": "you're giving up a lot of performance of only getting about eighteen thousand rights per second you can't increase",
    "start": "1030839",
    "end": "1036600"
  },
  {
    "text": "that make that that size bigger more about ten gig right but when you're",
    "start": "1036600",
    "end": "1041760"
  },
  {
    "text": "doing that you're gonna be you're gonna get you know thirty seven thousand or so rights per second at the trade of your",
    "start": "1041760",
    "end": "1048750"
  },
  {
    "text": "recovery time now your recovery time went from nineteen seconds out to fifty seconds you go even further of making",
    "start": "1048750",
    "end": "1056910"
  },
  {
    "text": "that 30 gigabytes right you get even more performance up around over forty",
    "start": "1056910",
    "end": "1063150"
  },
  {
    "text": "thousand rights per second but now your transaction your recovery time is up for two minutes right so - one of the",
    "start": "1063150",
    "end": "1070320"
  },
  {
    "text": "unfortunate things when you have databases that do the checkpoint you're trying to balance performance versus",
    "start": "1070320",
    "end": "1076920"
  },
  {
    "text": "your SLA s out to your customers right it's it's you're not making a technical decision you're making a business",
    "start": "1076920",
    "end": "1082050"
  },
  {
    "text": "decision in order to add how to be able to maintain your database I think but",
    "start": "1082050",
    "end": "1089250"
  },
  {
    "text": "that little dot out in the corner that's kind of hard to see is Aurora because there's no redo right",
    "start": "1089250",
    "end": "1097380"
  },
  {
    "text": "recovery time only takes three seconds because there's nothing - there's nothing that's to go through a recovery and you're doing a hundred and",
    "start": "1097380",
    "end": "1105060"
  },
  {
    "text": "thirty-five thousand transactions per second because you're off that checkpointing the full page writes you're able to get that higher",
    "start": "1105060",
    "end": "1110370"
  },
  {
    "text": "throughput and you don't have to be able to trade your business rules for the recovery times so let's talk a little",
    "start": "1110370",
    "end": "1119670"
  },
  {
    "text": "bit more about the base architecture we've talked about storage nodes in the 406 quorum what does that mean so",
    "start": "1119670",
    "end": "1126600"
  },
  {
    "start": "1124000",
    "end": "1124000"
  },
  {
    "text": "whenever you create a new instance of Aurora it's spread across three availability zones so when you when",
    "start": "1126600",
    "end": "1133410"
  },
  {
    "text": "you're talking about Aurora storage you want to think about it as just essentially clustered storage that's",
    "start": "1133410",
    "end": "1140250"
  },
  {
    "text": "there it's automatically spread across three availability zones for you and you",
    "start": "1140250",
    "end": "1145260"
  },
  {
    "text": "have multiple storage nodes in each one of those so when you're creating your application it's going to create each",
    "start": "1145260",
    "end": "1151500"
  },
  {
    "text": "one of those storage nodes and inside of that when you ask for something it's going to create ten gig segments in each",
    "start": "1151500",
    "end": "1157500"
  },
  {
    "text": "of those storage nodes right and that'll automatically scale for you up to the 64",
    "start": "1157500",
    "end": "1163830"
  },
  {
    "text": "terabytes that Kevin mentioned and then when you have your applications across",
    "start": "1163830",
    "end": "1169890"
  },
  {
    "text": "multiple availability zones we're all connecting to the readwrite nodes and it's just gonna write the transaction",
    "start": "1169890",
    "end": "1175740"
  },
  {
    "text": "log records out the storage right no need to do the flushes out of the actual",
    "start": "1175740",
    "end": "1180840"
  },
  {
    "text": "data pages itself Aurora Storage is handling that for you and it's gonna",
    "start": "1180840",
    "end": "1186240"
  },
  {
    "text": "write it out to those six individual storage nodes as we were talking about",
    "start": "1186240",
    "end": "1191510"
  },
  {
    "text": "it's gonna read those blocks back it's gonna try to get it from the local availability zone where it's gonna be",
    "start": "1191510",
    "end": "1196710"
  },
  {
    "text": "faster you keep track of what the highest the highest transactions are so this way",
    "start": "1196710",
    "end": "1202470"
  },
  {
    "text": "you're getting back the right versions but in the event that something happens to one of these storage storage notes",
    "start": "1202470",
    "end": "1209220"
  },
  {
    "text": "one of the segments didn't get the last updates for instance right we did four or six for the quorum one of the six",
    "start": "1209220",
    "end": "1217139"
  },
  {
    "text": "never actually made it their network clip whatever right we're we understand",
    "start": "1217139",
    "end": "1222419"
  },
  {
    "text": "in the world of computing nothing's perfect something didn't get there that's where",
    "start": "1222419",
    "end": "1228240"
  },
  {
    "text": "the peer-to-peer gossip comes into play it'll automatically get it from one of the other storage nodes that have the",
    "start": "1228240",
    "end": "1233639"
  },
  {
    "text": "latest version the Postgres engine itself doesn't have to be able to repair it",
    "start": "1233639",
    "end": "1238860"
  },
  {
    "text": "Aurora storage is going to self repair those for you Postgres doesn't need to worry about that again doing less work",
    "start": "1238860",
    "end": "1244950"
  },
  {
    "text": "or our storage is dealing with that right so in the event that a whole",
    "start": "1244950",
    "end": "1250169"
  },
  {
    "text": "storage node goes down some of your data is on one of those stores you know the whole thing goes down again",
    "start": "1250169",
    "end": "1255950"
  },
  {
    "text": "Aurora Storage will automatically take the the different segments that were on that storage ode and replaced them into",
    "start": "1255950",
    "end": "1262350"
  },
  {
    "text": "other storage notes completely transparent to you in the application",
    "start": "1262350",
    "end": "1270350"
  },
  {
    "text": "and then when you're speeding up a read-only replica right read-only note",
    "start": "1270440",
    "end": "1275809"
  },
  {
    "text": "when you're doing that in or or Postgres you need to be able to make a whole copy of the data in Aurora Postgres you have",
    "start": "1275809",
    "end": "1284159"
  },
  {
    "text": "shared storage there's no need to be able to create that copy of the data it's just gonna pull that back from the",
    "start": "1284159",
    "end": "1290369"
  },
  {
    "text": "stuff from the shared storage and there's going to be a little bit of communication between the the read/write",
    "start": "1290369",
    "end": "1296460"
  },
  {
    "text": "node and the read-only node in order to be able to sync up the caches and really",
    "start": "1296460",
    "end": "1302730"
  },
  {
    "text": "invalidate the caches that are there and you can create many of them more than one to three you can create up to 15",
    "start": "1302730",
    "end": "1310200"
  },
  {
    "text": "read-only notes so this way in the event of a failure of the readwrite node you",
    "start": "1310200",
    "end": "1317669"
  },
  {
    "text": "could just go ahead and from it'll just go ahead and automatically promote one of your read-only notes so going a",
    "start": "1317669",
    "end": "1325110"
  },
  {
    "text": "little bit further into why four or six quorum why did why did it go along doing",
    "start": "1325110",
    "end": "1331049"
  },
  {
    "start": "1331000",
    "end": "1331000"
  },
  {
    "text": "that so when you you're talking about RTS Postgres we have multi AG you have",
    "start": "1331049",
    "end": "1336780"
  },
  {
    "text": "synchronous replication from one availability to a second one why didn't we just do the same thing with aurora so",
    "start": "1336780",
    "end": "1344790"
  },
  {
    "text": "inside of RDS Postgres right we do a commit it gets flushed out to an EBS",
    "start": "1344790",
    "end": "1351480"
  },
  {
    "text": "volume comes back great when you're talking about a single availability zone really under the covers you're making",
    "start": "1351480",
    "end": "1360150"
  },
  {
    "text": "two copies of it question back there",
    "start": "1360150",
    "end": "1363860"
  },
  {
    "text": "we'll get to that we have slides for that right so under the covers EBS isn't",
    "start": "1369470",
    "end": "1378030"
  },
  {
    "text": "just writing out a single copy of it it's also backing itself up or it's making another copy of it so when you",
    "start": "1378030",
    "end": "1383730"
  },
  {
    "text": "write it out to an EBS volume it's also synchronously writing it out to a secondary right and has to come back",
    "start": "1383730",
    "end": "1390030"
  },
  {
    "text": "acknowledge it and then go back so this way you're already getting multiple copies of your data with EBS but in the",
    "start": "1390030",
    "end": "1396990"
  },
  {
    "text": "event that the entire availability zone goes down or that instance goes down you want to have it in a second availability",
    "start": "1396990",
    "end": "1402990"
  },
  {
    "text": "zone so you go ahead and create a second one great but really for things like",
    "start": "1402990",
    "end": "1409920"
  },
  {
    "text": "Aurora you want to have even greater availability across multiple availability zones so why didn't we just",
    "start": "1409920",
    "end": "1416070"
  },
  {
    "text": "add a third one compared to what was there right so we do commit when you're talking about the multiple availability",
    "start": "1416070",
    "end": "1422880"
  },
  {
    "text": "zones as to get synchronously flushed out to the the secondary and the",
    "start": "1422880",
    "end": "1428400"
  },
  {
    "text": "tertiary right and the the local availability zone is writing things out to local ubs volumes it's going ahead",
    "start": "1428400",
    "end": "1435660"
  },
  {
    "text": "right the secondary is kind of progressing a little bit more maybe the the tertiary was a little bit further",
    "start": "1435660",
    "end": "1441990"
  },
  {
    "text": "away geographically it took an extra fraction of the millisecond for it to get there so it's a little bit slower",
    "start": "1441990",
    "end": "1448410"
  },
  {
    "text": "starting the work of flushing everything out to the EBS volumes all right so we acknowledged we acknowledged back from",
    "start": "1448410",
    "end": "1454230"
  },
  {
    "text": "the local ability zone right finally we get it back from the secondary but we're not done yet",
    "start": "1454230",
    "end": "1459570"
  },
  {
    "text": "right we have to wait for that tertiary to finish in order to get all three availability zones all synced up",
    "start": "1459570",
    "end": "1465900"
  },
  {
    "text": "synchronously right so what happens if you actually lose an individual availability zone or",
    "start": "1465900",
    "end": "1473250"
  },
  {
    "text": "that instance that tertiary instance goes down we have to fence that off so this we don't do any rights to it while",
    "start": "1473250",
    "end": "1479280"
  },
  {
    "text": "it's repairing itself right so all the rights we go to their primary and secondary when the tertiary comes back",
    "start": "1479280",
    "end": "1485490"
  },
  {
    "text": "up it has to catch back up again right and has to do a post course would have to do all the work of being able to do",
    "start": "1485490",
    "end": "1491010"
  },
  {
    "text": "that but we did testing of looking what that would look like under a right",
    "start": "1491010",
    "end": "1498179"
  },
  {
    "text": "workload of having two copies versus three copies the two copies being what",
    "start": "1498179",
    "end": "1503340"
  },
  {
    "text": "RDS Postgres does today right so at the 50th percentile right difference between",
    "start": "1503340",
    "end": "1509250"
  },
  {
    "text": "two and three replicas six milliseconds versus seven really not that big of a difference if you wanted that extra",
    "start": "1509250",
    "end": "1515390"
  },
  {
    "text": "availability great you're you know giving up one millisecond big deal right",
    "start": "1515390",
    "end": "1521160"
  },
  {
    "text": "and then even as you go 90 or 99.9 you might be able to do that trade of 22",
    "start": "1521160",
    "end": "1526260"
  },
  {
    "text": "versus 28 but that 99.9 that one in 10,000 transactions is four times longer",
    "start": "1526260",
    "end": "1533990"
  },
  {
    "text": "you get a lot of jitter right of things that are there so this way that's model",
    "start": "1533990",
    "end": "1541350"
  },
  {
    "text": "won't work as we add more and more synchronous replicas you get more and more of that jitter you have more the",
    "start": "1541350",
    "end": "1546390"
  },
  {
    "text": "possibility of one of those transactions going slow right so it doesn't really work which is why the four or six quorum",
    "start": "1546390",
    "end": "1556970"
  },
  {
    "text": "smooths out that jitter right so when you do a commit Aurora is going to push it out so all six of them all at the",
    "start": "1556970",
    "end": "1564540"
  },
  {
    "text": "same time right and it's going to get back things from most likely from the local availability zone first and then",
    "start": "1564540",
    "end": "1572669"
  },
  {
    "text": "you're gonna wait from one you get back to we got the four or six we're done we don't have to wait anything from that",
    "start": "1572669",
    "end": "1578010"
  },
  {
    "text": "third availability zone we have four of six already committed right and gave us the acknowledgement back right and then",
    "start": "1578010",
    "end": "1583950"
  },
  {
    "text": "finally the comeback great right so in the event that it missed one of those",
    "start": "1583950",
    "end": "1589940"
  },
  {
    "text": "Aurora storage is going to resync that stuff the engine doesn't have to wait for it so to give you idea of just",
    "start": "1589940",
    "end": "1597419"
  },
  {
    "text": "getting rid of that some of that jitter did another test using sis bench right",
    "start": "1597419",
    "end": "1606230"
  },
  {
    "text": "we have things like over the course of 20 minutes not a very long test of the",
    "start": "1606230",
    "end": "1612540"
  },
  {
    "text": "response time in in milliseconds Aurora gives us a nice even flow across",
    "start": "1612540",
    "end": "1619140"
  },
  {
    "text": "the bottom there of nice very low jitter whereas Postgres with a single AZ not",
    "start": "1619140",
    "end": "1625740"
  },
  {
    "text": "even going multi AZ we get all these jitters so if you look at the bottom of",
    "start": "1625740",
    "end": "1630810"
  },
  {
    "text": "those that blue line it's fairly close to Aurora right not that big of a difference right but that jitter going up and down",
    "start": "1630810",
    "end": "1638130"
  },
  {
    "text": "all over the place those are checkpoints right every periodically every couple",
    "start": "1638130",
    "end": "1644940"
  },
  {
    "text": "minutes you got to flush out all your data pages and do a lot more work starving the rest of the system from",
    "start": "1644940",
    "end": "1650850"
  },
  {
    "text": "just flushing out those individual transactions all right so you whenever",
    "start": "1650850",
    "end": "1656460"
  },
  {
    "text": "you do a load test on a traditional database you're going to see that that wave action whereas Aurora you're going",
    "start": "1656460",
    "end": "1662070"
  },
  {
    "text": "to see a nice flat line right so even at it so at the very height you know that",
    "start": "1662070",
    "end": "1668430"
  },
  {
    "text": "low point there you're not going to see that big of difference between RDS Postgres in Aurora Postgres typical",
    "start": "1668430",
    "end": "1674760"
  },
  {
    "text": "thing I see as people are benchmarking RDS Postgres versus Aurora let me do a single AZ an RDS Postgres said spread",
    "start": "1674760",
    "end": "1682260"
  },
  {
    "text": "out my check point says 60 minutes and then run it and it hey look they're all about the same why would I use Aurora",
    "start": "1682260",
    "end": "1687920"
  },
  {
    "text": "it's because they haven't done checkpoints once you start doing checkpoints all of a sudden you start seeing that and the average is go away",
    "start": "1687920",
    "end": "1693750"
  },
  {
    "text": "off question same availability zone yeah",
    "start": "1693750",
    "end": "1704030"
  },
  {
    "text": "it'd be on a client putting the same availability zone so we don't get the latency between the engine driver and",
    "start": "1704030",
    "end": "1711660"
  },
  {
    "text": "the main database server itself",
    "start": "1711660",
    "end": "1715430"
  },
  {
    "text": "it's architecture around pushing a lot of the work that you would normally do the postcards engine has to do with the",
    "start": "1722519",
    "end": "1729070"
  },
  {
    "text": "background writer flushing out the data pages and doing checkpoints of taking that same essential work and pushing",
    "start": "1729070",
    "end": "1735250"
  },
  {
    "text": "that down into Aurora storage so instead of having one giant checkpoint you're doing all that work of coalescing those",
    "start": "1735250",
    "end": "1741549"
  },
  {
    "text": "data pages across many storage nodes you're doing in parallel and not impacting the main engine itself yeah",
    "start": "1741549",
    "end": "1751529"
  },
  {
    "text": "right right so you're only writing out those transaction logs and then Aurora Storage takes everything out that you",
    "start": "1751529",
    "end": "1757269"
  },
  {
    "text": "would most courses normally have to do and does it in parallel across many storage totes right so talking about the",
    "start": "1757269",
    "end": "1766659"
  },
  {
    "text": "replicas and clones which we had a question about right so in Postgres when",
    "start": "1766659",
    "end": "1771940"
  },
  {
    "text": "you need to be able to create a replica so RDS Postgres you ask for a replica we take a snapshot of the EBS volume create",
    "start": "1771940",
    "end": "1780419"
  },
  {
    "text": "you know move that over to a new EB s volume spin up a Postgres read-only note",
    "start": "1780419",
    "end": "1786879"
  },
  {
    "text": "it attaches to that EBS volume right and then we have to catch up so that might",
    "start": "1786879",
    "end": "1792610"
  },
  {
    "text": "take hours depending on the size of your database in how how much transact how",
    "start": "1792610",
    "end": "1799809"
  },
  {
    "text": "many transactions you're going through your read right now right if it's a very heavily loaded system it might take a",
    "start": "1799809",
    "end": "1805179"
  },
  {
    "text": "long time to be able to catch back up again right so as as you're doing",
    "start": "1805179",
    "end": "1810220"
  },
  {
    "text": "updates in Postgres whether it's going to be community Postgres or RDS Postgres",
    "start": "1810220",
    "end": "1816909"
  },
  {
    "text": "when you do an update need to be able to write that out to the EBS volumes but you might have to actually read that",
    "start": "1816909",
    "end": "1823029"
  },
  {
    "text": "block into memory first in order to be able to update that and then once that",
    "start": "1823029",
    "end": "1829750"
  },
  {
    "text": "comes back asynchronously it's going to go send out that that log record out to the read-only node on post Postgres and",
    "start": "1829750",
    "end": "1836590"
  },
  {
    "text": "get has to do the same amount of work it might have to pull that log off of storage B in order to be update that and",
    "start": "1836590",
    "end": "1842830"
  },
  {
    "text": "flush that back out the disk again right Aurora",
    "start": "1842830",
    "end": "1849340"
  },
  {
    "text": "you read right now it flushes things out there are starch the read-only node reads things off of our storage so when",
    "start": "1849340",
    "end": "1856630"
  },
  {
    "text": "you do that update the readwrite node does the same thing that would with",
    "start": "1856630",
    "end": "1863160"
  },
  {
    "text": "regular Postgres might have to read that block out of storage in order to be able to update it it'll then send that",
    "start": "1863160",
    "end": "1870130"
  },
  {
    "text": "asynchronous replication request out there and it doesn't have to do anything to storage if that block is in memory it",
    "start": "1870130",
    "end": "1877300"
  },
  {
    "text": "just invalidates that block but it doesn't have to make any changes because you have shared storage between them it",
    "start": "1877300",
    "end": "1883090"
  },
  {
    "text": "doesn't have to duplicate that change the way it does with traditional Postgres so just as an example PG bench",
    "start": "1883090",
    "end": "1891310"
  },
  {
    "start": "1888000",
    "end": "1888000"
  },
  {
    "text": "is one of the common benchmarking tools that the post-course community uses says simple for tables supposed to represent",
    "start": "1891310",
    "end": "1898870"
  },
  {
    "text": "a banking application with counts tellers branches in history and one of",
    "start": "1898870",
    "end": "1905410"
  },
  {
    "text": "the nice things about that that trick question",
    "start": "1905410",
    "end": "1910710"
  },
  {
    "text": "okay the question is is if we're getting everything out of Aurora storage why do",
    "start": "1922420",
    "end": "1928430"
  },
  {
    "text": "we have to send that asynchronous replica because that replica may have",
    "start": "1928430",
    "end": "1933830"
  },
  {
    "text": "the block in memory and page so we have to invalidate that so it gets the latest",
    "start": "1933830",
    "end": "1939380"
  },
  {
    "text": "version out of storage right so we have to send that invalidation message so it knows that it's no longer valid so then",
    "start": "1939380",
    "end": "1950480"
  },
  {
    "text": "one of the nice things about PG bench is that we could do a rewrite test where it's going to touch all the tables or a",
    "start": "1950480",
    "end": "1956870"
  },
  {
    "text": "read-only test or just going to touch the account tables all right so so if you're running that it's just going to",
    "start": "1956870",
    "end": "1962630"
  },
  {
    "text": "run a lot of selects across the accounts table right and we'll do our asynchronous replication from the",
    "start": "1962630",
    "end": "1967880"
  },
  {
    "text": "readwrite sending all its changes out to the read-only node right and it will apply it there but when it's doing that",
    "start": "1967880",
    "end": "1974600"
  },
  {
    "text": "it's going to have to pull off all four tables into memory it's gonna it has to",
    "start": "1974600",
    "end": "1980720"
  },
  {
    "text": "in order to be able to do the updates it's gonna have to pull all that stuff into the read read-only note in order to",
    "start": "1980720",
    "end": "1985940"
  },
  {
    "text": "apply all those changes back into storage whereas with Aurora Postgres since it's",
    "start": "1985940",
    "end": "1991700"
  },
  {
    "text": "only sending those invalidation messages right it's just going to do the in-memory updates for the things that",
    "start": "1991700",
    "end": "1997280"
  },
  {
    "text": "happen to the accounts table here's a graph that I'll kind of illustrates that",
    "start": "1997280",
    "end": "2002800"
  },
  {
    "text": "a little bit so the that orange line is your transactions right and what",
    "start": "2002800",
    "end": "2010540"
  },
  {
    "text": "happened at about 23 or 24 minutes or so we did an update of the p PG bench",
    "start": "2010540",
    "end": "2017860"
  },
  {
    "text": "history did a backfill of updating all the roads right we had the populate a value in there which happens sometimes",
    "start": "2017860",
    "end": "2024490"
  },
  {
    "text": "in production you roll out some new functionality you have to update everything you add a new default value",
    "start": "2024490",
    "end": "2029950"
  },
  {
    "text": "of some sort and what happens at that point when you're talking about Postgres all of that has to be replicated out",
    "start": "2029950",
    "end": "2037270"
  },
  {
    "text": "there read-only node so that green line is the trend replication lag so things",
    "start": "2037270",
    "end": "2044740"
  },
  {
    "text": "were going along great it was keeping up and then when you did that giant update all of a sudden things started lag",
    "start": "2044740",
    "end": "2050840"
  },
  {
    "text": "all right quite a bit this is in seconds right so that's up to 600 seconds so",
    "start": "2050840",
    "end": "2056330"
  },
  {
    "text": "your lag started going up to about 10 minutes so instead of things being there",
    "start": "2056330",
    "end": "2061340"
  },
  {
    "text": "in milliseconds being basically up to date that giant update all of a sudden made",
    "start": "2061340",
    "end": "2066770"
  },
  {
    "text": "your replica just wait for that giant update to get consumed right because all",
    "start": "2066770",
    "end": "2071929"
  },
  {
    "text": "your updates have to happen in order or an order database everything's transactional has set",
    "start": "2071930",
    "end": "2077179"
  },
  {
    "text": "everything all happened in same order so nothing else could go through until that giant update has been processed by the",
    "start": "2077180",
    "end": "2083210"
  },
  {
    "text": "read-only note button rora we did that same backfill you don't even",
    "start": "2083210",
    "end": "2090889"
  },
  {
    "text": "know this difference right and if we look at this this is in millisecond so this is lag is going along in about 10",
    "start": "2090890",
    "end": "2097250"
  },
  {
    "text": "milliseconds even when we did that backfill it's down to about 1 millisecond because that PG bench",
    "start": "2097250",
    "end": "2103160"
  },
  {
    "text": "history isn't being accessed on that read-only note the the messages go over",
    "start": "2103160",
    "end": "2108380"
  },
  {
    "text": "there and just get discarded so it didn't have to do any process so one of",
    "start": "2108380",
    "end": "2116360"
  },
  {
    "start": "2115000",
    "end": "2115000"
  },
  {
    "text": "the other cool features is cloning creating a fast clone so where as",
    "start": "2116360",
    "end": "2121880"
  },
  {
    "text": "replicas you're doing things in order to be able to create it so this way it keeps up to date with the the primary",
    "start": "2121880",
    "end": "2128420"
  },
  {
    "text": "readwrite node clones you're creating something that's completely separate so you might have a reporting application",
    "start": "2128420",
    "end": "2134480"
  },
  {
    "text": "that every night at midnight you have to kick off reports from yesterday instead",
    "start": "2134480",
    "end": "2139610"
  },
  {
    "text": "of having a read read-only node trying to keep up over the course of the day spin up a clone at midnight and what",
    "start": "2139610",
    "end": "2148580"
  },
  {
    "text": "that does is it creates its own readwrite node a completely different instance right but it's gonna be",
    "start": "2148580",
    "end": "2155510"
  },
  {
    "text": "accessing clone storage so if you have a 20 terabyte database you don't have to",
    "start": "2155510",
    "end": "2161090"
  },
  {
    "text": "make an entire copy of it what it does is just creates pointers out to the the",
    "start": "2161090",
    "end": "2167240"
  },
  {
    "text": "main data itself right so you're not paying for that extra 20 terabytes right",
    "start": "2167240",
    "end": "2173300"
  },
  {
    "text": "you're just creating that clone storage all right so come to that 20 terabytes comes up really quickly really as quick",
    "start": "2173300",
    "end": "2179780"
  },
  {
    "text": "as it takes in order to be able to spin up the instances and attach to the clone storage",
    "start": "2179780",
    "end": "2184869"
  },
  {
    "text": "right so when the application starts interacting with the node it's going to",
    "start": "2184869",
    "end": "2190190"
  },
  {
    "text": "when it asks for a block it's going to pull it off of that clone storage that pointer and it's really going to pull it",
    "start": "2190190",
    "end": "2195859"
  },
  {
    "text": "off of that main main main storage question know you see that in a second",
    "start": "2195859",
    "end": "2207230"
  },
  {
    "text": "right so the question is what happens when we make changes right so if we go ahead and make that change what happens",
    "start": "2207230",
    "end": "2215029"
  },
  {
    "text": "it's a copy on right so it copies that block from that main storage brings it",
    "start": "2215029",
    "end": "2221390"
  },
  {
    "text": "down to the clone storage so this way you have two distinct copies of it and it breaks that that pointer link right",
    "start": "2221390",
    "end": "2228500"
  },
  {
    "text": "so this way depending on as things diverge they're gonna have you could potentially have duplicate of the entire",
    "start": "2228500",
    "end": "2234619"
  },
  {
    "text": "database if you update all the rows in your database but it's only going to do it as you start writing and making",
    "start": "2234619",
    "end": "2239839"
  },
  {
    "text": "changes to that you might insert new rows into that clone storage it's just gonna write it a to the clone storage",
    "start": "2239839",
    "end": "2245900"
  },
  {
    "text": "area right or from the main application you start writing logs there it's just",
    "start": "2245900",
    "end": "2251299"
  },
  {
    "text": "gonna write it out to the primary storage area right or if you make a change to it it's gonna do the same copy",
    "start": "2251299",
    "end": "2258500"
  },
  {
    "text": "unwrite flush out that old version out to clone storage and write the new version in the primary storage area so",
    "start": "2258500",
    "end": "2265730"
  },
  {
    "text": "this way it wins the instance that you take that that clone there the same you're pointing all the pointers are out",
    "start": "2265730",
    "end": "2272839"
  },
  {
    "text": "to the primary storage but as you start making changes to either primary or the",
    "start": "2272839",
    "end": "2278180"
  },
  {
    "text": "clone it starts diverging alright that's why you're able to make those clones",
    "start": "2278180",
    "end": "2283220"
  },
  {
    "text": "very quickly if it's a read-only application it's gonna be what it was at that instance of when you took that",
    "start": "2283220",
    "end": "2288740"
  },
  {
    "text": "clone so you might be at midnight every day so this way you don't have to worry about you know all the changes that are",
    "start": "2288740",
    "end": "2294559"
  },
  {
    "text": "happening over the course of the day your database is good at midnight right one of the great things about this is",
    "start": "2294559",
    "end": "2300559"
  },
  {
    "text": "you want to test things on your primary database maybe an update you're rolling out some new DDL you want a time how",
    "start": "2300559",
    "end": "2306680"
  },
  {
    "text": "long it's going to take in order to create a new index do it on a clone you're basically doing it on production",
    "start": "2306680",
    "end": "2312609"
  },
  {
    "text": "right without having the overhead of you know restoring from backup right you're just doing it off a clone",
    "start": "2312609",
    "end": "2319100"
  },
  {
    "text": "right and illest",
    "start": "2319100",
    "end": "2324080"
  },
  {
    "start": "2321000",
    "end": "2321000"
  },
  {
    "text": "well it this way you could take an essentially an instant copy of your production database and do whatever you",
    "start": "2325940",
    "end": "2332490"
  },
  {
    "text": "will with it as opposed to having to restore from backup take a snapshot restore from that which will take a long",
    "start": "2332490",
    "end": "2338369"
  },
  {
    "text": "time of duplicating the entire storage with Aurora storage we have intelligent storage good Jim so it's yeah it's it's",
    "start": "2338369",
    "end": "2363000"
  },
  {
    "text": "basically a near-instant copy of your production database and it'll run the",
    "start": "2363000",
    "end": "2368490"
  },
  {
    "text": "same as your practice the same production database so that illustrates that here doing PG bench kind of",
    "start": "2368490",
    "end": "2375090"
  },
  {
    "text": "throttled it at 20,000 TPS right and that's what the that orange line is of",
    "start": "2375090",
    "end": "2381690"
  },
  {
    "text": "doing 20,000 PG bench transactions and then we requested a clone at about 20",
    "start": "2381690",
    "end": "2388109"
  },
  {
    "text": "minutes right and then grant who did this test kind of walked away and didn't",
    "start": "2388109",
    "end": "2393900"
  },
  {
    "text": "keep track of when it actually started but when he came back to his desk he he kicked off the same test on the on the",
    "start": "2393900",
    "end": "2399630"
  },
  {
    "text": "clone about 20 minutes or so later and it's doing exactly the same TPS you",
    "start": "2399630",
    "end": "2406410"
  },
  {
    "text": "start up the same instance ice for that clone it's going to give you the same performance it is essentially your production database is the exact copy",
    "start": "2406410",
    "end": "2412920"
  },
  {
    "text": "that comes back very quickly so going a",
    "start": "2412920",
    "end": "2419880"
  },
  {
    "text": "little deeper on replication right so with logical replication as Kevin mentioned and it is talked before we're",
    "start": "2419880",
    "end": "2426660"
  },
  {
    "start": "2421000",
    "end": "2421000"
  },
  {
    "text": "taking the physical changes in the wall log the transaction log and converting essentially that in the sequel",
    "start": "2426660",
    "end": "2432630"
  },
  {
    "text": "statements right and with that we could you know do a lot of cool things with it",
    "start": "2432630",
    "end": "2438390"
  },
  {
    "text": "there's a lot the logical decoding plug-in right that allows different types of formats is coming out instead",
    "start": "2438390",
    "end": "2444030"
  },
  {
    "text": "of getting out straight insert update delete statements out of your logical you could also get those changes as well",
    "start": "2444030",
    "end": "2450270"
  },
  {
    "text": "as JSON so the where you could process it in different ways a lot of the Postgres drivers like",
    "start": "2450270",
    "end": "2455880"
  },
  {
    "text": "the Python driver the the JDBC driver supports reading the Postgres logical replication stream so you could write it",
    "start": "2455880",
    "end": "2462330"
  },
  {
    "text": "in that and be able to access those your changes and just feeding you directly",
    "start": "2462330",
    "end": "2467400"
  },
  {
    "text": "off that stream by essentially making a JDBC connection so what logical decoding works is by",
    "start": "2467400",
    "end": "2473970"
  },
  {
    "text": "pulling from the main server itself right and then you could take that that",
    "start": "2473970",
    "end": "2479340"
  },
  {
    "text": "application you written in Java or Python and push that into something like Kinesis right or it could go use DMS",
    "start": "2479340",
    "end": "2486780"
  },
  {
    "text": "which uses the same mechanism in order to be able to do that to go to another go to an RDS Postgres instance could go",
    "start": "2486780",
    "end": "2493290"
  },
  {
    "text": "to s3 could go to dynamo right so this way you it's change data capture off of",
    "start": "2493290",
    "end": "2498720"
  },
  {
    "text": "your main database being able to push that wherever you'd like right or out to redshift what a lot of people do you",
    "start": "2498720",
    "end": "2504960"
  },
  {
    "text": "have your main OLTP database running on Aurora you want to go deeper reporting out to a data warehouse running on",
    "start": "2504960",
    "end": "2510420"
  },
  {
    "text": "redshift but one of the nice things in",
    "start": "2510420",
    "end": "2516090"
  },
  {
    "text": "Postgres 10 is the ability to be able to do that without having something else in",
    "start": "2516090",
    "end": "2521250"
  },
  {
    "text": "between right so we had an ec2 instance we had DMS that are sitting there",
    "start": "2521250",
    "end": "2526940"
  },
  {
    "text": "Postgres 10 has a publish/subscribe mechanism so this way Postgres could be",
    "start": "2526940",
    "end": "2532050"
  },
  {
    "text": "able to talk directly out to the the master server and be able to pull it out directly itself so you could have when",
    "start": "2532050",
    "end": "2537990"
  },
  {
    "text": "this is released out into Aurora and it's out in some private previews now",
    "start": "2537990",
    "end": "2543980"
  },
  {
    "text": "you could talk to the guy back in there there in the corner if you want to have access to it the better-looking one what",
    "start": "2543980",
    "end": "2562109"
  },
  {
    "text": "you're able to do is have as your changes are happening in Aurora it could flow out into a community Postgres",
    "start": "2562109",
    "end": "2567390"
  },
  {
    "text": "database maybe it's on-premise maybe it's on ec2 so if you wanted to be able to leverage",
    "start": "2567390",
    "end": "2573930"
  },
  {
    "text": "some of this stuff with Aurora but still have an instance running some PLR or some PL Python you're able to have your",
    "start": "2573930",
    "end": "2579960"
  },
  {
    "text": "main transactions go through there and be able to run some of your reporting through PLR on an ec2 instance because",
    "start": "2579960",
    "end": "2585180"
  },
  {
    "text": "you could subscribe off of the main aurora instances right or it could go out to an",
    "start": "2585180",
    "end": "2591000"
  },
  {
    "text": "RDS post-credits or another Aurora instance right so cross reading the",
    "start": "2591000",
    "end": "2596220"
  },
  {
    "text": "replication question good right yeah",
    "start": "2596220",
    "end": "2622740"
  },
  {
    "text": "that's that's absolutely true so the the folks that originally wrote P geological",
    "start": "2622740",
    "end": "2628770"
  },
  {
    "text": "a company called second quadrant they they pushed that into the community the community didn't take all of you",
    "start": "2628770",
    "end": "2635010"
  },
  {
    "text": "geological they took pieces of it so yeah you could use P geological to be able to do other things like replicating",
    "start": "2635010",
    "end": "2641310"
  },
  {
    "text": "DDL for instance that sequences yeah and sequences so there's other aspects to it",
    "start": "2641310",
    "end": "2647580"
  },
  {
    "text": "and an Aurora or Postgres and RDS both wonderful when our Aurora Postgres supports logical replication it will",
    "start": "2647580",
    "end": "2654210"
  },
  {
    "text": "support things like P geological the way we do with RDS post-crisis",
    "start": "2654210",
    "end": "2659150"
  },
  {
    "text": "yeah that's definitely something we could talk about offline there's some folks here whether it's Kevin or Dennis",
    "start": "2688830",
    "end": "2695920"
  },
  {
    "text": "that back there in a corner about getting involved in in some of the previews of that that Europe will be",
    "start": "2695920",
    "end": "2702040"
  },
  {
    "text": "able to take take a look at and you know the best time like it give you soon right but those folks could give you",
    "start": "2702040",
    "end": "2708940"
  },
  {
    "text": "better timelines out after the fact so cross region replication right so you're",
    "start": "2708940",
    "end": "2716860"
  },
  {
    "start": "2712000",
    "end": "2712000"
  },
  {
    "text": "running on us east you're working for a company that requires a dr plan right so",
    "start": "2716860",
    "end": "2723670"
  },
  {
    "text": "you want to be able to have everything running isn't in another region as well",
    "start": "2723670",
    "end": "2729480"
  },
  {
    "text": "so what cross region replication will do we'll introduce two new things a replication server and a replication",
    "start": "2729480",
    "end": "2736450"
  },
  {
    "text": "agent that's sitting there at the storage level so this way when a transaction comes in right it's going to",
    "start": "2736450",
    "end": "2742540"
  },
  {
    "text": "get pushed out to our storage invalidate the read-only nodes on the same region they're also pushed things out to that",
    "start": "2742540",
    "end": "2748300"
  },
  {
    "text": "replication sir so that replication server will push things out to the other region in the",
    "start": "2748300",
    "end": "2753640"
  },
  {
    "text": "replication ain't engine which will do the same sort of work that the rewrite node and push everything out to or our",
    "start": "2753640",
    "end": "2759730"
  },
  {
    "text": "storage and also invalidate the caches in the read-only nodes in the other region so in the you have the ability to",
    "start": "2759730",
    "end": "2768400"
  },
  {
    "text": "have multiple read-only nodes on that other region so if you want to have things that are closer to your customers",
    "start": "2768400",
    "end": "2774040"
  },
  {
    "text": "of being able to have reporting and other read-only queries running in a different region closer to your customer",
    "start": "2774040",
    "end": "2779110"
  },
  {
    "text": "you get up multiple of those it also in the event that you lose some of the",
    "start": "2779110",
    "end": "2784300"
  },
  {
    "text": "transactions get lost along the way right again Postgres itself doesn't have to do the work to catch it up the",
    "start": "2784300",
    "end": "2790720"
  },
  {
    "text": "replication server all pull things out of aurora storage on the local region and be able to repair that on the the",
    "start": "2790720",
    "end": "2797530"
  },
  {
    "text": "remote region right so this way it doesn't affect your transaction",
    "start": "2797530",
    "end": "2803620"
  },
  {
    "text": "throughput at all so one of the use cases of that is if",
    "start": "2803620",
    "end": "2808840"
  },
  {
    "text": "the region goes down right how do you how does your business survive in the",
    "start": "2808840",
    "end": "2814090"
  },
  {
    "text": "event that a region goes down right you could promote the the other replicate to",
    "start": "2814090",
    "end": "2820330"
  },
  {
    "text": "one of them having a read-only node and this way it will happily reporting your applications at that new new instance",
    "start": "2820330",
    "end": "2827500"
  },
  {
    "text": "and away you go some other customers are using that as we roll out new regions so you're",
    "start": "2827500",
    "end": "2835150"
  },
  {
    "text": "running in US east but if there's a new region that's more advantageous to your customers being able to replicate out to",
    "start": "2835150",
    "end": "2843390"
  },
  {
    "text": "the other region so this way your switch over time is a lot smaller you can replicate it in this way as you have a",
    "start": "2843390",
    "end": "2849100"
  },
  {
    "text": "little bit of down time to wait for things to catch up you're able to do that switch over in a fraction of the",
    "start": "2849100",
    "end": "2854470"
  },
  {
    "text": "time as opposed to reestablishing that new region from a snapshot right so this way as we're adding more and more",
    "start": "2854470",
    "end": "2861130"
  },
  {
    "text": "regions as we're constantly doing right you could take advantage of those of moving to a more advantageous region",
    "start": "2861130",
    "end": "2866800"
  },
  {
    "text": "region for your business so caching we're almost out of time here",
    "start": "2866800",
    "end": "2875070"
  },
  {
    "start": "2875000",
    "end": "2875000"
  },
  {
    "text": "in Postgres you have a when you're",
    "start": "2876600",
    "end": "2881710"
  },
  {
    "text": "talking about RDS Postgres we allocate about 25% for your you're out for Postgres and for the OS and then it's",
    "start": "2881710",
    "end": "2889090"
  },
  {
    "text": "main cache shared buffers we allocate about 25% all right which is kind of standard practice in the Postgres world",
    "start": "2889090",
    "end": "2895810"
  },
  {
    "text": "if you read about that and the rest is for linux page cache right of about 50%",
    "start": "2895810",
    "end": "2901410"
  },
  {
    "text": "right so in the event that you're looking for something it's going to try to pull it out of shared buffers it's",
    "start": "2901410",
    "end": "2906490"
  },
  {
    "text": "not in there it's gonna try to pull it out of the Linux page cache and if it's not in there and then it's gonna pull it",
    "start": "2906490",
    "end": "2911590"
  },
  {
    "text": "back from EBS storage and it's gonna have to go all the way back up the stack again of repopulating that so you get",
    "start": "2911590",
    "end": "2918880"
  },
  {
    "text": "duplicate buffers you get double buffering for that 25 percent that's in shared buffers right with Aurora we have",
    "start": "2918880",
    "end": "2925930"
  },
  {
    "text": "the same 25 percent for the OS and Postgres but we allocate 75% for shared buffers you're not getting that same",
    "start": "2925930",
    "end": "2933010"
  },
  {
    "text": "double buffering because we're writing everything out - Aurora storage not to the local file system right but one of the advantages of of",
    "start": "2933010",
    "end": "2941710"
  },
  {
    "text": "being able to have that Linux page cache is the event that you have to restart",
    "start": "2941710",
    "end": "2947859"
  },
  {
    "text": "Postgres because you change the max connections it doesn't have to it",
    "start": "2947859",
    "end": "2954940"
  },
  {
    "text": "doesn't get rid of that Linux page cache things are still in cache so when you start that backup and you still have a",
    "start": "2954940",
    "end": "2960099"
  },
  {
    "text": "pretty warm cache when you do that in post karora Postgres we didn't have that",
    "start": "2960099",
    "end": "2966160"
  },
  {
    "text": "same benefit so we had to create a new thing called survivable cache so then the event that you have to do a restart",
    "start": "2966160",
    "end": "2972640"
  },
  {
    "text": "or just you restart Postgres your page your shared buffer stays there and your",
    "start": "2972640",
    "end": "2978340"
  },
  {
    "text": "not to repopulate everything all right with that survival cache again trying to",
    "start": "2978340",
    "end": "2984340"
  },
  {
    "text": "speed things up a little bit here you know doing this for you know scale a PG",
    "start": "2984340",
    "end": "2991270"
  },
  {
    "text": "bench of read-only scale of 22,000 right which is a working set of about 350 gig running on an instance with an r4 16",
    "start": "2991270",
    "end": "2999760"
  },
  {
    "text": "Excel which has 488 gig of ram gives us",
    "start": "2999760",
    "end": "3004950"
  },
  {
    "text": "that 75 percent cache is essentially everything's in shared buffers and that gives us in a read-only note 689",
    "start": "3004950",
    "end": "3012599"
  },
  {
    "text": "thousand TPS a lot of transactions that really selects that you're turning",
    "start": "3012599",
    "end": "3018300"
  },
  {
    "text": "through really quickly right when we did that with Postgres with a 25% cache",
    "start": "3018300",
    "end": "3023339"
  },
  {
    "text": "we're getting four hundred seventeen thousand transactions for it's still really impressive numbers but 1.6 times",
    "start": "3023339",
    "end": "3031859"
  },
  {
    "text": "slower right so we were just limited by I ops because it's because of the double",
    "start": "3031859",
    "end": "3038460"
  },
  {
    "text": "buffering not everything was in RAM right so you read some of the good postcards community lists they say will",
    "start": "3038460",
    "end": "3044940"
  },
  {
    "text": "reduce your shared buffer size and use all the Linux page cache when you do that down to 10%",
    "start": "3044940",
    "end": "3050580"
  },
  {
    "text": "it gets even slower it's down to X and that's because it has to do more work of checking shared buffers then checking",
    "start": "3050580",
    "end": "3057060"
  },
  {
    "text": "the Linux page cache to pull everything back out again right so there's no no double buffering there but just to prove",
    "start": "3057060",
    "end": "3063990"
  },
  {
    "text": "that Postgres does about the same when you set that up to about 75% you're",
    "start": "3063990",
    "end": "3069570"
  },
  {
    "text": "doing 682,000 yes which is essentially the same as number so you get that same throughput",
    "start": "3069570",
    "end": "3076239"
  },
  {
    "text": "of pulling everything at Aram there was no no changes in there are Postgres for that particular use case but you don't",
    "start": "3076239",
    "end": "3082749"
  },
  {
    "text": "get that survivable cache go for another",
    "start": "3082749",
    "end": "3090069"
  },
  {
    "start": "3085000",
    "end": "3085000"
  },
  {
    "text": "couple minutes and when I get to the performance section I'm just going to stop because Jim's going to go deeper about that one of the other features is",
    "start": "3090069",
    "end": "3096579"
  },
  {
    "text": "cluster cache management so what what happens what do you do a failover when",
    "start": "3096579",
    "end": "3102549"
  },
  {
    "text": "you want to be able to go to a new a new server whether it's planned or unplanned",
    "start": "3102549",
    "end": "3107910"
  },
  {
    "text": "goes along you're doing a PG bench at 350,000 TPS and then you have that",
    "start": "3107910",
    "end": "3113739"
  },
  {
    "text": "failover at about 600 seconds the RORO Postgres pretty quick to fail over time",
    "start": "3113739",
    "end": "3119229"
  },
  {
    "text": "33 seconds problems when you fail it over you're at a cold cash essentially",
    "start": "3119229",
    "end": "3127140"
  },
  {
    "text": "so this line here is the the p90 so waiting to get back to 90% of what your",
    "start": "3127140",
    "end": "3133239"
  },
  {
    "text": "transaction throughput is in order to get the same cache level right it takes",
    "start": "3133239",
    "end": "3138700"
  },
  {
    "text": "three hundred and forty seconds to get to that same performance number in order to warm that cache back up again what cluster cache management does is it",
    "start": "3138700",
    "end": "3146799"
  },
  {
    "start": "3145000",
    "end": "3145000"
  },
  {
    "text": "takes these different read-only nodes and you assign a priority to it right so priority zero is the highest priority",
    "start": "3146799",
    "end": "3154529"
  },
  {
    "text": "before I fail over target all right so all the old ones are one so this way it'll prefer going to that fell over",
    "start": "3154529",
    "end": "3160779"
  },
  {
    "text": "priority of zero and if you enable that with a PG CCM enabled turn it on what it",
    "start": "3160779",
    "end": "3166599"
  },
  {
    "text": "does is it sends a the the read-only node sends her a bloom filter request of",
    "start": "3166599",
    "end": "3173680"
  },
  {
    "text": "here's everything that's in my in my shared buffers but the readwrite no",
    "start": "3173680",
    "end": "3179109"
  },
  {
    "text": "don't respond back of okay here's all the things that dress is all you have to load right and then it'll go ahead and",
    "start": "3179109",
    "end": "3184930"
  },
  {
    "text": "start loading those things into memory names of shared buffers and eventually it'll be fairly close to what the the",
    "start": "3184930",
    "end": "3191739"
  },
  {
    "text": "master is the net effect of that is when a fellow ver happens any when you have",
    "start": "3191739",
    "end": "3197259"
  },
  {
    "text": "CCM enabled that that 340 seconds now goes down to 32 seconds because that",
    "start": "3197259",
    "end": "3203829"
  },
  {
    "text": "cache is right warm to what that master was with that",
    "start": "3203829",
    "end": "3209230"
  },
  {
    "text": "I'm going to jump past all this and I think that the last thing is the",
    "start": "3209230",
    "end": "3214270"
  },
  {
    "text": "performance and that's all Jim will cover all that and with that questions",
    "start": "3214270",
    "end": "3223660"
  },
  {
    "text": "this is a lot longer talk than 50 minutes thank you",
    "start": "3223660",
    "end": "3232260"
  },
  {
    "text": "[Laughter]",
    "start": "3232260",
    "end": "3236530"
  }
]
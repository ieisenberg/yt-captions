[
  {
    "start": "0",
    "end": "51000"
  },
  {
    "text": "I'm going to kick off the pre day today I'm going to start the first session the",
    "start": "0",
    "end": "5220"
  },
  {
    "text": "Etsy HLC 301 this is basically to do with data science and healthcare",
    "start": "5220",
    "end": "12230"
  },
  {
    "text": "running large-scale data processing workloads on AWS we're going to share",
    "start": "12230",
    "end": "18000"
  },
  {
    "text": "this presentation between the three of us so we'll have our nod from cambia",
    "start": "18000",
    "end": "23070"
  },
  {
    "text": "who's the associate director it can be a join us rich who's the CTO and founder of one",
    "start": "23070",
    "end": "28500"
  },
  {
    "text": "strategy is also going to come in and talk about the implementation details and I'm module Ratan and the Solutions",
    "start": "28500",
    "end": "34170"
  },
  {
    "text": "Architect in AWS with the healthcare and life sciences speciality I'm also the area of depth I",
    "start": "34170",
    "end": "41309"
  },
  {
    "text": "say in the big data group so basically that means is I work at the intersection",
    "start": "41309",
    "end": "47399"
  },
  {
    "text": "of healthcare and life sciences and big data workloads so the way we are going to do this is divide this entire presentation into",
    "start": "47399",
    "end": "53940"
  },
  {
    "start": "51000",
    "end": "51000"
  },
  {
    "text": "three parts and the first part is going to be covered by our Noud he's going to talk about the business problem and what",
    "start": "53940",
    "end": "60930"
  },
  {
    "text": "exactly they were looking to solve rich is then gonna come in and talk about the implementation details so he's",
    "start": "60930",
    "end": "68220"
  },
  {
    "text": "gonna show you demos code snippets tell you how they went about implementing to",
    "start": "68220",
    "end": "73619"
  },
  {
    "text": "solve the business problem that are now laid out and then in the end I'm going",
    "start": "73619",
    "end": "79140"
  },
  {
    "text": "to come in and T up the use case with a machine-learning demo so this demo is going to talk about",
    "start": "79140",
    "end": "86430"
  },
  {
    "text": "a real-world problem of patient readmissions and then we will show how you can solve that by building a very",
    "start": "86430",
    "end": "92520"
  },
  {
    "text": "simple application using Amazon machine learning just to note before we begin this is a deep dice deep dive session so",
    "start": "92520",
    "end": "100259"
  },
  {
    "text": "you're not going to focus on a lot of the what part of the use case you know",
    "start": "100259",
    "end": "106619"
  },
  {
    "text": "what part of the service we are going to focus rather on the how so you want to go deep and show you how you can",
    "start": "106619",
    "end": "113070"
  },
  {
    "text": "implement similar use cases if you want to for that we expect you to have some sort of a familiarity with our services",
    "start": "113070",
    "end": "120180"
  },
  {
    "text": "especially on the Big Data side like EMR s3 if you'd like you can also see some",
    "start": "120180",
    "end": "126090"
  },
  {
    "text": "of our sessions on the architecture track and the big data track that may make sense for more introductory level",
    "start": "126090",
    "end": "133060"
  },
  {
    "text": "service introductions we also expect a little bit of similarity with encryption",
    "start": "133060",
    "end": "138459"
  },
  {
    "text": "and large-scale data processing on distributed systems especially Hadoop and that's going to feature heavily in",
    "start": "138459",
    "end": "145330"
  },
  {
    "text": "our talk especially during the richest section so with that I don't want to",
    "start": "145330",
    "end": "151750"
  },
  {
    "text": "take any more time I just hand it over to Anne now to take us through the first leg of the presentation thanks thank you",
    "start": "151750",
    "end": "158709"
  },
  {
    "text": "well good afternoon everybody my name is Arnaud Tati I'm an assistant",
    "start": "158709",
    "end": "164680"
  },
  {
    "text": "director of cloud and data architecture at cambia Health Solutions and it's a pleasure to be here this afternoon and",
    "start": "164680",
    "end": "169840"
  },
  {
    "text": "talk to you a little bit about what we've done with AWS so cambia Health Solutions we are about a hundred years",
    "start": "169840",
    "end": "177760"
  },
  {
    "start": "172000",
    "end": "172000"
  },
  {
    "text": "old company and our roots lie into the timber industry in the Pacific Northwest",
    "start": "177760",
    "end": "182950"
  },
  {
    "text": "where basically health insurance sort of I got its early start when the timber folks started to figure out that if you",
    "start": "182950",
    "end": "189220"
  },
  {
    "text": "pull your funds it would help you with injuries and illness so from that about",
    "start": "189220",
    "end": "194860"
  },
  {
    "text": "ten years ago we as a company starts to take on a new course which is that we",
    "start": "194860",
    "end": "200739"
  },
  {
    "text": "wanted to transform healthcare which is not a small thing to do we don't like the way things are right now we're",
    "start": "200739",
    "end": "207280"
  },
  {
    "text": "trying to change that as best as we can and today we're we're now a 20 company",
    "start": "207280",
    "end": "213280"
  },
  {
    "text": "organization we're far more than just health insurance and we've spread into the wellness areas as well and we are",
    "start": "213280",
    "end": "220390"
  },
  {
    "text": "really focusing on embracing the cloud and embracing the more modern technology to bring truly personalized and",
    "start": "220390",
    "end": "227889"
  },
  {
    "text": "intuitive health care to the individuals out there so when we started thinking about",
    "start": "227889",
    "end": "235269"
  },
  {
    "start": "232000",
    "end": "232000"
  },
  {
    "text": "lillico aw ask good we want to use that cloud piece to actually get there how do",
    "start": "235269",
    "end": "240459"
  },
  {
    "text": "we go about it what are the first things we're going to do and we said like okay let's take that personalization piece we",
    "start": "240459",
    "end": "245530"
  },
  {
    "text": "need to do master data management we need to figure out in all of our systems where we have records of the same person",
    "start": "245530",
    "end": "251739"
  },
  {
    "text": "but in two different systems maintained in two different ways or three systems or four systems so the master data",
    "start": "251739",
    "end": "257560"
  },
  {
    "text": "management one that's what we want to do we have one on Prem but it doesn't perform well and it doesn't really do as",
    "start": "257560",
    "end": "263050"
  },
  {
    "text": "well as we wanted so that's the one thing that we wanted to focus on then data science in general just what",
    "start": "263050",
    "end": "268400"
  },
  {
    "text": "can we do because getting that power and at the data science",
    "start": "268400",
    "end": "273970"
  },
  {
    "text": "technologically ideally suited for that so we focus also on the data science analytics",
    "start": "274060",
    "end": "280090"
  },
  {
    "text": "obviously that meant that we have to do it securely you're probably all aware HIPAA compliance there's a lot of",
    "start": "280090",
    "end": "285860"
  },
  {
    "text": "regulation pieces that you need to take care of of course we really like the pay-as-you-go part and we really want to",
    "start": "285860",
    "end": "292190"
  },
  {
    "text": "fully leverage that piece because that's the part that really comes into play with large models like the data science",
    "start": "292190",
    "end": "298759"
  },
  {
    "text": "stuff and then performance our on-premise solution for the master data",
    "start": "298759",
    "end": "304220"
  },
  {
    "text": "management was not performing the way we wanted we really want to get it better at that so we focused on the HIPAA",
    "start": "304220",
    "end": "310130"
  },
  {
    "text": "eligible services of course because you're required by the BIA which a lot of you probably have signed we wanted it",
    "start": "310130",
    "end": "316940"
  },
  {
    "text": "to be scalable and we also wanted to get some performance on a delivery side so hey if you've got a managed service we'd",
    "start": "316940",
    "end": "322490"
  },
  {
    "text": "like to make use of that let's work for us we like that so we've had our own",
    "start": "322490",
    "end": "327860"
  },
  {
    "text": "Prem Center and we went out and AWS and of course the first thing that ever always comes to mind - security security",
    "start": "327860",
    "end": "333860"
  },
  {
    "text": "security so we definitely turned on the cloud trail and all those things and if you",
    "start": "333860",
    "end": "339650"
  },
  {
    "text": "want to know more about that on what we do with our crowd trail rogues and such there's a session tomorrow",
    "start": "339650",
    "end": "345050"
  },
  {
    "text": "it's SES SEC 3 or 5 at 12:30 and there's",
    "start": "345050",
    "end": "350509"
  },
  {
    "text": "two repeats of that as def 3:17 where two of our colleagues will actually tell",
    "start": "350509",
    "end": "355550"
  },
  {
    "text": "you exactly on how we deal with our logs in a real-time fashion but what did we do we went for data Lake",
    "start": "355550",
    "end": "363529"
  },
  {
    "text": "so we built our data Lake to get the data there so we could process it for our master data management solution we",
    "start": "363529",
    "end": "371360"
  },
  {
    "text": "pretty much followed the model that was presented last year at we event in BDT three-one-seven session and you can look",
    "start": "371360",
    "end": "378979"
  },
  {
    "text": "it up it's not that different and we used their lambda I'm some III s3 of",
    "start": "378979",
    "end": "386419"
  },
  {
    "text": "course and no for the metadata elasticsearch and dinamo we used EMR for",
    "start": "386419",
    "end": "391699"
  },
  {
    "text": "our master data management and i'll get into more detail on what we achieved there and then we used EMR yet again and",
    "start": "391699",
    "end": "398169"
  },
  {
    "text": "redshift 40 so they designs any analytics so the bond problem that we had was that",
    "start": "398169",
    "end": "405169"
  },
  {
    "text": "EMR was HIPAA eligible but not HIPAA compliant and this was right after the New York summit with the announcement",
    "start": "405169",
    "end": "411050"
  },
  {
    "text": "that EMR was hip eligible there's a lot of work still to be done with that and",
    "start": "411050",
    "end": "416599"
  },
  {
    "text": "we'll talk about a little bit later ritual going to detail and what it meant and of course we have elasticsearch",
    "start": "416599",
    "end": "422030"
  },
  {
    "text": "that's not HIPAA eligible fine for metadata because there's no HIPAA data there but we wanted to use it also for a",
    "start": "422030",
    "end": "427669"
  },
  {
    "text": "HIPAA data and which we'll talk a little bit about that as well so back to that master data management piece so for all",
    "start": "427669",
    "end": "435409"
  },
  {
    "text": "of you in there in the room who know master data management this should be obvious but some of you might not have",
    "start": "435409",
    "end": "441110"
  },
  {
    "text": "know realized yet on what all takes to do masseria management if you look at the left hand side pretty much",
    "start": "441110",
    "end": "447349"
  },
  {
    "text": "everything is a match except for one attribute yet there's still two different people if you look on the",
    "start": "447349",
    "end": "452690"
  },
  {
    "text": "right inside everything is different except for one attribute and it's actually the same person and that sort",
    "start": "452690",
    "end": "459229"
  },
  {
    "text": "of our gives you an illustration of the complexity that goes into the logic to figure out how you line up your master",
    "start": "459229",
    "end": "465469"
  },
  {
    "text": "data and line it up to be the same person or the same organization if that's what you're after so we've got those many many sources",
    "start": "465469",
    "end": "473300"
  },
  {
    "start": "470000",
    "end": "470000"
  },
  {
    "text": "demographics geography lab data claims member files etc and what we",
    "start": "473300",
    "end": "480319"
  },
  {
    "text": "focused on is to build our own homegrown master matching and merging algorithms",
    "start": "480319",
    "end": "485870"
  },
  {
    "text": "to start lining that up and to get to the composite record of the best values",
    "start": "485870",
    "end": "490969"
  },
  {
    "text": "out there because not every record is the best record you might have to pick and choose between them so for that we",
    "start": "490969",
    "end": "498680"
  },
  {
    "text": "built it out we took like a four-person team to data scientists to ETL us and Tony might be in the room I haven't seen",
    "start": "498680",
    "end": "505610"
  },
  {
    "text": "him yet but he was working on that as well and what we did we can look okay so how do we go",
    "start": "505610",
    "end": "512060"
  },
  {
    "start": "510000",
    "end": "510000"
  },
  {
    "text": "about is how do we make sure that we do it right well the most important thing is the quality of your match DQ match",
    "start": "512060",
    "end": "517909"
  },
  {
    "text": "really did two people that should be matched instead of two people who should not be matched so we did a seven",
    "start": "517909",
    "end": "524089"
  },
  {
    "text": "thousand record truth set and we made sure that we check that by hand and in",
    "start": "524089",
    "end": "529459"
  },
  {
    "text": "the real world for the 1600 plus matches that were in there once we had that level truth set to start teaching our",
    "start": "529459",
    "end": "536830"
  },
  {
    "text": "testing our results with we started focusing on the quality and the first one that we did was match correctness",
    "start": "536830",
    "end": "542960"
  },
  {
    "text": "did we truly match to the right person when we looked at their vendor solution the answer was well 98.5 percent of the",
    "start": "542960",
    "end": "551750"
  },
  {
    "text": "time it's pretty high score but for HIPAA compliance means that you cannot use it for certain results because",
    "start": "551750",
    "end": "558080"
  },
  {
    "text": "certain purposes because she still got a lot of gap there when we went for our",
    "start": "558080",
    "end": "563570"
  },
  {
    "text": "first homegrown solution we had 99.9% that was a significant improvement we",
    "start": "563570",
    "end": "569300"
  },
  {
    "text": "were really happy with that then we did two algorithm tweaking and we got a two 99.99 percent and that's where the four",
    "start": "569300",
    "end": "578029"
  },
  {
    "text": "person team on EMR so we were very happy with that some of you in the room might",
    "start": "578029",
    "end": "584029"
  },
  {
    "text": "have already figured out to be all like well hang on I can hit a hundred percent dead easy math that's that's so simple I",
    "start": "584029",
    "end": "589490"
  },
  {
    "text": "just don't match anything and I've got a correctness of an of a sim because I didn't do any wrong matches well okay so",
    "start": "589490",
    "end": "595640"
  },
  {
    "text": "we can't cheat so what do we need else well we need match completeness out of all the matches that are there how many",
    "start": "595640",
    "end": "601460"
  },
  {
    "text": "did you truly find okay that's different from a vendor found 98.8%",
    "start": "601460",
    "end": "608290"
  },
  {
    "text": "our first attempt not so good well that makes sense because we were far more cautious with",
    "start": "608290",
    "end": "614810"
  },
  {
    "text": "our matches we wanted to update correctness so therefore you take less risk risk in your matches therefore you",
    "start": "614810",
    "end": "621920"
  },
  {
    "text": "are going to get lower in your match completeness second iteration",
    "start": "621920",
    "end": "627730"
  },
  {
    "text": "ninety-eight point ten percent and now we really liked where we were this was going like okay we've significantly",
    "start": "627730",
    "end": "633970"
  },
  {
    "text": "increased our correctness and completeness is on par with the vendor",
    "start": "633970",
    "end": "639650"
  },
  {
    "text": "solution but we had that little snack out there still which is performance so",
    "start": "639650",
    "end": "645260"
  },
  {
    "start": "645000",
    "end": "645000"
  },
  {
    "text": "let's talk about performance the one set that we use to test performance was for seventeen point seven million records",
    "start": "645260",
    "end": "650570"
  },
  {
    "text": "and with about eight one point eight matches so for our vendor solution on Prem",
    "start": "650570",
    "end": "656800"
  },
  {
    "text": "the effort run time was about 36 hours to play through that and that's the",
    "start": "656800",
    "end": "662420"
  },
  {
    "text": "efforts run time we had runs well over 50 hours and we at least one run that we",
    "start": "662420",
    "end": "668000"
  },
  {
    "text": "simply just kills because it just was coming on so what did our first own",
    "start": "668000",
    "end": "673670"
  },
  {
    "text": "version run like 19 minutes anymore now I'm guessing a",
    "start": "673670",
    "end": "680120"
  },
  {
    "text": "lot of you gone well how big a cluster was that pretty much the biggest one we could find but that's the beauty I've only got 19",
    "start": "680120",
    "end": "688279"
  },
  {
    "text": "minutes of the biggest cluster and I'm done and that's beautiful aw yes and that's exactly what we also told our",
    "start": "688279",
    "end": "694100"
  },
  {
    "text": "management code like this is why we move to the clouds this is the stuff where we can do we can process is now in 90",
    "start": "694100",
    "end": "699470"
  },
  {
    "text": "minutes then of course we treat your algorithm we didn't tweak it just only to get that correctness up",
    "start": "699470",
    "end": "705910"
  },
  {
    "text": "and completeness up but we also tweaked it for performance and we cut it down on the same cluster size to 14 minutes so",
    "start": "705910",
    "end": "712970"
  },
  {
    "text": "that's the kind of achievement that you can get with Amazon EMR when you go out there and that's the stuff that really",
    "start": "712970",
    "end": "719600"
  },
  {
    "text": "has convinced our management that this is where we should go so what are the next steps that we're looking at well",
    "start": "719600",
    "end": "725899"
  },
  {
    "start": "723000",
    "end": "723000"
  },
  {
    "text": "we're looking at Luca using Amazon machine learning itself to actually figure out what kind of cluster size do",
    "start": "725899",
    "end": "731750"
  },
  {
    "text": "we need to put in there or we put pretty much the biggest one in there but that really hit our sl√• but if our SLA has",
    "start": "731750",
    "end": "738769"
  },
  {
    "text": "more room can we do a smaller cluster would that be cost-efficient can we do that so we wanted if I figure out where",
    "start": "738769",
    "end": "744410"
  },
  {
    "text": "the machine learning can do that for us and whose wall it's gonna talk a little bit more about what else you can do with",
    "start": "744410",
    "end": "749540"
  },
  {
    "text": "machine learning the other thing of course EMR for far more data science models things that you could think about",
    "start": "749540",
    "end": "756500"
  },
  {
    "text": "as well along the lines of do I want to see where there's",
    "start": "756500",
    "end": "761949"
  },
  {
    "text": "overpayments or underpayments or under utilization and those kind of things and how can I help with those kind of things",
    "start": "761949",
    "end": "767540"
  },
  {
    "text": "the other piece that were looking for as I hinted towards we wanted the elastic search because we want to search the",
    "start": "767540",
    "end": "772970"
  },
  {
    "text": "HIPAA data as well and get our benefit from that and that's something we have to do on easy - an elastic search well",
    "start": "772970",
    "end": "779600"
  },
  {
    "text": "the elastic search is not HIPAA compliant at least not the managed service so we have to do something ourselves now these last two things rich",
    "start": "779600",
    "end": "787190"
  },
  {
    "text": "will talk to you about and give you a good detail on how to secure those rich thanks thanks or note once again var",
    "start": "787190",
    "end": "794750"
  },
  {
    "text": "nota round of applause",
    "start": "794750",
    "end": "797470"
  },
  {
    "text": "I wanted to add we're also have some time for questions hopefully at the end we're gonna try and leave some time to",
    "start": "800500",
    "end": "806630"
  },
  {
    "text": "do that we will have a mic but I just wanted to make sure you guys were clear on that our node and and cambia has been",
    "start": "806630",
    "end": "812660"
  },
  {
    "text": "awesome to work with my name is rich jewel I am the founder and CTO of a",
    "start": "812660",
    "end": "817970"
  },
  {
    "text": "company named one strategy we focus on Amazon Web Services that's our specialty",
    "start": "817970",
    "end": "823130"
  },
  {
    "text": "and that's exclusively what we do and all we do we also focus in healthcare as",
    "start": "823130",
    "end": "828920"
  },
  {
    "text": "well as big data [Music] we are here presenting and happy to be",
    "start": "828920",
    "end": "833959"
  },
  {
    "text": "participating we'd love for you guys to stop by our booth number 408 come pick up a cloud t-shirt and and and talk to",
    "start": "833959",
    "end": "842870"
  },
  {
    "text": "us a bit before we start to deep into the technical details I want to go through a",
    "start": "842870",
    "end": "848480"
  },
  {
    "start": "845000",
    "end": "845000"
  },
  {
    "text": "couple of definition of terms we're gonna be talking about data at various stages first we're going to talk about",
    "start": "848480",
    "end": "854569"
  },
  {
    "text": "data at rest and when I'm speaking about data at rest I want to be clear we're speaking about data as it's sitting inside of a storage state we'll talk",
    "start": "854569",
    "end": "862189"
  },
  {
    "text": "about data in transit which specifically is about data as it's being moved from storage into a processing node and then",
    "start": "862189",
    "end": "868189"
  },
  {
    "text": "third we'll talk about it while it's in process data that's temporary space so cambia came to us with this and said",
    "start": "868189",
    "end": "875750"
  },
  {
    "text": "hey we want to build this we need some help doing it I think they reached out to us at one strategy and said we need",
    "start": "875750",
    "end": "882319"
  },
  {
    "text": "the details of moving beyond HIPAA from a HIPAA eligible service to a HIPAA compliant service is that something you",
    "start": "882319",
    "end": "888560"
  },
  {
    "text": "can help us with we worked with them and Amazon Web Services to make sure that the services",
    "start": "888560",
    "end": "894860"
  },
  {
    "text": "that we deployed and the automation scripts and configuration that we built for them moved beyond HIPAA eligible",
    "start": "894860",
    "end": "901250"
  },
  {
    "text": "into HIPAA compliant for example we'll talk a little bit about some of the work we did on elasticsearch which is still not listed",
    "start": "901250",
    "end": "908180"
  },
  {
    "text": "on the HIPAA eligible services but they are using it for their healthcare workloads",
    "start": "908180",
    "end": "913870"
  },
  {
    "text": "in a in a compliant manner the heart of this presentation really",
    "start": "913870",
    "end": "919189"
  },
  {
    "start": "914000",
    "end": "914000"
  },
  {
    "text": "comes down to keys and encryption we use the AWS kms service or the key",
    "start": "919189",
    "end": "925519"
  },
  {
    "text": "management service we used it for a variety of different things and I'm talk through the ways in which we used it but",
    "start": "925519",
    "end": "931759"
  },
  {
    "text": "I want to be clear that keys and encryption is the heart of everything that we're doing in this workload as we",
    "start": "931759",
    "end": "937339"
  },
  {
    "text": "talk through this as we look at encryption and rest there's really two areas that we needed",
    "start": "937339",
    "end": "944269"
  },
  {
    "text": "to cover for elastic MapReduce or EMR the first one was the data stored in s3",
    "start": "944269",
    "end": "950389"
  },
  {
    "text": "or their data Lake in order to make sure that we did this we had to go through and make sure the the data that was",
    "start": "950389",
    "end": "956480"
  },
  {
    "text": "stored there was encrypted as well as the configuration files the bucket policies all those things made sure that",
    "start": "956480",
    "end": "961610"
  },
  {
    "text": "they were actually encrypting the data that was stored inside of that data Lake the second part was the Hadoop file",
    "start": "961610",
    "end": "968509"
  },
  {
    "text": "system that runs on the EMR cluster and we'll talk through the ways in which we enforced or made these things move from",
    "start": "968509",
    "end": "975889"
  },
  {
    "text": "eligible to compliance the first one is EMR FS on s3 we started",
    "start": "975889",
    "end": "984199"
  },
  {
    "text": "with an empty bucket turn on some bucket policies and there's a sample configuration of what that bucket policy",
    "start": "984199",
    "end": "989990"
  },
  {
    "text": "looks like you can see in here we're essentially denying the ability to put objects unless they're encrypted so you",
    "start": "989990",
    "end": "996769"
  },
  {
    "text": "won't be able to actually write data into this s3 bucket unless the data has encryption turned on so that's the first",
    "start": "996769",
    "end": "1002889"
  },
  {
    "text": "gate in which we put out the second part comes down to the HDFS",
    "start": "1002889",
    "end": "1009130"
  },
  {
    "text": "on the EMR cluster to do this we actually use the native Hadoop technologies that are built into EMR we",
    "start": "1009130",
    "end": "1018160"
  },
  {
    "text": "use the data encryption key and the envelope data encryption key but instead of using AWS as kms we use the Hadoop",
    "start": "1018160",
    "end": "1024909"
  },
  {
    "text": "kms as it's built into the system this was done using a bootstrap script",
    "start": "1024909",
    "end": "1030298"
  },
  {
    "text": "as the nodes were provisioned a couple of the key properties and values you can",
    "start": "1030299",
    "end": "1035558"
  },
  {
    "text": "see here outlined essentially make sure that when we enable that DFS encryption",
    "start": "1035559",
    "end": "1041130"
  },
  {
    "text": "we've specified some details about it so we go into the details of the configuration file and make sure that",
    "start": "1041130",
    "end": "1046720"
  },
  {
    "text": "every area in which there was encryption or an option for encryption we turn that on making sure that the system stored",
    "start": "1046720",
    "end": "1053140"
  },
  {
    "text": "any of its data on HDFS encrypted",
    "start": "1053140",
    "end": "1058470"
  },
  {
    "start": "1058000",
    "end": "1058000"
  },
  {
    "text": "those are the two parts the two parts that we covered and worked on for Justin at rest as we move into encryption in",
    "start": "1058470",
    "end": "1066220"
  },
  {
    "text": "transit we're going to talk specifically about the data as it's moved from s3",
    "start": "1066220",
    "end": "1071790"
  },
  {
    "text": "into EMR cluster as one of these so for encryption in transit the heart comes",
    "start": "1071790",
    "end": "1076990"
  },
  {
    "text": "down to SSL and making sure that the communication channels are encrypted making sure we're using SSL for all of",
    "start": "1076990",
    "end": "1083890"
  },
  {
    "text": "the communication traffic to start with this we use some configuration files in which you can see",
    "start": "1083890",
    "end": "1090250"
  },
  {
    "text": "here a couple of examples where we're enabling the client key store as well as that trust location and a",
    "start": "1090250",
    "end": "1096820"
  },
  {
    "text": "couple of other parameters so we dive into a little bit more of the details of this we're gonna look",
    "start": "1096820",
    "end": "1102850"
  },
  {
    "start": "1099000",
    "end": "1099000"
  },
  {
    "text": "specifically at the encryption in transit inside of the EMR cluster so not just for data going to and from s3 but",
    "start": "1102850",
    "end": "1109780"
  },
  {
    "text": "inside of the EMR cluster itself to do that specifically you have to enable",
    "start": "1109780",
    "end": "1115030"
  },
  {
    "text": "encryption for communications for RPC or client type connectivity this could be things like hive or Pig",
    "start": "1115030",
    "end": "1122410"
  },
  {
    "text": "for example not to do this we used configuration files",
    "start": "1122410",
    "end": "1130200"
  },
  {
    "text": "for example this one you can see that we're enabling Hadoop RPC protection and setting the level to authentication so",
    "start": "1130200",
    "end": "1136840"
  },
  {
    "text": "that any of the communication to and from these to this Hadoop cluster over RPC is encrypted",
    "start": "1136840",
    "end": "1144809"
  },
  {
    "text": "the next part that we need to take care of is encryption between the nodes so as",
    "start": "1144809",
    "end": "1150370"
  },
  {
    "text": "an EMR cluster communicates one with with each other in the various nodes we need to make sure that all of the",
    "start": "1150370",
    "end": "1156010"
  },
  {
    "text": "communication traffic is transmitted in an encrypted manner in order to do that again we're just using the data",
    "start": "1156010",
    "end": "1162309"
  },
  {
    "text": "encryption key and envelope data encryption key as well as the Hadoop kms this is this turned on with the data",
    "start": "1162309",
    "end": "1169300"
  },
  {
    "text": "transfer protocol enables this for all of these notes to communicate one with another over encrypted channels making",
    "start": "1169300",
    "end": "1175420"
  },
  {
    "text": "sure that if the data for example was being watched it would be encrypted it's secure",
    "start": "1175420",
    "end": "1183240"
  },
  {
    "text": "this is again done through a configuration file which I'm showing a sample of and some of the sample",
    "start": "1183240",
    "end": "1188740"
  },
  {
    "text": "parameters in here but you can see you turn on the DFS encrypt data transfer to true a lot of these things aren't super",
    "start": "1188740",
    "end": "1195429"
  },
  {
    "text": "complex but they require on knowledge of these systems and how they work and that's one of the areas in which we specialize at one strategy",
    "start": "1195429",
    "end": "1203759"
  },
  {
    "text": "so let's move on as an EMR cluster communicates and as its processing",
    "start": "1204809",
    "end": "1211419"
  },
  {
    "text": "there's a process called the shuffle and sort and this is where Hadoop determines",
    "start": "1211419",
    "end": "1217000"
  },
  {
    "text": "which nodes are going to do which processing which workloads are going to be distributed to which nodes this",
    "start": "1217000",
    "end": "1222279"
  },
  {
    "text": "communication also has to be encrypted this MapReduce shuffle is one of these",
    "start": "1222279",
    "end": "1227679"
  },
  {
    "text": "areas in which we needed to make sure was also in the HIPAA moving from HIPAA eligibility into compliance",
    "start": "1227679",
    "end": "1233850"
  },
  {
    "text": "we did this through the MapReduce shuffle SSL enabled equals true in some of these configuration files this is",
    "start": "1233850",
    "end": "1240760"
  },
  {
    "text": "something that's we we focused on and is still not available in some of the",
    "start": "1240760",
    "end": "1245769"
  },
  {
    "text": "updates that I'm going to talk about in just a few minutes but this is an extra value out of going into these details of",
    "start": "1245769",
    "end": "1251470"
  },
  {
    "text": "the service and configuration that one strategy focused on with with cambia",
    "start": "1251470",
    "end": "1256620"
  },
  {
    "text": "ok another part that cambia needed and this was specific to the way in which",
    "start": "1256620",
    "end": "1262690"
  },
  {
    "text": "they're using EMR was SPARC made a big bet on SPARC and using SPARC throughout their system again this isn't something",
    "start": "1262690",
    "end": "1269649"
  },
  {
    "text": "that's covered through that service that I'm going to talk about in just a minute with AWS but we worked with them to make",
    "start": "1269649",
    "end": "1276909"
  },
  {
    "text": "sure that the SPARC encryption was turned on",
    "start": "1276909",
    "end": "1282870"
  },
  {
    "start": "1283000",
    "end": "1283000"
  },
  {
    "text": "for encryption and process remember we're talking about data as its processed temporary files log files",
    "start": "1283919",
    "end": "1290350"
  },
  {
    "text": "those types of things in order to do this we use the standard Linux unified",
    "start": "1290350",
    "end": "1295659"
  },
  {
    "text": "key setup for the EMR nodes we encrypted the volumes on EBS on any of the storage",
    "start": "1295659",
    "end": "1303039"
  },
  {
    "text": "space that's temporary we use temporary keys and the reason that we chose temporary keys was for a very specific",
    "start": "1303039",
    "end": "1309340"
  },
  {
    "text": "reason temporary space is exactly that temporary it should never be used for",
    "start": "1309340",
    "end": "1314440"
  },
  {
    "text": "anything else and if the data's lost it shouldn't be a big deal to the business so in order to make sure that we were",
    "start": "1314440",
    "end": "1320470"
  },
  {
    "text": "meeting that security and compliance requirement we actually use disposable keys keys that would never be reused and",
    "start": "1320470",
    "end": "1325929"
  },
  {
    "text": "that we didn't keep around so that if the EMR node or something is terminated all the data and that would be lost for",
    "start": "1325929",
    "end": "1332410"
  },
  {
    "text": "that temporary space and that was designed or desired we did this and this is again a sample",
    "start": "1332410",
    "end": "1339460"
  },
  {
    "text": "of this bootstrap script so at the time in which these EMR nodes are provisioned every single node runs this",
    "start": "1339460",
    "end": "1344530"
  },
  {
    "text": "configuration in these bootstrap scripts which then configures this Linux unified key setup on each of these individual",
    "start": "1344530",
    "end": "1350680"
  },
  {
    "text": "nodes and the space and the storage for them to summarize you can see the way in",
    "start": "1350680",
    "end": "1357820"
  },
  {
    "start": "1354000",
    "end": "1354000"
  },
  {
    "text": "which we work to make HIPAA eligible become HIPAA compliant for",
    "start": "1357820",
    "end": "1362950"
  },
  {
    "text": "cambia you can see how we've covered the data at rest data in transit and in",
    "start": "1362950",
    "end": "1369070"
  },
  {
    "text": "process again with all of the communications to and from the EMR cluster",
    "start": "1369070",
    "end": "1374700"
  },
  {
    "text": "there were some EMR updates that I alluded to earlier they're released on September 21st of 2016 now as you look",
    "start": "1374700",
    "end": "1383740"
  },
  {
    "text": "at these updates you need to understand that there's not an exact feature parity between what it is that we worked with",
    "start": "1383740",
    "end": "1388990"
  },
  {
    "text": "for cambia and what actually is inside of these updates there's a link to that",
    "start": "1388990",
    "end": "1394360"
  },
  {
    "text": "blog article with some details on that as well as a link to the original article that shows the details about",
    "start": "1394360",
    "end": "1399760"
  },
  {
    "text": "these updates and how they play into the work that we've done I'm going to summarize it very quickly for you but",
    "start": "1399760",
    "end": "1405790"
  },
  {
    "start": "1403000",
    "end": "1403000"
  },
  {
    "text": "there was a security configurations option that was added to EMR in the security configurations option there was",
    "start": "1405790",
    "end": "1412390"
  },
  {
    "text": "a couple of things that enabled you to cover some of these elements and I've highlighted them here for you you can",
    "start": "1412390",
    "end": "1418030"
  },
  {
    "text": "see for data at rest you essentially say I want to require server-side encryption on s3 for",
    "start": "1418030",
    "end": "1424440"
  },
  {
    "text": "local disk encryption you then specify I want to use local disk encryption and here's the key in AWS is kms that I want",
    "start": "1424440",
    "end": "1432280"
  },
  {
    "text": "to use for your in transit you've also got the area to specify a TLS key which is used",
    "start": "1432280",
    "end": "1438550"
  },
  {
    "text": "for the encryption in transit or between the nodes and then in process with that",
    "start": "1438550",
    "end": "1443650"
  },
  {
    "text": "KMS key once you've created a security configuration at the time in which you",
    "start": "1443650",
    "end": "1449380"
  },
  {
    "text": "provision a new AMR cluster you get an option that says which security security",
    "start": "1449380",
    "end": "1454600"
  },
  {
    "text": "configuration would you like to use you specify that security configuration which has those options that are",
    "start": "1454600",
    "end": "1460390"
  },
  {
    "text": "outlined on that previous screen and then you provision that new our cluster",
    "start": "1460390",
    "end": "1465890"
  },
  {
    "text": "one of the services that cambia needed and still uses and needs today is",
    "start": "1467090",
    "end": "1473270"
  },
  {
    "text": "elasticsearch but as our node mentioned elasticsearch is not HIPAA eligible as it's managed by",
    "start": "1473270",
    "end": "1481020"
  },
  {
    "text": "AWS we worked with them to identify their needs and did the same process for",
    "start": "1481020",
    "end": "1486720"
  },
  {
    "text": "elasticsearch we created some provisioning scripts that provision all of the elasticsearch nodes they install",
    "start": "1486720",
    "end": "1493620"
  },
  {
    "text": "the elastic search service they set up the Linux Unified key setup for the temporary space we install and configure",
    "start": "1493620",
    "end": "1499770"
  },
  {
    "text": "a product that is an add-on that was formerly known as shield but is now known as security that then covered the",
    "start": "1499770",
    "end": "1506310"
  },
  {
    "text": "security encryption between these elastic search nodes as well as we use the temporary space which is essentially",
    "start": "1506310",
    "end": "1512850"
  },
  {
    "text": "what all of elastic search is we use the same process with that Linux Unified key",
    "start": "1512850",
    "end": "1518100"
  },
  {
    "text": "setup as you look at kind of the solution for",
    "start": "1518100",
    "end": "1524310"
  },
  {
    "start": "1521000",
    "end": "1521000"
  },
  {
    "text": "this one again the value ID comes into us working with cambia and other organizations in the healthcare space to",
    "start": "1524310",
    "end": "1531000"
  },
  {
    "text": "make sure that we were meeting this requirement to move them out of the space of a HIPAA eligible service to a HIPAA compliant service and that's kind",
    "start": "1531000",
    "end": "1539070"
  },
  {
    "text": "of that value add one of the areas that I didn't mention but I want to make sure to call out is that shuffling sort",
    "start": "1539070",
    "end": "1545640"
  },
  {
    "text": "process to date is not currently included in the HIPAA updates that I talked about from that September 21st",
    "start": "1545640",
    "end": "1552380"
  },
  {
    "text": "neither and so that's one of the areas in which you need to make sure that you're aware",
    "start": "1552380",
    "end": "1558030"
  },
  {
    "start": "1557000",
    "end": "1557000"
  },
  {
    "text": "of as well a key point that I need to stress and I",
    "start": "1558030",
    "end": "1563490"
  },
  {
    "text": "want you to when you leave this I don't want you to just think because I focused heavily on encryption I don't want you to think oh if it's encrypted it's HIPAA",
    "start": "1563490",
    "end": "1570930"
  },
  {
    "text": "compliant there's actually a lot more that goes into HIPAA compliance and eligibility and a lot of that comes down",
    "start": "1570930",
    "end": "1577440"
  },
  {
    "text": "to tools one of the tools that after we had gone through this work cambia came to us and",
    "start": "1577440",
    "end": "1582930"
  },
  {
    "text": "said we need a tool to be able to audit the data sitting in our data leak we need to be able to see who has access to",
    "start": "1582930",
    "end": "1588810"
  },
  {
    "text": "the data that's stored in our data like what permissions do they have for the data that's stored in our data Lake what",
    "start": "1588810",
    "end": "1594390"
  },
  {
    "text": "are the abilities of the users who have this access to this data and what can they do with it what are the roles and",
    "start": "1594390",
    "end": "1599960"
  },
  {
    "text": "permissions that are associated we work to create some automation and some tool sets for that we created one",
    "start": "1599960",
    "end": "1606410"
  },
  {
    "text": "that actually shows that the s3 data in sitting inside of a bucket is actually encrypted as well as some of these tools",
    "start": "1606410",
    "end": "1613880"
  },
  {
    "text": "we're currently working with Tamia we've open sourced a couple of these tools which there's a link to a blog and some",
    "start": "1613880",
    "end": "1620450"
  },
  {
    "text": "code that actually has a couple of these tools out there but I'm gonna walk through and give you a demo of that very quickly",
    "start": "1620450",
    "end": "1625990"
  },
  {
    "text": "in this demo we've got essentially this first process",
    "start": "1625990",
    "end": "1631190"
  },
  {
    "text": "I'm gonna kick off which is going to show us the compliance information we're gonna go through and on a bucket we're gonna enumerate all of the IM users the",
    "start": "1631190",
    "end": "1639170"
  },
  {
    "text": "groups and the roles essentially all of the people that could potentially have access permissions to this s3 data link",
    "start": "1639170",
    "end": "1644540"
  },
  {
    "text": "as we go through this I'm gonna get an output or a port in JSON format that",
    "start": "1644540",
    "end": "1649850"
  },
  {
    "text": "shows what users have access to which objects sitting in the data Lake and what their permissions are specifically",
    "start": "1649850",
    "end": "1656300"
  },
  {
    "text": "going into details this can be run on a regular basis to determine over time",
    "start": "1656300",
    "end": "1661880"
  },
  {
    "text": "what permissions are changing in the environment right this isn't something that other services like AWS config in",
    "start": "1661880",
    "end": "1667340"
  },
  {
    "text": "these other areas cover today but you can see the output of this going through showing the paths the objects the",
    "start": "1667340",
    "end": "1673610"
  },
  {
    "text": "statements specifically all of the permissions that are allowed on these objects moving you out of that space",
    "start": "1673610",
    "end": "1679700"
  },
  {
    "text": "into you know monitoring and auditing the services the next part that we're",
    "start": "1679700",
    "end": "1685250"
  },
  {
    "text": "gonna show is an encrypted bucket so we want to look at the objects in this bucket I'm going to enumerate them and I",
    "start": "1685250",
    "end": "1691400"
  },
  {
    "text": "want to make sure that they're encrypted is the data that I stored in there encrypted in my data Lake as we",
    "start": "1691400",
    "end": "1696980"
  },
  {
    "text": "enumerate these files we can see that encryption is turned on we can see the level of encryption and the details",
    "start": "1696980",
    "end": "1702860"
  },
  {
    "text": "about that file the last part is we're just going to simply enumerate or look inside of one",
    "start": "1702860",
    "end": "1708260"
  },
  {
    "text": "of these files and see that the data is encrypted that the data",
    "start": "1708260",
    "end": "1713360"
  },
  {
    "text": "is not actually sitting out there in plain text and if a person without permissions were to come back to it they",
    "start": "1713360",
    "end": "1718580"
  },
  {
    "text": "wouldn't have access to the data that's stored inside of that data Lake we're gonna move on and talk a little",
    "start": "1718580",
    "end": "1724460"
  },
  {
    "text": "bit more about how machine learning plays into this ecosystem that we've worked with cambia to build and to do so",
    "start": "1724460",
    "end": "1729770"
  },
  {
    "text": "we're going huge wall join us on stage and tell us a little bit more about that thank you thanks rich",
    "start": "1729770",
    "end": "1737590"
  },
  {
    "text": "Thanks so you heard the rich speak about how retrospective analysis was built for",
    "start": "1740530",
    "end": "1746809"
  },
  {
    "text": "large-scale data sets on AWS now that is great if you're looking at crunching huge data sets and then processing it at",
    "start": "1746809",
    "end": "1755270"
  },
  {
    "text": "scale but what if you want to extend this use case Sheen learning that's the",
    "start": "1755270",
    "end": "1760760"
  },
  {
    "text": "next logical step that one should pursue because they've got this huge repository",
    "start": "1760760",
    "end": "1766610"
  },
  {
    "text": "of data that they got from this exercise and machine learning model actually",
    "start": "1766610",
    "end": "1772159"
  },
  {
    "text": "expects you know nice data sets because it makes for accurate predictions",
    "start": "1772159",
    "end": "1777730"
  },
  {
    "text": "so there are multiple use cases that we can talk about in machine learning today especially in the healthcare space",
    "start": "1777730",
    "end": "1784429"
  },
  {
    "start": "1779000",
    "end": "1779000"
  },
  {
    "text": "you've got predictive analytics that you can use to predict hospital bed",
    "start": "1784429",
    "end": "1790130"
  },
  {
    "text": "utilizations for example you know you can do text classification mining for",
    "start": "1790130",
    "end": "1795230"
  },
  {
    "text": "prescriptions you can do medical image analysis all of these play heavily into",
    "start": "1795230",
    "end": "1801500"
  },
  {
    "text": "machine learning algorithms but what I'm going to talk about to you today is",
    "start": "1801500",
    "end": "1806710"
  },
  {
    "text": "patient readmission prediction and basically try and stratify patients based on their risk profile to see",
    "start": "1806710",
    "end": "1814070"
  },
  {
    "text": "whether they are more at risk to come back to the hospital within 30 days which is what readmissions is so let's",
    "start": "1814070",
    "end": "1823190"
  },
  {
    "start": "1823000",
    "end": "1823000"
  },
  {
    "text": "talk about the real world problem first before we like go into the implementation side of things it's part",
    "start": "1823190",
    "end": "1828770"
  },
  {
    "text": "of the hospital readmission prediction program it's part of the Affordable Care Act basically if a patient goes into the",
    "start": "1828770",
    "end": "1835429"
  },
  {
    "text": "hospital and gets admitted with the condition and is then discharged and",
    "start": "1835429",
    "end": "1840890"
  },
  {
    "text": "comes back to the hospital with the same condition within 30 days and counted as a readmission and what we are trying to",
    "start": "1840890",
    "end": "1847700"
  },
  {
    "text": "solve here is you know try and predict which patients are more likely to do so",
    "start": "1847700",
    "end": "1852830"
  },
  {
    "text": "and machine learning actually plays perfectly in this use case because every patient who comes back with historical",
    "start": "1852830",
    "end": "1859220"
  },
  {
    "text": "data displays a pattern and whenever we have a pattern to play with it can be used to predict a target",
    "start": "1859220",
    "end": "1866300"
  },
  {
    "text": "attribute which I'm going to talk about in the next few slides so to build a machine learning model in",
    "start": "1866300",
    "end": "1873110"
  },
  {
    "start": "1871000",
    "end": "1871000"
  },
  {
    "text": "AWS you have two options right now you can run those algorithms on your own you",
    "start": "1873110",
    "end": "1878120"
  },
  {
    "text": "can use an EMR service as rich explained and then you SPARC ml which is again",
    "start": "1878120",
    "end": "1884600"
  },
  {
    "text": "SPARC is natively supported on EMR so you can use a class you know just check box an option and then Spock will come",
    "start": "1884600",
    "end": "1891290"
  },
  {
    "text": "pre-installed you can use you know use that for you know based on what SPARC ml",
    "start": "1891290",
    "end": "1897320"
  },
  {
    "text": "provides you have multiple comprehensive up options for running those algorithms",
    "start": "1897320",
    "end": "1903070"
  },
  {
    "text": "you know the only downside there is obviously as with any build your own",
    "start": "1903070",
    "end": "1908440"
  },
  {
    "text": "application you you'll have to do more work to train it there's no support for",
    "start": "1908440",
    "end": "1913700"
  },
  {
    "text": "evaluation and then of course C ICD you know if you want to build a deployment",
    "start": "1913700",
    "end": "1919340"
  },
  {
    "text": "pipeline which actually deploys model and a continuous pipeline that becomes a problem you solve some of this you can",
    "start": "1919340",
    "end": "1926480"
  },
  {
    "text": "go with the managed service the Amazon machine learning service that actually provides you three algorithms that you",
    "start": "1926480",
    "end": "1932840"
  },
  {
    "text": "can play with the binary classification predicts between the state of 0 & 1 or",
    "start": "1932840",
    "end": "1938450"
  },
  {
    "text": "yes and no you can use the multi-class classification to predict the category",
    "start": "1938450",
    "end": "1944920"
  },
  {
    "text": "and then you have regression that predicts a number it's only three",
    "start": "1944920",
    "end": "1950630"
  },
  {
    "text": "algorithms but as you can imagine most of your use cases would actually fall into either of these your you know most",
    "start": "1950630",
    "end": "1956810"
  },
  {
    "text": "of the time trying to predict either a number you know thinking about let's say how much likely is it gonna rain",
    "start": "1956810",
    "end": "1963440"
  },
  {
    "text": "tomorrow right that's a percentage for which you can use a regression or just one example it's really simple to train easy to",
    "start": "1963440",
    "end": "1971060"
  },
  {
    "text": "evaluate and quick to deploy and it's targeted towards developers and this is what our focus is going to be today I'm",
    "start": "1971060",
    "end": "1977960"
  },
  {
    "text": "not going to go into spark ml and how you can write spark ml code but I'm rather going to show you how managed",
    "start": "1977960",
    "end": "1984290"
  },
  {
    "text": "service are managed service rather the Amazon machine learning service helps you build these really quickly and then",
    "start": "1984290",
    "end": "1990800"
  },
  {
    "text": "it's so easy to deploy just to introduce the service a little",
    "start": "1990800",
    "end": "1996350"
  },
  {
    "start": "1994000",
    "end": "1994000"
  },
  {
    "text": "bit it's very easy as I said it's targeted towards the developers so we don't",
    "start": "1996350",
    "end": "2003250"
  },
  {
    "text": "expect that you have a prerequisite knowledge of data science if you want to use this it's all API based and you know",
    "start": "2003250",
    "end": "2009820"
  },
  {
    "text": "can be operated from the console which is really great and you can deploy the model since to",
    "start": "2009820",
    "end": "2017080"
  },
  {
    "text": "production in seconds so you know you don't have to worry about retraining the model reevaluating it making sure that",
    "start": "2017080",
    "end": "2023169"
  },
  {
    "text": "everything is right you know if we take care of that behind the scenes as part",
    "start": "2023169",
    "end": "2028990"
  },
  {
    "text": "of the managed service so what are we trying to do here coming back to the use case what we are trying",
    "start": "2028990",
    "end": "2035590"
  },
  {
    "start": "2031000",
    "end": "2031000"
  },
  {
    "text": "to do is basically take a patient extract all his attributes so we talk",
    "start": "2035590",
    "end": "2042850"
  },
  {
    "text": "about patient demographics their history admission attributes and you know any",
    "start": "2042850",
    "end": "2048550"
  },
  {
    "text": "other feature that's relevant to the patient and do some magic and then what we want to do is put that patient as a",
    "start": "2048550",
    "end": "2056648"
  },
  {
    "text": "high-risk patient moderate kritis patient or a low-risk patient these attributes as you would imagine",
    "start": "2056649",
    "end": "2063849"
  },
  {
    "text": "are totally unrelated so simple analytics will won't will not work here because you know simple analytics",
    "start": "2063849",
    "end": "2069940"
  },
  {
    "text": "essentially relies on datasets that's already there which you can then crunch",
    "start": "2069940",
    "end": "2075010"
  },
  {
    "text": "and build your metrics on but this is more of predictive analytics things that have not happened and that's why you",
    "start": "2075010",
    "end": "2082510"
  },
  {
    "text": "know this is not magic there's machine learning that's actually enabling you to do this and",
    "start": "2082510",
    "end": "2087898"
  },
  {
    "text": "to build this use case I'm going to use a five step process I'm gonna do the rest of the presentation take you",
    "start": "2087899",
    "end": "2094210"
  },
  {
    "start": "2088000",
    "end": "2088000"
  },
  {
    "text": "through all these five steps first we are getting the data set into s3 and then I'm using Amazon redshift which is",
    "start": "2094210",
    "end": "2101650"
  },
  {
    "text": "a data warehouse to to standardize that data that's really important because if",
    "start": "2101650",
    "end": "2106690"
  },
  {
    "text": "you put in you know wrong data sets and give the wrong signals to your model you",
    "start": "2106690",
    "end": "2112089"
  },
  {
    "text": "really won't get the accurate results so it's very important that you feed in the right data sets the complete data sets",
    "start": "2112089",
    "end": "2118020"
  },
  {
    "text": "and inside the machine learning model then you know basically I'm creating a",
    "start": "2118020",
    "end": "2124030"
  },
  {
    "text": "data source with redshift as my storage and then I'm building machine learning",
    "start": "2124030",
    "end": "2129559"
  },
  {
    "text": "model on it the machine learning service actually allows you to do two kinds of",
    "start": "2129559",
    "end": "2135049"
  },
  {
    "text": "predictions you can either go with a batch prediction what that does is basically queries the machine learning",
    "start": "2135049",
    "end": "2141410"
  },
  {
    "text": "model with a set of data that you upload and then generate a prediction a prediction batch that goes and you know",
    "start": "2141410",
    "end": "2148250"
  },
  {
    "text": "uploads into s3 and then what you can do is use that static data sets to build",
    "start": "2148250",
    "end": "2153319"
  },
  {
    "text": "you know analytics reports for example actual versus predictive values the other thing that's really great is it",
    "start": "2153319",
    "end": "2160339"
  },
  {
    "text": "also allows you to do real-time predictions what that means is basically you can enable an endpoint which I'm",
    "start": "2160339",
    "end": "2166279"
  },
  {
    "text": "going to show you and that endpoint can be queried through api's for real-time predictions so what I am building here",
    "start": "2166279",
    "end": "2172700"
  },
  {
    "text": "is a static website that calls that endpoint through an API call and then I'm using",
    "start": "2172700",
    "end": "2178430"
  },
  {
    "text": "kognito to federate the access because I don't want to embed my AWS keys inside",
    "start": "2178430",
    "end": "2183529"
  },
  {
    "text": "my code so you can use kognito to make sure you have federated access to that endpoint",
    "start": "2183529",
    "end": "2189220"
  },
  {
    "start": "2189000",
    "end": "2189000"
  },
  {
    "text": "the data set that I use for this is from university of Irvine it's called about one hundred and two",
    "start": "2189220",
    "end": "2195799"
  },
  {
    "text": "thousand rows which is by no means enough to give you an accurate predictive model what you need to do is",
    "start": "2195799",
    "end": "2203359"
  },
  {
    "text": "strain it with much more which is a very rigorous process but what you need to take away from this session is",
    "start": "2203359",
    "end": "2211359"
  },
  {
    "text": "this process that I'm outlining is kind of similar with even large data sets most of it would be similar so I'm",
    "start": "2211359",
    "end": "2218390"
  },
  {
    "text": "hoping you you you're able to like look through the process and appreciate that so that you can then you know use the",
    "start": "2218390",
    "end": "2224539"
  },
  {
    "text": "same process with larger data sets it covers ten years of clinical care records with 130 hospitals and has 50",
    "start": "2224539",
    "end": "2231920"
  },
  {
    "text": "plus features or attributes which I'm going to use to draw connection and correlation to the target",
    "start": "2231920",
    "end": "2238130"
  },
  {
    "text": "attribute there's a link if you want to play around with it I highly recommend it it's a great repository if you want",
    "start": "2238130",
    "end": "2244910"
  },
  {
    "text": "to get started with building machine learning use cases so the first thing the first step that you saw in the",
    "start": "2244910",
    "end": "2250789"
  },
  {
    "start": "2248000",
    "end": "2248000"
  },
  {
    "text": "diagram was ingesting the data into s3 so what I do is use a simple s3 copy",
    "start": "2250789",
    "end": "2256579"
  },
  {
    "text": "command to get that data on s3 and then as you can see I listed the bucket of God a master in a transaction table now",
    "start": "2256579",
    "end": "2264040"
  },
  {
    "text": "why is this important I don't want the data to be denormalized from the very beginning I",
    "start": "2264040",
    "end": "2270940"
  },
  {
    "text": "want to process it I want to make sure that the keys that I'm using as foreign keys are not just numbers but have some",
    "start": "2270940",
    "end": "2278319"
  },
  {
    "text": "meaning to it so what I do is basically create three master tables one for",
    "start": "2278319",
    "end": "2283869"
  },
  {
    "text": "admission source admission type and then discharge this position and then diabetic data is my transaction table",
    "start": "2283869",
    "end": "2290020"
  },
  {
    "text": "which is then going to translate into a fact table in the actual data model in the in the in the data warehouse so",
    "start": "2290020",
    "end": "2297069"
  },
  {
    "text": "let's look at the schema really quickly so as you see the fact table is actually 50 about 50 attributes I would say 51",
    "start": "2297069",
    "end": "2304000"
  },
  {
    "text": "with the the target attribute that I built and then all the three dimension tables are really simple you know it",
    "start": "2304000",
    "end": "2310630"
  },
  {
    "text": "just has an ID in a description not much but in your case when you're building with larger data sets you wouldn't want",
    "start": "2310630",
    "end": "2316839"
  },
  {
    "text": "to like build a more sophisticated data model for this so that you're you know 100% sure that the data that you're",
    "start": "2316839",
    "end": "2323680"
  },
  {
    "text": "processing and feeding into your machine and a model is the right one the next step is actually once you have",
    "start": "2323680",
    "end": "2330730"
  },
  {
    "start": "2327000",
    "end": "2327000"
  },
  {
    "text": "the data inside redshift you have to load it and you know from s 3 and then",
    "start": "2330730",
    "end": "2337000"
  },
  {
    "text": "standardize it standardization is really important because it gives the right signals to",
    "start": "2337000",
    "end": "2343630"
  },
  {
    "text": "the machine learning model as I said so some of the things you can try with standardization is like updating null",
    "start": "2343630",
    "end": "2349420"
  },
  {
    "text": "values which is very important if you don't give complete information to the machine learning model it won't learn so",
    "start": "2349420",
    "end": "2355329"
  },
  {
    "text": "it's very important to give it complete as complete data set as possible to train it",
    "start": "2355329",
    "end": "2360930"
  },
  {
    "text": "our service actually splits the data set as 70/30 so you've got 70% of your",
    "start": "2360930",
    "end": "2367079"
  },
  {
    "text": "model that's used to train it 70 percent I beg your pardon your data that's used",
    "start": "2367079",
    "end": "2372099"
  },
  {
    "text": "to train it and 30 percent use to evaluate so it's really important you give the right training data set",
    "start": "2372099",
    "end": "2378300"
  },
  {
    "text": "you also have attributes certain attributes that's you know display a certain pattern for example phone",
    "start": "2378300",
    "end": "2384609"
  },
  {
    "text": "numbers you know that it's going to be in a certain pattern and if you don't see those pattern in your data set you",
    "start": "2384609",
    "end": "2390190"
  },
  {
    "text": "might as well go ahead and update it geographical data is also a great example",
    "start": "2390190",
    "end": "2395890"
  },
  {
    "text": "let's say you have the city information you can go ahead and update country county continent etc",
    "start": "2395890",
    "end": "2403500"
  },
  {
    "text": "timeline values is also a good example because let's say you know the admission",
    "start": "2403500",
    "end": "2409119"
  },
  {
    "text": "date and the discharge date any intervention or observation that happens between those two will happen between",
    "start": "2409119",
    "end": "2415089"
  },
  {
    "text": "those two dates so if you don't have the dates of your interventions and observations you can go ahead and update them through a simple script in redshift",
    "start": "2415089",
    "end": "2422109"
  },
  {
    "text": "and then the last one is really important because",
    "start": "2422109",
    "end": "2427140"
  },
  {
    "text": "granular values and numbers by themselves do not have a lot of meaning",
    "start": "2427140",
    "end": "2432220"
  },
  {
    "text": "for example age right if you say what's your age and in someone tells you 20",
    "start": "2432220",
    "end": "2437230"
  },
  {
    "text": "that number 20 by itself does not mean anything but if you tell the machine learning model okay I'm young or I'm old",
    "start": "2437230",
    "end": "2443849"
  },
  {
    "text": "that has much more meaning so so it's it's a good habit to kind of do away",
    "start": "2443849",
    "end": "2449950"
  },
  {
    "text": "with those granular aptitudes and group them together as categories that you can then use to train your model",
    "start": "2449950",
    "end": "2457829"
  },
  {
    "text": "once you have the data set massaged and ready and standardized what you have to",
    "start": "2457829",
    "end": "2462880"
  },
  {
    "start": "2458000",
    "end": "2458000"
  },
  {
    "text": "do is create a data source from redshift this can be done in two ways either you",
    "start": "2462880",
    "end": "2468099"
  },
  {
    "text": "can you can either you know call the create data source from redshift API or you can also do it via the console it",
    "start": "2468099",
    "end": "2475779"
  },
  {
    "text": "works just the same based on your preference the last thing I want to mention here before",
    "start": "2475779",
    "end": "2482200"
  },
  {
    "start": "2478000",
    "end": "2478000"
  },
  {
    "text": "I go into the demo is about real-time predictions as I said it's really simple to build",
    "start": "2482200",
    "end": "2488319"
  },
  {
    "text": "what you have to do is just enable that endpoint which I'm going to show and then the real-time prediction actually",
    "start": "2488319",
    "end": "2493690"
  },
  {
    "text": "can be used by API calls to you know send certain attributes the machine learning model",
    "start": "2493690",
    "end": "2500140"
  },
  {
    "text": "and get results immediately the way to do this is ml dot predict API which is",
    "start": "2500140",
    "end": "2506079"
  },
  {
    "text": "part of the SDK as well so you can use that for your API calls and the response",
    "start": "2506079",
    "end": "2512079"
  },
  {
    "text": "that you get is in the form of JSON so you can see it tells you what is the predicted value it gives you the",
    "start": "2512079",
    "end": "2519130"
  },
  {
    "text": "algorithm that was used and then the predictive model type which was a regression in this case so now you've",
    "start": "2519130",
    "end": "2526119"
  },
  {
    "text": "seen you know what exactly is the Phi step process to build this now let's try",
    "start": "2526119",
    "end": "2531500"
  },
  {
    "text": "and you know show this to you in a demo so I'm gonna take you through this entire thing and by the end you'll have",
    "start": "2531500",
    "end": "2537760"
  },
  {
    "text": "you know so you you see the the data set that I have on s3 I'm just quickly going",
    "start": "2537760",
    "end": "2545480"
  },
  {
    "text": "to show you the rich of cluster I'm using the default parameters for the cluster but you know obviously when",
    "start": "2545480",
    "end": "2552079"
  },
  {
    "text": "you're working with much larger data sets you have to find you in your cluster to make sure you know it's able to process data at that scale so I do",
    "start": "2552079",
    "end": "2560240"
  },
  {
    "text": "that I I get my cluster app and then I quickly shift over to show you the",
    "start": "2560240",
    "end": "2565490"
  },
  {
    "text": "visual visual of the data I'm using a visualization tool to just make sure that it's easy for you to see this as",
    "start": "2565490",
    "end": "2572900"
  },
  {
    "text": "you can see I've got the data set finally dressed up and prepped for feeding into a machine learning model",
    "start": "2572900",
    "end": "2578690"
  },
  {
    "text": "I've got all the 50 features and attributes here I'm going to talk about the target",
    "start": "2578690",
    "end": "2585049"
  },
  {
    "text": "attribute so the target attribute is really important which is readmission result one what this does is basically",
    "start": "2585049",
    "end": "2590950"
  },
  {
    "text": "alternates between yes and no so this is the attribute that my machine learning model is gonna predict in the end so",
    "start": "2590950",
    "end": "2597890"
  },
  {
    "text": "everything is good I switch over to the machine learning console and now",
    "start": "2597890",
    "end": "2603950"
  },
  {
    "text": "I'll try and build that data source that I just created inside redshift the way",
    "start": "2603950",
    "end": "2609559"
  },
  {
    "text": "to do this is just go here and say create a data source from redshift I specify a few parameters it lets me you",
    "start": "2609559",
    "end": "2617119"
  },
  {
    "text": "know create our database name the user name password and then I have to create",
    "start": "2617119",
    "end": "2623119"
  },
  {
    "text": "a role if I don't have a role you know I have to create one but in my case I do so I create that role and make sure that",
    "start": "2623119",
    "end": "2629809"
  },
  {
    "text": "that access is fine this space is actually for writing queries I write a very simple query which is a select star",
    "start": "2629809",
    "end": "2636349"
  },
  {
    "text": "but this is ANSI compatible so you can write any complex joins or anything you would like for your data set to be the",
    "start": "2636349",
    "end": "2643039"
  },
  {
    "text": "next few steps is just specifying a staging location and then a name for my",
    "start": "2643039",
    "end": "2648410"
  },
  {
    "text": "data source so I do all of that and I do a quick verification to make sure everything is fine and this is happening",
    "start": "2648410",
    "end": "2654980"
  },
  {
    "text": "as we speak so we are already creating a data source we have not reached the machine learning model each stage yet but I see my data source is already",
    "start": "2654980",
    "end": "2661849"
  },
  {
    "text": "create it has passed all the attribute that were there in my dears was all 50 attributes are here some of the",
    "start": "2661849",
    "end": "2668490"
  },
  {
    "text": "attributes are text so I want to quickly change that to categorical for the reasons I mentioned before so I do that",
    "start": "2668490",
    "end": "2674820"
  },
  {
    "text": "really quickly and then in the end what I want to do is just focus on the target",
    "start": "2674820",
    "end": "2679980"
  },
  {
    "text": "attribute this is the attribute that is finally going to be predicted so I want to make sure that I choose the right",
    "start": "2679980",
    "end": "2685380"
  },
  {
    "text": "data type for this because the model would be the model algorithm would be chosen based on this target attribute",
    "start": "2685380",
    "end": "2692810"
  },
  {
    "text": "once I do all of that it just asked me you know is there a target attribute so",
    "start": "2692810",
    "end": "2700020"
  },
  {
    "text": "I choose that and I continue and then I also have to choose whether this data",
    "start": "2700020",
    "end": "2707430"
  },
  {
    "text": "set has an identifier it's really important because if you don't choose an identifier it's going to be taken in the",
    "start": "2707430",
    "end": "2713340"
  },
  {
    "text": "learning process so I tell the machine learning model this is an identifier it's just numbers don't use it so I've",
    "start": "2713340",
    "end": "2719250"
  },
  {
    "text": "got my data source created and now I want to look at what the data source is",
    "start": "2719250",
    "end": "2726120"
  },
  {
    "text": "you know what it tells me so it's really simple you know in the first look you",
    "start": "2726120",
    "end": "2731130"
  },
  {
    "text": "have a lot of visual that's already available the pre analysis some metrics how many rows how many columns it",
    "start": "2731130",
    "end": "2737940"
  },
  {
    "text": "contains I can you know quickly do a quick visualization to see that you know",
    "start": "2737940",
    "end": "2743250"
  },
  {
    "text": "how the data set is distributed I can go to the car you know attribute level and see what the correlation of each of",
    "start": "2743250",
    "end": "2749700"
  },
  {
    "text": "those attributes to the target is these are the attributes that's actually affecting my machine learning model or",
    "start": "2749700",
    "end": "2754980"
  },
  {
    "text": "the result process so changing any of these attributes is going to affect the outcome once I have done all of that you",
    "start": "2754980",
    "end": "2761910"
  },
  {
    "text": "know I'm going to go I create my machine learning model I choose all default options for this but you can go custom",
    "start": "2761910",
    "end": "2767940"
  },
  {
    "text": "and write things called recipes recipes are things within a ml that allow you to",
    "start": "2767940",
    "end": "2773040"
  },
  {
    "text": "transform your data sets I did most of my transformation inside redshift but",
    "start": "2773040",
    "end": "2778140"
  },
  {
    "text": "you could use you know the AML recipes as well so I've got my AML model created",
    "start": "2778140",
    "end": "2784620"
  },
  {
    "text": "I try a real-time prediction now so let's try it right my model is already created in the next few minutes let's",
    "start": "2784620",
    "end": "2792600"
  },
  {
    "text": "make sure that I put the data in I just put a gender attribute maybe an",
    "start": "2792600",
    "end": "2799970"
  },
  {
    "text": "age category attribute and then all I have to do is just click create prediction so as you can see on the",
    "start": "2799970",
    "end": "2807080"
  },
  {
    "text": "right you will see the JSON output of what that model gives you now I want to",
    "start": "2807080",
    "end": "2812150"
  },
  {
    "text": "try this through the CLI so my model is set up my machine learning model is done",
    "start": "2812150",
    "end": "2818300"
  },
  {
    "text": "it's actually working from the data source that I had I have to enable real-time predictions which I just did",
    "start": "2818300",
    "end": "2824750"
  },
  {
    "text": "and I just copy all the attributes that is needed for that predict API call that",
    "start": "2824750",
    "end": "2830390"
  },
  {
    "text": "I'm going to make through the console so I just go back to the console just say AWS machine learning predict which is",
    "start": "2830390",
    "end": "2837050"
  },
  {
    "text": "the way to call this API and then you know just put in the attributes I go",
    "start": "2837050",
    "end": "2845030"
  },
  {
    "text": "with you know some records some options like gender equal to male Rae is equal to Caucasian and then from just the end",
    "start": "2845030",
    "end": "2853280"
  },
  {
    "text": "point value and then as I put the end point value you will see that same JSON",
    "start": "2853280",
    "end": "2859160"
  },
  {
    "text": "that you got as an output in the previous screen you will be able to see this in the CLI as well so the you've",
    "start": "2859160",
    "end": "2866480"
  },
  {
    "text": "made the API call through the console you've made it through the CLI now what you want to do is call this through an",
    "start": "2866480",
    "end": "2873320"
  },
  {
    "text": "API call because that is the real power you know that is way that is the way most of the developers would be using",
    "start": "2873320",
    "end": "2879890"
  },
  {
    "text": "this we are not going to come back to the console to actually you know do the prediction so the way to do this is",
    "start": "2879890",
    "end": "2886070"
  },
  {
    "text": "basically create a website which I did host it on s3 because s3 allows you to host the website without any service it",
    "start": "2886070",
    "end": "2893060"
  },
  {
    "text": "scales automatically it's really easy to host and then make this machine learning",
    "start": "2893060",
    "end": "2898430"
  },
  {
    "text": "you know API call like with all the parameters so you know you see the",
    "start": "2898430",
    "end": "2903710"
  },
  {
    "text": "machine learning model ID the predict endpoint the records and then this can be embedded in your code that runs in",
    "start": "2903710",
    "end": "2910130"
  },
  {
    "text": "the browser and basically calls that API in real time so let me switch over and",
    "start": "2910130",
    "end": "2916010"
  },
  {
    "text": "quickly show you what appliqu what that application looks like so I tried and build that application",
    "start": "2916010",
    "end": "2923380"
  },
  {
    "text": "myself and this is the way it looks like so I hosted this application it's basically asking for a few attributes so",
    "start": "2923380",
    "end": "2930170"
  },
  {
    "text": "let me select a few attributes so I'll just say gender equal to male",
    "start": "2930170",
    "end": "2935440"
  },
  {
    "text": "you know some attributes around admission source I don't need to select",
    "start": "2935440",
    "end": "2940730"
  },
  {
    "text": "all of them and what I do is just click the predict button and queries the real-time endpoint and gives",
    "start": "2940730",
    "end": "2947450"
  },
  {
    "text": "me the chance of that patient coming back to the hospital within 30 days and this has basically been done in the",
    "start": "2947450",
    "end": "2954230"
  },
  {
    "text": "period that I was talking this application has been has been built with the set of steps that I just showed you",
    "start": "2954230",
    "end": "2959630"
  },
  {
    "text": "so it's really simple to use as you saw I can change and then play around with this you know based on what my condition",
    "start": "2959630",
    "end": "2966950"
  },
  {
    "text": "is the whole idea is that these actually most of these attributes would be available to you at the time of admission or maybe during the process of",
    "start": "2966950",
    "end": "2974260"
  },
  {
    "text": "a patient's care plan so you can really you know keep querying this real-time",
    "start": "2974260",
    "end": "2979940"
  },
  {
    "text": "endpoint and seeing how the results vary and based on that you can alter the care",
    "start": "2979940",
    "end": "2984980"
  },
  {
    "text": "plan on the patient if you want to because the patient is still in the hospital you still have control before",
    "start": "2984980",
    "end": "2990530"
  },
  {
    "text": "you know by the time he gets discharged you may not have that much control whether the patient comes back to the",
    "start": "2990530",
    "end": "2995990"
  },
  {
    "text": "hospital or not so that's the intention now it's a different case of how easy it is to build a model that accurately",
    "start": "2995990",
    "end": "3001810"
  },
  {
    "text": "predicts this because you'll need really varied datasets a large amount of data set to actually build a very accurate",
    "start": "3001810",
    "end": "3007870"
  },
  {
    "text": "model that does this but the process is going to be the same so I'm going to quickly switch over and",
    "start": "3007870",
    "end": "3017850"
  },
  {
    "text": "also talk about a blog so this entire thing that I just showed you is also available as a blog it has much more",
    "start": "3017910",
    "end": "3025690"
  },
  {
    "text": "details than I just showed you in the presentation deck it has a link to the github repository that has sample code",
    "start": "3025690",
    "end": "3032310"
  },
  {
    "text": "that is available for you to go and implement or you know on your own if you want to and that will allow you to like",
    "start": "3032310",
    "end": "3038410"
  },
  {
    "text": "start experimenting with our AML service so just to end",
    "start": "3038410",
    "end": "3045150"
  },
  {
    "start": "3043000",
    "end": "3043000"
  },
  {
    "text": "you saw how the can be architecture that rich implemented talked about",
    "start": "3045150",
    "end": "3052020"
  },
  {
    "text": "retrospective analysis we just extended that with machine learning so how exactly this expanded architecture works",
    "start": "3052020",
    "end": "3058900"
  },
  {
    "text": "basically you got all your data sets into s3 remains common you use EMR to",
    "start": "3058900",
    "end": "3064250"
  },
  {
    "text": "actually do one structure data processing so large amount of unstructured data that cannot be processed by conventional relational",
    "start": "3064250",
    "end": "3070910"
  },
  {
    "text": "database technologies you can use EMR and Hadoop to actually do that processing right the data back into s3",
    "start": "3070910",
    "end": "3077780"
  },
  {
    "text": "and use redshift to create that structure data warehouse which you use for your machine learning model if you",
    "start": "3077780",
    "end": "3084290"
  },
  {
    "text": "want to build a website or an application and host it you can use ec2 instances to to run your web servers or",
    "start": "3084290",
    "end": "3090830"
  },
  {
    "text": "you can you know if it's a static website you can also host it on s3 and if you're going with batch predictions",
    "start": "3090830",
    "end": "3096380"
  },
  {
    "text": "you can you know take that entire batch of data put it put the batch prediction",
    "start": "3096380",
    "end": "3102020"
  },
  {
    "text": "back onto s3 build custom data marts on RDS and then",
    "start": "3102020",
    "end": "3107330"
  },
  {
    "text": "use quick site which is our reporting service bi reporting service that allows",
    "start": "3107330",
    "end": "3112970"
  },
  {
    "text": "you to build reports so you can use build a reports something like actual versus predicted value and then expose",
    "start": "3112970",
    "end": "3120170"
  },
  {
    "text": "it to your end users whether internet so that's all I had I just want to end",
    "start": "3120170",
    "end": "3126619"
  },
  {
    "text": "with saying that we have a happy are today and the Japanese restaurant and from 6:00 to 8:00 sponsored by cambia",
    "start": "3126619",
    "end": "3133400"
  },
  {
    "text": "and 8k miles you're all welcome to come also about the security session that are",
    "start": "3133400",
    "end": "3140210"
  },
  {
    "text": "now mentioned I encourage you to check it out it's happening on November 29",
    "start": "3140210",
    "end": "3145849"
  },
  {
    "text": "that's tomorrow from 12:30 to 1:30 thank you [Applause]",
    "start": "3145849",
    "end": "3153080"
  }
]
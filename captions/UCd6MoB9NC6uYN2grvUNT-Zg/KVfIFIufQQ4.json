[
  {
    "start": "0",
    "end": "14000"
  },
  {
    "text": "welcome to the last session of the day we saved obviously the most thrilling one for last this is going to be",
    "start": "0",
    "end": "6930"
  },
  {
    "text": "advanced container scheduling and management first things first what is",
    "start": "6930",
    "end": "12690"
  },
  {
    "text": "container scheduling and why do you care about it that's how your containers are placed and run on your instance so in a",
    "start": "12690",
    "end": "20010"
  },
  {
    "start": "14000",
    "end": "77000"
  },
  {
    "text": "lot of cases that's going to be how much how much resources should I allocate to that task which tasks given the choice",
    "start": "20010",
    "end": "28019"
  },
  {
    "text": "of many should I place that task on and it goes beyond the resource usage a",
    "start": "28019",
    "end": "34530"
  },
  {
    "text": "little bit - how do i schedule things so it's not just about do I have enough",
    "start": "34530",
    "end": "39600"
  },
  {
    "text": "resources for this or should I put it there or have I balanced across subnets and availability zones but I can",
    "start": "39600",
    "end": "45000"
  },
  {
    "text": "actually schedule things also and I can run them in response to something else so if I have task number one that runs I",
    "start": "45000",
    "end": "51719"
  },
  {
    "text": "can run a second task in response to that I could run it in response to a function I could schedule it to run like a cron job everyone's favorite and run",
    "start": "51719",
    "end": "60180"
  },
  {
    "text": "it every night at a certain time or every day in the middle of the day or something like that so there's more than",
    "start": "60180",
    "end": "65820"
  },
  {
    "text": "just scheduling and management but those are the big things here almost all of",
    "start": "65820",
    "end": "71400"
  },
  {
    "text": "you are here for my last two sessions so I have some intro that we're just going to skip over I think like with",
    "start": "71400",
    "end": "78509"
  },
  {
    "start": "77000",
    "end": "160000"
  },
  {
    "text": "everything else so management is scheduling are things set start to have really significant impacts once you get",
    "start": "78509",
    "end": "83909"
  },
  {
    "text": "to a production system so it doesn't really matter if I kind of tweak anything or tune anything or change",
    "start": "83909",
    "end": "89880"
  },
  {
    "text": "anything when I'm just running a couple of containers or one container or 50 containers and it doesn't even matter",
    "start": "89880",
    "end": "95070"
  },
  {
    "text": "that much at 100 containers but where it does matter is when I have a whole",
    "start": "95070",
    "end": "100290"
  },
  {
    "text": "production system and maybe for you a production system as 100 containers but it does really matter about how",
    "start": "100290",
    "end": "106950"
  },
  {
    "text": "efficiently I'm using my space how efficiently I'm using my resources how I'm getting the most out of the infrastructure that I have so a lot of",
    "start": "106950",
    "end": "113040"
  },
  {
    "text": "us might work for startups I know that I worked at a start-up before this and I definitely did not want to pay to run",
    "start": "113040",
    "end": "118829"
  },
  {
    "text": "any more instances than I had to and part of I think what's really great about containers is that the utilization",
    "start": "118829",
    "end": "125340"
  },
  {
    "text": "for monoliths for a lot of people was not that great of a percent right so since I in order to have redundancy or",
    "start": "125340",
    "end": "133680"
  },
  {
    "text": "fail ability I had to have that one copy of that one application running on several different servers and maybe I",
    "start": "133680",
    "end": "139379"
  },
  {
    "text": "was only using 10% of each of those servers maybe I was using 20% of one server because I had some other tasks",
    "start": "139379",
    "end": "145950"
  },
  {
    "text": "running on it but then 10% of the rest of them in my pool so we have an opportunity with containers and micro",
    "start": "145950",
    "end": "151439"
  },
  {
    "text": "services to really get the most out of the infrastructure that we're using so pack my tasks a little bit more closely",
    "start": "151439",
    "end": "157920"
  },
  {
    "text": "use my space a little bit more efficiently a couple of core components here we'll talk about all of them some",
    "start": "157920",
    "end": "163530"
  },
  {
    "text": "in more detail than others first is scheduling so how do the tasks",
    "start": "163530",
    "end": "168959"
  },
  {
    "text": "run what do they schedule them in response to placement engine that does things like and we will look at the",
    "start": "168959",
    "end": "175200"
  },
  {
    "text": "whole flow and the order of operations but how does the agent know where to",
    "start": "175200",
    "end": "181409"
  },
  {
    "text": "place the tasks so there are some seats in the front by the way if people are looking for them and it's okay to walk",
    "start": "181409",
    "end": "187739"
  },
  {
    "text": "in front of the camera I think everyone's seen me like four times already today so there's two seats up",
    "start": "187739",
    "end": "193469"
  },
  {
    "text": "here there's two more in that row there's two over there or no there's yeah there's two over there so if you're",
    "start": "193469",
    "end": "199349"
  },
  {
    "text": "looking for a seat come and join us sweet you're also welcome to lurk at the",
    "start": "199349",
    "end": "206699"
  },
  {
    "text": "back of the room with Adrian who's lurking at the back of the room so that's also fine if you don't want to come join us at the front so for those",
    "start": "206699",
    "end": "214500"
  },
  {
    "text": "of you that just walked in scheduling engine so how do I schedule my tasks what do they run a response to placement",
    "start": "214500",
    "end": "220650"
  },
  {
    "text": "engine will go through the whole order of operations for this but in general I have multiple instances and how does the",
    "start": "220650",
    "end": "227400"
  },
  {
    "text": "agent choose which instance out of those many I should place my tasks on finally",
    "start": "227400",
    "end": "232859"
  },
  {
    "text": "you have extensions and we will dig into that first off scheduling engines so we",
    "start": "232859",
    "end": "239220"
  },
  {
    "start": "237000",
    "end": "386000"
  },
  {
    "text": "have different types of schedulers here so the first ones are the service schedulers and that's the really common one right so within ECS I have my tasks",
    "start": "239220",
    "end": "247439"
  },
  {
    "text": "are separated out into services each service has its own scheduler associated with it or the agent is really",
    "start": "247439",
    "end": "253379"
  },
  {
    "text": "scheduling on behalf of the service but I run multiple copies of my tasks I spread those across availability zones",
    "start": "253379",
    "end": "259380"
  },
  {
    "text": "and subnets I also have a batch scheduler so I didn't bring a reference",
    "start": "259380",
    "end": "264810"
  },
  {
    "text": "architecture for this this time I think looking at reference architectures in a room is sad and I",
    "start": "264810",
    "end": "271410"
  },
  {
    "text": "don't think we should do that but they're online and I will send out links for them but something that I",
    "start": "271410",
    "end": "276630"
  },
  {
    "text": "actually think is a really nice architecture type for containers is is batch processing so how can I suck up",
    "start": "276630",
    "end": "282419"
  },
  {
    "text": "lots of events and process them all at once or go through them all sequentially",
    "start": "282419",
    "end": "287639"
  },
  {
    "text": "and process the whole batch so ECS and other container engines are actually really great for that sort of thing and",
    "start": "287639",
    "end": "293100"
  },
  {
    "text": "I don't think you hear about them quite as often as kind of the three-tier web app or I ran my application or I change",
    "start": "293100",
    "end": "299730"
  },
  {
    "text": "it from monolith and I ran into containers and that's also great but there are some different types in here",
    "start": "299730",
    "end": "304830"
  },
  {
    "text": "also that you can really get the most set up with containers what's also really cool or for a certain value of",
    "start": "304830",
    "end": "311100"
  },
  {
    "text": "cool I guess is that if I have a cluster so I have a staging cluster or production cluster I probably have",
    "start": "311100",
    "end": "317340"
  },
  {
    "text": "excess capacity there it might not be a lot of excess capacity but since I want",
    "start": "317340",
    "end": "322710"
  },
  {
    "text": "high availability I probably have multiple instances in my cluster that a",
    "start": "322710",
    "end": "328620"
  },
  {
    "text": "portion of them are unused and this is less of that is used if I'm using something like bin packing which we'll",
    "start": "328620",
    "end": "334320"
  },
  {
    "text": "talk about later but if I have excess capacity why not use that for other exciting stuff so that might be",
    "start": "334320",
    "end": "340560"
  },
  {
    "text": "event-driven processing that might be batch processing that might be daemon schedulers I can use that excess",
    "start": "340560",
    "end": "347190"
  },
  {
    "text": "capacity in my cluster because I have a little bit of excess because I need it for some things but so deployments is",
    "start": "347190",
    "end": "354570"
  },
  {
    "text": "one of them in order to roll over tasks one by one I need a little bit of excess space to start up new copy to the task",
    "start": "354570",
    "end": "361410"
  },
  {
    "text": "so I need my excess space for something but I can also use it for more exciting things that don't necessarily need their",
    "start": "361410",
    "end": "368160"
  },
  {
    "text": "whole instance dedicated to them so instead of running a whole separate pool of resources or even a single instance",
    "start": "368160",
    "end": "374220"
  },
  {
    "text": "just for batch processing or cron jobs or event processing I can use the same",
    "start": "374220",
    "end": "380430"
  },
  {
    "text": "pool and I can use up all my excess capacity so that I can get just a little bit extra out of my cluster placement",
    "start": "380430",
    "end": "387660"
  },
  {
    "text": "engine so before we start on this this is one of the things that I've been talking about all day but then there is",
    "start": "387660",
    "end": "393750"
  },
  {
    "text": "a default here that does not require you to do anything so you can take the",
    "start": "393750",
    "end": "399210"
  },
  {
    "text": "the easy option here if you don't have a lot of tuning that you want to do you do not have to choose how ECS places your",
    "start": "399210",
    "end": "406870"
  },
  {
    "text": "tasks you have the option to customize how it places them and what strategies it uses and you can get very fancy that",
    "start": "406870",
    "end": "413950"
  },
  {
    "text": "is not mandatory it will place it'll place tasks just fine if you don't do it",
    "start": "413950",
    "end": "419440"
  },
  {
    "text": "it will follow its own order of operations and I'll talk about them but what we're going to talk about right now",
    "start": "419440",
    "end": "426250"
  },
  {
    "text": "is that this is 400 level excitement is we are going to talk about the custom",
    "start": "426250",
    "end": "431440"
  },
  {
    "text": "cool way but it is not mandatory if you do not do this or if you do not find this is applicable to you the agent will",
    "start": "431440",
    "end": "438490"
  },
  {
    "text": "continue to place tasks by itself so it'll go by instance that meets its hard",
    "start": "438490",
    "end": "444250"
  },
  {
    "text": "requirements so we've been talking about those some memory port and CPU and then it will balance by availability zone and",
    "start": "444250",
    "end": "450400"
  },
  {
    "text": "then it will go by least of least number of running tasks so the agent by default",
    "start": "450400",
    "end": "455410"
  },
  {
    "text": "will go to the ones if I have two tasks that could fit my if I have two",
    "start": "455410",
    "end": "462520"
  },
  {
    "text": "instances it could fit my tasks and one of them has three tasks running on it",
    "start": "462520",
    "end": "467710"
  },
  {
    "text": "already and one has zero and they're in different availability zones it'll go on the one with zero so that's a default",
    "start": "467710",
    "end": "474550"
  },
  {
    "text": "behavior yes",
    "start": "474550",
    "end": "477240"
  },
  {
    "text": "so the question is cuz I'm gonna get it right this time I also have an Ethernet dongle so life is great right now",
    "start": "481940",
    "end": "489010"
  },
  {
    "text": "I've gotten zero VPN messages I'm having a great day now if you were in my front",
    "start": "489010",
    "end": "496130"
  },
  {
    "text": "gate talk and it was confusing because I kept running it up internet and couldn't get a demo to work you're welcome to come to Helsinki and I'll do it again on",
    "start": "496130",
    "end": "503000"
  },
  {
    "text": "Thursday so the question is is there a chance that the same task will be",
    "start": "503000",
    "end": "508490"
  },
  {
    "text": "executed multiple times in the same instance yes and no yes if there if",
    "start": "508490",
    "end": "516589"
  },
  {
    "text": "that's if it's if it doesn't require a port so if it's not bound to a specific",
    "start": "516589",
    "end": "522020"
  },
  {
    "text": "port so like processing tasks often are not bound to a report to a port they're reading off a queue or something like",
    "start": "522020",
    "end": "528170"
  },
  {
    "text": "that those you can have multiple copies executing on the same instance the",
    "start": "528170",
    "end": "534770"
  },
  {
    "text": "expected behavior of those is that that's totally fine because it doesn't have a port if there's enough resources",
    "start": "534770",
    "end": "540950"
  },
  {
    "text": "to run it it's fine to have multiple copies if however it is bound to a port",
    "start": "540950",
    "end": "546230"
  },
  {
    "text": "unless you're using dynamic port allocation you won't be able to run multiple copies because the behavior",
    "start": "546230",
    "end": "552589"
  },
  {
    "text": "said they'll both need to say import and I only have one of them so both yes and no but if yes it's probably because it",
    "start": "552589",
    "end": "559730"
  },
  {
    "text": "didn't need a specific port in which case that's fine for you there is something which we'll get into",
    "start": "559730",
    "end": "565930"
  },
  {
    "text": "a lot of people are looking for a concept of of one per host which is how",
    "start": "565930",
    "end": "571910"
  },
  {
    "text": "can I get one single copy of this task not exceeding one copy of this task to",
    "start": "571910",
    "end": "577430"
  },
  {
    "text": "run on each and every host so as long as that host is running I need a single",
    "start": "577430",
    "end": "582529"
  },
  {
    "text": "copy of that of that task I need at least one but no greater than one that",
    "start": "582529",
    "end": "588920"
  },
  {
    "text": "use case for a lot of people is for for daemon schedulers for logging agents from monitoring agents ECS does have a",
    "start": "588920",
    "end": "597560"
  },
  {
    "text": "concept of that it's not a hundred percent what people are I think are looking for it's not exactly what I",
    "start": "597560",
    "end": "602990"
  },
  {
    "text": "needed it for there's a lot of really interesting work arounds for this what I",
    "start": "602990",
    "end": "608510"
  },
  {
    "text": "did and this is maybe the weird opsi way to do it but I did it as",
    "start": "608510",
    "end": "614209"
  },
  {
    "text": "part of user data so I just started the container myself there's a cool there's",
    "start": "614209",
    "end": "619550"
  },
  {
    "text": "a people are laughing at me but it works really well bash solves all problems eventually",
    "start": "619550",
    "end": "625660"
  },
  {
    "text": "there's an interesting blog post out there that I will link if I can find the link to it but other people that were",
    "start": "626800",
    "end": "633500"
  },
  {
    "text": "not me and did not find bash and acceptable answer that wanted it to be managed as an ACS service have some interesting",
    "start": "633500",
    "end": "639470"
  },
  {
    "text": "workarounds so if I can find the blog post and people are interested in it I will I'll post it so that was a very as",
    "start": "639470",
    "end": "645350"
  },
  {
    "text": "always long and convoluted and distracted answer to that question but I did answer it before I got distracted",
    "start": "645350",
    "end": "651790"
  },
  {
    "text": "are there any other questions before we talked about task placement policies sweet ok task placement engine which is",
    "start": "651790",
    "end": "662110"
  },
  {
    "start": "658000",
    "end": "819000"
  },
  {
    "text": "more colloquially colloquially oh I don't know how to say that word but it's better known as task placement policies",
    "start": "662110",
    "end": "668870"
  },
  {
    "text": "and strategies so here's how it works so I can I can allocate tasks based on",
    "start": "668870",
    "end": "676009"
  },
  {
    "text": "specific tags as well so we just talked about the default way of ECS allocating",
    "start": "676009",
    "end": "681110"
  },
  {
    "text": "things which is by hard constraints so port memory and CPU only sometimes port",
    "start": "681110",
    "end": "688670"
  },
  {
    "text": "but things like that and then by availability zone and then by number of",
    "start": "688670",
    "end": "693709"
  },
  {
    "text": "running of running tasks if you you can also set specific ones so it'll match",
    "start": "693709",
    "end": "700550"
  },
  {
    "text": "against the constraints that you specify so an example might be a specific ami type so say you have a cluster you have",
    "start": "700550",
    "end": "707329"
  },
  {
    "text": "multiple instances running on it and you have some a.m. eyes that are for just a",
    "start": "707329",
    "end": "713449"
  },
  {
    "text": "regular ECS optimized ami and one that you've tuned to include something else",
    "start": "713449",
    "end": "718459"
  },
  {
    "text": "so you had some kernel settings on it or you're using a different instance type or you've done something special that",
    "start": "718459",
    "end": "723949"
  },
  {
    "text": "ami like for example install a package for your monitoring agent so you could",
    "start": "723949",
    "end": "730910"
  },
  {
    "text": "match based on that ami ID you could also match based and availability zones so if you only wanted some tasks to be",
    "start": "730910",
    "end": "737029"
  },
  {
    "text": "deployed to a certain availability zone you could do that same with instance type would you talked about this",
    "start": "737029",
    "end": "743630"
  },
  {
    "text": "Inked instances is a lot about what I'm just talking about with that one per host so given the chance put one of",
    "start": "743630",
    "end": "750920"
  },
  {
    "text": "these on each distinct instance works for a lot of cases I don't think it's a",
    "start": "750920",
    "end": "756770"
  },
  {
    "text": "little funky at auto-scaling but we'll talk about that you can add custom tags as well so when ECS was first kind of",
    "start": "756770",
    "end": "765200"
  },
  {
    "text": "getting started in beta it turned out that people were using the same cluster",
    "start": "765200",
    "end": "770390"
  },
  {
    "text": "they were using a shared cluster and then they were distributing their tasks within the cluster so they had some",
    "start": "770390",
    "end": "776180"
  },
  {
    "text": "instances that they wanted to run database tasks on some that they wanted to run event tasks on some that they",
    "start": "776180",
    "end": "782180"
  },
  {
    "text": "wanted to run messaging tasks on so they matched based they wanted to match based on custom tags so that tasks that were",
    "start": "782180",
    "end": "789140"
  },
  {
    "text": "supposed to be run in a certain kind of instance or on prod instances as part of their as part of their cluster or they",
    "start": "789140",
    "end": "797120"
  },
  {
    "text": "could do that that is not how I've set things up in the past I've usually done the cluster level isolation so a production stack staging one a",
    "start": "797120",
    "end": "804170"
  },
  {
    "text": "development cluster but if you prefer to share one cluster this is one way that",
    "start": "804170",
    "end": "810500"
  },
  {
    "text": "you might be able to support it is by defining the different instance types of tags and then writing a custom filter to",
    "start": "810500",
    "end": "816350"
  },
  {
    "text": "place your tasks based on those constraints the new order of operations",
    "start": "816350",
    "end": "822610"
  },
  {
    "start": "819000",
    "end": "902000"
  },
  {
    "text": "so cluster constraints are the hard restraints that I keep talking about so I cannot make more CPU and memory",
    "start": "822610",
    "end": "829040"
  },
  {
    "text": "without changing my instance type unless I'm very special maybe I don't know",
    "start": "829040",
    "end": "835790"
  },
  {
    "text": "port which we talked about depends on your load balancer type but unless",
    "start": "835790",
    "end": "840860"
  },
  {
    "text": "you're using application load balancer that is a hard constraint so the agent will satisfy those constraints first",
    "start": "840860",
    "end": "846820"
  },
  {
    "text": "then it will look for custom constraints and those are the ones that we just talked about so things that I wrote",
    "start": "846820",
    "end": "852560"
  },
  {
    "text": "myself outside of the actual placement engine then it will meet my strategy",
    "start": "852560",
    "end": "857810"
  },
  {
    "text": "which we're going to look at on the next slide and then it will select my final instance so hard constraints custom",
    "start": "857810",
    "end": "865190"
  },
  {
    "text": "constraints strategy if I've chosen one and then select the final one so if",
    "start": "865190",
    "end": "870980"
  },
  {
    "text": "you're ever not quite sure you writ if you wrote a custom strategy and you're not quite sure why the agent is",
    "start": "870980",
    "end": "877200"
  },
  {
    "text": "tasks in a way that doesn't meet your strategy from experience it's probably",
    "start": "877200",
    "end": "882370"
  },
  {
    "text": "due to this order of operations it's like middle school math class but the",
    "start": "882370",
    "end": "887710"
  },
  {
    "text": "the order does actually really matter here it will always follow this order when it places things so if you write a",
    "start": "887710",
    "end": "892870"
  },
  {
    "text": "custom policy make sure that you that you write something in such a way that it works for you while it follows that",
    "start": "892870",
    "end": "899980"
  },
  {
    "text": "order placement strategies so we're gonna go into all four of these you have",
    "start": "899980",
    "end": "907330"
  },
  {
    "text": "been packing you have spread you have affinity and you have distinct instance since these have been uncreated Lea",
    "start": "907330",
    "end": "913900"
  },
  {
    "text": "named like everything else that I've talked about I think its they're somewhat self-explanatory but we'll dig into them",
    "start": "913900",
    "end": "919480"
  },
  {
    "text": "so bin packing means to pack things as closely together as possible so use up",
    "start": "919480",
    "end": "925690"
  },
  {
    "text": "all the space that you can on this instance before allocating to a different instance so if I have one",
    "start": "925690",
    "end": "931720"
  },
  {
    "text": "instance that has ten tasks running on it and one that has zero if I have space so obviously if I fit those hard",
    "start": "931720",
    "end": "938470"
  },
  {
    "text": "constraints so if I have enough memory port and CPU to to support that task it",
    "start": "938470",
    "end": "945610"
  },
  {
    "text": "will go on the one that has ten tasks running so this is really good if you're either trying to use your infrastructure",
    "start": "945610",
    "end": "951340"
  },
  {
    "text": "as tightly as possible maybe if you have a development environment and you just",
    "start": "951340",
    "end": "956740"
  },
  {
    "text": "you only want to use one server to support this so you want to get as many as possible I talked about in the State",
    "start": "956740",
    "end": "962920"
  },
  {
    "text": "of the Union this morning coming to call it segment uses that in production actually that they want to be able to",
    "start": "962920",
    "end": "969370"
  },
  {
    "text": "cram as many short-lived tasks as possible onto the same instance so that they can fill up their whole cluster you",
    "start": "969370",
    "end": "976420"
  },
  {
    "text": "can use bin packing a production also but it just says use this space as efficiently as possible before moving on",
    "start": "976420",
    "end": "981850"
  },
  {
    "text": "to the next available instance spread will try to distribute them as evenly as possible so an example of spread might",
    "start": "981850",
    "end": "988480"
  },
  {
    "text": "be to spread across availability zones there's actually is structured a lot like a math class today so we will",
    "start": "988480",
    "end": "994060"
  },
  {
    "text": "definitely go through exercises on all of these because this is 400 level so we have examples",
    "start": "994060",
    "end": "1000180"
  },
  {
    "text": "spread will distribute them as evenly as possible so if I have two or three on everything and I have one another",
    "start": "1000180",
    "end": "1005910"
  },
  {
    "text": "it will add the second one to that one before moving on affinity will let you",
    "start": "1005910",
    "end": "1011100"
  },
  {
    "text": "do things in logical groups so if I have a logger and a monitor this is a stupid",
    "start": "1011100",
    "end": "1017220"
  },
  {
    "text": "example but if I have a logger in a monitor that I always want to be together I can keep those as affinity so",
    "start": "1017220",
    "end": "1024000"
  },
  {
    "text": "I want one of a and one of B and I always want a and B together I can do that with affinity and then distinct",
    "start": "1024000",
    "end": "1030689"
  },
  {
    "text": "instance attempt to run one copy on one",
    "start": "1030690",
    "end": "1036630"
  },
  {
    "text": "host so no more no less I'm not sure that that 100% always meets",
    "start": "1036630",
    "end": "1044189"
  },
  {
    "text": "that use case it definitely will do distinct instance but sometimes a little",
    "start": "1044190",
    "end": "1049200"
  },
  {
    "text": "bit of funky behavior with with auto-scaling so it is still an option",
    "start": "1049200",
    "end": "1054630"
  },
  {
    "text": "though you can also use these together so this particular I did not make this",
    "start": "1054630",
    "end": "1060210"
  },
  {
    "text": "diagram but it's pretty cool I can chain these together so it will spread across availability zone but it will bin pack",
    "start": "1060210",
    "end": "1067200"
  },
  {
    "text": "within that so if I have three open instances and I have available available",
    "start": "1067200",
    "end": "1073260"
  },
  {
    "text": "'ti zone a B and C if a is pretty full and B is pretty full it will fill up",
    "start": "1073260",
    "end": "1081330"
  },
  {
    "text": "it'll try to bin pack while still also distributing between availability zones for redundancy does that make sense",
    "start": "1081330",
    "end": "1088230"
  },
  {
    "text": "cool it's kind of it's kind of hard to explain but you can chain these",
    "start": "1088230",
    "end": "1094800"
  },
  {
    "text": "strategies together to benefit from both of them so you can use resources extremely efficiently while also going",
    "start": "1094800",
    "end": "1100950"
  },
  {
    "text": "for high availability or you could do within availability zone but also with",
    "start": "1100950",
    "end": "1106200"
  },
  {
    "text": "with also with affinity so I want to sent to deploy these pairs of tasks but also spread across availability zone so",
    "start": "1106200",
    "end": "1113280"
  },
  {
    "text": "you're not limited to just one you can chain them together just follow your order of operations so what is a",
    "start": "1113280",
    "end": "1119970"
  },
  {
    "start": "1118000",
    "end": "1197000"
  },
  {
    "text": "container manager do so in for ECS the the thing that's fitting this role is is",
    "start": "1119970",
    "end": "1127530"
  },
  {
    "text": "the ECS agent still so it looks for available resources it looks for changes in",
    "start": "1127530",
    "end": "1132659"
  },
  {
    "text": "amount of resources so if I start up a new cluster and it has ten instances associated with it but I deploy six",
    "start": "1132659",
    "end": "1140220"
  },
  {
    "text": "tasks my container manager knows the available amount of resources when I",
    "start": "1140220",
    "end": "1145710"
  },
  {
    "text": "started but then it tracks updates to that number of resources as well so as I deploy new copies or remove new copies",
    "start": "1145710",
    "end": "1152639"
  },
  {
    "text": "or change the amount of resources allocated to a service the container manager is responsible for tracking that",
    "start": "1152639",
    "end": "1158879"
  },
  {
    "text": "it's also responsible for tracking whether I can deploy it has to follow these rules so it has to look and say",
    "start": "1158879",
    "end": "1166470"
  },
  {
    "text": "okay so I have six instances left and four of them have enough resources to",
    "start": "1166470",
    "end": "1173429"
  },
  {
    "text": "support that task but three of them are us in u.s. East 1a and one of them is us east 1e and I",
    "start": "1173429",
    "end": "1180690"
  },
  {
    "text": "already have tasks than 1a so the only one left is 1e so it's not your responsibility to follow these rules you",
    "start": "1180690",
    "end": "1187590"
  },
  {
    "text": "have to write them if you want them but it's the containers manager container managers responsibility to enforce those",
    "start": "1187590",
    "end": "1193950"
  },
  {
    "text": "rules check for accuracy and keep track of those resources so I've been talking",
    "start": "1193950",
    "end": "1200099"
  },
  {
    "text": "about CPU and memory imports all day because I love a good port conversation",
    "start": "1200099",
    "end": "1205940"
  },
  {
    "text": "obviously there are other resource constraints so there are more than are on this page also disk space is another",
    "start": "1205940",
    "end": "1213749"
  },
  {
    "text": "one which is always really exciting because docker has very strange behavior when it runs out of disk space I ops",
    "start": "1213749",
    "end": "1220470"
  },
  {
    "text": "network bandwidth so these are all constraints that are both tracked by the resource manager and that you have to respect so some of these are things that",
    "start": "1220470",
    "end": "1228629"
  },
  {
    "text": "you can you can tweak a little bit both at the task and container level by changing how much resources you need to",
    "start": "1228629",
    "end": "1235259"
  },
  {
    "text": "allocate to the task but it's also controllable via instance type so I have",
    "start": "1235259",
    "end": "1240929"
  },
  {
    "text": "some instances that are optimized for memory use I have some that are optimized for CPU so you can control",
    "start": "1240929",
    "end": "1246690"
  },
  {
    "text": "some of these by selecting an instance type that's better for your workload but in general they are considered hard",
    "start": "1246690",
    "end": "1253080"
  },
  {
    "text": "constraints so without making some sort of change I cannot make more of one of these resources",
    "start": "1253080",
    "end": "1258970"
  },
  {
    "text": "a good time to mention by the way is that one of the most popular questions I get asked is but you have an EC s",
    "start": "1258970",
    "end": "1265990"
  },
  {
    "text": "optimized ami and what if I spend a lot of time working on my own ami and I would like to bring it myself to ECS the",
    "start": "1265990",
    "end": "1272590"
  },
  {
    "text": "short answer is you should feel free you can use whatever mi you'd like or whatever instance type you'd like some",
    "start": "1272590",
    "end": "1280270"
  },
  {
    "text": "things that you need to remember if you're going to bring your own so first is that it needs to be registered with the cluster so that's two extra lines",
    "start": "1280270",
    "end": "1285970"
  },
  {
    "text": "and something like easy to user data tell it which cluster it is you have to install and run the ECS agent if you",
    "start": "1285970",
    "end": "1292150"
  },
  {
    "text": "want it to communicate back with a nice es cluster so that it can do things like manage your containers for you and you",
    "start": "1292150",
    "end": "1299289"
  },
  {
    "text": "obviously need to install and run docker unless you know something that I don't know so you can bring your own ami so if",
    "start": "1299289",
    "end": "1307390"
  },
  {
    "text": "you've tuned something or if you've picked an instance type that you know is really great for your workloads you are not limited to using the EECS optimized",
    "start": "1307390",
    "end": "1314169"
  },
  {
    "text": "ami so how I would do this is I would either build my own ami or figure out the instance type that I wanted and",
    "start": "1314169",
    "end": "1320100"
  },
  {
    "text": "since we know that I like to solve all my problems with bash I would add some",
    "start": "1320100",
    "end": "1326770"
  },
  {
    "text": "stuff in user data possibly that either pulled what I wanted to or made sure an agent was running but mostly people a",
    "start": "1326770",
    "end": "1333789"
  },
  {
    "text": "lot of people dissing called the golden ami where they get the ami they make all their changes and then they commit their",
    "start": "1333789",
    "end": "1339429"
  },
  {
    "text": "own version of the ami back there it seems very old-school because we're doing everything at the container level",
    "start": "1339429",
    "end": "1345159"
  },
  {
    "text": "now but for a lot of people that have workloads that are very specifically dependent on tuning CPU or getting the",
    "start": "1345159",
    "end": "1352030"
  },
  {
    "text": "most out of their memory or a specific type of instance type or if they've done kernel level changes it is totally a normal thing to still have your ami that",
    "start": "1352030",
    "end": "1358659"
  },
  {
    "text": "is custom so you can do that with ECS but remember that you have three extra steps to do that to register all three",
    "start": "1358659",
    "end": "1366700"
  },
  {
    "text": "of those extra steps for some reason are in different sections of the documentation but they are all out there",
    "start": "1366700",
    "end": "1372159"
  },
  {
    "text": "if people would like to see them I will tweet them or posts about them if you would like to see all the instructions in the same place we just talked about",
    "start": "1372159",
    "end": "1380830"
  },
  {
    "start": "1378000",
    "end": "1481000"
  },
  {
    "text": "this because I got ahead of myself but it is the ECS agent that is responsible for pretty much everything that we're",
    "start": "1380830",
    "end": "1386049"
  },
  {
    "text": "talking about today I mean you're responsible for picking your own instance types at that saying that you're interested in you're making am i but for things like resource",
    "start": "1386049",
    "end": "1392770"
  },
  {
    "text": "allocation or enforcing rules or enforcing constraints or strategies that's your EC s agent a fun fact the EC",
    "start": "1392770",
    "end": "1401110"
  },
  {
    "text": "s agent is open sourced so if you would like to see how the EC s agent works her open pull requests or issues or comments",
    "start": "1401110",
    "end": "1408250"
  },
  {
    "text": "and that is on github so the agent itself is is open source so you can look",
    "start": "1408250",
    "end": "1413350"
  },
  {
    "text": "at it and talk to the team that way and offer suggestions so the agent is pretty",
    "start": "1413350",
    "end": "1420430"
  },
  {
    "text": "much doing most of your control here so all of your resource control it's coming from the agent this is another diagram",
    "start": "1420430",
    "end": "1427240"
  },
  {
    "text": "that's gonna look really small from here but will look much better on your I'm sure a very large laptop screens at home",
    "start": "1427240",
    "end": "1434130"
  },
  {
    "text": "high-level picture of what's happening here so you have API is that everything are talking to so this is basically this",
    "start": "1434130",
    "end": "1441760"
  },
  {
    "text": "is what's happening with EC s so your agent is running things and it's communicating with the agent that's on",
    "start": "1441760",
    "end": "1447520"
  },
  {
    "text": "all of your boxes so if you look if you looked inside your ec s cluster right you have everything has the EC s agent",
    "start": "1447520",
    "end": "1454540"
  },
  {
    "text": "running on it and that's what communicates back with EC s so how it knows ok well there are six of me in the",
    "start": "1454540",
    "end": "1460150"
  },
  {
    "text": "cluster and my desired count for the service is 10 but I only have 8 that's how you keep track of things like that",
    "start": "1460150",
    "end": "1465730"
  },
  {
    "text": "and that's how the ECS knows what's happening on each of the hosts and what's happening with the services if",
    "start": "1465730",
    "end": "1471490"
  },
  {
    "text": "the cluster management engine you have the API that things can talk to and you have the agent which communicates back with the Communication Service plus your",
    "start": "1471490",
    "end": "1478060"
  },
  {
    "text": "key value store so really high-level more things that are happening with the",
    "start": "1478060",
    "end": "1484960"
  },
  {
    "start": "1481000",
    "end": "1529000"
  },
  {
    "text": "EC s agent so we already know this is pretty much like the hub that's controlling everything on your ECS",
    "start": "1484960",
    "end": "1490540"
  },
  {
    "text": "cluster what happens when you register an instance so I mean if you have a",
    "start": "1490540",
    "end": "1496810"
  },
  {
    "text": "cluster and at a new cluster you're registering several instances but in a lot of cases you're registering or D",
    "start": "1496810",
    "end": "1502600"
  },
  {
    "text": "registering an instance when your cluster scales up or down so this is",
    "start": "1502600",
    "end": "1507730"
  },
  {
    "text": "pretty much what that looks like I register my container instance and it reports a certain amount of resources so",
    "start": "1507730",
    "end": "1514240"
  },
  {
    "text": "here I have 2048 for CPU I report that",
    "start": "1514240",
    "end": "1519430"
  },
  {
    "text": "if I do nothing the instance will report all resources it has back to the EC s agent",
    "start": "1519430",
    "end": "1524710"
  },
  {
    "text": "that's our UCS agent is responsible for a resource allocation so it has to know I do not have to report all of my",
    "start": "1524710",
    "end": "1531970"
  },
  {
    "start": "1529000",
    "end": "1610000"
  },
  {
    "text": "resources to the EC s agent so I can reserve memory so we talked about how I",
    "start": "1531970",
    "end": "1537700"
  },
  {
    "text": "could one way to do logging or monitoring for me which is not the best",
    "start": "1537700",
    "end": "1542769"
  },
  {
    "text": "way anymore but it is definitely a way is to run containers that were not managed by EC s so they're not part of a",
    "start": "1542769",
    "end": "1549190"
  },
  {
    "text": "service they're not being managed by the agent but I can still run them on the Box if I'm feeling so inclined if I need",
    "start": "1549190",
    "end": "1556480"
  },
  {
    "text": "to reserve if I need to reserve resources for those containers not",
    "start": "1556480",
    "end": "1562389"
  },
  {
    "text": "managed by UCS I can reserve memory so I can report not all of my resources back",
    "start": "1562389",
    "end": "1567759"
  },
  {
    "text": "to the EC s agent that means that the EC s agent can only modify and allocate and control the resources that I reported",
    "start": "1567759",
    "end": "1574749"
  },
  {
    "text": "back so in some cases it might be if I say half of my box for other tasks only",
    "start": "1574749",
    "end": "1581529"
  },
  {
    "text": "report the remaining half of those resources back to the EC s agent and you can do those here so I can reserve",
    "start": "1581529",
    "end": "1587529"
  },
  {
    "text": "memory I can reserve ports if I wanted to keep a port and not let UCS manage it and I can reserve UDP ports so there are",
    "start": "1587529",
    "end": "1599499"
  },
  {
    "text": "more of them I believe if you go to the EC SH and it will list all the options that you can pass back to it so if you",
    "start": "1599499",
    "end": "1604929"
  },
  {
    "text": "want to hide more resources from it reserve ports you can do all of that when you register your instance how does",
    "start": "1604929",
    "end": "1612309"
  },
  {
    "start": "1610000",
    "end": "1745000"
  },
  {
    "text": "the agent go about managing resource requests when I schedule my tasks it",
    "start": "1612309",
    "end": "1619360"
  },
  {
    "text": "starts by looking at the available resources so I obviously if I don't have",
    "start": "1619360",
    "end": "1625059"
  },
  {
    "text": "enough resources to run my tasks it can't start and some of you may have",
    "start": "1625059",
    "end": "1630309"
  },
  {
    "text": "definitely gotten the message before where it says there's not enough resources to start this task so this is",
    "start": "1630309",
    "end": "1636309"
  },
  {
    "text": "the point where that message is being returned saying there's actually nowhere that I can put this so I cannot possibly",
    "start": "1636309",
    "end": "1642279"
  },
  {
    "text": "start and for a lot of us we then have auto-scaling roles in the background saying well you don't have enough",
    "start": "1642279",
    "end": "1648309"
  },
  {
    "text": "resources you could put a role here at that point where you could scale up in response to that it's a little late",
    "start": "1648309",
    "end": "1654820"
  },
  {
    "text": "because you've already run out of space and you can't start one but you could scale in response to that when you start it you",
    "start": "1654820",
    "end": "1662950"
  },
  {
    "text": "both look for how much resources are available so what you should take away and then you look for how much resources",
    "start": "1662950",
    "end": "1669700"
  },
  {
    "text": "the application actually needs so there's two parts going on there and then you check against our cluster",
    "start": "1669700",
    "end": "1675310"
  },
  {
    "text": "management engine which we saw back in that first big diagram was part of it was part of ECS was cluster management",
    "start": "1675310",
    "end": "1681870"
  },
  {
    "text": "if I have enough resources to support that task I approve it or the cluster",
    "start": "1681870",
    "end": "1688180"
  },
  {
    "text": "management action engine approves it if I don't I reject it I send that message",
    "start": "1688180",
    "end": "1694890"
  },
  {
    "text": "people have asked about high availability here before if you have one",
    "start": "1695490",
    "end": "1700780"
  },
  {
    "text": "availability zone that is not functioning the cluster management engine will continue to schedule tasks",
    "start": "1700780",
    "end": "1707820"
  },
  {
    "text": "but not in that availability zone so if you if you're missing one availability",
    "start": "1707820",
    "end": "1713350"
  },
  {
    "text": "zone your cluster management engine will continue to schedule so there's if there's an issue it just won't schedule",
    "start": "1713350",
    "end": "1718900"
  },
  {
    "text": "in that availability zone so there's some fault tolerance that goes on there so basically it's isolated so it is not",
    "start": "1718900",
    "end": "1726580"
  },
  {
    "text": "availability zone dependent so each of them it schedules in each of them independently and if I've approved it it",
    "start": "1726580",
    "end": "1736060"
  },
  {
    "text": "goes to agent communication and we talked about that's the part that communicates with all the EECS agents on",
    "start": "1736060",
    "end": "1741220"
  },
  {
    "text": "all the instances so if it's approved that goes to that it sends a state",
    "start": "1741220",
    "end": "1746890"
  },
  {
    "start": "1745000",
    "end": "1868000"
  },
  {
    "text": "change request to that node so that a new task that when your since your",
    "start": "1746890",
    "end": "1753100"
  },
  {
    "text": "instance is starting or since your new task is starting it'll and you can see these all these messages by the way so",
    "start": "1753100",
    "end": "1759850"
  },
  {
    "text": "UCS emits a ton of messages so the tasks are starting that are stopping that are",
    "start": "1759850",
    "end": "1765160"
  },
  {
    "text": "pending that our instances are starting and stopping and pending that you are",
    "start": "1765160",
    "end": "1770920"
  },
  {
    "text": "out of memory that you're out of CPU you get messages for all of those you can see them in the ECS console but that's",
    "start": "1770920",
    "end": "1777190"
  },
  {
    "text": "probably not the most efficient way to consume those messages you can use",
    "start": "1777190",
    "end": "1783280"
  },
  {
    "text": "something called event stream for cloud watch logs so you can shove all those messages at cloud wash logs so you can",
    "start": "1783280",
    "end": "1789460"
  },
  {
    "text": "consume them from ECS and then you can either consume them in cloud watch or if you have a different",
    "start": "1789460",
    "end": "1794770"
  },
  {
    "text": "logging and monitoring tool that perhaps makes graphs or something exciting you",
    "start": "1794770",
    "end": "1799990"
  },
  {
    "text": "can consume those from cloud watch as well another good example of this might be that you can submit these to page or",
    "start": "1799990",
    "end": "1805630"
  },
  {
    "text": "duty so if you have low on disk space or CPU or memory across your cluster or if",
    "start": "1805630",
    "end": "1811930"
  },
  {
    "text": "X number of tasks have been so a good one to catch for is that if your task has been stopped many many times in the",
    "start": "1811930",
    "end": "1820780"
  },
  {
    "text": "in in minutes it's probably having an issue and that's probably something that",
    "start": "1820780",
    "end": "1826510"
  },
  {
    "text": "a human might want to involve themselves in so if your same task has been stopped 15 times in 20 minutes it probably is",
    "start": "1826510",
    "end": "1834400"
  },
  {
    "text": "either getting killed because it's using up all in the memory or something else is wrong with it so you can look for",
    "start": "1834400",
    "end": "1840340"
  },
  {
    "text": "these kind of events and you can consume them in cloud watch or alert and page or duty or something like that so it",
    "start": "1840340",
    "end": "1846190"
  },
  {
    "text": "doesn't MIT a lot of messages that are useful during this whole process so this registering process and the task starting process so once the agent",
    "start": "1846190",
    "end": "1855190"
  },
  {
    "text": "Communication Service has approved this request it's spoken to the agent it",
    "start": "1855190",
    "end": "1860770"
  },
  {
    "text": "opens a WebSocket connection between the agent on the host and the ECS communication service that it needs to",
    "start": "1860770",
    "end": "1868270"
  },
  {
    "text": "change its state and then the EECS agent on the host responds back and says that",
    "start": "1868270",
    "end": "1874090"
  },
  {
    "text": "you've either it's either performed or failed to perform the requested action so it started the task its failed to",
    "start": "1874090",
    "end": "1880660"
  },
  {
    "text": "start the task it started and stopped the task which is not great so that's",
    "start": "1880660",
    "end": "1887770"
  },
  {
    "text": "kind of the process that you that you're following through and what's acknowledging what and then what",
    "start": "1887770",
    "end": "1893350"
  },
  {
    "text": "messages are being emitted does anyone have any questions about how the task",
    "start": "1893350",
    "end": "1898570"
  },
  {
    "text": "states are being changed and how resources are being managed yeah",
    "start": "1898570",
    "end": "1904890"
  },
  {
    "text": "so reporting the question back I'm not gonna forget this time what happens if",
    "start": "1911760",
    "end": "1918060"
  },
  {
    "text": "the ECS agent dies or is unresponsive so the what happens to the tasks that are",
    "start": "1918060",
    "end": "1924570"
  },
  {
    "text": "on there and then what happens with scheduling I'm going to guess so couple",
    "start": "1924570",
    "end": "1929820"
  },
  {
    "text": "things so if the agent has become unresponsive you won't be able to",
    "start": "1929820",
    "end": "1936840"
  },
  {
    "text": "schedule in place tasks on that instance anymore so this has happened to me",
    "start": "1936840",
    "end": "1942150"
  },
  {
    "text": "before and it did not affect what was currently running on that instance but I",
    "start": "1942150",
    "end": "1947280"
  },
  {
    "text": "was unable to schedule more or to communicate with that instance so they were fine when they were running",
    "start": "1947280",
    "end": "1953750"
  },
  {
    "text": "eventually what happened is that that since that instance wasn't reporting anything back anymore it was kind of it",
    "start": "1953750",
    "end": "1960180"
  },
  {
    "text": "was kind of stuck I believe that there is better handling this for this now so",
    "start": "1960180",
    "end": "1965510"
  },
  {
    "text": "what should happen is that if the agent has become unresponsive you can't do",
    "start": "1965510",
    "end": "1970770"
  },
  {
    "text": "anything else with that and eventually that task will be reported that instance isn't you can't do anything with it so",
    "start": "1970770",
    "end": "1976650"
  },
  {
    "text": "you can't can't pass health checks it can't talk to the agent so it would be",
    "start": "1976650",
    "end": "1982080"
  },
  {
    "text": "it would task would be drained off and bring back brought brought brought back",
    "start": "1982080",
    "end": "1987540"
  },
  {
    "text": "up on another instance so if your agent is stuck there's there'll be some time",
    "start": "1987540",
    "end": "1992640"
  },
  {
    "text": "when it's your agents not responding and it used to be that you'd find that out",
    "start": "1992640",
    "end": "1997890"
  },
  {
    "text": "because you'd be like well I'm pretty sure I have enough resources but you'd get a message back saying there's not enough resources it's because if the",
    "start": "1997890",
    "end": "2004580"
  },
  {
    "text": "agents can't if the Communication Service can't communicate with the agent on the box you're kind of stuck like it",
    "start": "2004580",
    "end": "2010550"
  },
  {
    "start": "2007000",
    "end": "2051000"
  },
  {
    "text": "can't report the resources back but you also can't deploy anything because it has to open that WebSocket in order to",
    "start": "2010550",
    "end": "2016340"
  },
  {
    "text": "send the request to start the new task so what I've done in the past with those is I just killed them you can't there's",
    "start": "2016340",
    "end": "2023510"
  },
  {
    "text": "no point in trying to bring it back and I'm not attached to any of them so I just kill it and replace it and that's",
    "start": "2023510",
    "end": "2029780"
  },
  {
    "text": "actually something that in the future I probably could have automated if I if I",
    "start": "2029780",
    "end": "2035150"
  },
  {
    "text": "checked for that and the agent was unresponsive after n minutes just kill the tab just kill the host",
    "start": "2035150",
    "end": "2041900"
  },
  {
    "text": "there's no point and because what am i I'd rather I'd rather have a working",
    "start": "2041900",
    "end": "2047330"
  },
  {
    "text": "agent so just let the host be replaced does anyone else have any questions",
    "start": "2047330",
    "end": "2054408"
  },
  {
    "start": "2051000",
    "end": "2184000"
  },
  {
    "text": "before we power on yes",
    "start": "2054409",
    "end": "2058869"
  },
  {
    "text": "so repeating the question back when an instance is scaled up or down because of",
    "start": "2074140",
    "end": "2080770"
  },
  {
    "text": "auto scanner like scaling rules the tasks are not set in connection draining",
    "start": "2080770",
    "end": "2086919"
  },
  {
    "text": "state they're just kind of ungracefully killed are there any plans to do",
    "start": "2086920",
    "end": "2093340"
  },
  {
    "text": "something that's not ungracefully killing that so that's a good question I",
    "start": "2093340",
    "end": "2099880"
  },
  {
    "text": "don't know off the top of my head what the what the plans are for that I can",
    "start": "2099880",
    "end": "2108130"
  },
  {
    "text": "say which is only sort of its kind of relevant but only sort of relevant like all of my answers to everything",
    "start": "2108130",
    "end": "2114100"
  },
  {
    "text": "apparently you don't really have to handle two things in your in your app so",
    "start": "2114100",
    "end": "2121050"
  },
  {
    "text": "what I found for a while through the load bouncer is that it was if I was",
    "start": "2121050",
    "end": "2126640"
  },
  {
    "text": "auto-scaling it was being it was being sent sig term correctly and then before",
    "start": "2126640",
    "end": "2134620"
  },
  {
    "text": "and and then it wasn't draining connections and then was getting sick hill and then I was like now I can't do",
    "start": "2134620",
    "end": "2141160"
  },
  {
    "text": "anything anymore so what we found is that we just had to handle both of them that it was so when",
    "start": "2141160",
    "end": "2147430"
  },
  {
    "text": "this when it was scaling up and down it was spinning sig term and then just not",
    "start": "2147430",
    "end": "2152550"
  },
  {
    "text": "draining fast enough so it looks like it's not draining connections but it actually was just draining them very",
    "start": "2152550",
    "end": "2158410"
  },
  {
    "text": "slowly and too slowly for the auto scaling rules so not a hundred percent",
    "start": "2158410",
    "end": "2164680"
  },
  {
    "text": "an answer but what you can look at is one how are you handling the signal that you're getting from the load balancer so",
    "start": "2164680",
    "end": "2171960"
  },
  {
    "text": "are you shutting down fast enough in response to that instead of waiting for sig term at which case you're kind of",
    "start": "2171960",
    "end": "2178300"
  },
  {
    "text": "effed it's videoed so I didn't think I should swear alternatively something",
    "start": "2178300",
    "end": "2186010"
  },
  {
    "start": "2184000",
    "end": "2386000"
  },
  {
    "text": "that you can look at at the load balancer level is how long have you set your connection draining time out for",
    "start": "2186010",
    "end": "2191410"
  },
  {
    "text": "and how long is your auto scaling because if your connection draining period is really long but you're trying",
    "start": "2191410",
    "end": "2197530"
  },
  {
    "text": "to autos quicker than that you might end up getting your signals a little bit confused also because your connection",
    "start": "2197530",
    "end": "2202930"
  },
  {
    "text": "draining period if it's really generous maybe maybe your instance is coming out",
    "start": "2202930",
    "end": "2209260"
  },
  {
    "text": "of service and your connection training period is still going on I'm not sure",
    "start": "2209260",
    "end": "2214630"
  },
  {
    "text": "that that's supposed to be how it works but I know that I was having a problem",
    "start": "2214630",
    "end": "2219880"
  },
  {
    "text": "where I wasn't handling sake term and sake kill quickly enough so we're",
    "start": "2219880",
    "end": "2241840"
  },
  {
    "text": "talking about the same the same behavior I think actually is that where connections are connections are going to",
    "start": "2241840",
    "end": "2247900"
  },
  {
    "text": "an instances in service and it receives sig term and connections still get sent",
    "start": "2247900",
    "end": "2253960"
  },
  {
    "text": "to it but it's already restate received sig term so the process inside the container has already stopped but",
    "start": "2253960",
    "end": "2260260"
  },
  {
    "text": "connections new connections are still being allocated that there's that gap in between your process has shut down",
    "start": "2260260",
    "end": "2266260"
  },
  {
    "text": "correctly but it has not received the signal and so it hasn't been taking out of taken out of service we've I remember",
    "start": "2266260",
    "end": "2276610"
  },
  {
    "text": "that we got around that we got around that behavior because you were having the same one and I am trying to remember",
    "start": "2276610",
    "end": "2283330"
  },
  {
    "text": "how we how we did it but I'm pretty sure it was by setting the it was by changing",
    "start": "2283330",
    "end": "2288640"
  },
  {
    "text": "the connection draining behavior at the load balancer level so it was two years ago so I'm not a hundred percent sure",
    "start": "2288640",
    "end": "2295360"
  },
  {
    "text": "that it's still either the right answer or I don't remember what I did but I do",
    "start": "2295360",
    "end": "2303490"
  },
  {
    "text": "know that not a lot of people have been looking into the connection draining settings and that is actually more helpful than it sounds because you can",
    "start": "2303490",
    "end": "2311020"
  },
  {
    "text": "customize how long you either tries to hold connections open or how long it takes to drain off the connections that",
    "start": "2311020",
    "end": "2316840"
  },
  {
    "text": "are on there so you can make that a little bit more aggressive and it will speed things up a little bit so I'd look",
    "start": "2316840",
    "end": "2323500"
  },
  {
    "text": "into that yes",
    "start": "2323500",
    "end": "2326790"
  },
  {
    "text": "so is there any easy way to make out the scaling aware of say this doesn't really",
    "start": "2343530",
    "end": "2351369"
  },
  {
    "text": "have that many facets running on it so picked up on our you know and terminate this one instead of training 50 tasks is",
    "start": "2351369",
    "end": "2358990"
  },
  {
    "text": "there any easy way around that or will the underlying ECG over scaling just work the usual way that's a great",
    "start": "2358990",
    "end": "2366730"
  },
  {
    "text": "question and I do not know oh sorry",
    "start": "2366730",
    "end": "2373050"
  },
  {
    "text": "so the question which I've already said was a good one with spoiler alert was that if with the auto scaling rules and",
    "start": "2385650",
    "end": "2395380"
  },
  {
    "start": "2386000",
    "end": "2491000"
  },
  {
    "text": "for something like bin packing where I have a custom policy around that this this instance is important to me",
    "start": "2395380",
    "end": "2401530"
  },
  {
    "text": "basically it's running many many many tasks and this instance has almost no tasks is there anything that says to the",
    "start": "2401530",
    "end": "2408280"
  },
  {
    "text": "auto scaling rules or termination protection prefer to terminate this one",
    "start": "2408280",
    "end": "2413290"
  },
  {
    "text": "first and not the one that has many copies of tasks running on it I am not",
    "start": "2413290",
    "end": "2419109"
  },
  {
    "text": "aware of a future that does that it sounds very interesting though because",
    "start": "2419109",
    "end": "2424180"
  },
  {
    "text": "it seems like it would be something that you'd want as part of just the load balancer behavior is if custom policies",
    "start": "2424180",
    "end": "2430720"
  },
  {
    "text": "exist respect to the custom policies as part of termination protection so I do",
    "start": "2430720",
    "end": "2436450"
  },
  {
    "text": "not know but I will ask because I am curious and if we don't I will ask someone if we can do it because that's",
    "start": "2436450",
    "end": "2441700"
  },
  {
    "text": "very cool yes I will figure out a way to",
    "start": "2441700",
    "end": "2447460"
  },
  {
    "text": "let you know if that happens but that was really interesting so if anyone knows I'm sure there's a way to make it",
    "start": "2447460",
    "end": "2453640"
  },
  {
    "text": "yourself that you could do it with custom cloud watch events or you could write a lambda fun",
    "start": "2453640",
    "end": "2459350"
  },
  {
    "text": "for everything there's there's totally probably a lambda function for that but",
    "start": "2459350",
    "end": "2465100"
  },
  {
    "text": "that'll be really interesting to see if it was if there was anything that would handle that as part of the load bouncer",
    "start": "2465100",
    "end": "2472070"
  },
  {
    "text": "I do know that the custom policies from ECS are fairly new as in within the last",
    "start": "2472070",
    "end": "2477830"
  },
  {
    "text": "year so it's very possible that someone's doing something that I don't know about also that's very interesting",
    "start": "2477830",
    "end": "2483760"
  },
  {
    "text": "does anyone have another question before we talk more about exciting things okay",
    "start": "2483760",
    "end": "2491650"
  },
  {
    "start": "2491000",
    "end": "2520000"
  },
  {
    "text": "as promised because I'm hosting a math class today we have some examples on how",
    "start": "2491650",
    "end": "2498500"
  },
  {
    "text": "you can filter and match on attributes and how does it pick the right instance there's not actually that much math",
    "start": "2498500",
    "end": "2504080"
  },
  {
    "text": "there's actually no math but it feels like math class so number one so if you can't see this by the way as always the",
    "start": "2504080",
    "end": "2510500"
  },
  {
    "text": "slides will be posted so I realized that the test the text is a little hard to",
    "start": "2510500",
    "end": "2515570"
  },
  {
    "text": "read so if you can't see you'll see them when they get posted so this is a CLI",
    "start": "2515570",
    "end": "2520970"
  },
  {
    "start": "2520000",
    "end": "2721000"
  },
  {
    "text": "example of how I can how I can match on this so this is just matching on one",
    "start": "2520970",
    "end": "2527270"
  },
  {
    "text": "specific attribute so my attribute is my that my instance type is anything starting with t2 and you'll see that",
    "start": "2527270",
    "end": "2533420"
  },
  {
    "text": "I've used a wildcard there so T 2 dot wildcard so anything in that t2 family",
    "start": "2533420",
    "end": "2538910"
  },
  {
    "text": "would be matched by that wildcard and I would be able to allocate my tasks that way this one I have no wildcard so it",
    "start": "2538910",
    "end": "2547160"
  },
  {
    "text": "will only match on ones that are too too small I can match with both of these together so this one t2 but only in US",
    "start": "2547160",
    "end": "2557300"
  },
  {
    "text": "east 1a and then for this one you can also pass to the list so if you don't",
    "start": "2557300",
    "end": "2563900"
  },
  {
    "text": "want to use something like a wild card if you have three separate instance types so for this one smalls or mediums",
    "start": "2563900",
    "end": "2569510"
  },
  {
    "text": "I can also pass it a list of instance types and then filter on a secondary attribute so this one would only match",
    "start": "2569510",
    "end": "2576500"
  },
  {
    "text": "on to two smalls or to two mediums that were located and available that an availability zone that was not us",
    "start": "2576500",
    "end": "2582740"
  },
  {
    "text": "East 1d custom attributes this is the",
    "start": "2582740",
    "end": "2588560"
  },
  {
    "text": "one we talked about where you could you could filter based on an or a stack so this one past an actual",
    "start": "2588560",
    "end": "2595480"
  },
  {
    "text": "target ID so go by an instance ID and then I in typical AWS fashion you can",
    "start": "2595480",
    "end": "2603910"
  },
  {
    "text": "also pass at a key value pair so the knave that the custom tag is the stacked",
    "start": "2603910",
    "end": "2609940"
  },
  {
    "text": "value is prod so I had to pass it both a name and a value so the name of my custom attribute and then the value of",
    "start": "2609940",
    "end": "2615400"
  },
  {
    "text": "that costume attribute some examples of how task placement actually works so I",
    "start": "2615400",
    "end": "2622630"
  },
  {
    "text": "am NOT going to read these whole expressions out loud because that's crazy talk but it's passing the normal",
    "start": "2622630",
    "end": "2630460"
  },
  {
    "text": "parts of my of my ECS call so run task but it's running a task but also",
    "start": "2630460",
    "end": "2635920"
  },
  {
    "text": "respecting some parameters so running a specific task it's running five of them",
    "start": "2635920",
    "end": "2641400"
  },
  {
    "text": "and then it's I'm passing this placement constraints argument is what I'm looking for here so it asked me my placement",
    "start": "2641400",
    "end": "2648640"
  },
  {
    "text": "constraints it matches a certain value of instance types and it's not in 1d so the diagram here we that's a power point",
    "start": "2648640",
    "end": "2661360"
  },
  {
    "text": "that's a cool so my dots although it has not worked as well on the projector as I anticipated",
    "start": "2661360",
    "end": "2667810"
  },
  {
    "text": "it working they are mostly making it inside the instance so we'll just pretend that they all made it inside",
    "start": "2667810",
    "end": "2673180"
  },
  {
    "text": "here I try guys so slightly easier to",
    "start": "2673180",
    "end": "2680650"
  },
  {
    "text": "follow or not less easy to follow but an example of how the agent is thinking about managing and placing these tasks",
    "start": "2680650",
    "end": "2687220"
  },
  {
    "text": "so it fits the hard restraints that it has to meet and then if you pass it the custom ones and then it distributes them",
    "start": "2687220",
    "end": "2694150"
  },
  {
    "text": "within that this one you can spread across zone and bin pack so that's the",
    "start": "2694150",
    "end": "2700090"
  },
  {
    "text": "one that I said verbally but didn't have an expression for earlier it's because it was coming later",
    "start": "2700090",
    "end": "2705130"
  },
  {
    "text": "I can spread but also bin pack while I'm spreading around zones so it ends up",
    "start": "2705130",
    "end": "2710830"
  },
  {
    "text": "looking something like this that as long as I'm meeting my criteria and spreading",
    "start": "2710830",
    "end": "2716740"
  },
  {
    "text": "or rolling the availability zones bin pack within that so you can get pretty",
    "start": "2716740",
    "end": "2722890"
  },
  {
    "start": "2721000",
    "end": "2758000"
  },
  {
    "text": "fancy on these so and again the default behavior is also fine there's no you don't unless you",
    "start": "2722890",
    "end": "2730580"
  },
  {
    "text": "know what you're doing or you know that you have custom ones that you're really that you really know that you if you",
    "start": "2730580",
    "end": "2737330"
  },
  {
    "text": "really need custom ones you definitely can do this so you can bin pack so by default it will not bin pack for you it",
    "start": "2737330",
    "end": "2743060"
  },
  {
    "text": "will spread them pretty generously across availability zones and by least number of running tasks that is totally",
    "start": "2743060",
    "end": "2750350"
  },
  {
    "text": "fine but if you want to write one of these the way that you end up doing it",
    "start": "2750350",
    "end": "2756820"
  },
  {
    "text": "so an example from the console you can work on the template so there's a couple",
    "start": "2756820",
    "end": "2763340"
  },
  {
    "start": "2758000",
    "end": "2782000"
  },
  {
    "text": "like helper functions they're so balanced within a spread of availability",
    "start": "2763340",
    "end": "2769700"
  },
  {
    "text": "zone balance within availability zones but bin packed just been packed without",
    "start": "2769700",
    "end": "2774830"
  },
  {
    "text": "respect without respect for availability zones your one task per host but also",
    "start": "2774830",
    "end": "2780740"
  },
  {
    "text": "there's custom so if I wanted to customize it I can use the helper to write my own so I can choose the order",
    "start": "2780740",
    "end": "2789290"
  },
  {
    "start": "2782000",
    "end": "2831000"
  },
  {
    "text": "that I want it to do so for this example it's spreading on availability zone then it's spreading between instances and",
    "start": "2789290",
    "end": "2796730"
  },
  {
    "text": "then it's been packing according to memory so use up all the available available memory on one instance before",
    "start": "2796730",
    "end": "2802850"
  },
  {
    "text": "going to the next instance so this will help you out pretty significantly so you can keep adding these so I have the blue",
    "start": "2802850",
    "end": "2809570"
  },
  {
    "text": "add strategy button so I pick my order of operations but this stopped at 3 if you if you want to keep adding them you",
    "start": "2809570",
    "end": "2817490"
  },
  {
    "text": "definitely can so you can really really really customize make very granular the way that the ECS agent is going to",
    "start": "2817490",
    "end": "2823850"
  },
  {
    "text": "manage and place these tasks for you so if you want to use up all of your resources if you want to spread very",
    "start": "2823850",
    "end": "2829010"
  },
  {
    "text": "carefully that is all possible a little bit on scheduling before we wrap up just",
    "start": "2829010",
    "end": "2837830"
  },
  {
    "start": "2831000",
    "end": "2841000"
  },
  {
    "text": "like your calendar for people but for tasks couple things that I can do so a",
    "start": "2837830",
    "end": "2844040"
  },
  {
    "start": "2841000",
    "end": "2933000"
  },
  {
    "text": "good production example of this would be a look would be load based scheduling so I can scale up in response to CPU",
    "start": "2844040",
    "end": "2850760"
  },
  {
    "text": "utilization and you can see that my action here instead of adding an instance is adding another task so my",
    "start": "2850760",
    "end": "2857290"
  },
  {
    "text": "CPU utilization it goes above a certain threshold add another task if it goes",
    "start": "2857290",
    "end": "2864130"
  },
  {
    "text": "way above a certain secondary threshold as two tasks add two tasks you have to",
    "start": "2864130",
    "end": "2870970"
  },
  {
    "text": "have the opposite to your rule also so you don't want to just keep recklessly adding capacity until you've eaten up",
    "start": "2870970",
    "end": "2876400"
  },
  {
    "text": "all the disk space and then you get paged so you have to add that scale down",
    "start": "2876400",
    "end": "2882550"
  },
  {
    "text": "so in this example there's a scale down one but it actually works for any task level auto scaling that you're gonna do",
    "start": "2882550",
    "end": "2888030"
  },
  {
    "text": "definitely also scale back down so if you get to the point where you're not using that extra capacity make sure you",
    "start": "2888030",
    "end": "2893800"
  },
  {
    "text": "scale down my recommendation on those would be though to leave yourself a bit of a buffer so if you scale and add one",
    "start": "2893800",
    "end": "2899410"
  },
  {
    "text": "task when your CPU is greater than 80% don't scale back down on 79% I would",
    "start": "2899410",
    "end": "2906850"
  },
  {
    "text": "leave it on maybe like 65 or 60 so that you're using a little bit of extra capacity but that you're not flapping up",
    "start": "2906850",
    "end": "2913270"
  },
  {
    "text": "and down with tasks going up and down because you don't you don't usually have like a smooth rise and Seaview all the",
    "start": "2913270",
    "end": "2918820"
  },
  {
    "text": "time maybe you have spiky CPU or maybe you have spiky memory so rather than flap up and down give",
    "start": "2918820",
    "end": "2925900"
  },
  {
    "text": "yourself a little bit of a buffer so that it's dropped again below that much lower threshold before you remove your",
    "start": "2925900",
    "end": "2930940"
  },
  {
    "text": "extra task but that works for load time based scheduling you can create",
    "start": "2930940",
    "end": "2938020"
  },
  {
    "start": "2933000",
    "end": "3161000"
  },
  {
    "text": "scheduled tasks you can run it a lot like cron jobs so in this example it's",
    "start": "2938020",
    "end": "2943330"
  },
  {
    "text": "running at a fixed interval so every 15 hours but if you really missed cron",
    "start": "2943330",
    "end": "2948400"
  },
  {
    "text": "expressions this is your moment so you could write your own cron expression which I'm assuming you then have to",
    "start": "2948400",
    "end": "2955030"
  },
  {
    "text": "Google because I have to go it every time and then it never works and then I'm like sitting there and it's like",
    "start": "2955030",
    "end": "2961380"
  },
  {
    "text": "4:00 a.m. and I'm like why don't I remember Perl and then I'm very upset about it so you can write cron",
    "start": "2961380",
    "end": "2967930"
  },
  {
    "text": "expressions alternatively you can run them at a fixed interval so in a lot of cases for people they're traditional",
    "start": "2967930",
    "end": "2974770"
  },
  {
    "text": "kind of like log rotate jobs that run at 2:00 a.m. this is a way that you could handle that without resorting to actual",
    "start": "2974770",
    "end": "2982180"
  },
  {
    "text": "cron jobs so a bunch of different options that were not just they were not just",
    "start": "2982180",
    "end": "2989560"
  },
  {
    "text": "three-tier web apps so we had some batch jobs he had time base we had load based",
    "start": "2989560",
    "end": "2995260"
  },
  {
    "text": "and no one will ever want to hear and we talk about memory and CPU ever again so",
    "start": "2995260",
    "end": "3001690"
  },
  {
    "text": "that is the end of our scheduled content if anyone has any questions I'm happy to take them now yes if it returns nothing",
    "start": "3001690",
    "end": "3025710"
  },
  {
    "text": "so the question was since I'm repeating them out loud Paul's nodding at me from the back is if",
    "start": "3030330",
    "end": "3038950"
  },
  {
    "text": "I add an usk enough custom constraints would I eventually get to a point where my results was zero so where I had no",
    "start": "3038950",
    "end": "3045910"
  },
  {
    "text": "instances that I could place my tasks on and God answer says yeah I mean I'm sure",
    "start": "3045910",
    "end": "3052450"
  },
  {
    "text": "I could add so many custom constraints that I could no longer place my tasks I wouldn't want to do that but I there's",
    "start": "3052450",
    "end": "3060370"
  },
  {
    "text": "nothing to prevent you from adding so many custom constraints that it could not place a task any more no it will it",
    "start": "3060370",
    "end": "3074500"
  },
  {
    "text": "will this is a follow up question is does the end does the agent prefer to",
    "start": "3074500",
    "end": "3080170"
  },
  {
    "text": "would it prefer to execute the task if it could drop a constraint it will not drop a constraint for you it will",
    "start": "3080170",
    "end": "3086380"
  },
  {
    "text": "continue you're basically making an informed decision but there and saying I've added all of these constraints and",
    "start": "3086380",
    "end": "3092020"
  },
  {
    "text": "when we looked at our order of operations earlier remember so after it places things like memory CPU I ops",
    "start": "3092020",
    "end": "3098110"
  },
  {
    "text": "bandwidth port stuff like that it does your custom constraints it listens to you so you're saying like every other",
    "start": "3098110",
    "end": "3104320"
  },
  {
    "text": "problem in computer science you're saying I know better and I'm telling you what to do so it's gonna it's gonna follow you so it is used at your own",
    "start": "3104320",
    "end": "3111940"
  },
  {
    "text": "risk if you've chosen to eliminate your entire pool pew which would be funny actually so please let me know if you do that does",
    "start": "3111940",
    "end": "3120749"
  },
  {
    "text": "anyone else have a question and you can ask yes so you can so repeating the",
    "start": "3120749",
    "end": "3162720"
  },
  {
    "start": "3161000",
    "end": "3250000"
  },
  {
    "text": "question is there is there anything assuming I'm understanding it right can",
    "start": "3162720",
    "end": "3168089"
  },
  {
    "text": "you do can you respond to relative changes in hope so if you've gone from 50% utilization to 90% utilization can",
    "start": "3168089",
    "end": "3175710"
  },
  {
    "text": "you add 100% capacity instead of adding a number of tasks to respond to that",
    "start": "3175710",
    "end": "3182059"
  },
  {
    "text": "I've always done it the other way so that I had multiple alarms so if my CPU",
    "start": "3182059",
    "end": "3187529"
  },
  {
    "text": "had crossed 80 then responded this way if it's crossed 95 responded this way so",
    "start": "3187529",
    "end": "3193559"
  },
  {
    "text": "I don't know if I've ever done a relative jump like that you can write",
    "start": "3193559",
    "end": "3198690"
  },
  {
    "text": "custom alarms so it's possible that you could handle some of this with a custom alarm that I don't know about but I've",
    "start": "3198690",
    "end": "3203880"
  },
  {
    "text": "always responded in by giving in a specific action in response to a",
    "start": "3203880",
    "end": "3209519"
  },
  {
    "text": "specific threshold so above this add this and you can add more than one so",
    "start": "3209519",
    "end": "3214619"
  },
  {
    "text": "you saw in my example rule that if it crossed 80% add two at a time and keep",
    "start": "3214619",
    "end": "3220380"
  },
  {
    "text": "adding two and then you can change you could change the you wanted to respond quicker you could also change the",
    "start": "3220380",
    "end": "3225440"
  },
  {
    "text": "there's that period and auto-scaling where it's like the cooldown period before it reevaluate sin response to",
    "start": "3225440",
    "end": "3231420"
  },
  {
    "text": "that rule if you find that you're in situations like that one add more copies of the task at a time in response to",
    "start": "3231420",
    "end": "3238229"
  },
  {
    "text": "that but also you can change the cooldown period so that it it really it's their rule quicker so you'd add",
    "start": "3238229",
    "end": "3243930"
  },
  {
    "text": "more capacity a little bit quicker okay oh yeah go ahead so the question",
    "start": "3243930",
    "end": "3266779"
  },
  {
    "start": "3250000",
    "end": "3373000"
  },
  {
    "text": "was how do i optimize the sizes of my you will use a docker images and my",
    "start": "3266779",
    "end": "3273130"
  },
  {
    "text": "clarifying question here is do you mean the image size or the task okay so the",
    "start": "3273130",
    "end": "3280819"
  },
  {
    "text": "resources allocated to the task I'm",
    "start": "3280819",
    "end": "3285949"
  },
  {
    "text": "gonna be thorough and also careful here and say that in general the way that",
    "start": "3285949",
    "end": "3291979"
  },
  {
    "text": "I've done this is I've started with the default or a little bit lower and ivory evaluated based on the messages that I'm",
    "start": "3291979",
    "end": "3298400"
  },
  {
    "text": "getting back so I start at kind of a reasonable default threshold and then I",
    "start": "3298400",
    "end": "3303739"
  },
  {
    "text": "look at what the utilization is so if it's a process that's running very",
    "start": "3303739",
    "end": "3308869"
  },
  {
    "text": "little and in the past they maybe would have used something like a new relic or something to look at the actual resource",
    "start": "3308869",
    "end": "3314569"
  },
  {
    "text": "usage so I would keep an eye on what it's doing and then reevaluate as I",
    "start": "3314569",
    "end": "3320719"
  },
  {
    "text": "watched logs so I generally don't fool with it until I can see how the containers actually behaving because I",
    "start": "3320719",
    "end": "3327259"
  },
  {
    "text": "don't really and I haven't I usually don't set hard limits until I know that a container behaves poorly by",
    "start": "3327259",
    "end": "3334189"
  },
  {
    "text": "taking up resources so I don't to err on the side of go with a pretty sensible",
    "start": "3334189",
    "end": "3339469"
  },
  {
    "text": "default and don't set a hard cap and then only set a hard cap if I know that",
    "start": "3339469",
    "end": "3344569"
  },
  {
    "text": "I have a process that's greedy that will take up all the resources on the box if I let it so I tend to let them kind of",
    "start": "3344569",
    "end": "3351079"
  },
  {
    "text": "self moderate until they're killing other processes for being rude",
    "start": "3351079",
    "end": "3357670"
  },
  {
    "text": "I don't think I have a hard recommendation because I think it depends on what kind of task you're",
    "start": "3361720",
    "end": "3367300"
  },
  {
    "text": "running on it so not every task is going to be the same yes so repeating the",
    "start": "3367300",
    "end": "3391450"
  },
  {
    "start": "3373000",
    "end": "3600000"
  },
  {
    "text": "question is how do you detect errors with failed tasks or ones that keep restarting because there's a problem how",
    "start": "3391450",
    "end": "3399130"
  },
  {
    "text": "do I detect that and then fail back over to an existing version that is working so part of that behavior is is inherent",
    "start": "3399130",
    "end": "3407050"
  },
  {
    "text": "in ECS so if you have a container that tries to start up and fails health checks you will never drain off connections",
    "start": "3407050",
    "end": "3413349"
  },
  {
    "text": "from that old version to go to the new version you'll stay on that old one until it can successfully pass health",
    "start": "3413349",
    "end": "3419200"
  },
  {
    "text": "checks so that eliminates part of the cases but it doesn't eliminate are the ones that starts up and then path that",
    "start": "3419200",
    "end": "3426400"
  },
  {
    "text": "passes health checks and then immediately dies for something else or it runs out of resources or it fails to",
    "start": "3426400",
    "end": "3432700"
  },
  {
    "text": "start up in the first place so answering the second part first if it tries to",
    "start": "3432700",
    "end": "3439750"
  },
  {
    "text": "start up in the past I've listened for that event so we can consume those with",
    "start": "3439750",
    "end": "3445060"
  },
  {
    "text": "cloud watch and I've listened for that event so like task revision X has failed to",
    "start": "3445060",
    "end": "3452320"
  },
  {
    "text": "deploy or whatever the exact text to that message is I've watched for that and then I've taken an action in response to that so either I have",
    "start": "3452320",
    "end": "3458680"
  },
  {
    "text": "alerted a human or I've said done a slack message in a channel to say that",
    "start": "3458680",
    "end": "3463780"
  },
  {
    "text": "you know hey your deploy is not working but you could definitely use a lambda",
    "start": "3463780",
    "end": "3469180"
  },
  {
    "text": "function or something else and take an action in response to that I've always",
    "start": "3469180",
    "end": "3475150"
  },
  {
    "text": "alerted a person because I wanted to know I wanted someone to look into it before it turned into a 3 a.m. problem",
    "start": "3475150",
    "end": "3481720"
  },
  {
    "text": "party so that's what I would do is I would watch for that message and then",
    "start": "3481720",
    "end": "3486790"
  },
  {
    "text": "have a human go look but you that's something that you can automate and a couple companies have done some really",
    "start": "3486790",
    "end": "3491980"
  },
  {
    "text": "cool scaffolding or deployments on ECS to handle cases like that",
    "start": "3491980",
    "end": "3497220"
  },
  {
    "text": "so an example that there's a nice blog post of is BuzzFeed wrote something",
    "start": "3497220",
    "end": "3503970"
  },
  {
    "text": "called rig and they had a nice post but they've basically built in a bunch of deployment logic and scaffolding around",
    "start": "3503970",
    "end": "3510269"
  },
  {
    "text": "how do I handle things like fail deployments revisions that don't work things that don't go out so a lot of",
    "start": "3510269",
    "end": "3515940"
  },
  {
    "text": "people have built that based on their own cases as for how do you I would",
    "start": "3515940",
    "end": "3521400"
  },
  {
    "text": "actually handle the resource usage the same way so I would search for the met the the part of the message during that",
    "start": "3521400",
    "end": "3527519"
  },
  {
    "text": "was like container X has been killed for memory usage I would listen for that and",
    "start": "3527519",
    "end": "3532589"
  },
  {
    "text": "I would watch for that event in the and the logs and then I would I would tell someone so that they could go back and",
    "start": "3532589",
    "end": "3538799"
  },
  {
    "text": "fix a task definition something that could be automated also but I think at least to start that's always something",
    "start": "3538799",
    "end": "3545220"
  },
  {
    "text": "that I I want to be aware of so it's not just that I'm throwing resources at a memory problem just to get the the event",
    "start": "3545220",
    "end": "3552150"
  },
  {
    "text": "to go away it's something that I want a person to say actually if that process isn't working and that's why it takes up",
    "start": "3552150",
    "end": "3558479"
  },
  {
    "text": "all the memory so short answer watch for events notify something or take an",
    "start": "3558479",
    "end": "3564299"
  },
  {
    "text": "action and response to the in response to those events",
    "start": "3564299",
    "end": "3568849"
  },
  {
    "text": "there is a VIP so repeating the question",
    "start": "3578250",
    "end": "3589089"
  },
  {
    "text": "is there some sort of event stream for these events that I can watch to know things like has been killed for memory",
    "start": "3589089",
    "end": "3595540"
  },
  {
    "text": "usage there is there is Amazon",
    "start": "3595540",
    "end": "3600609"
  },
  {
    "text": "ECS event stream for cloud watch logs which should be a bunch of the events",
    "start": "3600609",
    "end": "3606359"
  },
  {
    "text": "alternatively you can there are there are also events that you can get that",
    "start": "3606359",
    "end": "3611740"
  },
  {
    "text": "hour that are coming from the hosts themselves so there's agent logs you can get the actual dock or process logs you",
    "start": "3611740",
    "end": "3617950"
  },
  {
    "text": "can get far like messages from the host or whatever your distributions equivalent is if you have extra",
    "start": "3617950",
    "end": "3623770"
  },
  {
    "text": "information that you are not finding is being consumed by the event stream for cloud watch logs you can also get those",
    "start": "3623770",
    "end": "3631630"
  },
  {
    "text": "messages and you can either push those to cloud watch logs as well or you can send them to another logging system so",
    "start": "3631630",
    "end": "3637260"
  },
  {
    "text": "event stream should have most of the ECS specific ones so task started tasks top",
    "start": "3637260",
    "end": "3645640"
  },
  {
    "text": "those should all go to the event stream for cloud watch logs but if there's other messages or like docker process",
    "start": "3645640",
    "end": "3651580"
  },
  {
    "text": "messages you can get those from the host and I would either I would just put them to my to my logging system as well so I",
    "start": "3651580",
    "end": "3657609"
  },
  {
    "text": "could look at all of them but I'm kind of a log hoarder I think so I would probably take all of them ok awesome",
    "start": "3657609",
    "end": "3664420"
  },
  {
    "text": "well thank you so much for coming it has been exciting containers day people will be hanging out around to answer your",
    "start": "3664420",
    "end": "3670390"
  },
  {
    "text": "questions and if not enjoy the rush your evening [Applause]",
    "start": "3670390",
    "end": "3676909"
  }
]
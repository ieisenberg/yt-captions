[
  {
    "text": "all right hi folks Emily here uh in this",
    "start": "280",
    "end": "3080"
  },
  {
    "text": "video you are going to learn how to do",
    "start": "3080",
    "end": "4520"
  },
  {
    "text": "prompt engineering uh on AWS so let's",
    "start": "4520",
    "end": "7200"
  },
  {
    "text": "get",
    "start": "7200",
    "end": "8080"
  },
  {
    "text": "started all right uh so prompt",
    "start": "8080",
    "end": "11400"
  },
  {
    "text": "engineering is a really important topic",
    "start": "11400",
    "end": "13519"
  },
  {
    "text": "um it is a way to modify the performance",
    "start": "13519",
    "end": "16760"
  },
  {
    "text": "of your large language model um and",
    "start": "16760",
    "end": "19400"
  },
  {
    "text": "especially changing out the prompt is an",
    "start": "19400",
    "end": "21800"
  },
  {
    "text": "easy way to test out how your model",
    "start": "21800",
    "end": "24359"
  },
  {
    "text": "behaves in different situations so you",
    "start": "24359",
    "end": "26880"
  },
  {
    "text": "can ask your model to behave uh respons",
    "start": "26880",
    "end": "30359"
  },
  {
    "text": "you can ask your model to be a little",
    "start": "30359",
    "end": "32078"
  },
  {
    "text": "funny um you can also give uh examples",
    "start": "32079",
    "end": "36320"
  },
  {
    "text": "of what you want your model to do inside",
    "start": "36320",
    "end": "38680"
  },
  {
    "text": "of the prompt directly um all of this",
    "start": "38680",
    "end": "41200"
  },
  {
    "text": "hinges around essentially modifying the",
    "start": "41200",
    "end": "44360"
  },
  {
    "text": "string that goes into the model um and",
    "start": "44360",
    "end": "47840"
  },
  {
    "text": "then that changes essentially the",
    "start": "47840",
    "end": "49800"
  },
  {
    "text": "behavior of the model on the Fly uh",
    "start": "49800",
    "end": "52280"
  },
  {
    "text": "that's called in context learning",
    "start": "52280",
    "end": "54559"
  },
  {
    "text": "because it demonstrates the appearance",
    "start": "54559",
    "end": "56520"
  },
  {
    "text": "of the model learning without actually",
    "start": "56520",
    "end": "58359"
  },
  {
    "text": "updating uh any of the wait so let's",
    "start": "58359",
    "end": "60800"
  },
  {
    "text": "let's see what this looks",
    "start": "60800",
    "end": "62160"
  },
  {
    "text": "like so it's really helpful to think",
    "start": "62160",
    "end": "64920"
  },
  {
    "text": "about the anatomy of a prompt most",
    "start": "64920",
    "end": "67600"
  },
  {
    "text": "prompts follow the same basic flow here",
    "start": "67600",
    "end": "70640"
  },
  {
    "text": "uh prompts tend to start with guidance",
    "start": "70640",
    "end": "73720"
  },
  {
    "text": "um and guidance is highlevel information",
    "start": "73720",
    "end": "77240"
  },
  {
    "text": "um that tells the model information",
    "start": "77240",
    "end": "79080"
  },
  {
    "text": "about itself um you can give it some",
    "start": "79080",
    "end": "81600"
  },
  {
    "text": "characteristics uh I named my model",
    "start": "81600",
    "end": "84240"
  },
  {
    "text": "na'vi uh and then I asked my model to be",
    "start": "84240",
    "end": "86799"
  },
  {
    "text": "helpful courteous responsible and",
    "start": "86799",
    "end": "88840"
  },
  {
    "text": "insightful um and I also asked uh the",
    "start": "88840",
    "end": "92200"
  },
  {
    "text": "model to make references to fairies when",
    "start": "92200",
    "end": "94360"
  },
  {
    "text": "possible to keep the mood light because",
    "start": "94360",
    "end": "96680"
  },
  {
    "text": "why not um and so the guidance to The",
    "start": "96680",
    "end": "100640"
  },
  {
    "text": "Prompt here that you're providing um",
    "start": "100640",
    "end": "103320"
  },
  {
    "text": "does modify the behavior slightly I",
    "start": "103320",
    "end": "105719"
  },
  {
    "text": "would say if your model is wildly more",
    "start": "105719",
    "end": "109079"
  },
  {
    "text": "responsible or wildly less responsible",
    "start": "109079",
    "end": "111680"
  },
  {
    "text": "it's not going to change the behavior",
    "start": "111680",
    "end": "114320"
  },
  {
    "text": "dramatically but it will help modify the",
    "start": "114320",
    "end": "117000"
  },
  {
    "text": "behavior slightly so so think about the",
    "start": "117000",
    "end": "118960"
  },
  {
    "text": "guidance that you give the model um once",
    "start": "118960",
    "end": "121479"
  },
  {
    "text": "you've given the model Guidance the next",
    "start": "121479",
    "end": "123799"
  },
  {
    "text": "thing you're going to do is give it",
    "start": "123799",
    "end": "125640"
  },
  {
    "text": "context usually um the context can be",
    "start": "125640",
    "end": "129520"
  },
  {
    "text": "previous examples in the case of f shot",
    "start": "129520",
    "end": "131920"
  },
  {
    "text": "learning um where you sort of prompt the",
    "start": "131920",
    "end": "134760"
  },
  {
    "text": "model to behaving in a certain way um",
    "start": "134760",
    "end": "137400"
  },
  {
    "text": "this is really useful if you want your",
    "start": "137400",
    "end": "138959"
  },
  {
    "text": "model to do data set",
    "start": "138959",
    "end": "141760"
  },
  {
    "text": "transformation um or to do uh text to",
    "start": "141760",
    "end": "144959"
  },
  {
    "text": "SQL for example if you want to be",
    "start": "144959",
    "end": "146760"
  },
  {
    "text": "generating SQL queries um in in it's",
    "start": "146760",
    "end": "150080"
  },
  {
    "text": "also very common to send in Documents To",
    "start": "150080",
    "end": "153200"
  },
  {
    "text": "The Prompt in the form of this context",
    "start": "153200",
    "end": "155959"
  },
  {
    "text": "and then have the model essentially read",
    "start": "155959",
    "end": "158319"
  },
  {
    "text": "the document and then just answer a",
    "start": "158319",
    "end": "160400"
  },
  {
    "text": "question based on what it sees um the",
    "start": "160400",
    "end": "163319"
  },
  {
    "text": "thing to note here is that you want the",
    "start": "163319",
    "end": "164800"
  },
  {
    "text": "context uh to fit inside of the length",
    "start": "164800",
    "end": "168239"
  },
  {
    "text": "of the model so if the model's context",
    "start": "168239",
    "end": "170159"
  },
  {
    "text": "length is say 40,000 is say 4,000 tokens",
    "start": "170159",
    "end": "174519"
  },
  {
    "text": "uh as is the case of many llama models",
    "start": "174519",
    "end": "176599"
  },
  {
    "text": "um then you want to just use a shorter",
    "start": "176599",
    "end": "178400"
  },
  {
    "text": "context length uh and then the",
    "start": "178400",
    "end": "181440"
  },
  {
    "text": "instruction um is essentially where you",
    "start": "181440",
    "end": "183560"
  },
  {
    "text": "tell the model directly uh this is the",
    "start": "183560",
    "end": "185879"
  },
  {
    "text": "instruction to follow such as answer uh",
    "start": "185879",
    "end": "188120"
  },
  {
    "text": "the customer's question um and then just",
    "start": "188120",
    "end": "190599"
  },
  {
    "text": "paste in the the question here so the",
    "start": "190599",
    "end": "192879"
  },
  {
    "text": "question might be what is gudo Valley if",
    "start": "192879",
    "end": "195360"
  },
  {
    "text": "you're asking questions about the Legend",
    "start": "195360",
    "end": "197239"
  },
  {
    "text": "of Zelda uh and then here uh the model",
    "start": "197239",
    "end": "200200"
  },
  {
    "text": "tells you all about this and so um",
    "start": "200200",
    "end": "204280"
  },
  {
    "text": "that's just a quick way of thinking",
    "start": "204280",
    "end": "205840"
  },
  {
    "text": "about your prompts now let's see how we",
    "start": "205840",
    "end": "208599"
  },
  {
    "text": "can uh do this in",
    "start": "208599",
    "end": "211599"
  },
  {
    "text": "all right uh so in this demo what we are",
    "start": "211599",
    "end": "214680"
  },
  {
    "text": "going to do is connect Sage maker and",
    "start": "214680",
    "end": "217480"
  },
  {
    "text": "Lang chain uh so Lang chain is a really",
    "start": "217480",
    "end": "220200"
  },
  {
    "text": "popular open- Source library that",
    "start": "220200",
    "end": "222480"
  },
  {
    "text": "developers can use to uh connect to",
    "start": "222480",
    "end": "225400"
  },
  {
    "text": "language models and interact with them",
    "start": "225400",
    "end": "227560"
  },
  {
    "text": "but also create chains of this basically",
    "start": "227560",
    "end": "230879"
  },
  {
    "text": "create different objects in an overall",
    "start": "230879",
    "end": "233959"
  },
  {
    "text": "framework for what you want to happen um",
    "start": "233959",
    "end": "236360"
  },
  {
    "text": "so a chain can be a prompt and a",
    "start": "236360",
    "end": "238760"
  },
  {
    "text": "language model a chain can be retrieval",
    "start": "238760",
    "end": "242319"
  },
  {
    "text": "a chain can be models and then a number",
    "start": "242319",
    "end": "244599"
  },
  {
    "text": "of functions a chain can be agents um",
    "start": "244599",
    "end": "247760"
  },
  {
    "text": "and so chains is sort of a nice way to",
    "start": "247760",
    "end": "250519"
  },
  {
    "text": "think about um executing different tasks",
    "start": "250519",
    "end": "254239"
  },
  {
    "text": "throughout the overall workflow that you",
    "start": "254239",
    "end": "255840"
  },
  {
    "text": "want to accomplish uh Lang chain is",
    "start": "255840",
    "end": "258199"
  },
  {
    "text": "definitely not the only way to prompt",
    "start": "258199",
    "end": "260239"
  },
  {
    "text": "with this but it is a helpful technique",
    "start": "260239",
    "end": "262000"
  },
  {
    "text": "so we'll we'll take a look at it here",
    "start": "262000",
    "end": "263960"
  },
  {
    "text": "and this notebook really just looks at",
    "start": "263960",
    "end": "265720"
  },
  {
    "text": "the absolute minimum um for connecting",
    "start": "265720",
    "end": "268479"
  },
  {
    "text": "Sage maker to Lang chain which is this",
    "start": "268479",
    "end": "270440"
  },
  {
    "text": "component that is the model so in this",
    "start": "270440",
    "end": "273160"
  },
  {
    "text": "notebook um first we're going to import",
    "start": "273160",
    "end": "275400"
  },
  {
    "text": "a couple objects here so of course pip",
    "start": "275400",
    "end": "277160"
  },
  {
    "text": "install L chain step one and then once",
    "start": "277160",
    "end": "279800"
  },
  {
    "text": "you've done that um we're importing the",
    "start": "279800",
    "end": "281840"
  },
  {
    "text": "sage maker endpoint here so that's um",
    "start": "281840",
    "end": "285160"
  },
  {
    "text": "essentially just an object again in Lang",
    "start": "285160",
    "end": "287479"
  },
  {
    "text": "chain that's going to let you point to",
    "start": "287479",
    "end": "289120"
  },
  {
    "text": "Sag maker",
    "start": "289120",
    "end": "290560"
  },
  {
    "text": "endpoints when you're pointing to a",
    "start": "290560",
    "end": "292479"
  },
  {
    "text": "stagemaker endpoint um what you're going",
    "start": "292479",
    "end": "294880"
  },
  {
    "text": "to build is something called a Content",
    "start": "294880",
    "end": "297039"
  },
  {
    "text": "Handler and so this content Handler",
    "start": "297039",
    "end": "300280"
  },
  {
    "text": "uh is exactly what you see below and",
    "start": "300280",
    "end": "302919"
  },
  {
    "text": "essentially this is just a couple really",
    "start": "302919",
    "end": "305280"
  },
  {
    "text": "lightweight functions that help make",
    "start": "305280",
    "end": "308039"
  },
  {
    "text": "sure that the formatting is appropriate",
    "start": "308039",
    "end": "310720"
  },
  {
    "text": "both on sending content to the model and",
    "start": "310720",
    "end": "314160"
  },
  {
    "text": "getting content back from the model",
    "start": "314160",
    "end": "316600"
  },
  {
    "text": "model providers will uh build their API",
    "start": "316600",
    "end": "320080"
  },
  {
    "text": "slightly differently so sometimes like",
    "start": "320080",
    "end": "322840"
  },
  {
    "text": "this word for example sometimes this is",
    "start": "322840",
    "end": "324840"
  },
  {
    "text": "just generation sometimes it's generated",
    "start": "324840",
    "end": "327720"
  },
  {
    "text": "text um and so just make sure that you",
    "start": "327720",
    "end": "331160"
  },
  {
    "text": "uh sort of Define this function",
    "start": "331160",
    "end": "334639"
  },
  {
    "text": "appropriately a couple other objects to",
    "start": "334639",
    "end": "336680"
  },
  {
    "text": "call out um so of course Json and then",
    "start": "336680",
    "end": "339680"
  },
  {
    "text": "in line chain um we're going to use this",
    "start": "339680",
    "end": "342240"
  },
  {
    "text": "prompt template object which is a way to",
    "start": "342240",
    "end": "345440"
  },
  {
    "text": "define a string uh and then just create",
    "start": "345440",
    "end": "347800"
  },
  {
    "text": "it into a prompt so let's do this yeah",
    "start": "347800",
    "end": "351319"
  },
  {
    "text": "so so this is our our content Handler",
    "start": "351319",
    "end": "354120"
  },
  {
    "text": "again uh we're defining the content type",
    "start": "354120",
    "end": "357280"
  },
  {
    "text": "and then we're just initializing it from",
    "start": "357280",
    "end": "359199"
  },
  {
    "text": "this BAS Bas content Handler um that",
    "start": "359199",
    "end": "361479"
  },
  {
    "text": "comes in from Lang chain after that um",
    "start": "361479",
    "end": "365400"
  },
  {
    "text": "we have these two key functions here so",
    "start": "365400",
    "end": "367440"
  },
  {
    "text": "again transform import input excuse me",
    "start": "367440",
    "end": "371080"
  },
  {
    "text": "where essentially the chain is passing",
    "start": "371080",
    "end": "373800"
  },
  {
    "text": "content to this function on its way to",
    "start": "373800",
    "end": "376280"
  },
  {
    "text": "the language model and then that is",
    "start": "376280",
    "end": "378840"
  },
  {
    "text": "taking in that's taking a",
    "start": "378840",
    "end": "381280"
  },
  {
    "text": "prompt and then putting it in as this",
    "start": "381280",
    "end": "383840"
  },
  {
    "text": "key here inputs model providers might",
    "start": "383840",
    "end": "386680"
  },
  {
    "text": "use a different word there so just make",
    "start": "386680",
    "end": "389039"
  },
  {
    "text": "sure that key is correct and then",
    "start": "389039",
    "end": "391800"
  },
  {
    "text": "parameters that'll take your your",
    "start": "391800",
    "end": "393599"
  },
  {
    "text": "keyword um",
    "start": "393599",
    "end": "395560"
  },
  {
    "text": "arguments sometimes you'll have endpoint",
    "start": "395560",
    "end": "398280"
  },
  {
    "text": "arguments such as the inference",
    "start": "398280",
    "end": "400000"
  },
  {
    "text": "component name if you're hosting",
    "start": "400000",
    "end": "401400"
  },
  {
    "text": "multiple models on the same endpoint so",
    "start": "401400",
    "end": "403440"
  },
  {
    "text": "you might have more objects there um in",
    "start": "403440",
    "end": "406440"
  },
  {
    "text": "this Json key here okay so we Define",
    "start": "406440",
    "end": "409759"
  },
  {
    "text": "this input string U then we're going to",
    "start": "409759",
    "end": "411680"
  },
  {
    "text": "encode this and that's it for the",
    "start": "411680",
    "end": "413800"
  },
  {
    "text": "transform input and then the transform",
    "start": "413800",
    "end": "416120"
  },
  {
    "text": "output it's going to take what comes out",
    "start": "416120",
    "end": "419240"
  },
  {
    "text": "of the llm uh and then uh decode this",
    "start": "419240",
    "end": "424400"
  },
  {
    "text": "we'll first read it so we do output.",
    "start": "424400",
    "end": "426479"
  },
  {
    "text": "read and that kind of extracts the the",
    "start": "426479",
    "end": "429199"
  },
  {
    "text": "bytes and and converts that into",
    "start": "429199",
    "end": "430800"
  },
  {
    "text": "something that's readable in Python then",
    "start": "430800",
    "end": "432800"
  },
  {
    "text": "we're going to decode that into utf8",
    "start": "432800",
    "end": "435560"
  },
  {
    "text": "load that into Json and that's here and",
    "start": "435560",
    "end": "438639"
  },
  {
    "text": "then um again this model provider uh",
    "start": "438639",
    "end": "441840"
  },
  {
    "text": "that's just the Syntax for how they how",
    "start": "441840",
    "end": "443759"
  },
  {
    "text": "they set this up so we'll take that uh",
    "start": "443759",
    "end": "446280"
  },
  {
    "text": "and let let's let's use our template so",
    "start": "446280",
    "end": "448560"
  },
  {
    "text": "so this is an AI assistant named mixture",
    "start": "448560",
    "end": "450639"
  },
  {
    "text": "all um that same sort of guidance we saw",
    "start": "450639",
    "end": "454199"
  },
  {
    "text": "before and then uh we Define this as a",
    "start": "454199",
    "end": "457319"
  },
  {
    "text": "prompt let's just do this together so we",
    "start": "457319",
    "end": "459360"
  },
  {
    "text": "Define this as a",
    "start": "459360",
    "end": "460720"
  },
  {
    "text": "prompt and then um you'll see I'm",
    "start": "460720",
    "end": "463199"
  },
  {
    "text": "importing from Lang chain uh the prom",
    "start": "463199",
    "end": "466159"
  },
  {
    "text": "template object and then uh essentially",
    "start": "466159",
    "end": "469199"
  },
  {
    "text": "we're creating this template right here",
    "start": "469199",
    "end": "472360"
  },
  {
    "text": "then the next thing we're going to do is",
    "start": "472360",
    "end": "474159"
  },
  {
    "text": "set up the connection to the stage maker",
    "start": "474159",
    "end": "476520"
  },
  {
    "text": "endpoint so I'm using Boda 3 again Boda",
    "start": "476520",
    "end": "479759"
  },
  {
    "text": "is the uh library for working with uh aw",
    "start": "479759",
    "end": "483479"
  },
  {
    "text": "services on on AWS uh and we are using",
    "start": "483479",
    "end": "487159"
  },
  {
    "text": "the sagemaker runtime client so the",
    "start": "487159",
    "end": "490000"
  },
  {
    "text": "sagemaker runtime client is a way to",
    "start": "490000",
    "end": "492280"
  },
  {
    "text": "connect to the sagemaker endpoints",
    "start": "492280",
    "end": "494639"
  },
  {
    "text": "specifically to send things to them and",
    "start": "494639",
    "end": "496400"
  },
  {
    "text": "get responses back from them um the",
    "start": "496400",
    "end": "498840"
  },
  {
    "text": "general sagemaker client uh works for",
    "start": "498840",
    "end": "501319"
  },
  {
    "text": "the rest of the sagemaker",
    "start": "501319",
    "end": "503080"
  },
  {
    "text": "capabilities so we're going to create",
    "start": "503080",
    "end": "505080"
  },
  {
    "text": "this llm here from the sagemaker",
    "start": "505080",
    "end": "508000"
  },
  {
    "text": "endpoint object we imported from Lang",
    "start": "508000",
    "end": "510479"
  },
  {
    "text": "chain and we're just going to pass an",
    "start": "510479",
    "end": "513000"
  },
  {
    "text": "endpoint name so the endpoint name",
    "start": "513000",
    "end": "516560"
  },
  {
    "text": "you'll notice I started with right at",
    "start": "516560",
    "end": "518760"
  },
  {
    "text": "the top I created this through sag maker",
    "start": "518760",
    "end": "521880"
  },
  {
    "text": "studio um so absolutely I went through",
    "start": "521880",
    "end": "524600"
  },
  {
    "text": "the sagemaker studio UI that you saw in",
    "start": "524600",
    "end": "526720"
  },
  {
    "text": "the earlier videos um picked mix dra all",
    "start": "526720",
    "end": "529560"
  },
  {
    "text": "adx 7B and then just deployed it and",
    "start": "529560",
    "end": "532560"
  },
  {
    "text": "then once that was deployed I copy the",
    "start": "532560",
    "end": "534920"
  },
  {
    "text": "endpoint name and move that into my",
    "start": "534920",
    "end": "537200"
  },
  {
    "text": "jupyter lab notebook so that's where we",
    "start": "537200",
    "end": "539800"
  },
  {
    "text": "are great so I got my prompt",
    "start": "539800",
    "end": "542880"
  },
  {
    "text": "template and then I set up the",
    "start": "542880",
    "end": "545600"
  },
  {
    "text": "client and then the sage maker endpoint",
    "start": "545600",
    "end": "548279"
  },
  {
    "text": "here we're going to pass in that",
    "start": "548279",
    "end": "549600"
  },
  {
    "text": "endpoint name which is this and then we",
    "start": "549600",
    "end": "552519"
  },
  {
    "text": "pass in the whole boto 3 client actually",
    "start": "552519",
    "end": "556000"
  },
  {
    "text": "um and so that way you can um sort of",
    "start": "556000",
    "end": "558560"
  },
  {
    "text": "just call this uh if you're in in studio",
    "start": "558560",
    "end": "562640"
  },
  {
    "text": "um then it's nice you can just sort of",
    "start": "562640",
    "end": "564480"
  },
  {
    "text": "call the client and it captures the",
    "start": "564480",
    "end": "566320"
  },
  {
    "text": "authentication otherwise uh if you're",
    "start": "566320",
    "end": "568360"
  },
  {
    "text": "running it locally you have to to pass",
    "start": "568360",
    "end": "569800"
  },
  {
    "text": "in your region um and your uh keys in",
    "start": "569800",
    "end": "573360"
  },
  {
    "text": "order to authenticate via Bodo 3 so we",
    "start": "573360",
    "end": "576519"
  },
  {
    "text": "set up your client we're going to send",
    "start": "576519",
    "end": "578760"
  },
  {
    "text": "in uh the model keyword arguments so",
    "start": "578760",
    "end": "582480"
  },
  {
    "text": "these are parameters that you can use to",
    "start": "582480",
    "end": "584680"
  },
  {
    "text": "modify how the model behaves um so max",
    "start": "584680",
    "end": "587800"
  },
  {
    "text": "new tokens sets how many uh tokens that",
    "start": "587800",
    "end": "591120"
  },
  {
    "text": "model is going to generate for you um",
    "start": "591120",
    "end": "593640"
  },
  {
    "text": "and then you have a couple other options",
    "start": "593640",
    "end": "595600"
  },
  {
    "text": "um for again what type of generation to",
    "start": "595600",
    "end": "597959"
  },
  {
    "text": "do uh and then we pass in that content",
    "start": "597959",
    "end": "601279"
  },
  {
    "text": "Handler that we identifi that we built",
    "start": "601279",
    "end": "604480"
  },
  {
    "text": "um in that first cell so again this is",
    "start": "604480",
    "end": "606680"
  },
  {
    "text": "the mixt all Handler that we're defining",
    "start": "606680",
    "end": "609200"
  },
  {
    "text": "here and by defining this I mean really",
    "start": "609200",
    "end": "612120"
  },
  {
    "text": "I just copied it from a notebook and did",
    "start": "612120",
    "end": "614000"
  },
  {
    "text": "some minor troubleshooting to get the",
    "start": "614000",
    "end": "616000"
  },
  {
    "text": "syntax to work out once that's",
    "start": "616000",
    "end": "619519"
  },
  {
    "text": "done then you're going to do this new uh",
    "start": "619519",
    "end": "622320"
  },
  {
    "text": "Lang train expression language that they",
    "start": "622320",
    "end": "624720"
  },
  {
    "text": "set up recently so the chain is prompt",
    "start": "624720",
    "end": "629640"
  },
  {
    "text": "bar llm which is kind of cool so it's",
    "start": "629640",
    "end": "632720"
  },
  {
    "text": "this really sort of clean way of",
    "start": "632720",
    "end": "635519"
  },
  {
    "text": "creating the chain and then if you have",
    "start": "635519",
    "end": "637880"
  },
  {
    "text": "extra functions that you want to put in",
    "start": "637880",
    "end": "640000"
  },
  {
    "text": "here or if you have um like agent calls",
    "start": "640000",
    "end": "643639"
  },
  {
    "text": "or retrieval chains you would build all",
    "start": "643639",
    "end": "646040"
  },
  {
    "text": "of that here so in any case we'll build",
    "start": "646040",
    "end": "647800"
  },
  {
    "text": "the chain uh and then we're going to",
    "start": "647800",
    "end": "650000"
  },
  {
    "text": "call chain",
    "start": "650000",
    "end": "651480"
  },
  {
    "text": "invoke and so let's run this so chain",
    "start": "651480",
    "end": "655320"
  },
  {
    "text": "invoke and essentially um yeah there we",
    "start": "655320",
    "end": "658639"
  },
  {
    "text": "go great so you send in your",
    "start": "658639",
    "end": "661600"
  },
  {
    "text": "question uh and so again that's a key",
    "start": "661600",
    "end": "664279"
  },
  {
    "text": "that's specific to the model provider so",
    "start": "664279",
    "end": "666639"
  },
  {
    "text": "question and then I'm just asking in my",
    "start": "666639",
    "end": "669399"
  },
  {
    "text": "prompt are you there mraw it's me Emily",
    "start": "669399",
    "end": "672360"
  },
  {
    "text": "um and then the model responds uh of",
    "start": "672360",
    "end": "674639"
  },
  {
    "text": "course here and ready to assist you in",
    "start": "674639",
    "end": "676880"
  },
  {
    "text": "the best possible way and then uh I'm",
    "start": "676880",
    "end": "680279"
  },
  {
    "text": "going to ask mixol to tell me a joke",
    "start": "680279",
    "end": "683720"
  },
  {
    "text": "because why not",
    "start": "683720",
    "end": "687480"
  },
  {
    "text": "and uh the the joke is why don't",
    "start": "689440",
    "end": "691839"
  },
  {
    "text": "scientists trust atams because they make",
    "start": "691839",
    "end": "694120"
  },
  {
    "text": "up",
    "start": "694120",
    "end": "695720"
  },
  {
    "text": "everything and so so that's that's just",
    "start": "695720",
    "end": "698399"
  },
  {
    "text": "a primer um for getting started with",
    "start": "698399",
    "end": "701440"
  },
  {
    "text": "sage maker and Lang chain um there are",
    "start": "701440",
    "end": "704240"
  },
  {
    "text": "so many examples that line chain",
    "start": "704240",
    "end": "706440"
  },
  {
    "text": "provides that you can use um to build on",
    "start": "706440",
    "end": "709079"
  },
  {
    "text": "top of sag maker from retrieval",
    "start": "709079",
    "end": "710959"
  },
  {
    "text": "augmented generation to hosting and end",
    "start": "710959",
    "end": "713720"
  },
  {
    "text": "apps um and developing really exciting",
    "start": "713720",
    "end": "716720"
  },
  {
    "text": "content we're going to show you and walk",
    "start": "716720",
    "end": "718440"
  },
  {
    "text": "through many of those examples uh",
    "start": "718440",
    "end": "720440"
  },
  {
    "text": "throughout the series all right so I",
    "start": "720440",
    "end": "722120"
  },
  {
    "text": "hope you enjoyed the demo uh here are",
    "start": "722120",
    "end": "724320"
  },
  {
    "text": "some resources that you can use to get",
    "start": "724320",
    "end": "726160"
  },
  {
    "text": "started with prompt engineering uh on",
    "start": "726160",
    "end": "728320"
  },
  {
    "text": "AWS with sage maker today so first off",
    "start": "728320",
    "end": "730720"
  },
  {
    "text": "of course just documentation um so uh",
    "start": "730720",
    "end": "733360"
  },
  {
    "text": "the documentation talks about using",
    "start": "733360",
    "end": "735600"
  },
  {
    "text": "again uh jump start Foundation models",
    "start": "735600",
    "end": "738240"
  },
  {
    "text": "and then customizing the performance of",
    "start": "738240",
    "end": "740079"
  },
  {
    "text": "those models using prompt engineering uh",
    "start": "740079",
    "end": "742800"
  },
  {
    "text": "which we just scratch the surface of uh",
    "start": "742800",
    "end": "745560"
  },
  {
    "text": "here in the video today uh and then you",
    "start": "745560",
    "end": "747760"
  },
  {
    "text": "have a couple example note books um this",
    "start": "747760",
    "end": "750440"
  },
  {
    "text": "is a lang chain example notebook",
    "start": "750440",
    "end": "752560"
  },
  {
    "text": "actually um that shows you how to",
    "start": "752560",
    "end": "754560"
  },
  {
    "text": "integrate stag maker uh with Lang chain",
    "start": "754560",
    "end": "757440"
  },
  {
    "text": "directly and again it's also just a very",
    "start": "757440",
    "end": "760160"
  },
  {
    "text": "uh introductory content and if you like",
    "start": "760160",
    "end": "762959"
  },
  {
    "text": "um below is another uh video where you",
    "start": "762959",
    "end": "765360"
  },
  {
    "text": "can learn all about again sagemaker uh",
    "start": "765360",
    "end": "768000"
  },
  {
    "text": "and then prompt engineering on that for",
    "start": "768000",
    "end": "769880"
  },
  {
    "text": "generative AI all right so I hope you",
    "start": "769880",
    "end": "772199"
  },
  {
    "text": "enjoyed that thanks for very much bye",
    "start": "772199",
    "end": "776720"
  }
]
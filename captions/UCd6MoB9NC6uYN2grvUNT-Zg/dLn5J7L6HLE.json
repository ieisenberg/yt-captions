[
  {
    "start": "0",
    "end": "101000"
  },
  {
    "text": "okay good evening everybody welcome to the session this session is SRV 373 building",
    "start": "650",
    "end": "7649"
  },
  {
    "text": "massively parallel event-driven architecture this is a repeat of the session on Monday my name is Amit",
    "start": "7649",
    "end": "15450"
  },
  {
    "text": "Kulkarni I'm a product manager on the AWS service team and it's 6:15 so I know",
    "start": "15450",
    "end": "22380"
  },
  {
    "text": "I am probably standing between people and and the cocktail bar so dangerous place to be so we have about an hour's",
    "start": "22380",
    "end": "30750"
  },
  {
    "text": "worth of content here and the two key parts to focus on in this particular session are in the title they are",
    "start": "30750",
    "end": "39800"
  },
  {
    "text": "event-driven architectures and massively pamel so this talk is all about how do you build scalable event-driven",
    "start": "39800",
    "end": "46170"
  },
  {
    "text": "architectures and so basically we are going to set the stage on what we talk",
    "start": "46170",
    "end": "51750"
  },
  {
    "text": "about when we talk about modern service applications this is a 300 level talk so we are not going to go deep into what",
    "start": "51750",
    "end": "57090"
  },
  {
    "text": "serverless is we expect sort of all of that you guys all know that we're going",
    "start": "57090",
    "end": "62670"
  },
  {
    "text": "to talk about what are the various concepts when we talk about event doing applications how do we look at",
    "start": "62670",
    "end": "68729"
  },
  {
    "text": "architectures and various parts of it and then we're going to go deep into three main areas of an event-driven",
    "start": "68729",
    "end": "74010"
  },
  {
    "text": "architecture the generation routing and processing of events and then we're going to look into what are the some of",
    "start": "74010",
    "end": "80070"
  },
  {
    "text": "the key considerations in each of these areas to focus on finally we're going to",
    "start": "80070",
    "end": "87180"
  },
  {
    "text": "talk about we will have make up here from map box and he's going to talk",
    "start": "87180",
    "end": "92430"
  },
  {
    "text": "about their architecture from one of our esteemed customers map box and then",
    "start": "92430",
    "end": "98610"
  },
  {
    "text": "we're going to wrap it all up so with that basically these are some of the",
    "start": "98610",
    "end": "103619"
  },
  {
    "start": "101000",
    "end": "101000"
  },
  {
    "text": "four key tenets we think about when we look at serverless applications and with",
    "start": "103619",
    "end": "109229"
  },
  {
    "text": "using these tenants we bring products and services to market and make sure that customers are able to develop agile",
    "start": "109229",
    "end": "117170"
  },
  {
    "text": "serverless applications take advantage of elasticity of the cloud and be able to",
    "start": "117170",
    "end": "123119"
  },
  {
    "text": "get the lowest TCO when they're building these applications and so basically",
    "start": "123119",
    "end": "129179"
  },
  {
    "text": "today building servers applications at scale is the new norm here are some examples of customers",
    "start": "129179",
    "end": "135630"
  },
  {
    "text": "FINRA processes half a trillion transactions are stock trade validations",
    "start": "135630",
    "end": "140670"
  },
  {
    "text": "every day MLB Major League Baseball processes petabytes of data using serverless technology so these are some",
    "start": "140670",
    "end": "147690"
  },
  {
    "text": "of the examples here and a particular example of interest is is financial",
    "start": "147690",
    "end": "153150"
  },
  {
    "text": "engines it's a financial services customer and what they do is they are basically advising their clients they",
    "start": "153150",
    "end": "159600"
  },
  {
    "text": "manage close to two trillion dollars of assets and they basically have a solver",
    "start": "159600",
    "end": "165240"
  },
  {
    "text": "that they have sourced from a third party and they are trying to evaluate portfolios of customers and trying to",
    "start": "165240",
    "end": "171630"
  },
  {
    "text": "give them find optimum advice for individual portfolios and so if you look",
    "start": "171630",
    "end": "177180"
  },
  {
    "text": "at them they've been able to take this and build it at scale to go to several",
    "start": "177180",
    "end": "183060"
  },
  {
    "text": "hundred million requests per month up to sixty thousand requests a minute and while doing so they have realized the",
    "start": "183060",
    "end": "189780"
  },
  {
    "text": "benefits of server less by reducing their TCO by 90 percent or over 90",
    "start": "189780",
    "end": "195090"
  },
  {
    "text": "percent actually while basically building this highly scalable reliable architecture and so what does it take to",
    "start": "195090",
    "end": "204900"
  },
  {
    "start": "203000",
    "end": "203000"
  },
  {
    "text": "actually go build such a server less high scale architecture right and it starts off very simple the core concepts",
    "start": "204900",
    "end": "210900"
  },
  {
    "text": "here there's an event source and the events was basically signals something in the real world that that changed and",
    "start": "210900",
    "end": "217709"
  },
  {
    "text": "there's a function that processes it and then the function can interact with other systems and basically they the",
    "start": "217709",
    "end": "223590"
  },
  {
    "text": "change in the event source can basically signal a change in state of data like a",
    "start": "223590",
    "end": "229230"
  },
  {
    "text": "file being dropped into s3 or it can be an endpoint being involved by an API",
    "start": "229230",
    "end": "235290"
  },
  {
    "text": "call or it can be a change in the state of a resource like an ec2 instance being being light and then your function can",
    "start": "235290",
    "end": "244290"
  },
  {
    "text": "be in any of these languages that are out there it cannot take action on that event so now the question is like what",
    "start": "244290",
    "end": "251700"
  },
  {
    "text": "does it take to basically take such-and-such core concepts and then build us a massively parallel service",
    "start": "251700",
    "end": "258810"
  },
  {
    "text": "architecture based on that and so the key thing to think about here is in order for you to scale to really really",
    "start": "258810",
    "end": "265770"
  },
  {
    "text": "high levels you to think about it upfront and one of the sayings is that you need to engineer",
    "start": "265770",
    "end": "272430"
  },
  {
    "text": "for the bottlenecks so as we look through various parts of a service architecture we are going to look at",
    "start": "272430",
    "end": "278130"
  },
  {
    "text": "what are the specific considerations in each of these areas that you need to look at so let's first go through",
    "start": "278130",
    "end": "287120"
  },
  {
    "text": "components of our vendor architecture and look at each of the concepts in there and then evaluate what are some of",
    "start": "287120",
    "end": "293520"
  },
  {
    "text": "the considerations in each of these areas so basically there are three parts",
    "start": "293520",
    "end": "298620"
  },
  {
    "start": "296000",
    "end": "296000"
  },
  {
    "text": "to our event-driven architecture to analyze that is the event generation portion that basically talks about how",
    "start": "298620",
    "end": "303930"
  },
  {
    "text": "the what information are you omitting about a specific event there is the routing part of the architecture which",
    "start": "303930",
    "end": "310650"
  },
  {
    "text": "says how do you get the event that has been generated from the source the event source to the event processor which is",
    "start": "310650",
    "end": "317340"
  },
  {
    "text": "for example lambda and then how do you take action on that event right so it's the three State Route parts and in each",
    "start": "317340",
    "end": "324570"
  },
  {
    "start": "324000",
    "end": "324000"
  },
  {
    "text": "of these components of the architecture you have a variety of choices in terms",
    "start": "324570",
    "end": "329910"
  },
  {
    "text": "of of the AWS services that you can use so in the event generation you can have",
    "start": "329910",
    "end": "335780"
  },
  {
    "text": "s3 generate an event if you drop a file in there and there are several other such event sources and one of the event",
    "start": "335780",
    "end": "342990"
  },
  {
    "text": "sources that is not on there but it's still quite relevant for this discussion is you can generate your own events you can emit your own events and invoke",
    "start": "342990",
    "end": "349590"
  },
  {
    "text": "lambda functions from them so that's also one of the things to think about event routing the services like lambda",
    "start": "349590",
    "end": "356130"
  },
  {
    "text": "event mappings SNS sqs and we're gonna go a little deep into each of these services a little bit later and then we",
    "start": "356130",
    "end": "363720"
  },
  {
    "text": "can process these events using either lambda functions or you can run a Fargate containers server Leslie in",
    "start": "363720",
    "end": "370170"
  },
  {
    "text": "order to process these events so now in each of these areas there are different",
    "start": "370170",
    "end": "375750"
  },
  {
    "start": "373000",
    "end": "373000"
  },
  {
    "text": "considerations so when you look at the event generation you have to look at payload what is the size of the payload",
    "start": "375750",
    "end": "380850"
  },
  {
    "text": "what goes inside the payload what whether the payload itself contains all",
    "start": "380850",
    "end": "386130"
  },
  {
    "text": "the information about the event or are you going to put a pointer to the actual",
    "start": "386130",
    "end": "391380"
  },
  {
    "text": "data in that event and then should the event be persisted or should it be all in line so we're gonna go a little deep",
    "start": "391380",
    "end": "397290"
  },
  {
    "text": "into this area as well when it comes to route you want to think about what is the",
    "start": "397290",
    "end": "403289"
  },
  {
    "text": "mechanism by which the events get to the event processor whether they are delivered with a certain number of",
    "start": "403289",
    "end": "410329"
  },
  {
    "text": "certain considerations in terms of whether they are duplicate whether they",
    "start": "410329",
    "end": "415859"
  },
  {
    "text": "are delivered in a certain order whether your application is resilient to handling duplicates whether it can",
    "start": "415859",
    "end": "423059"
  },
  {
    "text": "handle events out of order and then what is the retry semantics that goes into it",
    "start": "423059",
    "end": "428989"
  },
  {
    "text": "finally when it comes to building applications for scale you're going to look at well what is the the way in what",
    "start": "428989",
    "end": "436349"
  },
  {
    "text": "is the overall throughput you can achieve by virtue of the events routing part of the architecture as well as what",
    "start": "436349",
    "end": "443009"
  },
  {
    "text": "is the overall sort of batch size and how do the events get batch from the event source to the target when it comes",
    "start": "443009",
    "end": "451019"
  },
  {
    "text": "to event processing there are all these other considerations in terms of what is the the most parallel you can go in",
    "start": "451019",
    "end": "457409"
  },
  {
    "text": "terms of concurrency of of processors what is the rate at which you go from steady-state to the top of the ramp what",
    "start": "457409",
    "end": "465689"
  },
  {
    "text": "does each individual function take in terms of its duration what what are the",
    "start": "465689",
    "end": "471389"
  },
  {
    "text": "semantics when the function succeeds then fails and then whether what is happening inside the function whether it",
    "start": "471389",
    "end": "477239"
  },
  {
    "text": "is transforming data is it using the time in the function efficiently and then as we look across all of these",
    "start": "477239",
    "end": "483299"
  },
  {
    "text": "you've got to look at the cost implications of making certain choices",
    "start": "483299",
    "end": "489079"
  },
  {
    "text": "in each of these choices at scale you need to look at what happens when when",
    "start": "489079",
    "end": "494699"
  },
  {
    "text": "you go from a really small size in terms of number of requests RPS and throughput to really really millions or billions of",
    "start": "494699",
    "end": "502259"
  },
  {
    "text": "invocations and so the question is how do we choose right how do we go about",
    "start": "502259",
    "end": "507869"
  },
  {
    "text": "making these specific choices and the answer there really depends on your application so no two applications are",
    "start": "507869",
    "end": "515129"
  },
  {
    "text": "alike in terms of of their characteristics and so for each application you need to evaluate what",
    "start": "515129",
    "end": "522059"
  },
  {
    "text": "are the rate at which my events are flowing in what are the what's the sort of inflow rate then what goes inside an",
    "start": "522059",
    "end": "530879"
  },
  {
    "text": "individual event what is the event made of what is it trying to signal what's the size of it what is the goal",
    "start": "530879",
    "end": "539100"
  },
  {
    "text": "you have in terms of your application in terms of event happening to the output being generated is this is and then the",
    "start": "539100",
    "end": "547529"
  },
  {
    "text": "question to also ask is what is the implication of falling outside that SLA so you have to understand what is the",
    "start": "547529",
    "end": "554429"
  },
  {
    "text": "impact of going one minute beyond your SLA versus 10 minutes beyond your Salif",
    "start": "554429",
    "end": "560220"
  },
  {
    "text": "if it's all the same or whether there is any cost implication in terms of of what it costs your application in order to",
    "start": "560220",
    "end": "566610"
  },
  {
    "text": "miss this SLE and then you should also look at what are the downstream dependence in my architecture do I have",
    "start": "566610",
    "end": "571679"
  },
  {
    "text": "a relational database or do I have a legacy system that the function is going",
    "start": "571679",
    "end": "576989"
  },
  {
    "text": "to call and whether it has certain rate limits to it and what implications does",
    "start": "576989",
    "end": "582329"
  },
  {
    "text": "scaling have on those downstream dependencies and then we also talked about ordering and duplicates and how",
    "start": "582329",
    "end": "588899"
  },
  {
    "text": "does the application deal with these particular aspects of event delivery and",
    "start": "588899",
    "end": "594089"
  },
  {
    "text": "finally what is the budget I have in order for building this application at scale and how do I look at meeting SLA",
    "start": "594089",
    "end": "601860"
  },
  {
    "text": "and addressing the impact curve of the SLA adherence in in light of the budget",
    "start": "601860",
    "end": "607949"
  },
  {
    "text": "I have for this application so let's go to each of the three parts of an",
    "start": "607949",
    "end": "613889"
  },
  {
    "text": "event-driven architecture and look at some examples in which we can use these criteria to to focus on what what we",
    "start": "613889",
    "end": "622350"
  },
  {
    "text": "need to engineer in order to build highly scalable systems so here's an",
    "start": "622350",
    "end": "629040"
  },
  {
    "start": "628000",
    "end": "628000"
  },
  {
    "text": "example of in the in the generation area and an event and an application and this",
    "start": "629040",
    "end": "634049"
  },
  {
    "text": "particular application generates a customer I suggest an object and there's another application as an example it",
    "start": "634049",
    "end": "639929"
  },
  {
    "text": "generates a contract file and so the two choices in which you can generate this particular event so the first choice is",
    "start": "639929",
    "end": "646980"
  },
  {
    "text": "you can inline the content so you can basically take the file or you can take the customer up there and invoke lambda",
    "start": "646980",
    "end": "653579"
  },
  {
    "text": "with all of that inline as a part of the payload and the second choice is you can",
    "start": "653579",
    "end": "660449"
  },
  {
    "text": "put all of the event data in a persistent store and then invoke lambda",
    "start": "660449",
    "end": "667259"
  },
  {
    "text": "with the pointer to that particular particular event and so there are the it",
    "start": "667259",
    "end": "673199"
  },
  {
    "text": "on face value it may just like first seem that okay choice a is better for app one and choice B is better for app",
    "start": "673199",
    "end": "679680"
  },
  {
    "text": "two but it's not really that trivial you need to look at all of these considerations when you make a decision",
    "start": "679680",
    "end": "684930"
  },
  {
    "text": "so what is the actual payload size so even if it might is a JSON object it",
    "start": "684930",
    "end": "690209"
  },
  {
    "text": "might really go to thousands of attributes and so overall you you need to understand what does it take in order",
    "start": "690209",
    "end": "696209"
  },
  {
    "text": "to serialize deserialize this event from your application what are the implications of moving a large JSON object from point to point the other",
    "start": "696209",
    "end": "704850"
  },
  {
    "text": "question is if you are storing this event in persistent storage what are the semantics of it if you are inlining it",
    "start": "704850",
    "end": "710459"
  },
  {
    "text": "they event payload is going with the event so intermediate systems that are",
    "start": "710459",
    "end": "715500"
  },
  {
    "text": "handling the event are actually containing the the payload of the event and so is that the best way for you to",
    "start": "715500",
    "end": "722670"
  },
  {
    "text": "implement your application in terms of access and control and security or do you want to put in persistent storage",
    "start": "722670",
    "end": "727740"
  },
  {
    "text": "and actually secure the the storage self so that you know who has access to the payload of the event and then what are",
    "start": "727740",
    "end": "734100"
  },
  {
    "text": "the semantics when when something goes wrong what happens when the event gets lost so if if essentially this is a",
    "start": "734100",
    "end": "740519"
  },
  {
    "text": "customer lead and the event gets lost due to some problem in in the in the",
    "start": "740519",
    "end": "746670"
  },
  {
    "text": "infrastructure then would you be okay with losing that event that customer lead or would you want to really make",
    "start": "746670",
    "end": "754290"
  },
  {
    "text": "sure that the lead is saved somewhere and it's definitely processed rather than being lost and finally there is",
    "start": "754290",
    "end": "761190"
  },
  {
    "text": "what are the scale limits of all of the component in the system so if you are storing it in the precision storage you",
    "start": "761190",
    "end": "766829"
  },
  {
    "text": "need to ensure that that that persistent storage has the ability to scale to meet",
    "start": "766829",
    "end": "772110"
  },
  {
    "text": "the needs of your application as it grows and lastly as you bring in new",
    "start": "772110",
    "end": "778199"
  },
  {
    "text": "components to your system you need to evaluate the implications of cost and complexity that it adds on to your",
    "start": "778199",
    "end": "783810"
  },
  {
    "text": "architecture so essentially the choice here really boils down to these four factors is whether what's the",
    "start": "783810",
    "end": "790500"
  },
  {
    "start": "785000",
    "end": "785000"
  },
  {
    "text": "availability cost retention and complexity implications of making that choice and so if you choose to store the",
    "start": "790500",
    "end": "798600"
  },
  {
    "text": "event for example your events can be accessible even when actually we inline the event if the",
    "start": "798600",
    "end": "806010"
  },
  {
    "text": "events gonna be accessible even if the source is down however if you store it your events are accessibility there",
    "start": "806010",
    "end": "812670"
  },
  {
    "text": "they're completely processed by your downstream processor and then also take into account considerations of it's",
    "start": "812670",
    "end": "819420"
  },
  {
    "text": "there's an extra cost if you are storing the event in terms of data storage accessing the data and transferring the",
    "start": "819420",
    "end": "825060"
  },
  {
    "text": "data between source and and the processor and finally when you're looking at all of the other components",
    "start": "825060",
    "end": "831000"
  },
  {
    "text": "that you brought into your architecture do not ignore the implications of the dependencies you have taken and the",
    "start": "831000",
    "end": "837149"
  },
  {
    "text": "complexity it adds to your architecture so when it comes to event routing",
    "start": "837149",
    "end": "843740"
  },
  {
    "start": "843000",
    "end": "843000"
  },
  {
    "text": "there's some choices here and so the simplest routing mechanism is no routing your application essentially invoke slam",
    "start": "843740",
    "end": "850589"
  },
  {
    "text": "that directly and there are two modes in which you can do this the first mode is simple synchronous invocation it's a",
    "start": "850589",
    "end": "857040"
  },
  {
    "text": "request response mechanism and the results of your invocation are available",
    "start": "857040",
    "end": "862170"
  },
  {
    "text": "immediately to your application so the simplicity is great here but in this model you as the application developer",
    "start": "862170",
    "end": "869070"
  },
  {
    "text": "are managing retries ordering error handling how do you do multi-threading and what do you do when the application",
    "start": "869070",
    "end": "876480"
  },
  {
    "text": "times out the second mode and a very popular mode in the event Devon",
    "start": "876480",
    "end": "881910"
  },
  {
    "text": "architecture is the asynchronous mode and basically this is the fire-and-forget mode where you are",
    "start": "881910",
    "end": "887430"
  },
  {
    "text": "generating the event and now you are basically gonna get the results",
    "start": "887430",
    "end": "892980"
  },
  {
    "text": "downstream and in this model you get some default capabilities from lambda you get a retries ordering dlq and",
    "start": "892980",
    "end": "900720"
  },
  {
    "text": "through and a default sort of processing throughput and you're gonna go through each of these a little in a little bit",
    "start": "900720",
    "end": "908310"
  },
  {
    "text": "on the next slide but you are still managing what do you do whenever happens like what do we how do you respond to",
    "start": "908310",
    "end": "914699"
  },
  {
    "text": "the error being being present and your application still has to deal with duplicates in this model so a lot of the",
    "start": "914699",
    "end": "920550"
  },
  {
    "text": "event sources that come with lambda are built on this a synchronous model so an example is if the application generates",
    "start": "920550",
    "end": "925709"
  },
  {
    "text": "an object in s3 and s3 triggers a lambda function it's basically having this default behavior and so what is the default",
    "start": "925709",
    "end": "933209"
  },
  {
    "start": "932000",
    "end": "932000"
  },
  {
    "text": "behavior right so here are some of the async default considerations to look at so",
    "start": "933209",
    "end": "938620"
  },
  {
    "text": "basically whenever an event whenever lambda is invoking an asynchronous mode",
    "start": "938620",
    "end": "945250"
  },
  {
    "text": "the system automatically retries twice if your application fails to process that event and it does it automatically",
    "start": "945250",
    "end": "952850"
  },
  {
    "text": "with the system defined delay and so essentially it tries the first time and then two other times and if all three",
    "start": "952850",
    "end": "959390"
  },
  {
    "text": "tries fail then the event is discarded from from lambda now what you can do is",
    "start": "959390",
    "end": "968270"
  },
  {
    "text": "on the function you can configure a dead letter Q and the dead letter Q basically",
    "start": "968270",
    "end": "973610"
  },
  {
    "text": "sends these error events the events that have not been processed after three tries to a sqs queue or as a",
    "start": "973610",
    "end": "981980"
  },
  {
    "text": "notification in the SNS stopping and if you are developing applications at scale",
    "start": "981980",
    "end": "988240"
  },
  {
    "text": "recommendation is you should turn this on so that you don't lose the events that would go that that basically are",
    "start": "988240",
    "end": "995540"
  },
  {
    "text": "not able to be processed and they have errors and then when you turn this on you need to actually monitor your dead",
    "start": "995540",
    "end": "1001150"
  },
  {
    "text": "letter K so you need on the sqs side you should monitor the queue length and set up the right alarm so that you know that",
    "start": "1001150",
    "end": "1006910"
  },
  {
    "text": "yeah ax when your application is running in prod there're sort of spiking perhaps",
    "start": "1006910",
    "end": "1012580"
  },
  {
    "text": "in a in a particular period of time and then if you are using SNS the notification should also be either",
    "start": "1012580",
    "end": "1018760"
  },
  {
    "text": "stored reliably on a persistent store or you should process it via a function and",
    "start": "1018760",
    "end": "1024130"
  },
  {
    "text": "ensure that you do get delivery of that event and finally as the as described by",
    "start": "1024130",
    "end": "1031209"
  },
  {
    "text": "the retry behavior there are duplicates so your application should be ready to handle being invoked multiple times with",
    "start": "1031209",
    "end": "1038050"
  },
  {
    "text": "the same event and so you should be dhoop in your application or have the right keys that help you identify",
    "start": "1038050",
    "end": "1043959"
  },
  {
    "text": "whether this is a duplicate invocation or the first time it's being invoked so",
    "start": "1043959",
    "end": "1049060"
  },
  {
    "start": "1048000",
    "end": "1048000"
  },
  {
    "text": "next routing pattern we're going to look at is Amazon SQS and essentially your application here inserts a message in",
    "start": "1049060",
    "end": "1055600"
  },
  {
    "text": "sqs queue and lambda is configured with excuse queue as the event source and it",
    "start": "1055600",
    "end": "1061870"
  },
  {
    "text": "automatically pulls this event source so in this model the when configure",
    "start": "1061870",
    "end": "1069970"
  },
  {
    "text": "an event source lamda will automatically pull it does long polling and tries to keep up with the rate at which events",
    "start": "1069970",
    "end": "1077200"
  },
  {
    "text": "are flowing into the queue so what you need to do is on the lamda event source",
    "start": "1077200",
    "end": "1082330"
  },
  {
    "text": "side you to set the right batch size so the way lamda works is it pulls out events in that back in those batches",
    "start": "1082330",
    "end": "1088360"
  },
  {
    "text": "from the from the queue and then based on the rate at which the events are",
    "start": "1088360",
    "end": "1093940"
  },
  {
    "text": "flowing in it ramps up the concurrency of the function and it tries to go all",
    "start": "1093940",
    "end": "1099340"
  },
  {
    "text": "the way to to a thousand so it goes either all the way to a thousand or lower if your account level limit is set",
    "start": "1099340",
    "end": "1105760"
  },
  {
    "text": "to lower than thousand or on that function you set / function concurrency but in general it tries to go up all the",
    "start": "1105760",
    "end": "1112179"
  },
  {
    "text": "way up to thousand so that you can process events that are flowing in the queue as fast as possible and then if",
    "start": "1112179",
    "end": "1119760"
  },
  {
    "text": "the if the batch succeeds if your function succeeds all the events that",
    "start": "1119760",
    "end": "1125770"
  },
  {
    "text": "are in that batch are deleted from the queue but if it fails all the messages",
    "start": "1125770",
    "end": "1131470"
  },
  {
    "text": "are written lookyou so that sort of the the semantics it you should understand on this particular feature and so what happens is if there",
    "start": "1131470",
    "end": "1140740"
  },
  {
    "text": "are failures in your batch the messages are all returned to the queue and subsequent batches we are going to retry",
    "start": "1140740",
    "end": "1146730"
  },
  {
    "text": "those messages and so a good practice over there is on the sqs queue you",
    "start": "1146730",
    "end": "1152020"
  },
  {
    "text": "should set the read drive policy and then there's a max retry limit on the on the queue once you set these two things",
    "start": "1152020",
    "end": "1159429"
  },
  {
    "text": "what happens is is that is the message is automatically sent to a a dead letter",
    "start": "1159429",
    "end": "1166720"
  },
  {
    "text": "Q that is configured on your rescues queue if it is not successfully processed after a certain number of time",
    "start": "1166720",
    "end": "1172179"
  },
  {
    "text": "so the right sort of pattern over their application wise is whenever you're processing a a batch if you're partially",
    "start": "1172179",
    "end": "1179409"
  },
  {
    "text": "succeeded if you have partially succeeded in processing some of the messages you should just go ahead and delete them in your application code so",
    "start": "1179409",
    "end": "1186070"
  },
  {
    "text": "that the subsequent message that are returned to the queue are only the failed messages and they will eventually be dead later in terms of throughput",
    "start": "1186070",
    "end": "1194710"
  },
  {
    "text": "basically SQS scales horizontal your phone on the production side so you can",
    "start": "1194710",
    "end": "1202929"
  },
  {
    "text": "generate nearly unlimited TPS based on your incoming rate and on the consumption",
    "start": "1202929",
    "end": "1209590"
  },
  {
    "text": "side basically the the rate at which you can empty the queue is a function of the",
    "start": "1209590",
    "end": "1215710"
  },
  {
    "text": "batch size the duration at that an individual function takes or individual",
    "start": "1215710",
    "end": "1222460"
  },
  {
    "text": "execution takes and the concurrency that you have set on the function so it's a function of these three particular",
    "start": "1222460",
    "end": "1227559"
  },
  {
    "text": "parameters so the next pattern you're",
    "start": "1227559",
    "end": "1234700"
  },
  {
    "text": "going to look at is SNS here the application generates a notification in the SNS topic and then lambda function",
    "start": "1234700",
    "end": "1241929"
  },
  {
    "text": "would be one of the subscribers to this particular topic so the advantage of",
    "start": "1241929",
    "end": "1247090"
  },
  {
    "text": "this is this model is a that it's a simple pub/sub model where you can now",
    "start": "1247090",
    "end": "1252640"
  },
  {
    "text": "on the consumption side fan out to millions of subscribers and so you can publish at a very extremely high rate",
    "start": "1252640",
    "end": "1259029"
  },
  {
    "text": "and deliver the notifications to a lot of consumers lambda being one of them",
    "start": "1259029",
    "end": "1265980"
  },
  {
    "text": "again in this model ordering is not guaranteed so you you need to be prepared for at least once delivery and",
    "start": "1265980",
    "end": "1274320"
  },
  {
    "text": "then there two components to delivery of the event from the SNS side to the",
    "start": "1274320",
    "end": "1280360"
  },
  {
    "text": "lambda side the first component is basically getting the message from SNS to the lambdas intake tube and that is",
    "start": "1280360",
    "end": "1289539"
  },
  {
    "text": "highly reliable yes and this will make up to fifty attempts over 12 hours and ensure really the delivery of the divine",
    "start": "1289539",
    "end": "1295059"
  },
  {
    "text": "and then once the event gets into the lambda Q it is processed with the",
    "start": "1295059",
    "end": "1300520"
  },
  {
    "text": "default behavior so this is the same async behavior that we discussed a little earlier and then from the scale",
    "start": "1300520",
    "end": "1309399"
  },
  {
    "text": "and processing perspective the one thing to look at and remember is that in this application pattern every particular",
    "start": "1309399",
    "end": "1316960"
  },
  {
    "text": "notification will generate a single invocation of lambda so if there is no",
    "start": "1316960",
    "end": "1322000"
  },
  {
    "text": "batching here in this model and so if you desire to batch events or notifications you should really put an S",
    "start": "1322000",
    "end": "1329770"
  },
  {
    "text": "qsq ahead of SNS and then",
    "start": "1329770",
    "end": "1335400"
  },
  {
    "text": "apply batch processing on that SS qsq",
    "start": "1335400",
    "end": "1341300"
  },
  {
    "text": "alright so let's go through some of the considerations when it comes to event processing so one of the things to kind",
    "start": "1343760",
    "end": "1351930"
  },
  {
    "text": "of pay attention to in the on the event processing side is the concurrency with",
    "start": "1351930",
    "end": "1356970"
  },
  {
    "text": "which you process events and here one",
    "start": "1356970",
    "end": "1362730"
  },
  {
    "text": "thing to really pay attention to that sometimes a lot of developers get stumped with is they feel the rate at",
    "start": "1362730",
    "end": "1369060"
  },
  {
    "text": "which you invoke lambda the TPS the invoke TPS is what is concurrency so",
    "start": "1369060",
    "end": "1374070"
  },
  {
    "text": "it's not really that concurrency is really how many lambda functions you have running how many instances you have",
    "start": "1374070",
    "end": "1379710"
  },
  {
    "text": "running at a single point of time and so it is essentially a cross product of the TPS and the duration for which the",
    "start": "1379710",
    "end": "1386940"
  },
  {
    "text": "function runs and estimating this is not straightforward you need to look at what",
    "start": "1386940",
    "end": "1393210"
  },
  {
    "text": "is that invoke rate for your function what is the duration of function runs and what are the distributions of these",
    "start": "1393210",
    "end": "1399630"
  },
  {
    "text": "things that at mean and at various percentiles and the thing to pay",
    "start": "1399630",
    "end": "1406500"
  },
  {
    "text": "attention to here is that if you take peak numbers for everything and you multiply them all it just gets a really",
    "start": "1406500",
    "end": "1412230"
  },
  {
    "text": "high number and so this chronic over estimation is a problem that we see all the time people suffer from when they're",
    "start": "1412230",
    "end": "1420510"
  },
  {
    "text": "trying to estimate how much concurrency they actually need when their application scales but then you also",
    "start": "1420510",
    "end": "1426780"
  },
  {
    "text": "want to guess correctly because if you guessed it wrong you are going to have it has performance implications on your",
    "start": "1426780",
    "end": "1433590"
  },
  {
    "text": "application and so a good way to to estimate concurrency is you start with your peak TPS and then you multiplied by",
    "start": "1433590",
    "end": "1442200"
  },
  {
    "text": "your average duration and so that gives you a good starting point in terms of",
    "start": "1442200",
    "end": "1447990"
  },
  {
    "text": "what is the concurrency you need when your application scales to its full level and then you should basically",
    "start": "1447990",
    "end": "1453750"
  },
  {
    "text": "start there and and run a load test and then the two metrics concurrency and",
    "start": "1453750",
    "end": "1459360"
  },
  {
    "text": "duration that you should monitor through your load test and those will give you an idea of what's the max concurrency",
    "start": "1459360",
    "end": "1464760"
  },
  {
    "text": "you actually need and in general basically you can open a support and this is the and we are we can set",
    "start": "1464760",
    "end": "1473040"
  },
  {
    "text": "the right concurrency limit for you in order for you to experiment with and just get this right and then there are",
    "start": "1473040",
    "end": "1480270"
  },
  {
    "text": "two parts to setting the concurrency there is the account level concurrency limit and this whole calculation is all",
    "start": "1480270",
    "end": "1485880"
  },
  {
    "text": "about the account concurrency limit and we are gonna just talk in a moment about what the function concurrency limit is",
    "start": "1485880",
    "end": "1492740"
  },
  {
    "text": "super functional currency it's a limit it's not a reservation this is something",
    "start": "1492740",
    "end": "1497790"
  },
  {
    "start": "1493000",
    "end": "1493000"
  },
  {
    "text": "again lots of folks get wrong it's a subtle difference but a very important difference because it really is not",
    "start": "1497790",
    "end": "1504270"
  },
  {
    "text": "reserving anything for you what it is is that it is the maximum concurrency to",
    "start": "1504270",
    "end": "1509430"
  },
  {
    "text": "which a function is allowed to scale to so the real intent of this feature is",
    "start": "1509430",
    "end": "1515310"
  },
  {
    "text": "that we want to be able to control how much a function scales so that you can protect some of the targets you have",
    "start": "1515310",
    "end": "1521760"
  },
  {
    "text": "downstream so if you are app your lambda function is accessing say a legacy",
    "start": "1521760",
    "end": "1527670"
  },
  {
    "text": "system that has a PPS limit of 20 your application scales to a thousand instances is basically going to",
    "start": "1527670",
    "end": "1533880"
  },
  {
    "text": "overwhelm that system right so you want to be able to use the / function concurrency to set the right limit on an",
    "start": "1533880",
    "end": "1540810"
  },
  {
    "text": "individual function so it does not overwhelm downstream systems the other",
    "start": "1540810",
    "end": "1546750"
  },
  {
    "text": "use of power function concurrency is it's a kill switch you can use it to",
    "start": "1546750",
    "end": "1552230"
  },
  {
    "text": "throttle or runaway function and so if you set it to zero all the instances from there onwards will will not be able",
    "start": "1552230",
    "end": "1557640"
  },
  {
    "text": "to be be generated or instantiated and so all the inverters thereafter will be",
    "start": "1557640",
    "end": "1563100"
  },
  {
    "text": "failed the other side effect of setting the per function concurrency and",
    "start": "1563100",
    "end": "1568950"
  },
  {
    "text": "probably the reason why it is being sometimes confused with reservation is",
    "start": "1568950",
    "end": "1574140"
  },
  {
    "text": "it has the effect of reducing the effective limit available for all other functions and so for example if your",
    "start": "1574140",
    "end": "1581430"
  },
  {
    "text": "account limit is set to a thousand and the two functions in green and yellow are set to a perfunctory Wondrich then",
    "start": "1581430",
    "end": "1589260"
  },
  {
    "text": "everything else in the account can only go to 700 concurrency so the the benefit",
    "start": "1589260",
    "end": "1595890"
  },
  {
    "text": "of doing this is that it prevents noisy neighbor problems so for the green and",
    "start": "1595890",
    "end": "1601260"
  },
  {
    "text": "yellow function in this there you have the room to go to the stipulated concurrency that is set on",
    "start": "1601260",
    "end": "1608639"
  },
  {
    "text": "that those functions and so the the the guideline there is is for the SLA bound",
    "start": "1608639",
    "end": "1616590"
  },
  {
    "text": "parts of your account you should set the per function concurrency and what that",
    "start": "1616590",
    "end": "1621929"
  },
  {
    "text": "lets you do is whenever your account has has unpredictable load what what you are",
    "start": "1621929",
    "end": "1630809"
  },
  {
    "text": "assured of is that those particular functions have the room to be able to go to the concurrency edge of configured",
    "start": "1630809",
    "end": "1636090"
  },
  {
    "text": "and then the other sort of guideline here is say after you set it on all the",
    "start": "1636090",
    "end": "1641399"
  },
  {
    "text": "SLA bound functions if you are running out of account level limit you should evaluate getting a limit increase and so",
    "start": "1641399",
    "end": "1647669"
  },
  {
    "text": "do the math with us open add a support case with an increase limit request if",
    "start": "1647669",
    "end": "1654029"
  },
  {
    "text": "if the sum total of all the configured per function concurrency limits is",
    "start": "1654029",
    "end": "1659309"
  },
  {
    "text": "exceeding your account or get basically in leading no Headroom for the rest of your account the next topic that is also",
    "start": "1659309",
    "end": "1668340"
  },
  {
    "start": "1666000",
    "end": "1666000"
  },
  {
    "text": "of interest here in terms of of of event",
    "start": "1668340",
    "end": "1676230"
  },
  {
    "text": "processing is velocity and so velocity is the rate at which your application scales from steady-state to its top and",
    "start": "1676230",
    "end": "1682710"
  },
  {
    "text": "so here you have three examples in the top and they are all going to a thousand concurrency and so the top one is just a",
    "start": "1682710",
    "end": "1689789"
  },
  {
    "text": "slow steady ramp up the middle one just goes from its steady state 2000",
    "start": "1689789",
    "end": "1694980"
  },
  {
    "text": "immediately and then there's a spiky workload so you really need to know which type of workload your application",
    "start": "1694980",
    "end": "1701580"
  },
  {
    "text": "is and what type of throughput goals or what type of goals you want to achieve",
    "start": "1701580",
    "end": "1706789"
  },
  {
    "text": "basically with your bit lambda and one of the key things to think about is what",
    "start": "1706789",
    "end": "1712019"
  },
  {
    "text": "is act what is the goal in terms of the rate at which the overall work needs to finish like throughput and if you have",
    "start": "1712019",
    "end": "1718619"
  },
  {
    "text": "individual goals from event occurring to the event being process so this is the event to process the latency basically",
    "start": "1718619",
    "end": "1724279"
  },
  {
    "text": "now there is a fixed predefined scale behavior that lambda has and it",
    "start": "1724279",
    "end": "1732480"
  },
  {
    "text": "basically follows a token bucket mechanism whenever your applica",
    "start": "1732480",
    "end": "1737500"
  },
  {
    "text": "invoke rate increases lambda grants you an initial bucket of concurrency and then it ramps up at a certain rate so",
    "start": "1737500",
    "end": "1744010"
  },
  {
    "text": "depending on the region when your application is trying to scale up it goes to either 500 between 500 and 3,000",
    "start": "1744010",
    "end": "1751960"
  },
  {
    "text": "concurrency immediately and then it goes at 500 a minute so the slope of the ramp",
    "start": "1751960",
    "end": "1758620"
  },
  {
    "text": "is 500 a minute and then the initial grant is really depended on the region and then the part to here think about is",
    "start": "1758620",
    "end": "1767260"
  },
  {
    "text": "what's the impact of a slower ramp on your application so generally if your",
    "start": "1767260",
    "end": "1773710"
  },
  {
    "text": "application retries backs off and retries there and it's an asynchronous",
    "start": "1773710",
    "end": "1779560"
  },
  {
    "text": "application this there's really no impact in terms of of what it would what",
    "start": "1779560",
    "end": "1785770"
  },
  {
    "text": "it on your application or end-user experience right so I really think whether these limits that are there in",
    "start": "1785770",
    "end": "1792160"
  },
  {
    "text": "terms of the ramp and in terms of the initial concurrency grant are something",
    "start": "1792160",
    "end": "1797590"
  },
  {
    "text": "that you need increased or whether that is something that you your application",
    "start": "1797590",
    "end": "1802990"
  },
  {
    "text": "is just resilient to by virtue of backing off and retrying so the last",
    "start": "1802990",
    "end": "1810100"
  },
  {
    "start": "1808000",
    "end": "1808000"
  },
  {
    "text": "topic we're going to talk about is like and the what individual function does and so your overall application scale",
    "start": "1810100",
    "end": "1818380"
  },
  {
    "text": "really just depends on on the behavior of an individual function and its profile in execution and so the right",
    "start": "1818380",
    "end": "1824530"
  },
  {
    "text": "way to think about lambda is that you should use your functions to do transforms and not really do transport",
    "start": "1824530",
    "end": "1831490"
  },
  {
    "text": "so if your function is basically simply moving bytes from place a to place B lambda is not the right solution your",
    "start": "1831490",
    "end": "1839500"
  },
  {
    "text": "your most of the time in the function is spent on waiting for IO and you're",
    "start": "1839500",
    "end": "1844510"
  },
  {
    "text": "paying by the millisecond and so you really don't want to do that the other thing in terms of scaling is batch size",
    "start": "1844510",
    "end": "1850660"
  },
  {
    "text": "matters so make sure that you have said and P when you're a batch size so that",
    "start": "1850660",
    "end": "1855910"
  },
  {
    "text": "you cannot achieve the optimum throughput and so it's a really a trade-off between concurrency how",
    "start": "1855910",
    "end": "1861870"
  },
  {
    "text": "concurrent you go versus how long an individual function runs and what's really just the right more for you in",
    "start": "1861870",
    "end": "1867610"
  },
  {
    "text": "terms of your application and here also evaluate kind of how long and",
    "start": "1867610",
    "end": "1872940"
  },
  {
    "text": "individual function runs we this year also launched a longer running function",
    "start": "1872940",
    "end": "1878430"
  },
  {
    "text": "so functions can now individually go up to 15 minutes and that's something to consider in terms of like how you do in",
    "start": "1878430",
    "end": "1885390"
  },
  {
    "text": "your batch size and Cupid the other thing to also play with is the memory",
    "start": "1885390",
    "end": "1890430"
  },
  {
    "text": "size of an individual function and so CPU that is allotted to your function is proportional to the memory size and if",
    "start": "1890430",
    "end": "1898020"
  },
  {
    "text": "you are greater than 1.8 GB in terms of memory size you also get the ability to run multiple threads and that may be",
    "start": "1898020",
    "end": "1906120"
  },
  {
    "text": "beneficial for you in your particular application and so the last yeah I'll",
    "start": "1906120",
    "end": "1911130"
  },
  {
    "text": "just make the same point I'm almost pretty much made earlier on in this slide which is in terms of lambda",
    "start": "1911130",
    "end": "1917100"
  },
  {
    "text": "whenever you are waiting for something it's not the best use of that resource",
    "start": "1917100",
    "end": "1922430"
  },
  {
    "text": "so if you are spending time just waiting for a document to be OCR or waiting for",
    "start": "1922430",
    "end": "1928710"
  },
  {
    "text": "a slow API to complete you you are you",
    "start": "1928710",
    "end": "1933930"
  },
  {
    "text": "are not really making the best use in terms of your compute dollars that that you've spent on lambda and so if you",
    "start": "1933930",
    "end": "1940080"
  },
  {
    "text": "find yourself doing orchestration in your code that's not the best use of of lambda and so you should really look",
    "start": "1940080",
    "end": "1947490"
  },
  {
    "text": "into a double your step functions which will help you orchestrate a bunch of capabilities and will give you this very",
    "start": "1947490",
    "end": "1954710"
  },
  {
    "text": "beautiful state transition diagram and you can manage orchestration using a",
    "start": "1954710",
    "end": "1961470"
  },
  {
    "text": "double step functions so with that sort of overall guideline we have a little",
    "start": "1961470",
    "end": "1967710"
  },
  {
    "text": "bit of time now for I want to bring up Mick here from map box and he's gonna",
    "start": "1967710",
    "end": "1974040"
  },
  {
    "text": "give us a real world overview of how they implement some of these",
    "start": "1974040",
    "end": "1979320"
  },
  {
    "text": "capabilities in their application",
    "start": "1979320",
    "end": "1982669"
  },
  {
    "text": "thanks a minute so yeah so as I",
    "start": "1988770",
    "end": "1998380"
  },
  {
    "text": "mentioned I'm Nick I work at matte box and so I'm gonna just use satellite",
    "start": "1998380",
    "end": "2003870"
  },
  {
    "text": "images to make this more interesting since sometimes there's not a lot of diagrams to go with this and so in in",
    "start": "2003870",
    "end": "2013500"
  },
  {
    "text": "this section what I want to do is kind of highlight like a few of the things that Amit talked about in a real-world",
    "start": "2013500",
    "end": "2018930"
  },
  {
    "text": "pipeline that we run at matte box talked about a few of our additional like use cases that we have at matte box to give",
    "start": "2018930",
    "end": "2026430"
  },
  {
    "text": "you some variety of how we use lambda at different scales and different shapes and then give you a couple things that",
    "start": "2026430",
    "end": "2032910"
  },
  {
    "text": "we've found to look out for and how we've worked around that so just a quick",
    "start": "2032910",
    "end": "2040140"
  },
  {
    "text": "introduction to matte box to set up the use case matte box is a location services company where a platform really",
    "start": "2040140",
    "end": "2048450"
  },
  {
    "text": "for applications that want to take advantage of customizing how location is",
    "start": "2048450",
    "end": "2053908"
  },
  {
    "text": "used inside their application so that can be how the map looks how its styled what's on it how do the search works how",
    "start": "2053909",
    "end": "2060898"
  },
  {
    "text": "you get directions from A to B and we have hundreds of millions of customers hundreds millions of users around the",
    "start": "2060899",
    "end": "2067770"
  },
  {
    "text": "world and this since we are predominantly an API company translates",
    "start": "2067770",
    "end": "2072780"
  },
  {
    "text": "to tens of billions of requests per day we were here at reinvents I remember",
    "start": "2072780",
    "end": "2080878"
  },
  {
    "start": "2076000",
    "end": "2076000"
  },
  {
    "text": "when lambda was first introduced we were in the audience and we were like hey we run a lot of JavaScript and this runs",
    "start": "2080879",
    "end": "2087929"
  },
  {
    "text": "JavaScript we are totally going to use this but little did we know exactly how many uses that we would find for it so",
    "start": "2087929",
    "end": "2094378"
  },
  {
    "text": "lambda has been super useful in stream processing we have a live traffic",
    "start": "2094379",
    "end": "2100920"
  },
  {
    "text": "product so when I say traffic I actually mean cars on roads and we use lambda as",
    "start": "2100920",
    "end": "2108930"
  },
  {
    "text": "part of that stream processing we use it in dynamo streams actually having like change that's from dynamic DB we've used",
    "start": "2108930",
    "end": "2117480"
  },
  {
    "text": "that to create replication from dynamodb before that was a feature API Gateway",
    "start": "2117480",
    "end": "2124770"
  },
  {
    "text": "has let us use lambda for some internal purposes for also some post hooks has",
    "start": "2124770",
    "end": "2132060"
  },
  {
    "text": "just kind of expanded expanded where we can use lambda when s3 introduced s--",
    "start": "2132060",
    "end": "2140400"
  },
  {
    "text": "event notifications that kind of it really gave us another hook where we could use lambda and you'll see that's",
    "start": "2140400",
    "end": "2149070"
  },
  {
    "text": "actually the trigger that I'll talk about in the pipeline today but this",
    "start": "2149070",
    "end": "2154349"
  },
  {
    "text": "really is it's really part of the broad ways that lambda has been increasing the",
    "start": "2154349",
    "end": "2161970"
  },
  {
    "text": "way the the different event triggers and this has made lambda more and more",
    "start": "2161970",
    "end": "2168300"
  },
  {
    "text": "useful because lambda is I I think of it as really the thing that you can use to",
    "start": "2168300",
    "end": "2176310"
  },
  {
    "text": "bring all the other resources of AWS together so sometimes that means in a",
    "start": "2176310",
    "end": "2183119"
  },
  {
    "text": "CloudFormation template if there's not a feature that's already supported by CloudFormation or if there's a feature",
    "start": "2183119",
    "end": "2189599"
  },
  {
    "text": "that we want to add because it's a resource that's actually a custom resource something that is specific to",
    "start": "2189599",
    "end": "2194820"
  },
  {
    "text": "us we add it via lambda and then scheduled events pretty much speak for themselves running things every five",
    "start": "2194820",
    "end": "2203849"
  },
  {
    "text": "minutes isn't really massive scale this is a graph of as far back as cloud watch",
    "start": "2203849",
    "end": "2212730"
  },
  {
    "start": "2207000",
    "end": "2207000"
  },
  {
    "text": "head of our lambda invocations the the takeaway here is in the about the last",
    "start": "2212730",
    "end": "2218849"
  },
  {
    "text": "13 months we've doubled our lambda usage this doesn't really go back to as far",
    "start": "2218849",
    "end": "2224670"
  },
  {
    "text": "back as I wanted it to go but we've kept steady or increasing our lambda usage",
    "start": "2224670",
    "end": "2231270"
  },
  {
    "text": "because we found it very useful and that's because we start a lot of projects in a way that I would say we",
    "start": "2231270",
    "end": "2238560"
  },
  {
    "start": "2233000",
    "end": "2233000"
  },
  {
    "text": "think in lambda what I mean by that is we start out by piecing together something is just a series of functions",
    "start": "2238560",
    "end": "2245570"
  },
  {
    "text": "and really only take that use that as like a prototyping or like a proof",
    "start": "2245570",
    "end": "2252130"
  },
  {
    "text": "on set mode sometimes that ends up being exactly where we scale up and and that",
    "start": "2252130",
    "end": "2257770"
  },
  {
    "text": "proof-of-concept turns into an actual production system sometimes we can just reuse that same code those same",
    "start": "2257770",
    "end": "2264370"
  },
  {
    "text": "functions in in another system as as we actually need different resources so",
    "start": "2264370",
    "end": "2271540"
  },
  {
    "start": "2271000",
    "end": "2271000"
  },
  {
    "text": "let's get to the actual pipeline so we can talk about some more specifics so I",
    "start": "2271540",
    "end": "2277030"
  },
  {
    "text": "want to talk about log processing one of the use cases that we have being a company with a lot of API requests is a",
    "start": "2277030",
    "end": "2285580"
  },
  {
    "text": "lot of API requests generate a lot of logs and those logs are insightful for us it helps us track usage of the",
    "start": "2285580",
    "end": "2292600"
  },
  {
    "text": "platform it helps us analyze what customers are actually doing with our product and really we only get the full",
    "start": "2292600",
    "end": "2299410"
  },
  {
    "text": "picture of that from our cloud front logs from those requests so in order to bring in those tens of billions of",
    "start": "2299410",
    "end": "2306760"
  },
  {
    "text": "requests every day and be able to do that in a quick fashion so we can also",
    "start": "2306760",
    "end": "2313060"
  },
  {
    "text": "use this for debugging for for errors and perhaps for analysis of something that's very timely we use lambda now in",
    "start": "2313060",
    "end": "2322900"
  },
  {
    "start": "2321000",
    "end": "2321000"
  },
  {
    "text": "order to actually do the Quarian of that in an interactive fashion we use AWS",
    "start": "2322900",
    "end": "2328710"
  },
  {
    "text": "athena this isn't an Athena talk so I will be brief in just highlighting this",
    "start": "2328710",
    "end": "2334570"
  },
  {
    "text": "but a couple things to know about it Athena lets you take a sequel query and",
    "start": "2334570",
    "end": "2342630"
  },
  {
    "text": "directly query files that are on s3 does this in a highly distributed fashion",
    "start": "2342630",
    "end": "2348180"
  },
  {
    "text": "enabling you to do basically interactive queries on flat files on s3 but the the",
    "start": "2348180",
    "end": "2356740"
  },
  {
    "text": "catch with Athena is in order to make it more performant and also to keep cost",
    "start": "2356740",
    "end": "2362050"
  },
  {
    "text": "down it really matters how you shape the data on s3 both in how you actually do",
    "start": "2362050",
    "end": "2368320"
  },
  {
    "text": "the key structure for that data and also in the format that the data is stored in",
    "start": "2368320",
    "end": "2373510"
  },
  {
    "text": "so that's the first step of what we want to do with cloud front logs because our",
    "start": "2373510",
    "end": "2378580"
  },
  {
    "start": "2378000",
    "end": "2378000"
  },
  {
    "text": "cloud front logs as I mentioned are tens of billions of requests per day this translates to 20 to 30 terabytes of",
    "start": "2378580",
    "end": "2387510"
  },
  {
    "text": "data per month and CloudFront delivers this on one path on s3 with not a lot of",
    "start": "2387510",
    "end": "2396170"
  },
  {
    "text": "prefixing and they delivered as gzipped tab-separated values TSVs",
    "start": "2396170",
    "end": "2403320"
  },
  {
    "text": "and that's not the optimal format for for Athena we want a little more",
    "start": "2403320",
    "end": "2409260"
  },
  {
    "text": "structure in the key space and we also want a better more optimized format for",
    "start": "2409260",
    "end": "2417000"
  },
  {
    "text": "the data but the other thing about this is not only do we have traffic patterns",
    "start": "2417000",
    "end": "2423360"
  },
  {
    "text": "just daily traffic patterns of when people are awake on certain sides of the",
    "start": "2423360",
    "end": "2428400"
  },
  {
    "text": "planet but also cloud front does like a flush at the end of the hour for any",
    "start": "2428400",
    "end": "2435900"
  },
  {
    "text": "remaining logs so we actually see up to like 3 3x spikes of that traffic now we",
    "start": "2435900",
    "end": "2442800"
  },
  {
    "text": "don't want to be provisioned - 3 X spikes all the time so one of the things",
    "start": "2442800",
    "end": "2447990"
  },
  {
    "text": "that lambda lets us do is seamlessly scale up to that now someday I hope I",
    "start": "2447990",
    "end": "2457140"
  },
  {
    "text": "come to reinvent and cloud front says hey we're just gonna deliver the logs in",
    "start": "2457140",
    "end": "2462750"
  },
  {
    "text": "the exact format that you wanted and you get to delete this but even when that",
    "start": "2462750",
    "end": "2468570"
  },
  {
    "text": "day does come eventually we do more than that we do more than just a little bit of reshaping of the data we also add our",
    "start": "2468570",
    "end": "2475470"
  },
  {
    "text": "own business logic so in lambda we take advantage of being able to parse some of the complex queries that are in there as",
    "start": "2475470",
    "end": "2483180"
  },
  {
    "text": "everyone has a lot of information baked into your URLs interior requests we",
    "start": "2483180",
    "end": "2490440"
  },
  {
    "text": "parse some of that out so downstream it's easier to query do some lookups",
    "start": "2490440",
    "end": "2495710"
  },
  {
    "text": "important thing to note here about the lookups is these can be expensive in",
    "start": "2495710",
    "end": "2501270"
  },
  {
    "text": "terms of time parsing a lot of log files in JavaScript is not the fastest and",
    "start": "2501270",
    "end": "2507810"
  },
  {
    "text": "most performant thing ever and we'll get back to costs and ways that kind of",
    "start": "2507810",
    "end": "2513330"
  },
  {
    "text": "impacts things so no AWS talk is complete without a",
    "start": "2513330",
    "end": "2521320"
  },
  {
    "start": "2515000",
    "end": "2515000"
  },
  {
    "text": "diagram of all the complex resources involved in a pipeline and while we do",
    "start": "2521320",
    "end": "2527680"
  },
  {
    "text": "definitely have pipelines that are more complex and stacks that take advantage",
    "start": "2527680",
    "end": "2533110"
  },
  {
    "text": "of many resources one of the most powerful things I think about this stack is it has so few moving parts so for",
    "start": "2533110",
    "end": "2542500"
  },
  {
    "text": "doing this log ingestion all of the logs are delivered to s3 from s3 an event",
    "start": "2542500",
    "end": "2548860"
  },
  {
    "text": "notification triggers a lambda that lambda reads that file off of s3 it does",
    "start": "2548860",
    "end": "2556390"
  },
  {
    "text": "the parsing and writes that back to s3",
    "start": "2556390",
    "end": "2561690"
  },
  {
    "start": "2562000",
    "end": "2562000"
  },
  {
    "text": "one of the things that I think also sometimes gets glossed over is just how deployment can work with lambda so and",
    "start": "2563730",
    "end": "2573580"
  },
  {
    "text": "it's important because you're going to deploy your lambda function a lot of times you want to have this be very",
    "start": "2573580",
    "end": "2580360"
  },
  {
    "text": "seamless and very fast so we use cloud formation for all of our deployments",
    "start": "2580360",
    "end": "2586750"
  },
  {
    "text": "across Matt box and in lambda we actually so when we push to github we",
    "start": "2586750",
    "end": "2594520"
  },
  {
    "text": "trigger a lambda that then triggers code build to build an artifact that actually",
    "start": "2594520",
    "end": "2599650"
  },
  {
    "text": "bundles up all of the dependencies for that function into a zip file puts that",
    "start": "2599650",
    "end": "2605770"
  },
  {
    "text": "on to s3 named with get sha in the name of that file and then a deploy is just",
    "start": "2605770",
    "end": "2612940"
  },
  {
    "text": "as simple as updating the get sha on that CloudFormation stack so really can",
    "start": "2612940",
    "end": "2620260"
  },
  {
    "text": "just streamline the entire entire process also with lambda as I looked",
    "start": "2620260",
    "end": "2627130"
  },
  {
    "start": "2623000",
    "end": "2623000"
  },
  {
    "text": "into this talk one of the things I was gonna highlight is is the actual lambda code right so for this law log",
    "start": "2627130",
    "end": "2634660"
  },
  {
    "text": "processing pipeline but you know what when I like started pulling things out of it it's just all our business logic",
    "start": "2634660",
    "end": "2641410"
  },
  {
    "text": "and that's actually a great thing because rather than a lot of",
    "start": "2641410",
    "end": "2647190"
  },
  {
    "text": "orchestration or a lot of handling of concurrency really",
    "start": "2647190",
    "end": "2653950"
  },
  {
    "text": "this is just focused on our own business logic so loading and file parsing it writing it back to s3 the one thing that",
    "start": "2653950",
    "end": "2660490"
  },
  {
    "text": "I will note here is in order to be more",
    "start": "2660490",
    "end": "2665800"
  },
  {
    "text": "efficient with resources both in terms of speed and in terms of memory we do",
    "start": "2665800",
    "end": "2671560"
  },
  {
    "text": "stream the file entirely so we use node streams so as we read the file off of s3",
    "start": "2671560",
    "end": "2677590"
  },
  {
    "text": "we're already starting to parse it where are you starting to write it before we even have read the entire file now",
    "start": "2677590",
    "end": "2686200"
  },
  {
    "start": "2684000",
    "end": "2684000"
  },
  {
    "text": "things are gonna go wrong especially if you're streaming a file parsing it and writing it back to s 3 there will be",
    "start": "2686200",
    "end": "2693070"
  },
  {
    "text": "Network interruptions to that lambda automatically gives you retries and",
    "start": "2693070",
    "end": "2699210"
  },
  {
    "text": "that's important to know so you're already going to get to retries on an",
    "start": "2699210",
    "end": "2704770"
  },
  {
    "text": "event like this so this is triggered via SMS from the s3 notification event",
    "start": "2704770",
    "end": "2711340"
  },
  {
    "text": "notification and so you get to retries maybe the first one fails that'll show",
    "start": "2711340",
    "end": "2719620"
  },
  {
    "text": "up as an error if you're looking at your lambda errors and maybe it succeeds on",
    "start": "2719620",
    "end": "2727000"
  },
  {
    "text": "the next one maybe it doesn't what's confusing there or what like the state",
    "start": "2727000",
    "end": "2733120"
  },
  {
    "text": "that you don't actually know is whether or not you're that specific file has",
    "start": "2733120",
    "end": "2738550"
  },
  {
    "text": "succeeded and this is where as Amit mentioned the dead letter Q is super",
    "start": "2738550",
    "end": "2745360"
  },
  {
    "text": "useful so especially as you're you're building things at bigger and bigger scale you're",
    "start": "2745360",
    "end": "2750790"
  },
  {
    "text": "going to have many files going through your lambda and being able to track down individual files that are causing",
    "start": "2750790",
    "end": "2756820"
  },
  {
    "text": "problems or individual being able to replay those problem files to your",
    "start": "2756820",
    "end": "2763960"
  },
  {
    "text": "lambda is gonna be really help you debug things it's also going to help you in",
    "start": "2763960",
    "end": "2770350"
  },
  {
    "text": "monitoring so as I said you might see a spike in in lambda errors but maybe all",
    "start": "2770350",
    "end": "2778540"
  },
  {
    "text": "those files actually got retried successfully but when you have a dead letter q you actually know if a",
    "start": "2778540",
    "end": "2785589"
  },
  {
    "text": "file went through all the retries and wasn't successful so you actually know",
    "start": "2785589",
    "end": "2792460"
  },
  {
    "text": "that something is wrong things are not in retried successfully not making it through your lamda now cost is just",
    "start": "2792460",
    "end": "2804119"
  },
  {
    "text": "resources times duration in lambda so you have two levers in order to bring",
    "start": "2804119",
    "end": "2809410"
  },
  {
    "text": "the cost down and as I mentioned one of the ways we do that is by keeping our",
    "start": "2809410",
    "end": "2815220"
  },
  {
    "text": "footprint a little lower so with node streams we're both trying to do things a",
    "start": "2815220",
    "end": "2821050"
  },
  {
    "text": "little bit faster by already doing some processing while the data transfer is in",
    "start": "2821050",
    "end": "2826570"
  },
  {
    "text": "process but also we're keeping a lower memory footprint so instead of having to",
    "start": "2826570",
    "end": "2832570"
  },
  {
    "text": "load the entire file in memory and have a lambda that automatically cost more because it has more resources we're able",
    "start": "2832570",
    "end": "2838390"
  },
  {
    "text": "to reduce that cost lambda does a lot of",
    "start": "2838390",
    "end": "2846220"
  },
  {
    "start": "2842000",
    "end": "2842000"
  },
  {
    "text": "the scaling work for you which is great but with great scale comes a",
    "start": "2846220",
    "end": "2851890"
  },
  {
    "text": "responsibility to your co-workers not to impact everyone else's work so I I'm",
    "start": "2851890",
    "end": "2860859"
  },
  {
    "text": "guilty of that I've definitely done that before when you have many lambdas in an",
    "start": "2860859",
    "end": "2870520"
  },
  {
    "text": "account we have thousands it can be a little bit tricky to manage those resources and what can end up happening",
    "start": "2870520",
    "end": "2876880"
  },
  {
    "text": "is you suddenly have one lambda that someone set up that gets very popular",
    "start": "2876880",
    "end": "2883540"
  },
  {
    "text": "for whatever reason and that can cause throttling across your entire account now the ways around this the ways to fix",
    "start": "2883540",
    "end": "2891070"
  },
  {
    "text": "this are one to set up resource to actually set up limits per lambda",
    "start": "2891070",
    "end": "2898030"
  },
  {
    "text": "function right so this is something that Amit mentioned before and these are they're similar to reservations in that",
    "start": "2898030",
    "end": "2906130"
  },
  {
    "text": "it actually does like to reserve a portion of your overall lamda invokes for your account and this is where you",
    "start": "2906130",
    "end": "2912849"
  },
  {
    "text": "should email Amit and get a higher limit but it also gives you so I suggest doing",
    "start": "2912849",
    "end": "2920930"
  },
  {
    "text": "that especially for functions that you want to have like an SLA around right so there's going to be very important",
    "start": "2920930",
    "end": "2926390"
  },
  {
    "text": "functions your in your account that you want to make sure I always have enough resources so setting up that reservation",
    "start": "2926390",
    "end": "2931940"
  },
  {
    "text": "for those but then also being able to track down noisy lambdas is important so",
    "start": "2931940",
    "end": "2938420"
  },
  {
    "text": "one of the things that we've built is is really just a script that goes through all lambda indications to look for",
    "start": "2938420",
    "end": "2944630"
  },
  {
    "text": "anomalies we've only had to run it a few times because we've now managed to really",
    "start": "2944630",
    "end": "2951050"
  },
  {
    "text": "bring down the concurrency of our account by using the per function limits",
    "start": "2951050",
    "end": "2957579"
  },
  {
    "text": "now another trick in order to get more",
    "start": "2960730",
    "end": "2967640"
  },
  {
    "text": "out of your lambda function and this wasn't obvious when we first started",
    "start": "2967640",
    "end": "2973160"
  },
  {
    "text": "using lambda but lambda reuses the container between invocations but not",
    "start": "2973160",
    "end": "2980690"
  },
  {
    "text": "just the container also the process so if you're writing your lambda in JavaScript and you set a global variable",
    "start": "2980690",
    "end": "2991240"
  },
  {
    "text": "that's gonna get reused actually in the next invocation possibly there's no",
    "start": "2991240",
    "end": "2997160"
  },
  {
    "text": "guarantees right because new containers are going to start your lambda is going to scale at times containers are gonna",
    "start": "2997160",
    "end": "3002920"
  },
  {
    "text": "cycle but you can take advantage of this just as lambda overall is taking advantage of this to make the service",
    "start": "3002920",
    "end": "3009610"
  },
  {
    "text": "faster you can take advantage of this by caching some data so in our log",
    "start": "3009610",
    "end": "3015070"
  },
  {
    "text": "processing we cache certain lookups to make the overall processing faster you",
    "start": "3015070",
    "end": "3022150"
  },
  {
    "text": "can also use a little bit of disk space for this too it's an option to give you some flexibility in being able to bring",
    "start": "3022150",
    "end": "3028870"
  },
  {
    "text": "down that cost now we didn't initially",
    "start": "3028870",
    "end": "3036190"
  },
  {
    "text": "use sqs based lambdas because this was a feature that was introduced earlier this",
    "start": "3036190",
    "end": "3043540"
  },
  {
    "text": "year but one of the advantages that we've seen and and why we've been",
    "start": "3043540",
    "end": "3049330"
  },
  {
    "text": "migrating so I'm just to use sqs is it gives us another lever to deal with concurrency",
    "start": "3049330",
    "end": "3056860"
  },
  {
    "text": "and spikes so if you look back at",
    "start": "3056860",
    "end": "3063340"
  },
  {
    "text": "actually just having your lambda like throttle out of certain say like a",
    "start": "3063340",
    "end": "3068680"
  },
  {
    "text": "hundred concurrency right if your language starts throttling at that throttles our errors like those events",
    "start": "3068680",
    "end": "3074860"
  },
  {
    "text": "are getting retried and and maybe if you still have enough concurrency left",
    "start": "3074860",
    "end": "3080530"
  },
  {
    "text": "they'll be retried successful maybe not they'll end up in your dead letter Q but",
    "start": "3080530",
    "end": "3085870"
  },
  {
    "text": "sqs gives you a bit more control over that concurrency in the ability to build",
    "start": "3085870",
    "end": "3092020"
  },
  {
    "text": "up a bit of a queue so if you do have just a a sudden backlog or in our case",
    "start": "3092020",
    "end": "3099280"
  },
  {
    "text": "we've used this for doing actual back fills so we want to actually load up a",
    "start": "3099280",
    "end": "3105610"
  },
  {
    "text": "lot of work and have lamda process at scale but not too much scale it can be",
    "start": "3105610",
    "end": "3111580"
  },
  {
    "text": "useful for that of course with sqs you still have the ability to set up a read",
    "start": "3111580",
    "end": "3119050"
  },
  {
    "text": "rive policy on the queue so you still have that dead letter q you also have",
    "start": "3119050",
    "end": "3124300"
  },
  {
    "text": "more control over the retries itself so instead of just two retries from lamda",
    "start": "3124300",
    "end": "3130600"
  },
  {
    "text": "you can say i want to boost that a little bit I don't want to be paged in the middle of the night I want it to",
    "start": "3130600",
    "end": "3136720"
  },
  {
    "text": "retry a couple more times so yeah we",
    "start": "3136720",
    "end": "3142630"
  },
  {
    "text": "found lambda to be very flexible product something that we were able to build a lot of different pipelines around not",
    "start": "3142630",
    "end": "3151390"
  },
  {
    "text": "only log processing I use that in as an example because it's one of the easiest",
    "start": "3151390",
    "end": "3157240"
  },
  {
    "text": "ones to fit into like a short talk but also more complex use cases that",
    "start": "3157240",
    "end": "3163300"
  },
  {
    "text": "actually involve a series of change lambdas and many more things but the",
    "start": "3163300",
    "end": "3170170"
  },
  {
    "text": "important things that we found in building those is the monitoring and and",
    "start": "3170170",
    "end": "3176050"
  },
  {
    "text": "error reporting like I still can't emphasize dlq enough I'm sure though you",
    "start": "3176050",
    "end": "3181540"
  },
  {
    "text": "disagree cuz I've said that a lot and then the other important thing that",
    "start": "3181540",
    "end": "3186830"
  },
  {
    "text": "I would say is a good takeaway here is lambda can become an expensive product",
    "start": "3186830",
    "end": "3194390"
  },
  {
    "text": "if you use it in the right ways it can be very cheap fast way to iterate on",
    "start": "3194390",
    "end": "3200390"
  },
  {
    "text": "code but at the same time if you just crank up all the resources and do things",
    "start": "3200390",
    "end": "3207440"
  },
  {
    "text": "that have long durations it's not as as cheap as other ways of doing compute and",
    "start": "3207440",
    "end": "3214610"
  },
  {
    "text": "with that all pass it back to Amit Thank",
    "start": "3214610",
    "end": "3228950"
  },
  {
    "text": "You Mick what an exciting use case they have here so whether it be like mapping the world whether it be doing trillions",
    "start": "3228950",
    "end": "3236150"
  },
  {
    "text": "of stock trade validations you can build serverless applications at scale on AWS",
    "start": "3236150",
    "end": "3242570"
  },
  {
    "text": "and we have a rich portfolio of services on AWS that helps you build this",
    "start": "3242570",
    "end": "3247820"
  },
  {
    "text": "particular sort of applications and it is a world full of choices so really",
    "start": "3247820",
    "end": "3253790"
  },
  {
    "text": "what you need to do is to make the right choice in terms of the right tool for the job and basically what the right way",
    "start": "3253790",
    "end": "3264050"
  },
  {
    "text": "to build scalable systems is to just go part by part in your architecture and look at the three major areas of",
    "start": "3264050",
    "end": "3270430"
  },
  {
    "text": "generation routing and processing and go through the considerations on each of",
    "start": "3270430",
    "end": "3275450"
  },
  {
    "text": "these areas in order to identify well what are the likely pitfalls that you might run into",
    "start": "3275450",
    "end": "3281060"
  },
  {
    "text": "and then finally service pricing makes it easy you can experiment a bit and",
    "start": "3281060",
    "end": "3287300"
  },
  {
    "text": "then if you get it wrong the cost of retrying and overhauling is not really that much so you can really try tweak",
    "start": "3287300",
    "end": "3295760"
  },
  {
    "text": "clear up your architecture and deploy it over and over again if you can predict something it will just shorten your",
    "start": "3295760",
    "end": "3301270"
  },
  {
    "text": "overall cycle but if not you should just relax and and try to basically figure it",
    "start": "3301270",
    "end": "3308510"
  },
  {
    "text": "out as your application scales so with that this is the last breakout repeat of",
    "start": "3308510",
    "end": "3314720"
  },
  {
    "start": "3311000",
    "end": "3311000"
  },
  {
    "text": "this session and the other session I highly recommend everybody go - is this",
    "start": "3314720",
    "end": "3320090"
  },
  {
    "start": "3316000",
    "end": "3316000"
  },
  {
    "text": "leadership session and this will just give you an overview of the serverless landscape how we are thinking about",
    "start": "3320090",
    "end": "3325910"
  },
  {
    "text": "serve on less on AWS and what are some of the innovations that that that are in the pipeline and so this is tomorrow at",
    "start": "3325910",
    "end": "3334220"
  },
  {
    "text": "noon in the Venetian theater and you will see some of our leaders come out there and and just gives an overall lay",
    "start": "3334220",
    "end": "3340640"
  },
  {
    "text": "of the land here with that thank you so much for attending this session and here",
    "start": "3340640",
    "end": "3348440"
  },
  {
    "text": "is our contact information do let us know if there is something we can answer and definitely complete the mobile",
    "start": "3348440",
    "end": "3355670"
  },
  {
    "text": "survey and we'll be here a few more minutes after the talk if you if you want to chat with us",
    "start": "3355670",
    "end": "3361800"
  },
  {
    "text": "[Applause]",
    "start": "3361800",
    "end": "3364550"
  }
]
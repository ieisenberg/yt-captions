[
  {
    "start": "0",
    "end": "16000"
  },
  {
    "text": "hello everyone well hope you have been having a great dream win so far let's",
    "start": "60",
    "end": "9240"
  },
  {
    "text": "make it a notch better with a cool session on building log analytic solutions on AWS my name is preneur",
    "start": "9240",
    "end": "16949"
  },
  {
    "text": "number I'm a senior manager on AWS also I have with me Tommy Lee who is a senior",
    "start": "16949",
    "end": "24810"
  },
  {
    "text": "software architect at Autodesk together we're gonna talk to you about various",
    "start": "24810",
    "end": "30330"
  },
  {
    "text": "factors you need to consider as you think of building a log analytic solution our goal is to provide you",
    "start": "30330",
    "end": "37020"
  },
  {
    "text": "enough insights so that you can make informed decisions as you think about log analytics at scale or if you have",
    "start": "37020",
    "end": "44550"
  },
  {
    "text": "packed the session with a lot of content and so we won't have time for a Q&A in this one hour have a word both Tommy and",
    "start": "44550",
    "end": "51300"
  },
  {
    "text": "I will be around after the session so in case you have questions hold on to them and we can answer them for you separately sounds good so are you all",
    "start": "51300",
    "end": "60629"
  },
  {
    "text": "ready to get started awesome okay so let's get started I",
    "start": "60629",
    "end": "66960"
  },
  {
    "text": "thought the best way to get started would be to just talk about some of the key situations we face while dealing",
    "start": "66960",
    "end": "73380"
  },
  {
    "start": "67000",
    "end": "111000"
  },
  {
    "text": "with logs let's have a show of hands how many of you have dealt with situations where you actually fail you don't have",
    "start": "73380",
    "end": "79860"
  },
  {
    "text": "enough data or logs to solve a problem well pretty much all of you absolutely",
    "start": "79860",
    "end": "85770"
  },
  {
    "text": "right all of us have been in that situation and how do we respond to that the instinctive reaction is open up the",
    "start": "85770",
    "end": "93540"
  },
  {
    "text": "floodgates let's log everything let's make sure we don't have any case where we don't have data that's literally what",
    "start": "93540",
    "end": "100470"
  },
  {
    "text": "most of us do just log just keep logging stories doesn't cost as much so let's have answers ready but that brings us to",
    "start": "100470",
    "end": "108600"
  },
  {
    "text": "a new situation let's have a show of hands how many of you have dealt with",
    "start": "108600",
    "end": "113670"
  },
  {
    "start": "111000",
    "end": "126000"
  },
  {
    "text": "situations where you feel you have a lot of data but you really don't know if you're putting it to good use",
    "start": "113670",
    "end": "119420"
  },
  {
    "text": "okay pretty much all of you again right let's let's look at it once the deeper",
    "start": "119420",
    "end": "127439"
  },
  {
    "text": "frankly when you build any solution events a simple website you've got a lot of different components",
    "start": "127439",
    "end": "133230"
  },
  {
    "text": "when you go with the strategy of logging everything logs can pile up easily it's",
    "start": "133230",
    "end": "138780"
  },
  {
    "text": "going to be much more difficult to handle it until and unless you have a clear efficient log analytic solution",
    "start": "138780",
    "end": "146090"
  },
  {
    "text": "that brings up to our next situation how many of you have actually wondered are",
    "start": "146090",
    "end": "152280"
  },
  {
    "start": "150000",
    "end": "168000"
  },
  {
    "text": "you really operating efficiently with your logs I'm sure pretty much all of you the heads nodding here and there this is the",
    "start": "152280",
    "end": "158760"
  },
  {
    "text": "core situation that we face mostly because these days when it comes to logs people are figuring out ways to do log",
    "start": "158760",
    "end": "164700"
  },
  {
    "text": "analytics but it's not always the more efficient solution let's face it when you look at logs",
    "start": "164700",
    "end": "170459"
  },
  {
    "start": "168000",
    "end": "195000"
  },
  {
    "text": "here's a typical you know HTTP web server log it's not easy to digest a log",
    "start": "170459",
    "end": "177660"
  },
  {
    "text": "it's on structure and think of it at a very high volume what happens it's not easy to process it you could follow a",
    "start": "177660",
    "end": "184680"
  },
  {
    "text": "traditional approach you could run your grip commands or your scripts and process it take hours it's possible that",
    "start": "184680",
    "end": "190620"
  },
  {
    "text": "you make errors in that even a small spelling mistake would actually cause issues or you could actually use a",
    "start": "190620",
    "end": "196440"
  },
  {
    "start": "195000",
    "end": "222000"
  },
  {
    "text": "smarter approach you could use a product like Amazon Elastic search service and actually build you know more information",
    "start": "196440",
    "end": "203850"
  },
  {
    "text": "as parts you have a better programmatic interface to actually get insights at your fingerprint or fingertips in real",
    "start": "203850",
    "end": "210630"
  },
  {
    "text": "time so this session is all about the smarter solution it's about what you can",
    "start": "210630",
    "end": "217950"
  },
  {
    "text": "do with Amazon Elastic search service and what are the things that you need to note so what I'm gonna do is I'm going",
    "start": "217950",
    "end": "224190"
  },
  {
    "start": "222000",
    "end": "258000"
  },
  {
    "text": "to start off by giving you a high-level overview of Amazon Elastic search service we won't dive too deep into that",
    "start": "224190",
    "end": "229950"
  },
  {
    "text": "but we'll focus more on the factors you need to focus on while you're building",
    "start": "229950",
    "end": "235350"
  },
  {
    "text": "log analytic solutions and then we'll have Tommy who's going to come over and tell you about the Autodesk story",
    "start": "235350",
    "end": "241950"
  },
  {
    "text": "they've been through a similar process to where and you know you have a lot of data and how do you operate efficiently",
    "start": "241950",
    "end": "247230"
  },
  {
    "text": "and he's going to talk about all the insights they have gained from Autodesk to actually you know in terms of while",
    "start": "247230",
    "end": "253829"
  },
  {
    "text": "to build their log analytic solution so let's get started we start with the",
    "start": "253829",
    "end": "258959"
  },
  {
    "start": "258000",
    "end": "271000"
  },
  {
    "text": "first main question what is Amazon Elastic search service so I'm sure most",
    "start": "258959",
    "end": "264599"
  },
  {
    "text": "of you are familiar with the elastic search as such elastic search is a popular open source solution for both log analytics and",
    "start": "264599",
    "end": "270930"
  },
  {
    "text": "full-text search Amazon elastic search service offers you a fully managed solution around that it takes care of",
    "start": "270930",
    "end": "278040"
  },
  {
    "start": "271000",
    "end": "361000"
  },
  {
    "text": "the heavy lifting around deploying scaling and managing elastic search and",
    "start": "278040",
    "end": "283290"
  },
  {
    "text": "Cabana so that you can focus on your log analytic solution there are a number of",
    "start": "283290",
    "end": "289290"
  },
  {
    "text": "benefits of Amazon elastic search service first of all it's easy to use you can literally get started in minutes",
    "start": "289290",
    "end": "295740"
  },
  {
    "text": "you know just a few clicks you can get a cluster start to set up and you can ingest data and get going it's also",
    "start": "295740",
    "end": "301530"
  },
  {
    "text": "highly scalable the number of instance choices that you have we'll talk about it in a bit you also can easily scale up",
    "start": "301530",
    "end": "309510"
  },
  {
    "text": "or scale down depending on your workload situation it's also secure the number of",
    "start": "309510",
    "end": "315270"
  },
  {
    "text": "security features we'll touch upon a few key ones you have I am your VP C of encryption at rest and in transit the",
    "start": "315270",
    "end": "321690"
  },
  {
    "text": "number of different options it's also highly available it offers you a cross",
    "start": "321690",
    "end": "328260"
  },
  {
    "text": "zone replication so even if a zone goes down you still have availability it also takes care of automatic failure",
    "start": "328260",
    "end": "334410"
  },
  {
    "text": "recovery from hardware failures it's open source compatible with your open source api's so even if you are using",
    "start": "334410",
    "end": "340760"
  },
  {
    "text": "self manny's elasticsearch you can easily lift and shift it to Amazon Elastic search service and last but not",
    "start": "340760",
    "end": "348150"
  },
  {
    "text": "the least it works well with several other Amazon services and so it's easy",
    "start": "348150",
    "end": "354419"
  },
  {
    "text": "for you to ingest data or get it into Amazon Elastic search service and run analytics on it the number of use cases",
    "start": "354419",
    "end": "362520"
  },
  {
    "start": "361000",
    "end": "400000"
  },
  {
    "text": "where people use Amazon Elastic search service I'm sure you folks are deal with a lot many different use cases or at a",
    "start": "362520",
    "end": "369930"
  },
  {
    "text": "high level people use it for troubleshooting root cause analysis application performance management",
    "start": "369930",
    "end": "375360"
  },
  {
    "text": "application monitoring security intelligence you could have iot or mobile level metrics or application",
    "start": "375360",
    "end": "382500"
  },
  {
    "text": "tracking you could do business analytics click stream analytics and so on there are many many different use cases for it",
    "start": "382500",
    "end": "388320"
  },
  {
    "text": "and I'm sure you know you'll find even more use cases as you look at it from your business perspective for the sake",
    "start": "388320",
    "end": "394350"
  },
  {
    "text": "of this session we are not diving deep into the use cases part let's focus more on the architecture side of thing",
    "start": "394350",
    "end": "401300"
  },
  {
    "start": "400000",
    "end": "470000"
  },
  {
    "text": "at a simple level the core component of the architecture is the Amazon Elastic",
    "start": "401300",
    "end": "408330"
  },
  {
    "text": "search service domain the domain consists of all the hardware and software components that you need to run",
    "start": "408330",
    "end": "414330"
  },
  {
    "text": "an elastic search cluster so you set up the data instances that you need which hosts all your data you can optionally",
    "start": "414330",
    "end": "421020"
  },
  {
    "text": "have dedicated master instances you are there's already an LV fronted in front",
    "start": "421020",
    "end": "427290"
  },
  {
    "text": "of your data instances which does the load balancing you also have I am for access control and then you can interface with your",
    "start": "427290",
    "end": "434190"
  },
  {
    "text": "domain either via console SDK CLI or cloud formation you have cloud trail and",
    "start": "434190",
    "end": "439770"
  },
  {
    "text": "cloud watch for monitoring and audit now in general how do you go about operating this you just simply go ahead",
    "start": "439770",
    "end": "445740"
  },
  {
    "text": "create your domain you pick that kind of instances that you want ingested a DES and get started it's much literally in",
    "start": "445740",
    "end": "453450"
  },
  {
    "text": "minutes you can get going but now let's talk about actually ok so it gives you a lot of functionality makes things a lot",
    "start": "453450",
    "end": "459780"
  },
  {
    "text": "easier from different angles but let's talk about how can we actually put it to good use especially when you're building",
    "start": "459780",
    "end": "466800"
  },
  {
    "text": "your log analytics solution that brings up to the next part of this discussion",
    "start": "466800",
    "end": "472110"
  },
  {
    "start": "470000",
    "end": "480000"
  },
  {
    "text": "which is what are the factors that you need to consider while you are building",
    "start": "472110",
    "end": "477510"
  },
  {
    "text": "a log analytic solution so let's start with the log analytic solution at its",
    "start": "477510",
    "end": "483090"
  },
  {
    "start": "480000",
    "end": "524000"
  },
  {
    "text": "simplest level and then we'll build on top of it so at its simplest level you have a data source you ingest data your",
    "start": "483090",
    "end": "490770"
  },
  {
    "text": "Amazon Elastic search service domain and then you can you know either visualize",
    "start": "490770",
    "end": "496020"
  },
  {
    "text": "data using cubano you can query it programmatically if you want to a consumer right that's at a simplest",
    "start": "496020",
    "end": "502710"
  },
  {
    "text": "level but reality is very different from here in reality you have a lot mini data",
    "start": "502710",
    "end": "509340"
  },
  {
    "text": "sources you've got a number of different consumers who want to you know interact with the data and get the data in real",
    "start": "509340",
    "end": "515070"
  },
  {
    "text": "time and now how do you build a log analytics solution to cater to all these needs the two common models that we see",
    "start": "515070",
    "end": "523280"
  },
  {
    "text": "the first model is the decentralized model you have a problem you feel you",
    "start": "523280",
    "end": "529650"
  },
  {
    "start": "524000",
    "end": "600000"
  },
  {
    "text": "don't have data okay go ahead set up your own log analytic solution just build up your own elasticsearch",
    "start": "529650",
    "end": "534870"
  },
  {
    "text": "his domain and set it up you have your data source in just a data query it",
    "start": "534870",
    "end": "540029"
  },
  {
    "text": "however you want this model gives you flexibility if you have many teams in your organization",
    "start": "540029",
    "end": "545339"
  },
  {
    "text": "each team can have their own they can be on their own they can just run with it it helps you optimize those domains for",
    "start": "545339",
    "end": "552390"
  },
  {
    "text": "those requirements you can have their own separate security policies it also kind of isolates the area of failure",
    "start": "552390",
    "end": "560310"
  },
  {
    "text": "because at the max you'll be only failing one domain let's say due to some issue while the others are still operating and so on so there are",
    "start": "560310",
    "end": "566790"
  },
  {
    "text": "benefits to this model but let's go back to the three scenarios we talked about firstly we said okay do I have the data",
    "start": "566790",
    "end": "573089"
  },
  {
    "text": "and then you figure out okay I don't have let's log everything this is a situation that you get into when you say",
    "start": "573089",
    "end": "578160"
  },
  {
    "text": "let's log everything everybody logs data into their own domains then you come to",
    "start": "578160",
    "end": "583170"
  },
  {
    "text": "the third situation and you start questioning hey am i operating efficiently that's where things are a",
    "start": "583170",
    "end": "589230"
  },
  {
    "text": "bit tricky because then you have these multiple solutions you don't always",
    "start": "589230",
    "end": "594240"
  },
  {
    "text": "drive the best utilization that brings up to the next model which is more of a",
    "start": "594240",
    "end": "600660"
  },
  {
    "start": "600000",
    "end": "667000"
  },
  {
    "text": "centralized log analytics platform to which you ingest data from your multiple sources and you can read the data across",
    "start": "600660",
    "end": "608310"
  },
  {
    "text": "your different consumers you need to track and handle access control because yes the different kinds of consumers",
    "start": "608310",
    "end": "614070"
  },
  {
    "text": "different kinds of data sources not everybody needs access to everything else now this model reduces your",
    "start": "614070",
    "end": "620010"
  },
  {
    "text": "management overhead you're not having n different domain setup it also helps you enforce standards let's say security",
    "start": "620010",
    "end": "626310"
  },
  {
    "text": "standards or compliance you have a specific area that you can focus on you can have a dedicated team that actually",
    "start": "626310",
    "end": "632310"
  },
  {
    "text": "looks into it and you can build it so that it can actually cater to all the requirements it gives you better",
    "start": "632310",
    "end": "637560"
  },
  {
    "text": "utilization and in the sense that you know you can have ten different domains",
    "start": "637560",
    "end": "642660"
  },
  {
    "text": "with a lot of data or hardly being used or you can actually if you're using it in a single domain you might be able to",
    "start": "642660",
    "end": "647760"
  },
  {
    "text": "leverage the resources better because if one domain if one team is not using enough data while the other team is",
    "start": "647760",
    "end": "653310"
  },
  {
    "text": "using that's fine it's still utilizing that resource so for the sake of this discussion we're going to dive deeper",
    "start": "653310",
    "end": "659130"
  },
  {
    "text": "into a few factors that you need to consider as you're building such a solution for the sake of time I'm going",
    "start": "659130",
    "end": "666209"
  },
  {
    "text": "to focus on four key factors each of which I feel are very critical as you build log analytic solutions",
    "start": "666209",
    "end": "672660"
  },
  {
    "start": "667000",
    "end": "695000"
  },
  {
    "text": "let's start with the first one the first one is ingesting your data the second is",
    "start": "672660",
    "end": "679060"
  },
  {
    "text": "optimizing your domain third is securing your domain and last but not the least",
    "start": "679060",
    "end": "685420"
  },
  {
    "text": "is scaling we'll talk about each of these at and I'll try to give you some",
    "start": "685420",
    "end": "690730"
  },
  {
    "text": "key tidbits that you need to focus on as you're building this let's start with index our ingesting data then you talk",
    "start": "690730",
    "end": "699190"
  },
  {
    "start": "695000",
    "end": "723000"
  },
  {
    "text": "about a typical injection pipeline there are multiple parts to it you have a data source you collect the data you may",
    "start": "699190",
    "end": "705910"
  },
  {
    "text": "buffer it you need to transform it last six words needs JSON so if your data source doesn't give you JSON at least",
    "start": "705910",
    "end": "711910"
  },
  {
    "text": "you need that transformation you might have further business logic to do more transformation and then you need to",
    "start": "711910",
    "end": "717190"
  },
  {
    "text": "deliver the data to Amazon Elastic search service domain now for each of these phases there are a number of",
    "start": "717190",
    "end": "723339"
  },
  {
    "start": "723000",
    "end": "791000"
  },
  {
    "text": "different technologies and here's a few examples so you could collect the data",
    "start": "723339",
    "end": "729610"
  },
  {
    "text": "by running a Kinesis agent on your box you could have cloud watch agent you could run flu Indy you could have your",
    "start": "729610",
    "end": "735280"
  },
  {
    "text": "own custom application do that you could do it with lots - you could lure it with beats you could buffer the data using",
    "start": "735280",
    "end": "742180"
  },
  {
    "text": "Kinesis or cloud watch logs you could use Redis or on elastic cache you could",
    "start": "742180",
    "end": "747400"
  },
  {
    "text": "use s3 if you want you could use logs - rabbit and queue the tons of options",
    "start": "747400",
    "end": "752410"
  },
  {
    "text": "again with transformation you can use kinases you can write a lambda function to actually transform you could use",
    "start": "752410",
    "end": "757900"
  },
  {
    "text": "cloud watch you could use log stash and similarly to deliver the data - there",
    "start": "757900",
    "end": "762940"
  },
  {
    "text": "are different technologies available kinases data firehose can easily do that for you you could do that explicitly",
    "start": "762940",
    "end": "768490"
  },
  {
    "text": "through your application you could write a lambda function now if you just look at this there are many permutation",
    "start": "768490",
    "end": "775360"
  },
  {
    "text": "combinations to actually do this right look at it as Lego blocks and you can assemble them in any different form what",
    "start": "775360",
    "end": "782020"
  },
  {
    "text": "I'm going to focus on is provide you two key patterns that are pretty useful and",
    "start": "782020",
    "end": "787720"
  },
  {
    "text": "handy when you're building a log analytic solution the first pattern is what we call the Amazon s3 based data",
    "start": "787720",
    "end": "795250"
  },
  {
    "start": "791000",
    "end": "846000"
  },
  {
    "text": "like architecture so the idea here is that you collect the data from your various data sources",
    "start": "795250",
    "end": "801860"
  },
  {
    "text": "dumping them into s/3 s/3 triggers the s3 events to which you trigger a lambda",
    "start": "801860",
    "end": "807800"
  },
  {
    "text": "function which takes care of transforming the data as needed and writing it to Amazon Elastic search",
    "start": "807800",
    "end": "813950"
  },
  {
    "text": "service now the biggest advantage here is you have a highly highly highly",
    "start": "813950",
    "end": "819650"
  },
  {
    "text": "durable service in the form of s3 that houses all your data you can easily pump",
    "start": "819650",
    "end": "825590"
  },
  {
    "text": "this data to several other services Amazon Elastic search service is one of the options it's low cost storage for",
    "start": "825590",
    "end": "831410"
  },
  {
    "text": "that and you can always revert back to that storage as needed now in your case where you have multiple data so multiple",
    "start": "831410",
    "end": "837830"
  },
  {
    "text": "consumers this is a great model you can make sure all the data is in s3 and s3 forms are data Lake and then you can",
    "start": "837830",
    "end": "843050"
  },
  {
    "text": "consume it so this is one very handy tactic the other key one is using",
    "start": "843050",
    "end": "848720"
  },
  {
    "start": "846000",
    "end": "921000"
  },
  {
    "text": "Kinesis data fibres the one option is you have data sources you run your",
    "start": "848720",
    "end": "854420"
  },
  {
    "text": "kinases agent on it which writes the data as and when it comes to the Kinesis data firehose and from the Kinesis data",
    "start": "854420",
    "end": "861410"
  },
  {
    "text": "firehose you write it into elasticsearch there's a direct integration with Amazon Elastic search service you could write a lambda function to run",
    "start": "861410",
    "end": "868960"
  },
  {
    "text": "transformations on that data which is residing in the Kinesis firehose and change it however you want before it's",
    "start": "868960",
    "end": "875180"
  },
  {
    "text": "written into elasticsearch service also you could actually identify those data",
    "start": "875180",
    "end": "881060"
  },
  {
    "text": "components that are not meeting your requirements maybe the transformations fail you could put it into a different",
    "start": "881060",
    "end": "886070"
  },
  {
    "text": "s3 bucket if you want for debugging later if you feel here you need some kind of a data leak you want to actually",
    "start": "886070",
    "end": "892130"
  },
  {
    "text": "save the original data maybe there's a compliance need or maybe you want to actually retain it you could",
    "start": "892130",
    "end": "897410"
  },
  {
    "text": "always drag the data to s3 as well and store it in s3 while the data also goes",
    "start": "897410",
    "end": "902570"
  },
  {
    "text": "to Amazon Elastic search service so this is another very powerful scalable pattern especially when you have very",
    "start": "902570",
    "end": "908750"
  },
  {
    "text": "high injection rate Kinesis can help you with the buffering you can do the transformation with the lambda and get it through now these are the two key",
    "start": "908750",
    "end": "915890"
  },
  {
    "text": "things that I would like to you know you to consider as you're thinking of log analytics with that said let's actually",
    "start": "915890",
    "end": "922190"
  },
  {
    "start": "921000",
    "end": "993000"
  },
  {
    "text": "move on to the next step optimizing your elasticsearch Service domain the first",
    "start": "922190",
    "end": "928100"
  },
  {
    "text": "key part that most folks actually think of is tenancy should I use one bulky",
    "start": "928100",
    "end": "933890"
  },
  {
    "text": "index or should I use multiple this is to actually accomplish the task now with multiple indices you could have",
    "start": "933890",
    "end": "940370"
  },
  {
    "text": "dedicated indices per use case you could have different rotation patterns you could have different security you have",
    "start": "940370",
    "end": "946580"
  },
  {
    "text": "your credentials on those indices you have a lot of flexibility you can even add more your indices to just scale but",
    "start": "946580",
    "end": "953600"
  },
  {
    "text": "then you have the same problem when you have too many indices running on the domain you run the risk of having too",
    "start": "953600",
    "end": "959540"
  },
  {
    "text": "many shots and actually having performance issues so you may not always be that optimal so fewer indices can",
    "start": "959540",
    "end": "967580"
  },
  {
    "text": "actually provide you better optimization have a work if you have a just a single index with all this data you're forced",
    "start": "967580",
    "end": "974900"
  },
  {
    "text": "to query that index even if you want just a portion of data so that's where the trade-off comes in you need to",
    "start": "974900",
    "end": "980420"
  },
  {
    "text": "figure out a balance where you feel you know you have the right optimization there you have enough indices to take",
    "start": "980420",
    "end": "986360"
  },
  {
    "text": "care of the task rather than creating thousands and thousands of indices now that's part one the other key part is",
    "start": "986360",
    "end": "994010"
  },
  {
    "start": "993000",
    "end": "1067000"
  },
  {
    "text": "sharding what we have seen is sharding is one of the primary reasons because of",
    "start": "994010",
    "end": "1001030"
  },
  {
    "text": "which people face inefficiencies and performance issues so the two tips I would like to give you first of all try",
    "start": "1001030",
    "end": "1008080"
  },
  {
    "text": "to make sure at any given time the number of active shots is equal to the",
    "start": "1008080",
    "end": "1013750"
  },
  {
    "text": "number of V CPUs you have in your cluster so for example the chart here shows you you know when you're ingesting",
    "start": "1013750",
    "end": "1020410"
  },
  {
    "text": "at a high rate for an m4 to Excel which has eight V CPUs at eight charts it's",
    "start": "1020410",
    "end": "1026319"
  },
  {
    "text": "able to deliver maximum parallelization you have fewer than that you're not utilizing it well enough if you have",
    "start": "1026320",
    "end": "1031360"
  },
  {
    "text": "more it's actually overloading it and anyway it's not getting utilized well enough so that kind of helps you attain",
    "start": "1031360",
    "end": "1038050"
  },
  {
    "text": "the maximum throughput the other part is when you have multiple different indices",
    "start": "1038050",
    "end": "1043089"
  },
  {
    "text": "on the same domain try to ensure that you don't have fairly varied chart sizes",
    "start": "1043090",
    "end": "1048760"
  },
  {
    "text": "because when the shard sizes are skewed it's actually gonna make things imbalance in your cluster and that's",
    "start": "1048760",
    "end": "1054820"
  },
  {
    "text": "gonna run into further issues performance issues JVM memory pressure and so on so that's the second tip that",
    "start": "1054820",
    "end": "1060940"
  },
  {
    "text": "I would like to give you something for you to consider are you as you're thinking of optimizing a domain for",
    "start": "1060940",
    "end": "1066160"
  },
  {
    "text": "scale now let's move on to the other part securing a domain so if you're getting",
    "start": "1066160",
    "end": "1071770"
  },
  {
    "start": "1067000",
    "end": "1076000"
  },
  {
    "text": "multiple data sources multiple consumers a key part is how do you secure it of course Amazon Elastic search service has",
    "start": "1071770",
    "end": "1078700"
  },
  {
    "start": "1076000",
    "end": "1092000"
  },
  {
    "text": "a bunch of options it's got I am days access control you've got cloud trail for auditing",
    "start": "1078700",
    "end": "1083890"
  },
  {
    "text": "cloud watch for monitoring you've got a different options but I'm going to give you two key security tips that you would",
    "start": "1083890",
    "end": "1090370"
  },
  {
    "text": "want to use security features that you would want to focus on first one is V PC but V PC you ensure that your data is",
    "start": "1090370",
    "end": "1098140"
  },
  {
    "start": "1092000",
    "end": "1125000"
  },
  {
    "text": "not going over the internet it's within the Amazon network it also has the added benefit that you can actually you know",
    "start": "1098140",
    "end": "1105640"
  },
  {
    "text": "control access based on IP addresses and you restrict the surface area of access to your cluster and to top it all you",
    "start": "1105640",
    "end": "1113050"
  },
  {
    "text": "don't pay any extra cost just to enable V PC on Amazon Elastic search service it's free so this is something code that",
    "start": "1113050",
    "end": "1119740"
  },
  {
    "text": "you would want to consider no matter what kind of domain or use case scenario that you are actually focusing on the",
    "start": "1119740",
    "end": "1125440"
  },
  {
    "text": "other key one which we launched recently is integration with Amazon cognitive so",
    "start": "1125440",
    "end": "1131890"
  },
  {
    "text": "when you use Kabana typically I'm sure some of you might be using a signing proxy but with kognito",
    "start": "1131890",
    "end": "1137740"
  },
  {
    "text": "you no longer need to do that you can actually set up your user pools and identity pools incognito to manage the",
    "start": "1137740",
    "end": "1143860"
  },
  {
    "text": "different use users that you have you could integrate with your enterprise identity providers that way when you",
    "start": "1143860",
    "end": "1149950"
  },
  {
    "text": "make a call from Cabana it hits cognitive Maps your identity too and I am roll through which it actually",
    "start": "1149950",
    "end": "1156310"
  },
  {
    "text": "invokes Amazon Elastic search service domain so this is the other area that you might want to consider as a thinking",
    "start": "1156310",
    "end": "1162640"
  },
  {
    "text": "of security for your Amazon Elastic search service to me now with security aside let's look at the last big factor",
    "start": "1162640",
    "end": "1170470"
  },
  {
    "start": "1168000",
    "end": "1194000"
  },
  {
    "text": "which is scaling now all of us start with a small model for scale we always",
    "start": "1170470",
    "end": "1176800"
  },
  {
    "text": "think okay let's start small and as and when needed we need to add more and we need to scale up now it gets a bit",
    "start": "1176800",
    "end": "1183670"
  },
  {
    "text": "tricky and difficult if you don't plan it well and if you don't consider the right aspects so again I won't give you",
    "start": "1183670",
    "end": "1189490"
  },
  {
    "text": "two key tips as you're thinking of scaling your elasticsearch Service domain first and foremost understand",
    "start": "1189490",
    "end": "1197320"
  },
  {
    "start": "1194000",
    "end": "1245000"
  },
  {
    "text": "your bottlenecks so you've seen a number of people who actually just when we think of scale it's okay",
    "start": "1197320",
    "end": "1202870"
  },
  {
    "text": "let's add a few more instances get going but many times you need to understand is it between this CPU or memory where",
    "start": "1202870",
    "end": "1209980"
  },
  {
    "text": "exactly is your bottleneck and so you need to optimize you to scale on that angle first the other part is don't",
    "start": "1209980",
    "end": "1217540"
  },
  {
    "text": "ignore your master nodes so the master nodes actually help in orchestrating the",
    "start": "1217540",
    "end": "1222880"
  },
  {
    "text": "data if you have too many shards in the cluster it's actually going to get overwhelmed and it's actually going to",
    "start": "1222880",
    "end": "1228730"
  },
  {
    "text": "disrupt the performance many times folks just look at the data nodes ignore the master nodes but you need to consider",
    "start": "1228730",
    "end": "1234490"
  },
  {
    "text": "the master nodes as well when you're thinking of scaling and the bottlenecks that you need to handle now you might be wondering okay so if that is the case",
    "start": "1234490",
    "end": "1240940"
  },
  {
    "text": "which instances should I use so there are a number of instance types that Amazon Elastic search service supports",
    "start": "1240940",
    "end": "1247030"
  },
  {
    "start": "1245000",
    "end": "1306000"
  },
  {
    "text": "you could use the t2 instances for def test workloads it's not meant for production level scale you could use the",
    "start": "1247030",
    "end": "1254260"
  },
  {
    "text": "EM kind of workloads for general purpose scenarios where you don't have that heavy querying or that heavy indexing",
    "start": "1254260",
    "end": "1260460"
  },
  {
    "text": "you use the our tour series which is very memory optimized when you have",
    "start": "1260460",
    "end": "1266140"
  },
  {
    "text": "memory intensive workloads especially you have very high query rates immense aggregations of complicated queries you",
    "start": "1266140",
    "end": "1273490"
  },
  {
    "text": "could use the C family then you have been you need a lot more processing and you have lot more concurrent requests or",
    "start": "1273490",
    "end": "1279130"
  },
  {
    "text": "high indexing rates and you can use ice when you have high I ups requirements or",
    "start": "1279130",
    "end": "1284200"
  },
  {
    "text": "higher storage requirements the iSeries in general is very suitable when you",
    "start": "1284200",
    "end": "1289660"
  },
  {
    "text": "have large storage volumes especially if you're considering consolidating some workloads together which in case is",
    "start": "1289660",
    "end": "1295510"
  },
  {
    "text": "going to increase your eye ops and storage now with that said you know let",
    "start": "1295510",
    "end": "1301030"
  },
  {
    "text": "me quickly sum up some of the key tips that we just looked at so at a high",
    "start": "1301030",
    "end": "1306580"
  },
  {
    "text": "level I think understand your workload do consider situations where you know",
    "start": "1306580",
    "end": "1312610"
  },
  {
    "text": "you're not just going blindly and saying ok we need more data let's just go ahead create more domains create more analytic",
    "start": "1312610",
    "end": "1318340"
  },
  {
    "text": "solutions and just good going you need to think about the efficiency angle and so some level of centralization is going",
    "start": "1318340",
    "end": "1324340"
  },
  {
    "text": "to be useful consider security features like V PC that we discussed do look at",
    "start": "1324340",
    "end": "1330309"
  },
  {
    "text": "s3 as the data where data leak look at the Kinesis data pattern and of course",
    "start": "1330309",
    "end": "1335800"
  },
  {
    "text": "definitely think of your bottlenecks as your skill so I keep this you know fairly concise",
    "start": "1335800",
    "end": "1343540"
  },
  {
    "text": "and to limit it to ski factors that I feel are essential as you build log",
    "start": "1343540",
    "end": "1348880"
  },
  {
    "text": "analytic solution now in the interest of time I'm gonna stop there I'm gonna invite Tommy who's actually gonna walk",
    "start": "1348880",
    "end": "1355300"
  },
  {
    "text": "you through their experiences how they incorporated some of these principles into their use cases how they went about",
    "start": "1355300",
    "end": "1362230"
  },
  {
    "text": "building the actual log analytic solution and hopefully that is going to give you a lot more insights as well as",
    "start": "1362230",
    "end": "1367690"
  },
  {
    "text": "you think about building your log antek solution over to you Tommy hello",
    "start": "1367690",
    "end": "1380650"
  },
  {
    "start": "1373000",
    "end": "1386000"
  },
  {
    "text": "everyone my name is Tommy Lee I work for although - I'm myself an architect so",
    "start": "1380650",
    "end": "1386470"
  },
  {
    "start": "1386000",
    "end": "1422000"
  },
  {
    "text": "today I'm gonna cover the following topics I'm going to talk about the kind of problem that we are dealing with",
    "start": "1386470",
    "end": "1392550"
  },
  {
    "text": "what's bothering us and how are we gonna address that problem then I'm going to",
    "start": "1392550",
    "end": "1398410"
  },
  {
    "text": "get into some of the architecture technical stuff exactly how we build solution and then I put some emphasis on",
    "start": "1398410",
    "end": "1404410"
  },
  {
    "text": "the elastic search portion of our solution how we're gonna do that the kind of things that we have encountered",
    "start": "1404410",
    "end": "1410560"
  },
  {
    "text": "I would like to share those experience with you and last but not least I'm going to talk a bit about some of the",
    "start": "1410560",
    "end": "1415930"
  },
  {
    "text": "lessons learned and the things that that we have acquired through this project is",
    "start": "1415930",
    "end": "1422730"
  },
  {
    "text": "so I just want to give a brief introduction of what we do so although",
    "start": "1422730",
    "end": "1428470"
  },
  {
    "text": "that's we build software products to have a customer build things or make things and these are all the things that",
    "start": "1428470",
    "end": "1435910"
  },
  {
    "start": "1434000",
    "end": "1458000"
  },
  {
    "text": "our customers have built using our product so it's everything they do this",
    "start": "1435910",
    "end": "1441850"
  },
  {
    "text": "stuff I think that you use a lot of these things actually build with our products this is the amount of traffic",
    "start": "1441850",
    "end": "1449140"
  },
  {
    "text": "or end-users that is using our product is this is a web scale kind of problem",
    "start": "1449140",
    "end": "1456220"
  },
  {
    "text": "that we are dealing with every day so our products are built upon a cloud",
    "start": "1456220",
    "end": "1462310"
  },
  {
    "start": "1458000",
    "end": "1557000"
  },
  {
    "text": "platform so everything that is computing sensitive with a lot of data these are all century manners",
    "start": "1462310",
    "end": "1468360"
  },
  {
    "text": "to a platform we have a name of it called Forge so our products work upon",
    "start": "1468360",
    "end": "1474510"
  },
  {
    "text": "that our customers use our product which then depends on the platform and customers can also build their own apps",
    "start": "1474510",
    "end": "1481280"
  },
  {
    "text": "directly upon our platform so this is how a typical product situation or the",
    "start": "1481280",
    "end": "1490530"
  },
  {
    "text": "patterns that we're dealing with as a customers are using our product so a customer use a product to do work such",
    "start": "1490530",
    "end": "1497670"
  },
  {
    "text": "as I'm gonna design a hospital a skyscraper or whatever it might be so",
    "start": "1497670",
    "end": "1502890"
  },
  {
    "text": "most of the time they use our product to build the model and then they upload the",
    "start": "1502890",
    "end": "1508440"
  },
  {
    "text": "model to the cloud services which is the fourth platform to do interesting things",
    "start": "1508440",
    "end": "1513840"
  },
  {
    "text": "such as I'm going to transform this into different formats so that I can actually view it in a 2d or 3d model at the end",
    "start": "1513840",
    "end": "1520110"
  },
  {
    "text": "right so as the data is being uploaded into into the into our cloud platform it",
    "start": "1520110",
    "end": "1527309"
  },
  {
    "text": "actually goes through quite a few things behind the scenes so the gray boxes represents all our micro surfaces in",
    "start": "1527309",
    "end": "1533220"
  },
  {
    "text": "play they have a lot of relationship to each other and at the end whatever we do will end",
    "start": "1533220",
    "end": "1539549"
  },
  {
    "text": "up like a build like a turn the model into a view just like in a in a talking",
    "start": "1539549",
    "end": "1545580"
  },
  {
    "text": "to our show and the customer would work with it so so this is a very important",
    "start": "1545580",
    "end": "1552210"
  },
  {
    "text": "for us that the compass customer experience when they when they interact with us through our product so if the",
    "start": "1552210",
    "end": "1559169"
  },
  {
    "start": "1557000",
    "end": "1588000"
  },
  {
    "text": "upload process is completed but the rendering of the 2d 3d model is kind of",
    "start": "1559169",
    "end": "1565740"
  },
  {
    "text": "having a delay it actually impacts our customer right so because they're working on projects and they rely on our",
    "start": "1565740",
    "end": "1572760"
  },
  {
    "text": "product and the services to keep going so and at some point when the when when",
    "start": "1572760",
    "end": "1581160"
  },
  {
    "text": "things goes wrong the customers become anxious and this is the typical kind of support questions that we're dealing",
    "start": "1581160",
    "end": "1587490"
  },
  {
    "text": "with so it's a tough problem as we all know we're working and operating in a",
    "start": "1587490",
    "end": "1593970"
  },
  {
    "start": "1588000",
    "end": "1622000"
  },
  {
    "text": "high distributed environment and we all familiar with the policies in distributed computing this is the",
    "start": "1593970",
    "end": "1600750"
  },
  {
    "text": "reality that we deal with so rather than not like a I try to avoid it or whatever way that we",
    "start": "1600750",
    "end": "1608400"
  },
  {
    "text": "try to like a again ignore it we actually have to embrace it and this is",
    "start": "1608400",
    "end": "1613920"
  },
  {
    "text": "our new reality so we have to somehow deal with failures deal with problems and this is one of the things that that",
    "start": "1613920",
    "end": "1621510"
  },
  {
    "text": "we find this are very important so you know for us right to help our customers to have a excellent experience using our",
    "start": "1621510",
    "end": "1630660"
  },
  {
    "start": "1622000",
    "end": "1745000"
  },
  {
    "text": "product we got to be able to to know about what's going on in you know",
    "start": "1630660",
    "end": "1636780"
  },
  {
    "text": "ecosystem so we must have a way for us to consistently collect metrics so that",
    "start": "1636780",
    "end": "1645090"
  },
  {
    "text": "we can do the following things so these are the three major categories of",
    "start": "1645090",
    "end": "1650540"
  },
  {
    "text": "of goals that we want to achieve so first we want to make sure that we have",
    "start": "1650540",
    "end": "1655770"
  },
  {
    "text": "a real-time monitoring means so that when things happen in any part of our",
    "start": "1655770",
    "end": "1662190"
  },
  {
    "text": "cloud platform we know about the the situations immediately so that we can",
    "start": "1662190",
    "end": "1669510"
  },
  {
    "text": "take actions right we can call our teams to support our customers immediately so",
    "start": "1669510",
    "end": "1675210"
  },
  {
    "text": "the goal is to improve our overall time to detect MT DD interview detect so",
    "start": "1675210",
    "end": "1681180"
  },
  {
    "text": "won't improve in that area the other part is to support a foreign state activity when an incident happens and we",
    "start": "1681180",
    "end": "1687660"
  },
  {
    "text": "can successfully detect it very quickly so how do we support our teams to",
    "start": "1687660",
    "end": "1693660"
  },
  {
    "text": "actually troubleshoot where the problem is what the problem is and where does it happen so the quality of the information",
    "start": "1693660",
    "end": "1701400"
  },
  {
    "text": "that we collect the metrics we collect and the way that we can have our teams",
    "start": "1701400",
    "end": "1707100"
  },
  {
    "text": "to use the tools to do the job effectively will help us improve the",
    "start": "1707100",
    "end": "1714330"
  },
  {
    "text": "recovery time so the goal is to improve the overall mean time to recover last but not the least so all the things",
    "start": "1714330",
    "end": "1721800"
  },
  {
    "text": "metrics that we collect we would like to learn from it right draw in size from it",
    "start": "1721800",
    "end": "1726930"
  },
  {
    "text": "and so that we can have a continuous improvement so the better we do in this",
    "start": "1726930",
    "end": "1732360"
  },
  {
    "text": "area the better off we will improve a product and then the failure between incidents",
    "start": "1732360",
    "end": "1737890"
  },
  {
    "text": "will become far in between so we want to improve our overall mean time between",
    "start": "1737890",
    "end": "1743710"
  },
  {
    "text": "failure so the pain points that we going through is like this so although this",
    "start": "1743710",
    "end": "1751330"
  },
  {
    "start": "1745000",
    "end": "1900000"
  },
  {
    "text": "has been a while we are we have started our cloud journey like eight to ten",
    "start": "1751330",
    "end": "1756610"
  },
  {
    "text": "years already so throughout the entire process we built a lot of systems a lot",
    "start": "1756610",
    "end": "1762190"
  },
  {
    "text": "of these Alagna systems and then they're all in different sizes and shapes so we",
    "start": "1762190",
    "end": "1768130"
  },
  {
    "text": "do not have a way for us to effectively trace like in the workflow example that",
    "start": "1768130",
    "end": "1773620"
  },
  {
    "text": "I just show like how these things actually relate to each other so without being able to do so it's tough to",
    "start": "1773620",
    "end": "1780429"
  },
  {
    "text": "actually troubleshoot problems easily the quality of it is also a problem so",
    "start": "1780429",
    "end": "1786840"
  },
  {
    "text": "every team just some whatever they thing is important which is good to have but",
    "start": "1786840",
    "end": "1793720"
  },
  {
    "text": "when it comes to let's talk to each other and solve a problem because the customer has a dependency on all the",
    "start": "1793720",
    "end": "1799450"
  },
  {
    "text": "services then that be that will become a much quicker prompted for us to deal with so and because of that we have",
    "start": "1799450",
    "end": "1805659"
  },
  {
    "text": "problems about the quality of the data about the timeliness about correctness so on and so forth it's actually quite",
    "start": "1805659",
    "end": "1811779"
  },
  {
    "text": "hectic the infrastructure that we have and the solutions that we have built up",
    "start": "1811779",
    "end": "1818020"
  },
  {
    "text": "like over the years come to a point where we are dealing with some scalability issue it's kind of kind of",
    "start": "1818020",
    "end": "1825100"
  },
  {
    "text": "coupled with all the the first two problems that I've just mentioned that makes the ongoing like an operation and",
    "start": "1825100",
    "end": "1833080"
  },
  {
    "text": "I mean and the management of the cause becomes quite quite bad right we also",
    "start": "1833080",
    "end": "1842169"
  },
  {
    "text": "have been taking a to centric approach meaning everything goes to one place and",
    "start": "1842169",
    "end": "1847899"
  },
  {
    "text": "use a tool and rely on that to to help us solve all the problem answer all the questions right it turned out to be not",
    "start": "1847899",
    "end": "1855159"
  },
  {
    "text": "less effective right and the data is kind of law you know - and it's difficult to actually like I take the",
    "start": "1855159",
    "end": "1861520"
  },
  {
    "text": "data out and then we can do more of the potato carnivore analytics kind of work so is it's not efficient at",
    "start": "1861520",
    "end": "1868879"
  },
  {
    "text": "all so then the what did the overall",
    "start": "1868879",
    "end": "1875059"
  },
  {
    "text": "analytics quality becomes a problem because we have there all these like incoming the ingestion path where the",
    "start": "1875059",
    "end": "1882979"
  },
  {
    "text": "data is not accurate not timely so our teams cannot rely on that to draw the correct inside and then also we have so",
    "start": "1882979",
    "end": "1891769"
  },
  {
    "text": "many different kinds of pipelines different see sed process makes all the integration become quite complex and",
    "start": "1891769",
    "end": "1898460"
  },
  {
    "text": "they're not really comparable to each other so we have a chance early early",
    "start": "1898460",
    "end": "1905570"
  },
  {
    "text": "this year to rethink and rework the entire problem so the way that we that",
    "start": "1905570",
    "end": "1912470"
  },
  {
    "text": "we've approached is this this project is let's take let's tackle",
    "start": "1912470",
    "end": "1918349"
  },
  {
    "text": "this problem from a architecture point of view right our platform point of view",
    "start": "1918349",
    "end": "1923989"
  },
  {
    "text": "so as a platform what should we do about it so as we apply some of the architecture",
    "start": "1923989",
    "end": "1930080"
  },
  {
    "text": "principles into the problem the first thing we want to do is to make sure we have a very clear separation of concern",
    "start": "1930080",
    "end": "1935869"
  },
  {
    "text": "and each area each concern we have a well set of well-defined responsibilities and interfaces so by",
    "start": "1935869",
    "end": "1944059"
  },
  {
    "text": "being able to do so then we will be able to bring in the best-in-class solution to solve a particular kind of problem",
    "start": "1944059",
    "end": "1949729"
  },
  {
    "text": "and you can actually easily swap in and out different components as we see fit and we also wants to use as much managed",
    "start": "1949729",
    "end": "1957859"
  },
  {
    "text": "services as possible we have a very small team to start off this project and we want to focus ourselves on the",
    "start": "1957859",
    "end": "1964549"
  },
  {
    "text": "business problem rather than managing the infrastructure so the more we use managed services the better off we will",
    "start": "1964549",
    "end": "1970820"
  },
  {
    "text": "be because manage less is actually helped us to get more value out of it we also",
    "start": "1970820",
    "end": "1977179"
  },
  {
    "text": "want a simplified solution we don't want to have say the interesting part and have so many different flavors of",
    "start": "1977179",
    "end": "1983450"
  },
  {
    "text": "interesting combinations we cannot support all these different mix of work",
    "start": "1983450",
    "end": "1988609"
  },
  {
    "text": "it's just not going to be scalable like not manageable at all and we also",
    "start": "1988609",
    "end": "1995150"
  },
  {
    "text": "want to make sure that we have a common taxonomy common language for all the teams to interact so we standardize on",
    "start": "1995150",
    "end": "2001240"
  },
  {
    "text": "metrics so these are put that there's a standard set of metrics that we say everyone should use and then but we also",
    "start": "2001240",
    "end": "2007990"
  },
  {
    "text": "allow every product and services to extend upon a set of metrics to have their own set of custom metrics so right",
    "start": "2007990",
    "end": "2018910"
  },
  {
    "start": "2018000",
    "end": "2392000"
  },
  {
    "text": "now so this is the system architecture that we have built up to this point so",
    "start": "2018910",
    "end": "2024720"
  },
  {
    "text": "so there are four swimlanes in this diagram so they all represents the four areas of concern so the first",
    "start": "2024720",
    "end": "2033310"
  },
  {
    "text": "is sauce that's what I call the sauce where all our products and services are",
    "start": "2033310",
    "end": "2038970"
  },
  {
    "text": "reside so from the infrastructure point of view we largely have three kinds of",
    "start": "2038970",
    "end": "2045300"
  },
  {
    "text": "implementation first is easy to base classical easy to applications which is",
    "start": "2045300",
    "end": "2051370"
  },
  {
    "text": "at the top the middle one is ECS we have containers and then the third one is",
    "start": "2051370",
    "end": "2057520"
  },
  {
    "text": "lambda press service so each of these infrastructure so we'll have a person",
    "start": "2057520",
    "end": "2064540"
  },
  {
    "text": "running into it and we provide a SDK which called a ul SDK we call the",
    "start": "2064540",
    "end": "2070840"
  },
  {
    "text": "unified lock and SDK so I'll explain unify logging in the next slide so but",
    "start": "2070840",
    "end": "2076990"
  },
  {
    "text": "through the your SDK we simplified the notion that you lock something and you",
    "start": "2076990",
    "end": "2084310"
  },
  {
    "text": "also have to figure out exactly how your lock data needs to be looking like and structure and how do you like like",
    "start": "2084310",
    "end": "2091750"
  },
  {
    "text": "handle the distributed space that whoever's calling you you give you some information about your entire workflow",
    "start": "2091750",
    "end": "2099370"
  },
  {
    "text": "how do i propagate things down in my tank to my downstream services so these are all handled through the your SDK as",
    "start": "2099370",
    "end": "2107350"
  },
  {
    "text": "the log data is being collected so it will be like a move over right transport",
    "start": "2107350",
    "end": "2112810"
  },
  {
    "text": "it out from the source to the second swim lane which is the transport layer",
    "start": "2112810",
    "end": "2118150"
  },
  {
    "text": "so the this layer we pack the penises fire hose as our solution so",
    "start": "2118150",
    "end": "2126819"
  },
  {
    "text": "the data will be coming over and each service will have its own corresponding",
    "start": "2126819",
    "end": "2132759"
  },
  {
    "text": "fire hose and from which we enrich the data as we collect through data stream",
    "start": "2132759",
    "end": "2138999"
  },
  {
    "text": "so there's a lot of data validation data and Richmond work going on as well as",
    "start": "2138999",
    "end": "2145799"
  },
  {
    "text": "you can see at the bottom of the second swim link that we have used Kinesis",
    "start": "2145799",
    "end": "2151119"
  },
  {
    "text": "analytics so we can then drive like a real-time say with a like a five minutes",
    "start": "2151119",
    "end": "2157779"
  },
  {
    "text": "kind of rolling window we want to detect like what are the the spikes in latency",
    "start": "2157779",
    "end": "2164289"
  },
  {
    "text": "that the p99 of allegiance of service particular self api will there be any spikes in latency",
    "start": "2164289",
    "end": "2171099"
  },
  {
    "text": "error rates inside that these are all like a ton through this layer directly we don't have to wait until the data go",
    "start": "2171099",
    "end": "2178059"
  },
  {
    "text": "somewhere else before we do that so this live feed through the data stream in kinetise firehose we just take advantage",
    "start": "2178059",
    "end": "2184569"
  },
  {
    "text": "of that position and then we put Kinesis analytics we write sequels in canada and",
    "start": "2184569",
    "end": "2189940"
  },
  {
    "text": "it takes to have lambdas it goes of it and then we calculate all these important metrics and the metrics will",
    "start": "2189940",
    "end": "2195759"
  },
  {
    "text": "immediately be put into a cloud watch and then directly consumable through",
    "start": "2195759",
    "end": "2201759"
  },
  {
    "text": "Ravana we have dashboards for each of the services and of course the cloud watch",
    "start": "2201759",
    "end": "2208660"
  },
  {
    "text": "alerts can also send alerts to our others systems you know operating",
    "start": "2208660",
    "end": "2215349"
  },
  {
    "text": "centers such as vegetative source now so this is all kind of connected in some very nice way now from the fire host",
    "start": "2215349",
    "end": "2222700"
  },
  {
    "text": "when the data is coming through we and we do the monitoring immediate monitoring kind of work but the data",
    "start": "2222700",
    "end": "2229450"
  },
  {
    "text": "would then be really put into the third swim lane which is the what we call the",
    "start": "2229450",
    "end": "2234519"
  },
  {
    "text": "shared infrastructure for our storage and that is a primary based on s3 so",
    "start": "2234519",
    "end": "2240039"
  },
  {
    "text": "with s3 as later arrived then we we will do some enrichment and other work to",
    "start": "2240039",
    "end": "2246789"
  },
  {
    "text": "turn into the final form but the the data also as it goes into SV it actually",
    "start": "2246789",
    "end": "2252489"
  },
  {
    "text": "goes to the ethics search business on the in the in for swindling",
    "start": "2252489",
    "end": "2257790"
  },
  {
    "text": "so the elastic search is actually the important part of these of the swim link so we took advantage of the fact that",
    "start": "2257790",
    "end": "2264240"
  },
  {
    "text": "fire hose manages the the the indexing",
    "start": "2264240",
    "end": "2270480"
  },
  {
    "text": "workflow with elastic search we don't have to call a single line of code but",
    "start": "2270480",
    "end": "2276210"
  },
  {
    "text": "just simply get it done right because this is managed through the relationship between fire hose elastic search so we",
    "start": "2276210",
    "end": "2283590"
  },
  {
    "text": "also don't need to have to take care of the static mapping of the schemas we",
    "start": "2283590",
    "end": "2289170"
  },
  {
    "text": "simply rely on dynamic mapping and the the handling the handshake between fire",
    "start": "2289170",
    "end": "2297210"
  },
  {
    "text": "hose and unisex search is amazingly good yeah so we the fire hose will then like",
    "start": "2297210",
    "end": "2304620"
  },
  {
    "text": "a use if the elastic search as the primary destination and we treat s3 as",
    "start": "2304620",
    "end": "2311700"
  },
  {
    "text": "the back-up destination that's how we can achieve the two goes in in one shot",
    "start": "2311700",
    "end": "2317010"
  },
  {
    "text": "right so as the data gets into s3 then we will and reach as I said a little bit",
    "start": "2317010",
    "end": "2322260"
  },
  {
    "text": "earlier and then we this becomes our overall data like part of the operation",
    "start": "2322260",
    "end": "2327630"
  },
  {
    "text": "and then the end users and then based on the particular use case if I am a",
    "start": "2327630",
    "end": "2333720"
  },
  {
    "text": "forensic team I can use elastic search I can use Athena as well to act on some of",
    "start": "2333720",
    "end": "2340530"
  },
  {
    "text": "the data that's been store like over the weeks or months but then you'll ask",
    "start": "2340530",
    "end": "2345780"
  },
  {
    "text": "Church for elastic search we we give them immediate access to the data just happening so we do not store a lot of",
    "start": "2345780",
    "end": "2352980"
  },
  {
    "text": "data into elastic search we we saw like currently five days of operational data",
    "start": "2352980",
    "end": "2359520"
  },
  {
    "text": "because we believe the elastic search is primary to be used for forensic activities but we see selectively",
    "start": "2359520",
    "end": "2367400"
  },
  {
    "text": "allow data to some of the indexes to be having a longer retention period right",
    "start": "2367400",
    "end": "2373230"
  },
  {
    "text": "so there are things that we feel is important for create to create like real time dashboard on some operational stuff",
    "start": "2373230",
    "end": "2379290"
  },
  {
    "text": "so those are things that rely on your search keep honor for us to do it but the power cloak of the data storage will",
    "start": "2379290",
    "end": "2385730"
  },
  {
    "text": "on s3 as our long-term durable store so that's over architecture so so graph",
    "start": "2385730",
    "end": "2394460"
  },
  {
    "start": "2392000",
    "end": "2399000"
  },
  {
    "text": "honor as I call out is our primary dashboarding to make use of a carwash data that comes with the through the",
    "start": "2394460",
    "end": "2401750"
  },
  {
    "text": "Genesis Pharaoh's pipeline so this is one example the is one of our",
    "start": "2401750",
    "end": "2407060"
  },
  {
    "text": "mission-critical class zero surface you cannot go down so the metrics that you",
    "start": "2407060",
    "end": "2413930"
  },
  {
    "text": "show in here represents that progress service some of the key api so we",
    "start": "2413930",
    "end": "2419660"
  },
  {
    "text": "actually like a deuce kinases analytics as the log data of that service goes",
    "start": "2419660",
    "end": "2425480"
  },
  {
    "text": "through firehose we calculate these metrics and then it shows in cloud watch and picked up by keep on at just like",
    "start": "2425480",
    "end": "2432710"
  },
  {
    "text": "that it's pretty real-time right so when things goes wrong and if there's a like",
    "start": "2432710",
    "end": "2438350"
  },
  {
    "text": "a threshold of red light color cross then a loss will be sent and then the rest of the motion becoming to play we",
    "start": "2438350",
    "end": "2445369"
  },
  {
    "start": "2444000",
    "end": "2463000"
  },
  {
    "text": "also use coroner to monitor our own infrastructure which is the architects program that i just show you so this a",
    "start": "2445369",
    "end": "2452750"
  },
  {
    "text": "dashboard for this infrastructure and in particular i'm showing here the way that",
    "start": "2452750",
    "end": "2458180"
  },
  {
    "text": "we're monitoring elasticsearch using the same implementation so i want to touch",
    "start": "2458180",
    "end": "2464780"
  },
  {
    "start": "2463000",
    "end": "2660000"
  },
  {
    "text": "upon a little bit of our approach of handling law record so now i'm getting",
    "start": "2464780",
    "end": "2469940"
  },
  {
    "text": "into a little bit of a layer seven kind of discussion here now so i said this as i like explaining a bit earlier so we",
    "start": "2469940",
    "end": "2477920"
  },
  {
    "text": "have a problem dealing with different kinds of log format and then it's difficult for us to put the make sense",
    "start": "2477920",
    "end": "2485330"
  },
  {
    "text": "out of different systems a lot record together so this initiative which is called unify marketing is trying to address that problem right so the way",
    "start": "2485330",
    "end": "2492500"
  },
  {
    "text": "that we do it is to standardize on a log data model right something that is",
    "start": "2492500",
    "end": "2498320"
  },
  {
    "text": "people that that that we go through like a years of evolution come to a point",
    "start": "2498320",
    "end": "2504950"
  },
  {
    "text": "that we feel this is a way of doing it and the way that we do it is through",
    "start": "2504950",
    "end": "2511580"
  },
  {
    "text": "that log data model we allow a notation so we so it has to be a way for us to",
    "start": "2511580",
    "end": "2517880"
  },
  {
    "text": "put additional data into the lock record so that when we search through the lock record we can",
    "start": "2517880",
    "end": "2523610"
  },
  {
    "text": "rely on criteria based on metadata value so anything in law record is the key",
    "start": "2523610",
    "end": "2530110"
  },
  {
    "text": "part of the solution of this unify log initiative we adopt open tracing as our",
    "start": "2530110",
    "end": "2537260"
  },
  {
    "text": "standard so we don't have to reinvent some of the good work that the community",
    "start": "2537260",
    "end": "2542720"
  },
  {
    "text": "has done when it comes to representing first-class objects operations and things like that so that give us a",
    "start": "2542720",
    "end": "2548390"
  },
  {
    "text": "pretty good head start in this in this in this effort and we provide SDK",
    "start": "2548390",
    "end": "2554630"
  },
  {
    "text": "support so we have around five major languages in our ecosystem so each of these we have a corresponding SDK that",
    "start": "2554630",
    "end": "2561080"
  },
  {
    "text": "each of them are just parity having feature parity across each other so so",
    "start": "2561080",
    "end": "2566660"
  },
  {
    "text": "we make sure that all the teams that work with us here have their own tools to actually do the job very quickly this",
    "start": "2566660",
    "end": "2574580"
  },
  {
    "text": "is an example of what a before logging record looks like so it's in JSON it's largely divided into three parts so the",
    "start": "2574580",
    "end": "2581240"
  },
  {
    "text": "first part is a the part that we call the metadata part which deals with the",
    "start": "2581240",
    "end": "2588770"
  },
  {
    "text": "distributed tracing stage so you can take a look at the second one which the other has been ID so the hash value here",
    "start": "2588770",
    "end": "2596630"
  },
  {
    "text": "is a it's a time stamp based kind of hash value and it's x-ray compliant so",
    "start": "2596630",
    "end": "2602090"
  },
  {
    "text": "the the rest of the headers here so in the first section we we we are able to",
    "start": "2602090",
    "end": "2608300"
  },
  {
    "text": "inject additional stage as packages or set of like a key value pairs that we",
    "start": "2608300",
    "end": "2614930"
  },
  {
    "text": "can also inject and carry along and each of the lot record for the comment section for disabilities choice metadata",
    "start": "2614930",
    "end": "2620480"
  },
  {
    "text": "will contain those states as well the second part is the metadata for that particular span so if you recall in my",
    "start": "2620480",
    "end": "2627680"
  },
  {
    "text": "example or the gray boxes college it connected each other so each of the gray parts where the participating in a particular workflow",
    "start": "2627680",
    "end": "2633740"
  },
  {
    "text": "is actually can be represented as a span so if in the duration of the of the",
    "start": "2633740",
    "end": "2640250"
  },
  {
    "text": "lifespan of Earth gray box so the second section represents the metadata of - BAM",
    "start": "2640250",
    "end": "2646220"
  },
  {
    "text": "and then the third section is actually the real meet right which is the lock data the current that the applications or the service",
    "start": "2646220",
    "end": "2653400"
  },
  {
    "text": "cares about so this lastly is a structure of a unified locking solution so what we do",
    "start": "2653400",
    "end": "2662940"
  },
  {
    "text": "what can we do with this interlocking data so if you recall my architecture",
    "start": "2662940",
    "end": "2668070"
  },
  {
    "text": "diagram so as the data goes through the fire hose into different stages at some",
    "start": "2668070",
    "end": "2673410"
  },
  {
    "text": "point we do a lot of and Richmond and stuff so it is one example in the in the architecture diagram that we can",
    "start": "2673410",
    "end": "2679950"
  },
  {
    "text": "actually make sense out of the lock data and and do extraction upon the the meta",
    "start": "2679950",
    "end": "2686820"
  },
  {
    "text": "data for the digital stays and stuff and actually can put into x-ray as segments",
    "start": "2686820",
    "end": "2692190"
  },
  {
    "text": "so with x-ray we are able to do a graphical service map like this and we can do a coarse grain like a",
    "start": "2692190",
    "end": "2699080"
  },
  {
    "text": "understanding of the well-being of our entire fortune ecosystem for the last 24",
    "start": "2699080",
    "end": "2704310"
  },
  {
    "text": "hours so which system is actually having a problem turning to rest and things like that but we can also do very fine",
    "start": "2704310",
    "end": "2710460"
  },
  {
    "text": "grained service map because all the metadata that we are put as an OTA annotation in a lot record can be",
    "start": "2710460",
    "end": "2718070"
  },
  {
    "text": "annotation map and annotation metadata into x-ray segment you can actually create those things very precisely so we",
    "start": "2718070",
    "end": "2725190"
  },
  {
    "text": "can have a fine grain very fine grain source map per user intersection as well so it's pretty powerful so how do we",
    "start": "2725190",
    "end": "2733380"
  },
  {
    "start": "2731000",
    "end": "2864000"
  },
  {
    "text": "help each other team to easily get on to this solution so as you can see there",
    "start": "2733380",
    "end": "2739050"
  },
  {
    "text": "are so many moving parts we asked each team to to work on each of the solutions",
    "start": "2739050",
    "end": "2744210"
  },
  {
    "text": "and peel and provision things the way I show in a diagram it's gonna take forever and no one's going to do that so",
    "start": "2744210",
    "end": "2751050"
  },
  {
    "text": "we take a simplified CR C D onboarding kind of approach so a team just simply",
    "start": "2751050",
    "end": "2757589"
  },
  {
    "text": "needs to do this tell us a few things which is at a top right part of the",
    "start": "2757589",
    "end": "2762839"
  },
  {
    "text": "diagram a little bit the scripture that tell us about who you are and there is a what we call a system moniker which is a",
    "start": "2762839",
    "end": "2770250"
  },
  {
    "text": "label right a little taxonomy on outside identify this your identity so when you",
    "start": "2770250",
    "end": "2775740"
  },
  {
    "text": "when this when this JSON is pushed to the github then it will generate trigger",
    "start": "2775740",
    "end": "2783599"
  },
  {
    "text": "some Chinese job and generate the repo for that service and which is in the middle part of this",
    "start": "2783599",
    "end": "2788640"
  },
  {
    "text": "diagram so and that Killa people is well generated with templates and cokes and",
    "start": "2788640",
    "end": "2795630"
  },
  {
    "text": "stuff that the team will only need to define a few things such as okay these are the five api's and here the names",
    "start": "2795630",
    "end": "2802260"
  },
  {
    "text": "that I care about and here's the red line that I want you to keep to track this for me for any anonomys and show up",
    "start": "2802260",
    "end": "2809010"
  },
  {
    "text": "in a dashboard so you change a few of these things and then you check the lid and then we also kick off another",
    "start": "2809010",
    "end": "2815040"
  },
  {
    "text": "pipeline in Jenkins to actually do the provisioning for you so which ends up at the lower part of",
    "start": "2815040",
    "end": "2820800"
  },
  {
    "text": "the diagram or the fire hose pipelines for for your service will be will be",
    "start": "2820800",
    "end": "2825840"
  },
  {
    "text": "done correctly and then the we also will provision a coffin dashboard for you and",
    "start": "2825840",
    "end": "2831200"
  },
  {
    "text": "and then so automatics that that you you you tell us is needed to do will be",
    "start": "2831200",
    "end": "2837060"
  },
  {
    "text": "generated with corresponding Genesis analytics scripts so so the whole",
    "start": "2837060",
    "end": "2844260"
  },
  {
    "text": "process takes maybe fifteen minutes for us to actually publish in the entire structure and then immediately the teams",
    "start": "2844260",
    "end": "2851280"
  },
  {
    "text": "can start playing with it and general all records and then they almost like I in 15-20 minutes they can see the rocket",
    "start": "2851280",
    "end": "2857820"
  },
  {
    "text": "going through and that pipeline quite easily so that's how we do things and on board all our services team so now why",
    "start": "2857820",
    "end": "2867210"
  },
  {
    "start": "2864000",
    "end": "2937000"
  },
  {
    "text": "do we pay elasticsearch right Amazon you're a sexual surface first of all is a fully managed service where you don't",
    "start": "2867210",
    "end": "2873270"
  },
  {
    "text": "have to we don't have to know have a deep knowledge about some of the inner workings of your texture and and that's",
    "start": "2873270",
    "end": "2879450"
  },
  {
    "text": "not how we intend to do it anyway so we like this one is highly available it it",
    "start": "2879450",
    "end": "2885780"
  },
  {
    "text": "will it will take care of all the availability issues for us and we like it it's quite easy to provision and the",
    "start": "2885780",
    "end": "2892530"
  },
  {
    "text": "skinning process a simple point-and-click or running a similar man line you add more Knox to it and it will",
    "start": "2892530",
    "end": "2897660"
  },
  {
    "text": "done quite quite handily for us there's a lot of instance type selection for us",
    "start": "2897660",
    "end": "2903960"
  },
  {
    "text": "and and there is a exercise that we have that we've gone through about our sizing and capacity planning stuff which are",
    "start": "2903960",
    "end": "2909869"
  },
  {
    "text": "going to come next so but it gives a lot of options for us to like a configure our cluster",
    "start": "2909869",
    "end": "2916470"
  },
  {
    "text": "we like the seamless integration with a fire hose and all the things that about",
    "start": "2916470",
    "end": "2922270"
  },
  {
    "text": "s3 integration and all together this is a very well thought-out kind of integration solution carwash metrics",
    "start": "2922270",
    "end": "2929170"
  },
  {
    "text": "integration for our monitoring which is important Gabanna is part of it we love it and",
    "start": "2929170",
    "end": "2934410"
  },
  {
    "text": "it's very cost effective now so the cost effective in this part of the solution",
    "start": "2934410",
    "end": "2941640"
  },
  {
    "start": "2937000",
    "end": "3068000"
  },
  {
    "text": "doesn't come easy right so we actually have gone through a proper sizing exercise so this is the",
    "start": "2941640",
    "end": "2949630"
  },
  {
    "text": "template that we use for us to come up with that conclusion so enough had explained about some of",
    "start": "2949630",
    "end": "2957640"
  },
  {
    "text": "those shining concerns you got to take care of active shots and things like that now this is exactly the exercise",
    "start": "2957640",
    "end": "2963309"
  },
  {
    "text": "that we going through so when you do a sign saying exercise for MS Onalaska",
    "start": "2963309",
    "end": "2968799"
  },
  {
    "text": "search you have to think about your ingestion rate your storage requirement and then your particular pattern of how",
    "start": "2968799",
    "end": "2976809"
  },
  {
    "text": "how you're going to use the service for our purpose of doing log processing the",
    "start": "2976809",
    "end": "2983349"
  },
  {
    "text": "definition of active shots is about among of data that is going to ingest it",
    "start": "2983349",
    "end": "2988599"
  },
  {
    "text": "into the pipeline in a 24 hour period so we look at it as the selling point of",
    "start": "2988599",
    "end": "2994990"
  },
  {
    "text": "like 3 terabytes of bathing ingestion right and then from which we determine",
    "start": "2994990",
    "end": "3000839"
  },
  {
    "text": "okay so how many shots per index that we will be dealing with so by default as",
    "start": "3000839",
    "end": "3006150"
  },
  {
    "text": "you all know that the default is 5 shots but some indexes are smaller so we actually can have fewer number of shots",
    "start": "3006150",
    "end": "3013260"
  },
  {
    "text": "so altogether we do a tarry and then this is exactly how many shots we need and then with respect to the total",
    "start": "3013260",
    "end": "3019559"
  },
  {
    "text": "storage which is 2 terabytes as 3 terabytes of starting porn then we work",
    "start": "3019559",
    "end": "3024569"
  },
  {
    "text": "backwards and forward like what instant stuff is actually feeding our purpose because the number of active just",
    "start": "3024569",
    "end": "3030869"
  },
  {
    "text": "determined the number of we CPUs that we need so we ended up choose like I 3 as",
    "start": "3030869",
    "end": "3037200"
  },
  {
    "text": "our instant stuff of choice so you can see we might not fully utilize all the",
    "start": "3037200",
    "end": "3043890"
  },
  {
    "text": "BCP you but because of the fact that we have to deal with the source requirement so this is how we end",
    "start": "3043890",
    "end": "3049029"
  },
  {
    "text": "being and and you as you can see the other columns here gives our solution skills and start putting more data into",
    "start": "3049029",
    "end": "3057339"
  },
  {
    "text": "the pipeline the cost of the infrastructure actually is quite linear it's not gonna be expect this one n show",
    "start": "3057339",
    "end": "3063939"
  },
  {
    "text": "so it was I think this is a quick solution for us right so keep on",
    "start": "3063939",
    "end": "3070269"
  },
  {
    "start": "3068000",
    "end": "3083000"
  },
  {
    "text": "definitely is one of the things that we have adopted so there's so many teams that build their own dashboards for for",
    "start": "3070269",
    "end": "3076989"
  },
  {
    "text": "their own purpose so is a like a very good like a feature that everyone likes",
    "start": "3076989",
    "end": "3083369"
  },
  {
    "start": "3083000",
    "end": "3174000"
  },
  {
    "text": "now so this is a lessons that we have learned right we start small we we want",
    "start": "3083369",
    "end": "3091359"
  },
  {
    "text": "to keep the things key the ball rolling quickly so the first thing that we did is to put everything into one index so",
    "start": "3091359",
    "end": "3097719"
  },
  {
    "text": "we have our services and products are on board gradually so at the beginning let's keep it simple put everything into",
    "start": "3097719",
    "end": "3103390"
  },
  {
    "text": "one index but very quickly find out it's not gonna work you can see from the from",
    "start": "3103390",
    "end": "3109929"
  },
  {
    "text": "the dashboard here so the CPU utilization actually spikes up just like that right so it's like at 80% or above",
    "start": "3109929",
    "end": "3116409"
  },
  {
    "text": "as enough show you want to slide that definitely is not a good sign so when it",
    "start": "3116409",
    "end": "3121539"
  },
  {
    "text": "happens everything stops so I cannot do for indexing query it's gonna be extremely slow no one can do anything",
    "start": "3121539",
    "end": "3126999"
  },
  {
    "text": "right and then and because of that we cannot on putting more services",
    "start": "3126999",
    "end": "3132309"
  },
  {
    "text": "everything car stop so that's a bigger problem we also have find out that the",
    "start": "3132309",
    "end": "3138789"
  },
  {
    "text": "way that we put everything into a single index so as all the teams ingest a lot",
    "start": "3138789",
    "end": "3143799"
  },
  {
    "text": "record there's a lot of JSON and there's a lot of dynamic types of JSON like maps",
    "start": "3143799",
    "end": "3149019"
  },
  {
    "text": "or collections and stuff like that so we are not aware of the fact that when",
    "start": "3149019",
    "end": "3154089"
  },
  {
    "text": "everything together it exists a thousand views limitation so it a success index",
    "start": "3154089",
    "end": "3160329"
  },
  {
    "text": "by default is a thousand views if you exceed that will be per performance problem so we encounter that this",
    "start": "3160329",
    "end": "3166749"
  },
  {
    "text": "particular situation like maybe a few months into into the whole like",
    "start": "3166749",
    "end": "3171839"
  },
  {
    "text": "execution of the project so there are a couple options that we consider to",
    "start": "3171839",
    "end": "3177009"
  },
  {
    "start": "3174000",
    "end": "3336000"
  },
  {
    "text": "mitigate it we option number one we make we put up",
    "start": "3177009",
    "end": "3183369"
  },
  {
    "text": "an index for each service so we've actually find out that is pretty good deal for us because most other services",
    "start": "3183369",
    "end": "3190990"
  },
  {
    "text": "will have definitely much less than a thousand fields some of the picker ones we have 200 or 300 at most so this could",
    "start": "3190990",
    "end": "3197829"
  },
  {
    "text": "be a good thing and we can actually do query upon a index directly rather than",
    "start": "3197829",
    "end": "3203470"
  },
  {
    "text": "having a big index and every search you got to go through all all the records so",
    "start": "3203470",
    "end": "3208480"
  },
  {
    "text": "it's not so we believe it's going to give us better efficiency and but at the same time we increase our complexity in",
    "start": "3208480",
    "end": "3215260"
  },
  {
    "text": "terms of the provisioning process so but we can because of the automation work maybe it's worthwhile for us to do so",
    "start": "3215260",
    "end": "3221230"
  },
  {
    "text": "not everybody knows at least you know was how many be an Essene after all option two is to keep single index right",
    "start": "3221230",
    "end": "3228520"
  },
  {
    "text": "but to set the mass field to a bigger value like like two thousand but then we know",
    "start": "3228520",
    "end": "3234279"
  },
  {
    "text": "that is the anti-pattern there's going to be impact of impact performance but what what if we keep going and grow",
    "start": "3234279",
    "end": "3240520"
  },
  {
    "text": "beyond 2000 we're gonna do right so it doesn't work it won't scale and is we",
    "start": "3240520",
    "end": "3246369"
  },
  {
    "text": "can't do it like that option three is well then again keep a simple index but make it operationally Frannie so such as",
    "start": "3246369",
    "end": "3254260"
  },
  {
    "text": "we define maybe 50 coffee use and then we have another 200 like customers views",
    "start": "3254260",
    "end": "3259900"
  },
  {
    "text": "that customer views that you can do your own mapping so operationally that one is good right so we have pretty much control the",
    "start": "3259900",
    "end": "3267760"
  },
  {
    "text": "plus radius and it won't actually go beyond the limit but at the same time they used to pay this sucks right so how",
    "start": "3267760",
    "end": "3274480"
  },
  {
    "text": "do you do a query on some indirect referring to some fuse like that so you",
    "start": "3274480",
    "end": "3279490"
  },
  {
    "text": "know one will reduce the solution so that's why we go for option number one we do this thing right and there are",
    "start": "3279490",
    "end": "3286930"
  },
  {
    "text": "other things that we have learned along the way about managing the sizing of the of the cluster as well so as I said by",
    "start": "3286930",
    "end": "3294130"
  },
  {
    "text": "default there with five shots per index so for the most of indexes that are 250",
    "start": "3294130",
    "end": "3300430"
  },
  {
    "text": "gigabyte it works and we also stick to the recommendation that we use like a 5",
    "start": "3300430",
    "end": "3307089"
  },
  {
    "text": "gig of 50 gigabyte push as a shot-for-shot size so because of that smaller indexes smaller",
    "start": "3307089",
    "end": "3313210"
  },
  {
    "text": "services we do we we do a customization that they would have only one shot so",
    "start": "3313210",
    "end": "3318370"
  },
  {
    "text": "anything that is daily ingestion basis less than 50k well one shot for those",
    "start": "3318370",
    "end": "3323410"
  },
  {
    "text": "kind of indexes and we did a lot tons of offensive load tests to make sure some of the offers hypothesis theories kind",
    "start": "3323410",
    "end": "3330310"
  },
  {
    "text": "of whole we have a set of regression weapons load tests that will keep running so and at this point we feel",
    "start": "3330310",
    "end": "3337360"
  },
  {
    "start": "3336000",
    "end": "3354000"
  },
  {
    "text": "pretty good about our current status of things you can see this the the current state of our other stuff so most of the",
    "start": "3337360",
    "end": "3344350"
  },
  {
    "text": "time the CPUs around 40 to 50 percent so we are not under utilizing things and at",
    "start": "3344350",
    "end": "3350050"
  },
  {
    "text": "the same time we are not actually making things too crazy so I want to wrap it up",
    "start": "3350050",
    "end": "3356320"
  },
  {
    "start": "3354000",
    "end": "3488000"
  },
  {
    "text": "by sharing some of the overall lessons that we've learned so the the entire",
    "start": "3356320",
    "end": "3362290"
  },
  {
    "text": "initiatives start up small we are a relatively big company but we have we",
    "start": "3362290",
    "end": "3368350"
  },
  {
    "text": "take a little bit of a startup kind of mode in this and in this project so we go through some inception phase a little",
    "start": "3368350",
    "end": "3375520"
  },
  {
    "text": "incubator and to build entire end-to-end to make sure that these things works and then we acquire enough funding to build",
    "start": "3375520",
    "end": "3383260"
  },
  {
    "text": "an entire thing completely and then we're now getting into the aggressive adoption phase now so the whole unify",
    "start": "3383260",
    "end": "3389590"
  },
  {
    "text": "walking and the all these things can only bring up bring forth the best value",
    "start": "3389590",
    "end": "3395590"
  },
  {
    "text": "if there is a widespread adoption in a company so the management support from",
    "start": "3395590",
    "end": "3401140"
  },
  {
    "text": "the top down making sure everyone aware of the value is important so and we are",
    "start": "3401140",
    "end": "3406450"
  },
  {
    "text": "still in the process of making sure bringing in a lot of different services on board we have a lot of services",
    "start": "3406450",
    "end": "3412020"
  },
  {
    "text": "sizing is important so and we partner up early with our finance team to make sure",
    "start": "3412020",
    "end": "3417760"
  },
  {
    "text": "that our solution is well within budget so it's quite easy for us to put up something especially in classic search",
    "start": "3417760",
    "end": "3423190"
  },
  {
    "text": "that you don't understand the relationship between cost performance and the the infrastructure need you can",
    "start": "3423190",
    "end": "3431680"
  },
  {
    "text": "easily blow up your budget so I think it's important to be cost aware at the",
    "start": "3431680",
    "end": "3437260"
  },
  {
    "text": "beginning of this journey the HR just like any other project we don't overdo",
    "start": "3437260",
    "end": "3442780"
  },
  {
    "text": "and we encounter problems as I to you and then we tackle it there's always things that we we don't know that",
    "start": "3442780",
    "end": "3448670"
  },
  {
    "text": "we don't know and and those are the surprises that we know that will come at us at some point in different way we",
    "start": "3448670",
    "end": "3455720"
  },
  {
    "text": "just have to prioritize the risk divide and conquer use many services we we we",
    "start": "3455720",
    "end": "3463190"
  },
  {
    "text": "don't attempt to build and manage these things separately other than using a diverse menu services we're a small team",
    "start": "3463190",
    "end": "3469610"
  },
  {
    "text": "and actually it's the best deal for us partnership with a diverse team these",
    "start": "3469610",
    "end": "3475850"
  },
  {
    "text": "guys are very helpful every step along the way and we feel grateful about that so that's all I prepared for today and",
    "start": "3475850",
    "end": "3484220"
  },
  {
    "text": "thank you very much [Applause]",
    "start": "3484220",
    "end": "3490660"
  }
]
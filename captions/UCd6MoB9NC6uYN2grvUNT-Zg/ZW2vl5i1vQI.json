[
  {
    "start": "0",
    "end": "55000"
  },
  {
    "text": "so uh thanks for joining our session you know it's always nice to be the opening act here out of a great day of sessions",
    "start": "3290",
    "end": "10450"
  },
  {
    "text": "you know like like she mentioned my name's Spencer I'm a specialist essay in data and analytics and AI mmm what we're",
    "start": "10450",
    "end": "16910"
  },
  {
    "text": "going to be talking about in this session is really how can you use analytics big data and merge that with",
    "start": "16910",
    "end": "23060"
  },
  {
    "text": "AI technologies machine learning technologies to both be able to drive insights for your organization's as well",
    "start": "23060",
    "end": "29359"
  },
  {
    "text": "as added telogen stew your solutions and we'll do that by going through a couple of different flows essentially what",
    "start": "29359",
    "end": "35809"
  },
  {
    "text": "we're gonna do first is talk about analytics and some common pitfalls we see our customers have that way you",
    "start": "35809",
    "end": "41269"
  },
  {
    "text": "don't have to find yourself in that same situation we're gonna give some demonstrations throughout because it's",
    "start": "41269",
    "end": "47510"
  },
  {
    "text": "always nice to show you know real real running systems as you guys are seeing this and then some final tenants so you",
    "start": "47510",
    "end": "57409"
  },
  {
    "start": "55000",
    "end": "130000"
  },
  {
    "text": "know big data analytics are defined many many different ways by different customers what it really boils down to",
    "start": "57409",
    "end": "62659"
  },
  {
    "text": "is you know either high velocity data high volumes of data you don't necessarily have to have you know",
    "start": "62659",
    "end": "69650"
  },
  {
    "text": "petabytes and terabytes of information to have big data problems sometimes it's unstructured data sometimes the data is",
    "start": "69650",
    "end": "76340"
  },
  {
    "text": "coming at you very very quickly you need to be able to capture it story analyze it so big data oftentimes is",
    "start": "76340",
    "end": "82760"
  },
  {
    "text": "categorized in different types of v's and we won't necessarily spend a lot of time defining 3 B's 5 es 7 vs that sort",
    "start": "82760",
    "end": "89660"
  },
  {
    "text": "of thing but you know if you take a look at industry and what analysts are saying you know it's very consistent with this",
    "start": "89660",
    "end": "96530"
  },
  {
    "text": "so you know over 90% of today's data was generated in the last two years the rate",
    "start": "96530",
    "end": "102170"
  },
  {
    "text": "of data generation is constantly growing a lot of it is unstructured data and a lot of is coming very very quickly from",
    "start": "102170",
    "end": "109370"
  },
  {
    "text": "IOT sensors from clickstream data various data sources but what really",
    "start": "109370",
    "end": "114590"
  },
  {
    "text": "matters isn't necessarily you know how you define big data where the data is coming from but really being able to",
    "start": "114590",
    "end": "121190"
  },
  {
    "text": "drive insights from it so how can you use this data to be able to really drive insights in and power your your your",
    "start": "121190",
    "end": "128390"
  },
  {
    "text": "business and what that really requires is new ways of analyzing your data so a",
    "start": "128390",
    "end": "136400"
  },
  {
    "start": "130000",
    "end": "213000"
  },
  {
    "text": "lot times you know in traditional approaches with relational databases with data warehouses you know those approaches",
    "start": "136400",
    "end": "143090"
  },
  {
    "text": "work very well for structured data that you fit your data into that particular structure ahead of time and then you run",
    "start": "143090",
    "end": "149090"
  },
  {
    "text": "reports you run analytics on top of that data but as your different data sets are changing as you're collecting",
    "start": "149090",
    "end": "154880"
  },
  {
    "text": "unstructured and semi-structured data maybe it's imagery maybe it's video we're gonna show some demonstrations of",
    "start": "154880",
    "end": "160340"
  },
  {
    "text": "that later in the session being able to run new types of analytics on that data is really key and that's why we're",
    "start": "160340",
    "end": "167180"
  },
  {
    "text": "really seeing this this hybrid architecture or this architecture that is really complementing those databases",
    "start": "167180",
    "end": "174200"
  },
  {
    "text": "and data warehouses with you know the concepts of things like a data Lake how can you have really boast of those most",
    "start": "174200",
    "end": "180680"
  },
  {
    "text": "of both of those benefits where you have that high performance data warehouse but",
    "start": "180680",
    "end": "185750"
  },
  {
    "text": "you're also able to do big data analytics spark and pala press though these sorts of analytics on your data",
    "start": "185750",
    "end": "192230"
  },
  {
    "text": "you might also want to be able to do image recognition you know audio to text transcriptions those sorts of things on",
    "start": "192230",
    "end": "199880"
  },
  {
    "text": "different sorts of data artifacts to be able to power that that solution the",
    "start": "199880",
    "end": "206720"
  },
  {
    "text": "other really key thing is you know being able to plug in those machine learning algorithms into into your framework and",
    "start": "206720",
    "end": "213260"
  },
  {
    "start": "213000",
    "end": "293000"
  },
  {
    "text": "a little different you know comparison between you know a database a data",
    "start": "213260",
    "end": "218480"
  },
  {
    "text": "warehouse and a data Lake where with databases you know it's a schema on right what I'm what that means is you",
    "start": "218480",
    "end": "224959"
  },
  {
    "text": "know I define my schema up front and if I want to load new data in that schema I'd i use an ETL tool it might be our",
    "start": "224959",
    "end": "231320"
  },
  {
    "text": "tools it might be some of our great partners like informatica tell end you know cloud be maternity all these",
    "start": "231320",
    "end": "237020"
  },
  {
    "text": "partners that provide really good ETL to the software but you're really taking that data and fitting it into a schema",
    "start": "237020",
    "end": "243140"
  },
  {
    "text": "that you defined data links are a little different and that's why they complement each other really well with data lakes",
    "start": "243140",
    "end": "249500"
  },
  {
    "text": "you're able to store all your data upfront so when we're given our first demo we're actually going to be demoing where we have data already stored in our",
    "start": "249500",
    "end": "256760"
  },
  {
    "text": "data Lake and we want to start understanding that data and analyzing that data it might be at first just",
    "start": "256760",
    "end": "262669"
  },
  {
    "text": "understanding what the fields are what the distributions of the fields are how are those fields correlated but it might",
    "start": "262669",
    "end": "268910"
  },
  {
    "text": "also be advanced analytics and learning on that data you know maybe I want to predict something like customer",
    "start": "268910",
    "end": "274520"
  },
  {
    "text": "churn or citizen you know how happy our citizens are or you know maybe I want to recognize things in these audios and",
    "start": "274520",
    "end": "281599"
  },
  {
    "text": "these videos and those sorts of things so so those things data lakes and data",
    "start": "281599",
    "end": "287000"
  },
  {
    "text": "warehouses really work very very nicely together in those solutions the the",
    "start": "287000",
    "end": "295159"
  },
  {
    "start": "293000",
    "end": "347000"
  },
  {
    "text": "other thing is you know with data lakes on AWS essentially how we're seeing those architectures evolve is really",
    "start": "295159",
    "end": "302590"
  },
  {
    "text": "having a central storage on on AWS and you know s3 is the core piece of a data",
    "start": "302590",
    "end": "308960"
  },
  {
    "text": "Lake and on AWS so s3 becomes essential content storage you know it provides",
    "start": "308960",
    "end": "315620"
  },
  {
    "text": "11-9 to durability what that means in kind of layman terms is if you store 10 million objects out on s3 you may on",
    "start": "315620",
    "end": "323090"
  },
  {
    "text": "average lose one in every 10,000 years so that's kind of if you think about that you know data durability is a very very",
    "start": "323090",
    "end": "330560"
  },
  {
    "text": "fantastic on s3 in the past life I built a dupe clusters on premises and if we",
    "start": "330560",
    "end": "336500"
  },
  {
    "text": "tried to achieve 11:9 Center ability that was nearly impossible because we're always in one data center that sort of thing so",
    "start": "336500",
    "end": "342740"
  },
  {
    "text": "amazing amazing data durability so with",
    "start": "342740",
    "end": "348740"
  },
  {
    "start": "347000",
    "end": "476000"
  },
  {
    "text": "that data Lake and that data durability on s3 there's some other aspects to that data Lake so on the bottom here you'll",
    "start": "348740",
    "end": "355130"
  },
  {
    "text": "notice the storage piece you also need very very rich life cycles of your storage so your most recent data",
    "start": "355130",
    "end": "361880"
  },
  {
    "text": "oftentimes you're accessing most frequent so how can you make that very very hot easily consumable by your",
    "start": "361880",
    "end": "368000"
  },
  {
    "text": "analytics but then also being able to categorize that data it's in it's",
    "start": "368000",
    "end": "373159"
  },
  {
    "text": "interesting because metadata management is a very common aspect that's overlooked by folks that are standing up",
    "start": "373159",
    "end": "378560"
  },
  {
    "text": "data lakes analytics machine learning on AWS and really anywhere so being able to",
    "start": "378560",
    "end": "384590"
  },
  {
    "text": "categorize your data so you could find it and use it within these tools that's really really key so that's really the",
    "start": "384590",
    "end": "391340"
  },
  {
    "text": "foundational part but then you also have how you get data from on-premises into",
    "start": "391340",
    "end": "396409"
  },
  {
    "text": "the cloud how can get data from software vendors or as you know software as-a-service vendors into your system",
    "start": "396409",
    "end": "402620"
  },
  {
    "text": "how can you capture real time data cooked stream data IOT sensors connected sensors in cities smart cities",
    "start": "402620",
    "end": "409640"
  },
  {
    "text": "that sort of thing so these are all aspects of the data Lake kind of centered around that s3 storage that",
    "start": "409640",
    "end": "416630"
  },
  {
    "text": "that raw storage of being able to have those bits in s3 there's a lot of other",
    "start": "416630",
    "end": "422870"
  },
  {
    "text": "facets so very very important aspects like data security auditing logging",
    "start": "422870",
    "end": "428330"
  },
  {
    "text": "about all the access of your data we could easily spend an hour on any of",
    "start": "428330",
    "end": "433580"
  },
  {
    "text": "these boxes so but what we're going to do in this session is we're really going to focus on the analytics and machine",
    "start": "433580",
    "end": "439160"
  },
  {
    "text": "learning of your data and also the metadata management of that data so I want just to include this slide to say",
    "start": "439160",
    "end": "445610"
  },
  {
    "text": "there are these other parts worth considering when you're looking at your solution and the AWS services work very",
    "start": "445610",
    "end": "452810"
  },
  {
    "text": "very well together and with our partners to be able to provide aspects of these of these components so here's a here's",
    "start": "452810",
    "end": "460310"
  },
  {
    "text": "some of the services that fit into these different categories of being able to collect and ingest your data categorize",
    "start": "460310",
    "end": "466970"
  },
  {
    "text": "it analyze it and again we're going to spend a lot of time on the analyzing metadata management and machine learning",
    "start": "466970",
    "end": "473060"
  },
  {
    "text": "of the data so you know Before we jump",
    "start": "473060",
    "end": "478280"
  },
  {
    "start": "476000",
    "end": "567000"
  },
  {
    "text": "to some demonstrations and how to really do this in practice what I like to include a lot of times are what are some",
    "start": "478280",
    "end": "484220"
  },
  {
    "text": "of the most common issues common problems you know things to consider when you're looking at building an analytical system machine learning",
    "start": "484220",
    "end": "490660"
  },
  {
    "text": "system both in general and as well as on AWS the first analogy that we like to",
    "start": "490660",
    "end": "497600"
  },
  {
    "text": "give a lot of times is what tools should I use if you look at the ecosystem the",
    "start": "497600",
    "end": "503570"
  },
  {
    "text": "ecosystem is very very giant so you you have a lot of options to you in terms of what tool to use for different jobs and",
    "start": "503570",
    "end": "509570"
  },
  {
    "text": "what we like to say is you know pick the best tool for the job you're trying to do so rather than trying to use a giant",
    "start": "509570",
    "end": "516500"
  },
  {
    "text": "Swiss Army knife that sure it has a screwdriver that you could screw in a screw use a drill to screw in you know",
    "start": "516500",
    "end": "522560"
  },
  {
    "text": "the discourage that you need to screw in if you need to you know build a you know build a shed build a building you want",
    "start": "522560",
    "end": "528920"
  },
  {
    "text": "to use the right tools for the different purposes of that job as you're building that and the same sort of thing really",
    "start": "528920",
    "end": "534380"
  },
  {
    "text": "applies when you're working on analytics and machine learning pick the right tool for the type of job so if you're doing an image",
    "start": "534380",
    "end": "541190"
  },
  {
    "text": "classification certain tools are really good at that if you're doing audio to text certain tools are really good at",
    "start": "541190",
    "end": "547340"
  },
  {
    "text": "that if you're doing forecasting and time series analysis other tools might be good at that so rather than picking",
    "start": "547340",
    "end": "552800"
  },
  {
    "text": "one tool to be able to do every one of those sorts of analytics really pick a framework that you're able to plug in",
    "start": "552800",
    "end": "559640"
  },
  {
    "text": "different analytics into a common platform and run those for the right",
    "start": "559640",
    "end": "565190"
  },
  {
    "text": "type of problems so with AWS and you",
    "start": "565190",
    "end": "570500"
  },
  {
    "start": "567000",
    "end": "659000"
  },
  {
    "text": "guys are probably aware of this for the folks that I've used AWS a lot most",
    "start": "570500",
    "end": "575720"
  },
  {
    "text": "really all of our services are purpose-built what that means is each of",
    "start": "575720",
    "end": "581150"
  },
  {
    "text": "the services does a function very very well so we have services that are able to be able to capture real time data and",
    "start": "581150",
    "end": "587180"
  },
  {
    "text": "process it very very effectively we have services to be able to capture CDC logs from databases and populate your data",
    "start": "587180",
    "end": "593570"
  },
  {
    "text": "leak so these are very very purpose-built services that do that function very very",
    "start": "593570",
    "end": "599600"
  },
  {
    "text": "well so you know that's great but if you look out in out in the forecast of all",
    "start": "599600",
    "end": "606170"
  },
  {
    "text": "the data analytic services and all these purpose-built services this is a what you might see so there's a lot of",
    "start": "606170",
    "end": "612380"
  },
  {
    "text": "different options out there for you to use and really and really what's most",
    "start": "612380",
    "end": "618200"
  },
  {
    "text": "important as you're building these analytical systems on AWS in general is not necessarily going to analysis",
    "start": "618200",
    "end": "625400"
  },
  {
    "text": "paralysis of you know what's the perfect tool that I should use for every single use case but put together a framework",
    "start": "625400",
    "end": "631580"
  },
  {
    "text": "that you could experiment so experimentation and agility is really key trial a couple different tools to",
    "start": "631580",
    "end": "637160"
  },
  {
    "text": "see what works and and iterate on that adopt this solution and we're gonna talk about a couple case studies of customers",
    "start": "637160",
    "end": "643700"
  },
  {
    "text": "doing exactly that so rather than trying to spend six months trying to pick you know a tray study of what's the perfect",
    "start": "643700",
    "end": "649850"
  },
  {
    "text": "tool being able to try out a couple different tools in a bake-off pick the right one and then essentially keep",
    "start": "649850",
    "end": "655940"
  },
  {
    "text": "iterating on that so this is a really",
    "start": "655940",
    "end": "661280"
  },
  {
    "start": "659000",
    "end": "739000"
  },
  {
    "text": "good quote that I like to kind of steal or reuse from Gartner we're very very recent you know they're saying in this",
    "start": "661280",
    "end": "667790"
  },
  {
    "text": "year in 2018 eighty percent of the data Lake efforts are actually going to be in effective because of poor metadata",
    "start": "667790",
    "end": "674110"
  },
  {
    "text": "management I I work with so you know a lot of different customers that are new in the space and and they're storing",
    "start": "674110",
    "end": "679960"
  },
  {
    "text": "data out there but as soon as they start trying to analyze it it's a real challenge trying to find where is the data located how do I access it that",
    "start": "679960",
    "end": "686170"
  },
  {
    "text": "sort of thing so metadata management is really a key key piece of a lot of these analytical",
    "start": "686170",
    "end": "692050"
  },
  {
    "text": "systems there's a couple different ways of doing this one of them is using a service called database glue we're gonna",
    "start": "692050",
    "end": "699070"
  },
  {
    "text": "demo this in a in a minute and the reason that I like to talk about this as an option is one really really key",
    "start": "699070",
    "end": "706570"
  },
  {
    "text": "feature that bottom one that's listed there one is it's able to crawl your",
    "start": "706570",
    "end": "711700"
  },
  {
    "text": "your data repositories and discover your data so with metadata management crane",
    "start": "711700",
    "end": "717790"
  },
  {
    "text": "that metadata catalog is is really important upfront but maintaining it over time because your datasets change",
    "start": "717790",
    "end": "724570"
  },
  {
    "text": "your your schemas change and being able to have a consistent model of your data",
    "start": "724570",
    "end": "729970"
  },
  {
    "text": "over time is really really important and the crawlers are able to do that they're they could be scheduled so that it",
    "start": "729970",
    "end": "736240"
  },
  {
    "text": "updates your schemas over time and the other really important aspect so if",
    "start": "736240",
    "end": "741670"
  },
  {
    "start": "739000",
    "end": "800000"
  },
  {
    "text": "you're using glue if you use one of our partners that's great as well but one of the really important aspects is making",
    "start": "741670",
    "end": "747820"
  },
  {
    "text": "sure the metadata service that you're using is very very supportive of",
    "start": "747820",
    "end": "753340"
  },
  {
    "text": "different analytics that you could run you don't want to necessarily pick a storage platform and a metadata platform",
    "start": "753340",
    "end": "758980"
  },
  {
    "text": "that now you're pigeon-holed into using one sort of an alike you want to be very very have kind of analytics freedom to",
    "start": "758980",
    "end": "766000"
  },
  {
    "text": "be able to run deep learning machine learning real-time analytics spark those",
    "start": "766000",
    "end": "771940"
  },
  {
    "text": "sorts of things on your platform very very effectively so there's other ways",
    "start": "771940",
    "end": "778870"
  },
  {
    "text": "of populating your data set besides just crawling it it's really really powerful to get started using that but you can",
    "start": "778870",
    "end": "785170"
  },
  {
    "text": "shift your metadata catalog across different toolings different vendors that sort of thing one of the options is",
    "start": "785170",
    "end": "790480"
  },
  {
    "text": "actually to go from a high medic store in a Hadoop cluster into a common data catalog in Glu and vice versa so you",
    "start": "790480",
    "end": "797230"
  },
  {
    "text": "could go in and out of that so how can I get started you know how do I kind of",
    "start": "797230",
    "end": "803380"
  },
  {
    "start": "800000",
    "end": "863000"
  },
  {
    "text": "essentially get get start kicking the tires with one of the examples I like to give this",
    "start": "803380",
    "end": "810220"
  },
  {
    "text": "is the only commercial example I'll give the rest are public sector examples but you know Netflix got started very early",
    "start": "810220",
    "end": "816579"
  },
  {
    "text": "on AWS and the reason I don't like to show this is it really shows how you could innovate in and change your",
    "start": "816579",
    "end": "822670"
  },
  {
    "text": "platform over time so really one of the most important things like I mentioned",
    "start": "822670",
    "end": "827709"
  },
  {
    "text": "is picking a platform where you could change how you're doing things so they actually started with open source",
    "start": "827709",
    "end": "833079"
  },
  {
    "text": "projects to be able to do their data ingestion platform they're using this Apache project unfortunately they start",
    "start": "833079",
    "end": "840399"
  },
  {
    "text": "using it and about shortly after that it stopped being maintained it went about",
    "start": "840399",
    "end": "845560"
  },
  {
    "text": "two years without being contributed to so they want to shift so they shift to a project called Apache Kafka it's an",
    "start": "845560",
    "end": "852009"
  },
  {
    "text": "Apache project for real-time processing so they are able to shift to that pretty easily and use the use the kafka routers",
    "start": "852009",
    "end": "861009"
  },
  {
    "text": "from there their producers but then they want it to be able to start shifting out",
    "start": "861009",
    "end": "866230"
  },
  {
    "text": "that project that open-source project that isn't being maintained anymore so",
    "start": "866230",
    "end": "871449"
  },
  {
    "text": "then they went purely Kafka to be able to do all their real-time data and the reason I'd like to mention this is what",
    "start": "871449",
    "end": "878050"
  },
  {
    "text": "enabled them to do this is putting their data in s3 being able to have their producers use open standards so it's",
    "start": "878050",
    "end": "885519"
  },
  {
    "text": "very easy to talk to Kafka it's very easy to talk to this other open source project but it's also very easy to talk",
    "start": "885519",
    "end": "893110"
  },
  {
    "text": "to our managed services like Kinesis which they moved to after that so and",
    "start": "893110",
    "end": "898269"
  },
  {
    "text": "the reason why they did that is running Kafka is great Kafka is a really great open source project but when you're",
    "start": "898269",
    "end": "903939"
  },
  {
    "text": "doing that you're doing things like managing zookeeper which is a coordination service you're making it a",
    "start": "903939",
    "end": "909100"
  },
  {
    "text": "CH a highly available across a ZZZ so there's a lot of other heavy lifting that you need to be able to do when",
    "start": "909100",
    "end": "914920"
  },
  {
    "text": "you're running that real-time analytics and by shifting to higher level services",
    "start": "914920",
    "end": "919959"
  },
  {
    "start": "917000",
    "end": "998000"
  },
  {
    "text": "like Kinesis and some of the other ones we're going to dive into in a moment it really lets you as customers and",
    "start": "919959",
    "end": "926970"
  },
  {
    "text": "organizations focus on the analytics the driving insights that sort of thing and",
    "start": "926970",
    "end": "932019"
  },
  {
    "text": "really you know being able to do that rapid shift that you know let's test out",
    "start": "932019",
    "end": "937180"
  },
  {
    "text": "this framework fork some of our workload see works and then shift over to that it's",
    "start": "937180",
    "end": "942290"
  },
  {
    "text": "really key to be able to do that so you know really that agility being",
    "start": "942290",
    "end": "947330"
  },
  {
    "text": "able to experiment and be agile with the Analects you're running it's interesting because on Amazon's prime day Amazon",
    "start": "947330",
    "end": "955100"
  },
  {
    "text": "retail uses many of the services there are customer of ours just like you know many of other other customers but during",
    "start": "955100",
    "end": "961250"
  },
  {
    "text": "prime they they the no single database DynamoDB actually peaked at about 12",
    "start": "961250",
    "end": "966800"
  },
  {
    "text": "million requests per second and they're using that you know no sequel database they're they're using it as both key",
    "start": "966800",
    "end": "973490"
  },
  {
    "text": "value store in a document store and you know the retail side of the business just needs to focus on how do i",
    "start": "973490",
    "end": "979310"
  },
  {
    "text": "structure my objects how do I get them out and and the AWS services will you know structure the right way Auto scale",
    "start": "979310",
    "end": "985520"
  },
  {
    "text": "consume those messages consume those requests and scale back down so really really powerful to be able to have the",
    "start": "985520",
    "end": "992330"
  },
  {
    "text": "agility that scale that elasticity as you're writing your analytics so",
    "start": "992330",
    "end": "998840"
  },
  {
    "start": "998000",
    "end": "1048000"
  },
  {
    "text": "speaking of analytics you know I I could definitely spend multiple days talking",
    "start": "998840",
    "end": "1003850"
  },
  {
    "text": "about analytics so don't worry I won't many types of different analytics out there so the first I like to talk about",
    "start": "1003850",
    "end": "1010930"
  },
  {
    "text": "R is a Hadoop and spark analytics curious folks in the room and I should have asked the more upfront how many",
    "start": "1010930",
    "end": "1016840"
  },
  {
    "text": "folks in the room are are doing some sort of Hadoop or spark today on for their organizations okay a couple hands",
    "start": "1016840",
    "end": "1024938"
  },
  {
    "text": "maybe like four or five hands came up so Hadoop and spark is a platform to do massively parallel processing different",
    "start": "1024939",
    "end": "1031959"
  },
  {
    "text": "source and analytics both on-premises and in the cloud it started with very",
    "start": "1031959",
    "end": "1037780"
  },
  {
    "text": "patch oriented but then additional libraries and frameworks went on top of the ecosystem viewable runs different",
    "start": "1037780",
    "end": "1043360"
  },
  {
    "text": "sorts of analytics and what makes this really powerful in the cloud is excuse",
    "start": "1043360",
    "end": "1048940"
  },
  {
    "start": "1048000",
    "end": "1134000"
  },
  {
    "text": "me is being able to really focus on writing those analytics and and you know",
    "start": "1048940",
    "end": "1056410"
  },
  {
    "text": "using EMR for example elastic MapReduce to be able to spin up these clusters of",
    "start": "1056410",
    "end": "1061960"
  },
  {
    "text": "the last is sitting you know you could run multiple clusters in parallel for example if I want to spin up a real-time",
    "start": "1061960",
    "end": "1069160"
  },
  {
    "text": "cluster to do analysis of streaming data I could do that very effectively paper second when I'm not using it and then if I have",
    "start": "1069160",
    "end": "1076090"
  },
  {
    "text": "some ETL jobs I could spin that up so it really becomes a resource that is very",
    "start": "1076090",
    "end": "1081460"
  },
  {
    "text": "elastic just like you know compute and that sort of thing but in the analytical space and really what enables you to be",
    "start": "1081460",
    "end": "1089530"
  },
  {
    "text": "able to do this is that data lake or that common storage on s3 and that common metadata map catalog that's",
    "start": "1089530",
    "end": "1097270"
  },
  {
    "text": "described in that data so very very common to have you know real time",
    "start": "1097270",
    "end": "1102790"
  },
  {
    "text": "clusters that are running 24 by 7 and automatically scaling based on the workload and then these other transient clusters",
    "start": "1102790",
    "end": "1109179"
  },
  {
    "text": "all pointing to that that s3 and for the folks our running Hadoop essentially the",
    "start": "1109179",
    "end": "1116230"
  },
  {
    "text": "way that works under the covers is s3 is presented as if it's HDFS to that",
    "start": "1116230",
    "end": "1122230"
  },
  {
    "text": "cluster and then that cluster also has working space on the cluster itself for intermediate files to be able to be very",
    "start": "1122230",
    "end": "1128860"
  },
  {
    "text": "performant when you know it's building the disk that sort of thing and the way",
    "start": "1128860",
    "end": "1135460"
  },
  {
    "start": "1134000",
    "end": "1180000"
  },
  {
    "text": "this works you know of course the data is described on s3 or essentially stored on s3 and then one of these metadata",
    "start": "1135460",
    "end": "1142030"
  },
  {
    "text": "management stores for example the glue data catalog which we're going to demo here in a couple slides you know you can",
    "start": "1142030",
    "end": "1148030"
  },
  {
    "text": "actually run your own metadata catalog on manage relational databases we provide folks like FINRA got started",
    "start": "1148030",
    "end": "1155260"
  },
  {
    "text": "very early on a data Lake and we're gonna talk a little bit more about FINRA in a moment but they actually created",
    "start": "1155260",
    "end": "1160420"
  },
  {
    "text": "their own metadata management called herd because blue wasn't out yep and herd is an open source project that you",
    "start": "1160420",
    "end": "1166120"
  },
  {
    "text": "could very easily run as well so customers it's all about choice you know our services work very very well but you",
    "start": "1166120",
    "end": "1173170"
  },
  {
    "text": "have choices in terms of using some of these different projects when it comes to these different architectural",
    "start": "1173170",
    "end": "1178960"
  },
  {
    "text": "approaches so last thing I want to mention real quick and then shifting to",
    "start": "1178960",
    "end": "1184000"
  },
  {
    "start": "1180000",
    "end": "1234000"
  },
  {
    "text": "the first demo is Athena so Athena is one of our newer services in the analytical space and what it really",
    "start": "1184000",
    "end": "1190720"
  },
  {
    "text": "allows you to do is issue select statements against your data leak and you know remember the data is actually",
    "start": "1190720",
    "end": "1197230"
  },
  {
    "text": "stored in the raw form in this case so you know the data stored as CSV JSON parkia Avro you know these the XML these",
    "start": "1197230",
    "end": "1204130"
  },
  {
    "text": "different formats on s3 and I'm issuing slack statements as if it's in a database it's",
    "start": "1204130",
    "end": "1209570"
  },
  {
    "text": "not really loaded in the database it's actually a schema on read so it's actually inferring a schema as its",
    "start": "1209570",
    "end": "1214940"
  },
  {
    "text": "executing which makes it very very rapid to be able to test things out so if you're bringing in a completely new data",
    "start": "1214940",
    "end": "1221300"
  },
  {
    "text": "set from a vendor from a partner you know you want to start experimenting with data fusion very very easy to be",
    "start": "1221300",
    "end": "1228140"
  },
  {
    "text": "able to query the data in place before you load it into your databases your data warehouse is that sort of thing so",
    "start": "1228140",
    "end": "1234770"
  },
  {
    "start": "1234000",
    "end": "1290000"
  },
  {
    "text": "we're going to go ahead and shift to a demonstration here and we're gonna really start with the the data catalog",
    "start": "1234770",
    "end": "1240440"
  },
  {
    "text": "and within the data catalog what we see here is this is the glue console and",
    "start": "1240440",
    "end": "1247090"
  },
  {
    "text": "essentially we actually see these different tables here and I should say",
    "start": "1247090",
    "end": "1253100"
  },
  {
    "text": "tables and air quotes here because some of these are like traditional tables like in Postgres and redshift that you",
    "start": "1253100",
    "end": "1259580"
  },
  {
    "text": "see they're redshift is our petabyte scale data warehouse Postgres is a open source database but these are also the",
    "start": "1259580",
    "end": "1267080"
  },
  {
    "text": "schema honoree data Lake tables and you know so you'll notice also things like CSV tables and park' tables here and",
    "start": "1267080",
    "end": "1275330"
  },
  {
    "text": "these are data sets living on s3 so you'll notice the location there says s3",
    "start": "1275330",
    "end": "1280430"
  },
  {
    "text": "path that we're going to be able to analyze and start querying the data in place very very powerful to be able to",
    "start": "1280430",
    "end": "1286190"
  },
  {
    "text": "do that as you're investigating your data but before we do that I'm actually",
    "start": "1286190",
    "end": "1291920"
  },
  {
    "start": "1290000",
    "end": "1330000"
  },
  {
    "text": "going to demonstrate that crawling feature so this is a crawler configuration each crawler runs within I",
    "start": "1291920",
    "end": "1298700"
  },
  {
    "text": "am role so all of these services are integrated very very nicely with our security layer I am which is identity",
    "start": "1298700",
    "end": "1305900"
  },
  {
    "text": "access management so it allows you to do lease privileged access for all of these components so that when you set up your",
    "start": "1305900",
    "end": "1312740"
  },
  {
    "text": "crawler it's only even as if it's misconfigured it's only gonna crawl the buckets that your security posture",
    "start": "1312740",
    "end": "1318260"
  },
  {
    "text": "allows it to crawl so that goes without saying with all of the services we're going to go through that it's really a",
    "start": "1318260",
    "end": "1324650"
  },
  {
    "text": "key part integrated throughout all the tiers we're gonna look at so we're going",
    "start": "1324650",
    "end": "1331310"
  },
  {
    "start": "1330000",
    "end": "1432000"
  },
  {
    "text": "to run this crawler and this isn't recorded this isn't staged this is you know kind of given a live demo I happen",
    "start": "1331310",
    "end": "1337400"
  },
  {
    "text": "to be hitting us East so we're it's not hitting you know Dublin or one",
    "start": "1337400",
    "end": "1342680"
  },
  {
    "text": "of the more local regions but you know we're actually crawling this data set here and what's really cool is within",
    "start": "1342680",
    "end": "1352010"
  },
  {
    "text": "here within a couple seconds what's going to happen is I'm going to be able to refresh this and all of a sudden the",
    "start": "1352010",
    "end": "1358100"
  },
  {
    "text": "the list of metadata fields in my catalog just went from 3 to 13 within",
    "start": "1358100",
    "end": "1363740"
  },
  {
    "text": "this data Lake schema so what we just did is you could look at the time stamp",
    "start": "1363740",
    "end": "1368750"
  },
  {
    "text": "the time step is actually right now and we actually just discovered all of this data just now and what's really cool is",
    "start": "1368750",
    "end": "1375770"
  },
  {
    "text": "even though we just discovered all this data we can start querying it in place so this is the s3 location that Twitter",
    "start": "1375770",
    "end": "1381980"
  },
  {
    "text": "data is actually getting fed into my s3 bucket s3 happens to be or twitter",
    "start": "1381980",
    "end": "1387230"
  },
  {
    "text": "happens to be in JSON so we can see that we can also see things like all the fields and you'll notice JSON CSV all of",
    "start": "1387230",
    "end": "1394880"
  },
  {
    "text": "these data formats actually don't have types right all of its ASCII all of its string but it's deriving the type for me",
    "start": "1394880",
    "end": "1400940"
  },
  {
    "text": "so so it's deriving these are boolean's these are integers these are you know strings I could very easily go in here",
    "start": "1400940",
    "end": "1407990"
  },
  {
    "text": "and modify that so let's say I'm looking at flight information and and flight number if you just look at the data type",
    "start": "1407990",
    "end": "1414740"
  },
  {
    "text": "might be a numeric value but I might want to treat that as a string because there's no significant value of taking like an average flight number for a",
    "start": "1414740",
    "end": "1420890"
  },
  {
    "text": "carrier and doing it you know numeric functions over that so I might want to change that to be a string rather than a",
    "start": "1420890",
    "end": "1426050"
  },
  {
    "text": "flight integer that sort of thing so you could go in and change your schema on the fly here the other thing that it",
    "start": "1426050",
    "end": "1433400"
  },
  {
    "start": "1432000",
    "end": "1473000"
  },
  {
    "text": "allows you to do is for very nested objects like like tweets and a lot of",
    "start": "1433400",
    "end": "1438530"
  },
  {
    "text": "other data formats that have JSON that's very nested where has fields within fields and rays within fields very very",
    "start": "1438530",
    "end": "1445040"
  },
  {
    "text": "deep in there what it automatically just discovered live here is the crawler actually automatically discovered this",
    "start": "1445040",
    "end": "1451490"
  },
  {
    "text": "array of structs which actually goes quite deep I would not want to try to create this d do this crate table",
    "start": "1451490",
    "end": "1457310"
  },
  {
    "text": "statement that has all these different fields in here so really really powerful to be able to have it scan all your data",
    "start": "1457310",
    "end": "1463990"
  },
  {
    "text": "you know secure it through the IAM role so it's only gonna scan the data you allow it to and derive all of this",
    "start": "1463990",
    "end": "1469730"
  },
  {
    "text": "information I'm gonna save some time for some of the",
    "start": "1469730",
    "end": "1474850"
  },
  {
    "start": "1473000",
    "end": "1505000"
  },
  {
    "text": "really cool demos in the machine learning here don't worry but one of the other things that wanted show super",
    "start": "1474850",
    "end": "1481600"
  },
  {
    "text": "quick is how you start looking into this data so Athena is that sequel interface",
    "start": "1481600",
    "end": "1487750"
  },
  {
    "text": "into your data Lake so we're gonna actually look at this data set this taxi data set this is a CSV data set that we",
    "start": "1487750",
    "end": "1494320"
  },
  {
    "text": "just discovered just now and what we're gonna do is we're actually gonna go in here and say I want to look at this data",
    "start": "1494320",
    "end": "1500410"
  },
  {
    "text": "I want to view this data and even though",
    "start": "1500410",
    "end": "1506440"
  },
  {
    "start": "1505000",
    "end": "1564000"
  },
  {
    "text": "this is CSV data and folks in the room feel free to kind of give me a thumbs-up thumbs-down I could zoom in and zoom out",
    "start": "1506440",
    "end": "1512320"
  },
  {
    "text": "I can almost see people in the back or go like this if you can't see I'll try",
    "start": "1512320",
    "end": "1517840"
  },
  {
    "text": "to make it a little bit bigger but what we're showing on the screen is essentially a just a select star limit",
    "start": "1517840",
    "end": "1523300"
  },
  {
    "text": "10 and what that's doing is it's actually scanning through that CSV returning me back the first ten records",
    "start": "1523300",
    "end": "1529200"
  },
  {
    "text": "what's really powerful is you could actually create your own you know let's say you have a very custom format let's",
    "start": "1529200",
    "end": "1534790"
  },
  {
    "text": "say it's some very unique lock format that you describe through reg X what you could do is you could actually describe",
    "start": "1534790",
    "end": "1541000"
  },
  {
    "text": "that in your data catalog once and then within athina within your spark within Hadoop within all these environments",
    "start": "1541000",
    "end": "1547510"
  },
  {
    "text": "that's abstracted away from the people using that data so you define it once in your data Cal logger and then the people",
    "start": "1547510",
    "end": "1553870"
  },
  {
    "text": "writing your analytics don't need to know special ways of parsing these different log files it's done through that the adapters are through the",
    "start": "1553870",
    "end": "1560260"
  },
  {
    "text": "Surtees within the within the catalog the other thing I'll show here very",
    "start": "1560260",
    "end": "1566980"
  },
  {
    "start": "1564000",
    "end": "1651000"
  },
  {
    "text": "quickly and I always end up miss typing queries so I'm actually gonna just paste",
    "start": "1566980",
    "end": "1572020"
  },
  {
    "text": "this one in is this is actually a little",
    "start": "1572020",
    "end": "1578830"
  },
  {
    "text": "bit more complicated of a query and the reason I want to show this is you know this just took two seconds to query so",
    "start": "1578830",
    "end": "1585040"
  },
  {
    "text": "remember this isn't data in a database this is data like at rest on s3 I'm",
    "start": "1585040",
    "end": "1590560"
  },
  {
    "text": "paying very very minimum costs when it's lit it's kind of sitting there and I actually just did a count query a",
    "start": "1590560",
    "end": "1596320"
  },
  {
    "text": "maximum fare this is the New York City Taxi data it's 10 million entries in this one data set sometimes when we have",
    "start": "1596320",
    "end": "1603340"
  },
  {
    "text": "a longer demo we actually query eight years of the state which is about three billion entries which is really cool when it returns in",
    "start": "1603340",
    "end": "1609309"
  },
  {
    "text": "a couple of seconds and you're creating all the data but you know in this shorter session where we're talking",
    "start": "1609309",
    "end": "1614559"
  },
  {
    "text": "about multiple things we're going to just use this data set but we're able to do averages maxes fares things like",
    "start": "1614559",
    "end": "1621159"
  },
  {
    "text": "correlations so we're calculating the correlation between the fair amount and the distance the fair amount and the",
    "start": "1621159",
    "end": "1627190"
  },
  {
    "text": "total amounts so a lot of these correlation queries are things that you know you do a lot of times of the day",
    "start": "1627190",
    "end": "1632440"
  },
  {
    "text": "science side as well as you're starting to understand your data so you know this",
    "start": "1632440",
    "end": "1637840"
  },
  {
    "text": "is really letting you take massive massive data sets query over the entire data set and be able to calculate you",
    "start": "1637840",
    "end": "1644380"
  },
  {
    "text": "know correlation matrix is that sort of thing overdoing you know you can't do sampling that sort of thing so Athena's",
    "start": "1644380",
    "end": "1652210"
  },
  {
    "start": "1651000",
    "end": "1697000"
  },
  {
    "text": "one way of querying the data another way of doing it is essentially being able to",
    "start": "1652210",
    "end": "1659820"
  },
  {
    "text": "use sparkin and you know press though you know essentially the ecosystem on",
    "start": "1659820",
    "end": "1667840"
  },
  {
    "text": "the hadoop clusters so I actually spun up this Hadoop cluster you know a little",
    "start": "1667840",
    "end": "1673510"
  },
  {
    "text": "bit before the session it has been running very long I it's actually been running for two hours now I just spun it",
    "start": "1673510",
    "end": "1678940"
  },
  {
    "text": "up to be able to give some demos but the really cool thing here is this entire cluster this analytical ecosystem I spin",
    "start": "1678940",
    "end": "1686529"
  },
  {
    "text": "up with a click of a button or through programmatic scripts and then it plugs into a data linking and that that data",
    "start": "1686529",
    "end": "1693490"
  },
  {
    "text": "repository metadata Kellog on s3 and you know what I could do here is I could",
    "start": "1693490",
    "end": "1699880"
  },
  {
    "text": "spin up things like Zeppelin notebooks and start doing all types of things like spark queries analytics you know",
    "start": "1699880",
    "end": "1706480"
  },
  {
    "text": "visualizations sorry you guys probably can't see in the back I'll make it a little bit bigger but you'll notice when",
    "start": "1706480",
    "end": "1713020"
  },
  {
    "text": "I say show tables here this is the entire table list that you just saw that we discovered through crawlers and",
    "start": "1713020",
    "end": "1719860"
  },
  {
    "text": "that's were thing so when we you know when we're you know we run this you know that sort of thing where we're actually",
    "start": "1719860",
    "end": "1725020"
  },
  {
    "text": "pulling the the most recent crawlers that you know crawl data that sort of that sort of queries against the data",
    "start": "1725020",
    "end": "1730450"
  },
  {
    "text": "Lake you're also able to do spark ml in here so you're able to connect into the",
    "start": "1730450",
    "end": "1736840"
  },
  {
    "text": "data within the data lake through the cow and do recommendation engines",
    "start": "1736840",
    "end": "1742540"
  },
  {
    "text": "alternating least-squares all types of different analytics within this notebook the entire ecosystem has a lot of",
    "start": "1742540",
    "end": "1748270"
  },
  {
    "start": "1746000",
    "end": "1775000"
  },
  {
    "text": "different UIs that you're able to do on top of it and it's all about being able to enable different users to use these",
    "start": "1748270",
    "end": "1754810"
  },
  {
    "text": "different tools because they're oftentimes doing different jobs so next what we're gonna do is we're actually",
    "start": "1754810",
    "end": "1760690"
  },
  {
    "text": "going to shift back to the presentation give a quick introduction of machine",
    "start": "1760690",
    "end": "1766270"
  },
  {
    "text": "learning and how this is really powering a lot of machine learning and then we'll we save some really cool demos for the",
    "start": "1766270",
    "end": "1772150"
  },
  {
    "text": "second part here so you know what why are we bundling this talk with big data",
    "start": "1772150",
    "end": "1779560"
  },
  {
    "start": "1775000",
    "end": "1795000"
  },
  {
    "text": "analytics and machine learning together and really data is a key enabler for machine learning so without data you",
    "start": "1779560",
    "end": "1786850"
  },
  {
    "text": "know it's it you know data is really a key ingredient so you need the frameworks you need the infrastructure and you really need the data to be able",
    "start": "1786850",
    "end": "1792820"
  },
  {
    "text": "to do machine learning and what we're finding is it's really a flywheel effect so as our organizations as customers are",
    "start": "1792820",
    "end": "1801330"
  },
  {
    "start": "1795000",
    "end": "1825000"
  },
  {
    "text": "generating this data storing on s3 being able to analyze it to make better decisions that's really driving better",
    "start": "1801330",
    "end": "1807910"
  },
  {
    "text": "services for their citizens it's better education tools better products that",
    "start": "1807910",
    "end": "1814630"
  },
  {
    "text": "they're providing and this is all driving more users more data and this becomes a flywheel effect that really is",
    "start": "1814630",
    "end": "1821350"
  },
  {
    "text": "powering both big data systems as well as machine learning systems so on the data Lake side you know what we're",
    "start": "1821350",
    "end": "1828070"
  },
  {
    "start": "1825000",
    "end": "1836000"
  },
  {
    "text": "seeing is you know the Analects piece and the machine learning piece all working together with that with that",
    "start": "1828070",
    "end": "1834250"
  },
  {
    "text": "data light and you know with machine learning and analytics what's really key",
    "start": "1834250",
    "end": "1841540"
  },
  {
    "start": "1836000",
    "end": "1875000"
  },
  {
    "text": "is not necessarily picking one interface you know just like you wouldn't pick one and I like to solve every problem you",
    "start": "1841540",
    "end": "1848140"
  },
  {
    "text": "don't want to necessarily pick one interface for every single user you of course want security throughout your",
    "start": "1848140",
    "end": "1855040"
  },
  {
    "text": "layers you want to be able to have auditing all those but you don't want to necessarily say everyone's gonna use a",
    "start": "1855040",
    "end": "1860410"
  },
  {
    "text": "bi tool for every purpose bi tools are great but you know often times you want to use notebooks and you want to use",
    "start": "1860410",
    "end": "1865990"
  },
  {
    "text": "other environments for your data scientists that sort of thing so different tools are used by different folks within your organization to be",
    "start": "1865990",
    "end": "1872800"
  },
  {
    "text": "able to do do your analytics and we have a full machine learning session towards the end",
    "start": "1872800",
    "end": "1879580"
  },
  {
    "start": "1875000",
    "end": "1932000"
  },
  {
    "text": "of the day here today so we're not necessarily going to step through all of the different services within these",
    "start": "1879580",
    "end": "1884710"
  },
  {
    "text": "tiers when it comes to the application services platform services and framework services but what I did want to mention",
    "start": "1884710",
    "end": "1891400"
  },
  {
    "text": "here is when it comes to your data in your data like in s3 it's very very easy",
    "start": "1891400",
    "end": "1896559"
  },
  {
    "text": "to use different levels of services based on your skill sets so we have customers that are bringing different",
    "start": "1896559",
    "end": "1902920"
  },
  {
    "text": "data sets into s3 and doing things like creating content repositories that is",
    "start": "1902920",
    "end": "1908860"
  },
  {
    "text": "easily searchable without having data science skills and their way they're doing that is being able to use these",
    "start": "1908860",
    "end": "1914470"
  },
  {
    "text": "application level services so these services are really built with machine learning and deep learning under the",
    "start": "1914470",
    "end": "1920260"
  },
  {
    "text": "covers but it's very easy to plug in your data get results out to be able to do language services machine translation",
    "start": "1920260",
    "end": "1927280"
  },
  {
    "text": "image and video recognition that sort of thing then we have platform services so",
    "start": "1927280",
    "end": "1934390"
  },
  {
    "start": "1932000",
    "end": "1954000"
  },
  {
    "text": "these are services like sage maker and deep deep lens and an EMR that lets you",
    "start": "1934390",
    "end": "1939929"
  },
  {
    "text": "really plug in your own data to build very custom models and then deploy those",
    "start": "1939929",
    "end": "1945220"
  },
  {
    "text": "out to either endpoints hosted in AWS or endpoints out on the edge it could be a",
    "start": "1945220",
    "end": "1951669"
  },
  {
    "text": "connected car or drone whatever it might be and then lastly we have frameworks very very powerful for the data",
    "start": "1951669",
    "end": "1957520"
  },
  {
    "start": "1954000",
    "end": "1969000"
  },
  {
    "text": "scientists to be able to spin up very very powerful infrastructure either on",
    "start": "1957520",
    "end": "1963190"
  },
  {
    "text": "GPUs or Intel CPUs and be able to run those very very effectively on AWS one",
    "start": "1963190",
    "end": "1970210"
  },
  {
    "start": "1969000",
    "end": "2047000"
  },
  {
    "text": "example I like to give here and is digital globe so digital globe is a",
    "start": "1970210",
    "end": "1975880"
  },
  {
    "text": "customer of ours they built a data Lake on AWS it's about a hundred petabytes any time you're using mapping software a",
    "start": "1975880",
    "end": "1982750"
  },
  {
    "text": "lot of things leverage digital globe data because they take imagery across the globe and and run analytics on them",
    "start": "1982750",
    "end": "1989350"
  },
  {
    "text": "and this is a interesting use case because you know of course they're doing geospatial recognition for like oil and",
    "start": "1989350",
    "end": "1996160"
  },
  {
    "text": "gas companies and image processing on on the images themselves but they also",
    "start": "1996160",
    "end": "2001500"
  },
  {
    "text": "wanted to be able to drive down their costs using machine learning so what they did is they actually have multiple",
    "start": "2001500",
    "end": "2007200"
  },
  {
    "text": "years of services and they're able to use sage maker to actually improve their cash hit by over two times what they",
    "start": "2007200",
    "end": "2014549"
  },
  {
    "text": "were having before so now they're averaging around eighty three percent cash it's sometimes about ninety percent",
    "start": "2014549",
    "end": "2019860"
  },
  {
    "text": "and what they're able to do by doing that is actually drive their cost down they're paying about half of what they",
    "start": "2019860",
    "end": "2025559"
  },
  {
    "text": "did for storage by leveraging machine learning algorithms to be able to predict what data people are going to request before they request it and this",
    "start": "2025559",
    "end": "2033210"
  },
  {
    "text": "is just a video here showing you know some of the cash hits it's nice animation you know there's a couple",
    "start": "2033210",
    "end": "2040760"
  },
  {
    "text": "presentations on this from reinvents on our YouTube channel if you want to learn more about this and this is what their",
    "start": "2040760",
    "end": "2048300"
  },
  {
    "start": "2047000",
    "end": "2113000"
  },
  {
    "text": "architecture looks like being able to step through there one last example and then we're going to",
    "start": "2048300",
    "end": "2053550"
  },
  {
    "text": "dive into the essentially the machine learning you demo is spinner FINRA is a",
    "start": "2053550",
    "end": "2059070"
  },
  {
    "text": "very large financial regulatory organization that really monitors stock",
    "start": "2059070",
    "end": "2064648"
  },
  {
    "text": "trade inside the US they're actually monitoring tens of thousands of security",
    "start": "2064649",
    "end": "2070079"
  },
  {
    "text": "firms trying to do things like predict market manipulation they built a twenty petabyte data Lake and the reason I like",
    "start": "2070079",
    "end": "2077368"
  },
  {
    "text": "to talk about them as an example is they're really doing a mix of analytics",
    "start": "2077369",
    "end": "2084089"
  },
  {
    "text": "as well as machine learning together and the way they did that is they first looked at building a data Lake and",
    "start": "2084089",
    "end": "2089700"
  },
  {
    "text": "enabling analytics so they're running multiple Hadoop clusters for different jobs they have a very large no sequel",
    "start": "2089700",
    "end": "2096419"
  },
  {
    "text": "database running HBase and all powered by s3 and back-end but what's",
    "start": "2096419",
    "end": "2102210"
  },
  {
    "text": "interesting is as they were evolving this architecture they actually started here and then wanted to enable their",
    "start": "2102210",
    "end": "2107849"
  },
  {
    "text": "data scientists using these different tools so they're leveraging different tools to do these different jobs and",
    "start": "2107849",
    "end": "2113060"
  },
  {
    "start": "2113000",
    "end": "2139000"
  },
  {
    "text": "then lastly they want to be able to run different sorts of analytics they want to be able to run are not only are which",
    "start": "2113060",
    "end": "2119819"
  },
  {
    "text": "they're running very heavily on premises but they want to run tensorflow in MX net and cafe and all of these other",
    "start": "2119819",
    "end": "2127040"
  },
  {
    "text": "machine learning and deep learning technologies so it was very easy for them to plug their data science platform",
    "start": "2127040",
    "end": "2133440"
  },
  {
    "text": "into their data Lake and run it with an AWS using a suite of tools not just one tool so from here",
    "start": "2133440",
    "end": "2140880"
  },
  {
    "start": "2139000",
    "end": "2168000"
  },
  {
    "text": "we want to give some demonstrations of machine learning so once a welcome cake to the stage and she's gonna run through",
    "start": "2140880",
    "end": "2145920"
  },
  {
    "text": "some of those all right so good morning",
    "start": "2145920",
    "end": "2170220"
  },
  {
    "start": "2168000",
    "end": "2492000"
  },
  {
    "text": "my name is Kate whirling I'm a Solutions Architect so I have two demos and want to show today I worked specifically at",
    "start": "2170220",
    "end": "2177089"
  },
  {
    "text": "the public sector so both of these use cases are actually public sector use cases so hopefully a lot people here",
    "start": "2177089",
    "end": "2182940"
  },
  {
    "text": "will find them relevant the first one today is termed the reverse image search so we had a customer that came to us and",
    "start": "2182940",
    "end": "2189569"
  },
  {
    "text": "said you know we have all these security cameras throughout the city and we're collecting all this data all the time",
    "start": "2189569",
    "end": "2195029"
  },
  {
    "text": "we're having a really hard time being able to go back and query that in a meaningful way so what we want to show",
    "start": "2195029",
    "end": "2201119"
  },
  {
    "text": "us how they could leverage a service like recognition to help tag their data on their images as they come into the",
    "start": "2201119",
    "end": "2207359"
  },
  {
    "text": "system automatically so what we had was he actually had two of our solution",
    "start": "2207359",
    "end": "2212430"
  },
  {
    "text": "architects on the team they put a dash camera on their car and then drove all over the city in DC and took pictures of",
    "start": "2212430",
    "end": "2219029"
  },
  {
    "text": "traffic as they were driving along they then took these images and uploaded them",
    "start": "2219029",
    "end": "2224039"
  },
  {
    "text": "into s3 and then pass them through recognition and built out a DynamoDB database that contains all the object",
    "start": "2224039",
    "end": "2230549"
  },
  {
    "text": "tags as well as the geolocation metadata and then we're able to build this nice little user interface so you could go",
    "start": "2230549",
    "end": "2236339"
  },
  {
    "text": "ahead and query the data based on the tags returned by recognition so if I search for something like a car",
    "start": "2236339",
    "end": "2241789"
  },
  {
    "text": "I'll get back a collection of geo locations associated with that vehicle and unfortunately it's taking a little",
    "start": "2241789",
    "end": "2248309"
  },
  {
    "text": "bit of time because this is hosted in the East region there it goes of course ok so you know of course there are a lot",
    "start": "2248309",
    "end": "2255089"
  },
  {
    "text": "of cars unsurprisingly so as they're driving around a lot of cars were identified automatically using",
    "start": "2255089",
    "end": "2260369"
  },
  {
    "text": "recognition so I'm gonna search something a little bit more specific let's look for a school bus and they'll",
    "start": "2260369",
    "end": "2266460"
  },
  {
    "text": "say I want to only see images that contain a school bus with greater than",
    "start": "2266460",
    "end": "2271640"
  },
  {
    "text": "we'll say 80% confidence go ahead and search okay so",
    "start": "2271640",
    "end": "2278490"
  },
  {
    "text": "there's only one all right so here the geolocation coordinates of that School Bus when I click it will take me over to",
    "start": "2278490",
    "end": "2285119"
  },
  {
    "text": "where the school bus is this is actually where on the highway they saw the school bus we can see the different tags that",
    "start": "2285119",
    "end": "2291180"
  },
  {
    "text": "recognition generated from the image and then whenever we click we can see the original image and there in fact is a",
    "start": "2291180",
    "end": "2298200"
  },
  {
    "text": "school bus so definitely a very good way to be able to automatically tag a large",
    "start": "2298200",
    "end": "2303990"
  },
  {
    "text": "collection of images I will see that this website itself this whole interface",
    "start": "2303990",
    "end": "2309300"
  },
  {
    "text": "we built everything out using we had two solution architects work on this it took us about a week the web sites actually",
    "start": "2309300",
    "end": "2315599"
  },
  {
    "text": "entirely serverless so whenever we hit search that's triggering a lambda function the website",
    "start": "2315599",
    "end": "2321359"
  },
  {
    "text": "itself is being hosted in an s3 bucket and they were using DynamoDB to do all of our queries all right so the second",
    "start": "2321359",
    "end": "2330869"
  },
  {
    "text": "time I want to show I'm actually very excited about this is a project we're currently working on with our team",
    "start": "2330869",
    "end": "2336960"
  },
  {
    "text": "partnering with the ml solutions lab and the mo solutions I've had this model",
    "start": "2336960",
    "end": "2342390"
  },
  {
    "text": "that was already built it's a single shot detector model and what we're trying to do is retrain that model for a",
    "start": "2342390",
    "end": "2349140"
  },
  {
    "text": "very cool use case that we recently received so I'm not too long ago there were a series of hurricanes that hit the",
    "start": "2349140",
    "end": "2356130"
  },
  {
    "text": "Caribbean and had a pretty bad impact on the island nations down there and had",
    "start": "2356130",
    "end": "2362010"
  },
  {
    "text": "the team's thinking you know whenever they're in a scenario were you to go out and assess the disaster the damage from",
    "start": "2362010",
    "end": "2367829"
  },
  {
    "text": "a disaster a lot of times roads are inaccessible it's very difficult to get",
    "start": "2367829",
    "end": "2373079"
  },
  {
    "text": "around so what they wanted to do was be able to send their disaster teams out with a drone and then be able to fly",
    "start": "2373079",
    "end": "2378690"
  },
  {
    "text": "that drone around the area and have it to inference on the spot and kind of assess all right how many buildings are",
    "start": "2378690",
    "end": "2384690"
  },
  {
    "text": "still standing are the road or they're you know trees on the road what's the overall road conditions look like and things like that",
    "start": "2384690",
    "end": "2390510"
  },
  {
    "text": "so what weird working on here is actually training a model that we'll be able to do detection on objects in real",
    "start": "2390510",
    "end": "2397109"
  },
  {
    "text": "time from drone data as it flies through and to make it even a little more difficult we'll also be operating in an",
    "start": "2397109",
    "end": "2403619"
  },
  {
    "text": "environment that has limited network connectivity so I'll go ahead and play it's kind of",
    "start": "2403619",
    "end": "2410529"
  },
  {
    "text": "what we have thus far so right now we've been training it primarily on vehicles because we have a lot of training data",
    "start": "2410529",
    "end": "2415569"
  },
  {
    "text": "for that and some cool things here is that this model actually I was",
    "start": "2415569",
    "end": "2421329"
  },
  {
    "text": "pre-existing so we went ahead and we packaged it up into a container and then",
    "start": "2421329",
    "end": "2426640"
  },
  {
    "text": "we use sage maker for retraining the model so we're able to use that on-demand training with this",
    "start": "2426640",
    "end": "2431890"
  },
  {
    "text": "pre-existing model and then with the recent release of ML inference for",
    "start": "2431890",
    "end": "2437109"
  },
  {
    "text": "Greengrass our next step is going to be to then deploy this model to a device that has Greengrass installed so that",
    "start": "2437109",
    "end": "2444160"
  },
  {
    "text": "disaster teams can take it out to the field with them fly their drone and then run inference in real-time so this is",
    "start": "2444160",
    "end": "2450729"
  },
  {
    "text": "definitely I'm very excite about this project we've seen very positive results so far so the next step is of course as",
    "start": "2450729",
    "end": "2456759"
  },
  {
    "text": "with most machine learning problems to get more training data but again this I",
    "start": "2456759",
    "end": "2461799"
  },
  {
    "text": "think this is a good demonstration of how we're incorporating our infrastructure services like the p3 for",
    "start": "2461799",
    "end": "2467019"
  },
  {
    "text": "our custom models but still being able to leverage our platform type services like sage maker for being able to do",
    "start": "2467019",
    "end": "2472869"
  },
  {
    "text": "that training and deployment and then we're integrating with services like green grass to actually do the inference",
    "start": "2472869",
    "end": "2479229"
  },
  {
    "text": "at the edge capability so that's all I have and I will turn it back over to Ben",
    "start": "2479229",
    "end": "2486069"
  },
  {
    "text": "thank you",
    "start": "2486069",
    "end": "2488939"
  },
  {
    "start": "2492000",
    "end": "2546000"
  },
  {
    "text": "so what from here last few minutes we really wanted to just wrap up a little",
    "start": "2492480",
    "end": "2498160"
  },
  {
    "text": "bit with some core tenets when it comes to building these systems on AWS the",
    "start": "2498160",
    "end": "2503200"
  },
  {
    "text": "first one that we wanted to talk about is you know building loosely coupled systems so not necessarily picking a",
    "start": "2503200",
    "end": "2509200"
  },
  {
    "text": "storage type that will define your analytics not picking an ingest method that's going to define your storage type",
    "start": "2509200",
    "end": "2515140"
  },
  {
    "text": "that will indirectly define your Hana like so you know you could definitely keep performance you know a lot of times",
    "start": "2515140",
    "end": "2520839"
  },
  {
    "text": "we like to show how you could use s3 with a dupe and still have very very good performance versus using HDFS but",
    "start": "2520839",
    "end": "2528670"
  },
  {
    "text": "you know it's all about building a loosely coupled system and that really drives that future proofing it really it",
    "start": "2528670",
    "end": "2534880"
  },
  {
    "text": "lets you start ingesting imagery video you know all types of different data",
    "start": "2534880",
    "end": "2540039"
  },
  {
    "text": "sets and start running these analytics as you want to address different business problems within your organization and we're all about picking",
    "start": "2540039",
    "end": "2547720"
  },
  {
    "start": "2546000",
    "end": "2576000"
  },
  {
    "text": "the the best tool for the best job so architecting in a way that you know it's future proofing it's interesting because",
    "start": "2547720",
    "end": "2554230"
  },
  {
    "text": "a year from now there might be very different ways of analyzing your data then the way we're analyzing data today",
    "start": "2554230",
    "end": "2561010"
  },
  {
    "text": "which is very different than how we analyze data two years ago so how can you put together the an architecture",
    "start": "2561010",
    "end": "2566559"
  },
  {
    "text": "leveraging these services to be able to feature proof as you want to evolve your organization your business your",
    "start": "2566559",
    "end": "2573700"
  },
  {
    "text": "different agencies and elasticity multiple clusters a lot of our higher",
    "start": "2573700",
    "end": "2579910"
  },
  {
    "start": "2576000",
    "end": "2629000"
  },
  {
    "text": "level services like Sage maker which we're going to talk a little bit more in a session later this afternoon it really",
    "start": "2579910",
    "end": "2586089"
  },
  {
    "text": "keeps really good methodology to be able to spin up your clusters when you're",
    "start": "2586089",
    "end": "2591609"
  },
  {
    "text": "training and you're building your analytics and those services will automatically shut those things down when you're not using them that way",
    "start": "2591609",
    "end": "2598059"
  },
  {
    "text": "really keeps efficiency keeps your costs low and let's use do-more experimentations in that sort of thing",
    "start": "2598059",
    "end": "2604569"
  },
  {
    "text": "and uh you know I think there's a pain point in my past life so definitely",
    "start": "2604569",
    "end": "2609940"
  },
  {
    "text": "don't forget metadata management being able to find your data if you if you store massive amount of data out in in",
    "start": "2609940",
    "end": "2616930"
  },
  {
    "text": "the cloud and AWS and you don't know where it is you know you can't find the different pieces of information that",
    "start": "2616930",
    "end": "2621940"
  },
  {
    "text": "you're looking for it's almost like you don't have it anymore look for a very very effective metadata",
    "start": "2621940",
    "end": "2627490"
  },
  {
    "text": "management at the storage side you know picking the rice storage for the right job so s3 is really great for data leaks",
    "start": "2627490",
    "end": "2635200"
  },
  {
    "start": "2629000",
    "end": "2703000"
  },
  {
    "text": "but I wouldn't use it for a database I wouldn't use it for a graph database I wouldn't use it for a no sequel database so picking the rice storage tiers and",
    "start": "2635200",
    "end": "2642730"
  },
  {
    "text": "not necessarily one storage tier as well so we have many many customers that are having data funnel into s3 they're",
    "start": "2642730",
    "end": "2649720"
  },
  {
    "text": "popping you know materialized views in databases in data warehouses of that",
    "start": "2649720",
    "end": "2654850"
  },
  {
    "text": "data to be able to drive transactional data transactional systems graph",
    "start": "2654850",
    "end": "2660040"
  },
  {
    "text": "analysis or thing and you know one of the things I like to say is big data",
    "start": "2660040",
    "end": "2665440"
  },
  {
    "text": "analytics machine learning doesn't have to be big costs so it's all about making sure the services that you're leveraging",
    "start": "2665440",
    "end": "2671770"
  },
  {
    "text": "are being done in an effective way and our services really help enable that and using the right tool for the right job",
    "start": "2671770",
    "end": "2677950"
  },
  {
    "text": "so that's what we want to cover in this session again there's a lot more detail",
    "start": "2677950",
    "end": "2684040"
  },
  {
    "text": "on the machine learning side on the last session in the tech track today and I think we're gonna take some questions",
    "start": "2684040",
    "end": "2689710"
  },
  {
    "text": "outside because I think they need to prep the room here and you know thank you again and please remember to fill",
    "start": "2689710",
    "end": "2695830"
  },
  {
    "text": "out your survey so we definitely look at every piece every note that we get so and thanks again",
    "start": "2695830",
    "end": "2703230"
  }
]
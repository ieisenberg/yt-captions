[
  {
    "start": "0",
    "end": "18000"
  },
  {
    "text": "good afternoon thanks for coming for this presentation it's titled design",
    "start": "1070",
    "end": "6509"
  },
  {
    "text": "patterns and best practices for data analytics with Amazon EMR my name is John fritz I've run product management",
    "start": "6509",
    "end": "12059"
  },
  {
    "text": "for the Ammar team I'm joined here with Anja bita who's a senior member of the technical staff at Salesforce actually",
    "start": "12059",
    "end": "19080"
  },
  {
    "text": "real quick before we start by show of hands how many folks are running Hadoop or spark or presto today Johanns okay",
    "start": "19080",
    "end": "25650"
  },
  {
    "text": "wow that's great how many folks are running it on AWS today still a good amount and then how many are running",
    "start": "25650",
    "end": "31230"
  },
  {
    "text": "those workloads on EMR ok great so we're gonna go over a couple of things it",
    "start": "31230",
    "end": "36750"
  },
  {
    "text": "might be a refresher for some folks who use EMR but then go into some new features some best practices and design",
    "start": "36750",
    "end": "42570"
  },
  {
    "text": "patterns that we see and then I'll hand it over to Anya who will talk a little bit about you know using Amazon EMR",
    "start": "42570",
    "end": "50070"
  },
  {
    "text": "Salesforce and some interesting patterns and best practices that her team has come up with well when deploying and",
    "start": "50070",
    "end": "55739"
  },
  {
    "text": "running these workloads so I guess to begin just a real quick overview what is",
    "start": "55739",
    "end": "60809"
  },
  {
    "start": "57000",
    "end": "248000"
  },
  {
    "text": "Amazon EMR so EMR as a service in AWS makes it easy cost effective and secure to run big data processing machine",
    "start": "60809",
    "end": "67740"
  },
  {
    "text": "learning real-time processing with the Apache Hadoop ecosystem you know a couple main points you know easy to use",
    "start": "67740",
    "end": "73590"
  },
  {
    "text": "you can spin up a cluster in a couple of minutes you can use the AWS console you can use the ATS command line and",
    "start": "73590",
    "end": "79770"
  },
  {
    "text": "literally just in a couple of why and say at one you know one to thousands of Hadoop nodes in a cluster and start it",
    "start": "79770",
    "end": "85200"
  },
  {
    "text": "up it's also low cost the slide used to say a couple months back per our pricing",
    "start": "85200",
    "end": "91229"
  },
  {
    "text": "it's actually now per second pricing about two months ago along with ec2 EMR now you pay per second you can shut your",
    "start": "91229",
    "end": "97680"
  },
  {
    "text": "cluster down and stop paying for it immediately there's no hourly boundary anymore we've got a variety of open",
    "start": "97680",
    "end": "103020"
  },
  {
    "text": "source software so I think right now with EMR 5-10 I think we're at 19 open source projects we actually just added",
    "start": "103020",
    "end": "109079"
  },
  {
    "text": "support for MX net and we have a new release around every four to six weeks that means that the latest versions of",
    "start": "109079",
    "end": "115530"
  },
  {
    "text": "the open source projects are available in EMR pretty quickly that's important because like you know if your spark",
    "start": "115530",
    "end": "120840"
  },
  {
    "text": "developer every new version of spark has a variety of like oftentimes critical bug fixes and other new functionality",
    "start": "120840",
    "end": "126689"
  },
  {
    "text": "that's important so you know we won't force you to upgrade but we make a new release available",
    "start": "126689",
    "end": "131890"
  },
  {
    "text": "about every four to six weeks fully managed you know we replace nodes will Auto scale your cluster secure will talk",
    "start": "131890",
    "end": "138100"
  },
  {
    "text": "a little bit more about some new security features that have come out a little bit later and finally its flexible you know the goal is we want",
    "start": "138100",
    "end": "144520"
  },
  {
    "text": "you to be able to easily create a Hadoop cluster and just start writing applications not really worrying about configuring things and you know",
    "start": "144520",
    "end": "151380"
  },
  {
    "text": "troubleshooting that sort of stuff to get the cluster up and working but if you do want to say change all the default settings or even install custom",
    "start": "151380",
    "end": "158290"
  },
  {
    "text": "components we're not going to stop you you've got root access over all the boxes and you can even use a custom",
    "start": "158290",
    "end": "163540"
  },
  {
    "text": "Amazon Linux Omni as well so there's a lot of variation you can go from taking all of our defaults and we'll talk a",
    "start": "163540",
    "end": "169000"
  },
  {
    "text": "little bit about some of the default configurations for spark but you can also change everything kind of moving",
    "start": "169000",
    "end": "176200"
  },
  {
    "text": "from the open source application I've wanted not go spend much time on this slide but quickly just the way that we kind of organized you know EMR that",
    "start": "176200",
    "end": "182470"
  },
  {
    "text": "we've got you know a bunch of ec2 instances will spin up in your account oftentimes the process data and s3",
    "start": "182470",
    "end": "187690"
  },
  {
    "text": "you've got a variety of different cluster management options yarn which you know will run MapReduce spark",
    "start": "187690",
    "end": "193540"
  },
  {
    "text": "Tezz everything on top of that but also HBase and Phoenix you can run no sequel clusters you can use presto which is a",
    "start": "193540",
    "end": "200170"
  },
  {
    "text": "distributed low latency sequel engine now you can run MX net for distributed training a variety of front-end tools",
    "start": "200170",
    "end": "207760"
  },
  {
    "text": "like ganglia Zeppelin you know if you have notebooks you sequel develop Weda tur table browsers that sort of stuff",
    "start": "207760",
    "end": "215620"
  },
  {
    "text": "and then connectors to a variety of AWS services and so you know you can say you",
    "start": "215620",
    "end": "221980"
  },
  {
    "text": "spark to directly load redshift using the spark redshift connector which uses under the hood the unload command for",
    "start": "221980",
    "end": "228310"
  },
  {
    "text": "redshift to get really good throughput from redshift into s3 you can use an",
    "start": "228310",
    "end": "233530"
  },
  {
    "text": "open source we actually open sources sometime this year I think our hive DynamoDB connector so you can query and",
    "start": "233530",
    "end": "239140"
  },
  {
    "text": "do big data analytics on your tables and DynamoDB you know you can use scoop to",
    "start": "239140",
    "end": "245230"
  },
  {
    "text": "go access data and your my sequel databases but one particular connector I want to focus on is AWS glue and so AWS",
    "start": "245230",
    "end": "252760"
  },
  {
    "start": "248000",
    "end": "345000"
  },
  {
    "text": "glue great service it has a couple of components actually three main ones one is an ETL service where you can you know",
    "start": "252760",
    "end": "259150"
  },
  {
    "text": "not write any code and drag things together create serverless ETL pipelines what I want to focus on here is the aid",
    "start": "259150",
    "end": "264760"
  },
  {
    "text": "abuse glue data which is a fully managed hive Mehta store compliance service and we'll talk",
    "start": "264760",
    "end": "270010"
  },
  {
    "text": "about that in a minute and then finally crawlers which crawl data to infer schema so before the glue data catalog",
    "start": "270010",
    "end": "276070"
  },
  {
    "text": "what many customers would do is run in external hive meta store database in RDS",
    "start": "276070",
    "end": "281440"
  },
  {
    "text": "or aurora and that was great for a couple of reasons one is you could shut your cluster down all of your metadata was you know persisted you could bring",
    "start": "281440",
    "end": "287680"
  },
  {
    "text": "it back the next day you wouldn't have to recreate your tables or if something happened to say your hive meta store my",
    "start": "287680",
    "end": "293290"
  },
  {
    "text": "sequel database running on the master node you'd have the extra durability and availability but with glue all that's",
    "start": "293290",
    "end": "299710"
  },
  {
    "text": "fully managed and you actually have an intelligent meta store you don't need to write any DDL to create a table you can",
    "start": "299710",
    "end": "305560"
  },
  {
    "text": "have glue just crawl through your data and for what the schema is and create those tables for you",
    "start": "305560",
    "end": "310900"
  },
  {
    "text": "you can also have it add partitions one thing that could be a pain is if you're constantly updating your hive tables you",
    "start": "310900",
    "end": "315940"
  },
  {
    "text": "have to have some process to kick off the DL to load that new partition in AWS glue data catalog can do it for you you",
    "start": "315940",
    "end": "322690"
  },
  {
    "text": "can have a variety of complex data types that it supports as well and so with EMR 510 which we released last week we have",
    "start": "322690",
    "end": "328930"
  },
  {
    "text": "support not only now for hive and spark but also for presto so you really can full full stop move all of your kind of",
    "start": "328930",
    "end": "335710"
  },
  {
    "text": "data cataloging that you might have used the hive meta store component for - AWS glue and EMR and that's a click in the",
    "start": "335710",
    "end": "341830"
  },
  {
    "text": "console or some you know a couple configuration settings so moving from glue just going over a couple of newer",
    "start": "341830",
    "end": "348580"
  },
  {
    "text": "use cases that we're seeing as well or some kind of just design patterns one is utilizing HBase for random access at",
    "start": "348580",
    "end": "355930"
  },
  {
    "text": "massive scale and so we see a lot of customers running HBase using HDFS which",
    "start": "355930",
    "end": "362640"
  },
  {
    "text": "you know historically that's the only underlying file system that HBase could write out it's H files - in the past",
    "start": "362640",
    "end": "369130"
  },
  {
    "text": "year we've added support for HBase to utilize s3 as an object store instead of HDFS for H files and then also the",
    "start": "369130",
    "end": "376510"
  },
  {
    "text": "ability to use a read replica HBase cluster in another availability zone I mean a great example of HBase on s3 is",
    "start": "376510",
    "end": "383350"
  },
  {
    "text": "FINRA FINRA Financial Regulator in the United States wanted to have low latency",
    "start": "383350",
    "end": "388390"
  },
  {
    "text": "access over say trillions of Records to be able to basically pull out a couple of Records and see the relationships",
    "start": "388390",
    "end": "394780"
  },
  {
    "text": "between the two they're running a very large HDFS cluster by moving to s three they were able to save think",
    "start": "394780",
    "end": "400360"
  },
  {
    "text": "around 50% or so on their storage costs because instead of size in the cluster for HDFS they get sized it for the",
    "start": "400360",
    "end": "406870"
  },
  {
    "text": "amount of power they need out of their regions servers to be able to serve the data it had a much larger footprint and s3 with read replicas which is a",
    "start": "406870",
    "end": "413740"
  },
  {
    "text": "somewhat newer feature that happened later in this year you can spin up a read replica cluster in another AZ and",
    "start": "413740",
    "end": "420100"
  },
  {
    "text": "either load balanced writes so you don't overload one cluster with all the requests or from a DR perspective you",
    "start": "420100",
    "end": "426250"
  },
  {
    "text": "know you want to architect if you can for availability across a Z's s3 is available across a full region so you",
    "start": "426250",
    "end": "433300"
  },
  {
    "text": "don't need to replicate the data twice which you'd have to do with HDFS and have two full HDFS clusters in each AZ",
    "start": "433300",
    "end": "438580"
  },
  {
    "text": "you can spin up a smaller read replicas cluster pointed at that same set of H files and drive",
    "start": "438580",
    "end": "444130"
  },
  {
    "text": "you know reads through there in the case of a failover situation another use case",
    "start": "444130",
    "end": "450760"
  },
  {
    "text": "that we continue seeing a lot of growth for is just you know utilizing the EMR platform for real-time and batch and",
    "start": "450760",
    "end": "456070"
  },
  {
    "text": "data exploration and this is kind of one one diagram that we see customers often",
    "start": "456070",
    "end": "461080"
  },
  {
    "text": "times building out where you have Kinesis and you push Kinesis into spark spark streaming has a built in connector",
    "start": "461080",
    "end": "468700"
  },
  {
    "text": "for Kinesis but also for Kafka as well to do your real-time analytics maybe some data processing on the fly but then",
    "start": "468700",
    "end": "475210"
  },
  {
    "text": "dump that data into s3 and if you don't really need to do any real time processing honestly Kinesis firehoses is",
    "start": "475210",
    "end": "480310"
  },
  {
    "text": "a great use case for that as well just getting the data in there you get a catalogued in the glue data catalog and",
    "start": "480310",
    "end": "486400"
  },
  {
    "text": "then you have it basically open to a variety of different analytical engines so you know EMR has a bunch like hi Evan",
    "start": "486400",
    "end": "492940"
  },
  {
    "text": "tez SPARC presto we'll talk in a second about with some of those diagrams before but once it's in the data catalog in s3",
    "start": "492940",
    "end": "498850"
  },
  {
    "text": "you can use Athena which is you know serverless sequel queries you can use glue ETL which is service ETL or even",
    "start": "498850",
    "end": "506890"
  },
  {
    "text": "redshift spectrum as well but we see a couple of main use cases for EMR one data exploration with SPARC so with",
    "start": "506890",
    "end": "514570"
  },
  {
    "text": "SPARC and the availability of the zeppelin notebooks or you can easily bootstrap on a jupiter notebook and",
    "start": "514570",
    "end": "522370"
  },
  {
    "text": "utilize livvie which we'll talk about a little bit later you can arm your data scientists with an ad hoc way to interact with a large amounts of data",
    "start": "522370",
    "end": "529210"
  },
  {
    "text": "you know SPARC instead of being using one data scientist I instead you can",
    "start": "529210",
    "end": "534269"
  },
  {
    "text": "scale out those jobs across the cluster it also makes it easy to then move into production as well because then you can template eyes those clusters and then",
    "start": "534269",
    "end": "540750"
  },
  {
    "text": "run them on a regular basis we've seen a big rise and using presto for ad hoc sequel in combination with Athena I mean",
    "start": "540750",
    "end": "547470"
  },
  {
    "text": "they kind of approach the same thing from a different angle presto gives you kind of advanced configurations and the",
    "start": "547470",
    "end": "553379"
  },
  {
    "text": "way to really build exactly what you need for a use case but you have a cluster to manage and you have to deal with some of that sometimes it's good",
    "start": "553379",
    "end": "559529"
  },
  {
    "text": "sometimes it's a little bit overbearing versus Athena you just go to the console and start writing sequel presto now",
    "start": "559529",
    "end": "565170"
  },
  {
    "text": "supports LDAP authentication and in transit encryptions you can use it for a hip eligible service and there's many BI",
    "start": "565170",
    "end": "571860"
  },
  {
    "text": "tools that are now integrating with presto as well so you can have it power load that you can see dashboards and",
    "start": "571860",
    "end": "577529"
  },
  {
    "text": "finally just you know batch processing oftentimes the end place might be into elasticsearch or redshift which is",
    "start": "577529",
    "end": "584100"
  },
  {
    "text": "really a more optimized data warehouse then what presto can do in utilizing SPARC again to go or hive to go",
    "start": "584100",
    "end": "590970"
  },
  {
    "text": "transform the data and then load it into any of the other endpoints one final use case that we're starting to see adopted",
    "start": "590970",
    "end": "597300"
  },
  {
    "start": "594000",
    "end": "661000"
  },
  {
    "text": "and this is something new with the release last week is deep learning use cases so EMR for a long period of time",
    "start": "597300",
    "end": "602699"
  },
  {
    "text": "has done large scale machine learning we've had out and MapReduce for a long period of time we supported SPARC I",
    "start": "602699",
    "end": "608009"
  },
  {
    "text": "think around in 2015 but as of last week now you can launch a GPU Hardware in EMR and we have support for MX Net and so",
    "start": "608009",
    "end": "615379"
  },
  {
    "text": "you know why use EMR for a deep learning platform well oftentimes you need to do feature engineering before throwing",
    "start": "615379",
    "end": "621120"
  },
  {
    "text": "things into whatever model you're trying to Train and because you have things like hive and SPARC co-located with",
    "start": "621120",
    "end": "627779"
  },
  {
    "text": "things like MX net on the same cluster you can easily run your full end-to-end data engineering into whatever machine",
    "start": "627779",
    "end": "634860"
  },
  {
    "text": "learning models you want to use we actually released a blog post yesterday I highly encourage checking it out about",
    "start": "634860",
    "end": "641339"
  },
  {
    "text": "running SPARC and MX and it together for distributed inference and so we're gonna",
    "start": "641339",
    "end": "646589"
  },
  {
    "text": "be supporting tensorflow hopefully next month or sometime soon and then you know you throw in scanning your full control over the clusters you",
    "start": "646589",
    "end": "652589"
  },
  {
    "text": "can load up a custom ami with all sorts of deep learning libraries or other custom packages you have and run the",
    "start": "652589",
    "end": "658860"
  },
  {
    "text": "cluster with those as well so kind of moving from because design",
    "start": "658860",
    "end": "665040"
  },
  {
    "start": "661000",
    "end": "727000"
  },
  {
    "text": "patterns a couple tips to lower your costs and things that we oftentimes encourage customers to do as they're",
    "start": "665040",
    "end": "670110"
  },
  {
    "text": "optimizing their workloads one is thinking about whether you have a transient cluster at use case for a long-running cluster use case we see a",
    "start": "670110",
    "end": "676920"
  },
  {
    "text": "lot of both I mean some people think well um are is really meant to be a transient you know job flow engine that's not true we have people who are",
    "start": "676920",
    "end": "682649"
  },
  {
    "text": "running clusters for for many many months at a time the real question is is do you need the nodes up or not if",
    "start": "682649",
    "end": "687720"
  },
  {
    "text": "you're paying for a Hadoop node that's not doing anything they're just burning money and so we encourage people to think about are there ways you can batch",
    "start": "687720",
    "end": "693839"
  },
  {
    "text": "up your workloads together like in this case you know you take an inventory of the different jobs you have and say I",
    "start": "693839",
    "end": "699059"
  },
  {
    "text": "can make tweaks to make it so that certain things run in a batch a batch mode and I can shut the cluster down and",
    "start": "699059",
    "end": "705899"
  },
  {
    "text": "in between those times and then I can separate out the things that might need say an always-on cluster like an ad hoc",
    "start": "705899",
    "end": "712199"
  },
  {
    "text": "cluster for people to come to you can maybe use auto scaling with two to give",
    "start": "712199",
    "end": "718139"
  },
  {
    "text": "that but but not size it to where it's running everything so one thing is just thinking about if you're running a cluster could you be shutting it down",
    "start": "718139",
    "end": "724589"
  },
  {
    "text": "and not paying for it and if you can you should do it another thing is utilizing ec2 spot it's",
    "start": "724589",
    "end": "732720"
  },
  {
    "start": "727000",
    "end": "921000"
  },
  {
    "text": "a great way to save money off on demand oftentimes I think up to 80% you can really get a good discount on spot the",
    "start": "732720",
    "end": "739920"
  },
  {
    "text": "one caveat is is that it's possible that the spot market will take the instance back so if you have an SLA driven",
    "start": "739920",
    "end": "744959"
  },
  {
    "text": "workload that cannot withstand any failure you know that spot might not be the right call but oftentimes what you",
    "start": "744959",
    "end": "751529"
  },
  {
    "text": "can do is you can say well odds of failure are pretty low and you know Hadoop itself can handle several node failures and you should run tasks tasks",
    "start": "751529",
    "end": "758939"
  },
  {
    "text": "nodes that don't have data nodes you're not impacting HDFS but still there might be a failure you might lose a bunch of",
    "start": "758939",
    "end": "764790"
  },
  {
    "text": "nodes SPARC might not be able to recompute a data frame having the logic built-in where you can just kill the cluster and create a new one maybe with",
    "start": "764790",
    "end": "770910"
  },
  {
    "text": "all on-demand and for that one job it's more expensive but for the first you know the last hundred times it ran fine",
    "start": "770910",
    "end": "776519"
  },
  {
    "text": "and you got to save a lot so sometimes thinking a little bit differently about how can I like template eyes the",
    "start": "776519",
    "end": "781740"
  },
  {
    "text": "architecture so I quickly kind of recover if something happens is pretty doable and and oftentimes is recommended",
    "start": "781740",
    "end": "787799"
  },
  {
    "text": "if you're using spot and you're dealing with a workload that's pretty SLA bound but we want to talk about is the future",
    "start": "787799",
    "end": "793649"
  },
  {
    "text": "that we released earlier this year called instance fleets so instance leads is similar to spot fleets they're not",
    "start": "793649",
    "end": "800460"
  },
  {
    "text": "the same so we're not actually using spot fleets but using kind of the fleet mentality which is we're not you're not",
    "start": "800460",
    "end": "805560"
  },
  {
    "text": "going to specify the instance to use you're going to give us a list of instances and we're gonna do the best we",
    "start": "805560",
    "end": "810960"
  },
  {
    "text": "can based on availability of instances to give you some combination of what you want this is actually a screenshot from",
    "start": "810960",
    "end": "816720"
  },
  {
    "text": "the console where you can create and define one of these fleets the problems it solves are are actually three main",
    "start": "816720",
    "end": "822570"
  },
  {
    "text": "ones that we saw you know a lot of customers or customers at times running into that we wanted to solve one was you",
    "start": "822570",
    "end": "829710"
  },
  {
    "text": "know when you select one instance type and there's either not enough spot instances or things are starting be",
    "start": "829710",
    "end": "835770"
  },
  {
    "text": "reclaimed EMR will continue trying to get that instance for you but it might take some time and so what the instance",
    "start": "835770",
    "end": "842400"
  },
  {
    "text": "lead does to address this use cases is well you've given us you know four or five different choices you provided a",
    "start": "842400",
    "end": "848280"
  },
  {
    "text": "way to say I'd take you know eight are three X larges or one are three eight X large and we'll do the best we can to",
    "start": "848280",
    "end": "854010"
  },
  {
    "text": "provision across all that to get that incapacity that you want second one is AZ capacity you know if",
    "start": "854010",
    "end": "861540"
  },
  {
    "text": "your data is an s3 you can launch an EMR cluster and any AZ you might have a subnet but how do you know which AZ is",
    "start": "861540",
    "end": "867030"
  },
  {
    "text": "the right one to launch based on capacity and other heuristics so you can give us a list of AZ's and we'll choose",
    "start": "867030",
    "end": "872790"
  },
  {
    "text": "the one based on heuristics that we're watching that we think is the best one to launch the cluster based on what you asked for in a final use case might be I",
    "start": "872790",
    "end": "880320"
  },
  {
    "text": "really want to have spot but if I can't get all the spot instances I still need",
    "start": "880320",
    "end": "885450"
  },
  {
    "text": "to run the job and I'm going to pay full price and that's where the switched on demand feature comes in where you can say after thirty minutes or something if",
    "start": "885450",
    "end": "891870"
  },
  {
    "text": "I can't get all the boxes I want just switched on to man I'll pay full price I get a discount on the part that you",
    "start": "891870",
    "end": "897480"
  },
  {
    "text": "could push into spot but I really need to run the job with all the capacity so if you haven't checked out instance",
    "start": "897480",
    "end": "902550"
  },
  {
    "text": "fleet's it's a little bit more of an advanced feature it's you know more things to think about that instance groups is you're literally just what's",
    "start": "902550",
    "end": "908250"
  },
  {
    "text": "your instance type how many do you want but it's a powerful thing especially if you're running in very large spot",
    "start": "908250",
    "end": "913560"
  },
  {
    "text": "clusters and you're running them kind of on the fly this helps around a lot of provisioning issues that might come up",
    "start": "913560",
    "end": "919140"
  },
  {
    "text": "when you're running at scale another kind of best practice to use for say",
    "start": "919140",
    "end": "925290"
  },
  {
    "start": "921000",
    "end": "973000"
  },
  {
    "text": "long-running workloads or even transient workloads to some degree is scaling EMR auto-scaling utilizes some",
    "start": "925290",
    "end": "931589"
  },
  {
    "text": "of the application auto scaling features under the hood but we stitched things together ourselves you'd have to go in and configure cloud well if you",
    "start": "931589",
    "end": "937620"
  },
  {
    "text": "basically tell us what you want to do and we do all the stuff on your behalf under the hood there's a variety of",
    "start": "937620",
    "end": "943350"
  },
  {
    "text": "cloud watch metrics you can use like yarn memory or we have actually a ratio of believe containers pending two",
    "start": "943350",
    "end": "949709"
  },
  {
    "text": "containers active which is kind of a proxy for if you gave me another node would I have any yarn containers to put",
    "start": "949709",
    "end": "955230"
  },
  {
    "text": "on it and if so give me the other node pumps with a bunch of cloud watch metrics that make sense to use but also",
    "start": "955230",
    "end": "960740"
  },
  {
    "text": "you can push custom metrics to cloud watch so one example is there's no cloud watch metric yet for like aggregate CPU",
    "start": "960740",
    "end": "967290"
  },
  {
    "text": "on the cluster but if you've installed ganglia there is and so you can pump that to cloud watch and scale on that a",
    "start": "967290",
    "end": "974459"
  },
  {
    "start": "973000",
    "end": "1065000"
  },
  {
    "text": "couple notes on auto scaling so before five ten we actually had an option where",
    "start": "974459",
    "end": "979740"
  },
  {
    "text": "you could scale in an instance hour which has since been deprecated that was a feature that we built when there wasn't per second billing and you might",
    "start": "979740",
    "end": "985560"
  },
  {
    "text": "not want us to take away a node that you've paid for before the hour is up we've deprecated that because there isn't really a use case for that anymore",
    "start": "985560",
    "end": "991529"
  },
  {
    "text": "with five ten and beyond what we do when we scale in when when you've given us the right parameters and we say all",
    "start": "991529",
    "end": "997200"
  },
  {
    "text": "right well the metric is where you told us to scale in which nodes do we take we actually look to see which nodes aren't",
    "start": "997200",
    "end": "1003020"
  },
  {
    "text": "running into yarn containers and take those first if a node is running a yarn container we're gonna wait until that",
    "start": "1003020",
    "end": "1009260"
  },
  {
    "text": "value yarn dot resource manager decommissioning timeout which is set to one hour wait up for an hour and then if",
    "start": "1009260",
    "end": "1014959"
  },
  {
    "text": "no node is free we'll sorry we're gonna we're gonna take that one and kill the yarn container if you had a use case",
    "start": "1014959",
    "end": "1020870"
  },
  {
    "text": "like say you were caching a large spark data frame which has all the yarn containers up and you didn't want us to take it you can set that to an",
    "start": "1020870",
    "end": "1026959"
  },
  {
    "text": "arbitrarily high number and basically it will never take a node away that's running anything so it kind of depended",
    "start": "1026959",
    "end": "1032150"
  },
  {
    "text": "on your use case a couple other things as well for SPARC there used to we found",
    "start": "1032150",
    "end": "1038300"
  },
  {
    "text": "some customer issues where when you're scaling SPARC in and say it was in the middle of a shuffle blocks would be lost because we'd you know SPARC would say",
    "start": "1038300",
    "end": "1044420"
  },
  {
    "text": "we'll take this node away but actually would have data on it that you need so we're actually the process of pushing a lot of this back out to open source but",
    "start": "1044420",
    "end": "1050300"
  },
  {
    "text": "we build some optimizations into park scale down behavior to where it's more resilient it understands a little bit",
    "start": "1050300",
    "end": "1056450"
  },
  {
    "text": "where shuffle blocks are and in the case that there is an error that could be recomputed SPARC won't freeze and kill the job it'll",
    "start": "1056450",
    "end": "1062250"
  },
  {
    "text": "do the right thing and start me trying certain actions okay so we talked a little bit about cost-saving strategy",
    "start": "1062250",
    "end": "1068370"
  },
  {
    "start": "1065000",
    "end": "1148000"
  },
  {
    "text": "now moving on to a little bit of overview on security and so we'll talk",
    "start": "1068370",
    "end": "1074190"
  },
  {
    "text": "about a couple of new features - so the first encryption so EMR supports",
    "start": "1074190",
    "end": "1080100"
  },
  {
    "text": "end-to-end encryption for variety different frameworks this is just a quick diagram and I'll actually show in",
    "start": "1080100",
    "end": "1085710"
  },
  {
    "text": "a two-second demo like how it's just a couple clicks you could configure all this but it's a diagram useful to know",
    "start": "1085710",
    "end": "1091020"
  },
  {
    "text": "you know what's actually being encrypted you can configure s3 encryption server side or client side we encrypt all the",
    "start": "1091020",
    "end": "1097860"
  },
  {
    "text": "local disks of your clusters so any executor spills or HDFS blocks that are written all get encrypted on the local",
    "start": "1097860",
    "end": "1103530"
  },
  {
    "text": "disk and let a Linux file system and then we've got we been within the last",
    "start": "1103530",
    "end": "1109020"
  },
  {
    "text": "release when you enable in transit encryption wool and crypts bark tez Map Reduce presto HBase hive and pig so all",
    "start": "1109020",
    "end": "1117870"
  },
  {
    "text": "the kind of blocks that are flying across the wire are all encrypted now because we set up the SSL cert",
    "start": "1117870",
    "end": "1124050"
  },
  {
    "text": "configuration if there actually was something we weren't encrypting or something that you've installed that you would need like let's say hive server 2",
    "start": "1124050",
    "end": "1131010"
  },
  {
    "text": "or something like that you're connecting via JDBC or you need some sort of web UI encrypted oftentimes just through",
    "start": "1131010",
    "end": "1136500"
  },
  {
    "text": "configuration you can flip it on and over time we'll add more of that into the security configuration as well so for every release we have a note of the",
    "start": "1136500",
    "end": "1143340"
  },
  {
    "text": "actual things we're encrypting definitely check that out we add more things you know oftentimes every release from an authentication point of view a",
    "start": "1143340",
    "end": "1150270"
  },
  {
    "start": "1148000",
    "end": "1206000"
  },
  {
    "text": "lot of customers come and say you know how do i authenticate my users you know it's the EMR step is pretty",
    "start": "1150270",
    "end": "1155340"
  },
  {
    "text": "straightforward at the bottom user AWS credentials it's a nativist API and that's how I authenticate myself but from the Hadoop",
    "start": "1155340",
    "end": "1161940"
  },
  {
    "text": "stack you know I've got you know 200 business users and they all want to run a hive query and connect via JDBC what",
    "start": "1161940",
    "end": "1167700"
  },
  {
    "text": "do we do so it's wanted to quickly put up a slide showing kind of the groupings of some of these things we do support",
    "start": "1167700",
    "end": "1173490"
  },
  {
    "text": "LDAP for hive server to presto the spark thrift server hue which is a front-end",
    "start": "1173490",
    "end": "1178800"
  },
  {
    "text": "where you can you know query UI and Zeppelin which is a notebook some of these things you need to configure",
    "start": "1178800",
    "end": "1184320"
  },
  {
    "text": "through the configuration API we have and I think our Doc's information on how to configure that to have it connect out",
    "start": "1184320",
    "end": "1190350"
  },
  {
    "text": "to your directory we also have if you're SS aging the ec2 key pair you SSH in",
    "start": "1190350",
    "end": "1196260"
  },
  {
    "text": "has Hadoop which is and if you run an EMR step the user is also a dupe which is the Super User and so we have a new",
    "start": "1196260",
    "end": "1203220"
  },
  {
    "text": "feature that we released last week which kind of addresses some of these things is a big enterprise a scrander prize",
    "start": "1203220",
    "end": "1208770"
  },
  {
    "start": "1206000",
    "end": "1267000"
  },
  {
    "text": "customers was can you support Kerberos you know it's great that you can SSH units to dupe but really what we want is",
    "start": "1208770",
    "end": "1214350"
  },
  {
    "text": "to do a cross realm trust with our ad and have all of our Corp users come and",
    "start": "1214350",
    "end": "1219600"
  },
  {
    "text": "ssh in as themselves and we want to audit them to know who ran the hive query that took down the cluster and that's what a thing so or more",
    "start": "1219600",
    "end": "1226080"
  },
  {
    "text": "importantly data governance and so we in our last release 5:10 last week we've",
    "start": "1226080",
    "end": "1231750"
  },
  {
    "text": "got support for Kerberos and with a couple clicks you can launch you know a thousand node Hadoop cluster that's",
    "start": "1231750",
    "end": "1237450"
  },
  {
    "text": "fully kerberized if we install the KDC on the master node we store all the service principles there and then if you",
    "start": "1237450",
    "end": "1243120"
  },
  {
    "text": "want to do a a one-way trust with your active directory you can do that and then you can you know SSH in as yourself",
    "start": "1243120",
    "end": "1250560"
  },
  {
    "text": "and so we're excited about that feature this quick diagram showing kind of",
    "start": "1250560",
    "end": "1255650"
  },
  {
    "text": "high-level across across across from trust users run spark job as himself",
    "start": "1255650",
    "end": "1260930"
  },
  {
    "text": "yarn impersonations enabled and then now you're you're seeing exactly what's going on by the user who ran it and then",
    "start": "1260930",
    "end": "1268350"
  },
  {
    "text": "kind of to conclude on the security overview we talked about encryption and authentication and now authorization",
    "start": "1268350",
    "end": "1273750"
  },
  {
    "text": "once again a bunch of different modes depending on what you're trying to do you could be in a storage based world",
    "start": "1273750",
    "end": "1278790"
  },
  {
    "text": "where you use the Ackles or permissions on the storage level to determine whether you can run the job or not HDFS supports apples you can configure",
    "start": "1278790",
    "end": "1285360"
  },
  {
    "text": "it MRFs we'll talk about in the next slide so we can skip that for now but that's s3 access control hi server to",
    "start": "1285360",
    "end": "1293370"
  },
  {
    "text": "and now presto and the latest version supports sequel standards based access control so that's you know this guy can access this table this column kind of at",
    "start": "1293370",
    "end": "1300840"
  },
  {
    "text": "a sequel grain HBase support cell level yarn has cues with Kerberos now you can authenticate who's putting something to",
    "start": "1300840",
    "end": "1307320"
  },
  {
    "text": "yarn and make sure they don't put it in the wrong queue at an EMR cluster level you can use I am and tags to say this I",
    "start": "1307320",
    "end": "1314340"
  },
  {
    "text": "am user can't terminate you know an API action terminate cluster with tag X you",
    "start": "1314340",
    "end": "1319830"
  },
  {
    "text": "can do that and then finally you can install Ranger on a ec2 instance we have",
    "start": "1319830",
    "end": "1324990"
  },
  {
    "text": "a cloud formation template that can help Ranger is a kind of policy engine for Hadoop where you can configure each",
    "start": "1324990",
    "end": "1330390"
  },
  {
    "text": "application directly but Ranger kind of makes it a little bit easier because it's the same interface basically for creating all this and then install",
    "start": "1330390",
    "end": "1337049"
  },
  {
    "text": "plugins as well so you can you can use a bootstrap action to get that in but the",
    "start": "1337049",
    "end": "1342330"
  },
  {
    "start": "1341000",
    "end": "1393000"
  },
  {
    "text": "final new feature the earliest last week is back to Emaar FS storage based access control and now has been another major ask from customers who have the use case",
    "start": "1342330",
    "end": "1349320"
  },
  {
    "text": "where they have a shared cluster they're running sparks there really isn't any tables to use it's kind of arbitrary",
    "start": "1349320",
    "end": "1354450"
  },
  {
    "text": "data frames and they really want each user who comes in to assume a different",
    "start": "1354450",
    "end": "1359520"
  },
  {
    "text": "I am rule to limit what they can and can't access in s3 and so what this feature does is you can basically",
    "start": "1359520",
    "end": "1365520"
  },
  {
    "text": "specify users or groups like Hadoop users and groups on the cluster and say if I'm going to use the MRFs to access",
    "start": "1365520",
    "end": "1371640"
  },
  {
    "text": "s3 in the context to say group analysts use I am role analytics prod but if it's",
    "start": "1371640",
    "end": "1377100"
  },
  {
    "text": "user say dev use a different one and so that gives a kind of more fine-grain storage based access control real quick",
    "start": "1377100",
    "end": "1388040"
  },
  {
    "text": "I'm actually not sure we have we have time but I was going to show you is in the console there's a view basically one",
    "start": "1388040",
    "end": "1398220"
  },
  {
    "start": "1393000",
    "end": "1434000"
  },
  {
    "text": "page where it's a security configuration what you can do is all the things I've just described you basically check a",
    "start": "1398220",
    "end": "1404040"
  },
  {
    "text": "couple boxes choose the key that you want the SSL cert you have an s3 you click enable Kerberos if you have a",
    "start": "1404040",
    "end": "1410580"
  },
  {
    "text": "cross realm domain you've got to provide you know the address of where things are in the name of the realm and the domain of your ad and the users in groups you",
    "start": "1410580",
    "end": "1417600"
  },
  {
    "text": "want a map to the rules and then you save it with us as a name so see my security configuration when you create a",
    "start": "1417600",
    "end": "1423960"
  },
  {
    "text": "cluster you can reference that name security configuration you can create thousands of clusters with that same configuration so it makes it easy and",
    "start": "1423960",
    "end": "1430830"
  },
  {
    "text": "quick to preserve this across many clusters so just wanted to end with a",
    "start": "1430830",
    "end": "1436919"
  },
  {
    "start": "1434000",
    "end": "1441000"
  },
  {
    "text": "couple of things that we're seeing customers doing on submitting workflows the first is a new component that we've",
    "start": "1436919",
    "end": "1442980"
  },
  {
    "start": "1441000",
    "end": "1492000"
  },
  {
    "text": "added recently called Apache Livie and livvie basically serves as a spark job server actually for a long time we've",
    "start": "1442980",
    "end": "1449730"
  },
  {
    "text": "had a several customers who've been bootstrapping on a component called the spark job server which is open source by",
    "start": "1449730",
    "end": "1454799"
  },
  {
    "text": "a company who Yala eventually then livvie came about to kind of we think",
    "start": "1454799",
    "end": "1460200"
  },
  {
    "text": "that's the right the best technology for doing this stuff what it does is it it's an HTTP endpoint that you can interact with in",
    "start": "1460200",
    "end": "1466240"
  },
  {
    "text": "an ad hoc way what Livy will do is it'll create the spark session and manage it you can create multiple ones and on the",
    "start": "1466240",
    "end": "1472179"
  },
  {
    "text": "request you can name what sparks session you want to submit you know whatever interactions you want to go run and so",
    "start": "1472179",
    "end": "1479049"
  },
  {
    "text": "it's super useful if you want to build a cluster to basically serve the backing for an application or if say you're",
    "start": "1479049",
    "end": "1484090"
  },
  {
    "text": "running Jupiter off cluster you can use the spark magic Colonel pointed at Olivia endpoint and then you have now an",
    "start": "1484090",
    "end": "1489190"
  },
  {
    "text": "interactive spark cluster to use with your notebook you know one last thought is for more complicated DAGs you know",
    "start": "1489190",
    "end": "1495309"
  },
  {
    "start": "1492000",
    "end": "1555000"
  },
  {
    "text": "one question is you more step API it does one thing it does it pretty well it runs your job in sequence it doesn't run",
    "start": "1495309",
    "end": "1500710"
  },
  {
    "text": "you know jobs that are in parallel but it will be an API to basically serve the",
    "start": "1500710",
    "end": "1505750"
  },
  {
    "text": "run jobs if you have a really complicated dagi want to run we see really two two options that are that are",
    "start": "1505750",
    "end": "1511179"
  },
  {
    "text": "very popular one is easy which we support on the cluster musii now supports workflow definition files which",
    "start": "1511179",
    "end": "1516429"
  },
  {
    "text": "are these XML files in s3 you can spin up a cluster reference in s3 and start running a complicated dag that",
    "start": "1516429",
    "end": "1521830"
  },
  {
    "text": "screenshot actually is from hue-hue has a pretty robust UI to go design these jobs but also we see airflow being a new",
    "start": "1521830",
    "end": "1530049"
  },
  {
    "text": "popular when airflow is open sourced by air B&B it now recently is an Apache project and we see customers also",
    "start": "1530049",
    "end": "1536650"
  },
  {
    "text": "spinning that up on ec2 alongside their EMR clusters and it also has the intelligence to provision an EMR cluster",
    "start": "1536650",
    "end": "1542049"
  },
  {
    "text": "so within your workflow you can define you know create a cluster run these sorts of jobs and then shut it down",
    "start": "1542049",
    "end": "1547510"
  },
  {
    "text": "all from airflow so both are pretty powerful tools if you have these sorts of more complicated data flows you want",
    "start": "1547510",
    "end": "1552760"
  },
  {
    "text": "to design definitely take a look so anyway that's kind of a little bit of",
    "start": "1552760",
    "end": "1558580"
  },
  {
    "text": "overview talk a little about security spot auto-scaling a couple new features that we have and a couple of new components next I'm going to turn it",
    "start": "1558580",
    "end": "1565750"
  },
  {
    "text": "over to Anya to talk a little bit more about apache spark and EMR at Salesforce great thanks John thanks work hi",
    "start": "1565750",
    "end": "1574240"
  },
  {
    "start": "1566000",
    "end": "1593000"
  },
  {
    "text": "everybody I am Anya I am on the infrastructure side at Salesforce and I'm really happy to be here to tell you",
    "start": "1574240",
    "end": "1580659"
  },
  {
    "text": "about how we use spark with EMR so we Salesforce is a CRM company customer",
    "start": "1580659",
    "end": "1586360"
  },
  {
    "text": "relationship management we're obsessed with customer success because when our customers are successful then we are -",
    "start": "1586360",
    "end": "1593010"
  },
  {
    "start": "1593000",
    "end": "1597000"
  },
  {
    "text": "so that's what we do I'll give you an overview of the pieces that I'm gonna cover today I'm gonna",
    "start": "1593010",
    "end": "1599190"
  },
  {
    "start": "1597000",
    "end": "1651000"
  },
  {
    "text": "tell you our goal when we're we're trying to deploy a machine learning pipeline and how we kind of chose spark",
    "start": "1599190",
    "end": "1605309"
  },
  {
    "text": "and EMR I'm gonna get just level set and show everybody how to get started with EMR pretty quickly this might be review",
    "start": "1605309",
    "end": "1612600"
  },
  {
    "text": "for some of you but it'll be pretty quick I'll go through a quick spark primer just so that we're on the same",
    "start": "1612600",
    "end": "1617850"
  },
  {
    "text": "page there and then the best practices that we've kind of distilled from using spark on EMR namely monitoring multiple",
    "start": "1617850",
    "end": "1625080"
  },
  {
    "text": "environments I'm sorry monitoring our environments with multiple viewpoints using iam roles",
    "start": "1625080",
    "end": "1630780"
  },
  {
    "text": "the Identity and Access Management and isolating environments so that's the overview of let's get started so our",
    "start": "1630780",
    "end": "1637620"
  },
  {
    "text": "goal we wanted to create a complete machine learning pipeline we wanted eto",
    "start": "1637620",
    "end": "1642990"
  },
  {
    "text": "feature engineering we wanted to train our models but also we wanted to evaluate and deploy and operationalize",
    "start": "1642990",
    "end": "1648600"
  },
  {
    "text": "our models so this was this was kind of our requirement going in and we needed to select a tool that would support",
    "start": "1648600",
    "end": "1656090"
  },
  {
    "start": "1651000",
    "end": "1674000"
  },
  {
    "text": "allow us to reach our goal and also we needed a tool that would scale for small",
    "start": "1656090",
    "end": "1661110"
  },
  {
    "text": "jobs large jobs a tool that had built in machine learning libraries so we didn't have to reinvent the wheel and a tool",
    "start": "1661110",
    "end": "1668070"
  },
  {
    "text": "that had a great user base etc so for us SPARC was the choice and so okay we",
    "start": "1668070",
    "end": "1674250"
  },
  {
    "text": "wanted to deploy SPARC but how so we started out with ec2 we started out",
    "start": "1674250",
    "end": "1679380"
  },
  {
    "text": "creating Hadoop clusters and running SPARC there an ec2 and that was working for a while for us it was great that we",
    "start": "1679380",
    "end": "1686940"
  },
  {
    "text": "could spin up clusters large cluster of small clusters we weren't limited to the machines that we had in-house but this",
    "start": "1686940",
    "end": "1694770"
  },
  {
    "text": "got to be a little bit unwieldy after a while we started to have more and more clusters and started to dedicate more and more people to managing them so what",
    "start": "1694770",
    "end": "1701159"
  },
  {
    "text": "we ended a meeting was management of all these pieces we needed a service layer to manage that and again an EMR was the",
    "start": "1701159",
    "end": "1707520"
  },
  {
    "text": "key there take a drink of water so okay let's get",
    "start": "1707520",
    "end": "1719150"
  },
  {
    "start": "1718000",
    "end": "1749000"
  },
  {
    "text": "started with EMR let's provision so honestly the best way to that I think to get started with EMR",
    "start": "1719150",
    "end": "1725090"
  },
  {
    "text": "go through the wizard click through and take the options that you want but then click on that EWS command-line export",
    "start": "1725090",
    "end": "1731900"
  },
  {
    "text": "button and you're gonna get a command line that has all the all the flags that you selected through the wizard and this",
    "start": "1731900",
    "end": "1738410"
  },
  {
    "text": "is kind of the simplest command line to create a cluster AWS EMR create cluster and we're gonna create a cluster with",
    "start": "1738410",
    "end": "1744800"
  },
  {
    "text": "Hadoop and spark and ganglia angle is great for monitoring so kinda use that I added some notes when you're using",
    "start": "1744800",
    "end": "1751910"
  },
  {
    "start": "1749000",
    "end": "1819000"
  },
  {
    "text": "tagging go ahead and tag for cost analysis so all of our um our clusters are tagged with like four tags you know",
    "start": "1751910",
    "end": "1758330"
  },
  {
    "text": "environment in this case project it really helps when I'm going through and",
    "start": "1758330",
    "end": "1763910"
  },
  {
    "text": "deciding how much money am i spending on which project or in which environment so the tagging is really useful there send",
    "start": "1763910",
    "end": "1770240"
  },
  {
    "text": "the logs test three naming again choose kind of a naming convention that will",
    "start": "1770240",
    "end": "1775550"
  },
  {
    "text": "help you as well so maybe a naming convention would be region project version and environment and that is",
    "start": "1775550",
    "end": "1781640"
  },
  {
    "text": "really handy for templating your automation for service discovery and",
    "start": "1781640",
    "end": "1787220"
  },
  {
    "text": "then for that cost planning again next we're gonna select our instance",
    "start": "1787220",
    "end": "1794090"
  },
  {
    "text": "groups so we've I'm gonna select core nodes and task nodes here and I just wanted to",
    "start": "1794090",
    "end": "1799700"
  },
  {
    "text": "point out quickly here so the core nodes are actually going to be used for HDFS writes so the core nodes are running the",
    "start": "1799700",
    "end": "1805580"
  },
  {
    "text": "data node service and I'll show you kind of a diagram of this in a little bit whereas the task nodes are just for the",
    "start": "1805580",
    "end": "1811490"
  },
  {
    "text": "compute so might be wise to try spot instances here for the task notes okay",
    "start": "1811490",
    "end": "1817880"
  },
  {
    "text": "so that's just provisioning EMR it sounds good this is kind of the simplest approach when we think about our how we use EMR",
    "start": "1817880",
    "end": "1825290"
  },
  {
    "text": "it super simple I've got my data in s3 in my input bucket I'm gonna read from that I'm gonna run my job am I Mayim our",
    "start": "1825290",
    "end": "1832160"
  },
  {
    "text": "cluster and I'm gonna write to my output bucket and I'm gonna send my EMR logs over to s3 so super simple so my spark",
    "start": "1832160",
    "end": "1841340"
  },
  {
    "text": "job is running on my EMR cluster let's talk about that a little bit you're probably all familiar with this Apache spark diagram",
    "start": "1841340",
    "end": "1847460"
  },
  {
    "start": "1844000",
    "end": "1880000"
  },
  {
    "text": "right so you've got your driver that's going to run the user code the autumn awesome Deena scientists that created",
    "start": "1847460",
    "end": "1854090"
  },
  {
    "text": "this awesome application that's gonna run on the driver and the driver is gonna communicate with the cluster manager in this case yarn to negotiate",
    "start": "1854090",
    "end": "1861110"
  },
  {
    "text": "for some resources and then the the executor will spin up and that's where",
    "start": "1861110",
    "end": "1866330"
  },
  {
    "text": "the work is actually gonna happen the tasks running on the executor czar I'm going to do that data computation that's",
    "start": "1866330",
    "end": "1872360"
  },
  {
    "text": "needed for a particular partition okay so that's kind of just a real quick",
    "start": "1872360",
    "end": "1877539"
  },
  {
    "text": "spark overview well I took that diagram that you know and love I just created my",
    "start": "1877539",
    "end": "1884059"
  },
  {
    "start": "1880000",
    "end": "1895000"
  },
  {
    "text": "own what I'm gonna do is map this to my EMR nodes and see how that works because a lot of the time I get confused when I",
    "start": "1884059",
    "end": "1890269"
  },
  {
    "text": "think of oh there's this park driver but then there's the EMR master how does that work so here's my EMR diagram I've",
    "start": "1890269",
    "end": "1899269"
  },
  {
    "start": "1895000",
    "end": "1929000"
  },
  {
    "text": "got my master node and my core nodes and my task nodes and I've just got one of each here for simplicity I just wanted",
    "start": "1899269",
    "end": "1905690"
  },
  {
    "text": "to get point out on the master node I've got a couple of special services running the resource manager and the name node",
    "start": "1905690",
    "end": "1912440"
  },
  {
    "text": "services are running on the master node so EMR has done this for me I don't have to worry about that part and then again",
    "start": "1912440",
    "end": "1918320"
  },
  {
    "text": "as I pointed out earlier the the core nodes are running the data nodes service and you see that the task nodes are not",
    "start": "1918320",
    "end": "1924039"
  },
  {
    "text": "ok so how does my spark layout happen here so I put my spark driver I can put",
    "start": "1924039",
    "end": "1933500"
  },
  {
    "start": "1929000",
    "end": "1994000"
  },
  {
    "text": "my spark driver anywhere right I put it here on the core node just to illustrate that the spark driver doesn't have to",
    "start": "1933500",
    "end": "1939500"
  },
  {
    "text": "run on the EMR master node they're actually distinct items and then I've got my executor running they can",
    "start": "1939500",
    "end": "1945620"
  },
  {
    "text": "executives can run on any node ok so that's kind of my layout I gave a talk",
    "start": "1945620",
    "end": "1954259"
  },
  {
    "text": "once about how SPARC defaults are not recommended well EMR defaults with SPARC are usually",
    "start": "1954259",
    "end": "1959750"
  },
  {
    "text": "recommended just has like an overall statement and one thing that EMR does for me is it's enables dynamic",
    "start": "1959750",
    "end": "1965750"
  },
  {
    "text": "allocation by default so dynamic allocation is scaling out the number of executor x' and scallion or",
    "start": "1965750",
    "end": "1972330"
  },
  {
    "text": "to the number of nodes in my cluster the other thing that Yammer does for me is sizes my executor x' according to the",
    "start": "1972330",
    "end": "1979470"
  },
  {
    "text": "instance types that I've chosen so I want to choose this instance type I here's a however much I want to pay well",
    "start": "1979470",
    "end": "1984779"
  },
  {
    "text": "my executor czar sized automatically and that becomes really handy for making sure I'm getting the most utilization",
    "start": "1984779",
    "end": "1990929"
  },
  {
    "text": "that I can from my cluster okay and I talked about dynamic allocation so these",
    "start": "1990929",
    "end": "1996059"
  },
  {
    "start": "1994000",
    "end": "2010000"
  },
  {
    "text": "are some of the parameters that you would have to set if you were gonna do that on your own but I don't have to worry about that and then the next step",
    "start": "1996059",
    "end": "2008149"
  },
  {
    "text": "that everybody wants to know well how do I troubleshoot where do I find my metrics where do I find my logs so the",
    "start": "2008149",
    "end": "2013789"
  },
  {
    "text": "metrics are pretty much all set to called watch everything is there also I've suggested that we check out ganglia",
    "start": "2013789",
    "end": "2019519"
  },
  {
    "text": "um so kinkle is really handy for creating windows and dashboarding with ganglia i can understand at the cluster",
    "start": "2019519",
    "end": "2026330"
  },
  {
    "text": "wide level is my workflow kind of limited or bottlenecked at the cpu level",
    "start": "2026330",
    "end": "2032210"
  },
  {
    "text": "at the network level at the disk level so that helps me kind of get an ID to get an understanding of the of the cluster wide level and then I can also",
    "start": "2032210",
    "end": "2039470"
  },
  {
    "text": "use you know other tools J stat stats D for going into some metrics at a deeper",
    "start": "2039470",
    "end": "2045019"
  },
  {
    "text": "level okay what about logs so I'm really happy as of EMR 5.8 I think I can see my",
    "start": "2045019",
    "end": "2052310"
  },
  {
    "text": "application history in the this format so so all the other logging information in the in the easy to use web UI format",
    "start": "2052310",
    "end": "2060800"
  },
  {
    "text": "that you see here I can see that even after I terminate my cluster so I'm done",
    "start": "2060800",
    "end": "2066108"
  },
  {
    "text": "with running the cluster I don't want to pay for that anymore but I want to come back and look at the logs so that's",
    "start": "2066109",
    "end": "2071510"
  },
  {
    "text": "pretty handy of course all I'm also sending my logs to s3 so I can query them there as well but but this is a",
    "start": "2071510",
    "end": "2077540"
  },
  {
    "text": "nice way to click through you might have seen the application job stage tasks",
    "start": "2077540",
    "end": "2085148"
  },
  {
    "text": "words floating around with spark but I wanted to throw in a slide to kind of illustrate how those are defined because",
    "start": "2085149",
    "end": "2091099"
  },
  {
    "text": "it was baffling to me for a long time so here's a slide on the anatomy of a spark",
    "start": "2091099",
    "end": "2096770"
  },
  {
    "start": "2093000",
    "end": "2216000"
  },
  {
    "text": "job this I borrowed from a book high-performance spark by Holden Carrell and Rachel Warren",
    "start": "2096770",
    "end": "2102560"
  },
  {
    "text": "so it just I'm just showing how each of these levels is kind of defined so when I start my my spark session",
    "start": "2102560",
    "end": "2111320"
  },
  {
    "text": "there have got my spark application so that's the definitely how the spark application is defined when I do in",
    "start": "2111320",
    "end": "2117410"
  },
  {
    "text": "action that's how a job is going to be defined and you're familiar with spark there are actions and transformations",
    "start": "2117410",
    "end": "2123710"
  },
  {
    "text": "and spark is it lazily evaluating all of your code right so you can do all the",
    "start": "2123710",
    "end": "2129110"
  },
  {
    "text": "transformations that you want but until you perform an action spark well won't do any work it's kind of like the",
    "start": "2129110",
    "end": "2134930"
  },
  {
    "text": "sixteen year old teenager who says yeah I'm gonna do my chores kind of do me some lazy evaluation and they won't do",
    "start": "2134930",
    "end": "2141050"
  },
  {
    "text": "it until they're actually pushed it to really do it and that actually it's actually helpful with spark because spark waits to do what it actually needs",
    "start": "2141050",
    "end": "2148160"
  },
  {
    "text": "to do so if you say you know read all this data and then filter on the first",
    "start": "2148160",
    "end": "2153500"
  },
  {
    "text": "row and then print out the first row sparks not actually going to read all the data it's personally gonna read that row so that's very useful okay so anyway",
    "start": "2153500",
    "end": "2161480"
  },
  {
    "text": "back to the diagram so so that's actions and transformations when I call an action that's going to be the definition",
    "start": "2161480",
    "end": "2166520"
  },
  {
    "text": "of a job and then within the job there are several stages and stages are",
    "start": "2166520",
    "end": "2172850"
  },
  {
    "text": "defined defined by wide transformations wide transformation you think of it as a",
    "start": "2172850",
    "end": "2178610"
  },
  {
    "text": "shuffle so transformation where the child partitions depend on an unknown",
    "start": "2178610",
    "end": "2185120"
  },
  {
    "text": "number of the parent partitions so that's your wide transformation and that's going to define a stage okay and",
    "start": "2185120",
    "end": "2191150"
  },
  {
    "text": "then stages are made up of many tasks and that is the where the real work is happening that's the computation to evaluate one",
    "start": "2191150",
    "end": "2198200"
  },
  {
    "text": "single partition so typically you've got one task is running on one core and so",
    "start": "2198200",
    "end": "2203870"
  },
  {
    "text": "that task will take the data from that particular partition and use the core and do that evaluation",
    "start": "2203870",
    "end": "2210040"
  },
  {
    "text": "okay so that was the spark primer so getting back to my simple approach",
    "start": "2213410",
    "end": "2219370"
  },
  {
    "start": "2216000",
    "end": "2356000"
  },
  {
    "text": "diagram I've got my data in my input bucket my EMR cluster in my elver bucket so my input bucket I'm gonna read from",
    "start": "2219370",
    "end": "2226880"
  },
  {
    "text": "s3 I'm makin I want to make a note here I don't want to read too many small files from s3 that's you might have",
    "start": "2226880",
    "end": "2233480"
  },
  {
    "text": "encountered that problem I also I want to load my jar files to s3 I don't want",
    "start": "2233480",
    "end": "2238790"
  },
  {
    "text": "to load my jar files and fill up my the disk on my e-mart cluster so I'm gonna load my jar files test3 as well the EMR",
    "start": "2238790",
    "end": "2245570"
  },
  {
    "text": "cluster that's um what do I do about writing intermediate files so the next slide I'm gonna go into this a little",
    "start": "2245570",
    "end": "2251330"
  },
  {
    "text": "bit more do I want to do I want to write my intermediate files to memory or disk locally do I want to write to HDFS do I",
    "start": "2251330",
    "end": "2258620"
  },
  {
    "text": "want to write to Amazon s3 so we'll think about that in the next slide and then the output I'm gonna write my",
    "start": "2258620",
    "end": "2268010"
  },
  {
    "text": "output s3 so pretty simple and that's handy again because once I'm done with my compute I don't have to keep my",
    "start": "2268010",
    "end": "2274160"
  },
  {
    "text": "cluster running and my output is still available so that's that's great so",
    "start": "2274160",
    "end": "2279350"
  },
  {
    "text": "let's think about that writing intermediate files yeah so if you're using a spark how many people are using data sets maybe a couple anybody",
    "start": "2279350",
    "end": "2288980"
  },
  {
    "text": "using data frames okay and anybody still using rdd's a few dedicated developers",
    "start": "2288980",
    "end": "2297950"
  },
  {
    "text": "so so you're familiar with with data frames and data sets so as you know they",
    "start": "2297950",
    "end": "2303460"
  },
  {
    "text": "the data frame is a is an abstraction that allows me to take the take that RDD",
    "start": "2303460",
    "end": "2309470"
  },
  {
    "text": "and actually do some optimizations there actually I'm not doing the optimization SPARC is doing the optimizations for me",
    "start": "2309470",
    "end": "2315560"
  },
  {
    "text": "so the catalyst optimizer is going to think about the best way to create that",
    "start": "2315560",
    "end": "2320840"
  },
  {
    "text": "dag for me so that I don't have to shoot myself in the foot by doing a join and then a filter okay so that's really",
    "start": "2320840",
    "end": "2328610"
  },
  {
    "text": "handy and the data sets is that next improvement that then provides the type safety so with rdd's we had type safety with",
    "start": "2328610",
    "end": "2335930"
  },
  {
    "text": "data frames we didn't have type safety anymore but with data sets type safety is back wonderful okay so let me get",
    "start": "2335930",
    "end": "2341630"
  },
  {
    "text": "back to my original point how do I write my intermediate files well whether I'm using rdd's or data frames or data sets",
    "start": "2341630",
    "end": "2346740"
  },
  {
    "text": "I need to think about writing my intermediate files as an RDD actually because data frames and data sets are",
    "start": "2346740",
    "end": "2352200"
  },
  {
    "text": "going to boil down to an RDD in the end anyway so I want to think about RDD",
    "start": "2352200",
    "end": "2357300"
  },
  {
    "start": "2356000",
    "end": "2392000"
  },
  {
    "text": "reuse do I need to reuse my RDD at this if I've I've got an RDD that's going to",
    "start": "2357300",
    "end": "2363900"
  },
  {
    "text": "take a long time to recompute then I might want to save it if I've got if",
    "start": "2363900",
    "end": "2369300"
  },
  {
    "text": "I've got a noisy cluster that has some Network interruptions I might want to think about saving it and so these are the different ways that I can kind of",
    "start": "2369300",
    "end": "2375780"
  },
  {
    "text": "save my my RDD I can cache persist checkpoints or just to throw you a",
    "start": "2375780",
    "end": "2381840"
  },
  {
    "text": "curveball I could local checkpoint so okay I'll let you read the slide later",
    "start": "2381840",
    "end": "2387390"
  },
  {
    "text": "but but suffice to say that I want to I want to persist when I want to improve",
    "start": "2387390",
    "end": "2394890"
  },
  {
    "start": "2392000",
    "end": "2466000"
  },
  {
    "text": "speed and I want to checkpoint when I need to improve for tolerance so if if",
    "start": "2394890",
    "end": "2400740"
  },
  {
    "text": "my jobs are slow I'll go ahead and and persist but if my jobs are failing due to out of memory or this partition",
    "start": "2400740",
    "end": "2407490"
  },
  {
    "text": "doesn't fit in memory or network connectivity issues I'll think about checkpoint 8 now do I want to do that's",
    "start": "2407490",
    "end": "2418860"
  },
  {
    "text": "where I want to save my RDD locally or do I want to save it to external storage like HDFS or s3 well if I need my RTD to",
    "start": "2418860",
    "end": "2426570"
  },
  {
    "text": "persist after the that job is completed then I need to save to external storage whether HDFS or s3 if I if I just want",
    "start": "2426570",
    "end": "2435870"
  },
  {
    "text": "to delete my lineage graph but I want to continue with that RDD in the same job I can go ahead and use a local checkpoint",
    "start": "2435870",
    "end": "2442440"
  },
  {
    "text": "in that case so those are some considerations do I save to HDFS or s3",
    "start": "2442440",
    "end": "2447900"
  },
  {
    "text": "well it depends on the use case HDFS I'm saving relatively locally compared to s3",
    "start": "2447900",
    "end": "2454470"
  },
  {
    "text": "but s3 is has more durability maybe more availability so there's some pros and cons there so that's I guess it depends",
    "start": "2454470",
    "end": "2461160"
  },
  {
    "text": "on the use case and the SLA is that are needed there okay so we talked about our",
    "start": "2461160",
    "end": "2466560"
  },
  {
    "start": "2466000",
    "end": "2486000"
  },
  {
    "text": "goal at Salesforce to create a complete machine learning pipeline we we're doing",
    "start": "2466560",
    "end": "2472440"
  },
  {
    "text": "some getting started with EMR and we did a quick spark",
    "start": "2472440",
    "end": "2477900"
  },
  {
    "text": "so now let's talk about monitoring multiple viewpoints so what do I mean by",
    "start": "2477900",
    "end": "2483060"
  },
  {
    "text": "this so I'll use the example of a camera typically a camera has a single lens and",
    "start": "2483060",
    "end": "2488490"
  },
  {
    "start": "2486000",
    "end": "2506000"
  },
  {
    "text": "so I can just use one focal point to understand my environment well here I want to encourage you to use multiple",
    "start": "2488490",
    "end": "2495510"
  },
  {
    "text": "different perspectives this camera has 16 different lenses so I can use lots of different focal points to examine my",
    "start": "2495510",
    "end": "2500940"
  },
  {
    "text": "environment ok so let's dig into that let's monitor multiple viewpoints at the level of",
    "start": "2500940",
    "end": "2506520"
  },
  {
    "start": "2506000",
    "end": "2558000"
  },
  {
    "text": "understanding our resource allocation so here I've got my smart container and I",
    "start": "2506520",
    "end": "2512130"
  },
  {
    "text": "borrowed this diagram from a couple folks at Duke University I really like the way it shows inside the SPARC",
    "start": "2512130",
    "end": "2517230"
  },
  {
    "text": "container how is memory utilized so I think as I forget what your version of",
    "start": "2517230",
    "end": "2522570"
  },
  {
    "text": "SPARC they deployed the unified pool so if I want to use my memory for storage",
    "start": "2522570",
    "end": "2528240"
  },
  {
    "text": "or if I want to use my memory for executing the job excuse me for executing the task I've got this unified",
    "start": "2528240",
    "end": "2535710"
  },
  {
    "text": "pool so let's say oh I need more for storage that pool can be adjusted ok and use more memory for storage okay so",
    "start": "2535710",
    "end": "2542610"
  },
  {
    "text": "that's understanding the resource allocation inside the SPARC container but what if I just take a step back and take another perspective let's look at",
    "start": "2542610",
    "end": "2549390"
  },
  {
    "text": "the SPARC container just has a big blue box let's just say it's eight gigs I just want to know is my container gonna",
    "start": "2549390",
    "end": "2554790"
  },
  {
    "text": "launch I'm a data scientist please run my job ok so let's look at that is my",
    "start": "2554790",
    "end": "2560610"
  },
  {
    "text": "gig container going to launch on this cluster I've got a three node cluster eight gigs on each node and my data",
    "start": "2560610",
    "end": "2566760"
  },
  {
    "text": "scientist might say hey my job should lock my container should launch well no actually there's four gigs that are",
    "start": "2566760",
    "end": "2572550"
  },
  {
    "text": "already used on each node and so there's not eight gigs on a single node for you I'm sorry we'll have to wait until more",
    "start": "2572550",
    "end": "2578250"
  },
  {
    "text": "resources become available or we do some auto scaling so one suggestion here",
    "start": "2578250",
    "end": "2583320"
  },
  {
    "text": "would be to scale out according to the number of containers pending and I think John mentioned that as well thinking",
    "start": "2583320",
    "end": "2592710"
  },
  {
    "text": "about monitoring multiple viewpoints from in another in another way this is a connectivity viewer that a tool that one",
    "start": "2592710",
    "end": "2600180"
  },
  {
    "start": "2594000",
    "end": "2640000"
  },
  {
    "text": "of the team members by pop on my team built and he just built this tool so that we could see okay for each node",
    "start": "2600180",
    "end": "2605850"
  },
  {
    "text": "that is represented by a circle what could that would connect to and and I could see oh",
    "start": "2605850",
    "end": "2611630"
  },
  {
    "text": "I've got these three kind of clusters dev staging and prod it's great that I don't have any connections allowed from",
    "start": "2611630",
    "end": "2617540"
  },
  {
    "text": "pod to dev and if I did that might be a red flag I need to go and look into that so monitoring from multiple viewpoints",
    "start": "2617540",
    "end": "2624830"
  },
  {
    "text": "is pretty handy I'm gonna skip through the next couple of slides so I can get to the end just showing the different",
    "start": "2624830",
    "end": "2631370"
  },
  {
    "text": "ways that we can use the connectivity viewer and then I'm going to jump to actually using using the I am roles so",
    "start": "2631370",
    "end": "2638600"
  },
  {
    "text": "let's talk about that so here I've got we think about permissions and iam",
    "start": "2638600",
    "end": "2645200"
  },
  {
    "start": "2640000",
    "end": "2697000"
  },
  {
    "text": "stands for identity and access management so so authentication and authorization I typically think about",
    "start": "2645200",
    "end": "2650570"
  },
  {
    "text": "that as a applauding to a particular user so my user can access my job",
    "start": "2650570",
    "end": "2656150"
  },
  {
    "text": "scheduler that I built before Livi was available my user can access my cluster manager what spins up my aim our",
    "start": "2656150",
    "end": "2662510"
  },
  {
    "text": "clusters and that's all managed by the I am roles but that user is going to",
    "start": "2662510",
    "end": "2668330"
  },
  {
    "text": "schedule a job to run on the EMR cluster that particular job has to have some iam",
    "start": "2668330",
    "end": "2673730"
  },
  {
    "text": "role as well and so that's that's something that we don't always think about and not only that the job is going",
    "start": "2673730",
    "end": "2680090"
  },
  {
    "text": "to run and that job is going to end up reading or writing to some s3 buckets so so at every stage of the pipeline here",
    "start": "2680090",
    "end": "2689710"
  },
  {
    "text": "we have to employ these permissions the scheduler itself has an iamb role that",
    "start": "2689710",
    "end": "2695300"
  },
  {
    "text": "you know our cluster has an iamb role so every user every service every job should have specific and auditable",
    "start": "2695300",
    "end": "2701210"
  },
  {
    "start": "2697000",
    "end": "2724000"
  },
  {
    "text": "permissions and I really want to check out the new feature that John just mentioned that um RFS fine-grained",
    "start": "2701210",
    "end": "2706310"
  },
  {
    "text": "access control so I'm super excited about that and if I if I want to create my cluster with an iamb role here's how",
    "start": "2706310",
    "end": "2712310"
  },
  {
    "text": "I would do it I would use the service role flag",
    "start": "2712310",
    "end": "2717190"
  },
  {
    "text": "okay so now let's talk about isolating our environments this is kind of how we",
    "start": "2719540",
    "end": "2725030"
  },
  {
    "start": "2724000",
    "end": "2774000"
  },
  {
    "text": "production relies our deployments so let's say you need you've got multi-tenancy you're thinking about",
    "start": "2725030",
    "end": "2730910"
  },
  {
    "text": "deploying different apps for you know different customers and different parts of the world whatever you need multi-tenancy or for us I'm good we're",
    "start": "2730910",
    "end": "2738500"
  },
  {
    "text": "in I'm gonna use the use case of a build and release pipeline EMR is actually part of our pipeline so if I deploy some",
    "start": "2738500",
    "end": "2744920"
  },
  {
    "text": "configuration to the dev environment that's wrong or buggy right I need to check that out can't ease that out of my",
    "start": "2744920",
    "end": "2752510"
  },
  {
    "text": "of my cloud formation or my or my terraform templates before I deploy that to prod",
    "start": "2752510",
    "end": "2757970"
  },
  {
    "text": "so we actually do have a build and release pipeline that includes EMR so how do i how do i set this up how do i",
    "start": "2757970",
    "end": "2764360"
  },
  {
    "text": "explain my environments i'm gonna create a set up of VPC I've got a block of IP",
    "start": "2764360",
    "end": "2769400"
  },
  {
    "text": "addresses that I'm gonna use for all of the services in my environment and I'm going to use subnets so a smaller subset",
    "start": "2769400",
    "end": "2777710"
  },
  {
    "text": "of the of IP addresses allowed in the B PC and this allows me to isolate even",
    "start": "2777710",
    "end": "2783140"
  },
  {
    "text": "the scheduler from the EMR cluster and then I'm also going to use security groups so I'm going to say oh this the",
    "start": "2783140",
    "end": "2789350"
  },
  {
    "text": "the scheduler security group can talk to the EMR cluster only on this port or with my security group I could allow you",
    "start": "2789350",
    "end": "2796970"
  },
  {
    "text": "know from a particular subnet so just you can see lots of layers of isolation",
    "start": "2796970",
    "end": "2802280"
  },
  {
    "text": "here if I want to spin on my a mark cluster here's the flags that I would",
    "start": "2802280",
    "end": "2807980"
  },
  {
    "start": "2805000",
    "end": "2826000"
  },
  {
    "text": "use and if you're interested in security you're probably using the private security groups or I'm sorry the private",
    "start": "2807980",
    "end": "2813710"
  },
  {
    "text": "subnets so just the flags there",
    "start": "2813710",
    "end": "2819099"
  },
  {
    "text": "and this is basically my environment this is what I consider to be my environment and I want to build this in",
    "start": "2820670",
    "end": "2826450"
  },
  {
    "start": "2826000",
    "end": "2880000"
  },
  {
    "text": "dev and staging and canary and prod and you can see all these configurations I",
    "start": "2826450",
    "end": "2832039"
  },
  {
    "text": "need to template eyes this otherwise I'm gonna be making mistakes right so let's",
    "start": "2832039",
    "end": "2837049"
  },
  {
    "text": "go ahead and automate that with CloudFormation or with terraform and also when i want to upgrade EMR or i",
    "start": "2837049",
    "end": "2843559"
  },
  {
    "text": "want to spend up a new cluster I'm gonna essentially use the same provisioning script that I was using already that's",
    "start": "2843559",
    "end": "2848630"
  },
  {
    "text": "in the black boxes that you've seen but also I'm going to do a Bluegreen deployment so I'm my new cluster that I",
    "start": "2848630",
    "end": "2854779"
  },
  {
    "text": "spin up I'm gonna do a DNS up cert so that new jobs are routed to the new cluster and the old jobs kind of play",
    "start": "2854779",
    "end": "2861049"
  },
  {
    "text": "out on the old cluster so that's that's the automation there and it becomes",
    "start": "2861049",
    "end": "2866089"
  },
  {
    "text": "really handy when I want to deploy in multiple different availability zones and multiple different regions you can",
    "start": "2866089",
    "end": "2871130"
  },
  {
    "text": "see why I really need that those template a templated automation so this",
    "start": "2871130",
    "end": "2881630"
  },
  {
    "start": "2880000",
    "end": "2889000"
  },
  {
    "text": "is what we talked about today we talked about monitoring multiple viewpoints using I am roles and isolating",
    "start": "2881630",
    "end": "2887539"
  },
  {
    "text": "environments did we just automate ourselves out of our jobs well no so now",
    "start": "2887539",
    "end": "2893450"
  },
  {
    "start": "2889000",
    "end": "2912000"
  },
  {
    "text": "with all this automation with EMR now I have time to go and explore new projects and grow and really really have a lot of",
    "start": "2893450",
    "end": "2900710"
  },
  {
    "text": "fun in Salesforce so with that I will thank you for all your attentions and John and I will be around for questions",
    "start": "2900710",
    "end": "2906960"
  },
  {
    "text": "[Applause] [Music] [Applause]",
    "start": "2906960",
    "end": "2914530"
  }
]
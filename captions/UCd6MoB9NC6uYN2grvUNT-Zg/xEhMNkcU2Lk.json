[
  {
    "text": "good afternoon everyone thank you for joining to this session it's quite packed it's it's fun so my",
    "start": "1170",
    "end": "8320"
  },
  {
    "text": "name is Roy penalty' first name Roy last name when all time based in New York I'm a business development manager at AWS",
    "start": "8320",
    "end": "16028"
  },
  {
    "text": "I've been with AWS almost three years I started my career in AWS in our",
    "start": "16029",
    "end": "22720"
  },
  {
    "text": "professional service team helping customers to build data analytics or big",
    "start": "22720",
    "end": "28210"
  },
  {
    "text": "data analytics but with different services that most of you are familiar but this is a deep dive session so I'm",
    "start": "28210",
    "end": "36879"
  },
  {
    "text": "going to cover some real time streaming overview talk about a little bit about use cases but the majority of the",
    "start": "36879",
    "end": "44829"
  },
  {
    "text": "content will focus on deep dive on to Amazon Kinesis platform will talk about",
    "start": "44829",
    "end": "51670"
  },
  {
    "text": "streaming data ingestion and streaming processing and will use the time for you to have Q&A so just and check how many",
    "start": "51670",
    "end": "60640"
  },
  {
    "text": "are using Kinesis today in this room okay we have okay great how many are not",
    "start": "60640",
    "end": "66220"
  },
  {
    "text": "using Kinesis yeah how many are using",
    "start": "66220",
    "end": "71620"
  },
  {
    "text": "Kafka okay great so I will try to I'm the reason I'm asking I'm trying to use",
    "start": "71620",
    "end": "77530"
  },
  {
    "text": "the concept in acronym so it'll be familiar but let's start so we'll start",
    "start": "77530",
    "end": "84730"
  },
  {
    "text": "about like four or five years ago when when customers using data analytics",
    "start": "84730",
    "end": "91110"
  },
  {
    "text": "really the trend was about batch processing we build an add up cluster we",
    "start": "91110",
    "end": "96730"
  },
  {
    "text": "ingest data are using scoop bring data from different sources running click stream analytics then after or ETL we",
    "start": "96730",
    "end": "104590"
  },
  {
    "text": "have some nice reporting tool and have the business access there to that reports what happened is that the",
    "start": "104590",
    "end": "111940"
  },
  {
    "text": "business wants to move fast and it's not enough to get how early server logs aggregated and and get some visibility",
    "start": "111940",
    "end": "119830"
  },
  {
    "text": "or insights but you know want to know what happens now you want to build a fraud detection system regardless of",
    "start": "119830",
    "end": "126340"
  },
  {
    "text": "which vertical you're working real time become really the factor of how we want",
    "start": "126340",
    "end": "131860"
  },
  {
    "text": "to move business now in analyze our data set so it's all about really the pace of",
    "start": "131860",
    "end": "138300"
  },
  {
    "text": "processing data and have a really quick response time to our our business",
    "start": "138300",
    "end": "145210"
  },
  {
    "text": "challenges that we have there are three main verticals that we identify and",
    "start": "145210",
    "end": "150270"
  },
  {
    "text": "scenarios that happens across verticals whether is Internet of Things or digital",
    "start": "150270",
    "end": "155740"
  },
  {
    "text": "advertising gaming consumer online and there are three types of scenarios that",
    "start": "155740",
    "end": "161290"
  },
  {
    "text": "are very common across this vertical so the first one is the first column you",
    "start": "161290",
    "end": "166630"
  },
  {
    "text": "see the accelerate target transform load you have streaming data it comes from different sources you batch them and",
    "start": "166630",
    "end": "173410"
  },
  {
    "text": "then you store it on s3 you store it on on HDFS you store it in some persistent storage many of the use cases this is",
    "start": "173410",
    "end": "180820"
  },
  {
    "text": "what customers are doing they're using Kafka they have a consumer and batch it into HDFS or using Kinesis load it",
    "start": "180820",
    "end": "187840"
  },
  {
    "text": "eventually to achieve but before that they store the data on s3 other type of scenarios are really how you continuous",
    "start": "187840",
    "end": "195840"
  },
  {
    "text": "building metrics generation you are in gaming you have a nice gaming you have",
    "start": "195840",
    "end": "201010"
  },
  {
    "text": "many consumers online gaming you want to build a leaderboard or the top 10 players you want to start aggregating in",
    "start": "201010",
    "end": "208209"
  },
  {
    "text": "a near old time manner and show some aggregation so we can look at the IOT you have many devices for it around you",
    "start": "208209",
    "end": "215890"
  },
  {
    "text": "want to start measuring the operations how the device are behaving you might want to do a proactive character",
    "start": "215890",
    "end": "222220"
  },
  {
    "text": "identify trends and the last the last type of scenario is responsive data",
    "start": "222220",
    "end": "228810"
  },
  {
    "text": "analysis which is really the holy grail off of machine learning and all the hyper on data scientist is really okay I",
    "start": "228810",
    "end": "235390"
  },
  {
    "text": "know something is going to happen how can I now have a smart system that build",
    "start": "235390",
    "end": "241120"
  },
  {
    "text": "a recommendation engine you're on the website you add something to the cart can I offer a customer cross sell",
    "start": "241120",
    "end": "247060"
  },
  {
    "text": "another article based on the events and the streaming and and these are getting more and more traction however still the",
    "start": "247060",
    "end": "254260"
  },
  {
    "text": "first one of accelerating gesture arms from load is where many customers are still focusing and that but I will show",
    "start": "254260",
    "end": "261850"
  },
  {
    "text": "you different customers that are using different use cases and this is the only customer deck that you will see you",
    "start": "261850",
    "end": "268479"
  },
  {
    "text": "don't need to take picture of the slides all these reference they're going to be distributed with you for links with the",
    "start": "268479",
    "end": "275949"
  },
  {
    "text": "content around but I'll talk about for example Hearst so the in the morning we had a session with Hearst publishing",
    "start": "275949",
    "end": "282370"
  },
  {
    "text": "where they analyzing 30 terabytes of clickstream data and their business",
    "start": "282370",
    "end": "287440"
  },
  {
    "text": "requirements was to have the time to the time to insight from the time they have 300 plus websites and they're ingesting",
    "start": "287440",
    "end": "295060"
  },
  {
    "text": "different clickstream data from their consumers and readers of their architectures and and magazines and the",
    "start": "295060",
    "end": "301180"
  },
  {
    "text": "business wanted to have visibility under five minutes from the time that anyone is doing something on the website to the",
    "start": "301180",
    "end": "308020"
  },
  {
    "text": "time that their dashboard they're using elastic search that it will be available for their editors",
    "start": "308020",
    "end": "313120"
  },
  {
    "text": "it will be under five minutes so how you take such amount of data with different that every data sets can have different",
    "start": "313120",
    "end": "320139"
  },
  {
    "text": "fields and consume that in a way that the business eventually can take action",
    "start": "320139",
    "end": "325569"
  },
  {
    "text": "and can analyze the data Nordstrom is another customer in the retail space they build or command their",
    "start": "325569",
    "end": "331870"
  },
  {
    "text": "recommendation team build online stylists using Canisius and lambda that means that they have a server less flow",
    "start": "331870",
    "end": "339009"
  },
  {
    "text": "on the website so every time you want to schedule an appointment of a stylist in in their store you use their system and",
    "start": "339009",
    "end": "345789"
  },
  {
    "text": "all the events that based on the questionnaire that you feeling you just pop up and you can schedule an event",
    "start": "345789",
    "end": "352110"
  },
  {
    "text": "saunas in the IOT space they built they run in near real-time streaming",
    "start": "352110",
    "end": "357639"
  },
  {
    "text": "analytics on device data so for the hi-fi audio equipment they are capturing",
    "start": "357639",
    "end": "362650"
  },
  {
    "text": "all the information of course customer needs to opt in to make sure that they can capture the data but they want to",
    "start": "362650",
    "end": "368050"
  },
  {
    "text": "improve the customer experience of how customers are using their products and articles that they are building glue",
    "start": "368050",
    "end": "374979"
  },
  {
    "text": "mobile it in the gaming space as well they're you know they need to ingest",
    "start": "374979",
    "end": "380110"
  },
  {
    "text": "millions of events of from user devices to different mobile devices and they",
    "start": "380110",
    "end": "385150"
  },
  {
    "text": "need to consume the data and analyze it in every single day continuously the",
    "start": "385150",
    "end": "390729"
  },
  {
    "text": "challenges in in streaming data in general for those that you're familiar is is not about the volume it's it's the",
    "start": "390729",
    "end": "396969"
  },
  {
    "text": "variety and velocity this is really the main challenge because data can be in JSON format Avro percale like",
    "start": "396969",
    "end": "404450"
  },
  {
    "text": "different formats that you want to analyze MQTT in the IOT space and also",
    "start": "404450",
    "end": "409640"
  },
  {
    "text": "the velocity sometimes you have 100 fields you have 20 fields and you want to be able to process in a very generic",
    "start": "409640",
    "end": "416360"
  },
  {
    "text": "way every data records that you are ingesting into the streaming processing",
    "start": "416360",
    "end": "423770"
  },
  {
    "text": "so if you're talking about design patterns there are two main processing patterns the first one is I want to have",
    "start": "423770",
    "end": "432920"
  },
  {
    "text": "a real time when I say real time I really meant on the sub second time response time we are not talking about",
    "start": "432920",
    "end": "438860"
  },
  {
    "text": "high frequency trading or one digit milliseconds or nanoseconds but you want to have them the sub seconds response",
    "start": "438860",
    "end": "445580"
  },
  {
    "text": "time when something happened in the system so for example there is a hardware error in your device you want",
    "start": "445580",
    "end": "452450"
  },
  {
    "text": "to immediately to respond the customer to send an email if something you want to do a fraud detection the other one",
    "start": "452450",
    "end": "458780"
  },
  {
    "text": "that is very popular today especially if you're familiar with spark that you can do a micro batch processing it's more in",
    "start": "458780",
    "end": "465140"
  },
  {
    "text": "their near real-time that you can take a small operations running on a small batches of streaming and aggregate show",
    "start": "465140",
    "end": "473150"
  },
  {
    "text": "some aggregation of events that something is happening in your system you can monitor performance LS and",
    "start": "473150",
    "end": "480350"
  },
  {
    "text": "there's some customers that are using it for micro ETL of a lot of streaming data",
    "start": "480350",
    "end": "485990"
  },
  {
    "text": "so these are the main processing patterns we'll get that in the following slides of what's processing tools you",
    "start": "485990",
    "end": "492290"
  },
  {
    "text": "can use with Kinesis streams so for those of you not familiar with Kinesis",
    "start": "492290",
    "end": "497930"
  },
  {
    "text": "so Kinesis was introduced back in 2013 and today the platform offers you free",
    "start": "497930",
    "end": "504800"
  },
  {
    "text": "lines of services two of them are already and general availability and general available and one is going to be",
    "start": "504800",
    "end": "511910"
  },
  {
    "text": "released soon is already in preview we have customers that are playing and I'll go and talk about each one of them so",
    "start": "511910",
    "end": "518599"
  },
  {
    "text": "the first one is the Amazon Kinesis streams it's for engineers if you want to build your custom application that",
    "start": "518600",
    "end": "525290"
  },
  {
    "text": "process is the processing streaming data and analyze it you will use Kinesis",
    "start": "525290",
    "end": "530360"
  },
  {
    "text": "streams I will go and deep dive into Kinesis tree what does it mean for you if you what does it mean to build a consumer",
    "start": "530360",
    "end": "536579"
  },
  {
    "text": "application another service that we launched in reinvent its Amazon Kinesis",
    "start": "536579",
    "end": "541980"
  },
  {
    "text": "fire hose you don't need to be an engineer to use Kinesis fire hose because you don't build any custom",
    "start": "541980",
    "end": "547619"
  },
  {
    "text": "application you go to the console you define delivery stream and today we've",
    "start": "547619",
    "end": "554339"
  },
  {
    "text": "Canisius fire hose is an ingestion process that you can load data ingest streaming data into s3 into Amazon",
    "start": "554339",
    "end": "561449"
  },
  {
    "text": "redshift and as we announced today another endpoint is Amazon elastic search Amazon Kinesis analytics provide",
    "start": "561449",
    "end": "569249"
  },
  {
    "text": "you a way that you can build an application using fully on C sequel so",
    "start": "569249",
    "end": "574379"
  },
  {
    "text": "you can run query on your Kinesis streams and analyze your data based on",
    "start": "574379",
    "end": "579809"
  },
  {
    "text": "splain sequel code you don't need to write a Scala code or spark you will just need to build an application using",
    "start": "579809",
    "end": "585779"
  },
  {
    "text": "sequel I will start with kinases fire hose so we launched a mrs. Farrell in",
    "start": "585779",
    "end": "593670"
  },
  {
    "text": "the last three invent and today we added the new endpoint which is Amazon elastic search we're very excited about that",
    "start": "593670",
    "end": "600569"
  },
  {
    "text": "many customers are using today elastic search with Cubana just to have a dashboard or something that for",
    "start": "600569",
    "end": "606389"
  },
  {
    "text": "customers to start you know searching data on the Kinesis streams so the idea",
    "start": "606389",
    "end": "612059"
  },
  {
    "text": "with Kinesis firehose is that you have a direct to data store the integration for",
    "start": "612059",
    "end": "617309"
  },
  {
    "text": "example if you set up a delivery stream you can say I want to aggregate the data from one megabyte to 128 megabyte you",
    "start": "617309",
    "end": "625769"
  },
  {
    "text": "can define how I want you to encrypt the data you can use kms and land the data on s read encrypted and you can also set",
    "start": "625769",
    "end": "633629"
  },
  {
    "text": "up the compression algorithm we support gzip and lzo compression as of today you",
    "start": "633629",
    "end": "641490"
  },
  {
    "text": "don't need to admin that means that it's scale for you so for example if you have thousands of events per second or you",
    "start": "641490",
    "end": "647279"
  },
  {
    "text": "have 10,000 of events per second that you want to ingest with Kinesis firehose it will seamlessly scale to match your",
    "start": "647279",
    "end": "654209"
  },
  {
    "text": "throughput without really intervention so that's the Kinesis firehose from",
    "start": "654209",
    "end": "659819"
  },
  {
    "text": "destiny the other hand Amazon Kinesis streams for those that are not familiar the idea is that you have",
    "start": "659819",
    "end": "666150"
  },
  {
    "text": "many-to-many relationship you can have multiple producer of kidneys of streaming data and you can have multiple",
    "start": "666150",
    "end": "672570"
  },
  {
    "text": "consumer that consume the data so for example you can have a click stream that",
    "start": "672570",
    "end": "678240"
  },
  {
    "text": "comings from your mobile device or your web pages going into Kinesis streams and you can have multiple application you",
    "start": "678240",
    "end": "685140"
  },
  {
    "text": "can have one application that can aggregate the data store and s3 one application can be a sliding window in",
    "start": "685140",
    "end": "691380"
  },
  {
    "text": "that you wants to have a con a dashboard that shows you in real time all the metrics that you want to capture you can",
    "start": "691380",
    "end": "698760"
  },
  {
    "text": "apply machine learning and each one of the consumer can read data from the",
    "start": "698760",
    "end": "704040"
  },
  {
    "text": "stream without really impact each other that means that the impact only is",
    "start": "704040",
    "end": "710339"
  },
  {
    "text": "regarding the throughput and the way Kinesis stream works we have the concept of shards so if you're familiar with",
    "start": "710339",
    "end": "716850"
  },
  {
    "text": "Kafka in Kafka we have topic in Kinesis we have stream that's a topic we don't have brokers we have charge shard is the",
    "start": "716850",
    "end": "724110"
  },
  {
    "text": "capacity unit of stream so every shard have ingress of 1 megabyte per second or",
    "start": "724110",
    "end": "730529"
  },
  {
    "text": "egress of 2 megabyte per second and according to the fluid that you want to provision depends on how many consumer",
    "start": "730529",
    "end": "737130"
  },
  {
    "text": "you have you will set up how many shards I need in the system now because it's",
    "start": "737130",
    "end": "742740"
  },
  {
    "text": "fully managed service for streaming we don't want you to lose data you don't want to lose data so every data that you",
    "start": "742740",
    "end": "749310"
  },
  {
    "text": "put into Kinesis streams is replicated across free availability zone you have",
    "start": "749310",
    "end": "754529"
  },
  {
    "text": "the application that means that you have the data there and you can also have what we call a replayable function that",
    "start": "754529",
    "end": "762120"
  },
  {
    "text": "you can go into the stream and this is illustration of how it used up until",
    "start": "762120",
    "end": "768270"
  },
  {
    "text": "last year data was storing Canisius only for 24 hours the good news is that you",
    "start": "768270",
    "end": "775470"
  },
  {
    "text": "have the data available for 24 hours the bad news that you have 24 hours to process all your data in Kinesis streams",
    "start": "775470",
    "end": "781310"
  },
  {
    "text": "but sometimes you have one consumer that needs data every one hour sometimes you have a consumer that just need",
    "start": "781310",
    "end": "787670"
  },
  {
    "text": "continuously processing the data you invent we added a new feature that",
    "start": "787670",
    "end": "793170"
  },
  {
    "text": "you have an API that you can do an extended data retention in the Kinesis streams though you can",
    "start": "793170",
    "end": "798630"
  },
  {
    "text": "have it from 24 hours up to seven days you add another two cents per shard hour",
    "start": "798630",
    "end": "804000"
  },
  {
    "text": "when you use that but the good news is also that you can disable it in any given time it's very good if you have a",
    "start": "804000",
    "end": "810540"
  },
  {
    "text": "large-scale event that you need to have processing this amount of data and you think that you might have a backlog so",
    "start": "810540",
    "end": "817110"
  },
  {
    "text": "you can just you know turn on and whenever the data extend more than 24",
    "start": "817110",
    "end": "823110"
  },
  {
    "text": "hours so these are the this is the concept of shards as today we announce",
    "start": "823110",
    "end": "828960"
  },
  {
    "text": "also the approximately timestamp that you have the server time so now you can iterate across the streams based on",
    "start": "828960",
    "end": "836190"
  },
  {
    "text": "timestamp not just sequence which really gives you more flexibility for example I",
    "start": "836190",
    "end": "841740"
  },
  {
    "text": "want to look at data that comes from 7:00 a.m. or 7:30 a.m. based on the",
    "start": "841740",
    "end": "847110"
  },
  {
    "text": "timestamp so it's much more convenience for you how to iterate the notion of",
    "start": "847110",
    "end": "852120"
  },
  {
    "text": "replay so every consumer can go and back in time on the streams and read read eat",
    "start": "852120",
    "end": "858150"
  },
  {
    "text": "are streaming data because every consumer have different pattern it really depends on the use case and we",
    "start": "858150",
    "end": "864990"
  },
  {
    "text": "will go to the deep dive I will share with you like what you want to think about when you design a streaming data",
    "start": "864990",
    "end": "871370"
  },
  {
    "text": "system with consumer very common questions we are getting okay when I",
    "start": "871370",
    "end": "877320"
  },
  {
    "text": "should use Kinesis streams and when we can use Kinesis firehose and the difference are really mainly about how",
    "start": "877320",
    "end": "884100"
  },
  {
    "text": "the consumption of the data should look like so you will use Kinesis streams is",
    "start": "884100",
    "end": "889410"
  },
  {
    "text": "for use case when you're required to have a custom processing and build an application that means that you want to",
    "start": "889410",
    "end": "895320"
  },
  {
    "text": "have a sub-second response time processing the latency and then I want to build so for example we have",
    "start": "895320",
    "end": "900810"
  },
  {
    "text": "customers that are using storm with wave Kinesis or SPARC streaming with Kinesis",
    "start": "900810",
    "end": "906810"
  },
  {
    "text": "you will use kinases for hose only when you can tolerate data latency of like",
    "start": "906810",
    "end": "912390"
  },
  {
    "text": "around 60 seconds or higher and you don't need really to have the sub",
    "start": "912390",
    "end": "917670"
  },
  {
    "text": "seconds processing time but you can use both we have customers that are using Kinesis streams to store all their old",
    "start": "917670",
    "end": "924540"
  },
  {
    "text": "data have the lambda function that is triggered by put event and lambda function can trigger Kinesis firehose",
    "start": "924540",
    "end": "931350"
  },
  {
    "text": "and put to archive into s3 so we start seeing this trend of building a pipeline of",
    "start": "931350",
    "end": "937899"
  },
  {
    "text": "streams and the idea is that you don't really need to manage ec2 instances and",
    "start": "937899",
    "end": "943089"
  },
  {
    "text": "I will talk about lambda in the following slides on the following slide so let's talk about streaming data",
    "start": "943089",
    "end": "950950"
  },
  {
    "text": "ingestion so how you put data into Amazon Kinesis dreams and Kinesis",
    "start": "950950",
    "end": "956260"
  },
  {
    "text": "firehose so one thing you want to remember in Kinesis streams you have the",
    "start": "956260",
    "end": "962380"
  },
  {
    "text": "concept of partition key partition key is actually the you have a partition",
    "start": "962380",
    "end": "968020"
  },
  {
    "text": "hash range that when you land the data into the shards it's based on the shard",
    "start": "968020",
    "end": "973240"
  },
  {
    "text": "range that they can assist you in doing em the md5 hash where the partition key so if you need",
    "start": "973240",
    "end": "979990"
  },
  {
    "text": "high cardinality across your shards that means that you don't really care about ordering and you want to spread it",
    "start": "979990",
    "end": "985000"
  },
  {
    "text": "across all shards just use the random number of partition key make sure that",
    "start": "985000",
    "end": "991450"
  },
  {
    "text": "you provision adequate number of shards let's say that you're you estimated that",
    "start": "991450",
    "end": "997180"
  },
  {
    "text": "you need 10 megabytes per second and 20 megabytes per second out in general you",
    "start": "997180",
    "end": "1003660"
  },
  {
    "text": "can have 10 charge that will give you that throughput we always recommend that you take some Headroom to catch up with",
    "start": "1003660",
    "end": "1010620"
  },
  {
    "text": "data in the streams although you can extend the data retention but let's say that you have an urgent requirements for",
    "start": "1010620",
    "end": "1016770"
  },
  {
    "text": "another unit in your organization and you need to build another system that can consume the data it means that you",
    "start": "1016770",
    "end": "1022290"
  },
  {
    "text": "add another consumer that can run in parallel and processing the same data so you want to have that Headroom although",
    "start": "1022290",
    "end": "1028920"
  },
  {
    "text": "we have tools for you to be able to what we call split or merge charts per your",
    "start": "1028920",
    "end": "1034550"
  },
  {
    "text": "payer needs in order to put data into the Amazon Kinesis so we introduced",
    "start": "1034550",
    "end": "1041730"
  },
  {
    "text": "Amazon Kinesis agent I don't know if you're familiar with it two weeks ago we added support for pre-processing it's an",
    "start": "1041730",
    "end": "1049710"
  },
  {
    "text": "open source available in github the way it works you provision ec2 instance you",
    "start": "1049710",
    "end": "1055200"
  },
  {
    "text": "have an amazon machine image and you can take any log files that you generate and just render and it will this agent will",
    "start": "1055200",
    "end": "1062890"
  },
  {
    "text": "have we act as a listener to the log file and it will stream the data into Kinesis strings or Kinesis firehose",
    "start": "1062890",
    "end": "1069280"
  },
  {
    "text": "using our api other options if you have like collectors that running in your",
    "start": "1069280",
    "end": "1076660"
  },
  {
    "text": "data centers or you're using flume of flow indeed there are connectors to Amazon Kinesis they're also available",
    "start": "1076660",
    "end": "1083799"
  },
  {
    "text": "for you in github as well and you can make tweaks to your existing blogging so if you're using log4j all",
    "start": "1083799",
    "end": "1091210"
  },
  {
    "text": "you do you can take our jar just add it to your log 4j update the property file",
    "start": "1091210",
    "end": "1096610"
  },
  {
    "text": "and everything that you render into the log file will now add to Kenisha stream",
    "start": "1096610",
    "end": "1102040"
  },
  {
    "text": "so you can build your own logging an operation or monitoring Amazon Kinesis",
    "start": "1102040",
    "end": "1107950"
  },
  {
    "text": "producer library it's another option for you to put data into Kinesis streams but",
    "start": "1107950",
    "end": "1115330"
  },
  {
    "text": "it was built for those that have really massive amounts of events that they need",
    "start": "1115330",
    "end": "1121540"
  },
  {
    "text": "to process so you can use Amazon Kinesis produce a library it's an open source it",
    "start": "1121540",
    "end": "1126730"
  },
  {
    "text": "was written in C++ but it has a Java interface you can have it and it",
    "start": "1126730",
    "end": "1133270"
  },
  {
    "text": "aggregates all the records before we put into the Kinesis streams the reason you might want to use it is because when you",
    "start": "1133270",
    "end": "1140799"
  },
  {
    "text": "use Kinesis streams there are two dimension into the pricing one is the",
    "start": "1140799",
    "end": "1146650"
  },
  {
    "text": "shard hour and the other one is the payload you for every million puts you",
    "start": "1146650",
    "end": "1152080"
  },
  {
    "text": "are paying 1.4 cents per million puts however when we are what we're taking we're taking into consideration that",
    "start": "1152080",
    "end": "1158440"
  },
  {
    "text": "every record is 50 kilobytes so let's say that your events are really small like 5 bytes or 1 kilobyte sometimes",
    "start": "1158440",
    "end": "1166000"
  },
  {
    "text": "it's better for you to aggregate before you put into the Kinesis streams that",
    "start": "1166000",
    "end": "1171130"
  },
  {
    "text": "records now the thing is with Canisius producer library you need to run it on on an ec2 instance you need to run it on",
    "start": "1171130",
    "end": "1177880"
  },
  {
    "text": "on a server and machine and then in order to D a granade the records you need to use the Kinesis consumer library",
    "start": "1177880",
    "end": "1185850"
  },
  {
    "text": "we added very recently a supportive lambda so yeah now you have kpl Canisius",
    "start": "1185850",
    "end": "1192580"
  },
  {
    "text": "producer library available with AWS lambda so you can both do both aggregation and",
    "start": "1192580",
    "end": "1198030"
  },
  {
    "text": "D aggregation using lambda without really managing without managing ec2",
    "start": "1198030",
    "end": "1204240"
  },
  {
    "text": "instances which is really makes a lot of headaches go away from from your side one tip is just make sure that you have",
    "start": "1204240",
    "end": "1211410"
  },
  {
    "text": "enough memory because lambda has you know you can pick a different set of",
    "start": "1211410",
    "end": "1216809"
  },
  {
    "text": "memory that for each function when you define them and so you might want to and",
    "start": "1216809",
    "end": "1223320"
  },
  {
    "text": "it's based on the number of records that you really aggregate so for example if you have 1 gigabyte that your aggregate you might get a scenario of out of",
    "start": "1223320",
    "end": "1230130"
  },
  {
    "text": "memory so you want to make sure that you batch it in the right way also Amazon Kinesis producer library",
    "start": "1230130",
    "end": "1236850"
  },
  {
    "text": "provides you a cloud watch matrix that means that you can look at your performance of your put of the records",
    "start": "1236850",
    "end": "1244080"
  },
  {
    "text": "there are several very valuable metrics that you can look at the system and",
    "start": "1244080",
    "end": "1249480"
  },
  {
    "text": "measure it now that's another interesting topic about ordering so the",
    "start": "1249480",
    "end": "1256200"
  },
  {
    "text": "streaming czar order when they insert into Kinesis now the question is if we define the partition ID that is randomly",
    "start": "1256200",
    "end": "1264390"
  },
  {
    "text": "it will be across all shards so if you don't really care about ordering of the data so for example you just want to do",
    "start": "1264390",
    "end": "1270900"
  },
  {
    "text": "a count by something without without really and care about this ordering so",
    "start": "1270900",
    "end": "1276870"
  },
  {
    "text": "you can just randomize the partition key if you want to have the exact order of processing you want to control your",
    "start": "1276870",
    "end": "1283710"
  },
  {
    "text": "partition keys that then you can control the events how they are group into the",
    "start": "1283710",
    "end": "1288990"
  },
  {
    "text": "same shard and when you have the concept of worker and your reading with the shards reading from the Canisius stream",
    "start": "1288990",
    "end": "1295919"
  },
  {
    "text": "based on the partition here from the shards you will have an order I'll get an example I can I can share is that",
    "start": "1295919",
    "end": "1301260"
  },
  {
    "text": "let's say that you have add to cart activity on your ecommerce site and that",
    "start": "1301260",
    "end": "1307470"
  },
  {
    "text": "specific category of sets you want to make sure that that you want to look at",
    "start": "1307470",
    "end": "1312480"
  },
  {
    "text": "this organization like what or what article or what product I added to the e",
    "start": "1312480",
    "end": "1317669"
  },
  {
    "text": "to the cart first so this is for example a way that you will have a partition ID",
    "start": "1317669",
    "end": "1322679"
  },
  {
    "text": "that is based on the business logic of Add to Cart and all these events will",
    "start": "1322679",
    "end": "1328419"
  },
  {
    "text": "should we get into the same partition or age here and then you can process them in norther way if you need both you",
    "start": "1328419",
    "end": "1335049"
  },
  {
    "text": "won't need to build it from your application perspective a global sequence number we have customers that",
    "start": "1335049",
    "end": "1341259"
  },
  {
    "text": "use dynamodb to store that so that's another option for you to store that so",
    "start": "1341259",
    "end": "1348549"
  },
  {
    "text": "we talked about how you scale so sometimes you need more shards sometimes you want to reduce the number of shards",
    "start": "1348549",
    "end": "1355019"
  },
  {
    "text": "you have a tool in github that allows you to split and merge shard this is a",
    "start": "1355019",
    "end": "1362769"
  },
  {
    "text": "Java program you can invoke it programmatically in your system that allows you to split and merge charge so",
    "start": "1362769",
    "end": "1371440"
  },
  {
    "text": "you will split charge if you need more capacity the way it works you run it's",
    "start": "1371440",
    "end": "1376899"
  },
  {
    "text": "based on the con on our code so one of our great solution architects to build that utility so you run it you provide",
    "start": "1376899",
    "end": "1385840"
  },
  {
    "text": "the stream name into that tool and the scaling action so for example you want",
    "start": "1385840",
    "end": "1391059"
  },
  {
    "text": "to scale up scale down or resize you can also provide a percentage of for how",
    "start": "1391059",
    "end": "1397029"
  },
  {
    "text": "much percent you want to add for example like how many charge you want to add in to see more hong-won to shrink so the",
    "start": "1397029",
    "end": "1403119"
  },
  {
    "text": "way it works behind the scene while they are doing it you can still be able to read and write from Kinesis streams you",
    "start": "1403119",
    "end": "1410080"
  },
  {
    "text": "don't need to take the system down or anything it's still running so behind the scenes we distribute the data across",
    "start": "1410080",
    "end": "1416919"
  },
  {
    "text": "the shards but you will still be able to read and write from from the Kinesis streams so let's talk about how you do",
    "start": "1416919",
    "end": "1425259"
  },
  {
    "text": "the streaming processing because really this is eventually okay now we have",
    "start": "1425259",
    "end": "1430600"
  },
  {
    "text": "Kinesis it's managed we take care of all the high availability durability but now",
    "start": "1430600",
    "end": "1436749"
  },
  {
    "text": "ok what I'm doing with streaming data and this is where it becomes really interesting so the first option is to",
    "start": "1436749",
    "end": "1443019"
  },
  {
    "text": "use the Amazon Kinesis library they can Amazon Kinesis client library it's open",
    "start": "1443019",
    "end": "1448480"
  },
  {
    "text": "source it was written in Java but we are using the multi langdon so you can use",
    "start": "1448480",
    "end": "1454989"
  },
  {
    "text": "nodejs Ruby Python dotnet to read data and process data from from",
    "start": "1454989",
    "end": "1462940"
  },
  {
    "text": "your kidneys streams you deploy it on ec2 instances that means that if you need multiple ec2 instances to reach",
    "start": "1462940",
    "end": "1469450"
  },
  {
    "text": "from this time scream you can put it under auto scaling group and that and scale up scale down based on the",
    "start": "1469450",
    "end": "1475660"
  },
  {
    "text": "throughput that you are requiring and there are three components within KCl the first one is the record process",
    "start": "1475660",
    "end": "1483070"
  },
  {
    "text": "Factory that it's a factory that you can create all the interface all the objects of Kinesis record processor and record",
    "start": "1483070",
    "end": "1491290"
  },
  {
    "text": "processor that's really the the business logic that you write to process the data",
    "start": "1491290",
    "end": "1496660"
  },
  {
    "text": "into from from Kinesis streams you have a worker a worker it's actually mapped",
    "start": "1496660",
    "end": "1503470"
  },
  {
    "text": "to an ec2 instance that that's the processing you need that map's to each application instance so for example if",
    "start": "1503470",
    "end": "1509950"
  },
  {
    "text": "you have application one that has a fleet of ec2 instances you have a multiple record processors that are",
    "start": "1509950",
    "end": "1516790"
  },
  {
    "text": "processing the streams of the shards and you can have many of them so one of the",
    "start": "1516790",
    "end": "1522040"
  },
  {
    "text": "scenarios that can happen is that let's say that one of your ec2 instance died one of the worker died you'd still want",
    "start": "1522040",
    "end": "1528700"
  },
  {
    "text": "to be able to recover so what's unique about Kinesis client library it comes",
    "start": "1528700",
    "end": "1534340"
  },
  {
    "text": "with state management processing what we call checkpoint so behind the scene if",
    "start": "1534340",
    "end": "1539800"
  },
  {
    "text": "you if you use that you will see if you go to the console and you look at dynamodb will see a table and usually",
    "start": "1539800",
    "end": "1546400"
  },
  {
    "text": "the table name is the name of the application that you built so one record processor it maps to one",
    "start": "1546400",
    "end": "1553390"
  },
  {
    "text": "shard and it process the data records from the shard so for example you have a",
    "start": "1553390",
    "end": "1558550"
  },
  {
    "text": "mapping in the table you have the name of the shard you have the hash range and you have also the checkpoint like what",
    "start": "1558550",
    "end": "1565390"
  },
  {
    "text": "time so for example let's say that host egg died immediately when a new host will come it will pick up from the table",
    "start": "1565390",
    "end": "1572170"
  },
  {
    "text": "where I should continue to read the processing it also allows you to balance",
    "start": "1572170",
    "end": "1578260"
  },
  {
    "text": "the shard worker that associate with the shards if you're running a split or merge that also updates the that table",
    "start": "1578260",
    "end": "1587800"
  },
  {
    "text": "so you can know where to start or continue to process the record",
    "start": "1587800",
    "end": "1593150"
  },
  {
    "text": "one of the things that we see with customers is sometimes they have issues",
    "start": "1593150",
    "end": "1600270"
  },
  {
    "text": "and the caller's say what happened apparently the name of the table is unique so make sure that you don't give",
    "start": "1600270",
    "end": "1607110"
  },
  {
    "text": "the same application name to if you have different consumers because that can create a problems because it's unique so",
    "start": "1607110",
    "end": "1613320"
  },
  {
    "text": "you have the name of the table is unique for the application ID so other options",
    "start": "1613320",
    "end": "1619470"
  },
  {
    "text": "that you have so you can use third-party connectors we have also connector library so if you're running spunk spunk",
    "start": "1619470",
    "end": "1624870"
  },
  {
    "text": "build the connector to Kinesis with Kinesis we have third-party like queue",
    "start": "1624870",
    "end": "1631740"
  },
  {
    "text": "bill data breaks that also have integration with Kinesis our AWS iot",
    "start": "1631740",
    "end": "1638160"
  },
  {
    "text": "platform as integration for the rule manager there in with a with Kinesis",
    "start": "1638160",
    "end": "1643380"
  },
  {
    "text": "streams and Kinesis firehose I'm going to focus more about lambda and DMR",
    "start": "1643380",
    "end": "1649130"
  },
  {
    "text": "especially with Apache spark I'll show you a demo when we talk about Apache",
    "start": "1649130",
    "end": "1654240"
  },
  {
    "text": "spark but how many are familiar with spark oh great",
    "start": "1654240",
    "end": "1659370"
  },
  {
    "text": "three years ago if I will ask that will not meet so many entry so so spark is is",
    "start": "1659370",
    "end": "1665130"
  },
  {
    "text": "a distributed computing engine that the difference between MapReduce paradigm it's running in memory you have the",
    "start": "1665130",
    "end": "1671429"
  },
  {
    "text": "concept of resilient distributed data with spark so thanks to our friends in",
    "start": "1671429",
    "end": "1676620"
  },
  {
    "text": "data breaks they come up with ASL connector to Kinesis so you can use with spark your spark sequel you have the",
    "start": "1676620",
    "end": "1683400"
  },
  {
    "text": "spark core and you have spark streaming so spark streaming can read directly from Amazon Kinesis streams and you can",
    "start": "1683400",
    "end": "1690179"
  },
  {
    "text": "do a micro batch and processing the data many customers are using it for doing a",
    "start": "1690179",
    "end": "1695460"
  },
  {
    "text": "MicroBot ETL but not only that so think about with the concept of spark when you",
    "start": "1695460",
    "end": "1701490"
  },
  {
    "text": "have data let's say that you have a flat file on s3 and you have data in Kinesis streams you can have two rdd's and do a",
    "start": "1701490",
    "end": "1708360"
  },
  {
    "text": "joint between them you can have spark reading from multiple Kinesis streams as well and join the data within within",
    "start": "1708360",
    "end": "1715169"
  },
  {
    "text": "spark so the way you do it you just go to spark you build it with maven make",
    "start": "1715169",
    "end": "1720870"
  },
  {
    "text": "sure that you're using the latest KCl version because we reading the version as well like if some",
    "start": "1720870",
    "end": "1726830"
  },
  {
    "text": "bug fixes and cetera but make sure that you just update the pom.xml with the",
    "start": "1726830",
    "end": "1732230"
  },
  {
    "text": "latest spark version so a common a common workflow if you are using for",
    "start": "1732230",
    "end": "1738860"
  },
  {
    "text": "example redshift as your data warehouse and you're doing streaming data",
    "start": "1738860",
    "end": "1743870"
  },
  {
    "text": "ingestion with Amazon Kinesis streams and let's say the data the streaming data is really messy it means that you",
    "start": "1743870",
    "end": "1750740"
  },
  {
    "text": "need to do some ETL or building a tumbling window so you can use Apache spark VMR and I'll show a demo how it",
    "start": "1750740",
    "end": "1757970"
  },
  {
    "text": "works and then you can actually directly take the output and copy it into Amazon",
    "start": "1757970",
    "end": "1763850"
  },
  {
    "text": "redshift so some customers like to have the output back to s3 but you have option to copy it also to",
    "start": "1763850",
    "end": "1771080"
  },
  {
    "text": "directly from your mark lustre to Amazon redshift so you can just write the copy",
    "start": "1771080",
    "end": "1777470"
  },
  {
    "text": "command instead of table issue from EMR cluster and just give the cluster ID so",
    "start": "1777470",
    "end": "1782960"
  },
  {
    "text": "that that's a common integration pattern every use case you can build a real-time",
    "start": "1782960",
    "end": "1788240"
  },
  {
    "text": "dashboard of of tumbling window when you want to look at thresholds and cetera so",
    "start": "1788240",
    "end": "1793790"
  },
  {
    "text": "you can do that as well some tips and I just capture some of the recommendation",
    "start": "1793790",
    "end": "1802370"
  },
  {
    "text": "when you use spark streaming if Amazon Kinesis streams we published I think it",
    "start": "1802370",
    "end": "1807740"
  },
  {
    "text": "was months a half ago great post on our big data blog about how you optimize",
    "start": "1807740",
    "end": "1812890"
  },
  {
    "text": "spark streaming with with Ganesha streams there are some configuration around spark executors those are",
    "start": "1812890",
    "end": "1819680"
  },
  {
    "text": "familiar that that you want so and you have the link later on that you can read the entire blog but make sure that you",
    "start": "1819680",
    "end": "1827030"
  },
  {
    "text": "use spark 1.6 plus with VM RFS right now with VM are we support latest for",
    "start": "1827030",
    "end": "1834290"
  },
  {
    "text": "aversion so which one dot 6.1 EMR fans is an e/m RFS provided to have a",
    "start": "1834290",
    "end": "1840920"
  },
  {
    "text": "consistent view option that means that you can look at s3 as an HDFS especially",
    "start": "1840920",
    "end": "1847190"
  },
  {
    "text": "it's important when you want to do is the spark has its own check point it's different than Kinesis check point so to",
    "start": "1847190",
    "end": "1853490"
  },
  {
    "text": "maintain that checkpoint industry of the eventual consistency if s solved that problem that you can",
    "start": "1853490",
    "end": "1860600"
  },
  {
    "text": "really treat as really HDFS and you can do the checkpoint with s3 every time you need to do the checkpointing with spark",
    "start": "1860600",
    "end": "1868330"
  },
  {
    "text": "Amazon DynamoDB table make sure that there is always one instance of your",
    "start": "1868330",
    "end": "1873650"
  },
  {
    "text": "application running with with sparks T streaming especially because of the table names I",
    "start": "1873650",
    "end": "1879320"
  },
  {
    "text": "mentioned so sometimes we have customers that have multiple earmark clusters that",
    "start": "1879320",
    "end": "1884480"
  },
  {
    "text": "they brought up they are running but it didn't change the application name and now they have some some issues with that",
    "start": "1884480",
    "end": "1890710"
  },
  {
    "text": "there is a feature in spark based so you have a configuration you just need to",
    "start": "1890710",
    "end": "1896270"
  },
  {
    "text": "make sure that it's enable another other recommendation or the number of",
    "start": "1896270",
    "end": "1902300"
  },
  {
    "text": "executors you want to have is the number of course per executors so it depends on the ec2 instance that you peek in",
    "start": "1902300",
    "end": "1908990"
  },
  {
    "text": "earmarked so with spark we really love to work with our instance type they are",
    "start": "1908990",
    "end": "1915260"
  },
  {
    "text": "more expensive but they are very memory optimized and very good for spark we met",
    "start": "1915260",
    "end": "1920450"
  },
  {
    "text": "customer today that is using M 3 and H energy to R and they so better performance just because you want to",
    "start": "1920450",
    "end": "1926920"
  },
  {
    "text": "leverage the leverage the memory optimization also make sure that spark",
    "start": "1926920",
    "end": "1935480"
  },
  {
    "text": "streaming is used as default of 1 second with KCl so you can define I'll show you",
    "start": "1935480",
    "end": "1940520"
  },
  {
    "text": "in the demo that you can define 10 seconds so how much it went how much time you want to do the buffering you",
    "start": "1940520",
    "end": "1946190"
  },
  {
    "text": "can do like windowing tumbling every 10 seconds every 5 seconds so the default is 1 second so sometimes you want to",
    "start": "1946190",
    "end": "1952550"
  },
  {
    "text": "change it because in one second you know you have this amount of record truly depends on your producer so I'll",
    "start": "1952550",
    "end": "1959150"
  },
  {
    "text": "show you the demo and and this demo it's it's a record video that's represented in the latest rada the idea is that we",
    "start": "1959150",
    "end": "1965930"
  },
  {
    "text": "build build a simulator that do 20000",
    "start": "1965930",
    "end": "1972170"
  },
  {
    "text": "events per second and it's mimic like a device and temperature and the timestamp",
    "start": "1972170",
    "end": "1977300"
  },
  {
    "text": "and we're using spark streaming to process and then use Zeppelin which is a notebook to process their data so we are",
    "start": "1977300",
    "end": "1986150"
  },
  {
    "text": "building we build with Java simulator so that they start pumping",
    "start": "1986150",
    "end": "1991549"
  },
  {
    "text": "dreams of 20,000 events every second if you go to the Kinesis streams we'll give",
    "start": "1991549",
    "end": "1997220"
  },
  {
    "text": "it the name spark demo but in the console you can look at the cloud watch log so you can look at all the total",
    "start": "1997220",
    "end": "2003789"
  },
  {
    "text": "incoming records and different metrics to see live how many we provision 20 shards for that amounts of data and then",
    "start": "2003789",
    "end": "2011649"
  },
  {
    "text": "we create an EMR cluster when you create the EMR cluster so this is the fourth version you pick up Zeppelin for example",
    "start": "2011649",
    "end": "2019809"
  },
  {
    "text": "if you are not from your visiting is really cool tool for you to interact with data there are many common",
    "start": "2019809",
    "end": "2025389"
  },
  {
    "text": "notebooks like Jupiter but Zeppelin is an open source and now with EMR you can",
    "start": "2025389",
    "end": "2030399"
  },
  {
    "text": "actually launch it from the console so once I create the cluster and set up the",
    "start": "2030399",
    "end": "2036340"
  },
  {
    "text": "number of nodes we can now access from from the console to Zeppelin so we'll go",
    "start": "2036340",
    "end": "2043659"
  },
  {
    "text": "when we go in the customer once it's ready of Zeppelin Link you open the",
    "start": "2043659",
    "end": "2048970"
  },
  {
    "text": "notebook and with the notebook we can now in turn interact with our data that",
    "start": "2048970",
    "end": "2054790"
  },
  {
    "text": "is in Kinesis streams so this is a piece of this code by the way it's available in github we just today put a blog post",
    "start": "2054790",
    "end": "2061780"
  },
  {
    "text": "with all the content so you don't need to follow so here what we do every 10 seconds we pull data from Kinesis",
    "start": "2061780",
    "end": "2068799"
  },
  {
    "text": "streams and we want to build an aggregated real-time windowing and look",
    "start": "2068799",
    "end": "2074049"
  },
  {
    "text": "at the data and how its are being aggregated across to look at the",
    "start": "2074049",
    "end": "2079480"
  },
  {
    "text": "temperature average for all the device per time you can use spark sequel to build that and then Eponine also",
    "start": "2079480",
    "end": "2087339"
  },
  {
    "text": "provides you a visualization that you can look at in in near real time so we build a table and what you can see here",
    "start": "2087339",
    "end": "2093849"
  },
  {
    "text": "is that all the data is being displayed in a real-time aggregating so it's",
    "start": "2093849",
    "end": "2101230"
  },
  {
    "text": "become it's really messy because you're doing twenty thousand of events per second but if you see we run the counts",
    "start": "2101230",
    "end": "2108490"
  },
  {
    "text": "and this is using sparks equal so I can I create a table in sparks equal that",
    "start": "2108490",
    "end": "2114040"
  },
  {
    "text": "actually the data is in Kinesis streams I run it again and the number of records is is increasing so that's that's one",
    "start": "2114040",
    "end": "2122140"
  },
  {
    "text": "option for you to how to interact sparkies very become very common if",
    "start": "2122140",
    "end": "2127670"
  },
  {
    "text": "you're using machine learning library it comes with the n lip so now you can do some like really interesting stuff with",
    "start": "2127670",
    "end": "2133550"
  },
  {
    "text": "that but really it's a very robust data processing engine that you want to use",
    "start": "2133550",
    "end": "2139280"
  },
  {
    "text": "now for those that are not using spark today and still are using pig and hive when you use EMR",
    "start": "2139280",
    "end": "2145370"
  },
  {
    "text": "we build connectors so for example you can use Pig and hive and point to",
    "start": "2145370",
    "end": "2152150"
  },
  {
    "text": "Kinesis streams as well and we have caught samples on our on our website as well the last processing and M pattern",
    "start": "2152150",
    "end": "2160880"
  },
  {
    "text": "and this is really something that become very trendy how many are not familiar with lamda today",
    "start": "2160880",
    "end": "2166960"
  },
  {
    "text": "wow that's great not many so lambda is a compute service that it runs and you",
    "start": "2166960",
    "end": "2173030"
  },
  {
    "text": "don't need to manage ec2 people really like that but the way lambda is its trigger is based on events so there are",
    "start": "2173030",
    "end": "2180500"
  },
  {
    "text": "several events that we're exposing our AWS services so for example put object",
    "start": "2180500",
    "end": "2185660"
  },
  {
    "text": "into s3 delete object to a3 and Kinesis is one of these services that you can",
    "start": "2185660",
    "end": "2191030"
  },
  {
    "text": "really use lambda to trigger that event and process it with kinases so the way",
    "start": "2191030",
    "end": "2198380"
  },
  {
    "text": "it works when you put records into Kinesis streams and lambda function is being triggered of course you need to",
    "start": "2198380",
    "end": "2204710"
  },
  {
    "text": "set up the iron policy and so so forth but the function runs so if you want to",
    "start": "2204710",
    "end": "2210530"
  },
  {
    "text": "build a recommendation engine you want to send an SMS based on something happening the event and you have 5",
    "start": "2210530",
    "end": "2215780"
  },
  {
    "text": "minutes of timeout so that's a lot of time to process something in real time",
    "start": "2215780",
    "end": "2220880"
  },
  {
    "text": "so that's that become very popular today when you want to build a server less",
    "start": "2220880",
    "end": "2226630"
  },
  {
    "text": "chain of streaming processing and you can use both so this is the diagram for",
    "start": "2226630",
    "end": "2232940"
  },
  {
    "text": "one customers of us that using this common architectural pattern that it",
    "start": "2232940",
    "end": "2239330"
  },
  {
    "text": "takes data that comes from mobile from different devices web sites you have Kinesis streams that store all the raw",
    "start": "2239330",
    "end": "2245540"
  },
  {
    "text": "data what you see the site data it's a lambda function that what it does it",
    "start": "2245540",
    "end": "2250550"
  },
  {
    "text": "triggers every record and it's created in to you using Kinesis firehose and it",
    "start": "2250550",
    "end": "2256970"
  },
  {
    "text": "just archives the data into three because they want to make sure that they have archive of all this",
    "start": "2256970",
    "end": "2262790"
  },
  {
    "text": "clickstream data and that flow from Ganesha streams up to s3 through lambda",
    "start": "2262790",
    "end": "2268060"
  },
  {
    "text": "you don't there's zero administration you don't manage any ec2 instance it's like set-and-forget type of flow that",
    "start": "2268060",
    "end": "2275330"
  },
  {
    "text": "you want to set up on the other hand they want to do a micro ETL and that's",
    "start": "2275330",
    "end": "2280430"
  },
  {
    "text": "where you can use apache spark own EMR and have the process data also store in",
    "start": "2280430",
    "end": "2286700"
  },
  {
    "text": "s3 because maybe there is another unit that needs to use that clean data set and cetera so so these patterns of have",
    "start": "2286700",
    "end": "2293810"
  },
  {
    "text": "multiple consumers against the Kinesis streams and leveraging different services this is something that you can",
    "start": "2293810",
    "end": "2300500"
  },
  {
    "text": "orchestrate a streaming pipeline with with AWS using these services so so just",
    "start": "2300500",
    "end": "2308119"
  },
  {
    "text": "for conclusion when you think about using streams first think if you can",
    "start": "2308119",
    "end": "2313670"
  },
  {
    "text": "solve it with lambda that's the first type of choice like if you want to see can I do it without really managing an",
    "start": "2313670",
    "end": "2319940"
  },
  {
    "text": "ec2 if - you're welcome if not go to the other options",
    "start": "2319940",
    "end": "2325010"
  },
  {
    "text": "Amazon Kinesis streams allow you to it provides you a managed service that you don't need if you're using Kafka you",
    "start": "2325010",
    "end": "2332000"
  },
  {
    "text": "don't you don't have the concept of zookeeper and and managing it we're doing it for you that you can focus on",
    "start": "2332000",
    "end": "2338210"
  },
  {
    "text": "continuous processing over the systems if you want to ingest an aggregate data",
    "start": "2338210",
    "end": "2345260"
  },
  {
    "text": "and you have a massive amounts of Records like we are talking about you know millions of events per second or",
    "start": "2345260",
    "end": "2350869"
  },
  {
    "text": "you have like gigabytes per second use Kinesis produce a library that that really the way to do it if the data",
    "start": "2350869",
    "end": "2357800"
  },
  {
    "text": "records is really small if your data record is is one megabyte Kinesis",
    "start": "2357800",
    "end": "2364520"
  },
  {
    "text": "supports up to one megabyte but if you have more than that it's not really streaming data problem like if it every",
    "start": "2364520",
    "end": "2370010"
  },
  {
    "text": "record so this is maybe you need to work in a batch mode process see the data",
    "start": "2370010",
    "end": "2375800"
  },
  {
    "text": "look at our connector library look in our case here look at the ecosystem we",
    "start": "2375800",
    "end": "2380839"
  },
  {
    "text": "have many third party that integrate with Kinesis determine your partition",
    "start": "2380839",
    "end": "2386000"
  },
  {
    "text": "key strategy that's important you need to know ahead of time of how the consuming",
    "start": "2386000",
    "end": "2391330"
  },
  {
    "text": "of the data from Kinesis streams we look like so if you design if you know but if",
    "start": "2391330",
    "end": "2397180"
  },
  {
    "text": "you don't you can start using you know random but but then if you get in the",
    "start": "2397180",
    "end": "2402940"
  },
  {
    "text": "point that you ordering is as important so you might want to fling the logic but sometimes have another Kinney stream so",
    "start": "2402940",
    "end": "2409420"
  },
  {
    "text": "you can have a different condition like you have multiple Kinesis streams that you know for different business units so",
    "start": "2409420",
    "end": "2415330"
  },
  {
    "text": "that's another valid solution I'm sorry so all what I spoke like we don't have a",
    "start": "2415330",
    "end": "2422290"
  },
  {
    "text": "lot of time but it's everything you can find in our technical reference and you will have that text ready to you so we",
    "start": "2422290",
    "end": "2428620"
  },
  {
    "text": "have a long time for Q&A so thank you first though hopefully it was not on",
    "start": "2428620",
    "end": "2434800"
  },
  {
    "text": "fast Thanks so I want to take some",
    "start": "2434800",
    "end": "2442000"
  },
  {
    "text": "questions because this is any questions yes sorry yeah yeah yeah it can go it's",
    "start": "2442000",
    "end": "2455410"
  },
  {
    "text": "there is no free tier for for that service but one shards cost you one point five cents per hour when it runs",
    "start": "2455410",
    "end": "2461770"
  },
  {
    "text": "and but we have some special programs sometimes that you can talk to our",
    "start": "2461770",
    "end": "2466960"
  },
  {
    "text": "company sure but let's say that running tweets like Twitter feeds like for one",
    "start": "2466960",
    "end": "2473920"
  },
  {
    "text": "hours will call you will cost you less than a cup of Starbucks coffee so it's",
    "start": "2473920",
    "end": "2479410"
  },
  {
    "text": "not expensive yes",
    "start": "2479410",
    "end": "2486740"
  },
  {
    "text": "yeah the question from the gentleman was around elasticsearch so Kinesis firehose",
    "start": "2486740",
    "end": "2492420"
  },
  {
    "text": "as an end point now that you can ingest continuously the data into elasticsearch",
    "start": "2492420",
    "end": "2498360"
  },
  {
    "text": "now you can you have the elasticsearch - Kinesis streams connector but you will",
    "start": "2498360",
    "end": "2504240"
  },
  {
    "text": "need to build an ec2 instance that can read it and send it to chemists to elasticsearch with kinases fire hose you",
    "start": "2504240",
    "end": "2510240"
  },
  {
    "text": "don't need to do that all you do is point the endpoint to the document in the elastic search and it will",
    "start": "2510240",
    "end": "2515490"
  },
  {
    "text": "continuously flow the data there sorry so yeah you can use gabbana the Amazon",
    "start": "2515490",
    "end": "2522570"
  },
  {
    "text": "Elastic search when you launch that service you have Cabana link as well and you can launch it from the console yes",
    "start": "2522570",
    "end": "2532160"
  },
  {
    "text": "so my question is so we have this data source as possibly a sequel which is my",
    "start": "2532160",
    "end": "2539490"
  },
  {
    "text": "input to the ETL that we do so is there any way you can produce data streams",
    "start": "2539490",
    "end": "2545420"
  },
  {
    "text": "from the database so yeah it's a it's a good question so the question from and",
    "start": "2545420",
    "end": "2551850"
  },
  {
    "text": "you have you have a database and you want to capture data change event every time you're doing an update or insert so",
    "start": "2551850",
    "end": "2557820"
  },
  {
    "text": "some database have their unlocks that they generate like redo log so you can have an ec2 instance with the agent just",
    "start": "2557820",
    "end": "2565470"
  },
  {
    "text": "listener to the log and you can continuously stream that with Kinesis to Kinesis streams or Kinesis firehose you",
    "start": "2565470",
    "end": "2572220"
  },
  {
    "text": "will need to build a consumer for that event to log it no I want to actually",
    "start": "2572220",
    "end": "2577350"
  },
  {
    "text": "read the data from the tables as soon as they get inserted so you will need to",
    "start": "2577350",
    "end": "2582510"
  },
  {
    "text": "build a trigger in the table itself on RDS sorry if I'm Postgres so we need to",
    "start": "2582510",
    "end": "2588600"
  },
  {
    "text": "have an listener to that table at every time there is event it will add a Kinesis data into Canisius unless there",
    "start": "2588600",
    "end": "2596970"
  },
  {
    "text": "is a open source that does it for you but but you will need to build it or okay or have an agent you can use the",
    "start": "2596970",
    "end": "2603990"
  },
  {
    "text": "agent because every transaction that that you have in I think in Postgres has",
    "start": "2603990",
    "end": "2609960"
  },
  {
    "text": "been written into the like redo log like all the logs of the transaction so if you're using the agent basically you can",
    "start": "2609960",
    "end": "2616980"
  },
  {
    "text": "point to the same log that the database so all the the DLL the read/write updates delete",
    "start": "2616980",
    "end": "2622420"
  },
  {
    "text": "will being grid so also will stream into the kanesha streams I think it thank you",
    "start": "2622420",
    "end": "2630539"
  },
  {
    "text": "yes yes okay missus analytic since in",
    "start": "2630539",
    "end": "2636849"
  },
  {
    "text": "preview you can register from our website if you have Account Manager from AWS you can feel free to send him an",
    "start": "2636849",
    "end": "2644410"
  },
  {
    "text": "email with your account ID and we have we have customers that started to looking at it as well I don't know what",
    "start": "2644410",
    "end": "2652839"
  },
  {
    "text": "about the pricing yet so it's hopefully it will be it will be okay but I don't",
    "start": "2652839",
    "end": "2659230"
  },
  {
    "text": "have the information it's being recorded now I would say okay what okay but but",
    "start": "2659230",
    "end": "2665349"
  },
  {
    "text": "really if you look at Canisius you know in general the the the spending cost from your an entire pipeline it's really",
    "start": "2665349",
    "end": "2671559"
  },
  {
    "text": "minor it's not it's a pay-as-you-go service you don't need like with",
    "start": "2671559",
    "end": "2677109"
  },
  {
    "text": "customers like for example you use Kafka what they do if Kafka you need to have an ec2 any be s running 24/7 and here he",
    "start": "2677109",
    "end": "2684369"
  },
  {
    "text": "just you know limited to one shard or just delete the stream and that's it you don't need to provision that amount of",
    "start": "2684369",
    "end": "2690279"
  },
  {
    "text": "data so we don't want you to manage infrastructure when when you need to",
    "start": "2690279",
    "end": "2695440"
  },
  {
    "text": "deal with stream because stream is complex problem like you know we can start talking about at least once",
    "start": "2695440",
    "end": "2700510"
  },
  {
    "text": "exactly once it's a headache to manage it like especially you don't want to",
    "start": "2700510",
    "end": "2706960"
  },
  {
    "text": "lose data now there are some scenarios that customers really don't care about durability we care like the way we build",
    "start": "2706960",
    "end": "2714039"
  },
  {
    "text": "it we don't want customers to lose the data if you trust us to and we have customers like they're doing like tens",
    "start": "2714039",
    "end": "2722170"
  },
  {
    "text": "billions of events per day and then that's events are cost like these this is money eventually you know they they",
    "start": "2722170",
    "end": "2728589"
  },
  {
    "text": "create their bills their invoice eventually based on these events so you don't want to lose that",
    "start": "2728589",
    "end": "2735328"
  },
  {
    "text": "so so there was the question from from the gentleman is there and maximum limit",
    "start": "2747729",
    "end": "2753079"
  },
  {
    "text": "for Canisius pharaohs so there is no concept of consumers in in committees firehose because you have the",
    "start": "2753079",
    "end": "2759170"
  },
  {
    "text": "destination you can have multiple destination but you will need to have you have soft limits for the number of",
    "start": "2759170",
    "end": "2766459"
  },
  {
    "text": "delivery streams that you want and also the amount so by default we we have five",
    "start": "2766459",
    "end": "2772729"
  },
  {
    "text": "megabytes per second if you need to have more than that just fill your form request the reason we have these soft",
    "start": "2772729",
    "end": "2778309"
  },
  {
    "text": "limits we saw incidents in viral services that you have a data scientist",
    "start": "2778309",
    "end": "2784219"
  },
  {
    "text": "that came in the morning and provision 1000 notes clusters any left home and then you send available say wow it's up",
    "start": "2784219",
    "end": "2790759"
  },
  {
    "text": "and running so we want to have these soft limits to make sure that if you need to increase it you feel a form we",
    "start": "2790759",
    "end": "2796130"
  },
  {
    "text": "talk to you and make sure that you know because we don't want you to pay too much for our services as well so we look",
    "start": "2796130",
    "end": "2801680"
  },
  {
    "text": "up way of optimizing it so for example you know the topic you bought like we had a customer that said yeah we need",
    "start": "2801680",
    "end": "2808809"
  },
  {
    "text": "thousands of Kinesis for our house with thousands of buckets and I say ask why",
    "start": "2808809",
    "end": "2815089"
  },
  {
    "text": "because right now when you set up the destination bucket into Kinesis pharaohs they land into a specific bucket he said",
    "start": "2815089",
    "end": "2822259"
  },
  {
    "text": "no but i want to distribute it into different buckets so said okay let's have a lambda function that is trigger",
    "start": "2822259",
    "end": "2828319"
  },
  {
    "text": "every time the Kinesis pharaohs landed data on s3 now I can have a lambda function that can redistribute the data",
    "start": "2828319",
    "end": "2834349"
  },
  {
    "text": "in our region so we saved him all this work you can do it with lambda so just",
    "start": "2834349",
    "end": "2839569"
  },
  {
    "text": "find the right design pattern for you but hopefully answer the questions yes",
    "start": "2839569",
    "end": "2849758"
  },
  {
    "text": "yeah yeah I mean oh and so we we have",
    "start": "2851310",
    "end": "2873730"
  },
  {
    "text": "like supercell is the clash of titans like one of the number one games is a",
    "start": "2873730",
    "end": "2879580"
  },
  {
    "text": "clash of titans yeah it's it's our is a user of Kinesis and they talk there and",
    "start": "2879580",
    "end": "2885280"
  },
  {
    "text": "you can imagine the amount of throughput and events they have every day so so we",
    "start": "2885280",
    "end": "2891400"
  },
  {
    "text": "are we are we are we want to be part of the journey of these customers to scale when we build Kinesis internally it was",
    "start": "2891400",
    "end": "2899170"
  },
  {
    "text": "the solver on on metering problem so we have a lot of scalability to really",
    "start": "2899170",
    "end": "2906430"
  },
  {
    "text": "support now there are other tools like lumberyard now for gaming and that ecosystem is really involving but and we",
    "start": "2906430",
    "end": "2913330"
  },
  {
    "text": "will skip we will keep innovating on on streams because we really think like when you talk about the big data or",
    "start": "2913330",
    "end": "2919330"
  },
  {
    "text": "landscape yet you have data warehouse your FBI but I think as we move on with",
    "start": "2919330",
    "end": "2925450"
  },
  {
    "text": "the technologies we business really don't care what happened yesterday anymore they take care what happens now",
    "start": "2925450",
    "end": "2931450"
  },
  {
    "text": "and you know the rest is really history it doesn't really promote their business value so this is why we come up with",
    "start": "2931450",
    "end": "2938320"
  },
  {
    "text": "with kinases and analytics one of the talent was what is the common language that analysts are using and its sequel",
    "start": "2938320",
    "end": "2945790"
  },
  {
    "text": "and and running an C sequel and building a custom windowing dashboard running",
    "start": "2945790",
    "end": "2951430"
  },
  {
    "text": "sequel instead of writing it with Python or Java it's much easier to do it with sequel and and we will keep you know",
    "start": "2951430",
    "end": "2957820"
  },
  {
    "text": "doing that because first it's what you are asking from us like we all the features and an additional stuff that we",
    "start": "2957820",
    "end": "2965170"
  },
  {
    "text": "are adding to our ecosystem is based on discussions with customers and and what they asking are for us they want to",
    "start": "2965170",
    "end": "2971830"
  },
  {
    "text": "focus on innovating and building products and not really managing this infrastructure so that's really the",
    "start": "2971830",
    "end": "2978220"
  },
  {
    "text": "motivation behind the managed services",
    "start": "2978220",
    "end": "2982020"
  },
  {
    "text": "yes so I can tell you like for example",
    "start": "2983320",
    "end": "2994840"
  },
  {
    "text": "Hearst they work with tag management colic and seitan the way they did it they implemented JavaScript on all the",
    "start": "2994840",
    "end": "3002970"
  },
  {
    "text": "pages and inciting just took the JavaScript and they use elastic Beanstalk to trigger to do have like",
    "start": "3002970",
    "end": "3010320"
  },
  {
    "text": "serve it as a Kinesis proxy you know the pixel trick that use doing send the get with pixel and you concatenate the",
    "start": "3010320",
    "end": "3016650"
  },
  {
    "text": "entire string what we see now customers are using actually api gateway so you can use api gateway and send a",
    "start": "3016650",
    "end": "3024210"
  },
  {
    "text": "200 response and that api get we can trigger a lambda or can actually use Kinesis to load the data and I think",
    "start": "3024210",
    "end": "3032430"
  },
  {
    "text": "these tag management system will adopt to that so we we have it's made it",
    "start": "3032430",
    "end": "3037620"
  },
  {
    "text": "easier for them to integrate with our API so of course you can use SDK to push",
    "start": "3037620",
    "end": "3043860"
  },
  {
    "text": "data and put like everything in AWS you have API but we'll make it easier for",
    "start": "3043860",
    "end": "3049020"
  },
  {
    "text": "them using API get to because so that hopefully it answer your questions but",
    "start": "3049020",
    "end": "3054230"
  },
  {
    "text": "they are building like I'm working with other vendors now on they want to build",
    "start": "3054230",
    "end": "3059730"
  },
  {
    "text": "a connector so",
    "start": "3059730",
    "end": "3062780"
  },
  {
    "text": "yeah so you're talking about mourn the network streaming like packet inspection so these are use is the it's really",
    "start": "3084570",
    "end": "3092500"
  },
  {
    "text": "depends on the latency right now to be honest our propagation delay makini streams we are on 300 400 milliseconds",
    "start": "3092500",
    "end": "3100150"
  },
  {
    "text": "response time Green latency from put to get if you need the two-digit one digit you know these dark driver solutions",
    "start": "3100150",
    "end": "3107560"
  },
  {
    "text": "today we want to drive it down I'm not sure that will drive into the one milliseconds or the nanoseconds that's",
    "start": "3107560",
    "end": "3114550"
  },
  {
    "text": "that's a different business to be in because then you need to really work on the sometimes on the burn metal of the",
    "start": "3114550",
    "end": "3120790"
  },
  {
    "text": "network piece but for for really the sub seconds that's definitely many of the use case",
    "start": "3120790",
    "end": "3127600"
  },
  {
    "text": "can be filled so I would love to heard to you more about the use case like there I don't know if you know Apache",
    "start": "3127600",
    "end": "3133120"
  },
  {
    "text": "epics and things that you can have the ones digit of milliseconds sometimes so",
    "start": "3133120",
    "end": "3138540"
  },
  {
    "text": "but we just want to be open this is where we are now but we want to drive it the latency lower lower yes",
    "start": "3138540",
    "end": "3149100"
  },
  {
    "text": "right right now it's a hard limit and we",
    "start": "3153540",
    "end": "3158890"
  },
  {
    "text": "are we are thinking to increase it it's something that is on the roadmap right now it's a hard limit um there are",
    "start": "3158890",
    "end": "3165160"
  },
  {
    "text": "several reasons for doing that but just add more shards but we are going like",
    "start": "3165160",
    "end": "3170530"
  },
  {
    "text": "it's it's something on the roadmap like it's a understand where you're coming from because when you have multiple consumers you just want to have the",
    "start": "3170530",
    "end": "3176620"
  },
  {
    "text": "latency you don't want to pay more but but yeah right now it's a hard limit",
    "start": "3176620",
    "end": "3182820"
  },
  {
    "text": "right yeah so so sometimes like what they do like use sqs for example and",
    "start": "3186450",
    "end": "3193540"
  },
  {
    "text": "when you need to mess it and that's the difference between Q and n streaming like different use case but but we see",
    "start": "3193540",
    "end": "3199000"
  },
  {
    "text": "this type yeah thanks thanks for the the comment anything else guys thank you",
    "start": "3199000",
    "end": "3211540"
  },
  {
    "text": "very much for joining me like in the gay they how fully you enjoyed and learn and",
    "start": "3211540",
    "end": "3217450"
  },
  {
    "text": "I'm here if you want to ask me question offline thank you very much again",
    "start": "3217450",
    "end": "3222900"
  }
]
[
  {
    "start": "0",
    "end": "68000"
  },
  {
    "text": "appreciate you taking the time uh at the last minute to fit this change into your schedule uh we had a lot of folks that",
    "start": "3120",
    "end": "10880"
  },
  {
    "text": "were interested in this talk the first time so I'm excited uh to be able to share with you what they saw uh and",
    "start": "10880",
    "end": "17439"
  },
  {
    "text": "hopefully you take away from it the same value that they did this is uh a talk about how to extract the maximum amount",
    "start": "17439",
    "end": "24519"
  },
  {
    "text": "of performance from combination of ec2 and AWS wait one more minute all right",
    "start": "24519",
    "end": "32200"
  },
  {
    "text": "everybody check your email",
    "start": "32200",
    "end": "36640"
  },
  {
    "text": "now stop and we can collaborate and listen",
    "start": "62600",
    "end": "68680"
  },
  {
    "start": "68000",
    "end": "146000"
  },
  {
    "text": "so uh maybe to start this thing probably the easiest way to describe what we're",
    "start": "68680",
    "end": "74119"
  },
  {
    "text": "going to talk about today uh is the fact that the elastic Block store Service uh",
    "start": "74119",
    "end": "80640"
  },
  {
    "text": "in no part of those three words which are interesting uh does it say discs or",
    "start": "80640",
    "end": "86000"
  },
  {
    "text": "solid state discs or flash drives or zero and one automagic devices powered",
    "start": "86000",
    "end": "91680"
  },
  {
    "text": "by hamsters or anything weird like that elastic Block store is a service uh a restful web service for us that allows",
    "start": "91680",
    "end": "98600"
  },
  {
    "text": "you to provision storage that connects to the ec2 back flame that",
    "start": "98600",
    "end": "105360"
  },
  {
    "text": "service exposes a set of behaviors and those behaviors are different than the behaviors of physical devices so a lot",
    "start": "105360",
    "end": "112520"
  },
  {
    "text": "of what we're going to talk about today are the mechanics of that difference uh",
    "start": "112520",
    "end": "117680"
  },
  {
    "text": "most of the folks that I talk to that work in storage we've gotten really good at understanding the behavior of the",
    "start": "117680",
    "end": "124079"
  },
  {
    "text": "physical devices that we've been using for many many years to store data and in a lot of ways those can give you some",
    "start": "124079",
    "end": "130360"
  },
  {
    "text": "bad preconceived notions hopefully today disabuses you of some bad assumptions",
    "start": "130360",
    "end": "135800"
  },
  {
    "text": "about the way storage should be used in AWS and gives you some new baselines and",
    "start": "135800",
    "end": "140840"
  },
  {
    "text": "new tools to establish the highest performance patterns for deployment across a pretty broad range of workloads",
    "start": "140840",
    "end": "148480"
  },
  {
    "text": "so if storage has changed if we've done a lot to change the way that storage behaves what hasn't changed is the",
    "start": "148480",
    "end": "154519"
  },
  {
    "text": "workloads you're trying to run storage on so there are a lot of folks running relational databases on AWS not the",
    "start": "154519",
    "end": "161159"
  },
  {
    "text": "least of which uh includes our managed service which consumes the same resources you have access to are no SQL",
    "start": "161159",
    "end": "167840"
  },
  {
    "text": "databases across all sorts of open and closed source application layers all consume storage at an incredible rate",
    "start": "167840",
    "end": "173920"
  },
  {
    "text": "data warehouses file sharing file stores media systems all of those require access to a file system rather than an",
    "start": "173920",
    "end": "180239"
  },
  {
    "text": "object store and as a result need to be implemented on some kind of block",
    "start": "180239",
    "end": "186040"
  },
  {
    "text": "storage service we have one of those and we're going to talk through the mechanics of making your workload work",
    "start": "186040",
    "end": "192599"
  },
  {
    "text": "fastest on AWS so I am willing to bet given the fact",
    "start": "192599",
    "end": "198440"
  },
  {
    "text": "that you paid $1,300 to sit in this chair or if you are the winner of the cloud OSS prize how about no",
    "start": "198440",
    "end": "204680"
  },
  {
    "text": "dollar that you know the definitions of these things but to set a level to set a basis",
    "start": "204680",
    "end": "210519"
  },
  {
    "text": "uh IO operations are the individual transits of data to and from a storage",
    "start": "210519",
    "end": "215640"
  },
  {
    "text": "device we measure those typically in the number of them we can get done per second hence",
    "start": "215640",
    "end": "220879"
  },
  {
    "text": "iops throughput is the total aggregate of the data we've moved since each IO",
    "start": "220879",
    "end": "227159"
  },
  {
    "text": "can happen at a different size we also want to be able to measure the megabytes per second or gigabytes per second of",
    "start": "227159",
    "end": "232560"
  },
  {
    "text": "throughput that we can deliver that throughput happens over some kind of connection and so since the",
    "start": "232560",
    "end": "239760"
  },
  {
    "text": "contion exists there's an amount of latency the delay between you when you've asked for a piece of data and you",
    "start": "239760",
    "end": "245000"
  },
  {
    "text": "get it or when you write a piece of data and get a response that it's been written we measure storage and capacity",
    "start": "245000",
    "end": "251640"
  },
  {
    "text": "typically in gigabytes uh and and a lot of the talk today will be mostly around the first",
    "start": "251640",
    "end": "256959"
  },
  {
    "text": "three and this bottom one block size how did different applications interact with our storage back end at different",
    "start": "256959",
    "end": "262720"
  },
  {
    "text": "average block sizes and how can you optimize implementations to take advantage of",
    "start": "262720",
    "end": "268120"
  },
  {
    "start": "268000",
    "end": "343000"
  },
  {
    "text": "that so the interesting bit uh you can also order hard drives from Amazon uh",
    "start": "268120",
    "end": "274600"
  },
  {
    "text": "they just don't come by way of a rest interface uh and if you look at the back",
    "start": "274600",
    "end": "279759"
  },
  {
    "text": "of the box you get all of these physical characteristics mechanical characteristics there are this many",
    "start": "279759",
    "end": "286600"
  },
  {
    "text": "spindles and inside of those spindles there is this head sector density and",
    "start": "286600",
    "end": "293120"
  },
  {
    "text": "the aial density constructs a net number of gigabytes and there's a rotational rate of the drive media and all of these",
    "start": "293120",
    "end": "299400"
  },
  {
    "text": "numb many of them you have likely done the calculus on to compute the number of say",
    "start": "299400",
    "end": "305960"
  },
  {
    "text": "iops or the number of megabytes a second for sequential reads or other things that you can expect from this device",
    "start": "305960",
    "end": "311280"
  },
  {
    "text": "that skills one of those things that differentiates the folks that have the crappy slow dat bases versus the super",
    "start": "311280",
    "end": "317080"
  },
  {
    "text": "awesome fast ones conveniently Amazon has the ability to do that math as well",
    "start": "317080",
    "end": "322759"
  },
  {
    "text": "and has built services that make it so that you don't have to uh the block storage services from Amazon generate",
    "start": "322759",
    "end": "330280"
  },
  {
    "text": "those values directly and can be provisioned by you to an exact speed so provision doops allows you to provision",
    "start": "330280",
    "end": "336840"
  },
  {
    "text": "anywhere from 10 to 4,000 iops per EBS",
    "start": "336840",
    "end": "342600"
  },
  {
    "text": "volume and you can do that at a ratio of all the way from a terabyte at 4,000",
    "start": "342600",
    "end": "347919"
  },
  {
    "text": "iops or a terabyte at 10 iops if you really don't want to move the data back and forth down to a minimum ratio of 1 to 30",
    "start": "347919",
    "end": "356360"
  },
  {
    "text": "which uh gets you to around 134 gbt for for the 4,000 I volume that'd be the",
    "start": "356360",
    "end": "361479"
  },
  {
    "text": "smallest possible size that lines up kind of interestingly with those old 15,000 RPM discs we",
    "start": "361479",
    "end": "367680"
  },
  {
    "text": "thought that was a pretty good number so because you have the ability to dial exactly the number of iops that you need",
    "start": "367680",
    "end": "374520"
  },
  {
    "text": "for a given workload you aren't limited to the building block of physical devices once you buy a hard drive say it",
    "start": "374520",
    "end": "381039"
  },
  {
    "text": "can do 200 iops if you want to do 202 you need two hard drives with provision",
    "start": "381039",
    "end": "386960"
  },
  {
    "text": "iops you just change the number from 200 to 202 two and you're Off to the Races constructing these happens by way of our",
    "start": "386960",
    "end": "394440"
  },
  {
    "text": "CLI our restful interfaces our online user interfaces and potentially third",
    "start": "394440",
    "end": "399599"
  },
  {
    "text": "party applications that you have that sit on top of us provision iops is one system from us there's also another the",
    "start": "399599",
    "end": "406520"
  },
  {
    "start": "402000",
    "end": "610000"
  },
  {
    "text": "original EBS called EBS standard EBS standard and EBS provision iops are",
    "start": "406520",
    "end": "412280"
  },
  {
    "text": "substantially different infrastructures they're not built the same way they have different software we",
    "start": "412280",
    "end": "419599"
  },
  {
    "text": "wrestled with the concept of even calling provision iops a different product from standard EBS so recognize",
    "start": "419599",
    "end": "426720"
  },
  {
    "text": "that even if you did an amazing amount of testing on the behavior of standard evbs that that doesn't have anything to",
    "start": "426720",
    "end": "433800"
  },
  {
    "text": "do with the behavior of provision doops EBS in the same way that the performance",
    "start": "433800",
    "end": "438919"
  },
  {
    "text": "of your RAM is different than the performance of your network so how does",
    "start": "438919",
    "end": "444000"
  },
  {
    "text": "standard EBS work standard EBS provides uh 100 IOP steady state with best effort",
    "start": "444000",
    "end": "450199"
  },
  {
    "text": "bursts to low like a th000 1,20 1100 14400 maybe 700 all of that happens on a",
    "start": "450199",
    "end": "458520"
  },
  {
    "text": "best effort basis and is not something that you provision or configure and as a result there's a pretty significant",
    "start": "458520",
    "end": "463840"
  },
  {
    "text": "amount of variability of that performance you'll also observe behaviors where short-term bursts of",
    "start": "463840",
    "end": "470639"
  },
  {
    "text": "work are accepted by the standard EBS system pretty well U but then steady",
    "start": "470639",
    "end": "475680"
  },
  {
    "text": "state workloads will return to this wall rate of about a 100 I on a steady state basis",
    "start": "475680",
    "end": "482800"
  },
  {
    "text": "EBS does have as a result of that a a variable throughput just because you can",
    "start": "482800",
    "end": "489159"
  },
  {
    "text": "uh move an IO to a disc doesn't mean necessarily that you can move every bit but in general standard EBS moves and is",
    "start": "489159",
    "end": "495919"
  },
  {
    "text": "capable of slightly higher throughputs per IO than provisioned I and we'll go into what that means in a second",
    "start": "495919",
    "end": "502759"
  },
  {
    "text": "latencies for EBS standard uh range in the sort of 20 millisecond range uh for",
    "start": "502759",
    "end": "509599"
  },
  {
    "text": "reads with wrs faster than that and that's kind of an interesting detail at somewhere in the range of 10",
    "start": "509599",
    "end": "515200"
  },
  {
    "text": "milliseconds but again latency and total iops throughput are best effort on EVS",
    "start": "515200",
    "end": "521760"
  },
  {
    "text": "contrast that with provisioned iops so with provisioned iops uh you get within 10% of what you provision up to 4,000",
    "start": "521760",
    "end": "528080"
  },
  {
    "text": "iops 99.9% of a given year as provisioned so that means for a couple",
    "start": "528080",
    "end": "533399"
  },
  {
    "text": "of minutes out of the year you might see it go down below 3600 or so",
    "start": "533399",
    "end": "540640"
  },
  {
    "text": "if it goes to 3400 or something that's a ticket you file to us and say this one's",
    "start": "540640",
    "end": "546399"
  },
  {
    "text": "messed up you guys are doing a bad job throughput on provision doops uh",
    "start": "546399",
    "end": "553040"
  },
  {
    "text": "happens in 16k blocks and that's a really important number as a service rather than a physical device that's a",
    "start": "553040",
    "end": "559040"
  },
  {
    "text": "throttle that's a system that we've used to constrain the performance that you receive that also allows us to maintain",
    "start": "559040",
    "end": "565800"
  },
  {
    "text": "the consistency that you see so different than a physical device that isn't operating in a throttled managed",
    "start": "565800",
    "end": "572720"
  },
  {
    "text": "way this device will deliver what you provision in in an incredibly consistent",
    "start": "572720",
    "end": "577800"
  },
  {
    "text": "way so you also have a requirement around Q depth so we'll talk a lot about",
    "start": "577800",
    "end": "583760"
  },
  {
    "text": "Q depth and how that works uh with standard provision iops EBS you'll see latencies that are much much lower than",
    "start": "583760",
    "end": "591360"
  },
  {
    "text": "standard EBS uh you easy rule of thumb is that that starts in the range of the",
    "start": "591360",
    "end": "596760"
  },
  {
    "text": "number of iops you've provisioned take a second and divide it by that so if you have a th I up volume that' be in the",
    "start": "596760",
    "end": "603120"
  },
  {
    "text": "millisecond range if you have a 4,000 I up volume you could be as low as quarter milliseconds which is pretty",
    "start": "603120",
    "end": "610160"
  },
  {
    "text": "spectacular so the general thing that you'll take away from this you're going to hear me say a lot about these two",
    "start": "610160",
    "end": "615800"
  },
  {
    "text": "products please use provision iOS and EBS optimized for your databases",
    "start": "615800",
    "end": "621240"
  },
  {
    "text": "standard EBS was not designed for those work clads standard EBS is a root volume service designed to allow ec2 to start",
    "start": "621240",
    "end": "628240"
  },
  {
    "text": "and stop instances and so the characteristics the behavior of that disc they all line up with what you'd",
    "start": "628240",
    "end": "633640"
  },
  {
    "text": "need for a good instance booting service you'd like you'd like the ability to do",
    "start": "633640",
    "end": "639000"
  },
  {
    "text": "bursts of Rights like you'd do to swap memory on a VM you want to be able to provision it rapidly and you want low",
    "start": "639000",
    "end": "644760"
  },
  {
    "text": "cost because typically the root volume on your average computer doesn't get worked that hard very often now",
    "start": "644760",
    "end": "650480"
  },
  {
    "text": "provision diaps is built the different it's built specifically to be worked as hard as possible for years on end at",
    "start": "650480",
    "end": "657440"
  },
  {
    "text": "maximum throughput so we'll talk through why those two are so different so you also might have noticed I'll go back a",
    "start": "657440",
    "end": "663880"
  },
  {
    "text": "couple there are asterisks on this slide and I don't like those any more than you like the little asteris on how much",
    "start": "663880",
    "end": "671720"
  },
  {
    "text": "sugar is in your cereal or uh how fast it is that you're going to burn through your network bandwidth on your uh mobile",
    "start": "671720",
    "end": "677920"
  },
  {
    "text": "phone so the asterisks are for a reason let's think about the building blocks",
    "start": "677920",
    "end": "683800"
  },
  {
    "text": "that are a part of the system that makes up the ability to store rights so you",
    "start": "683800",
    "end": "689839"
  },
  {
    "text": "have an ec2 instance you have the network connection between the ec2 instance and the storage service and you",
    "start": "689839",
    "end": "697079"
  },
  {
    "text": "have the individual iops that make up that connection so you can think of at",
    "start": "697079",
    "end": "702320"
  },
  {
    "text": "any given speed that there's a certain finite number of slots so say you had a",
    "start": "702320",
    "end": "709160"
  },
  {
    "text": "provisioned IOP volume provisioned at 10 iops that means you have 10 opportunities to do work if you don't",
    "start": "709160",
    "end": "716160"
  },
  {
    "text": "take one of those opportunities you lose it we don't give them back to you it's not a bursty service we meter at a very",
    "start": "716160",
    "end": "722760"
  },
  {
    "text": "fine grain so what happens when you write a big IO a 32k or a 64 K IO that",
    "start": "722760",
    "end": "729240"
  },
  {
    "text": "consumes multiple of your opportunities to write to storage it consumes more",
    "start": "729240",
    "end": "734600"
  },
  {
    "text": "throughput over the network and so if you run out of bandwidth on your",
    "start": "734600",
    "end": "739760"
  },
  {
    "text": "connection you may see throttled rights independent of the provision iops or standard ebs's ability to take those",
    "start": "739760",
    "end": "745160"
  },
  {
    "text": "rights we'll talk through the Mechanics for that you might also Al write much smaller iOS than that if you're on a an",
    "start": "745160",
    "end": "752639"
  },
  {
    "text": "Oracle database configured at 2K rights or you're on a mongodb database that's got 4K rights for small operations you",
    "start": "752639",
    "end": "759959"
  },
  {
    "text": "don't get any bonus additional magic random ios's where you provision 4,000",
    "start": "759959",
    "end": "766000"
  },
  {
    "text": "you get 4,000 out of the device that's the way that it works even if you don't fill each of those opportunities to do",
    "start": "766000",
    "end": "771240"
  },
  {
    "text": "work uh it's that's not something that we give as extra so you also have this concept of Q",
    "start": "771240",
    "end": "778160"
  },
  {
    "text": "depth if you don't have enough work in the queue of work to storage and you",
    "start": "778160",
    "end": "783720"
  },
  {
    "text": "miss one of those opportunities to write to disk we don't give it back to you so you need to maintain enough Q depth to",
    "start": "783720",
    "end": "791320"
  },
  {
    "text": "keep the storage interface loaded you also can't overload the Q depth if you",
    "start": "791320",
    "end": "797800"
  },
  {
    "text": "have so many rights waiting in line you can cause latency that exceeds basic",
    "start": "797800",
    "end": "803959"
  },
  {
    "text": "buffers at the operating system tier or the networking tier and as a result nonlinearly increase latency that's a",
    "start": "803959",
    "end": "810920"
  },
  {
    "text": "problem we'll talk about what that looks like so so how to go faster how do how do we make this better um so let's say",
    "start": "810920",
    "end": "818680"
  },
  {
    "text": "if you just add more provisioned iops when you are already saturating the network connection or saturating the uh",
    "start": "818680",
    "end": "824720"
  },
  {
    "text": "performance of the ec2 instance more volumes won't help it doesn't make it go any faster you can hook up 500 provision",
    "start": "824720",
    "end": "832560"
  },
  {
    "text": "doops volumes at 1,000 iops a piece to an M1 small and by gum you'll not get much more done uh you",
    "start": "832560",
    "end": "839959"
  },
  {
    "text": "also could uh uh could not have enough provision DS for a given workload right so it is possible for the storage",
    "start": "839959",
    "end": "846240"
  },
  {
    "start": "841000",
    "end": "1017000"
  },
  {
    "text": "subsystem to be limiting your total throughput capacity and if it's underprovision you'll see a bloom of Q",
    "start": "846240",
    "end": "852839"
  },
  {
    "text": "depth and as a result a an increase in the latency of each of your individual rights you also could radically over",
    "start": "852839",
    "end": "860360"
  },
  {
    "text": "provision the ec2 side in comparison to the provision IOP side and not see any benefit you get this big honken machine",
    "start": "860360",
    "end": "866680"
  },
  {
    "text": "and you've got a seven iops volume not going to get a lot of work done so what's the the right thing for any given",
    "start": "866680",
    "end": "872839"
  },
  {
    "text": "workload is to make the combination of these three resources combined in a uniform efficient style a way to think",
    "start": "872839",
    "end": "879959"
  },
  {
    "text": "about this is you take the motor from a Honda Civic and you put it in a diesel",
    "start": "879959",
    "end": "885320"
  },
  {
    "text": "train and you take the motor from a diesel train and you put it in a Honda Civic neither of those Vehicles is going",
    "start": "885320",
    "end": "892040"
  },
  {
    "text": "anywhere quickly you really want the right parts in the right places so building patterns of infrastructure",
    "start": "892040",
    "end": "899600"
  },
  {
    "text": "that are balanced is the way to efficiently extract value from our systems and have oh yeah with your",
    "start": "899600",
    "end": "906839"
  },
  {
    "text": "asterisks so uh architecting perform performance how do you know what",
    "start": "906839",
    "end": "912360"
  },
  {
    "text": "balanced looks like so we haven't published this stuff yet this is brand new so welcome to one of those benefits",
    "start": "912360",
    "end": "918480"
  },
  {
    "text": "of the 1300 bucks uh we are uh we are working on formalized",
    "start": "918480",
    "end": "925199"
  },
  {
    "text": "publication of the exact performance throughput to to EBS for every instance",
    "start": "925199",
    "end": "931120"
  },
  {
    "text": "type this is a preview of that guidance so we are we are now showing a couple of",
    "start": "931120",
    "end": "937800"
  },
  {
    "text": "interesting things one um the relatively low amount of network bandwidth that exists between Smalls size instances and",
    "start": "937800",
    "end": "945000"
  },
  {
    "text": "the EBS system gives you better guidance as to what the right expectation is",
    "start": "945000",
    "end": "950800"
  },
  {
    "text": "we're also showing and it's a place that I really want you to squint and look at how much faster the cluster instances",
    "start": "950800",
    "end": "958079"
  },
  {
    "text": "are and everything else so that's cc2 CC1 cg1 the new i2s the high4 XLS the",
    "start": "958079",
    "end": "965759"
  },
  {
    "text": "hs1 8xl all of those instances are on the cluster compute Network 10 gabit",
    "start": "965759",
    "end": "971279"
  },
  {
    "text": "full bsection non blocking zero over subscription U monster network is what",
    "start": "971279",
    "end": "976720"
  },
  {
    "text": "we call it sometimes uh and that is not linear in relationship to cost so if an",
    "start": "976720",
    "end": "983000"
  },
  {
    "text": "M2 4XL is a dollar something an hour and a cc2 8xl is less than than a dollar",
    "start": "983000",
    "end": "989399"
  },
  {
    "text": "something an hour if it's maybe twice as expensive it's roughly eight times faster to dis so if you're able to",
    "start": "989399",
    "end": "997319"
  },
  {
    "text": "consume these larger instance types you're able to get pretty nonlinear benefits around storage performance and",
    "start": "997319",
    "end": "1003440"
  },
  {
    "text": "all of the numbers on the left are built around the assumption that your application is writing 16 CL 16k blocks",
    "start": "1003440",
    "end": "1010040"
  },
  {
    "text": "so if you're writing smaller block operations you can drive larger IOP counts we'll talk about the Mechanics",
    "start": "1010040",
    "end": "1015639"
  },
  {
    "text": "for that so places where that guidance starts to look funny uh is when you",
    "start": "1015639",
    "end": "1021120"
  },
  {
    "start": "1017000",
    "end": "1183000"
  },
  {
    "text": "don't have EBS optimized so the EBS optimized provides a totally different",
    "start": "1021120",
    "end": "1026640"
  },
  {
    "text": "network fabric for interaction with storage so the the red line at the bottom where it says with network load",
    "start": "1026640",
    "end": "1032918"
  },
  {
    "text": "test that's us writing 200 megabits a second of really awful random traffic",
    "start": "1032919",
    "end": "1039160"
  },
  {
    "text": "over Network to this instance the no network load is no network load so if you run this workload on EBS optimized",
    "start": "1039160",
    "end": "1047760"
  },
  {
    "text": "you see totally linear performance because we have a separate Network channel to EBS there isn't contention",
    "start": "1047760",
    "end": "1055919"
  },
  {
    "text": "between the network operations to the internet to other instances for replication uh to other AWS services and",
    "start": "1055919",
    "end": "1063240"
  },
  {
    "text": "your interaction with EBS if you run this same test without that little check",
    "start": "1063240",
    "end": "1068799"
  },
  {
    "text": "box I can tell you the numbers are worse and they're kind of catastrophically worse it's really important if you",
    "start": "1068799",
    "end": "1075480"
  },
  {
    "text": "intend to fully utilize any use of provision iOS that you have EBS",
    "start": "1075480",
    "end": "1080679"
  },
  {
    "text": "optimized turned on in fact if you go and look at trusted advisor a couple of days ago we added a check and that check",
    "start": "1080679",
    "end": "1087919"
  },
  {
    "text": "says you have provisioned IOS volumes and they're hooked up to instances that do not have EBS optimized turned on I",
    "start": "1087919",
    "end": "1094240"
  },
  {
    "text": "don't we don't invent a check like that if there aren't thousands of customers making that mistake and they are",
    "start": "1094240",
    "end": "1102600"
  },
  {
    "text": "hopefully you aren't and hopefully after this talk you won't but I can tell you it's getting done a lot now that benefit",
    "start": "1102600",
    "end": "1109919"
  },
  {
    "text": "the EBS optimized improved channel to the storage subsystem for EBS that that",
    "start": "1109919",
    "end": "1115400"
  },
  {
    "text": "works both for provision iops and for standard EBS if you need uh non-c contention between Network",
    "start": "1115400",
    "end": "1122720"
  },
  {
    "text": "traffic with the storage subsystem EBS optimized works for both storage types so we have a lot of folks that are",
    "start": "1122720",
    "end": "1128200"
  },
  {
    "text": "trying to get to higher throughputs but don't need the consistency guarantees around provision iops that are using",
    "start": "1128200",
    "end": "1134480"
  },
  {
    "text": "that with standard EVS pretty powerful pattern so iops again is optimized for your",
    "start": "1134480",
    "end": "1141080"
  },
  {
    "text": "database workloads uh and it does provide because of its throttled you can",
    "start": "1141080",
    "end": "1146440"
  },
  {
    "text": "say computer generated Behavior a very different experience from any of the physical devices that maybe you're used",
    "start": "1146440",
    "end": "1152120"
  },
  {
    "text": "to using it has the same performance for random and sequential workloads we don't care your physical devices don't do that",
    "start": "1152120",
    "end": "1159880"
  },
  {
    "text": "we have 16k blocks as the measure all sorts of different discs come in different block optimized sizes As you",
    "start": "1159880",
    "end": "1167039"
  },
  {
    "text": "move into solid state Hardware you have all kind kinds of different types that are the right size 16k is actually relatively large for your average SSD",
    "start": "1167039",
    "end": "1173480"
  },
  {
    "text": "and there are some complexities around databases that use large block sizes to take the best advantage of SSD provision",
    "start": "1173480",
    "end": "1180000"
  },
  {
    "text": "iops resolves that so some places where things might",
    "start": "1180000",
    "end": "1186360"
  },
  {
    "text": "look odd uh let's say for example use an M1 large so if you go back to that earlier chart M1 large has somewhere on",
    "start": "1186360",
    "end": "1193400"
  },
  {
    "text": "the order of theoretical Max 64 megabits a second connectivity to the storage",
    "start": "1193400",
    "end": "1198919"
  },
  {
    "text": "subsystem if you use provision iops that's that's the number that you'd get so if you hook up a 4,000 IOP volume you",
    "start": "1198919",
    "end": "1205120"
  },
  {
    "text": "need to do a little calculus in your head 4,000 iops time 16k is 64 megabytes a second so they're exactly the same",
    "start": "1205120",
    "end": "1212799"
  },
  {
    "text": "speed in in in the sort of theoretical level so if you have any loss of a",
    "start": "1212799",
    "end": "1217880"
  },
  {
    "text": "single bit in any of those transits if there's any latency Gap or variation even at a tenth of a percent you start",
    "start": "1217880",
    "end": "1224799"
  },
  {
    "text": "to lose opportunities to write to storage so at 4K operations on an M1",
    "start": "1224799",
    "end": "1230280"
  },
  {
    "text": "large you see the full 4,000 iops maybe even slightly above that from what's provisioned but at 16k blocks you're",
    "start": "1230280",
    "end": "1236919"
  },
  {
    "text": "right at the absolute threshold of what's configured and so you'll tend to see just slightly less than what you",
    "start": "1236919",
    "end": "1243480"
  },
  {
    "text": "asked for that's not provision iops doing what it's not supposed to do you've actually saturated the network channel if you take that same disc and",
    "start": "1243480",
    "end": "1251039"
  },
  {
    "text": "connect it to an M3 extra large it goes up to the 50 or 4157 that you'd",
    "start": "1251039",
    "end": "1256840"
  },
  {
    "text": "expect also interestingly if you look at the sequential 4K operations on the",
    "start": "1256840",
    "end": "1262640"
  },
  {
    "text": "instances with higher bandwidth if your operating system can serialize random",
    "start": "1262640",
    "end": "1267799"
  },
  {
    "text": "events through the file system into the same right operation to storage you may",
    "start": "1267799",
    "end": "1273679"
  },
  {
    "text": "see from your instances or from your software's perspective a higher actual",
    "start": "1273679",
    "end": "1279320"
  },
  {
    "text": "number of iOS right so your computer thinks you're getting 6,000 done where since we're only metering at 16k we",
    "start": "1279320",
    "end": "1286559"
  },
  {
    "text": "think you've only gotten 4,000 done if you compare that number to what's happening in cloudwatch cloudwatch will",
    "start": "1286559",
    "end": "1291600"
  },
  {
    "text": "say 4,000 same example only even more exacerbated on the M32 XL which has",
    "start": "1291600",
    "end": "1297919"
  },
  {
    "text": "double the bandwidth now you can move even more of these sequential 4K operations to storage with random you",
    "start": "1297919",
    "end": "1304919"
  },
  {
    "text": "don't get that benefit each of those operations is going to a different Target as a result the operating system",
    "start": "1304919",
    "end": "1311000"
  },
  {
    "text": "won't consume those into or serialize them into single rights and so you don't get a bloom of performance there so",
    "start": "1311000",
    "end": "1319880"
  },
  {
    "start": "1318000",
    "end": "1370000"
  },
  {
    "text": "another place to look is at the larger block operations you're going to run a data warehouse and so you don't even",
    "start": "1319880",
    "end": "1326000"
  },
  {
    "text": "really care about iops at all you want to know about the megabytes a second of throughput provisioned iops is just as",
    "start": "1326000",
    "end": "1331840"
  },
  {
    "text": "consistent at delivering megabytes per second as it is at delivering iOS because in this system they're",
    "start": "1331840",
    "end": "1337559"
  },
  {
    "text": "effectively the same thing and you'll see the same average bandwidth throughput the total number of",
    "start": "1337559",
    "end": "1344559"
  },
  {
    "text": "megabytes a second across different block size operations but while the iops will look really scary why is this",
    "start": "1344559",
    "end": "1351240"
  },
  {
    "text": "system only doing 116 iops well it's CU you're writing many many many many many",
    "start": "1351240",
    "end": "1356520"
  },
  {
    "text": "many iOS per block right at 512k the liar jur higher throughput",
    "start": "1356520",
    "end": "1363919"
  },
  {
    "text": "instances allow you to get to the full maximum uh for each EBS volum",
    "start": "1363919",
    "end": "1370320"
  },
  {
    "start": "1370000",
    "end": "1444000"
  },
  {
    "text": "type so another hugely important set of metrics are around the latency behavior",
    "start": "1370320",
    "end": "1375480"
  },
  {
    "text": "of these devices so this goes back to the Q depth that we talked about there is a totally linear relationship between",
    "start": "1375480",
    "end": "1382919"
  },
  {
    "text": "the Q depth that you're able to drive and its impact on latency or linear",
    "start": "1382919",
    "end": "1388720"
  },
  {
    "text": "isn't the right word but there's a there's a connection there that's important to understand so for right",
    "start": "1388720",
    "end": "1394480"
  },
  {
    "text": "latency you need a relatively low Q depth when we originally launched provision iops as we measured against",
    "start": "1394480",
    "end": "1401200"
  },
  {
    "text": "the workloads we were testing we saw slightly different Behavior than this and so we've retested and retested",
    "start": "1401200",
    "end": "1407600"
  },
  {
    "text": "across abroad range of customer workloads and at the 4 to8 q depth Mark",
    "start": "1407600",
    "end": "1414720"
  },
  {
    "text": "for 16k random rights on a full throughput uh ec2 instance you'd see in",
    "start": "1414720",
    "end": "1421440"
  },
  {
    "text": "the low singled digigit millisecond latencies 1.47 per operation 2.03 per",
    "start": "1421440",
    "end": "1427880"
  },
  {
    "text": "operation you'll not at Short Q deps latency goes up and at long Q depths",
    "start": "1427880",
    "end": "1433360"
  },
  {
    "text": "latency goes up so for right workloads the original guidance isn't accurate you want to be more bur in the range of 1 to",
    "start": "1433360",
    "end": "1439600"
  },
  {
    "text": "500 or 1 to a th000 in order to optimize on the right side and on the read side you'll see a",
    "start": "1439600",
    "end": "1447520"
  },
  {
    "start": "1444000",
    "end": "1499000"
  },
  {
    "text": "different Behavior so just like uh lots of different Services there's a little nonlinearity there uh you'd want to",
    "start": "1447520",
    "end": "1454440"
  },
  {
    "text": "optimize for a higher Q depth on reads uh and you'd still be able to earn these",
    "start": "1454440",
    "end": "1459600"
  },
  {
    "text": "these low singled digit latencies you'll also know a much bigger jump the scales on these two charts aren't the same so",
    "start": "1459600",
    "end": "1465880"
  },
  {
    "text": "on this chart you're stair stepping upwards by single- digigit milliseconds at the top you're at 7.7 milliseconds",
    "start": "1465880",
    "end": "1472720"
  },
  {
    "text": "latency per operation on the read side that's 90 at the top so it's really",
    "start": "1472720",
    "end": "1479919"
  },
  {
    "text": "crucial to not drive an overwhelming read load against the provision ey out",
    "start": "1479919",
    "end": "1485919"
  },
  {
    "text": "system it's not designed to do that so that guidance starts to look more",
    "start": "1485919",
    "end": "1491720"
  },
  {
    "text": "like a q depth of one for every 200 which is pretty CL or 250 which is pretty close to our original guidance it's gives you a little more room there",
    "start": "1491720",
    "end": "1500320"
  },
  {
    "start": "1499000",
    "end": "1568000"
  },
  {
    "text": "so from a design standpoint your application may have different requirements uh may be deeply bounded by",
    "start": "1500320",
    "end": "1507720"
  },
  {
    "text": "latency a way to think about that is you know is the event that happens in your database or your data store directly in",
    "start": "1507720",
    "end": "1513760"
  },
  {
    "text": "the line of a event that is touched by a customer or a user probably the most",
    "start": "1513760",
    "end": "1519559"
  },
  {
    "text": "extreme examples of this stuff are the uh events that happen inside of the ad retargeting efforts at sub 100",
    "start": "1519559",
    "end": "1525760"
  },
  {
    "text": "milliseconds full end to end round trip but there are lots of other places where reducing the latency of operations makes",
    "start": "1525760",
    "end": "1532279"
  },
  {
    "text": "better user experiences so if you're doing analytics workloads or big oap tables or you're grinding through chunks",
    "start": "1532279",
    "end": "1538799"
  },
  {
    "text": "of data latency may not matter to you very much at all uh so you may want to",
    "start": "1538799",
    "end": "1543840"
  },
  {
    "text": "tune this value in order to be able to extract the the performance value that",
    "start": "1543840",
    "end": "1549240"
  },
  {
    "text": "you want and generally very very high Q depths uh we're already looking at many",
    "start": "1549240",
    "end": "1555120"
  },
  {
    "text": "customers starting to implement alarms in an against cloudwatch at extreme Q",
    "start": "1555120",
    "end": "1560679"
  },
  {
    "text": "depth Heights as an indication that something's gone wrong and that they're going to really want to adjust the behavior of their",
    "start": "1560679",
    "end": "1567360"
  },
  {
    "text": "application so another question we get quite a lot from a performance standpoint is the pre-warming of EBS",
    "start": "1567360",
    "end": "1573159"
  },
  {
    "start": "1568000",
    "end": "1698000"
  },
  {
    "text": "volumes there is a lazy load process and a lazy assignment process from the EBS",
    "start": "1573159",
    "end": "1579080"
  },
  {
    "text": "subsystem to the storage that you consume that process is the same for",
    "start": "1579080",
    "end": "1584640"
  },
  {
    "text": "brand new net new EBS volumes as it is for volume was reconstructed from S3",
    "start": "1584640",
    "end": "1591000"
  },
  {
    "text": "snapshots you'll see typically a 5% or so impact extreme worst cases in the 50%",
    "start": "1591000",
    "end": "1598360"
  },
  {
    "text": "range we have customers that have experienced numbers much higher than this really really terrible performance",
    "start": "1598360",
    "end": "1605559"
  },
  {
    "text": "in the 80% range those are indications that something has gone wrong and you should be communicating with support",
    "start": "1605559",
    "end": "1611559"
  },
  {
    "text": "these are values for the correct real behavior of the service when you access each chunk of",
    "start": "1611559",
    "end": "1620159"
  },
  {
    "text": "data in an EBS volume you warm or or",
    "start": "1620159",
    "end": "1625240"
  },
  {
    "text": "assign or provision that chunk of disc and so for almost all of the customers",
    "start": "1625240",
    "end": "1630640"
  },
  {
    "text": "that we've worked with if they're actually intending to really use our drives there isn't anything they have to",
    "start": "1630640",
    "end": "1635919"
  },
  {
    "text": "do they just start using them and they work how they're supposed to work after a little bit there's kind of this",
    "start": "1635919",
    "end": "1641159"
  },
  {
    "text": "warming up period in the first couple of hours if you're doing a synthetic Benchmark that's not the deal you need",
    "start": "1641159",
    "end": "1648200"
  },
  {
    "text": "to know how fast it's going to go so you have to drive work across the disc to get us to give it all to you so uh in",
    "start": "1648200",
    "end": "1655120"
  },
  {
    "text": "Linux that's DD uh for Windows folks uh there's a hilarious DD Port called",
    "start": "1655120",
    "end": "1661360"
  },
  {
    "text": "cryome DD give that a crack or I've even seen folks run sigin and then run DD",
    "start": "1661360",
    "end": "1668039"
  },
  {
    "text": "which is gross if you have the time you can do an NTFS full format that has the same",
    "start": "1668039",
    "end": "1673320"
  },
  {
    "text": "effect uh it can take a long time to pre-war from standard EBS volumes their",
    "start": "1673320",
    "end": "1680519"
  },
  {
    "text": "eye op rate is very low they're very big you're going to see that take nontrivial",
    "start": "1680519",
    "end": "1685799"
  },
  {
    "text": "hours typically in the load just above a day for provision knes you'll see that go much more quickly especially if you",
    "start": "1685799",
    "end": "1692320"
  },
  {
    "text": "are touching across uh touching across the four megabyte boundary on",
    "start": "1692320",
    "end": "1697799"
  },
  {
    "text": "blocks so uh raid we have lots of questions about raid raid is a useful tool um if your application if your",
    "start": "1697799",
    "end": "1705480"
  },
  {
    "start": "1698000",
    "end": "1875000"
  },
  {
    "text": "workload uh like SQL Server from Microsoft soft as an example has the ability to directly manage storage discs",
    "start": "1705480",
    "end": "1712200"
  },
  {
    "text": "and storage volumes and storage pools it's typical that your application does a better job of this than a raid system",
    "start": "1712200",
    "end": "1718240"
  },
  {
    "text": "would you should just give your software dis or EBS volumes in this",
    "start": "1718240",
    "end": "1723799"
  },
  {
    "text": "case if your application can't do that raid's the way to go uh raid allows you to aggregate the performance of multiple",
    "start": "1723799",
    "end": "1730519"
  },
  {
    "text": "EBS volumes to deliver whatever iops number you need to get to for a given workload given the constraints of the",
    "start": "1730519",
    "end": "1736080"
  },
  {
    "text": "performance of the ec2 instance and the network connection uh a pretty important piece of guidance raid five and raid six are and I cannot",
    "start": "1736080",
    "end": "1744919"
  },
  {
    "text": "say this strongly enough not recommended on AWS please do not do that I'll",
    "start": "1744919",
    "end": "1750000"
  },
  {
    "text": "explain why so let's take four EBS volumes and you want to write to each one and you've provisioned for the sake",
    "start": "1750000",
    "end": "1756440"
  },
  {
    "text": "of this example one IO per second on each of those volumes if you're going to write data and it's at the Block size of",
    "start": "1756440",
    "end": "1763120"
  },
  {
    "text": "an individual disc even in raid five that only goes to one disc that's great it only consumes one IO except you have",
    "start": "1763120",
    "end": "1769760"
  },
  {
    "text": "to write parody data to every other dis so every write costs four iOS instead of",
    "start": "1769760",
    "end": "1776240"
  },
  {
    "text": "one iio and it contends with the other potentially concurrent rights increasing latency to each of those rights so raid",
    "start": "1776240",
    "end": "1782480"
  },
  {
    "text": "zero raid one in extreme cases RAID 10 make total sense now standard EBS and",
    "start": "1782480",
    "end": "1789039"
  },
  {
    "text": "provision I EBS both uh use and and operate at much higher durability than a",
    "start": "1789039",
    "end": "1795360"
  },
  {
    "text": "standard physical disc the AFR for provision iops EBS and standard EBS volume are both at 0.1 to0 4% per year",
    "start": "1795360",
    "end": "1804200"
  },
  {
    "text": "that uh crushes end mimes standard disc at roughly 4% a year that's from our",
    "start": "1804200",
    "end": "1810399"
  },
  {
    "text": "instance volumes so if the folks out there who are thinking about super high",
    "start": "1810399",
    "end": "1815720"
  },
  {
    "text": "performance systems on lots and lots of uh big ssds trust me failure is a thing that you have to come to accommodate uh",
    "start": "1815720",
    "end": "1823039"
  },
  {
    "text": "you should listen to Warner he's not joking when he says everything will fail at some point uh and so those higher",
    "start": "1823039",
    "end": "1828880"
  },
  {
    "text": "failure or lower failure rates on the manage system of provision iops EVS can",
    "start": "1828880",
    "end": "1834000"
  },
  {
    "text": "make RAID 10 feel more like raid 110 right it's kind of already mirrored",
    "start": "1834000",
    "end": "1841000"
  },
  {
    "text": "and you're kind of getting mirroring on top of that uh we have folks that do lvm",
    "start": "1841000",
    "end": "1846159"
  },
  {
    "text": "direct to the dis there isn't any problem with that there's maybe more users that are using mdadm uh we have a",
    "start": "1846159",
    "end": "1852320"
  },
  {
    "text": "lower volume of support requests on that side um we have plenty of users that use mdadm to manage the storage and lvm",
    "start": "1852320",
    "end": "1859399"
  },
  {
    "text": "above that to manage the volume you construct above that storage so for like for mongodb for example you'd create a",
    "start": "1859399",
    "end": "1866039"
  },
  {
    "text": "one big raid so that any one of the logical storage volumes you construct can use the iops you have available is a",
    "start": "1866039",
    "end": "1873000"
  },
  {
    "text": "better pattern typically so uh oh I can tell you about",
    "start": "1873000",
    "end": "1878679"
  },
  {
    "start": "1875000",
    "end": "1967000"
  },
  {
    "text": "it on this slide anyway um so when rated and when using block sizes uh that are",
    "start": "1878679",
    "end": "1885880"
  },
  {
    "text": "in the right range uh on on the larger instance types you can drive truly",
    "start": "1885880",
    "end": "1891440"
  },
  {
    "text": "ludicrous read performance in the not tens of thousands but 50,000 plus",
    "start": "1891440",
    "end": "1897120"
  },
  {
    "text": "range here at this test we're showing 48,2 when you do raid probably the",
    "start": "1897120",
    "end": "1904840"
  },
  {
    "text": "hardest single management change is the fact that because it's possible to have a right that's happening to multiple",
    "start": "1904840",
    "end": "1911240"
  },
  {
    "text": "different EBS volumes happening at slightly different latencies taking a snapshot from those volumes has to be",
    "start": "1911240",
    "end": "1916799"
  },
  {
    "text": "done in a way that it's more consistent uh which means that the file system cannot be in a state of change when a",
    "start": "1916799",
    "end": "1923880"
  },
  {
    "text": "snapshot's taken for a standalone volume you really can in almost all cases just smash the snapshot button and good",
    "start": "1923880",
    "end": "1929639"
  },
  {
    "text": "things happen uh so storage 402 which was presented yesterday so you're out of",
    "start": "1929639",
    "end": "1934799"
  },
  {
    "text": "luck you're just going to have to download the slides as they come public um but there are lots of new tools being",
    "start": "1934799",
    "end": "1940279"
  },
  {
    "text": "released uh by folks on my team uh that will add new functional Behavior around",
    "start": "1940279",
    "end": "1946320"
  },
  {
    "text": "snapshots two different things that happen there one makes it much easier to manage snapshots of rated discs and two",
    "start": "1946320",
    "end": "1953760"
  },
  {
    "text": "manages uh the snapshot diaspora as you take snapshots every five minutes on critical",
    "start": "1953760",
    "end": "1960000"
  },
  {
    "text": "volumes so it helps you clean up unused snapshot IDs as you age them out cool",
    "start": "1960000",
    "end": "1967039"
  },
  {
    "text": "stuff so we also think that it makes a lot more sense to not just give you the raw building blocks and make you do the",
    "start": "1967039",
    "end": "1974120"
  },
  {
    "text": "calculus uh we want to be able to publish just the straight cheat sheet",
    "start": "1974120",
    "end": "1979159"
  },
  {
    "text": "you run this software you want to go as fast as you can go for each of the different three instance types that we generally recommend or instance levels",
    "start": "1979159",
    "end": "1986080"
  },
  {
    "text": "something at 500 megabits something at 1,000 megabits something on the cluster Network we're just going to lay it all",
    "start": "1986080",
    "end": "1992919"
  },
  {
    "text": "out right this is what you should be running uh this works for say 80 to 90%",
    "start": "1992919",
    "end": "1999120"
  },
  {
    "text": "of the cases that we see in each of these different workloads we're working really hard as another one of those",
    "start": "1999120",
    "end": "2004559"
  },
  {
    "text": "benefits of reinvent we're working hard to get this published but we just don't have it done yet so first on the rdbms side um you'll see",
    "start": "2004559",
    "end": "2012480"
  },
  {
    "text": "the pretty significant variability in Block sizes and so you've got very different disc configurations that are",
    "start": "2012480",
    "end": "2018600"
  },
  {
    "text": "the result of that from uh all the way up to 24 provision iops volumes for your",
    "start": "2018600",
    "end": "2024720"
  },
  {
    "text": "uh postest SQL postest uh which uh maybe you won't ever have to do again since we",
    "start": "2024720",
    "end": "2029760"
  },
  {
    "text": "just turned it into RDS yes uh or uh down at the new SQL sort of",
    "start": "2029760",
    "end": "2035519"
  },
  {
    "text": "level you got um some at the very very small block sizes 4K and things like that also for no SQL systems mongodb",
    "start": "2035519",
    "end": "2043600"
  },
  {
    "start": "2040000",
    "end": "2082000"
  },
  {
    "text": "Cassandra couch base we'll be adding uh aerospike and Mark logic and several others to the list as quickly as we can",
    "start": "2043600",
    "end": "2050280"
  },
  {
    "text": "um similar behaviors couple of them do more to serialize IO uh so the mongod DB",
    "start": "2050280",
    "end": "2056200"
  },
  {
    "text": "stuff um you you will see that the actual storage system is doing 4ks but",
    "start": "2056200",
    "end": "2061560"
  },
  {
    "text": "because the rights are typically so serializable that actual averages are more like 40K or 50K for lots of the",
    "start": "2061560",
    "end": "2068679"
  },
  {
    "text": "synthetic workloads so it's really important in to evaluate we are actually doing with the database because",
    "start": "2068679",
    "end": "2073720"
  },
  {
    "text": "that has a much bigger impact in the average size than maybe other database systems experience but generally these",
    "start": "2073720",
    "end": "2080040"
  },
  {
    "text": "are good good starting points also the same for data",
    "start": "2080040",
    "end": "2085240"
  },
  {
    "start": "2082000",
    "end": "2176000"
  },
  {
    "text": "warehouses uh and distributed Network file systems um so file systems with",
    "start": "2085240",
    "end": "2090839"
  },
  {
    "text": "typically much larger block sizes uh you'll be seeing smaller numbers of provisioned iops uh in order to get to",
    "start": "2090839",
    "end": "2097920"
  },
  {
    "text": "the um same throughput totals and also the sort of switch typically here to",
    "start": "2097920",
    "end": "2103079"
  },
  {
    "text": "sequential rights so if that's if that's this sort",
    "start": "2103079",
    "end": "2108880"
  },
  {
    "text": "of cheat sheet an important sort of number to hold in your head is you know those are the throughputs that are the",
    "start": "2108880",
    "end": "2114079"
  },
  {
    "text": "absolute maximums for each of those instance types as they interact with the storage subsystem now those cluster",
    "start": "2114079",
    "end": "2120839"
  },
  {
    "text": "instances you'll know you can't poke that little EBS optimized button good questions about that uh you can't poke",
    "start": "2120839",
    "end": "2127880"
  },
  {
    "text": "it because all of the work that we can do to optimize the channel to EBS has already been done but that does not",
    "start": "2127880",
    "end": "2134320"
  },
  {
    "text": "construct the isolation that EBS optimize provides so it is possible for you to write at that 50,000 I op rate",
    "start": "2134320",
    "end": "2142640"
  },
  {
    "text": "but and have that consume and contend with the network workload to other instances now we're talking about you",
    "start": "2142640",
    "end": "2149119"
  },
  {
    "text": "know lots and lots and lots and lots and lots of the megabytes a second so uh",
    "start": "2149119",
    "end": "2154359"
  },
  {
    "text": "it's more important to be careful with those instance types as you plan what the real world",
    "start": "2154359",
    "end": "2160800"
  },
  {
    "text": "throughput will be for a replicated say for example data store or for a data",
    "start": "2160800",
    "end": "2166040"
  },
  {
    "text": "store that communicates much more heavily with the Internet or uh or other AWS services so that's a little",
    "start": "2166040",
    "end": "2172160"
  },
  {
    "text": "different than the EBS optimized for standard instance classes we also get lots of questions",
    "start": "2172160",
    "end": "2178040"
  },
  {
    "text": "about the behavior of those systems in the context of the instances that do have uh high performance local storage",
    "start": "2178040",
    "end": "2184720"
  },
  {
    "text": "uh high1 14xl the brand new super awesome some I2 instances hope everybody's excited about those uh and",
    "start": "2184720",
    "end": "2192560"
  },
  {
    "text": "uh and the HS ones the big storage boats with 48 terabytes of local disc so we see in lots and lots of patterns where",
    "start": "2192560",
    "end": "2199040"
  },
  {
    "text": "you can Implement replication this is typically on the nosql side but uh relational databases in some cases allow",
    "start": "2199040",
    "end": "2205040"
  },
  {
    "text": "you to follow these patterns having ssds as the primary right target primary read",
    "start": "2205040",
    "end": "2210760"
  },
  {
    "text": "Targets in some cases is an efficient implementation but in a clustered setup you're going to want at least one of",
    "start": "2210760",
    "end": "2217800"
  },
  {
    "text": "those instances on provisioned IOP CBS the reason is is that you can snapshot it getting that data into S3 where it is",
    "start": "2217800",
    "end": "2225240"
  },
  {
    "text": "not 0.1 to .4% AFR but 11 nines durable some zillion number of trillion objects",
    "start": "2225240",
    "end": "2233040"
  },
  {
    "text": "and we haven't really ever lost one of those things is a huge Improvement in the durability of data for business if",
    "start": "2233040",
    "end": "2239440"
  },
  {
    "text": "you have data and you like it and it's not in S3 I think you're a little weird right",
    "start": "2239440",
    "end": "2245800"
  },
  {
    "text": "so the the process here uh of building a replication is dependent on the software",
    "start": "2245800",
    "end": "2252280"
  },
  {
    "text": "so some software can do this some software can't um it's important that you test that for the specific workload",
    "start": "2252280",
    "end": "2258720"
  },
  {
    "text": "that you've got and there's also some tuning and behaviors stuff that we don't have time in this talk to go into around",
    "start": "2258720",
    "end": "2264839"
  },
  {
    "text": "the behavior of the local discs a lot of the it's not really a matter of time the I2 Guidance just hasn't been released",
    "start": "2264839",
    "end": "2270480"
  },
  {
    "text": "yet we'll get that stuff out as quick as we can so important to note though even for",
    "start": "2270480",
    "end": "2276240"
  },
  {
    "start": "2273000",
    "end": "2352000"
  },
  {
    "text": "the I2 instances even for the instances like high1 4XL you are interacting with",
    "start": "2276240",
    "end": "2281400"
  },
  {
    "text": "a physical device now you're back to the back of the box where you have actual behaviors of real physical services and",
    "start": "2281400",
    "end": "2288240"
  },
  {
    "text": "so as is common with physical devices there is variability in their performance right so if standard EBS has",
    "start": "2288240",
    "end": "2294960"
  },
  {
    "text": "crazy variability because it was built on best effort provision Diop is like a",
    "start": "2294960",
    "end": "2300160"
  },
  {
    "text": "ruler it's unbelievable the difference in your cloudwatch charts you know typical orders of magnitude you're at a",
    "start": "2300160",
    "end": "2305520"
  },
  {
    "text": "tenth of a percent variability over weeks and weeks and weeks of behavior this is it a,0 and then a,1 and 1,9",
    "start": "2305520",
    "end": "2313960"
  },
  {
    "text": "that's normal now the ssds are they're they're really fast they're catastrophically fast there's no getting",
    "start": "2313960",
    "end": "2320160"
  },
  {
    "text": "around but they have variability I mean that's that's approaching 10% from 65,000 iops down to 61,000 iops",
    "start": "2320160",
    "end": "2328359"
  },
  {
    "text": "for this test that's multiple dozens of megabytes a second in difference there's a 52,000 on that list so be sure as",
    "start": "2328359",
    "end": "2337839"
  },
  {
    "text": "you're testing your workload recognize that when you use the instances with local ephemeral dis that",
    "start": "2337839",
    "end": "2343440"
  },
  {
    "text": "you're talking about the actual behavior of a physical thing there and provision iops will tend to be significantly more",
    "start": "2343440",
    "end": "2349040"
  },
  {
    "text": "consistent than that since it is a managed service for lack of a better word so performance performance who",
    "start": "2349040",
    "end": "2357000"
  },
  {
    "start": "2352000",
    "end": "2507000"
  },
  {
    "text": "cares I have to buy this stuff with dollars and cents what's the right choices to make in terms of when are the",
    "start": "2357000",
    "end": "2363880"
  },
  {
    "text": "inflection points around one div device versus the other",
    "start": "2363880",
    "end": "2368960"
  },
  {
    "text": "so what we've noticed is that there's one set of decisions that happen if you're thinking about this on demand if",
    "start": "2368960",
    "end": "2375280"
  },
  {
    "text": "you have a workload that's short term if you have a workload that's has an unpredictable term it's pretty",
    "start": "2375280",
    "end": "2380800"
  },
  {
    "text": "conservative to plan around provision iops in most cases uh but as you go to much longer term because of the value of",
    "start": "2380800",
    "end": "2388079"
  },
  {
    "text": "reserved instances where there isn't today a reservation model around EBS",
    "start": "2388079",
    "end": "2393319"
  },
  {
    "text": "drives down the cost of local storage because it drives down the cost of local instances and as a result long-term",
    "start": "2393319",
    "end": "2400079"
  },
  {
    "text": "workloads may make more sense as you get efficient and optimize and you have better visibility into your workload uh",
    "start": "2400079",
    "end": "2406240"
  },
  {
    "text": "to run on these kinds of ephemeral surfaces so another model right now",
    "start": "2406240",
    "end": "2411400"
  },
  {
    "text": "because the high1 4X large instances are so large if you're smaller than this",
    "start": "2411400",
    "end": "2417079"
  },
  {
    "text": "provision iops is always going to be nice because you can dial it to exactly the speed that you want at those smaller sizes but if you're very very big then",
    "start": "2417079",
    "end": "2424319"
  },
  {
    "text": "High one is going to make a lot of sense now what's happened if you think think about it is I2 because of the I2 large",
    "start": "2424319",
    "end": "2430520"
  },
  {
    "text": "instance is a much smaller building block so some of this guidance will shift uh and you and high five for",
    "start": "2430520",
    "end": "2437599"
  },
  {
    "text": "that um uh what that will do is also change the Threshold at which provision",
    "start": "2437599",
    "end": "2443800"
  },
  {
    "text": "iops make sense uh if your systems can take advantage of that higher IOP throughput same kinds of calculus for",
    "start": "2443800",
    "end": "2451599"
  },
  {
    "text": "the comparison between the storage uh instances hs1 adex large uh versus the",
    "start": "2451599",
    "end": "2457440"
  },
  {
    "text": "cc28 XLS um in many cases that choice is a little more complex it is much more",
    "start": "2457440",
    "end": "2463440"
  },
  {
    "text": "bounded by um how long you're going to run the instance um and it's also",
    "start": "2463440",
    "end": "2468520"
  },
  {
    "text": "important to note that for both of these models we're not comparing against a single instance because if you're using",
    "start": "2468520",
    "end": "2474000"
  },
  {
    "text": "storage on a local instance and you have one copy I will smack you don't do it so",
    "start": "2474000",
    "end": "2481160"
  },
  {
    "text": "you have to have two you have to have replication of some kind and so when comparing the two instances that you'd",
    "start": "2481160",
    "end": "2487040"
  },
  {
    "text": "need also remember the management overhead that there's two computers to patch there's two computers to check metrics",
    "start": "2487040",
    "end": "2492680"
  },
  {
    "text": "on there's two computers to back up and maybe you do only one backup okay I'll mess with you so costs for those two are",
    "start": "2492680",
    "end": "2501119"
  },
  {
    "text": "also important to analyze and we as we add new instance types as we change prices that calculus will",
    "start": "2501119",
    "end": "2506920"
  },
  {
    "text": "shift there's also stuff that you can do at the software layer that has in some cases pretty significant impact on",
    "start": "2506920",
    "end": "2513280"
  },
  {
    "text": "performance storage uh we really do strongly recommend ext4 or xfs there are a couple different behaviors there uh",
    "start": "2513280",
    "end": "2519760"
  },
  {
    "text": "also important to note that journal access Alters the behavior patterns from most storage so uh worthwhile",
    "start": "2519760",
    "end": "2525599"
  },
  {
    "text": "experimenting there with the configuration of Journal um many many applications don't make use of some",
    "start": "2525599",
    "end": "2531440"
  },
  {
    "text": "costly file system features uh particularly like no a time and no Dura time uh and uh setting read ahads low on",
    "start": "2531440",
    "end": "2540720"
  },
  {
    "text": "provision IOP storage if you imagine that if you read ahead 512k for every",
    "start": "2540720",
    "end": "2546599"
  },
  {
    "text": "read and you only actually need this 4K read you just spent I think it's 32",
    "start": "2546599",
    "end": "2553079"
  },
  {
    "text": "separate ios's that you didn't need to spend against storage your storage will go very slow also um you may be able to",
    "start": "2553079",
    "end": "2560559"
  },
  {
    "text": "note from this slide that I have a pension for snapshots I suggest that you poke that button as frequently as you",
    "start": "2560559",
    "end": "2566599"
  },
  {
    "text": "even remotely think is reasonable and and then right after that poke it again so the the EBS storage model is designed",
    "start": "2566599",
    "end": "2574319"
  },
  {
    "text": "around the concept that each EBS volume holds at any given time less than 20",
    "start": "2574319",
    "end": "2579760"
  },
  {
    "text": "gabyt of data that hasn't been snapshotted so there's this weird thought that the more often you snapshot",
    "start": "2579760",
    "end": "2586480"
  },
  {
    "text": "the less often you'll need them which is also something to sort of take into mind as you're planning so uh we went from a thousand",
    "start": "2586480",
    "end": "2595559"
  },
  {
    "text": "to roughly 100,000 uh when I started as a Solutions architect three and a half years ago a",
    "start": "2595559",
    "end": "2601280"
  },
  {
    "text": "thousand iops uh it was rocket science we worked really hard with customers to design and configure and optimize those",
    "start": "2601280",
    "end": "2607480"
  },
  {
    "text": "implementations you had a lot of work to do to get to that level and we're we're roughly two orders of magnitude faster",
    "start": "2607480",
    "end": "2613760"
  },
  {
    "text": "than that today uh so you may also as you've been looking through evaluate the",
    "start": "2613760",
    "end": "2620359"
  },
  {
    "text": "workloads that maybe you evaluated before even if you tested when we put provision iops out at a thousand iops",
    "start": "2620359",
    "end": "2626200"
  },
  {
    "text": "it's four times faster now that's a big difference for most workloads my compute",
    "start": "2626200",
    "end": "2632119"
  },
  {
    "text": "is not four times faster my memory is not four times faster all of a sudden my storage is four times faster that's a",
    "start": "2632119",
    "end": "2638800"
  },
  {
    "text": "big difference so as you're looking through workloads that maybe were impossible you could never run that",
    "start": "2638800",
    "end": "2644400"
  },
  {
    "text": "stuff in Cloud we're seeing people uh really finding no upper barrier there isn't anything that you can't run in",
    "start": "2644400",
    "end": "2650079"
  },
  {
    "text": "here uh we're excited about taking uh those big Enterprise workloads on across",
    "start": "2650079",
    "end": "2655480"
  },
  {
    "text": "the full range of different storage workloads your data warehouses were good with those your file systems yep we can",
    "start": "2655480",
    "end": "2660880"
  },
  {
    "text": "do that your media storage yep we got that under control relational databases sh so",
    "start": "2660880",
    "end": "2667680"
  },
  {
    "text": "we have a lot of data here uh this is the second time we presented it so double feedback would be cool",
    "start": "2667680",
    "end": "2674920"
  }
]
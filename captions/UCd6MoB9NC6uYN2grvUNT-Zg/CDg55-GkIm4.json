[
  {
    "start": "0",
    "end": "79000"
  },
  {
    "text": "hi my name is Emily Weber and I'm a",
    "start": "30",
    "end": "2310"
  },
  {
    "text": "machine learning specialist at Amazon",
    "start": "2310",
    "end": "3929"
  },
  {
    "text": "Web Services and today I want you to",
    "start": "3929",
    "end": "6990"
  },
  {
    "text": "know how you can scale out your training",
    "start": "6990",
    "end": "8730"
  },
  {
    "text": "right you can actually add more data to",
    "start": "8730",
    "end": "11219"
  },
  {
    "text": "your model with relatively low pain and",
    "start": "11219",
    "end": "14460"
  },
  {
    "text": "relatively low cost and this is your",
    "start": "14460",
    "end": "17250"
  },
  {
    "text": "deep dive",
    "start": "17250",
    "end": "19580"
  },
  {
    "text": "so we know that there are 17 built-in",
    "start": "20680",
    "end": "24189"
  },
  {
    "text": "algorithms in Amazon sage maker right as",
    "start": "24189",
    "end": "26619"
  },
  {
    "text": "of today there are 17 built-in",
    "start": "26619",
    "end": "28119"
  },
  {
    "text": "algorithms so we also know that each one",
    "start": "28119",
    "end": "30400"
  },
  {
    "text": "of those algorithms solves a different",
    "start": "30400",
    "end": "32590"
  },
  {
    "text": "type of prediction problem right you've",
    "start": "32590",
    "end": "34449"
  },
  {
    "text": "got classification you've got computer",
    "start": "34449",
    "end": "35980"
  },
  {
    "text": "vision topic modeling forecasting all",
    "start": "35980",
    "end": "38440"
  },
  {
    "text": "the good stuff but each algorithm has",
    "start": "38440",
    "end": "41050"
  },
  {
    "text": "different specifications right some of",
    "start": "41050",
    "end": "43420"
  },
  {
    "text": "them can leverage incremental retraining",
    "start": "43420",
    "end": "46120"
  },
  {
    "text": "and some of them can run on multiple",
    "start": "46120",
    "end": "48760"
  },
  {
    "text": "nodes right some of them support",
    "start": "48760",
    "end": "50110"
  },
  {
    "text": "distributed training and so here we're",
    "start": "50110",
    "end": "52030"
  },
  {
    "text": "gonna deep dive on exactly what that",
    "start": "52030",
    "end": "53739"
  },
  {
    "text": "means so on top of those right on top of",
    "start": "53739",
    "end": "57610"
  },
  {
    "text": "those built-in algorithms there seems to",
    "start": "57610",
    "end": "59619"
  },
  {
    "text": "be an increasingly infinite array of",
    "start": "59619",
    "end": "61869"
  },
  {
    "text": "potential models that you can build and",
    "start": "61869",
    "end": "63820"
  },
  {
    "text": "run right these days it seems literally",
    "start": "63820",
    "end": "65920"
  },
  {
    "text": "infinite but as soon as I start thinking",
    "start": "65920",
    "end": "68170"
  },
  {
    "text": "about increasing an infinite something",
    "start": "68170",
    "end": "70119"
  },
  {
    "text": "else comes to mind all right and that's",
    "start": "70119",
    "end": "72159"
  },
  {
    "text": "a limit right so the limit we want to",
    "start": "72159",
    "end": "75369"
  },
  {
    "text": "think about kind of what that what that",
    "start": "75369",
    "end": "76689"
  },
  {
    "text": "would actually be and so in this case",
    "start": "76689",
    "end": "81490"
  },
  {
    "text": "what we actually want to know is that as",
    "start": "81490",
    "end": "84100"
  },
  {
    "text": "ec2 approaches infinity right the",
    "start": "84100",
    "end": "87520"
  },
  {
    "text": "function of our data set size our actual",
    "start": "87520",
    "end": "90610"
  },
  {
    "text": "limit is actually going to be how much",
    "start": "90610",
    "end": "92290"
  },
  {
    "text": "we want to spend right that's that's our",
    "start": "92290",
    "end": "94210"
  },
  {
    "text": "actual limit here is our is our dollar",
    "start": "94210",
    "end": "96880"
  },
  {
    "text": "value and so there are three ways that",
    "start": "96880",
    "end": "100240"
  },
  {
    "text": "you can scale your own models over",
    "start": "100240",
    "end": "103150"
  },
  {
    "text": "multiple nodes on Amazon Sage Maker and",
    "start": "103150",
    "end": "105730"
  },
  {
    "text": "the first one is using a built-in",
    "start": "105730",
    "end": "107350"
  },
  {
    "text": "algorithm right just taking that",
    "start": "107350",
    "end": "109150"
  },
  {
    "text": "algorithm off the shelf and then running",
    "start": "109150",
    "end": "110979"
  },
  {
    "text": "it over multiple nodes the second way",
    "start": "110979",
    "end": "113170"
  },
  {
    "text": "you can do that is by bringing a docker",
    "start": "113170",
    "end": "114940"
  },
  {
    "text": "file and then running that docker file",
    "start": "114940",
    "end": "117220"
  },
  {
    "text": "on to ec2 instances right that's that's",
    "start": "117220",
    "end": "119409"
  },
  {
    "text": "typically going to be getting to docker",
    "start": "119409",
    "end": "120670"
  },
  {
    "text": "files the last way you can do that is by",
    "start": "120670",
    "end": "123010"
  },
  {
    "text": "using script mode we're gonna walk",
    "start": "123010",
    "end": "124690"
  },
  {
    "text": "through how to get that set up so",
    "start": "124690",
    "end": "127990"
  },
  {
    "text": "there's a topic that we want to",
    "start": "127990",
    "end": "129340"
  },
  {
    "text": "understand here and that is multi node",
    "start": "129340",
    "end": "131459"
  },
  {
    "text": "versus single node and so if you've got",
    "start": "131459",
    "end": "133780"
  },
  {
    "text": "a single node I think one server right",
    "start": "133780",
    "end": "136599"
  },
  {
    "text": "that's one virtual machine that's one",
    "start": "136599",
    "end": "138010"
  },
  {
    "text": "instance of compute that's one ec2",
    "start": "138010",
    "end": "140110"
  },
  {
    "text": "instance so that's one single node right",
    "start": "140110",
    "end": "143049"
  },
  {
    "text": "and that's gonna have one docker",
    "start": "143049",
    "end": "144159"
  },
  {
    "text": "container separately we can also have",
    "start": "144159",
    "end": "146980"
  },
  {
    "text": "multiple nodes right we can have",
    "start": "146980",
    "end": "148540"
  },
  {
    "text": "multiple virtual servers we can have",
    "start": "148540",
    "end": "150670"
  },
  {
    "text": "multiple ec2 instances and then we can",
    "start": "150670",
    "end": "153790"
  },
  {
    "text": "just have one",
    "start": "153790",
    "end": "154450"
  },
  {
    "text": "master image that's passing code and",
    "start": "154450",
    "end": "157150"
  },
  {
    "text": "data to the rest of those nodes right so",
    "start": "157150",
    "end": "159670"
  },
  {
    "text": "that's single node versus multi node and",
    "start": "159670",
    "end": "162700"
  },
  {
    "text": "so what's cool is that you can actually",
    "start": "162700",
    "end": "165010"
  },
  {
    "text": "distribute your model training on a",
    "start": "165010",
    "end": "167200"
  },
  {
    "text": "single node right and that's because you",
    "start": "167200",
    "end": "169390"
  },
  {
    "text": "have all those CPUs so if you have your",
    "start": "169390",
    "end": "172000"
  },
  {
    "text": "system set up so that for each of those",
    "start": "172000",
    "end": "173800"
  },
  {
    "text": "V CPUs it's taking a different version",
    "start": "173800",
    "end": "176319"
  },
  {
    "text": "of your model and training with a",
    "start": "176319",
    "end": "177790"
  },
  {
    "text": "different set of your data you can",
    "start": "177790",
    "end": "179890"
  },
  {
    "text": "definitely do this there are frameworks",
    "start": "179890",
    "end": "181510"
  },
  {
    "text": "out there out there that are gonna help",
    "start": "181510",
    "end": "183670"
  },
  {
    "text": "you do that and one of those frameworks",
    "start": "183670",
    "end": "185890"
  },
  {
    "text": "is vaad alright and so vaad",
    "start": "185890",
    "end": "188440"
  },
  {
    "text": "is an open source framework that's a",
    "start": "188440",
    "end": "190480"
  },
  {
    "text": "very common way of distributing your",
    "start": "190480",
    "end": "193060"
  },
  {
    "text": "tensorflow models but again on a single",
    "start": "193060",
    "end": "196180"
  },
  {
    "text": "host right so that's on one single",
    "start": "196180",
    "end": "199150"
  },
  {
    "text": "virtual machine and so your instance",
    "start": "199150",
    "end": "201670"
  },
  {
    "text": "count in that case is one but your",
    "start": "201670",
    "end": "203860"
  },
  {
    "text": "processes per host is actually two and",
    "start": "203860",
    "end": "206950"
  },
  {
    "text": "so Horvat is gonna help you run multiple",
    "start": "206950",
    "end": "208980"
  },
  {
    "text": "processes on a single node but there are",
    "start": "208980",
    "end": "213940"
  },
  {
    "text": "also ways that you can distribute your",
    "start": "213940",
    "end": "215680"
  },
  {
    "text": "data over multiple nodes and we're gonna",
    "start": "215680",
    "end": "218049"
  },
  {
    "text": "talk about how to do that so in sage",
    "start": "218049",
    "end": "219760"
  },
  {
    "text": "maker there are two terms that we're",
    "start": "219760",
    "end": "221799"
  },
  {
    "text": "going to use here one term is called",
    "start": "221799",
    "end": "223090"
  },
  {
    "text": "fully replicated and another term is",
    "start": "223090",
    "end": "225579"
  },
  {
    "text": "called charted by s3 key and both of",
    "start": "225579",
    "end": "228790"
  },
  {
    "text": "those are going to be rooted in your s3",
    "start": "228790",
    "end": "230530"
  },
  {
    "text": "bucket right you're gonna have your data",
    "start": "230530",
    "end": "232090"
  },
  {
    "text": "in s3 when you are fully replicating",
    "start": "232090",
    "end": "235299"
  },
  {
    "text": "your dataset you're gonna have multiple",
    "start": "235299",
    "end": "237609"
  },
  {
    "text": "ec2 instances and sage Baker is gonna",
    "start": "237609",
    "end": "240639"
  },
  {
    "text": "send a full copy of your data set from",
    "start": "240639",
    "end": "243819"
  },
  {
    "text": "your s3 bucket to those ec2 instances",
    "start": "243819",
    "end": "246489"
  },
  {
    "text": "and both of those instances are gonna",
    "start": "246489",
    "end": "248769"
  },
  {
    "text": "have exactly the same data right that's",
    "start": "248769",
    "end": "251500"
  },
  {
    "text": "why it's called fully replicated it's",
    "start": "251500",
    "end": "253900"
  },
  {
    "text": "the same data over multiple ec2",
    "start": "253900",
    "end": "256150"
  },
  {
    "text": "instances over here you can also enable",
    "start": "256150",
    "end": "261849"
  },
  {
    "text": "what's called sharded by s3 key and so",
    "start": "261849",
    "end": "265630"
  },
  {
    "text": "that means that for each of your ec2",
    "start": "265630",
    "end": "267340"
  },
  {
    "text": "instances you'll have different version",
    "start": "267340",
    "end": "270250"
  },
  {
    "text": "you'll have different chunks of your",
    "start": "270250",
    "end": "272080"
  },
  {
    "text": "data right so say you've got you know a",
    "start": "272080",
    "end": "275050"
  },
  {
    "text": "terabyte of data that you want to Train",
    "start": "275050",
    "end": "276880"
  },
  {
    "text": "but you don't want to have a terabyte of",
    "start": "276880",
    "end": "278500"
  },
  {
    "text": "data on each node right so maybe you'll",
    "start": "278500",
    "end": "280300"
  },
  {
    "text": "split it out to having much smaller",
    "start": "280300",
    "end": "283330"
  },
  {
    "text": "chunks of your data over multiple ec2",
    "start": "283330",
    "end": "286360"
  },
  {
    "text": "instances and so you'll kind of",
    "start": "286360",
    "end": "288249"
  },
  {
    "text": "wrangle all of that by using sharded by",
    "start": "288249",
    "end": "291219"
  },
  {
    "text": "f3 key that is a term for a distribution",
    "start": "291219",
    "end": "294039"
  },
  {
    "text": "in sage maker ok so fully replicated",
    "start": "294039",
    "end": "299199"
  },
  {
    "text": "right when all of your data is being",
    "start": "299199",
    "end": "300939"
  },
  {
    "text": "copied over to all those ec2 instances",
    "start": "300939",
    "end": "303099"
  },
  {
    "text": "why would you do that",
    "start": "303099",
    "end": "304419"
  },
  {
    "text": "the first reason you would do that is",
    "start": "304419",
    "end": "306579"
  },
  {
    "text": "that it's actually gonna help you",
    "start": "306579",
    "end": "307959"
  },
  {
    "text": "increase your model stability what that",
    "start": "307959",
    "end": "310899"
  },
  {
    "text": "means is that models can be very",
    "start": "310899",
    "end": "313079"
  },
  {
    "text": "sensitive to initializations they can be",
    "start": "313079",
    "end": "315999"
  },
  {
    "text": "very sensitive to randomness in the",
    "start": "315999",
    "end": "319059"
  },
  {
    "text": "model to you know kind of arbitrary",
    "start": "319059",
    "end": "321189"
  },
  {
    "text": "pieces that that happen and so when you",
    "start": "321189",
    "end": "323349"
  },
  {
    "text": "increase the number of nodes that you're",
    "start": "323349",
    "end": "325839"
  },
  {
    "text": "using to train the model it's generally",
    "start": "325839",
    "end": "328089"
  },
  {
    "text": "gonna be more stable at the end right",
    "start": "328089",
    "end": "329829"
  },
  {
    "text": "it's had three four five different",
    "start": "329829",
    "end": "332349"
  },
  {
    "text": "versions of running and so the final",
    "start": "332349",
    "end": "333819"
  },
  {
    "text": "model is going to be more stable because",
    "start": "333819",
    "end": "335860"
  },
  {
    "text": "it's seen four or five versions of that",
    "start": "335860",
    "end": "337749"
  },
  {
    "text": "um you'd also use fully replicated if",
    "start": "337749",
    "end": "340089"
  },
  {
    "text": "you're basically just practicing scaling",
    "start": "340089",
    "end": "342249"
  },
  {
    "text": "out your resource usage if you just want",
    "start": "342249",
    "end": "343899"
  },
  {
    "text": "to make sure that you can touch multiple",
    "start": "343899",
    "end": "346059"
  },
  {
    "text": "ec2 instances for a single training job",
    "start": "346059",
    "end": "347889"
  },
  {
    "text": "you'll also do fully replicated when you",
    "start": "347889",
    "end": "350379"
  },
  {
    "text": "generally have smaller data amounts all",
    "start": "350379",
    "end": "352719"
  },
  {
    "text": "right so when you're not quite at all at",
    "start": "352719",
    "end": "355059"
  },
  {
    "text": "a large scale but you still want to run",
    "start": "355059",
    "end": "357759"
  },
  {
    "text": "on multiple nodes and so how you're",
    "start": "357759",
    "end": "363189"
  },
  {
    "text": "actually gonna get it done right when",
    "start": "363189",
    "end": "364929"
  },
  {
    "text": "you're setting up your channel not in",
    "start": "364929",
    "end": "366879"
  },
  {
    "text": "this case a validation channel just",
    "start": "366879",
    "end": "369039"
  },
  {
    "text": "specify your distribution type as fully",
    "start": "369039",
    "end": "371949"
  },
  {
    "text": "replicated and then for sharded by s3",
    "start": "371949",
    "end": "376329"
  },
  {
    "text": "key right so so why you're gonna do this",
    "start": "376329",
    "end": "378309"
  },
  {
    "text": "is firstly just because you have more",
    "start": "378309",
    "end": "380379"
  },
  {
    "text": "data right you have a lot of data and so",
    "start": "380379",
    "end": "382539"
  },
  {
    "text": "you want to distribute that over",
    "start": "382539",
    "end": "383860"
  },
  {
    "text": "multiple nodes you might be interested",
    "start": "383860",
    "end": "386110"
  },
  {
    "text": "in exposing parts of your model to",
    "start": "386110",
    "end": "388389"
  },
  {
    "text": "specific data samples so if you want you",
    "start": "388389",
    "end": "392229"
  },
  {
    "text": "know part of your model to look at one",
    "start": "392229",
    "end": "394149"
  },
  {
    "text": "area very very closely and then look at",
    "start": "394149",
    "end": "396639"
  },
  {
    "text": "another area very very closely you can",
    "start": "396639",
    "end": "398619"
  },
  {
    "text": "debate about the research methods there",
    "start": "398619",
    "end": "400029"
  },
  {
    "text": "but that might be a technique that would",
    "start": "400029",
    "end": "401589"
  },
  {
    "text": "help improve your performance in some",
    "start": "401589",
    "end": "403719"
  },
  {
    "text": "cases also it's just gonna make your",
    "start": "403719",
    "end": "405519"
  },
  {
    "text": "training faster right at the end of the",
    "start": "405519",
    "end": "407529"
  },
  {
    "text": "day you will definitely have a model",
    "start": "407529",
    "end": "409239"
  },
  {
    "text": "that's training faster once you've done",
    "start": "409239",
    "end": "410589"
  },
  {
    "text": "sharted by s3 key versus fully",
    "start": "410589",
    "end": "412629"
  },
  {
    "text": "replicated and then how you're actually",
    "start": "412629",
    "end": "415269"
  },
  {
    "text": "gonna get it done the first thing you",
    "start": "415269",
    "end": "416860"
  },
  {
    "text": "want to do is chunk your data into",
    "start": "416860",
    "end": "418689"
  },
  {
    "text": "smaller keys right so take that large",
    "start": "418689",
    "end": "421269"
  },
  {
    "text": "file and",
    "start": "421269",
    "end": "422080"
  },
  {
    "text": "just shrink it down right have multiple",
    "start": "422080",
    "end": "424000"
  },
  {
    "text": "files that are just a little bit smaller",
    "start": "424000",
    "end": "425889"
  },
  {
    "text": "you're gonna create an s3 input force a",
    "start": "425889",
    "end": "429159"
  },
  {
    "text": "to make it range so that's that that s3",
    "start": "429159",
    "end": "431110"
  },
  {
    "text": "underscore input code right there and",
    "start": "431110",
    "end": "433659"
  },
  {
    "text": "then just point that to your s3",
    "start": "433659",
    "end": "436419"
  },
  {
    "text": "directory it's all you gotta do okay so",
    "start": "436419",
    "end": "441280"
  },
  {
    "text": "the way this is gonna work in Sage maker",
    "start": "441280",
    "end": "443439"
  },
  {
    "text": "is by utilizing what is called a",
    "start": "443439",
    "end": "446020"
  },
  {
    "text": "parameter server and so in particular",
    "start": "446020",
    "end": "448659"
  },
  {
    "text": "this is how it's going to work for the",
    "start": "448659",
    "end": "450310"
  },
  {
    "text": "built-in algorithms essentially you're",
    "start": "450310",
    "end": "451960"
  },
  {
    "text": "gonna start with your data in s3 right",
    "start": "451960",
    "end": "454719"
  },
  {
    "text": "so you've got your data in that s3",
    "start": "454719",
    "end": "456099"
  },
  {
    "text": "bucket but then you're gonna chunk it so",
    "start": "456099",
    "end": "458710"
  },
  {
    "text": "you have multiple versions",
    "start": "458710",
    "end": "460780"
  },
  {
    "text": "I'm sorry multiple chunks within that",
    "start": "460780",
    "end": "462639"
  },
  {
    "text": "data set right so it's not that full",
    "start": "462639",
    "end": "464199"
  },
  {
    "text": "copy it's that charted by a sirki then",
    "start": "464199",
    "end": "466539"
  },
  {
    "text": "you'll have separate nodes right and",
    "start": "466539",
    "end": "468460"
  },
  {
    "text": "each node is gonna have a local state so",
    "start": "468460",
    "end": "470860"
  },
  {
    "text": "it's has local parameters has its own",
    "start": "470860",
    "end": "473050"
  },
  {
    "text": "local update mechanism that's gonna send",
    "start": "473050",
    "end": "476080"
  },
  {
    "text": "information to this master shared state",
    "start": "476080",
    "end": "479550"
  },
  {
    "text": "host basically that's taking care of all",
    "start": "479550",
    "end": "482830"
  },
  {
    "text": "the local processes and that's handling",
    "start": "482830",
    "end": "484900"
  },
  {
    "text": "no dropouts in the events that that",
    "start": "484900",
    "end": "487360"
  },
  {
    "text": "should happen and so the built-in",
    "start": "487360",
    "end": "489819"
  },
  {
    "text": "algorithms within Sage maker are going",
    "start": "489819",
    "end": "491500"
  },
  {
    "text": "to be leveraging what's called the",
    "start": "491500",
    "end": "492639"
  },
  {
    "text": "parameter server what's cool is that you",
    "start": "492639",
    "end": "495759"
  },
  {
    "text": "can also use the parameter server to",
    "start": "495759",
    "end": "498729"
  },
  {
    "text": "distribute your own tensor flow of",
    "start": "498729",
    "end": "501099"
  },
  {
    "text": "models across multiple nodes right",
    "start": "501099",
    "end": "503620"
  },
  {
    "text": "across multiple ec2 instances so in this",
    "start": "503620",
    "end": "506529"
  },
  {
    "text": "case we're setting up a tensor flow",
    "start": "506529",
    "end": "507969"
  },
  {
    "text": "estimator so again that's that manage",
    "start": "507969",
    "end": "510250"
  },
  {
    "text": "docker container that's pointing to that",
    "start": "510250",
    "end": "512110"
  },
  {
    "text": "tensor flow script and then we're we're",
    "start": "512110",
    "end": "515169"
  },
  {
    "text": "saying that we want to run on to p2",
    "start": "515169",
    "end": "518018"
  },
  {
    "text": "excels right so we're going to run on",
    "start": "518019",
    "end": "519430"
  },
  {
    "text": "two GPUs we've got the version of tensor",
    "start": "519430",
    "end": "521768"
  },
  {
    "text": "flow that we're working with and then",
    "start": "521769",
    "end": "523360"
  },
  {
    "text": "we're saying that we're just gonna use",
    "start": "523360",
    "end": "525399"
  },
  {
    "text": "the parameter server right and then",
    "start": "525399",
    "end": "527470"
  },
  {
    "text": "we'll send that out to s3 once it's",
    "start": "527470",
    "end": "529959"
  },
  {
    "text": "finished okay the next thing you want to",
    "start": "529959",
    "end": "534040"
  },
  {
    "text": "know about is when you're distributing",
    "start": "534040",
    "end": "535120"
  },
  {
    "text": "tensor flow specifically is getting a",
    "start": "535120",
    "end": "537760"
  },
  {
    "text": "global optimizer actually so when you're",
    "start": "537760",
    "end": "539980"
  },
  {
    "text": "building your optimizer right this one's",
    "start": "539980",
    "end": "541990"
  },
  {
    "text": "doing gradient ascent and then you're",
    "start": "541990",
    "end": "543250"
  },
  {
    "text": "trying to minimize the loss function",
    "start": "543250",
    "end": "544480"
  },
  {
    "text": "that you built you want your global step",
    "start": "544480",
    "end": "548050"
  },
  {
    "text": "to be taking global steps that is you",
    "start": "548050",
    "end": "550029"
  },
  {
    "text": "want your optimizer to be taking global",
    "start": "550029",
    "end": "552370"
  },
  {
    "text": "steps so that that's a method that you",
    "start": "552370",
    "end": "554380"
  },
  {
    "text": "can pass into",
    "start": "554380",
    "end": "555350"
  },
  {
    "text": "tensorflow model that tells it you know",
    "start": "555350",
    "end": "557450"
  },
  {
    "text": "hey I'm running a distributed process",
    "start": "557450",
    "end": "559910"
  },
  {
    "text": "here but what if we don't want to",
    "start": "559910",
    "end": "562910"
  },
  {
    "start": "561000",
    "end": "656000"
  },
  {
    "text": "retrain on our entire data set right",
    "start": "562910",
    "end": "565610"
  },
  {
    "text": "what if we are in marketing and within",
    "start": "565610",
    "end": "568370"
  },
  {
    "text": "marketing we trained our model on",
    "start": "568370",
    "end": "570530"
  },
  {
    "text": "everything that happened in 2018 right",
    "start": "570530",
    "end": "573470"
  },
  {
    "text": "but then going through 2019 we want to",
    "start": "573470",
    "end": "575810"
  },
  {
    "text": "retrain every month",
    "start": "575810",
    "end": "577280"
  },
  {
    "text": "but we want to retrain on just the new",
    "start": "577280",
    "end": "579080"
  },
  {
    "text": "data right we are not trying to retrain",
    "start": "579080",
    "end": "580970"
  },
  {
    "text": "on all the terabytes that we have just",
    "start": "580970",
    "end": "583100"
  },
  {
    "text": "the new stuff and so when you're in that",
    "start": "583100",
    "end": "584780"
  },
  {
    "text": "scenario you should be thinking about",
    "start": "584780",
    "end": "586910"
  },
  {
    "text": "incremental retraining right an",
    "start": "586910",
    "end": "589070"
  },
  {
    "text": "incremental retraining is a way that you",
    "start": "589070",
    "end": "590780"
  },
  {
    "text": "can retrain your model on just the new",
    "start": "590780",
    "end": "593060"
  },
  {
    "text": "content so you can slightly increase",
    "start": "593060",
    "end": "595370"
  },
  {
    "text": "your objective performance and also have",
    "start": "595370",
    "end": "597650"
  },
  {
    "text": "it just be more responsive to the newest",
    "start": "597650",
    "end": "599360"
  },
  {
    "text": "data and so incremental retraining there",
    "start": "599360",
    "end": "602840"
  },
  {
    "text": "are a couple ways we can get this done",
    "start": "602840",
    "end": "604130"
  },
  {
    "text": "that function up there is how you can",
    "start": "604130",
    "end": "606770"
  },
  {
    "text": "write your own incremental retrain er",
    "start": "606770",
    "end": "609800"
  },
  {
    "text": "using MX net and so you can absolutely",
    "start": "609800",
    "end": "612440"
  },
  {
    "text": "perform incremental retraining in a",
    "start": "612440",
    "end": "614690"
  },
  {
    "text": "variety of deep learning frameworks M",
    "start": "614690",
    "end": "617180"
  },
  {
    "text": "extent and tester flow are one of them",
    "start": "617180",
    "end": "618650"
  },
  {
    "text": "or some of them but essentially you'll",
    "start": "618650",
    "end": "620630"
  },
  {
    "text": "point to a job that you previously ran",
    "start": "620630",
    "end": "623560"
  },
  {
    "text": "specifically point to that model",
    "start": "623560",
    "end": "625250"
  },
  {
    "text": "artifact here that is an onyx model",
    "start": "625250",
    "end": "628490"
  },
  {
    "text": "artifact and then we're gonna load that",
    "start": "628490",
    "end": "630470"
  },
  {
    "text": "in and we're gonna load that into MX net",
    "start": "630470",
    "end": "632720"
  },
  {
    "text": "right and then we'll we'll export some",
    "start": "632720",
    "end": "635450"
  },
  {
    "text": "of the argh params and then we'll load",
    "start": "635450",
    "end": "637340"
  },
  {
    "text": "those our params into a new model right",
    "start": "637340",
    "end": "640100"
  },
  {
    "text": "into a new process that's gonna run if",
    "start": "640100",
    "end": "642680"
  },
  {
    "text": "that makes you feel queasy but you still",
    "start": "642680",
    "end": "644690"
  },
  {
    "text": "want to do incremental retraining then",
    "start": "644690",
    "end": "646760"
  },
  {
    "text": "they go for the built-in algorithms",
    "start": "646760",
    "end": "647960"
  },
  {
    "text": "right image classification and object",
    "start": "647960",
    "end": "650330"
  },
  {
    "text": "detection are built-in algorithms within",
    "start": "650330",
    "end": "652490"
  },
  {
    "text": "Amazon stage maker that both natively",
    "start": "652490",
    "end": "654170"
  },
  {
    "text": "support incremental retraining okay",
    "start": "654170",
    "end": "656930"
  },
  {
    "start": "656000",
    "end": "918000"
  },
  {
    "text": "let's check out an example so over here",
    "start": "656930",
    "end": "661550"
  },
  {
    "text": "again we are on a sage maker notebook",
    "start": "661550",
    "end": "664100"
  },
  {
    "text": "instance the u.s. distel one this is our",
    "start": "664100",
    "end": "665780"
  },
  {
    "text": "test d'emic tester and again this is an",
    "start": "665780",
    "end": "668900"
  },
  {
    "text": "example notebook that is public so you",
    "start": "668900",
    "end": "671600"
  },
  {
    "text": "can just pull down this example from the",
    "start": "671600",
    "end": "674000"
  },
  {
    "text": "from the sage maker examples alright",
    "start": "674000",
    "end": "676460"
  },
  {
    "text": "we're getting in our sage maker session",
    "start": "676460",
    "end": "678650"
  },
  {
    "text": "right we've got our execution room right",
    "start": "678650",
    "end": "680960"
  },
  {
    "text": "here we're gonna have our training data",
    "start": "680960",
    "end": "684550"
  },
  {
    "text": "right we're gonna get a script",
    "start": "684550",
    "end": "688320"
  },
  {
    "text": "for distributed training so first off",
    "start": "688320",
    "end": "692460"
  },
  {
    "text": "let me orient you here right so this is",
    "start": "692460",
    "end": "699360"
  },
  {
    "text": "the directory that we're working in and",
    "start": "699360",
    "end": "701780"
  },
  {
    "text": "this is our M miss top UI whoops looks",
    "start": "701780",
    "end": "706410"
  },
  {
    "text": "like that one's not not working with us",
    "start": "706410",
    "end": "708660"
  },
  {
    "text": "no problem so this was printed out in",
    "start": "708660",
    "end": "711030"
  },
  {
    "text": "the notebook so we're just gonna check",
    "start": "711030",
    "end": "712290"
  },
  {
    "text": "it out here",
    "start": "712290",
    "end": "714709"
  },
  {
    "text": "great so this is a CNN model right we've",
    "start": "715490",
    "end": "718830"
  },
  {
    "text": "got features labels and mode this first",
    "start": "718830",
    "end": "722880"
  },
  {
    "text": "one is just reading in our features",
    "start": "722880",
    "end": "724530"
  },
  {
    "text": "we've got a 2d convolutional layer here",
    "start": "724530",
    "end": "728570"
  },
  {
    "text": "yeah 32 filters kernel size of 5 by 5",
    "start": "728570",
    "end": "732720"
  },
  {
    "text": "it's a Rayleigh activation function very",
    "start": "732720",
    "end": "734790"
  },
  {
    "text": "common that's gonna be followed by a max",
    "start": "734790",
    "end": "737040"
  },
  {
    "text": "pooling layer here again - I - we've got",
    "start": "737040",
    "end": "740520"
  },
  {
    "text": "another convolutional layer here also",
    "start": "740520",
    "end": "742440"
  },
  {
    "text": "Rayleigh activation function another max",
    "start": "742440",
    "end": "745110"
  },
  {
    "text": "pooling we've got a reshape we've got a",
    "start": "745110",
    "end": "747120"
  },
  {
    "text": "dense I've got a drop out layer here and",
    "start": "747120",
    "end": "751020"
  },
  {
    "text": "then here they're predictions using",
    "start": "751020",
    "end": "755910"
  },
  {
    "text": "loads cool and so here's our loss",
    "start": "755910",
    "end": "759030"
  },
  {
    "text": "function and this is the piece that I",
    "start": "759030",
    "end": "762360"
  },
  {
    "text": "want you to really see right global step",
    "start": "762360",
    "end": "764040"
  },
  {
    "text": "is TF train get global stuff and so when",
    "start": "764040",
    "end": "768780"
  },
  {
    "text": "you add that line basically that is a",
    "start": "768780",
    "end": "771480"
  },
  {
    "text": "signal to the tensor flow framework that",
    "start": "771480",
    "end": "773820"
  },
  {
    "text": "you are gonna be able to run on multiple",
    "start": "773820",
    "end": "775800"
  },
  {
    "text": "nodes alright cool so the rest of that",
    "start": "775800",
    "end": "781170"
  },
  {
    "text": "should follow and so the setup for this",
    "start": "781170",
    "end": "784260"
  },
  {
    "text": "is is again really simple we're using",
    "start": "784260",
    "end": "787200"
  },
  {
    "text": "the the tensor flow managed container",
    "start": "787200",
    "end": "790380"
  },
  {
    "text": "within Sage maker so that's right here",
    "start": "790380",
    "end": "792090"
  },
  {
    "text": "we've got our entry point as that m-miss",
    "start": "792090",
    "end": "794310"
  },
  {
    "text": "- I got our stage make a roll and then",
    "start": "794310",
    "end": "797280"
  },
  {
    "text": "here are those 2 p2 XLS that we're",
    "start": "797280",
    "end": "801030"
  },
  {
    "text": "spinning up alright that's our version",
    "start": "801030",
    "end": "803250"
  },
  {
    "text": "of Python that's our framework version",
    "start": "803250",
    "end": "804840"
  },
  {
    "text": "and then that's the parameter server",
    "start": "804840",
    "end": "807150"
  },
  {
    "text": "right we're just passing that in as an",
    "start": "807150",
    "end": "808950"
  },
  {
    "text": "argument and saying saying that we want",
    "start": "808950",
    "end": "811200"
  },
  {
    "text": "to actually use it and then down here we",
    "start": "811200",
    "end": "813660"
  },
  {
    "text": "call estimator dot fit all right that",
    "start": "813660",
    "end": "816150"
  },
  {
    "text": "process is gonna is going to run then",
    "start": "816150",
    "end": "818160"
  },
  {
    "text": "we'll deploy that to a model endpoint",
    "start": "818160",
    "end": "819690"
  },
  {
    "text": "and will invoke the prediction",
    "start": "819690",
    "end": "822389"
  },
  {
    "text": "let's check it out so we've got training",
    "start": "822389",
    "end": "824459"
  },
  {
    "text": "jobs right over here and looks like",
    "start": "824459",
    "end": "829139"
  },
  {
    "text": "everything is working fine so thanks",
    "start": "829139",
    "end": "831809"
  },
  {
    "text": "let's switch back all right so some pro",
    "start": "831809",
    "end": "835619"
  },
  {
    "text": "tips when you're thinking about how to",
    "start": "835619",
    "end": "836909"
  },
  {
    "text": "add more data first off I really want",
    "start": "836909",
    "end": "840029"
  },
  {
    "text": "you to use what's there right there are",
    "start": "840029",
    "end": "841739"
  },
  {
    "text": "two hundred example notebooks out there",
    "start": "841739",
    "end": "843479"
  },
  {
    "text": "that by and large work off a shelf so",
    "start": "843479",
    "end": "846359"
  },
  {
    "text": "you can run those things see how we're",
    "start": "846359",
    "end": "848939"
  },
  {
    "text": "thinking about distributed data already",
    "start": "848939",
    "end": "850919"
  },
  {
    "text": "and then just modify it to use what's",
    "start": "850919",
    "end": "853049"
  },
  {
    "text": "already there",
    "start": "853049",
    "end": "854099"
  },
  {
    "text": "also I want you to think about pipe mode",
    "start": "854099",
    "end": "856079"
  },
  {
    "text": "pipe mode is a way that you can stream",
    "start": "856079",
    "end": "858359"
  },
  {
    "text": "your data to go from s3 to those",
    "start": "858359",
    "end": "860909"
  },
  {
    "text": "clusters the reason streaming is your",
    "start": "860909",
    "end": "863369"
  },
  {
    "text": "friend as we learned in a previous video",
    "start": "863369",
    "end": "865319"
  },
  {
    "text": "is that it help makes your model",
    "start": "865319",
    "end": "867419"
  },
  {
    "text": "training faster it makes your inference",
    "start": "867419",
    "end": "869579"
  },
  {
    "text": "faster it just it just greases the",
    "start": "869579",
    "end": "872189"
  },
  {
    "text": "wheels and makes everything work out a",
    "start": "872189",
    "end": "873749"
  },
  {
    "text": "lot easier so so definitely try and use",
    "start": "873749",
    "end": "875519"
  },
  {
    "text": "pipe mode also incremental retraining is",
    "start": "875519",
    "end": "878519"
  },
  {
    "text": "a awesome way that you can save a bunch",
    "start": "878519",
    "end": "881009"
  },
  {
    "text": "of training time right because if you",
    "start": "881009",
    "end": "882629"
  },
  {
    "text": "can incrementally retrain on what",
    "start": "882629",
    "end": "884220"
  },
  {
    "text": "happened last week or last month rather",
    "start": "884220",
    "end": "886470"
  },
  {
    "text": "than retraining your entire data from",
    "start": "886470",
    "end": "888299"
  },
  {
    "text": "scratch those are just dollars in your",
    "start": "888299",
    "end": "889859"
  },
  {
    "text": "bank account right that's just time back",
    "start": "889859",
    "end": "891299"
  },
  {
    "text": "to you that you can use to build other",
    "start": "891299",
    "end": "893039"
  },
  {
    "text": "features so that thank you very much I",
    "start": "893039",
    "end": "897539"
  },
  {
    "text": "hope you enjoyed our video on",
    "start": "897539",
    "end": "899459"
  },
  {
    "text": "distributed training and Amazon Sage",
    "start": "899459",
    "end": "901229"
  },
  {
    "text": "Maker my name is Emily Weber and I'm a",
    "start": "901229",
    "end": "903419"
  },
  {
    "text": "machine learning specialist at Amazon",
    "start": "903419",
    "end": "904949"
  },
  {
    "text": "Web Services thank you for your time and",
    "start": "904949",
    "end": "907409"
  },
  {
    "text": "I hope you have a great rest of your day",
    "start": "907409",
    "end": "909359"
  },
  {
    "text": "happy coding",
    "start": "909359",
    "end": "912439"
  }
]
[
  {
    "text": "Hello. My name is Andrew Hitchcock and I'm\nengineer on the Amazon Elastic MapReduce team.",
    "start": "5140",
    "end": "11309"
  },
  {
    "text": "Today I'm going to demonstrate how to run\nApache Hive on Elastic MapReduce.",
    "start": "11309",
    "end": "15719"
  },
  {
    "text": "Elastic MapReduce is a service which runs\nthe Hadoop framework on Amazon EC2.",
    "start": "15719",
    "end": "21010"
  },
  {
    "text": "Durable storage for the cluster is provided\nby Amazon S3.",
    "start": "21010",
    "end": "25850"
  },
  {
    "text": "Hive is an open source, highly scalable data\nwarehouse which runs on top of Hadoop.",
    "start": "25850",
    "end": "30849"
  },
  {
    "text": "You interact with Hive by writing SQL-like\nqueries in a language called HiveQL.",
    "start": "30849",
    "end": "35239"
  },
  {
    "text": "They are compiled down to MapReduce jobs and\nrun on your Hadoop cluster.",
    "start": "35239",
    "end": "40260"
  },
  {
    "text": "For the purpose of this demo, we are going\nto use the example of an ad serving company.",
    "start": "40260",
    "end": "45218"
  },
  {
    "text": "We have a fleet of ad servers in EC2 which\nupload their logs to S3 every five minutes.",
    "start": "45219",
    "end": "51590"
  },
  {
    "text": "These logs are stored in a Hive table.",
    "start": "51590",
    "end": "53629"
  },
  {
    "text": "We spawn an Elastic MapReduce job flow to\njoin the two tables and store the result back",
    "start": "53629",
    "end": "58920"
  },
  {
    "text": "in S3.",
    "start": "58920",
    "end": "61268"
  },
  {
    "text": "For this demonstration I'm going to show you\nhow to start an interactive job flow using",
    "start": "61269",
    "end": "66000"
  },
  {
    "text": "the Elastic MapReduce console,",
    "start": "66000",
    "end": "67780"
  },
  {
    "text": "we'll read tables that are stored in S3,",
    "start": "67780",
    "end": "69990"
  },
  {
    "text": "I'll show you how to use a custom JSON SerDe\nthat was written by Amazon,",
    "start": "69990",
    "end": "74670"
  },
  {
    "text": "and also the recover partition feature that\nwas written by Amazon.",
    "start": "74670",
    "end": "78390"
  },
  {
    "text": "Then we'll join tables and insert them back\ninto a partitioned table.",
    "start": "78390",
    "end": "84140"
  },
  {
    "text": "To begin, we should pull up the AWS console,",
    "start": "84140",
    "end": "89340"
  },
  {
    "text": "and navigate to the Amazon Elastic MapReduce\ntab.",
    "start": "89340",
    "end": "93469"
  },
  {
    "text": "From here, we can create a new job flow.",
    "start": "93470",
    "end": "100820"
  },
  {
    "text": "We should begin by giving it a descriptive\nname. This helps us identify it later when",
    "start": "100820",
    "end": "104829"
  },
  {
    "text": "we have multiple jobs running.",
    "start": "104829",
    "end": "107899"
  },
  {
    "text": "We can then select which type of job flow\nwe'd like to run, which in this case is a",
    "start": "107899",
    "end": "112060"
  },
  {
    "text": "Hive program.",
    "start": "112060",
    "end": "114210"
  },
  {
    "text": "If we click continue, we'll be taken to the\nnext step in starting our job flow.",
    "start": "114210",
    "end": "119030"
  },
  {
    "text": "Here you can see two options, Hive script\nor interactive Hive session.",
    "start": "119030",
    "end": "123740"
  },
  {
    "text": "The interactive Hive session allows you to\nSSH to your cluster and run your queries using",
    "start": "123740",
    "end": "128530"
  },
  {
    "text": "the Hive command line client.",
    "start": "128530",
    "end": "130259"
  },
  {
    "text": "The Hive script option allows you to run a\nHiveQL script stored in Amazon S3. This is",
    "start": "130259",
    "end": "135900"
  },
  {
    "text": "ideal for batch processes.",
    "start": "135900",
    "end": "138200"
  },
  {
    "text": "However, since I want to demonstrate the features\nof Hive, we'll create an interactive job flow.",
    "start": "138200",
    "end": "146480"
  },
  {
    "text": "This next page allows you to configure the\nEC2 instances that will be used to power your",
    "start": "146480",
    "end": "150940"
  },
  {
    "text": "cluster.",
    "start": "150940",
    "end": "151940"
  },
  {
    "text": "I'm going to start by bumping the number of\ninstances up to 10 and selecting the m1.xlarge",
    "start": "151940",
    "end": "158090"
  },
  {
    "text": "instance type.",
    "start": "158090",
    "end": "159090"
  },
  {
    "text": "Under advanced options, you'll find the Amazon\nS3 log path.",
    "start": "159090",
    "end": "162860"
  },
  {
    "text": "If specified when starting your job flow,\nwe'll upload all the job flow logs to your",
    "start": "162860",
    "end": "167560"
  },
  {
    "text": "bucket.",
    "start": "167560",
    "end": "168750"
  },
  {
    "text": "When creating an interactive job flow an EC2\nkeypair. This is what allows you to SSH onto",
    "start": "168750",
    "end": "176019"
  },
  {
    "text": "the master node once your cluster starts.",
    "start": "176019",
    "end": "180659"
  },
  {
    "text": "The final page lets you review your job flow\nsettings.",
    "start": "180659",
    "end": "183700"
  },
  {
    "text": "You can go back and change things that are\nwrong, but if everything looks okay, go ahead",
    "start": "183700",
    "end": "187989"
  },
  {
    "text": "and click create job flow.",
    "start": "187989",
    "end": "190890"
  },
  {
    "text": "You'll see a confirmation page if everything\nwent okay.",
    "start": "190890",
    "end": "194970"
  },
  {
    "text": "Now we are back at the list of job flows.\nYou can click on your job flow to see more",
    "start": "194970",
    "end": "198720"
  },
  {
    "text": "details.",
    "start": "198720",
    "end": "200569"
  },
  {
    "text": "If you scroll down you can see that your job\nflow already has one step, which sets up Hive",
    "start": "200569",
    "end": "205480"
  },
  {
    "text": "on the master node.",
    "start": "205480",
    "end": "211129"
  },
  {
    "text": "In a little while you'll see the public DNS\nname of your master node. It starts off blank",
    "start": "211130",
    "end": "216280"
  },
  {
    "text": "which means the node hasn't started yet.",
    "start": "216280",
    "end": "220400"
  },
  {
    "text": "You can refresh the page to see the status\nof your job flow as it starts.",
    "start": "220400",
    "end": "225849"
  },
  {
    "text": "If we look again we'll see that the master\nhas checked in but the job flow is still in",
    "start": "225849",
    "end": "230280"
  },
  {
    "text": "the starting state and not yet ready for jobs.",
    "start": "230280",
    "end": "234180"
  },
  {
    "text": "While the job flow is starting, we can grab\nthe job flow ID and switch to the Elastic",
    "start": "234180",
    "end": "239269"
  },
  {
    "text": "MapReduce command line client.",
    "start": "239270",
    "end": "241220"
  },
  {
    "text": "Using the client, we can list the job flow\nwe are interested in.",
    "start": "241220",
    "end": "245019"
  },
  {
    "text": "This gives us details such as job flow ID,\njob flow state, master public DNS name, job",
    "start": "245019",
    "end": "250989"
  },
  {
    "text": "flow name, and the status of the various steps.",
    "start": "250989",
    "end": "253470"
  },
  {
    "text": "I should note, I configured my client before\nthe demo.",
    "start": "253470",
    "end": "257579"
  },
  {
    "text": "If this is your first time using the client,\nyou'll need to create a credentials.json file",
    "start": "257580",
    "end": "262289"
  },
  {
    "text": "and include your AWS access key and secret\nkey.",
    "start": "262290",
    "end": "267010"
  },
  {
    "text": "Now the job flow is running and the first\nstep is being executed.",
    "start": "267010",
    "end": "270820"
  },
  {
    "text": "We are looking for the job flow to reach the\nwaiting state and for the setup hive step",
    "start": "270820",
    "end": "275000"
  },
  {
    "text": "to complete.",
    "start": "275000",
    "end": "275660"
  }
]
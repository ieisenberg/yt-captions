[
  {
    "start": "0",
    "end": "184000"
  },
  {
    "text": "sorry for the technical difficulties thanks for joining the d8t 303 closer look at",
    "start": "3040",
    "end": "10480"
  },
  {
    "text": "amazon rds for michael's microsoft sql server session my name is sergey sakalenka",
    "start": "10480",
    "end": "16720"
  },
  {
    "text": "i'm a product manager at aws and we have ellen parsons from video who's going to",
    "start": "16720",
    "end": "23439"
  },
  {
    "text": "join on stage to talk about video's use of rds sql server",
    "start": "23439",
    "end": "31359"
  },
  {
    "text": "over the next hour we are going to spend time on looking at best practices for security performance data migration",
    "start": "31359",
    "end": "39920"
  },
  {
    "text": "and data durability a recent forester report identified those four tasks",
    "start": "39920",
    "end": "46960"
  },
  {
    "text": "as one of the most important uh time sinks or tasks where developers",
    "start": "46960",
    "end": "53680"
  },
  {
    "text": "application developers and database developers spend their time on so we're going to be talking about best practices to",
    "start": "53680",
    "end": "59840"
  },
  {
    "text": "accomplish these tasks i am extremely happy to have ellen uh ellen",
    "start": "59840",
    "end": "65600"
  },
  {
    "text": "ellen parsons from video joining me just a few minutes to talk about",
    "start": "65600",
    "end": "72320"
  },
  {
    "text": "videos use of amazon rds",
    "start": "72320",
    "end": "76400"
  },
  {
    "text": "let's start with security best practices",
    "start": "77600",
    "end": "82080"
  },
  {
    "text": "we're going to start with a with a sample where you have a database and an application that accesses the database",
    "start": "83520",
    "end": "89840"
  },
  {
    "text": "and the major recommendation to you here is to control access to the database",
    "start": "89840",
    "end": "95200"
  },
  {
    "text": "starting with creating a user application related user that doesn't",
    "start": "95200",
    "end": "101360"
  },
  {
    "text": "have permissions to do any ddl statements and is only focused on writing and reading to the database so",
    "start": "101360",
    "end": "108560"
  },
  {
    "text": "use database access mechanisms to limit access to your database through",
    "start": "108560",
    "end": "114320"
  },
  {
    "text": "defining the separate user the next layer of protection that amazon",
    "start": "114320",
    "end": "120159"
  },
  {
    "text": "rds offers to you is a network layer protection you can",
    "start": "120159",
    "end": "125200"
  },
  {
    "text": "define security groups and these security groups will allow you to define",
    "start": "125200",
    "end": "130319"
  },
  {
    "text": "inbound and outbound rules you can you can set which hosts can access your database etc",
    "start": "130319",
    "end": "140000"
  },
  {
    "text": "yet another layer of protection available uh through amazon is the virtual virtual private cloud",
    "start": "140239",
    "end": "146400"
  },
  {
    "text": "vpcs vpcs are logically independent chunks of",
    "start": "146400",
    "end": "151840"
  },
  {
    "text": "sections of amazon web services you can divide the vpc into subnets you can have a",
    "start": "151840",
    "end": "159440"
  },
  {
    "text": "private subnet where you will run your database and application servers and you can have a public subnet where",
    "start": "159440",
    "end": "166560"
  },
  {
    "text": "you will deploy your web servers only only machines in the public subnet",
    "start": "166560",
    "end": "172879"
  },
  {
    "text": "can access your private net private subnet this way you prevent internet access to your",
    "start": "172879",
    "end": "180159"
  },
  {
    "text": "secure data in the database servers",
    "start": "180159",
    "end": "185360"
  },
  {
    "start": "184000",
    "end": "184000"
  },
  {
    "text": "last but not least you should consider using identity and access management",
    "start": "185360",
    "end": "191760"
  },
  {
    "text": "functionality offered through amazon for defining and managing permissions for",
    "start": "191760",
    "end": "196800"
  },
  {
    "text": "individual users the next recommendation i would like to",
    "start": "196800",
    "end": "201920"
  },
  {
    "text": "share with you is encrypting your data you can do encryption for data",
    "start": "201920",
    "end": "207280"
  },
  {
    "text": "in transit when it travels between your database server and the application server it's very",
    "start": "207280",
    "end": "212720"
  },
  {
    "text": "easy to do to do that you enable ssl which is the encryption technology",
    "start": "212720",
    "end": "218560"
  },
  {
    "text": "that supports the in-transit protection of your data by downloading a the public certificate",
    "start": "218560",
    "end": "225760"
  },
  {
    "text": "for ids and using the microsoft management console",
    "start": "225760",
    "end": "230799"
  },
  {
    "text": "for importing the certificate into your application server os",
    "start": "230799",
    "end": "237840"
  },
  {
    "text": "the last step for using ssl is to enable the encryption in your",
    "start": "237840",
    "end": "243840"
  },
  {
    "text": "connection string in addition to protecting data in",
    "start": "243840",
    "end": "249280"
  },
  {
    "text": "transit you can also use transparent data encryption to protect your data at rest",
    "start": "249280",
    "end": "256400"
  },
  {
    "text": "this is a feature that we just recently launched many of you will probably not be familiar with that so i'll spend a",
    "start": "256400",
    "end": "261840"
  },
  {
    "text": "little bit of time talking about it tge is a native technology supported by",
    "start": "261840",
    "end": "267440"
  },
  {
    "text": "microsoft and we recently enabled it into in in our enterprise edition rds for sql server it",
    "start": "267440",
    "end": "275520"
  },
  {
    "text": "encrypts data before it's written to disk and it decrypts data when it's being read from disk to",
    "start": "275520",
    "end": "281120"
  },
  {
    "text": "memory td is available for enterprise edition databases",
    "start": "281120",
    "end": "286160"
  },
  {
    "text": "it's available for both sql server 2008 and sql server 2012.",
    "start": "286160",
    "end": "291840"
  },
  {
    "text": "what you do to enable tda is adding a option to an option group and enabling",
    "start": "291840",
    "end": "298320"
  },
  {
    "text": "that option group for your sql server database option groups are new for sql server with the",
    "start": "298320",
    "end": "304240"
  },
  {
    "text": "addition of tde so i'm going to show you how to do it in the rds management console what you see",
    "start": "304240",
    "end": "311360"
  },
  {
    "text": "right now on the screen is the option groups option groups list",
    "start": "311360",
    "end": "316720"
  },
  {
    "text": "in my in my account doesn't have any custom options just the default ones",
    "start": "316720",
    "end": "321840"
  },
  {
    "text": "so i'm going to go and click on the create group button which leads to me leads me to the option group screen",
    "start": "321840",
    "end": "329120"
  },
  {
    "text": "when i need to enter the edition of the database or the i'm sorry the engine of the that i would",
    "start": "329120",
    "end": "335280"
  },
  {
    "text": "like to select as i said td is only available for enterprise edition so select sql server ee and then i also need to",
    "start": "335280",
    "end": "343919"
  },
  {
    "text": "select my major engine version you can select 11.0",
    "start": "343919",
    "end": "349759"
  },
  {
    "text": "for sql server 2012. and 10.5 for sql server 2008",
    "start": "349759",
    "end": "357840"
  },
  {
    "text": "once i created my option group i can easily add the tdo option apply it immediately",
    "start": "358000",
    "end": "364400"
  },
  {
    "text": "and be done with it well not here after creating the option group the the next simple step is to enable",
    "start": "364400",
    "end": "372080"
  },
  {
    "text": "tda in the instance i would like to encrypt i can either use an existing instance",
    "start": "372080",
    "end": "378800"
  },
  {
    "text": "or i can create a new instance a new sql server instance and use the option group during the",
    "start": "378800",
    "end": "386960"
  },
  {
    "text": "launch wizard in my particular case i'm going to encrypt an existing instance called",
    "start": "386960",
    "end": "393120"
  },
  {
    "text": "sso10 the only task task here is to change the",
    "start": "393120",
    "end": "399280"
  },
  {
    "text": "option group from the default one to the custom one that they just created",
    "start": "399280",
    "end": "406479"
  },
  {
    "text": "at this point rds will deploy a public certificate into my instance that",
    "start": "407759",
    "end": "414080"
  },
  {
    "text": "will contain the master instance key the interesting part about tde is that",
    "start": "414080",
    "end": "419680"
  },
  {
    "text": "there are a couple of keys that are used for protecting your data at the at the most basic level",
    "start": "419680",
    "end": "427599"
  },
  {
    "text": "you have the database encryption key the database encryption key is the key that you use to encrypt your",
    "start": "427599",
    "end": "434560"
  },
  {
    "text": "user database now for protecting the key the database encryption key",
    "start": "434560",
    "end": "441120"
  },
  {
    "text": "sql server uses a another key called the master instance key this key",
    "start": "441120",
    "end": "449120"
  },
  {
    "text": "the whole purpose of the master instance key is just to encrypt the database encryption keys",
    "start": "449120",
    "end": "454800"
  },
  {
    "text": "so up to this point what i've done is i enabled the option the tdu option for sql server rds has",
    "start": "454800",
    "end": "461280"
  },
  {
    "text": "pushed out the certificate that contains the master encryption key",
    "start": "461280",
    "end": "466479"
  },
  {
    "text": "into my instance i can now go to ssms and run a couple of sql statements",
    "start": "466479",
    "end": "472479"
  },
  {
    "text": "that will enable encryption in my database the first statement is is looking for",
    "start": "472479",
    "end": "478879"
  },
  {
    "text": "the certificate that was just added by rds uh the string pattern that you need to",
    "start": "478879",
    "end": "485120"
  },
  {
    "text": "look for is rds td certificate so i'll find this uh",
    "start": "485120",
    "end": "490160"
  },
  {
    "text": "the string and i'll save it in and reuse it in my next statements",
    "start": "490160",
    "end": "496000"
  },
  {
    "text": "i will create the database encryption key using the previously found certificate",
    "start": "496000",
    "end": "501440"
  },
  {
    "text": "and i will turn on database encryption",
    "start": "501440",
    "end": "507840"
  },
  {
    "text": "the la sorry the last couple of statements really just checked that encryption has taken hold and my databases are",
    "start": "509599",
    "end": "516719"
  },
  {
    "text": "encrypted the first select chooses or searches for databases where the",
    "start": "516719",
    "end": "522719"
  },
  {
    "text": "uh is encrypted flag is set to one and as you see at the bottom um the database that i wanted to encrypt",
    "start": "522719",
    "end": "529120"
  },
  {
    "text": "is indeed one of such databases the second select is just confirming",
    "start": "529120",
    "end": "534320"
  },
  {
    "text": "uh all the database that all the databases that have the database encryption key",
    "start": "534320",
    "end": "539519"
  },
  {
    "text": "provisioned to them and again the output shows i have two databases with database encryption keys",
    "start": "539519",
    "end": "545360"
  },
  {
    "text": "uh the first one is tempdb and the other one is my user database that i wanted to encrypt",
    "start": "545360",
    "end": "552080"
  },
  {
    "text": "as easy as that let's look at performance best practices",
    "start": "552160",
    "end": "557600"
  },
  {
    "text": "when we typically talk about performance we think about two two goals for that we want to",
    "start": "557600",
    "end": "563279"
  },
  {
    "text": "optimize for the first goal is increasing throughput throughput typically is measured by read",
    "start": "563279",
    "end": "570080"
  },
  {
    "text": "of write operations per second and it's a measure of how fast my database can read or write to disk",
    "start": "570080",
    "end": "577680"
  },
  {
    "text": "the the other operation or the other goal that we would like to optimize for is decreasing",
    "start": "577680",
    "end": "584480"
  },
  {
    "text": "latency latency is measured in milliseconds and shows typically tells me how fast can i",
    "start": "584480",
    "end": "592000"
  },
  {
    "text": "read from the database individual records and how fast can i write to the database",
    "start": "592000",
    "end": "598160"
  },
  {
    "text": "the three techniques that i have on the slide will help you with increasing throughput",
    "start": "598480",
    "end": "604320"
  },
  {
    "text": "the first one is push button scaling the second one is b2b shards and the",
    "start": "604320",
    "end": "609360"
  },
  {
    "start": "609000",
    "end": "609000"
  },
  {
    "text": "third one is provision diops revision diops will also help you with",
    "start": "609360",
    "end": "615360"
  },
  {
    "text": "decreasing latency let's look at it in detail over the next couple of minutes",
    "start": "615360",
    "end": "621680"
  },
  {
    "start": "619000",
    "end": "619000"
  },
  {
    "text": "push button scaling is a simple technique to scale your database vertically you can",
    "start": "621680",
    "end": "628640"
  },
  {
    "text": "start with very small instances at the beginning of your usage of rds maybe with a m1 small that",
    "start": "628640",
    "end": "636560"
  },
  {
    "text": "only has one virtual core and 1.7 gigs and once you realize that the demand for",
    "start": "636560",
    "end": "643360"
  },
  {
    "text": "your database is growing you can scale that instance to",
    "start": "643360",
    "end": "648640"
  },
  {
    "text": "m2 4x large box which is a eight core instance with 64 gigabytes of",
    "start": "648640",
    "end": "655920"
  },
  {
    "text": "ram another way to scale is to scale horizontally",
    "start": "655920",
    "end": "661600"
  },
  {
    "text": "you accomplish that by dividing your database into smaller chunks",
    "start": "661600",
    "end": "667120"
  },
  {
    "text": "and these chunks are called shards the way you divide your database into shards is by selecting",
    "start": "667920",
    "end": "674160"
  },
  {
    "text": "a key perhaps the customer id and then deciding that all all data related to customer id",
    "start": "674160",
    "end": "681440"
  },
  {
    "text": "starting with a zero would go to the zero chart all all records related to customer ids",
    "start": "681440",
    "end": "688160"
  },
  {
    "text": "touching with one will go to the first chart and so on uh potentially you can have hundreds of",
    "start": "688160",
    "end": "694240"
  },
  {
    "text": "shards we have customers who have hundreds of shards deployed and you can scale your your instances to",
    "start": "694240",
    "end": "702240"
  },
  {
    "text": "dozens of terabytes",
    "start": "702240",
    "end": "705360"
  },
  {
    "text": "provision they ops gives you give you the ability to reserve input output operations",
    "start": "707760",
    "end": "714800"
  },
  {
    "text": "that cannot that cannot be used by anyone else who is running on the same",
    "start": "714800",
    "end": "722079"
  },
  {
    "text": "physical machine as your rds instance we support instances up to one terabyte",
    "start": "722480",
    "end": "729440"
  },
  {
    "text": "in size rds sql server does and uh idea sql server also supports up to ten thousand",
    "start": "729440",
    "end": "735440"
  },
  {
    "text": "provision diops one io operation is eight kilobyte in the sql server world",
    "start": "735440",
    "end": "741279"
  },
  {
    "text": "so when you provision ten 10 000 iops you're getting 80 megabyte of read and",
    "start": "741279",
    "end": "747200"
  },
  {
    "text": "write performance let's say you you purchase 3 000 provision diops",
    "start": "747200",
    "end": "754320"
  },
  {
    "text": "and you're still not getting the performance you you thought you would get there are a couple of things you should",
    "start": "754320",
    "end": "760240"
  },
  {
    "text": "look at first look at look whether you're using provision tyop's optimized",
    "start": "760240",
    "end": "766000"
  },
  {
    "text": "instances not every instance type where rds is running is optimized for",
    "start": "766000",
    "end": "773120"
  },
  {
    "text": "high io you should probably start with m1 large and larger those instance classes are",
    "start": "773120",
    "end": "779279"
  },
  {
    "text": "optimized for revision types then you should check if",
    "start": "779279",
    "end": "784320"
  },
  {
    "text": "you if you have any contention on the database level perhaps check if you have database login",
    "start": "784320",
    "end": "791440"
  },
  {
    "start": "788000",
    "end": "788000"
  },
  {
    "text": "if you still don't see the maximum of of the i operations that you purchased",
    "start": "791440",
    "end": "799360"
  },
  {
    "text": "you probably have an issue with scaling or and concurrency on the application",
    "start": "799360",
    "end": "804720"
  },
  {
    "text": "layer and the the graph on on the right of the slide kind of shows a benchmarking",
    "start": "804720",
    "end": "810399"
  },
  {
    "text": "attempt where i started with just one application server that's the box in in the that's dropbox",
    "start": "810399",
    "end": "817519"
  },
  {
    "text": "so one application server reading from from my database",
    "start": "817519",
    "end": "823120"
  },
  {
    "text": "it only consumes about 600 700 io operations per second now i scaled it",
    "start": "823120",
    "end": "829360"
  },
  {
    "text": "out to four application servers reading from my database and the good news is um i immediately",
    "start": "829360",
    "end": "836320"
  },
  {
    "text": "saw a 3.5 x 4x in increase in read i",
    "start": "836320",
    "end": "841839"
  },
  {
    "text": "for my database by the way i'm using cloudwatch to monitor the performance of my of my",
    "start": "841839",
    "end": "848000"
  },
  {
    "text": "system this is something that we recommend you're also doing i still haven't reached the 3000",
    "start": "848000",
    "end": "854560"
  },
  {
    "text": "provision triops now so my my four four thread benchmark test",
    "start": "854560",
    "end": "860639"
  },
  {
    "text": "is only consuming about 2300 io operations per second so i",
    "start": "860639",
    "end": "867519"
  },
  {
    "text": "increased my the number of my application servers threads to 16 and i finally was able to",
    "start": "867519",
    "end": "876079"
  },
  {
    "text": "exhaust the 3 000 provision payoffs i purchased for my database so what this",
    "start": "876079",
    "end": "881839"
  },
  {
    "text": "graph tells me is that actually i don't have a problem on the application scaling level",
    "start": "881839",
    "end": "887040"
  },
  {
    "text": "my applications are able to use all the database i o function",
    "start": "887040",
    "end": "892079"
  },
  {
    "text": "capacity that i that i can throw at it if i if i have the time to continue with",
    "start": "892079",
    "end": "898880"
  },
  {
    "text": "the test i'll probably increase the provision ios and just see where the limit would be",
    "start": "898880",
    "end": "905199"
  },
  {
    "text": "so we looked at security best practices we also looked at optimizing your sql server instances for",
    "start": "907760",
    "end": "914079"
  },
  {
    "text": "high performance not every not everyone in the room has luxury of",
    "start": "914079",
    "end": "919360"
  },
  {
    "text": "starting to starting with starting from scratch and building a application uh",
    "start": "919360",
    "end": "927120"
  },
  {
    "text": "in a green field environment in rds many of us have to move data into rds to actually operate a",
    "start": "927120",
    "end": "934000"
  },
  {
    "text": "an application so let's look at how to move your data into rds",
    "start": "934000",
    "end": "941839"
  },
  {
    "text": "you have several techniques to accomplish this data migration you can start with",
    "start": "942000",
    "end": "948079"
  },
  {
    "text": "bulk migration either either by using the import expert wizard if you have small databases",
    "start": "948800",
    "end": "954000"
  },
  {
    "start": "952000",
    "end": "952000"
  },
  {
    "text": "or using bulk copy and you can also accomplish migration of data through replication",
    "start": "954000",
    "end": "961120"
  },
  {
    "text": "and switch over i'm going to give you a couple of examples of how to accomplish each of",
    "start": "961120",
    "end": "966800"
  },
  {
    "text": "these tasks but let me let me quickly comment on on",
    "start": "966800",
    "end": "972399"
  },
  {
    "text": "the individual boxes here the choice of the",
    "start": "972399",
    "end": "978959"
  },
  {
    "text": "migration technique will depend on the size of the database and whether you can put your database",
    "start": "978959",
    "end": "985440"
  },
  {
    "text": "offline for the duration of the migration the import expert wizard",
    "start": "985440",
    "end": "991519"
  },
  {
    "text": "is works great for smaller databases it will allow you to move both the",
    "start": "991519",
    "end": "996959"
  },
  {
    "text": "schema of your database and the data simultaneously to your target system and rds",
    "start": "996959",
    "end": "1004079"
  },
  {
    "text": "bcp will work with medium-sized databases large size databases",
    "start": "1004079",
    "end": "1010399"
  },
  {
    "text": "the only downside of bcp is that you need to shut down your on-premise database for",
    "start": "1010399",
    "end": "1016959"
  },
  {
    "text": "the duration of the migration the last recommendation the replication",
    "start": "1016959",
    "end": "1022720"
  },
  {
    "text": "will switch switchover works in such a way that you",
    "start": "1022720",
    "end": "1027760"
  },
  {
    "text": "keep your on-premise database and your rds database operating simultaneously while the data",
    "start": "1027760",
    "end": "1034959"
  },
  {
    "text": "is being onboarded from the source to the target and once the once the target database is",
    "start": "1034959",
    "end": "1041760"
  },
  {
    "text": "completely synced with the source database you switch over your application servers to use the rds instance",
    "start": "1041760",
    "end": "1049679"
  },
  {
    "text": "i'll start with the example of the one-time bulk load migration we have an application",
    "start": "1050160",
    "end": "1056320"
  },
  {
    "text": "running together with the database on-premise and what i want to do is i want to move",
    "start": "1056320",
    "end": "1061840"
  },
  {
    "text": "all this data into rdas and switch my application to rds so i'll create a",
    "start": "1061840",
    "end": "1067280"
  },
  {
    "text": "rds instance i will shut off the access to my on-premise instance from the",
    "start": "1067280",
    "end": "1072720"
  },
  {
    "text": "application service i will organize a export of data into",
    "start": "1072720",
    "end": "1078880"
  },
  {
    "start": "1077000",
    "end": "1077000"
  },
  {
    "text": "into text files flat files using bcpa i'll use pcp as well to import the data",
    "start": "1078880",
    "end": "1085440"
  },
  {
    "text": "into rds and then i will switch the application to rds",
    "start": "1085440",
    "end": "1092000"
  },
  {
    "text": "i've got a couple of code snippets that will allow you to simplify this move the first",
    "start": "1093120",
    "end": "1100240"
  },
  {
    "text": "recommendation is to use the publish publish script wizard available in the sql server",
    "start": "1100240",
    "end": "1108559"
  },
  {
    "start": "1103000",
    "end": "1103000"
  },
  {
    "text": "management studio to generate the schema of your database there are a",
    "start": "1108559",
    "end": "1114320"
  },
  {
    "text": "couple of optimization recommendations here just export the table definitions don't",
    "start": "1114320",
    "end": "1119679"
  },
  {
    "text": "include the constraints and foreign keys so that your bcp loads can achieve the",
    "start": "1119679",
    "end": "1124960"
  },
  {
    "text": "maximum performance the next snippet is a simple select statement that will generate you the the",
    "start": "1124960",
    "end": "1131120"
  },
  {
    "text": "batch script that will contain all the bcp out statements that you will need to export",
    "start": "1131120",
    "end": "1137679"
  },
  {
    "text": "your data yet another script will create a",
    "start": "1137679",
    "end": "1143679"
  },
  {
    "text": "batch script for importing data using bcpn and if you would like more info on on",
    "start": "1143679",
    "end": "1150160"
  },
  {
    "text": "this particular technique you could also look up the our data import guide",
    "start": "1150160",
    "end": "1155360"
  },
  {
    "text": "available at the aws documentation site",
    "start": "1155360",
    "end": "1159919"
  },
  {
    "text": "let's also look at the second technique that i mentioned the replication with switchover i'm",
    "start": "1161280",
    "end": "1167840"
  },
  {
    "text": "starting again with a application pointing to a on-premise database",
    "start": "1167840",
    "end": "1173600"
  },
  {
    "start": "1170000",
    "end": "1170000"
  },
  {
    "text": "and my task is to move all this data from from on-premise to rds so i'll set up a rds instance",
    "start": "1174320",
    "end": "1183360"
  },
  {
    "text": "and i'll set up a link server in my source source database that will point to the target system can",
    "start": "1183360",
    "end": "1192160"
  },
  {
    "text": "set up sql scripts and automate them using sql sql agent",
    "start": "1192160",
    "end": "1198400"
  },
  {
    "text": "or i can use ssis create a bunch of dtsx packages which will contain insert statements",
    "start": "1198400",
    "end": "1205200"
  },
  {
    "text": "that will move my data from the source to the target",
    "start": "1205200",
    "end": "1210400"
  },
  {
    "text": "and once all my data is synced up it might take a day or two or whatever the duration is to move all",
    "start": "1210400",
    "end": "1215840"
  },
  {
    "text": "your data from on-premise you'll switch the application to use the rds instance",
    "start": "1215840",
    "end": "1222720"
  },
  {
    "text": "i'll give you a couple of useful statements to accomplish the creation of the link servers and",
    "start": "1223919",
    "end": "1229120"
  },
  {
    "text": "establishing this data move the first set of statements here is",
    "start": "1229120",
    "end": "1235600"
  },
  {
    "text": "is to be run on the target instance the the one in amazon you'll create a login use just for",
    "start": "1235600",
    "end": "1243039"
  },
  {
    "text": "application and then you'll create a user in your source database and you will",
    "start": "1243039",
    "end": "1248720"
  },
  {
    "text": "define i'm sorry in in your target database and you will define you",
    "start": "1248720",
    "end": "1255039"
  },
  {
    "text": "will add permissions for this user to read and write to your target db in my example here i'm",
    "start": "1255039",
    "end": "1262000"
  },
  {
    "text": "assuming that i need to move a table called customers and that table only contains two two",
    "start": "1262000",
    "end": "1267840"
  },
  {
    "text": "columns customer id and the update date so i'll create a",
    "start": "1267840",
    "end": "1273120"
  },
  {
    "text": "staging table in my target database where i will be moving the chunks of data used at each of the",
    "start": "1273120",
    "end": "1280320"
  },
  {
    "text": "iterations of the replication",
    "start": "1280320",
    "end": "1284720"
  },
  {
    "text": "on my source instance although first i'll create a linked server and",
    "start": "1286640",
    "end": "1295600"
  },
  {
    "text": "take note of the syntax for defining this link server that points to rds",
    "start": "1295600",
    "end": "1302320"
  },
  {
    "text": "we'll say something like target amazon aws.com and then the port that you chose",
    "start": "1302320",
    "end": "1309760"
  },
  {
    "text": "i will then add the login both the source login and the",
    "start": "1311280",
    "end": "1317520"
  },
  {
    "text": "remote login to the linked server object kind of bind everything together",
    "start": "1317520",
    "end": "1324159"
  },
  {
    "text": "and once i accomplish that i can start writing my insert statements the target the the table in my target",
    "start": "1324159",
    "end": "1331760"
  },
  {
    "text": "database using a four-part specifier the first part will be the name of the",
    "start": "1331760",
    "end": "1339120"
  },
  {
    "text": "link server in my source database uh then then i'll have the the database the",
    "start": "1339120",
    "end": "1345120"
  },
  {
    "text": "um the schema and and the name of the table",
    "start": "1345120",
    "end": "1352480"
  },
  {
    "text": "so this simple script will allow you to create link servers and allow you to do ongoing replication with",
    "start": "1353520",
    "end": "1359039"
  },
  {
    "text": "a switchover last but not least i wanted to take a few minutes to",
    "start": "1359039",
    "end": "1364799"
  },
  {
    "text": "discuss or talk about data durability",
    "start": "1364799",
    "end": "1369200"
  },
  {
    "text": "the biggest suggestion i can i can make to you is use is using the automated backups that",
    "start": "1371120",
    "end": "1377520"
  },
  {
    "text": "amazon ideas provides to you we create nightly backups and keep",
    "start": "1377520",
    "end": "1383520"
  },
  {
    "text": "transaction logs for the duration during the day",
    "start": "1383520",
    "end": "1390159"
  },
  {
    "text": "this this approach allows you to restore use point in time recovery pretty much",
    "start": "1390159",
    "end": "1396080"
  },
  {
    "text": "to any point in time during the retention period which can be up to 35 days in addition to",
    "start": "1396080",
    "end": "1404640"
  },
  {
    "text": "automatic backups you can also create manual snapshots a recent feature that",
    "start": "1404640",
    "end": "1411039"
  },
  {
    "text": "we just launched a couple of days ago is is the ability to copy snapshots from one region to",
    "start": "1411039",
    "end": "1417039"
  },
  {
    "text": "another as you can imagine this technique can be used for",
    "start": "1417039",
    "end": "1423600"
  },
  {
    "text": "increasing the durability of your system against events in the entire region so i'm going",
    "start": "1423679",
    "end": "1430240"
  },
  {
    "text": "to show you how to use cross region replication or cross region snapshot copy to react to unavailability events",
    "start": "1430240",
    "end": "1438880"
  },
  {
    "text": "in the entire data center so i'll start with region 1 and the database deployed to region one",
    "start": "1438880",
    "end": "1447120"
  },
  {
    "start": "1445000",
    "end": "1445000"
  },
  {
    "text": "you can use cli command line interface to establish programmatic automated",
    "start": "1447120",
    "end": "1453760"
  },
  {
    "text": "copying of snapshots from region one to region two you're going to keep doing it until one",
    "start": "1453760",
    "end": "1461120"
  },
  {
    "text": "day there might be a unavailability event in in the first region",
    "start": "1461120",
    "end": "1466880"
  },
  {
    "text": "at which point you can span up a new instance in region 2 and use the snapshots that you",
    "start": "1466880",
    "end": "1474640"
  },
  {
    "text": "diligently copied to restore into that new instance",
    "start": "1474640",
    "end": "1481360"
  },
  {
    "text": "hopefully i was able to share some useful recommendations with you i would like to invite ellen parsons",
    "start": "1482960",
    "end": "1489279"
  },
  {
    "text": "from video to talk about videos use of rds sql server",
    "start": "1489279",
    "end": "1501840"
  },
  {
    "text": "one million users have shared over six million pieces of content from their mobile devices with us",
    "start": "1607440",
    "end": "1614720"
  },
  {
    "text": "sorry you guys hear me better all right",
    "start": "1621760",
    "end": "1626880"
  },
  {
    "text": "so those users those those 41 million users have shared over 6 million 30 second videos with us we transcode a",
    "start": "1626880",
    "end": "1634000"
  },
  {
    "text": "number of renditions and we deliver the optimal video based on that mobile device we detect networks so 3g gets",
    "start": "1634000",
    "end": "1640240"
  },
  {
    "text": "different renditions and the lte networks or wi-fi networks will get an hd quality video and our cdn",
    "start": "1640240",
    "end": "1646960"
  },
  {
    "text": "footprint is fairly impressive and fairly large we have over 30 million transcoded videos um and of those we capture images we",
    "start": "1646960",
    "end": "1654320"
  },
  {
    "text": "resize images rescale images so we have over two billion image assets um under management on s3",
    "start": "1654320",
    "end": "1660159"
  },
  {
    "text": "and then to give you an idea about how amazon helps us scale the human power of vidi",
    "start": "1660159",
    "end": "1665279"
  },
  {
    "text": "so we have four executives and support staff people that manage the community finance",
    "start": "1665279",
    "end": "1670960"
  },
  {
    "text": "executives etc we have six software developers and then there's me the only uh technical operations",
    "start": "1670960",
    "end": "1676880"
  },
  {
    "text": "guy at vidi most impressive is that we have zero dbas managing all of our",
    "start": "1676880",
    "end": "1681919"
  },
  {
    "text": "shards and all of our databases so we all are acting as part-time dbas",
    "start": "1681919",
    "end": "1687520"
  },
  {
    "text": "a lot of our community managers and interns and business analysts are able to get content that they need out of the database themselves",
    "start": "1687520",
    "end": "1694159"
  },
  {
    "text": "and rds really helps us scale that way this is just a high level overview of a",
    "start": "1694159",
    "end": "1700320"
  },
  {
    "text": "small portion of our infrastructure at the top we chose a vpc",
    "start": "1700320",
    "end": "1705520"
  },
  {
    "text": "so all of our infrastructure sits within a vpc um the top layer is a public subnet so",
    "start": "1705520",
    "end": "1712880"
  },
  {
    "text": "all of our web servers are publicly addressable stuff um sits in the public subnet and then we have subnet for caching so redis has its",
    "start": "1712880",
    "end": "1718880"
  },
  {
    "text": "own subnet memcache has its own subnet and then rds as well has its own private subnet",
    "start": "1718880",
    "end": "1724799"
  },
  {
    "text": "and within that rds subnet we have one the green database is kind of the",
    "start": "1724799",
    "end": "1730159"
  },
  {
    "text": "core data stores all the users all the metadata for videos et cetera and then we have eight",
    "start": "1730159",
    "end": "1736080"
  },
  {
    "text": "different shards so we shard based on a a user id and they go into one of",
    "start": "1736080",
    "end": "1741679"
  },
  {
    "text": "eight buckets each one of those eight storage shard instances have 64 consumer",
    "start": "1741679",
    "end": "1746799"
  },
  {
    "text": "shards and 64 producer shards we'll get a little bit more into that later and we'll break this out so you can get a little bit",
    "start": "1746799",
    "end": "1752480"
  },
  {
    "text": "better picture of what we're doing so what powers video what's our stack",
    "start": "1752480",
    "end": "1757760"
  },
  {
    "start": "1757000",
    "end": "1757000"
  },
  {
    "text": "we're technology agnostic the team is multiverse in a wide range of",
    "start": "1757760",
    "end": "1762799"
  },
  {
    "text": "technologies so we choose the right technology to get the job done our front-end presentation layer our api",
    "start": "1762799",
    "end": "1769200"
  },
  {
    "text": "servers and our web servers are using windows and iis the first iteration was written using c-sharp",
    "start": "1769200",
    "end": "1776080"
  },
  {
    "text": "with an mvc framework we are moving to python but our caching tier right now is done in linux via couchbase using",
    "start": "1776080",
    "end": "1782880"
  },
  {
    "text": "memcache buckets for persistent cache we use redis we have a couple clusters of redis servers",
    "start": "1782880",
    "end": "1788960"
  },
  {
    "text": "source control we use tfs and we have completely automated all builds so we've empowered developers",
    "start": "1788960",
    "end": "1794799"
  },
  {
    "text": "single click deploys uh to any environment of their choice uh right through tfs and for that we use jenkins",
    "start": "1794799",
    "end": "1800799"
  },
  {
    "text": "powershell which basically wraps ms build to deploy out to our environments and just some of the services that we",
    "start": "1800799",
    "end": "1806320"
  },
  {
    "text": "are using for from amazon we use exclusively vpcs we choose one vpc per",
    "start": "1806320",
    "end": "1811600"
  },
  {
    "text": "environment so dev production and qa each have their own vpc rds",
    "start": "1811600",
    "end": "1816720"
  },
  {
    "text": "we have 11 server instances housing over 144 databases per vpc",
    "start": "1816720",
    "end": "1821919"
  },
  {
    "text": "so in total across all of our vpcs we have approximately 300 databases and over 30 server instances we use",
    "start": "1821919",
    "end": "1828960"
  },
  {
    "text": "simple notification services and queuing services to guarantee eventual consistency uh we use route 53 and elastic load",
    "start": "1828960",
    "end": "1834720"
  },
  {
    "text": "balancers cloud watch for monitoring and alerting cloud search we use heavily for when users search for media or search for",
    "start": "1834720",
    "end": "1841200"
  },
  {
    "text": "users or search for tags and then we also use s3 and cloudfront we just moved off of a prior cdn",
    "start": "1841200",
    "end": "1846480"
  },
  {
    "text": "pushed over two billion objects into s3 and as of last week or serving content exclusively through cloudfront",
    "start": "1846480",
    "end": "1855039"
  },
  {
    "text": "some of the early technical challenges a lot of us at vidi inherited the infrastructure they built a prototype",
    "start": "1855279",
    "end": "1861519"
  },
  {
    "start": "1859000",
    "end": "1859000"
  },
  {
    "text": "and then secured some funding hired some devs so we inherited a platform as a service type of",
    "start": "1861519",
    "end": "1867039"
  },
  {
    "text": "architecture which made it very very difficult to scale we had some difficulties in caching we",
    "start": "1867039",
    "end": "1872799"
  },
  {
    "text": "have a twitter based model so if a user uploads a piece of content they want to see that feedback",
    "start": "1872799",
    "end": "1878880"
  },
  {
    "text": "immediately if a user likes a video or comments on a video we have to ensure that that user's device",
    "start": "1878880",
    "end": "1884399"
  },
  {
    "text": "displays that instantaneously which provides some challenges in caching",
    "start": "1884399",
    "end": "1890320"
  },
  {
    "text": "we kind of underestimated the power of facebook we were an early adopter of the facebook open graph for those of you unfamiliar facebook",
    "start": "1890320",
    "end": "1896559"
  },
  {
    "text": "open graph allowed application developers to capture email addresses and then a user would agree to",
    "start": "1896559",
    "end": "1903039"
  },
  {
    "text": "share that content back to their facebook feed so if you have john doe that's watching a video of a",
    "start": "1903039",
    "end": "1909120"
  },
  {
    "text": "dog skateboarding he has agreed to share the content back to his activity feed we share that john doe watched his dog",
    "start": "1909120",
    "end": "1916559"
  },
  {
    "text": "riding a skateboard all of his friends see that all his friends click on that all of his friends register with the vidi service so it",
    "start": "1916559",
    "end": "1922880"
  },
  {
    "text": "creates this really instantaneous viral loop totally underestimated the power of it we saw anywhere between 500 000 to a",
    "start": "1922880",
    "end": "1929360"
  },
  {
    "text": "million new user registrations within 24 hour periods for up to like 30 45 days straight um",
    "start": "1929360",
    "end": "1934480"
  },
  {
    "text": "until facebook kind of tweaked that that product um so all those user registrations led to a very very very",
    "start": "1934480",
    "end": "1941360"
  },
  {
    "text": "busy sql instance we had one sequence since housing six databases we split based on functionality we split",
    "start": "1941360",
    "end": "1947840"
  },
  {
    "text": "based on comments with a likes database with a user database etc um but we saw tremendous write latency",
    "start": "1947840",
    "end": "1954480"
  },
  {
    "text": "we saw table locking we saw delays in getting users into those tables so what we ended up doing was completely disabling key constraints",
    "start": "1954480",
    "end": "1961600"
  },
  {
    "text": "we were lucky early on we chose a global unique identifier as the primary key",
    "start": "1961600",
    "end": "1966799"
  },
  {
    "text": "so disabling key constraints really was an issue was not that big of an issue we thought at the time the other thing that was was",
    "start": "1966799",
    "end": "1975120"
  },
  {
    "text": "difficult was we were operating on a platform as a service with a very very busy database we were",
    "start": "1975120",
    "end": "1980480"
  },
  {
    "text": "unable to get transactionally consistent database backups out of our database so if somebody ran a",
    "start": "1980480",
    "end": "1985919"
  },
  {
    "text": "developer ran an update statement without where clause were screwed um so everyone's very very careful and it's one of the things that",
    "start": "1985919",
    "end": "1992320"
  },
  {
    "text": "drove us to move off of the platform as a service there was no way whatsoever for us to get a transactionally consistent",
    "start": "1992320",
    "end": "1997440"
  },
  {
    "text": "database out and then we also had an inflexible platform so",
    "start": "1997440",
    "end": "2002720"
  },
  {
    "text": "adding more servers would create more database load um and then on platform as a service we",
    "start": "2002720",
    "end": "2008399"
  },
  {
    "text": "couldn't just throw more money at it so we're in a multi-tenant environment we couldn't say hey here's a ton of money we want our own",
    "start": "2008399",
    "end": "2014080"
  },
  {
    "text": "dedicated hardware wasn't going to happen so it provided huge huge technical challenges",
    "start": "2014080",
    "end": "2020640"
  },
  {
    "text": "so in probably mid 2012 uh we started planning and and made a",
    "start": "2020640",
    "end": "2026480"
  },
  {
    "text": "decision to move off of our prior provider and into amazon um with the goal that we were going to",
    "start": "2026480",
    "end": "2031519"
  },
  {
    "text": "do this was absolutely zero downtime um we're still going to take and serve production traffic um",
    "start": "2031519",
    "end": "2037600"
  },
  {
    "text": "and we just we would not afford any type of downtime during that move um so we chose vpcs which guaranteed",
    "start": "2037600",
    "end": "2044799"
  },
  {
    "text": "guaranteed no dfinity it guaranteed our web servers our cache servers and our database servers were clustered together",
    "start": "2044799",
    "end": "2050079"
  },
  {
    "text": "and our cache servers or data was not publicly accessible for sql we chose rds but in that process",
    "start": "2050079",
    "end": "2056560"
  },
  {
    "text": "we had a tremendous amount of cleanup we had duplicate email addresses um we had to merge records when users signed",
    "start": "2056560",
    "end": "2063358"
  },
  {
    "text": "in they might get record a and then they come back later they get their record b so we had a tremendous tremendous um",
    "start": "2063359",
    "end": "2069118"
  },
  {
    "text": "cleanup effort and what we ended up was 144 rds shelves and we filled the initial load via etl",
    "start": "2069119",
    "end": "2074878"
  },
  {
    "text": "process um and then what we did during the process was also engineer for eventual consistency",
    "start": "2074879",
    "end": "2080480"
  },
  {
    "text": "um and i'll get into that a little bit later and then the other thing that was important from the get-go was enabling developers",
    "start": "2080480",
    "end": "2086000"
  },
  {
    "text": "single-click deploys to either the platform as a service infrastructure or the new infrastructure as a service um and so we built deploy scripts",
    "start": "2086000",
    "end": "2093118"
  },
  {
    "text": "developers could build any environment test on any environment ensure their data was correct et cetera and then during that move we",
    "start": "2093119",
    "end": "2100000"
  },
  {
    "text": "moved all of our dns records over to amazon lowered the ttls in preparation for that move",
    "start": "2100000",
    "end": "2105280"
  },
  {
    "text": "christmas eve 2012. we all took a couple hours signed online we shut down the",
    "start": "2105280",
    "end": "2112400"
  },
  {
    "text": "production instance waited for that eventual consistency uh those eventual consistency cues to go to",
    "start": "2112400",
    "end": "2117920"
  },
  {
    "text": "zero and then we swung traffic being a dns update so the only downtime that we did incur uh was approximately one minute to uh",
    "start": "2117920",
    "end": "2124400"
  },
  {
    "text": "move those dns records over um chrome went smoother um tremendous engineering effort",
    "start": "2124400",
    "end": "2130240"
  },
  {
    "text": "and it shows that that huge planning really really does pay off",
    "start": "2130240",
    "end": "2135920"
  },
  {
    "text": "um so how do we shard we shared based on a do it so when a user comes into our",
    "start": "2135920",
    "end": "2140960"
  },
  {
    "text": "service we hash that user id and they end up in one of 64 different shards so",
    "start": "2140960",
    "end": "2146960"
  },
  {
    "text": "we have we have total 128 shards um a user belongs to one of 64 producer shards or one",
    "start": "2146960",
    "end": "2152960"
  },
  {
    "text": "and one of 64 consumer shards so our users produce content and they also consume content so when they comment",
    "start": "2152960",
    "end": "2159359"
  },
  {
    "text": "we push to a producer shard if someone comments on their video they'll pull from the consumer shard",
    "start": "2159359",
    "end": "2165119"
  },
  {
    "text": "so what happens is the application servers for eventual consistency push a message to an sns topic and that",
    "start": "2165119",
    "end": "2173040"
  },
  {
    "text": "those sns topics we have simple queueing services uh we have one queue per shard that is",
    "start": "2173040",
    "end": "2179280"
  },
  {
    "text": "subscribed to those topics and pushes that message into one of the appropriate shards",
    "start": "2179280",
    "end": "2184560"
  },
  {
    "text": "via a windows service that we have running that's just constantly pulling all those cues some of the advantages we can lose that",
    "start": "2184560",
    "end": "2190960"
  },
  {
    "text": "windows box or that partition manager that's that's monitoring those cues and we don't lose messages there'll be a delay in delivery but we",
    "start": "2190960",
    "end": "2196800"
  },
  {
    "text": "do not lose those messages we can lose a db shard so shard zero one can go offline um",
    "start": "2196800",
    "end": "2202480"
  },
  {
    "text": "those messages will continue to queue and when shard zero one comes back online we'll push those messages into that particular shard and",
    "start": "2202480",
    "end": "2208720"
  },
  {
    "text": "it's really easy to scale if we need to scale up in terms of shards or databases we'll just create more cues more queues",
    "start": "2208720",
    "end": "2215599"
  },
  {
    "text": "equals more messages more messages equals more windows machines to process those and we can horizontally scale so it's very very",
    "start": "2215599",
    "end": "2221680"
  },
  {
    "text": "easy to scale horizontally using that eventual consistency type of model",
    "start": "2221680",
    "end": "2226880"
  },
  {
    "text": "so how do we provision on rds not a lot of science behind it we didn't have a ton of visibility at our prior provider didn't know how many",
    "start": "2226880",
    "end": "2233839"
  },
  {
    "text": "iops we were doing per second didn't really know the only thing we knew is that we were too big in terms of storage",
    "start": "2233839",
    "end": "2240960"
  },
  {
    "text": "so we chose sql server 2012 standard edition because we're on a biz spark license um",
    "start": "2240960",
    "end": "2247280"
  },
  {
    "text": "eventually bizmark is going to expire for us we didn't want to get stuck with sticker shock when it came time to open up our wallets for that",
    "start": "2247280",
    "end": "2254160"
  },
  {
    "text": "license storage allocation we just took the max if they're offering one terabyte we'll take one terabyte storage is cheap",
    "start": "2254160",
    "end": "2260880"
  },
  {
    "text": "um downtime is not so we chose one terabyte across all of our nodes iops our business database took we",
    "start": "2260880",
    "end": "2268320"
  },
  {
    "text": "partitioned or we provisioned 7000 iops on our busy database which is that green one that i showed you before it's kind",
    "start": "2268320",
    "end": "2274160"
  },
  {
    "text": "of the hub of all of our data none of the shards have any provision iops they're not as",
    "start": "2274160",
    "end": "2279200"
  },
  {
    "text": "busy we distributed that load we do to see occasional hotspots we have some celebrities that use our service",
    "start": "2279200",
    "end": "2285200"
  },
  {
    "text": "when justin bieber uploads a video we see huge traffic spikes and a large number of database queries",
    "start": "2285200",
    "end": "2292000"
  },
  {
    "text": "again changing iops or changing any type of storage in sql server does require downtime something we didn't want to do so we",
    "start": "2292000",
    "end": "2297760"
  },
  {
    "text": "just took 7000 iops on the largest instance it's in size busiest instance which is",
    "start": "2297760",
    "end": "2303920"
  },
  {
    "text": "our that green one again we just took the max m2 for xl all of our shards use a m22 xl um changing down changing",
    "start": "2303920",
    "end": "2312400"
  },
  {
    "text": "instant size it shouldn't require downtime but we didn't want to we don't want to risk it and then",
    "start": "2312400",
    "end": "2317680"
  },
  {
    "text": "everything is placed on a vpc vpc guarantees node affinity but moving across different availability zones",
    "start": "2317680",
    "end": "2325280"
  },
  {
    "text": "does cause some sort of downtime so how do we design for high",
    "start": "2325280",
    "end": "2330320"
  },
  {
    "text": "availability we didn't design for fault tolerance so we can't afford a downtime we can queue messages we'll guarantee",
    "start": "2330320",
    "end": "2336960"
  },
  {
    "start": "2333000",
    "end": "2333000"
  },
  {
    "text": "that they'll get there eventually so we designed for for high availability",
    "start": "2336960",
    "end": "2342000"
  },
  {
    "text": "amazon rds and vpcs um at the time that we provisioned there was no multi-az placement groups",
    "start": "2342000",
    "end": "2348960"
  },
  {
    "text": "available so you have to provision that sql server in one particular availability zone so",
    "start": "2348960",
    "end": "2354079"
  },
  {
    "text": "you do have a single point of failure so just be aware that when you are designing um",
    "start": "2354079",
    "end": "2359359"
  },
  {
    "text": "to run to run your sql server in rds um started model so a user exists in one of 64 consumer shards and one of 64",
    "start": "2359359",
    "end": "2366079"
  },
  {
    "text": "producer shards if we lose a shard only about one and a half percent of users are affected if we i'm sorry if we lose a database",
    "start": "2366079",
    "end": "2372400"
  },
  {
    "text": "only one and a half percent of users are affected if we lose an actual instance we affect about 12 and a half percent of",
    "start": "2372400",
    "end": "2377839"
  },
  {
    "text": "users until we can bring that back online for eventual consistency again we're using sns and sqs",
    "start": "2377839",
    "end": "2384160"
  },
  {
    "text": "visibility timeout or i'm sorry message visibility timeout gives us the ability to get that database back online without",
    "start": "2384160",
    "end": "2390320"
  },
  {
    "text": "losing that message um and we sharded the uh the sqsqs so that",
    "start": "2390320",
    "end": "2395680"
  },
  {
    "text": "if there's an instance down or there's any sort of backup it only affects an eighth of our entire environment",
    "start": "2395680",
    "end": "2401200"
  },
  {
    "text": "snapshots this is kind of what we really like set it and forget it it just works we've had to use it before",
    "start": "2401200",
    "end": "2407520"
  },
  {
    "text": "developers do run updates without where clauses so getting it happens so getting a",
    "start": "2407520",
    "end": "2414240"
  },
  {
    "text": "database back online reliably is very very important to us it does take time",
    "start": "2414240",
    "end": "2419520"
  },
  {
    "text": "25 30 minutes is what we typically see to get a database from the snapshot back online so we bring up that snapshot",
    "start": "2419520",
    "end": "2425839"
  },
  {
    "text": "in a secondary instance and then we just merge a table that the developer screwed up it's pretty easy to mitigate that as",
    "start": "2425839",
    "end": "2432960"
  },
  {
    "text": "long as one of the developers gets their hand up and says oops i made a mistake early on it's fairly easy to recover",
    "start": "2432960",
    "end": "2439520"
  },
  {
    "text": "also the snapshots allow us to regularly refresh non-production environments so if the",
    "start": "2439520",
    "end": "2444640"
  },
  {
    "text": "developer is working on something new in a dev environment test environment qa environment we have automated scripts and written in",
    "start": "2444640",
    "end": "2450319"
  },
  {
    "text": "python using the boto library that creates snapshots and then restored to those environments it takes about an hour we restore to",
    "start": "2450319",
    "end": "2457520"
  },
  {
    "text": "a staging set of servers and then we just do a name swap security considerations we kind of we're",
    "start": "2457520",
    "end": "2464000"
  },
  {
    "text": "small enough team we follow the facebook model so every developer has access to everything unrestricted access",
    "start": "2464000",
    "end": "2471119"
  },
  {
    "start": "2466000",
    "end": "2466000"
  },
  {
    "text": "it creates less friction developers are more efficient they're able to get their they're able to troubleshoot a lot more",
    "start": "2471119",
    "end": "2476720"
  },
  {
    "text": "quickly but with great privilege comes great responsibility so you screw something up you got to break it or you got to fix it",
    "start": "2476720",
    "end": "2484240"
  },
  {
    "text": "so some of the other basics just the the kind of does application config files use a",
    "start": "2484240",
    "end": "2491760"
  },
  {
    "text": "restricted user account that only has access to update insert delete and select",
    "start": "2491760",
    "end": "2497920"
  },
  {
    "text": "the dbs the databases sit in a private vpc segment they are not publicly addressable or publicly accessible",
    "start": "2497920",
    "end": "2504400"
  },
  {
    "text": "we have support restrictions done but we do all that restriction at the security group level we don't use any sort of like matted",
    "start": "2504400",
    "end": "2510240"
  },
  {
    "text": "tables or any sort of ip tables developers can connect over vpn we have an open vpn instance sitting",
    "start": "2510240",
    "end": "2517040"
  },
  {
    "text": "in the public section in the public segment of our environment developers can work from home get unrestricted access",
    "start": "2517040",
    "end": "2522319"
  },
  {
    "text": "across any vpc so we kind of flatten our entire environment um to allow developers connect the",
    "start": "2522319",
    "end": "2527680"
  },
  {
    "text": "production dev et cetera through openvpn and then support staff business analysts",
    "start": "2527680",
    "end": "2533520"
  },
  {
    "text": "anybody that wants to do a select query business intelligence type of stuff they get a select or they get a read-only database account so",
    "start": "2533520",
    "end": "2540240"
  },
  {
    "text": "we don't have to worry about them in addition to developers running an update without a where clause",
    "start": "2540240",
    "end": "2547119"
  },
  {
    "text": "so that's it i encourage you guys to check us out download our application we have a few other applications in",
    "start": "2547119",
    "end": "2552480"
  },
  {
    "text": "addition to vidi in the app store try us out let us know what you think and uh i'll use the remaining time for",
    "start": "2552480",
    "end": "2560240"
  },
  {
    "text": "questions you",
    "start": "2562839",
    "end": "2567760"
  }
]
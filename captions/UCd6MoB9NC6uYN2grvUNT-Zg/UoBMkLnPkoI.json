[
  {
    "text": "hello everyone and welcome to seventh",
    "start": "920",
    "end": "4259"
  },
  {
    "text": "episode of analytics byte series a video",
    "start": "4259",
    "end": "7500"
  },
  {
    "text": "series where we explore common analytics",
    "start": "7500",
    "end": "10260"
  },
  {
    "text": "use cases and how to architect for them",
    "start": "10260",
    "end": "13259"
  },
  {
    "text": "my name is Manish Chuck and I'm your",
    "start": "13259",
    "end": "15360"
  },
  {
    "text": "host today I'm a principal Solutions",
    "start": "15360",
    "end": "18000"
  },
  {
    "text": "architect on startups team here at AWS",
    "start": "18000",
    "end": "20520"
  },
  {
    "text": "I'm based out of San Francisco office",
    "start": "20520",
    "end": "23100"
  },
  {
    "text": "and in my day-to-day activities I help",
    "start": "23100",
    "end": "25740"
  },
  {
    "text": "my startup customers build deploy and",
    "start": "25740",
    "end": "27660"
  },
  {
    "text": "run scalable and cost effective",
    "start": "27660",
    "end": "30180"
  },
  {
    "text": "workloads on AWS cloud",
    "start": "30180",
    "end": "32398"
  },
  {
    "text": "in today's episode I am going to talk",
    "start": "32399",
    "end": "35280"
  },
  {
    "text": "about how to train and deploy your",
    "start": "35280",
    "end": "38280"
  },
  {
    "text": "machine learning models using Amazon",
    "start": "38280",
    "end": "39860"
  },
  {
    "text": "sagemaker and also how to design and",
    "start": "39860",
    "end": "43320"
  },
  {
    "text": "integrate modern data architecture with",
    "start": "43320",
    "end": "46260"
  },
  {
    "text": "sage maker for machine learning",
    "start": "46260",
    "end": "48059"
  },
  {
    "text": "predictions so let's get started",
    "start": "48059",
    "end": "51960"
  },
  {
    "text": "just to recap modern data architecture",
    "start": "51960",
    "end": "54840"
  },
  {
    "text": "allows startup customers to think big",
    "start": "54840",
    "end": "57360"
  },
  {
    "text": "start a small and scale fast",
    "start": "57360",
    "end": "60239"
  },
  {
    "text": "it helps modularize architecture",
    "start": "60239",
    "end": "63019"
  },
  {
    "text": "increases your agility and help scale",
    "start": "63019",
    "end": "66299"
  },
  {
    "text": "quickly as your business grows you can",
    "start": "66299",
    "end": "68820"
  },
  {
    "text": "easily add new data sources scale the",
    "start": "68820",
    "end": "71400"
  },
  {
    "text": "workloads up and down and add new",
    "start": "71400",
    "end": "73560"
  },
  {
    "text": "analytics workload when the business",
    "start": "73560",
    "end": "75000"
  },
  {
    "text": "demands",
    "start": "75000",
    "end": "76799"
  },
  {
    "text": "in the previous video of analytics byte",
    "start": "76799",
    "end": "79380"
  },
  {
    "text": "series we talked about modern data",
    "start": "79380",
    "end": "81659"
  },
  {
    "text": "architecture",
    "start": "81659",
    "end": "82860"
  },
  {
    "text": "and various segment of modern data",
    "start": "82860",
    "end": "85560"
  },
  {
    "text": "architectures such as serverless data",
    "start": "85560",
    "end": "88380"
  },
  {
    "text": "Lake",
    "start": "88380",
    "end": "89100"
  },
  {
    "text": "streaming data ingestion",
    "start": "89100",
    "end": "91380"
  },
  {
    "text": "transactional data Lake",
    "start": "91380",
    "end": "93360"
  },
  {
    "text": "redshift then how to prepare data for",
    "start": "93360",
    "end": "96720"
  },
  {
    "text": "machine learning using Amazon sagemaker",
    "start": "96720",
    "end": "99479"
  },
  {
    "text": "in these videos we covered specific use",
    "start": "99479",
    "end": "102659"
  },
  {
    "text": "cases reference architecture using AWS",
    "start": "102659",
    "end": "105840"
  },
  {
    "text": "services and customer success stories in",
    "start": "105840",
    "end": "109799"
  },
  {
    "text": "today's video I'll talk about how to use",
    "start": "109799",
    "end": "112619"
  },
  {
    "text": "sagemaker in building training and",
    "start": "112619",
    "end": "114299"
  },
  {
    "text": "deploying your machine learning model",
    "start": "114299",
    "end": "115799"
  },
  {
    "text": "and integrate with modern data",
    "start": "115799",
    "end": "117780"
  },
  {
    "text": "architecture",
    "start": "117780",
    "end": "120380"
  },
  {
    "text": "sagemaker includes a lot of different",
    "start": "120540",
    "end": "122939"
  },
  {
    "text": "features and capabilities",
    "start": "122939",
    "end": "124979"
  },
  {
    "text": "we typically talk about these features",
    "start": "124979",
    "end": "127079"
  },
  {
    "text": "and capabilities into four different",
    "start": "127079",
    "end": "128940"
  },
  {
    "text": "categories",
    "start": "128940",
    "end": "130140"
  },
  {
    "text": "data preparation model build phase",
    "start": "130140",
    "end": "132900"
  },
  {
    "text": "training and tuning deployment",
    "start": "132900",
    "end": "135360"
  },
  {
    "text": "management and hosting",
    "start": "135360",
    "end": "137940"
  },
  {
    "text": "in the previous video we talked about",
    "start": "137940",
    "end": "140180"
  },
  {
    "text": "different ml data prep capabilities of",
    "start": "140180",
    "end": "143940"
  },
  {
    "text": "sagemaker such as sagemaker data",
    "start": "143940",
    "end": "146879"
  },
  {
    "text": "Wrangler sagemaker feature store and",
    "start": "146879",
    "end": "149640"
  },
  {
    "text": "sagemaker ground truth we also talked",
    "start": "149640",
    "end": "152580"
  },
  {
    "text": "about sagemaker studio notebooks as well",
    "start": "152580",
    "end": "155099"
  },
  {
    "text": "as sagemaker Studio itself and how they",
    "start": "155099",
    "end": "157920"
  },
  {
    "text": "can help in building and prepping data",
    "start": "157920",
    "end": "159660"
  },
  {
    "text": "for machine learning",
    "start": "159660",
    "end": "161040"
  },
  {
    "text": "in today's session we'll talk about how",
    "start": "161040",
    "end": "164640"
  },
  {
    "text": "sagemaker helps in training tuning",
    "start": "164640",
    "end": "167840"
  },
  {
    "text": "deployment and managing machine learning",
    "start": "167840",
    "end": "170760"
  },
  {
    "text": "models in production",
    "start": "170760",
    "end": "173900"
  },
  {
    "text": "first up let's discuss how sagemaker",
    "start": "174660",
    "end": "177420"
  },
  {
    "text": "helps in building ml models sagemaker",
    "start": "177420",
    "end": "180360"
  },
  {
    "text": "offers ml engineer and data scientist as",
    "start": "180360",
    "end": "183959"
  },
  {
    "text": "we talked about Studio IDE as well as",
    "start": "183959",
    "end": "186780"
  },
  {
    "text": "the notebooks which are the starting",
    "start": "186780",
    "end": "189239"
  },
  {
    "text": "point for your model build phase",
    "start": "189239",
    "end": "191640"
  },
  {
    "text": "Sage maker also allows your ml",
    "start": "191640",
    "end": "194040"
  },
  {
    "text": "developers to pick different algorithms",
    "start": "194040",
    "end": "196140"
  },
  {
    "text": "including over 20 that are built in and",
    "start": "196140",
    "end": "199620"
  },
  {
    "text": "optimized for sage maker",
    "start": "199620",
    "end": "201659"
  },
  {
    "text": "it also offers over 300 pre-built models",
    "start": "201659",
    "end": "205080"
  },
  {
    "text": "from popular models available with just",
    "start": "205080",
    "end": "207840"
  },
  {
    "text": "a few clicks",
    "start": "207840",
    "end": "209099"
  },
  {
    "text": "and over 15 pre-built solution templates",
    "start": "209099",
    "end": "213420"
  },
  {
    "text": "Amazon sagemaker also offers a feature",
    "start": "213420",
    "end": "216420"
  },
  {
    "text": "called autopilot for customers who wants",
    "start": "216420",
    "end": "219659"
  },
  {
    "text": "to automatically build train and tune",
    "start": "219659",
    "end": "221819"
  },
  {
    "text": "the best machine learning models based",
    "start": "221819",
    "end": "224580"
  },
  {
    "text": "on their data you then can directly",
    "start": "224580",
    "end": "227040"
  },
  {
    "text": "deploy those models to production with",
    "start": "227040",
    "end": "229200"
  },
  {
    "text": "just one click or a trade to improve the",
    "start": "229200",
    "end": "231180"
  },
  {
    "text": "model quality",
    "start": "231180",
    "end": "232739"
  },
  {
    "text": "sagemaker also optimized for many",
    "start": "232739",
    "end": "235620"
  },
  {
    "text": "popular deep learning Frameworks such as",
    "start": "235620",
    "end": "237720"
  },
  {
    "text": "tensorflow",
    "start": "237720",
    "end": "239040"
  },
  {
    "text": "capacity Apache mxnet High torch and",
    "start": "239040",
    "end": "242760"
  },
  {
    "text": "more",
    "start": "242760",
    "end": "243480"
  },
  {
    "text": "Frameworks are Frameworks are always up",
    "start": "243480",
    "end": "246360"
  },
  {
    "text": "to date with latest version and are",
    "start": "246360",
    "end": "248400"
  },
  {
    "text": "optimized for performance on AWS",
    "start": "248400",
    "end": "251040"
  },
  {
    "text": "you don't need to manually set up these",
    "start": "251040",
    "end": "253260"
  },
  {
    "text": "Frameworks and can use them within the",
    "start": "253260",
    "end": "255360"
  },
  {
    "text": "pre-built containers",
    "start": "255360",
    "end": "257040"
  },
  {
    "text": "now let's talk about what capabilities",
    "start": "257040",
    "end": "259699"
  },
  {
    "text": "sagemaker provides to train these models",
    "start": "259699",
    "end": "263639"
  },
  {
    "text": "sagemaker provides full set of managed",
    "start": "263639",
    "end": "266759"
  },
  {
    "text": "training capabilities it reduces the",
    "start": "266759",
    "end": "269699"
  },
  {
    "text": "time and cost to train and tune machine",
    "start": "269699",
    "end": "272520"
  },
  {
    "text": "learning models without the need to",
    "start": "272520",
    "end": "274860"
  },
  {
    "text": "manage the infrastructure with sagemaker",
    "start": "274860",
    "end": "277860"
  },
  {
    "text": "you can easily train and tune ml models",
    "start": "277860",
    "end": "281280"
  },
  {
    "text": "using purpose-built tool to manage and",
    "start": "281280",
    "end": "284280"
  },
  {
    "text": "track training experiments automatically",
    "start": "284280",
    "end": "287639"
  },
  {
    "text": "choose the optimal hyper parameters",
    "start": "287639",
    "end": "290160"
  },
  {
    "text": "debug training jobs and automatically",
    "start": "290160",
    "end": "293100"
  },
  {
    "text": "monitor utilization of system resources",
    "start": "293100",
    "end": "295680"
  },
  {
    "text": "such as gpus CPUs and network bandwidth",
    "start": "295680",
    "end": "299820"
  },
  {
    "text": "all steps of training workflow can be",
    "start": "299820",
    "end": "303000"
  },
  {
    "text": "automated into machine learning workflow",
    "start": "303000",
    "end": "305340"
  },
  {
    "text": "so you can scale to thousands of",
    "start": "305340",
    "end": "307800"
  },
  {
    "text": "training experiments",
    "start": "307800",
    "end": "309740"
  },
  {
    "text": "sagemaker also offers the highest",
    "start": "309740",
    "end": "312540"
  },
  {
    "text": "performing machine learning compute",
    "start": "312540",
    "end": "314880"
  },
  {
    "text": "infrastructure including p4d instances",
    "start": "314880",
    "end": "318080"
  },
  {
    "text": "which provides up to 60 percent lower",
    "start": "318080",
    "end": "321060"
  },
  {
    "text": "cost to Drain Machine learning models",
    "start": "321060",
    "end": "323280"
  },
  {
    "text": "compared to previous generation",
    "start": "323280",
    "end": "324720"
  },
  {
    "text": "instances",
    "start": "324720",
    "end": "326520"
  },
  {
    "text": "Sage maker automatically scales training",
    "start": "326520",
    "end": "329340"
  },
  {
    "text": "infrastructure Up and Down based on your",
    "start": "329340",
    "end": "332280"
  },
  {
    "text": "training job requirements from gpus from",
    "start": "332280",
    "end": "335880"
  },
  {
    "text": "one GPU to thousands or from terabytes",
    "start": "335880",
    "end": "338699"
  },
  {
    "text": "to petabyte of storage therefore you",
    "start": "338699",
    "end": "341580"
  },
  {
    "text": "don't need to worry about managing the",
    "start": "341580",
    "end": "343320"
  },
  {
    "text": "infrastructure and since you only pay",
    "start": "343320",
    "end": "345720"
  },
  {
    "text": "for what you use you can better manage",
    "start": "345720",
    "end": "348180"
  },
  {
    "text": "your training cost",
    "start": "348180",
    "end": "349800"
  },
  {
    "text": "to make trading faster you can enable",
    "start": "349800",
    "end": "352620"
  },
  {
    "text": "the sagemaker training compiler and",
    "start": "352620",
    "end": "355380"
  },
  {
    "text": "immediately achieve up to 50 speed up",
    "start": "355380",
    "end": "358740"
  },
  {
    "text": "through graph and kernel level",
    "start": "358740",
    "end": "360180"
  },
  {
    "text": "optimizations which makes more efficient",
    "start": "360180",
    "end": "363060"
  },
  {
    "text": "use of gpus",
    "start": "363060",
    "end": "364740"
  },
  {
    "text": "also the sagemaker distributed training",
    "start": "364740",
    "end": "367440"
  },
  {
    "text": "libraries automatically split models and",
    "start": "367440",
    "end": "370680"
  },
  {
    "text": "training data sets across GPU instances",
    "start": "370680",
    "end": "373460"
  },
  {
    "text": "helping you complete distributed",
    "start": "373460",
    "end": "375600"
  },
  {
    "text": "training up to 40 faster",
    "start": "375600",
    "end": "378539"
  },
  {
    "text": "wow a lot of features there to help you",
    "start": "378539",
    "end": "382199"
  },
  {
    "text": "do your training",
    "start": "382199",
    "end": "383940"
  },
  {
    "text": "now let's explore the capabilities and",
    "start": "383940",
    "end": "386400"
  },
  {
    "text": "benefits of sagemaker for deploying",
    "start": "386400",
    "end": "388620"
  },
  {
    "text": "these ml models for inferences in",
    "start": "388620",
    "end": "390840"
  },
  {
    "text": "production",
    "start": "390840",
    "end": "392539"
  },
  {
    "text": "sagemaker makes it easy to deploy and",
    "start": "392539",
    "end": "395220"
  },
  {
    "text": "manage machine learning models at scale",
    "start": "395220",
    "end": "398400"
  },
  {
    "text": "as a fully managed service it takes care",
    "start": "398400",
    "end": "401160"
  },
  {
    "text": "of setting up and managing instances for",
    "start": "401160",
    "end": "403919"
  },
  {
    "text": "inferences ensuring software version",
    "start": "403919",
    "end": "406620"
  },
  {
    "text": "compatibilities and patching versions",
    "start": "406620",
    "end": "409919"
  },
  {
    "text": "sagemaker also provides built-in metrics",
    "start": "409919",
    "end": "412680"
  },
  {
    "text": "and logs for your endpoints that you can",
    "start": "412680",
    "end": "415979"
  },
  {
    "text": "use to Monitor and receive alerts",
    "start": "415979",
    "end": "418560"
  },
  {
    "text": "sagemaker also offers more than 70",
    "start": "418560",
    "end": "421800"
  },
  {
    "text": "instance type for your inferences with",
    "start": "421800",
    "end": "424740"
  },
  {
    "text": "varying level of compute and memory",
    "start": "424740",
    "end": "426800"
  },
  {
    "text": "including Amazon ec2 in one instances",
    "start": "426800",
    "end": "429900"
  },
  {
    "text": "based on AWS inferentia high performance",
    "start": "429900",
    "end": "433740"
  },
  {
    "text": "ml inference ship designed by AWS",
    "start": "433740",
    "end": "436680"
  },
  {
    "text": "and GPU instances such as ec2 G4 DNS to",
    "start": "436680",
    "end": "440639"
  },
  {
    "text": "meet the performance and cost",
    "start": "440639",
    "end": "442080"
  },
  {
    "text": "requirement of any use case including",
    "start": "442080",
    "end": "445259"
  },
  {
    "text": "real time how high throughput batch",
    "start": "445259",
    "end": "447720"
  },
  {
    "text": "inferences",
    "start": "447720",
    "end": "449340"
  },
  {
    "text": "sagemaker also allows developers to",
    "start": "449340",
    "end": "451620"
  },
  {
    "text": "access deployed models through API",
    "start": "451620",
    "end": "453780"
  },
  {
    "text": "requests with response time as low as",
    "start": "453780",
    "end": "456720"
  },
  {
    "text": "few milliseconds this supports use cases",
    "start": "456720",
    "end": "459960"
  },
  {
    "text": "required requiring real-time responses",
    "start": "459960",
    "end": "462840"
  },
  {
    "text": "such as ad serving fraud detection and",
    "start": "462840",
    "end": "466259"
  },
  {
    "text": "personalized product recommendations to",
    "start": "466259",
    "end": "468060"
  },
  {
    "text": "name a few",
    "start": "468060",
    "end": "469319"
  },
  {
    "text": "for inference requests that take longer",
    "start": "469319",
    "end": "472680"
  },
  {
    "text": "than real time or maybe real time and",
    "start": "472680",
    "end": "474840"
  },
  {
    "text": "near real time sagemaker offers",
    "start": "474840",
    "end": "477240"
  },
  {
    "text": "asynchronous inferences which supports",
    "start": "477240",
    "end": "480599"
  },
  {
    "text": "processing times up to 15 minutes and",
    "start": "480599",
    "end": "483180"
  },
  {
    "text": "payloads up to one gigabyte async",
    "start": "483180",
    "end": "486000"
  },
  {
    "text": "inferences are best suited for use cases",
    "start": "486000",
    "end": "488280"
  },
  {
    "text": "requiring real-time user experience but",
    "start": "488280",
    "end": "491160"
  },
  {
    "text": "use large computer vision or NLP models",
    "start": "491160",
    "end": "495380"
  },
  {
    "text": "sagemaker also provides scalable and",
    "start": "495380",
    "end": "498479"
  },
  {
    "text": "cost effective ways to deploy your",
    "start": "498479",
    "end": "500460"
  },
  {
    "text": "machine learning models whether it is",
    "start": "500460",
    "end": "502620"
  },
  {
    "text": "one model or large number of models",
    "start": "502620",
    "end": "505699"
  },
  {
    "text": "sagemaker multimodal endpoints and",
    "start": "505699",
    "end": "509099"
  },
  {
    "text": "sagemaker multi-container endpoints",
    "start": "509099",
    "end": "511560"
  },
  {
    "text": "enable you to deploy hundreds of models",
    "start": "511560",
    "end": "514740"
  },
  {
    "text": "on a single endpoint improving the cost",
    "start": "514740",
    "end": "517320"
  },
  {
    "text": "Effectiveness while providing the",
    "start": "517320",
    "end": "519599"
  },
  {
    "text": "flexibility to utilize models as often",
    "start": "519599",
    "end": "523080"
  },
  {
    "text": "as you need them",
    "start": "523080",
    "end": "524520"
  },
  {
    "text": "for use cases with intermittent",
    "start": "524520",
    "end": "527040"
  },
  {
    "text": "inference request",
    "start": "527040",
    "end": "529040"
  },
  {
    "text": "sagemaker serverless inference",
    "start": "529040",
    "end": "531480"
  },
  {
    "text": "automatically Provisions scales up and",
    "start": "531480",
    "end": "534180"
  },
  {
    "text": "down ton of compute capacity based on",
    "start": "534180",
    "end": "536760"
  },
  {
    "text": "number of inference requests",
    "start": "536760",
    "end": "539100"
  },
  {
    "text": "sagemaker serverless inference service",
    "start": "539100",
    "end": "542160"
  },
  {
    "text": "automatically removes the need to manage",
    "start": "542160",
    "end": "544740"
  },
  {
    "text": "complex scaling workflows by ensuring",
    "start": "544740",
    "end": "547200"
  },
  {
    "text": "the exact amount of resources are",
    "start": "547200",
    "end": "549360"
  },
  {
    "text": "available for inference to save time and",
    "start": "549360",
    "end": "552240"
  },
  {
    "text": "money",
    "start": "552240",
    "end": "553019"
  },
  {
    "text": "for all other use cases other than",
    "start": "553019",
    "end": "555240"
  },
  {
    "text": "serverless use cases you can use Auto",
    "start": "555240",
    "end": "557760"
  },
  {
    "text": "scaling in sagemaker policies to",
    "start": "557760",
    "end": "560700"
  },
  {
    "text": "elastically scale the underlying compute",
    "start": "560700",
    "end": "563220"
  },
  {
    "text": "resources to accommodate fluctuations in",
    "start": "563220",
    "end": "566459"
  },
  {
    "text": "inference requests while reducing the",
    "start": "566459",
    "end": "568740"
  },
  {
    "text": "cost",
    "start": "568740",
    "end": "570019"
  },
  {
    "text": "sagemaker model deployment features are",
    "start": "570019",
    "end": "573060"
  },
  {
    "text": "natively integrated with machine",
    "start": "573060",
    "end": "574920"
  },
  {
    "text": "learning operations capabilities as a",
    "start": "574920",
    "end": "577860"
  },
  {
    "text": "result deploying one model or tens of",
    "start": "577860",
    "end": "581220"
  },
  {
    "text": "thousands of models sagemaker helps",
    "start": "581220",
    "end": "583740"
  },
  {
    "text": "offload the operational overhead",
    "start": "583740",
    "end": "585779"
  },
  {
    "text": "overhead of deploying scaling and",
    "start": "585779",
    "end": "589140"
  },
  {
    "text": "managing ml models in production while",
    "start": "589140",
    "end": "592200"
  },
  {
    "text": "also getting your models to prediction",
    "start": "592200",
    "end": "594120"
  },
  {
    "text": "faster",
    "start": "594120",
    "end": "595399"
  },
  {
    "text": "sagemaker also allows you to implement",
    "start": "595399",
    "end": "598140"
  },
  {
    "text": "Advanced deployment capabilities for",
    "start": "598140",
    "end": "600540"
  },
  {
    "text": "machine learning such as a b testing",
    "start": "600540",
    "end": "603180"
  },
  {
    "text": "Canary deployment blue green deployment",
    "start": "603180",
    "end": "606200"
  },
  {
    "text": "using these techniques data scientists",
    "start": "606200",
    "end": "608880"
  },
  {
    "text": "can rapidly release model updates about",
    "start": "608880",
    "end": "612120"
  },
  {
    "text": "avoid down times during deployments and",
    "start": "612120",
    "end": "615360"
  },
  {
    "text": "Benchmark the performance of their ml",
    "start": "615360",
    "end": "617399"
  },
  {
    "text": "models in development tasks and",
    "start": "617399",
    "end": "619380"
  },
  {
    "text": "production environments",
    "start": "619380",
    "end": "621260"
  },
  {
    "text": "sagemaker inference recommender after a",
    "start": "621260",
    "end": "624779"
  },
  {
    "text": "service which is optionally available to",
    "start": "624779",
    "end": "626640"
  },
  {
    "text": "you to automatically select the optimal",
    "start": "626640",
    "end": "629519"
  },
  {
    "text": "compute instances and configurations",
    "start": "629519",
    "end": "632760"
  },
  {
    "text": "to deploy your machine learning models",
    "start": "632760",
    "end": "634800"
  },
  {
    "text": "sagemaker inference recommender reduces",
    "start": "634800",
    "end": "637500"
  },
  {
    "text": "the time to deploy from weeks to hours",
    "start": "637500",
    "end": "640260"
  },
  {
    "text": "by automatically recommending the ideal",
    "start": "640260",
    "end": "642779"
  },
  {
    "text": "compute instance configurations and",
    "start": "642779",
    "end": "645180"
  },
  {
    "text": "model optimization",
    "start": "645180",
    "end": "647160"
  },
  {
    "text": "machine learning life cycle does not",
    "start": "647160",
    "end": "649560"
  },
  {
    "text": "stop here",
    "start": "649560",
    "end": "651240"
  },
  {
    "text": "once models are deployed they need to be",
    "start": "651240",
    "end": "654180"
  },
  {
    "text": "monitored for quality and performance",
    "start": "654180",
    "end": "656279"
  },
  {
    "text": "and retrained when you new data is",
    "start": "656279",
    "end": "658980"
  },
  {
    "text": "available or the business and user",
    "start": "658980",
    "end": "661500"
  },
  {
    "text": "Dynamics changes or there is a bias",
    "start": "661500",
    "end": "663959"
  },
  {
    "text": "detection",
    "start": "663959",
    "end": "665100"
  },
  {
    "text": "so model or drift detection so model",
    "start": "665100",
    "end": "667860"
  },
  {
    "text": "development and deployment is not a one",
    "start": "667860",
    "end": "670860"
  },
  {
    "text": "and done task",
    "start": "670860",
    "end": "672300"
  },
  {
    "text": "handling the iterative nature of ml",
    "start": "672300",
    "end": "674579"
  },
  {
    "text": "lifecycle requires ml Ops practice that",
    "start": "674579",
    "end": "678120"
  },
  {
    "text": "brings us to the next component of",
    "start": "678120",
    "end": "679860"
  },
  {
    "text": "Amazon sagemaker",
    "start": "679860",
    "end": "682140"
  },
  {
    "text": "Amazon Sage makers offer the ml Ops",
    "start": "682140",
    "end": "684839"
  },
  {
    "text": "capabilities it helps you automate and",
    "start": "684839",
    "end": "687720"
  },
  {
    "text": "standardize ml Ops practice across your",
    "start": "687720",
    "end": "690779"
  },
  {
    "text": "organization sagemaker pipelines is a",
    "start": "690779",
    "end": "694019"
  },
  {
    "text": "fully managed feature that helps you",
    "start": "694019",
    "end": "696060"
  },
  {
    "text": "automate and orchestrate different steps",
    "start": "696060",
    "end": "698940"
  },
  {
    "text": "of machine learning workflow sagemaker",
    "start": "698940",
    "end": "701880"
  },
  {
    "text": "projects specifically brings CI CD",
    "start": "701880",
    "end": "704579"
  },
  {
    "text": "capabilities to machine learning such as",
    "start": "704579",
    "end": "707160"
  },
  {
    "text": "maintaining parity between development",
    "start": "707160",
    "end": "709140"
  },
  {
    "text": "and production environments source and",
    "start": "709140",
    "end": "711480"
  },
  {
    "text": "Version Control automated testing and",
    "start": "711480",
    "end": "714300"
  },
  {
    "text": "end-to-end automation with sagemaker",
    "start": "714300",
    "end": "717180"
  },
  {
    "text": "model registry specifically you can",
    "start": "717180",
    "end": "719940"
  },
  {
    "text": "track model versions their metadata such",
    "start": "719940",
    "end": "722880"
  },
  {
    "text": "as use case grouping and model",
    "start": "722880",
    "end": "724920"
  },
  {
    "text": "performance metric Baseline in central",
    "start": "724920",
    "end": "727140"
  },
  {
    "text": "Repository",
    "start": "727140",
    "end": "728720"
  },
  {
    "text": "sagemaker logs every step of your",
    "start": "728720",
    "end": "731700"
  },
  {
    "text": "workflow creating an audit trail of",
    "start": "731700",
    "end": "734100"
  },
  {
    "text": "modern artifacts such as training data",
    "start": "734100",
    "end": "736740"
  },
  {
    "text": "platform configuration model parameters",
    "start": "736740",
    "end": "739920"
  },
  {
    "text": "and learning gradients",
    "start": "739920",
    "end": "741980"
  },
  {
    "text": "sagemaker model monitor specifically",
    "start": "741980",
    "end": "744779"
  },
  {
    "text": "detects model drift concept drift in",
    "start": "744779",
    "end": "747959"
  },
  {
    "text": "models deployed in production in real",
    "start": "747959",
    "end": "750480"
  },
  {
    "text": "time",
    "start": "750480",
    "end": "751260"
  },
  {
    "text": "and it's also integrated with sagemaker",
    "start": "751260",
    "end": "753720"
  },
  {
    "text": "pipelines and model registry allowing",
    "start": "753720",
    "end": "756180"
  },
  {
    "text": "you to automatically schedule model",
    "start": "756180",
    "end": "758160"
  },
  {
    "text": "monitoring as part of CI CD pipeline",
    "start": "758160",
    "end": "761760"
  },
  {
    "text": "sagemaker offers a comprehensive set of",
    "start": "761760",
    "end": "764760"
  },
  {
    "text": "security features as well including",
    "start": "764760",
    "end": "767160"
  },
  {
    "text": "infrastructure security data protection",
    "start": "767160",
    "end": "770180"
  },
  {
    "text": "authorization authentication and",
    "start": "770180",
    "end": "773240"
  },
  {
    "text": "auditability to help your organization",
    "start": "773240",
    "end": "776040"
  },
  {
    "text": "with security requirements that may",
    "start": "776040",
    "end": "778019"
  },
  {
    "text": "apply to your machine learning workflows",
    "start": "778019",
    "end": "780899"
  },
  {
    "text": "oh a lot of features available for ML",
    "start": "780899",
    "end": "784560"
  },
  {
    "text": "Ops",
    "start": "784560",
    "end": "785820"
  },
  {
    "text": "now that we have talked about how",
    "start": "785820",
    "end": "787920"
  },
  {
    "text": "sagemaker can help in training tuning",
    "start": "787920",
    "end": "790440"
  },
  {
    "text": "and deploy your ml models let's talk",
    "start": "790440",
    "end": "793019"
  },
  {
    "text": "about how to integrate sagemaker",
    "start": "793019",
    "end": "795240"
  },
  {
    "text": "endpoints with much modern data",
    "start": "795240",
    "end": "797519"
  },
  {
    "text": "architecture to bring everything",
    "start": "797519",
    "end": "799380"
  },
  {
    "text": "together",
    "start": "799380",
    "end": "801600"
  },
  {
    "text": "first up we have predictive maintenance",
    "start": "801600",
    "end": "803880"
  },
  {
    "text": "use cases where sensors deployed in the",
    "start": "803880",
    "end": "807000"
  },
  {
    "text": "field uh field need to be replaced or",
    "start": "807000",
    "end": "810660"
  },
  {
    "text": "rectified before they become faulty or",
    "start": "810660",
    "end": "813240"
  },
  {
    "text": "cause you downtime",
    "start": "813240",
    "end": "814800"
  },
  {
    "text": "so device sensors stream various",
    "start": "814800",
    "end": "817680"
  },
  {
    "text": "measurements and readings about your",
    "start": "817680",
    "end": "819839"
  },
  {
    "text": "machine parts to Amazon Kinesis data",
    "start": "819839",
    "end": "822000"
  },
  {
    "text": "stream as shown on the diagram this",
    "start": "822000",
    "end": "824940"
  },
  {
    "text": "example solution then takes a slice of",
    "start": "824940",
    "end": "827700"
  },
  {
    "text": "streaming data each time and performs",
    "start": "827700",
    "end": "830700"
  },
  {
    "text": "processing and feature engineering to",
    "start": "830700",
    "end": "832920"
  },
  {
    "text": "create new features the created features",
    "start": "832920",
    "end": "835800"
  },
  {
    "text": "are then used to generate inferences",
    "start": "835800",
    "end": "838079"
  },
  {
    "text": "from trained and deployed ml models in",
    "start": "838079",
    "end": "841800"
  },
  {
    "text": "near real time using sagemaker endpoint",
    "start": "841800",
    "end": "844500"
  },
  {
    "text": "the generated inferences can be further",
    "start": "844500",
    "end": "847500"
  },
  {
    "text": "processed and consumed by Downstream",
    "start": "847500",
    "end": "850320"
  },
  {
    "text": "application to take appropriate actions",
    "start": "850320",
    "end": "852839"
  },
  {
    "text": "and measures to initiate maintenance",
    "start": "852839",
    "end": "854880"
  },
  {
    "text": "activity",
    "start": "854880",
    "end": "857540"
  },
  {
    "text": "one of the biggest challenge is to cope",
    "start": "857940",
    "end": "860220"
  },
  {
    "text": "with copper with the amount of data and",
    "start": "860220",
    "end": "862740"
  },
  {
    "text": "the value of that data diminishes how it",
    "start": "862740",
    "end": "865620"
  },
  {
    "text": "diminishes over a period of time the",
    "start": "865620",
    "end": "868260"
  },
  {
    "text": "challenge is to analyze learn and infer",
    "start": "868260",
    "end": "871380"
  },
  {
    "text": "from the real-time data to predict",
    "start": "871380",
    "end": "873899"
  },
  {
    "text": "future State as well as to detect",
    "start": "873899",
    "end": "876120"
  },
  {
    "text": "anomalies and get accurate results in",
    "start": "876120",
    "end": "879300"
  },
  {
    "text": "this second example we are using Amazon",
    "start": "879300",
    "end": "882000"
  },
  {
    "text": "Kinesis data analytics for Apache Flink",
    "start": "882000",
    "end": "885420"
  },
  {
    "text": "with Amazon's sagemaker and Apache link",
    "start": "885420",
    "end": "889139"
  },
  {
    "text": "using API Gateway to address the",
    "start": "889139",
    "end": "892320"
  },
  {
    "text": "challenges",
    "start": "892320",
    "end": "893519"
  },
  {
    "text": "such as real-time fraud detection on a",
    "start": "893519",
    "end": "896339"
  },
  {
    "text": "stream of credit card transaction data",
    "start": "896339",
    "end": "898860"
  },
  {
    "text": "data is ingested in Kinesis data stream",
    "start": "898860",
    "end": "902000"
  },
  {
    "text": "using Kinesis producer library and then",
    "start": "902000",
    "end": "905519"
  },
  {
    "text": "Kinesis data stream then streams the",
    "start": "905519",
    "end": "907680"
  },
  {
    "text": "data to Apache Flink based Kinesis data",
    "start": "907680",
    "end": "910139"
  },
  {
    "text": "analytics application",
    "start": "910139",
    "end": "912060"
  },
  {
    "text": "Kinesis data analytics manages the",
    "start": "912060",
    "end": "915060"
  },
  {
    "text": "required infrastructure for Flink and",
    "start": "915060",
    "end": "917760"
  },
  {
    "text": "scales the application in response to",
    "start": "917760",
    "end": "920100"
  },
  {
    "text": "changing traffic patterns and",
    "start": "920100",
    "end": "922199"
  },
  {
    "text": "automatically recovers from underlying",
    "start": "922199",
    "end": "924240"
  },
  {
    "text": "failures",
    "start": "924240",
    "end": "925199"
  },
  {
    "text": "this is a perfect setup for real time in",
    "start": "925199",
    "end": "928380"
  },
  {
    "text": "a stream inference using sagemaker",
    "start": "928380",
    "end": "932100"
  },
  {
    "text": "as discussed typical machine learning",
    "start": "932100",
    "end": "934680"
  },
  {
    "text": "workflow involves processes such as data",
    "start": "934680",
    "end": "937260"
  },
  {
    "text": "extraction data pre-processing feature",
    "start": "937260",
    "end": "940320"
  },
  {
    "text": "engineering model training and",
    "start": "940320",
    "end": "942000"
  },
  {
    "text": "evaluation and deployment as data",
    "start": "942000",
    "end": "945360"
  },
  {
    "text": "changes over time when you deploy models",
    "start": "945360",
    "end": "948120"
  },
  {
    "text": "to production you want your models to",
    "start": "948120",
    "end": "950699"
  },
  {
    "text": "learn continually continuously from the",
    "start": "950699",
    "end": "953639"
  },
  {
    "text": "stream of data this means supporting the",
    "start": "953639",
    "end": "956220"
  },
  {
    "text": "model's ability to automate Auto",
    "start": "956220",
    "end": "958579"
  },
  {
    "text": "autonomously learning and adapting in",
    "start": "958579",
    "end": "961260"
  },
  {
    "text": "production as new data is added in",
    "start": "961260",
    "end": "964380"
  },
  {
    "text": "practice data scientists often work with",
    "start": "964380",
    "end": "967320"
  },
  {
    "text": "jupyter notebook for development work",
    "start": "967320",
    "end": "969720"
  },
  {
    "text": "and find it hard to translate these",
    "start": "969720",
    "end": "972360"
  },
  {
    "text": "notebooks into automated pipelines to",
    "start": "972360",
    "end": "975480"
  },
  {
    "text": "achieve the two fun main functions of ml",
    "start": "975480",
    "end": "978120"
  },
  {
    "text": "service in production namely retraining",
    "start": "978120",
    "end": "980820"
  },
  {
    "text": "and inference you can use this example",
    "start": "980820",
    "end": "983459"
  },
  {
    "text": "this example demonstrates how to",
    "start": "983459",
    "end": "986760"
  },
  {
    "text": "orchestrate an ml training pipeline",
    "start": "986760",
    "end": "988920"
  },
  {
    "text": "using AWS glue workflows and drain",
    "start": "988920",
    "end": "992040"
  },
  {
    "text": "deploy the models using Amazon sagemaker",
    "start": "992040",
    "end": "995160"
  },
  {
    "text": "for this use case you can use AWS glue",
    "start": "995160",
    "end": "998820"
  },
  {
    "text": "workflows to build an end-to-end machine",
    "start": "998820",
    "end": "1001579"
  },
  {
    "text": "learning training pipeline that covers",
    "start": "1001579",
    "end": "1004040"
  },
  {
    "text": "data extraction data processing training",
    "start": "1004040",
    "end": "1007040"
  },
  {
    "text": "deploying the models to Amazon sagemaker",
    "start": "1007040",
    "end": "1009680"
  },
  {
    "text": "endpoint pretty cool",
    "start": "1009680",
    "end": "1013160"
  },
  {
    "text": "analyzing transforming and preparing",
    "start": "1013160",
    "end": "1016339"
  },
  {
    "text": "large amount of data is foundational",
    "start": "1016339",
    "end": "1018680"
  },
  {
    "text": "step for any data science project data",
    "start": "1018680",
    "end": "1021920"
  },
  {
    "text": "scientist and data Engineers sometimes",
    "start": "1021920",
    "end": "1024020"
  },
  {
    "text": "use Apache spark Hive and Presto running",
    "start": "1024020",
    "end": "1028280"
  },
  {
    "text": "on Amazon EMR for fast data preparation",
    "start": "1028280",
    "end": "1032260"
  },
  {
    "text": "sagemaker Studio comes with built-in",
    "start": "1032260",
    "end": "1035298"
  },
  {
    "text": "integration with Amazon EMR EMR enabling",
    "start": "1035299",
    "end": "1039860"
  },
  {
    "text": "you to do petabyte scale interactive",
    "start": "1039860",
    "end": "1041959"
  },
  {
    "text": "data preparation and machine learning",
    "start": "1041959",
    "end": "1044298"
  },
  {
    "text": "right within the studio notebook",
    "start": "1044299",
    "end": "1046459"
  },
  {
    "text": "in this example of predicting the",
    "start": "1046459",
    "end": "1048740"
  },
  {
    "text": "sentiment of a movie review you can run",
    "start": "1048740",
    "end": "1052160"
  },
  {
    "text": "an end-to-end ml workflow including",
    "start": "1052160",
    "end": "1054860"
  },
  {
    "text": "preparing data monitoring spark jobs and",
    "start": "1054860",
    "end": "1057919"
  },
  {
    "text": "training and deploying an ml model to",
    "start": "1057919",
    "end": "1059780"
  },
  {
    "text": "get prediction all from the same Studio",
    "start": "1059780",
    "end": "1062419"
  },
  {
    "text": "notebook",
    "start": "1062419",
    "end": "1063799"
  },
  {
    "text": "sagemaker provides an Apache spark",
    "start": "1063799",
    "end": "1066200"
  },
  {
    "text": "library in both Python and Scala that",
    "start": "1066200",
    "end": "1069500"
  },
  {
    "text": "you can use to easily train and tune",
    "start": "1069500",
    "end": "1071059"
  },
  {
    "text": "your models in sagemaker before",
    "start": "1071059",
    "end": "1073160"
  },
  {
    "text": "deploying at an end point",
    "start": "1073160",
    "end": "1075320"
  },
  {
    "text": "very powerful",
    "start": "1075320",
    "end": "1077660"
  },
  {
    "text": "another example can be natural language",
    "start": "1077660",
    "end": "1079940"
  },
  {
    "text": "understanding powered Search application",
    "start": "1079940",
    "end": "1082160"
  },
  {
    "text": "using sagemaker and Amazon open search",
    "start": "1082160",
    "end": "1085580"
  },
  {
    "text": "which was previously known as Amazon",
    "start": "1085580",
    "end": "1087740"
  },
  {
    "text": "Amazon elasticsearch",
    "start": "1087740",
    "end": "1089840"
  },
  {
    "text": "regular open search regular",
    "start": "1089840",
    "end": "1092360"
  },
  {
    "text": "elasticsearch text message and matching",
    "start": "1092360",
    "end": "1094880"
  },
  {
    "text": "search is useful when you want to do a",
    "start": "1094880",
    "end": "1097520"
  },
  {
    "text": "text-based search but K nearest neighbor",
    "start": "1097520",
    "end": "1099980"
  },
  {
    "text": "based search is more natural way to",
    "start": "1099980",
    "end": "1103340"
  },
  {
    "text": "search for something for example when",
    "start": "1103340",
    "end": "1106340"
  },
  {
    "text": "you search for a wedding dress using a k",
    "start": "1106340",
    "end": "1108799"
  },
  {
    "text": "n based Search application it gives you",
    "start": "1108799",
    "end": "1111380"
  },
  {
    "text": "similar results for if you type wedding",
    "start": "1111380",
    "end": "1114140"
  },
  {
    "text": "dress or marriage dress",
    "start": "1114140",
    "end": "1116480"
  },
  {
    "text": "this example demonstrates demonstrate",
    "start": "1116480",
    "end": "1119240"
  },
  {
    "text": "two phases of this application first",
    "start": "1119240",
    "end": "1121880"
  },
  {
    "text": "building the k n reference index and",
    "start": "1121880",
    "end": "1124580"
  },
  {
    "text": "then querying the index for results so",
    "start": "1124580",
    "end": "1126919"
  },
  {
    "text": "using Amazon sagemaker with open search",
    "start": "1126919",
    "end": "1129200"
  },
  {
    "text": "service for k n index feature you can",
    "start": "1129200",
    "end": "1132679"
  },
  {
    "text": "have k n based Search application which",
    "start": "1132679",
    "end": "1135260"
  },
  {
    "text": "can connect to any front-end user",
    "start": "1135260",
    "end": "1136940"
  },
  {
    "text": "experiences",
    "start": "1136940",
    "end": "1139160"
  },
  {
    "text": "last but not the least in this final",
    "start": "1139160",
    "end": "1141620"
  },
  {
    "text": "example you can also connect Amazon",
    "start": "1141620",
    "end": "1144260"
  },
  {
    "text": "sagemaker Jupiter notebooks to the",
    "start": "1144260",
    "end": "1146720"
  },
  {
    "text": "Amazon redshift cluster and run data API",
    "start": "1146720",
    "end": "1149900"
  },
  {
    "text": "commands in Python this in place",
    "start": "1149900",
    "end": "1152780"
  },
  {
    "text": "analysis is an effective way to pull",
    "start": "1152780",
    "end": "1155780"
  },
  {
    "text": "data directly into jupyter notebook",
    "start": "1155780",
    "end": "1158419"
  },
  {
    "text": "object and then apply transformation on",
    "start": "1158419",
    "end": "1161299"
  },
  {
    "text": "for further understanding processing or",
    "start": "1161299",
    "end": "1164600"
  },
  {
    "text": "feature engineering",
    "start": "1164600",
    "end": "1166100"
  },
  {
    "text": "the Amazon redshift data API makes it",
    "start": "1166100",
    "end": "1169520"
  },
  {
    "text": "easy for any application written in",
    "start": "1169520",
    "end": "1172340"
  },
  {
    "text": "popular programming languages to",
    "start": "1172340",
    "end": "1174679"
  },
  {
    "text": "interact with Amazon redshift",
    "start": "1174679",
    "end": "1176840"
  },
  {
    "text": "after exploring you can Implement",
    "start": "1176840",
    "end": "1179000"
  },
  {
    "text": "machine learning models in Amazon",
    "start": "1179000",
    "end": "1180559"
  },
  {
    "text": "sagemaker using data stored in Amazon",
    "start": "1180559",
    "end": "1183440"
  },
  {
    "text": "redshift cluster you can make use of",
    "start": "1183440",
    "end": "1186140"
  },
  {
    "text": "data build train and test and ml",
    "start": "1186140",
    "end": "1189500"
  },
  {
    "text": "algorithm in Amazon sagemaker and",
    "start": "1189500",
    "end": "1192020"
  },
  {
    "text": "finally you can deploy that model in",
    "start": "1192020",
    "end": "1194179"
  },
  {
    "text": "Amazon sagemaker instance and draw",
    "start": "1194179",
    "end": "1196400"
  },
  {
    "text": "inferences",
    "start": "1196400",
    "end": "1198020"
  },
  {
    "text": "there are these are just a few examples",
    "start": "1198020",
    "end": "1200660"
  },
  {
    "text": "there are hundreds of different use",
    "start": "1200660",
    "end": "1202640"
  },
  {
    "text": "cases and examples are out there for you",
    "start": "1202640",
    "end": "1206000"
  },
  {
    "text": "the different ways you can integrate",
    "start": "1206000",
    "end": "1207679"
  },
  {
    "text": "sagemaker in modern data architecture",
    "start": "1207679",
    "end": "1209720"
  },
  {
    "text": "for machine learning predictions",
    "start": "1209720",
    "end": "1212660"
  },
  {
    "text": "this brings us to the end of this",
    "start": "1212660",
    "end": "1214460"
  },
  {
    "text": "episode information share here is just a",
    "start": "1214460",
    "end": "1217700"
  },
  {
    "text": "tip of an iceberg to learn more about",
    "start": "1217700",
    "end": "1219919"
  },
  {
    "text": "modern data architecture and sagemaker",
    "start": "1219919",
    "end": "1222679"
  },
  {
    "text": "please watch other episodes of this",
    "start": "1222679",
    "end": "1224900"
  },
  {
    "text": "series and please do check out the link",
    "start": "1224900",
    "end": "1227059"
  },
  {
    "text": "shared Below in the next episode of",
    "start": "1227059",
    "end": "1229700"
  },
  {
    "text": "analytics white series we'll talk about",
    "start": "1229700",
    "end": "1231980"
  },
  {
    "text": "real-time search and log analytics with",
    "start": "1231980",
    "end": "1235640"
  },
  {
    "text": "Amazon open search thank you again for",
    "start": "1235640",
    "end": "1238820"
  },
  {
    "text": "joining this episode of analytics byte",
    "start": "1238820",
    "end": "1240919"
  },
  {
    "text": "series we'll see you in the next one",
    "start": "1240919",
    "end": "1242900"
  },
  {
    "text": "goodbye",
    "start": "1242900",
    "end": "1245900"
  }
]
[
  {
    "start": "0",
    "end": "16000"
  },
  {
    "text": "hello everyone good afternoon my name is Anand I'm from reddit here to talk about how reddit scaled to 1 billion plus",
    "start": "240",
    "end": "8309"
  },
  {
    "text": "video views using AWS and the session now we are ideas CTD 3:20 so a little",
    "start": "8309",
    "end": "16770"
  },
  {
    "start": "16000",
    "end": "69000"
  },
  {
    "text": "bit about me so I grew up in India and moved to the u.s. to work to do my",
    "start": "16770",
    "end": "23820"
  },
  {
    "text": "Master's at Purdue University and then spent about eight years at Microsoft working on a variety of different things",
    "start": "23820",
    "end": "29820"
  },
  {
    "text": "compilers big data connectors excel connectors and most notably I spent like",
    "start": "29820",
    "end": "37200"
  },
  {
    "text": "over three years as the engineering manager for the power bi team and scaled",
    "start": "37200",
    "end": "42780"
  },
  {
    "text": "it up from 0 to 5 million subscribers here at reddit right now I'm a director",
    "start": "42780",
    "end": "48329"
  },
  {
    "text": "for the AI and machine learning group called the knowledge group at reddit and in the last year I've worked on us",
    "start": "48329",
    "end": "54960"
  },
  {
    "text": "several different things like the web platform for reddit the native video platform that I'm going to talk about today and as well as I led the redesign",
    "start": "54960",
    "end": "62670"
  },
  {
    "text": "the reddit redesign massive redesign from its original inception so this is",
    "start": "62670",
    "end": "70799"
  },
  {
    "start": "69000",
    "end": "85000"
  },
  {
    "text": "kind of what I'm gonna cover today give a high-level overview of what read it is the reddit architecture and talk about",
    "start": "70799",
    "end": "77340"
  },
  {
    "text": "why we build video and a deep dive into the video pipeline and what were some results and some lessons learned quick",
    "start": "77340",
    "end": "87180"
  },
  {
    "start": "85000",
    "end": "161000"
  },
  {
    "text": "poll how many of you use reddit here often nice ok so I can breathe through",
    "start": "87180",
    "end": "92189"
  },
  {
    "text": "breeze through these slides soon so reddit is a platform for finding",
    "start": "92189",
    "end": "98970"
  },
  {
    "text": "different communities that you're passionate about and where you can have authentic conversations as most of you know reddit you don't need real identity",
    "start": "98970",
    "end": "107280"
  },
  {
    "text": "because of the psuedo enormous accounts you get authentic conversations and at",
    "start": "107280",
    "end": "112710"
  },
  {
    "text": "the core of reddit is communities where reddit is powered by community and community rules so we have communities",
    "start": "112710",
    "end": "119250"
  },
  {
    "text": "for video you follow their rules only post videos and so yeah check it out if",
    "start": "119250",
    "end": "125340"
  },
  {
    "text": "you haven't already checked it so even people who use reddit often they don't know how big reddit is by the numbers so",
    "start": "125340",
    "end": "132239"
  },
  {
    "text": "alex surfer for those who don't dranks the websites by their engagement and the time spent on the subreddit on",
    "start": "132239",
    "end": "138840"
  },
  {
    "text": "the site so reddit is at first in the u.s. ranked first in the US and 14th",
    "start": "138840",
    "end": "144600"
  },
  {
    "text": "globally and we have about three hundred and thirty million monthly active users and about 138 thousand active",
    "start": "144600",
    "end": "152940"
  },
  {
    "text": "communities and with problem lean posts per month 96 millions per month and two",
    "start": "152940",
    "end": "158250"
  },
  {
    "text": "billion ODEs per month so that's a lot of millions of millions of people a lot",
    "start": "158250",
    "end": "164970"
  },
  {
    "start": "161000",
    "end": "455000"
  },
  {
    "text": "of content so how do we build this one",
    "start": "164970",
    "end": "171440"
  },
  {
    "text": "so let's dig into what the site looks like so this is a very high-level overview of what the reddit architecture",
    "start": "171860",
    "end": "179040"
  },
  {
    "text": "looks like and it's focused more mainly on the core experiences I have left out",
    "start": "179040",
    "end": "185160"
  },
  {
    "text": "some interesting pieces like the data analysis stack machine learning stack ad start but like this is what powers the",
    "start": "185160",
    "end": "191100"
  },
  {
    "text": "core reddit experience so the one in the",
    "start": "191100",
    "end": "197070"
  },
  {
    "text": "middle it's called the giant blob it's called r2 what we call as r2 it's been",
    "start": "197070",
    "end": "202320"
  },
  {
    "text": "and it's an original monolithic application which has been reddit since 2008 and this is one big Python blob and",
    "start": "202320",
    "end": "210270"
  },
  {
    "text": "we'll talk about a little bit more detail in the coming slides so we just",
    "start": "210270",
    "end": "217860"
  },
  {
    "text": "added of new front-end applications like we had a handful of print and engineers",
    "start": "217860",
    "end": "223440"
  },
  {
    "text": "who really got frustrated with the outdated technology not to wear last January couple of my engineers went in",
    "start": "223440",
    "end": "229950"
  },
  {
    "text": "built node based modern applications and it shares code between client and the",
    "start": "229950",
    "end": "235170"
  },
  {
    "text": "server and these front-end applications are basic it acts like any other third",
    "start": "235170",
    "end": "241590"
  },
  {
    "text": "party API clients that reddit has so it uses a PS through the gateway or talks",
    "start": "241590",
    "end": "246780"
  },
  {
    "text": "directly to r2 we're also in the process of splitting",
    "start": "246780",
    "end": "252240"
  },
  {
    "text": "the monolithic r2 service into multiple micro services so the key thing to note",
    "start": "252240",
    "end": "259019"
  },
  {
    "text": "here is like each of so each of these are individual teams we have individual",
    "start": "259020",
    "end": "266220"
  },
  {
    "text": "teams responsible for every one of those services so we have a team for search we have a team for word",
    "start": "266220",
    "end": "271379"
  },
  {
    "text": "listing service we have a team for a pas etc so all of these new services are",
    "start": "271379",
    "end": "276930"
  },
  {
    "text": "being written in Python which was easier for us to split from our original Python",
    "start": "276930",
    "end": "283789"
  },
  {
    "text": "monolith and this also we also use a common library or a framework which",
    "start": "283789",
    "end": "288860"
  },
  {
    "text": "avoided as to not reinvent the wheel over and over again when we are building these new services and the framework",
    "start": "288860",
    "end": "295080"
  },
  {
    "text": "also provided as useful things like monitoring and tracing so each services",
    "start": "295080",
    "end": "300419"
  },
  {
    "text": "can be plugged into a data pipeline and these backends are written using thrift",
    "start": "300419",
    "end": "307560"
  },
  {
    "text": "and we also have a HTTP on the front-end so that the API gateway can talk to",
    "start": "307560",
    "end": "313469"
  },
  {
    "text": "these services from the outside as well like I mentioned our to the one we call",
    "start": "313469",
    "end": "320939"
  },
  {
    "text": "as r2 is kind of the original reddit and it's really complicated and it's it's a it's a beast by itself so have a like a",
    "start": "320939",
    "end": "328560"
  },
  {
    "text": "blown-up diagram for to walk through some of the key components of r2 so we",
    "start": "328560",
    "end": "336150"
  },
  {
    "text": "have a bunch of app servers and excuse me same code is deployed to all servers",
    "start": "336150",
    "end": "341400"
  },
  {
    "text": "and but excuse me each server might be",
    "start": "341400",
    "end": "346860"
  },
  {
    "text": "running a different request path and but the same stuff is deployed everywhere",
    "start": "346860",
    "end": "353639"
  },
  {
    "text": "and so we have also load balancers in the front which uses HTTP proxy and the",
    "start": "353639",
    "end": "361979"
  },
  {
    "text": "point is to split the user requests that come from different clients and isolate them into application tools it has been",
    "start": "361979",
    "end": "368189"
  },
  {
    "text": "super handy for us to do this because let's say if our comments pages ApS are",
    "start": "368189",
    "end": "373560"
  },
  {
    "text": "slow and it's running into some outages and people try to visit the front page or the they try to submit a post those",
    "start": "373560",
    "end": "382229"
  },
  {
    "text": "things don't get impacted and it has been super helpful for us and we didn't run into beard issues and so along with",
    "start": "382229",
    "end": "390120"
  },
  {
    "text": "the simple operations like uploading and submitting a post we also have some expensive operations that run which we",
    "start": "390120",
    "end": "397560"
  },
  {
    "text": "defer it to as an async job into our rabbit MQ and most problem most usually those get",
    "start": "397560",
    "end": "403710"
  },
  {
    "text": "processed pretty quickly and in this section which is the Postgres sequel and",
    "start": "403710",
    "end": "409950"
  },
  {
    "text": "the cache and the the thing which is highlighted below it's the core data model at reddit if you think about the",
    "start": "409950",
    "end": "416550"
  },
  {
    "text": "core of Reddit which is comments post subreddits accounts links and any kind",
    "start": "416550",
    "end": "424410"
  },
  {
    "text": "of post all these are defined by using our core data model called thing and",
    "start": "424410",
    "end": "429510"
  },
  {
    "text": "it's stored in the post class sequel and we have a memcache in front of it and we",
    "start": "429510",
    "end": "437040"
  },
  {
    "text": "have been using cassandra for almost little little over eight years and it's been super handy for us whenever",
    "start": "437040",
    "end": "443490"
  },
  {
    "text": "building the new features and one of the abilities that we really liked about this is the when one of the nodes going",
    "start": "443490",
    "end": "450210"
  },
  {
    "text": "down you can still continue using it so that's a super high level of what the",
    "start": "450210",
    "end": "457320"
  },
  {
    "start": "455000",
    "end": "663000"
  },
  {
    "text": "reddit architecture for just serving the code reddit experiences so let's talk about why reddit",
    "start": "457320",
    "end": "464040"
  },
  {
    "text": "neo decided to build video right in reddit like we have different types of",
    "start": "464040",
    "end": "470100"
  },
  {
    "text": "contents link post self post which is basically expose images videos gifs and",
    "start": "470100",
    "end": "475250"
  },
  {
    "text": "also links so but turns out video is one of our most Collar popular content types",
    "start": "475250",
    "end": "481110"
  },
  {
    "text": "and I just want to show a couple of sample videos that existed before we built this tell me if you don't like",
    "start": "481110",
    "end": "487830"
  },
  {
    "text": "this so that's a cat fist-bumping and a",
    "start": "487830",
    "end": "492870"
  },
  {
    "text": "human with like about a million views and this got about like I think hundred",
    "start": "492870",
    "end": "500700"
  },
  {
    "text": "thousand upwards so it's a lot of engagement for a contents like this and this one it's a cat walking a human",
    "start": "500700",
    "end": "507890"
  },
  {
    "text": "clearly a future where cats are in church and this again got close to a",
    "start": "507890",
    "end": "512909"
  },
  {
    "text": "half a million views and half a million upwards so the videos is like really an",
    "start": "512910",
    "end": "517979"
  },
  {
    "text": "engaging content and Reddit and it's a core part of Reddit why else did we decide to build it so it turns out if",
    "start": "517980",
    "end": "525780"
  },
  {
    "text": "you had to submit a video post and read it there's no native support so we obviously wanted to do it for that",
    "start": "525780",
    "end": "531510"
  },
  {
    "text": "reason and said mentioned earlier communities are the key and the core part of Reddit",
    "start": "531510",
    "end": "537100"
  },
  {
    "text": "and we wanted to give communities new ways to express and communities whatever we have found in reddit as their they",
    "start": "537100",
    "end": "543940"
  },
  {
    "text": "are super creative and you give them something simple they come up with like really interesting use cases and the",
    "start": "543940",
    "end": "550060"
  },
  {
    "text": "mobile opportunity like our options are endless we can innovate in our product before we couldn't do interesting things",
    "start": "550060",
    "end": "557920"
  },
  {
    "text": "like for example on the on the picture on the left so we doing a video post",
    "start": "557920",
    "end": "563380"
  },
  {
    "text": "when I'm scrolling through and looking the comments I can still see the video we are able to do all those things",
    "start": "563380",
    "end": "569170"
  },
  {
    "text": "because we had our native we could build our native video platform and obviously like it's a really high engaging content",
    "start": "569170",
    "end": "575500"
  },
  {
    "text": "so people like media so these are some of the key reasons and the last one was",
    "start": "575500",
    "end": "581710"
  },
  {
    "text": "around the way we did embedding for a video of like there are a lot of",
    "start": "581710",
    "end": "587380"
  },
  {
    "text": "different third-party video sites and it also helped us build a better performant",
    "start": "587380",
    "end": "592930"
  },
  {
    "text": "experiences when we had our own native platform so let's talk about what are",
    "start": "592930",
    "end": "598840"
  },
  {
    "text": "the key problems now that we have trying to build it what are the problems that",
    "start": "598840",
    "end": "605410"
  },
  {
    "text": "we were trying to solve first of all as I mentioned we didn't have a native upload experience it was really really",
    "start": "605410",
    "end": "611860"
  },
  {
    "text": "cumbersome so this gif talks about how you go to a third-party site like giffy or a major upload your video wait for",
    "start": "611860",
    "end": "618670"
  },
  {
    "text": "the video to be processed get a link and come back to read it and then you find a community and then you post it and then",
    "start": "618670",
    "end": "624820"
  },
  {
    "text": "pray to God that it is not going to get removed by Auto mods or the community rules so it was really really extremely",
    "start": "624820",
    "end": "630910"
  },
  {
    "text": "cumbersome and so people we didn't find a lot of new creators trying or",
    "start": "630910",
    "end": "637030"
  },
  {
    "text": "experienced and the other one was like I mentioned it's like the playback issues with when you don't have your native",
    "start": "637030",
    "end": "644320"
  },
  {
    "text": "platform we couldn't build interesting experiences to take into consideration of the slow network connectivity and the",
    "start": "644320",
    "end": "652390"
  },
  {
    "text": "latest technologies so all this limited engagement in our app and we wanted to",
    "start": "652390",
    "end": "658480"
  },
  {
    "text": "build a really clear user experience for these use cases so we looked at why we",
    "start": "658480",
    "end": "665770"
  },
  {
    "start": "663000",
    "end": "951000"
  },
  {
    "text": "need to build and some of the video problems I just want to walk through a couple of the key requirements we had to consider when you",
    "start": "665770",
    "end": "672199"
  },
  {
    "text": "are building this platform the first one was the run post right it's straightforward like when you upload a",
    "start": "672199",
    "end": "677959"
  },
  {
    "text": "pose it needs to go live once the video processing is done and so we want to enable it at the right time so that we",
    "start": "677959",
    "end": "684529"
  },
  {
    "text": "don't with the way it reddit works we don't want to penalize for the hot algorithm and it also needed to",
    "start": "684529",
    "end": "690319"
  },
  {
    "text": "integrated with the existing auto mode applications or the community validation of the rules as well as have a really",
    "start": "690319",
    "end": "697309"
  },
  {
    "text": "good experience built around the user getting real-time feedback what's happening is when the video is getting",
    "start": "697309",
    "end": "702679"
  },
  {
    "text": "processed when it's getting done and if it failed what they need to do and we also take privacy really seriously at",
    "start": "702679",
    "end": "710119"
  },
  {
    "text": "reddit and so we we also need to strip out the geodetic geo tagging data from",
    "start": "710119",
    "end": "716029"
  },
  {
    "text": "the video and we'll talk about how elastic transcoding helped us do that as",
    "start": "716029",
    "end": "721879"
  },
  {
    "text": "well so that's on the post requirements from the reddit post requirement side in terms of the video like we had a few",
    "start": "721879",
    "end": "727879"
  },
  {
    "text": "other requirements that we need to take into account so initially or the primary reason we want we went with mp4 was for",
    "start": "727879",
    "end": "735739"
  },
  {
    "text": "the performance reasons right like serving a huge gift to clients where would be a would be really bad and so",
    "start": "735739",
    "end": "744199"
  },
  {
    "text": "the way we supported gif in reddit today is like we take these mp4 videos and strip out the audio and then limit the",
    "start": "744199",
    "end": "751099"
  },
  {
    "text": "the video length to about a minute and let them auto loop the video so that's",
    "start": "751099",
    "end": "756109"
  },
  {
    "text": "how we do gifts in reddit but we don't have a direct gift support and also we",
    "start": "756109",
    "end": "762470"
  },
  {
    "text": "some of the other we also limited the number the long the length of the video that you could upload to about an hour",
    "start": "762470",
    "end": "769189"
  },
  {
    "text": "or a maximum size of a gigabyte and it gives Farabaugh like less than a minute and we also built experiences around how",
    "start": "769189",
    "end": "777169"
  },
  {
    "text": "you can like primarily we were targeting native audiences so we could we also",
    "start": "777169",
    "end": "782689"
  },
  {
    "text": "build the experience where we need to trim it out and the last but not the least was the the cross-platform we",
    "start": "782689",
    "end": "788659"
  },
  {
    "text": "needed to support it in all the different platforms and adapters streaming was something we needed to",
    "start": "788659",
    "end": "794239"
  },
  {
    "text": "take into consideration it's something for performances like for degrading",
    "start": "794239",
    "end": "799250"
  },
  {
    "text": "the connection speeds how does the video perform well so playback over low-speed environments",
    "start": "799250",
    "end": "806389"
  },
  {
    "text": "needs to be considered and we also had like - and a chalice video types dashes",
    "start": "806389",
    "end": "813589"
  },
  {
    "text": "for web and Android plans and a chalice is the apple standard for all iOS and Apple devices oh and the other",
    "start": "813589",
    "end": "822250"
  },
  {
    "text": "requirement I messed out is like reddit users are very change hours so we also",
    "start": "822250",
    "end": "828079"
  },
  {
    "text": "needed a way to build it in a way that we can roll it out to smaller audience like we can target a particular",
    "start": "828079",
    "end": "834139"
  },
  {
    "text": "community and just let them in and then go from there so these are some of the requirements and I think the interesting requirement",
    "start": "834139",
    "end": "841490"
  },
  {
    "text": "for this talk is probably around the infrastructure requirements that we had so we wanted something easy to manage",
    "start": "841490",
    "end": "847819"
  },
  {
    "text": "and handle the scale at reddit we call it sometimes hug of death so when you",
    "start": "847819",
    "end": "853040"
  },
  {
    "text": "build something for reddit you need to handle the scale of Reddit we also need to deal with spiky demands we have seen",
    "start": "853040",
    "end": "860209"
  },
  {
    "text": "a pattern where 5 to 8 a.m. in the mornings we get like a huge spike of video submissions and external events",
    "start": "860209",
    "end": "867050"
  },
  {
    "text": "like gaming concerts we get we get a spike of events so we wanted to make sure we have the elastic capability in",
    "start": "867050",
    "end": "873139"
  },
  {
    "text": "and that of course a rapid processing time is something key metric that we",
    "start": "873139",
    "end": "878990"
  },
  {
    "text": "targeted for this one of our KPI is that like when you build this video uploading tool like the whole processing time",
    "start": "878990",
    "end": "884420"
  },
  {
    "text": "should be in a write expected range and the last one and the most important one",
    "start": "884420",
    "end": "891410"
  },
  {
    "text": "for us was minimal in-house infrastructure when I'm what I same way that is like at this time when we",
    "start": "891410",
    "end": "896809"
  },
  {
    "text": "started building reddit video the whole engineering org or the number of",
    "start": "896809",
    "end": "902449"
  },
  {
    "text": "engineers in red it were like 40 engineers and the people who are working on this video project were like -",
    "start": "902449",
    "end": "907639"
  },
  {
    "text": "engineers like this one one engineer working on half time and he was a",
    "start": "907639",
    "end": "912680"
  },
  {
    "text": "manager and another engineer working on at full time and we had a couple of vendors helping out with the client stuff like we held like really really",
    "start": "912680",
    "end": "918709"
  },
  {
    "text": "limited resources and if you had to build this in house like a transcoding cluster it would have been a massive",
    "start": "918709",
    "end": "924829"
  },
  {
    "text": "massive undertaking and we couldn't handle that scale we probably need about like 30 40 people just maintaining that",
    "start": "924829",
    "end": "931279"
  },
  {
    "text": "transcoding Lester and again the ffmpeg transcoder",
    "start": "931279",
    "end": "936879"
  },
  {
    "text": "system is it brings with a lot of its own intricacies and it's not something we did we didn't we didn't want to deal",
    "start": "936879",
    "end": "943540"
  },
  {
    "text": "with and last one is for us it's like monitoring and observability is was really important so these were some of",
    "start": "943540",
    "end": "950230"
  },
  {
    "text": "the key requirements that we went in for building the video so let's take a quick",
    "start": "950230",
    "end": "956199"
  },
  {
    "start": "951000",
    "end": "1119000"
  },
  {
    "text": "look at what the reddit video pipeline looks like today and just wanted to",
    "start": "956199",
    "end": "962529"
  },
  {
    "text": "share like one of our first viral video so if you guys know what reddit is it's the it has like communities but it also",
    "start": "962529",
    "end": "969579"
  },
  {
    "text": "has this friend page it's called our popular and this was one of the first videos that hit our popular after a few",
    "start": "969579",
    "end": "976779"
  },
  {
    "text": "months of launching it it was like a monumental moment for monumental momentum moment for us and this kicked",
    "start": "976779",
    "end": "983860"
  },
  {
    "text": "off a lot of growth in Reddit and this video got about like a half a million",
    "start": "983860",
    "end": "989019"
  },
  {
    "text": "views and which made us really feel good and move forward with that plan so what",
    "start": "989019",
    "end": "995290"
  },
  {
    "text": "does the stack look like today so we",
    "start": "995290",
    "end": "1001619"
  },
  {
    "text": "have a we have I'll give a very quick overview of like the whole end-to-end",
    "start": "1001619",
    "end": "1007439"
  },
  {
    "text": "stack and then walk through in depth for each one of them so the client the",
    "start": "1007439",
    "end": "1012449"
  },
  {
    "text": "mobile or web or like a mobile or web they request r2 for a signed lease to",
    "start": "1012449",
    "end": "1021660"
  },
  {
    "text": "upload the video right and then the video gets uploaded to one of the temp",
    "start": "1021660",
    "end": "1026850"
  },
  {
    "text": "buckets and I'll talk about why we need at the time buckets in a bit and once",
    "start": "1026850",
    "end": "1032038"
  },
  {
    "text": "the video is uploaded we do the kind of the validation and the security checks that we need to run on these videos and",
    "start": "1032039",
    "end": "1039058"
  },
  {
    "text": "then the video upload queue which is right over there which helps up helps",
    "start": "1039059",
    "end": "1044788"
  },
  {
    "text": "with the validation and moving from the temporary bucket to the to the permanent bucket and once the video gets to the",
    "start": "1044789",
    "end": "1052110"
  },
  {
    "text": "permanent bucket it triggers a Fire's or s3 object creation event which invokes",
    "start": "1052110",
    "end": "1059070"
  },
  {
    "text": "the lambda over there and the lambda has a bunch of presets",
    "start": "1059070",
    "end": "1065520"
  },
  {
    "text": "and then it kicks off the transcoding job and once the transcoding is done it",
    "start": "1065520",
    "end": "1071910"
  },
  {
    "text": "drops the video into the transcode bucket right and then once the transcoding job is done based on the",
    "start": "1071910",
    "end": "1077940"
  },
  {
    "text": "results success or a failure we the elastic transcoder sends a message to via SNS through sqs to say",
    "start": "1077940",
    "end": "1085920"
  },
  {
    "text": "the job was done and if a success or failure which our EDS completion queue",
    "start": "1085920",
    "end": "1092640"
  },
  {
    "text": "picks it up and notifies the user this is kind of like the overall flow for what the reddit video pipeline looks",
    "start": "1092640",
    "end": "1099179"
  },
  {
    "text": "like and this is just a zoomed in",
    "start": "1099179",
    "end": "1106559"
  },
  {
    "text": "version of just the transcoding pipeline piece highlights the different Amazon management services that we leveraged",
    "start": "1106559",
    "end": "1114000"
  },
  {
    "text": "for building the transcoding pipeline and with that so let's let's zoom into",
    "start": "1114000",
    "end": "1121200"
  },
  {
    "start": "1119000",
    "end": "1430000"
  },
  {
    "text": "individual components in the video pipeline and see what happens in each of those components so the first one the",
    "start": "1121200",
    "end": "1129240"
  },
  {
    "text": "client upload the interesting pieces here were like because we use this temporary bucket we needed to get our signed urls from s3 for the plan to",
    "start": "1129240",
    "end": "1137190"
  },
  {
    "text": "start uploading the video we use transfer acceleration enabled which helped us get a really impressive upload",
    "start": "1137190",
    "end": "1145200"
  },
  {
    "text": "performance by leveraging edge locations from cloud watch Cloud Print sorry and of course we used multi-part uploads",
    "start": "1145200",
    "end": "1153059"
  },
  {
    "text": "which enabled us to upload a single video into multiple parts and then s3",
    "start": "1153059",
    "end": "1158550"
  },
  {
    "text": "gets them all and then gives back one single s3 object this enabled us to do uploads in parallel Postum resume them",
    "start": "1158550",
    "end": "1166140"
  },
  {
    "text": "these kinds of this kind of was really interesting and important for us because when you're talking about mobile network",
    "start": "1166140",
    "end": "1171900"
  },
  {
    "text": "connections when you go out us go into a spotty Network area it's easy to pause and resume the upload so that it doesn't",
    "start": "1171900",
    "end": "1178500"
  },
  {
    "text": "get the the bandwidth doesn't get wasted and the last one as I mention we used a",
    "start": "1178500",
    "end": "1185130"
  },
  {
    "text": "temporary bucket with the TTL or like I've got a day I'll talk about it that in a second but so is primarily to",
    "start": "1185130",
    "end": "1193260"
  },
  {
    "text": "delete unprocessed videos so this kind of what happens in the client upload",
    "start": "1193260",
    "end": "1198500"
  },
  {
    "text": "side of the media pipeline so once the",
    "start": "1198500",
    "end": "1205700"
  },
  {
    "text": "video is uploaded we go and go look into the video validation what happens once",
    "start": "1205700",
    "end": "1211070"
  },
  {
    "text": "you get the video into the temporary bucket are two returns a WebSocket to the client so the WebSocket was really",
    "start": "1211070",
    "end": "1216710"
  },
  {
    "text": "important for us so that we can know the current status and based on the transcoding job moving to the poem",
    "start": "1216710",
    "end": "1222500"
  },
  {
    "text": "bucket or the job is done we can we can refresh the status of the user or status",
    "start": "1222500",
    "end": "1228320"
  },
  {
    "text": "of the post and you send back messages to the user and once the WebSocket is",
    "start": "1228320",
    "end": "1233690"
  },
  {
    "text": "created a draft post is created like I said I mentioned earlier we don't want to create the post yet till the video is",
    "start": "1233690",
    "end": "1239360"
  },
  {
    "text": "done and the video is the video upload queue which is over there accused the",
    "start": "1239360",
    "end": "1248210"
  },
  {
    "text": "video for which basically contains a code for validating and moving the the",
    "start": "1248210",
    "end": "1253940"
  },
  {
    "text": "video between the temp bucket and the poem bucket the kind of validation we do were on the size the length and also on",
    "start": "1253940",
    "end": "1261890"
  },
  {
    "text": "the I can do some security checks to make sure the video headers are the right things that we are looking for and",
    "start": "1261890",
    "end": "1268150"
  },
  {
    "text": "then once the video is validated the T we said the object metadata with",
    "start": "1268150",
    "end": "1274610"
  },
  {
    "text": "interesting and metadata information that we want to set on the s3 object for example if the video is a gif or a video",
    "start": "1274610",
    "end": "1280640"
  },
  {
    "text": "or just like a normal video so this metadata is really really helpful because that metadata gets passed along",
    "start": "1280640",
    "end": "1287660"
  },
  {
    "text": "with your object through your entire transcoding pipeline and then you could leverage that to build interesting",
    "start": "1287660",
    "end": "1293390"
  },
  {
    "text": "things like either our own analytics or try to measure and for tracing so why",
    "start": "1293390",
    "end": "1305180"
  },
  {
    "text": "did we need the temporary bucket so say mentioned before like the experience was",
    "start": "1305180",
    "end": "1311540"
  },
  {
    "text": "like you need to upload the video before the post gets created so there was a use case where like the youth the user might",
    "start": "1311540",
    "end": "1317120"
  },
  {
    "text": "just upload a video and then just walk away before creating a post we don't wanna we didn't want to just let them orphan video scare on so we've both the",
    "start": "1317120",
    "end": "1325460"
  },
  {
    "text": "temporary bucket with the TTL like a shorter duration of like shorter duration for the detail and",
    "start": "1325460",
    "end": "1330900"
  },
  {
    "text": "so that we can just clean them without any overhead and this also applies for failed validation videos like we upload",
    "start": "1330900",
    "end": "1337559"
  },
  {
    "text": "the videos and then we try not valid Asian or community rules and the post gets rejected so we just go ahead and",
    "start": "1337559",
    "end": "1343770"
  },
  {
    "text": "remove them all so then we decided to increase our the TTL timeline to a day",
    "start": "1343770",
    "end": "1350280"
  },
  {
    "text": "because we wanted to support discover disastrous scenarios when you have an outages the videos uploaded we didn't",
    "start": "1350280",
    "end": "1356070"
  },
  {
    "text": "want to lose the user data till the outrageous recovered so we we landed on having a day's long worth of the key TTL",
    "start": "1356070",
    "end": "1364110"
  },
  {
    "text": "on the temporary buckets and so we had three different types of buckets the temporary bucket is what we use for the",
    "start": "1364110",
    "end": "1371700"
  },
  {
    "text": "uploading and validation and then the permanent bucket is where we store the original video as it was uploaded from",
    "start": "1371700",
    "end": "1378750"
  },
  {
    "text": "the from the user so it obviously needed different kinds of permissions on these the buckets the temporary allows you to",
    "start": "1378750",
    "end": "1386010"
  },
  {
    "text": "upload video from externally but the permanent bucket has the original video so we had different permission settings",
    "start": "1386010",
    "end": "1392550"
  },
  {
    "text": "on them as well as and sorry and the",
    "start": "1392550",
    "end": "1397710"
  },
  {
    "text": "transcode bucket is where the video gets out once elastic transcoding is done and one thing which we found really",
    "start": "1397710",
    "end": "1405059"
  },
  {
    "text": "interesting was the caching so we initially set up like really bad cache",
    "start": "1405059",
    "end": "1410250"
  },
  {
    "text": "headers and then video is something which quickly adds up the bandwidth quickly really quickly adds up but like",
    "start": "1410250",
    "end": "1417660"
  },
  {
    "text": "so it's really important to get caching right in this case so now that we have",
    "start": "1417660",
    "end": "1425730"
  },
  {
    "text": "uploaded the video validator the video what happens next let's go through that this is what the",
    "start": "1425730",
    "end": "1431790"
  },
  {
    "start": "1430000",
    "end": "1513000"
  },
  {
    "text": "interesting part of the AWS lambda comes in once the video is pushed to the the",
    "start": "1431790",
    "end": "1437490"
  },
  {
    "text": "permanent bucket it is three fires an event a notification with an event type",
    "start": "1437490",
    "end": "1445980"
  },
  {
    "text": "and so you can configure different event types to AMD the AWS lambda functions so",
    "start": "1445980",
    "end": "1457080"
  },
  {
    "text": "once this events are fired the lambda picks up the event data as a parameter",
    "start": "1457080",
    "end": "1462420"
  },
  {
    "text": "and then starts using it for its processing and we use for the metadata",
    "start": "1462420",
    "end": "1467670"
  },
  {
    "text": "extraction we use media and for byte binary metadata similar to like audio to",
    "start": "1467670",
    "end": "1476820"
  },
  {
    "text": "hide the width of the video and things like the new bit rate and resolution so we use media info for that one it was so",
    "start": "1476820",
    "end": "1482820"
  },
  {
    "text": "simple to just do a shell out by a subprocess to call into the media info binary and also the next thing was",
    "start": "1482820",
    "end": "1491070"
  },
  {
    "text": "setting up the expected outputs because we needed different resolution videos we",
    "start": "1491070",
    "end": "1496200"
  },
  {
    "text": "set them as presets on the lambda object and also the transcoding pipeline",
    "start": "1496200",
    "end": "1502620"
  },
  {
    "text": "supported multiple or multiple pipelines for performance and for performance",
    "start": "1502620",
    "end": "1509040"
  },
  {
    "text": "reasons as we the land also supported load balancing on that one so this code",
    "start": "1509040",
    "end": "1515700"
  },
  {
    "text": "this is a code sample to show the the various presets that we used and how",
    "start": "1515700",
    "end": "1521790"
  },
  {
    "text": "easy it was to map these presets with the metadata so so it was very easy to",
    "start": "1521790",
    "end": "1530730"
  },
  {
    "text": "change the preset by replacing the preset ID with the preset that we are looking for and so with this enabled us",
    "start": "1530730",
    "end": "1537960"
  },
  {
    "text": "to try out different presets to see to get the right user experience by looking",
    "start": "1537960",
    "end": "1543630"
  },
  {
    "text": "for the quality and the performance and the time it takes for getting the right resolution and this one this is a code",
    "start": "1543630",
    "end": "1553530"
  },
  {
    "start": "1550000",
    "end": "1670000"
  },
  {
    "text": "sample on what a lambda handler looks like one of the first things the the",
    "start": "1553530",
    "end": "1558630"
  },
  {
    "text": "lambda or handler does is to get the the",
    "start": "1558630",
    "end": "1563910"
  },
  {
    "text": "right pipeline we use a random function to pick the load balance between the right 80s pipelines and we also pick the",
    "start": "1563910",
    "end": "1570900"
  },
  {
    "text": "outputs outputs in this case are again like the different preset settings so if",
    "start": "1570900",
    "end": "1577230"
  },
  {
    "text": "I upload a 480p video it is essential that we only downscale it to below four",
    "start": "1577230",
    "end": "1584130"
  },
  {
    "text": "80s so we're not never going to transfer try to transcribe it into a 1080p video and the playlists in the code you see",
    "start": "1584130",
    "end": "1591780"
  },
  {
    "text": "those are basically the the manifest like either the - or the Chile's manifest and which basically",
    "start": "1591780",
    "end": "1599249"
  },
  {
    "text": "outputs outputs it to the different containers that they are associated with it the playlists are really important",
    "start": "1599249",
    "end": "1605639"
  },
  {
    "text": "because these are downloaded by various video players and used to determine the best bitrate for adaptive streaming so",
    "start": "1605639",
    "end": "1612330"
  },
  {
    "text": "it was important to get that right as well and we used Amazon's Python API",
    "start": "1612330",
    "end": "1617549"
  },
  {
    "text": "wrapper to cue the job settings job with the job settings into the cue and so",
    "start": "1617549",
    "end": "1624899"
  },
  {
    "text": "this is where we passed the user metadata which kind of tells like the",
    "start": "1624899",
    "end": "1630149"
  },
  {
    "text": "metadata around the video so one of the examples I quoted earlier was like tell what type of video it is and this is",
    "start": "1630149",
    "end": "1636179"
  },
  {
    "text": "kind of interesting right like because the lambda handler passes on this",
    "start": "1636179",
    "end": "1642210"
  },
  {
    "text": "metadata throughout or transcoding pipeline which helps us to manage different settings like for example we",
    "start": "1642210",
    "end": "1649289"
  },
  {
    "text": "try and kind of wanted to experiment like okay if it's a gift only subreddit high-quality gifts can we have a code",
    "start": "1649289",
    "end": "1656849"
  },
  {
    "text": "path or a request path which is optimized for that kind of flow so AWS lambda lets us do that with like the",
    "start": "1656849",
    "end": "1662759"
  },
  {
    "text": "metadata setting and we also had some logging information which I will talk about in a like when I talk about the",
    "start": "1662759",
    "end": "1669239"
  },
  {
    "text": "monitoring in a bit this would also call out how deploying lambda was pretty it's pretty",
    "start": "1669239",
    "end": "1676710"
  },
  {
    "start": "1670000",
    "end": "1722000"
  },
  {
    "text": "straightforward was as simple as running the command displayed there and which creates a zip file with the media info",
    "start": "1676710",
    "end": "1683820"
  },
  {
    "text": "binary and the lambda handler and then zips it up and the surplus get uploaded",
    "start": "1683820",
    "end": "1690450"
  },
  {
    "text": "to the lambda and to deploy it in the new lambda function so this could also",
    "start": "1690450",
    "end": "1697049"
  },
  {
    "text": "be integrated with the build step process so you can as you code in a new",
    "start": "1697049",
    "end": "1702720"
  },
  {
    "text": "Bill Gates or the music file gets generated using it is a double use",
    "start": "1702720",
    "end": "1709739"
  },
  {
    "text": "lambda was like say save it as a like a ton of overhead for our for our like",
    "start": "1709739",
    "end": "1716070"
  },
  {
    "text": "like just in general managing all these sources just having only one engineer work on this the entire time so with",
    "start": "1716070",
    "end": "1724799"
  },
  {
    "start": "1722000",
    "end": "1824000"
  },
  {
    "text": "that let's talk about what happens in the elastic transcoder so like I said",
    "start": "1724799",
    "end": "1731020"
  },
  {
    "text": "mentioned earlier like if we had to do this in-house we had to build our own ffmpeg cluster which is going to be a",
    "start": "1731020",
    "end": "1736240"
  },
  {
    "text": "really painful process so this was a lifesaver for us and we were able to",
    "start": "1736240",
    "end": "1742779"
  },
  {
    "text": "build a whole end-to-end reddit video pipeline and close to four months with a",
    "start": "1742779",
    "end": "1748150"
  },
  {
    "text": "couple of engineers and this was one of the key reasons so like basically the",
    "start": "1748150",
    "end": "1755320"
  },
  {
    "text": "transcoder produces two of the manifests a chalice and dash and it was also",
    "start": "1755320",
    "end": "1760450"
  },
  {
    "text": "extremely easy to set up multiple pipelines because we needed the multiple pipelines for performance reasons which",
    "start": "1760450",
    "end": "1767049"
  },
  {
    "text": "I'm going to talk about it in the next slide as well and again as I mentioned",
    "start": "1767049",
    "end": "1772960"
  },
  {
    "text": "earlier one of our key requirements or our own privacy that we need to strip out the geo-tagging data and the",
    "start": "1772960",
    "end": "1779919"
  },
  {
    "text": "transcoder helps us strip out the geo tags from them before it drops into the transcoder bucket and so the last the",
    "start": "1779919",
    "end": "1790950"
  },
  {
    "text": "most important thing for us was around the processing time and with the type of",
    "start": "1790950",
    "end": "1796090"
  },
  {
    "text": "video that was getting uploaded to read it what we noticed was like our p90 was on less than 30 seconds which was like",
    "start": "1796090",
    "end": "1801970"
  },
  {
    "text": "pretty significant for the scale of Reddit and the other interesting feature that the elastic transcoder gave us was",
    "start": "1801970",
    "end": "1809529"
  },
  {
    "text": "super handy was generating a poster image which is basically given a video with a bunch of frames what is a",
    "start": "1809529",
    "end": "1815309"
  },
  {
    "text": "thumbnail for the video so this enabled us to prototype really really quickly",
    "start": "1815309",
    "end": "1820480"
  },
  {
    "text": "and it was like almost like plug and play and got it working and the last",
    "start": "1820480",
    "end": "1828279"
  },
  {
    "start": "1824000",
    "end": "1861000"
  },
  {
    "text": "piece was around having multiple pipelines and as I said it was more around fault and performance reasons",
    "start": "1828279",
    "end": "1833950"
  },
  {
    "text": "when you have like a really long videos there's a potential that the queues can get really really long so we had two",
    "start": "1833950",
    "end": "1840520"
  },
  {
    "text": "dedicated pipelines for video and also dedicated pipeline forgive because gifs",
    "start": "1840520",
    "end": "1845710"
  },
  {
    "text": "were like because of the time like a but like less than a minute they were like really quick turnaround",
    "start": "1845710",
    "end": "1850840"
  },
  {
    "text": "and the shorter videos and metadata that we we tagged on in the",
    "start": "1850840",
    "end": "1856630"
  },
  {
    "text": "lambda handlers the one which helps us route to the right appropriate use",
    "start": "1856630",
    "end": "1861870"
  },
  {
    "start": "1861000",
    "end": "1900000"
  },
  {
    "text": "so once the video transcoding is done I talked about like the the notification",
    "start": "1862320",
    "end": "1868630"
  },
  {
    "text": "measure the message that gets sent out from the elastic transcoder here is an example of what that looks like we can",
    "start": "1868630",
    "end": "1874450"
  },
  {
    "text": "get to see the the job status like the settings was it a failure or a success",
    "start": "1874450",
    "end": "1880289"
  },
  {
    "text": "along with the user metadata the job settings that was initially the job was created with as well as the different",
    "start": "1880289",
    "end": "1888700"
  },
  {
    "text": "outputs the number of outputs and the manifest playlist and then again the",
    "start": "1888700",
    "end": "1893740"
  },
  {
    "text": "error codes and all the information that is needed for the client to give a reasonably good experience for the end",
    "start": "1893740",
    "end": "1899169"
  },
  {
    "text": "user so once the the transcoded video has",
    "start": "1899169",
    "end": "1905379"
  },
  {
    "start": "1900000",
    "end": "1986000"
  },
  {
    "text": "dropped it and dropped into the transcoding bucket EDS passes the",
    "start": "1905379",
    "end": "1910570"
  },
  {
    "text": "message which I just showed in the previous slide via SNS to sqs and we built our in our - we built our own EDS",
    "start": "1910570",
    "end": "1919529"
  },
  {
    "text": "completion queue which basically pulled pulled this information looked at the",
    "start": "1919529",
    "end": "1925210"
  },
  {
    "text": "metadata and was able to depending on if the job was success or a failure it did",
    "start": "1925210",
    "end": "1930460"
  },
  {
    "text": "a few things if it's a failure it just notified through the WebSocket to the clients that it was failed for so-and-so",
    "start": "1930460",
    "end": "1936250"
  },
  {
    "text": "reasons and if it's a success it tied the original post to the transcoded output and then queued it for indexing",
    "start": "1936250",
    "end": "1943480"
  },
  {
    "text": "in our listing service so that was from the client side or from the elastic",
    "start": "1943480",
    "end": "1948730"
  },
  {
    "text": "completion queue and again this is another call out for AWS infrastructure",
    "start": "1948730",
    "end": "1953919"
  },
  {
    "text": "where we were able to build this the glue between our job queue that I mentioned in our original reddit",
    "start": "1953919",
    "end": "1960279"
  },
  {
    "text": "architecture where we had the job queue to do some expensive operations we were able to tie into our existing job queues",
    "start": "1960279",
    "end": "1966580"
  },
  {
    "text": "using with elastic transcoder using SNS",
    "start": "1966580",
    "end": "1972279"
  },
  {
    "text": "and SQS it was super easy to build it and all we had to do was build like three like a",
    "start": "1972279",
    "end": "1978159"
  },
  {
    "text": "scalable solutions and we had I think three queue consumers and which was able",
    "start": "1978159",
    "end": "1983740"
  },
  {
    "text": "to handle the reddit scale and finally",
    "start": "1983740",
    "end": "1988840"
  },
  {
    "start": "1986000",
    "end": "2040000"
  },
  {
    "text": "so that's like kind of the whole end-to-end flow of what we just looked at client uploads Tim bucket",
    "start": "1988840",
    "end": "1996340"
  },
  {
    "text": "WebSocket comes back to the you to the client validation happens and most of the permanent bucket and then",
    "start": "1996340",
    "end": "2003400"
  },
  {
    "text": "notifications triggered by s3 to lambda lambda takes and defined presets once",
    "start": "2003400",
    "end": "2009790"
  },
  {
    "text": "the transcoding job is done elastic transcoder via SNS sends a",
    "start": "2009790",
    "end": "2015070"
  },
  {
    "text": "message to sqs and drops the image in the transcode bucket and then the EDS",
    "start": "2015070",
    "end": "2020790"
  },
  {
    "text": "transcoding completion queue picks up the message and either sends a user error message or it sends a message",
    "start": "2020790",
    "end": "2027450"
  },
  {
    "text": "saying this is the listing is live and queue it for indexing so that's a the",
    "start": "2027450",
    "end": "2033340"
  },
  {
    "text": "overall flow of what the reddit video looks like today - like when building",
    "start": "2033340",
    "end": "2043720"
  },
  {
    "start": "2040000",
    "end": "2067000"
  },
  {
    "text": "any service like monitoring's extremely extremely important and one of our key requirements was observed observer",
    "start": "2043720",
    "end": "2050260"
  },
  {
    "text": "ability and so monitoring led leads us to look at alerting and like when we",
    "start": "2050260",
    "end": "2055810"
  },
  {
    "text": "initially started we didn't have multiple video pipelines we saw like there were the queue size were like",
    "start": "2055810",
    "end": "2061570"
  },
  {
    "text": "quite increasing quite a bit so then we made a choice to like separate have dedicated time pipelines and so we got a",
    "start": "2061570",
    "end": "2069940"
  },
  {
    "start": "2067000",
    "end": "2111000"
  },
  {
    "text": "lot of metrics out of the box for free via cloud watch and it was really",
    "start": "2069940",
    "end": "2075190"
  },
  {
    "text": "extremely helpful with all the manage services I'll talk through some of the interesting metrics and other key thing",
    "start": "2075190",
    "end": "2082658"
  },
  {
    "text": "which kind of worked out in our favor was into getting it integrated with our existing monitoring and alerting",
    "start": "2082659",
    "end": "2087760"
  },
  {
    "text": "solutions were really really important I dreaded we use graph on and graphite and",
    "start": "2087760",
    "end": "2093780"
  },
  {
    "text": "so does all these things were integrated there but currently we are switching out of a friend with all the new kubernetes",
    "start": "2093780",
    "end": "2100060"
  },
  {
    "text": "world that read it is moving towards and on top of delic we also needed some kind of custom instrumentation that did not",
    "start": "2100060",
    "end": "2107440"
  },
  {
    "text": "come out of the box so let me walk through a couple of those examples so",
    "start": "2107440",
    "end": "2112780"
  },
  {
    "start": "2111000",
    "end": "2142000"
  },
  {
    "text": "these are some of the metrics that came out of the box I would say like the top two ones are kind of the most",
    "start": "2112780",
    "end": "2118510"
  },
  {
    "text": "interesting ones the jobs completed and jobs added out and also like the standby time",
    "start": "2118510",
    "end": "2125740"
  },
  {
    "text": "which kind of tells us how long the queue is and how long individual objects are waiting to be getting transported",
    "start": "2125740",
    "end": "2131830"
  },
  {
    "text": "which is kind of an important thing to look at and this kind of helped us go into multiple pipelines when we first",
    "start": "2131830",
    "end": "2139390"
  },
  {
    "text": "build our pipeline so as I mentioned",
    "start": "2139390",
    "end": "2145570"
  },
  {
    "start": "2142000",
    "end": "2166000"
  },
  {
    "text": "like we also needed a couple of instrumentation that was not readily available from cloud Wash Cloud watch",
    "start": "2145570",
    "end": "2152160"
  },
  {
    "text": "one of those things are the it's the transcode duration as I mentioned like one of the key requirements when we",
    "start": "2152160",
    "end": "2158410"
  },
  {
    "text": "started was like really extremely fast processing and so how can we add some",
    "start": "2158410",
    "end": "2164740"
  },
  {
    "text": "custom instrumentation so you just want to throw in a sample on how we were able",
    "start": "2164740",
    "end": "2170710"
  },
  {
    "start": "2166000",
    "end": "2251000"
  },
  {
    "text": "to measure this measure that the",
    "start": "2170710",
    "end": "2176170"
  },
  {
    "text": "transcoding duration so again it comes back to like all of this is running in the ETS completion queue which is our",
    "start": "2176170",
    "end": "2184420"
  },
  {
    "text": "integration point between sqs and r2 so remember like the original user metadata",
    "start": "2184420",
    "end": "2191230"
  },
  {
    "text": "object that you set when you created the original lambda function that gets passed around the entire pipeline comes",
    "start": "2191230",
    "end": "2196840"
  },
  {
    "text": "back to our completion queue so with that you know all the job settings and like the different outputs and initial",
    "start": "2196840",
    "end": "2204700"
  },
  {
    "text": "start time so we were able to add a duration with the by also looking at the",
    "start": "2204700",
    "end": "2211240"
  },
  {
    "text": "other metrics like the meta the height the width and what was the bitrate so which helps us kind of coordinate like",
    "start": "2211240",
    "end": "2217540"
  },
  {
    "text": "look at it from different dimensions like okay for bigger videos high resolution videos what is the duration and we also added the standby time which",
    "start": "2217540",
    "end": "2226270"
  },
  {
    "text": "kind of tells how long the video was waiting in the queue before the transcoding started so with those two",
    "start": "2226270",
    "end": "2232360"
  },
  {
    "text": "data we were able to plug them together and get a like an approximation of the transcode duration time so with this",
    "start": "2232360",
    "end": "2240790"
  },
  {
    "text": "like this is one of the custom metrics we added so we can think of adding metrics that are really interesting from",
    "start": "2240790",
    "end": "2247900"
  },
  {
    "text": "a product perspective or from a technical perspective and these are a few of the the metrics",
    "start": "2247900",
    "end": "2256700"
  },
  {
    "start": "2251000",
    "end": "2278000"
  },
  {
    "text": "that we used we got out of the box and sq as an SNS nothing really interesting",
    "start": "2256700",
    "end": "2261740"
  },
  {
    "text": "but like we just had a bunch of alerting and monitoring set to make sure the system was fine simple things are on",
    "start": "2261740",
    "end": "2268700"
  },
  {
    "text": "number of messages deleted receives and things like that on the SNS side is like",
    "start": "2268700",
    "end": "2274730"
  },
  {
    "text": "the number of notifications pushed and delivered so with that I just want to",
    "start": "2274730",
    "end": "2281660"
  },
  {
    "start": "2278000",
    "end": "2291000"
  },
  {
    "text": "walk through a couple of slides on what did how did we roll this out and what are the results looking almost after a",
    "start": "2281660",
    "end": "2289070"
  },
  {
    "text": "year since we launched this video platform when we first started like one",
    "start": "2289070",
    "end": "2294560"
  },
  {
    "text": "of the key things that we knew about reddit is like redditors or change I was like they are like I had really good",
    "start": "2294560",
    "end": "2302810"
  },
  {
    "text": "experience trying to build the redesign and got a really interesting experience",
    "start": "2302810",
    "end": "2308030"
  },
  {
    "text": "so our video was like the first time we tried to push in a new experience and the way we took there was like we worked",
    "start": "2308030",
    "end": "2315470"
  },
  {
    "text": "with communities that were like video heavy and give heavies and they're more",
    "start": "2315470",
    "end": "2320780"
  },
  {
    "text": "interested in trying out new things so gaming Commons and communities adopted the videos of course we got like a lot",
    "start": "2320780",
    "end": "2328730"
  },
  {
    "start": "2326000",
    "end": "2397000"
  },
  {
    "text": "of inspirational feedbacks once we launched I would read a couple of them shitty video site that doesn't work on",
    "start": "2328730",
    "end": "2335900"
  },
  {
    "text": "any of my three browsers or alien blues built on browser or the other one this",
    "start": "2335900",
    "end": "2341930"
  },
  {
    "text": "video should is awful opens and browser through read it is fun and slow self so",
    "start": "2341930",
    "end": "2348849"
  },
  {
    "text": "it's fun working at reddit sometimes so so like one of our product managers",
    "start": "2349660",
    "end": "2356180"
  },
  {
    "text": "Eamon he went and looked at through a ton of these feedback and one of the interesting analysis he came back was",
    "start": "2356180",
    "end": "2362420"
  },
  {
    "text": "that like most of these users who have been making these inspirational feedback",
    "start": "2362420",
    "end": "2368720"
  },
  {
    "text": "we're using a third-party clients so turns out the way the native media",
    "start": "2368720",
    "end": "2375710"
  },
  {
    "text": "platform the mistake we made was like we did not coordinate with our third-party developers so that they can use the",
    "start": "2375710",
    "end": "2381230"
  },
  {
    "text": "adaptive streaming technologies that we use so that they have a really good experience for the users so once we found out that like we",
    "start": "2381230",
    "end": "2389400"
  },
  {
    "text": "were able to go work with the third-party developers for like two to three minds and once they added it it's",
    "start": "2389400",
    "end": "2395039"
  },
  {
    "text": "when things kind of started turning it turning her on what we started seeing is",
    "start": "2395039",
    "end": "2400680"
  },
  {
    "start": "2397000",
    "end": "2440000"
  },
  {
    "text": "like we kind of started seeing new kinds of videos that didn't exist anywhere else before so we when we launched video",
    "start": "2400680",
    "end": "2407999"
  },
  {
    "text": "like the we dreaded video we were curious would it take down like other third-party sites videos that's getting",
    "start": "2407999",
    "end": "2414809"
  },
  {
    "text": "plugged into reddit but it kind of see like new types of content getting created and within the community centric",
    "start": "2414809",
    "end": "2422009"
  },
  {
    "text": "ones so this one the first one on the left is I dude is getting like videotaping his head and asking what",
    "start": "2422009",
    "end": "2428819"
  },
  {
    "text": "type of haircut he should get on the writer Simon asked him feedback on their golf swing so it was really interesting",
    "start": "2428819",
    "end": "2435450"
  },
  {
    "text": "to see people adapting it for interesting use cases and then finally",
    "start": "2435450",
    "end": "2442440"
  },
  {
    "text": "after like going through like a lot of this fun feedback it was like we just reached a monumental moment like I want",
    "start": "2442440",
    "end": "2448799"
  },
  {
    "text": "to say like a month back when reddit video reached like more than a billion views a month it was pretty phenomenal",
    "start": "2448799",
    "end": "2454829"
  },
  {
    "text": "for us and it was really really good and so for people who haven't watched",
    "start": "2454829",
    "end": "2460859"
  },
  {
    "start": "2457000",
    "end": "2512000"
  },
  {
    "text": "infinity Wars avenges this might be a spoiler so I apologize so in the more",
    "start": "2460859",
    "end": "2467009"
  },
  {
    "text": "end of the movie you know what happens tenuous snaps his finger and half of the population disappears so there is a",
    "start": "2467009",
    "end": "2473849"
  },
  {
    "text": "community in subreddit in reddit called Thanos did nothing wrong and there was a",
    "start": "2473849",
    "end": "2479670"
  },
  {
    "text": "petition there which was like ban half of the users in that subreddit so",
    "start": "2479670",
    "end": "2484829"
  },
  {
    "text": "obviously the things got uploaded and became really popular and it was Stannis himself sent a message and he snapped it",
    "start": "2484829",
    "end": "2491339"
  },
  {
    "text": "and I believe it's on July 6th we banned randomly half of the population so it was I said it like we read it has a",
    "start": "2491339",
    "end": "2501329"
  },
  {
    "text": "really unique way of bringing creativity we give them really simple too so that's one thing I really love about working at",
    "start": "2501329",
    "end": "2507150"
  },
  {
    "text": "reddit it's like the community powers read it and looking at some of the stats",
    "start": "2507150",
    "end": "2515750"
  },
  {
    "start": "2512000",
    "end": "2531000"
  },
  {
    "text": "obviously we see about 60 to 70% of the usage coming from our mobile devices 45%",
    "start": "2515750",
    "end": "2521720"
  },
  {
    "text": "from Iowa's and 22% from Android and the desktop is like 24% and like mobile but",
    "start": "2521720",
    "end": "2529099"
  },
  {
    "text": "we get around 10% and other interesting one is like the graph is starting it",
    "start": "2529099",
    "end": "2535970"
  },
  {
    "start": "2531000",
    "end": "2586000"
  },
  {
    "text": "like July 1st and going up to like August so you see a steady increase and",
    "start": "2535970",
    "end": "2541700"
  },
  {
    "text": "we've reached up to like almost 20% of videos that are hosted in Reddit our",
    "start": "2541700",
    "end": "2548260"
  },
  {
    "text": "native videos and I just want to point out this particular thing which started",
    "start": "2548260",
    "end": "2555049"
  },
  {
    "text": "at October and went down to like December this is kind of the face when you are getting all those inspirational",
    "start": "2555049",
    "end": "2560869"
  },
  {
    "text": "feedbacks just to tie it back so we were like that's the time we were working with all the the third-party developers",
    "start": "2560869",
    "end": "2568490"
  },
  {
    "text": "to bring their apps up to speed and we were very particular about bringing communities in front when you're rolling",
    "start": "2568490",
    "end": "2575180"
  },
  {
    "text": "it out so we didn't roll it out to a lot of users and it was it it took a tipping",
    "start": "2575180",
    "end": "2582079"
  },
  {
    "text": "point earlier beginning of this year and it's been growing linearly so what are",
    "start": "2582079",
    "end": "2587839"
  },
  {
    "start": "2586000",
    "end": "2589000"
  },
  {
    "text": "some of the lessons learned on the technical side minimal infrastructure as",
    "start": "2587839",
    "end": "2593869"
  },
  {
    "start": "2589000",
    "end": "2737000"
  },
  {
    "text": "I said like we like we have a billion views right now there's only one engineer working on it right now like",
    "start": "2593869",
    "end": "2599990"
  },
  {
    "text": "literally one engineer working on our the whole the reddit pipeline there's only one engineer working and thanks to",
    "start": "2599990",
    "end": "2606380"
  },
  {
    "text": "the AWS we don't have to worry about the infrastructure and observed observer",
    "start": "2606380",
    "end": "2611960"
  },
  {
    "text": "ability is key maybe which kind of helped us made some interesting product decisions around like load balancing our",
    "start": "2611960",
    "end": "2618619"
  },
  {
    "text": "pipelines or knowing when we are running into errors so always keep that in mind when you're building it the other one",
    "start": "2618619",
    "end": "2624920"
  },
  {
    "text": "which like the thing which is key for like some of the startups and these",
    "start": "2624920",
    "end": "2632000"
  },
  {
    "text": "product companies are like to focus on the core user experience like working with AWS ETS we were able to focus on",
    "start": "2632000",
    "end": "2641059"
  },
  {
    "text": "our core user experience problems instead of worrying about what the infrastructure should look like what should be the transcoding pipeline",
    "start": "2641059",
    "end": "2647260"
  },
  {
    "text": "and this helped us focus a lot of our time experiment going like quite a few different things like for example that",
    "start": "2647260",
    "end": "2653140"
  },
  {
    "text": "the segment lengths on the manifest like how long should it be what will be a right ideal experience trying it trying",
    "start": "2653140",
    "end": "2660760"
  },
  {
    "text": "to get adaptive streaming working the perfect way for slow connections and",
    "start": "2660760",
    "end": "2665920"
  },
  {
    "text": "again for a Chile's follow the guidelines it's like Apple defense strictly what needs to be done for - you",
    "start": "2665920",
    "end": "2672670"
  },
  {
    "text": "need to played around and get the right settings and in general video players have been I've been really hard like in",
    "start": "2672670",
    "end": "2678970"
  },
  {
    "text": "terms of the clients we have Android iOS mobile web and third-party mobile apps",
    "start": "2678970",
    "end": "2685090"
  },
  {
    "text": "as well so getting those things took a lot of time and we were able to focus on the key issues then worrying about our",
    "start": "2685090",
    "end": "2691480"
  },
  {
    "text": "infrastructure and scaling it and so AWS managed services was a perfect MVP for",
    "start": "2691480",
    "end": "2696940"
  },
  {
    "text": "us and for most of you guys I would believe we were able to get it right one of the other things which we learned by",
    "start": "2696940",
    "end": "2703510"
  },
  {
    "text": "paying us a little bit more money was around caching we messed up our caching initially and then when we went and",
    "start": "2703510",
    "end": "2710109"
  },
  {
    "text": "turned it around we were able to reduce her cause by one-fifth so that was really good and the last one is again we",
    "start": "2710109",
    "end": "2716650"
  },
  {
    "text": "were able to leverage the metadata to the object of pass around lambda function to learn a lot also not to",
    "start": "2716650",
    "end": "2723160"
  },
  {
    "text": "learn a lot to help make custom changes integrate with pieces that are like it",
    "start": "2723160",
    "end": "2732010"
  },
  {
    "text": "could be our analytics or it could be an own data pipeline so we were able to do all those things and some more some of",
    "start": "2732010",
    "end": "2739840"
  },
  {
    "start": "2737000",
    "end": "2842000"
  },
  {
    "text": "the lessons learnt but these are not technical this is purely from rolling it out to a community like Reddit it was",
    "start": "2739840",
    "end": "2745330"
  },
  {
    "text": "around first we identified a video friendly communities around gaming give memes",
    "start": "2745330",
    "end": "2751109"
  },
  {
    "text": "we obviously prevented NSFW we didn't wanna go into that and like it was the",
    "start": "2751109",
    "end": "2758859"
  },
  {
    "text": "struggle was getting the first initial viral content or the initial advocates for your video type once we got like",
    "start": "2758859",
    "end": "2765520"
  },
  {
    "text": "these early adopters and people started using it and when the video started coming up into the the popular page or",
    "start": "2765520",
    "end": "2772150"
  },
  {
    "text": "the front page it was kind of interesting to see like people started adopting it and in reddit we have user",
    "start": "2772150",
    "end": "2777790"
  },
  {
    "text": "profiles and we rolled it out to all profiles and we kind of got interest from like",
    "start": "2777790",
    "end": "2784760"
  },
  {
    "text": "like famous publishers like time Washington Post time also made a video",
    "start": "2784760",
    "end": "2790680"
  },
  {
    "text": "with like one of those Mon rx Sun rx eclipse I think and then it got like a",
    "start": "2790680",
    "end": "2795930"
  },
  {
    "text": "large turn of words so it's kind of interesting to see the whole role or tactic our own starting small here get",
    "start": "2795930",
    "end": "2803160"
  },
  {
    "text": "as much feedback as you can even if it means slowing down your role or takin all the feedback fix the issues and then",
    "start": "2803160",
    "end": "2811200"
  },
  {
    "text": "keep rolling it out and this is like a key lessons that we took in which we kind of applied in are ready",
    "start": "2811200",
    "end": "2816840"
  },
  {
    "text": "pre-designed or load as well so and so we have large partners working with us",
    "start": "2816840",
    "end": "2822090"
  },
  {
    "text": "right now and finally it's like was launched to all all s safer work communities I want",
    "start": "2822090",
    "end": "2829980"
  },
  {
    "text": "to say earlier this year and by like last month we hit like a billion views",
    "start": "2829980",
    "end": "2836400"
  },
  {
    "text": "and like with AWS we just need a single engineer to manage the whole process so",
    "start": "2836400",
    "end": "2841610"
  },
  {
    "text": "with that thank you [Applause]",
    "start": "2841610",
    "end": "2853709"
  },
  {
    "text": "any questions",
    "start": "2854410",
    "end": "2857980"
  },
  {
    "text": "okay I'm not sure I have Australia correct answer for you no but like let's",
    "start": "2874079",
    "end": "2879099"
  },
  {
    "text": "just catch up often I'll connect with you someone can answer that one",
    "start": "2879099",
    "end": "2883859"
  },
  {
    "text": "so for some of the things like the community validation we have our own frame I'd like to run through our auto",
    "start": "2896520",
    "end": "2902339"
  },
  {
    "text": "mode rules community rules we have our own framework for the actual validation",
    "start": "2902339",
    "end": "2909540"
  },
  {
    "text": "on the video itself is done through the media info where we get the metadata around like the size the duration and",
    "start": "2909540",
    "end": "2915869"
  },
  {
    "text": "things like that from the media info binary",
    "start": "2915869",
    "end": "2920990"
  },
  {
    "text": "so that's we we do have a team called trust in safety and anti evil and read",
    "start": "2934000",
    "end": "2939130"
  },
  {
    "text": "it so that word is completely out of my scope but I'm let's connect offline and I'm happy to connect with someone",
    "start": "2939130",
    "end": "2945310"
  },
  {
    "text": "because I wouldn't be able to do justice for that question yes so some of the",
    "start": "2945310",
    "end": "2959200"
  },
  {
    "text": "optimizations that we did were around the segment size and like be initially",
    "start": "2959200",
    "end": "2965740"
  },
  {
    "text": "when we started like we had a couple of we started with like only two to three resolution widths that we saved and we",
    "start": "2965740",
    "end": "2972400"
  },
  {
    "text": "tried out through a bunch of nano testing then we came back and then we",
    "start": "2972400",
    "end": "2977710"
  },
  {
    "text": "have like we came down to those some of the predefined presets that I had like I think Phi so that was one the segment",
    "start": "2977710",
    "end": "2984940"
  },
  {
    "text": "size we started off like with small segment size for our absolute streaming and what we found out was that like it",
    "start": "2984940",
    "end": "2990670"
  },
  {
    "text": "was taking because of the small segment size which means more bandwidth so taking a longer time so we we did end up",
    "start": "2990670",
    "end": "2997210"
  },
  {
    "text": "increasing our segment size to optimize for it so those two things were things I would probably call out",
    "start": "2997210",
    "end": "3004338"
  },
  {
    "text": "sorry sir they're gonna yeah setting the",
    "start": "3011660",
    "end": "3018660"
  },
  {
    "text": "right oh let's catch up after the Sam I",
    "start": "3018660",
    "end": "3025260"
  },
  {
    "text": "don't have a right answer for that one",
    "start": "3025260",
    "end": "3028609"
  },
  {
    "text": "not yet but like that's something in our so probably in the team that I'm running",
    "start": "3039539",
    "end": "3044640"
  },
  {
    "text": "right now so I'm running the emission learning platform you at some point you might have to look at it but it's not something we've been actively looking at",
    "start": "3044640",
    "end": "3052880"
  },
  {
    "text": "could you say that okay that's an",
    "start": "3060599",
    "end": "3069540"
  },
  {
    "text": "interesting idea but like I don't I'm not part of the team anymore now I'm in the machine learning team so yeah yeah",
    "start": "3069540",
    "end": "3080809"
  },
  {
    "text": "yeah so during once it gets to the the",
    "start": "3086330",
    "end": "3091910"
  },
  {
    "start": "3087000",
    "end": "3479000"
  },
  {
    "text": "temporary bucket is when we start looking at our few things we use the",
    "start": "3091910",
    "end": "3097670"
  },
  {
    "text": "median for to get the metadata on the video it's like the size the duration and different the the headers of the",
    "start": "3097670",
    "end": "3107480"
  },
  {
    "text": "video those are things that we are it's in the valid set once that is done there is a next round of validation which",
    "start": "3107480",
    "end": "3113870"
  },
  {
    "text": "happens which are specific to read it because in reddit like if you are uploading if you go to a community which",
    "start": "3113870",
    "end": "3119420"
  },
  {
    "text": "which only allows you to upload gifts you should not be uploading videos or",
    "start": "3119420",
    "end": "3124780"
  },
  {
    "text": "communities like there are like a lot of community specific rules and also auto",
    "start": "3124780",
    "end": "3130280"
  },
  {
    "text": "moderators which are like community rules are like defined by moderators of the community so they come and remove",
    "start": "3130280",
    "end": "3136670"
  },
  {
    "text": "those posts but they also have defined predefined settings called auto mode raters which come in remove them as well",
    "start": "3136670",
    "end": "3144790"
  },
  {
    "text": "sure",
    "start": "3156750",
    "end": "3159750"
  },
  {
    "text": "that's an interesting idea but like I think the way like today we don't",
    "start": "3187440",
    "end": "3193630"
  },
  {
    "text": "support media in the corns right like and we take comments it's like common",
    "start": "3193630",
    "end": "3200260"
  },
  {
    "text": "Cesare like the core part of Reddit and we want to be mindful about how do you want to get there right it's the Conda",
    "start": "3200260",
    "end": "3207910"
  },
  {
    "text": "when s a conversation is more on the discussion that's happening and like the videos are like more interesting as a post type rather",
    "start": "3207910",
    "end": "3215440"
  },
  {
    "text": "than as a discussion type that's my person we have",
    "start": "3215440",
    "end": "3220079"
  },
  {
    "text": "so again like that's like I'm happy to discuss with you offline which is something like we have a different",
    "start": "3235320",
    "end": "3242130"
  },
  {
    "text": "infrastructure team like I said we use the common frameworks which takes kind of a bunch of the logging integrating",
    "start": "3242130",
    "end": "3248160"
  },
  {
    "text": "with our data pipelines the whole system so that's not something I'm I was responsible of so but I'm happy to",
    "start": "3248160",
    "end": "3254700"
  },
  {
    "text": "connect you with someone",
    "start": "3254700",
    "end": "3257570"
  },
  {
    "text": "no the video like the validation happens after the video is in the temporary bucket it's a sequential process the video",
    "start": "3287950",
    "end": "3298490"
  },
  {
    "text": "upload queue is for when you have multiple videos in the temporary bucket and those needs to be validated like it could be multiple users coming in so",
    "start": "3298490",
    "end": "3305060"
  },
  {
    "text": "once you upload a video it goes to the temporary bucket and then you it goes into the validation queue but like and",
    "start": "3305060",
    "end": "3312710"
  },
  {
    "text": "then the queue is for multiple users trying to upload at the same time so",
    "start": "3312710",
    "end": "3329450"
  },
  {
    "text": "we'd like that's kind of in are probably not like down the line roadmap as part",
    "start": "3329450",
    "end": "3334970"
  },
  {
    "text": "of for some of our machine learning techniques so I currently run the machine learning team and just give a",
    "start": "3334970",
    "end": "3341870"
  },
  {
    "text": "talk about like how we use machine learning images is something we we do consider like primarily our focuses are",
    "start": "3341870",
    "end": "3348500"
  },
  {
    "text": "on natural language processing right now to understand the text and content but that's something we might consider in",
    "start": "3348500",
    "end": "3354680"
  },
  {
    "text": "the future",
    "start": "3354680",
    "end": "3357040"
  },
  {
    "text": "yeah I personally would wanna like the",
    "start": "3363529",
    "end": "3369690"
  },
  {
    "text": "way we think about that is like like I",
    "start": "3369690",
    "end": "3375509"
  },
  {
    "text": "found out like I led the redesign effort and I found out there is a site called I dot read it calm it still runs like",
    "start": "3375509",
    "end": "3381959"
  },
  {
    "text": "which is like way way back side and r2 from the client perspective like the old",
    "start": "3381959",
    "end": "3389609"
  },
  {
    "text": "reddit design that's something which is gonna you're gonna let it go let it let it live forever that's kind of what our",
    "start": "3389609",
    "end": "3395549"
  },
  {
    "text": "CEO promised when we went with the redesign but in terms of the back-end services we're just slowly plucking our",
    "start": "3395549",
    "end": "3401400"
  },
  {
    "text": "way into getting into micro services and there's another one of the APA teams that is responsible it's moving slowly",
    "start": "3401400",
    "end": "3408839"
  },
  {
    "text": "moving into graph q-ball so that's something we are working on as well now like we don't have a timeline on something I'm pretty sure we should have",
    "start": "3408839",
    "end": "3422759"
  },
  {
    "text": "done it black it was something we've already been using for yeah potentially",
    "start": "3422759",
    "end": "3435029"
  },
  {
    "text": "where I'm not but I'm happy to connect you with like this question and the previous question you add like the right",
    "start": "3435029",
    "end": "3440940"
  },
  {
    "text": "person",
    "start": "3440940",
    "end": "3443359"
  },
  {
    "text": "sorry say that again which this one I",
    "start": "3446760",
    "end": "3457650"
  },
  {
    "text": "probably should right yeah yeah it's",
    "start": "3457650",
    "end": "3463690"
  },
  {
    "text": "like well within an hour hopefully the video is like less than a gig so cool",
    "start": "3463690",
    "end": "3475020"
  },
  {
    "text": "thanks everyone",
    "start": "3475020",
    "end": "3478290"
  }
]
[
  {
    "text": "Perplexity is a\nconversational answer engine",
    "start": "0",
    "end": "3086"
  },
  {
    "text": "that directly answers your question.",
    "start": "3086",
    "end": "4921"
  },
  {
    "text": "Instead of giving you 10 blue\nlinks, large language model,",
    "start": "4921",
    "end": "7632"
  },
  {
    "text": "generative AI started advancing.",
    "start": "7632",
    "end": "10218"
  },
  {
    "text": "We knew that the opportunity\nwas right and we went for it.",
    "start": "10218",
    "end": "12929"
  },
  {
    "text": "We are all used to using fast products.",
    "start": "12929",
    "end": "15181"
  },
  {
    "text": "Latency is the most important thing,",
    "start": "15181",
    "end": "17434"
  },
  {
    "text": "and the service has to be\nup and running reliably.",
    "start": "17434",
    "end": "20562"
  },
  {
    "text": "If at the same time, 20,000\npeople are sending in a request,",
    "start": "20562",
    "end": "24190"
  },
  {
    "text": "a hundred thousand people\nare sending in a request.",
    "start": "24190",
    "end": "26317"
  },
  {
    "text": "The service shouldn't get slow,\nthe service shouldn't break.",
    "start": "26317",
    "end": "29195"
  },
  {
    "text": "So you need some hyperscaler\nto really help you",
    "start": "29195",
    "end": "32824"
  },
  {
    "text": "to keep the product up and running.",
    "start": "32824",
    "end": "34200"
  },
  {
    "text": "So we train our own large\nlanguage models too.",
    "start": "34200",
    "end": "36995"
  },
  {
    "text": "And why do we do that?",
    "start": "36995",
    "end": "38204"
  },
  {
    "text": "Because we want to actually\nmake these models a lot more",
    "start": "38204",
    "end": "41458"
  },
  {
    "text": "accurate, a lot more\nfactual, a lot more helpful,",
    "start": "41458",
    "end": "43334"
  },
  {
    "text": "and that requires you to",
    "start": "43334",
    "end": "44919"
  },
  {
    "text": "train these 70 billion\nparameter models on like dozens",
    "start": "46046",
    "end": "50341"
  },
  {
    "text": "of GPUs or more shard them",
    "start": "50341",
    "end": "52843"
  },
  {
    "text": "because they're not going to\nfit on one single GPU.",
    "start": "52844",
    "end": "55263"
  },
  {
    "text": "This requires really top of\nthe market infrastructure so",
    "start": "55263",
    "end": "59726"
  },
  {
    "text": "that all the updates through\nthese different portions",
    "start": "59726",
    "end": "62979"
  },
  {
    "text": "of these models are synchronized and fast.",
    "start": "62979",
    "end": "66566"
  },
  {
    "text": "And then you save time and you save costs.",
    "start": "66566",
    "end": "69736"
  },
  {
    "text": "This is generally referred\nto as distributed training.",
    "start": "69736",
    "end": "72072"
  },
  {
    "text": "AWS has its new solution\ncalled SageMaker HyperPod",
    "start": "72072",
    "end": "77076"
  },
  {
    "text": "that lets us do this at\ntwo times more throughput",
    "start": "77410",
    "end": "80288"
  },
  {
    "text": "than what was possible before.",
    "start": "80288",
    "end": "81414"
  },
  {
    "text": "So you learn more per day,\nyou get a better model,",
    "start": "81414",
    "end": "84167"
  },
  {
    "text": "and that lets us complete two jobs in one",
    "start": "84167",
    "end": "87253"
  },
  {
    "text": "hour instead of one job, right?",
    "start": "87253",
    "end": "88463"
  },
  {
    "text": "So you learn more per day.\nYou get a better model.",
    "start": "88463",
    "end": "91590"
  },
  {
    "text": "Instead of waiting for two weeks",
    "start": "91591",
    "end": "92967"
  },
  {
    "text": "to get a better model,\nyou get it in one week.",
    "start": "92967",
    "end": "94719"
  },
  {
    "text": "This makes a ton of difference.",
    "start": "94719",
    "end": "95970"
  },
  {
    "text": "You roll it out with\nusers, you get more data",
    "start": "95970",
    "end": "97639"
  },
  {
    "text": "and it just accelerates\nyour startup a lot, right?",
    "start": "97639",
    "end": "102352"
  },
  {
    "text": "It compounds.",
    "start": "102352",
    "end": "103144"
  }
]
[
  {
    "start": "0",
    "end": "36000"
  },
  {
    "text": "I'd like to welcome everybody to our session today architecting a data Lake on AWS this is Jerry CH your host today",
    "start": "440",
    "end": "8080"
  },
  {
    "text": "thanks for joining in if you have any questions feel free to use our Q&A panel on the right side of your screen just",
    "start": "8080",
    "end": "13799"
  },
  {
    "text": "look to the bottom of that panel type in your question and click the button to the right if you have a specific partner",
    "start": "13799",
    "end": "20000"
  },
  {
    "text": "you have in mind for that question please feel free to include that in the question that you ask that way we can",
    "start": "20000",
    "end": "25080"
  },
  {
    "text": "direct that question again you can ask questions throughout our session today we will have a Q&A at the end of our",
    "start": "25080",
    "end": "30240"
  },
  {
    "text": "call also so this time we'll go and hand a call over to rul R please go ahead uh",
    "start": "30240",
    "end": "35640"
  },
  {
    "text": "my name is Rahul and I work as a solution architect with Amazon web services uh joining me today we have",
    "start": "35640",
    "end": "41120"
  },
  {
    "start": "36000",
    "end": "36000"
  },
  {
    "text": "Mark Shriver who is General Manager at cloudwick along with Mark we have Raja Shake CTO at North Bay and mbas CEO at",
    "start": "41120",
    "end": "49879"
  },
  {
    "text": "47 lining in today's webinar we are going to talk about the benefits the value of",
    "start": "49879",
    "end": "57320"
  },
  {
    "text": "building a data Lake on AWS and our partners will help describe some of the features advantages you can achieve by",
    "start": "57320",
    "end": "64198"
  },
  {
    "text": "building a data Lake on ews let's go quickly through the agenda the first thing we're going to do is",
    "start": "64199",
    "end": "71119"
  },
  {
    "start": "68000",
    "end": "68000"
  },
  {
    "text": "Define what is a data Lake the second point we're going to say is what are the",
    "start": "71119",
    "end": "76759"
  },
  {
    "text": "benefits you can get from a data Lake as compared to a traditional data warehousing or a data analytics",
    "start": "76759",
    "end": "84119"
  },
  {
    "text": "architecture the third point we're going to talk about is why should you or how",
    "start": "84119",
    "end": "89280"
  },
  {
    "text": "could you deploy data L on AWS quickly and get the benefits from the data Lake and then we'll have each of our APN Big",
    "start": "89280",
    "end": "96240"
  },
  {
    "text": "Data comp competency Partners talk about these benefits in detail that how you",
    "start": "96240",
    "end": "101399"
  },
  {
    "text": "could achieve those benefits by partnering with our Consulting Partners today and in the last we're going to",
    "start": "101399",
    "end": "107719"
  },
  {
    "text": "summarize everything and talk about what are things you could do to getting started with the data Lake on AWS with",
    "start": "107719",
    "end": "114200"
  },
  {
    "text": "that let's just get started so before we get any deeper into",
    "start": "114200",
    "end": "120439"
  },
  {
    "start": "117000",
    "end": "117000"
  },
  {
    "text": "the webinar or talk about data Lakes the first thing we need to do is establish a ground framework for what exactly is a",
    "start": "120439",
    "end": "127360"
  },
  {
    "text": "data Lake many of us have worked in the data warehousing industry or the data",
    "start": "127360",
    "end": "134280"
  },
  {
    "text": "processing industry where we have been using a traditional databases for our most of our analytic needs a data lake",
    "start": "134280",
    "end": "142000"
  },
  {
    "text": "is a new way given the challenges we are facing in terms of increased velocity volume and variety of data to handle",
    "start": "142000",
    "end": "148920"
  },
  {
    "text": "with those kind of situations and not only that but to store data in a format the way it",
    "start": "148920",
    "end": "155760"
  },
  {
    "text": "originates without worrying about what is that you need to answer from a data",
    "start": "155760",
    "end": "161480"
  },
  {
    "text": "perspective in the earlier times we had to think of data as the way the",
    "start": "161480",
    "end": "166760"
  },
  {
    "text": "questions we want to answer and then we used to fit the data into a schema so that we could answer the questions the",
    "start": "166760",
    "end": "174000"
  },
  {
    "text": "not only that with storage and compute traditionally being very expensive we even had to cut down on how much of data",
    "start": "174000",
    "end": "179640"
  },
  {
    "text": "we could good store data LS helps you deal with that by giving you a centralized repository by giving you a",
    "start": "179640",
    "end": "186319"
  },
  {
    "text": "way to access all of your data and apply multiple types of compute on that to",
    "start": "186319",
    "end": "192159"
  },
  {
    "text": "reiterate if you think about it there are these are the challenges which organizations which which people which",
    "start": "192159",
    "end": "198599"
  },
  {
    "start": "193000",
    "end": "193000"
  },
  {
    "text": "customers have been facing with data legs in past and that's just is how do I",
    "start": "198599",
    "end": "204879"
  },
  {
    "text": "collect my data quickly uh we don't we don't want to DOL process to collect",
    "start": "204879",
    "end": "210040"
  },
  {
    "text": "data for example and if you look into each of these questions in a deeper meaning let's start with the first one",
    "start": "210040",
    "end": "216560"
  },
  {
    "start": "216000",
    "end": "216000"
  },
  {
    "text": "which is what are the benefits of building a data Lake In general the",
    "start": "216560",
    "end": "222560"
  },
  {
    "text": "first thing you can imagine is that in a traditional architecture where you collect your data from uh many sources",
    "start": "222560",
    "end": "230439"
  },
  {
    "text": "and then you do a processing on top of it which has been defined as ETL extract",
    "start": "230439",
    "end": "235720"
  },
  {
    "text": "transform and load to fit into a schema that process itself puts a burden or",
    "start": "235720",
    "end": "241879"
  },
  {
    "text": "puts a puts a cap on how fast you can inest data but with data L where you're",
    "start": "241879",
    "end": "248799"
  },
  {
    "text": "storing your data into a not a predefined schema but you're storing data as is you don't need to go through",
    "start": "248799",
    "end": "255040"
  },
  {
    "text": "a ETL process which may curtail on how much how fast you can injest data not",
    "start": "255040",
    "end": "260239"
  },
  {
    "text": "only that a data leg provides you a way to inest data from sources such as",
    "start": "260239",
    "end": "265440"
  },
  {
    "text": "realtime streams traditional databases or even uh sources such as log files and",
    "start": "265440",
    "end": "271639"
  },
  {
    "text": "other iot sources if you think of the second part which is in a traditional architecture",
    "start": "271639",
    "end": "279320"
  },
  {
    "text": "you distribute your data into many different stores data warehouses operational data stores data marks and",
    "start": "279320",
    "end": "286639"
  },
  {
    "text": "Etc and that puts another layer on top of how your customers how you guys could",
    "start": "286639",
    "end": "292800"
  },
  {
    "text": "access data from these sources the main question remains is that where should I go to find what data how do I know where",
    "start": "292800",
    "end": "299000"
  },
  {
    "text": "is my single source of truth but if you look at a data L then what data L",
    "start": "299000",
    "end": "305520"
  },
  {
    "text": "provides you is ability to store all of your data in a single repository and then each of these processing or each of",
    "start": "305520",
    "end": "312360"
  },
  {
    "text": "these data stores like ODS data Mar or data warehouses can be thought of a",
    "start": "312360",
    "end": "318039"
  },
  {
    "text": "projections on top of your data so you get a single version of your data from that very uh definition of a data",
    "start": "318039",
    "end": "326880"
  },
  {
    "text": "link the next part is which we mentioned earlier also was historically I mean",
    "start": "328280",
    "end": "334039"
  },
  {
    "text": "traditionally compute and storage has been expensive and not only that the storage and compute were tied together",
    "start": "334039",
    "end": "340280"
  },
  {
    "text": "which means that if your data is scaling up you need to scale both the infrastructure and whether if even if",
    "start": "340280",
    "end": "346520"
  },
  {
    "text": "you're not using the entire of the compute on a given platform you need to still keep up with the storage and that",
    "start": "346520",
    "end": "353520"
  },
  {
    "text": "means there was a not optimization you could do but with the data Lake architecture where allows you to",
    "start": "353520",
    "end": "360280"
  },
  {
    "text": "separate the compute from Storage by using um for example by using Amazon S3",
    "start": "360280",
    "end": "366000"
  },
  {
    "text": "as a storage platform you don't have to worry about scaling your storage you the",
    "start": "366000",
    "end": "371280"
  },
  {
    "text": "platform itself scales with as your data grows and then you can apply compute which is transient and this model gives",
    "start": "371280",
    "end": "378160"
  },
  {
    "text": "you a much more cost optimization a much more efficient model for processing your data at any scale versus a traditional",
    "start": "378160",
    "end": "385440"
  },
  {
    "text": "scale where you have to scale up a database and both the computer and storage are typed together and they grow hand in",
    "start": "385440",
    "end": "392758"
  },
  {
    "text": "hand the last one what we're going to talk about is that in a data warehousing",
    "start": "392919",
    "end": "398639"
  },
  {
    "text": "world or in a data bases world the only type of compute you do or the only type of processing you do is is based on a",
    "start": "398639",
    "end": "405280"
  },
  {
    "text": "SQL or based on a query of data if you wanted to do some different kind of processing for example let's say uh deep",
    "start": "405280",
    "end": "411520"
  },
  {
    "text": "learning machine learning dtive analytics you had to either get the data",
    "start": "411520",
    "end": "416759"
  },
  {
    "text": "out of it or rely on those databases to provide you that feature to run those kind of models on top of data but with",
    "start": "416759",
    "end": "424560"
  },
  {
    "text": "data legs you don't have to do that because your data is separate separately stored into a single storage and then",
    "start": "424560",
    "end": "431560"
  },
  {
    "text": "you can apply any sort of analytics be it be it querying the data be it running",
    "start": "431560",
    "end": "436919"
  },
  {
    "text": "machine learning algorithms or any type of processing such as even map reduce or",
    "start": "436919",
    "end": "442080"
  },
  {
    "text": "spark processing on top of the data set sitting in that data Lake and that gives you the flexibility that gives you the",
    "start": "442080",
    "end": "449000"
  },
  {
    "text": "ability to to democratize the data within your organization so any different kind of audience different",
    "start": "449000",
    "end": "454319"
  },
  {
    "text": "kind of uh Pro professionals can access the data in the way they most are familiar with and those are some of the",
    "start": "454319",
    "end": "461400"
  },
  {
    "text": "benefits you could get by building a data Lake but once we understand what are the",
    "start": "461400",
    "end": "470000"
  },
  {
    "start": "468000",
    "end": "468000"
  },
  {
    "text": "benefits of a data L the question remains is is just storing data",
    "start": "470000",
    "end": "476159"
  },
  {
    "text": "natively in its own original format is that what that defines a data Lake the",
    "start": "476159",
    "end": "481240"
  },
  {
    "text": "argument to that would be no that's just storing a data into a centralized repository does not constitute a data",
    "start": "481240",
    "end": "487120"
  },
  {
    "text": "Lake you had to think in terms of what are the features what are the ways you can ingest data into that",
    "start": "487120",
    "end": "493800"
  },
  {
    "text": "storage how do users find your data how are they going to search about it how do",
    "start": "493800",
    "end": "499080"
  },
  {
    "text": "I know that what kind of data I have inside the data Lake what are the business meaning associated with the",
    "start": "499080",
    "end": "504960"
  },
  {
    "text": "data Lake you have to think in terms of securing and protecting that asset because data is the most valuable asset",
    "start": "504960",
    "end": "512080"
  },
  {
    "text": "and you have to ensure that customer that people who are entitled to",
    "start": "512080",
    "end": "518240"
  },
  {
    "text": "access the data will get access to only that data set for example it may mean",
    "start": "518240",
    "end": "523399"
  },
  {
    "text": "that a marketing department has only to the data sets about campaigns about uh other marketing links they have and the",
    "start": "523399",
    "end": "530640"
  },
  {
    "text": "finally the last one being is that how do users access the data set with the choice of different variety of analytics",
    "start": "530640",
    "end": "536560"
  },
  {
    "text": "tools with the choice of variety of different apis you have to ensure that people could access data into any format",
    "start": "536560",
    "end": "542720"
  },
  {
    "text": "whether be from a user interface whether it be from apis or from any other method",
    "start": "542720",
    "end": "547839"
  },
  {
    "text": "which you seem is appropriate from a consumption perspective these are the four at least",
    "start": "547839",
    "end": "553360"
  },
  {
    "text": "four important components you have to think about holistically when building a data",
    "start": "553360",
    "end": "559680"
  },
  {
    "text": "l so if should really deep dive on about building a data Lake on AWS and if you",
    "start": "559680",
    "end": "566959"
  },
  {
    "start": "562000",
    "end": "562000"
  },
  {
    "text": "think from those four perspectives or those four components of building a data Lake Amazon S3 provides you as a Central",
    "start": "566959",
    "end": "573800"
  },
  {
    "text": "Storage platform where you don't have to worry about putting your data into schema or you don't have to worry about",
    "start": "573800",
    "end": "580320"
  },
  {
    "text": "scaling the Amazon S3 storage because Amazon S3 scales as your data grows",
    "start": "580320",
    "end": "585760"
  },
  {
    "text": "automatically but from the data inje perspective we have services such as",
    "start": "585760",
    "end": "591360"
  },
  {
    "text": "Amazon Kinesis both streams and fire hose Direct Connect which allows you to use your own propriety protocol or any",
    "start": "591360",
    "end": "599480"
  },
  {
    "text": "the software you want to transfer data from your on-prem back to AWS snowball",
    "start": "599480",
    "end": "605480"
  },
  {
    "text": "AWS import export snowball which allows you to move large quantities of data much easily or services such as data",
    "start": "605480",
    "end": "612560"
  },
  {
    "text": "migration service which allows you to copy or replicate data from your onr databases",
    "start": "612560",
    "end": "618720"
  },
  {
    "text": "or even databases running into uh AWS back to your uh back to database or like",
    "start": "618720",
    "end": "625360"
  },
  {
    "text": "red shift for example on the catalog and search side",
    "start": "625360",
    "end": "630560"
  },
  {
    "text": "just you could use Dynamo DB as a central catalog we Dynamo DB has integration with uh Lambda where Amazon",
    "start": "630560",
    "end": "639320"
  },
  {
    "text": "where anytime you put an object in Amazon S3 it can trigger a Lambda function which can create an entry into",
    "start": "639320",
    "end": "644680"
  },
  {
    "text": "a Dynamo DB to create to keep a catalog of the data set in the same model you",
    "start": "644680",
    "end": "650240"
  },
  {
    "text": "could also take the subset of data and fold it through a search system such as elastic search for example and AWS",
    "start": "650240",
    "end": "657360"
  },
  {
    "text": "provides you a manage elastic search service where your users can find data based on business context so they can search the",
    "start": "657360",
    "end": "665560"
  },
  {
    "text": "data in any way they want and be able to find where the data is within the data Lake regarding the management you could",
    "start": "665560",
    "end": "671760"
  },
  {
    "text": "use API Gateway to build apis for people to access the data set uh Amazon Cognito user pools could",
    "start": "671760",
    "end": "678639"
  },
  {
    "text": "be used to manage the control on how which who all can access the data Lake and then regarding protect and",
    "start": "678639",
    "end": "686680"
  },
  {
    "text": "secure you have in addition to what S3 provides for example server side encryption client side encryption uh",
    "start": "687079",
    "end": "694079"
  },
  {
    "text": "bucket policies you have features such as security token service where a simp simple token could be used to provide a",
    "start": "694079",
    "end": "701519"
  },
  {
    "text": "temporary authentication or provide temporary access to the data set or data in the data leges Cloud watch and cloud",
    "start": "701519",
    "end": "708959"
  },
  {
    "text": "trail could help you monitor what's going in who is accessing it uh what are the latencies what are the metrics",
    "start": "708959",
    "end": "714519"
  },
  {
    "text": "around that and finally Key Management Service which allows you to encrypt the data create your own data keys to",
    "start": "714519",
    "end": "721800"
  },
  {
    "text": "encrypt the data setting in the data Lake could be thought as another way to in protect and secure the data you could",
    "start": "721800",
    "end": "727800"
  },
  {
    "text": "control who can access the key to the encrypted data so only people with the right ENT entitlements can access the",
    "start": "727800",
    "end": "734760"
  },
  {
    "text": "data and decrypted to running any sort of processing or analytics on top of",
    "start": "734760",
    "end": "739800"
  },
  {
    "text": "it talking about processing and analytics you have machine learning",
    "start": "739800",
    "end": "745680"
  },
  {
    "text": "quick site EMR Amazon EMR and red shift and they all work with the Central Storage or the data sitting in a lake",
    "start": "745680",
    "end": "752240"
  },
  {
    "text": "you don't have to build any specific integration all of them automatically allows you to take the data in data Lake",
    "start": "752240",
    "end": "757920"
  },
  {
    "text": "and run the appropriate algorithm or processing framework on top of the data setting in",
    "start": "757920",
    "end": "763880"
  },
  {
    "start": "762000",
    "end": "762000"
  },
  {
    "text": "S3 so why would you build a data Lake on AWS we talked about these are the ways you could build different components of",
    "start": "763880",
    "end": "770160"
  },
  {
    "text": "a data Lake in AWS but if you look holistically a provides different features for example flexibility and",
    "start": "770160",
    "end": "776480"
  },
  {
    "text": "Agility in terms of on demand resources in terms of not worrying about managing the infrastructure but we also talked",
    "start": "776480",
    "end": "783079"
  },
  {
    "text": "about security and compliance and the most complete platform for big data analytics by giving you services such as",
    "start": "783079",
    "end": "789800"
  },
  {
    "text": "red sh for data warehousing Amazon EMR for manage adop clusters machine learning and even quick site for quick",
    "start": "789800",
    "end": "796040"
  },
  {
    "text": "visualization of data so if you take a look further into why build a data Lake on AWS in terms of",
    "start": "796040",
    "end": "802839"
  },
  {
    "text": "flexibility and Agility the first we talked about is that you could store all of your data in a very cost effective",
    "start": "802839",
    "end": "809440"
  },
  {
    "text": "manner on Amazon S3 Amazon S3 on a normalized rate cost you 3 cents per",
    "start": "809440",
    "end": "815360"
  },
  {
    "text": "gigabyte per month which translates to $30 for a terabyte for a month not only",
    "start": "815360",
    "end": "821120"
  },
  {
    "text": "that Amazon S3 has Integrations from fire hose from a import export snowball",
    "start": "821120",
    "end": "827240"
  },
  {
    "text": "from uh services such as sorry Direct Connect or uh S3 Hado",
    "start": "827240",
    "end": "833800"
  },
  {
    "text": "disc copy which allows you to move data over di connect back into AWS it allows you to",
    "start": "833800",
    "end": "839600"
  },
  {
    "text": "separate your computer from storage and eliminates the CH eliminates the challenges when you have to convert data",
    "start": "839600",
    "end": "845639"
  },
  {
    "text": "into predefined schema S3 is the way you",
    "start": "845639",
    "end": "851040"
  },
  {
    "text": "store the format you choose in uh to store data in S3 is is not important to",
    "start": "851040",
    "end": "856440"
  },
  {
    "text": "S3 uh uh S3 every treats as a blackbox object so you don't have to worry about",
    "start": "856440",
    "end": "862480"
  },
  {
    "text": "translating your object into specific format with that I would like to now invite mark shriber from cloud to talk",
    "start": "862480",
    "end": "869600"
  },
  {
    "text": "about the benefits you could achieve by from AWS in building a data Lake",
    "start": "869600",
    "end": "876519"
  },
  {
    "text": "mark thank you Rahul it's a pleasure to be here and uh on today's webinar um I'm",
    "start": "876519",
    "end": "882680"
  },
  {
    "text": "Mark shriber I'm general manager at cloudwick um what I'm going to talk about today is I think probably one of",
    "start": "882680",
    "end": "887839"
  },
  {
    "text": "the most important things that's facing the Enterprise it and line of business today and that is simply how do we",
    "start": "887839",
    "end": "894199"
  },
  {
    "text": "Leverage The Cloud to transform our business interestingly enough uh just",
    "start": "894199",
    "end": "900560"
  },
  {
    "start": "900000",
    "end": "900000"
  },
  {
    "text": "the other day IDC uh reported that they believe that we are now at the dawn of",
    "start": "900560",
    "end": "906199"
  },
  {
    "text": "the digital economy and this has really been cloudwick Focus for the last six",
    "start": "906199",
    "end": "911399"
  },
  {
    "text": "years um we've been working with leading datadriven Enterprises to transform their traditional data center",
    "start": "911399",
    "end": "918759"
  },
  {
    "text": "applications uh into big data and open source Cloud businesses um what I'm",
    "start": "918759",
    "end": "923920"
  },
  {
    "text": "going to talk to you today about is a story about an Enterprise probably much like all of you in which they had really",
    "start": "923920",
    "end": "930800"
  },
  {
    "text": "smart solution Architects they had really good developers and really good",
    "start": "930800",
    "end": "935839"
  },
  {
    "text": "data engineers and in their Journey you know they recognized that CL that AWS",
    "start": "935839",
    "end": "941959"
  },
  {
    "text": "was the right place for them to transform their business uh and build a",
    "start": "941959",
    "end": "947160"
  },
  {
    "text": "data Lake business and they were able to get there on their own in terms of their",
    "start": "947160",
    "end": "952199"
  },
  {
    "text": "first phase po um but I'm sure like many of you you know when you look at the challenges the options the different",
    "start": "952199",
    "end": "959279"
  },
  {
    "text": "software packages that put together and make up a data Lake it becomes really",
    "start": "959279",
    "end": "964319"
  },
  {
    "text": "complicated to optimize it for business so one of the things that we're focused on here at cloudwick is helping both the",
    "start": "964319",
    "end": "971959"
  },
  {
    "text": "Enterprise line of business and it do more with their data Lake whether it's",
    "start": "971959",
    "end": "977839"
  },
  {
    "text": "building a new one or optimizing an existing one so in this use case I'm",
    "start": "977839",
    "end": "984079"
  },
  {
    "start": "982000",
    "end": "982000"
  },
  {
    "text": "going to talk a little bit about a healthc care company and I think it's probably very similar to all of you in",
    "start": "984079",
    "end": "989160"
  },
  {
    "text": "which you have your line of business you know looking at ways in which they can drive new digital revenue and um how can",
    "start": "989160",
    "end": "996880"
  },
  {
    "text": "they become more competitive and I think this is one of those interesting things that we're all challenged as you know solution Architects and developers when",
    "start": "996880",
    "end": "1003880"
  },
  {
    "text": "we look at the traditional business models that we had it was really a packaged software market and we would go",
    "start": "1003880",
    "end": "1010120"
  },
  {
    "text": "out to an sap to an Oracle and they would tell us exactly what the",
    "start": "1010120",
    "end": "1015240"
  },
  {
    "text": "capabilities were of a platform of an application and where this has all changed and what",
    "start": "1015240",
    "end": "1021079"
  },
  {
    "text": "is so unique about AWS is it really transforms the it and business model",
    "start": "1021079",
    "end": "1027400"
  },
  {
    "text": "because now you're able to leverage infrastructure as a service as well as platform as a service to build very",
    "start": "1027400",
    "end": "1035438"
  },
  {
    "text": "unique and highly competitive and differentiated software analytics as well as business services so like I",
    "start": "1035439",
    "end": "1043038"
  },
  {
    "text": "indicated one of the challenges that this healthc care company had was their solution architect and engineering team",
    "start": "1043039",
    "end": "1049039"
  },
  {
    "text": "was able to start and create their data Lake however they ran into some problems with regards to the performance of their",
    "start": "1049039",
    "end": "1055720"
  },
  {
    "text": "data Lake and I'm sure this is something that many of you face um and what we really did there for them if we look at",
    "start": "1055720",
    "end": "1062559"
  },
  {
    "text": "in terms of the solution we consulted with them based upon the experience that we've developed working with the fortune",
    "start": "1062559",
    "end": "1069160"
  },
  {
    "text": "1000 for the last six years with both open source and Cloud Technologies um to",
    "start": "1069160",
    "end": "1074600"
  },
  {
    "text": "build an optimized cluster because the interesting thing that you'll find when you you start working with these",
    "start": "1074600",
    "end": "1080080"
  },
  {
    "text": "Technologies is that although the options almost seem endless um there are",
    "start": "1080080",
    "end": "1085640"
  },
  {
    "text": "really key and fundamental strategies for making them both performance driven",
    "start": "1085640",
    "end": "1090919"
  },
  {
    "text": "but also cost optimized so in this case the cloudwick solution after doing the",
    "start": "1090919",
    "end": "1096320"
  },
  {
    "text": "analysis in our phase one where we aligned the business and technology requirements their POC data Lake was not",
    "start": "1096320",
    "end": "1103760"
  },
  {
    "text": "able to ingest the data fast enough and uh they really needed help with re",
    "start": "1103760",
    "end": "1109400"
  },
  {
    "text": "architecting to create a business model in which their data ingestion could",
    "start": "1109400",
    "end": "1114640"
  },
  {
    "text": "process the data in real time and thereby deliver realtime analytic",
    "start": "1114640",
    "end": "1120080"
  },
  {
    "text": "results in doing this we had to help them with a new data governance process um we had to look at Predictive",
    "start": "1120080",
    "end": "1126440"
  },
  {
    "text": "Analytics and the range of options that they could use both open source and proprietary at the end of the day we",
    "start": "1126440",
    "end": "1133520"
  },
  {
    "text": "were able to help them improve their metadata management which frankly becomes one of the most important pieces",
    "start": "1133520",
    "end": "1138760"
  },
  {
    "text": "and a data Lake strategy uh for an Enterprise also what was interesting about this you know years ago you would",
    "start": "1138760",
    "end": "1145520"
  },
  {
    "text": "hear and even 69ine 10 months ago you'd hear things like oh healthc care Finance",
    "start": "1145520",
    "end": "1150760"
  },
  {
    "text": "regulated Industries are never going to move to the cloud well the reality is if you look at cloudwick Enterprise",
    "start": "1150760",
    "end": "1157600"
  },
  {
    "text": "customers we have leading health care and Banking and insurance companies that",
    "start": "1157600",
    "end": "1164320"
  },
  {
    "text": "are building their next Generation data Lakes on AWS because of the flexibility",
    "start": "1164320",
    "end": "1170320"
  },
  {
    "text": "and the power it actually gives it and business so you know here again is kind",
    "start": "1170320",
    "end": "1176880"
  },
  {
    "text": "of the complexity if you're in it and you're looking at the AWS landscape it's",
    "start": "1176880",
    "end": "1182600"
  },
  {
    "text": "absolutely amazing in terms of the options that it provides you there are so many different storage strategies",
    "start": "1182600",
    "end": "1188799"
  },
  {
    "text": "there are so many different compute strategies if you look at it from a platform perspective you've got both",
    "start": "1188799",
    "end": "1194600"
  },
  {
    "text": "open- Source commercial solutions from leading Hadoop vendors like cloud era Horton Works map R you have no SQL",
    "start": "1194600",
    "end": "1202480"
  },
  {
    "text": "options from mongodb uh as well as Cassandra and data stacks and then you have advanced",
    "start": "1202480",
    "end": "1209200"
  },
  {
    "text": "analytic solutions from companies like data bricks and at the end of the day",
    "start": "1209200",
    "end": "1214880"
  },
  {
    "text": "the real complexity here is you know and the opportunity for it is how do I take",
    "start": "1214880",
    "end": "1220640"
  },
  {
    "text": "this amazingly powerful portfolio of infrastructure and platform applications",
    "start": "1220640",
    "end": "1228120"
  },
  {
    "text": "and build my next Generation business and so in any event just to give you some feedback in terms of what we did do",
    "start": "1228120",
    "end": "1234679"
  },
  {
    "text": "the existing data Lake that they were using they had developed based on scoop for the data ingestion process they were",
    "start": "1234679",
    "end": "1241000"
  },
  {
    "text": "moving the data from a MySQL sharded environment to a Hadoop environment the problem they had was yes this",
    "start": "1241000",
    "end": "1247559"
  },
  {
    "text": "functionally worked however it took more than 48 hours and the company had to wait until weekend to conduct ingestion",
    "start": "1247559",
    "end": "1254400"
  },
  {
    "text": "due to the lengthy data ingestion process this meant that it had no real near had no near realtime analytics with",
    "start": "1254400",
    "end": "1261120"
  },
  {
    "text": "which to make crucial health care and business decisions so you know they hadn't really improveed their business",
    "start": "1261120",
    "end": "1267799"
  },
  {
    "text": "position they had designed a data late L that was going to provide them with the Next Generation analytic and business",
    "start": "1267799",
    "end": "1274039"
  },
  {
    "text": "services but they really needed help to come in and optimize it how do I now engineer it such that I can meet my",
    "start": "1274039",
    "end": "1280880"
  },
  {
    "text": "business objectives so we rearchitecturing",
    "start": "1280880",
    "end": "1286480"
  },
  {
    "text": "spk cluster solution and this again requires a lot of sophistication and",
    "start": "1288679",
    "end": "1293960"
  },
  {
    "text": "skill to do and so if you look at this and I think you're going to see many other different architectures I think",
    "start": "1293960",
    "end": "1299760"
  },
  {
    "text": "the one thing to take away from this is that there is not one data Lake architecture that fits all Business",
    "start": "1299760",
    "end": "1308039"
  },
  {
    "text": "Solutions and at the end of the day you know what we see is an incredible opportunity for it and business to",
    "start": "1308559",
    "end": "1316240"
  },
  {
    "text": "collaborate to build their next generation business analytics and applications on",
    "start": "1316240",
    "end": "1322720"
  },
  {
    "text": "AWS simply because you can't find a better platform to build that next",
    "start": "1322720",
    "end": "1328039"
  },
  {
    "text": "Generation digital business so from there I'd like to turn it back over to uh rul and um look",
    "start": "1328039",
    "end": "1335679"
  },
  {
    "start": "1331000",
    "end": "1331000"
  },
  {
    "text": "forward to questions cool um thank you can you guys",
    "start": "1335679",
    "end": "1341120"
  },
  {
    "text": "hear me again Jerry okay awesome um thank you Mark so",
    "start": "1341120",
    "end": "1348279"
  },
  {
    "text": "now we're going to talk about what security and compliance which is another benefit of building a data Lake on",
    "start": "1348279",
    "end": "1355679"
  },
  {
    "text": "AWS first of all anything you run on top of AWS runs on the top of secure AWS",
    "start": "1355679",
    "end": "1362039"
  },
  {
    "text": "infrastructure what it means is that we take care in ensuring that we meet the",
    "start": "1362039",
    "end": "1368559"
  },
  {
    "text": "compliance and and the regulatory needs for whatever workload you are running on top of AWS for instance it could be",
    "start": "1368559",
    "end": "1375360"
  },
  {
    "text": "something as PCI DSS or Hippa or fed from anything below uh below the in",
    "start": "1375360",
    "end": "1383080"
  },
  {
    "text": "infrastructure below the host level but you as a consumer have features available for example you can enable",
    "start": "1383080",
    "end": "1389480"
  },
  {
    "text": "encryption with S3 by checking a bucket by by checking a option to saying that",
    "start": "1389480",
    "end": "1395400"
  },
  {
    "text": "hey S3 encrypt all of my data before I store it in before you store it in S3 or",
    "start": "1395400",
    "end": "1400960"
  },
  {
    "text": "you could even pass your own encryption keys to Amazon S3 to say that take this",
    "start": "1400960",
    "end": "1407080"
  },
  {
    "text": "data set and take this key and encrypt the data set you store in S3 using the key I'm providing it to you and that key",
    "start": "1407080",
    "end": "1414120"
  },
  {
    "text": "could be stored further as we mentioned earlier into the KMS service so that allows you to create multiple keys for",
    "start": "1414120",
    "end": "1420760"
  },
  {
    "text": "storing data sets in a much more secure manner not only that we have services",
    "start": "1420760",
    "end": "1426760"
  },
  {
    "text": "such as red shift and EMR which supports security both at rest and in transit and",
    "start": "1426760",
    "end": "1432600"
  },
  {
    "text": "S3 when you access any objects from S3 by default we use SSL which which means that your data is",
    "start": "1432600",
    "end": "1439440"
  },
  {
    "text": "getting encrypted in transit itself further from a compliance or security perspective you could even manage your",
    "start": "1439440",
    "end": "1445640"
  },
  {
    "text": "user groups using AWS identity access management and take advantage of",
    "start": "1445640",
    "end": "1450880"
  },
  {
    "text": "services such as Cognito or Amazon secure token service to not deal with",
    "start": "1450880",
    "end": "1456320"
  },
  {
    "text": "passwords and usernames and anymore and you can just provide users with access to Temporary tokens or session tokens",
    "start": "1456320",
    "end": "1463480"
  },
  {
    "text": "which they can use for a limited duration to do a very specific thing for example you could say that a user is",
    "start": "1463480",
    "end": "1470600"
  },
  {
    "text": "only allowed to access this data or run only this API for example only to read",
    "start": "1470600",
    "end": "1476159"
  },
  {
    "text": "the data set in S3 but they not allow to write anything in S3 in even at a object or a prefix level",
    "start": "1476159",
    "end": "1483360"
  },
  {
    "text": "and to talk further in details about that benefit we'll invite razar shik who",
    "start": "1483360",
    "end": "1488640"
  },
  {
    "text": "CTO at North Bay RZA over to you to talk about security and",
    "start": "1488640",
    "end": "1494799"
  },
  {
    "text": "compliance thank you Rahul um hello everyone uh who joined today at the",
    "start": "1495760",
    "end": "1502600"
  },
  {
    "text": "webinar North is a 200 person growing uh APN partner with Advanced Consulting uh",
    "start": "1502720",
    "end": "1510840"
  },
  {
    "start": "1503000",
    "end": "1503000"
  },
  {
    "text": "status and we've been implementing data Lakes on AWS since",
    "start": "1510840",
    "end": "1516320"
  },
  {
    "text": "2013 in that we were one of the first uh to achieve the Big Data competence in",
    "start": "1516320",
    "end": "1522000"
  },
  {
    "text": "this space we provide uh services to our",
    "start": "1522000",
    "end": "1527520"
  },
  {
    "text": "customers build building data Lakes uh on AWS and we have done that for a",
    "start": "1527520",
    "end": "1532840"
  },
  {
    "text": "number of customers in the healthcare Finance education attech and media space",
    "start": "1532840",
    "end": "1540360"
  },
  {
    "text": "uh we provide a one team model um where",
    "start": "1540360",
    "end": "1546000"
  },
  {
    "text": "agile teams with scrum uh work together with you and the customers like you uh",
    "start": "1546000",
    "end": "1552279"
  },
  {
    "text": "to build uh the data platforms data pipelines and data strategies for your",
    "start": "1552279",
    "end": "1558320"
  },
  {
    "text": "your company how when you work with North Bay",
    "start": "1558320",
    "end": "1565080"
  },
  {
    "text": "as an organization to architect your data Lake what you get is first we start",
    "start": "1565080",
    "end": "1570720"
  },
  {
    "text": "with developing a strategy to address your shortterm and long-term business",
    "start": "1570720",
    "end": "1576080"
  },
  {
    "text": "needs um that may be a 4 to 8 week phase",
    "start": "1576080",
    "end": "1581679"
  },
  {
    "text": "where we help design uh the data L pattern and the architectural blueprint",
    "start": "1581679",
    "end": "1586919"
  },
  {
    "text": "of the solution uh as no one-sized at all uh",
    "start": "1586919",
    "end": "1592320"
  },
  {
    "text": "exists um then we move on to quickly built the foundation uh off that uh blueprint with",
    "start": "1592320",
    "end": "1600679"
  },
  {
    "text": "you within that phase uh to help you get started quickly and in subsequent phases",
    "start": "1600679",
    "end": "1607279"
  },
  {
    "text": "uh then migrate uh your workloads and your data over to your data Lake based",
    "start": "1607279",
    "end": "1613240"
  },
  {
    "text": "platform we've helped a number of customers move uh from the old world",
    "start": "1613240",
    "end": "1618960"
  },
  {
    "text": "Legacy World on Prem world to the cloud we call it teaching old data New Tricks",
    "start": "1618960",
    "end": "1625320"
  },
  {
    "text": "it's the same data but you can do a lot more with it in a more flexible",
    "start": "1625320",
    "end": "1631640"
  },
  {
    "text": "manner we can talk about one public uh case study with Eliza Corporation where",
    "start": "1631640",
    "end": "1639279"
  },
  {
    "start": "1632000",
    "end": "1632000"
  },
  {
    "text": "we as an APN partner help them build uh their data Lake Centric data platform on",
    "start": "1639279",
    "end": "1645159"
  },
  {
    "text": "AWS a little bit about uh Eliza corporation uh Eliza Corporation is in",
    "start": "1645159",
    "end": "1651799"
  },
  {
    "text": "the healthc care engagement uh business they help their customer as the uh",
    "start": "1651799",
    "end": "1659120"
  },
  {
    "text": "business of healthcare moves to pay for performance uh they help people like",
    "start": "1659120",
    "end": "1664320"
  },
  {
    "text": "Blue Cross Blue Shields of the world uh in terms of doing outreaches for",
    "start": "1664320",
    "end": "1669720"
  },
  {
    "text": "adherence prevention condition management bran loyalty and and retention uh Eliza Corporation does",
    "start": "1669720",
    "end": "1677559"
  },
  {
    "text": "order of magnitudes of 300 million outreaches and interactions per",
    "start": "1677559",
    "end": "1683799"
  },
  {
    "text": "year interactions and outreaches have uh the form of ivr outbound calls SMS um",
    "start": "1683799",
    "end": "1692320"
  },
  {
    "text": "emails and other channel each Outreach is a series of question response",
    "start": "1692320",
    "end": "1697519"
  },
  {
    "text": "decision three um did you visit your physician in the last 30 days might be a",
    "start": "1697519",
    "end": "1704799"
  },
  {
    "text": "question with a yes no response as an answer uh this question response pairs type of",
    "start": "1704799",
    "end": "1712360"
  },
  {
    "text": "data is coming in at a very high pace and at a very high volume on a daily",
    "start": "1712360",
    "end": "1719320"
  },
  {
    "text": "basis uh in addition to this type of data Eliza also had um other data sets",
    "start": "1719320",
    "end": "1726480"
  },
  {
    "text": "including electronic medical records Pharmacy data enrichment data and so on",
    "start": "1726480",
    "end": "1732640"
  },
  {
    "text": "in uh in their uh Enterprise um not not only that um Eliza",
    "start": "1732640",
    "end": "1739799"
  },
  {
    "text": "Corporation had a lot of diverse needs in terms of consumption query patterns",
    "start": "1739799",
    "end": "1745320"
  },
  {
    "text": "and usage on that data for some group of stakeholders it meant bright and butter",
    "start": "1745320",
    "end": "1750519"
  },
  {
    "text": "reports that they need for others it meant ad hoc questions that need to be",
    "start": "1750519",
    "end": "1755559"
  },
  {
    "text": "answered on demand and yet for other it meant uh machine learning and predictive",
    "start": "1755559",
    "end": "1761360"
  },
  {
    "text": "workloads uh for their business when we help uh design the data",
    "start": "1761360",
    "end": "1769840"
  },
  {
    "text": "Lake Centric architecture uh for Eliza's Next Generation platform the goal was to",
    "start": "1769840",
    "end": "1775799"
  },
  {
    "text": "build build that next Generation as rul also alluded one of the key features for",
    "start": "1775799",
    "end": "1782039"
  },
  {
    "text": "an S3 based data Lake on AWS is that you are able to decouple uh storage and",
    "start": "1782039",
    "end": "1789519"
  },
  {
    "text": "compute and processing uh giving you a lot more flexibility uh just to mention as an",
    "start": "1789519",
    "end": "1795679"
  },
  {
    "text": "aside that's not the case if you you were dumping all your data in",
    "start": "1795679",
    "end": "1800720"
  },
  {
    "text": "hdfs uh in that case you may call it a data Lake but you are still coupling",
    "start": "1800720",
    "end": "1806320"
  },
  {
    "text": "compute and storage you don't get the benefits and advantages another goal for",
    "start": "1806320",
    "end": "1812480"
  },
  {
    "text": "um designing this architecture for Eliza uh was to give them the ability to",
    "start": "1812480",
    "end": "1818519"
  },
  {
    "text": "process their current data but also uh enable them for future uh data sets and",
    "start": "1818519",
    "end": "1824080"
  },
  {
    "text": "data streams Eliza operates under um a regulated environment influenced by",
    "start": "1824080",
    "end": "1830919"
  },
  {
    "text": "Hippa and other regulations uh so considerations of aisc of data for Devon",
    "start": "1830919",
    "end": "1837640"
  },
  {
    "text": "test system with special filters while data is passing through to decouple Phi from",
    "start": "1837640",
    "end": "1843440"
  },
  {
    "text": "pii uh to um evaluate which managed",
    "start": "1843440",
    "end": "1848720"
  },
  {
    "text": "services with AWS are covered under the baa and which are not and if not then um",
    "start": "1848720",
    "end": "1856360"
  },
  {
    "text": "uh take appropriate measures uh the goal of the pl platform design was",
    "start": "1856360",
    "end": "1862000"
  },
  {
    "text": "to uh enable fast ingestion and storage of that data allow for both real time",
    "start": "1862000",
    "end": "1868559"
  },
  {
    "text": "and batch oriented processing uh of course uh data Lake does not equal to open access uh one of",
    "start": "1868559",
    "end": "1877360"
  },
  {
    "text": "the key components as R mentioned is to encapsulate your storage uh with access",
    "start": "1877360",
    "end": "1883880"
  },
  {
    "text": "U entitlements and governance and lastly one of of the important goal for this architecture for",
    "start": "1883880",
    "end": "1890159"
  },
  {
    "text": "Eliza was to enable self-service and increase that for their users as we",
    "start": "1890159",
    "end": "1895639"
  },
  {
    "start": "1894000",
    "end": "1894000"
  },
  {
    "text": "implemented that we do we did realize quite a number of benefits I'll briefly mentioned um The Hub and spoke model uh",
    "start": "1895639",
    "end": "1904720"
  },
  {
    "text": "for loading data into the plat the platform and ingesting and processing it",
    "start": "1904720",
    "end": "1910120"
  },
  {
    "text": "on the other side provided for a streamlined way of working and that resulted in a lot of reduction in manual",
    "start": "1910120",
    "end": "1918000"
  },
  {
    "text": "processing that human FTE needed to do in fact Eliza realized anywhere from 30",
    "start": "1918000",
    "end": "1923840"
  },
  {
    "text": "to 40% uh reduction in in in manual effort with that it resulted in improved",
    "start": "1923840",
    "end": "1930639"
  },
  {
    "text": "business agility their Eliza client portal that their customers actively use",
    "start": "1930639",
    "end": "1936760"
  },
  {
    "text": "um got updated in near real time rather than the daily basis that it was uh",
    "start": "1936760",
    "end": "1942159"
  },
  {
    "text": "being done before of course the cloud and AWS gives you the ability to scale",
    "start": "1942159",
    "end": "1948240"
  },
  {
    "text": "resources on demand and do cost attributions to business groups um they",
    "start": "1948240",
    "end": "1954440"
  },
  {
    "text": "also reduced uh their time for what they call client analytics from weeks to",
    "start": "1954440",
    "end": "1960519"
  },
  {
    "text": "hours um and overall resulted in a much more flexible scalable uh platform for",
    "start": "1960519",
    "end": "1967440"
  },
  {
    "text": "them I'll spend a little bit of time going through uh the architectural pattern that they ended up with and this",
    "start": "1967440",
    "end": "1974840"
  },
  {
    "text": "is sort of although there's not a one answer to all but uh this demonstrates the highlevel reference architecture for",
    "start": "1974840",
    "end": "1983240"
  },
  {
    "text": "uh building a data Lake on AWS it reads kind of left to right where the data",
    "start": "1983240",
    "end": "1989440"
  },
  {
    "text": "coming in starts from the left and ultimately is kind of getting accessed and consumed on the right uh we have",
    "start": "1989440",
    "end": "1995840"
  },
  {
    "text": "both uh realtime uh sources of data that are pushed into a Kinesis stream and bat",
    "start": "1995840",
    "end": "2002720"
  },
  {
    "text": "uh data that lands on initial stages of S3 uh for their knock and operations uh",
    "start": "2002720",
    "end": "2010120"
  },
  {
    "text": "they even used uh Kinesis analytics for near realtime uh",
    "start": "2010120",
    "end": "2016120"
  },
  {
    "text": "analytics uh all data coming in goes through uh a data quality governance and",
    "start": "2016120",
    "end": "2022360"
  },
  {
    "text": "metadata cataloging lare this is powered by Dynamo",
    "start": "2022360",
    "end": "2027720"
  },
  {
    "text": "DB uh with spark streaming uh jobs uh moving and transforming the data as it",
    "start": "2027720",
    "end": "2035080"
  },
  {
    "text": "lands into the data Lake storage the central piece of the storage is of",
    "start": "2035080",
    "end": "2040240"
  },
  {
    "text": "course S3 with life cycle management based on regulatory uh needs onto",
    "start": "2040240",
    "end": "2046559"
  },
  {
    "text": "Glacier um this whole thing is encapsulated uh in an API with u AWS API",
    "start": "2046559",
    "end": "2055440"
  },
  {
    "text": "Gateway um and the catalog is kept in a combination of um Dynamo DD and RDS uh",
    "start": "2055440",
    "end": "2065040"
  },
  {
    "text": "this provides a UI for data discovery through Cloud search uh for searching",
    "start": "2065040",
    "end": "2070240"
  },
  {
    "text": "what's in your Lake um and a UI for administrating administering",
    "start": "2070240",
    "end": "2076118"
  },
  {
    "text": "entitlements and access privileges now the real um interesting part is on the",
    "start": "2076119",
    "end": "2081638"
  },
  {
    "text": "right hand side where depending on the consumption need uh for example through",
    "start": "2081639",
    "end": "2087000"
  },
  {
    "text": "an EMR Presto um combination a SQL interface",
    "start": "2087000",
    "end": "2092440"
  },
  {
    "text": "was provided for their um client portal to be updated",
    "start": "2092440",
    "end": "2098680"
  },
  {
    "text": "um a red shift based Enterprise data warehouse was built uh fed through uh",
    "start": "2098680",
    "end": "2104920"
  },
  {
    "text": "EMR ingestion again uh EMR processing to feed some of their other needs um a hive",
    "start": "2104920",
    "end": "2113400"
  },
  {
    "text": "uh interface for their sasb based machine learning statistical workloads",
    "start": "2113400",
    "end": "2119200"
  },
  {
    "text": "and other uh consumption patterns uh with third parties all while the",
    "start": "2119200",
    "end": "2125079"
  },
  {
    "text": "operational monitoring uh and Auto in is provided um in summary the the the the",
    "start": "2125079",
    "end": "2133000"
  },
  {
    "text": "real um benefit that building a data Lake on AWS that you have is that you",
    "start": "2133000",
    "end": "2139240"
  },
  {
    "text": "can streamline your ingestion uh to be fast and be able to get things in",
    "start": "2139240",
    "end": "2144839"
  },
  {
    "text": "without worrying about schema on write and then be able to utilize that uh with",
    "start": "2144839",
    "end": "2150200"
  },
  {
    "text": "schema on read semantics as you need I'll turn it over back to Rahul thank",
    "start": "2150200",
    "end": "2156440"
  },
  {
    "text": "you so now with that let's just talk about the last benefit of data League",
    "start": "2156440",
    "end": "2161560"
  },
  {
    "text": "which is AWS provides you the most complete platform for running any sort of Big Data",
    "start": "2161560",
    "end": "2167920"
  },
  {
    "text": "workload with with whatever size of data you have for instance as we mentioned that regardless of the volume v velocity",
    "start": "2167920",
    "end": "2175160"
  },
  {
    "text": "or variety you could use workloads such as red Shi for data warehousing Amazon",
    "start": "2175160",
    "end": "2181200"
  },
  {
    "text": "EMR for manage Hardo clusters Amazon machine learning for running machine learning algorithms and Amazon quick",
    "start": "2181200",
    "end": "2188880"
  },
  {
    "text": "site for quickly visualizing and analyzing your data set the biggest Advantage is that if",
    "start": "2188880",
    "end": "2195040"
  },
  {
    "text": "your data is in S3 all of these Services natively integrate with Amazon S3 so you don't have to worry about moving or",
    "start": "2195040",
    "end": "2201720"
  },
  {
    "text": "transferring your data into any of these Services these Services have features which allows you to readily consume your",
    "start": "2201720",
    "end": "2207359"
  },
  {
    "text": "data set in S3 but not only that each of these Services could be scaled",
    "start": "2207359",
    "end": "2214160"
  },
  {
    "text": "independently irrespective of how much of data you have sitting in amaz on S3 for example even if you have petabytes",
    "start": "2214160",
    "end": "2220560"
  },
  {
    "text": "of data setting in S3 if you only want to analyze a few terabytes of data you can create Amazon EMR cluster or a red",
    "start": "2220560",
    "end": "2227440"
  },
  {
    "text": "shift cluster which can only work with that data set you could use Amazon machine learning to build a model and",
    "start": "2227440",
    "end": "2233960"
  },
  {
    "text": "train that model on a subset of data set and each of these cluster each of these",
    "start": "2233960",
    "end": "2239400"
  },
  {
    "text": "Services could be scaled independently irrespective of how large your data sets are and that model provides you with",
    "start": "2239400",
    "end": "2247200"
  },
  {
    "text": "many options to build a complete set of data services for example analytics",
    "start": "2247200",
    "end": "2252480"
  },
  {
    "text": "processing or even machine learning algorithms and with that now I would like to invite Mick bass CEO at 47",
    "start": "2252480",
    "end": "2259480"
  },
  {
    "text": "lining to talk about the last benefit of building a data Lake on AWS",
    "start": "2259480",
    "end": "2266319"
  },
  {
    "text": "Mick thanks rul thanks everyone for joining today's",
    "start": "2266319",
    "end": "2271839"
  },
  {
    "text": "webinar I'd also like to thank cloudwick and North Bay for sharing their insights and contributing to this true exciting",
    "start": "2271839",
    "end": "2278119"
  },
  {
    "text": "industry transformation I'm MC bass and I lead 47 Linings team of AWS Solutions and Big",
    "start": "2278119",
    "end": "2284160"
  },
  {
    "text": "Data Architects we're an APN Advanced Consulting partner with big data competency and we help our customers",
    "start": "2284160",
    "end": "2290480"
  },
  {
    "text": "build solid Bridges between the business value that they seek and the analytics Technologies and architectures that",
    "start": "2290480",
    "end": "2296760"
  },
  {
    "text": "we've been discussing here we help our customers at each stage of their data Lake journey we'll typically start with",
    "start": "2296760",
    "end": "2303960"
  },
  {
    "start": "2300000",
    "end": "2300000"
  },
  {
    "text": "an initial high value analytics use case validating a top a data Lake foundation",
    "start": "2303960",
    "end": "2309839"
  },
  {
    "text": "then we help our customer build Harden and launch their production data Lake and once launched we'll help them manage",
    "start": "2309839",
    "end": "2316240"
  },
  {
    "text": "their ongoing AWS in agile analytics operations so they can maintain their focus on how they generate value from",
    "start": "2316240",
    "end": "2323200"
  },
  {
    "text": "data to support their business it turns out this focus is really important",
    "start": "2323200",
    "end": "2329000"
  },
  {
    "text": "because most of our customers establish their data Lake in a way that's expected to be",
    "start": "2329000",
    "end": "2334240"
  },
  {
    "text": "self-funding data Lake efforts are often tied strongly to revenue upside to a",
    "start": "2334240",
    "end": "2340040"
  },
  {
    "text": "particular business initiative or otherwise directed uh towards uh Direct",
    "start": "2340040",
    "end": "2345240"
  },
  {
    "text": "business benefits proving value at every step is really critical to our customer",
    "start": "2345240",
    "end": "2350280"
  },
  {
    "text": "success here are some examples of the value sources that we've seen with our customers and we found that these are",
    "start": "2350280",
    "end": "2355640"
  },
  {
    "text": "actually uh relevant across most industry verticals the work that we've done with",
    "start": "2355640",
    "end": "2362200"
  },
  {
    "start": "2361000",
    "end": "2361000"
  },
  {
    "text": "the Howard Hughes Corporation is a good example of this journey they sometimes describe their business says Sim City in",
    "start": "2362200",
    "end": "2369160"
  },
  {
    "text": "real life they develop projects that span thousands of homes and condos millions of square feet of office space",
    "start": "2369160",
    "end": "2376079"
  },
  {
    "text": "and multi-tenant Retail shopping destinations and experiences as you can imagine there are",
    "start": "2376079",
    "end": "2381960"
  },
  {
    "text": "lots of opportunities to leverage data to create business value within this setting with the data Lake approach we",
    "start": "2381960",
    "end": "2387440"
  },
  {
    "text": "can combine multiple data sources to increase pricing transparency we can optimize the mix of",
    "start": "2387440",
    "end": "2393720"
  },
  {
    "text": "retail tenants in commercial spaces we can increase the dep and quality of qualified leads for purchases and we can",
    "start": "2393720",
    "end": "2400720"
  },
  {
    "text": "make real-time offers to consumers in retail settings our initial solution with the",
    "start": "2400720",
    "end": "2406599"
  },
  {
    "start": "2406000",
    "end": "2406000"
  },
  {
    "text": "Howard Hughes Corporation spanned large scale data injust Fusion of multiple data sources feature extraction and",
    "start": "2406599",
    "end": "2414599"
  },
  {
    "text": "creation of a machine learning model to enable predictions for purchase propensity based on historic",
    "start": "2414599",
    "end": "2420680"
  },
  {
    "text": "actuals their results were particularly compelling a 400% increase in the number",
    "start": "2420680",
    "end": "2425880"
  },
  {
    "text": "of leads in their pipeline together with Rich visibility as to the qualification of those leads at less than a tenth the",
    "start": "2425880",
    "end": "2432800"
  },
  {
    "text": "cost of their historic marketing and lead generation approaches we tend to focus a lot on",
    "start": "2432800",
    "end": "2439599"
  },
  {
    "text": "establishing early quick winds with our customers efficiently laying down a robust and solid foundation for a wide",
    "start": "2439599",
    "end": "2446560"
  },
  {
    "text": "range of use cases while getting initial data sources and valuable pilot analytics in place with all of our",
    "start": "2446560",
    "end": "2453200"
  },
  {
    "text": "customers we set up these early wins with our data Lake reference architecture in mind for Howard Hughes",
    "start": "2453200",
    "end": "2459599"
  },
  {
    "text": "this enables them to continually expand their portfolio of value generating analytics and to drive those quickly",
    "start": "2459599",
    "end": "2465960"
  },
  {
    "text": "into efficient operations let's take a closer look at this reference architecture and why it's important I'll",
    "start": "2465960",
    "end": "2472839"
  },
  {
    "text": "walk you through four key aspects of the architecture first we'll talk a little",
    "start": "2472839",
    "end": "2478079"
  },
  {
    "text": "bit about the concept of operations that is who are the distinct categories of actors and how do they each need to",
    "start": "2478079",
    "end": "2484160"
  },
  {
    "text": "interact with the data Lake second a bit about AWS foundations and fundamentals third a really important",
    "start": "2484160",
    "end": "2491480"
  },
  {
    "text": "category of data management best practices and how we help customers grapple with the organization of the",
    "start": "2491480",
    "end": "2497280"
  },
  {
    "text": "data within their data Lake and finally we'll talk about a flexible stock of agile analytics that support different",
    "start": "2497280",
    "end": "2503760"
  },
  {
    "text": "use cases driven by different business priorities and return on investment the",
    "start": "2503760",
    "end": "2509240"
  },
  {
    "text": "reason that this architecture tends to be important in customer settings is as many uh on the call have mentioned",
    "start": "2509240",
    "end": "2515960"
  },
  {
    "text": "there's so much Flex ability uh in the tools that you can bring to bear uh having this sort of a of an approach to",
    "start": "2515960",
    "end": "2522520"
  },
  {
    "text": "help customers reason about where to start and how to grow tends to drive a lot of repeatability into this",
    "start": "2522520",
    "end": "2529040"
  },
  {
    "text": "process if we look for a moment at the outside of the diagram we see three different uh four different kinds of",
    "start": "2529040",
    "end": "2535839"
  },
  {
    "text": "actors on the left we have data contributors these can be real-time streams from devices in the field on-",
    "start": "2535839",
    "end": "2542720"
  },
  {
    "text": "premise transactional systems feeds from SAS vendors data that you've bought from data",
    "start": "2542720",
    "end": "2548920"
  },
  {
    "text": "providers data from mobile apps it's really common for these data contributors to be diverse to reside in",
    "start": "2548920",
    "end": "2556119"
  },
  {
    "text": "multiple companies they often span internal B2B and b2c sources next we",
    "start": "2556119",
    "end": "2561800"
  },
  {
    "text": "have data late Governors this is a really different role they're accountable for decisions about how your",
    "start": "2561800",
    "end": "2567359"
  },
  {
    "text": "data Lake generates value for the business making decisions via policy about entitlements who should be able to",
    "start": "2567359",
    "end": "2573800"
  },
  {
    "text": "contribute who should be able to consume which analytic be able to access which data and they're accountable for manage",
    "start": "2573800",
    "end": "2580319"
  },
  {
    "text": "the cost for managing the cost foot footprint of your data Lake and its allocation back to business value",
    "start": "2580319",
    "end": "2586880"
  },
  {
    "text": "finally we have data consumers data consumers they're diverse as well they might be sophisticated data scientists",
    "start": "2586880",
    "end": "2593720"
  },
  {
    "text": "who need direct access to manage data sets in your data Lake they could be consumers of published data using",
    "start": "2593720",
    "end": "2600280"
  },
  {
    "text": "standard bi tools or they could be B2B or b2c data ecosystem consumers who need",
    "start": "2600280",
    "end": "2605559"
  },
  {
    "text": "highly available access to publish data through an API understanding each of these",
    "start": "2605559",
    "end": "2611119"
  },
  {
    "text": "categories of users and their needs helps us to optimize their interactions with your data Lake and refine your data",
    "start": "2611119",
    "end": "2617119"
  },
  {
    "text": "Lakes road map I want to talk just a moment about AWS foundations and fundamentals one of",
    "start": "2617119",
    "end": "2624119"
  },
  {
    "text": "the really cool things about AWS is it provides you all the tools that you need to manage concerns like security",
    "start": "2624119",
    "end": "2630359"
  },
  {
    "text": "reliability an important part of all of our data Lake Pilots is to establish a strong Foundation that covers those best",
    "start": "2630359",
    "end": "2636640"
  },
  {
    "text": "practices is security Enterprise connectivity identity and entitlements management",
    "start": "2636640",
    "end": "2642760"
  },
  {
    "text": "monitoring many of our customers they lean pretty heavily towards their particular data and analytics use cases",
    "start": "2642760",
    "end": "2650040"
  },
  {
    "text": "and some of them are relatively new to AWS so getting these foundations in place efficiently drives down their risk",
    "start": "2650040",
    "end": "2656240"
  },
  {
    "text": "while speeding time to demonstrated value from analytics now let's look at the center",
    "start": "2656240",
    "end": "2662400"
  },
  {
    "text": "of the diagram for just a moment and we'll talk about data flow we found that",
    "start": "2662400",
    "end": "2667599"
  },
  {
    "text": "designing your data Lake to support these three different categories of data really helps to increase the analytics",
    "start": "2667599",
    "end": "2673880"
  },
  {
    "text": "agility that your team can achieve first raw submissions are all about just persisting the raw contributions in your",
    "start": "2673880",
    "end": "2680960"
  },
  {
    "text": "data Lake they drive the contribution cost for data contributors almost to zero while ensuring that you can replay",
    "start": "2680960",
    "end": "2687920"
  },
  {
    "text": "history as your portfolio of analytics evolves the managed data sets in the middle are important because they're",
    "start": "2687920",
    "end": "2694160"
  },
  {
    "text": "sort of like the the the translation they're you know know a progression of",
    "start": "2694160",
    "end": "2699800"
  },
  {
    "text": "from the left very kind of you know vendor and device Centric sorts of data formats to on the right very business",
    "start": "2699800",
    "end": "2706240"
  },
  {
    "text": "Centric uh kinds of formats and so those managed data sets can be a lot more",
    "start": "2706240",
    "end": "2711880"
  },
  {
    "text": "flexible than they could historically be in the uh uh in the data warehouse World",
    "start": "2711880",
    "end": "2717160"
  },
  {
    "text": "finally on the right publish data provides enduser results for example",
    "start": "2717160",
    "end": "2722559"
  },
  {
    "text": "reporting Aggregates or structured drill Downs these are often tables Amazon red",
    "start": "2722559",
    "end": "2727720"
  },
  {
    "text": "shift or highly available data in Dynamo DB that's consumed by an",
    "start": "2727720",
    "end": "2733000"
  },
  {
    "text": "API the flexible stack of agile analytics is important because it drives throughput from your uh analysis team",
    "start": "2733000",
    "end": "2740720"
  },
  {
    "text": "it's driven by business priorities you don't have to create them all at the same time it really empowers analysts",
    "start": "2740720",
    "end": "2746280"
  },
  {
    "text": "because it allows them to use the right tool for the right job and it provides them access to a wide range of AWS Big",
    "start": "2746280",
    "end": "2753040"
  },
  {
    "text": "Data tools and services it decouples Development Across multiple teams and analysts and it gives you a scalable",
    "start": "2753040",
    "end": "2759160"
  },
  {
    "text": "model to generate value from data tying that all together the result is that the",
    "start": "2759160",
    "end": "2765040"
  },
  {
    "text": "data Lake approach increases your team's throughput and value velocity it really helps strike this balance between",
    "start": "2765040",
    "end": "2771359"
  },
  {
    "text": "business owners and business value it and analysts that can bring value to the",
    "start": "2771359",
    "end": "2776480"
  },
  {
    "text": "table provides a solid foundation so that you can focus on analytics that get you to immediate value and then expand",
    "start": "2776480",
    "end": "2783200"
  },
  {
    "text": "your portfolio over time thanks I'll hand it back to rul from AWS",
    "start": "2783200",
    "end": "2789720"
  },
  {
    "start": "2789000",
    "end": "2789000"
  },
  {
    "text": "now thank you thank you Mick so in this session today we talked about what",
    "start": "2789880",
    "end": "2797079"
  },
  {
    "text": "are sorry what are the benefits of first building a data Lake um what essentially",
    "start": "2797079",
    "end": "2803160"
  },
  {
    "text": "is a data Lake what we try to define the second are in terms of building a data L",
    "start": "2803160",
    "end": "2808480"
  },
  {
    "text": "you think of data Lake as a virtualization for you all of your data set in a single Central repository and",
    "start": "2808480",
    "end": "2814720"
  },
  {
    "text": "the benefits you achieve is first as all of our partners to explained which is Excel time to value and reduce total",
    "start": "2814720",
    "end": "2820960"
  },
  {
    "text": "cost of ownership not only that you get increased flexibility in terms of deploying different types of analytics",
    "start": "2820960",
    "end": "2827680"
  },
  {
    "text": "and storing data at any scale and then you benefit from the agility by which",
    "start": "2827680",
    "end": "2833160"
  },
  {
    "text": "you could increase the Thro of your analytics team by giving them the ability to apply any type of analytics",
    "start": "2833160",
    "end": "2839800"
  },
  {
    "text": "which can deliver the business insights or they can produce the business insights much more",
    "start": "2839800",
    "end": "2845599"
  },
  {
    "text": "quickly now you to choose AWS as a platform to build your data Lake not only we talked about",
    "start": "2845599",
    "end": "2852440"
  },
  {
    "text": "the benefits such as flexibility and Agility security and compliance and the most complete portfolio of any type of",
    "start": "2852440",
    "end": "2859200"
  },
  {
    "text": "Big Data applications or services and each of of our partners today cloudwick North Bay and 47 lining",
    "start": "2859200",
    "end": "2867559"
  },
  {
    "text": "touched in deep on how these you can translate these features these benefits into most tangible terms to build a data",
    "start": "2867559",
    "end": "2874920"
  },
  {
    "text": "Lake on AWS with that that's the summary of our webinar and now we would move to a Q&A",
    "start": "2874920",
    "end": "2884640"
  },
  {
    "text": "and you know answer the questions you may have at that point in time I would also request all of the participants to",
    "start": "2884640",
    "end": "2891040"
  },
  {
    "text": "take a moment to answer the questions which you see on the poll right now and we will take the questions right and",
    "start": "2891040",
    "end": "2898559"
  },
  {
    "text": "today so one of the first questions we got was what is the relationship between",
    "start": "2898559",
    "end": "2903920"
  },
  {
    "text": "a data Lake and Enterprise data warehouse do have to change all of my existing bi ETL and data warehousing",
    "start": "2903920",
    "end": "2910960"
  },
  {
    "text": "infrastructure to use a data Lake the answer to that in brief is probably no",
    "start": "2910960",
    "end": "2917800"
  },
  {
    "text": "because if you think about it there's a symbotic relation between a data warehouse and a data Lake earlier",
    "start": "2917800",
    "end": "2924920"
  },
  {
    "text": "because of any reason you may have or various reasons you may have to cut down on the type of data you could ingest you",
    "start": "2924920",
    "end": "2931160"
  },
  {
    "text": "may have to define a schema and directly capture it from the sources process it and then load it into the datawarehouse",
    "start": "2931160",
    "end": "2938520"
  },
  {
    "text": "you could rather change your data link to capture all of your data from the sources itself in a much more native",
    "start": "2938520",
    "end": "2944880"
  },
  {
    "text": "format and much more quickly and easily and then your existing ETL processes could directly read from the data Lake",
    "start": "2944880",
    "end": "2951880"
  },
  {
    "text": "and then push it into the data warehouse that way you could leverage all of the investment you have done by providing a",
    "start": "2951880",
    "end": "2958760"
  },
  {
    "text": "data warehouse to your end consumer yet at the same time capture",
    "start": "2958760",
    "end": "2966040"
  },
  {
    "text": "all your data in the data Lake to help your businesses grow or consume the data or turn into a much more valuable",
    "start": "2966040",
    "end": "2973839"
  },
  {
    "text": "asset the second question what I have is for 47 lining and the question is how do",
    "start": "2973839",
    "end": "2980319"
  },
  {
    "text": "you incorporate realtime analytics into a data link so I think the key there is",
    "start": "2980319",
    "end": "2986680"
  },
  {
    "text": "the use of this agile analytics Paradigm where you can actually uh have a process",
    "start": "2986680",
    "end": "2992680"
  },
  {
    "text": "that publishes the real-time subset of your data to say for example examp Le a realtime spark cluster that your uh that",
    "start": "2992680",
    "end": "3001079"
  },
  {
    "text": "your dashboard tools are connecting to uh as data comes in through Kinesis uh",
    "start": "3001079",
    "end": "3006200"
  },
  {
    "text": "if you need uh extreme real time observations you can actually reach all the way back into that Kinesis stream",
    "start": "3006200",
    "end": "3012720"
  },
  {
    "text": "and operate on data as it comes in you can also build uh flexible processes",
    "start": "3012720",
    "end": "3018760"
  },
  {
    "text": "where you can have a red shift cluster that is responsible for maintaining",
    "start": "3018760",
    "end": "3024400"
  },
  {
    "text": "historic data historic you know in air quotes meaning everything that's more than an hour old and a spark cluster",
    "start": "3024400",
    "end": "3031319"
  },
  {
    "text": "that's accountable for the stuff that's you know much more recent um and then the the bi tools uh kind of rely on uh",
    "start": "3031319",
    "end": "3039920"
  },
  {
    "text": "the spark uh subsystem for real-time information and the historic red shift system for queries that are longer",
    "start": "3039920",
    "end": "3048838"
  },
  {
    "text": "lived than M so the next question I have is for cloudwick and Mark which is what",
    "start": "3050920",
    "end": "3058200"
  },
  {
    "text": "advantage have your clients realize from AWS data Lake and data warehousing projects great question um I think the",
    "start": "3058200",
    "end": "3064119"
  },
  {
    "text": "most important one is really the transformation with business and it um",
    "start": "3064119",
    "end": "3069200"
  },
  {
    "text": "what we see uh with our customers who are working on AWS data Lakes is the",
    "start": "3069200",
    "end": "3075160"
  },
  {
    "text": "relationship between it and the business really becomes um very collaborative um",
    "start": "3075160",
    "end": "3081119"
  },
  {
    "text": "it is able to respond much quicker they're able to deliver results um where",
    "start": "3081119",
    "end": "3086400"
  },
  {
    "text": "it may have taken you know a year or more to deliver a project they're now able to deliver projects in months so I",
    "start": "3086400",
    "end": "3093240"
  },
  {
    "text": "think you know at the end of the day the real transformation here is that what we're seeing is a lot of the friction",
    "start": "3093240",
    "end": "3099160"
  },
  {
    "text": "that is uh become inherent because of the challenges that it has working with a traditional on premise data center",
    "start": "3099160",
    "end": "3105760"
  },
  {
    "text": "model as well as traditional applications um really is uh not",
    "start": "3105760",
    "end": "3110880"
  },
  {
    "text": "existent when it comes to AWS and it liberates both parties to collaborate and accelerate",
    "start": "3110880",
    "end": "3117079"
  },
  {
    "text": "um that successful business",
    "start": "3117079",
    "end": "3120720"
  },
  {
    "text": "relationship Mark so the next question I have is for North Bay which is what is",
    "start": "3124680",
    "end": "3131319"
  },
  {
    "text": "the key to getting data Lake projects off to a fast and successful start thank you R um in our experience at North Bay",
    "start": "3131319",
    "end": "3139319"
  },
  {
    "text": "I think the fastest way to start is to um start small uh work into a reference",
    "start": "3139319",
    "end": "3147000"
  },
  {
    "text": "architecture that works for you uh for example we at North Bay offer a package",
    "start": "3147000",
    "end": "3152920"
  },
  {
    "text": "service called a jump start package where uh in a short period of time we want to bring you uh as an Enterprise to",
    "start": "3152920",
    "end": "3161079"
  },
  {
    "text": "a state where you have answered some of the tooling questions the basic reference architecture and built a road",
    "start": "3161079",
    "end": "3167599"
  },
  {
    "text": "mapap for implementation and in that small uh you know four to eight weeks uh",
    "start": "3167599",
    "end": "3173920"
  },
  {
    "text": "time you have uh built the basic blueprint and lined it up for the next phases",
    "start": "3173920",
    "end": "3179720"
  },
  {
    "text": "we've seen that to be very effective because it answers a lot of questions in a short period of time and gets you as",
    "start": "3179720",
    "end": "3186400"
  },
  {
    "text": "an Enterprise starting uh quickly on [Music]",
    "start": "3186400",
    "end": "3192500"
  },
  {
    "text": "that thank you so the another question what we have is how should we inest",
    "start": "3194000",
    "end": "3201000"
  },
  {
    "text": "traditional SQL data into the data lay store it in S3 or elsewhere",
    "start": "3201000",
    "end": "3207520"
  },
  {
    "text": "um I think this has two parts to the question which is first how where should you store all of your data would it be",
    "start": "3207520",
    "end": "3213640"
  },
  {
    "text": "S3 or somewhere else it really depends on what is that you're trying to do if you're trying to build a data Lake",
    "start": "3213640",
    "end": "3219119"
  },
  {
    "text": "having a centralized repository is probably one of the key aspects for a data Lake and you definitely want to",
    "start": "3219119",
    "end": "3225200"
  },
  {
    "text": "store most of your data into S3 as for example Mick also mentioned in the terms of being able to having the raw data set",
    "start": "3225200",
    "end": "3232760"
  },
  {
    "text": "allows you to repeat history or retransform history as your put folio of analytics evolve as the understanding of",
    "start": "3232760",
    "end": "3238599"
  },
  {
    "text": "a data grows it's very important for you to have that raw data set as an asset sitting into your data the second part",
    "start": "3238599",
    "end": "3245599"
  },
  {
    "text": "of the question I think is about how do we inest traditional SQL data into a",
    "start": "3245599",
    "end": "3251920"
  },
  {
    "text": "data link and there are many tools as you mentioned for example AWS DMS provides your ability to replicate your",
    "start": "3251920",
    "end": "3258640"
  },
  {
    "text": "data from on Prime databases into red shift or even our partner such as attunity provides a product called",
    "start": "3258640",
    "end": "3265480"
  },
  {
    "text": "attunity Cloud break which can take your data from traditional sources and keep a copy back in S3 or even you could use",
    "start": "3265480",
    "end": "3273000"
  },
  {
    "text": "leverage custom implementation such as for example Oracle provides a product called Golden Gate and you can connect a",
    "start": "3273000",
    "end": "3279319"
  },
  {
    "text": "Golden Gate to a Kafka or Kinesis stream which can then ingest your data back into your data Lake on top of",
    "start": "3279319",
    "end": "3287440"
  },
  {
    "text": "S3 now one of the most one of the important questions I think we're seeing time and again into the Q&A is what is",
    "start": "3288280",
    "end": "3296119"
  },
  {
    "text": "that we do about the metadata what are the best practices for building a metadata what are the things we could do",
    "start": "3296119",
    "end": "3302480"
  },
  {
    "text": "around to make it easier for a metadata building on top of your data Lake the",
    "start": "3302480",
    "end": "3307680"
  },
  {
    "text": "one of the basic pattern we talked about earlier to answer that question was using something called S3 event triggers",
    "start": "3307680",
    "end": "3314040"
  },
  {
    "text": "you can use S3 event triggers and connect them to AWS Lambda functions to trigger a variety of workloads for",
    "start": "3314040",
    "end": "3320440"
  },
  {
    "text": "example keeping an entry or keeping a catalog updated in Dynamo GB or even",
    "start": "3320440",
    "end": "3326319"
  },
  {
    "text": "even feeding the data back to a downstream processing system such as elastic search to fully index your data",
    "start": "3326319",
    "end": "3331839"
  },
  {
    "text": "but all of these options are kind of something you have to build your own and that's why we had our partners today",
    "start": "3331839",
    "end": "3338480"
  },
  {
    "text": "talk about for example make Mark and RZA all talked about the benefits these Partners provide in terms of helping you",
    "start": "3338480",
    "end": "3345400"
  },
  {
    "text": "simplify in trying to build all these different components of data Lake from the various services from the various",
    "start": "3345400",
    "end": "3351480"
  },
  {
    "text": "features which AWS provides and that is one way you could leverage it there are some other isv Solutions or technology",
    "start": "3351480",
    "end": "3358839"
  },
  {
    "text": "Partners also who provide such services such as um waterline data or there open",
    "start": "3358839",
    "end": "3364960"
  },
  {
    "text": "source Frameworks for example which allows you to take advantage of data for example Apachi Atlas or anything else",
    "start": "3364960",
    "end": "3371240"
  },
  {
    "text": "which you can leverage to build that holistic view of the metadata and with that we'll have last",
    "start": "3371240",
    "end": "3377039"
  },
  {
    "text": "question because we're running on the hour and I think the question says that do any of the partners have experience",
    "start": "3377039",
    "end": "3383640"
  },
  {
    "text": "with FPA in higher education I'm not sure what FPA means but uh if M Mark or",
    "start": "3383640",
    "end": "3391319"
  },
  {
    "text": "RZA if you have any experience I would let you just chime in this is RZA with North pay uh we do",
    "start": "3391319",
    "end": "3399200"
  },
  {
    "text": "have a good amount of experience with edtech and higher education and we can",
    "start": "3399200",
    "end": "3404920"
  },
  {
    "text": "certainly uh take this offline and talk uh talk more about [Music]",
    "start": "3404920",
    "end": "3410079"
  },
  {
    "text": "it great thank you um that's all again thank you everybody for attending the",
    "start": "3410079",
    "end": "3415119"
  },
  {
    "text": "webinar today we hope that you enjoyed the webinar and got to learn about building or architecting a data Lake on AWS and you learn the value our partners",
    "start": "3415119",
    "end": "3422680"
  },
  {
    "text": "provide you in helping in collaborating with you for building that data Le easily and successfully on top of AWS",
    "start": "3422680",
    "end": "3429079"
  },
  {
    "text": "thank you again and we again appreciate Mick Mike and Raza to uh help us in",
    "start": "3429079",
    "end": "3435119"
  },
  {
    "text": "translating a value of building a data L back on AWS to our customers today thank",
    "start": "3435119",
    "end": "3441079"
  },
  {
    "text": "you everybody",
    "start": "3441079",
    "end": "3444240"
  }
]
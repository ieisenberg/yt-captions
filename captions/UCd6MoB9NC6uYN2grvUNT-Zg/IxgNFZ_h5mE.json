[
  {
    "start": "0",
    "end": "88000"
  },
  {
    "text": "everyone and welcome to this in our on building a data Lake on AWS",
    "start": "6430",
    "end": "12049"
  },
  {
    "text": "first up thanks for joining us today I know it's a busy work day so thanks for",
    "start": "12049",
    "end": "17450"
  },
  {
    "text": "taking time and joining us today when we look at our customers who are migrating",
    "start": "17450",
    "end": "23419"
  },
  {
    "text": "to the AWS right so they've got lot of reasons to migrate to previous so costs",
    "start": "23419",
    "end": "28820"
  },
  {
    "text": "cost savings agility innovation and so on so forth right one of the primary",
    "start": "28820",
    "end": "35239"
  },
  {
    "text": "reasons once they migrate to a tableau is what they do only platform it is to start innovating quickly and data",
    "start": "35239",
    "end": "42409"
  },
  {
    "text": "becomes a key driver to innovate right so we have tons of customers who",
    "start": "42409",
    "end": "49040"
  },
  {
    "text": "leverage the platform to innovate and leverage data to take decisions for",
    "start": "49040",
    "end": "54949"
  },
  {
    "text": "their business over the next 90 minutes we'll talk about how the AWS platform is",
    "start": "54949",
    "end": "60710"
  },
  {
    "text": "helping customers to build data Lake that helps businesses to move quickly and make decisions based on data I'm I'm",
    "start": "60710",
    "end": "69920"
  },
  {
    "text": "Rob Norman balachandran I currently work as a Big Data Solutions Architect with Amazon Internet services Private Limited",
    "start": "69920",
    "end": "75890"
  },
  {
    "text": "and I'm joined today by a guest speaker who's going to share how they have built",
    "start": "75890",
    "end": "82399"
  },
  {
    "text": "our data Lake on the a Tablas platform",
    "start": "82399",
    "end": "86649"
  },
  {
    "start": "88000",
    "end": "88000"
  },
  {
    "text": "if I go back to how traditionally analytics used to look most of us would relate to this kind of",
    "start": "89289",
    "end": "97039"
  },
  {
    "text": "a pipeline right so where you have various data sources you collect data",
    "start": "97039",
    "end": "102200"
  },
  {
    "text": "from various data sources you perform your ETL on those data and then feed the",
    "start": "102200",
    "end": "109609"
  },
  {
    "text": "data into your data warehouse which becomes your central repository and you",
    "start": "109609",
    "end": "114770"
  },
  {
    "text": "use your favorite business intelligence tool to connect to data warehouse and",
    "start": "114770",
    "end": "120310"
  },
  {
    "text": "start making analysis and insights out of your data right if you look at this",
    "start": "120310",
    "end": "126380"
  },
  {
    "text": "model this model worked very well for relational data where data is most",
    "start": "126380",
    "end": "131990"
  },
  {
    "text": "assured and you have got schema well-defined prior to loading your data into the data warehouse in terms of the",
    "start": "131990",
    "end": "139820"
  },
  {
    "text": "volume of data this model worked very very four terabytes too sometimes petabytes",
    "start": "139820",
    "end": "145520"
  },
  {
    "text": "of scale right and in terms of the use cases that typically gets delivered to",
    "start": "145520",
    "end": "153980"
  },
  {
    "text": "this model is pretty much your operational reporting and a doc reports kind of use cases right and you need",
    "start": "153980",
    "end": "161900"
  },
  {
    "text": "initially a lot of investments in terms of capex investments and typically this used to range in the order of ten to",
    "start": "161900",
    "end": "169580"
  },
  {
    "start": "169000",
    "end": "169000"
  },
  {
    "text": "fifty thousand dollars per terabyte per year right now if I look at the derelict",
    "start": "169580",
    "end": "175730"
  },
  {
    "text": "model Darryl X kind of extend the this traditional approach where you still continue to collect data from those",
    "start": "175730",
    "end": "183080"
  },
  {
    "text": "different data sources like euro ADP systems and CRMs and ERP but you also",
    "start": "183080",
    "end": "188420"
  },
  {
    "text": "start collecting data from these new data sources which are your mobile devices",
    "start": "188420",
    "end": "194030"
  },
  {
    "text": "your server logs your IOT devices your social feeds and so on so forth which",
    "start": "194030",
    "end": "202160"
  },
  {
    "text": "feeds into your data lake and beyond business intelligence and reporting use",
    "start": "202160",
    "end": "207650"
  },
  {
    "text": "cases you know start uncovering new use cases like your big data processing your",
    "start": "207650",
    "end": "212930"
  },
  {
    "text": "near real-time use cases and more importantly what's happening these days in terms of machine learning driven and",
    "start": "212930",
    "end": "219740"
  },
  {
    "text": "use cases right so this opens up to a lot of new different use cases which the era Lake now starts feeding into in",
    "start": "219740",
    "end": "226880"
  },
  {
    "text": "terms of comparing that with the traditional model the derelict model helps you collect both relational and",
    "start": "226880",
    "end": "233360"
  },
  {
    "text": "non-relational data and in terms of the volume you can go all the way up to",
    "start": "233360",
    "end": "238760"
  },
  {
    "text": "exabytes of data right it can scale to any amount of data and one of the key",
    "start": "238760",
    "end": "243890"
  },
  {
    "text": "differences here is that this kind of model allows you to use diversified",
    "start": "243890",
    "end": "249620"
  },
  {
    "text": "analytical engines you are no longer just restricted by a data warehouse but rather you would be able to use multiple",
    "start": "249620",
    "end": "257419"
  },
  {
    "text": "analytical engines depending upon what type of workload you want to run and start making different types of analysis",
    "start": "257419",
    "end": "263630"
  },
  {
    "text": "on your data right and from a cost model this helps you to keep your cost too low",
    "start": "263630",
    "end": "269810"
  },
  {
    "text": "from a storage perspective nan Alice's perspective",
    "start": "269810",
    "end": "274150"
  },
  {
    "start": "272000",
    "end": "272000"
  },
  {
    "text": "we talk a lot about Netflix because they are one of our great partners and they",
    "start": "275360",
    "end": "281840"
  },
  {
    "text": "kind of user platform at scale right I brought this particular use case",
    "start": "281840",
    "end": "289400"
  },
  {
    "text": "specifically because I think a lot of us would relate to Netflix I'm sure a lot of us are fan of Netflix for the content",
    "start": "289400",
    "end": "297259"
  },
  {
    "text": "that they deliver to us one of the important things that I want to call out on this particular slide is what you see",
    "start": "297259",
    "end": "304460"
  },
  {
    "text": "at the bottom portion of the slide right that's their recommendation engine art",
    "start": "304460",
    "end": "310340"
  },
  {
    "text": "working and I believe personally that one of the reasons why Netflix is so popular is that their recommendation",
    "start": "310340",
    "end": "316400"
  },
  {
    "text": "engine is just awesome right they keep recommending lot of awesome content that we all love to watch and we continue to",
    "start": "316400",
    "end": "324440"
  },
  {
    "text": "basically watch their platform if you look at that particular recommendation",
    "start": "324440",
    "end": "329840"
  },
  {
    "text": "engine Netflix can no longer just rely",
    "start": "329840",
    "end": "335030"
  },
  {
    "text": "on traditional data sources like your databases which collect you know your",
    "start": "335030",
    "end": "341270"
  },
  {
    "text": "profile information and so on so forth but they have to tap into a lot of different signals in terms of what user",
    "start": "341270",
    "end": "348050"
  },
  {
    "text": "is watching are you a user who tries to binge watch a lot of things together or",
    "start": "348050",
    "end": "354770"
  },
  {
    "text": "do you tend to watch at a particular time of the day so those are the different data sources right is these",
    "start": "354770",
    "end": "360889"
  },
  {
    "text": "data is coming from different data sources like your mobile devices your your video player when do you parse",
    "start": "360889",
    "end": "368050"
  },
  {
    "text": "which which videos do you watch and so on so forth we serve different types of signals which are very very different",
    "start": "368050",
    "end": "374030"
  },
  {
    "text": "from your traditional data sources and if you're trying to innovate you got to",
    "start": "374030",
    "end": "379669"
  },
  {
    "text": "look at those different type of signals to innovate on the platform right it's",
    "start": "379669",
    "end": "385699"
  },
  {
    "start": "381000",
    "end": "381000"
  },
  {
    "text": "just not Netflix if you look at the platform we've got like tons of",
    "start": "385699",
    "end": "391280"
  },
  {
    "text": "customers who are doing very very innovative things on the analytics side of things right so this is basically a",
    "start": "391280",
    "end": "397970"
  },
  {
    "text": "limited set of customers whom we can talk about in terms of what they are doing on the analytics side of things on",
    "start": "397970",
    "end": "404419"
  },
  {
    "text": "the aeropolis platform so you see here a wide range of customer be it large start herbs - even very",
    "start": "404419",
    "end": "412460"
  },
  {
    "text": "large enterprises building their analytics workloads on the platform for example you got like very large",
    "start": "412460",
    "end": "418509"
  },
  {
    "text": "regulated enterprise customers like the FINRA's and Nasdaq's of the world - even",
    "start": "418509",
    "end": "424910"
  },
  {
    "text": "very large consumer business startups like your lyft and Yelp and Airbnb and",
    "start": "424910",
    "end": "433039"
  },
  {
    "text": "so on so forth right so all of them are doing very very innovative things on the AWS analytics platforms I specifically",
    "start": "433039",
    "end": "442039"
  },
  {
    "text": "picked up a few customer customers to talk about because I found them very interesting the first one is is Nasdaq",
    "start": "442039",
    "end": "449780"
  },
  {
    "text": "right most of us would be aware of Nasdaq so they operate multiple financial",
    "start": "449780",
    "end": "455570"
  },
  {
    "text": "exchanges across the world and they process tons of data right so all the transactions that happens on these",
    "start": "455570",
    "end": "461780"
  },
  {
    "text": "exchanges go via NASDAQ and they had an entre mais on premised data warehouse",
    "start": "461780",
    "end": "469250"
  },
  {
    "text": "appliance which they have been using for many years and they want to move to a modern data platform to analyze all",
    "start": "469250",
    "end": "476000"
  },
  {
    "start": "476000",
    "end": "476000"
  },
  {
    "text": "their data the data that have collected over many years so if I look at the",
    "start": "476000",
    "end": "481340"
  },
  {
    "text": "pipeline that they build out so what they do is they they have like a lot of",
    "start": "481340",
    "end": "486650"
  },
  {
    "text": "operational data bases which are deployed across their many exchanges they collect data from all those",
    "start": "486650",
    "end": "493669"
  },
  {
    "text": "operational databases and also from various flat files and then push all the",
    "start": "493669",
    "end": "499310"
  },
  {
    "text": "data into s3 and then they use a combination of EMR and redshift to start",
    "start": "499310",
    "end": "506000"
  },
  {
    "text": "processing all that data right if you look at the scale that they are operating at they are operating at about",
    "start": "506000",
    "end": "512390"
  },
  {
    "text": "ingesting 4.8 billion rows per trading Bay right and in just all that through",
    "start": "512390",
    "end": "518240"
  },
  {
    "text": "this pipeline and start making some analysis all of that and don't worry about these terms like EMR and redshift",
    "start": "518240",
    "end": "524630"
  },
  {
    "text": "I'm gonna demystify all of those and then help you understand what these services mean how you can leverage that",
    "start": "524630",
    "end": "530120"
  },
  {
    "text": "right the next customer that I thought I would share with you guys is data Zoo so",
    "start": "530120",
    "end": "537200"
  },
  {
    "text": "data Zoo is a is an ad tech company spun out of MA labs and they currently provide a",
    "start": "537200",
    "end": "543759"
  },
  {
    "text": "petabyte scale digital marketing platform so what they do is they they primarily deal with ads that we see",
    "start": "543759",
    "end": "551740"
  },
  {
    "text": "across the internet so they deal with billions of impressions that gets delivered to various websites on mobile",
    "start": "551740",
    "end": "558279"
  },
  {
    "text": "devices and they they typically deal with petabytes of data in their platform",
    "start": "558279",
    "end": "564190"
  },
  {
    "text": "right if you look at how they went about you know understanding which ads are working which ads are relevant which ads",
    "start": "564190",
    "end": "572079"
  },
  {
    "text": "needs to be served to end-users they they feed all those near real-time data",
    "start": "572079",
    "end": "578980"
  },
  {
    "text": "from multiple Sirian providers and real-time bidding engines and their retargeting platform into into kinases",
    "start": "578980",
    "end": "586509"
  },
  {
    "text": "which is basically a streaming ingestion service they're able use offers and then they leverage spark on EMR to perform",
    "start": "586509",
    "end": "594490"
  },
  {
    "text": "their yields and attributions and machine learning use cases and feed that",
    "start": "594490",
    "end": "600069"
  },
  {
    "text": "all that into s3 to which they connect various third-party visualizations and",
    "start": "600069",
    "end": "605649"
  },
  {
    "text": "reporting engines to start making analysis of the data",
    "start": "605649",
    "end": "610740"
  },
  {
    "text": "another customer I'm very interested in customer is 25 21st Century Fox I'm sure",
    "start": "611399",
    "end": "617019"
  },
  {
    "text": "all of us know who this customer is they're into the movie business and they",
    "start": "617019",
    "end": "624970"
  },
  {
    "text": "operate one of the largest movie studios in the world right they regularly process hundreds of terabytes of data",
    "start": "624970",
    "end": "631350"
  },
  {
    "text": "every day and in terms of the query volumes that they run on the data it it",
    "start": "631350",
    "end": "636730"
  },
  {
    "text": "goes all the way up to twenty five thousand plus twenty five thousand queries per day right so they had a",
    "start": "636730",
    "end": "641769"
  },
  {
    "text": "legacy data platform which were which was not which was not meeting these demands struggling to scale and lots of",
    "start": "641769",
    "end": "648699"
  },
  {
    "text": "performance challenges and they've moved into the AWS analytics platform and built a data Lake on top of s3 right",
    "start": "648699",
    "end": "658800"
  },
  {
    "start": "655000",
    "end": "655000"
  },
  {
    "text": "again if you look at their pipeline they they use honor for partner tools",
    "start": "658800",
    "end": "664449"
  },
  {
    "text": "informatica to collect data from various data sources and feed all the data into",
    "start": "664449",
    "end": "669569"
  },
  {
    "text": "s3 that's where they have built their their data Lake and then they use Arab you exclu which",
    "start": "669569",
    "end": "676589"
  },
  {
    "text": "I'm going to talk about in a while to catalog all the information and run et Al's on top of the data and feed the",
    "start": "676589",
    "end": "684120"
  },
  {
    "text": "data into red ship and EMR and use MicroStrategy to start making",
    "start": "684120",
    "end": "690230"
  },
  {
    "text": "visualizations and insights out of that data right so those are the three use case that I",
    "start": "690230",
    "end": "697589"
  },
  {
    "text": "thought I'll I'll call out but if you go to our Big Data website you will see a",
    "start": "697589",
    "end": "702600"
  },
  {
    "text": "number of such different customers doing different interesting use cases on the AWS platform right so one common pattern",
    "start": "702600",
    "end": "709470"
  },
  {
    "text": "that you would see is that largest customers built data Lake on top of s3",
    "start": "709470",
    "end": "715440"
  },
  {
    "text": "and they used a combination of services like redshift and EMR and glue and",
    "start": "715440",
    "end": "722010"
  },
  {
    "text": "kinases to start making their decisions right so so what are the one of the",
    "start": "722010",
    "end": "728820"
  },
  {
    "start": "723000",
    "end": "723000"
  },
  {
    "text": "characteristics of a radar Lake so why did these customers build out using a combination of these different services",
    "start": "728820",
    "end": "734580"
  },
  {
    "text": "right so if I look at a data Lake and call out some specific characteristics I",
    "start": "734580",
    "end": "741450"
  },
  {
    "text": "would probably call out for important characteristics of a gator Lake the",
    "start": "741450",
    "end": "747329"
  },
  {
    "text": "first thing is obviously collect anything and everything right so your derelict should be capable of collecting",
    "start": "747329",
    "end": "753329"
  },
  {
    "text": "data from various data sources so some could be real time data sources Sun",
    "start": "753329",
    "end": "759270"
  },
  {
    "text": "could be badger sources the Sun could be your data bases some could be your IOT devices so your data layer should be",
    "start": "759270",
    "end": "765779"
  },
  {
    "text": "capable of collecting data from all these different types of data sources and durably store them and make it",
    "start": "765779",
    "end": "772680"
  },
  {
    "text": "available for analysis and once you are able to collect the data you should be",
    "start": "772680",
    "end": "779070"
  },
  {
    "text": "able to dive in anywhere into that data Lake right so what I mean by diving in",
    "start": "779070",
    "end": "784649"
  },
  {
    "text": "anywhere is that some use cases needs you to look at just aggregated data sets",
    "start": "784649",
    "end": "791040"
  },
  {
    "text": "at a very high level and some use cases would require you to dive very deep and look at data in much more granular level",
    "start": "791040",
    "end": "799520"
  },
  {
    "text": "for example your machine learning type of use cases requires you to operate at the raw data level to build your machine",
    "start": "799520",
    "end": "806270"
  },
  {
    "text": "models right so your data like that your building should be allowing these different types of use cases to dive in",
    "start": "806270",
    "end": "813080"
  },
  {
    "text": "at whatever granularity that they would like to dive in the third",
    "start": "813080",
    "end": "818840"
  },
  {
    "text": "characteristics is flexible access mechanisms because you're going to dive in at different granularity you would",
    "start": "818840",
    "end": "825830"
  },
  {
    "text": "probably end up using different combination of two pools so you would need flexible access mechanisms that",
    "start": "825830",
    "end": "832790"
  },
  {
    "text": "allows different people to use different tools to start looking at the data and",
    "start": "832790",
    "end": "839290"
  },
  {
    "text": "lastly being future-proof right so when you start building out your data leak not all the use cases are are visible",
    "start": "839290",
    "end": "847820"
  },
  {
    "text": "when you're building your when you're starting to build your data leak right you would probably know a few use cases that your business currently wants and",
    "start": "847820",
    "end": "854450"
  },
  {
    "text": "you would go and build out but the moment you open up your data leak to your business they would start coming",
    "start": "854450",
    "end": "859670"
  },
  {
    "text": "back coming back to you saying that here is a new use case that I want to go and do it right so your daily layers should",
    "start": "859670",
    "end": "864680"
  },
  {
    "text": "be flexible enough to be ready for the future where when new use cases evolved you should be able to readily evolve",
    "start": "864680",
    "end": "872870"
  },
  {
    "text": "your data like as well to meet those new use cases all right so what we will do over the next 30 minutes or so is to",
    "start": "872870",
    "end": "880040"
  },
  {
    "text": "look at each one of those characteristics and how you can address every such characteristic by building",
    "start": "880040",
    "end": "886370"
  },
  {
    "text": "out a data Lake on the AWS platform so let's jump into the first characteristic which is the collect anything aspect",
    "start": "886370",
    "end": "893270"
  },
  {
    "text": "right so I look at the collect anything aspect we see an increasing pattern",
    "start": "893270",
    "end": "899090"
  },
  {
    "text": "where Amazon s3 is becoming the underpinning service for building your",
    "start": "899090",
    "end": "904820"
  },
  {
    "text": "data Lake on the a SS platform right I'm I'm finally confident that most of",
    "start": "904820",
    "end": "909920"
  },
  {
    "text": "you know what Amazon s3 is if you're not aware Amazon s3 is a simple storage",
    "start": "909920",
    "end": "915920"
  },
  {
    "text": "service which is our story its service this service is one of her earlier services it's been operating for the",
    "start": "915920",
    "end": "922550"
  },
  {
    "text": "last 11 plus years right and it's primarily an object store in which you",
    "start": "922550",
    "end": "928670"
  },
  {
    "start": "928000",
    "end": "928000"
  },
  {
    "text": "can go and store any kind of binary object right s3 from a storage perspective is built",
    "start": "928670",
    "end": "936110"
  },
  {
    "text": "for any scale right over the eleven plus years of operations",
    "start": "936110",
    "end": "941830"
  },
  {
    "text": "customers have used s3 to store all types of data and if I look at the service today it currently stores",
    "start": "941830",
    "end": "948700"
  },
  {
    "text": "trillions of objects exabytes of data and regularly peaks at more than a",
    "start": "948700",
    "end": "955339"
  },
  {
    "text": "million requests per second right that's a scale at which s3 operates today it is",
    "start": "955339",
    "end": "961459"
  },
  {
    "text": "built to store any amount of data right so as a customer you can go to the",
    "start": "961459",
    "end": "967040"
  },
  {
    "text": "service and start very small you can start with let's say an empty bucket which doesn't contain anything and",
    "start": "967040",
    "end": "973329"
  },
  {
    "text": "seamlessly scale to terabytes and petabytes and exabytes of data on that particular service right it is",
    "start": "973329",
    "end": "979490"
  },
  {
    "text": "continuously scale depending upon your requirement the other thing is s3 allows",
    "start": "979490",
    "end": "986450"
  },
  {
    "text": "you to connect multiple analytical engines and I will talk about that going",
    "start": "986450",
    "end": "992480"
  },
  {
    "text": "down the slides where you can connect multiple analytical engines to s3 and start processing the data right",
    "start": "992480",
    "end": "999980"
  },
  {
    "text": "s3 allows you to operate in a highly decoupled compute and storage",
    "start": "999980",
    "end": "1005649"
  },
  {
    "start": "1005000",
    "end": "1005000"
  },
  {
    "text": "architecture right so we covered the",
    "start": "1005649",
    "end": "1010839"
  },
  {
    "text": "scale aspect right and one of the other important things from a data perspective is the durability aspect right so it's",
    "start": "1010839",
    "end": "1018130"
  },
  {
    "text": "not good enough if you are just able to ingest data and collect data it's also",
    "start": "1018130",
    "end": "1023529"
  },
  {
    "text": "important that you are able to durably store it make sure that data is always available for your analysis right so s3",
    "start": "1023529",
    "end": "1030970"
  },
  {
    "text": "is designed for eleven nines of durability right that's nineteen nine",
    "start": "1030970",
    "end": "1036550"
  },
  {
    "text": "dot so many nines after that right so that provides an extreme amount of",
    "start": "1036550",
    "end": "1042730"
  },
  {
    "text": "durability for your data so that you can be confident that your data is durably stored on the service right an s3 as a",
    "start": "1042730",
    "end": "1050500"
  },
  {
    "text": "service is multi AC by default right so when you create your bucket and store",
    "start": "1050500",
    "end": "1057790"
  },
  {
    "text": "your object within the bucket it is distributed it is distributed across multiple availability zones in a single",
    "start": "1057790",
    "end": "1064870"
  },
  {
    "text": "region by default right so just to give a bit of context about availability zone itself each availability zone in turn is",
    "start": "1064870",
    "end": "1073330"
  },
  {
    "text": "more data centers right so if I for example take Mumbai as an example there",
    "start": "1073330",
    "end": "1078789"
  },
  {
    "text": "are multiple availability zones within Mumbai and each availability zone in turn is one or more data centers right",
    "start": "1078789",
    "end": "1085899"
  },
  {
    "text": "so when you store your data in s3 its replicated across those multiple data centers and multiple availability zones",
    "start": "1085899",
    "end": "1092380"
  },
  {
    "text": "within Mumbai right all that happens automatically behind the scenes without you worrying about all the heavy lifting",
    "start": "1092380",
    "end": "1098620"
  },
  {
    "start": "1096000",
    "end": "1096000"
  },
  {
    "text": "right s3 also offers you multiple storage",
    "start": "1098620",
    "end": "1104890"
  },
  {
    "text": "tiers which you can use to optimize your price and performances right so by we",
    "start": "1104890",
    "end": "1110080"
  },
  {
    "text": "fault the storage class this s3 standard which offers you that livonians the durability for your data but in addition",
    "start": "1110080",
    "end": "1118299"
  },
  {
    "text": "you also got other storage classes like s3 standard infrequent axis f3 one zone",
    "start": "1118299",
    "end": "1125139"
  },
  {
    "text": "infrequent axis and Amazon glacier which is for your cold storage right now why",
    "start": "1125139",
    "end": "1130809"
  },
  {
    "text": "is this important from an analytics perspective so all of us would agree that data typically arrives hot and data",
    "start": "1130809",
    "end": "1138309"
  },
  {
    "text": "starts aging after a point of time right so you probably have hard data living",
    "start": "1138309",
    "end": "1143559"
  },
  {
    "text": "for about a month and after a month that data starts becoming slightly warm and then after let's say a few months down",
    "start": "1143559",
    "end": "1149980"
  },
  {
    "text": "the line it starts becoming cold right and you are no longer actively analyzing that data so what you could do with s3",
    "start": "1149980",
    "end": "1156850"
  },
  {
    "text": "is that a bucket level you can start setting up what is called as his life cycle policy so you could say that keep",
    "start": "1156850",
    "end": "1164080"
  },
  {
    "text": "data in s3 standard for a month after a month move it to s3 infrequent axis and",
    "start": "1164080",
    "end": "1170519"
  },
  {
    "text": "after three months move it to glacier and after a year delete that data right",
    "start": "1170519",
    "end": "1177220"
  },
  {
    "text": "it's a one-time configuration that you do at a bucket level and the service automatically takes care of",
    "start": "1177220",
    "end": "1182470"
  },
  {
    "text": "transitioning the data across these different storage classes what you benefit is that these different storage",
    "start": "1182470",
    "end": "1189159"
  },
  {
    "text": "classes are priced at different price points because they offer different levels of durability and availability",
    "start": "1189159",
    "end": "1195010"
  },
  {
    "text": "and you can automatically enjoy costly things by moving data across these different data storage classes right and",
    "start": "1195010",
    "end": "1203490"
  },
  {
    "start": "1199000",
    "end": "1199000"
  },
  {
    "text": "lastly one of the important things from again analytics perspective is that",
    "start": "1203490",
    "end": "1208919"
  },
  {
    "text": "making sure your data is kept in open data formats right because s3 is an",
    "start": "1208919",
    "end": "1215470"
  },
  {
    "text": "object store it doesn't really dictate any specific formats in which you have to store your data you could store any",
    "start": "1215470",
    "end": "1221950"
  },
  {
    "text": "kind of binary objects in s3 and from an analytics perspective it's important that you are keeping data in an open",
    "start": "1221950",
    "end": "1229389"
  },
  {
    "text": "data format formats like your CSV ease and JSON or even analytics optimized",
    "start": "1229389",
    "end": "1236590"
  },
  {
    "text": "formats like your park' and Orsi and have room so that you are able to use a",
    "start": "1236590",
    "end": "1241990"
  },
  {
    "text": "diverse set of analytical engines which which operate on open data formats and",
    "start": "1241990",
    "end": "1248110"
  },
  {
    "text": "you can keep your data in open data formats right so that's also important",
    "start": "1248110",
    "end": "1253270"
  },
  {
    "text": "from an analytics perspective so Esley allows it to keep data in that open data format and you can use a combination of",
    "start": "1253270",
    "end": "1259059"
  },
  {
    "text": "different engines like your Hadoop engines like your presto and spark and",
    "start": "1259059",
    "end": "1264700"
  },
  {
    "text": "readily query that data that is available on s3 awesome so we we saw",
    "start": "1264700",
    "end": "1271059"
  },
  {
    "text": "about how s3 can be leveraged as the underlying storage for your data like story so what we will do now is over the",
    "start": "1271059",
    "end": "1278169"
  },
  {
    "text": "next 30 minutes we will start putting together the pieces that forms your overall data like architecture right so",
    "start": "1278169",
    "end": "1285510"
  },
  {
    "text": "imagine this this universe where you are going to have multiple components of your data link and s3 kind of sits at",
    "start": "1285510",
    "end": "1293080"
  },
  {
    "text": "the center where it it acts as your centralized storage for storing all your",
    "start": "1293080",
    "end": "1298960"
  },
  {
    "text": "data right so we will come back to this particular architecture diagram and",
    "start": "1298960",
    "end": "1304149"
  },
  {
    "text": "start putting together other pieces in this architecture diagram fine ok so we looked at s3 which forms",
    "start": "1304149",
    "end": "1313629"
  },
  {
    "start": "1306000",
    "end": "1306000"
  },
  {
    "text": "as your centralized storage now how do you collect your data and feed all the",
    "start": "1313629",
    "end": "1319450"
  },
  {
    "text": "data into your s3 derelict when you've got lots of options here depending upon",
    "start": "1319450",
    "end": "1324610"
  },
  {
    "text": "from where you are ingesting your data right you've got lots of options to",
    "start": "1324610",
    "end": "1329710"
  },
  {
    "text": "ingest from on-premise data centers so for example if you are if you're looking",
    "start": "1329710",
    "end": "1335409"
  },
  {
    "text": "for connectivity there are Russians like Direct Connect which allows you to establish dedicated",
    "start": "1335409",
    "end": "1341739"
  },
  {
    "text": "network from on-premise data centers to AWS right if you're looking at migrating",
    "start": "1341739",
    "end": "1348399"
  },
  {
    "text": "data from on to visitor centers to the a tablets platform there are tons of options there as well right where you",
    "start": "1348399",
    "end": "1354279"
  },
  {
    "text": "can order now appliance called as snowball which is actually a physical appliance it comes with 8200 terabytes",
    "start": "1354279",
    "end": "1362109"
  },
  {
    "text": "of data storage on that you can out of the appliance we will ship it to your data center you connect your data center",
    "start": "1362109",
    "end": "1368139"
  },
  {
    "text": "you start copying all the data into the appliance and you ship it back to our",
    "start": "1368139",
    "end": "1373739"
  },
  {
    "text": "our data centers we copy all the data into s3 and make it available for your",
    "start": "1373739",
    "end": "1378909"
  },
  {
    "text": "analysis right we also have a service called as the database migration service",
    "start": "1378909",
    "end": "1384190"
  },
  {
    "text": "which allows you to connect to any on through- databases and start migrating",
    "start": "1384190",
    "end": "1391029"
  },
  {
    "text": "the data into AWS databases right so you could use that for example connect to",
    "start": "1391029",
    "end": "1396399"
  },
  {
    "text": "your OLTP systems and continuously replicate the data into databases and",
    "start": "1396399",
    "end": "1402489"
  },
  {
    "text": "data stores on the aeropolis platform in addition we also have got multiple",
    "start": "1402489",
    "end": "1407769"
  },
  {
    "text": "options to ingest data from real time data sources all right so here is a",
    "start": "1407769",
    "end": "1415089"
  },
  {
    "text": "snapshot of all that options for moving data from data centers we spoke about Direct Connect allowing you to establish",
    "start": "1415089",
    "end": "1422159"
  },
  {
    "text": "dedicated network connection you spoke about snowball to order an appliance to",
    "start": "1422159",
    "end": "1428469"
  },
  {
    "text": "ingest data from a compromised data centers to AWS and database migration service from a real-time sources",
    "start": "1428469",
    "end": "1436690"
  },
  {
    "start": "1431000",
    "end": "1431000"
  },
  {
    "text": "perspective again there are multiple options for you depending upon which are your data sources if you have got a lot",
    "start": "1436690",
    "end": "1443289"
  },
  {
    "text": "of IOT devices like your sensors in your factories we have got a platform AWS IOT",
    "start": "1443289",
    "end": "1449739"
  },
  {
    "text": "core which allows you to seemingly seamlessly connect all your IOT devices",
    "start": "1449739",
    "end": "1455190"
  },
  {
    "text": "over both MQTT and HTTP protocols and starting justing data from IOT devices",
    "start": "1455190",
    "end": "1461049"
  },
  {
    "text": "into this platform right if you're looking at ingesting data from mobile",
    "start": "1461049",
    "end": "1466839"
  },
  {
    "text": "devices and server logs and so on and so forth the kinases platform allows you to ingest",
    "start": "1466839",
    "end": "1473450"
  },
  {
    "text": "data from those different data sources right let's let's spend a little bit",
    "start": "1473450",
    "end": "1480679"
  },
  {
    "start": "1474000",
    "end": "1474000"
  },
  {
    "text": "more time on at the kinases platform which is which allows you to ingest data",
    "start": "1480679",
    "end": "1485900"
  },
  {
    "text": "from data sources like a mobile device sirs on your websites and servers and so",
    "start": "1485900",
    "end": "1491450"
  },
  {
    "text": "on so forth and start processing the data in near real-time right the first",
    "start": "1491450",
    "end": "1496730"
  },
  {
    "text": "service that we offer is kinases data streams so using kinases data streams what you",
    "start": "1496730",
    "end": "1502820"
  },
  {
    "text": "could do is you could go to the service and spin up a fully managed streaming",
    "start": "1502820",
    "end": "1509840"
  },
  {
    "text": "ingestion service and connect all your streaming sources for example your",
    "start": "1509840",
    "end": "1515330"
  },
  {
    "text": "mobile devices and your servers and start ingesting all the data in two",
    "start": "1515330",
    "end": "1522169"
  },
  {
    "text": "kinases right what Kinesis does be in the scenes is that it automatically",
    "start": "1522169",
    "end": "1527710"
  },
  {
    "text": "deploys infrastructure behind the scenes and deploys it infrastructure across",
    "start": "1527710",
    "end": "1533120"
  },
  {
    "text": "multiple availability zones and starts collecting all the data in",
    "start": "1533120",
    "end": "1538190"
  },
  {
    "text": "near-real-time and durably stores the data and allows multiple downstream",
    "start": "1538190",
    "end": "1545870"
  },
  {
    "text": "applications to connect to the service and start processing the data again in",
    "start": "1545870",
    "end": "1551570"
  },
  {
    "text": "near real-time right so for example you could connect your mobile devices and",
    "start": "1551570",
    "end": "1557120"
  },
  {
    "text": "start sending data in near real time into kinases and on the other side you",
    "start": "1557120",
    "end": "1563299"
  },
  {
    "text": "could spin up let's say a spark cluster or let's say a flink cluster on EMR and",
    "start": "1563299",
    "end": "1569840"
  },
  {
    "text": "start processing all the data in near real time so that's for your near real",
    "start": "1569840",
    "end": "1578720"
  },
  {
    "start": "1572000",
    "end": "1572000"
  },
  {
    "text": "time use cases right the platform also offers a service called as kinases data",
    "start": "1578720",
    "end": "1584419"
  },
  {
    "text": "firehouse which allows again data to be ingested from various data sources and",
    "start": "1584419",
    "end": "1592870"
  },
  {
    "text": "the service automatically lands the data into specific destinations right",
    "start": "1592870",
    "end": "1599890"
  },
  {
    "text": "why Kinesis gator streams allows you to connect any custom application and start processing the data in near real time",
    "start": "1599890",
    "end": "1605920"
  },
  {
    "text": "what firehose allows you to do is to ingest data into fire hose and fire hose",
    "start": "1605920",
    "end": "1612430"
  },
  {
    "text": "will automatically deliver the data into those four destination that you see on the right hand side right so from an",
    "start": "1612430",
    "end": "1619360"
  },
  {
    "text": "engines perspective we give you the given agent that you can deploy on on",
    "start": "1619360",
    "end": "1625450"
  },
  {
    "text": "any server or mobile devices or you could also hook up fire hose to your kinases streams if you already are",
    "start": "1625450",
    "end": "1631750"
  },
  {
    "text": "ingesting two Kinesis streams or if you are collecting data into let's say cloud wash logs or code watch events or our ot",
    "start": "1631750",
    "end": "1638320"
  },
  {
    "text": "platform you could connect all of those into kinases fire hose and fire hose",
    "start": "1638320",
    "end": "1644230"
  },
  {
    "text": "will take all the data and then fire hose will land the data into those four",
    "start": "1644230",
    "end": "1651300"
  },
  {
    "text": "destinations which are s3 Amazon redshift I'm as an elastic search service and",
    "start": "1651300",
    "end": "1656890"
  },
  {
    "text": "Splunk end-to-end fully managed without you managing any infrastructure in",
    "start": "1656890",
    "end": "1663940"
  },
  {
    "text": "addition to delivering to those destinations if you would want to perform any transformations before data",
    "start": "1663940",
    "end": "1670510"
  },
  {
    "text": "getting delivered into the destinations fire hose provides lambda integrations where you could have a lambda function",
    "start": "1670510",
    "end": "1676900"
  },
  {
    "text": "the function can have your own logic to basically let's say duper do some",
    "start": "1676900",
    "end": "1682750"
  },
  {
    "text": "cleansing or perform some transformations and then fire hose will deliver the data after those",
    "start": "1682750",
    "end": "1688990"
  },
  {
    "text": "transformations happen into those four destinations right so fire hose will be the quickest and easiest way to collect",
    "start": "1688990",
    "end": "1697050"
  },
  {
    "text": "real-time data and deliver into those four destinations the third service that",
    "start": "1697050",
    "end": "1706180"
  },
  {
    "start": "1700000",
    "end": "1700000"
  },
  {
    "text": "is available within the kinases platform is kinases data analytics where the",
    "start": "1706180",
    "end": "1713470"
  },
  {
    "text": "service allows you to run standard sequel queries against streaming data",
    "start": "1713470",
    "end": "1720120"
  },
  {
    "text": "right so for example if you're sending streaming data into either kinases data",
    "start": "1720120",
    "end": "1725500"
  },
  {
    "text": "streams or kinases data firehose you could go to kinases data analytics",
    "start": "1725500",
    "end": "1730690"
  },
  {
    "text": "and say I have got my data being sent in two streams or firehose here is my",
    "start": "1730690",
    "end": "1737090"
  },
  {
    "text": "sequel run this streaming speak wall against the data and give me the output",
    "start": "1737090",
    "end": "1744289"
  },
  {
    "text": "of the data right so you could for example go to the service and say define",
    "start": "1744289",
    "end": "1751970"
  },
  {
    "text": "a sequel which has let's say select sum of sales on the streaming data and",
    "start": "1751970",
    "end": "1761169"
  },
  {
    "text": "calculated some on a window of one minute right so if you are streaming all",
    "start": "1761169",
    "end": "1766460"
  },
  {
    "text": "your orders through kinases streams or firehorse then this particular query",
    "start": "1766460",
    "end": "1773059"
  },
  {
    "text": "would run on the streaming data and continuously calculate sum of orders or",
    "start": "1773059",
    "end": "1779510"
  },
  {
    "text": "sum of sales and then send the data into your new real-time dashboards right so",
    "start": "1779510",
    "end": "1785000"
  },
  {
    "text": "if you are let's say more familiar with sequel and you don't want to let's say",
    "start": "1785000",
    "end": "1790220"
  },
  {
    "text": "you run write your own custom applications to process new real-time data Kinesis data analytics allows you",
    "start": "1790220",
    "end": "1796070"
  },
  {
    "text": "to give those sequel queries and run that against your streaming data and",
    "start": "1796070",
    "end": "1801230"
  },
  {
    "text": "start processing the data right so all these services fit under the near",
    "start": "1801230",
    "end": "1806840"
  },
  {
    "text": "real-time our real-time space where you could use these services to ingest data",
    "start": "1806840",
    "end": "1813500"
  },
  {
    "text": "in your real time and process the data in near real time right so if I go back",
    "start": "1813500",
    "end": "1820700"
  },
  {
    "text": "to that diagram so s3 nicely sits into that sits of the center as a centralized",
    "start": "1820700",
    "end": "1825919"
  },
  {
    "text": "storage and now you have got various ingestion options to ingest data you can",
    "start": "1825919",
    "end": "1832010"
  },
  {
    "text": "use kinases for your near real-time streaming data you could use Direct",
    "start": "1832010",
    "end": "1837380"
  },
  {
    "text": "Connect for your connectivity and snowball and DMS for replicating your",
    "start": "1837380",
    "end": "1843169"
  },
  {
    "text": "data or migrating data from data centers to s3 right so multiple choices there depending upon your use cases so we",
    "start": "1843169",
    "end": "1851690"
  },
  {
    "text": "looked at the collect anything aspect now let's move to the next character 6 which is the dive in anywhere so how can",
    "start": "1851690",
    "end": "1857990"
  },
  {
    "text": "you dive in at any granularity and start making sense of your data so one of the",
    "start": "1857990",
    "end": "1865560"
  },
  {
    "start": "1860000",
    "end": "1860000"
  },
  {
    "text": "born challenges today is that most customers think about Darrell acres just collecting data and durably storing it",
    "start": "1865560",
    "end": "1873240"
  },
  {
    "text": "in a central location right using something like s3 but what they tend to forget is what is called that this dark",
    "start": "1873240",
    "end": "1880740"
  },
  {
    "text": "data right so while you're collecting lot of data how do you make sure that everyone in your organization has",
    "start": "1880740",
    "end": "1887610"
  },
  {
    "text": "visibility into what data lives in your data Lake right how do you make sure that they are able to discover what",
    "start": "1887610",
    "end": "1894630"
  },
  {
    "text": "lives in your data Lake and start making analysis or of your data right that's",
    "start": "1894630",
    "end": "1901230"
  },
  {
    "start": "1896000",
    "end": "1896000"
  },
  {
    "text": "where AWS glue comes in the picture where area bluest glue provides a centralized data catalog which allows",
    "start": "1901230",
    "end": "1909360"
  },
  {
    "text": "you to discover data and make it available for people to perform analysis",
    "start": "1909360",
    "end": "1916130"
  },
  {
    "text": "so one of the things that glue allows you to do is glue allows you to crawl various data sources so glue has got",
    "start": "1916130",
    "end": "1923220"
  },
  {
    "text": "built-in crawlers which can crawl various data sources including Amazon s3 and databases that either run on through",
    "start": "1923220",
    "end": "1931020"
  },
  {
    "text": "- are on AWS and automatically extract schema and make it available in a",
    "start": "1931020",
    "end": "1938430"
  },
  {
    "text": "centralized location within the glue catalog now the catalog maintains schema",
    "start": "1938430",
    "end": "1943860"
  },
  {
    "text": "definitions which can further be leveraged by other AWS services like",
    "start": "1943860",
    "end": "1949950"
  },
  {
    "text": "your Amazon EMR Athena and redshift all of them can centrally connect to that",
    "start": "1949950",
    "end": "1956670"
  },
  {
    "text": "glute data catalog and infer the schema the important thing to note here is that",
    "start": "1956670",
    "end": "1962070"
  },
  {
    "text": "the glue data catalog is a hive compatible catalog right so the",
    "start": "1962070",
    "end": "1968190"
  },
  {
    "text": "underlying catalog is is a hive compatible matter store which means that any processing engine which can",
    "start": "1968190",
    "end": "1974340"
  },
  {
    "text": "understand hive as the meta store can readily connect to glue so for example",
    "start": "1974340",
    "end": "1980970"
  },
  {
    "text": "if you are running a spa or cluster or a priest or cluster which can readily connect to hive they can automatically",
    "start": "1980970",
    "end": "1986460"
  },
  {
    "text": "connect to glue data card catalog and start processing the data in this model",
    "start": "1986460",
    "end": "1991830"
  },
  {
    "text": "you operate in a highly decoupled storage compute and catalog fashion",
    "start": "1991830",
    "end": "1997050"
  },
  {
    "text": "where Esteli becomes your centralized storage which is decoupled from your catalog the",
    "start": "1997050",
    "end": "2003500"
  },
  {
    "text": "glue bit becomes your central catalog and then now you can use various",
    "start": "2003500",
    "end": "2008660"
  },
  {
    "text": "computer engines that can go to the glue catalog infer the catalog and go back to",
    "start": "2008660",
    "end": "2015020"
  },
  {
    "start": "2014000",
    "end": "2014000"
  },
  {
    "text": "s3 and start processing the data in addition to offering the catalog glue",
    "start": "2015020",
    "end": "2021170"
  },
  {
    "text": "also offers an ETL service where you could go to the service and start let's",
    "start": "2021170",
    "end": "2028100"
  },
  {
    "text": "say defining your utl pipelines you could say here is my source and here is my destination and say that you want to",
    "start": "2028100",
    "end": "2036590"
  },
  {
    "text": "perform this kind of a transformation so glue will automatically generate the ETL script which you can further customize",
    "start": "2036590",
    "end": "2043340"
  },
  {
    "text": "because it generates Python script and there is a in browser editor to which",
    "start": "2043340",
    "end": "2050960"
  },
  {
    "text": "you can go and edit the Python script that glue generates for you and then once you're good enough with your script",
    "start": "2050960",
    "end": "2057169"
  },
  {
    "text": "you can save the script within glue and ask glue to run but script as a job you",
    "start": "2057169",
    "end": "2064490"
  },
  {
    "text": "can define that has to be a job that runs in no particular frequency at a particular point in time of the day and",
    "start": "2064490",
    "end": "2070908"
  },
  {
    "text": "then glue make sure that the job runs at that particular point in time and glue",
    "start": "2070909",
    "end": "2078800"
  },
  {
    "text": "automatically maintains the infrastructure for the job it automatically runs the job on an",
    "start": "2078800",
    "end": "2084560"
  },
  {
    "text": "infrastructure that is fully managed by glue and you are only charged for the",
    "start": "2084560",
    "end": "2090679"
  },
  {
    "text": "duration of your job if your job for example runs for 20 minutes during the day you're only charged for those 20",
    "start": "2090679",
    "end": "2097610"
  },
  {
    "text": "minutes of your job run right so absolutely no infrastructure to manage",
    "start": "2097610",
    "end": "2103270"
  },
  {
    "text": "everything is managed by a glue and you only pay for how much you use from an",
    "start": "2103270",
    "end": "2108920"
  },
  {
    "text": "infrastructure perspective so again going back to the particular diagram so",
    "start": "2108920",
    "end": "2114140"
  },
  {
    "text": "you got ingestion you've got a central storage now you've got the the third aspect which is the catalog so blue",
    "start": "2114140",
    "end": "2120470"
  },
  {
    "text": "becomes your catalog which is your metadata about your data and lives",
    "start": "2120470",
    "end": "2125750"
  },
  {
    "text": "outside of your storage lives independent of your storage and allows any processing engine to",
    "start": "2125750",
    "end": "2131510"
  },
  {
    "text": "to your catalogue right in addition if you want to let's say enrich that so what customers also do is stream that",
    "start": "2131510",
    "end": "2140030"
  },
  {
    "text": "catalog information to an Oracle database or Amazon Elastic search which makes it makes it good enough for search",
    "start": "2140030",
    "end": "2149900"
  },
  {
    "text": "right so people can go to let's say an elastic search and readily search your catalogue as well right and discover",
    "start": "2149900",
    "end": "2156650"
  },
  {
    "text": "what losing your data Lake so we looked at the character netting aspect we",
    "start": "2156650",
    "end": "2163430"
  },
  {
    "text": "looked at the dive anywhere aspect and then the third characteristics is the flexible axis mechanism right so before",
    "start": "2163430",
    "end": "2170690"
  },
  {
    "start": "2166000",
    "end": "2166000"
  },
  {
    "text": "I dive into the flexible axis mechanisms I want to talk a little bit about this particular aspect of expanding access",
    "start": "2170690",
    "end": "2176840"
  },
  {
    "text": "requirements right so gone are the days where people who are typically their",
    "start": "2176840",
    "end": "2182900"
  },
  {
    "text": "business users so they only tend to make those decisions but rather you got like different personas coming in opinion",
    "start": "2182900",
    "end": "2189530"
  },
  {
    "text": "organization right while business users are still making a lot of decisions through let's say dashboards you also",
    "start": "2189530",
    "end": "2195920"
  },
  {
    "text": "have folks like data analyst and data scientist who have different",
    "start": "2195920",
    "end": "2201050"
  },
  {
    "text": "requirements and want to access the same data right so lots and lots of different",
    "start": "2201050",
    "end": "2206860"
  },
  {
    "text": "personas who want to access the same data but they want to access using",
    "start": "2206860",
    "end": "2212690"
  },
  {
    "text": "different tools because for example a business user would like to go to a dashboard which is more of a user",
    "start": "2212690",
    "end": "2219080"
  },
  {
    "text": "interface and start slicing and dicing the data but data analysts would probably want to run sequel queries",
    "start": "2219080",
    "end": "2226310"
  },
  {
    "text": "against data a data an estate a scientist on the other hand probably",
    "start": "2226310",
    "end": "2231800"
  },
  {
    "text": "wants to leverage Python and start analyzing the data right so they would want different tools different engines",
    "start": "2231800",
    "end": "2239720"
  },
  {
    "text": "to look at the data and the other aspect is they would want to again look at the",
    "start": "2239720",
    "end": "2244790"
  },
  {
    "text": "data at different granularity the business user is probably looking at aggregated data set but a data scientist",
    "start": "2244790",
    "end": "2251030"
  },
  {
    "text": "on the other hand there's diving very deep and trying to build the machine learning models and so on so forth",
    "start": "2251030",
    "end": "2256430"
  },
  {
    "text": "right so that's where a lot of business operate today and your data leak should",
    "start": "2256430",
    "end": "2261650"
  },
  {
    "text": "be able to cater to all these different types of folks in organization so before I jump into that",
    "start": "2261650",
    "end": "2268740"
  },
  {
    "text": "I want to set a little bit of more context in terms of the services right so a terribly was we are not going to",
    "start": "2268740",
    "end": "2276420"
  },
  {
    "text": "give you a single purpose tool which does I cater to all those different people so we will not give you like a",
    "start": "2276420",
    "end": "2283260"
  },
  {
    "text": "Swiss Army knife which will give you all sort of capabilities but we are going to give you purpose-built tools which work",
    "start": "2283260",
    "end": "2291840"
  },
  {
    "text": "great for a specific use case right so if that particular data analyst needs a",
    "start": "2291840",
    "end": "2296910"
  },
  {
    "text": "sequel engine we're going to give you a sequel engine which is specifically built for those use cases right so",
    "start": "2296910",
    "end": "2303450"
  },
  {
    "text": "that's the kind of approach that we would love to take and we you would say that we're going to give you multiple",
    "start": "2303450",
    "end": "2309180"
  },
  {
    "start": "2308000",
    "end": "2308000"
  },
  {
    "text": "options to dole to do those different use cases the first service here is",
    "start": "2309180",
    "end": "2316080"
  },
  {
    "text": "Amazon redshift which is fully managed data warehousing as a service right so",
    "start": "2316080",
    "end": "2321690"
  },
  {
    "text": "you could go to Amazon redshift and spin up a large data warehouse in a matter of",
    "start": "2321690",
    "end": "2327900"
  },
  {
    "text": "minutes which is fully managed by AWS even after manage the underlying infrastructure and comes at typically",
    "start": "2327900",
    "end": "2334350"
  },
  {
    "text": "one tenth of the cost of traditional data warehouse Amazon redshift is a",
    "start": "2334350",
    "end": "2339540"
  },
  {
    "text": "massively parallel processing engine where begin the service you have got",
    "start": "2339540",
    "end": "2345450"
  },
  {
    "text": "multiple compute nodes which can operate in parallel and operate against your",
    "start": "2345450",
    "end": "2352290"
  },
  {
    "text": "data when you submit your queries to the service it it computes the query",
    "start": "2352290",
    "end": "2358500"
  },
  {
    "text": "execution plan and sends it down to multiple compute nodes in the cluster and all of them in parallel operate",
    "start": "2358500",
    "end": "2365940"
  },
  {
    "text": "across your data you can seamlessly scale from few gigabytes to all the way",
    "start": "2365940",
    "end": "2371370"
  },
  {
    "text": "to petabytes of data in the cluster right underneath the data that is stored",
    "start": "2371370",
    "end": "2377520"
  },
  {
    "text": "in redshift is stored in a columnar format which is most suitable for analytical type of workloads and helps",
    "start": "2377520",
    "end": "2384630"
  },
  {
    "text": "us reduce the amount of i/o that you have to do you could also store data in",
    "start": "2384630",
    "end": "2391470"
  },
  {
    "text": "open data formats in s3 and use a feature called a spectrum which I'll",
    "start": "2391470",
    "end": "2396840"
  },
  {
    "text": "talk about in a minute too analyze data in open data formats you",
    "start": "2396840",
    "end": "2401880"
  },
  {
    "text": "could deploy a service in a secured manner you could deploy a service within",
    "start": "2401880",
    "end": "2406920"
  },
  {
    "text": "your virtual private cloud within the AWS cloud and you could encrypt data in",
    "start": "2406920",
    "end": "2413850"
  },
  {
    "text": "transit and address the service is also compliant for all popular compliance",
    "start": "2413850",
    "end": "2419010"
  },
  {
    "text": "requirements like your PCI DSS HIPAA FedRAMP and so on so forth and lastly",
    "start": "2419010",
    "end": "2427140"
  },
  {
    "text": "the service allows you to start small and scale as you want you can start as",
    "start": "2427140",
    "end": "2432630"
  },
  {
    "text": "low as those in dollars per terabyte per year which is typically one tenth of",
    "start": "2432630",
    "end": "2437910"
  },
  {
    "text": "traditional data warehouses and scale all the way from from there to terabytes and exabytes of data Amazon redshift",
    "start": "2437910",
    "end": "2447869"
  },
  {
    "start": "2442000",
    "end": "2442000"
  },
  {
    "text": "also has a feature called as redshift spectrum which allows you to seamlessly",
    "start": "2447869",
    "end": "2453230"
  },
  {
    "text": "extend your data warehouse to the escalator Lake so using spectrum you",
    "start": "2453230",
    "end": "2458610"
  },
  {
    "text": "could readily fire sequel queries against data sitting in Amazon s3 and",
    "start": "2458610",
    "end": "2465270"
  },
  {
    "text": "start analyzing the data seamlessly in this model what you could do is you could keep certain portion of data",
    "start": "2465270",
    "end": "2471990"
  },
  {
    "text": "within redshift and certain data in s3 and seamlessly run analysis between both",
    "start": "2471990",
    "end": "2478950"
  },
  {
    "text": "the both those data you could have joins happening across your redshift data and",
    "start": "2478950",
    "end": "2484020"
  },
  {
    "text": "your destory data Lake and the beauty of the spectrum service is that you only pay whenever you use a service if you",
    "start": "2484020",
    "end": "2492090"
  },
  {
    "text": "are not firing a query that leverages spectrum you're not charged right so",
    "start": "2492090",
    "end": "2499290"
  },
  {
    "start": "2494000",
    "end": "2494000"
  },
  {
    "text": "that's why Amazon redshift and for your big data workloads Amazon EMR provides",
    "start": "2499290",
    "end": "2505530"
  },
  {
    "text": "you a fully managed service that allows you to quickly spin up a Hadoop cluster",
    "start": "2505530",
    "end": "2512040"
  },
  {
    "text": "in a matter of minutes right so you could go to the service and say I need a",
    "start": "2512040",
    "end": "2517170"
  },
  {
    "text": "100 node Hadoop cluster in this particular instance type and so on and",
    "start": "2517170",
    "end": "2523170"
  },
  {
    "text": "so forth and the cluster gets spun up in a matter of minutes Amazon EMR supports 19 different open",
    "start": "2523170",
    "end": "2531359"
  },
  {
    "text": "source projects including spark presto hbase flink Zeppelin all those projects are you",
    "start": "2531359",
    "end": "2539910"
  },
  {
    "text": "typically use in the Hadoop ecosystem you get the latest versions of all those",
    "start": "2539910",
    "end": "2545130"
  },
  {
    "text": "open source projects so we a mccarran's where if something becomes generally",
    "start": "2545130",
    "end": "2551010"
  },
  {
    "text": "available in the in the open source community it's available in EMR within 30 days of",
    "start": "2551010",
    "end": "2556440"
  },
  {
    "text": "release Amazon EMR also allows you to lower the cost of running big data",
    "start": "2556440",
    "end": "2563369"
  },
  {
    "text": "workloads where you get per second billing for your clusters and you also have",
    "start": "2563369",
    "end": "2569310"
  },
  {
    "text": "integrations with easy to spot easy to spot is as a mechanism where you can",
    "start": "2569310",
    "end": "2576810"
  },
  {
    "text": "access the unused capacity in your data centers and it's typically available at",
    "start": "2576810",
    "end": "2582240"
  },
  {
    "text": "80% savings over your typical on-demand pricing right and third aspect is Amazon",
    "start": "2582240",
    "end": "2589410"
  },
  {
    "text": "email directly can operate on top of your s3 data right you could spin up a",
    "start": "2589410",
    "end": "2597150"
  },
  {
    "text": "spark cluster and a presto cluster which can seamlessly operate on data that is",
    "start": "2597150",
    "end": "2602580"
  },
  {
    "text": "sitting out of your s3 bucket using a MRFs so MRFs is EMRs own implementation",
    "start": "2602580",
    "end": "2608820"
  },
  {
    "text": "of HDFS which can directly connect to s3 and start running your analysis in this",
    "start": "2608820",
    "end": "2613859"
  },
  {
    "text": "model you are decoupling the computer and storage of your Hadoop workload where you can even spin up multiple EMR",
    "start": "2613859",
    "end": "2623340"
  },
  {
    "text": "clusters and start running multiple analysis against the same data if you",
    "start": "2623340",
    "end": "2629280"
  },
  {
    "text": "are running let's say batch jobs that typically run once in a day your cluster can come up whenever you need let's say",
    "start": "2629280",
    "end": "2636119"
  },
  {
    "text": "at 12 in the night and start running for let's say a couple of hours and then once your batch job is complete your",
    "start": "2636119",
    "end": "2642900"
  },
  {
    "text": "cluster can be shut down and you can again run the same cluster again the",
    "start": "2642900",
    "end": "2649440"
  },
  {
    "text": "next day right and you're only being charged only for those hours that your cluster was operational right it helps",
    "start": "2649440",
    "end": "2655440"
  },
  {
    "text": "you reduce your overall cost of operating your Hadoop workloads on Amazon so that's",
    "start": "2655440",
    "end": "2662660"
  },
  {
    "start": "2657000",
    "end": "2657000"
  },
  {
    "text": "for your hard work loads and we spoke about that other persona who wants a",
    "start": "2662660",
    "end": "2667730"
  },
  {
    "text": "sequel engine that they can readily use for performing analysis those data analysts right so Amazon Athena is the",
    "start": "2667730",
    "end": "2676400"
  },
  {
    "text": "next service which allows you to perform interactive queries written on standard",
    "start": "2676400",
    "end": "2682550"
  },
  {
    "text": "sequel against data that is sitting on Amazon s3 so you can go to the service",
    "start": "2682550",
    "end": "2688130"
  },
  {
    "text": "and say here is my sequel query but on this sequel query against my s3 bucket",
    "start": "2688130",
    "end": "2694210"
  },
  {
    "text": "absolutely no infrastructure to set up and you can query instantly on your data",
    "start": "2694210",
    "end": "2699710"
  },
  {
    "text": "that is available on s3 the pricing model is pay per query which means that",
    "start": "2699710",
    "end": "2705380"
  },
  {
    "text": "if you run a query that's when we charge you depending upon how much of data that you scan and if you don't run any",
    "start": "2705380",
    "end": "2713360"
  },
  {
    "text": "queries after that you are no longer charged for that obviously you can save a cost on that by compressing your data",
    "start": "2713360",
    "end": "2721790"
  },
  {
    "text": "keeping data in your corner formats and so on and so forth the type of queries that you write are standard and C sequel",
    "start": "2721790",
    "end": "2729680"
  },
  {
    "text": "queries that you have written over many years so there is nothing new to learn and you can write any type of queries",
    "start": "2729680",
    "end": "2737180"
  },
  {
    "text": "including performing complex joins window functions and operating on",
    "start": "2737180",
    "end": "2743300"
  },
  {
    "text": "complex data types right we also provide a JDBC ODBC driver which means that you",
    "start": "2743300",
    "end": "2749090"
  },
  {
    "text": "can connect your favorite application and from the application you can start firing queries against your data set the",
    "start": "2749090",
    "end": "2759500"
  },
  {
    "start": "2753000",
    "end": "2753000"
  },
  {
    "text": "next service is Amazon Elastic search service which allows you to seamlessly",
    "start": "2759500",
    "end": "2764690"
  },
  {
    "text": "deploy an elastic search cluster on and the service fully manages the underlying",
    "start": "2764690",
    "end": "2770240"
  },
  {
    "text": "infrastructure for you right you can go to the service and say I need a 10 node",
    "start": "2770240",
    "end": "2775310"
  },
  {
    "text": "elasticsearch cluster we go and bring up the infrastructure we manage youngling",
    "start": "2775310",
    "end": "2780440"
  },
  {
    "text": "infrastructure we take care of availability replacing node failures and all that heavy lifting and give you a",
    "start": "2780440",
    "end": "2786800"
  },
  {
    "text": "single endpoint at the Unison point to which you can start connecting your applications and start firing your",
    "start": "2786800",
    "end": "2793040"
  },
  {
    "text": "queries against elasticsearch it's the same elastic it's the same open-source elasticsearch so you have",
    "start": "2793040",
    "end": "2798920"
  },
  {
    "text": "direct access to the elasticsearch AP ice and Sun comes with Cubana out of the",
    "start": "2798920",
    "end": "2805309"
  },
  {
    "text": "box and lock stretch out of the box right so you could start visualizing your log data to Capernaum in a matter",
    "start": "2805309",
    "end": "2811430"
  },
  {
    "text": "of minutes security is taking care where you could deploy and the service within your V PC",
    "start": "2811430",
    "end": "2817339"
  },
  {
    "text": "you could take care of encryption in trance said and addressed access",
    "start": "2817339",
    "end": "2823280"
  },
  {
    "text": "policies to control who has access to your data all that is available for you right so quickly allows you to deploy in",
    "start": "2823280",
    "end": "2830450"
  },
  {
    "text": "elasticsearch service and start running your analysis so those are the different",
    "start": "2830450",
    "end": "2836119"
  },
  {
    "text": "processing engines analytical ideas that you have to start analyzing your data so going back to that particular diagram",
    "start": "2836119",
    "end": "2841460"
  },
  {
    "text": "you now have those different engines that can readily connect your s3 data",
    "start": "2841460",
    "end": "2846680"
  },
  {
    "text": "Lake and start processing your data and starting make sense out of your data on",
    "start": "2846680",
    "end": "2854510"
  },
  {
    "start": "2849000",
    "end": "2849000"
  },
  {
    "text": "top of that you also get the highest levels of security so we call security",
    "start": "2854510",
    "end": "2860599"
  },
  {
    "text": "as job zero at Amazon and if you have been an area Bleus user you would have seen that we continue to I iterate and",
    "start": "2860599",
    "end": "2867950"
  },
  {
    "text": "bring newer and newer capability from a security perspective right so lots and lots of options to secure your data so",
    "start": "2867950",
    "end": "2876380"
  },
  {
    "text": "whether it is let's say things like encryption at rest encryption in transit there are multiple options there",
    "start": "2876380",
    "end": "2883309"
  },
  {
    "text": "including a key management service for you from identity perspective if you want to control who has access to what",
    "start": "2883309",
    "end": "2890180"
  },
  {
    "text": "we provide a rich Identity and Access Management Service we provide our",
    "start": "2890180",
    "end": "2895730"
  },
  {
    "text": "directory service which can connect to your unpromising directories or you",
    "start": "2895730",
    "end": "2901099"
  },
  {
    "text": "could also deploy a fully managed active directory on the a SS platform if you",
    "start": "2901099",
    "end": "2907250"
  },
  {
    "text": "need a Web Application Firewall we have a fully managed service for that you could deploy everything within your be",
    "start": "2907250",
    "end": "2914029"
  },
  {
    "text": "PC which is virtual private cloud allows you to deploy a private network within our AWS",
    "start": "2914029",
    "end": "2919730"
  },
  {
    "text": "platform and also from a compliance perspective a number of compliance checks are also met by the platform",
    "start": "2919730",
    "end": "2927170"
  },
  {
    "text": "right so you can be rest assured that you're deploying your data League you can operate in a secured in a compliant",
    "start": "2927170",
    "end": "2933140"
  },
  {
    "start": "2931000",
    "end": "2931000"
  },
  {
    "text": "manner on the platform specifically I wanted to call out a newer service called as Amazon Maisy",
    "start": "2933140",
    "end": "2938630"
  },
  {
    "text": "which which is a machine learning powered security service that",
    "start": "2938630",
    "end": "2944049"
  },
  {
    "text": "continuously monitors your data that is available in your s3 data Lake and",
    "start": "2944049",
    "end": "2949089"
  },
  {
    "text": "generates alerts when it detects any unauthorized access to your data right",
    "start": "2949089",
    "end": "2955039"
  },
  {
    "text": "it also recognizes any PII data if you have let's say if you do not want to if",
    "start": "2955039",
    "end": "2961819"
  },
  {
    "text": "you did not intend to store any pa derive if somebody accidentally puts a Pai data the service can automatically",
    "start": "2961819",
    "end": "2968059"
  },
  {
    "text": "detect that and start notifying you right so lots of options from a security",
    "start": "2968059",
    "end": "2975440"
  },
  {
    "text": "perspective so that's the next pillar from a data like perspective so you seemingly seamlessly all those different",
    "start": "2975440",
    "end": "2981109"
  },
  {
    "text": "security services and protect your data that's sitting out of here s3 bucket in",
    "start": "2981109",
    "end": "2986359"
  },
  {
    "text": "addition what customers also do is that if you would want to build your data",
    "start": "2986359",
    "end": "2991460"
  },
  {
    "text": "lake and start exposing your data leak through API stew both your internal organizations and your external users we",
    "start": "2991460",
    "end": "2998569"
  },
  {
    "text": "provide again multiple options to seamlessly deploy an API layer right so",
    "start": "2998569",
    "end": "3005109"
  },
  {
    "text": "you could go to the API a gateway service and deploy an a pH in a matter of minutes and start exposing your data",
    "start": "3005109",
    "end": "3011470"
  },
  {
    "text": "leg through API is to your end users so going back to those characteristics so",
    "start": "3011470",
    "end": "3017710"
  },
  {
    "text": "we covered the collect anything aspect dive in anywhere and flexible access mechanisms and lastly future proofing",
    "start": "3017710",
    "end": "3024369"
  },
  {
    "text": "how do you make sure that your data Lake is future proof for all your new use cases so when I talk about future proof",
    "start": "3024369",
    "end": "3031150"
  },
  {
    "start": "3026000",
    "end": "3026000"
  },
  {
    "text": "a lot of customers are trying to look at machine learning as a mechanism to drive",
    "start": "3031150",
    "end": "3036270"
  },
  {
    "text": "richer insights and start predicting data relating insights for your business",
    "start": "3036270",
    "end": "3043000"
  },
  {
    "text": "right but if I if you look at the machine learning process it's extremely hard and type and zooming today so where",
    "start": "3043000",
    "end": "3049660"
  },
  {
    "text": "you have to first collect all that data that makes sense to build your machine learning model here to go through a",
    "start": "3049660",
    "end": "3055660"
  },
  {
    "text": "rigorous process is to cleanse and format your data and the whole exercise",
    "start": "3055660",
    "end": "3061299"
  },
  {
    "text": "of training your machine learning model and Retraining it and I trading it it's very very",
    "start": "3061299",
    "end": "3067230"
  },
  {
    "text": "cumbersome and you need access to lot of sophisticated users expertise that is",
    "start": "3067230",
    "end": "3074590"
  },
  {
    "text": "very hard to find right that's where the platform provides you different",
    "start": "3074590",
    "end": "3080200"
  },
  {
    "text": "capabilities to run your machine learning and AI workloads from a perspective there are lots of services",
    "start": "3080200",
    "end": "3087190"
  },
  {
    "text": "available right from computer vision and text to speech and speech recognition and translation and natural language",
    "start": "3087190",
    "end": "3094420"
  },
  {
    "text": "processing lots of fully managed services available as an API right so all these services are fully managed",
    "start": "3094420",
    "end": "3100450"
  },
  {
    "text": "available as an API and you can readily consume these services in addition we",
    "start": "3100450",
    "end": "3106390"
  },
  {
    "text": "also have a service called a sage maker which allows you to quickly build out your machine learning models you can go",
    "start": "3106390",
    "end": "3113170"
  },
  {
    "text": "to the service and use a notebook to start building out your machine learning",
    "start": "3113170",
    "end": "3118960"
  },
  {
    "text": "models and then spin-off distributed training which we would fully manage",
    "start": "3118960",
    "end": "3124330"
  },
  {
    "text": "from infrastructure perspective and once your models are built out you could",
    "start": "3124330",
    "end": "3129400"
  },
  {
    "text": "deploy that through an endpoint on the service again fully managed from an availability perspective and start",
    "start": "3129400",
    "end": "3134859"
  },
  {
    "text": "paying for all the inferences in a per second model right so go and take a look at it it's it's one of our newer",
    "start": "3134859",
    "end": "3142390"
  },
  {
    "text": "services and we see lot of customers log into this for their machine learning and deep learning use cases right so if I go",
    "start": "3142390",
    "end": "3150280"
  },
  {
    "text": "back to the diagram that fits the last piece of the puzzle where lots of choices from a machine learning and a",
    "start": "3150280",
    "end": "3156010"
  },
  {
    "start": "3155000",
    "end": "3155000"
  },
  {
    "text": "deep learning perspective right so hopefully that gave you a perspective",
    "start": "3156010",
    "end": "3162520"
  },
  {
    "text": "in terms of how you could build out your data Lake using all those fundamental building blocks that we offer so if you",
    "start": "3162520",
    "end": "3168700"
  },
  {
    "text": "are more interested so we have a derelict solution which is available on our website that's the link that is",
    "start": "3168700",
    "end": "3175180"
  },
  {
    "text": "available where it's a reference architecture to build out all of that you could go there and in one click you",
    "start": "3175180",
    "end": "3180520"
  },
  {
    "text": "can go and deploy that data Lake on the riblets platform and readily get started from there all right so if you are",
    "start": "3180520",
    "end": "3187840"
  },
  {
    "start": "3183000",
    "end": "3183000"
  },
  {
    "text": "looking to build out your data Lake what we recommend typically for our customers is to typically start with some projects",
    "start": "3187840",
    "end": "3195520"
  },
  {
    "text": "where you can see some direct impact on your business so short list some small",
    "start": "3195520",
    "end": "3201430"
  },
  {
    "text": "projects are you are able to directly influence a business and then build out",
    "start": "3201430",
    "end": "3207760"
  },
  {
    "text": "a very simple pipeline that will allow you to pace to your idea and start filling your derelict and if you need",
    "start": "3207760",
    "end": "3214930"
  },
  {
    "text": "help please do reach out to us there are lots of solution architects through which you can help you build out your",
    "start": "3214930",
    "end": "3221349"
  },
  {
    "text": "data Lake and start making those insights or of your data all right with",
    "start": "3221349",
    "end": "3227980"
  },
  {
    "start": "3225000",
    "end": "3225000"
  },
  {
    "text": "that I'm gonna introduce our guest speaker so we have virtual number um who",
    "start": "3227980",
    "end": "3234010"
  },
  {
    "text": "heads cloud engineering at month on month on is one of our partners they are",
    "start": "3234010",
    "end": "3239829"
  },
  {
    "text": "an analytics is we and they have been one of our advanced users of the arab list platform and specifically the",
    "start": "3239829",
    "end": "3245640"
  },
  {
    "text": "analytics platform right so Vijay is here to talk about how month on is",
    "start": "3245640",
    "end": "3250720"
  },
  {
    "text": "leveraging the analytics platform and how they are built out I didn't like to",
    "start": "3250720",
    "end": "3255849"
  },
  {
    "text": "serve their business or do you which I",
    "start": "3255849",
    "end": "3260369"
  },
  {
    "text": "you",
    "start": "3272700",
    "end": "3274760"
  },
  {
    "text": "hi my name is Vijay Umbra my head cloud engineering commenting thank you for",
    "start": "3299880",
    "end": "3308200"
  },
  {
    "text": "your participation it's great to be talking to you about the month and data link what I'm going to do to start with",
    "start": "3308200",
    "end": "3315100"
  },
  {
    "text": "is give you a quick introduction on month in and then we will talk more about the dissolution itself",
    "start": "3315100",
    "end": "3322740"
  },
  {
    "text": "month is a leading cloud based analytics company of your pioneer and analytic",
    "start": "3322740",
    "end": "3329290"
  },
  {
    "text": "applications or custom facing businesses we have been in business for the last 14 years the last 8 years or so we have",
    "start": "3329290",
    "end": "3336960"
  },
  {
    "text": "radicalize the wave we have offered our analytic solutions on the cloud more so with what we have done with AWS all of",
    "start": "3336960",
    "end": "3344440"
  },
  {
    "text": "the solutions are based on very strong decision sciences advanced math and",
    "start": "3344440",
    "end": "3350700"
  },
  {
    "text": "artificial intelligences all of them powered natively by the AWS type so to speak we are very well recognized by the",
    "start": "3350700",
    "end": "3359830"
  },
  {
    "text": "experts collaboration with AWS fans over heat years now we've been widely",
    "start": "3359830",
    "end": "3364900"
  },
  {
    "text": "recognized by them as innovation partners two years in the road now and",
    "start": "3364900",
    "end": "3369960"
  },
  {
    "text": "highly rated and highly commented by most of the experts in the market so",
    "start": "3369960",
    "end": "3375130"
  },
  {
    "text": "that was a very quick introduction of month in for the guys will not be initiated an order thereof who month in",
    "start": "3375130",
    "end": "3381700"
  },
  {
    "text": "is so what we've always really jump into is the month ends version of the data",
    "start": "3381700",
    "end": "3386950"
  },
  {
    "text": "Lake on the AWS cloud and as you see what we like to see it from a vision",
    "start": "3386950",
    "end": "3393820"
  },
  {
    "text": "perspective from from the promise of what we deliver to our customers is basically an hyperscale repository of",
    "start": "3393820",
    "end": "3400600"
  },
  {
    "text": "enterprise and external data optimized for AI in analytical workloads this is a",
    "start": "3400600",
    "end": "3406090"
  },
  {
    "text": "very important guiding principle for us of how we design a data Lake on AWS predominantly what we've been hearing",
    "start": "3406090",
    "end": "3412810"
  },
  {
    "text": "from our customers are the fact that the analysis of data generated by",
    "start": "3412810",
    "end": "3420490"
  },
  {
    "text": "enterprises themselves or internal business systems for example your ERP co-financed systems your your",
    "start": "3420490",
    "end": "3427090"
  },
  {
    "text": "transactional system has pretty much reached a ceiling right where you look ad we looking at business objectives",
    "start": "3427090",
    "end": "3434230"
  },
  {
    "text": "which are improving by say about five or six percent getting an external data",
    "start": "3434230",
    "end": "3439900"
  },
  {
    "text": "data that you don't really generate which is basically generated on the",
    "start": "3439900",
    "end": "3445090"
  },
  {
    "text": "cloud in the internet space on social media on whether syndicates on other CDP",
    "start": "3445090",
    "end": "3451480"
  },
  {
    "text": "platforms for example other loyalty programs and an only channel into places",
    "start": "3451480",
    "end": "3456970"
  },
  {
    "text": "like e-commerce that's the data that our enterprises are looking to break in and that's the data that they have seen",
    "start": "3456970",
    "end": "3463170"
  },
  {
    "text": "enriched their business insights that much more leading to a far greater",
    "start": "3463170",
    "end": "3469090"
  },
  {
    "text": "realization of business objectives so that's what goddess really started in what we wanted to build out our version",
    "start": "3469090",
    "end": "3475990"
  },
  {
    "text": "of the data like on AWS so what do you",
    "start": "3475990",
    "end": "3481570"
  },
  {
    "text": "have engineer is basically on the order box engineer to scale designed to",
    "start": "3481570",
    "end": "3488260"
  },
  {
    "text": "deliver insights that drive business objective very clearly we are not focused on the mechanics of building the",
    "start": "3488260",
    "end": "3494920"
  },
  {
    "text": "data Lake of bringing all data and collecting the data you not focus merely on modernizing your head up your data",
    "start": "3494920",
    "end": "3500650"
  },
  {
    "text": "platform what we are interested in what we have delivered through Amazon is actually a data Lake that allow you to",
    "start": "3500650",
    "end": "3507880"
  },
  {
    "text": "go and achieve those business objectives that you said to that extent you should have the ability capability of bringing",
    "start": "3507880",
    "end": "3514930"
  },
  {
    "text": "in all of the data all of the non enterprise data social media data ecommerce IOT on structures unstructured",
    "start": "3514930",
    "end": "3521880"
  },
  {
    "text": "and also reached the best of the abyss",
    "start": "3521880",
    "end": "3527020"
  },
  {
    "text": "technology to drive the most economical and most probably the most resilient data store it will the large catalog in",
    "start": "3527020",
    "end": "3535180"
  },
  {
    "text": "search mechanism that seemed important because while you have all of this data you also need to have a very strong",
    "start": "3535180",
    "end": "3541750"
  },
  {
    "text": "capability of going and looking for the data that actually need you also need that to drive a lot of compliance lot of",
    "start": "3541750",
    "end": "3549430"
  },
  {
    "text": "data lineage concepts which are also very important from a governance perspective on data leak and of course",
    "start": "3549430",
    "end": "3555160"
  },
  {
    "text": "the end objective is the data leak the mountain is built on a table is designed to satisfy these various personas your",
    "start": "3555160",
    "end": "3563290"
  },
  {
    "text": "data Sciences or advanced business analytic users who run advanced algorithms and predictable",
    "start": "3563290",
    "end": "3570390"
  },
  {
    "text": "gherkins so essentially what we bring on AWS to our customers as an end-to-end",
    "start": "3570390",
    "end": "3576299"
  },
  {
    "text": "solution out of the box right from data ingestion collection storage maybe",
    "start": "3576299",
    "end": "3581549"
  },
  {
    "text": "manage the data in the various stages that we will talk to in a subsequent slides and of course having those n",
    "start": "3581549",
    "end": "3588089"
  },
  {
    "text": "consumers consume the data in those various ways so I mean the approach we",
    "start": "3588089",
    "end": "3595799"
  },
  {
    "text": "have taken in this is something that we have seen work for us is the fact that you can stage the way you build your",
    "start": "3595799",
    "end": "3602489"
  },
  {
    "text": "data lake you can stage the journey that you take in building the data lake the primary as maybe the keystone aspect of",
    "start": "3602489",
    "end": "3609449"
  },
  {
    "text": "any data lake is probably ingest the data collect any anything anywhere and",
    "start": "3609449",
    "end": "3614910"
  },
  {
    "text": "store it in a scalable resilient manner that's probably the base foundation layer whether it's batch data with its",
    "start": "3614910",
    "end": "3622109"
  },
  {
    "text": "real-time data whether it's operation or technical business metadata as well and",
    "start": "3622109",
    "end": "3628589"
  },
  {
    "text": "stored in a manner which can scale which is extremely resilient and which also",
    "start": "3628589",
    "end": "3634169"
  },
  {
    "text": "offers you ease of management disease or care lifecycle management and and then",
    "start": "3634169",
    "end": "3640019"
  },
  {
    "text": "segment the data in a fashion that basically takes care of the needs of the various consumers that's probably the",
    "start": "3640019",
    "end": "3646619"
  },
  {
    "text": "fundamental underlying keystone of how we build a gate early and top of that you can then progress to the next path",
    "start": "3646619",
    "end": "3654089"
  },
  {
    "text": "part of your derelict journey which is enabling the different consumers to come into play whether it is AI and machine",
    "start": "3654089",
    "end": "3660839"
  },
  {
    "text": "learning which probably tends to more use the concepts of scheming on reads",
    "start": "3660839",
    "end": "3668900"
  },
  {
    "text": "which is early lifecycle analytics without really having the burden of",
    "start": "3668900",
    "end": "3674419"
  },
  {
    "text": "large scale final view transformations so that's probably the next journey that",
    "start": "3674419",
    "end": "3680669"
  },
  {
    "text": "we have seen work for our customers and I see work for us and then the final end point is what we refer to as the",
    "start": "3680669",
    "end": "3687569"
  },
  {
    "text": "transform data link which allows us a whole slew of consumer services to come in this could be cell service analytics",
    "start": "3687569",
    "end": "3694169"
  },
  {
    "text": "it could be a depressurization advanced visualization and also could be like conversational",
    "start": "3694169",
    "end": "3699690"
  },
  {
    "text": "agents which allow wise and xti tools to actually integrate the data another big",
    "start": "3699690",
    "end": "3707550"
  },
  {
    "text": "trend that we are seeing is learn of a customers who are we missing in the data Lake also started to monetize what that",
    "start": "3707550",
    "end": "3713790"
  },
  {
    "text": "investment be running data monetization service a big part of what we offer to",
    "start": "3713790",
    "end": "3718800"
  },
  {
    "text": "our customers is an ability of actually dipping into it this data through a data",
    "start": "3718800",
    "end": "3725130"
  },
  {
    "text": "API through a API calls which not only allows them to get fast access to the",
    "start": "3725130",
    "end": "3730440"
  },
  {
    "text": "data really loosely coupled but also the ABI we have seen them monetize this",
    "start": "3730440",
    "end": "3736619"
  },
  {
    "text": "ability across the implementations that we have done so largely layer this down",
    "start": "3736619",
    "end": "3743250"
  },
  {
    "text": "into our journey I'll start with the fundamental Keystone which is going to future-proof you and then you can keep",
    "start": "3743250",
    "end": "3748710"
  },
  {
    "text": "adding capabilities as the emerge you can also keep bringing in the data from this various business needs as they",
    "start": "3748710",
    "end": "3754290"
  },
  {
    "text": "emerge one of the key aspects for us is",
    "start": "3754290",
    "end": "3759540"
  },
  {
    "text": "how do you structure the lake itself in a rather talk very extensively about the",
    "start": "3759540",
    "end": "3764880"
  },
  {
    "text": "ingestion so number really well with the capabilities of injection of things very well covered what I would like to share",
    "start": "3764880",
    "end": "3770910"
  },
  {
    "text": "with you guys is a the way via structure the entire storage mechanism or the vintage storage element largely we have",
    "start": "3770910",
    "end": "3779010"
  },
  {
    "text": "classified it or segmented into three zones or three data zones as we would",
    "start": "3779010",
    "end": "3784560"
  },
  {
    "text": "like to call it the startup is you push all of the data as native as possible as",
    "start": "3784560",
    "end": "3790680"
  },
  {
    "text": "granular as possible in something that we are referred to as the landing zone really there's no transformation you're",
    "start": "3790680",
    "end": "3795960"
  },
  {
    "text": "not bringing any kind of DQ and undergoing any kind of cleansing mechanisms over here you just replicating data into one place you're",
    "start": "3795960",
    "end": "3802230"
  },
  {
    "text": "just pushing in data and pulling in data in testing it and have it have it available for further processing in one",
    "start": "3802230",
    "end": "3807569"
  },
  {
    "text": "place this data is going to be largely transient because once you have worked on it you probably don't want it to be",
    "start": "3807569",
    "end": "3812849"
  },
  {
    "text": "in the landing zone the next stage that we progress the data through is three auditor zone again largely native in",
    "start": "3812849",
    "end": "3820740"
  },
  {
    "text": "format but we do now bring the capability of organizing this the need for us to do that is basically it also",
    "start": "3820740",
    "end": "3827579"
  },
  {
    "text": "helps a lot the governance aspects you can put the access privileges around this by",
    "start": "3827579",
    "end": "3833040"
  },
  {
    "text": "this structuring the data it helps you construct your bucket policies then your",
    "start": "3833040",
    "end": "3838440"
  },
  {
    "text": "least access privileges and basically start down ins from that point of view in terms of who got access to the data",
    "start": "3838440",
    "end": "3844110"
  },
  {
    "text": "who can put in data who can pull out data right and then this is then transition to the curated data zone this",
    "start": "3844110",
    "end": "3852240"
  },
  {
    "text": "is where things get interesting right this is where you want to be missing most of your DQ techniques is where you",
    "start": "3852240",
    "end": "3858360"
  },
  {
    "text": "want to be performing your duty applications your outliers ejections you missing value injections lot of",
    "start": "3858360",
    "end": "3863580"
  },
  {
    "text": "harmonization capabilities come through over here this is probably the data Zone where a lot of chemo and read workloads",
    "start": "3863580",
    "end": "3872310"
  },
  {
    "text": "are so lot of right and this is there probably and as we do is where we",
    "start": "3872310",
    "end": "3879300"
  },
  {
    "text": "structure it into probably analytically friendly structure comment maybe an open file structure to maybe a parking",
    "start": "3879300",
    "end": "3885870"
  },
  {
    "text": "structure which is more columnar in nature and antenna lends itself better for schema and real analytics this is",
    "start": "3885870",
    "end": "3892860"
  },
  {
    "text": "where probably you won most of your data science workloads to be dipping into the data this is where you want probably all",
    "start": "3892860",
    "end": "3898620"
  },
  {
    "text": "of your Eric data discovery in a doc varying capabilities to be served out so",
    "start": "3898620",
    "end": "3904200"
  },
  {
    "text": "that's the kind of definition that we have of the curated data zone and the",
    "start": "3904200",
    "end": "3910800"
  },
  {
    "text": "final one which is the transformed data zone is largely an optional segmentation",
    "start": "3910800",
    "end": "3915930"
  },
  {
    "text": "that you can do within the data Lake I am saying option to the lack of any other word but this is a data zone which",
    "start": "3915930",
    "end": "3922890"
  },
  {
    "text": "gets created knowing exactly what those consumers want and how they want it to be served off right you're probably",
    "start": "3922890",
    "end": "3929850"
  },
  {
    "text": "looking at people who want to do visualization so you need to have an aggregated data match so to speak and",
    "start": "3929850",
    "end": "3935910"
  },
  {
    "text": "that's when you probably would end up leveraging something like redshift to run this kind of a workload so this is",
    "start": "3935910",
    "end": "3941250"
  },
  {
    "text": "the final transformation this is when you are bringing in business visualization you're bringing in a line",
    "start": "3941250",
    "end": "3947280"
  },
  {
    "text": "of business controls in terms of how the data has to be structured transform aggregated and served out to a very",
    "start": "3947280",
    "end": "3953310"
  },
  {
    "text": "specific niche set up and humors right across the board are we have a catalog",
    "start": "3953310",
    "end": "3960300"
  },
  {
    "text": "maintained in blue and now spoken bloom the ability for us to have a",
    "start": "3960300",
    "end": "3966270"
  },
  {
    "text": "universal data catalog across the varying consuming entities BMRB redshift",
    "start": "3966270",
    "end": "3973380"
  },
  {
    "text": "beat Athena is what drove us to have a universal catalog on on glue and of",
    "start": "3973380",
    "end": "3979589"
  },
  {
    "text": "course you also have the lifecycle management equal then and we have those",
    "start": "3979589",
    "end": "3986369"
  },
  {
    "text": "rules configured which basically allows you to archive data which is no longer hot or no longer in the recency that you",
    "start": "3986369",
    "end": "3992880"
  },
  {
    "text": "basically want to spend on an active storage so that's the archive zone so to",
    "start": "3992880",
    "end": "3998970"
  },
  {
    "text": "speak so that's essentially how we have structured our a data Lake how can you",
    "start": "3998970",
    "end": "4006380"
  },
  {
    "text": "segmented this largely the deciding factor is the readiness of analytics",
    "start": "4006380",
    "end": "4013190"
  },
  {
    "text": "that the data in each one of these zones lends to here is a complete end-to-end",
    "start": "4013190",
    "end": "4021829"
  },
  {
    "text": "view a logical view of how the moving data into the data lead",
    "start": "4021829",
    "end": "4027380"
  },
  {
    "text": "how do what is the different ingestion mechanisms that are part of our ingestion factory the landing zone what",
    "start": "4027380",
    "end": "4035329"
  },
  {
    "text": "do we do after the landing zone what would we do within these various different zone beep the rowdy razandrich",
    "start": "4035329",
    "end": "4040940"
  },
  {
    "text": "aside from data so we look at the ingestion factory so all of our wrappers",
    "start": "4040940",
    "end": "4050660"
  },
  {
    "text": "where the quality month in real-time Egyptian factory is basically our differentiation over the native services",
    "start": "4050660",
    "end": "4058240"
  },
  {
    "text": "areas office be Genesis or the NS the data Pharaohs right similarly for the",
    "start": "4058240",
    "end": "4065000"
  },
  {
    "text": "month in IOT we use a double use IOT so to speak we have what our own differentiators on top of such a solid",
    "start": "4065000",
    "end": "4071089"
  },
  {
    "text": "as well as the data API server so to speak right once you predominantly in the use case",
    "start": "4071089",
    "end": "4078200"
  },
  {
    "text": "that you will drive will be supported by likes of snowballs",
    "start": "4078200",
    "end": "4084410"
  },
  {
    "text": "a breeze are expanding and even if accelerated s3 endpoints so we spoke",
    "start": "4084410",
    "end": "4090859"
  },
  {
    "text": "about the is a month and landing zone we spoke about the raw data zone and what we do",
    "start": "4090859",
    "end": "4095970"
  },
  {
    "text": "let's talk a little bit about the consumers that we have built as part of the solution out of the box we have a month in data API largely data",
    "start": "4095970",
    "end": "4103920"
  },
  {
    "text": "partnerships general monetization data collaboration across the enterprise to other enterprise entities or something",
    "start": "4103920",
    "end": "4110310"
  },
  {
    "text": "the support for example in case of a CPG year he probably wants to be looking at",
    "start": "4110310",
    "end": "4117380"
  },
  {
    "text": "retailers dip into his data links and draw the information that he probably has got which is valuable to them right",
    "start": "4117380",
    "end": "4124380"
  },
  {
    "text": "then you also have the month in a mynheer service largely powered by a double your sales maker and we have",
    "start": "4124380",
    "end": "4130920"
  },
  {
    "text": "advanced analytical workbenches machine learning workbenches that allows the data science community within our",
    "start": "4130920",
    "end": "4137100"
  },
  {
    "text": "customers to readily those execute model execute score the models and driver",
    "start": "4137100",
    "end": "4143910"
  },
  {
    "text": "inferences and of course we also have the prepackaged want an analytics platform but even then bringing any",
    "start": "4143910",
    "end": "4151140"
  },
  {
    "text": "other platform to Peter lake so to speak a realization tools like table or a great example of how we have seen some",
    "start": "4151140",
    "end": "4156778"
  },
  {
    "text": "of our customers actually bring in plugin the tool hold on to the capabilities probably hit the",
    "start": "4156779",
    "end": "4163020"
  },
  {
    "text": "transformed data zone more than anything else and run the visualization right and you can also have third-party",
    "start": "4163020",
    "end": "4169048"
  },
  {
    "text": "applications dip into the system so largely the way we have structured this",
    "start": "4169049",
    "end": "4174120"
  },
  {
    "text": "is builders have a loosely couple ingestion layer and a loosely coupled",
    "start": "4174120",
    "end": "4179880"
  },
  {
    "text": "consumer layer the basically takes care of the bearing submerging business enterprise so here's a quick snapshot of",
    "start": "4179880",
    "end": "4192238"
  },
  {
    "text": "some of that the AWS services that we have leverage the abuse we use Amazon",
    "start": "4192239",
    "end": "4199350"
  },
  {
    "text": "accelerated as three endpoints for batch loads very extensively give you snowball we also use Amazon DMS services of",
    "start": "4199350",
    "end": "4207120"
  },
  {
    "text": "curation and file structuring Biron have spark hive on a loop predominantly on",
    "start": "4207120",
    "end": "4213120"
  },
  {
    "text": "Amazon iam our catalog management in service capability something that we have built out of blue and Amazon",
    "start": "4213120",
    "end": "4219930"
  },
  {
    "text": "elasticsearch SN has allowed us to open up a lot of data discovery are acquiring",
    "start": "4219930",
    "end": "4225000"
  },
  {
    "text": "serving a sequel capabilities on the data Lake are deep data API sub of Nana moody be maybe a lot of lot of",
    "start": "4225000",
    "end": "4233159"
  },
  {
    "text": "very extremely responsive request to response and workloads are met we",
    "start": "4233159",
    "end": "4239310"
  },
  {
    "text": "flattened data or have it almost equal like DynamoDB have a reduced implementation on elastic cache and",
    "start": "4239310",
    "end": "4245010"
  },
  {
    "text": "front-end buying api gateway that's a pretty standard implementation that we have on AWS machine learning workbench",
    "start": "4245010",
    "end": "4251010"
  },
  {
    "text": "is a powered by sage make it in the background some of our NLP and NLU capabilities we have used election poly",
    "start": "4251010",
    "end": "4257190"
  },
  {
    "text": "as part of the services as well and of course the specialized big data",
    "start": "4257190",
    "end": "4262469"
  },
  {
    "text": "warehouses the use redshift in some cases we've also extended pressured into Amazon spectrum right a lot of our",
    "start": "4262469",
    "end": "4270889"
  },
  {
    "text": "process orchestration because there's a lot of process orchestration there's a lot of automation that you have to bring",
    "start": "4270889",
    "end": "4277860"
  },
  {
    "text": "into the entire ecosystem within the data link we use a proprietary protocol month and data sync but then they're",
    "start": "4277860",
    "end": "4283530"
  },
  {
    "text": "largely relies on a lot of these three events and lambda functions that we have very specifically written for what we",
    "start": "4283530",
    "end": "4291630"
  },
  {
    "text": "offer in the data link of course the foundational service which is which is Amazon s3 that's the the Keystone for",
    "start": "4291630",
    "end": "4298560"
  },
  {
    "text": "the entire data link design that Moulton is a world around AWS so what I'm going",
    "start": "4298560",
    "end": "4304889"
  },
  {
    "text": "to do is quickly walk through a couple of use cases such as videos cases that we have what do our customers",
    "start": "4304889",
    "end": "4311489"
  },
  {
    "text": "the first one is the consolidated platform of marketing advertising analytics for a global telecommunication",
    "start": "4311489",
    "end": "4318389"
  },
  {
    "text": "tool number eight now we're looking at about when you get up in 20 million",
    "start": "4318389",
    "end": "4323730"
  },
  {
    "text": "set-top boxes across about 12 million households again the project scope was",
    "start": "4323730",
    "end": "4332360"
  },
  {
    "text": "created secure data platform and allow a single view of customer across internal",
    "start": "4332360",
    "end": "4338820"
  },
  {
    "text": "and external layer sources right and what the scope of data was was ad",
    "start": "4338820",
    "end": "4344909"
  },
  {
    "text": "viewership across belly minion set-top boxes well minion households Sharon's calls call center data",
    "start": "4344909",
    "end": "4351290"
  },
  {
    "text": "transactional data and external data as well so this basically was greater scope",
    "start": "4351290",
    "end": "4356760"
  },
  {
    "text": "just to give some numbers in terms of what data and volumes you're looking at the link is basically 100",
    "start": "4356760",
    "end": "4362650"
  },
  {
    "text": "only 55% of that is structured around s3 and we have various components like",
    "start": "4362650",
    "end": "4370179"
  },
  {
    "text": "ethanol spectrum then allow the varying capability of that that structure about",
    "start": "4370179",
    "end": "4376960"
  },
  {
    "text": "25% of data is then structured into highly non persistent Hadoop clusters",
    "start": "4376960",
    "end": "4384219"
  },
  {
    "text": "which allow a lot of spark and high were closed to be process another 20% of the data is actually on rich chip data",
    "start": "4384219",
    "end": "4391719"
  },
  {
    "text": "warehouse which is then powering lot of that can report use cases visualization",
    "start": "4391719",
    "end": "4396909"
  },
  {
    "text": "and aggregated dashboards so this is a good example of how each one of the data",
    "start": "4396909",
    "end": "4402130"
  },
  {
    "text": "zones has been orchestrated to work in unison to drive a business objective I",
    "start": "4402130",
    "end": "4408850"
  },
  {
    "text": "mean a few turns over your security being very important because we are actually collecting a lot of customer",
    "start": "4408850",
    "end": "4415030"
  },
  {
    "text": "sensitive data multiple security gates all the deployments are within virtual private cloud we do a lot of pre",
    "start": "4415030",
    "end": "4423190"
  },
  {
    "text": "transfer encryption that is another recommendation that we give to our customers is encrypt pre transfer into",
    "start": "4423190",
    "end": "4428890"
  },
  {
    "text": "us and it is of course encrypted at rest with our suicide encryption on s3 as",
    "start": "4428890",
    "end": "4434710"
  },
  {
    "text": "well as on on on redshift as such are very compelling cost of skin pressure",
    "start": "4434710",
    "end": "4440320"
  },
  {
    "text": "which we have achieved by by literally constructing this entire thing of AWS s3 scale infinitely with very high",
    "start": "4440320",
    "end": "4447159"
  },
  {
    "text": "resilience all of our clusters and again this is in the important part wherever",
    "start": "4447159",
    "end": "4452170"
  },
  {
    "text": "you can use disposable disposes non persistent disposal resources within the data Lake go ahead and do that we learn",
    "start": "4452170",
    "end": "4459370"
  },
  {
    "text": "a lot of non persistent Hadoop clusters to do some of our our analytics on on",
    "start": "4459370",
    "end": "4465310"
  },
  {
    "text": "the riddle Lake a hybrid MVP based concise data Mart driving a lot of",
    "start": "4465310",
    "end": "4471400"
  },
  {
    "text": "advanced visualization for the customer and literally add to our scale",
    "start": "4471400",
    "end": "4477280"
  },
  {
    "text": "architecture across all of the elements the storage of the cluster whatever",
    "start": "4477280",
    "end": "4482650"
  },
  {
    "text": "consuming application servers and the ingestion service per se so very good use case basically covering all aspects",
    "start": "4482650",
    "end": "4488500"
  },
  {
    "text": "of what dragon high of spoken so far just run through one more before we be a",
    "start": "4488500",
    "end": "4495250"
  },
  {
    "text": "rapper when I open for questions this is a different kind of for business we're talking about a large conglomerate",
    "start": "4495250",
    "end": "4502390"
  },
  {
    "text": "nation conglomerate retailer specializing across grocery fashion and home and white good appliances again big",
    "start": "4502390",
    "end": "4511060"
  },
  {
    "text": "big driver for very data sources both external and internal even plus stores",
    "start": "4511060",
    "end": "4518950"
  },
  {
    "text": "of crowns about 240 cities so readily generated a lot of sort of data",
    "start": "4518950",
    "end": "4524130"
  },
  {
    "text": "internally as well as externally and externally again a Goods quick snapshot",
    "start": "4524130",
    "end": "4529870"
  },
  {
    "text": "of the numbers that we are talking about here so who refer out 35 million plus",
    "start": "4529870",
    "end": "4536110"
  },
  {
    "text": "customers customers in terms of customers associated with with this particular conglomerate huh about 13",
    "start": "4536110",
    "end": "4544930"
  },
  {
    "text": "different type of loyalty programs that are either pumping in data into the data leak a lot of transactions that happen",
    "start": "4544930",
    "end": "4552070"
  },
  {
    "text": "throughout the day it's a TBD italic and what we have seen this from Bengie we",
    "start": "4552070",
    "end": "4557770"
  },
  {
    "text": "implemented this data Lake and its current state this data late as and up slowly mocked itself into being a CDP or",
    "start": "4557770",
    "end": "4566290"
  },
  {
    "text": "a customer data platform and that's an interesting observation that's happened is you end up building in either link",
    "start": "4566290",
    "end": "4572560"
  },
  {
    "text": "but you see the data link that we have been specialized in to one of two form",
    "start": "4572560",
    "end": "4577750"
  },
  {
    "text": "factors there single agent legs completely specialized themselves into being a data monitor monetization",
    "start": "4577750",
    "end": "4583930"
  },
  {
    "text": "platforms in this case we have seen the data a kind of mask itself into being a customer data platform so literally a",
    "start": "4583930",
    "end": "4590620"
  },
  {
    "text": "well marketed to data Lake with the ability to consume",
    "start": "4590620",
    "end": "4596140"
  },
  {
    "text": "infinite data as a scale the right set of tools available to customers will see",
    "start": "4596140",
    "end": "4604270"
  },
  {
    "text": "you differentiate very quickly into a very specific usage patterns on the data",
    "start": "4604270",
    "end": "4610210"
  },
  {
    "text": "link see there's much more business value thousand being a kind of an academic mechanics of aggregating data",
    "start": "4610210",
    "end": "4617470"
  },
  {
    "text": "or modernizing your data platform so that's kind of the the the emerging",
    "start": "4617470",
    "end": "4622510"
  },
  {
    "text": "trend that we have seen but the fact remains that you you architected right you architected for scale and you",
    "start": "4622510",
    "end": "4628660"
  },
  {
    "text": "architected for being future-proof also that that's what I wanted to share with you guys you can",
    "start": "4628660",
    "end": "4636250"
  },
  {
    "text": "look up monthly net wwe.com my email id",
    "start": "4636250",
    "end": "4641410"
  },
  {
    "text": "will be shared to you guys and please feel to touch base with me thank you",
    "start": "4641410",
    "end": "4649680"
  },
  {
    "text": "over to you to go for questions okay",
    "start": "4663690",
    "end": "4668970"
  },
  {
    "text": "yeah thank you so much Vijay and that was very very insightful",
    "start": "4668970",
    "end": "4674410"
  },
  {
    "text": "so we'll do we do have few questions coming up over the Q&A window I'll try",
    "start": "4674410",
    "end": "4680920"
  },
  {
    "text": "to answer as much as possible keep keep sending any more questions till we hit the 12:30 mark the first question is is",
    "start": "4680920",
    "end": "4691030"
  },
  {
    "text": "about",
    "start": "4691030",
    "end": "4693360"
  }
]
[
  {
    "start": "0",
    "end": "177000"
  },
  {
    "text": "thanks everyone for coming I know we are probably one of the sessions that is holding you between now and the fun",
    "start": "30",
    "end": "5670"
  },
  {
    "text": "party today evening so without further ado let's get started let me start by",
    "start": "5670",
    "end": "11610"
  },
  {
    "text": "introducing myself I'm Rajeev Sreenivasan I'm an AW a solution architect and I work with a lot",
    "start": "11610",
    "end": "18300"
  },
  {
    "text": "of customers moving their website traffic onto CDN slack laughter and I",
    "start": "18300",
    "end": "24119"
  },
  {
    "text": "also focus on big data analytics and that's also another favorite field of",
    "start": "24119",
    "end": "29130"
  },
  {
    "text": "mine that I have sort of passion that I have for and then I have with me Joseph",
    "start": "29130",
    "end": "35850"
  },
  {
    "text": "Kelly I'm a software development manager in cloud front based out of my team is",
    "start": "35850",
    "end": "42210"
  },
  {
    "text": "based out of Vancouver Vancouver BC the breeze cheering okay my team was",
    "start": "42210",
    "end": "49320"
  },
  {
    "text": "responsible for a lot of what you're going to see here in on the cloud front side developing the reports and the",
    "start": "49320",
    "end": "57030"
  },
  {
    "text": "analytics and delivering the access logs to your your s3 buckets hello everyone",
    "start": "57030",
    "end": "64080"
  },
  {
    "text": "my name is sasha Bourassa i'm a senior consultant on the professional services team at arabia's we focus or I focus on the big data and",
    "start": "64080",
    "end": "73140"
  },
  {
    "text": "security thanks guys um so without further ado let's get",
    "start": "73140",
    "end": "78450"
  },
  {
    "text": "started just by show of hands you know how many of you here are web developers",
    "start": "78450",
    "end": "84540"
  },
  {
    "text": "or web engineers any web developers web engineers cool and any data analyst or",
    "start": "84540",
    "end": "91770"
  },
  {
    "text": "data engineers in the house okay so we have few cool and how many of you here",
    "start": "91770",
    "end": "99750"
  },
  {
    "text": "are already using cloud firm okay quite a few cool so today in this session",
    "start": "99750",
    "end": "108810"
  },
  {
    "text": "we're going to provide a server list framework whereby you know you can",
    "start": "108810",
    "end": "113939"
  },
  {
    "text": "analyze your cloud for an access logs that can that will get delivered to your",
    "start": "113939",
    "end": "119490"
  },
  {
    "text": "s3 bucket and in this architecture the architecture that we're proposing will",
    "start": "119490",
    "end": "125820"
  },
  {
    "text": "actually be able to scale up to terabytes of logs per day so it's four",
    "start": "125820",
    "end": "133340"
  },
  {
    "text": "large data set that you can actually analyze and gain deeper and actionable",
    "start": "133340",
    "end": "138739"
  },
  {
    "text": "insights and today we're just going to jump into few scenarios with our",
    "start": "138739",
    "end": "145810"
  },
  {
    "text": "analysis architecture and one thing that we're going to definitely deep dive into is baaad detection and mitigation",
    "start": "145810",
    "end": "153319"
  },
  {
    "text": "scenario however hopefully you can take that architecture and you will be able",
    "start": "153319",
    "end": "159019"
  },
  {
    "text": "to extend that to other needs that you have for example you can run power your",
    "start": "159019",
    "end": "166130"
  },
  {
    "text": "dashboards for being able to monitor your traffic coming in or even able to have alarms and custom reporting as well",
    "start": "166130",
    "end": "176980"
  },
  {
    "start": "177000",
    "end": "177000"
  },
  {
    "text": "nowadays it's really common for web servers to be fronted by a global",
    "start": "178060",
    "end": "185180"
  },
  {
    "text": "content delivery service like cloud 4 so customers use these kind of or type of",
    "start": "185180",
    "end": "191510"
  },
  {
    "text": "front-end acceleration to fast accelerate the delivery of their websites api's static content like media",
    "start": "191510",
    "end": "200299"
  },
  {
    "text": "assets and this is all done to make sure that your customers have enhanced and",
    "start": "200299",
    "end": "207859"
  },
  {
    "text": "rich experience on on your platform and at the same time no matter no matter",
    "start": "207859",
    "end": "214700"
  },
  {
    "text": "where they are in the globe they're able to access your website with reduced latency and here are some of the",
    "start": "214700",
    "end": "224060"
  },
  {
    "text": "challenges that we have and by analyzing the CloudFront logs these are some of the challenges that you can easily",
    "start": "224060",
    "end": "230239"
  },
  {
    "text": "mitigate for example reducing website latency right so by knowing what are the",
    "start": "230239",
    "end": "235579"
  },
  {
    "text": "popular objects or part where are the popular web pages that your customers are visiting you can get that",
    "start": "235579",
    "end": "242120"
  },
  {
    "text": "information from the logs and then based on that you can make sure that those content are cached closer to them that",
    "start": "242120",
    "end": "250669"
  },
  {
    "text": "way they can access them much faster rather than having to experience the",
    "start": "250669",
    "end": "256910"
  },
  {
    "text": "latency of going all the way towards your data center content optimization is another big challenge",
    "start": "256910",
    "end": "263700"
  },
  {
    "text": "nowadays customers or your users use multiple form factors right they may be",
    "start": "263700",
    "end": "270270"
  },
  {
    "text": "using tablets or browsers on the desktop phones and even within phones there are",
    "start": "270270",
    "end": "275910"
  },
  {
    "text": "multiple you know browsers that are there Android iPhone iOS others and so with",
    "start": "275910",
    "end": "283560"
  },
  {
    "text": "these different kinds of browsers being able to in provide better experience on",
    "start": "283560",
    "end": "289020"
  },
  {
    "text": "all of them or on a subset of them basically when you know that here are my",
    "start": "289020",
    "end": "294690"
  },
  {
    "text": "hardest browsers or here are the ways that users are actually coming and visiting my website so you can do",
    "start": "294690",
    "end": "301110"
  },
  {
    "text": "content optimization so in these access logs there is an user agent string that comes out and with the user agent string",
    "start": "301110",
    "end": "308040"
  },
  {
    "text": "you can figure out what kind of devices that they are using and psy will cover",
    "start": "308040",
    "end": "314610"
  },
  {
    "text": "more on the bar detection and mitigation so before we kind of jump into this the",
    "start": "314610",
    "end": "321870"
  },
  {
    "text": "framework I would like to provide a primer or introduce all these services",
    "start": "321870",
    "end": "327960"
  },
  {
    "text": "that we are using as part of this architecture so first to start with is",
    "start": "327960",
    "end": "333090"
  },
  {
    "text": "of course CloudFront so using cloud France 107 point of presence in 55",
    "start": "333090",
    "end": "338940"
  },
  {
    "text": "cities across 24 countries now your application can deliver the availability",
    "start": "338940",
    "end": "344640"
  },
  {
    "text": "scalability and performance for all of your customers in different parts of the world with cloud front you also benefit",
    "start": "344640",
    "end": "352260"
  },
  {
    "text": "using you know it's seamlessly integrated with the managed DDoS protection service called AWS shield and",
    "start": "352260",
    "end": "360030"
  },
  {
    "text": "you can deliver your api's or your application why are SSL and TLS that way you can now",
    "start": "360030",
    "end": "368130"
  },
  {
    "text": "secure your api's and CloudFront also deeply integrates with some of the services that you might be already using",
    "start": "368130",
    "end": "374400"
  },
  {
    "text": "like Amazon simple storage service like Amazon s3 Amazon ec2 or elastic load",
    "start": "374400",
    "end": "382620"
  },
  {
    "text": "balancing and these certain resources you can use them as your back-end",
    "start": "382620",
    "end": "387650"
  },
  {
    "text": "resources in your origin and with DNS like route 53 you can speed up DNS",
    "start": "387650",
    "end": "393810"
  },
  {
    "text": "resolution so that the from your users to the applications are",
    "start": "393810",
    "end": "398950"
  },
  {
    "text": "routed to the closest pop and also the",
    "start": "398950",
    "end": "404260"
  },
  {
    "text": "other thing is our front provides seamless integration with AWS lambda so",
    "start": "404260",
    "end": "411580"
  },
  {
    "text": "what that means is now you can run your own custom code or custom logic across",
    "start": "411580",
    "end": "416980"
  },
  {
    "text": "the AWS global network without having to provision or monitor servers and you can",
    "start": "416980",
    "end": "425860"
  },
  {
    "text": "further accelerate your api's because now CloudFront also integrates with",
    "start": "425860",
    "end": "431010"
  },
  {
    "text": "Amazon API gateway Third Front can be",
    "start": "431010",
    "end": "437050"
  },
  {
    "text": "used to accelerate both your dynamic and static content dynamic content such as",
    "start": "437050",
    "end": "442720"
  },
  {
    "text": "PHP pages or static content such as your images or your audio stream or it could",
    "start": "442720",
    "end": "451600"
  },
  {
    "text": "be your video stream or other software downloads by default CloudFront provides",
    "start": "451600",
    "end": "458290"
  },
  {
    "text": "a multi-tier cache so what that means is that now if you you can cache your",
    "start": "458290",
    "end": "463750"
  },
  {
    "text": "objects much closer to the user thereby not only lowering the latency but also",
    "start": "463750",
    "end": "469570"
  },
  {
    "text": "lowering the load on your back-end servers so you have enough resources and",
    "start": "469570",
    "end": "475780"
  },
  {
    "text": "it's also cost-efficient for you for dynamic content CloudFront can also help",
    "start": "475780",
    "end": "481990"
  },
  {
    "text": "the way it helps is using you know you're able to do your initial TLS termination closer to the user at the",
    "start": "481990",
    "end": "489070"
  },
  {
    "text": "pub so now for the initial handshake the traffic doesn't have to flow all the way",
    "start": "489070",
    "end": "494860"
  },
  {
    "text": "from your users browser to your origin which could be far far away from the",
    "start": "494860",
    "end": "500560"
  },
  {
    "text": "user rather than that now it'll terminate the connection much",
    "start": "500560",
    "end": "505870"
  },
  {
    "text": "closer to the user thereby reducing latency in other cases it also helps",
    "start": "505870",
    "end": "513310"
  },
  {
    "text": "with having where it routes your traffic or your users traffic why are the AWS",
    "start": "513310",
    "end": "518919"
  },
  {
    "text": "backbone so that even further accelerates your dynamic content the",
    "start": "518919",
    "end": "525490"
  },
  {
    "text": "next is purse it also persists a TCP connection between the pop as well as the origin so",
    "start": "525490",
    "end": "533510"
  },
  {
    "text": "by connection reuse you don't have to continuously re-establish connection",
    "start": "533510",
    "end": "538580"
  },
  {
    "text": "between your users browser and to your origin and yes you can front your web",
    "start": "538580",
    "end": "549380"
  },
  {
    "text": "servers and your applications running on your on-premise using AWS using Amazon",
    "start": "549380",
    "end": "555830"
  },
  {
    "text": "CloudFront at no additional charge and yet all the benefits that CloudFront",
    "start": "555830",
    "end": "560990"
  },
  {
    "text": "provides next let's look at AWS RAF",
    "start": "560990",
    "end": "566830"
  },
  {
    "text": "Fairford also seemingly integrates with AWS graph graph is a Web Application",
    "start": "566830",
    "end": "572210"
  },
  {
    "text": "Firewall and also with AWS shield advanced and these can help you protect",
    "start": "572210",
    "end": "578840"
  },
  {
    "text": "your applications from far more sophisticated threats and DDoS attacks",
    "start": "578840",
    "end": "584860"
  },
  {
    "text": "you can actually throw in the template so with laughs you can throw in a",
    "start": "584860",
    "end": "590000"
  },
  {
    "text": "template that contains a bunch of graph rules that best fits your needs and with that you can now block your",
    "start": "590000",
    "end": "597380"
  },
  {
    "text": "common threats such as cross-site scripting sequel injection or HTTP",
    "start": "597380",
    "end": "602510"
  },
  {
    "text": "floods you can also block IP addresses based on rate limits for example let's",
    "start": "602510",
    "end": "610070"
  },
  {
    "text": "say your BA a bot is hitting your website from a particular IP address and it's and and you can now set a rate or a",
    "start": "610070",
    "end": "618410"
  },
  {
    "text": "limit and once it exceeds the limit or the number of requests exceeds the threshold now I can start blocking that",
    "start": "618410",
    "end": "625400"
  },
  {
    "text": "IP using AWS well you can also block IPS",
    "start": "625400",
    "end": "630890"
  },
  {
    "text": "that are continuously sending you bad requests because now your resources or",
    "start": "630890",
    "end": "636110"
  },
  {
    "text": "your back-end servers are overloaded by just sending 4-xx response back to bad",
    "start": "636110",
    "end": "641660"
  },
  {
    "text": "requests you can take care or block those upfront in the edge rather than",
    "start": "641660",
    "end": "647990"
  },
  {
    "text": "the traffic having to flow all the way to your origin so let's kind of dive a",
    "start": "647990",
    "end": "656090"
  },
  {
    "start": "653000",
    "end": "653000"
  },
  {
    "text": "little bit into how the access logs are being delivered to your s3 bucket this",
    "start": "656090",
    "end": "662450"
  },
  {
    "text": "is important for your to analysis on how you want to analyze so this is kind of key so when",
    "start": "662450",
    "end": "670770"
  },
  {
    "text": "you're in this diagram you see two websites website a and website B so when I user sends a request to a web site a",
    "start": "670770",
    "end": "677850"
  },
  {
    "text": "or website B that are on two different there that you have configured on two different distributions so based on the",
    "start": "677850",
    "end": "686060"
  },
  {
    "text": "the URL your and the DNS lookup it's going to resolve to a particular edge",
    "start": "686060",
    "end": "692760"
  },
  {
    "text": "location so once it hits that edge location what CloudFront does is cut for",
    "start": "692760",
    "end": "698310"
  },
  {
    "text": "and capture some of the metadata and then it writes to a log file and these log files are one per distribution so it",
    "start": "698310",
    "end": "707220"
  },
  {
    "text": "will write to a log file per distribution so and then periodically CloudFront will deliver those log files",
    "start": "707220",
    "end": "714630"
  },
  {
    "text": "into your s3 bucket that you have configured and once the files are being",
    "start": "714630",
    "end": "722670"
  },
  {
    "text": "delivered what will then CloudFront will start another file and then the",
    "start": "722670",
    "end": "728280"
  },
  {
    "text": "subsequent request will be logged into the other file few other things to note",
    "start": "728280",
    "end": "734610"
  },
  {
    "text": "about the CloudFront access log so the",
    "start": "734610",
    "end": "740910"
  },
  {
    "text": "file format is kind of important when you're analyzing it's it's important to understand so the file format has a",
    "start": "740910",
    "end": "747420"
  },
  {
    "text": "bucket name it has an optional prefix that you can configure but it is a distribution ID the reason why you have",
    "start": "747420",
    "end": "755010"
  },
  {
    "text": "to kind of keep this in mind is if you're doing any further ETL downstream you have to make sure that the",
    "start": "755010",
    "end": "760920"
  },
  {
    "text": "distribution ID is actually put into the file so you will create the distribution",
    "start": "760920",
    "end": "766680"
  },
  {
    "text": "ID from the name of the file and then further put it if you want that information to propagate and there is a",
    "start": "766680",
    "end": "772860"
  },
  {
    "text": "timestamp a note here is that this timestamp is the timestamp at which the",
    "start": "772860",
    "end": "778950"
  },
  {
    "text": "request occurred it's not the timestamp at which the log file was delivered to your s3 bucket so that is key to",
    "start": "778950",
    "end": "786120"
  },
  {
    "text": "understand for the analysis and finally two other things that I want to mention",
    "start": "786120",
    "end": "792030"
  },
  {
    "text": "is that the the log file can take up to several it'll be delivered several times and our",
    "start": "792030",
    "end": "798660"
  },
  {
    "text": "and and and for a particular time period it's possible that there would be",
    "start": "798660",
    "end": "804060"
  },
  {
    "text": "multiple log files delivered for example let's say if you had a flash sale or something where your traffic just starts",
    "start": "804060",
    "end": "810389"
  },
  {
    "text": "spiking up in that case you would see multiple log files being delivered for the same time period so here are a bunch",
    "start": "810389",
    "end": "820560"
  },
  {
    "text": "of customers that use Amazon CloudFront like we have Hulu in the media and",
    "start": "820560",
    "end": "825990"
  },
  {
    "text": "entertainment we have supercell in gaming with Intuit in finance and we",
    "start": "825990",
    "end": "831690"
  },
  {
    "text": "have cannon in enterprise and amazon.com in the e-commerce aisle again I won't",
    "start": "831690",
    "end": "837810"
  },
  {
    "text": "talk about each in every use case but I'll kind of highlight one just for the essence and the essence of time slack is",
    "start": "837810",
    "end": "845730"
  },
  {
    "text": "a for most of you I think would know slack but for those of you who don't",
    "start": "845730",
    "end": "851130"
  },
  {
    "text": "know slack is a company that builds messaging app for teams that integrates",
    "start": "851130",
    "end": "856800"
  },
  {
    "text": "with thousands of popular tools and services and slack by adopting",
    "start": "856800",
    "end": "862380"
  },
  {
    "text": "CloudFront was able to not only secure their api's but was able to reduce their",
    "start": "862380",
    "end": "869699"
  },
  {
    "text": "latency by 300 milliseconds and that's really huge for all of you who already",
    "start": "869699",
    "end": "875970"
  },
  {
    "text": "know that you know like if you're doing any kind of a ecommerce platform or app",
    "start": "875970",
    "end": "881010"
  },
  {
    "text": "platform reducing latency by even a single millisecond is a huge deal",
    "start": "881010",
    "end": "887180"
  },
  {
    "text": "now let's look at some of the services that are going to be involved as part of",
    "start": "887180",
    "end": "895350"
  },
  {
    "text": "this architecture that we are going to propose further down again all the",
    "start": "895350",
    "end": "901769"
  },
  {
    "text": "services that you'll be looking in here will be serverless they are all serverless so how to think",
    "start": "901769",
    "end": "908220"
  },
  {
    "text": "about lambda most of you may be knowing about lambda but for those of you who don't know you can think of lambda as a",
    "start": "908220",
    "end": "913860"
  },
  {
    "text": "code or your custom logic or a function that will get executed when there is an event trigger so what that means is that",
    "start": "913860",
    "end": "921779"
  },
  {
    "text": "whenever there is a change in the ratio state of any W service or there's a chain the state of the data or if you make an",
    "start": "921779",
    "end": "929130"
  },
  {
    "text": "API call to directly to WS lambda then it triggers lambda and it'll execute",
    "start": "929130",
    "end": "936690"
  },
  {
    "text": "your code and since it's your custom code downstream you can interact with",
    "start": "936690",
    "end": "943800"
  },
  {
    "text": "anything like for example you can store it to a database or if you want to do ETL or you want to push it into Kinesis",
    "start": "943800",
    "end": "950610"
  },
  {
    "text": "stream or any any other thing that you want to do so but lambda the advantage",
    "start": "950610",
    "end": "957780"
  },
  {
    "text": "that you have is now you can actually focus on building dynamic and modular",
    "start": "957780",
    "end": "963990"
  },
  {
    "text": "and powerful applications and all the plumbing is taken care by us for example",
    "start": "963990",
    "end": "969480"
  },
  {
    "text": "what I mean by that is in as you will see in this architecture when your your",
    "start": "969480",
    "end": "976010"
  },
  {
    "text": "CloudFront access logs get delivered to the s3 bucket right and a put into the",
    "start": "976010",
    "end": "982920"
  },
  {
    "text": "s3 bucket will actually invoke your function so what that helps is now let's",
    "start": "982920",
    "end": "988830"
  },
  {
    "text": "say that you have a flash sale and a lot of access logs are getting delivered to",
    "start": "988830",
    "end": "994410"
  },
  {
    "text": "your s3 bucket now then your lambda will automatically scale for you to perform",
    "start": "994410",
    "end": "1000530"
  },
  {
    "text": "ETL on each and every file and when the flash sale ends and the number of",
    "start": "1000530",
    "end": "1007190"
  },
  {
    "text": "automatically the number of logs in the s3 bucket goes down lambda will not be invoked and you're not paying for",
    "start": "1007190",
    "end": "1013010"
  },
  {
    "text": "anything that's idle next let's look at",
    "start": "1013010",
    "end": "1019490"
  },
  {
    "text": "Canisius stream Canisius so within Kinesis we have three flavors Amazon",
    "start": "1019490",
    "end": "1025430"
  },
  {
    "text": "kanesha stream Amazon fire hose and Kinesis analytics so Amazon Kinesis so",
    "start": "1025430",
    "end": "1036560"
  },
  {
    "text": "in this diagram as you can see here with Amazon Kinesis you have something called",
    "start": "1036560",
    "end": "1041660"
  },
  {
    "text": "that's under most the left-hand side you see is a is a Kinesis producer right we",
    "start": "1041660",
    "end": "1047930"
  },
  {
    "text": "have two libraries one we call it the KPA library and there is also a Canisius",
    "start": "1047930",
    "end": "1054980"
  },
  {
    "text": "agent so using these now whatever log files get generated you actually push them into Kinesis stream",
    "start": "1054980",
    "end": "1061680"
  },
  {
    "text": "and on the other side now you can process the data that's being sent into",
    "start": "1061680",
    "end": "1067260"
  },
  {
    "text": "the Kinesis stream using either third party applications such as strong spark",
    "start": "1067260",
    "end": "1073530"
  },
  {
    "text": "or there is also a library called the Kinesis client library you can use that",
    "start": "1073530",
    "end": "1079830"
  },
  {
    "text": "to read the data off of the Kinesis stream and then further push it down for visualization or downstream analysis",
    "start": "1079830",
    "end": "1086490"
  },
  {
    "text": "with Kinesis client library you can do ETL as well with Kinesis has this",
    "start": "1086490",
    "end": "1093180"
  },
  {
    "text": "concept called charts and within a shard the the throughput is the input can be",
    "start": "1093180",
    "end": "1100770"
  },
  {
    "text": "one megabyte per second and your output rate can be two megabytes per second so",
    "start": "1100770",
    "end": "1105990"
  },
  {
    "text": "and if you want to if your throughput is much more than what you need now you can increase the number of shards and lower",
    "start": "1105990",
    "end": "1112170"
  },
  {
    "text": "the number of charts and with that you can adjust and scale to the throughput that you need the next one I want to",
    "start": "1112170",
    "end": "1123330"
  },
  {
    "start": "1120000",
    "end": "1120000"
  },
  {
    "text": "introduce is the Amazon fire hose so when we introduce Kinesis we saw that a",
    "start": "1123330",
    "end": "1130410"
  },
  {
    "text": "lot of customers were actually you know general we're actually running the KCl",
    "start": "1130410",
    "end": "1137070"
  },
  {
    "text": "or the KCl library to kind of move their data from the stream to a persistent",
    "start": "1137070",
    "end": "1142800"
  },
  {
    "text": "data store so what we thought was why don't we do this heavy lifting for our customers so that is when we built what",
    "start": "1142800",
    "end": "1150060"
  },
  {
    "text": "is called as Kinesis firehose so with Kinesis firehose now you can",
    "start": "1150060",
    "end": "1155520"
  },
  {
    "text": "actually push the data from 2s3 redshift or Amazon Elastic such so these",
    "start": "1155520",
    "end": "1164160"
  },
  {
    "text": "are the three targets that we provide and then you can do your downstream visualization and analytics so here is",
    "start": "1164160",
    "end": "1173310"
  },
  {
    "text": "an example of Kinesis firehose pushing data into s3 so within Kinesis firehose",
    "start": "1173310",
    "end": "1179820"
  },
  {
    "text": "itself you can do transformations as well so within Kinesis firehose you can invoke a lambda function that will do",
    "start": "1179820",
    "end": "1186480"
  },
  {
    "text": "the transformation for you and Kinesis fire hose also buffers the data so",
    "start": "1186480",
    "end": "1193140"
  },
  {
    "text": "you can have a buffer between like it can buffer your data between 1 to 128",
    "start": "1193140",
    "end": "1198420"
  },
  {
    "text": "megabyte and also you can specify a buffer interval so whichever it hits first let's say if you specify a buffer",
    "start": "1198420",
    "end": "1204960"
  },
  {
    "text": "interval of 3 minutes or if you specify a buffer interval or a buffer size of",
    "start": "1204960",
    "end": "1211410"
  },
  {
    "text": "say 2 megabyte whichever it hit first based on that condition it will get triggered and your data will be getting",
    "start": "1211410",
    "end": "1218340"
  },
  {
    "text": "delivered to your target and if there is any error for some reason there is an",
    "start": "1218340",
    "end": "1224280"
  },
  {
    "text": "error in your transformation code or anything in that case it'll automatically be delivered to a backup",
    "start": "1224280",
    "end": "1230070"
  },
  {
    "text": "bucket and the the file format is what is below so it's it's kind of a time",
    "start": "1230070",
    "end": "1236580"
  },
  {
    "text": "series data that's going to get delivered and this is really good for further downstream analysis the next one",
    "start": "1236580",
    "end": "1246450"
  },
  {
    "start": "1243000",
    "end": "1243000"
  },
  {
    "text": "we're going to look at is Amazon Kinesis analytics so we saw two one was Amazon",
    "start": "1246450",
    "end": "1252750"
  },
  {
    "text": "Kinesis streams and Amazon fire hose so now as data is coming or moving through",
    "start": "1252750",
    "end": "1258900"
  },
  {
    "text": "through these Kinesis streams or through Kinesis firehose now you can run your",
    "start": "1258900",
    "end": "1264020"
  },
  {
    "text": "sequel query on top of Kinesis and then based on those analytic queries the",
    "start": "1264020",
    "end": "1270840"
  },
  {
    "text": "results can be again pushed to another stream for doing visualization and",
    "start": "1270840",
    "end": "1276050"
  },
  {
    "text": "Kinesis analytics will automatically scale for you and you don't have to",
    "start": "1276050",
    "end": "1282570"
  },
  {
    "text": "deploy any servers for doing analysis and just to say all the services that we",
    "start": "1282570",
    "end": "1289590"
  },
  {
    "text": "are talking about all our server lists and so at the end with these you will be",
    "start": "1289590",
    "end": "1295590"
  },
  {
    "text": "building a entire serverless architecture the next one i'm going to talk about is athena so for those of you",
    "start": "1295590",
    "end": "1302520"
  },
  {
    "start": "1299000",
    "end": "1299000"
  },
  {
    "text": "who don't know Athena is an is an interactive interactive querying service",
    "start": "1302520",
    "end": "1311040"
  },
  {
    "text": "right so with Athena now you can actually query the data directly from s3",
    "start": "1311040",
    "end": "1316800"
  },
  {
    "text": "and be able to we gain insights into the data you don't have so in an on-premise",
    "start": "1316800",
    "end": "1323790"
  },
  {
    "text": "or in a traditional way the way it's being done is you would",
    "start": "1323790",
    "end": "1329520"
  },
  {
    "text": "spin up a Hadoop cluster or a spark then you would run spark or hive and in order",
    "start": "1329520",
    "end": "1334920"
  },
  {
    "text": "to process your data from your persistent storage now with Athena you",
    "start": "1334920",
    "end": "1339930"
  },
  {
    "text": "don't have to spin up any clusters you only pay for what data is being scanned",
    "start": "1339930",
    "end": "1346380"
  },
  {
    "text": "so you're paying for two things the data that you're storing in s3 or your data like and then the other thing that you",
    "start": "1346380",
    "end": "1352410"
  },
  {
    "text": "are paying for is how much data that you're scanning and by using partitions",
    "start": "1352410",
    "end": "1358320"
  },
  {
    "text": "and other best practices that we will discuss further now you can actually",
    "start": "1358320",
    "end": "1364040"
  },
  {
    "text": "limit the amount of data that you're scanning and at the same time be cost",
    "start": "1364040",
    "end": "1370170"
  },
  {
    "text": "efficient next look at Amazon quick site",
    "start": "1370170",
    "end": "1377850"
  },
  {
    "text": "so quick site is a bi tool built in the cloud and for the club so and with quick",
    "start": "1377850",
    "end": "1385320"
  },
  {
    "text": "site now you can analyze your data and then you will be able to create read",
    "start": "1385320",
    "end": "1390870"
  },
  {
    "text": "only dashboards that you can share with your sales and marketing team and then be able to generate storyboards off of",
    "start": "1390870",
    "end": "1397980"
  },
  {
    "text": "that so quick site connects to with",
    "start": "1397980",
    "end": "1403980"
  },
  {
    "text": "multiple data sources so quick site has a spiced engine spice stands for super",
    "start": "1403980",
    "end": "1410760"
  },
  {
    "text": "fast parallel in-memory cache calculation engine so with spice now you",
    "start": "1410760",
    "end": "1417870"
  },
  {
    "text": "can inject you can actually schedule a ingestion you can have scheduled",
    "start": "1417870",
    "end": "1424350"
  },
  {
    "text": "ingestion whereby now you can get data at an interval from s3 or from an",
    "start": "1424350",
    "end": "1430160"
  },
  {
    "text": "database that's running on ec2 in this architecture that we are going to",
    "start": "1430160",
    "end": "1436440"
  },
  {
    "text": "propose you will be looking at where you will be using Amazon quick site to query",
    "start": "1436440",
    "end": "1442200"
  },
  {
    "text": "using Athena for the data that's living in history so if the data is an s3 you",
    "start": "1442200",
    "end": "1448200"
  },
  {
    "text": "can query either using the spice engine or you can any for a larger data set you",
    "start": "1448200",
    "end": "1453210"
  },
  {
    "text": "can actually query using Athena and with few clicks you will be able",
    "start": "1453210",
    "end": "1460150"
  },
  {
    "text": "to connect to Athena as your data source in quick sight quick site data sources",
    "start": "1460150",
    "end": "1465970"
  },
  {
    "text": "are even extended to RDS so now you can query a data that's in a relational",
    "start": "1465970",
    "end": "1472060"
  },
  {
    "text": "database or it's also extended to Amazon redshift and redshift spectrum so in",
    "start": "1472060",
    "end": "1478600"
  },
  {
    "text": "this case where your heart data lives in redshift and your cold data lives in richer spectrum now you can query the",
    "start": "1478600",
    "end": "1485710"
  },
  {
    "text": "data directly from redshift and redshift spectrum for those of you who don't know",
    "start": "1485710",
    "end": "1491080"
  },
  {
    "text": "what redshift or redshift spectrum is it is a data warehousing service provided",
    "start": "1491080",
    "end": "1496450"
  },
  {
    "text": "by AWS so I kind of spoke about analysis",
    "start": "1496450",
    "end": "1501700"
  },
  {
    "text": "but analysis is also requires one more piece which is ETL right so now with AWS",
    "start": "1501700",
    "end": "1509890"
  },
  {
    "text": "blue you don't have to spin up any servers to perform your ETL ETL stands",
    "start": "1509890",
    "end": "1516610"
  },
  {
    "text": "for extract transform and load with glue will actually can crawl your data that's",
    "start": "1516610",
    "end": "1524590"
  },
  {
    "text": "in your data leak in history and will automatically discover the schema and not only it will discover the schema but",
    "start": "1524590",
    "end": "1532420"
  },
  {
    "text": "it will automatically generate the ETL code for you so and the code is actually",
    "start": "1532420",
    "end": "1538150"
  },
  {
    "text": "generated in Python pi spark so you can write your Python code on Apache spark",
    "start": "1538150",
    "end": "1543790"
  },
  {
    "text": "2.1 and it also integrates well with all the different analytic services on the",
    "start": "1543790",
    "end": "1550750"
  },
  {
    "text": "AWS platform so for a data catalog that is in glue it will integrate with EMR it",
    "start": "1550750",
    "end": "1558820"
  },
  {
    "text": "will integrate with attina it also integrates with spectrum and all the other analytical tools that we have and",
    "start": "1558820",
    "end": "1567820"
  },
  {
    "text": "for those of you who don't know what a glue data catalog contains is a glue data catalog contains metadata or",
    "start": "1567820",
    "end": "1574980"
  },
  {
    "text": "metadata about the schema the location where the data exists and as well as it",
    "start": "1574980",
    "end": "1581170"
  },
  {
    "text": "contains information about the partition",
    "start": "1581170",
    "end": "1586290"
  },
  {
    "start": "1586000",
    "end": "1586000"
  },
  {
    "text": "Blue has three components so the first one is the data catalog as I mentioned the data catalog is where you it's you",
    "start": "1586580",
    "end": "1594260"
  },
  {
    "text": "can the for those of you who know it's a hive compatible man it's kind of a hive compatible meta store with enhanced",
    "start": "1594260",
    "end": "1600049"
  },
  {
    "text": "functionality and it can and with the data catalog now you can crawl your data",
    "start": "1600049",
    "end": "1605750"
  },
  {
    "text": "in s3 and disk you can if let's say if you have a proprietary format now you",
    "start": "1605750",
    "end": "1612289"
  },
  {
    "text": "can crawl your data automatically and extract the metadata so if you have a",
    "start": "1612289",
    "end": "1618799"
  },
  {
    "text": "proprietary format then you can write your custom crawlers but for all the other open standards that are there",
    "start": "1618799",
    "end": "1626230"
  },
  {
    "text": "Glu will automatically discover what the schema is and then now you can author",
    "start": "1626230",
    "end": "1632899"
  },
  {
    "text": "and execute ETL jobs so you can schedule ETL jobs or you can even author jobs",
    "start": "1632899",
    "end": "1639590"
  },
  {
    "text": "using glue and you don't have to spin up a single server for any of this so what",
    "start": "1639590",
    "end": "1645710"
  },
  {
    "text": "essentially happens is with this framework with all using these services we have built a end-to-end data",
    "start": "1645710",
    "end": "1654830"
  },
  {
    "text": "analytics pipeline whereby now when your front access logs get delivered to your",
    "start": "1654830",
    "end": "1660409"
  },
  {
    "text": "s3 bucket now you don't have to spin up service you don't have to monitor service you don't have to hug your",
    "start": "1660409",
    "end": "1667220"
  },
  {
    "text": "servers so and you will only pay for what you query so with that I'm going to",
    "start": "1667220",
    "end": "1674539"
  },
  {
    "text": "hand it over to Joseph all right thank",
    "start": "1674539",
    "end": "1679669"
  },
  {
    "text": "you Jeff thanks so so now you guys have",
    "start": "1679669",
    "end": "1685940"
  },
  {
    "text": "a good overview of Cloud Print you have an overview of our access logs a brief",
    "start": "1685940",
    "end": "1692899"
  },
  {
    "text": "overview of our access logs and a good overview of the different Amazon and AWS",
    "start": "1692899",
    "end": "1698090"
  },
  {
    "text": "services that will allow you to build a server list reporting and analytics pipeline I'm gonna give you a little bit",
    "start": "1698090",
    "end": "1706070"
  },
  {
    "text": "of a deeper dive into what cloud Front provides out-of-the-box based on these access hogs and from that",
    "start": "1706070",
    "end": "1714409"
  },
  {
    "text": "hopefully you can get some idea of how you can leverage the data that's in the access logs for your",
    "start": "1714409",
    "end": "1721790"
  },
  {
    "text": "own benefit so out-of-the-box Amazon CloudFront provides five reports for you",
    "start": "1721790",
    "end": "1730720"
  },
  {
    "start": "1723000",
    "end": "1723000"
  },
  {
    "text": "these reports are designed to provide some insight into the viewer requests",
    "start": "1730720",
    "end": "1736610"
  },
  {
    "text": "that are landing on our edge locations and are intended for your your",
    "start": "1736610",
    "end": "1742250"
  },
  {
    "text": "application or your service four of these reports are based directly off of",
    "start": "1742250",
    "end": "1747830"
  },
  {
    "text": "the access logs themselves the access logs are the raw the raw data the fifth report the usage report is actually",
    "start": "1747830",
    "end": "1755960"
  },
  {
    "text": "shares a data source with the AWS usage report that can be found in the billing",
    "start": "1755960",
    "end": "1763070"
  },
  {
    "text": "console so where the access logs are",
    "start": "1763070",
    "end": "1771100"
  },
  {
    "text": "generally available to you in your s3 bucket about 10 to 15 minutes after the",
    "start": "1771100",
    "end": "1776210"
  },
  {
    "text": "request lands on a an edge location these reports are available for the last",
    "start": "1776210",
    "end": "1782929"
  },
  {
    "text": "hour going back 60 days so they're available in the console in the",
    "start": "1782929",
    "end": "1788660"
  },
  {
    "text": "reporting cloud run console for the last 60 days the intent of these reports are",
    "start": "1788660",
    "end": "1794630"
  },
  {
    "text": "to provide you with an accurate historical view of your service or your",
    "start": "1794630",
    "end": "1800870"
  },
  {
    "text": "application and the viewers that are using this your customers if you do want",
    "start": "1800870",
    "end": "1807500"
  },
  {
    "text": "to maintain this data to persist this data for longer you have a couple of different options the first is that you",
    "start": "1807500",
    "end": "1814250"
  },
  {
    "text": "can export this to CSV and you will get exactly the data that we have in the",
    "start": "1814250",
    "end": "1821210"
  },
  {
    "text": "reports and the other is of course the access logs themselves you just turn on you enable your access logs in the cloud",
    "start": "1821210",
    "end": "1828980"
  },
  {
    "text": "for our console and they'll be delivered to the s3 bucket of your choice",
    "start": "1828980",
    "end": "1834130"
  },
  {
    "start": "1835000",
    "end": "1835000"
  },
  {
    "text": "also provides you with six operational metrics these are near real-time metrics",
    "start": "1836930",
    "end": "1842330"
  },
  {
    "text": "that are intended to give you a right",
    "start": "1842330",
    "end": "1847670"
  },
  {
    "text": "now view of what's happening in your service for example using the one-minute",
    "start": "1847670",
    "end": "1853390"
  },
  {
    "text": "granularity for these metrics these metrics are available to you about two minutes after the the request lands on",
    "start": "1853390",
    "end": "1861670"
  },
  {
    "text": "lands on ours our servers one minute to aggregate the data and one minute to",
    "start": "1861670",
    "end": "1867800"
  },
  {
    "text": "ship it to cog watch these metrics are available in the cloud front console and",
    "start": "1867800",
    "end": "1873500"
  },
  {
    "text": "the cloud watch console and we monitor things like requests and your bytes",
    "start": "1873500",
    "end": "1878840"
  },
  {
    "text": "downloaded and your error rate because it is a cloud watch metric you get all",
    "start": "1878840",
    "end": "1886850"
  },
  {
    "start": "1882000",
    "end": "1882000"
  },
  {
    "text": "the benefits of cloud watch as well so for example you can set alarms on these",
    "start": "1886850",
    "end": "1895550"
  },
  {
    "text": "metrics and have them when they exceed a threshold have them notify you through",
    "start": "1895550",
    "end": "1901160"
  },
  {
    "text": "something like SNS and that'll will allow you to react to the events that",
    "start": "1901160",
    "end": "1906230"
  },
  {
    "text": "are happening on your service right now the idea behind all of this is for",
    "start": "1906230",
    "end": "1911350"
  },
  {
    "text": "operational monitoring where as the",
    "start": "1911350",
    "end": "1920540"
  },
  {
    "text": "metrics are meant for operational monitoring the reports that I talked about are more for that operational",
    "start": "1920540",
    "end": "1925910"
  },
  {
    "text": "analysis they do ultimately share the same data source it's the requests that are landing on on",
    "start": "1925910",
    "end": "1933110"
  },
  {
    "text": "our hosts and are intended for your your application so here you can see a cloud",
    "start": "1933110",
    "end": "1939620"
  },
  {
    "text": "watch on the left and our usage report on the right and they're both showing",
    "start": "1939620",
    "end": "1945740"
  },
  {
    "text": "you roughly the same information who are showing you requests and we're showing you data transfer as an example and you",
    "start": "1945740",
    "end": "1951620"
  },
  {
    "text": "can see that the pattern is the same I'm showing you different granularities which is why you know you get the peaks",
    "start": "1951620",
    "end": "1959000"
  },
  {
    "text": "and valleys in the one and you don't and it's a little bit smoother and the other side.now while they're the same they do",
    "start": "1959000",
    "end": "1965960"
  },
  {
    "text": "go through a different set of processing and therefore there can be some discrepancies between the two in the",
    "start": "1965960",
    "end": "1973550"
  },
  {
    "text": "presentation of this data then one is meant for real time and one is meant for a historical view I'd also like to point",
    "start": "1973550",
    "end": "1981260"
  },
  {
    "text": "out a couple of differences and this is where you start to see what those access",
    "start": "1981260",
    "end": "1986870"
  },
  {
    "text": "logs can give you while this is relatively a basic report the usage",
    "start": "1986870",
    "end": "1992210"
  },
  {
    "text": "report it still gives you a bit more of a view into your service we're not just",
    "start": "1992210",
    "end": "1998090"
  },
  {
    "text": "showing you account of your request we're showing you account of your requests broken down by for example protocol",
    "start": "1998090",
    "end": "2005200"
  },
  {
    "text": "we've also you can see at the top you can see that we break this down by billing region so now you're starting to",
    "start": "2005200",
    "end": "2011620"
  },
  {
    "start": "2010000",
    "end": "2010000"
  },
  {
    "text": "see how you can dive a little bit further into this this information by looking at your billing region you can",
    "start": "2011620",
    "end": "2018250"
  },
  {
    "text": "see how your usage varies on the billing region and that might help you for example decide on what price class you",
    "start": "2018250",
    "end": "2025570"
  },
  {
    "text": "might want to to use staying with",
    "start": "2025570",
    "end": "2031290"
  },
  {
    "text": "operational analysis for a moment here you have the cash stats report and you have the usage report cash stats is",
    "start": "2031290",
    "end": "2038800"
  },
  {
    "text": "meant to kind of tell you the performance of the cash and we're going to tell you about your hits and your misses",
    "start": "2038800",
    "end": "2044050"
  },
  {
    "text": "I just wanted to I'm using this example to show you an event that happened on",
    "start": "2044050",
    "end": "2050649"
  },
  {
    "text": "October 25th on October 25th you see an increase in total bytes to the viewers",
    "start": "2050650",
    "end": "2056980"
  },
  {
    "text": "and perhaps you've already had a cloud front metric and operational metric fire",
    "start": "2056980",
    "end": "2062290"
  },
  {
    "text": "and alarm and tell you this and now you're looking back at it and figuring out well what what happened looking at",
    "start": "2062290",
    "end": "2068740"
  },
  {
    "text": "these reports you can see that you also have an increase in misses you can see",
    "start": "2068740",
    "end": "2074139"
  },
  {
    "text": "that you have an increase in 5-xx errors and this is starting to give you a sense",
    "start": "2074140",
    "end": "2079330"
  },
  {
    "text": "of what you can what information you can glean from these these access logs",
    "start": "2079330",
    "end": "2085530"
  },
  {
    "text": "taking a look at the the usage report you see the same the same spike and you",
    "start": "2085530",
    "end": "2092010"
  },
  {
    "text": "can start to correlate the data and tell you where to go look to find out what",
    "start": "2092010",
    "end": "2097600"
  },
  {
    "text": "happened we also have three additional three",
    "start": "2097600",
    "end": "2107440"
  },
  {
    "text": "additional reports we have the top referrers report which will show you the top 25 refers and it will show you the",
    "start": "2107440",
    "end": "2114759"
  },
  {
    "text": "number of requests and how they relates to the other refers we have the",
    "start": "2114759",
    "end": "2119920"
  },
  {
    "text": "conference viewers report which actually digs into the user agent string and to",
    "start": "2119920",
    "end": "2125950"
  },
  {
    "text": "the viewer IP the source IP addresses and this is going to be used both for an",
    "start": "2125950",
    "end": "2132190"
  },
  {
    "text": "operational point of view and also for maybe a content optimization or a sales",
    "start": "2132190",
    "end": "2138729"
  },
  {
    "text": "and marketing point of view because now you are able to get a view pardon the",
    "start": "2138729",
    "end": "2144130"
  },
  {
    "text": "pun you are able to get a view of your viewers who they are what browsers",
    "start": "2144130",
    "end": "2150489"
  },
  {
    "text": "they're using what devices they're using and maybe that now you can make some business decisions about what your what",
    "start": "2150489",
    "end": "2158559"
  },
  {
    "text": "your actual audience is who is actually using using your service the location",
    "start": "2158559",
    "end": "2164680"
  },
  {
    "text": "report uses IP to figure out where the viewers are coming from and you can",
    "start": "2164680",
    "end": "2171489"
  },
  {
    "text": "compare our location report allows you to compare the different locations we're going to show you the top 50 locations",
    "start": "2171489",
    "end": "2177819"
  },
  {
    "text": "top 50 countries or US US states the",
    "start": "2177819",
    "end": "2183519"
  },
  {
    "text": "popular object report is a good report to get an idea of the objects your",
    "start": "2183519",
    "end": "2190180"
  },
  {
    "text": "hottest objects we show you the top 50 popular objects and we're going to break",
    "start": "2190180",
    "end": "2195640"
  },
  {
    "text": "that down into the number of requests for that particular object the number of",
    "start": "2195640",
    "end": "2200829"
  },
  {
    "text": "hits the number of misses and now you can start to see what those viewers are",
    "start": "2200829",
    "end": "2205960"
  },
  {
    "text": "actually looking at I did want to caution one one thing on this particular",
    "start": "2205960",
    "end": "2211809"
  },
  {
    "text": "report we show you the top 50 we tracked the top 150 we don't track every single",
    "start": "2211809",
    "end": "2219309"
  },
  {
    "text": "one of your objects and as such this is an estimation so for certain use cases",
    "start": "2219309",
    "end": "2227609"
  },
  {
    "text": "this estimation can lead to an margin of error however",
    "start": "2227609",
    "end": "2233690"
  },
  {
    "text": "because this is all based off of the access logs we also give you that raw data that you can use to get a perfectly",
    "start": "2233690",
    "end": "2241490"
  },
  {
    "text": "accurate view of your popular objects should you choose and that kind of leads",
    "start": "2241490",
    "end": "2251270"
  },
  {
    "text": "into the next thing I wanted to say which was which is that these reports",
    "start": "2251270",
    "end": "2258920"
  },
  {
    "text": "that we have are just the tip of the iceberg it's just meant to give you some kind of idea of what you can look at and",
    "start": "2258920",
    "end": "2267890"
  },
  {
    "text": "what information you can glean from the data that we collect on your behalf so",
    "start": "2267890",
    "end": "2273700"
  },
  {
    "text": "how do you actually get more information out of this and how do you turn this raw",
    "start": "2273700",
    "end": "2281630"
  },
  {
    "text": "data that is the access logs into something more meaningful than maybe you",
    "start": "2281630",
    "end": "2287450"
  },
  {
    "text": "would end up using something like quick cite which we've described to prepare your data and analyze it and to create",
    "start": "2287450",
    "end": "2294140"
  },
  {
    "text": "some visualizations that can be used for your your operations or can be used for",
    "start": "2294140",
    "end": "2299210"
  },
  {
    "text": "your sales and marketing or your business execs I'm going to show you one",
    "start": "2299210",
    "end": "2307930"
  },
  {
    "text": "simple way to do this as you saw from Rajiv's slides there we at Amazon in AWS",
    "start": "2307930",
    "end": "2315650"
  },
  {
    "text": "have a lot of different tools that you can use and you can stitch together in",
    "start": "2315650",
    "end": "2320720"
  },
  {
    "text": "some fashion to perform this analysis I wanted to show you this one which is",
    "start": "2320720",
    "end": "2327950"
  },
  {
    "text": "very simple hopefully you'll see very simple to setup and simple to use and",
    "start": "2327950",
    "end": "2334790"
  },
  {
    "text": "hopefully you can see the benefit of that our access logs as I said are",
    "start": "2334790",
    "end": "2339800"
  },
  {
    "text": "delivered every 10 or 15 minutes to Amazon s3 you can set up glu AWS clue to",
    "start": "2339800",
    "end": "2348260"
  },
  {
    "text": "crawl that data source and it's going to discover those logs in your s3 bucket",
    "start": "2348260",
    "end": "2353420"
  },
  {
    "text": "it's going to create a catalog for you and that catalog is now available to Athena Athena was then used to query",
    "start": "2353420",
    "end": "2362260"
  },
  {
    "text": "back to query those buckets and pull that data right out of the",
    "start": "2362260",
    "end": "2367650"
  },
  {
    "text": "right under the log files that we have there and then because quick site is built on top of it thena uses Athena as",
    "start": "2367650",
    "end": "2373829"
  },
  {
    "text": "a data source all that information is now available for those visualizations that analysis that quick site allows you",
    "start": "2373829",
    "end": "2380670"
  },
  {
    "text": "to do and it really is that simple and the other benefit is that it's it's",
    "start": "2380670",
    "end": "2387690"
  },
  {
    "text": "servantless now I'm hoping that you guys",
    "start": "2387690",
    "end": "2392970"
  },
  {
    "start": "2391000",
    "end": "2391000"
  },
  {
    "text": "kind of understand the benefits because the benefits are dependent upon your",
    "start": "2392970",
    "end": "2398070"
  },
  {
    "text": "your use case why would you want to turn this data into into something more",
    "start": "2398070",
    "end": "2405240"
  },
  {
    "text": "meaningful here are a couple of couple of examples but definitely not an exhaustive list first it's going to give",
    "start": "2405240",
    "end": "2413220"
  },
  {
    "text": "you a deeper insight into your service into your application into your viewers",
    "start": "2413220",
    "end": "2418619"
  },
  {
    "text": "than what we provide with our with our default out-of-the-box reports you're",
    "start": "2418619",
    "end": "2423990"
  },
  {
    "text": "going to be able to create your own customized reports maybe dive deeper into those status codes that we have",
    "start": "2423990",
    "end": "2430260"
  },
  {
    "text": "those for xx we only show you for xx maybe you want to see 404s compared to",
    "start": "2430260",
    "end": "2435329"
  },
  {
    "text": "403 so you can start to correlate this data so not only are you looking into",
    "start": "2435329",
    "end": "2441660"
  },
  {
    "text": "the error rates but you're looking into the error rates and you're breaking it down per region we give you the edge",
    "start": "2441660",
    "end": "2447420"
  },
  {
    "text": "locations in the access logs so now you can actually see how these viewer data",
    "start": "2447420",
    "end": "2453540"
  },
  {
    "text": "flows through the Cloud Print Network and maybe you can correlate that with",
    "start": "2453540",
    "end": "2458900"
  },
  {
    "text": "viewer behavior or error rates or whatever and then there you can start to",
    "start": "2458900",
    "end": "2464640"
  },
  {
    "text": "make decisions on these correlation correlations that you are gleaning to",
    "start": "2464640",
    "end": "2470339"
  },
  {
    "text": "optimize your your cache maybe you now discover that Firefox is the most",
    "start": "2470339",
    "end": "2476490"
  },
  {
    "text": "popular browser in China and you want to",
    "start": "2476490",
    "end": "2482000"
  },
  {
    "text": "Asia and you want to start targeting targeting your application for that",
    "start": "2482000",
    "end": "2489030"
  },
  {
    "text": "particular viewer use case or for those particular objects",
    "start": "2489030",
    "end": "2494910"
  },
  {
    "text": "sales and marketing can use this information to mine the viewer data that we provide and to mine the Geo data to",
    "start": "2494910",
    "end": "2501510"
  },
  {
    "text": "really get a good deep understanding of who your viewers are and what they want and maybe even what problems are they're",
    "start": "2501510",
    "end": "2508170"
  },
  {
    "text": "coming up against now this is kind of telling you the benefits of of what",
    "start": "2508170",
    "end": "2516210"
  },
  {
    "text": "information is there and what you what you can glean from turning this data",
    "start": "2516210",
    "end": "2522030"
  },
  {
    "text": "into this information but I think that the one of the most powerful things that can happen from this is your ability to",
    "start": "2522030",
    "end": "2529620"
  },
  {
    "text": "take action on this information and I'm",
    "start": "2529620",
    "end": "2534750"
  },
  {
    "text": "going to turn this over to psy and he's going to tell you how to take this information that you've now gathered and",
    "start": "2534750",
    "end": "2539940"
  },
  {
    "text": "turned it into an action thank you okay",
    "start": "2539940",
    "end": "2549600"
  },
  {
    "text": "so from what Joseph already mentioned there are multiple posts that we can",
    "start": "2549600",
    "end": "2554910"
  },
  {
    "text": "focus on who are the top talkers what are the most popular objects what are my most popular pops",
    "start": "2554910",
    "end": "2562440"
  },
  {
    "text": "what sort of caching behavior do I have so these are all good reports I think",
    "start": "2562440",
    "end": "2568950"
  },
  {
    "text": "there are more reports that we can actually generate and analyze I personally am a data guy so the more the",
    "start": "2568950",
    "end": "2575160"
  },
  {
    "text": "data that I get I actually start running more analysis and I'd like more insights but for this use case for this section",
    "start": "2575160",
    "end": "2582540"
  },
  {
    "text": "will actually focus on border tection and mitigation the idea here would be not just are we taking a look at the",
    "start": "2582540",
    "end": "2589860"
  },
  {
    "text": "data what is the easiest way to analyze the data extract an insight and also",
    "start": "2589860",
    "end": "2595890"
  },
  {
    "text": "respond to that sort of insight right so a good amount of time maybe I actually have known users or reliable users that",
    "start": "2595890",
    "end": "2605970"
  },
  {
    "text": "are actually accessing my content but what if I actually get hit by an",
    "start": "2605970",
    "end": "2611220"
  },
  {
    "text": "unreliable user or maybe even a bot at that point I really won't understand",
    "start": "2611220",
    "end": "2616380"
  },
  {
    "text": "where this data is coming from what is the pattern of axis right so we actually",
    "start": "2616380",
    "end": "2622950"
  },
  {
    "text": "take an approach of how simple or how can we actually simplify this",
    "start": "2622950",
    "end": "2628910"
  },
  {
    "text": "sort of process rather than me as a user running the fleet of servers to detect",
    "start": "2628910",
    "end": "2635329"
  },
  {
    "text": "these sort of things beat on a batch basis or bid on a real-time or close to",
    "start": "2635329",
    "end": "2640369"
  },
  {
    "text": "real-time or even an online basis and then even build up my own incident response strategy before we get into the",
    "start": "2640369",
    "end": "2648880"
  },
  {
    "text": "detection piece in the mitigation PC it's a very simple example where we have",
    "start": "2648880",
    "end": "2654049"
  },
  {
    "text": "a bat bot that's coming in and we understand that this is a bad bot given",
    "start": "2654049",
    "end": "2659989"
  },
  {
    "text": "that they've already identified this and maybe even label this and as the data comes in I take a look at the user agent",
    "start": "2659989",
    "end": "2667210"
  },
  {
    "text": "once the request hits CloudFront the request is passed to aw swath Wharf",
    "start": "2667210",
    "end": "2674029"
  },
  {
    "text": "Dick's look at all the ecl's that are available if the ACL says this",
    "start": "2674029",
    "end": "2679190"
  },
  {
    "text": "guy's a bad guy or a certain bad pattern I would take this sort of response to",
    "start": "2679190",
    "end": "2684259"
  },
  {
    "text": "either block it or to redirect it having said that there are multiple other ways",
    "start": "2684259",
    "end": "2689839"
  },
  {
    "text": "to detect abort right so there probably could be IP range patterns that we",
    "start": "2689839",
    "end": "2695029"
  },
  {
    "text": "already have they could be predefined baud signatures that we want to monitor they could even",
    "start": "2695029",
    "end": "2701299"
  },
  {
    "text": "be more convoluted bot patterns where if within a minute I have requests coming",
    "start": "2701299",
    "end": "2707960"
  },
  {
    "text": "in from same board with a same IP rain IP address or even an IP Sider at that",
    "start": "2707960",
    "end": "2714469"
  },
  {
    "text": "point I'd actually react and start redirecting that contact so how does",
    "start": "2714469",
    "end": "2720589"
  },
  {
    "start": "2719000",
    "end": "2719000"
  },
  {
    "text": "this how does that really work users are accessing the content the first request",
    "start": "2720589",
    "end": "2726650"
  },
  {
    "text": "would always end up on the CDN the CDN is taking the data in the headers and",
    "start": "2726650",
    "end": "2732920"
  },
  {
    "text": "then it would pass pass on the header Tawaf guav starts taking a look at it all this would be monitored and the",
    "start": "2732920",
    "end": "2741859"
  },
  {
    "text": "metrics are sent to Amazon CloudWatch after a little bit of time a few minutes",
    "start": "2741859",
    "end": "2747950"
  },
  {
    "text": "these requests start they're flushed into logs these access logs make their",
    "start": "2747950",
    "end": "2754640"
  },
  {
    "text": "way to Amazon s3 now well these logs have good information such as the date in",
    "start": "2754640",
    "end": "2765220"
  },
  {
    "text": "time when request was completed the pop that was used to respond to this request",
    "start": "2765220",
    "end": "2772560"
  },
  {
    "text": "the HTTP access methods that were used for a certain request the user agent",
    "start": "2772560",
    "end": "2779040"
  },
  {
    "text": "many other fields are populated via these are provided via these sort of",
    "start": "2779040",
    "end": "2785520"
  },
  {
    "text": "access logs but I think one key element that we be looking for would be work is",
    "start": "2785520",
    "end": "2791590"
  },
  {
    "text": "the IP address work is the user agent what is the date and time when a certain",
    "start": "2791590",
    "end": "2797710"
  },
  {
    "text": "request was completed now once these logs are delivered to Amazon s3 then we",
    "start": "2797710",
    "end": "2805570"
  },
  {
    "text": "can start either preparing the logs or directly analyzing the logs now 9 out of",
    "start": "2805570",
    "end": "2813070"
  },
  {
    "text": "10 times there would be some amount of preparation that we might want to think about think about the scenario where I",
    "start": "2813070",
    "end": "2819730"
  },
  {
    "text": "am the customer I actually have a lot of distributions across a region or within",
    "start": "2819730",
    "end": "2828480"
  },
  {
    "text": "or across the world or within a region CloudFront would deliver the locks and",
    "start": "2828480",
    "end": "2835090"
  },
  {
    "text": "the file name format would always carry the distribution ID so in this case if",
    "start": "2835090",
    "end": "2841240"
  },
  {
    "text": "you actually want to add that distribution ID for the locks we can trigger a lambda B s3 notification and",
    "start": "2841240",
    "end": "2847450"
  },
  {
    "text": "start adding that data taking this further I might even start building my",
    "start": "2847450",
    "end": "2854110"
  },
  {
    "text": "own ETL transformation pieces into it",
    "start": "2854110",
    "end": "2859390"
  },
  {
    "text": "what if I want to build a binary classifier or what if I want to build a multi label classifier where I actually",
    "start": "2859390",
    "end": "2866680"
  },
  {
    "text": "look at patterns that are coming in I already have a model that I could load up on to lambda and lambda in itself",
    "start": "2866680",
    "end": "2873010"
  },
  {
    "text": "would classify the data before it sends the data out one option that we have is",
    "start": "2873010",
    "end": "2879010"
  },
  {
    "text": "every record or every set of records that are flowing into lambda can be flushed onto s3 but how do we access",
    "start": "2879010",
    "end": "2887770"
  },
  {
    "text": "this data is very important when we use either something like an EMR or an Athena or user red ship the",
    "start": "2887770",
    "end": "2895569"
  },
  {
    "text": "recommendation would normally be understand your split size if we actually have too many files that are",
    "start": "2895569",
    "end": "2902109"
  },
  {
    "text": "being pushed to s3 and Athena has to read all of those files at that point there'll be multiple containers or",
    "start": "2902109",
    "end": "2908829"
  },
  {
    "text": "multiple executors or multiple mappers that are actually loaded and pulling this data and the cost of building on",
    "start": "2908829",
    "end": "2915730"
  },
  {
    "text": "each star each task or each mapper sometimes would be around five to twenty seconds so understanding what sort of",
    "start": "2915730",
    "end": "2922150"
  },
  {
    "text": "data access patterns do we have is very necessary before we start splitting the data to disk so as the data grows the",
    "start": "2922150",
    "end": "2930819"
  },
  {
    "text": "recommendation that we have actually noticed that helps is lot would be send",
    "start": "2930819",
    "end": "2936190"
  },
  {
    "text": "the data over to Kinesis firehose what Canisius Pharos here would do is aggregate the data on a time basis so",
    "start": "2936190",
    "end": "2945339"
  },
  {
    "text": "depending on how how quickly do we want to analyze the data you could either go begin from 501 minute or even go up to",
    "start": "2945339",
    "end": "2953759"
  },
  {
    "text": "much larger time period so that you actually are building this sort of time blocks but the object sizes would",
    "start": "2953759",
    "end": "2960910"
  },
  {
    "text": "actually be bigger once we have the data on s3 we can then start running our",
    "start": "2960910",
    "end": "2968619"
  },
  {
    "text": "analysis to see what sort of patterns are we noticing",
    "start": "2968619",
    "end": "2974489"
  },
  {
    "text": "once we notice these patterns and assuming we actually find a certain bot",
    "start": "2974910",
    "end": "2981009"
  },
  {
    "text": "pattern or or unreliable signature at that point the next thing would be how",
    "start": "2981009",
    "end": "2988539"
  },
  {
    "text": "do we respond to this incident we either have to go back to off and use the",
    "start": "2988539",
    "end": "2993970"
  },
  {
    "text": "create rule API build an ACL and make sure that the ACL is applied but this",
    "start": "2993970",
    "end": "3002670"
  },
  {
    "text": "sort of a batch analysis needs to be done maybe once every day or could even",
    "start": "3002670",
    "end": "3007920"
  },
  {
    "text": "be done every hour depending on how many what sort of a bot traffic do we have a",
    "start": "3007920",
    "end": "3013279"
  },
  {
    "text": "question here would be this sort of batch analysis is good but to build a",
    "start": "3013279",
    "end": "3018329"
  },
  {
    "text": "much maker much quicker continuous response strategy should we think a",
    "start": "3018329",
    "end": "3025180"
  },
  {
    "text": "little further and how about make it a little bit more of an online process so",
    "start": "3025180",
    "end": "3031480"
  },
  {
    "start": "3031000",
    "end": "3031000"
  },
  {
    "text": "for an online personal online analysis where do we fork the process we are we",
    "start": "3031480",
    "end": "3038530"
  },
  {
    "text": "have data living in Kinesis Pharaohs already so how about we start running",
    "start": "3038530",
    "end": "3044770"
  },
  {
    "text": "analytics using kanesha Amazon Kinesis analytics using sequel or using standard",
    "start": "3044770",
    "end": "3050590"
  },
  {
    "text": "sequel queries we can now start looking at what sort of patterns do we get and",
    "start": "3050590",
    "end": "3055990"
  },
  {
    "text": "as long as we have taken enough measures in preparing the data running sequel",
    "start": "3055990",
    "end": "3063040"
  },
  {
    "text": "with Canisius analytics would be very simple once we realize that there is",
    "start": "3063040",
    "end": "3070630"
  },
  {
    "text": "there are some bad BOTS signatures at that point our incident response",
    "start": "3070630",
    "end": "3076480"
  },
  {
    "text": "strategy would begin Canisius analytics can push the data into or in this case",
    "start": "3076480",
    "end": "3082840"
  },
  {
    "text": "the outliers into Kinesis streams and then we can trigger a lambda against the",
    "start": "3082840",
    "end": "3089890"
  },
  {
    "text": "tennessee streams and build the response strategy how'd that look like so in this",
    "start": "3089890",
    "end": "3096640"
  },
  {
    "text": "case they've identified that there is a bot signature we understand what the bot",
    "start": "3096640",
    "end": "3102880"
  },
  {
    "text": "signature is it could be a combination it could it could just be a user agent or it could even be a combination of an",
    "start": "3102880",
    "end": "3108820"
  },
  {
    "text": "IP address and a user agent and this using the Java SDK or Mbutu 3 we can",
    "start": "3108820",
    "end": "3116350"
  },
  {
    "text": "update the wofe and make a request saying that hey add this new web ACL and",
    "start": "3116350",
    "end": "3122340"
  },
  {
    "text": "use this web ACL from her on putting",
    "start": "3122340",
    "end": "3128740"
  },
  {
    "text": "things together do we have to use if I were given an opportunity to pick",
    "start": "3128740",
    "end": "3134980"
  },
  {
    "text": "between batch analysis and an online analysis I probably reasonable further",
    "start": "3134980",
    "end": "3141220"
  },
  {
    "text": "inside need both right so irrespective of how quickly I go back and update or",
    "start": "3141220",
    "end": "3147310"
  },
  {
    "text": "even analyze my data I still would want to do some sort of batch analysis so",
    "start": "3147310",
    "end": "3152650"
  },
  {
    "text": "that I can update my models machine learning model or update my rules if I'm using standard sequel the",
    "start": "3152650",
    "end": "3161890"
  },
  {
    "text": "next thing would be if there is a necessity to build a dashboard who are",
    "start": "3161890",
    "end": "3167770"
  },
  {
    "text": "the top talkers where are the bad BOTS coming from what sort of IP ranges are we seeing what sort of fluctuations do we see what",
    "start": "3167770",
    "end": "3174220"
  },
  {
    "text": "at what point do certain bad BOTS headers from a certain geo for these",
    "start": "3174220",
    "end": "3180180"
  },
  {
    "text": "recommendations would be to build your dashboards they could be operational",
    "start": "3180180",
    "end": "3185590"
  },
  {
    "text": "dashboard from they could just be reports who could either use Amazon quick side or we could use plastic search while building this sort of an",
    "start": "3185590",
    "end": "3194920"
  },
  {
    "text": "architecture there are a few best practices that we have come across and these pretty much apply even outside of",
    "start": "3194920",
    "end": "3202240"
  },
  {
    "text": "this architecture but these normally have helped us while implementing this",
    "start": "3202240",
    "end": "3208410"
  },
  {
    "text": "when it comes to data partitioning is always a good practice there might be",
    "start": "3208410",
    "end": "3216850"
  },
  {
    "text": "certain use case where I want to query all of the data that I have had since my",
    "start": "3216850",
    "end": "3222700"
  },
  {
    "text": "app has gotten to production but for certain scenarios I just want to understand what happened in the last day",
    "start": "3222700",
    "end": "3229450"
  },
  {
    "text": "or what has happened in the last hour for this sort of a scenario where we are",
    "start": "3229450",
    "end": "3235930"
  },
  {
    "text": "charged based on how much data gets scanned per query a recommendation would",
    "start": "3235930",
    "end": "3243760"
  },
  {
    "text": "be partitioning would help you write so the amount of data that's being scanned",
    "start": "3243760",
    "end": "3248800"
  },
  {
    "text": "would be less at the same time using compression or even coming up with the",
    "start": "3248800",
    "end": "3254980"
  },
  {
    "text": "right compression strategy is another recommendation most of these analyses",
    "start": "3254980",
    "end": "3261160"
  },
  {
    "text": "wouldn't need all the all the columns where we have to scan all the columns",
    "start": "3261160",
    "end": "3267870"
  },
  {
    "text": "where they actually are coming back so syncing columnar formats is also",
    "start": "3267870",
    "end": "3273100"
  },
  {
    "text": "recommended so columnar format such as apache park' or apache or she is",
    "start": "3273100",
    "end": "3279100"
  },
  {
    "text": "recommended using columnar format we only bring the columns that are necessary and we are not running a whole",
    "start": "3279100",
    "end": "3286450"
  },
  {
    "text": "table scan or a file scan in this case coming to lambda it's always recommended",
    "start": "3286450",
    "end": "3294519"
  },
  {
    "start": "3290000",
    "end": "3290000"
  },
  {
    "text": "to use environmental variables as we actually pass the operational parameters say the name of the stream it could be",
    "start": "3294519",
    "end": "3301599"
  },
  {
    "text": "different from your dev to test to prod so always operationalizing this and",
    "start": "3301599",
    "end": "3307480"
  },
  {
    "text": "using environmental variables is recommended one thing that I have personally run into while implementing",
    "start": "3307480",
    "end": "3313750"
  },
  {
    "text": "this is testing it with different batches in record sizes there have been",
    "start": "3313750",
    "end": "3319630"
  },
  {
    "text": "certain scenarios where my lambda function works in ninety or cases but it will fail in like a few cases those are",
    "start": "3319630",
    "end": "3328779"
  },
  {
    "text": "the scenarios where either the bat size is pretty big or the record size or the file size would be big so identifying",
    "start": "3328779",
    "end": "3334869"
  },
  {
    "text": "what is the memory the we actually won't need or the view that we'll need is very",
    "start": "3334869",
    "end": "3341049"
  },
  {
    "text": "important security again is job zero so using the most restrictive permissions",
    "start": "3341049",
    "end": "3348339"
  },
  {
    "text": "when setting up IM policies either for lambda or for fire rows are recommended",
    "start": "3348339",
    "end": "3357240"
  },
  {
    "text": "finally setting up flood watch alarms is always recommended as an example if we",
    "start": "3357299",
    "end": "3363819"
  },
  {
    "text": "have Kinesis analytics that is processing the data from either a fire",
    "start": "3363819",
    "end": "3370930"
  },
  {
    "text": "hose delivery stream or from Kenichi streams understanding what sort of input/output bytes are we processing or",
    "start": "3370930",
    "end": "3378069"
  },
  {
    "text": "even the number of Records the view processing is necessary at the same time",
    "start": "3378069",
    "end": "3383200"
  },
  {
    "text": "understanding back pressure is also recommended so using milliseconds behind",
    "start": "3383200",
    "end": "3389470"
  },
  {
    "text": "latest is something that is necessary to track how far behind is the application",
    "start": "3389470",
    "end": "3395740"
  },
  {
    "text": "in reading and processing the data the last recommendation would be",
    "start": "3395740",
    "end": "3402390"
  },
  {
    "text": "continuously monitoring or even automating the monitoring of Roberts",
    "start": "3402390",
    "end": "3407619"
  },
  {
    "text": "alarms mainly when we use a combination of Kinesis analytics applications with",
    "start": "3407619",
    "end": "3414130"
  },
  {
    "text": "Kinesis fire hose or worth Kinesis streams understanding that we use the",
    "start": "3414130",
    "end": "3419829"
  },
  {
    "text": "optimal number of applications with the stream is necessary because the",
    "start": "3419829",
    "end": "3426010"
  },
  {
    "text": "delivery stream is already doing a job of sending the data to a delivery target",
    "start": "3426010",
    "end": "3431560"
  },
  {
    "text": "beat STD or redshift or elasticsearch or now with Splunk which is in preview",
    "start": "3431560",
    "end": "3439260"
  },
  {
    "text": "putting everything together and summarizing the session there are",
    "start": "3439470",
    "end": "3446380"
  },
  {
    "text": "multiple different ways to slice and dice and analyze the logs and by using",
    "start": "3446380",
    "end": "3454270"
  },
  {
    "text": "solace architecture the amount of infrastructure infrastructure that we end up managing would actually be lower",
    "start": "3454270",
    "end": "3461110"
  },
  {
    "text": "and also automating this sort of an environment would be easier yeah so",
    "start": "3461110",
    "end": "3467560"
  },
  {
    "text": "that's pretty much it again thank you all given that this being the last",
    "start": "3467560",
    "end": "3473980"
  },
  {
    "text": "session you guys have made it we're just a little away from the replay party",
    "start": "3473980",
    "end": "3479400"
  },
  {
    "text": "thank you all for your patience and making it to the last session so you have a couple of minutes if there are",
    "start": "3479400",
    "end": "3485200"
  },
  {
    "text": "any questions we'll be happy to take the questions here or after the session we'll be outside and we've more than",
    "start": "3485200",
    "end": "3491830"
  },
  {
    "text": "happy to take any questions [Applause]",
    "start": "3491830",
    "end": "3499889"
  }
]
[
  {
    "start": "0",
    "end": "53000"
  },
  {
    "text": "all right so good morning everyone it's great to see you all here my name is",
    "start": "27860",
    "end": "34200"
  },
  {
    "text": "Catherine Chi I'm a product manager for the AWS data pipeline service which those of you coming from burners Keynote",
    "start": "34200",
    "end": "40800"
  },
  {
    "text": "may have just heard about and I'm going to give you quick overview of first of",
    "start": "40800",
    "end": "47100"
  },
  {
    "text": "all what this thing is and then we're going to do a little tour of how you would actually use it so what is data",
    "start": "47100",
    "end": "53430"
  },
  {
    "start": "53000",
    "end": "53000"
  },
  {
    "text": "pipeline this is a lightweight workflow orchestration service for data-driven workflows and the idea here",
    "start": "53430",
    "end": "59460"
  },
  {
    "text": "is that if you're trying to build some data-driven workflow there's all this nitty-gritty detail you have to worry",
    "start": "59460",
    "end": "66030"
  },
  {
    "text": "about what happens if your data doesn't arrive on time what happens if one of your processing steps fails what happens",
    "start": "66030",
    "end": "73039"
  },
  {
    "text": "if a transient arrow takes out one of your machines and you don't really want",
    "start": "73039",
    "end": "78270"
  },
  {
    "text": "to have to worry about this stuff you want to focus on the business logic that's going to make you more successful",
    "start": "78270",
    "end": "83880"
  },
  {
    "text": "and it's going to actually create value for your organization so data pipeline makes it so you can ignore the stupid",
    "start": "83880",
    "end": "89970"
  },
  {
    "text": "details focus on the business logic and everything else will just work like all",
    "start": "89970",
    "end": "95970"
  },
  {
    "text": "AWS services this is on demand pricing pay only for what you use there's no",
    "start": "95970",
    "end": "101460"
  },
  {
    "text": "minimum commitment no upfront fees and there's going to be a free tier so if you want to do things like basic",
    "start": "101460",
    "end": "107310"
  },
  {
    "text": "replication of dynamo data to s3 it'll be no charge at all for that and more on",
    "start": "107310",
    "end": "113520"
  },
  {
    "text": "pricing later so I'm going to do three things here first discuss the general",
    "start": "113520",
    "end": "119640"
  },
  {
    "text": "problem and go into how data pipeline would help you address this and finally",
    "start": "119640",
    "end": "124770"
  },
  {
    "text": "I'll give you some examples of creating pipelines either through the console or through the command-line interface and",
    "start": "124770",
    "end": "130048"
  },
  {
    "text": "then show you a little bit about how managing pipelines would work so let's talk about the problem to make this a",
    "start": "130049",
    "end": "137070"
  },
  {
    "text": "little more concrete say you've got a website with premium content and your goal is to improve your business by",
    "start": "137070",
    "end": "143040"
  },
  {
    "start": "140000",
    "end": "140000"
  },
  {
    "text": "better targeting this content so you could just show every user everything but you could do a lot better if you",
    "start": "143040",
    "end": "148590"
  },
  {
    "text": "start showing specific users things that you think they're likely to want to see or purchase so your goal is to improve",
    "start": "148590",
    "end": "155160"
  },
  {
    "text": "your targeting improve your business you've got a secondary goal probably which is that right now your application",
    "start": "155160",
    "end": "161099"
  },
  {
    "text": "works generating logs in some format storing its data in existing databases you could",
    "start": "161099",
    "end": "167010"
  },
  {
    "text": "start mucking around and they are trying to rewrite the data to be more friendly to your analytics but it's going to be a",
    "start": "167010",
    "end": "172500"
  },
  {
    "text": "lot safer for you if instead you make your analytics friendly to your existing data and then finally like all else you",
    "start": "172500",
    "end": "180510"
  },
  {
    "text": "would love to do this better faster cheaper so let's talk about your",
    "start": "180510",
    "end": "185820"
  },
  {
    "text": "existing data there's a variety of data sources that could probably be in and it's not just going to be in one of them",
    "start": "185820",
    "end": "191340"
  },
  {
    "text": "right if I told you to take s3 and use this for all of your data needs going forward forever in time hopefully you",
    "start": "191340",
    "end": "197940"
  },
  {
    "text": "would boo me off the stage is it's a horrible idea instead you should be thinking about for each piece of data is",
    "start": "197940",
    "end": "204510"
  },
  {
    "text": "what are your specific needs around this data store and then you should be picking a data store that meets them so",
    "start": "204510",
    "end": "210060"
  },
  {
    "text": "for example if you're generating lots of event type data you have real-time eye",
    "start": "210060",
    "end": "215310"
  },
  {
    "text": "ops needs you want to be sure you're going to hit that should be saying something like dynamo DB where you can provision a level of throughput and",
    "start": "215310",
    "end": "221460"
  },
  {
    "text": "you're guaranteed to get it on the other hand if you have got a lot of bulk",
    "start": "221460",
    "end": "228900"
  },
  {
    "text": "objects you're trying to store somewhere maybe s3 is a great fit for that and so different parts of your application I'm",
    "start": "228900",
    "end": "234960"
  },
  {
    "text": "going to be using different data stores depending on what's best for them so going back to our hypothetical what data",
    "start": "234960",
    "end": "241950"
  },
  {
    "text": "does our current website probably have well in all likelihood we have some",
    "start": "241950",
    "end": "247020"
  },
  {
    "start": "245000",
    "end": "245000"
  },
  {
    "text": "historical web server logs so we know who's been clicking where we probably know how long it took to generate their",
    "start": "247020",
    "end": "252180"
  },
  {
    "text": "content we can maybe reconstruct clickstream logs from this for registered users probably got some",
    "start": "252180",
    "end": "258450"
  },
  {
    "text": "real-time information about what they've purchased what actual transactions they've done again for registered users",
    "start": "258450",
    "end": "265980"
  },
  {
    "text": "will probably have demographic data from when they signed up so we know how long they've been on the platform maybe we",
    "start": "265980",
    "end": "271650"
  },
  {
    "text": "know where they live maybe we know know how old they are things like that and then let's say we've purchased data to a",
    "start": "271650",
    "end": "278160"
  },
  {
    "text": "third-party IP geolocation service so if we have a visitors IP address maybe we",
    "start": "278160",
    "end": "283200"
  },
  {
    "text": "can tell that they live for example in Las Vegas and where is this stuff going",
    "start": "283200",
    "end": "288360"
  },
  {
    "text": "to be well our web server logs taking a whole bunch of big chunks",
    "start": "288360",
    "end": "294270"
  },
  {
    "text": "data sticking those in s3 would make a ton of sense for our user demographics",
    "start": "294270",
    "end": "299310"
  },
  {
    "text": "this is classic relational data right so maybe it's on-premise database maybe it's already s and then for our event",
    "start": "299310",
    "end": "307260"
  },
  {
    "text": "data about who's been subscribing to what who's been generating what events so it's dynamo and then from this we",
    "start": "307260",
    "end": "315540"
  },
  {
    "text": "want to generate some kind of smart analytics intelligent output just so you some usage statistics analysis for those",
    "start": "315540",
    "end": "323340"
  },
  {
    "text": "of you who are here yesterday this is going to be redshift or some kind of data warehouse all right so we want to",
    "start": "323340",
    "end": "329040"
  },
  {
    "text": "take all this different data load it into redshift but it's not that simple you don't want to just take these logs",
    "start": "329040",
    "end": "335640"
  },
  {
    "text": "and blindly shove them into a relational database because they have no structure it's just not going to work what you",
    "start": "335640",
    "end": "341010"
  },
  {
    "text": "actually need to do is take all this stuff perform some analysis add structure to your unstructured data and",
    "start": "341010",
    "end": "347070"
  },
  {
    "text": "then think about loading it into your relational data warehouse so we've already added a separate complexity and",
    "start": "347070",
    "end": "352940"
  },
  {
    "text": "as time goes on this is only going to get more complex it would be awesome if",
    "start": "352940",
    "end": "358230"
  },
  {
    "start": "355000",
    "end": "355000"
  },
  {
    "text": "all of our bosses said you know what targeting is pretty good we don't need it turn off the systems go home early",
    "start": "358230",
    "end": "364680"
  },
  {
    "text": "have a beer I have yet to see that happen instead what happens is someone",
    "start": "364680",
    "end": "369840"
  },
  {
    "text": "comes up and says hey your targeting is great but wouldn't it be better if we",
    "start": "369840",
    "end": "375090"
  },
  {
    "text": "started adding Twitter data or if we added I don't know information about the weather maybe people when it's sunny you want to",
    "start": "375090",
    "end": "381420"
  },
  {
    "text": "see the beach um maybe people will say hey we're curious not just about the",
    "start": "381420",
    "end": "386790"
  },
  {
    "text": "events that happened but about what dollar the transaction level actually was maybe you start running simulations",
    "start": "386790",
    "end": "392340"
  },
  {
    "text": "so you do are you run analysis of hypothetically if we extended this a B",
    "start": "392340",
    "end": "397590"
  },
  {
    "text": "test in this direction what results do we think we'd see maybe your users have created videos or images that you want",
    "start": "397590",
    "end": "403260"
  },
  {
    "text": "to analyze maybe you have sensor data so if you have a mobile phone application maybe you know what the GPS coordinates",
    "start": "403260",
    "end": "409890"
  },
  {
    "text": "of your users were and maybe you've purchased additional third-party data sets I could stand here all day and add",
    "start": "409890",
    "end": "416220"
  },
  {
    "text": "extra things for this list but I think the point is clear you're only going to have more and more different data sources and different data formats",
    "start": "416220",
    "end": "423120"
  },
  {
    "text": "feeding into this analysis and as you have more and more of these it's going to become more painful to try to manage them what",
    "start": "423120",
    "end": "430440"
  },
  {
    "text": "happens if one of them goes down and the others are unaffected what happens if there's a fluke in one of your external",
    "start": "430440",
    "end": "435990"
  },
  {
    "text": "AP is so this is where that a pipeline comes in so we're going to first talk",
    "start": "435990",
    "end": "441510"
  },
  {
    "start": "441000",
    "end": "441000"
  },
  {
    "text": "about what the basic functionality is and then we'll go over how you'd actually use it in this example so at a",
    "start": "441510",
    "end": "450480"
  },
  {
    "text": "very high level data pipeline consists of data notes these are the things that hold your data so a data node could be a",
    "start": "450480",
    "end": "457800"
  },
  {
    "start": "455000",
    "end": "455000"
  },
  {
    "text": "directory in an s3 bucket it could be a DynamoDB table could be a table in a relational database either on AWS or",
    "start": "457800",
    "end": "465480"
  },
  {
    "text": "on-premise anything like that and then activities are things that act on your",
    "start": "465480",
    "end": "471030"
  },
  {
    "text": "data so an activity could be a sequel query it could be a script running on an instance you know some 20 lines of pearl",
    "start": "471030",
    "end": "478140"
  },
  {
    "text": "it could be a big EMR job that's going to chug through petabytes of logs and produce some complicated analysis and",
    "start": "478140",
    "end": "485060"
  },
  {
    "text": "typically your activities are going to generate even more data you know if you have a sequel query just going to have",
    "start": "485060",
    "end": "491160"
  },
  {
    "text": "some output which you probably don't want to just drop on the floor if you have an EMR job again you've paid some",
    "start": "491160",
    "end": "496710"
  },
  {
    "text": "money for that output you probably love to keep it occasionally you'll have an activity that's maybe send an email so",
    "start": "496710",
    "end": "502620"
  },
  {
    "text": "that an output data nodes are technically optional but we generally",
    "start": "502620",
    "end": "507690"
  },
  {
    "text": "recommend that you have them adding a bit of complexity you can attach preconditions to your",
    "start": "507690",
    "end": "513300"
  },
  {
    "text": "data notes and activities get failure and delay notifications so let's talk",
    "start": "513300",
    "end": "518310"
  },
  {
    "text": "about those a little bit so preconditions there's two classes there's ones that we run for you so for",
    "start": "518310",
    "end": "524880"
  },
  {
    "start": "520000",
    "end": "520000"
  },
  {
    "text": "these you don't need to have any kind of long-standing compute resource and then there's ones that you run so for ones",
    "start": "524880",
    "end": "531750"
  },
  {
    "text": "that rerun we can check for existence of s3 files or directories we can check for",
    "start": "531750",
    "end": "537270"
  },
  {
    "text": "existence of data in dynamo and then we can run queries against RDS or redshift",
    "start": "537270",
    "end": "542430"
  },
  {
    "text": "so for example you could say this data is available once this RDS query returns",
    "start": "542430",
    "end": "549120"
  },
  {
    "text": "at least 100 rows or my dad is available once I see my last hour of web server",
    "start": "549120",
    "end": "554490"
  },
  {
    "text": "logs in s3 then there are some data sources that we can't check easily so",
    "start": "554490",
    "end": "559589"
  },
  {
    "text": "for example if you have an on premise J et database we cannot reach through your firewall magically and query that thing",
    "start": "559589",
    "end": "566250"
  },
  {
    "text": "so we give you the ability to run queries against it I'll have some more details later about how this works with",
    "start": "566250",
    "end": "572459"
  },
  {
    "text": "on-premise resources and then also we give you the ability to express preconditions as custom scripts so if",
    "start": "572459",
    "end": "579120"
  },
  {
    "text": "you are for example querying a third-party ftp it's not something that we're hosts but we give you the ability",
    "start": "579120",
    "end": "584610"
  },
  {
    "text": "to write the code to do that I'm easily plug it into the system for retries and",
    "start": "584610",
    "end": "589890"
  },
  {
    "text": "notifications on activities by default we retry all activities three times so this gives you some resilience against",
    "start": "589890",
    "end": "595890"
  },
  {
    "start": "593000",
    "end": "593000"
  },
  {
    "text": "transient failures you know if something has a brief fluke it's no big deal processing will continue and you can",
    "start": "595890",
    "end": "601260"
  },
  {
    "text": "configure this so if you're running some really heavy job that takes lots of compute resources for a long time maybe",
    "start": "601260",
    "end": "608070"
  },
  {
    "text": "you want to go with a very low number of retries so that you detect failures early and you don't pay a bunch of money",
    "start": "608070",
    "end": "614310"
  },
  {
    "text": "to you know repeatedly try something that you don't think it's going to work on the other hand maybe you're running a",
    "start": "614310",
    "end": "620190"
  },
  {
    "text": "quick little sequel query against the database that you know is kind of overloaded maybe this thing tends to",
    "start": "620190",
    "end": "625230"
  },
  {
    "text": "timeout and you can just crank up your retries and not really worry about it and then we provide this concept of",
    "start": "625230",
    "end": "632160"
  },
  {
    "text": "lateness so lateness lets you say hey I think this activity is going to take five",
    "start": "632160",
    "end": "638070"
  },
  {
    "text": "minutes to complete if it starts taking two hours something is really really wrong here you've got two options for",
    "start": "638070",
    "end": "645300"
  },
  {
    "text": "lateness one is to notify yourself and then keep on trying the other is to say",
    "start": "645300",
    "end": "651000"
  },
  {
    "text": "that's it it gets two hours and then it's done I want you to stop it so we",
    "start": "651000",
    "end": "656010"
  },
  {
    "text": "support both of those and then for notifications you can also notify yourself by a SMS when an activity",
    "start": "656010",
    "end": "662490"
  },
  {
    "text": "succeeds if it's late or if it outright fails so if you've exhausted your attempts and you have to go intervene",
    "start": "662490",
    "end": "669209"
  },
  {
    "text": "fix some things and then actually click retry which would reset that so you can",
    "start": "669209",
    "end": "674459"
  },
  {
    "text": "then um is this alright so architectural II how does this work this big green",
    "start": "674459",
    "end": "681930"
  },
  {
    "text": "blob at the top is us so data pipeline sits on top of your existing resources",
    "start": "681930",
    "end": "687149"
  },
  {
    "text": "and provides management and orchestration so it's going to signal signal your compute resources when it's",
    "start": "687149",
    "end": "693390"
  },
  {
    "text": "time to do stuff it's going to monitor your attitude aside when it's time to do things it's not that the data actually",
    "start": "693390",
    "end": "699180"
  },
  {
    "text": "flows through app instead that it's you know on top providing management and resilience and you can take this",
    "start": "699180",
    "end": "705060"
  },
  {
    "text": "individual step of data to compute to data and you can chain it together in interesting and complicated ways so",
    "start": "705060",
    "end": "712319"
  },
  {
    "start": "709000",
    "end": "709000"
  },
  {
    "text": "here's an example pipeline a little bit abstract when we begin execution of this pipeline the system is going to look for",
    "start": "712319",
    "end": "719100"
  },
  {
    "text": "the data and the top left so nothing's running until that dad is there once the data is there the activities that",
    "start": "719100",
    "end": "725130"
  },
  {
    "text": "consume it begin to execute and these things go independently so the one on the top right could succeed before the",
    "start": "725130",
    "end": "732029"
  },
  {
    "text": "one on the left it's done it's data is ready the activity that consumes that data though is still waiting for the",
    "start": "732029",
    "end": "738420"
  },
  {
    "text": "output from the other one so it's going to keep on waiting eventually the data appears and the activity starts to run now in general we",
    "start": "738420",
    "end": "746910"
  },
  {
    "text": "recommend that you have explicit data nodes in between your activities this",
    "start": "746910",
    "end": "751949"
  },
  {
    "text": "gives you better statefulness and makes retries a little bit easier but it's not strictly required maybe you have",
    "start": "751949",
    "end": "757139"
  },
  {
    "text": "activities that for one reason or another um that for one reason or",
    "start": "757139",
    "end": "762269"
  },
  {
    "text": "another can't actually put their data into a cleanly model data store so that's fine in that case we let you",
    "start": "762269",
    "end": "769769"
  },
  {
    "text": "directly chain the activities so here we've chained two activities once one completes the other just starts to go",
    "start": "769769",
    "end": "775380"
  },
  {
    "text": "and then as it finishes you see the success move through the pipeline and",
    "start": "775380",
    "end": "784730"
  },
  {
    "text": "then all of this stuff runs on a schedule so at a very basic level a",
    "start": "784730",
    "end": "790889"
  },
  {
    "text": "schedule consists of a start time an interval which is how often the stuff",
    "start": "790889",
    "end": "796170"
  },
  {
    "text": "should run and then optionally and end time so we can make this a little bit more concrete example schedule would",
    "start": "796170",
    "end": "803610"
  },
  {
    "text": "start today at noon it would run every hour and we're just going to say this thing runs forever so when you take this",
    "start": "803610",
    "end": "810660"
  },
  {
    "text": "schedule what happens go today the first",
    "start": "810660",
    "end": "817949"
  },
  {
    "text": "interval is noon to 1:00 so that time we kick off a copy of the pipeline we start",
    "start": "817949",
    "end": "823290"
  },
  {
    "text": "looking for the first data node when it's there we do its activities continue on the same thing happens for",
    "start": "823290",
    "end": "829530"
  },
  {
    "text": "one two two two two three and so on and once we have this we can configure what",
    "start": "829530",
    "end": "837630"
  },
  {
    "text": "Matt was talking about the keynote oh sorry um if during this you know let's say",
    "start": "837630",
    "end": "843960"
  },
  {
    "text": "that twelve to one data it never becomes available that's totally fine it's not going to interfere with processing for",
    "start": "843960",
    "end": "850140"
  },
  {
    "text": "your subsequent set of logs the twelve to one block will hold up waiting for that data the other periods will",
    "start": "850140",
    "end": "856230"
  },
  {
    "text": "continue to execute just fine so now we can go on to what Matt was talking about",
    "start": "856230",
    "end": "861570"
  },
  {
    "start": "858000",
    "end": "858000"
  },
  {
    "text": "which is the idea of roll-ups so let's say we have this hourly processing and we want to produce a daily summary of",
    "start": "861570",
    "end": "868740"
  },
  {
    "text": "everything that was in our logs and all the activity we saw today we can define another schedule with a daily interval",
    "start": "868740",
    "end": "874410"
  },
  {
    "text": "and we can create an activity that consumes all of these individual hourly",
    "start": "874410",
    "end": "879810"
  },
  {
    "text": "buckets the system will just know that usually there's 24 hours in a day twice",
    "start": "879810",
    "end": "885420"
  },
  {
    "text": "a year on these annoying days there's other 23 or 25 handles all that stuff and as always if one of the input data",
    "start": "885420",
    "end": "892440"
  },
  {
    "text": "nodes never becomes available that's fine the activity will just pause and wait for it and again if you had",
    "start": "892440",
    "end": "897870"
  },
  {
    "text": "lateness notification configured you'd hear if for example this data node two",
    "start": "897870",
    "end": "903300"
  },
  {
    "text": "days later still wasn't there you start to get the SNS messages saying hey maybe you should go take a look at this and",
    "start": "903300",
    "end": "910430"
  },
  {
    "text": "you can chain together your roll-ups in interesting and complicated ways I'm not",
    "start": "910430",
    "end": "915600"
  },
  {
    "text": "sure who would actually want this many steps but it's totally possible if that's you so let's go back to our",
    "start": "915600",
    "end": "923010"
  },
  {
    "text": "example problem okay we've got this website with the premium content when I",
    "start": "923010",
    "end": "929610"
  },
  {
    "text": "improve our targeting so to break this down a little bit say we form a plan I'm",
    "start": "929610",
    "end": "935400"
  },
  {
    "text": "going to do three or four steps depending on how you count so we had that geo look up data that we bought we",
    "start": "935400",
    "end": "942630"
  },
  {
    "text": "have our server logs to tell who's clicking on what and we're going to try to merge these that we can say users",
    "start": "942630",
    "end": "947760"
  },
  {
    "text": "from this geography like to look at this users from the other geography maybe behave in some completely separate",
    "start": "947760",
    "end": "953310"
  },
  {
    "text": "fashion then we have our event data",
    "start": "953310",
    "end": "959040"
  },
  {
    "text": "and we're going to try to merge that with what we know about users from when they signed up to again say maybe",
    "start": "959040",
    "end": "964649"
  },
  {
    "text": "different types of users are doing different things we're going to load all of this into a database so that we can",
    "start": "964649",
    "end": "970889"
  },
  {
    "text": "programmatically consume it on web servers and do dynamic targeting and then we want to take the results put",
    "start": "970889",
    "end": "977819"
  },
  {
    "text": "them in reporting dashboard and generate some automated reports for a business owner so let's look at step one first",
    "start": "977819",
    "end": "984410"
  },
  {
    "text": "merging the Geo lookup data with the server logs here pipeline for this part",
    "start": "984410",
    "end": "991649"
  },
  {
    "start": "989000",
    "end": "989000"
  },
  {
    "text": "is pretty simple we have s3 logs we've got a third party API with our lookup data let's say we're",
    "start": "991649",
    "end": "997319"
  },
  {
    "text": "going to use an EMR streaming job because our logs are probably pretty big and then we're going to load the results",
    "start": "997319",
    "end": "1002420"
  },
  {
    "text": "into redshift we can add some preconditions so for s3 we'd use a file exists to make",
    "start": "1002420",
    "end": "1008120"
  },
  {
    "text": "sure that the logs are actually there and that none of the server's have been delayed and sending the stuff for the",
    "start": "1008120",
    "end": "1013370"
  },
  {
    "text": "geolocation data we could use a custom script here because you know who knows what third party API exactly looks like",
    "start": "1013370",
    "end": "1020199"
  },
  {
    "text": "once these preconditions are met we'll start doing the processing and the results will go into a redshift step two",
    "start": "1020199",
    "end": "1027918"
  },
  {
    "text": "merging the event data with the demographics this is pretty simple too it's another pipeline we're combining",
    "start": "1027919",
    "end": "1034400"
  },
  {
    "text": "two data sources in this case dynamo RDS and then results into database that's",
    "start": "1034400",
    "end": "1041480"
  },
  {
    "text": "already done by those two pipelines so we all that we have left is step four displaying our results in the dashboard",
    "start": "1041480",
    "end": "1048069"
  },
  {
    "text": "again here you even though it's a single database you'd actually model this as two data nodes in data pipeline because",
    "start": "1048070",
    "end": "1054799"
  },
  {
    "text": "they're probably separate tables and data pipeline is much is modeling things kind of at the logical unit not at the",
    "start": "1054799",
    "end": "1061970"
  },
  {
    "text": "physical unit so we're going to model this as two tables when they're ready we've run some reporting query outcomes",
    "start": "1061970",
    "end": "1068059"
  },
  {
    "text": "and email so plan is done and to build the pipeline you can just take each of",
    "start": "1068059",
    "end": "1074030"
  },
  {
    "text": "these individual things you've constructed stick them all together and now you have more complex behavior",
    "start": "1074030",
    "end": "1079190"
  },
  {
    "text": "arising out of these relatively simple logical building blocks and then we",
    "start": "1079190",
    "end": "1084200"
  },
  {
    "text": "translate this to our data nodes and arc tivities so let's talk a little bit more",
    "start": "1084200",
    "end": "1090380"
  },
  {
    "text": "about what the activities can actually be you support four broad classes the first",
    "start": "1090380",
    "end": "1096230"
  },
  {
    "start": "1092000",
    "end": "1092000"
  },
  {
    "text": "is arbitrary Linux applications so the system knows how to call out to the linux shell run anything that works",
    "start": "1096230",
    "end": "1102830"
  },
  {
    "text": "there we also support copies between different data sources so for example if you have CSV data and s3 and JDBC data",
    "start": "1102830",
    "end": "1110870"
  },
  {
    "text": "we give you the logic kind of out of the box to just move between the two of them can run sequel queries and then EMR jobs",
    "start": "1110870",
    "end": "1119480"
  },
  {
    "text": "and we can run these on two classes to compute resources so we have ones that",
    "start": "1119480",
    "end": "1126590"
  },
  {
    "text": "we manage and ones that you manage talk about the difference and cover the ones that we manage first so what does it",
    "start": "1126590",
    "end": "1132890"
  },
  {
    "start": "1132000",
    "end": "1132000"
  },
  {
    "text": "mean for data pipeline to manage resource for you well what this means is that data pipeline watches your data",
    "start": "1132890",
    "end": "1139730"
  },
  {
    "text": "nodes for readiness and when all of the preconditions for an activity are met it will actually launch the resource for",
    "start": "1139730",
    "end": "1145670"
  },
  {
    "text": "you run all of the activities that need to happen on the resource and then tear it down so if you're doing something",
    "start": "1145670",
    "end": "1151550"
  },
  {
    "text": "like daily analytics that takes three or four hours this is going to potentially save you a bunch of money compared to",
    "start": "1151550",
    "end": "1157010"
  },
  {
    "text": "just having a compute resource sitting there idle half the time so easier to pay for what you use on the other hand",
    "start": "1157010",
    "end": "1163760"
  },
  {
    "text": "there are plenty of jobs that either take some manual configuration or that are running in on on-premise resources",
    "start": "1163760",
    "end": "1170150"
  },
  {
    "text": "and we support those too so this is where resources that you manage come in so to manage these we're distributing a",
    "start": "1170150",
    "end": "1179420"
  },
  {
    "start": "1177000",
    "end": "1177000"
  },
  {
    "text": "java-based task agent and it's a really small little jar you install this on a",
    "start": "1179420",
    "end": "1185030"
  },
  {
    "text": "computer source you control and it since they're pulling or API is for work so as you know hey I'm this agent this is my",
    "start": "1185030",
    "end": "1191720"
  },
  {
    "text": "account ID you can just or you can assign these things to logical groups so",
    "start": "1191720",
    "end": "1197420"
  },
  {
    "text": "you could have a group of task agents running say on your on-premise servers and a separate group of task agents",
    "start": "1197420",
    "end": "1202490"
  },
  {
    "text": "running on AWS web servers and when you create activities you say this activity",
    "start": "1202490",
    "end": "1208490"
  },
  {
    "text": "should be executed by that group of agents so then when the activity is ready to go next time in agent polls the",
    "start": "1208490",
    "end": "1215120"
  },
  {
    "text": "web service says Oh works available take it and start doing it and then the web service monitors the agent for liveness",
    "start": "1215120",
    "end": "1222410"
  },
  {
    "text": "if the agent goes down it's no big deal next time different one polls will reassign the",
    "start": "1222410",
    "end": "1227710"
  },
  {
    "text": "work to it and you can use this to run your activities anywhere within reason I",
    "start": "1227710",
    "end": "1233710"
  },
  {
    "text": "haven't tried a smartphone but reasonable servers at least and so if",
    "start": "1233710",
    "end": "1238900"
  },
  {
    "text": "you have manual configuration you can bring up your computer source you can do whatever manual mucking around you need",
    "start": "1238900",
    "end": "1244090"
  },
  {
    "text": "to do on the other hand maybe you don't have any manual install but you want to use existing on-premise compute",
    "start": "1244090",
    "end": "1250480"
  },
  {
    "text": "resources that's fine you just install this agent on-premise as long as it's a",
    "start": "1250480",
    "end": "1255970"
  },
  {
    "text": "vaguely Linux UNIX II machine and as long as you have internet access to our API endpoint should just work for our",
    "start": "1255970",
    "end": "1263350"
  },
  {
    "start": "1256000",
    "end": "1256000"
  },
  {
    "text": "copy logic that's included on the agent so if you want to start reading a copy between say on-premise logs and s3 or if",
    "start": "1263350",
    "end": "1270760"
  },
  {
    "text": "you want a copy between on-premise JDBC and AWS JDBC the agent has that logic so",
    "start": "1270760",
    "end": "1277299"
  },
  {
    "text": "it can access your on-premise database and then it can reach out to your AWS compute resources and seamlessly connect",
    "start": "1277299",
    "end": "1282880"
  },
  {
    "text": "the two and again these activities are scheduled and managed just like anything else in the system so a little bit of",
    "start": "1282880",
    "end": "1291730"
  },
  {
    "text": "configuration is this work um where is the computer for this ok got it",
    "start": "1291730",
    "end": "1302080"
  },
  {
    "text": "all right much chaos later",
    "start": "1302080",
    "end": "1306690"
  },
  {
    "text": "so here is the data pipeline console so these are all of the pipeline's I've got configured and running and we can go",
    "start": "1311659",
    "end": "1319429"
  },
  {
    "text": "create a new one yes a Catherine's pipeline um this is just a description",
    "start": "1319429",
    "end": "1327589"
  },
  {
    "text": "so if you want to look at it later you can say you know this help me keep track of what on earth I was trying to do and",
    "start": "1327589",
    "end": "1337089"
  },
  {
    "text": "then pipelines are associated with roles so the idea of a role is that data",
    "start": "1337089",
    "end": "1342949"
  },
  {
    "text": "pipeline is going to be taking a pretty broad range of actions in your behalf it's potentially going to be looking at your s3 data your dynamo data will be",
    "start": "1342949",
    "end": "1350239"
  },
  {
    "text": "launching ec2 instance instances on your behalf and maybe you don't want it to you know have full access to do whatever",
    "start": "1350239",
    "end": "1356659"
  },
  {
    "text": "it feels like with your account right so if you're familiar with pause and rolls on ec2 we're actually using these",
    "start": "1356659",
    "end": "1362929"
  },
  {
    "text": "throughout the system so when you configure a pipeline you pick a role you associate the pipeline with that role",
    "start": "1362929",
    "end": "1368119"
  },
  {
    "text": "and then whenever we're doing something we actually use the role to do it so if",
    "start": "1368119",
    "end": "1373519"
  },
  {
    "text": "you want to for example allow the system to look at your s3 data and your dynamo",
    "start": "1373519",
    "end": "1379489"
  },
  {
    "text": "data for availability but you want it to keep its hands off of your RDS data you can use these to enforce that and then",
    "start": "1379489",
    "end": "1387379"
  },
  {
    "text": "you can also choose what role you decide to push to any ec2 instances it launches so if it's provisioning compute for you",
    "start": "1387379",
    "end": "1394069"
  },
  {
    "text": "you can very carefully sandbox this compute so that you if anything does go haywire in your scripts",
    "start": "1394069",
    "end": "1399559"
  },
  {
    "text": "you know the blast radius is significantly limited so I'm just going",
    "start": "1399559",
    "end": "1404809"
  },
  {
    "text": "to use the default roles and to create the pipeline and then let's just say we",
    "start": "1404809",
    "end": "1411139"
  },
  {
    "text": "want to backup dynamo we'll just drop in the dynamo DES through replication template you can see here we've got two",
    "start": "1411139",
    "end": "1419389"
  },
  {
    "text": "data nodes dynamo and s3 for dynamo need",
    "start": "1419389",
    "end": "1424909"
  },
  {
    "text": "to provide a table name so my example I don't think this is actually going to",
    "start": "1424909",
    "end": "1430819"
  },
  {
    "text": "work because I don't have any dynamo table name that but and then press three",
    "start": "1430819",
    "end": "1436399"
  },
  {
    "text": "similarly you provide a path and Matt touched on this a little bit",
    "start": "1436399",
    "end": "1443630"
  },
  {
    "text": "but we provide this expression language that allows you to embed things like the",
    "start": "1443630",
    "end": "1449520"
  },
  {
    "text": "date and the time into your paths so for replication it's not going to be very useful if you clobber your old back up",
    "start": "1449520",
    "end": "1456480"
  },
  {
    "text": "every time you have a new one right you want to actually keep track of historical states that if you realize you had a bug a week ago you can roll",
    "start": "1456480",
    "end": "1463770"
  },
  {
    "text": "back to it so here I'd say you know start time dot format maybe this is a",
    "start": "1463770",
    "end": "1472470"
  },
  {
    "text": "daily job so I'll just put the day in month day and then it's going to be I",
    "start": "1472470",
    "end": "1480120"
  },
  {
    "text": "think CSV data so this way I'll get new data each day I won't be clobbering the",
    "start": "1480120",
    "end": "1486570"
  },
  {
    "text": "old data and you could potentially do something interesting here you could configure s3 to start aging your backups",
    "start": "1486570",
    "end": "1492330"
  },
  {
    "text": "out to glacier so that you save even more money compared to just having in this bulk dynamo data sitting there in",
    "start": "1492330",
    "end": "1498179"
  },
  {
    "text": "s3 so once it's all done save that guy yeah there's a validation error my",
    "start": "1498179",
    "end": "1504929"
  },
  {
    "text": "bucket is imaginary that's okay and then once I have a pipeline running you can",
    "start": "1504929",
    "end": "1511860"
  },
  {
    "text": "see we show you some brief details here so I can see how much my pipeline's been",
    "start": "1511860",
    "end": "1517260"
  },
  {
    "text": "doing lately know how many times has completed many times has it failed this one's failed so let's go look at it",
    "start": "1517260",
    "end": "1523170"
  },
  {
    "text": "a little bit I'm going to say look at details I actually created this thing to",
    "start": "1523170",
    "end": "1529590"
  },
  {
    "text": "have an example of a good script and a buggy script my buggy script is failing",
    "start": "1529590",
    "end": "1534600"
  },
  {
    "text": "because it's echoing false but you can see here we show you what went wrong",
    "start": "1534600",
    "end": "1539760"
  },
  {
    "text": "what our error code was why they ever happened in this case it's because I'm running a manual script and the thing is",
    "start": "1539760",
    "end": "1545820"
  },
  {
    "text": "failing and from here you can start downloading logs and actually diving into the problem once I think I fixed",
    "start": "1545820",
    "end": "1551160"
  },
  {
    "text": "the problem I can go up here so I up problem solved my script bug is gone I",
    "start": "1551160",
    "end": "1556679"
  },
  {
    "text": "click rerun to make the system retry and it would just pick up where it had stopped for that particular workflow so",
    "start": "1556679",
    "end": "1566309"
  },
  {
    "text": "back to the slides so it's provisioning in a nutshell yeah",
    "start": "1566309",
    "end": "1578180"
  },
  {
    "text": "can you turn this one back on ER this is",
    "start": "1578180",
    "end": "1584840"
  },
  {
    "text": "what I get for using a Mac right",
    "start": "1584840",
    "end": "1587950"
  },
  {
    "text": "right",
    "start": "1597130",
    "end": "1599730"
  },
  {
    "text": "they're you brilliant all right so you can also provision these things through",
    "start": "1607070",
    "end": "1612270"
  },
  {
    "text": "the CLI or the API I decided to skip on the code samples but if you're doing it",
    "start": "1612270",
    "end": "1617550"
  },
  {
    "start": "1616000",
    "end": "1616000"
  },
  {
    "text": "to the CLI we have adjacent pipeline definition format so here's an example of me - finding a copy between RDS and",
    "start": "1617550",
    "end": "1624630"
  },
  {
    "text": "s3 so I've said that you know the name of my activity is copy type is copy",
    "start": "1624630",
    "end": "1631620"
  },
  {
    "text": "action I'm going to have one input data source which is RDS data I'm going to",
    "start": "1631620",
    "end": "1637260"
  },
  {
    "text": "have one output which is the s3 data it's using runs on which means that for",
    "start": "1637260",
    "end": "1642660"
  },
  {
    "text": "this pipeline data pipeline is going to configure an ec2 instance for me and there's my configuration right below and",
    "start": "1642660",
    "end": "1648809"
  },
  {
    "text": "then the schedule is off the screen but you can imagine what it would look like so for this one imagine it's a daily",
    "start": "1648809",
    "end": "1655830"
  },
  {
    "text": "schedule whenever the copy is ready to go we'll spin up an m1 small run the copy tear down the m1 small I have no",
    "start": "1655830",
    "end": "1664830"
  },
  {
    "text": "idea what showing up up here's the monitoring example and here's our",
    "start": "1664830",
    "end": "1669929"
  },
  {
    "start": "1669000",
    "end": "1669000"
  },
  {
    "text": "pricing so again this is paid for what you use no advance charges the way this",
    "start": "1669929",
    "end": "1676410"
  },
  {
    "text": "works is that the cost is a function of how many activities or preconditions you have and every running pipeline and we",
    "start": "1676410",
    "end": "1683130"
  },
  {
    "text": "have two types we have high frequency and we have low frequency a high",
    "start": "1683130",
    "end": "1688320"
  },
  {
    "text": "frequency activity is one that you've scheduled to run more often than daily so every 12 hours every hour 15 minutes",
    "start": "1688320",
    "end": "1697230"
  },
  {
    "text": "is the fastest option and then a low frequency is one that's daily or less",
    "start": "1697230",
    "end": "1702480"
  },
  {
    "text": "daily weekly monthly you could schedule to run I don't know every 17 days or",
    "start": "1702480",
    "end": "1708240"
  },
  {
    "text": "every 8 months not sure exactly what your use case would be there but whatever makes you happy and then for",
    "start": "1708240",
    "end": "1714900"
  },
  {
    "text": "activities running on AWS we have one set of prices and if you go purely on premise then it's 250 versus 150 our",
    "start": "1714900",
    "end": "1723630"
  },
  {
    "text": "free tier is three low frequency AWS preconditions a month and five low",
    "start": "1723630",
    "end": "1729090"
  },
  {
    "text": "frequency ad based activities so with the free tier if you wanted to do something like replicate dynamo data",
    "start": "1729090",
    "end": "1734820"
  },
  {
    "text": "once a day to s3 that's a single activity so completely covered by the free tier if you wanted to replicate your dynamo",
    "start": "1734820",
    "end": "1741420"
  },
  {
    "text": "data and start moving stuff between two different AWS databases both of those",
    "start": "1741420",
    "end": "1747750"
  },
  {
    "text": "tasks will fit within the free tier the prices here are monthly but it's",
    "start": "1747750",
    "end": "1752820"
  },
  {
    "text": "actually prorated hourly the monthly is just to make it a little bit easier to wrap your head around what your expected cost is so if I created a pipeline I",
    "start": "1752820",
    "end": "1760290"
  },
  {
    "text": "scheduled it to run once a day I ran it for six hours and I turned it off on let's say six activities in the pipeline",
    "start": "1760290",
    "end": "1768360"
  },
  {
    "text": "it would cost me 60 cents times six 360 a month and then that would be prorated",
    "start": "1768360",
    "end": "1774750"
  },
  {
    "text": "for those six hours so divide by say 30 times four I know it'll cost me a couple",
    "start": "1774750",
    "end": "1781290"
  },
  {
    "text": "cents to have that thing active for six months no sorry for six hours for six months it'll cost me a couple bucks so it's",
    "start": "1781290",
    "end": "1791820"
  },
  {
    "text": "three configured um and then you could configure them to run you know daily two days three days on because it's low",
    "start": "1791820",
    "end": "1798510"
  },
  {
    "text": "frequency daily is the maximum frequency on to the free tier and if you wanted to",
    "start": "1798510",
    "end": "1803760"
  },
  {
    "text": "you know have one set and then midway through the month you could delete that pump those pipelines swap them out for",
    "start": "1803760",
    "end": "1809190"
  },
  {
    "text": "second set of pipelines that'll be flying into the free tier",
    "start": "1809190",
    "end": "1814100"
  },
  {
    "text": "yeah just like ec2 this does round by the hour so you know how that math works",
    "start": "1814880",
    "end": "1821630"
  },
  {
    "text": "so goals talked about the problem our data pipeline will help you solve it then solve provisioning examples our",
    "start": "1822860",
    "end": "1831740"
  },
  {
    "text": "current status right now we are in private beta public beta is coming soon",
    "start": "1831740",
    "end": "1836850"
  },
  {
    "start": "1836000",
    "end": "1836000"
  },
  {
    "text": "if you have questions or if you want to try this thing out we are at the Big Data booth for the rest of the day you",
    "start": "1836850",
    "end": "1842730"
  },
  {
    "text": "can come find us and we are more than happy to talk to you about the stuff and I have like one minute left so uh",
    "start": "1842730",
    "end": "1852320"
  },
  {
    "text": "you",
    "start": "1855220",
    "end": "1857280"
  }
]
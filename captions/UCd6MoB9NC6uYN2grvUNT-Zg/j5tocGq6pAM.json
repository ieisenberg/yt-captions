[
  {
    "start": "0",
    "end": "108000"
  },
  {
    "text": "morning everyone I am assuming that people are finding it difficult to find",
    "start": "0",
    "end": "7589"
  },
  {
    "text": "the room and come here or they feel that Athena is a better service are not sure",
    "start": "7589",
    "end": "13820"
  },
  {
    "text": "so thank you I'm honored to be introduced by Alexa so today's session",
    "start": "13820",
    "end": "20850"
  },
  {
    "text": "we are going to talk about some recent features that we released in redshift",
    "start": "20850",
    "end": "26789"
  },
  {
    "text": "some best practices right what you can take away from here if you had if you're",
    "start": "26789",
    "end": "32610"
  },
  {
    "text": "not following these best practices can you start following these best practices and also some additional resources many",
    "start": "32610",
    "end": "38850"
  },
  {
    "text": "of you if you have spoken to your essays account managers you'd be knowing these additional resources but these are very",
    "start": "38850",
    "end": "44399"
  },
  {
    "text": "critical for you to monitor your redshift cluster and what how to tune",
    "start": "44399",
    "end": "49739"
  },
  {
    "text": "your redshift cluster so are you a redshift user right of an please okay",
    "start": "49739",
    "end": "56850"
  },
  {
    "text": "I've got one person using redshift that's good so let's shift is not a database but",
    "start": "56850",
    "end": "65460"
  },
  {
    "text": "what we did is we chose something that is a database which you are all familiar with something like pole square sequel",
    "start": "65460",
    "end": "73560"
  },
  {
    "text": "and we added MPP capabilities into it OLAP capabilities into it and columnar",
    "start": "73560",
    "end": "80490"
  },
  {
    "text": "capabilities into that database and added of flow of additional services",
    "start": "80490",
    "end": "86970"
  },
  {
    "text": "that are running on AWS like SWF like VP C's like kms route 53 and made it",
    "start": "86970",
    "end": "94560"
  },
  {
    "text": "available as a service to you called Amazon touchiered so it's not a possible",
    "start": "94560",
    "end": "100259"
  },
  {
    "text": "sequel database we expose post or sequel views for you but it is not a foscar",
    "start": "100259",
    "end": "105659"
  },
  {
    "text": "sequel database internally we have introduced 125 significant patches since",
    "start": "105659",
    "end": "113340"
  },
  {
    "start": "108000",
    "end": "108000"
  },
  {
    "text": "we launched and under than 65 significant features since we launched",
    "start": "113340",
    "end": "120960"
  },
  {
    "text": "redshift so when a feature is released you don't have to come to us to say can",
    "start": "120960",
    "end": "125969"
  },
  {
    "text": "you enable that feature for us the feature is automatically added to your redshift cluster it's available in the",
    "start": "125969",
    "end": "133020"
  },
  {
    "text": "next spatulas so you don't have to do anything for it to move towards a new",
    "start": "133020",
    "end": "139910"
  },
  {
    "text": "patch or a new feature set everything is automated for you fully managed fully",
    "start": "139910",
    "end": "145340"
  },
  {
    "text": "automated so looking at the redshift architecture we have a leader node the",
    "start": "145340",
    "end": "152540"
  },
  {
    "start": "147000",
    "end": "147000"
  },
  {
    "text": "leader node is your sequel endpoint which is where you send your sequel queries to it's your JDBC ODBC endpoint",
    "start": "152540",
    "end": "158900"
  },
  {
    "text": "as well it stores metadata about the cluster in itself it stores details about which node in",
    "start": "158900",
    "end": "165980"
  },
  {
    "text": "the cluster is having this particular key space what are all the queries that have been running on that what failed",
    "start": "165980",
    "end": "172790"
  },
  {
    "text": "curries are there whether we are using certain parameters like shortcut acceleration which I'm going to talk",
    "start": "172790",
    "end": "178670"
  },
  {
    "text": "about and these kind of stuff are stored in the metadata it also coordinates your",
    "start": "178670",
    "end": "184040"
  },
  {
    "text": "sequel processing it says how do I say which node should execute this piece of",
    "start": "184040",
    "end": "189950"
  },
  {
    "text": "the query it converts your sequel queries into C code and pushes it into the core nodes and then consumes it your",
    "start": "189950",
    "end": "196940"
  },
  {
    "text": "compute nodes are local store columnar stores they are locally storing all your",
    "start": "196940",
    "end": "202340"
  },
  {
    "text": "data on local disks you execute queries in parallel each of the nodes also have",
    "start": "202340",
    "end": "208489"
  },
  {
    "text": "multiple CPUs in them so they execute things in parallel each CPU is a slice for us it also helps you to load/unload",
    "start": "208489",
    "end": "216130"
  },
  {
    "text": "back up from the compute nodes the leader dot doesn't get involved in this",
    "start": "216130",
    "end": "221239"
  },
  {
    "text": "you may send a request to unload data or you may send a request to back up your cluster but all the hard work is being",
    "start": "221239",
    "end": "228319"
  },
  {
    "text": "done by the compute nodes it's not being done by the leader node last year we",
    "start": "228319",
    "end": "236239"
  },
  {
    "text": "released redshift spectrum which allows you to go and query data from the s3",
    "start": "236239",
    "end": "243139"
  },
  {
    "text": "buckets without having to load the data into a redshift cluster customers were",
    "start": "243139",
    "end": "248329"
  },
  {
    "text": "asking us for this feature for a long time there are two reasons that you increase the size of a cluster one",
    "start": "248329",
    "end": "254180"
  },
  {
    "text": "reason is you have run out of storage space so you need to add more a storage",
    "start": "254180",
    "end": "259609"
  },
  {
    "text": "space or you want more processing power we want you to Ray increase the size of",
    "start": "259609",
    "end": "264680"
  },
  {
    "text": "the cluster only because you have run out of processing power not because your run out of storage we would like you to keep",
    "start": "264680",
    "end": "271729"
  },
  {
    "text": "data that is not being frequently queried in the s3 layer and query it",
    "start": "271729",
    "end": "276979"
  },
  {
    "text": "from redshift spectra lectured spectrum is a massive cluster that runs its a",
    "start": "276979",
    "end": "283639"
  },
  {
    "text": "multi-tenant cluster that runs underneath redshift and it is accessible only by our Richard it's not accessible",
    "start": "283639",
    "end": "290360"
  },
  {
    "text": "outside Richard so you should be thinking toaster when I say redshift so",
    "start": "290360",
    "end": "300740"
  },
  {
    "start": "292000",
    "end": "292000"
  },
  {
    "text": "you don't want to know the underlying inside workings of the toaster what you want to know is how can I tune my",
    "start": "300740",
    "end": "307850"
  },
  {
    "text": "toaster so that my bread comes out in perfection right I need to understand what are all the tuners that I'm",
    "start": "307850",
    "end": "315590"
  },
  {
    "text": "available for me knobs that are available how can I increase how can I make it more warmer how can I there is a",
    "start": "315590",
    "end": "322639"
  },
  {
    "text": "freeze button on the toaster how do I use that freeze button all you need to do is that right it runs fast and cheap",
    "start": "322639",
    "end": "330500"
  },
  {
    "text": "that's what we wanted to do it just runs I don't want to worry about hi what's happening internally fought on the",
    "start": "330500",
    "end": "336440"
  },
  {
    "text": "toaster similarly redshift is something like that and we wanted to be a toaster for",
    "start": "336440",
    "end": "343940"
  },
  {
    "text": "you but what we also want you to know is what are all the knobs available for you",
    "start": "343940",
    "end": "350870"
  },
  {
    "text": "to tune your redshift cluster for peak performance and I'm going to walk you through a few of them today and I'm",
    "start": "350870",
    "end": "358250"
  },
  {
    "text": "happy to take questions I'll be available outside after this if you want to dive deep on certain areas or send me",
    "start": "358250",
    "end": "365510"
  },
  {
    "text": "an email as well the first feature that we released which we did not mark it too well was short",
    "start": "365510",
    "end": "372410"
  },
  {
    "start": "367000",
    "end": "367000"
  },
  {
    "text": "query acceleration a new cue is enabled for queries a cue is where your queries",
    "start": "372410",
    "end": "380270"
  },
  {
    "text": "run on redshift so on the cue we actually run the redshift and we give",
    "start": "380270",
    "end": "385520"
  },
  {
    "text": "six slots in that cue if you have set up your total concurrent users to be less",
    "start": "385520",
    "end": "392180"
  },
  {
    "text": "than 15 then short query acceleration is by default enabled for you you can",
    "start": "392180",
    "end": "398419"
  },
  {
    "text": "enable short Korea acceleration via the AP even if you have set it over 15 but we",
    "start": "398419",
    "end": "403430"
  },
  {
    "text": "feel that the ideal number should be 15 or else you are going to unnecessarily load the redshift cluster so when a",
    "start": "403430",
    "end": "414350"
  },
  {
    "text": "query is executing based on machine learning algorithms it understands which",
    "start": "414350",
    "end": "419390"
  },
  {
    "text": "query and what time it is going to execute for and then if it feels that this query is going to execute within",
    "start": "419390",
    "end": "425510"
  },
  {
    "text": "three seconds or five seconds it takes it out of this original queue and runs",
    "start": "425510",
    "end": "430580"
  },
  {
    "text": "it on the new queue that we have created with six slots on it this query once it",
    "start": "430580",
    "end": "436190"
  },
  {
    "text": "finishes the customer gets the results he doesn t do not have to wait for it if",
    "start": "436190",
    "end": "441290"
  },
  {
    "text": "it doesn't finish for some reason that's not finished in five seconds that we anticipated that it will finish we will",
    "start": "441290",
    "end": "447170"
  },
  {
    "text": "take the query and put it back in the same place in the old queue from where",
    "start": "447170",
    "end": "452180"
  },
  {
    "text": "we took it out which means the user doesn't feel anything he just continues to wait for the query to complete once",
    "start": "452180",
    "end": "458150"
  },
  {
    "text": "the query completes he gets the result out of it what is the advantage of doing short curly acceleration the advantages",
    "start": "458150",
    "end": "464690"
  },
  {
    "text": "of doing short carry acceleration is to ensure that people don't wait for",
    "start": "464690",
    "end": "470860"
  },
  {
    "text": "queries to complete we don't wait for queries to complete so if I can remove",
    "start": "470860",
    "end": "477200"
  },
  {
    "text": "five queries from the queue then five more queries can run faster on the existing queues that's the whole idea",
    "start": "477200",
    "end": "483740"
  },
  {
    "text": "behind short query acceleration based on initial tests that we did based on the",
    "start": "483740",
    "end": "491900"
  },
  {
    "text": "private beta that we opened up for customers we got a 3x throughput improvement on short curly workloads",
    "start": "491900",
    "end": "497660"
  },
  {
    "text": "with minimal effect on long running queries there is no effect on long running queries the short curry started",
    "start": "497660",
    "end": "504110"
  },
  {
    "text": "working better if you are having a Q separate for short queries you may want",
    "start": "504110",
    "end": "509570"
  },
  {
    "text": "to disregard that queue and start using short Korea acceleration it's a tick box in the console the tick box is enabled",
    "start": "509570",
    "end": "517550"
  },
  {
    "text": "only if your concurrency is set to less than 15 and it's the API call the API",
    "start": "517550",
    "end": "524960"
  },
  {
    "text": "call can be called even if your concurrency level is over 50",
    "start": "524960",
    "end": "530470"
  },
  {
    "text": "whistles caching this is one of the other features that we launched which helps you to fast-track your query",
    "start": "530960",
    "end": "538350"
  },
  {
    "start": "531000",
    "end": "531000"
  },
  {
    "text": "through the Q we will case your results for a query that has run and next time",
    "start": "538350",
    "end": "545100"
  },
  {
    "text": "when you run the same query we will give you the results on the cache and not have to go and fetch all the data and",
    "start": "545100",
    "end": "551700"
  },
  {
    "text": "process the query we are fully acid compliant so if you update the record we",
    "start": "551700",
    "end": "558780"
  },
  {
    "text": "will remove the results at cache so you don't have to worry about getting stale",
    "start": "558780",
    "end": "564570"
  },
  {
    "text": "data to your customers and we will provide you a cache size that is",
    "start": "564570",
    "end": "572190"
  },
  {
    "text": "proportional to the node type so if you choose a node type which is smaller you get a lesser cache if you choose a",
    "start": "572190",
    "end": "578190"
  },
  {
    "text": "higher bigger node type you get a bigger case for it we have given you a view",
    "start": "578190",
    "end": "583230"
  },
  {
    "text": "that tells you whether the query was returned because from a cached query or",
    "start": "583230",
    "end": "589260"
  },
  {
    "text": "from a regular occurring right late",
    "start": "589260",
    "end": "594920"
  },
  {
    "text": "materialization these are the feature that we launched but people really do",
    "start": "594920",
    "end": "601050"
  },
  {
    "text": "not understand this may be and this was again something that just got switched on right it was not something you had to",
    "start": "601050",
    "end": "608330"
  },
  {
    "text": "configure to nor anything like that so late metallization is aimed at reducing",
    "start": "608330",
    "end": "613560"
  },
  {
    "text": "IO on columns when you are reading columns with predicate filters on them",
    "start": "613560",
    "end": "619650"
  },
  {
    "text": "we can actually reduce the amount of i/o that we do on it with late",
    "start": "619650",
    "end": "625590"
  },
  {
    "text": "materialization you can also have compression on short keys because when",
    "start": "625590",
    "end": "631920"
  },
  {
    "text": "we read the data we would be able to understand and apply the predicates before you start using the query to get",
    "start": "631920",
    "end": "639600"
  },
  {
    "text": "more data out of the query a new column called is our LF scan on STL scan table",
    "start": "639600",
    "end": "645690"
  },
  {
    "text": "tells you whether we used late materialisation on a particular query and and you can figure out how many late",
    "start": "645690",
    "end": "654150"
  },
  {
    "text": "materialization queries have run and how much how much of i/o you have saved and",
    "start": "654150",
    "end": "659310"
  },
  {
    "text": "we every i/o saved is a query running faster under chat",
    "start": "659310",
    "end": "664700"
  },
  {
    "text": "this is something again we tuned inside the cluster not great marketing we did",
    "start": "665810",
    "end": "671370"
  },
  {
    "text": "not do any kind of marketing on this we increase the comet speeds when you're running your queries read only queries",
    "start": "671370",
    "end": "678480"
  },
  {
    "text": "we are but we have now started to batch all the check points together and these",
    "start": "678480",
    "end": "684540"
  },
  {
    "text": "check point batching effectively means that your queries are running faster executing faster on temporary tables as",
    "start": "684540",
    "end": "691500"
  },
  {
    "text": "well we will continue to work on this this is not the end of it we will continue to work on it we will continue",
    "start": "691500",
    "end": "697500"
  },
  {
    "text": "to work to ensure that we are able to provide better checkpointing on the redshift cluster awesome so those are",
    "start": "697500",
    "end": "705779"
  },
  {
    "text": "the features that I wanted to talk about let us now get into the best practices for using a redshift cluster migration",
    "start": "705779",
    "end": "718069"
  },
  {
    "start": "715000",
    "end": "715000"
  },
  {
    "text": "don't don't do a lift and shift friends",
    "start": "718069",
    "end": "723329"
  },
  {
    "text": "don't let friends do left and shift of their data warehousing clusters into redshift please make sure that you",
    "start": "723329",
    "end": "732899"
  },
  {
    "text": "follow our design guidelines make sure that you follow our best practices to",
    "start": "732899",
    "end": "738180"
  },
  {
    "text": "bring up your redshift cluster and port your data from your existing data warehouse into redshift",
    "start": "738180",
    "end": "744800"
  },
  {
    "text": "your final solution will use other AWS services as well it will not only be redshift",
    "start": "744800",
    "end": "750449"
  },
  {
    "text": "so you may want to glue in certain other services with red ship for example you",
    "start": "750449",
    "end": "756149"
  },
  {
    "text": "may want to put a post close sequel database having a materialized view of the data from redshift you can do that",
    "start": "756149",
    "end": "764040"
  },
  {
    "text": "today so your Co you mean you are not constrained only by redshift so think out of the box see how you can make your",
    "start": "764040",
    "end": "771720"
  },
  {
    "text": "data warehouse better so lifting and shifting doesn't solve your problem you",
    "start": "771720",
    "end": "777149"
  },
  {
    "text": "may end up in more problems when you do lift ensure please make use of solutions",
    "start": "777149",
    "end": "783420"
  },
  {
    "text": "architects Pro serve partners to come and help you don't wait till the problem",
    "start": "783420",
    "end": "789269"
  },
  {
    "text": "has hit the roof alright call us early on we are happy to",
    "start": "789269",
    "end": "794279"
  },
  {
    "text": "work with you we are happy to work with you to identify the solution for you identify design table designs for",
    "start": "794279",
    "end": "800670"
  },
  {
    "text": "you so that you can get the maximum out of the redshift cluster talk to your accountant we are more than happy to",
    "start": "800670",
    "end": "806459"
  },
  {
    "text": "help you data distribution is very important for a MPP data warehouse we",
    "start": "806459",
    "end": "814380"
  },
  {
    "start": "808000",
    "end": "808000"
  },
  {
    "text": "offer you three kinds of data distributions one is key level distribution value define a key and we",
    "start": "814380",
    "end": "820560"
  },
  {
    "text": "will distribute the data based on the king the other one is even distribution where we will evenly distribute the data",
    "start": "820560",
    "end": "827100"
  },
  {
    "text": "of a table across the cluster all the slices in the cluster the all",
    "start": "827100",
    "end": "832860"
  },
  {
    "text": "distribution keeps the data in the first slice of every node so if a node has two",
    "start": "832860",
    "end": "840810"
  },
  {
    "text": "slices the first slice will always have the data so the data is duplicated you",
    "start": "840810",
    "end": "846060"
  },
  {
    "text": "need to be careful when you use all because you don't want to use all on a 15 billion row table you will basically",
    "start": "846060",
    "end": "852959"
  },
  {
    "text": "be duplicating the data into all the nodes whereas all may be a good",
    "start": "852959",
    "end": "858560"
  },
  {
    "text": "distribution style for your dead dimension your data that is less than a",
    "start": "858560",
    "end": "866880"
  },
  {
    "text": "few million rows can be easily distributed on the allstar right the",
    "start": "866880",
    "end": "871920"
  },
  {
    "text": "whole idea behind distribution is to distribute the data evenly for parallel processing and also reduce the network",
    "start": "871920",
    "end": "879360"
  },
  {
    "text": "chatter between the nodes any network chatter is IO and if I cannot reduce the",
    "start": "879360",
    "end": "886200"
  },
  {
    "text": "IO my queries are not going to run faster so I need to reduce my IO again",
    "start": "886200",
    "end": "891829"
  },
  {
    "text": "distribution is very very critical for your optimal performance of your achieve",
    "start": "891829",
    "end": "897300"
  },
  {
    "text": "cluster table design I always say to",
    "start": "897300",
    "end": "904529"
  },
  {
    "start": "900000",
    "end": "900000"
  },
  {
    "text": "customers that 80% of your redshift cluster performance is stable design 20% is or 15% does query tuning and 5% is",
    "start": "904529",
    "end": "912810"
  },
  {
    "text": "our toaster which is redshift everything else is in your hands",
    "start": "912810",
    "end": "918120"
  },
  {
    "text": "if you don't design properly you will not get the best out of wretched",
    "start": "918120",
    "end": "923930"
  },
  {
    "text": "materialized often filtered columns into fact tables we like star schemas when I",
    "start": "923930",
    "end": "931470"
  },
  {
    "text": "say there's people say hey don't he like star schemas absolutely we love star schemas all right rich if love star schemas",
    "start": "931470",
    "end": "937410"
  },
  {
    "text": "but then if I'm going to join 300 tables to derive a value for a query can I",
    "start": "937410",
    "end": "943590"
  },
  {
    "text": "materialize that data into my fact table and reduce the number of joins I do every join is an i/o can I reduce the",
    "start": "943590",
    "end": "951120"
  },
  {
    "text": "i/o that I do on a particular HF cluster having said that I cannot materialize",
    "start": "951120",
    "end": "957690"
  },
  {
    "text": "every dimension into the fact table I would want to still have dimensions outside like my type 2 dimensions I",
    "start": "957690",
    "end": "963870"
  },
  {
    "text": "would like to have type two dimensions and these dimensions have to live outside we're not saying denormalize",
    "start": "963870",
    "end": "969870"
  },
  {
    "text": "completely we are saying denormalize where possible for example in your",
    "start": "969870",
    "end": "975090"
  },
  {
    "text": "address table if you have a country table and an address table and a country ID in your address table you can say I",
    "start": "975090",
    "end": "981600"
  },
  {
    "text": "will move my country codes into the address table I don't need to have it separately right so try to Deena",
    "start": "981600",
    "end": "988140"
  },
  {
    "text": "materialize what you can materialize leave what you cannot materialize and we will work through that keep data types",
    "start": "988140",
    "end": "997470"
  },
  {
    "text": "as wide as necessary I have seen customers go and say I'm just going to say bad cat 256 for everything that's",
    "start": "997470",
    "end": "1004880"
  },
  {
    "text": "not a good practice because I need to allocate 256 bytes of memory when I want",
    "start": "1004880",
    "end": "1010490"
  },
  {
    "text": "to process the data and when you say and you are only going to store like five characters in it why do you want to",
    "start": "1010490",
    "end": "1016310"
  },
  {
    "text": "allocate 256 bytes of memory on it right so we would like you to be cautious and",
    "start": "1016310",
    "end": "1022330"
  },
  {
    "text": "conscious of the fact that you would want to only allocate the amount of",
    "start": "1022330",
    "end": "1027650"
  },
  {
    "text": "memory that is needed so that your load operations are faster your queries run faster as well compression to columns",
    "start": "1027650",
    "end": "1035360"
  },
  {
    "text": "very critical please add compression to columns you need compression compression",
    "start": "1035360",
    "end": "1040640"
  },
  {
    "text": "we do anywhere from 2 X - 4 X compression on redshift on data stored in redshift and when you compress your",
    "start": "1040640",
    "end": "1046910"
  },
  {
    "text": "data the amount of i/o we do is limited as well so please do compression which",
    "start": "1046910",
    "end": "1052460"
  },
  {
    "text": "will improve your query performance had sort keys don't run without sort keys",
    "start": "1052460",
    "end": "1058550"
  },
  {
    "text": "you already know value of filtering on whenever you are filtering on use those filter columns as your sort keys",
    "start": "1058550",
    "end": "1065539"
  },
  {
    "text": "that'll improve your query performance dramatically improve your career performance so coming to copy and unload",
    "start": "1065539",
    "end": "1073629"
  },
  {
    "start": "1070000",
    "end": "1070000"
  },
  {
    "text": "we recommend delimited files don't do fixed-width files preferred delimited",
    "start": "1073629",
    "end": "1080600"
  },
  {
    "text": "files fixed with files the processor has to do more job to identify the data delimited files are better every slice",
    "start": "1080600",
    "end": "1090019"
  },
  {
    "text": "in a thread shift cluster if you run a DC 2x large we have two slices in every",
    "start": "1090019",
    "end": "1095840"
  },
  {
    "text": "node so every slice in the redshift cluster can actually load data so",
    "start": "1095840",
    "end": "1101479"
  },
  {
    "text": "instead of giving us one massive fight terabyte file and you have a 10 node cluster of DC 2x large which basically",
    "start": "1101479",
    "end": "1108019"
  },
  {
    "text": "means you have 20 slices split the file into 20 chunks and give it to us and the",
    "start": "1108019",
    "end": "1113899"
  },
  {
    "text": "load process will be very faster when you do that all right file should be 1",
    "start": "1113899",
    "end": "1121279"
  },
  {
    "text": "MB to 1 gig after compression don't give us files more than that because we",
    "start": "1121279",
    "end": "1126769"
  },
  {
    "text": "cannot really process them fast so if you split your files and give it to us that's the best way to do it and split",
    "start": "1126769",
    "end": "1132889"
  },
  {
    "text": "it at one gig checks use unload to extract large amounts of data you can",
    "start": "1132889",
    "end": "1139729"
  },
  {
    "text": "still use select statements to extract the data but then the Select statements are all funneled through the leader node",
    "start": "1139729",
    "end": "1145729"
  },
  {
    "text": "whereas when you use an unload function to extract the data the unload function",
    "start": "1145729",
    "end": "1151039"
  },
  {
    "text": "actually operates on the data nodes or the compute nodes and they run way",
    "start": "1151039",
    "end": "1156590"
  },
  {
    "text": "faster in parallel as well you can run non parallel unloads where do you want",
    "start": "1156590",
    "end": "1163340"
  },
  {
    "text": "to run on parallel unloads an unload operation will generate multiple files a",
    "start": "1163340",
    "end": "1168519"
  },
  {
    "text": "file per slice that you are having if you want to run get a single file then",
    "start": "1168519",
    "end": "1176090"
  },
  {
    "text": "it makes sense to run a non parallel unload but do it only for small amounts of data or else you will be hogging the",
    "start": "1176090",
    "end": "1182090"
  },
  {
    "text": "system trying to extract all that data to a single node ok there are customers",
    "start": "1182090",
    "end": "1190759"
  },
  {
    "start": "1187000",
    "end": "1187000"
  },
  {
    "text": "who do ETLs extract transform load and there are customers who do elts extract",
    "start": "1190759",
    "end": "1197389"
  },
  {
    "text": "load and then do a transform and that's a good practice it's not something that we say should not do we",
    "start": "1197389",
    "end": "1204800"
  },
  {
    "text": "just say that be aware of these best practices when you do an ELT ELT is done by customers because they",
    "start": "1204800",
    "end": "1212120"
  },
  {
    "text": "feel they have a redshift cluster that's not doing any work overnight and why would I spin up another EMR cluster or a",
    "start": "1212120",
    "end": "1219620"
  },
  {
    "text": "glue cluster to do the transformation why can't I do the transformations on drag shift on sequel so when you are",
    "start": "1219620",
    "end": "1227090"
  },
  {
    "text": "doing transformations use temporary tables with backup no option we don't",
    "start": "1227090",
    "end": "1233480"
  },
  {
    "text": "want to backup your temporary tables your staging tables your load tables we don't want to back them up put a backup",
    "start": "1233480",
    "end": "1239510"
  },
  {
    "text": "no option to them so that backups are not triggered for the whole the huge amount of data that you are bringing in",
    "start": "1239510",
    "end": "1245090"
  },
  {
    "text": "for you to do transformations on use the same style of distribution between the",
    "start": "1245090",
    "end": "1252380"
  },
  {
    "text": "staging tables and the primary table so that insert into selects are way faster they are not hindered by distribution if",
    "start": "1252380",
    "end": "1263870"
  },
  {
    "text": "you're copying lot of data use alter table append instead of insert as select",
    "start": "1263870",
    "end": "1270350"
  },
  {
    "text": "alter table append what it will do is it will take all the blocks of data format",
    "start": "1270350",
    "end": "1276260"
  },
  {
    "text": "the blocks and attach it to the existing table that's way faster than using",
    "start": "1276260",
    "end": "1281480"
  },
  {
    "text": "insert as select don't do compression",
    "start": "1281480",
    "end": "1288200"
  },
  {
    "text": "settings on comp update off put comp update off so that come default compressions are not done use analyze",
    "start": "1288200",
    "end": "1295010"
  },
  {
    "text": "compression and do the compression on those staging tables or copy the compression from your target tables into",
    "start": "1295010",
    "end": "1304550"
  },
  {
    "text": "the staging tables this is like brushing",
    "start": "1304550",
    "end": "1310880"
  },
  {
    "start": "1308000",
    "end": "1308000"
  },
  {
    "text": "your teeth you need to do it daily no options alright if you don't do it",
    "start": "1310880",
    "end": "1316340"
  },
  {
    "text": "you're going to have problems later on sure for sure right so vacuum and",
    "start": "1316340",
    "end": "1321560"
  },
  {
    "text": "analyze are critical things vacuum do it daily at least a delete only vacuum",
    "start": "1321560",
    "end": "1327290"
  },
  {
    "text": "daily so that your drawers which are deleted or come compacted and kept",
    "start": "1327290",
    "end": "1332330"
  },
  {
    "text": "do vacuum weekly which runs on a full table research the table compresses the",
    "start": "1332330",
    "end": "1338779"
  },
  {
    "text": "data gives you a very clean table with with no empty blocks in them analyze can",
    "start": "1338779",
    "end": "1345679"
  },
  {
    "text": "be run periodically after ingestion so that the optimizer gets the statistics of your ingestion analyzes meant for the",
    "start": "1345679",
    "end": "1354559"
  },
  {
    "text": "optimizer it's meant for the optimizer to decide whether I should do a merge join whether I should do a nested loop",
    "start": "1354559",
    "end": "1360110"
  },
  {
    "text": "whether I should do a hash join there is a utility to vacuum and analyze all the",
    "start": "1360110",
    "end": "1366799"
  },
  {
    "text": "tables in the cluster you can use that utility it's available on github on the AWS lab section please feel free to go",
    "start": "1366799",
    "end": "1374269"
  },
  {
    "text": "and download it modify it we have customers who have done changes to these",
    "start": "1374269",
    "end": "1381289"
  },
  {
    "text": "scripts and given it back to us and improve the quality of these curves",
    "start": "1381289",
    "end": "1387850"
  },
  {
    "start": "1388000",
    "end": "1388000"
  },
  {
    "text": "workload management and query monitoring rules workload management allows you to",
    "start": "1388659",
    "end": "1394460"
  },
  {
    "text": "specify queues and allows you to kill your queries if they are running over",
    "start": "1394460",
    "end": "1399620"
  },
  {
    "text": "time if they don't have enough memory enough CPU it's h on them qumar goes the",
    "start": "1399620",
    "end": "1406010"
  },
  {
    "text": "other way round it says let me monitor your query and tell you whether you are going to exceed the quota given to you",
    "start": "1406010",
    "end": "1412610"
  },
  {
    "text": "and then I will go and kill the query use qumar to better manage your queries",
    "start": "1412610",
    "end": "1418880"
  },
  {
    "text": "then wlm wlm should be used as the queueing technology for your business users for your general managers for your",
    "start": "1418880",
    "end": "1427940"
  },
  {
    "text": "data analysts separate queues for each of them but then qumar can be used for fine-grained access to those saying hey",
    "start": "1427940",
    "end": "1435139"
  },
  {
    "text": "if if a business analyst runs a query and it runs for more than 10 minutes kill the kwid right and again don't",
    "start": "1435139",
    "end": "1443149"
  },
  {
    "text": "start off by killing the queries you don't want to kill a curry of your GM alright because he ran a curry for 10",
    "start": "1443149",
    "end": "1448490"
  },
  {
    "text": "minutes or more start logging these queries look at the queries look at the logs and then understand what queries",
    "start": "1448490",
    "end": "1455990"
  },
  {
    "text": "are running and then decide what needs to be killed what are the functions that you need to use to kill it or whether",
    "start": "1455990",
    "end": "1462590"
  },
  {
    "text": "you need to you may not be the number of records right it may be the amount of GB",
    "start": "1462590",
    "end": "1468380"
  },
  {
    "text": "that he is fetching from spectrum you may want to use key Omar to even monitor and kill those queries save the",
    "start": "1468380",
    "end": "1476720"
  },
  {
    "text": "superuser queue for administrative tasks only don't give it off to your data analyst and ask them to run queries on",
    "start": "1476720",
    "end": "1482240"
  },
  {
    "text": "bother that is meant for administrative tasks if that queue is also blocked you don't have no ways of getting into the",
    "start": "1482240",
    "end": "1488600"
  },
  {
    "text": "cluster to run a query to kill liquid or to make modifications to a long-running",
    "start": "1488600",
    "end": "1494330"
  },
  {
    "text": "query right please make sure you use that we recommend that you use queue",
    "start": "1494330",
    "end": "1501620"
  },
  {
    "text": "Amar's or timeouts and not wlm they do they both do the same kind of things but",
    "start": "1501620",
    "end": "1506960"
  },
  {
    "text": "they come from different angles and it is easier to work with key Omar to manage this whole thing custom sizing",
    "start": "1506960",
    "end": "1517450"
  },
  {
    "start": "1516000",
    "end": "1516000"
  },
  {
    "text": "again I have seen customers come and tell me hey I'm going to run a single node cluster don't do that for",
    "start": "1517450",
    "end": "1523580"
  },
  {
    "text": "production it's good for tests but don't do that for production when you run a single node cluster we run the leader",
    "start": "1523580",
    "end": "1529430"
  },
  {
    "text": "node inside that single node cluster so the amount of CPU cycles required to run",
    "start": "1529430",
    "end": "1535850"
  },
  {
    "text": "the leader node is consumed from that single node that you are having if you run more than two nodes we will",
    "start": "1535850",
    "end": "1542680"
  },
  {
    "text": "give you a leader node outside your data nodes or your compute nodes which",
    "start": "1542680",
    "end": "1549380"
  },
  {
    "text": "effectively means your leader node is free of charge we don't charge you for a leader node so please run more than one",
    "start": "1549380",
    "end": "1556940"
  },
  {
    "text": "node redshift clusters testing purpose single node redshift clusters are good",
    "start": "1556940",
    "end": "1563710"
  },
  {
    "text": "the others challenge with single node clusters or small node clusters is every",
    "start": "1563710",
    "end": "1570320"
  },
  {
    "text": "spectrum job is allocated ten nodes per slice right or there abouts so when",
    "start": "1570320",
    "end": "1578900"
  },
  {
    "text": "there are only ten nodes that are allocated you will only get so much processing power from spectrum so you",
    "start": "1578900",
    "end": "1584660"
  },
  {
    "text": "will not be able to go and fetch petabytes of data from spectrum by running a single redshift cluster no",
    "start": "1584660",
    "end": "1590300"
  },
  {
    "text": "right so what we want you to do is size your cluster appropriately and use",
    "start": "1590300",
    "end": "1596810"
  },
  {
    "text": "spectrum for all the data that is",
    "start": "1596810",
    "end": "1601180"
  },
  {
    "text": "lifecycle to s3 from the red chef's cluster it's not used for hey I'll use",
    "start": "1601929",
    "end": "1607640"
  },
  {
    "text": "spectrum as an access layer for my data it's not supposed to be used like that it's supposed to be used like your",
    "start": "1607640",
    "end": "1613280"
  },
  {
    "text": "lifecycle data is sitting in s3 which is over seven years old and five years worth of data is sitting on the redshift",
    "start": "1613280",
    "end": "1620179"
  },
  {
    "text": "cluster I want to join these two then I would use redshift for that I'll use spectrum for that maintain at least 20",
    "start": "1620179",
    "end": "1629840"
  },
  {
    "text": "percent free space remember we are compressing the data when we want to do some work on the data we need to",
    "start": "1629840",
    "end": "1635720"
  },
  {
    "text": "uncompress the data we need that space to uncompress and run your queries we need to uncompress and do update",
    "start": "1635720",
    "end": "1641450"
  },
  {
    "text": "statements delete statements we need data for doing all that so please have 20% free space in your cluster for doing",
    "start": "1641450",
    "end": "1649159"
  },
  {
    "text": "that so again just repeating that point",
    "start": "1649159",
    "end": "1654740"
  },
  {
    "text": "sorry just repeating that point there maximum number of available spectrum",
    "start": "1654740",
    "end": "1659809"
  },
  {
    "text": "nodes is a function of your achieve cluster size remember that always if you",
    "start": "1659809",
    "end": "1665780"
  },
  {
    "text": "are using dc1 instances anybody using DC ones ok DC one is our old generation",
    "start": "1665780",
    "end": "1673039"
  },
  {
    "text": "instance compute instances please move to DC two instances DC two instances are far better same price nor additional",
    "start": "1673039",
    "end": "1680150"
  },
  {
    "text": "price you have to pay if you have got reserved instances please talk to your account teams we are more than happy to",
    "start": "1680150",
    "end": "1685429"
  },
  {
    "text": "migrate your reserved instances from DC ones to DC - right so a few additional",
    "start": "1685429",
    "end": "1693110"
  },
  {
    "text": "resources before I close this talk labs on github we have admin scripts which",
    "start": "1693110",
    "end": "1700580"
  },
  {
    "start": "1697000",
    "end": "1697000"
  },
  {
    "text": "allow you to do administrative tasks on the redshift cluster we have admin views",
    "start": "1700580",
    "end": "1706659"
  },
  {
    "text": "we have the analyze and vacuum utility that I spoke about so you can do analyze and vacuum for all the tables in the",
    "start": "1706659",
    "end": "1713000"
  },
  {
    "text": "redshift cluster to column encoding utility which allows you to look at what are the encoding types suitable for your",
    "start": "1713000",
    "end": "1721970"
  },
  {
    "text": "table drops the table recreates the table and copies the data back-end so it's a one-stop-shop for improving your",
    "start": "1721970",
    "end": "1729799"
  },
  {
    "text": "encoding for your tables you don't have to do it regularly but at least try to do it the early ones",
    "start": "1729799",
    "end": "1735469"
  },
  {
    "text": "because your data patterns would have changed from the day you started we would have introduced newer encoding",
    "start": "1735469",
    "end": "1741859"
  },
  {
    "text": "algorithms and that should help you to run your redshift cluster optimal so",
    "start": "1741859",
    "end": "1749719"
  },
  {
    "text": "these three blogs the first one table design playbook please take a printout",
    "start": "1749719",
    "end": "1755690"
  },
  {
    "text": "of it and keep it on your desk anytime you are doing design data model design",
    "start": "1755690",
    "end": "1761149"
  },
  {
    "text": "please refer to this very critical highly recommended top ten performance",
    "start": "1761149",
    "end": "1768950"
  },
  {
    "text": "tuning techniques for Amazon redshift it covers a lot of what I spoke today but in more depth please refer to this blog",
    "start": "1768950",
    "end": "1776629"
  },
  {
    "text": "as far if you are using spectrum I would recommend that you toss see this ten",
    "start": "1776629",
    "end": "1782389"
  },
  {
    "text": "best practices for using red shirts bactrim and remember red ship spectrum is not Athena they are two different",
    "start": "1782389",
    "end": "1787909"
  },
  {
    "text": "services right so please when something works doesn't work in spectrum don't say",
    "start": "1787909",
    "end": "1794959"
  },
  {
    "text": "hey it works in Athena why is it not working in spectrum there are two different services and we are trying to",
    "start": "1794959",
    "end": "1800299"
  },
  {
    "text": "make it as close to each other as possible feel free to give us your comments on what you think is working",
    "start": "1800299",
    "end": "1805969"
  },
  {
    "text": "what is not working and we are happy to improve on it so back to our toaster redshift is the toaster for you we want",
    "start": "1805969",
    "end": "1815119"
  },
  {
    "start": "1809000",
    "end": "1809000"
  },
  {
    "text": "you to think of it as a toaster we are working towards making it the toaster so that you don't have to worry about any",
    "start": "1815119",
    "end": "1820399"
  },
  {
    "text": "of those knobs but you still need those buttons and knobs to get the optimal use",
    "start": "1820399",
    "end": "1826009"
  },
  {
    "text": "of the toaster and you need to use that in redshift as well good data modeling",
    "start": "1826009",
    "end": "1831889"
  },
  {
    "text": "good distribution key is good encoding sort keys cluster size all these form",
    "start": "1831889",
    "end": "1838190"
  },
  {
    "text": "important parts of your redshift design I hope you enjoyed this start today",
    "start": "1838190",
    "end": "1843249"
  },
  {
    "text": "please fill in your feedbacks very important for us so that we can improve this session for the next summit let me",
    "start": "1843249",
    "end": "1850940"
  },
  {
    "text": "know if you have any questions I don't think I have time to take questions here but I will I'm available outside if you",
    "start": "1850940",
    "end": "1857450"
  },
  {
    "text": "want to ask any customs thank you guys yes",
    "start": "1857450",
    "end": "1862089"
  }
]
[
  {
    "start": "0",
    "end": "95000"
  },
  {
    "text": "good morning everyone did you have a good time at the party last night super are you all awake from the",
    "start": "2600",
    "end": "10960"
  },
  {
    "text": "party great so let us start planning for gold um remember this is a level 300",
    "start": "10960",
    "end": "17680"
  },
  {
    "text": "session so we would need you to have some amount of knowledge on simple",
    "start": "17680",
    "end": "23640"
  },
  {
    "text": "storage service Red shift kesis and elastic map reduce",
    "start": "23640",
    "end": "31080"
  },
  {
    "text": "as an individual probably you are generating reams of unstructured data as we are talking",
    "start": "32200",
    "end": "37559"
  },
  {
    "text": "now your mobile phones are generating data and if this data is harnessed you",
    "start": "37559",
    "end": "43399"
  },
  {
    "text": "would be able to derive lot of information from this data which will help you to understand your customers",
    "start": "43399",
    "end": "50120"
  },
  {
    "text": "and business better the unstructured data is a maze and in this session we are going to show you how you can",
    "start": "50120",
    "end": "57719"
  },
  {
    "text": "collect store and analyze this data scale to get a 360Â° business view of",
    "start": "57719",
    "end": "63600"
  },
  {
    "text": "your customers and your",
    "start": "63600",
    "end": "67159"
  },
  {
    "text": "business the cost of data generation is falling every day your watches mobile",
    "start": "69159",
    "end": "75200"
  },
  {
    "text": "phones Automobiles and even heavy duty machines are generating data the global",
    "start": "75200",
    "end": "81000"
  },
  {
    "text": "data is supposedly going to cross 40 zettabytes by",
    "start": "81000",
    "end": "86640"
  },
  {
    "text": "2020 and 85% of this data is going to to be unstructured",
    "start": "86640",
    "end": "93240"
  },
  {
    "text": "data so what is unstructured data unstructured data is data that",
    "start": "93240",
    "end": "99520"
  },
  {
    "start": "95000",
    "end": "95000"
  },
  {
    "text": "doesn't conform to any data model examples include personal",
    "start": "99520",
    "end": "105439"
  },
  {
    "text": "messaging business documents web documents and sensor outputs all your phones are generating",
    "start": "105439",
    "end": "112719"
  },
  {
    "text": "data today and you are sending them to the cloud somewhere so that somebody can process it and that data is unstructured",
    "start": "112719",
    "end": "119680"
  },
  {
    "text": "dat data object metadata or markup does not",
    "start": "119680",
    "end": "126759"
  },
  {
    "start": "123000",
    "end": "123000"
  },
  {
    "text": "alone give structure to the data it doesn't give structure to the data for example HTML has markup",
    "start": "126759",
    "end": "134720"
  },
  {
    "text": "information on it this markup information does not give you structure and it only provides you a means of",
    "start": "134720",
    "end": "141640"
  },
  {
    "text": "getting relevant information from the data you still need to classify it as unstructured data process it and create",
    "start": "141640",
    "end": "148840"
  },
  {
    "text": "structure on it there are four ways of the unstructured",
    "start": "148840",
    "end": "154920"
  },
  {
    "text": "data volume variety variability and",
    "start": "154920",
    "end": "161319"
  },
  {
    "text": "velocity 90% of the world's data has been generated in the last 2 years and",
    "start": "161319",
    "end": "167680"
  },
  {
    "text": "this velocity is going to increase in the future the four vs of unstructured data",
    "start": "167680",
    "end": "176840"
  },
  {
    "text": "poses many challenges where you need to innovate to get some information from the data",
    "start": "176840",
    "end": "184239"
  },
  {
    "text": "the variety of data makes sure that one size fits all solutions don't anymore",
    "start": "184239",
    "end": "190599"
  },
  {
    "text": "work for you you need to innovate on how you collect store and analyze data for",
    "start": "190599",
    "end": "197920"
  },
  {
    "text": "various data streams and each data stream is going to be unique for you in how you're going to collect the data or",
    "start": "197920",
    "end": "204080"
  },
  {
    "text": "store or analyze the data the amount of data that you need to",
    "start": "204080",
    "end": "209319"
  },
  {
    "text": "store for pre and postprocessing is going to be huge and the volume of data brings an",
    "start": "209319",
    "end": "216680"
  },
  {
    "text": "innovation on how you're going to store this data as I mentioned earlier your",
    "start": "216680",
    "end": "222920"
  },
  {
    "text": "velocity of data is always increasing and this needs a scalable solution where",
    "start": "222920",
    "end": "228280"
  },
  {
    "text": "you can sync all your evens in why do you need it to be scalable because the velocity is not",
    "start": "228280",
    "end": "235200"
  },
  {
    "text": "constant it's going to increase with time or decrease so maybe for reinvent",
    "start": "235200",
    "end": "240599"
  },
  {
    "text": "we had a million tweets coming in with the hashtag reinvent tomorrow I'll not have those tweets so I need to be have a",
    "start": "240599",
    "end": "248079"
  },
  {
    "text": "scalable solution that can go up or down as needed I then I have variability of",
    "start": "248079",
    "end": "255720"
  },
  {
    "text": "data so the variability brings in the other three vs are making it variable",
    "start": "255720",
    "end": "261199"
  },
  {
    "text": "you're making the other three vs variable and you need a solution that can scale up or down based on",
    "start": "261199",
    "end": "268199"
  },
  {
    "text": "that and AWS provides you Ways and Means",
    "start": "268199",
    "end": "273400"
  },
  {
    "text": "to harness this data at scale at a very low cost data generated from social media",
    "start": "273400",
    "end": "281960"
  },
  {
    "text": "from iot devices or your web page events needs to be stored in a high throughput",
    "start": "281960",
    "end": "288840"
  },
  {
    "text": "sync store and that can be kenesis Amazon kenesis is a realtime streaming",
    "start": "288840",
    "end": "295919"
  },
  {
    "text": "and processing service that allows you to store data at a very high velocity",
    "start": "295919",
    "end": "301039"
  },
  {
    "text": "for up to 24 hours for you to process later data stored in kesis can be",
    "start": "301039",
    "end": "308479"
  },
  {
    "text": "processed using applications running on ec2 these applications can scale up or",
    "start": "308479",
    "end": "315840"
  },
  {
    "text": "down based on the amount of data present in",
    "start": "315840",
    "end": "320240"
  },
  {
    "text": "kesis the data in kesis is processed or",
    "start": "321199",
    "end": "326440"
  },
  {
    "text": "pre-processed I would say pre-processed or massaged using these kesis applications this application if written",
    "start": "326440",
    "end": "333680"
  },
  {
    "text": "on Java or python can you make use of kesis client libraries to further",
    "start": "333680",
    "end": "339720"
  },
  {
    "text": "interact with kenesis in real time data stored in kenesis can also be",
    "start": "339720",
    "end": "345680"
  },
  {
    "text": "processed using elastic map reduce elastic map reduce is our service",
    "start": "345680",
    "end": "353280"
  },
  {
    "text": "that allows you to run scalable compute distributed scalable compute at scale",
    "start": "353280",
    "end": "361720"
  },
  {
    "text": "this data can be stored in S3 for further",
    "start": "361720",
    "end": "366759"
  },
  {
    "text": "processing you can also take data from web pages using applications running on",
    "start": "366759",
    "end": "373319"
  },
  {
    "text": "ec2 these applications again can scale up or down based on the number of web pages I need to visit to extract",
    "start": "373319",
    "end": "379560"
  },
  {
    "text": "information I can use part instances or on demand instances here which gives me the ability to scale up or down at a",
    "start": "379560",
    "end": "386080"
  },
  {
    "text": "very low cost the data collected from web pages is stored in S3 as",
    "start": "386080",
    "end": "392560"
  },
  {
    "text": "unstructured data and further processed using EMR and again stored back into",
    "start": "392560",
    "end": "400599"
  },
  {
    "text": "S3 so now we look at it you have got enrichment happening at various stages",
    "start": "400599",
    "end": "406520"
  },
  {
    "text": "for the unstructured data and this enrichment gives structure to your data",
    "start": "406520",
    "end": "412479"
  },
  {
    "text": "and you'll also notice that all data is being stored in S3 S3 is my",
    "start": "412479",
    "end": "418680"
  },
  {
    "text": "data Repository I store my unstructured and my structured data in S3 so what is structured",
    "start": "418680",
    "end": "427599"
  },
  {
    "start": "427000",
    "end": "427000"
  },
  {
    "text": "data structure data is data that resides in a database conforms to a data model",
    "start": "428240",
    "end": "435560"
  },
  {
    "text": "maybe resides in fields in a file as well but it conforms to a data",
    "start": "435560",
    "end": "441599"
  },
  {
    "text": "model and unlike unstructured data structured data is generated by missions or",
    "start": "441599",
    "end": "447400"
  },
  {
    "text": "applications an example is un structured data to structured data conversion so this data is generated by missiones or",
    "start": "447400",
    "end": "456039"
  },
  {
    "text": "your order entry system for an example structure data still exhibit the",
    "start": "456039",
    "end": "461319"
  },
  {
    "text": "four vs they still exhibit the four vs you need a scalable solution to store",
    "start": "461319",
    "end": "468919"
  },
  {
    "text": "and analyze this data as well apart from this it also exhibits a management",
    "start": "468919",
    "end": "475479"
  },
  {
    "text": "overhead of managing a database where you will store this data data you need to manage the database you need to",
    "start": "475479",
    "end": "481680"
  },
  {
    "text": "performance tune the database you need to backup the database Amazon's relational database",
    "start": "481680",
    "end": "488520"
  },
  {
    "text": "service Dynamo DB and red shift allows",
    "start": "488520",
    "end": "493599"
  },
  {
    "text": "you to concentrate on your business without",
    "start": "493599",
    "end": "498680"
  },
  {
    "text": "having to do undifferentiated heavy lifting of managing the database these",
    "start": "498680",
    "end": "504039"
  },
  {
    "text": "manage services allows you to run your database at scale",
    "start": "504039",
    "end": "510360"
  },
  {
    "start": "513000",
    "end": "513000"
  },
  {
    "text": "so let us continuing on the slide where I left on massaging the unstructured",
    "start": "513000",
    "end": "519719"
  },
  {
    "text": "data the data that is massaged by Kinesis applications can be stored in",
    "start": "519719",
    "end": "525760"
  },
  {
    "text": "Dynamo DB for further processing or can be used",
    "start": "525760",
    "end": "533519"
  },
  {
    "text": "for millisecond responses to your realtime dashboards",
    "start": "533519",
    "end": "540000"
  },
  {
    "text": "data stored in S3 can be loaded into red shift which a petabyte scale data",
    "start": "540360",
    "end": "546399"
  },
  {
    "text": "wouse which allows you to analyze the data using popular bi tools like Jasper",
    "start": "546399",
    "end": "553640"
  },
  {
    "text": "soft micro strategy",
    "start": "553640",
    "end": "557240"
  },
  {
    "text": "Etc at this time I would like to invite Krishna W from latent view on stage to",
    "start": "559399",
    "end": "566800"
  },
  {
    "text": "talk about how they built a highly scalable application using the AWS building",
    "start": "566800",
    "end": "572720"
  },
  {
    "text": "blocks to pan for gold for their customer",
    "start": "572720",
    "end": "578880"
  },
  {
    "text": "[Applause]",
    "start": "579870",
    "end": "585759"
  },
  {
    "text": "Krishan thank you AWS for this opportunity and thanks Ganesh for giving the introduction to the session",
    "start": "586480",
    "end": "594320"
  },
  {
    "text": "um before we quickly go on to how we panned uh for insights from unstructured",
    "start": "594320",
    "end": "600640"
  },
  {
    "text": "data let me talk to you about Laten view analytics I'm the director for west coast region for Laten view analytics we",
    "start": "600640",
    "end": "607240"
  },
  {
    "text": "are a leading and one of the fastest growing analytic service provider for Fortune 500 firms um we are an AWS",
    "start": "607240",
    "end": "614320"
  },
  {
    "text": "Advanced Consulting partner um we have over 500 people strong and we have over",
    "start": "614320",
    "end": "620279"
  },
  {
    "text": "50 people trained in AWS um in fact Deo has recognized us as um the top 5050",
    "start": "620279",
    "end": "627000"
  },
  {
    "text": "India compan uh the fastest top 50 India technology firms to look out",
    "start": "627000",
    "end": "632600"
  },
  {
    "text": "for so before we go into how we panned uh for gold in unstructured data I just",
    "start": "633880",
    "end": "640120"
  },
  {
    "text": "want us to go back in history in terms of how an online user was typically understood in past typically when you",
    "start": "640120",
    "end": "647120"
  },
  {
    "text": "wanted to understand online user Behavior you had two sources of data you basically had structured and",
    "start": "647120",
    "end": "652839"
  },
  {
    "text": "unstructured data sources from internal data you had customer profile typical",
    "start": "652839",
    "end": "658000"
  },
  {
    "text": "transaction characteristics about what the person is doing with your website Etc and you had some unstructured data",
    "start": "658000",
    "end": "664639"
  },
  {
    "text": "which is surveys customer reviews some of the support related conversations he is having and all of this is in there in",
    "start": "664639",
    "end": "671480"
  },
  {
    "text": "server server logs but increasingly we are finding out that this is just a one-way transaction",
    "start": "671480",
    "end": "679560"
  },
  {
    "text": "of a user with a company and that's not always the only version of",
    "start": "679560",
    "end": "686079"
  },
  {
    "text": "Truth so we feel that there is some missing part here and U some of our",
    "start": "686720",
    "end": "692600"
  },
  {
    "text": "clients have come to us and have asked us to identify what is this missing uh",
    "start": "692600",
    "end": "697680"
  },
  {
    "text": "part that we can potentially use to augment and enable them to do better I",
    "start": "697680",
    "end": "702839"
  },
  {
    "text": "mean to understand the customer better and the idea where we started uh",
    "start": "702839",
    "end": "708959"
  },
  {
    "start": "706000",
    "end": "706000"
  },
  {
    "text": "doing some of these projects is and where we built a solution called panel minor was to build a 360Â° view of the",
    "start": "708959",
    "end": "715639"
  },
  {
    "text": "customer where we not only had internal data as we typically had had but we also have external data what customers are",
    "start": "715639",
    "end": "723240"
  },
  {
    "text": "talking on in social media what they are doing for what is the kind of browsing",
    "start": "723240",
    "end": "728440"
  },
  {
    "text": "history that they're having on their mobile phones on their on different sites on their web pages Etc so this is",
    "start": "728440",
    "end": "734360"
  },
  {
    "text": "not only interaction with your firm's uh online presence but also your competitors Etc so now you have not only",
    "start": "734360",
    "end": "742160"
  },
  {
    "text": "data of interactions with your firm but you also have external data U or what",
    "start": "742160",
    "end": "748079"
  },
  {
    "text": "what I mean is a company complete view of what the user is looking for what the user is actually doing um in the",
    "start": "748079",
    "end": "756160"
  },
  {
    "text": "marketplace but now that comes with a lot of challenges one of the typical challenges is you have a ton of more",
    "start": "756160",
    "end": "762639"
  },
  {
    "start": "757000",
    "end": "757000"
  },
  {
    "text": "data to analyze so you know not only have your internal data but you also have external data and that brings a lot",
    "start": "762639",
    "end": "769880"
  },
  {
    "text": "of issues in terms of handling this in terms of infrastructure provisioning management and so it increases Capital",
    "start": "769880",
    "end": "776680"
  },
  {
    "text": "cost astronomically for clients we also notice that there are ever shortening SLA time",
    "start": "776680",
    "end": "786160"
  },
  {
    "text": "constraints so clients typically want analysis to be done very quickly",
    "start": "786160",
    "end": "791680"
  },
  {
    "text": "sometimes they want it real time sometimes they want it to be done very quickly and just because your data is increasing doesn't mean that your",
    "start": "791680",
    "end": "797760"
  },
  {
    "text": "clients are ready to wait for answers they actually want answers faster and quicker in some of our clients cases we",
    "start": "797760",
    "end": "804040"
  },
  {
    "text": "found out that almost one terabyte of data was being created from external sources which they were plowing down and the was just with a panel of about 90 to",
    "start": "804040",
    "end": "811240"
  },
  {
    "text": "100,000 users which was fairly dramatic and there was all the diverse data",
    "start": "811240",
    "end": "816680"
  },
  {
    "text": "sources so there is data that is done on web pages Mobile on your Safari browsers",
    "start": "816680",
    "end": "822440"
  },
  {
    "text": "different kind of browsers and you have also social data that is being there which is being aggregated along with",
    "start": "822440",
    "end": "827800"
  },
  {
    "text": "internal data so you have multiple sources to go so there's a new business challenge that is there and you need to",
    "start": "827800",
    "end": "833519"
  },
  {
    "text": "find out resources who are able to analyze all of this data and who have the technology experience and also the",
    "start": "833519",
    "end": "839160"
  },
  {
    "text": "analytics capability to do all of this so we when we initially did a uh",
    "start": "839160",
    "end": "846160"
  },
  {
    "text": "what we did was we did a proof of concept in terms of looking at can we create a 360Â° view of a customer and",
    "start": "846160",
    "end": "851519"
  },
  {
    "text": "like any other company we started with a small pilot we did this at a small scale we did this with couple of servers where",
    "start": "851519",
    "end": "857240"
  },
  {
    "text": "we had about 24 GB Ram um we had 16 uh CPUs um um I think it's about 5 terab of",
    "start": "857240",
    "end": "864839"
  },
  {
    "text": "storage Etc and we noticed that once we wanted to scale that I don't think we would",
    "start": "864839",
    "end": "871600"
  },
  {
    "text": "have been able to use um just server infrastructure to do this and we had to identify a Cloud solution to for this",
    "start": "871600",
    "end": "878199"
  },
  {
    "text": "whole thing and we actually benchmarked and looked at multiple ways we could do this and we narrowed down on AWS and why",
    "start": "878199",
    "end": "884920"
  },
  {
    "text": "we chose AWS I think the first important thing for our clients was there is no upfront capital expenditure you only pay",
    "start": "884920",
    "end": "891959"
  },
  {
    "text": "for what you analyze so depending on the amount of data that you want to analyze as much as the data is coming you only",
    "start": "891959",
    "end": "898040"
  },
  {
    "text": "pay for that you don't keep your you don't buy all the equipment for all the data and keep them idle you whenever you",
    "start": "898040",
    "end": "904320"
  },
  {
    "text": "need equipment to be provisioned you provision there is it's almost like a paysu go model so to say we were also",
    "start": "904320",
    "end": "911240"
  },
  {
    "text": "able to scale one of the things with our EMR solution we were able to scale almost take advantage of infinite",
    "start": "911240",
    "end": "918000"
  },
  {
    "text": "scaling so that we could shorten our lead time to deliver so we actually almost did at constant time which I'll be covering later on the",
    "start": "918000",
    "end": "925160"
  },
  {
    "text": "slide and we also found out that interestingly the cost total cost of ownership was much lower than going for",
    "start": "925160",
    "end": "931720"
  },
  {
    "text": "an in-house solution which was very good and the adoption was very easy the the greatest part of our the AWS system is",
    "start": "931720",
    "end": "938440"
  },
  {
    "text": "the strong support and auxiliary product services that are there you have different kind of services that are available so you can easily architect a",
    "start": "938440",
    "end": "945040"
  },
  {
    "text": "solution and build it out and it helps people who are just adopting Cloud",
    "start": "945040",
    "end": "950319"
  },
  {
    "text": "Solutions it it helps them to move to AWS very quickly and so this was a almost a no-brainer for us to use AWS",
    "start": "950319",
    "end": "956839"
  },
  {
    "text": "for a solution where we wanted to uh pan for unstructured",
    "start": "956839",
    "end": "962240"
  },
  {
    "text": "data so what I'll do in the next few slides is I will try to go through some of the challenges that we encountered as",
    "start": "962680",
    "end": "969880"
  },
  {
    "text": "we were analyzing some of this unstructured data and how we overcame it um which will give you food for thought",
    "start": "969880",
    "end": "974959"
  },
  {
    "text": "in terms of when you are looking for unstructured data analysis some of these things and you're looking at AWS as a",
    "start": "974959",
    "end": "981160"
  },
  {
    "text": "solution for enabling this for your customers you're able to understand what are the challenges we came up and hopefully would not make those same",
    "start": "981160",
    "end": "987800"
  },
  {
    "text": "mistakes so to say the first challenge that we had when we",
    "start": "987800",
    "end": "993680"
  },
  {
    "start": "991000",
    "end": "991000"
  },
  {
    "text": "looked at um the user Behavior was users are now continuously working on multiple",
    "start": "993680",
    "end": "999639"
  },
  {
    "text": "devices I think Ganesh mentioned that now people are interacting with your businesses through mobiles PCS tablets",
    "start": "999639",
    "end": "1006519"
  },
  {
    "text": "and we needed to analyze the behavior across multiple devices and there's different types of",
    "start": "1006519",
    "end": "1011759"
  },
  {
    "text": "data that is being created so one of the types of data is browsing history um which you're doing on your web pages so",
    "start": "1011759",
    "end": "1017759"
  },
  {
    "text": "you have you create your user profiles you have um HTML sessions that you have",
    "start": "1017759",
    "end": "1023519"
  },
  {
    "text": "you there is also location devices you're going through multiple uh places and you also create a lot of data around",
    "start": "1023519",
    "end": "1030400"
  },
  {
    "text": "in Social your Facebook feeds your Twitter feeds Etc so there's a ton of data that you're creating in in addition",
    "start": "1030400",
    "end": "1036199"
  },
  {
    "text": "to what you do which is a transaction with a with a company and there's also surveys and reviews um data that you",
    "start": "1036199",
    "end": "1043918"
  },
  {
    "text": "typically either at the end of a transaction or typically if you're part of a panel and you do uh surveys you",
    "start": "1043919",
    "end": "1049559"
  },
  {
    "text": "those are data that you would typically have and the method of collection for",
    "start": "1049559",
    "end": "1055720"
  },
  {
    "text": "all of these sources are different so for typically for social sources we used to write typical API so Twitter has",
    "start": "1055720",
    "end": "1061679"
  },
  {
    "text": "gives you apis Facebook gives you apis to be able to collect some of this data and for the second block we used third",
    "start": "1061679",
    "end": "1069600"
  },
  {
    "text": "party data providers who used um cookies to actually be able to um collect this",
    "start": "1069600",
    "end": "1074919"
  },
  {
    "text": "data and provide it to us on a batch mod",
    "start": "1074919",
    "end": "1079880"
  },
  {
    "start": "1079000",
    "end": "1079000"
  },
  {
    "text": "the other challenge that we found out was that there were multiple velocities in which the uh data",
    "start": "1080159",
    "end": "1087200"
  },
  {
    "text": "was coming so some of the browsing history that was being a made available to us was not in real time so we went",
    "start": "1087200",
    "end": "1093039"
  },
  {
    "text": "with the panel provider who used to aggregate this data and give Us Weekly",
    "start": "1093039",
    "end": "1098080"
  },
  {
    "text": "batches of data whereas social data came to us as a streaming data flow and",
    "start": "1098080",
    "end": "1104120"
  },
  {
    "text": "people wanted to have real-time visualization of um what are what is the sentiment about the brand as compared to",
    "start": "1104120",
    "end": "1110840"
  },
  {
    "text": "its competitors Etc in fact we had a demo also um that was set up in our",
    "start": "1110840",
    "end": "1116480"
  },
  {
    "text": "booth which talked about how we were doing the real-time streaming part but they also wanted to integrate this with batch data that was coming from the",
    "start": "1116480",
    "end": "1123760"
  },
  {
    "text": "panel so one of the things that we had to do was what we call create a unit",
    "start": "1123760",
    "end": "1128919"
  },
  {
    "text": "worker the problem of creating you've got a HTML data uh page you need to",
    "start": "1128919",
    "end": "1135559"
  },
  {
    "text": "create it into a structured data set for any analysis you need to identify what do people view what do people click and",
    "start": "1135559",
    "end": "1142679"
  },
  {
    "text": "what do they do on your uh online presence as compared to your competitors and for that just having raw HTML dumps",
    "start": "1142679",
    "end": "1149559"
  },
  {
    "text": "is not going to be helping so first what we had to do was we we wrote a python unit worker almost a unit cell which",
    "start": "1149559",
    "end": "1155880"
  },
  {
    "text": "showed us how to con um convert the unstructured data into a structured data set once you do",
    "start": "1155880",
    "end": "1162600"
  },
  {
    "text": "this how do you do this for a million files you have got a ton of browsing history now you need to convert all of",
    "start": "1162600",
    "end": "1168159"
  },
  {
    "text": "this unst structure Ed HTML files into structured data and we used Amazon EMR for that and once you have converted it",
    "start": "1168159",
    "end": "1175000"
  },
  {
    "text": "and return into your S3 buckets you need to load it into a data arrow and we used red shift for this because red shift was",
    "start": "1175000",
    "end": "1181520"
  },
  {
    "text": "um able to do very quick processing and I'll talk to you about some of the processing speeds that we were able to",
    "start": "1181520",
    "end": "1187039"
  },
  {
    "text": "achieve using red",
    "start": "1187039",
    "end": "1190240"
  },
  {
    "start": "1192000",
    "end": "1192000"
  },
  {
    "text": "shift the other challenge that we got as I mentioned and I alluded to it earlier was we us to get a week's worth of",
    "start": "1193120",
    "end": "1200679"
  },
  {
    "text": "browsing history on the users bundled into do tar.gz files for every single",
    "start": "1200679",
    "end": "1210159"
  },
  {
    "text": "day so you'll have for a week worth of data you'll have seven such files and they used to be dumped into an Amazon S3",
    "start": "1210159",
    "end": "1217080"
  },
  {
    "text": "location where they're typically um these files used to be about 10gb and once you uncompress them they used to be",
    "start": "1217080",
    "end": "1222679"
  },
  {
    "text": "about 50 to 100 GB depending on the data that they have and this had the user demography the contents the HTML pages",
    "start": "1222679",
    "end": "1230360"
  },
  {
    "text": "that the person has browsed what places has he clicked on which is very useful information to say what is the users",
    "start": "1230360",
    "end": "1237200"
  },
  {
    "text": "looking at and what is the user then responding to that so it's not enough to",
    "start": "1237200",
    "end": "1242320"
  },
  {
    "text": "show the coolest things unless the user doesn't do an action on top of that so we needed to download all of",
    "start": "1242320",
    "end": "1249840"
  },
  {
    "text": "these files extract them clean and upload them back so this was a parallel processing",
    "start": "1249840",
    "end": "1256679"
  },
  {
    "start": "1255000",
    "end": "1255000"
  },
  {
    "text": "architecture and we are actually now en capap ating this and hopefully we'll be moving this to the marketplace as well",
    "start": "1256679",
    "end": "1263559"
  },
  {
    "text": "where we have a base E2 base E2 node which the moment data is written it",
    "start": "1263559",
    "end": "1271760"
  },
  {
    "text": "used to pull the S3 buckets of the provider and say when they' have dropped in um data and once data has been",
    "start": "1271760",
    "end": "1278960"
  },
  {
    "text": "dropped the ec2 node will send job messages using Amazon sqs and it will",
    "start": "1278960",
    "end": "1285159"
  },
  {
    "text": "store these job messages in terms of how to read these files and what needs to be done the basic2 node will also launch",
    "start": "1285159",
    "end": "1292640"
  },
  {
    "text": "instances so it will launch seven instances and each of each of these instances would then independently pull",
    "start": "1292640",
    "end": "1299840"
  },
  {
    "text": "the jobs from the queue and the jobs would basically tell that take each of those star",
    "start": "1299840",
    "end": "1307039"
  },
  {
    "text": "files unzip untar them and basically process them write those outputs into the S3 output buckets and then destroy",
    "start": "1307039",
    "end": "1315840"
  },
  {
    "text": "yourself now there were multiple ways that we could have done this we could have actually had this as just cloned",
    "start": "1315840",
    "end": "1324159"
  },
  {
    "text": "instances but we actually chose to have them as plain vanilla instances where these machines will be bootstrapped up",
    "start": "1324159",
    "end": "1331520"
  },
  {
    "text": "we used to run take the code we used to put the code here and we used to actually run them and we found that much more flexible in our architecture when",
    "start": "1331520",
    "end": "1337679"
  },
  {
    "text": "we wanted to make code changes we wanted to be and in some cases where you have say multiple modeling techniques run you",
    "start": "1337679",
    "end": "1344159"
  },
  {
    "text": "would want each of these instances to operate differently also so they necessarily need not be evenly balanced",
    "start": "1344159",
    "end": "1350279"
  },
  {
    "text": "in this case it was um but it is possible that some instances will work faster than",
    "start": "1350279",
    "end": "1355960"
  },
  {
    "text": "other the important thing here to note is that there is once these instances",
    "start": "1355960",
    "end": "1361760"
  },
  {
    "text": "are launched they are they're on their own they don't have to have any interaction with the base ec2 node so",
    "start": "1361760",
    "end": "1368120"
  },
  {
    "text": "for example if the base ec2 node is goes down we don't lose this entire",
    "start": "1368120",
    "end": "1373840"
  },
  {
    "text": "processing we just lose some of the logs or some of the statistics that will be there in terms of processing but we",
    "start": "1373840",
    "end": "1379240"
  },
  {
    "text": "don't lose the work all of these instances can independently run and they",
    "start": "1379240",
    "end": "1384279"
  },
  {
    "text": "will write to the output in case one of the instances fails we keep having the alarms and",
    "start": "1384279",
    "end": "1390640"
  },
  {
    "text": "notifications to actually basically keep looking at the sqs keeps looking at whether all of the jobs are being done",
    "start": "1390640",
    "end": "1396200"
  },
  {
    "text": "and the job is not removed till the there is a successful out um successful",
    "start": "1396200",
    "end": "1401720"
  },
  {
    "text": "complete message that goes back so at the end of this what we would have is now that we have got this panel",
    "start": "1401720",
    "end": "1409120"
  },
  {
    "text": "provider has given us data for a week um we have now gotten the output up to a",
    "start": "1409120",
    "end": "1415600"
  },
  {
    "text": "million HTML files that are ready to be processed by our process but this",
    "start": "1415600",
    "end": "1420799"
  },
  {
    "text": "architecture was important because um we needed to do this on a fairly quick time",
    "start": "1420799",
    "end": "1426200"
  },
  {
    "text": "we actually looking at Ways by which we can instead of having this as a single",
    "start": "1426200",
    "end": "1432000"
  },
  {
    "text": "tar gz file for every day we could have it for a day cross hour so now you have",
    "start": "1432000",
    "end": "1437480"
  },
  {
    "text": "168 instance that you can potentially have you don't have to just do it at 7 days so there are ways to optimize for",
    "start": "1437480",
    "end": "1442799"
  },
  {
    "text": "this as well to increase the extraction process um but this is how we were able to do it and these are S2 S3 buckets can",
    "start": "1442799",
    "end": "1450159"
  },
  {
    "text": "now now the HTML files can be consumed by a process in terms of how you can convert it to into structured",
    "start": "1450159",
    "end": "1457799"
  },
  {
    "text": "data so now that you've got all the HTML files the next challenge is okay the HTML files are great but how do you",
    "start": "1457799",
    "end": "1463640"
  },
  {
    "start": "1458000",
    "end": "1458000"
  },
  {
    "text": "convert them to structured data and you needed to move the HTML file into a",
    "start": "1463640",
    "end": "1469880"
  },
  {
    "text": "structured data set around different features different uh elements of the",
    "start": "1469880",
    "end": "1475880"
  },
  {
    "text": "HTML uh things which are important for the client so we used a tree based",
    "start": "1475880",
    "end": "1481919"
  },
  {
    "text": "comparison logic to extract features from the HTML so we identified that",
    "start": "1481919",
    "end": "1487279"
  },
  {
    "text": "typically in a tree traversal logic you will have you'll start with a head and",
    "start": "1487279",
    "end": "1492679"
  },
  {
    "text": "you'll start with a HTML head and you'll have the div classes Etc and as the",
    "start": "1492679",
    "end": "1498720"
  },
  {
    "text": "python worker would go here there would be a rules engine that we have written saying that this means that if once you",
    "start": "1498720",
    "end": "1505039"
  },
  {
    "text": "have gone to this side this means that you have identified feature one please extract this information and put it into",
    "start": "1505039",
    "end": "1510559"
  },
  {
    "text": "a table and we would then go across this and we will read that entire HTML it's almost like a tree traversal",
    "start": "1510559",
    "end": "1518120"
  },
  {
    "text": "logic and so there were three layers that are or three levers one is the HTML data that is there that is the parser",
    "start": "1518120",
    "end": "1524679"
  },
  {
    "text": "which actually parsers through the entire HTML structure and once it identifies a certain path it goes and",
    "start": "1524679",
    "end": "1531559"
  },
  {
    "text": "I'm sorry it goes and checks for the rules engine to see whether this rule",
    "start": "1531559",
    "end": "1536679"
  },
  {
    "text": "has been configured now there are some interesting scenarios here web pages are not constant people introduce new",
    "start": "1536679",
    "end": "1542840"
  },
  {
    "text": "features right so you have new things that are constantly being introduced so this rules engine is your key to be",
    "start": "1542840",
    "end": "1550399"
  },
  {
    "text": "continuously updated so your rules need to be continuously so we used to update it on almost a weekly basis in which we",
    "start": "1550399",
    "end": "1557000"
  },
  {
    "text": "update rules for the new features that typically happen and we also identify",
    "start": "1557000",
    "end": "1562159"
  },
  {
    "text": "which rules are no more uh this one so for example if your competitor is",
    "start": "1562159",
    "end": "1567679"
  },
  {
    "text": "changing certain features he could change it either at the level at the div level he changes",
    "start": "1567679",
    "end": "1573919"
  },
  {
    "text": "the entire feature or he introduces a new div class Etc you will be now able to identify which kind of new features",
    "start": "1573919",
    "end": "1579480"
  },
  {
    "text": "are being launched you can also identify among those features what has",
    "start": "1579480",
    "end": "1584679"
  },
  {
    "text": "been the user engagement so great that he has launched a new feature lot of users have seen it but there's not",
    "start": "1584679",
    "end": "1590000"
  },
  {
    "text": "enough coverage or there's not enough engagement so this was extremely useful to start analyzing feature new feature",
    "start": "1590000",
    "end": "1597399"
  },
  {
    "text": "introduction into the P into the users how many of them are looking at it what is their response rates and this kind of",
    "start": "1597399",
    "end": "1603559"
  },
  {
    "text": "data was not available to uh to our clients at all so we used to extract all",
    "start": "1603559",
    "end": "1609320"
  },
  {
    "text": "visible features I mean invisible features are not really required because those are not things that the user is",
    "start": "1609320",
    "end": "1614919"
  },
  {
    "text": "seeing so we only extracted visible features and also Al the layout and position of each feature which is very",
    "start": "1614919",
    "end": "1620360"
  },
  {
    "text": "critical to identify which are those parts in a web page that people are actually recognizing so is the the F",
    "start": "1620360",
    "end": "1627440"
  },
  {
    "text": "kind of U heat map still existent on is there a different kind of heat map on your web page because of your web design",
    "start": "1627440",
    "end": "1633760"
  },
  {
    "text": "these are all inputs that can potentially be got from this",
    "start": "1633760",
    "end": "1637799"
  },
  {
    "text": "analysis so I a simple um illustration of how this process would be is that all",
    "start": "1639159",
    "end": "1645360"
  },
  {
    "text": "of the panel data and the web or the web logs would be the source of the data we'll also have social data and these are",
    "start": "1645360",
    "end": "1651360"
  },
  {
    "text": "unstructured data that is potentially there you would have this is the python unit worker that does the tree traversal",
    "start": "1651360",
    "end": "1658039"
  },
  {
    "text": "logic and it reads the rules engine and it basically outputs a",
    "start": "1658039",
    "end": "1663760"
  },
  {
    "text": "feature or it outputs tweets and whether the sentiment is positive or negative",
    "start": "1663760",
    "end": "1670039"
  },
  {
    "text": "Etc and so this data is now structured which is great but you needed to scale a processing so the unique thing for us",
    "start": "1670039",
    "end": "1677480"
  },
  {
    "text": "was that one of the things or one of the curve balls that the client threw to us was irrespective of the amount of data",
    "start": "1677480",
    "end": "1684360"
  },
  {
    "text": "you need to do this in constant time once you have reach this process if I have if I give you um a million files",
    "start": "1684360",
    "end": "1691559"
  },
  {
    "text": "and in this case it was a few terabytes of data so if it is tens of terabytes of data or hundreds of terabytes of data",
    "start": "1691559",
    "end": "1698399"
  },
  {
    "text": "you need to still constantly process this and that became a unique CH challenge for us because we needed to",
    "start": "1698399",
    "end": "1704559"
  },
  {
    "text": "Scale based on the input load and we had to use Amazon EMR for this where we were",
    "start": "1704559",
    "end": "1709640"
  },
  {
    "text": "able to scale our processing depending on what the input load was and what we also needed to",
    "start": "1709640",
    "end": "1715760"
  },
  {
    "text": "understand was how would we go with it so should we go with on demand or spot instances or should we go with reserved",
    "start": "1715760",
    "end": "1723080"
  },
  {
    "text": "instances one of the things here was we actually had to do multiple iterations and looking at multiple variations of",
    "start": "1723080",
    "end": "1729279"
  },
  {
    "text": "input load availability of spot instances and on demand in some cases we we were fairly aggressive we went from a",
    "start": "1729279",
    "end": "1734880"
  },
  {
    "text": "20% on demand 80% spot and we realized that the reliability is a bit lower so",
    "start": "1734880",
    "end": "1741120"
  },
  {
    "text": "we are not we not sure whether we'll keep getting enough instances to do it so we had a Time based s and we had also",
    "start": "1741120",
    "end": "1747080"
  },
  {
    "text": "cost based metric that we wanted to be conscious of how much cost we were incurring and after a lot of iterations",
    "start": "1747080",
    "end": "1752960"
  },
  {
    "text": "we were able to actually narrow down on the fact that a 66% on demand and 33% spot in senses worked for us to have a",
    "start": "1752960",
    "end": "1760039"
  },
  {
    "text": "comfortable leeway to meet the slas that we had and we ensured that we were um",
    "start": "1760039",
    "end": "1765080"
  },
  {
    "text": "having enough leeway and we were also cost competive",
    "start": "1765080",
    "end": "1770039"
  },
  {
    "text": "and when you have a large number of files you had a million set of HTML files you have to have a memory",
    "start": "1770200",
    "end": "1775919"
  },
  {
    "text": "intensive name node um because there was so many so when I talk about million",
    "start": "1775919",
    "end": "1781320"
  },
  {
    "text": "files we had we also encountered what we call a small file problem and we also had a huge name node which had to have",
    "start": "1781320",
    "end": "1787440"
  },
  {
    "text": "the pointers in terms of if I run multiple processes that are uh processing these HTML files you needed",
    "start": "1787440",
    "end": "1793080"
  },
  {
    "text": "to have a name node which actually had the pointers to which are the different HTML files being processed under which",
    "start": "1793080",
    "end": "1798240"
  },
  {
    "text": "units and what are the outputs being written the small file problem is the Amazon EMR has a unique way of",
    "start": "1798240",
    "end": "1804799"
  },
  {
    "text": "allocating memory um it allocates memory for a job and when you have a million",
    "start": "1804799",
    "end": "1810000"
  },
  {
    "text": "files to be processed we were quickly running out of memory issues so some EMR fine tuning steps were done by us the",
    "start": "1810000",
    "end": "1816279"
  },
  {
    "text": "technical team actually went through and we worked with ganesh's Team to actually go through some EMR fine tuning",
    "start": "1816279",
    "end": "1821559"
  },
  {
    "text": "processes by which we overcame this we ensure that um the the instances that we",
    "start": "1821559",
    "end": "1827399"
  },
  {
    "text": "were spinning on a persistent and we also didn't allocate too much of memory so we were able to solve some of this",
    "start": "1827399",
    "end": "1833320"
  },
  {
    "text": "but in case this the small file uh uh problem is actually critical because",
    "start": "1833320",
    "end": "1838600"
  },
  {
    "text": "sometimes it brings down the entire cluster it actually can uh bring down the cluster so when in testing we actually notice that this is a fairly",
    "start": "1838600",
    "end": "1844799"
  },
  {
    "text": "critical thing that if you have a large number of files to be processed in Amazon EMR you need to be careful in terms of whether you're going to uh",
    "start": "1844799",
    "end": "1852799"
  },
  {
    "text": "whether you're going to have memory problems or not we also had to have transparent",
    "start": "1852799",
    "end": "1858320"
  },
  {
    "text": "reporting of usage and stats which we used Dynamo db4 and we also had a unique case in which since we had a million",
    "start": "1858320",
    "end": "1865240"
  },
  {
    "text": "files which were on the date format on the ddmm y y format we had an Amazon S3 race",
    "start": "1865240",
    "end": "1872639"
  },
  {
    "text": "condition and let me just talk to you a bit about that which is typically when you have the ddmm YY uh kind of format",
    "start": "1872639",
    "end": "1881639"
  },
  {
    "text": "when you write the out uh write output into S3 typically the first character is what",
    "start": "1881639",
    "end": "1887080"
  },
  {
    "text": "is used as an an entry point into the S3 buckets and so what happened was because",
    "start": "1887080",
    "end": "1892720"
  },
  {
    "text": "say we had from 10th march to 17th March that was the week of data that was available we had just one entry point",
    "start": "1892720",
    "end": "1898600"
  },
  {
    "text": "that was one right and this became an issue we could have the mm and y y are",
    "start": "1898600",
    "end": "1904960"
  },
  {
    "text": "not changing in the in our file format so we are having an issue that we have just one entry point and we have a large number of files so we are hitting a",
    "start": "1904960",
    "end": "1911240"
  },
  {
    "text": "raise condition scenario so one of the things that we needed to do and one of the things that are very critical here",
    "start": "1911240",
    "end": "1916279"
  },
  {
    "text": "is to have an hash key generator we did a simple hash key generator where we actually took we took a standard date",
    "start": "1916279",
    "end": "1923360"
  },
  {
    "text": "we actually took January 1st 2010 as a standard date and any date file that you",
    "start": "1923360",
    "end": "1928720"
  },
  {
    "text": "take you look at the number of days since the start of the January 1 2010 so",
    "start": "1928720",
    "end": "1934679"
  },
  {
    "text": "you took say today minus the number of days you find out the number of days and you did a modulo 35 operation on that",
    "start": "1934679",
    "end": "1941360"
  },
  {
    "text": "the Modo 35 operation will come out with what the day index will be and now instead of having one day index you",
    "start": "1941360",
    "end": "1948000"
  },
  {
    "text": "could potentially have up to 35 day indexes or one or two or three right and",
    "start": "1948000",
    "end": "1953919"
  },
  {
    "text": "we also then went so we said okay we have 35 entry points which is very good we've said let's do a second iteration",
    "start": "1953919",
    "end": "1961799"
  },
  {
    "text": "which we'll once you have got into the day you can also have other sub entry points and we created the week index so",
    "start": "1961799",
    "end": "1967399"
  },
  {
    "text": "we did the same thing we found out the number of days we did a Modelo 7 so we found out the week and then we did a",
    "start": "1967399",
    "end": "1972720"
  },
  {
    "text": "Model 35 and found out a new index in terms of what is the weak index also So",
    "start": "1972720",
    "end": "1978360"
  },
  {
    "text": "based on this we were actually able to create a fairly large index format but what you will interestingly note is that",
    "start": "1978360",
    "end": "1984600"
  },
  {
    "text": "the first character was now 35 entry points this actually helped us increase",
    "start": "1984600",
    "end": "1990200"
  },
  {
    "text": "the number of entry points into the S3 output and this was fairly critical um because we were noticing that once we",
    "start": "1990200",
    "end": "1995799"
  },
  {
    "text": "were able to process we were not able to write the output correctly into the S3 which was pretty painful for us so this",
    "start": "1995799",
    "end": "2003000"
  },
  {
    "text": "hash key generation was fairly critical now once you have stored this data into S3 buckets you kind of need to have a",
    "start": "2003000",
    "end": "2009639"
  },
  {
    "text": "way of retrieval so you need to have a reverse hash key generator so anytime you want to say I want to look at what",
    "start": "2009639",
    "end": "2015559"
  },
  {
    "text": "is my user behavior on so and so date you need to identify what the hash key was so you needed to have that in your",
    "start": "2015559",
    "end": "2020960"
  },
  {
    "text": "red shift database or somewhere to basically programmatically tell that this is the uh place that you're trying",
    "start": "2020960",
    "end": "2026519"
  },
  {
    "text": "to look for I told you at some point of time in",
    "start": "2026519",
    "end": "2033200"
  },
  {
    "start": "2029000",
    "end": "2029000"
  },
  {
    "text": "terms of sometime earlier that irrespec of the number of files we needed to process in constant time and this was",
    "start": "2033200",
    "end": "2039519"
  },
  {
    "text": "actually achieved using the uh Amazon EMR if you notice initially we were um I",
    "start": "2039519",
    "end": "2046840"
  },
  {
    "text": "would say not very efficient we were actually just learning the ropes but from week six onwards we pretty much",
    "start": "2046840",
    "end": "2052280"
  },
  {
    "text": "have a flat line in terms of processing and we were also able to start looking at Ways by which we can",
    "start": "2052280",
    "end": "2059480"
  },
  {
    "text": "optimize the costs and in fact from week 19 which was the fifth month after we",
    "start": "2059480",
    "end": "2064878"
  },
  {
    "text": "started getting here we found out various input sizes and this was",
    "start": "2064879",
    "end": "2070000"
  },
  {
    "text": "actually double the amount of input that we were getting earlier but we were processing all of this in constant time",
    "start": "2070000",
    "end": "2075158"
  },
  {
    "text": "in fact this since then I think this is now in week week 100 or week 150 and we",
    "start": "2075159",
    "end": "2080878"
  },
  {
    "text": "are still on constant time so there's a fairly rig robust process it's it's fairly well evolved and we noticed that",
    "start": "2080879",
    "end": "2088960"
  },
  {
    "text": "um Amazon's reliability is extremely good as compared to some of the competitors that that are out",
    "start": "2088960",
    "end": "2095760"
  },
  {
    "start": "2095000",
    "end": "2095000"
  },
  {
    "text": "there what of the unique challenges that we did was we took a lot of time into solving the problem of taking out the",
    "start": "2095760",
    "end": "2102520"
  },
  {
    "text": "unstructured data uh from the HTML files putting it we've got the social data Etc and when we loaded all of this data",
    "start": "2102520",
    "end": "2109480"
  },
  {
    "text": "into Amazon rad shift we were not thinking of what are the kind of questions that the business wants to solve we were very looking at getting",
    "start": "2109480",
    "end": "2116760"
  },
  {
    "text": "the data available so what we noticed was we had another project where we wanted to",
    "start": "2116760",
    "end": "2122680"
  },
  {
    "text": "optimize the Amazon rad shift performance we were seeing that some of the queries were taking about 15 to 20",
    "start": "2122680",
    "end": "2127839"
  },
  {
    "text": "minutes and then we sat with ganesh's team and said we really need to get this to a sub minute query that was one of",
    "start": "2127839",
    "end": "2133760"
  },
  {
    "text": "the requirements or mandates from the client that we cannot be sitting for 20 minutes in front of a console waiting for data to come out so the first",
    "start": "2133760",
    "end": "2141440"
  },
  {
    "text": "approach was seeing that whether we can denormalized tables let's not have too many joints that are there which are",
    "start": "2141440",
    "end": "2146960"
  },
  {
    "text": "fairly expensive operations as you would all know so we had to have uh highly Deniz tables so we would trade off space",
    "start": "2146960",
    "end": "2154800"
  },
  {
    "text": "um to time and then what we decided was we tried to see what are the kind of",
    "start": "2154800",
    "end": "2160079"
  },
  {
    "text": "questions that we're looking and can we set appropriate distribution keys and sort keys so the distribution Keys what",
    "start": "2160079",
    "end": "2166920"
  },
  {
    "text": "are the kind of um joints that people are doing what are the kind of Chara",
    "start": "2166920",
    "end": "2172079"
  },
  {
    "text": "characteristics that people are looking for so am I looking for what is the page experience on iPad versus iPhone that",
    "start": "2172079",
    "end": "2178960"
  },
  {
    "text": "tells me that if I'm comparing between form factors form factors is a critical key to have or if I'm not really looking",
    "start": "2178960",
    "end": "2185119"
  },
  {
    "text": "at uh form factors then I don't really need to keep that as a s keep so how should I organize my data so we took a",
    "start": "2185119",
    "end": "2191640"
  },
  {
    "text": "set of business questions that are typically or we went did a poll of the business users and found out that there",
    "start": "2191640",
    "end": "2197520"
  },
  {
    "text": "are typically a lot of certain uh or certain Keys which they very commonly used and we started saying let's use",
    "start": "2197520",
    "end": "2204839"
  },
  {
    "text": "them as the appropriate distribution and sort keys and just by using them we were able to improve the performance by",
    "start": "2204839",
    "end": "2212040"
  },
  {
    "text": "aex what we also realized after doing this is that red shift has also to do",
    "start": "2212040",
    "end": "2218119"
  },
  {
    "text": "compression of the data and that actually improves it significantly just by using our existing and not changing",
    "start": "2218119",
    "end": "2224200"
  },
  {
    "text": "any distribution or S key we could improve just by using the compression Technique we could use it by 40x or 40",
    "start": "2224200",
    "end": "2230920"
  },
  {
    "text": "times so in a combination when we were able to do it queries which were taking about 20 minutes came down to about 20",
    "start": "2230920",
    "end": "2237160"
  },
  {
    "text": "to 30 seconds and that was really remarkable for them that they were now",
    "start": "2237160",
    "end": "2242520"
  },
  {
    "text": "multiple teams could actually Access Data get queries quick responses to their queries the other thing that we",
    "start": "2242520",
    "end": "2248560"
  },
  {
    "text": "noticed as we were doing this is there's some amount of Maintenance that needs to be done on red shift we need to",
    "start": "2248560",
    "end": "2254000"
  },
  {
    "text": "periodically do some kind of defragmentation of your so you so you as",
    "start": "2254000",
    "end": "2259200"
  },
  {
    "text": "you are actually moving data into red shift you typically create chunks of blocks Etc so vacuum and analyze",
    "start": "2259200",
    "end": "2265400"
  },
  {
    "text": "typically sees that all of this data is aggregated in the right form so you're actually putting all of the data in a",
    "start": "2265400",
    "end": "2270520"
  },
  {
    "text": "continuous format so that helps in actually querying Etc so periodic um execution of vacuum and analyze actually",
    "start": "2270520",
    "end": "2277520"
  },
  {
    "text": "I would say one of the things that a database administrator should constantly look at and it should be part of your process in terms of maintaining a",
    "start": "2277520",
    "end": "2284319"
  },
  {
    "text": "pipeline and you can also scale up and scale down the data varrow on demand so obviously you can have more nodes SP up",
    "start": "2284319",
    "end": "2290319"
  },
  {
    "text": "if you've got much more data and as as well as you can scale down the number of red shift nodes that were",
    "start": "2290319",
    "end": "2296760"
  },
  {
    "start": "2297000",
    "end": "2297000"
  },
  {
    "text": "there lastly we had the challenge in terms of analyzing as I talked about so this is the panel data we also had some",
    "start": "2298160",
    "end": "2305200"
  },
  {
    "text": "of the social data that is coming which needed to be analyzed real time so",
    "start": "2305200",
    "end": "2310560"
  },
  {
    "text": "customers wanted to definitely look at um taking them along with the panel data",
    "start": "2310560",
    "end": "2315880"
  },
  {
    "text": "but they also wanted to understand some of the themes Etc when campaigns are being launched what are the top themes",
    "start": "2315880",
    "end": "2321760"
  },
  {
    "text": "so what is the sentiment of what consumers are talking about so we used U Amazon ec2 workers uh um scaled up",
    "start": "2321760",
    "end": "2330040"
  },
  {
    "text": "Amazon ec2 workers and then we also used a s inhouse sentimental algorithm and a lexical parel and what this used to do",
    "start": "2330040",
    "end": "2337560"
  },
  {
    "text": "was it used to give out um the top themes that are occurring and what is the sentiment around this and this used",
    "start": "2337560",
    "end": "2343280"
  },
  {
    "text": "to compare with the top sentiments and themes of a competition so when you do a launch um what is the theme and what is",
    "start": "2343280",
    "end": "2350200"
  },
  {
    "text": "the sentiment around the launch what are the key themes that or key topics that people are talking about Etc and there is all there's also ability to do",
    "start": "2350200",
    "end": "2357200"
  },
  {
    "text": "real-time visualization of this on a flowing data so we actually had done this for reinvent we had actually got the reinvent U Twitter stream being uh",
    "start": "2357200",
    "end": "2365079"
  },
  {
    "text": "done live in our booth as well um and what you can do is once you have created this template I will talk about",
    "start": "2365079",
    "end": "2371680"
  },
  {
    "text": "the cloud deployment template in the next slide as the AWS toolkit for infrastructure",
    "start": "2371680",
    "end": "2379079"
  },
  {
    "start": "2375000",
    "end": "2375000"
  },
  {
    "text": "and process so this was some of the services that we used um we used the identity and access management for",
    "start": "2379079",
    "end": "2385440"
  },
  {
    "text": "overall security and access um we use the cloud watch to monitor the infrastructure so how the cluster is doing we had Dynamic scaling in Amazon",
    "start": "2385440",
    "end": "2393599"
  },
  {
    "text": "EMR so we used auto scaling we used for notifications simp simp email services to say this is for cost thresholds this",
    "start": "2393599",
    "end": "2400839"
  },
  {
    "text": "is for usage thresholds we used to use this and this was some notifications that we wanted to do to see whether we need to",
    "start": "2400839",
    "end": "2406640"
  },
  {
    "text": "intervene um and also when processes get completed when processing is completed you wanted to use notification services",
    "start": "2406640",
    "end": "2412319"
  },
  {
    "text": "for that so if I look at the overall",
    "start": "2412319",
    "end": "2418040"
  },
  {
    "text": "architecture of what we looked at so we had all these devices that used to give us data and we have an identity access",
    "start": "2418040",
    "end": "2425599"
  },
  {
    "text": "manager that controls this entire Cloud solution we had three buckets which was",
    "start": "2425599",
    "end": "2430640"
  },
  {
    "text": "social data social streaming data we had the provider data this was the panel data of the browsing history",
    "start": "2430640",
    "end": "2437160"
  },
  {
    "text": "that people were having and there was some internal uh client data that was there as well the provided data we had a",
    "start": "2437160",
    "end": "2444920"
  },
  {
    "text": "parall processing architecture to extract the data and put it into Amazon S3 buckets these were the HTML files that are ready for processing then we",
    "start": "2444920",
    "end": "2452160"
  },
  {
    "text": "used Amazon EMR with a 66% on demand and 33% spot",
    "start": "2452160",
    "end": "2457839"
  },
  {
    "text": "to actually write the output back into S3 buckets for surveys and reviews we used",
    "start": "2457839",
    "end": "2464760"
  },
  {
    "text": "a similar thing to the social where we used e to content crawlers and we had lexical analyzers to actually identify",
    "start": "2464760",
    "end": "2471160"
  },
  {
    "text": "top themes and sentiments of what people are talking about in the survey this was the unstructured part in terms of comments that you're giving in survey",
    "start": "2471160",
    "end": "2477720"
  },
  {
    "text": "which we would also write into S3 buckets and the social data was being streamed in real time we had used Amazon",
    "start": "2477720",
    "end": "2483720"
  },
  {
    "text": "kinosis and we had autoscaling sentiment Passover workers as Ganesh alluded to it",
    "start": "2483720",
    "end": "2490000"
  },
  {
    "text": "earlier that depending on the amount of data you needed to have multiple sentiment parer flows or lexical parser",
    "start": "2490000",
    "end": "2496280"
  },
  {
    "text": "workers to actually process all of the social data and put it into the S3",
    "start": "2496280",
    "end": "2501400"
  },
  {
    "text": "buckets once you have created this infrastructure what we used was AWS cloud formation because we needed to",
    "start": "2501400",
    "end": "2506800"
  },
  {
    "text": "replicate this for different regions and as you know online companies would want to have want to look at different",
    "start": "2506800",
    "end": "2512440"
  },
  {
    "text": "regions from a security perspective there are different things that they want to typically replicate so weuse used this AWS cloud formation to be able",
    "start": "2512440",
    "end": "2519440"
  },
  {
    "text": "to create deployment templates of this architecture for multiple regions so it could be scaled or uh deployed in",
    "start": "2519440",
    "end": "2525640"
  },
  {
    "text": "multiple regions very quickly all of these S3 outputs as Ganesh also mentioned about was written into Amazon",
    "start": "2525640",
    "end": "2533400"
  },
  {
    "text": "R shift which was a unified data store and we used this for a lot of reasons one is it was in the AWS ecosystem it",
    "start": "2533400",
    "end": "2540240"
  },
  {
    "text": "was also much faster than a lot of other data stores that we looked at and we used Amazon Dynamo DB for",
    "start": "2540240",
    "end": "2547760"
  },
  {
    "text": "operations tracking a lot of this was one of the things uh that typically clients ask for is it's great to know",
    "start": "2547760",
    "end": "2554240"
  },
  {
    "text": "that the process ran successfully what is the time what is the cost transparent reporting so we had all of this",
    "start": "2554240",
    "end": "2560079"
  },
  {
    "text": "happening at real time so nobody used to come out with a report Etc this used to automatically be there there used to be",
    "start": "2560079",
    "end": "2565880"
  },
  {
    "text": "a visualization in terms the visualization that you saw earlier in terms of constant time used to come out of the Dynamo",
    "start": "2565880",
    "end": "2572079"
  },
  {
    "text": "DB and this red shift database was then used for mining um insights so you could",
    "start": "2572079",
    "end": "2577839"
  },
  {
    "text": "look at what kind of features are comp are your competitors giving richer features on their page are they giving",
    "start": "2577839",
    "end": "2583680"
  },
  {
    "text": "better user experience are users more engaged on them are they spending more time and a lot of questions once this",
    "start": "2583680",
    "end": "2589880"
  },
  {
    "text": "data was available this this was truly data that had that can be merged with",
    "start": "2589880",
    "end": "2595040"
  },
  {
    "text": "internal data which is any internal transaction behavior and youve got now a 360 degree view of the customer which",
    "start": "2595040",
    "end": "2600520"
  },
  {
    "text": "was used a lot for a lot of product planning marketing customer retention",
    "start": "2600520",
    "end": "2605559"
  },
  {
    "text": "based initiatives",
    "start": "2605559",
    "end": "2609119"
  },
  {
    "start": "2610000",
    "end": "2610000"
  },
  {
    "text": "as I'm winding down I would say that some of the key takeaways that I would say is or the learnings that we had was",
    "start": "2611599",
    "end": "2617880"
  },
  {
    "text": "I would visualize the process and the problem workflow and map out the requirements and the services available",
    "start": "2617880",
    "end": "2623079"
  },
  {
    "text": "so what are we really looking to conquer are we looking for a way to what kind of data are we",
    "start": "2623079",
    "end": "2630920"
  },
  {
    "text": "looking at real time are we looking at batch identify your problem statement and then try to visualize the process",
    "start": "2630920",
    "end": "2636400"
  },
  {
    "text": "workflow and I think this is fairly critical in terms of architecting your solution and very importantly you should",
    "start": "2636400",
    "end": "2642599"
  },
  {
    "text": "also estimate the amount of data flow that would typically be there so it is easy to build a pilot to identify your solution but also to identify what would",
    "start": "2642599",
    "end": "2649520"
  },
  {
    "text": "be the amount of data flow that would be there we actually encountered as I talked to you about the race conditions",
    "start": "2649520",
    "end": "2655000"
  },
  {
    "text": "um that was basically about not foreseeing those problems well enough so I think one of the great things would be",
    "start": "2655000",
    "end": "2660760"
  },
  {
    "text": "to see how your data would flow into your different buckets and how that would actually be used and consumed I think shift is also one of",
    "start": "2660760",
    "end": "2668520"
  },
  {
    "text": "those places where I think you should have a sound underlying model you should understand why it has been architectured",
    "start": "2668520",
    "end": "2674559"
  },
  {
    "text": "in a certain way why are distribution Keys s Keys Etc being used in a certain way it's very good to work with the",
    "start": "2674559",
    "end": "2680599"
  },
  {
    "text": "business and trying to understand what are the questions that they are looking for and that's very powerful in terms of fine tuning red",
    "start": "2680599",
    "end": "2687280"
  },
  {
    "text": "shift and we should ensure alarms and monitors I think this is very critical",
    "start": "2687280",
    "end": "2692359"
  },
  {
    "text": "for any cloud-based deployment when things are going great it's always going great but you could have that rare event",
    "start": "2692359",
    "end": "2698520"
  },
  {
    "text": "when say your name node is going down and you need to very quickly restart the process Etc we use alarms and monitors",
    "start": "2698520",
    "end": "2704200"
  },
  {
    "text": "very very um effectively to be able to monitor each and every step of the process whether everything worked right",
    "start": "2704200",
    "end": "2711000"
  },
  {
    "text": "look at statistics and see okay there were certain processes that failed they restarted Etc how do we make them more",
    "start": "2711000",
    "end": "2717520"
  },
  {
    "text": "durable are there things that are there other fail safe operations that we need to do and one of the most important things",
    "start": "2717520",
    "end": "2724079"
  },
  {
    "text": "is architect in a way that your infrastructure and processes scalable and repeatable um so when we created the",
    "start": "2724079",
    "end": "2730000"
  },
  {
    "text": "python unit worker I think one of the key things that we learned is now that we' have created the way to take",
    "start": "2730000",
    "end": "2735079"
  },
  {
    "text": "unstructured data and created into structured data we needed to scale this process scale this across regions Etc so",
    "start": "2735079",
    "end": "2740160"
  },
  {
    "text": "it's extremely important to architect a solution which is scalable and",
    "start": "2740160",
    "end": "2745559"
  },
  {
    "text": "repeatable once we did this some of the things that our clients had to mention about some of the work that we did was a",
    "start": "2747400",
    "end": "2753040"
  },
  {
    "text": "lot of the business impact in fact This was um we had about we took about one10",
    "start": "2753040",
    "end": "2758800"
  },
  {
    "text": "the cost half the cost and we were about 10 times as faster than a conventional setup and the team size that we had",
    "start": "2758800",
    "end": "2764640"
  },
  {
    "text": "deployed for a project like this was about I think 12 12th of the overall team that used to generate insights and",
    "start": "2764640",
    "end": "2770920"
  },
  {
    "text": "we were responsible for about one3 of the business impact that was uh there in this client's um",
    "start": "2770920",
    "end": "2777920"
  },
  {
    "text": "pnl and a lot of the dread shift tuning also a lot of the analysts were actually",
    "start": "2777920",
    "end": "2783079"
  },
  {
    "text": "extremely happy by uh being able to do submitted queries I think uh the fact that they were able to do very quick",
    "start": "2783079",
    "end": "2788960"
  },
  {
    "text": "queries analyze data very quickly and that two terabytes of data was something",
    "start": "2788960",
    "end": "2794599"
  },
  {
    "text": "that they they had not seen even in their internal infrastructure so that was pretty cool for them and I think the",
    "start": "2794599",
    "end": "2800599"
  },
  {
    "text": "business teams were very the product planning the marketing teams were very um happy with the kind of insight that",
    "start": "2800599",
    "end": "2806480"
  },
  {
    "text": "they were able to get about the customers so they now they had views about what the customer was doing benchmarking them to competition what",
    "start": "2806480",
    "end": "2813559"
  },
  {
    "text": "they doing say for example not only on their website but also on other apps other websites that the person is",
    "start": "2813559",
    "end": "2820000"
  },
  {
    "text": "actually browsing Etc and so the one of the things that they took this was actually this was one",
    "start": "2820000",
    "end": "2825800"
  },
  {
    "text": "of the key inputs into product planning decisions that were typically done in the Strategic road map and trying to see what drives user Behavior what are the",
    "start": "2825800",
    "end": "2832160"
  },
  {
    "text": "things that could be done potentially so hopefully you guys had some sense in terms of how we developed",
    "start": "2832160",
    "end": "2838680"
  },
  {
    "text": "the solution and I hope this session helped we have uh a few flyers in terms of the panel minor solution that we that",
    "start": "2838680",
    "end": "2845599"
  },
  {
    "text": "I just talked about and um hopefully um my technical team will also be able to answer any other questions that you have",
    "start": "2845599",
    "end": "2852040"
  },
  {
    "text": "specifically to the solution that we build but thanks thanks a lot for coming thanks for your time",
    "start": "2852040",
    "end": "2858480"
  }
]
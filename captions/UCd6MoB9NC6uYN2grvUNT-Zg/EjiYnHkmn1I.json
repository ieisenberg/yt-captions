[
  {
    "text": "- Hey folks, Emily here today.",
    "start": "300",
    "end": "2040"
  },
  {
    "text": "You are gonna learn how\nto get started with MLOps",
    "start": "2040",
    "end": "4680"
  },
  {
    "text": "on Amazon SageMaker for generative AI.",
    "start": "4680",
    "end": "7229"
  },
  {
    "text": "So let's dive in.",
    "start": "7230",
    "end": "8280"
  },
  {
    "text": "All right, so what on Earth is MLOps",
    "start": "8280",
    "end": "10710"
  },
  {
    "text": "and why do we need this for generative AI?",
    "start": "10710",
    "end": "12900"
  },
  {
    "text": "So MLOps, of course, is a very broad field",
    "start": "12900",
    "end": "15480"
  },
  {
    "text": "that encompasses people,\nprocesses, and technology",
    "start": "15480",
    "end": "18599"
  },
  {
    "text": "to help you deploy your\nmodels more efficiently.",
    "start": "18600",
    "end": "20970"
  },
  {
    "text": "Now, deploying a model is not just",
    "start": "20970",
    "end": "23070"
  },
  {
    "text": "about creating a RESTful API.",
    "start": "23070",
    "end": "25439"
  },
  {
    "text": "Although of course it can be.",
    "start": "25440",
    "end": "27210"
  },
  {
    "text": "At first, of course, you need to find",
    "start": "27210",
    "end": "28890"
  },
  {
    "text": "the right deployment technique,",
    "start": "28890",
    "end": "30689"
  },
  {
    "text": "then you need to integrate\nthat deployment technique",
    "start": "30690",
    "end": "33510"
  },
  {
    "text": "into the rest of your application.",
    "start": "33510",
    "end": "35250"
  },
  {
    "text": "So if you're building an\nenterprise search system,",
    "start": "35250",
    "end": "38100"
  },
  {
    "text": "if you're standing up a chatbot,\nif you are creating media,",
    "start": "38100",
    "end": "42989"
  },
  {
    "text": "if you are creating, you\nknow, any sort of new content",
    "start": "42990",
    "end": "46200"
  },
  {
    "text": "that you wanna use a\nlarge language model for,",
    "start": "46200",
    "end": "49680"
  },
  {
    "text": "then essentially you need\nto integrate that model",
    "start": "49680",
    "end": "52740"
  },
  {
    "text": "into the rest of your user flow.",
    "start": "52740",
    "end": "54300"
  },
  {
    "text": "So that integration stop\nis really important.",
    "start": "54300",
    "end": "56910"
  },
  {
    "text": "Once you've integrated the\nmodel into the application,",
    "start": "56910",
    "end": "60360"
  },
  {
    "text": "you wanna keep it healthy,\nyou wanna check it,",
    "start": "60360",
    "end": "62970"
  },
  {
    "text": "you wanna monitor it, you\nwanna run retraining pipelines",
    "start": "62970",
    "end": "67560"
  },
  {
    "text": "to ensure that it stays up to date.",
    "start": "67560",
    "end": "69659"
  },
  {
    "text": "A pipeline is a technology,\nis a piece of technology",
    "start": "69660",
    "end": "72993"
  },
  {
    "text": "that you can build to help\nautomate your processes,",
    "start": "72993",
    "end": "76320"
  },
  {
    "text": "so automate model evaluation,\nautomate your integration,",
    "start": "76320",
    "end": "81090"
  },
  {
    "text": "and then automate your deployment,",
    "start": "81090",
    "end": "83009"
  },
  {
    "text": "and all of that helps you\nbuild technology more quickly.",
    "start": "83010",
    "end": "86580"
  },
  {
    "text": "So once you get into a\nplace where you can add,",
    "start": "86580",
    "end": "89790"
  },
  {
    "text": "you know, new code and ship\nchanges to your application",
    "start": "89790",
    "end": "93360"
  },
  {
    "text": "and then trigger pipelines",
    "start": "93360",
    "end": "95640"
  },
  {
    "text": "to automatically integrate those features",
    "start": "95640",
    "end": "98460"
  },
  {
    "text": "into your application and then\ndeploy those on a schedule,",
    "start": "98460",
    "end": "102690"
  },
  {
    "text": "then you can start to\nactually ship changes",
    "start": "102690",
    "end": "105360"
  },
  {
    "text": "and features to your\ncode for your customers,",
    "start": "105360",
    "end": "107340"
  },
  {
    "text": "which is the place we all wanna get to.",
    "start": "107340",
    "end": "109560"
  },
  {
    "text": "And so today we're gonna get started",
    "start": "109560",
    "end": "111899"
  },
  {
    "text": "with SageMaker pipelines\nas a technology you can use",
    "start": "111900",
    "end": "116022"
  },
  {
    "text": "to build your own pipelines",
    "start": "116022",
    "end": "118170"
  },
  {
    "text": "to help establish your MLOps\npractices across the board.",
    "start": "118170",
    "end": "121680"
  },
  {
    "text": "So let's dive in.",
    "start": "121680",
    "end": "123150"
  },
  {
    "text": "All right, and so I have created",
    "start": "123150",
    "end": "126180"
  },
  {
    "text": "a number of pipelines for you.",
    "start": "126180",
    "end": "127650"
  },
  {
    "text": "We're gonna take a look at\nthese here in SageMaker Studio.",
    "start": "127650",
    "end": "130740"
  },
  {
    "text": "Now, these are LLM evaluation pipelines.",
    "start": "130740",
    "end": "134160"
  },
  {
    "text": "So these are pipelines that you can run",
    "start": "134160",
    "end": "136530"
  },
  {
    "text": "to understand how well\ndifferent models are performing",
    "start": "136530",
    "end": "139470"
  },
  {
    "text": "for a variety of topics.",
    "start": "139470",
    "end": "141690"
  },
  {
    "text": "Now, you can follow along\nin the source code with me.",
    "start": "141690",
    "end": "145170"
  },
  {
    "text": "So this is a repository\nthat's available publicly,",
    "start": "145170",
    "end": "148470"
  },
  {
    "text": "and essentially you can use this",
    "start": "148470",
    "end": "150510"
  },
  {
    "text": "to learn about SageMaker pipelines,",
    "start": "150510",
    "end": "154170"
  },
  {
    "text": "such as the new launch last year",
    "start": "154170",
    "end": "156750"
  },
  {
    "text": "that lets you create a step in a pipeline",
    "start": "156750",
    "end": "159210"
  },
  {
    "text": "just by adding a couple lines of code",
    "start": "159210",
    "end": "161292"
  },
  {
    "text": "as wrappers around your content.",
    "start": "161292",
    "end": "164070"
  },
  {
    "text": "So it should be much easier",
    "start": "164070",
    "end": "165750"
  },
  {
    "text": "to create pipelines using your functions.",
    "start": "165750",
    "end": "169290"
  },
  {
    "text": "And then essentially you're gonna track",
    "start": "169290",
    "end": "171000"
  },
  {
    "text": "those pipelines together\nusing SageMaker pipelines.",
    "start": "171000",
    "end": "174390"
  },
  {
    "text": "Now, if you already have\na different MLOps tooling",
    "start": "174390",
    "end": "177750"
  },
  {
    "text": "that you'd prefer to use,",
    "start": "177750",
    "end": "179490"
  },
  {
    "text": "and then point to the\nlower level SageMaker APIs",
    "start": "179490",
    "end": "182100"
  },
  {
    "text": "and frameworks, you absolutely can.",
    "start": "182100",
    "end": "184140"
  },
  {
    "text": "I'm just gonna show you how to\nuse these SageMaker pipelines",
    "start": "184140",
    "end": "187110"
  },
  {
    "text": "to create this evaluation pipeline.",
    "start": "187110",
    "end": "189990"
  },
  {
    "text": "So let's get started.",
    "start": "189990",
    "end": "191940"
  },
  {
    "text": "So over here, of course, you see",
    "start": "191940",
    "end": "193470"
  },
  {
    "text": "I have a variety of pipelines.",
    "start": "193470",
    "end": "195990"
  },
  {
    "text": "So the first pipeline\nwe're gonna take a look at",
    "start": "195990",
    "end": "198030"
  },
  {
    "text": "is evaluating a single model.",
    "start": "198030",
    "end": "200550"
  },
  {
    "text": "And so that is right here.",
    "start": "200550",
    "end": "203730"
  },
  {
    "text": "So again, in SageMaker Studio,",
    "start": "203730",
    "end": "205409"
  },
  {
    "text": "it's really nice that you\ncan visualize the pipelines",
    "start": "205410",
    "end": "208620"
  },
  {
    "text": "and look at all of the\ndifferent steps in your pipeline",
    "start": "208620",
    "end": "211260"
  },
  {
    "text": "to ensure that it's built appropriately.",
    "start": "211260",
    "end": "213569"
  },
  {
    "text": "So the first step in this pipeline",
    "start": "213570",
    "end": "215580"
  },
  {
    "text": "was deploying a Llama\ntext generation model.",
    "start": "215580",
    "end": "219030"
  },
  {
    "text": "Let me zoom out here a little bit",
    "start": "219030",
    "end": "221250"
  },
  {
    "text": "so you still have a nice visual.",
    "start": "221250",
    "end": "223023"
  },
  {
    "text": "All right, great, so the\nfirst step was deploying",
    "start": "224190",
    "end": "226740"
  },
  {
    "text": "the 7 billion parameter Llama model.",
    "start": "226740",
    "end": "229950"
  },
  {
    "text": "And then the next step was pre-processing.",
    "start": "229950",
    "end": "232739"
  },
  {
    "text": "And so we can see our source S3 buckets,",
    "start": "232740",
    "end": "236430"
  },
  {
    "text": "that remote function\nthat created the pipeline",
    "start": "236430",
    "end": "239519"
  },
  {
    "text": "and some of the packages and dependencies.",
    "start": "239520",
    "end": "242220"
  },
  {
    "text": "And then after that,\nwe evaluated the model.",
    "start": "242220",
    "end": "245340"
  },
  {
    "text": "So then we went through\nthis evaluation step",
    "start": "245340",
    "end": "248790"
  },
  {
    "text": "to evaluate that model",
    "start": "248790",
    "end": "250530"
  },
  {
    "text": "and then ultimately clean up the process.",
    "start": "250530",
    "end": "253230"
  },
  {
    "text": "And so this pipeline is a really simple",
    "start": "253230",
    "end": "257040"
  },
  {
    "text": "and quick way of showing\nhow to first deploy model",
    "start": "257040",
    "end": "261030"
  },
  {
    "text": "and then pre-process data sets\nand then evaluate the model",
    "start": "261030",
    "end": "264240"
  },
  {
    "text": "on those data sets all in one flow.",
    "start": "264240",
    "end": "266699"
  },
  {
    "text": "And this is using our FMEval\nlibrary under the hood",
    "start": "266700",
    "end": "270450"
  },
  {
    "text": "to help you evaluate language\nmodels really quickly.",
    "start": "270450",
    "end": "273540"
  },
  {
    "text": "So that's evaluating one model.",
    "start": "273540",
    "end": "275520"
  },
  {
    "text": "Now, let's look at\nevaluating multiple models.",
    "start": "275520",
    "end": "278400"
  },
  {
    "text": "So that is right over here.",
    "start": "278400",
    "end": "281163"
  },
  {
    "text": "So in this flow,",
    "start": "282000",
    "end": "284160"
  },
  {
    "text": "and I'm gonna leave this\nout here for a minute,",
    "start": "284160",
    "end": "286290"
  },
  {
    "text": "in this flow, essentially\nwe're deploying two models.",
    "start": "286290",
    "end": "290430"
  },
  {
    "text": "So over here you're deploying\na Llama 7 billion parameter.",
    "start": "290430",
    "end": "294180"
  },
  {
    "text": "Over here you're deploying",
    "start": "294180",
    "end": "295500"
  },
  {
    "text": "a Falcon 7 billion parameter model.",
    "start": "295500",
    "end": "298500"
  },
  {
    "text": "And then over here you're fine tuning",
    "start": "298500",
    "end": "301320"
  },
  {
    "text": "that 7 billion parameter\nmodel and then deploying it.",
    "start": "301320",
    "end": "304080"
  },
  {
    "text": "So I have these three\nseparate model streams",
    "start": "304080",
    "end": "307409"
  },
  {
    "text": "that I'm working with.",
    "start": "307410",
    "end": "308850"
  },
  {
    "text": "Once we've deployed all three of these",
    "start": "308850",
    "end": "311520"
  },
  {
    "text": "and then evaluated them,\nessentially we have this final step",
    "start": "311520",
    "end": "315389"
  },
  {
    "text": "where you can compare the\nperformance of these models.",
    "start": "315390",
    "end": "317850"
  },
  {
    "text": "So one core step where you can, again,",
    "start": "317850",
    "end": "320610"
  },
  {
    "text": "look at the performance of each\nof these three custom models",
    "start": "320610",
    "end": "324270"
  },
  {
    "text": "and ensure that you're\npicking the right one",
    "start": "324270",
    "end": "327449"
  },
  {
    "text": "for your processes.",
    "start": "327450",
    "end": "328500"
  },
  {
    "text": "And then, of course, you\ncan clean up the assets.",
    "start": "328500",
    "end": "331500"
  },
  {
    "text": "And then again, all of this is available",
    "start": "331500",
    "end": "333900"
  },
  {
    "text": "in the SageMaker pipelines.",
    "start": "333900",
    "end": "336479"
  },
  {
    "text": "You can take a look at\nthe notebook with me.",
    "start": "336480",
    "end": "339600"
  },
  {
    "text": "This is just getting started\nagain with FM Evaluation",
    "start": "339600",
    "end": "343500"
  },
  {
    "text": "and then running the\nSageMaker pipelines processes",
    "start": "343500",
    "end": "347670"
  },
  {
    "text": "on top of it.",
    "start": "347670",
    "end": "349170"
  },
  {
    "text": "And so with that, I hope\nyou enjoyed this video",
    "start": "349170",
    "end": "351900"
  },
  {
    "text": "Getting Started with MLOps on SageMaker.",
    "start": "351900",
    "end": "354750"
  },
  {
    "text": "We have a whole series set up for you",
    "start": "354750",
    "end": "356640"
  },
  {
    "text": "to dive into the different components",
    "start": "356640",
    "end": "358740"
  },
  {
    "text": "of using SageMaker for generative AI.",
    "start": "358740",
    "end": "360930"
  },
  {
    "text": "So I will see you next time. Thanks.",
    "start": "360930",
    "end": "362883"
  }
]
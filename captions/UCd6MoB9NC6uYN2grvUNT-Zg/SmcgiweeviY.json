[
  {
    "start": "0",
    "end": "24000"
  },
  {
    "text": "well welcome everybody welcome to analyzing streaming data in real time",
    "start": "140",
    "end": "5310"
  },
  {
    "text": "with Amazon Kinesis analytics realize I could be the last session you have today",
    "start": "5310",
    "end": "11370"
  },
  {
    "text": "before you make your way over to the Welcome Reception so I appreciate you spending some time here this afternoon",
    "start": "11370",
    "end": "17580"
  },
  {
    "text": "with me to learn a little bit about what we've got going with Kinesis analytics",
    "start": "17580",
    "end": "23210"
  },
  {
    "text": "so before we kind of dive into the details let's just take a quick look at",
    "start": "23210",
    "end": "28560"
  },
  {
    "start": "24000",
    "end": "24000"
  },
  {
    "text": "what we'll discuss over the next 45 minutes or so we'll take a look at just",
    "start": "28560",
    "end": "33960"
  },
  {
    "text": "a streaming data overview just kind of get a good idea to kind of level set set some context for streaming data and you",
    "start": "33960",
    "end": "39930"
  },
  {
    "text": "know why Kinesis analytics is important in that space then we'll do an Amazon Kinesis platform",
    "start": "39930",
    "end": "46590"
  },
  {
    "text": "overview if you're not familiar with the Amazon Kinesis suite of products it's",
    "start": "46590",
    "end": "51629"
  },
  {
    "text": "more than just Kinesis analytics so we'll talk a little bit about the entire platform and then we'll move right along",
    "start": "51629",
    "end": "57449"
  },
  {
    "text": "and get into Kinesis analytics overview we'll dive a bit deeper into that we'll",
    "start": "57449",
    "end": "63570"
  },
  {
    "text": "talk a bit about Kinesis analytics patterns what we've been seeing from customers who are using it today in the",
    "start": "63570",
    "end": "70290"
  },
  {
    "text": "real world and production and then we're going to a walk through to kind of help you understand Kinesis analytics how you",
    "start": "70290",
    "end": "76799"
  },
  {
    "text": "might be able to build your own application using Kinesis analytics we're going to walk through a fictitious",
    "start": "76799",
    "end": "82590"
  },
  {
    "text": "scenario but it's a real-world scenario scenario and so that should give you some good insights into how you might be",
    "start": "82590",
    "end": "88080"
  },
  {
    "text": "able to leverage this in your own with your own data and then finally no",
    "start": "88080",
    "end": "93810"
  },
  {
    "text": "reinvent talk is complete without a discussion of best practices for any",
    "start": "93810",
    "end": "99630"
  },
  {
    "text": "given service so we'll talk a little bit about some Kinesis analytics best practices so quick",
    "start": "99630",
    "end": "106640"
  },
  {
    "text": "show hands maybe how many folks in here are already processing data in real time",
    "start": "106640",
    "end": "112350"
  },
  {
    "text": "doing some street real time streaming data analysis cool maybe about a quarter for the room so that's that's awesome",
    "start": "112350",
    "end": "119719"
  },
  {
    "text": "so you're probably familiar with a few of these things that we're about to discuss but I think it's important so",
    "start": "119719",
    "end": "125450"
  },
  {
    "start": "120000",
    "end": "120000"
  },
  {
    "text": "most data today is produced continuously",
    "start": "125450",
    "end": "130459"
  },
  {
    "text": "whether that be from a mobile app maybe it's a web blog and Apache Apache",
    "start": "130459",
    "end": "137520"
  },
  {
    "text": "access log perhaps application logs that are going to be unique to your application I have T sensors all of",
    "start": "137520",
    "end": "144420"
  },
  {
    "text": "these things are producing data at a lightning pace and that's because of the",
    "start": "144420",
    "end": "150630"
  },
  {
    "text": "prevalence of like real-time data sources they're creating the data extremely fast and it gives us and you",
    "start": "150630",
    "end": "158100"
  },
  {
    "text": "all insight into what your customers or your organization is doing right now so",
    "start": "158100",
    "end": "164970"
  },
  {
    "text": "it's really important but what is that data worth how can you",
    "start": "164970",
    "end": "172140"
  },
  {
    "start": "167000",
    "end": "167000"
  },
  {
    "text": "extract value from that data recent data is is extremely valuable but",
    "start": "172140",
    "end": "178920"
  },
  {
    "text": "only if you can act on it in time old plus recent data is more valuable if",
    "start": "178920",
    "end": "186060"
  },
  {
    "text": "you have the means to combine them so what we're looking at here this chart it's from a really good white paper",
    "start": "186060",
    "end": "192480"
  },
  {
    "text": "called perishable insights created by Forrester what's interesting about the white",
    "start": "192480",
    "end": "198299"
  },
  {
    "text": "papers they discuss exactly what I described as the value of data if you",
    "start": "198299",
    "end": "203459"
  },
  {
    "text": "can act on it immediately is immensely more valuable than if you wait",
    "start": "203459",
    "end": "209239"
  },
  {
    "text": "for a significant amount of time maybe days or weeks to process the data a couple of examples think of a business",
    "start": "209239",
    "end": "215010"
  },
  {
    "text": "report that maybe your business has created last year right it's not if you",
    "start": "215010",
    "end": "220590"
  },
  {
    "text": "pull it up today it might still be sort of interesting to look at but there's not a ton of value not as much value in",
    "start": "220590",
    "end": "226230"
  },
  {
    "text": "that report as in the report that might have been created yesterday so that's you know kind of a long-term view think",
    "start": "226230",
    "end": "233370"
  },
  {
    "text": "about machine data or error log data if you look at that error log data from a",
    "start": "233370",
    "end": "240600"
  },
  {
    "text": "month ago a year ago probably has some value but not as interesting as an error",
    "start": "240600",
    "end": "246900"
  },
  {
    "text": "log right now so it gives you some good insight into why real-time current data",
    "start": "246900",
    "end": "253380"
  },
  {
    "text": "is important but processing it as it arrives is",
    "start": "253380",
    "end": "259190"
  },
  {
    "text": "difficult right it requires a special skill set a lot of times you have to either hire developers with a new skill",
    "start": "259190",
    "end": "266220"
  },
  {
    "text": "set you have to train developers to do this then they have to go implement it",
    "start": "266220",
    "end": "271440"
  },
  {
    "text": "it might take weeks or months for them to implement the solution and build a robust infrastructure to do it so the",
    "start": "271440",
    "end": "278820"
  },
  {
    "text": "fact of the matter is a lot of people who start down this path they generally don't get all the way to real-time",
    "start": "278820",
    "end": "285930"
  },
  {
    "text": "streaming processing that typically kind of go with the status quo you're",
    "start": "285930",
    "end": "291240"
  },
  {
    "text": "like okay I'm good with the batch process I'll run nightly or hourly or you know weekly ETL jobs and I'll run my",
    "start": "291240",
    "end": "297570"
  },
  {
    "text": "process because it's just too difficult to do it in real time you need a different set of tools to do",
    "start": "297570",
    "end": "305510"
  },
  {
    "start": "301000",
    "end": "301000"
  },
  {
    "text": "collect and analyze real-time data with traditional analytics and",
    "start": "305510",
    "end": "311720"
  },
  {
    "text": "processing the data at rest data would come in you'd persist it in a database you'd write a query and then like I said",
    "start": "311720",
    "end": "318960"
  },
  {
    "text": "a moment ago you might be fine with getting that data tomorrow or next week but that doesn't give you the immediate",
    "start": "318960",
    "end": "324150"
  },
  {
    "text": "insights that you might want for your business and real-time analysts analysis system is different it",
    "start": "324150",
    "end": "332789"
  },
  {
    "text": "needs to be able to process that data as it comes through the system also the data is coming at an extremely fast",
    "start": "332789",
    "end": "340979"
  },
  {
    "text": "pace and a very variable rate a lot of times this data is going to kind of burst through the system depending on",
    "start": "340979",
    "end": "347520"
  },
  {
    "text": "what your systems are doing and then maybe you know shrink back down again overnight in that",
    "start": "347520",
    "end": "353250"
  },
  {
    "text": "kind of a scenario so a streaming analysis system needs to be able to process this data as it flows through",
    "start": "353250",
    "end": "360330"
  },
  {
    "text": "the system before it lands in a durable storage location some of the key requirements for building a stream",
    "start": "360330",
    "end": "367020"
  },
  {
    "text": "processing system is that it needs to be durable when a message get gets written to a streaming data system you want to",
    "start": "367020",
    "end": "374220"
  },
  {
    "text": "make sure that you know you're confident and that when the data was written it's written durably and you're not going to lose that data needs to be continuous",
    "start": "374220",
    "end": "380729"
  },
  {
    "text": "this is streaming data the system needs to be able to process the data as it goes through needs to be fast a lot of",
    "start": "380729",
    "end": "387539"
  },
  {
    "text": "times you may decide that you want to process that data sub-second if you're streaming data can't keep up if your",
    "start": "387539",
    "end": "393720"
  },
  {
    "text": "streaming data platform can't can't keep up with it then you're losing the real-time value of course it needs to be",
    "start": "393720",
    "end": "400780"
  },
  {
    "text": "so at least once processing only once processing these are semantics that are important in a real-time streaming",
    "start": "400780",
    "end": "406750"
  },
  {
    "text": "processing system you need to make sure that the data arrives in the destination and that it's accurate when it gets",
    "start": "406750",
    "end": "412780"
  },
  {
    "text": "there it needs to be reactive you need as a business you are going to react to",
    "start": "412780",
    "end": "419050"
  },
  {
    "text": "this data if you're processing real-time streaming data you're doing it for a reason you want to react quickly to something that's going on in your",
    "start": "419050",
    "end": "425260"
  },
  {
    "text": "environment or something that's happening in your business so the system needs to be able to give you the ability to react to that data quickly and it",
    "start": "425260",
    "end": "432610"
  },
  {
    "text": "needs to be react reliable it needs to be highly available and needs to do fast failover in the event that there's some",
    "start": "432610",
    "end": "439630"
  },
  {
    "text": "kind of an issue and you want to be sure that it's able to handle that and that your data is flowing through and that",
    "start": "439630",
    "end": "446140"
  },
  {
    "text": "it's available to you and to the downstream systems from your real-time",
    "start": "446140",
    "end": "451510"
  },
  {
    "text": "ingestion platform so let's take a look at Kinesis how you can build a",
    "start": "451510",
    "end": "457740"
  },
  {
    "text": "real-time streaming data platform using the suite of Amazon Kinesis products",
    "start": "457740",
    "end": "466229"
  },
  {
    "text": "so as I mentioned Amazon Kinesis comprise comprises of three different",
    "start": "466229",
    "end": "473350"
  },
  {
    "text": "products today we've got Amazon Kinesis streams Amazon Kinesis firehose and",
    "start": "473350",
    "end": "478930"
  },
  {
    "text": "Amazon Kinesis analytics we're going to touch briefly on Kinesis streams and",
    "start": "478930",
    "end": "485229"
  },
  {
    "text": "Kinesis firehose and then we'll get into Kinesis analytics in a bit more depth the reason we need to talk about Kinesis",
    "start": "485229",
    "end": "491890"
  },
  {
    "text": "streams and Kinesis firehose is because they are a requirement to use Kinesis analytics",
    "start": "491890",
    "end": "497940"
  },
  {
    "text": "so Kinesis streams gives you the ability to reliably ingest and durably store",
    "start": "497940",
    "end": "503229"
  },
  {
    "start": "498000",
    "end": "498000"
  },
  {
    "text": "streaming data at low cost and you can build custom real-time applications to",
    "start": "503229",
    "end": "508510"
  },
  {
    "text": "process that streaming data so if you take a look here at the diagram across the bottom we have our data producer in",
    "start": "508510",
    "end": "515620"
  },
  {
    "text": "this case it shows clickstream data that's being sent to a stream there's a",
    "start": "515620",
    "end": "521140"
  },
  {
    "text": "number of ways to ingest data using Kinesis streams all of our SDKs support Kinesis we have",
    "start": "521140",
    "end": "530230"
  },
  {
    "text": "a couple of libraries open source libraries that you can use as well that give you a lot more",
    "start": "530230",
    "end": "536390"
  },
  {
    "text": "efficiencies and how you can produce data and write it to a stream we have the K PL the Kinesis producer library we",
    "start": "536390",
    "end": "544730"
  },
  {
    "text": "have a Kinesis agent which is as it sounds is an agent that runs in your box and will tale log files and",
    "start": "544730",
    "end": "550660"
  },
  {
    "text": "automatically push those records to a stream so that's the production side",
    "start": "550660",
    "end": "556160"
  },
  {
    "text": "that's how one way you can produce data and then you want to consume the data from the stream we have a library again called the KCl",
    "start": "556160",
    "end": "564230"
  },
  {
    "text": "the Kinesis client library so if you want to write your own application run around ec2 pull data out of the stream",
    "start": "564230",
    "end": "570410"
  },
  {
    "text": "and do your own processing KCl gives you that option it also supports lamda so if you're familiar with AWS lamda it's very",
    "start": "570410",
    "end": "577400"
  },
  {
    "text": "easy to configure write your own function in lamda and Java Python or node and have it process the stream for",
    "start": "577400",
    "end": "585140"
  },
  {
    "text": "you so lambda will pull the stream pull the data out and then of course we're depending on your your business logic in",
    "start": "585140",
    "end": "591740"
  },
  {
    "text": "your lambda function will go downstream from there we also support other third-party",
    "start": "591740",
    "end": "598750"
  },
  {
    "text": "consumers such as spark streaming and storm you can create a spark streaming application and use Kinesis streams as",
    "start": "598750",
    "end": "605180"
  },
  {
    "text": "your your ingestion stream and then all the way down streams so the last you know on the far right of the diagram is",
    "start": "605180",
    "end": "611440"
  },
  {
    "text": "ultimately what you're doing with the data as it streams through the system so",
    "start": "611440",
    "end": "616490"
  },
  {
    "text": "that's a quick view of Kinesis streams one point I would make on this before",
    "start": "616490",
    "end": "622640"
  },
  {
    "text": "you go further is it also gives you the ability to scale so we in a Kinesis",
    "start": "622640",
    "end": "628790"
  },
  {
    "text": "stream there is the notion of shards so a shard gives you a certain throughput a",
    "start": "628790",
    "end": "634730"
  },
  {
    "text": "single shard gives you a thousand writes per second or one megabyte of total ingestion and so if your use case is",
    "start": "634730",
    "end": "642170"
  },
  {
    "text": "more than that it's very easy we have an API or of course we have the AWS console where you can go in and say I need 10",
    "start": "642170",
    "end": "648530"
  },
  {
    "text": "shards because I want to support 10,000 writes per second through my ingestion stream and the reason I'm talking about",
    "start": "648530",
    "end": "654560"
  },
  {
    "text": "shards now is when we get into Kinesis analytics there's a sub relationship there so it's important to know a little",
    "start": "654560",
    "end": "660860"
  },
  {
    "text": "bit about Kinesis streams and how it's comprised of shards before we go into Kinesis analytics",
    "start": "660860",
    "end": "667889"
  },
  {
    "text": "so next up we have Kinesis firehose Kinesis firehose was created it went",
    "start": "667889",
    "end": "674709"
  },
  {
    "text": "generally available last year at reinvent the",
    "start": "674709",
    "end": "679860"
  },
  {
    "text": "most common use case we saw when we announced Kinesis streams so just the",
    "start": "679860",
    "end": "685029"
  },
  {
    "text": "pure streaming product was purely loading streaming data into a persistent data store so data was getting rid of",
    "start": "685029",
    "end": "691660"
  },
  {
    "text": "written into streams and customers were writing their own applications maybe it was like a KCl app that's the library",
    "start": "691660",
    "end": "698889"
  },
  {
    "text": "that we've created to write data into s3 right I just wanted s3 to host the",
    "start": "698889",
    "end": "704319"
  },
  {
    "text": "static data that was flowing through their stream that was with Kinesis streams we noticed that a lot of",
    "start": "704319",
    "end": "709600"
  },
  {
    "text": "customers were doing it so we decided it'd be great since so many customers are doing this if we could just offer",
    "start": "709600",
    "end": "714940"
  },
  {
    "text": "this to the customer you don't have to write your own application if you could",
    "start": "714940",
    "end": "720339"
  },
  {
    "text": "just configure it Kinesis firehose have the data flow into it have the data land",
    "start": "720339",
    "end": "725769"
  },
  {
    "text": "in a durable storage location it makes your life much easier no custom code",
    "start": "725769",
    "end": "731230"
  },
  {
    "text": "they have to write and that's sort of the genesis for Kinesis firehose so Kinesis fire hose has Kinesis streams",
    "start": "731230",
    "end": "736689"
  },
  {
    "text": "under the covers but you don't see that as a as a customer of Kinesis firehose you configure Kinesis firehose you also",
    "start": "736689",
    "end": "744040"
  },
  {
    "text": "configure your destination so you configure where does it where do you want the data to reside once it is put",
    "start": "744040",
    "end": "750519"
  },
  {
    "text": "through the stream and excuse me we have three choices for you today is s3 redshift or Amazon Elastic search",
    "start": "750519",
    "end": "757540"
  },
  {
    "text": "service so those are the three destinations that you can choose to persist your data as it goes through",
    "start": "757540",
    "end": "762730"
  },
  {
    "text": "Kinesis pyros and there's no administration that you need to do here it's basically through the API or most",
    "start": "762730",
    "end": "768639"
  },
  {
    "text": "customers in this case because it's usually a one-time setup go into the console configure the firehose and",
    "start": "768639",
    "end": "774160"
  },
  {
    "text": "you're done so that's firehose very simple very common use case for streaming data and durable storage of",
    "start": "774160",
    "end": "782019"
  },
  {
    "text": "that streaming data so that brings us to Kinesis analytics so so far we've got the streaming data",
    "start": "782019",
    "end": "789220"
  },
  {
    "text": "either your own custom application to process it or you're just writing it durably into a storage location like s3",
    "start": "789220",
    "end": "795339"
  },
  {
    "text": "or elasticsearch or or redshift but in a real-time streaming data",
    "start": "795339",
    "end": "803240"
  },
  {
    "text": "scenario you want to be able to process that data as it flows through the system and so that's what Amazon Kinesis",
    "start": "803240",
    "end": "809300"
  },
  {
    "text": "analytics brings to the table allows you to interact with that streaming data using SQL and it's built upon ANSI 2008",
    "start": "809300",
    "end": "820400"
  },
  {
    "text": "standards supports almost the entire standard and we've extended it a little bit to support streaming data scenarios",
    "start": "820400",
    "end": "826390"
  },
  {
    "text": "and you can build fully managed elastic stream processing that produce data for",
    "start": "826390",
    "end": "831650"
  },
  {
    "text": "real-time visualizations we'll get into the details of like a few common use cases that we see but this is what we're here to really talk about today",
    "start": "831650",
    "end": "838360"
  },
  {
    "text": "so let's get a bit deeper into Kinesis analytics just a few sort of bullet",
    "start": "838360",
    "end": "843860"
  },
  {
    "text": "points easy to use it automatically scales based on the based on the",
    "start": "843860",
    "end": "851840"
  },
  {
    "text": "throughput and the amount of data and the amount of processing that the system needs to do to process your data it's in",
    "start": "851840",
    "end": "857450"
  },
  {
    "text": "real time you pay only for what you what you use and I'm going to talk a little bit more about the cost model later and",
    "start": "857450",
    "end": "863450"
  },
  {
    "text": "as I mentioned standard sequel for analytics so the reason we chose standard sequel is a very common very",
    "start": "863450",
    "end": "870200"
  },
  {
    "text": "popular language obviously in many parts of the",
    "start": "870200",
    "end": "875560"
  },
  {
    "text": "data analytics world so it just is natural that we could make that an offering and many people would be very",
    "start": "875560",
    "end": "882770"
  },
  {
    "text": "familiar with it I have to go learn a new technology a lot of people in the industry are already familiar with",
    "start": "882770",
    "end": "888620"
  },
  {
    "text": "sequel so it was kind of a natural a natural choice to analyze data using a",
    "start": "888620",
    "end": "894500"
  },
  {
    "text": "very common language SQL so it's really a three step process when you create",
    "start": "894500",
    "end": "900730"
  },
  {
    "start": "897000",
    "end": "897000"
  },
  {
    "text": "Kinesis analytics application you connect to a streaming source you write the sequel code to process the data and",
    "start": "900730",
    "end": "907430"
  },
  {
    "text": "then you deliver the results somewhere which I'll describe in a moment so connecting to a streaming data source",
    "start": "907430",
    "end": "913850"
  },
  {
    "start": "911000",
    "end": "911000"
  },
  {
    "text": "and that's why it's important to understand in this case why Kinesis dreams and Kinesis firehose kind of have",
    "start": "913850",
    "end": "921020"
  },
  {
    "text": "a good understanding of those before we start because those are your two sources that you can choose for Kinesis analytics so if data is streaming in if",
    "start": "921020",
    "end": "928280"
  },
  {
    "text": "you already have a kinesio stream or Kinesis firehose you can today go and create a Kinesis analytics app and start processing and",
    "start": "928280",
    "end": "934470"
  },
  {
    "text": "analyzing that data in real time if you don't you can create a konista stream or fire hose and Kinesis analytics can",
    "start": "934470",
    "end": "939720"
  },
  {
    "text": "process that but those are your two input choices the input types that Kinesis analytics support are JSON CSV",
    "start": "939720",
    "end": "947309"
  },
  {
    "text": "or unstructured text and we can talk a little bit about that as well but",
    "start": "947309",
    "end": "952639"
  },
  {
    "text": "most of the use cases that we see today customers who are putting data into",
    "start": "952639",
    "end": "958439"
  },
  {
    "text": "streams or firehose they're putting in typically JSON or CSV or some delimited",
    "start": "958439",
    "end": "964429"
  },
  {
    "text": "delimited structure into their stream and that",
    "start": "964429",
    "end": "970049"
  },
  {
    "text": "makes it pretty simple to create a schema out of it so because we're writing sequel in Kinesis analytics to",
    "start": "970049",
    "end": "976709"
  },
  {
    "text": "analyze your data we need to have a schema right select star from table where you need to have a schema to make",
    "start": "976709",
    "end": "982290"
  },
  {
    "text": "that work and so the when you connect to a streaming source with Kinesis analytics it will create a schema based",
    "start": "982290",
    "end": "989609"
  },
  {
    "text": "on your input data you have some options around that and we'll get into the details of that but it's important to realize that you know a schema is",
    "start": "989609",
    "end": "995970"
  },
  {
    "text": "created from your input data and you can also leverage reference data sources static data that you might have an s3",
    "start": "995970",
    "end": "1002449"
  },
  {
    "text": "you can use that in your application as well to enrich the streaming data in real time",
    "start": "1002449",
    "end": "1008049"
  },
  {
    "text": "next step is to write your sequel code one or more statements doesn't have to",
    "start": "1008049",
    "end": "1013699"
  },
  {
    "text": "be a simple select you can have nested select statements you can have joins inner joins outer joins just like I said",
    "start": "1013699",
    "end": "1020689"
  },
  {
    "text": "that the 2008 ANSI sequel standard is supported and when I talk through the",
    "start": "1020689",
    "end": "1025760"
  },
  {
    "text": "example I think you'll see kind of a good example of multiple streams of data",
    "start": "1025760",
    "end": "1032480"
  },
  {
    "text": "and using several sequel statements to get the output that you want for your application and support for at least",
    "start": "1032480",
    "end": "1040339"
  },
  {
    "text": "once processing semantics so when you write your sequel to process",
    "start": "1040339",
    "end": "1045649"
  },
  {
    "text": "your application and Kinesis analytics is going to attempt to deliver that to your destination if for",
    "start": "1045649",
    "end": "1052130"
  },
  {
    "text": "some reason your destination is unavailable Kinesis analytics will continue to try and process that data",
    "start": "1052130",
    "end": "1057470"
  },
  {
    "text": "and get it into your destination so that it's available to you",
    "start": "1057470",
    "end": "1063370"
  },
  {
    "text": "cool and that's where we get into the continuously delivering the sequel results so you send your process data to",
    "start": "1063370",
    "end": "1069970"
  },
  {
    "start": "1064000",
    "end": "1064000"
  },
  {
    "text": "one of two sources but ultimately because firehose gives you the three",
    "start": "1069970",
    "end": "1075430"
  },
  {
    "text": "destinations of redshift elasticsearch service and s3 you get four destinations",
    "start": "1075430",
    "end": "1081940"
  },
  {
    "text": "that you can send your output of Kinesis analytics into so you can set it to s3",
    "start": "1081940",
    "end": "1087190"
  },
  {
    "text": "redshift elasticsearch or into another stream so you can set it into another Kinesis",
    "start": "1087190",
    "end": "1093550"
  },
  {
    "text": "stream so you can then do further analysis downstream if you'd like to or if you have for example a lambda",
    "start": "1093550",
    "end": "1100090"
  },
  {
    "text": "function and you want to take the output of your analytic analytics application",
    "start": "1100090",
    "end": "1105220"
  },
  {
    "text": "and you want to maybe send like a an alert to an operator you can use a",
    "start": "1105220",
    "end": "1110890"
  },
  {
    "text": "stream with a lambda function the lambda function can then just put a message into SNS simple notification service if",
    "start": "1110890",
    "end": "1117910"
  },
  {
    "text": "you're familiar that and then that might be able to send an email or text so that's a very popular use case for using",
    "start": "1117910",
    "end": "1123610"
  },
  {
    "text": "streams as an output source you can achieve end end latency as low as a second I will point out here that you",
    "start": "1123610",
    "end": "1130420"
  },
  {
    "text": "know the end to end processing speed depends on your query not so much the complexity of your query but the",
    "start": "1130420",
    "end": "1136179"
  },
  {
    "text": "aggregation that you're doing in most use cases in Kinesis analytics you're doing some kind of an aggregation over",
    "start": "1136179",
    "end": "1141250"
  },
  {
    "text": "time you're going to say tell me the number of records that meet these criteria in one minute or one hour so if",
    "start": "1141250",
    "end": "1149020"
  },
  {
    "text": "you do that and depending on a number of other factors like the windowing which we're going to get into you'll have one",
    "start": "1149020",
    "end": "1154240"
  },
  {
    "text": "output per 10 seconds let's say so if you want to say count the number of times something has happened in a 10",
    "start": "1154240",
    "end": "1161170"
  },
  {
    "text": "second window every 10 seconds there will be an output from Kinesis analytics",
    "start": "1161170",
    "end": "1166800"
  },
  {
    "text": "and then nice thing about this is it separates the processing and data delivery so all the processing being",
    "start": "1166800",
    "end": "1173050"
  },
  {
    "text": "done by Kinesis analytics is separate from the destination of Canisius fire hose or",
    "start": "1173050",
    "end": "1179710"
  },
  {
    "text": "Kinesis streams and the at least once processing ensures that the data ultimately arrives at your destination",
    "start": "1179710",
    "end": "1186300"
  },
  {
    "text": "so what are some common use cases for Canisius analytics as I mentioned Kinesis analytics went generally",
    "start": "1186300",
    "end": "1193510"
  },
  {
    "text": "available we announced it last year we invent became available for all customers in August so it's been",
    "start": "1193510",
    "end": "1200409"
  },
  {
    "text": "in production for about three months now and we're getting a good feel for what customers are using it for one of the",
    "start": "1200409",
    "end": "1206139"
  },
  {
    "start": "1205000",
    "end": "1205000"
  },
  {
    "text": "most popular that we're seeing and this is the demo that I'm going to walk through here momentarily is just computing key performance indicators",
    "start": "1206139",
    "end": "1213249"
  },
  {
    "text": "overtime periods so you can imagine let's say it's an e-commerce company and you want to track what is the most",
    "start": "1213249",
    "end": "1220720"
  },
  {
    "text": "popular product in the last 10 minutes if it's a very popular website that",
    "start": "1220720",
    "end": "1227499"
  },
  {
    "text": "would be a good aggregation that you could run here and you could output it downstream for further analysis for visualization",
    "start": "1227499",
    "end": "1233070"
  },
  {
    "text": "feeding real-time dashboards so similarly if I have some business metrics that I want to track and I want",
    "start": "1233070",
    "end": "1239499"
  },
  {
    "text": "them to be available to my business or my operations staff immediately and I want to make it",
    "start": "1239499",
    "end": "1246029"
  },
  {
    "text": "visually available to them through tools like Cabana or quick site that's a very common use case that we",
    "start": "1246029",
    "end": "1253330"
  },
  {
    "text": "see for Canisius analytics feeding aggregate data into real-time dashboards and then thirdly we see a lot of",
    "start": "1253330",
    "end": "1260289"
  },
  {
    "start": "1258000",
    "end": "1258000"
  },
  {
    "text": "customers using it to create real-time alarms and notifications so they're building",
    "start": "1260289",
    "end": "1265619"
  },
  {
    "text": "sequences of events so how many times in a certain period has something happened and if that's important so a good",
    "start": "1265619",
    "end": "1272859"
  },
  {
    "text": "example might be clickstream I'm sorry Apache access log data so if you have a large fleet of web servers maybe you",
    "start": "1272859",
    "end": "1279399"
  },
  {
    "text": "have 20 web servers and all of them are pushing their Apache access log data",
    "start": "1279399",
    "end": "1285039"
  },
  {
    "text": "through a stream and you use Kinesis analytics to do some analysis on that it's very simple to say when I get more",
    "start": "1285039",
    "end": "1292179"
  },
  {
    "text": "than 10 500 HTTP response codes in a brief period of",
    "start": "1292179",
    "end": "1297700"
  },
  {
    "text": "time I should probably do something about that and so we have a lot of customers who are now using Kinesis",
    "start": "1297700",
    "end": "1303580"
  },
  {
    "text": "analytics to do as an example of patchy access log analysis and alerting their operations team when they see anomalies",
    "start": "1303580",
    "end": "1310059"
  },
  {
    "text": "in their streaming data so let's walk through an example we're",
    "start": "1310059",
    "end": "1315609"
  },
  {
    "text": "going to take a look at some Twitter data a very common use case I think if you guys have been through a few",
    "start": "1315609",
    "end": "1320799"
  },
  {
    "text": "different sessions you're probably seen you have probably seen that the Twitter is a nice use case for kind of",
    "start": "1320799",
    "end": "1327039"
  },
  {
    "text": "practicing streaming data it's a very simple use case 22.2 there's lots of data coming through",
    "start": "1327039",
    "end": "1333160"
  },
  {
    "text": "Twitter and then NHL so National Hockey League I am from Canada so I",
    "start": "1333160",
    "end": "1339210"
  },
  {
    "text": "enjoy hockey so I thought it would be kind of a neat use case to take a look at some Twitter data related to National",
    "start": "1339210",
    "end": "1347770"
  },
  {
    "text": "Hockey League teams here are the requirements for the scenario",
    "start": "1347770",
    "end": "1353070"
  },
  {
    "start": "1351000",
    "end": "1351000"
  },
  {
    "text": "first thing I want to do is filter for NHL related tweets twitter is very noisy",
    "start": "1353070",
    "end": "1358120"
  },
  {
    "text": "if you guys have a Twitter account you know this already we want to look at the total number of",
    "start": "1358120",
    "end": "1364300"
  },
  {
    "text": "tweets per hour that contain hashtags for NHL teams and then the top 5 NHL",
    "start": "1364300",
    "end": "1369640"
  },
  {
    "text": "related hashtags per hour so that's sort of the data we want to capture but the output that we want to send downstream filtered tweets we want to get rid of",
    "start": "1369640",
    "end": "1376870"
  },
  {
    "text": "all the ones that aren't relevant to us we want to do some aggregations so we wanna do an hourly aggregate count and",
    "start": "1376870",
    "end": "1382600"
  },
  {
    "text": "save it to Amazon Elastic search and we want to take the full team name so the",
    "start": "1382600",
    "end": "1387880"
  },
  {
    "text": "hashtag is usually very short right I'll have an example here in a moment but it's usually four five letters that is the nickname of a team but it typically",
    "start": "1387880",
    "end": "1394900"
  },
  {
    "text": "doesn't have like the the city write for it might say Rangers and it means New",
    "start": "1394900",
    "end": "1400330"
  },
  {
    "text": "York Rangers so we want to do is how the output actually contain the full team name and",
    "start": "1400330",
    "end": "1406840"
  },
  {
    "text": "then how many times that team was referenced in an hour overtime",
    "start": "1406840",
    "end": "1411960"
  },
  {
    "text": "so why is Kinesis analytics good for this solution a few things there's a few",
    "start": "1411960",
    "end": "1417910"
  },
  {
    "start": "1412000",
    "end": "1412000"
  },
  {
    "text": "challenges with this first of all like I said Twitter streams are noisy a tweet",
    "start": "1417910",
    "end": "1424330"
  },
  {
    "text": "structure is quite complex if you haven't looked at a tweet its JSON but it's very complicated has hundreds of",
    "start": "1424330",
    "end": "1430510"
  },
  {
    "text": "attributes and a lot of different nested layers to that and also NHL related",
    "start": "1430510",
    "end": "1436780"
  },
  {
    "text": "tweet volume is very cyclical as you can imagine certainly on an annual basis it is but even weekly and hourly it's",
    "start": "1436780",
    "end": "1443350"
  },
  {
    "text": "cyclical so over a week weekends are more popular and then even the given period of a day certainly in the",
    "start": "1443350",
    "end": "1449290"
  },
  {
    "text": "evenings when actually games are happening there's a lot more tweets than there are at you know 6 a.m. so it's a",
    "start": "1449290",
    "end": "1454570"
  },
  {
    "text": "very cyclical use case so with Kinesis analytics we can easily the reason",
    "start": "1454570",
    "end": "1459730"
  },
  {
    "text": "that's good for this use case makes it very straightforward with a sequel statement to filter out sweets we don't care about",
    "start": "1459730",
    "end": "1465040"
  },
  {
    "text": "it makes it very simple to normalize the tweet structure so that gives us the",
    "start": "1465040",
    "end": "1470060"
  },
  {
    "text": "ability to do sequel on that data and then it automatically scales so because",
    "start": "1470060",
    "end": "1475430"
  },
  {
    "text": "of the cyclical nature of this kind of data we don't want to pay we don't want to over provision for",
    "start": "1475430",
    "end": "1482560"
  },
  {
    "text": "something if it's not going to be used in July or if it's not going to be used at 6:00 a.m. so it's a really good use",
    "start": "1482560",
    "end": "1490280"
  },
  {
    "text": "case because can use its analytics will automatically scale based on the data",
    "start": "1490280",
    "end": "1495760"
  },
  {
    "text": "so this is what we're going to build this is our end-to-end architecture we go from left to right we've got our our",
    "start": "1495760",
    "end": "1501530"
  },
  {
    "start": "1496000",
    "end": "1496000"
  },
  {
    "text": "Twitter stream there's an ec2 instance here in the mix I'll explain that in a moment",
    "start": "1501530",
    "end": "1507250"
  },
  {
    "text": "actually I'll explain it now if you're if you are um if you're not familiar",
    "start": "1507250",
    "end": "1512990"
  },
  {
    "text": "with how you integrate with Twitter basically like Twitter is not going to push the data directly to a Kinesis",
    "start": "1512990",
    "end": "1518780"
  },
  {
    "text": "stream you have to have a your own Twitter application in the middle so basically something that will take the",
    "start": "1518780",
    "end": "1524180"
  },
  {
    "text": "data from Twitter and then do something with it in our case the doing something with it is putting it into a canoe so",
    "start": "1524180",
    "end": "1529550"
  },
  {
    "text": "stream that's that's the model with with Twitter is you create a Kinesis or so",
    "start": "1529550",
    "end": "1535100"
  },
  {
    "text": "you Kuwait it you create a Twitter application that receives the data the streaming data from from Twitter and",
    "start": "1535100",
    "end": "1541250"
  },
  {
    "text": "then you can do whatever you want with it at that point so that's the left hand side we have the stream as the ingestion",
    "start": "1541250",
    "end": "1547970"
  },
  {
    "text": "konista stream then we have our Kinesis analytics application and some reference data which I'll explain in a moment and",
    "start": "1547970",
    "end": "1553610"
  },
  {
    "text": "then we're going to output that to firehose and then ultimately s3 an elastic search on the far right of our diagram",
    "start": "1553610",
    "end": "1560080"
  },
  {
    "start": "1560000",
    "end": "1560000"
  },
  {
    "text": "so if we kind of take that we're going to we're going to walk through this from",
    "start": "1560080",
    "end": "1565340"
  },
  {
    "text": "left to right as I mentioned the source JSON data from Twitter is quite noisy",
    "start": "1565340",
    "end": "1570380"
  },
  {
    "text": "hundreds of attributes it's about 5k per tweet and most attributes we don't care about for this",
    "start": "1570380",
    "end": "1576650"
  },
  {
    "text": "use case so what the ec2 instance is doing here is when you create a Twitter",
    "start": "1576650",
    "end": "1582020"
  },
  {
    "text": "application you can tell Twitter I want you to just filter out some of this stuff for me already I don't have to get",
    "start": "1582020",
    "end": "1587990"
  },
  {
    "text": "a full stream of all tweets I can say just give me stuff relevant to NHL NFL",
    "start": "1587990",
    "end": "1595220"
  },
  {
    "text": "NBA MLB I can even give it like the hashtags for teams that I want so it can give me an",
    "start": "1595220",
    "end": "1600830"
  },
  {
    "text": "already filtered list and so in this scenario I'm getting some still getting some dirty data I've asked for all kinds of sports data but obviously in my use",
    "start": "1600830",
    "end": "1608899"
  },
  {
    "text": "case given given the criteria for this I only care about the NHL teams so I'm still getting some noise and they ec2",
    "start": "1608899",
    "end": "1616190"
  },
  {
    "text": "instance here in the middle it's going to do a bit of filtering like that's what it's it's going to ask for only some limited sets of data and it's going",
    "start": "1616190",
    "end": "1623600"
  },
  {
    "text": "to also get rid of some of the data that I know I don't care about in my application so it's doing a bit of",
    "start": "1623600",
    "end": "1629149"
  },
  {
    "text": "filtering up front and then the Kinesis streams data so what ultimately lands in",
    "start": "1629149",
    "end": "1634340"
  },
  {
    "text": "our Kinesis stream on the on the front end of our analytics system is going to",
    "start": "1634340",
    "end": "1640309"
  },
  {
    "text": "be a smaller record because i'm getting rid of the noise medival it's only going to contain some relevant attributes for",
    "start": "1640309",
    "end": "1645769"
  },
  {
    "text": "our use case so this is an example if we look at the JSON on the left this is a this is a",
    "start": "1645769",
    "end": "1652039"
  },
  {
    "start": "1646000",
    "end": "1646000"
  },
  {
    "text": "tweet you can see it's pretty pretty basic I've taken a lot of the noise of",
    "start": "1652039",
    "end": "1658879"
  },
  {
    "text": "data out of it but it gives me the data that I want has the tags cannes NHL has",
    "start": "1658879",
    "end": "1664759"
  },
  {
    "text": "the actual text that the user tweeted and it has some other couple of other things like the created date created",
    "start": "1664759",
    "end": "1670940"
  },
  {
    "text": "date and a unique ID that twitter creates when they when they give tweet and as I mentioned earlier",
    "start": "1670940",
    "end": "1677259"
  },
  {
    "text": "Kinesis analytics will attempt automatically to take the input data and",
    "start": "1677259",
    "end": "1683090"
  },
  {
    "text": "map it to a schema so on the right side of the screen you see what looks like a table in a relational database right I",
    "start": "1683090",
    "end": "1688639"
  },
  {
    "text": "have a column have an ID a text I created at and a tag column and Kinesis",
    "start": "1688639",
    "end": "1694190"
  },
  {
    "text": "analytics automatically takes the tag array from the JSON and creates it and",
    "start": "1694190",
    "end": "1699289"
  },
  {
    "text": "it basically explodes it so we now have two rows in my table one with each tag and the rest of the data is the same so",
    "start": "1699289",
    "end": "1705529"
  },
  {
    "text": "this schema was automatically created by Kinesis analytics the first time it",
    "start": "1705529",
    "end": "1710899"
  },
  {
    "text": "inspected the ingestion stream and noticed the schema of the source and then it created this the schema so that",
    "start": "1710899",
    "end": "1717619"
  },
  {
    "text": "I can now use it in my application when we talk about best practices in a few moments there are some things to",
    "start": "1717619",
    "end": "1724249"
  },
  {
    "text": "note about the automatic schema creation the short answer is don't blindly trust",
    "start": "1724249",
    "end": "1729619"
  },
  {
    "text": "what Kinesis analytics creates I'll get into that into why that is but it does",
    "start": "1729619",
    "end": "1734730"
  },
  {
    "text": "make a really good first pass but you need to make sure that you've inspected it and you made sure that you change it",
    "start": "1734730",
    "end": "1741540"
  },
  {
    "text": "to be relevant for your data a lot of times if your data comes in and",
    "start": "1741540",
    "end": "1746840"
  },
  {
    "text": "Kinesis analytics looks at a sample of the data to create the schema if for",
    "start": "1746840",
    "end": "1752850"
  },
  {
    "text": "some reason one of the attributes didn't exist then it won't put that in your schema but if you want that attribute to",
    "start": "1752850",
    "end": "1759360"
  },
  {
    "text": "be converted into a column in your schema then you need to go in and manually change the schema so that's the best practice I got ahead but anyway now",
    "start": "1759360",
    "end": "1765660"
  },
  {
    "text": "you know all right so before we get into the specifics of the streaming data you know",
    "start": "1765660",
    "end": "1771150"
  },
  {
    "start": "1767000",
    "end": "1767000"
  },
  {
    "text": "how we're going to implement this there are a few constructs and as I mentioned earlier we support ANSI 2008 sequel but",
    "start": "1771150",
    "end": "1778290"
  },
  {
    "text": "we had to extend it to support streaming data so there's two constructs that are",
    "start": "1778290",
    "end": "1783480"
  },
  {
    "text": "important one is called a stream and one is called the pump with a stream it's important and I don't",
    "start": "1783480",
    "end": "1790050"
  },
  {
    "text": "want to confuse you because it's important to realize this is not the same as a Kinesis stream it's unfortunate and fortunately they have",
    "start": "1790050",
    "end": "1796470"
  },
  {
    "text": "the same word but when I talk about Kinesis analytics I'm going to talk a lot about in application streams this is",
    "start": "1796470",
    "end": "1803480"
  },
  {
    "text": "only contextually relevant inside of the Kinesis analytics app it's",
    "start": "1803480",
    "end": "1810390"
  },
  {
    "text": "not at all related to the Kinesis stream from which your data is being sourced so just keep that in mind a stream it's",
    "start": "1810390",
    "end": "1817800"
  },
  {
    "text": "analogous to a table so if you're familiar was in a relational databases of course you have tables you're going",
    "start": "1817800",
    "end": "1823920"
  },
  {
    "text": "to write your queries against those tables a stream is very similar so if you look at this first statement here create or replace stream NHL tweet",
    "start": "1823920",
    "end": "1831360"
  },
  {
    "text": "stream you see that it's it looks like I'm creating a table alright if I was to say create table I would give it a schema this is very similar I'm creating",
    "start": "1831360",
    "end": "1838050"
  },
  {
    "text": "an in application stream in my Kinesis analytics app and this is what the data structure is going to look like in that",
    "start": "1838050",
    "end": "1843600"
  },
  {
    "text": "stream but because it's a stream it's not static data right if you have a table in",
    "start": "1843600",
    "end": "1849930"
  },
  {
    "text": "a relational database it's generally static of course you can do inserts and updates but it's generally static",
    "start": "1849930",
    "end": "1855380"
  },
  {
    "text": "the difference being with Kinesis analytics the stream is always changing I've got data flowing through my system",
    "start": "1855380",
    "end": "1862050"
  },
  {
    "text": "and I need to figure out how do I populate that table or that stream with data that's always changing and that's",
    "start": "1862050",
    "end": "1869310"
  },
  {
    "text": "what a pump does it's essentially running a continuous insert query into your stream so if you look at the bottom",
    "start": "1869310",
    "end": "1876600"
  },
  {
    "text": "create a replace pump and then it has insert into so your insert into statement here would be essentially",
    "start": "1876600",
    "end": "1883380"
  },
  {
    "text": "running continuously to ensure that your stream always has a flow of data going",
    "start": "1883380",
    "end": "1889770"
  },
  {
    "text": "through it so those two constructs are important as we kind of get into the rest of the requirements and how we",
    "start": "1889770",
    "end": "1895350"
  },
  {
    "text": "solve that problem so how do we model our data right",
    "start": "1895350",
    "end": "1900950"
  },
  {
    "start": "1896000",
    "end": "1896000"
  },
  {
    "text": "we have these boxes as I mentioned streams are very similar to tables so",
    "start": "1900950",
    "end": "1908340"
  },
  {
    "text": "you can think of these like tables in a relational database and you can join on them you can select you can you can even",
    "start": "1908340",
    "end": "1916110"
  },
  {
    "text": "do inserts via the pump but if you were to model this kind of solution using a relational database database it might",
    "start": "1916110",
    "end": "1921960"
  },
  {
    "text": "look something like this if these were your tables the difference being these little green arrows these are the pumps",
    "start": "1921960",
    "end": "1927210"
  },
  {
    "text": "so I have a sequel statement that's continuously being executed selecting",
    "start": "1927210",
    "end": "1933420"
  },
  {
    "text": "and inserting data into my NHL tweet stream stream so the source stream on",
    "start": "1933420",
    "end": "1938760"
  },
  {
    "text": "the Left this is what gets created based on the data coming in from Twitter it's my raw data and then I have subsequent",
    "start": "1938760",
    "end": "1945930"
  },
  {
    "text": "streams downstream from that that I can then use sequel to query and get my aggregator metrics so let's take a look",
    "start": "1945930",
    "end": "1953670"
  },
  {
    "text": "at the top one so how do we filter for unwanted tweets right that was one of the requirements I",
    "start": "1953670",
    "end": "1958890"
  },
  {
    "text": "want to get rid of the stuff that I don't care about so I'm going to create a pump and I'm going to insert into the",
    "start": "1958890",
    "end": "1965070"
  },
  {
    "text": "NHL tweet stream some data that data is very simple right I'm going to select data from my source where I don't want",
    "start": "1965070",
    "end": "1974910"
  },
  {
    "text": "NFL MLB and NBA so I remember correctly I'm still getting some noise out of Twitter getting all those hockey team",
    "start": "1974910",
    "end": "1980760"
  },
  {
    "text": "tweets but I'm also getting some stuff I don't care about because I'm in my filter to Twitter I said also give me",
    "start": "1980760",
    "end": "1986250"
  },
  {
    "text": "stuff that has NFL and it also give me stuff that has MLB but for this particular use case I don't want that",
    "start": "1986250",
    "end": "1992070"
  },
  {
    "text": "data so it's very easy now the stream called NHL tweet stream does not contain",
    "start": "1992070",
    "end": "1998830"
  },
  {
    "text": "it just drops it it's gone in this use case you can of course have another queries if you wanted that data and put",
    "start": "1998830",
    "end": "2004950"
  },
  {
    "text": "it somewhere else you could have another sequel statement that would do that for you but in our use case we don't want",
    "start": "2004950",
    "end": "2010049"
  },
  {
    "text": "that data so it's gone so my stream just contains now relevant data so simple as that pretty simple I've now got basic",
    "start": "2010049",
    "end": "2016710"
  },
  {
    "text": "sequel doing a where clause getting rid of the data I don't want so now my NHL",
    "start": "2016710",
    "end": "2021750"
  },
  {
    "text": "tweet stream which is like now my new source for the rest of the application contains only relevant tweets",
    "start": "2021750",
    "end": "2027980"
  },
  {
    "start": "2026000",
    "end": "2026000"
  },
  {
    "text": "but as I mentioned the the data that we're looking at only has the hashtag I",
    "start": "2027980",
    "end": "2033570"
  },
  {
    "text": "want the team name so if you look at the little table here on the bottom you can see it's a map right I've got I've got",
    "start": "2033570",
    "end": "2041450"
  },
  {
    "text": "the hashtag on the left and then the team name on the right comma separated so NY Rangers means New York Rangers and",
    "start": "2041450",
    "end": "2048960"
  },
  {
    "text": "why are also means New York Rangers all the way down to Oilers I've been to Nola's and sharks San Jose Sharks so",
    "start": "2048960",
    "end": "2054358"
  },
  {
    "text": "pretty basic I created a file in s3 that contains all the teams in the NHL and",
    "start": "2054359",
    "end": "2060240"
  },
  {
    "text": "contains the mapping of all the official hashtags of the team support and that sword an s3 so I created CSV a sort of",
    "start": "2060240",
    "end": "2067108"
  },
  {
    "text": "nest 3 and I configured Kinesis analytics to use that as a reference data source and then to get the team",
    "start": "2067109",
    "end": "2075388"
  },
  {
    "text": "name it's as simple as just doing an inner join between my streaming data that contains the hash tag and the",
    "start": "2075389",
    "end": "2082679"
  },
  {
    "start": "2076000",
    "end": "2076000"
  },
  {
    "text": "reference data which contains of course the hash tag and also the full team name so on the left here you'll see team name",
    "start": "2082679",
    "end": "2089339"
  },
  {
    "text": "that's a table that gets created in Kinesis analytics once you tell it where",
    "start": "2089339",
    "end": "2095760"
  },
  {
    "text": "the location of your static data is so team name as a table contains two columns hash tagging team and then the",
    "start": "2095760",
    "end": "2101760"
  },
  {
    "text": "NHL tweet stream is the data the filter data that's gotten only the NHL related",
    "start": "2101760",
    "end": "2108750"
  },
  {
    "text": "tweets and you can see my sequel statement here this is basically we're going to see where this select",
    "start": "2108750",
    "end": "2114420"
  },
  {
    "text": "statement statement goes like I said it's a to get continuous stream data you need a pump we also have some other functions",
    "start": "2114420",
    "end": "2121020"
  },
  {
    "text": "I'm going to get to that in a moment but the purpose of this call-out here is you can see how simple it is to do an inner",
    "start": "2121020",
    "end": "2127020"
  },
  {
    "text": "join and my output now of this query is just the team names right I've got now",
    "start": "2127020",
    "end": "2133380"
  },
  {
    "text": "New York Rangers Carolina Hurricanes oiler sharks so all the all that query",
    "start": "2133380",
    "end": "2138450"
  },
  {
    "text": "did is do an inner join between my static data and my streaming data and now I can use that data the data on the",
    "start": "2138450",
    "end": "2143490"
  },
  {
    "text": "right the full team name elsewhere in my application now we want to do aggregations how do I",
    "start": "2143490",
    "end": "2150960"
  },
  {
    "start": "2147000",
    "end": "2147000"
  },
  {
    "text": "aggregate streaming data it's very common to do analytics to know I want to",
    "start": "2150960",
    "end": "2156420"
  },
  {
    "text": "do counts averages maximum extremely common analytics use cases but I can't simply",
    "start": "2156420",
    "end": "2163500"
  },
  {
    "text": "aggregate over an entire table like you can in a relational or a static data set streaming data I remember I could have",
    "start": "2163500",
    "end": "2169890"
  },
  {
    "text": "this application running for days or for weeks and so if I said select star from",
    "start": "2169890",
    "end": "2176460"
  },
  {
    "text": "my stream where you know some value equals five in fact the it won't let you",
    "start": "2176460",
    "end": "2183150"
  },
  {
    "text": "Kinesis analytics will say you can't do that because the stream is is potentially infinite right we need some",
    "start": "2183150",
    "end": "2188820"
  },
  {
    "text": "way to telekinesis analytics how do I do just a subset of my",
    "start": "2188820",
    "end": "2194910"
  },
  {
    "text": "streaming data I only care about the data in this one-hour chunk or this 10",
    "start": "2194910",
    "end": "2200280"
  },
  {
    "text": "minute chunk and that's through windowing functions so we'll take an aside and quickly talk",
    "start": "2200280",
    "end": "2205980"
  },
  {
    "start": "2203000",
    "end": "2203000"
  },
  {
    "text": "about windowing functions in Kinesis analytics they're important and we're going to use them in our in our problem solution here there's two types we have",
    "start": "2205980",
    "end": "2214410"
  },
  {
    "text": "tumbling and sliding they're fixed length and in the case of a tumbling",
    "start": "2214410",
    "end": "2219540"
  },
  {
    "text": "scenario it'll be one record at the output of that window that contains all",
    "start": "2219540",
    "end": "2225360"
  },
  {
    "text": "of the aggregate data for that time period so a tumbling window when you",
    "start": "2225360",
    "end": "2231480"
  },
  {
    "start": "2228000",
    "end": "2228000"
  },
  {
    "text": "define a tumbling window and you say I want my winner to be one minute every one minute Kinesis analytics it's going",
    "start": "2231480",
    "end": "2238260"
  },
  {
    "text": "to run your aggregate functions that you've defined in your sequel and it's going to output a record so let's say",
    "start": "2238260",
    "end": "2244890"
  },
  {
    "text": "you have no data coming through your stream but your your function is using a tumbling window and your window size is",
    "start": "2244890",
    "end": "2251250"
  },
  {
    "text": "a minute every one minute there'll be an output but your aggregate will be zero right I've got no data is still going to",
    "start": "2251250",
    "end": "2256710"
  },
  {
    "text": "account but there's been no record still to be 0 so that's a example of a tumbling window at the end of every",
    "start": "2256710",
    "end": "2263790"
  },
  {
    "text": "window there is a result set regarde of data or not and inside of that window if",
    "start": "2263790",
    "end": "2269420"
  },
  {
    "text": "you do have data of course it'll run your aggregation and it'll give you a result with a sliding window it's",
    "start": "2269420",
    "end": "2274940"
  },
  {
    "text": "slightly different sliding windows the window starts when the record arrives so",
    "start": "2274940",
    "end": "2280670"
  },
  {
    "text": "if I have again a one minute window a record arrives Kinesis analytics will",
    "start": "2280670",
    "end": "2285800"
  },
  {
    "text": "now based on the timestamp of that arriving record it will run the aggregation for all the records that",
    "start": "2285800",
    "end": "2292460"
  },
  {
    "text": "were that had arrived in the minute previous to that record including of course the current record and now let's",
    "start": "2292460",
    "end": "2299300"
  },
  {
    "text": "say one second later another record arrives cases analytics will run another analysis and it will include that record",
    "start": "2299300",
    "end": "2307040"
  },
  {
    "text": "and it will look at all the records that arrived in one minute previous to that record arriving and it'll do the",
    "start": "2307040",
    "end": "2312500"
  },
  {
    "text": "aggregation and give you an output so in that ladder scenario with a sliding window I actually have two outputs from",
    "start": "2312500",
    "end": "2318740"
  },
  {
    "text": "Kinesis analytics one second apart but there's still one minute aggregations they're just one minutes one minute",
    "start": "2318740",
    "end": "2324920"
  },
  {
    "text": "aggregations based on the time that the record arrived versus a tumbling window",
    "start": "2324920",
    "end": "2329930"
  },
  {
    "text": "which is just every 1 minute give me an output so those are the two differences between a tumbling window and a sliding",
    "start": "2329930",
    "end": "2336140"
  },
  {
    "text": "window and in our scenario we are we're just counting those records based on a",
    "start": "2336140",
    "end": "2342170"
  },
  {
    "text": "one-hour tumbling window so how do we aggregate these team mentions per hour",
    "start": "2342170",
    "end": "2350110"
  },
  {
    "start": "2344000",
    "end": "2344000"
  },
  {
    "text": "amazon Kinesis analytics supports a number of built-in functions that make",
    "start": "2350110",
    "end": "2355490"
  },
  {
    "text": "some analysis much simpler than you could do just by writing the sequel you can always write the sequel to do things",
    "start": "2355490",
    "end": "2362030"
  },
  {
    "text": "like distinct counts or top number of items in a window but",
    "start": "2362030",
    "end": "2368030"
  },
  {
    "text": "we've created a few functions for common use cases like top K items tumbling so it's a function that you can use in your",
    "start": "2368030",
    "end": "2373370"
  },
  {
    "text": "application to do a basic count it's more efficient essentially than doing it on your own in sequel so we've created a",
    "start": "2373370",
    "end": "2379850"
  },
  {
    "text": "few of these functions to make that easier for you and then how this function in particular works is you give",
    "start": "2379850",
    "end": "2385670"
  },
  {
    "text": "it a cursor to a stream and then you provided a couple of parameters you say",
    "start": "2385670",
    "end": "2390700"
  },
  {
    "text": "here are the number of items I want you to count and then here's the window size and so in this case I'm actually giving",
    "start": "2390700",
    "end": "2396560"
  },
  {
    "text": "it a cursor to a stream stream just happens to be that stream that I created earlier that has all the",
    "start": "2396560",
    "end": "2403040"
  },
  {
    "text": "team names so the full team name stream that I created a moment ago is input",
    "start": "2403040",
    "end": "2408110"
  },
  {
    "text": "into this it's passed as a reference with the cursor and then top K items tumbling",
    "start": "2408110",
    "end": "2415400"
  },
  {
    "text": "every one hour will tell me the top five mentions top five teams that were",
    "start": "2415400",
    "end": "2421370"
  },
  {
    "text": "included in that stream and it'll tell me how many times they were also mentioned so it's going to do that count",
    "start": "2421370",
    "end": "2427790"
  },
  {
    "text": "for me and it's going to give me the output every hour because it's a tumbling window",
    "start": "2427790",
    "end": "2432850"
  },
  {
    "start": "2432000",
    "end": "2432000"
  },
  {
    "text": "and lastly we're going to output that data to Amazon Kinesis firehose so if",
    "start": "2432850",
    "end": "2440900"
  },
  {
    "text": "firehose like I mentioned gives you the option to put data into a number of different locations in this case it's",
    "start": "2440900",
    "end": "2448300"
  },
  {
    "text": "we're putting it into elasticsearch so that we can kind of visualize the team the team data so every hour because my",
    "start": "2448300",
    "end": "2458630"
  },
  {
    "text": "function aggregation function was giving me the top five mentions top five teams that were",
    "start": "2458630",
    "end": "2464990"
  },
  {
    "text": "mentioned every hour I'm going to have five records each record is going to look very similar to this right I've got",
    "start": "2464990",
    "end": "2472220"
  },
  {
    "text": "a time it's my aggregation time so that's the end of my one hour window and then I have the full team name so the",
    "start": "2472220",
    "end": "2479660"
  },
  {
    "text": "input recall was the hashtag nyr but I didn't that's not very useful to me in my use case I want the team name so on",
    "start": "2479660",
    "end": "2485660"
  },
  {
    "text": "the output I send the full team name and then I have my aggregation and so there'd be five of these records every",
    "start": "2485660",
    "end": "2491960"
  },
  {
    "text": "hour one for each team going into firehose firehose has a few features for",
    "start": "2491960",
    "end": "2497600"
  },
  {
    "text": "buffering the shortest the the minimum amount of time that you can buffer with",
    "start": "2497600",
    "end": "2503450"
  },
  {
    "text": "fire hose is one minute so in this scenario I would just buffer and because my aggregation is an hour the buffer",
    "start": "2503450",
    "end": "2509390"
  },
  {
    "text": "size here can be you know a minute or five minutes it's not that important Amazon Kinesis sorry Amazon fire hose",
    "start": "2509390",
    "end": "2516590"
  },
  {
    "text": "will once an hour sorry once a minute if I've configured it that way put my records into elasticsearch and then I",
    "start": "2516590",
    "end": "2524240"
  },
  {
    "text": "can visualize it using Cabana so if you're not familiar with with the elasticsearch service it has",
    "start": "2524240",
    "end": "2529880"
  },
  {
    "text": "cabana built in natively as well so for things like visualization why they're kind of wrapped in one single box here",
    "start": "2529880",
    "end": "2535700"
  },
  {
    "text": "it's very straightforward Cabana is a nice tool for visualizing data in elastic search and our elastic search",
    "start": "2535700",
    "end": "2541760"
  },
  {
    "text": "service has native support for Cabana it's just one click and you have a cabana implementation so that's the",
    "start": "2541760",
    "end": "2549260"
  },
  {
    "text": "output and then we want to visualize it so it was very simple I went into Cabana just said show me all the data over a",
    "start": "2549260",
    "end": "2554930"
  },
  {
    "start": "2550000",
    "end": "2550000"
  },
  {
    "text": "24-hour period of all the teams and how many dimensions there were and you can see the chart that I've got here and the",
    "start": "2554930",
    "end": "2561500"
  },
  {
    "text": "team it's maybe hard to make out you know Chicago Blackhawks had 2,500 mentions what's kind of neat about this",
    "start": "2561500",
    "end": "2567140"
  },
  {
    "text": "solution this scenario was as you know obviously it gives you a good insight",
    "start": "2567140",
    "end": "2572720"
  },
  {
    "text": "into who was playing so I I took this data I kind of correlated it with the actual schedule and not surprisingly",
    "start": "2572720",
    "end": "2579380"
  },
  {
    "text": "where you see these Peaks was when these teams were playing so it gives you some kind of good into site insight into what",
    "start": "2579380",
    "end": "2585620"
  },
  {
    "text": "was going on in the league at that period of time who was playing who was winning actually so it was kind of a",
    "start": "2585620",
    "end": "2590660"
  },
  {
    "text": "nice insight into that so that's a quick overview of Kinesis analytics kind of",
    "start": "2590660",
    "end": "2596180"
  },
  {
    "text": "one use case for how you can simply aggregate data and",
    "start": "2596180",
    "end": "2602480"
  },
  {
    "text": "put it into a persistent data source and then visualize that data so if you recall the three you know three of the",
    "start": "2602480",
    "end": "2608600"
  },
  {
    "text": "most common use cases that I've seen in Kinesis analytics usage were one of them was dashboarding and so this is a good",
    "start": "2608600",
    "end": "2614870"
  },
  {
    "text": "example of that I'm collecting some business metrics in this case it's you know mentions team mentions and I'm",
    "start": "2614870",
    "end": "2620750"
  },
  {
    "text": "visualizing them in real time in a dashboard so that's one of the most common use cases that we see today",
    "start": "2620750",
    "end": "2627340"
  },
  {
    "text": "so Amazon Kinesis analytics best practices like I said I'd reinvent",
    "start": "2627340",
    "end": "2633440"
  },
  {
    "text": "you're here to kind of learn how how you can do it and then what you know what should you consider when you're when you're implementing something so let's",
    "start": "2633440",
    "end": "2639170"
  },
  {
    "text": "take a look at a few best practices for Canisius analytics as with pretty much everything in AWS",
    "start": "2639170",
    "end": "2647320"
  },
  {
    "start": "2641000",
    "end": "2641000"
  },
  {
    "text": "cloud watch alarms are very important right we are writing metrics about your",
    "start": "2647320",
    "end": "2652520"
  },
  {
    "text": "application into cloud watch and you should in regardless of whether it's",
    "start": "2652520",
    "end": "2657740"
  },
  {
    "text": "cases analytics or some other system you should monitor those metrics and make decisions based on the data that you see",
    "start": "2657740",
    "end": "2664240"
  },
  {
    "text": "no difference with Kinesis analytics the most important metric we have a few others but the most important one you",
    "start": "2664240",
    "end": "2670470"
  },
  {
    "text": "should track is Millie's behind latest what that is is it tells you how far",
    "start": "2670470",
    "end": "2675750"
  },
  {
    "text": "behind your Kinesis analytics application is in processing a stream relative to the most recent record added",
    "start": "2675750",
    "end": "2682859"
  },
  {
    "text": "to the stream so if you get to about an hour behind that's it's totally a rough",
    "start": "2682859",
    "end": "2689700"
  },
  {
    "text": "guidance it's really going to be dependent upon your tolerance for latency in your use case but an hour you",
    "start": "2689700",
    "end": "2695970"
  },
  {
    "text": "know that's a rough kind of rule of thumb if you get over an hour there's probably something wrong and you should",
    "start": "2695970",
    "end": "2701970"
  },
  {
    "text": "consider you know investigating that in your use case you might decide that a minute latency is too long and so you",
    "start": "2701970",
    "end": "2708690"
  },
  {
    "text": "should do something about that as well but where you will get that data is the Millie's behind latest metrics so that",
    "start": "2708690",
    "end": "2714420"
  },
  {
    "text": "is a very important metric to monitor so what happens if you do see that happening right if you do start to fall",
    "start": "2714420",
    "end": "2721950"
  },
  {
    "text": "behind processing your ingestion stream your education what do you do one",
    "start": "2721950",
    "end": "2727109"
  },
  {
    "text": "approach is to increase the input parallelism to improve the performance so the reason I",
    "start": "2727109",
    "end": "2733109"
  },
  {
    "text": "talked earlier about shards in a Kinesis stream is because with Kinesis analytics",
    "start": "2733109",
    "end": "2739710"
  },
  {
    "text": "when you create an application it'll go look at your straight your input stream it'll notice the number of shards",
    "start": "2739710",
    "end": "2745730"
  },
  {
    "text": "but by default it will map all of those into one single in application stream",
    "start": "2745730",
    "end": "2751950"
  },
  {
    "text": "remember that's a that's a casus analytics construct an in-app stream so you now have one stream in Kinesis",
    "start": "2751950",
    "end": "2757470"
  },
  {
    "text": "analytics containing the data from all of your input shards if you notice yourself getting perhaps behind one",
    "start": "2757470",
    "end": "2764640"
  },
  {
    "text": "approach is to create additional there's a basically a feature in Kinesis",
    "start": "2764640",
    "end": "2771510"
  },
  {
    "text": "analytics allows you to create more in application streams for the number of",
    "start": "2771510",
    "end": "2777900"
  },
  {
    "text": "shards in your input Kinesis stream so it gets a little complicated with all those streams but what you want to do is",
    "start": "2777900",
    "end": "2784109"
  },
  {
    "text": "take a look at the parallelism attribute associated with your Kinesis analytics app and",
    "start": "2784109",
    "end": "2791420"
  },
  {
    "text": "increase it if you let's say you have four shards and you create Kinesis",
    "start": "2791420",
    "end": "2796500"
  },
  {
    "text": "analytics parallelism attributes set to four now you'll have four or in",
    "start": "2796500",
    "end": "2801599"
  },
  {
    "text": "application streams in your cases analytics app one for each shard you",
    "start": "2801599",
    "end": "2806880"
  },
  {
    "text": "probably have to go in and change your sequel because now you've got four different in-app streams one contending",
    "start": "2806880",
    "end": "2812099"
  },
  {
    "text": "each shard you're probably going to have to do a little bit of aggregation to put them into a single in application stream in the Kinesis analytics app but now",
    "start": "2812099",
    "end": "2819509"
  },
  {
    "text": "you've got some parallel processing that you can do and so if you find the middle e's behind",
    "start": "2819509",
    "end": "2825289"
  },
  {
    "text": "latest metric falling behind take a look at the parallelism feature that you can",
    "start": "2825289",
    "end": "2832099"
  },
  {
    "text": "that you can adjust in your Kinesis analytics app",
    "start": "2832099",
    "end": "2838160"
  },
  {
    "text": "limit the number of applications reading from the same source so this isn't necessarily a limitation of Kinesis",
    "start": "2838549",
    "end": "2844109"
  },
  {
    "text": "analytics but if you're familiar or even if you're not familiar with Kinesis streams or Kinesis firehose",
    "start": "2844109",
    "end": "2849349"
  },
  {
    "text": "Kinesis streams has egress limits five transactions per",
    "start": "2849349",
    "end": "2855450"
  },
  {
    "text": "second can come out of a Kinesis stream or two megabytes per second can come out of a Kinesis stream so if you have a",
    "start": "2855450",
    "end": "2861599"
  },
  {
    "text": "Kinesis analytics app that you've written to do analysis on the data in that stream",
    "start": "2861599",
    "end": "2867710"
  },
  {
    "text": "you need to consider that that Kinesis analytics app is just another consumer",
    "start": "2867710",
    "end": "2872759"
  },
  {
    "text": "of that stream so because that stream only supports five TPS or two Meg's egress if you were to put ten you know",
    "start": "2872759",
    "end": "2880109"
  },
  {
    "text": "Kinesis analytics applications all reading from the same stream you would go beyond the five reads per second",
    "start": "2880109",
    "end": "2886619"
  },
  {
    "text": "because Kinesis analytics is actually reading once a second from your stream so if you go over five and in fact if",
    "start": "2886619",
    "end": "2893069"
  },
  {
    "text": "you go like even less than that but if you go to five you're going to be throttled by the Kinesis stream so you",
    "start": "2893069",
    "end": "2899700"
  },
  {
    "text": "want to make sure that you you don't go over to to be on the safe side and then Kinesis firehose very similarly because",
    "start": "2899700",
    "end": "2907619"
  },
  {
    "text": "because like I said earlier Kinesis firehose is ultimately writing your data to a destination whether that's s3 or",
    "start": "2907619",
    "end": "2914099"
  },
  {
    "text": "elasticsearch that's one consumer already right so we don't want to impact the system that's already writing data",
    "start": "2914099",
    "end": "2921479"
  },
  {
    "text": "to s3 so with Kinesis analytics if using firehose as a source you should limit it",
    "start": "2921479",
    "end": "2926759"
  },
  {
    "text": "just to one Kinesis analytics app reading from that firehose stream same thing you don't want to get the reprovision throughput exceeded",
    "start": "2926759",
    "end": "2934019"
  },
  {
    "text": "exception being thrown by your source firehose or your source Kinesis stream I",
    "start": "2934019",
    "end": "2941280"
  },
  {
    "start": "2940000",
    "end": "2940000"
  },
  {
    "text": "kind of talked about this already but review and test that inferred schema",
    "start": "2941280",
    "end": "2946690"
  },
  {
    "text": "like I said Kinesis analytics is going to look at that input data it's going to create a schema but it's only looking at",
    "start": "2946690",
    "end": "2952329"
  },
  {
    "text": "a sample of your input so if your data didn't contain every single attribute in",
    "start": "2952329",
    "end": "2959290"
  },
  {
    "text": "the sample set the kinase is analytics used your scheme is not going to match if the let's say your input type was a",
    "start": "2959290",
    "end": "2967869"
  },
  {
    "text": "text and it was a string of let's say maximum size it could ever be as 200 characters but the sample records that",
    "start": "2967869",
    "end": "2975130"
  },
  {
    "text": "Kinesis analytics looked at never had a text size greater than 50 characters",
    "start": "2975130",
    "end": "2980430"
  },
  {
    "text": "it's going to create a VAR car 50 as the input data type and so as soon as you",
    "start": "2980430",
    "end": "2986980"
  },
  {
    "text": "get to like a string that's 100 characters it's going to truncate that and it's not going to be useful to you so you need to be aware of what your",
    "start": "2986980",
    "end": "2993280"
  },
  {
    "text": "input data looks like go in and modify the schema because the inferred schema is like our best guess but you know best",
    "start": "2993280",
    "end": "3000660"
  },
  {
    "text": "based on your use case",
    "start": "3000660",
    "end": "3003770"
  },
  {
    "text": "yeah okay the last point here sorry so using sequel functions in your application run structured data so",
    "start": "3006440",
    "end": "3012950"
  },
  {
    "text": "it's possible if you have very unstructured data and Kinesis analytics",
    "start": "3012950",
    "end": "3018180"
  },
  {
    "text": "could not create an inferred schema from it doesn't mean you can't use Kinesis analytics but there are plenty of string",
    "start": "3018180",
    "end": "3024300"
  },
  {
    "text": "manipulation functions that you could use inside of you can uses analytics app to do the the parsing of your data and",
    "start": "3024300",
    "end": "3031109"
  },
  {
    "text": "then you know do additional analysis after you've parsed it in your application",
    "start": "3031109",
    "end": "3036230"
  },
  {
    "start": "3036000",
    "end": "3036000"
  },
  {
    "text": "when you're writing your application code try to avoid time-based windows greater than an hour I know my example",
    "start": "3036230",
    "end": "3042030"
  },
  {
    "text": "use an hour that's the most that we'd probably want to go the reason being if for some reason you",
    "start": "3042030",
    "end": "3048420"
  },
  {
    "text": "like let's say you went and you stopped the Kinesis analytics app or something happened in Kinesis analytics and it stopped processing your application it's",
    "start": "3048420",
    "end": "3055170"
  },
  {
    "text": "going to go back and reprocess the data it's checkpointing where it left last left off so if your time windows are",
    "start": "3055170",
    "end": "3061710"
  },
  {
    "text": "large and say longer than an hour when it comes back up it's going to go back and it's going to reprocess the process",
    "start": "3061710",
    "end": "3067170"
  },
  {
    "text": "the data and on your application it might have a hard time getting caught up so that Millie's behind latest might",
    "start": "3067170",
    "end": "3072720"
  },
  {
    "text": "continue to be kind of out of the threshold that you've set so try and keep your your time based windows",
    "start": "3072720",
    "end": "3079260"
  },
  {
    "text": "shorter and in fact and kind of another point is if you're talking about longer than an hour aggregations it's probably",
    "start": "3079260",
    "end": "3085860"
  },
  {
    "text": "it's now it's no longer like real-time streaming data there might be other solutions that are better for doing that",
    "start": "3085860",
    "end": "3091290"
  },
  {
    "text": "kind of analysis when you're building your application this is kind of a no-brainer but keep your keep your",
    "start": "3091290",
    "end": "3097260"
  },
  {
    "text": "window size is small when I was developing that NHL one I use",
    "start": "3097260",
    "end": "3102990"
  },
  {
    "text": "like 10 second aggregations it just makes it easier to see what's going on if you have to wait an hour to see the",
    "start": "3102990",
    "end": "3108150"
  },
  {
    "text": "output of your results because your business asks you to give you an hourly result it's going to take you forever to",
    "start": "3108150",
    "end": "3114660"
  },
  {
    "text": "develop the app so just create like you know five-second ten-second windows gives you a lot more visibility and similarly the last one this is kind of",
    "start": "3114660",
    "end": "3120720"
  },
  {
    "text": "best practices and just development think of it like micro service development use smaller queries so",
    "start": "3120720",
    "end": "3126150"
  },
  {
    "text": "instead of creating one large sequel query with a whole bunch of nested sequel in your application because you",
    "start": "3126150",
    "end": "3131850"
  },
  {
    "text": "can create in application streams create a create more smaller streams because",
    "start": "3131850",
    "end": "3137160"
  },
  {
    "text": "you can inspect the output of these smaller streams so you can create several select statements and then you",
    "start": "3137160",
    "end": "3142290"
  },
  {
    "text": "can inspect them in your application and the in app and the Kinesis analytics app it's going to be much easier to debug",
    "start": "3142290",
    "end": "3147690"
  },
  {
    "text": "your application there's a few limits if you've used AWS for a while you know most of our services have limits some",
    "start": "3147690",
    "end": "3153780"
  },
  {
    "start": "3149000",
    "end": "3149000"
  },
  {
    "text": "are soft some are hard in this case these are all fixed limits these these",
    "start": "3153780",
    "end": "3158940"
  },
  {
    "text": "can't be changed but over every row sized Internet application stream maximum size is 50k maximum input",
    "start": "3158940",
    "end": "3165330"
  },
  {
    "text": "parallelism I talked about that having the ability to change the input parallelism is 10 so you can have 10 in",
    "start": "3165330",
    "end": "3171060"
  },
  {
    "text": "application streams based on your input data and then we talked about this as well but each applications can support",
    "start": "3171060",
    "end": "3177540"
  },
  {
    "text": "one streaming source in one reference data source so you can connect to either Kinesis stream or Kinesis firehose and",
    "start": "3177540",
    "end": "3185180"
  },
  {
    "text": "you can use some reference data from s3 in your application the point on the",
    "start": "3185180",
    "end": "3190920"
  },
  {
    "text": "last point here to your reference data can't be larger than than one gig one gig is the next size and that brings us to the last point",
    "start": "3190920",
    "end": "3198000"
  },
  {
    "start": "3195000",
    "end": "3195000"
  },
  {
    "text": "that we'll talk about here and then what I think we'll have a couple of minutes for questions but pricing and then tied to pricing is this notion of kpu or the",
    "start": "3198000",
    "end": "3206050"
  },
  {
    "text": "Kinesis processing unit so with Kinesis analytics you pay only for what you use",
    "start": "3206050",
    "end": "3211800"
  },
  {
    "text": "but you're charged based on an Amazon Kinesis processing unit so what does",
    "start": "3211800",
    "end": "3218050"
  },
  {
    "text": "that mean a kpu is a single V CPU and four gigs of RAM so as your application",
    "start": "3218050",
    "end": "3223660"
  },
  {
    "text": "is running of course we are monitoring it and we know how much CPU and memory is required to process",
    "start": "3223660",
    "end": "3231040"
  },
  {
    "text": "your data and give you the results in the time that you're expecting so if you're doing a ten-minute aggregation we",
    "start": "3231040",
    "end": "3237609"
  },
  {
    "text": "want the within after the ten minutes we want that to go downstream nearly",
    "start": "3237609",
    "end": "3243220"
  },
  {
    "text": "immediately after that ten minute window so we will scale accordingly to do that we'll add virtual CPUs and we'll add",
    "start": "3243220",
    "end": "3248710"
  },
  {
    "text": "memory up to 8k p use so the max you can",
    "start": "3248710",
    "end": "3253780"
  },
  {
    "text": "consume at any point in time is eight CPUs or 32 gigs of ram on the hosts that are managing the application and you're",
    "start": "3253780",
    "end": "3260710"
  },
  {
    "text": "charged in this isn't us yeast the prices are of course dependent on the region but in the u.s. East eleven cents",
    "start": "3260710",
    "end": "3267250"
  },
  {
    "text": "per kpu hour so for every hour that your application is running if it is only",
    "start": "3267250",
    "end": "3273940"
  },
  {
    "text": "consuming one virtual 1kp you then you're paying eleven cents an hour of course with the example that I described",
    "start": "3273940",
    "end": "3280599"
  },
  {
    "text": "the the Twitter analysis keeping in mind that there's some cyclical nature to that you know it might at night on",
    "start": "3280599",
    "end": "3286900"
  },
  {
    "text": "Saturday it bursts it up to like two V CPUs and eight gigs of RAM and so for",
    "start": "3286900",
    "end": "3292690"
  },
  {
    "text": "the couple of hours and that was happening I might have paid 22 cents an hour X's 2 K P use and then when it goes back down overnight it automatically",
    "start": "3292690",
    "end": "3299109"
  },
  {
    "text": "scales back down you're only paying the eleven cents an hour so it's based on the based on the the K P uses how you",
    "start": "3299109",
    "end": "3304690"
  },
  {
    "text": "pay for cases handled eggs so that's that's a introduction I hope",
    "start": "3304690",
    "end": "3310660"
  },
  {
    "text": "to Kinesis analytics gives you a kind of a good idea of some of the common use cases that we're seeing today",
    "start": "3310660",
    "end": "3315960"
  },
  {
    "text": "walks through an example I hope that gave you some insights into perhaps how you can leverage Kinesis analytics in",
    "start": "3315960",
    "end": "3321430"
  },
  {
    "text": "your application with your business data so that's it thank you very much we do have four minutes if I take two",
    "start": "3321430",
    "end": "3328060"
  },
  {
    "text": "questions you",
    "start": "3328060",
    "end": "3331560"
  }
]
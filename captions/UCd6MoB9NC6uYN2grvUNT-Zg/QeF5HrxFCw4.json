[
  {
    "text": "good afternoon everybody we're back",
    "start": "5660",
    "end": "8460"
  },
  {
    "text": "I'm Sania we're here to talk more",
    "start": "8460",
    "end": "10889"
  },
  {
    "text": "machine learning",
    "start": "10889",
    "end": "11760"
  },
  {
    "text": "I've got Slava here with me from the MX",
    "start": "11760",
    "end": "14700"
  },
  {
    "text": "Neve team so we're going to talk about",
    "start": "14700",
    "end": "19500"
  },
  {
    "text": "so we're launching model server for a",
    "start": "19500",
    "end": "22800"
  },
  {
    "text": "mix at Apache MX nets are we adding the",
    "start": "22800",
    "end": "25529"
  },
  {
    "text": "container support for scalable model",
    "start": "25529",
    "end": "28109"
  },
  {
    "text": "inference so yeah maybe we can just talk",
    "start": "28109",
    "end": "32640"
  },
  {
    "text": "about like why is it cool and this is",
    "start": "32640",
    "end": "42930"
  },
  {
    "text": "one among other reasons why the AWS",
    "start": "42930",
    "end": "45570"
  },
  {
    "text": "actually make it our deep learning",
    "start": "45570",
    "end": "47040"
  },
  {
    "text": "framework of choice and the second one",
    "start": "47040",
    "end": "49080"
  },
  {
    "text": "is simplicity it's really simple to use",
    "start": "49080",
    "end": "50909"
  },
  {
    "text": "it so basically first the speed usually",
    "start": "50909",
    "end": "53760"
  },
  {
    "text": "attracts you and makes it you want to",
    "start": "53760",
    "end": "56549"
  },
  {
    "text": "use it and the second one keeps you in",
    "start": "56549",
    "end": "58229"
  },
  {
    "text": "so it's really cool just give it a try",
    "start": "58229",
    "end": "60750"
  },
  {
    "text": "and may I add like we also have duan",
    "start": "60750",
    "end": "63150"
  },
  {
    "text": "support which is on top of makes that so",
    "start": "63150",
    "end": "65460"
  },
  {
    "text": "the imperative interface makes it really",
    "start": "65460",
    "end": "67740"
  },
  {
    "text": "easy and intuitive for developers to",
    "start": "67740",
    "end": "70020"
  },
  {
    "text": "pick up on deep learning yeah and we",
    "start": "70020",
    "end": "73049"
  },
  {
    "text": "kind of women have a book straight dog",
    "start": "73049",
    "end": "75450"
  },
  {
    "text": "but they basically teach you how to use",
    "start": "75450",
    "end": "77340"
  },
  {
    "text": "it make sure you want right",
    "start": "77340",
    "end": "79799"
  },
  {
    "text": "maybe you want to talk a little bit",
    "start": "79799",
    "end": "81090"
  },
  {
    "text": "about what's the the a mixed model",
    "start": "81090",
    "end": "83429"
  },
  {
    "text": "server first sure yes",
    "start": "83429",
    "end": "85530"
  },
  {
    "text": "so basically let's say you have a model",
    "start": "85530",
    "end": "87539"
  },
  {
    "text": "right you have a model that is ready for",
    "start": "87539",
    "end": "89820"
  },
  {
    "text": "the production deployment so how and we",
    "start": "89820",
    "end": "92100"
  },
  {
    "text": "are going to deploy it you actually have",
    "start": "92100",
    "end": "94079"
  },
  {
    "text": "several options you can build from",
    "start": "94079",
    "end": "95640"
  },
  {
    "text": "ground up the software for precisely",
    "start": "95640",
    "end": "97560"
  },
  {
    "text": "your model supported and deployed",
    "start": "97560",
    "end": "100320"
  },
  {
    "text": "somewhere or you can go to the services",
    "start": "100320",
    "end": "102270"
  },
  {
    "text": "like sage maker deployed completely in",
    "start": "102270",
    "end": "104280"
  },
  {
    "text": "the cloud there are a lot of customers",
    "start": "104280",
    "end": "106200"
  },
  {
    "text": "who wants to be in between them",
    "start": "106200",
    "end": "108180"
  },
  {
    "text": "to the point there are all instances but",
    "start": "108180",
    "end": "111060"
  },
  {
    "text": "they're not ready to deploy from ground",
    "start": "111060",
    "end": "113100"
  },
  {
    "text": "up the system for production deployment",
    "start": "113100",
    "end": "115170"
  },
  {
    "text": "and model server for patchy mix that",
    "start": "115170",
    "end": "118320"
  },
  {
    "text": "sits exactly in that spot so you can",
    "start": "118320",
    "end": "120420"
  },
  {
    "text": "think about it is a Tomcat in Java board",
    "start": "120420",
    "end": "122990"
  },
  {
    "text": "ready using to deploy applications but",
    "start": "122990",
    "end": "125580"
  },
  {
    "text": "this is Tomcat particular onic where you",
    "start": "125580",
    "end": "127260"
  },
  {
    "text": "can charge the power model and by the",
    "start": "127260",
    "end": "129179"
  },
  {
    "text": "way even though IMAX netting the name of",
    "start": "129179",
    "end": "131670"
  },
  {
    "text": "the product itself a model servers for",
    "start": "131670",
    "end": "133890"
  },
  {
    "text": "Apache max it's not only died for a max",
    "start": "133890",
    "end": "136230"
  },
  {
    "text": "net it's actually capable of serving any",
    "start": "136230",
    "end": "138600"
  },
  {
    "text": "model that is using ponics today yeah",
    "start": "138600",
    "end": "142700"
  },
  {
    "text": "maybe you want to talk to our developers",
    "start": "142700",
    "end": "145470"
  },
  {
    "text": "here what's onyx what's the story there",
    "start": "145470",
    "end": "147840"
  },
  {
    "text": "sure so there are a lot of cases when",
    "start": "147840",
    "end": "150870"
  },
  {
    "text": "you designing the model let's say in the",
    "start": "150870",
    "end": "153000"
  },
  {
    "text": "PI torch right and then you want to",
    "start": "153000",
    "end": "154650"
  },
  {
    "text": "deploy it to somewhere but this",
    "start": "154650",
    "end": "156239"
  },
  {
    "text": "deployment environment not a necessary",
    "start": "156239",
    "end": "158580"
  },
  {
    "text": "capable to work with a PI touch model",
    "start": "158580",
    "end": "160590"
  },
  {
    "text": "format so the onyx is basically a form",
    "start": "160590",
    "end": "163020"
  },
  {
    "text": "of representing your model that can be",
    "start": "163020",
    "end": "165060"
  },
  {
    "text": "shared between many many many deep",
    "start": "165060",
    "end": "166709"
  },
  {
    "text": "learning frameworks so essentially by",
    "start": "166709",
    "end": "168900"
  },
  {
    "text": "supporting onyx M accept model server is",
    "start": "168900",
    "end": "172350"
  },
  {
    "text": "capable to serving any model you can",
    "start": "172350",
    "end": "174810"
  },
  {
    "text": "even use a tender flow because desert",
    "start": "174810",
    "end": "177120"
  },
  {
    "text": "already have a converter to onyx tools",
    "start": "177120",
    "end": "179459"
  },
  {
    "text": "so yes this is really cool so can you",
    "start": "179459",
    "end": "185549"
  },
  {
    "text": "talk a little bit about how you work",
    "start": "185549",
    "end": "187200"
  },
  {
    "text": "with containers",
    "start": "187200",
    "end": "189180"
  },
  {
    "text": "model server okay so basically with",
    "start": "189180",
    "end": "192420"
  },
  {
    "text": "parent deployment we introducing",
    "start": "192420",
    "end": "194300"
  },
  {
    "text": "containers that inside already have MX",
    "start": "194300",
    "end": "197190"
  },
  {
    "text": "net model server",
    "start": "197190",
    "end": "198300"
  },
  {
    "text": "this basically means of the now you can",
    "start": "198300",
    "end": "200190"
  },
  {
    "text": "the boy you model do anything that",
    "start": "200190",
    "end": "202350"
  },
  {
    "text": "support containers like easy as",
    "start": "202350",
    "end": "204240"
  },
  {
    "text": "kubernetes eager ass or far gate right",
    "start": "204240",
    "end": "207690"
  },
  {
    "text": "so basically we introducing the last",
    "start": "207690",
    "end": "211080"
  },
  {
    "text": "step that is needed to for easy deploy",
    "start": "211080",
    "end": "213810"
  },
  {
    "text": "of your production models so I'd love to",
    "start": "213810",
    "end": "217890"
  },
  {
    "text": "see if you know demo but maybe if people",
    "start": "217890",
    "end": "221130"
  },
  {
    "text": "are just joining in you can summarize",
    "start": "221130",
    "end": "222660"
  },
  {
    "text": "what are we launching today okay so",
    "start": "222660",
    "end": "225120"
  },
  {
    "text": "we're launching support of the",
    "start": "225120",
    "end": "226380"
  },
  {
    "text": "containers for model server for party MX",
    "start": "226380",
    "end": "229620"
  },
  {
    "text": "net so now you can actually use our",
    "start": "229620",
    "end": "231600"
  },
  {
    "text": "containers to deploy your model to any",
    "start": "231600",
    "end": "233970"
  },
  {
    "text": "environment that supports containers I'm",
    "start": "233970",
    "end": "237720"
  },
  {
    "text": "excited yeah",
    "start": "237720",
    "end": "238680"
  },
  {
    "text": "so let's actually switch to my screen",
    "start": "238680",
    "end": "240560"
  },
  {
    "text": "let me start with the pictures of the",
    "start": "240560",
    "end": "243270"
  },
  {
    "text": "kitten because everyone loves kiddin",
    "start": "243270",
    "end": "244860"
  },
  {
    "text": "right so yes we all do let's say I have",
    "start": "244860",
    "end": "248040"
  },
  {
    "text": "a model that knows how to identify type",
    "start": "248040",
    "end": "250230"
  },
  {
    "text": "of the canal picture so this is a",
    "start": "250230",
    "end": "251790"
  },
  {
    "text": "picture with the growing use for testing",
    "start": "251790",
    "end": "253320"
  },
  {
    "text": "if you want to deploy this model to the",
    "start": "253320",
    "end": "255360"
  },
  {
    "text": "production you need to do a three simple",
    "start": "255360",
    "end": "257130"
  },
  {
    "text": "steps step number one you need to see",
    "start": "257130",
    "end": "260430"
  },
  {
    "text": "that MMS is actually correctly working",
    "start": "260430",
    "end": "262590"
  },
  {
    "text": "with your model this is a very simple",
    "start": "262590",
    "end": "264870"
  },
  {
    "text": "step you need to install where the keep",
    "start": "264870",
    "end": "267210"
  },
  {
    "text": "MMS on your machine this is actually",
    "start": "267210",
    "end": "269850"
  },
  {
    "text": "deploying a myelination to instance and",
    "start": "269850",
    "end": "271770"
  },
  {
    "text": "for people who don't know this is the",
    "start": "271770",
    "end": "273300"
  },
  {
    "text": "best way to get your environment set up",
    "start": "273300",
    "end": "275250"
  },
  {
    "text": "on AWS so use the deep learning a my web",
    "start": "275250",
    "end": "277740"
  },
  {
    "text": "unto and the next version the next",
    "start": "277740",
    "end": "280229"
  },
  {
    "text": "version all the drivers for CUDA all the",
    "start": "280229",
    "end": "283979"
  },
  {
    "text": "deep learning frameworks are plop water",
    "start": "283979",
    "end": "285810"
  },
  {
    "text": "come and the data science library is all",
    "start": "285810",
    "end": "287910"
  },
  {
    "text": "packaged so it couldn't be easier to get",
    "start": "287910",
    "end": "290280"
  },
  {
    "text": "your deep learning setup it just worked",
    "start": "290280",
    "end": "292260"
  },
  {
    "text": "yes",
    "start": "292260",
    "end": "294030"
  },
  {
    "text": "so this is basically packaged and the",
    "start": "294030",
    "end": "296100"
  },
  {
    "text": "only thing that I need to provide is URL",
    "start": "296100",
    "end": "299310"
  },
  {
    "text": "for my model as you can see URL can be",
    "start": "299310",
    "end": "301169"
  },
  {
    "text": "any public URL nothing else so this is",
    "start": "301169",
    "end": "303510"
  },
  {
    "text": "basically one-liner and who started the",
    "start": "303510",
    "end": "305160"
  },
  {
    "text": "process and now my model already running",
    "start": "305160",
    "end": "307320"
  },
  {
    "text": "let's just double check by requesting a",
    "start": "307320",
    "end": "310919"
  },
  {
    "text": "team just to verify that my servers",
    "start": "310919",
    "end": "312870"
  },
  {
    "text": "running and let's actually run the",
    "start": "312870",
    "end": "314850"
  },
  {
    "text": "inference I have a predefined model for",
    "start": "314850",
    "end": "318169"
  },
  {
    "text": "for the inference that I'm going to",
    "start": "318169",
    "end": "320860"
  },
  {
    "text": "copy/paste this is a request post",
    "start": "320860",
    "end": "324770"
  },
  {
    "text": "request that I'm going to execute and",
    "start": "324770",
    "end": "326389"
  },
  {
    "text": "here's the result so according to",
    "start": "326389",
    "end": "327979"
  },
  {
    "text": "nominal model this is a Gyptian cat I",
    "start": "327979",
    "end": "330139"
  },
  {
    "text": "have no idea what the description can",
    "start": "330139",
    "end": "332330"
  },
  {
    "text": "but let's let's just drop the mono it's",
    "start": "332330",
    "end": "334419"
  },
  {
    "text": "sometimes you've you know your training",
    "start": "334419",
    "end": "336680"
  },
  {
    "text": "data is not doesn't have you know kitten",
    "start": "336680",
    "end": "339050"
  },
  {
    "text": "so well",
    "start": "339050",
    "end": "340009"
  },
  {
    "text": "put more kittens into your model like",
    "start": "340009",
    "end": "342169"
  },
  {
    "text": "training data that's the key yes so okay",
    "start": "342169",
    "end": "344749"
  },
  {
    "text": "now you you see that your MMS is capable",
    "start": "344749",
    "end": "347360"
  },
  {
    "text": "to work with your model the second step",
    "start": "347360",
    "end": "349099"
  },
  {
    "text": "would be to create a container the only",
    "start": "349099",
    "end": "351169"
  },
  {
    "text": "thing that you need you need to provide",
    "start": "351169",
    "end": "353419"
  },
  {
    "text": "a config this is example of the conflict",
    "start": "353419",
    "end": "356180"
  },
  {
    "text": "that basically container will be using",
    "start": "356180",
    "end": "358430"
  },
  {
    "text": "underneath and to get started you just",
    "start": "358430",
    "end": "360860"
  },
  {
    "text": "need to change one line this line is",
    "start": "360860",
    "end": "362810"
  },
  {
    "text": "line that sets the model again you've",
    "start": "362810",
    "end": "365120"
  },
  {
    "text": "been wanting this one liner and you",
    "start": "365120",
    "end": "366949"
  },
  {
    "text": "start in your container container is",
    "start": "366949",
    "end": "368509"
  },
  {
    "text": "essentially just the one line of the",
    "start": "368509",
    "end": "370490"
  },
  {
    "text": "starter container let me quickly find",
    "start": "370490",
    "end": "373129"
  },
  {
    "text": "this is the one line so as simple this",
    "start": "373129",
    "end": "375589"
  },
  {
    "text": "I'm starting the container with my",
    "start": "375589",
    "end": "377360"
  },
  {
    "text": "config and let me double check that it's",
    "start": "377360",
    "end": "381349"
  },
  {
    "text": "actually",
    "start": "381349",
    "end": "383290"
  },
  {
    "text": "running the inference so I think I'd be",
    "start": "383290",
    "end": "384940"
  },
  {
    "text": "based on my comment again the same",
    "start": "384940",
    "end": "388900"
  },
  {
    "text": "comment basically I'm going to execute",
    "start": "388900",
    "end": "390430"
  },
  {
    "text": "the inference for the same models so I'm",
    "start": "390430",
    "end": "392530"
  },
  {
    "text": "going to send the same signal",
    "start": "392530",
    "end": "394419"
  },
  {
    "text": "I just changing the port to 80 because",
    "start": "394419",
    "end": "396220"
  },
  {
    "text": "this time I have the port mapping and we",
    "start": "396220",
    "end": "399430"
  },
  {
    "text": "have the same Egyptian cat ok so now we",
    "start": "399430",
    "end": "401680"
  },
  {
    "text": "have a container",
    "start": "401680",
    "end": "402580"
  },
  {
    "text": "right now we're absolutely ready to",
    "start": "402580",
    "end": "404260"
  },
  {
    "text": "avoid container to the production system",
    "start": "404260",
    "end": "406150"
  },
  {
    "text": "as of now you",
    "start": "406150",
    "end": "407800"
  },
  {
    "text": "we actually have released the article",
    "start": "407800",
    "end": "410080"
  },
  {
    "text": "how to deploy mms on the Fargate to",
    "start": "410080",
    "end": "412840"
  },
  {
    "text": "actually do absolutely several lays",
    "start": "412840",
    "end": "414880"
  },
  {
    "text": "inference in the production's it's",
    "start": "414880",
    "end": "416770"
  },
  {
    "text": "amazing like we should take a moment",
    "start": "416770",
    "end": "418090"
  },
  {
    "text": "like the entire like ml pipeline on the",
    "start": "418090",
    "end": "420940"
  },
  {
    "text": "inference side has been simplified",
    "start": "420940",
    "end": "422680"
  },
  {
    "text": "I don't know if people realize this but",
    "start": "422680",
    "end": "425260"
  },
  {
    "text": "you know we often give emphasis on the",
    "start": "425260",
    "end": "427630"
  },
  {
    "text": "training aspect of you know model and",
    "start": "427630",
    "end": "430450"
  },
  {
    "text": "that that's where we spend a lot of time",
    "start": "430450",
    "end": "432010"
  },
  {
    "text": "thinking but if you think about like",
    "start": "432010",
    "end": "434950"
  },
  {
    "text": "production cost like you know a",
    "start": "434950",
    "end": "437310"
  },
  {
    "text": "disproportionate amount of cost is",
    "start": "437310",
    "end": "439479"
  },
  {
    "text": "actually spent on the hosting and",
    "start": "439479",
    "end": "440919"
  },
  {
    "text": "inference side so it's really important",
    "start": "440919",
    "end": "443050"
  },
  {
    "text": "that you think too that peels two things",
    "start": "443050",
    "end": "444610"
  },
  {
    "text": "and like you know with with his new",
    "start": "444610",
    "end": "447220"
  },
  {
    "text": "releases we are simplifying you know you",
    "start": "447220",
    "end": "449350"
  },
  {
    "text": "have the option like like lambda",
    "start": "449350",
    "end": "450940"
  },
  {
    "text": "inference we've got change maker",
    "start": "450940",
    "end": "452500"
  },
  {
    "text": "inference now with the imagine that in a",
    "start": "452500",
    "end": "454960"
  },
  {
    "text": "model hosting so server like we are",
    "start": "454960",
    "end": "457570"
  },
  {
    "text": "simplifying this hosting piece right in",
    "start": "457570",
    "end": "461380"
  },
  {
    "text": "this particular article you will create",
    "start": "461380",
    "end": "463750"
  },
  {
    "text": "the absolutely server less server less",
    "start": "463750",
    "end": "466750"
  },
  {
    "text": "cluster based on ECS this is like a",
    "start": "466750",
    "end": "469180"
  },
  {
    "text": "high-level overview of the cluster will",
    "start": "469180",
    "end": "471490"
  },
  {
    "text": "have a lower bounds on from that",
    "start": "471490",
    "end": "473050"
  },
  {
    "text": "actually serving the traffic and sends",
    "start": "473050",
    "end": "475210"
  },
  {
    "text": "the traffic to the Fargate task",
    "start": "475210",
    "end": "476849"
  },
  {
    "text": "underneath and we collecting all the",
    "start": "476849",
    "end": "479349"
  },
  {
    "text": "logs metrics in cloud watch so we can",
    "start": "479349",
    "end": "481240"
  },
  {
    "text": "use this logs metric to decide when you",
    "start": "481240",
    "end": "483039"
  },
  {
    "text": "want to scale up your cluster or scale",
    "start": "483039",
    "end": "485080"
  },
  {
    "text": "down and i'm not going to actually walk",
    "start": "485080",
    "end": "487510"
  },
  {
    "text": "you through to the actual cluster",
    "start": "487510",
    "end": "488650"
  },
  {
    "text": "creation right now but let's say you",
    "start": "488650",
    "end": "490630"
  },
  {
    "text": "already finish the article in the end he",
    "start": "490630",
    "end": "492460"
  },
  {
    "text": "will have load balancer so if you just",
    "start": "492460",
    "end": "494860"
  },
  {
    "text": "copy/paste the DNS name of the ward",
    "start": "494860",
    "end": "497440"
  },
  {
    "text": "bouncer and the end of the article you",
    "start": "497440",
    "end": "499240"
  },
  {
    "text": "can basically run this same inference so",
    "start": "499240",
    "end": "501940"
  },
  {
    "text": "first let me being to verify that groups",
    "start": "501940",
    "end": "504419"
  },
  {
    "text": "to really find that our load balancer",
    "start": "504419",
    "end": "507190"
  },
  {
    "text": "actually healthy and now again let me go",
    "start": "507190",
    "end": "509410"
  },
  {
    "text": "and go to base inference of the same",
    "start": "509410",
    "end": "511240"
  },
  {
    "text": "kitten that I'm going to send life to my",
    "start": "511240",
    "end": "513640"
  },
  {
    "text": "ECS forget surveillance cluster",
    "start": "513640",
    "end": "516279"
  },
  {
    "text": "with three tasks and I will have the",
    "start": "516279",
    "end": "518379"
  },
  {
    "text": "same result Egyptian right yes so this",
    "start": "518379",
    "end": "521740"
  },
  {
    "text": "is fully server less influence only CS",
    "start": "521740",
    "end": "524920"
  },
  {
    "text": "with MMS and far gate this is great like",
    "start": "524920",
    "end": "527949"
  },
  {
    "text": "I don't know if you can go back to the",
    "start": "527949",
    "end": "529959"
  },
  {
    "text": "config file so having worked with web",
    "start": "529959",
    "end": "532569"
  },
  {
    "text": "servers a long time back I've built a",
    "start": "532569",
    "end": "534879"
  },
  {
    "text": "lot of web servers in my life all right",
    "start": "534879",
    "end": "536740"
  },
  {
    "text": "what I love is the options right like",
    "start": "536740",
    "end": "538480"
  },
  {
    "text": "the log rotation I mean some of the",
    "start": "538480",
    "end": "539800"
  },
  {
    "text": "things that people sort of forget like",
    "start": "539800",
    "end": "541809"
  },
  {
    "text": "at scale what can happen so it's great",
    "start": "541809",
    "end": "544300"
  },
  {
    "text": "to see me like when I see that like it",
    "start": "544300",
    "end": "546579"
  },
  {
    "text": "tells me like if I've taught through all",
    "start": "546579",
    "end": "548740"
  },
  {
    "text": "that you need to operate at scale which",
    "start": "548740",
    "end": "551110"
  },
  {
    "text": "is really important for us at AWS",
    "start": "551110",
    "end": "552730"
  },
  {
    "text": "because you're not only thinking about",
    "start": "552730",
    "end": "554499"
  },
  {
    "text": "in a few we want we want to make sure",
    "start": "554499",
    "end": "556779"
  },
  {
    "text": "the products actually scale and glad to",
    "start": "556779",
    "end": "559360"
  },
  {
    "text": "see that are being incorporated into a",
    "start": "559360",
    "end": "561160"
  },
  {
    "text": "product like this yes and basically they",
    "start": "561160",
    "end": "564579"
  },
  {
    "text": "said the only thing that we need to",
    "start": "564579",
    "end": "565870"
  },
  {
    "text": "change is one line with the model but as",
    "start": "565870",
    "end": "567579"
  },
  {
    "text": "you grow you can actually be tuned with",
    "start": "567579",
    "end": "568930"
  },
  {
    "text": "everyone like for that actually is a",
    "start": "568930",
    "end": "570699"
  },
  {
    "text": "severability single proxy or anything",
    "start": "570699",
    "end": "572800"
  },
  {
    "text": "you want right any for some reason you",
    "start": "572800",
    "end": "575110"
  },
  {
    "text": "do want to run if you your premises you",
    "start": "575110",
    "end": "576999"
  },
  {
    "text": "can set up a guess or ECS just with a",
    "start": "576999",
    "end": "579009"
  },
  {
    "text": "few instances any of them yes do we have",
    "start": "579009",
    "end": "583930"
  },
  {
    "text": "any questions from Ray Internet I think",
    "start": "583930",
    "end": "588129"
  },
  {
    "text": "people have been happy I don't see any",
    "start": "588129",
    "end": "590649"
  },
  {
    "text": "questions here but just to maybe we can",
    "start": "590649",
    "end": "593259"
  },
  {
    "text": "just start summarizing right like how",
    "start": "593259",
    "end": "598360"
  },
  {
    "text": "can customers start like let's let's go",
    "start": "598360",
    "end": "600129"
  },
  {
    "text": "there like how can somebody get started",
    "start": "600129",
    "end": "601809"
  },
  {
    "text": "yes so when they said you just need to",
    "start": "601809",
    "end": "604449"
  },
  {
    "text": "do a three simple step you basically",
    "start": "604449",
    "end": "606399"
  },
  {
    "text": "spinning up a deep learning ami or any",
    "start": "606399",
    "end": "608110"
  },
  {
    "text": "environment when you do want to test you",
    "start": "608110",
    "end": "610059"
  },
  {
    "text": "inference you starting simple in pipe i",
    "start": "610059",
    "end": "611800"
  },
  {
    "text": "package that already have model server",
    "start": "611800",
    "end": "613899"
  },
  {
    "text": "in it and then you've just testing your",
    "start": "613899",
    "end": "616120"
  },
  {
    "text": "model wheezes mms error and basically",
    "start": "616120",
    "end": "618670"
  },
  {
    "text": "the only thing you need to do to start",
    "start": "618670",
    "end": "620170"
  },
  {
    "text": "it is the link for the model we do have",
    "start": "620170",
    "end": "622750"
  },
  {
    "text": "a model do that has a tons of already",
    "start": "622750",
    "end": "624819"
  },
  {
    "text": "pre-configured predefined models on onyx",
    "start": "624819",
    "end": "627970"
  },
  {
    "text": "that you can play with then you can",
    "start": "627970",
    "end": "630490"
  },
  {
    "text": "actually the second step you do need to",
    "start": "630490",
    "end": "632139"
  },
  {
    "text": "prepare a container actually I'm a mess",
    "start": "632139",
    "end": "634029"
  },
  {
    "text": "capable of running more than one model",
    "start": "634029",
    "end": "636009"
  },
  {
    "text": "at the same time on the same server when",
    "start": "636009",
    "end": "638019"
  },
  {
    "text": "I when I yes so yeah",
    "start": "638019",
    "end": "640690"
  },
  {
    "text": "just to sort of summarize through I",
    "start": "640690",
    "end": "643060"
  },
  {
    "text": "think here you go you have a model right",
    "start": "643060",
    "end": "645580"
  },
  {
    "text": "like now we want to build an endpoint so",
    "start": "645580",
    "end": "647650"
  },
  {
    "text": "what you can do is with the model server",
    "start": "647650",
    "end": "650220"
  },
  {
    "text": "when we basically have a config file",
    "start": "650220",
    "end": "653080"
  },
  {
    "text": "that's shown here you can just plug in",
    "start": "653080",
    "end": "655660"
  },
  {
    "text": "your config file and the model in the",
    "start": "655660",
    "end": "658390"
  },
  {
    "text": "config file and then start a scaleable",
    "start": "658390",
    "end": "660550"
  },
  {
    "text": "server like not that's that's the first",
    "start": "660550",
    "end": "663190"
  },
  {
    "text": "version the simplest version the model",
    "start": "663190",
    "end": "666220"
  },
  {
    "text": "server brings you but the the additional",
    "start": "666220",
    "end": "669190"
  },
  {
    "text": "capability we add today is you can bring",
    "start": "669190",
    "end": "671080"
  },
  {
    "text": "in a container because you can have",
    "start": "671080",
    "end": "672310"
  },
  {
    "text": "dependency in terms of your libraries",
    "start": "672310",
    "end": "674410"
  },
  {
    "text": "are you doing something more",
    "start": "674410",
    "end": "675610"
  },
  {
    "text": "sophisticated you can bring in your",
    "start": "675610",
    "end": "677350"
  },
  {
    "text": "container and run it in the model server",
    "start": "677350",
    "end": "679240"
  },
  {
    "text": "with a similar config file so that's the",
    "start": "679240",
    "end": "682570"
  },
  {
    "text": "key here but moreover you can get all of",
    "start": "682570",
    "end": "685930"
  },
  {
    "text": "this on forget and have a completely",
    "start": "685930",
    "end": "691980"
  },
  {
    "text": "hands-off approach to getting it hosted",
    "start": "691980",
    "end": "695050"
  },
  {
    "text": "and having a scalable endpoint I mean",
    "start": "695050",
    "end": "697570"
  },
  {
    "text": "that's the key here like that's the",
    "start": "697570",
    "end": "699280"
  },
  {
    "text": "end-to-end story and I just wanted to",
    "start": "699280",
    "end": "701110"
  },
  {
    "text": "mention for our power users if you're",
    "start": "701110",
    "end": "703660"
  },
  {
    "text": "planning to use MMS for your on your",
    "start": "703660",
    "end": "706060"
  },
  {
    "text": "particular instances CPU container is",
    "start": "706060",
    "end": "708340"
  },
  {
    "text": "optimized for spy like CPU which is",
    "start": "708340",
    "end": "710680"
  },
  {
    "text": "essentially our C pipe instances and of",
    "start": "710680",
    "end": "713350"
  },
  {
    "text": "course GPU one optimized for our p3",
    "start": "713350",
    "end": "715450"
  },
  {
    "text": "instances who is using canned media",
    "start": "715450",
    "end": "717310"
  },
  {
    "text": "water underneath just a piece of",
    "start": "717310",
    "end": "719470"
  },
  {
    "text": "information to keep in mind when you're",
    "start": "719470",
    "end": "720940"
  },
  {
    "text": "actually planning to bootstrap a cluster",
    "start": "720940",
    "end": "723160"
  },
  {
    "text": "on your own instances and where were",
    "start": "723160",
    "end": "725770"
  },
  {
    "text": "they what's the link that people should",
    "start": "725770",
    "end": "727870"
  },
  {
    "text": "go to check check this out Oh everything",
    "start": "727870",
    "end": "732040"
  },
  {
    "text": "is available in our article that",
    "start": "732040",
    "end": "733810"
  },
  {
    "text": "basically I'm showing right now so both",
    "start": "733810",
    "end": "735160"
  },
  {
    "text": "on the P show get copied the blares slop",
    "start": "735160",
    "end": "738490"
  },
  {
    "text": "I'm excited or server and check out the",
    "start": "738490",
    "end": "740470"
  },
  {
    "text": "latest article MMS on the pocket",
    "start": "740470",
    "end": "744430"
  },
  {
    "text": "yeah so the codes available guys go",
    "start": "744430",
    "end": "746290"
  },
  {
    "text": "check it out in WS labs as MX net -",
    "start": "746290",
    "end": "749650"
  },
  {
    "text": "model - server",
    "start": "749650",
    "end": "751810"
  },
  {
    "text": "learn how to build a scalable endpoint",
    "start": "751810",
    "end": "754089"
  },
  {
    "text": "end-to-end",
    "start": "754089",
    "end": "755340"
  },
  {
    "text": "bringing you a container and use the mxf",
    "start": "755340",
    "end": "758820"
  },
  {
    "text": "model server along with forget to build",
    "start": "758820",
    "end": "761310"
  },
  {
    "text": "a scalable and fun alright thank you",
    "start": "761310",
    "end": "763440"
  },
  {
    "text": "very thank you",
    "start": "763440",
    "end": "765860"
  }
]